
@Article{su7067604,
AUTHOR = {Lu, Dong and Tian, Ye and Liu, Vincent Y. and Zhang, Yi},
TITLE = {The Performance of the Smart Cities in China—A Comparative Study by Means of Self-Organizing Maps and Social  Networks Analysis},
JOURNAL = {Sustainability},
VOLUME = {7},
YEAR = {2015},
NUMBER = {6},
PAGES = {7604--7621},
URL = {https://www.mdpi.com/2071-1050/7/6/7604},
ISSN = {2071-1050},
ABSTRACT = {Smart cities link the city services, citizens, resource and infrastructures together and form the heart of the modern society. As a “smart” ecosystem, smart cities focus on sustainable growth, efficiency, productivity and environmentally friendly development. By comparing with the European Union, North America and other countries, smart cities in China are still in the preliminary stage. This study offers a comparative analysis of ten smart cities in China on the basis of an extensive database covering two time periods: 2005–2007 and 2008–2010. The unsupervised computational neural network self-organizing map (SOM) analysis is adopted to map out the various cities based on their performance. The demonstration effect and mutual influences between these ten smart cities are also discussed by using social network analysis. Based on the smart city performance and cluster network, current problems for smart city development in China were pointed out. Future research directions for smart city research are discussed at the end this paper.},
DOI = {10.3390/su7067604}
}



@Article{s17122812,
AUTHOR = {Mahapatra, Chinmaya and Moharana, Akshaya Kumar and Leung, Victor C. M.},
TITLE = {Energy Management in Smart Cities Based on Internet of Things: Peak Demand Reduction and Energy Savings},
JOURNAL = {Sensors},
VOLUME = {17},
YEAR = {2017},
NUMBER = {12},
ARTICLE-NUMBER = {2812},
URL = {https://www.mdpi.com/1424-8220/17/12/2812},
ISSN = {1424-8220},
ABSTRACT = {Around the globe, innovation with integrating information and communication technologies (ICT) with physical infrastructure is a top priority for governments in pursuing smart, green living to improve energy efficiency, protect the environment, improve the quality of life, and bolster economy competitiveness. Cities today faces multifarious challenges, among which energy efficiency of homes and residential dwellings is a key requirement. Achieving it successfully with the help of intelligent sensors and contextual systems would help build smart cities of the future. In a Smart home environment Home Energy Management plays a critical role in finding a suitable and reliable solution to curtail the peak demand and achieve energy conservation. In this paper, a new method named as Home Energy Management as a Service (HEMaaS) is proposed which is based on neural network based Q-learning algorithm. Although several attempts have been made in the past to address similar problems, the models developed do not cater to maximize the user convenience and robustness of the system. In this paper, authors have proposed an advanced Neural Fitted Q-learning method which is self-learning and adaptive. The proposed method provides an agile, flexible and energy efficient decision making system for home energy management. A typical Canadian residential dwelling model has been used in this paper to test the proposed method. Based on analysis, it was found that the proposed method offers a fast and viable solution to reduce the demand and conserve energy during peak period. It also helps reducing the carbon footprint of residential dwellings. Once adopted, city blocks with significant residential dwellings can significantly reduce the total energy consumption by reducing or shifting their energy demand during peak period. This would definitely help local power distribution companies to optimize their resources and keep the tariff low due to curtailment of peak demand.},
DOI = {10.3390/s17122812}
}



@Article{su10010037,
AUTHOR = {Shi, Hongbo and Tsai, Sang-Bing and Lin, Xiaowei and Zhang, Tianyi},
TITLE = {How to Evaluate Smart Cities’ Construction? A Comparison of Chinese Smart City Evaluation Methods Based on PSF},
JOURNAL = {Sustainability},
VOLUME = {10},
YEAR = {2018},
NUMBER = {1},
ARTICLE-NUMBER = {37},
URL = {https://www.mdpi.com/2071-1050/10/1/37},
ISSN = {2071-1050},
ABSTRACT = {With the rapid development of smart cities in the world, research relating to smart city evaluation has become a new research hotspot in academia. However, there are general problems of cognitive deprivation, lack of planning experience, and low level of coordination in smart cities construction. It is necessary for us to develop a set of scientific, reasonable, and effective evaluation index systems and evaluation models to analyze the development degree of urban wisdom. Based on the theory of the urban system, we established a comprehensive evaluation index system for urban intelligent development based on the people-oriented, city-system, and resources-flow (PSF) evaluation model. According to the characteristics of the comprehensive evaluation index system of urban intelligent development, the analytic hierarchy process (AHP) combined with the experts’ opinions determine the index weight of this system. We adopted the neural network model to construct the corresponding comprehensive evaluation model to characterize the non-linear characteristics of the comprehensive evaluation indexes system, thus to quantitatively quantify the comprehensive evaluation indexes of urban intelligent development. Finally, we used the AHP, AHP-BP (Back Propagation), and AHP-ELM (Extreme Learning Machine) models to evaluate the intelligent development level of 151 cities in China, and compared them from the perspective of model accuracy and time cost. The final simulation results show that the AHP-ELM model is the best evaluation model.},
DOI = {10.3390/su10010037}
}



@Article{ijgi7010037,
AUTHOR = {Ma, Chunyong and Zhang, Yu and Wang, Anni and Wang, Yuan and Chen, Ge},
TITLE = {Traffic Command Gesture Recognition for Virtual Urban Scenes Based on a Spatiotemporal Convolution Neural Network},
JOURNAL = {ISPRS International Journal of Geo-Information},
VOLUME = {7},
YEAR = {2018},
NUMBER = {1},
ARTICLE-NUMBER = {37},
URL = {https://www.mdpi.com/2220-9964/7/1/37},
ISSN = {2220-9964},
ABSTRACT = {Intelligent recognition of traffic police command gestures increases authenticity and interactivity in virtual urban scenes. To actualize real-time traffic gesture recognition, a novel spatiotemporal convolution neural network (ST-CNN) model is presented. We utilized Kinect 2.0 to construct a traffic police command gesture skeleton (TPCGS) dataset collected from 10 volunteers. Subsequently, convolution operations on the locational change of each skeletal point were performed to extract temporal features, analyze the relative positions of skeletal points, and extract spatial features. After temporal and spatial features based on the three-dimensional positional information of traffic police skeleton points were extracted, the ST-CNN model classified positional information into eight types of Chinese traffic police gestures. The test accuracy of the ST-CNN model was 96.67%. In addition, a virtual urban traffic scene in which real-time command tests were carried out was set up, and a real-time test accuracy rate of 93.0% was achieved. The proposed ST-CNN model ensured a high level of accuracy and robustness. The ST-CNN model recognized traffic command gestures, and such recognition was found to control vehicles in virtual traffic environments, which enriches the interactive mode of the virtual city scene. Traffic command gesture recognition contributes to smart city construction.},
DOI = {10.3390/ijgi7010037}
}



@Article{electronics8030273,
AUTHOR = {Cui, Xin and Huang, Xiaohong and Ma, Yan and Meng, Qingke},
TITLE = {A Load Balancing Routing Mechanism Based on SDWSN in Smart City},
JOURNAL = {Electronics},
VOLUME = {8},
YEAR = {2019},
NUMBER = {3},
ARTICLE-NUMBER = {273},
URL = {https://www.mdpi.com/2079-9292/8/3/273},
ISSN = {2079-9292},
ABSTRACT = {In the wireless sensor network infrastructure of smart cities, whether the network traffic is balanced will directly affect the service quality of the network. Because of the traditional WSN (wireless sensor network) architecture, load balancing technology is difficult to meet the requirements of adaptability and high flexibility. This paper proposes a load balancing mechanism based on SDWSN (software defined wireless sensor network). This mechanism utilizes the advantages of a centralized control SDN (software defined network) and flexible traffic scheduling. The OpenFlow protocol is used to monitor the running status and link load information of the network in real time. According to the bandwidth requirement of the data flow, the improved load balanced routing is obtained by an Elman neural network. The simulation results show that the improved SDSNLB (software-defined sensor network load balancing) routing algorithm has better performance than LEACH (Low Energy Adaptive Clustering Hierarchy) protocol in balancing node traffic and improving throughput.},
DOI = {10.3390/electronics8030273}
}



@Article{en12050929,
AUTHOR = {Aymen, Flah and Mahmoudi, Chokri},
TITLE = {A Novel Energy Optimization Approach for Electrical Vehicles in a Smart City},
JOURNAL = {Energies},
VOLUME = {12},
YEAR = {2019},
NUMBER = {5},
ARTICLE-NUMBER = {929},
URL = {https://www.mdpi.com/1996-1073/12/5/929},
ISSN = {1996-1073},
ABSTRACT = {Electric Vehicles (EVs) have emerged rapidly across the globe as a powerful eco-friendly initiative that if integrated well with an urban environment could be iconic for the host city&rsquo;s commitment to sustainable mobility and be a key ingredient of the smart city concept. This paper examines ways that will help us to develop a better understanding of how EVs can achieve energy use optimization and be connected with a smart city. As a whole, the present study is based on an original idea that would be useful in informing policy-makers, automotive manufacturers and transport operators of how to improve and embrace better EV technologies in the context of smart cities. The proposed approach is based on vehicles&rsquo; and buildings&rsquo; communication to share some special information related to the vehicles&rsquo; status and to the road conditions. EVs can share their own information related to their energy consumption experience on a specific path. This information can be gathered in a gigantic database and used for managing the power inside these vehicles. In this field, this paper exposes a new approach to power management inside an electric vehicle based on two-way communication between vehicles and buildings. The principle of this method is established in two sections; the first one is related to vehicles&rsquo; classification and the second one is attached to the buildings&rsquo; recommendations, according to the car position. The classification problem is resolved using the support vector classification method. The recommendation phase is resolved using the artificial intelligence principle and a neural network was employed to give the best decision. The optimal decision will be calculated inside the building, according to its position and using the old vehicle&rsquo;s data, and transferred to the coming vehicle, for optimizing its energy consumption method in the corresponding building zone. Different possibilities and situations in this approach were discussed. The proposed power management methodology was tested and validated using Simulink/Matlab tool. Results related to the battery state of charge and to the consumed energy were compared at the end of this work, to show the efficiency of this approach.},
DOI = {10.3390/en12050929}
}



@Article{smartcities2020009,
AUTHOR = {Allam, Zaheer},
TITLE = {Achieving Neuroplasticity in Artificial Neural Networks through Smart Cities},
JOURNAL = {Smart Cities},
VOLUME = {2},
YEAR = {2019},
NUMBER = {2},
PAGES = {118--134},
URL = {https://www.mdpi.com/2624-6511/2/2/9},
ISSN = {2624-6511},
ABSTRACT = {Through the Internet of things (IoT), as promoted by smart cities, there is an emergence of big data accentuating the use of artificial intelligence through various components of urban planning, management, and design. One such system is that of artificial neural networks (ANNs), a component of machine learning that boasts similitude with brain neurological networks and its functioning. However, the development of ANN was done in singular fashion, whereby processes are rendered in sequence in a unidimensional perspective, contrasting with the functions of the brain to which ANN boasts similitude, and in particular to the concept of neuroplasticity which encourages unique complex interactions in self-learning fashion, thereby encouraging more inclusive urban processes and render urban coherence. This paper takes inspiration from Christopher Alexander&rsquo;s Nature of Order and dwells in the concept of complexity theory; it also proposes a theoretical model of how ANN can be rendered with the same plastic properties as brain neurological networks with multidimensional interactivity in the context of smart cities through the use of big data and its emerging complex networks. By doing so, this model caters to the creation of stronger, richer, and more complex patterns that support Alexander&rsquo;s concept of &ldquo;wholeness&rdquo; through the connection of overlapping networks. This paper is aimed toward engineers with interdisciplinary interest looking at creating more complex and intricate ANN models, and toward urban planners and urban theorists working on the emerging contemporary concept of smart cities.},
DOI = {10.3390/smartcities2020009}
}



@Article{s19071676,
AUTHOR = {Baba, Marius and Gui, Vasile and Cernazanu, Cosmin and Pescaru, Dan},
TITLE = {A Sensor Network Approach for Violence Detection in Smart Cities Using Deep Learning},
JOURNAL = {Sensors},
VOLUME = {19},
YEAR = {2019},
NUMBER = {7},
ARTICLE-NUMBER = {1676},
URL = {https://www.mdpi.com/1424-8220/19/7/1676},
ISSN = {1424-8220},
ABSTRACT = {Citizen safety in modern urban environments is an important aspect of life quality. Implementation of a smart city approach to video surveillance depends heavily on the capability of gathering and processing huge amounts of live urban data. Analyzing data from high bandwidth surveillance video streams provided by large size distributed sensor networks is particularly challenging. We propose here an efficient method for automatic violent behavior detection designed for video sensor networks. Known solutions to real-time violence detection are not suitable for implementation in a resource-constrained environment due to the high processing power requirements. Our algorithm achieves real-time processing on a Raspberry PI-embedded architecture. To ensure separation of temporal and spatial information processing we employ a computationally effective cascaded approach. It consists of a deep neural network followed by a time domain classifier. In contrast with current approaches, the deep neural network input is fed exclusively with motion vector features extracted directly from the MPEG encoded video stream. As proven by results, we achieve state-of-the-art performance, while running on a low computational resources embedded architecture.},
DOI = {10.3390/s19071676}
}



@Article{s19071708,
AUTHOR = {Tan, Daniel Stanley and Yao, Chih-Yuan and Ruiz, Conrado and Hua, Kai-Lung},
TITLE = {Single-Image Depth Inference Using Generative Adversarial Networks},
JOURNAL = {Sensors},
VOLUME = {19},
YEAR = {2019},
NUMBER = {7},
ARTICLE-NUMBER = {1708},
URL = {https://www.mdpi.com/1424-8220/19/7/1708},
ISSN = {1424-8220},
ABSTRACT = {Depth has been a valuable piece of information for perception tasks such as robot grasping, obstacle avoidance, and navigation, which are essential tasks for developing smart homes and smart cities. However, not all applications have the luxury of using depth sensors or multiple cameras to obtain depth information. In this paper, we tackle the problem of estimating the per-pixel depths from a single image. Inspired by the recent works on generative neural network models, we formulate the task of depth estimation as a generative task where we synthesize an image of the depth map from a single Red, Green, and Blue (RGB) input image. We propose a novel generative adversarial network that has an encoder-decoder type generator with residual transposed convolution blocks trained with an adversarial loss. Quantitative and qualitative experimental results demonstrate the effectiveness of our approach over several depth estimation works.},
DOI = {10.3390/s19071708}
}



@Article{s19091987,
AUTHOR = {Zhang, Hong and Zhang, Zeyu and Zhang, Lei and Yang, Yifan and Kang, Qiaochu and Sun, Daniel},
TITLE = {Object Tracking for a Smart City Using IoT and Edge Computing},
JOURNAL = {Sensors},
VOLUME = {19},
YEAR = {2019},
NUMBER = {9},
ARTICLE-NUMBER = {1987},
URL = {https://www.mdpi.com/1424-8220/19/9/1987},
ISSN = {1424-8220},
ABSTRACT = {As the Internet-of-Things (IoT) and edge computing have been major paradigms for distributed data collection, communication, and processing, smart city applications in the real world tend to adopt IoT and edge computing broadly. Today, more and more machine learning algorithms would be deployed into front-end sensors, devices, and edge data centres rather than centralised cloud data centres. However, front-end sensors and devices are usually not so capable as those computing units in huge data centres, and for this sake, in practice, engineers choose to compromise for limited capacity of embedded computing and limited memory, e.g., neural network models being pruned to fit embedded devices. Visual object tracking is one of many important elements of a smart city, and in the IoT and edge computing context, high requirements to computing power and memory space severely prevent massive and accurate tracking. In this paper, we report on our contribution to object tracking on lightweight computing including (1) using limited computing capacity and memory space to realise tracking; (2) proposing a new algorithm region proposal correlation filter fitting for most edge devices. Systematic evaluations show that (1) our techniques can fit most IoT devices; (2) our techniques can keep relatively high accuracy; and (3) the generated model size is much less than others.},
DOI = {10.3390/s19091987}
}



@Article{s19112472,
AUTHOR = {Ullah, Fath U Min and Ullah, Amin and Muhammad, Khan and Haq, Ijaz Ul and Baik, Sung Wook},
TITLE = {Violence Detection Using Spatiotemporal Features with 3D Convolutional Neural Network},
JOURNAL = {Sensors},
VOLUME = {19},
YEAR = {2019},
NUMBER = {11},
ARTICLE-NUMBER = {2472},
URL = {https://www.mdpi.com/1424-8220/19/11/2472},
ISSN = {1424-8220},
ABSTRACT = {The worldwide utilization of surveillance cameras in smart cities has enabled researchers to analyze a gigantic volume of data to ensure automatic monitoring. An enhanced security system in smart cities, schools, hospitals, and other surveillance domains is mandatory for the detection of violent or abnormal activities to avoid any casualties which could cause social, economic, and ecological damages. Automatic detection of violence for quick actions is very significant and can efficiently assist the concerned departments. In this paper, we propose a triple-staged end-to-end deep learning violence detection framework. First, persons are detected in the surveillance video stream using a light-weight convolutional neural network (CNN) model to reduce and overcome the voluminous processing of useless frames. Second, a sequence of 16 frames with detected persons is passed to 3D CNN, where the spatiotemporal features of these sequences are extracted and fed to the Softmax classifier. Furthermore, we optimized the 3D CNN model using an open visual inference and neural networks optimization toolkit developed by Intel, which converts the trained model into intermediate representation and adjusts it for optimal execution at the end platform for the final prediction of violent activity. After detection of a violent activity, an alert is transmitted to the nearest police station or security department to take prompt preventive actions. We found that our proposed method outperforms the existing state-of-the-art methods for different benchmark datasets.},
DOI = {10.3390/s19112472}
}



@Article{app9132630,
AUTHOR = {Le, Le Thi and Nguyen, Hoang and Dou, Jie and Zhou, Jian},
TITLE = {A Comparative Study of PSO-ANN, GA-ANN, ICA-ANN, and ABC-ANN in Estimating the Heating Load of Buildings’ Energy Efficiency for Smart City Planning},
JOURNAL = {Applied Sciences},
VOLUME = {9},
YEAR = {2019},
NUMBER = {13},
ARTICLE-NUMBER = {2630},
URL = {https://www.mdpi.com/2076-3417/9/13/2630},
ISSN = {2076-3417},
ABSTRACT = {Energy-efficiency is one of the critical issues in smart cities. It is an essential basis for optimizing smart cities planning. This study proposed four new artificial intelligence (AI) techniques for forecasting the heating load of buildings&rsquo; energy efficiency based on the potential of artificial neural network (ANN) and meta-heuristics algorithms, including artificial bee colony (ABC) optimization, particle swarm optimization (PSO), imperialist competitive algorithm (ICA), and genetic algorithm (GA). They were abbreviated as ABC-ANN, PSO-ANN, ICA-ANN, and GA-ANN models; 837 buildings were considered and analyzed based on the influential parameters, such as glazing area distribution (GLAD), glazing area (GLA), orientation (O), overall height (OH), roof area (RA), wall area (WA), surface area (SA), relative compactness (RC), for estimating heating load (HL). Three statistical criteria, such as root-mean-squared error (RMSE), coefficient determination (R2), and mean absolute error (MAE), were used to assess the potential of the aforementioned models. The results indicated that the GA-ANN model provided the highest performance in estimating the heating load of buildings&rsquo; energy efficiency, with an RMSE of 1.625, R2 of 0.980, and MAE of 0.798. The remaining models (i.e., PSO-ANN, ICA-ANN, ABC-ANN) yielded lower performance with RMSE of 1.932, 1.982, 1.878; R2 of 0.972, 0.970, 0.973; MAE of 1.027, 0.980, 0.957, respectively.},
DOI = {10.3390/app9132630}
}



@Article{infrastructures4030052,
AUTHOR = {Serrano, Will},
TITLE = {Deep Reinforcement Learning Algorithms in Intelligent Infrastructure},
JOURNAL = {Infrastructures},
VOLUME = {4},
YEAR = {2019},
NUMBER = {3},
ARTICLE-NUMBER = {52},
URL = {https://www.mdpi.com/2412-3811/4/3/52},
ISSN = {2412-3811},
ABSTRACT = {Intelligent infrastructure, including smart cities and intelligent buildings, must learn and adapt to the variable needs and requirements of users, owners and operators in order to be future proof and to provide a return on investment based on Operational Expenditure (OPEX) and Capital Expenditure (CAPEX). To address this challenge, this article presents a biological algorithm based on neural networks and deep reinforcement learning that enables infrastructure to be intelligent by making predictions about its different variables. In addition, the proposed method makes decisions based on real time data. Intelligent infrastructure must be able to proactively monitor, protect and repair itself: this includes independent components and assets working the same way any autonomous biological organisms would. Neurons of artificial neural networks are associated with a prediction or decision layer based on a deep reinforcement learning algorithm that takes into consideration all of its previous learning. The proposed method was validated against an intelligent infrastructure dataset with outstanding results: the intelligent infrastructure was able to learn, predict and adapt to its variables, and components could make relevant decisions autonomously, emulating a living biological organism in which data flow exhaustively.},
DOI = {10.3390/infrastructures4030052}
}



@Article{ijerph16193505,
AUTHOR = {Mo, Xinyue and Zhang, Lei and Li, Huan and Qu, Zongxi},
TITLE = {A Novel Air Quality Early-Warning System Based on Artificial Intelligence},
JOURNAL = {International Journal of Environmental Research and Public Health},
VOLUME = {16},
YEAR = {2019},
NUMBER = {19},
ARTICLE-NUMBER = {3505},
URL = {https://www.mdpi.com/1660-4601/16/19/3505},
PubMedID = {31547044},
ISSN = {1660-4601},
ABSTRACT = {The problem of air pollution is a persistent issue for mankind and becoming increasingly serious in recent years, which has drawn worldwide attention. Establishing a scientific and effective air quality early-warning system is really significant and important. Regretfully, previous research didn&rsquo;t thoroughly explore not only air pollutant prediction but also air quality evaluation, and relevant research work is still scarce, especially in China. Therefore, a novel air quality early-warning system composed of prediction and evaluation was developed in this study. Firstly, the advanced data preprocessing technology Improved Complete Ensemble Empirical Mode Decomposition with Adaptive Noise (ICEEMDAN) combined with the powerful swarm intelligence algorithm Whale Optimization Algorithm (WOA) and the efficient artificial neural network Extreme Learning Machine (ELM) formed the prediction model. Then the predictive results were further analyzed by the method of fuzzy comprehensive evaluation, which offered intuitive air quality information and corresponding measures. The proposed system was tested in the Jing-Jin-Ji region of China, a representative research area in the world, and the daily concentration data of six main air pollutants in Beijing, Tianjin, and Shijiazhuang for two years were used to validate the accuracy and efficiency. The results show that the prediction model is superior to other benchmark models in pollutant concentration prediction and the evaluation model is satisfactory in air quality level reporting compared with the actual status. Therefore, the proposed system is believed to play an important role in air pollution control and smart city construction all over the world in the future.},
DOI = {10.3390/ijerph16193505}
}



@Article{info11020064,
AUTHOR = {Fu, Qianwen and Lv, Jian and Zhao, Zeyu and Yue, Di},
TITLE = {Research on Optimization Method of VR Task Scenario Resources Driven by User Cognitive Needs},
JOURNAL = {Information},
VOLUME = {11},
YEAR = {2020},
NUMBER = {2},
ARTICLE-NUMBER = {64},
URL = {https://www.mdpi.com/2078-2489/11/2/64},
ISSN = {2078-2489},
ABSTRACT = {Research was performed in order to improve the efficiency of a user&rsquo;s access to information and the interactive experience of task selection in a virtual reality (VR) system, reduce the level of a user&rsquo;s cognitive load, and improve the efficiency of designers in building a VR system. On the basis of user behavior cognition-system resource mapping, a task scenario resource optimization method for VR system based on quality function deployment-convolution neural network (QFD-CNN) was proposed. Firstly, under the guidance of user behavior cognition, the characteristics of multi-channel information resources in a VR system were analyzed, and the correlation matrix of the VR system scenario resource characteristics was constructed based on the design criteria of human&ndash;computer interaction, cognition, and low-load demand. Secondly, analytic hierarchy process (AHP)-QFD combined with evaluation matrix is used to output the priority ranking of VR system resource characteristics. Then, the VR system task scenario cognitive load experiment is carried out on users, and the CNN input set and output set data are collected through the experiment, in order to build a CNN system and predict the user cognitive load and satisfaction in the human&ndash;computer interaction in the VR system. Finally, combined with the task information interface of a VR system in a smart city, the application research of the system resource feature optimization method under multi-channel cognition is carried out. The results show that the test coefficient CR value of the AHP-QFD model based on cognitive load is less than 0.1, and the MSE of CNN prediction model network is 0.004247, which proves the effectiveness of this model. According to the requirements of the same design task in a VR system, by comparing the scheme formed by the traditional design process with the scheme optimized by the method in this paper, the results show that the user has a lower cognitive load and better task operation experience when interacting with the latter scheme, so the optimization method studied in this paper can provide a reference for the system construction of virtual reality.},
DOI = {10.3390/info11020064}
}



@Article{info11040183,
AUTHOR = {Avanzato, Roberta and Beritelli, Francesco},
TITLE = {An Innovative Acoustic Rain Gauge Based on Convolutional Neural Networks},
JOURNAL = {Information},
VOLUME = {11},
YEAR = {2020},
NUMBER = {4},
ARTICLE-NUMBER = {183},
URL = {https://www.mdpi.com/2078-2489/11/4/183},
ISSN = {2078-2489},
ABSTRACT = {An accurate estimate of rainfall levels is fundamental in numerous application scenarios: weather forecasting, climate models, design of hydraulic structures, precision agriculture, etc. An accurate estimate becomes essential to be able to warn of the imminent occurrence of a calamitous event and reduce the risk to human beings. Unfortunately, to date, traditional techniques for estimating rainfall levels present numerous critical issues. The algorithm applies the Convolution Neural Network (CNN) directly to the audio signal, using 3 s sliding windows with an offset of only 100 milliseconds. Therefore, by using low cost and low power hardware, the proposed algorithm allows implementing critical high rainfall event alerting mechanisms with short response times and low estimation errors. More specifically, this paper proposes a new approach to rainfall estimation based on the classification of different acoustic timbres that rain produces at different intensities and on CNN. The results obtained on seven classes ranging from &ldquo;No rain&rdquo; to &ldquo;Cloudburst&rdquo; indicate an average accuracy of 75%, which rises to 93% if the misclassifications of the adjacent classes are not considered. Some application contexts concern smart cities for which the integration of an audio sensor inside the luminaire of a street lamp is foreseen, precision agriculture, as well as highway safety, by minimizing the risks of aquaplaning.},
DOI = {10.3390/info11040183}
}



@Article{s20071941,
AUTHOR = {Szeląg, Bartosz and Drewnowski, Jakub and Łagód, Grzegorz and Majerek, Dariusz and Dacewicz, Ewa and Fatone, Francesco},
TITLE = {Soft Sensor Application in Identification of the Activated Sludge Bulking Considering the Technological and Economical Aspects of Smart Systems Functioning},
JOURNAL = {Sensors},
VOLUME = {20},
YEAR = {2020},
NUMBER = {7},
ARTICLE-NUMBER = {1941},
URL = {https://www.mdpi.com/1424-8220/20/7/1941},
ISSN = {1424-8220},
ABSTRACT = {The paper presented the methodology for the construction of a soft sensor used for activated sludge bulking identification. Devising such solutions fits within the current trends and development of a smart system and infrastructure within smart cities. In order to optimize the selection of the data-mining method depending on the data collected within a wastewater treatment plant (WWTP), a number of methods were considered, including: artificial neural networks, support vector machines, random forests, boosted trees, and logistic regression. The analysis conducted sought the combinations of independent variables for which the devised soft sensor is characterized with high accuracy and at a relatively low cost of determination. With the measurement results pertaining to the quantity and quality of wastewater as well as the temperature in the activated sludge chambers, a good fit can be achieved with the boosted trees method. In order to simplify the selection of an optimal method for the identification of activated sludge bulking depending on the model requirements and the data collected within the WWTP, an original system of weight estimation was proposed, enabling a reduction in the number of independent variables in a model&mdash;quantity and quality of wastewater, operational parameters, and the cost of conducting measurements.},
DOI = {10.3390/s20071941}
}



@Article{s20123348,
AUTHOR = {Ma, Yicao and Liu, Shifeng and Xue, Gang and Gong, Daqing},
TITLE = {Soft Sensor with Deep Learning for Functional Region Detection in Urban Environments},
JOURNAL = {Sensors},
VOLUME = {20},
YEAR = {2020},
NUMBER = {12},
ARTICLE-NUMBER = {3348},
URL = {https://www.mdpi.com/1424-8220/20/12/3348},
ISSN = {1424-8220},
ABSTRACT = {The rapid development of urbanization has increased traffic pressure and made the identification of urban functional regions a popular research topic. Some studies have used point of interest (POI) data and smart card data (SCD) to conduct subway station classifications; however, the unity of both the model and the dataset limits the prediction results. This paper not only uses SCD and POI data, but also adds Online to Offline (OTO) e-commerce platform data, an application that provides customers with information about different businesses, like the location, the score, the comments, and so on. In this paper, these data are combined to and used to analyze each subway station, considering the diversity of data, and obtain a passenger flow feature map of different stations, the number of different types of POIs within 800 m, and the situation of surrounding OTO stores. This paper proposes a two-stage framework, to identify the functional region of subway stations. In the passenger flow stage, the SCD feature is extracted and converted to a feature map, and a ResNet model is used to get the output of stage 1. In the built environment stage, the POI and OTO features are extracted, and a deep neural network with stacked autoencoders (SAE&ndash;DNN) model is used to get the output of stage 2. Finally, the outputs of the two stages are connected and a SoftMax function is used to make the final identification of functional region. We performed experimental testing, and our experimental results show that the framework exhibits good performance and has a certain reference value in the planning of subway stations and their surroundings, contributing to the construction of smart cities.},
DOI = {10.3390/s20123348}
}



@Article{s20123503,
AUTHOR = {Crivellari, Alessandro and Beinat, Euro},
TITLE = {Trace2trace—A Feasibility Study on Neural Machine Translation Applied to Human Motion Trajectories},
JOURNAL = {Sensors},
VOLUME = {20},
YEAR = {2020},
NUMBER = {12},
ARTICLE-NUMBER = {3503},
URL = {https://www.mdpi.com/1424-8220/20/12/3503},
ISSN = {1424-8220},
ABSTRACT = {Neural machine translation is a prominent field in the computational linguistics domain. By leveraging the recent developments of deep learning, it gave birth to powerful algorithms for translating text from one language to another. This study aims to assess the feasibility of transferring the neural machine translation approach into a completely different context, namely human mobility and trajectory analysis. Building a conceptual parallelism between sentences (sequences of words) and motion traces (sequences of locations), we aspire to translate individual trajectories generated by a certain category of users into the corresponding mobility traces potentially generated by a different category of users. The experiment is inserted in the background of tourist mobility analysis, with the goal of translating the motion behavior of tourists belonging to a specific nationality into the motion behavior of tourists belonging to a different nationality. The model adopted is based on the seq2seq approach and consists of an encoder&ndash;decoder architecture based on long short-term memory (LSTM) neural networks and neural embeddings. The encoder turns an input location sequence into a corresponding hidden vector; the decoder reverses the process, turning the vector into an output location sequence. The proposed framework, tested on a real-world large-scale dataset, explores an effective attempt of motion transformation between different entities, arising as a potentially powerful source of mobility information disclosure, especially in the context of crowd management and smart city services.},
DOI = {10.3390/s20123503}
}



@Article{s20133749,
AUTHOR = {Awan, Faraz Malik and Minerva, Roberto and Crespi, Noel},
TITLE = {Improving Road Traffic Forecasting Using Air Pollution and Atmospheric Data: Experiments Based on LSTM Recurrent Neural Networks},
JOURNAL = {Sensors},
VOLUME = {20},
YEAR = {2020},
NUMBER = {13},
ARTICLE-NUMBER = {3749},
URL = {https://www.mdpi.com/1424-8220/20/13/3749},
ISSN = {1424-8220},
ABSTRACT = {Traffic flow forecasting is one of the most important use cases related to smart cities. In addition to assisting traffic management authorities, traffic forecasting can help drivers to choose the best path to their destinations. Accurate traffic forecasting is a basic requirement for traffic management. We propose a traffic forecasting approach that utilizes air pollution and atmospheric parameters. Air pollution levels are often associated with traffic intensity, and much work is already available in which air pollution has been predicted using road traffic. However, to the best of our knowledge, an attempt to improve forecasting road traffic using air pollution and atmospheric parameters is not yet available in the literature. In our preliminary experiments, we found out the relation between traffic intensity, air pollution, and atmospheric parameters. Therefore, we believe that addition of air pollutants and atmospheric parameters can improve the traffic forecasting. Our method uses air pollution gases, including     C O , N O , N  O 2  , N  O x  ,     and     O 3    . We chose these gases because they are associated with road traffic. Some atmospheric parameters, including pressure, temperature, wind direction, and wind speed have also been considered, as these parameters can play an important role in the dispersion of the above-mentioned gases. Data related to traffic flow, air pollution, and the atmosphere were collected from the open data portal of Madrid, Spain. The long short-term memory (LSTM) recurrent neural network (RNN) was used in this paper to perform traffic forecasting.},
DOI = {10.3390/s20133749}
}



@Article{informatics7030023,
AUTHOR = {Ciaburro, Giuseppe and Iannace, Gino},
TITLE = {Improving Smart Cities Safety Using Sound Events Detection Based on Deep Neural Network Algorithms},
JOURNAL = {Informatics},
VOLUME = {7},
YEAR = {2020},
NUMBER = {3},
ARTICLE-NUMBER = {23},
URL = {https://www.mdpi.com/2227-9709/7/3/23},
ISSN = {2227-9709},
ABSTRACT = {In recent years, security in urban areas has gradually assumed a central position, focusing increasing attention on citizens, institutions and political forces. Security problems have a different nature&mdash;to name a few, we can think of the problems deriving from citizens&rsquo; mobility, then move on to microcrime, and end up with the ever-present risk of terrorism. Equipping a smart city with an infrastructure of sensors capable of alerting security managers about a possible risk becomes crucial for the safety of citizens. The use of unmanned aerial vehicles (UAVs) to manage citizens&rsquo; needs is now widespread, to highlight the possible risks to public safety. These risks were then increased using these devices to carry out terrorist attacks in various places around the world. Detecting the presence of drones is not a simple procedure given the small size and the presence of only rotating parts. This study presents the results of studies carried out on the detection of the presence of UAVs in outdoor/indoor urban sound environments. For the detection of UAVs, sensors capable of measuring the sound emitted by UAVs and algorithms based on deep neural networks capable of identifying their spectral signature that were used. The results obtained suggest the adoption of this methodology for improving the safety of smart cities.},
DOI = {10.3390/informatics7030023}
}



@Article{rs12162513,
AUTHOR = {Ma, Qiwei and Gong, Zhaoya and Kang, Jing and Tao, Ran and Dang, Anrong},
TITLE = {Measuring Functional Urban Shrinkage with Multi-Source Geospatial Big Data: A Case Study of the Beijing-Tianjin-Hebei Megaregion},
JOURNAL = {Remote Sensing},
VOLUME = {12},
YEAR = {2020},
NUMBER = {16},
ARTICLE-NUMBER = {2513},
URL = {https://www.mdpi.com/2072-4292/12/16/2513},
ISSN = {2072-4292},
ABSTRACT = {Most of the shrinking cities experience an unbalanced deurbanization across different urban areas in cities. However, traditional ways of measuring urban shrinkage are focused on tracking population loss at the city level and are unable to capture the spatially heterogeneous shrinking patterns inside a city. Consequently, the spatial mechanism and patterns of urban shrinkage inside a city remain less understood, which is unhelpful for developing accommodation strategies for shrinkage. The smart city initiatives and practices have provided a rich pool of geospatial big data resources and technologies to tackle the complexity of urban systems. Given this context, we propose a new measure for the delineation of shrinking areas within cities by introducing a new concept of functional urban shrinkage, which aims to capture the mismatch between urban built-up areas and the areas where significantly intensive human activities take place. Taking advantage of a data fusion approach to integrating multi-source geospatial big data and survey data, a general analytical framework is developed to construct functional shrinkage measures. Specifically, Landsat-8 remote sensing images were used for extracting urban built-up areas by supervised neural network classifications and Geographic Information System tools, while cellular signaling data from China Unicom Inc. was used to depict human activity areas generated by spatial clustering methods. Combining geospatial big data with urban land-use functions obtained from land surveys and Points-Of-Interests data, the framework further enables the comparison between cities from dimensions characterized by indices of spatial and urban functional characteristics and the landscape fragmentation; thus, it has the capacity to facilitate an in-depth investigation of fundamental causes and internal mechanisms of urban shrinkage. With a case study of the Beijing-Tianjin-Hebei megaregion using data from various sources collected for the year of 2018, we demonstrate the validity of this approach and its potential generalizability for other spatial contexts in facilitating timely and better-informed planning decision support.},
DOI = {10.3390/rs12162513}
}



@Article{ijgi9090493,
AUTHOR = {Andrade, Renato and Alves, Ana and Bento, Carlos},
TITLE = {POI Mining for Land Use Classification: A Case Study},
JOURNAL = {ISPRS International Journal of Geo-Information},
VOLUME = {9},
YEAR = {2020},
NUMBER = {9},
ARTICLE-NUMBER = {493},
URL = {https://www.mdpi.com/2220-9964/9/9/493},
ISSN = {2220-9964},
ABSTRACT = {The modern planning and management of urban spaces is an essential topic for smart cities and depends on up-to-date and reliable information on land use and the functional roles of the places that integrate urban areas. In the last few years, driven by the increased availability of geo-referenced data from social media, embedded sensors, and remote sensing images, various techniques have become popular for land use analysis. In this paper, we first highlight and discuss the different data types and methods usually adopted in this context, as well as their purposes. Then, based on a systematic state-of-the-art study, we focused on exploring the potential of points of interest (POIs) for land use classification, as one of the most common categories of crowdsourced data. We developed an application to automatically collect POIs for the study area, creating a dataset that was used to generate a large number of features. We used a ranking technique to select, among them, the most suitable features for classifying land use. As ground truth data, we used CORINE Land Cover (CLC), which is a solid and reliable dataset available for the whole European territory. It was used an artificial neural network (ANN) in different scenarios and our results reveal values of more than 90% for the accuracy and F-score in one experiment performed. Our analysis suggests that POI data have promising potential to characterize geographic spaces. The work described here aims to provide an alternative to the current methodologies for land use and land cover (LULC) classification, which are usually time-consuming and depend on expensive data types.},
DOI = {10.3390/ijgi9090493}
}



@Article{s20185240,
AUTHOR = {Koubaa, Anis and Ammar, Adel and Alahdab, Mahmoud and Kanhouch, Anas and Azar, Ahmad Taher},
TITLE = {DeepBrain: Experimental Evaluation of Cloud-Based Computation Offloading and Edge Computing in the Internet-of-Drones for Deep Learning Applications},
JOURNAL = {Sensors},
VOLUME = {20},
YEAR = {2020},
NUMBER = {18},
ARTICLE-NUMBER = {5240},
URL = {https://www.mdpi.com/1424-8220/20/18/5240},
ISSN = {1424-8220},
ABSTRACT = {Unmanned Aerial Vehicles (UAVs) have been very effective in collecting aerial images data for various Internet-of-Things (IoT)/smart cities applications such as search and rescue, surveillance, vehicle detection, counting, intelligent transportation systems, to name a few. However, the real-time processing of collected data on edge in the context of the Internet-of-Drones remains an open challenge because UAVs have limited energy capabilities, while computer vision techniquesconsume excessive energy and require abundant resources. This fact is even more critical when deep learning algorithms, such as convolutional neural networks (CNNs), are used for classification and detection. In this paper, we first propose a system architecture of computation offloading for Internet-connected drones. Then, we conduct a comprehensive experimental study to evaluate the performance in terms of energy, bandwidth, and delay of the cloud computation offloading approach versus the edge computing approach of deep learning applications in the context of UAVs. In particular, we investigate the tradeoff between the communication cost and the computation of the two candidate approaches experimentally. The main results demonstrate that the computation offloading approach allows us to provide much higher throughput (i.e., frames per second) as compared to the edge computing approach, despite the larger communication delays.},
DOI = {10.3390/s20185240}
}



@Article{s20195481,
AUTHOR = {Papacharalampopoulos, Alexios and Tzimanis, Konstantinos and Sabatakakis, Kyriakos and Stavropoulos, Panagiotis},
TITLE = {Deep Quality Assessment of a Solar Reflector Based on Synthetic Data: Detecting Surficial Defects from Manufacturing and Use Phase},
JOURNAL = {Sensors},
VOLUME = {20},
YEAR = {2020},
NUMBER = {19},
ARTICLE-NUMBER = {5481},
URL = {https://www.mdpi.com/1424-8220/20/19/5481},
ISSN = {1424-8220},
ABSTRACT = {Vision technologies are used in both industrial and smart city applications in order to provide advanced value products due to embedded self-monitoring and assessment services. In addition, for the full utilization of the obtained data, deep learning is now suggested for use. To this end, the current work presents the implementation of image recognition techniques alongside the original the quality assessment of a Parabolic Trough Collector (PTC) reflector surface to locate and identify surface irregularities by classifying images as either acceptable or non-acceptable. The method consists of a three-step solution that promotes an affordable implementation in a relatively small time period. More specifically, a 3D Computer Aided Design (CAD) of the PTC was used for the pre-training of neural networks, while an aluminum reflector surface was used to verify algorithm performance. The results are promising, as this method proved applicable in cases where the actual part was manufactured in small batches or under the concept of customized manufacturing. Consequently, the algorithm is capable of being trained with a limited number of data.},
DOI = {10.3390/s20195481}
}



@Article{a13100254,
AUTHOR = {Fedele, Rosario and Merenda, Massimo},
TITLE = {An IoT System for Social Distancing and Emergency Management in Smart Cities Using Multi-Sensor Data},
JOURNAL = {Algorithms},
VOLUME = {13},
YEAR = {2020},
NUMBER = {10},
ARTICLE-NUMBER = {254},
URL = {https://www.mdpi.com/1999-4893/13/10/254},
ISSN = {1999-4893},
ABSTRACT = {Smart cities need technologies that can be really applied to raise the quality of life and environment. Among all the possible solutions, Internet of Things (IoT)-based Wireless Sensor Networks (WSNs) have the potentialities to satisfy multiple needs, such as offering real-time plans for emergency management (due to accidental events or inadequate asset maintenance) and managing crowds and their spatiotemporal distribution in highly populated areas (e.g., cities or parks) to face biological risks (e.g., from a virus) by using strategies such as social distancing and movement restrictions. Consequently, the objective of this study is to present an IoT system, based on an IoT-WSN and on algorithms (Neural Network, NN, and Shortest Path Finding) that are able to recognize alarms, available exits, assembly points, safest and shortest paths, and overcrowding from real-time data gathered by sensors and cameras exploiting computer vision. Subsequently, this information is sent to mobile devices using a web platform and the Near Field Communication (NFC) technology. The results refer to two different case studies (i.e., emergency and monitoring) and show that the system is able to provide customized strategies and to face different situations, and that this is also applies in the case of a connectivity shutdown.},
DOI = {10.3390/a13100254}
}



@Article{app10217448,
AUTHOR = {Gaviria, Jorge Felipe and Escalante-Perez, Alejandra and Castiblanco, Juan Camilo and Vergara, Nicolas and Parra-Garces, Valentina and Serrano, Juan David and Zambrano, Andres Felipe and Giraldo, Luis Felipe},
TITLE = {Deep Learning-Based Portable Device for Audio Distress Signal Recognition in Urban Areas},
JOURNAL = {Applied Sciences},
VOLUME = {10},
YEAR = {2020},
NUMBER = {21},
ARTICLE-NUMBER = {7448},
URL = {https://www.mdpi.com/2076-3417/10/21/7448},
ISSN = {2076-3417},
ABSTRACT = {Real-time automatic identification of audio distress signals in urban areas is a task that in a smart city can improve response times in emergency alert systems. The main challenge in this problem lies in finding a model that is able to accurately recognize these type of signals in the presence of background noise and allows for real-time processing. In this paper, we present the design of a portable and low-cost device for accurate audio distress signal recognition in real urban scenarios based on deep learning models. As real audio distress recordings in urban areas have not been collected and made publicly available so far, we first constructed a database where audios were recorded in urban areas using a low-cost microphone. Using this database, we trained a deep multi-headed 2D convolutional neural network that processed temporal and frequency features to accurately recognize audio distress signals in noisy environments with a significant performance improvement to other methods from the literature. Then, we deployed and assessed the trained convolutional neural network model on a Raspberry Pi that, along with the low-cost microphone, constituted a device for accurate real-time audio recognition. Source code and database are publicly available.},
DOI = {10.3390/app10217448}
}



@Article{electronics9111780,
AUTHOR = {Pan, Daohua and Liu, Hongwei and Qu, Dongming and Zhang, Zhan},
TITLE = {CNN-Based Fall Detection Strategy with Edge Computing Scheduling in Smart Cities},
JOURNAL = {Electronics},
VOLUME = {9},
YEAR = {2020},
NUMBER = {11},
ARTICLE-NUMBER = {1780},
URL = {https://www.mdpi.com/2079-9292/9/11/1780},
ISSN = {2079-9292},
ABSTRACT = {The livelihood problem, especially the medical wisdom, has played an important role during the process of the building of smart cities. For the medical wisdom, the fall detection has attracted the considerable attention from the global researchers and medical institutions. It is very difficult for the traditional fall detection strategies to realize the intelligent detection with the following three reasons: (i) the data collection cannot reach the real-time level; (ii) the adopted detection methods cannot satisfy the enough stability; and (iii) the computation overhead of collection device is very high, which causes the barely satisfactory detection effect. Therefore, this paper proposes Convolutional Neural Network (CNN)-based fall detection strategy with edge computing consideration, where the global network view ability of Software-Defined Networking (SDN) is used to collect the generated data from smartphone. Meanwhile, on one hand, the edge computing is exploited to put some computation tasks at the edge server by the scheduling technique. On the other hand, CNN is equipped with both edge server and smartphone, and it is leveraged to train the related data and further give the guidance of fall detection. The experimental results show that the novel fall detection strategy has a more accurate rate, transmission delay, and stability than two cutting-edge strategies.},
DOI = {10.3390/electronics9111780}
}



@Article{rs12223794,
AUTHOR = {Taoufiq, Salma and Nagy, Balázs and Benedek, Csaba},
TITLE = {HierarchyNet: Hierarchical CNN-Based Urban Building Classification},
JOURNAL = {Remote Sensing},
VOLUME = {12},
YEAR = {2020},
NUMBER = {22},
ARTICLE-NUMBER = {3794},
URL = {https://www.mdpi.com/2072-4292/12/22/3794},
ISSN = {2072-4292},
ABSTRACT = {Automatic building categorization and analysis are particularly relevant for smart city applications and cultural heritage programs. Taking a picture of the facade of a building and instantly obtaining information about it can enable the automation of processes in urban planning, virtual city tours, and digital archiving of cultural artifacts. In this paper, we go beyond traditional convolutional neural networks (CNNs) for image classification and propose the HierarchyNet: a new hierarchical network for the classification of urban buildings from all across the globe into different main and subcategories from images of their facades. We introduce a coarse-to-fine hierarchy on the dataset and the model learns to simultaneously extract features and classify across both levels of hierarchy. We propose a new multiplicative layer, which is able to improve the accuracy of the finer prediction by considering the feedback signal of the coarse layers. We have quantitatively evaluated the proposed approach both on our proposed building datasets, as well as on various benchmark databases to demonstrate that the model is able to efficiently learn hierarchical information. The HierarchyNet model is able to outperform the state-of-the-art convolutional neural networks in urban building classification as well as in other multi-label classification tasks while using significantly fewer parameters.},
DOI = {10.3390/rs12223794}
}



@Article{su122410327,
AUTHOR = {Munjal, Rashmi and Liu, William and Li, Xue Jun and Gutierrez, Jairo},
TITLE = {A Neural Network-Based Sustainable Data Dissemination through Public Transportation for Smart Cities},
JOURNAL = {Sustainability},
VOLUME = {12},
YEAR = {2020},
NUMBER = {24},
ARTICLE-NUMBER = {10327},
URL = {https://www.mdpi.com/2071-1050/12/24/10327},
ISSN = {2071-1050},
ABSTRACT = {In recent years, there has been a big data revolution in smart cities dues to multiple disciplines such as smart healthcare, smart transportation, and smart community. However, most services in these areas of smart cities have become data-driven, thus generating big data that require sharing, storing, processing, and analysis, which ultimately consumes massive amounts of energy. The accumulation process of these data from different areas of a smart city is a challenging issue. Therefore, researchers have started aiming at the Internet of vehicles (IoV), in which smart vehicles are equipped with computing and storage capabilities to communicate with surrounding infrastructure. In this paper, we propose a subcategory of IoV as the Internet of buses (IoB), where public buses enable a service as a data carrier in a smart city by introducing a neural network-based sustainable data dissemination system (NESUDA), where opportunistic sensing comprises delay-tolerant data collection, processing and disseminating from one place to another place around the city. The objective was to use public transport to carry data from one place to another and to reduce the traffic from traditional networks and energy consumption. An advanced neural network (NN) algorithm was applied to locate the realistic arrival time of public buses for data allocation. We used the Auckland transport (AT) buses data set from the transport agency to validate our model for the level of accuracy in predicted bus arrival time and scheduled arrival time to disseminate data using bus services. Data were uploaded onto buses as per their dwelling time at each stop and terminals within the coverage area of deployed RSU. The offloading capacity of our proposed data dissemination system showed that it could be utilized to effectively complement traditional data networks. Moreover, the maximum offloading capacity at each parent stop could reach up to 360 GB with a huge saving of energy consumption.},
DOI = {10.3390/su122410327}
}



@Article{w12123537,
AUTHOR = {Park, Kidoo and Jung, Younghun and Kim, Kyungtak and Park, Seung Kook},
TITLE = {Determination of Deep Learning Model and Optimum Length of Training Data in the River with Large Fluctuations in Flow Rates},
JOURNAL = {Water},
VOLUME = {12},
YEAR = {2020},
NUMBER = {12},
ARTICLE-NUMBER = {3537},
URL = {https://www.mdpi.com/2073-4441/12/12/3537},
ISSN = {2073-4441},
ABSTRACT = {Recently, developing countries have steadily been pushing for the construction of stream-oriented smart cities, breaking away from the existing old-town-centered development in the past. Due to the accelerating effects of climate change along with such urbanization, it is imperative for urban rivers to establish a flood warning system that can predict the amount of high flow rates of accuracy in engineering, compared to using the existing Computational Fluid Dynamics (CFD) models for disaster prevention. In this study, in the case of streams where missing data existed or only small observations were obtained, the variation in flow rates could be predicted with only the appropriate deep learning models, using only limited time series flow data. In addition, the selected deep learning model allowed the minimum number of input learning data to be determined. In this study, the time series flow rates were predicted by applying the deep learning models to the Han River, which is a highly urbanized stream that flows through the capital of Korea, Seoul and has a large seasonal variation in the flow rate. The deep learning models used are Convolution Neural Network (CNN), Simple Recurrent Neural Network (RNN), Long Short-Term Memory (LSTM), Bidirectional LSTM (Bi-LSTM) and Gated Recurrent Unit (GRU). Sequence lengths for time series runoff data were determined first to assess the accuracy and applicability of the deep learning models. By analyzing the forecast results of the outflow data of the Han River, sequence length for 14 days was appropriate in terms of the predicted accuracy of the model. In addition, the GRU model is effective for deep learning models that use time series data of the region with large fluctuations in flow rates, such as the Han River. Furthermore, through this study, it was possible to propose the minimum number of training data that could provide flood warning system with an effective flood forecasting system although the number of input data such as flow rates secured in new towns developed around rivers was insufficient.},
DOI = {10.3390/w12123537}
}



@Article{s20247228,
AUTHOR = {Delli Priscoli, Francesco and Giuseppi, Alessandro and Lisi, Federico},
TITLE = {Automatic Transportation Mode Recognition on Smartphone Data Based on Deep Neural Networks},
JOURNAL = {Sensors},
VOLUME = {20},
YEAR = {2020},
NUMBER = {24},
ARTICLE-NUMBER = {7228},
URL = {https://www.mdpi.com/1424-8220/20/24/7228},
ISSN = {1424-8220},
ABSTRACT = {In the last few years, with the exponential diffusion of smartphones, services for turn-by-turn navigation have seen a surge in popularity. Current solutions available in the market allow the user to select via an interface the desired transportation mode, for which an optimal route is then computed. Automatically recognizing the transportation system that the user is travelling by allows to dynamically control, and consequently update, the route proposed to the user. Such a dynamic approach is an enabling technology for multi-modal transportation planners, in which the optimal path and its associated transportation solutions are updated in real-time based on data coming from (i) distributed sensors (e.g., smart traffic lights, road congestion sensors, etc.); (ii) service providers (e.g., car-sharing availability, bus waiting time, etc.); and (iii) the user&rsquo;s own device, in compliance with the development of smart cities envisaged by the 5G architecture. In this paper, we present a series of Machine Learning approaches for real-time Transportation Mode Recognition and we report their performance difference in our field tests. Several Machine Learning-based classifiers, including Deep Neural Networks, built on both statistical feature extraction and raw data analysis are presented and compared in this paper; the result analysis also highlights which features are proven to be the most informative ones for the classification.},
DOI = {10.3390/s20247228}
}



@Article{electronics10010014,
AUTHOR = {Kumar, Saurav and Yadav, Drishti and Gupta, Himanshu and Verma, Om Prakash and Ansari, Irshad Ahmad and Ahn, Chang Wook},
TITLE = {A Novel YOLOv3 Algorithm-Based Deep Learning Approach for Waste Segregation: Towards Smart Waste Management},
JOURNAL = {Electronics},
VOLUME = {10},
YEAR = {2021},
NUMBER = {1},
ARTICLE-NUMBER = {14},
URL = {https://www.mdpi.com/2079-9292/10/1/14},
ISSN = {2079-9292},
ABSTRACT = {The colossal increase in environmental pollution and degradation, resulting in ecological imbalance, is an eye-catching concern in the contemporary era. Moreover, the proliferation in the development of smart cities across the globe necessitates the emergence of a robust smart waste management system for proper waste segregation based on its biodegradability. The present work investigates a novel approach for waste segregation for its effective recycling and disposal by utilizing a deep learning strategy. The YOLOv3 algorithm has been utilized in the Darknet neural network framework to train a self-made dataset. The network has been trained for 6 object classes (namely: cardboard, glass, metal, paper, plastic and organic waste). Moreover, for comparative assessment, the detection task has also been performed using YOLOv3-tiny to validate the competence of the YOLOv3 algorithm. The experimental results demonstrate that the proposed YOLOv3 methodology yields satisfactory generalization capability for all the classes with a variety of waste items.},
DOI = {10.3390/electronics10010014}
}



@Article{info12010014,
AUTHOR = {Rocha Neto, Aluizio and Silva, Thiago P. and Batista, Thais and Delicato, Flávia C. and Pires, Paulo F. and Lopes, Frederico},
TITLE = {Leveraging Edge Intelligence for Video Analytics in Smart City Applications},
JOURNAL = {Information},
VOLUME = {12},
YEAR = {2021},
NUMBER = {1},
ARTICLE-NUMBER = {14},
URL = {https://www.mdpi.com/2078-2489/12/1/14},
ISSN = {2078-2489},
ABSTRACT = {In smart city scenarios, the huge proliferation of monitoring cameras scattered in public spaces has posed many challenges to network and processing infrastructure. A few dozen cameras are enough to saturate the city&rsquo;s backbone. In addition, most smart city applications require a real-time response from the system in charge of processing such large-scale video streams. Finding a missing person using facial recognition technology is one of these applications that require immediate action on the place where that person is. In this paper, we tackle these challenges presenting a distributed system for video analytics designed to leverage edge computing capabilities. Our approach encompasses architecture, methods, and algorithms for: (i) dividing the burdensome processing of large-scale video streams into various machine learning tasks; and (ii) deploying these tasks as a workflow of data processing in edge devices equipped with hardware accelerators for neural networks. We also propose the reuse of nodes running tasks shared by multiple applications, e.g., facial recognition, thus improving the system&rsquo;s processing throughput. Simulations showed that, with our algorithm to distribute the workload, the time to process a workflow is about 33% faster than a naive approach.},
DOI = {10.3390/info12010014}
}



@Article{s21020434,
AUTHOR = {Hong, Qingqi and Ding, Yiwei and Lin, Jinpeng and Wang, Meihong and Wei, Qingyang and Wang, Xianwei and Zeng, Ming},
TITLE = {Image-Based Automatic Watermeter Reading under Challenging Environments},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {2},
ARTICLE-NUMBER = {434},
URL = {https://www.mdpi.com/1424-8220/21/2/434},
PubMedID = {33435444},
ISSN = {1424-8220},
ABSTRACT = {With the rapid development of artificial intelligence and fifth-generation mobile network technologies, automatic instrument reading has become an increasingly important topic for intelligent sensors in smart cities. We propose a full pipeline to automatically read watermeters based on a single image, using deep learning methods to provide new technical support for an intelligent water meter reading. To handle the various challenging environments where watermeters reside, our pipeline disentangled the task into individual subtasks based on the structures of typical watermeters. These subtasks include component localization, orientation alignment, spatial layout guidance reading, and regression-based pointer reading. The devised algorithms for orientation alignment and spatial layout guidance are tailored to improve the robustness of our neural network. We also collect images of watermeters in real scenes and build a dataset for training and evaluation. Experimental results demonstrate the effectiveness of the proposed method even under challenging environments with varying lighting, occlusions, and different orientations. Thanks to the lightweight algorithms adopted in our pipeline, the system can be easily deployed and fully automated.},
DOI = {10.3390/s21020434}
}



@Article{s21041350,
AUTHOR = {Gao, Rui and Wen, Mingyun and Park, Jisun and Cho, Kyungeun},
TITLE = {Human Mesh Reconstruction with Generative Adversarial Networks from Single RGB Images},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {4},
ARTICLE-NUMBER = {1350},
URL = {https://www.mdpi.com/1424-8220/21/4/1350},
PubMedID = {33672934},
ISSN = {1424-8220},
ABSTRACT = {Applications related to smart cities require virtual cities in the experimental development stage. To build a virtual city that are close to a real city, a large number of various types of human models need to be created. To reduce the cost of acquiring models, this paper proposes a method to reconstruct 3D human meshes from single images captured using a normal camera. It presents a method for reconstructing the complete mesh of the human body from a single RGB image and a generative adversarial network consisting of a newly designed shape–pose-based generator (based on deep convolutional neural networks) and an enhanced multi-source discriminator. Using a machine learning approach, the reliance on multiple sensors is reduced and 3D human meshes can be recovered using a single camera, thereby reducing the cost of building smart cities. The proposed method achieves an accuracy of 92.1% in body shape recovery; it can also process 34 images per second. The method proposed in this paper approach significantly improves the performance compared with previous state-of-the-art approaches. Given a single view image of various humans, our results can be used to generate various 3D human models, which can facilitate 3D human modeling work to simulate virtual cities. Since our method can also restore the poses of the humans in the image, it is possible to create various human poses by given corresponding images with specific human poses.},
DOI = {10.3390/s21041350}
}



@Article{s21041375,
AUTHOR = {Gao, Jinfeng and Chen, Yu and Wei, Yongming and Li, Jiannan},
TITLE = {Detection of Specific Building in Remote Sensing Images Using a Novel YOLO-S-CIOU Model. Case: Gas Station Identification},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {4},
ARTICLE-NUMBER = {1375},
URL = {https://www.mdpi.com/1424-8220/21/4/1375},
PubMedID = {33669229},
ISSN = {1424-8220},
ABSTRACT = {The specific building is of great significance in smart city planning, management practices, or even military use. However, traditional classification or target identification methods are difficult to distinguish different type of buildings from remote sensing images, because the characteristics of the environmental landscape around the buildings (like the pixels of the road and parking area) are complex, and it is difficult to define them with simple rules. Convolution neural networks (CNNs) have a strong capacity to mine information from the spatial context and have been used in many tasks of image processing. Here, we developed a novel CNN model named YOLO-S-CIOU, which was improved based on YOLOv3 for specific building detection in two aspects: (1) module Darknet53 in YOLOv3 was replaced with SRXnet (constructed by superimposing multiple SE-ResNeXt) to significantly improve the feature learning ability of YOLO-S-CIOU while maintaining the similar complexity as YOLOv3; (2) Complete-IoU Loss (CIoU Loss) was used to obtain a better regression for the bounding box. We took the gas station as an example. The experimental results on the self-made gas station dataset (GS dataset) showed YOLO-S-CIOU achieved an average precision (AP) of 97.62%, an F1 score of 97.50%, and had 59,065,366 parameters. Compared with YOLOv3, YOLO-S-CIOU reduced the parameters’ number by 2,510,977 (about 4%) and improved the AP by 2.23% and the F1 score by 0.5%. Moreover, in gas stations detection in Tumshuk City and Yanti City, the recall (R) and precision (P) of YOLO-S-CIOU were 50% and 40% higher than those of YOLOv3, respectively. It showed that our proposed network had stronger robustness and higher detection ability in remote sensing image detection of different regions.},
DOI = {10.3390/s21041375}
}



@Article{rs13050879,
AUTHOR = {Mao, Zhu and Zhang, Fan and Huang, Xianfeng and Jia, Xiangyang and Gong, Yiping and Zou, Qin},
TITLE = {Deep Neural Networks for Road Sign Detection and Embedded Modeling Using Oblique Aerial Images},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {5},
ARTICLE-NUMBER = {879},
URL = {https://www.mdpi.com/2072-4292/13/5/879},
ISSN = {2072-4292},
ABSTRACT = {Oblique photogrammetry-based three-dimensional (3D) urban models are widely used for smart cities. In 3D urban models, road signs are small but provide valuable information for navigation. However, due to the problems of sliced shape features, blurred texture and high incline angles, road signs cannot be fully reconstructed in oblique photogrammetry, even with state-of-the-art algorithms. The poor reconstruction of road signs commonly leads to less informative guidance and unsatisfactory visual appearance. In this paper, we present a pipeline for embedding road sign models based on deep convolutional neural networks (CNNs). First, we present an end-to-end balanced-learning framework for small object detection that takes advantage of the region-based CNN and a data synthesis strategy. Second, under the geometric constraints placed by the bounding boxes, we use the scale-invariant feature transform (SIFT) to extract the corresponding points on the road signs. Third, we obtain the coarse location of a single road sign by triangulating the corresponding points and refine the location via outlier removal. Least-squares fitting is then applied to the refined point cloud to fit a plane for orientation prediction. Finally, we replace the road signs with computer-aided design models in the 3D urban scene with the predicted location and orientation. The experimental results show that the proposed method achieves a high mAP in road sign detection and produces visually plausible embedded results, which demonstrates its effectiveness for road sign modeling in oblique photogrammetry-based 3D scene reconstruction.},
DOI = {10.3390/rs13050879}
}



@Article{math9050500,
AUTHOR = {Lydia, E. Laxmi and Jovith, A. Arokiaraj and Devaraj, A. Francis Saviour and Seo, Changho and Joshi, Gyanendra Prasad},
TITLE = {Green Energy Efficient Routing with Deep Learning Based Anomaly Detection for Internet of Things (IoT) Communications},
JOURNAL = {Mathematics},
VOLUME = {9},
YEAR = {2021},
NUMBER = {5},
ARTICLE-NUMBER = {500},
URL = {https://www.mdpi.com/2227-7390/9/5/500},
ISSN = {2227-7390},
ABSTRACT = {Presently, a green Internet of Things (IoT) based energy aware network plays a significant part in the sensing technology. The development of IoT has a major impact on several application areas such as healthcare, smart city, transportation, etc. The exponential rise in the sensor nodes might result in enhanced energy dissipation. So, the minimization of environmental impact in green media networks is a challenging issue for both researchers and business people. Energy efficiency and security remain crucial in the design of IoT applications. This paper presents a new green energy-efficient routing with DL based anomaly detection (GEER-DLAD) technique for IoT applications. The presented model enables IoT devices to utilize energy effectively in such a way as to increase the network span. The GEER-DLAD technique performs error lossy compression (ELC) technique to lessen the quantity of data communication over the network. In addition, the moth flame swarm optimization (MSO) algorithm is applied for the optimal selection of routes in the network. Besides, DLAD process takes place via the recurrent neural network-long short term memory (RNN-LSTM) model to detect anomalies in the IoT communication networks. A detailed experimental validation process is carried out and the results ensured the betterment of the GEER-DLAD model in terms of energy efficiency and detection performance.},
DOI = {10.3390/math9050500}
}



@Article{app11052214,
AUTHOR = {Hettiarachchi, Prasad and Nawaratne, Rashmika and Alahakoon, Damminda and De Silva, Daswin and Chilamkurti, Naveen},
TITLE = {Rain Streak Removal for Single Images Using Conditional Generative Adversarial Networks},
JOURNAL = {Applied Sciences},
VOLUME = {11},
YEAR = {2021},
NUMBER = {5},
ARTICLE-NUMBER = {2214},
URL = {https://www.mdpi.com/2076-3417/11/5/2214},
ISSN = {2076-3417},
ABSTRACT = {Rapid developments in urbanization and smart city environments have accelerated the need to deliver safe, sustainable, and effective resource utilization and service provision and have thereby enhanced the need for intelligent, real-time video surveillance. Recent advances in machine learning and deep learning have the capability to detect and localize salient objects in surveillance video streams; however, several practical issues remain unaddressed, such as diverse weather conditions, recording conditions, and motion blur. In this context, image de-raining is an important issue that has been investigated extensively in recent years to provide accurate and quality surveillance in the smart city domain. Existing deep convolutional neural networks have obtained great success in image translation and other computer vision tasks; however, image de-raining is ill posed and has not been addressed in real-time, intelligent video surveillance systems. In this work, we propose to utilize the generative capabilities of recently introduced conditional generative adversarial networks (cGANs) as an image de-raining approach. We utilize the adversarial loss in GANs that provides an additional component to the loss function, which in turn regulates the final output and helps to yield better results. Experiments on both real and synthetic data show that the proposed method outperforms most of the existing state-of-the-art models in terms of quantitative evaluations and visual appearance.},
DOI = {10.3390/app11052214}
}



@Article{app11062714,
AUTHOR = {Zhang, Xue and Kuehnelt, Helmut and De Roeck, Wim},
TITLE = {Traffic Noise Prediction Applying Multivariate Bi-Directional Recurrent Neural Network},
JOURNAL = {Applied Sciences},
VOLUME = {11},
YEAR = {2021},
NUMBER = {6},
ARTICLE-NUMBER = {2714},
URL = {https://www.mdpi.com/2076-3417/11/6/2714},
ISSN = {2076-3417},
ABSTRACT = {With the drastically increasing traffic in the last decades, crucial environmental problems have been caused, such as greenhouse gas emission and traffic noise pollution. These problems have adversely affected our life quality and health conditions. In this paper, modelling of traffic noise employing deep learning is investigated. The goal is to identify the best machine-learning model for predicting traffic noise from real-life traffic data with multivariate traffic features as input. An extensive study on recurrent neural network (RNN) is performed in this work for modelling time series traffic data, which was collected through an experimental campaign at an inner city roundabout, including both video traffic data and audio data. The preprocessing of the data, namely how to generate the appropriate input and output for deep learning model, is detailed in this paper. A selection of different architectures of RNN, such as many-to-one, many-to-many, encoder–decoder architectures, was investigated. Moreover, gated recurrent unit (GRU) and long short-term memory (LSTM) were further discussed. The results revealed that a multivariate bi-directional GRU model with many-to-many architecture achieved the best performance with both high accuracy and computation efficiency. The trained model could be promising for a future smart city concept; with the proposed model, real-time traffic noise predictions can be potentially feasible using only traffic data collected by different sensors in the city, thanks to the generated big data by smart cities. The forecast of excessive noise exposure can help the regulation and policy makers to make early decisions, in order to mitigate the noise level.},
DOI = {10.3390/app11062714}
}



@Article{machines9040078,
AUTHOR = {Kalinin, Maxim and Krundyshev, Vasiliy and Zegzhda, Peter},
TITLE = {Cybersecurity Risk Assessment in Smart City Infrastructures},
JOURNAL = {Machines},
VOLUME = {9},
YEAR = {2021},
NUMBER = {4},
ARTICLE-NUMBER = {78},
URL = {https://www.mdpi.com/2075-1702/9/4/78},
ISSN = {2075-1702},
ABSTRACT = {The article is devoted to cybersecurity risk assessment of the dynamic device-to-device networks of a smart city. Analysis of the modern security threats at the IoT/IIoT, VANET, and WSN inter-device infrastructures demonstrates that the main concern is a set of network security threats targeted at the functional sustainability of smart urban infrastructure, the most common use case of smart networks. As a result of our study, systematization of the existing cybersecurity risk assessment methods has been provided. Expert-based risk assessment and active human participation cannot be provided for the huge, complex, and permanently changing digital environment of the smart city. The methods of scenario analysis and functional analysis are specific to industrial risk management and are hardly adaptable to solving cybersecurity tasks. The statistical risk evaluation methods force us to collect statistical data for the calculation of the security indicators for the self-organizing networks, and the accuracy of this method depends on the number of calculating iterations. In our work, we have proposed a new approach for cybersecurity risk management based on object typing, data mining, and quantitative risk assessment for the smart city infrastructure. The experimental study has shown us that the artificial neural network allows us to automatically, unambiguously, and reasonably assess the cyber risk for various object types in the dynamic digital infrastructures of the smart city.},
DOI = {10.3390/machines9040078}
}



@Article{s21082811,
AUTHOR = {Ullah, Waseem and Ullah, Amin and Hussain, Tanveer and Khan, Zulfiqar Ahmad and Baik, Sung Wook},
TITLE = {An Efficient Anomaly Recognition Framework Using an Attention Residual LSTM in Surveillance Videos},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {8},
ARTICLE-NUMBER = {2811},
URL = {https://www.mdpi.com/1424-8220/21/8/2811},
PubMedID = {33923712},
ISSN = {1424-8220},
ABSTRACT = {Video anomaly recognition in smart cities is an important computer vision task that plays a vital role in smart surveillance and public safety but is challenging due to its diverse, complex, and infrequent occurrence in real-time surveillance environments. Various deep learning models use significant amounts of training data without generalization abilities and with huge time complexity. To overcome these problems, in the current work, we present an efficient light-weight convolutional neural network (CNN)-based anomaly recognition framework that is functional in a surveillance environment with reduced time complexity. We extract spatial CNN features from a series of video frames and feed them to the proposed residual attention-based long short-term memory (LSTM) network, which can precisely recognize anomalous activity in surveillance videos. The representative CNN features with the residual blocks concept in LSTM for sequence learning prove to be effective for anomaly detection and recognition, validating our model’s effective usage in smart cities video surveillance. Extensive experiments on the real-world benchmark UCF-Crime dataset validate the effectiveness of the proposed model within complex surveillance environments and demonstrate that our proposed model outperforms state-of-the-art models with a 1.77%, 0.76%, and 8.62% increase in accuracy on the UCF-Crime, UMN and Avenue datasets, respectively.},
DOI = {10.3390/s21082811}
}



@Article{electronics10091048,
AUTHOR = {Chen, You-Shyang and Lin, Chien-Ku and Chen, Su-Fen and Chen, Shang-Hung},
TITLE = {Two Advanced Models of the Function of MRT Public Transportation in Taipei},
JOURNAL = {Electronics},
VOLUME = {10},
YEAR = {2021},
NUMBER = {9},
ARTICLE-NUMBER = {1048},
URL = {https://www.mdpi.com/2079-9292/10/9/1048},
ISSN = {2079-9292},
ABSTRACT = {Tour traffic prediction is very important in determining the capacity of public transportation and planning new transportation devices, allowing them to be built in accordance with people’s basic needs. From a review of a limited number of studies, the common methods for forecasting tour traffic demand appear to be regression analysis, econometric modeling, time-series modeling, artificial neural networks, and gray theory. In this study, a two-step procedure is used to build a predictive model for public transport. In the first step of this study, regression analysis is used to find the correlations between two or more variables and their associated directions and strength, and the regression function is used to predict future changes. In the second step, the regression analysis and artificial neural network methods are assessed and the results are compared. The artificial neural network is more accurate in prediction than regression analysis. The study results can provide useful references for transportation organizations in the development of business operation strategies for managing sustainable smart cities.},
DOI = {10.3390/electronics10091048}
}



@Article{s21124223,
AUTHOR = {Nasif, Ammar and Othman, Zulaiha Ali and Sani, Nor Samsiah},
TITLE = {The Deep Learning Solutions on Lossless Compression Methods for Alleviating Data Load on IoT Nodes in Smart Cities},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {12},
ARTICLE-NUMBER = {4223},
URL = {https://www.mdpi.com/1424-8220/21/12/4223},
PubMedID = {34203024},
ISSN = {1424-8220},
ABSTRACT = {Networking is crucial for smart city projects nowadays, as it offers an environment where people and things are connected. This paper presents a chronology of factors on the development of smart cities, including IoT technologies as network infrastructure. Increasing IoT nodes leads to increasing data flow, which is a potential source of failure for IoT networks. The biggest challenge of IoT networks is that the IoT may have insufficient memory to handle all transaction data within the IoT network. We aim in this paper to propose a potential compression method for reducing IoT network data traffic. Therefore, we investigate various lossless compression algorithms, such as entropy or dictionary-based algorithms, and general compression methods to determine which algorithm or method adheres to the IoT specifications. Furthermore, this study conducts compression experiments using entropy (Huffman, Adaptive Huffman) and Dictionary (LZ77, LZ78) as well as five different types of datasets of the IoT data traffic. Though the above algorithms can alleviate the IoT data traffic, adaptive Huffman gave the best compression algorithm. Therefore, in this paper, we aim to propose a conceptual compression method for IoT data traffic by improving an adaptive Huffman based on deep learning concepts using weights, pruning, and pooling in the neural network. The proposed algorithm is believed to obtain a better compression ratio. Additionally, in this paper, we also discuss the challenges of applying the proposed algorithm to IoT data compression due to the limitations of IoT memory and IoT processor, which later it can be implemented in IoT networks.},
DOI = {10.3390/s21124223}
}



@Article{s21134253,
AUTHOR = {Ghazal, Rubina and Malik, Ahmad Kamran and Raza, Basit and Qadeer, Nauman and Qamar, Nafees and Bhatia, Sajal},
TITLE = {Agent-Based Semantic Role Mining for Intelligent Access Control in Multi-Domain Collaborative Applications of Smart Cities},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {13},
ARTICLE-NUMBER = {4253},
URL = {https://www.mdpi.com/1424-8220/21/13/4253},
PubMedID = {34206164},
ISSN = {1424-8220},
ABSTRACT = {Significance and popularity of Role-Based Access Control (RBAC) is inevitable; however, its application is highly challenging in multi-domain collaborative smart city environments. The reason is its limitations in adapting the dynamically changing information of users, tasks, access policies and resources in such applications. It also does not incorporate semantically meaningful business roles, which could have a diverse impact upon access decisions in such multi-domain collaborative business environments. We propose an Intelligent Role-based Access Control (I-RBAC) model that uses intelligent software agents for achieving intelligent access control in such highly dynamic multi-domain environments. The novelty of this model lies in using a core I-RBAC ontology that is developed using real-world semantic business roles as occupational roles provided by Standard Occupational Classification (SOC), USA. It contains around 1400 business roles, from nearly all domains, along with their detailed task descriptions as well as hierarchical relationships among them. The semantic role mining process is performed through intelligent agents that use word embedding and a bidirectional LSTM deep neural network for automated population of organizational ontology from its unstructured text policy and, subsequently, matching this ontology with core I-RBAC ontology to extract unified business roles. The experimentation was performed on a large number of collaboration case scenarios of five multi-domain organizations and promising results were obtained regarding the accuracy of automatically derived RDF triples (Subject, Predicate, Object) from organizational text policies as well as the accuracy of extracted semantically meaningful roles.},
DOI = {10.3390/s21134253}
}



@Article{s21155036,
AUTHOR = {Minea, Marius and Dumitrescu, Cătălin Marian and Minea, Viviana Laetitia},
TITLE = {Intelligent Network Applications Monitoring and Diagnosis Employing Software Sensing and Machine Learning Solutions},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {15},
ARTICLE-NUMBER = {5036},
URL = {https://www.mdpi.com/1424-8220/21/15/5036},
PubMedID = {34372272},
ISSN = {1424-8220},
ABSTRACT = {The article presents a research in the field of complex sensing, detection, and recovery of communications networks applications and hardware, in case of failures, maloperations, or unauthorized intrusions. A case study, based on Davis AI engine operation versus human maintenance operation is performed on the efficiency of artificial intelligence agents in detecting faulty operation, in the context of growing complexity of communications networks, and the perspective of future development of internet of things, big data, smart cities, and connected vehicles. (*). In the second part of the article, a new solution is proposed for the detection of applications faults or unauthorized intrusions in traffic of communications networks. The first objective of the proposed method is to propose an approach for predicting time series. This approach is based on a multi-resolution decomposition of the signals employing the undecimate wavelet transform (UWT). The second approach for assessing traffic flow is based on the analysis of long-range dependence (LRD) (for this case, a long-term dependence). Estimating the degree of long-range dependence is performed by estimating the Hurst parameter of the analyzed time series. This is a relatively new statistical concept in communications traffic analysis and can be implemented using UWT. This property has important implications for network performance, design, and sizing. The presence of long-range dependency in network traffic is assumed to have a significant impact on network performance, and the occurrence of LRD can be the result of faults that occur during certain periods. The strategy chosen for this purpose is based on long-term dependence on traffic, and for the prediction of faults occurrence, a predictive control model (MPC) is proposed, combined with a neural network with radial function (RBF). It is demonstrated via simulations that, in the case of communications traffic, time location is the most important feature of the proposed algorithm.},
DOI = {10.3390/s21155036}
}



@Article{rs13163099,
AUTHOR = {Nebiker, Stephan and Meyer, Jonas and Blaser, Stefan and Ammann, Manuela and Rhyner, Severin},
TITLE = {Outdoor Mobile Mapping and AI-Based 3D Object Detection with Low-Cost RGB-D Cameras: The Use Case of On-Street Parking Statistics},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {16},
ARTICLE-NUMBER = {3099},
URL = {https://www.mdpi.com/2072-4292/13/16/3099},
ISSN = {2072-4292},
ABSTRACT = {A successful application of low-cost 3D cameras in combination with artificial intelligence (AI)-based 3D object detection algorithms to outdoor mobile mapping would offer great potential for numerous mapping, asset inventory, and change detection tasks in the context of smart cities. This paper presents a mobile mapping system mounted on an electric tricycle and a procedure for creating on-street parking statistics, which allow government agencies and policy makers to verify and adjust parking policies in different city districts. Our method combines georeferenced red-green-blue-depth (RGB-D) imagery from two low-cost 3D cameras with state-of-the-art 3D object detection algorithms for extracting and mapping parked vehicles. Our investigations demonstrate the suitability of the latest generation of low-cost 3D cameras for real-world outdoor applications with respect to supported ranges, depth measurement accuracy, and robustness under varying lighting conditions. In an evaluation of suitable algorithms for detecting vehicles in the noisy and often incomplete 3D point clouds from RGB-D cameras, the 3D object detection network PointRCNN, which extends region-based convolutional neural networks (R-CNNs) to 3D point clouds, clearly outperformed all other candidates. The results of a mapping mission with 313 parking spaces show that our method is capable of reliably detecting parked cars with a precision of 100% and a recall of 97%. It can be applied to unslotted and slotted parking and different parking types including parallel, perpendicular, and angle parking.},
DOI = {10.3390/rs13163099}
}



@Article{rs13163220,
AUTHOR = {Zou, Yanling and Weinacker, Holger and Koch, Barbara},
TITLE = {Towards Urban Scene Semantic Segmentation with Deep Learning from LiDAR Point Clouds: A Case Study in Baden-Württemberg, Germany},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {16},
ARTICLE-NUMBER = {3220},
URL = {https://www.mdpi.com/2072-4292/13/16/3220},
ISSN = {2072-4292},
ABSTRACT = {An accurate understanding of urban objects is critical for urban modeling, intelligent infrastructure planning and city management. The semantic segmentation of light detection and ranging (LiDAR) point clouds is a fundamental approach for urban scene analysis. Over the last years, several methods have been developed to segment urban furniture with point clouds. However, the traditional processing of large amounts of spatial data has become increasingly costly, both time-wise and financially. Recently, deep learning (DL) techniques have been increasingly used for 3D segmentation tasks. Yet, most of these deep neural networks (DNNs) were conducted on benchmarks. It is, therefore, arguable whether DL approaches can achieve the state-of-the-art performance of 3D point clouds segmentation in real-life scenarios. In this research, we apply an adapted DNN (ARandLA-Net) to directly process large-scale point clouds. In particular, we develop a new paradigm for training and validation, which presents a typical urban scene in central Europe (Munzingen, Freiburg, Baden-Württemberg, Germany). Our dataset consists of nearly 390 million dense points acquired by Mobile Laser Scanning (MLS), which has a rather larger quantity of sample points in comparison to existing datasets and includes meaningful object categories that are particular to applications for smart cities and urban planning. We further assess the DNN on our dataset and investigate a number of key challenges from varying aspects, such as data preparation strategies, the advantage of color information and the unbalanced class distribution in the real world. The final segmentation model achieved a mean Intersection-over-Union (mIoU) score of 54.4% and an overall accuracy score of 83.9%. Our experiments indicated that different data preparation strategies influenced the model performance. Additional RGB information yielded an approximately 4% higher mIoU score. Our results also demonstrate that the use of weighted cross-entropy with inverse square root frequency loss led to better segmentation performance than when other losses were considered.},
DOI = {10.3390/rs13163220}
}



@Article{app11167608,
AUTHOR = {Chen, Jian and Chen, Jianpeng and She, Xiangrong and Mao, Jian and Chen, Gang},
TITLE = {Deep Contrast Learning Approach for Address Semantic Matching},
JOURNAL = {Applied Sciences},
VOLUME = {11},
YEAR = {2021},
NUMBER = {16},
ARTICLE-NUMBER = {7608},
URL = {https://www.mdpi.com/2076-3417/11/16/7608},
ISSN = {2076-3417},
ABSTRACT = {Address is a structured description used to identify a specific place or point of interest, and it provides an effective way to locate people or objects. The standardization of Chinese place name and address occupies an important position in the construction of a smart city. Traditional address specification technology often adopts methods based on text similarity or rule bases, which cannot handle complex, missing, and redundant address information well. This paper transforms the task of address standardization into calculating the similarity of address pairs, and proposes a contrast learning address matching model based on the attention-Bi-LSTM-CNN network (ABLC). First of all, ABLC use the Trie syntax tree algorithm to extract Chinese address elements. Next, based on the basic idea of contrast learning, a hybrid neural network is applied to learn the semantic information in the address. Finally, Manhattan distance is calculated as the similarity of the two addresses. Experiments on the self-constructed dataset with data augmentation demonstrate that the proposed model has better stability and performance compared with other baselines.},
DOI = {10.3390/app11167608}
}



@Article{rs13163338,
AUTHOR = {Xiao, Xiao and Jin, Zhiling and Hui, Yilong and Xu, Yueshen and Shao, Wei},
TITLE = {Hybrid Spatial–Temporal Graph Convolutional Networks for On-Street Parking Availability Prediction},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {16},
ARTICLE-NUMBER = {3338},
URL = {https://www.mdpi.com/2072-4292/13/16/3338},
ISSN = {2072-4292},
ABSTRACT = {With the development of sensors and of the Internet of Things (IoT), smart cities can provide people with a variety of information for a more convenient life. Effective on-street parking availability prediction can improve parking efficiency and, at times, alleviate city congestion. Conventional methods of parking availability prediction often do not consider the spatial–temporal features of parking duration distributions. To this end, we propose a parking space prediction scheme called the hybrid spatial–temporal graph convolution networks (HST-GCNs). We use graph convolutional networks and gated linear units (GLUs) with a 1D convolutional neural network to obtain the spatial features and the temporal features, respectively. Then, we construct a spatial–temporal convolutional block to obtain the instantaneous spatial–temporal correlations. Based on the similarity of the parking duration distributions, we propose an attention mechanism called distAtt to measure the similarity of parking duration distributions. Through the distAtt mechanism, we add the long-term spatial–temporal correlations to our spatial–temporal convolutional block, and thus, we can capture complex hybrid spatial–temporal correlations to achieve a higher accuracy of parking availability prediction. Based on real-world datasets, we compare the proposed scheme with the benchmark models. The experimental results show that the proposed scheme has the best performance in predicting the parking occupancy rate.},
DOI = {10.3390/rs13163338}
}



@Article{app11188394,
AUTHOR = {Lhoest, Lancelot and Lamrini, Mimoun and Vandendriessche, Jurgen and Wouters, Nick and da Silva, Bruno and Chkouri, Mohamed Yassin and Touhafi, Abdellah},
TITLE = {MosAIc: A Classical Machine Learning Multi-Classifier Based Approach against Deep Learning Classifiers for Embedded Sound Classification},
JOURNAL = {Applied Sciences},
VOLUME = {11},
YEAR = {2021},
NUMBER = {18},
ARTICLE-NUMBER = {8394},
URL = {https://www.mdpi.com/2076-3417/11/18/8394},
ISSN = {2076-3417},
ABSTRACT = {Environmental Sound Recognition has become a relevant application for smart cities. Such an application, however, demands the use of trained machine learning classifiers in order to categorize a limited set of audio categories. Although classical machine learning solutions have been proposed in the past, most of the latest solutions that have been proposed toward automated and accurate sound classification are based on a deep learning approach. Deep learning models tend to be large, which can be problematic when considering that sound classifiers often have to be embedded in resource constrained devices. In this paper, a classical machine learning based classifier called MosAIc, and a lighter Convolutional Neural Network model for environmental sound recognition, are proposed to directly compete in terms of accuracy with the latest deep learning solutions. Both approaches are evaluated in an embedded system in order to identify the key parameters when placing such applications on constrained devices. The experimental results show that classical machine learning classifiers can be combined to achieve similar results to deep learning models, and even outperform them in accuracy. The cost, however, is a larger classification time.},
DOI = {10.3390/app11188394}
}



@Article{smartcities4030063,
AUTHOR = {Azimi Nasab, Morteza and Zand, Mohammad and Eskandari, Mohsen and Sanjeevikumar, Padmanaban and Siano, Pierluigi},
TITLE = {Optimal Planning of Electrical Appliance of Residential Units in a Smart Home Network Using Cloud Services},
JOURNAL = {Smart Cities},
VOLUME = {4},
YEAR = {2021},
NUMBER = {3},
PAGES = {1173--1195},
URL = {https://www.mdpi.com/2624-6511/4/3/63},
ISSN = {2624-6511},
ABSTRACT = {One of the important aspects of realizing smart cities is developing smart homes/buildings and, from the energy perspective, designing and implementing an efficient smart home area energy management system (HAEMS) is vital. To be effective, the HAEMS should include various electrical appliances as well as local distributed/renewable energy resources and energy storage systems, with the whole system as a microgrid. However, the collecting and processing of the data associated with these appliances/resources are challenging in terms of the required sensors/communication infrastructure and computational burden. Thanks to the internet-of-things and cloud computing technologies, the physical requirements for handling the data have been provided; however, they demand suitable optimization/management schemes. In this article, a HAEMS is developed using cloud services to increase the accuracy and speed of the data processing. A management protocol is proposed that provides an optimal schedule for a day-ahead operation of the electrical equipment of smart residential homes under welfare indicators. The proposed system comprises three layers: (1) sensors associated with the home appliances and generation/storage units, (2) local fog nodes, and (3) a cloud where the information is processed bilaterally with HAEMS and the hourly optimal operation of appliances/generation/storage units is planned. The neural network and genetic algorithm (GA) are used as part of the HAEMS program. The neural network is used to predict the amount of workload corresponding to users’ requests. Improving the load factor and the economic efficiency are considered as the objective function that is optimized using GA. Numerical studies are performed in the MATLAB platform and the results are compared with a conventional method.},
DOI = {10.3390/smartcities4030063}
}



@Article{ijgi10100703,
AUTHOR = {You, Lan and Guan, Zhengyi and Li, Na and Zhang, Jiahe and Cui, Haibo and Claramunt, Christophe and Cao, Rui},
TITLE = {A Spatio-Temporal Schedule-Based Neural Network for Urban Taxi Waiting Time Prediction},
JOURNAL = {ISPRS International Journal of Geo-Information},
VOLUME = {10},
YEAR = {2021},
NUMBER = {10},
ARTICLE-NUMBER = {703},
URL = {https://www.mdpi.com/2220-9964/10/10/703},
ISSN = {2220-9964},
ABSTRACT = {Taxi waiting times is an important criterion for taxi passengers to choose appropriate pick-up locations in urban environments. How to predict the taxi waiting time accurately at a certain time and location is the key solution for the imbalance between the taxis’ supplies and demands. Considering the life schedule of urban residents and the different functions of geogrid regions, the research developed in this paper introduces a spatio-temporal schedule-based neural network for urban taxi waiting time prediction. The approach integrates a series of multi-source data from taxi trajectories to city points of interest, different time frames and human behaviors in the city. We apply a grid-based and functional structuration of an urban space that provides a lower-level data representation. Overall, the neural network model can dynamically predict the waiting time of taxi passengers in real time under some given spatio-temporal constraints. The experimental results show that the granular-based grids and spatio-temporal neural network can effectively predict and optimize the accuracy of taxi waiting times. This work provides a decision support for intelligent travel predictions of taxi waiting time in a smart city.},
DOI = {10.3390/ijgi10100703}
}



@Article{app112210735,
AUTHOR = {Domingo, Mari Carmen},
TITLE = {Deep Learning and Internet of Things for Beach Monitoring: An Experimental Study of Beach Attendance Prediction at Castelldefels Beach},
JOURNAL = {Applied Sciences},
VOLUME = {11},
YEAR = {2021},
NUMBER = {22},
ARTICLE-NUMBER = {10735},
URL = {https://www.mdpi.com/2076-3417/11/22/10735},
ISSN = {2076-3417},
ABSTRACT = {Smart seaside cities can fully exploit the capabilities brought by Internet of Things (IoT) and artificial intelligence to improve the efficiency of city services in traditional smart city applications: smart home, smart healthcare, smart transportation, smart surveillance, smart environment, cyber security, etc. However, smart coastal cities are characterized by their specific application domain, namely, beach monitoring. Beach attendance prediction is a beach monitoring application of particular importance for coastal managers to successfully plan beach services in terms of security, rescue, health and environmental assistance. In this paper, an experimental study that uses IoT data and deep learning to predict the number of beach visitors at Castelldefels beach (Barcelona, Spain) was developed. Images of Castelldefels beach were captured by a video monitoring system. An image recognition software was used to estimate beach attendance. A deep learning algorithm (deep neural network) to predict beach attendance was developed. The experimental results prove the feasibility of Deep Neural Networks (DNNs) for beach attendance prediction. For each beach, a classification of occupancy was estimated, depending on the number of beach visitors. The proposed model outperforms other machine learning models (decision tree, k-nearest neighbors, and random forest) and can successfully classify seven beach occupancy levels with the Mean Absolute Error (MAE), accuracy, precision, recall and F1-score of 0.03, 92.7%, 92.9%, 92.7%, and 92.7%, respectively.},
DOI = {10.3390/app112210735}
}



@Article{rs13244974,
AUTHOR = {Feng, Dejun and Shen, Xingyu and Xie, Yakun and Liu, Yangge and Wang, Jian},
TITLE = {Efficient Occluded Road Extraction from High-Resolution Remote Sensing Imagery},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {24},
ARTICLE-NUMBER = {4974},
URL = {https://www.mdpi.com/2072-4292/13/24/4974},
ISSN = {2072-4292},
ABSTRACT = {Road extraction is important for road network renewal, intelligent transportation systems and smart cities. This paper proposes an effective method to improve road extraction accuracy and reconstruct the broken road lines caused by ground occlusion. Firstly, an attention mechanism-based convolution neural network is established to enhance feature extraction capability. By highlighting key areas and restraining interference features, the road extraction accuracy is improved. Secondly, for the common broken road problem in the extraction results, a heuristic method based on connected domain analysis is proposed to reconstruct the road. An experiment is carried out on a benchmark dataset to prove the effectiveness of this method, and the result is compared with that of several famous deep learning models including FCN8s, SegNet, U-Net and D-Linknet. The comparison shows that this model increases the IOU value and the F1 score by 3.35&ndash;12.8% and 2.41&ndash;9.8%, respectively. Additionally, the result proves the proposed method is effective at extracting roads from occluded areas.},
DOI = {10.3390/rs13244974}
}



@Article{electronics11010073,
AUTHOR = {Avazov, Kuldoshbay and Mukhiddinov, Mukhriddin and Makhmudov, Fazliddin and Cho, Young Im},
TITLE = {Fire Detection Method in Smart City Environments Using a Deep-Learning-Based Approach},
JOURNAL = {Electronics},
VOLUME = {11},
YEAR = {2022},
NUMBER = {1},
ARTICLE-NUMBER = {73},
URL = {https://www.mdpi.com/2079-9292/11/1/73},
ISSN = {2079-9292},
ABSTRACT = {In the construction of new smart cities, traditional fire-detection systems can be replaced with vision-based systems to establish fire safety in society using emerging technologies, such as digital cameras, computer vision, artificial intelligence, and deep learning. In this study, we developed a fire detector that accurately detects even small sparks and sounds an alarm within 8 s of a fire outbreak. A novel convolutional neural network was developed to detect fire regions using an enhanced You Only Look Once (YOLO) v4network. Based on the improved YOLOv4 algorithm, we adapted the network to operate on the Banana Pi M3 board using only three layers. Initially, we examined the originalYOLOv4 approach to determine the accuracy of predictions of candidate fire regions. However, the anticipated results were not observed after several experiments involving this approach to detect fire accidents. We improved the traditional YOLOv4 network by increasing the size of the training dataset based on data augmentation techniques for the real-time monitoring of fire disasters. By modifying the network structure through automatic color augmentation, reducing parameters, etc., the proposed method successfully detected and notified the incidence of disastrous fires with a high speed and accuracy in different weather environments&mdash;sunny or cloudy, day or night. Experimental results revealed that the proposed method can be used successfully for the protection of smart cities and in monitoring fires in urban areas. Finally, we compared the performance of our method with that of recently reported fire-detection approaches employing widely used performance matrices to test the fire classification results achieved.},
DOI = {10.3390/electronics11010073}
}



@Article{s22020586,
AUTHOR = {Gascón, Alberto and Casas, Roberto and Buldain, David and Marco, Álvaro},
TITLE = {Providing Fault Detection from Sensor Data in Complex Machines That Build the Smart City},
JOURNAL = {Sensors},
VOLUME = {22},
YEAR = {2022},
NUMBER = {2},
ARTICLE-NUMBER = {586},
URL = {https://www.mdpi.com/1424-8220/22/2/586},
PubMedID = {35062547},
ISSN = {1424-8220},
ABSTRACT = {Household appliances, climate control machines, vehicles, elevators, cash counting machines, etc., are complex machines with key contributions to the smart city. Those devices have limited memory and processing power, but they are not just actuators; they embed tens of sensors and actuators managed by several microcontrollers and microprocessors communicated by control buses. On the other hand, predictive maintenance and the capability of identifying failures to avoid greater damage of machines is becoming a topic of great relevance in Industry 4.0, and the large amount of data to be processed is a concern. This article proposes a layered methodology to enable complex machines with automatic fault detection or predictive maintenance. It presents a layered structure to perform the collection, filtering and extraction of indicators, along with their processing. The aim is to reduce the amount of data to work with, and to optimize them by generating indicators that concentrate the information provided by data. To test its applicability, a prototype of a cash counting machine has been used. With this prototype, different failure cases have been simulated by introducing defective elements. After the extraction of the indicators, using the Kullback&ndash;Liebler divergence, it has been possible to visualize the differences between the data associated with normal and failure operation. Subsequently, using a neural network, good results have been obtained, being able to correctly classify the failure in 90% of the cases. The result of this application demonstrates the proper functioning of the proposed approach in complex machines.},
DOI = {10.3390/s22020586}
}



@Article{s22041381,
AUTHOR = {Ansarnia, Masoomeh Shireen and Tisserand, Etienne and Schweitzer, Patrick and Zidane, Mohamed Amine and Berviller, Yves},
TITLE = {Contextual Detection of Pedestrians and Vehicles in Orthophotography by Fusion of Deep Learning Algorithms},
JOURNAL = {Sensors},
VOLUME = {22},
YEAR = {2022},
NUMBER = {4},
ARTICLE-NUMBER = {1381},
URL = {https://www.mdpi.com/1424-8220/22/4/1381},
PubMedID = {35214281},
ISSN = {1424-8220},
ABSTRACT = {In the context of smart cities, monitoring pedestrian and vehicle movements is essential to recognize abnormal events and prevent accidents. The proposed method in this work focuses on analyzing video streams captured from a vertically installed camera, and performing contextual road user detection. The final detection is based on the fusion of the outputs of three different convolutional neural networks. We are simultaneously interested in detecting road users, their motion, and their location respecting the static environment. We use YOLOv4 for object detection, FC-HarDNet for background semantic segmentation, and FlowNet 2.0 for motion detection. FC-HarDNet and YOLOv4 were retrained with our orthophotographs dataset. The last step involves a data fusion module. The presented results show that the method allows one to detect road users, identify the surfaces on which they move, quantify their apparent velocity, and estimate their actual velocity.},
DOI = {10.3390/s22041381}
}



@Article{app12041863,
AUTHOR = {Al-Taleb, Najla and Saqib, Nazar Abbas},
TITLE = {Towards a Hybrid Machine Learning Model for Intelligent Cyber Threat Identification in Smart City Environments},
JOURNAL = {Applied Sciences},
VOLUME = {12},
YEAR = {2022},
NUMBER = {4},
ARTICLE-NUMBER = {1863},
URL = {https://www.mdpi.com/2076-3417/12/4/1863},
ISSN = {2076-3417},
ABSTRACT = {The concept of a smart city requires the integration of information and communication technologies and devices over a network for the better provision of services to citizens. As a result, the quality of living is improved by continuous analyses of data to improve service delivery by governments and other organizations. Due to the presence of extensive devices and data flow over networks, the probability of cyber attacks and intrusion detection has increased. The monitoring of this huge amount of data traffic is very difficult, though machine learning algorithms have huge potential to support this task. In this study, we compared different machine learning models used for cyber threat classification. Our comparison was focused on the analyzed cyber threats, algorithms, and performance of these models. We have identified that real-time classification, accuracy, and false-positive rates are still the major issues in the performance of existing models. Accordingly, we have proposed a hybrid deep learning (DL) model for cyber threat intelligence (CTI) to improve threat classification performance. Our model was based on a convolutional neural network (CNN) and quasi-recurrent neural network (QRNN). The use of QRNN not only resulted in improved accuracy but also enabled real-time classification. The model was tested on BoT-IoT and TON_IoT datasets, and the results showed that the proposed model outperformed the other models. Due to this improved performance, we emphasize that the application of this model in the real-time environment of a smart system network will help in reducing threats in a reasonable time.},
DOI = {10.3390/app12041863}
}



@Article{app12052281,
AUTHOR = {Alsubaei, Faisal S. and Al-Wesabi, Fahd N. and Hilal, Anwer Mustafa},
TITLE = {Deep Learning-Based Small Object Detection and Classification Model for Garbage Waste Management in Smart Cities and IoT Environment},
JOURNAL = {Applied Sciences},
VOLUME = {12},
YEAR = {2022},
NUMBER = {5},
ARTICLE-NUMBER = {2281},
URL = {https://www.mdpi.com/2076-3417/12/5/2281},
ISSN = {2076-3417},
ABSTRACT = {In recent years, object detection has gained significant interest and is considered a challenging problem in computer vision. Object detection is mainly employed for several applications, such as instance segmentation, object tracking, image captioning, healthcare, etc. Recent studies have reported that deep learning (DL) models can be employed for effective object detection compared to traditional methods. The rapid urbanization of smart cities necessitates the design of intelligent and automated waste management techniques for effective recycling of waste. In this view, this study develops a novel deep learning-based small object detection and classification model for garbage waste management (DLSODC-GWM) technique. The proposed DLSODC-GWM technique mainly focuses on detecting and classifying small garbage waste objects to assist intelligent waste management systems. The DLSODC-GWM technique follows two major processes, namely, object detection and classification. For object detection, an arithmetic optimization algorithm (AOA) with an improved RefineDet (IRD) model is applied, where the hyperparameters of the IRD model are optimally chosen by the AOA. Secondly, the functional link neural network (FLNN) technique was applied for the classification of waste objects into multiple classes. The design of IRD for waste classification and AOA-based hyperparameter tuning demonstrates the novelty of the work. The performance validation of the DLSODC-GWM technique is performed using benchmark datasets, and the experimental results show the promising performance of the DLSODC-GWM method on existing approaches with a maximum accuy of 98.61%.},
DOI = {10.3390/app12052281}
}



@Article{electronics11060861,
AUTHOR = {Han, Shi-Yuan and Sun, Qi-Wei and Zhao, Qiang and Han, Rui-Zhi and Chen, Yue-Hui},
TITLE = {Traffic Forecasting Based on Integration of Adaptive Subgraph Reformulation and Spatio-Temporal Deep Learning Model},
JOURNAL = {Electronics},
VOLUME = {11},
YEAR = {2022},
NUMBER = {6},
ARTICLE-NUMBER = {861},
URL = {https://www.mdpi.com/2079-9292/11/6/861},
ISSN = {2079-9292},
ABSTRACT = {Traffic forecasting provides the foundational guidance for many typical applications in the smart city management, such as urban traffic control, congestion avoidance, and navigation guidance. Many researchers have focused on the spatio-temporal correlations under fixed topology structure in traffic network to improve the traffic forecasting accuracy. Despite their advantages, the existing approaches are not completely discussed that the association relationship among traffic network nodes are not invariable under different traffic conditions. In this paper, a novel traffic forecasting framework is proposed by integrating the dynamic association of traffic nodes with the spatio-temporal deep learning model. To be specific, an adaptive subgraph reformulation algorithm is designed first based on the specific forecasting interval to reduce the interference of irrelevant spatio-temporal information. After that, by enhancing the attention mechanism with the generative decoder, a spatio-temporal deep learning model with only one forward operation is proposed to avoid the degradation of accuracy in the long-term prediction, in which the spatio-temporal information and the external factors (such as weather and holiday) are fused together to be as an input vector. Based on the reformulated subgraph constructed of traffic nodes with closer spatio-temporal correlation, experiments show that the proposed framework consistently outperforms other GNN (Graph Neural Network)-based state-of-the-art baselines for various forecasting intervals on a real-world dataset.},
DOI = {10.3390/electronics11060861}
}



@Article{electronics11060904,
AUTHOR = {Kumar, Tamilarasan Ananth and Rajmohan, Rajendrane and Pavithra, Muthu and Ajagbe, Sunday Adeola and Hodhod, Rania and Gaber, Tarek},
TITLE = {Automatic Face Mask Detection System in Public Transportation in Smart Cities Using IoT and Deep Learning},
JOURNAL = {Electronics},
VOLUME = {11},
YEAR = {2022},
NUMBER = {6},
ARTICLE-NUMBER = {904},
URL = {https://www.mdpi.com/2079-9292/11/6/904},
ISSN = {2079-9292},
ABSTRACT = {The World Health Organization (WHO) has stated that the spread of the coronavirus (COVID-19) is on a global scale and that wearing a face mask at work is the only effective way to avoid becoming infected with the virus. The pandemic made governments worldwide stay under lock-downs to prevent virus transmissions. Reports show that wearing face masks would reduce the risk of transmission. With the rise in population in cities, there is a greater need for efficient city management in today&rsquo;s world for reducing the impact of COVID-19 disease. For smart cities to prosper, significant improvements to occur in public transportation, roads, businesses, houses, city streets, and other facets of city life will have to be developed. The current public bus transportation system, such as it is, should be expanded with artificial intelligence. The autonomous mask detection and alert system are needed to find whether the person is wearing a face mask or not. This article presents a novel IoT-based face mask detection system in public transportation, especially buses. This system would collect real-time data via facial recognition. The main objective of the paper is to detect the presence of face masks in real-time video stream by utilizing deep learning, machine learning, and image processing techniques. To achieve this objective, a hybrid deep and machine learning model was designed and implemented. The model was evaluated using a new dataset in addition to public datasets. The results showed that the transformation of Convolution Neural Network (CNN) classifier has better performance over the Deep Neural Network (DNN) classifier; it has almost complete face-identification capabilities with respect to people&rsquo;s presence in the case where they are wearing masks, with an error rate of only 1.1%. Overall, compared with the standard models, AlexNet, Mobinet, and You Only Look Once (YOLO), the proposed model showed a better performance. Moreover, the experiments showed that the proposed model can detect faces and masks accurately with low inference time and memory, thus meeting the IoT limited resources.},
DOI = {10.3390/electronics11060904}
}



@Article{bdcc6010032,
AUTHOR = {S. D., Mohana and Prakash, S. P. Shiva and Krinkin, Kirill},
TITLE = {Service Oriented R-ANN Knowledge Model for Social Internet of Things},
JOURNAL = {Big Data and Cognitive Computing},
VOLUME = {6},
YEAR = {2022},
NUMBER = {1},
ARTICLE-NUMBER = {32},
URL = {https://www.mdpi.com/2504-2289/6/1/32},
ISSN = {2504-2289},
ABSTRACT = {Increase in technologies around the world requires adding intelligence to the objects, and making it a smart object in an environment leads to the Social Internet of Things (SIoT). These social objects are uniquely identifiable, transferable and share information from user-to-objects and objects-to objects through interactions in a smart environment such as smart homes, smart cities and many more applications. SIoT faces certain challenges such as handling of heterogeneous objects, selection of generated data in objects, missing values in data. Therefore, the discovery and communication of meaningful patterns in data are more important for every application. Thus, the analysis of data is essential in smarter decisions and qualifies performance of data for various applications. In a smart environment, social networks of intelligent objects are increasing services and decreasing the relationship in a reliable and efficient way of sharing resources and services. Hence, this work proposed the feature selection method based on proposed semantic rules and established the relationships to classify the services using relationship artificial neural networks (R-ANN). R-ANN is an inversely proportional relationship to the objects based on certain rules and conditions between the objects to objects and users to objects. It provides the service oriented knowledge model to make decisions in the proposed R-ANN model that produces service to the users. The proposed R-ANN provides an accuracy of 89.62% for various services namely weather, air quality, parking, light status, and people presence respectively in the SIoT environment compared to the existing model.},
DOI = {10.3390/bdcc6010032}
}





@Article{s19071676,
AUTHOR = {Baba, Marius and Gui, Vasile and Cernazanu, Cosmin and Pescaru, Dan},
TITLE = {A Sensor Network Approach for Violence Detection in Smart Cities Using Deep Learning},
JOURNAL = {Sensors},
VOLUME = {19},
YEAR = {2019},
NUMBER = {7},
ARTICLE-NUMBER = {1676},
URL = {https://www.mdpi.com/1424-8220/19/7/1676},
ISSN = {1424-8220},
ABSTRACT = {Citizen safety in modern urban environments is an important aspect of life quality. Implementation of a smart city approach to video surveillance depends heavily on the capability of gathering and processing huge amounts of live urban data. Analyzing data from high bandwidth surveillance video streams provided by large size distributed sensor networks is particularly challenging. We propose here an efficient method for automatic violent behavior detection designed for video sensor networks. Known solutions to real-time violence detection are not suitable for implementation in a resource-constrained environment due to the high processing power requirements. Our algorithm achieves real-time processing on a Raspberry PI-embedded architecture. To ensure separation of temporal and spatial information processing we employ a computationally effective cascaded approach. It consists of a deep neural network followed by a time domain classifier. In contrast with current approaches, the deep neural network input is fed exclusively with motion vector features extracted directly from the MPEG encoded video stream. As proven by results, we achieve state-of-the-art performance, while running on a low computational resources embedded architecture.},
DOI = {10.3390/s19071676}
}



@Article{s19092206,
AUTHOR = {Aqib, Muhammad and Mehmood, Rashid and Alzahrani, Ahmed and Katib, Iyad and Albeshri, Aiiad and Altowaijri, Saleh M.},
TITLE = {Smarter Traffic Prediction Using Big Data, In-Memory Computing, Deep Learning and GPUs},
JOURNAL = {Sensors},
VOLUME = {19},
YEAR = {2019},
NUMBER = {9},
ARTICLE-NUMBER = {2206},
URL = {https://www.mdpi.com/1424-8220/19/9/2206},
ISSN = {1424-8220},
ABSTRACT = {Road transportation is the backbone of modern economies, albeit it annually costs     1.25     million deaths and trillions of dollars to the global economy, and damages public health and the environment. Deep learning is among the leading-edge methods used for transportation-related predictions, however, the existing works are in their infancy, and fall short in multiple respects, including the use of datasets with limited sizes and scopes, and insufficient depth of the deep learning studies. This paper provides a novel and comprehensive approach toward large-scale, faster, and real-time traffic prediction by bringing four complementary cutting-edge technologies together: big data, deep learning, in-memory computing, and Graphics Processing Units (GPUs). We trained deep networks using over 11 years of data provided by the California Department of Transportation (Caltrans), the largest dataset that has been used in deep learning studies. Several combinations of the input attributes of the data along with various network configurations of the deep learning models were investigated for training and prediction purposes. The use of the pre-trained model for real-time prediction was explored. The paper contributes novel deep learning models, algorithms, implementation, analytics methodology, and software tool for smart cities, big data, high performance computing, and their convergence.},
DOI = {10.3390/s19092206}
}



@Article{su11102736,
AUTHOR = {Aqib, Muhammad and Mehmood, Rashid and Alzahrani, Ahmed and Katib, Iyad and Albeshri, Aiiad and Altowaijri, Saleh M.},
TITLE = {Rapid Transit Systems: Smarter Urban Planning Using Big Data, In-Memory Computing, Deep Learning, and GPUs},
JOURNAL = {Sustainability},
VOLUME = {11},
YEAR = {2019},
NUMBER = {10},
ARTICLE-NUMBER = {2736},
URL = {https://www.mdpi.com/2071-1050/11/10/2736},
ISSN = {2071-1050},
ABSTRACT = {Rapid transit systems or metros are a popular choice for high-capacity public transport in urban areas due to several advantages including safety, dependability, speed, cost, and lower risk of accidents. Existing studies on metros have not considered appropriate holistic urban transport models and integrated use of cutting-edge technologies. This paper proposes a comprehensive approach toward large-scale and faster prediction of metro system characteristics by employing the integration of four leading-edge technologies: big data, deep learning, in-memory computing, and Graphics Processing Units (GPUs). Using London Metro as a case study, and the Rolling Origin and Destination Survey (RODS) (real) dataset, we predict the number of passengers for six time intervals (a) using various access transport modes to reach the train stations (buses, walking, etc.); (b) using various egress modes to travel from the metro station to their next points of interest (PoIs); (c) traveling between different origin-destination (OD) pairs of stations; and (d) against the distance between the OD stations. The prediction allows better spatiotemporal planning of the whole urban transport system, including the metro subsystem, and its various access and egress modes. The paper contributes novel deep learning models, algorithms, implementation, analytics methodology, and software tool for analysis of metro systems.},
DOI = {10.3390/su11102736}
}



@Article{infrastructures4030052,
AUTHOR = {Serrano, Will},
TITLE = {Deep Reinforcement Learning Algorithms in Intelligent Infrastructure},
JOURNAL = {Infrastructures},
VOLUME = {4},
YEAR = {2019},
NUMBER = {3},
ARTICLE-NUMBER = {52},
URL = {https://www.mdpi.com/2412-3811/4/3/52},
ISSN = {2412-3811},
ABSTRACT = {Intelligent infrastructure, including smart cities and intelligent buildings, must learn and adapt to the variable needs and requirements of users, owners and operators in order to be future proof and to provide a return on investment based on Operational Expenditure (OPEX) and Capital Expenditure (CAPEX). To address this challenge, this article presents a biological algorithm based on neural networks and deep reinforcement learning that enables infrastructure to be intelligent by making predictions about its different variables. In addition, the proposed method makes decisions based on real time data. Intelligent infrastructure must be able to proactively monitor, protect and repair itself: this includes independent components and assets working the same way any autonomous biological organisms would. Neurons of artificial neural networks are associated with a prediction or decision layer based on a deep reinforcement learning algorithm that takes into consideration all of its previous learning. The proposed method was validated against an intelligent infrastructure dataset with outstanding results: the intelligent infrastructure was able to learn, predict and adapt to its variables, and components could make relevant decisions autonomously, emulating a living biological organism in which data flow exhaustively.},
DOI = {10.3390/infrastructures4030052}
}



@Article{atmos10090560,
AUTHOR = {Sun, Xiaotong and Xu, Wei},
TITLE = {Deep Random Subspace Learning: A Spatial-Temporal Modeling Approach for Air Quality Prediction},
JOURNAL = {Atmosphere},
VOLUME = {10},
YEAR = {2019},
NUMBER = {9},
ARTICLE-NUMBER = {560},
URL = {https://www.mdpi.com/2073-4433/10/9/560},
ISSN = {2073-4433},
ABSTRACT = {Decrease in air quality is one of the most crucial threats to human health. There is an imperative and necessary need for more accurate air quality prediction. To meet this need, we propose a novel long short-term memory-based deep random subspace learning (LSTM-DRSL) framework for air quality forecasting. Specifically, we incorporate real-time pollutant emission data into the model input. We also design a spatial-temporal analysis approach to make good use of these data. The prediction model is developed by combining random subspace learning with a deep learning algorithm in order to improve the prediction accuracy. Empirical analyses based on multiple datasets over China from January 2015 to September 2017 are performed to demonstrate the efficacy of the proposed framework for hourly pollutant concentration prediction at an urban-agglomeration scale. The empirical results indicate that our framework is a viable method for air quality prediction. With consideration of the regional scale, the LSTM-DRSL framework performs better at a relatively large regional scale (around 200&ndash;300 km). In addition, the quality of predictions is higher in industrial areas. From a temporal point of view, the LSTM-DRSL framework is more suitable for hourly predictions.},
DOI = {10.3390/atmos10090560}
}



@Article{s20010322,
AUTHOR = {Awan, Faraz Malik and Saleem, Yasir and Minerva, Roberto and Crespi, Noel},
TITLE = {A Comparative Analysis of Machine/Deep Learning Models for Parking Space Availability Prediction},
JOURNAL = {Sensors},
VOLUME = {20},
YEAR = {2020},
NUMBER = {1},
ARTICLE-NUMBER = {322},
URL = {https://www.mdpi.com/1424-8220/20/1/322},
ISSN = {1424-8220},
ABSTRACT = {Machine/Deep Learning (ML/DL) techniques have been applied to large data sets in order to extract relevant information and for making predictions. The performance and the outcomes of different ML/DL algorithms may vary depending upon the data sets being used, as well as on the suitability of algorithms to the data and the application domain under consideration. Hence, determining which ML/DL algorithm is most suitable for a specific application domain and its related data sets would be a key advantage. To respond to this need, a comparative analysis of well-known ML/DL techniques, including Multilayer Perceptron, K-Nearest Neighbors, Decision Tree, Random Forest, and Voting Classifier (or the Ensemble Learning Approach) for the prediction of parking space availability has been conducted. This comparison utilized Santander&rsquo;s parking data set, initiated while working on the H2020 WISE-IoT project. The data set was used in order to evaluate the considered algorithms and to determine the one offering the best prediction. The results of this analysis show that, regardless of the data set size, the less complex algorithms like Decision Tree, Random Forest, and KNN outperform complex algorithms such as Multilayer Perceptron, in terms of higher prediction accuracy, while providing comparable information for the prediction of parking space availability. In addition, in this paper, we are providing Top-K parking space recommendations on the basis of distance between current position of vehicles and free parking spots.},
DOI = {10.3390/s20010322}
}



@Article{s20020495,
AUTHOR = {Ai, Sophy and Kwon, Jangwoo},
TITLE = {Extreme Low-Light Image Enhancement for Surveillance Cameras Using Attention U-Net},
JOURNAL = {Sensors},
VOLUME = {20},
YEAR = {2020},
NUMBER = {2},
ARTICLE-NUMBER = {495},
URL = {https://www.mdpi.com/1424-8220/20/2/495},
ISSN = {1424-8220},
ABSTRACT = {Low-light image enhancement is one of the most challenging tasks in computer vision, and it is actively researched and used to solve various problems. Most of the time, image processing achieves significant performance under normal lighting conditions. However, under low-light conditions, an image turns out to be noisy and dark, which makes subsequent computer vision tasks difficult. To make buried details more visible, and reduce blur and noise in a low-light captured image, a low-light image enhancement task is necessary. A lot of research has been applied to many different techniques. However, most of these approaches require much effort or expensive equipment to perform low-light image enhancement. For example, the image has to be captured in a raw camera file in order to be processed, and the addressing method does not perform well under extreme low-light conditions. In this paper, we propose a new convolutional network, Attention U-net (the integration of an attention gate and a U-net network), which is able to work on common file types (.PNG, .JPEG, .JPG, etc.) with primary support from deep learning to solve the problem of surveillance camera security in smart city inducements without requiring the raw image file from the camera, and it can perform under the most extreme low-light conditions.},
DOI = {10.3390/s20020495}
}



@Article{s20030903,
AUTHOR = {Navarro, Juan M. and Martínez-España, Raquel and Bueno-Crespo, Andrés and Martínez, Ramón and Cecilia, José M.},
TITLE = {Sound Levels Forecasting in an Acoustic Sensor Network Using a Deep Neural Network},
JOURNAL = {Sensors},
VOLUME = {20},
YEAR = {2020},
NUMBER = {3},
ARTICLE-NUMBER = {903},
URL = {https://www.mdpi.com/1424-8220/20/3/903},
ISSN = {1424-8220},
ABSTRACT = {Wireless acoustic sensor networks are nowadays an essential tool for noise pollution monitoring and managing in cities. The increased computing capacity of the nodes that create the network is allowing the addition of processing algorithms and artificial intelligence that provide more information about the sound sources and environment, e.g., detect sound events or calculate loudness. Several models to predict sound pressure levels in cities are available, mainly road, railway and aerial traffic noise. However, these models are mostly based in auxiliary data, e.g., vehicles flow or street geometry, and predict equivalent levels for a temporal long-term. Therefore, forecasting of temporal short-term sound levels could be a helpful tool for urban planners and managers. In this work, a Long Short-Term Memory (LSTM) deep neural network technique is proposed to model temporal behavior of sound levels at a certain location, both sound pressure level and loudness level, in order to predict near-time future values. The proposed technique can be trained for and integrated in every node of a sensor network to provide novel functionalities, e.g., a method of early warning against noise pollution and of backup in case of node or network malfunction. To validate this approach, one-minute period equivalent sound levels, captured in a two-month measurement campaign by a node of a deployed network of acoustic sensors, have been used to train it and to obtain different forecasting models. Assessments of the developed LSTM models and Auto regressive integrated moving average models were performed to predict sound levels for several time periods, from 1 to 60 min. Comparison of the results show that the LSTM models outperform the statistics-based models. In general, the LSTM models achieve a prediction of values with a mean square error less than 4.3 dB for sound pressure level and less than 2 phons for loudness. Moreover, the goodness of fit of the LSTM models and the behavior pattern of the data in terms of prediction of sound levels are satisfactory.},
DOI = {10.3390/s20030903}
}



@Article{s20133749,
AUTHOR = {Awan, Faraz Malik and Minerva, Roberto and Crespi, Noel},
TITLE = {Improving Road Traffic Forecasting Using Air Pollution and Atmospheric Data: Experiments Based on LSTM Recurrent Neural Networks},
JOURNAL = {Sensors},
VOLUME = {20},
YEAR = {2020},
NUMBER = {13},
ARTICLE-NUMBER = {3749},
URL = {https://www.mdpi.com/1424-8220/20/13/3749},
ISSN = {1424-8220},
ABSTRACT = {Traffic flow forecasting is one of the most important use cases related to smart cities. In addition to assisting traffic management authorities, traffic forecasting can help drivers to choose the best path to their destinations. Accurate traffic forecasting is a basic requirement for traffic management. We propose a traffic forecasting approach that utilizes air pollution and atmospheric parameters. Air pollution levels are often associated with traffic intensity, and much work is already available in which air pollution has been predicted using road traffic. However, to the best of our knowledge, an attempt to improve forecasting road traffic using air pollution and atmospheric parameters is not yet available in the literature. In our preliminary experiments, we found out the relation between traffic intensity, air pollution, and atmospheric parameters. Therefore, we believe that addition of air pollutants and atmospheric parameters can improve the traffic forecasting. Our method uses air pollution gases, including     C O , N O , N  O 2  , N  O x  ,     and     O 3    . We chose these gases because they are associated with road traffic. Some atmospheric parameters, including pressure, temperature, wind direction, and wind speed have also been considered, as these parameters can play an important role in the dispersion of the above-mentioned gases. Data related to traffic flow, air pollution, and the atmosphere were collected from the open data portal of Madrid, Spain. The long short-term memory (LSTM) recurrent neural network (RNN) was used in this paper to perform traffic forecasting.},
DOI = {10.3390/s20133749}
}



@Article{s20185240,
AUTHOR = {Koubaa, Anis and Ammar, Adel and Alahdab, Mahmoud and Kanhouch, Anas and Azar, Ahmad Taher},
TITLE = {DeepBrain: Experimental Evaluation of Cloud-Based Computation Offloading and Edge Computing in the Internet-of-Drones for Deep Learning Applications},
JOURNAL = {Sensors},
VOLUME = {20},
YEAR = {2020},
NUMBER = {18},
ARTICLE-NUMBER = {5240},
URL = {https://www.mdpi.com/1424-8220/20/18/5240},
ISSN = {1424-8220},
ABSTRACT = {Unmanned Aerial Vehicles (UAVs) have been very effective in collecting aerial images data for various Internet-of-Things (IoT)/smart cities applications such as search and rescue, surveillance, vehicle detection, counting, intelligent transportation systems, to name a few. However, the real-time processing of collected data on edge in the context of the Internet-of-Drones remains an open challenge because UAVs have limited energy capabilities, while computer vision techniquesconsume excessive energy and require abundant resources. This fact is even more critical when deep learning algorithms, such as convolutional neural networks (CNNs), are used for classification and detection. In this paper, we first propose a system architecture of computation offloading for Internet-connected drones. Then, we conduct a comprehensive experimental study to evaluate the performance in terms of energy, bandwidth, and delay of the cloud computation offloading approach versus the edge computing approach of deep learning applications in the context of UAVs. In particular, we investigate the tradeoff between the communication cost and the computation of the two candidate approaches experimentally. The main results demonstrate that the computation offloading approach allows us to provide much higher throughput (i.e., frames per second) as compared to the edge computing approach, despite the larger communication delays.},
DOI = {10.3390/s20185240}
}



@Article{electronics9101696,
AUTHOR = {Ali, Ghulam and Ali, Tariq and Irfan, Muhammad and Draz, Umar and Sohail, Muhammad and Glowacz, Adam and Sulowicz, Maciej and Mielnik, Ryszard and Faheem, Zaid Bin and Martis, Claudia},
TITLE = {IoT Based Smart Parking System Using Deep Long Short Memory Network},
JOURNAL = {Electronics},
VOLUME = {9},
YEAR = {2020},
NUMBER = {10},
ARTICLE-NUMBER = {1696},
URL = {https://www.mdpi.com/2079-9292/9/10/1696},
ISSN = {2079-9292},
ABSTRACT = {Traffic congestion is one of the most notable urban transport problems, as it causes high energy consumption and air pollution. Unavailability of free parking spaces is one of the major reasons for traffic jams. Congestion and parking are interrelated because searching for a free parking spot creates additional delays and increase local circulation. In the center of large cities, 10% of the traffic circulation is due to cruising, as drivers nearly spend 20 min searching for free parking space. Therefore, it is necessary to develop a parking space availability prediction system that can inform the drivers in advance about the location-wise, day-wise, and hour-wise occupancy of parking lots. In this paper, we proposed a framework based on a deep long short term memory network to predict the availability of parking space with the integration of Internet of Things (IoT), cloud technology, and sensor networks. We use the Birmingham parking sensors dataset to evaluate the performance of deep long short term memory networks. Three types of experiments are performed to predict the availability of free parking space which is based on location, days of a week, and working hours of a day. The experimental results show that the proposed model outperforms the state-of-the-art prediction models.},
DOI = {10.3390/electronics9101696}
}



@Article{app10217448,
AUTHOR = {Gaviria, Jorge Felipe and Escalante-Perez, Alejandra and Castiblanco, Juan Camilo and Vergara, Nicolas and Parra-Garces, Valentina and Serrano, Juan David and Zambrano, Andres Felipe and Giraldo, Luis Felipe},
TITLE = {Deep Learning-Based Portable Device for Audio Distress Signal Recognition in Urban Areas},
JOURNAL = {Applied Sciences},
VOLUME = {10},
YEAR = {2020},
NUMBER = {21},
ARTICLE-NUMBER = {7448},
URL = {https://www.mdpi.com/2076-3417/10/21/7448},
ISSN = {2076-3417},
ABSTRACT = {Real-time automatic identification of audio distress signals in urban areas is a task that in a smart city can improve response times in emergency alert systems. The main challenge in this problem lies in finding a model that is able to accurately recognize these type of signals in the presence of background noise and allows for real-time processing. In this paper, we present the design of a portable and low-cost device for accurate audio distress signal recognition in real urban scenarios based on deep learning models. As real audio distress recordings in urban areas have not been collected and made publicly available so far, we first constructed a database where audios were recorded in urban areas using a low-cost microphone. Using this database, we trained a deep multi-headed 2D convolutional neural network that processed temporal and frequency features to accurately recognize audio distress signals in noisy environments with a significant performance improvement to other methods from the literature. Then, we deployed and assessed the trained convolutional neural network model on a Raspberry Pi that, along with the low-cost microphone, constituted a device for accurate real-time audio recognition. Source code and database are publicly available.},
DOI = {10.3390/app10217448}
}



@Article{rs12244142,
AUTHOR = {Kalajdjieski, Jovan and Zdravevski, Eftim and Corizzo, Roberto and Lameski, Petre and Kalajdziski, Slobodan and Pires, Ivan Miguel and Garcia, Nuno M. and Trajkovik, Vladimir},
TITLE = {Air Pollution Prediction with Multi-Modal Data and Deep Neural Networks},
JOURNAL = {Remote Sensing},
VOLUME = {12},
YEAR = {2020},
NUMBER = {24},
ARTICLE-NUMBER = {4142},
URL = {https://www.mdpi.com/2072-4292/12/24/4142},
ISSN = {2072-4292},
ABSTRACT = {Air pollution is becoming a rising and serious environmental problem, especially in urban areas affected by an increasing migration rate. The large availability of sensor data enables the adoption of analytical tools to provide decision support capabilities. Employing sensors facilitates air pollution monitoring, but the lack of predictive capability limits such systems&rsquo; potential in practical scenarios. On the other hand, forecasting methods offer the opportunity to predict the future pollution in specific areas, potentially suggesting useful preventive measures. To date, many works tackled the problem of air pollution forecasting, most of which are based on sequence models. These models are trained with raw pollution data and are subsequently utilized to make predictions. This paper proposes a novel approach evaluating four different architectures that utilize camera images to estimate the air pollution in those areas. These images are further enhanced with weather data to boost the classification accuracy. The proposed approach exploits generative adversarial networks combined with data augmentation techniques to mitigate the class imbalance problem. The experiments show that the proposed method achieves robust accuracy of up to 0.88, which is comparable to sequence models and conventional models that utilize air pollution data. This is a remarkable result considering that the historic air pollution data is directly related to the output&mdash;future air pollution data, whereas the proposed architecture uses camera images to recognize the air pollution&mdash;which is an inherently much more difficult problem.},
DOI = {10.3390/rs12244142}
}



@Article{s21041350,
AUTHOR = {Gao, Rui and Wen, Mingyun and Park, Jisun and Cho, Kyungeun},
TITLE = {Human Mesh Reconstruction with Generative Adversarial Networks from Single RGB Images},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {4},
ARTICLE-NUMBER = {1350},
URL = {https://www.mdpi.com/1424-8220/21/4/1350},
PubMedID = {33672934},
ISSN = {1424-8220},
ABSTRACT = {Applications related to smart cities require virtual cities in the experimental development stage. To build a virtual city that are close to a real city, a large number of various types of human models need to be created. To reduce the cost of acquiring models, this paper proposes a method to reconstruct 3D human meshes from single images captured using a normal camera. It presents a method for reconstructing the complete mesh of the human body from a single RGB image and a generative adversarial network consisting of a newly designed shape–pose-based generator (based on deep convolutional neural networks) and an enhanced multi-source discriminator. Using a machine learning approach, the reliance on multiple sensors is reduced and 3D human meshes can be recovered using a single camera, thereby reducing the cost of building smart cities. The proposed method achieves an accuracy of 92.1% in body shape recovery; it can also process 34 images per second. The method proposed in this paper approach significantly improves the performance compared with previous state-of-the-art approaches. Given a single view image of various humans, our results can be used to generate various 3D human models, which can facilitate 3D human modeling work to simulate virtual cities. Since our method can also restore the poses of the humans in the image, it is possible to create various human poses by given corresponding images with specific human poses.},
DOI = {10.3390/s21041350}
}



@Article{su13063198,
AUTHOR = {Moayedi, Hossein and Mosavi, Amir},
TITLE = {Synthesizing Multi-Layer Perceptron Network with Ant Lion Biogeography-Based Dragonfly Algorithm Evolutionary Strategy Invasive Weed and League Champion Optimization Hybrid Algorithms in Predicting Heating Load in Residential Buildings},
JOURNAL = {Sustainability},
VOLUME = {13},
YEAR = {2021},
NUMBER = {6},
ARTICLE-NUMBER = {3198},
URL = {https://www.mdpi.com/2071-1050/13/6/3198},
ISSN = {2071-1050},
ABSTRACT = {The significance of accurate heating load (HL) approximation is the primary motivation of this research to distinguish the most efficient predictive model among several neural-metaheuristic models. The proposed models are formulated through synthesizing a multi-layer perceptron network (MLP) with ant lion optimization (ALO), biogeography-based optimization (BBO), the dragonfly algorithm (DA), evolutionary strategy (ES), invasive weed optimization (IWO), and league champion optimization (LCA) hybrid algorithms. Each ensemble is optimized in terms of the operating population. Accordingly, the ALO-MLP, BBO-MLP, DA-MLP, ES-MLP, IWO-MLP, and LCA-MLP presented their best performance for population sizes of 350, 400, 200, 500, 50, and 300, respectively. The comparison was carried out by implementing a ranking system. Based on the obtained overall scores (OSs), the BBO (OS = 36) featured as the most capable optimization technique, followed by ALO (OS = 27) and ES (OS = 20). Due to the efficient performance of these algorithms, the corresponding MLPs can be promising substitutes for traditional methods used for HL analysis.},
DOI = {10.3390/su13063198}
}



@Article{en14061649,
AUTHOR = {Moayedi, Hossein and Mosavi, Amir},
TITLE = {Suggesting a Stochastic Fractal Search Paradigm in Combination with Artificial Neural Network for Early Prediction of Cooling Load in Residential Buildings},
JOURNAL = {Energies},
VOLUME = {14},
YEAR = {2021},
NUMBER = {6},
ARTICLE-NUMBER = {1649},
URL = {https://www.mdpi.com/1996-1073/14/6/1649},
ISSN = {1996-1073},
ABSTRACT = {Early prediction of thermal loads plays an essential role in analyzing energy-efficient buildings’ energy performance. On the other hand, stochastic algorithms have recently shown high proficiency in dealing with this issue. These are the reasons that this study is dedicated to evaluating an innovative hybrid method for predicting the cooling load (CL) in buildings with residential usage. The proposed model is a combination of artificial neural networks and stochastic fractal search (SFS–ANNs). Two benchmark algorithms, namely the grasshopper optimization algorithm (GOA) and firefly algorithm (FA) are also considered to be compared with the SFS. The non-linear effect of eight independent factors on the CL is analyzed using each model’s optimal structure. Evaluation of the results outlined that all three metaheuristic algorithms (with more than 90% correlation) can adequately optimize the ANN. In this regard, this tool’s prediction error declined by nearly 23%, 18%, and 36% by applying the GOA, FA, and SFS techniques. Moreover, all used accuracy criteria indicated the superiority of the SFS over the benchmark schemes. Therefore, it is inferred that utilizing the SFS along with ANN provides a reliable hybrid model for the early prediction of CL.},
DOI = {10.3390/en14061649}
}



@Article{s21124223,
AUTHOR = {Nasif, Ammar and Othman, Zulaiha Ali and Sani, Nor Samsiah},
TITLE = {The Deep Learning Solutions on Lossless Compression Methods for Alleviating Data Load on IoT Nodes in Smart Cities},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {12},
ARTICLE-NUMBER = {4223},
URL = {https://www.mdpi.com/1424-8220/21/12/4223},
PubMedID = {34203024},
ISSN = {1424-8220},
ABSTRACT = {Networking is crucial for smart city projects nowadays, as it offers an environment where people and things are connected. This paper presents a chronology of factors on the development of smart cities, including IoT technologies as network infrastructure. Increasing IoT nodes leads to increasing data flow, which is a potential source of failure for IoT networks. The biggest challenge of IoT networks is that the IoT may have insufficient memory to handle all transaction data within the IoT network. We aim in this paper to propose a potential compression method for reducing IoT network data traffic. Therefore, we investigate various lossless compression algorithms, such as entropy or dictionary-based algorithms, and general compression methods to determine which algorithm or method adheres to the IoT specifications. Furthermore, this study conducts compression experiments using entropy (Huffman, Adaptive Huffman) and Dictionary (LZ77, LZ78) as well as five different types of datasets of the IoT data traffic. Though the above algorithms can alleviate the IoT data traffic, adaptive Huffman gave the best compression algorithm. Therefore, in this paper, we aim to propose a conceptual compression method for IoT data traffic by improving an adaptive Huffman based on deep learning concepts using weights, pruning, and pooling in the neural network. The proposed algorithm is believed to obtain a better compression ratio. Additionally, in this paper, we also discuss the challenges of applying the proposed algorithm to IoT data compression due to the limitations of IoT memory and IoT processor, which later it can be implemented in IoT networks.},
DOI = {10.3390/s21124223}
}



@Article{a14080245,
AUTHOR = {Albeshri, Aiiad},
TITLE = {SVSL: A Human Activity Recognition Method Using Soft-Voting and Self-Learning},
JOURNAL = {Algorithms},
VOLUME = {14},
YEAR = {2021},
NUMBER = {8},
ARTICLE-NUMBER = {245},
URL = {https://www.mdpi.com/1999-4893/14/8/245},
ISSN = {1999-4893},
ABSTRACT = {Many smart city and society applications such as smart health (elderly care, medical applications), smart surveillance, sports, and robotics require the recognition of user activities, an important class of problems known as human activity recognition (HAR). Several issues have hindered progress in HAR research, particularly due to the emergence of fog and edge computing, which brings many new opportunities (a low latency, dynamic and real-time decision making, etc.) but comes with its challenges. This paper focuses on addressing two important research gaps in HAR research: (i) improving the HAR prediction accuracy and (ii) managing the frequent changes in the environment and data related to user activities. To address this, we propose an HAR method based on Soft-Voting and Self-Learning (SVSL). SVSL uses two strategies. First, to enhance accuracy, it combines the capabilities of Deep Learning (DL), Generalized Linear Model (GLM), Random Forest (RF), and AdaBoost classifiers using soft-voting. Second, to classify the most challenging data instances, the SVSL method is equipped with a self-training mechanism that generates training data and retrains itself. We investigate the performance of our proposed SVSL method using two publicly available datasets on six human activities related to lying, sitting, and walking positions. The first dataset consists of 562 features and the second dataset consists of five features. The data are collected using the accelerometer and gyroscope smartphone sensors. The results show that the proposed method provides 6.26%, 1.75%, 1.51%, and 4.40% better prediction accuracy (average over the two datasets) compared to GLM, DL, RF, and AdaBoost, respectively. We also analyze and compare the class-wise performance of the SVSL methods with that of DL, GLM, RF, and AdaBoost.},
DOI = {10.3390/a14080245}
}



@Article{infrastructures6100138,
AUTHOR = {Borges, Fábio de Souza Pereira and Fonseca, Adelayda Pallavicini and Garcia, Reinaldo Crispiniano},
TITLE = {Deep Reinforcement Learning Model to Mitigate Congestion in Real-Time Traffic Light Networks},
JOURNAL = {Infrastructures},
VOLUME = {6},
YEAR = {2021},
NUMBER = {10},
ARTICLE-NUMBER = {138},
URL = {https://www.mdpi.com/2412-3811/6/10/138},
ISSN = {2412-3811},
ABSTRACT = {Urban traffic congestion has a significant detrimental impact on the environment, public health and the economy, with at a high cost to society worldwide. Moreover, it is not possible to continually modify urban road infrastructure in order to mitigate increasing traffic demand. Therefore, it is important to develop traffic control models that can handle high-volume traffic data and synchronize traffic lights in an urban network in real time, without interfering with other initiatives. Within this context, this study proposes a model, based on deep reinforcement learning, for synchronizing the traffic signals of an urban traffic network composed of two intersections. The calibration of this model, including training of its neural network, was performed using real traffic data collected at the approach to each intersection. The results achieved through simulations were very promising, yielding significant improvements in indicators measured in relation to the pre-existing conditions in the network. The model was able to deal with a broad spectrum of traffic flows and, in peak demand periods, reduced delays and queue lengths by more than 28% and 42%, respectively.},
DOI = {10.3390/infrastructures6100138}
}



@Article{app112110037,
AUTHOR = {Kilicay-Ergin, Nil and Barb, Adrian S.},
TITLE = {Semantic Fusion with Deep Learning and Formal Ontologies for Evaluation of Policies and Initiatives in the Smart City Domain},
JOURNAL = {Applied Sciences},
VOLUME = {11},
YEAR = {2021},
NUMBER = {21},
ARTICLE-NUMBER = {10037},
URL = {https://www.mdpi.com/2076-3417/11/21/10037},
ISSN = {2076-3417},
ABSTRACT = {Decision makers and policy analysts at different administrative levels often lack a holistic view of the problem as there are semantic variations in policy documents due to domain-specific content. For example, smart city initiatives are derived from national and international initiatives which may influence the incentives for local participants, but local initiatives reflect the local contextual elements of the city. Balanced assessment of smart city initiatives should include a systemic evaluation of the initiatives at multiple levels including the city, the country in which the city resides as well as at international level. In this paper, a knowledge elicitation methodology is presented for multi-granularity evaluation of policies and initiatives. The methodology is demonstrated on the evaluation of smart city initiatives generated at different administrative levels. Semantic networks are constructed using formal ontologies and deep learning methods for automatic semantic evaluation of initiatives to abstract knowledge found in text. Three smart city initiatives published by different administrative levels including international, national, and city level are evaluated in terms of relevance, coherence, and alignment of multi-level smart city initiatives. Experiments and analysis ultimately provide a holistic view of the problem which is necessary for decision makers and policy analysts of smart cities.},
DOI = {10.3390/app112110037}
}



@Article{s21217339,
AUTHOR = {Huszár, Viktor Dénes and Adhikarla, Vamsi Kiran},
TITLE = {Live Spoofing Detection for Automatic Human Activity Recognition Applications},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {21},
ARTICLE-NUMBER = {7339},
URL = {https://www.mdpi.com/1424-8220/21/21/7339},
PubMedID = {34770646},
ISSN = {1424-8220},
ABSTRACT = {Human Activity Recognition (HAR) has become increasingly crucial in several applications, ranging from motion-driven virtual games to automated video surveillance systems. In these applications, sensors such as smart phone cameras, web cameras or CCTV cameras are used for detecting and tracking physical activities of users. Inevitably, spoof detection in HAR is essential to prevent anomalies and false alarms. To this end, we propose a deep learning based approach that can be used to detect spoofing in various fields such as border control, institutional security and public safety by surveillance cameras. Specifically, in this work, we address the problem of detecting spoofing occurring from video replay attacks, which is more common in such applications. We present a new database containing several videos of users juggling a football, captured under different lighting conditions and using different display and capture devices. We train our models using this database and the proposed system is capable of running in parallel with the HAR algorithms in real-time. Our experimental results show that our approach precisely detects video replay spoofing attacks and generalizes well, even to other applications such as spoof detection in face biometric authentication. Results show that our approach is effective even under resizing and compression artifacts that are common in HAR applications using remote server connections.},
DOI = {10.3390/s21217339}
}



@Article{app112210735,
AUTHOR = {Domingo, Mari Carmen},
TITLE = {Deep Learning and Internet of Things for Beach Monitoring: An Experimental Study of Beach Attendance Prediction at Castelldefels Beach},
JOURNAL = {Applied Sciences},
VOLUME = {11},
YEAR = {2021},
NUMBER = {22},
ARTICLE-NUMBER = {10735},
URL = {https://www.mdpi.com/2076-3417/11/22/10735},
ISSN = {2076-3417},
ABSTRACT = {Smart seaside cities can fully exploit the capabilities brought by Internet of Things (IoT) and artificial intelligence to improve the efficiency of city services in traditional smart city applications: smart home, smart healthcare, smart transportation, smart surveillance, smart environment, cyber security, etc. However, smart coastal cities are characterized by their specific application domain, namely, beach monitoring. Beach attendance prediction is a beach monitoring application of particular importance for coastal managers to successfully plan beach services in terms of security, rescue, health and environmental assistance. In this paper, an experimental study that uses IoT data and deep learning to predict the number of beach visitors at Castelldefels beach (Barcelona, Spain) was developed. Images of Castelldefels beach were captured by a video monitoring system. An image recognition software was used to estimate beach attendance. A deep learning algorithm (deep neural network) to predict beach attendance was developed. The experimental results prove the feasibility of Deep Neural Networks (DNNs) for beach attendance prediction. For each beach, a classification of occupancy was estimated, depending on the number of beach visitors. The proposed model outperforms other machine learning models (decision tree, k-nearest neighbors, and random forest) and can successfully classify seven beach occupancy levels with the Mean Absolute Error (MAE), accuracy, precision, recall and F1-score of 0.03, 92.7%, 92.9%, 92.7%, and 92.7%, respectively.},
DOI = {10.3390/app112210735}
}



@Article{technologies10010005,
AUTHOR = {Navarro-Espinoza, Alfonso and López-Bonilla, Oscar Roberto and García-Guerrero, Enrique Efrén and Tlelo-Cuautle, Esteban and López-Mancilla, Didier and Hernández-Mejía, Carlos and Inzunza-González, Everardo},
TITLE = {Traffic Flow Prediction for Smart Traffic Lights Using Machine Learning Algorithms},
JOURNAL = {Technologies},
VOLUME = {10},
YEAR = {2022},
NUMBER = {1},
ARTICLE-NUMBER = {5},
URL = {https://www.mdpi.com/2227-7080/10/1/5},
ISSN = {2227-7080},
ABSTRACT = {Nowadays, many cities have problems with traffic congestion at certain peak hours, which produces more pollution, noise and stress for citizens. Neural networks (NN) and machine-learning (ML) approaches are increasingly used to solve real-world problems, overcoming analytical and statistical methods, due to their ability to deal with dynamic behavior over time and with a large number of parameters in massive data. In this paper, machine-learning (ML) and deep-learning (DL) algorithms are proposed for predicting traffic flow at an intersection, thus laying the groundwork for adaptive traffic control, either by remote control of traffic lights or by applying an algorithm that adjusts the timing according to the predicted flow. Therefore, this work only focuses on traffic flow prediction. Two public datasets are used to train, validate and test the proposed ML and DL models. The first one contains the number of vehicles sampled every five minutes at six intersections for 56 days using different sensors. For this research, four of the six intersections are used to train the ML and DL models. The Multilayer Perceptron Neural Network (MLP-NN) obtained better results (R-Squared and EV score of 0.93) and took less training time, followed closely by Gradient Boosting then Recurrent Neural Networks (RNNs), with good metrics results but the longer training time, and finally Random Forest, Linear Regression and Stochastic Gradient. All ML and DL algorithms scored good performance metrics, indicating that they are feasible for implementation on smart traffic light controllers.},
DOI = {10.3390/technologies10010005}
}



@Article{app12041863,
AUTHOR = {Al-Taleb, Najla and Saqib, Nazar Abbas},
TITLE = {Towards a Hybrid Machine Learning Model for Intelligent Cyber Threat Identification in Smart City Environments},
JOURNAL = {Applied Sciences},
VOLUME = {12},
YEAR = {2022},
NUMBER = {4},
ARTICLE-NUMBER = {1863},
URL = {https://www.mdpi.com/2076-3417/12/4/1863},
ISSN = {2076-3417},
ABSTRACT = {The concept of a smart city requires the integration of information and communication technologies and devices over a network for the better provision of services to citizens. As a result, the quality of living is improved by continuous analyses of data to improve service delivery by governments and other organizations. Due to the presence of extensive devices and data flow over networks, the probability of cyber attacks and intrusion detection has increased. The monitoring of this huge amount of data traffic is very difficult, though machine learning algorithms have huge potential to support this task. In this study, we compared different machine learning models used for cyber threat classification. Our comparison was focused on the analyzed cyber threats, algorithms, and performance of these models. We have identified that real-time classification, accuracy, and false-positive rates are still the major issues in the performance of existing models. Accordingly, we have proposed a hybrid deep learning (DL) model for cyber threat intelligence (CTI) to improve threat classification performance. Our model was based on a convolutional neural network (CNN) and quasi-recurrent neural network (QRNN). The use of QRNN not only resulted in improved accuracy but also enabled real-time classification. The model was tested on BoT-IoT and TON_IoT datasets, and the results showed that the proposed model outperformed the other models. Due to this improved performance, we emphasize that the application of this model in the real-time environment of a smart system network will help in reducing threats in a reasonable time.},
DOI = {10.3390/app12041863}
}



@Article{app12052281,
AUTHOR = {Alsubaei, Faisal S. and Al-Wesabi, Fahd N. and Hilal, Anwer Mustafa},
TITLE = {Deep Learning-Based Small Object Detection and Classification Model for Garbage Waste Management in Smart Cities and IoT Environment},
JOURNAL = {Applied Sciences},
VOLUME = {12},
YEAR = {2022},
NUMBER = {5},
ARTICLE-NUMBER = {2281},
URL = {https://www.mdpi.com/2076-3417/12/5/2281},
ISSN = {2076-3417},
ABSTRACT = {In recent years, object detection has gained significant interest and is considered a challenging problem in computer vision. Object detection is mainly employed for several applications, such as instance segmentation, object tracking, image captioning, healthcare, etc. Recent studies have reported that deep learning (DL) models can be employed for effective object detection compared to traditional methods. The rapid urbanization of smart cities necessitates the design of intelligent and automated waste management techniques for effective recycling of waste. In this view, this study develops a novel deep learning-based small object detection and classification model for garbage waste management (DLSODC-GWM) technique. The proposed DLSODC-GWM technique mainly focuses on detecting and classifying small garbage waste objects to assist intelligent waste management systems. The DLSODC-GWM technique follows two major processes, namely, object detection and classification. For object detection, an arithmetic optimization algorithm (AOA) with an improved RefineDet (IRD) model is applied, where the hyperparameters of the IRD model are optimally chosen by the AOA. Secondly, the functional link neural network (FLNN) technique was applied for the classification of waste objects into multiple classes. The design of IRD for waste classification and AOA-based hyperparameter tuning demonstrates the novelty of the work. The performance validation of the DLSODC-GWM technique is performed using benchmark datasets, and the experimental results show the promising performance of the DLSODC-GWM method on existing approaches with a maximum accuy of 98.61%.},
DOI = {10.3390/app12052281}
}



@Article{en15051906,
AUTHOR = {Suanpang, Pannee and Jamjuntr, Pitchaya and Jermsittiparsert, Kittisak and Kaewyong, Phuripoj},
TITLE = {Autonomous Energy Management by Applying Deep Q-Learning to Enhance Sustainability in Smart Tourism Cities},
JOURNAL = {Energies},
VOLUME = {15},
YEAR = {2022},
NUMBER = {5},
ARTICLE-NUMBER = {1906},
URL = {https://www.mdpi.com/1996-1073/15/5/1906},
ISSN = {1996-1073},
ABSTRACT = {Autonomous energy management is becoming a significant mechanism for attaining sustainability in energy management. This resulted in this research paper, which aimed to apply deep reinforcement learning algorithms for an autonomous energy management system of a microgrid. This paper proposed a novel microgrid model that consisted of a combustion set of a household load, renewable energy, an energy storage system, and a generator, which were connected to the main grid. The proposed autonomous energy management system was designed to cooperate with the various flexible sources and loads by defining the priority resources, loads, and electricity prices. The system was implemented by using deep reinforcement learning algorithms that worked effectively in order to control the power storage, solar panels, generator, and main grid. The system model could achieve the optimal performance with near-optimal policies. As a result, this method could save 13.19% in the cost compared to conducting manual control of energy management. In this study, there was a focus on applying Q-learning for the microgrid in the tourism industry in remote areas which can produce and store energy. Therefore, we proposed an autonomous energy management system for effective energy management. In future work, the system could be improved by applying deep learning to use energy price data to predict the future energy price, when the system could produce more energy than the demand and store it for selling at the most appropriate price; this would make the autonomous energy management system smarter and provide better benefits for the tourism industry. This proposed autonomous energy management could be applied to other industries, for example businesses or factories which need effective energy management to maintain microgrid stability and also save energy.},
DOI = {10.3390/en15051906}
}



@Article{mi13030449,
AUTHOR = {Guo, Xiaoqiang and Liu, Xinhua and Zhou, Hao and Stanislawski, Rafal and Królczyk, Grzegorz and Li, Zhixiong},
TITLE = {Belt Tear Detection for Coal Mining Conveyors},
JOURNAL = {Micromachines},
VOLUME = {13},
YEAR = {2022},
NUMBER = {3},
ARTICLE-NUMBER = {449},
URL = {https://www.mdpi.com/2072-666X/13/3/449},
PubMedID = {35334743},
ISSN = {2072-666X},
ABSTRACT = {The belt conveyor is the most commonly used conveying equipment in the coal mining industry. As the core part of the conveyor, the belt is vulnerable to various failures, such as scratches, cracks, wear and tear. Inspection and defect detection is essential for conveyor belts, both in academic research and industrial applications. In this paper, we discuss existing techniques used in industrial production and state-of-the-art theories for conveyor belt tear detection. First, the basic structure of conveyor belts is discussed and an overview of tear defect detection methods for conveyor belts is studied. Next, the causes of conveyor belt tear are classified, such as belt aging, scratches by sharp objects, abnormal load or a combination of the above reasons. Then, recent mainstream techniques and theories for conveyor belt tear detection are reviewed, and their characteristics, advantages and shortcomings are discussed. Furthermore, image dataset preparation and data imbalance problems are studied for belt defect detection. Moreover, the current challenges and opportunities for conveyor belt defect detection are discussed. Lastly, a case study was carried out to compare the detection performance of popular techniques using industrial image datasets. This paper provides professional guidelines and promising research directions for researchers and engineers based on the leading theories in machine vision and deep learning.},
DOI = {10.3390/mi13030449}
}





@Article{electronics8020195,
AUTHOR = {Haider, Amir and Wei, Yiqiao and Liu, Shuzhi and Hwang, Seung-Hoon},
TITLE = {Pre- and Post-Processing Algorithms with Deep Learning Classifier for Wi-Fi Fingerprint-Based Indoor Positioning},
JOURNAL = {Electronics},
VOLUME = {8},
YEAR = {2019},
NUMBER = {2},
ARTICLE-NUMBER = {195},
URL = {https://www.mdpi.com/2079-9292/8/2/195},
ISSN = {2079-9292},
ABSTRACT = {To accommodate the rapidly increasing demand for connected infrastructure, automation for industrial sites and building smart cities, the development of Internet of Things (IoT)-based solutions is considered one of the major trends in modern day industrial revolution. In particular, providing high precision indoor positioning services for such applications is a key challenge. Wi-Fi fingerprint-based indoor positioning systems have been adapted as promising candidates for such applications. The performance of such indoor positioning systems degrade drastically due to several impairments like noisy datasets, high variation in Wi-Fi signals over time, fading of Wi-Fi signals due to multipath propagation caused by hurdles, people walking in the area under consideration and the addition/removal of Wi-Fi access points (APs). In this paper, we propose data pre- and post-processing algorithms with deep learning classifiers for Wi-Fi fingerprint-based indoor positioning, in order to provide immunity against limitations in the database and the indoor environment. In addition, we investigate the performance of the proposed system through simulation as well as extensive experiments. The results demonstrate that the pre-processing algorithm can efficiently fill in the missing Wi-Fi received signal strength fingerprints in the database, resulting in a success rate of 88.96% in simulation and 86.61% in a real-time experiment. The post-processing algorithm can improve the results from 9.05&ndash;10.94% for the conducted experiments, providing the highest success rate of 95.94% with a precision of 4 m for Wi-Fi fingerprint-based indoor positioning.},
DOI = {10.3390/electronics8020195}
}



@Article{s19061345,
AUTHOR = {Leung, Carson K. and Braun, Peter and Cuzzocrea, Alfredo},
TITLE = {AI-Based Sensor Information Fusion for Supporting Deep Supervised Learning},
JOURNAL = {Sensors},
VOLUME = {19},
YEAR = {2019},
NUMBER = {6},
ARTICLE-NUMBER = {1345},
URL = {https://www.mdpi.com/1424-8220/19/6/1345},
ISSN = {1424-8220},
ABSTRACT = {In recent years, artificial intelligence (AI) and its subarea of deep learning have drawn the attention of many researchers. At the same time, advances in technologies enable the generation or collection of large amounts of valuable data (e.g., sensor data) from various sources in different applications, such as those for the Internet of Things (IoT), which in turn aims towards the development of smart cities. With the availability of sensor data from various sources, sensor information fusion is in demand for effective integration of big data. In this article, we present an AI-based sensor-information fusion system for supporting deep supervised learning of transportation data generated and collected from various types of sensors, including remote sensed imagery for the geographic information system (GIS), accelerometers, as well as sensors for the global navigation satellite system (GNSS) and global positioning system (GPS). The discovered knowledge and information returned from our system provides analysts with a clearer understanding of trajectories or mobility of citizens, which in turn helps to develop better transportation models to achieve the ultimate goal of smarter cities. Evaluation results show the effectiveness and practicality of our AI-based sensor information fusion system for supporting deep supervised learning of big transportation data.},
DOI = {10.3390/s19061345}
}



@Article{s19092206,
AUTHOR = {Aqib, Muhammad and Mehmood, Rashid and Alzahrani, Ahmed and Katib, Iyad and Albeshri, Aiiad and Altowaijri, Saleh M.},
TITLE = {Smarter Traffic Prediction Using Big Data, In-Memory Computing, Deep Learning and GPUs},
JOURNAL = {Sensors},
VOLUME = {19},
YEAR = {2019},
NUMBER = {9},
ARTICLE-NUMBER = {2206},
URL = {https://www.mdpi.com/1424-8220/19/9/2206},
ISSN = {1424-8220},
ABSTRACT = {Road transportation is the backbone of modern economies, albeit it annually costs     1.25     million deaths and trillions of dollars to the global economy, and damages public health and the environment. Deep learning is among the leading-edge methods used for transportation-related predictions, however, the existing works are in their infancy, and fall short in multiple respects, including the use of datasets with limited sizes and scopes, and insufficient depth of the deep learning studies. This paper provides a novel and comprehensive approach toward large-scale, faster, and real-time traffic prediction by bringing four complementary cutting-edge technologies together: big data, deep learning, in-memory computing, and Graphics Processing Units (GPUs). We trained deep networks using over 11 years of data provided by the California Department of Transportation (Caltrans), the largest dataset that has been used in deep learning studies. Several combinations of the input attributes of the data along with various network configurations of the deep learning models were investigated for training and prediction purposes. The use of the pre-trained model for real-time prediction was explored. The paper contributes novel deep learning models, algorithms, implementation, analytics methodology, and software tool for smart cities, big data, high performance computing, and their convergence.},
DOI = {10.3390/s19092206}
}



@Article{s19112472,
AUTHOR = {Ullah, Fath U Min and Ullah, Amin and Muhammad, Khan and Haq, Ijaz Ul and Baik, Sung Wook},
TITLE = {Violence Detection Using Spatiotemporal Features with 3D Convolutional Neural Network},
JOURNAL = {Sensors},
VOLUME = {19},
YEAR = {2019},
NUMBER = {11},
ARTICLE-NUMBER = {2472},
URL = {https://www.mdpi.com/1424-8220/19/11/2472},
ISSN = {1424-8220},
ABSTRACT = {The worldwide utilization of surveillance cameras in smart cities has enabled researchers to analyze a gigantic volume of data to ensure automatic monitoring. An enhanced security system in smart cities, schools, hospitals, and other surveillance domains is mandatory for the detection of violent or abnormal activities to avoid any casualties which could cause social, economic, and ecological damages. Automatic detection of violence for quick actions is very significant and can efficiently assist the concerned departments. In this paper, we propose a triple-staged end-to-end deep learning violence detection framework. First, persons are detected in the surveillance video stream using a light-weight convolutional neural network (CNN) model to reduce and overcome the voluminous processing of useless frames. Second, a sequence of 16 frames with detected persons is passed to 3D CNN, where the spatiotemporal features of these sequences are extracted and fed to the Softmax classifier. Furthermore, we optimized the 3D CNN model using an open visual inference and neural networks optimization toolkit developed by Intel, which converts the trained model into intermediate representation and adjusts it for optimal execution at the end platform for the final prediction of violent activity. After detection of a violent activity, an alert is transmitted to the nearest police station or security department to take prompt preventive actions. We found that our proposed method outperforms the existing state-of-the-art methods for different benchmark datasets.},
DOI = {10.3390/s19112472}
}



@Article{fi11080170,
AUTHOR = {Sgantzos, Konstantinos and Grigg, Ian},
TITLE = {Artificial Intelligence Implementations on the Blockchain. Use Cases and Future Applications},
JOURNAL = {Future Internet},
VOLUME = {11},
YEAR = {2019},
NUMBER = {8},
ARTICLE-NUMBER = {170},
URL = {https://www.mdpi.com/1999-5903/11/8/170},
ISSN = {1999-5903},
ABSTRACT = {An exemplary paradigm of how an AI can be a disruptive technological paragon via the utilization of blockchain comes straight from the world of deep learning. Data scientists have long struggled to maintain the quality of a dataset for machine learning by an AI entity. Datasets can be very expensive to purchase, as, depending on both the proper selection of the elements and the homogeneity of the data contained within, constructing and maintaining the integrity of a dataset is difficult. Blockchain as a highly secure storage medium presents a technological quantum leap in maintaining data integrity. Furthermore, blockchain&rsquo;s immutability constructs a fruitful environment for creating high quality, permanent and growing datasets for deep learning. The combination of AI and blockchain could impact fields like Internet of things (IoT), identity, financial markets, civil governance, smart cities, small communities, supply chains, personalized medicine and other fields, and thereby deliver benefits to many people.},
DOI = {10.3390/fi11080170}
}



@Article{infrastructures4030052,
AUTHOR = {Serrano, Will},
TITLE = {Deep Reinforcement Learning Algorithms in Intelligent Infrastructure},
JOURNAL = {Infrastructures},
VOLUME = {4},
YEAR = {2019},
NUMBER = {3},
ARTICLE-NUMBER = {52},
URL = {https://www.mdpi.com/2412-3811/4/3/52},
ISSN = {2412-3811},
ABSTRACT = {Intelligent infrastructure, including smart cities and intelligent buildings, must learn and adapt to the variable needs and requirements of users, owners and operators in order to be future proof and to provide a return on investment based on Operational Expenditure (OPEX) and Capital Expenditure (CAPEX). To address this challenge, this article presents a biological algorithm based on neural networks and deep reinforcement learning that enables infrastructure to be intelligent by making predictions about its different variables. In addition, the proposed method makes decisions based on real time data. Intelligent infrastructure must be able to proactively monitor, protect and repair itself: this includes independent components and assets working the same way any autonomous biological organisms would. Neurons of artificial neural networks are associated with a prediction or decision layer based on a deep reinforcement learning algorithm that takes into consideration all of its previous learning. The proposed method was validated against an intelligent infrastructure dataset with outstanding results: the intelligent infrastructure was able to learn, predict and adapt to its variables, and components could make relevant decisions autonomously, emulating a living biological organism in which data flow exhaustively.},
DOI = {10.3390/infrastructures4030052}
}



@Article{ijgi8090366,
AUTHOR = {Han, Yong and Wang, Cheng and Ren, Yibin and Wang, Shukang and Zheng, Huangcheng and Chen, Ge},
TITLE = {Short-Term Prediction of Bus Passenger Flow Based on a Hybrid Optimized LSTM Network},
JOURNAL = {ISPRS International Journal of Geo-Information},
VOLUME = {8},
YEAR = {2019},
NUMBER = {9},
ARTICLE-NUMBER = {366},
URL = {https://www.mdpi.com/2220-9964/8/9/366},
ISSN = {2220-9964},
ABSTRACT = {The accurate prediction of bus passenger flow is the key to public transport management and the smart city. A long short-term memory network, a deep learning method for modeling sequences, is an efficient way to capture the time dependency of passenger flow. In recent years, an increasing number of researchers have sought to apply the LSTM model to passenger flow prediction. However, few of them pay attention to the optimization procedure during model training. In this article, we propose a hybrid, optimized LSTM network based on Nesterov accelerated adaptive moment estimation (Nadam) and the stochastic gradient descent algorithm (SGD). This method trains the model with high efficiency and accuracy, solving the problems of inefficient training and misconvergence that exist in complex models. We employ a hybrid optimized LSTM network to predict the actual passenger flow in Qingdao, China and compare the prediction results with those obtained by non-hybrid LSTM models and conventional methods. In particular, the proposed model brings about a 4%–20% extra performance improvements compared with those of non-hybrid LSTM models. We have also tried combinations of other optimization algorithms and applications in different models, finding that optimizing LSTM by switching Nadam to SGD is the best choice. The sensitivity of the model to its parameters is also explored, which provides guidance for applying this model to bus passenger flow data modelling. The good performance of the proposed model in different temporal and spatial scales shows that it is more robust and effective, which can provide insightful support and guidance for dynamic bus scheduling and regional coordination scheduling.},
DOI = {10.3390/ijgi8090366}
}



@Article{app9235254,
AUTHOR = {Hernández-Jiménez, Roberto and Cardenas, Cesar and Muñoz Rodríguez, David},
TITLE = {Modeling and Solution of the Routing Problem in Vehicular Delay-Tolerant Networks: A Dual, Deep Learning Perspective},
JOURNAL = {Applied Sciences},
VOLUME = {9},
YEAR = {2019},
NUMBER = {23},
ARTICLE-NUMBER = {5254},
URL = {https://www.mdpi.com/2076-3417/9/23/5254},
ISSN = {2076-3417},
ABSTRACT = {The exponential growth of cities has brought important challenges such as waste management, pollution and overpopulation, and the administration of transportation. To mitigate these problems, the idea of the smart city was born, seeking to provide robust solutions integrating sensors and electronics, information technologies, and communication networks. More particularly, to face transportation challenges, intelligent transportation systems are a vital component in this quest, helped by vehicular communication networks, which offer a communication framework for vehicles, road infrastructure, and pedestrians. The extreme conditions of vehicular environments, nonetheless, make communication between nodes that may be moving at very high speeds very difficult to achieve, so non-deterministic approaches are necessary to maximize the chances of packet delivery. In this paper, we address this problem using artificial intelligence from a hybrid perspective, focusing on both the best next message to replicate and the best next hop in its path. Furthermore, we propose a deep learning&ndash;based router (DLR+), a router with a prioritized type of message scheduler and a routing algorithm based on deep learning. Simulations done to assess the router performance show important gains in terms of network overhead and hop count, while maintaining an acceptable packet delivery ratio and delivery delays, with respect to other popular routing protocols in vehicular networks.},
DOI = {10.3390/app9235254}
}



@Article{s20020495,
AUTHOR = {Ai, Sophy and Kwon, Jangwoo},
TITLE = {Extreme Low-Light Image Enhancement for Surveillance Cameras Using Attention U-Net},
JOURNAL = {Sensors},
VOLUME = {20},
YEAR = {2020},
NUMBER = {2},
ARTICLE-NUMBER = {495},
URL = {https://www.mdpi.com/1424-8220/20/2/495},
ISSN = {1424-8220},
ABSTRACT = {Low-light image enhancement is one of the most challenging tasks in computer vision, and it is actively researched and used to solve various problems. Most of the time, image processing achieves significant performance under normal lighting conditions. However, under low-light conditions, an image turns out to be noisy and dark, which makes subsequent computer vision tasks difficult. To make buried details more visible, and reduce blur and noise in a low-light captured image, a low-light image enhancement task is necessary. A lot of research has been applied to many different techniques. However, most of these approaches require much effort or expensive equipment to perform low-light image enhancement. For example, the image has to be captured in a raw camera file in order to be processed, and the addressing method does not perform well under extreme low-light conditions. In this paper, we propose a new convolutional network, Attention U-net (the integration of an attention gate and a U-net network), which is able to work on common file types (.PNG, .JPEG, .JPG, etc.) with primary support from deep learning to solve the problem of surveillance camera security in smart city inducements without requiring the raw image file from the camera, and it can perform under the most extreme low-light conditions.},
DOI = {10.3390/s20020495}
}



@Article{s20071908,
AUTHOR = {Ma, Chao and Shi, Xiaochuan and Li, Wei and Zhu, Weiping},
TITLE = {Edge4TSC: Binary Distribution Tree-Enabled Time Series Classification in Edge Environment},
JOURNAL = {Sensors},
VOLUME = {20},
YEAR = {2020},
NUMBER = {7},
ARTICLE-NUMBER = {1908},
URL = {https://www.mdpi.com/1424-8220/20/7/1908},
ISSN = {1424-8220},
ABSTRACT = {In the past decade, time series data have been generated from various fields at a rapid speed, which offers a huge opportunity for mining valuable knowledge. As a typical task of time series mining, Time Series Classification (TSC) has attracted lots of attention from both researchers and domain experts due to its broad applications ranging from human activity recognition to smart city governance. Specifically, there is an increasing requirement for performing classification tasks on diverse types of time series data in a timely manner without costly hand-crafting feature engineering. Therefore, in this paper, we propose a framework named Edge4TSC that allows time series to be processed in the edge environment, so that the classification results can be instantly returned to the end-users. Meanwhile, to get rid of the costly hand-crafting feature engineering process, deep learning techniques are applied for automatic feature extraction, which shows competitive or even superior performance compared to state-of-the-art TSC solutions. However, because time series presents complex patterns, even deep learning models are not capable of achieving satisfactory classification accuracy, which motivated us to explore new time series representation methods to help classifiers further improve the classification accuracy. In the proposed framework Edge4TSC, by building the binary distribution tree, a new time series representation method was designed for addressing the classification accuracy concern in TSC tasks. By conducting comprehensive experiments on six challenging time series datasets in the edge environment, the potential of the proposed framework for its generalization ability and classification accuracy improvement is firmly validated with a number of helpful insights.},
DOI = {10.3390/s20071908}
}



@Article{su12072789,
AUTHOR = {Nikitas, Alexandros and Michalakopoulou, Kalliopi and Njoya, Eric Tchouamou and Karampatzakis, Dimitris},
TITLE = {Artificial Intelligence, Transport and the Smart City: Definitions and Dimensions of a New Mobility Era},
JOURNAL = {Sustainability},
VOLUME = {12},
YEAR = {2020},
NUMBER = {7},
ARTICLE-NUMBER = {2789},
URL = {https://www.mdpi.com/2071-1050/12/7/2789},
ISSN = {2071-1050},
ABSTRACT = {Artificial intelligence (AI) is a powerful concept still in its infancy that has the potential, if utilised responsibly, to provide a vehicle for positive change that could promote sustainable transitions to a more resource-efficient livability paradigm. AI with its deep learning functions and capabilities can be employed as a tool which empowers machines to solve problems that could reform urban landscapes as we have known them for decades now and help with establishing a new era; the era of the &ldquo;smart city&rdquo;. One of the key areas that AI can redefine is transport. Mobility provision and its impact on urban development can be significantly improved by the employment of intelligent transport systems in general and automated transport in particular. This new breed of AI-based mobility, despite its machine-orientation, has to be a user-centred technology that &ldquo;understands&rdquo; and &ldquo;satisfies&rdquo; the human user, the markets and the society as a whole. Trust should be built, and risks should be eliminated, for this transition to take off. This paper provides a novel conceptual contribution that thoroughly discusses the scarcely studied nexus of AI, transportation and the smart city and how this will affect urban futures. It specifically covers key smart mobility initiatives referring to Connected and Autonomous Vehicles (CAVs), autonomous Personal and Unmanned Aerial Vehicles (PAVs and UAVs) and Mobility-as-a-Service (MaaS), but also interventions that may work as enabling technologies for transport, such as the Internet of Things (IoT) and Physical Internet (PI) or reflect broader transformations like Industry 4.0. This work is ultimately a reference tool for researchers and city planners that provides clear and systematic definitions of the ambiguous smart mobility terms of tomorrow and describes their individual and collective roles underpinning the nexus in scope.},
DOI = {10.3390/su12072789}
}



@Article{su12124947,
AUTHOR = {Zhuang, Haoran and Zhang, Jian and C. B., Sivaparthipan and Muthu, Bala Anand},
TITLE = {Sustainable Smart City Building Construction Methods},
JOURNAL = {Sustainability},
VOLUME = {12},
YEAR = {2020},
NUMBER = {12},
ARTICLE-NUMBER = {4947},
URL = {https://www.mdpi.com/2071-1050/12/12/4947},
ISSN = {2071-1050},
ABSTRACT = {In a global world, the human population invariably increases while resources gradually decrease as cities and towns constantly consume resources to satisfy their needs and requirements. At this point, it is very necessary to focus on making these urban areas more sustainable and greener. The need for some advanced and automated systems improves the situation, which leads to the innovation of smart cities. Smart city is the concept that helps in developing sustainable cities via optimized resource utilization methods. In smart city development, various sensing technologies can be used that can sense and utilize natural resources in better ways, like storing rainwater to use afterward, intelligent and smart control system, smart infrastructure monitoring system, smart healthcare system, smart transportation system, and smart system for energy consumption and generation by various facilities. To make the city smart and sustainable with efficient energy consumption, we propose renewable solar and wind energy-enabled hybrid heating and cooling HVAC-DHW (heating, ventilation, and air conditioning-Domestic Hot Water) system in which energy consumption is evaluated using optimized NARX-ANN and fuzzy controller based on user needs, dynamic behavior of the atmospheric environment, and spatial distribution of energy supply. To achieve the proposed goal, first, via sensor, heating and cooling effect of environment and building is sensed and these sensed inputs are then fed into deep-learning-based NARX-ANN that forecast internal building temperature. This forecasted temperature is fed into a fuzzy controller for optimizing output based on user demand. This processed information leads to energy distribution based on their requirement using a smart energy sensing system. Based on the experimentation result and performance analysis, it was found that the proposed system is more robust and has a high control response in comparison to the existing systems with minimum energy consumption. The analytical results support the feasibility of the proposed framework architecture to facilitate energy conserving in smart city buildings.},
DOI = {10.3390/su12124947}
}



@Article{s20123503,
AUTHOR = {Crivellari, Alessandro and Beinat, Euro},
TITLE = {Trace2trace—A Feasibility Study on Neural Machine Translation Applied to Human Motion Trajectories},
JOURNAL = {Sensors},
VOLUME = {20},
YEAR = {2020},
NUMBER = {12},
ARTICLE-NUMBER = {3503},
URL = {https://www.mdpi.com/1424-8220/20/12/3503},
ISSN = {1424-8220},
ABSTRACT = {Neural machine translation is a prominent field in the computational linguistics domain. By leveraging the recent developments of deep learning, it gave birth to powerful algorithms for translating text from one language to another. This study aims to assess the feasibility of transferring the neural machine translation approach into a completely different context, namely human mobility and trajectory analysis. Building a conceptual parallelism between sentences (sequences of words) and motion traces (sequences of locations), we aspire to translate individual trajectories generated by a certain category of users into the corresponding mobility traces potentially generated by a different category of users. The experiment is inserted in the background of tourist mobility analysis, with the goal of translating the motion behavior of tourists belonging to a specific nationality into the motion behavior of tourists belonging to a different nationality. The model adopted is based on the seq2seq approach and consists of an encoder&ndash;decoder architecture based on long short-term memory (LSTM) neural networks and neural embeddings. The encoder turns an input location sequence into a corresponding hidden vector; the decoder reverses the process, turning the vector into an output location sequence. The proposed framework, tested on a real-world large-scale dataset, explores an effective attempt of motion transformation between different entities, arising as a potentially powerful source of mobility information disclosure, especially in the context of crowd management and smart city services.},
DOI = {10.3390/s20123503}
}



@Article{a13090208,
AUTHOR = {Santos, Guto Leoni and Endo, Patricia Takako and Sadok, Djamel and Kelner, Judith},
TITLE = {When 5G Meets Deep Learning: A Systematic Review},
JOURNAL = {Algorithms},
VOLUME = {13},
YEAR = {2020},
NUMBER = {9},
ARTICLE-NUMBER = {208},
URL = {https://www.mdpi.com/1999-4893/13/9/208},
ISSN = {1999-4893},
ABSTRACT = {This last decade, the amount of data exchanged on the Internet increased by over a staggering factor of 100, and is expected to exceed well over the 500 exabytes by 2020. This phenomenon is mainly due to the evolution of high-speed broadband Internet and, more specifically, the popularization and wide spread use of smartphones and associated accessible data plans. Although 4G with its long-term evolution (LTE) technology is seen as a mature technology, there is continual improvement to its radio technology and architecture such as in the scope of the LTE Advanced standard, a major enhancement of LTE. However, for the long run, the next generation of telecommunication (5G) is considered and is gaining considerable momentum from both industry and researchers. In addition, with the deployment of the Internet of Things (IoT) applications, smart cities, vehicular networks, e-health systems, and Industry 4.0, a new plethora of 5G services has emerged with very diverging and technologically challenging design requirements. These include high mobile data volume per area, high number of devices connected per area, high data rates, longer battery life for low-power devices, and reduced end-to-end latency. Several technologies are being developed to meet these new requirements, and each of these technologies brings its own design issues and challenges. In this context, deep learning models could be seen as one of the main tools that can be used to process monitoring data and automate decisions. As these models are able to extract relevant features from raw data (images, texts, and other types of unstructured data), the integration between 5G and DL looks promising and one that requires exploring. As main contribution, this paper presents a systematic review about how DL is being applied to solve some 5G issues. Differently from the current literature, we examine data from the last decade and the works that address diverse 5G specific problems, such as physical medium state estimation, network traffic prediction, user device location prediction, self network management, among others. We also discuss the main research challenges when using deep learning models in 5G scenarios and identify several issues that deserve further consideration.},
DOI = {10.3390/a13090208}
}



@Article{s20185240,
AUTHOR = {Koubaa, Anis and Ammar, Adel and Alahdab, Mahmoud and Kanhouch, Anas and Azar, Ahmad Taher},
TITLE = {DeepBrain: Experimental Evaluation of Cloud-Based Computation Offloading and Edge Computing in the Internet-of-Drones for Deep Learning Applications},
JOURNAL = {Sensors},
VOLUME = {20},
YEAR = {2020},
NUMBER = {18},
ARTICLE-NUMBER = {5240},
URL = {https://www.mdpi.com/1424-8220/20/18/5240},
ISSN = {1424-8220},
ABSTRACT = {Unmanned Aerial Vehicles (UAVs) have been very effective in collecting aerial images data for various Internet-of-Things (IoT)/smart cities applications such as search and rescue, surveillance, vehicle detection, counting, intelligent transportation systems, to name a few. However, the real-time processing of collected data on edge in the context of the Internet-of-Drones remains an open challenge because UAVs have limited energy capabilities, while computer vision techniquesconsume excessive energy and require abundant resources. This fact is even more critical when deep learning algorithms, such as convolutional neural networks (CNNs), are used for classification and detection. In this paper, we first propose a system architecture of computation offloading for Internet-connected drones. Then, we conduct a comprehensive experimental study to evaluate the performance in terms of energy, bandwidth, and delay of the cloud computation offloading approach versus the edge computing approach of deep learning applications in the context of UAVs. In particular, we investigate the tradeoff between the communication cost and the computation of the two candidate approaches experimentally. The main results demonstrate that the computation offloading approach allows us to provide much higher throughput (i.e., frames per second) as compared to the edge computing approach, despite the larger communication delays.},
DOI = {10.3390/s20185240}
}



@Article{app10186580,
AUTHOR = {Cecaj, Alket and Lippi, Marco and Mamei, Marco and Zambonelli, Franco},
TITLE = {Comparing Deep Learning and Statistical Methods in Forecasting Crowd Distribution from Aggregated Mobile Phone Data},
JOURNAL = {Applied Sciences},
VOLUME = {10},
YEAR = {2020},
NUMBER = {18},
ARTICLE-NUMBER = {6580},
URL = {https://www.mdpi.com/2076-3417/10/18/6580},
ISSN = {2076-3417},
ABSTRACT = {Accurately forecasting how crowds of people are distributed in urban areas during daily activities is of key importance for the smart city vision and related applications. In this work we forecast the crowd density and distribution in an urban area by analyzing an aggregated mobile phone dataset. By comparing the forecasting performance of statistical and deep learning methods on the aggregated mobile data we show that each class of methods has its advantages and disadvantages depending on the forecasting scenario. However, for our time-series forecasting problem, deep learning methods are preferable when it comes to simplicity and immediacy of use, since they do not require a time-consuming model selection for each different cell. Deep learning approaches are also appropriate when aiming to reduce the maximum forecasting error. Statistical methods instead show their superiority in providing more precise forecasting results, but they require data domain knowledge and computationally expensive techniques in order to select the best parameters.},
DOI = {10.3390/app10186580}
}



@Article{s20195481,
AUTHOR = {Papacharalampopoulos, Alexios and Tzimanis, Konstantinos and Sabatakakis, Kyriakos and Stavropoulos, Panagiotis},
TITLE = {Deep Quality Assessment of a Solar Reflector Based on Synthetic Data: Detecting Surficial Defects from Manufacturing and Use Phase},
JOURNAL = {Sensors},
VOLUME = {20},
YEAR = {2020},
NUMBER = {19},
ARTICLE-NUMBER = {5481},
URL = {https://www.mdpi.com/1424-8220/20/19/5481},
ISSN = {1424-8220},
ABSTRACT = {Vision technologies are used in both industrial and smart city applications in order to provide advanced value products due to embedded self-monitoring and assessment services. In addition, for the full utilization of the obtained data, deep learning is now suggested for use. To this end, the current work presents the implementation of image recognition techniques alongside the original the quality assessment of a Parabolic Trough Collector (PTC) reflector surface to locate and identify surface irregularities by classifying images as either acceptable or non-acceptable. The method consists of a three-step solution that promotes an affordable implementation in a relatively small time period. More specifically, a 3D Computer Aided Design (CAD) of the PTC was used for the pre-training of neural networks, while an aluminum reflector surface was used to verify algorithm performance. The results are promising, as this method proved applicable in cases where the actual part was manufactured in small batches or under the concept of customized manufacturing. Consequently, the algorithm is capable of being trained with a limited number of data.},
DOI = {10.3390/s20195481}
}



@Article{s20216019,
AUTHOR = {Lozano Domínguez, José Manuel and Al-Tam, Faroq and Mateo Sanguino, Tomás de J. and Correia, Noélia},
TITLE = {Analysis of Machine Learning Techniques Applied to Sensory Detection of Vehicles in Intelligent Crosswalks},
JOURNAL = {Sensors},
VOLUME = {20},
YEAR = {2020},
NUMBER = {21},
ARTICLE-NUMBER = {6019},
URL = {https://www.mdpi.com/1424-8220/20/21/6019},
ISSN = {1424-8220},
ABSTRACT = {Improving road safety through artificial intelligence-based systems is now crucial turning smart cities into a reality. Under this highly relevant and extensive heading, an approach is proposed to improve vehicle detection in smart crosswalks using machine learning models. Contrarily to classic fuzzy classifiers, machine learning models do not require the readjustment of labels that depend on the location of the system and the road conditions. Several machine learning models were trained and tested using real traffic data taken from urban scenarios in both Portugal and Spain. These include random forest, time-series forecasting, multi-layer perceptron, support vector machine, and logistic regression models. A deep reinforcement learning agent, based on a state-of-the-art double-deep recurrent Q-network, is also designed and compared with the machine learning models just mentioned. Results show that the machine learning models can efficiently replace the classic fuzzy classifier.},
DOI = {10.3390/s20216019}
}



@Article{app10217448,
AUTHOR = {Gaviria, Jorge Felipe and Escalante-Perez, Alejandra and Castiblanco, Juan Camilo and Vergara, Nicolas and Parra-Garces, Valentina and Serrano, Juan David and Zambrano, Andres Felipe and Giraldo, Luis Felipe},
TITLE = {Deep Learning-Based Portable Device for Audio Distress Signal Recognition in Urban Areas},
JOURNAL = {Applied Sciences},
VOLUME = {10},
YEAR = {2020},
NUMBER = {21},
ARTICLE-NUMBER = {7448},
URL = {https://www.mdpi.com/2076-3417/10/21/7448},
ISSN = {2076-3417},
ABSTRACT = {Real-time automatic identification of audio distress signals in urban areas is a task that in a smart city can improve response times in emergency alert systems. The main challenge in this problem lies in finding a model that is able to accurately recognize these type of signals in the presence of background noise and allows for real-time processing. In this paper, we present the design of a portable and low-cost device for accurate audio distress signal recognition in real urban scenarios based on deep learning models. As real audio distress recordings in urban areas have not been collected and made publicly available so far, we first constructed a database where audios were recorded in urban areas using a low-cost microphone. Using this database, we trained a deep multi-headed 2D convolutional neural network that processed temporal and frequency features to accurately recognize audio distress signals in noisy environments with a significant performance improvement to other methods from the literature. Then, we deployed and assessed the trained convolutional neural network model on a Raspberry Pi that, along with the low-cost microphone, constituted a device for accurate real-time audio recognition. Source code and database are publicly available.},
DOI = {10.3390/app10217448}
}



@Article{smartcities3040065,
AUTHOR = {Thakker, Dhavalkumar and Mishra, Bhupesh Kumar and Abdullatif, Amr and Mazumdar, Suvodeep and Simpson, Sydney},
TITLE = {Explainable Artificial Intelligence for Developing Smart Cities Solutions},
JOURNAL = {Smart Cities},
VOLUME = {3},
YEAR = {2020},
NUMBER = {4},
PAGES = {1353--1382},
URL = {https://www.mdpi.com/2624-6511/3/4/65},
ISSN = {2624-6511},
ABSTRACT = {Traditional Artificial Intelligence (AI) technologies used in developing smart cities solutions, Machine Learning (ML) and recently Deep Learning (DL), rely more on utilising best representative training datasets and features engineering and less on the available domain expertise. We argue that such an approach to solution development makes the outcome of solutions less explainable, i.e., it is often not possible to explain the results of the model. There is a growing concern among policymakers in cities with this lack of explainability of AI solutions, and this is considered a major hindrance in the wider acceptability and trust in such AI-based solutions. In this work, we survey the concept of &lsquo;explainable deep learning&rsquo; as a subset of the &lsquo;explainable AI&rsquo; problem and propose a new solution using Semantic Web technologies, demonstrated with a smart cities flood monitoring application in the context of a European Commission-funded project. Monitoring of gullies and drainage in crucial geographical areas susceptible to flooding issues is an important aspect of any flood monitoring solution. Typical solutions for this problem involve the use of cameras to capture images showing the affected areas in real-time with different objects such as leaves, plastic bottles etc., and building a DL-based classifier to detect such objects and classify blockages based on the presence and coverage of these objects in the images. In this work, we uniquely propose an Explainable AI solution using DL and Semantic Web technologies to build a hybrid classifier. In this hybrid classifier, the DL component detects object presence and coverage level and semantic rules designed with close consultation with experts carry out the classification. By using the expert knowledge in the flooding context, our hybrid classifier provides the flexibility on categorising the image using objects and their coverage relationships. The experimental results demonstrated with a real-world use case showed that this hybrid approach of image classification has on average 11% improvement (F-Measure) in image classification performance compared to DL-only classifier. It also has the distinct advantage of integrating experts&rsquo; knowledge on defining the decision-making rules to represent the complex circumstances and using such knowledge to explain the results.},
DOI = {10.3390/smartcities3040065}
}



@Article{w12123537,
AUTHOR = {Park, Kidoo and Jung, Younghun and Kim, Kyungtak and Park, Seung Kook},
TITLE = {Determination of Deep Learning Model and Optimum Length of Training Data in the River with Large Fluctuations in Flow Rates},
JOURNAL = {Water},
VOLUME = {12},
YEAR = {2020},
NUMBER = {12},
ARTICLE-NUMBER = {3537},
URL = {https://www.mdpi.com/2073-4441/12/12/3537},
ISSN = {2073-4441},
ABSTRACT = {Recently, developing countries have steadily been pushing for the construction of stream-oriented smart cities, breaking away from the existing old-town-centered development in the past. Due to the accelerating effects of climate change along with such urbanization, it is imperative for urban rivers to establish a flood warning system that can predict the amount of high flow rates of accuracy in engineering, compared to using the existing Computational Fluid Dynamics (CFD) models for disaster prevention. In this study, in the case of streams where missing data existed or only small observations were obtained, the variation in flow rates could be predicted with only the appropriate deep learning models, using only limited time series flow data. In addition, the selected deep learning model allowed the minimum number of input learning data to be determined. In this study, the time series flow rates were predicted by applying the deep learning models to the Han River, which is a highly urbanized stream that flows through the capital of Korea, Seoul and has a large seasonal variation in the flow rate. The deep learning models used are Convolution Neural Network (CNN), Simple Recurrent Neural Network (RNN), Long Short-Term Memory (LSTM), Bidirectional LSTM (Bi-LSTM) and Gated Recurrent Unit (GRU). Sequence lengths for time series runoff data were determined first to assess the accuracy and applicability of the deep learning models. By analyzing the forecast results of the outflow data of the Han River, sequence length for 14 days was appropriate in terms of the predicted accuracy of the model. In addition, the GRU model is effective for deep learning models that use time series data of the region with large fluctuations in flow rates, such as the Han River. Furthermore, through this study, it was possible to propose the minimum number of training data that could provide flood warning system with an effective flood forecasting system although the number of input data such as flow rates secured in new towns developed around rivers was insufficient.},
DOI = {10.3390/w12123537}
}



@Article{electronics10010014,
AUTHOR = {Kumar, Saurav and Yadav, Drishti and Gupta, Himanshu and Verma, Om Prakash and Ansari, Irshad Ahmad and Ahn, Chang Wook},
TITLE = {A Novel YOLOv3 Algorithm-Based Deep Learning Approach for Waste Segregation: Towards Smart Waste Management},
JOURNAL = {Electronics},
VOLUME = {10},
YEAR = {2021},
NUMBER = {1},
ARTICLE-NUMBER = {14},
URL = {https://www.mdpi.com/2079-9292/10/1/14},
ISSN = {2079-9292},
ABSTRACT = {The colossal increase in environmental pollution and degradation, resulting in ecological imbalance, is an eye-catching concern in the contemporary era. Moreover, the proliferation in the development of smart cities across the globe necessitates the emergence of a robust smart waste management system for proper waste segregation based on its biodegradability. The present work investigates a novel approach for waste segregation for its effective recycling and disposal by utilizing a deep learning strategy. The YOLOv3 algorithm has been utilized in the Darknet neural network framework to train a self-made dataset. The network has been trained for 6 object classes (namely: cardboard, glass, metal, paper, plastic and organic waste). Moreover, for comparative assessment, the detection task has also been performed using YOLOv3-tiny to validate the competence of the YOLOv3 algorithm. The experimental results demonstrate that the proposed YOLOv3 methodology yields satisfactory generalization capability for all the classes with a variety of waste items.},
DOI = {10.3390/electronics10010014}
}



@Article{s21020434,
AUTHOR = {Hong, Qingqi and Ding, Yiwei and Lin, Jinpeng and Wang, Meihong and Wei, Qingyang and Wang, Xianwei and Zeng, Ming},
TITLE = {Image-Based Automatic Watermeter Reading under Challenging Environments},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {2},
ARTICLE-NUMBER = {434},
URL = {https://www.mdpi.com/1424-8220/21/2/434},
PubMedID = {33435444},
ISSN = {1424-8220},
ABSTRACT = {With the rapid development of artificial intelligence and fifth-generation mobile network technologies, automatic instrument reading has become an increasingly important topic for intelligent sensors in smart cities. We propose a full pipeline to automatically read watermeters based on a single image, using deep learning methods to provide new technical support for an intelligent water meter reading. To handle the various challenging environments where watermeters reside, our pipeline disentangled the task into individual subtasks based on the structures of typical watermeters. These subtasks include component localization, orientation alignment, spatial layout guidance reading, and regression-based pointer reading. The devised algorithms for orientation alignment and spatial layout guidance are tailored to improve the robustness of our neural network. We also collect images of watermeters in real scenes and build a dataset for training and evaluation. Experimental results demonstrate the effectiveness of the proposed method even under challenging environments with varying lighting, occlusions, and different orientations. Thanks to the lightweight algorithms adopted in our pipeline, the system can be easily deployed and fully automated.},
DOI = {10.3390/s21020434}
}



@Article{smartcities4010013,
AUTHOR = {Ye, Xinyue and Duan, Lian and Peng, Qiong},
TITLE = {Spatiotemporal Prediction of Theft Risk with Deep Inception-Residual Networks},
JOURNAL = {Smart Cities},
VOLUME = {4},
YEAR = {2021},
NUMBER = {1},
PAGES = {204--216},
URL = {https://www.mdpi.com/2624-6511/4/1/13},
ISSN = {2624-6511},
ABSTRACT = {Spatiotemporal prediction of crime is crucial for public safety and smart cities operation. As crime incidents are distributed sparsely across space and time, existing deep-learning methods constrained by coarse spatial scale offer only limited values in prediction of crime density. This paper proposes the use of deep inception-residual networks (DIRNet) to conduct fine-grained, theft-related crime prediction based on non-emergency service request data (311 events). Specifically, it outlines the employment of inception units comprising asymmetrical convolution layers to draw low-level spatiotemporal dependencies hidden in crime events and complaint records in the 311 dataset. Afterward, this paper details how residual units can be applied to capture high-level spatiotemporal features from low-level spatiotemporal dependencies for the final prediction. The effectiveness of the proposed DIRNet is evaluated based on theft-related crime data and 311 data in New York City from 2010 to 2015. The results confirm that the DIRNet obtains an average F1 of 71%, which is better than other prediction models.},
DOI = {10.3390/smartcities4010013}
}



@Article{app11052214,
AUTHOR = {Hettiarachchi, Prasad and Nawaratne, Rashmika and Alahakoon, Damminda and De Silva, Daswin and Chilamkurti, Naveen},
TITLE = {Rain Streak Removal for Single Images Using Conditional Generative Adversarial Networks},
JOURNAL = {Applied Sciences},
VOLUME = {11},
YEAR = {2021},
NUMBER = {5},
ARTICLE-NUMBER = {2214},
URL = {https://www.mdpi.com/2076-3417/11/5/2214},
ISSN = {2076-3417},
ABSTRACT = {Rapid developments in urbanization and smart city environments have accelerated the need to deliver safe, sustainable, and effective resource utilization and service provision and have thereby enhanced the need for intelligent, real-time video surveillance. Recent advances in machine learning and deep learning have the capability to detect and localize salient objects in surveillance video streams; however, several practical issues remain unaddressed, such as diverse weather conditions, recording conditions, and motion blur. In this context, image de-raining is an important issue that has been investigated extensively in recent years to provide accurate and quality surveillance in the smart city domain. Existing deep convolutional neural networks have obtained great success in image translation and other computer vision tasks; however, image de-raining is ill posed and has not been addressed in real-time, intelligent video surveillance systems. In this work, we propose to utilize the generative capabilities of recently introduced conditional generative adversarial networks (cGANs) as an image de-raining approach. We utilize the adversarial loss in GANs that provides an additional component to the loss function, which in turn regulates the final output and helps to yield better results. Experiments on both real and synthetic data show that the proposed method outperforms most of the existing state-of-the-art models in terms of quantitative evaluations and visual appearance.},
DOI = {10.3390/app11052214}
}



@Article{su13052876,
AUTHOR = {Parlina, Anne and Ramli, Kalamullah and Murfi, Hendri},
TITLE = {Exposing Emerging Trends in Smart Sustainable City Research Using Deep Autoencoders-Based Fuzzy C-Means},
JOURNAL = {Sustainability},
VOLUME = {13},
YEAR = {2021},
NUMBER = {5},
ARTICLE-NUMBER = {2876},
URL = {https://www.mdpi.com/2071-1050/13/5/2876},
ISSN = {2071-1050},
ABSTRACT = {The literature discussing the concepts, technologies, and ICT-based urban innovation approaches of smart cities has been growing, along with initiatives from cities all over the world that are competing to improve their services and become smart and sustainable. However, current studies that provide a comprehensive understanding and reveal smart and sustainable city research trends and characteristics are still lacking. Meanwhile, policymakers and practitioners alike need to pursue progressive development. In response to this shortcoming, this research offers content analysis studies based on topic modeling approaches to capture the evolution and characteristics of topics in the scientific literature on smart and sustainable city research. More importantly, a novel topic-detecting algorithm based on the deep learning and clustering techniques, namely deep autoencoders-based fuzzy C-means (DFCM), is introduced for analyzing the research topic trend. The topics generated by this proposed algorithm have relatively higher coherence values than those generated by previously used topic detection methods, namely non-negative matrix factorization (NMF), latent Dirichlet allocation (LDA), and eigenspace-based fuzzy C-means (EFCM). The 30 main topics that appeared in topic modeling with the DFCM algorithm were classified into six groups (technology, energy, environment, transportation, e-governance, and human capital and welfare) that characterize the six dimensions of smart, sustainable city research.},
DOI = {10.3390/su13052876}
}



@Article{app11062714,
AUTHOR = {Zhang, Xue and Kuehnelt, Helmut and De Roeck, Wim},
TITLE = {Traffic Noise Prediction Applying Multivariate Bi-Directional Recurrent Neural Network},
JOURNAL = {Applied Sciences},
VOLUME = {11},
YEAR = {2021},
NUMBER = {6},
ARTICLE-NUMBER = {2714},
URL = {https://www.mdpi.com/2076-3417/11/6/2714},
ISSN = {2076-3417},
ABSTRACT = {With the drastically increasing traffic in the last decades, crucial environmental problems have been caused, such as greenhouse gas emission and traffic noise pollution. These problems have adversely affected our life quality and health conditions. In this paper, modelling of traffic noise employing deep learning is investigated. The goal is to identify the best machine-learning model for predicting traffic noise from real-life traffic data with multivariate traffic features as input. An extensive study on recurrent neural network (RNN) is performed in this work for modelling time series traffic data, which was collected through an experimental campaign at an inner city roundabout, including both video traffic data and audio data. The preprocessing of the data, namely how to generate the appropriate input and output for deep learning model, is detailed in this paper. A selection of different architectures of RNN, such as many-to-one, many-to-many, encoder–decoder architectures, was investigated. Moreover, gated recurrent unit (GRU) and long short-term memory (LSTM) were further discussed. The results revealed that a multivariate bi-directional GRU model with many-to-many architecture achieved the best performance with both high accuracy and computation efficiency. The trained model could be promising for a future smart city concept; with the proposed model, real-time traffic noise predictions can be potentially feasible using only traffic data collected by different sensors in the city, thanks to the generated big data by smart cities. The forecast of excessive noise exposure can help the regulation and policy makers to make early decisions, in order to mitigate the noise level.},
DOI = {10.3390/app11062714}
}



@Article{s21082811,
AUTHOR = {Ullah, Waseem and Ullah, Amin and Hussain, Tanveer and Khan, Zulfiqar Ahmad and Baik, Sung Wook},
TITLE = {An Efficient Anomaly Recognition Framework Using an Attention Residual LSTM in Surveillance Videos},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {8},
ARTICLE-NUMBER = {2811},
URL = {https://www.mdpi.com/1424-8220/21/8/2811},
PubMedID = {33923712},
ISSN = {1424-8220},
ABSTRACT = {Video anomaly recognition in smart cities is an important computer vision task that plays a vital role in smart surveillance and public safety but is challenging due to its diverse, complex, and infrequent occurrence in real-time surveillance environments. Various deep learning models use significant amounts of training data without generalization abilities and with huge time complexity. To overcome these problems, in the current work, we present an efficient light-weight convolutional neural network (CNN)-based anomaly recognition framework that is functional in a surveillance environment with reduced time complexity. We extract spatial CNN features from a series of video frames and feed them to the proposed residual attention-based long short-term memory (LSTM) network, which can precisely recognize anomalous activity in surveillance videos. The representative CNN features with the residual blocks concept in LSTM for sequence learning prove to be effective for anomaly detection and recognition, validating our model’s effective usage in smart cities video surveillance. Extensive experiments on the real-world benchmark UCF-Crime dataset validate the effectiveness of the proposed model within complex surveillance environments and demonstrate that our proposed model outperforms state-of-the-art models with a 1.77%, 0.76%, and 8.62% increase in accuracy on the UCF-Crime, UMN and Avenue datasets, respectively.},
DOI = {10.3390/s21082811}
}



@Article{s21093261,
AUTHOR = {Sultan, Salman Md and Waleed, Muhammad and Pyun, Jae-Young and Um, Tai-Won},
TITLE = {Energy Conservation for Internet of Things Tracking Applications Using Deep Reinforcement Learning},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {9},
ARTICLE-NUMBER = {3261},
URL = {https://www.mdpi.com/1424-8220/21/9/3261},
PubMedID = {34066766},
ISSN = {1424-8220},
ABSTRACT = {The Internet of Things (IoT)-based target tracking system is required for applications such as smart farm, smart factory, and smart city where many sensor devices are jointly connected to collect the moving target positions. Each sensor device continuously runs on battery-operated power, consuming energy while perceiving target information in a particular environment. To reduce sensor device energy consumption in real-time IoT tracking applications, many traditional methods such as clustering, information-driven, and other approaches have previously been utilized to select the best sensor. However, applying machine learning methods, particularly deep reinforcement learning (Deep RL), to address the problem of sensor selection in tracking applications is quite demanding because of the limited sensor node battery lifetime. In this study, we proposed a long short-term memory deep Q-network (DQN)-based Deep RL target tracking model to overcome the problem of energy consumption in IoT target applications. The proposed method is utilized to select the energy-efficient best sensor while tracking the target. The best sensor is defined by the minimum distance function (i.e., derived as the state), which leads to lower energy consumption. The simulation results show favorable features in terms of the best sensor selection and energy consumption.},
DOI = {10.3390/s21093261}
}



@Article{s21124223,
AUTHOR = {Nasif, Ammar and Othman, Zulaiha Ali and Sani, Nor Samsiah},
TITLE = {The Deep Learning Solutions on Lossless Compression Methods for Alleviating Data Load on IoT Nodes in Smart Cities},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {12},
ARTICLE-NUMBER = {4223},
URL = {https://www.mdpi.com/1424-8220/21/12/4223},
PubMedID = {34203024},
ISSN = {1424-8220},
ABSTRACT = {Networking is crucial for smart city projects nowadays, as it offers an environment where people and things are connected. This paper presents a chronology of factors on the development of smart cities, including IoT technologies as network infrastructure. Increasing IoT nodes leads to increasing data flow, which is a potential source of failure for IoT networks. The biggest challenge of IoT networks is that the IoT may have insufficient memory to handle all transaction data within the IoT network. We aim in this paper to propose a potential compression method for reducing IoT network data traffic. Therefore, we investigate various lossless compression algorithms, such as entropy or dictionary-based algorithms, and general compression methods to determine which algorithm or method adheres to the IoT specifications. Furthermore, this study conducts compression experiments using entropy (Huffman, Adaptive Huffman) and Dictionary (LZ77, LZ78) as well as five different types of datasets of the IoT data traffic. Though the above algorithms can alleviate the IoT data traffic, adaptive Huffman gave the best compression algorithm. Therefore, in this paper, we aim to propose a conceptual compression method for IoT data traffic by improving an adaptive Huffman based on deep learning concepts using weights, pruning, and pooling in the neural network. The proposed algorithm is believed to obtain a better compression ratio. Additionally, in this paper, we also discuss the challenges of applying the proposed algorithm to IoT data compression due to the limitations of IoT memory and IoT processor, which later it can be implemented in IoT networks.},
DOI = {10.3390/s21124223}
}



@Article{rs13163220,
AUTHOR = {Zou, Yanling and Weinacker, Holger and Koch, Barbara},
TITLE = {Towards Urban Scene Semantic Segmentation with Deep Learning from LiDAR Point Clouds: A Case Study in Baden-Württemberg, Germany},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {16},
ARTICLE-NUMBER = {3220},
URL = {https://www.mdpi.com/2072-4292/13/16/3220},
ISSN = {2072-4292},
ABSTRACT = {An accurate understanding of urban objects is critical for urban modeling, intelligent infrastructure planning and city management. The semantic segmentation of light detection and ranging (LiDAR) point clouds is a fundamental approach for urban scene analysis. Over the last years, several methods have been developed to segment urban furniture with point clouds. However, the traditional processing of large amounts of spatial data has become increasingly costly, both time-wise and financially. Recently, deep learning (DL) techniques have been increasingly used for 3D segmentation tasks. Yet, most of these deep neural networks (DNNs) were conducted on benchmarks. It is, therefore, arguable whether DL approaches can achieve the state-of-the-art performance of 3D point clouds segmentation in real-life scenarios. In this research, we apply an adapted DNN (ARandLA-Net) to directly process large-scale point clouds. In particular, we develop a new paradigm for training and validation, which presents a typical urban scene in central Europe (Munzingen, Freiburg, Baden-Württemberg, Germany). Our dataset consists of nearly 390 million dense points acquired by Mobile Laser Scanning (MLS), which has a rather larger quantity of sample points in comparison to existing datasets and includes meaningful object categories that are particular to applications for smart cities and urban planning. We further assess the DNN on our dataset and investigate a number of key challenges from varying aspects, such as data preparation strategies, the advantage of color information and the unbalanced class distribution in the real world. The final segmentation model achieved a mean Intersection-over-Union (mIoU) score of 54.4% and an overall accuracy score of 83.9%. Our experiments indicated that different data preparation strategies influenced the model performance. Additional RGB information yielded an approximately 4% higher mIoU score. Our results also demonstrate that the use of weighted cross-entropy with inverse square root frequency loss led to better segmentation performance than when other losses were considered.},
DOI = {10.3390/rs13163220}
}



@Article{a14080245,
AUTHOR = {Albeshri, Aiiad},
TITLE = {SVSL: A Human Activity Recognition Method Using Soft-Voting and Self-Learning},
JOURNAL = {Algorithms},
VOLUME = {14},
YEAR = {2021},
NUMBER = {8},
ARTICLE-NUMBER = {245},
URL = {https://www.mdpi.com/1999-4893/14/8/245},
ISSN = {1999-4893},
ABSTRACT = {Many smart city and society applications such as smart health (elderly care, medical applications), smart surveillance, sports, and robotics require the recognition of user activities, an important class of problems known as human activity recognition (HAR). Several issues have hindered progress in HAR research, particularly due to the emergence of fog and edge computing, which brings many new opportunities (a low latency, dynamic and real-time decision making, etc.) but comes with its challenges. This paper focuses on addressing two important research gaps in HAR research: (i) improving the HAR prediction accuracy and (ii) managing the frequent changes in the environment and data related to user activities. To address this, we propose an HAR method based on Soft-Voting and Self-Learning (SVSL). SVSL uses two strategies. First, to enhance accuracy, it combines the capabilities of Deep Learning (DL), Generalized Linear Model (GLM), Random Forest (RF), and AdaBoost classifiers using soft-voting. Second, to classify the most challenging data instances, the SVSL method is equipped with a self-training mechanism that generates training data and retrains itself. We investigate the performance of our proposed SVSL method using two publicly available datasets on six human activities related to lying, sitting, and walking positions. The first dataset consists of 562 features and the second dataset consists of five features. The data are collected using the accelerometer and gyroscope smartphone sensors. The results show that the proposed method provides 6.26%, 1.75%, 1.51%, and 4.40% better prediction accuracy (average over the two datasets) compared to GLM, DL, RF, and AdaBoost, respectively. We also analyze and compare the class-wise performance of the SVSL methods with that of DL, GLM, RF, and AdaBoost.},
DOI = {10.3390/a14080245}
}



@Article{rs13173458,
AUTHOR = {Yang, Chong and Zhang, Fan and Gao, Yunlong and Mao, Zhu and Li, Liang and Huang, Xianfeng},
TITLE = {Moving Car Recognition and Removal for 3D Urban Modelling Using Oblique Images},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {17},
ARTICLE-NUMBER = {3458},
URL = {https://www.mdpi.com/2072-4292/13/17/3458},
ISSN = {2072-4292},
ABSTRACT = {With the progress of photogrammetry and computer vision technology, three-dimensional (3D) reconstruction using aerial oblique images has been widely applied in urban modelling and smart city applications. However, state-of-the-art image-based automatic 3D reconstruction methods cannot effectively handle the unavoidable geometric deformation and incorrect texture mapping problems caused by moving cars in a city. This paper proposes a method to address this situation and prevent the influence of moving cars on 3D modelling by recognizing moving cars and combining the recognition results with a photogrammetric 3D modelling procedure. Through car detection using a deep learning method and multiview geometry constraints, we can analyse the state of a car’s movement and apply a proper preprocessing method to the geometrically model generation and texture mapping steps of 3D reconstruction pipelines. First, we apply the traditional Mask R-CNN object detection method to detect cars from oblique images. Then, a detected car and its corresponding image patch calculated by the geometry constraints in the other view images are used to identify the moving state of the car. Finally, the geometry and texture information corresponding to the moving car will be processed according to its moving state. Experiments on three different urban datasets demonstrate that the proposed method is effective in recognizing and removing moving cars and can repair the geometric deformation and error texture mapping problems caused by moving cars. In addition, the methods proposed in this paper can be applied to eliminate other moving objects in 3D modelling applications.},
DOI = {10.3390/rs13173458}
}



@Article{app11188394,
AUTHOR = {Lhoest, Lancelot and Lamrini, Mimoun and Vandendriessche, Jurgen and Wouters, Nick and da Silva, Bruno and Chkouri, Mohamed Yassin and Touhafi, Abdellah},
TITLE = {MosAIc: A Classical Machine Learning Multi-Classifier Based Approach against Deep Learning Classifiers for Embedded Sound Classification},
JOURNAL = {Applied Sciences},
VOLUME = {11},
YEAR = {2021},
NUMBER = {18},
ARTICLE-NUMBER = {8394},
URL = {https://www.mdpi.com/2076-3417/11/18/8394},
ISSN = {2076-3417},
ABSTRACT = {Environmental Sound Recognition has become a relevant application for smart cities. Such an application, however, demands the use of trained machine learning classifiers in order to categorize a limited set of audio categories. Although classical machine learning solutions have been proposed in the past, most of the latest solutions that have been proposed toward automated and accurate sound classification are based on a deep learning approach. Deep learning models tend to be large, which can be problematic when considering that sound classifiers often have to be embedded in resource constrained devices. In this paper, a classical machine learning based classifier called MosAIc, and a lighter Convolutional Neural Network model for environmental sound recognition, are proposed to directly compete in terms of accuracy with the latest deep learning solutions. Both approaches are evaluated in an embedded system in order to identify the key parameters when placing such applications on constrained devices. The experimental results show that classical machine learning classifiers can be combined to achieve similar results to deep learning models, and even outperform them in accuracy. The cost, however, is a larger classification time.},
DOI = {10.3390/app11188394}
}



@Article{smartcities4030065,
AUTHOR = {Munawar, Hafiz Suliman and Ullah, Fahim and Qayyum, Siddra and Heravi, Amirhossein},
TITLE = {Application of Deep Learning on UAV-Based Aerial Images for Flood Detection},
JOURNAL = {Smart Cities},
VOLUME = {4},
YEAR = {2021},
NUMBER = {3},
PAGES = {1220--1242},
URL = {https://www.mdpi.com/2624-6511/4/3/65},
ISSN = {2624-6511},
ABSTRACT = {Floods are one of the most fatal and devastating disasters, instigating an immense loss of human lives and damage to property, infrastructure, and agricultural lands. To cater to this, there is a need to develop and implement real-time flood management systems that could instantly detect flooded regions to initiate relief activities as early as possible. Current imaging systems, relying on satellites, have demonstrated low accuracy and delayed response, making them unreliable and impractical to be used in emergency responses to natural disasters such as flooding. This research employs Unmanned Aerial Vehicles (UAVs) to develop an automated imaging system that can identify inundated areas from aerial images. The Haar cascade classifier was explored in the case study to detect landmarks such as roads and buildings from the aerial images captured by UAVs and identify flooded areas. The extracted landmarks are added to the training dataset that is used to train a deep learning algorithm. Experimental results show that buildings and roads can be detected from the images with 91% and 94% accuracy, respectively. The overall accuracy of 91% is recorded in classifying flooded and non-flooded regions from the input case study images. The system has shown promising results on test images belonging to both pre- and post-flood classes. The flood relief and rescue workers can quickly locate flooded regions and rescue stranded people using this system. Such real-time flood inundation systems will help transform the disaster management systems in line with modern smart cities initiatives.},
DOI = {10.3390/smartcities4030065}
}



@Article{app112110037,
AUTHOR = {Kilicay-Ergin, Nil and Barb, Adrian S.},
TITLE = {Semantic Fusion with Deep Learning and Formal Ontologies for Evaluation of Policies and Initiatives in the Smart City Domain},
JOURNAL = {Applied Sciences},
VOLUME = {11},
YEAR = {2021},
NUMBER = {21},
ARTICLE-NUMBER = {10037},
URL = {https://www.mdpi.com/2076-3417/11/21/10037},
ISSN = {2076-3417},
ABSTRACT = {Decision makers and policy analysts at different administrative levels often lack a holistic view of the problem as there are semantic variations in policy documents due to domain-specific content. For example, smart city initiatives are derived from national and international initiatives which may influence the incentives for local participants, but local initiatives reflect the local contextual elements of the city. Balanced assessment of smart city initiatives should include a systemic evaluation of the initiatives at multiple levels including the city, the country in which the city resides as well as at international level. In this paper, a knowledge elicitation methodology is presented for multi-granularity evaluation of policies and initiatives. The methodology is demonstrated on the evaluation of smart city initiatives generated at different administrative levels. Semantic networks are constructed using formal ontologies and deep learning methods for automatic semantic evaluation of initiatives to abstract knowledge found in text. Three smart city initiatives published by different administrative levels including international, national, and city level are evaluated in terms of relevance, coherence, and alignment of multi-level smart city initiatives. Experiments and analysis ultimately provide a holistic view of the problem which is necessary for decision makers and policy analysts of smart cities.},
DOI = {10.3390/app112110037}
}



@Article{e23111457,
AUTHOR = {Drosouli, Ifigenia and Voulodimos, Athanasios and Miaoulis, Georgios and Mastorocostas, Paris and Ghazanfarpour, Djamchid},
TITLE = {Transportation Mode Detection Using an Optimized Long Short-Term Memory Model on Multimodal Sensor Data},
JOURNAL = {Entropy},
VOLUME = {23},
YEAR = {2021},
NUMBER = {11},
ARTICLE-NUMBER = {1457},
URL = {https://www.mdpi.com/1099-4300/23/11/1457},
PubMedID = {34828155},
ISSN = {1099-4300},
ABSTRACT = {The advancement of sensing technologies coupled with the rapid progress in big data analysis has ushered in a new era in intelligent transport and smart city applications. In this context, transportation mode detection (TMD) of mobile users is a field that has gained significant traction in recent years. In this paper, we present a deep learning approach for transportation mode detection using multimodal sensor data elicited from user smartphones. The approach is based on long short-term Memory networks and Bayesian optimization of their parameters. We conducted an extensive experimental evaluation of the proposed approach, which attains very high recognition rates, against a multitude of machine learning approaches, including state-of-the-art methods. We also discuss issues regarding feature correlation and the impact of dimensionality reduction.},
DOI = {10.3390/e23111457}
}



@Article{app112210735,
AUTHOR = {Domingo, Mari Carmen},
TITLE = {Deep Learning and Internet of Things for Beach Monitoring: An Experimental Study of Beach Attendance Prediction at Castelldefels Beach},
JOURNAL = {Applied Sciences},
VOLUME = {11},
YEAR = {2021},
NUMBER = {22},
ARTICLE-NUMBER = {10735},
URL = {https://www.mdpi.com/2076-3417/11/22/10735},
ISSN = {2076-3417},
ABSTRACT = {Smart seaside cities can fully exploit the capabilities brought by Internet of Things (IoT) and artificial intelligence to improve the efficiency of city services in traditional smart city applications: smart home, smart healthcare, smart transportation, smart surveillance, smart environment, cyber security, etc. However, smart coastal cities are characterized by their specific application domain, namely, beach monitoring. Beach attendance prediction is a beach monitoring application of particular importance for coastal managers to successfully plan beach services in terms of security, rescue, health and environmental assistance. In this paper, an experimental study that uses IoT data and deep learning to predict the number of beach visitors at Castelldefels beach (Barcelona, Spain) was developed. Images of Castelldefels beach were captured by a video monitoring system. An image recognition software was used to estimate beach attendance. A deep learning algorithm (deep neural network) to predict beach attendance was developed. The experimental results prove the feasibility of Deep Neural Networks (DNNs) for beach attendance prediction. For each beach, a classification of occupancy was estimated, depending on the number of beach visitors. The proposed model outperforms other machine learning models (decision tree, k-nearest neighbors, and random forest) and can successfully classify seven beach occupancy levels with the Mean Absolute Error (MAE), accuracy, precision, recall and F1-score of 0.03, 92.7%, 92.9%, 92.7%, and 92.7%, respectively.},
DOI = {10.3390/app112210735}
}



@Article{rs13234803,
AUTHOR = {Ojogbane, Sani Success and Mansor, Shattri and Kalantar, Bahareh and Khuzaimah, Zailani Bin and Shafri, Helmi Zulhaidi Mohd and Ueda, Naonori},
TITLE = {Automated Building Detection from Airborne LiDAR and Very High-Resolution Aerial Imagery with Deep Neural Network},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {23},
ARTICLE-NUMBER = {4803},
URL = {https://www.mdpi.com/2072-4292/13/23/4803},
ISSN = {2072-4292},
ABSTRACT = {The detection of buildings in the city is essential in several geospatial domains and for decision-making regarding intelligence for city planning, tax collection, project management, revenue generation, and smart cities, among other areas. In the past, the classical approach used for building detection was by using the imagery and it entailed human&ndash;computer interaction, which was a daunting proposition. To tackle this task, a novel network based on an end-to-end deep learning framework is proposed to detect and classify buildings features. The proposed CNN has three parallel stream channels: the first is the high-resolution aerial imagery, while the second stream is the digital surface model (DSM). The third was fixed on extracting deep features using the fusion of channel one and channel two, respectively. Furthermore, the channel has eight group convolution blocks of 2D convolution with three max-pooling layers. The proposed model&rsquo;s efficiency and dependability were tested on three different categories of complex urban building structures in the study area. Then, morphological operations were applied to the extracted building footprints to increase the uniformity of the building boundaries and produce improved building perimeters. Thus, our approach bridges a significant gap in detecting building objects in diverse environments; the overall accuracy (OA) and kappa coefficient of the proposed method are greater than 80% and 0.605, respectively. The findings support the proposed framework and methodologies&rsquo; efficacy and effectiveness at extracting buildings from complex environments.},
DOI = {10.3390/rs13234803}
}



@Article{fi13120306,
AUTHOR = {Dirir, Ahmed and Ignatious, Henry and Elsayed, Hesham and Khan, Manzoor and Adib, Mohammed and Mahmoud, Anas and Al-Gunaid, Moatasem},
TITLE = {An Advanced Deep Learning Approach for Multi-Object Counting in Urban Vehicular Environments},
JOURNAL = {Future Internet},
VOLUME = {13},
YEAR = {2021},
NUMBER = {12},
ARTICLE-NUMBER = {306},
URL = {https://www.mdpi.com/1999-5903/13/12/306},
ISSN = {1999-5903},
ABSTRACT = {Object counting is an active research area that gained more attention in the past few years. In smart cities, vehicle counting plays a crucial role in urban planning and management of the Intelligent Transportation Systems (ITS). Several approaches have been proposed in the literature to address this problem. However, the resulting detection accuracy is still not adequate. This paper proposes an efficient approach that uses deep learning concepts and correlation filters for multi-object counting and tracking. The performance of the proposed system is evaluated using a dataset consisting of 16 videos with different features to examine the impact of object density, image quality, angle of view, and speed of motion towards system accuracy. Performance evaluation exhibits promising results in normal traffic scenarios and adverse weather conditions. Moreover, the proposed approach outperforms the performance of two recent approaches from the literature.},
DOI = {10.3390/fi13120306}
}



@Article{rs13244974,
AUTHOR = {Feng, Dejun and Shen, Xingyu and Xie, Yakun and Liu, Yangge and Wang, Jian},
TITLE = {Efficient Occluded Road Extraction from High-Resolution Remote Sensing Imagery},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {24},
ARTICLE-NUMBER = {4974},
URL = {https://www.mdpi.com/2072-4292/13/24/4974},
ISSN = {2072-4292},
ABSTRACT = {Road extraction is important for road network renewal, intelligent transportation systems and smart cities. This paper proposes an effective method to improve road extraction accuracy and reconstruct the broken road lines caused by ground occlusion. Firstly, an attention mechanism-based convolution neural network is established to enhance feature extraction capability. By highlighting key areas and restraining interference features, the road extraction accuracy is improved. Secondly, for the common broken road problem in the extraction results, a heuristic method based on connected domain analysis is proposed to reconstruct the road. An experiment is carried out on a benchmark dataset to prove the effectiveness of this method, and the result is compared with that of several famous deep learning models including FCN8s, SegNet, U-Net and D-Linknet. The comparison shows that this model increases the IOU value and the F1 score by 3.35&ndash;12.8% and 2.41&ndash;9.8%, respectively. Additionally, the result proves the proposed method is effective at extracting roads from occluded areas.},
DOI = {10.3390/rs13244974}
}



@Article{electronics11010031,
AUTHOR = {Xu, Jianqiang and Zhao, Haoyu and Min, Weidong and Zou, Yi and Fu, Qiyan},
TITLE = {DGG: A Novel Framework for Crowd Gathering Detection},
JOURNAL = {Electronics},
VOLUME = {11},
YEAR = {2022},
NUMBER = {1},
ARTICLE-NUMBER = {31},
URL = {https://www.mdpi.com/2079-9292/11/1/31},
ISSN = {2079-9292},
ABSTRACT = {Crowd gathering detection plays an important role in security supervision of public areas. Existing image-processing-based methods are not robust for complex scenes, and deep-learning-based methods for gathering detection mainly focus on the design of the network, which ignores the inner feature of the crowd gathering action. To alleviate such problems, this work proposes a novel framework Detection of Group Gathering (DGG) based on the crowd counting method using deep learning approaches and statistics to detect crowd gathering. The DGG mainly contains three parts, i.e., Detecting Candidate Frame of Gathering (DCFG), Gathering Area Detection (GAD), and Gathering Judgement (GJ). The DCFG is proposed to find the frame index in a video that has the maximum people number based on the crowd counting method. This frame means that the crowd has gathered and the specific gathering area will be detected next. The GAD detects the local area that has the maximum crowd density in a frame with a slide search box. The local area contains the inner feature of the gathering action and represents that the crowd gathering in this local area, which is denoted by grid coordinates in a video frame. Based on the detected results of the DCFG and the GAD, the GJ is proposed to analyze the statistical relationship between the local area and the global area to find the stable pattern for the crowd gathering action. Experiments based on benchmarks show that the proposed DGG has a robust representation of the gathering feature and a high detection accuracy. There is the potential that the DGG can be used in social security and smart city domains.},
DOI = {10.3390/electronics11010031}
}



@Article{electronics11010073,
AUTHOR = {Avazov, Kuldoshbay and Mukhiddinov, Mukhriddin and Makhmudov, Fazliddin and Cho, Young Im},
TITLE = {Fire Detection Method in Smart City Environments Using a Deep-Learning-Based Approach},
JOURNAL = {Electronics},
VOLUME = {11},
YEAR = {2022},
NUMBER = {1},
ARTICLE-NUMBER = {73},
URL = {https://www.mdpi.com/2079-9292/11/1/73},
ISSN = {2079-9292},
ABSTRACT = {In the construction of new smart cities, traditional fire-detection systems can be replaced with vision-based systems to establish fire safety in society using emerging technologies, such as digital cameras, computer vision, artificial intelligence, and deep learning. In this study, we developed a fire detector that accurately detects even small sparks and sounds an alarm within 8 s of a fire outbreak. A novel convolutional neural network was developed to detect fire regions using an enhanced You Only Look Once (YOLO) v4network. Based on the improved YOLOv4 algorithm, we adapted the network to operate on the Banana Pi M3 board using only three layers. Initially, we examined the originalYOLOv4 approach to determine the accuracy of predictions of candidate fire regions. However, the anticipated results were not observed after several experiments involving this approach to detect fire accidents. We improved the traditional YOLOv4 network by increasing the size of the training dataset based on data augmentation techniques for the real-time monitoring of fire disasters. By modifying the network structure through automatic color augmentation, reducing parameters, etc., the proposed method successfully detected and notified the incidence of disastrous fires with a high speed and accuracy in different weather environments&mdash;sunny or cloudy, day or night. Experimental results revealed that the proposed method can be used successfully for the protection of smart cities and in monitoring fires in urban areas. Finally, we compared the performance of our method with that of recently reported fire-detection approaches employing widely used performance matrices to test the fire classification results achieved.},
DOI = {10.3390/electronics11010073}
}



@Article{e24010058,
AUTHOR = {Balicki, Jerzy},
TITLE = {Many-Objective Quantum-Inspired Particle Swarm Optimization Algorithm for Placement of Virtual Machines in Smart Computing Cloud},
JOURNAL = {Entropy},
VOLUME = {24},
YEAR = {2022},
NUMBER = {1},
ARTICLE-NUMBER = {58},
URL = {https://www.mdpi.com/1099-4300/24/1/58},
PubMedID = {35052084},
ISSN = {1099-4300},
ABSTRACT = {Particle swarm optimization algorithm (PSO) is an effective metaheuristic that can determine Pareto-optimal solutions. We propose an extended PSO by introducing quantum gates in order to ensure the diversity of particle populations that are looking for efficient alternatives. The quality of solutions was verified in the issue of assignment of resources in the computing cloud to improve the live migration of virtual machines. We consider the multi-criteria optimization problem of deep learning-based models embedded into virtual machines. Computing clouds with deep learning agents can support several areas of education, smart city or economy. Because deep learning agents require lots of computer resources, seven criteria are studied such as electric power of hosts, reliability of cloud, CPU workload of the bottleneck host, communication capacity of the critical node, a free RAM capacity of the most loaded memory, a free disc memory capacity of the most busy storage, and overall computer costs. Quantum gates modify an accepted position for the current location of a particle. To verify the above concept, various simulations have been carried out on the laboratory cloud based on the OpenStack platform. Numerical experiments have confirmed that multi-objective quantum-inspired particle swarm optimization algorithm provides better solutions than the other metaheuristics.},
DOI = {10.3390/e24010058}
}



@Article{s22030921,
AUTHOR = {Park, Se-Ho and Yu, Saet-Byeol and Kim, Jeong-Ah and Yoon, Hyoseok},
TITLE = {An All-in-One Vehicle Type and License Plate Recognition System Using YOLOv4},
JOURNAL = {Sensors},
VOLUME = {22},
YEAR = {2022},
NUMBER = {3},
ARTICLE-NUMBER = {921},
URL = {https://www.mdpi.com/1424-8220/22/3/921},
PubMedID = {35161666},
ISSN = {1424-8220},
ABSTRACT = {In smart surveillance and urban mobility applications, camera-equipped embedded platforms with deep learning technology have demonstrated applicability and effectiveness in identifying various targets. These use cases can be found in a variety of contexts and locations. It is critical to collect relevant data from the location where the application will be deployed. In this paper, we propose an integrated vehicle type and license plate recognition system using YOLOv4, which consists of vehicle type detection, license plate detection, and license plate character detection to better support the context of Korean vehicles in multilane highway and urban environments. Using our dataset of one to four multilane images, our system detected six vehicle classes and license plates with mAP of 98.0%, 94.0%, 97.1%, and 84.6%, respectively. On our dataset and a publicly available open dataset, our system demonstrated mAP of 99.3% and 99.4% for the detected license plates, respectively. From 4K high-resolution images, our system was able to detect minuscule license plates as small as 100 pixels wide. We believe that our system can be used in densely populated regions to address the high demands for enhanced visual sensitivity in smart cities and Internet-of-Things.},
DOI = {10.3390/s22030921}
}



@Article{app12041863,
AUTHOR = {Al-Taleb, Najla and Saqib, Nazar Abbas},
TITLE = {Towards a Hybrid Machine Learning Model for Intelligent Cyber Threat Identification in Smart City Environments},
JOURNAL = {Applied Sciences},
VOLUME = {12},
YEAR = {2022},
NUMBER = {4},
ARTICLE-NUMBER = {1863},
URL = {https://www.mdpi.com/2076-3417/12/4/1863},
ISSN = {2076-3417},
ABSTRACT = {The concept of a smart city requires the integration of information and communication technologies and devices over a network for the better provision of services to citizens. As a result, the quality of living is improved by continuous analyses of data to improve service delivery by governments and other organizations. Due to the presence of extensive devices and data flow over networks, the probability of cyber attacks and intrusion detection has increased. The monitoring of this huge amount of data traffic is very difficult, though machine learning algorithms have huge potential to support this task. In this study, we compared different machine learning models used for cyber threat classification. Our comparison was focused on the analyzed cyber threats, algorithms, and performance of these models. We have identified that real-time classification, accuracy, and false-positive rates are still the major issues in the performance of existing models. Accordingly, we have proposed a hybrid deep learning (DL) model for cyber threat intelligence (CTI) to improve threat classification performance. Our model was based on a convolutional neural network (CNN) and quasi-recurrent neural network (QRNN). The use of QRNN not only resulted in improved accuracy but also enabled real-time classification. The model was tested on BoT-IoT and TON_IoT datasets, and the results showed that the proposed model outperformed the other models. Due to this improved performance, we emphasize that the application of this model in the real-time environment of a smart system network will help in reducing threats in a reasonable time.},
DOI = {10.3390/app12041863}
}



@Article{app12052281,
AUTHOR = {Alsubaei, Faisal S. and Al-Wesabi, Fahd N. and Hilal, Anwer Mustafa},
TITLE = {Deep Learning-Based Small Object Detection and Classification Model for Garbage Waste Management in Smart Cities and IoT Environment},
JOURNAL = {Applied Sciences},
VOLUME = {12},
YEAR = {2022},
NUMBER = {5},
ARTICLE-NUMBER = {2281},
URL = {https://www.mdpi.com/2076-3417/12/5/2281},
ISSN = {2076-3417},
ABSTRACT = {In recent years, object detection has gained significant interest and is considered a challenging problem in computer vision. Object detection is mainly employed for several applications, such as instance segmentation, object tracking, image captioning, healthcare, etc. Recent studies have reported that deep learning (DL) models can be employed for effective object detection compared to traditional methods. The rapid urbanization of smart cities necessitates the design of intelligent and automated waste management techniques for effective recycling of waste. In this view, this study develops a novel deep learning-based small object detection and classification model for garbage waste management (DLSODC-GWM) technique. The proposed DLSODC-GWM technique mainly focuses on detecting and classifying small garbage waste objects to assist intelligent waste management systems. The DLSODC-GWM technique follows two major processes, namely, object detection and classification. For object detection, an arithmetic optimization algorithm (AOA) with an improved RefineDet (IRD) model is applied, where the hyperparameters of the IRD model are optimally chosen by the AOA. Secondly, the functional link neural network (FLNN) technique was applied for the classification of waste objects into multiple classes. The design of IRD for waste classification and AOA-based hyperparameter tuning demonstrates the novelty of the work. The performance validation of the DLSODC-GWM technique is performed using benchmark datasets, and the experimental results show the promising performance of the DLSODC-GWM method on existing approaches with a maximum accuy of 98.61%.},
DOI = {10.3390/app12052281}
}



@Article{electronics11060861,
AUTHOR = {Han, Shi-Yuan and Sun, Qi-Wei and Zhao, Qiang and Han, Rui-Zhi and Chen, Yue-Hui},
TITLE = {Traffic Forecasting Based on Integration of Adaptive Subgraph Reformulation and Spatio-Temporal Deep Learning Model},
JOURNAL = {Electronics},
VOLUME = {11},
YEAR = {2022},
NUMBER = {6},
ARTICLE-NUMBER = {861},
URL = {https://www.mdpi.com/2079-9292/11/6/861},
ISSN = {2079-9292},
ABSTRACT = {Traffic forecasting provides the foundational guidance for many typical applications in the smart city management, such as urban traffic control, congestion avoidance, and navigation guidance. Many researchers have focused on the spatio-temporal correlations under fixed topology structure in traffic network to improve the traffic forecasting accuracy. Despite their advantages, the existing approaches are not completely discussed that the association relationship among traffic network nodes are not invariable under different traffic conditions. In this paper, a novel traffic forecasting framework is proposed by integrating the dynamic association of traffic nodes with the spatio-temporal deep learning model. To be specific, an adaptive subgraph reformulation algorithm is designed first based on the specific forecasting interval to reduce the interference of irrelevant spatio-temporal information. After that, by enhancing the attention mechanism with the generative decoder, a spatio-temporal deep learning model with only one forward operation is proposed to avoid the degradation of accuracy in the long-term prediction, in which the spatio-temporal information and the external factors (such as weather and holiday) are fused together to be as an input vector. Based on the reformulated subgraph constructed of traffic nodes with closer spatio-temporal correlation, experiments show that the proposed framework consistently outperforms other GNN (Graph Neural Network)-based state-of-the-art baselines for various forecasting intervals on a real-world dataset.},
DOI = {10.3390/electronics11060861}
}



@Article{electronics11060879,
AUTHOR = {Tian, Kang and Chai, Haojun and Liu, Yameng and Liu, Boyang},
TITLE = {Edge Intelligence Empowered Dynamic Offloading and Resource Management of MEC for Smart City Internet of Things},
JOURNAL = {Electronics},
VOLUME = {11},
YEAR = {2022},
NUMBER = {6},
ARTICLE-NUMBER = {879},
URL = {https://www.mdpi.com/2079-9292/11/6/879},
ISSN = {2079-9292},
ABSTRACT = {Internet of Things (IoT) has emerged as an enabling platform for smart cities. In this paper, the IoT devices&rsquo; offloading decisions, CPU frequencies and transmit powers joint optimization problem is investigated for a multi-mobile edge computing (MEC) server and multi-IoT device cellular network. An optimization problem is formulated to minimize the weighted sum of the computing pressure on the primary MEC server (PMS), the sum of energy consumption of the network, and the task dropping cost. The formulated problem is a mixed integer nonlinear program (MINLP) problem, which is difficult to solve since it contains strongly coupled constraints and discrete integer variables. Taking the dynamic of the environment into account, a deep reinforcement learning (DRL)-based optimization algorithm is developed to solve the nonconvex problem. The simulation results demonstrate the correctness and the effectiveness of the proposed algorithm.},
DOI = {10.3390/electronics11060879}
}



@Article{electronics11060904,
AUTHOR = {Kumar, Tamilarasan Ananth and Rajmohan, Rajendrane and Pavithra, Muthu and Ajagbe, Sunday Adeola and Hodhod, Rania and Gaber, Tarek},
TITLE = {Automatic Face Mask Detection System in Public Transportation in Smart Cities Using IoT and Deep Learning},
JOURNAL = {Electronics},
VOLUME = {11},
YEAR = {2022},
NUMBER = {6},
ARTICLE-NUMBER = {904},
URL = {https://www.mdpi.com/2079-9292/11/6/904},
ISSN = {2079-9292},
ABSTRACT = {The World Health Organization (WHO) has stated that the spread of the coronavirus (COVID-19) is on a global scale and that wearing a face mask at work is the only effective way to avoid becoming infected with the virus. The pandemic made governments worldwide stay under lock-downs to prevent virus transmissions. Reports show that wearing face masks would reduce the risk of transmission. With the rise in population in cities, there is a greater need for efficient city management in today&rsquo;s world for reducing the impact of COVID-19 disease. For smart cities to prosper, significant improvements to occur in public transportation, roads, businesses, houses, city streets, and other facets of city life will have to be developed. The current public bus transportation system, such as it is, should be expanded with artificial intelligence. The autonomous mask detection and alert system are needed to find whether the person is wearing a face mask or not. This article presents a novel IoT-based face mask detection system in public transportation, especially buses. This system would collect real-time data via facial recognition. The main objective of the paper is to detect the presence of face masks in real-time video stream by utilizing deep learning, machine learning, and image processing techniques. To achieve this objective, a hybrid deep and machine learning model was designed and implemented. The model was evaluated using a new dataset in addition to public datasets. The results showed that the transformation of Convolution Neural Network (CNN) classifier has better performance over the Deep Neural Network (DNN) classifier; it has almost complete face-identification capabilities with respect to people&rsquo;s presence in the case where they are wearing masks, with an error rate of only 1.1%. Overall, compared with the standard models, AlexNet, Mobinet, and You Only Look Once (YOLO), the proposed model showed a better performance. Moreover, the experiments showed that the proposed model can detect faces and masks accurately with low inference time and memory, thus meeting the IoT limited resources.},
DOI = {10.3390/electronics11060904}
}





@Article{infrastructures4030052,
AUTHOR = {Serrano, Will},
TITLE = {Deep Reinforcement Learning Algorithms in Intelligent Infrastructure},
JOURNAL = {Infrastructures},
VOLUME = {4},
YEAR = {2019},
NUMBER = {3},
ARTICLE-NUMBER = {52},
URL = {https://www.mdpi.com/2412-3811/4/3/52},
ISSN = {2412-3811},
ABSTRACT = {Intelligent infrastructure, including smart cities and intelligent buildings, must learn and adapt to the variable needs and requirements of users, owners and operators in order to be future proof and to provide a return on investment based on Operational Expenditure (OPEX) and Capital Expenditure (CAPEX). To address this challenge, this article presents a biological algorithm based on neural networks and deep reinforcement learning that enables infrastructure to be intelligent by making predictions about its different variables. In addition, the proposed method makes decisions based on real time data. Intelligent infrastructure must be able to proactively monitor, protect and repair itself: this includes independent components and assets working the same way any autonomous biological organisms would. Neurons of artificial neural networks are associated with a prediction or decision layer based on a deep reinforcement learning algorithm that takes into consideration all of its previous learning. The proposed method was validated against an intelligent infrastructure dataset with outstanding results: the intelligent infrastructure was able to learn, predict and adapt to its variables, and components could make relevant decisions autonomously, emulating a living biological organism in which data flow exhaustively.},
DOI = {10.3390/infrastructures4030052}
}



@Article{info11020101,
AUTHOR = {Han, Junying and Zhang, Zhenyu and Wu, Xiaohong},
TITLE = {A Real-World-Oriented Multi-Task Allocation Approach Based on Multi-Agent Reinforcement Learning in Mobile Crowd Sensing},
JOURNAL = {Information},
VOLUME = {11},
YEAR = {2020},
NUMBER = {2},
ARTICLE-NUMBER = {101},
URL = {https://www.mdpi.com/2078-2489/11/2/101},
ISSN = {2078-2489},
ABSTRACT = {Mobile crowd sensing is an innovative and promising paradigm in the construction and perception of smart cities. However, multi-task allocation in real-world scenarios is a huge challenge. There are many unexpected factors in the execution of mobile crowd sensing tasks, such as traffic jams or accidents, that make participants unable to reach the target area. In addition, participants may quit halfway due to equipment failure, network paralysis, dishonest behavior, etc. Previous task allocation approaches mainly ignored some of the heterogeneity of participants and tasks in the real-world scenarios. This paper proposes a real-world-oriented multi-task allocation approach based on multi-agent reinforcement learning. Firstly, under the premise of fully considering the heterogeneity of participants and tasks, the approach enables participants as agents to learn multiple solutions independently, based on modified soft Q-learning. Secondly, two cooperation mechanisms are proposed for obtaining the stable joint action, which can minimize the total sensing time while meeting the sensing quality constraint, which optimizes the sensing quality of mobile crowd sensing (MCS) tasks. Experiments verify that the approach can effectively reduce the impact of emergencies on the efficiency of large-scale MCS platform and outperform baselines based on a real-world dataset under different experiment settings.},
DOI = {10.3390/info11020101}
}



@Article{s20154291,
AUTHOR = {Wu, Qiang and Wu, Jianqing and Shen, Jun and Yong, Binbin and Zhou, Qingguo},
TITLE = {An Edge Based Multi-Agent Auto Communication Method for Traffic Light Control},
JOURNAL = {Sensors},
VOLUME = {20},
YEAR = {2020},
NUMBER = {15},
ARTICLE-NUMBER = {4291},
URL = {https://www.mdpi.com/1424-8220/20/15/4291},
ISSN = {1424-8220},
ABSTRACT = {With smart city infrastructures growing, the Internet of Things (IoT) has been widely used in the intelligent transportation systems (ITS). The traditional adaptive traffic signal control method based on reinforcement learning (RL) has expanded from one intersection to multiple intersections. In this paper, we propose a multi-agent auto communication (MAAC) algorithm, which is an innovative adaptive global traffic light control method based on multi-agent reinforcement learning (MARL) and an auto communication protocol in edge computing architecture. The MAAC algorithm combines multi-agent auto communication protocol with MARL, allowing an agent to communicate the learned strategies with others for achieving global optimization in traffic signal control. In addition, we present a practicable edge computing architecture for industrial deployment on IoT, considering the limitations of the capabilities of network transmission bandwidth. We demonstrate that our algorithm outperforms other methods over 17% in experiments in a real traffic simulation environment.},
DOI = {10.3390/s20154291}
}



@Article{s20216019,
AUTHOR = {Lozano Domínguez, José Manuel and Al-Tam, Faroq and Mateo Sanguino, Tomás de J. and Correia, Noélia},
TITLE = {Analysis of Machine Learning Techniques Applied to Sensory Detection of Vehicles in Intelligent Crosswalks},
JOURNAL = {Sensors},
VOLUME = {20},
YEAR = {2020},
NUMBER = {21},
ARTICLE-NUMBER = {6019},
URL = {https://www.mdpi.com/1424-8220/20/21/6019},
ISSN = {1424-8220},
ABSTRACT = {Improving road safety through artificial intelligence-based systems is now crucial turning smart cities into a reality. Under this highly relevant and extensive heading, an approach is proposed to improve vehicle detection in smart crosswalks using machine learning models. Contrarily to classic fuzzy classifiers, machine learning models do not require the readjustment of labels that depend on the location of the system and the road conditions. Several machine learning models were trained and tested using real traffic data taken from urban scenarios in both Portugal and Spain. These include random forest, time-series forecasting, multi-layer perceptron, support vector machine, and logistic regression models. A deep reinforcement learning agent, based on a state-of-the-art double-deep recurrent Q-network, is also designed and compared with the machine learning models just mentioned. Results show that the machine learning models can efficiently replace the classic fuzzy classifier.},
DOI = {10.3390/s20216019}
}



@Article{s21093261,
AUTHOR = {Sultan, Salman Md and Waleed, Muhammad and Pyun, Jae-Young and Um, Tai-Won},
TITLE = {Energy Conservation for Internet of Things Tracking Applications Using Deep Reinforcement Learning},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {9},
ARTICLE-NUMBER = {3261},
URL = {https://www.mdpi.com/1424-8220/21/9/3261},
PubMedID = {34066766},
ISSN = {1424-8220},
ABSTRACT = {The Internet of Things (IoT)-based target tracking system is required for applications such as smart farm, smart factory, and smart city where many sensor devices are jointly connected to collect the moving target positions. Each sensor device continuously runs on battery-operated power, consuming energy while perceiving target information in a particular environment. To reduce sensor device energy consumption in real-time IoT tracking applications, many traditional methods such as clustering, information-driven, and other approaches have previously been utilized to select the best sensor. However, applying machine learning methods, particularly deep reinforcement learning (Deep RL), to address the problem of sensor selection in tracking applications is quite demanding because of the limited sensor node battery lifetime. In this study, we proposed a long short-term memory deep Q-network (DQN)-based Deep RL target tracking model to overcome the problem of energy consumption in IoT target applications. The proposed method is utilized to select the energy-efficient best sensor while tracking the target. The best sensor is defined by the minimum distance function (i.e., derived as the state), which leads to lower energy consumption. The simulation results show favorable features in terms of the best sensor selection and energy consumption.},
DOI = {10.3390/s21093261}
}



@Article{app12010425,
AUTHOR = {Joo, Hyunjin and Lim, Yujin},
TITLE = {Intelligent Traffic Signal Phase Distribution System Using Deep Q-Network},
JOURNAL = {Applied Sciences},
VOLUME = {12},
YEAR = {2022},
NUMBER = {1},
ARTICLE-NUMBER = {425},
URL = {https://www.mdpi.com/2076-3417/12/1/425},
ISSN = {2076-3417},
ABSTRACT = {Traffic congestion is a worsening problem owing to an increase in traffic volume. Traffic congestion increases the driving time and wastes fuel, generating large amounts of fumes and accelerating environmental pollution. Therefore, traffic congestion is an important problem that needs to be addressed. Smart transportation systems manage various traffic problems by utilizing the infrastructure and networks available in smart cities. The traffic signal control system used in smart transportation analyzes and controls traffic flow in real time. Thus, traffic congestion can be effectively alleviated. We conducted preliminary experiments to analyze the effects of throughput, queue length, and waiting time on the system performance according to the signal allocation techniques. Based on the results of the preliminary experiment, the standard deviation of the queue length is interpreted as an important factor in an order allocation technique. A smart traffic signal control system using a deep Q-network, which is a type of reinforcement learning, is proposed. The proposed algorithm determines the optimal order of a green signal. The goal of the proposed algorithm is to maximize the throughput and efficiently distribute the signals by considering the throughput and standard deviation of the queue length as reward parameters.},
DOI = {10.3390/app12010425}
}



@Article{smartcities5010011,
AUTHOR = {Dey, Somdip and Saha, Suman and Singh, Amit Kumar and McDonald-Maier, Klaus},
TITLE = {SmartNoshWaste: Using Blockchain, Machine Learning, Cloud Computing and QR Code to Reduce Food Waste in Decentralized Web 3.0 Enabled Smart Cities},
JOURNAL = {Smart Cities},
VOLUME = {5},
YEAR = {2022},
NUMBER = {1},
PAGES = {162--176},
URL = {https://www.mdpi.com/2624-6511/5/1/11},
ISSN = {2624-6511},
ABSTRACT = {Food waste is an important social and environmental issue that the current society faces, where one third of the total food produced is wasted or lost every year while more than 820 million people around the world do not have access to adequate food. However, as we move towards a decentralized Web 3.0 enabled smart city, we can utilize cutting edge technologies such as blockchain, artificial intelligence, cloud computing and many more to reduce food waste in different phases of the supply chain. In this paper, we propose SmartNoshWaste&mdash;a blockchain based multi-layered framework utilizing cloud computing, QR code and reinforcement learning to reduce food waste. We also evaluate SmartNoshWaste on real world food data collected from the nosh app to show the efficacy of the proposed framework and we are able to reduce food waste by 9.46% in comparison to the originally collected food data based on the experimental evaluation.},
DOI = {10.3390/smartcities5010011}
}



@Article{electronics11060879,
AUTHOR = {Tian, Kang and Chai, Haojun and Liu, Yameng and Liu, Boyang},
TITLE = {Edge Intelligence Empowered Dynamic Offloading and Resource Management of MEC for Smart City Internet of Things},
JOURNAL = {Electronics},
VOLUME = {11},
YEAR = {2022},
NUMBER = {6},
ARTICLE-NUMBER = {879},
URL = {https://www.mdpi.com/2079-9292/11/6/879},
ISSN = {2079-9292},
ABSTRACT = {Internet of Things (IoT) has emerged as an enabling platform for smart cities. In this paper, the IoT devices&rsquo; offloading decisions, CPU frequencies and transmit powers joint optimization problem is investigated for a multi-mobile edge computing (MEC) server and multi-IoT device cellular network. An optimization problem is formulated to minimize the weighted sum of the computing pressure on the primary MEC server (PMS), the sum of energy consumption of the network, and the task dropping cost. The formulated problem is a mixed integer nonlinear program (MINLP) problem, which is difficult to solve since it contains strongly coupled constraints and discrete integer variables. Taking the dynamic of the environment into account, a deep reinforcement learning (DRL)-based optimization algorithm is developed to solve the nonconvex problem. The simulation results demonstrate the correctness and the effectiveness of the proposed algorithm.},
DOI = {10.3390/electronics11060879}
}




@article{LIANG2020102414,
title = {A research on remote fracturing monitoring and decision-making method supporting smart city},
journal = {Sustainable Cities and Society},
volume = {62},
pages = {102414},
year = {2020},
issn = {2210-6707},
doi = {https://doi.org/10.1016/j.scs.2020.102414},
url = {https://www.sciencedirect.com/science/article/pii/S2210670720306351},
author = {Haibo Liang and Aohang Xian and Min Mao and Pengbo Ni and Haosheng Wu},
keywords = {Hydraulic fracturing, Machine learning, Remote monitoring, Cluster, Fracturing fluid, Data mining, Smart city},
abstract = {Based on the investigation of the development of fracturing monitoring at home and abroad, this paper studies the mechanism of fracturing fluid injection and fractures monitoring, and puts forward a remote fracturing monitoring and decision-making method suitable for conventional wells. Firstly, combined with the dynamic monitoring model of fracturing fluid, many parameters are optimized and analyzed. The velocity monitoring of fracturing fluid is realized by constructing the average velocity formula of fracturing fluid, and its approximate position is calculated. After analyzing the limitations of traditional models, the monitoring model of the unsteady friction resistance is established by summarizing the existing models and fitting the weight function by the gradient descent method. In this paper, the relationship between the pressure-time curve and crack is studied. Then the pressure curve is optimized by OPTICS algorithm improved by the adjacency list, and conduct the unsupervised learning about the stress data. By using computers, the pressure data can be clustered automatically. The classification is rapid and more accurate than the manual classification, which improves the intelligence and accuracy of data analysis, and realizes more accurate and intuitive monitoring of fractures than before. At the same time, the relationship between the city and well sites is analyzed in this paper. Combined with WITS acquisition and industrial Internet technology, the real-time data of the well site is remotely transmitted to the headquarters, which makes it possible to monitor fracturing in the city far from the well site, so that the combination of city and industry is no longer restricted by geographical location. It is beneficial to give full play to the role of industry in promoting urban development and promote the sustainable development of the city. Surface monitoring instruments have been fully utilized by using this method. This method of remote monitoring of fracturing promotes the development of intelligent city and provides a method for builders to ensure the construction safe and to make abnormal early warning of on-site fracturing.}
}
@article{AHMED2021107226,
title = {IoT-based crowd monitoring system: Using SSD with transfer learning},
journal = {Computers & Electrical Engineering},
volume = {93},
pages = {107226},
year = {2021},
issn = {0045-7906},
doi = {https://doi.org/10.1016/j.compeleceng.2021.107226},
url = {https://www.sciencedirect.com/science/article/pii/S0045790621002147},
author = {Imran Ahmed and Misbah Ahmad and Awais Ahmad and Gwanggil Jeon},
keywords = {Internet of Things, Crowd monitoring, People detection, People counting, Overhead view, Deep learning},
abstract = {The constantly developing urbanization and the emergence of smart cities require better security surveillance and crowd monitoring systems. The growing availability of the Internet of Things (IoT) devices in public and private organizations also provide intelligent and secure surveillance solutions for real-time monitoring in public spaces. This article introduces an IoT-based crowd surveillance system that uses a deep learning model to detect and count people using an overhead view perspective. The Single Shot Multibox Detector (SSD) model with Mobilenetv2 as the basic network is used for the detection of people. The detection model’s accuracy is enhanced with a transfer learning approach. Two virtual lines are defined to count how many people are leaving and entering the scene. In order to assess performance, experiments are performed using different video clips. Results indicate that transfer learning increases the overall detection performance of the system with an accuracy of 95%.}
}
@article{SARANYA20201251,
title = {Performance Analysis of Machine Learning Algorithms in Intrusion Detection System: A Review},
journal = {Procedia Computer Science},
volume = {171},
pages = {1251-1260},
year = {2020},
note = {Third International Conference on Computing and Network Communications (CoCoNet'19)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2020.04.133},
url = {https://www.sciencedirect.com/science/article/pii/S1877050920311121},
author = {T. Saranya and S. Sridevi and C. Deisy and Tran Duc Chung and M.K.A.Ahamed Khan},
keywords = {Intrusion Detection System(IDS), Machine Learning(ML) Algorithm, Classification, Random Forest, Support Vector Machine, Accuracy},
abstract = {The rapid growth of technologies not only formulates life easier but also exposes a lot of security issues. With the advancement of the Internet over years, the number of attacks over the Internet has been increased. Intrusion Detection System (IDS) is one of the supportive layers applicable to information security. IDS provide a salubrious environment for business and keeps away from suspicious network activities. Recently, Machine Learning (ML) algorithms are applied in IDS in order to identify and classify the security threats. This paper explores the comparative study of various ML algorithms used in IDS for several applications such as fog computing, Internet of Things (IoT), big data, smart city, and 5G network. In addition, this work also aims for classifying the intrusions using ML algorithms like Linear Discriminant Analysis (LDA), Classification and Regression Trees (CART) and Random Forest. The work was tested with the KDD-CUP dataset and their efficiency was measured and also compared along with the latest researches.}
}
@article{ALIZADEH2019102400,
title = {Capturing citizen voice online: Enabling smart participatory local government},
journal = {Cities},
volume = {95},
pages = {102400},
year = {2019},
issn = {0264-2751},
doi = {https://doi.org/10.1016/j.cities.2019.102400},
url = {https://www.sciencedirect.com/science/article/pii/S0264275118315981},
author = {Tooran Alizadeh and Somwrita Sarkar and Sandy Burgoyne},
keywords = {Citizen engagement, Social media, Twitter, Sentiment analysis, Topic/cluster analysis, Crowdsourcing},
abstract = {Social media and online communication have changed the way citizens engage in all aspects of lives from shopping and education, to how communities are planned and developed. It is no longer one-way or two- way communication. Instead, via networked all-to-all communication channels, our citizens engage on urban issues in a complex and more connected way than ever before. So government needs new ways to listen to its citizens. The paper comprises three components. Firstly, we build on the growing discussions in the literature focused on smart cities, on one hand, and social media research, on the other, to capture the diversity of citizen voices and better inform decision-making. Secondly, with the support of the Australian Federal Government and in collaboration with the local government partners, we collect citizen voices from Twitter on selected urban projects. Thirdly, we present preliminary findings in terms of quantity and quality of publicly available online data representing citizen concerns on the urban matters. By analyzing the sentiments of the citizen voices captured online, clustering them into topic areas, and then reevaluating citizen's sentiments within each cluster, we elaborate the scope and value of technologically-enabled opportunities in terms of enabling participatory local government decision making processes.}
}
@article{LU202034,
title = {LSTM variants meet graph neural networks for road speed prediction},
journal = {Neurocomputing},
volume = {400},
pages = {34-45},
year = {2020},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2020.03.031},
url = {https://www.sciencedirect.com/science/article/pii/S0925231220303775},
author = {Zhilong Lu and Weifeng Lv and Yabin Cao and Zhipu Xie and Hao Peng and Bowen Du},
keywords = {Neural network, LSTM, LSTM Variant, GNN, Road speed prediction},
abstract = {Traffic flow prediction is a fundamental issue in smart cities and plays an important role in urban traffic planning and management. An accurate predictive model can help individuals make reliable travel plans and choose optimal routes while efficiently helping administrators maintain traffic order. Road speed prediction, which is a sub-task of traffic flow forecasting, is challenging due to the complicated spatial dependencies characterizing road networks and dynamic temporal traffic patterns. Given the power of recurrent neural networks (RNNs) in learning temporal relations and graph neural networks (GNNs) in integrating graph-structured and node-attributed features, in this paper, we design a novel graph LSTM (GLSTM) framework to capture spatial-temporal representations in road speed forecasting. More specifically, we first present a temporal directed attributed graph to model complex traffic flow. Then, to take advantage of the structure properties and graph features, we employ a message-passing mechanism for feature aggregation and updating. Finally, we further implement several variants of LSTMs with a GN block under the encoder-decoder framework to model spatial-temporal dependencies. The experiments show that our proposed model is able to fully utilize both the road latent graph structure and traffic speed to forecast the road state during future periods. The results on two real-world datasets show that our GLSTM can outperform state-of-the-art baseline methods by up to 32.8% in terms of MAE, 43.2% in terms of MAPE and 23.1% in terms of RMSE.}
}
@article{CHEN202075,
title = {PR-KELM: Icing level prediction for transmission lines in smart grid},
journal = {Future Generation Computer Systems},
volume = {102},
pages = {75-83},
year = {2020},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2019.08.002},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X17323993},
author = {Yunliang Chen and Junqing Fan and Ze Deng and Bo Du and Xiaohui Huang and Qirui Gui},
keywords = {Smart city, Smart grid, Icing level prediction, Feature extraction, Image processing},
abstract = {As a hot spot, the diffusion of the smart city has been more and more popular and widespread all over the world. The concept of smart city has supported a higher quality of urban spaces and a better offering of public services. Smart grid is an important component and the energy supply of smart city. The health of the smart grid will directly affect the health of the smart city. Efficient and accurate prediction about icing level of transmission lines provides a reliable basis for anti-icing and deicing of power grids. The prediction can not only significantly enhance the reliability, safety and stability of transmission networks, but also timely provide the state monitoring of ice on wires to the workers to make proper decisions and to prevent freezing disasters so as to effectively protect people’s safety and build a stable and friendly society. To reduce catastrophic damages caused by the iced transmission lines of the grid, this paper proposed a novel hybrid model called PR-KELM, an integration of Principal Component Analysis, ReliefF and Kernel based ELM (Extreme Learning Machine) method to predict the icing level of transmission lines. This hybrid model covered two stages including: 1) structured and unstructured data feature extraction by local binary patterns, principal component analysis and ReliefF; 2) radial basis function Kernel based ELM predicting the processed data. The experimental data adopted in this paper were from the online monitoring system of South China State Grid Online Monitoring System by terminal CC0289 between December 1, 2011 and March 1, 2016. Experimental results indicated: compared with Elman neural network model, random forest model, support vector machine model and Bayesian networks model, PR-KELM approach demonstrated high accuracy and lower prediction error in terms of RMSE (Root Mean Square Error), MAE (Mean Absolute Error), MAPE (Mean Absolute Percentage Error), and R (Coefficient of Correlation) while applied to predicting in real datasets.}
}
@article{VALERIO201746,
title = {A communication efficient distributed learning framework for smart environments},
journal = {Pervasive and Mobile Computing},
volume = {41},
pages = {46-68},
year = {2017},
issn = {1574-1192},
doi = {https://doi.org/10.1016/j.pmcj.2017.07.014},
url = {https://www.sciencedirect.com/science/article/pii/S1574119217303875},
author = {Lorenzo Valerio and Andrea Passarella and Marco Conti},
keywords = {Iot, Big data, Smart cities, Distributed learning, Communications efficiency},
abstract = {Due to the pervasive diffusion of personal mobile and IoT devices, many “smart environments” (e.g., smart cities and smart factories) will be, among others, generators of huge amounts of data. To provide value-add services in these environments, data will have to be analysed to extract knowledge. Currently, this is typically achieved through centralised cloud-based data analytics services. However, according to many studies, this approach may present significant issues from the standpoint of data ownership, and even wireless network capacity. One possibility to cope with these shortcomings is to move data analytics closer to where data is generated. In this paper we tackle this issue by proposing and analysing a distributed learning framework, whereby data analytics are performed at the edge of the network, i.e., on locations very close to where data is generated. Specifically, in our framework, partial data analytics are performed directly on the nodes that generate the data, or on nodes close by (e.g., some of the data generators can take this role on behalf of subsets of other nodes nearby). Then, nodes exchange partial models and refine them accordingly. Our framework is general enough to host different analytics services. In the specific case analysed in the paper we focus on a learning task, considering two distributed learning algorithms. Using an activity recognition and a pattern recognition task, both on reference datasets, we compare the two learning algorithms between each other and with a central cloud solution (i.e., one that has access to the complete datasets). Our results show that using distributed machine learning techniques, it is possible to drastically reduce the network overhead, while obtaining performance comparable to the cloud solution in terms of learning accuracy. The analysis also shows when each distributed learning approach is preferable, based on the specific distribution of the data on the nodes.}
}
@article{HASEEB2021102779,
title = {Intelligent and secure edge-enabled computing model for sustainable cities using green internet of things},
journal = {Sustainable Cities and Society},
volume = {68},
pages = {102779},
year = {2021},
issn = {2210-6707},
doi = {https://doi.org/10.1016/j.scs.2021.102779},
url = {https://www.sciencedirect.com/science/article/pii/S2210670721000718},
author = {Khalid Haseeb and Ikram {Ud Din} and Ahmad Almogren and Imran Ahmed and Mohsen Guizani},
keywords = {Data security, Edge computing, Green internet of things, Intelligent routing, Deep learning},
abstract = {Internet of Things (IoT) consists of a huge number of sensors along with physical things to gather and forward data intelligently. Green IoT applications based on Wireless Sensor Networks (WSNs) are developed in various domains, such as medical, engineering, industry, and smart cities to grow the production. To increase the performance of sustainable cities, communicating nodes are interconnected autonomously to observe the environment, where they need to be more energy-efficient. Edge computing operates in a distributed manner and improves the response time with the least latency through various edge servers. Although the integration of edge computing and Green IoT significantly improves the network performance in terms of computation and data storage, low powered sensors have constraints in terms of battery power, low transmission range, and security aspects. Therefore, adopting an emerging solution is needed to offer energy services with secure data delivery for sustainable cities. This paper presents an intelligent and secure edge-enabled computing (ISEC) model for sustainable cities using Green IoT, which aims to develop the communication strategy with decreasing the liability in terms of energy management and data security for data transportation. The proposed model generates optimal features using deep learning for data routing, which may help to train the sensors for predicting the finest routes toward edge servers. Moreover, the integration of distributed hashing with chaining strategy eases security solutions with efficient computing system. The experimental results reveal the improved performance of the proposed ISEC model against other solutions for energy consumption by 21 %, network throughput by 15 %, end-to-end delay by 12 %, route interruption by 36 %, and network overhead by 52 %.}
}
@article{JANOWSKI2021104938,
title = {Remote measurement of building usable floor area – Algorithms fusion},
journal = {Land Use Policy},
volume = {100},
pages = {104938},
year = {2021},
issn = {0264-8377},
doi = {https://doi.org/10.1016/j.landusepol.2020.104938},
url = {https://www.sciencedirect.com/science/article/pii/S0264837720307602},
author = {Artur Janowski and Małgorzata Renigier-Biłozor and Marek Walacik and Aneta Chmielewska},
keywords = {Building usable floor area, Machine learning, Computer vision, Fuzzy theory, Measurement data processing, Algorithms fusion},
abstract = {Rapid changes that are taking place in the urban environment have significant impact on urban growth. Most cities and urban regions all over the world compete to increase resident and visitor satisfaction. The growing requirements and rapidity of introducing new technologies to all aspects of residents’ lives force cities and urban regions to implement "smart cities" concepts in their activities. Real estate is one of the principal anthropogenic components of urban environment thus become a subject of thorough multidisciplinary analysis in the field of data requiring spatial information systems. Recent advances in information technology, combined with the increased availability of high-resolution imagery from Earth observation, create an opportunity to use new sources of data that enable to identify, monitor, and solved many of urban environmental problem. The aim of the paper is to elaborate precise, complete and detailed property information with the use of remote sensing observations in a suitable numerical algorithm. The authors concentrate on providing one of the most important, and probably the most lacking, feature describing properties – building usable floor area (BUFA). The solution is elaborated in the form of an automatic algorithm based on machine learning and computer vision technology related to LiDAR (big data), close range images with respect to spatial information systems requirements. The obtained results related to BUFA estimation in comparison to the state-of-the-art results are satisfactory and may increase the reliability of decision-making in investment, fiscal, registration and planning aspects.}
}
@article{ULLAH2020101091,
title = {IoT-based green city architecture using secured and sustainable android services},
journal = {Environmental Technology & Innovation},
volume = {20},
pages = {101091},
year = {2020},
issn = {2352-1864},
doi = {https://doi.org/10.1016/j.eti.2020.101091},
url = {https://www.sciencedirect.com/science/article/pii/S2352186420313912},
author = {Farhan Ullah and Fadi Al-Turjman and Anand Nayyar},
keywords = {Green city, Internet of Things, Mobile applications, Abstract syntax tree, Deep learning},
abstract = {Green and smart cities deliver services to their residents using mobile applications that make daily life more convenient. The privacy and security of these applications are significant in providing sustainable services in a green city. The software cloning is a severe threat which may breach the security and privacy of android applications. A centrally controlled and automated screening system across multiple app stores is inevitable to prevent the release of copyrighted or cloned copies of these apps. In this paper, we proposed IoT-enabled green city architecture for clone detection in android markets using a deep learning approach. First, the proposed system obtained an original APK file together with potential candidate cloned APKs via the cloud network. For each subject software, the system uses an APK Extractor tool to retrieve Dalvik Executable (DEX) files. The Jdex decompiler is utilized to retrieve Java source files through Dalvik Executables. Second, the AST features are extracted using ANother Tool for Language Recognition (ANTLR) parser. Third, the linear features are mined from these hierarchical structures, and Term Frequency Inverse Document Frequency (TFIDF) is applied to estimate the significance of each feature. Finally, the deep learning model is configured to detect cloned apps. The deep learning model is fine-tuned to get better accuracy. The proposed approach is analyzed on five different cloned applications collected from different android markets. The main objective of this system is to avoid the release of pirated apps with various pirated labels in multiple app markets.}
}
@article{KUYUK2018298,
title = {Real-Time Classification of Earthquake using Deep Learning},
journal = {Procedia Computer Science},
volume = {140},
pages = {298-305},
year = {2018},
note = {Cyber Physical Systems and Deep Learning Chicago, Illinois November 5-7, 2018},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2018.10.316},
url = {https://www.sciencedirect.com/science/article/pii/S1877050918319896},
author = {H. Serdar Kuyuk and Ohno Susumu},
keywords = {Earthquake Early Warning System, Deep Learning, Convulational Neural Network, Long Short-Term Memory},
abstract = {Existing Earthquake Early Warning Systems (EEWSs) calculates the location and magnitude of an earthquake using real-time waveforms from seismic stations within a few seconds. Typically, three to six stations are necessary to estimate earthquake parameters. Waiting for primary (P-) wave information from closest stations results in a blind-zone area where the arrival of secondary (S-) wave cannot be provided around the epicenter of an earthquake. If an earthquake occurred under a city center, EEWSs would not work even though each building has a seismic sensor in a smart city in future. Here, we present a methodology to classify earthquake vibrations into near-source or far-source within one second after P-wave detection. This will allow warnings to citizens who are the residence of earthquake epicenter in case of an earthquake very close by. We trained a deep learning Long Short-Term Memory (LSTM) network for sequence-to-label classification. 305 three component accelerations recorded between 2000 and 2018 in Japan are used to train the artificial network by extracting thirteen features of one second of P-wave. The accuracy of the methodology is 98.2%. 54 out of 55 near-source waveforms classified correctly and only 2 of 80 waveforms were misclassified. We tested the LSTM network with 2018 Northern Osaka (M 6.1.) earthquakes in Japan where closest stations are correctly identified with 83.3% accuracy. Therefore, smart cities donated with smart automated shut-on/off machines and sensors will be more resilient against earthquake disaster even EEWSs are not available in the blind zone area in future.}
}
@article{BUNYAKITANON2020107433,
title = {Auto-3P: An autonomous VNF performance prediction & placement framework based on machine learning},
journal = {Computer Networks},
volume = {181},
pages = {107433},
year = {2020},
issn = {1389-1286},
doi = {https://doi.org/10.1016/j.comnet.2020.107433},
url = {https://www.sciencedirect.com/science/article/pii/S1389128620311221},
author = {Monchai Bunyakitanon and Aloizio Pereira {da Silva} and Xenofon Vasilakos and Reza Nejabati and Dimitra Simeonidou},
keywords = {Machine learning, Network function virtualization, End-to-End communication, Zero-Touch management, Cloud and edge computing},
abstract = {We propose Auto-3P, an Autonomous module for Virtual Network Functions Performance Prediction and Placement at network cloud and edge facilities based on Machine Learning (ML). Auto-3P augments the autonomous placement capabilities of MANagement and Orchestration frameworks (MANOs) by considering both resource availability at hosting nodes and the implied impact of a VNF node placement decisions on the whole service level end-to-end performance. Unlike that, most existing placement methods take a rather myopic approach after manual rule-based decisions, and/or based exclusively on a host-centric view that focuses merely on node-local resource availability and network metrics. We evaluate and validate Auto-3P with real-field trials in the context of a well-defined Smart City Safety use case using a real end-to-end application over a real city-based testbed. We meticulously conduct repeated tests to assess (i) the accuracy of our adopted prediction models; and (ii) their placement performance against three other existing MANO approaches, namely, a “Traditional”, a “Latency-aware” and a “Random” one, as well as against a collection of well-known Time Series Forecasting (TSF) methods. Our results show that the accuracy of our ML models outperforms the one by TSF models, with the most prominent accuracy performances being exhibited by models such as K-Nearest Neighbors Regression (K-NNR), Decision Tree (DT), and Support Vector Regression (SVR). What is more, the resulted end-to-end service level performance of our approach outperforms “Traditional”, “Latency-aware”, and Random MANO placement. Last, Auto-3P achieves load balancing at selected VNF hosts without degrading end-to-end service level delay, and without a need for a (fixed) overload threshold check, unlike what is suggested by other works in the literature for coping with heavy system-wide load conditions.}
}
@article{YONG2022108335,
title = {Analysis and prediction of diaphragm wall deflection induced by deep braced excavations using finite element method and artificial neural network optimized by metaheuristic algorithms},
journal = {Reliability Engineering & System Safety},
volume = {221},
pages = {108335},
year = {2022},
issn = {0951-8320},
doi = {https://doi.org/10.1016/j.ress.2022.108335},
url = {https://www.sciencedirect.com/science/article/pii/S0951832022000163},
author = {Weixun Yong and Wengang Zhang and Hoang Nguyen and Xuan-Nam Bui and Yosoon Choi and Trung Nguyen-Thoi and Jian Zhou and Trung Tin Tran},
keywords = {System safety, Diaphragm wall, Soft clay, Braced excavation, Artificial neural network, Metaheuristic algorithms},
abstract = {The construction of metropolises in smart cities is the trend of developed countries. However, it may cause damages to the surrounding structures. For this reason, the diaphragm wall has been applied to prevent the deformation or collapse of the surrounding structures. Diaphragm walls can be deflected due to the swelling pressure or other geotechnical properties during construction. Therefore, the accurate prediction of diaphragm wall deflection (DWD) is challenging in construction aiming to ensure the safety of the surrounding structures. This study is, therefore, to propose two intelligent models for predicting DWD induced by deep braced excavations based on finite element method (FEM) and metaheuristic algorithms. Accordingly, a total of 1120 finite elements were analyzed to investigate the behaviors of DWD. Finally, a neural network with multiple layer perceptron (MLP) was optimized by two metaheuristic algorithms for predicting DWD, including whale optimization (WO) and Harris hawks optimization (HHO), called MLP-HHO and MLP-WO, respectively. The results indicated that the proposed MLP-HHO and MLP-WO provided high accuracy in predicting DWD. A comparison of the proposed models in this study and previous studies was also discussed to highlight the superiority of the proposed MLP-HHO and MLP-WO models.}
}
@article{ANTHOPOULOS2022103492,
title = {Urban energy efficiency assessment models from an AI and big data perspective: Tools for policy makers},
journal = {Sustainable Cities and Society},
volume = {76},
pages = {103492},
year = {2022},
issn = {2210-6707},
doi = {https://doi.org/10.1016/j.scs.2021.103492},
url = {https://www.sciencedirect.com/science/article/pii/S2210670721007587},
author = {Leonidas Anthopoulos and Vasiliki Kazantzi},
keywords = {Energy efficiency, Assessment, Models, AI, Big data, City, Smart City},
abstract = {Although energy efficiency is quite a cliché term, it is a topic that attracts an increasing attention the last decade, especially in the context of cities and as a means to address emerging challenges like sustainability and climate change. Several models have been introduced to conceptualize and calculate the urban energy system, and to demonstrate the variants that calibrate the local energy efficiency. Nevertheless, cutting-edge technologies like blockchain, electrical -and even autonomous- vehicles, smart building systems, Artificial Intelligence (AI) and big data etc. are growing within cities and question the identified urban energy efficiency, since they demand enormous amounts of power. In this regard, policy makers are concerned of the emerging technologies’ energy efficiency and their impact on the urban energy system and they attempt to introduce corresponding standards for their development. This article focuses on the impact of AI and big data in city's energy efficiency. More specifically, a literature analysis is performed and returned a taxonomy of existing energy efficiency assessment models under the lens of AI and big data. Moreover, the definition of a unified assessment model for AI and big data energy efficiency is approached.}
}
@article{BAI2021147,
title = {PrePCT: Traffic congestion prediction in smart cities with relative position congestion tensor},
journal = {Neurocomputing},
volume = {444},
pages = {147-157},
year = {2021},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2020.08.075},
url = {https://www.sciencedirect.com/science/article/pii/S0925231220315642},
author = {Mengting Bai and Yangxin Lin and Meng Ma and Ping Wang and Lihua Duan},
keywords = {Relative position congestion tensor, Congestion prediction, Convolutional long-short term memory network},
abstract = {Traffic congestion prediction is a vital part of Intelligent Transportation Systems in smart cities. Effective methods for traffic congestion prediction can help people make travel plans reasonably with Advanced Traveler Information Systems. Most of the existing methods for traffic congestion prediction was designed for a specific location. The parameters need to be modified when applying these methods to different locations. Other studies on the traffic network require sophisticated data pre-processing such as map matching. In this paper, we build a model named Relative Position Congestion Tensor and propose a Predictor for Position Congestion Tensor for traffic congestion prediction. First, we design a novel approach to construct congestion matrix on region traffic networks using the concept of relative locations for road nodes and convert matrices into three-dimensional spatio-temporal tensors. Then, we propose a method based on convolutional long-short term memory network to predict congestion at all locations of the road network in the near future. The experiments show that in all locations where congestion often occurs, the proposed method significantly outperforms baseline models including Linear Regression, Autoregressive Integrated Moving Average, Support Vector Regression, Random Forest, Gradient Boosting Regression, Long-Short Term Memory and generally outperforms the Convolution-based deep Neural Network modeling Periodic traffic data. Furthermore, we study the internal structure of the Predictor for Position Congestion Tensor model to analyze the interpretability of the model for congestion prediction. The results show that the proposed model can accurately capture the temporal and spatial characteristics of traffic.}
}
@article{GONCALVES2020110146,
title = {One step forward toward smart city Utopia: Smart building energy management based on adaptive surrogate modelling},
journal = {Energy and Buildings},
volume = {223},
pages = {110146},
year = {2020},
issn = {0378-7788},
doi = {https://doi.org/10.1016/j.enbuild.2020.110146},
url = {https://www.sciencedirect.com/science/article/pii/S037877882030400X},
author = {Diogo Gonçalves and Yahya Sheikhnejad and Mónica Oliveira and Nelson Martins},
keywords = {Intelligent energy management, Machine learning, Supervisory predictive control, Adaptive surrogate modelling, Smart green buildings},
abstract = {This study steps into the roadmap of agenda 2030 to mitigate the human footprint on an environment with the aim of management of energy consumption in residential/commercial buildings. In order to materialize this concept, a new generation of adaptable systems of intelligent supervisory predictive control (ISPC) is introduced and implemented in which energy consumption tends to be minimized without sacrificing occupants thermal comfort. The methodology of ISPC includes building thermal simulation and multi-objective optimization algorithm that interact with conventional machine-level controllers of HVAC systems, to define optimized setpoints considering current and forecasted operation conditions. The development of a reliable surrogate model, based on robust machine learning techniques, is a key feature to confer greenness to a building in order to promote sustainability in the built environment and finally to have a smart green building. It is showed that the proposed ISPC is capable of delivering a robust, energy- and cost-effective decision while being independent of the HVAC system. The implemented energy management, as a non-destructive retrofitting procedure, can be applied to both new and existing buildings and with any level of HVAC technology.}
}
@article{ALOQAILY2019101842,
title = {An intrusion detection system for connected vehicles in smart cities},
journal = {Ad Hoc Networks},
volume = {90},
pages = {101842},
year = {2019},
note = {Recent advances on security and privacy in Intelligent Transportation Systems},
issn = {1570-8705},
doi = {https://doi.org/10.1016/j.adhoc.2019.02.001},
url = {https://www.sciencedirect.com/science/article/pii/S1570870519301131},
author = {Moayad Aloqaily and Safa Otoum and Ismaeel Al Ridhawi and Yaser Jararweh},
keywords = {Smart city, Connected vehicles, Intrusion detection, Vehicular cloud computing, Smart transportation, Service-specific clusters, QoS, QoE},
abstract = {In the very near future, transportation will go through a transitional period that will shape the industry beyond recognition. Smart vehicles have played a significant role in the advancement of intelligent and connected transportation systems. Continuous vehicular cloud service availability in smart cities is becoming a crucial subscriber necessity which requires improvement in the vehicular service management architecture. Moreover, as smart cities continue to deploy diversified technologies to achieve assorted and high-performance cloud services, security issues with regards to communicating entities which share personal requester information still prevails. To mitigate these concerns, we introduce an automated secure continuous cloud service availability framework for smart connected vehicles that enables an intrusion detection mechanism against security attacks and provides services that meet users’ quality of service (QoS) and quality of experience (QoE) requirements. Continuous service availability is achieved by clustering smart vehicles into service-specific clusters. Cluster heads are selected for communication purposes with trusted third-party entities (TTPs) acting as mediators between service requesters and providers. The most optimal services are then delivered from the selected service providers to the requesters. Furthermore, intrusion detection is accomplished through a three-phase data traffic analysis, reduction, and classification technique used to identify positive trusted service requests against false requests that may occur during intrusion attacks. The solution adopts deep belief and decision tree machine learning mechanisms used for data reduction and classification purposes, respectively. The framework is validated through simulations to demonstrate the effectiveness of the solution in terms of intrusion attack detection. The proposed solution achieved an overall accuracy of 99.43% with 99.92% detection rate and 0.96% false positive and false negative rate of 1.53%.}
}
@article{HUANG2020109975,
title = {Cooperative Adaptive Cruise Control and exhaust emission evaluation under heterogeneous connected vehicle network environment in urban city},
journal = {Journal of Environmental Management},
volume = {256},
pages = {109975},
year = {2020},
issn = {0301-4797},
doi = {https://doi.org/10.1016/j.jenvman.2019.109975},
url = {https://www.sciencedirect.com/science/article/pii/S0301479719316937},
author = {Ling Huang and Cong Zhai and Haiwei Wang and Ronghui Zhang and Zhijun Qiu and Jianping Wu},
keywords = {Intelligent connected vehicle, Cooperative adaptive cruise control, Heterogeneous, Exhaust emission evaluation, Transportation simulation and environment, Smart city},
abstract = {With the development of information communication and artificial intelligence, the ICV (intelligent connected vehicle) will inevitably play an important part in future urban transport system. In this paper, we study the car following behaviour under the heterogeneous ICV environment. The time to receive information varies from vehicle to vehicle, since the manual vehicles and autonomous vehicles co-exist on the road. By introducing time-varying lags function, a new car following model is proposed, and the cooperative control strategy of this model is studied. Based on Lyapunov function theory and linear matrix inequality (LMI) approach, the sufficient condition that the existence of the feedback controller is given, which makes the closed-loop system asymptotically stable under mixed traffic flow environment. That is to say, traffic congestion phenomenon under heterogeneous traffic flow can be effectively suppressed, and the feedback controller gain matrix can be obtained via solving linear matrix inequality. Finally, by simulation the method is verified effective in alleviating traffic congestions and reducing fuel consumption and exhaust emissions. It could be a useful reference to Cooperative Vehicle Infrastructure System and Smart City.}
}
@article{QU2021247,
title = {DroneCOCoNet: Learning-based edge computation offloading and control networking for drone video analytics},
journal = {Future Generation Computer Systems},
volume = {125},
pages = {247-262},
year = {2021},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2021.06.040},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X21002351},
author = {Chengyi Qu and Prasad Calyam and Jeromy Yu and Aditya Vandanapu and Osunkoya Opeoluwa and Ke Gao and Songjie Wang and Raymond Chastain and Kannappan Palaniappan},
keywords = {Edge/fog computation offloading, Drone video analytics, Mobile edge computing, Learning-based scheme, Data processing in fog computing},
abstract = {Multi-Unmanned Aerial Vehicle (UAV) systems with high-resolution cameras have been found useful for operations such as smart city and disaster management. These systems feature Flying Ad-Hoc Networks (FANETs) that connect the computation edge with UAVs and a Ground Control Station (GCS) through air-to-ground wireless network links. Leveraging the edge/fog computation resources effectively with energy-latency-awareness, and handling intermittent failures of FANETs are the major challenges in supporting video processing applications. In this paper, we propose a novel “DroneCOCoNet” framework for drone video analytics that coordinates intelligent processing of large video datasets using edge computation offloading and performs network protocol selection based on resource-awareness. We present two edge computation offloading approaches, i.e., heuristic-based and reinforcement learning-based approaches. These approaches provide intelligent task sharing and co-ordination for dynamic offloading decision-making among UAVs. Our scheme handles the problem of computation offloading tasks in two separate ways: (i) heuristic decision-making process, and (ii) Markov decision process; wherein we aim to minimize the total computation costs as well as latency in the edge/fog resources while minimizing video processing times to meet application requirements. Our experimental results show that our heuristic-based offloading decision-making scheme enables lower scheduling time and energy consumption for low drone-to-ground server ratios. In comparison, our dynamic reinforcement learning-based decision-making approach increases the accuracy and saves overall time periodically. Notably, these results also hold in various other multi-UAV scenarios involving largely different numbers of detected objects in e.g., smart farming, transportation traffic flow monitoring and disaster response.}
}
@article{ALKHATIB2020121426,
title = {A sentiment reporting framework for major city events: Case study on the China-United States trade war},
journal = {Journal of Cleaner Production},
volume = {264},
pages = {121426},
year = {2020},
issn = {0959-6526},
doi = {https://doi.org/10.1016/j.jclepro.2020.121426},
url = {https://www.sciencedirect.com/science/article/pii/S0959652620314736},
author = {Manar AlKhatib and May {El Barachi} and Abolfazl AleAhmad and Farhad Oroumchian and Khaled Shaalan},
keywords = {Smart cities, Sustainable cities, Public opinion, Opinion leaders, Sentiment analysis},
abstract = {Smart cities are conceptualized as a vehicle for sustainable urban development and a means to deliver high quality of life for residents. One of the core functions of a smart city consists in the continuous monitoring of events, assets and people and the use of this information and intelligence for the streamlining of the city’s operations. Public opinion represents one type of intelligence of particular importance and value. By monitoring public opinion, governments seek to understand prevalent views about the current events and policies, as well as identify extreme views and trends that may represent problematic situations or precursors to violent actions. Ultimately, maintaining a constant awareness of public opinion means that authorities can better assess and predict public reactions in relation to ongoing events, and thus take appropriate actions to maintain public safety. Due to the popular use of social media to express sentiments and emotions about current events, social media content analysis has been contemplated as a promising solution to capture public opinion. However, existing approaches take a coarse-grained retrospective approach to social media content analysis. Furthermore, those approaches suffer from the lack of scalability and efficiency, as they necessitate the collection and analysis of large volumes of social media content (often millions of posts), to come up with relevant conclusions. In this work, we address those limitations by proposing a novel framework for the real-time monitoring of public opinion. To ensure efficiency and scalability, our framework focuses on the analysis of high impact social media content generated by opinion leaders and their followers as means to offer in-depth insights and sentiment intelligence reports about events, as they are occurring in real time. The proposed framework was implemented and tested on data harvested from 52 economic opinion leaders, with a focus on the China-US trade war as case study. The results show that the convolutional neural network (CNN) classifier used for sentiment analysis yielded a classification accuracy of 86% when differentiating between four sentiment categories: Support, strong support, dissent, and strong dissent. The Support Vector Machine (SVM) classifier employed to perform in-depth emotional analysis attained an accuracy of 82% when differentiating between five emotions: Angry, depressed, excited, happy, and worried. Unlike existing retrospective social media analysis approaches that require the analysis of millions of posts, our approach focuses on the analysis of high-impact social media content in real-time, thus constituting an efficient, sustainable, and timely solution to public opinion monitoring.}
}
@article{MEI2020103018,
title = {Densely connected deep neural network considering connectivity of pixels for automatic crack detection},
journal = {Automation in Construction},
volume = {110},
pages = {103018},
year = {2020},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2019.103018},
url = {https://www.sciencedirect.com/science/article/pii/S0926580519307502},
author = {Qipei Mei and Mustafa Gül and Md Riasat Azim},
keywords = {Crack detection, Deep learning, Transposed convolution layer, Densely connected layers, Connectivity of pixels},
abstract = {In order to develop smart cities, the demand for assessing the condition of existing infrastructure systems in an automated manner is burgeoning rapidly. Among all the early signs of potential damage in infrastructure systems, formation of cracks is a critical one because it is directly related to the structural capacity and could significantly affect the serviceability of the infrastructure. This paper proposes a novel deep learning-based method considering the connectivity of pixels for automatic pavement crack detection which has the potential to complement the current practice involving visual inspection which is costly, inefficient and time-consuming. In the proposed method, the convolutional layers are densely connected in a feed-forward fashion to reuse features from multiple layers, and transposed convolution layers are used for multiple level feature fusion. A novel loss function considering the connectivity of pixels is introduced to overcome the issues related to the output of transposed convolution layers. The proposed method is tested on two datasets, where the first one is collected from a handheld smartphone and the second one is collected from a high-speed camera mounted on the rear of a moving car. In both datasets, the proposed method shows superior performance than other available methods.}
}
@article{MASTALERZ20203780,
title = {Passenger BIBO detection with IoT support and machine learning techniques for intelligent transport systems},
journal = {Procedia Computer Science},
volume = {176},
pages = {3780-3793},
year = {2020},
note = {Knowledge-Based and Intelligent Information & Engineering Systems: Proceedings of the 24th International Conference KES2020},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2020.09.009},
url = {https://www.sciencedirect.com/science/article/pii/S1877050920319001},
author = {Marcin W. Mastalerz and Aleksander Malinowski and Sławomir Kwiatkowski and Anna Śniegula and Bartosz Wieczorek},
keywords = {Machine learning, Electronic Toll Collection System, Internet of Things, Beacon, Smartphone, Prediction Analytics, Smart city},
abstract = {The present article discusses the issue of automation of the CICO (Check-In/Check-Out) process for public transport fare collection systems, using modern tools forming part of the Internet of Things, such as Beacon and Smartphone. It describes the concept of an integrated passenger identification model applying machine learning technology in order to reduce or eliminate the risks associated with the incorrect classification of a smartphone user as a vehicle passenger. This will allow for the construction of an intelligent fare collection system, operating in the BIBO (Be-In/Be-Out) model, implementing the "hands-free" and "pay-as-you-go" approach. The article describes the architecture of the research environment, and the implementation of the elaborated model in the Bad.App4 proprietary solution. We also presented the complete process of concept verification under real-life conditions. Research results were described and supplemented with commentary.}
}
@article{CASARES20185,
title = {The brain of the future and the viability of democratic governance: The role of artificial intelligence, cognitive machines, and viable systems},
journal = {Futures},
volume = {103},
pages = {5-16},
year = {2018},
note = {Futures of Society: The Interactions Revolution},
issn = {0016-3287},
doi = {https://doi.org/10.1016/j.futures.2018.05.002},
url = {https://www.sciencedirect.com/science/article/pii/S0016328717302896},
author = {Alexandre Perez Casares},
keywords = {Artificial intelligence, Viable systems, Democratic governance, Technological disruption, Income inequality, Communication systems, Complexity},
abstract = {At a time when smartphones, smart-homes, smart-cities, wearables, factories, etc., are becoming increasingly omnipresent, shall we also expect technological progress in artificial intelligence (AI) to result in the emergence of smart-governments and nations? The field of AI, and more broadly the development of artificial cognitive machines, is making breathtaking advances. A significant increase in computing power is enabling the rapid adoption of a new paradigm of AI, whereby cognitive machines are no longer programmed line by line, instruction by instruction, but instead are now capable of learning autonomously, thereby continuously developing themselves. The new paradigm is unleashing extraordinary progress in a wide range of applications, from healthcare to transportation and even the justice system; at the same time, these new forms of intelligence are making decisions in complex ways that escape the limits of human comprehension. The technological transformation driven by artificial cognitive machines is already beginning to have far reaching consequences, some unintended, at a scale and pace which exceeds even that of the first and second industrial revolutions. This paper aims to discuss these implications, both with an ontological and epistemological perspective, to assess the potential challenges for the systemic viability of democratic societies: a fundamental change in the nature of economic wealth creation, which could raise significant social tensions, combined with the paradoxical reduction in the effectiveness of human communication. It then explores the potential role of artificial cognitive machines to address its own challenges, introducing the idea of a future brain for public governance, understanding brain as an emergent property resulting from the interaction of human agents and AI systems created to address the priorities of social organizations.}
}
@article{AMATO202179,
title = {Enhancing random forest classification with NLP in DAMEH: A system for DAta Management in eHealth Domain},
journal = {Neurocomputing},
volume = {444},
pages = {79-91},
year = {2021},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2020.08.091},
url = {https://www.sciencedirect.com/science/article/pii/S0925231221001302},
author = {Flora Amato and Luigi Coppolino and Giovanni Cozzolino and Giovanni Mazzeo and Francesco Moscato and Roberto Nardone},
keywords = {Big data processing, E-health, Machine learning, Random forests, Multi-classification schema},
abstract = {The use of pervasive IoT devices in Smart Cities, have increased the Volume of data produced in many and many field. Interesting and very useful applications grow up in number in E-health domain, where smart devices are used in order to manage huge amount of data, in highly distributed environments, in order to provide smart services able to collect data to fill medical records of patients. The problem here is to gather data, to produce records and to analyze medical records depending on their contents. Since data gathering involve very different devices (not only wearable medical sensors, but also environmental smart devices, like weather, pollution and other sensors) it is very difficult to classify data depending their contents, in order to enable better management of patients. Data from smart devices couple with medical records written in natural language: we describe here an architecture that is able to determine best features for classification, depending on existent medical records. The architecture is based on pre-filtering phase based on Natural Language Processing, that is able to enhance Machine learning classification based on Random Forests. We carried on experiments on about 5000 medical records from real (anonymized) case studies from various health-care organizations in Italy. We show accuracy of the presented approach in terms of Accuracy-Rejection curves.}
}
@article{YANG2020207,
title = {Counting crowds using a scale-distribution-aware network and adaptive human-shaped kernel},
journal = {Neurocomputing},
volume = {390},
pages = {207-216},
year = {2020},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2019.02.071},
url = {https://www.sciencedirect.com/science/article/pii/S0925231219314651},
author = {Biao Yang and Weiqin Zhan and Nan Wang and Xiaofeng Liu and Jidong Lv},
keywords = {Crowd counting, Intelligent bus system, Multi-column convolutional neural network, Weighted euclidean loss, Human-machine system},
abstract = {Intelligent bus system plays a key role in the modern smart city. The number of passengers in the buses or at the stations is necessary for making an optimal scheduling policy of public buses. We develop a crowd counting algorithm to provide the counting information for a bus dispatch system in a human–machine system. In consideration of the challenges (e.g., pedestrian occlusions, non-uniform crowd distributions, and scale variations) existed in hand-crafted features based crowd counting, a scale-distribution-aware multi-column convolutional neural network (SDA-MCNN) is presented to count crowds by summing up the output (denoted as the density map) of the SDA-MCNN. The SDA-MCNN is robust to scale variations by processing a crowd image with multiple convolutional neural network (CNN) columns and minimizing the per-scale loss. A weighted Euclidean loss is proposed to handle non-uniform crowd distributions. The loss can increase activations in dense regions and restrain activations in backgrounds. A new approach to estimate perspective maps of dense crowds is put forward to offer necessary information for generating density maps with human-shaped kernels. Evaluations on benchmarks are performed with other state-of-the-art counting approaches using deep neural networks. Comparative results verify the accuracy of our counting approach in challenging crowds. Evaluations on the real world BUS data reveal the accuracy of the proposed approach in counting passengers in spite of the complex environment.}
}
@article{MAIUROVA2022131604,
title = {Promoting digital transformation in waste collection service and recycling in Moscow (Russia): Applying a circular economy paradigm to mitigate climate change impacts on the environment},
journal = {Journal of Cleaner Production},
pages = {131604},
year = {2022},
issn = {0959-6526},
doi = {https://doi.org/10.1016/j.jclepro.2022.131604},
url = {https://www.sciencedirect.com/science/article/pii/S0959652622012215},
author = {Aleksandra Maiurova and Tonni Agustiono Kurniawan and Marina Kustikova and Elena Bykovskaia and Mohd Hafiz Dzarfan Othman and Deepak Singh and Hui Hwang Goh},
keywords = {Climate change, Digitalization, Resource recovery, Smart city, Zero emission},
abstract = {Due to industrialization, recently Moscow (Russia) has been overwhelmed with municipal solid waste (MSW), while the capital does not provide residents with organized waste collection and waste recycling. Digitalization enables smart cities such as Moscow to do more work with less resources. This article identifies and analyzes the existing waste management facilities in Moscow with respect to drawbacks and the ways forward to mitigate the bottlenecks. To improve its waste management, lessons drawn from Berlin's experiences in waste management are discussed to inspire transformation in the city's waste sector in the framewok of resource recovery. In line with the 2030 UN Agenda, this work proposes a digitalization to accelerate societal transitions through waste recycling industry. Its global relevance is elaborated by presenting perspective of digitalization in waste management practices. In this work, case-study was selected as the research method to provide a means to investigate a complex waste problem in Moscow and Berlin. It was evident from cleaner production paradigm that digital technology can minimize the amount of unrecycled MSW, while conserving raw materials and reducing operational cost and GHG emissions. Digitalization builds cities' resilience by strengthening local waste management practices to respond to the Covid-19 pandemic. In Moscow, the transition towards the digitalization of waste recycling through informal waste sectors has created 5,000 new jobs that reduces unemployment rate. This maximizes pick up time and enhance efficiency with a lower cost of operating trucks up to 75%. A convolutional neural network–based identification system that classifies identified materials yields almost perfect accuracy. A single robot arm can handle four varying fractions of construction and demolition waste with 99% of purity. Robotic deployment could reduce the volume of unrecycled waste by 20%. This could be replicated to resist the pressure of resource consumption and deliver socio-economic and environmental benefits worldwide.}
}
@article{MANNION2015956,
title = {Parallel Reinforcement Learning for Traffic Signal Control},
journal = {Procedia Computer Science},
volume = {52},
pages = {956-961},
year = {2015},
note = {The 6th International Conference on Ambient Systems, Networks and Technologies (ANT-2015), the 5th International Conference on Sustainable Energy Information Technology (SEIT-2015)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2015.05.172},
url = {https://www.sciencedirect.com/science/article/pii/S1877050915009722},
author = {Patrick Mannion and Jim Duggan and Enda Howley},
keywords = {Reinforcement Learning, Parallel Learning, Multi Agent Systems, Intelligent Transportation Systems, Adaptive Traffic Signal Control, Smart Cities},
abstract = {Developing Adaptive Traffic Signal Control strategies for efficient urban traffic management is a challenging problem, which is not easily solved. Reinforcement Learning (RL) has been shown to be a promising approach when applied to traffic signal control (TSC) problems. When using RL agents for TSC, difficulties may arise with respect to convergence times and performance. This is especially pronounced on complex intersections with many different phases, due to the increased size of the state action space. Parallel Learning is an emerging technique in RL literature, which allows several learning agents to pool their experiences while learning concurrently on the same problem. Here we present an extension to a leading published work on RL for TSC, which leverages the benefits of Parallel Learning to increase exploration and reduce delay times and queue lengths.}
}
@article{YUAN2021109,
title = {Mask-RCNN with spatial attention for pedestrian segmentation in cyber–physical systems},
journal = {Computer Communications},
volume = {180},
pages = {109-114},
year = {2021},
issn = {0140-3664},
doi = {https://doi.org/10.1016/j.comcom.2021.09.002},
url = {https://www.sciencedirect.com/science/article/pii/S0140366421003315},
author = {Lin Yuan and Zhao Qiu},
keywords = {Pedestrian segmentation, Mask-RCNN, Spatial attention mechanism, Transfer learning, Cyber–physical systems},
abstract = {With the application of industrial cyber–physical systems in various fields such as transportation systems, smart cities, and medical systems, pedestrian scenarios are becoming more and more complex, which brings difficulties to pedestrian segmentation. The difficulty of pedestrian segmentation lies in the scene’s complexity where the pedestrian is located, including the pedestrian’s shooting angle, light, and obstructions, which makes it difficult to distinguish accurately. This paper proposes an S-Mask-RCNN network that integrates spatial attention mechanisms for pedestrian segmentation. Mask-RCNN uses residual neural networks in the feature extraction network, and the effect of model feature extraction is not ideal. Based on transfer learning, a spatial attention mechanism is introduced to focus more spatially on areas that need attention. The force mechanism focuses more on the areas that need attention in space. Experiments show that the S-Mask-RCNN method proposed in this paper has better performance than traditional Mask-RCNN in pedestrian segmentation. Experiments show that the S-Mask-RCNN method proposed in this paper has better performance than traditional Mask-RCNN in pedestrian segmentation, also can provide more comprehensive and practical information for the construction of cyber–physical systems.}
}
@article{IDOWU2016478,
title = {Applied machine learning: Forecasting heat load in district heating system},
journal = {Energy and Buildings},
volume = {133},
pages = {478-488},
year = {2016},
issn = {0378-7788},
doi = {https://doi.org/10.1016/j.enbuild.2016.09.068},
url = {https://www.sciencedirect.com/science/article/pii/S0378778816310155},
author = {Samuel Idowu and Saguna Saguna and Christer Åhlund and Olov Schelén},
keywords = {Data driven modeling, District heating, Energy efficiency, Machine learning, Smart cities},
abstract = {Forecasting energy consumption in buildings is a key step towards the realization of optimized energy production, distribution and consumption. This paper presents a data driven approach for analysis and forecast of aggregate space and water thermal load in buildings. The analysis and the forecast models are built using district heating data unobtrusively collected from 10 residential and commercial buildings located in Skellefteå, Sweden. The load forecast models are generated using supervised machine learning techniques, namely, support vector machine, regression tree, feed forward neural network, and multiple linear regression. The model takes the outdoor temperature, historical values of heat load, time factor variables and physical parameters of district heating substations as its input. A performance comparison among the machine learning methods and identification of the importance of models input variables is carried out. The models are evaluated with varying forecast horizons of every hour from 1 up to 48h. Our results show that support vector machine, feed forward neural network and multiple linear regression are more suitable machine learning methods with lower performance errors than the regression tree. Support vector machine has the least normalized root mean square error of 0.07 for a forecast horizon of 24h.}
}
@article{BENDALIBRAHAM2021100023,
title = {Recent trends in crowd analysis: A review},
journal = {Machine Learning with Applications},
volume = {4},
pages = {100023},
year = {2021},
issn = {2666-8270},
doi = {https://doi.org/10.1016/j.mlwa.2021.100023},
url = {https://www.sciencedirect.com/science/article/pii/S2666827021000049},
author = {Mounir Bendali-Braham and Jonathan Weber and Germain Forestier and Lhassane Idoumghar and Pierre-Alain Muller},
keywords = {Crowd analysis, Crowd behavior analysis, Group behavior analysis, Abnormal behavior detection, Deep Learning, Video-surveillance},
abstract = {When overpopulated cities face frequent crowded events like strikes, demonstrations, parades or other sorts of people gatherings, they are confronted to multiple security issues. To mitigate these issues, security forces are often involved to monitor the gatherings and to ensure the security of their participants. However, when access to technology is limited, the security forces can quickly become overwhelmed. Fortunately, more and more important smart cities are adopting the concept of intelligent surveillance systems. In these situations, intelligent surveillance systems require the most advanced techniques of crowd analysis to monitor crowd events properly. In this review, we explore various studies related to crowd analysis. Crowd analysis is commonly broken down into two major branches: crowd statistics and crowd behavior analysis. When crowd statistics determines the Level Of Service (LoS) of a crowded scene, crowd behavior analysis describes the motion patterns and the activities that are observed in a scene. One of the hottest topics of crowd analysis is anomaly detection. Although a unanimous definition of anomaly has not yet been met, each of crowd analysis subtopics can be subjected to abnormality. The purpose of our review is to find subareas, in crowd analysis, that are still unexplored or that seem to be rarely addressed through the prism of Deep Learning.}
}
@article{RAJPUT2020101246,
title = {Opportunistic sensing based detection of crowdedness in public transport buses},
journal = {Pervasive and Mobile Computing},
volume = {68},
pages = {101246},
year = {2020},
issn = {1574-1192},
doi = {https://doi.org/10.1016/j.pmcj.2020.101246},
url = {https://www.sciencedirect.com/science/article/pii/S1574119220300961},
author = {Pruthvish Rajput and Manish Chaturvedi and Vivek Patel},
keywords = {Smart city, Intelligent Transportation System (ITS), Opportunistic sensing (crowdsourcing), Public transportation, Machine learning},
abstract = {This paper presents an opportunistic sensing based solution to detect crowdedness in public transportation buses. The solution uses data of accelerometer and Global Positioning System (GPS) sensors available in smartphones carried by the commuters. These data are used to accurately identify bus boarding event and whether a commuter got a seat during his/her trip. The solution is energy efficient as it uses power hungry GPS very conservatively and keeps it off majority of the times. The solution is evaluated using data collected over the arterial roads of Ahmedabad and Gandhinagar city. The length of routes varies from 25 to 45 kilometers. The effect of application penetration on crowdedness detection in buses is also evaluated. It is found that the penetration of 8 to 12% in commuter population can detect the crowdedness for more than 80% of route segments on the test routes. Further, the solution results in the energy-saving of about 50% compared to a solution that requires GPS data continuously. We also present the bus scheduling scheme that uses the historical data of bus-crowdedness to schedule the feeder buses on the crowded segments of the route.}
}
@article{JU2018881,
title = {Citizen-centered big data analysis-driven governance intelligence framework for smart cities},
journal = {Telecommunications Policy},
volume = {42},
number = {10},
pages = {881-896},
year = {2018},
note = {Smart Cities: Governance and Economics},
issn = {0308-5961},
doi = {https://doi.org/10.1016/j.telpol.2018.01.003},
url = {https://www.sciencedirect.com/science/article/pii/S0308596117301556},
author = {Jingrui Ju and Luning Liu and Yuqiang Feng},
keywords = {Citizen-centered big data, Governance intelligence, Smart cities, Data-analysis algorithm, Data merging, Citizen profile, Citizen persona, Ontology model},
abstract = {Sensors and systems within rapidly expanding smart cities produce citizen-centered big data which have potential value to support citizen-centered urban governance decision-making. There exists a wealth of extant conceptual studies, however, further operational studies are needed to establish a specific path towards implementation of such data to governance decision-making with analytical algorithms that are appropriate for each step of the path. This paper proposes a framework for the use of citizen-centered big data analysis to drive governance intelligence in smart cities from two perspectives: urban governance issues and data-analysis algorithms. The framework consists of three layers: 1) A data-merging layer, which builds a citizen-centered panoramic data set for each citizen by merging citizen-related big data from multiple sources in collaborative urban governance via similarity calculation and conflict resolution; 2) a knowledge-discovery layer, which plots the citizen profile and citizen persona at both individual and group levels in terms of urban public service delivery and citizen participation via simple statistical analysis techniques, machine learning, and econometrics methods; and 3) a decision-making layer, which uses ontology models to standardize urban governance-related attributes, personas, and associations to support governance decision-making via data mining and Bayesian Net techniques. Finally, the proposed framework is validated in a case study on blood donation governance in China. This research highlights the value of citizen-centered big data, pushes data-to-decision research from conceptual to operational, synthesizes previously published frameworks for citizen-centered big data analysis in smart cities, and enhances the mutual supplement cross multiple disciplinaries.}
}
@article{HAKANSSON20182107,
title = {Ipsum – An Approach to Smart Volatile ICT-Infrastructures for Smart Cities and Communities},
journal = {Procedia Computer Science},
volume = {126},
pages = {2107-2116},
year = {2018},
note = {Knowledge-Based and Intelligent Information & Engineering Systems: Proceedings of the 22nd International Conference, KES-2018, Belgrade, Serbia},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2018.07.241},
url = {https://www.sciencedirect.com/science/article/pii/S1877050918312171},
author = {Anne Håkansson},
keywords = {Distributed systems, Cyber-Physical Systems},
abstract = {Information and Communication Technology (ICT)-infrastructures are increasingly important for enabling technology within smart society with smart cities and communities. An ICT-infrastructure handles data and information and encompasses devices and networks, protocols and procedures including Internet, Internet of Things and Cyber-Physical Systems. The current challenges of ICT-infrastructures are delivering services and applications that are requested by users, such as residents, public organisations and institutions. These services and applications must be combined to enhance and enrich the environment and provide personalised services. This requires radical changes in technology, such as dynamic ICT-infrastructures, which should dynamically provide requested services to be able to build smart societies. This paper is about pursuing smart and connected cities and communities by creating smart volatile ICT-infrastructures for smart cities and communities, called Ipsum. The infrastructure is of multidisciplinary art and includes different kinds of hardware, software, artificial intelligence techniques depending on the available parts and the services to be delivered. The goal is to provide a powerful and smart, and cost-saving volatile ICT-infrastructure with person-centred, ubiquitous and malleable parts, i.e., devices, sensors and services. Volatile means in real-time constitute a volatile network of devices and deploying it into cities and communities. Ipsum will be smart everywhere by collaborating with several different hardware and software systems and cooperating to perform complex tasks. By including ubiquitous and malleable parts in the infrastructure, Ipsum can facilitate an informed and engaged populace.}
}
@article{ROLDAN2020113251,
title = {Integrating complex event processing and machine learning: An intelligent architecture for detecting IoT security attacks},
journal = {Expert Systems with Applications},
volume = {149},
pages = {113251},
year = {2020},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2020.113251},
url = {https://www.sciencedirect.com/science/article/pii/S0957417420300762},
author = {José Roldán and Juan Boubeta-Puig and José {Luis Martínez} and Guadalupe Ortiz},
keywords = {Complex event processing, Machine learning, Software architecture, Intelligent decision making, Internet of Things, Security attack},
abstract = {The Internet of Things (IoT) is growing globally at a fast pace: people now find themselves surrounded by a variety of IoT devices such as smartphones and wearables in their everyday lives. Additionally, smart environments, such as smart healthcare systems, smart industries and smart cities, benefit from sensors and actuators interconnected through the IoT. However, the increase in IoT devices has brought with it the challenge of promptly detecting and combating the cybersecurity attacks and threats that target them, including malware, privacy breaches and denial of service attacks, among others. To tackle this challenge, this paper proposes an intelligent architecture that integrates Complex Event Processing (CEP) technology and the Machine Learning (ML) paradigm in order to detect different types of IoT security attacks in real time. In particular, such an architecture is capable of easily managing event patterns whose conditions depend on values obtained by ML algorithms. Additionally, a model-driven graphical tool for security attack pattern definition and automatic code generation is provided, hiding all the complexity derived from implementation details from domain experts. The proposed architecture has been applied in the case of a healthcare IoT network to validate its ability to detect attacks made by malicious devices. The results obtained demonstrate that this architecture satisfactorily fulfils its objectives.}
}
@article{SALEHI2019259,
title = {Data mining methodology employing artificial intelligence and a probabilistic approach for energy-efficient structural health monitoring with noisy and delayed signals},
journal = {Expert Systems with Applications},
volume = {135},
pages = {259-272},
year = {2019},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2019.05.051},
url = {https://www.sciencedirect.com/science/article/pii/S0957417419303860},
author = {Hadi Salehi and Saptarshi Das and Subir Biswas and Rigoberto Burgueño},
keywords = {Structural health monitoring, Data mining, Artificial intelligence, Probabilistic approach, Signal time delay},
abstract = {Numerous methods have been developed in the context of expert and intelligent systems for structural health monitoring (SHM) with wireless sensor networks (WSNs). However, these techniques have been proven to be efficient when dealing with continuous signals, and the applicability of such expert systems with discrete noisy signals has not yet been explored. This study presents an intelligent data mining methodology as part of an expert system developed for SHM with noisy and delayed signals, which are generated by a through-substrate self-powered sensor network. The noted sensor network has been demonstrated as an effective means for minimizing energy consumption in WSNs for SHM. Experimental vibration tests were conducted on a cantilever plate to evaluate the developed expert system for SHM. The proposed data mining method is based on the integration of pattern recognition, an innovative probabilistic approach, and machine learning. The novelty of the proposed system for SHM with data interpretation methodology lies in the integration of the noted intelligent techniques on discrete, binary, noisy, and delayed patterns of signals collected from self-powered sensing technology in the application to a practical engineering problem, i.e., data-driven energy-efficient SHM. Results confirm that the proposed data mining method employing a probabilistic approach can be effectively used to reconstruct delayed and missing signals, thereby addressing the important issue of energy availability for intelligent SHM systems being used for damage identification in civil and aerospace structures. The applicability and effectiveness of the expert system with the data mining approach in detecting damage with noisy signals was demonstrated for plate-like structures with an accuracy of 97%. The present study successfully contributes to advance data mining and signal processing techniques in the SHM domain, indicating a practical application of expert and intelligent systems applied to damage detection in SHM platforms. Findings from this research pave a way for development of the data analysis techniques that can be employed for interpreting noisy and incomplete signals collected from various expert systems such as those being used in intelligent infrastructure monitoring systems and smart cities.}
}
@article{SINGH2020283,
title = {An integrated fog and Artificial Intelligence smart health framework to predict and prevent COVID-19},
journal = {Global Transitions},
volume = {2},
pages = {283-292},
year = {2020},
issn = {2589-7918},
doi = {https://doi.org/10.1016/j.glt.2020.11.002},
url = {https://www.sciencedirect.com/science/article/pii/S2589791820300244},
author = {Prabhdeep Singh and Rajbir Kaur},
keywords = {Smart city, Quality of service framework, Ensemble model, Cloud/fog computing, Artificial intelligence, COVID-19},
abstract = {Nowadays, COVID-19 is spreading at a rapid rate in almost all the continents of the world. It has already affected many people who are further spreading it day by day. Hence, it is the most essential to alert nearby people to be aware of it due to its communicable behavior. Till May 2020, no vaccine is available for the treatment of this COVID-19, but the existing technologies can be used to minimize its effect. Cloud/fog computing could be used to monitor and control this rapidly spreading infection in a cost-effective and time-saving manner. To strengthen COVID-19 patient prediction, Artificial Intelligence(AI) can be integrated with cloud/fog computing for practical solutions. In this paper, fog assisted the internet of things based quality of service framework is presented to prevent and protect from COVID-19. It provides real-time processing of users’ health data to predict the COVID-19 infection by observing their symptoms and immediately generates an emergency alert, medical reports, and significant precautions to the user, their guardian as well as doctors/experts. It collects sensitive information from the hospitals/quarantine shelters through the patient IoT devices for taking necessary actions/decisions. Further, it generates an alert message to the government health agencies for controlling the outbreak of chronic illness and for tanking quick and timely actions.}
}
@article{JIN202017047,
title = {Motion Planning at Intersections with Event-driven Recurrent Q-Learning},
journal = {IFAC-PapersOnLine},
volume = {53},
number = {2},
pages = {17047-17052},
year = {2020},
note = {21st IFAC World Congress},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2020.12.1533},
url = {https://www.sciencedirect.com/science/article/pii/S2405896320321285},
author = {Xinze Jin and Qing-Shan Jia and Dongchun Ren and Yu Bai},
keywords = {motion planning, reinforcement learning, event-driven, recurrency},
abstract = {Autonomous driving at intersection has great potential on control for smart cities to relieve the energy consumption and transportation congestion. However, it remains challenging to find promising behavior sequence in multi-agent environment with uncertain participation of obstacles. This work develops Event-driven Recurrent Q-Learning (ERQL) to focus on the motion planning task towards intersection scenarios to conclude a sample path with safety and efficiency. We elaborate the definition of events to capture the environment structure and introduce recurrency to process sequence model. Besides, we incorporate collision-avoidance into the event-driven framework and design a mechanism to extract recurrent feature from replay buffer in Q-learning framework. Simulation results show that the developed off-line learning procedure can adapt to on-line decision making towards uncertain agent behaviors.}
}
@article{RATHORE2019167,
title = {BlockSecIoTNet: Blockchain-based decentralized security architecture for IoT network},
journal = {Journal of Network and Computer Applications},
volume = {143},
pages = {167-177},
year = {2019},
issn = {1084-8045},
doi = {https://doi.org/10.1016/j.jnca.2019.06.019},
url = {https://www.sciencedirect.com/science/article/pii/S1084804519302243},
author = {Shailendra Rathore and Byung {Wook Kwon} and Jong Hyuk Park},
keywords = {Internet of things, Security attack detection, Edge computing, Fog computing, Blockchain, Deep learning, Software defined networking},
abstract = {The exponential growth of the use of insecure stationary and portable devices in the Internet of Things (IoT) network of the smart city has made the security of the smart city against cyber-attacks a vital issue. Various mechanisms for detecting security attacks that rely on centralized and distributed architectures have already been proposed, but they tend to be inefficient due to such problems as storage constraints, the high cost of computation, high latency, and a single point of failure. Moreover, existing security mechanisms are faced with the issue of monitoring and collecting historic data throughout the entire IoT network of the smart city in order to deliver optimal security and defense against cyberattacks. To address the current challenges, this paper proposes a decentralized security architecture based on Software Defined Networking (SDN) coupled with a blockchain technology for IoT network in the smart city that relies on the three core technologies of SDN, Blockchain, and Fog and mobile edge computing in order to detect attacks in the IoT network more effectively. Thus, in the proposed architecture, SDN is liable to continuous monitoring and analysis of traffic data in the entire IoT network in order to provide an optimal attack detection model; Blockchain delivers decentralized attack detection to mitigate the “single point of failure” problem inherent to the existing architecture; and Fog and mobile edge computing supports attack detection at the fog node and, subsequently, attack mitigation at the edge node, thus enabling early detection and mitigation with lesser storage constraints, cheaper computation, and low latency. To validate the performance of the proposed architecture, it was subjected to an experimental evaluation, the results of which show that it outperforms both centralized and distributed architectures in terms of accuracy and detection time.}
}
@article{LI2020109,
title = {Machine learning based code dissemination by selection of reliability mobile vehicles in 5G networks},
journal = {Computer Communications},
volume = {152},
pages = {109-118},
year = {2020},
issn = {0140-3664},
doi = {https://doi.org/10.1016/j.comcom.2020.01.034},
url = {https://www.sciencedirect.com/science/article/pii/S0140366419315609},
author = {Ting Li and Ming Zhao and Kelvin Kian Loong Wong},
keywords = {Machine learning, Code disseminations, Safety degree, Coverage ratio, Reliability, 5G networks},
abstract = {Recently, the evolving of 5G networks is foreseen as a major driver of future mobile vehicular social networks (VSNs), which can provide a novel method of code disseminations. Based on this concept, vehicles can be used as code disseminators. That is, infrastructures of a smart city can be upgraded by receiving updated program codes that are disseminated by vehicles in the VSNs. Specifically, vehicles in the 5G network are hard to be managed. Under this domain, safety of program codes is a key challenge. Meanwhile, improving coverage of program codes is also challenging. However, arranging plenty of vehicles as code disseminators will incur large costs of the ground control station (GCS). Therefore, by utilizing machine learning methods, this paper proposes a “Machine Learning based Code Dissemination by Selecting Reliability Mobile Vehicles in 5G Networks” (MLCD) scheme to choose vehicles with higher reliable degree and coverage ratio as code disseminators to deliver code with lower costs. Firstly, reliable degrees of vehicles are calculated and selected to improve safety degree of code disseminations. Secondly, vehicles with higher coverage ratio are preferred to promise code coverage. Thirdly, machine learning methods are utilized to select vehicles with both higher coverage ratios and reliable degrees as code disseminators with limited costs. Compared to random-selection and coverage-only scheme respectively, the MLCD scheme can improve safety degree of code dissemination process by 83.6% and 18.86% in 5G networks, and can improve coverage ratio of updated information by 23.16%. Comprehensive performances of the proposed scheme can be improved by 80.56% and 17.25% respectively. Future works focus on improving code security in 5G networks by more advanced and suitable machine learning methods.}
}
@article{XIN20221568,
title = {A deep learning architecture for power management in smart cities},
journal = {Energy Reports},
volume = {8},
pages = {1568-1577},
year = {2022},
issn = {2352-4847},
doi = {https://doi.org/10.1016/j.egyr.2021.12.053},
url = {https://www.sciencedirect.com/science/article/pii/S235248472101492X},
author = {Qin Xin and Mamoun Alazab and Vicente García Díaz and Carlos Enrique Montenegro-Marin and Rubén González Crespo},
keywords = {Deep learning, Internet of Things, Power management, Wireless communication},
abstract = {Sustainable energy management is an inexpensive approach for improved energy use. However, the research used does not focus on cutting-edge technology possibilities in an Internet of things (IoT). This paper includes the needs for today’s distributed generation, households, and industries in proposing smart resource management deep learning model. A deep learning architecture of power management (DLA-PM) is presented in this article. It predicts future power consumption for a short period and provides effective communication between power distributors and customers. To keep power consumption and supply constant, mobile devices are linked to a universal IoT cloud server connected to the intelligent grids in the proposed design. An effective brief forecast decision-making method is followed by various preprocessing strategies to deal with electrical data. It conducts extensive tests with RMSE reduced by 0.08 for both residential and business data sources. Significant strengths include refined device-based, real-time energy administration via a shared cloud-based server data monitoring system, optimized selection of standardization technology, a new energy prediction framework, a learning process with decreased time, and lower error rates. In the proposed architecture, mobile devices link to a universal IoT cloud server communicating with the corresponding intelligent grids such that the power consumption and supply phenomena continually continue. It utilizes many preprocessing strategies to cope with the diversity of electrical data, follows an effective short prediction decision-making method, and executes it using resources. For residential and business data sources, it runs comprehensive trials with RMSE lowered by 0.08.}
}
@article{LI2020871,
title = {Data analytics of urban fabric metrics for smart cities},
journal = {Future Generation Computer Systems},
volume = {107},
pages = {871-882},
year = {2020},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2018.02.017},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X1731227X},
author = {Xin Li and Shidan Cheng and Zhihan Lv and Houbing Song and Tao Jia and Ning Lu},
keywords = {Urban morphology, Urban fabric, Block unit, Clustering, Data mining},
abstract = {Comprehensive understanding of the built environment, especially the urban form, is a prerequisite for building a smart city. Data analytics of urban fabric metrics using quantitative methods is critical to understanding a city’s complexity. This paper aims to study urban fabric using comprehensive computation methods. A series of morphological indexes of urban blocks are established to measure the blocks’ overall features and subtle differences. This study uses multiple statistical methods with computation techniques and machine learning to fulfill factor analysis and clustering to classify major block types and their spatial distribution, and this study aims to precisely position the important continuous zone and fracture locations within the study area based on a geo-information system (GIS), effectively revealing the potential morphological order of different block types in the urban fabric. The study provides accurate basis and technical support for the optimization of urban construction. It has important and practical significance for promoting the scientific and reasonable implementation of a new type of urbanization.}
}
@article{ZHAO2019449,
title = {Machine learning based privacy-preserving fair data trading in big data market},
journal = {Information Sciences},
volume = {478},
pages = {449-460},
year = {2019},
issn = {0020-0255},
doi = {https://doi.org/10.1016/j.ins.2018.11.028},
url = {https://www.sciencedirect.com/science/article/pii/S0020025518309174},
author = {Yanqi Zhao and Yong Yu and Yannan Li and Gang Han and Xiaojiang Du},
keywords = {Data trading, Privacy-preserving, Machine learning, Fairness},
abstract = {In the era of big data, the produced and collected data explode due to the emerging technologies and applications that pervade everywhere in our daily lives, including internet of things applications such as smart home, smart city, smart grid, e-commerce applications and social network. Big data market can carry out efficient data trading, which provides a way to share data and further enhances the utility of data. However, to realize effective data trading in big data market, several challenges need to be resolved. The first one is to verify the data availability for a data consumer. The second is privacy of a data provider who is unwilling to reveal his real identity to the data consumer. The third is the payment fairness between a data provider and a data consumer with atomic exchange. In this paper, we address these challenges by proposing a new blockchain-based fair data trading protocol in big data market. The proposed protocol integrates ring signature, double-authentication-preventing signature and similarity learning to guarantee the availability of trading data, privacy of data providers and fairness between data providers and data consumers. We show the proposed protocol achieves the desirable security properties that a secure data trading protocol should have. The implementation results with Solidity smart contract demonstrate the validity of the proposed blockchain-based fair data trading protocol.}
}
@article{RAHMAN2021103083,
title = {A secure, private, and explainable IoHT framework to support sustainable health monitoring in a smart city},
journal = {Sustainable Cities and Society},
volume = {72},
pages = {103083},
year = {2021},
issn = {2210-6707},
doi = {https://doi.org/10.1016/j.scs.2021.103083},
url = {https://www.sciencedirect.com/science/article/pii/S221067072100367X},
author = {Md Abdur Rahman and M. Shamim Hossain and Ahmad J. Showail and Nabil A. Alrajeh and Mohammed F. Alhamid},
keywords = {Sustainable cities, Blockchain, Off-chain, Connected living, 5G healthcare vertical, Internet of health things, Explainable AI},
abstract = {Internet of Health Things (IoHT) have allowed connected health paradigm ubiquitous. 5 G supported healthcare vertical allows IoHT to offer connected health monitoring with quality of service and ultra-low latency. Deep learning has shown potential in processing massive amount of IoHT data that are generated daily, automate connected healthcare workflows, and help in decision making processes. However, three important challenges need to be addressed to attain long term healthcare-related sustainability – data security, data privacy, and social acceptance of deep learning process. In this paper, we propose a framework that will allow healthcare sustainability through the following contributions 1) ensure privacy of training dataset, 2) support the aggregation of the global model gradients through a private Blockchain-brokered entity, 3) support trustworthiness and provenance of the federated clients by blockchain and off-chain, 4) share the dataset, train the model and share trained model among the federated clients in an encrypted fashion, and 5) add explainability and reasoning of deep learning process to make the model acceptable by the society. We will present the detailed design of our proposed sustainable system, the implementation details and test results. The test results show promising prospect of achieving sustainability of IoHT-enabled connected health applications.}
}
@article{PONCE2019170,
title = {An indoor predicting climate conditions approach using Internet-of-Things and artificial hydrocarbon networks},
journal = {Measurement},
volume = {135},
pages = {170-179},
year = {2019},
issn = {0263-2241},
doi = {https://doi.org/10.1016/j.measurement.2018.11.043},
url = {https://www.sciencedirect.com/science/article/pii/S0263224118310972},
author = {Hiram Ponce and Sebastián Gutiérrez},
keywords = {Artificial intelligence, Distributed services architecture, EnOcean, Internet of Things, Machine learning, Predictive, Raspberry Pi, Sensors, Weather station, Web service},
abstract = {The prediction and understanding of environmental conditions are of great importance to prevent and analyze changes in environment, supporting meteorological based sectors, such as agriculture or smart cities. In that sense, this paper presents an Internet of Things (IoT) system for predicting climate conditions inside enclosures, i.e. temperature, using artificial intelligence by means of a supervised learning method, the artificial hydrocarbon networks model. It allows predicting the temperature of remote locations using information from a web service comparing it with field temperature sensors. Experimental results of the supervised learning model are presented in two modes: offline training to detect the suitable parameters of the model and testing to validate the model with new data retrieval from the web service. Experimental results over ten days of data conclude that artificial hydrocarbon networks model helps to predict remote temperatures with root-mean square error of 2.7 °C in testing mode.}
}
@article{GUEVARA2020102596,
title = {On the classification of fog computing applications: A machine learning perspective},
journal = {Journal of Network and Computer Applications},
volume = {159},
pages = {102596},
year = {2020},
issn = {1084-8045},
doi = {https://doi.org/10.1016/j.jnca.2020.102596},
url = {https://www.sciencedirect.com/science/article/pii/S1084804520300709},
author = {Judy C. Guevara and Ricardo da S. Torres and Nelson L.S. {da Fonseca}},
keywords = {Fog computing, Edge computing, Cloud computing, Internet of things, Scheduling, Classes of service, Quality of service, Machine learning, Feature selection, Attribute noise, Classification algorithms},
abstract = {Currently, Internet applications running on mobile devices generate a massive amount of data that can be transmitted to a Cloud for processing. However, one fundamental limitation of a Cloud is the connectivity with end devices. Fog computing overcomes this limitation and supports the requirements of time-sensitive applications by distributing computation, communication, and storage services along the Cloud to Things (C2T) continuum, empowering potential new applications, such as smart cities, augmented reality (AR), and virtual reality (VR). However, the adoption of Fog-based computational resources and their integration with the Cloud introduces new challenges in resource management, which requires the implementation of new strategies to guarantee compliance with the quality of service (QoS) requirements of applications. In this context, one major question is how to map the QoS requirements of applications on Fog and Cloud resources. One possible approach is to discriminate the applications arriving at the Fog into Classes of Service (CoS). This paper thus introduces a set of CoS for Fog applications which includes, the QoS requirements that best characterize these Fog applications. Moreover, this paper proposes the implementation of a typical machine learning classification methodology to discriminate Fog computing applications as a function of their QoS requirements. Furthermore, the application of this methodology is illustrated in the assessment of classifiers in terms of efficiency, accuracy, and robustness to noise. The adoption of a methodology for machine learning-based classification constitutes a first step towards the definition of QoS provisioning mechanisms in Fog computing. Moreover, classifying Fog computing applications can facilitate the decision-making process for Fog scheduler.}
}
@article{EMBARAK2021445,
title = {A New Paradigm Through Machine Learning: A Learning Maximization Approach for Sustainable Education},
journal = {Procedia Computer Science},
volume = {191},
pages = {445-450},
year = {2021},
note = {The 18th International Conference on Mobile Systems and Pervasive Computing (MobiSPC), The 16th International Conference on Future Networks and Communications (FNC), The 11th International Conference on Sustainable Energy Information Technology},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2021.07.055},
url = {https://www.sciencedirect.com/science/article/pii/S1877050921014551},
author = {Ossama Embarak},
keywords = {Theory of maximization model, machine learning in education, sustainable education system, education forms, sustainable education applications},
abstract = {Machine learning algorithms have been used to predict student performance in academic institutions over the last decade. The developed prediction models classified students as either those who were likely to receive a distinctive or those who were likely to be at-risk or withdraw from the class. Although, the early prediction aid in the targeting of educational interventions and achieved a more efficient allocation of educational resources. All proposed solutions fell within the scope of predictions that result in active or proactive actions to support universities and learners. On the other hand, they fail to comprehend the various forms of education systems and whether it appropriate for the twenty-first century and future generations. The paper classifies education into five types based on the design mode, the scope of production, and the interaction between learners and educational systems (Push, Pull, coupling, Integrated, and Sustainable). The paper proposes a sustainable education paradigm that maximizes the knowledge and skill matrix accumulated for the desired program. The proposed theory implementation phases are modelled and demonstrated using 21st-century technologies, such as personalized and coaching education based on the learner’s learning style and remediation actions for strong learners with innovative competencies. The study emphasized various aspects of sustainable education systems that are required for smart city transition. The limitations and proposed solutions for dealing with anticipated issues were demonstrated, and the benefits of sustainable education are based on the proposed maximization theory rather than the current block-based learning of outcomes.}
}
@article{BASSETTI2022237,
title = {ML-based re-orientation of smartphone-collected car motion data},
journal = {Procedia Computer Science},
volume = {198},
pages = {237-242},
year = {2022},
note = {12th International Conference on Emerging Ubiquitous Systems and Pervasive Networks / 11th International Conference on Current and Future Trends of Information and Communication Technologies in Healthcare},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2021.12.234},
url = {https://www.sciencedirect.com/science/article/pii/S187705092102473X},
author = {Enrico Bassetti and Alessio Luciani and Emanuele Panizzi},
keywords = {smartphone, parking, sensing, implicit interaction, machine learning, curb, parallel, angle parking, smart city, context aware},
abstract = {Smartphone sensors can collect data in many different contexts. They make it feasible to obtain large amounts of data at little or no cost because most people own mobile phones. In this work, we focus on the collection of smartphone data in the car. Motion sensors, such as accelerometers and gyroscopes, can help obtain information about the vehicle’s dynamics. The possible spatial orientations of the smartphone in the car are infinite, and this can be a problem in an attempt to extract patterns from the data. Thus, we propose an approach to automatically re-orient smartphone data collected in the car to a standardized orientation (i.e. with 0 yaw, roll, and pitch angles with respect to the vehicle). We use a combination of a least-square plane approximation and an ML model to infer the relative orientation angles. Then we populate rotation matrices and perform the data rotation. We trained the model by collecting data both in an actual vehicle and using a vehicle physics simulator.}
}
@article{SEMANJSKI201738,
title = {Spatial context mining approach for transport mode recognition from mobile sensed big data},
journal = {Computers, Environment and Urban Systems},
volume = {66},
pages = {38-52},
year = {2017},
issn = {0198-9715},
doi = {https://doi.org/10.1016/j.compenvurbsys.2017.07.004},
url = {https://www.sciencedirect.com/science/article/pii/S0198971516304367},
author = {Ivana Semanjski and Sidharta Gautama and Rein Ahas and Frank Witlox},
keywords = {Transport mode recognition, Mobile sensed big data, Spatial awareness, Geographic information systems, Smart city, Support vector machines, Context mining, Urban data},
abstract = {Knowledge about what transport mode people use is important information of any mobility or travel behaviour research. With ubiquitous presence of smartphones, and its sensing possibilities, new opportunities to infer transport mode from movement data are appearing. In this paper we investigate the role of spatial context of human movements in inferring transport mode from mobile sensed data. For this we use data collected from more than 8000 participants over a period of four months, in combination with freely available geographical information. We develop a support vectors machines-based model to infer five transport modes and achieve success rate of 94%. The developed model is applicable across different mobile sensed data, as it is independent on the integration of additional sensors in the device itself. Furthermore, suggested approach is robust, as it strongly relies on pre-processed data, which makes it applicable for big data implementations in (smart) cities and other data-driven mobility platforms.}
}
@article{GALANGARCIA2014557,
title = {An accelerated-time simulation for traffic flow in a smart city},
journal = {Journal of Computational and Applied Mathematics},
volume = {270},
pages = {557-563},
year = {2014},
note = {Fourth International Conference on Finite Element Methods in Engineering and Sciences (FEMTEC 2013)},
issn = {0377-0427},
doi = {https://doi.org/10.1016/j.cam.2013.11.020},
url = {https://www.sciencedirect.com/science/article/pii/S0377042713006523},
author = {José L. Galán-García and Gabriel Aguilera-Venegas and Pedro Rodríguez-Cielos},
keywords = {Accelerated-time simulations, Smart cities, Car traffic, CAS},
abstract = {Traffic control is one of the most important problems related with urban development. Current trends for traffic control are based on the use of smart traffic lights and signals as a part of smart cities’ projects. Different cities are currently involved in the design and implementation of smart traffic control. Since the cost of physically installing these systems is very high, in terms of both money and resources, accelerated-time simulations of traffic flow using smart traffic lights and signals significantly reduce these costs. In this work we present a new model for accelerated-time simulations for traffic flow within. The philosophy of this model is based on previous works of the authors, where accelerated-time simulations for car traffic in a motorway or a roundabout and baggage traffic in an airport were developed. The philosophy of this model combines ideas from cellular automata and neural network theories, obtaining a mixed model. This system was developed using a Computer Algebra System (CAS) called Maxima  for mathematical computations and a Java  based interface for graphical display. Maxima  allows the system to support the use of ad hoc distribution functions for the different events dealt with in the simulations. The interface provides a friendly framework for entering input data and visualizing the simulations, providing also some statistical data.}
}
@article{FERNANDEZ201463,
title = {Modeling energy consumption in automated vacuum waste collection systems},
journal = {Environmental Modelling & Software},
volume = {56},
pages = {63-73},
year = {2014},
note = {Thematic issue on Modelling and evaluating the sustainability of smart solutions},
issn = {1364-8152},
doi = {https://doi.org/10.1016/j.envsoft.2013.11.013},
url = {https://www.sciencedirect.com/science/article/pii/S1364815213003058},
author = {Cèsar Fernández and Felip Manyà and Carles Mateu and Francina Sole-Mauri},
keywords = {Waste collection, Smart city, Artificial intelligence, Constraint integer programming (CIP), Sustainability, Computational sustainability},
abstract = {In a world where resources are scarce and urban areas consume the vast majority of these resources, it is vital to make cities greener and more sustainable. A smart city is a city in which information and communications technology are merged with traditional infrastructures, coordinated and integrated using new digital technologies. The increasing amount of waste generated, and the collection and treatment of waste poses a major challenge to modern urban planning in general, and to smart cities in particular. To cope with this problem, automated vacuum waste collection (AVWC) uses air suction on a closed network of underground pipes to transport waste from the drop off points scattered throughout the city to a central collection point, reducing greenhouse gas emissions and the inconveniences of conventional methods (odours, noise, etc.). Since a significant part of the cost of operating AVWC systems is energy consumption, we have developed a model with the aim of applying constraint programming technology to schedule the daily emptying sequences of the drop off points in such a way that energy consumption is minimized. In this paper we describe how the problem of deciding the drop off points that should be emptied at a given time can be modeled as a constraint integer programming (CIP) problem. Moreover, we report on experiments using real data from AVWC systems installed in different cities that provide empirical evidence that CIP offers a suitable technology for reducing energy consumption in AVWC.}
}
@article{SHEN2020667,
title = {Urban acoustic classification based on deep feature transfer learning},
journal = {Journal of the Franklin Institute},
volume = {357},
number = {1},
pages = {667-686},
year = {2020},
issn = {0016-0032},
doi = {https://doi.org/10.1016/j.jfranklin.2019.10.014},
url = {https://www.sciencedirect.com/science/article/pii/S0016003219307446},
author = {Yexin Shen and Jiuwen Cao and Jianzhong Wang and Zhixin Yang},
abstract = {Urban acoustic classification (UAC) plays a vital role in smart city engineering, urban security, noise pollution analysis, etc. Convolutional neural networks (CNNs) based feature transfer learning have been shown competitive performance in many applications but little attention has been paid to UAC. In this study, a novel UAC algorithm exploiting the deep CNNs based feature transfer learning and the deep belief net (DBN) based classification is developed. The spectrogram is first adopted for the urban acoustic stream representation. Then, three deep CNNs pre-trained on ImageNet database are applied as feature extractors. The extracted features are concatenated and fed to a DBN for classifier learning. To achieve a good generalization performance, three restricted boltzmann machines (RBM) trained by the contrastive divergence algorithm (CD) followed by a back-propagation (BP) based fine parameter tuning is adopted in DBN. The proposed UAC is evaluated on a real acoustic database, including 11 categories of acoustic signals recorded from the urban environment. Performance comparisons to many state-of-the-art algorithms are presented to demonstrate the superiority of the proposed method.}
}
@article{MAKKAR2022103658,
title = {SecureEngine: Spammer classification in cyber defence for leveraging green computing in Sustainable city},
journal = {Sustainable Cities and Society},
volume = {79},
pages = {103658},
year = {2022},
issn = {2210-6707},
doi = {https://doi.org/10.1016/j.scs.2021.103658},
url = {https://www.sciencedirect.com/science/article/pii/S2210670721009215},
author = {Aaisha Makkar},
keywords = {Web spam, Green computing, PageRank, Security, Artificial intelligence},
abstract = {In today’s era, Sustainable city is evaluated using the services provided to the society. The designing of the integral part of the society should be focused towards the benefits of people. Internet is extensively utilized by the society using Search Engines. The accuracy and time it takes for different search engines to retrieve information from a cloud computing repository around the world, varies. However, it has been discovered in the literature that webpage ranking reduces the amount of time a user spends surfing, which saves a significant amount of energy during computation and transmission across the network. The hyperlink structure of the web graph is used in most of the earlier solutions documented in the literature, which consumes a lot of energy during calculation. It may exacerbate the link leakage problem by increasing the frequency of spam pages. In light of the energy consumption of various smart gadgets, hyperlink structure alone is no longer sufficient for predicting webpage relevance. Its true importance is revealed by user surfing activity. To improve search engine accuracy and speed, it is critical to demote spam pages, lowering energy consumption. Among all the existing ranking algorithms in the literature, one of the important components is the PageRank algorithm used by Google’s ranking module. Keeping focus on these points, in this paper, various page ranking algorithms based upon supervised learning are surveyed and summarized with respect to different selected parameters and experiments performed. Using this information, a detailed taxonomy of search engine results is presented in the text. Moreover, PageRank algorithms are explored by using different supervised learning techniques applied in the existing proposals for getting and processing the results. In the nutshell, the PageRank methodology is surveyed with respect to web spam detection which is the demand of cognitive systems in smart cities.}
}
@article{BUI2019222,
title = {Computational negotiation-based edge analytics for smart objects},
journal = {Information Sciences},
volume = {480},
pages = {222-236},
year = {2019},
issn = {0020-0255},
doi = {https://doi.org/10.1016/j.ins.2018.12.046},
url = {https://www.sciencedirect.com/science/article/pii/S002002551830985X},
author = {Khac-Hoai Nam Bui and Jason J. Jung},
keywords = {Internet of things, Edge analytics, Smart objects, Computational negotiation, Smart decision making},
abstract = {In this paper, we propose a computational negotiation approach on Internet of Things (IoT) system where distributed edge devices can make their own decisions for smart applications. Particularly, Artificial Intelligence (AI) techniques play an important role of edge analytics in order to adaptively improve the performance of IoT systems. In this regard, we apply several AI techniques to provide negotiation models (e.g., synchronization, competition, and cooperation) among connected objects for edge analytics. Moreover, in the context of smart city, two typical use cases on IoT applications have been presented to evaluate our proposed approach. They are i) smart traffic control and ii) smart home energy management system.}
}
@article{SLIMANI2020128,
title = {Road traffic forecasting using a real data set in Morocco},
journal = {Procedia Computer Science},
volume = {177},
pages = {128-135},
year = {2020},
note = {The 11th International Conference on Emerging Ubiquitous Systems and Pervasive Networks (EUSPN 2020) / The 10th International Conference on Current and Future Trends of Information and Communication Technologies in Healthcare (ICTH 2020) / Affiliated Workshops},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2020.10.020},
url = {https://www.sciencedirect.com/science/article/pii/S1877050920322857},
author = {Nadia Slimani and Ilham Slimani and Mustapha Amghar and Nawal Sbiti},
keywords = {Road traffic forecasting, artificial neural networks, MLP, statistical forecasting, SMOreg, SARIMA},
abstract = {Traffic forecasting is a research topic debated by several researchers affiliated to a range of disciplines. It is becoming increasingly important given the growth of motorized vehicles on the one hand, and the scarcity of lands for new transportation infrastructure on the other. In this context, the ability to provide highly accurate traffic forecasts is of fundamental importance to manage traffic, especially in the context of smart cities. This work is in line with this perspective and aims to solve this problem. The proposed methodology plans to forecast day-by-day traffic stream using three different models: the Multilayer Perceptron of Artificial Neural Networks (ANN), the Seasonal Autoregressive Integrated Moving Average (SARIMA) and the Support Machine Regression (SMOreg). Using those three models, the forecast is realized based on a history of real traffic data recorded on a road section over 42 months. Besides, a recognized traffic manager in Morocco provides this dataset; the performance is then tested based on predefined criteria. From the experiment results, it is clear that the proposed ANN model achieves highest prediction accuracy with the lowest absolute relative error of 0.57%.}
}
@article{GONZALEZVIDAL201971,
title = {A methodology for energy multivariate time series forecasting in smart buildings based on feature selection},
journal = {Energy and Buildings},
volume = {196},
pages = {71-82},
year = {2019},
issn = {0378-7788},
doi = {https://doi.org/10.1016/j.enbuild.2019.05.021},
url = {https://www.sciencedirect.com/science/article/pii/S0378778818338775},
author = {Aurora González-Vidal and Fernando Jiménez and Antonio F. Gómez-Skarmeta},
keywords = {Feature selection, Energy efficiency, Time series, Smart buildings, Smart cities},
abstract = {The massive collection of data via emerging technologies like the Internet of Things (IoT) requires finding optimal ways to reduce the created features that have a potential impact on the information that can be extracted through the machine learning process. The mining of knowledge related to a concept is done on the basis of the features of data. The process of finding the best combination of features is called feature selection. In this paper we deal with multivariate time-dependent series of data points for energy forecasting in smart buildings. We propose a methodology to transform the time-dependent database into a structure that standard machine learning algorithms can process, and then, apply different types of feature selection methods for regression tasks. We used Weka for the tasks of database transformation, feature selection, regression, statistical test and forecasting. The proposed methodology improves MAE by 59.97% and RMSE by 40.75%, evaluated on training data, and it improves MAE by 42.28% and RMSE by 36.62%, evaluated on test data, on average for 1-step-ahead, 2-step-ahead and 3-step-ahead when compared to not applying any feature selection methodology.}
}
@article{RAHMAN2020102324,
title = {Scalable machine learning-based intrusion detection system for IoT-enabled smart cities},
journal = {Sustainable Cities and Society},
volume = {61},
pages = {102324},
year = {2020},
issn = {2210-6707},
doi = {https://doi.org/10.1016/j.scs.2020.102324},
url = {https://www.sciencedirect.com/science/article/pii/S221067072030545X},
author = {Md Arafatur Rahman and A. Taufiq Asyhari and L.S. Leong and G.B. Satrya and M. {Hai Tao} and M.F. Zolkipli},
keywords = {Feature extraction, Feature selection, IDS, Intrusion detection, IoT, Machine learning, Semi-distributed, Distributed},
abstract = {Given a scale expansion of Internet of Things for sustainable resource management in smart cities, proper design of an intrusion detection system (IDS) is critical to safeguard the future network infrastructure from intruders. With the growth of connected things, the most-widely used centralized (cloud-based) IDS often suffers from high latency and network overhead, thereby resulting in unresponsiveness to attacks and slow detection of malicious users. In this paper, we address the limitation of centralized IDS for resource-constrained devices by proposing two methods, namely semi-distributed and distributed, that combine well-performing feature extraction and selection and exploit potential fog-edge coordinated analytics. In order to distribute the computational tasks, we individually develop parallel machine-learning models corresponding to a partitioned attack dataset. In the semi-distributed case, the parallel models, running on the edge side, are applied for side-by-side feature selections, which are then followed by a single multi-layer perceptron classification running on the fog side. In the distributed case, the parallel models individually perform both the feature selection and multi-layer perceptron classification after which the outputs are combined by a coordinating edge or fog for final decision making. Based on the comparative study of existing works, the numerical results demonstrate the promise of the proposed methods, giving a comparable detection accuracy to the superior centralized IDS as well as exemplify their inherent trade-offs between the accuracy and building time performance.}
}
@article{RIVAS2022,
title = {Towards automatic model specialization for edge video analytics},
journal = {Future Generation Computer Systems},
year = {2022},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2022.03.039},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X22001200},
author = {Daniel Rivas and Francesc Guim and Jordà Polo and Pubudu M. Silva and Josep Ll. Berral and David Carrera},
keywords = {Model specialization, Computer vision, Edge cloud, Cova framework, Real-time video analytics},
abstract = {The number of cameras deployed to the edge of the network increases by the day, while emerging use cases, such as smart cities or autonomous driving, also grow to expect images to be analyzed in real-time by increasingly accurate and complex neural networks. Unfortunately, state-of-the-art accuracy comes at a computational cost rarely available in the edge cloud. At the same time, due to strict latency constraints and the vast amount of bandwidth edge cameras generate, we can no longer rely on offloading the task to a centralized cloud. Consequently, there is a need for a meeting point between the resource-constrained edge cloud and accurate real-time video analytics. If state-of-the-art models are too expensive to run on the edge, and lightweight models are not accurate enough for the use cases in the edge, one solution is to demand less from the lightweight model and specialize it in a narrower scope of the problem, a technique known as model specialization. By specializing a model to the context of a single camera, we can boost its accuracy while keeping its computational cost constant. However, this also involves one training per camera, which quickly becomes unfeasible unless the entire process is fully automated. In this paper, we present and evaluate COVA (Contextually Optimized Video Analytics), a framework to assist in the automatic specialization of models for video analytics in edge cloud cameras. COVA aims to automatically improve the accuracy of lightweight models by specializing them to the context to which they will be deployed. Moreover, we discuss and analyze each step involved in the process to understand the different trade-offs that each one entails. Using COVA, we demonstrate that the whole pipeline can be effectively automated by leveraging large neural networks used as teachers whose predictions are used to train and specialize lightweight neural networks. Results show that COVA can automatically improve pre-trained models by an average of 21% mAP on the different scenes of the VIRAT dataset.}
}
@article{VALERIO201827,
title = {Energy efficient distributed analytics at the edge of the network for IoT environments},
journal = {Pervasive and Mobile Computing},
volume = {51},
pages = {27-42},
year = {2018},
issn = {1574-1192},
doi = {https://doi.org/10.1016/j.pmcj.2018.09.004},
url = {https://www.sciencedirect.com/science/article/pii/S1574119218300932},
author = {Lorenzo Valerio and Marco Conti and Andrea Passarella},
keywords = {Iot, Big data, Smart cities, Distributed learning, Communications efficiency},
abstract = {Due to the pervasive diffusion of personal mobile and IoT devices, many “smart environments” (e.g., smart cities and smart factories) will be, generators of huge amounts of data. Currently, analysis of this data is typically achieved through centralised cloud-based services. However, according to many studies, this approach may present significant issues from the standpoint of data ownership, as well as wireless network capacity. In this paper, we exploit the fog computing paradigm to move computation close to where data is produced. We exploit a well-known distributed machine learning framework (Hypothesis Transfer Learning), and perform data analytics on mobile nodes passing by IoT devices, in addition to fog gateways at the edge of the network infrastructure. We analyse the performance of different configurations of the distributed learning framework, in terms of (i) accuracy obtained in the learning task and (ii) energy spent to send data between the involved nodes. Specifically, we consider reference wireless technologies for communication between the different types of nodes we consider, e.g. LTE, Nb-IoT, 802.15.4, 802.11, etc. Our results show that collecting data through the mobile nodes and executing the distributed analytics using short-range communication technologies, such as 802.15.4 and 802.11, allows to strongly reduce the energy consumption of the system up to 94% with a loss in accuracy w.r.t. a centralised cloud solution up to 2%.}
}
@article{CUBRIC2020101257,
title = {Drivers, barriers and social considerations for AI adoption in business and management: A tertiary study},
journal = {Technology in Society},
volume = {62},
pages = {101257},
year = {2020},
issn = {0160-791X},
doi = {https://doi.org/10.1016/j.techsoc.2020.101257},
url = {https://www.sciencedirect.com/science/article/pii/S0160791X19307171},
author = {Marija Cubric},
keywords = {Artificial intelligence, Business, Machine learning, Management, Systematic literature review, Tertiary study},
abstract = {The number of academic papers in the area of Artificial Intelligence (AI) and its applications across business and management domains has risen significantly in the last decade, and that rise has been followed by an increase in the number of systematic literature reviews. The aim of this study is to provide an overview of existing systematic reviews in this growing area of research and to synthesise the findings related to drivers, barriers and social implications of the AI adoption in business and management. The methodology used for this tertiary study is based on Kitchenham and Charter's guidelines [14], resulting in a selection of 30 reviews published between 2005 and 2019 which are reporting results of 2021 primary studies. These reviews cover the AI adoption across various business sectors (healthcare, information technology, energy, agriculture, apparel industry, engineering, smart cities, tourism and transport), management and business functions (HR, customer services, supply chain, health and safety, project management, decision-support, systems management and technology adoption). While the drivers for the AI adoption in these areas are mainly economic, the barriers are related to the technical aspects (e.g. availability of data, reusability of models) as well as the social considerations such as, increased dependence on non-humans, job security, lack of knowledge, safety, trust and lack of multiple stakeholders’perspectives. Very few reviews outside of the healthcare management domain consider human, organisational and wider societal factors of the AI adoption. In addition to increased focus on social implications of AI, the reviews are recommending more rigorous evaluation, increased use of hybrid solutions (AI and non-AI) and multidisciplinary approach to AI design and evaluation. Furthermore, this study found that there is a lack of systematic reviews in some of the early AI adoption sectors such as financial industry and retail.}
}
@article{SINGH2020125590,
title = {Prediction of arsenic vulnerable zones in the groundwater environment of a rapidly urbanizing setup, Guwahati, India},
journal = {Geochemistry},
volume = {80},
number = {4, Supplement },
pages = {125590},
year = {2020},
issn = {0009-2819},
doi = {https://doi.org/10.1016/j.chemer.2019.125590},
url = {https://www.sciencedirect.com/science/article/pii/S0009281919300649},
author = {Ashwin Singh and Arbind Kumar Patel and Jyoti Prakash Deka and Aparna Das and Abhay Kumar and Manish Kumar},
keywords = {Urbanisation, Groundwater, Vulnerability, Artificial Neural Network (ANN), LULC, Smart city, Guwahati},
abstract = {The present study, through a multi model assessment approach emphasizes the relevance of prior urban settlement planning with respect to the changing land use pattern. A coupled approach integrating satellite data products of Land Use and Land Cover (LULC) change along with chemical evaluation of As toxicity were modelled to evaluate the groundwater vulnerability. Change detection analysis was incorporated using the satellite images of 2013 and 2016 which shows 10 % increase in the buildings as compared to the total area of the study in given period. The LULC class that has been most compromised in this expansion and got reduced were the vegetation (∼6 %) and the barren areas (∼4 %) and the total surface water sources (0.5 %), all contributing in increased urban sprawl. As per the origin of As contamination in the area it seems that high sediment deposition along the braided Brahmaputra River stretch leads to As contamination which was associated with Fe-(oxy)-hydroxide dissolution. The vulnerability assessment using Artificial Neural Network technique in this region shows that As is present relatively in lesser concentration in the east direction. The continuous expansion of the urban habitation towards the greater As concentration zone will further make the situation critical for the people dependent on groundwater. The study suggests that prior settlement planning must be carried out in accordance to the presence of any toxic constituent in drinking water source to avoid future crisis for potable water.}
}
@article{LEVINGER2020176,
title = {Human satisfaction as the ultimate goal in ridesharing},
journal = {Future Generation Computer Systems},
volume = {112},
pages = {176-184},
year = {2020},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2020.05.028},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X19302249},
author = {Chaya Levinger and Noam Hazon and Amos Azaria},
keywords = {Ride-sharing, Modeling human behavior, Human–agent interaction, Smart-cities},
abstract = {Transportation services play a crucial part in the development of modern smart cities. In particular, on-demand ridesharing services, which group together passengers with similar itineraries, are already operating in several metropolitan areas. These services can be of significant social and environmental benefit, by reducing travel costs, road congestion and CO2 emissions. The deployment of autonomous cars in the near future will surely change the way people are traveling. It is even more promising for a ridesharing service, since it will be easier and cheaper for a company to handle a fleet of autonomous cars that can serve the demands of different passengers. We argue that user satisfaction should be the main objective when trying to find the best assignment of passengers to vehicles and the determination of their routes. Moreover, the model of user satisfaction should be rich enough to capture the traveling time, cost, and other factors as well. We show that it is more important to capture a rich model of human satisfaction than peruse an optimal performance. That is, we developed a practical algorithm for assigning passengers to vehicles, which outperforms brute-force assignment algorithms that use a simpler satisfaction model. To the best of our knowledge, this is the first paper to exclusively concentrate on a rich and realistic general function of user satisfaction as the objective, which is (arguably) the most important aspect to consider for achieving a widespread adaption of ridesharing services.}
}
@article{CHEN202123,
title = {A mutual information based federated learning framework for edge computing networks},
journal = {Computer Communications},
volume = {176},
pages = {23-30},
year = {2021},
issn = {0140-3664},
doi = {https://doi.org/10.1016/j.comcom.2021.05.013},
url = {https://www.sciencedirect.com/science/article/pii/S0140366421001973},
author = {Naiyue Chen and Yinglong Li and Xuejun Liu and Zhenjiang Zhang},
keywords = {Intelligent edge computing, Federated learning, Mutual information},
abstract = {With the application of artificial intelligence in all field of life, people pay more attention to user privacy and data security. Under the condition of protecting user privacy, the federated learning model has become a popular research technology to solve the data islands problems. The edge computing network can be applied to smart city, Internet of vehicles and so on. Federated learning is a framework in which multiple hosts jointly learn a machine learning model. Each work device maintains the local model of its local training dataset, while the master device maintains the global model by aggregating the local models from the work devices. However, it cannot ensure that every local work device is an honest user because of a phenomenon that the hosts has been operated by attacker interferes in the process of local model training. In this paper, we assume that malicious nodes upload unreal learning parameters in the federated learning framework, which the global model will have high error rate. We propose a federated learning parameter aggregating algorithm based on mutual information. We introduced the relevance of model training learning rate to determine the consistency of the training direction of the local and central models at coarse granularity. We aggregated the parameters of the models at fine granularity based on the correlation of the gradients based on the mutual information. The mutual information method is used to calculate the similarity of the gradient trend between the local training model and overall model. We set the trust weight of each work device to reduce the negative impact of malicious nodes. The evaluation results show that the classification accuracy of the MIFL model is improved as compared with the average federated learning without malicious node. Especially, in the case of existing malicious nodes, the proposed algorithm can defend against malicious node attacks and sustain the robustness of Federated learning.}
}
@article{SINGH2020721,
title = {BlockIoTIntelligence: A Blockchain-enabled Intelligent IoT Architecture with Artificial Intelligence},
journal = {Future Generation Computer Systems},
volume = {110},
pages = {721-743},
year = {2020},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2019.09.002},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X19316474},
author = {Sushil Kumar Singh and Shailendra Rathore and Jong Hyuk Park},
keywords = {Artificial intelligence, Blockchain, Internet of things, Big data analysis, Security and privacy},
abstract = {In the recent year, Internet of Things (IoT) is industrializing in several real-world applications such as smart transportation, smart city to make human life reliable. With the increasing industrialization in IoT, an excessive amount of sensing data is producing from various sensors devices in the Industrial IoT. To analyzes of big data, Artificial Intelligence (AI) plays a significant role as a strong analytic tool and delivers a scalable and accurate analysis of data in real-time. However, the design and development of a useful big data analysis tool using AI have some challenges, such as centralized architecture, security, and privacy, resource constraints, lack of enough training data. Conversely, as an emerging technology, Blockchain supports a decentralized architecture. It provides a secure sharing of data and resources to the various nodes of the IoT network is encouraged to remove centralized control and can overcome the existing challenges in AI. The main goal of our research is to design and develop an IoT architecture with blockchain and AI to support an effective big data analysis. In this paper, we propose a Blockchain-enabled Intelligent IoT Architecture with Artificial Intelligence that provides an efficient way of converging blockchain and AI for IoT with current state-of-the-art techniques and applications. We evaluate the proposed architecture and categorized into two parts: qualitative analysis and quantitative analysis. In qualitative evaluation, we describe how to use AI and Blockchain in IoT applications with “AI-driven Blockchain” and “Blockchain-driven AI.” In quantitative analysis, we present a performance evaluation of the BlockIoTIntelligence architecture to compare existing researches on device, fog, edge and cloud intelligence according to some parameters such as accuracy, latency, security and privacy, computational complexity and energy cost in IoT applications. The evaluation results show that the proposed architecture performance over the existing IoT architectures and mitigate the current challenges.}
}
@article{KHAIRE2022301346,
title = {A semi-supervised deep learning based video anomaly detection framework using RGB-D for surveillance of real-world critical environments},
journal = {Forensic Science International: Digital Investigation},
volume = {40},
pages = {301346},
year = {2022},
issn = {2666-2817},
doi = {https://doi.org/10.1016/j.fsidi.2022.301346},
url = {https://www.sciencedirect.com/science/article/pii/S2666281722000154},
author = {Pushpajit Khaire and Praveen Kumar},
keywords = {Surveillance, Anomaly detection, RGB-D, Deep learning, Bank-ATM, Crime, Real world environments, Bi-LSTM, Auto-encoder},
abstract = {Video surveillance has become very important in the current era of smart cities. Large amounts of surveillance cameras are deployed at public and private places for surveillance of infrastructural property and public safety. These surveillance cameras generate huge amount of video data and it is impractical for a human observer to continuously monitor these long-hour videos manually and detect any unwanted or anomalous event. This paper presents a multi-modal semi-supervised deep learning based CNN-BiLSTM autoencoder framework to detect anomalous events in critical surveillance environments like Bank-ATMs. The significance of the framework is that it only requires weakly labelled normal video samples for training. We leverage the power of transfer learning by extracting important video features using a compact pretrained CNN to significantly reduce the computational complexity of training and detection. Moreover, due to the unavailability of any dataset for ATM surveillance in the public domain, we also contributed a unique RGB + D dataset for surveillance of ATMs. The proposed framework is tested on the collected RGB + D dataset and other real-world benchmark video anomaly datasets: Avenue and UCFCrime2Local. Results show that the proposed framework gives competitive results with other state-of-the-art methods and can be applied to both indoor and outdoor environments for detection of anomalies in real-world surveillance sites.}
}
@article{VLAHOGIANNI2016192,
title = {A Real-Time Parking Prediction System for Smart Cities},
journal = {Journal of Intelligent Transportation Systems},
volume = {20},
number = {2},
pages = {192-204},
year = {2016},
issn = {1547-2450},
doi = {https://doi.org/10.1080/15472450.2015.1037955},
url = {https://www.sciencedirect.com/science/article/pii/S1547245022000500},
author = {Eleni I. Vlahogianni and Konstantinos Kepaptsoglou and Vassileios Tsetsos and Matthew G. Karlaftis},
keywords = {Duration Modeling, Internet of Things, Neural Networks, Parking Occupancy, Parking Sensors, Smart City},
abstract = {ABSTRACT
A methodological framework for multiple steps ahead parking availability prediction is presented. Two different types of predictions are provided: the probability of a free space to continue being free in subsequent time intervals, and the short-term parking occupancy prediction in selected regions of an urban road network. The available data come from a wide network of on-street parking sensors in the “smart” city of Santander, Spain. The sensor network is segmented in four different regions, and then survival and neural network models are developed for each region separately. Findings show that the Weibull parametric models best describe the probability of a parking space to continue to be free in the forthcoming time intervals. Moreover, simple genetically optimized multilayer perceptrons accurately predict region parking occupancy rates up to 30 minutes in the future by exploiting 1-minute data. Finally, the real time, Web-based, implementation of the proposed parking prediction availability system is presented.}
}
@article{DAWOUD201882,
title = {Deep learning and software-defined networks: Towards secure IoT architecture},
journal = {Internet of Things},
volume = {3-4},
pages = {82-89},
year = {2018},
issn = {2542-6605},
doi = {https://doi.org/10.1016/j.iot.2018.09.003},
url = {https://www.sciencedirect.com/science/article/pii/S2542660518300593},
author = {Ahmed Dawoud and Seyed Shahristani and Chun Raun},
keywords = {Internet of Things, Software-defined networks, Anomalies detection, Deep learning, Restricted-Boltzmann machines},
abstract = {Internet of Things (IoT) introduces new challenges to conventional communication model. IoT networks characteristics, such as objects heterogeneity and scalability, require revolutionary solutions. Currently, there is no universal architecture for IoT. However, several architectures were proposed based on Software Defined Networks (SDN). SDN introduces network programmability, and centralisation, these features facilitate network abstractions, simplifying network management and eases evolution. In this paper, we investigate SDN as a novel communication architecture for IoT networking to enhance the security and resilience of IoT. SDN enhances network resilience and scalability which are essential in large-scale IoT deployments, e.g., smart cities. However, security is a significant concern for IoT while SDN deepens these concerns. SDN itself presents new security threats; specifically, threats related to the controller. We propose a secure, framework for IoT based on SDN. The framework is generalization for the integration of SDN and IoT. We focus on massive IoT deployment, for instance, smart cities applications, where, security is critical, and network traffic is enormous. The study investigates the SDN architecture from a security perspective. Improving SDN security will boost the deployment of SDN-based IoT architecture. We deploy an Intrusion detection system based on Deep Learning (DL). The detection module uses Restricted Boltzmann Machines (RBM). The precision rate shows significant improvements over standard ML, e.g. SVM and PCA.}
}
@article{VASHISHTHA2020334,
title = {DMAPS: An Effective and Efficient Way for the Air Purification of the Outdoors: (Deep-mind Air Purification System for a smart city)},
journal = {Procedia Computer Science},
volume = {167},
pages = {334-343},
year = {2020},
note = {International Conference on Computational Intelligence and Data Science},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2020.03.233},
url = {https://www.sciencedirect.com/science/article/pii/S1877050920306992},
author = {Pranavi Vashishtha and Tanupriya Choudhury},
keywords = {Deep reinforcement learning, Arduino, YOLO algorithm, artificially intelligent},
abstract = {The air pollution these days is a serious environmental concern and it is not just a mere fact but a harsh reality which is creating problems for the mankind such as some serious health issues. In some parts of the world the air quality index have reached to an irrefutable level which demands for a solution now. Hence, the purpose of this paper is to tackle this problem at a large scale by providing with an artificially intelligent mobile air purifier for “outdoors”. The main problem of DMAPS is to provide with purified air in the outdoors, such as a residential colony, in apartments, office complex, etc. since most of the times people travel outdoors and stay away from their home for a long time. This ability of providing with such a smart-sensing, self-driving machine is the advantage of the paper because other air purifiers exist but they are made for indoors, they do not have mobility and also do not possess AI capabilities. The method used in this air purifier is formulated by connecting three major functions. The first one being, ‘the smart mobility’ of the machine using the approach of deep reinforcement learning, the second is the air ‘purification using the Arduino system’ and the last is, ‘the detection of humans’ so that DMAPS can be around them and provide them with purified air, based on the YOLO algorithm. The whole system, works in a way that each and every function is very much connected and works simultaneously. In a nutshell, this air purifier, moves from one place (where there is low pollution content) to another place (where there is higher pollution content), purifies the environment and simultaneously have an objective to smartly detect humans to give out fresh air to them. Hence, in this way the whole methodology tries to fix the problem of air pollution by purifying the air outdoors to make it safe to inhale.}
}
@article{IQBAL2018291,
title = {An enhanced framework for multimedia data: Green transmission and portrayal for smart traffic system},
journal = {Computers & Electrical Engineering},
volume = {67},
pages = {291-308},
year = {2018},
issn = {0045-7906},
doi = {https://doi.org/10.1016/j.compeleceng.2018.03.021},
url = {https://www.sciencedirect.com/science/article/pii/S0045790617332469},
author = {Muhamad Munwar Iqbal and Muhammad Tahir Mehmood and Sohail Jabbar and Shehzad Khalid and Awais Ahmad and Gwanggil Jeon},
keywords = {Internet of thing, Big data, Cloud computing, Green transmission, Artificial Neural Network, Object tracking},
abstract = {The object tracking in video surveillance for intelligent traffic handling in smart cities requires an enormous amount of data called big data to be transmitted over the network using the Internet of Things. Manual monitoring and surveillance are impossible because traditional computer vision technologies are no more useful for massive processing and intelligent decision making. In this paper, a framework is proposed which enables both on spot data processing and intelligent decision making by using cloud computing. The developed application is a trained on Artificial Neural Network, which can handle different traffic techniques with congested traffic scenario and priorities traffic such as ambulance handling. The Message Queue Telemetry Transport protocol is used for green transmission with mobile access to traffic data. The results analyzed with thirty videos processed data which handle real-time data prioritization for the people for smart surveillance to fastest route and enhance the intelligent data transmission.}
}
@article{HASSAN2021102045,
title = {Leveraging Deep Learning and SNA approaches for Smart City Policing in the Developing World},
journal = {International Journal of Information Management},
volume = {56},
pages = {102045},
year = {2021},
issn = {0268-4012},
doi = {https://doi.org/10.1016/j.ijinfomgt.2019.102045},
url = {https://www.sciencedirect.com/science/article/pii/S0268401219302129},
author = {Saeed-Ul Hassan and Mudassir Shabbir and Sehrish Iqbal and Anwar Said and Faisal Kamiran and Raheel Nawaz and Umar Saif},
keywords = {Smart City, Criminal Social Network, Criminal Prediction Modelling, Low-Cost Solution, Graph Convolutional Network},
abstract = {Is it possible to identify crime suspects by their mobile phone call records? Can the spatial-temporal movements of individuals linked to convicted criminals help to identify those who facilitate crime? Might we leverage the usage of mobile phones, such as incoming and outgoing call numbers, coordinates, call duration and frequency of calls, in a specific time window on either side of a crime to provide a focus for the location and period under investigation? Might the call data records of convicted criminals' social networks serve to distinguish criminals from non-criminals? To address these questions, we used heterogeneous call data records dataset by tapping into the power of social network analysis and the advancements in graph convolutional networks. In collaboration with the Punjab Police and Punjab Information Technology Board, these techniques were useful in identifying convicted individuals. The approaches employed are useful in identifying crime suspects and facilitators to support smart policing in the fight against the country's increasing crime rates. Last but not least, the applied methods are highly desirable to complement high-cost video-based smart city surveillance platforms in developing countries.}
}
@article{JING2020104025,
title = {Building NAS: Automatic designation of efficient neural architectures for building extraction in high-resolution aerial images},
journal = {Image and Vision Computing},
volume = {103},
pages = {104025},
year = {2020},
issn = {0262-8856},
doi = {https://doi.org/10.1016/j.imavis.2020.104025},
url = {https://www.sciencedirect.com/science/article/pii/S0262885620301578},
author = {Weipeng Jing and Jingbo Lin and Huihui Wang},
keywords = {Convolutional neural network, Deep learning, Aerial images, Semantic segmentation, Neural architecture search},
abstract = {Building extraction, which is a fundamental task in the community of remote sensing image analysis, has been extensively applied in various applications related to smart cities. Due to the complicated background information in urban areas, how to extract building footprints from high-resolution aerial images is challenging. The recent achievements of deep learning have shed light on building extraction and other remote sensing domain tasks. However, the heavy consumption of computational resources and the design of the neural architectures became the biggest bottleneck of utilizing deep learning techniques to improve the performance. In this work, we developed a Neural Architecture Search (NAS) algorithm, dubbed BuildingNAS, for building extraction from high-resolution aerial images. In particular, we built an efficient candidate operation set upon Separable Factorized Residual Blocks as our cell-level search space. Different from previous NAS in semantic segmentation tasks, we employed the hierarchical search space and proposed the Single-Path Sampling strategy to eliminate excessive GPU memory comsumption in searching process. In addition, we proposed an entropy regularized objective for the optimization of architecture parameters. As the result, the larger batch size can be adopted in the whole pipeline to accelerate the searching process, and make the resulted architecture more stable and accurate. We evaluated our proposed algorithm in WHUBuilding Dataset, the derived network achieved mIoU of 86.95% with only 2.05G FLOPs and 3.10 M parameters. The comparison results demonstrate that the network discovered by our algorithm can achieve great efficiency-accuracy trade-off.}
}
@article{DU2021114571,
title = {Deep learning with long short-term memory neural networks combining wavelet transform and principal component analysis for daily urban water demand forecasting},
journal = {Expert Systems with Applications},
volume = {171},
pages = {114571},
year = {2021},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2021.114571},
url = {https://www.sciencedirect.com/science/article/pii/S0957417421000129},
author = {Baigang Du and Qiliang Zhou and Jun Guo and Shunsheng Guo and Lei Wang},
keywords = {Urban water demand forecasting, Long short-term memory network, Discrete wavelet transform, Principal components analysis},
abstract = {A reliable and accurate urban water demand forecasting plays a significant role in building intelligent water supplying system and smart city. Due to the high frequency noise and complicated relationships in water demand series, forecasting the urban water demand is not an easy task. In order to improve the model’s abilities in handling the complex patterns and catching the peaks in time series, we propose a hybrid long short-term memory model combining with discrete wavelet transform (DWT) and principal component analysis (PCA) pre-processing techniques for water demand forecasting, i.e., DWT-PCA-LSTM. First, the outliers of water demand series are identified and smoothed by 3σ criterion and weighted average method, respectively. Then, the noise component of water demand series is eliminated by DWT method and the principal components (PCs) among influencing factors of water demand are selected by PCA method. In addition, two LSTM networks are built to yield the daily urban water demand predictions using the results of DWT and PCA techniques. At last, the superiorities of the proposed model are demonstrated by comparing with the other benchmark predictive models. The water demand from 2016 to 2020 of a waterworks located in Suzhou, China is used for the experiment. The predictive performance of the experiments are evaluated by the mean absolute percentage error (MAPE), mean absolute percentage errors of peaks (pMAPE), explain variance score (EVS) and correlation coefficient (R). The results show that the DWT-PCA-LSTM model outperforms the other models and has satisfactory performance both in catching the peaks and the average prediction accuracy.}
}
@article{TIAN2020620,
title = {Predictive model of energy consumption for office building by using improved GWO-BP},
journal = {Energy Reports},
volume = {6},
pages = {620-627},
year = {2020},
issn = {2352-4847},
doi = {https://doi.org/10.1016/j.egyr.2020.03.003},
url = {https://www.sciencedirect.com/science/article/pii/S2352484719312387},
author = {Ying Tian and Junqi Yu and Anjun Zhao},
keywords = {Building electrical load prediction, BP neural network, Fuzzy C-means clustering algorithm, Grey wolf optimizer algorithm},
abstract = {Building energy data analysis is a major branch of smart city development research. The usual back propagation neural network model for building energy prediction has problems of unclear physical significance, poor data generalization and low fitting accuracy. Therefore, a composite prediction model of building power consumption based on FCM-GWO-BP neural network was proposed. According to the similar statistical distribution characteristics of data, the fuzzy C-means clustering algorithm (FCM) was used to cluster the historical power consumption data. BP neural network prediction model was established for different categories to reduce the impact of relevant noise in the sample data on the modeling accuracy. Then, according to the train and test data sets of each category, the corresponding grey wolf algorithm was established to optimize the error back propagation neural network prediction model (GWO-BP). The experimental results showed that compared with the sample prediction accuracy index root mean square percentage error (RMSPE), the GWO-BP neural network after FCM clustering was reduced by about 0.225 compared with the BP model, and was reduced by about 0.135 compared with the GWO-BP model, so its prediction accuracy was improved by 75% at most. Respectively, the mean absolute percentage error (MAPE) was reduced by 14.41% and 6.48%. It can be seen that this model has strong generalization ability, better prediction accuracy and reliability, and absolutely can meet the needs of practical engineering.}
}
@article{FANITABASI2020541,
title = {A self-integration testbed for decentralized socio-technical systems},
journal = {Future Generation Computer Systems},
volume = {113},
pages = {541-555},
year = {2020},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2020.07.036},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X20303435},
author = {Farzam Fanitabasi and Edward Gaere and Evangelos Pournaras},
keywords = {Internet of Things, Testbed architecture, Socio-technical system, Self-integration, Decentralized systems, Multi-agent system},
abstract = {The Internet of Things (IoT) comes along with new challenges for experimenting, testing, and operating decentralized socio-technical systems at large-scale. In such systems, autonomous agents interact locally with their users, and remotely with other agents to make intelligent collective choices. Via these interactions they self-regulate the consumption and production of distributed (common) resources, e.g., self-management of traffic flows and power demand in Smart Cities. While such complex systems are often deployed and operated using centralized computing infrastructures, the socio-technical nature of these decentralized systems requires new value-sensitive design paradigms; empowering trust, transparency, and alignment with citizens’ social values, such as privacy preservation, autonomy, and fairness among citizens’ choices. Currently, instruments and tools to study such systems and guide the prototyping process from simulation, to live deployment, and ultimately to a robust operation of a high Technology Readiness Level (TRL) are missing, or not practical in this distributed socio-technical context. This paper bridges this gap by introducing a novel testbed architecture for decentralized socio-technical systems running on IoT. This new architecture is designed for a seamless reusability of (i) application-independent decentralized services by an IoT application, and (ii) different IoT applications by the same decentralized service. This dual self-integration promises IoT applications that are simpler to prototype, and can interoperate with decentralized services during runtime to self-integrate more complex functionality, e.g., data analytics, distributed artificial intelligence. Additionally, such integration provides stronger validation of IoT applications, and improves resource utilization, as computational resources are shared, thus cutting down deployment and operational costs. Pressure and crash tests during continuous operations of several weeks, with more than 80K network joining and leaving of agents, 2.4M parameter changes, and 100M communicated messages, confirm the robustness and practicality of the testbed architecture. This work promises new pathways for managing the prototyping and deployment complexity of decentralized socio-technical systems running on IoT, whose complexity has so far hindered the adoption of value-sensitive self-management approaches in Smart Cities.}
}
@article{LIU2020102363,
title = {Edge sensing data-imaging conversion scheme of load forecasting in smart grid},
journal = {Sustainable Cities and Society},
volume = {62},
pages = {102363},
year = {2020},
issn = {2210-6707},
doi = {https://doi.org/10.1016/j.scs.2020.102363},
url = {https://www.sciencedirect.com/science/article/pii/S2210670720305849},
author = {Xiaozhu Liu and Zhiyang Xiao and Rongbo Zhu and Jun Wang and Lu Liu and Maode Ma},
keywords = {Empirical mode decomposition, Data-image conversion, Load forecasting, Smart grid, Edge intelligence},
abstract = {Edge sensing data in smart grid provides vast valuable information, which promotes further innovated smart power applications in Internet of things (IoT) oriented smart cities and society. While in power load prediction, the potential relationships between the time series of power load data and the characteristics of temperature, weather and date, have not been explored comprehensively, which degrades the accuracy of load prediction in smart grid. In order to extract the generalized features and latent relationships in power load related edge sensing data, a power load prediction scheme based on edge sensing data-imaging conversion (DIC) is proposed to improve the forecasting accuracy in smart cites and society. DIC employs empirical mode decomposition (EMD) for power load time series data and combines it with characteristic time series including temperature, weather and date to form an image-like structure. And a DIC-based convolutional neural network (DI-CNN) is presented to implement convolution. Experimental results show that, compared with long short-term memory (LSTM), support vector machines (SVM), and CNN, the proposed DIC scheme improves the training speed by 61.7 %, reduces root mean square error (RMSE) by 32.9 % at least, and enhances the prediction accuracy by 1.4 %.}
}
@article{JAVED2021102572,
title = {Automated cognitive health assessment in smart homes using machine learning},
journal = {Sustainable Cities and Society},
volume = {65},
pages = {102572},
year = {2021},
issn = {2210-6707},
doi = {https://doi.org/10.1016/j.scs.2020.102572},
url = {https://www.sciencedirect.com/science/article/pii/S2210670720307903},
author = {Abdul Rehman Javed and Labiba Gillani Fahad and Asma Ahmad Farhan and Sidra Abbas and Gautam Srivastava and Reza M. Parizi and Mohammad S. Khan},
keywords = {Cognitive assessment, Healthcare, Internet of Things, Remote Monitoring, Smart cities, Smart homes, Sustainability, MCI, Dementia, Machine learning},
abstract = {The Internet of Things (IoT) provides smart solutions for future urban communities to address key benefits with the least human intercession. A smart home offers the necessary capabilities to promote efficiency and sustainability to a resident with their healthcare-related, social, and emotional needs. In particular, it provides an opportunity to assess the functional health ability of the elderly or individuals with cognitive impairment in performing daily life activities. This work proposes an approach named Cognitive Assessment of Smart Home Resident (CA-SHR) to measure the ability of smart home residents in executing simple to complex activities of daily living using pre-defined scores assigned by a neuropsychologist. CA-SHR also measures the quality of tasks performed by the participants using supervised classification. Furthermore, CA-SHR provides a temporal feature analysis to estimate if the temporal features help to detect impaired individuals effectively. The goal of this study is to detect cognitively impaired individuals in their early stages. CA-SHR assess the health condition of individuals through significant features and improving the representation of dementia patients. For the classification of individuals into healthy, Mild Cognitive Impaired (MCI), and dementia categories, we use ensemble AdaBoost. This results in improving the reliability of the CA-SHR through the correct assignment of labels to the smart home resident compared with existing techniques.}
}
@article{DIN2019826,
title = {Machine learning in the Internet of Things: Designed techniques for smart cities},
journal = {Future Generation Computer Systems},
volume = {100},
pages = {826-843},
year = {2019},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2019.04.017},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X19304030},
author = {Ikram Ud Din and Mohsen Guizani and Joel J.P.C. Rodrigues and Suhaidi Hassan and Valery V. Korotaev},
keywords = {Internet of Things, Machine learning, Medical, Smart grid, VANET},
abstract = {Machine learning is one of the emerging technologies that has grabbed the attention of academicians and industrialists, and is expected to evolve in the near future. Machine learning techniques are anticipated to provide pervasive connections for wireless nodes. In fact, machine learning paves the way for the Internet of Things (IoT)—a network that supports communications among various devices without human interactions. Machine learning techniques are being utilized in several fields such as healthcare, smart grids, vehicular communications, and so on. In this paper, we study different IoT-based machine learning mechanisms that are used in the mentioned fields among others. In addition, the lessons learned are reported and the assessments are explored viewing the basic aim machine learning techniques are expected to play in IoT networks.}
}
@article{DAO2017323,
title = {Daily Human Activities Recognition Using Heterogeneous Sensors from Smartphones},
journal = {Procedia Computer Science},
volume = {111},
pages = {323-328},
year = {2017},
note = {The 8th International Conference on Advances in Information Technology},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2017.06.030},
url = {https://www.sciencedirect.com/science/article/pii/S1877050917312036},
author = {Minh-Son Dao and Tuan-Anh Nguyen-Gia and Van-Cuong Mai},
keywords = {Human Activity Recognition, Smartphones, Embedded Sensors, Smart-City, Heterogeneous Sensory Data Analytics, Data Mining, Machine Learning},
abstract = {On-line understanding human activities can contribute solutions to some problems existing in the smart-city schema such as health-care, urban mobility, or security. Wearable sensors, especially sensors embedded in smartphones, turn to be good data streams for human activity recognition (HAR) tasks. Unfortunately, most of the existing methods are evaluated on small and fixed-size datasets, and lack of data sharing as well as classifiers re-training functions. These issues will lead to the challenge of unadaptable learning when facing problems of volume and variety of data. In order to tackle these problems, this paper proposes a new method with adaptive, interactive, and general-personal-model training components, and data sharing on the cloud. The major advantage of the proposed method is very fast to detect human activities of a new user at the beginning (i.e. deploying a system to a new user) with an acceptable accuracy of detection using the general model. Then, the personal model will help to increase the accuracy of activities detection personally by interacting with users. Another advantage of the proposed method is to share data (e.g. sensory data, models, activities, and user’s profiles) among users/apps joined the system. These data will help to increase the accuracy of models timely by re-training periodically. Besides, the method can be used as a human-activity sensor that streams detected human activities to related components of smart-city scheme. The proposed method is evaluated and compared to de-facto datasets as well as state-of-the-art of HAR using smartphones. The experimental results show that there is a significant improvement of HAR’s accuracy when utilizing the proposed method.}
}
@article{LORIMER2018348,
title = {COVERS-UP: Collaborative Verification of Smart User Profiles for social sustainability of smart cities},
journal = {Sustainable Cities and Society},
volume = {38},
pages = {348-358},
year = {2018},
issn = {2210-6707},
doi = {https://doi.org/10.1016/j.scs.2017.11.030},
url = {https://www.sciencedirect.com/science/article/pii/S2210670717311496},
author = {Philip A.K. Lorimer and Victor Ming-Fai Diec and Burak Kantarci},
keywords = {Mobile social networks, Smart cities, Social sustainability, User verification, Machine learning},
abstract = {Non-dedicated sensing models in smart cities, such as social sensing, aim at recruiting smart users while mobile social platforms’ vulnerability to identity theft attacks introduces the risks of de-incentivizing mobile users against participating and spreading disinformation through social platforms in case of successful identity theft attempts. In this paper, we present a mobile edge-based collaborative solution against identity theft over social platforms by taking advantage of the convergence of social, wireless, and mobile networks in the 5G Era. The collaborative framework delegates detection of a potential identity theft to other smart users who are the connections of the potential victim over a social platform. The collaborating smart users are not involved in semantic analysis but are assigned a subset of the contextual features of the smart user under review. We present thorough performance evaluation by using real social platform data in simulations. The numerical results show that collaboration among smart users can reveal anomalous behavior on the social accounts of other participants with a success ratio at the order of >90%. Furthermore, we show that false positive (FP) decisions can be mitigated while false negatives, which are less severe than FPs, can be reduced down to the order of ≤3%.}
}
@article{JIA2022103844,
title = {Multiscale analysis of human social sensing of urban appearance and its effects on house price appreciation in Wuhan, China},
journal = {Sustainable Cities and Society},
volume = {81},
pages = {103844},
year = {2022},
issn = {2210-6707},
doi = {https://doi.org/10.1016/j.scs.2022.103844},
url = {https://www.sciencedirect.com/science/article/pii/S2210670722001718},
author = {Jia Jia and Xiaoqing Zhang and Caihong Huang and Hao Luan},
keywords = {Human social sensing, House price appreciation, Multiscale geographically weighted regression (MGWR), Hedonic price model (HPM), Wuhan city},
abstract = {City managers seek to achieve people-oriented sustainable city development, which requires a clear understanding of socioeconomic effects of citizens’ perceptions of urban appearance. Traditional studies have investigated effects of urban appearance but have ignored the perception of place, which depends on people's unique social experiences. We distinguish “house” and “home” and propose an integrated model to test the prediction effect of combining conventional perception and social perception variables on house price appreciation. We establish a dataset that includes factors, e.g., housing structures, visual quality, and human physical perception. Then, we use machine learning models to extract features from multisource data, investigate the price appreciation of 1,032 houses in Wuhan from 2015 to 2020 and use multiscale geographically weighted regression (MGWR) to discuss spatial dependence. Finally, we perform a cluster analysis to understand the combined effects. The results show that human physical perception has the highest effect, the visual quality of urban streets has the highest impact in places where highly educated people gather, and the impact of service facilities is greatest in economically underdeveloped areas. Our findings provide novel insights into the interlinkages between human social sensing and appreciation rates, which can be efficiently applied to build sustainable smart cities.}
}
@article{MASHALY2021299,
title = {Connecting the Twins: A Review on Digital Twin Technology & its Networking Requirements},
journal = {Procedia Computer Science},
volume = {184},
pages = {299-305},
year = {2021},
note = {The 12th International Conference on Ambient Systems, Networks and Technologies (ANT) / The 4th International Conference on Emerging Data and Industry 4.0 (EDI40) / Affiliated Workshops},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2021.03.039},
url = {https://www.sciencedirect.com/science/article/pii/S1877050921006694},
author = {Maggie Mashaly},
keywords = {Digital Twin, Digital Transformation, Data Analytics, Artificial Intelligence, Real-time Communications, Network Requirements},
abstract = {Digital twin technology can be considered as an innovation accelerator. By providing a live copy of physical systems, digital twins bring to the table numerous advantages such as accelerated business processes, enhanced productivity, and faster innovation with reduced costs. For these numerous advantages digital twin is an ideal solution for several problems in domains such as Industry 4.0, education, healthcare and smart cities. However, to make sure the digital twin contributes effectively to these domains by representing a synchronized real-time copy of the physical system, the network connecting the physical and digital twins should fulfill a set of requirements such as low latency of real-time communication, data security and quality. This paper provides an overview on the technology of digital twin and its application domains with a detailed discussion on its networking requirements and proposed enabling technologies to fulfill them.}
}
@article{WU2022103716,
title = {Developing a data-fusing method for mapping fine-scale urban three-dimensional building structure},
journal = {Sustainable Cities and Society},
volume = {80},
pages = {103716},
year = {2022},
issn = {2210-6707},
doi = {https://doi.org/10.1016/j.scs.2022.103716},
url = {https://www.sciencedirect.com/science/article/pii/S2210670722000488},
author = {Xinxin Wu and Jinpei Ou and Youyue Wen and Xiaoping Liu and Jialv He and Jinbao Zhang},
keywords = {Urban morphology, Building height estimation, High-resolution optical images, Synthetic aperture radar, Morphological metrics},
abstract = {Understanding urban morphology is essential for various urban management studies and local environmental issues and guiding sustainable city development. Existing studies mainly focus on analyzing urban morphology from the horizontal aspect, while the urban vertical structure has rarely been discussed due to the scarcity of reliable and fine-scale urban three-dimensional (3-D) building data. This study develops an effective data-fusing methodology to estimate the heights of individual buildings at a city scale. We examined a machine-learning regression model by collecting public materials, including multi-source remote sensing-(RS)-based products, building-derived features, and relevant data to verify its performance in building height estimation. By applying the model in Shenzhen City, a dense city in the Guangdong-Hong Kong-Macao Greater Bay Area, results demonstrated that integrating rich multi-source explanatory variables could achieve high-accuracy building height retrieval. Using multiple building morphological metrics derived by building height data as proxy measures, the urban 3-D form patterns were further analyzed to understand current heterogeneous urban morphological structures. The proposed methodology can be conveniently applied to worldwide cities for urban 3-D morphology retrieval. Also, the available building height information is useful for planners to design morphological control for cities and thus contributes to sustainable and smart city development.}
}
@article{REZAPOUR2021100347,
title = {RL-PMAgg: Robust aggregation for PM2.5 using deep RL-based trust management system},
journal = {Internet of Things},
volume = {13},
pages = {100347},
year = {2021},
issn = {2542-6605},
doi = {https://doi.org/10.1016/j.iot.2020.100347},
url = {https://www.sciencedirect.com/science/article/pii/S2542660520301785},
author = {Amir Rezapour and Wen-Guey Tzeng},
keywords = {Anomaly detection, Internet of Things, PM2.5, Smart city, Trust management system, Reinforcement learning},
abstract = {Air pollution has become a major environmental issue in large cities. Air pollutants, especially fine particulate matter (PM2.5) has raised various concerns on human health. As a result, several low-cost PM2.5 monitoring systems have been deployed worldwide. However, an accurate air pollution monitoring system profoundly relies on data quality. In this paper, we propose RL-PMAgg for robustly computing PM2.5 pollution rates in existence of faulty sensors. Our method consists of three modules. The outlier detector gives quality assessments to the measurements. We use an RL-based trust management system to create a profile for each sensor and track its behavior in the long run. Then, an aggregated PM2.5 rate is computed by using a set of honest sensors along with their trust levels and measurements. We evaluate RL-PMAgg on both simulated and real-world datasets. We compare the proposed method with relevant works. Experimental results show that RL-PMAgg resists the majority of attacks as compared with other works.}
}
@article{ZOU2021100269,
title = {FDN-learning: Urban PM2.5-concentration Spatial Correlation Prediction Model Based on Fusion Deep Neural Network},
journal = {Big Data Research},
volume = {26},
pages = {100269},
year = {2021},
issn = {2214-5796},
doi = {https://doi.org/10.1016/j.bdr.2021.100269},
url = {https://www.sciencedirect.com/science/article/pii/S2214579621000861},
author = {Guojian Zou and Bo Zhang and Ruihan Yong and Dongming Qin and Qin Zhao},
keywords = {Fusion deep neural network, Gaussian function, LSTM, PM-concentration prediction, Stacked anti-autoencoder},
abstract = {The problem of increasing air pollution poses a challenge to smart city development, as spatial air pollution correlation exists among adjacent cities. However, it is difficult to predict the degree of air pollution of a location by exploiting massive air pollution datasets incorporating data on spatially related locations. Construction of a spatial correlation prediction model for air pollution is therefore required for air pollution big-data mining. In this paper, we propose an air pollution-concentration spatial correlation prediction model based on a fusion deep neural network called FDN-learning. Three models are combined: a stacked anti-autoencoder network, Gaussian function model, and long short-term memory network (LSTM). The FDN-learning model is composed of three layers for feature expansion, intermediate processing, and data prediction. In the first layer, we employ a stacked anti-autoencoder model to learn the source-data spatial features through a feature expansion hidden layer; this can enrich the feature vector and mine more information for further prediction. In the second layer, the Gaussian function evaluates effective weights for the outputs of the stacked anti-autoencoder models in the preceding layer; the spatial correction effects are therefore incorporated in this layer. Finally, the LSTM model in the data prediction layer learns the air pollution-concentration temporal features. A fine-tuning method based on stochastic gradient descent is applied to the FDN-learning model for improved performance. Empirical results are used to verify the feasibility and effectiveness of our proposed model based on a real-world air pollution dataset.}
}
@article{ASHAYERI2022103647,
title = {A framework for integrated energy and exposure to ambient pollution (iEnEx) assessment toward low-carbon, healthy, and equitable cities},
journal = {Sustainable Cities and Society},
volume = {78},
pages = {103647},
year = {2022},
issn = {2210-6707},
doi = {https://doi.org/10.1016/j.scs.2021.103647},
url = {https://www.sciencedirect.com/science/article/pii/S2210670721009100},
author = {Mehdi Ashayeri and Narjes Abbasabadi},
keywords = {Urban building energy, Human health, Exposure to PM pollution, Natural ventilation, Equity within the built environment, Machine learning},
abstract = {This research develops a framework for integrated energy and exposure to ambient pollution (iEnEx) assessment addressing energy, health, and equity as an interconnected problem within the built environment. Its focus is to explore spatial disparities of households’ energy burden and their exposure to ambient particulate matters (PM2.5 as end point) in supporting energy efficiency goals of cities. In this study, energy burden is defined as energy affordability of households for paying energy costs. And natural ventilation (NV) is examined as a catalyst of building energy efficiency to measure tradeoffs between energy burden mitigation and exposure to ambient PM2.5 pollution. The framework is built upon a five-step workflow using spatiotemporal land use regression (LUR) with gradient boosting machine (GBM) and bringing human behavioral patterns along with array of urban big data from smart cities platforms into the model to improve the explanatory capacities of the exposure model. We tested Chicago, IL as a case study. Findings indicate the effectiveness of the proposed framework in integrating urban energy and human health systems for envisioning urban building energy reduction goals. A web-based interactive platform is designed to communicate the results. iEnEx framework can assist designers, engineers, planners, and policymakers in better understanding these systems from environmental and social lenses in the context of equity within the built environment to ensure future sustainable cities.}
}
@article{THAKURIAH2020101427,
title = {Integrated Multimedia City Data (iMCD): A composite survey and sensing approach to understanding urban living and mobility},
journal = {Computers, Environment and Urban Systems},
volume = {80},
pages = {101427},
year = {2020},
issn = {0198-9715},
doi = {https://doi.org/10.1016/j.compenvurbsys.2019.101427},
url = {https://www.sciencedirect.com/science/article/pii/S0198971519301929},
author = {Piyushimita (Vonu) Thakuriah and Katarzyna Sila-Nowicka and Jinhyun Hong and Christina Boididou and Michael Osborne and Catherine Lido and Andrew McHugh},
keywords = {Wearable sensors, Image data, Urban metabolism, Travel behavior, Social media, Smart cities},
abstract = {We describe the Integrated Multimedia City Data (iMCD), a data platform involving detailed person-level self-reported and sensed information, with additional Internet, remote sensing, crowdsourced and environmental data sources that measure the wider social, economic and physical context of the participant. Selected aspects of the platform, which covers the Glasgow, UK, city-region, are available to other researchers, and allows knowledge discovery on critical urban living themes, for example in transportation, lifelong learning, sustainable behavior, social cohesion, ways of being in a digital age, and other topics. It further allows research into the technological and methodological aspects of emerging forms of urban data. Key highlights of the platform include a multi-topic household and person-level survey; travel and activity diaries; a privacy and personal device sensitivity survey; a rich set of GPS trajectory data; accelerometer, light intensity and other personal environment sensor data from wearable devices; an image data collection at approximately 5-second resolution of participants’ daily lives; multiple forms of text-based and multimedia Internet data; high resolution satellite and LiDAR data; and data from transportation, weather and air quality sensors. We demonstrate the power of the platform in understanding personal behavior and urban patterns by means of three examples: an examination of the links between mobility and literacy/learning using the household survey, a social media analysis of urban activity patterns, and finally, the degree of physical isolation levels using deep learning algorithms on image data. The analysis highlights the importance of purposefully designed multi-construct and multi-instrument data collection approaches that are driven by theoretical frameworks underpinning complex urban challenges, and the need to link to policy frameworks (e.g., Smart Cities, Future Cities, UNESCO Learning Cities agendas) that have the potential to translate data to impactful decision-making.}
}
@article{GAO2021100217,
title = {CSIP: Enhanced Link Prediction with Context of Social Influence Propagation},
journal = {Big Data Research},
volume = {24},
pages = {100217},
year = {2021},
issn = {2214-5796},
doi = {https://doi.org/10.1016/j.bdr.2021.100217},
url = {https://www.sciencedirect.com/science/article/pii/S2214579621000344},
author = {Han Gao and Bohan Li and Wenbin Xie and Yuxin Zhang and Donghai Guan and Weitong Chen and Ken Cai},
keywords = {Link prediction, Social network, Influence propagation},
abstract = {Data mining in social networks brings an indispensable role for the construction of smart cities from the perspective of social development. Link prediction is an important task of data mining, especially in the knowledge graph, which is also called knowledge graph completion. Link prediction aims to find missing links or predict potential links according to the current social network. The most existing link prediction methods focus on static information in social networks, such as topology and node attributes, which are partly provided by users. When users are unwilling to provide or intentionally hide these static features, traditional link prediction methods cannot achieve ideal performance. The dynamic information of social influence propagation in social networks can avoid the user's subjective impact and better reflect the relationship between users. In addition, users show different degrees of interest and authority on various topics in the real world, leading to different influence propagation patterns. Therefore, we use context of social influence to optimize the topic-aware influence propagation model to improve the performance of link prediction. In this paper, we propose a new multi-output graph neural network framework to capture influence propagation in social networks and model the influence of users in different roles. In this way, the underlying information of influence between users can be used to construct new features to improve the performance of link prediction. Our experiments conduct the method on multiple benchmark datasets. The experimental results show that the modeling of context is effective, and our model outperforms the compared state-of-the-art link prediction methods.}
}
@article{CHAMMAS2019249,
title = {An efficient data model for energy prediction using wireless sensors},
journal = {Computers & Electrical Engineering},
volume = {76},
pages = {249-257},
year = {2019},
issn = {0045-7906},
doi = {https://doi.org/10.1016/j.compeleceng.2019.04.002},
url = {https://www.sciencedirect.com/science/article/pii/S0045790618331653},
author = {Michel Chammas and Abdallah Makhoul and Jacques Demerjian},
keywords = {Energy prediction, Multilayer Perceptron (MLP), Data mining, Machine learning, Classification algorithms},
abstract = {Energy prediction is in high importance for smart homes and smart cities, since it helps reduce power consumption and provides better energy and cost savings. Many algorithms have been used for predicting energy consumption using data collected from Internet of Things (IoT) devices and wireless sensors. In this paper, we propose a system based on Multilayer Perceptron (MLP) to predict energy consumption of a building using collected information (e.g., light energy, day of the week, humidity, temperature, etc.) from a Wireless Sensor Network (WSN). We compare our system against four other classification algorithms, namely: Linear Regression (LR), Support Vector Machine (SVM), Gradient Boosting Machine (GBM) and Random Forest (RF). We achieve state-of-the-art results with 64% of the coefficient of Determination R2, 59.84% Root Mean Square Error (RMSE), 27.28% Mean Absolute Error (MAE) and 27.09% Mean Absolute Percentage Error (MAPE) in the testing set when using weather and temporal data.}
}
@article{KAISER2013708,
title = {Enabling real-time city sensing with kernel stream oracles and MapReduce},
journal = {Pervasive and Mobile Computing},
volume = {9},
number = {5},
pages = {708-721},
year = {2013},
note = {Special issue on Pervasive Urban Applications},
issn = {1574-1192},
doi = {https://doi.org/10.1016/j.pmcj.2012.11.003},
url = {https://www.sciencedirect.com/science/article/pii/S1574119212001381},
author = {Christian Kaiser and Alexei Pozdnoukhov},
keywords = {Sensor networks, Machine learning, Kernel methods, Spatial statistics, Smart cities},
abstract = {An algorithmic architecture for kernel-based modelling of data streams from city sensing infrastructures is introduced. It is both applicable for pre-installed, moving and extemporaneous sensors, including the “citizen-as-a-sensor” view on user-generated data. The approach is centred around a kernel dictionary implementing a general hypothesis space which is updated incrementally, accounting for memory and processing capacity limitations. It is general for both kernel-based classification and regression. An extension to area-to-point modelling is introduced to account for the data aggregated over a spatial region. A distributed implementation realised under the Map-Reduce framework is presented to train an ensemble of sequential kernel learners.}
}
@article{HAO2020788,
title = {New insights on ground control in intelligent mining with Internet of Things},
journal = {Computer Communications},
volume = {150},
pages = {788-798},
year = {2020},
issn = {0140-3664},
doi = {https://doi.org/10.1016/j.comcom.2019.12.032},
url = {https://www.sciencedirect.com/science/article/pii/S0140366419315002},
author = {Yang Hao and Yu Wu and Ranjith P.G. and Kai Zhang and Houquan Zhang and Yanlong Chen and Ming Li and Pan Li},
keywords = {Ground control, Intelligence Mining, Mine safety, Internet of Things},
abstract = {The conception of Smart city has been gaining momentum in recent years. Coal mines as a part of city should be characterized with smart or intelligent features. Production and safety are two major themes in coal mining. With the development of automation, Internet of Things (IoT), big data, artificial intelligence, and cloud computing in Fourth Industrial Revolution, Intelligence Mining has been put forward by Chinese Academy of Engineering to achieve the goal of unmanned workface production. However, safety is not highlighted in the novel idea. In this paper, ground control in intelligent mining with IoT is studied. An architecture of ground control with IoT is proposed. The previous research on theoretical modeling and on-site monitoring methods are reviewed. Then the IoT based ground control method is proposed. An on-going dynamic platform on ground control are proposed based on our research of nondestructive testing (NDT) on rock bolt anchorage quality assessment. The research progress is introduced with equipment introduction, principles, and an on-site experiment. Future developments on combination of NDT and IoT of ground control is discussed. The ideas, frameworks, and results in this paper can make efforts on safety control and spark new ideas in the much-anticipated Intelligence Mining.}
}
@article{DEPRISCO2021114951,
title = {Providing music service in Ambient Intelligence: experiments with gym users},
journal = {Expert Systems with Applications},
volume = {177},
pages = {114951},
year = {2021},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2021.114951},
url = {https://www.sciencedirect.com/science/article/pii/S0957417421003924},
author = {Roberto {De Prisco} and Alfonso Guarino and Nicola Lettieri and Delfina Malandrino and Rocco Zaccagnino},
keywords = {Ambient Intelligence, Internet of Things, Machine learning, Genetic algorithm, Multi-agent systems, Background music service},
abstract = {Ambient Intelligence (AmI) is an interdisciplinary research area of ICT which has evolved since the 90s, taking great advantage from the advent of the Internet of Things (IoT). AmI creates, by using Artificial Intelligence (AI), an intelligent ecosystem in which computers, sensors, lighting, music, personal devices, and distributed services, work together to improve the user experience through the support of natural and intuitive user interfaces. Nowadays, AmI is used in various contexts, e.g., for building smart homes and smart cities, providing healthcare, and creating an adequate atmosphere in retail and public environments. In this paper, we propose a novel AmI system for gym environments, named Gym Intelligence, able to provide adequate music atmosphere, according to the users’ physical effort during the training. The music is taken from Spotify and is classified according to some music features, as provided by Spotify itself. The system is based on a multi-agent computational intelligence model built on two main components: (i) machine learning methods that forecast appropriate values for the Spotify music features, and (ii) a multi-objective dynamic genetic algorithm that selects a specific Spotify music track, according to such values. Gym Intelligence is built by sensing the ambient with a minimal, low-cost, and non-intrusive set of sensors, and it has been designed considering the outcome of a preliminary analysis in real gyms, involving real users. We have considered well-known regression methods and we have validated them using a collected data (i) about the users’ physical effort, through the sensors, and (ii) about the users’ music preferences, through an Android app that the users have used during the training. Among the regression methods considered, the one that provided the best results is the Random Forest, which predicted Spotify music features with a mean absolute error of 0.02 and a root mean squared error of 0.05. We have implemented Gym Intelligence and deployed it in five real gyms. We have evaluated it conducting several experiments. The experiments show how, with the help of Gym Intelligence, the users’ satisfaction about the provided background music, rose from 3.05 to 4.91 (on a scale from 1 to 5, where 5 is the maximum score).}
}
@article{ZHANG2021102442,
title = {Modeling fine-scale residential land price distribution: An experimental study using open data and machine learning},
journal = {Applied Geography},
volume = {129},
pages = {102442},
year = {2021},
issn = {0143-6228},
doi = {https://doi.org/10.1016/j.apgeog.2021.102442},
url = {https://www.sciencedirect.com/science/article/pii/S0143622821000588},
author = {Peng Zhang and Shougeng Hu and Weidong Li and Chuanrong Zhang and Shengfu Yang and Shijin Qu},
keywords = {Land price distribution, Determinants, Spatiotemporal variation, Machine learning, Open data, Wuhan},
abstract = {Modeling the fine-scale spatiotemporal distribution of residential land prices (RLPs) is the basis for scientifically allocating land resources, managing the residential market and improving urban planning. The accurate mapping of the RLP dynamics require reliable land price prediction models and data with fine spatial and temporal resolution. With the aid of point of interest (POI) data and nighttime light (NTL) images, this paper attempts to explore the ability of machine learning algorithms (MLAs) to model grid-level RLPs using the case of Wuhan in China. Several land price prediction models were built using five MLAs and various geographic variables. The experimental results show that the extra-trees regression algorithm and the radial basis function-based support vector regression algorithm perform best in Period Ⅰ (2010–2014) and Period Ⅱ (2015–2019), respectively; therefore, they were selected to estimate the RLPs of the grids without observations in the corresponding period. Based on the estimated results, we found that the spatial pattern of the RLP in Wuhan transitioned from monocentric to polycentric between the two periods, and RLPs grew rapidly near newly formed urban subcenters and waterscapes. The relative importance of the predictor variables shows that commercial and educational facilities are important determinants of the RLP distribution in Wuhan; moreover, the relative importance of natural amenities and education facilities increased over time, while that of commercial facilities and public transportation decreased slightly. The case of Wuhan confirms the feasibility of MLAs and openly accessible urban data in modeling fine-scale RLP distributions. Our proposed framework provides a new approach to monitor the urban land price dynamics accurately and closely, which is beneficial for improving the infrastructure layout and achieve smart city growth.}
}
@article{MALIK2022107938,
title = {Village 4.0: Digitalization of village with smart internet of things technologies},
journal = {Computers & Industrial Engineering},
volume = {165},
pages = {107938},
year = {2022},
issn = {0360-8352},
doi = {https://doi.org/10.1016/j.cie.2022.107938},
url = {https://www.sciencedirect.com/science/article/pii/S0360835222000080},
author = {Praveen Kumar Malik and Rajesh Singh and Anita Gehlot and Shaik Vaseem Akram and Prabin {Kumar Das}},
keywords = {Digitalization, Artificial Intelligence, Blockchain, Big data, Smart ecosystem, Village},
abstract = {The United Nations (UN) 2030 Agenda makes it clear that growth and sustainable management are not confined to cities, but also to those living in rural and villages. In addition, the villages are the heart of every nation, the villages not only support and maintain the geological ecosystem but also have a great impact on the economic and social ecosystem. Currently, digital technologies have had a big influence on smart cities in terms of digitalization, and with the same motivation, these technologies may also help to build the digital and smart village. In this study, we present a detailed discussion of the implementation of smart and digital villages with different new digital technologies. In addition, we also present the possible enhancements in the village with the digitized village concept. From the discussion on the smart village, it is concluded that digitization is only possible if a reliable and robust network and communication infrastructure is installed in the village area.}
}
@article{ALCAZARGARCIA2022123719,
title = {Model-based design validation and optimization of drive systems in electric, hybrid, plug-in hybrid and fuel cell vehicles},
journal = {Energy},
pages = {123719},
year = {2022},
issn = {0360-5442},
doi = {https://doi.org/10.1016/j.energy.2022.123719},
url = {https://www.sciencedirect.com/science/article/pii/S0360544222006223},
author = {Désirée Alcázar-García and José Luis {Romeral Martínez}},
keywords = {Design optimization, Electric vehicle, Energy consumption, Fuel cell vehicle, Genetic algorithm, Hybrid electric vehicle, Micromobility, Vehicle configuration, Vehicle efficiency},
abstract = {Currently we are at the beginning of the fourth industrial revolution, which involves, among others, technology to prevent climate change, transformation of the transport sector, digitization, and artificial intelligence. This paper contributes to technological development accelerating the design of ecological vehicles and their introduction in smart cities. This paper describes an adaptive, flexible, expandable, simple, and high-accuracy methodology capable of maximizing vehicle range with the finest computational effort, thanks to a genetic algorithm. Further, it produces predictive information to minimize cost, volume, and weight of the drivetrain in the vehicle structure while meeting the desires of the designer. Range is calculated using a standard or customised drive cycle. Calculation of the CO2 produced in the electricity production process is also provided. The reliability of the system has been verified with commercially available vehicles, taking into account their technical specifications such as electric motor type (e.g. induction, permanent magnet, or hybrid electric motors), the technology of the energy storage system (e.g. nickel-metal hydride or lithium-ion batteries or fuel cell), configuration (e.g. pure electric vehicle, series/parallel/series-parallel (plug-in) hybrid electric vehicle, or fuel cell vehicle) and their category (light quadricycles [L6e], heavy quadricycles [L7e], passenger cars [M1], vans [N1], or low-speed vehicles). The results obtained demonstrate that the model is capable of extraordinary precision.}
}
@article{PRIHASTOMO2019994,
title = {Theoretical Framework of Smart Intellectual Property Office in Developing Countries},
journal = {Procedia Computer Science},
volume = {161},
pages = {994-1001},
year = {2019},
note = {The Fifth Information Systems International Conference, 23-24 July 2019, Surabaya, Indonesia},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2019.11.209},
url = {https://www.sciencedirect.com/science/article/pii/S1877050919319209},
author = {Yoga Prihastomo and Raymond Kosala and Suhono Harso Supangkat and Benny Ranti and Agung Trisetyarso},
keywords = {Smart IP Office Framework, IP Office, IT Governance},
abstract = {Rapid ICT development, globalization challenges, intellectual property (IP) as indicators of economic development, and the challenge are the patentability of computer-implemented inventions and artificial intelligence implications for the IP Office (IPO) to transform from the digital paradigm to the smart paradigm. Nevertheless, because of the lack of literature on the smart IPO framework, we refer to smart government and smart city framework. The aim of this paper is to propose a framework for smart IPO in developing countries in the context of smart city framework. The study found that smart IPO composed of several components such as 1) Smart IPO Model; 2) Smart IPO Enterprise Architecture; 3) Smart IPO Collaboration Model; 4) Smart IPO Development Model; 5) Smart IPO Measurement Model; 6) Smart IPO Standard; and 7) Smart IPO Services. It also found that there are four models of IP office as follows: Model 1 (basic web-based, public services); Model 2 (advanced internal administration); Model 3 (full process automation); and Model 4 (knowledge-based IP services). Moreover, we found also three stages of IP development model: Stage 1 (automation of internal processes); Stage 2 (web-based e-services); Stage 3 (e-dossier, e-filing, e-payment).}
}
@article{HEGARTY2021105576,
title = {Digital evidence in fog computing systems},
journal = {Computer Law & Security Review},
volume = {41},
pages = {105576},
year = {2021},
issn = {0267-3649},
doi = {https://doi.org/10.1016/j.clsr.2021.105576},
url = {https://www.sciencedirect.com/science/article/pii/S0267364921000492},
author = {R. Hegarty and M. Taylor},
keywords = {Digital evidence, Fog computing, Cyber crime},
abstract = {Fog Computing provides a myriad of potential societal benefits: personalised healthcare, smart cities, automated vehicles, Industry 4.0, to name just a few. The highly dynamic and complex nature of Fog Computing with its low latency communication networks connecting sensors, devices and actuators facilitates ambient computing at scales previously unimaginable. The combination of Machine Learning, Data Mining, and the Internet of Things, supports endless innovation in our data driven society. Fog computing incurs new threats to security and privacy since these become more difficult when there are an increased number of connected devices, and such devices (for example sensors) typically have limited capacity for in-built security. For law enforcement agencies, the existing models for digital forensic investigations are ill suited to the emerging fog paradigm. In this paper we examine the procedural, technical, legal, and geopolitical challenges associated with digital forensic investigations in Fog Computing. We highlight areas that require further development, and posit a framework to stimulate further consideration and discussion around the challenges associated with extracting digital evidence from Fog Computing systems.}
}
@article{KAYA2021100548,
title = {Waste-to-Energy Framework: An intelligent energy recycling management},
journal = {Sustainable Computing: Informatics and Systems},
volume = {30},
pages = {100548},
year = {2021},
issn = {2210-5379},
doi = {https://doi.org/10.1016/j.suscom.2021.100548},
url = {https://www.sciencedirect.com/science/article/pii/S2210537921000391},
author = {Kiymet Kaya and Elif Ak and Yusuf Yaslan and Sema Fatma Oktug},
keywords = {Waste-To-Energy, Smart city, Waste management, MSW, Machine learning},
abstract = {Nowadays, waste to energy (WTE) transformation solutions play a vital role in waste disposal. Accurate WTE resource planning can be made using high-performance waste amount prediction models. Thus, a significant gain can be obtained both in economic and environmental terms. In this paper, we proposed different machine learning models to predict the amount of municipal solid waste (MSW) to be used for smart energy management systems. To point this problem, we study a new WTE Framework and use the real-world data set obtained from MSW stations on the European side of Istanbul, Turkey. The basis of our motivation for choosing Istanbul is based on the ‘Waste Incineration and Power Generation Plant,11https://www.stantec.com/tr/projects/istanbul-waste-incineration-power-generation-plant-construction.’ which was built in Eyupsultan, Istanbul in 2017 and is planned to be operational in 2021. This plant will be Europe’s largest domestic waste incinerator with a capacity of 3000 tons/day. For the proposed WTE framework, we first build an ensemble model, Gradient Boosting (GB), to predict the amount of MSW using daily data related to other variables such as seasonality and socio-economic status. Then we use the calorific index value to predict generated energy from solid waste, categorized in 14 different waste types.}
}
@article{HONARVAR201956,
title = {Towards Sustainable Smart City by Particulate Matter Prediction Using Urban Big Data, Excluding Expensive Air Pollution Infrastructures},
journal = {Big Data Research},
volume = {17},
pages = {56-65},
year = {2019},
issn = {2214-5796},
doi = {https://doi.org/10.1016/j.bdr.2018.05.006},
url = {https://www.sciencedirect.com/science/article/pii/S2214579617302587},
author = {Ali Reza Honarvar and Ashkan Sami},
keywords = {Particulate matter prediction, Big data, Sustainable smart cities, Multi-source data, Urban data analytics},
abstract = {Living in the age of data and the new era of digitalization of cities have created a large volume of datasets and data flows associated with the urban environments. It is significantly vital to capture and analyze the data from various resources in smart cities. For instance, the real-time air pollution data are remarkably important in controlling air pollution for urban sustainability and protecting humans against the air pollution damages. However, in reality, the average construction investment and maintenance costs in the air pollution stations are too high. This paper intends to investigate whether and how we can measure air pollution using cost effective means and without using the expensive pollution sensors and facilities. In order to realize such a goal, a predictive model for particulate matter prediction was developed. The proposed model consists of multiple components to integrate heterogeneous multiple sources of urban data and predict the particulate matter based on transfer learning perspective in which neural network and regression was leveraged as the core of the prediction. The results of the particulate matter prediction exposed that while these data sources are capable of proper prediction of the particulate matter, they can also yield better results over the models, which were based only on the features of the air pollution sensors. This work provides an opportunity for evaluation of the model with the urban data from the city of Aarhus, in Denmark, and comparison of the model performance against various specified baselines. The superiority of the model over the baselines shows the practicality of the model.}
}
@article{GUO201951,
title = {LCC: Towards efficient label completion and correction for supervised medical image learning in smart diagnosis},
journal = {Journal of Network and Computer Applications},
volume = {133},
pages = {51-59},
year = {2019},
issn = {1084-8045},
doi = {https://doi.org/10.1016/j.jnca.2019.02.009},
url = {https://www.sciencedirect.com/science/article/pii/S1084804519300530},
author = {Kehua Guo and Rui Cao and Xiaoyan Kui and Jianhua Ma and Jian Kang and Tao Chi},
keywords = {Smart diagnosis, Label completion, Label correction, Deep learning},
abstract = {Smart technology brings convenience to our lives, and smart medical diagnosis plays a particularly important role in smart cities and the smart world. In smart diagnosis, high-quality image labels are essential for supervised medical image learning. The correctness of labels has a substantial influence on smart disease diagnosis. However, the labelling of disease images by professional doctors is a time-consuming and labour-intensive project; therefore, obtaining correct and high-quality labels is a difficult task. This paper proposes a deep convolutional neural network (CNN)-based label completion and correction method (LCC) for supervised medical image learning in smart diagnosis. We use a small number of labelled images in a dataset to train a model, and design a strategy to complement most of the unlabelled data and correct noise label data, and then use the results of completion and correction to continually modify the model to achieve better results. We take the diagnosis of Seborrheic Keratosis (SK) and Flat Wart (FW) as examples; the experimental results show that this strategy can use limited labelled data to complete the labels for most of the unlabelled data and correct some noise labels in the dataset, which improves the accuracy rate of the model to identify diseases.}
}
@article{DUBEY20201950,
title = {Household Waste Management System Using IoT and Machine Learning},
journal = {Procedia Computer Science},
volume = {167},
pages = {1950-1959},
year = {2020},
note = {International Conference on Computational Intelligence and Data Science},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2020.03.222},
url = {https://www.sciencedirect.com/science/article/pii/S1877050920306876},
author = {Sonali Dubey and Pushpa Singh and Piyush Yadav and Krishna Kant Singh},
keywords = {IoT, smart city, waste management, biodegradable, sensor, machine learning},
abstract = {IOT and machine learning based household waste management system for Green smart society are aimed to make management of waste from the every apartment of the society more efficient using the most upcoming technology IOT. This paper discusses the collection and decomposition of waste in the smart way so that benefit from the waste is maximized and the actual waste is minimized efficiently. This paper focus on the segregation of the waste at two levels: the first level of segregation is on the individual house of the society and the second level of segregation is at the society. Author, discuss the recycling of the biodegradable waste for making compost. The machine learning technique such as KNN is used to generate an alert message for various combinations of three sensor values like level of bio and non biodegradable waste,concentration of poisonous gas. The overall impact of this research is in the upliftment of the green technologies by reducing pollutants, conserving, resourcing and reusing the energy through the use of technology.}
}
@article{SAJJAD2020995,
title = {Raspberry Pi assisted face recognition framework for enhanced law-enforcement services in smart cities},
journal = {Future Generation Computer Systems},
volume = {108},
pages = {995-1007},
year = {2020},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2017.11.013},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X17309512},
author = {Muhammad Sajjad and Mansoor Nasir and Khan Muhammad and Siraj Khan and Zahoor Jan and Arun Kumar Sangaiah and Mohamed Elhoseny and Sung Wook Baik},
keywords = {IoT and smart cities, Face recognition, Video processing, Image prioritization, Machine learning, Multimedia},
abstract = {Similar to a fingerprint search system, face recognition technology can assist law enforcement agencies in identifying suspects or finding missing persons. Face recognition technology lets the police detect a suspect’s face and compare it with image databases of known criminals and provides investigators with a match list of the most similar faces. Face recognition is a highly efficient and accurate tool in investigation processes. However, in some sensitive scenarios covert methods are required for the detection of suspects or missing persons without risking the lives of police. With the availability of the nano devices such as Raspberry Pi, law enforcement agencies such as police can be equipped with a concealed and secure face recognition system. In this paper, a Raspberry Pi and cloud assisted face recognition framework is proposed. A small-sized portable wireless camera is mounted on a police officer’s uniform to capture a video stream, which is passed to Raspberry Pi for face detection and recognition. The proposed method uses Bag of Words for extraction of oriented FAST and rotated BRIEF points from the detected face, followed by support vector machine for identification of suspects. Raspberry Pi has limited resources such as storage space, memory, and processing power, and therefore the proposed classifier is stored and trained on the cloud. The proposed method is implemented on Raspberry Pi 3 model B in Python 2.7 and is tested on various standard datasets. Experimental results validate the efficiency of the proposed method in accurate detection of faces compared to state-of-the-art face detection and recognition methods, and verify its effectiveness for enhancing law-enforcement services in smart cities.}
}
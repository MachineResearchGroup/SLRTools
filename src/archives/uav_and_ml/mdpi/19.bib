
@Article{rs13193928,
AUTHOR = {Lu, Qikai and Si, Wei and Wei, Lifei and Li, Zhongqiang and Xia, Zhihong and Ye, Song and Xia, Yu},
TITLE = {Retrieval of Water Quality from UAV-Borne Hyperspectral Imagery: A Comparative Study of Machine Learning Algorithms},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {19},
ARTICLE-NUMBER = {3928},
URL = {https://www.mdpi.com/2072-4292/13/19/3928},
ISSN = {2072-4292},
ABSTRACT = {The rapidly increasing world population and human activities accelerate the crisis of the limited freshwater resources. Water quality must be monitored for the sustainability of freshwater resources. Unmanned aerial vehicle (UAV)-borne hyperspectral data can capture fine features of water bodies, which have been widely used for monitoring water quality. In this study, nine machine learning algorithms are systematically evaluated for the inversion of water quality parameters including chlorophyll-a (Chl-a) and suspended solids (SS) with UAV-borne hyperspectral data. In comparing the experimental results of the machine learning model on the water quality parameters, we can observe that the prediction performance of the Catboost regression (CBR) model is the best. However, the prediction performances of the Multi-layer Perceptron regression (MLPR) and Elastic net (EN) models are very unsatisfactory, indicating that the MLPR and EN models are not suitable for the inversion of water quality parameters. In addition, the water quality distribution map is generated, which can be used to identify polluted areas of water bodies.},
DOI = {10.3390/rs13193928}
}



@Article{electronics10192397,
AUTHOR = {Pandya, Aarav and Jha, Ajit and Cenkeramaddi, Linga Reddy},
TITLE = {A Velocity Estimation Technique for a Monocular Camera Using mmWave FMCW Radars},
JOURNAL = {Electronics},
VOLUME = {10},
YEAR = {2021},
NUMBER = {19},
ARTICLE-NUMBER = {2397},
URL = {https://www.mdpi.com/2079-9292/10/19/2397},
ISSN = {2079-9292},
ABSTRACT = {Perception in terms of object detection, classification, and dynamic estimation (position and velocity) are fundamental functionalities that autonomous agents (unmanned ground vehicles, unmanned aerial vehicles, or robots) have to navigate safely and autonomously. To date, various sensors have been used individually or in combination to achieve this goal. In this paper, we present a novel method for leveraging millimeter wave radar’s (mmW radar’s) ability to accurately measure position and velocity in order to improve and optimize velocity estimation using a monocular camera (using optical flow) and machine learning techniques. The proposed method eliminates ambiguity in optical flow velocity estimation when the object of interest is at the edge of the frame or far away from the camera without requiring camera–radar calibration. Moreover, algorithms of various complexity were implemented using custom dataset, and each of them successfully detected the object and estimated its velocity accurately and independently of the object’s distance and location in frame. Here, we present a complete implementation of camera–mmW radar late feature fusion to improve the camera’s velocity estimation performance. It includes setup design, data acquisition, dataset development, and finally, implementing a lightweight ML model that successfully maps the mmW radar features to the camera, allowing it to perceive and estimate the dynamics of a target object without any calibration.},
DOI = {10.3390/electronics10192397}
}



@Article{rs13193983,
AUTHOR = {Pontoglio, Emanuele and Dabove, Paolo and Grasso, Nives and Lingua, Andrea Maria},
TITLE = {Automatic Features Detection in a Fluvial Environment through Machine Learning Techniques Based on UAVs Multispectral Data},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {19},
ARTICLE-NUMBER = {3983},
URL = {https://www.mdpi.com/2072-4292/13/19/3983},
ISSN = {2072-4292},
ABSTRACT = {The present work aims to demonstrate how machine learning (ML) techniques can be used for automatic feature detection and extraction in fluvial environments. The use of photogrammetry and machine learning algorithms has improved the understanding of both environmental and anthropic issues. The developed methodology was applied considering the acquisition of multiple photogrammetric images thanks to unmanned aerial vehicles (UAV) carrying multispectral cameras. These surveys were carried out in the Salbertrand area, along the Dora Riparia River, situated in Piedmont (Italy). The authors developed an algorithm able to identify and detect the water table contour concerning the landed areas: the automatic classification in ML found a valid identification of different patterns (water, gravel bars, vegetation, and ground classes) in specific hydraulic and geomatics conditions. Indeed, the RE+NIR data gave us a sharp rise in terms of accuracy by about 11% and 13.5% of F1-score average values in the testing point clouds compared to RGB data. The obtained results about the automatic classification led us to define a new procedure with precise validity conditions.},
DOI = {10.3390/rs13193983}
}



@Article{rs13204091,
AUTHOR = {Ndlovu, Helen S. and Odindi, John and Sibanda, Mbulisi and Mutanga, Onisimo and Clulow, Alistair and Chimonyo, Vimbayi G. P. and Mabhaudhi, Tafadzwanashe},
TITLE = {A Comparative Estimation of Maize Leaf Water Content Using Machine Learning Techniques and Unmanned Aerial Vehicle (UAV)-Based Proximal and Remotely Sensed Data},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {20},
ARTICLE-NUMBER = {4091},
URL = {https://www.mdpi.com/2072-4292/13/20/4091},
ISSN = {2072-4292},
ABSTRACT = {Determining maize water content variability is necessary for crop monitoring and in developing early warning systems to optimise agricultural production in smallholder farms. However, spatially explicit information on maize water content, particularly in Southern Africa, remains elementary due to the shortage of efficient and affordable primary sources of suitable spatial data at a local scale. Unmanned Aerial Vehicles (UAVs), equipped with light-weight multispectral sensors, provide spatially explicit, near-real-time information for determining the maize crop water status at farm scale. Therefore, this study evaluated the utility of UAV-derived multispectral imagery and machine learning techniques in estimating maize leaf water indicators: equivalent water thickness (EWT), fuel moisture content (FMC), and specific leaf area (SLA). The results illustrated that both NIR and red-edge derived spectral variables were critical in characterising the maize water indicators on smallholder farms. Furthermore, the best models for estimating EWT, FMC, and SLA were derived from the random forest regression (RFR) algorithm with an rRMSE of 3.13%, 1%, and 3.48%, respectively. Additionally, EWT and FMC yielded the highest predictive performance and were the most optimal indicators of maize leaf water content. The findings are critical towards developing a robust and spatially explicit monitoring framework of maize water status and serve as a proxy of crop health and the overall productivity of smallholder maize farms.},
DOI = {10.3390/rs13204091}
}



@Article{rs13214282,
AUTHOR = {Yu, Jin-Woo and Yoon, Young-Woong and Baek, Won-Kyung and Jung, Hyung-Sup},
TITLE = {Forest Vertical Structure Mapping Using Two-Seasonal Optic Images and LiDAR DSM Acquired from UAV Platform through Random Forest, XGBoost, and Support Vector Machine Approaches},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {21},
ARTICLE-NUMBER = {4282},
URL = {https://www.mdpi.com/2072-4292/13/21/4282},
ISSN = {2072-4292},
ABSTRACT = {Research on the forest structure classification is essential, as it plays an important role in assessing the vitality and diversity of vegetation. However, classifying forest structure involves in situ surveying, which requires considerable time and money, and cannot be conducted directly in some instances; also, the update cycle of the classification data is very late. To overcome these drawbacks, feasibility studies on mapping the forest vertical structure from aerial images using machine learning techniques were conducted. In this study, we investigated (1) the performance improvement of the forest structure classification, using a high-resolution LiDAR-derived digital surface model (DSM) acquired from an unmanned aerial vehicle (UAV) platform and (2) the performance comparison of results obtained from the single-seasonal and two-seasonal data, using random forest (RF), extreme gradient boosting (XGBoost), and support vector machine (SVM). For the performance comparison, the UAV optic and LiDAR data were divided into three cases: (1) only used autumn data, (2) only used winter data, and (3) used both autumn and winter data. From the results, the best model was XGBoost, and the F1 scores achieved using this method were approximately 0.92 in the autumn and winter cases. A remarkable improvement was achieved when both two-seasonal images were used. The F1 score improved by 35.3% from 0.68 to 0.92. This implies that (1) the seasonal variation in the forest vertical structure can be more important than the spatial resolution, and (2) the classification performance achieved from the two-seasonal UAV optic images and LiDAR-derived DSMs can reach 0.9 with the application of an optimal machine learning approach.},
DOI = {10.3390/rs13214282}
}



@Article{drones5040127,
AUTHOR = {Raza, Wamiq and Osman, Anas and Ferrini, Francesco and Natale, Francesco De},
TITLE = {Energy-Efficient Inference on the Edge Exploiting TinyML Capabilities for UAVs},
JOURNAL = {Drones},
VOLUME = {5},
YEAR = {2021},
NUMBER = {4},
ARTICLE-NUMBER = {127},
URL = {https://www.mdpi.com/2504-446X/5/4/127},
ISSN = {2504-446X},
ABSTRACT = {In recent years, the proliferation of unmanned aerial vehicles (UAVs) has increased dramatically. UAVs can accomplish complex or dangerous tasks in a reliable and cost-effective way but are still limited by power consumption problems, which pose serious constraints on the flight duration and completion of energy-demanding tasks. The possibility of providing UAVs with advanced decision-making capabilities in an energy-effective way would be extremely beneficial. In this paper, we propose a practical solution to this problem that exploits deep learning on the edge. The developed system integrates an OpenMV microcontroller into a DJI Tello Micro Aerial Vehicle (MAV). The microcontroller hosts a set of machine learning-enabled inference tools that cooperate to control the navigation of the drone and complete a given mission objective. The goal of this approach is to leverage the new opportunistic features of TinyML through OpenMV including offline inference, low latency, energy efficiency, and data security. The approach is successfully validated on a practical application consisting of the onboard detection of people wearing protection masks in a crowded environment.},
DOI = {10.3390/drones5040127}
}



@Article{s21217312,
AUTHOR = {Fuentes, Sigfredo and Gonzalez Viejo, Claudia and Hall, Chelsea and Tang, Yidan and Tongson, Eden},
TITLE = {Berry Cell Vitality Assessment and the Effect on Wine Sensory Traits Based on Chemical Fingerprinting, Canopy Architecture and Machine Learning Modelling},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {21},
ARTICLE-NUMBER = {7312},
URL = {https://www.mdpi.com/1424-8220/21/21/7312},
PubMedID = {34770618},
ISSN = {1424-8220},
ABSTRACT = {Berry cell death assessment can become one of the most objective parameters to assess important berry quality traits, such as aroma profiles that can be passed to the wine in the winemaking process. At the moment, the only practical tool to assess berry cell death in the field is using portable near-infrared spectroscopy (NIR) and machine learning (ML) models. This research tested the NIR and ML approach and developed supervised regression ML models using Shiraz and Chardonnay berries and wines from a vineyard located in Yarra Valley, Victoria, Australia. An ML model was developed using NIR measurements from intact berries as inputs to estimate berry cell death (BCD), living tissue (LT) (Model 1). Furthermore, canopy architecture parameters obtained from cover photography of grapevine canopies and computer vision analysis were also tested as inputs to develop ML models to assess BCD and LT (Model 2) and the intensity of sensory descriptors based on visual and aroma profiles of wines for Chardonnay (Model 3) and Shiraz (Model 4). The results showed high accuracy and performance of models developed based on correlation coefficient (R) and slope (b) (M1: R = 0.87; b = 0.82; M2: R = 0.98; b = 0.93; M3: R = 0.99; b = 0.99; M4: R = 0.99; b = 1.00). Models developed based on canopy architecture, and computer vision can be used to automatically estimate the vigor and berry and wine quality traits using proximal remote sensing and with visible cameras as the payload of unmanned aerial vehicles (UAV).},
DOI = {10.3390/s21217312}
}



@Article{rs13214476,
AUTHOR = {Traore, Adama and Ata-Ul-Karim, Syed Tahir and Duan, Aiwang and Soothar, Mukesh Kumar and Traore, Seydou and Zhao, Ben},
TITLE = {Predicting Equivalent Water Thickness in Wheat Using UAV Mounted Multispectral Sensor through Deep Learning Techniques},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {21},
ARTICLE-NUMBER = {4476},
URL = {https://www.mdpi.com/2072-4292/13/21/4476},
ISSN = {2072-4292},
ABSTRACT = {The equivalent water thickness (EWT) is an important biophysical indicator of water status in crops. The effective monitoring of EWT in wheat under different nitrogen and water treatments is important for irrigation management in precision agriculture. This study aimed to investigate the performances of machine learning (ML) algorithms in retrieving wheat EWT. For this purpose, a rain shelter experiment (Exp. 1) with four irrigation quantities (0, 120, 240, 360 mm) and two nitrogen levels (75 and 255 kg N/ha), and field experiments (Exps. 2–3) with the same irrigation and rainfall water levels (360 mm) but different nitrogen levels (varying from 75 to 255 kg N/ha) were conducted in the North China Plain. The canopy reflectance was measured for all plots at 30 m using an unmanned aerial vehicle (UAV)-mounted multispectral camera. Destructive sampling was conducted immediately after the UAV flights to measure total fresh and dry weight. Deep Neural Network (DNN) is a special type of neural network, which has shown performance in regression analysis is compared with other machine learning (ML) models. A feature selection (FS) algorithm named the decision tree (DT) was used as the automatic relevance determination method to obtain the relative relevance of 5 out of 67 vegetation indices (Vis), which were used for estimating EWT. The selected VIs were used to estimate EWT using multiple linear regression (MLR), deep neural network multilayer perceptron (DNN-MLP), artificial neural networks multilayer perceptron (ANN-MLP), boosted tree regression (BRT), and support vector machines (SVMs). The results show that the DNN-MLP with R2 = 0.934, NSE = 0.933, RMSE = 0.028 g/cm2, and MAE of 0.017 g/cm2 outperformed other ML algorithms (ANN-MPL, BRT, and SVM- Polynomial) owing to its high capacity for estimating EWT as compared to other ML methods. Our findings support the conclusion that ML can potentially be applied in combination with VIs for retrieving EWT. Despite the complexity of the ML models, the EWT map should help farmers by improving the real-time irrigation efficiency of wheat by quantifying field water content and addressing variability.},
DOI = {10.3390/rs13214476}
}



@Article{electronics10222764,
AUTHOR = {Hassan, Syed-Ali and Rahim, Tariq and Shin, Soo-Young},
TITLE = {An Improved Deep Convolutional Neural Network-Based Autonomous Road Inspection Scheme Using Unmanned Aerial Vehicles},
JOURNAL = {Electronics},
VOLUME = {10},
YEAR = {2021},
NUMBER = {22},
ARTICLE-NUMBER = {2764},
URL = {https://www.mdpi.com/2079-9292/10/22/2764},
ISSN = {2079-9292},
ABSTRACT = {Recent advancements in the field of machine learning (ML) provide opportunity to conduct research on autonomous devices for a variety of applications. Intelligent decision-making is a critical task for self-driving systems. An attempt is made in this study to use a deep learning (DL) approach for the early detection of road cracks, potholes, and the yellow lane. The accuracy is not sufficient after training with the default model. To enhance accuracy, a convolutional neural network (CNN) model with 13 convolutional layers, a softmax layer as an output layer, and two fully connected layers (FCN) are constructed. In order to achieve the deeper propagation and to prevent saturation in the training phase, mish activation is employed in the first 12 layers with a rectified linear unit (ReLU) activation function. The upgraded CNN model performs better than the default CNN model in terms of accuracy. For the varied situation, a revised and enriched dataset for road cracks, potholes, and the yellow lane is created. The yellow lane is detected and tracked in order to move the unmanned aerial vehicle (UAV) autonomously by following yellow lane. After identifying a yellow lane, the UAV performs autonomous navigation while concurrently detecting road cracks and potholes using the robot operating system within the UAV. The performance model is benchmarked using performance measures, such as accuracy, sensitivity, F1-score, F2-score, and dice-coefficient, which demonstrate that the suggested technique produces better outcomes.},
DOI = {10.3390/electronics10222764}
}



@Article{rs13224591,
AUTHOR = {Zhou, Xiaoteng and Liu, Chun and Akbar, Akram and Xue, Yun and Zhou, Yuan},
TITLE = {Spectral and Spatial Feature Integrated Ensemble Learning Method for Grading Urban River Network Water Quality},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {22},
ARTICLE-NUMBER = {4591},
URL = {https://www.mdpi.com/2072-4292/13/22/4591},
ISSN = {2072-4292},
ABSTRACT = {Urban river networks have the characteristics of medium and micro scales, complex water quality, rapid change, and time–space incoherence. Aiming to monitor the water quality accurately, it is necessary to extract suitable features and establish a universal inversion model for key water quality parameters. In this paper, we describe a spectral- and spatial-feature-integrated ensemble learning method for urban river network water quality grading. We proposed an in situ sampling method for urban river networks. Factor and correlation analyses were applied to extract the spectral features. Moreover, we analyzed the maximum allowed bandwidth for feature bands. We demonstrated that spatial features can improve the accuracy of water quality grading using kernel canonical correlation analysis (KCCA). Based on the spectral and spatial features, an ensemble learning model was established for total phosphorus (TP) and ammonia nitrogen (NH3-N). Both models were evaluated by means of fivefold validation. Furthermore, we proposed an unmanned aerial vehicle (UAV)-borne water quality multispectral remote sensing application process for urban river networks. Based on the process, we tested the model in practice. The experiment confirmed that our model can improve the grading accuracy by 30% compared to other machine learning models that use only spectral features. Our research can extend the application field of water quality remote sensing to complex urban river networks.},
DOI = {10.3390/rs13224591}
}



@Article{sym13112190,
AUTHOR = {Hashim, Wahidah and Eng, Lim Soon and Alkawsi, Gamal and Ismail, Rozita and Alkahtani, Ammar Ahmed and Dzulkifly, Sumayyah and Baashar, Yahia and Hussain, Azham},
TITLE = {A Hybrid Vegetation Detection Framework: Integrating Vegetation Indices and Convolutional Neural Network},
JOURNAL = {Symmetry},
VOLUME = {13},
YEAR = {2021},
NUMBER = {11},
ARTICLE-NUMBER = {2190},
URL = {https://www.mdpi.com/2073-8994/13/11/2190},
ISSN = {2073-8994},
ABSTRACT = {Vegetation inspection and monitoring is a time-consuming task. In the era of industrial revolution 4.0 (IR 4.0), unmanned aerial vehicles (UAV), commercially known as drones, are in demand, being adopted for vegetation inspection and monitoring activities. However, most off-the-shelf drones are least favoured by vegetation maintenance departments for on-site inspection due to limited spectral bands camera restricting advanced vegetation analysis. Most of these drones are normally equipped with a normal red, green, and blue (RGB) camera. Additional spectral bands are found to produce more accurate analysis during vegetation inspection, but at the cost of advanced camera functionalities, such as multispectral camera. Vegetation indices (VI) is a technique to maximize detection sensitivity related to vegetation characteristics while minimizing other factors which are not categorised otherwise. The emergence of machine learning has slowly influenced the existing vegetation analysis technique in order to improve detection accuracy. This study focuses on exploring VI techniques in identifying vegetation objects. The selected VIs investigated are Visible Atmospheric Resistant Index (VARI), Green Leaf Index (GLI), and Vegetation Index Green (VIgreen). The chosen machine learning technique is You Only Look Once (YOLO), which is a clever convolutional neural network (CNN) offering object detection in real time. The CNN model has a symmetrical structure along the direction of the tensor flow. Several series of data collection have been conducted at identified locations to obtain aerial images. The proposed hybrid methods were tested on captured aerial images to observe vegetation detection performance. Segmentation in image analysis is a process to divide the targeted pixels for further detection testing. Based on our findings, more than 70% of the vegetation objects in the images were accurately detected, which reduces the misdetection issue faced by previous VI techniques. On the other hand, hybrid segmentation methods perform best with the combination of VARI and YOLO at 84% detection accuracy.},
DOI = {10.3390/sym13112190}
}



@Article{rs13224632,
AUTHOR = {Teodoro, Paulo Eduardo and Teodoro, Larissa Pereira Ribeiro and Baio, Fábio Henrique Rojo and da Silva Junior, Carlos Antonio and dos Santos, Regimar Garcia and Ramos, Ana Paula Marques and Pinheiro, Mayara Maezano Faita and Osco, Lucas Prado and Gonçalves, Wesley Nunes and Carneiro, Alexsandro Monteiro and Junior, José Marcato and Pistori, Hemerson and Shiratsuchi, Luciano Shozo},
TITLE = {Predicting Days to Maturity, Plant Height, and Grain Yield in Soybean: A Machine and Deep Learning Approach Using Multispectral Data},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {22},
ARTICLE-NUMBER = {4632},
URL = {https://www.mdpi.com/2072-4292/13/22/4632},
ISSN = {2072-4292},
ABSTRACT = {In soybean, there is a lack of research aiming to compare the performance of machine learning (ML) and deep learning (DL) methods to predict more than one agronomic variable, such as days to maturity (DM), plant height (PH), and grain yield (GY). As these variables are important to developing an overall precision farming model, we propose a machine learning approach to predict DM, PH, and GY for soybean cultivars based on multispectral bands. The field experiment considered 524 genotypes of soybeans in the 2017/2018 and 2018/2019 growing seasons and a multitemporal–multispectral dataset collected by embedded sensor in an unmanned aerial vehicle (UAV). We proposed a multilayer deep learning regression network, trained during 2000 epochs using an adaptive subgradient method, a random Gaussian initialization, and a 50% dropout in the first hidden layer for regularization. Three different scenarios, including only spectral bands, only vegetation indices, and spectral bands plus vegetation indices, were adopted to infer each variable (PH, DM, and GY). The DL model performance was compared against shallow learning methods such as random forest (RF), support vector machine (SVM), and linear regression (LR). The results indicate that our approach has the potential to predict soybean-related variables using multispectral bands only. Both DL and RF models presented a strong (r surpassing 0.77) prediction capacity for the PH variable, regardless of the adopted input variables group. Our results demonstrated that the DL model (r = 0.66) was superior to predict DM when the input variable was the spectral bands. For GY, all machine learning models evaluated presented similar performance (r ranging from 0.42 to 0.44) for each tested scenario. In conclusion, this study demonstrated an efficient approach to a computational solution capable of predicting multiple important soybean crop variables based on remote sensing data. Future research could benefit from the information presented here and be implemented in subsequent processes related to soybean cultivars or other types of agronomic crops.},
DOI = {10.3390/rs13224632}
}



@Article{rs13224716,
AUTHOR = {Zhu, Wanxue and Rezaei, Ehsan Eyshi and Nouri, Hamideh and Yang, Ting and Li, Binbin and Gong, Huarui and Lyu, Yun and Peng, Jinbang and Sun, Zhigang},
TITLE = {Quick Detection of Field-Scale Soil Comprehensive Attributes via the Integration of UAV and Sentinel-2B Remote Sensing Data},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {22},
ARTICLE-NUMBER = {4716},
URL = {https://www.mdpi.com/2072-4292/13/22/4716},
ISSN = {2072-4292},
ABSTRACT = {Satellite and unmanned aerial vehicle (UAV) remote sensing can be used to estimate soil properties; however, little is known regarding the effects of UAV and satellite remote sensing data integration on the estimation of soil comprehensive attributes, or how to estimate quickly and robustly. In this study, we tackled those gaps by employing UAV multispectral and Sentinel-2B data to estimate soil salinity and chemical properties over a large agricultural farm (400 ha) covered by different crops and harvest areas at the coastal saline-alkali land of the Yellow River Delta of China in 2019. Spatial information of soil salinity, organic matter, available/total nitrogen content, and pH at 0&ndash;10 cm and 10&ndash;20 cm layers were obtained via ground sampling (n = 195) and two-dimensional spatial interpolation, aiming to overlap the soil information with remote sensing information. The exploratory factor analysis was conducted to generate latent variables, which represented the salinity and chemical characteristics of the soil. A machine learning algorithm (random forest) was applied to estimate soil attributes. Our results indicated that the integration of UAV texture and Sentinel-2B spectral data as random forest model inputs improved the accuracy of latent soil variable estimation. The remote sensing-based information from cropland (crop-based) had a higher accuracy compared to estimations performed on bare soil (soil-based). Therefore, the crop-based approach, along with the integration of UAV texture and Sentinel-2B data, is recommended for the quick assessment of soil comprehensive attributes.},
DOI = {10.3390/rs13224716}
}



@Article{rs13234757,
AUTHOR = {Sekrecka, Aleksandra},
TITLE = {Application of the XBoost Regressor for an A Priori Prediction of UAV Image Quality},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {23},
ARTICLE-NUMBER = {4757},
URL = {https://www.mdpi.com/2072-4292/13/23/4757},
ISSN = {2072-4292},
ABSTRACT = {In general, the quality of imagery from Unmanned Aerial Vehicles (UAVs) is evaluated after the flight, and then a decision is made on the further value and use of the acquired data. In this paper, an a priori (preflight) image quality prediction methodology is proposed to estimate the preflight image quality and to avoid unfavourable flights, which is extremely important from a time and cost management point of view. The XBoost Regressor model and cross-validation were used for machine learning of the model and image quality prediction. The model was learned on a rich database of real-world images acquired from UAVs under conditions varying in both sensor type, UAV type, exposure parameters, weather, topography, and land cover. Radiometric quality indices (SNR, Entropy, PIQE, NIQE, BRISQUE, and NRPBM) were calculated for each image to train and test the model and to assess the accuracy of image quality prediction. Different variants of preflight parameter knowledge were considered in the study. The proposed methodology offers the possibility of predicting image quality with high accuracy. The correlation coefficient between the actual and predicted image quality, depending on the number of parameters known a priori, ranged from 0.90 to 0.96. The methodology was designed for data acquired from a UAV. Similar prediction accuracy is expected for other low-altitude or close-range photogrammetric data.},
DOI = {10.3390/rs13234757}
}



@Article{telecom2040027,
AUTHOR = {Singh, Simran and Kumbhar, Abhaykumar and Güvenç, İsmail and Sichitiu, Mihail L.},
TITLE = {Intelligent Interference Management in UAV-Based HetNets},
JOURNAL = {Telecom},
VOLUME = {2},
YEAR = {2021},
NUMBER = {4},
PAGES = {472--488},
URL = {https://www.mdpi.com/2673-4001/2/4/27},
ISSN = {2673-4001},
ABSTRACT = {Unmanned aerial vehicles (UAVs) can play a key role in meeting certain demands of cellular networks. UAVs can be used not only as user equipment (UE) in cellular networks but also as mobile base stations (BSs) wherein they can either augment conventional BSs by adapting their position to serve the changing traffic and connectivity demands or temporarily replace BSs that are damaged due to natural disasters. The flexibility of UAVs allows them to provide coverage to UEs in hot-spots, at cell-edges, in coverage holes, or regions with scarce cellular infrastructure. In this work, we study how UAV locations and other cellular parameters may be optimized in such scenarios to maximize the spectral efficiency (SE) of the network. We compare the performance of machine learning (ML) techniques with conventional optimization approaches. We found that, on an average, a double deep Q learning approach can achieve 93.46% of the optimal median SE and 95.83% of the optimal mean SE. A simple greedy approach, which tunes the parameters of each BS and UAV independently, performed very well in all the cases that we tested. These computationally efficient approaches can be utilized to enhance the network performance in existing cellular networks.},
DOI = {10.3390/telecom2040027}
}



@Article{math9233117,
AUTHOR = {Herich, Dušan and Vaščák, Ján and Zolotová, Iveta and Brecko, Alexander},
TITLE = {Automatic Path Planning Offloading Mechanism in Edge-Enabled Environments},
JOURNAL = {Mathematics},
VOLUME = {9},
YEAR = {2021},
NUMBER = {23},
ARTICLE-NUMBER = {3117},
URL = {https://www.mdpi.com/2227-7390/9/23/3117},
ISSN = {2227-7390},
ABSTRACT = {The utilization of edge-enabled cloud computing in unmanned aerial vehicles has facilitated advances in autonomous control by employing computationally intensive algorithms frequently related to traversal among different locations in an environment. A significant problem remains in designing an effective strategy to offload tasks from the edge to the cloud. This work focuses on creating such a strategy by employing a network evaluation method built on the mean opinion score metrics in concoction with machine learning algorithms for path length prediction to assess computational complexity and classification models to perform an offloading decision on the data provided by both network metrics and solution depth prediction. The proposed system is applied to the A* path planning algorithm, and the presented results demonstrate up to 94% accuracy in offloading decisions.},
DOI = {10.3390/math9233117}
}



@Article{electronics10243053,
AUTHOR = {Zuniga-Mejia, Jaime and Villalpando-Hernandez, Rafaela and Vargas-Rosales, Cesar and Zareei, Mahdi},
TITLE = {LC-IDS: Loci-Constellation-Based Intrusion Detection for Reconfigurable Wireless Networks},
JOURNAL = {Electronics},
VOLUME = {10},
YEAR = {2021},
NUMBER = {24},
ARTICLE-NUMBER = {3053},
URL = {https://www.mdpi.com/2079-9292/10/24/3053},
ISSN = {2079-9292},
ABSTRACT = {Detection accuracy of current machine-learning approaches to intrusion detection depends heavily on feature engineering and dimensionality-reduction techniques (e.g., variational autoencoder) applied to large datasets. For many use cases, a tradeoff between detection performance and resource requirements must be considered. In this paper, we propose Loci-Constellation-based Intrusion Detection System (LC-IDS), a general framework for network intrusion detection (detection of already known and previously unknown routing attacks) for reconfigurable wireless networks (e.g., vehicular ad hoc networks, unmanned aerial vehicle networks). We introduce the concept of &lsquo;attack-constellation&rsquo;, which allows us to represent all the relevant information for intrusion detection (misuse detection and anomaly detection) on a latent 2-dimensional space that arises naturally by considering the temporal structure of the input data. The attack/anomaly-detection performance of LC-IDS is analyzed through simulations in a wide range of network conditions. We show that for all the analyzed network scenarios, we can detect known attacks, with a good detection accuracy, and anomalies with low false positive rates. We show the flexibility and scalability of LC-IDS that allow us to consider a dynamic number of neighboring nodes and routing attacks in the &lsquo;attack-constellation&rsquo; in a distributed fashion and with low computational requirements.},
DOI = {10.3390/electronics10243053}
}



@Article{rs13244985,
AUTHOR = {Kilwenge, Regina and Adewopo, Julius and Sun, Zhanli and Schut, Marc},
TITLE = {UAV-Based Mapping of Banana Land Area for Village-Level Decision-Support in Rwanda},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {24},
ARTICLE-NUMBER = {4985},
URL = {https://www.mdpi.com/2072-4292/13/24/4985},
ISSN = {2072-4292},
ABSTRACT = {Crop monitoring is crucial to understand crop production changes, agronomic practice decision-support, pests/diseases mitigation, and developing climate change adaptation strategies. Banana, an important staple food and cash crop in East Africa, is threatened by Banana Xanthomonas Wilt (BXW) disease. Yet, there is no up-to-date information about the spatial distribution and extent of banana lands, especially in Rwanda, where banana plays a key role in food security and livelihood. Therefore, delineation of banana-cultivated lands is important to prioritize resource allocation for optimal productivity. We mapped the spatial extent of smallholder banana farmlands by acquiring and processing high-resolution (25 cm/px) multispectral unmanned aerial vehicles (UAV) imageries, across four villages in Rwanda. Georeferenced ground-truth data on different land cover classes were combined with reflectance data and vegetation indices (NDVI, GNDVI, and EVI2) and compared using pixel-based supervised multi-classifiers (support vector models-SVM, classification and regression trees-CART, and random forest&ndash;RF), based on varying ground-truth data richness. Results show that RF consistently outperformed other classifiers regardless of data richness, with overall accuracy above 95%, producer&rsquo;s/user&rsquo;s accuracies above 92%, and kappa coefficient above 0.94. Estimated banana farmland areal coverage provides concrete baseline for extension-delivery efforts in terms of targeting banana farmers relative to their scale of production, and highlights opportunity to combine UAV-derived data with machine-learning methods for rapid landcover classification.},
DOI = {10.3390/rs13244985}
}



@Article{rs13245166,
AUTHOR = {Wang, Jianjun and Zhou, Qi and Shang, Jiali and Liu, Chang and Zhuang, Tingxuan and Ding, Junjie and Xian, Yunyu and Zhao, Lingtian and Wang, Weiling and Zhou, Guisheng and Tan, Changwei and Huo, Zhongyang},
TITLE = {UAV- and Machine Learning-Based Retrieval of Wheat SPAD Values at the Overwintering Stage for Variety Screening},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {24},
ARTICLE-NUMBER = {5166},
URL = {https://www.mdpi.com/2072-4292/13/24/5166},
ISSN = {2072-4292},
ABSTRACT = {In recent years, the delay in sowing has become a major obstacle to high wheat yield in Jiangsu Province, one of the major wheat producing areas in China; hence, it is necessary to screen wheat varieties are resilient for late sowing. This study aimed to provide an effective, fast, and non-destructive monitoring method of soil plant analysis development (SPAD) values, which can represent leaf chlorophyll contents, for late-sown winter wheat variety screening. This study acquired multispectral images using an unmanned aerial vehicle (UAV) at the overwintering stage of winter wheat growth, and further processed these images to extract reflectance of five single spectral bands and calculated 26 spectral vegetation indices. Based on these 31 variables, this study combined three variable selection methods (i.e., recursive feature elimination (RFE), random forest (RF), and Pearson correlation coefficient (r)) with four machine learning algorithms (i.e., random forest regression (RFR), linear kernel-based support vector regression (SVR), radial basis function (RBF) kernel-based SVR, and sigmoid kernel-based SVR), resulted in seven SVR models (i.e., RFE-SVR_linear, RF-SVR_linear, RF-SVR_RBF, RF-SVR_sigmoid, r-SVR_linear, r-SVR_RBF, and r-SVR_sigmoid) and three RFR models (i.e., RFE-RFR, RF-RFR, and r-RFR). The performances of the 10 machine learning models were evaluated and compared with each other according to the achieved coefficient of determination (R2), residual prediction deviation (RPD), root mean square error (RMSE), and relative RMSE (RRMSE) in SPAD estimation. Of the 10 models, the best one was the RF-SVR_sigmoid model, which was the combination of the RF variable selection method and the sigmoid kernel-based SVR algorithm. It achieved high accuracy in estimating SPAD values of the wheat canopy (R2 = 0.754, RPD = 2.017, RMSE = 1.716 and RRMSE = 4.504%). The newly developed UAV- and machine learning-based model provided a promising and real time method to monitor chlorophyll contents at the overwintering stage, which can benefit late-sown winter wheat variety screening.},
DOI = {10.3390/rs13245166}
}



@Article{rs13245173,
AUTHOR = {Cao, Xiaofeng and Liu, Yulin and Yu, Rui and Han, Dejun and Su, Baofeng},
TITLE = {A Comparison of UAV RGB and Multispectral Imaging in Phenotyping for Stay Green of Wheat Population},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {24},
ARTICLE-NUMBER = {5173},
URL = {https://www.mdpi.com/2072-4292/13/24/5173},
ISSN = {2072-4292},
ABSTRACT = {High throughput phenotyping (HTP) for wheat (Triticum aestivum L.) stay green (SG) is expected in field breeding as SG is a beneficial phenotype for wheat high yield and environment adaptability. The RGB and multispectral imaging based on the unmanned aerial vehicle (UAV) are widely popular multi-purpose HTP platforms for crops in the field. The purpose of this study was to compare the potential of UAV RGB and multispectral images (MSI) in SG phenotyping of diversified wheat germplasm. The multi-temporal images of 450 samples (406 wheat genotypes) were obtained and the color indices (CIs) from RGB and MSI and spectral indices (SIs) from MSI were extracted, respectively. The four indices (CIs in RGB, CIs in MSI, SIs in MSI, and CIs + SIs in MSI) were used to detect four SG stages, respectively, by machine learning classifiers. Then, all indices&rsquo; dynamics were analyzed and the indices that varied monotonously and significantly were chosen to calculate wheat temporal stay green rates (SGR) to quantify the SG in diverse genotypes. The correlations between indices&rsquo; SGR and wheat yield were assessed and the dynamics of some indices&rsquo; SGR with different yield correlations were tracked in three visual observed SG grades samples. In SG stage detection, classifiers best average accuracy reached 93.20&ndash;98.60% and 93.80&ndash;98.80% in train and test set, respectively, and the SIs containing red edge or near-infrared band were more effective than the CIs calculated only by visible bands. Indices&rsquo; temporal SGR could quantify SG changes on a population level, but showed some differences in the correlation with yield and in tracking visual SG grades samples. In SIs, the SGR of Normalized Difference Red-edge Index (NDRE), Red-edge Chlorophyll Index (CIRE), and Normalized Difference Vegetation Index (NDVI) in MSI showed high correlations with yield and could track visual SG grades at an earlier stage of grain filling. In CIs, the SGR of Normalized Green Red Difference Index (NGRDI), the Green Leaf Index (GLI) in RGB and MSI showed low correlations with yield and could only track visual SG grades at late grain filling stage and that of Norm Red (NormR) in RGB images failed to track visual SG grades. This study preliminarily confirms the MSI is more available and reliable than RGB in phenotyping for wheat SG. The index-based SGR in this study could act as HTP reference solutions for SG in diversified wheat genotypes.},
DOI = {10.3390/rs13245173}
}



@Article{rs14010046,
AUTHOR = {Wei, Lele and Luo, Yusen and Xu, Lizhang and Zhang, Qian and Cai, Qibing and Shen, Mingjun},
TITLE = {Deep Convolutional Neural Network for Rice Density Prescription Map at Ripening Stage Using Unmanned Aerial Vehicle-Based Remotely Sensed Images},
JOURNAL = {Remote Sensing},
VOLUME = {14},
YEAR = {2022},
NUMBER = {1},
ARTICLE-NUMBER = {46},
URL = {https://www.mdpi.com/2072-4292/14/1/46},
ISSN = {2072-4292},
ABSTRACT = {In this paper, UAV (unmanned aerial vehicle, DJI Phantom4RTK) and YOLOv4 (You Only Look Once) target detection deep neural network methods were employed to collected mature rice images and detect rice ears to produce a rice density prescription map. The YOLOv4 model was used for rice ear quick detection of rice images captured by a UAV. The Kriging interpolation algorithm was used in ArcGIS to make rice density prescription maps. Mature rice images collected by a UAV were marked manually and used to build the training and testing datasets. The resolution of the images was 300 &times; 300 pixels. The batch size was 2, and the initial learning rate was 0.01, and the mean average precision (mAP) of the best trained model was 98.84%. Exceptionally, the network ability to detect rice in different health states was also studied with a mAP of 95.42% in the no infection rice images set, 98.84% in the mild infection rice images set, 94.35% in the moderate infection rice images set, and 93.36% in the severe infection rice images set. According to the severity of rice sheath blight, which can cause rice leaves to wither and turn yellow, the blighted grain percentage increased and the thousand-grain weight decreased, the rice images were divided into these four infection levels. The ability of the network model (R2 = 0.844) was compared with traditional image processing segmentation methods (R2 = 0.396) based on color and morphology features and machine learning image segmentation method (Support Vector Machine, SVM R2 = 0.0817, and K-means R2 = 0.1949) for rice ear counting. The results highlight that the CNN has excellent robustness, and can generate a wide range of rice density prescription maps.},
DOI = {10.3390/rs14010046}
}



@Article{drones6010005,
AUTHOR = {Munawar, Hafiz Suliman and Ullah, Fahim and Heravi, Amirhossein and Thaheem, Muhammad Jamaluddin and Maqsoom, Ahsen},
TITLE = {Inspecting Buildings Using Drones and Computer Vision: A Machine Learning Approach to Detect Cracks and Damages},
JOURNAL = {Drones},
VOLUME = {6},
YEAR = {2022},
NUMBER = {1},
ARTICLE-NUMBER = {5},
URL = {https://www.mdpi.com/2504-446X/6/1/5},
ISSN = {2504-446X},
ABSTRACT = {Manual inspection of infrastructure damages such as building cracks is difficult due to the objectivity and reliability of assessment and high demands of time and costs. This can be automated using unmanned aerial vehicles (UAVs) for aerial imagery of damages. Numerous computer vision-based approaches have been applied to address the limitations of crack detection but they have their limitations that can be overcome by using various hybrid approaches based on artificial intelligence (AI) and machine learning (ML) techniques. The convolutional neural networks (CNNs), an application of the deep learning (DL) method, display remarkable potential for automatically detecting image features such as damages and are less sensitive to image noise. A modified deep hierarchical CNN architecture has been used in this study for crack detection and damage assessment in civil infrastructures. The proposed architecture is based on 16 convolution layers and a cycle generative adversarial network (CycleGAN). For this study, the crack images were collected using UAVs and open-source images of mid to high rise buildings (five stories and above) constructed during 2000 in Sydney, Australia. Conventionally, a CNN network only utilizes the last layer of convolution. However, our proposed network is based on the utility of multiple layers. Another important component of the proposed CNN architecture is the application of guided filtering (GF) and conditional random fields (CRFs) to refine the predicted outputs to get reliable results. Benchmarking data (600 images) of Sydney-based buildings damages was used to test the proposed architecture. The proposed deep hierarchical CNN architecture produced superior performance when evaluated using five methods: GF method, Baseline (BN) method, Deep-Crack BN, Deep-Crack GF, and SegNet. Overall, the GF method outperformed all other methods as indicated by the global accuracy (0.990), class average accuracy (0.939), mean intersection of the union overall classes (IoU) (0.879), precision (0.838), recall (0.879), and F-score (0.8581) values. Overall, the proposed CNN architecture provides the advantages of reduced noise, highly integrated supervision of features, adequate learning, and aggregation of both multi-scale and multilevel features during the training procedure along with the refinement of the overall output predictions.},
DOI = {10.3390/drones6010005}
}



@Article{drones6010008,
AUTHOR = {Basan, Elena and Basan, Alexandr and Nekrasov, Alexey and Fidge, Colin and Sushkin, Nikita and Peskova, Olga},
TITLE = {GPS-Spoofing Attack Detection Technology for UAVs Based on Kullback&ndash;Leibler Divergence},
JOURNAL = {Drones},
VOLUME = {6},
YEAR = {2022},
NUMBER = {1},
ARTICLE-NUMBER = {8},
URL = {https://www.mdpi.com/2504-446X/6/1/8},
ISSN = {2504-446X},
ABSTRACT = {Here, we developed a method for detecting cyber security attacks aimed at spoofing the Global Positioning System (GPS) signal of an Unmanned Aerial Vehicle (UAV). Most methods for detecting UAV anomalies indicative of an attack use machine learning or other such methods that compare normal behavior with abnormal behavior. Such approaches require large amounts of data and significant &ldquo;training&rdquo; time to prepare and implement the system. Instead, we consider a new approach based on other mathematical methods for detecting UAV anomalies without the need to first collect a large amount of data and describe normal behavior patterns. Doing so can simplify the process of creating an anomaly detection system, which can further facilitate easier implementation of intrusion detection systems in UAVs. This article presents issues related to ensuring the information security of UAVs. Development of the GPS spoofing detection method for UAVs is then described, based on a preliminary study that made it possible to form a mathematical apparatus for solving the problem. We then explain the necessary analysis of parameters and methods of data normalization, and the analysis of the Kullback&mdash;Leibler divergence measure needed to detect anomalies in UAV systems.},
DOI = {10.3390/drones6010008}
}



@Article{f13010048,
AUTHOR = {Kamarulzaman, Aisyah Marliza Muhmad and Wan Mohd Jaafar, Wan Shafrina and Abdul Maulud, Khairul Nizam and Saad, Siti Nor Maizah and Omar, Hamdan and Mohan, Midhun},
TITLE = {Integrated Segmentation Approach with Machine Learning Classifier in Detecting and Mapping Post Selective Logging Impacts Using UAV Imagery},
JOURNAL = {Forests},
VOLUME = {13},
YEAR = {2022},
NUMBER = {1},
ARTICLE-NUMBER = {48},
URL = {https://www.mdpi.com/1999-4907/13/1/48},
ISSN = {1999-4907},
ABSTRACT = {Selective logging can cause significant impacts on the residual stands, affecting biodiversity and leading to environmental changes. Proper monitoring and mapping of the impacts from logging activities, such as the stumps, felled logs, roads, skid trails, and forest canopy gaps, are crucial for sustainable forest management operations. The purpose of this study is to assess the indicators of selective logging impacts by detecting the individual stumps as the main indicators, evaluating the performance of classification methods to assess the impacts and identifying forest gaps from selective logging activities. The combination of forest inventory field plots and unmanned aerial vehicle (UAV) RGB and overlapped imaged were used in this study to assess these impacts. The study area is located in Ulu Jelai Forest Reserve in the central part of Peninsular Malaysia, covering an experimental study area of 48 ha. The study involved the integration of template matching (TM), object-based image analysis (OBIA), and machine learning classification&mdash;support vector machine (SVM) and artificial neural network (ANN). Forest features and tree stumps were classified, and the canopy height model was used for detecting forest canopy gaps in the post selective logging region. Stump detection using the integration of TM and OBIA produced an accuracy of 75.8% when compared with the ground data. Forest classification using SVM and ANN methods were adopted to extract other impacts from logging activities such as skid trails, felled logs, roads and forest canopy gaps. These methods provided an overall accuracy of 85% and kappa coefficient value of 0.74 when compared with conventional classifier. The logging operation also caused an 18.6% loss of canopy cover. The result derived from this study highlights the potential use of UAVs for efficient post logging impact analysis and can be used to complement conventional forest inventory practices.},
DOI = {10.3390/f13010048}
}



@Article{app12020670,
AUTHOR = {Tursunboev, Jamshid and Kang, Yong-Sung and Huh, Sung-Bum and Lim, Dong-Woo and Kang, Jae-Mo and Jung, Heechul},
TITLE = {Hierarchical Federated Learning for Edge-Aided Unmanned Aerial Vehicle Networks},
JOURNAL = {Applied Sciences},
VOLUME = {12},
YEAR = {2022},
NUMBER = {2},
ARTICLE-NUMBER = {670},
URL = {https://www.mdpi.com/2076-3417/12/2/670},
ISSN = {2076-3417},
ABSTRACT = {Federated learning (FL) allows UAVs to collaboratively train a globally shared machine learning model while locally preserving their private data. Recently, the FL in edge-aided unmanned aerial vehicle (UAV) networks has drawn an upsurge of research interest due to a bursting increase in heterogeneous data acquired by UAVs and the need to build the global model with privacy; however, a critical issue is how to deal with the non-independent and identically distributed (non-i.i.d.) nature of heterogeneous data while ensuring the convergence of learning. To effectively address this challenging issue, this paper proposes a novel and high-performing FL scheme, namely, the hierarchical FL algorithm, for the edge-aided UAV network, which exploits the edge servers located in base stations as intermediate aggregators with employing commonly shared data. Experiment results demonstrate that the proposed hierarchical FL algorithm outperforms several baseline FL algorithms and exhibits better convergence behavior.},
DOI = {10.3390/app12020670}
}



@Article{drones6010021,
AUTHOR = {Zhang, Ruohao and Condomines, Jean-Philippe and Lochin, Emmanuel},
TITLE = {A Multifractal Analysis and Machine Learning Based Intrusion Detection System with an Application in a UAS/RADAR System},
JOURNAL = {Drones},
VOLUME = {6},
YEAR = {2022},
NUMBER = {1},
ARTICLE-NUMBER = {21},
URL = {https://www.mdpi.com/2504-446X/6/1/21},
ISSN = {2504-446X},
ABSTRACT = {The rapid development of Internet of Things (IoT) technology, together with mobile network technology, has created a never-before-seen world of interconnection, evoking research on how to make it vaster, faster, and safer. To support the ongoing fight against the malicious misuse of networks, in this paper we propose a novel algorithm called AMDES (unmanned aerial system multifractal analysis intrusion detection system) for spoofing attack detection. This novel algorithm is based on both wavelet leader multifractal analysis (WLM) and machine learning (ML) principles. In earlier research on unmanned aerial systems (UAS), intrusion detection systems (IDS) based on multifractal (MF) spectral analysis have been used to provide accurate MF spectrum estimations of network traffic. Such an estimation is then used to detect and characterize flooding anomalies that can be observed in an unmanned aerial vehicle (UAV) network. However, the previous contributions have lacked the consideration of other types of network intrusions commonly observed in UAS networks, such as the man in the middle attack (MITM). In this work, this promising methodology has been accommodated to detect a spoofing attack within a UAS. This methodology highlights a robust approach in terms of false positive performance in detecting intrusions in a UAS location reporting system.},
DOI = {10.3390/drones6010021}
}



@Article{s22020601,
AUTHOR = {Sharma, Prakriti and Leigh, Larry and Chang, Jiyul and Maimaitijiang, Maitiniyazi and Caffé, Melanie},
TITLE = {Above-Ground Biomass Estimation in Oats Using UAV Remote Sensing and Machine Learning},
JOURNAL = {Sensors},
VOLUME = {22},
YEAR = {2022},
NUMBER = {2},
ARTICLE-NUMBER = {601},
URL = {https://www.mdpi.com/1424-8220/22/2/601},
PubMedID = {35062559},
ISSN = {1424-8220},
ABSTRACT = {Current strategies for phenotyping above-ground biomass in field breeding nurseries demand significant investment in both time and labor. Unmanned aerial vehicles (UAV) can be used to derive vegetation indices (VIs) with high throughput and could provide an efficient way to predict forage yield with high accuracy. The main objective of the study is to investigate the potential of UAV-based multispectral data and machine learning approaches in the estimation of oat biomass. UAV equipped with a multispectral sensor was flown over three experimental oat fields in Volga, South Shore, and Beresford, South Dakota, USA, throughout the pre- and post-heading growth phases of oats in 2019. A variety of vegetation indices (VIs) derived from UAV-based multispectral imagery were employed to build oat biomass estimation models using four machine-learning algorithms: partial least squares (PLS), support vector machine (SVM), Artificial neural network (ANN), and random forest (RF). The results showed that several VIs derived from the UAV collected images were significantly positively correlated with dry biomass for Volga and Beresford (r = 0.2&ndash;0.65), however, in South Shore, VIs were either not significantly or weakly correlated with biomass. For Beresford, approximately 70% of the variance was explained by PLS, RF, and SVM validation models using data collected during the post-heading phase. Likewise for Volga, validation models had lower coefficient of determination (R2 = 0.20&ndash;0.25) and higher error (RMSE = 700&ndash;800 kg/ha) than training models (R2 = 0.50&ndash;0.60; RMSE = 500&ndash;690 kg/ha). In South Shore, validation models were only able to explain approx. 15&ndash;20% of the variation in biomass, which is possibly due to the insignificant correlation values between VIs and biomass. Overall, this study indicates that airborne remote sensing with machine learning has potential for above-ground biomass estimation in oat breeding nurseries. The main limitation was inconsistent accuracy in model prediction across locations. Multiple-year spectral data, along with the inclusion of textural features like crop surface model (CSM) derived height and volumetric indicators, should be considered in future studies while estimating biophysical parameters like biomass.},
DOI = {10.3390/s22020601}
}



@Article{agronomy12010202,
AUTHOR = {Li, Zongpeng and Chen, Zhen and Cheng, Qian and Duan, Fuyi and Sui, Ruixiu and Huang, Xiuqiao and Xu, Honggang},
TITLE = {UAV-Based Hyperspectral and Ensemble Machine Learning for Predicting Yield in Winter Wheat},
JOURNAL = {Agronomy},
VOLUME = {12},
YEAR = {2022},
NUMBER = {1},
ARTICLE-NUMBER = {202},
URL = {https://www.mdpi.com/2073-4395/12/1/202},
ISSN = {2073-4395},
ABSTRACT = {Winter wheat is a widely-grown cereal crop worldwide. Using growth-stage information to estimate winter wheat yields in a timely manner is essential for accurate crop management and rapid decision-making in sustainable agriculture, and to increase productivity while reducing environmental impact. UAV remote sensing is widely used in precision agriculture due to its flexibility and increased spatial and spectral resolution. Hyperspectral data are used to model crop traits because of their ability to provide continuous rich spectral information and higher spectral fidelity. In this study, hyperspectral image data of the winter wheat crop canopy at the flowering and grain-filling stages was acquired by a low-altitude unmanned aerial vehicle (UAV), and machine learning was used to predict winter wheat yields. Specifically, a large number of spectral indices were extracted from the spectral data, and three feature selection methods, recursive feature elimination (RFE), Boruta feature selection, and the Pearson correlation coefficient (PCC), were used to filter high spectral indices in order to reduce the dimensionality of the data. Four major basic learner models, (1) support vector machine (SVM), (2) Gaussian process (GP), (3) linear ridge regression (LRR), and (4) random forest (RF), were also constructed, and an ensemble machine learning model was developed by combining the four base learner models. The results showed that the SVM yield prediction model, constructed on the basis of the preferred features, performed the best among the base learner models, with an R2 between 0.62 and 0.73. The accuracy of the proposed ensemble learner model was higher than that of each base learner model; moreover, the R2 (0.78) for the yield prediction model based on Boruta&rsquo;s preferred characteristics was the highest at the grain-filling stage.},
DOI = {10.3390/agronomy12010202}
}



@Article{s22020662,
AUTHOR = {Talaei Khoei, Tala and Ismail, Shereen and Kaabouch, Naima},
TITLE = {Dynamic Selection Techniques for Detecting GPS Spoofing Attacks on UAVs},
JOURNAL = {Sensors},
VOLUME = {22},
YEAR = {2022},
NUMBER = {2},
ARTICLE-NUMBER = {662},
URL = {https://www.mdpi.com/1424-8220/22/2/662},
PubMedID = {35062623},
ISSN = {1424-8220},
ABSTRACT = {Unmanned aerial vehicles are prone to several cyber-attacks, including Global Positioning System spoofing. Several techniques have been proposed for detecting such attacks. However, the recurrence and frequent Global Positioning System spoofing incidents show a need for effective security solutions to protect unmanned aerial vehicles. In this paper, we propose two dynamic selection techniques, Metric Optimized Dynamic selector and Weighted Metric Optimized Dynamic selector, which identify the most effective classifier for the detection of such attacks. We develop a one-stage ensemble feature selection method to identify and discard the correlated and low importance features from the dataset. We implement the proposed techniques using ten machine-learning models and compare their performance in terms of four evaluation metrics: accuracy, probability of detection, probability of false alarm, probability of misdetection, and processing time. The proposed techniques dynamically choose the classifier with the best results for detecting attacks. The results indicate that the proposed dynamic techniques outperform the existing ensemble models with an accuracy of 99.6%, a probability of detection of 98.9%, a probability of false alarm of 1.56%, a probability of misdetection of 1.09%, and a processing time of 1.24 s.},
DOI = {10.3390/s22020662}
}



@Article{rs14020415,
AUTHOR = {Ilniyaz, Osman and Kurban, Alishir and Du, Qingyun},
TITLE = {Leaf Area Index Estimation of Pergola-Trained Vineyards in Arid Regions Based on UAV RGB and Multispectral Data Using Machine Learning Methods},
JOURNAL = {Remote Sensing},
VOLUME = {14},
YEAR = {2022},
NUMBER = {2},
ARTICLE-NUMBER = {415},
URL = {https://www.mdpi.com/2072-4292/14/2/415},
ISSN = {2072-4292},
ABSTRACT = {The leaf area index (LAI), a valuable variable for assessing vine vigor, reflects nutrient concentrations in vineyards and assists in precise management, including fertilization, improving yield, quality, and vineyard uniformity. Although some vegetation indices (VIs) have been successfully used to assess LAI variations, they are unsuitable for vineyards of different types and structures. By calibrating the light extinction coefficient of a digital photography algorithm for proximal LAI measurements, this study aimed to develop VI-LAI models for pergola-trained vineyards based on high-resolution RGB and multispectral images captured by an unmanned aerial vehicle (UAV). The models were developed by comparing five machine learning (ML) methods, and a robust ensemble model was proposed using the five models as base learners. The results showed that the ensemble model outperformed the base models. The highest R2 and lowest RMSE values that were obtained using the best combination of VIs with multispectral data were 0.899 and 0.434, respectively; those obtained using the RGB data were 0.825 and 0.547, respectively. By improving the results by feature selection, ML methods performed better with multispectral data than with RGB images, and better with higher spatial resolution data than with lower resolution data. LAI variations can be monitored efficiently and accurately for large areas of pergola-trained vineyards using this framework.},
DOI = {10.3390/rs14020415}
}



@Article{agriculture12020124,
AUTHOR = {Song, Xiaoxin and Wu, Fei and Lu, Xiaotong and Yang, Tianle and Ju, Chengxin and Sun, Chengming and Liu, Tao},
TITLE = {The Classification of Farming Progress in Rice&ndash;Wheat Rotation Fields Based on UAV RGB Images and the Regional Mean Model},
JOURNAL = {Agriculture},
VOLUME = {12},
YEAR = {2022},
NUMBER = {2},
ARTICLE-NUMBER = {124},
URL = {https://www.mdpi.com/2077-0472/12/2/124},
ISSN = {2077-0472},
ABSTRACT = {Extraction of farming progress information in rice&ndash;wheat rotation regions is an important topic in smart field research. In this study, a new method for the classification of farming progress types using unmanned aerial vehicle (UAV) RGB images and the proposed regional mean (RM) model is presented. First, RGB information was extracted from the images to create and select the optimal color indices. After index classification, we compared the brightness reflection of the corresponding grayscale map, the classification interval, and the standard deviation of each farming progress type. These comparisons showed that the optimal classification color indices were the normalized red&ndash;blue difference index (NRBDI), the normalized green&ndash;blue difference index (NGBDI), and the modified red&ndash;blue difference index (MRBDI). Second, the RM model was built according to the whole-field farming progress classification requirements to achieve the final classification. We verified the model accuracy, and the Kappa coefficients obtained by combining the NRBDI, NGBDI, and MRBDI with the RM model were 0.86, 0.82, and 0.88, respectively. The proposed method was then applied to predict UAV RGB images of unharvested wheat, harvested wheat, and tilled and irrigated fields. The results were compared with those obtained with traditional machine learning methods, that is, the support vector machine, maximum likelihood classification, and random forest methods. The NRBDI, NGBDI, and MRBDI were combined with the RM model to monitor farming progress of ground truth ROIs, and the Kappa coefficients obtained were 0.9134, 0.8738, and 0.9179, respectively, while traditional machine learning methods all produced a Kappa coefficient less than 0.7. The results indicate a significantly higher accuracy of the proposed method than those of the traditional machine learning classification methods for the identification of farming progress type. The proposed work provides an important reference for the application of UAV to the field classification of progress types.},
DOI = {10.3390/agriculture12020124}
}



@Article{telecom3010005,
AUTHOR = {Tsipi, Lefteris and Karavolos, Michail and Vouyioukas, Demosthenes},
TITLE = {An Unsupervised Machine Learning Approach for UAV-Aided Offloading of 5G Cellular Networks},
JOURNAL = {Telecom},
VOLUME = {3},
YEAR = {2022},
NUMBER = {1},
PAGES = {86--102},
URL = {https://www.mdpi.com/2673-4001/3/1/5},
ISSN = {2673-4001},
ABSTRACT = {Today&rsquo;s terrestrial cellular communications networks face difficulties in serving coexisting users and devices due to the enormous demands of mass connectivity. Further, natural disasters and unexpected events lead to an unpredictable amount of data traffic, thus causing congestion to the network. In such cases, the addition of on-demand network entities, such as fixed or aerial base stations, has been proposed as a viable solution for managing high data traffic and offloading the existing terrestrial infrastructure. This paper presents an unmanned aerial vehicles (UAVs) aided offloading strategy of the terrestrial network, utilizing an unsupervised machine learning method for the best placement of UAVs in sites with high data traffic. The proposed scheme forms clusters of users located in the affected area using the k-medoid algorithm. Followingly, based on the number of available UAVs, a cluster selection scheme is employed to select the available UAVs that will be deployed to achieve maximum offloading in the system. Comparisons with traditional offloading strategies integrating terrestrial picocells and other UAV-aided schemes show that significant offloading, throughput, spectral efficiency, and sum rate gains can be harvested through the proposed method under a varying number of UAVs.},
DOI = {10.3390/telecom3010005}
}



@Article{rs14030518,
AUTHOR = {Brewer, Kiara and Clulow, Alistair and Sibanda, Mbulisi and Gokool, Shaeden and Naiken, Vivek and Mabhaudhi, Tafadzwanashe},
TITLE = {Predicting the Chlorophyll Content of Maize over Phenotyping as a Proxy for Crop Health in Smallholder Farming Systems},
JOURNAL = {Remote Sensing},
VOLUME = {14},
YEAR = {2022},
NUMBER = {3},
ARTICLE-NUMBER = {518},
URL = {https://www.mdpi.com/2072-4292/14/3/518},
ISSN = {2072-4292},
ABSTRACT = {Smallholder farmers depend on healthy and productive crop yields to sustain their socio-economic status and ensure livelihood security. Advances in South African precision agriculture in the form of unmanned aerial vehicles (UAVs) provide spatially explicit near-real-time information that can be used to assess crop dynamics and inform smallholder farmers. The use of UAVs with remote-sensing techniques allows for the acquisition of high spatial resolution data at various spatio-temporal planes, which is particularly useful at the scale of fields and farms. Specifically, crop chlorophyll content is assessed as it is one of the best known and reliable indicators of crop health, due to its biophysical pigment and biochemical processes that indicate plant productivity. In this regard, the study evaluated the utility of multispectral UAV imagery using the random forest machine learning algorithm to estimate the chlorophyll content of maize through the various growth stages. The results showed that the near-infrared and red-edge wavelength bands and vegetation indices derived from these wavelengths were essential for estimating chlorophyll content during the phenotyping of maize. Furthermore, the random forest model optimally estimated the chlorophyll content of maize over the various phenological stages. Particularly, maize chlorophyll was best predicted during the early reproductive, late vegetative, and early vegetative growth stages to RMSE accuracies of 40.4 &micro;mol/m&minus;2, 39 &micro;mol/m&minus;2, and 61.6 &micro;mol/m&minus;2, respectively. The least accurate chlorophyll content results were predicted during the mid-reproductive and late reproductive growth stages to RMSE accuracies of 66.6 &micro;mol/m&minus;2 and 69.6 &micro;mol/m&minus;2, respectively, as a consequence of a hailstorm. A resultant chlorophyll variation map of the maize growth stages captured the spatial heterogeneity of chlorophyll within the maize field. Therefore, the study&rsquo;s findings demonstrate that the use of remotely sensed UAV imagery with a robust machine algorithm is a critical tool to support the decision-making and management in smallholder farms.},
DOI = {10.3390/rs14030518}
}



@Article{rs14030592,
AUTHOR = {Reedha, Reenul and Dericquebourg, Eric and Canals, Raphael and Hafiane, Adel},
TITLE = {Transformer Neural Network for Weed and Crop Classification of High Resolution UAV Images},
JOURNAL = {Remote Sensing},
VOLUME = {14},
YEAR = {2022},
NUMBER = {3},
ARTICLE-NUMBER = {592},
URL = {https://www.mdpi.com/2072-4292/14/3/592},
ISSN = {2072-4292},
ABSTRACT = {Monitoring crops and weeds is a major challenge in agriculture and food production today. Weeds compete directly with crops for moisture, nutrients, and sunlight. They therefore have a significant negative impact on crop yield if not sufficiently controlled. Weed detection and mapping is an essential step in weed control. Many existing research studies recognize the importance of remote sensing systems and machine learning algorithms in weed management. Deep learning approaches have shown good performance in many agriculture-related remote sensing tasks, such as plant classification, disease detection, etc. However, despite the success of these approaches, they still face many challenges such as high computation cost, the need of large labelled datasets, intra-class discrimination (in growing phase weeds and crops share many attributes similarity as color, texture, and shape), etc. This paper aims to show that the attention-based deep network is a promising approach to address the forementioned problems, in the context of weeds and crops recognition with drone system. The specific objective of this study was to investigate visual transformers (ViT) and apply them to plant classification in Unmanned Aerial Vehicles (UAV) images. Data were collected using a high-resolution camera mounted on a UAV, which was deployed in beet, parsley and spinach fields. The acquired data were augmented to build larger dataset, since ViT requires large sample sets for better performance, we also adopted the transfer learning strategy. Experiments were set out to assess the effect of training and validation dataset size, as well as the effect of increasing the test set while reducing the training set. The results show that with a small labeled training dataset, the ViT models outperform state-of-the-art models such as EfficientNet and ResNet. The results of this study are promising and show the potential of ViT to be applied to a wide range of remote sensing image analysis tasks.},
DOI = {10.3390/rs14030592}
}



@Article{rs14030799,
AUTHOR = {Kurihara, Junichi and Koo, Voon-Chet and Guey, Cheaw Wen and Lee, Yang Ping and Abidin, Haryati},
TITLE = {Early Detection of Basal Stem Rot Disease in Oil Palm Tree Using Unmanned Aerial Vehicle-Based Hyperspectral Imaging},
JOURNAL = {Remote Sensing},
VOLUME = {14},
YEAR = {2022},
NUMBER = {3},
ARTICLE-NUMBER = {799},
URL = {https://www.mdpi.com/2072-4292/14/3/799},
ISSN = {2072-4292},
ABSTRACT = {Early detection of basal stem rot (BSR) disease in oil palm trees is important for the sustainable production of palm oil in the limited land for plantation in Southeast Asia. However, previous studies based on satellite and aircraft hyperspectral remote sensing could not discriminate oil palm trees in the early-stage of the BSR disease from healthy or late-stage trees. In this study, hyperspectral imaging of oil palm trees from an unmanned aerial vehicle (UAV) and machine learning using a random forest algorithm were employed for the classification of four infection categories of the BSR disease: healthy, early-stage, late-stage, and dead trees. A concentric disk segmentation was applied to tree crown segmentation at the sub-plant scale, and recursive feature elimination was used for feature selection. The results revealed that the classification performance for the early-stage trees is maximum at the specific tree crown segments, and only a few spectral bands in the red-edge region are sufficient to classify the infection categories. These findings will be useful for future UAV-based multispectral imaging to efficiently cover a wide area of oil palm plantations for the early detection of BSR disease.},
DOI = {10.3390/rs14030799}
}



@Article{rs14040909,
AUTHOR = {Junttila, Samuli and Näsi, Roope and Koivumäki, Niko and Imangholiloo, Mohammad and Saarinen, Ninni and Raisio, Juha and Holopainen, Markus and Hyyppä, Hannu and Hyyppä, Juha and Lyytikäinen-Saarenmaa, Päivi and Vastaranta, Mikko and Honkavaara, Eija},
TITLE = {Multispectral Imagery Provides Benefits for Mapping Spruce Tree Decline Due to Bark Beetle Infestation When Acquired Late in the Season},
JOURNAL = {Remote Sensing},
VOLUME = {14},
YEAR = {2022},
NUMBER = {4},
ARTICLE-NUMBER = {909},
URL = {https://www.mdpi.com/2072-4292/14/4/909},
ISSN = {2072-4292},
ABSTRACT = {Climate change is increasing pest insects&rsquo; ability to reproduce as temperatures rise, resulting in vast tree mortality globally. Early information on pest infestation is urgently needed for timely decisions to mitigate the damage. We investigated the mapping of trees that were in decline due to European spruce bark beetle infestation using multispectral unmanned aerial vehicles (UAV)-based imagery collected in spring and fall in four study areas in Helsinki, Finland. We used the Random Forest machine learning to classify trees based on their symptoms during both occasions. Our approach achieved an overall classification accuracy of 78.2% and 84.5% for healthy, declined and dead trees for spring and fall datasets, respectively. The results suggest that fall or the end of summer provides the most accurate tree vitality classification results. We also investigated the transferability of Random Forest classifiers between different areas, resulting in overall classification accuracies ranging from 59.3% to 84.7%. The findings of this study indicate that multispectral UAV-based imagery is capable of classifying tree decline in Norway spruce trees during a bark beetle infestation.},
DOI = {10.3390/rs14040909}
}



@Article{rs14040998,
AUTHOR = {Liang, Min-Chih and Tfwala, Samkele S. and Chen, Su-Chin},
TITLE = {The Evaluation of Color Spaces for Large Woody Debris Detection in Rivers Using XGBoost Algorithm},
JOURNAL = {Remote Sensing},
VOLUME = {14},
YEAR = {2022},
NUMBER = {4},
ARTICLE-NUMBER = {998},
URL = {https://www.mdpi.com/2072-4292/14/4/998},
ISSN = {2072-4292},
ABSTRACT = {Large woody debris (LWD) strongly influences river systems, especially in forested and mountainous catchments. In Taiwan, LWD are mainly from typhoons and extreme torrential events. To effectively manage the LWD, it is necessary to conduct regular surveys on river systems. Simple, low cost, and accurate tools are therefore necessary. The proposed methodology applies image processing and machine learning (XGBoost classifier) to quantify LWD distribution, location, and volume in river channels. XGBoost algorithm was selected due to its scalability and faster execution speeds. Nishueibei River, located in Taitung County, was used as the area of investigation. Unmanned aerial vehicles (UAVs) were used to capture the terrain and LWD. Structure from Motion (SfM) was used to build high-resolution orthophotos and digital elevation models (DEM), after which machine learning and different color spaces were used to recognize LWD. Finally, the volume of LWD in the river was estimated. The findings show that RGB color space as LWD recognition factor suffers serious collinearity problems, and it is easy to lose some LWD information; thus, it is not suitable for LWD recognition. On the contrary, the combination of different factors in different color spaces enhances the results, and most of the factors are related to the YCbCr color space. The CbCr factor in the YCbCr color space was best for identifying LWD. LWD volume was then estimated from the identified LWD using manual, field, and automatic measurements. The results indicate that the manual measurement method was the best (R2 = 0.88) to identify field LWD volume. Moreover, automatic measurement (R2 = 0.72) can also obtain LWD volume to save time and workforce.},
DOI = {10.3390/rs14040998}
}



@Article{rs14041023,
AUTHOR = {Guan, Yunyi and Grote, Katherine and Schott, Joel and Leverett, Kelsi},
TITLE = {Prediction of Soil Water Content and Electrical Conductivity Using Random Forest Methods with UAV Multispectral and Ground-Coupled Geophysical Data},
JOURNAL = {Remote Sensing},
VOLUME = {14},
YEAR = {2022},
NUMBER = {4},
ARTICLE-NUMBER = {1023},
URL = {https://www.mdpi.com/2072-4292/14/4/1023},
ISSN = {2072-4292},
ABSTRACT = {The volumetric water content (VWC) of soil is a critical parameter in agriculture, as VWC strongly influences crop yield, provides nutrients to plants, and maintains the microbes that are needed for the biological health of the soil. Measuring VWC is difficult, as it is spatially and temporally heterogeneous, and most agricultural producers use point measurements that cannot fully capture this parameter. Electrical conductivity (EC) is another soil parameter that is useful in agriculture, since it can be used to indicate soil salinity, soil texture, and plant nutrient availability. Soil EC is also very heterogeneous; measuring EC using conventional soil sampling techniques is very time consuming and often fails to capture the variability in EC at a site. In contrast to the point-based methods used to measure VWC and EC, multispectral data acquired with unmanned aerial vehicles (UAV) can cover large areas with high resolution. In agriculture, multispectral data are often used to calculate vegetation indices (VIs). In this research UAV-acquired VIs and raw multispectral data were used to predict soil VWC and EC. High-resolution geophysical methods were used to acquire more than 41,000 measurements of VWC and 8000 measurements of EC in 18 traverses across a field that contained 56 experimental plots. The plots varied by crop type (corn, soybeans, and alfalfa) and drainage (no drainage, moderate drainage, high drainage). Machine learning was performed using the random forest method to predict VWC and EC using VIs and multispectral data. Prediction accuracy was determined for several scenarios that assumed different levels of knowledge about crop type or drainage. Results showed that multispectral data improved prediction of VWC and EC, and the best predictions occurred when both the crop type and degree of drainage were known, but drainage was a more important input than crop type. Predictions were most accurate in drier soil, which may be due to the lower overall variability of VWC and EC under these conditions. An analysis of which multispectral data were most important showed that NDRE, VARI, and blue band data improved predictions the most. The final conclusions of this study are that inexpensive UAV-based multispectral data can be used to improve estimation of heterogenous soil properties, such as VWC and EC in active agricultural fields. In this study, the best estimates of these properties were obtained when the agriculture parameters in a field were fairly homogeneous (one crop type and the same type of drainage throughout the field), although improvements were observed even when these conditions were not met. The multispectral data that were most useful for prediction were those that penetrated deeper into the soil canopy or were sensitive to bare soil.},
DOI = {10.3390/rs14041023}
}



@Article{rs14051140,
AUTHOR = {Narmilan, Amarasingam and Gonzalez, Felipe and Salgadoe, Arachchige Surantha Ashan and Kumarasiri, Unupen Widanelage Lahiru Madhushanka and Weerasinghe, Hettiarachchige Asiri Sampageeth and Kulasekara, Buddhika Rasanjana},
TITLE = {Predicting Canopy Chlorophyll Content in Sugarcane Crops Using Machine Learning Algorithms and Spectral Vegetation Indices Derived from UAV Multispectral Imagery},
JOURNAL = {Remote Sensing},
VOLUME = {14},
YEAR = {2022},
NUMBER = {5},
ARTICLE-NUMBER = {1140},
URL = {https://www.mdpi.com/2072-4292/14/5/1140},
ISSN = {2072-4292},
ABSTRACT = {The use of satellite-based Remote Sensing (RS) is a well-developed field of research. RS techniques have been successfully utilized to evaluate the chlorophyll content for the monitoring of sugarcane crops. This research provides a new framework for inferring the chlorophyll content in sugarcane crops at the canopy level using unmanned aerial vehicles (UAVs) and spectral vegetation indices processed with multiple machine learning algorithms. Studies were conducted in a sugarcane field located in Sugarcane Research Institute (SRI, Uda Walawe, Sri Lanka), with various fertilizer applications over the entire growing season from 2020 to 2021. An UAV with multispectral camera was used to collect the aerial images to generate the vegetation indices. Ground measurements of leaf chlorophyll were used as indications for fertilizer status in the sugarcane field. Different machine learning (ML) algorithms were used ground-truthing data of chlorophyll content and spectral vegetation indices to forecast sugarcane chlorophyll content. Several machine learning algorithms such as MLR, RF, DT, SVR, XGB, KNN and ANN were applied in two ways: before feature selection (BFS) by training the algorithms with all twenty-four (24) vegetation indices with five (05) spectral bands and after feature selection (AFS) by training algorithms with fifteen (15) vegetation indices. All the algorithms with both BFS and AFS methods were compared with an estimated coefficient of determination (R2) and root mean square error (RMSE). Spectral indices such as RVI and DVI were shown to be the most reliable indices for estimating chlorophyll content in sugarcane fields, with coefficients of determination (R2) of 0.94 and 0.93, respectively. XGB model shows the highest validation score (R2) and lowest RMSE in both methods of BFS (0.96 and 0.14) and AFS (0.98 and 0.78), respectively. However, KNN and SVR algorithms show the lowest validation accuracy than other models. According to the results, the AFS validation score is higher than BFS in MLR, SVR, XGB and KNN. Even though, validation score of the ANN model is decreased in AFS. The findings demonstrated that the use of multispectral UAV could be utilized to estimate chlorophyll content and measure crop health status over a larger sugarcane field. This methodology will aid in real-time crop nutrition management in sugarcane plantations by reducing the need for conventional measurement of sugarcane chlorophyll content.},
DOI = {10.3390/rs14051140}
}



@Article{f13030418,
AUTHOR = {Xu, Zhanghua and Zhang, Qi and Xiang, Songyang and Li, Yifan and Huang, Xuying and Zhang, Yiwei and Zhou, Xin and Li, Zenglu and Yao, Xiong and Li, Qiaosi and Guo, Xiaoyu},
TITLE = {Monitoring the Severity of Pantana phyllostachysae Chao Infestation in Moso Bamboo Forests Based on UAV Multi-Spectral Remote Sensing Feature Selection},
JOURNAL = {Forests},
VOLUME = {13},
YEAR = {2022},
NUMBER = {3},
ARTICLE-NUMBER = {418},
URL = {https://www.mdpi.com/1999-4907/13/3/418},
ISSN = {1999-4907},
ABSTRACT = {In recent years, the rapid development of unmanned aerial vehicle (UAV) remote sensing technology has provided a new means to efficiently monitor forest resources and effectively prevent and control pests and diseases. This study aims to develop a detection model to study the damage caused to Moso bamboo forests by Pantana phyllostachysae Chao (PPC), a major leaf-eating pest, at 5 cm resolution. Damage sensitive features were extracted from multispectral images acquired by UAVs and used to train detection models based on support vector machines (SVM), random forests (RF), and extreme gradient boosting tree (XGBoost) machine learning algorithms. The overall detection accuracy (OA) and Kappa coefficient of SVM, RF, and XGBoost were 81.95%, 0.733, 85.71%, 0.805, and 86.47%, 0.811, respectively. Meanwhile, the detection accuracies of SVM, RF, and XGBoost were 78.26%, 76.19%, and 80.95% for healthy, 75.00%, 83.87%, and 79.17% for mild damage, 83.33%, 86.49%, and 85.00% for moderate damage, and 82.5%, 90.91%, and 93.75% for severe damage Moso bamboo, respectively. Overall, XGBoost exhibited the best detection performance, followed by RF and SVM. Thus, the study findings provide a technical reference for the regional monitoring and control of PPC in Moso bamboo.},
DOI = {10.3390/f13030418}
}



@Article{s22052049,
AUTHOR = {Douklias, Athanasios and Karagiannidis, Lazaros and Misichroni, Fay and Amditis, Angelos},
TITLE = {Design and Implementation of a UAV-Based Airborne Computing Platform for Computer Vision and Machine Learning Applications},
JOURNAL = {Sensors},
VOLUME = {22},
YEAR = {2022},
NUMBER = {5},
ARTICLE-NUMBER = {2049},
URL = {https://www.mdpi.com/1424-8220/22/5/2049},
PubMedID = {35271196},
ISSN = {1424-8220},
ABSTRACT = {Visual sensing of the environment is crucial for flying an unmanned aerial vehicle (UAV) and is a centerpiece of many related applications. The ability to run computer vision and machine learning algorithms onboard an unmanned aerial system (UAS) is becoming more of a necessity in an effort to alleviate the communication burden of high-resolution video streaming, to provide flying aids, such as obstacle avoidance and automated landing, and to create autonomous machines. Thus, there is a growing interest on the part of many researchers in developing and validating solutions that are suitable for deployment on a UAV system by following the general trend of edge processing and airborne computing, which transforms UAVs from moving sensors into intelligent nodes that are capable of local processing. In this paper, we present, in a rigorous way, the design and implementation of a 12.85 kg UAV system equipped with the necessary computational power and sensors to serve as a testbed for image processing and machine learning applications, explain the rationale behind our decisions, highlight selected implementation details, and showcase the usefulness of our system by providing an example of how a sample computer vision application can be deployed on our platform.},
DOI = {10.3390/s22052049}
}



@Article{computation10030042,
AUTHOR = {Vasilopoulos, Emmanuel and Vosinakis, Georgios and Krommyda, Maria and Karagiannidis, Lazaros and Ouzounoglou, Eleftherios and Amditis, Angelos},
TITLE = {A Comparative Study of Autonomous Object Detection Algorithms in the Maritime Environment Using a UAV Platform},
JOURNAL = {Computation},
VOLUME = {10},
YEAR = {2022},
NUMBER = {3},
ARTICLE-NUMBER = {42},
URL = {https://www.mdpi.com/2079-3197/10/3/42},
ISSN = {2079-3197},
ABSTRACT = {Maritime operations rely heavily on surveillance and require reliable and timely data that can inform decisions and planning. Critical information in such cases includes the exact location of objects in the water, such as vessels, persons, and others. Due to the unique characteristics of the maritime environment, the location of even inert objects changes through time, depending on the weather conditions, water currents, etc. Unmanned aerial vehicles (UAVs) can be used to support maritime operations by providing live video streams and images from the area of operations. Machine learning algorithms can be developed, trained, and used to automatically detect and track objects of specific types and characteristics. EFFECTOR is an EU-funded project, developing an Interoperability Framework for maritime surveillance. Within the project, we developed an embedded system that employs machine learning algorithms, allowing a UAV to autonomously detect objects in the water and keep track of their changing position through time. Using the on-board computation unit of the UAV, we ran and present the results of a series of comparative tests among possible architecture sizes and training datasets for the detection and tracking of objects in the maritime environment. We tested architectures based on their efficiency, accuracy, and speed. A combined solution for training the datasets is suggested, providing optimal efficiency and accuracy.},
DOI = {10.3390/computation10030042}
}



@Article{rs14061474,
AUTHOR = {Bian, Chaofa and Shi, Hongtao and Wu, Suqin and Zhang, Kefei and Wei, Meng and Zhao, Yindi and Sun, Yaqin and Zhuang, Huifu and Zhang, Xuewei and Chen, Shuo},
TITLE = {Prediction of Field-Scale Wheat Yield Using Machine Learning Method and Multi-Spectral UAV Data},
JOURNAL = {Remote Sensing},
VOLUME = {14},
YEAR = {2022},
NUMBER = {6},
ARTICLE-NUMBER = {1474},
URL = {https://www.mdpi.com/2072-4292/14/6/1474},
ISSN = {2072-4292},
ABSTRACT = {Accurate prediction of food crop yield is of great significance for global food security and regional trade stability. Since remote sensing data collected from unmanned aerial vehicle (UAV) platforms have the features of flexibility and high resolution, these data can be used as samples to develop regional regression models for accurate prediction of crop yield at a field scale. The primary objective of this study was to construct regional prediction models for winter wheat yield based on multi-spectral UAV data and machine learning methods. Six machine learning methods including Gaussian process regression (GPR), support vector machine regression (SVR) and random forest regression (RFR) were used for the construction of the yield prediction models. Ten vegetation indices (VIs) extracted from canopy spectral images of winter wheat acquired from a multi-spectral UAV at five key growth stages in Xuzhou City, Jiangsu Province, China in 2021 were selected as the variables of the models. In addition, in situ measurements of wheat yield were obtained in a destructive sampling manner for prediction algorithm modeling and validation. Prediction results of single growth stages showed that the optimal model was GPR constructed from extremely strong correlated VIs (ESCVIs) at the filling stage (R2 = 0.87, RMSE = 49.22 g/m2, MAE = 42.74 g/m2). The results of multiple stages showed GPR achieved the highest accuracy (R2 = 0.88, RMSE = 49.18 g/m2, MAE = 42.57 g/m2) when the ESCVIs of the flowering and filling stages were used. Larger sampling plots were adopted to verify the accuracy of yield prediction; the results indicated that the GPR model has strong adaptability at different scales. These findings suggest that using machine learning methods and multi-spectral UAV data can accurately predict crop yield at the field scale and deliver a valuable application reference for farm-scale field crop management.},
DOI = {10.3390/rs14061474}
}



@Article{ijgi11040222,
AUTHOR = {Ren, Simiao and Malof, Jordan and Fetter, Rob and Beach, Robert and Rineer, Jay and Bradbury, Kyle},
TITLE = {Utilizing Geospatial Data for Assessing Energy Security: Mapping Small Solar Home Systems Using Unmanned Aerial Vehicles and Deep Learning},
JOURNAL = {ISPRS International Journal of Geo-Information},
VOLUME = {11},
YEAR = {2022},
NUMBER = {4},
ARTICLE-NUMBER = {222},
URL = {https://www.mdpi.com/2220-9964/11/4/222},
ISSN = {2220-9964},
ABSTRACT = {Solar home systems (SHS), a cost-effective solution for rural communities far from the grid in developing countries, are small solar panels and associated equipment that provides power to a single household. A crucial resource for targeting further investment of public and private resources, as well as tracking the progress of universal electrification goals, is shared access to high-quality data on individual SHS installations including information such as location and power capacity. Though recent studies utilizing satellite imagery and machine learning to detect solar panels have emerged, they struggle to accurately locate many SHS due to limited image resolution (some small solar panels only occupy several pixels in satellite imagery). In this work, we explore the viability and cost-performance tradeoff of using automatic SHS detection on unmanned aerial vehicle (UAV) imagery as an alternative to satellite imagery. More specifically, we explore three questions: (i) what is the detection performance of SHS using drone imagery; (ii) how expensive is the drone data collection, compared to satellite imagery; and (iii) how well does drone-based SHS detection perform in real-world scenarios? To examine these questions, we collect and publicly-release a dataset of high-resolution drone imagery encompassing SHS imaged under a variety of real-world conditions and use this dataset and a dataset of imagery from Rwanda to evaluate the capabilities of deep learning models to recognize SHS, including those that are too small to be reliably recognized in satellite imagery. The results suggest that UAV imagery may be a viable alternative to identify very small SHS from perspectives of both detection accuracy and financial costs of data collection. UAV-based data collection may be a practical option for supporting electricity access planning strategies for achieving sustainable development goals and for monitoring the progress towards those goals.},
DOI = {10.3390/ijgi11040222}
}



@Article{s22072762,
AUTHOR = {Bae, Jaehoon and Lee, Jonghoon and Jang, Arum and Ju, Young K. and Park, Min Jae},
TITLE = {SMART SKY EYE System for Preliminary Structural Safety Assessment of Buildings Using Unmanned Aerial Vehicles},
JOURNAL = {Sensors},
VOLUME = {22},
YEAR = {2022},
NUMBER = {7},
ARTICLE-NUMBER = {2762},
URL = {https://www.mdpi.com/1424-8220/22/7/2762},
ISSN = {1424-8220},
ABSTRACT = {The development of unmanned aerial vehicles (UAVs) is expected to become one of the most commercialized research areas in the world over the next decade. Globally, unmanned aircraft have been increasingly used for safety surveillance in the construction industry and civil engineering fields. This paper presents an aerial image-based approach using UAVs to inspect cracks and deformations in buildings. A state-of-the-art safety evaluation method termed SMART SKY EYE (Smart building safety assessment system using UAV) is introduced; this system utilizes an unmanned airplane equipped with a thermal camera and programmed with various surveying efficiency improvement methods, such as thermography, machine-learning algorithms, and 3D point cloud modeling. Using this method, crack maps, crack depths, and the deformations of structures can be obtained. Error rates are compared between the proposed and conventional methods.},
DOI = {10.3390/s22072762}
}





@Article{s16010097,
AUTHOR = {Gonzalez, Luis F. and Montes, Glen A. and Puig, Eduard and Johnson, Sandra and Mengersen, Kerrie and Gaston, Kevin J.},
TITLE = {Unmanned Aerial Vehicles (UAVs) and Artificial Intelligence Revolutionizing Wildlife Monitoring and Conservation},
JOURNAL = {Sensors},
VOLUME = {16},
YEAR = {2016},
NUMBER = {1},
ARTICLE-NUMBER = {97},
URL = {https://www.mdpi.com/1424-8220/16/1/97},
PubMedID = {26784196},
ISSN = {1424-8220},
ABSTRACT = {Surveying threatened and invasive species to obtain accurate population estimates is an important but challenging task that requires a considerable investment in time and resources. Estimates using existing ground-based monitoring techniques, such as camera traps and surveys performed on foot, are known to be resource intensive, potentially inaccurate and imprecise, and difficult to validate. Recent developments in unmanned aerial vehicles (UAV), artificial intelligence and miniaturized thermal imaging systems represent a new opportunity for wildlife experts to inexpensively survey relatively large areas. The system presented in this paper includes thermal image acquisition as well as a video processing pipeline to perform object detection, classification and tracking of wildlife in forest or open areas. The system is tested on thermal video data from ground based and test flight footage, and is found to be able to detect all the target wildlife located in the surveyed area. The system is flexible in that the user can readily define the types of objects to classify and the object characteristics that should be considered during classification.},
DOI = {10.3390/s16010097}
}



@Article{su12072789,
AUTHOR = {Nikitas, Alexandros and Michalakopoulou, Kalliopi and Njoya, Eric Tchouamou and Karampatzakis, Dimitris},
TITLE = {Artificial Intelligence, Transport and the Smart City: Definitions and Dimensions of a New Mobility Era},
JOURNAL = {Sustainability},
VOLUME = {12},
YEAR = {2020},
NUMBER = {7},
ARTICLE-NUMBER = {2789},
URL = {https://www.mdpi.com/2071-1050/12/7/2789},
ISSN = {2071-1050},
ABSTRACT = {Artificial intelligence (AI) is a powerful concept still in its infancy that has the potential, if utilised responsibly, to provide a vehicle for positive change that could promote sustainable transitions to a more resource-efficient livability paradigm. AI with its deep learning functions and capabilities can be employed as a tool which empowers machines to solve problems that could reform urban landscapes as we have known them for decades now and help with establishing a new era; the era of the &ldquo;smart city&rdquo;. One of the key areas that AI can redefine is transport. Mobility provision and its impact on urban development can be significantly improved by the employment of intelligent transport systems in general and automated transport in particular. This new breed of AI-based mobility, despite its machine-orientation, has to be a user-centred technology that &ldquo;understands&rdquo; and &ldquo;satisfies&rdquo; the human user, the markets and the society as a whole. Trust should be built, and risks should be eliminated, for this transition to take off. This paper provides a novel conceptual contribution that thoroughly discusses the scarcely studied nexus of AI, transportation and the smart city and how this will affect urban futures. It specifically covers key smart mobility initiatives referring to Connected and Autonomous Vehicles (CAVs), autonomous Personal and Unmanned Aerial Vehicles (PAVs and UAVs) and Mobility-as-a-Service (MaaS), but also interventions that may work as enabling technologies for transport, such as the Internet of Things (IoT) and Physical Internet (PI) or reflect broader transformations like Industry 4.0. This work is ultimately a reference tool for researchers and city planners that provides clear and systematic definitions of the ambiguous smart mobility terms of tomorrow and describes their individual and collective roles underpinning the nexus in scope.},
DOI = {10.3390/su12072789}
}



@Article{s21124061,
AUTHOR = {Chodorek, Agnieszka and Chodorek, Robert Ryszard and Sitek, Paweł},
TITLE = {UAV-Based and WebRTC-Based Open Universal Framework to Monitor Urban and Industrial Areas},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {12},
ARTICLE-NUMBER = {4061},
URL = {https://www.mdpi.com/1424-8220/21/12/4061},
PubMedID = {34204805},
ISSN = {1424-8220},
ABSTRACT = {Nowadays, we are observing a rapid development of UAV-based monitoring systems, which are faced with more and more new tasks, such as high temporal resolution and high spatial resolution of measurements, or Artificial Intelligence on board. This paper presents the open universal framework intended for fast prototyping or building a short series of specialized flying monitoring systems able to work in urban and industrial areas. The proposed framework combines mobility of UAV with IoT measurements and full-stack WebRTC communications. WebRTC offers simultaneous transmission of both a real-time video stream and the flow of data coming from sensors, and ensures a kind of protection of data flow, which leads to preserving its near-real-time character and enables contextual communication. Addition of the AI accelerator hardware makes this system AI-ready, i.e., the IoT communication hub, which is the air component of our system, is able to perform tasks of AI-supported computing. The exemplary prototype of this system was evaluated in terms of the ability to work with fast-response sensors, the ability to work with high temporal and high spatial resolutions, video information in poor visibility conditions and AI-readiness. Results show that prototypes based on the proposed framework are able to meet the challenges of monitoring systems in smart cities and industrial areas.},
DOI = {10.3390/s21124061}
}



@Article{drones5020052,
AUTHOR = {Lee, Thomas and Mckeever, Susan and Courtney, Jane},
TITLE = {Flying Free: A Research Overview of Deep Learning in Drone Navigation Autonomy},
JOURNAL = {Drones},
VOLUME = {5},
YEAR = {2021},
NUMBER = {2},
ARTICLE-NUMBER = {52},
URL = {https://www.mdpi.com/2504-446X/5/2/52},
ISSN = {2504-446X},
ABSTRACT = {With the rise of Deep Learning approaches in computer vision applications, significant strides have been made towards vehicular autonomy. Research activity in autonomous drone navigation has increased rapidly in the past five years, and drones are moving fast towards the ultimate goal of near-complete autonomy. However, while much work in the area focuses on specific tasks in drone navigation, the contribution to the overall goal of autonomy is often not assessed, and a comprehensive overview is needed. In this work, a taxonomy of drone navigation autonomy is established by mapping the definitions of vehicular autonomy levels, as defined by the Society of Automotive Engineers, to specific drone tasks in order to create a clear definition of autonomy when applied to drones. A top–down examination of research work in the area is conducted, focusing on drone navigation tasks, in order to understand the extent of research activity in each area. Autonomy levels are cross-checked against the drone navigation tasks addressed in each work to provide a framework for understanding the trajectory of current research. This work serves as a guide to research in drone autonomy with a particular focus on Deep Learning-based solutions, indicating key works and areas of opportunity for development of this area in the future.},
DOI = {10.3390/drones5020052}
}



@Article{su131810426,
AUTHOR = {Munawar, Hafiz Suliman and Inam, Hina and Ullah, Fahim and Qayyum, Siddra and Kouzani, Abbas Z. and Mahmud, M. A. Parvez},
TITLE = {Towards Smart Healthcare: UAV-Based Optimized Path Planning for Delivering COVID-19 Self-Testing Kits Using Cutting Edge Technologies},
JOURNAL = {Sustainability},
VOLUME = {13},
YEAR = {2021},
NUMBER = {18},
ARTICLE-NUMBER = {10426},
URL = {https://www.mdpi.com/2071-1050/13/18/10426},
ISSN = {2071-1050},
ABSTRACT = {Coronavirus Disease 2019 (COVID-19) has emerged as a global pandemic since late 2019 and has affected all forms of human life and economic developments. Various techniques are used to collect the infected patients’ sample, which carries risks of transferring the infection to others. The current study proposes an AI-powered UAV-based sample collection procedure through self-collection kits delivery to the potential patients and bringing the samples back for testing. Using a hypothetical case study of Islamabad, Pakistan, various test cases are run where the UAVs paths are optimized using four key algorithms, greedy, intra-route, inter-route, and tabu, to save time and reduce carbon emissions associated with alternate transportation methods. Four cases with 30, 50, 100, and 500 patients are investigated for delivering the self-testing kits to the patients. The results show that the Tabu algorithm provides the best-optimized paths covering 31.85, 51.35, 85, and 349.15 km distance for different numbers of patients. In addition, the algorithms optimize the number of UAVs to be used in each case and address the studied cases patients with 5, 8, 14, and 71 UAVs, respectively. The current study provides the first step towards the practical handling of COVID-19 and other pandemics in developing countries, where the risks of spreading the infections can be minimized by reducing person-to-person contact. Furthermore, the reduced carbon footprints of these UAVs are an added advantage for developing countries that struggle to control such emissions. The proposed system is equally applicable to both developed and developing countries and can help reduce the spread of COVID-19 through minimizing the person-to-person contact, thus helping the transformation of healthcare to smart healthcare.},
DOI = {10.3390/su131810426}
}



@Article{rs13214481,
AUTHOR = {Sandino, Juan and Maire, Frederic and Caccetta, Peter and Sanderson, Conrad and Gonzalez, Felipe},
TITLE = {Drone-Based Autonomous Motion Planning System for Outdoor Environments under Object Detection Uncertainty},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {21},
ARTICLE-NUMBER = {4481},
URL = {https://www.mdpi.com/2072-4292/13/21/4481},
ISSN = {2072-4292},
ABSTRACT = {Recent advances in autonomy of unmanned aerial vehicles (UAVs) have increased their use in remote sensing applications, such as precision agriculture, biosecurity, disaster monitoring, and surveillance. However, onboard UAV cognition capabilities for understanding and interacting in environments with imprecise or partial observations, for objects of interest within complex scenes, are limited, and have not yet been fully investigated. This limitation of onboard decision-making under uncertainty has delegated the motion planning strategy in complex environments to human pilots, which rely on communication subsystems and real-time telemetry from ground control stations. This paper presents a UAV-based autonomous motion planning and object finding system under uncertainty and partial observability in outdoor environments. The proposed system architecture follows a modular design, which allocates most of the computationally intensive tasks to a companion computer onboard the UAV to achieve high-fidelity results in simulated environments. We demonstrate the system with a search and rescue (SAR) case study, where a lost person (victim) in bushland needs to be found using a sub-2 kg quadrotor UAV. The navigation problem is mathematically formulated as a partially observable Markov decision process (POMDP). A motion strategy (or policy) is obtained once a POMDP is solved mid-flight and in real time using augmented belief trees (ABT) and the TAPIR toolkit. The system’s performance was assessed using three flight modes: (1) mission mode, which follows a survey plan and used here as the baseline motion planner; (2) offboard mode, which runs the POMDP-based planner across the flying area; and (3) hybrid mode, which combines mission and offboard modes for improved coverage in outdoor scenarios. Results suggest the increased cognitive power added by the proposed motion planner and flight modes allow UAVs to collect more accurate victim coordinates compared to the baseline planner. Adding the proposed system to UAVs results in improved robustness against potential false positive readings of detected objects caused by data noise, inaccurate detections, and elevated complexity to navigate in time-critical applications, such as SAR.},
DOI = {10.3390/rs13214481}
}



@Article{buildings12020156,
AUTHOR = {Munawar, Hafiz Suliman and Ullah, Fahim and Shahzad, Danish and Heravi, Amirhossein and Qayyum, Siddra and Akram, Junaid},
TITLE = {Civil Infrastructure Damage and Corrosion Detection: An Application of Machine Learning},
JOURNAL = {Buildings},
VOLUME = {12},
YEAR = {2022},
NUMBER = {2},
ARTICLE-NUMBER = {156},
URL = {https://www.mdpi.com/2075-5309/12/2/156},
ISSN = {2075-5309},
ABSTRACT = {Automatic detection of corrosion and associated damages to civil infrastructures such as bridges, buildings, and roads, from aerial images captured by an Unmanned Aerial Vehicle (UAV), helps one to overcome the challenges and shortcomings (objectivity and reliability) associated with the manual inspection methods. Deep learning methods have been widely reported in the literature for civil infrastructure corrosion detection. Among them, convolutional neural networks (CNNs) display promising applicability for the automatic detection of image features less affected by image noises. Therefore, in the current study, we propose a modified version of deep hierarchical CNN architecture, based on 16 convolution layers and cycle generative adversarial network (CycleGAN), to predict pixel-wise segmentation in an end-to-end manner using the images of Bolte Bridge and sky rail areas in Victoria (Melbourne). The convolutedly designed model network proposed in the study is based on learning and aggregation of multi-scale and multilevel features while moving from the low convolutional layers to the high-level layers, thus reducing the consistency loss in images due to the inclusion of CycleGAN. The standard approaches only use the last convolutional layer, but our proposed architecture differs from these approaches and uses multiple layers. Moreover, we have used guided filtering and Conditional Random Fields (CRFs) methods to refine the prediction results. Additionally, the effectiveness of the proposed architecture was assessed using benchmarking data of 600 images of civil infrastructure. Overall, the results show that the deep hierarchical CNN architecture based on 16 convolution layers produced advanced performances when evaluated for different methods, including the baseline, PSPNet, DeepLab, and SegNet. Overall, the extended method displayed the Global Accuracy (GA); Class Average Accuracy (CAC); mean Intersection Of the Union (IOU); Precision (P); Recall (R); and F-score values of 0.989, 0.931, 0.878, 0.849, 0.818 and 0.833, respectively.},
DOI = {10.3390/buildings12020156}
}



@Article{su14073758,
AUTHOR = {Almalki, Faris A. and Aljohani, Maha and Algethami, Merfat and Soufiene, Ben Othman},
TITLE = {Incorporating Drone and AI to Empower Smart Journalism via Optimizing a Propagation Model},
JOURNAL = {Sustainability},
VOLUME = {14},
YEAR = {2022},
NUMBER = {7},
ARTICLE-NUMBER = {3758},
URL = {https://www.mdpi.com/2071-1050/14/7/3758},
ISSN = {2071-1050},
ABSTRACT = {In the recent digital age, information and communication technologies are rapidly contributing to remodel the media and journalism. Numerous technologies can be utilized by the media industry to capture news or events, taking footage and pictures of a breaking news. Technology and the media are interwoven, and neither can be detached from contemporary society in most nations. Unsurprisingly, technology has affected how and where information is shared. Nowadays, it is impractical to discuss media and the methods in which societies communicate without addressing the rapidity of technology change. Thus, the aerial journalism term has emerged, which refers to the ability of creating and conveying media content in a timely and efficient fashion. This work aims to integrate a drone with AI to empower aerial journalism via training a neural network to obtain an accurate channel using the NN-RBFN approach. The proposed work can enhance aerial media missions including investigative reporting (e.g., humanitarian crises), footage of news events (e.g., man-made and/or natural disasters), and livestreams for short-term, large-scale events (e.g., Olympic Games). In our digital media era, such a smart journalism approach would help to become far more sustainable and an eco-efficient process. Both MATLAB and 3D Remcom Wireless Insite tools have been used to carry out the simulation work. Simulated results indicate that the proposed NN-RBFN managed to obtain an accurate channel propagation model in a 3D scenario with a high accuracy rate reaching 99%. The proposed framework also could offer various media and journalism services (e.g., high data rate, wider coverage footprint) in timely and cost-effective manners in both normal scenarios or even in hard-to-reach zones and/or short-term, large-scale events.},
DOI = {10.3390/su14073758}
}





@Article{s16010097,
AUTHOR = {Gonzalez, Luis F. and Montes, Glen A. and Puig, Eduard and Johnson, Sandra and Mengersen, Kerrie and Gaston, Kevin J.},
TITLE = {Unmanned Aerial Vehicles (UAVs) and Artificial Intelligence Revolutionizing Wildlife Monitoring and Conservation},
JOURNAL = {Sensors},
VOLUME = {16},
YEAR = {2016},
NUMBER = {1},
ARTICLE-NUMBER = {97},
URL = {https://www.mdpi.com/1424-8220/16/1/97},
PubMedID = {26784196},
ISSN = {1424-8220},
ABSTRACT = {Surveying threatened and invasive species to obtain accurate population estimates is an important but challenging task that requires a considerable investment in time and resources. Estimates using existing ground-based monitoring techniques, such as camera traps and surveys performed on foot, are known to be resource intensive, potentially inaccurate and imprecise, and difficult to validate. Recent developments in unmanned aerial vehicles (UAV), artificial intelligence and miniaturized thermal imaging systems represent a new opportunity for wildlife experts to inexpensively survey relatively large areas. The system presented in this paper includes thermal image acquisition as well as a video processing pipeline to perform object detection, classification and tracking of wildlife in forest or open areas. The system is tested on thermal video data from ground based and test flight footage, and is found to be able to detect all the target wildlife located in the surveyed area. The system is flexible in that the user can readily define the types of objects to classify and the object characteristics that should be considered during classification.},
DOI = {10.3390/s16010097}
}



@Article{s17102196,
AUTHOR = {Sandino, Juan and Wooler, Adam and Gonzalez, Felipe},
TITLE = {Towards the Automatic Detection of Pre-Existing Termite Mounds through UAS and Hyperspectral Imagery},
JOURNAL = {Sensors},
VOLUME = {17},
YEAR = {2017},
NUMBER = {10},
ARTICLE-NUMBER = {2196},
URL = {https://www.mdpi.com/1424-8220/17/10/2196},
ISSN = {1424-8220},
ABSTRACT = {The increased technological developments in Unmanned Aerial Vehicles (UAVs) combined with artificial intelligence and Machine Learning (ML) approaches have opened the possibility of remote sensing of extensive areas of arid lands. In this paper, a novel approach towards the detection of termite mounds with the use of a UAV, hyperspectral imagery, ML and digital image processing is intended. A new pipeline process is proposed to detect termite mounds automatically and to reduce, consequently, detection times. For the classification stage, several ML classification algorithms’ outcomes were studied, selecting support vector machines as the best approach for their role in image classification of pre-existing termite mounds. Various test conditions were applied to the proposed algorithm, obtaining an overall accuracy of 68%. Images with satisfactory mound detection proved that the method is “resolution-dependent”. These mounds were detected regardless of their rotation and position in the aerial image. However, image distortion reduced the number of detected mounds due to the inclusion of a shape analysis method in the object detection phase, and image resolution is still determinant to obtain accurate results. Hyperspectral imagery demonstrated better capabilities to classify a huge set of materials than implementing traditional segmentation methods on RGB images only.},
DOI = {10.3390/s17102196}
}



@Article{s18051413,
AUTHOR = {Aadil, Farhan and Raza, Ali and Khan, Muhammad Fahad and Maqsood, Muazzam and Mehmood, Irfan and Rho, Seungmin},
TITLE = {Energy Aware Cluster-Based Routing in Flying Ad-Hoc Networks},
JOURNAL = {Sensors},
VOLUME = {18},
YEAR = {2018},
NUMBER = {5},
ARTICLE-NUMBER = {1413},
URL = {https://www.mdpi.com/1424-8220/18/5/1413},
ISSN = {1424-8220},
ABSTRACT = {Flying ad-hoc networks (FANETs) are a very vibrant research area nowadays. They have many military and civil applications. Limited battery energy and the high mobility of micro unmanned aerial vehicles (UAVs) represent their two main problems, i.e., short flight time and inefficient routing. In this paper, we try to address both of these problems by means of efficient clustering. First, we adjust the transmission power of the UAVs by anticipating their operational requirements. Optimal transmission range will have minimum packet loss ratio (PLR) and better link quality, which ultimately save the energy consumed during communication. Second, we use a variant of the K-Means Density clustering algorithm for selection of cluster heads. Optimal cluster heads enhance the cluster lifetime and reduce the routing overhead. The proposed model outperforms the state of the art artificial intelligence techniques such as Ant Colony Optimization-based clustering algorithm and Grey Wolf Optimization-based clustering algorithm. The performance of the proposed algorithm is evaluated in term of number of clusters, cluster building time, cluster lifetime and energy consumption.},
DOI = {10.3390/s18051413}
}



@Article{s18061855,
AUTHOR = {Shen, Lili and Guo, Jiming and Wang, Lei},
TITLE = {A Self-Organizing Spatial Clustering Approach to Support Large-Scale Network RTK Systems},
JOURNAL = {Sensors},
VOLUME = {18},
YEAR = {2018},
NUMBER = {6},
ARTICLE-NUMBER = {1855},
URL = {https://www.mdpi.com/1424-8220/18/6/1855},
ISSN = {1424-8220},
ABSTRACT = {The network real-time kinematic (RTK) technique can provide centimeter-level real time positioning solutions and play a key role in geo-spatial infrastructure. With ever-increasing popularity, network RTK systems will face issues in the support of large numbers of concurrent users. In the past, high-precision positioning services were oriented towards professionals and only supported a few concurrent users. Currently, precise positioning provides a spatial foundation for artificial intelligence (AI), and countless smart devices (autonomous cars, unmanned aerial-vehicles (UAVs), robotic equipment, etc.) require precise positioning services. Therefore, the development of approaches to support large-scale network RTK systems is urgent. In this study, we proposed a self-organizing spatial clustering (SOSC) approach which automatically clusters online users to reduce the computational load on the network RTK system server side. The experimental results indicate that both the SOSC algorithm and the grid algorithm can reduce the computational load efficiently, while the SOSC algorithm gives a more elastic and adaptive clustering solution with different datasets. The SOSC algorithm determines the cluster number and the mean distance to cluster center (MDTCC) according to the data set, while the grid approaches are all predefined. The side-effects of clustering algorithms on the user side are analyzed with real global navigation satellite system (GNSS) data sets. The experimental results indicate that 10 km can be safely used as the cluster radius threshold for the SOSC algorithm without significantly reducing the positioning precision and reliability on the user side.},
DOI = {10.3390/s18061855}
}



@Article{rs11040410,
AUTHOR = {Ampatzidis, Yiannis and Partel, Victor},
TITLE = {UAV-Based High Throughput Phenotyping in Citrus Utilizing Multispectral Imaging and Artificial Intelligence},
JOURNAL = {Remote Sensing},
VOLUME = {11},
YEAR = {2019},
NUMBER = {4},
ARTICLE-NUMBER = {410},
URL = {https://www.mdpi.com/2072-4292/11/4/410},
ISSN = {2072-4292},
ABSTRACT = {Traditional plant breeding evaluation methods are time-consuming, labor-intensive, and costly. Accurate and rapid phenotypic trait data acquisition and analysis can improve genomic selection and accelerate cultivar development. In this work, a technique for data acquisition and image processing was developed utilizing small unmanned aerial vehicles (UAVs), multispectral imaging, and deep learning convolutional neural networks to evaluate phenotypic characteristics on citrus crops. This low-cost and automated high-throughput phenotyping technique utilizes artificial intelligence (AI) and machine learning (ML) to: (i) detect, count, and geolocate trees and tree gaps; (ii) categorize trees based on their canopy size; (iii) develop individual tree health indices; and (iv) evaluate citrus varieties and rootstocks. The proposed remote sensing technique was able to detect and count citrus trees in a grove of 4,931 trees, with precision and recall of 99.9% and 99.7%, respectively, estimate their canopy size with overall accuracy of 85.5%, and detect, count, and geolocate tree gaps with a precision and recall of 100% and 94.6%, respectively. This UAV-based technique provides a consistent, more direct, cost-effective, and rapid method to evaluate phenotypic characteristics of citrus varieties and rootstocks.},
DOI = {10.3390/rs11040410}
}



@Article{s19040933,
AUTHOR = {Wang, Linhui and Yue, Xuejun and Liu, Yongxin and Wang, Jian and Wang, Huihui},
TITLE = {An Intelligent Vision Based Sensing Approach for Spraying Droplets Deposition Detection},
JOURNAL = {Sensors},
VOLUME = {19},
YEAR = {2019},
NUMBER = {4},
ARTICLE-NUMBER = {933},
URL = {https://www.mdpi.com/1424-8220/19/4/933},
ISSN = {1424-8220},
ABSTRACT = {The rapid development of vision sensor based on artificial intelligence (AI) is reforming industries and making our world smarter. Among these trends, it is of great significance to adapt AI technologies into the intelligent agricultural management. In smart agricultural aviation spraying, the droplets&rsquo; distribution and deposition are important indexes for estimating effectiveness in plant protection process. However, conventional approaches are problematic, they lack adaptivity to environmental changes, and consumes non-reusable test materials. One example is that the machine vision algorithms they employ can&rsquo;t guarantee that the division of adhesive droplets thereby disabling the accurate measurement of critical parameters. To alleviate these problems, we put forward an intelligent visual droplet detection node which can adapt to the environment illumination change. Then, we propose a modified marker controllable watershed segmentation algorithm to segment those adhesive droplets, and calculate their characteristic parameters on the basis of the segmentation results, including number, coverage, coverage density, etc. Finally, we use the intelligent node to detect droplets, and then expound the situation that the droplet region is effectively segmented and marked. The intelligent node has better adaptability and robustness even under the condition of illumination changing. The large-scale distributed detection result indicates that our approach has good consistency with the non-recyclable water-sensitive paper approach. Our approach provides an intelligent and environmental friendly way of tests for spraying techniques, especially for plant protection with Unmanned Aerial Vehicles.},
DOI = {10.3390/s19040933}
}



@Article{ijgi8110501,
AUTHOR = {Ham, Sungil and Im, Junhyuck and Kim, Minjun and Cho, Kuk},
TITLE = {Construction and Verification of a High-Precision Base Map for an Autonomous Vehicle Monitoring System},
JOURNAL = {ISPRS International Journal of Geo-Information},
VOLUME = {8},
YEAR = {2019},
NUMBER = {11},
ARTICLE-NUMBER = {501},
URL = {https://www.mdpi.com/2220-9964/8/11/501},
ISSN = {2220-9964},
ABSTRACT = {For autonomous driving, a control system that supports precise road maps is required to monitor the operation status of autonomous vehicles in the research stage. Such a system is also required for research related to automobile engineering, sensors, and artificial intelligence. The design of Google Maps and other map services is limited to the provision of map support at 20 levels of high-resolution precision. An ideal map should include information on roads, autonomous vehicles, and Internet of Things (IOT) facilities that support autonomous driving. The aim of this study was to design a map suitable for the control of autonomous vehicles in Gyeonggi Province in Korea. This work was part of the project &ldquo;Building a Testbed for Pilot Operations of Autonomous Vehicles&rdquo;. The map design scheme was redesigned for an autonomous vehicle control system based on the &ldquo;Easy Map&rdquo; developed by the National Geography Center, which provides free design schema. In addition, a vector-based precision map, including roads, sidewalks, and road markings, was produced to provide content suitable for 20 levels. A hybrid map that combines the vector layer of the road and an unmanned aerial vehicle (UAV) orthographic map was designed to facilitate vehicle identification. A control system that can display vehicle and sensor information based on the designed map was developed, and an environment to monitor the operation of autonomous vehicles was established. Finally, the high-precision map was verified through an accuracy test and driving data from autonomous vehicles.},
DOI = {10.3390/ijgi8110501}
}



@Article{rs12050767,
AUTHOR = {Cheng, Zhenzhen and Qi, Lijun and Cheng, Yifan and Wu, Yalei and Zhang, Hao},
TITLE = {Interlacing Orchard Canopy Separation and Assessment using UAV Images},
JOURNAL = {Remote Sensing},
VOLUME = {12},
YEAR = {2020},
NUMBER = {5},
ARTICLE-NUMBER = {767},
URL = {https://www.mdpi.com/2072-4292/12/5/767},
ISSN = {2072-4292},
ABSTRACT = {To minimize pesticide dosage and its adverse environmental impact, Unmanned Aerial Vehicle (UAV) spraying requires precise individual canopy information. Branches from neighboring trees may overlap, preventing image-based artificial intelligence analysis from correctly identifying individual trees. To solve this problem, this paper proposes a segmentation and evaluation method for mingled fruit tree canopies with irregular shapes. To extract the individual trees from mingled canopies, the study fitted the projection curve distribution of the interlacing tree with Gaussian Mixture Model (GMM) and solved the matter of segmentation by estimating the GMM parameters. For the intermingling degree assessment, the Gaussian parameters were used to quantify the characteristics of the mingled fruit trees and then as the input for Extreme Gradient Boosting (XGBoost) model training. The proposed method was tested on the aerial images of cherry and apple trees. Results of the experiments show that the proposed method can not only accurately identify individual trees, but also estimate the intermingledness of the interlacing canopies. The root mean squares (R) of the over-segmentation rate (Ro) and under-segmentation rate (Ru) for individual trees counting were less than 10%. Moreover, the Intersection over Union (IoU), used to evaluate the integrity of a single canopy area, was greater than 88%. An 84.3% Accuracy (ACC) with a standard deviation of 1.2% was achieved by the assessment model. This method will supply more accurate data of individual canopy for spray volume assessments or other precision-based applications in orchards.},
DOI = {10.3390/rs12050767}
}



@Article{su12072789,
AUTHOR = {Nikitas, Alexandros and Michalakopoulou, Kalliopi and Njoya, Eric Tchouamou and Karampatzakis, Dimitris},
TITLE = {Artificial Intelligence, Transport and the Smart City: Definitions and Dimensions of a New Mobility Era},
JOURNAL = {Sustainability},
VOLUME = {12},
YEAR = {2020},
NUMBER = {7},
ARTICLE-NUMBER = {2789},
URL = {https://www.mdpi.com/2071-1050/12/7/2789},
ISSN = {2071-1050},
ABSTRACT = {Artificial intelligence (AI) is a powerful concept still in its infancy that has the potential, if utilised responsibly, to provide a vehicle for positive change that could promote sustainable transitions to a more resource-efficient livability paradigm. AI with its deep learning functions and capabilities can be employed as a tool which empowers machines to solve problems that could reform urban landscapes as we have known them for decades now and help with establishing a new era; the era of the &ldquo;smart city&rdquo;. One of the key areas that AI can redefine is transport. Mobility provision and its impact on urban development can be significantly improved by the employment of intelligent transport systems in general and automated transport in particular. This new breed of AI-based mobility, despite its machine-orientation, has to be a user-centred technology that &ldquo;understands&rdquo; and &ldquo;satisfies&rdquo; the human user, the markets and the society as a whole. Trust should be built, and risks should be eliminated, for this transition to take off. This paper provides a novel conceptual contribution that thoroughly discusses the scarcely studied nexus of AI, transportation and the smart city and how this will affect urban futures. It specifically covers key smart mobility initiatives referring to Connected and Autonomous Vehicles (CAVs), autonomous Personal and Unmanned Aerial Vehicles (PAVs and UAVs) and Mobility-as-a-Service (MaaS), but also interventions that may work as enabling technologies for transport, such as the Internet of Things (IoT) and Physical Internet (PI) or reflect broader transformations like Industry 4.0. This work is ultimately a reference tool for researchers and city planners that provides clear and systematic definitions of the ambiguous smart mobility terms of tomorrow and describes their individual and collective roles underpinning the nexus in scope.},
DOI = {10.3390/su12072789}
}



@Article{ecsa-6-06640,
AUTHOR = {Harweg, Thomas and Peters, Annika and Bachmann, Daniel and Weichert, Frank},
TITLE = {CNN-Based Deep Architecture for Health Monitoring of Civil and Industrial Structures Using UAVs},
JOURNAL = {Proceedings},
VOLUME = {42},
YEAR = {2020},
NUMBER = {1},
ARTICLE-NUMBER = {69},
URL = {https://www.mdpi.com/2504-3900/42/1/69},
ISSN = {2504-3900},
ABSTRACT = {Health monitoring of civil and industrial structures has been gaining importance since the collapse of the bridge in Genoa (Italy). It is vital for the creation and maintenance of reliable infrastructure. Traditional manual inspections for this task are crucial but time consuming. We present a novel approach for combining Unmanned Aerial Vehicles (UAVs) and artificial intelligence to tackle the above-mentioned challenges. Modern architectures in Convolutional Neural Networks (CNNs) were adapted to the special characteristics of data streams gathered from UAV visual sensors. The approach allows for automated detection and localization of various damages to steel structures, coatings, and fasteners, e.g., cracks or corrosion, under uncertain and real-life environments. The proposed model is based on a multi-stage cascaded classifier to account for the variety of detail level from the optical sensor captured during an UAV flight. This allows for reconciliation of the characteristics of gathered image data and crucial aspects from a steel engineer’s point of view. To improve performance of the system and minimize manual data annotation, we use transfer learning based on the well-known COCO dataset combined with field inspection images. This approach provides a solid data basis for object localization and classification with state-of-the-art CNN architectures.},
DOI = {10.3390/ecsa-6-06640}
}



@Article{agriengineering2020019,
AUTHOR = {Deng, Xiaoling and Tong, Zejing and Lan, Yubin and Huang, Zixiao},
TITLE = {Detection and Location of Dead Trees with Pine Wilt Disease Based on Deep Learning and UAV Remote Sensing},
JOURNAL = {AgriEngineering},
VOLUME = {2},
YEAR = {2020},
NUMBER = {2},
PAGES = {294--307},
URL = {https://www.mdpi.com/2624-7402/2/2/19},
ISSN = {2624-7402},
ABSTRACT = {Pine wilt disease causes huge economic losses to pine wood forestry because of its destructiveness and rapid spread. This paper proposes a detection and location method of pine wood nematode disease at a large scale adopting UAV (Unmanned Aerial Vehicle) remote sensing and artificial intelligence technology. The UAV remote sensing images were enhanced by computer vision tools. A Faster-RCNN (Faster Region Convolutional Neural Networks) deep learning framework based on a RPN (Region Proposal Network) network and the ResNet residual neural network were used to train the pine wilt diseased dead tree detection model. The loss function and the anchors in the RPN of the convolutional neural network were optimized. Finally, the location of pine wood nematode dead tree was conducted, which generated the geographic information on the detection results. The results show that ResNet101 performed better than VGG16 (Visual Geometry Group 16) convolutional neural network. The detection accuracy was improved and reached to about 90% after a series of optimizations to the network, meaning that the optimization methods proposed in this paper are feasible to pine wood nematode dead tree detection.},
DOI = {10.3390/agriengineering2020019}
}



@Article{electronics9071121,
AUTHOR = {Kong, Weiren and Zhou, Deyun and Yang, Zhen and Zhao, Yiyang and Zhang, Kai},
TITLE = {UAV Autonomous Aerial Combat Maneuver Strategy Generation with Observation Error Based on State-Adversarial Deep Deterministic Policy Gradient and Inverse Reinforcement Learning},
JOURNAL = {Electronics},
VOLUME = {9},
YEAR = {2020},
NUMBER = {7},
ARTICLE-NUMBER = {1121},
URL = {https://www.mdpi.com/2079-9292/9/7/1121},
ISSN = {2079-9292},
ABSTRACT = {With the development of unmanned aerial vehicle (UAV) and artificial intelligence (AI) technology, Intelligent UAV will be widely used in future autonomous aerial combat. Previous researches on autonomous aerial combat within visual range (WVR) have limitations due to simplifying assumptions, limited robustness, and ignoring sensor errors. In this paper, in order to consider the error of the aircraft sensors, we model the aerial combat WVR as a state-adversarial Markov decision process (SA-MDP), which introduce the small adversarial perturbations on state observations and these perturbations do not alter the environment directly, but can mislead the agent into making suboptimal decisions. Meanwhile, we propose a novel autonomous aerial combat maneuver strategy generation algorithm with high-performance and high-robustness based on state-adversarial deep deterministic policy gradient algorithm (SA-DDPG), which add a robustness regularizers related to an upper bound on performance loss at the actor-network. At the same time, a reward shaping method based on maximum entropy (MaxEnt) inverse reinforcement learning algorithm (IRL) is proposed to improve the aerial combat strategy generation algorithm&rsquo;s efficiency. Finally, the efficiency of the aerial combat strategy generation algorithm and the performance and robustness of the resulting aerial combat strategy is verified by simulation experiments. Our main contributions are three-fold. First, to introduce the observation errors of UAV, we are modeling air combat as SA-MDP. Second, to make the strategy network of air combat maneuver more robust in the presence of observation errors, we introduce regularizers into the policy gradient. Third, to solve the problem that air combat&rsquo;s reward function is too sparse, we use MaxEnt IRL to design a shaping reward to accelerate the convergence of SA-DDPG.},
DOI = {10.3390/electronics9071121}
}



@Article{inventions5030048,
AUTHOR = {Patel, Brijesh and Patle, Bhumeshwar},
TITLE = {Analysis of Firefly–Fuzzy Hybrid Algorithm for Navigation of Quad-Rotor Unmanned Aerial Vehicle},
JOURNAL = {Inventions},
VOLUME = {5},
YEAR = {2020},
NUMBER = {3},
ARTICLE-NUMBER = {48},
URL = {https://www.mdpi.com/2411-5134/5/3/48},
ISSN = {2411-5134},
ABSTRACT = {In the present scenario for the development of the unmanned aerial vehicle (UAV), artificial intelligence plays an important role in path planning and obstacle detection. Due to different environments, it is always a task to achieve the proper moment for achieving the target goal while avoiding obstacles with minimum human interference. To achieve the goal with the avoidance of obstacles, individual optimization techniques with metaheuristic algorithms such as fuzzy, particle swarm optimization (PSO), etc. were implemented in various configurations. However, the optimal solution was not attained. Thus, in order to achieve an optimal solution, a hybrid model was developed by using the firefly algorithm and the fuzzy algorithm, establishing multiple features of the individual controller. The path and time optimization were achieved by a standalone controller and a hybrid firefly&ndash;fuzzy controller in different conditions, whereby the results of the controller were validated by simulation and experimental results, highlighting the advantages of the hybrid controller over the single controller.},
DOI = {10.3390/inventions5030048}
}



@Article{rs12203305,
AUTHOR = {Kerkech, Mohamed and Hafiane, Adel and Canals, Raphael},
TITLE = {VddNet: Vine Disease Detection Network Based on Multispectral Images and Depth Map},
JOURNAL = {Remote Sensing},
VOLUME = {12},
YEAR = {2020},
NUMBER = {20},
ARTICLE-NUMBER = {3305},
URL = {https://www.mdpi.com/2072-4292/12/20/3305},
ISSN = {2072-4292},
ABSTRACT = {Vine pathologies generate several economic and environmental problems, causing serious difficulties for the viticultural activity. The early detection of vine disease can significantly improve the control of vine diseases and avoid spread of virus or fungi. Currently, remote sensing and artificial intelligence technologies are emerging in the field of precision agriculture. They offer interesting potential for crop disease management. However, despite the advances in these technologies, particularly deep learning technologies, many problems still present considerable challenges, such as semantic segmentation of images for disease mapping. In this paper, we present a new deep learning architecture called Vine Disease Detection Network (VddNet). It is based on three parallel auto-encoders integrating different information (i.e., visible, infrared and depth). Then, the decoder reconstructs and retrieves the features, and assigns a class to each output pixel. An orthophotos registration method is also proposed to align the three types of images and enable the processing by VddNet. The proposed architecture is assessed by comparing it with the most known architectures: SegNet, U-Net, DeepLabv3+ and PSPNet. The deep learning architectures were trained on multispectral data from an unmanned aerial vehicle (UAV) and depth map information extracted from 3D processing. The results of the proposed architecture show that the VddNet architecture achieves higher scores than the baseline methods. Moreover, this study demonstrates that the proposed method has many advantages compared to methods that directly use the UAV images.},
DOI = {10.3390/rs12203305}
}



@Article{s20216299,
AUTHOR = {Bhowmick, Sutanu and Nagarajaiah, Satish and Veeraraghavan, Ashok},
TITLE = {Vision and Deep Learning-Based Algorithms to Detect and Quantify Cracks on Concrete Surfaces from UAV Videos},
JOURNAL = {Sensors},
VOLUME = {20},
YEAR = {2020},
NUMBER = {21},
ARTICLE-NUMBER = {6299},
URL = {https://www.mdpi.com/1424-8220/20/21/6299},
ISSN = {1424-8220},
ABSTRACT = {Immediate assessment of structural integrity of important civil infrastructures, like bridges, hospitals, or dams, is of utmost importance after natural disasters. Currently, inspection is performed manually by engineers who look for local damages and their extent on significant locations of the structure to understand its implication on its global stability. However, the whole process is time-consuming and prone to human errors. Due to their size and extent, some regions of civil structures are hard to gain access for manual inspection. In such situations, a vision-based system of Unmanned Aerial Vehicles (UAVs) programmed with Artificial Intelligence algorithms may be an effective alternative to carry out a health assessment of civil infrastructures in a timely manner. This paper proposes a framework of achieving the above-mentioned goal using computer vision and deep learning algorithms for detection of cracks on the concrete surface from its image by carrying out image segmentation of pixels, i.e., classification of pixels in an image of the concrete surface and whether it belongs to cracks or not. The image segmentation or dense pixel level classification is carried out using a deep neural network architecture named U-Net. Further, morphological operations on the segmented images result in dense measurements of crack geometry, like length, width, area, and crack orientation for individual cracks present in the image. The efficacy and robustness of the proposed method as a viable real-life application was validated by carrying out a laboratory experiment of a four-point bending test on an 8-foot-long concrete beam of which the video is recorded using a camera mounted on a UAV-based, as well as a still ground-based, video camera. Detection, quantification, and localization of damage on a civil infrastructure using the proposed framework can directly be used in the prognosis of the structure&rsquo;s ability to withstand service loads.},
DOI = {10.3390/s20216299}
}



@Article{en13246496,
AUTHOR = {Pierdicca, Roberto and Paolanti, Marina and Felicetti, Andrea and Piccinini, Fabio and Zingaretti, Primo},
TITLE = {Automatic Faults Detection of Photovoltaic Farms: solAIr, a Deep Learning-Based System for Thermal Images},
JOURNAL = {Energies},
VOLUME = {13},
YEAR = {2020},
NUMBER = {24},
ARTICLE-NUMBER = {6496},
URL = {https://www.mdpi.com/1996-1073/13/24/6496},
ISSN = {1996-1073},
ABSTRACT = {Renewable energy sources will represent the only alternative to limit fossil fuel usage and pollution. For this reason, photovoltaic (PV) power plants represent one of the main systems adopted to produce clean energy. Monitoring the state of health of a system is fundamental. However, these techniques are time demanding, cause stops to the energy generation, and often require laboratory instrumentation, thus being not cost-effective for frequent inspections. Moreover, PV plants are often located in inaccessible places, making any intervention dangerous. In this paper, we propose solAIr, an artificial intelligence system based on deep learning for anomaly cells detection in photovoltaic images obtained from unmanned aerial vehicles equipped with a thermal infrared sensor. The proposed anomaly cells detection system is based on the mask region-based convolutional neural network (Mask R-CNN) architecture, adopted because it simultaneously performs object detection and instance segmentation, making it useful for the automated inspection task. The proposed system is trained and evaluated on the photovoltaic thermal images dataset, a publicly available dataset collected for this work. Furthermore, the performances of three state-of-art deep neural networks, (DNNs) including UNet, FPNet and LinkNet, are compared and evaluated. Results show the effectiveness and the suitability of the proposed approach in terms of intersection over union (IoU) and the Dice coefficient.},
DOI = {10.3390/en13246496}
}



@Article{rs13050858,
AUTHOR = {Koh, Joshua C.O. and Spangenberg, German and Kant, Surya},
TITLE = {Automated Machine Learning for High-Throughput Image-Based Plant Phenotyping},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {5},
ARTICLE-NUMBER = {858},
URL = {https://www.mdpi.com/2072-4292/13/5/858},
ISSN = {2072-4292},
ABSTRACT = {Automated machine learning (AutoML) has been heralded as the next wave in artificial intelligence with its promise to deliver high-performance end-to-end machine learning pipelines with minimal effort from the user. However, despite AutoML showing great promise for computer vision tasks, to the best of our knowledge, no study has used AutoML for image-based plant phenotyping. To address this gap in knowledge, we examined the application of AutoML for image-based plant phenotyping using wheat lodging assessment with unmanned aerial vehicle (UAV) imagery as an example. The performance of an open-source AutoML framework, AutoKeras, in image classification and regression tasks was compared to transfer learning using modern convolutional neural network (CNN) architectures. For image classification, which classified plot images as lodged or non-lodged, transfer learning with Xception and DenseNet-201 achieved the best classification accuracy of 93.2%, whereas AutoKeras had a 92.4% accuracy. For image regression, which predicted lodging scores from plot images, transfer learning with DenseNet-201 had the best performance (R2 = 0.8303, root mean-squared error (RMSE) = 9.55, mean absolute error (MAE) = 7.03, mean absolute percentage error (MAPE) = 12.54%), followed closely by AutoKeras (R2 = 0.8273, RMSE = 10.65, MAE = 8.24, MAPE = 13.87%). In both tasks, AutoKeras models had up to 40-fold faster inference times compared to the pretrained CNNs. AutoML has significant potential to enhance plant phenotyping capabilities applicable in crop breeding and precision agriculture.},
DOI = {10.3390/rs13050858}
}



@Article{app11104706,
AUTHOR = {Tullu, Abera and Endale, Bedada and Wondosen, Assefinew and Hwang, Ho-Yon},
TITLE = {Machine Learning Approach to Real-Time 3D Path Planning for Autonomous Navigation of Unmanned Aerial Vehicle},
JOURNAL = {Applied Sciences},
VOLUME = {11},
YEAR = {2021},
NUMBER = {10},
ARTICLE-NUMBER = {4706},
URL = {https://www.mdpi.com/2076-3417/11/10/4706},
ISSN = {2076-3417},
ABSTRACT = {The need for civilian use of Unmanned Aerial Vehicles (UAVs) has drastically increased in recent years. Their potential applications for civilian use include door-to-door package delivery, law enforcement, first aid, and emergency services in urban areas, which put the UAVs into obstacle collision risk. Therefore, UAVs are required to be equipped with sensors so as to acquire Artificial Intelligence (AI) to avoid potential risks during mission execution. The AI comes with intensive training of an on-board machine that is responsible to autonomously navigate the UAV. The training enables the UAV to develop humanoid perception of the environment it is to be navigating in. During the mission, this perception detects and localizes objects in the environment. It is based on this AI that this work proposes a real-time three-dimensional (3D) path planner that maneuvers the UAV towards destination through obstacle-free path. The proposed path planner has a heuristic sense of A⋆ algorithm, but requires no frontier nodes to be stored in a memory unlike A⋆. The planner relies on relative locations of detected objects (obstacles) and determines collision-free paths. This path planner is light-weight and hence a fast guidance method for real-time purposes. Its performance efficiency is proved through rigorous Software-In-The-Loop (SITL) simulations in constrained-environment and preliminary real flight tests.},
DOI = {10.3390/app11104706}
}



@Article{rs13112189,
AUTHOR = {Kang, Suktae and Yu, Myeong-Jong},
TITLE = {Ant-Mutated Immune Particle Filter Design for Terrain Referenced Navigation with Interferometric Radar Altimeter},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {11},
ARTICLE-NUMBER = {2189},
URL = {https://www.mdpi.com/2072-4292/13/11/2189},
ISSN = {2072-4292},
ABSTRACT = {This study aims to design a robust particle filter using artificial intelligence algorithms to enhance estimation performance using a low-grade interferometric radar altimeter (IRA). Based on the synthetic aperture radar (SAR) interferometry technology, the IRA can extract three-dimensional ground coordinates with at least two antennas. However, some IRA uncertainties caused by geometric factors and IRA-inherent measurement errors have proven to be difficult to eliminate by signal processing. These uncertainties contaminate IRA outputs, crucially impacting the navigation performance of low-grade IRA sensors in particular. To deal with such uncertainties, an ant-mutated immune particle filter (AMIPF) is proposed. The proposed filter combines the ant colony optimization (ACO) algorithm with the immune auxiliary particle filter (IAPF) to bring individual mutation intensity. The immune system indicates the stochastic parameters of the ACO, which conducts the mutation process in one step for the purpose of computational efficiency. The ant mutation then moves particles into the most desirable position using parameters from the immune system to obtain optimal particle diversity. To verify the performance of the proposed filter, a terrain referenced navigation (TRN) simulation was conducted on an unmanned aerial vehicle (UAV). The Monte Carlo simulation results show that the proposed filter is not only more computationally efficient than the IAPF but also outperforms both the IAPF and the auxiliary particle filter (APF) in navigation performance and robustness.},
DOI = {10.3390/rs13112189}
}



@Article{app11156864,
AUTHOR = {Shafiq, Muhammad and Ali, Zain Anwar and Alkhammash, Eman H.},
TITLE = {A Cluster-Based Hierarchical-Approach for the Path Planning of Swarm},
JOURNAL = {Applied Sciences},
VOLUME = {11},
YEAR = {2021},
NUMBER = {15},
ARTICLE-NUMBER = {6864},
URL = {https://www.mdpi.com/2076-3417/11/15/6864},
ISSN = {2076-3417},
ABSTRACT = {This paper addresses the path planning and control of multiple colonies/clusters that have unmanned aerial vehicles (UAV) which make a network in a hazardous environment. To solve the aforementioned issue, we design a new and novel hybrid algorithm. As seen in the mission requirement, to combine the Maximum-Minimum ant colony optimization (ACO) with Vicsek based multi-agent system (MAS) to make an Artificially Intelligent (AI) scheme. In order to control and manage the different colonies, UAVs make a form of a network. The designed method overcomes the deficiencies of existing algorithms related to controlling and synchronizing the information globally. Furthermore, our designed architecture bounds, lemmatizes the pheromone, and finds the best ants which then make the most optimized path. The key contribution of this study is to merge two unique algorithms into a hybrid algorithm that has superior performance than both algorithms operating separately. Another contribution of the designed method is the ability to increase the number of individual agents inside the colony or the number of colonies with a good convergence rate. Lastly, we also compared the simulation results with the non-dominated sorting genetic algorithm II (NSGA-II) in order to prove the designed algorithm has a better convergence rate.},
DOI = {10.3390/app11156864}
}



@Article{app11157148,
AUTHOR = {Endale, Bedada and Tullu, Abera and Shi, Hayoung and Kang, Beom-Soo},
TITLE = {Robust Approach to Supervised Deep Neural Network Training for Real-Time Object Classification in Cluttered Indoor Environment},
JOURNAL = {Applied Sciences},
VOLUME = {11},
YEAR = {2021},
NUMBER = {15},
ARTICLE-NUMBER = {7148},
URL = {https://www.mdpi.com/2076-3417/11/15/7148},
ISSN = {2076-3417},
ABSTRACT = {Unmanned aerial vehicles (UAVs) are being widely utilized for various missions: in both civilian and military sectors. Many of these missions demand UAVs to acquire artificial intelligence about the environments they are navigating in. This perception can be realized by training a computing machine to classify objects in the environment. One of the well known machine training approaches is supervised deep learning, which enables a machine to classify objects. However, supervised deep learning comes with huge sacrifice in terms of time and computational resources. Collecting big input data, pre-training processes, such as labeling training data, and the need for a high performance computer for training are some of the challenges that supervised deep learning poses. To address these setbacks, this study proposes mission specific input data augmentation techniques and the design of light-weight deep neural network architecture that is capable of real-time object classification. Semi-direct visual odometry (SVO) data of augmented images are used to train the network for object classification. Ten classes of 10,000 different images in each class were used as input data where 80% were for training the network and the remaining 20% were used for network validation. For the optimization of the designed deep neural network, a sequential gradient descent algorithm was implemented. This algorithm has the advantage of handling redundancy in the data more efficiently than other algorithms.},
DOI = {10.3390/app11157148}
}



@Article{agronomy11081554,
AUTHOR = {Lee, Dong-Ho and Kim, Hyeon-Jin and Park, Jong-Hwa},
TITLE = {UAV, a Farm Map, and Machine Learning Technology Convergence Classification Method of a Corn Cultivation Area},
JOURNAL = {Agronomy},
VOLUME = {11},
YEAR = {2021},
NUMBER = {8},
ARTICLE-NUMBER = {1554},
URL = {https://www.mdpi.com/2073-4395/11/8/1554},
ISSN = {2073-4395},
ABSTRACT = {South Korea’s agriculture is characterized by a mixture of various cultivated crops. In such an agricultural environment, convergence technology for ICT (information, communications, and technology) and AI (artificial intelligence) as well as agriculture is required to classify objects and predict yields. In general, the classification of paddy fields and field boundaries takes a lot of time and effort. The Farm Map was developed to clearly demarcate and classify the boundaries of paddy fields and fields in Korea. Therefore, this study tried to minimize the time and effort required to divide paddy fields and fields through the application of the Farm Map. To improve the fact that UAV image processing for a wide area requires a lot of time and effort to classify objects, we suggest a method for optimizing cultivated crop recognition. This study aimed to evaluate the applicability and effectiveness of machine learning classification techniques using a Farm Map in object-based mapping of agricultural land using unmanned aerial vehicles (UAVs). In this study, the advanced function selection method for object classification is to improve classification accuracy by using two types of classifiers, support vector machine (SVM) and random forest (RF). As a result of classification by applying a Farm Map-based SVM algorithm to wide-area UAV images, producer’s accuracy (PA) was 81.68%, user’s accuracy (UA) was 75.09%, the Kappa coefficient was 0.77, and the F-measure was 0.78. The results of classification by the Farm Map-based RF algorithm were as follows: PA of 96.58%, UA of 92.27%, a Kappa coefficient of 0.94, and the F-measure of 0.94. In the cultivation environment in which various crops were mixed, the corn cultivation area was estimated to be 96.54 ha by SVM, showing an accuracy of 90.27%. RF provided an estimate of 98.77 ha and showed an accuracy of 92.36%, which was higher than that of SVM. As a result of using the Farm Map for the object-based classification method, the agricultural land classification showed a higher efficiency in terms of time than the existing object classification method. Most importantly, it was confirmed that the efficiency of data processing can be increased by minimizing the possibility of misclassification in the obtained results. The obtained results confirmed that rapid and reliable analysis is possible when the cultivated area of crops is identified using UAV images, a Farm Map, and machine learning.},
DOI = {10.3390/agronomy11081554}
}



@Article{rs13163188,
AUTHOR = {Takechi, Hitoshi and Aragaki, Shunsuke and Irie, Mitsuteru},
TITLE = {Differentiation of River Sediments Fractions in UAV Aerial Images by Convolution Neural Network},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {16},
ARTICLE-NUMBER = {3188},
URL = {https://www.mdpi.com/2072-4292/13/16/3188},
ISSN = {2072-4292},
ABSTRACT = {Riverbed material has multiple functions in river ecosystems, such as habitats, feeding grounds, spawning grounds, and shelters for aquatic organisms, and particle size of riverbed material reflects the tractive force of the channel flow. Therefore, regular surveys of riverbed material are conducted for environmental protection and river flood control projects. The field method is the most conventional riverbed material survey. However, conventional surveys of particle size of riverbed material require much labor, time, and cost to collect material on site. Furthermore, its spatial representativeness is also a problem because of the limited survey area against a wide riverbank. As a further solution to these problems, in this study, we tried an automatic classification of riverbed conditions using aerial photography with an unmanned aerial vehicle (UAV) and image recognition with artificial intelligence (AI) to improve survey efficiency. Due to using AI for image processing, a large number of images can be handled regardless of whether they are of fine or coarse particles. We tried a classification of aerial riverbed images that have the difference of particle size characteristics with a convolutional neural network (CNN). GoogLeNet, Alexnet, VGG-16 and ResNet, the common pre-trained networks, were retrained to perform the new task with the 70 riverbed images using transfer learning. Among the networks tested, GoogleNet showed the best performance for this study. The overall accuracy of the image classification reached 95.4%. On the other hand, it was supposed that shadows of the gravels caused the error of the classification. The network retrained with the images taken in the uniform temporal period gives higher accuracy for classifying the images taken in the same period as the training data. The results suggest the potential of evaluating riverbed materials using aerial photography with UAV and image recognition with CNN.},
DOI = {10.3390/rs13163188}
}



@Article{aerospace8090267,
AUTHOR = {Kim, Eric J. and Perez, Ruben E.},
TITLE = {Neuroevolutionary Control for Autonomous Soaring},
JOURNAL = {Aerospace},
VOLUME = {8},
YEAR = {2021},
NUMBER = {9},
ARTICLE-NUMBER = {267},
URL = {https://www.mdpi.com/2226-4310/8/9/267},
ISSN = {2226-4310},
ABSTRACT = {The energy efficiency and flight endurance of small unmanned aerial vehicles (SUAVs) can be improved through the implementation of autonomous soaring strategies. Biologically inspired flight techniques such as dynamic and thermal soaring offer significant energy savings through the exploitation of naturally occurring wind phenomena for thrustless flight. Recent interest in the application of artificial intelligence algorithms for autonomous soaring has been motivated by the pursuit of instilling generalized behavior in control systems, centered around the use of neural networks. However, the topology of such networks is usually predetermined, restricting the search space of potential solutions, while often resulting in complex neural networks that can pose implementation challenges for the limited hardware onboard small-scale autonomous vehicles. In exploring a novel method of generating neurocontrollers, this paper presents a neural network-based soaring strategy to extend flight times and advance the potential operational capability of SUAVs. In this study, the Neuroevolution of Augmenting Topologies (NEAT) algorithm is used to train efficient and effective neurocontrollers that can control a simulated aircraft along sustained dynamic and thermal soaring trajectories. The proposed approach evolves interpretable neural networks in a way that preserves simplicity while maximizing performance without requiring extensive training datasets. As a result, the combined trajectory planning and aircraft control strategy is suitable for real-time implementation on SUAV platforms.},
DOI = {10.3390/aerospace8090267}
}



@Article{su132011359,
AUTHOR = {Aliyari, Mostafa and Droguett, Enrique Lopez and Ayele, Yonas Zewdu},
TITLE = {UAV-Based Bridge Inspection via Transfer Learning},
JOURNAL = {Sustainability},
VOLUME = {13},
YEAR = {2021},
NUMBER = {20},
ARTICLE-NUMBER = {11359},
URL = {https://www.mdpi.com/2071-1050/13/20/11359},
ISSN = {2071-1050},
ABSTRACT = {As bridge inspection becomes more advanced and more ubiquitous, artificial intelligence (AI) techniques, such as machine and deep learning, could offer suitable solutions to the nation’s problems of overdue bridge inspections. AI coupling with various data that can be captured by unmanned aerial vehicles (UAVs) enables fully automated bridge inspections. The key to the success of automated bridge inspection is a model capable of detecting failures from UAV data like images and films. In this context, this paper investigates the performances of state-of-the-art convolutional neural networks (CNNs) through transfer learning for crack detection in UAV-based bridge inspection. The performance of different CNN models is evaluated via UAV-based inspection of Skodsberg Bridge, located in eastern Norway. The low-level features are extracted in the last layers of the CNN models and these layers are trained using 19,023 crack and non-crack images. There is always a trade-off between the number of trainable parameters that CNN models need to learn for each specific task and the number of non-trainable parameters that come from transfer learning. Therefore, selecting the optimized amount of transfer learning is a challenging task and, as there is not enough research in this area, it will be studied in this paper. Moreover, UAV-based bridge inception images require specific attention to establish a suitable dataset as the input of CNN models that are trained on homogenous images. However, in the real implementation of CNN models in UAV-based bridge inspection images, there are always heterogeneities and noises, such as natural and artificial effects like different luminosities, spatial positions, and colors of the elements in an image. In this study, the effects of such heterogeneities on the performance of CNN models via transfer learning are examined. The results demonstrate that with a simplified image cropping technique and with minimum effort to preprocess images, CNN models can identify crack elements from non-crack elements with 81% accuracy. Moreover, the results show that heterogeneities inherent in UAV-based bridge inspection data significantly affect the performance of CNN models with an average 32.6% decrease of accuracy of the CNN models. It is also found that deeper CNN models do not provide higher accuracy compared to the shallower CNN models when the number of images for adoption to a specific task, in this case crack detection, is not large enough; in this study, 19,023 images and shallower models outperform the deeper models.},
DOI = {10.3390/su132011359}
}



@Article{agronomy11112140,
AUTHOR = {Gagliardi, Gianfranco and Lupia, Marco and Cario, Gianni and Cicchello Gaccio, Francesco and D’Angelo, Vincenzo and Cosma, Antonio Igor Maria and Casavola, Alessandro},
TITLE = {An Internet of Things Solution for Smart Agriculture},
JOURNAL = {Agronomy},
VOLUME = {11},
YEAR = {2021},
NUMBER = {11},
ARTICLE-NUMBER = {2140},
URL = {https://www.mdpi.com/2073-4395/11/11/2140},
ISSN = {2073-4395},
ABSTRACT = {Over the last decade, the increased use of information and communication technology (ICT) in agriculture applications has led to the definition of the concept of precision farming or equivalently smart agriculture. In this respect, the latest progress in connectivity, automation, images analysis and artificial intelligence allow farmers to monitor all production phases and, due to the help of automatic procedures, determine better treatments for their farms. One of the main objectives of a smart agriculture system is to improve the yield of the field. From this point of view, the Internet of Things (IoT) paradigm plays a key role in precision farming applications due to the fact that the use of IoT sensors provides precise information about the health of the production. In this paper, the results of the recently concluded R&amp;D project ENOTRIA TELLUS are reported. The project aimed at the development of all hardware/software components for implementing a precision farming architecture allowing the farmers to manage and monitor the vineyards’ health status. The smart architecture combines various sub-systems (web application, local controllers, unmanned aerial vehicles, multi-spectral cameras, weather sensors etc.) and electronic devices, each of them in charge of performing specific operations: remote data analysis, video processing for vegetation analysis, wireless data exchanges and weather and monitoring data evaluation. Two pilot sites were built where the smart architecture was tested and validated in real scenarios. Experimental activities show that the designed smart agriculture architecture allowed the farmers to properly schedule the various phases of cultivation and harvesting.},
DOI = {10.3390/agronomy11112140}
}



@Article{land10121365,
AUTHOR = {Agapiou, Athos and Vionis, Athanasios and Papantoniou, Giorgos},
TITLE = {Detection of Archaeological Surface Ceramics Using Deep Learning Image-Based Methods and Very High-Resolution UAV Imageries},
JOURNAL = {Land},
VOLUME = {10},
YEAR = {2021},
NUMBER = {12},
ARTICLE-NUMBER = {1365},
URL = {https://www.mdpi.com/2073-445X/10/12/1365},
ISSN = {2073-445X},
ABSTRACT = {Mapping surface ceramics through systematic pedestrian archaeological survey is considered a consistent method to recover the cultural biography of sites within a micro-region. Archaeologists nowadays conduct surface survey equipped with navigation devices counting, documenting, and collecting surface archaeological potsherds within a set of plotted grids. Recent advancements in unmanned aerial vehicles (UAVs) and image processing analysis can be utilised to support such surface archaeological investigations. In this study, we have implemented two different artificial intelligence image processing methods over two areas of interest near the present-day village of Kophinou in Cyprus, in the Xeros River valley. We have applied a random forest classifier through the Google Earth Engine big data cloud platform and a Single Shot Detector neural network in the ArcGIS Pro environment. For the first case study, the detection was based on red&ndash;green&ndash;blue (RGB) high-resolution orthophotos. In contrast, a multispectral camera covering both the visible and the near-infrared parts of the spectrum was used in the second area of investigation. The overall results indicate that such an approach can be used in the future as part of ongoing archaeological pedestrian surveys to detect scattered potsherds in areas of archaeological interest, even if pottery shares a very high spectral similarity with the surface.},
DOI = {10.3390/land10121365}
}



@Article{drones6010005,
AUTHOR = {Munawar, Hafiz Suliman and Ullah, Fahim and Heravi, Amirhossein and Thaheem, Muhammad Jamaluddin and Maqsoom, Ahsen},
TITLE = {Inspecting Buildings Using Drones and Computer Vision: A Machine Learning Approach to Detect Cracks and Damages},
JOURNAL = {Drones},
VOLUME = {6},
YEAR = {2022},
NUMBER = {1},
ARTICLE-NUMBER = {5},
URL = {https://www.mdpi.com/2504-446X/6/1/5},
ISSN = {2504-446X},
ABSTRACT = {Manual inspection of infrastructure damages such as building cracks is difficult due to the objectivity and reliability of assessment and high demands of time and costs. This can be automated using unmanned aerial vehicles (UAVs) for aerial imagery of damages. Numerous computer vision-based approaches have been applied to address the limitations of crack detection but they have their limitations that can be overcome by using various hybrid approaches based on artificial intelligence (AI) and machine learning (ML) techniques. The convolutional neural networks (CNNs), an application of the deep learning (DL) method, display remarkable potential for automatically detecting image features such as damages and are less sensitive to image noise. A modified deep hierarchical CNN architecture has been used in this study for crack detection and damage assessment in civil infrastructures. The proposed architecture is based on 16 convolution layers and a cycle generative adversarial network (CycleGAN). For this study, the crack images were collected using UAVs and open-source images of mid to high rise buildings (five stories and above) constructed during 2000 in Sydney, Australia. Conventionally, a CNN network only utilizes the last layer of convolution. However, our proposed network is based on the utility of multiple layers. Another important component of the proposed CNN architecture is the application of guided filtering (GF) and conditional random fields (CRFs) to refine the predicted outputs to get reliable results. Benchmarking data (600 images) of Sydney-based buildings damages was used to test the proposed architecture. The proposed deep hierarchical CNN architecture produced superior performance when evaluated using five methods: GF method, Baseline (BN) method, Deep-Crack BN, Deep-Crack GF, and SegNet. Overall, the GF method outperformed all other methods as indicated by the global accuracy (0.990), class average accuracy (0.939), mean intersection of the union overall classes (IoU) (0.879), precision (0.838), recall (0.879), and F-score (0.8581) values. Overall, the proposed CNN architecture provides the advantages of reduced noise, highly integrated supervision of features, adequate learning, and aggregation of both multi-scale and multilevel features during the training procedure along with the refinement of the overall output predictions.},
DOI = {10.3390/drones6010005}
}



@Article{app12031331,
AUTHOR = {Xu, Shufang and Li, Linlin and Zhou, Ziyun and Mao, Yingchi and Huang, Jianxin},
TITLE = {A Task Allocation Strategy of the UAV Swarm Based on Multi-Discrete Wolf Pack Algorithm},
JOURNAL = {Applied Sciences},
VOLUME = {12},
YEAR = {2022},
NUMBER = {3},
ARTICLE-NUMBER = {1331},
URL = {https://www.mdpi.com/2076-3417/12/3/1331},
ISSN = {2076-3417},
ABSTRACT = {With the continuous development of artificial intelligence, swarm control and other technologies, the application of Unmanned Aerial Vehicles (UAVs) in the battlefield is more and more extensive, and the UAV swarm is increasingly playing a prominent role in the future of warfare. How tasks are assigned in the dynamic and complex battlefield environment is very important. This paper proposes a task assignment model and its objective function based on dynamic information convergence. In order to resolve this multidimensional function, the Wolf Pack Algorithm (WPA) is selected as the alternative optimization algorithm. This is because its functional optimization of high-dimensional complex problems is better than other intelligent algorithms, and the fact that it is more suitable for UAV swarm task allocation scenarios. Based on the traditional WPA algorithm, this paper proposes a Multi-discrete Wolf Pack Algorithm (MDWPA) to solve the UAV task assignment problem in a complex environment through the discretization of wandering, calling, sieging behavior, and new individual supplement. Through Orthogonal Experiment Design (OED) and analysis of variance, the results show that MDWPA performs with better accuracy, robustness, and convergence rate and can effectively solve the task assignment problem of UAVs in a complex dynamic environment.},
DOI = {10.3390/app12031331}
}



@Article{min12020268,
AUTHOR = {Sinaice, Brian Bino and Owada, Narihiro and Ikeda, Hajime and Toriya, Hisatoshi and Bagai, Zibisani and Shemang, Elisha and Adachi, Tsuyoshi and Kawamura, Youhei},
TITLE = {Spectral Angle Mapping and AI Methods Applied in Automatic Identification of Placer Deposit Magnetite Using Multispectral Camera Mounted on UAV},
JOURNAL = {Minerals},
VOLUME = {12},
YEAR = {2022},
NUMBER = {2},
ARTICLE-NUMBER = {268},
URL = {https://www.mdpi.com/2075-163X/12/2/268},
ISSN = {2075-163X},
ABSTRACT = {The use of drones in mining environments is one way in which data pertaining to the state of a site in various industries can be remotely collected. This paper proposes a combined system that employs a 6-bands multispectral image capturing camera mounted on an Unmanned Aerial Vehicle (UAV) drone, Spectral Angle Mapping (SAM), as well as Artificial Intelligence (AI). Depth possessing multispectral data were captured at different flight elevations. This was in an attempt to find the best elevation where remote identification of magnetite iron sands via the UAV drone specialized in collecting spectral information at a minimum accuracy of +/&minus; 16 nm was possible. Data were analyzed via SAM to deduce the cosine similarity thresholds at each elevation. Using these thresholds, AI algorithms specialized in classifying imagery data were trained and tested to find the best performing model at classifying magnetite iron sand. Considering the post flight logs, the spatial area coverage of 338 m2, a global classification accuracy of 99.7%, as well the per-class precision of 99.4%, the 20 m flight elevation outputs presented the best performance ratios overall. Thus, the positive outputs of this study suggest viability in a variety of mining and mineral engineering practices.},
DOI = {10.3390/min12020268}
}



@Article{s22051870,
AUTHOR = {Sefidgar, Mohammad and Landry, Rene},
TITLE = {Landing System Development Based on Inverse Homography Range Camera Fusion (IHRCF)},
JOURNAL = {Sensors},
VOLUME = {22},
YEAR = {2022},
NUMBER = {5},
ARTICLE-NUMBER = {1870},
URL = {https://www.mdpi.com/1424-8220/22/5/1870},
PubMedID = {35271018},
ISSN = {1424-8220},
ABSTRACT = {The Unmanned Aerial Vehicle (UAV) is one of the most remarkable inventions of the last 100 years. Much research has been invested in the development of this flying robot. The landing system is one of the more challenging aspects of this system&rsquo;s development. Artificial Intelligence (AI) has become the preferred technique for landing system development, including reinforcement learning. However, current research is more focused is on system development based on image processing and advanced geometry. A novel calibration based on our previous research had been used to ameliorate the accuracy of the AprilTag pose estimation. With the help of advanced geometry from camera and range sensor data, a process known as Inverse Homography Range Camera Fusion (IHRCF), a pose estimation that outperforms our previous work, is now possible. The range sensor used here is a Time of Flight (ToF) sensor, but the algorithm can be used with any range sensor. First, images are captured by the image acquisition device, a monocular camera. Next, the corners of the landing landmark are detected through AprilTag detection algorithms (ATDA). The pixel correspondence between the image and the range sensor is then calculated via the calibration data. In the succeeding phase, the planar homography between the real-world locations of sensor data and their obtained pixel coordinates is calculated. In the next phase, the pixel coordinates of the AprilTag-detected four corners are transformed by inverse planar homography from pixel coordinates to world coordinates in the camera frame. Finally, knowing the world frame corner points of the AprilTag, rigid body transformation can be used to create the pose data. A CoppeliaSim simulation environment was used to evaluate the IHRCF algorithm, and the test was implemented in real-time Software-in-the-Loop (SIL). The IHRCF algorithm outperformed the AprilTag-only detection approach significantly in both translational and rotational terms. To conclude, the conventional landmark detection algorithm can be ameliorated by incorporating sensor fusion for cameras with lower radial distortion.},
DOI = {10.3390/s22051870}
}





@Article{electronics8050576,
AUTHOR = {You, Shixun and Diao, Ming and Gao, Lipeng},
TITLE = {Completing Explorer Games with a Deep Reinforcement Learning Framework Based on Behavior Angle Navigation},
JOURNAL = {Electronics},
VOLUME = {8},
YEAR = {2019},
NUMBER = {5},
ARTICLE-NUMBER = {576},
URL = {https://www.mdpi.com/2079-9292/8/5/576},
ISSN = {2079-9292},
ABSTRACT = {In cognitive electronic warfare, when a typical combat vehicle, such as an unmanned combat air vehicle (UCAV), uses radar sensors to explore an unknown space, the target-searching fails due to an inefficient servoing/tracking system. Thus, to solve this problem, we developed an autonomous reasoning search method that can generate efficient decision-making actions and guide the UCAV as early as possible to the target area. For high-dimensional continuous action space, the UCAV&rsquo;s maneuvering strategies are subject to certain physical constraints. We first record the path histories of the UCAV as a sample set of supervised experiments and then construct a grid cell network using long short-term memory (LSTM) to generate a new displacement prediction to replace the target location estimation. Finally, we enable a variety of continuous-control-based deep reinforcement learning algorithms to output optimal/sub-optimal decision-making actions. All these tasks are performed in a three-dimensional target-searching simulator, i.e., the Explorer game. Please note that we use the behavior angle (BHA) for the first time as the main factor of the reward-shaping of the deep reinforcement learning framework and successfully make the trained UCAV achieve a 99.96% target destruction rate, i.e., the game win rate, in a 0.1 s operating cycle.},
DOI = {10.3390/electronics8050576}
}



@Article{drones6020045,
AUTHOR = {Siddiqui, Abdul Basit and Aqeel, Iraj and Alkhayyat, Ahmed and Javed, Umer and Kaleem, Zeeshan},
TITLE = {Prioritized User Association for Sum-Rate Maximization in UAV-Assisted Emergency Communication: A Reinforcement Learning Approach},
JOURNAL = {Drones},
VOLUME = {6},
YEAR = {2022},
NUMBER = {2},
ARTICLE-NUMBER = {45},
URL = {https://www.mdpi.com/2504-446X/6/2/45},
ISSN = {2504-446X},
ABSTRACT = {Unmanned air vehicles (UAVs) used as aerial base stations (ABSs) can provide communication services in areas where cellular network is not functional due to a calamity. ABSs provide high coverage and high data rates to the user because of the advantage of a high altitude. ABSs can be static or mobile; they can adjust their position according to real-time location of ground user and maintain a good line-of-sight link with ground users. In this paper, a reinforcement learning framework is proposed to maximize the number of served users by optimizing the ABS 3D location and power. We also design a reward function that prioritize the emergency users to establish a connection with the ABS using Q-learning. Simulation results reveal that the proposed scheme clearly outperforms the baseline schemes.},
DOI = {10.3390/drones6020045}
}




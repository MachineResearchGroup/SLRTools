@ARTICLE{9606501,
author={Wang, Yanxiang and Wang, Honglun and Liu, Bailing and Liu, Yiheng and Wu, Jianfa and Lu, Zhenyi},
journal={IEEE Transactions on Instrumentation and Measurement}, title={A Visual Navigation Framework for the Aerial Recovery of UAVs},
year={2021},
volume={70},
number={},
pages={1-13},
abstract={This article proposes a visual navigation framework for the aerial recovery of unmanned aerial vehicles (UAVs). The framework is employed for pose estimation between the drogue and the probe to guide the recovery UAV to safely dock with the drogue. First, a deep learning-based detector and the proposed adaptive region of interest (AROI) tracker give the region of interest (ROI) of the drogue at high speed. Second, the centroids of the markers installed on the ring of the drogue can be extracted by image processing of the ROI, which can effectively reduce the computational overhead and the noise impact from other irrelevant areas. To improve the robustness of the framework, a marker compensation method is proposed to address situations of occlusion. After all the centroid coordinates in the image are obtained, stereo vision is employed to measure the drogue pose. Then, a Kalman filter (KF) is applied to accurately estimate the drogue pose. Finally, a ground semiphysical closed-loop experiment of the docking phase of aerial recovery is developed to verify the effectiveness of the proposed framework. The experimental results show that our framework has high accuracy, strong robustness, and good real-time performance.},
keywords={Navigation;Pose estimation;Autonomous aerial vehicles;Real-time systems;Deep learning;Stereo vision;Aerial recovery;pose estimation;semiphysical closed-loop experiment;stereo vision;visual navigation},
doi={10.1109/TIM.2021.3126398},
ISSN={1557-9662},
month={},}
@INPROCEEDINGS{9341347,
author={Bartolomei, Luca and Teixeira, Lucas and Chli, Margarita},
booktitle={2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)}, title={Perception-aware Path Planning for UAVs using Semantic Segmentation},
year={2020},
volume={},
number={},
pages={5808-5815},
abstract={In this work, we present a perception-aware path-planning pipeline for Unmanned Aerial Vehicles (UAVs) for navigation in challenging environments. The objective is to reach a given destination safely and accurately by relying on monocular camera-based state estimators, such as Keyframe-based Visual-Inertial Odometry (VIO) systems. Motivated by the recent advances in semantic segmentation using deep learning, our path-planning architecture takes into consideration the semantic classes of parts of the scene that are perceptually more informative than others. This work proposes a planning strategy capable of avoiding both texture-less regions and problematic areas, such as lakes and oceans, that may cause large drift or failures in the robot's pose estimation, by using the semantic information to compute the next best action with respect to perception quality. We design a hierarchical planner, composed of an A* path-search step followed by B-Spline trajectory optimization. While the A* steers the UAV towards informative areas, the optimizer keeps the most promising landmarks in the camera's field of view. We extensively evaluate our approach in a set of photo-realistic simulations, showing a remarkable improvement with respect to the state-of-the-art in active perception.},
keywords={Uncertainty;Navigation;Semantics;Pipelines;Computer architecture;Unmanned aerial vehicles;Planning},
doi={10.1109/IROS45743.2020.9341347},
ISSN={2153-0866},
month={Oct},}
@ARTICLE{9072517,
author={Dahmane, Mohamed and Alam, Jahangir and St-Charles, Pierre-Luc and Lalonde, Marc and Heffner, Kevin and Foucher, Samuel},
journal={IEEE Transactions on Affective Computing}, title={A Multimodal Non-Intrusive Stress Monitoring from the Pleasure-Arousal Emotional Dimensions},
year={2020},
volume={},
number={},
pages={1-1},
abstract={With the increasing development of advanced unmanned aerial vehicles (UAVs), communication between operators and these intelligent systems is becoming more stressful. For the safety of UAV flights, automatic psychological stress detection is becoming a key research topic for successful missions. Stress can be reliably estimated via some biological markers which are not appropriate in many cases of human-machine-interaction setups. In this paper, we propose a non-intrusive deep learning-based stress level estimation approach. The goal is to identify the region where the operator's emotional state projects in the space defined by the latent dimensional emotions of arousal and valence since the stress region is well delimited in this space. The proposed multimodal approach uses sequential temporal CNN and LSTM with an Attention Weighted Average layer in the vision modality. As a second modality, we investigate local and global descriptors such as Mel-frequency cepstral coefficients, i-vector embeddings as well as Fisher-vector encodings. The multimodal-fusion approach uses a strategy referred to as "late-fusion" that involves the combination of unimodal model outputs as inputs of the decision engine. Since we have to deal with more naturalistic behavior in operator-machine interaction contexts, the One minute Gradual Emotion Challenge dataset was used for predictive model validation.},
keywords={Stress;Feature extraction;Unmanned aerial vehicles;Psychology;Visualization;Monitoring;Face;Operator state monitoring;emotion analysis;continuous emotions;stress monitoring;face analysis;deep learning;feature representation},
doi={10.1109/TAFFC.2020.2988455},
ISSN={1949-3045},
month={},}
@ARTICLE{9210014,
author={Cué La Rosa, Laura Elena and Oliveira, Dário A. B. and Zortea, Maciel and Holtz Gemignani, Bruno and Queiroz Feitosa, Raul},
journal={IEEE Geoscience and Remote Sensing Letters}, title={Learning Geometric Features for Improving the Automatic Detection of Citrus Plantation Rows in UAV Images},
year={2022},
volume={19},
number={},
pages={1-5},
abstract={Unmanned aerial vehicles (UAVs) allow on-demand imaging of orchards at an unprecedented level of detail. The automated detection of plantation rows in the images helps in the successive analysis steps, such as the detection of individual fruit trees and planting gaps, aiding producers with inventory and planting operations. Citrus trees can be planted in curved rows that form intricate geometric patterns in aerial images, requiring robust detection approaches. While deep learning methods rank among state-of-the-art methods for segmenting images with particular geometrical patterns, they struggle to hold their performance when testing data differs much from training data (e.g., image intensity differences, image artifacts, vegetation characteristics, and landscape conditions). In this letter, we propose a method to learn geometric features of orchards in UAV images and use them to improve the detection of plantation rows. First, we train a detection encoder–decoder network (DetED) to segment planting rows in RGB images. Then, with labeled data, we train an encoder–decoder correction network (CorrED) that learns to map binary masks with spurious row segmentation geometries into corrected ones. Finally, we use the CorrED network to fix geometric inconsistencies in DetED outcome. Our experiments with commercial plantations of orange trees show that the proposed CorrED postprocessing can restore missing segments of plantation rows and improve detection accuracy in testing data.},
keywords={Image segmentation;Geometry;Vegetation;Training;Testing;Decoding;Feature extraction;Encoder–decoder networks;geometric patterns;plantation rows detection;postprocessing},
doi={10.1109/LGRS.2020.3024641},
ISSN={1558-0571},
month={},}
@INPROCEEDINGS{9731176,
author={Chen, Wenxing and Zhang, Wenlin and Huang, Yuntong and Zheng, Baojuan and Wang, Xiaoyin and Fan, Qingkun},
booktitle={2021 International Conference on Networking, Communications and Information Technology (NetCIT)}, title={An Improved Particle Kalman Filter Optimization Algorithm is Applied to Unmanned Vehicle Field},
year={2021},
volume={},
number={},
pages={255-260},
abstract={In the era of internet information development, with the growth of artificial intelligence technology, unmanned driving technology has made rapidly progress, which has been applied to many fields. Such as UAV, robot, automobile and other industries. At present, there are many algorithms have been proposed in the filed of unmanned vehicles, multi-sensor fusion and deep learning. However, the accurate estimation of the real-time motion state of moving car has always been a problem. We combine the Extended Kalman Filter (EKF) algorithm with the particle swarm optimization algorithm to form a new tracking algorithm PSO-EKF. This algorithm makes up for the deficiency of the analysis and tracking ability of unknown models, and improves the accuracy of state variables by fitness function. It also improves the estimation level of entity motion state by our method, which realizes the precise control of unmanned vehicles and provides effective theoretical support for navigation and planning and real-time decision-making. In this paper, the specific theoretical derivation and detailed solving steps are provided, as well as the specific numerical examples are given. By comparing with the traditional KF and EKF algorithm, the conclusion of this paper is that the PSO-EKM method is more accurate in predicting the state of moving objects, which can quickly adapt to various motion state estimations. Our method is helpful to improve the function of real-time positioning of unmanned vehicles with a high accuracy. It is beneficial for unmanned driving to enter full automation faster and realize intelligent transportation early.},
keywords={Visualization;Uncertainty;Tracking;Transportation;Prediction algorithms;Real-time systems;Mathematical models;SLAM;Unmanned Driving;Extended Kalman Filter;motion state estimation;particle swarm optimization},
doi={10.1109/NetCIT54147.2021.00058},
ISSN={},
month={Dec},}
@ARTICLE{9275363,
author={Ban, Tae-Won},
journal={IEEE Transactions on Vehicular Technology}, title={An Autonomous Transmission Scheme Using Dueling DQN for D2D Communication Networks},
year={2020},
volume={69},
number={12},
pages={16348-16352},
abstract={In this paper, we investigate device-to-device (D2D) communication networks which are one of the key technologies for next-generation mobile communication networks and many other applications such as unmanned aerial vehicles (UAVs), vehicle-to-vehicle (V2V), and Internet of things (IoT). The overlay D2D communication networks that are considered in our study use dedicated radio resources separate from what cellular networks use and there exists co-channel interference in D2D networks without cross-channel interference between two networks. We propose a new transmission scheme for overlay D2D networks that uses a dueling deep reinforcement learning (DRL) architecture. The DRL is especially effective in environments where actions do not affect subsequent states as in wireless communication networks. The main contribution of this paper is that the proposed architecture is designed to utilize only information that each D2D devices can easily obtain by measuring channels. The proposed scheme thus enables D2D devices to train their own neural networks and to decide autonomously whether to transmit data without any intervention from infrastructures. The performance of the proposed scheme is analyzed in terms of average sum-rates and is compared to three baseline schemes. Simulation results show that the proposed scheme can achieve almost optimal sum-rates with low signal-to-noise (SNR) values without any intervention from infrastructure.},
keywords={Device-to-device communication;Communication networks;Receivers;Cellular networks;Wireless communication;Signal to noise ratio;Resource management;Autonomous transmission;device-to-device (D2D);dueling deep reinforcement learning (DRL);transmission scheme},
doi={10.1109/TVT.2020.3041458},
ISSN={1939-9359},
month={Dec},}
@INPROCEEDINGS{9633086,
author={Shehab, Mazen and Zaghloul, Ahmed and El-Badawy, Ayman},
booktitle={2021 18th International Conference on Electrical Engineering, Computing Science and Automatic Control (CCE)}, title={Low-Level Control of a Quadrotor using Twin Delayed Deep Deterministic Policy Gradient (TD3)},
year={2021},
volume={},
number={},
pages={1-6},
abstract={Unmanned Aerial Vehicles (UAVs) like Quadrotors are inherently under-actuated and unstable systems. The mechanical complexity and non-linearity of such systems make it a difficult task to control the flight of the mentioned systems. However, due to recent advancements in the fields of data science and machine learning, new algorithms for flight stabilization and trajectory control were developed using Deep Reinforcement Learning. This paper presents two low-level Quadrotor controllers based on the same algorithm. The first designed controller aims to stabilize the Quadrotor at a certain preset point given any random initial position. The second is to track any target position given in the 3D space. Twin Delayed Deep Deterministic Policy Gradient (TD3) is used to train the agents to achieve the required tasks. This method is an off-policy Actor-Critic based method. It was used as it does not require a system model and works on environments with continuous action and state spaces. The superb performance of the trained policies is demonstrated in a simulation to illustrate the effectiveness of the proposed controllers.},
keywords={Training;Adaptation models;Machine learning algorithms;Uncertainty;Trajectory tracking;Computational modeling;Neural networks;Quadrotor;Machine Learning;Reinforcement Learning;TD3},
doi={10.1109/CCE53527.2021.9633086},
ISSN={2642-3766},
month={Nov},}
@INPROCEEDINGS{9448959,
author={Sliwa, Benjamin and Schüler, Cedrik and Patchou, Manuel and Wietfeld, Christian},
booktitle={2021 IEEE 93rd Vehicular Technology Conference (VTC2021-Spring)}, title={PARRoT: Predictive Ad-hoc Routing Fueled by Reinforcement Learning and Trajectory Knowledge},
year={2021},
volume={},
number={},
pages={1-7},
abstract={Swarms of collaborating Unmanned Aerial Vehicles (UAVs) that utilize ad-hoc networking technologies for coordinating their actions offer the potential to catalyze emerging research fields such as autonomous exploration of disaster areas, demand-driven network provisioning, and near field packet delivery in Intelligent Transportation Systems (ITSs). As these mobile robotic networks are characterized by high grades of relative mobility, existing routing protocols often fail to adopt their decision making to the implied network topology dynamics. For addressing these challenges, we present Predictive Ad-hoc Routing fueled by Reinforcement learning and Trajectory knowledge (PARRoT) as a novel machine learning-enabled routing protocol which exploits mobility control information for integrating knowledge about the future motion of the mobile agents into the routing process. The performance of the proposed routing approach is evaluated using comprehensive network simulation. In comparison to established routing protocols, PARRoT achieves a massively higher robustness and a significantly lower end-to-end latency.},
keywords={Vehicular and wireless technologies;Robot kinematics;Decision making;Reinforcement learning;Routing;Routing protocols;Ad hoc networks},
doi={10.1109/VTC2021-Spring51267.2021.9448959},
ISSN={2577-2465},
month={April},}
@ARTICLE{8303767,
author={Martinez-Cantin, Ruben},
journal={IEEE Transactions on Cybernetics}, title={Funneled Bayesian Optimization for Design, Tuning and Control of Autonomous Systems},
year={2019},
volume={49},
number={4},
pages={1489-1500},
abstract={In this paper, we tackle several problems that appear in robotics and autonomous systems: algorithm tuning, automatic control, and intelligent design. All those problems share in common that they can be mapped to global optimization problems where evaluations are expensive. Bayesian optimization (BO) has become a fundamental global optimization algorithm in many problems where sample efficiency is of paramount importance. BO uses a probabilistic surrogate model to learn the response function and reduce the number of samples required. Gaussian processes (GPs) have become a standard surrogate model for their flexibility to represent a distribution over functions. In a black-box settings, the common assumption is that the underlying function can be modeled with a stationary GP. In this paper, we present a novel kernel function specially designed for BO, that allows nonstationary behavior of the surrogate model in an adaptive local region. This kernel is able to reconstruct nonstationarity even with the irregular sampling distribution that arises from BO. Furthermore, in our experiments, we found that this new kernel results in an improved local search (exploitation), without penalizing the global search (exploration) in many applications. We provide extensive results in well-known optimization benchmarks, machine learning hyperparameter tuning, reinforcement learning, and control problems, and UAV wing optimization. The results show that the new method is able to outperform the state of the art in BO both in stationary and nonstationary problems.},
keywords={Optimization;Kernel;Bayes methods;Adaptation models;Tuning;Biological system modeling;Gaussian processes;Bayesian optimization (BO);Gaussian processes (GPs);global optimization;reinforcement learning},
doi={10.1109/TCYB.2018.2805695},
ISSN={2168-2275},
month={April},}
@INPROCEEDINGS{9671314,
author={Safavi, Farshad and Chowdhury, Tashnim and Rahnemoonfar, Maryam},
booktitle={2021 IEEE International Conference on Big Data (Big Data)}, title={Comparative Study Between Real-Time and Non-Real-Time Segmentation Models on Flooding Events},
year={2021},
volume={},
number={},
pages={4199-4207},
abstract={Scene understanding of aerial imagery is essential for proper emergency response during catastrophic events such as hurricanes, earthquakes, and floods. Unmanned Aerial Vehicles (UAVs) capture aerial images and analyze the context by passing images into a semantic segmentation model for monitoring damaged areas. However, the state-of-the-art semantic segmentation models are mainly trained and evaluated on ground-based datasets such as Cityscapes, MS-COCO, and CamVid, unsuitable for aerial image segmentations. For example, extracted features from objects in aerial perspective are distinct from objects on the ground view. Hence, neural networks cannot properly segment an aerial scene, especially on deformed or damaged objects during disasters. This research analyzes current semantic segmentation models to explore the feasibility of applying these models for emergency response during catastrophic events. We compare the performance of real-time semantic segmentation models with non-real-time counterparts constrained by aerial images under adversarial settings. Furthermore, we train several models on the FloodNet dataset, containing UAV images captured after Hurricane Harvey, and benchmark their execution on special classes such as flooded-buildings vs. non-flooded buildings or flooded-roads vs. non-flooded roads. In this research, real-time UNet-MobileNetV3 yields 59.3% test mIoU while non-real-time PSPNet [1] attains 79.7% test mIoU on the FloodNet, demonstrating the trade-off between accuracy and efficiency in the segmentation models.},
keywords={Image segmentation;Analytical models;Semantics;Big Data;Emergency services;Autonomous aerial vehicles;Feature extraction;Computer Vision;Deep Learning;Convolutional Neural Network(CNN);Aerial Image Segmentation;Real-Time Semantic Segmentation},
doi={10.1109/BigData52589.2021.9671314},
ISSN={},
month={Dec},}
@INPROCEEDINGS{9217127,
author={Scazzoli, Davide and Magarini, Maurizio and Reggiani, Luca and Moullec, Yannick Le and Mahtab Alam, Muhammad},
booktitle={2020 IEEE 31st Annual International Symposium on Personal, Indoor and Mobile Radio Communications}, title={A Deep Learning Approach for LoS/NLoS Identification via PRACH in UAV-assisted Public Safety Networks},
year={2020},
volume={},
number={},
pages={1-6},
abstract={The high mobility of Unmanned Aerial Vehicles (UAVs) and their capability to rapidly deploy Aerial Base Stations (ABS) in areas where the terrestrial network becomes unavailable is a key enabler for Public Safety Networks. In our work we introduce a model in order to identify Line of Sight (LoS) and Non-Line of Sight (NLoS) conditions for User Equipments (UEs) that attempt a connection to an ABS through the Physical Random Access Channel (PRACH) based on Convolutional Neural Networks (CNNs). Our method limits the number of antennas employed with respect to other methods that were developed for traditional approaches, while achieving higher than 80% accuracy for SNR of -20 dB. Finally, we study the impact of UAV’s height on the accuracy of our method and we compare it with typical computationally efficient methods based on the delay spread with and without the aid of beamforming.},
keywords={Signal to noise ratio;Delays;Estimation;Channel estimation;Indexes;Support vector machines;Channel models;Public Safety Network (PSN);Localization;Convolutional Neural Networks (CNNa);Non Line of Sight (NLoS)},
doi={10.1109/PIMRC48278.2020.9217127},
ISSN={2166-9589},
month={Aug},}
@INPROCEEDINGS{9465460,
author={Bahnsen, Fin Hendrik and Kaiser, Jan and Fey, Goerschwin},
booktitle={2021 IEEE European Test Symposium (ETS)}, title={Designing Recurrent Neural Networks for Monitoring Embedded Devices},
year={2021},
volume={},
number={},
pages={1-4},
abstract={Embedded systems play an important role in various tasks in many areas of our lives. In the case of safety-critical applications, e.g., in the fields of autonomous driving, medical devices or control of unmanned aerial vehicles (UAV), the correct system operation must always be guaranteed. Standard methods for monitoring an embedded application, i.e., detecting erroneous behavior at run-time, require a detailed system understanding during development which increases the design effort significantly.Our approach uses Artificial Neural Networks (ANN), specifically recurrent Long Short-Term Memory (LSTM) architectures, to realize cost efficient monitoring for embedded systems. We propose extensions to existing ANN-based monitoring approaches and investigate suitable ANN architectures, which facilitate fault detection on the open-source UAV flight stack PX4. We demonstrate that our ANN-based approach can detect faults on a raw data stream coming from the monitored system, thus minimizing the need to engineer curated data streams in order to adapt the approach to a different device.},
keywords={Embedded systems;Recurrent neural networks;Systems operation;Artificial neural networks;Unmanned aerial vehicles;Biomedical monitoring;Task analysis;Monitoring;Artificial Neural Network;Long Short-Term Memory;Anomaly Detection;Unmanned Aerial Vehicles;PX4},
doi={10.1109/ETS50041.2021.9465460},
ISSN={1558-1780},
month={May},}
@INPROCEEDINGS{8923960,
author={da Silva, Suane Pires P. and Honório Filho, Paulo and Marinho, Leandro B. and Almeida, Jefferson S. and Nascimento, Navar Medeiros M. and Rodrigues, Antonio Wendell de O. and Filho, Pedro Pedrosa Rebouças},
booktitle={2019 8th Brazilian Conference on Intelligent Systems (BRACIS)}, title={A New Approach to Navigation of Unmanned Aerial Vehicle using Deep Transfer Learning},
year={2019},
volume={},
number={},
pages={222-227},
abstract={With the advancement of Unmanned Aerial Vehicles (UAVs) and their application in the most diverse areas, the demand for increasingly better precision in their positioning and navigation task has arisen. Based on this context, this article proposes a new approach for localization and navigation UAVs using topological maps and Convolutional Neural Networks (CNN). CNN is used as features extractor, according to the concept of Transfer Learning. The use of topological maps helps to guide the vehicle through the exploration environment. To evaluate the performance of the approach, parameters such as Accuracy, F1-Score, and processing time are considered. For the classification were used Bayesian Classifier, k-Nearest Neighbor (kNN), Multi-layer Perceptron (MLP), Optimum-Path Forest (OPF) and Support Vector Machine (SVM). The results show that CNN achieved 99.97% Accuracy and also F1-Score in combination with most of the considered classifiers, proving the effectiveness of our approach.},
keywords={Unmanned aerial vehicles;Feature extraction;Support vector machines;Satellite navigation systems;Machine learning;Databases;Unmanned Aerial Vehicles;Convolutional Neural Network;Transfer Learning;Topological Maps;UAV Navigation},
doi={10.1109/BRACIS.2019.00047},
ISSN={2643-6264},
month={Oct},}
@ARTICLE{8668525,
author={Goudos, Sotirios K. and Tsoulos, George V. and Athanasiadou, Georgia and Batistatos, Michael C. and Zarbouti, Dimitra and Psannis, Kostas E.},
journal={IEEE Transactions on Antennas and Propagation}, title={Artificial Neural Network Optimal Modeling and Optimization of UAV Measurements for Mobile Communications Using the L-SHADE Algorithm},
year={2019},
volume={67},
number={6},
pages={4022-4031},
abstract={Channel modeling of wireless communications from unmanned aerial vehicles (UAVs) is an emerging research challenge. In this paper, we propose a solution to this issue by applying a new framework for the prediction of received signal strength (RSS) in mobile communications based on artificial neural networks (ANNs). The experimental data measurements are taken with a UAV at different altitudes. We apply several evolutionary algorithms (EAs) in conjunction with the Levenberg-Marquardt (LM) backpropagation algorithm in order to train different ANNs and in particular the L-SHADE algorithm, which self-adapts control parameters and dynamically adjusts population size. Five new hybrid training methods are designed by combining LM with self-adaptive differential evolution (DE) strategies. These new training methods obtain better performance to ANN weight optimization than the original LM method. The received results are compared with the real values using representative ANN performance indices and exhibit satisfactory accuracy.},
keywords={Training;Antenna measurements;Long Term Evolution;Power measurement;Software;Area measurement;Frequency measurement;Artificial neural network (ANN);cellular communications;differential evolution (DE);optimization methods;unmanned aerial vehicle (UAV)},
doi={10.1109/TAP.2019.2905665},
ISSN={1558-2221},
month={June},}
@INPROCEEDINGS{9230274,
author={Zhao, Dongyang and Chen, Yuqing and Yu, Shuanghe},
booktitle={2020 5th International Conference on Automation, Control and Robotics Engineering (CACRE)}, title={Tracking and Speed Estimation of Ground Vehicles Using Aerial-view Videos},
year={2020},
volume={},
number={},
pages={597-601},
abstract={With the rapid technology development in autonomous navigation of Unmanned Aerial Vehicles (UAVs) and robust object detection based on deep neural networks, the field of traffic analysis through aerial video has attracted widespread attention. In this paper, we investigate the problems of ground vehicle tracking and speed estimation using aerial view videos. At the first stage, the vehicle detection is performed through the YOLOv3 network, which is the state-of-the-art object detector. Then, a tracking-by-detection method is designed to tracking the traffic vehicles. Furthermore, in order to estimate the vehicle speed in traffic while the UAV navigating in different heights, the least square algorithm is utilized to fit the measurement data and determine the power function mapping relationship between the vehicle pixel distance and the actual distance, which further improves the accuracy of speed estimation effectively.},
keywords={Vehicle detection;Videos;Estimation;Radar tracking;Tracking;Cameras;Fitting;UAV;vehicle tracking;speed estimation},
doi={10.1109/CACRE50138.2020.9230274},
ISSN={},
month={Sep.},}
@INPROCEEDINGS{8119468,
author={Tri, Nguyen Cao and Duong, Hieu N. and Van Hoai, Tran and Van Hoa, Tran and Nguyen, Vu H. and Toan, Nguyen Thanh and Snasel, Vaclav},
booktitle={2017 9th International Conference on Knowledge and Systems Engineering (KSE)}, title={A novel approach based on deep learning techniques and UAVs to yield assessment of paddy fields},
year={2017},
volume={},
number={},
pages={257-262},
abstract={Yield assessment is one of the main interests at regional and national levels of agriculture management. The accuracy of the assessment is not highly expected inherently and, moreover, some costly and sophisticated tools (e.g., satellite images) have been usually involved without a careful consideration of their investment. In this paper, a novel approach has been proposed orienting to farmers (especially in Southeastern Asia) who are only affordable for low cost and easy-to-use tools. With this vision, the paper presents an idea to co-operate certain, powerful and modern technologies-deep neural networks (DNNs) and unmanned aerial vehicles (UAVs)-with respect to solving the problem of yield assessment. The imagery of paddy fields acquired by UAVs at low altitudes is then used for training DNNs and assessing the yield of the paddy fields. Four DNN models are applied to figure out the most appropriate one for this approach. To test the applicability of the proposed approach, some experiments are conducted on a dataset which was collected at paddy fields in Tay Ninh province, Vietnam. The yield assessment is not directly predicted from DNNs, instead being achieved by a combination of the classification results and a bush-level yield estimation of agricultural experts in the fields. The paper indicates that the proposed approach is quite potential for precision agriculture, along with some remaining challenges.},
keywords={Agriculture;Machine learning;Neural networks;Convolution;Electronic mail;Image resolution;Image segmentation;Deep Learning;Paddy Field;Unmanned Aerial Vehicles;Yield Assessment},
doi={10.1109/KSE.2017.8119468},
ISSN={},
month={Oct},}
@ARTICLE{8972612,
author={Hosseini, Mohammad Mehdi and Umunnakwe, Amarachi and Parvania, Masood and Tasdizen, Tolga},
journal={IEEE Transactions on Smart Grid}, title={Intelligent Damage Classification and Estimation in Power Distribution Poles Using Unmanned Aerial Vehicles and Convolutional Neural Networks},
year={2020},
volume={11},
number={4},
pages={3325-3333},
abstract={Damage estimation is part of daily operation of power utilities, often requiring a manual process of crew deployment and damage report to quantify and locate damages. Advancement in unmanned aerial vehicles (UAVs) as well as real-time communication and learning technologies could be harnessed towards efficient and accurate automation of this process. This paper develops a model to automate the process of estimating and localizing damages in power distribution poles, which utilizes the images taken by UAVs transferred in real-time to an intelligent damage classification and estimation (IDCE) unit. The IDCE unit integrates four convolutional neural networks to learn the states of poles from images, extract the image characteristics, and train an automated intelligent tool to replace manual fault location and damage estimation. The proposed model first determines the type of pole damages, including falling and burning, and then estimates the percentage of damage in each type. The IDCE unit also localizes damages in the poles by locating possible burning or arcing parts. A data set of 1615 images is utilized to train, validate and test the proposed model, which demonstrates high accuracy of the model in classifying and estimating damages in distribution poles.},
keywords={Estimation;Inspection;Detectors;Convolutional neural networks;Power systems;Unmanned aerial vehicles;Data models;Deep neural network;damage classification and estimation;unmanned aerial vehicles;resilience},
doi={10.1109/TSG.2020.2970156},
ISSN={1949-3061},
month={July},}
@INPROCEEDINGS{9581973,
author={Roychowdhury, Saurabh and Ghosh, Debalina},
booktitle={2021 2nd International Conference on Range Technology (ICORT)}, title={Machine Learning Based Classification of Radar Signatures of Drones},
year={2021},
volume={},
number={},
pages={1-5},
abstract={With the current popularity of drones and UAVs, there is an urgent need to be able to classify the aerial objects with sufficient accuracy. Hence, several methods have been proposed for classification of drones and UAVs. Such methods are often based on visual sources and thus classification becomes dependent on extraneous parameters. In contrast, the use of Radar Cross Section (RCS) for drone classification shows less dependency of extraneous parameters. Radar Cross Section (RCS) is a significant radar signature that is popularly used for identification of targets. In this paper, the primary objective is to demonstrate a viable solution to classify drones based on their RCS values. During the process, various classification algorithms such as Support Vector Machines, Decision Tree, Naive Bayes Classifier, Neural Networks have been investigated for performance and accuracy.},
keywords={Visualization;Radar cross-sections;Gaussian noise;Neural networks;Support vector machine classification;Machine learning;Robustness;RCS- Radar Cross Section;Machine Learning;Decision Tree;K Nearest Neighbour;Linear Discriminant Analysis;Naive Bayes;Additive White Gaussian Noise (AWGN);Long short-term memory(LSTM);Recurrent Neural Network (RNN);Support Vector Machine;Ensemble Classifier},
doi={10.1109/ICORT52730.2021.9581973},
ISSN={},
month={Aug},}
@INPROCEEDINGS{9551637,
author={le Fevre Sejersen, Jonas and Pimentel De Figueiredo, Rui and Kayacan, Erdal},
booktitle={2021 IEEE 17th International Conference on Automation Science and Engineering (CASE)}, title={Safe Vessel Navigation Visually Aided by Autonomous Unmanned Aerial Vehicles in Congested Harbors and Waterways},
year={2021},
volume={},
number={},
pages={1901-1907},
abstract={In the maritime sector, safe vessel navigation is of great importance, particularly in congested harbors and waterways. The focus of this work is to estimate the distance between an object of interest and potential obstacles using a companion UAV. The proposed approach fuses global positioning system (GPS) data with long-range aerial images. First, we employ semantic segmentation deep neural networks (DNNs) for discriminating the vessel of interest, water, and potential solid objects using raw image data. The network is trained with both real and images generated and automatically labeled from a realistic AirSim simulation environment. Then, the distances between the extracted vessel and non-water obstacle blobs are computed using a novel ground sample distance (GSD) estimation algorithm. To the best of our knowledge, this work is the first attempt to detect and estimate distances to unknown objects from long-range visual data captured with conventional RGB cameras and auxiliary absolute positioning systems (e.g. GPS). The simulation results illustrate the accuracy and efficacy of the proposed method for visually aided navigation of vessels assisted by unmanned aerial vehicles (UAVs).},
keywords={Image segmentation;Visualization;Navigation;Magnetometers;Simulation;Semantics;Estimation},
doi={10.1109/CASE49439.2021.9551637},
ISSN={2161-8089},
month={Aug},}
@INPROCEEDINGS{9721999,
author={Lin, Guohuai and Cheng, Zhijian and Ren, Hongru and Li, Hongyi and Lu, Renquan},
booktitle={2021 8th International Conference on Information, Cybernetics, and Computational Social Systems (ICCSS)}, title={Command-Filter-Based Finite-Time Control for Human-in-the-Loop UAVs With Dead-Zone Inputs},
year={2021},
volume={},
number={},
pages={338-343},
abstract={This paper studies the adaptive neural finite-time attitude control problem for six-rotor unmanned aerial vehicles (UAVs) with dead-zone inputs. Under the assumption that control inputs of leader are provided by a human operator, the command-filter-based finite-time attitude control protocol is proposed to achieve leader-follower consensus in finite time. In the control design, the command filter technique and radial basis function neural networks (RBF NNs) are adopted to solve the problems of explosion of complexity and uncertain nonlinear dynamics, respectively. In addition, dead-zone nonlinearities of control inputs are compensated by the boundedness of dead-zone slopes. Based on the presented control scheme, the finite-time stability of UAVs is obtained via the Lyapunov stability theory. Finally, simulation results validate the control property of the proposed strategy.},
keywords={Protocols;Attitude control;Simulation;Radial basis function networks;Filtering theory;Explosions;Stability analysis;command filter technique;dead-zone inputs;finite-time control;human-in-the-loop;unmanned aerial vehicles (UAVs)},
doi={10.1109/ICCSS53909.2021.9721999},
ISSN={2639-4235},
month={Dec},}
@INPROCEEDINGS{8519012,
author={Kellenberger, Benjamin and Marcos, Diego and Courty, Nicolas and Tuia, Devis},
booktitle={IGARSS 2018 - 2018 IEEE International Geoscience and Remote Sensing Symposium}, title={Detecting Animals in Repeated UAV Image Acquisitions by Matching CNN Activations with Optimal Transport},
year={2018},
volume={},
number={},
pages={3643-3646},
abstract={Repeated animal censuses are crucial for wildlife parks to ensure ecological equilibriums. They are increasingly conducted using images generated by Unmanned Aerial Vehicles (UAVs), often coupled to semi-automatic object detection methods. Such methods have shown great progress also thanks to the employment of Convolutional Neural Networks (CNNs), but even the best models trained on the data acquired in one year struggle predicting animal abundances in subsequent campaigns due to the inherent shift between the datasets. In this paper we adapt a CNN-based animal detector to a follow-up UAV dataset by employing an unsupervised domain adaptation method based on Optimal Transport. We show how to infer updated labels from the source dataset by means of an ensemble of bootstraps. Our method increases the precision compared to the unmodified CNN, while not requiring additional labels from the target set.},
keywords={Feature extraction;Detectors;Unmanned aerial vehicles;Couplings;Wildlife;Livestock estimation;Unmanned Aerial Vehicle (UAV);Domain Adaptation;Optimal Transport;Convolutional Neural Network (CNN)},
doi={10.1109/IGARSS.2018.8519012},
ISSN={2153-7003},
month={July},}
@INPROCEEDINGS{8265457,
author={Tijtgat, Nils and Van Ranst, Wiebe and Volckaert, Bruno and Goedemé, Toon and De Turck, Filip},
booktitle={2017 IEEE International Conference on Computer Vision Workshops (ICCVW)}, title={Embedded Real-Time Object Detection for a UAV Warning System},
year={2017},
volume={},
number={},
pages={2110-2118},
abstract={In this paper, we demonstrate and evaluate a method to perform real-time object detection on-board a UAV using the state of the art YOLOv2 object detection algorithm running on an NVIDIA Jetson TX2, an GPU platform targeted at power constrained mobile applications that use neural networks under the hood. This, as a result of comparing several cutting edge object detection algorithms. Multiple evaluations we present provide insights that help choose the optimal object detection configuration given certain frame rate and detection accuracy requirements. We propose how this setup running on-board a UAV can be used to process a video feed during emergencies in real-time, and feed a decision support warning system using the generated detections.},
keywords={Object detection;Graphics processing units;Real-time systems;Unmanned aerial vehicles;Detectors;Decision trees},
doi={10.1109/ICCVW.2017.247},
ISSN={2473-9944},
month={Oct},}
@INPROCEEDINGS{9444035,
author={Liu, Yanjuan and Kong, Yingying and Zhang, Bowen and Peng, Xiangyang and Leung, Henry},
booktitle={2020 4th International Conference on Imaging, Signal Processing and Communications (ICISPC)}, title={A Novel Deep Transfer Learning Method for Airborne Remote Sensing Semantic Segmentation Based on Fully Convolutional Network},
year={2020},
volume={},
number={},
pages={13-19},
abstract={Semantic segmentation for airborne remote sensing images is a critical process in the workflow of object-based image analysis. The success of deep neural networks for semantic segmentation heavily rely on large-scale and well-labeled datasets, which are hard to collect in practice. In this paper, we consider transfer learning for semantic segmentation that can address the cross-domain learning problem by extracting useful information from data of related domain and transferring them to target domain. Considering the high similarity between Unmanned Aerial Vehicles (UAV) images and airborne remote sensing images, we propose a deep novel transfer learning method, which transfers a semantically segment model used UAV images to airborne remote sensing images. The experimental results show that the method proposed achieves higher Global Accuracy (GA) with less running time compared other transfer algorithm.},
keywords={Image segmentation;Convolution;Atmospheric modeling;Transfer learning;Semantics;Neural networks;Signal processing algorithms;semantic segmentation;airborne remote sensing images;transfer learning;UAV images},
doi={10.1109/ICISPC51671.2020.00010},
ISSN={},
month={Oct},}
@INPROCEEDINGS{9110234,
author={Montalbano, Nicholas G. and Humphreys, Todd E.},
booktitle={2020 IEEE/ION Position, Location and Navigation Symposium (PLANS)}, title={Intercepting Unmanned Aerial Vehicle Swarms with Neural- Network-Aided Game-Theoretic Target Assignment},
year={2020},
volume={},
number={},
pages={36-43},
abstract={This paper examines the use of neural networks to perform low-level control calculations within a larger game-theoretic framework for drone swarm interception. As unmanned aerial vehicles (UAVs) become more capable and less expensive, their malicious use becomes a greater public threat. This paper examines the problem of intercepting rogue UAV swarms by exploiting the underlying game-theoretic nature of large-scale pursuit-evasion games to develop locally optimal profiles for target assignment. It paper also examines computationally efficient means to streamline this process.},
keywords={pursuit-evasion game;neural network;UAV swarm control},
doi={10.1109/PLANS46316.2020.9110234},
ISSN={2153-3598},
month={April},}
@INPROCEEDINGS{8659470,
author={Funahashi, Isana and Umeki, Yo and Yoshida, Taichi and Iwahashi, Masahiro},
booktitle={2018 Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA ASC)}, title={Safety-level Estimation of Aerial Images based on Convolutional Neural Network for Emergency Landing of Unmanned Aerial Vehicle},
year={2018},
volume={},
number={},
pages={886-890},
abstract={We propose an estimation method for the safety-level of local regions in aerial images for the emergency landing of Unmanned Aerial Vehicles (UAVs) based on Convolutional Neural Networks (CNNs), and introduce a new definition of safe areas and a new dataset. The estimation methods calculate scores of the safety-level for each region, and based on the results, the landing system detects safe areas where UAVs land without injuring humans, animals, buildings, artifacts, and themselves. Previous methods generally define natural flat regions, such as grass, lawn, soil and sand areas, as safe. However, if the flat regions are small and adjoin undesirable objects, the definition is dangerous and has the possibility of the injuring. Therefore, we introduce new definition to avoid the above complicated regions, and produce the dataset. Based on the dataset, we propose a CNN model to estimate scores of the safety-level. The proposed model can use various local and global features, and consider the environment of a target region. Hence, the proposed method estimates safe regions without the complicated ones, and then has better scores in the precision than the state-of-the-art method in experiments.},
keywords={Estimation;Feature extraction;Training;Unmanned aerial vehicles;Safety;Buildings;Soil},
doi={10.23919/APSIPA.2018.8659470},
ISSN={2640-0103},
month={Nov},}
@ARTICLE{8288824,
author={Bazi, Yakoub and Melgani, Farid},
journal={IEEE Transactions on Geoscience and Remote Sensing}, title={Convolutional SVM Networks for Object Detection in UAV Imagery},
year={2018},
volume={56},
number={6},
pages={3107-3118},
abstract={Nowadays, unmanned aerial vehicles (UAVs) are viewed as effective acquisition platforms for several civilian applications. They can acquire images with an extremely high level of spatial detail compared to standard remote sensing platforms. However, these images are highly affected by illumination, rotation, and scale changes, which further increases the complexity of analysis compared to those obtained using standard remote sensing platforms. In this paper, we introduce a novel convolutional support vector machine (CSVM) network for the analysis of this type of imagery. Basically, the CSVM network is based on several alternating convolutional and reduction layers ended by a linear SVM classification layer. The convolutional layers in CSVM rely on a set of linear SVMs as filter banks for feature map generation. During the learning phase, the weights of the SVM filters are computed through a forward supervised learning strategy unlike the backpropagation algorithm widely used in standard convolutional neural networks (CNNs). This makes the proposed CSVM particularly suitable for detecting problems characterized by very limited training sample availability. The experiments carried out on two UAV data sets related to vehicles and solar-panel detection issues, with a 2-cm resolution, confirm the promising capability of the proposed CSVM network compared to recent state-of-the-art solutions based on pretrained CNNs.},
keywords={Support vector machines;Training;Feature extraction;Standards;Object detection;Remote sensing;Spatial resolution;Convolutional support vector machine (CSVM) filtering;CSVM network;extremely high-spatial-resolution images;object detection;supervised feature generation;unmanned aerial vehicle (UAV) platforms},
doi={10.1109/TGRS.2018.2790926},
ISSN={1558-0644},
month={June},}
@INPROCEEDINGS{6842300,
author={Lokman, Gurcan and Yilmaz, Guray},
booktitle={2014 International Conference on Unmanned Aircraft Systems (ICUAS)}, title={A new method for anomaly detection and target recognition},
year={2014},
volume={},
number={},
pages={577-583},
abstract={Use of unmanned Aerial Vehicles (UAVs) has gained significant importance in the recent years because they are capable of to be used in in civilian and military purposes for reconnaissance, surveillance, disaster relief, among other tasks. In this paper we present new automated anomaly detection and target recognition methodology that can be used on such a UAV. The standard paradigm for anomaly detection and target recognition in hyperspectral imagery (HSI) is to run a detection or recognition algorithm, typically statistical in nature, and visually inspect each high-scoring pixel to decide whether it is an anomaly or background data. A new method of anomaly detection and target recognition in HSI was studied based on a Neural Network (NN). Two multi-layered neural networks are used for anomaly detection and target recognition. The first phase of the model is used to detect anomalies in HSI. The second phase of the model is to use determine whether the anomaly is a predefined target or not. Both networks are trained in accordance with its intended purpose, so increase in performance is provided. This method can be a suitable solution for applications where the unmanned aerial vehicles used.},
keywords={Unmanned aerial vehicles},
doi={10.1109/ICUAS.2014.6842300},
ISSN={},
month={May},}
@INPROCEEDINGS{8981629,
author={Souza, Victor and Tavares, Alan and Quiroz, Cesar and Kurka, Paulo},
booktitle={2019 19th International Conference on Advanced Robotics (ICAR)}, title={Monocular vision navigation for aerial surveillance of power lines based on Deep Neural Networks and Hough transform},
year={2019},
volume={},
number={},
pages={414-419},
abstract={Surveillance of overhead power line installations can be conveniently addressed using unmanned aerial vehicles (UAV). UAV are robotic platforms able to perform sophisticated tasks such as autonomous flight based on visual information. In this paper, we propose a novel solution to the problem of following a power line autonomously based on monocular vision. The method uses Deep Neural Networks (DNN) and the Hough transform to successfully discern power line images from environmental information, which is an essential result to accomplish fully autonomous vision-based navigation. A simulated navigation test demonstrates the efficiency of the proposed method, in the special condition of following right-angled changes of direction, which is a known restriction in many navigation methods reported in literature. The design of the proposed method is modular and can be incorporated in navigation strategies for automatic surveillance applications.},
keywords={},
doi={10.1109/ICAR46387.2019.8981629},
ISSN={},
month={Dec},}
@INPROCEEDINGS{6564667,
author={Cook, Kevin and Bryan, Everett and Yu, Huili and Bai, He and Seppi, Kevin and Beard, Randal},
booktitle={2013 International Conference on Unmanned Aircraft Systems (ICUAS)}, title={Intelligent cooperative control for urban tracking with Unmanned Air Vehicles},
year={2013},
volume={},
number={},
pages={1-7},
abstract={We introduce an intelligent cooperative control system for ground target tracking in a cluttered urban environment with a team of Unmanned Air Vehicles (UAVs). We extend the work of Yu et. al. [1] to add a machine learning component that uses observations of target position to learn a model of target motion. Our learner is the Sequence Memoizer [2], a Bayesian model for discrete sequence data, which we use to predict future target location identifiers, given a context of previous location identifiers. Simulated cooperative control of a team of 3 UAVs in a 100-block city filled with various sizes of buildings verifies that learning a model of target motion can improve target tracking performance.},
keywords={Vehicles;Kinematics;Cities and towns;Target tracking;Artificial intelligence;Control systems;Buildings},
doi={10.1109/ICUAS.2013.6564667},
ISSN={},
month={May},}
@INPROCEEDINGS{9720738,
author={Gasimova, Aydan and Khoei, Tala Talaei and Kaabouch, Naima},
booktitle={2022 IEEE 12th Annual Computing and Communication Workshop and Conference (CCWC)}, title={A Comparative Analysis of the Ensemble Models for Detecting GPS Spoofing attacks on UAVs},
year={2022},
volume={},
number={},
pages={0310-0315},
abstract={Unmanned Aerial Vehicles have been widely used in military and civilian areas. The positioning and return-to-home tasks of UAVs deliberately depend on Global Positioning Systems (GPS). However, the civilian GPS signals are not encrypted, which can motivate numerous cyber-attacks on UAVs, including Global Positioning System spoofing attacks. In these spoofing attacks, a malicious user transmits counterfeit GPS signals. Numerous studies have proposed techniques to detect these attacks. However, these techniques have some limitations, including low probability of detection, high probability of misdetection, and high probability of false alarm. In this paper, we investigate and compare the performances of three ensemble-based machine learning techniques, namely bagging, stacking, and boosting, in detecting GPS attacks. The evaluation metrics are the accuracy, probability of detection, probability of misdetection, probability of false alarm, memory size, processing time, and prediction time per sample. The results show that the stacking model has the best performance compared to the two other ensemble models in terms of all the considered evaluation metrics.},
keywords={Measurement;Computational modeling;Conferences;Simulation;Stacking;Boosting;Task analysis;Unmanned Aerial Vehicles;GPS spoofing attacks;spoofing detection;machine learning;ensemble models;cyber-attacks;classification;cybersecurity},
doi={10.1109/CCWC54503.2022.9720738},
ISSN={},
month={Jan},}
@INPROCEEDINGS{9685988,
author={Ng, Wei Chong and Lim, Wei Yang Bryan and Ng, Jer Shyuan and Sawadsitang, Suttinee and Xiong, Zehui and Niyato, Dusit},
booktitle={2021 IEEE Global Communications Conference (GLOBECOM)}, title={Optimal Stochastic Coded Computation Offloading in Unmanned Aerial Vehicles Network},
year={2021},
volume={},
number={},
pages={1-6},
abstract={Today, modern unmanned aerial vehicles (UAVs) are equipped with increasingly advanced capabilities that can run applications enabled by machine learning techniques, which require computationally intensive operations such as matrix multiplications. Due to computation constraints, the UAVscan offload their computation tasks to edge servers. To mitigate stragglers, coded distributed computing (CDC) based offloading can be adopted. In this paper, we propose an Optimal Task Allocation Scheme (OTAS) based on Stochastic Integer Programming with the objective to minimize energy consumption during computation offloading. The simulation results show that amid uncertainty of task completion, the energy consumption in the UAV network is minimized.},
keywords={Integer programming;Energy consumption;Uncertainty;Simulation;Machine learning;Programming;Autonomous aerial vehicles;Unmanned Aerial Vehicles;Coded Distributed Computing;Stochastic Integer Programming;Task Allocation},
doi={10.1109/GLOBECOM46510.2021.9685988},
ISSN={},
month={Dec},}
@ARTICLE{8961915,
author={Hong, Tao and Zhao, Weiting and Liu, Rongke and Kadoch, Michel},
journal={IEEE Wireless Communications}, title={Space-Air-Ground IoT Network and Related Key Technologies},
year={2020},
volume={27},
number={2},
pages={96-104},
abstract={The integration of multidimensional networks such as space, air and ground is the future trend of the IoT. In this article, we introduce the SAG IoT network paradigm, including its composition and network architecture. Network slicing, the core 5G technology, will be applied to the SAG IoT network. The wide use of mmWave and UAVs is to produce many new scenarios, and it is necessary to study the effects of UAVs on mmWave channels in these new scenarios. In addition, mmWave imaging technology can provide a basis for this research. Machine learning is an important new technology that can be widely used in the SAG IoT. Simulation and measurement are both important means of evaluating the performance of communication systems. To cope with the emerging new applications and technologies, a cloud-based modular simulation system is introduced for 5G and future IoTs; this system is characterized by high efficiency, flexible configuration and high precision.},
keywords={Internet of Things;5G mobile communication;Satellites;Solid modeling;Three-dimensional displays;Network slicing},
doi={10.1109/MWC.001.1900186},
ISSN={1558-0687},
month={April},}
@ARTICLE{9456965,
author={Shafique, Arslan and Mehmood, Abid and Elhadef, Mourad},
journal={IEEE Access}, title={Detecting Signal Spoofing Attack in UAVs Using Machine Learning Models},
year={2021},
volume={9},
number={},
pages={93803-93815},
abstract={Due to the tremendous advancement in interactive multimedia systems and technologies, security has become a major aspect. Advanced technology can be utilized for hacking autonomous systems like Unmanned Aerial vehicles (UAVs) in different ways such as spoofing and jamming. It can be spoofed by the injection of fake signals into the sensors. For the protection of the UAVs from the Global Positioning System (GPS) signal spoofing attack, we propose a new methodology by incorporating a machine learning (ML) algorithm such as Support Vector Machine (SVM). A detailed analysis of several learning algorithms is also carried out to choose the suitable learning algorithm for the proposed work. Once the suitable ML algorithm is selected, we perform K-fold analyses to develop other learning models by choosing different values of K-folds thus we called them K-learning models. The purpose of developing K-learning models is to apply voting techniques to the developed K-learning models. Moreover, the signal features used in the proposed work are jitter, jitter (absolute), jitter (local), jitter (RAP), jitter (ppq5), shimmer, shimmer (local), shimmer (dB), shimmer (apq3), shimmer (apq5) and frequency modulation. Based on these features of the signal, we train our proposed model for the detection of counterfeit GPS signals. To gauge the performance of the proposed model, we perform different experimentation analyses such as accuracy, precision, recall, and F1-score. The results and analysis show the effectiveness of the proposed work over existing techniques.},
keywords={Global Positioning System;Support vector machines;Receivers;Jamming;Trajectory;Machine learning algorithms;Jitter;UAV;SVM;spoofing attack;signal characteristics;GPS signal},
doi={10.1109/ACCESS.2021.3089847},
ISSN={2169-3536},
month={},}
@INPROCEEDINGS{7502586,
author={Carrio, Adrian and Sampedro, Carlos and Fu, Changhong and Collumeau, Jean-François and Campoy, Pascual},
booktitle={2016 International Conference on Unmanned Aircraft Systems (ICUAS)}, title={A real-time supervised learning approach for sky segmentation onboard unmanned aerial vehicles},
year={2016},
volume={},
number={},
pages={8-14},
abstract={Vision-based sky segmentation and horizon line detection can be extremely useful to perform important tasks onboard Unmanned Aerial Vehicles (UAVs), such as pose estimation and collision avoidance. Most of the existing vision-based solutions use traditional image processing methods to identify the horizon line. This results in good overall accuracy and fast computation times. However, difficult environmental conditions such as a foggy or cloudy skies hinder correct sky segmentation. This paper proposes a solution for sky segmentation in RGB images using a supervised Machine Learning approach by first splitting the image into fixed-size patches, extracting and classifying color descriptors for each patch and performing a final post-processing stage to improve segmentation quality. A method for automatic horizon line detection is also proposed. The performance of our approach was evaluated on flight images captured onboard UAVs, achieving performance accuracies above 93% at real-time frame rates.},
keywords={Image color analysis;Image segmentation;Aircraft;Image edge detection;Histograms;Real-time systems;Unmanned aerial vehicles},
doi={10.1109/ICUAS.2016.7502586},
ISSN={},
month={June},}
@ARTICLE{9551794,
author={Feng, Chaosheng and Liu, Bin and Yu, Keping and Goudos, Sotirios K. and Wan, Shaohua},
journal={IEEE Transactions on Industrial Informatics}, title={Blockchain-Empowered Decentralized Horizontal Federated Learning for 5G-Enabled UAVs},
year={2022},
volume={18},
number={5},
pages={3582-3592},
abstract={Motivated by Industry 4.0, 5G-enabled unmanned aerial vehicles (UAVs; also known as drones) are widely applied in various industries. However, the open nature of 5G networks threatens the safe sharing of data. In particular, privacy leakage can lead to serious losses for users. As a new machine learning paradigm, federated learning (FL) avoids privacy leakage by allowing data models to be shared instead of raw data. Unfortunately, the traditional FL framework is strongly dependent on a centralized aggregation server, which will cause the system to crash if the server is compromised. Unauthorized participants may launch poisoning attacks, thereby reducing the usability of models. In addition, communication barriers hinder collaboration among a large number of cross-domain devices for learning. To address the abovementioned issues, a blockchain-empowered decentralized horizontal FL framework is proposed. The authentication of cross-domain UAVs is accomplished through multisignature smart contracts. Global model updates are computed by using these smart contracts instead of a centralized server. Extensive experimental results show that the proposed scheme achieves high efficiency of cross-domain authentication and good accuracy.},
keywords={Blockchains;Authentication;Industrial Internet of Things;Training;Data models;Drones;Informatics;5G-enabled unmanned aerial vehicles (UAVs);cross-domain authentication;federated learning (FL);privacy preservation;smart contract},
doi={10.1109/TII.2021.3116132},
ISSN={1941-0050},
month={May},}
@INPROCEEDINGS{9414985,
author={Xu, Chengtao and He, Fengyu and Chen, Bowen and Jiang, Yushan and Song, Houbing},
booktitle={ICASSP 2021 - 2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, title={Adaptive RF Fingerprint Decomposition in Micro UAV Detection based on Machine Learning},
year={2021},
volume={},
number={},
pages={7968-7972},
abstract={Radio frequency (RF) signal classification has significantly been used for detecting and identifying the features of unknown unmanned aerial vehicles (UAVs). This paper proposes a method using empirical mode decomposition (EMD) and ensemble empirical mode decomposition (EEMD) on extracting the communication channel characteristics of intruding UAVs. The decomposed intrinsic mode functions (IMFs) except noise components are selected for RF signal pattern recognition based on machine learning (ML). The classification results show that the denoising effects introduced by EMD and EEMD could both fit in improving the detection accuracy with different features of RF communication channel, especially on identifying time-varying RF signal sources.},
keywords={Radio frequency;Empirical mode decomposition;RF signals;Machine learning;Communication channels;Fingerprint recognition;Feature extraction;Micro UAS Detection;EMD;EEMD;RF Fingerprint;Machine Learning;time-varying RF signal},
doi={10.1109/ICASSP39728.2021.9414985},
ISSN={2379-190X},
month={June},}
@INPROCEEDINGS{7502626,
author={Nakamura, Takuma and Johnson, Eric N.},
booktitle={2016 International Conference on Unmanned Aircraft Systems (ICUAS)}, title={Vision-based multiple model adaptive estimation of ground targets from airborne images},
year={2016},
volume={},
number={},
pages={598-607},
abstract={This paper describes a vision-based multiple model adaptive estimation using UAVs that enables the tracking of a mobile target that changes the system model depending on unknown factors. In our system the machine-learning-based target identification method uses Haar-like classifiers that detects the target position. The system uses multiple extended Kalman filters for each system model and estimates the states of the target through the observed positions. We estimate the probability that each system is true and use the max-probability method to determine the current model. The position controller of the UAVs uses the vision system not only to determine a desired waypoint but also to switch the control law for another model. Implementation of this system is validated through an image-in-the-loop simulation. We also explore an vision-based solution for Mission 7 of the international aerial robotics competition.},
keywords={Cameras;Target tracking;TV;Vehicles;Feature extraction;Wheels;Adaptation models},
doi={10.1109/ICUAS.2016.7502626},
ISSN={},
month={June},}
@INPROCEEDINGS{8651718,
author={Wang, Jing-Ling and Li, Yun-Ruei and Adege, Abebe Belay and Wang, Li-Chun and Jeng, Shiann-Shiun and Chen, Jen-Yeu},
booktitle={2019 16th IEEE Annual Consumer Communications Networking Conference (CCNC)}, title={Machine Learning Based Rapid 3D Channel Modeling for UAV Communication Networks},
year={2019},
volume={},
number={},
pages={1-5},
abstract={This paper applies Machine Learning (ML) to predict the quality of Air-to-Ground (A2G) links performance for Unmanned Aerial Vehicles Base Stations (UAV-BSs) services. UAV-BSs can instantly identify the status of the current 3D wireless channel in an unknown environment without relying on previous statistical channel modeling. The proposed method that employs the unsupervised learning clustering technology applying to A2G channel modeling in 3D wireless communication scenarios. As environment changing, the proposed method can derive the 3D temporary channel model based on collected RSS data and analyzing. To evaluate the proposed method, the simulation data and measurement data are used to co-verify the performance. As the results shown, the RMSE of conventional statistical channel model and proposed temporary channel model are very similar. The similarity achieves about 91.8% both of the simulation and experimental environments to verify the accuracy and feasibility of our proposed method, and that provides more fast and effective of 3D channel modeling approach.},
keywords={Channel models;Three-dimensional displays;Wireless communication;Solid modeling;Atmospheric modeling;Data models;Current measurement},
doi={10.1109/CCNC.2019.8651718},
ISSN={2331-9860},
month={Jan},}
@ARTICLE{9020299,
author={Chen, Huichao and Wang, Zheng and Zhang, Linyuan},
journal={China Communications}, title={Collaborative spectrum sensing for illegal drone detection: A deep learning-based image classification perspective},
year={2020},
volume={17},
number={2},
pages={81-92},
abstract={Drones, also known as mini-unmanned aerial vehicles (UAVs), are enjoying great popularity in recent years due to their advantages of low cost, easy to pilot and small size, which also makes them hard to detect. They can provide real time situational awareness information by live videos or high definition pictures and pose serious threats to public security. In this article, we combine collaborative spectrum sensing with deep learning to effectively detect potential illegal drones with states of high uncertainty. First, we formulate the detection of potential illegal drones under illegitimate access and rogue power emission as a quaternary hypothesis test problem. Then, we propose an algorithm of image classification based on convolutional neural network which converts the cooperative spectrum sensing data at a sensing slot into one image. Furthermore, to exploit more information and improve the detection performance, we develop a trajectory classification algorithm which converts the flight process of the drones in consecutive multiple sensing slots into trajectory images. In addition, simulations are provided to verify the proposed methods' performance under various parameter configurations.},
keywords={Drones;Sensors;Convolutional neural networks;Wireless sensor networks;Radar cross-sections;Machine learning;Classification algorithms;illegal drones detection;deep learning;collaborative spectrum sensing},
doi={10.23919/JCC.2020.02.007},
ISSN={1673-5447},
month={Feb},}
@ARTICLE{8715489,
author={Palossi, Daniele and Loquercio, Antonio and Conti, Francesco and Flamand, Eric and Scaramuzza, Davide and Benini, Luca},
journal={IEEE Internet of Things Journal}, title={A 64-mW DNN-Based Visual Navigation Engine for Autonomous Nano-Drones},
year={2019},
volume={6},
number={5},
pages={8357-8371},
abstract={Fully miniaturized robots (e.g., drones), with artificial intelligence (AI)-based visual navigation capabilities, are extremely challenging drivers of Internet-of-Things edge intelligence capabilities. Visual navigation based on AI approaches, such as deep neural networks (DNNs) are becoming pervasive for standard-size drones, but are considered out of reach for nano-drones with a size of a few cm2. In this paper, we present the first (to the best of our knowledge) demonstration of a navigation engine for autonomous nano-drones capable of closed-loop end-to-end DNN-based visual navigation. To achieve this goal we developed a complete methodology for parallel execution of complex DNNs directly on board resource-constrained milliwatt-scale nodes. Our system is based on GAP8, a novel parallel ultralow-power computing platform, and a 27-g commercial, open-source Crazyflie 2.0 nano-quadrotor. As part of our general methodology, we discuss the software mapping techniques that enable the DroNet state-of-the-art deep convolutional neural network to be fully executed aboard within a strict 6 frame-per-second real-time constraint with no compromise in terms of flight results, while all processing is done with only 64 mW on average. Our navigation engine is flexible and can be used to span a wide performance range: at its peak performance corner, it achieves 18 frames/s while still consuming on average just 3.5% of the power envelope of the deployed nano-aircraft. To share our key findings with the embedded and robotics communities and foster further developments in autonomous nano-unmanned aerial vehicles (UAVs), we publicly release all our code, datasets, and trained networks.},
keywords={Navigation;Internet of Things;Visualization;Engines;Drones;Robot sensing systems;Autonomous UAV;CNNs;end-to-end learning;nano-UAV;ultralow-power},
doi={10.1109/JIOT.2019.2917066},
ISSN={2327-4662},
month={Oct},}
@INPROCEEDINGS{8123592,
author={Hsu, Chihwei and Chen, Feng and Wang, Guijin},
booktitle={2017 International Conference on Vision, Image and Signal Processing (ICVISP)}, title={High-Resolution Image Inpainting through Multiple Deep Networks},
year={2017},
volume={},
number={},
pages={76-81},
abstract={For the operation and aerial photography of the UAV, it is important to identify the blindspots and observe the details on the ground. But limited by the camera resolution, small or fuzzy objects can not be effectively observed. Therefore, repairment of high-definition images has become one of the important problems to be solved. In recent years, the development of the deep learning method has effectively solved the loss and blurring of images, but because of the difficulties in training and the speed of calculation it can only be used with low-pixel images. Therefore, we propose a method for superimposing images first with the content and textual recovery for the defaced area. We use unsupervised learning GANs and trained VGG network to restore holes and missing areas of the image, and then enlarge it through CNN method. Our preliminary results show that high resolution image restoration speed has been greatly improved, and details become sharper than using traditional method.},
keywords={Signal processing;Image Inpainting;Deep Learning;Super Resolution},
doi={10.1109/ICVISP.2017.27},
ISSN={},
month={Sep.},}
@INPROCEEDINGS{9538305,
author={Niu, L. and Wang, S. and Lü, F.},
booktitle={The 16th IET International Conference on AC and DC Power Transmission (ACDC 2020)}, title={Recognition of main electrical equipment images based on YOLOv3},
year={2020},
volume={2020},
number={},
pages={1350-1353},
abstract={With the advantages of high sensitivity, non-contact and intuitive characterization in discharge detection, the solar-blind UV imaging detection method has been used in the UAV and robotic inspections. Based on the characteristics of dual-channel imaging of UV imager, this paper proposes a visible channel image insulator recognition method based on YOLOv3.The hardware and software platform of deep learning based on the TensorFlow and Darknet framework in the Linux environment was built. The labeled database of the main electrical equipment was established and then the training of the convolution neural network was complete. The influence of the number of training samples and the layers of the network on the recognition accuracy was studied. The optimization method of the network parameters and the super parameter was given. With the network optimized, the recognition accuracy on the test set increasing by 3% reached 95%. This paper may provide guidance for engineering applications.},
keywords={},
doi={10.1049/icp.2020.0049},
ISSN={},
month={July},}
@INPROCEEDINGS{8986281,
author={Tsuyama, Masahiko and Oki, Takuro and Kobayashi, Shingo and Aoki, Risako and Miyamoto, Ryusuke and Yomo, Hiroyuki and Hara, Shinsuke},
booktitle={2019 International Symposium on Intelligent Signal Processing and Communication Systems (ISPACS)}, title={Embedded Implementation of Human Detection Using Only Color Features on the NVIDIA Xavier},
year={2019},
volume={},
number={},
pages={1-2},
abstract={The authors are developing a novel vital sensing system for real-time exercises using image-assisted routing (IAR), which requires the accurate detection of humans wearing sensor nodes in aerial images captured by a camera mounted on an UAV for sensor localization. To achieve real-time human detection for IAR, this paper proposes the embedded implementation of an accurate human detection scheme, which is constructed with informed filters using only color features and can achieve higher accuracy than deep learning for sports scenes. The experimental results for the actual aerial images of a sports scene revealed that our implementation on the NVIDIA Jetson Xavier board could process a 3840×2160 imaae in annroximatelv 44.93 ms.},
keywords={Human detection;edge computing;informed-filters;NVIDIA Jetson Xavier},
doi={10.1109/ISPACS48206.2019.8986281},
ISSN={2642-3529},
month={Dec},}
@INPROCEEDINGS{8591267,
author={Ayhan, Bulent and Kwan, Chiman},
booktitle={IECON 2018 - 44th Annual Conference of the IEEE Industrial Electronics Society}, title={A Comparative Study of Two Approaches for UAV Emergency Landing Site Surface Type Estimation},
year={2018},
volume={},
number={},
pages={5589-5593},
abstract={An automatic landing site selection algorithm generates potential landing sites for unmanned air vehicles (UAVs) with engine failures. One important step in the landing site selection algorithm is surface type estimation. In this paper, we focus on distinguishing the following three surface types: grass/soil, tree, and inland water. Two approaches are presented. One is a conventional approach that combines Gabor features and a nonlinear classifier known as Support Vector Machine (SVM). Another one is a deep learning-based approach called SegNet. Extensive simulations showed that although both approaches achieved high performance, the Gabor/SVM approach yielded slightly better robustness with respect to illumination changes.},
keywords={UAVs;landing site selection;Gabor features;SVM;SegNet},
doi={10.1109/IECON.2018.8591267},
ISSN={2577-1647},
month={Oct},}
@INPROCEEDINGS{9524024,
author={Qi, Le and Yuan, Baoxi and Ma, Peng and Guo, Yingxia and Wang, Feng and Mi, Chen},
booktitle={2020 International Conference on Robots Intelligent System (ICRIS)}, title={Scene Simulation and Cooperative Target Detection During UAV Autonomous Landing},
year={2020},
volume={},
number={},
pages={40-43},
abstract={In order to overcome the problems of low guidance accuracy, poor autonomy and high experimental cost during the landing of UA V, a method of scene simulation and cooperative target detection in uav autonomous landing is proposed. In this method, QR code image with strong error correction ability is adopted as the cooperation target, Unreal Engine 4 (UE4) is used to build UA V landing simulation scene, and the UnrealCV plug-in is installed to enable UE4 to communicate with external programs. Finally, in the scene, the accuracy of yolov3 (You Only Look Once v3), a object detection algorithm based on deep learning adopted in this paper, to detect the cooperative target position on the runway is verified. The simulation results show that the algorithm can detect the landing target position with 100% accuracy and recall rate, ensuring the smooth completion of the whole landing process.},
keywords={Training;Deep learning;Visualization;Costs;Navigation;Simulation;Object detection;UE4;UAV Autonomous Landing;Scene Design;Cooperative Object Detection},
doi={10.1109/ICRIS52159.2020.00018},
ISSN={},
month={Nov},}
@INPROCEEDINGS{7991052,
author={Chen, Chien-Hung and Liu, Keng-Hao},
booktitle={2017 IEEE International Conference on Consumer Electronics - Taiwan (ICCE-TW)}, title={Stingray detection of aerial images with region-based convolution neural network},
year={2017},
volume={},
number={},
pages={175-176},
abstract={The image processing technologies have become a popular tool for biological related researches. In order to detect the specific animal from aerial videos, this paper attempts to use the region-based convolution neural network to implement stingray detection on aerial images obtained by UAV. The experimental shows that using Faster R-CNN algorithm as the target detector can achieve good detection accuracy with short computing time. It suggests that deep learning-based methods have considerable potential to aid real-time applications.},
keywords={Videos;Convolution;Neural networks;Training;Machine learning;Object detection;Proposals},
doi={10.1109/ICCE-China.2017.7991052},
ISSN={},
month={June},}
@INPROCEEDINGS{9470420,
author={Rauch, Jonas and Doer, Christopher and Trommer, Gert F.},
booktitle={2021 28th Saint Petersburg International Conference on Integrated Navigation Systems (ICINS)}, title={Object Detection on Thermal Images for Unmanned Aerial Vehicles Using Domain Adaption Through Fine-Tuning},
year={2021},
volume={},
number={},
pages={1-4},
abstract={This work addresses state-of-the-art object detection methods using deep learning on thermal images for application on Unmanned Aerial Vehicles (UAVs). For this purpose, fine-tuning is performed using a custom dataset. Special focus is given to the generation of this dataset, as the annotations for the thermal images are automatically generated from simultaneously acquired visual images. The bounding boxes found on visual images using state-of-the-art object detection methods are applied as annotations to the thermal images. Furthermore, it is shown how the fine-tuned models can be executed in real-time on the drone's embedded PC, which is limited in its computing power, by using additional accelerator hardware.},
keywords={Deep learning;Training;Visualization;Annotations;Computational modeling;Pose estimation;Object detection;Real-time object detection;Domain adaption;Fine-tuning;Thermal imaging},
doi={10.23919/ICINS43216.2021.9470420},
ISSN={},
month={May},}
@INPROCEEDINGS{9213538,
author={Lin, Fuyan and Zheng, Xin and Wu, Qiang},
booktitle={2020 IEEE International Conference on Advances in Electrical Engineering and Computer Applications( AEECA)}, title={Small object detection in aerial view based on improved YoloV3 neural network},
year={2020},
volume={},
number={},
pages={522-525},
abstract={In application scenarios such as UAV inspection, deep learning-based object detection methods are increasingly used to improve the automation of line inspection. In the aerial view scene, the drone is usually fly at a high altitude from the ground, so the proportion of the object in the image is relatively small. When the YoloV3 network identifies small objects, the detection result would not be good because there is less information in the 8x downsampling feature map. In this paper, base on the LaSOT data set, the YoloV3 network has been modified by adjusting the values of anchors and establishing the 4x downsampling prediction layer to enhance the detection effect of small objects. Compared with the original YoloV3 network, the improved YoloV3 network has a certain improvement in convergence ability and detection accuracy compared to the original YoloV3 network.},
keywords={Feature extraction;Object detection;Training;Inspection;Object recognition;Convergence;Neural networks;object detection;YoloV3;small object identify;Kmeans clustering;Multi-scale feature fusion},
doi={10.1109/AEECA49918.2020.9213538},
ISSN={},
month={Aug},}
@INPROCEEDINGS{8909830,
author={Nalamati, Mrunalini and Kapoor, Ankit and Saqib, Muhammed and Sharma, Nabin and Blumenstein, Michael},
booktitle={2019 16th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS)}, title={Drone Detection in Long-Range Surveillance Videos},
year={2019},
volume={},
number={},
pages={1-6},
abstract={The usage of small drones/UAVs has significantly increased recently. Consequently, there is a rising potential of small drones being misused for illegal activities such as terrorism, smuggling of drugs, etc. posing high-security risks. Hence, tracking and surveillance of drones are essential to prevent security breaches. The similarity in the appearance of small drone and birds in complex background makes it challenging to detect drones in surveillance videos. This paper addresses the challenge of detecting small drones in surveillance videos using popular and advanced deep learning-based object detection methods. Different CNN-based architectures such as ResNet-101 and Inception with Faster-RCNN, as well as Single Shot Detector (SSD) model was used for experiments. Due to sparse data available for experiments, pre-trained models were used while training the CNNs using transfer learning. Best results were obtained from experiments using Faster-RCNN with the base architecture of ResNet-101. Experimental analysis on different CNN architectures is presented in the paper, along with the visual analysis of the test dataset.},
keywords={Drones;Training;Videos;Object detection;Detectors;Proposals;Birds;Drone detection;Deep learning;Faster R-CNN},
doi={10.1109/AVSS.2019.8909830},
ISSN={2643-6213},
month={Sep.},}
@INPROCEEDINGS{9554952,
author={Zuo, Yihao and Yang, Junli and Zhu, Zihao and Li, Ruizhe and Zhou, Yuhan and Zheng, Yutong},
booktitle={2021 IEEE International Geoscience and Remote Sensing Symposium IGARSS}, title={Real-Time Semantic Segmentation of Aerial Videos Based on Bilateral Segmentation Network},
year={2021},
volume={},
number={},
pages={2763-2766},
abstract={In recent years, deep learning algorithms have been widely used in semantic segmentation of aerial images. However, most of the current research in this field focus on images but not videos. In this paper, we address the problem of real-time aerial video semantic segmentation with BiSeNet[1]. Since BiSeNet is originally proposed for semantic segmentation of natural city scene images, we need a corresponding dataset to ensure the effect of transfer learning when applying it to aerial video segmentation. Therefore, we build a UAV streetscape sequence dataset (USSD) to fill the vacancy of dataset in this field and facilitate our research. Evaluation on USSD shows that BiSeNet outperforms other state-of-the-art methods. It achieves 79.26% mIoU and 93.37% OA with speed of 148.7 FPS on NVIDIA Tesla V100 for a 1920x1080 frame size input aerial video, which satisfies the demand of aerial video semantic segmentation with a competitive balance of accuracy and speed. The aerial video semantic segmentation results are provided at Our Repository.},
keywords={Deep learning;Image segmentation;Visualization;Semantics;Urban areas;Transfer learning;Geoscience and remote sensing;Real-time Aerial Video Semantic Segmentation;High-resolution Aerial Imagery;Deep Learning},
doi={10.1109/IGARSS47720.2021.9554952},
ISSN={2153-7003},
month={July},}
@INPROCEEDINGS{9716276,
author={Narkhede, Parag and Mishra, Animesh and Hamshita, K and Shubham, Ankit Kumar and Chauhan, Aditya},
booktitle={2022 4th International Conference on Smart Systems and Inventive Technology (ICSSIT)}, title={Inertial Sensors and GPS Fusion Using LSTM for Position Estimation of Aerial Vehicle},
year={2022},
volume={},
number={},
pages={671-675},
abstract={Accurate position estimation is an application of high demand in unmanned aerial vehicles. Accelerometer, Gyroscope, Magnetometer, and Global Positioning System are some of the extensively used sensing units while estimating position. Kalman Filter is one of the widely used sensor fusion mechanisms for this purpose. With the applicability of Artificial Intelligence-based techniques in various navigation applications, this paper bestows a novel procedure for positioning an aerial vehicle in a 3D environment using the Long-Short Term Memory architecture. The LSTM network has feedback connections, making it stand different from the other typical feed-forward Neural Networks. The proposed framework's reliability and effectiveness have been exhibited on the robust dataset collected from the MATLAB example. This proposed framework provides a notable improvement in the results compared with the classic method. An AI module for real time operations can provide an effective action in estimating the position of UAVs using the LSTM network approach.},
keywords={Three-dimensional displays;Navigation;Neural networks;Memory architecture;Estimation;Sensor fusion;Real-time systems;Global Positioning System;Inertial Sensors;Long short-term memory;Position Estimation;Sensor Fusion;Unmanned aerial vehicle},
doi={10.1109/ICSSIT53264.2022.9716276},
ISSN={},
month={Jan},}
@INPROCEEDINGS{9315197,
author={Gajalakshmi, P and Satyanarayana, J V and Reddy, G Venkat and Dhavale, Sunita},
booktitle={2020 4th International Conference on Computer, Communication and Signal Processing (ICCCSP)}, title={Detection of Strategic Targets of Interest in Satellite Images using YOLO},
year={2020},
volume={},
number={},
pages={1-5},
abstract={This paper details about training a convolutional neural network for object detection and classification of a custom generated dataset from google earth satellite images. The objects of interest in satellite images are strategic targets such as nuclear power plants and oil refineries. The deep learning network is YOLO version 3 which has shown significant improvement in detecting smaller objects. YOLO v3 is three times faster than SSD and its AP metric for COCO dataset is on par with SSD. Hence YOLO v3 is a faster detector in comparison to SSD. But AP0.75 is low when compared with RetinaNet due to higher localization error. On the other hand, the simpler network of YOLO, Tiny YOLO v3 takes lesser detection time. The objective of experimentation is to evaluate the performance of YOLO v3 and Tiny YOLO v3 for objects from satellite imagery. Google earth satellite images consumes less time and provides cost effective solution rather than acquiring the overhead images through unmanned aerial vehicles (UAVs) and drones. The objects size varies from 120 pixels to 1250 pixels. The experimental results demonstrate its detection capability, metrics results. GeForce RTX GPU was used for training the network.},
keywords={Object detection;Training;Satellites;Power generation;Oil refineries;Conferences;Testing;Deep learning;convolutional neural network;mean average precision;precision;recall},
doi={10.1109/ICCCSP49186.2020.9315197},
ISSN={},
month={Sep.},}
@ARTICLE{9220178,
author={Kim, Hyunbum and Ben-Othman, Jalel and Mokdad, Lynda and Son, Junggab and Li, Chunguo},
journal={IEEE Network}, title={Research Challenges and Security Threats to AI-Driven 5G Virtual Emotion Applications Using Autonomous Vehicles, Drones, and Smart Devices},
year={2020},
volume={34},
number={6},
pages={288-294},
abstract={Thanks to comprehensive potential with new access technology, massive bandwidths and ultrahigh reliability, it is highly expected that recent 5G network and beyond 5G network (B5G) will fundamentally influence various autonomous systems, applications and devices. Also, Artificial intelligence (Ai) is expanding its applicability to numerous existing and next generation systems and research branches. Conversely, Ai can be utilized to threaten 5G-enabled components as well as to attack Ai-based systems and machine learning algorithms. So, it is indispensable to investigate new Ai-based security threats and solutions in 5G-enabled smart cities. in this article, we introduce Ai-driven 5G integrated virtual emotion system, called 5G-i-VEmoSYS, which covers Ai-VEmoBAR, Ai-VEmoFLOW, and Ai-VEmoMAP as applications in 5G environments. First, we explain how to operate those Ai-driven promising applications in 5G-enabled components including autonomous vehicles, smart UAVs or drones. Also, we describe how to perform those applications in public areas and private areas with different perspectives. Then, we carefully deal with research challenges, security threats and issues according to the proposed 5G-i-VEmoSYS.},
keywords={5G mobile communication;Autonomous vehicles;Security;Smart devices;Drones;Smart cities},
doi={10.1109/MNET.011.2000245},
ISSN={1558-156X},
month={November},}
@ARTICLE{8612450,
author={Kato, Nei and Fadlullah, Zubair Md. and Tang, Fengxiao and Mao, Bomin and Tani, Shigenori and Okamura, Atsushi and Liu, Jiajia},
journal={IEEE Wireless Communications}, title={Optimizing Space-Air-Ground Integrated Networks by Artificial Intelligence},
year={2019},
volume={26},
number={4},
pages={140-147},
abstract={It is widely acknowledged that the development of traditional terrestrial communication technologies cannot provide all users with fair and high quality services due to scarce network resources and limited coverage areas. To complement the terrestrial connection, especially for users in rural, disaster-stricken, or other difficult-to-serve areas, satellites, UAVs, and balloons have been utilized to relay communication signals. On this basis, SAGINs have been proposed to improve the users' QoE. However, compared with existing networks such as ad hoc networks and cellular networks, SAGINs are much more complex due to the various characteristics of three network segments. To improve the performance of SAGINs, researchers are facing many unprecedented challenges. In this article, we propose the AI technique to optimize SAGINs, as the AI technique has shown its predominant advantages in many applications. We first analyze several main challenges of SAGINs and explain how these problems can be solved by AI. Then, we consider the satellite traffic balance as an example and propose a deep learning based method to improve traffic control performance. Simulation results evaluate that the deep learning technique can be an efficient tool to improve the performance of SAGINs.},
keywords={Deep learning;Satellite broadcasting;Satellites;Security;Delays;Quality of experience},
doi={10.1109/MWC.2018.1800365},
ISSN={1558-0687},
month={August},}
@INPROCEEDINGS{9553826,
author={Trujillano, Fedra and Gonzalez, Jessenia and Saito, Carlos and Flores, Andres and Racoceanu, Daniel},
booktitle={2021 IEEE International Geoscience and Remote Sensing Symposium IGARSS}, title={Corn Crops Identification Using Multispectral Images from Unmanned Aircraft Systems},
year={2021},
volume={},
number={},
pages={4712-4715},
abstract={Corn is cultivated by smallholder farmers in Ancash - Peru and it is one of the most important crops of the region. Climate change and migration from rural to urban areas are affecting agricultural production and therefore, food security. Information about the cultivated extension is needed for the authorities in order to evaluate the impact in the region. The present study proposes corn areas segmentation in multi-spectral images acquired from Unmanned Aerial Vehicles (UAV), using convolutional neural networks. U-net and U-net using VGG11 encoder were compared using dice and IoU coefficient as metrics. Results show that with the second model, 81.5% dice coefficient can be obtained in this challenging task, allowing envisaging an effective and efficient use of this technology, in this hard context.},
keywords={Measurement;Image segmentation;Urban areas;Crops;Geoscience and remote sensing;Production;Unmanned aerial vehicles;UAV;climate change;corn identification;semantic segmentation},
doi={10.1109/IGARSS47720.2021.9553826},
ISSN={2153-7003},
month={July},}
@INPROCEEDINGS{9059492,
author={Chun, Chanjun and Jeon, Kwang Myung and Kim, Taewoon and Choi, Wooyeol},
booktitle={2019 IEEE 16th International Conference on Mobile Ad Hoc and Sensor Systems Workshops (MASSW)}, title={Drone Noise Reduction using Deep Convolutional Autoencoder for UAV Acoustic Sensor Networks},
year={2019},
volume={},
number={},
pages={168-169},
abstract={Drones are widely utilized in various industries. Unfortunately, when a drone acquires sound through a microphone, which is installed itself, drone flying and wind noises appear in recorded signals. Therefore, it is necessary to reduce such drone flying and wind noises for enhancing the quality of the recorded sound signals for UAV acoustic sensor networks. In this paper, we proposes the noise reduction method using a deep convolutional denoising autoencoder for eliminating drone flying and wind noises. The deep convolutional denoising autoencoder is widely utilized to extract the target sound source in monaural audio source separation. To do this task, a training dataset is constructed by mixing drone flying and wind noises in clean speech signal. Also, we train the neural network model, which is in form of fully convolutional neural networks. From the sound signals recorded in the real outdoor environment, it is shown that the trained model can reduce the drone flying and wind noises, and only separate the target speech.},
keywords={Drones;Noise reduction;Convolution;Convolutional codes;Convolutional neural networks;Training;Time-frequency analysis;Drone noise reduction; Convolutional neural network; Denoising autoencoder},
doi={10.1109/MASSW.2019.00043},
ISSN={},
month={Nov},}
@INPROCEEDINGS{9554313,
author={Wang, Taojun and Crawford, Melba M.},
booktitle={2021 IEEE International Geoscience and Remote Sensing Symposium IGARSS}, title={Multi-Year Sorghum Biomass Prediction with UAV-Based Remote Sensing Data},
year={2021},
volume={},
number={},
pages={4312-4315},
abstract={Multi-temporal Remote Sensing (RS) data acquired by multisensor mobile mapping systems such as Unmanned Aerial Vehicles (UAVs) provide significant utility for collecting plant phenotypic traits. Biomass is a plant trait that is highly correlated with biofuel production, yet also highly affected by genetics and the environment. Previous studies demonstrated the effectiveness of Recurrent Neural Networks (RNNs) for predicting end-of-season biomass in a single year. However, biomass prediction across multiple years remains a challenge due to the variation of environments and breeding trials. This paper focuses on exploring the transferability of an RNN model incorporating features extracted from LiDAR, hyperspectral and weather data. A k-means assisted transfer learning strategy is proposed to identify optimal samples for fine-tuning the pre-trained RNN model. Results from multiple experiments conducted on sorghum breeding trials at the Purdue University are summarized.},
keywords={Recurrent neural networks;Laser radar;Biological system modeling;Transfer learning;Production;Feature extraction;Unmanned aerial vehicles;Hyperspectral;LiDAR;RNN;transfer learning;deep learning;k-means clustering},
doi={10.1109/IGARSS47720.2021.9554313},
ISSN={2153-7003},
month={July},}
@INPROCEEDINGS{9610823,
author={Pethő, Máté and Zsedrovits, Tamás},
booktitle={2021 17th International Workshop on Cellular Nanoscale Networks and their Applications (CNNA)}, title={UAV obstacle detection with bio-motivated computer vision},
year={2021},
volume={},
number={},
pages={1-4},
abstract={Unmanned aerial vehicles (UAVs) are becoming more and more common. They show excellent potential for multiple types of autonomous work, although they must achieve these tasks safely. For flight safety, it must be assured that the UA V will not endanger its surroundings during autonomous operations; it will avoid collision with any objects in its flight path. Camera-based computer vision and artificial neural networks have shown to be effective in many applications. However, biological vision systems and the brain areas responsible for visual processing may hold solutions capable of acquiring information effectively. Previous work has shown the usability of biologically motivated algorithms using vision systems of insects or even behavioral patterns to solve computer vision problems. We are proposing a novel system, which performs visual cue extraction with algorithms based on the structure and functionality of the retina and the visual cortex of the mammalian visual system. We are also developing a modular artificial neural network with a training dataset, which will perform autonomous obstacle recognition tasks using the data from the image processing algorithm.},
keywords={Training;Visualization;Computer vision;Machine vision;Visual systems;Retina;Unmanned aerial vehicles;vision-aided navigation;bio-motivated algorithms;artificial neural networks},
doi={10.1109/CNNA49188.2021.9610823},
ISSN={},
month={Sep.},}
@INPROCEEDINGS{9702922,
author={Britez, David and Recalde, Gustavo and Gregor, Derlis and Gomez-Redondo, Marcos and Arzamendia, Mario and Vidal, Angélica},
booktitle={2021 IEEE CHILEAN Conference on Electrical, Electronics Engineering, Information and Communication Technologies (CHILECON)}, title={Exploratory approach of neural networks applied to orthomosaics for detection of tires as possible larval foci},
year={2021},
volume={},
number={},
pages={1-5},
abstract={Mosquitoes causes several pandemies nowadays, like dengue, malaria and others. In Paraguay Dengue has become an endemic disease, and every year there are prevention campaigns that attempt to reduce the proliferation of the Aedes Aegypti mosquito. Abandoned tires are a potential place for their re-production. Then it is important to detect and eliminate them. This work presents the use of an UAV (DJI Mavic 2 Pro) for image collection in a city environment and convolutional neural networks (SSD Mobile Network V2) for detection of tire images. For geolocating the tires two approaches were developed, the first approach is to apply object detection with the trained network to an orthomosaic. Because of a poor performance a second approach was proposed, the use of a a super-resolution network to the orthomosaic and then the object detection with the trained network. This later approach achieved better results.},
keywords={Geology;Neural networks;Urban areas;Superresolution;Object detection;Tires;Information and communication technology;Aerial Vehicle;orthomosaic;Convolutional neural networks},
doi={10.1109/CHILECON54041.2021.9702922},
ISSN={},
month={Dec},}
@INPROCEEDINGS{8927923,
author={Yuan, Danni and Zhu, Xiaoyan and Mao, Yaoru and Zheng, Binwen and Wu, Tao},
booktitle={2019 11th International Conference on Wireless Communications and Signal Processing (WCSP)}, title={Privacy-Preserving Pedestrian Detection for Smart City with Edge Computing},
year={2019},
volume={},
number={},
pages={1-6},
abstract={Edge computing is an ideal platform for pedestrian detection in smart city because of low latency and location awareness. In edge computing, data collected by IoT devices are processed on edge servers rather than being transported to cloud server. Compared with cloud computing, edge computing could avoid the possibility of pedestrians' privacy being leaked from cloud server or being stolen in the process of transmission. However, edge servers are not always safe. For instance, there are researches show that 89% of WiFi hotspots are unsecured. Hence, it is possible for attackers to know where you go at a given time of the day, which places you prefer to visit from images collected by IoT devices, such as camera, UAVs. Considering the data collected by IoT devices could include the sensitive information about users, we propose a scheme that applies differential privacy to protect the collected data. We experiment on the INRIA Person Dataset and use three deep learning networks. Results show that even though adding differential privacy makes images blurred, the deep learning network on edge servers can detect pedestrians in the images with accuracy as high as 97.3%.},
keywords={Cloud computing;Servers;Machine learning;Edge computing;Image edge detection;Smart cities;Pedestrian detection;differential privacy;smart city;deep learning;edge computing},
doi={10.1109/WCSP.2019.8927923},
ISSN={2472-7628},
month={Oct},}
@INPROCEEDINGS{9247800,
author={Maximov, Dmitry},
booktitle={2020 13th International Conference "Management of large-scale system development" (MLSD)}, title={Multi-Valued Neural Networks and their Use in Decision Making on the Management of a Group of Unmanned Vehicles},
year={2020},
volume={},
number={},
pages={1-5},
abstract={To make a management decision in the UAV group, a multi-valued associative memory is used. Such a memory is a new concept, generalizing the similar in fuzzy neural networks. In a multi-valued neural network, inputs are elements or subsets of the lattice of linguistic variables. The lattice is assumed to be distributive and defines the implication used to determine the output of a neural network.},
keywords={Neural networks;Decision making;Lattices;Linguistics;Fuzzy neural networks;Unmanned aerial vehicles;Large-scale systems;multi-valued neural networks;fuzzy neural networks;associative memory;unmanned aerial vehicles},
doi={10.1109/MLSD49919.2020.9247800},
ISSN={},
month={Sep.},}
@INPROCEEDINGS{9150902,
author={Cai, Enyu and Baireddy, Sriram and Yang, Changye and Crawford, Melba and Delp, Edward J.},
booktitle={2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)}, title={Deep Transfer Learning For Plant Center Localization},
year={2020},
volume={},
number={},
pages={277-284},
abstract={Plant phenotyping focuses on the measurement of plant characteristics throughout the growing season, typically with the goal of evaluating genotypes for plant breeding. Estimating plant location is important for identifying genotypes which have low emergence, which is also related to the environment and management practices such as fertilizer applications. The goal of this paper is to investigate methods that estimate plant locations for afield-based crop using RGB aerial images captured using Unmanned Aerial Vehicles (UAVs). Deep learning approaches provide promising capability for locating plants observed in RGB images, but they require large quantities of labeled data (ground truth) for training. Using a deep learning architecture fine-tuned on a single field or a single type of crop on fields in other geographic areas or with other crops may not have good results. The problem of generating ground truth for each new field is labor-intensive and tedious. In this paper, we propose a method for estimating plant centers by transferring an existing model to a new scenario using limited ground truth data. We describe the use of transfer learning using a model fine-tuned for a single field or a single type of plant on a varied set of similar crops and fields. We show that transfer learning provides promising results for detecting plant locations.},
keywords={Training;Machine learning;Task analysis;Agriculture;Data models;Training data;Shape},
doi={10.1109/CVPRW50498.2020.00039},
ISSN={2160-7516},
month={June},}
@INPROCEEDINGS{9349620,
author={Mahdavi, Fatemeh and Rajabi, Roozbeh},
booktitle={2020 6th Iranian Conference on Signal Processing and Intelligent Systems (ICSPIS)}, title={Drone Detection Using Convolutional Neural Networks},
year={2020},
volume={},
number={},
pages={1-5},
abstract={In image processing, it is essential to detect and track air targets, especially UAVs. In this paper, we detect the flying drone using a fisheye camera. In the field of diagnosis and classification of objects, there are always many problems that prevent the development of rapid and significant progress in this area. During the previous decades, a couple of advanced classification methods such as convolutional neural networks and support vector machines have been developed. In this study, the drone was detected using three methods of classification of convolutional neural network (CNN), support vector machine (SVM), and nearest neighbor. The outcomes show that CNN, SVM, and nearest neighbor have total accuracy of 93%, 88%, and 80%, respectively. Compared with other classifiers with the same experimental conditions, the accuracy of the convolutional neural network classifier is satisfactory.},
keywords={Support vector machines;Training;Target tracking;Support vector machine classification;Convolutional neural networks;Drones;Testing;Drone Detection;Bird Detection;Classification;Convolutional Neural Network;Support Vector Machine;Nearest Neighbor},
doi={10.1109/ICSPIS51611.2020.9349620},
ISSN={},
month={Dec},}
@INPROCEEDINGS{9613287,
author={Wang, Hongxing and Huang, Zheng and Chen, Yuquan and Zhang, Xin and Shen, Jie and Mao, Weiping and Hao, Zhenyang},
booktitle={2021 13th International Conference on Wireless Communications and Signal Processing (WCSP)}, title={Defect Detection from Power Line Images using Advanced Deep Detectors},
year={2021},
volume={},
number={},
pages={1-5},
abstract={Automatic defect detection from power line images captured by unmanned aerial vehicles (UAV), e.g., drones, using deep learning is an important research topic with significant applications. In this paper, we first collect a large-scale high-resolution power line image dataset and manually annotate the defect bounding boxes. Then, we apply the state-of-the-art deep learning detectors, such as Faster R-CNN, YOLOv4 and FCOS, on this dataset. By applying suitable pre-processing and multi-crop training, we obtain impressive power line defect detection results and provide extensive analysis on the results. The research in this paper can provide a strong baseline for future studies on this challenging computer vision application problem.},
keywords={Deep learning;Wireless communication;Training;Signal processing algorithms;Detectors;Object detection;Signal processing;Defect Detection;Power Line;Deep Learning;Faster R-CNN;FCOS;Baseline},
doi={10.1109/WCSP52459.2021.9613287},
ISSN={2472-7628},
month={Oct},}
@ARTICLE{9743453,
author={Zhang, Hui and Wu, Liuchen and Chen, Yurong and Chen, Ruibo and Kong, Senlin and Wang, Yaonan and Hu, Jianwen and Wub, Jonathan},
journal={IEEE Transactions on Instrumentation and Measurement}, title={Attention-Guided Multitask Convolutional Neural Network for Power Line Parts Detection},
year={2022},
volume={},
number={},
pages={1-1},
abstract={Power line parts detection refers to the inspection of key parts on transmission lines against the complex background in aerial images and identifying whether exist anomalies that cause transmission failure. Obviously, this process plays a pivotal role in ensuring the safety of power transmission. Most of the existing methods are based on deep convolutional neural networks. However, the complexity and variability of the aerial image background and the problem of unmanned aerial vehicles(UAVs) shooting perspective and distance pose a challenge for previous works. This study aims to improve the detection accuracy of the model and propose an attention-guided multi-task convolutional neural network(AGMNet). First, to enhance the feature representation of objects in aerial images, we construct spatial region attention blocks that are suitable for object detection. It can be inserted into any existing convolutional backbone network. Due to its efficient feature tensor computation method, the network can obtain competitive results with less computational memory. Second, we introduce a multitask framework that creatively considers the identification of rust levels and abnormal conditions of power line components, which has not been considered in previous works. Finally, we incorporate the refinable region proposal network(RPN) structure and multiscale training strategy to improve the robustness of the network. The experimental results on the testing datasets show that the proposed AGMNet can recognize the power parts(dampers and suspension clamps) with a mean average precision (mAP) of 95.3%, and simultaneously identify their rust levels with an mAP of 75.4% and abnormal conditions with an mAP of 92.7%.},
keywords={Power transmission lines;Task analysis;Computational modeling;Inspection;Feature extraction;Shock absorbers;Clamps;transmission lines detection;rust levels;abnormal state;deep learning;multi-task learning;attention mechanism},
doi={10.1109/TIM.2022.3162615},
ISSN={1557-9662},
month={},}
@INPROCEEDINGS{9442183,
author={Blekos, Kostas and Nousias, Stavros and Lalos, Aris S},
booktitle={2020 IEEE 18th International Conference on Industrial Informatics (INDIN)}, title={Efficient automated U - Net based tree crown delineation using UAV multi-spectral imagery on embedded devices},
year={2020},
volume={1},
number={},
pages={541-546},
abstract={Delineation approaches provide significant benefits to various domains, including agriculture, environmental and natural disasters monitoring. Most of the work in the literature utilize traditional segmentation methods that require a large amount of computational and storage resources. Deep learning has transformed computer vision and dramatically improved machine translation, though it requires massive dataset for training and significant resources for inference. More importantly, energy-efficient embedded vision hardware delivering real-time and robust performance is crucial in the aforementioned application. In this work, we propose a U-Net based tree delineation method, which is effectively trained using multi-spectral imagery but can then delineate single-spectrum images. The deep architecture that also performs localization, i.e., a class label corresponds to each pixel, has been successfully used to allow training with a small set of segmented images. The ground truth data were generated using traditional image denoising and segmentation approaches. To be able to execute the proposed DNN efficiently in embedded platforms designed for deep learning approaches, we employ traditional model compression and acceleration methods. Extensive evaluation studies using data collected from UAV s equipped with multi-spectral cameras demonstrate the effectiveness of the proposed methods in terms of delineation accuracy and execution efficiency.},
keywords={Training;Deep learning;Location awareness;Image segmentation;Vegetation;Real-time systems;Machine translation;CNN;Accelerated CNN;Deep learning;U-net;Image segmentation},
doi={10.1109/INDIN45582.2020.9442183},
ISSN={2378-363X},
month={July},}
@INPROCEEDINGS{8128413,
author={Zhang, Zhou and Masjedi, Ali and Zhao, Jieqiong and Crawford, Melba M.},
booktitle={2017 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)}, title={Prediction of sorghum biomass based on image based features derived from time series of UAV images},
year={2017},
volume={},
number={},
pages={6154-6157},
abstract={High throughput plant phenotyping has gained significant interest in the plant science community due to its potential impact in advancing the use of advanced plant genetics for problems ranging from global food security to biomass-based energy crops. While traditional collection of field-based phenotypes is manual, automated remote sensing-based methods can reduce the manual requirements, expand the number of sampled points, and accelerate associations with genotypes. In this preliminary work, we use multiple types of features derived from multi-temporal UAV-based hyperspectral and RGB image data for prediction of sorghum biomass. Considering the nonlinear properties of the spectral input features, multiple layer perception (MLP) neural networks and support vector regression (SVR) are explored for predicting dry biomass. The analysis is conducted on datasets acquired during June-August 2016 over an agricultural test field at the Agronomy Center for Research and Education (ACRE) at Purdue University.},
keywords={Biomass;Hyperspectral imaging;Biological system modeling;Predictive models;Data models;Automated phenotyping;regression;hyperspectral data;RGB images},
doi={10.1109/IGARSS.2017.8128413},
ISSN={2153-7003},
month={July},}
@INPROCEEDINGS{9135639,
author={Goudos, Sotirios K. and Athanasiadou, Georgia and Tsoulos, George V. and Rekkas, Vasileios},
booktitle={2020 14th European Conference on Antennas and Propagation (EuCAP)}, title={Modelling Ray Tracing Propagation Data Using Different Machine Learning Algorithms},
year={2020},
volume={},
number={},
pages={1-4},
abstract={In this paper, we apply different machine learning methods for the prediction of path loss in urban environment for cellular communications with unmanned aerial vehicles (UAVs). We generate the training set using a ray tracing technique assuming a flying base station at different heights within the city of Tripolis, Greece. We produce prediction models for the path loss using three different learners the k-Nearest Neighbors (kNN), the Support Vector Regression (SVR)and the Random Forest (RF). The obtained numerical results are compared with the original data from the test dataset using representative performance indicators and overall they exhibit good precision.},
keywords={Training;Support vector machines;Base stations;Urban areas;Ray tracing;Predictive models;Propagation losses;Ray tracing;mobile communications;Support Vector Regression;Random Forest;k-Nearest Neighbors},
doi={10.23919/EuCAP48036.2020.9135639},
ISSN={},
month={March},}
@INPROCEEDINGS{9476271,
author={Correia, Anacleto and Água, Pedro B. and Graça, Rafael},
booktitle={2021 16th Iberian Conference on Information Systems and Technologies (CISTI)}, title={Machine Learning in coastal incident detection, identification and classification with UAVs},
year={2021},
volume={},
number={},
pages={1-6},
abstract={Coastal areas enable the development of economic activities, such as fishing and tourism. The occurrence of maritime incidents can, however, jeopardize these activities. Water pollution, accidents with vessels or falling cliffs are some of these incidents. A proactive surveillance and monitoring of threats by maritime authorities is important. This text proposes a system, installed in a UAV, based on machine learning, and aiming to detect, identify and classify maritime incidents in coastal areas in real time, contributing to a more effective coastal surveillance.},
keywords={Economics;Surveillance;Sea measurements;Machine learning;Water pollution;Real-time systems;Sensors;machine learning;remote sensing;unmanned aerial vehicles;usability},
doi={10.23919/CISTI52073.2021.9476271},
ISSN={2166-0727},
month={June},}
@INPROCEEDINGS{9057865,
author={Zhang, Shiqi and Stewart, Christopher},
booktitle={2019 IEEE National Aerospace and Electronics Conference (NAECON)}, title={Computational Thinking Curriculum for Unmanned Aerial Systems},
year={2019},
volume={},
number={},
pages={122-125},
abstract={Unmanned aerial systems (UAS) can explore common, vast and unsafe places at low cost. They could transform multiple sectors from photography to farming to city planning. However, the software underlying UAS is complex and requires multiple distinct programming skills, e.g., AI, machine learning and flight control. Few programmers encompass these skills, hampering software development and dampening the impact of UAS. We contend that early exposure to UAS software could help align workforce skills. However, early exposure requires curriculum that (1) captures the breadth of UAS software, (2) supports multiple levels of depth for diverse programming backgrounds and (3) fits within resource and institutional challenges. We propose a computational thinking framework. In our approach, lessons fit within 20-30 minute instructional blocks, making them usable in short workshop and extended classroom settings. UAV topics and computational thinking depth link lessons. Teachers can trade breadth for in-depth coding and vice versa. In early work, we presented an autonomous UAS to middle school students. Our 1 hour workshop focused on breadth and was received well.},
keywords={Software;Conferences;Artificial intelligence;Drones;Face;Password;FAA},
doi={10.1109/NAECON46414.2019.9057865},
ISSN={2379-2027},
month={July},}
@INPROCEEDINGS{9249561,
author={Kakamoukas, Georgios and Sarigiannidis, Panagiotis and Moscholios, Ioannis},
booktitle={2020 12th International Symposium on Communication Systems, Networks and Digital Signal Processing (CSNDSP)}, title={Towards Protecting Agriculture from Exogenous and Endogenous Factors: An Holistic Architecture},
year={2020},
volume={},
number={},
pages={1-4},
abstract={An holistic architecture that fosters the application of Smart Farming (SF) in the context of agriculture is proposed in this paper. The proposed architecture exploits the benefits of Internet of Things (IoT), by utilizing a) Wireless Sensor Networks (WSN) for real time monitoring and b) Unmanned Aerial Vehicles (UAVs) / flying Ad-hoc Networks (FANETs) for macroscopic monitoring of the field and inspecting the crops using multispectral cameras. The aggregated data coming from the monitoring process feed the cloud infrastructure, where Machine Learning (ML) and Computer Vision (CV) techniques are applied in order to protect plants from exogenous (e.g., pests) and endogenous (e.g., diseases) factors.},
keywords={Wireless sensor networks;Computer architecture;Ad hoc networks;Unmanned aerial vehicles;Real-time systems;Internet of Things;Monitoring;unmanned aerial vehicles;smart farming;flying ad-hoc networks;wireless sensor networks;plant protection},
doi={10.1109/CSNDSP49049.2020.9249561},
ISSN={},
month={July},}
@INPROCEEDINGS{8127595,
author={Chen, Bowei and Li, Zengyuan and Pang, Yong and Liu, Qingwang and Gao, Xianlian and Gao, Jinping and Fu, Anmin},
booktitle={2017 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)}, title={Forest height estimation based on uav lidar simulated waveform},
year={2017},
volume={},
number={},
pages={2859-2862},
abstract={The accurate estimation of forest height is very important for understanding forest biomass and forest vertical structures. To investigate the potentials of forest height mapping for future Chinese satellite mission concepts with a waveform Lidar system onboard, a field campaign was designed and implemented in Weihe forest farm, Northeastern China in August of 2016. The method we proposed in this paper is that firstly we generate simulated waveforms from Unmanned Aerial Vehicles (UAV) Lidar data, then we use random forest (RF) to get the most relevant variables from 18 waveform parameters driven from our simulated results and 11 terrain parameters from ASTER-DEM. Finally, we used Cubist machine learning algorithm to establish the relationships between 4 different forest heights and the selected variables. Initial results demonstrated that the simulated waveforms could estimate forest height very well.},
keywords={Laser radar;Satellites;Estimation;Remote sensing;Vegetation;Unmanned aerial vehicles;Biomass;Forest height;UAV Lidar;waveform;simulation;Cubist},
doi={10.1109/IGARSS.2017.8127595},
ISSN={2153-7003},
month={July},}
@ARTICLE{9652086,
author={Liao, Haijun and Wang, Zhao and Zhou, Zhenyu and Wang, Yang and Zhang, Hui and Mumtaz, Shahid and Guizani, Mohsen},
journal={IEEE Journal of Selected Topics in Signal Processing}, title={Blockchain and Semi-Distributed Learning-Based Secure and Low-Latency Computation Offloading in Space-Air-Ground-Integrated Power IoT},
year={2021},
volume={},
number={},
pages={1-1},
abstract={Power systems impose stringent security and delay requirements on computation offloading, which cannot be satisfied by existing power Internet of Things (PIoT) networks. In this paper, we tackle this challenge by combining blockchain, space-air-ground integrated PIoT (SAG-PIoT) and machine learning. Low earth orbit (LEO) satellites assist in broadcasting consensus message to reduce the block creation delay, and unmanned aerial vehicles (UAVs) provide flexible coverage enhancement. Specifically, we propose a Blockchain and semi-distributed leaRning-based secure and low-latency electromAgnetic interferenCe-awarE computation offloading algorithm (BRACE) to minimize the total queuing delay under the long-term security constraint. First, task offloading is decoupled from computational resource allocation by Lyapunov optimization. Second, the task offloading problem is solved by the proposed federated deep actor-critic-based electromagnetic interference-aware task offloading algorithm (FDAC-EMI). Finally, the resource allocation problem is solved by smooth approximation and Lagrange optimization. Simulation results verify that BRACE achieves superior delay and security performance.},
keywords={Task analysis;Servers;Security;Delays;Computational modeling;Blockchains;Electromagnetic interference;Space-air-ground-integrated power IoT (SAGPIoT);computation offloading;blockchain;semi-distributed learning;electromagnetic interference awareness},
doi={10.1109/JSTSP.2021.3135751},
ISSN={1941-0484},
month={},}
@INPROCEEDINGS{9012139,
author={Dixit, Krishna R and Verma, Tarun and Subramanya, U S and Umadevi, V},
booktitle={2018 3rd IEEE International Conference on Recent Trends in Electronics, Information Communication Technology (RTEICT)}, title={Hand Gesture Based Quadcopter Control Using Image Processing And Adaptive Machine Learning},
year={2018},
volume={},
number={},
pages={1214-1218},
abstract={Accurately recognizing gesture in real time is a complex problem to solve. It can be addressed to some extent using colored gloves and markers, but models so built do not generalize well. Another option is to utilize boundary based gesture recognition, but these are more complex to build and prediction is time consuming. Through this work we try to resolve both these issues by construction of a straightforward machine learning architecture which accurately implements gesture recognition in real time and can also be utilized to build a generalized model. The solution we have developed is based on the premise that an architecture which can contextually recognize gestures and can also adaptively identify variations to the same can be used for solving problems ranging from body language detection, translating sign language to devising an intuitive method for controlling UAVs (Unmanned Aerial Vehicles).},
keywords={Gesture recognition;Real-time systems;Streaming media;Feature extraction;Machine learning;Cameras;Face;quadcopter;adaptive learning;image processing;sequence learning;hand motion detection;machine learning;gesture control},
doi={10.1109/RTEICT42901.2018.9012139},
ISSN={},
month={May},}
@INPROCEEDINGS{9670517,
author={Panigrahy, Satyajit and Karmakar, Subrata and Sahoo, Rakesh},
booktitle={2021 IEEE 5th International Conference on Condition Assessment Techniques in Electrical Systems (CATCON)}, title={Transfer Learning based Condition Assessment of High Voltage Insulator: A Comparative Analysis},
year={2021},
volume={},
number={},
pages={145-150},
abstract={Routine inspection of a power line insulator system for early problem detection and maintenance is required for the effective transmission of electrical power to customers. Unlike the traditional manual inspection methods such as foot patrol, helicopter assisted methods, flying and climbing robots are time consuming, dangerous, labor intensive, and expensive. This work primarily focused on the insulator image classification of the Chinese Power Line Insulator Dataset (CPLID). Convolutional Neural Network (CNN) and pre-trained neural networks with different optimizers like Adam, Adamax, Adagrad, Adadelta, Nadam, Ftrl, and RMSprop were used to find out the best combination of CNN and pre-trained neural network with the optimizer to provide robust performance and higher accuracy. Finally, CNN with Adamax optimizer provided overall accuracy of 95.27% and the pre-trained CNN Densenet 201 with Adam optimizer gave overall accuracy of 100%. In the automated inspection of transmission line insulators, the deployment of UAVs and deep learning algorithms can be a useful starting point for many researchers throughout the world.},
keywords={Power transmission lines;Neural networks;Transfer learning;Manuals;Inspection;Maintenance engineering;Insulators;Polymeric Insulator;Image Classification;Convolutional Neural Network (CNN);Transfer Learning},
doi={10.1109/CATCON52335.2021.9670517},
ISSN={},
month={Dec},}
@INPROCEEDINGS{9197071,
author={Sadhu, Vidyasagar and Zonouz, Saman and Pompili, Dario},
booktitle={2020 IEEE International Conference on Robotics and Automation (ICRA)}, title={On-board Deep-learning-based Unmanned Aerial Vehicle Fault Cause Detection and Identification},
year={2020},
volume={},
number={},
pages={5255-5261},
abstract={With the increase in use of Unmanned Aerial Vehicles (UAVs)/drones, it is important to detect and identify causes of failure in real time for proper recovery from a potential crash-like scenario or post incident forensics analysis. The cause of crash could be either a fault in the sensor/actuator system, a physical damage/attack, or a cyber attack on the drone's software. In this paper, we propose novel architectures based on deep Convolutional and Long Short-Term Memory Neural Networks (CNNs and LSTMs) to detect (via Autoencoder) and classify drone mis-operations based on real-time sensor data. The proposed architectures are able to learn high-level features automatically from the raw sensor data and learn the spatial and temporal dynamics in the sensor data. We validate the proposed deep-learning architectures via simulations and realworld experiments on a drone. Empirical results show that our solution is able to detect (with over 90% accuracy) and classify various types of drone mis-operations (with about 99% accuracy (simulation data) and upto 85% accuracy (experimental data)).},
keywords={Drones;Computer crashes;Real-time systems;Robot sensing systems;Computer architecture;Neural networks;Data models},
doi={10.1109/ICRA40945.2020.9197071},
ISSN={2577-087X},
month={May},}
@INPROCEEDINGS{9274817,
author={Gao, Wang and Wang, Changqing and Li, Lei},
booktitle={2020 3rd International Conference on Unmanned Systems (ICUS)}, title={Depth Estimation for Small Obstacles Based on Monocular Vision},
year={2020},
volume={},
number={},
pages={407-411},
abstract={In order to solve the problem of small obstacles avoidance in ultra-low altitude flying of unmanned aerial vehicles (UAVs), a depth estimation algorithm based on monocular visual for small tower obstacles is proposed by combining deep learning and traditional methods. With the advantage of convolutional neural networks to extract the salient features of the images, a lightweight and multi-level residual convolution neural network for obstacle segmentation is proposed. The cross-entropy loss function is optimized by adding the weight of the background and obstacles area. A method based on pairs of coplanar points is introduced to complete the depth estimation of a single frame image. Moreover, the recursive formula of sequence images depth results is derived, and a multi-frame voting optimization algorithm is proposed. Finally, the simulation results show that the proposed algorithm can effectively realize the fast segmentation and accurate depth estimation of the small tower obstacles in the sequence images.},
keywords={Intelligent agents;Estimation;Control systems;Training;Deep learning;Computer vision;Complex systems;ultra-low altitude flight;monocular vision;small obstacles;depth estimation},
doi={10.1109/ICUS50048.2020.9274817},
ISSN={},
month={Nov},}
@ARTICLE{8424456,
author={Nikonorov, Artem V. and Petrov, Maksim V. and Bibikov, Sergei A. and Yakimov, Pavel Y. and Kutikova, Viktoriya V. and Yuzifovich, Yuriy V. and Morozov, Andrey A. and Skidanov, Roman V. and Kazanskiy, Nikolay L.},
journal={IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing}, title={Toward Ultralightweight Remote Sensing With Harmonic Lenses and Convolutional Neural Networks},
year={2018},
volume={11},
number={9},
pages={3338-3348},
abstract={In this paper, we describe our advances in manufacturing a 256-layer 7-μm thick harmonic lens with 150 and 300 mm focal distances combined with color correction, deconvolution, and a feedforwarding deep learning neural network capable of producing images approaching photographic visual quality. While reconstruction of images taken with diffractive optics was presented in previous works, this paper is the first to use deep neural networks during the restoration step. The level of imaging quality we achieved with our imaging system can facilitate the emergence of ultralightweight remote sensing cameras for nano- and pico-satellites, and for aerial remote sensing systems onboard small UAVs and solar-powered airplanes.},
keywords={Lenses;Harmonic analysis;Optical diffraction;Optical imaging;Remote sensing;Image color analysis;Color correction;deconvolution;deep learning;harmonic lens;point spread function (PSF) estimation;remote sensing},
doi={10.1109/JSTARS.2018.2856538},
ISSN={2151-1535},
month={Sep.},}
@INPROCEEDINGS{9626844,
author={Marcos, Juliana T.C. and Utete, Simukai W.},
booktitle={2021 IEEE 24th International Conference on Information Fusion (FUSION)}, title={Animal Tracking within a Formation of Drones},
year={2021},
volume={},
number={},
pages={1-8},
abstract={In this study, we develop a distributed system that can be used by unmanned aerial vehicles (UAVs) or drones for single-animal tracking in terrestrial settings. The system involves a video object tracking (VOT) solution and a drone formation. The proposed VOT solution is based on the particle filter (PF) with two measurement providers: a colour image segmentation (CIS) approach and a machine learning (ML) technique. They are switched based on the structural similarity (SSIM) index between the initial and the current target appearances to mitigate the limitation of computational resources of civilian drones, and to ensure good tracking performance. At first, the deep learning object detector You Only Look Once version three (YOLOv3) is used as the second measurement provider. The proposed VOT solution has been tested on wildlife footage recorded by drones (and obtained from an animal behaviour group). The tests demonstrate amongst other results that the proposed VOT solution is more efficient when YOLOv3 is replaced by other methods such as boosting and channel and spatial reliability tracking (CSRT). The results suggest the utility of the proposed VOT solution in single-animal tracking with cooperative drones for wildlife preservation.},
keywords={Target tracking;Current measurement;Wildlife;Switches;Particle measurements;Information filters;Particle filters;Animal tracking;Boosting;channel and spatial reliability tracking (CSRT);drone;multiple instance learning (MIL);particle filter;structural similarity (SSIM) index;unmanned aerial vehicle (UAV);You Only Look Once version 3 (YOLOv3)},
doi={10.23919/FUSION49465.2021.9626844},
ISSN={},
month={Nov},}
@INPROCEEDINGS{7844524,
author={Zhang, Weishan and Dehai Zhao and Xu, Liang and Li, Zhongwei and Wenjuan Gong and Jiehan Zhou},
booktitle={2016 IEEE International Conference on Systems, Man, and Cybernetics (SMC)}, title={Distributed embedded deep learning based real-time video processing},
year={2016},
volume={},
number={},
pages={001945-001950},
abstract={There arises the needs for fast processing of continuous video data using embedded devices, for example the one needed for UAV aerial photography. In this paper, we proposed a distributed embedded platform built with NVIDIA Jetson TX1 using deep learning techniques for real time video processing, mainly for object detection. We design a Storm based distributed real-time computation platform and ran object detection algorithm based on convolutional neural networks. We have evaluated the performance of our platform by conducting real-time object detection on surveillance video. Compared with the high end GPU processing of NVIDIA TITAN X, our platform achieves the same processing speed but a much lower power consumption when doing the same work. At the same time, our platform had a good scalability and fault tolerance, which is suitable for intelligent mobile devices such as unmanned aerial vehicles or self-driving cars.},
keywords={Streaming media;Object detection;Real-time systems;Machine learning;Power demand;Storms;Neural networks;Distributed embedded platform;video processing;low power consumption;Stream processing},
doi={10.1109/SMC.2016.7844524},
ISSN={},
month={Oct},}
@INPROCEEDINGS{8748953,
author={Hu, Bin and Wang, Jiacun},
booktitle={2018 24th International Conference on Automation and Computing (ICAC)}, title={Deep Learning Based Hand Gesture Recognition and UAV Flight Controls},
year={2018},
volume={},
number={},
pages={1-6},
abstract={Dynamic hand gesture recognition is desired as an alternative means for human-computer interactions. This paper presents a hand gesture recognition system that is designed for the control of flights of unmanned aerial vehicles (UAV). To train the system to recognize designed gestures, skeleton data collected from a Leap Motion Controller are converted to two different data models. As many as 9124 samples of training dataset, 1938 samples of testing dataset are created to train and test the proposed three deep learning neural networks, which are a 2-layer fully connected neural network, a 5-layer fully connected neural network and an 8-layer convolutional neural network. The static testing results show that the 2-layer fully connected neural network achieves an average accuracy of 98.2% on normalized datasets and 11% on raw datasets. The 5-layer fully connected neural network achieves an average accuracy of 95.2% on normalized datasets and 45% on raw datasets. The 8-layers convolutional neural network achieves an average accuracy of 96.2% on normalized datasets and raw datasets. Testing on a drone-kit simulator and a real drone shows that this system is feasible for drone flight controls.},
keywords={Deep learning;Gesture recognition;Training;Neural networks;Tracking;Testing;Skeleton;Deep learning;neural networks;hand gesture recognition;leap motion controllers;drones},
doi={10.23919/IConAC.2018.8748953},
ISSN={},
month={Sep.},}
@INPROCEEDINGS{9613590,
author={Rad, Pedram Amini and Hofmann, Danny and Pertuz Mendez, Sergio Andres and Goehringer, Diana},
booktitle={2021 26th IEEE International Conference on Emerging Technologies and Factory Automation (ETFA )}, title={Optimized Deep Learning Object Recognition for Drones using Embedded GPU},
year={2021},
volume={},
number={},
pages={1-7},
abstract={Nowadays, drones can be seen in various applications in industry like surveillance and transportation. Industrial drones leverage fully-fledged computer vision techniques, such as object detection based on Deep Learning Neural Networks (DNN), to efficiently perform these objectives. Those techniques come with a high computational effort and are implemented on distributed schemes using ground devices with high performance and power consumption. This limits a drone's operational range since it has to communicate with the ground devices constantly. To alleviate such constraints, an optimized, low-power perception system on the drone is desirable. This work improves a trained DNN architecture to navigate a UAV introduced by the University of Zurich called DroNet. DroNet is computationally expensive and has a high power consumption, making it unsuitable for embedded platforms because of low memory and computational power. In this paper, a ROS-based architecture is first designed to port DroNet on a low-power Jetson Nano board, which conducts the drone's perception and control tasks. Secondly, tuning parameters and various schemes have been carried out to run the inference of the DNN efficiently. To implement the different layers in DNNs, Nvidia's TensorRT SDK is used to compile a high-performance inference engine for the Jetson Nano. Results showed that the Jetson Nano can achieve real-time performance, with 47 frames per second using a Winograd convolution and well-tuned parallelization parameters. The implementation can also achieve a speedup of 2× as compared with the Jetson Nanos ARM CPU while increasing the power consumption by 54%. Finally, the Jetson Nano's usability for drone inference algorithm is shown, achieving real-time response using the DroNet DNN without losing detection accuracy.},
keywords={Performance evaluation;Deep learning;Power demand;Estimation;Object detection;Real-time systems;Inference algorithms;drones;Jetson Nano;low power deep learning;deep learning;neural networks;object detection},
doi={10.1109/ETFA45728.2021.9613590},
ISSN={},
month={Sep.},}
@INPROCEEDINGS{9312252,
author={Fang, Wang and Yue, Liu and Dandan, Cui},
booktitle={2020 International Conference on Internet of Things and Intelligent Applications (ITIA)}, title={Classification system study of soybean leaf disease based on deep learning},
year={2020},
volume={},
number={},
pages={1-5},
abstract={Accurate and automatic identification of leaf diseases can help farmers to formulate early response actions to reduce economic losses. A deep learning-based classification system against soybean leaf disease was proposed in this paper. The dataset was derived from multi-blade real crop images taken directly by small UAVs at different time periods and under different illumination conditions. First, for the collected leaf images, SLIC method was used to segment the image of plant leaves by classification system. Then, fine-tuning and transfer learning strategies was adopted to expand training of deep neural networks, as well as data enlargement and Dropout techniques were used to avoid over-fitting. Finally, test results of real data sets are presented quantitatively and qualitatively by means of visualization. The results showed that the classification accuracy can be as high as 99.04% when using Inception-v3 combined with 75% fine-tune parameter strategy.},
keywords={Diseases;Image segmentation;Visualization;Training;Agriculture;Deep learning;Computational modeling;intelligent agriculture;deep learning;soybean leaf disease;fine-tune;dropout},
doi={10.1109/ITIA50152.2020.9312252},
ISSN={},
month={Nov},}
@ARTICLE{9057581,
author={Li, Peng and Han, Lirong and Tao, Xuanwen and Zhang, Xiaoyu and Grecos, Christos and Plaza, Antonio and Ren, Peng},
journal={IEEE Transactions on Geoscience and Remote Sensing}, title={Hashing Nets for Hashing: A Quantized Deep Learning to Hash Framework for Remote Sensing Image Retrieval},
year={2020},
volume={58},
number={10},
pages={7331-7345},
abstract={Fast and accurate remote sensing image retrieval from large data archives has been an important research topic in the remote sensing research literature. Recently, hashing-based remote sensing image retrieval has attracted extreme attention because of its efficient search capabilities. Especially, deep remote sensing image hashing algorithms have been developed based on convolutional neural networks (CNNs) and have shown effective retrieval performance. However, implementing a deep hashing network tends to be highly expensive in terms of storage space and computing resources to be suitable for on-orbit remote sensing image retrieval, which usually operates on resource-limited devices such as satellites and unmanned aerial vehicles (UAVs). To address this limitation, we propose to hash a deep network that in turn hashes remote sensing images. Specifically, we develop a quantized deep learning to hash (QDLH) framework for large-scale remote sensing image retrieval. The weights and activation functions in the QDLH framework are binarized to low-bit representations, which require comparatively much less storage space and computing resources. The QDLH results in a lightweight deep neural network for effective remote sensing image hashing. We conduct extensive experiments on two public remote sensing image data sets by incorporating several state-of-the-art network architectures into our QDLH methodology for remote sensing image hashing. The experimental results demonstrate that the proposed QDLH is effective in saving hardware resources in terms of both storage and computation. Moreover, superior remote sensing image retrieval performance is also achieved by our QDLH, compared with state-of-the-art deep remote sensing image hashing methods.},
keywords={Remote sensing;Image retrieval;Task analysis;Neurons;Satellites;Machine learning;Computational modeling;Class intensive;deep hashing;quantized deep network;remote sensing images retrieval},
doi={10.1109/TGRS.2020.2981997},
ISSN={1558-0644},
month={Oct},}
@INPROCEEDINGS{8794057,
author={Mérida-Floriano, M. and Caballero, F. and Acedo, D. and García-Morales, D. and Casares, F. and Merino, L.},
booktitle={2019 International Conference on Robotics and Automation (ICRA)}, title={Bioinspired Direct Visual Estimation of Attitude Rates with Very Low Resolution Images using Deep Networks},
year={2019},
volume={},
number={},
pages={5672-5678},
abstract={In this work we present a bioinspired visual system sensor to estimate angular rates in unmanned aerial vehicles (UAV) using Neural Networks. We have conceived a hardware setup to emulate Drosophila's ocellar system, three simple eyes related to stabilization. This device is composed of three low resolution cameras with a similar spatial configuration as the ocelli. There have been previous approaches based on this ocellar system, most of them considering assumptions such as known light source direction or a punctual light source. In contrast, here we present a learning approach using Artificial Neural Networks in order to recover the system's angular rates indoors and outdoors without previous knowledge. A classical computer vision based method is also derived to be used as a benchmark for the learning approach. The method is validated with a large dataset of images (more than half a million samples) including synthetic and real data. The source code of the algorithms and the datasets used in this paper have been released in an open repository.},
keywords={Cameras;Robot sensing systems;Visualization;Estimation;Neural networks;Computer vision;Image resolution},
doi={10.1109/ICRA.2019.8794057},
ISSN={2577-087X},
month={May},}
@INPROCEEDINGS{9680068,
author={Margapuri, Venkat and Penumajji, Niketa and Neilsen, Mitchell},
booktitle={2021 20th IEEE International Conference on Machine Learning and Applications (ICMLA)}, title={Seed Classification using Synthetic Image Datasets Generated from Low-Altitude UAV Imagery},
year={2021},
volume={},
number={},
pages={116-121},
abstract={Plant breeding programs extensively monitor the evolution of seed kernals for seed certification, wherein lies the need to appropriately label the seed kernels by type and quality. However, the breeding environments are large where the monitoring of seed kernels can be challenging due to the minuscule size of seed kernals. The use of unmanned aerial vehicles aids in seed monitoring and labeling since they can capture images at low altitudes whilst being able to access even the remotest areas in the environment. A key bottleneck in the labeling of seeds using UAV imagery is drone altitude i.e. the classification accuracy decreases as the altitude increases due to lower image detail. Convolutional neural networks are a great tool for multi-class image classification when there is a training dataset that closely represents the different scenarios that the network might encounter during evaluation. However, with the seeds being in a breeder environment coupled with the varying image resolution and clarity, it is challenging to generate a training dataset that covers every evaluation scenario. The article addresses the challenge of training data creation using Domain Randomization wherein synthetic image datasets are generated from a meager sample of seeds captured by the bottom camera of an autonomously driven Parrot AR Drone 2.0. Besides, the article proposes a seed classification framework as a proof-of-concept using the convolutional neural networks of Microsoft's ResNet-lOO, Oxford's VGG-16, and VGG-19. To enhance the classification accuracy of the framework, an ensemble model is developed resulting in an overall accuracy of 94.6%. The task of classification is performed on five different types of seeds, canola, rough rice, sorghum, soy, and wheat.},
keywords={Image resolution;Training data;Machine learning;Autonomous aerial vehicles;Labeling;Convolutional neural networks;Kernel;Domain Randomization;ParrotAR Drone 2. 0;Plant Breeding;ResNet-101;Synthetic Image Dataset;Seed Classification;Seed Phenotyping VGG-1 6;VGG-1 9.},
doi={10.1109/ICMLA52953.2021.00026},
ISSN={},
month={Dec},}
@INPROCEEDINGS{9025597,
author={Masjedi, Ali and Carpenter, Neal R. and Crawford, Melba M. and Tuinstra, Mitch R.},
booktitle={2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)}, title={Prediction of Sorghum Biomass Using Uav Time Series Data and Recurrent Neural Networks},
year={2019},
volume={},
number={},
pages={2695-2702},
abstract={Phenotyping via Unmanned Aerial Vehicles (UAVs) is of increasing interest for many applications because of their capability to carry advanced sensors and achieve accurate positioning required to collect both high temporal and high spatial resolution data required over relatively limited areas. This paper focuses development of a data analytics based predictive modeling strategy that incorporates multi-sensor data acquisition systems and accommodates environmental inputs. Unsupervised feature learning based on fully connected and convolutional neural networks is investigated. Predictive models based on Recurrent Neural Networks (RNNs) are designed and implemented to accommodate high dimensional, multi-modal, multi-temporal data. Remote sensing data, including Light Detection and Ranging (LiDAR) and hyperspectral inputs, as well as weather data, are incorporated in RNN models. Results from multiple experiments focused on high throughput phenotyping of sorghum for biomass predictions are provided and evaluated for agricultural test fields at the Agronomy Center for Research and Education (ACRE) at Purdue University.},
keywords={Biomass;Predictive models;Feature extraction;Hyperspectral imaging;Biological system modeling;Laser radar;Data models},
doi={10.1109/CVPRW.2019.00327},
ISSN={2160-7516},
month={June},}
@INPROCEEDINGS{8768102,
author={Opitz, Felix and Dästner, Kaeye and Roseneckh-Köhler, Bastian von Haßler zu and Schmid, Elke},
booktitle={2019 20th International Radar Symposium (IRS)}, title={Data Analytics and Machine Learning in Wide Area Surveillance Systems},
year={2019},
volume={},
number={},
pages={1-10},
abstract={Modern surveillance networks are able to provide trajectories of all kind of vessels and aircrafts within worldwide or at least extended environment. Most widely used are Automatic Dependent Surveillance - Broadcast (ADS-B) and (Satellite-) Automatic Identification System (AIS) used within air and maritime surveillance. Both of them are cooperative systems. Besides these systems, sensor networks based on ground installations or mounted on airborne and space-based platforms deliver object trajectories independent of any cooperation. Examples include GMTI radar-based systems operating on UAV platforms and coastal or air traffic control sensor network installations. These surveillance systems provide mid- and long-term trajectories. The challenging part is the related situational awareness and the estimation of the intent of the tracked objects. New technologies include activity-based intelligence and the determination of patterns of life. An approach for these technologies can be found in the advanced analysis of those trajectories, which are extracted by the mentioned surveillance systems. Trajectories are partitioned into specific segments of interest using cluster algorithms. This helps to decode their pattern of life based on unsupervised machine learning. Trajectories are aggregated into different routes with dedicated representatives. Calculated probabilities indicate the frequentation of these routes. This allows predictive analytics and the identification of anomalous behaviour. Finally, these new data analytic techniques have to be integrated in existing near real time surveillance systems. This requires specific system architectures as well as a completely new software and hardware landscape. So, trajectory-based Machine Learning is embedded in local or global clouds and uses dedicated mechanisms for distributed and parallel processing.},
keywords={Trajectory;Machine learning;Surveillance;Heating systems;Radar tracking;Aircraft},
doi={10.23919/IRS.2019.8768102},
ISSN={2155-5753},
month={June},}
@ARTICLE{8839973,
author={Shu, Feng and Shen, Tong and Xu, Ling and Qin, Yaolu and Wan, Siming and Jin, Shi and You, Xiaohu and Wang, Jiangzhou},
journal={IEEE Network}, title={Directional Modulation: A Physical-Layer Security Solution to B5G and Future Wireless Networks},
year={2020},
volume={34},
number={2},
pages={210-216},
abstract={Directional modulation (DM), as an efficient secure transmission method, offers security through its directive property and is suitability for LoP channels such as millimeter wave, UAV, satellite communication, and smart transportation. If the direction angle of the desired user is known, the desired channel gain vector is obtainable. Thus, in advance, the DM transmitter knows the values of the directional angles of the desired user and eavesdropper, or their DOAs because the BVCM andANPM are mainly determined by the directional angles of the desired user and eavesdropper. For a DM transceiver, working as a receiver, the first step is to measure the DOAs of the desired user and eavesdropper. Then, in the second step, using the measured DOAs, the BVCM and ANPM are designed. In this article, we describe DOA measurement methods, power allocation, and beamforming in DM networks. A machine learning-based DOA measurement method is proposed to make a substantial secrecy rate (SR) performance gain compared to single-snapshot measurement without machine learning for a given null-space projection beamforming scheme. However, for a conventional DM network, there still exists a serious security issue: the eavesdropper moves inside the main beam of the desired user and may intercept the CMs intended for the desired users because the BVCM and ANPM are only angle-dependent. To address this problem, we present a new concept of SPWT, where the transmit waveform has two-dimensional dependency by using DM, random subcarrier selection with randomization procedure, and phase alignment at the DM transmitter.},
keywords={Direction-of-arrival estimation;Transmitters;Array signal processing;Measurement errors;Measurement uncertainty;Antenna arrays;Machine learning},
doi={10.1109/MNET.001.1900258},
ISSN={1558-156X},
month={March},}
@INPROCEEDINGS{9307102,
author={Nogueira Alves, Adson and Ferreira, Murillo Augusto S. and Colombini, Esther Luna and da Silva Simões, Alexandre},
booktitle={2020 Latin American Robotics Symposium (LARS), 2020 Brazilian Symposium on Robotics (SBR) and 2020 Workshop on Robotics in Education (WRE)}, title={An Evolutionary Algorithm for Quadcopter Trajectory Optimization in Aerial Challenges},
year={2020},
volume={},
number={},
pages={1-6},
abstract={Machine learning methods have been widely employed in robotics over the years, and recent developments in machine learning have completely re-shaped problem-solving in the area. Indeed, if we consider multi-objective planning, these models' optimization and learning capabilities can derive more robust strategies. Inspired by the species natural selection mechanism, Evolutionary Algorithms (EA) are among the best known computational approaches available for this purpose. In this scenario, this work proposed an EA model developed to find the best travel trajectory for a quadcopter in the “Desafio Petrobras” challenge. In the challenge, a set of landing platforms that the robot has to visit are displaced in the 3D-space. To find the best trajectory possible, we optimize an EA over a low-level control that can take the quadcopter from point A to B. We vary our fitness function to support more complex decisions. The software-in-the-loop technique was applied for a simulated quadrotor in the Coppelia simulated environment. The proposed approach has shown the capability to generate short trajectories while considering variables like UAV dynamics and energy consumption.},
keywords={Trajectory;Statistics;Sociology;Genetics;Genetic algorithms;Vehicle dynamics;Unmanned aerial vehicles},
doi={10.1109/LARS/SBR/WRE51543.2020.9307102},
ISSN={2643-685X},
month={Nov},}
@INPROCEEDINGS{9551457,
author={Yu, Qifei and Shen, Zhexin and Pang, Yijiang and Liu, Rui},
booktitle={2021 IEEE 17th International Conference on Automation Science and Engineering (CASE)}, title={Proficiency Constrained Multi-Agent Reinforcement Learning for Environment-Adaptive Multi UAV-UGV Teaming},
year={2021},
volume={},
number={},
pages={2114-2118},
abstract={A mixed aerial and ground robot team, which includes both unmanned ground vehicles (UGVs) and unmanned aerial vehicles (UAVs), is widely used for disaster rescue, social security, precision agriculture, and military missions. However, team capability and corresponding configuration vary since robots have different motion speeds, perceiving ranges, reaching areas, and resilient capabilities to the dynamic environment. Due to heterogeneous robots inside a team and the resilient capabilities of robots, it is challenging to perform a task with an optimal balance between reasonable task allocations and maximum utilization of robot capability. To address this challenge for effective mixed ground and aerial teaming, this paper developed a novel teaming method, proficiency aware multi-agent deep reinforcement learning (Mix-RL), to guide ground and aerial cooperation by considering the best alignments between robot capabilities, task requirements, and environment conditions. Mix-RL largely exploits robot capabilities while being aware of the adaption of robot capabilities to task requirements and environment conditions. Mix-RL's effectiveness in guiding mixed teaming was validated with the task “social security for criminal vehicle tracking”.},
keywords={Target tracking;Scalability;Reinforcement learning;Unmanned aerial vehicles;Land vehicles;Security;Resource management},
doi={10.1109/CASE49439.2021.9551457},
ISSN={2161-8089},
month={Aug},}
@INPROCEEDINGS{6237275,
author={Fang, Zhou and Hao, Chuanchuan and Li, Ping},
booktitle={2012 IEEE International Symposium on Industrial Electronics}, title={Model reference output feedback control using episodic natural actor-critic},
year={2012},
volume={},
number={},
pages={1286-1290},
abstract={In this paper, we develop a novel reinforcement learning algorithm which requires only system output and converges to an optimal output feedback control policy with expected dynamic performance. An informative reward function based on reference model is adopted to intuitively represent the desired closed-loop performance, which significantly reduces the difficulty of reward construction. A stochastic output feedback control policy based on PID law is used to release the complete observability requirement. The episodic Natural Actor-Critic (eNAC) algorithm is used for policy search. Simulations on a second-order unstable system and a nonlinear LPV model of UAV's longitudinal dynamics demonstrate the efficiency of the proposed algorithm.},
keywords={Heuristic algorithms;Output feedback;Learning;Stochastic processes;Educational institutions;Aerodynamics;Approximation algorithms},
doi={10.1109/ISIE.2012.6237275},
ISSN={2163-5145},
month={May},}
@INPROCEEDINGS{9149258,
author={Qiu, Jin and Lyu, Jiangbin and Fu, Liqun},
booktitle={ICC 2020 - 2020 IEEE International Conference on Communications (ICC)}, title={Placement Optimization of Aerial Base Stations with Deep Reinforcement Learning},
year={2020},
volume={},
number={},
pages={1-6},
abstract={Unmanned aerial vehicles (UAVs) can be utilized as aerial base stations (ABSs) to assist terrestrial infrastructure for keeping wireless connectivity in various emergency scenarios. To maximize the coverage rate of N ground users (GUs) by jointly placing multiple ABSs with limited coverage range is known to be a NP-hard problem with exponential complexity in N. The problem is further complicated when the coverage range becomes irregular due to site-specific blockage (e.g., buildings) on the air-ground channel in the 3-dimensional (3D) space. To tackle this challenging problem, this paper applies the Deep Reinforcement Learning (DRL) method by 1) representing the state by a coverage bitmap to capture the spatial correlation of GUs/ABSs, whose dimension and associated neural network complexity is invariant with arbitrarily large N; and 2) designing the action and reward for the DRL agent to effectively learn from the dynamic interactions with the complicated propagation environment represented by a 3D Terrain Map. Specifically, a novel two-level design approach is proposed, consisting of a preliminary design based on the dominant line-of-sight (LoS) channel model, and an advanced design to further refine the ABS positions based on site-specific LoS/non-LoS channel states. The double deep Q-network (DQN) with Prioritized Experience Replay (Prioritized Replay DDQN) algorithm is applied to train the policy of multi-ABS placement decision. Numerical results show that the proposed approach significantly improves the coverage rate in complex environment, compared to the benchmark DQN and K-means algorithms.},
keywords={Channel models;Complexity theory;Three-dimensional displays;Optimization;Signal to noise ratio;Base stations;Machine learning},
doi={10.1109/ICC40277.2020.9149258},
ISSN={1938-1883},
month={June},}
@ARTICLE{8740879,
author={Liu, Mushuang and Wan, Yan and Lewis, Frank L.},
journal={IEEE Control Systems Letters}, title={Adaptive Optimal Decision in Multi-Agent Random Switching Systems},
year={2020},
volume={4},
number={2},
pages={265-270},
abstract={Random switching models have been widely used in areas of communication, physics and aerospace, to capture the random movement patterns of mobile agents. In this letter, we study the optimal decision-making problem for multi-agent systems governed by random switching dynamics. In particular, we develop a novel online optimal control solution that integrates the reinforcement learning (RL) with an effective uncertainty sampling method, called multivariate probabilistic collocation method (MPCM), to adaptively find the optimal policies for agents of randomly switching mobility. We also develop a novel estimator that integrates the unscented Kalman filter (UKF) and MPCM to provide online estimation solutions for these agents. Efficiency and accuracy of the proposed solutions are analyzed. A concrete communication and antenna control co-design problem for a multi-UAV network is studied in the end to illustrate and validate the results.},
keywords={Switches;Optimal control;Uncertainty;Switching systems;Random variables;Turning;Adaptive systems;Random switching systems;learning control;nonlinear estimation},
doi={10.1109/LCSYS.2019.2923915},
ISSN={2475-1456},
month={April},}
@ARTICLE{8821415,
author={Liu, Chi Harold and Dai, Zipeng and Zhao, Yinuo and Crowcroft, Jon and Wu, Dapeng and Leung, Kin K.},
journal={IEEE Transactions on Mobile Computing}, title={Distributed and Energy-Efficient Mobile Crowdsensing with Charging Stations by Deep Reinforcement Learning},
year={2021},
volume={20},
number={1},
pages={130-146},
abstract={Mobile crowdsensing (MCS) represents a new sensing paradigm that utilizes the smart mobile devices to collect and share data. Traditional MCS systems mainly leverages the people carried smartphones and other wearable devices which are constrained by the limited sensing capability and battery power. With the popularity of unmanned vehicles like unmanned aerial vehicles (UAVs) and driverless cars, they can provide much more reliable, accurate and cost-efficient sensing services due to to their equipped more powerful sensors. In this paper, we propose a distributed control framework for energy-efficient and DIstributed VEhicle navigation with chaRging sTations, called “e-Divert”. It is a distributed multi-agent deep reinforcement learning (DRL) solution, which uses a convolutional neural network (CNN) to extract useful spatial features as the input to the actor-critic network to produce a real-time action. Also, e-Divert incorporates a distributed prioritized experience replay for better exploration and exploitation, and a long short-term memory (LSTM) enabled N-step temporal sequence modeling module. The solution fully explores the spatiotemporal nature of the considered scenario for better vehicle cooperation and competition between themselves and charging stations, to maximize the energy efficiency, data collection ratio, geographic fairness, and minimize the energy consumption simultaneously. Through extensive simulations, we find an appropriate set of hyperparameters that achieve the best performance, i.e., 5 actors in Ape-X architecture, priority exponent 0.5, and LSTM sequence length 3. Finally, we compare with four baselines including one state-of-the-art approach MADDPG. Results show that our proposed e-Divert significantly improves the energy efficiency, as compared to MADDPG, by 3.62 and 2.36 times on average when varying different numbers of vehicles and charging stations, respectively.},
keywords={Sensors;Charging stations;Task analysis;Unmanned vehicles;Data collection;Crowdsensing;Reinforcement learning;Mobile crowdsensing;charging stations;deep reinforcement learning},
doi={10.1109/TMC.2019.2938509},
ISSN={1558-0660},
month={Jan},}
@ARTICLE{9508149,
author={Hong, Dooyoung and Lee, Seonhoon and Cho, Young Hoo and Baek, Donkyu and Kim, Jaemin and Chang, Naehyuck},
journal={IEEE Transactions on Vehicular Technology}, title={Energy-Efficient Online Path Planning of Multiple Drones Using Reinforcement Learning},
year={2021},
volume={70},
number={10},
pages={9725-9740},
abstract={Drones, typically unmanned aerial vehicles (UAVs), have many purposes. However, simultaneous operation of multiple drones is challenging, considering the real-time interactions and the environment; the drone must avoid collision with the other drones or obstacles. The proposed Advanced TD3 model performs energy-efficient path planning at the edge-level drone. We modify the twin-delayed deep deterministic policy gradient (TD3), which is the state-of-the-art policy gradient reinforcement learning. The frame stacking technique considers the continuous action space of the drone to the TD3 model. During the training, we gradually increase the observation range of agents for fast and stable convergence. We train the modified TD3 model through Offline RL to reduce the overhead for the RL model training. Drones mount the converged RL model on their onboard computer. The Advanced TD3 model in the drones selects an energy-efficient path without the overhead of the training process of the RL model in real-time, considering external factors such as wind or another drone. The total energy consumption of drones in flight along with online path planning is approximately 106% of the total energy consumption of drones that follow offline path planning, even though the trained TD3 model does not require complex computations for real-time execution.},
keywords={Drones;Path planning;Convergence;Real-time systems;Computational modeling;Training;Interference;Multi-robot systems;cyber-physical systems;unmanned aerial vehicles;path planning;reinforcement learning},
doi={10.1109/TVT.2021.3102589},
ISSN={1939-9359},
month={Oct},}
@INPROCEEDINGS{9737165,
author={Rouch, T. Bagheri and Allahverdy, D. and Fakharian, A.},
booktitle={2022 8th International Conference on Control, Instrumentation and Automation (ICCIA)}, title={Adaptive Controller for Swash Mass Helicopter based on Reinforcement Learning Algorithm},
year={2022},
volume={},
number={},
pages={1-6},
abstract={In this paper, a dynamical model of unmanned aerial vehicles (UAVs) known as a swash mass helicopter (SMH) is described. Since the SMH is a highly nonlinear system, an adaptive control framework is required to stabilize this type of vehicle. First, a feedback linearization control approach is applied to the rotational and translational of the SMH subsystems. Then, a learning algorithm named reinforcement learning algorithm has been employed to train the proposed controller. Finally, the simulation results have been illustrated to assess the suggested controller's performance.},
keywords={Machine learning algorithms;Automation;Heuristic algorithms;Simulation;Instruments;Helicopters;Reinforcement learning;Reinforcement learning;Swash mass helicopter;Fitted value iteration;Feedback linearization;train},
doi={10.1109/ICCIA54998.2022.9737165},
ISSN={},
month={March},}
@INPROCEEDINGS{9718819,
author={Xu, Chengyuan and Zhu, Ruijie and Yang, Dongce},
booktitle={2021 International Conference on Computer Information Science and Artificial Intelligence (CISAI)}, title={Karting racing: A revisit to PPO and SAC algorithm},
year={2021},
volume={},
number={},
pages={310-316},
abstract={Proximal Policy Optimization (PPO) is a classical algorithm in reinforcement learning, which has been tested in a collection of benchmark tasks. In this paper, we test PPO in Unity environment to train Karting racing agent, with different parameters and different training settings. In our experiments, the improved PPO algorithm has a better performance in convergence rate and practical results (the average speed of agent) than baseline and other algorithms, such as Soft Actor-Critic (SAC). Visually, the agent trained by PPO appears more stable, which is able to cope with challenging tracks and has better generalization ability when we turned our trained model into a new environment. Our improved algorithm enables several applications, such as auto-pilot and UAV navigation.},
keywords={Training;Information science;Three-dimensional displays;Navigation;Reinforcement learning;Learning (artificial intelligence);Robustness;agent;PPO;SAC;Unity;reinforcement learning},
doi={10.1109/CISAI54367.2021.00066},
ISSN={},
month={Sep.},}
@INPROCEEDINGS{9155522,
author={Rashid, Md Tahmid and Zhang, Daniel Yue and Wang, Dong},
booktitle={IEEE INFOCOM 2020 - IEEE Conference on Computer Communications}, title={SocialDrone: An Integrated Social Media and Drone Sensing System for Reliable Disaster Response},
year={2020},
volume={},
number={},
pages={218-227},
abstract={Social media sensing has emerged as a new disaster response application paradigm to collect real-time observations from online social media users about the disaster status. Due to the noisy nature of social media data, the task of identifying trustworthy information (referred to as "truth discovery") has been a crucial task in social media sensing. However, existing truth discovery solutions often fall short of providing accurate results in disaster response applications due to the spread of misinformation and difficulty of an efficient verification in such scenarios. In this paper, we present SocialDrone, a novel closed-loop social-physical active sensing framework that integrates social media and unmanned aerial vehicles (UAVs) for reliable disaster response applications. In SocialDrone, signals emitted from the social media are distilled to drive the drones to target areas to verify the emergency events. The verification results are then taken back to improve the sensing and distillation process on social media. The SocialDrone framework introduces several unique challenges: i) how to drive the drones using the unreliable social media signals? ii) How to ensure the system is adaptive to the high dynamics from both the physical world and social media? iii) How to incorporate real-world constraints (e.g., the deadlines of events, limited number of drones) into the framework? The SocialDrone addresses these challenges by building a novel integrated social-physical sensing system that leverages techniques from game theory, constrained optimization, and reinforcement learning. The evaluation results on a real-world disaster response application show that SocialDrone significantly outperforms state-of-the-art truth discovery schemes and drone-only solutions by providing more effective disaster response.},
keywords={Social network services;Sensors;Drones;Reliability;Task analysis;Real-time systems;Fires},
doi={10.1109/INFOCOM41043.2020.9155522},
ISSN={2641-9874},
month={July},}
@INPROCEEDINGS{9197152,
author={He, Lei and Aouf, Nabil and Whidborne, James F. and Song, Bifeng},
booktitle={2020 IEEE International Conference on Robotics and Automation (ICRA)}, title={Integrated moment-based LGMD and deep reinforcement learning for UAV obstacle avoidance},
year={2020},
volume={},
number={},
pages={7491-7497},
abstract={In this paper, a bio-inspired monocular vision perception method combined with a learning-based reaction local planner for obstacle avoidance of micro UAVs is presented. The system is more computationally efficient than other vision-based perception and navigation methods such as SLAM and optical flow because it does not need to calculate accurate distances. To improve the robustness of perception against illuminance change, the input image is remapped using image moment which is independent of illuminance variation. After perception, a local planner is trained using deep reinforcement learning for mapless navigation. The proposed perception and navigation methods are evaluated in some realistic simulation environments. The result shows that this light-weight monocular perception and navigation system works well in different complex environments without accurate depth information.},
keywords={Navigation;Collision avoidance;Robustness;Lighting;Robots;Optical imaging;Machine learning},
doi={10.1109/ICRA40945.2020.9197152},
ISSN={2577-087X},
month={May},}


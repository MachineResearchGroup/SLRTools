@INPROCEEDINGS{9333895,
author={Jung, Soyi and Yun, Won Joon and Kim, Joongheon and Kim, Jae-Hyun},
booktitle={2021 International Conference on Information Networking (ICOIN)}, title={Infrastructure-Assisted Cooperative Multi-UAV Deep Reinforcement Energy Trading Learning for Big-Data Processing},
year={2021},
volume={},
number={},
pages={159-162},
abstract={This paper proposes a cooperative multi-agent deep reinforcement learning (MADRL) algorithm for energy trading among multiple unmanned aerial vehicles (UAVs) in order to perform big-data processing in a distributed manner. In order to realize UAV-based aerial surveillance or mobile cellular services, seamless and robust wireless charging mechanisms are required for delivering energy sources from charging infrastructure (i.e., charging towers) to UAVs for the consistent operations of the UAVs in the sky. For actively and intelligently managing the charging towers, MADRL-based energy management system (EMS) is proposed and designed for energy trading among the energy storage systems those are equipped with charging towers. If the required energy for charging UAVs is not enough, the purchasing energy from utility company is desired which takes high consts. The main purpose of MADRL-based EMS learning is for minimizing purchasing energy from outside utility company for minimizing operational costs. Our data-intensive performance evaluation verifies that our proposed framework achieves desired performance.},
keywords={Performance evaluation;Surveillance;Poles and towers;Inductive charging;Companies;Reinforcement learning;Unmanned aerial vehicles;Big-data processing;Multi-agent deep reinforcement learning;Deep learning;Smart grid;Unmanned aerial vehicle (UAV).},
doi={10.1109/ICOIN50884.2021.9333895},
ISSN={1976-7684},
month={Jan},}
@INPROCEEDINGS{8567160,
author={Ho, Chia Yu and Tseng, Shau Yin and Lai, Chin Feng and Wang, Ming Shi and Chen, Ching Ju},
booktitle={2018 1st International Cognitive Cities Conference (IC3)}, title={A Parameter Sharing Method for Reinforcement Learning Model between AirSim and UAVs},
year={2018},
volume={},
number={},
pages={20-23},
abstract={In recent years, unmanned aerial vehicle aerial photography has developed rapidly. Unmanned aerial vehicle can get a different perspective and allow us to do more difficult tasks. Controlling unmanned aerial vehicle requires a lot of manpower, so there are a number of studies that use reinforcement learning to make the unmanned aerial vehicle fly autonomously. It is an expensive and time-consuming task to use reinforcement learning and training unmanned aerial vehicle to accomplish specific tasks in a realistic environment. Therefore this study in a virtual environment using the Q - learning training unmanned aerial vehicle landing, then transplanted model of virtual environment in which to train good into real environment, makes the realistic environment of unmanned aerial vehicle can use cheaper and quickly achieve the same task.},
keywords={Unmanned aerial vehicles;Virtual environments;Training;Task analysis;Sensors;Atmospheric modeling;UAV (Unmanned Aerial Vehicle);machine learning;parameter sharing},
doi={10.1109/IC3.2018.00014},
ISSN={},
month={Aug},}
@INPROCEEDINGS{9620751,
author={Yun, Won Joon and Ha, Yoo Jeong and Jung, Soyi and Kim, Joongheon},
booktitle={2021 International Conference on Information and Communication Technology Convergence (ICTC)}, title={Autonomous Aerial Mobility Learning for Drone-Taxi Flight Control},
year={2021},
volume={},
number={},
pages={329-332},
abstract={In smart city scenarios, the use of unmanned aerial vehicle (UAV) networks is one of actively discussed technologies. In this paper, we consider the scenario where carpoolable UAV-based drone taxis configure their optimal routes to deliver packages and passengers in an autonomous and efficient way. In order to realize this application with drone-taxi UAV networks, a multiagent deep reinforcement learning (MADRL) based algorithm is designed and implemented for the optimal route configuration. In the corresponding MADRL formulation, the drone-taxi related states, actions, and rewards are defined in this paper. Lastly, we confirm that our proposed algorithm achieves desired results.},
keywords={Smart cities;Reinforcement learning;Autonomous aerial vehicles;Information and communication technology;Public transportation;Drones;Convergence;Smart City;Unmanned Aerial Vehicle (UAV);Drone-Taxi;Reinforcement Learning;Multi-Agent Deep Reinforcement Learning (MADRL)},
doi={10.1109/ICTC52510.2021.9620751},
ISSN={2162-1233},
month={Oct},}
@INPROCEEDINGS{9268253,
author={Kim, Sanghyun and Park, Jongmin and Yun, Jae-Kwan and Seo, Jiwon},
booktitle={2020 20th International Conference on Control, Automation and Systems (ICCAS)}, title={Motion Planning by Reinforcement Learning for an Unmanned Aerial Vehicle in Virtual Open Space with Static Obstacles},
year={2020},
volume={},
number={},
pages={784-787},
abstract={In this study, we applied reinforcement learning based on the proximal policy optimization algorithm to perform motion planning for an unmanned aerial vehicle (UAV) in an open space with static obstacles. The application of reinforcement learning through a real UAV has several limitations such as time and cost; thus, we used the Gazebo simulator to train a virtual quadrotor UAV in a virtual environment. As the reinforcement learning progressed, the mean reward and goal rate of the model were increased. Furthermore, the test of the trained model shows that the UAV reaches the goal with an 81% goal rate using the simple reward function suggested in this work.},
keywords={Reinforcement learning;Unmanned aerial vehicles;Planning;Robots;Aerospace electronics;Virtual environments;Training;motion planning;unmanned aerial vehicle (UAV);reinforcement learning;proximal policy optimization (PPO)},
doi={10.23919/ICCAS50221.2020.9268253},
ISSN={2642-3901},
month={Oct},}
@INPROCEEDINGS{9363809,
author={Yin, Rui and Li, Wei and Wang, Zhi-qiang and Xu, Xin-xin},
booktitle={2020 5th International Conference on Information Science, Computer Technology and Transportation (ISCTT)}, title={The Application of Artificial Intelligence Technology in UAV},
year={2020},
volume={},
number={},
pages={238-241},
abstract={From the key technology level, the application of artificial intelligence (AI) in unmanned aerial vehicle (UAV) is discussed. The basic connotation of AI technology is introduced. In the four fields which are machine learning, expert system, automatic planning and distributed artificial intelligence, the application of AI technology in UAV is discussed. The future development trend of UAV based on AI is prospected, which provides a reference for promoting the application of AI in UAV.},
keywords={Process control;Transportation;Market research;Unmanned aerial vehicles;Planning;Internet of Things;Artificial intelligence;Unmanned aerial vehicle;Machine learning;Expert system;Automatic planning;Distributed artificial intelligence},
doi={10.1109/ISCTT51595.2020.00048},
ISSN={},
month={Nov},}
@ARTICLE{9411725,
author={Zhang, Liang and Celik, Abdulkadir and Dang, Shuping and Shihada, Basem},
journal={IEEE Transactions on Mobile Computing}, title={Energy-Efficient Trajectory Optimization for UAV-Assisted IoT Networks},
year={2021},
volume={},
number={},
pages={1-1},
abstract={In this paper, we propose and study an energy-efficient trajectory optimization scheme for unmanned aerial vehicle (UAV) assisted Internet of Things (IoT) networks. In such networks, a single UAV is powered by both solar energy and charging stations (CSs), resulting in sustainable communication services, while avoiding energy outage. In particular, we optimize the trajectory design of UAV by jointly considering the average data rate, the total energy consumption, and the fairness of coverage for the IoT terminals. A dynamic spatial-temporal configuration scheme is operated for terminals working in the discontinuous reception (DRX) mode. The module-free, action-confined on-policy and off-policy reinforcement learning approaches are proposed and jointly applied to solve the formulated optimization problem in this paper. We evaluate the effectiveness of the proposed strategy by comparing it with other dynamic benchmark algorithms. The extensive simulation results provided in this paper reveal that the proposed scheme outperforms the benchmarks in terms of data transmission, energy efficiency and adaptivity of avoiding battery depletion. By deploying the proposed trajectory scheme, the UAV is able to adapt itself according to the temporal and dynamic conditions of communication networks.},
keywords={Unmanned aerial vehicles;Cascading style sheets;Batteries;Optimization;Data communication;Trajectory optimization;Quality of service;Unmanned aerial vehicle (UAV);Internet of Things (IoT);energy harvesting;reinforcement learning (RL);trajectory optimization},
doi={10.1109/TMC.2021.3075083},
ISSN={1558-0660},
month={},}
@ARTICLE{7061535,
author={Lai, Guanyu and Liu, Zhi and Zhang, Yun and Chen, C. L. Philip},
journal={IEEE Transactions on Neural Networks and Learning Systems}, title={Adaptive Position/Attitude Tracking Control of Aerial Robot With Unknown Inertial Matrix Based on a New Robust Neural Identifier},
year={2016},
volume={27},
number={1},
pages={18-31},
abstract={This paper presents a novel adaptive controller for controlling an autonomous helicopter with unknown inertial matrix to asymptotically track the desired trajectory. To identify the unknown inertial matrix included in the attitude dynamic model, this paper proposes a new structural identifier that differs from those previously proposed in that it additionally contains a neural networks (NNs) mechanism and a robust adaptive mechanism, respectively. Using the NNs to compensate the unknown aerodynamic forces online and the robust adaptive mechanism to cancel the combination of the overlarge NNs compensation error and the external disturbances, the new robust neural identifier exhibits a better identification performance in the complex flight environment. Moreover, an optimized algorithm is included in the NNs mechanism to alleviate the burdensome online computation. By the strict Lyapunov argument, the asymptotic convergence of the inertial matrix identification error, position tracking error, and attitude tracking error to arbitrarily small neighborhood of the origin is proved. The simulation and implementation results are provided to evaluate the performance of the proposed controller.},
keywords={Aerodynamics;Symmetric matrices;Artificial neural networks;Helicopters;Robustness;Attitude control;Trajectory;Aerial robot;inertial matrix identifier;neural networks (NNs);robust adaptive control;unmanned aerial vehicle (UAV).;Aerial robot;inertial matrix identifier;neural networks (NNs);robust adaptive control;unmanned aerial vehicle (UAV)},
doi={10.1109/TNNLS.2015.2406812},
ISSN={2162-2388},
month={Jan},}
@INPROCEEDINGS{8453315,
author={Lee, Seongheon and Shim, Taemin and Kim, Sungjoong and Park, Junwoo and Hong, Kyungwoo and Bang, Hyochoong},
booktitle={2018 International Conference on Unmanned Aircraft Systems (ICUAS)}, title={Vision-Based Autonomous Landing of a Multi-Copter Unmanned Aerial Vehicle using Reinforcement Learning},
year={2018},
volume={},
number={},
pages={108-114},
abstract={This paper presents vision-based landing guidance of multi-copter Unmanned Aerial Vehicle (UAV) using reinforcement learning. In this approach, the guidance method is not designed or proposed by a human, but deployed by a neural network trained in simulated environments; which contains a quad-copter UAV model with Proportional-Integral-Derivative (PID) Controller, ground looking camera model that gives pixel deviation of targeting landing location from the center of an image frame, and laser rangefinder that gives altitude above ground level. Since we aimed for various types of multi-copter UAVs to track targeting ground location, reinforcement learning method has been used to generate proper roll and pitch attitude commands in multiple situations. Series of flight experiments show that a multi-copter UAV equipped with a proper attitude controller and trained artificial intelligence pilot can guide a multi-copter UAV to a ground target position.},
keywords={Unmanned aerial vehicles;Training;Learning (artificial intelligence);Cameras;Attitude control;Aerospace engineering;Neural networks;autonomous landing;multi-copter;unmanned aerial vehicle (UAV);artificial intelligence (AI);reinforcement learning;neural networks},
doi={10.1109/ICUAS.2018.8453315},
ISSN={2575-7296},
month={June},}
@INPROCEEDINGS{9649794,
author={Park, Jongmin and Jang, Sooyoung and Shin, Younghoon},
booktitle={2021 21st International Conference on Control, Automation and Systems (ICCAS)}, title={Indoor Path Planning for an Unmanned Aerial Vehicle via Curriculum Learning},
year={2021},
volume={},
number={},
pages={529-533},
abstract={In this study, reinforcement learning was applied to learning two-dimensional path planning including obstacle avoidance by unmanned aerial vehicle (UAV) in an indoor environment. The task assigned to the UAV was to reach the goal position in the shortest amount of time without colliding with any obstacles. Reinforcement learning was performed in a virtual environment created using Gazebo, a virtual environment simulator, to reduce the learning time and cost. Curriculum learning, which consists of two stages was performed for more efficient learning. As a result of learning with two reward models, the maximum goal rates achieved were 71.2% and 88.0%.},
keywords={Costs;Government;Virtual environments;Reinforcement learning;Autonomous aerial vehicles;Path planning;Telecommunications;path planning;curriculum learning;reinforcement learning;unmanned aerial vehicle (UAV)},
doi={10.23919/ICCAS52745.2021.9649794},
ISSN={2642-3901},
month={Oct},}
@ARTICLE{9600566,
author={Cai, Zhuoran and Liu, Zhiyuan and Kou, Liang},
journal={IEEE Transactions on Reliability}, title={Reliable UAV Monitoring System Using Deep Learning Approaches},
year={2021},
volume={},
number={},
pages={1-11},
abstract={In recent years, unmanned aerial vehicles (UAV) or drones have become ubiquitous in our daily lives, bringing great convenience to our lives and playing a pivotal role in future wireless networks and the Internet of things. One of the major problems associated with the UAV is the heterogeneous nature of such deployments; this heterogeneity poses many challenges, particularly in the areas of security and privacy. The key to solving these problems is to accurately identify and authenticate drones. In this article, a reliable UAV identify framework based on radio frequency fingerprint is proposed. First, we established a wireless signal label architecture and systematically collected, analyzed, and recorded the radio frequency signals of different UAVs in different flight modes and different distances in the telemetry link, and established UAV signal datasets. Then, the intelligent algorithm and anti-UAV system are designed by using the collected dataset, and the feasibility of the developed dataset for detecting and identifying UAVs is verified by using machine learning and deep learning. The simulation results show that under the condition of Gaussian white noise, the method based on deep learning achieves high reliability, and when the SNR is not less than 5dB, the model achieves more than 95% of the monitoring and recognition accuracy. Finally, we discussed the possible applications of the dataset in the future.},
keywords={Drones;Feature extraction;Fractals;Deep learning;Wireless communication;Monitoring;Radio frequency;Data collection;deep learning;radio frequency (RF) fingerprinting;unmanned aerial vehicle (UAV) reliable monitoring},
doi={10.1109/TR.2021.3119068},
ISSN={1558-1721},
month={},}
@ARTICLE{9619467,
author={Mondal, Abhishek and Mishra, Deepak and Prasad, Ganesh and Hossain, Ashraf},
journal={IEEE Internet of Things Journal}, title={Joint Optimization Framework for Minimization of Device Energy Consumption in Transmission Rate Constrained UAV-assisted IoT Network},
year={2021},
volume={},
number={},
pages={1-1},
abstract={Due to their high maneuverability and flexible deployment, unmanned aerial vehicles (UAVs) could be an alternative option for a scenario where IoT devices consume high energy to achieve the required data rate when they are far away from the terrestrial base station (BS). Therefore, this paper has proposed an energy-efficient UAV-assisted IoT network where a low altitude quad-rotor UAV provides mobile data collection service from static IoT devices. We develop a novel optimization framework that minimizes the total energy consumption of all devices by jointly optimizing the UAV’s trajectory, devices association, and respectively transmit power allocation at every time slot while ensuring that every device should achieve a given data rate constraint. As this joint optimization problem is non-convex and combinatorial, we adopt a reinforcement learning (RL) based solution methodology that effectively decouples it into three individual optimization sub-problems. The formulated optimization problem has transformed into a Markov decision process (MDP) where the UAV learns its trajectory according to its current state and corresponding action for maximizing the generated reward under the current policy. Finally, we conceive SARSA, a low complexity iterative algorithm for updating the current policy of UAV, that achieves an excellent computational complexity-optimality tradeoff. Numerical results validate the analysis and provide various insights on optimal UAV trajectory. The proposed methodology reduces the total energy consumption of all devices by 6.91%, 8.48%, and 9.94% in 80, 100, and 120 available time slots of UAV, respectively, compared to the particle swarm optimization (PSO) algorithm.},
keywords={Trajectory;Unmanned aerial vehicles;Energy consumption;Optimization;Energy efficiency;Data collection;Internet of Things;Internet of things (IoT);unmanned aerial vehicle (UAV);energy efficiency;joint optimization;reinforcement learning (RL);state-action-reward-state-action (SARSA).},
doi={10.1109/JIOT.2021.3128883},
ISSN={2327-4662},
month={},}
@INPROCEEDINGS{7983613,
author={Moriarty, Padraic and Sheehy, Robert and Doody, Pat},
booktitle={2017 28th Irish Signals and Systems Conference (ISSC)}, title={Neural networks to aid the autonomous landing of a UAV on a ship},
year={2017},
volume={},
number={},
pages={1-4},
abstract={This paper proposes to examine the possible uses of Artificial Neural Networks (ANN) to aid the landing of an Unmanned Aerial Vehicle (UAV) on a ship. Three distinct phases are proposed. The dataset required for training and testing was produced by simulating a ship's motion at sea using Unity. Phase 1 converts video images from a UAV on-board camera to numeric data. Phase 2 utilizes Phase 1 data and calculates the current relative orientation and distance of the UAV to the landing platform. Co-ordinate pairs representing screen positions of particular areas of a ship's landing pad were normalized and used to train the Phase 2 ANN. Orientation has been calculated to an accuracy of +/-1% and distance +/-2%. Phase 3 determines future landing windows. Phase 3 uses the orientations produced in Phase 2 and calculates future periods when a landing, within a time limit, could be attempted. This paper proposes strategies and current research into Phases 1, 2 and 3 and suggests development of an indicator of optimal landing times for Manned Aerial Vehicles (MAV).},
keywords={Unmanned aerial vehicles;Marine vehicles;Artificial neural networks;Training;MATLAB;Cameras;Auto-landing;Unmanned Aerial Vehicle (UAV);Unity;Artificial Neural Networks},
doi={10.1109/ISSC.2017.7983613},
ISSN={},
month={June},}
@ARTICLE{9682599,
author={Yun, Won Joon and Park, Soohyun and Kim, Joongheon and Shin, Myungjae and Jung, Soyi and Mohaisen, Aziz and Kim, Jae-Hyun},
journal={IEEE Transactions on Industrial Informatics}, title={Cooperative Multi-Agent Deep Reinforcement Learning for Reliable Surveillance via Autonomous Multi-UAV Control},
year={2022},
volume={},
number={},
pages={1-1},
abstract={CCTV-based surveillance using unmanned aerial vehicles (UAVs) is considered a key technology for security in smart city environments. This paper creates a case where the UAVs with CCTV-cameras fly over the city area for flexible and reliable surveillance services. For a reliable surveillance UAV system, UAVs should be deployed to observe wide areas while minimizing overlapping and shadow areas. However, the operation of UAVs is subject to high uncertainty, necessitating autonomous recovery systems. This work develops a multi-agent deep reinforcement learning-based management scheme for reliable industry surveillance in smart city applications. The core idea this paper employs is autonomously replenishing the UAV's deficient network requirements with communications. Via intensive simulations, our proposed algorithm outperforms the state-of-the-art algorithms in terms of surveillance coverage, user support capability, and computational costs.},
keywords={Surveillance;Reliability;Optimization;Uncertainty;Electronic mail;Multi-agent systems;Image resolution;Multi-agent systems;Neural networks;Surveillance;Unmanned aerial vehicle (UAV)},
doi={10.1109/TII.2022.3143175},
ISSN={1941-0050},
month={},}
@ARTICLE{9354996,
author={Wang, Liang and Wang, Kezhi and Pan, Cunhua and Xu, Wei and Aslam, N and Nallanathan, Arumugam},
journal={IEEE Transactions on Mobile Computing}, title={Deep Reinforcement Learning Based Dynamic Trajectory Control for UAV-assisted Mobile Edge Computing},
year={2021},
volume={},
number={},
pages={1-1},
abstract={In this paper, we consider a platform of flying mobile edge computing (F-MEC), where unmanned aerial vehicles (UAVs) serve as equipment providing computation resource, and they enable task offloading from user equipment (UE). We aim to minimize energy consumption of all the UEs via optimizing the user association, resource allocation and the trajectory of UAVs. To this end, we first propose a Convex optimizAtion based Trajectory control algorithm (CAT), which solves the problem in an iterative way by using block coordinate descent (BCD) method. Then, to make the real-time decision while taking into account the dynamics of the environment (i.e., UAV may take off from different locations), we propose a deep Reinforcement leArning based Trajectory control algorithm (RAT). In RAT, we apply the Prioritized Experience Replay (PER) to improve the convergence of the training procedure. Different from the convex optimization based algorithm which may be susceptible to the initial points and requires iterations, RAT can be adapted to any taking off points of the UAVs and can obtain the solution more rapidly than CAT once training process has been completed. Simulation results show that the proposed CAT and RAT achieve the considerable performance and both outperform traditional algorithms.},
keywords={Trajectory;Unmanned aerial vehicles;Radio access technologies;Task analysis;Resource management;Reinforcement learning;Cats;Deep Reinforcement Learning;Mobile Edge Computing;Unmanned Aerial Vehicle (UAV);Trajectory Control;User Association},
doi={10.1109/TMC.2021.3059691},
ISSN={1558-0660},
month={},}
@ARTICLE{9656563,
author={Alos, Ahmad and Dahrouj, Zouhair},
journal={IEEE Aerospace and Electronic Systems Magazine}, title={Using MLSTM and Multi-output Convolutional LSTM Algorithms for Detecting Anomalous Patterns in Streamed Data of Unmanned Aerial Vehicles},
year={2021},
volume={},
number={},
pages={1-1},
abstract={In this paper, we present a comparative study of two existing deep learning tools that are used in a novel way to detect anomalies in the streamed data of the Unmanned Aerial Vehicle (UAV). Detecting anomalies is very vital to predict potential faults that are caused by hardware and software faults and may prevent the UAV from hazardous accidents. Therefore, we suggest using Multiple Long Short-Term Memory (MLSTM) and Multi-Output Convolutional LSTM to detect anomalies in UAV data. LSTM networks attracted many researchers in several domains, as it is a useful tool for learning dynamic temporal patterns and long-range dependencies in sequential data, which cannot be achieved using traditional neural networks. However, utilizing multiple LSTM networks would result in too much redundancy. The redundancy issue can be solved by incorporating one Convolutional LSTM (ConvLSTM) network with multiple outputs. The ConvLSTM is suitable for analyzing multivariate temporal data; due to its convolutional architecture and the advantage of preserving the benefits of the LSTM networks. We evaluated and compared the two approaches using well-known indicators such as the Detection Rate, the False Alarm Rate, the Precision, and the F.score indicators. The two methods exhibited promising results in predicting different types of faults, for instance (sensor-impulse and sensor-cut). However, the multi-output ConvLSTM was faster in training and testing phases, and its results were superior in predicting (sensor-stuck and sensor-drift) faults.},
keywords={Logic gates;Autonomous aerial vehicles;Anomaly detection;Computer architecture;Prediction algorithms;Memory management;Data models;Anomaly Detection;Convolutional LSTM;Deep Learning;Fault Detection;LSTM;Machine learning;Neural networks;Sliding window;UAV},
doi={10.1109/MAES.2021.3053108},
ISSN={1557-959X},
month={},}
@ARTICLE{9248522,
author={Nie, Yiwen and Zhao, Junhui and Liu, Jun and Jiang, Jing and Ding, Ruijin},
journal={China Communications}, title={Energy-efficient UAV trajectory design for backscatter communication: A deep reinforcement learning approach},
year={2020},
volume={17},
number={10},
pages={129-141},
abstract={Recently, backscatter communication (BC) has been introduced as a green paradigm for Internet of Things (IoT). Meanwhile, unmanned aerial vehicles (UAVs) can serve as aerial base stations (BSs) to enhance the performance of BC system thanks to their high mobility and flexibility. In this paper, we investigate the problem of energy efficiency (EE) for an energy-limited backscatter communication (BC) network, where backscatter devices (BDs) on the ground harvest energy from the wireless signal of a flying rotary-wing quadrotor. Specifically, we first reformulate the EE optimization problem as a Markov decision process (MDP) and then propose a deep reinforcement learning (DRL) algorithm to design the UAV trajectory with the constraints of the BD scheduling, the power reflection coefficients, the transmission power, and the fairness among BDs. Simulation results show the proposed DRL algorithm achieves close-to-optimal performance and significant EE gains compared to the benchmark schemes.},
keywords={Unmanned aerial vehicles;Trajectory;Backscatter;Internet of Things;Energy efficiency;Optimization;Radio frequency;unmanned aerial vehicle (UAV);trajectory design;backscatter communication;deep reinforcement learning;energy-efficient},
doi={10.23919/JCC.2020.10.009},
ISSN={1673-5447},
month={Oct},}
@ARTICLE{9541336,
author={Wu, Zhiwei and Yang, Zilin and Yang, Chao and Lin, Jixu and Liu, Yi and Chen, Xin},
journal={Journal of Communications and Networks}, title={Joint deployment and trajectory optimization in UAV-assisted vehicular edge computing networks},
year={2022},
volume={24},
number={1},
pages={47-58},
abstract={As the general mobile edge computing (MEC) scheme cannot adequately handle the emergency communication requirements in vehicular networks, unmanned aerial vehicle (UAV)-assisted vehicular edge computing networks (VECNs) are envisioned as the reliable and cost-efficient paradigm for the mobility and flexibility of UAVs. UAVs can perform as the temporary base stations to provide edge services for road vehicles with heavy traffic. However, it takes a long time and huge energy consumption for the UAV to fly from the stay charging station to the mission areas disorderly. In this paper, we design a pre-dispatch UAV-assisted VECNs system to cope with the demand of vehicles in multiple traffic jams. We propose an optimal UAV flight trajectory algorithm based on the traffic situation awareness. The cloud computing center (CCC) server predicts the real-time traffic conditions, and assigns UAVs to different mission areas periodically. Then, a flight trajectory optimization problem is formulated to minimize the cost of UAVs, while both the UAV flying and turning energy costs are mainly considered. In addition, we propose a deep reinforcement learning(DRL)-based energy efficiency autonomous deployment strategy, to obtain the optimal hovering position of UAV at each assigned mission area. Simulation results demonstrate that our proposed method can obtain an optimal flight path and deployment of UAV with lower energy consumption.},
keywords={Energy consumption;Servers;Task analysis;Turning;Unmanned aerial vehicles;Roads;Edge computing;Deep reinforcement learning;energy efficiency;mobile edge computing;unmanned aerial vehicle relay},
doi={10.23919/JCN.2021.000026},
ISSN={1976-5541},
month={Feb},}
@INPROCEEDINGS{9555767,
author={Chouhan, Avinash and S, Shivaraj and Chutia, Dibyajyoti and Raju, PLN},
booktitle={2019 International Conference on Intelligent Computing and Remote Sensing (ICICRS)}, title={Comparison of tree canopy extraction using Object Based Image Analysis and Deep Learning Technique in UAV images},
year={2019},
volume={},
number={},
pages={1-5},
abstract={Unmanned aerial vehicle captured images is a new method of acquiring very high resolution data. Present days there is a huge need of precise land cover data in various fields, example land use, and natural resource conservation. For extraction of information from imagery various algorithms mostly object based has been used. Using Object Base Image Analysis methods usually achieve good results for segmentation of tree canopy in high spatial resolution aerial images. In this paper we are providing insights of segmentation algorithms used for extraction of tree canopy from very high resolution imagery. We provide detailed comparison of output generated from earlier object based tree canopy extraction algorithm with upcoming deep learning based new techniques.},
keywords={Deep learning;Image segmentation;Image analysis;Unmanned aerial vehicles;Sensors;Data mining;Reliability;Tree canopy;Unmanned Aerial Vehicle (UAV);Remote Sensing;Object Based Image Analysis (OBIA);Segmentation;Deep Learning},
doi={10.1109/ICICRS46726.2019.9555767},
ISSN={},
month={July},}
@INPROCEEDINGS{8567273,
author={Körez, Atakan and Bariş÷i, Necaattin},
booktitle={2018 2nd International Symposium on Multidisciplinary Studies and Innovative Technologies (ISMSIT)}, title={İnsansız Hava Aracı (İHA) Görüntülerindeki Yayaların Faster R-CNN Algoritması ile Otomatik Tespiti},
year={2018},
volume={},
number={},
pages={1-4},
abstract={Drone or Unmanned Aerial Vehicles (UAVs) are now actively used by many different sectors. In particular, the drone who have gained popularity in recent years; From advertising to cargo transportation, various tasks can be undertaken. Detection of objects in unmanned aerial images is often done by the operator using the vehicle. In this study, the Faster R-CNN algorithm, which is used frequently in the object detection application literature, was modified to automate this situation and was used for automatic detection of bounces in images taken by unmanned aerial photographs.},
keywords={Drones;Conferences;Object detection;Computer vision;Unmanned Air Vehicle;Object Detection;Deep Learning;Faster RCNN;Convolutional Neural Networks},
doi={10.1109/ISMSIT.2018.8567273},
ISSN={},
month={Oct},}
@ARTICLE{9460988,
author={Rahnemoonfar, Maryam and Chowdhury, Tashnim and Sarkar, Argho and Varshney, Debvrat and Yari, Masoud and Murphy, Robin Roberson},
journal={IEEE Access}, title={FloodNet: A High Resolution Aerial Imagery Dataset for Post Flood Scene Understanding},
year={2021},
volume={9},
number={},
pages={89644-89654},
abstract={Visual scene understanding is the core task in making any crucial decision in any computer vision system. Although popular computer vision datasets like Cityscapes, MS-COCO, PASCAL provide good benchmarks for several tasks (e.g. image classification, segmentation, object detection), these datasets are hardly suitable for post disaster damage assessments. On the other hand, existing natural disaster datasets include mainly satellite imagery which has low spatial resolution and a high revisit period. Therefore, they do not have a scope to provide quick and efficient damage assessment tasks. Unmanned Aerial Vehicle (UAV) can effortlessly access difficult places during any disaster and collect high resolution imagery that is required for aforementioned tasks of computer vision. To address these issues we present a high resolution UAV imagery, FloodNet, captured after the hurricane Harvey. This dataset demonstrates the post flooded damages of the affected areas. The images are labeled pixel-wise for semantic segmentation task and questions are produced for the task of visual question answering. FloodNet poses several challenges including detection of flooded roads and buildings and distinguishing between natural water and flooded water. With the advancement of deep learning algorithms, we can analyze the impact of any disaster which can make a precise understanding of the affected areas. In this paper, we compare and contrast the performances of baseline methods for image classification, semantic segmentation, and visual question answering on our dataset. FloodNet dataset can be downloaded from here: https://github.com/BinaLab/FloodNet-Supervised_v1.0.},
keywords={Image segmentation;Semantics;Task analysis;Satellites;Computer vision;Image resolution;Buildings;Artificial intelligence;deep learning;hurricane Harvey;image classification;machine learning;natural disaster dataset;remote sensing;semantic segmentation;unmanned aerial vehicle (UAV);visual question answering},
doi={10.1109/ACCESS.2021.3090981},
ISSN={2169-3536},
month={},}
@INPROCEEDINGS{9730961,
author={Chen, Sifan and Yang, Haoran and Zhang, Ang and Chen, Baihe and Shu, Peng and Xiang, Jin and Lin, Chen},
booktitle={2021 3rd International Conference on Machine Learning, Big Data and Business Intelligence (MLBDBI)}, title={UAV Dynamic Tracking Algorithm Based on Deep learning},
year={2021},
volume={},
number={},
pages={482-485},
abstract={In recent years, unmanned aerial vehicle (UAV) has been widely used in target tracking tasks such as security, anti-terrorism, tracking and monitoring because of its wide and flexible perspective. At the same time, deep learning creates new conditions for UAV visual recognition and motion tracking because it has high recognition accuracy and fast recognition speed. This paper presents an UAV dynamic tracking algorithm based on deep learning. The algorithm mainly includes three parts: the PTZ control, relative position calculation and the UAV control. The main work includes: 1. The tracking target is identified through the deep learning network based on YOLOv3, and the PTZ angle is adjusted in real time by using the control method of combining the PID control with the time-delay control to reduce the impact of image transmission delay; 2. The relative position between the UAV and the target is calculated by combining the UAV flight altitude, UAV attitude, PTZ angle and the coordinate of the target in the image. At the same time, the relative position prediction is added to estimate the relative distance between the UAV and the target at the next frame time as a reference value of the UAV speed, so as to improve the dynamic tracking ability; 3. The relative position information is fed back to the flight control function, and the linear velocity of UAV is output by the PID controller. Through the simulation test in Airsim, it is proved that the proposed algorithm can effectively improve the stability and robustness of the UAV tracking system.},
keywords={Deep learning;Target tracking;PI control;Heuristic algorithms;Atmospheric modeling;Autonomous aerial vehicles;Cameras;unmanned aerial vehicle;deep learning;tracking;time-delay control;PID control},
doi={10.1109/MLBDBI54094.2021.00098},
ISSN={},
month={Dec},}
@INPROCEEDINGS{8607668,
author={Won, D. and Park, M.-W. and Chi, S.},
booktitle={2018 IEEE International Conference on Industrial Engineering and Engineering Management (IEEM)}, title={Construction Resource Localization Based on UAV-RFID Platform Using Machine Learning Algorithm},
year={2018},
volume={},
number={},
pages={1086-1090},
abstract={Although location data of construction resources, such as materials, heavy machinery and workers, is one of the most critical keys to understand the context of construction site, most sites still rely on human-oriented observations to localize the resources. As one of techniques for collecting location data, RFID technology has been extensively studied. However, RFID requires multiple readers or a lot of manpower because RFID receiver is fixed or carried by human. It is infeasible in terms of time and cost in complex or large-scale construction sites. The aim of this study is to overcome the limitations of current approaches by proposing a localization method based on UAV-RFID integrated platform. With data from the platform, we applied a machine learning algorithm, k-nearest neighbors, to localize tags. Our method estimates the location of the tag with 94% accuracy. We have demonstrated the feasibility of the UAV-RFID integrated platform for construction site.},
keywords={Global Positioning System;Machine learning algorithms;Receivers;Machine learning;RFID tags;Unmanned aerial vehicles;Unmanned Aerial Vehicle (UAV);Radio Frequency Identification (RFID);Localization;Construction Resource;Machine Learning;k-Nearest Neighbors.},
doi={10.1109/IEEM.2018.8607668},
ISSN={2157-362X},
month={Dec},}
@ARTICLE{9359476,
author={Zhang, Ran and Wang, Miao and Cai, Lin X. and Shen, Xuemin},
journal={IEEE Transactions on Wireless Communications}, title={Learning to Be Proactive: Self-Regulation of UAV Based Networks With UAV and User Dynamics},
year={2021},
volume={20},
number={7},
pages={4406-4419},
abstract={Multi-Unmanned Aerial Vehicle (UAV) control is one of the major research interests in UAV-based networks. Yet few existing works focus on how the network should optimally react when the UAV lineup and user distribution change. In this work, proactive self-regulation (PSR) of UAV-based networks is investigated when one or more UAVs are about to quit or join the network, with considering dynamic user distribution. We target at an optimal UAV trajectory control policy which proactively relocates the UAVs whenever the UAV lineup is about to change, rather than passively dispatches the UAVs after the change. Specifically, a deep reinforcement learning (DRL)-based self-regulation approach is developed to maximize the accumulated user satisfaction (US) score for a certain period within which at least one UAV will quit or join the network. To handle the changed dimension of the state-action space before and after the lineup changes, the state transition is deliberately designed. To accommodate continuous state and action space, an actor-critic based DRL, i.e., deep deterministic policy gradient (DDPG), is applied with better convergence stability. To effectively promote learning exploration around the timing of lineup change, an asynchronous parallel computing (APC) learning structure is proposed. Referred to as PSR-APC, the developed approach is then extended to the case of dynamic user distribution by incorporating time as one of the agent states. Finally, numerical results are presented to demonstrate the convergence and superiority of PSR-APC over a passive reaction method, and its capability in jointly handling the dynamics of both UAV lineup and user distribution.},
keywords={Trajectory;Wireless communication;Vehicle dynamics;Unmanned aerial vehicles;Convergence;Task analysis;Interference;Unmanned aerial vehicle (UAV);machine learning;deep reinforcement learning (DRL);trajectory design;proactive self-regulation},
doi={10.1109/TWC.2021.3058533},
ISSN={1558-2248},
month={July},}
@INPROCEEDINGS{9390913,
author={Jing, Letian and Jia, Xiangdong and Lv, Yaping and Wan, Nini},
booktitle={2021 IEEE 5th Advanced Information Technology, Electronic and Automation Control Conference (IAEAC)}, title={Maximizing the Average Secrecy Rate for UAV-assisted MEC: A DRL Method},
year={2021},
volume={5},
number={},
pages={2514-2518},
abstract={In the unmanned aerial vehicle (UAV)-assisted mobile edge computing (MEC) system where eavesdropper existed, UAV was faced with the problem of secure communication when served users, so this paper proposed a security algorithm based on deep reinforcement learning which enabled UAV to find the optimal flight strategy to maximize the average secrecy rate of serving users. Firstly, the process of maximizing the average secrecy rate was modeled as a Markov decision process (MDP) without transition probability, and states, actions and reward function of UAV were defined. Secondly, UAV used the proposed algorithm to change its position through RL online learning and deep neural network offline training to find the optimal flight strategy in a battery cycle so as to maximize the average secrecy rate. Finally, the proposed algorithm was compared with the traditional algorithms, and the simulation results show that the proposed algorithm can effectively improve the average secrecy rate when UAV is serving users and has faster convergence rate than Q-Learning algorithm.},
keywords={Training;Simulation;Neural networks;Reinforcement learning;Markov processes;Unmanned aerial vehicles;Security;unmanned aerial vehicle;mobile edge computing;secrecy rate;deep reinforcement learning},
doi={10.1109/IAEAC50856.2021.9390913},
ISSN={2689-6621},
month={March},}
@ARTICLE{9397778,
author={Ren, Tao and Niu, Jianwei and Dai, Bin and Liu, Xuefeng and Hu, Zheyuan and Xu, Mingliang and Guizani, Mohsen},
journal={IEEE Internet of Things Journal}, title={Enabling Efficient Scheduling in Large-Scale UAV-Assisted Mobile Edge Computing via Hierarchical Reinforcement Learning},
year={2021},
volume={},
number={},
pages={1-1},
abstract={Due to the high maneuverability and flexibility, unmanned-aerial-vehicles (UAVs) have been considered as a promising paradigm to assist mobile edge computing (MEC) in many scenarios including disaster rescue and field operation. Most existing research focuses on the study of trajectory and computation-offloading scheduling for UAV-assisted MEC in stationary environments, and could face challenges in dynamic environments where the locations of UAVs and mobile devices (MDs) vary significantly. Some latest research attempts to develop scheduling policies for dynamic environments by means of reinforcement learning. However, as these need to explore in high-dimensional state and action space, they may fail to cover in large-scale networks where multiple UAVs serve numerous MDs. To address this challenge, we leverage the idea of ‘divide-and-conquer’ and propose HT3O, a scalable scheduling approach for large-scale UAV-assisted MEC. First, HT3O is built with neural networks via deep reinforcement learning to obtain real-time scheduling policies for MEC in dynamic environments. More importantly, to make HT3O more scalable, we decompose the scheduling problem into two-layered sub-problems and optimize them alternately via hierarchical reinforcement learning. This not only substantially reduces the complexity of each sub-problem, but also improves the convergence efficiency. Experimental results show that HT3O can achieve promising performance improvements over state-of-the-art approaches.},
keywords={Optimization;Processor scheduling;Task analysis;Dynamic scheduling;Reinforcement learning;Computational modeling;Real-time systems;Unmanned aerial vehicle;mobile edge computing;computation offloading;trajectory optimization;hierarchical reinforcement learning.},
doi={10.1109/JIOT.2021.3071531},
ISSN={2327-4662},
month={},}
@INPROCEEDINGS{6490861,
author={Samy, I. and Postlethwaite, I. and Gu, D.-W. and Fan, I. S.},
booktitle={UKACC International Conference on Control 2010}, title={Detection of multiple sensor faults using neural networks- demonstrated on a unmanned air vehicle (UAV) model},
year={2010},
volume={},
number={},
pages={1-7},
abstract={Model-based sensor fault detection, isolation and accommodation (SFDIA) is a direction of development in particular with small UAVs where sensor redundancy may not be an option due to weight, cost and space implications. SFDIA via neural networks (NNs) have been proposed over the years due to their nonlinear structures and online learning capabilities. However few applications have considered multiple sensor faults in fixed-wing UAVs where full autonomy is most needed. In this paper an Extended Minimum Resource Allocating Network (EMRAN) Radial Basis Function (RBF) NN is chosen for modelling purposes due to its ability to adapt well to nonlinear environments while maintaining high computational speeds. After 30 separate SFDIA tests implemented on a 1.6 GHz Pentium processor, the NN-SFDIA scheme detected all but 2 faults and the NN processing time was 97% lower than the flight data sampling time.},
keywords={Sensor analytical redundancy;neural networks;fault detection;unmanned air vehicle},
doi={10.1049/ic.2010.0403},
ISSN={},
month={Sep.},}
@ARTICLE{9679714,
author={Jinqiang, Hu and Husheng, Wu and Renjun, Zhan and Rafik, Menassel and Xuanwu, Zhou},
journal={Journal of Systems Engineering and Electronics}, title={Self-organized search-attack mission planning for UAV swarm based on wolf pack hunting behavior},
year={2021},
volume={32},
number={6},
pages={1463-1476},
abstract={Cooperative search-attack is an important application of unmanned aerial vehicle (UAV) swarm in military field. The coupling between path planning and task allocation, the heterogeneity of UAVs, and the dynamic nature of task environment greatly increase the complexity and difficulty of the UAV swarm cooperative search-attack mission planning problem. Inspired by the collaborative hunting behavior of wolf pack, a distributed self-organizing method for UAV swarm search-attack mission planning is proposed. First, to solve the multi-target search problem in unknown environments, a wolf scouting behavior-inspired cooperative search algorithm for UAV swarm is designed. Second, a distributed self-organizing task allocation algorithm for UAV swarm cooperative attacking of targets is proposed by analyzing the flexible labor division behavior of wolves. By abstracting the UAV as a simple artificial wolf agent, the flexible motion planning and group task coordinating for UAV swarm can be realized by self-organizing. The effectiveness of the proposed method is verified by a set of simulation experiments, the stability and scalability are evaluated, and the integrated solution for the coupled path planning and task allocation problems for the UAV swarm cooperative search-attack task can be well performed.},
keywords={Task analysis;Autonomous aerial vehicles;Search problems;Resource management;Planning;Scalability;Path planning;search-attack mission planning;unmanned aerial vehicle (UAV) swarm;wolf pack;hunting behavior;swarm intelligence;labor division},
doi={10.23919/JSEE.2021.000124},
ISSN={1004-4132},
month={Dec},}
@ARTICLE{9663025,
author={Wu, Jia and Luo, Chunbo and Luo, Yang and Li, Ke},
journal={IEEE Transactions on Cybernetics}, title={Distributed UAV Swarm Formation and Collision Avoidance Strategies Over Fixed and Switching Topologies},
year={2021},
volume={},
number={},
pages={1-11},
abstract={This article proposes a controlling framework for multiple unmanned aerial vehicles (UAVs) to integrate the modes of formation flight and swarm deployment over fixed and switching topologies. Formation strategies enable UAVs to enjoy key collective benefits including reduced energy consumption, but the shape of the formation and each UAV's freedom are significantly restrained. Swarm strategies are thus proposed to maximize each UAV's freedom following simple yet powerful rules. This article investigates the integration and switch between these two strategies, considering the deployment environment factors, such as poor network conditions and unknown and often highly mobile obstacles. We design a distributed formation controller to guide multiple UAVs in orderless states to swiftly reach an intended formation. Inspired by starling birds and similar biological creatures, a distributed collision avoidance controller is proposed to avoid unknown and mobile obstacles. We further illustrated the stability of the controllers over both fixed and switching topologies. The experimental results confirm the effectiveness of the framework.},
keywords={Birds;Collision avoidance;Switches;Topology;Shape;Autonomous aerial vehicles;Network topology;Collision avoidance;formation;swarm intelligence;unmanned aerial vehicle (UAV)},
doi={10.1109/TCYB.2021.3132587},
ISSN={2168-2275},
month={},}
@INPROCEEDINGS{9259868,
author={Böyük, Mustafa and Duvar, Ramazan and Urhan, Oğuzhan},
booktitle={2020 Innovations in Intelligent Systems and Applications Conference (ASYU)}, title={Deep Learning Based Vehicle Detection with Images Taken from Unmanned Air Vehicle},
year={2020},
volume={},
number={},
pages={1-4},
abstract={Especially in recent years, unmanned aerial vehicles (UAV) have been used in many platforms for military, commercial and entertainment purposes. Thanks to high computational graphics cards, many computer vision applications based on deep learning can work in real time on unmanned aerial vehicles. In this study, fast and high-performance object detection algorithms Faster R-CNN, YOLOv3-Tiny and SSD algorithms are used to detect vehicles in image taken from UAVs. Thus, the positions of vehicles driving in traffic are found automatically.},
keywords={Unmanned aerial vehicles;Real-time systems;Object detection;Deep learning;Vehicle detection;Proposals;Graphics processing units;Unmanned air vehicle;deep learning;vehicle detection;Yolov3-Tiny;SSD;Faster R-CNN},
doi={10.1109/ASYU50717.2020.9259868},
ISSN={},
month={Oct},}
@INPROCEEDINGS{9321625,
author={Li, Yibing and Zhang, Sitong and Ye, Fang and Jiang, Tao and Li, Yingsong},
booktitle={2020 IEEE USNC-CNC-URSI North American Radio Science Meeting (Joint with AP-S Symposium)}, title={A UAV Path Planning Method Based on Deep Reinforcement Learning},
year={2020},
volume={},
number={},
pages={93-94},
abstract={The path planning of Unmanned Aerial Vehicle (UAV) is a critical component of rescue operation. As impacted by the continuity of the task space and the high dynamics of the aircraft, conventional approaches cannot find the optimal control strategy. Accordingly, in this study, a deep reinforcement learning (DRL)-based UAV path planning method is proposed, enabling the UAV to complete the path planning in a 3D continuous environment. The deep deterministic policy gradient (DDPG) algorithm is employed to enable UAV to autonomously make decisions. Besides, to avoid obstacles, the concepts of connected area and threat function are proposed and adopted in the reward shaping. Lastly, an environment with static obstacles is built, and the agent is trained using the proposed method. As has been proved by the experiments, the proposed algorithm can fit a range of scenarios.},
keywords={Unmanned aerial vehicles;Task analysis;Reinforcement learning;Vehicle dynamics;Trajectory;Three-dimensional displays;Optimal control;Unmanned aerial vehicle;path planning;deep reinforcement learning;reward shaping},
doi={10.23919/USNC/URSI49741.2020.9321625},
ISSN={},
month={July},}
@INPROCEEDINGS{6954257,
author={Gautam, S Aditya and Verma, Nilmani},
booktitle={2014 International Conference on Data Mining and Intelligent Computing (ICDMIC)}, title={Path planning for unmanned aerial vehicle based on genetic algorithm amp; artificial neural network in 3D},
year={2014},
volume={},
number={},
pages={1-5},
abstract={The planning of path for Unmanned Aerial Vehicle (UAV) is always considered to be a vital task. Path planning for UAV for avoiding the obstacle in its path can be accomplished by finding the solution for an optimization problem. Genetic Algorithm which is a global optimization tool can be of great use to solve the optimization problem for path planning of UAV. Artificial Neural Network (ANN) works well for function fitting quickly and can be used to approximate almost any function. The Genetic Algorithms are good at converging to the globally optimum solution generation by generation. Each generation is expected to be better than its previous generation. Neural Networks work faster than Genetic Algorithms for finding the solution to a given problem but may get converged to local optimum instead of global optimum. In this paper a new method for path planning for UAV to avoid obstacle coming in its path based on the combination of Genetic Algorithms and Artificial Neural Networks has been proposed in which the output generated from the Genetic Algorithms is used to train the network of Artificial Neural Networks. The model for path planning is based on 3D digital map.},
keywords={Genetic algorithms;Artificial neural networks;Sociology;Statistics;Path planning;Radar;Optimization;Unmanned Aerial Vehicle;path planning;Genetic Algorithms;Artificial Neural Networks;Evolutionary Algorithms},
doi={10.1109/ICDMIC.2014.6954257},
ISSN={},
month={Sep.},}
@ARTICLE{9530723,
author={Tian, Jiwei and Wang, Buhong and Guo, Rongxiao and Wang, Zhen and Cao, Kunrui and Wang, Xiaodong},
journal={IEEE Internet of Things Journal}, title={Adversarial Attacks and Defenses for Deep Learning-based Unmanned Aerial Vehicles},
year={2021},
volume={},
number={},
pages={1-1},
abstract={The introduction of deep learning technology can improve the performance of cyber-physical systems (CPSs) in many ways. However, this also brings new security issues. To tackle these challenges, this paper explores the vulnerabilities of deep learning-based unmanned aerial vehicles (UAVs), which are typical CPSs. Although many research works have been reported previously on adversarial attacks of deep learning models, only few of them are concerned about safety-critical CPSs, especially regression models in such systems. In this paper, we analyze the problem of adversarial attacks against deep learning-based UAVs and propose two adversarial attack methods against regression models in UAVs. Experiments demonstrate that the proposed non-targeted and targeted attack methods both can craft imperceptible adversarial images and pose a considerable threat to the navigation and control of UAVs. To address this problem, adversarial training and defensive distillation methods are further investigated and evaluated, increasing the robustness of deep learning models in UAVs. To our knowledge, this is the first study on adversarial attacks and defenses against deep learning-based UAVs, which calls for more attention to the security and safety of such safety-critical applications.},
keywords={Navigation;Internet of Things;Training;Cameras;Security;Deep learning;Task analysis;Adversarial example;adversarial training;defensive distillation;deep learning;unmanned aerial vehicle.},
doi={10.1109/JIOT.2021.3111024},
ISSN={2327-4662},
month={},}
@ARTICLE{9448189,
author={Chang, Huan and Chen, Yicheng and Zhang, Baochang and Doermann, David},
journal={IEEE Transactions on Emerging Topics in Computational Intelligence}, title={Multi-UAV Mobile Edge Computing and Path Planning Platform Based on Reinforcement Learning},
year={2021},
volume={},
number={},
pages={1-10},
abstract={Unmanned Aerial vehicles (UAVs) are widely used as network processors in mobile networks, but more recently, UAVs have been used in Mobile Edge Computing as mobile servers. However, there are significant challenges to use UAVs in complex environments with obstacles and cooperation between UAVs. We introduce a new multi-UAV Mobile Edge Computing platform, which aims to provide better Quality-of-Service and path planning based on reinforcement learning to address these issues. The contributions of our work include: 1) optimizing the quality of service for mobile edge computing and path planning in the same reinforcement learning framework; 2) using a sigmoid-like function to depict the terminal users’ demand to ensure a higher quality of service; 3) applying synthetic considerations of the terminal users’ demand, risk and geometric distance in reinforcement learning reward matrix to ensure the quality of service, risk avoidance, and the cost-savings. Simulations have shown the effectiveness and feasibility of our platform, which can help advance related researches. The source code can be found at https://github.com/bczhangbczhang.},
keywords={Edge computing;Path planning;Quality of service;Planning;Task analysis;Reinforcement learning;Prediction algorithms;Unmanned Aerial Vehicle;Mobile Edge Computing;Path Planning;Reinforcement Learning},
doi={10.1109/TETCI.2021.3083410},
ISSN={2471-285X},
month={},}
@INPROCEEDINGS{8029186,
author={Yao, Haodi and Yu, Qingtao and Xing, Xiaowei and He, Fenghua and Ma, Jie},
booktitle={2017 36th Chinese Control Conference (CCC)}, title={Deep-learning-based moving target detection for unmanned air vehicles},
year={2017},
volume={},
number={},
pages={11459-11463},
abstract={In this paper, a deep learning network is investigated to detect moving targets for a UAV equipped with monocular camera. An algorithm based on fully convolutional network is proposed to obtain the position and moving direction of targets. A Kalman filter is incorporated into the proposed algorithm to increase the accuracy of target position information acquisition. The experimental results show the effectiveness of the proposed algorithm with a relatively low hardware resource consumption.},
keywords={Cameras;Machine learning;Classification algorithms;Robots;Unmanned aerial vehicles;Image color analysis;Kalman filters;deep learning;fully convolutional network;Kalman filter;unmanned air vehicle},
doi={10.23919/ChiCC.2017.8029186},
ISSN={1934-1768},
month={July},}
@ARTICLE{9583941,
author={Cai, Ting and Yang, Zhihua and Chen, Yufei and Chen, Wuhui and Zheng, Zibin and Yu, Yang and Dai, Hong-Ning},
journal={IEEE Transactions on Network Science and Engineering}, title={Cooperative Data Sensing and Computation Offloading in UAV-assisted Crowdsensing with Multi-agent Deep Reinforcement Learning},
year={2021},
volume={},
number={},
pages={1-1},
abstract={Unmanned aerial vehicles (UAVs) can be leveraged in mobile crowdsensing (MCS) to conduct sensing tasks at remote or rural areas through computation offloading and data sensing. Nonetheless, both computation offloading and data sensing have been separately investigated in most existing studies. In this paper, we propose a novel cooperative data sensing and computation offloading scheme for the UAV-assisted MCS system with an aim to maximize the overall system utility. First, a multi-objective function is formulated to evaluate the system utility by jointly considering flight direction, flight distance,task offloading proportion, and server offload selection for each UAV. Then, the problem is modeled as a partially observable Markov decision process and a multi-agent actor-critic algorithm framework is proposed to train the strategy network for UAVs. Due to high delay and energy cost caused by communications among multiple agents, we leverage the critic network to model other agents and to seek equilibrium among all UAVs rather than adopting the explicit channel for information exchange. Furthermore, we introduce attention mechanism to enhance the convergence performance in model training phases. Finally, experimental results demonstrate the effectiveness and applicability of our scheme. Compared with baselines, our algorithm shows significant advantages in convergence performance and system utility.},
keywords={Sensors;Task analysis;Servers;Computational modeling;Optimization;Costs;Heuristic algorithms;Mobile crowdsensing (MCS);unmanned aerial vehicle (UAV);data sensing;computation offloading;deep reinforcement learning (DRL)},
doi={10.1109/TNSE.2021.3121690},
ISSN={2327-4697},
month={},}
@ARTICLE{9743553,
author={Zhang, Tingting and Chai, Lai and Wang, Shenshen and Jin, Junyu and Liu, Xiaofan and Song, Aiguo and Lan, Yushi},
journal={IEEE Transactions on Reliability}, title={Improving Autonomous Behavior Strategy Learning in an Unmanned Swarm System Through Knowledge Enhancement},
year={2022},
volume={},
number={},
pages={1-12},
abstract={An unmanned swarm system (UWS) is a multiagent system that can fulfill task requirements through autonomous and cooperative behavior strategy learning. However, learning instability is inevitable in a dynamic mission setting, as the agents continuously adapt to an evolving mission objective. This article proposes several knowledge enhancement mechanisms to improve the training efficiency and learning stability of a UWS in a confined-space confrontation mission. Specifically, a punishment for transcending action-space boundary and a reward for satisfying agent space-time distance constraints are introduced as training reward enhancements. Meanwhile, experience sharing among agents is optimized for unanimous behavior. We apply these novel mechanisms to several representative single-agent and multiagent reinforcement learning algorithms and verify their effectiveness on our proprietary, SwarmFlow, simulation system. Simulations show that the proposed mechanisms improve existing algorithms’ convergence speed and performance stability. The increase is more prominent for multiagent reinforcement learning algorithms than single-agent algorithms where the convergence time is halved, and the mission success rates increase by 3–4%.},
keywords={Training;Task analysis;Heuristic algorithms;Reinforcement learning;Convergence;Convolutional neural networks;Complexity theory;Behavioral decision;confrontation mission;multiagent reinforcement learning;reward mechanism;SwarmFlow;unmanned aerial vehicle (UAV);unmanned swarm system (UWS)},
doi={10.1109/TR.2022.3158279},
ISSN={1558-1721},
month={},}
@ARTICLE{8859289,
author={Borup, Kasper Trolle and Fossen, Thor Inge and Johansen, Tor Arne},
journal={IEEE Transactions on Aerospace and Electronic Systems}, title={A Machine Learning Approach for Estimating Air Data Parameters of Small Fixed-Wing UAVs Using Distributed Pressure Sensors},
year={2020},
volume={56},
number={3},
pages={2157-2173},
abstract={This paper presents a method for estimating the air data parameters for a small fixed-wing, unmanned aerial vehicle (UAV) using an arrangement of low-cost Micro-electromechinal systems (MEMS)-based pressure sensors embedded in the surface of the UAV. The pressure measurements are used in a machine learning (ML) model to estimate the angle of attack, sideslip angle, and airspeed. Two ML algorithms based on artificial neural networks (NNs) and linear regression (LR) are implemented, tested, and assessed using data collected from wind tunnel experiments and a flight test, and the results are compared to a benchmark flight test. Training the ML algorithms using wind tunnel data was found to introduce several potential error sources that need to be addressed in order to provide accurate estimation on the benchmark flight test, whereas training the algorithms using flight data provides lower estimation RMSE values. The performance of the NN structures has been found to slightly outperform the LR algorithms in estimation accuracy. Finally, results from using different sensor configurations and a pseudo-Reynolds number are presented in an effort to evaluate the influence of sensor number and placement on the accuracy of the method.},
keywords={Atmospheric modeling;Aircraft;Pressure measurement;Pressure sensors;Unmanned aerial vehicles;Aerodynamics;Wind tunnels;Air data parameters;airspeed;angle of attack (AOA);fixed-wing;flight tests;linear regression (LR);machine learning (ML);neural networks (NNs);pressure sensors;sideslip angle (SSA);unmanned aerial vehicle (UAV);wind tunnel experiments},
doi={10.1109/TAES.2019.2945383},
ISSN={1557-9603},
month={June},}
@ARTICLE{9190025,
author={Al-Hilo, Ahmed and Samir, Moataz and Assi, Chadi and Sharafeddine, Sanaa and Ebrahimi, Dariush},
journal={IEEE Transactions on Intelligent Transportation Systems}, title={UAV-Assisted Content Delivery in Intelligent Transportation Systems-Joint Trajectory Planning and Cache Management},
year={2021},
volume={22},
number={8},
pages={5155-5167},
abstract={Unmanned Aerial Vehicles (UAVs) are gaining growing interests due to the paramount roles they play, particularly these days, in enabling new services that help modernize our transportation, supply chain, search and rescue, among others. They are capable of positively influencing wireless systems through enabling and fostering emerging technologies such as autonomous driving, vertical industries, virtual reality and so many others. The Internet of Vehicles is a prime sector benefiting from the services offered by future cellular systems in general and UAVs in particular, and this paper considers the problem of content delivery to vehicles on road segments with either overloaded or no available communication infrastructure. Incoming vehicles demand service from a library of contents that is partially cached at the UAV; the content of the library is also assumed to change as new vehicles carrying more popular contents arrive. Each inbound vehicle makes a request and the UAV decides on its best trajectory to provide service while maximizing a certain operational utility. Given the energy limitation at the UAV, we seek an energy efficient solution. Hence, our problem consists of jointly finding caching decisions, UAV trajectory and radio resource allocation which is formulated mathematically as a Mixed Integer Non-Linear Problem (MINLP). However, owing to uncertainties in the environment (e.g., random arrival of vehicles, their requests for contents and their existing contents), it is often hard and impractical to solve using standard optimization techniques. To this end, we formulate our problem as a Markov Decision Process (MDP) and we resort to tools such as Proximal Policy Optimization (PPO), a very promising Reinforcement Learning method, along with a set of crafted algorithms to solve our problem. Finally, we conduct simulation-based experiments to analyze and demonstrate the superiority of our solution approach compared with four counterparts and baseline schemes.},
keywords={Trajectory;Unmanned aerial vehicles;Wireless communication;Libraries;Resource management;Delays;Unmanned aerial vehicle (UAV);UAVs’ trajectories;resource allocation;Deep Reinforcement Learning;Vehicular Ad-hoc Networks (VANETs)},
doi={10.1109/TITS.2020.3020220},
ISSN={1558-0016},
month={Aug},}
@INPROCEEDINGS{9559106,
author={Benincasa, Giancarlo and Leitgeb, Erich and Kainrath, Klaus and Ivanov, Hristo},
booktitle={2021 International Conference on Software, Telecommunications and Computer Networks (SoftCOM)}, title={Using Feedforward Neural Networks for Parameter Modeling of a 4G Link for Unmanned Aerial Vehicles},
year={2021},
volume={},
number={},
pages={1-5},
abstract={A prediction of link parameters based on positional information contributes to a safe operation of Unmanned Aerial Vehicles (UAVs). For logistical and economical reasons, it makes sense to establish the wireless link via the fourth generation mobile standard Long Term Evolution (LTE) as it offers an already existing and stable infrastructure. The usual non line of sight (NLOS) connection in such a scenario poses challenges in parameter modeling, for which artificial neural networks are shown to be a suitable solution in this paper. The connection quality between transmitter station and UAV is mainly described by the parameters Reference Signal Received Power (RSRP) and Reference Signal Received Quality (RSRQ), which are tried to be predicted via an Artificial Neural Network (ANN) in this work. This approach takes the UAVs position (either Cartesian or polar coordinates) as input and maps them to the respective parameter.},
keywords={Wireless communication;Wireless sensor networks;Radio transmitters;Artificial neural networks;Unmanned aerial vehicles;Software;Telecommunications;UAV;BVLOS;mobile radio;machine learning;neural networks;deep learning},
doi={10.23919/SoftCOM52868.2021.9559106},
ISSN={1847-358X},
month={Sep.},}
@ARTICLE{9475535,
author={Yin, Sixing and Yu, F. Richard},
journal={IEEE Internet of Things Journal}, title={Resource Allocation and Trajectory Design in UAV-Aided Cellular Networks Based on Multiagent Reinforcement Learning},
year={2022},
volume={9},
number={4},
pages={2933-2943},
abstract={In this article, we focus on a downlink cellular network, where multiple unmanned aerial vehicles (UAVs) serve as aerial base stations for ground users through frequency-division multiple access (FDMA). With user locations and channel parameters inaccessible, the UAVs coordinate to make a decision on resource allocation and trajectory design in a decentralized way. Aiming at optimizing both overall and fairness throughput, we model resource allocation and trajectory design as a decentralized partially observable Markov decision process (Dec-POMDP) and propose multiagent reinforcement learning (RL) as a solution. Specifically, we use parameterized deep $Q$ -network (P-DQN) for the action space comprising both discrete and continuous actions and the QMIX framework is leveraged to aggregate each UAV’s local critics. For fairness throughput optimization, we introduce an entropy-like fairness indicator to the reward to make the total return decomposable. In addition, we further propose a novel distributed learning framework for overall throughput optimization such that each UAV can contribute its local gradient, and model training can be implemented in parallel without need of observation data sharing among the UAVs. Simulation results show that the proposed multiagent RL approach as well as the distributed learning framework are efficient in model training and present acceptable performance close to that achieved by deterministic optimization, which relies on convention optimization techniques with user locations and channel parameters explicitly known beforehand. For fairness throughput optimization, we also show that ground users achieve individual throughputs close to each other, which verifies the effectiveness of the proposed fairness indicator as the reward definition in the RL framework.},
keywords={Throughput;Optimization;Resource management;Trajectory;Reinforcement learning;Downlink;Base stations;Distributed reinforcement learning (RL);multiagent reinforcement learning;resource allocation;trajectory design;unmanned aerial vehicle (UAV)-aided wireless communications},
doi={10.1109/JIOT.2021.3094651},
ISSN={2327-4662},
month={Feb},}
@INPROCEEDINGS{8951624,
author={Liang, Wei-Che and Yang, You-Jei and Chao, Chih-Min},
booktitle={2019 Seventh International Symposium on Computing and Networking Workshops (CANDARW)}, title={Low-Cost Weed Identification System Using Drones},
year={2019},
volume={},
number={},
pages={260-263},
abstract={Weeds compete with crops for resources such as light, nutrients, water and space. When mature, weeds can produce thousands to hundreds of thousands of seeds that can survive for a long time and posing a great threat to crops. The best way to avoid weed threats is to remove weeds before they bloom such that the chances of weed seeds falling into the soil can be reduced. Most existing drone-based weeds identification methods use additional equipments to enhance the identification ability. In addition to increasing the cost, such solutions also increase power consumption and load burden of drones. In this paper, we propose a low-cost Weed Identification System (WIS) using RGB images taken by drones as training data and applying Convolutional Neural Networks (CNN) to build the identification model. The result of the WIS can be used as a reference for agriculture researchers and can also be used to inform farmers to take necessary reactions. The WIS identifies weeds with an accuracy of up to 98.8%. Compared to other high-cost methods, the WIS does achieve similar identification accuracy at low cost.},
keywords={Convolutional Neural Networks (CNN), Weed Detection, Unmanned Aerial Vehicle (UAV), Histogram Equalization, Drone, Farm},
doi={10.1109/CANDARW.2019.00052},
ISSN={},
month={Nov},}
@INPROCEEDINGS{9327752,
author={Fan, Jiaxuan and Wang, Zhenya and Ren, Jinlei and Lu, Ying and Liu, Yiheng},
booktitle={2020 Chinese Automation Congress (CAC)}, title={UAV online path planning technology based on deep reinforcement learning},
year={2020},
volume={},
number={},
pages={5382-5386},
abstract={This paper proposes a method for planning three-dimensional path for unmanned aerial vehicle (UAV) in complex airspace based on interfered fluid dynamical system (IFDS) and deep reinforcement learning. Firstly, the model of unmanned aerial vehicle under various constraints and the mathematical expression of threat zone are established. Secondly, in order to solve the problems of slow calculation speed and difficult to make the global optimal solution existed at present, an intelligent 3D path planning method on the basis of IFDS is proposed, and deep reinforcement learning is used to solve the coefficient of IFDS. The simulation results show that the path planned by the proposed method can avoid the threat zone effectively, meanwhile, the path is smooth, suitable and fuel saving for UAV.},
keywords={Unmanned aerial vehicles;Path planning;Planning;Reinforcement learning;Atmospheric modeling;Mathematical model;Research and development;path planning;interfered fluid dynamical system (IFDS);unmanned aerial vehicle (UAV);deep reinforcement learning;Twin Delayed Deep Deterministic Policy Gradient (TD3)},
doi={10.1109/CAC51589.2020.9327752},
ISSN={2688-0938},
month={Nov},}
@ARTICLE{9462495,
author={Palossi, Daniele and Zimmerman, Nicky and Burrello, Alessio and Conti, Francesco and Müller, Hanna and Gambardella, Luca Maria and Benini, Luca and Giusti, Alessandro and Guzzi, Jérôme},
journal={IEEE Internet of Things Journal}, title={Fully Onboard AI-Powered Human-Drone Pose Estimation on Ultralow-Power Autonomous Flying Nano-UAVs},
year={2022},
volume={9},
number={3},
pages={1913-1929},
abstract={Many emerging applications of nano-sized unmanned aerial vehicles (UAVs), with a few cm2 form-factor, revolve around safely interacting with humans in complex scenarios, for example, monitoring their activities or looking after people needing care. Such sophisticated autonomous functionality must be achieved while dealing with severe constraints in payload, battery, and power budget (~100mW). In this work, we attack a complex task going from perception to control: to estimate and maintain the nano-UAV’s relative 3-D pose with respect to a person while they freely move in the environment—a task that, to the best of our knowledge, has never previously been targeted with fully onboard computation on a nano-sized UAV. Our approach is centered around a novel vision-based deep neural network (DNN), called Frontnet, designed for deployment on top of a parallel ultra-low power (PULP) processor aboard a nano-UAV. We present a vertically integrated approach starting from the DNN model design, training, and dataset augmentation down to 8-bit quantization and deployment in-field. PULP-Frontnet can operate in real-time (up to 135 frame/s), consuming less than 87 mW for processing at peak throughput and down to 0.43 mJ/frame in the most energy-efficient operating point. Field experiments demonstrate a closed-loop top-notch autonomous navigation capability, with a tiny 27-g Crazyflie 2.1 nano-UAV. Compared against an ideal sensing setup, onboard pose inference yields excellent drone behavior in terms of median absolute errors, such as positional (onboard: 41cm, ideal: 26 cm) and angular (onboard: 3.7°, ideal: 4.1°). We publicly release videos and the source code of our work.},
keywords={Task analysis;Internet of Things;Robots;Computational modeling;Aerospace electronics;Drones;Aircraft;Artificial intelligence;autonomous unmanned aerial vehicle (UAV);convolutional neural networks;nano-UAV;ultra-low-power},
doi={10.1109/JIOT.2021.3091643},
ISSN={2327-4662},
month={Feb},}
@ARTICLE{8755391,
author={Goudos, Sotirios K. and Athanasiadou, Georgia},
journal={IEEE Antennas and Wireless Propagation Letters}, title={Application of an Ensemble Method to UAV Power Modeling for Cellular Communications},
year={2019},
volume={18},
number={11},
pages={2340-2344},
abstract={In this letter, we apply ensemble learning methods for the prediction of the ground (cellular base station) to air (flying node) received signal strength (RSS) at different heights, for future mobile communications. We model the RSS using different ensemble methods. Moreover, we propose a new ensemble method that combines results from five different methods. The proposed method also uses a recently introduced evolutionary algorithm, the Salp Swarm Algorithm, for weight optimization. The proposed method outperforms all the other methods and common ensemble methods. In this context, the produced results are compared to measurements using representative performance indices and exhibit satisfactory accuracy.},
keywords={Bagging;Sociology;Statistics;Machine learning;Training;Predictive models;Learning systems;Bagging;boosting;ensemble learning;machine learning;mobile communications;unmanned aerial vehicle (UAV)},
doi={10.1109/LAWP.2019.2926784},
ISSN={1548-5757},
month={Nov},}
@ARTICLE{9574645,
author={Tao, Ye and Zongyang, Zhao and Jun, Zhang and Xinghua, Chai and Fuqiang, Zhou},
journal={Journal of Systems Engineering and Electronics}, title={Low-altitude small-sized object detection using lightweight feature-enhanced convolutional neural network},
year={2021},
volume={32},
number={4},
pages={841-853},
abstract={Unauthorized operations referred to as "black flights" of unmanned aerial vehicles (UAVs) pose a significant danger to public safety, and existing low-attitude object detection algorithms encounter difficulties in balancing detection precision and speed. Additionally, their accuracy is insufficient, particularly for small objects in complex environments. To solve these problems, we propose a lightweight feature-enhanced convolutional neural network able to perform detection with high precision detection for low-attitude flying objects in real time to provide guidance information to suppress black-flying UAVs. The proposed network consists of three modules. A lightweight and stable feature extraction module is used to reduce the computational load and stably extract more low-level feature, an enhanced feature processing module significantly improves the feature extraction ability of the model, and an accurate detection module integrates low-level and advanced features to improve the multiscale detection accuracy in complex environments, particularly for small objects. The proposed method achieves a detection speed of 147 frames per second (FPS) and a mean average precision (mAP) of 90.97% for a dataset composed of flying objects, indicating its potential for low-altitude object detection. Furthermore, evaluation results based on microsoft common objects in context (MS COCO) indicate that the proposed method is also applicable to object detection in general.},
keywords={Feature extraction;Object detection;Unmanned aerial vehicles;Safety;Real-time systems;Neural networks;Load modeling;unmanned aerial vehicle (UAV);deep learning;lightweight network;object detection;low-attitude},
doi={10.23919/JSEE.2021.000073},
ISSN={1004-4132},
month={Aug},}
@INPROCEEDINGS{9573995,
author={Koundinya, Poluri Nikhil and Sanjukumar, NT and Rajalakshmi, P},
booktitle={2021 IEEE 4th International Conference on Computing, Power and Communication Technologies (GUCON)}, title={A Comparative analysis of Algorithms for Pedestrian Tracking using Drone Vision},
year={2021},
volume={},
number={},
pages={1-6},
abstract={In recent years, there has been an upsurge in the use of drones for various applications such as intelligent transportation, smart agriculture, military, product delivery, etc. With the advancement of high computational edge devices which can support Machine Learning and Deep Learning algorithms, various functions such as object detection and object tracking can be performed in real-time. Though there are many tracking algorithms available for object tracking, there is always a tradeoff between accuracy and their run-time. Executing computationally expensive algorithms is largely bottle-necked by hardware constraints. This paper has compared different object tracking algorithms (both conventional and Deep learning-based) based on tracking accuracy, speed of tracking, and computational complexity of each algorithm. The comparison is based on the accuracy of detection and tracking of an object at the beginning, end, or time of any occlusion scenario in the drone's video.},
keywords={Performance evaluation;Machine learning algorithms;Military computing;Image edge detection;Transportation;Object detection;Hardware;UAV(Unmanned Aerial vehicle);Deep Learning;Object detection;Object tracking},
doi={10.1109/GUCON50781.2021.9573995},
ISSN={},
month={Sep.},}
@INPROCEEDINGS{8390528,
author={Heng, Yang and Tao, Guo and Ping, Shen and Fengxiang, Chen and Wei, Wang and Xiaowei, Liu},
booktitle={2017 2nd International Conference on Power and Renewable Energy (ICPRE)}, title={Anti-vibration hammer detection in UAV image},
year={2017},
volume={},
number={},
pages={204-207},
abstract={Anti-vibration hammer is a key component in the power power line to prevent vibration of power line for a long time, resulting in power line damage, broken and other hazards. Therefore, it is important to accurately locate the position of the anti-vibration hammer in an image for the subsequent judgment, repair or replacement work. However, the traditional anti-vibration hammer positioning and identification is time-consuming, costly and inefficient. An accurate and efficient method is proposed to detect anti-vibrations in aerial images. This method use deep learning to learn insulators by the convolution neural network, and identify and locate the anti-vibrations in aerial images. The proposed algorithm is tested on lots of aerial images and experimental results show the proposed algorithm detected anti-vibration successfully and efficiently. It is promising to significantly facilitate the visual inspection and automatic identification of anti-vibration in aerial images.},
keywords={Convolution;Feature extraction;Inspection;Unmanned aerial vehicles;Training;Vibrations;Machine learning;anti-vibration hammer;defect detection;R-CNN;unmanned aerial vehicle (UAV);inspection;deep learning},
doi={10.1109/ICPRE.2017.8390528},
ISSN={},
month={Sep.},}
@INPROCEEDINGS{9324182,
author={Mou, Lichao and Hua, Yuansheng and Jin, Pu and Zhu, Xiao Xiang},
booktitle={IGARSS 2020 - 2020 IEEE International Geoscience and Remote Sensing Symposium}, title={Event and Activity Recognition in Aerial Videos Using Deep Neural Networks and a New Dataset},
year={2020},
volume={},
number={},
pages={952-955},
abstract={Unmanned aerial vehicles (UAVs) are now widespread available. Yet the more UAVs there are in the skies, the more video data they create. It is unrealistic for humans to screen such big data and understand their contents. Hence methodological research on UAV video content understanding is of great importance. In this paper, we introduce a novel task of event recognition in unconstrained aerial videos in the remote sensing community and present a dataset for this task. Organized in a rich semantic taxonomy, the proposed dataset covers a wide range of events involving diverse environments and scales. We report results of plenty of deep networks in two ways: single-frame classification and video classification. The dataset and trained models can be downloaded from https://1cmou.github.io/ERA_Dataset/.},
keywords={Videos;Sports;Terrain factors;Training;Unmanned aerial vehicles;Three-dimensional displays;Remote sensing;Unmanned aerial vehicle (UAV) video;deep learning;event recognition;activity recognition},
doi={10.1109/IGARSS39084.2020.9324182},
ISSN={2153-7003},
month={Sep.},}
@ARTICLE{9200475,
author={Chen, Ching-Ju and Huang, Ya-Yu and Li, Yuan-Shuo and Chang, Chuan-Yu and Huang, Yueh-Min},
journal={IEEE Access}, title={An AIoT Based Smart Agricultural System for Pests Detection},
year={2020},
volume={8},
number={},
pages={180750-180761},
abstract={In this study, artificial intelligence and image recognition technologies are combined with environmental sensors and the Internet of Things (IoT) for pest identification. Real-time agricultural meteorology and pest identification systems on mobile applications are evaluated based on intelligent pest identification and environmental IoT data. We combined the current mature AIoT technology and deep learning and applied it to smart agriculture. We used deep learning YOLOv3 for image recognition to obtain the location of Tessaratoma papillosa and analyze the environmental information from weather stations through Long Short-Term Memory (LSTM) to predict the occurrence of pests. The experimental results showed that the pest identification accuracy reached 90%. Precise positioning can effectively reduce the amount of pesticides used and reduce pesticide damage to the soil. The current research provides the location of the pest and the extent of the pests to farmers can accurately use pesticide application at a precise time and place and thus reduce the agricultural workforce required for timely pest control, thus achieving the goal of smart agriculture. The proposed system notifies farmers of the presence of different pests before they start multiplying in large numbers. It improves overall agricultural economic value by providing appropriate pest control methods that decrease crop losses and reduce the environmental damage caused by the excessive usage of pesticides.},
keywords={Agriculture;Machine learning;Image recognition;Feature extraction;Training;Detectors;Deep learning;YOLOv3;pests and diseases;smart agriculture;unmanned aerial vehicle (UAV);artificial intelligence (AI);Internet of Things (IoT);the artificial Intelligence of Things (AIoT)},
doi={10.1109/ACCESS.2020.3024891},
ISSN={2169-3536},
month={},}
@INPROCEEDINGS{8939564,
author={Hassan, Syed Ali and Rahim, Tariq and Shin, Soo Young},
booktitle={2019 International Conference on Information and Communication Technology Convergence (ICTC)}, title={Real-time UAV Detection based on Deep Learning Network},
year={2019},
volume={},
number={},
pages={630-632},
abstract={This paper presents deep learning-based YOLO (You only look once), for the detection of an unmanned aerial vehicle (UAV). In common practice, the creation of own data set is an extensive and hectic task, that takes a long time because it requires proper resolution images from different angles. These issues make the data set creation an important task. Implementation of YOLOv2 and YOLOv3 is done on the own created data set for the real-time UAV's detection and to benchmark the performance of both models in terms of mean average precision (MAP) and accuracy. For the specifically created data set made, YOLOv3 is outperforming YOLOv2 both in MAP and accuracy.},
keywords={Deep learning;Unmanned aerial vehicles;Training;Real-time systems;Data models;Object detection;Feature extraction;Deep learning;Object Detection;Unmanned Aerial Vehicle;YOLO;YOLOv3},
doi={10.1109/ICTC46691.2019.8939564},
ISSN={2162-1233},
month={Oct},}
@ARTICLE{9456858,
author={Arafat, Muhammad Yeasir and Moh, Sangman},
journal={IEEE Internet of Things Journal}, title={A Q-Learning-Based Topology-Aware Routing Protocol for Flying Ad Hoc Networks},
year={2022},
volume={9},
number={3},
pages={1985-2000},
abstract={Flying ad hoc networks (FANETs) have emanated over the last few years for numerous civil and military applications. Owing to underlying attributes, such as a dynamic topology, node mobility in 3-D space, and the limited energy of unmanned aerial vehicles (UAVs), a routing protocol for FANETs is challenging to design. Exiting topology-based routing is unsuitable for highly dynamic FANETs. Location-based routing protocols can be preferred for FANETs owing to their scalability, but are based on one-hop neighbor information and do not contemplate the reachability of further appropriate nodes for forwarding. Owing to the rapid mobility of UAVs, the topology frequently changes; thus, some route entries in the routing table can become invalid and the next-hop nodes may be unavailable before a timeout. That is, the routing decision based on one-hop neighbors cannot assure a successful delivery. In this study, we propose a novel $Q$ -learning-based topology-aware routing (QTAR) protocol for FANETs to provide reliable combinations between the source and destination. The proposed QTAR improves the routing decision by considering two-hop neighbor nodes, extending the local view of the network topology. With the ${Q}$ -learning technique, QTAR adaptively adjusts the routing decision according to the network condition. Our simulation results reveal that QTAR outstrips the existing routing protocols in respect of various performance metrics under distinct scenarios.},
keywords={Routing;Routing protocols;Topology;Delays;Network topology;Drones;Vehicle dynamics;Drone ad hoc network;flying ad hoc network (FANET);machine learning;Q-learning;reinforcement learning;routing;unmanned aerial vehicle (UAV) network;UAV network},
doi={10.1109/JIOT.2021.3089759},
ISSN={2327-4662},
month={Feb},}
@INPROCEEDINGS{9200107,
author={Karmokar, Alokita and Jani, Nikhil and Kalla, Anushka and Harlalka, Harsh and Sonar, Poonam},
booktitle={2020 International Conference on Computational Performance Evaluation (ComPE)}, title={Inspection of Concrete Structures by a Computer Vision Technique and an Unmanned Aerial Vehicle},
year={2020},
volume={},
number={},
pages={338-343},
abstract={We have proposed a visual inspection technique for concrete structures using deep learning and a hardware ecosystem, an Unmanned Aerial Vehicle (UAV). The UAV is a quadcopter that can fly to unreachable sections of a site which consists of a camera that captures images of the concrete surfaces via a mobile device and feed the real time images in the CNN model. The images taken from such remote locations may contain different types of surfaces, shadowed regions and surfaces with holes. The cracks are properly detected by the CNN `AlexNet' algorithm and masking with sliding window technique in such conditions due to variation in the image data set. The experimental results were simulated on a standard online data set of 40,000 images of Mendeley Data which is freely available and 3000 images have been chosen from the entire data set for this method. The classes have been divided into 2 categories of `crack' and `no crack' for the proposed method's data set. There are 1050 training images and 450 testing images for each category. Experimental results were achieved on Google Colab cloud service using Python Tensorflow API (Application Programming Interface). The proposed `AlexNet' CNN algorithm achieves 98.4 % accuracy and the model is deployed to a masking technique with sliding window to detect cracks in a 3008×2000 pixel resolution image by breaking the image into 227×227 pixel resolution image patches. The experimental results have proved that the proposed method handles noisy background such as cracks with shadows and stains, cracks on rusty and rough surfaces and minor dimension cracks with good efficiency.},
keywords={Drones;Testing;Feature extraction;Inspection;Communications technology;Machine Learning;Deep Learning;Computer Vision;Convolutional Neural Network;AlexNet;Unmanned Aerial Vehicle(UAV);Image Processing;Drone;Crack Detection;Construction},
doi={10.1109/ComPE49325.2020.9200107},
ISSN={},
month={July},}
@INPROCEEDINGS{9377082,
author={Sharma, Chiranjeev and Isha, Isha and Vashisht, Vasudha},
booktitle={2021 11th International Conference on Cloud Computing, Data Science Engineering (Confluence)}, title={Water Quality Estimation using Computer Vision in UAV},
year={2021},
volume={},
number={},
pages={448-453},
abstract={The color change of water in a water body is often a tell - tale sign of its health. To counter the sources of water pollution an Unmanned Aerial Vehicle is deployed over a water body which reports back any discrepancies by channeling the feed through Computer Vision based model. This allows for rapid steps to be taken by the Concerned Authorities to mitigate the current situation. Algae formation, floating impurities and color change of the water body are the scope of the project and each of these are detected with an independent Machine Learning Models. The UAV communicates and sends results based on the accuracy of these models.},
keywords={Computer vision;Image color analysis;Computational modeling;Water pollution;Unmanned aerial vehicles;Sensors;Water resources;Deep learning;Computer vision Remote sensing;Water pollution;Monitoring;Image resolution;Surface contamination Unmanned Aerial Vehicle (UAV);Remote Sensing;Water pollution Investigation;decision-support system;Sensing;Floating;UAV imaging;participatory sensing},
doi={10.1109/Confluence51648.2021.9377082},
ISSN={},
month={Jan},}
@ARTICLE{8871183,
author={Zhu, Shichao and Gui, Lin and Cheng, Nan and Sun, Fei and Zhang, Qi},
journal={IEEE Internet of Things Journal}, title={Joint Design of Access Point Selection and Path Planning for UAV-Assisted Cellular Networks},
year={2020},
volume={7},
number={1},
pages={220-233},
abstract={Unmanned aerial vehicle (UAV)-assisted communication is envisioned as a potential solution to the data traffic explosion in the massive machine-type communications (mMTC) scenario. In this article, we investigate the UAV-assisted cellular networks, where a UAV acts as a flying relay to offload part of the data traffic from the overloaded cell to another. We utilize the practical spatial distribution of data traffic and a convincing air-to-ground channel model. The quality of service (QoS) is defined as a UAV utility function which is designed based on a packet loss ratio (PLR)-related users' cost function to represent the performance improvements brought by the UAV. We formulate a joint optimization problem to maximize the UAV utility function and then decompose it into the subproblems about the access point selection and the UAV path planning, which influence the PLR by influencing the packet collision rate and channel state. Since the access point selection subproblem is NP-hard, a game-theory-based distributed algorithm is proposed, instructing the users to select the base station (BS) or the UAV as the access point autonomously. To achieve the most superior channel state, we solve the UAV path planning subproblem by a deep reinforcement learning (DRL)-based approach, instructing the UAV to take the optimal action in each position. The simulation results show that the proposed access point selection scheme can significantly reduce the average cost of users and the proposed UAV path planning method can achieve a path with smaller average channel pathloss compared with other approaches.},
keywords={Cellular networks;Quality of service;Resource management;Trajectory;Internet of Things;Unmanned aerial vehicles;Access point selection;deep reinforcement learning (DRL);game theory;path planning;quality of service (QoS);unmanned aerial vehicle (UAV)},
doi={10.1109/JIOT.2019.2947718},
ISSN={2327-4662},
month={Jan},}
@ARTICLE{9321340,
author={Fu, Shu and Tang, Yujie and Wu, Yuan and Zhang, Ning and Gu, Huaxi and Chen, Chen and Liu, Min},
journal={IEEE Internet of Things Journal}, title={Energy-Efficient UAV-Enabled Data Collection via Wireless Charging: A Reinforcement Learning Approach},
year={2021},
volume={8},
number={12},
pages={10209-10219},
abstract={In this article, we study the application of unmanned aerial vehicle (UAV) for data collection with wireless charging, which is crucial for providing seamless coverage and improving system performance in the next-generation wireless networks. To this end, we propose a reinforcement learning-based approach to plan the route of UAV to collect sensor data from sensor devices scattered in the physical environment. Specifically, the physical environment is divided into multiple grids, where one spot for UAV hovering as well as the wireless charging of UAV is located at the center of each grid. Each grid has a spot for the UAV to hover, and moreover, there is a wireless charger at the center of each grid, which can provide wireless charging to UAV when it is hovering in the grid. When the UAV lacks energy, it can be charged by the wireless charger at the spot. By taking into account the collected data amount as well as the energy consumption, we formulate the problem of data collection with UAV as a Markov decision problem, and exploit Q-learning to find the optimal policy. In particular, we design the reward function considering the energy efficiency of UAV flight and data collection, based on which Q-table is updated for guiding the route of UAV. Through extensive simulation results, we verify that our proposed reward function can achieve a better performance in terms of the average throughput, delay of data collection, as well as the energy efficiency of UAV, in comparison with the conventional capacity-based reward function.},
keywords={Sensors;Unmanned aerial vehicles;Wireless sensor networks;Reinforcement learning;Data collection;Wireless networks;Inductive charging;Data collection;design of reward function;energy efficiency;Q-learning;reinforcement learning;unmanned aerial vehicle (UAV)},
doi={10.1109/JIOT.2021.3051370},
ISSN={2327-4662},
month={June},}
@INPROCEEDINGS{9685462,
author={Benfaid, Ahmed and Adem, Nadia and Khalfi, Bassem},
booktitle={2021 IEEE Global Communications Conference (GLOBECOM)}, title={AdaptSky: A DRL Based Resource Allocation Framework in NOMA-UAV Networks},
year={2021},
volume={},
number={},
pages={01-07},
abstract={The unmanned aerial vehicle (UAV) technology has recently attracted a lot of attention as a candidate to meet the 6G ubiquitous connectivity demand and boost the resiliency of terrestrial networks. Thanks to the high spectral efficiency and low latency, non-orthogonal multiple access (NOMA) is a potential access technique for future communication networks. In this paper, we propose to use the UAV as a moving base station (BS) to serve multiple users using NOMA and jointly solve for the 3D UAV placement and resource allocation problem. Since the corresponding optimization problem is non-convex, we rely on the recent advances in artificial intelligence AI and propose AdaptSky, a deep reinforcement learning (DRL)-based framework, to efficiently solve it. To the best of our knowledge, AdaptSky is the first framework that optimizes NOMA power allocation jointly with 3D UAV placement using both sub-6GHz and millimeter wave mmWave spectrum. Furthermore, for the first time in NOMA-UAV networks, AdaptSky integrates the dueling network DN architecture to the DRL technique to improve its learning capabilities. Our findings show that AdaptSky not only outperforms the state-of-the-art baseline approach in data rate and fairness, but also generalizes very well.},
keywords={NOMA;Three-dimensional displays;Spectral efficiency;Simulation;Reinforcement learning;Autonomous aerial vehicles;Resource management;Deep reinforcement learning (DRL);dueling network (DN) architecture;millimeter wave (mmWave);non-orthogonal multiple access (NOMA);unmanned aerial vehicle (UAV)},
doi={10.1109/GLOBECOM46510.2021.9685462},
ISSN={},
month={Dec},}
@INPROCEEDINGS{9369744,
author={Han, Seung Heon and Rahim, Tariq and Shin, Soo Young},
booktitle={2021 International Conference on Electronics, Information, and Communication (ICEIC)}, title={Detection of Faults in Solar Panels Using Deep Learning},
year={2021},
volume={},
number={},
pages={1-4},
abstract={Renewable energies, carbon neutrality, and sustainable practices have become an important aim for many countries. Solar power generation has drawn much consideration where maintenance of solar panels is an essential task due to the natural and other mechanical circumstances. In this paper, we have proposed a deep learning (DL) approach for the detection of faults in solar panels. The proposed system uses an unmanned aerial vehicle (UAV) equipped with a thermal camera and GPS for acquiring thermal images and localization of the fault in solar panels. An improved version of You only look once (YOLOv3-tiny) is employed as a DL model for the detection of the fault and then transmitted that information using Long-Term Evolution (LTE) to a remote server for visualization. The performance of the proposed model is compared with the current default YOLOv3-tiny, where high performance was achieved by the proposed DL model.},
keywords={Deep learning;Visualization;Maintenance engineering;Unmanned aerial vehicles;Solar panels;Servers;Task analysis;Solar panels;deep learning;you only look once;thermal camera;unmanned aerial vehicle},
doi={10.1109/ICEIC51217.2021.9369744},
ISSN={},
month={Jan},}
@INPROCEEDINGS{9124759,
author={Ghavimi, Fayezeh and Jantti, Riku},
booktitle={2020 IEEE Wireless Communications and Networking Conference Workshops (WCNCW)}, title={Energy-Efficient UAV Communications with Interference Management: Deep Learning Framework},
year={2020},
volume={},
number={},
pages={1-6},
abstract={In this paper, an interference-aware energy- efficient scheme for a network of coexisting aerial-terrestrial cellular users is proposed. In particular, each aerial user aims at achieving a trade-off between maximizing energy efficiency and spectral efficiency while minimizing the incurred interference on the terrestrial users along its path. To provide a solution, we first formulate the energy efficiency problem for UAVs as an optimization problem by considering different key performance indicators (KPIs) for the network, coexisting terrestrial users, and UAVs as aerial users. Then, leveraging tools from deep learning, we transform this problem into a deep queue learning problem and present a learning-powered solution that incorporates the KPIs of interest in the design of the reward function to solve energy efficiency maximization for aerial users while minimizing interference to terrestrial users. A broad set of simulations have been conducted in order to investigate how the altitude of UAVs, and the tolerable level of interference, shape the optimal energy-efficient policy in the network. Simulation results show that the proposed scheme achieves better energy and spectral efficiency for UAV and less interference to terrestrial users incurred from aerial users. The obtained results further provide insights on the benefits of leveraging intelligent energy-efficient scheme. For example, a significant increase in the energy efficiency of aerial users with respect to increases in their spectral efficiency, while a considerable decrease in incurred interference to the terrestrial users is achieved in comparison to the non-learning scheme.},
keywords={Deep learning;Spectral efficiency;Simulation;Conferences;Interference;Transforms;Autonomous aerial vehicles;Energy efficiency;unmanned aerial vehicle (UAV);drone;cellular networks;machine learning;deep reinforcement learning;interference management},
doi={10.1109/WCNCW48565.2020.9124759},
ISSN={},
month={April},}
@INPROCEEDINGS{9356664,
author={He, Boyong and Huang, Bo and Lin, Yuxing and Wu, Liaoni},
booktitle={2020 7th International Forum on Electrical Engineering and Automation (IFEEA)}, title={Intelligent unmanned aerial vehicle (UAV) system for aircraft surface inspection},
year={2020},
volume={},
number={},
pages={316-321},
abstract={Aircraft surface inspection is critical to the safe flight of aircraft. At present, aircraft surface inspection is still mainly conducted by manual visual inspection. In order to improve the efficiency of inspection efficiency, in this paper, we designed an unmanned aerial vehicle (UAV) intelligent system to collect aircraft surface images and used deep learning object detection algorithm to independently and efficiently solved aircraft surface inspection include:(1) Used unmanned aerial vehicle (UAV) to collect the whole surface image of the aircraft wholly and independently according to the pre-planning information. (2) A high-performance algorithm for real-time detection and a high-precision algorithm for accurate detection were designed to realize intelligent inspection of aircraft surface damage based on deep learning object detection. Our experiments showed that this system could quickly and accurately inspect the entire aircraft surface with meeting the safety requirements.},
keywords={Deep learning;Visualization;Object detection;Manuals;Inspection;Unmanned aerial vehicles;Aircraft;unmanned aerial vehicle (UAV);deep learning;object detection;surface inspection},
doi={10.1109/IFEEA51475.2020.00073},
ISSN={},
month={Sep.},}
@INPROCEEDINGS{8658283,
author={Korki, Mehdi and Shankar, Nikhil Dwarakanath and Naymeshbhai Shah, Raj and Waseem, Syed Muhammad and Hodges, Steven},
booktitle={2019 1st International Conference on Unmanned Vehicle Systems-Oman (UVS)}, title={Automatic Fault Detection of Power Lines using Unmanned Aerial Vehicle (UAV)},
year={2019},
volume={},
number={},
pages={1-6},
abstract={Safety and automation are the two major challenges in the application of Unmanned Aerial Vehicle (UAV), commonly known as drone, to the power lines inspection and fault detection. While current state-of-the-art UAVs are equipped with collision avoidance features, there is less attention to the automatic and real-time fault detection of power lines using UAVs. This paper presents the architecture of three drone-oriented concept designs for automatic and real-time fault detection of power lines using UAVs. The proposed systems could be potential candidates for replacing traditional inspection methods of power lines, which are risky and costly. By incorporating a robust neural network, i.e., Artificial Intelligence (AI), and using appropriate and efficient sensors, the systems can automatically detect various faults and defects on power lines with high precision. We propose three concept design options comprised of different hardware/software components and their feasibility factors. For instance, FLIR Duo Pro R as a thermal sensor and Zenmuse XT for thermal vision have been proposed to be used in the concept designs. For data communication, the proposed designs use cloud-based virtual private network (VPN) for a secure connection between remote control (RC) of the UAV and the server. Based on the advantages and disadvantages of the three proposed design options, the most efficient design is also discussed. This design proposes a system with lightweight sensors, which could increase the flight time of the UAV. Further, the AI interface is coded on to the RC, making it economical, without any database for big data storage. The back-end of the neural network is stored in a cloud server. With the help of GSM antenna, the AI can run on the tablet if there is an available cellular network.},
keywords={Inspection;Unmanned aerial vehicles;Sensors;Cameras;Artificial intelligence;Servers;Fault detection;Unmanned Aerial Vehicle (UAV);Artificial Intelligence (AI);Convolutional Neural Network (CNN);Power lines;Automatic Fault Detection},
doi={10.1109/UVS.2019.8658283},
ISSN={},
month={Feb},}
@ARTICLE{9684973,
author={Mei, Haibo and Yang, Kun and Liu, Qiang and Wang, Kezhi},
journal={IEEE Transactions on Vehicular Technology}, title={3D-Trajectory and Phase-Shift Design for RIS-Assisted UAV Systems Using Deep Reinforcement Learning},
year={2022},
volume={71},
number={3},
pages={3020-3029},
abstract={Unmanned aerial vehicle (UAV) can effectively work as temporary base station or access point in the air to transfer/receive data to/from ground terminals (GTs). However, UAV-GT links might be blocked by ground obstacles, like buildings in urban area, leading to a poor performance on data transferring rate. To address this problem, reconfigurable intelligent surface (RIS), as a promising technique, can intelligently reflect the received signals between UAV and GT to significantly enhance the communication quality. Under this deployment of RIS-assisted UAV, we intend to jointly optimize the 3D-space of the UAV and the phase-shift of the RIS to maximize the data transferring rate of the UAV, while minimizing the UAV propulsion energy. The joint problem is non-convex in its original form and difficult to be timely solved by using traditional method, like successive convex approximation (SCA). Therefore, to facilitate the online decision making to this joint problem, we leverage deep reinforcement learning (DRL) to learn the near-optimal solution, and the well known Double Deep Q-Network (DDQN) and Deep Deterministic Policy Gradient (DDPG) algorithms are ultilized. Numerical results show that DRL can effectively improve the energy-efficiency performance of the RIS-Assisted UAV system, compared with benchmark solutions.},
keywords={Autonomous aerial vehicles;Propulsion;Wireless networks;Base stations;Rotors;Resource management;Array signal processing;Reconfigurable intelligent surface (RIS);intelligent reflecting surface (IRS);deep reinforcement learning (DRL);3D-trajectory;unmanned aerial vehicle (UAV)},
doi={10.1109/TVT.2022.3143839},
ISSN={1939-9359},
month={March},}
@ARTICLE{9504602,
author={Wang, Yang and Gao, Zhen and Zhang, Jun and Cao, Xianbin and Zheng, Dezhi and Gao, Yue and Ng, Derrick Wing Kwan and Renzo, Marco Di},
journal={IEEE Internet of Things Journal}, title={Trajectory Design for UAV-Based Internet of Things Data Collection: A Deep Reinforcement Learning Approach},
year={2022},
volume={9},
number={5},
pages={3899-3912},
abstract={In this article, we investigate an unmanned aerial vehicle (UAV)-assisted Internet of Things (IoT) system in a sophisticated 3-D environment, where the UAV’s trajectory is optimized to efficiently collect data from multiple IoT ground nodes. Unlike existing approaches focusing only on a simplified 2-D scenario and the availability of perfect channel state information (CSI), this article considers a practical 3-D urban environment with imperfect CSI, where the UAV’s trajectory is designed to minimize data collection completion time subject to practical throughput and flight movement constraints. Specifically, inspired by the state-of-the-art deep reinforcement learning approaches, we leverage the twin-delayed deep deterministic policy gradient (TD3) to design the UAV’s trajectory and we present a TD3-based trajectory design for completion time minimization (TD3-TDCTM) algorithm. In particular, we set an additional information, i.e., the merged pheromone, to represent the state information of the UAV and environment as a reference of reward which facilitates the algorithm design. By taking the service statuses of the IoT nodes, the UAV’s position, and the merged pheromone as input, the proposed algorithm can continuously and adaptively learn how to adjust the UAV’s movement strategy. By interacting with the external environment in the corresponding Markov decision process, the proposed algorithm can achieve a near-optimal navigation strategy. Our simulation results show the superiority of the proposed TD3-TDCTM algorithm over three conventional nonlearning-based baseline methods.},
keywords={Trajectory;Data collection;Sensors;Optimization;Three-dimensional displays;Minimization;Resource management;Data collection;deep reinforcement learning (DRL);Internet of Things (IoT);trajectory design;unmanned aerial vehicle (UAV) communications},
doi={10.1109/JIOT.2021.3102185},
ISSN={2327-4662},
month={March},}
@INPROCEEDINGS{9615420,
author={Tovkach, S.S.},
booktitle={2021 IEEE 6th International Conference on Actual Problems of Unmanned Aerial Vehicles Development (APUAVD)}, title={Formation of Fuzzy Temporal Descriptions of Changes in UAV Engine Parameters of Controlled Devices},
year={2021},
volume={},
number={},
pages={119-122},
abstract={One of the important areas of research in the field of Artificial Intelligence (AI) is the theoretical study of the properties of models of data representation and knowledge with uncertainty in the technical systems of DAV s. Considered a detailed study of the circumstances of the transition of the UAV device in a particular diagnostic state, it is necessary to refer to the data of the protocol of changes in signals and parameters, inviting them from storage. For analysis many situations over a period of time, or a group of devices, there is a need to automate this process, the need for a subsystem that analyzes the data of the signal and measurement protocol, forms informative generalizations, such as fuzzy, descriptions of UAV engine parameter changes, suitable for further use by the operator. A method of forming a fuzzy temporal description of the parameter change of the UAV diagnostic object is proposed. The basis of the method is a fuzzy description of options for changing the parameter over time, taking into account the temporal relations between the elements of this description of the UAV engine parameters of the object.},
keywords={Protocols;Uncertainty;Heuristic algorithms;Conferences;Knowledge based systems;Unmanned aerial vehicles;Time measurement;aviation;unmanned aerial vehicle;data bases;information system;fuzzy temporal descriptions;parameter changes;artificial intelligence},
doi={10.1109/APUAVD53804.2021.9615420},
ISSN={},
month={Oct},}
@INPROCEEDINGS{9461279,
author={Bayhan, Erdem and Ozkan, Zehra and Namdar, Mustafa and Basgumus, Arif},
booktitle={2021 3rd International Congress on Human-Computer Interaction, Optimization and Robotic Applications (HORA)}, title={Deep Learning Based Object Detection and Recognition of Unmanned Aerial Vehicles},
year={2021},
volume={},
number={},
pages={1-5},
abstract={In this study, the methods of deep learning-based detection and recognition of the threats, evaluated in terms of military and defense industry, by unmanned aerial vehicles (UAV) are presented. In the proposed approach, firstly, the training for machine learning on the objects is carried out using convolutional neural networks, which is one of the deep learning algorithms. By choosing the Faster-RCNN and YoloV4 architectures of the deep learning method, it is aimed to compare the achievements of the accuracy in the training process. In order to be used in the training and testing stages of the recommended methods, data sets containing images selected from different weather, land conditions and different time periods of the day are determined. The model for the detection and recognition of the threatening elements is trained, using 2595 images. The method of detecting and recognizing the objects is tested with military operation images and records taken by the UAVs. While an accuracy rate of 93% has been achieved in the Faster-RCNN architecture in object detection and recognition, this rate has been observed as 88% in the YoloV4 architecture.},
keywords={Training;Deep learning;Image recognition;Machine learning algorithms;Object detection;Unmanned aerial vehicles;Robots;deep learning;Faster-RCNN;UAV;machine learning;object detection;object recognition;YoloV4.},
doi={10.1109/HORA52670.2021.9461279},
ISSN={},
month={June},}
@ARTICLE{7809052,
author={Zeng, Yi and Wang, Guixiang and Xu, Bo},
journal={IEEE Transactions on Cognitive and Developmental Systems}, title={A Basal Ganglia Network Centric Reinforcement Learning Model and Its Application in Unmanned Aerial Vehicle},
year={2018},
volume={10},
number={2},
pages={290-303},
abstract={Reinforcement learning brings flexibility and generality for machine learning, while most of them are mathematical optimization driven approaches, and lack of cognitive and neural evidence. In order to provide a more cognitive and neural mechanisms driven foundation and validate its applicability in complex task, we develop a basal ganglia (BG) network centric reinforcement learning model. Compared to existing work on modeling BG, this paper is unique from the following perspectives: 1) the orbitofrontal cortex (OFC) is taken into consideration. OFC is critical in decision making because of its responsibility for reward representation and is critical in controlling the learning process, while most of the BG centric models do not include OFC; 2) to compensate the inaccurate memory of numeric values, precise encoding is proposed to enable working memory system remember important values during the learning process. The method combines vector convolution and the idea of storage by digit bit and is efficient for accurate value storage; and 3) for information coding, the Hodgkin-Huxley model is used to obtain a more biological plausible description of action potential with plenty of ionic activities. To validate the effectiveness of the proposed model, we apply the model to the unmanned aerial vehicle (UAV) autonomous learning process in a 3-D environment. Experimental results show that our model is able to give the UAV the ability of free exploration in the environment and has comparable learning speed as the Q learning algorithm, while the major advances for our model is that it is with solid cognitive and neural basis.},
keywords={Brain modeling;Biological system modeling;Computational modeling;Reinforcement learning;Task analysis;Unmanned aerial vehicles;Solid modeling;Basal ganglia (BG) network;brain-inspired intelligence;precise encoding;reinforcement learning model;unmanned aerial vehicle (UAV) autonomous learning},
doi={10.1109/TCDS.2017.2649564},
ISSN={2379-8939},
month={June},}
@ARTICLE{8933072,
author={Alipour-Fanid, Amir and Dabaghchian, Monireh and Wang, Ning and Wang, Pu and Zhao, Liang and Zeng, Kai},
journal={IEEE Transactions on Information Forensics and Security}, title={Machine Learning-Based Delay-Aware UAV Detection and Operation Mode Identification Over Encrypted Wi-Fi Traffic},
year={2020},
volume={15},
number={},
pages={2346-2360},
abstract={The consumer unmanned aerial vehicle (UAV) market has grown significantly over the past few years. Despite its huge potential in spurring economic growth by supporting various applications, the increase of consumer UAVs poses potential risks to public security and personal privacy. To minimize the risks, efficiently detecting and identifying invading UAVs is in urgent need for both invasion detection and forensics purposes. Aiming to complement the existing physical detection mechanisms, we propose a machine learning-based framework for fast UAV identification over encrypted Wi-Fi traffic. It is motivated by the observation that many consumer UAVs use Wi-Fi links for control and video streaming. The proposed framework extracts features derived only from packet size and inter-arrival time of encrypted Wi-Fi traffic, and can efficiently detect UAVs and identify their operation modes. In order to reduce the online identification time, our framework adopts a re-weighted ℓ1-norm regularization, which considers the number of samples and computation cost of different features. This framework jointly optimizes feature selection and prediction performance in a unified objective function. To tackle the packet inter-arrival time uncertainty when optimizing the trade-off between the detection accuracy and delay, we utilize maximum likelihood estimation (MLE) method to estimate the packet inter-arrival time. We collect a large number of real-world Wi-Fi data traffic of eight types of consumer UAVs and conduct extensive evaluation on the performance of our proposed method. Evaluation results show that our proposed method can detect and identify tested UAVs within 0.15-0.35s with high accuracy of 85.7-95.2%. The UAV detection range is within the physical sensing range of 70m and 40m in the line-of-sight (LoS) and non-line-of-sight (NLoS) scenarios, respectively. The operation mode of UAVs can be identified with high accuracy of 88.5-98.2%.},
keywords={Unmanned aerial vehicles;Wireless fidelity;Feature extraction;Cryptography;Delays;Radar detection;Unmanned aerial vehicle (UAV) detection;machine learning;encrypted Wi-Fi traffic classification},
doi={10.1109/TIFS.2019.2959899},
ISSN={1556-6021},
month={},}
@ARTICLE{9146631,
author={Rajagopal, Aghila and Joshi, Gyanendra Prasad and Ramachandran, A. and Subhalakshmi, R. T. and Khari, Manju and Jha, Sudan and Shankar, K. and You, Jinsang},
journal={IEEE Access}, title={A Deep Learning Model Based on Multi-Objective Particle Swarm Optimization for Scene Classification in Unmanned Aerial Vehicles},
year={2020},
volume={8},
number={},
pages={135383-135393},
abstract={Recently, the increase in inexpensive and compact unmanned aerial vehicles (UAVs) and light-weight imaging sensors has led to an interest in using them in various remote sensing applications. The processes of collecting, calibrating, registering, and processing data from miniature UAVs and interpreting the data semantically are time-consuming. In UAV aerial imagery, learning effective image representations is central to the scene classification process. Earlier approaches to the scene classification process depended on feature coding methods with low-level hand-engineered features or unsupervised feature learning. These methods could produce mid-level image features with restricted representational abilities, which generally yielded mediocre results. The development of convolutional neural networks (CNNs) has made image classification more efficient. Due to the limited resources in UAVs, it is hard to fine-tune the hyperparameters and the trade-offs between classifier results and computation complexity. This paper introduces a new multi-objective optimization model for evolving state-of-the-art deep CNNs for scene classification, which generates the non-dominant solutions in an automated way at the Pareto front. We use a set of two benchmark datasets to test the performance of the scene classification model and make a detailed comparative study. The proposed method attains a very low computational time of 80 sec and maximum accuracy of 97.88% compared to all other methods. The proposed method is found to be appropriate for the effective scene classification of images captured by UAVs.},
keywords={Unmanned aerial vehicles;Machine learning;Visualization;Feature extraction;Image classification;Training;Unmanned aerial vehicle;particle swarm optimization;deep learning;convolutional neural networks;machine learning;internet of everything;aerial images;smart environment},
doi={10.1109/ACCESS.2020.3011502},
ISSN={2169-3536},
month={},}
@ARTICLE{9127428,
author={Tang, Fengxiao and Zhou, Yibo and Kato, Nei},
journal={IEEE Journal on Selected Areas in Communications}, title={Deep Reinforcement Learning for Dynamic Uplink/Downlink Resource Allocation in High Mobility 5G HetNet},
year={2020},
volume={38},
number={12},
pages={2773-2782},
abstract={Recently, the 5G is widely deployed for supporting communications of high mobility nodes including train, vehicular and unmanned aerial vehicles (UAVs) largely emerged as the main components for constructing the wireless heterogeneous network (HetNet). To further improve the radio utilization, the Time Division Duplex (TDD) is considered to be the potential full-duplex communication technology in the high mobility 5G network. However, the high mobility of users leads to the high dynamic network traffic and unpredicted link state change. A new method to predict the dynamic traffic and channel condition and schedule the TDD configuration in real-time is essential for the high mobility environment. In this paper, we investigate the channel model in the high mobility and heterogeneous network and proposed a novel deep reinforcement learning based intelligent TDD configuration algorithm to dynamically allocate radio resources in an online manner. In the proposal, the deep neural network is employed to extract the features of the complex network information, and the dynamic Q-value iteration based reinforcement learning with experience replay memory mechanism is proposed to adaptively change TDD Up/Down-link ratio by evaluated rewards. The simulation results show that the proposal achieves significant network performance improvement in terms of both network throughput and packet loss rate, comparing with conventional TDD resource allocation algorithms.},
keywords={5G mobile communication;Resource management;Heuristic algorithms;Vehicle dynamics;Interference;Dynamic scheduling;Device-to-device communication;Vehicular ad hoc networks;5G;high mobility;resource allocation;unmanned aerial vehicle (UAV);time division duplex (TDD);reinforcement learning (RL);Q-learning;deep learning;deep belief network;heterogeneous network (HetNet)},
doi={10.1109/JSAC.2020.3005495},
ISSN={1558-0008},
month={Dec},}
@ARTICLE{9563249,
author={Nie, Yiwen and Zhao, Junhui and Gao, Feifei and Yu, F. Richard},
journal={IEEE Transactions on Vehicular Technology}, title={Semi-Distributed Resource Management in UAV-Aided MEC Systems: A Multi-Agent Federated Reinforcement Learning Approach},
year={2021},
volume={70},
number={12},
pages={13162-13173},
abstract={Recently, unmanned aerial vehicle (UAV)-enabled multi-access edge computing (MEC) has been introduced as a promising edge paradigm for the future space-aerial-terrestrial integrated communications. Due to the high maneuverability of UAVs, such a flexible paradigm can improve the communication and computation performance for multiple user equipments (UEs). In this paper, we consider the sum power minimization problem by jointly optimizing resource allocation, user association, and power control in an MEC system with multiple UAVs. Since the problem is nonconvex, we propose a centralized multi-agent reinforcement learning (MARL) algorithm to solve it. However, the centralized method ignores essential issues like distributed framework and privacy concern. We then propose a multi-agent federated reinforcement learning (MAFRL) algorithm in a semi-distributed framework. Meanwhile, we introduce the Gaussian differentials to protect the privacy of all UEs. Simulation results show that the semi-distributed MAFRL algorithm achieves close performances to the centralized MARL algorithm and significantly outperform the benchmark schemes. Moreover, the semi-distributed MAFRL algorithm costs 23$\%$ lower opeartion time than the centralized algorithm.},
keywords={Unmanned aerial vehicles;Edge computing;Deep learning;Artificial intelligence;Resource management;Reinforcement learning;Unmanned aerial vehicle (UAV);multi-access edge computing (MEC);deep reinforcement learning (DRL);federated learning (FL);resource allocation},
doi={10.1109/TVT.2021.3118446},
ISSN={1939-9359},
month={Dec},}
@INPROCEEDINGS{9120492,
author={Huang, Yuwei and Mo, Xiaopeng and Xu, Jie and Qiu, Ling and Zeng, Yong},
booktitle={2020 IEEE Wireless Communications and Networking Conference (WCNC)}, title={Online Maneuver Design for UAV-Enabled NOMA Systems via Reinforcement Learning},
year={2020},
volume={},
number={},
pages={1-6},
abstract={This paper considers an unmanned aerial vehicle (UAV)-enabled uplink non-orthogonal multiple-access (NOMA) system, where multiple users on the ground send independent messages to a UAV via NOMA transmission. We aim to design the UAV’s dynamic maneuver in real time for maximizing the sum-rate throughput of all ground users over a finite time horizon. Different from conventional offline designs considering static user locations under deterministic or stochastic channel models, we consider a more challenging scenario with mobile users and segmented channel models, where the UAV only causally knows the users’ (moving) locations and channel state information (CSI). Under this setup, we first propose a new approach for UAV dynamic maneuver design based on reinforcement learning (RL) via Q-learning. Next, in order to further speed up the convergence and increase the throughput, we present an enhanced RL-based approach by additionally exploiting expert knowledge of well-established wireless channel models to initialize the Q-table values. Numerical results show that our proposed RL-based and enhanced RL-based approaches significantly improve the sum-rate throughput, and the enhanced RL-based approach considerably speeds up the learning process owing to the proposed Q-table initialization.},
keywords={Wireless communication;NOMA;Q-learning;Stochastic processes;Autonomous aerial vehicles;Throughput;Real-time systems;Unmanned aerial vehicle (UAV);maneuver design;reinforcement learning (RL);Q-learning;non-orthogonal multiple-access (NOMA)},
doi={10.1109/WCNC45663.2020.9120492},
ISSN={1558-2612},
month={May},}
@ARTICLE{9528844,
author={Liu, Lingshan and Xiong, Ke and Cao, Jie and Lu, Yang and Fan, Pingyi and Letaief, Khaled Ben},
journal={IEEE Internet of Things Journal}, title={Average AoI Minimization in UAV-Assisted Data Collection With RF Wireless Power Transfer: A Deep Reinforcement Learning Scheme},
year={2022},
volume={9},
number={7},
pages={5216-5228},
abstract={This article studies the unmanned aerial vehicle (UAV)-assisted wireless powered network, where a UAV is dispatched to wirelessly charge multiple ground nodes (GNs) by using radio frequency (RF) energy transfer and then the GNs use their harvested energy to upload the sensed information to the UAV. At each moment, the UAV is scheduled to charge the GNs or only one GN is scheduled to upload its data. An optimization problem is formulated to minimize the average Age of Information (AoI) of the GNs by jointly optimizing the trajectory of the UAV and the scheduling of information transmission and energy harvesting of GNs. As the problem is a combinational optimization problem with a set of binary variables, it is difficult to be solved. Thus, it is modeled as a Markov problem with large state spaces and a deep ${Q}$ network (DQN)-based scheme is proposed to find its near-optimal solution on the basis of the deep reinforcement learning (DRL) framework. Two nets are structured with artificial neural network (ANN), where one is for evaluating the reward of the action performed in current state, and the other is for predicting realistic action. The corresponding state spaces, the efficient action spaces, and reward function are designed. Simulation results demonstrate the convergence of the proposed DQN scheme, which also show that the proposed DQN scheme gets much smaller average AoI than the three other known schemes. Moreover, by involving the energy punishment in the reward, the UAV may save its energy but yield higher AoI. Additionally, the effects of the packet size, the transmit power, and the distribution area of GNs on the GNs’ average AoI are also discussed, which are expected to provide some useful insights.},
keywords={Trajectory;Radio frequency;Internet of Things;Wireless networks;Wireless sensor networks;Reinforcement learning;Energy consumption;Age of Information (AoI);deep reinforcement learning (DRL);unmanned aerial vehicle (UAV);wireless power transmission},
doi={10.1109/JIOT.2021.3110138},
ISSN={2327-4662},
month={April},}
@ARTICLE{9395130,
author={Zhang, Lu and Zhang, Zi-Yan and Min, Luo and Tang, Chao and Zhang, Hong-Ying and Wang, Ya-Hong and Cai, Peng},
journal={IEEE Access}, title={Task Offloading and Trajectory Control for UAV-Assisted Mobile Edge Computing Using Deep Reinforcement Learning},
year={2021},
volume={9},
number={},
pages={53708-53719},
abstract={Mobile Edge Computing (MEC) has been widely employed to support various Internet of Things (IoT) and mobile applications. By leveraging the advantages of easily deployed and flexibility of Unmanned Aerial Vehicle (UAV), one of MEC primary functions is employing UAVs equipped with MEC servers to provide computation supports for the offloaded tasks by mobile users in temporally hotspot areas or some emergent scenarios, such as sports game areas or destroyed by natural disaster areas. Despite the numerous advantages of UAV carried with a MEC server, it is restricted by its limited computation resources and sensitive energy consumption. Moreover, due to the complexity of UAV-assisted MEC system, its computational resource optimization and energy consumption optimization cannot be achieved well in traditional optimization methods. Furthermore, the computational cost of the MEC system optimization is often exponentially growing with the increase of the MEC servers and mobile users. Therefore, it is considerably challenging to control the UAV positions and schedule the task offloading ratio. In this paper, we proposed a novel Deep Reinforcement Learning (DRL) method to optimize UAV trajectory controlling and users' offloaded task ratio scheduling and improve the performance of the UAV-assisted MEC system. We maximized the system stability and minimized the energy consumption and computation latency of UAV-assisted the MEC system. The simulation results show that the proposed method outperforms existing work and has better scalability.},
keywords={Task analysis;Computational modeling;Servers;Energy consumption;Trajectory;Reinforcement learning;Unmanned aerial vehicles;Computation offloading;deep learning;energy saving;mobile edge computing;reinforcement learning;unmanned aerial vehicle},
doi={10.1109/ACCESS.2021.3070908},
ISSN={2169-3536},
month={},}
@ARTICLE{8917687,
author={Singla, Abhik and Padakandla, Sindhu and Bhatnagar, Shalabh},
journal={IEEE Transactions on Intelligent Transportation Systems}, title={Memory-Based Deep Reinforcement Learning for Obstacle Avoidance in UAV With Limited Environment Knowledge},
year={2021},
volume={22},
number={1},
pages={107-118},
abstract={This paper presents our method for enabling a UAV quadrotor, equipped with a monocular camera, to autonomously avoid collisions with obstacles in unstructured and unknown indoor environments. When compared to obstacle avoidance in ground vehicular robots, UAV navigation brings in additional challenges because the UAV motion is no more constrained to a well-defined indoor ground or street environment. Unlike ground vehicular robots, a UAV has to navigate across more types of obstacles - for e.g., objects like decorative items, furnishings, ceiling fans, sign-boards, tree branches, etc., are also potential obstacles for a UAV. Thus, methods of obstacle avoidance developed for ground robots are clearly inadequate for UAV navigation. Current control methods using monocular images for UAV obstacle avoidance are heavily dependent on environment information. These controllers do not fully retain and utilize the extensively available information about the ambient environment for decision making. We propose a deep reinforcement learning based method for UAV obstacle avoidance (OA) which is capable of doing exactly the same. The crucial idea in our method is the concept of partial observability and how UAVs can retain relevant information about the environment structure to make better future navigation decisions. Our OA technique uses recurrent neural networks with temporal attention and provides better results compared to prior works in terms of distance covered without collisions. In addition, our technique has a high inference rate and reduces power wastage as it minimizes oscillatory motion of UAV.},
keywords={Collision avoidance;Navigation;Cameras;Unmanned aerial vehicles;Simultaneous localization and mapping;Visualization;Unmanned aerial vehicle (UAV) obstacle avoidance (OA);deep reinforcement learning (DRL);partial observability;deep Q-networks (DQN)},
doi={10.1109/TITS.2019.2954952},
ISSN={1558-0016},
month={Jan},}
@INPROCEEDINGS{9255181,
author={Altan, Aytaç},
booktitle={2020 4th International Symposium on Multidisciplinary Studies and Innovative Technologies (ISMSIT)}, title={Performance of Metaheuristic Optimization Algorithms based on Swarm Intelligence in Attitude and Altitude Control of Unmanned Aerial Vehicle for Path Following},
year={2020},
volume={},
number={},
pages={1-6},
abstract={Nowadays, it is very important for the success of the determined missions or operations that the Unmanned Aerial Vehicles (UAVs), which are used extensively in the performance of many civil and military tasks, follow the predetermined path with high accuracy at the determined altitude. The fact that the UAV performs its mission by adhering to the predetermined height and path enables the UAV to spend less energy and therefore fly for a longer time. Many traditional control algorithms, especially Proportional-Integral-Derivative (PID), are used in the attitude and altitude control of UAV for path following. Unlike other studies, in this study, metaheuristic optimization algorithms based on swarm intelligence estimate the parameters of the control algorithm proposed for UAV. Using meta-heuristic optimization algorithms such as Particle Swarm Optimization (PSO) and Harris Hawks Optimization (HHO), both attitude and altitude control of the quadrotor have been performed for path following in routes with different geometries such as rectangle, circle, and lemniscate. The performance of each control algorithm in the study for the specified routes has been tested and the test results obtained have been compared with each other. Considering the features such as simplicity, flexibility, ability to search randomly and avoiding local optima, a new control algorithm whose KP, KI, and KD parameter values optimized by HHO, have been proposed for UAV's attitude and altitude control.},
keywords={Geometry;Attitude control;Unmanned aerial vehicles;PD control;Particle swarm optimization;Task analysis;Optimization;unmanned aerial vehicle (UAV);path following;Harris hawks optimization;real time control;swarm intelligence},
doi={10.1109/ISMSIT50672.2020.9255181},
ISSN={},
month={Oct},}
@INPROCEEDINGS{9299862,
author={Gu, Jiangchun and Wang, Haichao and Ding, Guoru and Xu, Yitao and Jiao, Yutao},
booktitle={2020 International Conference on Wireless Communications and Signal Processing (WCSP)}, title={UAV-Enabled Mobile Radiation Source Tracking with Deep Reinforcement Learning},
year={2020},
volume={},
number={},
pages={672-678},
abstract={Employing unmanned aerial vehicle (UAV) in localization and tracking system can bring many attractive advantages due to its high mobility, on-demand deployment and low cost. In this paper, we utilize the UAV as a mobile sensor to close up and track a mobile radiation source only based on the received signal strengths. We aim to maximize the sum of received signal strengths at the UAV receiver during a certain time interval, while taking the UAV's maximum speed and fly region constraints into account. However, it is very challenging since the positions of radiation source are unknown and dynamically changing. To address this issue, we propose a deep reinforcement learning (DRL) based framework. We first reformulate the original problem into a Markov decision process (MDP). Then, we apply the double deep Q-network (DDQN) with dueling network structure and accordingly develop a multi-step dueling-DDQN learning algorithm for radiation source tracking. The simulation results demonstrate the effectiveness of the proposed algorithm under various parameter settings.},
keywords={Reinforcement learning;Unmanned aerial vehicles;Target tracking;Radar tracking;Prediction algorithms;Wireless sensor networks;Trajectory;Unmanned aerial vehicle (UAV);radiation source;localization;tracking;deep reinforcement learning (DRL)},
doi={10.1109/WCSP49889.2020.9299862},
ISSN={2472-7628},
month={Oct},}
@INPROCEEDINGS{8995935,
author={Xu, Tonghua and Wang, Nan and Lin, Hong and Sun, Zhaomei},
booktitle={2019 IEEE International Conference on Unmanned Systems (ICUS)}, title={UAV Autonomous Reconnaissance Route Planning Based on Deep Reinforcement Learning},
year={2019},
volume={},
number={},
pages={761-766},
abstract={In order to improve the autonomous reconnaissance efficiency of unmanned aerial vehicle (UAV) in an uncertain environment, situation and observation information acquired by UAV are input into the replay buffer. Model-free training is performed on the data of the replay buffer by deep reinforcement learning (DRL) method, so as to generate the corresponding network model. The reward function is designed for UAV regional reconnaissance missions to further improve the generalization ability of the model. The simulation results show that the UAV autonomous reconnaissance route planning algorithm based on DRL has a high degree of sustainable coverage and its patrol path is unpredictable.},
keywords={unmanned aerial vehicle (UAV);autonomous reconnaissance;deep reinforcement learning (DRL);reward function},
doi={10.1109/ICUS48101.2019.8995935},
ISSN={},
month={Oct},}
@INPROCEEDINGS{9345106,
author={Lyu, Zhonghao and Ren, Chenhao and Qiu, Ling},
booktitle={2020 IEEE 6th International Conference on Computer and Communications (ICCC)}, title={Movement and Communication Co-Design in Multi-UAV Enabled Wireless Systems via DRL},
year={2020},
volume={},
number={},
pages={220-226},
abstract={This paper studies downlink communications in multi-unmanned aerial vehicle (UAV) enabled wireless communication systems with co-channel interference, where multiple UAVs are employed as aerial base stations (BSs) to serve mobile users on the ground. Our goal is to maximize the average sum-rate throughput of all users over a finite time horizon via UAV dynamic movement and communication (including user association and power control) co-design. Different from conventional offline designs based on the ideal assumption that channel state information (CSI) is perfectly known ahead of the flight, here we consider more challenging scenarios that the UAV can only obtain the real-time CSI along its flight. To tackle the online movement and communication co-design problem, we propose a deep reinforcement learning (DRL) algorithm based on deep deterministic policy gradient (DDPG), which can handle the problem of our interest with high-dimensional action space. Numerical results show that our proposed algorithm outperforms other benchmark schemes and baseline algorithms significantly.},
keywords={Wireless communication;Power control;Reinforcement learning;Throughput;Unmanned aerial vehicles;Real-time systems;Vehicle dynamics;unmanned aerial vehicle (UAV);dynamic movement design;communication design;deep reinforcement learning (DRL)},
doi={10.1109/ICCC51575.2020.9345106},
ISSN={},
month={Dec},}
@ARTICLE{8536405,
author={Zhu, Jiasong and Sun, Ke and Jia, Sen and Li, Qingquan and Hou, Xianxu and Lin, Weidong and Liu, Bozhi and Qiu, Guoping},
journal={IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing}, title={Urban Traffic Density Estimation Based on Ultrahigh-Resolution UAV Video and Deep Neural Network},
year={2018},
volume={11},
number={12},
pages={4968-4981},
abstract={This paper presents an advanced urban traffic density estimation solution using the latest deep learning techniques to intelligently process ultrahigh-resolution traffic videos taken from an unmanned aerial vehicle (UAV). We first capture nearly an hour-long ultrahigh-resolution traffic video at five busy road intersections of a modern megacity by flying a UAV during the rush hours. We then randomly sampled over 17 K 512×512 pixel image patches from the video frames and manually annotated over 64 K vehicles to form a dataset for this paper, which will also be made available to the research community for research purposes. Our innovative urban traffics analysis solution consists of an advanced deep neural network (DNN) based vehicle detection and localization, type (car, bus, and truck) recognition, tracking, and vehicle counting over time. We will present extensive experimental results to demonstrate the effectiveness of our solution. We will show that our enhanced single shot multibox detector (Enhanced-SSD) outperforms other DNN-based techniques and that deep learning techniques are more effective than traditional computer vision techniques in traffic video analysis. We will also show that ultrahigh-resolution video provides more information that enables more accurate vehicle detection and recognition than lower resolution contents. This paper not only demonstrates the advantages of using the latest technological advancements (ultrahigh-resolution video and UAV), but also provides an advanced DNN-based solution for exploiting these technological advancements for urban traffic density estimation.},
keywords={Neural networks;Traffic control;Unmanned aerial vehicles;Vehicle detection;Urban areas;Road traffic;Deep neural networks (DNNs);road traffic monitoring;traffic density estimation;unmanned aerial vehicle (UAV);vehicle counting;vehicle detection;vehicle tracking},
doi={10.1109/JSTARS.2018.2879368},
ISSN={2151-1535},
month={Dec},}
@ARTICLE{9466945,
author={Chen, Yu-Jia and Huang, Da-Yu},
journal={IEEE Internet of Things Journal}, title={Joint Trajectory Design and BS Association for Cellular-Connected UAV: An Imitation-Augmented Deep Reinforcement Learning Approach},
year={2022},
volume={9},
number={4},
pages={2843-2858},
abstract={This article concerns the problem of the trajectory design and base station (BS) association for cellular-connected unmanned aerial vehicles (UAVs). To support safety-critical functions, one primary requirement for UAVs is to maintain reliable cellular connectivity at every time instant during the flight mission. Since the antenna gain of a ground BS (GBS) changes with the position of the UAV, the UAV-GBS association strategy should be jointly considered with the trajectory design, which has not been studied in the prior arts. In this article, we first formulate the problem of joint BS association and trajectory design with the objective of minimizing the mission completion time under a connectivity outage constraint. Then, a deep learning framework is proposed to solve the formulated nonconvex optimization problem in a decoupled manner. For the UAV-GBS association strategy, the signal strength radio map of a given area is constructed, which is used to train a deep neural network (DNN) to approximate the nonlinear mapping from the UAV position to the optimal GBS. To tackle the high complexity due to the coupled decision variables of GBS association and UAV movement, a novel deep reinforcement learning (DRL) approach is developed to learn the optimal trajectory, in which the UAV can learn from its own past good experiences. Our simulation results confirm the superiority of the proposed DRL approach compared to the conventional DRL approaches in terms of the trajectory length. Additionally, it is demonstrated that the nearest association scheme fails to provide reliable cellular connections, whereas our proposed approach can ensure strong connectivity with the GBS during the whole trajectory.},
keywords={Trajectory;Unmanned aerial vehicles;Interference;Antenna radiation patterns;Trajectory optimization;Signal to noise ratio;Three-dimensional displays;Cell association;cellular networks;deep reinforcement learning (DRL);trajectory design;unmanned aerial vehicle (UAV)},
doi={10.1109/JIOT.2021.3093116},
ISSN={2327-4662},
month={Feb},}
@ARTICLE{9290094,
author={Li, Lixin and Cheng, Qianqian and Xue, Kaiyuan and Yang, Chungang and Han, Zhu},
journal={IEEE Transactions on Vehicular Technology}, title={Downlink Transmit Power Control in Ultra-Dense UAV Network Based on Mean Field Game and Deep Reinforcement Learning},
year={2020},
volume={69},
number={12},
pages={15594-15605},
abstract={As an emerging technology in 5G, ultra-dense unmanned aerial vehicles (UAVs) network can significantly improve the system capacity and networks coverage. However, it is still a challenge to reduce interference and improve energy efficiency (EE) of UAVs. In this paper, we investigate a downlink power control problem to maximize the EE in an ultra-dense UAV network. Firstly, the power control problem is formulated as a discrete mean field game (MFG) to imitate the interactions among a large number of UAVs, and then the MFG framework is transformed into a Markov decision process (MDP) to obtain the equilibrium solution of the MFG due to the dense deployment of UAVs. Specifically, a deep reinforcement learning-based MFG (DRL-MFG) algorithm is proposed to suppress the interference and maximize the EE by using deep neural networks (DNN) to explore the optimal power strategy for UAVs. The numerical results show that the UAVs can effectively interact with the environment to obtain the optimal power control strategy. Compared with the benchmarks algorithms, the DRL-MFG algorithm converges faster to the solution of MFG and improves the EE of UAVs. Moreover, the impact of the transmit power on EE under the different heights of the UAVs is also analyzed.},
keywords={Power control;Interference;Mathematical model;Games;Downlink;Resource management;Game theory;Unmanned aerial vehicle (UAV);power control;energy efficiency (EE);mean field game (MFG);deep reinforcement learning (DRL)},
doi={10.1109/TVT.2020.3043851},
ISSN={1939-9359},
month={Dec},}
@ARTICLE{9686616,
author={Zhan, Cheng and Zeng, Yong},
journal={IEEE Transactions on Wireless Communications}, title={Energy Minimization for Cellular-Connected UAV: From Optimization to Deep Reinforcement Learning},
year={2022},
volume={},
number={},
pages={1-1},
abstract={Cellular-connected unmanned aerial vehicles (UAVs) are expected to become integral components of future cellular networks. To this end, one of the important problems to address is how to support energy-efficient UAV operation while maintaining reliable connectivity between those aerial users and cellular networks. In this paper, we aim to minimize the energy consumption of cellular-connected UAV via jointly designing the mission completion time and UAV trajectory, as well as communication base station (BS) associations, while ensuring a satisfactory communication connectivity with the ground cellular network during the UAV flight. An optimization problem is formulated by taking into account the UAV’s flight energy consumption and various practical aspects of the air-ground communication models, including BS antenna pattern, interference from non-associated BSs and local environment. The formulated problem is difficult to tackle due to the lack of closed-form expressions and non-convexity nature. To this end, we first assume that the channel knowledge map (CKM) or radio map for the considered area is available, which contains rich information about the relatively stable (large-scale) channel parameters. By utilizing path discretization technique, we obtain a discretized equivalent problem and develop an efficient solution based on graph theory by employing convex optimization technique and a dynamic-weight shortest path algorithm over graph. Next, we study the more practical case that the CKM is unavailable initially. By transforming the optimization problem to a Markov decision process (MDP), we develop a deep reinforcement learning (DRL) algorithm based on multi-step learning and double Q-learning over a dueling Deep Q-Network (DQN) architecture, where the UAV acts as an agent to explore and learn its moving policy according to its local observations of the measured signal samples. Extensive simulations are carried out and the results show that our proposed designs significantly outperform baseline schemes. Furthermore, our results reveal new insights of energy-efficient UAV flight with connectivity requirements and unveil the tradeoff between UAV energy consumption and time duration along line segments.},
keywords={Autonomous aerial vehicles;Trajectory;Wireless communication;Cellular networks;Propulsion;Energy consumption;Optimization;Energy-efficient UAV;cellular-connected UAV;trajectory design;channel knowledge map;reinforcement learning},
doi={10.1109/TWC.2022.3142018},
ISSN={1558-2248},
month={},}
@ARTICLE{8558518,
author={Zhang, Wei and Song, Ke and Rong, Xuewen and Li, Yibin},
journal={IEEE Transactions on Automation Science and Engineering}, title={Coarse-to-Fine UAV Target Tracking With Deep Reinforcement Learning},
year={2019},
volume={16},
number={4},
pages={1522-1530},
abstract={The aspect ratio of a target changes frequently during an unmanned aerial vehicle (UAV) tracking task, which makes the aerial tracking very challenging. Traditional trackers struggle from such a problem as they mainly focus on the scale variation issue by maintaining a certain aspect ratio. In this paper, we propose a coarse-to-fine deep scheme to address the aspect ratio variation in UAV tracking. The coarse-tracker first produces an initial estimate for the target object, then a sequence of actions are learned to fine-tune the four boundaries of the bounding box. The coarse-tracker and the fine-tracker are designed to have different action spaces and operating target. The former dominates the entire bounding box and the latter focuses on the refinement of each boundary. They are trained jointly by sharing the perception network with an end-to-end reinforcement learning architecture. Experimental results on benchmark aerial data set prove that the proposed approach outperforms existing trackers and produces significant accuracy gains in dealing with the aspect ratio variation in UAV tracking.},
keywords={Target tracking;Unmanned aerial vehicles;Computer vision;Reinforcement learning;Computer vision;reinforcement learning (RL);unmanned aerial vehicle (UAV);visual tracking},
doi={10.1109/TASE.2018.2877499},
ISSN={1558-3783},
month={Oct},}
@ARTICLE{9448399,
author={Anokye, Stephen and Ayepah-Mensah, Daniel and Seid, Abegaz Mohammed and Boateng, Gordon Owusu and Sun, Guolin},
journal={IEEE Systems Journal}, title={Deep Reinforcement Learning-Based Mobility-Aware UAV Content Caching and Placement in Mobile Edge Networks},
year={2022},
volume={16},
number={1},
pages={275-286},
abstract={With the proliferation of smart mobile devices, there is now an ever increasing craving for higher bandwidth for end user satisfaction. Increasing mobile traffic leads to congestion of backhaul networks. One promising solution to this problem is the mobile edge network and consequently mobile edge caching. There is an emerging paradigm shift toward the use of unmanned aerial vehicles (UAVs) to assist the traditional cellular networks and also to provide connectivity in places where there are no small base stations or faulty ones as a result of some natural disaster such as flooding. Hence, UAVs can be used to assist in content caching as well. This work proposes the use of human centric features, random waypoint user mobility model, and deep reinforcement learning to predict the location of the UAVs and the contents to cache at the UAVs. We formulated our problem as a Markov decision problem (MDP) and proposed a dueling reinforcement learning-based algorithm to solve the MDP problem. Our simulation results prove that our algorithm converges to an optimal solution and performs better than other baseline reinforcement learning algorithms in terms of quality of experience satisfaction, transmit power, and cache resource utilization},
keywords={Optimization;Quality of experience;Wireless communication;Trajectory;Bandwidth;Throughput;Interference;Mobile edge caching;mobile edge network (MEN);reinforcement learning (RL);unmanned aerial vehicle (UAV)},
doi={10.1109/JSYST.2021.3082837},
ISSN={1937-9234},
month={March},}
@ARTICLE{9444812,
author={Khodaparast, Seyed Saeed and Lu, Xiao and Wang, Ping and Nguyen, Uyen Trang},
journal={IEEE Open Journal of Vehicular Technology}, title={Deep Reinforcement Learning Based Energy Efficient Multi-UAV Data Collection for IoT Networks},
year={2021},
volume={2},
number={},
pages={249-260},
abstract={Unmanned aerial vehicles (UAVs) are regarded as an emerging technology, which can be effectively utilized to perform the data collection tasks in the Internet of Things (IoT) networks. However, both the UAVs and the sensors in these networks are energy-limited devices, which necessitates an energy-efficient data collection procedure to ensure the network lifetime. In this paper, we propose a multi-UAV-assisted network, where the UAVs fly to the ground sensors and control the sensor's transmit power during the data collection time. Our goal is to minimize the total energy consumption of the UAVs and the sensors, which is needed to accomplish the data collection mission. We formulate this problem into three sub-problems of single UAV navigation, sensor power control as well as multi-UAV scheduling and model each part as a finite-horizon Markov Decision Process (MDP). We deploy deep reinforcement learning (DRL)-based frameworks to solve each part. Specifically, we use deep deterministic policy gradient (DDPG) method to generate the best trajectory for the UAVs in an obstacle-constraint environment, given its starting position and the target sensor. We also deploy DDPG to control the sensor's transmit power during data collection. To schedule activity plans for each UAV to visit the sensors, we propose a multi-agent deep Q-learning (DQL) approach by taking the total energy consumption of the UAVs on each path into account. Our simulations show that the UAVs can find a safe and optimal path for each of their trips. Continuous power control of the sensors achieves better performance over the fixed power approaches in terms of the total energy consumption during data collection. In addition, compared to the two commonly used baselines, our scheduling framework achieves better and near-optimal results.},
keywords={Sensors;Data collection;Energy consumption;Trajectory;Navigation;Unmanned aerial vehicles;Task analysis;Data collection;unmanned aerial vehicle (UAV);Internet of Things (IoT);deep reinforcement learning (DRL);energy consumption},
doi={10.1109/OJVT.2021.3085421},
ISSN={2644-1330},
month={},}
@ARTICLE{8494742,
author={Hu, Jingzhi and Zhang, Hongliang and Song, Lingyang},
journal={IEEE Internet of Things Journal}, title={Reinforcement Learning for Decentralized Trajectory Design in Cellular UAV Networks With Sense-and-Send Protocol},
year={2019},
volume={6},
number={4},
pages={6177-6189},
abstract={Recently, the unmanned aerial vehicles (UAVs) have been widely used in real-time sensing applications over cellular networks. The performance of a UAV is determined by both its sensing and transmission processes, which are influenced by the trajectory of the UAV. However, it is challenging for the UAV to determine its trajectory, since it works in a dynamic environment, where other UAVs determine their trajectories dynamically and compete for the limited spectrum resources in the same time. To tackle this challenge, we adopt the reinforcement learning to solve the UAV trajectory design problem in a decentralized manner. To coordinate multiple UAVs performing real-time sensing tasks, we first propose a sense-and-send protocol, and analyze the probability for successful valid data transmission using nested Markov chains. Then, we propose an enhanced multi-UAV Q-learning algorithm to solve the decentralized UAV trajectory design problem. Simulation results show that the proposed algorithm converges faster and achieves higher utilities for the UAVs, compared to traditional singleand multi-agent Q-learning algorithms.},
keywords={Sensors;Task analysis;Trajectory;Real-time systems;Protocols;Unmanned aerial vehicles;Learning (artificial intelligence);Reinforcement learning;sense-and-send protocol;trajectory design;unmanned aerial vehicle (UAV)},
doi={10.1109/JIOT.2018.2876513},
ISSN={2327-4662},
month={Aug},}
@INPROCEEDINGS{7520118,
author={de Sousa Paula, Patrícia and de Castro, Miguel Franklin and Paillard, Gabriel A. Louis and Sarmento, Wellington W. F.},
booktitle={2016 8th Euro American Conference on Telematics and Information Systems (EATIS)}, title={A swarm solution for a cooperative and self-organized team of UAVs to search targets},
year={2016},
volume={},
number={},
pages={1-8},
abstract={The context of this research is the use of Unmanned Aerial Vehicles (UAV) to search and localize a target. The problem to be solved is the cooperative behavior of the UAV group to optimize the search. The focus of this research is the use of bioinspired algorithms to spread the aerial vehicles and the optimization of the time of search, comparing the application of Particle Swarm Optimization with others found in literature.},
keywords={Wireless sensor networks;Unmanned aerial vehicles;Particle swarm optimization;Land vehicles;Monitoring;Software;Unmanned Aerial Vehicle;UAV;swarm intelligence;UAV swarm;bio-inspired},
doi={10.1109/EATIS.2016.7520118},
ISSN={},
month={April},}
@INPROCEEDINGS{9023811,
author={Duc, Nam-Tran and Hai, Quan-Tran and Van, Dat-Nguyen and Trong, Thanh-Han and Trong, Tuan-Do},
booktitle={2019 6th NAFOSTED Conference on Information and Computer Science (NICS)}, title={An approach for UAV indoor obstacle avoidance based on AI technique with ensemble of ResNet8 and Res-DQN},
year={2019},
volume={},
number={},
pages={330-335},
abstract={Unmanned Aerial Vehicles (UAVs) have many important applications in both civil and military areas. One of the most popular type of UAVs is quad-copter which uses four propellers to carry out its flight process. In this paper, a new control model which helps quad-copter to automatically find path and avoid obstacles indoor is introduced. The challenge of this model for quad-copter is the complex indoor environments with obstacles. Base on Deep Reinforcement Learning and Deep Learning platform, state of the art algorithms in Artificial Intelligence (AI), a new Ensemble model is proposed. The proposed model uses two algorithms to control quad-copter. One is quad-copter path finding algorithm (Deep Learning - ResNet8) and the other algorithm (Deep Reinforcement Learning - Res-DQN) dealing with obstacle avoidance. The output of both two algorithms are combined to change the direction of quad-copter adaptively with indoor environments. The simulation results have been assessed to verify the numerous performance of proposed control model.},
keywords={Machine learning;Collision avoidance;Training;Computational modeling;Computer science;Atmospheric modeling;Artificial Intelligence;Deep Learning;Deep Reinforcement Learning;UAV;obstacle avoidance},
doi={10.1109/NICS48868.2019.9023811},
ISSN={},
month={Dec},}
@ARTICLE{9099826,
author={Cheng, Zihuan and Pei, Hailong and Li, Shuai},
journal={IEEE Access}, title={Neural-Networks Control for Hover to High-Speed-Level-Flight Transition of Ducted Fan UAV With Provable Stability},
year={2020},
volume={8},
number={},
pages={100135-100151},
abstract={In this paper, we focus on the transition control of a ducted fan vertical take-off and landing (VTOL) unmanned aerial vehicle (UAV). To achieve a steady transition from hover to high-speed flight, a neural-networks-based controller is proposed to learn the system dynamics and compensate for the tracking error between the aircraft dynamics and the desired dynamic performance. In prior, we derive the nonlinear system model of the aircraft full-envelope dynamics. Then, we propose a novel neural-networks-based control scheme and apply it on the underactuated aircraft system. Key features of the proposed controller consist of projection operator, state predictor and dynamic-formed adaptive input. It is proved and guaranteed that the tracking errors of both state predictor and neural-networks weights are upper bounded during the whole neural-networks learning procedure. The very adaptive input is formed into a dynamic structure that helps achieve a reliable fast convergence performance of the proposed controller, especially in high-frequency disturbance conditions. Consequently, the closed-loop system of the aircraft is able to track a certain trajectory with desired dynamic performance. Satisfactory results are obtained from both simulations and practical flight test in accomplishing the designed flight course.},
keywords={Fans;Artificial neural networks;Aerodynamics;Aircraft;Aerospace control;Unmanned aerial vehicles;Atmospheric modeling;Ducted fan;fast convergence;high-speed flight;neural networks;transition control;unmanned aerial vehicle (UAV)},
doi={10.1109/ACCESS.2020.2997877},
ISSN={2169-3536},
month={},}
@ARTICLE{9154460,
author={Bai, Tong and Pan, Cunhua and Wang, Jingjing and Deng, Yansha and Elkashlan, Maged and Nallanathan, Arumugam and Hanzo, Lajos},
journal={IEEE Internet of Things Journal}, title={Dynamic Aerial Base Station Placement for Minimum-Delay Communications},
year={2021},
volume={8},
number={3},
pages={1623-1635},
abstract={Queuing delay is of essential importance in the Internet-of-Things scenarios where the buffer sizes of devices are limited. The existing cross-layer research contributions aiming at minimizing the queuing delay usually rely on either transmit power control or dynamic spectrum allocation. Bearing in mind that the transmission throughput is dependent on the distance between the transmitter and the receiver, in this context we exploit the agility of the unmanned-aerial-vehicle (UAV)-mounted base stations (BSs) for proactively adjusting the aerial BS (ABS)’s placement in accordance with wireless teletraffic dynamics. Specifically, we formulate a minimum-delay ABS placement problem for UAV-enabled networks, subject to realistic constraints on the ABS’s battery life and velocity. Its solutions are technically realized under three different assumptions in regard to the wireless teletraffic dynamics. The backward induction technique is invoked for both the scenario where the full knowledge of the wireless teletraffic dynamics is available, and for the case where only their statistical knowledge is available. In contrast, a reinforcement learning aided approach is invoked for the case when neither the exact number of arriving packets nor that of their statistical knowledge is available. The numerical results demonstrate that our proposed algorithms are capable of improving the system’s performance compared to the benchmark schemes in terms of both the average delay and of the buffer overflow probability.},
keywords={Wireless communication;Delays;Throughput;Vehicle dynamics;Base stations;Heuristic algorithms;Resource management;Delay optimal;dynamic programming;Markov decision process (MDP);reinforcement learning;unmanned aerial vehicle (UAV)},
doi={10.1109/JIOT.2020.3013752},
ISSN={2327-4662},
month={Feb},}
@ARTICLE{9437338,
author={Bayerlein, Harald and Theile, Mirco and Caccamo, Marco and Gesbert, David},
journal={IEEE Open Journal of the Communications Society}, title={Multi-UAV Path Planning for Wireless Data Harvesting With Deep Reinforcement Learning},
year={2021},
volume={2},
number={},
pages={1171-1187},
abstract={Harvesting data from distributed Internet of Things (IoT) devices with multiple autonomous unmanned aerial vehicles (UAVs) is a challenging problem requiring flexible path planning methods. We propose a multi-agent reinforcement learning (MARL) approach that, in contrast to previous work, can adapt to profound changes in the scenario parameters defining the data harvesting mission, such as the number of deployed UAVs, number, position and data amount of IoT devices, or the maximum flying time, without the need to perform expensive recomputations or relearn control policies. We formulate the path planning problem for a cooperative, non-communicating, and homogeneous team of UAVs tasked with maximizing collected data from distributed IoT sensor nodes subject to flying time and collision avoidance constraints. The path planning problem is translated into a decentralized partially observable Markov decision process (Dec-POMDP), which we solve through a deep reinforcement learning (DRL) approach, approximating the optimal UAV control policy without prior knowledge of the challenging wireless channel characteristics in dense urban environments. By exploiting a combination of centered global and local map representations of the environment that are fed into convolutional layers of the agents, we show that our proposed network architecture enables the agents to cooperate effectively by carefully dividing the data collection task among themselves, adapt to large complex environments and state spaces, and make movement decisions that balance data collection goals, flight-time efficiency, and navigation constraints. Finally, learning a control policy that generalizes over the scenario parameter space enables us to analyze the influence of individual parameters on collection performance and provide some intuition about system-level benefits.},
keywords={Path planning;Robot sensing systems;Training;Data collection;Wireless communication;Task analysis;Navigation;Internet of Things (IoT);map-based planning;multi-agent reinforcement learning (MARL);trajectory planning;unmanned aerial vehicle (UAV)},
doi={10.1109/OJCOMS.2021.3081996},
ISSN={2644-125X},
month={},}
@ARTICLE{9137257,
author={Chen, Dezhi and Qi, Qi and Zhuang, Zirui and Wang, Jingyu and Liao, Jianxin and Han, Zhu},
journal={IEEE Internet of Things Journal}, title={Mean Field Deep Reinforcement Learning for Fair and Efficient UAV Control},
year={2021},
volume={8},
number={2},
pages={813-828},
abstract={Unmanned aerial vehicles (UAVs) can provide flexible network coverage services. UAVs can be applied in a large number of scenarios, such as emergency communication and network access in areas without terrestrial network coverage. However, UAVs are limited to relatively short communication range and restricted energy resources. In extreme conditions such as disasters, there may also be a problem that the communication bandwidth is limited and the UAV cannot communicate with the server with a large amount of information, so a decentralized solution is expected. In addition, the interaction between multiple objectives and multiple UAVs leads to a huge state space, which makes large-scale practical applications difficult. To simplify complex interactions, we modeled the UAV control problem with mean-field game (MFG). We propose a new UAV control method, the mean-field trust region policy optimization (MFTRPO), which uses the MFG method to construct the Hamilton-Jacobi-Bellman/Fokker-Planck-Kolmogorov equation that obtains the optimal solution and solves the difficulties in the practical application through the trust region policy optimization and neural network feature embedding methods. The proposed method: 1) maximizes communication efficiency while ensuring fair communication range and network connectivity; 2) fuses the mean-field theory with deep reinforcement learning techniques; and 3) is scalable and adaptive. We conduct extensive simulations for performance evaluation. The simulation results have shown that MFTRPO significantly and consistently outperforms two commonly used baseline methods in terms of coverage, fairness, and energy consumption.},
keywords={Unmanned aerial vehicles;Internet of Things;Aerospace electronics;Games;Energy consumption;Mathematical model;Reinforcement learning;Mean field;multiagent deep reinforcement learning (DRL);trust region policy optimization (TRPO);unmanned aerial vehicle (UAV)},
doi={10.1109/JIOT.2020.3008299},
ISSN={2327-4662},
month={Jan},}
@ARTICLE{9406813,
author={Moon, Jiseon and Papaioannou, Savvas and Laoudias, Christos and Kolios, Panayiotis and Kim, Sunwoo},
journal={IEEE Internet of Things Journal}, title={Deep Reinforcement Learning Multi-UAV Trajectory Control for Target Tracking},
year={2021},
volume={8},
number={20},
pages={15441-15455},
abstract={In this article, we propose a novel deep reinforcement learning (DRL) approach for controlling multiple unmanned aerial vehicles (UAVs) with the ultimate purpose of tracking multiple first responders (FRs) in challenging 3-D environments in the presence of obstacles and occlusions. We assume that the UAVs receive noisy distance measurements from the FRs which are of two types, i.e., Line of Sight (LoS) and non-LoS (NLoS) measurements and which are used by the UAV agents in order to estimate the state (i.e., position) of the FRs. Subsequently, the proposed DRL-based controller selects the optimal joint control actions according to the Cramér–Rao lower bound (CRLB) of the joint measurement likelihood function to achieve high tracking performance. Specifically, the optimal UAV control actions are quantified by the proposed reward function, which considers both the CRLB of the entire system and each UAV’s individual contribution to the system, called global reward and difference reward, respectively. Since the UAVs take actions that reduce the CRLB of the entire system, tracking accuracy is improved by ensuring the reception of high quality LoS measurements with high probability. Our simulation results show that the proposed DRL-based UAV controller provides a highly accurate target tracking solution with a very low runtime cost.},
keywords={Target tracking;Unmanned aerial vehicles;Reinforcement learning;Navigation;Location awareness;Time measurement;State estimation;Multiagent deep reinforcement learning (DRL);multitarget tracking;unmanned aerial vehicle (UAV)},
doi={10.1109/JIOT.2021.3073973},
ISSN={2327-4662},
month={Oct},}
@INPROCEEDINGS{9488719,
author={Wang, Yuntao and Su, Zhou and Xu, Qichao and Li, Ruidong and Luan, Tom H.},
booktitle={IEEE INFOCOM 2021 - IEEE Conference on Computer Communications}, title={Lifesaving with RescueChain: Energy-Efficient and Partition-Tolerant Blockchain Based Secure Information Sharing for UAV-Aided Disaster Rescue},
year={2021},
volume={},
number={},
pages={1-10},
abstract={Unmanned aerial vehicles (UAVs) have brought numerous potentials to establish flexible and reliable emergency networks in disaster areas when terrestrial communication infrastructures go down. Nevertheless, potential security threats may occur on UAVs during data transmissions due to the untrustful environment and open-access UAV networking. Moreover, UAVs typically have limited battery and computation capacity, making them unaffordable to execute heavy security provisioning operations when carrying out complicated rescue tasks. In this paper, we develop RescueChain, a secure and efficient information sharing scheme for UAV-aided disaster rescue. Specifically, we first implement a lightweight blockchain-based framework to safeguard data sharing under disasters and immutably trace misbehaving entities. A reputation-based consensus protocol is devised to adapt the weakly connected environment with improved consensus efficiency and promoted UAVs' honest behaviors. Furthermore, we introduce a novel vehicular fog computing based off-chain mechanism by leveraging ground vehicles as moving fog nodes to offload UAVs' heavy data processing and storage tasks. To optimally stimulate vehicles to share their idle computing resources, we also design a two-layer reinforcement learning based incentive algorithm for UAVs and ground vehicles in the highly dynamic networks. Simulation results show that RescueChain can effectively accelerate consensus process, enhance user payoffs, and reduce delivery latency, compared with representative existing approaches.},
keywords={Simulation;Heuristic algorithms;Data processing;Land vehicles;Unmanned aerial vehicles;Information management;Consensus protocol;Unmanned aerial vehicle (UAV);disaster rescue;vehicular fog computing;blockchain;reinforcement learning},
doi={10.1109/INFOCOM42981.2021.9488719},
ISSN={2641-9874},
month={May},}
@ARTICLE{9035635,
author={Su, Zhou and Wang, Yuntao and Xu, Qichao and Zhang, Ning},
journal={IEEE Transactions on Dependable and Secure Computing}, title={LVBS: Lightweight Vehicular Blockchain for Secure Data Sharing in Disaster Rescue},
year={2022},
volume={19},
number={1},
pages={19-32},
abstract={In disaster areas, a large amount of data (e.g., rescue commands, road damage, and rescue experience) should be delivered among ground rescuing vehicles for safe driving and efficient rescue. When communication infrastructures are destroyed by disasters, unmanned aerial vehicles (UAVs) can be employed to perform immediate rescue missions in destroyed areas and assist data sharing for ground Internet of vehicles (IoV). However, in such UAV-assisted IoV under disaster situation, there exist potential security threats on data sharing among vehicles and UAVs because of the untrusted network environment, unreliable misbehavior tracing, and low-quality shared data. To address these issues, in this article, we develop a lightweight vehicular blockchain-enabled secure (LVBS) data sharing framework in UAV-aided IoV for disaster rescue. First, we propose a novel UAV and blockchain-assisted collaborative aerial-ground network architecture in disaster areas. Second, we develop a credit-based consensus algorithm in the lightweight vehicular blockchain to securely and immutably trace misbehaviors and record data transactions for UAVs and vehicles with improved efficiency and security in reaching consensus. Third, since UAVs and vehicles have little explicit knowledge of the whole network, we develop reinforcement learning-based algorithms to optimally schedule the pricing and quality of data sharing strategies for both data contributor and data consumer via trial and error. Finally, extensive simulations are conducted, which demonstrate that LVBS can effectively improve the security of consensus phase and promote high-quality data sharing.},
keywords={Land vehicles;Roads;Voting;Security;Consensus protocol;Complexity theory;Unmanned aerial vehicle (UAV);blockchain;reinforcement learning;data sharing;disaster rescue},
doi={10.1109/TDSC.2020.2980255},
ISSN={1941-0018},
month={Jan},}
@ARTICLE{9721621,
author={Kant, Ravi and Saini, Poonam and Kumari, Julee},
journal={IEEE Transactions on Artificial Intelligence}, title={Long-Short Term Memory Auto-Encoder based Position Prediction Model for Fixed-wing UAV during Communication Failure},
year={2022},
volume={},
number={},
pages={1-1},
abstract={Unmanned Aerial Vehicles (UAV's) safe flight is one of the most important tasks of Ground Control Stations (GCS). However, sometimes due to communication failure between Ground Data Terminal (GDT) and UAV, GCS is not able to ensure a safe flight which could be hazardous. In such conditions, an accurate UAV position finding (UPF) prediction becomes essential to serve as sustenance for UAVs. Hence, this paper proposes a UAVs position finding prediction model using a deep neural network application for successfully pointing the Ground Data Terminal towards UAV in real-time. The proposed work consists of three components, namely, data preprocessing, Long Short Term Memory Auto-Encoder (LSTM-AE) based deep learning model, and mathematical formulation to calculate the ground radar look angle. Firstly, we use different pre-processing techniques on a historical raw dataset for better visualization and generate patterns. To achieve this, Tensor Flow along with Keras packages have been used. Next, an LSTM auto-encoder deep learning model is applied to the same dataset in order to predict an accurate 4-dimensional (4D) position of the UAV. Lastly, the output from the LSTM auto-encoder model is used in a mathematical model to calculate the GDT look-angles called Azimuth and Elevation. Both the parameters have been used to point the GDT towards the predicted point on the Airspace. We evaluate our proposed model against famous evaluation matrices, namely, Mean Absolute Error (MAE), Mean Square Error (MSE) and Root Mean Square Error (RMSE) to validate the experimental results.},
keywords={Hidden Markov models;Trajectory;Predictive models;Autonomous aerial vehicles;Mathematical models;Atmospheric modeling;Real-time systems;Deep Learning;LSTM Auto-encoder;UAV Trajectory;UAV Position Finding Prediction},
doi={10.1109/TAI.2022.3153763},
ISSN={2691-4581},
month={},}
@ARTICLE{9416564,
author={Dong, Runze and Wang, Buhong and Cao, Kunrui},
journal={IEEE Wireless Communications Letters}, title={Deep Learning Driven 3D Robust Beamforming for Secure Communication of UAV Systems},
year={2021},
volume={10},
number={8},
pages={1643-1647},
abstract={Beamforming is a promising technique to enhance the security of wireless transmission, while the optimal beamforming design with partial channel state informing (CSI) is challenging. This letter develops a three-dimensional (3D) robust beamforming method for unmanned aerial vehicle (UAV) communication systems in the physical layer security perspective. Specifically, aiming at maximizing the average secrecy rate of the considered system, a precisely designed neural network is trained to optimize the beamformer for confidential signal and artificial noise (AN), with partial CSIs of legitimate UAV and eavesdropping UAV. Simulation experiments show that the proposed deep learning (DL) based method could achieve better secrecy rate and flexible beam steering than benchmarks.},
keywords={Array signal processing;Unmanned aerial vehicles;Neural networks;Eavesdropping;Wireless communication;Training;Three-dimensional displays;Beamforming;unmanned aerial vehicle (UAV);physical layer security;deep learning (DL);secrecy rate maximization},
doi={10.1109/LWC.2021.3075996},
ISSN={2162-2345},
month={Aug},}
@ARTICLE{9573510,
author={Peng, Manman and Han, Wenting and Li, Chaoqun and Huang, Shenjin},
journal={IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing}, title={Improving the Spatial and Temporal Estimation of Maize Daytime Net Ecosystem Carbon Exchange Variation Based on Unmanned Aerial Vehicle Multispectral Remote Sensing},
year={2021},
volume={14},
number={},
pages={10560-10570},
abstract={Accurate estimation of net ecosystem carbon exchange (NEE) is vital to regional carbon balance. Currently, NEE observations at the canopy scale are mainly based on the chamber method. However, the chamber method is labor intensive, time consuming, and measures only plot-scale NEE. It cannot reflect whole-field NEE with high spatial resolution. In this article, maize daytime NEE variations in four fields under different irrigation treatments in a semiarid area was measured using the chamber method, and the spectral reflectance in the maize canopy at noon was obtained using an unmanned aerial vehicle (UAV) multispectral system. We established a daytime NEE variation estimation model and up-scaled the level of NEE observations in maize canopy using UAV-based remote sensing. Twelve widely used vegetation indices were employed for NEE estimation. To obtain an optimal NEE variation estimation method, we compared the performance of several models, including simple linear regression, multiple stepwise regression, and four machine learning (ML) algorithms. Based on the comparison, the modified triangular vegetation index-2 is the best predictor for analyzing simple linear regression, with a coefficient of determination R2 = 0.719. Compared with the simple linear regression, there is no substantial increase in the R2 of NEE estimation based on multiple stepwise regression. However, the ML algorithms greatly improved R2 values. In particular, the gradient boosting regression model exhibits the best performance (R2 = 0.856). This article demonstrates that high-resolution UAV multispectral remote sensing shows great potential in improving the spatial and temporal estimating of maize daytime NEE variations.},
keywords={Crops;Irrigation;Ecosystems;Remote sensing;Unmanned aerial vehicles;Soil;Estimation;Gradient boosting regression (GBR);machine learning (ML);net ecosystem carbon exchange (NEE);unmanned aerial vehicle (UAV) multispectral systems;vegetation index},
doi={10.1109/JSTARS.2021.3119908},
ISSN={2151-1535},
month={},}
@ARTICLE{9712375,
author={Dai, Zhaojun and Zhang, Yan and Zhang, Wancheng and Luo, Xinran and He, Zunwen},
journal={IEEE Transactions on Signal and Information Processing over Networks}, title={A Multi-Agent Collaborative Environment Learning Method for UAV Deployment and Resource Allocation},
year={2022},
volume={8},
number={},
pages={120-130},
abstract={The dynamic position deployment and resource allocation of the unmanned aerial vehicle (UAV) communication networks has great significance in terms of interference management, coverage enhancement, and capacity improvement. Since the transmission power and energy resources of the UAVs are limited and the actual communication environment is complex and time-varying, it is challenging for the multiple UAVs to dynamically make decisions to ensure the communication performance of the system. Meanwhile, the centralized architecture may generate a certain degree of communication delay and affect communication efficiency. Facing this challenge, a resource allocation algorithm for the UAV networks based on multi-agent collaborative environment learning is proposed. This method is based on a distributed architecture. Each UAV is modeled as an independent agent, which improves the utility of the UAV networks through the dynamic selection decisions of its deployment position, transmission power, and occupied sub-channels. Each UAV learns the mapping of the network information to the position deployment and resource selection decisions based on the reinforcement learning algorithm according to partial of the state information it can observe. For the overall network, a multi-agent reinforcement learning method based on federated learning is designed on the purpose of realizing information interaction and combined dispatching of the UAVs. In the multi-agent system, the framework of federated learning is introduced to realize the sharing of non-privacy data among the UAVs. Simulation results indicate that the proposed method can effectively improve the network utility compared with the multi-agent deep reinforcement learning algorithm without information interaction.},
keywords={Resource management;Autonomous aerial vehicles;Communication networks;Reinforcement learning;Information processing;Machine learning algorithms;Heuristic algorithms;Federated learning;location deployment;reinforcement learning;resource allocation;unmanned aerial vehicle networks},
doi={10.1109/TSIPN.2022.3150911},
ISSN={2373-776X},
month={},}
@ARTICLE{9606925,
author={Afifi, Ghada and Gadallah, Yasser},
journal={IEEE Access}, title={Autonomous 3-D UAV Localization Using Cellular Networks: Deep Supervised Learning Versus Reinforcement Learning Approaches},
year={2021},
volume={9},
number={},
pages={155234-155248},
abstract={Unmanned aerial vehicles (UAVs) are becoming an integral part of numerous commercial and military applications. In many of these applications, the UAV is required to self-navigate in highly dynamic urban environments. This means that the UAV must have the ability to determine its location in an autonomous and real time manner. Existing localization techniques rely mainly on the Global Positioning System (GPS) and do not provide a reliable real time localization solution, particularly in dense urban environments. Our objective is to propose an effective alternative solution to enable the UAV to autonomously determine its location independent of the GPS and without message exchanges. We therefore propose utilizing the existing 5G cellular infrastructure to enable the UAV to determine its 3-D location without the need to interact with the cellular network. We formulate the UAV localization problem to minimize the error of the RSSI measurements from the surrounding cellular base stations. While exact optimization techniques can be applied to accurately solve such a problem, they cannot provide the real time calculation that is needed in such dynamic applications. Machine learning based techniques are strong candidates to provide an attractive alternative to provide a near-optimal localization solution with the needed practical real-time calculation. Accordingly, we propose two machine learning-based approaches, namely, deep neural network and reinforcement learning based approaches, to solve the formulated UAV localization problem in real time. We then provide a detailed comparative analysis for each of the proposed localization techniques along with a comparison with the optimization-based techniques as well as other techniques from the literature.},
keywords={Location awareness;5G mobile communication;Real-time systems;Global Positioning System;Unmanned aerial vehicles;Reinforcement learning;Base stations;5G;UAV 3-D autonomous localization;optimization;deep learning;reinforcement learning;neural networks;Q-learning},
doi={10.1109/ACCESS.2021.3126775},
ISSN={2169-3536},
month={},}
@ARTICLE{9363308,
author={Ding, Ruijin and Xu, Yadong and Gao, Feifei and Shen, Xuemin},
journal={IEEE Internet of Things Journal}, title={Trajectory Design and Access Control for Air-Ground Coordinated Communications System with Multi-Agent Deep Reinforcement Learning},
year={2021},
volume={},
number={},
pages={1-1},
abstract={Unmanned Aerial Vehicle (UAV)-assisted communications has attracted increasing attention recently. This paper investgates air-ground coordinated communications system, in which trajectories of air UAV base stations (UAV-BSs) and access control of ground users (GUs) are jointly optimized. We formulated this optimization problem as a mixed cooperative-competitive game, where each GU competes for the limited resources of UAV-BSs to maximize its own throughput by accessing a suitable UAV-BS, and UAV-BSs cooperate with each other and design their trajectories to maximize the defined fair throughput to improve the total throughput and keep the GU fairness. Moreover, the action space of GUs is discrete, while that of UAV-BS is continuous. To tackle this hybrid action space issue, we transform the discrete actions into continuous action probabilities and propose a multi-agent deep reinforcement learning (MADRL) approach, named AG-PMADDPG (air-ground probabilistic multi-agent deep deterministic policy gradient). With well-designed rewards, AG-PMADDPG can coordinate two types of agents, UAV-BSs and GUs, to achieve their own objectives based on local observations. Simulation results demonstrate that AG-PMADDPG can outperform the benchmark algorithms in terms of throughput and fairness.},
keywords={Trajectory;Throughput;Access control;Optimization;Communication systems;Training;Reinforcement learning;Air-ground coordinated communications;user access control;UAV trajectory design;fair communication;multi-agent deep reinforcement learning.},
doi={10.1109/JIOT.2021.3062091},
ISSN={2327-4662},
month={},}


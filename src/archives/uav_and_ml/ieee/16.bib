@INPROCEEDINGS{9554481,
author={Talreja, Pratyush and Durbha, Surya S and Shinde, Rajat C. and Potnis, Abhishek V.},
booktitle={2021 IEEE International Geoscience and Remote Sensing Symposium IGARSS}, title={Real-Time Embedded HPC Based Earthquake Damage Mapping Using 3D LiDAR Point Clouds},
year={2021},
volume={},
number={},
pages={8241-8244},
abstract={In the early hours following the earthquake, supporting humanitarian actions like rescue operations and relief distribution is the primary objective of the rescue managers. The damage mapping can be performed using reliable data that can be obtained from high-resolution satellite imagery but obtaining satellite imagery can be challenging for some days post disaster due to revisit time. Considering the disaster response timing, Unmanned Aerial Vehicles (UAV) are used because ground transportation systems are ineffective due to road blockage. In this work, we make use of Light Detection and Ranging (LiDAR) 3D point cloud data obtained for Haiti Earthquake. The focus of our work is to develop and implement an approach for LiDAR data classification to enable Earthquake damage mapping and detection. This is obtained by running our deep learning network on NVIDIA Jetson Nano embedded supercomputing platform. This approach takes the advantage of embedded High-Performance computing and low power consumption capabilities of Jetson Nano which enhances the classification and promotes rapid response which is the key to manage post-disaster activities. Jetson Nano is a feasible option which provides a GPU architecture that is optimized for running energy-aware deep learning models and which generates the results in real or near-real time. We envisage that our work could be extended to perform near real-time classification of LiDAR point clouds in a post earthquake scenario.},
keywords={Deep learning;Performance evaluation;Laser radar;Three-dimensional displays;Satellites;Power demand;Earthquakes;LiDAR;High Performance Computing;Deep Learning;Damage Mapping;Earthquake},
doi={10.1109/IGARSS47720.2021.9554481},
ISSN={2153-7003},
month={July},}
@INPROCEEDINGS{9323651,
author={Hoxha, Genc and Melgani, Farid},
booktitle={IGARSS 2020 - 2020 IEEE International Geoscience and Remote Sensing Symposium}, title={Remote Sensing Image Captioning with SVM-Based Decoding},
year={2020},
volume={},
number={},
pages={6734-6737},
abstract={With the fast development of remote sensing (RS) technology we are now able to acquire high resolution images. To cope with the new challenges of analyzing such images, a recently introduced tool is RS image captioning (IC). With respect to conventional techniques such as scene classification, RSIC provides more information about an image. It aims to generate a description that summarizes the content of an image. Most of RSIC systems are based on deep learning frameworks (encoder-decoder). The performance of these frameworks strongly depend on the number of annotated samples used during training. In this paper, we propose an alternative RSIC system for a relatively small dataset based on support vector machines (SVMs). A pre-trained CNN is used to extract the image visual features and a network of SVMs is used to generate the descriptions. Experimental results on a RS image archive composed of images acquired by unmanned aerial vehicles (UAV), show that the proposed IC system could be an interesting alternative to deep learning frameworks when only small training samples are available.},
keywords={Support vector machines;Remote sensing;Training;Feature extraction;Recurrent neural networks;Decoding;Visualization;Image captioning;support vector machines;unmanned aerial vehicles (UAV)},
doi={10.1109/IGARSS39084.2020.9323651},
ISSN={2153-7003},
month={Sep.},}
@INPROCEEDINGS{9502749,
author={Kopečný, Ladislav and Hnidka, Jakub},
booktitle={2021 International Conference on Military Technologies (ICMT)}, title={Aerial Landscape Recognition via Multi-Input Neural Network},
year={2021},
volume={},
number={},
pages={1-5},
abstract={Throughout the last decade, the advancements in the hardware allow use for wider applications of the unmanned aerial vehicles (UAV). UAVs feature significant advantages in autonomous aerial landscape mapping and recognition (ALR) over traditional methods due to their high level of operationality and mission repeatability, along with a simple alteration of e.g., on board remote sensors. ALR system based on convolutional neural networks is proposed. The system is designed with real-time capabilities. Data classification based on histogram and Gabor filter is explored on commercially available aerial images. The research roadmap designed to offload the dependency of the process on flight testing to improve the cost-efficiency of the development is proposed as well.},
keywords={Histograms;Military computing;Neural networks;Software algorithms;Unmanned aerial vehicles;Real-time systems;Software;Unmanned Aerial Vehicles;Multi-input neural networks;aerial landscape recognition;histogram;Principal Component Analysis;Gabor Filter},
doi={10.1109/ICMT52455.2021.9502749},
ISSN={},
month={June},}
@INPROCEEDINGS{9324354,
author={Karami, Azam and Crawford, Melba and Delp, Edward J.},
booktitle={IGARSS 2020 - 2020 IEEE International Geoscience and Remote Sensing Symposium}, title={A Weakly Supervised Deep Learning Approach for Plant Center Detection and Counting},
year={2020},
volume={},
number={},
pages={1584-1587},
abstract={Deep learning applications are rapidly advancing in agriculture, and phenotyping in particular. Identifying the locations of plant centers and counting are critical for assessing stand quality. Yet, its precise measurement after the emergence of plants is impractical in large-scale production fields due to the labor required. In this paper, we propose a weakly supervised deep learning framework for detecting the centers and counting maize plants using high resolution georeferenced RGB data acquired from a UAV platform. We evaluate the performance of the proposed method over two dates. The obtained results show that the proposed method can efficiently identify the locations of plant centers, and thereby the plant counts, reducing both the manual field counting and human labeling required for image-based analysis.},
keywords={Training;Image segmentation;Detectors;Deep learning;Estimation;Random access memory;Pattern recognition;Weakly Supervised;Deep Learning;Phe-notyping;Plant Centers;Counting},
doi={10.1109/IGARSS39084.2020.9324354},
ISSN={2153-7003},
month={Sep.},}
@INPROCEEDINGS{9356802,
author={Zhang, Ke and Houqiang and Huang, Wenli},
booktitle={2020 7th International Forum on Electrical Engineering and Automation (IFEEA)}, title={Defect Detection of Anti-vibration Hammer Based on Improved Faster R-CNN},
year={2020},
volume={},
number={},
pages={889-893},
abstract={The damage or corrosion of the anti-vibration hammer will endanger the safe operation in the high-voltage transmission line. In this paper, the images of transmission line acquired during UAV patrol inspection are used as a research object. A deep learning method is proposed to improve the detection accuracy and defect identification of anti-vibration hammer in the influence of light variation, complex background, and small targets. Firstly, the original images are enhanced by using a Retinex algorithm to reduce the influence of light variation and shadow. Then the anti-vibration hammers are detected by using a deep learning framework called Faster Region-based Convolutional Neural Network (Faster R-CNN), in which the Feature Pyramid Networks (FPN) is used to extract and fuse the multi-scale feature of the image. A two-stage cascade Region Proposal Network (RPN) is designed to generate regions proposal. In the first stage, a standard RPN is used and the anchor is the proposal obtained by the sliding window. In the second stage RPN, the output proposal from the first RPN is as the new anchor position and a more accurate proposal can be obtained. Finally, the proposed boxes and the original feature map are sent to the subsequent network to complete the final defects classification and position regression of the anti-vibration hammer. Experimental results show that the proposed method improves the detection accuracy in 4 kinds of anti-vibration hammer defects, which has a good reference for the popularization of intelligent inspection of high-voltage transmission lines.},
keywords={Deep learning;Power transmission lines;Fuses;Inspection;Feature extraction;Proposals;Standards;Anti-vibration Hammer Defect Detection;Faster RCNN;Feature Pyramid Network FPN;Regional Proposal Network RPN},
doi={10.1109/IFEEA51475.2020.00186},
ISSN={},
month={Sep.},}
@INPROCEEDINGS{8793321,
author={Choi, Jaewan and Park, Woo-Chan},
booktitle={2019 34th International Technical Conference on Circuits/Systems, Computers and Communications (ITC-CSCC)}, title={Object movement highlighting technique using a deep-learning based object detector for effective UAV control},
year={2019},
volume={},
number={},
pages={1-4},
abstract={This paper propose a method that highlights the objects, which are moving in real-time, using a deep-learning based detector. The method first detects the objects in real-time, using the state-of-art deep learning object detector named “YOLOv3”. After that, for effective Unmanned Aerial Vehicles (UAV) control, the objects, which were detected, will be highlighted by the image difference function. In this part, the most important job is to know which object has moved and how much it has moved. Our study, focus on these two parts. Using the Bounding box size sort, the object bounding boxes will be sorted from small size to big size boxes and with the Pixel winning function, the object boxes will take the pixels that belong to them. At last, with each object's pixel value the percentage of the object's movement will be calculated.},
keywords={Detectors;Object detection;Drones;Webcams;Image color analysis;image difference;object detection;bounding box size sort;pixel winning function},
doi={10.1109/ITC-CSCC.2019.8793321},
ISSN={},
month={June},}
@INPROCEEDINGS{8517641,
author={Peng, Bo and Li, Yuxia and He, Lei and Fan, Kunlong and Tong, Ling},
booktitle={IGARSS 2018 - 2018 IEEE International Geoscience and Remote Sensing Symposium}, title={Road Segmentation of UAV RS Image Using Adversarial Network with Multi-Scale Context Aggregation},
year={2018},
volume={},
number={},
pages={6935-6938},
abstract={Semantic segmentation using adversarial networks has been approved to produce the better artificial results in image processing fields. Focused on current Deep Convolutional Neural Networks (DCNNs), since the convolutional kernel size has been fixed in every convolutional operation, the small objects would be ignored with large convolutional kernel size, and the segmentation result of large objects is not continuous with small convolutional kernel size. The paper developed a semantic segmentation model that combined the adversarial networks with multi-scale context aggregation. Further, the model was applied to road segmentation of UAV RS images. The experimental results of this semantic segmentation model with multi-scale context aggregation has a better performance for road segmentation and fit well with the reference standard results. It can improve the road segmentation accuracy obviously in the situation where there are other small regions whose shape or color is similar to road regions in UAV RS images.},
keywords={Image segmentation;Roads;Semantics;Generators;Training;Context modeling;Kernel;Road Segmentation;multi-scale context aggregation;Image processing;Adversarial Network;UAV image},
doi={10.1109/IGARSS.2018.8517641},
ISSN={2153-7003},
month={July},}
@INPROCEEDINGS{9477912,
author={Ünlü, Aybüke and Yüksel, Tolga},
booktitle={2021 29th Signal Processing and Communications Applications Conference (SIU)}, title={Dört Kanatlı İnsansız Hava Araçları İçin Yapay Sinir Ağları İle Konum Tabanlı Görsel Servolama Position Based Visual Servoing with Artificial Neural Networks for Quadrotor-type Unmanned Aerial Vehicles},
year={2021},
volume={},
number={},
pages={1-4},
abstract={UAVs offer many advantages over manned vehicles and their application area expands in time passes. Particularly, interest in UAVs with rotary wing types is increasing. Increasing interest in these vehicles has spawned many different controller designs. In this study, estimating the pose of the vehicle according to the image features with the help of a single camera mounted on the quadrotor and then positionbased visual servoing, a technique that allows the vehicle to be controlled by using the image features, was used. In this study position-based visual servoing (PBVS); 3D parameter estimates of the vehicle pose were implemented with artificial neural networks.},
keywords={Transmission line matrix methods;Robots;Kalman filters;Visual servoing;Visualization;Servosystems;Unmanned aerial vehicles;quadrotor-type Unmanned Aerial Vehicles;position based visual servoing;artificial neural networks},
doi={10.1109/SIU53274.2021.9477912},
ISSN={2165-0608},
month={June},}
@INPROCEEDINGS{8127090,
author={Kellenberger, Benjamin and Volpi, Michele and Tuia, Devis},
booktitle={2017 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)}, title={Fast animal detection in UAV images using convolutional neural networks},
year={2017},
volume={},
number={},
pages={866-869},
abstract={Illegal wildlife poaching poses one severe threat to the environment. Measures to stem poaching have only been with limited success, mainly due to efforts required to keep track of wildlife stock and animal tracking. Recent developments in remote sensing have led to low-cost Unmanned Aerial Vehicles (UAVs), facilitating quick and repeated image acquisitions over vast areas. In parallel, progress in object detection in computer vision yielded unprecedented performance improvements, partially attributable to algorithms like Convolutional Neural Networks (CNNs). We present an object detection method tailored to detect large animals in UAV images. We achieve a substantial increase in precision over a robust state-of-the-art model on a dataset acquired over the Kuzikus wildlife reserve park in Namibia. Furthermore, our model processes data at over 72 images per second, as opposed 3 for the baseline, allowing for real-time applications.},
keywords={Proposals;Predictive models;Wildlife;Feature extraction;Remote sensing},
doi={10.1109/IGARSS.2017.8127090},
ISSN={2153-7003},
month={July},}
@INPROCEEDINGS{9679260,
author={Zhang, Mingjiang and Wang, Chengyuan and Yang, Jungang and Zheng, Kouquan},
booktitle={2021 14th International Symposium on Computational Intelligence and Design (ISCID)}, title={Research on Engineering Vehicle Target Detection in Aerial Photography Environment based on YOLOX},
year={2021},
volume={},
number={},
pages={254-256},
abstract={The aerial target detection of engineering vehicles such as excavators is the key technology for UAV inspection of optical cable lines and petroleum pipelines. It is proposed to apply the deep learning YOLOX (You Only Look Once version X) target detection algorithm to the target detection of engineering vehicles in aerial images. Based on the Pytorch deep learning framework, through the production of engineering vehicle aerial photography data sets, simulation has realized the target detection of engineering vehicles, and its target recognition AP@0.5:0.95 value reaches 59.38%. Based on the same data set and training conditions, its detection accuracy and speed surpass classic algorithms such as YOLOv4 and YOLOv5. The simulation results can provide a certain reference for the research of aerial inspection and maintenance of underground pipeline facilities.},
keywords={Photography;Deep learning;Training;Target recognition;Simulation;Pipelines;Object detection;YOLOX;Engineering vehicles target detection;Aerial inspection;Deep learning},
doi={10.1109/ISCID52796.2021.00066},
ISSN={2473-3547},
month={Dec},}
@INPROCEEDINGS{8898969,
author={Martins, José and Junior, José Marcato and Menezes, Geazy and Pistori, Hemerson and Sant´Ana, Diego and Gonçalves, Wesley},
booktitle={IGARSS 2019 - 2019 IEEE International Geoscience and Remote Sensing Symposium}, title={Image Segmentation and Classification with SLIC Superpixel and Convolutional Neural Network in Forest Context},
year={2019},
volume={},
number={},
pages={6543-6546},
abstract={Unmanned aerial vehicles (UAVs) are platforms suitable for obtaining information utilizing sensors in a great variety of areas and enviroments, thus in this context, this paper objective was to identify trees in images collected using UAV high-resolution imagery, with the digital approach of superpixel segmentation and convolutional neural networks. A forest environment was analyzed in the form of an orthomosaic that was produced using 423 images. Superpixels were generated using the Simple Linear Iterative Clustering (SLIC) method, considering only two classes for the classification: trees and background. The generation of superpixels (segmentation) and classification were performed considering the configurations: 2000, 3000 and 4000 segments, sigma 5 and compactness 10 for SLIC and 100% transfer of learning. For the purposes of classification, the deep convolutional networks were adopted through ResNet-50 architecture, the weights of this network were previously trained in an Image bank and later the bank of images of superpixels underwent a fine-tuning. The experiments obtained a maximum classification accuracy of 89% with 3000 superpixels distinction between canopies and Background.},
keywords={Unmanned aerial vehicle (UAV) platforms;Convolutional Neural Network (CNN);high-spatial-resolution images;forest segmentation},
doi={10.1109/IGARSS.2019.8898969},
ISSN={2153-7003},
month={July},}
@INPROCEEDINGS{9389908,
author={Qu, Jingyi and Bi, Xinjie and Liu, Shanliang},
booktitle={2021 IEEE 2nd International Conference on Big Data, Artificial Intelligence and Internet of Things Engineering (ICBAIE)}, title={Research on recognition algorithm of LSS based on video in airport clearance area},
year={2021},
volume={},
number={},
pages={110-113},
abstract={LSS (Low, Small and Slow) targets have characteristics of low cost, simple operation, easy to carry, low take-off requirements, strong sudden takeoff, and difficult to find and handle. With the development of aviation industry, the cases of LSS flying illegally and used in terrorist attacks are increasing day by day. It will not only cause great negative effects on economy, but also have serious influence on the national security and the normal development of the national economy. In order to eliminate the threat of illegal flight of UAV in the airport clearance area to the safe operation of airport, a LSS recognition algorithm based on the deep learning was proposed in the paper. Compared with other detection types, the video detection was used in the algorithm, which has many advantages such as strong visualization, low cost and fast detection speed. By using the Yolov3 object detection model, one of the most popular deep learning methods, the problem of low accuracy of small objects such as LSS can be solved. The experiments show that the Yolov3 model can improve the accuracy for small objects and can effectively detect the LSS. Thus, the necessary precondition for the subsequent LSS countermeasures can be provided, and the safe operation of the airport can be ensured.},
keywords={Deep learning;Atmospheric modeling;Training data;Object detection;Airports;Internet of Things;National security;Deep learning;convolution neutral network;object detection;LSS},
doi={10.1109/ICBAIE52039.2021.9389908},
ISSN={},
month={March},}
@INPROCEEDINGS{7860044,
author={Mukadam, Kausar and Sinh, Aishwarya and Karani, Ruhina},
booktitle={2016 International Conference on Computing Communication Control and automation (ICCUBEA)}, title={Detection of landing areas for unmanned aerial vehicles},
year={2016},
volume={},
number={},
pages={1-5},
abstract={Unmanned aerial vehicles (UAV), also referred to as drones, are a growing field in computer science with applications in military systems, delivery services, emergency relief and evacuation. One of the primary obstructions to the allowance of UAV journeys over populated areas is the lack of sophisticated automated systems that detect drone landing sites. In this paper, we propose a landing area detection system using machine learning and image processing. This system compares the suitability of various features (RGB Color Model, HSV Color Model, LBP, Edge Density) in determining a suitable drop-off point. Classification on these features has been carried out using Support Vector Machines (Linear, Polynomial and RBF Kernel).},
keywords={Image edge detection;Image color analysis;Support vector machines;Feature extraction;Kernel;Unmanned aerial vehicles;Computers;Support Vector Machines;RGB Colour Model;Sobel Edge Detection;HSV Colour Model;Canny Edge Detection;Local Binary Pattern},
doi={10.1109/ICCUBEA.2016.7860044},
ISSN={},
month={Aug},}
@INPROCEEDINGS{8023640,
author={Cao, Zhengjiang and Zhao, Kuang and Fang, Qiang and Kong, Weiwei and Tang, Dengqing and Hu, Tianjiang},
booktitle={2017 18th International Conference on Advanced Robotics (ICAR)}, title={Enabling ∼100fps detection on a landing unmanned aircraft for its on-ground vision-based recovery},
year={2017},
volume={},
number={},
pages={407-411},
abstract={In this paper, a deep learning inspired solution is proposed and developed to enable timeliness and practicality of the pre-existing ground stereo vision guidance system for flxed-wing UAVs' safe landing. Since the ground guidance prototype was restricted within applications due to its untimeliness, eventually the vision-based detection less than 15 fps (frame per second). Under such circumstances, we employ a regression based deep learning algorithm into automatic detection on the flying aircraft in the landing sequential images. The system architecture is upgraded so as to be compatible with the novel deep learning requests, and furthermore, annotated datasets are conducted to support training and testing of the regression-based learning detection algorithm. Experimental results validate that the detection attaches 100 fps or more while the localization accuracy is kept in the same level.},
keywords={Machine learning;Prototypes;Unmanned aerial vehicles;Testing;Graphics processing units;Aircraft;Object detection;Safe landing;stereo vision;aerial robots;unmanned aerial vehicle (UAV);100 fps},
doi={10.1109/ICAR.2017.8023640},
ISSN={},
month={July},}
@INPROCEEDINGS{9610752,
author={Mazzilli, Irene and Mirabile, Gianmario and Lino, Paolo and Maione, Guido and Rybakov, Alexey V. and Svishchev, Nikolai and Blanco, Ileana and De Bellis, Luigi and Luvisi, Andrea},
booktitle={2021 17th International Workshop on Cellular Nanoscale Networks and their Applications (CNNA)}, title={UAV Inspection of Olive Trees for the Detection of Xylella Fastidiosa Disease Using Neural Networks},
year={2021},
volume={},
number={},
pages={1-4},
abstract={This paper presents a fully automated procedure for the detection of trees affected by Xylella Fastidiosa using UAVs and convolutional neural networks. Drones are able to collect an adequate number of olive leaf images to detect the presence of disease symptoms. Several neural networks are trained to compare results and determine the best solution.},
keywords={Conferences;Neural networks;Inspection;Nanoscale devices;Convolutional neural networks;Diseases;Drones;Drones;Xylella Fastidiosa;Convolutional Neural Network;EfficientDet},
doi={10.1109/CNNA49188.2021.9610752},
ISSN={},
month={Sep.},}
@INPROCEEDINGS{6475088,
author={Chumachenko, Olena and Gorbatiuk, Vladyslav},
booktitle={2012 2nd International Conference "Methods and Systems of Navigation and Motion Control" (MSNMC)}, title={Method for predicting a failure risk of the UAV navigation systems},
year={2012},
volume={},
number={},
pages={63-65},
abstract={This paper introduces a new algorithm for predicting a failure risk of the UAV navigation systems using genetic algorithms, fuzzy rules and neural networks. This approach combines the advantages of fuzzy rules and neural networks such as interpretability and learning ability, while using genetic algorithm to construct an initial set of fuzzy rules.},
keywords={Navigation;Biological neural networks;Xenon;Artificial neural networks;XML;Convergence;Psychology;Neural networks;fuzzy rules;genetic algorithm},
doi={10.1109/MSNMC.2012.6475088},
ISSN={},
month={Oct},}
@INPROCEEDINGS{8600838,
author={Anwar, Malik Aqeel and Raychowdhury, Arijit},
booktitle={2018 25th International Conference on Mechatronics and Machine Vision in Practice (M2VIP)}, title={NavREn-Rl: Learning to fly in real environment via end-to-end deep reinforcement learning using monocular images},
year={2018},
volume={},
number={},
pages={1-6},
abstract={We present NavREn-RL, an approach to NAVigate an unmanned aerial vehicle in an indoor Real ENvironment via end-to-end reinforcement learning (RL). A suitable reward function is designed keeping in mind the cost and weight constraints for micro drone with minimum number of sensing modalities. Collection of small number of expert data and knowledge based data aggregation is integrated into the RL process to aid convergence. Experimentation is carried out on a Parrot AR drone in different indoor arenas and the results are compared with other baseline technologies. We demonstrate how the drone successfully avoids obstacles and navigates across different arenas. Video of the drone navigating using the proposed approach can be seen at https://youtu.be/yOTkTHUPNVY.},
keywords={Drones;Navigation;Computer crashes;Cameras;Sensors;Collision avoidance;Neural networks},
doi={10.1109/M2VIP.2018.8600838},
ISSN={},
month={Nov},}
@INPROCEEDINGS{8430922,
author={Elnaggar, Mahmoud and Bezzo, Nicola},
booktitle={2018 Annual American Control Conference (ACC)}, title={An IRL Approach for Cyber-Physical Attack Intention Prediction and Recovery},
year={2018},
volume={},
number={},
pages={222-227},
abstract={Modern autonomous cyber-physical systems have been demonstrated to be vulnerable to cyber-attacks like sensor spoofing in which an attacker stealthily compromises sensor readings to hijack the system toward undesired and possibly hazardous states. The majority of security techniques developed today are, however, reactive and concerned with detection and interdiction of attacks without considering predicting the intention of the attack. To deal with such problem, we propose a Bayesian Inverse Reinforcement Learning technique that leverages the history of sensor data and control inputs to predict the goal of sensor spoofing attacks, determine which sensors are compromised, and recover the system. We also propose an active exploration framework to improve the convergence rate of the intention inference before reaching undesired states. The proposed approach is validated with simulation results on a quadrotor unmanned aerial vehicle navigation case study.},
keywords={Robot sensing systems;Learning (artificial intelligence);Unmanned aerial vehicles;Bayes methods;Global Positioning System;Task analysis},
doi={10.23919/ACC.2018.8430922},
ISSN={2378-5861},
month={June},}
@INPROCEEDINGS{8999689,
author={Keong, Choo Wai and Shin, Hyo-Sang and Tsourdos, Antonios},
booktitle={2019 Workshop on Research, Education and Development of Unmanned Aerial Systems (RED UAS)}, title={Reinforcement Learning for Autonomous Aircraft Avoidance},
year={2019},
volume={},
number={},
pages={126-131},
abstract={Effective collision avoidance strategy is crucial for the operation of any unmanned aerial vehicle. In order to maximise the safety and the effectiveness of the collision avoidance strategy, the strategy needs to solve for choosing the best action by taking account of any situation. In this paper, the traditional control method is replaced by a Reinforcement Learning (RL) method called Deep-Q-Network (DQN) and investigate the performance of DQN in aerial collision avoidance. This paper formulate the collision avoidance process as a Markov Decision Process (MDP). DQN will be trained in two simulated scenarios to approximate the best policy which will give us the best action for performing the collision avoidance. First simulation is head-to-head collision simulation following with head-to-head with a crossing aircraft simulation.},
keywords={},
doi={10.1109/REDUAS47371.2019.8999689},
ISSN={},
month={Nov},}
@ARTICLE{9171419,
author={Cubuktepe, Murat and Jansen, Nils and Alshiekh, Mohammed and Topcu, Ufuk},
journal={IEEE Transactions on Automatic Control}, title={Synthesis of Provably Correct Autonomy Protocols for Shared Control},
year={2021},
volume={66},
number={7},
pages={3251-3258},
abstract={We synthesize shared control protocols subject to probabilistic temporal logic specifications. Specifically, we develop a framework in which a human and an autonomy protocol can issue commands to carry out a certain task. We blend these commands into a joint input to a robot. We model the interaction between the human and the robot as a Markov decision process representing the shared control scenario. Using inverse reinforcement learning, we obtain an abstraction of the human's behavior. We use randomized strategies to account for randomness in human's decisions, caused by factors such as the complexity of the task specifications or imperfect interfaces. We design the autonomy protocol to ensure that the resulting robot behavior satisfies given safety and performance specifications in probabilistic temporal logic. Additionally, the resulting strategies generate behavior as similar to the behavior induced by the human's commands as possible. We solve the underlying problem efficiently using quasiconvex programming. Case studies involving autonomous wheelchair navigation and unmanned aerial vehicle mission planning showcase the applicability of our approach.},
keywords={Protocols;Task analysis;Wheelchairs;Markov processes;Probabilistic logic;Mobile robots;Human-robot interaction;Markov processes;optimization;robotics},
doi={10.1109/TAC.2020.3018029},
ISSN={1558-2523},
month={July},}
@INPROCEEDINGS{6608784,
author={Gururajan, Srikanth and Fravolini, Mario L. and Chao, Haiyang and Rhudy, Matthew and Napolitano, Marcello R.},
booktitle={21st Mediterranean Conference on Control and Automation}, title={Performance evaluation of neural network based approaches for airspeed Sensor Failure Accommodation on a small UAV},
year={2013},
volume={},
number={},
pages={603-608},
abstract={Traditional approaches to sensor fault tolerance for flight control systems have been based on triple or quadruple physical redundancy. However, recent events have highlighted the criticality of "common mode" failures on the Air Data System (ADS). In fact, since the parameters of flight control laws are typically scheduled as a function of airspeed, incorrect readings from the ADS can lead to potentially catastrophic conditions. In this paper, we describe the evaluation of an analytical redundancy-based approach to the problem of Sensor Failure Accommodation following simulated failures on the ADS of a research UAV, using Artificial Neural Networks (ANNs). Specifically, two different neural networks are evaluated - the Extended Minimal Resource Allocating Network and a Multilayer Feedforward NN. These neural networks are trained and validated using experimental flight data from the WVU YF-22 research aircraft which was designed, manufactured, instrumented, and flight tested by researchers at the Flight Control Systems Laboratory at West Virginia University. The performance of the two approaches is evaluated in terms of the statistics of the tracking error in the estimation of the airspeed, as compared to actual measurements from the ADS, operating under nominal conditions.},
keywords={Training;Artificial neural networks;Aircraft;Neurons;Aerospace control;Redundancy;Standards},
doi={10.1109/MED.2013.6608784},
ISSN={},
month={June},}
@ARTICLE{9665421,
author={Albanese, Antonio and Sciancalepore, Vincenzo and Costa-Pérez, Xavier},
journal={IEEE Communications Magazine}, title={First Responders Got Wings: UAVs to the Rescue of Localization Operations in Beyond 5G Systems},
year={2021},
volume={59},
number={11},
pages={28-34},
abstract={Natural and human-made disasters have dramatically increased in recent decades. Given the strong relationship between first responders' localization time and the final number of deaths, the modernization of search and rescue operations has become imperative. In this context, unmanned-aerial-vehicle-based solutions are the most promising candidates to take on the localization challenge by leveraging emerging technologies such as artificial Intelligence, reconfigurable intelligent surfaces, and orthogonal time-frequency space modulations. In this article, we capitalize on such recently available techniques by shedding light on the main challenges and future opportunities to boost the localization performance of state-of-the-art techniques to give birth to unprecedentedly effective missing victims localization solutions.},
keywords={Location awareness;Time-frequency analysis;OFDM;Modulation;Reconfigurable intelligent surfaces;Position measurement;Doppler effect},
doi={10.1109/MCOM.101.2100273},
ISSN={1558-1896},
month={November},}
@INPROCEEDINGS{8798329,
author={Liu, Xu and He, Yuqing and Chen, Bo and Hou, Yongqiang and Bi, Kaiyuan and Li, Decai},
booktitle={2019 International Conference on Unmanned Aircraft Systems (ICUAS)}, title={A Vision-based Unmanned Aircraft System for Autonomous Grasp amp; Transport},
year={2019},
volume={},
number={},
pages={1186-1193},
abstract={The progress in sensor technologies, computer capabilities and artificial intelligence has endowed the unmanned aircraft system (UAS) with more autonomous abilities. Motivated by the 6th International Unmanned Aerial Vehicle Innovation Grand Prix (UAVGP), a UAS with high degree of autonomy was developed to perform the mission of building a simulated tower using prefabricated components. According to the requirement of the competition, the UAS was designed and implemented from the following four parts: 1) navigation and control, 2) recognition and location, 3) grasp and construction, and 4) task planning and scheduling. Different levels of autonomy have been given to the UAS based on these parts. The system hardware was developed on a quadrotor platform by integrating various components, including sensors, computers, power and grasp mechanism. Software which included precise navigation, mission planning, real-time perception and control was implemented and integrated with the developed UAS hardware. The performance in the test environment and actual competition showed that the UAS could perform the mission without human intervention with high autonomy and reliability. This paper addresses the major components and development process of the UAS and describes its application to the practical mission.},
keywords={Navigation;Hardware;Cameras;Robots;Software;Automation;Planning},
doi={10.1109/ICUAS.2019.8798329},
ISSN={2575-7296},
month={June},}
@ARTICLE{8536880,
author={Zhang, Jianhua and Liu, Ruyu and Yin, Kejie and Wang, Zengyuan and Gui, Mengping and Chen, Shengyong},
journal={IEEE Transactions on Industrial Electronics}, title={Intelligent Collaborative Localization Among Air-Ground Robots for Industrial Environment Perception},
year={2019},
volume={66},
number={12},
pages={9673-9681},
abstract={Multiple mobile robots have gradually played a key role in many industrial systems, such as factory freight logistics system, patrol security in the factory environment, and multirobot collaborative service and work. As a key issue in industrial environment perception, the accurate robot localization can enhance their autonomous ability and is an important branch of robotic studies in artificial intelligence. In this paper, we propose a new method for cooperative autonomous localization among air-ground robots in a wide-ranging outdoor industrial environment. The aerial robot first maps an area of interest and achieves self-localization. Then the aerial robot transfers a simplified orthogonal perspective 2.5-D map to the ground robots for collaboration. Within the collaboration, the ground robot achieves pose estimation with respect to the unmanned aerial vehicle pose by instantaneously registering a single panorama with respect to the 2.5-D map. The 2.5-D map is used as the spatial association among air-ground robots. The ground robots estimate the orientation using automatically detected geometric information and generates the translation by aligning the 2.5-D map with a semantic segmentation of the panorama. Our method effectively overcomes the dramatic differences between the air-level view and the ground-level view. A set of experiments is performed in the outdoor industrial environment to demonstrate the applicability of our localization method. The proposed robotic collaborative localization outperforms most consumer sensor in accuracy and also has an outstanding running time.},
keywords={Service robots;Robot kinematics;Robot sensing systems;Collaboration;Unmanned aerial vehicles;Three-dimensional displays;Air-ground robot;collaborative localization;omnidirectional vision;semantic segmentation;vanishing points (VPs)},
doi={10.1109/TIE.2018.2880727},
ISSN={1557-9948},
month={Dec},}
@INPROCEEDINGS{8628677,
author={Fan, David D. and Theodorou, Evangelos A. and Reeder, John},
booktitle={2018 IEEE Symposium Series on Computational Intelligence (SSCI)}, title={Model-Based Stochastic Search for Large Scale Optimization of Multi-Agent UAV Swarms},
year={2018},
volume={},
number={},
pages={2216-2222},
abstract={Recent work from the reinforcement learning community has shown that Evolution Strategies are a fast and scalable alternative to other reinforcement learning methods. In this paper we show that Evolution Strategies are a special case of model-based stochastic search methods. This class of algorithms has nice asymptotic convergence properties and known convergence rates. We show how these methods can be used to solve both cooperative and competitive multiagent problems in an efficient manner. We demonstrate the effectiveness of this approach on two complex multi-agent UAV swarm combat scenarios: where a team of fixed wing aircraft must attack a well-defended base, and where two teams of agents go head to head to defeat each other T.},
keywords={Stochastic processes;Convergence;Reinforcement learning;Approximation algorithms;Optimization;Search methods;Evolutionary computation},
doi={10.1109/SSCI.2018.8628677},
ISSN={},
month={Nov},}
@INPROCEEDINGS{8372049,
author={Lelerre, Mathieu and Mouaddib, Abdel-Illah and Jeanpierre, Laurent},
booktitle={2017 IEEE 29th International Conference on Tools with Artificial Intelligence (ICTAI)}, title={Robust Inverse Planning Approaches for Policy Estimation of Semi-autonomous Agents},
year={2017},
volume={},
number={},
pages={951-958},
abstract={Most of existing coordination techniques for autonomous agents assume the knowledge or the estimation of the other agents' policy. However, this assumption is not valid in semi-autonomous agents because an external entity can take the control and modify the behavior of the agent. We face this problem in applications where an operator can take the control of the system (Robot/UAV). Many human factors may affect this behavior, such as stress, hesitations and preferences. Estimating the policy in such contexts is a difficult problem. Many existing algorithms using Inverse Reinforcement learning or imitation have been developed. However most of them have weak performance when non-optimal policy is followed. In this paper, we investigate techniques for estimating the followed policies of semi-autonomous agents that could be nonoptimal due to critical situations We extend some prediction methods and algorithms based on Factored MDPs and Inverse Reinforcement Learning to improve their stability and their efficiency during the execution of a mission. Then, we develop various experiments showing the performance on efficiency and stability of our approach in different conditions and comparing with it.},
keywords={Estimation;Markov processes;Learning (artificial intelligence);Linear programming;Force;Autonomous agents;Mathematical model;MDP;inverse reinforcement learning;Activity and Plan Recognition},
doi={10.1109/ICTAI.2017.00146},
ISSN={2375-0197},
month={Nov},}
@INPROCEEDINGS{7487169,
author={Faust, Aleksandra and Chiang, Hao-Tien and Rackley, Nathanael and Tapia, Lydia},
booktitle={2016 IEEE International Conference on Robotics and Automation (ICRA)}, title={Avoiding moving obstacles with stochastic hybrid dynamics using PEARL: PrEference Appraisal Reinforcement Learning},
year={2016},
volume={},
number={},
pages={484-490},
abstract={Manual derivation of optimal robot motions for task completion is difficult, especially when a robot is required to balance its actions between opposing preferences. One solution has been proposed to automatically learn near optimal motions with Reinforcement Learning (RL). This has been successful for several tasks including swing-free UAV flight, table tennis, and autonomous driving. However, high-dimensional problems remain a challenge. We address this dimensionality constraint with PrEference Appraisal Reinforcement Learning (PEARL), which solves tasks with opposing preferences for acceleration controlled robots. PEARL projects the high-dimensional continuous robot state space to a low dimensional preference feature space resulting in efficient and adaptable planning. We demonstrate that on a dynamic obstacle avoidance robotic task, a single learning on a much simpler problem performs real-time decision-making for significantly larger, high-dimensional problems working in unbounded continuous states and actions. We trained the agent with 4 static obstacles, while the trained agent avoids up to 900 moving obstacles with complex hybrid stochastic obstacle dynamics in a highly constrained space using only limited information about the environment. We compare these tasks to traditional, often manually tuned solutions for these high-dimensional problems.},
keywords={Dynamics;Planning;Robot kinematics;Collision avoidance;Aerospace electronics;Acceleration},
doi={10.1109/ICRA.2016.7487169},
ISSN={},
month={May},}
@ARTICLE{9103927,
author={Xu, Fangmin and Yang, Fan and Zhao, Chenglin and Wu, Sheng},
journal={China Communications}, title={Deep reinforcement learning based joint edge resource management in maritime network},
year={2020},
volume={17},
number={5},
pages={211-222},
abstract={Due to the rapid development of the maritime networks, there has been a growing demand for computation-intensive applications which have various energy consumption, transmission bandwidth and computing latency requirements. Mobile edge computing (MEC) can efficiently minimize computational latency by offloading computation tasks by the terrestrial access network. In this work, we introduce a space-air-ground-sea integrated network architecture with edge and cloud computing components to provide flexible hybrid computing service for maritime service. In the integrated network, satellites and unmanned aerial vehicles (UAVs) provide the users with edge computing services and network access. Based on the architecture, the joint communication and computation resource allocation problem is modelled as a complex decision process, and a deep reinforcement learning based solution is designed to solve the complex optimization problem. Finally, numerical results verify that the proposed approach can improve the communication and computing efficiency greatly.},
keywords={Task analysis;Edge computing;Resource management;Servers;Satellites;Computer architecture;Cloud computing;maritime network;edge computing;computation offload;computation latency;reinforcement learning;deep learning},
doi={10.23919/JCC.2020.05.016},
ISSN={1673-5447},
month={May},}
@INPROCEEDINGS{9289086,
author={Ryoo, Dokyun and Baek, Seungwoo and Lee, Yonghun and Kang, Seongjoon and Kim, Byungjun and Bahk, Saewoong},
booktitle={2020 International Conference on Information and Communication Technology Convergence (ICTC)}, title={Reinforcement Learning based Real Time Aerial BS Positioning for Dense Urban 5G Mobile Network},
year={2020},
volume={},
number={},
pages={431-433},
abstract={Due to the recent surge in mobile users and traffic, next-generation mobile communication aims to increase network capacity through large bandwidth and small cell deployment. To respond to this situation, there have been lots of researches on aerial base stations (BSs) using unmanned aerial vehicles (UAVs) for the mobile user. Aerial BS has the advantage of providing flexible communication range by avoiding obstacles such as buildings in urban areas through 3D positioning. However, finding an optimal point for aerial BS considering the variance of user's requirements, movement, and obstacles in real time is difficult problem to solve. Therefore, it is necessary to find an approximate optimal point for applying to the real-time flight path control of aerial BS. This paper aims to find optimal behavior in real time interacting with a given environment, through reinforcement learning. We propose the algorithm based on Q-learning with a new concept called Coarse Search to reduce convergence speed. We evaluate the performance of the algorithm by comparing it with that of other heuristic algorithms.},
keywords={Three-dimensional displays;Heuristic algorithms;Urban areas;Reinforcement learning;Real-time systems;Unmanned aerial vehicles;Convergence},
doi={10.1109/ICTC49870.2020.9289086},
ISSN={2162-1233},
month={Oct},}
@INPROCEEDINGS{9314848,
author={LIU, Jianmin and WANG, Qi and HE, Chentao and XU, Yongjun},
booktitle={2020 IEEE 45th Conference on Local Computer Networks (LCN)}, title={ARdeep: Adaptive and Reliable Routing Protocol for Mobile Robotic Networks with Deep Reinforcement Learning},
year={2020},
volume={},
number={},
pages={465-468},
abstract={The mobile robotic network consisting multiple robotic devices such as unmanned aerial vehicles (UAVs) is a high-speed mobile wireless network. Existing mobile ad hoc protocols cannot meet the demands of mobile robotic networks due to intermittently connected links and frequent topology changes. This paper proposes a deep reinforcement learning based adaptive and reliable routing protocol, ARdeep. We formulate routing decisions with a Markov Decision Process model to automatically characterize the network variations. To better infer network environment, the link status is considered when making routing decisions. Simulation results demonstrate that ARdeep outperforms the existing good performing QGeo and conventional GPSR.},
keywords={Routing;Robots;Routing protocols;Network topology;Topology;Reinforcement learning;Markov processes;Adaptive routing;Deep reinforcement learning;Deep Q-Network (DQN);Mobile robotic devices},
doi={10.1109/LCN48667.2020.9314848},
ISSN={0742-1303},
month={Nov},}
@ARTICLE{9521193,
author={Xi, Mao and Zhou, Yun and Chen, Zheng and Zhou, Wengang and Li, Houqiang},
journal={IEEE Transactions on Circuits and Systems for Video Technology}, title={Anti-distractor Active Object Tracking in 3D Environments},
year={2021},
volume={},
number={},
pages={1-1},
abstract={In active object tracking, given a visual observation as input, the goal is to lockup the target by autonomously adjusting camera’s position and posture. Previous works on active tracking assume that there is only one object (person) in the environment without distractors. In this work, towards realistic setting, we move forward to a more challenging scenario, where the tracker moves freely in 3D space like unmanned aerial vehicles (UAV) to track a person in various complex scenes with multiple distractors. To this end, we propose a novel end-to-end anti-distractor active object tracking framework by introducing multiple attention modules. On one hand, we take the target template to learn an embedding as channel-wise attention for current observation to distinguish the target from the distractors. On the other hand, temporal attention is introduced to fuse the observation history to extract a feature representation, which is then fed into a reinforcement learning network to output the action of the tracker. To evaluate our method, we build several multi-object 3D environments in Unreal Engine and extensive experiments demonstrate the effectiveness of our approach.},
keywords={Target tracking;Object tracking;Training;Three-dimensional displays;Reinforcement learning;Cameras;Visualization;Active object tracking;reinforcement learning;attention mechanism},
doi={10.1109/TCSVT.2021.3107153},
ISSN={1558-2205},
month={},}
@ARTICLE{9712866,
author={Zhang, Ruilong and Zong, Qun and Zhang, Xiuyun and Dou, Liqian and Tian, Bailing},
journal={IEEE Transactions on Neural Networks and Learning Systems}, title={Game of Drones: Multi-UAV Pursuit-Evasion Game With Online Motion Planning by Deep Reinforcement Learning},
year={2022},
volume={},
number={},
pages={1-10},
abstract={As one of the tiniest flying objects, unmanned aerial vehicles (UAVs) are often expanded as the ``swarm'' to execute missions. In this article, we investigate the multiquadcopter and target pursuit-evasion game in the obstacles environment. For high-quality simulation of the urban environment, we propose the pursuit-evasion scenario (PES) framework to create the environment with a physics engine, which enables quadcopter agents to take actions and interact with the environment. On this basis, we construct multiagent coronal bidirectionally coordinated with target prediction network (CBC-TP Net) with a vectorized extension of multiagent deep deterministic policy gradient (MADDPG) formulation to ensure the effectiveness of the damaged ``swarm'' system in pursuit-evasion mission. Unlike traditional reinforcement learning, we design a target prediction network (TP Net) innovatively in the common framework to imitate the way of human thinking: situation prediction is always before decision-making. The experiments of the pursuit-evasion game are conducted to verify the state-of-the-art performance of the proposed strategy, both in the normal and antidamaged situations.},
keywords={Games;Reinforcement learning;Physics;Engines;Urban areas;Real-time systems;Trajectory;Multiagent reinforcement learning;multiquadcopter motion planning;pursuit-evasion game;trajectory prediction.},
doi={10.1109/TNNLS.2022.3146976},
ISSN={2162-2388},
month={},}
@INPROCEEDINGS{8446007,
author={Sikeridis, Dimitrios and EleniTsiropoulou, Eirini and Devetsikiotis, Michael and Papavassiliou, Symeon},
booktitle={2018 IEEE 19th International Workshop on Signal Processing Advances in Wireless Communications (SPAWC)}, title={Self-Adaptive Energy Efficient Operation in UAV-Assisted Public Safety Networks},
year={2018},
volume={},
number={},
pages={1-5},
abstract={Public Safety Networks (PSN) are expected to provide resilient communication paradigms under disaster recovery scenarios. Towards providing an energy efficient solution an UAV-supported multi-level architecture is employed where user equipments (UEs) are grouped together in clusters. Initially, the UEs choose their role (clusterhead (ch) or cluster member) in the network independently and in a distributed fashion, following the theory of Minority Games (MG), while subsequently the member UEs act as stochastic learning automata selecting a clusterhead to be associated with, based on reinforcement learning. Upon completion of the cluster formation, the UAV optimal positioning in an Euclidean 3D space is obtained by treating a maximization problem of the clusterhead's energy availability, being the UEs that play a critical role within the PSN. Lastly, a non-cooperative game-theoretic approach is adopted to determine in a distributed manner the optimal transmission power (unique Nash equilibrium) of each UE. The performance evaluation of the proposed approach is achieved via modeling and simulation and the corresponding numerical results demonstrate its energy efficiency and effectiveness.},
keywords={Games;Wireless communication;Safety;Uplink;Receivers;Three-dimensional displays;Nash equilibrium;Public Safety Networks;minority games;reinforcement learning;game theory;energy efficiency},
doi={10.1109/SPAWC.2018.8446007},
ISSN={1948-3252},
month={June},}
@INPROCEEDINGS{9524972,
author={Wang, Qi and Liu, Jianmin and Liu, Cunzhuang and Huang, Jianhui and He, Chentao and Xu, Yongjun},
booktitle={2021 IEEE 46th Conference on Local Computer Networks (LCN)}, title={MPRdeep: Multi-Objective Joint Optimal Node Positioning and Resource Allocation for FANETs with Deep Reinforcement learning},
year={2021},
volume={},
number={},
pages={315-318},
abstract={This paper addresses the problem of UAV positioning and resource allocation under dynamic network conditions and under instantaneous communication demands in FANETs. We propose MPRdeep, an adaptive, deep reinforcement learning (DRL) approach considering several QoS requirements concurrently. MPRdeep learns to optimize relay UAVs’ positions and forwarding probabilities to minimize reliability-achieving delay and reliability-achieving energy consumption. The key advantage is that MPRdeep is able to learn and dynamically adjust the node positioning and resource allocation according to ongoing network conditions. The results show that MPRdeep converges fast and has generalization ability that adapts well under dynamic network conditions and dynamic locations of users. Compared with baseline methods, MPRdeep shows superior performance in terms of lower reliability-achieving delay and lower reliability-achieving energy consumption via simulations and experiments.},
keywords={Energy consumption;Adaptation models;Computer network reliability;Simulation;Reinforcement learning;Quality of service;Delays;Relay positioning;Resource allocation;Deep Q-Learning Network (DQN);Multi-Objective Optimal;FANETs},
doi={10.1109/LCN52139.2021.9524972},
ISSN={0742-1303},
month={Oct},}
@INPROCEEDINGS{8593539,
author={Haksar, Ravi N. and Schwager, Mac},
booktitle={2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)}, title={Distributed Deep Reinforcement Learning for Fighting Forest Fires with a Network of Aerial Robots},
year={2018},
volume={},
number={},
pages={1067-1074},
abstract={This paper proposes a distributed deep reinforcement learning (RL) based strategy for a team of Unmanned Aerial Vehicles (UAVs) to autonomously fight forest fires. We first model the forest fire as a Markov decision process (MDP) with a factored structure. We consider optimally controlling the forest fire without agents using dynamic programming, and show any exact solution and many approximate solutions are computationally intractable. Given the problem complexity, we consider a deep RL approach in which each agent learns a policy requiring only local information. We show with Monte Carlo simulations that the deep RL policy outperforms a hand-tuned heuristic, and scales well for various forest sizes and different numbers of UAVs as well as variations in model parameters. Experimental demonstrations with mobile robots fighting a simulated forest fire in the Robotarium at the Georgia Institute of Technology are also presented.},
keywords={Vegetation;Forestry;Sensors;Retardants;Monitoring;Lattices;Unmanned aerial vehicles},
doi={10.1109/IROS.2018.8593539},
ISSN={2153-0866},
month={Oct},}
@ARTICLE{8207610,
author={Zhang, Bo and Liu, Chi Harold and Tang, Jian and Xu, Zhiyuan and Ma, Jian and Wang, Wendong},
journal={IEEE Transactions on Industrial Informatics}, title={Learning-Based Energy-Efficient Data Collection by Unmanned Vehicles in Smart Cities},
year={2018},
volume={14},
number={4},
pages={1666-1676},
abstract={Mobile crowdsourcing (MCS) is now an important source of information for smart cities, especially with the help of unmanned aerial vehicles (UAVs) and driverless cars. They are equipped with different kinds of high-precision sensors, and can be scheduled/controlled completely during data collection, which will make MCS system more robust. However, they are limited to energy constraint, especially for long-term, long-distance sensing tasks, and cities are almost too crowded to set stationary charging station. Towards this end, in this paper we propose to leverage emerging deep reinforcement learning (DRL) techniques for enabling model-free unmanned vehicles control, and present a novel and highly effective control framework, called “DRL-RVC.” It utilizes the powerful convolutional neural network for feature extraction of the necessary information (including sample distribution, traffic flow, etc.), then makes decisions under the guidance of the deep Q network. That is, UAVs will cruise in the city without control and collect most required data in the sensing region, while mobile unmanned charging station will reach the charging point in the shortest possible time. Finally, we validate and evaluate the proposed framework via extensive simulations based on a real dataset in Rome. Extensive simulation results well justify the effectiveness and robustness of our approach.},
keywords={Sensors;Charging stations;Mobile communication;Data collection;Unmanned vehicles;Urban areas;Data crowdsourcing;energy-efficiency;smart city},
doi={10.1109/TII.2017.2783439},
ISSN={1941-0050},
month={April},}
@INPROCEEDINGS{9018854,
author={Zhou, Benchun and Wang, Weihong and Wang, Zhifeng and Ding, Baoyang},
booktitle={2018 IEEE CSAA Guidance, Navigation and Control Conference (CGNCC)}, title={Neural Q Learning Algorithm based UAV Obstacle Avoidance},
year={2018},
volume={},
number={},
pages={1-6},
abstract={In the paper, Neural Q Learning algorithm (NQL) was involved to solve the obstacle avoidance problem for UAV path planning. Q learning was good at online learning and BP network provided excellent function approximation. The combination of two methods can provided UAV a collision-free trajectory in unknown environment. Through several simulations, the proposed algorithm could gain better performance and gain higher success rate than classic Q-learning (CQL). Besides, this method was extended for deep reinforcement learning, such as DQN, which is more suitable for practical applications.},
keywords={Path planning;Navigation;Unmanned aerial vehicles;Collision avoidance;Learning (artificial intelligence);Training;Approximation algorithms},
doi={10.1109/GNCC42960.2018.9018854},
ISSN={},
month={Aug},}
@INPROCEEDINGS{9356016,
author={Sadhu, Vidyasagar and Sun, Chuanneng and Karimian, Arman and Tron, Roberto and Pompili, Dario},
booktitle={2020 IEEE 17th International Conference on Mobile Ad Hoc and Sensor Systems (MASS)}, title={Aerial-DeepSearch: Distributed Multi-Agent Deep Reinforcement Learning for Search Missions},
year={2020},
volume={},
number={},
pages={165-173},
abstract={Search and Rescue (SAR) is an important part of several applications of national and social interest. Existing solutions for search missions in both terrestrial and aerial domains are mostly limited to single agent and specific environments; however, search missions can significantly benefit from the use of multiple agents that can quickly adapt to new environments. In this paper, we propose a framework based on Multi-Agent Deep Reinforcement Learning (MADRL) that realizes the actor-critic framework in a distributed manner for coordinating multiple Unmanned Aerial Vehicles (UAVs) in the exploration of unknown regions. One of the original aspects of our work is that the actors represent simulated or actual UAVs exploring the environment in parallel instead of traditional computer threads. Also, we propose addition of Long Short Term Memory (LSTM) neural network layers to the actor and critic architectures to handle imperfect communication and partial observability scenarios. The proposed approach has been evaluated in a grid world and has been compared against other competing algorithms such as Multi-Agent Q-Learning, Multi-Agent Deep Q-Learning to show its advantages. More generally, our approach could be extended to image-based/continuous action space environments as well.},
keywords={Instruction sets;Neural networks;Reinforcement learning;Unmanned aerial vehicles;Sensor systems;Observability;Long short term memory;Multi-Agent Deep Reinforcement Learning;Search and Rescue;Drones;wireless communication},
doi={10.1109/MASS50613.2020.00030},
ISSN={2155-6814},
month={Dec},}
@INPROCEEDINGS{9602323,
author={Cheng, Haoyu and Wang, Meng and Ma, Yifeng and Jiao, Jiayue and Song, Ruijia},
booktitle={2021 33rd Chinese Control and Decision Conference (CCDC)}, title={Intelligent $H_{\infty}$ Control for UAVs via Fuzzy Deep Reinforcement Learning},
year={2021},
volume={},
number={},
pages={7182-7187},
abstract={The problem of intelligent $H_{\infty}$ control for unmanned aerial vehicles (UAVs) is investigated in this paper. The linear model of UAV can be obtained by the aid of Jacobian linearization. Considering the time delay and packet losses in the network, the robust $H_{\infty}$ controller is proposed to overcome the undesirable response caused by time delay and packet losses. The deep reinforcement learning is introduced to improve the performance. Moreover, to improve the learning efficiency, we utilize a fuzzy reward system for the control process. The non-fragile control theory and Lyapunov functional method are combined to ensure the stability of closed-loop system. Simulation results in the end demonstrate the effectiveness and superiority of proposed method.},
keywords={Uncertainty;Delay effects;Packet loss;Reinforcement learning;Switches;Unmanned aerial vehicles;Stability analysis;Fuzzy Deep Reinforcement Learning;Switched System;$H_{\infty}$ Control;Non-fragile Control},
doi={10.1109/CCDC52312.2021.9602323},
ISSN={1948-9447},
month={May},}
@INPROCEEDINGS{7502678,
author={Ramasamy, Manickam and Ghose, Debasish},
booktitle={2016 International Conference on Unmanned Aircraft Systems (ICUAS)}, title={Learning-based preferential surveillance algorithm for persistent surveillance by unmanned aerial vehicles},
year={2016},
volume={},
number={},
pages={1032-1040},
abstract={In this paper, we present an algorithm called Learning-based Preferential Surveillance Algorithm (LPSA), which is specific to the problem of persistent surveillance by unmanned aerial vehicles. The novelty of the algorithm lies in providing the capability to a UAV to increase the probability of target detection through learning. The algorithm considers the neighborhood of a localized target as potential additional targets and motivates the UAV to verify if this is indeed true. Once a target is located in any of the neighborhood grid points, that point is visited more often than other points. Moreover, this technique uses the risk calculation method of an existing geometric reinforcement learning algorithm to reduce the frequency of visits to risky regions. Simulation results are used to demonstrate the effectiveness of the algorithm.},
keywords={Surveillance;Object detection;Unmanned aerial vehicles;Urban areas;Planning;Target tracking;persistent surveillance;preferential surveillance;learning;target detection;UAV},
doi={10.1109/ICUAS.2016.7502678},
ISSN={},
month={June},}
@ARTICLE{9426943,
author={Gao, Ang and Wang, Qi and Chen, Kaiyue and Liang, Wei},
journal={IEEE Communications Letters}, title={Multi-UAV Assisted Offloading Optimization: A Game Combined Reinforcement Learning Approach},
year={2021},
volume={25},
number={8},
pages={2629-2633},
abstract={Although unmanned aerial vehicles (UAVs) have attracted much attention by providing aerial relays to massive ground users (GUs) for tasks offloading, there still exist several issues, such as the unbalance of tasks size and trajectory optimization related to energy efficiency and obstacles avoidance. The letter models the multi-UAV assisted offloading system as two separate problems optimized by a potential game combined reinforcement learning algorithm, i.e., potential game for service assignment, and deep deterministic policy gradient (DDPG) for trajectory planning. The former largely reduces the convergence time, and the latter can search the best action in a continuous domain. The numerical results show that the proposed approach has great advantages in minimizing offloading delay, enhancing energy efficiency and avoiding obstacles.},
keywords={Games;Task analysis;Relays;Energy consumption;Delays;Convergence;Trajectory optimization;Offloading;DRL;potential game;DDPG},
doi={10.1109/LCOMM.2021.3078469},
ISSN={1558-2558},
month={Aug},}
@ARTICLE{9475451,
author={Ni, Wenjun and Wu, Di and Ma, Xiaoping},
journal={IEEE Access}, title={Energy-Optimal Flight Strategy for Solar-Powered Aircraft Using Reinforcement Learning With Discrete Actions},
year={2021},
volume={9},
number={},
pages={95317-95334},
abstract={The low efficiency of photovoltaic cells limits the energy absorption of high-altitude long-endurance (HALE) solar-powered unmanned aircraft vehicles (UAVs), which dramatically weakens the capacity for long-endurance missions. Therefore, finding a method to extend the flight duration with finite solar energy drives extensive research. The present work introduces a method that applies a deep reinforcement learning (DRL) framework to generate an energy-optimized flight strategy for HALE solar-powered aircraft. The neural network controller is designed to realize autonomous flight navigation by giving commands of thrust, attack angle, and bank angle. A mission area with a radius of 5 km is assumed to test the RL controller performance. The simulation results show that the RL controller leads to a 28 % increase in the battery SoC after a 24-hour flight, which indicates that a controller based on the RL framework might be a potential method for solving the solar-powered UAV trajectory planning problem. Aiming to explore the applicability of the RL controller, a sustained flight test is implemented. The results show that a 39-day endurance flight is achieved by the RL controller, which is 50% higher than the base case with a steady flight trajectory.},
keywords={Aircraft;Aerospace control;Reinforcement learning;Atmospheric modeling;Aircraft navigation;Solar energy;Optimization;High-altitude long-endurance aircraft;flight strategy optimization;automatic navigation;reinforcement learning;photovoltaic cell},
doi={10.1109/ACCESS.2021.3095224},
ISSN={2169-3536},
month={},}
@ARTICLE{9406006,
author={Cui, Zhengyang and Wang, Yong},
journal={IEEE Access}, title={UAV Path Planning Based on Multi-Layer Reinforcement Learning Technique},
year={2021},
volume={9},
number={},
pages={59486-59497},
abstract={Unmanned aerial vehicles (UAVs) have been widely used in many applications due to its small size, swift mobility and low cost. Therefore, the study of guidance, navigation and control (GNC) system of UAV has becoming a popular research direction. Path planning plays an important role in the GNC system. In this paper, a multi-layer path planning algorithm based on reinforcement learning (RL) technique is proposed. Compared to the classic Q-learning, the proposed multi-layer algorithm has a distinct advantage that it collects both global and local information which greatly improves overall performance. The proposed RL algorithm has two layers, the higher layer deals with the local information, which could be considered as a short-term strategy. The lower layer deals with the global information, which could be considered as a long-term strategy. Both the higher layer and lower layer are working in harmony to plan a collision-free path. B-spline curve approach is applied for on-line path smoothing. Simulation results in different scenarios prove the effectiveness of multi-layer Q-learning algorithm.},
keywords={Path planning;Heuristic algorithms;Unmanned aerial vehicles;Navigation;Collision avoidance;Reinforcement learning;Fuzzy logic;Path planning;reinforcement learning;multi-layer Q-learning;B-spline curve},
doi={10.1109/ACCESS.2021.3073704},
ISSN={2169-3536},
month={},}
@ARTICLE{7590013,
author={Shi, Haobin and Li, Xuesi and Hwang, Kao-Shing and Pan, Wei and Xu, Genjiu},
journal={IEEE Transactions on Industrial Informatics}, title={Decoupled Visual Servoing With Fuzzy Q-Learning},
year={2018},
volume={14},
number={1},
pages={241-252},
abstract={The objective of visual servoing aims to control an object's motion with visual feedbacks and becomes popular recently. Problems of complex modeling and instability always exist in visual servoing methods. Moreover, there are few research works on selection of the servoing gain in image-based visual servoing (IBVS) methods. This paper proposes an IBVS method with Q-Learning, where the learning rate is adjusted by a fuzzy system. Meanwhile, a synthetic preprocess is introduced to perform feature extraction. The extraction method is actually a combination of a color-based recognition algorithm and an improved contour-based recognition algorithm. For dealing with underactuated dynamics of the unmanned aerial vehicles (UAVs), a decoupled controller is designed, where the velocity and attitude are decoupled through attenuating the effects of underactuation in roll and pitch and two independent servoing gains, for linear and angular motion servoing, respectively, are designed in place of single servoing gain in traditional methods. For further improvement in convergence and stability, a reinforcement learning method, Q-Learning, is taken for adaptive servoing gain adjustment. The Q-Learning is composed of two independent learning agents for adjusting two serving gains, respectively. In order to improve the performance of the Q-Learning, a fuzzy-based method is proposed for tuning the learning rate. The results of simulations and experiments on control of UAVs demonstrate that the proposed method has better properties in stability and convergence than the competing methods.},
keywords={Unmanned aerial vehicles;Feature extraction;Visual servoing;Cameras;Visualization;Vehicle dynamics;Convergence;Fuzzy control;underactuated dynamic system;unmanned aerial vehicles;visual servoing; $Q$ -Learning},
doi={10.1109/TII.2016.2617464},
ISSN={1941-0050},
month={Jan},}
@INPROCEEDINGS{9712561,
author={Li, Yilan and Fang, Haowen and Li, Mingyang and Ma, Yue and Qiu, Qinru},
booktitle={2022 27th Asia and South Pacific Design Automation Conference (ASP-DAC)}, title={Neural Network Pruning and Fast Training for DRL-based UAV Trajectory Planning},
year={2022},
volume={},
number={},
pages={574-579},
abstract={Deep reinforcement learning (DRL) has been applied for optimal control of autonomous UAV trajectory generation. The energy and payload capacity of small UAVs impose constraints on the complexity and size of the neural network. While Model compression has the potential to optimize the trained neural network model for efficient deployment on em-bedded platforms, pruning a neural network for DRL is more difficult due to the slow convergence in the training before and after pruning. In this work, we focus on improving the speed of DRL training and pruning. New reward function and action exploration are first introduced, resulting in convergence speedup by 34.14%. The framework that integrates pruning and DRL training is then presented with an emphasize on how to reduce the training cost. The pruning does not only improve computational performance of inference, but also reduces the training effort with-out compromising the quality of the trajectory. Finally, experimental results are presented. We show that the integrated training and pruning framework reduces 67.16% of the weight and improves trajectory success rate by 1.7%. It achieves a 4.43x reduction of the floating-point operations for the inference, resulting a measured 41.85% run time reduction.},
keywords={Training;Trajectory planning;Optimal control;Reinforcement learning;Time measurement;Trajectory;Planning},
doi={10.1109/ASP-DAC52403.2022.9712561},
ISSN={2153-697X},
month={Jan},}
@ARTICLE{9366781,
author={Venturini, Federico and Mason, Federico and Pase, Francesco and Chiariotti, Federico and Testolin, Alberto and Zanella, Andrea and Zorzi, Michele},
journal={IEEE Transactions on Cognitive Communications and Networking}, title={Distributed Reinforcement Learning for Flexible and Efficient UAV Swarm Control},
year={2021},
volume={7},
number={3},
pages={955-969},
abstract={Over the past few years, the use of swarms of Unmanned Aerial Vehicles (UAVs) in monitoring and remote area surveillance applications has become widespread thanks to the price reduction and the increased capabilities of drones. The drones in the swarm need to cooperatively explore an unknown area, in order to identify and monitor interesting targets, while minimizing their movements. In this work, we propose a distributed Reinforcement Learning (RL) approach that scales to larger swarms without modifications. The proposed framework relies on the possibility for the UAVs to exchange some information through a communication channel, in order to achieve context-awareness and implicitly coordinate the swarm’s actions. Our experiments show that the proposed method can yield effective strategies, which are robust to communication channel impairments, and that can easily deal with non-uniform distributions of targets and obstacles. Moreover, when agents are trained in a specific scenario, they can adapt to a new one with minimal additional training. We also show that our approach achieves better performance compared to a computationally intensive look-ahead heuristic.},
keywords={Drones;Training;Sensors;Surveillance;Reinforcement learning;Wireless communication;Transfer learning;Artificial intelligence;distributed decision making;mobile robots;neural network applications},
doi={10.1109/TCCN.2021.3063170},
ISSN={2332-7731},
month={Sep.},}
@ARTICLE{9525079,
author={Jiang, Bote and Givigi, Sidney N. and Delamer, Jean-Alexis},
journal={IEEE Access}, title={A MARL Approach for Optimizing Positions of VANET Aerial Base-Stations on a Sparse Highway},
year={2021},
volume={9},
number={},
pages={133989-134004},
abstract={A Vehicular Ad-Hoc Network (VANET) helps vehicles send and receive environmental and traffic information, making it a crucial component towards fully autonomous roads. For VANETs to serve their purpose, there has to be sufficient coverage, even in areas where there is less demand. Moreover, a lot of the safety information is time-sensitive; excessive delay in data transfer can increase the risk of fatal accidents. Unmanned Aerial Vehicles (UAVs) can be used as mobile base-stations to fill in gaps of coverage. The placement of these UAVs is crucial towards how well the system performs. We are particularly interested in the placement of mobile base-stations for a rural highway with sparse traffic, as it represents the worst-case scenario for vehicular communication. Instead of heuristic or linear programming methods for optimal placement, we use multi-agent reinforcement learning (MARL). The main benefit of MARL is that it allows the agents to learn model-free through experience. We propose a variation of the traditional Deep Independent Q-Learning. The modifications include an observation function augmented with information directly shared between neighbouring agents as well a shared policy scheme. We also implement a custom sparse highway simulator that is used for training and testing our algorithm. Our testing shows that the proposed MARL algorithm is able to learn the placement policies that produce the maximum rewards for different scenarios while adapting to the dynamic road densities along the service area. Our experiments show that our model is scalable, allowing the number of agents to increase without any modifications to the code. Finally, we show that our model can be generalized as the algorithm can be directly used on an industry standard simulator with similar performance. Future experiments can be performed to improve the realism and complexity of the highway models as well as to test the method on real-world data.},
keywords={Roads;Delays;Drones;Vehicular ad hoc networks;Reinforcement learning;Heuristic algorithms;Adaptation models;Automated highways;autonomous agents;unmanned aerial vehicles;end-to-end delay;multi-agent reinforcement learning;reinforcement learning;drones;VANET;vehicular network},
doi={10.1109/ACCESS.2021.3108891},
ISSN={2169-3536},
month={},}
@ARTICLE{8672604,
author={Cheng, Nan and Lyu, Feng and Quan, Wei and Zhou, Conghao and He, Hongli and Shi, Weisen and Shen, Xuemin},
journal={IEEE Journal on Selected Areas in Communications}, title={Space/Aerial-Assisted Computing Offloading for IoT Applications: A Learning-Based Approach},
year={2019},
volume={37},
number={5},
pages={1117-1129},
abstract={Internet of Things (IoT) computing offloading is a challenging issue, especially in remote areas where common edge/cloud infrastructure is unavailable. In this paper, we present a space-air-ground integrated network (SAGIN) edge/cloud computing architecture for offloading the computation-intensive applications considering remote energy and computation constraints, where flying unmanned aerial vehicles (UAVs) provide near-user edge computing and satellites provide access to the cloud computing. First, for UAV edge servers, we propose a joint resource allocation and task scheduling approach to efficiently allocate the computing resources to virtual machines (VMs) and schedule the offloaded tasks. Second, we investigate the computing offloading problem in SAGIN and propose a learning-based approach to learn the optimal offloading policy from the dynamic SAGIN environments. Specifically, we formulate the offloading decision making as a Markov decision process where the system state considers the network dynamics. To cope with the system dynamics and complexity, we propose a deep reinforcement learning-based computing offloading approach to learn the optimal offloading policy on-the-fly, where we adopt the policy gradient method to handle the large action space and actor-critic method to accelerate the learning process. Simulation results show that the proposed edge VM allocation and task scheduling approach can achieve near-optimal performance with very low complexity and the proposed learning-based computing offloading algorithm not only converges fast but also achieves a lower total cost compared with other offloading approaches.},
keywords={Task analysis;Servers;Internet of Things;Edge computing;Delays;Resource management;Computer architecture;Computing offloading;edge computing;space-air-ground;IoT;reinforcement learning},
doi={10.1109/JSAC.2019.2906789},
ISSN={1558-0008},
month={May},}
@INPROCEEDINGS{8587021,
author={Vlahović, Nataša and Ilić, Nemanja and Stanković, Miloš},
booktitle={2018 14th Symposium on Neural Networks and Applications (NEUREL)}, title={Deep Learning in Video Stabilization Homography Estimation},
year={2018},
volume={},
number={},
pages={1-5},
abstract={The main goal of digital video stabilization algorithms is to remove unwanted motion from a video sequence. The undesired motion is typically present in videos recorded by hand-held cameras, by cameras mounted on some moving platform (vehicle, boat, Unmanned Aerial Vehicle), or by stationary cameras under severe wind conditions. In this paper, the motion estimation step in video stabilization is performed in a novel way using deep learning homography matrix estimation. Convolutional Neural Network (CNN) takes two grayscale images as inputs, and produces a six degree of freedom affine transformation matrix that maps the pixels from the first image to the second one. After obtaining the homography transformation using a trained CNN, Kalman filter is used to separate the intentional from unintentional motion and calculate the final motion compensation transformation, stabilizing the video sequence.},
keywords={Training;Cameras;Estimation;Kalman filters;Motion estimation;Streaming media;Deep learning;Affine transformation;Video stabilization;Neural networks;Kalman filter;Homography estimation},
doi={10.1109/NEUREL.2018.8587021},
ISSN={},
month={Nov},}
@INPROCEEDINGS{8001185,
author={Okafor, Emmanuel and Smit, Rik and Schomaker, Lambert and Wiering, Marco},
booktitle={2017 IEEE International Conference on INnovations in Intelligent SysTems and Applications (INISTA)}, title={Operational data augmentation in classifying single aerial images of animals},
year={2017},
volume={},
number={},
pages={354-360},
abstract={In deep learning, data augmentation is important to increase the amount of training images to obtain higher classification accuracies. Most data-augmentation methods adopt the use of the following techniques: cropping, mirroring, color casting, scaling and rotation for creating additional training images. In this paper, we propose a novel data-augmentation method that transforms an image into a new image containing multiple rotated copies of the original image in the operational classification stage. The proposed method creates a grid of n×n cells, in which each cell contains a different randomly rotated image and introduces a natural background in the newly created image. This algorithm is used for creating new training and testing images, and enhances the amount of information in an image. For the experiments, we created a novel dataset with aerial images of cows and natural scene backgrounds using an unmanned aerial vehicle, resulting in a binary classification problem. To classify the images, we used a convolutional neural network (CNN) architecture and compared two loss functions (Hinge loss and cross-entropy loss). Additionally, we compare the CNN to classical feature-based techniques combined with a k-nearest neighbor classifier or a support vector machine. The results show that the pre-trained CNN with our proposed data-augmentation technique yields significantly higher accuracies than all other approaches.},
keywords={Cows;Unmanned aerial vehicles;Training;Neural networks;Computer architecture;Agriculture;Fasteners;Data Augmentation;Convolutional Neural Networks;Classical Feature Descriptors;Supervised Learning;Aerial Image Classification},
doi={10.1109/INISTA.2017.8001185},
ISSN={},
month={July},}
@ARTICLE{9362177,
author={Garcia, Jorge Alberto Bañuelos and Younes, Ahmad Bani},
journal={IEEE Transactions on Aerospace and Electronic Systems}, title={Real-Time Navigation for Drogue-Type Autonomous Aerial Refueling Using Vision-Based Deep Learning Detection},
year={2021},
volume={57},
number={4},
pages={2225-2246},
abstract={This article develops a deep learning object detector to provide accurate six-degree-of-freedom (DoF) information of the drogue relative to a monocular camera onboard a flying unmanned aerial vehicle. An object detector helps to provide the needed information for an autonomous vehicle to dock and refuel without the need for human intervention. This object detector can detect eight different beacons by training on 8746 images of a mock drogue. Once these beacons were detected, a nonlinear least squares algorithm that uses the collinearity equations as a system model takes the beacon's location on the captured image to provide an accurate six-DoF navigation solution. These navigation solutions from the object detector were evaluated on multiple metrics and then compared to navigation solutions provided by a VICON motion tracking system. Finally, Monte Carlo analysis, using the collinearity equations as a system model, evaluates an object detector's performance with various noise levels.},
keywords={Detectors;Aircraft navigation;Aircraft;Mathematical model;Measurement;Object detection;Feature extraction;Attitude estimation;detection algorithms;high-order nonlinear least squares methods;image processing;inference algorithms;machine learning algorithms;Monte Carlo methods;neural networks;object detection;pose estimation;position and attitude determination},
doi={10.1109/TAES.2021.3061807},
ISSN={1557-9603},
month={Aug},}
@INPROCEEDINGS{9627024,
author={Brandenburger, André and Hoffmann, Folker and Charlish, Alexander},
booktitle={2021 IEEE 24th International Conference on Information Fusion (FUSION)}, title={Co-Training an Observer and an Evading Target},
year={2021},
volume={},
number={},
pages={1-8},
abstract={Reinforcement learning (RL) is already widely applied to applications such as robotics, but it is only sparsely used in sensor management. In this paper, we apply the popular Proximal Policy Optimization (PPO) approach to a multi-agent UAV tracking scenario. While recorded data of real scenarios can accurately reflect the real world, the required amount of data is not always available. Simulation data, however, is typically cheap to generate, but the utilized target behavior is often naive and only vaguely represents the real world. In this paper, we utilize multi-agent RL to jointly generate protagonistic and antagonistic policies and overcome the data generation problem, as the policies are generated on-the-fly and adapt continuously. This way, we are able to clearly outperform baseline methods and robustly generate competitive policies. In addition, we investigate explainable artificial intelligence (XAI) by interpreting feature saliency and generating an easy-to-read decision tree as a simplified policy.},
keywords={Training;Adaptation models;Target tracking;Reinforcement learning;Observers;Robot sensing systems;Trajectory},
doi={10.23919/FUSION49465.2021.9627024},
ISSN={},
month={Nov},}
@ARTICLE{9275621,
author={Jiang, Feibo and Wang, Kezhi and Dong, Li and Pan, Cunhua and Xu, Wei and Yang, Kun},
journal={IEEE Network}, title={AI Driven Heterogeneous MEC System with UAV Assistance for Dynamic Environment: Challenges and Solutions},
year={2021},
volume={35},
number={1},
pages={400-408},
abstract={By taking full advantage of Computing, Communication and Caching (3C) resources at the network edge, Mobile Edge Computing (MEC) is envisioned as one of the key enablers for next generation networks. However, current fixed-lo-cation MEC architecture may not be able to make real-time decision in dynamic environments, especially in large-scale scenarios. To address this issue, in this article, a Heterogeneous MEC (H-MEC) architecture is proposed, which is composed of fixed unit, i.e., Ground Stations (GSs) as well as moving nodes, i.e., Ground Vehicles (GVs) and Unmanned Aerial Vehicles (UAVs), all with 3C resource enabled. The key challenges in H-MEC, i.e., mobile edge node management, real-time decision making, user association and resource allocation along with the possible Artificial Intelligence (AI)-based solutions, are discussed. In addition, the AI-based joint Resource schEduling (ARE) framework with two different AI-based mechanisms, i.e., Deep neural network (DNN)-based and deep reinforcement learning (DRL)-based architectures, are proposed. DNN-based solution with online incremental learning applies the global optimizer and therefore has better performance than the DRL-based architecture with online policy updating, but requires longer training time. The simulation results are given to verify the efficiency of our proposed ARE framework.},
keywords={Artificial intelligence;Computer architecture;Task analysis;Real-time systems;Training;Vehicle dynamics;Resource management},
doi={10.1109/MNET.011.2000440},
ISSN={1558-156X},
month={January},}
@ARTICLE{9507513,
author={Munir, Arslan and Kwon, Jisu and Lee, Jong Hun and Kong, Joonho and Blasch, Erik and Aved, Alexander J. and Muhammad, Khan},
journal={IEEE Access}, title={FogSurv: A Fog-Assisted Architecture for Urban Surveillance Using Artificial Intelligence and Data Fusion},
year={2021},
volume={9},
number={},
pages={111938-111959},
abstract={Urban surveillance, of which airborne urban surveillance is a vital constituent, provides situational awareness (SA) and timely response to emergencies. The significance and scope of urban surveillance has increased manyfold in recent years due to the proliferation of unmanned aerial vehicles (UAVs), Internet of things (IoTs), and multitude of sensors. In this article, we propose FogSurv—a fog-assisted surveillance architecture and framework leveraging artificial intelligence (AI) and information/data fusion for enabling real-time SA and monitoring. We also propose an AI- and data-driven information fusion model for FogSurv to help provide (near) real-time SA, threat assessment, and automated decision-making. We further present a latency model for AI and information fusion processing in FogSurv. We then discuss several use cases of FogSurv that can have a huge impact on multifarious fronts of national significance ranging from safeguarding national security to monitoring of critical infrastructures. We conduct an extensive set of experiments to demonstrate that FogSurv using AI and data fusion help provide near real-time inferences and SA. Experimental results demonstrate that FogSurv provides a latency improvement of 37% on average over cloud architectures for the selected benchmarks. Results further indicate that combining AI with data fusion as in FogSurv can provide a speedup of up to $9.8\times $ over AI without data fusion while also maintaining or improving the inference accuracy. Additionally, results show that AI combined with fusion of different image modalities obtained through UAVs in FogSurv results in improved average precision of target detection for surveillance as compared to AI without data fusion for different target scales and environment complexity.},
keywords={Surveillance;Artificial intelligence;Computer architecture;Cloud computing;Data integration;Real-time systems;Peer-to-peer computing;Urban surveillance;situational awareness;fog computing;unmanned aerial vehicles;information fusion;artificial intelligence;deep neural networks},
doi={10.1109/ACCESS.2021.3102598},
ISSN={2169-3536},
month={},}
@INPROCEEDINGS{8524800,
author={Bálint, Krisztián},
booktitle={2018 IEEE 16th International Symposium on Intelligent Systems and Informatics (SISY)}, title={UAVs with Biometric Facial Recognition Capabilities in the Combat Against Terrorism},
year={2018},
volume={},
number={},
pages={000185-000190},
abstract={Terrorism represents an ever-growing danger these days. Regretfully, acts of terrorism have been recurring in an ever-growing number. Due to the rapid development of computer science in the 21st century, it is necessary to find a technical solution enabling the pretermission or prevention of the acts of terror. The unmanned aerial vehicles (UAVs) capable of biometric facial recognition may have a great contribution to the prevention of an eventual act of terror committed by suspicious persons, who jeopardize or end lives of innocent people. In large cities, or during mass happenings, timely identification of the suspicious persons represents a key question of national security. The aim of the present research is to find answers regarding the questions concerning the identification of drones to become efficient and operable. Such a question can be like what kind of battery should be installed on a drone, as this greatly influences flight time. Furthermore, it is important to consider the question of artificial intelligence, as an image taken by a drone is only relevant when it can be rapidly compared with the images of suspicious persons in the database on hand. The article digresses even to what kind of camera should be installed on the UAVs, respectively, the type of the most optimal communication between the user and the vehicle.},
keywords={Terrorism;Face recognition;Organizations;Databases;Unmanned aerial vehicles;Cameras;Face;biometric facial recognition;UAVs;communication;terrorism},
doi={10.1109/SISY.2018.8524800},
ISSN={1949-0488},
month={Sep.},}
@INPROCEEDINGS{8810987,
author={Niccolai, Alessandro and Gandelli, Alessandro and Grimaccia, Francesco and Zich, Riccardo and Leva, Sonia},
booktitle={2019 IEEE Milan PowerTech}, title={Overview on Photovoltaic Inspections Procedure by means of Unmanned Aerial Vehicles},
year={2019},
volume={},
number={},
pages={1-6},
abstract={Inspection of photovoltaic power plants is a crucial aspect for improving the performances and increasing their profitability. The reduced O&M budget pushes the market to more effective inspection procedures. In this framework, Unmanned Aerial Vehicles have been proved to be very effective for the reduced amount of time required and for the higher quality of the obtained information with respect to traditional inspections.Furthermore UAVs application becomes very attractive if combined with artificial intelligence and computational techniques for the fast and effective analysis of the large amount of data (in the great majority of the cases of pictures) get by UAVs.In this paper, an overview on the entire inspection process, from the planning to the exploitation of the results obtained is provided. All the aspects are analysed and the open issues highlighted.},
keywords={Inspection;Image resolution;Cameras;Hardware;Indexing;Image recognition;Drones;Photolvoltaic monitoring;Unmanned Aerial Vehicles;Computational Intelligence;Sensors},
doi={10.1109/PTC.2019.8810987},
ISSN={},
month={June},}
@INPROCEEDINGS{8861575,
author={Knyaz, Vladimir and Zheltov, Sergey and Lebedev, Georgy and Mikhailin, Denis and Goncharenko, Vladimir},
booktitle={IEEE EUROCON 2019 -18th International Conference on Smart Technologies}, title={Intelligent mobile object monitoring by unmanned aerial vehicles},
year={2019},
volume={},
number={},
pages={1-6},
abstract={The progress in technical characteristics of unmanned aerial vehicles (UAV) creates a background for their expanding use in applications where human capabilities are limited. Such applications as object monitoring in hard-to-get environment, extremal sport rally, rescue operation, require object surveillance in large regions and complex conditions. To provide high level of UAV autonomy three tasks should be solved: intelligent mission planning, object recognition and on the fly mission modifying according to changing conditions. The paper presents algorithms for these tasks based on artificial intelligence techniques.},
keywords={Unmanned aerial vehicles;Object recognition;Task analysis;Planning;Cameras;Convolutional neural networks;Monitoring;Mission planning, genetic algorithm, object recognition, convolutional neural network, unmanned aerial vehicle, fuzzy logic},
doi={10.1109/EUROCON.2019.8861575},
ISSN={},
month={July},}
@INPROCEEDINGS{7778103,
author={Maleki, K. Niki and Ashenayi, Kaveh and Hook, Loyd R and Fuller, Justin G and Hutchins, Nathan},
booktitle={2016 IEEE/AIAA 35th Digital Avionics Systems Conference (DASC)}, title={A reliable system design for nondeterministic adaptive controllers in small UAV autopilots},
year={2016},
volume={},
number={},
pages={1-5},
abstract={Despite the tremendous attention Unmanned Aerial Vehicles (UAVs) have received in recent years for applications in transportation, surveillance, agriculture, and search and rescue, as well as their possible enormous economic impact, UAVs are still banned from fully autonomous commercial flights. One of the main reasons for this is the safety of the flight. Traditionally, pilots control the aircraft when complex situations emerge that even advanced autopilots are not able to manage. Artificial Intelligence based methods and Adaptive Controllers have proven themselves to be efficient in scenarios with uncertainties; however, they also introduce another concern: nondeterminism. This research endeavors to find a solution on how such algorithms can be utilized with higher reliability. Our method is based on using an adaptive model to verify the performance of a control parameter - proposed by a nondeterministic adaptive controller or AI-based optimizer - before it is deployed on the physical platform. Furthermore, a backup mechanism is engaged to recover the drone in case of failure. A Neural Network is employed to model the aircraft, and a Genetic Algorithm is utilized to optimize the PID controller of a quadcopter. The initial experimental results from test flights indicate the feasibility of this method.},
keywords={Adaptation models;Genetic algorithms;Drones;Artificial intelligence;Atmospheric modeling;Adaptive systems;Neural networks;Adaptive Controller;Artificial Intelligence;Genetic Algorithm;Neural Network;Quadcopter},
doi={10.1109/DASC.2016.7778103},
ISSN={2155-7209},
month={Sep.},}
@INPROCEEDINGS{9273977,
author={li, Lu and Luo, Xiaoyan and Wan, Han and Wu, Chengxi and Zheng, Yu and Zhou, Fugen},
booktitle={2020 IEEE Frontiers in Education Conference (FIE)}, title={A Comprehensive Experiment to Enhance Multidisciplinary Engineering Ability via UAVs Visual Navigation},
year={2020},
volume={},
number={},
pages={1-5},
abstract={This Research to Practice WIP presents a UAVs visual navigation based comprehensive experiment to enhance multidisciplinary engineering ability in Aerospace engineering education. In traditional courses, aerospace-related disciplines are independently distributed in different courses, and there is rarely a hands-on platform which includes signal processing, control theory, and artificial intelligence into Aerospace engineering. Facing this problem, this paper designs a multidisciplinary comprehensive experiment, aiming to provide a hand-on platform and flexible project-based program to students of aerospace engineering professions. First of all, in order to let the students understand actual aerospace problems, a multidisciplinary simulation platform containing UAVs and remote objects scenarios is constructed for them to explore in the experiments. Second, the content of the experiment is designed into three stages including data acquisition and processing, conceptual design and simulation, in-flight validation, during which the multidisciplinary engineering ability runs through the whole process of the activities. Finally, Project Oriented Design Based Learning is also introduced here to combine engineering design education with innovation and creativity. Through the project demonstration and presentation at the end of the experiment, the multidisciplinary engineering ability of each student can be effectively evaluated. The UVN comprehensive experiment enables students to work on real-world aerospace engineering problems through a hardware-software integration framework, which may greatly stimulate their curiosity and interest in autonomously learning. It also provides students unprecedented opportunities to immerse themselves in projects that cross disciplinary boundaries, improve their professional ability and enhance their exploration competence in aerospace areas.},
keywords={Aerospace engineering;Visualization;Image processing;Data models;Data acquisition;Aerospace control;Remote sensing;Multidisciplinary Engineering Ability;Comprehensive Experiment;Aerospace Engineering;UAVs Visual Navigation},
doi={10.1109/FIE44824.2020.9273977},
ISSN={2377-634X},
month={Oct},}
@INPROCEEDINGS{7988808,
author={de Oliveira, Hugo Andrade and Ferreira Rosa, Paulo Fernando},
booktitle={2017 International Conference on Military Technologies (ICMT)}, title={Genetic neuro-fuzzy approach for unmanned fixed wing attitude control},
year={2017},
volume={},
number={},
pages={485-492},
abstract={With the imminent growth and the progressive interest in the subject, the unmanned aerial vehicles (UAVs) are already a reality in our daily life. The search for air vehicles, which is ambitious for a future in which the UAVs can act autonomously and safely, continuously drives this sector. The present work aims to apply artificial intelligence techniques to classical control systems, in order to control the attitude of a fixed wing aircraft adaptively. The open source software ArduPlane was used as the basis for this project, which has an enhanced implementation of a PID controller for attitude. It is noteworthy the need to frequent adjustment for gains tied to the attitude control system; either for basic adjustment constants, as well as for parameters whose calibration needs specific technical knowledge of the system. In order to automate this process and ensure the optimization of these parameters throughout the mission, a genetic neuro-fuzzy approach was proposed to make this procedure implicit and transparent to the flight operator. With the use of an Adaptive Neuro-Fuzzy Inference System (ANFIS) capable of predicting the attitude of the aircraft, together with an optimization system (genetic algorithm), it is possible to construct an efficient control architecture, which ensures an improved control that always searches for optimized parameters throughout the mission autonomously.},
keywords={Software;Attitude control;Genetic algorithms;Aircraft;Genetics;Optimization;Hardware;UAV;Fixed Wing;ANFIS;Genetic Algorithm;AI;Attitude Controller},
doi={10.1109/MILTECHS.2017.7988808},
ISSN={},
month={May},}
@INPROCEEDINGS{9476742,
author={Savva, Antonis and Zacharia, Angelos and Makrigiorgis, Rafael and Anastasiou, Antreas and Kyrkou, Christos and Kolios, Panayiotis and Panayiotou, Christos and Theocharides, Theocharis},
booktitle={2021 International Conference on Unmanned Aircraft Systems (ICUAS)}, title={ICARUS: Automatic Autonomous Power Infrastructure Inspection with UAVs},
year={2021},
volume={},
number={},
pages={918-926},
abstract={Power transmission and distribution networks mostly span across harsh environments and thus, frequent faults and failures are observed, increasing the maintenance costs, pressing the authorities to provide electricity continuously and uninterruptedly. To this end, thorough field inspections with skilled personnel are regularly conducted, which are labor-intensive, costly and slow, whereby efficiency and staff safety cannot be always ensured. UAVs stem as a promising solution for power infrastructure inspection; however, their use is mostly limited by the fact that a remote pilot is in control of flight and mission processes, rendering reliable data acquisition in short time interval a tedious task. Despite research efforts for automating inspection procedures, these have not been widely adopted. In this study, we address this challenge by developing a Power Distribution Network Inspection Platform Using UAVs (ICARUS), based on a vision-based artificial intelligence toolkit, that integrates multiple sensors and automates many tasks, such as detection, tracking and identification of infrastructure components, gathering reliable spatial/time data associated to these components autonomously, safely and fast.},
keywords={Process control;Power transmission;Pressing;Inspection;Rendering (computer graphics);Aircraft navigation;Safety;power line inspection;vision-based inspection;autonomous navigation;unmanned aerial vehicles;deep learning},
doi={10.1109/ICUAS51884.2021.9476742},
ISSN={2575-7296},
month={June},}
@ARTICLE{9369851,
author={Moussa, Majda and Beltrame, Giovanni},
journal={IEEE Robotics and Automation Letters}, title={Real-Time Path Planning With Virtual Magnetic Fields},
year={2021},
volume={6},
number={2},
pages={3279-3286},
abstract={Humans and animals have learned or evolved to use magnetic fields for navigation. Knowing how to model and estimate these fields can be used for motion planning. However, computing the propagation of electromagnetic fields in a given environment requires solving complex differential equations with advanced numerical methods, and therefore it is not suitable for real-time decision making. In this latter, we present a real-time approximator for Maxwell's equations based on deep neural networks that predicts the distribution of a virtual magnetic field. We show how our approximator can be used to perform autonomous 2D navigation tasks, outperforming state-of-the-art navigation algorithms, ensuring completeness, and providing a near-optimal path up to 200 times per second without any post processing stage. We demonstrate the effectiveness of our method with physics-based simulations of an unmanned aerial vehicle, an autonomous car, as well as real-world experiments using a small off-road autonomous racing vehicle. Furthermore, we show how the approach can be applied to multi-robot systems, video game technology, and can be extended to 3D problems.},
keywords={Conductivity;Magnetic resonance imaging;Real-time systems;Robots;Path planning;Magnetosphere;Computational modeling;Autonomous vehicle navigation;deep learning;path planning;robotics},
doi={10.1109/LRA.2021.3063992},
ISSN={2377-3766},
month={April},}
@INPROCEEDINGS{6693261,
author={Castellucci, Pedro B. and Lucca, Luiz C. and SantAnna, Marcelo and Traballe, Gustavo and Mustacio, Victor H. and Silva, José Franciso Resende da and Vallin, Sérgio},
booktitle={2013 Latin American Robotics Symposium and Competition}, title={Pole and Crossarm Identification in Distribution Power Line Images},
year={2013},
volume={},
number={},
pages={2-7},
abstract={Society is getting more and more dependent of the energy industry. Therefore it is producers, distributors and consumers interest that the energy system is maintained accordingly. Nowadays, only 20% of a distribution grid is covered by preventive inspections. This work present an initial step in a system of preventively inspect a network using an Unmanned Aerial Vehicle that will acquire low altitude images of the distribution system network and an intelligent image analysis is used to look for irregularities in the network. Here, a method for identifying poles and cross arms using neural networks is presented. Also, measurements done in the image database allowed to define a somewhat non-conventional set of entries increasing the hit hate by more than 20%. The results justify, once more, the advantages of exploring the available knowledge around a problem.},
keywords={Image color analysis;Training;Inspection;Artificial neural networks;Image databases;Pattern classification;distribution lines;image analysis;aerial images;neural networks;feature analysis},
doi={10.1109/LARS.2013.48},
ISSN={},
month={Oct},}
@ARTICLE{8405592,
author={Li, Yan and Pan, Chaofeng and Cao, Xianbin and Wu, Dapeng},
journal={IEEE Transactions on Emerging Topics in Computational Intelligence}, title={Power Line Detection by Pyramidal Patch Classification},
year={2019},
volume={3},
number={6},
pages={416-426},
abstract={Obstacle recognition, especially power line detection, is very important for the safety of unmanned aerial vehicle flight. Current methods for power line detection mainly rely on the assistance of spatial context, such as tower-line correlation. These methods tend to produce low detection rates without auxiliaries while high false alarm rates due to heavy clutters caused by complicated backgrounds. In this paper, we propose a pyramidal patch classification framework that explicitly excludes the clutters without any extra auxiliaries. This framework enables good balance between detection precision and time-critical requirement; thanks to the proposed hierarchical patches partition and selection strategy. Accordingly, we design a new spatial grid pooling layer for our convolutional-neural-networks-based classifier, which is trained on the set of pyramidal patches. The final power lines are obtained by line detection in each patch of the smallest size, coupled with a line-line correlation procedure. Our experiments show that the proposed method can eliminate most false alarms and obtain a high detection rate with low computational cost.},
keywords={Image segmentation;Feature extraction;Correlation;Detection algorithms;Safety;Unmanned aerial vehicles;Time factors;Power line detection;aerial images;pyramidal patch classification;spatial grid pooling},
doi={10.1109/TETCI.2018.2849414},
ISSN={2471-285X},
month={Dec},}
@INPROCEEDINGS{9659899,
author={Alvey, Brendan J. and Anderson, Derek T. and Yang, Clare and Buck, Andrew and Keller, James M. and Yasuda, Ken E. and Ryan, Hollie A.},
booktitle={2021 IEEE Symposium Series on Computational Intelligence (SSCI)}, title={Characterization of Deep Learning-Based Aerial Explosive Hazard Detection using Simulated Data},
year={2021},
volume={},
number={},
pages={1-8},
abstract={Automatic object detection is one of the most common and fundamental tasks in computational intelligence (CI). Neural networks (NNs) are now often the tool of choice for this task. Unlike more traditional approaches that have interpretable parameters, explaining what a NN has learned and characterizing under what conditions the model does and does not perform well is a challenging, yet important task. The most straightforward approach to evaluate performance is to run test imagery through a model. However, the gaining popularity of self-supervised methods among big players such as Tesla and Google serve as evidence that labeled data is scarce in real-world settings. On the other hand, modern high-fidelity graphics simulation is now accessible and programmable, allowing for generation of large amounts of accurately labeled training and testing data for CI. Herein, we describe a framework to assess the performance of a NN model for automatic explosive hazard detection (EHD) from an unmanned aerial vehicle using simulation. The data was generated by the Unreal Engine with Microsoft's AirSim plugin. A workflow for generating simulated data and using it to assess and understand strengths and weaknesses in a learned EHD model is demonstrated.},
keywords={Training;Atmospheric modeling;Computational modeling;Artificial neural networks;Data models;Hazards;Explosives},
doi={10.1109/SSCI50451.2021.9659899},
ISSN={},
month={Dec},}
@ARTICLE{8270594,
author={Shin, Jongho and Kwak, Kiho and Kim, Suseong and Kim, H. Jin},
journal={IEEE/ASME Transactions on Mechatronics}, title={Adaptive Range Estimation in Perspective Vision System Using Neural Networks},
year={2018},
volume={23},
number={2},
pages={972-977},
abstract={This paper proposes an adaptive range estimation method in a perspective vision system using neural networks (NN). With a universal function approximation property of the NN, this study first defines the NN-based range value and the adaptive observer to determine the distance is designed with the known object motion, i.e., translational and rotational velocities. To remove the uncertainty between the true range and the estimated value, the proposed estimator utilizes a saturation function with a time-varying gain. The adaptive rules of the weight parameters of the NN and time-varying gain are derived using Lyapunov stability theory and the overall closed-loop stability is proven by introducing a deadzoned estimation error, which is composed of the estimation error and the saturation function. Finally, to validate the performance of the proposed method, experiments are conducted for the estimation of the relative distance between a target and a camera mounted on a multirotor unmanned aerial vehicle with an inertial measurement unit and a motion capture system.},
keywords={Cameras;Artificial neural networks;Observers;Estimation error;Unmanned aerial vehicles;Robot vision systems;Adaptive estimation;neural networks (NN);robot vision systems},
doi={10.1109/TMECH.2018.2798819},
ISSN={1941-014X},
month={April},}
@ARTICLE{8839109,
author={Zhang, Yu and Zhang, Yan and Shi, Zhiguang and Zhang, Jinghua and Wei, Ming},
journal={IEEE Access}, title={Design and Training of Deep CNN-Based Fast Detector in Infrared SUAV Surveillance System},
year={2019},
volume={7},
number={},
pages={137365-137377},
abstract={Real-time detection of small unmanned aerial vehicle (SUAV) targets in SUAV surveillance systems has become a challenge due to their high mobility, sudden bursts, and small sizes. In this study, we used infrared sensors and Convolutional Neural Networks (CNN)-based detectors to achieve the real-time detection of SUAV targets. Existing object detectors generally suffer from a computational burden or low detection accuracy on small targets, which limits their practicality and further application in SUAV surveillance systems. To solve these problems, we developed a real-time SUAV target detection algorithm based on deep residual networks. In order to improve the sensitivity to small targets, a laterally connected multi-scale feature fusion approach was proposed to fully combine the context features and semantic features. A densely paved pre-defined box with geometric analysis was used for single-stage prediction. Compared with the state-of-the-art object detectors, the proposed method achieved superior performance with respect to average-precision and frames-per-second. As the training set was limited, to improve generalization, we investigate the benefits introduced by data augmentation and data balance, and proposed a weighted augmentation approach. The proposed approach improved the robustness of the detector and the overall accuracy.},
keywords={Feature extraction;Detectors;Training;Object detection;Real-time systems;Surveillance;Semantics;Small unmanned aerial vehicle (SUAV) surveillance;infrared target detection;real-time detection;data augmentation},
doi={10.1109/ACCESS.2019.2941509},
ISSN={2169-3536},
month={},}
@INPROCEEDINGS{7487304,
author={Oliveira, Gabriel L. and Valada, Abhinav and Bollen, Claas and Burgard, Wolfram and Brox, Thomas},
booktitle={2016 IEEE International Conference on Robotics and Automation (ICRA)}, title={Deep learning for human part discovery in images},
year={2016},
volume={},
number={},
pages={1634-1641},
abstract={This paper addresses the problem of human body part segmentation in conventional RGB images, which has several applications in robotics, such as learning from demonstration and human-robot handovers. The proposed solution is based on Convolutional Neural Networks (CNNs). We present a network architecture that assigns each pixel to one of a predefined set of human body part classes, such as head, torso, arms, legs. After initializing weights with a very deep convolutional network for image classification, the network can be trained end-to-end and yields precise class predictions at the original input resolution. Our architecture particularly improves on over-fitting issues in the up-convolutional part of the network. Relying only on RGB rather than RGB-D images also allows us to apply the approach outdoors. The network achieves state-of-the-art performance on the PASCAL Parts dataset. Moreover, we introduce two new part segmentation datasets, the Freiburg sitting people dataset and the Freiburg people in disaster dataset. We also present results obtained with a ground robot and an unmanned aerial vehicle.},
keywords={Image segmentation;Robots;Semantics;Image resolution;Training;Proposals;Feature extraction},
doi={10.1109/ICRA.2016.7487304},
ISSN={},
month={May},}
@INPROCEEDINGS{8977051,
author={Daviran, Richard and Quispe, Grimaldo and Chavez-Arias, Heyul and Raymundo-Ibañez, Carlos and Dominguez, Francisco},
booktitle={2019 IEEE 39th Central America and Panama Convention (CONCAPAN XXXIX)}, title={Design of an unmanned aerial system for the detection of dangerous areas during fires},
year={2019},
volume={},
number={},
pages={1-6},
abstract={This article presents the design of an unmanned aerial vehicle manufactured in aramid, through the use of sensors and actuators for flight stabilization, capturing the images through a thermal imager and its wireless transmission for ground processing for application in the social security area used in fire accidents. The work shows that it is feasible to use the aramid material for the construction of the prototype, since it is a high temperature resistant material, also the integration of neural networks for semi-automatic flight control. The results of this research will serve to develop more advanced control devices, with simple components and controls so that people with technological limitations can use it, so that they can save lives in danger, that of their colleagues or themselves.},
keywords={Aramid;Unmanned Aerial Vehicle;neural network;Save lives},
doi={10.1109/CONCAPANXXXIX47272.2019.8977051},
ISSN={},
month={Nov},}
@ARTICLE{8671503,
author={Mu, Chaoxu and Zhang, Yong},
journal={IEEE Transactions on Neural Networks and Learning Systems}, title={Learning-Based Robust Tracking Control of Quadrotor With Time-Varying and Coupling Uncertainties},
year={2020},
volume={31},
number={1},
pages={259-273},
abstract={In this paper, a learning-based robust tracking control scheme is proposed for a quadrotor unmanned aerial vehicle system. The quadrotor dynamics are modeled including time-varying and coupling uncertainties. By designing position and attitude tracking error subsystems, the robust tracking control strategy is conducted by involving the approximately optimal control of associated nominal error subsystems. Furthermore, an improved weight updating rule is adopted, and neural networks are applied in the learning-based control scheme to get the approximately optimal control laws of the nominal error subsystems. The stability of tracking error subsystems with time-varying and coupling uncertainties is provided as the theoretical guarantee of learning-based robust tracking control scheme. Finally, considering the variable disturbances in the actual environment, three simulation cases are presented based on linear and nonlinear models of quadrotor with competitive results to demonstrate the effectiveness of the proposed control scheme.},
keywords={Uncertainty;Couplings;Rotors;Adaptation models;Optimal control;Nonlinear systems;Time-varying systems;Adaptive dynamic programming (ADP);learning-based control;neural networks;Quadrotor;robust tracking control;time-varying and coupling uncertainties},
doi={10.1109/TNNLS.2019.2900510},
ISSN={2162-2388},
month={Jan},}
@ARTICLE{8522052,
author={Song, Yongduan and He, Liu and Zhang, Dong and Qian, Jiye and Fu, Jin},
journal={IEEE Transactions on Neural Networks and Learning Systems}, title={Neuroadaptive Fault-Tolerant Control of Quadrotor UAVs: A More Affordable Solution},
year={2019},
volume={30},
number={7},
pages={1975-1983},
abstract={This paper investigates the position and attitude tracking control problem of a quadrotor unmanned aerial vehicle subject to modeling uncertainties and actuator failures. A comprehensive mathematical model reflecting the nonlinearity and state-space coupling of the dynamics as well as actuation faults and external disturbances is derived. By combining the radial basis function neural networks (NNs) with virtual parameter estimating algorithms, an indirect NN-based adaptive fault-tolerant control scheme is developed, which exhibits several attractive features as compared with most existing methods: 1) it is not only robust and adaptive to nonparametric uncertainties but also tolerant to unexpected actuation faults; 2) it ensures stable tracking without the need for precise information on system model; and 3) it only involves one lumped parameter adaptation, thus is structurally simpler and computationally less expensive, rendering the resultant scheme less demanding in programming and more affordable for onboard implementation. The effectiveness and benefits of the proposed method are confirmed via computer simulation.},
keywords={Aerodynamics;Vehicle dynamics;Rotors;Heuristic algorithms;Artificial neural networks;Uncertainty;Fault tolerance;Actuation faults;fault-tolerant control (FTC);indirect neuroadaptive;unmanned aerial vehicle (UAV)},
doi={10.1109/TNNLS.2018.2876130},
ISSN={2162-2388},
month={July},}
@INPROCEEDINGS{9259777,
author={Kantue, Paulin and Pedro, Jimoh Olarewaju},
booktitle={2020 24th International Conference on System Theory, Control and Computing (ICSTCC)}, title={Integrated Fault Detection and Diagnosis of an Unmanned Aerial Vehicle using Time Difference of Arrival},
year={2020},
volume={},
number={},
pages={336-342},
abstract={An integrated approach to the fault detection and diagnosis (FDD) of an unmanned aerial vehicle is presented. A novel approach using the Time Difference Of Arrival (TDOA) principle has been developed to detect, isolate and identify an incipient fault condition in the rotor dynamics. The requirements of a reconfigurable controller (RC) has been taken into account through the real-time implementation of a continuous forward algorithm (CFA) with a golden section search (GSS) combined with a meta-heuristic global optimization technique. The training and testing data for Radial Basis Function Neural Networks (RBF-NN) learning and prediction were supplied in discrete-time and its integration capacity validated through a Hardware-in-the-loop simulation (HILS) using a Teensy 3.6 microcontroller. The Pseudo real-time desktop simulation showed that the FDD algorithm was able to detect and isolate an incipient rotor fault and supply the RC a post-fault model and associated fault uncertainties. This method showed robustness towards prediction errors (bias and variance) and can be used in an integrated fault-tolerant control framework.},
keywords={Fault detection;Time difference of arrival;Uncertainty;Fault tolerant systems;Fault tolerance;Artificial neural networks;Pulse width modulation;fault detection and diagnosis;Unmanned Systems;rotor dynamics;radial basis functions;incipient fault;time difference of arrival},
doi={10.1109/ICSTCC50638.2020.9259777},
ISSN={2372-1618},
month={Oct},}
@INPROCEEDINGS{9173158,
author={Piao, Zhengquan and Zhao, Baojun and Tang, Linbo and Tang, Wei and Zhou, Shichao and Jing, Donglin},
booktitle={2019 IEEE International Conference on Signal, Information and Data Processing (ICSIDP)}, title={VDetor: An Effective and Efficient Neural Network for Vehicle Detection in Aerial Image},
year={2019},
volume={},
number={},
pages={1-4},
abstract={Vehicle detection in aerial image is the foundation of some applications, such as the traffic management, parking lot utilization, etc. Recently, universal object detection methods based on the convolutional neural networks have achieved state-of-the-art performances, this is mainly because CNNs can extract more effective features compared with the handcrafted features in early mainstream methods. Extracting effective feature is crucial for vehicle detection in aerial image where the vehicles are small and the background is rather complicated. As a result, these methods based on CNNs have been used to detect the vehicles in aerial image. However, the performance may be poor when directly performing these universal methods. Firstly, these existing methods mostly detect the vehicles with horizontal bounding boxes. But these horizontal boxes do not match the vehicles in aerial image with arbitrary orientations and multiply aspect ratios. As a result, this kind of box would harm the detection accuracy directly. In addition, these methods are mostly computationally expensive, so they are not suitable for the platform with limited computational resources, for example the unmanned aerial vehicle. To address these problems above, by introducing the rotated bounding box regression and a lightweight network into SSD, we propose our vehicle detection networks, VDetor. Specifically, we use rotated bounding box rather than horizontal one to match the vehicle well and use a lightweight network, PeleeNet, as the backbone network of SSD to speed up the inference. Experiments on VEDAI dataset illustrate that our model performs better than SSD in terms of the detection accuracy and detection speed.},
keywords={vehicle detection;deep learning;SSD;PeleeNet;aerial image},
doi={10.1109/ICSIDP47821.2019.9173158},
ISSN={},
month={Dec},}
@INPROCEEDINGS{8793848,
author={Hutchinson, Michael and Ladosz, Pawel and Liu, Cunjia and Chen, Wen-Hua},
booktitle={2019 International Conference on Robotics and Automation (ICRA)}, title={Experimental Assessment of Plume Mapping using Point Measurements from Unmanned Vehicles},
year={2019},
volume={},
number={},
pages={7720-7726},
abstract={This paper presents experiments to assess the plume mapping performance of autonomous robots. The paper compares several mapping algorithms including Gaussian Process regression, Neural networks and polynomial and piecewise linear interpolation. The methods are compared in Monte Carlo simulations using a well known plume model and in indoor experiments using a ground robot. Unlike previous work on mapping using unmanned vehicles, the indoor experiments were performed in a controlled and repeatable manner where a steady state ground truth could be obtained in order to properly assess the various regression methods using data from a real dispersive source and sensor. The effect of sampling time during data collection was assessed with regards to the mapping accuracy, and the data collected during the experiments have been made available. Overall, the Gaussian Process method was found to perform the best among the regression algorithms, showing more robustness to the noisy measurements obtained from short sampling periods, enabling an accurate map to be produced in significantly less time. Finally, plume mapping results are presented in uncontrolled outdoor conditions, using an unmanned aerial vehicle, to demonstrate the system in a realistic uncontrolled environment.},
keywords={Robot sensing systems;Interpolation;Gaussian processes;Dispersion;Noise measurement;Neural networks},
doi={10.1109/ICRA.2019.8793848},
ISSN={2577-087X},
month={May},}
@INPROCEEDINGS{9553232,
author={Marques, Ademir and Racolte, Graciela and de Souza, Eniuce Menezes and Domingos, Hiduino Venâncio and Horota, Rafael Kenji and Motta, João Gabriel and Zanotta, Daniel Capella and Cazarin, Caroline Lessio and Gonzaga, Luiz and Veronez, Maurício Roberto},
booktitle={2021 IEEE International Geoscience and Remote Sensing Symposium IGARSS}, title={Deep Learning Application for Fracture Segmentation Over Outcrop Images from UAV-Based Digital Photogrammetry},
year={2021},
volume={},
number={},
pages={4692-4695},
abstract={Fractures affect the intrinsic properties of permeability and porosity of reservoir geobodies, making its network characterization an important task for fluid flow modeling. Direct acquisition of data on reservoirs is labor-intensive and generally produces sparse information. Thus, the study of analogue outcrops with similar characteristics is often carried out by using unmanned aerial vehicle image acquisition and digital photogrammetry. However, the accurate automatic recognition of the fractures network over the outcrop images remains a challenge. Image segmentation methods based on convolution neural networks (CNNs) were successfully applied in medicine, biology, and other areas, however, not yet in geological fracture detection. This work proposes the validation of two popular CNNs - Segnet and Unet - for pixel-to-pixel segmentation targeting fracture detection. Initial results showed acceptable scores of the metrics mean intersection over union (mIoU) and dice intersection (F1) in both CNNs.},
keywords={Measurement;Image segmentation;Image recognition;Geology;Neural networks;Geoscience and remote sensing;Reservoirs;Fracture detection;CNN;Unet;Segnet;UAV;Photogrammetry;Segmentation},
doi={10.1109/IGARSS47720.2021.9553232},
ISSN={2153-7003},
month={July},}
@INPROCEEDINGS{9295894,
author={Zeng, Xiaoli and Liu, Yichuan},
booktitle={2020 IEEE 20th International Conference on Communication Technology (ICCT)}, title={A Multiple Representation Network with Adversarial Regularization for Automatic Modulation Recognition},
year={2020},
volume={},
number={},
pages={213-217},
abstract={In this paper, we proposed a multiple representation network with adversarial regularization (MRN_AR) for automatic modulation recognition. For multiple representation module, the MRN_AR can extract features with different scales to improve recognition accuracy by utilizing convolutional neural networks. Moreover, the adversarial regularization was employed for improving generalization of the network. The adversarial regularization was conducted by virtual adversarial training, which can promote the robustness of the model for conditional label distribution by local disturbance. Experiments on unmanned aerial vehicle communication signal datasets demonstrates the effectiveness of the proposed method.},
keywords={Modulation;Feature extraction;Convolution;Training;Kernel;Neural networks;Convolutional neural networks;automatic modulation recognition;convolutional neural networks;multiple representation;adversarial regularization},
doi={10.1109/ICCT50939.2020.9295894},
ISSN={2576-7828},
month={Oct},}
@ARTICLE{9327466,
author={Liu, Wei and Xu, Jiawei and Guo, Zihui and Li, Erzhu and Li, Xing and Zhang, Lianpeng and Liu, Wensong},
journal={IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing}, title={Building Footprint Extraction From Unmanned Aerial Vehicle Images Via PRU-Net: Application to Change Detection},
year={2021},
volume={14},
number={},
pages={2236-2248},
abstract={As the manual detection of building footprint is inefficient and labor-intensive, this study proposed a method of building footprint extraction and change detection based on deep convolutional neural networks. The study modified the existing U-Net model to develop the “PRU-Net” model. PRU-Net incorporates pyramid scene parsing (PSP) to allow multiscale scene parsing, a residual block (RB) in ResNet for feature extraction, and focal loss to address sample imbalance. Within the proposed method, building footprint extraction is conducted as follows: 1) unmanned aerial vehicle images are cropped, denoised, and semantically marked, and datasets are created (including training/validation and prediction datasets); 2) the training/validation and prediction datasets are input into the full convolutional neural network PRU-Net for model training/validation and prediction. Compared with the U-Net, PSP+U-Net (PU-Net), and U-Net++ models, PRU-Net offers improved footprint extraction of buildings with a range of sizes and shapes. The large-scale experimental results demonstrated the effectiveness of the PSP module for multiscale scene analysis and the RB module for feature extraction. After demonstrating the improvements in building extraction offered by PRU-Net, the building footprint results were further processed to generate a building change map.},
keywords={Feature extraction;Buildings;Licenses;Semantics;Predictive models;Image segmentation;Data mining;Building footprint change detection;deep convolutional neural network (DCNN);U-Net;unmanned aerial vehicle (UAV) image},
doi={10.1109/JSTARS.2021.3052495},
ISSN={2151-1535},
month={},}
@INPROCEEDINGS{9197140,
author={Zein, Mohammad Kassem and Sidaoui, Abbas and Asmar, Daniel and Elhajj, Imad H.},
booktitle={2020 IEEE International Conference on Robotics and Automation (ICRA)}, title={Enhanced Teleoperation Using Autocomplete},
year={2020},
volume={},
number={},
pages={9178-9184},
abstract={Controlling and manning robots from a remote location is difficult because of the limitations one faces in perception and available degrees of actuation. Although humans can become skilled teleoperators, the amount of training time required to acquire such skills is typically very high. In this paper, we propose a novel solution (named Autocomplete) to aid novice teleoperators in manning robots adroitly. At the input side, Autocomplete relies on machine learning to detect and categorize human inputs as one from a group of motion primitives. Once a desired motion is recognized, at the actuation side an automated command replaces the human input in performing the desired action. So far, Autocomplete can recognize and synthesize lines, arcs, full circles, 3-D helices, and sine trajectories. Autocomplete was tested in simulation on the teleoperation of an unmanned aerial vehicle, and results demonstrate the advantages of the proposed solution versus manual steering.},
keywords={Task analysis;Trajectory;Robots;Training;Support vector machines;Manuals;Drones},
doi={10.1109/ICRA40945.2020.9197140},
ISSN={2577-087X},
month={May},}
@INPROCEEDINGS{9258813,
author={Zuo, Jiankai and Chen, Jiatong and Li, Zhengsheng and Li, Zhongzhi and Liu, Zeyuan and Han, Zhixuan},
booktitle={2020 International Conference on Communications, Information System and Computer Engineering (CISCE)}, title={Research on Maritime Rescue UAV Based on Beidou CNSS and Extended Square Search Algorithm},
year={2020},
volume={},
number={},
pages={102-106},
abstract={With the development of multi-intelligence related technologies and distributed artificial intelligence, people have gradually applied drones to maritime search and rescue work. Maritime search and rescue requires high efficiency and short search time, which is difficult, and how to use UAVs for efficient and rapid maritime search and rescue has become a major concern. In this paper, based on the extended square search algorithm, the original algorithm is improved, and the probability function of target discovery is introduced to make the algorithm closer to the actual search and rescue situation. Finally, based on the MATLAB platform, this paper simulates the algorithm by writing a program, and studies the relationship between flight height, search pitch and search width overlap ratio and search time. The simulation results show that the flying height of the drone is inversely proportional to the search time, and the overlap ratio is proportional to the time. In the aspect of emergency data backhaul and communication, based on the original agreement of Beidou, the necessary transmission agreement keywords are added to facilitate the subsequent processing of the data.},
keywords={Navigation;Intelligent control;Information systems;Multi-agent;Beidou navigation;Search efficiency;Intelligent control;Extended square search},
doi={10.1109/CISCE50729.2020.00027},
ISSN={},
month={July},}
@INPROCEEDINGS{8909267,
author={Favenza, Alfredo and Imam, Rayan and Dovis, Fabio and Pini, Marco},
booktitle={2019 IEEE International Workshop on Metrology for Agriculture and Forestry (MetroAgriFor)}, title={Detecting water using UAV-based GNSS-Reflectometry data and Artificial Intelligence},
year={2019},
volume={},
number={},
pages={7-12},
abstract={GNSS Reflectometry (GNSS-R) is a consolidated remote sensing technique that exploits the back-scattered GNSS signals to retrieve information about the Earth surface. By the use of GNSS-R sensors onboard UAVs, this tool can bring significant advantages in agriculture, especially for the detection of the presence of water/moisure in specific rural areas. However, to perform this detection, GNSS-R needs a priori calibration of a threshold on the received reflected power in order to distinguish the presence/no prence of water. This is a limitation for the adoption of this approach at large scale. The work presented in this paper aims at overcoming such a limitation, proposing a novel approach based on artificial intelligence for the automatic water detection on the Earth surface, avoiding a priori, empirical, thresholding.},
keywords={Sensors;Global navigation satellite system;Machine learning;Clustering algorithms;Machine learning algorithms;Agriculture;Measurement;GNSS-R;ICT;agriculture;k-means},
doi={10.1109/MetroAgriFor.2019.8909267},
ISSN={},
month={Oct},}
@INPROCEEDINGS{9356780,
author={Qi, Shuaitao},
booktitle={2020 7th International Forum on Electrical Engineering and Automation (IFEEA)}, title={Cleaning System Based on Autonomous Patrol of UAV and Intelligent Detection of Foreign Matters},
year={2020},
volume={},
number={},
pages={675-678},
abstract={In order to remove the foreign matters on the highvoltage transmission lines and high-voltage power towers, we designed a foreign matter cleaning system based on the UAV patrolling on a fixed path, aiming to solve the problem of foreign matters cleaning on the high-voltage wire by using artificial intelligence. It can improve the speed and efficiency of wire inspection and foreign matters removal, avoid accidents effectively, and also reduce the worker's intensity of work to ensure the operation safety.},
keywords={Power transmission lines;Wires;Search problems;Cleaning;Safety;Artificial intelligence;Accidents;automatic patrol;intelligent detection;foreign matters cleaning system},
doi={10.1109/IFEEA51475.2020.00144},
ISSN={},
month={Sep.},}
@INPROCEEDINGS{8575743,
author={Manderson, Travis and Holliday, Andrew and Dudek, Gregory},
booktitle={2018 15th Conference on Computer and Robot Vision (CRV)}, title={Gaze Selection for Enhanced Visual Odometry During Navigation},
year={2018},
volume={},
number={},
pages={110-117},
abstract={We present an approach to enhancing visual odometry and Simultaneous Localization and Mapping (SLAM) in the context of robot navigation by actively modulating the gaze direction to enhance the quality of the odometric estimates that are returned. We focus on two quality factors: i) stability of the visual features, and ii) consistency of the visual features with respect to robot motion and the associated correspondence between frames. We assume that local texture measures are associated with underlying scene content and thus with the quality of the visual features for the associated region of the scene. Based on this assumption, we train a machine-learning system to score different regions of an image based on their texture and then guide the robot's gaze toward high scoring image regions. Our work is targeted towards motion estimation and SLAM for small, lightweight, and autonomous air vehicles where computational resources are constrained in weight, size, and power. However, we believe that our work is also applicable to other types of robotic systems. Our experimental validation consists of simulations, constrained tests, and outdoor flight experiments on an unmanned aerial vehicle. We find that modulating gaze direction can improve localization accuracy by up to 62 percent.},
keywords={Cameras;Simultaneous localization and mapping;Visual odometry;Visualization;Real-time systems;Motion estimation;active sensing;robotics;vision;SLAM},
doi={10.1109/CRV.2018.00025},
ISSN={},
month={May},}
@INPROCEEDINGS{9386496,
author={XIANG, Bo and MENG, Hongfu and ZHOU, Jiawei and LIU, Yida and HE, Liang and LUO, Zhenghua and ZENG, Chao},
booktitle={2020 International Conference on Microwave and Millimeter Wave Technology (ICMMT)}, title={UAV Detection Research Based on A Low-cost SDR},
year={2020},
volume={},
number={},
pages={1-3},
abstract={In this paper, a low-cost SDR hardware platform is proposed. The hardware platform can carry out experiments using amplitude-comparison method, phase Interferometer, time difference of arrival and hybrid direction finding and locating techniques. By integrating with artificial intelligence algorithm of amplitude-comparison method is designed and is also implemented to complement the hardware platform. The outfield test show that accuracy of detecting UAV is about 10 degree with hardware platform with amplitude-comparison method.},
keywords={Microwave technology;Time difference of arrival;Software algorithms;Neural networks;Millimeter wave technology;Hardware;Software},
doi={10.1109/ICMMT49418.2020.9386496},
ISSN={},
month={Sep.},}
@INPROCEEDINGS{8817250,
author={Ming, Hua and Oyama, Katsunori},
booktitle={2019 IEEE World Congress on Services (SERVICES)}, title={Dimensional Situation Analytics: An Introduction and Its Application Prospects},
year={2019},
volume={2642-939X},
number={},
pages={133-134},
abstract={Dimensional situation analytics provides a formal framework to analyze situations from Data Information Knowl-edge Wisdom (DIKW) point of view. To date, the advent of big data driven applications opens up many frontiers in artificial intelligence and computer science, and yet it also raises a series of challenges due to theirs empirical and experimental nature. In particular, to systematically and analytically understand the logical connection through which intelligence and knowledge is derived from data and information deterministically is one of the far-reaching future objectives in computer science. Starting from an earlier result on Dimensional Situation Analytics (DSA), where the initial efforts targeted at the integration of situations and DIKW ontology, this paper brings the prospect of real world applications of DSA into perspective. A good example is UAV path planning for efficient radiation detection and monitoring, which links the pervious result, i.e., the DSA formal framework, with real world experimentation and thereof further explores on the effectiveness and future work for the DSA.},
keywords={Path planning;Ontologies;Decision making;Computer science;Software;Unmanned aerial vehicles;Monitoring;Dimensional Situaion Analytics, Ontology, Data Information Knowledge Wisdom (DIKW), Unmanned Aerial Vehicle (UAV)},
doi={10.1109/SERVICES.2019.00036},
ISSN={2642-939X},
month={July},}
@INPROCEEDINGS{7139675,
author={Souza, Jefferson R. and Mendes, Caio C. T. and Guizilini, Vitor and Vivaldini, Kelen C. T. and Colturato, Adimara and Ramos, Fabio and Wolf, Denis F.},
booktitle={2015 IEEE International Conference on Robotics and Automation (ICRA)}, title={Automatic detection of Ceratocystis wilt in Eucalyptus crops from aerial images},
year={2015},
volume={},
number={},
pages={3443-3448},
abstract={One of the challenges in precision agriculture is the detection of diseased crops in agricultural environments. This paper presents a methodology to detect the Ceratocystis wilt disease in Eucalyptus crops. An unmanned aerial vehicle is used to obtain high-resolution RGB images of a predefined area. The methodology enables the extraction of visual features from image regions and uses several supervised machine learning (ML) techniques to classify regions into three classes: ground, healthy and diseased plants. Several learning techniques were compared using data obtained from a commercial Eucalyptus plantation. Experimental results show that the GP learning model is more reliable than the other learning methods for accurately identifying diseased trees.},
keywords={Feature extraction;Training;Vegetation;Testing;Artificial neural networks;Image color analysis;Radio frequency},
doi={10.1109/ICRA.2015.7139675},
ISSN={1050-4729},
month={May},}
@INPROCEEDINGS{8343706,
author={Zhu, Mingzhu and Wang, Hongbo},
booktitle={2017 6th International Conference on Computer Science and Network Technology (ICCSNT)}, title={Fast detection of moving object based on improved frame-difference method},
year={2017},
volume={},
number={},
pages={299-303},
abstract={It is difficult to detect the moving object in the video which is captured with the moving camera, and it costs a lot of time to use current method of object detection, because there is a large false rate based on the basic method of moving object detection. In this paper, we propose an improved frame-difference method, which can shorten the running time and improve the accuracy of the object detection. The results of the experiment show that after adding the improved frame-difference method, the detection speed is increased by 21.06 times, the image detection accuracy is improved about 8%. The algorithm is robust and it can be adapted to different scenes including indoor and outdoor. It could be applied to the field of artificial intelligence, such as Intelligent Driving, UAV aerial detection technology and so on.},
keywords={Object detection;Cameras;Feature extraction;Streaming media;Image recognition;Machine learning algorithms;Artificial intelligence;Artificial Intelligence;moving object detection;frame-difference;robust},
doi={10.1109/ICCSNT.2017.8343706},
ISSN={},
month={Oct},}
@INPROCEEDINGS{9515736,
author={Yaqot, Mohammed and Menezes, Brenno C.},
booktitle={2021 1st International Conference on Emerging Smart Technologies and Applications (eSmarTA)}, title={Unmanned Aerial Vehicle (UAV) in Precision Agriculture: Business Information Technology Towards Farming as a Service},
year={2021},
volume={},
number={},
pages={1-7},
abstract={Humanity has facing emerging global issues as new virus diseases, extremes in weather conditions, increasing climatic changes, depletion of the environment and natural resources, sharply rising demand for food, to just name a few. Therefore, the agriculture industry has been challenged in its processes and products, resulting in a surge of application of novel technologies and practices to maintain itself sustainable. Despite that, this industry is still responsible for 37% of the worldwide workforce, consumes 34% of the global arable land, utilizes 70% of the total water, and emits up to 30% of greenhouse gases (GHG). Progressively widespread in the sector, smart farming is a high-tech, efficient, and sustainable approach achieved by applying integrated technologies within the agricultural value chain processes. It includes increasing feed and food production and decreasing of their waste, prediction of diseases, better estimation of product yields ahead of time, determination of the best harvest time, monitoring of plants-growth cycles, etc. The results are going to yield a sustainable use of soil and water resources while maintaining the green landscape and biodiversity of nature. Emerging remote-sensing technologies and artificial intelligence applications have become essential tools to address these challenges. Drones, also known as Unmanned aerial vehicles (UAVs) are among the most promising industry 4.0 (I4) applications for the next generation of agriculture. This paper is a forehead into applications of drones from the innovation economy's standpoint as a viable tool and an effective manpower replacement in the agro-industry. In such a field, artificial intelligence (AI) has the potential to be the engine for automation of processes to be integrated into cyber-physical systems and enhanced modeling towards improved agriculture, more efficiently than the previous stages of the applications of technologies in this sector. Agricultural communities and businesses must take a strategic approach for continuous improvement production processes by implementing quicker, safer, and cheaper plans through data analytics and farming as a service (FaaS).},
keywords={Economics;Data analysis;FAA;Tools;Biodiversity;Water resources;Drones;UAV;drones;information and communication technologies;innovation economy;data analytics},
doi={10.1109/eSmarTA52612.2021.9515736},
ISSN={},
month={Aug},}
@INPROCEEDINGS{9024679,
author={Wang, Li-Chun and Lai, Chuan-Chi and Shuai, Hong-Han and Lin, Hsin-Piao and Li, Chi-Yu and Cheng, Teng-Hu and Chen, Chiun-Hsun},
booktitle={2019 IEEE Globecom Workshops (GC Wkshps)}, title={Communications and Networking Technologies for Intelligent Drone Cruisers},
year={2019},
volume={},
number={},
pages={1-6},
abstract={Future mobile communication networks require an Aerial Base Station (ABS) with fast mobility and long-term hovering capabilities. At present, unmanned aerial vehicles (UAV) or drones do not have long flight times and are mainly used for monitoring, surveillance, and image post-processing. On the other hand, the traditional airship is too large and not easy to take off and land. Therefore, we propose to develop an "Artificial Intelligence (AI) Drone-Cruiser" base station that can help 5G mobile communication systems and beyond quickly recover the network after a disaster and handle the instant communications by the flash crowd. The drone-cruiser base station can overcome the communications problem for three types of flash crowds, such as in stadiums, parades, and large plaza so that an appropriate number of aerial base stations can be accurately deployed to meet large and dynamic traffic demands. Artificial intelligence can solve these problems by analyzing the collected data, and then adjust the system parameters in the framework of Self-Organizing Network (SON) to achieve the goals of self-configuration, self- optimization, and self-healing. With the help of AI technologies, 5G networks can become more intelligent. This paper aims to provide a new type of service, On-Demand Aerial Base Station as a Service. This work needs to overcome the following five technical challenges: innovative design of drone-cruisers for the long-time hovering, crowd estimation and prediction, rapid 3D wireless channel learning and modeling, 3D placement of aerial base stations and the integration of WiFi front-haul and millimeter wave/WiGig back-haul networks.},
keywords={Three-dimensional displays;Base stations;Wireless communication;Drones;Estimation;Millimeter wave communication;Artificial intelligence},
doi={10.1109/GCWkshps45667.2019.9024679},
ISSN={},
month={Dec},}
@INPROCEEDINGS{9600519,
author={Shehata, Hisham Arafat and El-Helw, Mohamed},
booktitle={2021 3rd Novel Intelligent and Leading Emerging Sciences Conference (NILES)}, title={Modeling Collaborative AI for Dynamic Systems of Blockchain-ed Autonomous Agents},
year={2021},
volume={},
number={},
pages={421-426},
abstract={Artificial Intelligence has been strongly evolving disrupting almost every research and application domain. One of the key attributes - and at the same time an enabler - of today's innovations is the massive connectivity resulted in the opportunity to exploit Artificial Intelligence across distributed network of self-contained smart agents those could range from software bots to complex devices like autonomous vehicles, IoT collations, UAVs and Robot Swarms. Such heterogenous networks of Autonomous Agents could differ in size, networking topology, protocols, computing profiles, algorithms, interaction strategy among other attributes thus require different factors to achieve desired combined intelligent goals. While Blockchain technology has been evolving with the birth and swift breakthrough of cryptocurrencies and cryptocontracts, alternate types have emerged to serve as a layer of trust among independent peer-to-peer computing nodes lend itself to be a foundation for distributed systems of edge inference agents. In this paper we discuss adopting a Collaborative AI edge model for dynamic systems of Blockchain-ed Autonomous Agents.},
keywords={Analytical models;Technological innovation;Computational modeling;Collaboration;Autonomous agents;Software;Peer-to-peer computing;Collaborative AI;Autonomous Agents;Robot Swarm;IoT Collation;UAVs;Blockchain DLT;Edge Computing},
doi={10.1109/NILES53778.2021.9600519},
ISSN={},
month={Oct},}
@INPROCEEDINGS{9534520,
author={Hao-peng, Sun and Xiao-gang, Tang and Yuan, Guangming and Sun’an, Wang},
booktitle={2021 2nd International Conference on Artificial Intelligence and Education (ICAIE)}, title={A Comparative Simulation Study of Multi-aircraft Cooperative Task Planning Based on Artificial Intelligence Optimization Algorithm},
year={2021},
volume={},
number={},
pages={15-24},
abstract={Considering the inherent characteristics of the return module in manned space missions, this paper proposes a multi-aircraft collaborative target search strategy and establishes a multi-aircraft collaborative target search model. Based on the analysis of collaborative search solutions, this paper proposes a multi-aircraft collaborative search task solution based on an artificial intelligence optimization algorithm. However, the general artificial intelligence optimization algorithm suffers from slow convergence rate and excessive resource consumption. In order to effectively address this problem, this paper proposes GA-Dstar hybrid UAV trajectory planning algorithm to reduce the computation time by using the Dstar algorithm for planning the local path for searching within the local search range. The simulation results show that the proposed hybrid algorithm is more effective than the traditional GA algorithm for performing a global search. The proposed algorithm significantly reduces resource consumption while maintaining the optimality of the trajectory planning route. The improved algorithm proposed in this work is useful for multi-aircraft collaborative mission planning and related research.},
keywords={Trajectory planning;Space missions;Simulation;Collaboration;Search problems;Planning;Artificial intelligence;Artificial Intelligence algorithms;multi-aircraft collaboration;mission planning;GA-Dstar hybrid algorithm},
doi={10.1109/ICAIE53562.2021.00011},
ISSN={},
month={June},}
@INPROCEEDINGS{8615853,
author={Le, Xuesong and Wang, Yufei and Jo, Jun},
booktitle={2018 Digital Image Computing: Techniques and Applications (DICTA)}, title={Combining Deep and Handcrafted Image Features for Vehicle Classification in Drone Imagery},
year={2018},
volume={},
number={},
pages={1-6},
abstract={Using unmanned aerial vehicles (UAVs) as devices for traffic data collection exhibits many advantages in collecting traffic information. This paper presents an efficient method based on the deep learning and handcrafted features to classify vehicles taken from drone imagery. Experimental results show that compared to classification algorithms based on pre-trained CNN or hand-crafted features, the proposed algorithm exhibits higher accuracy in vehicle recognition at different UAV altitudes with different view scopes, which can be used in future traffic monitoring and control in metropolitan areas.},
keywords={Feature extraction;Histograms;Training;Drones;Visualization;Image recognition;Deep learning;deep feature;handcrafted features;classification},
doi={10.1109/DICTA.2018.8615853},
ISSN={},
month={Dec},}
@INPROCEEDINGS{9019146,
author={Ding, Dian and Wang, Yangzhu and Xiao, Yao and Han, Zhen},
booktitle={2018 IEEE CSAA Guidance, Navigation and Control Conference (CGNCC)}, title={Low-altitude Fixed-wing UAV Obstacle Recognition Based on Deep Learning},
year={2018},
volume={},
number={},
pages={1-6},
abstract={This paper applies deep learning to obstacle identification in UAV flight. In order to achieve a better recognition effect, the dataset collates the two types of images of the simulation software screenshots and real-life photos. The basic principle of YOLO is briefly introduced. On the basis of not modifying the network, the data set is continuously trained using the pre-trained parameters. In this paper, we mainly optimize the loss function. The first is to optimize the difference between the simulation software screenshots and real photos by adding another weight. The second is class optimization, which increases the proportion of samples with low class confidence, like UAVs with different structures and colors. Finally achieved a good recognition effect.},
keywords={Training;Optimization;Target recognition;Machine learning;Feature extraction;Classification algorithms;Task analysis},
doi={10.1109/GNCC42960.2018.9019146},
ISSN={},
month={Aug},}
@INPROCEEDINGS{8101662,
author={Junoh, Shahmi and Aouf, Nabil},
booktitle={2017 Workshop on Research, Education and Development of Unmanned Aerial Systems (RED-UAS)}, title={Person classification leveraging Convolutional Neural Network for obstacle avoidance via Unmanned Aerial Vehicles},
year={2017},
volume={},
number={},
pages={168-173},
abstract={Obstacle avoidance capability for Unmanned Aerial Vehicles (UAVs) remains an active research in order to provide a better sense-and-avoid technology. More severely, in an environment where it contains and involves humans, the capability required is of high reliability and robustness. Prior to avoiding obstacles during mission, having a high performance of obstacle detection is deemed important. We first tackled the detection problem by solving the classification task. In this work, humans were treated as a special type of obstacles in indoor environment by which they may potentially cooperate with UAVs in indoor setting. While existing works have long been focusing on using classical computer vision techniques that suffer from substantial disadvantages with respect to robustness, studies on the use of deep learning approach i.e. Convolutional Neural Network (CNN) to achieve this purpose are still scarce. Using this approach for binary person classification task has revealed improved performance of more than 99% both for True Positive Rate (TPR) and True Negative Rate (TNR), hence, is promising for realizing robust obstacle avoidance.},
keywords={Training;Cameras;Robustness;Collision avoidance;Machine learning;Convergence},
doi={10.1109/RED-UAS.2017.8101662},
ISSN={},
month={Oct},}
@INPROCEEDINGS{9522771,
author={Pirvu, Mihai and Robu, Victor and Licaret, Vlad and Costea, Dragos and Marcu, Alina and Slusanschi, Emil and Sukthankar, Rahul and Leordeanu, Marius},
booktitle={2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)}, title={Depth distillation: unsupervised metric depth estimation for UAVs by finding consensus between kinematics, optical flow and deep learning},
year={2021},
volume={},
number={},
pages={3209-3217},
abstract={Estimating precise metric depth is an essential task for UAV navigation, which is very difficult to learn unsupervised without access to odometry. At the same time, depth recovery from kinematics and optical flow is mathematically precise, but less numerically stable and robust, especially in the focus of expansion areas. We propose a model that combines the analytical, vision-with-odometry approach, with deep unsupervised learning, into a single formulation for metric depth estimation, which is both fast and accurate. The two pathways – analytical and data-driven – form a robust ensemble, which provides supervisory signal to a single deep net that distills the consensus between scene geometry, pose, kinematics, camera intrinsics and the input RGB. The distilled net has low runtime and memory costs, being suitable for embedded devices. We validate our results against an off-the-shelf SfM-based solution. We also introduce a new real-world dataset of almost 20 minutes of continuous UAV flight, on which we demonstrate better accuracy and capabilities than the deep learning and analytical approaches.},
keywords={Measurement;Deep learning;Training;Geometry;Pipelines;Estimation;Kinematics},
doi={10.1109/CVPRW53098.2021.00359},
ISSN={2160-7516},
month={June},}
@ARTICLE{9408352,
author={Youn, Wonkeun and Lim, Hyungtae and Choi, Hyoung Sik and Rhudy, Matthew B. and Ryu, Hyeok and Kim, Sungyug and Myung, Hyun},
journal={IEEE Robotics and Automation Letters}, title={State Estimation for HALE UAVs With Deep-Learning-Aided Virtual AOA/SSA Sensors for Analytical Redundancy},
year={2021},
volume={6},
number={3},
pages={5276-5283},
abstract={High-altitudelong-endurance (HALE) unmanned aerial vehicles (UAVs) are employed in a variety of fields because of their ability to fly for a long time at high altitudes, even in the stratosphere. Two paramount concerns exist: enhancing their safety during long-term flight and reducing their weight as much as possible to increase their energy efficiency based on analytical redundancy approaches. In this letter, a novel deep-learning-aided navigation filter is proposed, which consists of two parts: an end-to-end mapping-based synthetic sensor measurement model that utilizes long short-term memory (LSTM) networks to estimate the angle of attack (AOA) and sideslip angle (SSA) and an unscented Kalman filter for state estimation. Our proposed method can not only reduce the weight of HALE UAVs but also ensure their safety by means of an analytical redundancy approach. In contrast to conventional approaches, our LSTM-based method achieves better estimation by virtue of its nonlinear mapping capability.},
keywords={Aerodynamics;Atmospheric measurements;Sensors;State estimation;Redundancy;Global Positioning System;Pollution measurement;Sensor fusion;aerial systems, applications;field robotics;ai-enabled robotics},
doi={10.1109/LRA.2021.3074084},
ISSN={2377-3766},
month={July},}
@ARTICLE{9357330,
author={Pokhrel, Shiva Raj},
journal={IEEE Sensors Journal}, title={Blockchain Brings Trust to Collaborative Drones and LEO Satellites: An Intelligent Decentralized Learning in the Space},
year={2021},
volume={21},
number={22},
pages={25331-25339},
abstract={In this paper, we develop a foundation for a constellation of Low Earth Orbit (LEO) satellite IoT by constructing a Blockchain-based framework for continual knowledge sharing and learning collaboratively. This approach is directly applicable for a swarm of Unmanned Aerial Vehicles (UAVs). We ablate Federated Learning (FL) successful features as a basis to ensure high precision of learning inferences at timescales relevant to the underlying time-varying space network and channel dynamics. In such a dynamic setting, there is always a likelihood that miners may be compromised or fail to propagate information in time because of some intrinsic factors such as channel impairments, satellite handovers and attacks. Such transmission failures often lead to undesirable forking events in the Blockchain. Consequently, maintaining a low energy consumption and smallish delay in such an erratic network is highly nontrivial and challenging. To quantify the impacts of the forking and minimize the occurrence of such unwanted events and their adverse effects, we develop a procedure to estimate the expected energy consumption for a given set of miners, block transmissions, and LEOs’ or UAVs’ mobility. Besides, we shed light on deep learning-based resource allocation for mobile mining and demonstrate the synergic gain of FL with Blockchain.},
keywords={Blockchain;Drones;Delays;Satellites;Low earth orbit satellites;Sensors;Collaborative work;Blockchain;federated learning;forking;low earth orbit (LEO) satellites;mobile miners;satellite-IoT;UAVs},
doi={10.1109/JSEN.2021.3060185},
ISSN={1558-1748},
month={Nov},}
@INPROCEEDINGS{9305491,
author={Cui, Aiya and Zhang, Ying and Zhang, Pengyu and Dong, Wei and Wang, Chunyan},
booktitle={2020 16th International Conference on Control, Automation, Robotics and Vision (ICARCV)}, title={Intelligent Health Management of Fixed-Wing UAVs: A Deep-Learning-based Approach},
year={2020},
volume={},
number={},
pages={1055-1060},
abstract={In this paper, the fault diagnosis and health management of fixed-wing UAVs are investigated based on the deep learning technique. The proposed method includes 5 models: flight data generation model, sample training prediction model based on the Long Short-Term Memory (LSTM) network, prediction model based on the grey model, combined prediction model and health calculation and management model. The realtime output of the health prediction value of the fixed-wing UAVs can be obtained, which makes it possible to take remedial action before the fault occurs. And numerical simulations demonstrate the feasibility of the proposed method.},
keywords={Predictive models;Data models;Mathematical model;Fault diagnosis;Atmospheric modeling;Aerodynamics;Adaptation models},
doi={10.1109/ICARCV50220.2020.9305491},
ISSN={},
month={Dec},}
@INPROCEEDINGS{9292632,
author={Feraru, Valeria Alexandra and Andersen, Rasmus Eckholdt and Boukas, Evangelos},
booktitle={2020 IEEE International Symposium on Safety, Security, and Rescue Robotics (SSRR)}, title={Towards an Autonomous UAV-based System to Assist Search and Rescue Operations in Man Overboard Incidents},
year={2020},
volume={},
number={},
pages={57-64},
abstract={Man overboard (MOB) incidents in open sea travel are a risk for the shipping industry. In this work we aim to design an autonomous system in charge of planning and executing a search for a person in water (PIW), victim of MOB. The proposed solution consists of an autonomous UAV that initiates a SAR mission when it receives a MOB signal. The UAV is located in an autonomous docking mechanism onboard the ship. The probabilistic leeway model is implemented to find the location of the PIW and a Deep Learning object detection algorithm (Faster R-CNN) is employed to locate the PIW. To the best of our knowledge, this is the first time that a search system on-board a vessel -capable of live planning and execution- is proposed. Our results indicate that employing our solution would increase the success probability of finding a PIW and decrease the total search time.},
keywords={Cameras;Marine vehicles;Uncertainty;Robots;Search problems;Probabilistic logic;Planning},
doi={10.1109/SSRR50563.2020.9292632},
ISSN={2475-8426},
month={Nov},}
@ARTICLE{9729188,
author={Dousai, Nayee Muddin Khan and Lončarić, Sven},
journal={IEEE Access}, title={Detecting Humans in Search and Rescue Operations Based on Ensemble Learning},
year={2022},
volume={10},
number={},
pages={26481-26492},
abstract={Detection of humans accurately in aerial images is critical for various applications such as surveillance, detecting and tracking athletes on sports fields, and search and rescue operations (SAR). The goal of SAR is to assist, detect, and rescue people who have had accidents in the mountains or other hazardous environments. By using drones in SAR applications, it is desirable to minimize the cost and time spent on SAR operations. In this paper, we present a convolutional neural network-based model for the detection of humans in aerial images of mountain landscapes acquired by unmanned aerial vehicles (UAVs) used in search and rescue operations. Detection of humans in aerial images remains a complex task due to various challenges such as pose and scale variations of humans, low visibility, camouflaged environment, adverse weather conditions, motion blur, and high-resolution aerial images. Due to imaging from high altitudes, in most high-resolution aerial images captured by UAVs, only 0.1 to 0.2 percentage of the image represents humans. To solve the problem of low coverage of the object of interest in high-resolution aerial images, we propose to implement a deep learning-based object detection model. In this paper, we propose a novel method for the detection of humans in aerial images based on the EfficientDET architecture and ensemble learning. The method has been validated on the HERIDAL image dataset. By implementing the proposed methodologies, we achieved an mAP of 95.11%. To the best of our knowledge, this is the highest accuracy result for human detection on the HERIDAL dataset.},
keywords={Object detection;Detectors;Cameras;Proposals;Drones;Training;Search problems;Deep-learning;detection of humans;EfficientDET;ensemble learning;HERIDAL dataset;image analysis;search and rescue (SAR) operations},
doi={10.1109/ACCESS.2022.3156903},
ISSN={2169-3536},
month={},}
@INPROCEEDINGS{8453398,
author={Xu, Shuoyuan and Savvaris, Al and He, Shaoming and Shin, Hyo-sang and Tsourdos, Antonios},
booktitle={2018 International Conference on Unmanned Aircraft Systems (ICUAS)}, title={Real-time Implementation of YOLO+JPDA for Small Scale UAV Multiple Object Tracking},
year={2018},
volume={},
number={},
pages={1336-1341},
abstract={This paper describes the development of a real-time multiple object detection and tracking system for a small scale UAV. The YOLO deep learning visual object detection algorithm and JPDA multiple target detection algorithm, were selected and implemented. The theory and implementation details of these algorithms are presented. The performance analysis of the system is done on both public dataset and aerial videos taken by UAV.},
keywords={Object detection;Current measurement;Target tracking;Real-time systems;Unmanned aerial vehicles;Estimation;Object tracking},
doi={10.1109/ICUAS.2018.8453398},
ISSN={2575-7296},
month={June},}


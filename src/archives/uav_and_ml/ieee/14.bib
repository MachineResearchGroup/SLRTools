@INPROCEEDINGS{9618703,
author={Zhang, Wenlu and Chen, Xinyi and Bhadani, Dhara and Rex, Patrick and Yang, Yu and Lowe, Christopher G. and Yeh, Hen-Geul},
booktitle={2021 IEEE Green Energy and Smart Systems Conference (IGESSC)}, title={Deep Learning for Shark Detection Tasks},
year={2021},
volume={},
number={},
pages={1-6},
abstract={Automatic detection of free-ranging sharks from beach areas is of great importance in maintaining a safe humans-hark interaction. The task is especially challenging due to most existing shark detection methods and the sparsity features of field images collected from Unmanned Aerial Vehicle (UAV). Recently, deep learning has been tremendously successful in various real-world applications such as automatic driving system, object detection, face recognition, medical diagnosis, etc. In this paper, we propose an automated pipeline of shark detection tasks. In specific, we implement several state-of-the-art object detection models into our shark field data set. These algorithms are Faster R-CNN, Mask R-CNN, Feature Pyramid Network (FPN) and RetinaNet. We report the quantitative comparison results on the above mentioned object detection models and we also provide some detection example images. The experiments show that the models are capable of making a fast and efficient detection among shark and non-shark objects.},
keywords={Deep learning;Face recognition;Pipelines;Object detection;Feature extraction;Unmanned aerial vehicles;Data models;Object Detection;Shark Recognition;Deep Learning;Convolutional Neural Network},
doi={10.1109/IGESSC53124.2021.9618703},
ISSN={2640-0138},
month={Nov},}
@INPROCEEDINGS{9230250,
author={Li, Boxuan and Wu, Jiezhang and Tan, Xiaojun and Wang, Benfei},
booktitle={2020 5th International Conference on Automation, Control and Robotics Engineering (CACRE)}, title={ArUco Marker Detection under Occlusion Using Convolutional Neural Network},
year={2020},
volume={},
number={},
pages={706-711},
abstract={Camera pose estimation is a significant warranty during Unmanned Aerial Vehicle (UAV) autonomous landing process. Fiducial marker system is a popular method to offer relatively precise pose information. However, square-based markers are unreliable under occlusion condition, especially when their corners are covered by unexpected disturbances. This study proposes a novel method to detect fiducial markers using neural network. The method is developed based on Convolutional Neural Network (CNN) and achieves outstanding results under various occlusion conditions, including different cover shapes and ratios. YOLOv3, along with its improved version YOLOv3-spp and its lightweight version YOLOv3-tiny, are applied as the marker detector. Compared to the traditional ArUco fiducial marker system, CNN architectures are more robust and stable in extreme environment. Performance of three different CNN models is quantified as marker detection rate. This work validates the feasibility of square-based fiducial marker localization employing CNN architecture, and reveals the potential of deep learning method in the field of fiducial marker detection and recognition.},
keywords={Warranties;Shape;Pose estimation;Fiducial markers;Unmanned aerial vehicles;Convolutional neural networks;Robots;Fiducial Marker;Convolutional Neural Network;Objection Detection;Occlusion},
doi={10.1109/CACRE50138.2020.9230250},
ISSN={},
month={Sep.},}
@ARTICLE{9364688,
author={Westfechtel, Thomas and Ohno, Kazunori and Akegawa, Tetsu and Yamada, Kento and Neto, Ranulfo Plutarco Bezerra and Kojima, Shotaro and Suzuki, Taro and Komatsu, Tomohiro and Shibata, Yukinori and Asano, Kimitaka and Nagatani, Keji and Miyamoto, Naoto and Suzuki, Takahiro and Harada, Tatsuya and Tadokoro, Satoshi},
journal={IEEE Robotics and Automation Letters}, title={Semantic Mapping of Construction Site From Multiple Daily Airborne LiDAR Data},
year={2021},
volume={6},
number={2},
pages={3073-3080},
abstract={Semantic maps are an important tool to provide robots with high-level knowledge about the environment, enabling them to better react to and interact with their surroundings. However, as a single measurement of the environment is solely a snapshot of a specific time, it does not necessarily reflect the underlying semantics. In this work, we propose a method to create a semantic map of a construction site by fusing multiple daily data. The construction site is measured by an unmanned aerial vehicle (UAV) equipped with a LiDAR. We extract clusters above ground level from the measurements and classify them using either a random forest or a deep learning based classifier. Furthermore, we combine the classification results of several measurements to generalize the classification of the single measurements and create a general semantic map of the working site. We measured two construction fields for our evaluation. The classification models can achieve an average intersection over union (IoU) score of 69.2% during classification on the Sanbongi field, which is used for training, validation and testing and an IoU score of 49.16% on a hold-out testing field. In a final step, we show how the semantic map can be employed to suggest a parking spot for a dump truck, and in addition, show that the semantic map can be utilized to improve path planning inside the construction site.},
keywords={Semantics;Robots;Three-dimensional displays;Image segmentation;Laser radar;Random forests;Data mining;Field robots;robotics and automation in construction;semantic scene understanding},
doi={10.1109/LRA.2021.3062606},
ISSN={2377-3766},
month={April},}
@INPROCEEDINGS{8324593,
author={Yang, Liang and Li, Bing and Li, Wei and Liu, Zhaoming and Yang, Guoyong and Xiao, Jizhong},
booktitle={2017 IEEE International Conference on Robotics and Biomimetics (ROBIO)}, title={A robotic system towards concrete structure spalling and crack database},
year={2017},
volume={},
number={},
pages={1276-1281},
abstract={Concrete spalling and crack inspection is a labor intensive and routine task. However, it plays an important role in structure health monitoring (SHM) of civil infrastructures. Autonomous inspection with robots has been regarded as one of the best ways to reduce both error and cost. This paper presents an automated approach using Unmanned Aerial Vehicle(UAV) and towards a Concrete Structure Spalling and Crack database (CSSC), which is by far the first released database for deep learning inspection. We aim locate the spalling and crack regions to assist 3D registration and visualization. For deep inspection, we provide a complete procedure of data searching, labeling, training, and post processing. We further present a visual Simultaneously Localization and Mapping(SLAM) approach for localization and reconstruction. Comparative experiments and field tests are illustrated, results show that we can achieve an accuracy over 70% for field tests, and more than 93% accuracy with CSSC database.},
keywords={Inspection;Databases;Concrete;Training;Three-dimensional displays;Labeling;Robots},
doi={10.1109/ROBIO.2017.8324593},
ISSN={},
month={Dec},}
@ARTICLE{8787847,
author={Wu, Chunxue and Ju, Bobo and Wu, Yan and Lin, Xiao and Xiong, Naixue and Xu, Guangquan and Li, Hongyan and Liang, Xuefeng},
journal={IEEE Access}, title={UAV Autonomous Target Search Based on Deep Reinforcement Learning in Complex Disaster Scene},
year={2019},
volume={7},
number={},
pages={117227-117245},
abstract={In recent years, artificial intelligence has played an increasingly important role in the field of automated control of drones. After AlphaGo used Intensive Learning to defeat the World Go Championship, intensive learning gained widespread attention. However, most of the existing reinforcement learning is applied in games with only two or three moving directions. This paper proves that deep reinforcement learning can be successfully applied to an ancient puzzle game Nokia Snake after further processing. A game with four directions of movement. Through deep intensive learning and training, the Snake (or self-learning Snake) learns to find the target path autonomously, and the average score on the Snake Game exceeds the average score on human level. This kind of Snake algorithm that can find the target path autonomously has broad prospects in the industrial field, such as: UAV oil and gas field inspection, Use drones to search for and rescue injured people after a complex disaster. As we all know, post-disaster relief requires careful staffing and material dispatch. There are many factors that need to be considered in the artificial planning of disaster relief. Therefore, we want to design a drone that can search and rescue personnel and dispatch materials. Current drones are quite mature in terms of automation control, but current drones require manual control. Therefore, the Snake algorithm proposed here to be able to find the target path autonomously is an attempt and key technology in the design of autonomous search and rescue personnel and material dispatching drones.},
keywords={Reinforcement learning;Drones;Games;Training;Task analysis;Deep learning;Genetic algorithms;Deep reinforcement learning;Markov decision;Monte Carlo;Q-learning},
doi={10.1109/ACCESS.2019.2933002},
ISSN={2169-3536},
month={},}
@INPROCEEDINGS{8407558,
author={Cheng, Haiyan and Chen, Rui and Wang, Jinna and Liu, Xinyue and Zhang, Muliu and Zhai, Yongjie},
booktitle={2018 Chinese Control And Decision Conference (CCDC)}, title={Study on insulator recognition method based on simulated samples expansion},
year={2018},
volume={},
number={},
pages={2569-2573},
abstract={In the application of the deep learning to the unmanned aerial vehicle (UAV) autonomous inspection, a problem about the insufficiency of both quantity and quality for insulator images emerges. In the light of this situation, a sample expansion method based on a combination of statute and 3D modelling technology is proposed. Its feasibility is verified in a deep convolutional neural network by using five kinds of insulator simulated samples. The classification accuracy acquired by the proposed method is higher verified by the comparison of the experimental results, which proves its superiority to the traditional method containing no simulated samples. It is concluded that the simulated intensive samples of pure background have a significant effect on the accuracy of network classification. And when the ratio of real samples to simulated intensive samples goes to an appropriate value, the classification has the best accuracy.},
keywords={Insulators;Training;Databases;Machine learning;Inspection;Power transmission lines;Ceramics;3D modelling;Simulated intensive samples;Deep learning;Insulators},
doi={10.1109/CCDC.2018.8407558},
ISSN={1948-9447},
month={June},}
@INPROCEEDINGS{9323266,
author={Kumar, Ajay and Taparia, Mahesh and Rajalakshmi, P. and Guo, Wei and B, Balaji Naik and Marathi, Balram and Desai, U.B.},
booktitle={IGARSS 2020 - 2020 IEEE International Geoscience and Remote Sensing Symposium}, title={UAV Based Remote Sensing for Tassel Detection and Growth Stage Estimation of Maize Crop Using Multispectral Images},
year={2020},
volume={},
number={},
pages={1588-1591},
abstract={The monitoring of growth stages of a crop is vital for farmers to optimize the use of agronomic inputs and crop-management. Manual observation of the growth stages of a crop in large fields is a time consuming and labor-intensive task. To reduce human efforts in this tedious work, Unmanned Aerial Vehicle (UAV)-based remote sensing with the emergence of different technologies like deep learning is helping in monitoring the health of a crop. However, Convolutional Neural Network (CNN) based models need a lot of labeled data and computations to get trained to automate the process. In this paper, a pixel-based segmentation method has been proposed for tassel detection, and estimation of growth stages like tasseling, and day to 50% tasseling of maize crop. The performance analysis shows that the proposed method reduces time in developing the dataset for the training of CNN models. It also gives an advantage over training-time and computational complexity when compared to CNN models like YOLO and Faster-RCNN.},
keywords={Agriculture;Image segmentation;Soil;Monitoring;Indexes;Computational modeling;Cameras;Multi-spectral images;UAV based remote sensing;high throughput plant phenotyping;growth stages;crop monitoring},
doi={10.1109/IGARSS39084.2020.9323266},
ISSN={2153-7003},
month={Sep.},}
@ARTICLE{9543551,
author={Akter, Rubina and Doan, Van-Sang and Huynh-The, Thien and Kim, Dong-Seong},
journal={IEEE Transactions on Vehicular Technology}, title={RFDOA-Net: An Efficient ConvNet for RF-Based DOA Estimation in UAV Surveillance Systems},
year={2021},
volume={70},
number={11},
pages={12209-12214},
abstract={This paper presents a convolution neural network (CNN)-based direction of arrival (DOA) estimation method for radio frequency (RF) signals acquired by a nonuniform linear antenna array (NULA) in unmanned aerial vehicle (UAV) localization systems. The proposed deep CNN, namely RFDOA-Net, is designed with three primary processing modules, such as collective feature extraction, multi-scaling feature processing, and complexity-accuracy trade-off, to learn the multi-scale intrinsic characteristics for multi-class angle classification. In several specific modules, the regular convolutional and grouped convolutional layers are leveraged with different filter sizes to enrich diversified features and reduce network complexity besides adopting residual connection to prevent vanishing gradient. For performance evaluation, we generate a synthetic signal dataset for DOA estimation under the multipath propagation channel with the presence of additive noise, propagation attenuation and delay. In simulations, the effectiveness of RFDOA-Net is investigated comprehensively with various processing modules and antenna configurations. Compared with several state-of-the-art deep learning-based models, RFDOA-Net shows the superiority in terms of accuracy with over 94% accuracy at 5 dB signal-to-noise ratio (SNR) with cost-efficiency.},
keywords={Direction-of-arrival estimation;Feature extraction;Array signal processing;Linear antenna arrays;Convolutional neural networks;Antenna arrays;Convolution neural network;direction of arrival estimation;nonuniform linear antenna array},
doi={10.1109/TVT.2021.3114058},
ISSN={1939-9359},
month={Nov},}
@ARTICLE{9560148,
author={Xu, Yaxin and Liu, Ningzhong and Yin, Tianxiang and Sun, Han},
journal={IEEE Geoscience and Remote Sensing Letters}, title={A Multiscale Feature Fusion Method for Automatic Detection of Eggs From Two Pomacea Spp. In UAV Aerial Images},
year={2022},
volume={19},
number={},
pages={1-5},
abstract={The widespread Pomacea canaliculata and Pomacea maculata in North America and Asia have caused significant adverse effects on the local ecological environment and residents’ health. Timely knowledge of the distribution of eggs from the two Pomacea spp. in a certain region can effectively reduce the cost of treatment and improve prevention effectiveness. Most of the existing methods are only able to identify eggs from the two Pomacea spp. or detect them in specific but not natural environments while they cannot achieve good results in the face of a complex real-world scene. This letter proposes a model for detecting eggs from the two Pomacea spp. based on dynamic convolution and multiscale feature fusion. The model can identify and locate the eggs of the two Pomacea spp. effectively. At the same time, we combined the proposed model with scale invariant feature transform (SIFT) algorithm to design a system for counting eggs of the two Pomacea spp., which can automatically identify the eggs in the actual natural environment and alleviate duplicate counting caused by image acquisition. Besides, we also built a dataset of 20 000 images of Pomacea canaliculata eggs and Pomacea maculata eggs from unmanned aerial vehicle (UAV) aerial photography. Experimental results showed that the proposed deep learning model has a better performance than others, and the proposed computer vision system can be successfully applied to support Pomacea spp. disease management.},
keywords={Convolution;Kernel;Vehicle dynamics;Diseases;Biological system modeling;Computational modeling;Deep learning;Deep learning;dynamic convolution;multiscale;pest;Pomacea},
doi={10.1109/LGRS.2021.3108045},
ISSN={1558-0571},
month={},}
@ARTICLE{9130679,
author={Ayyad, Abdulla and Chehadeh, Mohamad and Awad, Mohammad I. and Zweiri, Yahya},
journal={IEEE Access}, title={Real-Time System Identification Using Deep Learning for Linear Processes With Application to Unmanned Aerial Vehicles},
year={2020},
volume={8},
number={},
pages={122539-122553},
abstract={System identification is a key discipline within the field of automation that deals with inferring mathematical models of dynamic systems based on input-output measurements. Conventional identification methods require extensive data generation and are thus not suitable for real-time applications. In this paper, a novel real-time approach for the parametric identification of linear systems using Deep Learning (DL) and the Modified Relay Feedback Test (MRFT) is proposed. The proposed approach requires only a single steady-state cycle of MRFT, and guarantees stability and performance in the identification and control phases. The MRFT output is passed to a trained DL model that identifies the underlying process parameters in milliseconds. A novel modification to the Softmax function is derived to better conform the DL model for the process identification task. Quadrotor Unmanned Aerial Vehicle (UAV) attitude and altitude dynamics were used in simulation and experimentation to verify the presented approach. Results show the effectiveness and real-time capabilities of the proposed approach, which outperforms the conventional Prediction Error Method in terms of accuracy, robustness to biases, computational efficiency and data requirements.},
keywords={Real-time systems;Tuning;Unmanned aerial vehicles;Dynamical systems;Oscillators;Stability analysis;Computational modeling;System identification;unmanned aerial vehicles;learning systems;sliding mode control;process control},
doi={10.1109/ACCESS.2020.3006277},
ISSN={2169-3536},
month={},}
@ARTICLE{8873637,
author={Adege, Abebe Belay and Lin, Hsin-Piao and Wang, Li-Chun},
journal={IEEE Internet of Things Journal}, title={Mobility Predictions for IoT Devices Using Gated Recurrent Unit Network},
year={2020},
volume={7},
number={1},
pages={505-517},
abstract={Wireless and mobile technologies, as well as their users, are growing rapidly as the Internet of Things (IoT) products, such as sensor-network technologies, mobile devices, and supporting applications, become widely dispersed. Owing to the dynamic changes in the wireless networks and the exponential growth of the IoT products, which make it difficult to locate large quantities of users and devices, providing accurate tracking and trajectory predictions in open and highly condensed wireless networks is extremely difficult. An adaptive and scalable system is required to offer accurate location-based services (LBSs) for the success of IoT. To enhance the attainment of IoT, we propose a hybrid of principal component analysis (PCA) and gated recurrent unit (GRU) algorithms for mobility predictions in a wireless urban area. During the system development processes, we first collect an LTE signal from three unmanned aerial vehicle base stations (UAV-BSs), the Wi-Fi signal strength from each reachable Wi-Fi access points (APs), and channel information from the Wi-Fi signal media. We then apply PCA to reduce the number of Wi-Fi features and to decrease signal noise. Next, we train the GRU algorithm to develop models that can predict the mobility of IoT device users. Finally, we evaluate the tracking and trajectory models. To evaluate the proposed techniques, we compare the common parameters of the GRU with those of other deep learning types. The proposed technique provides plausible and state-of-the-art results for mobility predictions of IoT devices in a wireless environment.},
keywords={Internet of Things;Wireless fidelity;Wireless sensor networks;Wireless networks;Trajectory;Principal component analysis;Deep learning;gated recurrent units (GRUs);mobility predictions;principal component analysis (PCA)},
doi={10.1109/JIOT.2019.2948075},
ISSN={2327-4662},
month={Jan},}
@INPROCEEDINGS{9124868,
author={Zhang, Xupei and Ma, Zhong and He, Zhanzhuang and Wang, Zhuping},
booktitle={2019 IEEE International Conference on Unmanned Systems and Artificial Intelligence (ICUSAI)}, title={Vision-based UAV Obstacle Avoidance Algorithm on the Embedded Platform},
year={2019},
volume={},
number={},
pages={85-90},
abstract={Due to the limited budget for power and memory consumption on the mobile/IoT platforms make deep learning algorithm hard to get the ideal efficiency and accuracy on the obstacle detection and avoidance for unmanned aerial vehicle (UAV) with monocular version. To resolve this, we design a learning based virtual odometry method and combine it with a quantization scheme which can be added into the training framework. During the obstacle detection networks training process it will reduce the accuracy loss on the original models caused by the quantization. By evaluating the feature detection and matching we used in the avoidance detection on MS-COCO dataset, our method can archive 8-bit inference accuracy loss less than 3%, almost close to the float pipeline.},
keywords={Quantization;obstacle avoidance;neural network;UAV},
doi={10.1109/ICUSAI47366.2019.9124868},
ISSN={},
month={Nov},}
@ARTICLE{8978670,
author={Wang, Yu and Yang, Jie and Liu, Miao and Gui, Guan},
journal={IEEE Transactions on Vehicular Technology}, title={LightAMC: Lightweight Automatic Modulation Classification via Deep Learning and Compressive Sensing},
year={2020},
volume={69},
number={3},
pages={3491-3495},
abstract={Automatic modulation classification (AMC) is an promising technology for non-cooperative communication systems in both military and civilian scenarios. Recently, deep learning (DL) based AMC methods have been proposed with outstanding performances. However, both high computing cost and large model sizes are the biggest hinders for deployment of the conventional DL based methods, particularly in the application of internet-of-things (IoT) networks and unmanned aerial vehicle (UAV)-aided systems. In this correspondence, a novel DL based lightweight AMC (LightAMC) method is proposed with smaller model sizes and faster computational speed. We first introduce a scaling factor for each neuron in convolutional neural network (CNN) and enforce scaling factors sparsity via compressive sensing. It can give an assist to screen out redundant neurons and then these neurons are pruned. Experimental results show that the proposed LightAMC method can effectively reduce model sizes and accelerate computation with the slight performance loss.},
keywords={Neurons;Signal to noise ratio;Modulation;Feature extraction;Training;Support vector machines;Computational modeling;Lightweight automatic modulation classification (LightAMC);convolutional neural network (CNN);neuron pruning;compressive sensing},
doi={10.1109/TVT.2020.2971001},
ISSN={1939-9359},
month={March},}
@INPROCEEDINGS{8202236,
author={Li, Jiaxin and Zhan, Huangying and Chen, Ben M. and Reid, Ian and Lee, Gim Hee},
booktitle={2017 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)}, title={Deep learning for 2D scan matching and loop closure},
year={2017},
volume={},
number={},
pages={763-768},
abstract={Although 2D LiDAR based Simultaneous Localization and Mapping (SLAM) is a relatively mature topic nowadays, the loop closure problem remains challenging due to the lack of distinctive features in 2D LiDAR range scans. Existing research can be roughly divided into correlation based approaches e.g. scan-to-submap matching and feature based methods e.g. bag-of-words (BoW). In this paper, we solve loop closure detection and relative pose transformation using 2D LiDAR within an end-to-end Deep Learning framework. The algorithm is verified with simulation data and on an Unmanned Aerial Vehicle (UAV) flying in indoor environment. The loop detection ConvNet alone achieves an accuracy of 98.2% in loop closure detection. With a verification step using the scan matching ConvNet, the false positive rate drops to around 0.001%. The proposed approach processes 6000 pairs of raw LiDAR scans per second on a Nvidia GTX1080 GPU.},
keywords={Feature extraction;Laser radar;Training;Two dimensional displays;Machine learning;Simultaneous localization and mapping},
doi={10.1109/IROS.2017.8202236},
ISSN={2153-0866},
month={Sep.},}
@INPROCEEDINGS{9607701,
author={Aslahishahri, Masoomeh and Stanley, Kevin G. and Duddu, Hema and Shirtliffe, Steve and Vail, Sally and Bett, Kirstin and Pozniak, Curtis and Stavness, Ian},
booktitle={2021 IEEE/CVF International Conference on Computer Vision Workshops (ICCVW)}, title={From RGB to NIR: Predicting of near infrared reflectance from visible spectrum aerial images of crops},
year={2021},
volume={},
number={},
pages={1312-1322},
abstract={Near infrared spectroscopy (NIR) provides rich information in agricultural operations and experiments to determine crop parameters which are not visible to the human eye. Collecting the NIR spectral band requires a multispectral camera which is typically more expensive and has lower resolution than a comparable RGB camera. We investigate image-to-image translation as a means to generate an NIR spectral band from an RGB image alone in aerial crop imagery. Aerial images were captured via a multispectral sensor mounted on an unmanned aerial vehicle (UAV) flown over canola, lentil, dry bean, and wheat breeding trials. A software workflow was created to preprocess raw aerial images creating a dataset suitable for training and evaluating deep learning based band inferencing algorithms. Two different experiments including in-domain and out-of-domain experiments over different crop types in our dataset were conducted to evaluate efficacy in an agricultural context.},
keywords={Reflectivity;Training;Spectroscopy;Software algorithms;Crops;Cameras;Radiometry},
doi={10.1109/ICCVW54120.2021.00152},
ISSN={2473-9944},
month={Oct},}
@INPROCEEDINGS{9019163,
author={Ruan, Wenyang and Wang, Honglun and Kou, Zhan and Su, Zikang},
booktitle={2018 IEEE CSAA Guidance, Navigation and Control Conference (CGNCC)}, title={Drogue Detection and Location for UAV Autonomous Aerial Refueling Based on Deep Learning and Vision},
year={2018},
volume={},
number={},
pages={1-6},
abstract={The accurate detection and location of the drogue under complex environment is an important issue in UAV (Unmanned Aerial Vehicle) autonomous aerial refueling. In this paper, a new drogue detection and location method based on deep learning and vision is proposed for this intractable problem. The method consists of two parts: drogue detection and drogue location. The well-trained Yolo (You only look once) model is established to detect the drogue in the image to obtain the parameters of the predicted bounding box. A small part of the entire image is selected for processing based on these parameters, then the position of the eight beacons on the drogue ring in the image can be obtained. Least-squares ellipse fitting is performed on these eight points in the image coordinate system to obtain the long semi-axis of the ellipse. Finally, monocular vision is used to measure the position of the drogue in camera coordinate system. The simulation results show that this method can not only correctly identify the drogue but also accurately locate it with a distance of 2.5m to 45m under complex environment.},
keywords={Cameras;Mathematical model;Unmanned aerial vehicles;Machine learning;Image processing;Simulation;Navigation},
doi={10.1109/GNCC42960.2018.9019163},
ISSN={},
month={Aug},}
@INPROCEEDINGS{9299682,
author={Wang, Guangya and Hong, Hanyu and Zhang, Yaozong and Wu, Jinmeng and Wang, Yunfei and Li, Shiyang},
booktitle={2020 International Conference on Wireless Communications and Signal Processing (WCSP)}, title={Realization of Detection Algorithms for Key Parts of Unmanned Aerial Vehicle Based on Deep Learning},
year={2020},
volume={},
number={},
pages={137-142},
abstract={Fixed-point attack on the key parts of small aerial vehicles is one of the important means of UAV (Unmanned Aerial Vehicle) countermeasure. Fixed-wing aircraft flying in the air has two characteristics: fast speed and fast attitude change of aircraft. However, the traditional detection method of key parts of fixed-wing aircraft in infrared images is not only slow in speed but also low in accuracy. This paper presents an improved target detection and motion tracking algorithm based on deep learning method. The algorithm uses a deeper neural network to enhance the feature extraction capabilities of CNN and obtain richer feature information. The detection algorithm obtains the position and motion direction of the key points of the target. Experimental results show that the detection algorithm proposed in this paper is up to 30 frame/s, with an average accuracy of 91.5%/. The method achieved good results in the experiment.},
keywords={Feature extraction;Aircraft;Unmanned aerial vehicles;Convolution;Target recognition;Prediction algorithms;Object detection;deep learning;fixed-wing aircraft;target detection},
doi={10.1109/WCSP49889.2020.9299682},
ISSN={2472-7628},
month={Oct},}
@INPROCEEDINGS{9560756,
author={Fu, Changhong and Cao, Ziang and Li, Yiming and Ye, Junjie and Feng, Chen},
booktitle={2021 IEEE International Conference on Robotics and Automation (ICRA)}, title={Siamese Anchor Proposal Network for High-Speed Aerial Tracking},
year={2021},
volume={},
number={},
pages={510-516},
abstract={In the domain of visual tracking, most deep learning-based trackers highlight the accuracy but casting aside efficiency. Therefore, their real-world deployment on mobile platforms like the unmanned aerial vehicle (UAV) is impeded. In this work, a novel two-stage Siamese network-based method is proposed for aerial tracking, i.e., stage-1 for high-quality anchor proposal generation, stage-2 for refining the anchor proposal. Different from anchor-based methods with numerous pre-defined fixed-sized anchors, our no-prior method can 1) increase the robustness and generalization to different objects with various sizes, especially to small, occluded, and fast-moving objects, under complex scenarios in light of the adaptive anchor generation, 2) make calculation feasible due to the substantial decrease of anchor numbers. In addition, compared to anchor-free methods, our framework has better performance owing to refinement at stage-2. Comprehensive experiments on three benchmarks have proven the superior performance of our approach, with a speed of ∼200 frames/s.},
keywords={Visualization;Casting;Automation;Conferences;Semantics;Refining;Benchmark testing},
doi={10.1109/ICRA48506.2021.9560756},
ISSN={2577-087X},
month={May},}
@ARTICLE{9277923,
author={Teng, Chieh-Fang and Chou, Ching-Yao and Chen, Chun-Hsiang and Wu, An-Yeu},
journal={IEEE Transactions on Vehicular Technology}, title={Accumulated Polar Feature-Based Deep Learning for Efficient and Lightweight Automatic Modulation Classification With Channel Compensation Mechanism},
year={2020},
volume={69},
number={12},
pages={15472-15485},
abstract={In next-generation communications, massive machine-type communications (mMTC) induce severe burden on base stations. To address such an issue, automatic modulation classification (AMC) can help to reduce signaling overhead by blindly recognizing the modulation types without handshaking. Thus, it plays an important role in future intelligent modems. The emerging deep learning (DL) technique stores intelligence in the network, resulting in superior performance over traditional approaches. However, DL-based approaches suffer from heavy training overhead, memory overhead, and computational complexity, which severely hinder practical applications for resource-limited scenarios, such as Internet-of-Things (IoT) networks and unmanned aerial vehicle (UAV)-aided systems. Furthermore, the overhead of online retraining under time-varying fading channels has not been studied in the prior arts. In this work, an accumulated polar feature-based DL with a channel compensation mechanism is proposed to cope with the aforementioned issues. Firstly, the simulation results show that learning features from the polar domain with historical data information can approach near-optimal performance while reducing training overhead by 99.8 times. Secondly, the proposed neural network-based channel estimator (NN-CE) can learn the channel response and compensate for the distorted channel with 13% improvement. Moreover, in applying this lightweight NN-CE in a time-varying fading channel, two efficient mechanisms of online retraining are proposed, which can reduce transmission overhead and retraining overhead by 90% and 76%, respectively. Finally, the performance of the proposed approach is evaluated and compared with prior arts on a public dataset to demonstrate its great efficiency and lightness. The lightweight and efficient learning features of the proposed mechanism will be very attractive for future resource-constrained/aware IoT and Vehicle-to-Everything (V2X) applications.},
keywords={Modulation;Channel estimation;Feature extraction;Training;Deep learning;Fading channels;Computational complexity;Automatic modulation classification;polar coordinate;deep learning;convolutional neural network;time-varying fading channel;online retraining},
doi={10.1109/TVT.2020.3041843},
ISSN={1939-9359},
month={Dec},}
@INPROCEEDINGS{8593751,
author={Andrew, William and Greatwood, Colin and Burghardt, Tilo},
booktitle={2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)}, title={Deep Learning for Exploration and Recovery of Uncharted and Dynamic Targets from UAV-like Vision},
year={2018},
volume={},
number={},
pages={1124-1131},
abstract={This paper discusses deep learning for solving static and dynamic search and recovery tasks - such as the retrieval of all instances of actively moving targets - based on partial-view Unmanned Aerial Vehicle (UAV)-like sensing. In particular, we demonstrate that abstracted tactic and strategic explorational agency can be implemented effectively via a single deep network that optimises in unity: the mapping of sensory inputs and positional history towards navigational actions. We propose a dual-stream classification paradigm that integrates one Convolutional Neural Network (CNN) for sensory processing with a second one for interpreting an evolving longterm map memory. In order to learn effective search behaviours given agent location and agent-centric sensory inputs, we train this design against 400k+ optimal navigational decision samples from each set of static and dynamic evolutions for different multi-target behaviour classes. We quantify recovery performance across an extensive range of scenarios; including probabilistic placement and dynamics, as well as fully random target walks and herd-inspired behaviours. Detailed results comparisons show that our design can outperform naive, independent stream and off-the-shelf DRQN solutions. We conclude that the proposed dual-stream architecture can provide a unified, rationally motivated and effective architecture for solving online search tasks in dynamic, multi-target environments. With this paper we publish3 key source code and associated models.},
keywords={Navigation;Robot sensing systems;Task analysis;History;Visualization;Vehicle dynamics;Reinforcement learning},
doi={10.1109/IROS.2018.8593751},
ISSN={2153-0866},
month={Oct},}
@INPROCEEDINGS{9183674,
author={Fragkos, Georgios and Tsiropoulou, Eirini Eleni and Papavassiliou, Symeon},
booktitle={2020 16th International Conference on Distributed Computing in Sensor Systems (DCOSS)}, title={Artificial Intelligence Enabled Distributed Edge Computing for Internet of Things Applications},
year={2020},
volume={},
number={},
pages={450-457},
abstract={Artificial Intelligence (AI) based techniques are typically used to model decision making in terms of strategies and mechanisms that can result in optimal payoffs for a number of interacting entities, often presenting antagonistic behaviors. In this paper, we propose an AI-enabled multi-access edge computing (MEC) framework, supported by computing-equipped Unmanned Aerial Vehicles (UAVs) to facilitate IoT applications. Initially, the problem of determining the IoT nodes optimal data offloading strategies to the UAV-mounted MEC servers, while accounting for the IoT nodes' communication and computation overhead, is formulated based on a game-theoretic model. The existence of at least one Pure Nash Equilibrium (PNE) point is shown by proving that the game is submodular. Furthermore, different operation points (i.e. offloading strategies) are obtained and studied, based either on the outcome of Best Response Dynamics (BRD) algorithm, or via alternative reinforcement learning approaches (i.e. gradient ascent, log-linear, and Q-learning algorithms), which explore and learn the environment towards determining the users' stable data offloading strategies. The corresponding outcomes and inherent features of these approaches are critically compared against each other, via modeling and simulation.},
keywords={Servers;Edge computing;Task analysis;Computational modeling;Distributed databases;Artificial intelligence;Games;Edge Computing;Game Theory;Reinforcement Learning;Internet of Things},
doi={10.1109/DCOSS49796.2020.00077},
ISSN={2325-2944},
month={May},}
@INPROCEEDINGS{7364583,
author={Pedroza, Natalie Ramos and MacKunis, William and Golubev, Vladimir},
booktitle={2015 15th International Conference on Control, Automation and Systems (ICCAS)}, title={A new method of synthetic jet actuator-based LCO suppression using an output feedback control strategy},
year={2015},
volume={},
number={},
pages={1463-1468},
abstract={A sliding mode control method is presented in this paper, which is proven to achieve asymptotic limit cycle oscillation (LCO) suppression in unmanned aerial vehicle wings equipped with synthetic jet actuators (SJA). With a focus on applications involving small unmanned aerial vehicles (SUAV) with limited onboard computing resources, the proposed control law is designed to be inexpensively implemented, requiring no adaptive laws, function approximators, or pitching and plunging velocity measurements. Challenges in the control design include input-multiplicative uncertainty due to the parametric uncertainty and nonlinearity that are inherent in the SJA dynamic model. To achieve the result, a sliding mode control strategy is amalgamated with a velocity estimator, which is designed using a bank of dynamic filters. This is the first output feedback control result that achieves asymptotic LCO regulation in the presence of an uncertain, nonlinear SJA dynamic model, without the use of adaptive laws or neural networks. A detailed model of the SUAV dynamics is utilized along with a rigorous Lyapunov-based stability analysis to prove asymptotic regulation of the pitching and plunging displacements, and numerical simulation results are provided to demonstrate the performance of the proposed control design.},
keywords={Robustness;Phase frequency detector;Nonlinear control;output feedback;limit cycle oscillations;synthetic jet actuators},
doi={10.1109/ICCAS.2015.7364583},
ISSN={2093-7121},
month={Oct},}
@INPROCEEDINGS{7969645,
author={Ramirez-Atencia, Cristian and Rodríguez-Fernández, Víctor and Gonzalez-Pardo, Antonio and Camacho, David},
booktitle={2017 IEEE Congress on Evolutionary Computation (CEC)}, title={New Artificial Intelligence approaches for future UAV Ground Control Stations},
year={2017},
volume={},
number={},
pages={2775-2782},
abstract={The increasing interest in the use of Unmanned Aerial Vehicles (UAV) in the last years has opened up a new complex area of research applications. Many works have been focused on the applicability of new Artificial Intelligence techniques to facilitate the successfully execution of UAV operations from the Ground Control Stations (GCSs). Some of the most demanded applications in this field are the reduction of the workload of operators and the automation of training processes. This paper presents new algorithms focused on this field: a Multi-Objective Genetic Algorithm for solving Mission Planning and Replanning problems and a Procedure Following Evaluation methodology based on Petri Nets. This paper is based on a framework that simulates a GCS with support for multiple UAVs. The functionality of this framework has been extended in two different directions: on the one hand, to deal with Mission Designing, Automated Mission Planning and Replanning, and Alert Generation; and, on the other hand, to perform different analysis tasks of the UAV operators. Using this framework, a test mission has been executed and debriefed, focusing on the main AI-based issues described in this work.},
keywords={Training;Planning;Unmanned aerial vehicles;Genetic algorithms;Materials requirements planning;Approximation algorithms;Sensors},
doi={10.1109/CEC.2017.7969645},
ISSN={},
month={June},}
@ARTICLE{9354921,
author={Aloqaily, Moayad and Bouachir, Ouns and Boukerche, Azzedine and Ridhawi, Ismaeel Al},
journal={IEEE Network}, title={Design Guidelines for Blockchain-Assisted 5G-UAV Networks},
year={2021},
volume={35},
number={1},
pages={64-71},
abstract={Fifth generation (5G) wireless networks are designed to meet various end-user quality of service (QoS) requirements through high data rates (typically of gigabits per second) and low latencies. Coupled with fog and mobile edge computing, 5G can achieve high data rates, enabling complex autonomous smart city services such as the large deployment of self-driving vehicles and large-scale artificial-intelligence-enabled industrial manufacturing. However, to meet the exponentially growing number of connected IoT devices and irregular data and service requests in both low- and high-density locations, the process of enacting traditional cells supported through fixed and costly base stations requires rethought to enable on-demand mobile access points in the form of unmanned aerial vehicles (UAV) for diversified smart city scenarios. This article envisions a 5G network environment that is supported by blockchain-enabled UAVs to meet dynamic user demands with network access supply. The solution enables decentralized service delivery (drones as a service) and routing to and from end users in a reliable and secure manner. Both public and private blockchains are deployed within the UAVs, supported by fog and cloud computing devices and data centers to provide a wide range of complex authenticated service and data availability. Particular attention is paid to comparing data delivery success rates and message exchange in the proposed solution against traditional UAV-supported cellular networks. Challenges and future research are also discussed with highlights on emerging technologies such as federated learning.},
keywords={Cloud computing;5G mobile communication;Smart cities;Blockchain;Quality of service;Routing;Drones},
doi={10.1109/MNET.011.2000170},
ISSN={1558-156X},
month={January},}
@INPROCEEDINGS{9484461,
author={Sarkar, Sayani and Khare, Shivanjali and Totaro, Michael W. and Kumar, Ashok},
booktitle={IEEE INFOCOM 2021 - IEEE Conference on Computer Communications Workshops (INFOCOM WKSHPS)}, title={A Novel Energy Aware Secure Internet of Drones Design: ESIoD},
year={2021},
volume={},
number={},
pages={1-6},
abstract={Unmanned aerial vehicles (UAVs), or drones, are emerging as a promising technology for a variety of monitoring and surveillance-based applications. Smart UAVs are not limited only to image capturing, but also to real-time decision making using artificial intelligence. Moreover, it is important to consider the data security of captured images. In this paper, we propose a novel Energy-aware Secure Internet of Drone (ESIoD) architecture. A crucial research problem addressed by this work is how to accomplish faster onboard processing and reduce battery usage for a UAV to prolong the flight time while retaining data security of UAV captured images. Specifically, drone-captured real-time images are encrypted using either AES or RSA algorithms and offloaded by the onboard computer to a cloud server for the processing of cognitive actions using both a standard Haar cascade classifier and an advanced faster R-CNN classifier. The focus of this study is to conserve the drone battery life by secure computational offloading to optimize drone flight time. Two sets of experiments were performed using drone-captured sample images and videos. Results show that the ESIoD architecture can conserve 80% onboard processing time and 3X drone battery charge usage as compared to conventional real-time onboard processing for the considered application.},
keywords={Cloud computing;Conferences;Computational modeling;Decision making;Computer architecture;Real-time systems;Batteries;Drones;Haar cascade;faster R-CNN;AES;RSA;cloud offloading;drone battery;drone flight time},
doi={10.1109/INFOCOMWKSHPS51825.2021.9484461},
ISSN={},
month={May},}
@INPROCEEDINGS{8947702,
author={Kusyk, Janusz and Uyar, Muharrem Umit and Ma, Kelvin and Wu, Jun Jie and Ruan, Weimin and Guha, Dilip K and Bertoli, Giorgio and Boksiner, Jeffrey},
booktitle={2018 International Conference on Computational Science and Computational Intelligence (CSCI)}, title={AI Based Flight Control for Autonomous UAV Swarms},
year={2018},
volume={},
number={},
pages={1155-1160},
abstract={Artificial intelligence (AI) based flight control algorithms can be successfully utilized to deploy a swarm of autonomous Unmanned Areal Vehicles (UAVs). In a swarm of autonomous UAVs operating as a mobile ad-hoc network (MANET), use of centralized control, pre-planned missions, synchronization of nodes and reliance on conditional procedures are not feasible We introduce near real-time AI based flight control algorithms for autonomous UAVs to position themselves over an area of interest. Each UAV uses only local neighbor information to advance the swarm toward a desired MANET topology. Simulation experiments in OPNET show that our algorithms can provide high percentage area coverage over a target, while requiring limited near neighbor communication. They are lightweight and power efficient, hence well-suited for military applications.},
keywords={Mobile ad hoc networks;Topology;Three-dimensional displays;Autonomous underwater vehicles;Military computing;Network topology;AI, MANET, autonomous, UAV, swarm, bio-inspired computation},
doi={10.1109/CSCI46756.2018.00223},
ISSN={},
month={Dec},}
@INPROCEEDINGS{8304318,
author={Wang, Shengke and Liu, Lu and Duan, Lianghua and Yu, Changyin and Cai, Guiyan and Gao, Feng and Dong, Junyu},
booktitle={2017 International Conference on Security, Pattern Analysis, and Cybernetics (SPAC)}, title={Accurate segmentation of Ulva prolifera regions with superpixel and CNNs},
year={2017},
volume={},
number={},
pages={433-438},
abstract={To get regions of Ulva prolifera, we propose a novel end-to-end way to segment the Ulva prolifera regions via aggregation of local classify prediction results. We creatively adopt SEEDS (Superpixels Extracted via Energy-Driven Sampling) to generate local multi-scale patches. We use powerful convolution neural networks to learn and classify the patches. At last, mapping the classify prediction results of patches to the whole image according to the patches classify prediction results, we can get more detailed segmentation of Ulva prolifera. As for the dataset, we collected images by UAV (unmanned aerial vehicle) in coastal waters off Qingdao, China. We show experimentally this method achieves great segmentation performance of Ulva prolifera, despite its indistinct features. In contrast, we train the model in fully convolutional networks for semantic segmentation based on our dataset, while our result achieves superior accuracy.},
keywords={Image segmentation;Convolution;Neural networks;Security;Pattern analysis;Cybernetics;Green products;superpixel;convolution neural networks;segmentation;Ulva prolifera},
doi={10.1109/SPAC.2017.8304318},
ISSN={},
month={Dec},}
@ARTICLE{9187552,
author={Sun, Ying and Zhang, Xinchang and Huang, Jianfeng and Wang, Haiying and Xin, Qinchuan},
journal={IEEE Geoscience and Remote Sensing Letters}, title={Fine-Grained Building Change Detection From Very High-Spatial-Resolution Remote Sensing Images Based on Deep Multitask Learning},
year={2022},
volume={19},
number={},
pages={1-5},
abstract={Building change detection from very high-spatial-resolution (VHR) remote sensing images has gained increasing popularity in a variety of applications, such as urban planning and damage assessment. Detecting fine-grained “from–to” changes (change transition from one land cover type to another) of buildings from the VHR images is still challenging as multitemporal representation is complicated. Recently, fully convolutional neural networks (FCNs) have been proven to be capable of feature extraction and semantic segmentation of VHR images, but its ability in change detection is untested and unknown. In this letter, we leverage the semantic segmentation of buildings as an auxiliary source of information for the fine-grained “from–to” change detection. A deep multitask learning framework for change detection (MTL-CD) is proposed for detecting building changes from the VHR images. MTL-CD adopts the encoder–decoder architecture and solves the main task of change detection and the auxiliary tasks of semantic segmentation simultaneously. Accordingly, the change detection loss function is constrained by the auxiliary semantic segmentation tasks and enables the back-propagation of the building footprints’ detection errors for the improvement of change detection. A building change detection data set named the Guangzhou data set is also developed for model evaluation, in which the bitemporal R–G–B images were collected by airplane (2009) and unmanned aerial vehicle (UAV, 2019) with different flight heights. Experiments on the Guangzhou data set demonstrate that the MTL-CD method effectively detects fine-grained “from–to” changes and outperforms the postclassification methods and the direct change detection methods.},
keywords={Task analysis;Buildings;Semantics;Feature extraction;Image segmentation;Remote sensing;Architecture;Building changes;deep multitask learning;fine-grained change detection;fully convolutional neural network (FCN);semantic segmentation},
doi={10.1109/LGRS.2020.3018858},
ISSN={1558-0571},
month={},}
@INPROCEEDINGS{6712547,
author={Garbarino, Luca and Zazzaro, Gaetano and Genito, Nicola and Fasano, Giancarmine and Accardo, Domenico},
booktitle={2013 IEEE/AIAA 32nd Digital Avionics Systems Conference (DASC)}, title={Neural Network based architecture for Fault Detection and Isolation in air data systems},
year={2013},
volume={},
number={},
pages={2D4-1-2D4-11},
abstract={This paper presents the design, development, integration and flight testing of a Fault Detection and Isolation architecture for an air data computer based on Artificial Neural Networks. A lot of Networks have been trained using Knowledge Discovery in Data Base Process in order to identify faults on air data measurements such as airspeed, sideslip angle, and angle of attack. The proposed methodology makes use of a huge number of flight data for training and testing in the Neural Network design. Flight data have been recorded during flight trials carried out using the experimental aircraft of the Italian Aerospace Research Centre. The proposed architecture tested on flight data gathered during an autonomous mission of an Unmanned Aerial Vehicle (UAV) shows good performance in identifying fault occurrences.},
keywords={Clustering algorithms;Atmospheric modeling;Training;Sensors;Aircraft;Data models;Computer architecture},
doi={10.1109/DASC.2013.6712547},
ISSN={2155-7209},
month={Oct},}
@INPROCEEDINGS{9274913,
author={Wang, Zhichao and Wang, Chang and Niu, Yifeng},
booktitle={2020 3rd International Conference on Unmanned Systems (ICUS)}, title={Mixed-initiative Manned-unmanned Teamwork Using Coactive Design and Graph Neural Network},
year={2020},
volume={},
number={},
pages={538-543},
abstract={Mixed-initiative decision making is a flexible and effective way for coherent manned-unmanned teamwork (MUT). It allows the autonomous adjustment of levels of autonomy (LOA) and the human-robot collaboration modes according to the task requirements as well as the states of environments, robots and the human operator. However, it is still difficult for humans and robots to understand each other's intentions and motivations due to the challenges of cognition representation and behavior reasoning. In this paper, we propose a novel mixed-initiative MUT approach using coactive design and graph neural networks (GNN) towards explainable human-robot collaboration. First, an interdependence analysis table is designed for a specific manned-unmanned aerial vehicle task following the coactive design principles of observability, predictability and directablity. Then, a multi-agent dynamic task assignment system is designed based on a task model with key decision-making points. Finally, we have used the Graph Network Library to design a GNN model for adjusting the LOA among the MAV and UAVs in the given task.},
keywords={Task analysis;Man-machine systems;Libraries;mixed-initiative;coactive design;dynamic task assignment;graph neural network;levels of autonomy},
doi={10.1109/ICUS50048.2020.9274913},
ISSN={},
month={Nov},}
@ARTICLE{9359491,
author={Menshchikov, Alexander and Shadrin, Dmitrii and Prutyanov, Viktor and Lopatkin, Daniil and Sosnin, Sergey and Tsykunov, Evgeny and Iakovlev, Evgeny and Somov, Andrey},
journal={IEEE Transactions on Computers}, title={Real-Time Detection of Hogweed: UAV Platform Empowered by Deep Learning},
year={2021},
volume={70},
number={8},
pages={1175-1188},
abstract={The Hogweed of Sosnowskyi (lat. Heracleum sosnówskyi) is poisonous for humans, dangerous for farming crops, and local ecosystems. This plant is fast-growing and has already spread all over Eurasia: from Germany to the Siberian part of Russia, and its distribution expands year-by-year. In-situ detection of this harmful plant is a tremendous challenge for many countries. Meanwhile, there are no automatic systems for detection and localization of hogweed. In this article, we report on an approach for fast and accurate detection of hogweed. The approach includes the Unmanned Aerial Vehicle (UAV) with an embedded system on board running various Fully Convolutional Neural Networks (FCNN). We propose the optimal architecture of FCNN for the embedded system relying on the trade-off between the detection quality and frame rate. We propose a model that achieves ROC AUC 0.96 in the hogweed segmentation task, which can process 4K frames at 0.46 FPS on NVIDIA Jetson Nano. The developed system can recognize the hogweed on the scale of individual plants and leaves. This system opens up a wide vista for obtaining comprehensive and relevant data about the spreading of harmful plants allowing for the elimination of their expansion.},
keywords={Agriculture;Monitoring;Task analysis;Satellites;Image segmentation;Embedded systems;Cameras;Deep learning;edge computing;aerial imagery;unmanned aerial vehicles;precision agriculture;plant phenotype},
doi={10.1109/TC.2021.3059819},
ISSN={1557-9956},
month={Aug},}
@INPROCEEDINGS{8902734,
author={Oliveira, Alexandre J. and Assis, Gleice A. and Faria, Elaine R. and Souza, Jefferson R. and Vivaldini, Kelen C. T. and Guizilini, Vitor and Ramos, Fabio and Mendes, C. T. Caio and Wolf, Denis F.},
booktitle={2019 27th European Signal Processing Conference (EUSIPCO)}, title={Analysis of nematodes in coffee crops at different altitudes using aerial images},
year={2019},
volume={},
number={},
pages={1-5},
abstract={Precision agriculture presents several challenges, amongst them the detection of diseases and pests in agricultural environments. This paper describes a methodology capable of detecting the presence of the nematode pest in coffee crops and also analyzing the behavior of this pest in several altitudes using aerial images. An Unmanned Aerial Vehicle (UAV) is used to obtain high-resolution RGB images of a Brazilian coffee farm. The proposed methodology uses Convolutional Neural Networks (CNN) with U-Net and PSPNet architectures to classify areas into two classes: pests and non-pests. Results demonstrate the viability of the proposed methodology, with an average F-measure of 0.69 for the U-Net architecture with the image resolution 640 × 480.},
keywords={Agriculture;Convolution;Training;Diseases;Soil;Image resolution;Unmanned aerial vehicles;CNN;Nematodes;Coffee Crops;UAV;Altitudes.},
doi={10.23919/EUSIPCO.2019.8902734},
ISSN={2076-1465},
month={Sep.},}
@ARTICLE{9020017,
author={Li, Youyou and Melgani, Farid and He, Binbin},
journal={IEEE Transactions on Geoscience and Remote Sensing}, title={CSVM Architectures for Pixel-Wise Object Detection in High-Resolution Remote Sensing Images},
year={2020},
volume={58},
number={9},
pages={6059-6070},
abstract={Detecting objects becomes an increasingly important task in very high resolution (VHR) remote sensing imagery analysis. With the development of GPU-computing capability, a growing number of deep convolutional neural networks (CNNs) have been designed to address the object detection challenge. However, compared with CPU, GPU is much more costly. Therefore, GPU-based methods are less attractive in practical applications. In this article, we propose a CPU-based method that is based on convolutional support vector machines (CSVMs) to address the object detection challenge in VHR images. Experiments are conducted on three VHR and two unmanned aerial vehicle (UAV) data sets with very limited training data. Results show that the proposed CSVM achieves competitive performance compared to U-Net which is an efficient CNN-based model designed for small training data sets.},
keywords={Object detection;Convolution;Remote sensing;Feature extraction;Training;Image resolution;Support vector machines;Convolutional neural network (CNN);convolutional support vector machine (CSVM);object detection;remote sensing;very high resolution (VHR)},
doi={10.1109/TGRS.2020.2972289},
ISSN={1558-0644},
month={Sep.},}
@INPROCEEDINGS{8384903,
author={Kong, Xiangdong and Zhang, Baochang and Yue, Lei and Xiao, Zehao},
booktitle={2018 Integrated Communications, Navigation, Surveillance Conference (ICNS)}, title={Attentional convolutional neural networks for object tracking},
year={2018},
volume={},
number={},
pages={5B1-1-5B1-11},
abstract={As low-altitude airspace opens up, aeronautical surveillance based Unmanned Aerial Vehicle (UAV) has started to be widely used in the transportation system. Visual object tracking plays an important role in aeronautical surveillance for its accuracy and timeliness. Although traditional trackers have made great progress, they still tend to fail in complex scenes, such as occlusions, illumination variations, background clutter, and etc. In order to make use of appearance features to distinguish the object and surroundings, we propose a novel architecture called attentional convolutional neural networks (ACNN) in conjunction with offline training and online learning for object tracking. ACNN consists of a trunk equipped with attention blocks that highlight the interesting object, and several branches, which are respectively responsible for specific training sequences. In the tracking stage, all branches are removed and a new fully-connected (fc) layer is added to accomplish binary classification. We regard the candidate with the highest probability as current target. Extensive experimental results on public benchmark show that our method performs outstandingly against state-of-the-art methods. In addition, we have also investigated the relationship between the number of network layers and tracking performance for its practical use.},
keywords={Training;Object tracking;Target tracking;Feature extraction;Visualization;Convolutional neural networks},
doi={10.1109/ICNSURV.2018.8384903},
ISSN={},
month={April},}
@INPROCEEDINGS{8309180,
author={Ribera, Javier and Chen, Yuhao and Boomsma, Christopher and Delp, Edward J.},
booktitle={2017 IEEE Global Conference on Signal and Information Processing (GlobalSIP)}, title={Counting plants using deep learning},
year={2017},
volume={},
number={},
pages={1344-1348},
abstract={In this paper we address the task of counting crop plants in a field using Convolutional Neural Networks (CNN). The number of plants in an Unmanned Aerial Vehicle (UAV) image of the field is estimated using regression instead of classification. This avoids to need to know (or guess) the maximum expected number of plants. We also describe a method to extract images of sections or “plots” from an orthorectified image of the entire crop field. These images will be used for training and evaluation of the CNN. Our experiments show that we can obtain a Mean Absolute Percentage Error (MAPE) as low as 6.7% with the Inception-v3 CNN architecture.},
keywords={Agriculture;Task analysis;Neurons;Training;Machine learning;Unmanned aerial vehicles;Neural networks;phenotyping;deep learning;neural network;counting;regression},
doi={10.1109/GlobalSIP.2017.8309180},
ISSN={},
month={Nov},}
@INPROCEEDINGS{8463154,
author={Mansard, N. and DelPrete, A. and Geisert, M. and Tonneau, S. and Stasse, O.},
booktitle={2018 IEEE International Conference on Robotics and Automation (ICRA)}, title={Using a Memory of Motion to Efficiently Warm-Start a Nonlinear Predictive Controller},
year={2018},
volume={},
number={},
pages={2986-2993},
abstract={Predictive control is an efficient model-based methodology to control complex dynamical systems. In general, it boils down to the resolution at each control cycle of a large nonlinear optimization problem. A critical issue is then to provide a good guess to initialize the nonlinear solver so as to speed up convergence. This is particularly important when disturbances or changes in the environment prevent the use of the trajectory computed at the previous control cycle as initial guess. In this paper, we introduce an original and very efficient solution to automatically build this initial guess. We propose to rely on off-line computation to build an approximation of the optimal trajectories, that can be used on-line to initialize the predictive controller. To that end, we combined the use of sampling-based planning, policy learning with generic representations (such as neural networks), and direct optimal control. We first propose an algorithm to simultaneously build a kinodynamic probabilistic roadmap (PRM) and approximate value function and control policy. This algorithm quickly converges toward an approximation of the optimal state-control trajectories (along with an optimal PRM). Then, we propose two methods to store the optimal trajectories and use them to initialize the predictive controller. We experimentally show that directly storing the state-control trajectories leads the predictive controller to quickly converges (2 to 5 iterations) toward the (global) optimal solution. The results are validated in simulation with an unmanned aerial vehicle (UAV) and other dynamical systems.},
keywords={Computational modeling;Approximation algorithms;Optimal control;Planning;Robots;Trajectory optimization},
doi={10.1109/ICRA.2018.8463154},
ISSN={2577-087X},
month={May},}
@INPROCEEDINGS{8833958,
author={Chen, Yanhong and Zhang, Youmin and Xin, Jing and Wang, Guangyi and Mu, Lingxia and Yi, Yingmin and Liu, Han and Liu, Ding},
booktitle={2019 14th IEEE Conference on Industrial Electronics and Applications (ICIEA)}, title={UAV Image-based Forest Fire Detection Approach Using Convolutional Neural Network},
year={2019},
volume={},
number={},
pages={2118-2123},
abstract={Forest fires are very dangerous. Once they become disasters, it is very difficult to extinguish. In this paper, an unmanned aerial vehicle (UAV) image-based forest fire detection approach is proposed. Firstly, the local binary pattern (LBP) feature extraction and support vector machine (SVM) classifier are used for smoke detection, so as to make a preliminary discrimination of forest fire. In order to accurately identify it in the early stage of the fire, according to the convolutional neural network (CNN), it has the characteristics of reducing the number of parameters and improving the training performance through local receptive domain, weight sharing and pooling. This paper proposes another method for detecting forest fires in convolutional neural networks. Image preprocessing operations such as histogram equalization and smooth low-pass filtering are performed prior to inserting the image into the CNN network. The effectiveness of the proposed method is verified by detecting real forest fire images.},
keywords={Forestry;Feature extraction;Histograms;Convolutional neural networks;Support vector machines;Monitoring;Smoothing methods;Forest Fire Detection (FFD);Convolutional Neural Network (CNN);Unmanned Aerial Vehicles (UAVs);Local Binary Pattern (LBP);Image Preprocessing},
doi={10.1109/ICIEA.2019.8833958},
ISSN={2158-2297},
month={June},}
@ARTICLE{8836448,
author={Ghazal, Mohammed Asaad and Mahmoud, Ali and Aslantas, Ali and Soliman, Ahmed and Shalaby, Ahmed and Benediktsson, Jón Atli and El-Baz, Ayman},
journal={IEEE Access}, title={Vegetation Cover Estimation Using Convolutional Neural Networks},
year={2019},
volume={7},
number={},
pages={132563-132576},
abstract={Vegetation is an important parameter in all bio- and ecosystems, and it should be monitored to conserve and restore the environment. This paper presents a design and implementation of a compact system for vegetation cover monitoring, which consists of a small unmanned aerial vehicle (UAV) equipped with four different cameras (RGB, NIR, NDVI, and red). These cameras simultaneously record videos and wirelessly send them to a ground station that applies on them a set of algorithms to construct a mosaic representing the covered area and segment vegetative regions. Mosaicing is performed using a fast multi-threaded approach based on binary descriptors. For segmenting vegetation, two scenarios are tested by using convolutional neural networks (CNNs). The first scenario trained a CNN using the images obtained from the four cameras, and then used it with the constructed mosaics. In the second scenario, we trained individual CNNs using images from each of the four cameras individually. The performance of the former scenario exceeded the others from the perspective of accuracy. Moreover, it proved to be highly comparable to previous approaches utilizing level sets, while the processing time is reduced. The proposed approach obtained high accuracy in terms of the Dice similarity coefficient (97 %), which demonstrates its favorable performance.},
keywords={Vegetation mapping;Cameras;Remote sensing;Videos;Estimation;Monitoring;Image segmentation;CNN;segmentation;UAV;vegetation cover estimation},
doi={10.1109/ACCESS.2019.2941441},
ISSN={2169-3536},
month={},}
@INPROCEEDINGS{9605915,
author={Patrona, Fotini and Mademlis, Ioannis and Pitas, Ioannis},
booktitle={2021 10th International Conference on Information and Automation for Sustainability (ICIAfS)}, title={Self-Supervised Convolutional Neural Networks for Fast Gesture Recognition in Human-Robot Interaction},
year={2021},
volume={},
number={},
pages={88-93},
abstract={Current autonomous systems (e.g., self-driving cars, autonomous drones, consumer robots, etc.) can already perform a wide variety of tasks and are predicted to be able to collaboratively assist humans in the near future. Thus, the need for efficient human-robot interaction (HRI) methods is greatly increasing. Gesture recognition is an effective HRI approach, since many robots are equipped with cameras and computer vision algorithms have progressed significantly in recent years, with advanced Deep Neural Networks (DNNs) being able to be executed on-board an autonomous system. However, computational/memory limitations are still significant for embedded AI methods, rendering the increase of DNN accuracy without imposing a penalty on runtime requirements a very important research priority. This paper investigates self-supervised DNN pretraining for a novel pretext task, relying on spatiotemporal video frame compression via tensor decomposition and low-rank approximation, as a means to augment gesture recognition performance, without inducing any runtime overhead during the inference stage. Thus, the method permits the use of less complex and much faster neural architectures that are well-suited to robotics applications and HRI. Quantitative evaluation on a gesture recognition dataset for autonomous Unmanned Aerial Vehicle (UAV) handling demonstrates the effectiveness and real-time performance of the proposed method on embedded AI compute hardware.},
keywords={Tensors;Runtime;Autonomous systems;Human-robot interaction;Gesture recognition;Computer architecture;Spatiotemporal phenomena;Self-Supervised Learning;Human-Robot Interaction;Gesture Recognition;Convolutional Neural Networks;Tensor Decomposition;Low-Rank Approximation;Autonomous Unmanned Aerial Vehicles},
doi={10.1109/ICIAfS52090.2021.9605915},
ISSN={2151-1810},
month={Aug},}
@INPROCEEDINGS{8623277,
author={Mai, Xiaoming and Pan, Ziyu and Qian, Jinju and Tan, Jin},
booktitle={2018 Chinese Automation Congress (CAC)}, title={Anomaly Detection of Power Transmission Line Using Stereo Vision-Based Multi-Rotor UAV},
year={2018},
volume={},
number={},
pages={2440-2445},
abstract={The distance between a line and the object below is an important index in the maintenance of power transmission, it must be controlled rigidly in tolerance. To accomplish the established task, we proposed a method of measuring the distance between line and the object below based on three-dimensional scene reconstruction using stereo vision on Unmanned Aerial Vehicle (UAV), including Multimodal Neural Networks (MNN)-based semantic segmentation on RGB-D data for power transmission line extraction, and a large-scale semantic scene reconstruction method based on voxel hashing and line modeling. Through fitted line models, we judge whether the distance conforms to safety condition or not. The experimental results demonstrate the practicability and accuracy of the distance measurement solution.},
keywords={Power transmission lines;Three-dimensional displays;Semantics;Inspection;Cameras;Transmission line measurements;Unmanned aerial vehicles;Multi-rotor UAV;power line inspection;stereo vision;sensor registration;reconstruction},
doi={10.1109/CAC.2018.8623277},
ISSN={},
month={Nov},}
@INPROCEEDINGS{9476857,
author={Duggan, Christopher D.R. and Bhandari, Subodh},
booktitle={2021 International Conference on Unmanned Aircraft Systems (ICUAS)}, title={Nonlinear Adaptive Control of Unmanned Aerial Vehicle Using Echo State Neural Networks},
year={2021},
volume={},
number={},
pages={1225-1232},
abstract={This paper presents the use of Echo State neural Networks (ESN) for nonlinear adaptive control of a fixed-wing unmanned aerial vehicle (UAV). Both offline and online trained ESNs are investigated. Flight test data and simulated data are used to train the ESNs offline. The first offline trained ESN is used to estimate the inverse transformation function required for feedback linearization, specifically for the lateral-directional case. The second ESN is trained to estimate error in the output of the first ESN. The estimated error from the second ESN is used to make real time controller corrections as well as update the weighting parameters of the output phase of the first ESN, and thus allowing the controller to adapt in flight. Simulated results show that including online adaptive control improves performance in the presence of noise and disturbances.},
keywords={Recurrent neural networks;Time series analysis;Unmanned aerial vehicles;Real-time systems;Feedback linearization;Adaptive control;Aircraft},
doi={10.1109/ICUAS51884.2021.9476857},
ISSN={2575-7296},
month={June},}
@INPROCEEDINGS{9651348,
author={De Mello, Alexandre R and Barbosa, Flávio G O and Fonseca, Murilo L and Smiderle, Camila D},
booktitle={2021 IEEE International Conference on Imaging Systems and Techniques (IST)}, title={Concrete Dam Inspection with UAV Imagery and DCNN-based Object Detection},
year={2021},
volume={},
number={},
pages={1-6},
abstract={This work aims at developing a solution to aid concrete dam inspections using unmanned aerial vehicle (UAV) imagery and DCNN-based (deep convolutional neural network) object detection. This paper introduces materials used to create the Sentinel dataset, which is a heterogeneous dataset that contains 304 images on the training set and 316 images on the test set from a roller-compacted concrete water dam, with a Creager profile spillway, with annotation of three different types of objects: unwanted objects, harmless objects, and structural damage. This work proposes the use of the Faster R-RCNN and the Single Shot Multibox Detector, which are two deep convolutional neural networks for object detection with singular architectures, to identify nonconformity during an automatic dam inspection system, and analyzes the robustness of both networks considering the accuracy, true positive rate, true negative rate, precision, and F1 metrics. Using the Sentinel dataset, the best result yielded a Faster R-RCNN model with accuracy and an F1 score of 88.9%, which shows the viability of using the proposed solution in an operational environment.},
keywords={Training;Dams;Object detection;Detectors;Inspection;Autonomous aerial vehicles;Safety;machine learning;dam inspection;dam safety monitoring;dam aerial monitoring;deep learning;object detection},
doi={10.1109/IST50367.2021.9651348},
ISSN={1558-2809},
month={Aug},}
@ARTICLE{5751231,
author={Khansari-Zadeh, Seyed Mohammad and Saghafi, Fariborz},
journal={IEEE Transactions on Aerospace and Electronic Systems}, title={Vision-Based Navigation in Autonomous Close Proximity Operations using Neural Networks},
year={2011},
volume={47},
number={2},
pages={864-883},
abstract={Tight unmanned aerial vehicle (UAV) autonomous missions such as formation flight (FF) and aerial refueling (AR) require an active controller that works in conjunction with a precise sensor that is able to identify an in-front aircraft and to estimate its relative position and orientation. Among possible choices vision sensors are of interest because they are passive in nature and do not require the cooperation of the in-front aircraft in any way. In this paper new vision-based estimation and navigation algorithms based on neural networks is developed. The accuracy and robustness of the proposed algorithm have been validated via a detailed modeling and a complete virtual environment based on the six degrees of freedom (6-DOF) nonlinear simulation of aircraft dynamics in an autonomous aerial refueling (AAR) mission. In addition a full-state time-variant tracking controller based on the pole placement method is designed to generate required commands for aircraft control surfaces and engine during an AAR. The performance of the system in the presence of noise has also been examined.},
keywords={Aircraft;Pixel;Feature extraction;Atmospheric modeling;Artificial neural networks;Aircraft navigation;Estimation},
doi={10.1109/TAES.2011.5751231},
ISSN={1557-9603},
month={April},}
@INPROCEEDINGS{8620930,
author={ALTUNDOGAN, Turan Goktug and KARAKOSE, Mehmet},
booktitle={2018 International Conference on Artificial Intelligence and Data Processing (IDAP)}, title={Performance Analysis of EEG Signal Processing Based Device Control Applications},
year={2018},
volume={},
number={},
pages={1-6},
abstract={Nowadays, many types of devices are controlled by electroselenography (EEG) signals. In the literature and in daily life, related studies with EEG controlled devices are increasing day by day. EEG based control applications are applied on many devices such as robot arm, robot, vehicle and unmanned aerial vehicle (UAV). EEG based control procedures usually involve taking, pre-processing, classifying EEG signals, and applying the resulting command to the controlled device. In this study, a performance analysis was carried out by examining the control application studies using EEG signals in the literature. In this analysis study, firstly all studies related to the subject in the literature are examined and the devices, methods, signal processing techniques and classification algorithms used in these studies are handled separately. Appropriate electrode selection for the type of device used in device control applications using EEG signals and type of interaction for command extraction from EEG signal appears to be an important step. In this respect, performance correlations between the types of EEG devices used in the literature studies and the electrode choices used in these studies were compared. Since there are a variety of preprocessing steps for EEG signals, this study provides comparisons based on EEG signal preprocessing techniques. Artificial neural networks (ANN), support vector machines (SVM) and K nearest neighbours (Knn) are used to classify the works in the literature. In this study, comparative studies based on classification methods used in literature studies are also included. As a result, in this study, the studies in the literature for the device control using the EEG signal are examined, compared, interpreted and evaluated, and the points to be considered in the designs to be performed in this area are given.},
keywords={Electroencephalography;Feature extraction;Classification algorithms;Performance evaluation;Artificial neural networks;Support vector machines;Robots;EEG Signal;Control;Brain-Computer Interaction},
doi={10.1109/IDAP.2018.8620930},
ISSN={},
month={Sep.},}
@INPROCEEDINGS{8751810,
author={Celen, Burak and Oniz, Yesim},
booktitle={2018 6th International Conference on Control Engineering Information Technology (CEIT)}, title={Trajectory Tracking of a Quadcopter Using Fuzzy Logic and Neural Network Controllers},
year={2018},
volume={},
number={},
pages={1-6},
abstract={In this work, the trajectory tracking control of an Unmanned Aerial Vehicle (UAV) has been realised using fuzzy logic and neural network based controllers. Parrot AR.Drone 2.0 has been selected as the test platform. For simulated and real-time experimental studies, a square shaped reference trajectory has been generated, and the discrepancies from this trajectory in x-and y-directions along with their derivatives have been employed as the input signals to the proposed controllers. The update rules for the neural network have been derived based on the variable structure systems theory to enable stable online tuning of the parameters. The obtained results indicate that both fuzzy logic and neural network controllers can be applied effectively to the trajectory tracking of a drone, and particularly neural networks with variable structure systems theory based learning algorithms exhibit a highly robust behaviour against disturbances.},
keywords={Drones;Fuzzy logic;Neural networks;Trajectory;Mathematical model;Trajectory tracking;Simulation},
doi={10.1109/CEIT.2018.8751810},
ISSN={},
month={Oct},}
@ARTICLE{9678334,
author={Jiao, Jian and Yu, Ping and Zhao, Xiao and Bi, Fengyi},
journal={IEEE Geoscience and Remote Sensing Letters}, title={Real-Time Aeromagnetic Compensation With Compressed and Accelerated Neural Networks},
year={2022},
volume={19},
number={},
pages={1-5},
abstract={As neural networks become an increasingly popular technique in the field of aeromagnetic compensation, there is an increasing demand for hardware systems with more computing power. Compared with the linear regression method, applying a neural network to the task of real-time compensation is difficult because of insufficient computing resources in the unmanned aerial vehicle (UAV) flight detection platform. To perform real-time compensation calculations with limited computing resources, we optimized back propagation neural network (OBPNN) through model compression and acceleration. In this study, we found that the most time-consuming part of network training is the iterative updating of the weights in the BPNN interference model. Using transfer learning, we replace the randomly initialized weights (RWs) with pretrained weights, thereby greatly reducing the number of iterations required. We also apply other model compression and acceleration algorithms. In a case study of our new technique, we implement the fast training of the OBPNN on a Raspberry Pi 4B system. This network processes approximately 316 samples per 0.1 s, which is fast enough to complete aeromagnetic compensation in real time.},
keywords={Neural networks;Real-time systems;Interference;Atmospheric modeling;Autonomous aerial vehicles;Training;Magnetometers;Parameter quantization;pruning;real-time aeromagnetic compensation;transfer learning;unmanned aerial vehicle (UAV)},
doi={10.1109/LGRS.2022.3142007},
ISSN={1558-0571},
month={},}
@INPROCEEDINGS{9628565,
author={Piani, Mirko and Bortolotti, Gianmarco and Manfrini, Luigi},
booktitle={2021 IEEE International Workshop on Metrology for Agriculture and Forestry (MetroAgriFor)}, title={Apple orchard flower clusters density mapping by unmanned aerial vehicle RGB acquisitions},
year={2021},
volume={},
number={},
pages={92-96},
abstract={Flower load is one of the earlier indicators of potential yield in fruit orchards. Usually, a higher flower clusters number are present on a tree than needed for an optimal production. The most used techniques to manage the flower load are manual, mechanical, and chemical thinning. The main issue is to calibrate these techniques on the base of the desired yield. Drone imagery, being able to collect highly detailed information, could offer a solution to automate flower counting since manual flower counting would be too laborious. The main goals of this study were to test an easy to use and quick be analyzed data acquisition for sudden field interventions, short computing time and reliability. This was achieved by applying and comparing two methodologies that allow to map apple’s flower clusters density at full bloom stage by processing Unmanned aerial Vehicle’s (UAV) imagery with binary classification and K-Nearest Neighbor algorithm, respectively. A comparison between the flower cluster estimation and the actual cluster load analysis highlighted that mapping flower clusters by binary classification is more suitable than machine learning in terms of image processing because it allowed to have a quicker (8 minutes) , easier and less noise - affected image analysis with R2 values ranging from 0,60 to 0,71. Furthermore, the proposed methodology seemed to be able to manage with a high spatial variability since it produced a map that clearly corresponded with zonal field conditions.},
keywords={Filtering;Manuals;Production;Soil;Autonomous aerial vehicles;Software;Sensors;Precise management;thinning;fruit quality;yield;remote sensing;K-nearest neighbor},
doi={10.1109/MetroAgriFor52389.2021.9628565},
ISSN={},
month={Nov},}
@INPROCEEDINGS{9297196,
author={Danesh, Shadi and Araghi, Ali and Khalily, Mohsen and Xiao, Pei and Tafazolli, Rahim},
booktitle={2020 International Symposium on Networks, Computers and Communications (ISNCC)}, title={Millimeter Wave Phased Array Antenna Synthesis Using a Machine Learning Technique for Different 5G Applications},
year={2020},
volume={},
number={},
pages={1-5},
abstract={A machine learning (ML) technique has been used to synthesis a linear millimetre wave (mmWave) phased array antenna by considering the phase-only synthesis approach. For the first time, gradient boosting tree (GBT) is applied to estimate the phase values of a 16-element array antenna to generate different far-field radiation patterns. GBT predicts phases while the amplitude values have been equally set to generate different beam patterns for various 5G mmWave transmission scenarios such as multicast, unicast, broadcast and unmanned aerial vehicle (UAV) applications.},
keywords={Phased arrays;Antenna radiation patterns;Linear antenna arrays;5G mobile communication;Unicast;Unmanned aerial vehicles;Training;5G;phased array antenna;gradient boosting tree (GBT);machine learning (ML);millimetre wave (mmWave);array factor;phase-only synthesis},
doi={10.1109/ISNCC49221.2020.9297196},
ISSN={},
month={Oct},}
@INPROCEEDINGS{9258846,
author={Xin, Qing and Wang, Shixun},
booktitle={2020 International Conference on Communications, Information System and Computer Engineering (CISCE)}, title={GPS Positioning Method of UAV Based on Improved Particle Filter},
year={2020},
volume={},
number={},
pages={97-101},
abstract={With the development of artificial intelligence, particle filter algorithm has become a research hotspot of Chinese and foreign scholars. Since the particle filter algorithm has better performance in the non-linear Gaussian system, the particle filter is applied in the UAV positioning system. The Monte Carlo sampling method is used for the posterior distribution. In view of the particle degradation problem existing in the particle filter algorithm, the re-sampling of the particle filter method is improved. In order to verify the performance of the improved algorithm, experiments were carried out on a quadrotor UAV platform based on STM32. The results show that the improved positioning algorithm can effectively improve the positioning accuracy of the UAV, and has good practicability.},
keywords={Sampling methods;Monte Carlo methods;Information systems;particle filter;re-sampling;UAV;positioning},
doi={10.1109/CISCE50729.2020.00026},
ISSN={},
month={July},}
@INPROCEEDINGS{9255701,
author={Rocha, Bruno Moraes and da Silva Vieira, Gabriel and Fonseca, Afonso U. and Pedrini, Helio and de Sousa, Naiane Maria and Soares, Fabrizzio},
booktitle={2020 IEEE Canadian Conference on Electrical and Computer Engineering (CCECE)}, title={Evaluation and Detection of Gaps in Curved Sugarcane Planting Lines in Aerial Images},
year={2020},
volume={},
number={},
pages={1-4},
abstract={Sugarcane is one of the main crops in the world due to the economic value it promotes by selling its derivatives. A diversity of technologies has been developed to optimize agricultural activities and maximize the productivity of sugarcane crops. In this sense, our primary goal is to contribute to this research area by detecting planting lines and measuring their faults, including the evaluation of curved lines that substantially limit numerous solutions in practical applications. An automatic method that identifies and measures sugarcane planting lines through digital image processing techniques and machine learning algorithms is presented. The proposal is evaluated using a database of real scene images, which were classified by K-Nearest Neighbors (KNN) and prepared with the support of a small unmanned aerial vehicle (UAV). Experimental tests show a low relative error of approximately 1.65% compared to manual mapping in the planting regions. It means that our proposal can identify and measure planting lines accurately, which enables automated inspections with high precision measurements.},
keywords={Agriculture;Proposals;Sugar industry;Unmanned aerial vehicles;Conferences;Area measurement;Vegetation;Image Segmentation;Unmanned Aerial Vehicle;Planting Lines;Intelligent Agriculture},
doi={10.1109/CCECE47787.2020.9255701},
ISSN={2576-7046},
month={Aug},}
@INPROCEEDINGS{5979706,
author={Guizilini, Vitor and Ramos, Fabio},
booktitle={2011 IEEE International Conference on Robotics and Automation}, title={Visual odometry learning for unmanned aerial vehicles},
year={2011},
volume={},
number={},
pages={6213-6220},
abstract={This paper addresses the problem of using visual information to estimate vehicle motion (a.k.a. visual odometry) from a machine learning perspective. The vast majority of current visual odometry algorithms are heavily based on geometry, using a calibrated camera model to recover relative translation (up to scale) and rotation by tracking image features over time. Our method eliminates the need for a parametric model by jointly learning how image structure and vehicle dynamics affect camera motion. This is achieved with a Gaussian Process extension, called Coupled GP, which is trained in a supervised manner to infer the underlying function mapping optical flow to relative translation and rotation. Matched image features parameters are used as inputs and linear and angular velocities are the outputs in our non-linear multi-task regression problem. We show here that it is possible, using a single uncalibrated camera and establishing a first-order temporal dependency between frames, to jointly estimate not only a full 6 DoF motion (along with a full covariance matrix) but also relative scale, a non-trivial problem in monocular configurations. Experiments were performed with imagery collected with an unmanned aerial vehicle (UAV) flying over a deserted area at speeds of 100-120 km/h and altitudes of 80-100 m, a scenario that constitutes a challenge for traditional visual odometry estimators.},
keywords={Visualization;Training;Cameras;Covariance matrix;Vehicles;Optical sensors},
doi={10.1109/ICRA.2011.5979706},
ISSN={1050-4729},
month={May},}
@INPROCEEDINGS{8215283,
author={Carrijo, Gabriel L. A. and Oliveira, Danilo E. and de Assis, Gleice A. and Carneiro, Murillo G. and Guizilini, Vitor C. and Souza, Jefferson R.},
booktitle={2017 Latin American Robotics Symposium (LARS) and 2017 Brazilian Symposium on Robotics (SBR)}, title={Automatic detection of fruits in coffee crops from aerial images},
year={2017},
volume={},
number={},
pages={1-6},
abstract={A big challenge in the precision agriculture is the detection of fruits in coffee crops on agricultural environments. This paper presents a comparison of four features set to detect the red fruits (mature) in Coffee plants. An Unmanned Aerial Vehicle (UAV) is used to obtain high-resolution RGB images of a coffee hall. The proposed methodology enables the extraction of visual features from image regions and uses supervised Machine Learning (ML) techniques to classify areas as coffee fruits and non-fruits (e.g. branches and leaves). Several ML methods were compared using the test data achieved from a Coffee plantation. Experimental results show that the ANN model is more reliable than other ML methods for accurately identifying coffee fruits.},
keywords={Feature extraction;Agriculture;Training;Image color analysis;Visualization;Robots;Testing},
doi={10.1109/SBR-LARS-R.2017.8215283},
ISSN={},
month={Nov},}
@INPROCEEDINGS{9060209,
author={Wang, Shuqin and Gao, Jerry Zeyu and Li, Weiyi and Li, Yanning and Wang, Kaixuan and Lu, Shengqiang},
booktitle={2019 IEEE SmartWorld, Ubiquitous Intelligence Computing, Advanced Trusted Computing, Scalable Computing Communications, Cloud Big Data Computing, Internet of People and Smart City Innovation (SmartWorld/SCALCOM/UIC/ATC/CBDCom/IOP/SCI)}, title={Building Smart City Drone for Graffiti Detection and Clean-up},
year={2019},
volume={},
number={},
pages={1922-1928},
abstract={Graffiti on buildings and bridges are oftentimes an eyesore. Those on road symbol signs can even pose safety risks to motorists. Not only is graffiti cleaning costly, it also disrupts normal traffic. Graffiti is a widespread problem in many cities in the U.S. This paper proposes a machine learning approach to unmanned aerial vehicle (UAV) graffiti detection and removal. Our solution builds on the smart city framework. The proposed solution is expected to lower graffiti cleaning cost and minimize impact on city traffic.},
keywords={Drones;Smart cities;Collision avoidance;Navigation;Cleaning;Machine learning;UAV;Smart City;Graffiti detection},
doi={10.1109/SmartWorld-UIC-ATC-SCALCOM-IOP-SCI.2019.00337},
ISSN={},
month={Aug},}
@INPROCEEDINGS{8858305,
author={Chen, Whai-En and Fan, Xiang-Yuan and Chen, Li-Xian},
booktitle={2019 International Conference on Intelligent Computing and its Emerging Applications (ICEA)}, title={A CNN-based Packet Classification of eMBB, mMTC and URLLC Applications for 5G},
year={2019},
volume={},
number={},
pages={140-145},
abstract={5G supports more new services, including enhanced Mobile Broadband (eMBB), Ultra-reliable and Low Latency Communications (URLLC) and massive Machine Type Communications (mMTC). The Quality of Service (QoS) requirements of these 5G service types are different. In this paper, we capture the packets from the Narrow Band-Internet of Things (NB-IoT) transmission, Unmanned Aerial Vehicle (UAV) control, 4K video and Facebook access for emulating mMTC, URLLC, eMBB and Internet traffic in 5G. With the captured packets, we investigate using the machine learning technology to classify the packets based on the payload information. Specifically, the Convolutional Neural Network (CNN) model is performed to classify the application packets into suitable groups. In addition, this paper studies the effects of various parameters such as the kernel number, kernel size, pooling window size, the dropout rate and the payload length to find the optimal values for high accuracy and low latency.},
keywords={Kernel;5G mobile communication;Payloads;Machine learning;Two dimensional displays;Internet;CNN;eMBB;mMTC;NB-IoT;QoS;URLLC;Machine Learning},
doi={10.1109/ICEA.2019.8858305},
ISSN={},
month={Aug},}
@INPROCEEDINGS{7759731,
author={Grabe, Volker and Nuske, Stephen T.},
booktitle={2016 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)}, title={Long distance visual ground-based signaling for unmanned aerial vehicles},
year={2016},
volume={},
number={},
pages={4976-4983},
abstract={We present a long-range visual signal detection system that is suitable for an unmanned aerial vehicle to find an optical signal released at a desired landing site for the purposes of cargo delivery or rescue situations where radio signals or other communication systems are not available or the wind conditions at the landing site need to be signaled. The challenge here is to have a signal and detection system that works from long range (> 1000m) amongst ground clutter during various seasonal conditions on passive imagery. We use a smoke-grenade as a ground signal, which has the advantageous properties of being easy to carry by ground crews because of its light weight and small size, but when released has a long visual signaling range. We employ a camera system on the UAV with a visual texture feature extraction approach in a machine learning framework to classify image patches as `signal' or `background'. We study conventional approaches and develop a visual feature descriptor that can better differentiate the appearance of the visual signal under varying conditions and, when used to train a random-forest classifier, outperforms commonly used feature descriptors. The system was rigorously and quantitatively evaluated on data collected from a camera mounted on a helicopter and flown towards a plume of signal smoke over a variety of seasons, ground conditions, weather conditions, and environments. Our system was capable of detecting the smoke cloud with both precision and recall rates greater than 0.95 from ranges between 1000m and 1500m. Further, we develop a method to estimate wind orientation and approximate wind strength by assessing the shape of the smoke signal. We present a preliminary evaluation of the wind estimation in conditions with different wind intensities and orientations relative to the approach direction.},
keywords={Visualization;Helicopters;Image segmentation;Cameras;Image color analysis;Feature extraction;Histograms},
doi={10.1109/IROS.2016.7759731},
ISSN={2153-0866},
month={Oct},}
@INPROCEEDINGS{9613210,
author={Ning, Benzhe and Mao, Kai and Wang, Manxi and Li, Hanpeng and Chen, Xiaomin and Zhang, Taotao and Zhu, Qiuming},
booktitle={2021 13th International Conference on Wireless Communications and Signal Processing (WCSP)}, title={Machine Learning Based Angle Estimation for Air-to-Ground Channel Measurements},
year={2021},
volume={},
number={},
pages={1-5},
abstract={Angle parameters are important for channel modeling and performance evaluation of communication systems. In this paper, a channel measurement system is developed for air-to-ground (A2G) scenarios. Moreover, a new angle estimation method based on machine learning for measured channel data is proposed, which includes channel impulse response (CIR) extraction and backpropagation neural network (BPNN) based angle estimation. Based on the extracted CIRs and conventional spatial alternate generalized expectation maximization (SAGE) algorithm, the training dataset is generated to train the BPNN. A measurement campaign is carried out under campus scenario and the analysis results show that the proposed angle estimation method can predict the angle parameter of different multipath accurately and efficiently. The proposed angle estimation method can assist the system design of unmanned aerial vehicle (UAV) beamforming communication, radiation source searching, etc.},
keywords={Training;Wireless communication;Neural networks;Estimation;Channel estimation;Signal processing algorithms;Machine learning;Angle estimation;air-to-ground (A2G);back-propagation neural network (BPNN);channel measurement system},
doi={10.1109/WCSP52459.2021.9613210},
ISSN={2472-7628},
month={Oct},}
@INPROCEEDINGS{9395990,
author={Minu, M. S. and Canessane, R. Aroul},
booktitle={2021 International Conference on Artificial Intelligence and Smart Systems (ICAIS)}, title={An Efficient Squirrel Search Algorithm based Vector Quantization for Image Compression in Unmanned Aerial Vehicles},
year={2021},
volume={},
number={},
pages={789-793},
abstract={Unmanned aerial vehicles (UAVs) typically fly at low altitudes for capturing high-resolution images covering smaller areas. Since short flights also and high-resolution cameras lead to the generation of massive gigabytes (GBs) of data regions, image compression is essential to compress the data to a compact form resulted in shorter file size without any loss of quality. The vector quantization (VQ) is an effective type of image compression and the conventionally employed technique namely Linde-Buzo-Gray (LBG) algorithm continually created local optimal codebook. The codebook design process can be considered as a high dimensional optimization problem and can be resolved by the use of swarm intelligence algorithms. This paper designs a novel squirrel search algorithm (SSA) with LBG based image compression technique, called SSA-LBG for UAVs. The SSA is applied for the construction of codebooks for VQ and it makes use of LBG model as the initialization of the SSA for VQ. The application of SSA-LBG results in effective compression with low computation time (CT) and high peak signal to noise ratio (PSNR). An extensive set of simulations were performed on benchmark test images and the results are examined with respect to CT and PSNR undervarying bit rates and codebook sizes.},
keywords={Image coding;PSNR;Computed tomography;Vector quantization;Computational modeling;Unmanned aerial vehicles;Particle swarm optimization;Compression ratio Codebook generation;Image compression;LBG model;Squirrel search algorithm Unmanned aerial vehicle;Vector quantization},
doi={10.1109/ICAIS50930.2021.9395990},
ISSN={},
month={March},}
@ARTICLE{8809217,
author={Sarabakha, Andriy and Kayacan, Erdal},
journal={IEEE Transactions on Fuzzy Systems}, title={Online Deep Fuzzy Learning for Control of Nonlinear Systems Using Expert Knowledge},
year={2020},
volume={28},
number={7},
pages={1492-1503},
abstract={This article presents an online learning method for improved control of nonlinear systems by combining deep learning and fuzzy logic. Given the ability of deep learning to generalize knowledge from training samples, the proposed method requires minimum amount of information about the system to be controlled. However, in robotics, particularly in aerial robotics where the operating conditions may vary, online learning is required. In this article, fuzzy logic is preferred to provide supervising feedback to the deep model for adapting to variations in the system dynamics as well as new operational conditions. The learning method is divided into two phases: offline pretraining and online posttraining. In the former, the system is controlled by a conventional controller and a deep fuzzy neural network (DFNN) is pretrained based on the recorded input-output dataset, in order to approximate the inverse dynamical model of the system. In the latter, only the pretrained DFNN is used to control the system. In this phase, the fuzzy logic, which encodes the expert knowledge, is utilized to observe the behavior of the system and to correct the action of DFNN instantaneously. The experimental results show that the proposed online learning-based approach improves the trajectory tracking performance of the unmanned aerial vehicle.},
keywords={Control systems;Training;Fuzzy logic;Neurons;Nonlinear systems;Fuzzy neural networks;Noise measurement;Adaptive process control;aerial robotics;deep learning;fuzzy logic;nonlinear systems},
doi={10.1109/TFUZZ.2019.2936787},
ISSN={1941-0034},
month={July},}
@INPROCEEDINGS{8844074,
author={Bayu, Azady and Wibisono, Ari and Wisesa, Hanif Arief and Intizhami, Naili Suri and Jatmiko, Wisnu and Gamal, Ahmad},
booktitle={2019 IEEE International Conference on Communication, Networks and Satellite (Comnetsat)}, title={Semantic Segmentation of Lidar Point Cloud in Rural Area},
year={2019},
volume={},
number={},
pages={73-78},
abstract={A 3D surface modeling format that is commonly used today is point cloud. 3D surface model segmentation could provide data for analysis in various fields. In the context of Geographic Information Systems, point cloud data obtained from the Light Detection and Ranging (LiDAR) sensor are used by machines to automatically identify objects such as houses, buildings, land, and rivers. There has been many Deep Learning approach through Convolutional Neural Network (CNN) that has been proven to be very capable for 2-dimensional imagery classification and segmentation. PointNet is a Deep Learning architecture that is designed so that the point cloud format that is still tabular form, can be directly convoluted by the CNN model. In this study, an improvement of PointNet is proposed for Point Cloud data of Kupang City. The Point Cloud data were acquired using an Unmanned Aerial Vehicle with a LiDAR sensor installed. The data were pre-processed and divided into training and testing data. The data were processed with the PointNet architecture and the model was tested using several metrics. The experiment shows that the PointNet architecture is capable on segmenting Geographical Point Cloud Data. In addition, incorporating voxel's color features could increase the performance of the segmentation.},
keywords={Three-dimensional displays;Laser radar;Data models;Deep learning;Solid modeling;Image segmentation;Training;Point Cloud;Deep Learning;PointNet;LiDAR;Convolutional Neural Network},
doi={10.1109/COMNETSAT.2019.8844074},
ISSN={},
month={Aug},}
@INPROCEEDINGS{9292621,
author={Andersen, Rasmus and Nalpantidis, Lazaros and Ravn, Ole and Boukas, Evangelos},
booktitle={2020 IEEE International Symposium on Safety, Security, and Rescue Robotics (SSRR)}, title={Investigating Deep Learning Architectures towards Autonomous Inspection for Marine Classification},
year={2020},
volume={},
number={},
pages={197-204},
abstract={Marine vessels undergo periodic inspections under which the condition of the vessel is documented. A part of these inspections is to detect defects such as corrosion that degrade the structural integrity of the vessel. The goal of this paper is to evaluate several deep learning architectures and create a hierarchical pipeline that best fits an autonomous inspection system, in the form of an unmanned aerial vehicle, capable of detecting defects in the ballast tanks of a marine vessel. Due to the limited resources available on such an autonomous system, we devised and tested a pipeline to use a smaller deep learning architecture to trigger a larger one when the presence of corrosion is detected. The produced segmentation can then be used to compute the condition of the vessel. In total ten architectures/combinations were tested ranging from traditional classification to object detection and instance segmentation. All the architectures were trained on a dataset containing images from ballast tanks with varying degree of corrosion. The results presented in this paper show that regular object localization architectures such as YOLO and Faster-RCNN suffer from overestimation of the affected corroded area. Binary whole image classification followed by instance segmentation proved to be the best performing pipeline.},
keywords={Computer architecture;Corrosion;Inspection;Image segmentation;Feature extraction;Object detection;Deep learning},
doi={10.1109/SSRR50563.2020.9292621},
ISSN={2475-8426},
month={Nov},}
@INPROCEEDINGS{8761472,
author={Chen, Mingzhe and Saad, Walid and Yin, Changchuan},
booktitle={ICC 2019 - 2019 IEEE International Conference on Communications (ICC)}, title={Deep Learning for 360 amp;#x000B0; Content Transmission in UAV-Enabled Virtual Reality},
year={2019},
volume={},
number={},
pages={1-6},
abstract={In this paper, the problem of content caching and transmission is studied for a wireless virtual reality (VR) network in which cellular-connected unmanned aerial vehicles (UAVs) capture videos on live games or sceneries and transmit them to small base stations (SBSs) that service the VR users. To meet the VR delay requirements, the UAVs can extract specific visible content from the original 360° VR data and send this visible content to the users so as to reduce the traffic load over backhaul and radio access links. To further alleviate the UAV-SBS backhaul traffic, the SBSs can also cache the popular contents that users request. This joint content caching and transmission problem is formulated as an optimization problem whose goal is to maximize the users' reliability, defined as the probability that the content transmission delay of each user satisfies the instantaneous VR delay target. To address this problem, a distributed deep learning algorithm that brings together new neural network ideas from liquid state machine (LSM) and echo state networks (ESNs) is proposed. The proposed algorithm enables each SBS to predict the users' reliability so as to find the optimal contents to cache and content transmission format for each cellular-connected UAV. Simulation results show that the proposed algorithm yields 25.4% gain in terms of reliability compared to Q-learning.},
keywords={Servers;Computer architecture;IEC Standards;Load management;Control systems;Automation},
doi={10.1109/ICC.2019.8761472},
ISSN={1938-1883},
month={May},}
@INPROCEEDINGS{9188835,
author={Shen, Kai and Zhuang, Yu and Zhu, Yixiao},
booktitle={2020 39th Chinese Control Conference (CCC)}, title={Incremental learning-based land mark recognition for mirco-UAV autonomous landing},
year={2020},
volume={},
number={},
pages={6786-6791},
abstract={In order to expand the application fields of micro-UAVs, the ability of land mark recognition and autonomous landing is one of the key technologies for UAVs flighting in complex environment. For achieving more robust and precise relative pose estimation, we propose to apply an ellipse feature-based pose estimation method instead of QR code features. Considering the poor calculating ability on-board, the land mark recognition algorithms based on deep learning are difficult to be used in micro-UAVs. Hence, we put forward a new strategy for target recognition by taking advantage of incremental learning. Concretely, we select to use broad learning system (BLS) to replace the classification layer of MobileNetV3, and design a new target recognition network that may be named as MobileNetV3-BLS. To verify the effectiveness of proposed MobileNetV3-BLS, we use PASCAL VOC2007 and data set collected in our university, and carry out a series of comparative experiments on Nvidia TX2. Results of experiments show that MobileNetV3-BLS can progressively increase the accuracy of landmark recognition online. In addition, the proposed MobileNetV3-BLS does meet the need of deployment on Nvidia TX2 and the real-time requirement of on-board calculation in mirco-UAV avionics systems.},
keywords={Target recognition;Convolutional codes;Real-time systems;Heuristic algorithms;Robustness;Learning systems;Computer architecture;Incremental learning;Broad learning system;Landmark recognition;MobileNetV3;Mirco-UAVs},
doi={10.23919/CCC50068.2020.9188835},
ISSN={1934-1768},
month={July},}
@INPROCEEDINGS{9568788,
author={Stache, Felix and Westheider, Jonas and Magistri, Federico and Popović, Marija and Stachniss, Cyrill},
booktitle={2021 European Conference on Mobile Robots (ECMR)}, title={Adaptive Path Planning for UAV-based Multi-Resolution Semantic Segmentation},
year={2021},
volume={},
number={},
pages={1-6},
abstract={In this paper, we address the problem of adaptive path planning for accurate semantic segmentation of terrain using unmanned aerial vehicles (UAVs). The usage of UAVs for terrain monitoring and remote sensing is rapidly gaining momentum due to their high mobility, low cost, and flexible deployment. However, a key challenge is planning missions to maximize the value of acquired data in large environments given flight time limitations. To address this, we propose an online planning algorithm which adapts the UAV paths to obtain high-resolution semantic segmentations necessary in areas on the terrain with fine details as they are detected in incoming images. This enables us to perform close inspections at low altitudes only where required, without wasting energy on exhaustive mapping at maximum resolution. A key feature of our approach is a new accuracy model for deep learning-based architectures that captures the relationship between UAV altitude and semantic segmentation accuracy. We evaluate our approach on the application of crop/weed segmentation in precision agriculture using real-world field data.},
keywords={Image segmentation;Shape;Semantics;Performance gain;Unmanned aerial vehicles;Path planning;Agriculture},
doi={10.1109/ECMR50962.2021.9568788},
ISSN={},
month={Aug},}
@INPROCEEDINGS{9587621,
author={Akshatha, K R and Biswas, Subhrajyoti and Karunakar, A K and Satish Shenoy, B},
booktitle={2021 2nd Global Conference for Advancement in Technology (GCAT)}, title={Anchored versus Anchorless Detector for Car Detection in Aerial Imagery},
year={2021},
volume={},
number={},
pages={1-6},
abstract={With the increase in the traffic on roadways, traffic monitoring is the major need we have at this moment. Using UAVs for traffic monitoring has numerous advantages such as broader field of view, higher mobility, no effect on detected traffic, etc., however, variation in camera orientation, UAV height, cluttered background imposes challenges to this aerial object detection. To provide a UAV-based traffic monitoring solution, we have proposed a car detection system for UAV images using deep learning approaches. We compared the performance of the anchorless Fully Convolutional One Stage (FCOS) object detection algorithm with the popular YOLOv3 algorithm. The performance analysis of these models based on mean Average Precision (mAP) indicates that FCOS yields better results over YOLOv3, whereas in terms of computation speed YOLOv3 performed better.},
keywords={Deep learning;Vehicle detection;Surveillance;Object detection;Detectors;Traffic control;Real-time systems;Object Detection;aerial images;FCOS;YOLOv3;car detection},
doi={10.1109/GCAT52182.2021.9587621},
ISSN={},
month={Oct},}
@INPROCEEDINGS{9025436,
author={Kyrkou, Christos and Theocharides, Theocharis},
booktitle={2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)}, title={Deep-Learning-Based Aerial Image Classification for Emergency Response Applications Using Unmanned Aerial Vehicles},
year={2019},
volume={},
number={},
pages={517-525},
abstract={Unmanned Aerial Vehicles (UAVs), equipped with camera sensors can facilitate enhanced situational awareness for many emergency response and disaster management applications since they are capable of operating in remote and difficult to access areas. In addition, by utilizing an embedded platform and deep learning UAVs can autonomously monitor a disaster stricken area, analyze the image in real-time and alert in the presence of various calamities such as collapsed buildings, flood, or fire in order to faster mitigate their effects on the environment and on human population. To this end, this paper focuses on the automated aerial scene classification of disaster events from on-board a UAV. Specifically, a dedicated Aerial Image Database for Emergency Response (AIDER) applications is introduced and a comparative analysis of existing approaches is performed. Through this analysis a lightweight convolutional neural network (CNN) architecture is developed, capable of running efficiently on an embedded platform achieving ~3x higher performance compared to existing models with minimal memory requirements with less than 2% accuracy drop compared to the state-of-the-art. These preliminary results provide a solid basis for further experimentation towards real-time aerial image classification for emergency response applications using UAVs.},
keywords={},
doi={10.1109/CVPRW.2019.00077},
ISSN={2160-7516},
month={June},}
@INPROCEEDINGS{9042120,
author={Rădescu, Radu and Dragu, Mihaela},
booktitle={2019 11th International Conference on Electronics, Computers and Artificial Intelligence (ECAI)}, title={Automatic Analysis of Potential Hazard Events Using Unmanned Aerial Vehicles},
year={2019},
volume={},
number={},
pages={1-6},
abstract={This paper is motivated by the possibility of developing a wide variety of applications and domains in which Unmanned Aerial Vehicles (UAVs) can be used globally for various purposes. UAVs are currently used by public administrations and security forces such as police, fire brigades, civil protection, research institutions, construction, and agriculture entities. The purpose of this paper is to facilitate the handling of UAVs to retrieve various data from the environment. The drone (UAV) visits some points to collect data (image and/or video input) from sensors like GPS, camera, gyroscope, and accelerometer. GPS sensor coordinates are used to compare the data taken with subsequent results through processing with specialized software. The drone is used as an access gate with built-in sensors. Certain hazard events (fires, floods, avalanches, landslides) are not limited to narrow geographical areas, but can impact the environment by triggering negative chain events. 3D modeling offers a wide range of possibilities to prevent potential hazard events, or, if such an event has occurred, makes it possible to monitor the affected area and assess the damage by comparing the area in the pre-event configuration with the after-event one. After image processing and data acquisition, a report is generated that includes the map and the 3D model of the analyzed object. A hazard is an agent that has the potential to cause damage to a particular target. Terms such as risk or danger can be used in similar contexts. TensorFlow is an open source software library in high-performance computing. Flexible architecture allows easy deployment of computing on a variety of platforms (CPU, GPU, TPU), from desktop to server or mobile devices. We used the learning transfer: at first we used a model that was already prepared for another problem, and then we re-qualified it on a similar problem. Deep learning from scratch can take several days, but learning transfer can be done shortly. We applied Python along with TensorFlow to train an image classifier and classify images with it. We formed a consistent set of training pictures, using three labels: fire, flood (detectable hazards) and nature (non-hazard images). We then re-qualified an efficient, small-sized neural network by (re)training the image set in order to get the best results in the hazards prediction selection process with a progressive higher accuracy as (re) training evolves at optimal rating. With Python and OpenCV technologies, we used four decision algorithms to generate prediction of hazard: Support Vector Machine, Naive Bayes, Logistic Regression, and Decision Tree Classifier. Each generated report includes precision, recall, f1-score, and support indices, depending on the class and intervals used. We also used the confusion matrix as an alternative method to evaluate the classification accuracy. Analyzing the 4 algorithms we noticed that they behave differently. Training using TensorFlow generated better results than the other methods. For the main classes tested hazard is recognized up to 99%.},
keywords={UAV;hazard;classifiers;decision;prediction},
doi={10.1109/ECAI46879.2019.9042120},
ISSN={},
month={June},}
@INPROCEEDINGS{9636183,
author={Yan, Chao and Xiang, Xiaojia and Wang, Chang and Lan, Zhen},
booktitle={2021 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)}, title={Flocking and Collision Avoidance for a Dynamic Squad of Fixed-Wing UAVs Using Deep Reinforcement Learning},
year={2021},
volume={},
number={},
pages={4738-4744},
abstract={Developing the flocking behavior for a dynamic squad of fixed-wing UAVs is still a challenge due to kinematic complexity and environmental uncertainty. In this paper, we deal with the decentralized flocking and collision avoidance problem through deep reinforcement learning (DRL). Specifically, we formulate a decentralized DRL-based decision making framework from the perspective of every follower, where a collision avoidance mechanism is integrated into the flocking controller. Then, we propose a novel reinforcement learning algorithm PS-CACER for training a shared control policy for all the followers. Besides, we design a plug-n-play embedding module based on convolutional neural networks and the attention mechanism. As a result, the variable-length system state can be encoded into a fixed-length embedding vector, which makes the learned DRL policy independent with the number and the order of followers. Finally, numerical simulation results demonstrate the effectiveness of the proposed method, and the learned policies can be directly transferred to semi-physical simulation without any parameter finetuning.},
keywords={Training;Uncertainty;Heuristic algorithms;Reinforcement learning;Kinematics;Numerical simulation;Numerical models},
doi={10.1109/IROS51168.2021.9636183},
ISSN={2153-0866},
month={Sep.},}
@ARTICLE{8408520,
author={Mou, Lichao and Zhu, Xiao Xiang},
journal={IEEE Transactions on Geoscience and Remote Sensing}, title={Vehicle Instance Segmentation From Aerial Image and Video Using a Multitask Learning Residual Fully Convolutional Network},
year={2018},
volume={56},
number={11},
pages={6699-6711},
abstract={Object detection and semantic segmentation are two main themes in object retrieval from high-resolution remote sensing images, which have recently achieved remarkable performance by surfing the wave of deep learning and, more notably, convolutional neural networks. In this paper, we are interested in a novel, more challenging problem of vehicle instance segmentation, which entails identifying, at a pixel level, where the vehicles appear as well as associating each pixel with a physical instance of a vehicle. In contrast, vehicle detection and semantic segmentation each only concern one of the two. We propose to tackle this problem with a semantic boundary-aware multitask learning network. More specifically, we utilize the philosophy of residual learning to construct a fully convolutional network that is capable of harnessing multilevel contextual feature representations learned from different residual blocks. We theoretically analyze and discuss why residual networks can produce better probability maps for pixelwise segmentation tasks. Then, based on this network architecture, we propose a unified multitask learning network that can simultaneously learn two complementary tasks, namely, segmenting vehicle regions and detecting semantic boundaries. The latter subproblem is helpful for differentiating “touching” vehicles that are usually not correctly separated into instances. Currently, data sets with a pixelwise annotation for vehicle extraction are the ISPRS data set and the IEEE GRSS DFC2015 data set over Zeebrugge, which specializes in a semantic segmentation. Therefore, we built a new, more challenging data set for vehicle instance segmentation, called the Busy Parking Lot Unmanned Aerial Vehicle Video data set, and we make our data set available at http://www.sipeo.bgu.tum.de/downloads so that it can be used to benchmark future vehicle instance segmentation algorithms.},
keywords={Image segmentation;Semantics;Feature extraction;Vehicle detection;Remote sensing;Task analysis;Object detection;Boundary-aware multitask learning network;fully convolutional network (FCN);high-resolution remote sensing image/video;instance semantic segmentation;residual neural network (ResNet);vehicle detection},
doi={10.1109/TGRS.2018.2841808},
ISSN={1558-0644},
month={Nov},}
@ARTICLE{9678336,
author={Alkayas, Abdulaziz Y. and Chehadeh, Mohamad and Ayyad, Abdulla and Zweiri, Yahya},
journal={IEEE Access}, title={Systematic Online Tuning of Multirotor UAVs for Accurate Trajectory Tracking Under Wind Disturbances and In-Flight Dynamics Changes},
year={2022},
volume={10},
number={},
pages={6798-6813},
abstract={The demand for accurate and fast trajectory tracking for multirotor Unmanned Aerial Vehicles (UAVs) have grown recently due to advances in UAV avionics technology and application domains. In many applications, the multirotor UAV is required to accurately perform aggressive maneuvers in challenging scenarios like the presence of external wind disturbances or in-flight payload changes. In this paper, we propose a systematic controller tuning approach based on identification results obtained by a recently developed Deep Neural Networks with the Modified Relay Feedback Test (DNN-MRFT) algorithm. We formulate a linear equivalent representation suitable for DNN-MRFT using feedback linearization. This representation enables the analytical investigation of different controller structures and tuning settings, and captures the non-linearity trends of the system. With this approach, the trade-off between performance and robustness in design was made possible which is convenient for the design of controllers of UAVs operating in uncertain environments. We demonstrate that our approach is adaptive and robust through a set of experiments, where accurate trajectory tracking is maintained despite significant changes to the UAV aerodynamic characteristics and the application of wind disturbance. Due to the model-based system design, it was possible to obtain low discrepancy between simulation and experimental results which is beneficial for potential use of the proposed approach for real-time model-based planning and fault detection tasks. We obtained RMSE of 3.59 cm when tracking aggressive trajectories in the presence of strong wind, which is on par with state-of-the-art.},
keywords={Trajectory;Trajectory tracking;Aerodynamics;Tuning;Autonomous aerial vehicles;Real-time systems;Feedforward systems;Unmanned aerial vehicles;system identification;adaptive and robust control;trajectory tracking;PID control;machine learning},
doi={10.1109/ACCESS.2022.3142388},
ISSN={2169-3536},
month={},}
@INPROCEEDINGS{8794228,
author={Shetty, Akshay and Gao, Grace Xingxin},
booktitle={2019 International Conference on Robotics and Automation (ICRA)}, title={UAV Pose Estimation using Cross-view Geolocalization with Satellite Imagery},
year={2019},
volume={},
number={},
pages={1827-1833},
abstract={We propose an image-based cross-view geolocalization method that estimates the global pose of a UAV with the aid of georeferenced satellite imagery. Our method consists of two Siamese neural networks that extract relevant features despite large differences in viewpoints. The input to our method is an aerial UAV image and nearby satellite images, and the output is the weighted global pose estimate of the UAV camera. We also present a framework to integrate our crossview geolocalization output with visual odometry through a Kalman filter. We build a dataset of simulated UAV images and satellite imagery to train and test our networks. We show that our method performs better than previous camera pose estimation methods, and we demonstrate our networks ability to generalize well to test datasets with unseen images. Finally, we show that integrating our method with visual odometry significantly reduces trajectory estimation errors.},
keywords={Satellites;Geology;Cameras;Feature extraction;Training;Visual odometry;Google},
doi={10.1109/ICRA.2019.8794228},
ISSN={2577-087X},
month={May},}
@INPROCEEDINGS{9349317,
author={Fesenko, Oleksii and Bieliakov, Robert and Radzivilov, Hrygorii and Hulii, Volodymyr and Kovalchuk, Oleh and Korotchenko, Liudmyla},
booktitle={2020 IEEE 2nd International Conference on Advanced Trends in Information Theory (ATIT)}, title={Trajectory Control Method Of UAV In Autonomous Flight Mode Using Neural Network MELM Algorithm},
year={2020},
volume={},
number={},
pages={114-118},
abstract={in our time, the use of unmanned aerial vehicles (UAVs) for communication purposes, for example in Flying Ad-Hoc Networks, often correlates with the emergence of a number of scientific and technical tasks for designing flight control systems of UAVs in the absence of GPS signals: Firstly, in connection with the requirement for the number of errors of setting the flight path. Secondly,compliance with computational accuracy requirements with power limitations of the microcomputer base. In order to solve these problems, it is proposed to use the Method of trajectory control UAV in autonomous flight mode using neural network. Multiple Hidden Layers Extreme Learning Machine (MELM) algorithm, the result of which is tested using experimental comparison with existing Extreme learning machine (ELM) algorithms - Kalman and Weight Agnostic Neural Networks (WANN) - Recurrent Neural Network (RNN) Madgwick. To solve the scientific and technical problem, for the first time it was proposed to use a unit for converting navigation data into a quaternion form to reduce the dimension of the input data, which in turn made it possible to increase the speed and accuracy of training the neural network without using the quantization process. For the first time, the MELM neural network algorithm was applied to solve autonomous navigation problems to reduce the deviation of UAVs from the target trajectory during the disappearance of GPS signals. It has been experimentally proved that the application of the developed technique has ensured a relatively slightest error in predicting the navigation parameters of the trajectory, which occurs in the event of the disappearance of signals of global satellite positioning systems. },
keywords={Training;Recurrent neural networks;Heuristic algorithms;Quaternions;Neurons;Prediction algorithms;Unmanned aerial vehicles;Trajectory;Biological neural networks;Global Positioning System},
doi={10.1109/ATIT50783.2020.9349317},
ISSN={},
month={Nov},}
@ARTICLE{9606685,
author={Niculescu, Vlad and Lamberti, Lorenzo and Conti, Francesco and Benini, Luca and Palossi, Daniele},
journal={IEEE Journal on Emerging and Selected Topics in Circuits and Systems}, title={Improving Autonomous Nano-Drones Performance via Automated End-to-End Optimization and Deployment of DNNs},
year={2021},
volume={11},
number={4},
pages={548-562},
abstract={The evolution of energy-efficient ultra-low-power (ULP) parallel processors and the diffusion of convolutional neural networks (CNNs) are fueling the advent of autonomous driving nano-sized unmanned aerial vehicles (UAVs). These sub-10cm robotic platforms are envisioned as next-generation ubiquitous smart-sensors and unobtrusive robotic-helpers. However, the limited computational/memory resources available aboard nano-UAVs introduce the challenge of minimizing and optimizing vision-based CNNs – which to date require error-prone, labor-intensive iterative development flows. This work explores methodologies and software tools to streamline and automate all the deployment of vision-based CNN navigation on a ULP multicore system-on-chip acting as a mission computer on a Crazyflie 2.1 nano-UAV. We focus on the deployment of PULP-Dronet (Palossi et al., 2019), a state-of-the-art CNN for autonomous navigation of nano-UAVs, from the initial training to the final closed-loop evaluation. Compared to the original hand-crafted CNN, our results show a $2\times $ reduction of memory footprint and a speedup of $1.6\times $ in inference time while guaranteeing the same prediction accuracy and significantly improving the behavior in the field, achieving: i) obstacle avoidance with a peak braking-speed of 1.65m/s and improving the speed/braking-space ratio of the baseline, ii) free flight in a familiar environment up to 1.96m/s (0.5m/s for the baseline), and iii) lane following on a path featuring a 90deg turn – all while using for computation less than 1.6% of the drone’s power budget. To foster new applications and future research, we open-source all the software design in a ready-to-run project compatible with the Crazyflie 2.1.},
keywords={Drones;Navigation;Autonomous robots;Task analysis;Collision avoidance;Sensors;Performance evaluation;Unmanned aerial vehicle (UAV);convolutional neural network (CNN);autonomous navigation;nano-drone;ultra-low-power (ULP)},
doi={10.1109/JETCAS.2021.3126259},
ISSN={2156-3365},
month={Dec},}
@INPROCEEDINGS{8430428,
author={Yousefi, Parsa and Fekriazgomi, Hamid and Demir, Mevlut A. and Prevost, John J. and Jamshidi, Mo},
booktitle={2018 World Automation Congress (WAC)}, title={Data-Driven Fault Detection of Un-Manned Aerial Vehicles Using Supervised Learning Over Cloud Networks},
year={2018},
volume={},
number={},
pages={1-6},
abstract={Modern applications of Unmanned Aerial Vehicles are increasingly attracting the attention of traditional safety and reliability fields. There exist many standard approaches for determining UAV fault detection. However, there doesn't exist a method that is not only model independent but also has the ability to detect faults which have not been predefined for the UAV system. In this research we present two supervised machine learning algorithms implementing Logistic Regression and Linear Discriminant Analysis of Algorithms, respectively, to predict UAV faults. The data which has been used for these approaches comes from discrete-sampled, de-noised analog signals based on the voltage and current inputs belonging to four actuators of the UAV drones. In addition, we demonstrate that by using a five-fold cross validation process to generate different types of training and test datasets, the optimized model can be selected. We verify our results through an analysis describing the accuracies of our proposed model.},
keywords={Fault detection;Training;Mathematical model;Data models;Logistics;Drones;Un-manned Aerial Vehicles;Signal-based Fault Detection;Machine Learning;Supervised Learning;Data Prediction;Linear Discriminant Analysis;Logistic Regression},
doi={10.23919/WAC.2018.8430428},
ISSN={},
month={June},}
@INPROCEEDINGS{8689249,
author={Liu, Xuanlin and Chen, Mingzhe and Yin, Changchuan},
booktitle={2018 IEEE International Conference on Communication Systems (ICCS)}, title={Optimized Trajectory Design in UAV Based Cellular Networks: A Double Q-Learning Approach},
year={2018},
volume={},
number={},
pages={13-18},
abstract={In this paper, the problem of trajectory design of unmanned aerial vehicles (UAVs) for maximizing the number of satisfied users is studied in a UAV based cellular network. In this network, the UAV works as a flying base station that serves users, and the user indicates its satisfaction in terms of completion of its data request within an allowable maximum waiting time. The trajectory design is formulated as an optimization problem whose goal is to maximize the number of satisfied users. To solve this problem, a machine learning framework based on double Q-learning algorithm is proposed. The algorithm enables the UAV to find the optimal trajectory that maximizes the number of satisfied users. Compared to the traditional learning algorithms, such as Q-learning that selects and evaluates the action using the same Q-table, the proposed algorithm can decouple the selection from the evaluation, therefore avoid overestimation which leads to sub-optimal policies. Simulation results show that the proposed algorithm can achieve up to 19.4% and 6.7% gains in terms of the number of satisfied users compared to random algorithm and Q-learning algorithm.},
keywords={},
doi={10.1109/ICCS.2018.8689249},
ISSN={},
month={Dec},}
@ARTICLE{9234009,
author={Sun, Yingxiang and Abeywickrama, Samith and Jayasinghe, Lahiru and Yuen, Chau and Chen, Jiajia and Zhang, Meng},
journal={IEEE Transactions on Geoscience and Remote Sensing}, title={Micro-Doppler Signature-Based Detection, Classification, and Localization of Small UAV With Long Short-Term Memory Neural Network},
year={2021},
volume={59},
number={8},
pages={6285-6300},
abstract={Along with the popularization of small unmanned aerial vehicles (UAVs), societal concerns related to security, privacy, and public safety have gained more attention, thus opening a new avenue for small UAV surveillance. However, the conventional radar technologies pose challenges for the surveillance of small UAVs due to the high cost, small radar cross section, low flying altitude, and slow flying speed. In this article, we propose a novel micro-Doppler signature-based surveillance method using machine learning techniques, for detection, classification, and localization of small UAVs. Via extensive experiments, we demonstrate the performance gain of our proposed method by applying long short-term memory neural network.},
keywords={Surveillance;Propellers;Feature extraction;Unmanned aerial vehicles;Radar cross-sections;Receivers;Classification;detection;localization;long short-term memory (LSTM);micro-Doppler signature (MDS);unmanned aerial vehicle (UAV)},
doi={10.1109/TGRS.2020.3028654},
ISSN={1558-0644},
month={Aug},}
@INPROCEEDINGS{8254657,
author={Esrafilian, Omid and Gesbert, David},
booktitle={GLOBECOM 2017 - 2017 IEEE Global Communications Conference}, title={3D City Map Reconstruction from UAV-Based Radio Measurements},
year={2017},
volume={},
number={},
pages={1-6},
abstract={This paper considers the problem of 3D city map reconstruction. The key novelty here lies in the sole exploitation of UAV-bound radio measurements as a way to recover the map data, i.e. no image of the city is taken or processed. The proposed approach relies on the unique ability for a UAV- to-ground communication system to detect and classify line-of-sight (LoS) vs. non line-of-sight (NLoS) channels towards ground users using machine learning tools. Once classification is carried out, the LoS vs. NLoS data is fed as input to a building position and height reconstruction algorithm. The map reconstruction quality is analyzed as a function of user density and UAV altitude, revealing the notion of an optimal height for the UAV which is predicted using an analytical model.},
keywords={Urban areas;Three-dimensional displays;Image reconstruction;Buildings;Drones;Training data},
doi={10.1109/GLOCOM.2017.8254657},
ISSN={},
month={Dec},}
@INPROCEEDINGS{8254746,
author={Chen, Mingzhe and Saad, Walid and Yin, Changchuan},
booktitle={GLOBECOM 2017 - 2017 IEEE Global Communications Conference}, title={Liquid State Machine Learning for Resource Allocation in a Network of Cache-Enabled LTE-U UAVs},
year={2017},
volume={},
number={},
pages={1-6},
abstract={In this paper, the problem of joint caching and resource allocation is investigated for a network of cache-enabled unmanned aerial vehicles (UAVs) that service wireless ground users over the LTE licensed and unlicensed (LTE-U) bands. The considered model focuses on users that can access both licensed and unlicensed bands while receiving contents through UAV cache-user links and content server-UAV-user links. This problem is formulated as an optimization problem which jointly incorporates user association, spectrum allocation, and content caching. To solve this problem, a distributed algorithm based on the machine learning framework of liquid state machine (LSM) is proposed. Using the proposed LSM algorithm, the cloud can predict the users' content request distribution while having only limited information on the network's and users' states. The proposed algorithm also enables the UAVs to autonomously choose the optimal resource allocation strategies depending on the network states. Simulation results using real datasets show that the proposed approach yields up to 33.3% and 50.3% gains, respectively, in terms of the number of users that have stable queues compared to two baseline algorithms: Q-learning with cache and Q-learning without cache. The results also show that LSM significantly improves the convergence time of up to 33.3% compared to Q-learning.},
keywords={Wireless fidelity;Resource management;Wireless communication;Downlink;Unmanned aerial vehicles;Servers;Long Term Evolution},
doi={10.1109/GLOCOM.2017.8254746},
ISSN={},
month={Dec},}
@INPROCEEDINGS{9367523,
author={Lu, Linyan and Hu, Ye and Zhang, Yirun and Jia, Guangyu and Nie, Jiangtian and Shikh-Bahaei, Mohammad},
booktitle={2020 IEEE Globecom Workshops (GC Wkshps}, title={Machine Learning for Predictive Deployment of UAVs with Rate Splitting Multiple Access},
year={2020},
volume={},
number={},
pages={1-6},
abstract={In this paper, an unmanned aerial vehicles (UAVs) deployment framework based on machine learning is studied. UAVs are deployed as flying base stations (BSs) to offload heavy traffic from ground BSs. A method of backpropagation neuron network (BP) algorithm is used to predict the future cellular traffic. According to the cellular traffic spatial distribution, a KEG algorithm, which is a joint K-means and expectation maximization (EM) algorithm based on Gaussian mixture model (GMM), is proposed for determining each UAV's service area. The UAV locations are optimized to minimize transmit power in their service area. Three multi-access techniques are compared to minimize the total uplink transmit power. Simulation results show that the proposed method can reduce up to 24% of the total power consumption compared to the conventional method without traffic prediction. Besides, rate splitting multiple access (RSMA) has the lower required transmit power compared to frequency domain multiple access (FDMA) and time domain multiple access (TDMA).},
keywords={Time division multiple access;Machine learning algorithms;Power demand;Simulation;Prediction algorithms;Unmanned aerial vehicles;Uplink;UAV Deployment;BP;K-means;EM;GMM;RSMA},
doi={10.1109/GCWkshps50303.2020.9367523},
ISSN={},
month={Dec},}
@INPROCEEDINGS{8885648,
author={Hu, JunShi and Zhang, Heli and Liu, YiMing and Li, Xi and Ji, Hong},
booktitle={2019 IEEE Wireless Communications and Networking Conference (WCNC)}, title={An Intelligent UAV Deployment Scheme for Load Balance in Small Cell Networks Using Machine Learning},
year={2019},
volume={},
number={},
pages={1-6},
abstract={In wireless networks, network load can be highly unbalanced due to the mobility of user equipments (UEs). Unmanned Aerial Vehicles (UAVs) supported base station with the advantage of flexible deployment, ubiquitous wireless coverage and high speed data rate, is a promising approach to handle with the foregoing problem. However, how to achieve cost-effective UAV deployment in an autonomous and dynamic manner is a significant challenge. Facing this problem, we propose a novel UAV base station intelligent deployment scheme based on machine learning and evaluate its performance on a realworld dataset. First, we conduct data preprocessing to process, clean, and transform raw data into formatted data. Missing values are filled by Conditional Mean Imputation (CMI) method and outliers are corrected by pauta criterion. Then, we use hybrid approach which contains ARIMA model and XGBoost model. Linear predictions are carried out by ARIMA model and later nonlinear model XGBoost are applied on residue of ARIMA. Resultant prediction is obtained by adding linear and nonlinear prediction, hybrid model is estimated by Root Mean Square Error (RMSE) and R2 score. Finally, according to predicted results, UAV base stations can be deployed to cater for dynamically changing demands in the hotspot areas and achieve cost-effective deployment. Simulation results show that the propose scheme is superior to other benchmark schemes in load balancing.},
keywords={Base stations;Predictive models;Load modeling;Load management;Conferences;Machine learning;Data preprocessing;UAV base station;hybrid ARIMA-XGBoost model;load balancing optimization},
doi={10.1109/WCNC.2019.8885648},
ISSN={1558-2612},
month={April},}
@INPROCEEDINGS{9348605,
author={Abdalla, Aly Sabri and Marojevic, Vuk},
booktitle={2020 IEEE 92nd Vehicular Technology Conference (VTC2020-Fall)}, title={Machine Learning-Assisted UAV Operations with the UTM: Requirements, Challenges, and Solutions},
year={2020},
volume={},
number={},
pages={1-5},
abstract={Unmanned aerial vehicles (UAVs) are emerging in commercial spaces and will support many applications, such as smart agriculture, dynamic network deployment, network coverage extension, surveillance and security. The unmanned aircraft system (UAS) traffic management (UTM) provides a framework for safe UAV operation by integrating UAV controllers and central data bases through a communications network. This paper discusses the challenges and opportunities for machine learning (ML) for effectively providing critical UTM services. We introduce the four pillars of UTM—operation planning, situational awareness, failure detection and recovery, and remote identification—and discuss the main services, specific opportunities for ML and the ongoing research. We conclude that the multi-faceted operating environment and operational parameters will benefit from collected data and data-driven algorithms, as well as online learning to support new UAV operation situations.},
keywords={Space vehicles;Vehicular and wireless technologies;Surveillance;Unmanned aerial vehicles;Regulation;Security;Vehicle dynamics;UAS;UAV;UTM;ML},
doi={10.1109/VTC2020-Fall49728.2020.9348605},
ISSN={2577-2465},
month={Nov},}
@ARTICLE{9641812,
author={Masmoudi, Nizar and Jaafar, Wael and Cherif, Safa and Abderrazak, Jihene Ben and Yanikomeroglu, Halim},
journal={IEEE Access}, title={UAV-Based Crowd Surveillance in Post COVID-19 Era},
year={2021},
volume={9},
number={},
pages={162276-162290},
abstract={Since outdoor events are gradually allowed within the current pandemic situation, a close monitoring of the crowd activity is needed to avoid undesired contact and disease transmission. In this context, unmanned aerial vehicles (UAVs) can be occasionally used to watch these activities, to ensure that health measures are applied, and to trigger alerts when an anomaly is detected. Consequently, we propose in this paper a complete UAV framework for intelligent monitoring of post COVID-19 outdoor activities. Specifically, we propose a three-step approach. In the first, captured images are analyzed using machine learning to detect and locate individuals. The second step consists of a novel coordinates mapping approach to evaluate distances among individuals and cluster them, while the third step provides an energy-efficient and reliable UAV trajectory to further inspect clusters for restrictions violation. Obtained results provide important insights towards the efficient design of the framework: 1) Efficient detection of individuals depends on the angle from which the images were captured, 2) coordinates mapping is very sensitive to estimate errors in individuals’ bounding boxes, and 3) UAV trajectory design algorithm 2-Opt is recommended for practical real-time deployments due to its low-complexity and near-optimal performance.},
keywords={Autonomous aerial vehicles;Cameras;Surveillance;Social factors;Human factors;COVID-19;Detectors;Object detection;clustering;unmanned aerial vehicle;computer vision;image coordinates mapping},
doi={10.1109/ACCESS.2021.3133796},
ISSN={2169-3536},
month={},}
@ARTICLE{8727504,
author={Liu, Xiao and Liu, Yuanwei and Chen, Yue and Hanzo, Lajos},
journal={IEEE Transactions on Vehicular Technology}, title={Trajectory Design and Power Control for Multi-UAV Assisted Wireless Networks: A Machine Learning Approach},
year={2019},
volume={68},
number={8},
pages={7957-7969},
abstract={A novel framework is proposed for the trajectory design of multiple unmanned aerial vehicles (UAVs) based on the prediction of users' mobility information. The problem ofjoint trajectory design and power control is formulated for maximizing the instantaneous sum transmit rate while satisfying the rate requirement of users. In an effort to solve this pertinent problem, a threestep approach is proposed, which is based on machine learning techniques to obtain both the position information of users and the trajectory design of UAVs. First, a multi-agent Q-learning-based placement algorithm is proposed for determining the optimal positions of the UAVs based on the initial location of the users. Second, in an effort to determine the mobility information of users based on a real dataset, their position data is collected from Twitter to describe the anonymous user-trajectories in the physical world. In the meantime, an echo state network (ESN) based prediction algorithm is proposed for predicting the future positions of users based on the real dataset. Third, a multi-agent Q-learning-based algorithm is conceived for predicting the position of UAVs in each time slot based on the movement of users. In this algorithm, multiple UAVs act as agents to find optimal actions by interacting with their environment and learn from their mistakes. Additionally, we also prove that the proposed multi-agent Q-learning-based trajectory design and power control algorithm can converge under mild conditions. Numerical results are provided to demonstrate that as the size of the reservoir increases, the proposed ESN approach improves the prediction accuracy. Finally, we demonstrate that the throughput gains of about 17% are achieved.},
keywords={Trajectory;Prediction algorithms;Power control;Twitter;Throughput;Base stations;Wireless communication;Multi-agent Q-learning;power control;trajectory design;Twitter;unmanned aerial vehicle (UAV)},
doi={10.1109/TVT.2019.2920284},
ISSN={1939-9359},
month={Aug},}
@ARTICLE{8916643,
author={Liu, Xuanlin and Chen, Mingzhe and Yin, Changchuan},
journal={Journal of Communications and Information Networks}, title={Optimized Trajectory Design in UAV Based Cellular Networks for 3D Users: A Double Q-Learning Approach},
year={2019},
volume={4},
number={1},
pages={24-32},
abstract={In this paper, the problem of trajectory design of unmanned aerial vehicles (UAVs) for maximizing the number of satisfied users is studied in a UAV based cellular network where the UAV works as a flying base station that serves users, and the user indicates its satisfaction in terms of completion of its data request within an allowable maximum waiting time. The trajectory design is formulated as an optimization problem whose goal is to maximize the number of satisfied users. To solve this problem, a machine learning framework based on double Q-learning algorithm is proposed. The algorithm enables the UAV to find the optimal trajectory that maximizes the number of satisfied users. Compared to the traditional learning algorithms, such as Q-learning that selects and evaluates the action using the same Q-table, the proposed algorithm can decouple the selection from the evaluation, therefore avoid overestimation which leads to sub-optimal policies. Simulation results show that the proposed algorithm can achieve up to 19.4% and 14.1% gains in terms of the number of satisfied users compared to random algorithm and Q-learning algorithm.},
keywords={Trajectory;Delays;Unmanned aerial vehicles;Cellular networks;Downlink;Wireless communication;Base stations;UAV communication;trajectory design;double Q-learning algorithm;user satisfaction;cellular network},
doi={10.23919/JCIN.2019.8916643},
ISSN={2509-3312},
month={March},}
@INPROCEEDINGS{6723680,
author={Kelcey, Joshua and Lucieer, Arko},
booktitle={2013 IEEE International Geoscience and Remote Sensing Symposium - IGARSS}, title={An adaptive texture selection framework for ultra-high resolution UAV imagery},
year={2013},
volume={},
number={},
pages={3883-3886},
abstract={The capacity for additional textural derivatives to compensate for the lack of broader spectral sensitivity of consumer grade digitial cameras is established within a UAV context. A texture selection framework utilising random forest machine learning, was developed for application with ultra-high spatial resolution UAV imagery limited to the visible spectrum. The framework represents an adaptive approach, providing a rapid assessment of different texture measures relative to a specific user-defined application. This framework is illustrated within the context of UAV salt marsh mapping. This study highlights the importance of texture selection for improving classification of UAV imagery exhibiting high local spatial variance.},
keywords={Remote sensing;Spatial resolution;Accuracy;Vegetation mapping;Image texture;Geospatial analysis;Texture;Classification;Vegetation},
doi={10.1109/IGARSS.2013.6723680},
ISSN={2153-7003},
month={July},}
@INPROCEEDINGS{9596683,
author={Rezo, M. and Čagalj, K.-M. and Ušljebrka, I. and Kovačić, Z.},
booktitle={2021 44th International Convention on Information, Communication and Electronic Technology (MIPRO)}, title={Collecting Information for Biomass Estimation in Mariculture with a Heterogeneous Robotic System},
year={2021},
volume={},
number={},
pages={1125-1130},
abstract={In this paper, we address the problem of fish stock estimation in marine fisheries using a heterogeneous robotic system consisting of unmanned aerial vehicles (UAVs) and unmanned underwater vehicles (UUVs). UAVs take aerial photographs of the cage during fish feeding, while UUVs take photographs of fish from top to bottom in the cage. The photos and videos obtained provide the input data for estimating the number of fish and the amount of biomass of fish in the cage. The paper analyzes a number of factors that affect the accuracy of the estimate. Preliminary results obtained with an approximate method for estimating the number of fish, based on the processing of images obtained in a virtual simulator and resembling aerial photographs of fish taken during feeding, are described. The results obtained show that this problem is extremely complex and that it is worth trying to use machine learning and artificial intelligence methods to achieve the desired maximum estimation error of less than 20%.},
keywords={Graphical models;Estimation;Machine learning;Fish;Unmanned underwater vehicles;Unmanned aerial vehicles;Biomass;marine fish farming;heterogeneous robotics systems;fish counting;fish biomass estimation},
doi={10.23919/MIPRO52101.2021.9596683},
ISSN={2623-8764},
month={Sep.},}
@INPROCEEDINGS{9525995,
author={Xian, Langmin and Zhao, Weihu and Zhang, Yifan and Zhang, Na and Chen, Xiya},
booktitle={2021 International Conference on Intelligent Transportation, Big Data Smart City (ICITBS)}, title={Identification and Positioning of Engineering Vehicle in UAV Inspection for Optical Cable Lines},
year={2021},
volume={},
number={},
pages={17-20},
abstract={In order to overcome the low efficiency and high risk of the traditional manual inspection method of optical cable lines, this paper proposes a method of identification and positioning of engineering vehicle in UAV inspection. The method is based on the Pytroch deep learning framework and uses YOLOv4 target detection algorithm to realize intelligent detection of hidden faults. At the same time, the paper designs the positioning algorithm of the UAV inspection target based on the image coordinates of the recognition target and the multiple coordinate conversion method. Through test experiments, the results show that the AP value of engineering vehicles inspected by UAV reaches 83.28%, and the target positioning accuracy is about 20 meters, which can meet the inspection requirements. The test results show that based on the method proposed in the paper, the hidden faults of the optical cable can be accurately identified and located, which can effectively improve the inspection efficiency and reduce the workload of the inspectors.},
keywords={Integrated optics;Meters;Target recognition;Smart cities;Vehicle detection;Object detection;Inspection;YOLO;Optical cable inspection;UAV patrol inspection;Target detection;Fault location},
doi={10.1109/ICITBS53129.2021.00013},
ISSN={},
month={March},}
@INPROCEEDINGS{9482383,
author={Luo, Kai and Luo, Rongjian and Zhou, Youwei},
booktitle={2021 IEEE 4th Advanced Information Management, Communicates, Electronic and Automation Control Conference (IMCEC)}, title={UAV detection based on rainy environment},
year={2021},
volume={4},
number={},
pages={1207-1210},
abstract={Based on the UAV detection is under the rainy day will remove the rain to UAV for the front-end process highlighted in depth study methods. Target detection technology has made great progress in recent years. But when it comes to low-flying drones, especially in the case of environmental impacts such as rain and fog. the accuracy and robustness can not meet the real-time requirement. Based on the existing results, this paper uses deep convolutional neural network to detect UAV. First,. introduce the current image fog removal, rain removal related algorithms, using the basic DID-MDN algorithm to achieve rain removal. Second, introduce the algorithm of target detection, and YOLOv5 based on deep learning is used for target detection.},
keywords={Deep learning;Rain;Object detection;Unmanned aerial vehicles;Real-time systems;Robustness;Information management;Rain streak removal;UAV detection;Neiwork contrast;Network cascade},
doi={10.1109/IMCEC51613.2021.9482383},
ISSN={2693-2776},
month={June},}
@INPROCEEDINGS{8782768,
author={Eriş, Halit and Çevik, Ulus},
booktitle={2019 IEEE 17th World Symposium on Applied Machine Intelligence and Informatics (SAMI)}, title={Implementation of Target Tracking Methods on Images Taken from Unmanned Aerial Vehicles},
year={2019},
volume={},
number={},
pages={311-316},
abstract={Traditional object detection algorithms generate proposals and implement feature extraction. Then, a classification algorithm is implemented to label object classes. This process is slow, and the accuracy may not be adequate for UAV's real-time application tasks due to their movement in the air. We specified and practically implemented an object detection and localization scheme on images taken from a UAV, and provided the UAV with an advanced vision. We used YOLOv2 model. The YOLOv2 is a suitable object detection approach based on deep learning, and it presents a network architecture with accurate results in high speed. The object detection and localization were successfully implemented for people, car, and motorcycle classes within the threshold confidence scores. We pre-trained the model on COCO dataset and tested the model with our test images. The confidence scores were higher in altitudes from 5 to 15 meters and the confidence scores varied between %45 - %79 mAP.},
keywords={Unmanned aerial vehicles;Object detection;Task analysis;Target tracking;Automobiles;Computer architecture;Real-time systems;image analysis;deep learning;neural network;convolutional neural network;object classification;target tracking},
doi={10.1109/SAMI.2019.8782768},
ISSN={},
month={Jan},}
@ARTICLE{9716758,
author={Bartoli, Giulio and Marabissi, Dania},
journal={IEEE Transactions on Vehicular Technology}, title={CQI prediction through recurrent neural network for UAV control information exchange under URLLC regime},
year={2022},
volume={},
number={},
pages={1-1},
abstract={Unmanned aerial vehicles (UAVs) control information delivery is a critical communication with stringent requirements in terms of reliability and latency. In this context, link adaptation has an essential role and a relevant impact on the fulfillment of the strict performance in terms of decode error probability and/or delay. Link adaptation is usually based on channel quality indicator (CQI) feedback information from the user equipment that should represent the current state of the channel. However, measurement, scheduling and processing delays introduce a CQI aging effect, that is a mismatch between the current channel state and its CQI representation. Using outdated CQI values may lead to the selection of a wrong modulation and coding scheme, with a detrimental effect on performance. This is particularly relevant in ultra reliable and low latency communications (URLLC) where the control of the reliability can be negatively impacted, and it is more evident when the channel is fast varying as the case of UAVs. This paper analyzes the effects of CQI aging on URLLCs, considering transmissions under the finite blocklength regime, that characterizes such communications type. A deep learning approach is investigated to predict the next CQI from the knowledge of past reports, and performance in terms of decode error probability and throughput is given. The results show the benefit of CQI proposed prediction mechanism also in comparison with previously proposed methods.},
keywords={Ultra reliable low latency communication;Channel estimation;Reliability;Aging;Signal to noise ratio;Autonomous aerial vehicles;Error probability;Link adaptation;CQI report;URLLC;recurrent neural network;spectral efficiency},
doi={10.1109/TVT.2022.3152408},
ISSN={1939-9359},
month={},}
@ARTICLE{9724231,
author={Wang, Lei and Li, Jianan and Huang, Bo and Chen, Junjie and Li, Xiangmin and Wang, Jihui and Xu, Tingfa},
journal={IEEE Transactions on Circuits and Systems for Video Technology}, title={Auto-Perceiving Correlation Filter for UAV Tracking},
year={2022},
volume={},
number={},
pages={1-1},
abstract={Discriminative correlation filter (DCF)-based methods have demonstrated superior performance in UAV tracking via fusing multiple types of features and updating models online. However, most DCF-based trackers simply cascade different features, failing to fully take advantage of their complementary strength. In addition, online update strategies are limited to using a single and fixed learning rate, which often leads to model degradation when suffering tracking challenges. In this paper, we present an Auto-Perceiving Correlation Filter (APCF) which explicitly models the target and context with a novel Target State and Background Perception (TSBP) feature. Concretely, we first propose a simple yet effective State Evaluation Metric (SEM) to estimate target states by analyzing the spatial distribution of responses. Based on SEM, we extract TSBP features by adaptively selecting effective features depending on the current target state. Accordingly, a new online model update strategy is also introduced to avoid model degradation. Moreover, we further introduce a perception regularization term to make the extracted feature emphasis more on the target rather than background. Extensive experiments on four widely-used UAV benchmarks have well demonstrated the superiority of the proposed method compared with both DCF and deep learning based trackers while running at a high speed of 76.7 FPS on a single CPU. In addition, APCF with deep features also performs favorably against state-of-the-art trackers.},
keywords={Target tracking;Adaptation models;Feature extraction;Correlation;Mathematical models;Estimation;Strain;Correlation Filter;Feature Extraction;State Evaluation;Model Update;UAV Tracking},
doi={10.1109/TCSVT.2022.3155731},
ISSN={1558-2205},
month={},}
@INPROCEEDINGS{7934801,
author={Jardine, Peter T. and Givigi, Sidney N. and Yousefi, Shahram},
booktitle={2017 Annual IEEE International Systems Conference (SysCon)}, title={Experimental results for autonomous model-predictive trajectory planning tuned with machine learning},
year={2017},
volume={},
number={},
pages={1-7},
abstract={This paper presents experimental results of a high-level trajectory planning algorithm for autonomous quadrotors based on Model Predictive Control (MPC) tuned with machine learning. Time-varying planar inequality constraints are used to avoid obstacles. The nonlinear plant dynamics are linearized around a hover condition. Learning Automata is used to select the relative weights of the objective function and compensate for nonlinearities lost during this linearization. The proposed technique successfully guides a quadcopter to a target while avoiding a spherical obstacle placed in its path. These results demonstrate the potential application for MPC-based techniques in unmanned aerial vehicle operations that involve obstacles. Furthermore, they demonstrate that machine learning can be used to tune parameters in an MPC formulation.},
keywords={Trajectory;Planning;Iron;Linear programming;Computational modeling;Nonlinear dynamical systems;Unmanned aerial vehicles},
doi={10.1109/SYSCON.2017.7934801},
ISSN={2472-9647},
month={April},}
@INPROCEEDINGS{8556769,
author={Das, Aditya and Kol, Patrik and Lundberg, Cody and Doelling, Kris and Sevil, Hakki Erhan and Lewis, Frank},
booktitle={NAECON 2018 - IEEE National Aerospace and Electronics Conference}, title={A Rapid Situational Awareness Development Framework for Heterogeneous Manned-Unmanned Teams},
year={2018},
volume={},
number={},
pages={417-424},
abstract={This paper presents a robust framework for configuring and deploying a heterogeneous team of smart unmanned systems and human agents in dynamic and un-modeled environments to rapidly build mission critical situational awareness with selective details of potential areas of interest, especially focusing on minimized cognitive loading of the human agents. Five key components, namely control, communication, artificial intelligence (AI), platform, and visualization, merge seamlessly into a holistic framework to deliver this rapid situational awareness development capability to the heterogeneous manned unmanned team (MUM-T). In this framework, the overall control is seen as a combination of agent level control and mission level control. A common software, Robot Operating System (ROS), is used to establish communication, and consequently consensus, among the heterogeneous swarm of unmanned systems. These unmanned platforms are customized with co-processing hardware that can execute advanced artificial intelligence machine learning (AI/ML) modules to not only deliver stable and cooperative performance of these unmanned platforms in the swarm but also support human-centric human robot interaction (HRI). Finally, to reduce the cognitive burden on the human agents, a triaged visualization scheme, enabled through mixed reality (MR) technology, is implemented. This paper presents a preliminary proof of concept study for the presented hybrid map (i.e. 2D mapping with 3D detailing) construction framework, tested with a heterogeneous swarm of unmanned aerial vehicles (UAVs) of varying capabilities, teamed with a human operator.},
keywords={Visualization;Three-dimensional displays;Operating systems;Mixed reality;Virtual reality;Unmanned aerial vehicles;Software;Supervised Autonomy;Triaged Visualization;Human Robot Interaction;Consensus Control;Mixed Reality},
doi={10.1109/NAECON.2018.8556769},
ISSN={2379-2027},
month={July},}
@INPROCEEDINGS{6363344,
author={Silva, Diego M. P. F. and de Oliveira, Luiz Felipe F. and Macedo, Mariana G. M. and Filho, Carmelo J. A. Bastos},
booktitle={2012 Brazilian Robotics Symposium and Latin American Robotics Symposium}, title={On the Analysis of a Swarm Intelligence Based Coordination Model for Multiple Unmanned Aerial Vehicles},
year={2012},
volume={},
number={},
pages={208-213},
abstract={This paper presents an analysis of a model for the coordination of multiple unmanned aerial vehicles (UAVs) using a swarm intelligence approach based on Particle Swarm Optimization. The model considers locomotion constraints, anti-collision mechanisms, ad hoc communication and environmental perception information from the UAVs sensors. We analyze the performance in terms of target tracking and energy consumption. We developed a simulator with a graphic user interface to allow the visual analysis of the swarm of UAVs.},
keywords={Target tracking;Sensors;Analytical models;Engines;Robot kinematics;Particle swarm optimization;Unmanned Aerial Vehicles;Swarm Robots;Swarm intelligence;Energy consumption},
doi={10.1109/SBR-LARS.2012.41},
ISSN={},
month={Oct},}
@INPROCEEDINGS{8206296,
author={Albani, Dario and Nardi, Daniele and Trianni, Vito},
booktitle={2017 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)}, title={Field coverage and weed mapping by UAV swarms},
year={2017},
volume={},
number={},
pages={4319-4325},
abstract={The demands from precision agriculture (PA) for high-quality information at the individual plant level require to re-think the approaches exploited to date for remote sensing as performed by unmanned aerial vehicles (UAVs). A swarm of collaborating UAVs may prove more efficient and economically viable compared to other solutions. To identify the merits and limitations of a swarm intelligence approach to remote sensing, we propose here a decentralised multi-agent system for a field coverage and weed mapping problem, which is efficient, intrinsically robust and scalable to different group sizes. The proposed solution is based on a reinforced random walk with inhibition of return, where the information available from other agents (UAVs) is exploited to bias the individual motion pattern. Experiments are performed to demonstrate the efficiency and scalability of the proposed approach under a variety of experimental conditions, accounting also for limited communication range and different routing protocols.},
keywords={Robots;Remote sensing;Agriculture;Robustness;Unmanned aerial vehicles;Multi-agent systems;Optimization},
doi={10.1109/IROS.2017.8206296},
ISSN={2153-0866},
month={Sep.},}
@INPROCEEDINGS{7806419,
author={Leonov, Alexey V.},
booktitle={2016 13th International Scientific-Technical Conference on Actual Problems of Electronics Instrument Engineering (APEIE)}, title={Modeling of bio-inspired algorithms AntHocNet and BeeAdHoc for Flying Ad Hoc Networks (FANETs)},
year={2016},
volume={02},
number={},
pages={90-99},
abstract={Due to versatility, flexibility and fairly small operating costs, the use of small unmanned aerial vehicles (UAVs) groups provides new opportunities for civil application. FANET (Flying Ad Hoc Network), similar to mobile peer-to-peer networks MANET and vehicular peer-to-peer networks VANET represents a special type of peer-to-peer ad hoc network based on UAVs. FANETs are characterized by high nodes mobility, dynamically-changing topology and movement in 3D-space. To organize multi-UAV network one needs to use special routing algorithms developed due to their specific features. The article gives a short overview of the existing FANET algorithms, as well as of the algorithms based on the swarm intelligence (of the ant and bee colonies). The experimental analysis was conducted, that proved the possibility of efficient application of bio-inspired algorithms. The analysis was performed on protocols AntHocNet and BeeAdHoc, simulating the behavior of bees and ants in wildlife, to solve the routing problems in FANETs.},
keywords={Mobile ad hoc networks;Vehicular ad hoc networks;Wireless sensor networks;Feedback loop;Quality of service;FANET;Routing Protocols;Network Simulation;AntHocNet;BeeAdHoc},
doi={10.1109/APEIE.2016.7806419},
ISSN={},
month={Oct},}
@ARTICLE{9405647,
author={Shao, Shikai and He, Chenglong and Zhao, Yuanjie and Wu, Xiaojing},
journal={IEEE Access}, title={Efficient Trajectory Planning for UAVs Using Hierarchical Optimization},
year={2021},
volume={9},
number={},
pages={60668-60681},
abstract={Automatic generation of feasible trajectory is one of the key technologies for autonomous flying of unmanned aerial vehicles (UAVs). The existing path planning methods, such as swarm intelligence algorithm and graph-based algorithm, cannot incorporate the flying time and UAV dynamic model into evolution. To overcome such disadvantages, a hierarchical trajectory optimization scheme consisted by improved particle swarm optimization (PSO) and Gauss pseudo-spectral method (GPM) is investigated in this paper. Firstly, considering that traditional GPM is sensitive to initial values, we design an improved PSO for path planning in the first layer. By introducing adaptive parameter adjustment strategy and position mutation updating strategy, the rapidity and optimality of the improved PSO is enhanced. Then in the second layer, a fitted curve based on the path waypoints generated by improved PSO is constructed and served as the initial values for GPM. Comparing with random initial values, the designed curve can significant improve GPM efficiency. A multi-segment strategy is also put forward to further improve the efficiency. Finally, with the consideration of dynamic model and state constraints, the time minimum trajectory planning for quadrotor UAVs is solved. Plenty of simulations are carried out and the results illustrate that the proposed scheme guarantees much better efficiency.},
keywords={Trajectory planning;Optimization;Heuristic algorithms;Unmanned aerial vehicles;Vehicle dynamics;Particle swarm optimization;Planning;Unmanned aerial vehicles;trajectory planning;particle swarm optimization;Gauss pseudo-spectral method},
doi={10.1109/ACCESS.2021.3073420},
ISSN={2169-3536},
month={},}
@INPROCEEDINGS{6089619,
author={Varela, Gervasio and Caamaño, Pilar and Orjales, Felix and Deibe, Álvaro and López-Peña, Fernando and Duro, Richard J.},
booktitle={2011 Third World Congress on Nature and Biologically Inspired Computing}, title={Swarm intelligence based approach for real time UAV team coordination in search operations},
year={2011},
volume={},
number={},
pages={365-370},
abstract={This paper proposes swarm intelligence based approach for the real time coordination of groups of UAVs (Unmanned Aerial Vehicles) in tasks where values that are sensed from the aerial platform can be used to qualify the individuals. In particular, as an example application, here we consider environmental monitoring UAV teams. Their function is to monitor an area and when some undesired environmental condition arises, coordinate themselves to find the source as fast as possible. The swarm based algorithm has been extensively tested using a 3D simulation platform and validated with real UAVs flying over an industrial area.},
keywords={Pollution;Airplanes;Sensors;Monitoring;Three dimensional displays;Real time systems;Atmospheric modeling;Unmanned Aerial Vehicles;Evolution;Robot Coordination},
doi={10.1109/NaBIC.2011.6089619},
ISSN={},
month={Oct},}
@INPROCEEDINGS{8996026,
author={Li, Hongnan and Wu, Lizhen and Niu, Yifeng and Wang, Chang and Liu, Tianqing},
booktitle={2019 IEEE International Conference on Unmanned Systems (ICUS)}, title={Small Sample Meta-leaming Towards Object Recognition Through UAV Observations},
year={2019},
volume={},
number={},
pages={860-865},
abstract={Deep learning has achieved impressive results for image classification and object recognition. However, deep learning typically requires too many labeled data for model training which is not always applicable in the tasks that data collection is difficult or expensive. In this paper, we consider the problem of object recognition by a UAV that can observe a given object from different viewpoints and learn to recognize similar objects. Specifically, we have used the Recursive Cortical Network (RCN) for car recognition based on a recorded UAV video. Furthermore, we have combined meta-learning and transfer learning to further improve the training efficiency. Experiments results have demonstrated the effectiveness of the proposed method using the Ominiglot dataset.},
keywords={Feature extraction;Training;Target recognition;Unmanned aerial vehicles;Bayes methods;Automobiles;Machine learning;UAV;object recognition;Recursive Cortical Network;meta-learning;transfer learning},
doi={10.1109/ICUS48101.2019.8996026},
ISSN={},
month={Oct},}
@INPROCEEDINGS{8996643,
author={Wanguo, Wang and Zhenli, Wang and Bin, Liu and Yuechen, Yang and Xiaobin, Sun},
booktitle={2019 Chinese Automation Congress (CAC)}, title={Typical Defect Detection Technology of Transmission Line Based on Deep Learning},
year={2019},
volume={},
number={},
pages={1185-1189},
abstract={Detection of line component defects in UAV transmission line inspection is always a difficult problem. In order to solve the problem of identifying the defects of insulators and anti-vibration hammers in transmission lines, a target detection technique based on deep learning is proposed to diagnose the typical defects of transmission lines. SSD algorithm based on candidate regions is selected to locate and identify the defects. Firstly, the influence of different feature extraction networks and network parameters on the accuracy and speed of target detection is studied. The network is improved by adjusting network parameters and model optimization method, and the network parameters that are most conducive to transmission line defect detection are selected.Then, the influence of different data enhancement methods on the accuracy of defect detection is studied. The training samples are expanded by multi-scale training and horizontal mirror method to further improve the accuracy of target detection.Finally, the recognition and classification experiments are carried out using the actual images collected by UAV. The experimental results show that the target detection method based on deep learning can accurately locate the location of defects from the transmission line image, and can be applied to the fault diagnosis task in the transmission line scene.},
keywords={Power transmission lines;Feature extraction;Training;Convolution;Mathematical model;Machine learning;Insulators;transmission line;object detection;deep learning},
doi={10.1109/CAC48633.2019.8996643},
ISSN={2688-0938},
month={Nov},}
@ARTICLE{9556573,
author={Lim, Hyungtae and Ryu, Hanseok and Rhudy, Matthew B. and Lee, Dongjin and Jang, Dongjin and Lee, Changho and Park, Youngmin and Youn, Wonkeun and Myung, Hyun},
journal={IEEE Robotics and Automation Letters}, title={Deep Learning-Aided Synthetic Airspeed Estimation of UAVs for Analytical Redundancy With a Temporal Convolutional Network},
year={2022},
volume={7},
number={1},
pages={17-24},
abstract={A synthetic air data system (SADS) is an analytical redundancy technique that is crucial for unmanned aerial vehicles (UAVs) and is used as a backup system during air data sensor failures. Unfortunately, the existing state-of-the-art approaches for SADS require GPS signals or high-fidelity dynamic UAV models. To address this problem, a novel synthetic airspeed estimation method that leverages deep learning and an unscented Kalman filter (UKF) for analytical redundancy is proposed. Our novel fusion-based method only requires an inertial measurement unit (IMU), elevator control input, and airflow angles while GPS, lift/drag coefficients, and complex aircraft dynamic models are not required. Additionally, we demonstrate that our proposed temporal convolutional network (TCN) is a more efficient model for airspeed estimation than the renowned models, such as ResNet or bidirectional long short-term memory (LSTM). Our deep learning-aided UKF was experimentally verified on long-duration real flight data and has promising performance compared with the state-of-the-art methods. In particular, it is confirmed that our proposed method robustly estimates the airspeed even under dynamic flight conditions where the performance of conventional methods is degraded.},
keywords={Redundancy;Atmospheric modeling;Estimation;Aircraft;Global Positioning System;Unmanned aerial vehicles;Deep learning;Aerial Systems: applications;sensor fusion;field robots;temporal convolutional network;Deep learning;unmanned aerial vehicles;analytical redundancy},
doi={10.1109/LRA.2021.3117021},
ISSN={2377-3766},
month={Jan},}


@INPROCEEDINGS{9259811,
author={Ates, Ugurkan},
booktitle={2020 Innovations in Intelligent Systems and Applications Conference (ASYU)}, title={Long-Term Planning with Deep Reinforcement Learning on Autonomous Drones},
year={2020},
volume={},
number={},
pages={1-6},
abstract={In this paper, we study a long-term planning scenario that is based on drone racing competitions held in real life. We conducted this experiment on a framework created for “Game of Drones: Drone Racing Competition” at NeurIPS 2019. The racing environment was created using Microsoft's AirSim Drone Racing Lab. We have trained a reinforcement learning agent, simulated quadrotor in our case, with the Policy Proximal Optimization (PPO) algorithm. After training process it was successfully able to compete against another simulated quadrotor that was running a classical path planning algorithm. Agent observations consist of data from IMU sensors, GPS coordinates of drone obtained through simulation and opponent drone GPS information. Using opponent drone GPS information during training helps dealing with complex state spaces which serves as expert guidance. This approach allows efficient and stable training process. Our work fits into Clought's level 10 UAV autonomy categorization. All experiments performed in this paper can be found and reproduced with code at our GitHub repository.},
keywords={Drones;Task analysis;Training;Robots;Planning;Reinforcement learning;Neural networks;Deep Reinforcement Learning;Path Planning;Machine Learning;Drone Racing},
doi={10.1109/ASYU50717.2020.9259811},
ISSN={},
month={Oct},}
@INPROCEEDINGS{7989380,
author={Martinez-Cantin, Ruben},
booktitle={2017 IEEE International Conference on Robotics and Automation (ICRA)}, title={Bayesian optimization with adaptive kernels for robot control},
year={2017},
volume={},
number={},
pages={3350-3356},
abstract={Active policy search combines the trial-and-error methodology from policy search with Bayesian optimization to actively find the optimal policy. First, policy search is a type of reinforcement learning which has become very popular for robot control, for its ability to deal with complex continuous state and action spaces. Second, Bayesian optimization is a sample efficient global optimization method that uses a surrogate model, like a Gaussian process, and optimal decision making to carefully select each sample during the optimization process. Sample efficiency is of paramount importance when each trial involves the real robot, expensive Monte Carlo runs, or a complex simulator. Black-box Bayesian optimization generally assumes a cost function from a stationary process, because nonstationary modeling is usually based on prior knowledge. However, many control problems are inherently nonstationary due to their failure conditions, terminal states and other abrupt effects. In this paper, we present a kernel function specially designed for Bayesian optimization, that allows nonstationary modeling without prior knowledge, using an adaptive local region. The new kernel results in an improved local search (exploitation), without penalizing the global search (exploration), as shown experimentally in well-known optimization benchmarks and robot control scenarios. We finally show its potential for the design of the wing shape of a UAV.},
keywords={Kernel;Optimization;Bayes methods;Gaussian processes;Robots;Adaptation models;Learning (artificial intelligence)},
doi={10.1109/ICRA.2017.7989380},
ISSN={},
month={May},}
@INPROCEEDINGS{9488791,
author={Dai, Zipeng and Wang, Hao and Liu, Chi Harold and Han, Rui and Tang, Jian and Wang, Guoren},
booktitle={IEEE INFOCOM 2021 - IEEE Conference on Computer Communications}, title={Mobile Crowdsensing for Data Freshness: A Deep Reinforcement Learning Approach},
year={2021},
volume={},
number={},
pages={1-10},
abstract={Data collection by mobile crowdsensing (MCS) is emerging as data sources for smart city applications, however how to ensure data freshness has sparse research exposure but quite important in practice. In this paper, we consider to use a group of mobile agents (MAs) like UAVs and driverless cars which are equipped with multiple antennas to move around in the task area to collect data from deployed sensor nodes (SNs). Our goal is to minimize the age of information (AoI) of all SNs and energy consumption of MAs during movement and data upload. To this end, we propose a centralized deep reinforcement learning (DRL)-based solution called "DRL-freshMCS" for controlling MA trajectory planning and SN scheduling. We further utilize implicit quantile networks to maintain the accurate value estimation and steady policies for MAs. Then, we design an exploration and exploitation mechanism by dynamic distributed prioritized experience replay. We also derive the theoretical lower bound for episodic AoI. Extensive simulation results show that DRL-freshMCS significantly reduces the episodic AoI per remaining energy, compared to five baselines when varying different number of antennas and data upload thresholds, and number of SNs. We also visualize their trajectories and AoI update process for clear illustrations.},
keywords={Trajectory planning;Crowdsensing;Smart cities;Simulation;Estimation;Reinforcement learning;Dynamic scheduling;Mobile crowdsensing;Data freshness;Deep reinforcement learning},
doi={10.1109/INFOCOM42981.2021.9488791},
ISSN={2641-9874},
month={May},}
@INPROCEEDINGS{8866189,
author={Yuan, Xin and Sun, Yuewen and Wang, Yuanda and Sun, Changyin},
booktitle={2019 Chinese Control Conference (CCC)}, title={Deterministic Policy Gradient with Advantage Function for Fixed Wing UAV Automatic Landing},
year={2019},
volume={},
number={},
pages={8305-8310},
abstract={This paper addresses the autolanding problem for fixed wing unmanned aerial vehicles (UAV) in the presence of the downburst. The proposed method is developed based on the reinforcement learning methodology. The solution consists of a path-tracking controller for the glideslope maneuver and an attitude controller for the flare maneuver. Both controllers are designed in continuous state and action spaces. In our study, two complementary techniques are proposed within the framework of deterministic policy gradient (DPG). First, the advantage function is introduced in the critic network to improve the performance of the learning process. The proposed representation of the action value function consists of two parts: the low-frequency part and the high-frequency one. Second, a two-stream network is developed to tackle with the issue of partially observable Markov decision process (POMDP). The architecture synthesizes past experiences to perform policy evaluations and policy improvements, which has successfully improved the robustness of the learned policy. The described performance of our approach is illustrated in flight simulations under the influence of the wind field.},
keywords={Aerodynamics;Vehicle dynamics;Mathematical model;Unmanned aerial vehicles;Task analysis;Computational modeling;Deterministic policy gradient;advantage function;automatic landing;fixed wing UAV;wind field},
doi={10.23919/ChiCC.2019.8866189},
ISSN={1934-1768},
month={July},}
@INPROCEEDINGS{9196611,
author={Fei, Fan and Tu, Zhan and Xu, Dongyan and Deng, Xinyan},
booktitle={2020 IEEE International Conference on Robotics and Automation (ICRA)}, title={Learn-to-Recover: Retrofitting UAVs with Reinforcement Learning-Assisted Flight Control Under Cyber-Physical Attacks},
year={2020},
volume={},
number={},
pages={7358-7364},
abstract={In this paper, we present a generic fault-tolerant control (FTC) strategy via reinforcement learning (RL). We demonstrate the effectiveness of this method on quadcopter unmanned aerial vehicles (UAVs). The fault-tolerant control policy is trained to handle actuator and sensor fault/attack. Unlike traditional FTC, this policy does not require fault detection and diagnosis (FDD) nor tailoring the controller for specific attack scenarios. Instead, the policy is running simultaneously alongside the stabilizing controller without the need for on- detection activation. The effectiveness of the policy is compared with traditional active and passive FTC strategies against actuator and sensor faults. We compare their performance in position control tasks via simulation and experiments on quadcopters. The result shows that the strategy can effectively tolerate different types of attacks/faults and maintain the vehicle's position, outperforming the other two methods.},
keywords={Actuators;Fault tolerance;Fault tolerant systems;Vehicle dynamics;Learning (artificial intelligence);Training;Solid modeling},
doi={10.1109/ICRA40945.2020.9196611},
ISSN={2577-087X},
month={May},}
@INPROCEEDINGS{9549604,
author={Ma, Longfei and Wang, Hsiucheng and Liu, Fenghua and Li, Kaiyuan},
booktitle={2021 40th Chinese Control Conference (CCC)}, title={Remote Monitoring Algorithm for Unmanned Surface Vessel: A System Based on Classification and Learning},
year={2021},
volume={},
number={},
pages={5117-5123},
abstract={The Unmanned Surface Vessel (USV) is a type of driverless and intelligent vessel capable of automatic navigation. It can perform the extremely dangerous tasks that humans cannot complete. Through a method that combines classification and learning, we have built a remote monitoring system for USV. This system uses the Chebyshev fitting algorithm to process the data features of the UAV working states by preprocessing the telemetry data. Feature vectors substitute the original data. Based on reinforcement learning and PSO-improved SVM, state analysis of the USV is implemented in the Microsoft Foundation Classes (MFC) environment. By comparing with other algorithms, the performance of the designed system verifies its effectiveness, and at the end of this paper, we also discussed the limitations of the algorithm.},
keywords={Support vector machines;Software algorithms;Reinforcement learning;Software systems;Unmanned aerial vehicles;Classification algorithms;Telemetry;reinforcement learning;particle swarm optimization;support vector machine;unmanned surface vessel;remote monitoring system},
doi={10.23919/CCC52363.2021.9549604},
ISSN={1934-1768},
month={July},}
@INPROCEEDINGS{9473729,
author={Zhu, Zheqi and Wan, Shuo and Fan, Pingyi and Letaief, Khaled B.},
booktitle={2021 IEEE International Conference on Communications Workshops (ICC Workshops)}, title={An Edge Federated MARL Approach for Timeliness Maintenance in MEC Collaboration},
year={2021},
volume={},
number={},
pages={1-6},
abstract={Mobile edge computing (MEC) has been widely studied to provide new schemes for communication-computing systems such as industrial Internet of Things (IoTs), vehicular networks, smart city applications, etc. In this work, we mainly investigate on the timeliness maintenance of the MEC systems where the freshness of the data and computation tasks plays a significant role. We firstly formulate the average age of information (AoI) minimization problem of the UAV-assisted MEC systems. To maintain the system timeliness, we propose a novel multi-agent reinforcement learning (MARL) approach, called edge federated multi-agent actor-critic (MAAC), for joint trajectory planning, data scheduling and resource management in the investigated MEC systems. Through the proposed online learning method, edge devices and center controller learn the interactive policies through local observations and carry out the model-wise communication. We build up a simulation platform for time sensitive MEC systems as a gym environment module and implement the proposed algorithm. Furthermore, the comparisons with a popular MARL solution, MADDPG, show that the proposed approach achieves better performance in terms of data freshness and system stability.},
keywords={Job shop scheduling;Trajectory planning;Conferences;Collaboration;Maintenance engineering;Channel allocation;Stability analysis;MEC collaboration;multi-agent deep reinforcement learning;actor-critic;federated learning},
doi={10.1109/ICCWorkshops50388.2021.9473729},
ISSN={2694-2941},
month={June},}
@INPROCEEDINGS{8453318,
author={Kim, Inwook and Morrison, James R.},
booktitle={2018 International Conference on Unmanned Aircraft Systems (ICUAS)}, title={Learning Based Framework for Joint Task Allocation and System Design in Stochastic Multi-UAV Systems},
year={2018},
volume={},
number={},
pages={324-334},
abstract={We consider a system of UAVs, depots, service stations and tasks in a stochastic environment. Our goal is to jointly determine the system resources (system design), task allocation and waypoint selection. To our knowledge, none have studied this joint decision problem in the stochastic context. We formulate the problem as a Markov decision process (MDP) and resort to deep reinforcement learning (DRL) to obtain state-based decisions. Numerical studies are conducted to assess the performance of the proposed approach. In small examples for which an optimal policy can be found, the DRL based approach is much faster than value iteration and obtained nearly optimal solutions. In large examples, the DRL based approach can find efficient designs and policies.},
keywords={Task analysis;Resource management;Fuels;Stochastic processes;Loading;Robots},
doi={10.1109/ICUAS.2018.8453318},
ISSN={2575-7296},
month={June},}
@INPROCEEDINGS{8397177,
author={Passalis, Nikolaos and Tefas, Anastasios},
booktitle={2018 IEEE Conference on Evolving and Adaptive Intelligent Systems (EAIS)}, title={Deep reinforcement learning for frontal view person shooting using drones},
year={2018},
volume={},
number={},
pages={1-8},
abstract={Unmanned Aerial Vehicles (UAVs), also known as drones, are increasingly used for a wide variety of novel tasks, including drone-based cinematography. However, flying drones in such setting requires the coordination of several people, increasing the cost of using drones for aerial cinematography and limiting the shooting flexibility by putting a significant cognitive load on the director and drone/camera operators. To overcome some of these limitation, this paper proposes a deep reinforcement learning (RL) method for performing autonomous frontal view shooting. To this end, a realistic simulation environment is developed, which ensures that the learned agent can be directly deployed on a drone. Then, a deep RL algorithm, tailored to the needs of the specific application, is derived building upon the well known deep Q-learning approach. The effectiveness of the proposed technique is experimentally demonstrated using several quantitative and qualitative experiments.},
keywords={Drones;Face;Machine learning;Task analysis;Cinematography;Cameras},
doi={10.1109/EAIS.2018.8397177},
ISSN={2473-4691},
month={May},}
@INPROCEEDINGS{9348835,
author={Xu, Wenchao and Zhou, Haibo and Cheng, Nan and Lu, Ning and Xu, Lijuan and Qin, Meng and Guo, Song},
booktitle={2020 IEEE 92nd Vehicular Technology Conference (VTC2020-Fall)}, title={Autonomous Rate Control for Mobile Internet of Things: A Deep Reinforcement Learning Approach},
year={2020},
volume={},
number={},
pages={1-6},
abstract={With the ubiquitous deployment of mobile sensors and smart devices, the scope of Internet of things (IoT) has extended to the space of mobile networks, where IoT terminals are moving around instead of being fixed in buildings, ground infrastructures, etc. In this paper, we consider such mobile Internet of things (MIoT), and propose an autonomous rate control (RC) scheme for the uplink transmission from MIoT terminals to access stations. A deep reinforcement learning (DRL) based approach is designed to capture the channel variations of the link and to improve the effectiveness of the rate selection for each egress frame. Extensive simulations are conducted for MIoT terminals including vehicles and UAVs and show significant throughput performance improvement comparing with traditional methods, as well as the robustness and scalability of the DRL-RC algorithm. The proposed DRL-RC can provide inspirations for efficient and scalable link adaptation schemes for MIoT terminals.},
keywords={Fading channels;Vehicular and wireless technologies;Reinforcement learning;Throughput;Trajectory;Internet of Things;Uplink;Mobile Internet of things;rate control;deep reinforcement learning},
doi={10.1109/VTC2020-Fall49728.2020.9348835},
ISSN={2577-2465},
month={Nov},}
@INPROCEEDINGS{6943039,
author={Montella, Corey and Spletzer, John R.},
booktitle={2014 IEEE/RSJ International Conference on Intelligent Robots and Systems}, title={Reinforcement learning for autonomous dynamic soaring in shear winds},
year={2014},
volume={},
number={},
pages={3423-3428},
abstract={Dynamic soaring (DS) is an aerobatic maneuver whereby a gliding aircraft harnesses energy from horizontal wind that varies in strength and/or direction to support flight. Typical approaches to dynamic soaring in autonomous unmanned aerial vehicles (UAVs) use nonlinear optimizers to generate energy-gaining trajectories, which are then followed using traditional controllers. The effectiveness of such a strategy is limited by both the local optimality of the generated trajectory, as well as controller tracking errors. In this paper, we investigate a reinforcement learning (RL) approach working in continuous space to control a DS aircraft flying in shear wind conditions. The RL controller operates in two stages: In the first stage, it observes a traditional sample-based controller flying a locally optimal DS trajectory generated a priori. In the second stage, the sample-based controller is removed and authority is passed to the RL algorithm. We show that by deviating from the original planned trajectory, the RL controller is able to achieve better performance than its baseline teacher controller.},
keywords={Trajectory;Aircraft;Education;Atmospheric modeling;Aerodynamics;Aerospace electronics;Vectors},
doi={10.1109/IROS.2014.6943039},
ISSN={2153-0866},
month={Sep.},}
@INPROCEEDINGS{9019122,
author={Li, Haochen and Wu, SenTang and Xie, Pengzhi and Qin, Zekui and Zhang, Baochang},
booktitle={2018 IEEE CSAA Guidance, Navigation and Control Conference (CGNCC)}, title={A Path Planning for One UAV Based on Geometric Algorithm},
year={2018},
volume={},
number={},
pages={1-5},
abstract={In this paper, a new learning algorithm named geometric learning algorithm is proposed to solve the UAV's track planning problem. Actually, based on the environment modeling, the optimal path planning problem is to find an optimal route. The Geometric learning algorithm is essentially an reinforcement learning algorithm. It can not only fully use the distance information to calculate the track based on the geometric distance information but can also fuse dangerous information in a complex environment, which solves the problem of track planning from a practical and theoretical point of view. Based on the two-dimensional successful planning of a single drone, the algorithm is extended to the path planning and decision making of single drone three-dimensional planning. And from a practical and theoretical point of view, the path planning problem has been well solved.},
keywords={Planning;Heuristic algorithms;Trajectory;Mathematical model;Real-time systems;Task analysis;path planning;real-time;Geometric learning;Unmanned aerial vehicles},
doi={10.1109/GNCC42960.2018.9019122},
ISSN={},
month={Aug},}
@ARTICLE{8664596,
author={Liu, Chi Harold and Chen, Zheyu and Zhan, Yufeng},
journal={IEEE Journal on Selected Areas in Communications}, title={Energy-Efficient Distributed Mobile Crowd Sensing: A Deep Learning Approach},
year={2019},
volume={37},
number={6},
pages={1262-1276},
abstract={High-quality data collection is crucial for mobile crowd sensing (MCS) with various applications like smart cities and emergency rescues, where various unmanned mobile terminals (MTs), e.g., driverless cars and unmanned aerial vehicles (UAVs), are equipped with different sensors that aid to collect data. However, they are limited with fixed carrying capacity, and thus, MT's energy resource and sensing range are constrained. It is quite challenging to navigate a group of MTs to move around a target area to maximize their total amount of collected data with the limited energy reserve, while geographical fairness among those point-of-interests (PoIs) should also be maximized. It is even more challenging if fully distributed execution is enforced, where no central control is allowed at the backend. To this end, we propose to leverage emerging deep reinforcement learning (DRL) techniques for directing MT's sensing and movement and to present a novel and highly efficient control algorithm, called energy-efficient distributed MCS (Edics). The proposed neural network integrates convolutional neural network (CNN) for feature extraction and then makes decision under the guidance of multi-agent deep deterministic policy gradient (DDPG) method in a fully distributed manner. We also propose two enhancements into Edics with N-step return and prioritized experienced replay buffer. Finally, we evaluate Edics through extensive simulations and found the appropriate set of hyperparameters in terms of number of CNN hidden layers and neural units for all the fully connected layers. Compared with three commonly used baselines, results have shown its benefits.},
keywords={Sensors;Task analysis;Data collection;Autonomous automobiles;Navigation;Reinforcement learning;Smart phones;Mobile crowd sensing;deep reinforcement learning;energy-efficiency;distributed data collection},
doi={10.1109/JSAC.2019.2904353},
ISSN={1558-0008},
month={June},}
@INPROCEEDINGS{9723097,
author={Wang, Xinghan and Fields, Gregory and Javidi, Tara},
booktitle={2021 55th Asilomar Conference on Signals, Systems, and Computers}, title={Contextual Shortest Path with Unknown Context Distributions},
year={2021},
volume={},
number={},
pages={471-476},
abstract={This paper proposes a class of stochastic decision problems, which we call Contextual Shortest Path (CSP) problems. The problem is motivated by dynamic path planning and obstacle avoidance for UAV and drone applications. More specifically, in path planning applications, there is a need to compute the path between two pre-determined locations in space while avoiding various spontaneous obstacles in the environment. In general, finding the optimal path in a stochastic environment with time-varying obstacles generalizes the problem of finding the shortest path over an undirected graph with stochastic edges, where random edge realizations are augmented with richer contexts that can change over time and require online inspection.Under perfect knowledge of context distributions, we provide an extended Dijkstra’s algorithm to solve the associated dynamic program efficiently. When the context distributions are unknown and need to be learned online, we first adapt two algorithms as our baselines, one based on Thompson Sampling and the other based on ϵ-greedy exploration. We then propose a novel reinforcement learning algorithm, RL-CSP, which intelligently distributes exploration episodes over the time horizon and ensures the agent visits under-explored states. We bound the regret for RL-CSP, and augment the theoretical results with simulations over various network topologies. We further demonstrate the improved robustness of our RL-based algorithm in the stochastic shortest path setting.},
keywords={Shortest path problem;Computers;Q-learning;Network topology;Heuristic algorithms;Path planning;Robustness},
doi={10.1109/IEEECONF53345.2021.9723097},
ISSN={2576-2303},
month={Oct},}
@INPROCEEDINGS{8780127,
author={Sacharny, David and Henderson, Thomas C.},
booktitle={2019 IEEE International Conference on Industrial Cyber Physical Systems (ICPS)}, title={Optimal Policies in Complex Large-scale UAS Traffic Management},
year={2019},
volume={},
number={},
pages={352-357},
abstract={There is currently a worldwide effort to develop UAS Traffic Management (UTM) systems that help ensure safe and reliable operation of Unmanned Autonomous Systems (UAS) in urban environments. A large number of factors must be considered in planning such flights, including GIS (roads, topography, etc.), weather (temperature, wind, precipitation), localization and navigation (GPS, V2X communication), infrastructure obstacles (buildings, towers, etc.), excluded zones of operation, etc. We have developed a cloud-based geospatial intelligence system, BRECCIA, which brokers such information among a set of intelligent agents. In this work, an extended version of BRECCIA is proposed as a universal-UTM (U-UTM) which allows the specification of urban airways constrained to be above roadways. In addition, we develop a reinforcement learning approach for the determination of optimal flight policies through such airways, where these policies can take into account a variety of factors (wind, precipitation, communication, etc.) which impact UAV path following capabilities. A novel context-based probabilistic state transition function is introduced. Simulation experiments are performed to demonstrate the performance of the approach.},
keywords={Indexes;Reinforcement learning;Urban areas;Probabilistic logic;Convergence;Global Positioning System;Aerospace electronics;UAS Traffic Management;Reinforcement Learning},
doi={10.1109/ICPHYS.2019.8780127},
ISSN={},
month={May},}
@ARTICLE{8723347,
author={Rohan, Ali and Rabah, Mohammed and Kim, Sung-Ho},
journal={IEEE Access}, title={Convolutional Neural Network-Based Real-Time Object Detection and Tracking for Parrot AR Drone 2},
year={2019},
volume={7},
number={},
pages={69575-69584},
abstract={Recent advancements in the field of Artificial Intelligence (AI) have provided an opportunity to create autonomous devices, robots, and machines characterized particularly with the ability to make decisions and perform tasks without human mediation. One of these devices, Unmanned Aerial Vehicles (UAVs) or drones are widely used to perform tasks like surveillance, search and rescue, object detection and target tracking, parcel delivery (recently started by Amazon), and many more. The sensitivity in performing said tasks demands that drones must be efficient and reliable. For this, in this paper, an approach to detect and track the target object, moving or still, for a drone is presented. The Parrot AR Drone 2 is used for this application. Convolutional Neural Network (CNN) is used for object detection and target tracking. The object detection results show that CNN detects and classifies object with a high level of accuracy (98%). For real-time tracking, the tracking algorithm responds faster than conventionally used approaches, efficiently tracking the detected object without losing it from sight. The calculations based on several iterations exhibit that the efficiency achieved for target tracking is 96.5%.},
keywords={Drones;Object detection;Target tracking;Cameras;Detectors;Training;Convolutional neural networks;Convolutional neural network;deep learning;object detection;target tracking;unmanned aerial vehicles},
doi={10.1109/ACCESS.2019.2919332},
ISSN={2169-3536},
month={},}
@ARTICLE{6421105,
author={Young, Alexander R. and Bostian, Charles W.},
journal={IEEE Microwave Magazine}, title={Simple and low-cost platforms for cognitive radio experiments [Application Notes]},
year={2013},
volume={14},
number={1},
pages={146-157},
abstract={In the decade since it was first proposed, cognitive radio (CR) has become a popular research topic. While most prototypes are based on a cognitive engine (CE) controlling a software defined radio (SDR) subsystem, in this article we present the reader with a somewhat novel CR architecture in which an RF application specific integrated circuit (ASIC) or system on a chip replaces the usual SDR portion of a CR, reducing the radio's cost, computational complexity, and size. While our work was motivated a need to develop an inexpensive CR suitable for deployment in small radio controlled (RC) model-airplane-sized unmanned aerial vehicles (UAVs), we hope the ideas presented here will be useful for engineering educators and CR researchers interested in learning about the RF and artificial intelligence (CE) aspects of CR and studying real radio behavior in live RF environments without designing and building specialized SDRs. We present a simple CR platform called SKIRL for experimentation and educational purposes, with a component cost less than US$240.},
keywords={Radio frequency;Frequency shift keying;Radiofrequency integrated circuits;Computers;Hardware;Software radio;Cognitive radio},
doi={10.1109/MMM.2012.2226543},
ISSN={1557-9581},
month={Jan},}
@INPROCEEDINGS{9255295,
author={Luque Vega, Luis F. and Lopez-Neri, Emmanuel and Arellano-Muro, Carlos A. and González-Jiménez, Luis E. and Ghommam, Jawhar and Carrasco-Navarro, Rocío},
booktitle={IECON 2020 The 46th Annual Conference of the IEEE Industrial Electronics Society}, title={UAV Flight Instructional Design for Industry 4.0 based on the Framework of Educational Mechatronics},
year={2020},
volume={},
number={},
pages={2313-2318},
abstract={The new stage of the industrial revolution, called industry 4.0, involves the use of Internet of Things, Artificial Intelligence, process automation and cyber-physical systems to achieve smart factories; these technologies are part of the Information and Communications Technology (ICT) and are devoted to increase levels of industrial intelligence. Within Industry 4.0, drones appear as intelligent devices that have been changing the rules of the game in the industrial sector, providing benefits with innovative applications. However, the required knowledge, skills and attitudes to manage these technological devices are not being developed in most of the Universities. This paper presents an instructional design for teaching UAV flight dynamics based on the Educational Mechatronics Conceptual Framework (EMCF) with the aim to develop the mechatronic concept. This EMCF includes the macro-process levels: concrete, graphic and abstract, and the processes involved to promote learning construction. Moreover, it takes into account the perspective entities: flight Dynamics (Process), Aerial Robotics (Application) and Drone (Artifact). The designed manual is focused on developing knowledge, skills and attitudes in the new jobs generated in Industry 4.0. We consider it key to disseminate educational mechatronics to help Countries in its transformation to become a relevant actor in the fourth industrial revolution.},
keywords={Drones;Mechatronics;Industries;Education;Software packages;Mathematical model;Tracking;Educational mechatronics;UAV;industry 4.0},
doi={10.1109/IECON43393.2020.9255295},
ISSN={2577-1647},
month={Oct},}
@INPROCEEDINGS{9587290,
author={Chen, Jiangqi and Zhang, Xi and Wang, Bo and Liu, Siyan and Zhao, Ting},
booktitle={2021 IEEE 5th Information Technology,Networking,Electronic and Automation Control Conference (ITNEC)}, title={Edge-cloud Collaborative Electric Power Inspection Image Target Detection Method},
year={2021},
volume={5},
number={},
pages={1389-1393},
abstract={Electric power companies use UAVs, cameras, robots and other equipment for electric power transmission line inspections and image collection. Further, through artificial intelligence image detection technology, the images are processed to identify the defects or hidden dangers. Image detection model services are generally deployed on cloud platform, which is the cloud, or edge computing devices, which is the edge. On the one hand, if all images are processed at the edge nearby, the calculation will take a long time due to the limitation of edge computing capability. On the other hand, if all images are uploaded to the cloud for process, it will still take a long time when the bandwidth is limited. Transferring too much data will lead to inefficiency, and it is unrealistic to upload all data to the cloud. Edge-cloud collaborative electric power inspection image target detection method splits and deploys the image detection model services to the cloud and the edge. They are all involved in calculation, which reduces the amount of data transmitted and improves efficiency.},
keywords={Power transmission lines;Image edge detection;Collaboration;Object detection;Bandwidth;Inspection;Power systems;artificial intelligence;computing capability;bandwidth limited;edge-cloud collaboration;electric power inspection},
doi={10.1109/ITNEC52019.2021.9587290},
ISSN={2693-3128},
month={Oct},}
@INPROCEEDINGS{6726695,
author={Abilash, C. and Lakshminath, B.},
booktitle={2013 Fourth International Conference on Computing, Communications and Networking Technologies (ICCCNT)}, title={Earth Moon Communication incorporated Internet webpage based control for robots},
year={2013},
volume={},
number={},
pages={1-5},
abstract={This paper mainly concentrates on the control of Lunar-bots and is also applicable to other kinds of robots like the one used in warfare, medical surgeries, and even the one that is used for UAV automation using the world wide accessed internet communication with Earth Moon Communication (EMC). This paper discusses the unique way in which we can control the robot deployed in the Moon for space research using EMC (Earth Moon Communication) technique and all other robots located anywhere in the world with the help of a simple webpage loaded with controls. Here a particular webpage is created over the internet whose administrator privileges are restricted to the authority. The robot in which this system is implemented also has access to the webpage, but is read only. The input to the webpage is designed by using simple LabVIEW programs interfacing sophisticated piezoelectric, tactile sensors and other sensor systems to provide gesture, speech, and image inputs. This LabVIEW program is then sourced to an administrative website. The robot is already programmed in such a way that it is able to understand and synchronize with these commands uniquely. The robot which is permanently connected to the internet with the help of wireless modem (3G/4G), can read these commands with ease. This control is extended to the moon by deploying EMC, developed from the existing ancient Moon Bounce technique. This is accomplished by replacing the Moon's rugged reflector surface by a parabolic reflector antenna. Two similar antennas are placed on diametrically opposite zones of Earth in order to maintain the path of sight with the Moon. BPSK (Binary Phase Shift Keying) modulation is employed here. Using this technique we can extend the internet connectivity to the lunar atmosphere. In addition, these robots are also pre-programmed with Artificial Intelligence (AI), in order to survive communication breakdowns. In this mode it acts precisely according to the sustaining environment.},
keywords={Moon;Internet;Earth;Robot sensing systems;Surgery;Electromagnetic compatibility;Moon Bounce Technique;robots;webpage integrated with EMC;BPSK;parabolic antenna;self-control},
doi={10.1109/ICCCNT.2013.6726695},
ISSN={},
month={July},}
@INPROCEEDINGS{9435223,
author={Hassan, Fahad and Usman, M. Rehan and Hamid, Shahzaib and Usman, M. Arslan and Politis, Christos and Satrya, G.B.},
booktitle={2021 IEEE Asia Pacific Conference on Wireless and Mobile (APWiMob)}, title={Solar Powered Autonomous Hex-Copter for Surveillance, Security and Monitoring},
year={2021},
volume={},
number={},
pages={188-194},
abstract={Due to innovation in machine automation and artificial intelligence (AI), surveillance and security paradigms are changing. The unmanned aerial vehicles are designed for surveillance of high importance area, that are either difficult to access or are located in dangerous zones. This paper focuses on design and construction of hex-copter with surveillance capabilities. The designed hex-copter has the ability to fly autonomously and cover the predefined path as well as send the video signals which are to be viewed on the ground base station, i.e., PC and smart phones etc., also the UAV is fully capable of self-controlled flight and solar based self-powering mechanism. For self-control mechanism, our design includes an ArduPilot Mega (APM) Version 2.8 flight controller having an in-built microcontroller with capability of interfacing with GPS and Inertial measurement sensor unit. The auto-flight path is generated with the help of mission planner software. For the surveillance purpose, a camera is attached with the hex-copter that transmits video data wirelessly to the ground station. This system provides an extremely maneuverable and versatile platform for applications like surveillance and aerial photography. It can be used for government agencies, military applications, and disaster relief etc.},
keywords={Wireless communication;Wireless sensor networks;Technological innovation;Surveillance;Cameras;Software;Unmanned aerial vehicles;Autonomous;Mission planner;Surveillance and security;UAV},
doi={10.1109/APWiMob51111.2021.9435223},
ISSN={},
month={April},}
@ARTICLE{9712457,
author={Bera, Basudeb and Wazid, Mohammad and Das, Ashok Kumar and Rodrigues, Joel J. P. C.},
journal={IEEE Internet of Things Magazine}, title={Securing Internet of Drones Networks Using AI-Envisioned Smart-Contract-Based Blockchain},
year={2021},
volume={4},
number={4},
pages={68-73},
abstract={Drones, sometimes called unmanned aerial vehicles (UAVs), can be deployed in a flying Internet of Things (IoT)/Internet of Drones (IoD) environment to execute some specific tasks, like environmental monitoring, disaster management, aerial photography, monitoring and tracking of enemies at borders, and many more. For security reasons, the deployed drones can sense and collect the data from their surroundings, and then securely send the information to the ground station server. The ground station server then provides the collected data to the peer-to-peer cloud server (P2PCS) network after converting them into encrypted transactions in a secure way. Finally, the blocks are created from the encrypted transactions and added into a blockchain by applying consensus algorithms implemented by the P2PCS network. The deployed artificial intelligence (AI)-based big data analytics is required to predict the useful results from the collected and processed data. In this article, we propose a novel AI-envisioned smart-contract-based blockchain-enabled security framework for secure communication in IoD. The provided security analysis proves the security of the proposed framework against different potential attacks. The blockchain implementation of the proposed framework is then executed to identify its impact on the performance of the system.},
keywords={Photography;Disaster management;Blockchains;Peer-to-peer computing;Servers;Internet of Things;Environmental monitoring;Drones},
doi={10.1109/IOTM.001.2100044},
ISSN={2576-3199},
month={December},}
@ARTICLE{9286685,
author={Gupta, Rajesh and Shukla, Arpit and Tanwar, Sudeep},
journal={IEEE Transactions on Network Science and Engineering}, title={BATS: A Blockchain and AI-Empowered Drone-Assisted Telesurgery System Towards 6G},
year={2021},
volume={8},
number={4},
pages={2958-2967},
abstract={Artificial Intelligence (AI) has great potential in diverse real-time mission-critical applications and one such application is telesurgery or robotic surgery. However, some issues like security, throughput, reliability, trust, and transparency are still challenging in an AI-enabled telesurgery system. Motivated from these challenges, in this paper, we propose a blockchain and AI-empowered telesurgery system towards 6G called BATS, which is a self-manageable, secure, transparent, and trustable system with massive Ultra-Reliable Low-Latency Communication (mURLLC). BATS uses AI algorithms such as eXtreme Gradient Boosting (XGBoost) to classify the disease with their criticality score ranging from 0 to 1. Moreover, BATS uses UAVs to transport light-weight healthcare items such as medicines and surgical tools in an emergent situation (during surgical procedures) to avoid road-traffic congestions. Results show that the proposed BATS scheme achieves better prediction accuracy, high throughput when the number of users increases, extremely low packet loss ratio, low storage cost, high mining profit, and low bandwidth consumption by the InterPlanetary File System (IPFS) compared to the traditional HaBiTs and AaYusH schemes.},
keywords={Surgery;Blockchains;6G mobile communication;Artificial intelligence;Hospitals;Unmanned aerial vehicles;Telemedicine;Smart contracts;Medical services;Unmanned aerial vehicles;6G;telesurgery;blockchain;smart contract;healthcare 4.0;artificial intelligence.},
doi={10.1109/TNSE.2020.3043262},
ISSN={2327-4697},
month={Oct},}
@INPROCEEDINGS{8484837,
author={Zhao, Haitao and Wang, Haijun and Zhang, Yichi and Wei, Jibo and Li, Xiang},
booktitle={2018 International Conference on Communications (COMM)}, title={Modelling Smart Mobile Robotic Networks from a Cyber Physical System Perspective},
year={2018},
volume={},
number={},
pages={259-264},
abstract={Mobile robotic network (MRN) consists of a group of robotic nodes (such as mobile sensors, unmanned vehicles, UAVs and mobile robots) that can communicate with each other for collaboration, in which motion control and communication will both play crucial roles. With recent advances in artificial intelligence, robotic nodes are becoming smart with more powerful computational capability. Therefore, there appears a strong trend to integrally design MRNs from these three aspects: motion control, communication and computation. Cyber physical system that bridges the cyber world of communication and computation with the physical world of motion control provides us a new perspective to MRNs. In this research, we analyze the tight integration and coupling of these cyber physical aspects in MRNs, and provide a framework to specify the effect of each aspect and the transitions among them in terms of their contributions to the network performance. We use illustrative examples of flock motion, topology motion and ad hoc networking in MRNs to demonstrate the framework.},
keywords={Mobile robotic networks;cyber physical system;motion control;communication;computation},
doi={10.1109/ICComm.2018.8484837},
ISSN={},
month={June},}
@ARTICLE{9145564,
author={Akyildiz, Ian F. and Kak, Ahan and Nie, Shuai},
journal={IEEE Access}, title={6G and Beyond: The Future of Wireless Communications Systems},
year={2020},
volume={8},
number={},
pages={133995-134030},
abstract={6G and beyond will fulfill the requirements of a fully connected world and provide ubiquitous wireless connectivity for all. Transformative solutions are expected to drive the surge for accommodating a rapidly growing number of intelligent devices and services. Major technological breakthroughs to achieve connectivity goals within 6G include: (i) a network operating at the THz band with much wider spectrum resources, (ii) intelligent communication environments that enable a wireless propagation environment with active signal transmission and reception, (iii) pervasive artificial intelligence, (iv) large-scale network automation, (v) an all-spectrum reconfigurable front-end for dynamic spectrum access, (vi) ambient backscatter communications for energy savings, (vii) the Internet of Space Things enabled by CubeSats and UAVs, and (viii) cell-free massive MIMO communication networks. In this roadmap paper, use cases for these enabling techniques as well as recent advancements on related topics are highlighted, and open problems with possible solutions are discussed, followed by a development timeline outlining the worldwide efforts in the realization of 6G. Going beyond 6G, promising early-stage technologies such as the Internet of NanoThings, the Internet of BioNanoThings, and quantum communications, which are expected to have a far-reaching impact on wireless communications, have also been discussed at length in this paper.},
keywords={6G mobile communication;Wireless communication;5G mobile communication;Automation;Internet;Measurement;Communication system security;6G;wireless communications;terahertz band;intelligent communication environments;pervasive artificial intelligence;network automation;all-spectrum reconfigurable transceivers;ambient backscatter communications;cell-free massive MIMO;Internet of NanoThings;Internet of BioNanoThings;quantum communications},
doi={10.1109/ACCESS.2020.3010896},
ISSN={2169-3536},
month={},}
@INPROCEEDINGS{9081624,
author={Paces, Pavel and Udatny, Vitek},
booktitle={2019 IEEE/AIAA 38th Digital Avionics Systems Conference (DASC)}, title={Comparison of Flight-Planning Algorithms in View of Certification Requirements},
year={2019},
volume={},
number={},
pages={1-8},
abstract={In this paper, a comparison of flight path planning algorithms is presented to solve three-dimensional planning problem for a typical flight path scenario for UAV indoor and outdoor applications with oversight into general aviation and paid transport. The algorithms consider the performance of the navigation sensors and expected departure and arrival procedures which use the existing navigation means (VOR, NDB, ILS, GPS). The cruise situation is simplified to GPS navigation and obstacle avoidance. We choose to analyze the selected algorithms from the point of view of the certification issues according to the existing HW and SW requirements on determinism and time consumption. The analysis is made from the point of view of DO-178 standard. We describe the Artificial Intelligence phenomena and discuss the determinism of the currently used algorithms for flight-path panning. Within our work we focus on and summarize advantages and disadvantages of Breadth First Search, A*, Iterative Deepening A*, Theta*, and RRT* algorithms. Their reasoning process and path selection methodology with perspective of aerospace requirements are evaluated. Our main focus will be on the randomization element and uncertainty of these algorithms. We will also describe selected evaluation parameters required by FAA and EASA Technical Standard Order (TSO) documents on electronic systems and what are the conflicts between these requirements and the natural principle of the existing path-planning algorithms.},
keywords={path;planning;algorithm;certification;DO-178},
doi={10.1109/DASC43569.2019.9081624},
ISSN={2155-7209},
month={Sep.},}
@INPROCEEDINGS{7915449,
author={de Oliveira, Hugo Andrade and Rosa, Paulo Fernando Ferreira},
booktitle={2017 IEEE International Conference on Industrial Technology (ICIT)}, title={Adaptive genetic neuro-fuzzy attitude control for a fixed wing UAV},
year={2017},
volume={},
number={},
pages={726-731},
abstract={The remarkable growth of the different applications for unmanned aerial vehicles (UAVs) are currently of high research interest. This paper proposes a new approach for the attitude control system of a fixed wing aircraft. Using techniques of Artificial Intelligence (AI), this research presents a solution that uses Adaptive Neuro-Fuzzy Inference System (ANFIS) as flight dynamics identifier, and genetic algorithms (GA) as parameter optimization to the attitude control. This approach ensures always the best control system response during a flight, and prevent the user from having to tune the control parameters before every mission.},
keywords={Software;Genetic algorithms;Attitude control;Genetics;Optimization;Hardware;Control systems},
doi={10.1109/ICIT.2017.7915449},
ISSN={},
month={March},}
@INPROCEEDINGS{9476681,
author={Causa, Flavia and Opromolla, Roberto and Fasano, Giancarmine},
booktitle={2021 International Conference on Unmanned Aircraft Systems (ICUAS)}, title={Cooperative navigation and visual tracking with passive ranging for UAV flight in GNSS-challenging environments},
year={2021},
volume={},
number={},
pages={1538-1547},
abstract={This paper discusses an approach conceived to improve navigation performance of small Unmanned Aerial Vehicles (UAVs) in GNSS-challenging environments by exploiting cooperation with other aircraft flying in better GNSS coverage conditions. Cooperation is realized by exchanging navigation data (i.e., GNSS observables when available) and exploiting a monocular camera system for relative vision-based tracking. Cooperative measurements are used within an Extended Kalman Filter, developing a solution potentially ready for real-time applications. The visual algorithm exploits both Deep Learning-based detectors and standard machine vision techniques to provide not only accurate line-of-sight but also distance estimates, and it is designed to deal with targets placed both above and below the horizon. The two algorithmic blocks are integrated in a closed loop fashion since navigation estimates are used in feedback to support visual processing. An experimental flight test campaign is carried out using two quadcopters to assess attainable navigation performance in terms of attitude and positioning. Results compare filter performance when using line-of-sight only with the case of using line-of-sight and ranging measurements altogether. They demonstrate that reliability and integrity of visual algorithms are good enough for the navigation filter needs, and that metric positioning error is achieved within GNSS-challenging areas by using the proposed cooperative strategy. The added value of range estimation strongly depends on the formation geometry and the GNSS coverage conditions.},
keywords={Visualization;Global navigation satellite system;Uncertainty;Target tracking;Measurement uncertainty;Filtering algorithms;Aircraft navigation;Unmanned Aerial Vehicles;cooperative navigation;visual detection and tracking;deep learning;shape-based ranging;GNSS-challenging environments},
doi={10.1109/ICUAS51884.2021.9476681},
ISSN={2575-7296},
month={June},}
@INPROCEEDINGS{8967885,
author={Windrim, Lloyd and Bryson, Mitch},
booktitle={2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)}, title={Forest Tree Detection and Segmentation using High Resolution Airborne LiDAR},
year={2019},
volume={},
number={},
pages={3898-3904},
abstract={This paper presents an autonomous approach to tree detection and segmentation from high resolution airborne LiDAR pointclouds, such as those collected from a UAV, that utilises region-based CNN and 3D-CNN deep learning algorithms. Trees are first detected in 2D before individual trees are further characterised in 3D. If the number of training examples for a site is low, it is shown to be beneficial to transfer a segmentation network learnt from a different site with more training data and fine-tune it. The algorithm was validated using airborne laser scanning over two different commercial pine plantations. The results show that the proposed approach performs favourably in comparison to other methods for tree detection and segmentation.},
keywords={},
doi={10.1109/IROS40897.2019.8967885},
ISSN={2153-0866},
month={Nov},}
@ARTICLE{9015998,
author={Gao, Qian and Shen, Xukun and Niu, Wensheng},
journal={IEEE Access}, title={Large-Scale Synthetic Urban Dataset for Aerial Scene Understanding},
year={2020},
volume={8},
number={},
pages={42131-42140},
abstract={The geometric extraction and semantic understanding in bird's eye view plays an important role in cyber-physical-social systems (CPSS), because it can help human or intelligent agents (IAs) to perceive larger range of environment. Moreover, due to lack of comprehensive dataset from oblique perspective, fog-end deep learning algorithms for this purpose is still in blank. In this paper, we propose a novel method to generate synthetic large-scale dataset for geometric and semantic urban scene understanding from bird's eye view. There are two main steps involved, one is modeling and the other is rendering, which are processed by CityEngine and UnrealEngine4 respectively. In this way, synthetic aligned multi-model data are obtained efficiently, including spectral images, semantic labels, depth and normal maps. Specifically, terrain elevation, street graph, building style and trees distribution are all randomly generated according realistic situation, a few of handcrafted semantic labels annotated by colors spread throughout the scene, virtual cameras moved according to realistic trajectories of unmanned aerial vehicles (UAVs). For evaluation of practicability of our dataset, we manually labeled tens of aerial images downloaded from internet. And the experiment result show that, in both pure and combined mode, the dataset can improve the performance significantly.},
keywords={Buildings;Semantics;Roads;Urban areas;Machine learning;Three-dimensional displays;Rendering (computer graphics);Deep learning;environment understanding;geometric extraction;large-scale urban scene;semantic segmentation;synthetic data set},
doi={10.1109/ACCESS.2020.2976686},
ISSN={2169-3536},
month={},}
@INPROCEEDINGS{8967919,
author={Koumis, Alexander S. and Preiss, James A. and Sukhatme, Gaurav S.},
booktitle={2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)}, title={Estimating Metric Scale Visual Odometry from Videos using 3D Convolutional Networks},
year={2019},
volume={},
number={},
pages={265-272},
abstract={We present an end-to-end deep learning approach for performing metric scale-sensitive regression tasks such visual odometry with a single camera and no additional sensors. We propose a novel 3D convolutional architecture, 3DC-VO, that can leverage temporal relationships over a short moving window of images to estimate linear and angular velocities. The network makes local predictions on stacks of images that can be integrated to form a full trajectory. We apply 3DC-VO to the KITTI visual odometry benchmark and the task of estimating a pilot’s control inputs from a first-person video of a quadrotor flight. Our method exhibits increased accuracy relative to comparable learning-based algorithms trained on monocular images. We also show promising results for quadrotor control input prediction when trained on a new dataset collected with a UAV simulator.},
keywords={Measurement;Training;Three-dimensional displays;Network architecture;Cameras;Prediction algorithms;Trajectory},
doi={10.1109/IROS40897.2019.8967919},
ISSN={2153-0866},
month={Nov},}
@INPROCEEDINGS{8354281,
author={Vidal, Rosaura G. and Banerjee, Sreya and Grm, Klemen and Struc, Vitomir and Scheirer, Walter J.},
booktitle={2018 IEEE Winter Conference on Applications of Computer Vision (WACV)}, title={UG^2: A Video Benchmark for Assessing the Impact of Image Restoration and Enhancement on Automatic Visual Recognition},
year={2018},
volume={},
number={},
pages={1597-1606},
abstract={Advances in image restoration and enhancement techniques have led to discussion about how such algorithms can be applied as a pre-processing step to improve automatic visual recognition. In principle, techniques like deblurring and super-resolution should yield improvements by de-emphasizing noise and increasing signal in an input image. But the historically divergent goals of computational photography and visual recognition communities have created a significant need for more work in this direction. To facilitate new research, we introduce a new benchmark dataset called UG2, which contains three difficult real-world scenarios: uncontrolled videos taken by UAVs and manned gliders, as well as controlled videos taken on the ground. Over 150,000 annotated frames for hundreds of ImageNet classes are available, which are used for baseline experiments that assess the impact of known and unknown image artifacts and other conditions on common deep learning-based object classification approaches. Further, current image restoration and enhancement techniques are evaluated by determining whether or not they improve baseline classification performance. Results show that there is plenty of room for algorithmic innovation, making this dataset a useful tool going forward.},
keywords={Image restoration;Image resolution;Image recognition;Visualization;Object recognition;Benchmark testing;Photography},
doi={10.1109/WACV.2018.00177},
ISSN={},
month={March},}
@INPROCEEDINGS{9359098,
author={Chiu, Wen-Tse and Lin, Cheng-Hsuan and Jhu, Ci-Lin and Lin, Chinsu and Chen, Ying-Cheng and Huang, Mei-Jing and Liu, Wei-Min},
booktitle={2020 International Computer Symposium (ICS)}, title={Semantic Segmentation of Lotus Leaves in UAV Aerial Images via U-Net and DeepLab-based Networks},
year={2020},
volume={},
number={},
pages={535-540},
abstract={In the applications of remote sensing images, separating or segmenting the desired objects from the vast background is usually challenging. For example, calculating the number of single crops on agricultural land and the area of crops occupied per unit field, and quantizing the amount of new leaf buds in a forest area. Even though the targets of interest are visually recognizable, sometimes a large amount of them make an automatic segmentation tool preferable than the manual operation.In this work, the real-world problem we attempt to solve is to segment the lotus leaves from the background including water, field, and other plants. The segmentation result can be used to either monitor the growth rate of lotus or evaluate the severity of pests and diseases according to different color contrast. The look-down color image data were collected through a quadrotor UAV at different altitudes up to 20 meters. The image taken at the lowest altitude was chosen to delineate the groundtruth manually. We adopted two deep learning methods, U-net and DeepLab_v3+, to perform automatic leaves segmentation. The results show that both methods have similar performance but the latter one requires more computation. Then the conditional random fields (CRF) are applied as a post-processing to clean up the fragmented segmentation result.},
keywords={Image segmentation;Target recognition;Semantics;Tools;Agriculture;Remote sensing;Monitoring;Segmentation;Lotus leaves;UAV;U-net;DeepLab;Conditional random field},
doi={10.1109/ICS51289.2020.00110},
ISSN={},
month={Dec},}
@INPROCEEDINGS{8265456,
author={Costea, Dragos and Marcu, Alina and Leordeanu, Marius and Slusanschi, Emil},
booktitle={2017 IEEE International Conference on Computer Vision Workshops (ICCVW)}, title={Creating Roadmaps in Aerial Images with Generative Adversarial Networks and Smoothing-Based Optimization},
year={2017},
volume={},
number={},
pages={2100-2109},
abstract={Recognizing roads and intersections in aerial images is a challenging problem in computer vision with many real world applications, such as localization and navigation for unmanned aerial vehicles (UAVs). The problem is currently gaining momentum in computer vision and is still far from being solved. While recent approaches have greatly improved due to the advances in deep learning, they provide only pixel-level semantic segmentations. In this paper, we argue that roads and intersections should be recognized at the higher semantic level of road graphs - with roads being edges that connect nodes. Towards this goal we present a method consisting of two stages. During the first stage, we detect roads and intersections with a novel, dual-hop generative adversarial network (DH-GAN) that segments images at the level of pixels. At the second stage, given the pixelwise road segmentation, we find its best covering road graph by applying a smoothing-based graph optimization procedure. Our approach is able to outperform recent published methods and baselines on a large dataset with European roads.},
keywords={Roads;Image segmentation;Optimization;Gallium nitride;Image edge detection;Generators},
doi={10.1109/ICCVW.2017.246},
ISSN={2473-9944},
month={Oct},}
@INPROCEEDINGS{8936110,
author={Dahmane, Mohamed and St-Charles, Pierre-Luc and Lalonde, Marc and Heffner, Kevin and Foucher, Samuel},
booktitle={2019 Ninth International Conference on Image Processing Theory, Tools and Applications (IPTA)}, title={Arousal and Valence Estimation for Visual Non-Intrusive Stress Monitoring},
year={2019},
volume={},
number={},
pages={1-6},
abstract={As the capabilities and usefulness of advanced Unmanned Aerial Vehicles (UAVs) increase, communication between the operator and these intelligent systems is becoming a very important factor for mission success. In this context, automatic stress detection is becoming a key research topic in emotion analysis. Stress can be estimated by means of an array of intrusive sensors or via the measurement of some biological markers (e.g. cortisol levels). However, these approaches are not appropriate in many cases of human-machine interactions. In this paper, we propose a deep learning-based psychological stress level estimation approach. The goal is to identify the region where the emotional state of the operator projects in the space defined by the latent dimensional emotions of arousal and valence. The stress region is well defined in this space according to prior works in psychology. The proposed predictive model first extracts and aligns the operator's face, then generates embeddings from a pre-trained face model. These embeddings are then used to train two different architectures, a hierarchical temporal CNN and a LSTM with an Attention Weighted Average layer. Since we deal with naturalistic behavior in a context of operator-machine interaction, the One-Minute Gradual-Emotion Behavior Challenge (OMG) dataset is used for the validation of continuously estimated arousal/valence levels.},
keywords={Stress;Face recognition;Visualization;Monitoring;Psychology;Predictive models;Faces;Continuous emotion analysis;operator stress monitoring;face analysis;deep learning;Unmanned Aerial Vehicles.},
doi={10.1109/IPTA.2019.8936110},
ISSN={2154-512X},
month={Nov},}
@INPROCEEDINGS{8968555,
author={Andrew, William and Greatwood, Colin and Burghardt, Tilo},
booktitle={2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)}, title={Aerial Animal Biometrics: Individual Friesian Cattle Recovery and Visual Identification via an Autonomous UAV with Onboard Deep Inference},
year={2019},
volume={},
number={},
pages={237-243},
abstract={This paper describes a computationally-enhanced M100 UAV platform with an onboard deep learning inference system for integrated computer vision and navigation. The system is able to autonomously find and visually identify by coat pattern individual Holstein Friesian cattle in freely moving herds. We propose an approach that utilises three deep convolutional neural network architectures running live onboard the aircraft: (1) a YOLOv2-based species detector, (2) a dual-stream deep network delivering exploratory agency, and (3) an InceptionV3-based biometric long-term recurrent convolutional network for individual animal identification. We evaluate the performance of each of the components offline, and also online via real-world field tests comprising 147 minutes of autonomous low altitude flight in a farm environment over a dispersed herd of 17 heifer dairy cows. We report error-free identification performance on this online experiment. The presented proof-of-concept system is the first of its kind. It represents a practical step towards autonomous biometric identification of individual animals from the air in open pasture environments for tag-less AI support in farming and ecology.},
keywords={},
doi={10.1109/IROS40897.2019.8968555},
ISSN={2153-0866},
month={Nov},}
@ARTICLE{9351600,
author={Deng, Wenjing and Shi, Qian and Li, Jun},
journal={IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing}, title={Attention-Gate-Based Encoder–Decoder Network for Automatical Building Extraction},
year={2021},
volume={14},
number={},
pages={2611-2620},
abstract={Rapidly developing remote sensing technology provides massive data for urban planning, mapping, and disaster management. As a carrier of human productive activities, buildings are essential to both urban dynamic monitoring and suburban construction inspection. Fully-convolutional-network-based methods have provided a paradigm for automatically extracting buildings from high-resolution imagery. However, high intraclass variance and complexity are two problems in building extraction. It is hard to identify different scales of buildings by using a single receptive field. For this purpose, in this article, we use the stable encoder- decoder architecture, combined with a grid-based attention gate and atrous spatial pyramid pooling module, to capture and restore features progressively and effectively. A modified ResNet50 encoder is also applied to extract features. The proposed method could learn gated features and distinguish buildings from complex surroundings such as trees. We evaluate our model on two building datasets, WHU aerial building dataset and our DB UAV rural building dataset. Experiments show that our model outperforms other five most recent models. The results also exhibit great potential for extracting buildings with different scales and validate the effectiveness of deep learning in practical scenarios.},
keywords={Buildings;Feature extraction;Convolution;Logic gates;Task analysis;Semantics;Decoding;Attention gate (AG);building extraction;deep learning;fully convolutional networks (FCNs);semantic segmentation},
doi={10.1109/JSTARS.2021.3058097},
ISSN={2151-1535},
month={},}
@INPROCEEDINGS{8639127,
author={Acatay, Oliver and Sommer, Lars and Schumann, Arne and Beyerer, Jürgen},
booktitle={2018 15th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS)}, title={Comprehensive Evaluation of Deep Learning based Detection Methods for Vehicle Detection in Aerial Imagery},
year={2018},
volume={},
number={},
pages={1-6},
abstract={Automatic analysis of aerial imagery acquired by satellites, planes and UAVs facilitates several applications such as traffic monitoring, surveillance, search and rescue tasks. These applications have in common the need for an accurate object detection. In recent years, applying Faster R-CNN, a deep learning based detection method, outperformed conventional detection methods for the task of vehicle detection in aerial imagery. For this, adaptations to the characteristics of aerial imagery are necessary. In this paper, we adapt several state-of-the-art detectors including Faster R-CNN, SSD, and YOLOv2 and analyze the detection performance with respect to object categories, ground sampling distances and inference time. Furthermore, we examine the impact of adding more semantic information for each detector separately. For that purpose, we propose an extension of YOLOv2 by adding a deconvolutional module. We achieve state-of-the-art results on the publicly available DOTA dataset.},
keywords={Semantics;Detectors;Feature extraction;Sports;Deep learning;Task analysis;Vehicle detection},
doi={10.1109/AVSS.2018.8639127},
ISSN={},
month={Nov},}
@ARTICLE{9162036,
author={Liu, Yingjie and Yang, Fengbao and Hu, Peng},
journal={IEEE Access}, title={Small-Object Detection in UAV-Captured Images via Multi-Branch Parallel Feature Pyramid Networks},
year={2020},
volume={8},
number={},
pages={145740-145750},
abstract={Small object is one of the primary challenges in the field of object detection, which is notably pronounced to the detection in the images from Unmanned Aerial Vehicles (UAV). Existing detectors based on deep-learning methods usually apply the feature extraction networks with a large down-sampling factor to obtain higher-level features. However, such big stride tends to make the feature information of small objects become the little point or even vanish in the low-resolution feature maps due to the limitation of pixels. Therefore, a novel structure called Multi-branch Parallel Feature Pyramid Networks (MPFPN) is proposed in this article, which aims to extract more abundant feature information of the objects with a small size. Specifically, the parallel branch is designed to recover the features that missed in the deeper layers. Meanwhile, a supervised spatial attention module (SSAM) is applied to weaken the impact of background noise inference and focus object information. Furthermore, we adopt cascade architecture in the Fast R-CNN stage for a more powerful localization capability. Experiments on the public drone-based datasets named VisDrone-DET demonstrate that our method achieves competitive performance compared with other state-of-the-art detection algorithms.},
keywords={Feature extraction;Object detection;Detectors;Proposals;Unmanned aerial vehicles;Noise measurement;Computer architecture;Unmanned aerial vehicle;object detection;multi-branch parallel feature pyramid networks (MPFPN);feature fusion;cascade architecture},
doi={10.1109/ACCESS.2020.3014910},
ISSN={2169-3536},
month={},}
@INPROCEEDINGS{9687268,
author={Ajakwe, Simeon Okechukwu and Ihekoronye, Vivian Ukamaka and Akter, Rubina and Kim, Dong-Seong and Lee, Jae Min},
booktitle={2022 International Conference on Information Networking (ICOIN)}, title={Adaptive Drone Identification and Neutralization Scheme for Real-Time Military Tactical Operations},
year={2022},
volume={},
number={},
pages={380-384},
abstract={The surging proliferation in the deployment of unmanned aerial vehicles (UAVs) in various domains has resulted into unsolicited intrusion into private properties and protected areas thereby posing threat to national security. This paper proposed an adaptive scenario-based approach for detecting drone invasion using enhanced YOLOv5 deep learning model to detect different drones and identify attached objects operating under any environment, size, speed, or shape. The dataset consists of 6 drone models and 8 attached weapons manually generated and preprocessed to form samples. In terms of accuracy, sensitivity, and timeliness, the result shows that our model achieved superior detection precision of 100%, sensitivity of 99.9%, F1-score of 87.2% for weapons identification at a shorter time of 0. 021s than other models. The high detection accuracy undoubtedly makes our model well suited for real-time drone monitoring and countering of illegal drones in military offensives with minimal resource usage.},
keywords={Deep learning;Adaptation models;Sensitivity;Adaptive systems;Computational modeling;Weapons;Autonomous aerial vehicles;Deep Learning;Drone;Military;Surveillance;Detection},
doi={10.1109/ICOIN53446.2022.9687268},
ISSN={1976-7684},
month={Jan},}
@INPROCEEDINGS{9287525,
author={Gérard, Julien and Tomasik, Joanna and Morisseau, Christèle and Rimmel, Arpad and Vieillard, Gilles},
booktitle={2020 28th European Signal Processing Conference (EUSIPCO)}, title={Micro-Doppler Signal Representation for Drone Classification by Deep Learning},
year={2021},
volume={},
number={},
pages={1561-1565},
abstract={There are numerous formats which represent the micro-Doppler signature. Our goal is to determine which one is the most adapted to classify small UAV (Unmanned Aerial Vehicules) with Deep Learning. To achieve this goal, we compare drone classification results with the different micro-Doppler signatures for a given neural network. This comparison has been performed on data obtained during a radar measurement campaign. We evaluate the classification performance in function of different use conditions we identified with a given neural network. According to the experiments conducted, the recommended format is a spectrum issued from long observations as its classification results are better for most criteria.},
keywords={Deep learning;Training;Radar measurements;Neural networks;Signal to noise ratio;Drones;Testing},
doi={10.23919/Eusipco47968.2020.9287525},
ISSN={2076-1465},
month={Jan},}
@INPROCEEDINGS{9722001,
author={Zhang, Xiangzhu and Zhang, Lijia and Xu, Ding and Pei, Hailong},
booktitle={2021 8th International Conference on Information, Cybernetics, and Computational Social Systems (ICCSS)}, title={Multi-Loss Function for Distance-to-collision Estimation},
year={2021},
volume={},
number={},
pages={205-210},
abstract={Estimation of the drone’s distance-to-collision is the key to the indoor autonomous obstacle avoidance and navigation of monocular UAVs. At present, the distance-to-collision model mainly uses regression loss or ordinal regression for training Regression loss utilizes the continuity of distance, and ordinal regression loss utilizes the order of distance. To improve the prediction performance of the model, this paper proposes a multi-loss function trained deep learning model based on the linear combination of ordinal regression loss and regression loss. The regression loss can be obtained by adding a distance decoder after the ordinal regression estimation, without changing the original structure of the model. Finally, we test the model performance in public datasets and obtain good results.},
keywords={Training;Deep learning;Navigation;Estimation;Predictive models;Decoding;Collision avoidance;deep learning;distance-to-collision;multi-loss;ordinal regression loss},
doi={10.1109/ICCSS53909.2021.9722001},
ISSN={2639-4235},
month={Dec},}
@INPROCEEDINGS{8798096,
author={James, Jasmin and Ford, Jason J. and Molloy, Timothy L.},
booktitle={2019 International Conference on Unmanned Aircraft Systems (ICUAS)}, title={Below Horizon Aircraft Detection Using Deep Learning for Vision-Based Sense and Avoid},
year={2019},
volume={},
number={},
pages={965-970},
abstract={The commercial operation of unmanned aerial vehicles (UAVs) would benefit from an onboard capability to sense and avoid (SAA) potential mid-air collision threats in the same manner expected from a human pilot. In this paper we present a new approach for detection of aircraft below the horizon. We address some of the challenges faced by existing vision-based SAA methods such as detecting stationary aircraft (that have no relative motion to the background), rejecting moving ground vehicles, and simultaneous detection of multiple aircraft. We propose a multi-stage vision-based aircraft detection system which utilises deep learning to produce candidate aircraft that we track over time. We evaluate the performance of our proposed system on real flight data where we demonstrate detection ranges comparable to the state of the art with the additional capability of detecting stationary aircraft, rejecting moving ground vehicles, and tracking multiple aircraft.},
keywords={Aircraft;Land vehicles;Image sequences;Training;Cameras;Deep learning;Visualization},
doi={10.1109/ICUAS.2019.8798096},
ISSN={2575-7296},
month={June},}
@INPROCEEDINGS{9500764,
author={Raja, Ashok and Yuan, Jiawei},
booktitle={ICC 2021 - IEEE International Conference on Communications}, title={Detecting Spying Activities from the Sky via Deep Learning},
year={2021},
volume={},
number={},
pages={1-6},
abstract={The increasing prevalence of unmanned aerial vehicles (UAVs), or drones, has raised serious privacy concerns from the general public due to their pervasive reachability and rich sensing capabilities. In recent years, multiple systems have been proposed to enable drone detection for the general public. However, these systems mainly focus on the detection of nearby drones, but are not able to tell whether the drones are performing unauthorized activities or not. In this paper, we propose a novel solution for the detection of spying activities from drones, which can effectively identify if a drone is spying on a specific victim. Our solution is designed with a deep learning-enabled multi-level analysis by exploring the characteristics of drones’ first-personview (FPV) communication channel. Both indoor and outdoor environments are supported in our solution with low-cost off-the-shelf hardware (under $50). A prototype implementation is provided and evaluated under different conditions. Our experimental results demonstrated that our solution is able to achieve high accuracy under different conditions.},
keywords={Deep learning;Privacy;Correlation;Conferences;Prototypes;Communication channels;Hardware},
doi={10.1109/ICC42927.2021.9500764},
ISSN={1938-1883},
month={June},}
@INPROCEEDINGS{8923347,
author={Tsuyama, Masahiko and Aoki, Shuhei and Oki, Takuro and Miyamoto, Ryusuke},
booktitle={2018 International Symposium on Intelligent Signal Processing and Communication Systems (ISPACS)}, title={Hardware Implementation of a Classifier Trained with Informed-Filters Using Only Color Features},
year={2018},
volume={},
number={},
pages={319-324},
abstract={We are constructing a novel sensor networking system for real-time sensing human vital signs during exercise in real time using image-assisted routing. Image-assisted routing requires accurate localization of humans wearing sensor nodes using aerial images captured from cameras mounted on UAVs. To detect humans in aerial images in real time, we propose a hardware implementation of a classifier constructed with informed-filters using only color features that shows a higher accuracy than deep learning for sports scenes. Experimental results showed that the detection accuracy of the classifier did not become worse when we only applied fixed-point operations. The proposed hardware also requires a few computation resources in an FPGA though a large amount of memory was required. The processing time for an image whose size was 2560 ×1352 was about 36ms, demonstrating that our hardware can achieve very fast computation on an FPGA.},
keywords={Image color analysis;Hardware;Feature extraction;Real-time systems;Machine learning;Routing},
doi={10.1109/ISPACS.2018.8923347},
ISSN={2642-3529},
month={Nov},}
@INPROCEEDINGS{8122126,
author={Gibson, David and Campbell, Neill},
booktitle={2017 Conference on Design and Architectures for Signal and Image Processing (DASIP)}, title={Adaptive space-time structural coherence for selective imaging},
year={2017},
volume={},
number={},
pages={1-6},
abstract={In this paper we present a novel close-to-sensor computational camera design. The hardware can be configured for a wide range of autonomous applications such as industrial inspection, binocular/stereo robotic vision, UAV navigation/control and biological vision analogues. Close coupling of the image sensor with computation, motor control and motion sensors enables low latency responses to changes in the visual field. An image processing pipeline that detects and processes regions containing space-time structural coherence, in order to reduce the transmission of redundant pixel data and stabilise selective imaging, is introduced. The pipeline is designed to exploit close-to-sensor processing of regions-of-interest (ROI) adaptively captured at high temporal rates (up to 1000 ROI/s) and at multiple spatial and temporal resolutions. Space-time structurally coherent macro blocks are detected using a novel temporal block matching approach; the high temporal sampling rate allows a monotonicity constraint to be enforced to efficiently assess confidence of matches. The robustness of the sparse motion estimation approach is demonstrated in comparison to a state-of-the-art optical flow algorithm and optimal Baysian grid-based filtering. A description of how the system can generate unsupervised training data for higher level multiple instance or deep learning systems is discussed.},
keywords={Spatial resolution;Image sensors;Motion estimation;Sensors;Visualization;Pipelines;Close-to-sensor processing;low latency processing;feature analysis;sub-pixel tracking},
doi={10.1109/DASIP.2017.8122126},
ISSN={},
month={Sep.},}
@INPROCEEDINGS{9081802,
author={Tian, Yifan and Njilla, Laurent and Raja, Ashok and Yuan, Jiawei and Yu, Shucheng and Steinbacher, Alexander and Tong, Thaniel and Tinsley, Jayson},
booktitle={2019 IEEE/AIAA 38th Digital Avionics Systems Conference (DASC)}, title={Cost-Effective NLOS Detection for Privacy Invasion Attacks by Consumer Drones},
year={2019},
volume={},
number={},
pages={1-7},
abstract={The pervasive operation of customer drones, or small-scale unmanned aerial vehicles (UAVs), has raised serious concerns about their privacy threats to the public. In recent years, privacy invasion events caused by customer drones have been frequently reported. Given such a fact, timely detection of invading drones has become an emerging task. Existing solutions using active radar, video or acoustic sensors are usually too costly (especially for individuals) or exhibit various constraints (e.g., requiring visual line of sight). Recent research on drone detection with passive RF signals provides an opportunity for low-cost deployment of drone detectors on commodity wireless devices. However, the state of the arts in this direction rely on line-of-sight (LOS) RF signals, which makes them only work under very constrained conditions. The support of more common scenarios, i.e., non-line-of-sight (NLOS), is still missing for low-cost solutions. In this paper, we propose a novel detection system for privacy invasion caused by customer drone. Our system is featured with accurate NLOS detection with low-cost hardware (under $50). By exploring and validating the relationship between drone motions and RF signal under the NLOS condition, we find that RF signatures of drones are somewhat “amplified” by multipaths in NLOS. Based on this observation, we design a two-step solution which first classifies received RSS measurements into LOS and NLOS categories; deep learning is then used to extract the signatures and ultimately detect the drones. Our experimental results show that LOS and NLOS signals can be identified at accuracy rates of 98.4% and 96% respectively. Our drone detection rate for NLOS condition is above 97% with a system implemented using Raspberry PI 3 B+.},
keywords={},
doi={10.1109/DASC43569.2019.9081802},
ISSN={2155-7209},
month={Sep.},}
@INPROCEEDINGS{9658653,
author={Distefano, Joseph P. and Manjunatha, Hemanth and Chowdhury, Souma and Dantu, Karthik and Doermann, David and Esfahani, Ehsan T.},
booktitle={2021 IEEE International Conference on Systems, Man, and Cybernetics (SMC)}, title={Using Physiological Information to Classify Task Difficulty in Human-Swarm Interaction},
year={2021},
volume={},
number={},
pages={1198-1203},
abstract={Human-swarm interaction has recently gained attention due to its plethora of new applications in disaster relief, surveillance, rescue, and exploration. However, if the task difficulty increases, the performance of the human operator decreases, thereby decreasing the overall efficacy of the human-swarm team. Thus, it is critical to identify the task difficulty and adaptively allocate the task to the human operator to maintain optimal performance. In this direction, we study the classification of task difficulty in a human-swarm interaction experiment performing a target search mission. The human may control platoons of unmanned aerial vehicles (UAVs) and unmanned ground vehicles (UGVs) to search a partially observable environment during the target search mission. The mission complexity is increased by introducing adversarial teams that humans may only see when the environment is explored. While the human is completing the mission, their brain activity is recorded using an electroencephalogram (EEG), which is used to classify the task difficulty. We have used two different approaches for classification: A feature-based approach using coherence values as input and a deep learning-based approach using raw EEG as input. Both approaches can classify the task difficulty well above the chance. The results showed the importance of the occipital lobe (O1 and O2) coherence feature with the other brain regions. Moreover, we also study individual differences (expert vs. novice) in the classification results. The analysis revealed that the temporal lobe in experts (T4 and T3) is predominant for task difficulty classification compared with novices.},
keywords={Deep learning;Support vector machines;Temporal lobe;Visualization;Coherence;Feature extraction;Electroencephalography},
doi={10.1109/SMC52423.2021.9658653},
ISSN={2577-1655},
month={Oct},}
@INPROCEEDINGS{8883543,
author={Hao, Yanping and Xu, Liangjie and Wang, Xiaohan and Li, Yuanchen and Chen, Guojun},
booktitle={2019 5th International Conference on Transportation Information and Safety (ICTIS)}, title={Aggressive Lane-change Analysis Closing to Intersection Based on UAV Video and Deep Learning},
year={2019},
volume={},
number={},
pages={496-502},
abstract={Lane-change is stressful operation for driver, especially when closing to the complex intersection. Accurate analysis the factor that relate to aggressive lane-change is foundation of any future driving safety research. Tracker was using for analyzing aggressive lane-changing behavior that based on amount of naturalistic on-road experiment using an UAV. Over two thousand lane-change video pieces have been recorded, then the selected features are extracted in to matrix. Also, the anonymous drivers and vehicle information is obtained according to license plates. Based on an advanced DBN deep learning algorithm, a relation model of lane-change behavior is constructed by considering the potential influence factors, including vehicle information, driver information, and the driving behavior. Finally, the accuracy of proposed model is validated by comparing to other common models, which approves our model's superior accuracy, feasibility and concreteness.},
keywords={Vehicles;Safety;Hidden Markov models;Training;Acceleration;Deep learning;aggressive lane-change;minimum safety distance;Deep Belief Network;Lasso},
doi={10.1109/ICTIS.2019.8883543},
ISSN={},
month={July},}
@INPROCEEDINGS{8577143,
author={Demange, V. and Nicolaou, J. and Delhaye, F. and Robert, E. and Budin, J.},
booktitle={2018 DGON Inertial Sensors and Systems (ISS)}, title={Visual lnertial Hybridization Technique based on Beacons identified by Deep Learning},
year={2018},
volume={},
number={},
pages={1-23},
abstract={Safran has been working for several years on autonomy of vehicles. Whether it is airborne with the UAV Patroller, or on the ground with the military vehicle eRider and with the civilian autonomous car in cooperation with Valeo. This paper focuses on the use of visual information to improve the localization of the car, more precisely, it presents, from a theoretical point of view, the hybridization of the inertial sensors measurement with the line of sight of known position visual beacons: road signs detected on the camera image thanks to deep learning. This fusion algorithm has been implemented in a prototype version of Safran's well know Epsilon 10 navigator and simulation results as well as first real-time results are presented.},
keywords={},
doi={10.1109/InertialSensors.2018.8577143},
ISSN={2377-3480},
month={Sep.},}
@INPROCEEDINGS{9150631,
author={Koksal, Aybora and Ince, Kutalmis Gokalp and Aydin Alatan, A.},
booktitle={2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)}, title={Effect of Annotation Errors on Drone Detection with YOLOv3},
year={2020},
volume={},
number={},
pages={4439-4447},
abstract={Following the recent advances in deep networks, object detection and tracking algorithms with deep learning backbones have been improved significantly; however, this rapid development resulted in the necessity of large amounts of annotated labels. Even if the details of such semi-automatic annotation processes for most of these datasets are not known precisely, especially for the video annotations, some automated labeling processes are usually employed. Unfortunately, such approaches might result with erroneous annotations. In this work, different types of annotation errors for object detection problem are simulated and the performance of a popular state-of-the-art object detector, YOLOv3, with erroneous annotations during training and testing stages is examined. Moreover, some inevitable annotation errors in Anti-UAV Challenge dataset is also examined in this manner, while proposing a solution to correct such annotation errors of this valuable data set.},
keywords={Detectors;Training;Feature extraction;Labeling;Real-time systems;Measurement;Drones},
doi={10.1109/CVPRW50498.2020.00523},
ISSN={2160-7516},
month={June},}
@ARTICLE{9519668,
author={Haroun, Fathi Mahdi Elsiddig and Deros, Siti Noratiqah Mohamad and Din, Norashidah Md},
journal={IEEE Access}, title={Detection and Monitoring of Power Line Corridor From Satellite Imagery Using RetinaNet and K-Mean Clustering},
year={2021},
volume={9},
number={},
pages={116720-116730},
abstract={Monitoring of electrical transmission towers (TTs) is required to maintain the integrity of power lines. One major challenge is monitoring vegetation encroachment that can cause power interruption. Most of the current monitoring techniques use unmanned aerial vehicles (UAV) and airborne photography as an observation medium. However, these methods are expensive and not practical for monitoring wide areas. In this paper, we introduced a new method for monitoring the power line corridor from satellite imagery. The proposed method consists of two stages. In the first stage, we used the existing state-of-the-art RetinaNet deep learning (DL) model to detect the locations of the TTs from satellite imagery. A routing algorithm has been developed to create a path between every adjacent detected TT. In addition to the routing algorithm, a corridor identification algorithm has been established for extracting the power line corridor area. In the second stage, the k-mean clustering algorithm has been used to highlight the VE regions within the power line corridor area after converting the target satellite image into hue, saturation, and value (HSV) color space. The proposed monitoring system was able to detect TTs from satellite imagery with a mean average precision (mAP) of 72.45% for an Intersection of Union (IoU) threshold of 0.5 and 85.21% for IoU threshold of 0.3. Also, the monitoring system was able to successfully discriminate high- and low-density vegetation regions within the power line corridor area.},
keywords={Satellites;Monitoring;Vegetation mapping;Training;Classification algorithms;Power transmission lines;Clustering algorithms;Deep learning;K-mean;satellite images;transmission tower detection},
doi={10.1109/ACCESS.2021.3106550},
ISSN={2169-3536},
month={},}
@INPROCEEDINGS{9150737,
author={Wang, Zixuan and Zhao, Zhicheng and Su, Fei},
booktitle={2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)}, title={Real-time Tracking with Stabilized Frame},
year={2020},
volume={},
number={},
pages={4431-4438},
abstract={Deep learning methods have dramatically increased tracking accuracy benefitting from exquisite features extractor. Among these methods, siamese-based tracker performs well. However, in case of camera shaking, the objects are easily to be lost because of no consideration of camera judder, and the position of each pixel changes drastically between frames. In particular, the tracking performance would degrade dramatically in case that the target is small and moving fast, such as UAV tracking. In this paper, the S-Siam framework is proposed to deal with this problem and improves the performance of real-time tracking. Through stabilizing each frame by estimating where the object is going to move, the camera is adjusted adaptively to keep the object in its original position. Experimental results on the VOT2018 dataset show that the proposed method obtained an EAO score 0.449, and achieved 10% robustness improvement compared with existing three trackers, i.e., SiamFC, SiamMask and SiamRPN++, which demonstrates the effectiveness of the proposed algorithm.},
keywords={Target tracking;Cameras;Real-time systems;Robustness;Object tracking;Streaming media},
doi={10.1109/CVPRW50498.2020.00522},
ISSN={2160-7516},
month={June},}
@INPROCEEDINGS{9605371,
author={Charles, Camargo P. and Kim, Pedro Henrique Corrêa and de Almeida, Aline Gabriel and Do Nascimentok, Eduardo Vieira and Da Rocha, Lidia Gianne Souza and Vivaldini, Kelen Cristiane Teixeira},
booktitle={2021 Latin American Robotics Symposium (LARS), 2021 Brazilian Symposium on Robotics (SBR), and 2021 Workshop on Robotics in Education (WRE)}, title={Detection of invasive vegetation through UAV and Deep Learning},
year={2021},
volume={},
number={},
pages={114-119},
abstract={Species originating from one biome are often irregularly introduced into other biomes by accident. This event configures a biological invasion, which can cause irreversible adverse impacts on biodiversity and affect economic productivity in sectors such as fisheries, forestry, and agriculture. Furthermore, many species are vectors of human diseases, making biological invasions a significant problem. In Brazil, monitoring becomes very complex, with many closed forests, such as the mountain regions and other places with difficult accessibility, and demands many resources to maintain it, whether human or financial. Remotely and autonomously detecting invasive vegetation in large or complicated physical access areas can positively impact conservation work. Governments can take concrete actions to favor the environment through this monitoring and avoid irreversible damage to the ecosystem. Therefore, this paper proposes the classification of images using Deep Learning algorithms to detect the invasive species Hedychium Coronarium. We will capture the photos by remote sensing through UAVs (Unmanned Aerial Vehicles).},
keywords={Deep learning;Productivity;Neural networks;Government;Vegetation mapping;Forestry;Unmanned aerial vehicles;Unmanned Aerial Vehicles;Deep Learning;Artificial Neural Networks (ANNs);U-Net},
doi={10.1109/LARS/SBR/WRE54079.2021.9605371},
ISSN={2643-685X},
month={Oct},}
@INPROCEEDINGS{9096949,
author={Andrew, William and Greatwood, Colin and Burghardt, Tilo},
booktitle={2020 IEEE Winter Applications of Computer Vision Workshops (WACVW)}, title={Fusing Animal Biometrics with Autonomous Robotics: Drone-based Search and Individual ID of Friesian Cattle (Extended Abstract)},
year={2020},
volume={},
number={},
pages={38-43},
abstract={This work covers the robotic drone integration of a re-identification system for Friesian Cattle. We have built a computationally-enhanced M100 UAV platform with an on-board deep learning inference system for integrated computer vision and navigation able to autonomously find and visually identify by coat pattern individual Holstein Friesian cattle in freely moving herds. For autonomous drone-based identification we describe an approach that utilises three deep convolutional neural network architectures running live onboard the aircraft; that is, a YoloV2-based species detector, a dual-stream Convolutional Neural Network (CNN) delivering exploratory agency and an InceptionV3-based biometric Long-term Recurrent Convoluational Network (LRCN) for individual animal identification. We evaluate the performance of components offline, and also online via real-world field tests of autonomous low-altitude flight in a farm environment. The presented proof-of-concept system is a successful step towards autonomous biometric identification of individual animals from the air in open pasture environments and inside farms for tag-less AI support in farming and ecology. The work is published in full in IROS 2019 [4].},
keywords={Cows;Navigation;Task analysis;Training;Biometrics (access control);Cameras},
doi={10.1109/WACVW50321.2020.9096949},
ISSN={},
month={March},}
@INPROCEEDINGS{8451504,
author={Chou, Yi-Min and Chen, Chien-Hung and Liu, Keng-Hao and Chen, Chu-Song},
booktitle={2018 25th IEEE International Conference on Image Processing (ICIP)}, title={Changing Background to Foreground: An Augmentation Method Based on Conditional Generative Network for Stingray Detection},
year={2018},
volume={},
number={},
pages={2740-2744},
abstract={Image processing has been a popular tool for biological researches. Detecting specific animals in aerial images captured by an UAV is a crucial research topic. As the rapid progress of deep learning (DL), it has been a popular approach to many image classification and object detection tasks. However, DL usually requires a large set of training samples to learn the network weights, while the biological image materials are often insufficient to fulfill the demand. To improve the detection of stingrays in aerial images, this paper presents a new training sample augmentation method called Mixed Bg-Fg Synthesis. We extend a generative network, Generative Latent Optimization (GLO) to its conditional version, namely, Conditional GLO (C-GLO), which can increase stingray samples on the background and thus improve the training efficacy of a CNN detector. Unlike traditional data augmentation methods that generate new data only for image classification, our proposed method that mixes foreground and background together can generate new data for an object detection task. Experimental results show that the C-GLO augmented stingray samples is helpful to enhance the detection capability.},
keywords={Training;Gallium nitride;Object detection;Sea surface;Generators;Detectors;Task analysis;Object detection;aerial image;deep learning;generative model;generative latent optimization},
doi={10.1109/ICIP.2018.8451504},
ISSN={2381-8549},
month={Oct},}
@ARTICLE{8962227,
author={Teixeira, Lucas and Oswald, Martin R. and Pollefeys, Marc and Chli, Margarita},
journal={IEEE Robotics and Automation Letters}, title={Aerial Single-View Depth Completion With Image-Guided Uncertainty Estimation},
year={2020},
volume={5},
number={2},
pages={1055-1062},
abstract={On the pursuit of autonomous flying robots, the scientific community has been developing onboard real-time algorithms for localisation, mapping and planning. Despite recent progress, the available solutions still lack accuracy and robustness in many aspects. While mapping for autonomous cars had a substantive boost using deep-learning techniques to enhance LIDAR measurements using image-based depth completion, the large viewpoint variations experienced by aerial vehicles are still posing major challenges for learning-based mapping approaches. In this letter, we propose a depth completion and uncertainty estimation approach that better handles the challenges of aerial platforms, such as large viewpoint and depth variations, and limited computing resources. The core of our method is a novel compact network that performs both depth completion and confidence estimation using an image-guided approach. Real-time performance onboard a GPU suitable for small flying robots is achieved by sharing deep features between both tasks. Experiments demonstrate that our network outperforms the state-of-the-art in depth completion and uncertainty estimation for single-view methods on mobile GPUs. We further present a new photorealistic aerial depth completion dataset that exhibits more challenging depth completion scenarios than the established indoor and car driving datasets. The dataset includes an open-source, visual-inertial UAV simulator for photo-realistic data generation. Our results show that our network trained on this dataset can be directly deployed on real-world outdoor aerial public datasets without fine-tuning or style transfer.},
keywords={Estimation;Simultaneous localization and mapping;Uncertainty;Three-dimensional displays;Task analysis;Training;Aerial systems: perception and autonomy;deep learning in robotics and automation},
doi={10.1109/LRA.2020.2967296},
ISSN={2377-3766},
month={April},}
@ARTICLE{8976241,
author={Wang, Wuwei and Zhang, Ke and Lv, Meibo and Wang, Jingyu},
journal={IEEE Transactions on Cybernetics}, title={Hierarchical Spatiotemporal Context-Aware Correlation Filters for Visual Tracking},
year={2021},
volume={51},
number={12},
pages={6066-6079},
abstract={Discriminative correlation filters (DCF)-based trackers have been increasingly applied to visual tracking due to their high precision while running at high frame rates. However, most recent DCF-based methods solely concentrate on learning the correlation filter with spatial information and thus do not have sufficient descriptive power to discriminate the target from the background in the complex circumstances, such as full occlusion (OCC) and rapid target variation. In this article, we introduce a novel tracking framework that exploits the relationship between the target and its spatiotemporal context to improve tracking accuracy and robustness. Especially, we present our spatiotemporal context model in a hierarchical way, where each layer of the context pyramid is a spatial correlation filter learned from different temporal instances. For gaining an accurate spatiotemporal model, we propose an optimization fusion approach that can adaptively and efficiently learn the effect of each hierarchical layer and exploit these multiple temporal levels of correlation filters for visual tracking. Moreover, an adaptive model update strategy for correlation filters is introduced into the framework to dynamically select proper hierarchical layers, which boosts the temporal diversity of the target appearance, while radically reduces the number of model parameters and guarantees the real-time performance of the tracking method. The experimental results show that, with conventional handcrafted features, our tracker achieves the best success rates among available state-of-the-art trackers with handcrafted features, and provides state-of-the-art performance comparable to those of deep-learning-based trackers on OTB-2013, OTB-2015, VOT-2016, and UAV-20L benchmarks but runs significantly faster than deep trackers.},
keywords={Target tracking;Visualization;Spatiotemporal phenomena;Adaptation models;Training data;Discriminative correlation filter (DCF);hierarchical spatiotemporal context (HSTC);online model update;visual tracking},
doi={10.1109/TCYB.2020.2964757},
ISSN={2168-2275},
month={Dec},}
@INPROCEEDINGS{8658300,
author={Benjdira, Bilel and Khursheed, Taha and Koubaa, Anis and Ammar, Adel and Ouni, Kais},
booktitle={2019 1st International Conference on Unmanned Vehicle Systems-Oman (UVS)}, title={Car Detection using Unmanned Aerial Vehicles: Comparison between Faster R-CNN and YOLOv3},
year={2019},
volume={},
number={},
pages={1-6},
abstract={Unmanned Aerial Vehicles are increasingly being used in surveillance and traffic monitoring thanks to their high mobility and ability to cover areas at different altitudes and locations. One of the major challenges is to use aerial images to accurately detect cars and count-them in real-time for traffic monitoring purposes. Several deep learning techniques were recently proposed based on convolution neural network (CNN) for real-time classification and recognition in computer vision. However, their performance depends on the scenarios where they are used. In this paper, we investigate the performance of two state-of-the art CNN algorithms, namely Faster R-CNN and YOLOv3, in the context of car detection from aerial images. We trained and tested these two models on a large car dataset taken from UAVs. We demonstrated in this paper that YOLOv3 outperforms Faster R-CNN in sensitivity and processing time, although they are comparable in the precision metric.},
keywords={Automobiles;Feature extraction;Object detection;Computer architecture;Real-time systems;Surveillance;Proposals;Car detection;convolutional neural networks;You Only Look Once;Faster R-CNN;unmanned aerial vehicles;object detection and recognition},
doi={10.1109/UVS.2019.8658300},
ISSN={},
month={Feb},}
@INPROCEEDINGS{9435549,
author={Fichtel, Lars and Frühwald, Alexander M. and Hösch, Leonhard and Schreibmann, Vitaliy and Bachmeir, Christian and Bohlander, Frank},
booktitle={2021 29th Conference of Open Innovations Association (FRUCT)}, title={Tree Localization and Monitoring on Autonomous Drones employing Deep Learning},
year={2021},
volume={},
number={},
pages={132-140},
abstract={Forest management relies on the analysis of satellite imagery and time intensive physical on-site inspections. Both methods are costly and time consuming. Satellite based images are often not updated in a sufficient frequency to react to infestations or other occurring problems. Forest management benefits greatly from accurate and recent information about the local forest areas. In order to react appropriately and in time to incidents such as areas damaged by storms, areas infested by bark beetles and decaying ground water level, this information can be extracted from high resolution imagery. In this work, we propose UAVs to meet this demand and demonstrate that they are fully capable of gathering this information in a cost efficient way. Our work focuses on the cartography of trees to optimize forest-operation. We apply deep learning for image processing as a method to identify and isolate individual trees for GPS tagging and add some additional information such as height and diameter.},
keywords={Deep learning;Technological innovation;Satellites;Three-dimensional displays;Vegetation;Forestry;Tagging},
doi={10.23919/FRUCT52173.2021.9435549},
ISSN={2305-7254},
month={May},}
@INPROCEEDINGS{8278309,
author={Li, Jiankun and Ding, Wenrui and Li, Hongguang and Liu, Chunlei},
booktitle={2017 IEEE International Conference on Unmanned Systems (ICUS)}, title={Semantic segmentation for high-resolution aerial imagery using multi-skip network and Markov random fields},
year={2017},
volume={},
number={},
pages={12-17},
abstract={Semantic segmentation for aerial imagery is a significant work for remote sensing applications especially for unmanned aerial vehicles (UAVs). In recent years, with the success of deep learning methods, convolutional neural network (CNN) based model plays an important role in both image classification and segmentation. However, due to the presence of small objects in the imagery and imbalance of classes distribution, the pixel-wise semantic segmentation remains a challenge for high-resolution remote sensing imagery. In this paper, a novel CNN based semantic segmentation method is proposed to solve the mentioned problem. To provide more context information for the decoding stage, multi-scale skip connections are designed to feed the pooling layers output from encoding stage to the decoding part. Inception modules are also used to replace the convolutional layers providing multi-scale reception areas. Finally, to enhance the result visually, we re-correct the result basing on prediction confidence in post processing procedure, and then a Markov random fields model is built to refine the label map using simulated annealing algorithm. Experiments on Vaihingen dataset show accuracy improvement on overall performance and car class segmentations.},
keywords={Vegetation;Automobiles;Indexes;Markov random fields;Simulated annealing;Buildings;semantic segmentation;convolutional neural network;Markov random fields;remote sensing;unmanned aerial vehicles},
doi={10.1109/ICUS.2017.8278309},
ISSN={},
month={Oct},}
@INPROCEEDINGS{8866322,
author={Wang, Hao and Yang, Guodong and Li, En and Tian, Yunong and Zhao, Meng and Liang, Zize},
booktitle={2019 Chinese Control Conference (CCC)}, title={High-Voltage Power Transmission Tower Detection Based on Faster R-CNN and YOLO-V3},
year={2019},
volume={},
number={},
pages={8750-8755},
abstract={The power transmission mainly depends on overhead transmission infrastructures, such as towers and lines. Automatic inspection by robots or UAVs for the power transmission infrastructures is an essential way to ensure the safety of power transmission. Automatic detection and classification of the power towers is the prerequisite for automatic inspection. This paper compares two state-of-art deep learning methods to realize the high-voltage power transmission tower detection. We build the dedicated dataset of the power towers for multi-object detection, including data collection, preprocessing and annotation. After that, the models of YOLO-v3 and Faster R-CNN are used to solve multi-object detection on our dataset. The performances of the two models are evaluated under different indicators. It is verified that Faster R-CNN has a better detection performance in accuracy. However, the detection speed of YOLO-V3 model is faster and can be used in real-time detection.},
keywords={Poles and towers;Inspection;Feature extraction;Object detection;Training;Proposals;object detection;images acquisition;power tower detection;Faster R-CNN;YOLO-V3},
doi={10.23919/ChiCC.2019.8866322},
ISSN={1934-1768},
month={July},}
@INPROCEEDINGS{9115112,
author={Zhao, Dequn and Li, Xinmeng},
booktitle={2020 Asia-Pacific Conference on Image Processing, Electronics and Computers (IPEC)}, title={Ocean ship detection and recognition algorithm based on aerial image},
year={2020},
volume={},
number={},
pages={218-222},
abstract={Because the image of UAV aerial photography is easy to be affected by light, sea area and other conditions, there are many kinds of ships. Under different conditions, the characteristics of ships are different, which makes the target recognition more difficult. In order to improve the efficiency of sea surface supervision and make the sea surface management more intelligent, an ocean ship detection algorithm based on aerial photography image is proposed. In this paper, the improved Yolo algorithm is mainly used for high-efficiency ship detection of aerial video, which can achieve real-time performance and detection speed of 23fps. In order to improve the accuracy, this paper proposes a standardized mechanism of fixed frame length detection results, which uses deep learning mask RCNN algorithm for fine detection of specific frame images, and the detection map is 85%, which improves the detection speed without affecting the detection speed The accuracy of the algorithm forms an efficient and accurate algorithm for the detection of ships on the sea, which brings convenience to the management of the sea.},
keywords={Photography;Deep learning;Sea surface;Visualization;Image recognition;Target recognition;Streaming media;Yolo algorithm;Mask-RCNN;Ocean vessel;object detection},
doi={10.1109/IPEC49694.2020.9115112},
ISSN={},
month={April},}
@INPROCEEDINGS{9647507,
author={Sunduijav, Chinzorig and Hardt, Wolfram and Bayasgalan, Zagdkhorol},
booktitle={2021 XV International Scientific-Technical Conference on Actual Problems Of Electronic Instrument Engineering (APEIE)}, title={Image Processing of Insulator and Vibration Damper by YOLO Algorithm},
year={2021},
volume={},
number={},
pages={375-379},
abstract={Image processing is widely used in many fields, including electronics, computer science, energy, construction, medicine, and self-driving cars. Deep learning based object detection methods have also evolved to detect in real-time. Depending on the nature of the object or image to be processed, the performance of image processing methods will vary from application to application. Therefore, researchers test different types of algorithms in each case and compare performance results. The study aims to detect and report selected objects, such as insulators and vibration dampers. This video was recorded by using an UAV in a power transmission line. The research aims to identify the insulator from the input data processed by image processing, create an image database, and then report the visible physical damages. This study summarizes the results of a study in which video insulators and vibration dampers were detected using the DL youonly look once algorithm.},
keywords={Vibrations;Training;Power transmission lines;Image processing;Object detection;Detectors;Insulators;deep learning;yolov4;object detection;insulator;vibration damper},
doi={10.1109/APEIE52976.2021.9647507},
ISSN={2473-8573},
month={Nov},}
@INPROCEEDINGS{9483044,
author={Chen, Zhu and Liang, Xiao and Zheng, Minghui},
booktitle={2021 American Control Conference (ACC)}, title={Deep Iterative Learning Control for Quadrotor's Trajectory Tracking},
year={2021},
volume={},
number={},
pages={1408-1413},
abstract={Iterative learning control (ILC) is an effective control technique to enhance system performance. ILC requires the system to execute identical operations repetitively such that the system performance can be improved by learning from previous iterations. To remove the requirement of repetitive operation, this paper leverages recent advances in deep learning and proposes a new ILC scheme, named Deep ILC, with detailed formulation, analysis, and validation. The proposed Deep ILC consists of two main components, the long short-term memory (LSTM) neural network based prediction and the optimization based learning filter design. In particular, we formulate the learning filter design problem into an optimization problem by purposely constructing an augmented dynamic feedback system, of which the to-be-designed learning filter is in the feedback loop. The proposed Deep ILC is applied to the trajectory tracking of quadrotor unmanned aerial vehicles (UAVs) and its effectiveness is validated through experimental studies.},
keywords={Deep learning;Trajectory tracking;System performance;Neural networks;Unmanned aerial vehicles;Stability analysis;Trajectory},
doi={10.23919/ACC50511.2021.9483044},
ISSN={2378-5861},
month={May},}
@INPROCEEDINGS{9342131,
author={Paul, Joseph K. and Yuvaraj, Tankala and Gundepudi, Karthikay},
booktitle={2020 IEEE 17th India Council International Conference (INDICON)}, title={Demonstrating Low-Cost Unmanned Aerial Vehicle for anti-Poaching},
year={2020},
volume={},
number={},
pages={1-7},
abstract={With the ceaseless threat to the animals in the forest, poaching has made them vulnerable. The increased demand in boasting of pride in holding animal assets has crossed the limit, which made poachers, money-\\making entities in the black market. Continuous monitoring by the park rangers would be a tedious task and may not even be done properly at times too. Accompanying to the current world technological advancements in the Internet of Things and Deep Learning; Object detection has become an effortless job. The goal of our research is to achieve a feasible perspective on anti-\\poaching. The result of our solution gives the best suitable approach towards reducing the poaching of animals by using Unmanned Aerial Vehicles. These UAVs are the future aerial robots and are capable of performing multiple tasks in numerous fields. Advanced technical tools like Raspberry Pi, Computer Vision, and Encryption can tackle world-class problems to some extent.},
keywords={Animals;Object detection;Tools;Unmanned aerial vehicles;Encryption;Task analysis;Monitoring;(UAV) Unmanned Aerial Vehicle;Computer Vision;Raspberry Pi;YOLOv4;AES (Advanced Encryption Standard);ArduPilot-Mission Planner;Encryption},
doi={10.1109/INDICON49873.2020.9342131},
ISSN={2325-9418},
month={Dec},}
@INPROCEEDINGS{8015012,
author={Wu, Di and Zou, Wenbin and Li, Xia and Zhao, Yong},
booktitle={2017 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)}, title={Kernalised Multi-resolution Convnet for Visual Tracking},
year={2017},
volume={},
number={},
pages={2241-2248},
abstract={Visual tracking is intrinsically a temporal problem. Discriminative Correlation Filters (DCF) have demonstrated excellent performance for high-speed generic visual object tracking. Built upon their seminal work, there has been a plethora of recent improvements relying on convolutional neural network (CNN) pretrained on ImageNet as a feature extractor for visual tracking. However, most of their works relying on ad hoc analysis to design the weights for different layers either using boosting or hedging techniques as an ensemble tracker. In this paper, we go beyond the conventional DCF framework and propose a Kernalised Multi-resolution Convnet (KMC) formulation that utilises hierarchical response maps to directly output the target movement. When directly deployed the learnt network to predict the unseen challenging UAV tracking dataset without any weight adjustment, the proposed model consistently achieves excellent tracking performance. Moreover, the transfered multireslution CNN renders it possible to be integrated into the RNN temporal learning framework, therefore opening the door on the end-to-end temporal deep learning (TDL) for visual tracking.},
keywords={Feature extraction;Target tracking;Visualization;Correlation;Kernel;Training;Object tracking},
doi={10.1109/CVPRW.2017.278},
ISSN={2160-7516},
month={July},}
@INPROCEEDINGS{7926512,
author={Lee, Jangwon and Wang, Jingya and Crandall, David and Šabanović, Selma and Fox, Geoffrey},
booktitle={2017 First IEEE International Conference on Robotic Computing (IRC)}, title={Real-Time, Cloud-Based Object Detection for Unmanned Aerial Vehicles},
year={2017},
volume={},
number={},
pages={36-43},
abstract={Real-time object detection is crucial for many applications of Unmanned Aerial Vehicles (UAVs) such as reconnaissance and surveillance, search-and-rescue, and infrastructure inspection. In the last few years, Convolutional Neural Networks (CNNs) have emerged as a powerful class of models for recognizing image content, and are widely considered in the computer vision community to be the de facto standard approach for most problems. However, object detection based on CNNs is extremely computationally demanding, typically requiring high-end Graphics Processing Units (GPUs) that require too much power and weight, especially for a lightweight and low-cost drone. In this paper, we propose moving the computation to an off-board computing cloud, while keeping low-level object detection and short-term navigation onboard. We apply Faster Regions with CNNs (R-CNNs), a state-of-the-art algorithm, to detect not one or two but hundreds of object types in near real-time.},
keywords={Object detection;Drones;Cloud computing;Cameras;Robots;Real-time systems;Estimation;Robot Vision;Object Detection;Unmanned Aerial Systems;Convolutional Neural Networks},
doi={10.1109/IRC.2017.77},
ISSN={},
month={April},}
@INPROCEEDINGS{5929115,
author={Jung, Sunghun and Ariyur, Kartik B.},
booktitle={2011 IEEE International Systems Conference}, title={Robustness for large scale UAV autonomous operations},
year={2011},
volume={},
number={},
pages={309-314},
abstract={Unmanned aerial vehicles (UAVs) need multiple operators as of today. Because of limitations of human attention and sensory cueing the operators cannot use all of the data coming in through these sensors. Large scale autonomy would mean the following: fewer operators, larger areas of coverage, and more vehicles. Rigorous optimization of decision theory based approaches to handling this problem suffer from speed limits to real-time computations. Soft-computing methods based on heuristics (AI, reasoning, neural networks and fuzzy logic) are able to handle certain circumstances but cannot supply any guarantees of performance in unstructured environments. We provide solutions based on rigorous approaches, but avoid heavy real-time computation through off line processing. For mapped regions, we convert maps into traversability graphs using trapezoidal map/voronoi type algorithms. We then find the shortest permissible paths for different vehicles using Dijkstra's algorithm and then preening the allowable paths using constraints on individual vehicles. Out third step consists in determining the minimum time taken by a given vehicle over those paths. We insert margins of safety at each level of this hierarchy: buffer zones (size of buffer zone is a ten meters extended polygon around each building) around mapped structures to account for map errors; buffer zones around flight paths to account for position uncertainty of vehicles; performing 1-D optimal control within limits of the vehicles performance so that vehicles can slow down or speed up in response to unexpected events.},
keywords={Buildings;Vehicles;Genetic algorithms;Traveling salesman problems;Computational modeling;Arrays;Real time systems;Unmanned Aerial Vehicle (UAV);Unmanned Ground Vehicle (UGV);Multiple Traveling Salesman Problem (mTSP);Traveling Salesman Problem (TSP);Genetic Algorithm (GA);Dijkstra},
doi={10.1109/SYSCON.2011.5929115},
ISSN={},
month={April},}
@INPROCEEDINGS{7244733,
author={Pedro, Jimoh O. and Crouse, Andrew J.},
booktitle={2015 10th Asian Control Conference (ASCC)}, title={Direct adaptive neural control of a quadrotor unmanned aerial vehicle},
year={2015},
volume={},
number={},
pages={1-6},
abstract={This paper presents the design of a direct adaptive neural network (DANN)-based feedback linearization (FBL) controller for a multi-input multi output, unstable, nonlinear and underactuated quadrotor UAV. A full system identification was performed on the quadrotor using radial basis function neural networks (RBFNN). The DANN controller was benchmarked against a conventional PD controller which was tuned using Ziegler-Nichols tuning method. The designed controller was found to be capable of accurately tracking the desired output variables simultaneously (altitude, roll, pitch, and yaw angles respectively) and also was robust to parameter variations and disturbance input.},
keywords={Mathematical model;Rotors;PD control;Angular velocity;Propellers;Radial basis function networks},
doi={10.1109/ASCC.2015.7244733},
ISSN={},
month={May},}
@INPROCEEDINGS{8798039,
author={Verberne, Johannes and Moncayo, Hever},
booktitle={2019 International Conference on Unmanned Aircraft Systems (ICUAS)}, title={Robust Control Architecture for Wind Rejection in Quadrotors},
year={2019},
volume={},
number={},
pages={152-161},
abstract={Current efforts at the Advanced Dynamics and Control Laboratory (ADCL) at Embry-Riddle Aeronautical University (ERAU) are focusing on the implementation of robust control laws for disturbance rejection in quadrotors. This paper describes the development of two types of control architectures in an effort to reject or minimize wind effects in quadrotor UAVs. The design of a novel extension of the classic Non-Linear Dynamic Inversion (NLDI) control architecture for wind disturbance rejection is presented. This is followed by the application of adaptive artificial neural networks (ANN) to augment the classic NLDI control law designed to correct inversion errors caused by wind disturbance. Models are presented along with a simulation environment for various wind generated forces and moments. Monte Carlo numerical simulations are performed to analyze the performance of the classic NLDI, extended NLDI and NLDI with ANN augmentation under wind conditions. Results show that the NLDI with ANN augmentation outperforms the classic and extended NLDI controllers.},
keywords={Drag;Vehicle dynamics;Artificial neural networks;Blades;Propellers;Force;Wind},
doi={10.1109/ICUAS.2019.8798039},
ISSN={2575-7296},
month={June},}
@INPROCEEDINGS{8706004,
author={Han, Heejae and Kim, Jeonghwan and Park, Junyoung and Lee, YuJin and Jo, Hyunwoo and Park, Yonghyeon and Matson, Eric T. and Park, Seongha},
booktitle={2019 IEEE Sensors Applications Symposium (SAS)}, title={Object classification on raw radar data using convolutional neural networks},
year={2019},
volume={},
number={},
pages={1-6},
abstract={This paper evaluates the classification of objects given their signal data via a simple convolutional neural network (CNN). Many of the signal processing neural networks involve sound frequency data or Doppler signatures that contain the characteristic features of each object. In this study, we use frequency-intensity data within range-time domain from a Frequency-Modulated Continuous-Wave (FMCW) radar to classify detected objects. The application of various data augmentation methods mitigated the scarcity of labeled data from our field experiments. Time stretching, frequency shifting and noise addition preserved the semantic information of each rangetime data, further improving the models ability to generalize. Modifications applied to our data, which is then converted into a low-level log-scaled mel-spectrogram representation, are learned by CNN models with a set of convolutional and max-pooling layers along with fully-connected layers and selective residual module. Based on our experiments, we conclude that raw radar data can be used for training CNNs for classification and thus can be used to classify a car, a human, and an UAV.},
keywords={Feature extraction;Radar;Time-frequency analysis;Data models;Convolutional neural networks;Convolution;object classification;radar system;data augmentation;convolutional neural networks},
doi={10.1109/SAS.2019.8706004},
ISSN={},
month={March},}
@INPROCEEDINGS{7587103,
author={Zhong, Hang and Li, Shushuai and Wang, Yaonan and Liu, Hongjian},
booktitle={2016 12th IEEE/ASME International Conference on Mechatronic and Embedded Systems and Applications (MESA)}, title={Adaptive robust RBFNNs-based model estimator for a small quadrotor aircraft robot},
year={2016},
volume={},
number={},
pages={1-6},
abstract={This paper presents an on-line estimator that incorporates adaptive MIMO radical basis function neural networks (RBFNNs) for model identification of quadrotor unmanned aerial vehicles (UAVs). The inputs and outputs of quadrotor aircrafts can be obtained from dynamic models or real attitude and position sensors. The adaptive learning rate is employed in the gradient descent method for the update of the weights of RBFNNs, and Lyapunov approach guarantees the stability of the global convergence of the modeling errors. The Welsch functions are also employed as the error functions to get rid of the influence from the noise due to disturbances like wind gusts. Simulation results using Robotics Toolbox for Matlab verify the effectiveness and robustness of the proposed estimator compared with results of traditional RBFNNs. Experiment results from real aircraft platform show that RBFNNs combining adaptive learning rate and Welsch error functions can approximate the overall system with high accuracy and robustness to disturbances.},
keywords={Atmospheric modeling;Aircraft;Mathematical model;Adaptation models;Robustness;Robots;MIMO;Quadrotor;model estimator;RBFNNs;adaptive learning rate;Welsch functions},
doi={10.1109/MESA.2016.7587103},
ISSN={},
month={Aug},}
@INPROCEEDINGS{9616354,
author={Souidene Mseddi, Wided and Sedrine, Mohamed Ali and Attia, Rabah},
booktitle={2021 29th European Signal Processing Conference (EUSIPCO)}, title={YOLOv5 Based Visual Localization For Autonomous Vehicles},
year={2021},
volume={},
number={},
pages={746-750},
abstract={In this paper, we use the advances brought by neural networks for the implementation of a vision based localization framework for autonomous vehicles namely UAVs. We base our work on monocular visual odometry. It is used for incremental localization of autonomous vehicles. This method suffers from drift. Loop closure detection is a way to improve its accuracy. Thus, we introduce a Siamese network able to perform binary classification in order to detect the visited places and the loop closures. This gives us an accurate, light and fast vision based localization framework.},
keywords={Location awareness;Adaptation models;Visualization;Protocols;Neural networks;Signal processing;Real-time systems;Autonomous vehicle;Visual odometry;Loop closure;Neural networks;YOLOv5;Deep Learning},
doi={10.23919/EUSIPCO54536.2021.9616354},
ISSN={2076-1465},
month={Aug},}
@INPROCEEDINGS{8741718,
author={Levasseur, Baptiste and Bertrand, Sylvain and Raballand, Nicolas and Viguier, Flavien and Goussu, Grégoire},
booktitle={2019 IEEE Aerospace Conference}, title={Accurate Ground Impact Footprints and Probabilistic Maps for Risk Analysis of UAV Missions},
year={2019},
volume={},
number={},
pages={1-10},
abstract={This paper addresses the generation of accurate ground impact footprints and probabilistic maps for fixed-wing UAVs. Monte Carlo simulations are performed using a 6DOF dynamic model of aircraft accounting for wind conditions and different types of uncertainties. Use of generated probabilistic maps for risk analysis is shown along an example of real flight trajectory. To also address possible online use of ground impact footprints, surrogate models (kriging and neural networks) are developed to reduce computation time. Real flight data are used for model and application purposes.},
keywords={Computational modeling;Trajectory;Aerodynamics;Uncertainty;Probabilistic logic;Engines;Atmospheric modeling},
doi={10.1109/AERO.2019.8741718},
ISSN={1095-323X},
month={March},}
@INPROCEEDINGS{9025370,
author={Akhauri, Yash},
booktitle={2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)}, title={HadaNets: Flexible Quantization Strategies for Neural Networks},
year={2019},
volume={},
number={},
pages={526-534},
abstract={On-board processing elements on UAVs are currently inadequate for training and inference of Deep Neural Networks. This is largely due to the energy consumption of memory accesses in such a network. HadaNets introduce a flexible train-from-scratch tensor quantization scheme by pairing a full precision tensor to a binary tensor in the form of a Hadamard product. Unlike wider reduced precision neural network models, we preserve the train-time parameter count, thus out-performing XNOR-Nets without a train-time memory penalty. Such training routines could see great utility in semi-supervised online learning tasks. Our method also offers advantages in model compression, as we reduce the model size of ResNet-18 by 7.43× with respect to a full precision model without utilizing any other compression techniques. We also demonstrate a 'Hadamard Binary Matrix Multiply' kernel, which delivers a 10-fold increase in performance over full precision matrix multiplication with a similarly optimized kernel.},
keywords={Tensile stress;Neural networks;Kernel;Quantization (signal);Training;Random access memory;Computer architecture},
doi={10.1109/CVPRW.2019.00078},
ISSN={2160-7516},
month={June},}
@ARTICLE{9369397,
author={Najla, Mehyar and Becvar, Zdenek and Mach, Pavel and Gesbert, David},
journal={IEEE Wireless Communications Letters}, title={Positioning and Association Rules for Transparent Flying Relay Stations},
year={2021},
volume={10},
number={6},
pages={1276-1280},
abstract={Transparent flying relay stations (FlyRSs), represented by transparent relays mounted on unmanned aerial vehicles (UAVs), have the potential to improve cellular network's capacity and coverage at little extra complexity and energy cost, especially when compared with non-transparent relays. As the transparent relays do not transmit reference signals, they do not lend themselves easily to channel estimation. This makes solving the problems of user association and positioning of transparent FlyRSs much harder. We propose a solution enabling an efficient association of users to the FlyRSs and determining suitable positions of the FlyRSs. Surprisingly, this can be done knowing neither the qualities of the channels linking the FlyRSs and the users nor the users' location information. Our approach involves the users being grouped into clusters based on the channels to nearby static base stations via agglomerative hierarchical clustering. Then, 3D positions of one FlyRS per cluster are determined by deep neural networks. The proposal improves the users' sum capacity with respect to existing solutions that rely on the knowledge of users' positions.},
keywords={Relays;Channel estimation;Gain;Buildings;Neural networks;Urban areas;Unmanned aerial vehicles;Transparent relays;unmanned aerial vehicles;agglomerative hierarchical clustering;deep neural networks},
doi={10.1109/LWC.2021.3063909},
ISSN={2162-2345},
month={June},}
@INPROCEEDINGS{9642199,
author={Shang, Erzhen and Gao, Yang and Li, Yang and Yu, Bo and Sun, Jiasen and Jia, Yilin and Zhong, Cheng and Zhu, Guoqiang and Zhang, Xiuyu},
booktitle={2021 11th International Conference on Intelligent Control and Information Processing (ICICIP)}, title={Event-Triggered Based Adaptive Dynamic Surface Control for a Class of Quadrotor UAVs},
year={2021},
volume={},
number={},
pages={398-403},
abstract={A hybrid adaptive control scheme for quadrotor control system based on event-triggered mechanism is proposed for the trajectory tracking control problem of quadrotor UAV. The high-gain state observer is constructed to estimate the unmeasurable states, then the adaptive radial basis function neural networks (RBFNNs) dynamic surface control strategy is designed to achieve precise tracking control. The event-triggered mechanism is introduced, which is effective reduces the update frequency of the system control signal. The simulation results show that the proposed control scheme can achieve more accurate tracking performance than the traditional backstepping sliding mode control (BSMC) scheme without sacrificing the tracking performance of the control system.},
keywords={Backstepping;Trajectory tracking;Heuristic algorithms;Simulation;Radial basis function networks;Observers;Trajectory;Quadrotor UAVs;Output-feedback;Dynamic surface control;Event-triggered control},
doi={10.1109/ICICIP53388.2021.9642199},
ISSN={},
month={Dec},}
@INPROCEEDINGS{9647121,
author={Javed, Muhammad Gohar and Raza, Minahil and Ghaffar, Muhammad Mohsin and Weis, Christian and Wehn, Norbert and Shahzad, Muhammad and Shafait, Faisal},
booktitle={2021 Digital Image Computing: Techniques and Applications (DICTA)}, title={QuantYOLO: A High-Throughput and Power-Efficient Object Detection Network for Resource and Power Constrained UAVs},
year={2021},
volume={},
number={},
pages={01-08},
abstract={Convolutional Neural Networks (CNNs) are producing state-of-the-art results in the object detection field. However, deep topologies of CNN are computationally intensive and typically require excessive resources (i.e. high-end GPUs), which hinder their deployment on resource and power constrained UAVs. In this work, we present a high-throughput and power efficient quantized object detection network, QuantYOLO, which is based on the Tiny-YOLOv2 topology. We conduct a detailed exploration of precision and filter pruning vs. accuracy, throughput and power consumption trade-off for the object detection task. As a result of these explorations, we select a network with binarized weights and 4-bit activations (except the output layer), which is 21.8× smaller than the Tiny-YOLOv2 achieving a mean Average Precision (mAP) of 51.5% on the PASCAL-VOC dataset. Finally, we present an FPGA based accelerator, which achieves 1.6× higher throughput (FPS) and is 3.1× more power efficient as compared to prior FPGA architectures.},
keywords={Quantization (signal);Power demand;Network topology;Object detection;Computer architecture;Throughput;Topology;Quantized Convolutional Neural Networks;Object Detection;Pruning;Depthwise Separable Convolutions;Real-Time and Power-Efficient Architecture},
doi={10.1109/DICTA52665.2021.9647121},
ISSN={},
month={Nov},}
@INPROCEEDINGS{9696375,
author={Gaul, Nathan J. and Leishman, Robert C.},
booktitle={NAECON 2021 - IEEE National Aerospace and Electronics Conference}, title={Artificial Dataset Generation for Automated Aircraft Visual Inspection},
year={2021},
volume={},
number={},
pages={302-306},
abstract={Aircraft visual inspection is both essential to the maintenance of an aircraft, and expensive and time-consuming to perform. Augmenting trained maintenance professionals with automated UAVs to collect and analyze images for aircraft inspection is an active research topic and a potential application of convolutional neural networks (CNNs). Training datasets for niche research topics such as aircraft visual inspection are small and challenging to produce, and the manual labeling process of these datasets produces subjective annotations. Self-driving car researchers have experimented with generating artificial datasets with modern computer graphics that can train for real-world driving scenarios. Our research borrows this idea and proposes a work-in-progress artificial data generation pipeline to create 3D rendered automatically annotated images for training CNNs for automated visual aircraft inspection.},
keywords={Training;Visualization;Three-dimensional displays;Pipelines;Manuals;Aerospace electronics;Inspection;aircraft inspection;neural network;artificial dataset generation},
doi={10.1109/NAECON49338.2021.9696375},
ISSN={2379-2027},
month={Aug},}
@ARTICLE{9523765,
author={Teganya, Yves and Romero, Daniel},
journal={IEEE Transactions on Wireless Communications}, title={Deep Completion Autoencoders for Radio Map Estimation},
year={2022},
volume={21},
number={3},
pages={1710-1724},
abstract={Radio maps provide metrics such as power spectral density for every location in a geographic area and find numerous applications such as UAV communications, interference control, spectrum management, resource allocation, and network planning to name a few. Radio maps are constructed from measurements collected by spectrum sensors distributed across space. Since radio maps are complicated functions of the spatial coordinates due to the nature of electromagnetic wave propagation, model-free approaches are strongly motivated. Nevertheless, all existing schemes for radio occupancy map estimation rely on interpolation algorithms unable to learn from experience. In contrast, this paper proposes a novel approach in which the spatial structure of propagation phenomena such as shadowing is learned beforehand from a data set with measurements in other environments. Relative to existing schemes, a significantly smaller number of measurements is therefore required to estimate a map with a prescribed accuracy. As an additional novelty, this is also the first work to estimate radio occupancy maps using deep neural networks. Specifically, a fully convolutional deep completion autoencoder architecture is developed to effectively exploit the manifold structure of this class of maps.},
keywords={Estimation;Wireless communication;Radio transmitters;Tensors;Sensors;Deep learning;Shadow mapping;Radio maps;spectrum cartography;deep learning;completion autoencoders;electromagnetic wave propagation},
doi={10.1109/TWC.2021.3106154},
ISSN={1558-2248},
month={March},}
@INPROCEEDINGS{8784782,
author={Hartawan, Dean Rizki and Purboyo, Tito Waluyo and Setianingsih, Casi},
booktitle={2019 IEEE International Conference on Industry 4.0, Artificial Intelligence, and Communications Technology (IAICT)}, title={Disaster Victims Detection System Using Convolutional Neural Network (CNN) Method},
year={2019},
volume={},
number={},
pages={105-111},
abstract={Natural disasters are one of the things that cannot be predicted. Natural disasters can cause losses, both assets and objects can even take lives. To reduce the number of losses, rapid evacuation handling from the Search and Rescue (SAR) team is needed to help victims of natural disasters. But in fact, there are often obstacles in the evacuation process. Such obstacles are such as bad weather conditions, disconnection of telecommunications networks, difficulty access to the victims of natural disasters and the spread of SAR teams that are not evenly distributed throughout the disaster area. Convolutional Neural Network is one of the developments of Artificial Neural Networks for image classification, image segmentation, and object recognition with high accuracy and high performance. CNN can learn to detect various images according to images from the dataset studied. So, this paper designed a system for detecting victims of natural disasters using the CNN method and implemented it on a raspberry pi which can detect victims of natural disasters through streaming cameras placed on UAVs. In this paper, the Convolutional Neural Network (CNN) method with 100% accuracy with distance object 1-4 m uses the Mobile-net SSD model.},
keywords={Convolutional neural networks;Feature extraction;Convolution;Unmanned aerial vehicles;Artificial intelligence;Object detection;Cameras;Object Detection;Convolutional Neural Network (CNN);Disaster Victim Detection},
doi={10.1109/ICIAICT.2019.8784782},
ISSN={},
month={July},}
@ARTICLE{8869893,
author={Zhuang, Junfei and Dong, Yuan and Bai, Hongliang and Zuo, Peiliang and Cheng, Jianming},
journal={IEEE Access}, title={Auto-Selecting Receptive Field Network for Visual Tracking},
year={2019},
volume={7},
number={},
pages={157449-157458},
abstract={Recently, Convolutional Neural Networks (CNNs) have shown tremendous potential in the visual tracking community. It is well-known that the receptive field is a critical factor for CNN affecting performance. However, standard CNNs based tracking methods design the receptive fields of artificial neurons in each layer that have the same size. We identify the main bottleneck of affecting the tracking accuracy as regular receptive fields. To settle the problem, we propose an Auto-Selecting Receptive Field Network (ASRF) to select receptive field information and effective clues dynamically. In particular, a Selective Receptive Field Block (SRFB) is designed to adaptively adjust receptive field size for each neuron according to multiple scales of input information. Additionally, we develop a Multi-Scale Receptive Field module (MSRF) that marks a further step in selecting effective clues from different scale receptive fields. The proposed ASRF method performs favorably against state-of-the-art trackers on five benchmarks, including OTB-2013, OTB-2015, UAV-123, VOT-2015, and VOT-2017 while running beyond real-time tracking speed.},
keywords={Target tracking;Visualization;Convolution;Task analysis;Neurons;Benchmark testing;Computational modeling;Visual tracking;deep learning;Siamese network;receptive field},
doi={10.1109/ACCESS.2019.2947472},
ISSN={2169-3536},
month={},}
@INPROCEEDINGS{8936030,
author={McDonnell, Mark D. and Mostafa, Hesham and Wang, Runchun and Schaik, Andrévan},
booktitle={2019 4th Asia-Pacific Conference on Intelligent Robot Systems (ACIRS)}, title={Single-Bit-per-Weight Deep Convolutional Neural Networks without Batch-Normalization Layers for Embedded Systems},
year={2019},
volume={},
number={},
pages={197-204},
abstract={Batch-normalization (BN) layers are thought to be an integrally important layer type in today's state-of-the-art deep convolutional neural networks for computer vision tasks such as classification and detection. However, BN layers introduce complexity and computational overheads that are highly undesirable for training and/or inference on low-power custom hardware implementations of real-time embedded vision systems such as UAVs, robots and Internet of Things (IoT) devices. They are also problematic when batch sizes need to be very small during training, and innovations such as residual connections introduced more recently than BN layers could potentially have lessened their impact. In this paper we aim to quantify the benefits BN layers offer in image classification networks, in comparison with alternative choices. In particular, we study networks that use shifted-ReLU layers instead of BN layers. We found, following experiments with wide residual networks applied to the ImageNet, CIFAR 10 and CIFAR 100 image classification datasets, that BN layers do not consistently offer a significant advantage. We found that the accuracy margin offered by BN layers depends on the data set, the network size, and the bit-depth of weights. We conclude that in situations where BN layers are undesirable due to speed, memory or complexity costs, that using shifted-ReLU layers instead should be considered; we found they can offer advantages in all these areas, and often do not impose a significant accuracy cost.},
keywords={Training;Neurons;Convolutional neural networks;Australia;Complexity theory;Hardware;deep convolutional neural network;batch normalization;low-bit-depth;1-bit-per-weight},
doi={10.1109/ACIRS.2019.8936030},
ISSN={},
month={July},}
@INPROCEEDINGS{9073885,
author={Plastiras, George and Siddiqui, Shahid and Kyrkou, Christos and Theocharides, Theocharis},
booktitle={2020 2nd IEEE International Conference on Artificial Intelligence Circuits and Systems (AICAS)}, title={Efficient Embedded Deep Neural-Network-based Object Detection Via Joint Quantization and Tiling},
year={2020},
volume={},
number={},
pages={6-10},
abstract={Embedded visual AI is a growing trend in applications requiring low latency, real-time decision support, increased robustness and security. Visual object detection, a key task in visual data analytics, has enjoyed significant improvements in terms of capabilities and accuracy due to the emergence of Convolutional Neural Networks (CNNs). However, such complex paradigms require heavy computational resources that prevent their deployment on resource-constrained devices, and in particular, impose significant constraints in possible hardware accelerators geared towards such applications. In this work therefore, we investigate how a combination of techniques can lead to efficient visual AI pipelines for resource-constrained object detection. In particular we leverage an efficient search strategy based on a combination of pre-processing mechanisms, that reduce the processing demands of deep network as a counter measure for potential accuracy reduction caused by quantization. The proposed approach enables the detection of objects in higher resolution frames using quantized models, while maintaining the accuracy of full-precision CNN-based object detectors. We illustrate the impact on the accuracy and average processing time using quantization techniques and different tiling approaches on efficient object detection architectures; as a case study, we focus on Unmanned-Aerial- Vehicles (UAVs). Through the proposed methodology, hardware accelerator demands are thereby reduced, leading to both performance benefits and associated power savings.},
keywords={Quantization (signal);Detectors;Object detection;Visualization;Image resolution;Real-time systems;Pipelines},
doi={10.1109/AICAS48895.2020.9073885},
ISSN={},
month={Aug},}
@INPROCEEDINGS{8665167,
author={Dike, Happiness Ugochi and Wu, Qingtian and Zhou, Yimin and Liang, Gong},
booktitle={2018 IEEE International Conference on Robotics and Biomimetics (ROBIO)}, title={Unmanned Aerial Vehicle (UAV) Based Running Person Detection from a Real-Time Moving Camera},
year={2018},
volume={},
number={},
pages={2273-2278},
abstract={The information captured by Unmanned Aerial Vehicles (UAVs) are highly exploited to detect a running person which is given in this paper. In this scheme, 11 frame per seconds and an adequate detection precision in outdoor background was realized, using one dispensation thread without resorting to distinct hardware. The high precision and realtime detection were made promising by two aids. First, we used a progression of preprocessing procedures to extract the regions of interest (ROI), this includes spatial domain analysis, calculating the optical flow in every two consecutive images and having a predefined threshold built on optical flow to select actual areas as ROIs. Secondly, we also used relatively minor-batch models to train our 5-layer convolutional neural networks (CNN) in order to realize an adequate detection ratio. The experiments from numerous videos shot in diverse time and locations proved that the proposed scheme can detect running person in outdoors efficiently and enhance the Realtime necessity with a very high detection ratio.},
keywords={Cameras;Real-time systems;Unmanned aerial vehicles;Optical computing;Optical imaging;Convolutional neural networks;Biomedical optical imaging;Running detection;moving camera;optical flow;real-time detection},
doi={10.1109/ROBIO.2018.8665167},
ISSN={},
month={Dec},}
@INPROCEEDINGS{8667172,
author={Abbas, Ghulam and Nawaz, Menaa and Kamran, Farrukh},
booktitle={2019 16th International Bhurban Conference on Applied Sciences and Technology (IBCAST)}, title={Performance Comparison of NARX amp; RNN-LSTM Neural Networks for LiFePO4 Battery State of Charge Estimation},
year={2019},
volume={},
number={},
pages={463-468},
abstract={The purpose of this research is to evaluate the performance of NARX network and an improved RNN with LSTM artificial neural networks to estimate the SOC of LiFePO4 batteries used in EVs, HEVs, UAVs, UUVs and energy storage systems for power electronics and solar power systems. Due to unequal self-discharge rates, difference in current leakage and temperature under repeated charge discharge cycles of the battery pack, made by series and parallel combinations of different cells to increase the power rating for different applications, the SOC of each battery cell mismatched with respect to others. Therefore, an accurate estimation of SOC is required for optimal power use of Li-Ion battery pack. In this research two neural network models for SOC estimation of LiFePO4 batteries are designed and their performance is evaluated on different parameters. These models are trained by optimal selection of hyper parameters using real time data of voltage, current and battery pack temperature as input and SOC as output of the models. The input dataset has been preprocessed as multivariate time series forecasting problem for RNN-LSTM neural network. The tested results showed that accurate results with an RMSE lower than 0.001 is achieved in NARX and lower than 0.002 is achieved in RNN-LSTM at different test datasets. However, RNN-LSTM has better performance than NARX in multivariate time series in seq2seq future forecasting configuration with an RMSE lower than 0.003 at different test datasets with a temperature range of 5 to 25°C.},
keywords={State of charge;Batteries;Estimation;Delays;Training;Neurons;Data models;Nonlinear Autoregressive with Exogenous input;Recurrent Neural Network;Long Short Time Memory;State of charge},
doi={10.1109/IBCAST.2019.8667172},
ISSN={2151-1411},
month={Jan},}
@ARTICLE{9233348,
author={Wang, Xiangtong and Li, Wei and Yang, Menglong and Cheng, Peng and Liang, Binbin},
journal={IEEE Access}, title={Unsupervised Monocular Training Method for Depth Estimation Using Statistical Masks},
year={2020},
volume={8},
number={},
pages={191530-191541},
abstract={Recently, unsupervised monocular training methods based on convolutional neural networks have already shown surprisingly progress in improving the accuracy of depth estimation. However, the performance of these methods suffers deeply from problematic pixels such as occluded pixels, low-texture pixels, and so on. In this paper, we introduce a method to a mask by the statistic of error maps for segmenting the problematic pixels. Different from the conventional methods which use additional segmentation networks to classify problematic pixels, we use a multi-task learning architecture to generate identical mask, mean mask, and variance mask for filtering the problematic pixels. Experimental results show that our proposed method has satisfactory performance compared with other relative methods on the KITTI dataset. Moreover, we also apply our method to the UAV dataset VisDrone, and the results also indicate the effectiveness of the method in detecting moving objects.},
keywords={Training;Estimation;Cameras;Adaptive optics;Optical imaging;Optical filters;Three-dimensional displays;Monocular depth estimation;error map;problematic pixels;statistical masks},
doi={10.1109/ACCESS.2020.3032582},
ISSN={2169-3536},
month={},}
@INPROCEEDINGS{9213845,
author={Zhu, Jing and Zhang, Peng and Jiang, Bin},
booktitle={2020 International Conference on Unmanned Aircraft Systems (ICUAS)}, title={Online ADP based Oxygen Excess Ratio Control of the PEM Fuel Cell System Applying to UAVs},
year={2020},
volume={},
number={},
pages={1376-1383},
abstract={The excess ratio control of PEM fuel cells systems is investigated in this paper with the use of double loop cascade control structure. In the outer loop, an improved super-twisting control algorithm is proposed which is robust against dynamics and disturbances in UAVs. As for the inner loop, the optimal tracking controller based upon adaptive dynamic programming (ADP) is exploited to adaptively approximate the optimal control policy, where the weights of neural networks are updated real-time. Simulation results are demonstrated with comparison between the traditional cascaded super twisting control scheme and the ADP based scheme.},
keywords={Fuel cells;Cathodes;Mathematical model;Angular velocity;Heuristic algorithms;Robustness;Voltage control},
doi={10.1109/ICUAS48674.2020.9213845},
ISSN={2575-7296},
month={Sep.},}
@INPROCEEDINGS{6908370,
author={Jin, Jonghoon and Gokhale, Vinayak and Dundar, Aysegul and Krishnamurthy, Bharadwaj and Martini, Berin and Culurciello, Eugenio},
booktitle={2014 IEEE 57th International Midwest Symposium on Circuits and Systems (MWSCAS)}, title={An efficient implementation of deep convolutional neural networks on a mobile coprocessor},
year={2014},
volume={},
number={},
pages={133-136},
abstract={In this paper we present a hardware accelerated real-time implementation of deep convolutional neural networks (DCNNs). DCNNs are becoming popular because of advances in the processing capabilities of general purpose processors. However, DCNNs produce hundreds of intermediate results whose constant memory accesses result in inefficient use of general purpose processor hardware. By using an efficient routing strategy, we are able to maximize utilization of available hardware resources but also obtain high performance in real world applications. Our system, consisting of an ARM Cortex-A9 processor and a coprocessor, is capable of a peak performance of 40 G-ops/s while consuming less than 4W of power. The entire platform is in a small form factor which, combined with its high performance at low power consumption makes it feasible to use this hardware in applications like micro-UAVs, surveillance systems and autonomous robots.},
keywords={Program processors;Mobile communication;Robots;Robustness},
doi={10.1109/MWSCAS.2014.6908370},
ISSN={1558-3899},
month={Aug},}
@INPROCEEDINGS{9364523,
author={Veramendi, Wilbur N. Chiuyari and Cruvinel, Paulo E.},
booktitle={2021 IEEE 15th International Conference on Semantic Computing (ICSC)}, title={Algorithm For the Countering Maize Plants Based On UAV, Digital Image Processing and Semantic Modeling},
year={2021},
volume={},
number={},
pages={393-397},
abstract={With the need to increase agricultural production and to avoid loss, this paper presents the development of a new method for counting plants of maize in an agricultural field using spectral images obtained by an UAV, as well as digital processing and semantic modeling techniques. The method is based on the use of the Circular Hough Transform (CHT) in conjunction with the techniques of Backmapping, neighborhood analysis, and a classification of patterns. Both the supper vector machines (SVM) and the neural networks (NN) methods have been evaluated for the classification procedure. Besides, using a computational environment for simulation, previous results have been obtained, i.e., showing not only the usefulness of the direct measures but also an automatic way for the plants identification, counting and height determination of the planted maize. Also, the establishment of a friendly interface has been carried out, which allows the monitoring of the phenological phases involved in the stages of the maize cultivation.},
keywords={Visualization;Plants (biology);Digital images;Semantics;Two dimensional displays;Process control;Production;Image Processing;Semantic Decision Making;Hough Transform;UAVs;Risk Management;Pest Control},
doi={10.1109/ICSC50631.2021.00072},
ISSN={2325-6516},
month={Jan},}
@INPROCEEDINGS{9476879,
author={Arnegaard, Ola Tranum and Leira, Frederik S. and Helgesen, Håkon H. and Kemna, Stephanie and Johansen, Tor A.},
booktitle={2021 International Conference on Unmanned Aircraft Systems (ICUAS)}, title={Detection of objects on the ocean surface from a UAV with visual and thermal cameras: A machine learning approach},
year={2021},
volume={},
number={},
pages={81-90},
abstract={Unmanned aerial vehicles (UAVs) can provide great value in off-shore operations that require aerial surveillance, for example by detecting objects on the water surface. For efficient operations by autonomous aerial surveillance, a reliable automatic detection system must be in place: one that will limit the amount of false negatives, but not at the expense of too many false positives. In this paper, we assess multiple aspects of the detection system that may provide significant impact in off-shore aerial surveillance: First by assessing detection architectures based on convolutional neural networks, then by adding tracking algorithms to utilize temporal information, and finally by investigating the use of different imaging modalities. Through a comparison of several detection models, the experiments prove that misclassification of objects is a particular issue, where input resolution and size of objects influence the overall model performance. The use of a tracking algorithm allows for decreasing the confidence threshold, which results in fewer false negatives, without a significant increase in false positives. In addition, comparing information obtained from visual and thermal imaging systems shows that these modalities provide complementary information in the presence of sunlight reflection.},
keywords={Visualization;Sea surface;Surveillance;Video sequences;Unmanned aerial vehicles;Reflection;Synchronization},
doi={10.1109/ICUAS51884.2021.9476879},
ISSN={2575-7296},
month={June},}
@ARTICLE{8681121,
author={Li, Shuai and Xu, Yuelei and Zhu, Mingming and Ma, Shiping and Tang, Hong},
journal={IEEE Geoscience and Remote Sensing Letters}, title={Remote Sensing Airport Detection Based on End-to-End Deep Transferable Convolutional Neural Networks},
year={2019},
volume={16},
number={10},
pages={1640-1644},
abstract={Rapid intelligent detection of airports from remote sensing images is required to accomplish autonomous intelligent landing of unmanned aerial vehicles (UAVs) and other tasks. To address the insufficiency of traditional models in detecting airports under complicated backgrounds from remote sensing images, we propose an end-to-end remote sensing airport hierarchical expression and detection model based on deep transferable convolutional neural networks. Based on transfer learning, we solve the fundamental problem of overfitting due to the inadequate number of labeled remote sensing images by transferring the network model from natural image source domain to remote sensing image target domain. In addition, we introduce a cascade region proposal network with soft-decision nonmaximal suppression to improve the network structure and the performance of our method under complex backgrounds. Moreover, we use skip-layer feature fusion and hard example mining methods to improve the object expression ability and the training efficiency. Finally, the experimental results demonstrate that the method established in this letter can quickly and effectively detect different types of airports over complex backgrounds and obtain better detection performance than the other detection methods.},
keywords={Airports;Feature extraction;Remote sensing;Atmospheric modeling;Training;Nonhomogeneous media;Task analysis;Airport detection;convolutional neural network;feature fusion;region proposal network (RPN);remote sensing images;transfer learning},
doi={10.1109/LGRS.2019.2904076},
ISSN={1558-0571},
month={Oct},}
@INPROCEEDINGS{8723734,
author={Zerrouk, Ilham and Moumen, Younes and Khiati, Wassim and Berrich, Jamal and Bouchentouf, Toumi},
booktitle={2019 International Conference on Wireless Technologies, Embedded and Intelligent Systems (WITS)}, title={Detection Process of Ships in Aerial Imagery Using Two Convnets},
year={2019},
volume={},
number={},
pages={1-8},
abstract={In this article, we focus on boat real time detection in high resolution aerial images taken by UAVs, using convolutional neural networks. This problem is similar to object detection in images taken from the terrestrial surface at ground level or on elevations, but present certain specificities regarding: the smaller size of objects to be detected and camera orientations that are different. As a result, the methods designed for the general detection purpose are not adapted to our problem. Some of these convolutional network-based methods have been adapted for locating objects on remote sensing images by making changes and enhancements on the networks' models and parameters. In this article, we will take a look at some of these techniques and architectures. We will also draw up a comparison table between the various improvements used in these methods. We will also present the strategy and techniques we will adopt in order to provide practical advantages and a reliable solution to our problem. And finally, we will expose the results obtained using our approach.},
keywords={Boats;Feature extraction;Image resolution;Cameras;Neural networks;Task analysis;Object detection;detection process;ship detection;target detection;aerial imagery;UAV;convnet},
doi={10.1109/WITS.2019.8723734},
ISSN={},
month={April},}
@ARTICLE{9534897,
author={Gu, Jiaqi and Sun, Ruisheng and Chen, Jieqing},
journal={IEEE Access}, title={Improved Back-Stepping Control for Nonlinear Small UAV Systems With Transient Prescribed Performance Design},
year={2021},
volume={9},
number={},
pages={128786-128798},
abstract={This paper proposes an improved back-stepping control approach and its application to small nonlinear UAV control systems with uncertainties such as external disturbance. Unlike traditional back-stepping control methods, the idea of prescribed performance function (PPF) is incorporated into the control design, such that both the transient and steady-state control performance can be strictly guaranteed. Moreover, we design a novel tracking differentiator to avoid the “differential expansion” problem well caused by the calculation of derivative. Significantly, the function approximators (e.g. neural networks) that are widely used to address the unknown nonlinearities in the nonlinear control designs are not needed. Finally, the numerical simulation verifies the convergence and robustness of the system, and the results show that the control strategy can obtain better transient and steady-state performance.},
keywords={Transient analysis;Steady-state;Mathematical model;Control design;Unmanned aerial vehicles;Aerodynamics;Uncertainty;Back-stepping control;nonlinear control;prescribed performance function;robust control;tracking differentiator},
doi={10.1109/ACCESS.2021.3111619},
ISSN={2169-3536},
month={},}
@INPROCEEDINGS{9448699,
author={Aledhari, Mohammed and Razzak, Rehma and Parizi, Reza M. and Srivastava, Gautam},
booktitle={2021 IEEE 93rd Vehicular Technology Conference (VTC2021-Spring)}, title={Sensor Fusion for Drone Detection},
year={2021},
volume={},
number={},
pages={1-7},
abstract={With the rapid development of commercial drones, drone detection and classification have emerged and grown recently. Drone detection works to detect unmanned aerial vehicles (UAVs). Usually, systems for drone detection utilize a combination of one or more sensors and some methodology. Many unique technologies and methods are used to detect drones. However, each type of technology offers its benefits and limitations. Most approaches use computer vision or machine learning, but one methodology that has not been given much attention is Sensor Fusion. Sensor Fusion has less uncertainty than most methods, making it suitable for drone detection. In this paper, we propose an artificial neural network-based detection system that uses a deep neural network (DNN) to process the RF data and a convolutional neural network (CNN) to process image data. The features from CNNs and DNNs are concatenated and input into another DNN, which outputs a single prediction score of drone presence. Our model achieved a validation accuracy of 75% that shows the feasibility of a sensor fusion based technique for drone detection.},
keywords={Radio frequency;Vehicular and wireless technologies;Uncertainty;Conferences;Machine learning;Sensor fusion;Sensor systems;DNN;CNN;multi-sensor;data fusion;drone;UAVs},
doi={10.1109/VTC2021-Spring51267.2021.9448699},
ISSN={2577-2465},
month={April},}
@INPROCEEDINGS{7158930,
author={Abuleil, Ammar M. and Taylor, Graham W. and Moussa, Medhat},
booktitle={2015 12th Conference on Computer and Robot Vision}, title={An Integrated System for Mapping Red Clover Ground Cover Using Unmanned Aerial Vehicles: A Case Study in Precision Agriculture},
year={2015},
volume={},
number={},
pages={277-284},
abstract={In the field of precision agriculture (PA), Un-manned Aerial Vehicles (UAVs) are creating new opportunities for remotely assessing various characteristics of crops. In this paper, we present two main contributions that were evaluated on a novel application: mapping red clover ground cover (RCGC). First, we develop an integrated system for collecting, pre-processing and analyzing aerial data for the mapping of RCGC at a patch-level. Second, we collected, ground-trusted, and pre-processed a RCGC dataset that we make public for further analysis. We evaluated several different machine learning classifiers for mapping image patches to discrete clover coverage levels, reaching an accuracy of 91%.},
keywords={Hyperspectral sensors;Agriculture;Support vector machines;Sensors;Global Positioning System;Accuracy;Data collection;precision agriculture;remote sensing;machine learning;red clover;ground cover;classification},
doi={10.1109/CRV.2015.43},
ISSN={},
month={June},}
@INPROCEEDINGS{8909862,
author={Hellert, Christian and Koch, Simon and Stütz, Peter},
booktitle={2019 16th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS)}, title={Using Algorithm Selection for Adaptive Vehicle Perception Aboard UAV},
year={2019},
volume={},
number={},
pages={1-8},
abstract={Surveillance sensors aboard UAV are affected by environmental influences, e.g. atmospheric or topographic factors. This paper proposes a method for the automatic adaption of airborne sensor applications such as street surveillance to changing environmental conditions, preventing overall performance degradation with minimum human intervention. The basic principle of the concept relies on the selection of the most appropriate data processing algorithm available on board. To facilitate the determination of the most effective algorithm, performance models are used to predict the expected suitability of each algorithm for the given environmental conditions. Modeling the relation between the environmental state and the performance of the algorithms is achieved by two approaches leveraging expert knowledge and machine learning methods. An evaluation was carried out in simulation as well as in real flight experiments showing that the proposed method is able to improve overall vehicle perception performance.},
keywords={Data models;Prediction algorithms;Adaptation models;Image sensors;Sensor systems;Data processing},
doi={10.1109/AVSS.2019.8909862},
ISSN={2643-6213},
month={Sep.},}
@INPROCEEDINGS{7502544,
author={Wang, Xian and Zhang, Youmin},
booktitle={2016 International Conference on Unmanned Aircraft Systems (ICUAS)}, title={Insulator identification from aerial images using Support Vector Machine with background suppression},
year={2016},
volume={},
number={},
pages={892-897},
abstract={Insulator identification in aerial videos is one of the key procedures to the condition analysis for aerial power line inspections. This paper proposes a novel insulator recognition method for images taken by Unmanned Aerial Vehicles (UAVs) with highly cluttered background, which is to adopt a machine learning algorithm Support Vector Machine (SVM) as a classifier to distinguish insulator from the cluttered background based on Gabor features. An innovative background suppression method is proposed to remove the redundant background information as much as possible. The test results show that not only the proposed method can successfully recognize insulator in the aerial images with complex and cluttered background, but also the background suppression procedure can greatly drop the computational load and reduce faulty classification.},
keywords={Insulators;Support vector machines;Feature extraction;Image recognition;Inspection;Training;Videos},
doi={10.1109/ICUAS.2016.7502544},
ISSN={},
month={June},}
@INPROCEEDINGS{9052924,
author={Dovis, Fabio and Imam, Rayan and Qin, Wenjian and Savas, Caner and Visser, Hans},
booktitle={ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, title={Opportunistic use of GNSS Signals to Characterize the Environment by Means of Machine Learning Based Processing},
year={2020},
volume={},
number={},
pages={9190-9194},
abstract={GNSS is widely used to provide positions in an absolute reference frame in Unmanned Aerial Vehicles (UAV) and Unmanned Ground Vehicles (UGV), where GNSS is merged with the information provided by other sensors. Even if the main goal of GNSS signal processing is the positioning, multifrequency signals are a rich source of information about the propagation environment surrounding the mobile vehicle. In urban and harsh environment, situational awareness is essential to tailor the operations and take proper countermeasure to harsh propagation conditions. Given this framework the present paper will describe the use of GNSS as signals of opportunity for the characterization of the operative environment by processing the GNSS observables through Machine Learning (ML) algorithms that can be used as efficient features extractors. The paper will present some case studies of operational scenarios for UGVs and for a static monitoring station, showing how through combining DSP techniques with both unsupervised and supervised ML algorithms (K-means classes, Support Vector Machines) it is possible to retrieve the information about the propagation scenario for multipath, interference and atmospheric limitations.},
keywords={Support vector machines;Global navigation satellite system;Machine learning algorithms;Computational modeling;Signal processing algorithms;Interference;Machine learning;Multipath;interference;scintillation;K-means clustering;support vector machines},
doi={10.1109/ICASSP40776.2020.9052924},
ISSN={2379-190X},
month={May},}


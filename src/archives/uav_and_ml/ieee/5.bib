@INPROCEEDINGS{8651796,
author={Shamsoshoara, Alireza and Khaledi, Mehrdad and Afghah, Fatemeh and Razi, Abolfazl and Ashdown, Jonathan},
booktitle={2019 16th IEEE Annual Consumer Communications Networking Conference (CCNC)}, title={Distributed Cooperative Spectrum Sharing in UAV Networks Using Multi-Agent Reinforcement Learning},
year={2019},
volume={},
number={},
pages={1-6},
abstract={In this paper, we develop a distributed mechanism for spectrum sharing among a network of unmanned aerial vehicles (UAV) and licensed terrestrial networks. This method can provide a practical solution for situations where the UAV network may need external spectrum when dealing with congested spectrum or need to change its operational frequency due to security threats. Here we study a scenario where the UAV network performs a remote sensing mission. In this model, the UAVs are categorized to two clusters of relaying and sensing UAVs. The relay UAVs provide a relaying service for a licensed network to obtain spectrum access for the rest of UAVs that perform the sensing task. We develop a distributed mechanism in which the UAVs locally decide whether they need to participate in relaying or sensing considering the fact that communications among UAVs may not be feasible or reliable. The UAVs learn the optimal task allocation using a distributed reinforcement learning algorithm. Convergence of the algorithm is discussed and simulation results are presented for different scenarios to verify the convergence.},
keywords={Receivers;Relays;Transmitters;Unmanned aerial vehicles;Task analysis;Sensors;Mathematical model;Spectrum Sharing;multi-Agent Learning;UAV Networks;reinforcement learning},
doi={10.1109/CCNC.2019.8651796},
ISSN={2331-9860},
month={Jan},}
@INPROCEEDINGS{9498726,
author={Emami, Yousef and Wei, Bo and Li, Kai and Ni, Wei and Tovar, Eduardo},
booktitle={2021 International Wireless Communications and Mobile Computing (IWCMC)}, title={Deep Q-Networks for Aerial Data Collection in Multi-UAV-Assisted Wireless Sensor Networks},
year={2021},
volume={},
number={},
pages={669-674},
abstract={Unmanned Aerial Vehicles (UAVs) can collaborate to collect and relay data for ground sensors in remote and hostile areas. In multi-UAV-assisted wireless sensor networks (MA-WSN), the UAVs' movements impact on channel condition and can fail data transmission, this situation along with newly arrived data give rise to buffer overflows at the ground sensors. Thus, scheduling data transmission is of utmost importance in MA-WSN to reduce data packet losses resulting from buffer overflows and channel fading. In this paper, we investigate the optimal ground sensor selection at the UAVs to minimize data packet losses. The optimization problem is formulated as a multi-agent Markov decision process, where network states consist of battery levels and data buffer lengths of the ground sensor, channel conditions, and waypoints of the UAV along the trajectory. In practice, an MA-WSN contains a large number of network states, while the up-to-date knowledge of the network states and other UAVs' sensor selection decisions is not available at each agent. We propose a Multi-UAV Deep Reinforcement Learning based Scheduling Algorithm (MUAIS) to minimize the data packet loss, where the UAVs learn the underlying patterns of the data and energy arrivals at all the ground sensors. Numerical results show that the proposed MUAIS achieves at least 46 % and 35% lower packet loss than an optimal solution with single-UAV and an existing non-learning greedy algorithm, respectively.},
keywords={Greedy algorithms;Fading channels;Wireless sensor networks;Packet loss;Buffer overflows;Data collection;Unmanned aerial vehicles;Unmanned aerial vehicles;Communication scheduling;Multi-UAV Deep Reinforcement Learning;Deep Q- Network},
doi={10.1109/IWCMC51323.2021.9498726},
ISSN={2376-6506},
month={June},}
@ARTICLE{9039640,
author={Qi, Hang and Hu, Zhiqun and Huang, Hao and Wen, Xiangming and Lu, Zhaoming},
journal={IEEE Access}, title={Energy Efficient 3-D UAV Control for Persistent Communication Service and Fairness: A Deep Reinforcement Learning Approach},
year={2020},
volume={8},
number={},
pages={53172-53184},
abstract={Recently, unmanned aerial vehicles (UAVs) as flying wireless communication platform have attracted much attention. Benefiting from the mobility, UAV aerial base stations can be deployed quickly and flexibly, and can effectively establish Line-of-Sight communication links. However, there are many challenges in UAV communication system. The first challenge is energy constraint, where the UAV battery lifetime is in the order of fraction of an hour. The second challenge is that the coverage area of UAV aerial base station is limited and the commercial UAV is usually expensive. Thus, covering a large target region all the time with sufficient UAVs is quite challenging. To solve above challenges, in this paper, we propose energy efficient and fair 3-D UAV scheduling with energy replenishment, where UAVs move around to serve users and recharge timely to replenish energy. Inspired by the success of deep reinforcement learning, we propose a UAV Control policy based on Deep Deterministic Policy Gradient (UC-DDPG) to address the combination problem of 3-D mobility of multiple UAVs and energy replenishment scheduling, which ensures energy efficient and fair coverage of each user in a large region and maintains the persistent service. Simulation results reveal that UC-DDPG shows a good convergence and outperforms other scheduling algorithms in terms of data volume, energy efficiency and fairness.},
keywords={Unmanned aerial vehicles;Data models;Trajectory;Energy consumption;Batteries;Wireless networks;UAV communication;energy efficiency;fairness;energy replenishment;deep reinforcement learning;DDPG},
doi={10.1109/ACCESS.2020.2981403},
ISSN={2169-3536},
month={},}
@INPROCEEDINGS{9274899,
author={Yan, Peng and Bai, Chengchao and Zheng, Hongxing and Guo, Jifeng},
booktitle={2020 3rd International Conference on Unmanned Systems (ICUS)}, title={Flocking Control of UAV Swarms with Deep Reinforcement Leaming Approach},
year={2020},
volume={},
number={},
pages={592-599},
abstract={The flocking control of UAV swarms has been studied extensively due to its wide applications. In this paper, the UAV flocking control problem is formulated as a Partial Observable Markov Decision Process (POMDP) where the constraints of the UAV's communication and perception ranges are considered. A deep reinforcement learning approach is proposed to solve this problem with centralized training and decentralized execution manner. The experience collected by all UAVs is used to train the shared flocking control policy, and each UAV performs actions based on the local environment information it observes. To enable the UAV swarm to maintain a flock and navigate in an environment with dense obstacles, a reward function is constructed considering with goal reaching, obstacles avoidance and flocking maintenance. Especially, the flocking maintenance reward is designed with the global information of the UAV swarm, which can only be obtained during the training phase. Simulation results demonstrate that the policy trained with the flocking maintenance reward can make the UAV swarm keep a flock when encountering obstacles and has good generalization ability with different number of UAVs.},
keywords={Training;Navigation;Simulation;Reinforcement learning;Maintenance engineering;Aerospace electronics;Unmanned aerial vehicles;UAV swarms;flocking control;obstacles avoidance;deep reinforcement learning},
doi={10.1109/ICUS50048.2020.9274899},
ISSN={},
month={Nov},}
@ARTICLE{8894381,
author={Huang, Hongji and Yang, Yuchun and Wang, Hong and Ding, Zhiguo and Sari, Hikmet and Adachi, Fumiyuki},
journal={IEEE Transactions on Vehicular Technology}, title={Deep Reinforcement Learning for UAV Navigation Through Massive MIMO Technique},
year={2020},
volume={69},
number={1},
pages={1117-1121},
abstract={Unmanned aerial vehicles (UAVs) technique has been recognized as a promising solution in future wireless connectivity from the sky, and UAV navigation is one of the most significant open research problems, which has attracted wide interest in the research community. However, the current UAV navigation schemes are unable to capture the UAV motion and select the best UAV-ground links in real-time, and these weaknesses overwhelm the UAV navigation performance. To tackle these fundamental limitations, in this paper, we merge the state-of-the-art deep reinforcement learning with the UAV navigation through massive multiple-input-multiple-output (MIMO) technique. To be specific, we carefully design a deep Q-network (DQN) for optimizing the UAV navigation by selecting the optimal policy, and then we propose a learning mechanism for processing the DQN. The DQN is trained so that the agent is capable of making decisions based on the received signal strengths for navigating the UAVs with the aid of the powerful Q-learning. Simulation results are provided to corroborate the superiority of the proposed schemes in terms of the coverage and convergence compared with those of the other schemes.},
keywords={Navigation;Reinforcement learning;Wireless communication;Unmanned aerial vehicles;Signal to noise ratio;Massive multiple-input-multiple-output (MIMO);deep reinforcement learning;UAV navigation},
doi={10.1109/TVT.2019.2952549},
ISSN={1939-9359},
month={Jan},}
@INPROCEEDINGS{9299760,
author={Dai, Anna and Li, Rongpeng and Zhao, Zhifeng and Zhang, Honggang},
booktitle={2020 International Conference on Wireless Communications and Signal Processing (WCSP)}, title={Graph Convolutional Multi-Agent Reinforcement Learning for UAV Coverage Control},
year={2020},
volume={},
number={},
pages={1106-1111},
abstract={Benefiting from the convenience of aerial flying, unmanned aerial vehicles (UAVs) can provide linear accessibility and dynamic adjusted coverage scheme to ground users, thus promising to act as removable base stations (BSs). Therefore, it necessitates the UAVs to work as a group or team and cooperate with each other, since the embedded computational and energy resources of UAVs lead to relevantly limited coverage range. In typical UAV groups, neighboring UAVs can create connections, forming a dynamic local network, to which UAVs are encouraged to stay connected due to the limited gateway resources. The connection form and networking mode of UAVs group have the characteristics of graph, which can help improve the group performance. Connections bring information sharing while the dynamic characteristics of the connections make the network topology changing with the UAVs' moving. Taking these into consideration, we utilize a graph convolutional based multi-agent reinforcement learning (MARL) method for UAVs group controlling. The proposed method is able to capture and take advantage of the mutual interplay between UAVs, so as to effectively improve the signal coverage as well as fairness and reduce the overall energy consumption in the meantime. Extensive simulation results verify the effectiveness of the proposed method.},
keywords={Reinforcement learning;Unmanned aerial vehicles;Convolution;Feature extraction;Energy consumption;Kernel;Vehicle dynamics;UAV control;multi-agent;deep reinforcement learning;signal covering;energy efficiency},
doi={10.1109/WCSP49889.2020.9299760},
ISSN={2472-7628},
month={Oct},}
@INPROCEEDINGS{9500519,
author={Moorthy, Sabarish Krishna and Guan, Zhangyu and Pudlewski, Scott and Bentley, Elizabeth Serena},
booktitle={ICC 2021 - IEEE International Conference on Communications}, title={FlyBeam: Echo State Learning for Joint Flight and Beamforming Control in Wireless UAV Networks},
year={2021},
volume={},
number={},
pages={1-6},
abstract={This paper aims at designing high-data-rate swarm UAV networks with distributed beamforming capabilities. The primary challenge is that the beamforming gain in swarm UAV networks is highly affected by the UAVs’ flight altitude, their movements and the resulting intermittent link blockages, as well as the availability of channel state information (CSI) at individual UAVs. To address this challenge, we propose FlyBeam, a learning- based framework for joint flight and beamforming control in swarm UAV networks. We first present a mathematical formulation of the control problem with the objective of maximizing the throughput of swarm UAV networks by jointly controlling the flight and distributed beamforming of UAVs. Then, a distributed solution algorithm is designed based on a combination of Echo State Network learning and online reinforcement learning. The former is adopted to approximate the utility function for individual UAVs based on online measurements, by jointly considering the unknown blockage dynamics and other factors that affect the beamforming gain. The latter is used to guide the exploitation and exploration in FlyBeam. The effectiveness of FlyBeam is evaluated through an extensive simulation campaign. Results indicate that significant (up to 450%) beamforming gain can be achieved by FlyBeam. We also investigate the effects of blockages and UAV flight altitude on the beamforming gain. It is found that, which is somewhat surprising, higher (rather than lower) beamforming gain can be achieved by FlyBeam with denser blockages in swarm UAV networks.},
keywords={Wireless communication;Array signal processing;Simulation;Heuristic algorithms;Conferences;Reinforcement learning;Gain measurement;Swarm UAV Networks;Distributed Beamforming;Echo State Network;Reinforcement Learning},
doi={10.1109/ICC42927.2021.9500519},
ISSN={1938-1883},
month={June},}
@ARTICLE{9161257,
author={Zhang, Yu and Mou, Zhiyu and Gao, Feifei and Jiang, Jing and Ding, Ruijin and Han, Zhu},
journal={IEEE Transactions on Vehicular Technology}, title={UAV-Enabled Secure Communications by Multi-Agent Deep Reinforcement Learning},
year={2020},
volume={69},
number={10},
pages={11599-11611},
abstract={Unmanned aerial vehicles (UAVs) can be employed as aerial base stations to support communication for the ground users (GUs). However, the aerial-to-ground (A2G) channel link is dominated by line-of-sight (LoS) due to the high flying altitude, which is easily wiretapped by the ground eavesdroppers (GEs). In this case, a single UAV has limited maneuvering capacity to obtain the desired secure rate in the presence of multiple eavesdroppers. In this paper, we propose a cooperative jamming approach by letting UAV jammers help the UAV transmitter defend against GEs. To be specific, the UAV transmitter sends the confidential information to GUs, and the UAV jammers send the artificial noise signals to the GEs by 3D beamforming. We propose a multi-agent deep reinforcement learning (MADRL) approach, i.e., multi-agent deep deterministic policy gradient (MADDPG) to maximize the secure capacity by jointly optimizing the trajectory of UAVs, the transmit power from UAV transmitter and the jamming power from the UAV jammers. The MADDPG algorithm adopts centralized training and distributed execution. The simulation results show the MADRL method can realize the joint trajectory design of UAVs and achieve good performance. To improve the learning efficiency and convergence, we further propose a continuous action attention MADDPG (CAA-MADDPG) method, where the agent learns to pay attention to the actions and observations of other agents that are more relevant with it. From the simulation results, the rewards performance of CAA-MADDPG is better than the MADDPG without attention.},
keywords={Jamming;Trajectory;Training;Radio transmitters;Machine learning;Three-dimensional displays;UAV;multi-agent deep reinforcement learning;trajectory design;policy gradient;physical layer security},
doi={10.1109/TVT.2020.3014788},
ISSN={1939-9359},
month={Oct},}
@INPROCEEDINGS{9580284,
author={Su, Yuhan and Liwang, Minghui and Hosseinalipour, Seyyedali and Huang, Lianfen and Dai, Huaiyu},
booktitle={2021 IEEE/CIC International Conference on Communications in China (ICCC)}, title={Cooperative Relaying and Power Control for UAV-Assisted Vehicular Networks with Deep Q-Network},
year={2021},
volume={},
number={},
pages={318-323},
abstract={This paper investigates the usage of unmanned aerial vehicles (UAV s) as relays for data transmission in vehicular networks. We are motivated to address the challenges induced by the lack of direct communication between the vehicles and the infrastructures, such as signal coverage limitations and the existence of obstacles. We consider a scenario in which UAV relays perform cooperative communication in vehicular networks to offer extended coverage to the vehicles, which results in an improvement in the system capacity and reliability. Identifying an efficient UAV-assisted collaboration strategy for vehicular networks is challenging due to the vehicle mobility and the limited power consumption of UAVs. To tackle this problem, we propose a UAV-assisted cooperative relaying scheme based on deep reinforcement learning. To this end, we first determine the optimal transmit powers of a given set of UAV relays to maximize the total throughput of the system. Then, we formulate the UAV-assisted cooperative relaying process as a Markov process and apply a deep Q-network to obtain an effective UAV relay selection strategy. One of the advantages of our solution is that it does not require the knowledge of the vehicle moving trajectories. Through simulations, we demonstrate the effectiveness of our proposed method.},
keywords={Power demand;Cooperative communication;Simulation;Power control;Reinforcement learning;Throughput;Unmanned aerial vehicles;Vehicular networks;unmanned aerial vehicles (UAV s);power control;deep reinforcement learning},
doi={10.1109/ICCC52777.2021.9580284},
ISSN={2377-8644},
month={July},}
@INPROCEEDINGS{9155535,
author={Liu, Chi Harold and Piao, Chengzhe and Tang, Jian},
booktitle={IEEE INFOCOM 2020 - IEEE Conference on Computer Communications}, title={Energy-Efficient UAV Crowdsensing with Multiple Charging Stations by Deep Learning},
year={2020},
volume={},
number={},
pages={199-208},
abstract={Different from using human-centric mobile devices like smartphones, unmanned aerial vehicles (UAVs) can be utilized to form a new UAV crowdsensing paradigm, where UAVs are equipped with build-in high-precision sensors, to provide data collection services especially for emergency situations like earthquakes or flooding. In this paper, we aim to propose a new deep learning based framework to tackle the problem that a group of UAVs energy-efficiently and cooperatively collect data from low-level sensors, while charging the battery from multiple randomly deployed charging stations. Specifically, we propose a new deep model called "j-PPO+ConvNTM" which contains a novel spatiotemporal module "Convolution Neural Turing Machine" (ConvNTM) to better model long-sequence spatiotemporal data, and a deep reinforcement learning (DRL) model called "j-PPO", where it has the capability to make continuous (i.e., route planing) and discrete (i.e., either to collect data or go for charging) action decisions simultaneously for all UAVs. Finally, we perform extensive simulation to show its illustrative movement trajectories, hyperparameter tuning, ablation study, and compare with four other baselines.},
keywords={Charging stations;Sensors;Machine learning;Data models;Data collection;Spatiotemporal phenomena;Task analysis;UAV crowdsensing;spatiotemporal modeling;deep reinforcement learning;charging stations},
doi={10.1109/INFOCOM41043.2020.9155535},
ISSN={2641-9874},
month={July},}
@INPROCEEDINGS{9682412,
author={Rizk, Mostafa and Slim, Fatima and Charara, Jamal},
booktitle={2021 International Conference on Decision Aid Sciences and Application (DASA)}, title={Toward AI-Assisted UAV for Human Detection in Search and Rescue Missions},
year={2021},
volume={},
number={},
pages={781-786},
abstract={Search and rescue missions during and after disasters require all efforts and high financial expenses. Rapid locating of wounded and lost individuals contributes in directing the rescuers and medical teams. This may increase the probability of saving human lives and plays a significant role in reducing expenses. Currently, the use of unmanned aerial vehicles (UAVs) or drones for remote surveillance and reconnaissance is becoming increasingly popular. On the other hand, emergent artificial intelligence (AI) algorithms based on convolution neural networks (CNN) reveal the ability of real-time detection. Combining the high-performance detection and classification capabilities provided by emergent AI techniques with the exploratory abilities of UAVs allows the UAVs to process the captured sequence of images and report back results in real-time. The evolution of AI-assisted UAVs enables the detection of wounded and trapped persons while flying and allows proper and fast transfer of information to ground stations to lead the rescuers and medical teams to victims' locations. In this paper, we explore augmenting UAVs with processing units executing emergent AI-based detectors. The proposed system can detect humans in real time and send the corresponding coordinates to the ground station.},
keywords={Surveillance;Video sequences;Neural networks;Object detection;Reconnaissance;Autonomous aerial vehicles;Real-time systems;UAV;Human detection;Search and rescue missions;artificial intelligence;YOLO},
doi={10.1109/DASA53625.2021.9682412},
ISSN={},
month={Dec},}
@INPROCEEDINGS{9476517,
author={Malo, Sadouanouan and Bayala, Thierry Roger and Ouattara, Issouf and Visala, Arto},
booktitle={2021 16th Iberian Conference on Information Systems and Technologies (CISTI)}, title={Cashew Trees Detection And Yield Analysis Using UAV-Based Map},
year={2021},
volume={},
number={},
pages={1-5},
abstract={In this study we developed a novel method to detect cashew trees in an orthophoto map derived from images collected by an unmanned aerial vehicle (UAV). We also suggest a way in which these detections can be used to analyze the yield of the cashew farm. The proposed method uses image analysis to find the tops of trees, to merge different tops located on the same tree, and to segment individual tree. The segmented trees are used in a deep learning framework to know the exact location of cashew trees. The preliminary cashew detection from UAV-based map is promising. This study can be interesting for developing countries where UAV system are nowadays gaining popularity in agriculture. Our method does not require any additional sensor other than the RGB camera onboard the UAV. This low-cost solution is suitable for small and medium cashew farmers. The developed method can also be extended to other types of trees, other than the cashew.},
keywords={Deep learning;Image segmentation;Image analysis;Developing countries;Cameras;Unmanned aerial vehicles;Agriculture;UAV;Deep Learning;Image Processing;Cashew Plant Detection},
doi={10.23919/CISTI52073.2021.9476517},
ISSN={2166-0727},
month={June},}
@ARTICLE{9229058,
author={He, Ming-Xiang and Hao, Peng and Xin, You-Zhi},
journal={IEEE Access}, title={A Robust Method for Wheatear Detection Using UAV in Natural Scenes},
year={2020},
volume={8},
number={},
pages={189043-189053},
abstract={In recent years, deep learning has greatly improved the ability of wheatear detection. However, there are still three main problems in wheatear detection based on unmanned aerial vehicle (UAV) platforms. First, dense wheat plants often overlap, and the wind direction will blur the pictures, which obviously interferes with the detection of wheatears; second, due to the different maturity, color, genotype, and head orientation, the appearance will also be different; third, UAV needs to take images in the field and conduct real-time detection, which requires the embedded module to detect wheatears quickly and accurately. Given the above problems, we studied and improved YoloV4, and proposed a robust method for wheatear detection using UAV in natural scenes. For the first problem, we modified the network structure, deleted the feature map with a size of 19×19, and used k-means algorithm to re-cluster the anchors, and we proposed a method of prediction box fusion. For the second problem, we used the pseudo-labeling method and data augmentation methods to improve the generalization ability of the model. For the third problem, we simplified the network structure, replaced the original network convolution with the improved depthwise separable convolution, and proposed an adaptive ReLU activation function to reduce the amount of calculation and speed up the calculation. The experimental results showed that our method can effectively mark the bounding of wheatears. In test sets, our method achieves 96.71% in f1-score, which is 9.61% higher than the state of the art method, and the detection speed is 23% faster than the original method. It can be concluded that our method can effectively solve the problems of wheatear detection based on the UAV platform in natural scenes.},
keywords={Convolution;Feature extraction;Object detection;Agriculture;Unmanned aerial vehicles;Deep learning;Head;Wheatear detection;improved YoloV4;UAV;object detection;deep learning},
doi={10.1109/ACCESS.2020.3031896},
ISSN={2169-3536},
month={},}
@INPROCEEDINGS{8511243,
author={Matos-Carvalho, J. P. and Fonseca, José M. and Mora, André},
booktitle={2018 Federated Conference on Computer Science and Information Systems (FedCSIS)}, title={UAV Downwash Dynamic Texture Features for Terrain Classification on Autonomous Navigation},
year={2018},
volume={},
number={},
pages={1079-1083},
abstract={The information generated by a computer vision system capable of labelling a land surface as water, vegetation, soil or other type, can be used for mapping and decision making. For example, an unmanned aerial vehicle (UAV) can use it to find a suitable landing position or to cooperate with other robots to navigate across an unknown region. Previous works on terrain classification from RGB images taken onboard of UAVs shown that only static pixel-based features were tested with a considerable classification error. This paper proposes a robust and efficient computer vision algorithm capable of classifying the terrain from RGB images with improved accuracy. The algorithm complement the static image features with dynamic texture patterns produced by UAVs rotors downwash effect (visible at lower altitudes) and machine learning methods to classify the underlying terrain. The system is validated using videos acquired onboard of a UAV.},
keywords={Unmanned aerial vehicles;Feature extraction;Vegetation mapping;Heuristic algorithms;Image color analysis;Computer vision;Machine learning;Image processing;Texture;Machine Learning;Terrain Classification;UAV},
doi={},
ISSN={},
month={Sep.},}
@ARTICLE{9311842,
author={Wang, Jiaxing and Han, Rui and Bai, Lin and Zhang, Tao and Liu, Jianwei and Choi, Jinho},
journal={IEEE Transactions on Cognitive Communications and Networking}, title={Coordinated Beamforming for UAV-Aided Millimeter-Wave Communications Using GPML-Based Channel Estimation},
year={2021},
volume={7},
number={1},
pages={100-109},
abstract={In the 5th generation (5G) networks, coordinated multiple point (CoMP) is one of key technologies to improve the quality of service (QoS) of edge users. To meet the requirement of growing data rates, millimeter-wave (mmWave) can be employed in the CoMP system. However, the QoS of users may be degraded if line-of-sight (LoS) mmWave channels are not guaranteed. In this article, an unmanned aerial vehicle (UAV)-aided communication scheme is proposed to enhance the QoS of edge users, where the UAV helps a primary base station (BS) and a coordinated BS simultaneously. In the proposed scheme, since the UAV only feeds back the channel state information (CSI) to the primary BS, the CSI obtained at the coordinated BS through a backbone network becomes outdated. In order to overcome the performance loss caused by the CSI feedback delay, a machine learning based channel estimation scheme is studied for the coordinated BS to perform hybrid beamforming. Furthermore, to eliminate the inter-BS interference, a maximize signal to interference-plus-noise ratio (Max-SINR) based beamforming compensation scheme is proposed for the primary BS and UAV. The simulation results show that both the bit error rate (BER) and sum rate performance can be improved by employing the proposed schemes.},
keywords={Array signal processing;Unmanned aerial vehicles;Quality of service;Channel estimation;Radio frequency;Millimeter wave communication;5G mobile communication;UAV communication networks;machine learning;millimeter-wave (mmWave);hybrid beamforming;beamforming compensation},
doi={10.1109/TCCN.2020.3048399},
ISSN={2332-7731},
month={March},}
@INPROCEEDINGS{9441503,
author={Wu, Songbing and Du, Chun and Chen, Hao and Jing, Ning},
booktitle={2021 2nd Information Communication Technologies Conference (ICTC)}, title={Coarse-to-Fine UAV Image Geo-Localization Using Multi-stage Lucas-Kanade Networks},
year={2021},
volume={},
number={},
pages={220-224},
abstract={Unmanned aerial vehicles (UAVs) have become an indispensable part of our intelligent society. Accurate UAV image geo-localization is fundamental in many applications such as search and rescue, precision agriculture, change detection. Previously, the UAV image geo-localization was usually calculated by photogrammetry method or by matching with the well-located reference images. The photogrammetry method relies heavily on the accuracy of the UAV positioning parameters, however, the construction and use of high-precision positioning equipment are expensive and difficult to be widely used. The method based on image matching requires good similarity between matching images, which is hard to be satisfied as the reference image and UAV image are heterologous. The existing methods are difficult to achieve accurate image geo-location on UAVs equipped with economical positioning devices. To address this issue, we propose a coarse-to-fine UAV image geo-localization pipeline. Firstly, we implement the coarse UAV image geo-localization by utilizing the UAV's position parameters. Then, a deep learning algorithm multi-stage Lucas-Kanade (MS-LK) is proposed to refine the UAV image geo-localization results iteratively. MS-LK can make full use of the UAV images' global texture. We validate the effectiveness of the proposed method on two real UAV data sets. The results show that the proposed UAV image geo-localization method can promote the results of the traditional photogrammetry-based approaches.},
keywords={Deep learning;Learning systems;Image sensors;Satellites;Image matching;Pipelines;Unmanned aerial vehicles;UAV image geo-localization;deep learning;MS-LK (multi-stage Lucas-Kanade) network;coarse-to-fine},
doi={10.1109/ICTC51749.2021.9441503},
ISSN={},
month={May},}
@INPROCEEDINGS{9653285,
author={Sarwar, Farah and Griffin, Anthony and Chong, Peter Han Joo and Pasang, Timotius},
booktitle={2021 36th International Conference on Image and Vision Computing New Zealand (IVCNZ)}, title={Pasture Fence Line Detection in UAV Videos},
year={2021},
volume={},
number={},
pages={1-6},
abstract={Farms in many countries use fenced pastures—known as paddocks—for keeping livestock. These farms usually spread over many hectares with paddocks of various shapes and sizes. Farm managers face the difficulty of counting their animals on regular basis and recently the use of an unmanned aerial vehicle (UAV) has been proposed for counting livestock. To get the data from only a respective paddock, the fence lines must also be detected correctly in the aerial images and videos. This will help to keep the data from each paddock separate. A unique system based on a combination of deep learning and machine learning is proposed to accurately detect the fence lines in the videos recorded by a UAV at an altitude of 80 m.},
keywords={Deep learning;Machine learning algorithms;Shape;Animals;Linear regression;Autonomous aerial vehicles;Agriculture;fence detection;UAV;computer vision;deep learning;DBSCAN},
doi={10.1109/IVCNZ54163.2021.9653285},
ISSN={2151-2205},
month={Dec},}
@INPROCEEDINGS{9553715,
author={Lin, Zixun and Doyog, Nova D. and Huang, Shin-Fu and Lin, Chinsu},
booktitle={2021 IEEE International Geoscience and Remote Sensing Symposium IGARSS}, title={Segmentation and Classification of UAV-based Orthophoto of Watermelon Field Using Support Vector Machine Technique},
year={2021},
volume={},
number={},
pages={6504-6507},
abstract={Agricultural crops monitoring covering large-scale areas with high-efficiency is of great importance in sustainable agriculture management to combat the demand for agricultural crops brought by the exponential growth of population worldwide. The study was conducted to assess the promising potential of segmenting cloud free and high-resolution images for watermelon fruit monitoring using the combination of Unmanned Aerial Vehicle (UAV) orthophotographs and Support Vector Machine (SVM) supervised machine learning model. The digital images of the watermelon field were captured using UAV DJI Mavic 2 Pro through Pix4D operation and were orthorectified to generate an orthophotograph of the study site using the Agisoft Metashape software. After the segmentation using the edge segmentation and full lambda algorithm, the segmented objects were classified using the SVM technique with 150 and 100 segmented blocks as training samples representing the fruit of the watermelon and the non-fruit, respectively. The result revealed that use of high-resolution digital imagery and the application of machine learning techniques could be a tool to a wide area accounting of agricultural crops as indicated by the overall classification accuracy of 91% and a Kappa coefficient of 0.79.},
keywords={Support vector machines;Training;Image segmentation;Digital images;Crops;Machine learning;Tools;Image segmentation;machine learning;UAV remote sensing;Agriculture},
doi={10.1109/IGARSS47720.2021.9553715},
ISSN={2153-7003},
month={July},}
@ARTICLE{9456900,
author={Li, Yuanjian and Aghvami, A. Hamid and Dong, Daoyi},
journal={IEEE Wireless Communications Letters}, title={Intelligent Trajectory Planning in UAV-Mounted Wireless Networks: A Quantum-Inspired Reinforcement Learning Perspective},
year={2021},
volume={10},
number={9},
pages={1994-1998},
abstract={In this letter, we consider a wireless uplink transmission scenario in which an unmanned aerial vehicle (UAV) serves as an aerial base station collecting data from ground users. To optimize the expected sum uplink transmit rate without any prior knowledge of ground users (e.g., locations, channel state information and transmit power), the trajectory planning problem is optimized via the quantum-inspired reinforcement learning (QiRL) approach. Specifically, the QiRL method adopts novel probabilistic action selection policy and new reinforcement strategy, which are inspired by the collapse phenomenon and amplitude amplification in quantum computation theory, respectively. Numerical results demonstrate that the proposed QiRL solution can offer natural balancing between exploration and exploitation via ranking collapse probabilities of possible actions, compared to the traditional reinforcement learning approaches that are highly dependent on tuned exploration parameters.},
keywords={Quantum computing;Uplink;Trajectory;Trajectory planning;Reinforcement learning;Quantum mechanics;Fading channels;UAV;trajectory planning;quantum computation;quantum-inspired reinforcement learning (QiRL)},
doi={10.1109/LWC.2021.3089876},
ISSN={2162-2345},
month={Sep.},}
@INPROCEEDINGS{9418199,
author={Sharma, Manish K. and Singal, Gaurav and Gupta, Suneet K. and Chandraneil, Basa and Agarwal, Saksham and Garg, Deepak and Mukhopadhyay, Debajyoti},
booktitle={2021 6th International Conference for Convergence in Technology (I2CT)}, title={INTERVENOR: Intelligent Border Surveillance using Sensors and Drones},
year={2021},
volume={},
number={},
pages={1-7},
abstract={Borders play an integral part in a country's security, but Borders are extremely vulnerable and prone to terrorist assaults, illegal smuggling of drugs, and unauthorized immigration. To achieve improved situation analysis, it is essential to fuse sensor-based detection with drone surveillance system to aid the present surveillance system. A wide range of threats can be detected, monitored, and classified by the system, it provides real-time actionable intelligence; endures difficult environments and remote location. Defending borders from unlawful entry of individuals, guns, narcotics and illicit goods is crucial to the protection of a country, and so are ground troops. This special issue aims to give simultaneous erudite examinations of border security by conducting more focus over a specific field of inquiry involved in the securing of borders. We proposed a solution to design an architecture that supports the sharing of information from heterogeneous sources. We are using various sensors which we will install around the perimeter of an area to detect any unknown disturbance (intrusion) around it. With the help of the gathered sensor data, the drone surveillance will be automatically activated and the location of the disturbance will also be sent to the drone and the soldiers in the nearby region, which will help us to track the disturbance so that we can apprehend the treason. We will install camera in the drone which will help us for tracking the target if any.},
keywords={Target tracking;Surveillance;Terrorism;Intrusion detection;Sonar;Software;Servers;Autonomous Systems;Unmanned Aerial Vehicle;IoT;Sensor;Intrusion Detection System;Border Security;Artificial Intelligence},
doi={10.1109/I2CT51068.2021.9418199},
ISSN={},
month={April},}
@INPROCEEDINGS{9302621,
author={Munaye, Yirga Yayeh and Juang, Rong-Terng and Lin, Hsin-Piao and Tarekegn, Getaneh Berie},
booktitle={2020 International Conference on Pervasive Artificial Intelligence (ICPAI)}, title={Resource Allocation for Multi-UAV Assisted IoT Networks: A Deep Reinforcement Learning Approach},
year={2020},
volume={},
number={},
pages={15-22},
abstract={The wireless communication system for the massively heterogeneous Internet of Things (IoT) network hinders the allocation of resources. For this study, an unmanned aerial vehicle (UAV) is considered as a base station (BS) for IoT system communications to maximize the utilization of future wireless network capacity. Two UAVs are used as the power source and an information transmitter (Tx). To be easily managed, IoT devices are categorized into two clusters of urban and semi-urban features based on their signal distribution and fluctuations. Next, the deep reinforcement learning (DRL) approach is proposed as a resource allocation (RA) scheme. The allocation of resources for bandwidth, throughput, and power consumption issues are considered to be our resources. TensorFlow (Python) programming tool is executed to evaluate and estimate the overall capability of the system. Finally, we analyzed the proposed approach based on different scenarios. Based on the experimental results, our method shows promising outcomes with rapid convergence, suitable for heterogeneous networks, and low complexity based on the evaluation tasks of classification and regression.},
keywords={Throughput;Resource management;Unmanned aerial vehicles;Signal to noise ratio;Mathematical model;Interference;Receivers;Resource allocation (RA);unmanned aerial vehicles (UAV);Deep Reinforcement Learning(DRL)},
doi={10.1109/ICPAI51961.2020.00011},
ISSN={},
month={Dec},}
@ARTICLE{8752017,
author={Li, Wanyi and Wang, Li and Fei, Aiguo},
journal={IEEE Wireless Communications Letters}, title={Minimizing Packet Expiration Loss With Path Planning in UAV-Assisted Data Sensing},
year={2019},
volume={8},
number={6},
pages={1520-1523},
abstract={With explosive attention on data-sensing services, the unmanned aerial vehicle (UAV) has been applied to accelerate the information collection. Particularly, as for the deadline-sensitive data, the age of information (AoI) has become a significant metric to avoid messages expiration. In this letter, we propose a UAV trajectory planning model for data collection with minimizing expired data packets in the whole sensor system, and then relax the obscure original problem into a min-max-AoI-optimal path scheme due to complex constraints. We utilize a reinforcement learning-based strategy for the solution and validate its effectiveness with comparison of other two benchmarks in simulations.},
keywords={Unmanned aerial vehicles;Sensors;Trajectory;Data communication;Wireless communication;Measurement;UAV-assisted data transmission;AoI;expired packets;reinforcement learning},
doi={10.1109/LWC.2019.2925796},
ISSN={2162-2345},
month={Dec},}
@INPROCEEDINGS{9594413,
author={Çetin, Ender and Barrado, Cristina and Pastor, Enric},
booktitle={2021 IEEE/AIAA 40th Digital Avionics Systems Conference (DASC)}, title={Counter a Drone and the Performance Analysis of Deep Reinforcement Learning Method and Human Pilot},
year={2021},
volume={},
number={},
pages={1-7},
abstract={Artificial Intelligence (AI) has been used in different research areas in aerospace to create an intelligent system. Especially, an unmanned aerial vehicle (UAV), known as a drone, can be controlled by AI methods such as deep reinforcement learning (DRL) in different purposes. Drones with DRL become more intelligent and eventually they can be fully autonomous. In this paper, DRL method supported by real time object detection model is proposed to detect and catch a drone. Additionally, the results are analyzed by comparing the time to catch the target drone in seconds between DRL method, human pilot and an algorithm which directs the drone towards the target position without using any AI method or navigation and guidance method. The main idea is to catch a drone in an environment as fast as possible without crashing any obstacles inside the environment. In DRL method, the agent is a quadcopter drone and it is rewarded in each time step by the environment provided by Airsim flight simulator. Drone is trained to catch the target drone by using DRL model which is based on deep Q-Network algorithm. After training, the tests have been made by the agent drone with DRL model and human pilots to catch stationary and non-stationary target drone. The training and test results show that the agent drone learns to catch target drone which can be a stationary and a non-stationary. In addition. the agent avoids crashing any obstacles in the environment with a minimum success rate of 94%. Also, DRL model performance is compared with the human pilot performances and the agent with DRL model shows better time to catch the target drone. Human pilots struggle to control the drone by using remote controller when catching the target in simulation. However, the agent with DRL model is rarely missing the target when trying to catch the target},
keywords={Training;Navigation;Atmospheric modeling;Reinforcement learning;Object detection;Real-time systems;Performance analysis;Counter-Drone;UAV;Drones;AI;Deep Reinforcement Learning;DDQN;Airsim;Image Processing},
doi={10.1109/DASC52595.2021.9594413},
ISSN={2155-7209},
month={Oct},}
@ARTICLE{9665744,
author={Li, Dongcheng and Yin, Wangping and Wong, W. Eric and Jian, Mingyong and Chau, Matthew},
journal={IEEE Access}, title={Quality-Oriented Hybrid Path Planning Based on A* and Q-Learning for Unmanned Aerial Vehicle},
year={2022},
volume={10},
number={},
pages={7664-7674},
abstract={Unmanned aerial vehicles (UAVs) are playing an increasingly important role in people’s daily lives due to their low cost of operation, low requirements for ground support, high maneuverability, high environmental adaptability, and high safety. Yet UAV path planning under various safety risks, such as crash and collision, is not an easy task, due to the complicated and dynamic nature of path environments. Therefore, developing an efficient and flexible algorithm for UAV path planning has become inevitable. Aimed at quality-oriented UAV path planning, this paper is designed to analyze UAV path planning from two aspects: global static planning and local dynamic hierarchical planning. Through a theoretical and mathematical approach, a three-dimensional UAV path planning model was established. Based on the A* algorithm, the search strategy, the step size, and the cost function were improved, and the OPEN set was simplified, thereby shortening the planning time and greatly improving the execution efficiency of the algorithm. Moreover, a dynamic exploration factor was added to the exploration mechanism of Q-learning to solve the exploration-exploitation dilemma of Q-learning to adapt to the local dynamic path adjustment for UAVs. The global-local hybrid UAV path planning algorithm was formed by combining the two. The simulation results indicate that the proposed planning model and algorithm can efficiently solve the problem of UAV path planning, improve the path quality, and can be a significant reference for solving other problems related to path planning, such as the reliability, security, and safety of UAV, when embedded into the heuristic function of the proposed algorithm.},
keywords={Path planning;Costs;Autonomous aerial vehicles;Heuristic algorithms;Planning;Turning;Q-learning;Unmanned aerial vehicle;quality-oriented path planning;A* algorithm;reinforcement learning;hierarchical planning},
doi={10.1109/ACCESS.2021.3139534},
ISSN={2169-3536},
month={},}
@INPROCEEDINGS{9615555,
author={Zhao, Yikun and Zhou, Fanqin and Li, Wenjing and Gao, Yuan and Feng, Lei and Yu, Peng},
booktitle={2021 17th International Conference on Network and Service Management (CNSM)}, title={3D Deployment and User Association of CoMP-assisted Multiple Aerial Base Stations for Wireless Network Capacity Enhancement},
year={2021},
volume={},
number={},
pages={56-62},
abstract={Deploying aerial base stations (AeBSs) has been regarded as an effective solution to wireless network capacity enhancement in specific areas with excessive traffic burden but insufficient capacity. Since the traffic distributions in wireless networks tend to be ever-changing, the deployed AeBS need to adjust its position to rapidly and continuously adapt to the drifting capacity enhancement demands, which is difficult to handle with traditional optimization methods due to high computational complexity and poor scalability. In this paper, we design a multi-agent deep reinforcement learning-based 3D AeBS deployment algorithm with the goal of maximizing the system throughput, which is able to make decisions in dynamic environments and conducts in a distributed manner. Additionally, in order to address the interference issue between multiple AeBSs, we adopt the Coordinated Multiple Points Transmission (CoMP) in the air-to-ground communication and propose a clustering algorithm to form groups of AeBSs for cooperative communication based on the network interference characteristics. Simulation results demonstrate that the proposed approach has significant throughput gains over conventional schemes without CoMP, and that the proposed multi-agent deep Q network (MADQN) is more efficient than centralized DQN in deriving the solution.},
keywords={Base stations;Three-dimensional displays;Wireless networks;Heuristic algorithms;Simulation;Scalability;Clustering algorithms;Unmanned aerial vehicle;cooperative communication;capacity enhancement;multi-agent deep reinforcement learning},
doi={10.23919/CNSM52442.2021.9615555},
ISSN={2165-963X},
month={Oct},}
@ARTICLE{9622148,
author={Dai, Bin and Niu, Jianwei and Ren, Tao and Hu, Zheyuan and Atiquzzaman, Mohammed},
journal={IEEE Transactions on Vehicular Technology}, title={Towards Energy-Efficient Scheduling of UAV and Base Station Hybrid Enabled Mobile Edge Computing},
year={2022},
volume={71},
number={1},
pages={915-930},
abstract={Mobile edge computing (MEC) has been considered as a promising paradigm to support the growing popularity of mobile devices (MDs) with similar capabilities as cloud computing. Most existing research focuses on MEC enabled by terrestrial base stations (BSs), which is unable to work in certain scenarios, e.g., disaster rescue and field operation. Some researchers have been making efforts on studying MEC assisted by unmanned-aerial-vehicles (UAVs) and developed lots of efficient scheduling algorithms. However, MEC assisted only by UAVs has limited capability and is unsuitable for heavy-computation applications. To address the issue, this paper proposes a novel UAV-and-BS hybrid enabled MEC system, where multiple UAVs and one BS are deployed to facilitate the provisioning of MEC services either directly from UAVs or indirectly from the BS. Considering maximizing the lifetime of all MDs, the energy-efficient scheduling problem is formulated as minimizing the energy consumption of all MDs by jointly optimizing UAV trajectories, task associations, computing-and-transmitting resource allocations. The optimization problem is further decomposed into three sub-problems and solved by the proposed hybrid heuristic and learning based scheduling algorithms to reduce the complexity. Experimental results show that the proposed algorithm can achieve promising performance improvements over baseline algorithms, including local-computing, random-offloading and greedy-offloading.},
keywords={Task analysis;Wireless communication;Energy consumption;Trajectory;Optimization;Resource management;Dynamic scheduling;Unmanned aerial vehicle;mobile edge computing;computation offloading;task association;deep reinforcement learning},
doi={10.1109/TVT.2021.3129214},
ISSN={1939-9359},
month={Jan},}
@ARTICLE{9044434,
author={Liu, Qian and Shi, Long and Sun, Linlin and Li, Jun and Ding, Ming and Shu, Feng},
journal={IEEE Transactions on Vehicular Technology}, title={Path Planning for UAV-Mounted Mobile Edge Computing With Deep Reinforcement Learning},
year={2020},
volume={69},
number={5},
pages={5723-5728},
abstract={In this letter, we study an unmanned aerial vehicle (UAV)-mounted mobile edge computing network, where the UAV executes computational tasks offloaded from mobile terminal users (TUs) and the motion of each TU follows a Gauss-Markov random model. To ensure the quality-of-service (QoS) of each TU, the UAV with limited energy dynamically plans its trajectory according to the locations of mobile TUs. Towards this end, we formulate the problem as a Markov decision process, wherein the UAV trajectory and UAV-TU association are modeled as the parameters to be optimized. To maximize the system reward and meet the QoS constraint, we develop a QoS-based action selection policy in the proposed algorithm based on double deep Q-network. Simulations show that the proposed algorithm converges more quickly and achieves a higher sum throughput than conventional algorithms.},
keywords={Quality of service;Trajectory;Unmanned aerial vehicles;Task analysis;Energy consumption;Edge computing;Computational modeling;Unmanned aerial vehicle;edge computing;path planning;Markov decision process;deep reinforcement learning},
doi={10.1109/TVT.2020.2982508},
ISSN={1939-9359},
month={May},}
@INPROCEEDINGS{9512618,
author={Ou, Jiajun and Guo, Xiao and Lou, Wenjie and Zhu, Ming},
booktitle={2021 IEEE International Conference on Mechatronics and Automation (ICMA)}, title={Learning the Spatial Perception and Obstacle Avoidance with the Monocular Vision on a Quadrotor},
year={2021},
volume={},
number={},
pages={582-587},
abstract={We present a learning-based framework to simultaneously realize spatial perception and obstacle avoidance in this paper. It learns to extract the visual representations of obstacles from raw monocular images using unsupervised contrastive learning. Moreover, the framework utilizes the dueling double deep recurrent Q network to learn the optimal obstacle avoidance policy using the extracted representation features. The learned policy in the framework can reduce the side effects of the onboard fixed camera's limited observation capacity by adding recurrency to stack a history of observations. Compared with other typical obstacle avoidance methods, the proposed framework is more light weighted and data-efficient. The framework is trained and evaluated in several simulation scenarios, which are built in the ROS Gazebo environment. The trained framework is capable to control the quadrotor to pass through the crowded environments in evaluation.},
keywords={Training;Learning systems;Visualization;Mechatronics;Training data;Reinforcement learning;Feature extraction;Unmanned aerial vehicle;Obstacle avoidance;Contrastive learning;Deep reinforcement learning},
doi={10.1109/ICMA52036.2021.9512618},
ISSN={2152-744X},
month={Aug},}
@ARTICLE{9497328,
author={Zhang, Meng and Fu, Shu and Fan, Qilin},
journal={IEEE Wireless Communications Letters}, title={Joint 3D Deployment and Power Allocation for UAV-BS: A Deep Reinforcement Learning Approach},
year={2021},
volume={10},
number={10},
pages={2309-2312},
abstract={Due to its high mobility and low cost, unmanned aerial vehicle mounted base station (UAV-BS) can be deployed in a fast and cost-efficient manner for providing wireless services in areas where traditional terrestrial infrastructures cannot be laid for technical and economic reasons. In this letter, we investigate the problem of joint three-dimensional (3D) deployment and power allocation for maximizing the system throughput in a UAV-BS system. To solve this non-convex problem, we propose a deep deterministic policy gradient (DDPG) based algorithm. The proposed algorithm allows the UAV-BS to explore in continuous state and action spaces to learn the optimal 3D hovering location and power allocation. Simulation results show that the proposed algorithm outperforms the traditional deep Q-learning-based method and genetic algorithm.},
keywords={Resource management;Three-dimensional displays;Throughput;Wireless communication;Unmanned aerial vehicles;Optimization;Simulation;Unmanned aerial vehicle;3D deployment;power allocation;deep reinforcement learning},
doi={10.1109/LWC.2021.3100388},
ISSN={2162-2345},
month={Oct},}
@ARTICLE{9277627,
author={Liu, Xiao and Liu, Yuanwei and Chen, Yue},
journal={IEEE Journal on Selected Areas in Communications}, title={Machine Learning Empowered Trajectory and Passive Beamforming Design in UAV-RIS Wireless Networks},
year={2021},
volume={39},
number={7},
pages={2042-2055},
abstract={A novel framework is proposed for integrating reconfigurable intelligent surfaces (RIS) in unmanned aerial vehicle (UAV) enabled wireless networks, where an RIS is deployed for enhancing the service quality of the UAV. Non-orthogonal multiple access (NOMA) technique is invoked to further improve the spectrum efficiency of the network, while mobile users (MUs) are considered as roaming continuously. The energy consumption minimizing problem is formulated by jointly designing the movement of the UAV, phase shifts of the RIS, power allocation policy from the UAV to MUs, as well as determining the dynamic decoding order. A decaying deep Q-network (D-DQN) based algorithm is proposed for tackling this pertinent problem. In the proposed D-DQN based algorithm, the central controller is selected as an agent for periodically observing the state of UAV-enabled wireless network and for carrying out actions to adapt to the dynamic environment. In contrast to the conventional DQN algorithm, the decaying learning rate is leveraged in the proposed D-DQN based algorithm for attaining a tradeoff between accelerating training speed and converging to the local optimal. Numerical results demonstrate that: 1) In contrast to the conventional Q-learning algorithm, which cannot converge when being adopted for solving the formulated problem, the proposed D-DQN based algorithm is capable of converging with minor constraints; 2) The energy dissipation of the UAV can be significantly reduced by integrating RISs in UAV-enabled wireless networks; 3) By designing the dynamic decoding order and power allocation policy, the RIS-NOMA case consumes 11.7% less energy than the RIS-OMA case.},
keywords={Heuristic algorithms;Array signal processing;Wireless networks;Trajectory;Unmanned aerial vehicles;Resource management;Decoding;Non-orthogonal multiple access;reconfigurable intelligent surfaces;reinforcement learning;trajectory design;unmanned aerial vehicle},
doi={10.1109/JSAC.2020.3041401},
ISSN={1558-0008},
month={July},}
@INPROCEEDINGS{9221115,
author={Bouhamed, Omar and Wan, Xiangpeng and Ghazzai, Hakim and Massoud, Yehia},
booktitle={2020 IEEE 6th World Forum on Internet of Things (WF-IoT)}, title={A DDPG-based Approach for Energy-aware UAV Navigation in Obstacle-constrained Environment},
year={2020},
volume={},
number={},
pages={1-6},
abstract={In this paper, we propose a three-dimensional autonomous UAV navigation framework using Deep Deterministic Policy Gradient (DDPG) learning approach. The objective is to employ a self-trained UAV as an airborne Internet of Things (IoT) unit to navigate obstacles and reach a destination point, where it can communicate with a ground sensor node with sufficiently high data rate. We develop a customized reward function which aims to minimize the distance separating the UAV and its destination while penalizing collisions. A dynamic energy threshold is also set to redirect the UAV towards the charging station in case of battery depletion. We numerically simulate the behavior of the UAV when learning the environmental obstacles, and autonomously selecting trajectories for selected scenarios. Finally, we show that our learning approach achieves close performance to the one of the graph-based Dijkstra's algorithm.},
keywords={Training;Navigation;Simulation;Urban areas;Transfer learning;Autonomous aerial vehicles;Trajectory;Autonomous navigation;deep reinforcement learning;internet of things;obstacle avoidance;unmanned aerial vehicle},
doi={10.1109/WF-IoT48130.2020.9221115},
ISSN={},
month={June},}
@ARTICLE{9520121,
author={Zhong, Ruikang and Liu, Xiao and Liu, Yuanwei and Chen, Yue},
journal={IEEE Transactions on Wireless Communications}, title={Multi-Agent Reinforcement Learning in NOMA-Aided UAV Networks for Cellular Offloading},
year={2022},
volume={21},
number={3},
pages={1498-1512},
abstract={A novel framework is proposed for cellular offloading with the aid of multiple unmanned aerial vehicles (UAVs), while non-orthogonal multiple access (NOMA) technique is employed at each UAV to further improve the spectrum efficiency of the wireless network. The optimization problem of joint three-dimensional (3D) trajectory design and power allocation is formulated for maximizing the throughput. Since ground mobile users are considered as roaming continuously, the UAVs need to be re-deployed timely based on the movement of users. In an effort to solve this pertinent dynamic problem, a K-means based clustering algorithm is first adopted for periodically partitioning users. Afterward, a mutual deep Q-network (MDQN) algorithm is proposed to jointly determine the optimal 3D trajectory and power allocation of UAVs. In contrast to the conventional deep Q-network (DQN) algorithm, the MDQN algorithm enables the experience of multi-agent to be input into a shared neural network to shorten the training time with the assistance of state abstraction. Numerical results demonstrate that: 1) the proposed MDQN algorithm is capable of converging under minor constraints and has a faster convergence rate than the conventional DQN algorithm in the multi-agent case; 2) The achievable sum rate of the NOMA enhanced UAV network is 23% superior to the case of orthogonal multiple access (OMA); 3) By designing the optimal 3D trajectory of UAVs with the MDON algorithm, the sum rate of the network enjoys 142% and 56% gains than invoking the circular trajectory and the 2D trajectory, respectively.},
keywords={Trajectory;NOMA;Resource management;Unmanned aerial vehicles;Heuristic algorithms;Cellular networks;Base stations;Deep Q-network;non-orthogonal multiple access;reinforcement learning;unmanned aerial vehicle},
doi={10.1109/TWC.2021.3104633},
ISSN={1558-2248},
month={March},}
@INPROCEEDINGS{8443226,
author={Yan, Chao and Xiang, Xiaojia},
booktitle={2018 2nd International Conference on Robotics and Automation Sciences (ICRAS)}, title={A Path Planning Algorithm for UAV Based on Improved Q-Learning},
year={2018},
volume={},
number={},
pages={1-5},
abstract={In this paper, a new learning algorithm based on improved Q-learning is proposed using for path planning of Unmanned Aerial Vehicle (UAV) in an unknown antagonistic environment. According to the optimized object of UAV's task, the reward function is designed, and a new action selection strategy and a Q-function initialization method are used to improve the performance of the proposed algorithm. We use the STAGE Scenario simulation software as the training and validation environment, and a plug-in is designed to build up the link between the environment and learning algorithms. Finally, the experimental results show that the improved method is more effective than the original method, and the proposed algorithm is feasible and effective for UAV path planning.},
keywords={Path planning;Unmanned aerial vehicles;Training;Learning (artificial intelligence);Software algorithms;Heuristic algorithms;Task analysis;unmanned aerial vehicle;reinforcement learning;Q-learning;path planning;STAGE},
doi={10.1109/ICRAS.2018.8443226},
ISSN={},
month={June},}
@ARTICLE{9605668,
author={Chen, Xianfu and Wu, Celimuge and Chen, Tao and Liu, Zhi and Zhang, Honggang and Bennis, Mehdi and Liu, Hang and Ji, Yusheng},
journal={IEEE Journal on Selected Areas in Communications}, title={Information Freshness-Aware Task Offloading in Air-Ground Integrated Edge Computing Systems},
year={2022},
volume={40},
number={1},
pages={243-258},
abstract={This paper investigates an air-ground integrated multi-access edge computing system, which is deployed by an infrastructure provider (InP). Under a business agreement with the InP, a third-party service provider provides computing services to the subscribed mobile users (MUs). MUs compete for the shared spectrum and computing resources over time to achieve their distinctive goals. From the perspective of an MU, we deliberately define the age of update to capture the staleness of information from refreshing computation outcomes. Given the system dynamics, we model the interactions among MUs as a stochastic game. In the Nash equilibrium without cooperation, each MU behaves in accordance with the local system states and conjectures. We can hence transform the stochastic game into a single-agent Markov decision process. As another major contribution, we develop an online deep reinforcement learning (RL) scheme that adopts two separate double deep Q-networks to approximate the Q-factor and the post-decision Q-factor, respectively. The deep RL scheme allows each MU to optimize the behaviours with unknown dynamic statistics. Numerical experiments show that our proposed scheme outperforms the baselines in terms of the average utility under various system conditions.},
keywords={Task analysis;Servers;Indium phosphide;III-V semiconductor materials;Games;System dynamics;Q-factor;Multi-access edge computing;unmanned aerial vehicle;stochastic games;age of update;multi-agent deep reinforcement learning},
doi={10.1109/JSAC.2021.3126075},
ISSN={1558-0008},
month={Jan},}
@ARTICLE{9360739,
author={Alnagar, Sidqy I. and Salhab, Anas M. and Zummo, Salam A.},
journal={IEEE Access}, title={Q-Learning-Based Power Allocation for Secure Wireless Communication in UAV-Aided Relay Network},
year={2021},
volume={9},
number={},
pages={33169-33180},
abstract={Unmanned aerial vehicle (UAV)-aided wireless relay networks are at risk of eavesdropping activities due to their open nature. In this paper, we study the security of a UAV-aided selective relaying wireless network in which N UAVs are employed as decode-and-forward (DF) relays linking a ground base station (BS) with L legitimate users on the ground in the presence of a passive eavesdropper ( Eave). Direct links between the ground BS and both the ground users and the eavesdropper are assumed to be blocked. The ground-to-air and air-to-ground channels are assumed to follow Rician fading model with opportunistic scheduling scheme for UAVs and users selection. In order to secure data transmissions against such an interception action, the UAV of the worst UAV-selected user link transmits a jamming artificial noise (AN) signal to degrade Eave ability in decoding the confidential information successfully. The transmission outage probability, intercept probability, and hybrid outage probability are derived and analyzed. Due to the heavy computation burden raised by increasing the number of UAVs and users as well as the difficulty in estimating the instantaneous channel state information (CSI), existing traditional optimization methods are not highly efficient in solving the considered power allocation problem. Therefore, we propose a dynamic power control scheme based on Q-learning algorithm combined with statistical CSI where the hybrid outage probability is minimized. Simulation results show that the proposed algorithm efficiently reduces the hybrid outage probability with a noticeable reduction in the computational time.},
keywords={Unmanned aerial vehicles;Resource management;Probability;Power system reliability;Relay networks (telecommunication);Jamming;Wireless networks;Unmanned aerial vehicle;Rician fading;physical layer security;outage probability;intercept probability;reinforcement learning;Q-learning;power allocation},
doi={10.1109/ACCESS.2021.3061406},
ISSN={2169-3536},
month={},}
@INPROCEEDINGS{9484604,
author={Yang, Helin and Zhao, Jun and Nie, Jiangtian and Kumar, Neeraj and Lam, Kwok-Yan and Xiong, Zehui},
booktitle={IEEE INFOCOM 2021 - IEEE Conference on Computer Communications Workshops (INFOCOM WKSHPS)}, title={UAV-Assisted 5G/6G Networks: Joint Scheduling and Resource Allocation Based on Asynchronous Reinforcement Learning},
year={2021},
volume={},
number={},
pages={1-6},
abstract={Unmanned aerial vehicles (UAVs) can be used as flying base stations (BSs) for providing wireless communications and coverage enhancement in fifth/sixth-generation (5G/6G) wireless networks. Operating multiple UAV-BSs to guarantee reliable device connectivity, intelligent control of UAV movements, and resource allocation plays an important role in dynamic UAV-assisted wireless networks. In this paper, an asynchronous advantage actor-critic (A3C) based UAVs placement and resource allocation approach is proposed to maximize the network capacity while guaranteeing the wireless service requirements of ground devices. The approach enables UAVs to intelligently update their locations and resource allocation strategy according to devices' locations, to support the favourable channel gain between UAVs and devices, and maximize network benefit. Simulations show that our presented approach achieves higher learning efficiency, network capacity and QoS satisfaction level compared to popular approaches.},
keywords={Wireless networks;Conferences;Simulation;Quality of service;Reinforcement learning;Unmanned aerial vehicles;Resource management;Unmanned aerial vehicle;wireless communication;scheduling;resource allocation;reinforcement learning},
doi={10.1109/INFOCOMWKSHPS51825.2021.9484604},
ISSN={},
month={May},}
@ARTICLE{8960481,
author={Samir, Moataz and Ebrahimi, Dariush and Assi, Chadi and Sharafeddine, Sanaa and Ghrayeb, Ali},
journal={IEEE Networking Letters}, title={Trajectory Planning of Multiple Dronecells in Vehicular Networks: A Reinforcement Learning Approach},
year={2020},
volume={2},
number={1},
pages={14-18},
abstract={The agility of unmanned aerial vehicles (UAVs) have been recently harnessed in developing potential solutions that provide seamless coverage for vehicles in areas with poor cellular infrastructure. In this letter, multiple UAVs are deployed to provide the needed cellular coverage to vehicles traveling with random speeds over a given highway segment. This letter minimizes the number of deployed UAVs and optimizes their trajectories to offer prevalent communication coverage to all vehicles crossing the highway segment while saving energy consumption of the UAVs. Due to varying traffic conditions on the highway, a reinforcement learning approach is utilized to govern the number of needed UAVs and their trajectories to serve the existing and newly arriving vehicles. Numerical results demonstrate the effectiveness of the proposed design and show that during the mission time, a minimum number of UAVs adapt their velocities in order to cover the vehicles.},
keywords={Road transportation;Trajectory;Energy consumption;Reinforcement learning;Unmanned aerial vehicles;Base stations;Vehicle dynamics;Artificial intelligence;UAVs;Trajectory Planning;Vehicular Networks;Coverage},
doi={10.1109/LNET.2020.2966976},
ISSN={2576-3156},
month={March},}
@ARTICLE{9623508,
author={Xia, Zhaoyue and Du, Jun and Wang, Jingjing and Jiang, Chunxiao and Ren, Yong and Li, Gang and Han, Zhu},
journal={IEEE Transactions on Vehicular Technology}, title={Multi-Agent Reinforcement Learning Aided Intelligent UAV Swarm for Target Tracking},
year={2022},
volume={71},
number={1},
pages={931-945},
abstract={Past few years have witnessed the widespread adoption of unmanned aerial vehicles (UAVs) in target tracking for regional monitor and strike. Most existing target tracking approaches rely on the target motion frames obtained by the camera equipped, or on ideally assuming a pre-set target trajectory. However, in practice, the real trajectory of the target cannot be perfectly known to the UAVs in advance, and also the target may intelligently adjust its flying strategy according to the environment. Besides, the limited flight performance, as well as information capture and processing capability, of a single UAV can hardly fulfill high tracking success rate requirements. To address aforementioned issues, this paper proposes an end-to-end cooperative multi-agent reinforcement learning (MARL) scheme, where UAVs are enabled to make intelligent flight decisions for cooperative target tracking, on the basis of the past and current states of the target. In order to reduce power consumption and prolong the lifetime of the UAV tracking system, the propulsion power consumption model and energy saving strategy are introduced. Moreover, to further increase the detection coverage, spatial information entropy is introduced in the tracking algorithm. Simulation results show that our proposed algorithm outperfoms the deep reinforcement learning baselines in terms of the mean episode rewards, while also yields high performances with respect to tracking success rates, power saving efficiency and detection coverage.},
keywords={Target tracking;Reinforcement learning;Unmanned aerial vehicles;Cameras;Real-time systems;Sensors;Radar;Unmanned aerial vehicles (UAVs);cooperative target tracking;multi-agent reinforcement learning (MARL);energy efficient},
doi={10.1109/TVT.2021.3129504},
ISSN={1939-9359},
month={Jan},}
@ARTICLE{9127468,
author={Faraci, Giuseppe and Grasso, Christian and Schembra, Giovanni},
journal={IEEE Journal on Selected Areas in Communications}, title={Design of a 5G Network Slice Extension With MEC UAVs Managed With Reinforcement Learning},
year={2020},
volume={38},
number={10},
pages={2356-2371},
abstract={Network slices for delay-constrained applications in 5G systems require computing facilities at the edge of the network to guarantee ultra-low latency in processing data flows generated by connected devices, which is challenging with larger volumes of data, and larger distances to the edge of the network. To address this challenge, we propose to extend 5G network slices with Unmanned Aerial Vehicles (UAV) equipped with multi-access edge computing (MEC) facilities. However, onboard computing elements (CE) consume UAV's battery power thus impacting its flight duration. We propose a framework where a System Controller (SC) can turn on and off UAV's CEs, with the possibility of offloading jobs to other UAVs, to maximize an objective function defined in terms of power consumption, job loss, and incurred delay. Management of this framework is achieved by reinforcement learning. A Markov model of the system is introduced to enable reinforcement learning and provide guidelines for the selection of system parameters. A use case is considered to demonstrate the gain achieved by the proposed framework and discuss numerical results.},
keywords={5G mobile communication;Cloud computing;Reinforcement learning;Wireless communication;Unmanned aerial vehicles;Edge computing;Delays;5G;network slicing;UAVs;reinforcement learning;Markov decision processes (MDP)},
doi={10.1109/JSAC.2020.3000416},
ISSN={1558-0008},
month={Oct},}
@INPROCEEDINGS{9691567,
author={Kaushik, Prakarsh and Garg, Armaan and Jha, Shashi Shekhar},
booktitle={2021 IEEE 18th India Council International Conference (INDICON)}, title={On Learning Multi-UAV Policy for Multi-Object Tracking and Formation Control},
year={2021},
volume={},
number={},
pages={1-6},
abstract={Autonomous navigation and formation control of multi-UAV systems poses a significant challenge for the robotic systems that operate in partially-observable, dynamic and continuous environments. This paper addresses the problem of multi-UAV formation control while cooperatively tracking a set of moving objects. The objective of the multi-UAV system is to maintain the moving objects under their joint coverage along with aligning themselves in an optimal formation for maximizing the overall area coverage. We develop a multi-agent reinforcement learning model to learn a cooperative multi-UAV policy for the multi-object tracking and formation control. We design a reward function to encode the objectives of tracking, formation and collision avoidance into the model. The proposed deep reinforcement learning based model is deployed and tested against a baseline controller using the Gazebo simulator. The result indicates that the proposed model is robust against the tracking and alignment errors outperforming the baseline model.},
keywords={Measurement;Solid modeling;Target tracking;Three-dimensional displays;Conferences;Reinforcement learning;Robustness;Unmanned Aerial Vehicles (UAVs);Deep Reinforcement Learning;Active Tracking;Formation Control;Gazebo Simulator},
doi={10.1109/INDICON52576.2021.9691567},
ISSN={2325-9418},
month={Dec},}
@ARTICLE{9154432,
author={Hu, Jingzhi and Zhang, Hongliang and Song, Lingyang and Schober, Robert and Poor, H. Vincent},
journal={IEEE Transactions on Communications}, title={Cooperative Internet of UAVs: Distributed Trajectory Design by Multi-Agent Deep Reinforcement Learning},
year={2020},
volume={68},
number={11},
pages={6807-6821},
abstract={Due to the advantages of flexible deployment and extensive coverage, unmanned aerial vehicles (UAVs) have significant potential for sensing applications in the next generation of cellular networks, which will give rise to a cellular Internet of UAVs. In this article, we consider a cellular Internet of UAVs, where the UAVs execute sensing tasks through cooperative sensing and transmission to minimize the age of information (AoI). However, the cooperative sensing and transmission is tightly coupled with the UAVs' trajectories, which makes the trajectory design challenging. To tackle this challenge, we propose a distributed sense-and-send protocol, where the UAVs determine the trajectories by selecting from a discrete set of tasks and a continuous set of locations for sensing and transmission. Based on this protocol, we formulate the trajectory design problem for AoI minimization and propose a compound-action actor-critic (CA2C) algorithm to solve it based on deep reinforcement learning. The CA2C algorithm can learn the optimal policies for actions involving both continuous and discrete variables and is suited for the trajectory design. Our simulation results show that the CA2C algorithm outperforms four baseline algorithms. Also, we show that by dividing the tasks, cooperative UAVs can achieve a lower AoI compared to non-cooperative UAVs.},
keywords={Sensors;Task analysis;Trajectory;Internet;Machine learning;Protocols;Electronic mail;Cooperative Internet of UAVs;distributed trajectory design;deep reinforcement learning},
doi={10.1109/TCOMM.2020.3013599},
ISSN={1558-0857},
month={Nov},}
@ARTICLE{8807386,
author={Cui, Jingjing and Liu, Yuanwei and Nallanathan, Arumugam},
journal={IEEE Transactions on Wireless Communications}, title={Multi-Agent Reinforcement Learning-Based Resource Allocation for UAV Networks},
year={2020},
volume={19},
number={2},
pages={729-743},
abstract={Unmanned aerial vehicles (UAVs) are capable of serving as aerial base stations (BSs) for providing both cost-effective and on-demand wireless communications. This article investigates dynamic resource allocation of multiple UAVs enabled communication networks with the goal of maximizing long-term rewards. More particularly, each UAV communicates with a ground user by automatically selecting its communicating user, power level and subchannel without any information exchange among UAVs. To model the dynamics and uncertainty in environments, we formulate the long-term resource allocation problem as a stochastic game for maximizing the expected rewards, where each UAV becomes a learning agent and each resource allocation solution corresponds to an action taken by the UAVs. Afterwards, we develop a multi-agent reinforcement learning (MARL) framework that each agent discovers its best strategy according to its local observations using learning. More specifically, we propose an agent-independent method, for which all agents conduct a decision algorithm independently but share a common structure based on Q-learning. Finally, simulation results reveal that: 1) appropriate parameters for exploitation and exploration are capable of enhancing the performance of the proposed MARL based resource allocation algorithm; 2) the proposed MARL algorithm provides acceptable performance compared to the case with complete information exchanges among UAVs. By doing so, it strikes a good tradeoff between performance gains and information exchange overheads.},
keywords={Resource management;Trajectory;Wireless communication;Communication networks;Dynamic scheduling;Stochastic processes;Reinforcement learning;Dynamic resource allocation;multi-agent reinforcement learning (MARL);stochastic games;UAV communications},
doi={10.1109/TWC.2019.2935201},
ISSN={1558-2248},
month={Feb},}
@INPROCEEDINGS{8824917,
author={Shamsoshoara, Alireza and Khaledi, Mehrdad and Afghah, Fatemeh and Razi, Abolfazl and Ashdown, Jonathan and Turck, Kurt},
booktitle={2019 16th Annual IEEE International Conference on Sensing, Communication, and Networking (SECON)}, title={A Solution for Dynamic Spectrum Management in Mission-Critical UAV Networks},
year={2019},
volume={},
number={},
pages={1-6},
abstract={In this paper, we study the problem of spectrum scarcity in a network of unmanned aerial vehicles (UAVs) during mission-critical applications such as disaster monitoring and public safety missions, where the pre-allocated spectrum is not sufficient to offer a high data transmission rate for real-time video-streaming. In such scenarios, the UAV network can lease part of the spectrum of a terrestrial licensed network in exchange for providing relaying service. In order to optimize the performance of the UAV network and prolong its lifetime, some of the UAVs will function as a relay for the primary network while the rest of the UAVs carry out their sensing tasks. Here, we propose a team reinforcement learning algorithm performed by the UAV's controller unit to determine the optimum allocation of sensing and relaying tasks among the UAVs as well as their relocation strategy at each time. We analyze the convergence of our algorithm and present simulation results to evaluate the system throughput in different scenarios.},
keywords={History;Probability density function;Smoothing methods;Noise measurement;Additives;Time measurement;Current measurement;multi-agent systems;reinforcement learning;spectrum sharing;task allocation;UAV networks},
doi={10.1109/SAHCN.2019.8824917},
ISSN={2155-5494},
month={June},}
@ARTICLE{8876694,
author={Saxena, Vidit and Jaldén, Joakim and Klessig, Henrik},
journal={IEEE Transactions on Cognitive Communications and Networking}, title={Optimal UAV Base Station Trajectories Using Flow-Level Models for Reinforcement Learning},
year={2019},
volume={5},
number={4},
pages={1101-1112},
abstract={Cellular base stations (BS) and remote radio heads can be mounted on unmanned aerial vehicles (UAV) for flexible, traffic-aware deployment. These UAV base station networks (UAVBSN) promise an unprecendented degree of freedom that can be exploited for spectral efficiency gains as well as optimal network utilization. However, the current literature lacks realistic radio and traffic models for UAVBSN deployment planning and for performance evaluation. In this paper, we propose flowlevel models (FLM) for realistically characterizing the UAVBSN performance in terms of a broad range of flow- and system-level metrics. Further, we propose a deep reinforcement learning (DRL) approach that relies on the UAVBSN FLM for learning the optimal traffic-aware UAV trajectories. For a given user traffic density and starting UAV locations, our RL approach learns the optimal UAV trajectories offline that maximizes a cumulative performance metric. We then execute the learned UAV trajectories in a discrete event simulator to evaluate online UAVBSN performance. For M = 9 UAVs deployed in a simulated Downtown San Francisco model, where the UAV trajectories are defined by N = 20 discrete actions, our approach achieves approximately a three-fold increase in the average user throughput compared to the initial UAV placement, while simultaneously balancing traffic loads across the BSs.},
keywords={Unmanned aerial vehicles;Trajectory;Base stations;Reinforcement learning;Wireless communication;Throughput;Unmanned aerial vehicles;Trajectory;Base stations;Reinforcement learning;Wireless communication;Throughput;UAV base stations;flow-level models;reinforcement learning;proximal policy optimization},
doi={10.1109/TCCN.2019.2948324},
ISSN={2332-7731},
month={Dec},}
@INPROCEEDINGS{9700536,
author={Omoniwa, Babatunji and Galkin, Boris and Dusparic, Ivana},
booktitle={2022 IEEE 19th Annual Consumer Communications Networking Conference (CCNC)}, title={Energy-aware optimization of UAV base stations placement via decentralized multi-agent Q-learning},
year={2022},
volume={},
number={},
pages={216-222},
abstract={Unmanned aerial vehicles serving as aerial base stations (UAV-BSs) can be deployed to provide wireless connectivity to ground devices in events of increased network demand, points-of-failure in existing infrastructure, or disasters. However, it is challenging to conserve the energy of UAVs during prolonged coverage tasks, considering their limited on-board battery capacity. Reinforcement learning-based (RL) approaches have been previously used to improve energy utilization of multiple UAVs, however, a central cloud controller is assumed to have complete knowledge of the end-devices’ locations, i.e., the controller periodically scans and sends updates for UAV decision-making. This assumption is impractical in dynamic network environments with UAVs serving mobile ground devices. To address this problem, we propose a decentralized Q-learning approach, where each UAVBS is equipped with an autonomous agent that maximizes the connectivity of mobile ground devices while improving its energy utilization. Experimental results show that the proposed design significantly outperforms the centralized approaches in jointly maximizing the number of connected ground devices and the energy utilization of the UAV-BSs.},
keywords={Wireless communication;Performance evaluation;Base stations;Q-learning;Decision making;Interference;Autonomous aerial vehicles;Reinforcement learning;UAV base stations;energy management;wireless connectivity},
doi={10.1109/CCNC49033.2022.9700536},
ISSN={2331-9860},
month={Jan},}
@ARTICLE{9507262,
author={Zhu, Botao and Bedeer, Ebrahim and Nguyen, Ha H. and Barton, Robert and Henry, Jerome},
journal={IEEE Transactions on Vehicular Technology}, title={UAV Trajectory Planning in Wireless Sensor Networks for Energy Consumption Minimization by Deep Reinforcement Learning},
year={2021},
volume={70},
number={9},
pages={9540-9554},
abstract={Unmanned aerial vehicles (UAVs) have emerged as a promising candidate solution for data collection of large-scale wireless sensor networks (WSNs). In this paper, we investigate a UAV-aided WSN, where cluster heads (CHs) receive data from their member nodes, and a UAV is dispatched to collect data from CHs. We aim to minimize the total energy consumption of the UAV-WSN system in a complete round of data collection. Toward this end, we formulate the energy consumption minimization problem as a constrained combinatorial optimization problem by jointly selecting CHs from clusters and planning the UAV's visiting order to the selected CHs. The formulated energy consumption minimization problem is NP-hard, and hence, hard to solve optimally. To tackle this challenge, we propose a novel deep reinforcement learning (DRL) technique, pointer network-A* (Ptr-A*), which can efficiently learn the UAV trajectory policy for minimizing the energy consumption. The UAV's start point and the WSN with a set of pre-determined clusters are fed into the Ptr-A*, and the Ptr-A* outputs a group of CHs and the visiting order of CHs, i.e., the UAV's trajectory. The parameters of the Ptr-A* are trained on small-scale clusters problem instances for faster training by using the actor-critic algorithm in an unsupervised manner. Simulation results show that the trained models based on 20-clusters and 40-clusters have a good generalization ability to solve the UAV's trajectory planning problem in WSNs with different numbers of clusters, without retraining the models. Furthermore, the results show that our proposed DRL algorithm outperforms two baseline techniques.},
keywords={Trajectory;Wireless sensor networks;Energy consumption;Unmanned aerial vehicles;Trajectory planning;Clustering algorithms;Wireless networks;Combinatorial optimization;deep reinforcement learning;trajectory planning;UAV;WSN},
doi={10.1109/TVT.2021.3102161},
ISSN={1939-9359},
month={Sep.},}
@ARTICLE{9473012,
author={Chen, Yu-Jia and Liao, Kai-Min and Ku, Meng-Lin and Tso, Fung Po and Chen, Guan-Yi},
journal={IEEE Transactions on Vehicular Technology}, title={Multi-Agent Reinforcement Learning Based 3D Trajectory Design in Aerial-Terrestrial Wireless Caching Networks},
year={2021},
volume={70},
number={8},
pages={8201-8215},
abstract={This paper investigates a dynamic 3D trajectory design of multiple cache-enabled unmanned aerial vehicles (UAVs) in a wireless device-to-device (D2D) caching network with the goal of maximizing the long-term network throughput. By storing popular content at the nearby mobile user devices, D2D caching is an efficient method to improve network throughput and alleviate backhaul burden. With the attractive features of high mobility and flexible deployment, UAVs have recently attracted significant attention as cache-enabled flying base stations. The use of cache-enabled UAVs opens up the possibility of tracking the mobility pattern of the corresponding users and serving them under limited cache storage capacity. However, it is challenging to determine the optimal UAV trajectory due to the dynamic environment with frequently changing network topology and the coexistence of aerial and terrestrial caching nodes. In response, we propose a novel multi-agent reinforcement learning based framework to determine the optimal 3D trajectory of each UAV in a distributed manner without a central coordinator. In the proposed method, multiple UAVs can cooperatively make flight decisions by sharing the gained experiences within a certain proximity to each other. Simulation results reveal that our algorithm outperforms the traditional single- and multi-agent Q-learning algorithms. This work confirms the feasibility and effectiveness of cache-enabled UAVs which serve as an important complement to terrestrial D2D caching nodes.},
keywords={Trajectory;Device-to-device communication;Wireless communication;Cache storage;Wireless sensor networks;Unmanned aerial vehicles;Throughput;Unmanned aerial vehicles (UAVs);trajectory design;wireless caching;multi-agent reinforcement learning},
doi={10.1109/TVT.2021.3094273},
ISSN={1939-9359},
month={Aug},}
@INPROCEEDINGS{9651916,
author={Wang, Yuhang and He, Ying and Dong, Minhui},
booktitle={2021 IEEE 29th International Conference on Network Protocols (ICNP)}, title={Resource Allocation in Vehicular Networks with Multi-UAV Served Edge Computing},
year={2021},
volume={},
number={},
pages={1-6},
abstract={With the rapid development of intelligent transportation systems, there is an increasingly strong demand for low-latency and high-bandwidth vehicular services, such as automatic driving assistance, emergency alarm, and infotainment. However, in some cases (e.g., traffic congestion, remote areas), the ground communication networks alone cannot meet the vast needs of vehicles. Unmanned aerial vehicles (UAVs) are flexible and deployable, which can be used as a supplement to the ground networks, to relieve the communication pressure on ground facilities, such as base stations. In this paper, we use multiple UAVs to provide services for vehicles and model the multi-UAV scenario as a collaborative multi-agent system. All UAVs share limited bandwidth resources and equip with edge computing servers to serve the vehicles. In addition, serious consequences may be caused if the delay requirements of vehicles are not satisfied. Therefore, we take vehicle safety as the top priority and the delay requirement as the constraints. Then we exploit the Lagrange multiplier to combine the constraint function and cost function, so as to reduce the resource consumption as much as possible on the premise of ensuring the safety of the vehicles. The influence of channel efficiency and computing power should also be taken into account when allocating resources. We adopt the multi-agent reinforcement learning to train the UAVs, and meanwhile introduce the attention mechanism so that each UAV can optimize itself better with the information of other UAVs. Through a large number of experiments, the effectiveness of our proposed method is verified. Particularly, in the case of strictly limiting bandwidth resources, resources can still be allocated according to vehicle needs under the premise of ensuring vehicle safety.},
keywords={Base stations;Computational modeling;Bandwidth;Reinforcement learning;Autonomous aerial vehicles;Safety;Delays;multi-UAV;security constraints;multi-agent reinforcement learning;resources allocation;attention mechanism},
doi={10.1109/ICNP52444.2021.9651916},
ISSN={2643-3303},
month={Nov},}
@INPROCEEDINGS{9473768,
author={Cicek, Cihan Tugrul},
booktitle={2021 IEEE International Conference on Communications Workshops (ICC Workshops)}, title={A Reinforcement Learning Algorithm for Data Collection in UAV-aided IoT Networks with Uncertain Time Windows},
year={2021},
volume={},
number={},
pages={1-6},
abstract={Unmanned aerial vehicles (UAVs) have been considered as an efficient solution to collect data from ground sensor nodes in Internet-of-Things (IoT) networks due to their several advantages such as flexibility, quick deployment and maneuverability. Studies on this subject have been mainly focused on problems where limited UAV battery is introduced as a tight constraint that shortens the mission time in the models, which significantly undervalues the UAV potential. Moreover, the sensors in the network are typically assumed to have deterministic working times during which the data is uploaded. In this study, we revisit the UAV trajectory planning problem with a different approach and revise the battery constraint by allowing UAVs to swap their batteries at fixed stations and continue their data collection task, hence, the planning horizon can be extended. In particular, we develop a discrete time Markov process (DTMP) in which the UAV trajectory and battery swapping times are jointly determined to minimize the total data loss in the network, where the sensors have uncertain time windows for uploading. Due to the so-called curse-of-dimensionality, we propose a reinforcement learning (RL) algorithm in which the UAV is trained as an agent to explore the network. The computational study shows that our proposed algorithm outperforms two benchmark approaches and achieves significant reduction in data loss.},
keywords={Trajectory planning;Conferences;Heuristic algorithms;Reinforcement learning;Data collection;Benchmark testing;Unmanned aerial vehicles;UAV;internet-of-things;reinforcement learning;battery swapping;time windows;uncertainty},
doi={10.1109/ICCWorkshops50388.2021.9473768},
ISSN={2694-2941},
month={June},}
@INPROCEEDINGS{9602993,
author={Wang, Hsuan-Fu and Huang, Cheng-Sen and Wang, Li-Chun},
booktitle={2021 30th Wireless and Optical Communications Conference (WOCC)}, title={RIS-assisted UAV Networks: Deployment Optimization with Reinforcement-Learning-Based Federated Learning},
year={2021},
volume={},
number={},
pages={257-262},
abstract={Unmanned Aerial Vehicles assisted (UAV-assisted) communication with Reconfigurable Intelligent Surfaces (RIS) is one of the key technologies for future 6G communication due to the advantages, such as high mobility, coverage extend, power-saving, and signal concentration. However, the deployment of UAVs to optimize the overall objective of the system is proved to be an NP-hard problem. To address the complexity issue, several approaches present heuristic algorithms as a solution. Nevertheless, the request to locate the users for heuristic algorithms can lead to an invasion of privacy. In this paper, we propose a reinforcement learning solution with the federated learning framework, each UAV as an agent with Q-table to learn the deployment via observation from the total capacity of the relayed users. In addition, UAVs update the Q-table values through federated learning with others to bring the learning process together. As UAVs do not require location information and only model parameters are exchanged, user privacy is protected. The simulation shows that the proposed method deploys the UAVs with less information obtained in advance, and reaches the ability to transmit to the users as high as possible.},
keywords={Wireless communication;Privacy;NP-hard problem;Heuristic algorithms;Reinforcement learning;Reconfigurable intelligent surfaces;Collaborative work;UAV-assisted communication;reinforcement learning;federated learning},
doi={10.1109/WOCC53213.2021.9602993},
ISSN={2379-1276},
month={Oct},}
@ARTICLE{9174950,
author={Li, Kai and Ni, Wei and Tovar, Eduardo and Guizani, Mohsen},
journal={IEEE Internet of Things Journal}, title={Joint Flight Cruise Control and Data Collection in UAV-Aided Internet of Things: An Onboard Deep Reinforcement Learning Approach},
year={2021},
volume={8},
number={12},
pages={9787-9799},
abstract={Employing unmanned aerial vehicles (UAVs) as aerial data collectors in Internet-of-Things (IoT) networks is a promising technology for large-scale environment sensing. A key challenge in UAV-aided data collection is that UAV maneuvering gives rise to buffer overflow at the IoT node and unsuccessful transmission due to lossy airborne channels. This article formulates a joint optimization of flight cruise control and data collection schedule to minimize network data loss as a partially observable Markov decision process (POMDP), where the states of individual IoT nodes can be obscure to the UAV. The problem can be optimally solvable by reinforcement learning, but suffers from the curse of dimensionality and becomes rapidly intractable with the growth in the number of IoT nodes. In practice, a UAV-aided IoT network contains a large number of network states and actions in POMDP while the up-to-date knowledge is not available at the UAV. We propose an onboard deep Q-network-based flight resource allocation scheme (DQN-FRAS) to optimize the online flight cruise control of the UAV and data scheduling given outdated knowledge on the network states. Numerical results demonstrate that DQN-FRAS reduces the packet loss by over 51%, as compared to existing nonlearning heuristics.},
keywords={Trajectory;Unmanned aerial vehicles;Data collection;Machine learning;Cruise control;Internet of Things;Resource management;Communication decisions;deep reinforcement learning;flight cruise control;Internet of Things (IoT);unmanned aerial vehicles (UAVs)},
doi={10.1109/JIOT.2020.3019186},
ISSN={2327-4662},
month={June},}
@INPROCEEDINGS{8656971,
author={Wu, Weidong and Qurishee, Murad A. and Owino, Joseph and Fomunung, Ignatius and Onyango, Mbakisya and Atolagbe, Babatunde},
booktitle={2018 IEEE International Smart Cities Conference (ISC2)}, title={Coupling Deep Learning and UAV for Infrastructure Condition Assessment Automation},
year={2018},
volume={},
number={},
pages={1-7},
abstract={We propose coupling the state-of-the-art computer technology deep learning and unmanned aerial vehicles (UAV) to automatically detect and assess the health condition of civil infrastructure such as bridges and pavements. UAV carrying high resolution camera and infrared thermography camera to collect a large amount of image data from the target infrastructure, which serves as inputs of trained deep neural networks for damage classification and condition assessment. Details of the framework that may guide the automation process are explained. We demonstrated preliminary application of using UAV and deep neural network in concrete crack and asphalt pavement distress classification. Challenges and needs for deployment of UAV and deep learning are briefly discussed in the end.},
keywords={Bridges;Inspection;Neural networks;Cameras;Standards;Drones;deep learning;UAV;Raspberry Pi;infrastructure;pavement condition;bridge inspection},
doi={10.1109/ISC2.2018.8656971},
ISSN={},
month={Sep.},}
@ARTICLE{9075277,
author={Pham, Quoc-Viet and Huynh-The, Thien and Alazab, Mamoun and Zhao, Jun and Hwang, Won-Joo},
journal={IEEE Internet of Things Journal}, title={Sum-Rate Maximization for UAV-Assisted Visible Light Communications Using NOMA: Swarm Intelligence Meets Machine Learning},
year={2020},
volume={7},
number={10},
pages={10375-10387},
abstract={As the integration of unmanned aerial vehicles (UAVs) into visible light communications (VLCs) can offer many benefits for massive-connectivity applications and services in 5G and beyond, this article considers a UAV-assisted VLC using nonorthogonal multiple-access. More specifically, we formulate a joint problem of power allocation and UAV's placement to maximize the sum rate of all users, subject to constraints on power allocation, quality of service of users, and UAV's position. Since the problem is nonconvex and NP-hard in general, it is difficult to be solved optimally. Moreover, the problem is not easy to be solved by conventional approaches, e.g., coordinate descent algorithms, due to channel modeling in VLC. Therefore, we propose using the Harris hawks optimization (HHO) algorithm to solve the formulated problem and obtain an efficient solution. We then use the HHO algorithm together with artificial neural networks to propose a design that can be used in real-time applications and avoid falling into the “local minima” trap in conventional trainers. Numerical results are provided to verify the effectiveness of the proposed algorithm and further demonstrate that the proposed algorithm/HHO trainer is superior to several alternative schemes and existing metaheuristic algorithms.},
keywords={NOMA;Resource management;5G mobile communication;Optimization;Light emitting diodes;Particle swarm optimization;Wireless communication;Artificial neural network (ANN);Harris hawks optimization (HHO);nonorthogonal multiple access (NOMA);sum-rate maximization;swarm intelligence;unmanned aerial vehicles (UAVs);visible light communications (VLCs)},
doi={10.1109/JIOT.2020.2988930},
ISSN={2327-4662},
month={Oct},}
@INPROCEEDINGS{9322190,
author={Steiger, Juaren and Lu, Ning and Sorour, Sameh},
booktitle={GLOBECOM 2020 - 2020 IEEE Global Communications Conference}, title={Learning for Path Planning and Coverage Mapping in UAV-Assisted Emergency Communications},
year={2020},
volume={},
number={},
pages={1-6},
abstract={We consider a setting in which a rotary-wing unmanned aerial vehicle (UAV) acts as an aerial base station to provide emergency communication service to an area of unknown and inhomogeneous user distribution. The UAV has communication with a ground node deployed to the area, which acts as a charging station. We are interested in two important problems in this setting, namely the path planning and coverage mapping problems. In the path planning problem, the UAV must plan its path starting and ending at the charging station, visiting a series of waypoints over which it hovers to provide coverage to surrounding users. On the other hand, the coverage mapping problem focuses on learning the distribution of user coverage over the area. We highlight the importance of learning this distribution to collect valuable data in an emergency situation. We then propose an online algorithm that simultaneously solves the path planning and coverage mapping problems using a deep learning model. We highlight the interplay and conflicting goals of path planning and coverage mapping, but show through Monte Carlo simulation that, under the correct parameters, the algorithm is able to achieve success on both problems.},
keywords={Path planning;Nonhomogeneous media;Batteries;Charging stations;Base stations;Wireless communication;Relays;UAV;wireless communications;emergency communications;machine learning;path planning;coverage},
doi={10.1109/GLOBECOM42002.2020.9322190},
ISSN={2576-6813},
month={Dec},}
@ARTICLE{9336232,
author={Mughal, Muhammad Hamza and Khokhar, Muhammad Jawad and Shahzad, Muhammad},
journal={IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing}, title={Assisting UAV Localization Via Deep Contextual Image Matching},
year={2021},
volume={14},
number={},
pages={2445-2457},
abstract={In this article, we aim to explore the potential of using onboard cameras and pre-stored geo-referenced imagery for Unmanned Aerial Vehicle (UAV) localization. Such a vision-based localization enhancing system is of vital importance, particularly in situations where the integrity of the global positioning system (GPS) is in question (i.e., in the occurrence of GPS outages, jamming, etc.). To this end, we propose a complete trainable pipeline to localize an aerial image in a pre-stored orthomosaic map in the context of UAV localization. The proposed deep architecture extracts the features from the aerial imagery and localizes it in a pre-ordained, larger, and geotagged image. The idea is to train a deep learning model to find neighborhood consensus patterns that encapsulate the local patterns in the neighborhood of the established dense feature correspondences by introducing semi-local constraints. We qualitatively and quantitatively evaluate the performance of our approach on real UAV imagery. The training and testing data is acquired via multiple flights over different regions. The source code along with the entire dataset, including the annotations of the collected images has been made public.11https://github.com/m-hamza-mughal/Aerial-Template-Matching. Up-to our knowledge, such a dataset is novel and first of its kind which consists of 2052 high-resolution aerial images acquired at different times over three different areas in Pakistan spanning a total area of around 2 km2.},
keywords={Feature extraction;Location awareness;Global Positioning System;Deep learning;Image matching;Data mining;Neural networks;Deep learning;neighborhood consensus networks;remote sensing;SIFT;template matching;UAV;vision-based localization},
doi={10.1109/JSTARS.2021.3054832},
ISSN={2151-1535},
month={},}
@INPROCEEDINGS{9498845,
author={Yang, Yuzhou and Jing, Xiaojun and Mu, Junsheng and Gao, Haitao},
booktitle={2021 International Wireless Communications and Mobile Computing (IWCMC)}, title={SNR Estimation of UAV Control Signal Based on Convolutional Neural Network},
year={2021},
volume={},
number={},
pages={780-784},
abstract={The signal-to-noise ratio (SNR) is an effective evaluation index for channel status and communication quality, and plays an important role in signal analysis. Under the gradual complexity of the unmanned aerial vehicle (UAV) remote control signal environment and the rapid development of neural network models in deep learning, this paper proposes a convolutional neural network (CNN) model-based SNR estimation method of UAV remote control signal environment. We construct a simulation dataset of UAV remote control signal with different SNRs, then train the model and its parameters, save the model with better performance and use the test set to verify the performance of the algorithm finally. The experimental result shows that the performance of the algorithm is improved compared to the two known algorithm.},
keywords={Deep learning;Wireless communication;Neural networks;Estimation;Unmanned aerial vehicles;Classification algorithms;Convolutional neural networks;UAV;Deep learning;SNR estimation},
doi={10.1109/IWCMC51323.2021.9498845},
ISSN={2376-6506},
month={June},}
@ARTICLE{8676325,
author={Liu, Chi Harold and Ma, Xiaoxin and Gao, Xudong and Tang, Jian},
journal={IEEE Transactions on Mobile Computing}, title={Distributed Energy-Efficient Multi-UAV Navigation for Long-Term Communication Coverage by Deep Reinforcement Learning},
year={2020},
volume={19},
number={6},
pages={1274-1285},
abstract={In this paper, we aim to design a fully-distributed control solution to navigate a group of unmanned aerial vehicles (UAVs), as the mobile Base Stations (BSs) to fly around a target area, to provide long-term communication coverage for the ground mobile users. Different from existing solutions that mainly solve the problem from optimization perspectives, we proposed a decentralized deep reinforcement learning (DRL) based framework to control each UAV in a distributed manner. Our goal is to maximize the temporal average coverage score achieved by all UAVs in a task, maximize the geographical fairness of all considered point-of-interests (PoIs), and minimize the total energy consumptions, while keeping them connected and not flying out of the area border. We designed the state, observation, action space, and reward in an explicit manner, and model each UAV by deep neural networks (DNNs). We conducted extensive simulations and found the appropriate set of hyperparameters, including experience replay buffer size, number of neural units for two fully-connected hidden layers of actor, critic, and their target networks, and the discount factor for remembering the future reward. The simulation results justified the superiority of the proposed model over the state-of-the-art DRL-EC3 approach based on deep deterministic policy gradient (DDPG), and three other baselines.},
keywords={Navigation;Energy consumption;Reinforcement learning;Path planning;Drones;Three-dimensional displays;UAV control;deep reinforcement learning;energy efficiency;communication coverage},
doi={10.1109/TMC.2019.2908171},
ISSN={1558-0660},
month={June},}
@ARTICLE{8432464,
author={Liu, Chi Harold and Chen, Zheyu and Tang, Jian and Xu, Jie and Piao, Chengzhe},
journal={IEEE Journal on Selected Areas in Communications}, title={Energy-Efficient UAV Control for Effective and Fair Communication Coverage: A Deep Reinforcement Learning Approach},
year={2018},
volume={36},
number={9},
pages={2059-2070},
abstract={Unmanned aerial vehicles (UAVs) can be used to serve as aerial base stations to enhance both the coverage and performance of communication networks in various scenarios, such as emergency communications and network access for remote areas. Mobile UAVs can establish communication links for ground users to deliver packets. However, UAVs have limited communication ranges and energy resources. Particularly, for a large region, they cannot cover the entire area all the time or keep flying for a long time. It is thus challenging to control a group of UAVs to achieve certain communication coverage in a long run, while preserving their connectivity and minimizing their energy consumption. Toward this end, we propose to leverage emerging deep reinforcement learning (DRL) for UAV control and present a novel and highly energy-efficient DRL-based method, which we call DRL-based energy-efficient control for coverage and connectivity (DRL-EC3). The proposed method 1) maximizes a novel energy efficiency function with joint consideration for communications coverage, fairness, energy consumption and connectivity; 2) learns the environment and its dynamics; and 3) makes decisions under the guidance of two powerful deep neural networks. We conduct extensive simulations for performance evaluation. Simulation results have shown that DRL-EC3 significantly and consistently outperform two commonly used baseline methods in terms of coverage, fairness, and energy consumption.},
keywords={Energy consumption;Task analysis;Aerospace electronics;Communication networks;Machine learning;Unmanned aerial vehicles;Energy resources;UAV control;deep reinforcement learning;energy efficiency;communication coverage},
doi={10.1109/JSAC.2018.2864373},
ISSN={1558-0008},
month={Sep.},}
@INPROCEEDINGS{5670230,
author={Oh, Soo-Hun and Suk, Jinyoung},
booktitle={ICCAS 2010}, title={Evolutionary design of the controller for the search of area with obstacles using multiple UAVs},
year={2010},
volume={},
number={},
pages={2541-2546},
abstract={Simultaneous operation of multiple UAVs enables to enhance the mission accomplishment efficiency. In order to achieve this, easily scalable control algorithms are required, and swarm intelligence having such characteristics as flexibility, robustness, decentralized control, and self-organization based on behavioral model comes into the spotlight as a practical alternative. Recently, evolutionary robotics is applied to the control of UAVs to overcome the weakness of difficulties in the logical design of behavioral rules. In this paper, the neural net controllers evolved by evolutionary robotics are applied to the control of multiple UAVs which have the mission of searching area with obstacles. Several numerical demonstrations show the proposed algorithm has superior results to those of behavior based neural net controllers designed by intuition.},
keywords={Robots;Feedforward neural networks;Unmanned aerial vehicles;Collision avoidance;Particle swarm optimization;Algorithm design and analysis;Atmospheric modeling;Multiple UAVs;Evolutionary Robotics;Swarm Intelligence;Behavioral Model;Genetic Algorithm},
doi={10.1109/ICCAS.2010.5670230},
ISSN={},
month={Oct},}
@INPROCEEDINGS{8885504,
author={Martinez-Alpiste, Ignacio and Casaseca-de-la-Higuera, Pablo and Alcaraz-Calero, Jose and Grecos, Christos and Wang, Qi},
booktitle={2019 IEEE Wireless Communications and Networking Conference (WCNC)}, title={Benchmarking Machine-Learning-Based Object Detection on a UAV and Mobile Platform},
year={2019},
volume={},
number={},
pages={1-6},
abstract={Object detection systems mounted on Unmanned Aerial Vehicles (UAVs) have gained momentum in recent years in light of the widespread use cases enabled by such systems in public safety and other areas. Machine learning has emerged as an enabler for improving the performance of object detection. However, there is little existing work that has studied the performance of the machine learning approach, which is computationally resource demanding, in a portable mobile platform for UAV based object detection in user mobility scenarios. This paper evaluates an integrated real-world testbed for this scenario, by employing commercial-off-the-shelf devices including a UAV system and a machine-learning-enabled mobile platform. It presents benchmarking results about the performance of popular machine learning and computer vision frameworks such as TensorFlow and OpenCV and the associated algorithms such as YOLO, embedded in a smartphone execution environment of limited resources. The results highlight opportunities and provide insights into technical gaps to be filled to realize real-time machine-learning-based object detection on a mobile platform with constrained resources.},
keywords={Drones;Object detection;Machine learning;Machine learning algorithms;Benchmark testing;Streaming media;Machine learning;object detection;image processing;mobile platform;UAV},
doi={10.1109/WCNC.2019.8885504},
ISSN={1558-2612},
month={April},}
@INPROCEEDINGS{8812497,
author={Chen, Zhiheng and Wang, Can and Wang, Huiguo and Li, Panwei and Li, Yuxiao and Wu, Xinyu},
booktitle={2018 IEEE International Conference on Information and Automation (ICIA)}, title={Object Detection for UAV Grasping: Solution and Analysis},
year={2018},
volume={},
number={},
pages={1078-1083},
abstract={Fast and accurate detection of the object's species and position are prerequisites for improving the efficiency of the UAV's grasping and transporting. Accurate detection of the optimal grasping box for different objects is the guarantee to improve the success rate of the UAV's grasping. The traditional UAV grasping researches frequently used external devices to acquire position and attitude information between the UAV and the object, such as using a motion capture system, but these methods have their own limitations. This paper designs an object detection system for UAV grasping. The system uses the object detection algorithm to provide the species and position information of object for UAV, and controls the UAV to fly over the object. The RGB-D sensor is used to acquire the image and depth information of object, and an optimal grasping box is trained based on the deep learning network to provide the grasping information for the UAV. The experiments show that the object detection system under the scene of UAV grasping can provide the species, localization and optimal grasping box of the object.},
keywords={Grasping;Object detection;Deep learning;Cameras;Feature extraction;Neural networks;Robots;UAV;Object Detection;Grasping;Deep Learning},
doi={10.1109/ICInfA.2018.8812497},
ISSN={},
month={Aug},}
@ARTICLE{8964365,
author={Yang, Yang and Gao, Zhen and Zhang, Yue and Yan, Qing and He, Dazhong},
journal={IEEE Access}, title={Codeword Selection for Concurrent Transmissions in UAV Networks: A Machine Learning Approach},
year={2020},
volume={8},
number={},
pages={26583-26590},
abstract={The unmanned aerial vehicles (UAVs) have been widely considered as one of the key applications for future wireless communication systems, where UAVs can be used as aerial base stations (BSs) for coverage extension, transmission improvement, emergency communication, and etc. Against this background, each UAV BS is expected to select the optimal codeword to form directional analog beams, and it is capable of achieving concurrent transmissions from multiple other UAV BSs simultaneously. However, in such a kind of UAV networks, due to the vast number of connected mobile users (MUEs), UAV BSs cannot timely and preciously select the codeword from the pre-defined codebook. Fortunately, machine learning (ML) is suitable for decreasing complexity in codeword selection, because ML could extract features from the data samples acquired in real environments. In this paper, we propose an ML approach to achieve an efficient and low complexity codeword selection for UAV networks. Specifically, we first derive the probabilities that multiple UAV BSs serve one MUE to obtain the average sum rate (ASR) in UAV networks. On that basis, we develop an ML approach to maximize the ASR, where we design a classifier based on support vector machine (SVM), where our ML approach is used for selecting the optimal codeword and maximizing the ASR in UAV networks. Third, we proposed an iterative sequential minimal optimization (SMO) training algorithm to train the data of all links between UAV BSs and MUEs, where the algorithm convergence is also discussed. Finally, we show the comparison between our proposed algorithm and the traditional methods by the simulation results. The simulation at last demonstrate our method is a more efficient solution for obtain a higher performance, where a much lower computational complexity can achieved than the traditional algorithm based on channel estimation.},
keywords={Unmanned aerial vehicles;Support vector machines;Training;Wireless communication;Feature extraction;Downlink;Antenna arrays;Machine learning;UAV networks;concurrent transmissions;codeword selection;support vector machine},
doi={10.1109/ACCESS.2020.2968533},
ISSN={2169-3536},
month={},}
@INPROCEEDINGS{8489064,
author={Nguyen, Hung and Garratt, Matthew and Abbass, Hussein},
booktitle={2018 International Joint Conference on Neural Networks (IJCNN)}, title={Apprenticeship Bootstrapping},
year={2018},
volume={},
number={},
pages={1-8},
abstract={Apprenticeship learning is a learning scheme based on the direct imitation of humans. Inverse reinforcement learning is used to learn a reward function from human data. Coupling Inverse reinforcement learning with reinforcement learning has demonstrated production of human-competitive policies. However, obtaining human subjects with the right level of skills for complex tasks can be a challenge. We propose a new learning scheme called Apprenticeship Bootstrapping to learn a composite task using human demonstrations on sub-tasks. The scenario is a ground-air interaction task with an Unmanned Aerial Vehicle that needs to maintain 3 autonomous Unmanned Ground Vehicles within range of an imaging sensor. For validation, we show that the bootstrapped policy performs as good as a policy learnt from a human performing the composite task. The method offers a clear advantage when skilled humans are available for simpler tasks that form the building blocks for a more complex task, where availability of experts is limited.},
keywords={Task analysis;Mathematical model;Learning (artificial intelligence);Unmanned aerial vehicles;Approximation algorithms;Feature extraction;Trajectory;Inverse Reinforcement Learning;Learning by Imitation;UAVs;UGVs;Ground-Air Interaction},
doi={10.1109/IJCNN.2018.8489064},
ISSN={2161-4407},
month={July},}
@ARTICLE{5978234,
author={Shin, Jongho and Kim, H. Jin and Kim, Youdan and Dixon, Warren E.},
journal={IEEE Transactions on Control Systems Technology}, title={Autonomous Flight of the Rotorcraft-Based UAV Using RISE Feedback and NN Feedforward Terms},
year={2012},
volume={20},
number={5},
pages={1392-1399},
abstract={A position tracking control system is developed for a rotorcraft-based unmanned aerial vehicle (RUAV) using robust integral of the signum of the error (RISE) feedback and neural network (NN) feedforward terms. While the typical NN-based adaptive controller guarantees uniformly ultimately bounded stability, the proposed NN-based adaptive control system guarantees semi-global asymptotic tracking of the RUAV using the RISE feedback control. The developed control system consists of an inner-loop and outer-loop. The inner-loop control system determines the attitude of the RUAV based on an adaptive NN-based linear dynamic model inversion (LDI) method with the RISE feedback. The outer-loop control system generates the attitude reference corresponding to the given position, velocity, and heading references, and controls the altitude of the RUAV by the LDI method with the RISE feedback. The linear model for the LDI is obtained by a linearization of the nonlinear RUAV dynamics during hover flight. Asymptotic tracking of the attitude and altitude states is proven by a Lyapunov-based stability analysis, and a numerical simulation is performed on the nonlinear RUAV model to validate the effectiveness of the controller.},
keywords={Control systems;Attitude control;Artificial neural networks;Adaptation models;Adaptive control;Dynamics;Uncertainty;Adaptive position tracking control system;asymptotic stability;neural networks (NNs);robust integral of the signum of the error (RISE) feedback;rotorcraft-based unmanned aerial vehicle (RUAV)},
doi={10.1109/TCST.2011.2160179},
ISSN={1558-0865},
month={Sep.},}
@INPROCEEDINGS{8554008,
author={Copur, Mert and Ozyildirim, Buse Melis and Ibrikci, Turgay},
booktitle={2018 Innovations in Intelligent Systems and Applications Conference (ASYU)}, title={Image Classification of Aerial Images Using CNN-SVM},
year={2018},
volume={},
number={},
pages={1-6},
abstract={Image classification is a very easy task for humans. Even a three years old child can classify an image instantly and without any doubt. However, teaching computers classifying images has been a working area for researchers for a long time because of the intrinsic difficulties of the task for computers. With the rise of deep learning, it has been possible to get better classification performance than before. In this work, we evaluated the performance of convolutional neural network combined with support vector machine for classifying aerial images based on presence of a vehicle.},
keywords={Support vector machines;Kernel;Feature extraction;Convolutional neural networks;Histograms;Image classification;Training;Support vector machines;convolutional neural networks;image classification;vehicle detection;aerial image;unmanned aerial vehicle},
doi={10.1109/ASYU.2018.8554008},
ISSN={},
month={Oct},}
@INPROCEEDINGS{9349416,
author={Tanveer, M. Hassan and Zhu, Hongxiao and Ahmed, Waqar and Thomas, Antony and Imran, Basit Muhammad and Salman, Muhammad},
booktitle={2021 International Conference on Computer, Control and Robotics (ICCCR)}, title={Mel-spectrogram and Deep CNN Based Representation Learning from Bio-Sonar Implementation on UAVs},
year={2021},
volume={},
number={},
pages={220-224},
abstract={In this paper, we present an approach for estimating the leaf density of trees while navigating in a forest. To this end, we consider an Unmanned Aerial Vehicle (UAV) equipped with a biosonar sensor that mimics the sonar sensors of echolocating bats. Such sensors provide a light-weight and cost-effective alternative to other widely used sensors such as camera, LiDAR and are gaining popularity among the robotics research community. The obtained echo signals during UAV navigation are processed to obtain the leaf density in the main lobe of the sonar first using a mel spectogram and then a Deep Convolutional Neural Network (CNN) trained on a set of known environment. We further evaluate our approach in simulation by considering trees with different leaf density (that is, resolution). It is seen that our method achieves promising results with an accuracy of 98.7%.},
keywords={Sonar;Vegetation;Forestry;Sonar navigation;Feature extraction;Unmanned aerial vehicles;Sensors;Unmanned Aerial Vehicle;Deep Convolutional Neural Networks;Mel-Spectogram;Unknown Environment},
doi={10.1109/ICCCR49711.2021.9349416},
ISSN={},
month={Jan},}
@INPROCEEDINGS{7260573,
author={Guanyu, Lai and Zhi, Liu and Yun, Zhang},
booktitle={2015 34th Chinese Control Conference (CCC)}, title={Image-based adaptive neural control of underactuated aerial mobile robot without direct position measurement},
year={2015},
volume={},
number={},
pages={5965-5969},
abstract={This paper proposes a new image-based adaptive neural controller for the position tracking control of the underactuated aerial mobile robots without the realtime position measurement. To realize this point, a relationship between the position tracking error and the image projection error is first established. One challenging difficulty in stabilization is the fact that the dynamics of the aerial robot is physically underactuated. To address this challenge, a new designed methodology is proposed in this work. In addition, the proposed adaptive controller does not require the explicit inertia information and has a simplified structure because of the inclusion of a new inertia estimator and an optimized structure neural network. Based on the Lyapunov synthesis, the asymptotic convergence of the position tracking error as well as the image projection error to an adjustable region of zero is proved. Lastly, the performance results are provided to verify the effectiveness of the proposed adaptive control scenario.},
keywords={Mobile robots;Visual servoing;Visualization;Position measurement;Cameras;Adaptive control;neural networks;underactuated mobile robots;visual servoing;unmanned aerial vehicle;nonlinear systems},
doi={10.1109/ChiCC.2015.7260573},
ISSN={1934-1768},
month={July},}
@INPROCEEDINGS{9238313,
author={Vasić, Mirela Kundid and Drak, Ahmad and Bugarin, Nediljko and Kružić, Stanko and Musić, Josip and Pomrehn, Christoph and Schöbel, Maximilian and Johenneken, Maximilian and Stančić, Ivo and Papić, Vladan and Herpers, Rainer},
booktitle={2020 International Conference on Software, Telecommunications and Computer Networks (SoftCOM)}, title={Deep Semantic Image Segmentation for UAV-UGV Cooperative Path Planning: A Car Park Use Case},
year={2020},
volume={},
number={},
pages={1-6},
abstract={Navigation of Unmanned Ground Vehicles (UGV) in unknown environments is an active area of research for mobile robotics. A main hindering factor for UGV navigation is the limited range of the on-board sensors that process only restricted areas of the environment at a time. In addition, most existing approaches process sensor information under the assumption of a static environment. This restrains the exploration capability of the UGV especially in time-critical applications such as search and rescue. The cooperation with an Unmanned Aerial Vehicle (UAV) can provide the UGV with an extended perspective of the environment which enables a better-suited path planning solution that can be adjusted on demand. In this work, we propose a UAV-UGV cooperative path planning approach for dynamic environments by performing semantic segmentation on images acquired from the UAV’s view via a deep neural network. The approach is evaluated in a car park scenario, with the goal of providing a path plan to an empty parking space for a ground-based vehicle. The experiments were performed on a created dataset of real-world car park images located in Croatia and Germany, in addition to images from a simulated environment. The segmentation results demonstrate the viability of the proposed approach in producing maps of the dynamic environment on demand and accordingly generating path plans for ground-based vehicles.},
keywords={Deep learning;Image segmentation;Navigation;Semantics;Autonomous aerial vehicles;Path planning;Sensors;cooperative path planning;semantic image segmentation;neural networks;unmanned ground vehicle;unmanned aerial vehicle},
doi={10.23919/SoftCOM50211.2020.9238313},
ISSN={1847-358X},
month={Sep.},}
@INPROCEEDINGS{6916236,
author={Pérez, Alberto and Chamoso, Pablo and Parra, Víctor and Sánchez, Antonio Juan},
booktitle={17th International Conference on Information Fusion (FUSION)}, title={Ground vehicle detection through aerial images taken by a UAV},
year={2014},
volume={},
number={},
pages={1-6},
abstract={Advantages in the application of intelligent approaches, such as the conjunction of artificial vision and Unmanned Aerial Vehicles (UAV), have been recently emerging. This paper presents a system capable of detecting ground vehicles through aerial images taken by a UAV in real time. In addition, the system offers the possibility to autonomously guide the UAV to keep track of a vehicle that has been previously detected.},
keywords={Vehicles;Cameras;Target tracking;Software;Computers;Neural networks;Unmanned Aerial Vehicle;Convolutional Neural Networks;Vehicle detection;Vehicle tracking;Multi-Agent Systems},
doi={},
ISSN={},
month={July},}
@INPROCEEDINGS{9699897,
author={Wang, Yaqin and Fagian, Facundo Esquivel and Ho, Kar Ee and Matson, Eric T},
booktitle={2021 Fifth IEEE International Conference on Robotic Computing (IRC)}, title={A Feature Engineering Focused System for Acoustic UAV Detection},
year={2021},
volume={},
number={},
pages={125-130},
abstract={The evolution of Unmanned Aerial Vehicles (UAVs) technology has made these devices suitable for a wide new range of applications, but it has also raised safety concerns as UAVs can be used for carrying explosives or weapons with malicious intentions. In this paper, Machine Learning (ML) algorithms are used to identify UAVs by using the sound signals they emit. We evaluate and propose a feature-based classification. Five individual features, and one combination of features are used to train four machine learning classification approaches: a neural network (NN), a support vector machine (SVM), a Gaussian Naive Bayes (GNB), and K-Nearest Neighbor (KNN). The training and testing dataset is composed of sound samples of UAVs and noise. The labels in the dataset we collected include the sound files of noise and UAVs. The results show that the combination of features outperforms the individual ones, with higher average accuracy scores.},
keywords={Support vector machines;Training;Weapons;Machine learning;Feature extraction;Autonomous aerial vehicles;Acoustics;Audio Classification;UAV Detection;Machine Learning;Drone Security;Acoustic Classification;Neural Network;Feature Extraction;Feature Engineering},
doi={10.1109/IRC52146.2021.00031},
ISSN={},
month={Nov},}
@INPROCEEDINGS{9720893,
author={Xing, Yuan and Carlson, Charles and Yuan, Holly},
booktitle={2022 IEEE 12th Annual Computing and Communication Workshop and Conference (CCWC)}, title={Optimize Path Planning for UAV COVID-19 Test Kits Delivery System by Hybrid Reinforcement Learning},
year={2022},
volume={},
number={},
pages={0177-0183},
abstract={This paper aims to solve an optimization problem in the UAV-enabled COVID-19 test kits delivery system. The UAV intends to find the optimal path to deliver the COVID-19 test kits to people with a high probability of COVID-19 infection in the shortest time. The traditional Deep Reinforcement Learning doesn't perform well in solving the optimization problem because of the slow converging speed and difficult parameters-tuning. In order to solve this problem efficiently, a low-complexity Hybrid Reinforcement Learning is proposed. The algorithm consists of a heuristic algorithm and a Q Learning algorithm. At first, a heuristic algorithm is utilized to calculate the optimal path between any two users. Next, Q learning is applied to determine the sequence of the users to deliver the COVID-19 test kits. As a result, both the delivery sequence and the specific path from one user to another can be generated. The simulation results prove the superiority of the proposed Hybrid Reinforcement Learning in solving the proposed optimization problem compared with the state-of-arts.},
keywords={COVID-19;Q-learning;Heuristic algorithms;Conferences;Simulation;Path planning;Planning;UAV-enabled delivery system;COVID-19 diag nosis;Hybrid Reinforcement Learning;Path Planning},
doi={10.1109/CCWC54503.2022.9720893},
ISSN={},
month={Jan},}
@INPROCEEDINGS{9547180,
author={Shan, Mingang and Xiong, Jian and Liu, Bo and Shi, Zhiping and Li, Xia and Miao, Ningjie},
booktitle={2021 IEEE International Symposium on Broadband Multimedia Systems and Broadcasting (BMSB)}, title={UAV Resource Cooperation Based on Reinforcement Learning},
year={2021},
volume={},
number={},
pages={1-6},
abstract={Internet of things (IoT) devices are generally incapable of transmitting data over a long distance due to their energy limitations. With the advantages of flexibility, mobility and line-of-sight links to target devices, UAV are becoming more and more widely used in data acquisition systems. Because of the limited airborne resources of UAV, we must replenish them in time. This paper focuses on the aerial replenishment strategy, which can minimizes replenishment consumption while guaranteeing the fastest completion of the mission. We employ reinforcement learning to optimize UAVs' paths and replenishment strategy. The results show that, compared to the greedy algorithm and genetic algorithm, the reinforcement learning algorithm not only has the smallest energy consumption, but also has faster convergence speed.},
keywords={Greedy algorithms;Energy consumption;Simulation;Reinforcement learning;Data collection;Internet of Things;Multimedia communication;IoT;Reinforcement learning;UAV},
doi={10.1109/BMSB53066.2021.9547180},
ISSN={2155-5052},
month={Aug},}
@INPROCEEDINGS{9623051,
author={Li, Jiankang and Liu, Yang},
booktitle={2021 8th International Conference on Dependable Systems and Their Applications (DSA)}, title={Deep Reinforcement Learning based Adaptive Real-Time Path Planning for UAV},
year={2021},
volume={},
number={},
pages={522-530},
abstract={Real-time path planning typically aims to obtain a collision-free and shorter path with lower computational complexity for UAVs in unknown environment. Apart from the above basic objective, kinematic constraints and the smoothness of path should be further considered especially for fixed-wing UAVs restricted by their maneuverability. In this paper, we propose an adaptive real-time path planning method based on Deep Reinforcement Learning. Taking the sensor data of obstacles nearby and the target’s position relative to the UAV as the decision information, and designing the action satisfying kinematic constraints of fixed-wing UAV, the proposed method can plan a feasible path for fixed-wing UAV in real-time. Experimental results show that the adaptive action devised combining with greedy reward, granularity reward and smoothness reward can accelerate the convergence speed of the algorithm and enhance the smoothness of the planned path.},
keywords={Adaptive systems;Reinforcement learning;Kinematics;Real-time systems;Path planning;Computational complexity;Convergence;adaptive;real-time path planning;deep reinforcement learning;UAV;fixed-wing},
doi={10.1109/DSA52907.2021.00077},
ISSN={2767-6684},
month={Aug},}
@INPROCEEDINGS{8997436,
author={Yue, Wei and Guan, Xianhe and Xi, Yun},
booktitle={2019 Chinese Automation Congress (CAC)}, title={Reinforcement Learning based Approach for Multi-UAV Cooperative Searching in Unknown Environments},
year={2019},
volume={},
number={},
pages={2018-2023},
abstract={In this paper, an important topic of cooperative search for multi-dynamic targets in unknown sea area by unmanned aerial vehicles (UAVs) is studied based on reinforcement learning (RL) algorithm. First of all, considering the model of environmental, UAVs dynamics, target dynamics and sensor detection, the multi-UAVs sea area search map is established, then, the search map is updated by using the concept of “Territory awareness information map and the original search map is expanded. Finally, according to the search efficiency function, a reward and punishment function is designed, and RL method is used to generate a multi-UAVs cooperative search path on-line. The simulation results show that, according to the proposed algorithm, UAVs can effectively perform the search task in the sea area with no prior information.},
keywords={Manganese;Search problems;Task analysis;Learning (artificial intelligence);Vehicle dynamics;Unmanned aerial vehicles;Uncertainty;Multi-UAVs;cooperative search;reinforcement learning;dynamic target},
doi={10.1109/CAC48633.2019.8997436},
ISSN={2688-0938},
month={Nov},}
@INPROCEEDINGS{9484490,
author={Cui, Yuling and Deng, Danhao and Wang, Chaowei and Wang, Weidong},
booktitle={IEEE INFOCOM 2021 - IEEE Conference on Computer Communications Workshops (INFOCOM WKSHPS)}, title={Joint Trajectory and Power Optimization for Energy Efficient UAV Communication Using Deep Reinforcement Learning},
year={2021},
volume={},
number={},
pages={1-6},
abstract={In recent years, unmanned aerial vehicles (UAVs) have been widely used in wireless communication, attracting intensive attentions. UAVs can not only serve as relays, but also serve as aerial base station for ground users (GUs). However, limited energy means that they cannot work for long and cover a limited area of services. In this paper, we investigate 2D UAV trajectory design and power allocation in order to maximize the UAV's service time and downlink throughput. Based on deep reinforcement learning, we propose a deep deterministic policy gradient (DDPG) algorithm for trajectory design and power allocation (TDPA) to solve the energy efficient and communication service quality problem. The simulation results show that TDPA can extend the service time of UAV, improve the communication service quality, and realize the maximization of downlink throughput, which are significantly improved compared with existing methods.},
keywords={Wireless communication;Conferences;Reinforcement learning;Throughput;Downlink;Unmanned aerial vehicles;Energy efficiency;UAV trajectory design;power allocation;energy efficient;downlink throughput;deep reinforcement learning;DDPG},
doi={10.1109/INFOCOMWKSHPS51825.2021.9484490},
ISSN={},
month={May},}
@INPROCEEDINGS{8309082,
author={Wang, Chao and Wang, Jian and Zhang, Xudong and Zhang, Xiao},
booktitle={2017 IEEE Global Conference on Signal and Information Processing (GlobalSIP)}, title={Autonomous navigation of UAV in large-scale unknown complex environment with deep reinforcement learning},
year={2017},
volume={},
number={},
pages={858-862},
abstract={Unmanned Aerial Vehicles (UAVs) based delivery is thriving. In this paper, we model autonomous navigation of UAV in large-scale unknown complex environment as a discrete-time continuous control problem and solve it using deep reinforcement learning. Without path planning or map construction, our method enables UAVs to navigate from arbitrary departure places to destinations using only sensory information of local environment and GPS signal. We argue the navigation task is a partially observable Markov decision process (POMDP) and extant recurrent deterministic policy gradient algorithm is less efficient. Consequently, we derive a faster policy learning algorithm for POMDP based on actor-critic architecture. To validate our ideas, we simulate five virtual environments and a virtual UAV flying at a fixed altitude with constant speed. Cognition of local environment is achieved by measuring distances from UAV to obstacles in multiple directions. Simulation results demonstrate the effectiveness of our method.},
keywords={Trajectory;Navigation;Approximation algorithms;Unmanned aerial vehicles;History;Autonomous robots;Machine learning;large-scale autonomous navigation;UAV delivery;deep reinforcement learning;partially observable Markov decision process},
doi={10.1109/GlobalSIP.2017.8309082},
ISSN={},
month={Nov},}
@ARTICLE{8960453,
author={Ebrahimi, Dariush and Sharafeddine, Sanaa and Ho, Pin-Han and Assi, Chadi},
journal={IEEE Transactions on Mobile Computing}, title={Autonomous UAV Trajectory for Localizing Ground Objects: A Reinforcement Learning Approach},
year={2021},
volume={20},
number={4},
pages={1312-1324},
abstract={Disaster management, search and rescue missions, and health monitoring are examples of critical applications that require object localization with high precision and sometimes in a timely manner. In the absence of the global positioning system (GPS), the radio received signal strength index (RSSI) can be used for localization purposes due to its simplicity and cost-effectiveness. However, due to the low accuracy of RSSI, unmanned aerial vehicles (UAVs) or drones may be used as an efficient solution for improved localization accuracy due to their agility and higher probability of line-of-sight (LoS). Hence, in this context, we propose a novel framework based on reinforcement learning (RL) to enable a UAV (agent) to autonomously find its trajectory that results in improving the localization accuracy of multiple objects in shortest time and path length, fewer signal-strength measurements (waypoints), and/or lower UAV energy consumption. In particular, we first control the agent through initial scan trajectory on the whole region to 1) know the number of nodes and estimate their initial locations, and 2) train the agent online during operation. Then, the agent forms its trajectory by using RL to choose the next waypoints in order to minimize the average location errors of all objects. Our framework includes detailed UAV to ground channel characteristics with an empirical path loss and log-normal shadowing model, and also with an elaborate energy consumption model. We investigate and compare the localization precision of our approach with existing methods from the literature by varying the UAV's trajectory length, energy, number of waypoints, and time. Furthermore, we study the impact of the UAV's velocity, altitude, hovering time, communication range, number of maximum RSSI measurements, and number of objects. The results show the superiority of our method over the state-of-art and demonstrates its fast reduction of the localization error.},
keywords={Trajectory;Energy consumption;Drones;Shadow mapping;Global Positioning System;Reinforcement learning;Localization;reinforcement learning;Q-Learning;unmanned aerial vehicles (UAVs);drones;trajectory planning;received signal strength (RSS)},
doi={10.1109/TMC.2020.2966989},
ISSN={1558-0660},
month={April},}
@INPROCEEDINGS{9145089,
author={Chowdhury, Md Moin Uddin and Saad, Walid and Güvenç, Ismail},
booktitle={2020 IEEE International Conference on Communications Workshops (ICC Workshops)}, title={Mobility Management for Cellular-Connected UAVs: A Learning-Based Approach},
year={2020},
volume={},
number={},
pages={1-6},
abstract={The pervasiveness of the wireless cellular network can be a key enabler for the deployment of autonomous unmanned aerial vehicles (UAVs) in beyond visual line of sight scenarios without human control. However, traditional cellular networks are optimized for ground user equipment (GUE) such as smartphones which makes providing connectivity to flying UAVs very challenging. Moreover, ensuring better connectivity to a moving cellular-connected UAV is notoriously difficult due to the complex air-to-ground path loss model. In this paper, a novel mechanism is proposed to ensure robust wireless connectivity and mobility support for cellular-connected UAVs by tuning the downtilt (DT) angles of all the ground base stations (GBSs). By leveraging tools from reinforcement learning (RL), DT angles are dynamically adjusted by using a model-free RL algorithm. The goal is to provide efficient mobility support in the sky by maximizing the received signal quality at the UAV while also maintaining good throughput performance of the ground users. Simulation results show that the proposed RL-based mobility management (MM) technique can reduce the number of handovers while maintaining the performance goals, compared to the baseline MM scheme in which the network always keeps the DT angle fixed.},
keywords={Antennas;Cellular networks;Unmanned aerial vehicles;Trajectory;3GPP;Tuning;Handover;3GPP;antenna radiation;mobility management;reinforcement learning;trajectory;UAV},
doi={10.1109/ICCWorkshops49005.2020.9145089},
ISSN={2474-9133},
month={June},}
@ARTICLE{9465215,
author={Cheng, Hai and Bertizzolo, Lorenzo and D’oro, Salvatore and Buczek, John and Melodia, Tommaso and Bentley, Elizabeth Serena},
journal={IEEE Open Journal of the Communications Society}, title={Learning to Fly: A Distributed Deep Reinforcement Learning Framework for Software-Defined UAV Network Control},
year={2021},
volume={2},
number={},
pages={1486-1504},
abstract={Control and performance optimization of wireless networks of Unmanned Aerial Vehicles (UAVs) require scalable approaches that go beyond architectures based on centralized network controllers. At the same time, the performance of model-based optimization approaches is often limited by the accuracy of the approximations and relaxations necessary to solve the UAV network control problem through convex optimization or similar techniques, and by the accuracy of the channel network models used. To address these challenges, this article introduces a new architectural framework to control and optimize UAV networks based on Deep Reinforcement Learning (DRL). Furthermore, it proposes a virtualized, `ready-to-fly' emulation environment to generate the extensive wireless data traces necessary to train DRL algorithms, which are notoriously hard to generate and collect on battery-powered UAV networks. The training environment integrates previously developed wireless protocol stacks for UAVs into the CORE/EMANE emulation tool. Our `ready-to-fly' virtual environment guarantees scalable collection of high-fidelity wireless traces that can be used to train DRL agents. The proposed DRL architecture enables distributed data-driven optimization (with up to 3.7 × throughput improvement and 0.2 × latency reduction in reported experiments), facilitates network reconfiguration, and provides a scalable solution for large UAV networks.},
keywords={Optimization;Ad hoc networks;Protocols;Drones;Emulation;Wireless sensor networks;Virtual environments;UAV networks;non-terrestrial netoworks;deep reinforcement learning;AI for wireless networks;6G},
doi={10.1109/OJCOMS.2021.3092690},
ISSN={2644-125X},
month={},}
@INPROCEEDINGS{9299806,
author={Zhang, Ning and Liu, Juan and Xie, Lingfu and Tong, Peng},
booktitle={2020 International Conference on Wireless Communications and Signal Processing (WCSP)}, title={A Deep Reinforcement Learning Approach to Energy-harvesting UAV-aided Data Collection},
year={2020},
volume={},
number={},
pages={93-98},
abstract={Unmanned aerial vehicles (UAVs) can be used as mobile relays to assist in wireless communications due to their high mobility. This paper considers UAV-assisted data collection in wireless sensor networks (WSNs), where energy harvesting is used to provide sustainable energy for the UAV. In particular, the transmission opportunities of the ground sensor nodes and the flight trajectory of the energy-harvesting-powered UAV are jointly optimized to minimize the age of information (AoI) while maintaining the UAV's energy consumption as low as possible. This problem is modeled as a Markov decision process (MDP) with relatively large state and action spaces. To break the curse of dimension and speed up the convergence, the Asynchronous Advantage Actor-Critic (A3C) algorithm is employed to make real-time decisions in the deep reinforcement learning framework. Simulation verify the effectiveness of the proposed data collection approach.},
keywords={Unmanned aerial vehicles;Data collection;Wireless sensor networks;Energy harvesting;Energy consumption;Relays;Data centers;UAV;Energy harvesting;Deep Reinforcement Learning},
doi={10.1109/WCSP49889.2020.9299806},
ISSN={2472-7628},
month={Oct},}
@INPROCEEDINGS{9691696,
author={Singh, Arshdeep and Jha, Shashi Shekhar},
booktitle={2021 IEEE 18th India Council International Conference (INDICON)}, title={Learning Safe Cooperative Policies in Autonomous Multi-UAV Navigation},
year={2021},
volume={},
number={},
pages={1-6},
abstract={The deployment of multiple Unmanned Aerial Vehicles (UAV) in constrained environments has various challenges concerning trajectory optimization with the target(s) reachability and collisions. In this paper, we formulate multi-UAV navigation in constrained environments as a multi-agent learning problem. Further, we propose a reinforcement learning based Safe-MADDPG method to learn safe and cooperative multi-UAV navigation policies in a constrained environment. The safety constraints to handle inter-UAV collisions during navigation are modeled through action corrections of the learned autonomous navigation policies using an additional safety layer. We have implemented our proposed approach on the Webots Simulator and provided a detailed analysis of the proposed solution. The results demonstrate that the proposed Safe-MADDPG approach is effective in learning safe actions for multi-UAV navigation in constrained environments.},
keywords={Navigation;Conferences;Reinforcement learning;Autonomous aerial vehicles;Safety;Task analysis;Trajectory optimization;UAV;Reinforcement Learning;Policy Gradient;Safe Navigation;Multi-agent System;Webots},
doi={10.1109/INDICON52576.2021.9691696},
ISSN={2325-9418},
month={Dec},}
@ARTICLE{7885056,
author={Zeggada, Abdallah and Melgani, Farid and Bazi, Yakoub},
journal={IEEE Geoscience and Remote Sensing Letters}, title={A Deep Learning Approach to UAV Image Multilabeling},
year={2017},
volume={14},
number={5},
pages={694-698},
abstract={In this letter, we face the problem of multilabeling unmanned aerial vehicle (UAV) imagery, typically characterized by a high level of information content, by proposing a novel method based on convolutional neural networks. These are exploited as a means to yield a powerful description of the query image, which is analyzed after subdividing it into a grid of tiles. The multilabel classification task of each tile is performed by the combination of a radial basis function neural network and a multilabeling layer (ML) composed of customized thresholding operations. Experiments conducted on two different UAV image data sets demonstrate the promising capability of the proposed method compared to the state of the art, at the expense of a higher but still contained computation time.},
keywords={Unmanned aerial vehicles;Training;Neural networks;Feature extraction;Histograms;Image segmentation;Computer architecture;Convolutional neural networks (CNNs);image multilabeling;Otsu’s algorithm;unmanned aerial vehicles (UAVs);urban monitoring},
doi={10.1109/LGRS.2017.2671922},
ISSN={1558-0571},
month={May},}
@ARTICLE{9288680,
author={Toorchi, Niloofar and Hu, Fei and Bentley, Elizabeth Serena and Kumar, Sunil},
journal={IEEE Access}, title={Skeleton-Based Swarm Routing (SSR): Intelligent Smooth Routing for Dynamic UAV Networks},
year={2021},
volume={9},
number={},
pages={1286-1303},
abstract={A swarm of unmanned aerial vehicles (UAVs) requires the transmission of mission-related data across the network. The resource constraints and dynamic nature of the swarm bring critical challenges to the design of UAV routing protocols. Most of the conventional ad hoc routing schemes are not intelligent and cannot adapt to the dynamic nature of UAV swarming networks. On the other hand, some artificial intelligence (AI)-based routing schemes may consume significant computational resources in the UAVs. In this article, a low-cost, adaptive routing protocol, namely skeleton-based swarm routing (SSR), is proposed, which exploits an intelligent online learning algorithm and the topology features of the mission-driven UAV swarm to distribute the traffic over optimal routes. Here, the skeleton represents the most stable parts of the swarm formation. SSR architecture consists of three modules: 1) A geometric addressing module, which assigns geometric coordinates to each node based on the swarm skeleton structure; 2) A leaf-like routing pipe which allows the selection of multiple candidate routes around the shortest path; 3) An intelligent low-complexity learning model which determines how to distribute the packets inside the routing pipe to achieve load-balanced, high-throughput transmissions. The proposed skeleton-based scheme can also facilitate the UAV formation construction and morphing. The simulation results show that the proposed SSR protocol can noticeably improve the network performance (up to 100% throughput improvement) compared to the single path routing schemes, such as the ad-hoc on-demand distance vector (AODV) and link-quality and traffic-load aware optimized link state routing (LTA-OLSR) protocols.},
keywords={Routing;Quality of service;Unmanned aerial vehicles;Routing protocols;Skeleton;Computer architecture;Ad hoc networks;Geometric routing;quality of service;reinforcement learning;stochastic dynamic programming;swarm networks;UAV communication},
doi={10.1109/ACCESS.2020.3043672},
ISSN={2169-3536},
month={},}
@INPROCEEDINGS{8678972,
author={Grumazescu, Constantin and Vladuta, Valentin-Alexandru and Timofte, Andrei},
booktitle={2018 10th International Conference on Electronics, Computers and Artificial Intelligence (ECAI)}, title={Hybrid identity based cryptographic scheme optimization using machine learning in WSN},
year={2018},
volume={},
number={},
pages={1-6},
abstract={Wireless sensor networks (WSN) security has become a very important issue considering the wide range of applications and implementation challenges. In this article we are proposing a machine learning based technique in order to optimize all aspects of wireless sensor network based applications that are being secured using a previously proposed Hybrid Distributed-Hierarchical Identity Based Cryptographic Scheme (HYDISH).},
keywords={Cryptography;Wireless sensor networks;Unmanned aerial vehicles;Generators;Optimization;Routing;identity;hierarchic;distributed;wireless sensor network;machine learning;unmanned aerial vehicle;sink;optimization},
doi={10.1109/ECAI.2018.8678972},
ISSN={},
month={June},}
@ARTICLE{9210562,
author={Miao, Yiming and Tang, Yuan and Alzahrani, Bander A. and Barnawi, Ahmed and Alafif, Tarik and Hu, Long},
journal={IEEE Transactions on Intelligent Transportation Systems}, title={Airborne LiDAR Assisted Obstacle Recognition and Intrusion Detection Towards Unmanned Aerial Vehicle: Architecture, Modeling and Evaluation},
year={2021},
volume={22},
number={7},
pages={4531-4540},
abstract={With the rapid development of wireless communication and flight control technologies, the unmanned aerial vehicles (UAVs) have been widely used in multiple application scenarios. A typical scenario is massive crowd management of the multi-millions annual Hajj Pilgrimage to Mecca where UAVs are widely utilized to conduct crowd monitoring by carrying sensory devices. The safe flight of a UAV is crucial for ensuring the successful execution of missions. With the aim to overcome the disadvantage caused by the ground station intrusion detection, the combination of UAV and airborne LiDAR has been widely studied in the field of UAV obstacle recognition. This article studies the UAV network architecture under a common scenario and proposes an obstacle recognition and intrusion detection algorithm for UAV based on an airborne LiDAR (ALORID). First, the preprocessing of the data obtained by a LiDAR, i.e., the coordinate conversion of LiDAR data in combination with UAV motion parameters, is completed. Then, the LiDAR data graph at the current moment is generated by the image noisy point filtering algorithm. After that, the improved density-based spatial clustering of applications with noise (DBSCAN) algorithm is used for image clustering of intrusions to obtain the LiDAR time-domain cumulative graph in a certain detection time. Finally, the motion recognition and location detection of each cluster are completed. The experiment results verify the effectiveness of the proposed algorithm in identifying the moving state of the intrusions.},
keywords={Laser radar;Unmanned aerial vehicles;Intrusion detection;Clustering algorithms;Monitoring;Image edge detection;Distance measurement;Intrusion detection;light detection and ranging;machine learning;obstacle recognition;unmanned aerial vehicle},
doi={10.1109/TITS.2020.3023189},
ISSN={1558-0016},
month={July},}
@INPROCEEDINGS{9299671,
author={Wang, Lingyu and Huang, Yang},
booktitle={2020 International Conference on Wireless Communications and Signal Processing (WCSP)}, title={UAV-Based Estimation of Direction of Arrival: An Approach Based on Image Processing},
year={2020},
volume={},
number={},
pages={1165-1169},
abstract={Direction of arrival (DOA) based localization is widely applied in interferer localization. However, conventional terrestrial DOA estimation suffers from multi-path effects and shadow fading, while the UAV-based measurement on the shortwave and the very high frequency (VHF) band is subject to stringent constraints on the weight, size and power consumption of the payloads. This paper proposes to place an directional antenna at a pan-and-tilt positioner to measure and collect RSS values for DOA estimation. Nevertheless, to address such a three-dimensional (3-D) DOA estimation, conventional estimation methods based on solving a least square minimization problem suffer high computational complexity. As a countermeasure, this paper proposes an image processing-based DOA estimation. Benefiting from image denoising and a proposed k-means clustering-based image segmentation, the proposed approach can outperform various baseline schemes, in terms of estimation accuracy, especially in the low signal-to-noise regions. Compared to the conventional estimation method, the proposed approach can significantly decrease the average running time.},
keywords={Direction-of-arrival estimation;Estimation;Antenna measurements;Interference;Directional antennas;Position measurement;Unmanned aerial vehicles;Wireless communications;direction of arrival estimation;image processing;machine learning;unmanned aerial vehicle},
doi={10.1109/WCSP49889.2020.9299671},
ISSN={2472-7628},
month={Oct},}
@INPROCEEDINGS{8886040,
author={Rydén, Henrik and Redhwan, Sakib Bin and Lin, Xingqin},
booktitle={2019 IEEE Wireless Communications and Networking Conference (WCNC)}, title={Rogue Drone Detection: A Machine Learning Approach},
year={2019},
volume={},
number={},
pages={1-6},
abstract={The emerging, practical and observed issue of how to detect rogue drones carrying terrestrial user equipment (UE) on mobile networks is addressed in this paper. This issue has drawn much attention since the rogue drones may generate excessive interference to mobile networks and may not be allowed by regulations in some regions. In this paper, we propose a novel machine learning approach to identify the rogue drones in mobile networks based on radio measurements. We apply two classification machine learning models, Logistic Regression, and Decision Tree, using features from radio measurements to identify the rogue drones. Simulation results show that the proposed machine learning solutions can achieve high rogue drone detection rate for high altitudes while not mis-classifying regular ground based UEs as rogue drone UEs.},
keywords={Drones;Machine learning;Computational modeling;Predictive models;Training;Decision trees;Long Term Evolution;Drone;Unmanned aerial vehicle;Machine learning;Radio access network},
doi={10.1109/WCNC.2019.8886040},
ISSN={1558-2612},
month={April},}
@INPROCEEDINGS{9324117,
author={Araya, Samuel N. and Fryjoff-Hung, Anna and Anderson, Andreas and Viers, Joshua H. and Ghezzehei, Teamrat A.},
booktitle={IGARSS 2020 - 2020 IEEE International Geoscience and Remote Sensing Symposium}, title={Machine Learning Based Soil Moisture Retrieval from Unmanned Aircraft System Multispectral Remote Sensing},
year={2020},
volume={},
number={},
pages={4598-4601},
abstract={We developed machine learning models to retrieve surface soil moisture (0–4 cm) from high resolution multispectral imagery, terrain attributes, and local climate covariates. Using a small unmanned aircraft system (UAS) equipped with a multispectral sensor we captured high resolution imagery in part to create a high-resolution digital elevation model (DEM) as well as quantify relative vegetation photosynthetic status. We tested four different machine learning algorithms. The boosted regression tree algorithm provided the best accuracy model with mean absolute error of 3.8 % volumetric water content. The most important variables for the prediction of soil moisture were precipitation, reflectance in the red wavelengths, potential evapotranspiration, and topographic position indices (TPI). Our results demonstrate that the dynamics of soil water status across heterogeneous terrain may be adequately described and predicted by UAS remote sensing data and machine learning. Our modeling approach and the variable importance and relationships we have assessed in this study should be useful for management and environmental modeling tasks where spatially explicit soil moisture information is important.},
keywords={Soil moisture;Remote sensing;Machine learning;Predictive models;Data models;Soil measurements;Reflectivity;Machine learning;boosted regression tree;multispectral;unmanned aerial vehicle;remote sensing;soil moisture;digital elevation model},
doi={10.1109/IGARSS39084.2020.9324117},
ISSN={2153-7003},
month={Sep.},}
@INPROCEEDINGS{8692953,
author={Wiratsin, Inon and Suchaiporn, Veerapong and Trainorapong, Pojchara and Chaichinvara, Jirachaipat and Rattanajitdamrong, Sakwaroon and Hnoohom, Narit},
booktitle={2018 International Joint Symposium on Artificial Intelligence and Natural Language Processing (iSAI-NLP)}, title={Classification of Terrain Types in Unmanned Aerial Vehicle Images},
year={2018},
volume={},
number={},
pages={1-6},
abstract={Classification of terrain images taken from an unmanned aerial vehicle (UAV) is presented in this work. The objective is to classify terrain into 5 types: building, green zone, car park, road and canal. The processing flow consists of stitching sets of 4 images to form large field of view images to covers the area of interest. The stitched images were then divided into grids, and each grid were manually labeled as one of the five terrain types. Feature extraction was performed on each grid, where the features consist of percentage of pixels whose color falls with in certain range in the HSV color space, the mean pixel value of each of the BG R channels separately, the mean pixel value of all the channels together, and the number of contours detected from binary images thresholded by simple thresholding and by Otsu's method. Three different classifiers were experimented with: k nearest neighbor, decision tree, and extra tree. Two different dataset were used for training the classifiers: raw dataset where the number of each type of grid were imbalanced due to the nature of the terrains in the area of interest, and an augmented dataset where we artificially increased the number of grids by random flips and rotation such that each class has exactly the same number of grids. A total of six stitched images were reserved for the test set. Experiment results show that best accuracy was achieved by extra tree with accuracy of 85.5%. The results also show that augmenting the training data did not improve the performance.},
keywords={Drones;Green buildings;Buildings;Feature extraction;Roads;Image color analysis;unmanned aerial vehicle;image processing;machine learning;terrain recognition},
doi={10.1109/iSAI-NLP.2018.8692953},
ISSN={},
month={Nov},}
@INPROCEEDINGS{9302744,
author={Adege, Abebe Belay and Li, Yun-Ruei and Shuai, Hong-Han and Lin, Hsin-Piao and Wang, Li-Chun},
booktitle={2020 International Conference on Pervasive Artificial Intelligence (ICPAI)}, title={Improving UAV Personalized-Tracking Services by Fusing Visual and Radio Data},
year={2020},
volume={},
number={},
pages={9-14},
abstract={This work presents a high precision unmanned aerial vehicle (UAV) communications to detect, track and locate people during moving using real-time dataset. We use a fusion of visual and radio data collected using a UAV, where the UAV is used to provide radio signals to mobile users and to collect visual and wireless datasets simultaneously. During data collection, the UAV is connected to smartphones and laptops, and the UAV is connected to a controller and an edge server through a wireless network. You only look once version4 (YOLOv4), Kalman filter, and long-short term memory (LSTM) algorithms are combined to evaluate the proposed system. YOLOv4-Kalman filter uses video inputs to detect and track people. The detail information of the bounding boxes of the detected persons is integrated with wireless data to locate people in motion. We use a variety of optimization methods, such as batch normalization, error smoothing and DROPOUT to optimize the performances of our proposed system. The proposed model improves the conventional approach by 10 % during localization.},
keywords={Wireless communication;Visualization;Unmanned aerial vehicles;Kalman filters;Wireless sensor networks;Data integration;Target tracking;unmanned aerial vehicle;data fusion;tracking and localization;deep learning},
doi={10.1109/ICPAI51961.2020.00010},
ISSN={},
month={Dec},}
@ARTICLE{9210077,
author={Zhang, Hongming and Hanzo, Lajos},
journal={IEEE Transactions on Vehicular Technology}, title={Federated Learning Assisted Multi-UAV Networks},
year={2020},
volume={69},
number={11},
pages={14104-14109},
abstract={Unmanned aerial vehicles (UAVs) have been recognized as a promising technology to be used in a wide range of civilian, public and military applications. However, given their limited payload and flight time, multiple UAVs may have to be harnessed for accomplishing complex high-level tasks, where a control center can be employed for coordinating their actions. In this article, we consider image classification tasks in UAV-aided exploration scenarios, where the coordination of multiple UAVs is implemented by a ground fusion center (GFC) positioned in a strategic, but inaccessible location, such as a mountain top, where recharging the battery is uneconomical or may even be infeasible. On-board cameras are carried by each UAV and then, federated learning (FL) is invoked for reducing the communication cost between the UAVs and the GFC, and the computational complexity imposed on the GFC. In our proposed FL-aided classification approach, initially local training is performed by each UAV based on the locally collected images to create a local model. Then, each UAV sends its locally acquired model to the GFC via a fading wireless channel, where a global model is generated, which is then fed back to each UAV for the next round of their local training. In order to further minimize the computational complexity imposed on the GFC by the UAVs, weighted zero-forcing (WZF) transmit precoding (TPC) is used at each UAV based on realistic imperfect channel state information (CSI). The system performance attained is evaluated by simulations, showing that the proposed system is capable of attaining a high classification accuracy at relatively low communication cost.},
keywords={Task analysis;Training;Unmanned aerial vehicles;Computational modeling;Cameras;Wireless communication;Fading channels;Federated learning;unmanned aerial vehicle;multi-class classification;convolutional neural network;deep learning;imperfect CSI},
doi={10.1109/TVT.2020.3028011},
ISSN={1939-9359},
month={Nov},}
@INPROCEEDINGS{9511748,
author={Saetchnikov, Ivan and Skakun, Victor and Tcherniavskaia, Elina},
booktitle={2021 IEEE 8th International Workshop on Metrology for AeroSpace (MetroAeroSpace)}, title={Efficient objects tracking from an unmanned aerial vehicle},
year={2021},
volume={},
number={},
pages={221-225},
abstract={object tracking is one of the most sophisticated and least researched tasks in computer vision, especially with respect to unmanned aerial vehicles. Primarily it caused by several challenges such as high distance to the tracking objects, variety in object sizes, camera motion, etc. This paper demonstrates the implementation of a tracking pipeline using the YOLOv4-based architecture network defined as YOLOv4eff with the doubled long-short time memory (LSTM) network for road-objects tracking. Our optimization method within YOLOv4eff addresses higher accuracy by improving the network architecture, using modified CSP techniques, Swish activation function, etc. Our object tracker used convolutional network as feature map extractor network of differential sequential frames, YOLOv4eff as detector and doubled long-short time memory (LSTM) network as tracking locations predictor. Our extensive experimental results on self-collected dataset at the height of 10-30 meters and performance comparison with other state-of-the-art tracking methods show that our LYOLOv4eff is more accurate and effectively applicable to objects tracking from a drone.},
keywords={Meters;Computer vision;Trajectory tracking;Urban areas;Pipelines;Feature extraction;Software;multi-object tracking;visual tracking;convolutional neural network;deep learning;unmanned aerial vehicle},
doi={10.1109/MetroAeroSpace51421.2021.9511748},
ISSN={2575-7490},
month={June},}
@INPROCEEDINGS{9160198,
author={Saetchnikov, Ivan and Skakun, Victor and Tcherniavskaia, Elina},
booktitle={2020 IEEE 7th International Workshop on Metrology for AeroSpace (MetroAeroSpace)}, title={Pattern recognition on aerospace images using deep neural networks},
year={2020},
volume={},
number={},
pages={336-340},
abstract={Pattern recognition is one of the most important tasks in aerospace image processing. Various methods based on convolutional neural networks attain state-of-the-art accuracy; however, their effectiveness on exact images is influenced by the chosen architecture and its training parameters.This work present methods based on convolutional neural networks for pattern recognition on the aerospace images. A possibility for objects segmentation into ten classes is demonstrated on example of the multispectral images from the World View 3 satellite. Four networks with different architectures were built, trained and optimized parametrically based on the auto-encoder neural networks. Segmentation results has been analyzed by means of three parameters: training Jacard Index, testing Jacard Index and weight numbers. The positive impact of the properly selected shearing augmentation on extension of a small marked dataset is discussed. The influence of the nonequilibrium classes on the segmentation accuracy and how to account this feature during training of deep neural networks is pointing out.},
keywords={Convolution;Image segmentation;Neural networks;Task analysis;Training;Indexes;Satellites;convolutional neural network;deep learning;unmanned aerial vehicle;pattern recognition;segmentation;autoencoder;aerospace image},
doi={10.1109/MetroAeroSpace48742.2020.9160198},
ISSN={2575-7490},
month={June},}
@INPROCEEDINGS{9326776,
author={Rao, Yinglu and Ma, Sile and Xing, Jinhao and Zhang, Heng and Ma, Xiaojing},
booktitle={2020 Chinese Automation Congress (CAC)}, title={Real time vision-based autonomous precision landing system for UAV airborne processor},
year={2020},
volume={},
number={},
pages={532-537},
abstract={Autonomous precision landing of unmanned aerial vehicle can be widely used in ocean inspection, mine inspection and other industries. Vision based autonomous precision landing research can be used in global positioning system (GPS) denied area with low cost and high accuracy which has become a hot research spot. Previous vision-based methods cannot cope with complex environmental changes while landing and can not achieve real time in airborne processor. A lightweight detection model named Myolo is designed to detect landmark. Fast contour optimization algorithm is proposed to further enhance location results. Experimental results show that Myolo can achieve 16.1 FPS which is 23 times faster than faster-RCNN and 5 times faster than yolo. After using fast local contour optimization algorithm, Myolo's position accuracy is increased to 4.2 pixel, 12.5% higher than yolo and 50.6% higher than tiny-yolo. Myolo can significantly outperforms state-of-the-art object detection model in terms of both accuracy and speed in complex landing environment.},
keywords={Optimization;Convolution;Drones;Image edge detection;Real-time systems;Prediction algorithms;Global Positioning System;Unmanned aerial vehicle;Autonomous precision landing;Deep learning;Vision-based},
doi={10.1109/CAC51589.2020.9326776},
ISSN={2688-0938},
month={Nov},}
@ARTICLE{9220104,
author={Giang, Tuan Linh and Dang, Kinh Bac and Toan Le, Quang and Nguyen, Vu Giang and Tong, Si Son and Pham, Van-Manh},
journal={IEEE Access}, title={U-Net Convolutional Networks for Mining Land Cover Classification Based on High-Resolution UAV Imagery},
year={2020},
volume={8},
number={},
pages={186257-186273},
abstract={Mining activities are the leading cause of deforestation, land-use changes, and pollution. Land use/cover mapping in Vietnam every five years is not useful to monitor land covers in mining areas, especially in the Central Highland region. It is necessary to equip managers with a better tool to monitor and map land cover using high-resolution images. Therefore, the authors proposed using the U-Net convolutional network for land-cover classification based on multispectral Unmanned aerial vehicle (UAV) image in a mining area of Daknong province, Vietnam. An area of 0.5kmx0.8km was used for training and testing seven U-Net models using seven optimizer function types. The final U-Net model can interpret six land cover types: (1) open-case mining lands, (2) old permanent croplands, (3) young permanent croplands, (4) grasslands, (5) bare soils, (6) water bodies. As a result, two models using Nadam and Adadelta optimizer function can be used to classify six land cover types with accuracy higher than 83%, especially in open-case mining lands and polluted streams flowed out from the mining areas. The trained U-Net models can potentially update new land cover types in other mining areas towards monitoring land cover changes in real-time in the future.},
keywords={Unmanned aerial vehicles;Monitoring;Data mining;Deep learning;Soil;Real-time systems;Computational modeling;U-Net convolutional network;unmanned aerial vehicle;deep learning;Daknong;segmentation;permanent cropland;open-cast mining;loss function;optimization},
doi={10.1109/ACCESS.2020.3030112},
ISSN={2169-3536},
month={},}
@INPROCEEDINGS{8965752,
author={Chen, Shikun and Lu, Xiaobo and Li, Yongbin and Wu, Renliang},
booktitle={2019 12th International Congress on Image and Signal Processing, BioMedical Engineering and Informatics (CISP-BMEI)}, title={A Convolutional Neural Network for Real-Time Vehicle Detection Under the Unmanned Aerial Vehicle Platform},
year={2019},
volume={},
number={},
pages={1-6},
abstract={The detection of vehicles under the unmanned aerial vehicle platform has several technical challenges. Compared with surveillance videos, aerial videos have more complex background and broader range which lead to larger space for searching. It is also difficult to build a effective background model due to the movement of the unmanned aerial vehicle. The low performance of development board on the aerial vehicle also make it difficult to perform real-time detection. We proposes a convolutional neural network to carry out real-time detection of vehicles under the unmanned aerial vehicle platform. Multi-scale anchor design is carried out to improve the adaptability to different vehicles and the algorithm is time optimized based on the binary weight network. As a consequence, our algorithm runs at 28.8 FPS with average precision of 91.2% under the unmanned aerial vehicle platform.},
keywords={deep learning;unmanned aerial vehicle;convolution neural network;real-time;vehicle detection},
doi={10.1109/CISP-BMEI48845.2019.8965752},
ISSN={},
month={Oct},}
@INPROCEEDINGS{9217205,
author={Liu, Jie and Wang, Qiang and Li, Xuan and Zhang, Wenqi},
booktitle={2020 IEEE 31st Annual International Symposium on Personal, Indoor and Mobile Radio Communications}, title={A Fast Deployment Strategy for UAV Enabled Network Based on Deep Learning},
year={2020},
volume={},
number={},
pages={1-6},
abstract={In this paper, a fast deployment strategy of unmanned aerial vehicles (UAVs) served as base stations (BSs) in an object region is investigated. To be specific, it solves a problem of how to find proper BSs position for multi-UAV as quickly as possible, and it also achieves the goal of maximizing the sum of downlink rates in a communication network. For this purpose, we design a geographical position information learning (GPI-Learning) algorithm to learn the GPI relationship between users and UAVs. This approach consumes less time by avoiding calculation of exact channels and fills a gap existed in the scenario of setting multi-UAV rapidly to serve multi-user. Without loss of generality, we apply GPI-Learning in different scenarios, such as changes in user number or area size. As for different area size, simulation reveals that a proper size is adequate to any smaller size on condition that the smaller size is included in training set. Numerical results witness the good performance of our proposed algorithm.},
keywords={Machine learning;Neural networks;Learning (artificial intelligence);Land mobile radio;Business;Unmanned aerial vehicles;Base stations;unmanned aerial vehicle;fast deployment;communication service;deep learning},
doi={10.1109/PIMRC48278.2020.9217205},
ISSN={2166-9589},
month={Aug},}
@INPROCEEDINGS{8929613,
author={Arvind, C.S. and Prajwal, R and Bhat, Prithvi Narayana and Sreedevi, A and Prabhudeva, K N},
booktitle={TENCON 2019 - 2019 IEEE Region 10 Conference (TENCON)}, title={Fish Detection and Tracking in Pisciculture Environment using Deep Instance Segmentation},
year={2019},
volume={},
number={},
pages={778-783},
abstract={This study presents a novel approach in detecting and tracking of fish in pisciculture. Pisciculture in general involves challenging tasks of counting and monitoring fish in natural or nature like, man-made habitats such as inland fisheries for breeding, feeding and sorting purposes. These are presently achieved using conventional methods that are inefficient when implemented in large-scale commercial productions. To overcome such difficulties and improve the efficiency of the processes, images of fish and fish seeds are captured in natural murky water habitats through a vision sensor on board an unmanned aerial vehicle (UAV). In this research paper, a deep instance segmentation algorithm called Mask R-CNN along with GOTURN tracking algorithm is employed for real time fish detection and tracking. A comparison study is also carried out (i) fish detection on high resolution images (ii) fish detection on high resolution image multi-region parallel processing (iii) fish detection on high resolution image multi-region parallel processing with tracking. The results are found to be accurate with image multi-region parallel processing along with tracking, with an F1 score of 0.91 at 16 frames per seconds on in-land fishes environment.},
keywords={Fish;Aquaculture;Unmanned aerial vehicles;Training;Machine learning;Image segmentation;Real-time systems;Pisciculture;Deep learning;Mask-RCNN;GOTURN;Unmanned aerial vehicle;Region Proposal Network;filter pyramid network},
doi={10.1109/TENCON.2019.8929613},
ISSN={2159-3450},
month={Oct},}
@INPROCEEDINGS{9476864,
author={Sanna, Giovanni and Godio, Simone and Guglieri, Giorgio},
booktitle={2021 International Conference on Unmanned Aircraft Systems (ICUAS)}, title={Neural Network Based Algorithm for Multi-UAV Coverage Path Planning},
year={2021},
volume={},
number={},
pages={1210-1217},
abstract={This paper proposes a method to tackle the Coverage Path Planning (CPP) problem for a fleet of AI-driven UAVs while accounting for congestion, collision avoidance, and efficiency of the path. The algorithm relies on a mixed-use of decentralized Artificial Neural Networks (ANN) and the A* pathfinder. Each UAV has elementary cognitive skills to sense information about the nearby environment which are then fed as an input to the network. The neural network creates a correlation between the current state of a UAV and the best action to take at each time step. The exploration strategy is stored in a labeled database for the single-UAV case; the neural network learns and replicates it in the multi-UAV case, being able to generalize the acquired skills over new maps not contained in the database. The training session imitates human priors in a multi-class classification, which completely bypasses common drawbacks such as the need for large databases or high computational resources. The case study focuses on complex urban areas, for which the grid resolution of the traditional approaches can't model the problem with sufficient accuracy.},
keywords={Training;Correlation;Databases;Computational modeling;Urban areas;Artificial neural networks;Path planning;Neural Network;Artificial Intelligence;UAV;Supervised Imitation Learning;Urban Coverage Path Planning},
doi={10.1109/ICUAS51884.2021.9476864},
ISSN={2575-7296},
month={June},}
@ARTICLE{8808853,
author={Alshehri, Aaliyah and Bazi, Yakoub and Ammour, Nassim and Almubarak, Haidar and Alajlan, Naif},
journal={IEEE Access}, title={Deep Attention Neural Network for Multi-Label Classification in Unmanned Aerial Vehicle Imagery},
year={2019},
volume={7},
number={},
pages={119873-119880},
abstract={The multi-label classification problem in Unmanned Aerial Vehicle (UAV) images is particularly challenging compared to single-label classification due to its combinatorial nature. To tackle this issue, we propose in this paper a deep learning approach based on encoder-decoder neural network architecture with channel and spatial attention mechanisms. Specifically, the encoder module which is based on a pre-trained convolutional neural network (CNN) has the task to transform the input image to a set of feature maps using an opportune feature combination. To improve the feature representation further, this module incorporates a squeeze excitation (SE) layer for modelling the interdependencies between the channels of the feature maps. The decoder module which is based on a long short terms memory (LSTM) network has the task of generating, in a sequential way, the classes present in the image. At each time step, it predicts the next class-label by aligning its hidden state to the corresponding region in the image by means of an adaptive spatial attention mechanism. The experiments carried out on two UAV datasets with a spatial resolution of 2-cm show that our method is promising in predicting the labels present in the image while attending the relevant objects in the image. Additionally, it is able to provide better classification results compared to state-of-the-art methods.},
keywords={Computer architecture;Task analysis;Logic gates;Unmanned aerial vehicles;Neural networks;Correlation;Deep learning;UAV imagery;deep learning;attention neural network;multi-label image classification},
doi={10.1109/ACCESS.2019.2936616},
ISSN={2169-3536},
month={},}


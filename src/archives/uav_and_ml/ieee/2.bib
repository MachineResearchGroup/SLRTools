@ARTICLE{9036089,
author={Liu, Chang and Li, Huiying and Su, Anyang and Chen, Shengbo and Li, Wenhui},
journal={IEEE Geoscience and Remote Sensing Letters}, title={Identification and Grading of Maize Drought on RGB Images of UAV Based on Improved U-Net},
year={2021},
volume={18},
number={2},
pages={198-202},
abstract={A prerequisite for solving many agricultural problems is to accurately estimate the area affected by crop disasters and its severity rating. In this letter, we propose a pipeline to segment the drought area and distinguish the severity rating of the maize on RGB images accessed by an unmanned aerial vehicle (UAV) through a semantic segmentation method based on deep learning. First, the ground truth is created through expert evaluation and visual interpretation with the aid of the Normalized Difference Vegetation Index (NDVI). The neural network structure that was used is based on U-Net. Some structural and parameter improvements on U-net were made using SE-ResNeXt-50 as the backbone with the atrous spatial pyramid pooling (ASPP) module. By using RGB images as the input of the neural network for training, the final trained network can work on RGB images captured by a consumer UAV. The experimental results showed that our pipeline achieved an F1-score of 0.9034 and a Jaccard index of 0.8287 on the test set.},
keywords={Convolution;Feature extraction;Indexes;Unmanned aerial vehicles;Image segmentation;Agriculture;Semantics;Convolutional neural networks (CNNs);maize drought identification;semantic segmentation;U-Net;unmanned aerial vehicle (UAV) imagery},
doi={10.1109/LGRS.2020.2972313},
ISSN={1558-0571},
month={Feb},}
@ARTICLE{9099309,
author={Zhang, Jian and Yu, Zhitao and Mao, Shiwen and Periaswamy, Senthilkumar C. G. and Patton, Justin and Xia, Xue},
journal={IEEE Access}, title={IADRL: Imitation Augmented Deep Reinforcement Learning Enabled UGV-UAV Coalition for Tasking in Complex Environments},
year={2020},
volume={8},
number={},
pages={102335-102347},
abstract={Recent developments in Unmanned Aerial Vehicles (UAVs) and Unmanned Ground Vehicles (UGVs) have made them highly useful for various tasks. However, they both have their respective constraints that make them incapable of completing intricate tasks alone in many scenarios. For example, a UGV is unable to reach high places, while a UAV is limited by its power supply and payload capacity. In this paper, we propose an Imitation Augmented Deep Reinforcement Learning (IADRL) model that enables a UGV and UAV to form a coalition that is complementary and cooperative for completing tasks that they are incapable of achieving alone. IADRL learns the underlying complementary behaviors of UGVs and UAVs from a demonstration dataset that is collected from some simple scenarios with non-optimized strategies. Based on observations from the UGV and UAV, IADRL provides an optimized policy for the UGV-UAV coalition to work in an complementary way while minimizing the cost. We evaluate the IADRL approach in an visual game-based simulation platform, and conduct experiments that show how it effectively enables the coalition to cooperatively and cost-effectively accomplish tasks.},
keywords={Task analysis;Unmanned aerial vehicles;Machine learning;Navigation;Resource management;Gallium nitride;Land vehicles;Unmanned aerial vehicle (UAV);unmanned ground vehicle (UGV);coalition;deep reinforcement learning (DRL);imitation learning},
doi={10.1109/ACCESS.2020.2997304},
ISSN={2169-3536},
month={},}
@INPROCEEDINGS{9348616,
author={Zhong, Xukai and Huo, Yiming and Dong, Xiaodai and Liang, Zhonghua},
booktitle={2020 IEEE 92nd Vehicular Technology Conference (VTC2020-Fall)}, title={Deep Q-Network Based Dynamic Movement Strategy in a UAV-Assisted Network},
year={2020},
volume={},
number={},
pages={1-6},
abstract={Unmanned aerial vehicle (UAV)-assisted communications is a promising solution to improve the performance of future wireless networks, where UAVs are deployed as base stations for enhancing the quality of service (QoS) provided to ground users when traditional terrestrial base stations are unavailable or not sufficient. An effective framework is proposed in this paper to manage the dynamic movement of multiple unmanned aerial vehicles (UAVs) in response to ground user mobility, with the objective to maximize the sum data rate of the ground users. First, we discuss the relationship between the air-to-ground (A2G) path loss (PL) and the location of UAVs. Then a deep Q-network (DQN) based method is proposed to adjust the locations of UAVs to maximize the sum data rate of the user equipment (UE). Finally, simulation results show that the proposed method is capable of adjusting UAV locations in a real-time condition to improve the QoS of the entire network.},
keywords={Base stations;Heuristic algorithms;Wireless networks;Quality of service;Unmanned aerial vehicles;Real-time systems;Vehicle dynamics;Unmanned aerial vehicle (UAV);UAV-assisted network;reinforcement learning;user equipment (UE);quality of service (QoS)},
doi={10.1109/VTC2020-Fall49728.2020.9348616},
ISSN={2577-2465},
month={Nov},}
@ARTICLE{8520858,
author={Mukherjee, Anandarup and Misra, Sudip and Chandra, Vadde Santosha Pradeep and Obaidat, Mohammad S.},
journal={IEEE Internet of Things Journal}, title={Resource-Optimized Multiarmed Bandit-Based Offload Path Selection in Edge UAV Swarms},
year={2019},
volume={6},
number={3},
pages={4889-4896},
abstract={This paper looks into the problem of a decentralized data offloading within an edge unmanned aerial vehicle (UAV) swarm to mitigate the complexities of a single UAV continually generating and processing large application-specific data. The mobile edge UAVs considered here are multirotor types having constrained energy and processing power, which makes long-term handling of large data volumes impossible for standalone UAVs. The load mitigation is carried out by offloading data from a source UAV to other swarm members with sufficient energy and processing requirements. In this paper, we focus on selecting the most optimal multihop path through the UAVs concerning available energies and processing resources, which can survive the duration of the data offload between the source and a target UAV. We formulate a multiarmed bandit-based offload path selection scheme, which selects the most energy and processing optimized multihop path between a source and a target UAV. Upon comparison of our scheme against the naive shortest path approach, we observe that our approach results in significant savings of collective network energies, even for long operational durations.},
keywords={Task analysis;Unmanned aerial vehicles;Routing;Internet of Things;Collaboration;Bandwidth;Relays;Data offloading;edge unmanned aerial vehicle (UAV) network;multiarmed bandits (MABs);path selection;reinforcement learning;UAV swarm},
doi={10.1109/JIOT.2018.2879459},
ISSN={2327-4662},
month={June},}
@INPROCEEDINGS{8482830,
author={Xu, Yinbo and Liu, Zhihong and Wang, Xiangke},
booktitle={2018 37th Chinese Control Conference (CCC)}, title={Monocular Vision based Autonomous Landing of Quadrotor through Deep Reinforcement Learning},
year={2018},
volume={},
number={},
pages={10014-10019},
abstract={An improved deep reinforcement learning (DRL) method is proposed to solve autonomous landing problem of quadrotor. Autonomous landing is a significant function for unmanned aerial vehicle (UAV) such as quadrotor. Previous solutions are mainly based on relative position calculation or the landmark detection, which either needs massive additional sensors or lacks intelligence. In this paper, we focus on realizing autonomous landing through DRL method. Whole landing process is implemented by an improved deep Q-learning network (DQN) based end-to-end control scheme. Only one down-looking camera is used to capture raw images directly as input states. An Aruco tag is placed at the landing region for feature extraction. Double network and the dueling architecture are applied to improve DQN algorithm. Besides, the reward function is well designed to fit the auto-landing scenario. The experiments show that the improved DQN can make the quadrotor land on the landmark successfully and achieve better performance while comparing to the original deep Q-learning solution.},
keywords={Training;Computer architecture;Machine learning;Cameras;Feature extraction;Neural networks;Unmanned aerial vehicles;Unmanned Aerial Vehicle (UAV);Autonomous Landing;Deep Reinforcement Learning (DRL);DQN},
doi={10.23919/ChiCC.2018.8482830},
ISSN={1934-1768},
month={July},}
@INPROCEEDINGS{7019067,
author={Sharma, Rajneesh},
booktitle={2014 Innovative Applications of Computational Intelligence on Power, Energy and Controls with their impact on Humanity (CIPECH)}, title={Fuzzy Q learning based UAV autopilot},
year={2014},
volume={},
number={},
pages={29-33},
abstract={Navigation and control of an unmanned aerial vehicle (UAV) is a challenging problem and could be framed as a Reinforcement Learning (RL) task. Herein, we propose to use reinforcement learning for designing a UAV autopilot based on the Fuzzy Q Learning (FQL) approach. Proposed control scheme envisages an amalgamation of proportional (P) control that stabilizes the UAV and an action triggering Fuzzy Inference system (FIS) control that learns the correct control action to achieve the desired flight trajectory for a UAV flight. We test the proposed RL based UAV control for three cases: (i) Altitude control (ii) Trajectory Tracking, and (iii) Reconnaissance flight of a UAV. Results demonstrate the viability and effectiveness of a UAV autopilot designed using FQL.},
keywords={Learning (artificial intelligence);Trajectory;Fuzzy logic;Reconnaissance;Computational intelligence;Vectors;Navigation;Reinforcement Learning;FQL;UAV},
doi={10.1109/CIPECH.2014.7019067},
ISSN={},
month={Nov},}
@INPROCEEDINGS{7022455,
author={Bandala, Argel A. and Vicerra, Ryan Rhay P. and Dadios, Elmer P.},
booktitle={TENCON 2014 - 2014 IEEE Region 10 Conference}, title={Formation stabilization algorithm for swarm tracking in unmanned aerial vehicle (UAV) quadrotors},
year={2014},
volume={},
number={},
pages={1-6},
abstract={This paper presents swarm formation algorithm for swarm tracking behavior in multi robotic system of flying quadrotor unmanned aerial vehicles (QUAV). Multi robotic system ensures the success of the task through the increase in members of the swarm. This characteristic is very suitable for tracking moving objects. Another key feature would be the decentralized processing of the swarm. The loss of a swarm member would not contribute significantly to the swarm. The behaviors were patterned to biological traits of insects and animals and are applied to computer applications. Simulations were performed and results showed that swarm tracking accuracy yielded 89.23%. This result is due to the accuracy of 84.65% of the formation behavior of the swarm. Furthermore, the aggregation behavior further contributed with an accuracy of 90.62%.},
keywords={Robot kinematics;Accuracy;Target tracking;Animals;Unmanned aerial vehicles;Swarm robotics;Swarm Intelligence;Social Behaviors;Unmanned Aerial Vehicle;Swarm Tracking. (key words)},
doi={10.1109/TENCON.2014.7022455},
ISSN={2159-3450},
month={Oct},}
@INPROCEEDINGS{5498477,
author={Chao Zhang and Zhen, Ziyang and Daobo Wang and Meng Li},
booktitle={2010 Chinese Control and Decision Conference}, title={UAV path planning method based on ant colony optimization},
year={2010},
volume={},
number={},
pages={3790-3792},
abstract={A new UAV path planning method based on ant colony optimization (ACO) is presented. The target position is considered as the food source which the ants are going to find. The enemy defense region is considered as the searching area of the ants and is divided into equally spaced grids. The ants move to the destination node through several nodes on the grid region. The visibility function of ACO algorithm considers the enemy threats intensity on the paths and the distance to the destination node. The weighted sums of the flight path length, the threat cost and the maximum restriction of the yaw angle are considered as the evaluation function of ACO algorithm. The pheromone amounts on the paths are updated according to the evaluation function values. Therefore, the UAV optimal flight path is expressed by a group of node number, which is obtained by the ants finding the optimal route to the food source. The ACO algorithm based UAV path planning method is characterized as simple coding and good optimization guidance, and the simulation results also show its effectiveness.},
keywords={Unmanned aerial vehicles;Path planning;Ant colony optimization;Particle swarm optimization;Radar tracking;Chaos;Educational institutions;Automation;Cost function;Navigation;Unmanned Aerial Vehicle;Path Planning;Ant Colony Optimization;Swarm Intelligence},
doi={10.1109/CCDC.2010.5498477},
ISSN={1948-9447},
month={May},}
@ARTICLE{9749020,
author={Zhang, Xiaoqi and Zhang, Haijun and Du, Wenbo and Long, Keping and Nallanathan, Arumugam},
journal={IEEE Transactions on Wireless Communications}, title={IRS Empowered UAV Wireless Communication with Resource Allocation, Reflecting Design and Trajectory Optimization},
year={2022},
volume={},
number={},
pages={1-1},
abstract={As revolutionary technologies that can actively change the communication link signal, intelligent reflecting surface (IRS) and unmanned aerial vehicle (UAV) have emerged as reliable, economical and convenient wireless communication solutions for a variety of practical scenarios. Therefore, this paper focuses on an IRS empowered UAV downlink communication network, where the dynamic UAV establishes a cascade link via IRS to provide signal enhancement services for multiple users. Considering constraints of transmit power, flight speed and area at the UAV and the reflecting constraints at the IRS, the block coordinate descent (BCD) method based on resource allocation, reflecting design and trajectory optimization is adopted to maximize the sum-rate of all users. The proposed problem is converted by using quadratic transformation and Lagrangian dual transformation. Then applying for the approximate linear method and Iterative Rank Minimization (IRM) to optimize the transmit power of UAV and phase shift of IRS respectively. Since additional reflection propagation paths by IRS, the complexity of the channel model makes the trajectory design difficult. To tackle this problem, this paper proposes a UAV trajectory optimization method based on enhanced reinforcement learning with the fixed initial location and destination. In the end, the convergence of the proposed scheme is effectively verified by simulations. Moreover, abundant simulation comparisons between the proposed scheme and other benchmark schemes demonstrate the validity and high performance gains of the proposed algorithm.},
keywords={Optimization;Autonomous aerial vehicles;Trajectory optimization;Array signal processing;Communication networks;Resource management;Wireless networks;IRS;UAV;resource allocation;reflecting design;trajectory optimization;BCD;IRM;reinforcement learning},
doi={10.1109/TWC.2022.3162704},
ISSN={1558-2248},
month={},}
@ARTICLE{9712630,
author={Chu, Nam H. and Hoang, Dinh Thai and Nguyen, Diep N. and Van Huynh, Nguyen and Dutkiewicz, Eryk},
journal={IEEE Internet of Things Journal}, title={Joint Speed Control and Energy Replenishment Optimization for UAV-assisted IoT Data Collection with Deep Reinforcement Transfer Learning},
year={2022},
volume={},
number={},
pages={1-1},
abstract={Unmanned aerial vehicle (UAV)-assisted data collection has been emerging as a prominent application due to its flexibility, mobility, and low operational cost. However, under the dynamic and uncertainty of IoT data collection and energy replenishment processes, optimizing the performance for UAV collectors is a very challenging task. Thus, this paper introduces a novel framework that jointly optimizes the flying speed and energy replenishment for each UAV to significantly improve the overall system performance (e.g., data collection and energy usage efficiency). Specifically, we first develop a Markov decision process to help the UAV automatically and dynamically make optimal decisions under the dynamics and uncertainties of the environment. Although traditional reinforcement learning algorithms such as Q-learning and deep Q-learning can help the UAV to obtain the optimal policy, they often take a long time to converge and require high computational complexity. Therefore, it is impractical to deploy these conventional methods on UAVs with limited computing capacity and energy resource. To that end, we develop advanced transfer learning techniques that allow UAVs to “share” and “transfer” learning knowledge, thereby reducing the learning time as well as significantly improving learning quality. Extensive simulations demonstrate that our proposed solution can improve the average data collection performance of the system up to 200% and reduce the convergence time up to 50% compared with those of conventional methods.},
keywords={Data collection;Transfer learning;Batteries;Internet of Things;Q-learning;Task analysis;Velocity control;UAV;IoT data collection;Markov decision process;deep reinforcement learning;transfer learning.},
doi={10.1109/JIOT.2022.3151201},
ISSN={2327-4662},
month={},}
@INPROCEEDINGS{9045905,
author={AlOwais, Aisha and Naseem, Safa and Dawdi, Takwa and Abdisalam, Mariam and Elkalyoubi, Yusra and Adwan, Anas and Hassan, Khawla and Fernini, Ilias},
booktitle={2019 2nd International Conference on Signal Processing and Information Security (ICSPIS)}, title={Meteorite Hunting Using Deep Learning and UAVs},
year={2019},
volume={},
number={},
pages={1-4},
abstract={In this paper, we present an automated meteorite detection system that employs an autonomous Unmanned Aerial Vehicle (UAV). It is programmed to recognize and locate meteorites using machine learning. In this design, the UAV carries a Single Board Computer (SBC), through which realtime data processing of the live video feed from an optical camera is performed. The integration of a GPS module into the system enables localization of the detected meteorites. The onboard processing, carried out by the SBC, involves analyzing each frame from the video and running it through our deep learning model. This model is trained on images of different types of commonly found meteorites, via Transfer Learning performed on Convolutional Neural Networks (CNN). The results were promising, with an accuracy of approximately 90%. Future enhancements, including the addition of an infrared sensor to capture thermal images, are also discussed.},
keywords={Training;Cameras;Deep learning;Drones;Hardware;Rocks;Machine Learning;Deep Learning;Meteorite;Convolutional Neural Networks;UAV;Drone},
doi={10.1109/ICSPIS48135.2019.9045905},
ISSN={},
month={Oct},}
@ARTICLE{9356600,
author={Hajiakhondi-Meybodi, Zohreh and Mohammadi, Arash and Abouei, Jamshid},
journal={IEEE Access}, title={Deep Reinforcement Learning for Trustworthy and Time-Varying Connection Scheduling in a Coupled UAV-Based Femtocaching Architecture},
year={2021},
volume={9},
number={},
pages={32263-32281},
abstract={The paper is motivated by the urgent need, imposed by the COVID-19 pandemic, for trustworthy access to secure communication systems with the highest achievable availability and minimum latency. In this regard, we focus on an ultra-dense wireless network consisting of Femto Access Points (FAPs) and Unmanned Aerial Vehicles (UAVs), known as caching nodes, where there are more than one possible caching node to handle user's request. To efficiently cope with the dynamic topology of wireless networks and time-varying behavior of ground users, our focus is to develop an efficient connection scheduling framework, where ground users are autonomously trained to determine the optimal caching node, i.e., UAV or FAP. Our aim is to minimize users' access delay by maintaining a trade-off between the energy consumption of UAVs and the occurrence of handovers. To achieve these objectives, we formulate a multi-objective optimization problem and propose the Convolutional Neural Network (CNN) and Q-Network-based Connection Scheduling (CQN-CS) framework. More specifically, to solve the constructed multi-objective connection scheduling problem, a deep Q-Network model is developed as an efficient Reinforcement Learning (RL) approach to train ground users to handle their requests in an optimal and trustworthy fashion within the coupled UAV-based femtocaching network. The effectiveness of the proposed CQN-CS framework is evaluated in terms of the cache-hit ratio, user's access delay, energy consumption of UAVs, handover, lifetime of the network, and cumulative rewards. Based on the simulation results, the proposed CQN-CS framework illustrates significant performance improvements in companion to Q-learning and Deep Q-Network (DQN) schemes across all the aforementioned aspects.},
keywords={Delays;Handover;Energy consumption;Wireless networks;Quality of service;Unmanned aerial vehicles;Job shop scheduling;Caching;cache-hit-ratio;connection scheduling;femtocaching;femto access point (FAP);reinforcement learning;unmanned aerial vehicle (UAV)},
doi={10.1109/ACCESS.2021.3060323},
ISSN={2169-3536},
month={},}
@ARTICLE{8993742,
author={Wang, Chao and Wang, Jian and Wang, Jingjing and Zhang, Xudong},
journal={IEEE Internet of Things Journal}, title={Deep-Reinforcement-Learning-Based Autonomous UAV Navigation With Sparse Rewards},
year={2020},
volume={7},
number={7},
pages={6180-6190},
abstract={Unmanned aerial vehicles (UAVs) have the potential in delivering Internet-of-Things (IoT) services from a great height, creating an airborne domain of the IoT. In this article, we address the problem of autonomous UAV navigation in large-scale complex environments by formulating it as a Markov decision process with sparse rewards and propose an algorithm named deep reinforcement learning (RL) with nonexpert helpers (LwH). In contrast to prior RL-based methods that put huge efforts into reward shaping, we adopt the sparse reward scheme, i.e., a UAV will be rewarded if and only if it completes navigation tasks. Using the sparse reward scheme ensures that the solution is not biased toward potentially suboptimal directions. However, having no intermediate rewards hinders the agent from efficient learning since informative states are rarely encountered. To handle the challenge, we assume that a prior policy (nonexpert helper) that might be of poor performance is available to the learning agent. The prior policy plays the role of guiding the agent in exploring the state space by reshaping the behavior policy used for environmental interaction. It also assists the agent in achieving goals by setting dynamic learning objectives with increasing difficulty. To evaluate our proposed method, we construct a simulator for UAV navigation in large-scale complex environments and compare our algorithm with several baselines. Experimental results demonstrate that LwH significantly outperforms the state-of-the-art algorithms handling sparse rewards and yields impressive navigation policies comparable to those learned in the environment with dense rewards.},
keywords={Navigation;Internet of Things;Unmanned aerial vehicles;Task analysis;Reinforcement learning;Space exploration;Heuristic algorithms;Deep reinforcement learning (RL);prior information;sparse reward;unmanned aerial vehicle (UAV) navigation},
doi={10.1109/JIOT.2020.2973193},
ISSN={2327-4662},
month={July},}
@ARTICLE{9470972,
author={Yan, Chao and Wang, Chang and Xiang, Xiaojia and Lan, Zhen and Jiang, Yuna},
journal={IEEE Transactions on Industrial Informatics}, title={Deep Reinforcement Learning of Collision-Free Flocking Policies for Multiple Fixed-Wing UAVs Using Local Situation Maps},
year={2022},
volume={18},
number={2},
pages={1260-1270},
abstract={The evolution of artificial intelligence and Internet of Things (IoT) envision a highly integrated artificial IoT (AIoT) network. Flocking and cooperation with multiple unmanned aerial vehicles (UAVs) are expected to play a vital role in industrial AIoT networks. In this article, we formulate the collision-free flocking problem of fixed-wing UAVs as a Markov decision process and solve it in the deep reinforcement learning (DRL) framework. Our method can deal with a variable number of followers by encoding the dynamic environmental state into a fixed-length embedding tensor. Specifically, each follower constructs a fixed-size local situation map that describes the collision risks with other followers nearby. The local situation maps are used by a proposed DRL algorithm to learn the collision-free flocking behavior. To further improve the learning efficiency, we design a reference-point-based action selection strategy and an adaptive mechanism. We compare the proposed MA2D3QN algorithm with several benchmark DRL algorithms through numerical simulation, and we verify its advantages in learning efficiency and performance. Finally, we demonstrate the scalability and adaptability of MA2D3QN in a semiphysical simulation experiment.},
keywords={Collision avoidance;Informatics;Internet of Things;Unmanned aerial vehicles;Reinforcement learning;Sensors;Vehicle dynamics;Artificial Internet of Things (AIoT);collision avoidance;deep $Q$ -network (DQN);deep reinforcement learning (DRL);unmanned aerial vehicle (UAV) flocking},
doi={10.1109/TII.2021.3094207},
ISSN={1941-0050},
month={Feb},}
@ARTICLE{9301300,
author={Lee, Gyeong Taek and Kim, Chang Ouk},
journal={IEEE Access}, title={Autonomous Control of Combat Unmanned Aerial Vehicles to Evade Surface-to-Air Missiles Using Deep Reinforcement Learning},
year={2020},
volume={8},
number={},
pages={226724-226736},
abstract={This paper proposes a new reinforcement learning approach for executing combat unmanned aerial vehicle (CUAV) missions. We consider missions with the following goals: guided missile avoidance, shortest-path flight and formation flight. For reinforcement learning, the representation of the current agent state is important. We propose a novel method of using the coordinates and angle of a CUAV to effectively represent its state. Furthermore, we develop a reinforcement learning algorithm with enhanced exploration through amplification of the imitation effect (AIE). This algorithm consists of self-imitation learning and random network distillation algorithms. We assert that these two algorithms complement each other and that combining them amplifies the imitation effect for exploration. Empirical results show that the proposed AIE approach is highly effective at finding a CUAV's shortest-flight path while avoiding enemy missiles. Test results confirm that with our method, a single CUAV reaches its target from its starting point 95% of the time and a squadron of four simultaneously operating CUAVs reaches the target 70% of the time.},
keywords={Missiles;Reinforcement learning;Games;Unmanned aerial vehicles;Mathematical model;Licenses;Task analysis;Deep reinforcement learning;combat unmanned aerial vehicle;deep learning;autonomous flight management system;path planning;exploration},
doi={10.1109/ACCESS.2020.3046284},
ISSN={2169-3536},
month={},}
@ARTICLE{9167249,
author={Yang, Bo and Cao, Xuelin and Yuen, Chau and Qian, Lijun},
journal={IEEE Internet of Things Journal}, title={Offloading Optimization in Edge Computing for Deep-Learning-Enabled Target Tracking by Internet of UAVs},
year={2021},
volume={8},
number={12},
pages={9878-9893},
abstract={The empowering unmanned aerial vehicles (UAVs) have been extensively used in providing intelligence such as target tracking. In our field experiments, a pretrained convolutional neural network (CNN) is deployed at UAV to identify a target (a vehicle) from the captured video frames and enable the UAV to keep tracking. However, this kind of visual target tracking demands a lot of computational resources due to the desired high inference accuracy and stringent delay requirement. This motivates us to consider offloading this type of deep learning (DL) tasks to a mobile-edge computing (MEC) server due to the limited computational resource and energy budget of the UAV and further improve the inference accuracy. Specifically, we propose a novel hierarchical DL tasks distribution framework, where the UAV is embedded with lower layers of the pretrained CNN model while the MEC server (MES) with rich computing resources will handle the higher layers of the CNN model. An optimization problem is formulated to minimize the weighted-sum cost, including the tracking delay and energy consumption introduced by communication and computing of UAVs while taking into account the quality of data (e.g., video frames) input to the DL model and the inference errors. Analytical results are obtained and insights are provided to understand the tradeoff between the weighted-sum cost and inference error rate in the proposed framework. Numerical results demonstrate the effectiveness of the proposed offloading framework.},
keywords={Target tracking;Visualization;Machine learning;Streaming media;Unmanned aerial vehicles;Delays;Internet of Things;Deep learning (DL);mobile-edge computing (MEC);offloading;unmanned aerial vehicle (UAV);visual target tracking},
doi={10.1109/JIOT.2020.3016694},
ISSN={2327-4662},
month={June},}
@ARTICLE{9056568,
author={Li, Yue and Han, Wei and Wang, Yongqing},
journal={IEEE Access}, title={Deep Reinforcement Learning With Application to Air Confrontation Intelligent Decision-Making of Manned/Unmanned Aerial Vehicle Cooperative System},
year={2020},
volume={8},
number={},
pages={67887-67898},
abstract={With the development of intelligence in air confrontation, the demand for cooperative engagement of manned/unmanned aerial vehicle (MAV/UAV) is becoming more intense. Deep reinforcement learning (DRL), which combines the abstract representation capability of deep learning (DL) and the optimal decision-making and control capability of reinforcement learning (RL), is an appropriate application for dealing with this problem. In the case of continuous action space, the dynamics model of UAV and the basic structure of one of the most popular DRL methods called deep deterministic policy gradient (DDPG) are built firstly. To establish the framework of intelligent decision-making of MAV/UAV, typical intentions including Head-on attack, Fleeing, Pursuing and Energy-storing, corresponding to four optimization models, are introduced secondly. Then the neural network is trained by means of reconstructing the replay buffer of DDPG algorithm. Finally, simulation results show that UAV is able to learn intelligent decision-making throughout the intention guiding of MAV. Compared with original DDPG algorithm, the improved method can achieve a better performance in convergence and stability. Furthermore, the level of intelligent decision-making in air confrontation can be improved by self-learning.},
keywords={Decision making;Cooperative systems;Mathematical model;Reinforcement learning;Atmospheric modeling;Optimization;Approximation algorithms;Manned/unmanned aerial vehicle;intelligent decision-making;application of deep reinforcement learning;intention guiding;deep deterministic policy gradient;self-learning},
doi={10.1109/ACCESS.2020.2985576},
ISSN={2169-3536},
month={},}
@INPROCEEDINGS{9596707,
author={Domitran, Sandro and Babac, Marina Bagić},
booktitle={2021 44th International Convention on Information, Communication and Electronic Technology (MIPRO)}, title={A Machine Learning Approach to Flight Control of a VTOL Tailsitter UAV},
year={2021},
volume={},
number={},
pages={1741-1746},
abstract={Unmanned aerial vehicles, commonly known as drones, are used for many different purposes. However, it is still a challenging task to fly a drone, which limits its potential for doing more useful things. The goal of this paper is to explain how to fly a drone using a machine learning approach, which should make its flight more accurate, efficient and stable. In this paper, we propose an artificial-intelligence-based flight control of unmanned aerial vehicles in a realistic simulated environment. In addition, the drone can learn to perform a certain task to elaborate the benefits of this approach.},
keywords={Training;Optimization methods;Reinforcement learning;Task analysis;Physics;Engines;Drones;unmanned aerial vehicle;UAV flight control;machine learning;reinforcement learning},
doi={10.23919/MIPRO52101.2021.9596707},
ISSN={2623-8764},
month={Sep.},}
@INPROCEEDINGS{5544109,
author={Jevtić, Aleksandar and Andina, Diego and Jaimes, Aldo and Gomez, Jose and Jamshidi, Mo},
booktitle={2010 5th International Conference on System of Systems Engineering}, title={Unmanned Aerial Vehicle route optimization using ant system algorithm},
year={2010},
volume={},
number={},
pages={1-6},
abstract={Unmanned Aerial Vehicle (UAV) is defined as aircraft without the onboard presence of pilots. UAVs have been used to perform intelligence, surveillance, and reconnaissance missions. The UAVs are not limited to military operations, they can also be used in commercial applications such as telecommunications, ground traffic control, search and rescue operations, crop monitoring, etc. In this paper, we propose a swarm intelligence-based method for UAVs' route optimization. The team of UAVs is used for area coverage with the defined set of waypoints. The problem can be interpreted as a well-known Traveling Salesman Problem where the task is to find the route of minimal length such that all the waypoints are visited only once. We applied the Ant System algorithm and compared it with the Nearest Neighbor Search. The experimental results confirm the effectiveness of our method, especially for a large number of waypoints.},
keywords={Unmanned aerial vehicles;Military aircraft;Air traffic control;Surveillance;Reconnaissance;Military communication;Traffic control;Crops;Monitoring;Particle swarm optimization;Unmanned aerial vehicle;traveling salesman problem;swarm intelligence;ant colony optimization},
doi={10.1109/SYSOSE.2010.5544109},
ISSN={},
month={June},}
@INPROCEEDINGS{9394263,
author={Dong, Jiong and Ota, Kaoru and Dong, Mianxiong},
booktitle={2020 16th International Conference on Mobility, Sensing and Networking (MSN)}, title={Real-Time Survivor Detection in UAV Thermal Imagery Based on Deep Learning},
year={2020},
volume={},
number={},
pages={352-359},
abstract={Unmanned Aerial Vehicles (UAVs) uses evolved significantly due to its high durability, lower costs, easy implementation, and flexibility. After a natural disaster occurs, UAVs can quickly search the affected area to save more survivors. Dataset is crucial in developing a round-the-clock rescue system applying deep learning methods. In this paper, we collected a new thermal image dataset captured by UAV for post-disaster search and rescue (SAR) activities. After that, we employed several different deep convolutional neural networks to train the pedestrian detection models on our datasets, including YOLOV3, YOLOV3-MobileNetV1 and YOLOV3-MobileNetV3. Because the onboard microcomputer has limited computing capacity and memory, for balancing the inference time and accuracy, we find optimal points to prune and fine-tune the network based on the sensitivity of convolutional layers. We validate on NVIDIA's Jetson TX2 and achieve 26.60 FPS (Frames per second) real-time performance.},
keywords={Deep learning;Sensitivity;Microcomputers;Unmanned aerial vehicles;Real-time systems;Sensors;Convolutional neural networks;Unmanned Aerial Vehicle (UAV);thermal image;search and rescue;pedestrian detection;deep learning.},
doi={10.1109/MSN50589.2020.00065},
ISSN={},
month={Dec},}
@ARTICLE{9687843,
author={Khamidehi, Behzad and Sousa, Elvino S.},
journal={IEEE Internet of Things Journal}, title={Reinforcement Learning-aided Safe Planning for Aerial Robots to Collect Data in Dynamic Environments},
year={2022},
volume={},
number={},
pages={1-1},
abstract={We study the data collection problem in an Internet of things (IoT) network where an unmanned aerial vehicle (UAV) is utilized to aggregate data from a set of IoT devices. We formulate the scheduling and path planning problems for the UAV. The goal of the scheduling problem is to find the sequence of nodes that the UAV will visit to complete the data collection task in the shortest possible time, ensuring that it does not run out of energy during its mission. We express this problem as a mixed-integer non-linear problem and propose an efficient algorithm to solve the aforementioned NP-hard problem in polynomial time. Path planning problem aims to find a collision-free path for the UAV. While the state-of-art schemes have focused on solving the path planning problem in static environments, we study the problem in a dynamic environment with moving obstacles. We develop an algorithm that works on both static and dynamic environments. Our method combines deep reinforcement learning (RL) with graph-based global path planning algorithms to find a collision-free path for the UAV. One important advantage of our RL-based method over the existing studies is its map-independency, which allows us to transform the agent’s learning from one environment to another. Via simulation studies, we show that our method is significantly effective in improving the safety of the path planning algorithms in dynamic environments.},
keywords={Autonomous aerial vehicles;Sensors;Internet of Things;Data collection;Heuristic algorithms;Batteries;Wireless sensor networks;Deep Reinforcement learning;Unmanned Aerial Vehicles (UAVs);Internet of Things (IoT);Path Planning.},
doi={10.1109/JIOT.2022.3145008},
ISSN={2327-4662},
month={},}
@ARTICLE{9655514,
author={Han, Chen and Liu, Aijun and An, Kang and Wang, Haichao and Zheng, Gan and Chatzinotas, Symeon and Huo, Liangyu and Tong, Xinhai},
journal={IEEE Transactions on Vehicular Technology}, title={Satellite-assisted UAV Trajectory Control in Hostile Jamming Environments},
year={2021},
volume={},
number={},
pages={1-1},
abstract={Satellite and unmanned aerial vehicle (UAV) networks have been introduced as enhanced approach to provide dynamic control, massive connections and global coverage for future wireless communication systems. This paper considers a coordinated satellite-UAV communication system, where the UAV performs the environmental reconnaissance task with the assistance of satellite in a hostile jamming environment. To fulfill this task, the UAV needs to realize autonomous trajectory control and upload the collected data to the satellite. With the aid of the uploading data, the satellite builds the environment situation map integrating the beam quality, jamming status, and traffic distribution. Accordingly, we propose a closed-loop anti-jamming dynamic trajectory optimization approach, which is divided into three stages. Firstly, an intentional trajectory planning is made according to the limited prior information and preset points. Secondly, the flight control between two preset points is formulated as a Markov decision process, and a reinforcement learning (RL) based automatic flying control algorithm is proposed to explore the unknown hostile environment and realize autonomous and precise trajectory control. Thirdly, based on the collected data during the UAV's flight, the satellite utilizes an environment situation estimating algorithm to build an environment situation map, which is used to reselect the preset points for the first stage and provide better initialization for the RL process in the second stage. Simulation results verify the validity and superiority of the proposed approach.},
keywords={Trajectory;Satellites;Jamming;Autonomous aerial vehicles;Task analysis;Reconnaissance;Vehicle dynamics;Jamming;Satellite-UAV coordination communication;Trajectory optimization;Reinforcement learning;Graph theory},
doi={10.1109/TVT.2021.3136187},
ISSN={1939-9359},
month={},}
@INPROCEEDINGS{9708942,
author={Badnava, Babak and Kim, Taejoon and Cheung, Kenny and Ali, Zaheer and Hashemi, Morteza},
booktitle={2021 IEEE/ACM Symposium on Edge Computing (SEC)}, title={Spectrum-Aware Mobile Edge Computing for UAVs Using Reinforcement Learning},
year={2021},
volume={},
number={},
pages={376-380},
abstract={We consider the problem of task offloading by unmanned aerial vehicles (UAV) using mobile edge computing (MEC). In this context, each UAV makes a decision to offload the computation task to a more powerful MEC server (e.g., base station), or to perform the task locally. In this paper, we propose a spectrum-aware decision-making framework such that each agent can dynamically select one of the available channels for offloading. To this end, we develop a deep reinforcement learning (DRL) framework for the UAVs to select the channel for task offloading or perform the computation locally. In the numerical results based on deep Q-network, we con-sider a combination of energy consumption and task completion time as the reward. Simulation results based on low-band, mid-band, and high-band channels demonstrate that the DQN agents efficiently learn the environment and dynamically adjust their actions to maximize the long-term reward.},
keywords={Energy consumption;Multi-access edge computing;Simulation;Bit rate;Decision making;Reinforcement learning;Autonomous aerial vehicles;Unmanned Aerial Vehicle (UAV);Mobile Edge Computing;Deep Reinforcement Learning},
doi={10.1145/3453142.3491414},
ISSN={},
month={Dec},}
@ARTICLE{9365706,
author={Li, Zhiwei and Lu, Yu and Li, Xi and Wang, Zengguang and Qiao, Wenxin and Liu, Yicen},
journal={IEEE Internet of Things Journal}, title={UAV Networks Against Multiple Maneuvering Smart Jamming With Knowledge-Based Reinforcement Learning},
year={2021},
volume={8},
number={15},
pages={12289-12310},
abstract={The unmanned aerial vehicles (UAVs) networks are very vulnerable to smart jammers that can choose their jamming strategy based on the ongoing channel state accordingly. Although reinforcement learning (RL) algorithms can give UAV networks the ability to make intelligent decisions, the high-dimensional state space makes it difficult for algorithms to converge quickly. This article proposes a knowledge-based RL method, which uses domain knowledge to compress the state space that the agent needs to explore and then improve the algorithm convergence speed. Specifically, we use the inertial law of the aircraft and the law of signal attenuation in free space to guide the highly efficient exploration of the UAVs in the state space. We incorporate the performance indicators of the receiver and the subjective value of the task into the design of the reward function, and build a virtual environment for pretraining to accelerate the convergence of anti-jamming decisions. In addition, the algorithm proposed is completely based on observable data, which is more realistic than those studies that assume the position or the channel strategy of the jammer. The simulation shows that the proposed algorithm can outperform the benchmarks of model-free RL algorithm in terms of converge speed and averaged reward.},
keywords={Jamming;Interference;Reinforcement learning;Games;Receivers;Signal to noise ratio;Convergence;Anti-jamming;domain knowledge;reinforcement learning (RL);unmanned aerial vehicle (UAV) networks},
doi={10.1109/JIOT.2021.3062659},
ISSN={2327-4662},
month={Aug},}
@INPROCEEDINGS{9553713,
author={Carrillo, Juan and Borda, Katherine},
booktitle={2021 IEEE International Geoscience and Remote Sensing Symposium IGARSS}, title={Recent Advances in Artificial Intelligence and Computer Vision for Unmanned Aerial Vehicles},
year={2021},
volume={},
number={},
pages={7959-7962},
abstract={In recent years we have seen an accelerated development in the technologies enabling advanced navigation and control of Unmanned Aerial Vehicles (UAVs). Such progress has been fueled by the combination of improved hardware as well as breakthrough advances in Artificial Intelligence methods to accomplish tasks that were previously though extremely difficult to automate. In this document we present a brief summary of some of the most representative methods focused on enabling advanced perception, collision avoidance, flight planning and control, as well as some key industry applications of these capabilities.},
keywords={Navigation;Image processing;Industry applications;Geoscience and remote sensing;Unmanned aerial vehicles;Hardware;Planning;UAVs;Artificial Intelligence;Computer Vision;Deep Learning},
doi={10.1109/IGARSS47720.2021.9553713},
ISSN={2153-7003},
month={July},}
@ARTICLE{9678963,
author={Hu, Jun and Zhang, Yanfeng and Zhao, Dandan and Yang, Guijun and Chen, Feiyun and Zhou, Chengquan and Chen, Wenxuan},
journal={IEEE Transactions on Geoscience and Remote Sensing}, title={A Robust Deep Learning Approach for the Quantitative Characterization and Clustering of Peach Tree Crowns Based on UAV Images},
year={2022},
volume={60},
number={},
pages={1-13},
abstract={The accurate large-scale measurement of peach crowns is vital in horticultural science and the optimization of orchard management. Nowadays, numerous crown parameters (e.g., crown area, height, and volume) can be obtained via the analysis of point clouds or photographs. Current laser-based sensors provide the required reliable and accurate information; however, they are costly and time-consuming. Therefore, a simpler approach for crown measurement is required. For this purpose, this study presents a pipeline for the monitoring and clustering of 259 peach tree crowns based on unmanned aerial vehicle (UAV) images of a peach orchard in Southeast China. Considering the limitation that the original aerial image dataset contains little information, a data augmentation process is adopted, and an efficient deep learning architecture based on conditional generative adversarial networks (cGANs) was designed to extract the crown area. Then, the shape of the crown area was clustered using an edge detection process and a $k$ -means algorithm. Finally, an ellipsoid volume method (EVM) was applied to estimate the crown volume. Five indicators—namely, $Q_{\mathrm {seg}}$ , $S_{\mathrm {r}}$ , Precision, Recall, and F-measure—were employed to evaluate the crown extraction effects, and the average results for testing samples were 0.832, 0.847, 0.851, 0.828, and 0.846, respectively. Compared with other approaches—namely, fully convolutional network (FCN), U-Net, SegNet21, the excess green index (ExG), and the color index of vegetation extraction (CIVE)—the proposed cGAN model performs better, achieving an accuracy improvement of 5%–25%. For the estimation of crown volume, using measurements from a light detection and ranging (LIDAR) scanner as a reference, the correlation coefficient and relative-root-mean-square error (R-RMSE) were found to be 0.836% and 14.93%, respectively. Overall, the results demonstrate that the proposed method is feasible for measuring peach tree crowns. The wide application of such technology would facilitate applied research in plant phenotyping and precision horticulture.},
keywords={Vegetation;Autonomous aerial vehicles;Laser radar;Remote sensing;Agriculture;Volume measurement;Monitoring;Crown measurement;deep learning;shape clustering;unmanned aerial vehicle (UAV) images;volume estimation},
doi={10.1109/TGRS.2022.3142288},
ISSN={1558-0644},
month={},}
@ARTICLE{8735795,
author={Shan, Lin and Miura, Ryu and Kagawa, Toshinori and Ono, Fumie and Li, Huan-Bang and Kojima, Fumihide},
journal={IEEE Access}, title={Machine Learning-Based Field Data Analysis and Modeling for Drone Communications},
year={2019},
volume={7},
number={},
pages={79127-79135},
abstract={In recent years, unmanned aerial vehicle (UAV), also called a drone, is getting more and more important in many emerging technology areas. For communication area, the drone also takes an important role in lots of significant topics like emergency communications, device-to-device (D2D) communications, and the Internet of Things (IoT). One of the important drone applications is to collect and share data among drones and other aircraft, which is useful for drone control so that dangerous conditions can be avoided. In particular, the drone control and safety guarantees are difficult to attain, especially, when drones fly beyond the line of sight (BLOS). For this reason, we develop a drone location information sharing system using the 920-MHz band. We use this system to do a long distance propagation field experiment for model establishment. Unfortunately, the current data collection for model establishment work needs a great effort and time to do experiments to collect a huge number of data for data analysis so that a suitable model can be established. Therefore, in this paper, we propose a novel method, which is based on machine learning approach, to data analysis and model establishment for drone communications, so that the effort and cost for establishing model can be reduced and a model, which captures more details about the drone communications, can be obtained. The results of this paper validate that the proposed method can indeed establish a more complicated model with less effort. Specifically, from the distribution of the training error, it can be known that there are over 80% training errors with intensity less than 5, which ensures the error performance of the proposed method.},
keywords={Drones;Machine learning;Data models;Information management;Communication systems;Analytical models;Aircraft;Unmanned aerial vehicle (UAV);drone communication;machine learning;Internet of Things (IoT)},
doi={10.1109/ACCESS.2019.2922544},
ISSN={2169-3536},
month={},}
@ARTICLE{8805152,
author={Tetila, Everton Castelão and Machado, Bruno Brandoli and Menezes, Gabriel Kirsten and Da Silva Oliveira, Adair and Alvarez, Marco and Amorim, Willian Paraguassu and De Souza Belete, Nícolas Alessandro and Da Silva, Gercina Gonçalves and Pistori, Hemerson},
journal={IEEE Geoscience and Remote Sensing Letters}, title={Automatic Recognition of Soybean Leaf Diseases Using UAV Images and Deep Convolutional Neural Networks},
year={2020},
volume={17},
number={5},
pages={903-907},
abstract={Plant diseases are a crucial issue in agriculture. An accurate and automatic identification of leaf diseases could help to develop an early response to reduce economic losses. Recent research in plant diseases has adopted deep neural networks. However, such research has used the models as a black-box passing the labeled images through the networks. This letter presents an analysis of the network weights for the automatic recognition of soybean leaf diseases applied to images taken straight from a small and cheap unmanned aerial vehicle (UAV). To achieve high accuracy, we evaluated four deep neural network models trained with different parameters for fine-tuning (FT) and transfer learning. Data augmentation and dropout were used during the network training to avoid overfitting. Our methodology consists of using the SLIC method to segment the plant leaves in the top-view images obtained during the flight. We tested our data set created from real flight inspections in an end-to-end computer vision approach. Results strongly suggest that the FT of parameters substantially improves the identification accuracy.},
keywords={Diseases;Image segmentation;Deep learning;Training;Agriculture;Inspection;Image recognition;Aerial imagery;deep learning;precision agriculture;soybean leaf diseases;unmanned aerial vehicle (UAV)-based remote sensing},
doi={10.1109/LGRS.2019.2932385},
ISSN={1558-0571},
month={May},}
@ARTICLE{9584850,
author={Do, Quang Vinh and Pham, Quoc-Viet and Hwang, Won-Joo},
journal={IEEE Communications Letters}, title={Deep Reinforcement Learning for Energy-Efficient Federated Learning in UAV-Enabled Wireless Powered Networks},
year={2022},
volume={26},
number={1},
pages={99-103},
abstract={Federated learning (FL) is a promising solution to privacy preservation for data-driven deep learning approaches. However, enabling FL in unmanned aerial vehicle (UAV)-assisted wireless networks is still challenging due to limited resources and battery capacity in the UAV and user devices. In this regard, we propose a deep reinforcement learning (DRL)-based framework for joint UAV placement and resource allocation to enable sustainable FL with energy harvesting user devices. We aim to maximize the long-term FL performance considering the limited resources in the network, such as harvested energy, bandwidth resources, and UAV’s energy budget. To reduce the complexity of the original problem, we leverage the Lyapunov optimization technique to transform a long-term energy constraint into a deterministic problem. We reformulate the optimization problem as the framework of a Markov decision process (MDP) and design a DRL-based algorithm to solve the MDP. The proposed solution can guarantee the sustainable operation of UAV-aided wireless networks by improving energy conservation of the network in the long run.},
keywords={Unmanned aerial vehicles;Training;Energy consumption;Task analysis;Batteries;Bandwidth;Optimization;Deep reinforcement learning;energy harvesting;federated learning;resource allocation;unmanned aerial vehicle},
doi={10.1109/LCOMM.2021.3122129},
ISSN={1558-2558},
month={Jan},}
@INPROCEEDINGS{8793294,
author={Ku, Sungmo and Jung, Sangwon and Lee, Chungyoung},
booktitle={2019 34th International Technical Conference on Circuits/Systems, Computers and Communications (ITC-CSCC)}, title={UAV Trajectory Design Based on Reinforcement Learning for Wireless Power Transfer},
year={2019},
volume={},
number={},
pages={1-3},
abstract={We studied wireless power transfer (WPT) system where unmanned aerial vehicle (UAV) broadcasts power to energy receivers (ERs) on the ground to solve the fairness problem. Since the design of the optimal UAV trajectory based on the location information of all ERs is not practical for UAV and requires high complexity, we apply Q-learning among reinforcement learning techniques to design the suboptimal trajectory with lower complexity. We confirmed that the proposed reinforcement learning-based trajectory design approaches the outer bound of the achievable region of two ERs.},
keywords={Erbium;Unmanned aerial vehicles;Trajectory;Reinforcement learning;Wireless communication;Wireless power transfer;Charging stations;UAV trajectory design;wireless power transfer;reinforcement learning;Q-learning},
doi={10.1109/ITC-CSCC.2019.8793294},
ISSN={},
month={June},}
@ARTICLE{8004441,
author={Lu, Huimin and Li, Yujie and Mu, Shenglin and Wang, Dong and Kim, Hyoungseop and Serikawa, Seiichi},
journal={IEEE Internet of Things Journal}, title={Motor Anomaly Detection for Unmanned Aerial Vehicles Using Reinforcement Learning},
year={2018},
volume={5},
number={4},
pages={2315-2322},
abstract={Unmanned aerial vehicles (UAVs) are used in many fields including weather observation, farming, infrastructure inspection, and monitoring of disaster areas. However, the currently available UAVs are prone to crashing. The goal of this paper is the development of an anomaly detection system to prevent the motor of the drone from operating at abnormal temperatures. In this anomaly detection system, the temperature of the motor is recorded using DS18B20 sensors. Then, using reinforcement learning, the motor is judged to be operating abnormally by a Raspberry Pi processing unit. A specially built user interface allows the activity of the Raspberry Pi to be tracked on a Tablet for observation purposes. The proposed system provides the ability to land a drone when the motor temperature exceeds an automatically generated threshold. The experimental results confirm that the proposed system can safely control the drone using information obtained from temperature sensors attached to the motor.},
keywords={Drones;Temperature measurement;Temperature sensors;DC motors;Learning (artificial intelligence);Monitoring;Standards;Anomaly detection;reinforcement learning;temperature sensor;unmanned aerial vehicle (UAV)},
doi={10.1109/JIOT.2017.2737479},
ISSN={2327-4662},
month={Aug},}
@ARTICLE{9311612,
author={Hou, Huitai and Xu, Qing and Lan, Chaozhen and Lu, Wanjie and Zhang, Yongxian and Cui, Zhixiang and Qin, Jianqi},
journal={IEEE Access}, title={UAV Pose Estimation in GNSS-Denied Environment Assisted by Satellite Imagery Deep Learning Features},
year={2021},
volume={9},
number={},
pages={6358-6367},
abstract={With the growing maturity of unmanned aerial vehicle (UAV) technology, its applications have widened to many spheres of life. The prerequisite for a UAV to perform air tasks smoothly is an accurate localization of its own position. Traditional UAV navigation relies on the Global Navigation Satellite System (GNSS) for localization; however, this system has disadvantages of instability and susceptibility to interference. Therefore, to obtain accuracy in UAV pose estimation in GNSS-denied environments, a UAV localization method that is assisted by deep learning features of satellite imagery is proposed. With the inclusion of a top-view optical camera to the UAV, localization is achieved based on satellite imageries with geographic coordinates and a digital elevation model (DEM). By utilizing the difference between the UAV frame and satellite imagery, the convolutional neural network is used to extract deep learning features between the two images to achieve stable registration. To improve the accuracy and robustness of the localization method, a local optimization method based on bundle adjustment (BA) is proposed. Experiments demonstrate that when the UAV's relative altitude is 0.5 km, the average localization error of this method under different trajectories is within 15 m.},
keywords={Satellites;Location awareness;Feature extraction;Unmanned aerial vehicles;Deep learning;Pose estimation;Global navigation satellite system;Bundle adjustment;deep learning;localization;satellite imagery;unmanned aerial vehicle},
doi={10.1109/ACCESS.2020.3048342},
ISSN={2169-3536},
month={},}
@ARTICLE{9244134,
author={Zhu, Lingzhi and Zhang, Shuning and Wang, Xun and Chen, Si and Zhao, Huichang and Wei, Dongxu},
journal={IEEE Transactions on Instrumentation and Measurement}, title={Multilevel Recognition of UAV-to-Ground Targets Based on Micro-Doppler Signatures and Transfer Learning of Deep Convolutional Neural Networks},
year={2021},
volume={70},
number={},
pages={1-11},
abstract={Unmanned aerial vehicles (UAVs) are used in different scenarios. The need for intelligent and accurate recognition of targets using UAV-based radars is increasingly urgent. As unique information of targets, micro-Doppler characteristics have become an important basis for target recognition. For three typical ground targets including pedestrians, wheeled vehicles, and tracked vehicles, the micro-Doppler modulation of the UAV vibration on echo signals is analyzed first in this article. Second, the singular value decomposition (SVD) is adopted to suppress ground clutter and environmental noise. In order to decrease the computation and increase the contrast, all colored time-frequency diagrams of micro-Doppler signals are transferred into grayscale images. Third, a multilevel target recognition method based on the transfer learning of deep convolutional neural networks (DCNNs) is proposed. The first-level recognition is designed to accurately distinguish pedestrians, wheeled vehicles, and tracked vehicles, while the purpose of the second-level of recognition is to determine the three states of pedestrians including stepping, walking, and jogging. At last, experiments are carried out using a designed Doppler radar to prove the effectiveness of the proposed method. Results indicate that the method in this article not only avoids the complex feature extraction process, but also has higher accuracy and better robustness.},
keywords={Vibrations;Radar tracking;Wheels;Doppler effect;Target recognition;Feature extraction;Scattering;Deep convolutional neural networks (DCNNs);micro-Doppler;multilevel recognition;singular value decomposition (SVD);transfer learning;unmanned aerial vehicle (UAV)-to-ground targets},
doi={10.1109/TIM.2020.3034616},
ISSN={1557-9662},
month={},}
@ARTICLE{9564247,
author={Ke, Hongchang and Wang, Hui and Sun, Weijia and Sun, Hongbin},
journal={IEEE Transactions on Network and Service Management}, title={Adaptive Computation Offloading Policy for Multi-Access Edge Computing in Heterogeneous Wireless Networks},
year={2022},
volume={19},
number={1},
pages={289-305},
abstract={In heterogeneous wireless networks, massive mobile terminals randomly generate a large number of computation tasks (payloads). How to better manage these mobile terminals located in wireless networks to achieve acceptable quality of service (QoS) such as latency minimization, energy consumption minimization is crucial. A multi-access edge computing (MEC) server can be leveraged to execute the offloaded payloads generated from mobile terminals owing to its powerful processing power and location proximity features. However, an MEC server cannot tackle all offloaded tasks from multiple mobile terminals, and its energy consumption needs further consideration. We introduce an edge server model combined with the unmanned aerial vehicle (UAV) and equipped with the macro base station (MBS-MEC) to process the arrival payloads, and all UAVs and MBS-MECs can harvest renewable energy by using energy harvesting equipment. Furthermore, we model the computation offloading as a deep reinforcement learning scheme without priori knowledge. Considering the infeasibility of deep-reinforcement learning-based centralized learning for the proposed edge computing framework, we propose a distributed computation offloading scheme based on deep reinforcement learning (DCODRL) to minimize the weighted average cost, including the latency cost and the energy cost. Each mobile terminal can be regarded as a learning agent for the DCODRL. To compensate for the lack of cooperation of the DCODRL, we propose a gated-recurrent-unit-assisted multi-agent computation offloading scheme based on deep reinforcement learning (MCODRL) to improve the offloading policy by obtaining global observation information and designing a common reward for all agents. Comprehensive numerical results reflect the convergence and effectiveness of the DCODRL and MCODRL, and the efficacy of the proposed algorithms is further verified through comparisons with two baseline algorithms.},
keywords={Servers;Costs;Computational modeling;Task analysis;Optimization;Energy consumption;Decision making;Multi-access edge computing;unmanned aerial vehicle;quality of service;cost minimization;deep reinforcement learning},
doi={10.1109/TNSM.2021.3118696},
ISSN={1932-4537},
month={March},}
@INPROCEEDINGS{8996021,
author={Zhu, Yuanyuan and Liu, Hao and Ren, Bin and Duan, Hongliang and She, Xiaoyu and Wu, Zhenglong},
booktitle={2019 IEEE International Conference on Unmanned Systems (ICUS)}, title={A Model-free Flat Spin Recovery Scheme for Miniature Fixed-wing Unmanned Aerial Vehicle},
year={2019},
volume={},
number={},
pages={623-630},
abstract={The present paper proposes a Deep- Reinforcement-Learning-based (DRL-based) model-free flat spin recovery scheme to recover a miniature unmanned aerial vehicle (UAV) back to steady level flight swiftly. Two types of deep reinforcement learning (DRL) are utilized for the two recovery phases to fully exploit DRL's strengths in model-free situations. In the first phase, the angular rates of UAV are attenuated swiftly by a deep Q-network (DQN); in the second phase, the UAV is continuously regulated with a novel algorithm termed LA-DDPG, which is the deep deterministic policy gradient (DDPG) exploring by learning automata (LA). Simulation tests show that the proposed recovery scheme can recover the UAV from flat spin mode to steady level flight with satisfactory performance without relying on accurate prior models or other control structures. Furthermore, LA-DDPG exhibits better stability and efficiency than DDPG.},
keywords={Unmanned aerial vehicles;Learning automata;Couplings;Space vehicles;Learning (artificial intelligence);Aerospace electronics;Training;Reinforcement Learning;Model Free;Flat Spin Recovery;Fixed-wing Unmanned Aerial Vehicle},
doi={10.1109/ICUS48101.2019.8996021},
ISSN={},
month={Oct},}
@ARTICLE{9513250,
author={Ghdiri, Oussama and Jaafar, Wael and Alfattani, Safwan and Abderrazak, Jihene Ben and Yanikomeroglu, Halim},
journal={IEEE Transactions on Green Communications and Networking}, title={Offline and Online UAV-Enabled Data Collection in Time-Constrained IoT Networks},
year={2021},
volume={5},
number={4},
pages={1918-1933},
abstract={Recently, unmanned aerial vehicle (UAV) technology is endorsed to enable applications in domains such as Internet of Things (IoT), wireless sensor networks, and cellular networks. Particularly, time-sensitive and energy-limited IoT networks located in hard-to-reach areas require efficient/cost-effective data collection solution. To address this matter, we consider a multi-UAV enabled IoT network, where several UAVs collect data from time-constrained sensor nodes (SNs). In our framework, SNs are managed by cluster heads (CHs), then UAVs collect data from them. We formulate the problem of minimizing system’s deployment costs and operating energy to collect data within deadlines, subject to communication, UAVs mission time, and battery capacity constraints. To solve it, we propose a two-step approach. In the first step, an efficient K-means based method groups SNs and deploys CHs. Then, UAV-based offline and online data collection methods are proposed. In the offline setting where the system’s status is known beforehand, UAV paths are determined using near-optimal meta-heuristics. In simulations, the nearest-neighbor and Tabu search provided best offline performances, conditioned on the system’s parameters. In the online setting where no system information is available, deep reinforcement learning (DRL) based approaches are proposed. Results demonstrate the superiority of the actor-critic solution.},
keywords={Data collection;Internet of Things;Trajectory;Unmanned aerial vehicles;Optimization;Resource management;Reinforcement learning;Unmanned aerial vehicle;Internet of Things;clustering;reinforcement learning;data collection},
doi={10.1109/TGCN.2021.3104801},
ISSN={2473-2400},
month={Dec},}
@INPROCEEDINGS{9625082,
author={Yin, Baolin and Li, Xinmin and Zhang, Xiaoqiang and Wei, Lili},
booktitle={2021 IEEE 94th Vehicular Technology Conference (VTC2021-Fall)}, title={Trajectory Optimization for Age of Information Minimization in UAV Communication Systems},
year={2021},
volume={},
number={},
pages={1-6},
abstract={Unmanned aerial vehicle (UAV) as a promising technology in the 6G communication system can collect and transmit information intelligently. However, the existing methods are difficult to design UAV's trajectory to guarantee the information freshness performance. In this paper, the information freshness of a multiple-UAV communication system is modeled based on the age of information (AoI) and the minimization AoI optimization problem subjected to the minimal energy is formulated. In order to solve this nonconvex optimization problem, reinforcement learning (RL)-based scheme is proposed to design the UAVs' trajectory. The proposed scheme constructs the reward function depending on the accumulated AoI to make a fast trajectory decision and reduce the AoI of UAV communication system. The simulation results show that the proposed scheme can improve 21.7% performance gain of information freshness compared to the random scheme and the greedy scheme, and 7.7% performance gain compared to the flying-hover-communication scheme. In addition, the proposed UAV trajectory design scheme has the superior convergence.},
keywords={Vehicular and wireless technologies;Communication systems;Simulation;Reinforcement learning;Performance gain;Autonomous aerial vehicles;Minimization;Unmanned aerial vehicle;age of information;trajectory optimization;reinforcement learning},
doi={10.1109/VTC2021-Fall52928.2021.9625082},
ISSN={2577-2465},
month={Sep.},}
@ARTICLE{8855031,
author={Xiao, Xuedou and Wang, Wei and Chen, Taobin and Cao, Yang and Jiang, Tao and Zhang, Qian},
journal={IEEE Transactions on Multimedia}, title={Sensor-Augmented Neural Adaptive Bitrate Video Streaming on UAVs},
year={2020},
volume={22},
number={6},
pages={1567-1576},
abstract={Recent advances in unmanned aerial vehicle (UAV) technology have revolutionized a broad class of civil and military applications. However, the designs of wireless technologies that enable real-time streaming of high-definition video between UAVs and ground clients present a conundrum. Most existing adaptive bitrate (ABR) algorithms are not optimized for the air-to-ground links, which usually fluctuate dramatically due to the dynamic flight states of the UAV. In this paper, we present SA-ABR, a new sensor-augmented system that generates ABR video streaming algorithms with the assistance of various kinds of inherent sensor data that are used to pilot UAVs. By incorporating the inherent sensor data with network observations, SA-ABR trains a deep reinforcement learning (DRL) model to extract salient features from the flight state information and automatically learn an ABR algorithm to adapt to the varying UAV channel capacity through the training process. SA-ABR does not rely on any assumptions or models about UAV's flight states or the environment, but instead, it makes decisions by exploiting temporal properties of past throughput through the long short-term memory (LSTM) to adapt itself to a wide range of highly dynamic environments. We have implemented SA-ABR in a commercial UAV and evaluated it in the wild. We compare SA-ABR with a variety of existing state-of-the-art ABR algorithms, and the results show that our system outperforms the best known existing ABR algorithm by 21.4% in terms of the average quality of experience (QoE) reward.},
keywords={Throughput;Streaming media;Acceleration;Heuristic algorithms;Bit rate;Unmanned aerial vehicles;Adaptation models;Unmanned aerial vehicle;adaptive bitrate algorithm;video streaming;sensor-augmented system;deep reinforcement learning},
doi={10.1109/TMM.2019.2945167},
ISSN={1941-0077},
month={June},}
@INPROCEEDINGS{9417292,
author={Peng, Yingsheng and Liu, Yong and Zhang, Han},
booktitle={2021 IEEE Wireless Communications and Networking Conference (WCNC)}, title={Deep Reinforcement Learning based Path Planning for UAV-assisted Edge Computing Networks},
year={2021},
volume={},
number={},
pages={1-6},
abstract={Mobile edge computing (MEC) harvests the computation capability at the network edge to perform the computation intensive tasks for diverse IoT applications. Meanwhile, the unmanned aerial vehicle (UAV) has a great potential to flexibly enlarge the coverage, and enhance the network performance. Accordingly, it has been a promising paradigm to use the UAV to provide the edge computing service for massive IoT devices. This paper studies the path planning problem of a UAV-assisted edge computing network, where an UAV is deployed with an edge server to execute the computing tasks offloaded from multiple devices. We consider the mobility of devices, where a GaussMarkov random movement model is adopted. By taking the energy consumed for the dynamic flying and executing the tasks at the UAV into account, we formulate a path planning problem that aims to maximize the amount of offloaded data bits by the devices while minimizing the energy consumption of the UAV. To deal with the dynamic change of the complex environment, we apply the deep reinforcement learning (DRL) method to develop an online path planning algorithm based on double deep Q-learning network (DDQN). Extensive simulation results validate the effectiveness of the proposed DRL-based path planning algorithm in terms of the convergence speed and the system reward.},
keywords={Performance evaluation;Heuristic algorithms;Simulation;Reinforcement learning;Path planning;Unmanned aerial vehicles;Internet of Things;Deep Reinforcement Learning;Gauss-Markov stochastic model;Mobile edge computing;Unmanned Aerial Vehicle;Path optimization},
doi={10.1109/WCNC49053.2021.9417292},
ISSN={1558-2612},
month={March},}
@INPROCEEDINGS{9043152,
author={Krusniak, Miles and Leppanen, Keaton and Tang, Zhicheng and Gao, Fan and Wang, Yizhen and Shang, Yi},
booktitle={2020 IEEE International Conference on Consumer Electronics (ICCE)}, title={A Detection Confidence-Regulated Path Planning (DCRPP) Algorithm for Improved Small Object Counting in Aerial Images},
year={2020},
volume={},
number={},
pages={1-6},
abstract={Computerized object counting shows potential for conservation population estimates as an alternative to manual counting, but remains unsatisfactory for minuscule objects, such as those in UAV-produced images. We improve UAV data collection by using a novel path planner which shifts altitude to maximize deep learning-based object detection confidences from a Faster Region-Convolutional Neural Network, considering energy consumption trade-offs. Using an empirical altitude confidence relationship, our adaptive path planner (”DCRPP”) adjusts UAV altitude based on confidence, yielding better quality data given energy constraints. DCRPP achieves 11.92% greater accuracy compared to fixed-height methods in our conservation-aimed simulation.},
keywords={Deep learning;Sociology;Neural networks;Object detection;Manuals;Data collection;Autonomous aerial vehicles;Unmanned aerial vehicle;small object detection;aerial image;UAV path planning;deep learning},
doi={10.1109/ICCE46568.2020.9043152},
ISSN={2158-4001},
month={Jan},}
@INPROCEEDINGS{9299676,
author={Hao, Guoliang and Ni, Wanli and Tian, Hui and Cao, Leilei},
booktitle={2020 International Conference on Wireless Communications and Signal Processing (WCSP)}, title={Mobility-Aware Trajectory Design for Aerial Base Station Using Deep Reinforcement Learning},
year={2020},
volume={},
number={},
pages={1131-1136},
abstract={In this paper, an unmanned aerial vehicle (UAV) assisted wireless network is investigated, where an aerial base station (ABS) is deployed for serving both ground and aerial users. The objective is to maximize the uplink sum-rate of all users by designing the trajectory of the ABS, while considering the mobility of users. Specifically, it is assumed that all aerial UAVs move individually with the random waypoint mobility model (RWM). Meanwhile, some ground users move with the reference point group mobility model, while others follow the RWM as well. Due to the mobility of both ground and aerial users, conventional reinforcement learning (such as Q-learning) is very likely to fail for the curse of dimensionality. Therefore, it is non-trivial to solve the trajectory design problem in the large-scale highly dynamic environment. By approximating the value functions with neural networks, a deep reinforcement learning-based algorithm is proposed for the ABS to autonomously provide network services in the rapidly changing environment. Simulation results demonstrate that our designed double deep Q-network (DDQN) can learn the environment information very well with our elaborate rewards. Compared to the conventional DDQN with fully connected network, our proposed DDQN converges faster and has better stability.},
keywords={Trajectory;Atmospheric modeling;Reinforcement learning;Wireless networks;Approximation algorithms;Uplink;Neural networks;Unmanned aerial vehicle;trajectory design;deep reinforcement learning},
doi={10.1109/WCSP49889.2020.9299676},
ISSN={2472-7628},
month={Oct},}
@INPROCEEDINGS{9621076,
author={Kim, Young–il and Min, Yeo Geon and Hee, Park Seong and Wun-Cheol, Jeong and Soonyong, Song and Tae–Wook, Heo},
booktitle={2021 International Conference on Information and Communication Technology Convergence (ICTC)}, title={The analysis of UAV detection performance using rotating cameras},
year={2021},
volume={},
number={},
pages={1262-1265},
abstract={With the development of the drone industry, various technologies to detect the increasing illegal intrusion drones are being developed to reduce the damage caused by illegal intrusion drones. Deep learning-based image sensing techniques are useful for detecting and classifying drones at close range, but this requires the use of a large number of cameras. To solve this problem, this paper intends to analyze the detection performance of the unmanned aerial vehicle using the image sensing technology that rotates the camera. To this end, a method of constructing a UAV protection area and a method of rotating the camera in a spiral to increase the opportunity of UAV detection are proposed, and performance analysis based on rotating camera is performed.},
keywords={Industries;Image sensors;Spirals;Surveillance;Autonomous aerial vehicles;Cameras;Sensors;UAV detection;Deep Learning;UAV surveillance area},
doi={10.1109/ICTC52510.2021.9621076},
ISSN={2162-1233},
month={Oct},}
@ARTICLE{9515771,
author={Aloqaily, Moayad and Ridhawi, Ismaeel Al and Guizani, Mohsen},
journal={IEEE Transactions on Intelligent Transportation Systems}, title={Energy-Aware Blockchain and Federated Learning-Supported Vehicular Networks},
year={2021},
volume={},
number={},
pages={1-12},
abstract={The aerial capabilities and flexibility in movement of Unmanned Aerial Vehicles (UAVs) has enabled them to adaptively provide both traditional and more contemporary services. In this article, we introduce a solution that integrates the capabilities of both UAVs and Unmanned Ground Vehicles (UGVs) to provide both intelligent connectivity and services to both aerial and ground connected devices. A cooperative solution is adopted that considers nodes' power and movement constraints. The UAV and UGV cooperative process ensures continuous power availability to UAVs to support seamless and continuous service availability to end-devices. A Federated Learning (FL) approach is adopted at the edge to ensure accurate and up-to-date service provisioning in accordance with the surrounding environment and network constraints. Moreover, Blockchain technology is used to decentralize the provisioning and control aspects, and ensure authenticity and integrity. Extensive simulations are conducted to test the soundness and applicability of the proposed solution. Results show significant improvement in terms of connectivity, service availability, and UAV energy enhancements when compared to traditional mobile and vehicular communication techniques.},
keywords={Task analysis;Performance evaluation;Blockchains;Virtualization;Unmanned aerial vehicles;Service level agreements;Servers;Unmanned aerial vehicle;unmanned ground vehicle;artificial intelligence;blockchain;federated learning.},
doi={10.1109/TITS.2021.3103645},
ISSN={1558-0016},
month={},}
@INPROCEEDINGS{9279634,
author={Zhang, Shiming and Lei, Zeyu and Liu, Yi and Yang, Wei and Zhao, Qiang and Yang, Shenglan and Xu, Peng},
booktitle={2020 IEEE International Conference on High Voltage Engineering and Application (ICHVE)}, title={Analysis of intelligent inspection program for UAV grid based on AI},
year={2020},
volume={},
number={},
pages={1-4},
abstract={Realizing the standardization, intellectualization and automation of power line patrol is the ultimate goal of the development of power line patrol service. In this paper, the development history of power line patrol is briefly described, and the feasibility of AI-enabled power line patrol industry is analyzed. The “UAV patrol and AI intelligent analysis” processing scheme is proposed, and the future of the deep integration of AI and power grid is prospected.},
keywords={Inspection;Artificial intelligence;Power grids;Manuals;Unmanned aerial vehicles;Data models;Companies;artificial intelligence;unmanned aerial vehicle;power grid patrol},
doi={10.1109/ICHVE49031.2020.9279634},
ISSN={2474-3852},
month={Sep.},}
@ARTICLE{9652445,
author={Hou, Zhifeng and Chen, Jin and Huang, Yuzhen and Luo, Yijie and Wang, Ximing and Gu, Jiangchun and Xu, Yifan and Yao, Kailing},
journal={China Communications}, title={Joint trajectory and passive beamforming optimization in IRS-UAV enhanced anti-jamming communication networks},
year={2021},
volume={},
number={},
pages={1-15},
abstract={This paper investigates the anti-jamming communication scenario where an intelligent reflecting surface (IRS) is mounted on the unmanned aerial vehicle (UAV) to resist the malicious jamming attacks. Different from existing works, we consider the dynamic deployment of IRS-UAV in the environment of the mobile user and unknown jammer. Therefore, a joint trajectory and passive beamforming optimization approach is proposed in the IRS-UAV enhanced networks. In detail, the optimization problem is firstly formulated into a Markov decision process (MDP). Then, a dueling double deep Q networks multi-step learning algorithm is proposed to tackle the complex and coupling decision-making problem. Finally, simulation results show that the proposed scheme can significantly improve the anti-jamming communication performance of the mobile user.},
keywords={Jamming;Trajectory;Optimization;Array signal processing;Autonomous aerial vehicles;Reflection;Frequency-domain analysis;intelligent reflecting surface;unmanned aerial vehicle;deep reinforcement learning;trajectory optimization},
doi={10.23919/JCC.2021.00.001},
ISSN={1673-5447},
month={},}
@INPROCEEDINGS{6318697,
author={Kamarulzaman, Syafiq Fauzi and Shibuya, Takeshi and Yasunobu, Seiji},
booktitle={2012 Proceedings of SICE Annual Conference (SICE)}, title={A learning control system for rapid position control of aerial hovering vehicles},
year={2012},
volume={},
number={},
pages={1546-1551},
abstract={A learning based control system for rapid position control of aerial hovering vehicles is proposed. An aerial hovering vehicle uses angular orientation to accelerate during position control where target angle is preserve to produce acceleration. By arranging target angle, the acceleration and deceleration during position control can be configured, thus able to produce a rapid position control. In order to create a learning based control system for rapid position control, the characteristic of the position control by target angle of an aerial hovering vehicle is simplified an applied to an inverted pendulum system. The effectiveness was confirmed on the inverted pendulum system through simulations where several target position was assigned to be achieved.},
keywords={Vehicles;Acceleration;Position control;Force;Humans;Process control;Reinforcement Learning;Unmanned Aerial Vehicle;Inverted Pendulum},
doi={},
ISSN={},
month={Aug},}
@INPROCEEDINGS{9519367,
author={Ukaegbu, Uchechi and Tartibu, Lagouge and Okwu, Modestus},
booktitle={2021 International Conference on Artificial Intelligence, Big Data, Computing and Data Communication Systems (icABCD)}, title={Unmanned Aerial Vehicles for the Future: Classification, Challenges, and Opportunities},
year={2021},
volume={},
number={},
pages={1-7},
abstract={The world is moving very fast as Industry 4.0 has changed the way we live our daily lives. Researchers and strategists continue daily to explore technological innovations linked with artificial intelligence, machine learning, and robotics to support humans. The new technology no doubt will boost utilisation of resources and improve operations in diverse areas ranging from agriculture, health, military, oil and gas, transportation, big-box facilities, and fast-food services, thereby optimising processes and making life better and much more comfortable for humans. Unmanned aerial vehicle (UAV) has been identified as a special robotic system capable of meeting human needs if effectively programmed. This research is focused on the exposition of the diverse areas of application of UAV in the twenty-first century. Application of UAV in Agriculture, health, military, security, and others have been detailed. The challenges and future opportunities of UAVs have equally been identified. One of the major issues of concern is the endurance problem of UAV systems and issues on safety. Suggestions have been made on possible ways to address such issues.},
keywords={Service robots;Robot kinematics;Oils;Urban planning;Unmanned aerial vehicles;Agriculture;Distance measurement;unmanned aerial vehicle;Industry 4.0;robotics;machine learning;last-mile operations},
doi={10.1109/icABCD51485.2021.9519367},
ISSN={},
month={Aug},}
@ARTICLE{9527132,
author={Nouri, Nima and Fazel, Fahimeh and Abouei, Jamshid and Plataniotis, Kostas},
journal={IEEE Transactions on Mobile Computing}, title={Multi-UAV Placement and User Association in Uplink MIMO Ultra-Dense Wireless Networks},
year={2021},
volume={},
number={},
pages={1-1},
abstract={This paper investigates an Unmanned Aerial Vehicle (UAV)-enabled network consisting of smart mobile devices and multiple UAVs as aerial base stations in a Multiple-Input Multiple-Output (MIMO) architecture. Mobile devices are partitioned into several clusters and offload their tasks to UAV servers via the Non-Orthogonal Multiple Access (NOMA) protocol. We aim to jointly maximize the number of served IMDs, the user scheduling, the number of UAVs, and their $3$D placement. To this end, we formulate an optimization problem subject to some Quality of Service (QoS) constraints. Due to its non-convexity, we break the problem into two subproblems. We propose a machine-learning-based algorithm for the first subproblem, i.e., optimizing the UAVs' number and $3$D placements, and the user association. Unlike existing literature, our algorithm achieves low computational complexity and fast convergence. The second subproblem, the user scheduling, is non-convex too. We utilize the $\ell_p$-norm concept and optimize the user scheduling by applying the Successive Convex Approximation (SCA) algorithm. The aforementioned process is performed iteratively until convergence, and a near-optimal solution is achieved. Moreover, the computational complexity of the proposed scheme is analyzed. Regarding fast convergence and low computational complexity of the proposed algorithm, we confirm its superior performance through simulation results.},
keywords={NOMA;Three-dimensional displays;Servers;Approximation algorithms;Optimization;Mobile computing;Resource management;3D UAV placement;Mobile Edge Computing;MIMO;Machine learning},
doi={10.1109/TMC.2021.3108960},
ISSN={1558-0660},
month={},}
@ARTICLE{9027887,
author={Su, Jinya and Yi, Dewei and Su, Baofeng and Mi, Zhiwen and Liu, Cunjia and Hu, Xiaoping and Xu, Xiangming and Guo, Lei and Chen, Wen-Hua},
journal={IEEE Transactions on Industrial Informatics}, title={Aerial Visual Perception in Smart Farming: Field Study of Wheat Yellow Rust Monitoring},
year={2021},
volume={17},
number={3},
pages={2242-2249},
abstract={Agriculture is facing severe challenges from crop stresses, threatening its sustainable development and food security. This article exploits aerial visual perception for yellow rust disease monitoring, which seamlessly integrates state-of-the-art techniques and algorithms, including unmanned aerial vehicle sensing, multispectral imaging, vegetation segmentation, and deep learning U-Net. A field experiment is designed by infecting winter wheat with yellow rust inoculum, on top of which multispectral aerial images are captured by DJI Matrice 100 equipped with RedEdge camera. After image calibration and stitching, multispectral orthomosaic is labeled for system evaluation by inspecting high-resolution RGB images taken by Parrot Anafi Drone. The merits of the developed framework drawing spectral-spatial information concurrently are demonstrated by showing improved performance over purely spectral-based classifier by the classical random forest algorithm. Moreover, various network input band combinations are tested, including three RGB bands and five selected spectral vegetation indices, by sequential forward selection strategy of wrapper algorithm.},
keywords={Diseases;Monitoring;Cameras;Agriculture;Stress;Informatics;Sensors;Deep learning;multispectral image;precision agriculture;semantic segmentation;U-Net;unmanned aerial vehicle (UAV)},
doi={10.1109/TII.2020.2979237},
ISSN={1941-0050},
month={March},}
@INPROCEEDINGS{9554735,
author={Maimaitijiang, Maitiniyazi and Sagan, Vasit and Fritschi, Felix B.},
booktitle={2021 IEEE International Geoscience and Remote Sensing Symposium IGARSS}, title={Crop Yield Prediction using Satellite/Uav Synergy and Machine Learning},
year={2021},
volume={},
number={},
pages={6276-6279},
abstract={The work aims to predict soybean yield using satellite and Unmanned Aerial Vehicle (UAV) synergy and machine learning. UAV RGB imagery and Worldview satellite data was acquired in the summer of 2017 over a soybean field near Columbia, Missouri, USA. Canopy spectral features from satellite data and structural features from UAV imagery were combined and fused to predict soybean grain yield. Commonly used machine learning regression methods including Extreme Learning Regression (ELR), Random Forest Regression (RFR), Support Vector Regression (SVR) and Partial Least Squares Regression (PLSR) were utilized to predict soybean yield using spectral features from satellite data and structural features from UAV imagery. The results showed that canopy structure features such as canopy height and canopy coverage are important indicators for soybean grain yield estimation, and complementarities between Satellite and UAV data reveal a great potential of synergy, and lead to an improved performance for soybean grain yield estimation.},
keywords={Support vector machines;Satellites;Three-dimensional displays;Crops;Soil;Optical saturation;Unmanned aerial vehicles;yield prediction;machine learning;satellite and UAV synergy},
doi={10.1109/IGARSS47720.2021.9554735},
ISSN={2153-7003},
month={July},}
@INPROCEEDINGS{8766458,
author={Wang, Liang and Huang, Peiqiu and Wang, Kezhi and Zhang, Guopeng and Zhang, Lei and Aslam, Nauman and Yang, Kun},
booktitle={2019 15th International Wireless Communications Mobile Computing Conference (IWCMC)}, title={RL-Based User Association and Resource Allocation for Multi-UAV enabled MEC},
year={2019},
volume={},
number={},
pages={741-746},
abstract={In this paper, multi-unmanned aerial vehicle (UAV) enabled mobile edge computing (MEC), i.e., UAVE is studied, where several UAVs are deployed as flying MEC platform to provide computing resource to ground user equipments (UEs). Compared to the traditional fixed location MEC, UAV enabled MEC (i.e., UAVE) is particular useful in case of temporary events, emergency situations and on-demand services, due to its high flexibility, low cost and easy deployment features. However, operation of UAVE faces several challenges, two of which are how to achieve both 1) the association between multiple UEs and UAVs and 2) the resource allocation from UAVs to UEs, while minimizing the energy consumption for all the UEs. To address this, we formulate the above problem into a mixed integer nonlinear programming (MINLP), which is difficult to be solved in general, especially in the large-scale scenario. We then propose a Reinforcement Learning (RL)-based user Association and resource Allocation (RLAA) algorithm to tackle this problem efficiently and effectively. Numerical results show that the proposed RLAA can achieve the optimal performance with comparison to the exhaustive search in small scale, and have considerable performance gain over other typical algorithms in large-scale cases.},
keywords={Task analysis;Resource management;Energy consumption;Unmanned aerial vehicles;Edge computing;Programming;Reinforcement Learning;Mobile Edge Computing;Unmanned Aerial Vehicle;User Association;Resource Allocation},
doi={10.1109/IWCMC.2019.8766458},
ISSN={2376-6506},
month={June},}
@INPROCEEDINGS{9580253,
author={Sha, Deshuang and Zhao, Rui},
booktitle={2021 IEEE/CIC International Conference on Communications in China (ICCC)}, title={DRL-based Task Offloading and Resource Allocation in Multi-UAV-MEC Network with SDN},
year={2021},
volume={},
number={},
pages={595-600},
abstract={Mobile edge computing (MEC) is applied to 5G communication to meet the needs of large-scale data communication. Unmanned aerial vehicle (UAV) can be used as air base station to provide edge computing services for users in remote areas. In this paper, we consider a multi- UAV enabled MEC (i.e., Multi-UAV-MEC) network, where software defined network (SDN) is adopted to improve the quality of services (QoS) for all users, and we study the problem of task offloading and resource allocation. In the proposed network, UAV s act as MEC servers to provide computation offloading services for ground equipments (GEs), and a SDN controller is responsible for collecting network global information and providing offloading decision and resource allocation strategy for all GEs and UAV s. We aim to minimize the weighted sum of the task processing delay and energy consumption in the network, and the above problem is a mixed-integer and non-convex problem. To address this challenge, we transform the problem into a MDP, and propose a deep reinforcement learning (DRL)-based algorithm. The SDN controller is considered as a agent to learn the optimal offloading and resource allocation strategy. Simulation results show that the proposed DRL-based algorithm can achieve better performance than other baseline algorithms under different conditions.},
keywords={Costs;Simulation;Reinforcement learning;Quality of service;Transforms;Germanium;Unmanned aerial vehicles;Mobile edge computing;unmanned aerial vehicle;software defined network;deep reinforcement learning},
doi={10.1109/ICCC52777.2021.9580253},
ISSN={2377-8644},
month={July},}
@INPROCEEDINGS{9299784,
author={Wang, Ziduan and Zhang, Tiankui and Liu, Yuanwei and Xu, Wenjun},
booktitle={2020 International Conference on Wireless Communications and Signal Processing (WCSP)}, title={Deep Reinforcement Learning for Caching Placement and Content Delivery in UAV NOMA Networks},
year={2020},
volume={},
number={},
pages={406-411},
abstract={The cache-enabling unmanned aerial vehicle (UAV) cellular network is investigated in this article, where the massive access capability is enhanced by applying non-orthogonal multiple access (NOMA). More particularly, a mobile UAV base station, which caches the popular contents to release the pressure on wireless backhaul links, is deployed to assist the delivery of large volume multimedia contents for ground users. The dynamic UAV cellular network with the dynamic UAV locations and content requests in practical scenario is considered in this paper. A long-term caching placement and content delivery joint optimization problem for content delivery delay minimization is formulated as a Markov decision process (MDP) to cope with the dynamic environment. A deep reinforcement learning (DRL) based caching placement and content delivery algorithm is proposed to tackle the MDP with large action space. Finally, it is demonstrated by the numerical results that: 1) a low content delivery delay is achieved by the studied cache-enabling UAV NOMA networks; 2) a good performance is provided by the proposed algorithm.},
keywords={Unmanned aerial vehicles;Delays;NOMA;Wireless communication;Vehicle dynamics;Interference;Resource management;dynamic resource allocation;non-orthogonal multiple access;reinforcement learning;unmanned aerial vehicle},
doi={10.1109/WCSP49889.2020.9299784},
ISSN={2472-7628},
month={Oct},}
@INPROCEEDINGS{9120668,
author={Li, Xuan and Wang, Qiang and Liu, Jie and Zhang, Wenqi},
booktitle={2020 IEEE Wireless Communications and Networking Conference (WCNC)}, title={Trajectory Design and Generalization for UAV Enabled Networks:A Deep Reinforcement Learning Approach},
year={2020},
volume={},
number={},
pages={1-6},
abstract={In this paper, an unmanned aerial vehicle (UAV) flies as a base station (BS) to provide wireless communication service. We propose two algorithms for designing the trajectory of the UAV and analyze the impact of different training approaches on transferring to new environments. When the UAV is used to track users that move along some specific paths, we propose a proximal policy optimization (PPO) -based algorithm to maximize the instantaneous sum rate (MSR-PPO). The UAV is modeled as a deep reinforcement learning (DRL) agent to learn how to move by interacting with the environment. When the UAV serves users along unknown paths for emergencies, we propose a random training proximal policy optimization (RT-PPO) algorithm which can transfer the pre-trained model to new tasks to achieve quick deployment. Unlike classical DRL algorithms that the agent is trained on the same task to learn its actions, RT-PPO randomizes the features of tasks to get the ability to transfer to new tasks. Numerical results reveal that MSR-PPO achieves a remarkable improvement and RT-PPO shows an effective generalization performance.},
keywords={Training;Wireless communication;Q-learning;Tracking;Conferences;Autonomous aerial vehicles;Trajectory;unmanned aerial vehicle;trajectory design;generalization;deep reinforcement learning},
doi={10.1109/WCNC45663.2020.9120668},
ISSN={1558-2612},
month={May},}
@INPROCEEDINGS{8249468,
author={Alihodzic, Adis and Tuba, Eva and Capor-Hrosik, Romana and Dolicanin, Edin and Tuba, Milan},
booktitle={2017 25th Telecommunication Forum (TELFOR)}, title={Unmanned aerial vehicle path planning problem by adjusted elephant herding optimization},
year={2017},
volume={},
number={},
pages={1-4},
abstract={Unmanned aerial vehicle path planning is a high dimensional NP-hard problem. It is related to optimizing the flight route subject to various constraints inside the battlefield environment. Since the number of control points is large the traditional methods could not produce acceptable results when tackling this problem. Elephant herding optimization algorithm is one of the recent swarm intelligence algorithms which has not been sufficiently researched. In this paper we have adjusted the elephant herding optimization algorithm for the unmanned aerial vehicle path planning problem. We tested our approach using parameters of the battlefield environments from the literature and the comparative analysis has shown that our adjusted elephant herding optimization algorithm outperformed other approaches from the literature.},
keywords={Path planning;Unmanned aerial vehicles;Algorithm design and analysis;Optimization;Sociology;Statistics;Particle swarm optimization;Unmanned aerial vehicle;Drone;Elephant herding optimization;Swarm intelligence;Path planning},
doi={10.1109/TELFOR.2017.8249468},
ISSN={},
month={Nov},}
@INPROCEEDINGS{8898996,
author={Wyniawskyj, Nina Sofia and Napiorkowska, Milena and Petit, David and Podder, Pritimoy and Wilson, Jim and Woods, Doug},
booktitle={IGARSS 2019 - 2019 IEEE International Geoscience and Remote Sensing Symposium}, title={KORE Application: Potatoes Yield Assessment},
year={2019},
volume={},
number={},
pages={7239-7242},
abstract={KORE is a cloud-based precision agriculture platform, based on subscriptions, that combines satellites, drones and ground sensor data. This paper focuses on one of its applications: yield assessment in potato fields using UAV data and deep learning.},
keywords={Agriculture;Deep learning;Image segmentation;Satellites;Remote sensing;Classification algorithms;Cloud computing;machine learning;deep learning;remote sensing;image segmentation;classification;CNN;UAV},
doi={10.1109/IGARSS.2019.8898996},
ISSN={2153-7003},
month={July},}
@INPROCEEDINGS{9639807,
author={Karahan, Mehmet and Kasnakoglu, Cosku},
booktitle={2021 International Conference Automatics and Informatics (ICAI)}, title={Path Planning and Collision Avoidance with Artificial Intelligence for a Quadrotor UAV},
year={2021},
volume={},
number={},
pages={163-166},
abstract={Artificial intelligence has brought new features to unmanned aerial vehicles. Path planning, trajectory optimization and obstacle avoidance are some of the features that artificial intelligence brings to drones. In this study, path planning optimization and collision avoidance with artificial intelligence for an unmanned aerial vehicle are emphasized. Path planning and collision avoidance simulations were performed using MATLAB software under ideal conditions and under noisy conditions. It is shown that the unmanned aerial vehicle finds the shortest path on maps with various obstacles.},
keywords={White noise;Autonomous aerial vehicles;Distortion;Path planning;Software;Noise measurement;Collision avoidance;Quadrotor;UAV;path planning;obstacle avoidance;optimization;A-star algorithm;artificial intelligence},
doi={10.1109/ICAI52893.2021.9639807},
ISSN={},
month={Sep.},}
@ARTICLE{9165228,
author={Zhang, Tiankui and Wang, Ziduan and Liu, Yuanwei and Xu, Wenjun and Nallanathan, Arumugam},
journal={IEEE Transactions on Vehicular Technology}, title={Caching Placement and Resource Allocation for Cache-Enabling UAV NOMA Networks},
year={2020},
volume={69},
number={11},
pages={12897-12911},
abstract={This article investigates the cache-enabling unmanned aerial vehicle (UAV) cellular networks with massive access capability supported by non-orthogonal multiple access (NOMA). The delivery of a large volume of multimedia contents for ground users is assisted by a mobile UAV base station, which caches some popular contents for wireless backhaul link traffic offloading. In cache-enabling UAV NOMA networks, the caching placement of content caching phase and radio resource allocation of content delivery phase are crucial for network performance. To cope with the dynamic UAV locations and content requests in practical scenarios, we formulate the long-term caching placement and resource allocation optimization problem for content delivery delay minimization as a Markov decision process (MDP). The UAV acts as an agent to take actions for caching placement and resource allocation, which includes the user scheduling of content requests and the power allocation of NOMA users. In order to tackle the MDP, we propose a Q-learning based caching placement and resource allocation algorithm, where the UAV learns and selects action with soft ${\varepsilon }$-greedy strategy to search for the optimal match between actions and states. Since the action-state table size of Q-learning grows with the number of states in the dynamic networks, we propose a function approximation based algorithm with combination of stochastic gradient descent and deep neural networks, which is suitable for large-scale networks. Finally, the numerical results show that the proposed algorithms provide considerable performance compared to benchmark algorithms, and obtain a trade-off between network performance and calculation complexity.},
keywords={Resource management;NOMA;Cellular networks;Optimization;Approximation algorithms;Heuristic algorithms;Wireless communication;Dynamic resource allocation;non-orthogonal multiple access;reinforcement learning;unmanned aerial vehicle},
doi={10.1109/TVT.2020.3015578},
ISSN={1939-9359},
month={Nov},}
@ARTICLE{8740949,
author={Asheralieva, Alia and Niyato, Dusit},
journal={IEEE Internet of Things Journal}, title={Hierarchical Game-Theoretic and Reinforcement Learning Framework for Computational Offloading in UAV-Enabled Mobile Edge Computing Networks With Multiple Service Providers},
year={2019},
volume={6},
number={5},
pages={8753-8769},
abstract={We present a novel game-theoretic (GT) and reinforcement learning (RL) framework for computational offloading in the mobile edge computing (MEC) network operated by multiple service providers (SPs). The network is formed by MEC servers installed at stationary base stations (BSs) and unmanned aerial vehicles (UAVs) deployed as quasi-stationary BSs. Since computing powers of MEC servers are limited, the BSs in proximity can form coalitions with shared data processing resources to serve their users more efficiently. However, as BSs can be privately owned or controlled by different SPs, in any coalition, the BSs: 1) take only the actions that maximize their long-term payoffs and 2) do not coordinate their actions with other BSs in the coalition. That is, inside each coalition, BSs act in an independent and self-interested manner. Therefore, the interactions among BSs cannot be described by conventional coalitional games. Instead, the network operation is modeled by a two-level hierarchical model. The upper level is a cooperative game that defines the process of coalition formation. The lower level comprises the set of noncooperative subgames to represent a self-interested and independent behavior of BSs in coalitions. To enable each BS to select a coalition and decide on its action maximizing its long-term payoff, we propose two algorithms that combine coalition formation with RL and prove that these algorithms converge to the states where the coalitional structure is strongly stable and the strategies of BSs are in the mixed-strategy Nash equilibrium (NE).},
keywords={Servers;Games;Task analysis;Quality of service;Computational modeling;Internet of Things;Stochastic processes;Edge computing;game theory;heterogeneous networks;mobile cloud computing (MEC);reinforcement learning (RL);resource allocation;unmanned aerial vehicle (UAV) communication},
doi={10.1109/JIOT.2019.2923702},
ISSN={2327-4662},
month={Oct},}
@INPROCEEDINGS{9345069,
author={Ma, Xingjie and Yin, Changchuan and Liu, Xuanlin},
booktitle={2020 IEEE 6th International Conference on Computer and Communications (ICCC)}, title={Machine Learning Based Joint Offloading and Trajectory Design in UAV Based MEC System for IoT Devices},
year={2020},
volume={},
number={},
pages={902-909},
abstract={In this paper, we consider an unmanned aerial vehicle (UAV)-based mobile edge computing (MEC) system for Internet of Things devices (IoTDs), in which the mobile UAV equipped with computing resources provides service for all IoTDs in the system and each IoTD also has a certain amount of computing power. Each IoTD has a computing task to be completed and the computing task will be offloaded to the UAV or implemented locally. After the UAV completes the service for any IoTD, it proceeds to the next IoTD, until that all IoTDs in the system have been served. The UAV can collect all information related to all IoTDs before taking off, such as the data size of the computing task and the coordinate of the locations of all IoTDs. Our goal is to minimize the total delay of the system (i.e., flying delay, transmission delay, local computing delay and UAV-aided edge computing delay) through joint optimization of the flying trajectory of the UAV and the ratio of the offloading tasks. Aiming at this problem, a machine learning framework based on Q-learning algorithm is proposed so as to minimize the total delay of the system. Simulation results show that the proposed algorithm can achieve up to 15.7% and 38.0% gain compared to the random algorithm with dynamic selection of task offloading mode and the Q-learning algorithm with fixed selection of task offloading mode.},
keywords={Machine learning algorithms;Heuristic algorithms;Simulation;Unmanned aerial vehicles;Delays;Trajectory;Task analysis;unmanned aerial vehicle communications;mobile edge computing;Internet of Things;machine learning},
doi={10.1109/ICCC51575.2020.9345069},
ISSN={},
month={Dec},}
@ARTICLE{9560080,
author={Qin, Zhenquan and Liu, Zhonghao and Han, Guangjie and Lin, Chuan and Guo, Linlin and Xie, Ling},
journal={IEEE Transactions on Vehicular Technology}, title={Distributed UAV-BSs Trajectory Optimization for User-Level Fair Communication Service With Multi-Agent Deep Reinforcement Learning},
year={2021},
volume={70},
number={12},
pages={12290-12301},
abstract={Unmanned Aerial Vehicles (UAVs) have attacted much attention in the field of wireless communication due to its agility and altitude. UAVs can be used as low-altitude aerial base stations (UAV-BSs) to provide communication services for ground devices (GDs) in various scenarios, such as emergency communication and traffic offloading in hotspots. However, due to the limited communication ranges and high prices of commercial UAV-BSs, covering a target area all the time with sufficient UAVs is quite challenging, especially under dynamic environment. We need to design the trajectory of the UAV-BSs to optimize system performance. Most existing works focus on the energy-efficient coverage and throughput maximization but ignore the fairness of communication service, especially the fairness at user-level. Besides, reinforcement learning is suitable for solving decision problems in dynamic environments. However, most existing works use centralized deep reinforcement learning (DRL) approaches. Due to the scalability and low time complexity, a distributed DRL approach is more suitable for multiple UAV-BSs communication system in dynamic environment. Unlike previous works, we characterize the fairness at user-level based on proportional fairness scheduling and formulate a weighted-throughput maximization problem via designing UAV-BSs’ trajectory. Then we model the dynamic deploymentproblem of UAV-BSs as a Markov game and propose a multi-agent deep reinforcement learning-based distributed UAV-BSs control approach named MAUC. MAUC approach adopts the framework of centralized training with distributed execution. Simulation results show that the MAUC can improve fairness of communication service by sacrificing a small amount of throughput.},
keywords={Multi-agent systems;Trajectory optimization;Wireless communication;Reinforcement learning;Unmanned aerial vehicles;UAV communication;deep reinforcement learning;UAV control;fairness},
doi={10.1109/TVT.2021.3117792},
ISSN={1939-9359},
month={Dec},}
@ARTICLE{9707819,
author={Li, Yuchen and Pawlak, Jered and Price, Joshua and Al Shamaileh, Khair and Niyaz, Quamar and Paheding, Sidike and Devabhaktuni, Vijay},
journal={IEEE Access}, title={Jamming Detection and Classification in OFDM-Based UAVs via Feature- and Spectrogram-Tailored Machine Learning},
year={2022},
volume={10},
number={},
pages={16859-16870},
abstract={In this paper, a machine learning (ML) approach is proposed to detect and classify jamming attacks against orthogonal frequency division multiplexing (OFDM) receivers with applications to unmanned aerial vehicles (UAVs). Using software-defined radio (SDR), four types of jamming attacks; namely, barrage, protocol-aware, single-tone, and successive-pulse are launched and investigated. Each type is qualitatively evaluated considering jamming range, launch complexity, and attack severity. Then, a systematic testing procedure is established by placing an SDR in the vicinity of a UAV (i.e., drone) to extract radiometric features before and after a jamming attack is launched. Numeric features that include signal-to-noise ratio (SNR), energy threshold, and key OFDM parameters are used to develop a feature-based classification model via conventional ML algorithms. Furthermore, spectrogram images collected following the same testing procedure are exploited to build a spectrogram-based classification model via state-of-the-art deep learning algorithms (i.e., convolutional neural networks). The performance of both types of algorithms is analyzed quantitatively with metrics including detection and false alarm rates. Results show that the spectrogram-based model classifies jamming with an accuracy of 99.79% and a false-alarm of 0.03%, in comparison to 92.20% and 1.35%, respectively, with the feature-based counterpart.},
keywords={Jamming;Feature extraction;OFDM;Interference;Drones;Spectrogram;Testing;Cybersecurity;convolutional neural networks (CNNs);deep learning;jamming;machine learning (ML);orthogonal frequency division multiplexing (OFDM);software-defined radio (SDR);spectrogram;unmanned aerial vehicles (UAVs)},
doi={10.1109/ACCESS.2022.3150020},
ISSN={2169-3536},
month={},}
@INPROCEEDINGS{9627359,
author={Li, Chunnu},
booktitle={2021 IEEE/ACIS 20th International Fall Conference on Computer and Information Science (ICIS Fall)}, title={Artificial Intelligence Technology in UAV Equipment},
year={2021},
volume={},
number={},
pages={299-302},
abstract={Modern science and technology is developing rapidly, at the same time, artificial intelligence technology is also developing rapidly. Now, artificial intelligence technology has penetrated into all aspects of our lives. In this paper, the application of artificial intelligence technology in UAV equipment is studied. In the study, we selected two aircraft for simulation experiments, one is an unmanned aircraft using artificial intelligence technology, the other is an aircraft without artificial intelligence technology, other conditions are the same, respectively from the two aircraft capabilities and detection performance are analyzed. In the ability evaluation, the perception ability, decision-making ability, behavior ability and learning ability are evaluated respectively, and the detection performance is analyzed from the detection rate and false detection rate. The results show that the average score of UAV with AI technology is 9.25, while the average score of UAV without AI technology is 7.85. It can be seen that the UAV equipment using artificial intelligence technology has advantages in all aspects of capabilities.},
keywords={Analytical models;Information science;Computational modeling;Atmospheric modeling;Decision making;Artificial intelligence;Aircraft;Artificial Intelligence Technology;UAV Equipment;Capability Evaluation;Detection Performance},
doi={10.1109/ICISFall51598.2021.9627359},
ISSN={},
month={Oct},}
@ARTICLE{9738820,
author={Grasso, Christian and Raftopoulos, Raoul and Schembra, Giovanni},
journal={IEEE Transactions on Network and Service Management}, title={Smart Zero-Touch Management of UAV-Based Edge Network},
year={2022},
volume={},
number={},
pages={1-1},
abstract={The next generation of wireless communications networks, namely 6G, will be aimed at realizing a fully connected world, and at providing ubiquitous connectivity to people and objects even in remote areas that are very far from the structured Internet core network. These goals include the definition and the design of intelligent communications environments mainly characterized by pervasive artificial intelligence and large-scale automation. The target of this paper is the design of a management framework for edge networks realized with Flying Ad-Hoc Networks (FANET) consisting of a set of Unmanned Aerial Vehicles (UAVs) to provide a remote geographic area with computing and networking facilities for delay-sensitive applications. To this purpose, each UAV is equipped with a Computing Element (CE) to process jobs received through vertical offloading from ground devices. In addition, horizontal offload among UAVs of the FANET is introduced for load balancing purposes, to guarantee that the FANET computation delay for each received job is minimized and is almost independent of the activity state of the area covered by the UAV receiving that job. The proposed FANET management framework is based on Deep Reinforcement Learning (DRL) to allow zero-touch adaptation to the timevariant activity state of the area covered by each UAV. Numerical results demonstrate the power of the proposed framework and the enhancements achieved with respect to the current literature.},
keywords={6G mobile communication;Artificial intelligence;Delays;5G mobile communication;Internet;Autonomous aerial vehicles;Edge computing;6G;Zero-Touch Network Management;UAVs;Deep Reinforcement Learning;Markov Decision Process.},
doi={10.1109/TNSM.2022.3160858},
ISSN={1932-4537},
month={},}
@INPROCEEDINGS{6705283,
author={Chumachenko, O. I. and Gorbatiuk, V. S.},
booktitle={2013 IEEE 2nd International Conference Actual Problems of Unmanned Air Vehicles Developments Proceedings (APUAVD)}, title={Forecasting the demand for UAV using different neural networks topology},
year={2013},
volume={},
number={},
pages={62-64},
abstract={According to modern researches and reports there will be significant growth in UAV sector. This paper introduces another method of forecasting that can be used to predict the demand for UAV of different types.},
keywords={Forecasting;Topology;Network topology;Neurons;Neural networks;Time series analysis;Logic gates;unmanned aerial vehicle;neural networks;demand forecasting;group method of data handling},
doi={10.1109/APUAVD.2013.6705283},
ISSN={},
month={Oct},}
@INPROCEEDINGS{9641207,
author={Ding, Yuanxue and Qu, Yanchen and Zhang, Qing and Tong, Jiahui and Yang, Xianhui and Sun, Jianfeng},
booktitle={2021 IEEE International Conference on Unmanned Systems (ICUS)}, title={Research on UAV Detection Technology of Gm-APD Lidar Based on YOLO Model},
year={2021},
volume={},
number={},
pages={105-109},
abstract={In recent years, unmanned aerial vehicle (UAV) technology has developed rapidly, which plays an important role in both military and civil fields. While it brings convenience to all walks of life, there are also a lot of security problems. Therefore, it is necessary to study anti-UAV technology, but the detection of UAV is an important basis of anti-UAV technology. In this paper, by combining the three-dimensional range profile collected by Gm-APD (Geiger mode Avalanche Photo Diode) lidar with the deep learning method, a UAV detection method based on the improved YOLOv3 (You Only Look Once v3) network is proposed. Firstly, the data of UAV in low altitude real scene is collected by Gm-APD lidar, and range profile information is generated. Then, the YOLOv3 network is improved, and the SPP module can be added to combine the local features of the target with the global features to improve the detection accuracy. It is suitable for the detection of UAVs. Finally, the trajectory of the UAV is drawn based on the distance information. The experimental results show that the improved method can effectively detect UAV targets, and is better than the previous method, YOLOv3-Tiny method and YOLOv4 method. The farthest detection distance is 238m, the detection speed is fast, and the purpose of real-time detection and positioning can be achieved. Therefore, this method can be applied to anti-UAV technology and has important research significance.},
keywords={Deep learning;Laser radar;Conferences;Object detection;Autonomous aerial vehicles;Feature extraction;Real-time systems;target detection;UAV;anti-UAV technology;deep learning;YOLOv3},
doi={10.1109/ICUS52573.2021.9641207},
ISSN={},
month={Oct},}
@INPROCEEDINGS{8308815,
author={Sineglazov, V.M. and Chumachenko, O.I. and Gorbatiuk, V.S.},
booktitle={2017 IEEE 4th International Conference Actual Problems of Unmanned Aerial Vehicles Developments (APUAVD)}, title={A new approach in cluster analysis},
year={2017},
volume={},
number={},
pages={223-226},
abstract={A new clustering approach that is capable of finding clusters that are separated by some complex hypersurface is proposed. The approach can be useful for performing analysis of big amounts of unlabeled images that can be nowadays easily gathered, in particular by using unmanned aerial vehicle with mounted cameras. The approach is based on “softening” the initial clustering criterion and then using nonlinear optimization to find the optimal hypersurface that separates clusters.},
keywords={Clustering algorithms;Neurons;Approximation algorithms;Optimization;Self-organizing feature maps;Unmanned aerial vehicles;Conferences;unmanned aerial vehicle;soft clustering;nonlinear optimization;artificial neural networks},
doi={10.1109/APUAVD.2017.8308815},
ISSN={},
month={Oct},}
@INPROCEEDINGS{9128981,
author={Chen, Xianfu and Chen, Tao and Zhao, Zhifeng and Zhang, Honggang and Bennis, Mehdi and JI, Yusheng},
booktitle={2020 IEEE 91st Vehicular Technology Conference (VTC2020-Spring)}, title={Resource Awareness In Unmanned Aerial Vehicle-Assisted Mobile-Edge Computing Systems},
year={2020},
volume={},
number={},
pages={1-6},
abstract={This paper investigates an unmanned aerial vehicle (UAV)-assisted mobile-edge computing (MEC) system, in which the UAV provides complementary computation resource to the terrestrial MEC system. The UAV processes the received computation tasks from the mobile users (MUs) by creating the corresponding virtual machines. Due to finite shared I/O resource of the UAV in the MEC system, each MU competes to schedule local as well as remote task computations across the decision epochs, aiming to maximize the expected long-term computation performance. The non-cooperative interactions among the MUs are modeled as a stochastic game, in which the decision makings of a MU depend on the global state statistics and the task scheduling policies of all MUs are coupled. To approximate the Nash equilibrium solutions, we propose a proactive scheme based on the long short-term memory and deep reinforcement learning (DRL) techniques. A digital twin of the MEC system is established to train the proactive DRL scheme offline. Using the proposed scheme, each MU makes task scheduling decisions only with its own information. Numerical experiments show a significant performance gain from the scheme in terms of average utility per MU across the decision epochs.},
keywords={Task analysis;Unmanned aerial vehicles;Computational modeling;Mobile handsets;Wireless communication;Stochastic processes;Cloud computing;Mobile-edge computing;unmanned aerial vehicle;resource awareness;deep reinforcement learning;long shortterm memory;digital twin.},
doi={10.1109/VTC2020-Spring48590.2020.9128981},
ISSN={2577-2465},
month={May},}
@ARTICLE{9434412,
author={Guo, Xufeng and Chen, Yuanbin and Wang, Ying},
journal={IEEE Wireless Communications Letters}, title={Learning-Based Robust and Secure Transmission for Reconfigurable Intelligent Surface Aided Millimeter Wave UAV Communications},
year={2021},
volume={10},
number={8},
pages={1795-1799},
abstract={In this letter, we study the robust and secure transmission in the millimeter-wave (mmWave) unmanned aerial vehicle (UAV) communication assisted by a reconfigurable intelligent surface (RIS) under imperfect channel state information (CSI). Specifically, the active beamforming of the UAV, the coefficients of the RIS elements and the UAV trajectory are jointly designed to maximize the sum secrecy rate of all legitimate users in the presence of multiple eavesdroppers. However, the CSI is coupled with the UAV trajectory, which results in complex constraints. Furthermore, the time-related issue caused by the outdated CSI also makes the formulated problem intractable to solve. To tackle these challenges, by leveraging the deep deterministic policy gradient (DDPG) framework, a novel and effective twin-DDPG deep reinforcement learning (TDDRL) algorithm is proposed. Simulation results demonstrate the effectiveness and robustness of the proposed algorithm, and the RIS can significantly improve the sum secrecy rate.},
keywords={Unmanned aerial vehicles;Array signal processing;Trajectory;Reinforcement learning;Millimeter wave communication;Optimization;Wireless communication;Reconfigurable intelligent surface;physical layer security;unmanned aerial vehicle;millimeter-wave communications;deep reinforcement learning},
doi={10.1109/LWC.2021.3081464},
ISSN={2162-2345},
month={Aug},}
@ARTICLE{8854903,
author={Li, Kai and Ni, Wei and Tovar, Eduardo and Jamalipour, Abbas},
journal={IEEE Transactions on Vehicular Technology}, title={On-Board Deep Q-Network for UAV-Assisted Online Power Transfer and Data Collection},
year={2019},
volume={68},
number={12},
pages={12215-12226},
abstract={Unmanned Aerial Vehicles (UAVs) with Microwave Power Transfer (MPT) capability provide a practical means to deploy a large number of wireless powered sensing devices into areas with no access to persistent power supplies. The UAV can charge the sensing devices remotely and harvest their data. A key challenge is online MPT and data collection in the presence of on-board control of a UAV (e.g., patrolling velocity) for preventing battery drainage and data queue overflow of the devices, while up-to-date knowledge on battery level and data queue of the devices is not available at the UAV. In this paper, an on-board deep Q-network is developed to minimize the overall data packet loss of the sensing devices, by optimally deciding the device to be charged and interrogated for data collection, and the instantaneous patrolling velocity of the UAV. Specifically, we formulate a Markov Decision Process (MDP) with the states of battery level and data queue length of devices, channel conditions, and waypoints given the trajectory of the UAV; and solve it optimally with Q-learning. Furthermore, we propose the on-board deep Q-network that enlarges the state space of the MDP, and a deep reinforcement learning based scheduling algorithm that asymptotically derives the optimal solution online, even when the UAV has only outdated knowledge on the MDP states. Numerical results demonstrate that our deep reinforcement learning algorithm reduces the packet loss by at least 69.2%, as compared to existing non-learning greedy algorithms.},
keywords={Trajectory;Batteries;Data collection;Wireless communication;Wireless sensor networks;Resource management;Sensors;Unmanned aerial vehicle;microwave power transfer;online resource allocation;deep reinforcement learning;Markov decision process},
doi={10.1109/TVT.2019.2945037},
ISSN={1939-9359},
month={Dec},}
@INPROCEEDINGS{9580401,
author={Wang, Yang and Gao, Zhen},
booktitle={2021 IEEE/CIC International Conference on Communications in China (ICCC)}, title={Three-Dimensional Trajectory Design for Multi-User MISO UAV Communications: A Deep Reinforcement Learning Approach},
year={2021},
volume={},
number={},
pages={706-711},
abstract={In this paper, we investigate a multi-user downlink multiple-input single-output (MISO) unmanned aerial vehicle (UAV) communication system, where a multi-antenna UAV is employed to serve multiple ground terminals. Unlike existing approaches focus only on a simplified two-dimensional scenario, this paper considers a three-dimensional (3D) urban environment, where the UAV's 3D trajectory is designed to minimize data transmission completion time subject to practical throughput and flight movement constraints. Specifically, we propose a deep reinforcement learning (DRL)-based trajectory design for completion time minimization (DRL- TDCTM), which is developed from a deep deterministic policy gradient algorithm. In particular, to represent the state information of UAV and environment, we set an additional information, i.e., the merged pheromone, as a reference of reward which facilitates the algorithm design. By interacting with the external environment in the corresponding Markov decision process, the proposed algorithm can continuously and adaptively learn how to adjust the UAV's movement strategy. Finally, simulation results show the superiority of the proposed DRL- TDCTM algorithm over the conventional baseline methods.},
keywords={Three-dimensional displays;Simulation;Urban areas;Reinforcement learning;MISO communication;Throughput;Downlink;Multi-antenna UAV;UAV communication systems;3D trajectory design;deep reinforcement learning},
doi={10.1109/ICCC52777.2021.9580401},
ISSN={2377-8644},
month={July},}
@INPROCEEDINGS{9322761,
author={Matsui, Kai and Shirai, Hikaru and Kageyama, Yoichi and Yokoyama, Hiroshi},
booktitle={2020 Joint 11th International Conference on Soft Computing and Intelligent Systems and 21st International Symposium on Advanced Intelligent Systems (SCIS-ISIS)}, title={Learning Data Conditions for Resolution Improvement Using UAV Data},
year={2020},
volume={},
number={},
pages={1-2},
abstract={This study investigates a resolution improvement method using the visible range and its band ratio of remote sensing data. In this paper, we examined the conditions of learning data to improve the accuracy of the resolution improvement method through the band ratio of unmanned aerial vehicle data. Results obtained using the dataset with a large standard deviation had greater accuracy than those using the dataset with a small standard deviation for 72.2 % of the band ratio in the test data.},
keywords={Standards;Water quality;Unmanned aerial vehicles;Remote sensing;Training data;Training;Lakes;remote sensing;unmanned aerial vehicle;machine learning;resolution improvement},
doi={10.1109/SCISISIS50064.2020.9322761},
ISSN={},
month={Dec},}
@INPROCEEDINGS{9339049,
author={Ma, Linfei and Yan, Kai and Wang, Long},
booktitle={2020 IEEE 9th Joint International Information Technology and Artificial Intelligence Conference (ITAIC)}, title={Research on Person Re-identification Method Based on Data Link Technology},
year={2020},
volume={9},
number={},
pages={1157-1161},
abstract={Person re-identification (re-ID) aims to query or match the identical individuals across multiple non-overlapping surveillance cameras and has become an important visual task in various applications such as pedestrian security and video surveillance. Although much recent progress has been made to address the problem of person re-ID, the blind areas without surveillance cameras are not considered, which are usually the hiding places of criminals or suspects. In order to solve this problem, in this paper, we apply data link technology to person re-ID, and propose a person re-ID model based on data link technology, which can realize all-round, continuous and real-time monitoring and tracking of target persons, and even achieve the identifying and attacking of partial key target persons.},
keywords={Visualization;Target tracking;Cameras;Video surveillance;Data models;Real-time systems;Security;person re-identification;data link;unmanned aerial vehicle;deep learning},
doi={10.1109/ITAIC49862.2020.9339049},
ISSN={2693-2865},
month={Dec},}
@ARTICLE{9728721,
author={Masuduzzaman, Md and Rahim, Tariq and Islam, Anik and Shin, Soo Young},
journal={IEEE Internet of Things Journal}, title={UxV-based Deep-Learning Integrated Automated and Secure Garbage Management Scheme using Blockchain},
year={2022},
volume={},
number={},
pages={1-1},
abstract={This paper presents a deep learning (DL) model integrated automated and secure garbage management scheme using unmanned any vehicle (UxV) to minimize the human effort in terms of the traditional garbage management system. Different kinds of UxV (unmanned aerial vehicles, automated guided vehicles, unmanned surface vehicles, unmanned underwater vehicles, etc.) are utilized to establish an automated garbage management scheme to collect and place the garbage both from the ground and sea surfaces. However, due to the limited battery capacity and inadequate resources of different UxV, a lightweight DL model is developed to detect the garbage successfully with a higher accuracy rate. The proposed lightweight DL model uses two activation functions named MISH and rectified linear unit to enhance the feature extraction and detect the garbage. Moreover, a multi-access edge computing (MEC) server is allocated in the proposed scheme to improve the quality of service (QoS) (i.e., reduce latency and improve security). Furthermore, a blockchain-based secure hazardous garbage (e.g., infectious, toxic, or radioactive materials) tracking technique is concluded in this scheme to identify the individual and reduce the potential harm to the environment. Experimental results demonstrate that the UxV can successfully detect the garbage using the proposed lightweight DL model within a minimum time frame and the obtained accuracy is higher than the other existing DL models. Besides, QoS has been investigated to verify the efficacy of the proposed scheme. Finally, a private blockchain network is established to demonstrate the performance of the proposed hazardous garbage tracking technique.},
keywords={Blockchains;Servers;Sea surface;Quality of service;Feature extraction;Convolutional neural networks;Hazardous materials;Blockchain;Deep learning;Multi-access edge computing;Quality of service;Unmanned aerial vehicle.},
doi={10.1109/JIOT.2022.3156617},
ISSN={2327-4662},
month={},}
@INPROCEEDINGS{8404201,
author={Sarıbaş, Hasan and Çevıkalp, Hakan and Kahvecıoğlu, Sinem},
booktitle={2018 26th Signal Processing and Communications Applications Conference (SIU)}, title={Car detection in images taken from unmanned aerial vehicles},
year={2018},
volume={},
number={},
pages={1-4},
abstract={In recent years, unmanned aerial vehicles have become a popular research platform with many application areas such as military, civil, commercial and recreational areas, thanks to their high maneuverability, vertical take-off / landing, and outdoor and indoor use. Today, small, light, and very high powerful embedding systems have been developed. Therefore, many real-time computer vision applications can be run on unmanned aerial vehicle platforms by integrating such embedding systems onto these vehicles. In this work, the problem of car detection (localization) in images taken from unmanned aerial vehicles has been studied. To this end, we collected a new aerial image dataset by using quadcopters and different type of cameras. To solve the car detection problem, the results were compared by using both the Polyhedral Conic Classifier and the You Only Look Once (YOLO) algorithm which is considered one of the fastest deep neural network methods in the literature.},
keywords={Computer vision;Object detection;Unmanned aerial vehicles;Automobiles;Real-time systems;Conferences;Histograms;Unmanned aerial vehicle;car detection;polyhedralcConiccClassifier;deep learning;you only look once (YOLO)},
doi={10.1109/SIU.2018.8404201},
ISSN={},
month={May},}
@INPROCEEDINGS{9369789,
author={Wan Seo, Jong and Heon Han, Seung and Young Shin, Soo},
booktitle={2021 International Conference on Electronics, Information, and Communication (ICEIC)}, title={Deep learning based Nuclear Power Plant Monitoring System using UAV},
year={2021},
volume={},
number={},
pages={1-4},
abstract={This paper proposes a nuclear power plant monitoring system using drones. Existing surveillance systems have a disadvantage in that manpower is wasted due to the blind spots of fixed observatories and CCTVs, and it is impossible to quickly respond to situations. The proposed system detects motion winners and suspicious vehicles around nuclear power plants by using object detection technology using thermal imaging cameras and autonomous flight technology and also measures radiation levels and temperature data using Geiger counters and temperature sensors. Data can be transmitted through the 5G/LTE module and monitored in real-time.},
keywords={Temperature measurement;Temperature sensors;Temperature distribution;Power measurement;Surveillance;Power generation;Nuclear measurements;Radioactivity measurement;deep learning;you only look once;thermal camera;unmanned aerial vehicle},
doi={10.1109/ICEIC51217.2021.9369789},
ISSN={},
month={Jan},}
@INPROCEEDINGS{8965587,
author={Kutlu, Özgür and Demir, Önder and Doğan, Barış},
booktitle={2019 1st International Informatics and Software Engineering Conference (UBMYK)}, title={Analysis Of Images Obtained By Unmanned Aerial Vehicle By Deep Learning Methods},
year={2019},
volume={},
number={},
pages={1-4},
abstract={In artificial intelligence applications, many sub-methods such as machine learning, artificial neural networks, classification, clustering algorithms are used. One of these methods is deep learning. Deep learning is an advanced machine learning class. Using the Deep Learning method, video analysis, image classification, speech recognition and natural language processing are very successful. The data and experiences to be provided by the projects covering Deep Learning and Unmanned Aerial Vehicles will increase the number of qualified studies on these issues and contribute to the development of high value-added products in these technologies. In this study, a control software that evaluates image data from unmanned aerial vehicles and makes various inferences (classification, positioning, marking) is created. By using the method of retraining the last layers of the pre-trained artificial neural network models with our data set, it has been tried to reduce the training time and increase the success. In these studies, 2 pre-educated models were used and as a result of training of these models, as a result of 190 thousand steps of training, 25.39 and 27.87 mAP values were reached.},
keywords={Unmanned aerial vehicles;Deep learning;Google;Artificial neural networks;Training;deep learning;artificial neural network;classification;unmanned aerial vehicle)},
doi={10.1109/UBMYK48245.2019.8965587},
ISSN={},
month={Nov},}
@INPROCEEDINGS{8928091,
author={Zhou, Conghao and He, Hongli and Yang, Peng and Lyu, Feng and Wu, Wen and Cheng, Nan and Shen, Xuemin},
booktitle={2019 11th International Conference on Wireless Communications and Signal Processing (WCSP)}, title={Deep RL-based Trajectory Planning for AoI Minimization in UAV-assisted IoT},
year={2019},
volume={},
number={},
pages={1-6},
abstract={Due to the flexibility and low deployment cost, unmanned aerial vehicles (UAVs) have been widely used to assist cellular networks in providing extended coverage for Internet of Things (IoT) networks. Existing throughput or delay-based UAV trajectory planning methods cannot meet the requirement of collecting fresh information from IoT devices. In this paper, by taking age-of-information (AoI) as a measure of information freshness, we investigate AoI-based UAV trajectory planning for fresh data collection. To model the complicated association and interaction pattern between UAV and IoT devices, the UAV trajectory planning problem is formulated as a Markov decision process (MDP) to capture the dynamics of UAV locations. As network topology and traffic generation pattern are unknown ahead, we propose an AoI-based trajectory planning (A-TP) algorithm using deep reinforcement learning (RL) technique. To accelerate the learning process during online decision making, the off-line pre-training of deep neural networks is performed. Extensive simulation results demonstrate that the proposed algorithm can significantly reduce the AoI of collected IoT data, as compared to other benchmark approaches.},
keywords={Trajectory;Planning;Unmanned aerial vehicles;Monitoring;Delays;Internet of Things;Throughput;Internet of Things;age-of-information;unmanned aerial vehicle;trajectory planning;deep reinforcement learning},
doi={10.1109/WCSP.2019.8928091},
ISSN={2472-7628},
month={Oct},}
@ARTICLE{9681290,
author={Liu, Haishi and Sun, Yuxuan and Cao, Jianing and Chen, Shiyun and Pan, Nan and Dai, Yujiao and Pan, Dilin},
journal={IEEE Transactions on Industrial Informatics}, title={Study on UAV Parallel Planning System for Transmission Line Project Acceptance under the Background of Industry 5.0},
year={2022},
volume={},
number={},
pages={1-1},
abstract={In the context of Industry 5.0, this paper studies the Cyber-Physical-Social Systems in UAVs based on the task background of transmission line project acceptance. Firstly, based on the idea of a parallel system, a parallel UAV planning system for transmission line project acceptance tasks is developed. The mathematical model based on swarm intelligence is then constructed from the multi-dimensional perspective of improving the acceptance efficiency, shortening the acceptance time, and reducing the energy consumption. This is done based on the physical system data, while considering the constraints of UAVs in performing acceptance tasks. Experiments are simulated based on the actual environment data of the quality supervision and acceptance of a 500kv transmission line project in a plateau area before it is put into production. The obtained results are compared with those of other similar cutting-edge algorithms. The efficiency and practicality of the proposed artificial parallel planning system are finally verified.},
keywords={Power transmission lines;Task analysis;Planning;Industries;Mathematical models;Trajectory planning;Particle swarm optimization;UAVs for Industry 50;Cyber-Physical-Social Systems;Swarm Intelligence;Parallel Systems;Transmission Line Project Acceptance},
doi={10.1109/TII.2022.3142723},
ISSN={1941-0050},
month={},}
@ARTICLE{9749133,
author={Zhu, Kun and Yang, Jia and Zhang, Yang and Nie, Jiangtian and Lim, Wei Yang Bryan and Zhang, Hongliang and Xiong, Zehui},
journal={IEEE Transactions on Green Communications and Networking}, title={Aerial Refueling: Scheduling Wireless Energy Charging for UAV Enabled Data Collection},
year={2022},
volume={},
number={},
pages={1-1},
abstract={The working scope and working time of small size unmanned aerial vehicles (UAVs) are limited because of the limited battery capacity. In this work, inspired by aerial refueling for aircrafts, we propose a wireless power transmission (WPT) scheme by categorizing the UAVs into charging UAV (CUAV) and mission UAV (MUAV) for charging UAVs without interrupting the mission. In the proposed aerial refueling scheme, mission UAVs (MUAV) can be recharged by charging UAVs on the fly and operate in a perpetual manner. The feasibility of aerially wireless charging for small UAVs is firstly discussed and evaluated. Then we consider a practical application scenario of multiple MUAVs for collecting data from several points of interest, where the MUAVs are recharged by CUAVs. Accordingly, the issue of scheduling the flying path and charging process of each CUAV to minimize the mission time arises. Deep reinforcement learning (DRL) based algorithms for scheduling both single and multiple CUAVs are proposed and deployed. Extensive simulation evaluations demonstrate that, by applying the proposed aerial refueling scheme, CUAVs can explore and optimize the scheduling strategies, thereby improving the system performance in terms of mission completion and charging efficiency.},
keywords={Autonomous aerial vehicles;Inductive charging;Wireless communication;Charging stations;Magnetic resonance;Couplings;Batteries;UAV energy management;wireless charging;deep reinforcement learning.},
doi={10.1109/TGCN.2022.3164602},
ISSN={2473-2400},
month={},}
@ARTICLE{9629361,
author={Wang, Xueyuan and Cenk Gursoy, M.},
journal={IEEE Transactions on Wireless Communications}, title={Learning-Based UAV Trajectory Optimization with Collision Avoidance and Connectivity Constraints},
year={2021},
volume={},
number={},
pages={1-1},
abstract={Unmanned aerial vehicles (UAVs) are expected to be an integral part of wireless networks, and determining collision-free trajectories for multiple UAVs while satisfying requirements of connectivity with ground base stations (GBSs) is a challenging task. In this paper, we consider non-cooperative multi-UAV scenarios, in which multiple UAVs need to fly from initial locations to destinations, while satisfying collision avoidance, wireless connectivity, and kinematic constraints. We aim to find trajectories for the UAVs with the goal to minimize their mission completion time. We first formulate the multi-UAV trajectory optimization problem as a sequential decision making problem. We, then, propose a decentralized deep reinforcement learning approach to solve the problem. More specifically, a value network is developed to obtain values given the agent’s joint state (including the agent’s information, the nearby agents’ observable information, and the locations of the nearby GBSs). A signal-to-interference-plus-noise ratio (SINR)-prediction neural network is also designed, using accumulated SINR measurements obtained when interacting with the cellular network, to map the GBSs’ locations into the SINR levels in order to predict the UAV’s SINR. Numerical results show that with the value network and SINR-prediction network, real-time navigation for multi-UAVs can be efficiently performed in various environments with high success rate.},
keywords={Reinforcement learning;Collision avoidance;Wireless communication;Autonomous aerial vehicles;Trajectory optimization;Cellular networks;Antennas;Collision avoidance;decentralized algorithms;deep reinforcement learning;multi-UAV trajectory design;wireless connectivity},
doi={10.1109/TWC.2021.3129226},
ISSN={1558-2248},
month={},}
@ARTICLE{9678008,
author={Liu, Ying and Yan, Junjie and Zhao, Xiaohui},
journal={IEEE Transactions on Vehicular Technology}, title={Deep Reinforcement Learning based Latency Minimization for Mobile Edge Computing with Virtualization in Maritime UAV Communication Network},
year={2022},
volume={},
number={},
pages={1-1},
abstract={The rapid development of maritime activities has led to the emergence of more and more computation-intensive applications. In order to meet the huge demand for wireless communications in maritime environment, mobile edge computing (MEC) is considered as an effective solution to provide powerful computing capabilities for maritime terminals of resource scarcity or latency sensitive. A basic technology to implement MEC is virtual machine (VM) multiplexing, through which multi-task parallel computing on a server is realized. In this paper, a two-layer unmanned aerial vehicles (UAVs) maritime communication network with a centralized top-UAV (T-UAV) and a group of distributed bottom-UAVs (B-UAVs) is established and MEC is used on T-UAV. We aim to solve the latency minimization problem for both communication and computation in this maritime UAV swarm mobile edge computing network. We reformulate this problem into a Markov decision process (MDP), since it is a non-convex and multiply constrained but has the characteristics of MDP. Based on this MDP model, we take deep reinforcement learning (DRL) as our tool to propose a deep Q-network (DQN) and a deep deterministic policy gradient (DDPG) algorithms to optimize the trajectory of T-UAV and configuration of virtual machines (VMs). Using these two proposed algorithms, we can minimize the system latency. Simulation results show that the given solutions are valid and effective.},
keywords={Task analysis;Trajectory;Maritime communications;Servers;Resource management;Parallel processing;Optimization;Maritime communication;deep reinforcement learning (DRL);latency minimization;UAV trajectory design;mobile edge computing (MEC);virtual machine (VM)},
doi={10.1109/TVT.2022.3141799},
ISSN={1939-9359},
month={},}
@ARTICLE{9440534,
author={Dong, Jiong and Ota, Kaoru and Dong, Mianxiong},
journal={IEEE Journal on Miniaturization for Air and Space Systems}, title={UAV-Based Real-Time Survivor Detection System in Post-Disaster Search and Rescue Operations},
year={2021},
volume={2},
number={4},
pages={209-219},
abstract={When a natural disaster occurs, the most critical task is to search and rescue trapped people as soon as possible. In recent years, unmanned aerial vehicles (UAVs) have been widely employed because of their high durability, low cost, ease of implementation, and flexibility. In this article, we collected a new thermal image dataset captured by drones. After that, we used several different deep convolutional neural networks to train survivor detection models on our dataset, including YOLOV3, YOLOV3-MobileNetV1, and YOLOV3- MobileNetV3. Due to the limited computing power and memory of the onboard microcomputer, to balance the inference time and accuracy, we found the optimal points to prune and fine-tune the survivor detection network based on the sensitivity of the convolutional layer. We verified it on NVIDIA’s Jetson TX2 and achieved a real-time performance of 26.60 frames/s (FPS). Moreover, we designed a real-time survivor detection system based on DJI Matrice 210 and Manifold 2-G to provide search and rescue services after the disaster.},
keywords={Unmanned aerial vehicles;Drones;Convolutional neural networks;Rescue robots;Real-time systems;Robot vision systems;Convolutional neural networks (CNNs);search and rescue;survivor detection;thermal image;unmanned aerial vehicle (UAV)},
doi={10.1109/JMASS.2021.3083659},
ISSN={2576-3164},
month={Dec},}
@INPROCEEDINGS{9352109,
author={Trong, Tuan Do and Tran Hai, Quan and Duc, Nam Tran and Trong Thanh, Han},
booktitle={2020 IEEE Eighth International Conference on Communications and Electronics (ICCE)}, title={A Novelty Approach to Emulate Field Data Captured by Unmanned Aerial Vehicles for Training Deep Learning Algorithms Used for Search-and-Rescue Activities at Sea},
year={2021},
volume={},
number={},
pages={288-293},
abstract={Nowadays, unmanned aerial vehicle (UAV) is gradually becoming popular and has applications in many fields of life and protection of national sovereignty over islands and sea. In particular, along with the increase in economic exploitation activities in the exclusive economic zones and climate change, the need for rescue and safety in the marine environment is urgent more than ever. The integration of deep learning algorithms into UAVs is a new trend to help finding the victim's location at sea faster as well as increase the chances of the victim being rescued. This paper proposes an method for detection of humans on the surface of the sea together with the GPS location of the victim and the algorithm to search for the victims in the orbit of concentric circles using deep learning algorithms. The novelty of the proposed system is to build a simulated marine environment to provide a diverse number of dataset for training in deep learning algorithms and simulated rescue scenarios. Thereby the costs and risks in training could be reduced as comparing to actions taking place in real marine environments.},
keywords={Deep learning;Training;Economics;Sea surface;Unmanned aerial vehicles;Safety;Global Positioning System;Unmanned Aerial Vehicle;Deep Learning;Search and Rescue},
doi={10.1109/ICCE48956.2021.9352109},
ISSN={},
month={Jan},}
@INPROCEEDINGS{9136980,
author={Zhou, Shanglin and Li, Bingbing and Ding, Caiwu and Lu, Lu and Ding, Caiwen},
booktitle={2020 21st International Symposium on Quality Electronic Design (ISQED)}, title={An Efficient Deep Reinforcement Learning Framework for UAVs},
year={2020},
volume={},
number={},
pages={323-328},
abstract={3D Dynamic simulator such as Gazebo has become a popular substitution for unmanned aerial vehicle (UAV) because of its user-friendly in real-world scenarios. At this point, well-functioning algorithms on the UAV controller are needed for guidance, navigation, and control for autonomous navigation. Deep reinforcement learning (DRL) comes into sight as its famous self-learning characteristic. This goal-orientated algorithm can learn how to attain a complex objective or maximize along a particular dimension over many steps. In this paper, we propose a general framework to incorporate DRL with the UAV simulation environment. The whole system consists of the DRL algorithm for attitude control, packing algorithm on the Robot Operation System (ROS) to connect DRL with PX4 controller, and a Gazebo simulator that emulates the real-world environment. Experimental results demonstrate the effectiveness of the proposed framework.},
keywords={Solid modeling;Three-dimensional displays;Attitude control;Navigation;Heuristic algorithms;Rotors;Reinforcement learning;Deep Reinforcement Learning;Gazebo;PX4;Simulation Environment;Unmanned Aerial Vehicle},
doi={10.1109/ISQED48828.2020.9136980},
ISSN={1948-3287},
month={March},}
@INPROCEEDINGS{8641189,
author={Li, Jun and Liu, Qian and Wu, Pingyang and Shu, Feng and Jin, Shi},
booktitle={2018 IEEE/CIC International Conference on Communications in China (ICCC)}, title={Task Offloading for UAV-based Mobile Edge Computing via Deep Reinforcement Learning},
year={2018},
volume={},
number={},
pages={798-802},
abstract={With rapid increase of data processing demands from users in mobile edge computing (MEC), the conventional mobile edge servers (MESs) are no longer capable of providing timely and effective services. Against this background, we focus on applying unmanned aerial vehicle (UAV) as an MES to provide computational task offloading services for users. In this paper, we aim at maximizing the migration throughput of user tasks with limited energy at the UAV. To be specific, we first formulate the maximization problem as a semi-Markov decision process (SMDP) without transition probability. Then we propose the deep reinforcement learning (DRL)-based scheme of maximizing user tasks migration throughput to solve the maximization problem. The scheme realizes a maximum autonomic migration throughput of users with limited UAV energy and improves quality of service (QoS) of MEC to some extent. Simulation results demonstrate that the proposed scheme is sufficient with favourable convergence.},
keywords={Task analysis;Throughput;Unmanned aerial vehicles;Energy consumption;Quality of service;Reinforcement learning;Path planning;Unmanned aerial vehicle;semi-Markov decision process;deep reinforcement learning},
doi={10.1109/ICCChina.2018.8641189},
ISSN={2377-8644},
month={Aug},}
@INPROCEEDINGS{9604698,
author={Ozkan, Zehra and Bayhan, Erdem and Namdar, Mustafa and Basgumus, Arif},
booktitle={2021 5th International Symposium on Multidisciplinary Studies and Innovative Technologies (ISMSIT)}, title={Object Detection and Recognition of Unmanned Aerial Vehicles Using Raspberry Pi Platform},
year={2021},
volume={},
number={},
pages={467-472},
abstract={In this study, the methods of deep learningbased detection and recognition of threats, evaluated in terms of military and defense industry, using Raspberry Pi platform by unmanned aerial vehicles (UAV) are presented. In the proposed approach, firstly, the training for machine learning on the objects is carried out using convolutional neural networks, which is one of the deep learning algorithms. By choosing the Faster-RCNN and SSD MobileNet V2 architectures of the deep learning method, it is aimed to compare the achievements of the accuracy at the end of the training. In order to be used in the training and testing stages of the recommended methods, data sets containing images selected from different weather, land conditions and different time periods of the day are determined. The model for the detection and recognition of the threatening elements is trained, using 3948 images. Then, the trained model was transferred to the Raspberry Pi 4 Model B electronic board. The method of detecting and recognizing the objects is tested with military operation images and records taken by the UAVs via Raspberry Pi Camera V2 module. While an accuracy rate of %91 has been achieved in the Faster-RCNN architecture in object detection and recognition, this rate has been observed as %88 in the SSD MobileNet V2 architecture.},
keywords={Training;Deep learning;Image recognition;Machine learning algorithms;Defense industry;Object detection;Unmanned aerial vehicles;Faster-RCNN;UAV;machine learning;object recognition;object detection;Raspberry Pi;SSD MobileNet V2},
doi={10.1109/ISMSIT52890.2021.9604698},
ISSN={},
month={Oct},}
@ARTICLE{9201288,
author={Chen, Elin and Chen, Junfu and Mohamed, Ali Wagdy and Wang, Bi and Wang, Zhendong and Chen, Yang},
journal={IEEE Access}, title={Swarm Intelligence Application to UAV Aided IoT Data Acquisition Deployment Optimization},
year={2020},
volume={8},
number={},
pages={175660-175668},
abstract={It is feasible and safe to use unmanned aerial vehicle (UAV) as the data collection platform of the Internet of things (IoT). In order to save the energy loss of the platform and make the UAV perform the collection work effectively, it is necessary to optimize the deployment of UAV. The objective problem is to minimize the sum of the lost energy of UAV and the loss of data transmission of Internet of things devices. The key to solving the problem is to calculate the location of the docking points and the number of docking points when the UAV is working to collect data. This paper proposes a coding scheme based on swarm intelligence optimization, which encapsulates the docking position of UAV into a dimension, so the number of docking points to be calculated is the dimension number of optimization objective. This problem is considered as a dynamic dimension optimization problem. Each individual in swarm intelligence algorithm is a solution. When adjusting the dimension, the best individual is added or deleted to achieve dynamic search in the evolutionary process. Collaborative search among multiple individuals can improve the local optimal limit of search to a certain extent. Finally, the validity of the swarm intelligence-based coding approach is verified by simulation under seven IoT device distribution scenarios. The swarm intelligence algorithms we used are flower pollination algorithm (FPA), salp swarm algorithm (SSA), sine cosine algorithm (SCA). FPA and SCA perform most efficiently in three and four scenarios among the seven IoT device scenarios, respectively.},
keywords={Unmanned aerial vehicles;Optimization;Internet of Things;Data collection;Energy consumption;Particle swarm optimization;Encoding;UAV deployment optimization;Internet of things data collection;swarm intelligence;dynamic dimension optimization},
doi={10.1109/ACCESS.2020.3025409},
ISSN={2169-3536},
month={},}
@INPROCEEDINGS{7593592,
author={Budaev, Denis and Amelin, Konstantin and Voschuk, Georgy and Skobelev, Petr and Amelina, Natalia},
booktitle={2016 International Conference on Control, Decision and Information Technologies (CoDIT)}, title={Real-time task scheduling for multi-agent control system of UAV's group based on network-centric technology},
year={2016},
volume={},
number={},
pages={378-381},
abstract={The multi-agent approach and technology for distributed scheduling, coordination and control of several UAV in group in order to perform joint tasks in real time was considered. The network-centric multi-agent system for real-time task scheduling for UAV's group was proposed. Two part of sheduling initial scheduling and dynamic rescheduling (task redistributed) were considered. For real-time task redistributed the randomized local voting protocol was used. The architecture of system consists of three basic subsystem. The approach to the organization of subsystems and agents within each subsystem interaction was described).},
keywords={Unmanned aerial vehicles;Real-time systems;Planning;Scheduling;Protocols;Fires;Software;Unmanned aerial vehicle (UAV);multi-agent systems;swarm intelligence;coordinated control},
doi={10.1109/CoDIT.2016.7593592},
ISSN={},
month={April},}
@ARTICLE{9446301,
author={Zhou, Longyu and Leng, Supeng and Liu, Qiang and Wang, Qing},
journal={IEEE Internet of Things Journal}, title={Intelligent UAV Swarm Cooperation for Multiple Targets Tracking},
year={2022},
volume={9},
number={1},
pages={743-754},
abstract={With the advantages of easy deployment and flexible usage, unmanned aerial vehicle (UAV) has advanced the multitarget tracking (MTT) applications. The UAV-MTT system has great potentials to execute dull, dangerous, and critical missions for frontier defense and security. A key challenge in UAV-MTT is how to coordinate multiple UAVs to track diverse invading targets accurately and consecutively. In this article, we propose a UAV swarm-based cooperative tracking architecture to systematically improve the UAV tracking performance. We design an intelligent UAV swarm-based cooperative algorithm for consecutive target tracking and physical collision avoidance. Moreover, we design an efficient cooperative algorithm to predict the trajectory of invading targets accurately. Our simulation results demonstrate that the swarm behaviors stay stable in realistic scenarios with perturbing obstacles. Compared with state-of-the-art solutions, such as the matched deep $Q$ -network, our algorithms can increase tracking accuracy by 60%, reduce tracking delay by 23%, and achieve physical collision-avoidance during the tracking process.},
keywords={Target tracking;Sensors;Task analysis;Trajectory;Unmanned aerial vehicles;Computational modeling;Prediction algorithms;Mobile target tracking;prediction;scheduling;unmanned-aerial-vehicle (UAV) swarm intelligence (SI)},
doi={10.1109/JIOT.2021.3085673},
ISSN={2327-4662},
month={Jan},}
@INPROCEEDINGS{8997771,
author={Chen, Yutong and Zhang, Liang and Liu, Yufen and Chen, Yuqin},
booktitle={2019 IEEE 4th Advanced Information Technology, Electronic and Automation Control Conference (IAEAC)}, title={Research on gesture recognition control of UAV based on CNN+FCN},
year={2019},
volume={1},
number={},
pages={2174-2177},
abstract={Unmanned aerial vehicles (UAVs) are the focus of development and Cultivation in China, especially in artificial intelligence. Current UAV control mainly carries out related flight tasks through a certain professional training of pilots'hand-held remote controllers, which is undoubtedly not conducive to the popularity of UAVs. In recent years, the rapid development of artificial intelligence, especially in image recognition, has achieved good results. In many practical applications, its identification ability surpasses human beings and brings opportunities to the development of all walks of life. In order to popularize UAV better, this paper studies the introduction of gesture recognition control in UAV, and puts forward a scheme of camera mounted in UAV and human gesture shooting and recognition, which simplifies the cumbersome control of UAV.},
keywords={Gesture recognition;Unmanned aerial vehicles;Mathematical model;Biological neural networks;Artificial intelligence;Industries;UAV;Artificial Intelligence;Camera;Gesture Recognition},
doi={10.1109/IAEAC47372.2019.8997771},
ISSN={2381-0947},
month={Dec},}
@ARTICLE{8633299,
author={Hu, Bo and Yang, Hanzhang and Wang, Lei and Chen, Shanzhi},
journal={China Communications}, title={A trajectory prediction based intelligent handover control method in UAV cellular networks},
year={2019},
volume={16},
number={1},
pages={1-14},
abstract={The airborne base station (ABS) can provide wireless coverage to the ground in unmanned aerial vehicle (UAV) cellular networks. When mobile users move among adjacent ABSs, the measurement information reported by a single mobile user is used to trigger the handover mechanism. This handover mechanism lacks the consideration of movement state of mobile users and the location relationship between mobile users, which may lead to handover misjudgments and even communication interrupts. In this paper, we propose an intelligent handover control method in UAV cellular networks. Firstly, we introduce a deep learning model to predict the user trajectories. This prediction model learns the movement behavior of mobile users from the measurement information and analyzes the positional relations between mobile users such as avoiding collision and accommodating fellow pedestrians. Secondly, we propose a handover decision method, which can calculate the users' corresponding receiving power based on the predicted location and the characteristic of air-to-ground channel, to make handover decisions accurately. Finally, we use realistic data sets with thousands of non-linear trajectories to verify the basic functions and performance of our proposed intelligent handover control method. The simulation results show that the handover success rate of the proposed method is 8% higher than existing methods.},
keywords={Handover;Trajectory;Predictive models;Unmanned aerial vehicles;Cellular networks;Deep learning;UAV airborne base station;handover control;trajectory prediction;deep learning},
doi={10.12676/j.cc.2019.01.001},
ISSN={1673-5447},
month={Jan},}
@ARTICLE{9738818,
author={Wei, Kaimin and Huang, Kai and Wu, Yongdong and Li, Zhetao and He, Hongliang and Zhang, Jilian and Chen, Jinpeng and Guo, Song},
journal={IEEE Internet of Things Journal}, title={High-performance UAV Crowdsensing: A Deep Reinforcement Learning Approach},
year={2022},
volume={},
number={},
pages={1-1},
abstract={Path planning is critical to realizing a high-performance UAV crowdsensing system, which can be deployed to carry out large-scale tasks in the physical world, especially in emergency scenarios like earthquakes and mudslides. Deep reinforcement learning (DRL) has recently proven its superiority in path design. However, it is often applied under the assumption that the entire status of the target region is available, which is hard to achieve in practice. Instead, efforts should be made to ensure efficient flight of several UAVs in order to collect data with incomplete observations in specified places. In this work, we set out to create a high-performance UAV crowdsensing system by combining deep reinforcement learning with partial observations. We present a novel DRL-based path planning algorithm called DRL-PP. Specifically, we integrate an attention mechanism into the actor-critic technique to assist UAV swarm collaboration to collect data. We also design an incentive mechanism to ease the problem of sparse reward. Furthermore, we provide a dilemma detection system to prevent the generation of overlapping flight paths. Experimental results from extensive simulations prove that, compared with the state-of-the-art approaches, the proposed DRL-PP can significantly improve the efficiency of data collection.},
keywords={Crowdsensing;Task analysis;Sensors;Autonomous aerial vehicles;Data collection;Navigation;Trajectory;Crowdsensing;UAV;Deep Reinforcement Learning;Markov Decision Process.},
doi={10.1109/JIOT.2022.3160887},
ISSN={2327-4662},
month={},}
@ARTICLE{9082162,
author={Samir, Moataz and Ebrahimi, Dariush and Assi, Chadi and Sharafeddine, Sanaa and Ghrayeb, Ali},
journal={IEEE Transactions on Mobile Computing}, title={Leveraging UAVs for Coverage in Cell-Free Vehicular Networks: A Deep Reinforcement Learning Approach},
year={2021},
volume={20},
number={9},
pages={2835-2847},
abstract={The success in transitioning towards smart cities relies on the availability of information and communication technologies that meet the demands of this transformation. The terrestrial infrastructure presents itself as a preeminent component in this change. Unmanned aerial vehicles (UAVs) empowered with artificial intelligence (AI) are expected to become an integral component of future smart cities that provide seamless coverage for vehicles on highways with poor cellular infrastructure. Motivated by the above, in this paper, we introduce UAVs cell-free network for providing coverage to vehicles entering a highway that is not covered by other infrastructure. However, UAVs have limited energy resources and cannot serve the entire highway all the time. Furthermore, the deployed UAVs have insufficient knowledge about the environment (e.g., the vehicles' instantaneous location). Therefore, it is challenging to control a swarm of UAVs to achieve efficient communication coverage. To address these challenges, we formulate the trajectories decisions making as a Markov decision process (MDP) where the system state space considers the vehicular network dynamics. Then, we leverage deep reinforcement learning (DRL) to propose an approach for learning the optimal trajectories of the deployed UAVs to efficiently maximize the vehicular coverage, where we adopt Actor-Critic algorithm to learn the vehicular environment and its dynamics to handle the complex continuous action space. Finally, simulations results are provided to verify our findings and demonstrate the effectiveness of the proposed design and show that during the mission time, the deployed UAVs adapt their velocities in order to cover the vehicles.},
keywords={Trajectory;Road transportation;Reinforcement learning;Vehicle dynamics;Aerospace electronics;Wireless networks;Task analysis;UAV coverage;deep reinforcement learning;UAVs’ trajectories;drive-thru;actor-critic algorithm;vehicular networks},
doi={10.1109/TMC.2020.2991326},
ISSN={1558-0660},
month={Sep.},}
@ARTICLE{9678344,
author={Liu, Yitong and Yan, Junjie and Zhao, Xiaohui},
journal={IEEE Internet of Things Journal}, title={Deep Reinforcement Learning based optimal transmission policies for opportunistic UAVs-aided Wireless Sensor Network},
year={2022},
volume={},
number={},
pages={1-1},
abstract={When there are UAVs performing their specifically assigned tasks in the air, some of them still have available resources to access different ground communication networks to improve their communication performance, especially for the wireless sensor network. Technically, when they execute their own given missions with predetermined trajectories, they can also provide opportunistic assistance for terrestrial networks at the same time. In this paper, we solve an opportunistic UAVs-assisted data transmission problem in a wireless sensor network from a novel perspective. In consideration of UAVs dynamic behaviors, varying transmission tasks and real-time matching between UAVs and sensor clusters, we propose to jointly optimize UAV scheduling and power control aiming to obtain optimal policies to maximize the network data transmission in a long run under the opportunistic access mode. We reformulate this optimization problem as a Markov decision process (MDP) and take deep reinforcement learning (DRL) as our tool to obtain solutions. We develop a DQN based and a deep deterministic policy gradient (DDPG) based optimization approaches to adjust the power allocation of cluster heads, and the scheduling and bandwidth allocation of UAVs during their missions over the covered area to improve the whole network data transmission performance. Simulation results demonstrate the validity and superiority of our proposed approaches compared with other benchmark policies in different perspectives.},
keywords={Trajectory;Data communication;Wireless sensor networks;Autonomous aerial vehicles;Internet of Things;Task analysis;Optimization;opportunistic UAV transmission;wireless sensor network;resource allocation;scheduling;deep reinforcement learning.},
doi={10.1109/JIOT.2022.3142269},
ISSN={2327-4662},
month={},}
@ARTICLE{9709537,
author={Oubbati, Omar Sami and Lakas, Abderrahmane and Guizani, Mohsen},
journal={IEEE Internet of Things Journal}, title={Multi-Agent Deep Reinforcement Learning for Wireless-Powered UAV Networks},
year={2022},
volume={},
number={},
pages={1-1},
abstract={Unmanned Aerial Vehicles (UAVs) have attracted much attention lately and are being used in a multitude of applications. But the duration of being in the sky remains to be an issue due to their energy limitation. In particular, this represents a major challenge when UAVs are used as base stations (BSs) to complement the wireless network. Therefore, as UAVs execute their missions in the sky, it becomes beneficial to wirelessly harvest energy from external and adjustable flying energy sources (FESs) to power their onboard batteries and avoid disrupting their trajectories. For this purpose, wireless power transfer (WPT) is seen as a promising charging technology to keep UAVs in flight and allow them to complete their missions. In this work, we leverage a multi-agent deep reinforcement learning (MADRL) method to optimize the task of energy transfer between FESs and UAVs. The optimization is performed by carrying out three essential tasks: (i) maximizing the sum-energy received by all UAVs based on FESs using WPT, (ii) optimizing the energy loading process of FESs from a ground BS, and (iii) computing the most energy-efficient trajectories of the FESs while carrying out their charging duties. Furthermore, to ensure highlevel reliability of energy transmission, we use directional energy transfer for charging both FESs and UAVs by using laser beams and energy beam-forming technologies, respectively. In this study, the simulation results show that the proposed MADRL method has efficiently optimized the trajectories and energy consumption of FESs, which translates into a significant energy transfer gain compared to the baseline strategies.},
keywords={Trajectory;Energy exchange;Internet of Things;Autonomous aerial vehicles;Iron;Wireless sensor networks;Wireless communication;UAV;Wireless Power Transfer (WPT);Energy Harvesting;Deep Reinforcement Learning; Energy Efficiency.},
doi={10.1109/JIOT.2022.3150616},
ISSN={2327-4662},
month={},}
@ARTICLE{9725258,
author={Zhao, Nan and Ye, Zhiyang and Pei, Yiyang and Liang, Ying-Chang and Niyato, Dusit},
journal={IEEE Transactions on Wireless Communications}, title={Multi-Agent Deep Reinforcement Learning for Task Offloading in UAV-assisted Mobile Edge Computing},
year={2022},
volume={},
number={},
pages={1-1},
abstract={Mobile edge computing can effectively reduce service latency and improve service quality by offloading computation-intensive tasks to the edges of wireless networks. Due to the characteristic of flexible deployment, wide coverage and reliable wireless communication, unmanned aerial vehicles (UAVs) have been employed as assisted edge clouds (ECs) for large-scale sparely-distributed user equipment. Considering the limited computation and energy capacities of UAVs, a collaborative mobile edge computing system with multiple UAVs and multiple ECs is investigated in this paper. The task offloading issue is addressed to minimize the sum of execution delays and energy consumptions by jointly designing the trajectories, computation task allocation, and communication resource management of UAVs. Moreover, to solve the above non-convex optimization problem, a Markov decision process is formulated for the multi-UAV assisted mobile edge computing system. To obtain the joint strategy of trajectory design, task allocation, and power management, a cooperative multi-agent deep reinforcement learning framework is investigated. Considering the high-dimensional continuous action space, the twin delayed deep deterministic policy gradient algorithm is exploited. The evaluation results demonstrate that our multi-UAV multi-EC task offloading method can achieve better performance compared with the other optimization approaches.},
keywords={Task analysis;Resource management;Trajectory;Wireless communication;Servers;Optimization;Manganese;Mobile edge computing;UAV networks;task offloading;cooperative offloading;deep reinforcement learning},
doi={10.1109/TWC.2022.3153316},
ISSN={1558-2248},
month={},}
@ARTICLE{9701330,
author={Nguyen, Khoi Khac and Duong, Trung Q. and Do-Duy, Tan and Claussen, Holger and Hanzo, Lajos},
journal={IEEE Transactions on Communications}, title={3D UAV Trajectory and Data Collection Optimisation via Deep Reinforcement Learning},
year={2022},
volume={},
number={},
pages={1-1},
abstract={Unmanned aerial vehicles (UAVs) are now beginning to be deployed for enhancing the network performance and coverage in wireless communication. However, due to the limitation of their on-board power and flight time, it is challenging to obtain an optimal resource allocation scheme for the UAV-assisted Internet of Things (IoT). In this paper, we design a new UAV-assisted IoT system relying on the shortest flight path of the UAVs while maximising the amount of data collected from IoT devices. Then, a deep reinforcement learning-based technique is conceived for finding the optimal trajectory and throughput in a specific coverage area. After training, the UAV has the ability to autonomously collect all the data from user nodes at a significant total sum-rate improvement while minimising the associated resources used. Numerical results are provided to highlight how our techniques strike a balance between the throughput attained, trajectory, and the time spent. More explicitly, we characterise the attainable performance in terms of the UAV trajectory, the expected reward and the total sum-rate.},
keywords={Trajectory;Wireless networks;Resource management;Optimization;Data collection;Throughput;Three-dimensional displays;UAV-assisted wireless network;trajectory;data collection;deep reinforcement learning},
doi={10.1109/TCOMM.2022.3148364},
ISSN={1558-0857},
month={},}
@ARTICLE{9540290,
author={Dai, Zipeng and Liu, Chi Harold and Han, Rui and Wang, Guoren and Leung, Kin and Tang, Jian},
journal={IEEE Transactions on Mobile Computing}, title={Delay-Sensitive Energy-Efficient UAV Crowdsensing by Deep Reinforcement Learning},
year={2021},
volume={},
number={},
pages={1-1},
abstract={Mobile crowdsensing (MCS) by unmanned aerial vehicles (UAVs) servicing delay-sensitive applications becomes popular by navigating a group of UAVs to take advantage of their equipped high-precision sensors and durability for data collection in harsh environments. In this paper, we aim to simultaneously maximize collected data amount, geographical fairness, and minimize the energy consumption of all UAVs, as well as to guarantee the data freshness by setting a deadline in each timeslot. Specifically, we propose a centralized control, distributed execution framework by decentralized deep reinforcement learning (DRL) for delay-sensitive and energy-efficient UAV crowdsensing, called "DRL-eFresh". It includes a synchronous computational architecture with GRU sequential modeling to generate multi-UAV navigation decisions. Also, we derive an optimal time allocation solution for data collection while considering all UAV efforts and avoiding much data dropout due to limited data upload time and wireless data rate. Simulation results show that DRL-eFresh significantly improves the energy efficiency, as compared to the best baseline DPPO, by 14% and 22% on average when varying different sensing ranges and number of PoIs, respectively.},
keywords={Sensors;Task analysis;Crowdsensing;Data collection;Navigation;Delays;Computational modeling;UAV crowdsensing;Delay-sensitive applications;Energy-efficiency;Deep reinforcement learning},
doi={10.1109/TMC.2021.3113052},
ISSN={1558-0660},
month={},}
@INPROCEEDINGS{9558907,
author={Taş, Mehmet Bilge Han and Irmak, Muhammed Coşkun and Turan, Sedat and Haşıloğlu, Abdulsamet},
booktitle={2021 6th International Conference on Computer Science and Engineering (UBMK)}, title={Real-Time Puddle Detection Using Convolutional Neural Networks with Unmanned Aerial Vehicles},
year={2021},
volume={},
number={},
pages={598-602},
abstract={The study was carried out in order to enable systems with weak processing power and motion to detect objects using cloud services. In addition, the dataset is expanded by continuous labeling to create big data. In the study, it is aimed to detect objects using cloud-based deep learning methods with an unmanned aerial vehicle (UAV). In the study, training processes were carried out with Google Colaboratory, a cloud service provider. The training processes are a YOLO-based system, and a convolutional neural network was created by revising the parameters in line with the needs. The convolutional neural network model provides communication between neurons in the convolutional layers by bringing the image data to the desired pixel ranges. Unlabeled pictures are included in the training by being tagged. In this way, it is possible to continuously enlarge the data pool. Since the microcomputers used in UAVs are insufficient for these processes, a cloud-based training model has been created. As a result of the study, cloud-based deep learning models work as desired. It is possible to show the accuracy of the model with the low losses seen in the loss functions and the mAP value. Graphic cards with high processing power are needed to provide training. It is essential to use powerful graphics cards when working on image data. Cost reduced by using cloud services. The training was accelerated and high-rate object detections were made. YOLOv5x was used in the study. It is preferred because of its fast training and high frame rate. Recall 80% Precision 93% mAP 82.6% values were taken.},
keywords={Training;Graphics;Deep learning;Neurons;Object detection;Microcomputers;Unmanned aerial vehicles;cloud based deep learning;unmanned aerial vehicle;real time object detection;puddle detection;YOLOv5;convolutional neural network},
doi={10.1109/UBMK52708.2021.9558907},
ISSN={2521-1641},
month={Sep.},}


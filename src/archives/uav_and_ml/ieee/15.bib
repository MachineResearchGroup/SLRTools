@ARTICLE{9590492,
author={Chadwick, Andrew J. and Coops, Nicholas C. and Bater, Christopher W. and Martens, Lee A. and White, Barry},
journal={IEEE Geoscience and Remote Sensing Letters}, title={Species Classification of Automatically Delineated Regenerating Conifer Crowns Using RGB and Near-Infrared UAV Imagery},
year={2022},
volume={19},
number={},
pages={1-5},
abstract={Unmanned aerial vehicles (UAVs) and deep learning are important tools at the forefront of automated forest monitoring research, where classification of individual tree species is a critical forest management goal. Near-infrared (NIR) information provided by specialized UAV sensors may improve classification accuracy at the cost of added operational complexity; however, this potential for improvement is context-dependent and, therefore, may not be necessary. We assessed the performance of conventional red-green-blue (RGB) versus NIR imagery when classifying regenerating lodgepole pine and white spruce crowns automatically delineated by a trained deep learning algorithm. Models trained on NIR imagery slightly outperformed those trained on RGB imagery. Models trained on spectral bands outperformed those trained on spectral indices. The minor difference in performance between the two sets of imagery showed that accurate classification of lodgepole pine and white spruce can be carried-out using conventional RGB imagery.},
keywords={Forestry;Sensors;Spatial resolution;Cameras;Vegetation mapping;Unmanned aerial vehicles;Deep learning;Forest regeneration;mask R-CNN;species classification;unmanned aerial vehicle (UAV)},
doi={10.1109/LGRS.2021.3123552},
ISSN={1558-0571},
month={},}
@INPROCEEDINGS{9619442,
author={Hossain, F M Anim and Zhang, Youmin},
booktitle={2021 3rd International Conference on Industrial Artificial Intelligence (IAI)}, title={Development of New Efficient Transposed Convolution Techniques for Flame Segmentation from UAV-captured Images},
year={2021},
volume={},
number={},
pages={1-6},
abstract={Although Fully Convolutional Networks (FCNs) have been proven to be a very powerful tool in deep learning-based image segmentation, they are still too computationally expensive to be incorporated into mobile platforms such as Unmanned Aerial Vehicles (UAVs) for real-time performance. While significant efforts have been made to make the encoder side of a FCN more efficient, the decoder side, which involves upsampling the feature maps, is still overlooked in comparison. This paper proposes two new efficient upsampling techniques, “Reversed Depthwise Separable Transposed Convolution (RDSTC)” and “Compression-Expansion Transposed Convolution (CETC)”. U-Net architecture and UAV-captured forest pile fire images have been used to evaluate the performance of these new efficient upsampling techniques. RDSTC and CETC achieve Dice scores of 0.8815 and 0.8832 respectively, outperforming commonly used bilinear interpolation and original transposed convolution, while significantly reducing the number of upsampling computations. The results of this paper demonstrate that upsampling operation in a deep learning architecture can be made more efficient without degradation in performance.},
keywords={Degradation;Image segmentation;Interpolation;Image coding;Convolution;Fires;Computer architecture;efficient transposed convolution;deep learning;unmanned aerial vehicles;forest fire detection;flame segmentation},
doi={10.1109/IAI53119.2021.9619442},
ISSN={},
month={Nov},}
@INPROCEEDINGS{9477914,
author={Ünlü, Aybüke and Yüksel, Tolga},
booktitle={2021 29th Signal Processing and Communications Applications Conference (SIU)}, title={Dört Kanatlı İnsansız Hava Araçları İçin Yapay Sinir Ağları İle Konum Tabanlı Görsel Servolama Position Based Visual Servoing with Artificial Neural Networks for Quadrotor-type Unmanned Aerial Vehicles},
year={2021},
volume={},
number={},
pages={1-4},
abstract={UAVs offer many advantages over manned vehicles and their application area expands in time passes. Particularly, interest in UAVs with rotary wing types is increasing. Increasing interest in these vehicles has spawned many different controller designs. In this study, estimating the pose of the vehicle according to the image features with the help of a single camera mounted on the quadrotor and then positionbased visual servoing, a technique that allows the vehicle to be controlled by using the image features, was used. In this study position-based visual servoing (PBVS); 3D parameter estimates of the vehicle pose were implemented with artificial neural networks.},
keywords={Bit error rate;Search engines;Internet;Deep learning;Tuning;Task analysis;Standards},
doi={10.1109/SIU53274.2021.9477914},
ISSN={2165-0608},
month={June},}
@INPROCEEDINGS{9695659,
author={Chen, Xing and Zou, Mi and Yan, Yan-Bing and Wen, Bo},
booktitle={2021 3rd International Academic Exchange Conference on Science and Technology Innovation (IAECST)}, title={UAV remote sensing image Rural homestead detection based on deep learning},
year={2021},
volume={},
number={},
pages={592-595},
abstract={With the implementation of the rural revitalization strategy, the revitalization of rural homestead utilization is extremely important, master the regional location, quantity, size and distribution of rural homestead is a necessary prerequisite for the revitalization of rural homestead utilization. To detect rural homestead in UAV remote sensing image, it is necessary to seek a method that can automatically learn image features from a large number of samples and obtain the most effective feature information in the image, Deep learning is an algorithm that can automatically learn effective features from a large amount of data. In this paper, the SSD_MobileNet deep learning model is trained using massive UAV remote sensing data to realize intelligent detection of rural homestead. The experimental results show that the accuracy of the model is more than 90%, which can meet the needs of rural homestead detection in practical work.},
keywords={Deep learning;Technological innovation;Feature extraction;Data models;Remote sensing;deep learning;rural homestead;SSD_MobileNet;detection Introduction},
doi={10.1109/IAECST54258.2021.9695659},
ISSN={},
month={Dec},}
@INPROCEEDINGS{8898661,
author={Li, Youyou and Melgani, Farid and He, Binbin},
booktitle={IGARSS 2019 - 2019 IEEE International Geoscience and Remote Sensing Symposium}, title={Fully Convolutional SVM for Car Detection In Uav Imagery},
year={2019},
volume={},
number={},
pages={2451-2454},
abstract={Semantic segmentation is understanding images at pixel level, which becomes increasingly vital in unmanned aerial vehicles (UAV) imagery classification tasks. With the powerful calculating ability of GPU, a growing number of deep convolutional neural networks (DCNNs) are designed to address semantic segmentation challenges. However, compared with CPU, GPU is much more costly, and GPU relies on powerful supplementary equipments to support it. Therefore, GPU-based methods are hard to carry out in practical applications. In this study, we propose a CPU-based method named fully convolutional support vector machine (FCSVM) to address the semantic segmentation challenge in UAV images. On the one hand, we adopt the SVM kernel from the original convolutional SVM networks (CSVM), which completes classification at image level. On the other hand, FCSVM consists of two processes which are a compressed process and a extensive process. In the compressed process, the FCSVM has convolutional layers and reduction layers. In the extensive process, the FCSVM has convolutional layers and upsampling layers. This structure allows FCSVM to classify images at pixel level using limited number of training data. The experiments are implemented on one UAV dataset with very little training data. The result shows our FCSVM achieves competitive performance compared to modern state-of-the-art semantic segmentation methods.},
keywords={Image segmentation;Semantics;Support vector machines;Convolution;Unmanned aerial vehicles;Image coding;Remote sensing;Semantic Segmentation;Fully Convolutional Support Vector Machine (CSVM);Unmanned Aerial Vehicles (UAV)},
doi={10.1109/IGARSS.2019.8898661},
ISSN={2153-7003},
month={July},}
@INPROCEEDINGS{8909879,
author={Zhang, Huaizhong and Liptrott, Mark and Bessis, Nik and Cheng, Jianquan},
booktitle={2019 16th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS)}, title={Real-Time Traffic Analysis using Deep Learning Techniques and UAV based Video},
year={2019},
volume={},
number={},
pages={1-5},
abstract={In urban environments there are daily issues of traffic congestion which city authorities need to address. Realtime analysis of traffic flow information is crucial for efficiently managing urban traffic. This paper aims to conduct traffic analysis using UAV-based videos and deep learning techniques. The road traffic video is collected by using a position-fixed UAV. The most recent deep learning methods are applied to identify the moving objects in videos. The relevant mobility metrics are calculated to conduct traffic analysis and measure the consequences of traffic congestion. The proposed approach is validated with the manual analysis results and the visualization results. The traffic analysis process is real-time in terms of the pre-trained model used.},
keywords={Motorcycles;Traffic congestion;Roads;Measurement;Streaming media;Urban areas;Manuals},
doi={10.1109/AVSS.2019.8909879},
ISSN={2643-6213},
month={Sep.},}
@INPROCEEDINGS{9043101,
author={Ehara, Kakeru and Aljehani, Maher and Yokemura, Taketoshi and Inoue, Masahiro},
booktitle={2020 IEEE International Conference on Consumer Electronics (ICCE)}, title={Individual Status Recognition System Assisted by UAV in Post-Disaster},
year={2020},
volume={},
number={},
pages={1-3},
abstract={When natural disasters occur, there is a possibility of having many injured people in the disaster area. In the meanwhile, rescue teams have to aid these injured individuals as fast as possible. In this study, we proposed a recognition system of individual status to help rescue teams. Employing Unmanned Aerial Vehicles (UAVs) system after disaster occurrence gives many advantages. For instance, a UAV can cover a wide area and provide aerial photographs in a short period. This study aims to classify whether an individual status is standing, sitting, or lying on the ground by using supervised machine learning. Experiments revealed that the system is able to recognize all three types of individual status with an accuracy of 95.6%. Moreover, the authors confirmed the usefulness of using a UAV to recognize individuals in the post-disaster scenario.},
keywords={Deep learning;Image recognition;Conferences;Autonomous aerial vehicles;Feature extraction;Data models;Consumer electronics;Unmanned Aerial Vehicles;status recognition;disaster response;rescue missions;deep learning;image processing},
doi={10.1109/ICCE46568.2020.9043101},
ISSN={2158-4001},
month={Jan},}
@ARTICLE{9729110,
author={Ruby, Rukhsana and Yang, Hailiang and de Figueiredo, Felipe A. P. and Huynh-The, Thien and Wu, Kaishun},
journal={IEEE Internet of Things Journal}, title={Energy-Efficient Multi-Processor-based Computation and Communication Resource Allocation in Two-Tier Federated Learning Networks},
year={2022},
volume={},
number={},
pages={1-1},
abstract={In conventional federated learning (FL), multiple edge devices holding local data jointly train a machine learning model by communicating learning updates with a centralized aggregator without exchanging their data samples. Owing to the communication and computation bottleneck at the centralized aggregator and inaccurate learning model caused by the non-IID data, we here consider a two-tier FL network, in which IoT nodes are the core clients that hold data, the model aggregators at the middle tier are the low altitude aerial platforms (UAVs), and the model aggregator at the top-most layer is the high altitude aerial platform (UAV with relatively high altitude). Under the assumption that each IoT node has parallel computing ability, we study the energy-efficient computation and communication resource allocation in such a network within some time budget. Upon formulating the problem as an optimization problem, we solve the computation and communication resource allocation problems as the separate subproblems within a time frame, and then propose an iterative algorithm to solve the entire problem jointly. More specifically, We solve both the energyefficient computation and communication resource allocation subproblems using the dual decomposition technique, and then apply a bisection search-based recursive technique to solve the entire energy efficiency problem jointly. Moreover, we propose offline and online client scheduling schemes that not only select the optimal edge nodes for association but also assign workload to each client based on the data quality and workload constraint. With real data, extensive simulations are conducted to verify the effectiveness of the proposed resource allocation scheme. The results further reveal that the learning performance not only is dependent on the computation and communication energy consumption of the FL process but also the model divergence weight owing to the non-IID data at client IoT nodes.},
keywords={Resource management;Computational modeling;Edge computing;Data models;Training;Energy consumption;Convergence;Federated Learning (FL);Energy-Efficient Resource Allocation;Dual Decomposition Technique;Computation and Communication Resource Allocation.},
doi={10.1109/JIOT.2022.3153996},
ISSN={2327-4662},
month={},}
@ARTICLE{9716929,
author={Zhang, Min and Dong, Chao and Yang, Peng and Tao, Ting and Wu, Qihui and Quek, Tony Q. S.},
journal={IEEE Communications Letters}, title={Adaptive Routing Design for Flying Ad Hoc Networks},
year={2022},
volume={},
number={},
pages={1-1},
abstract={Adaptive routing and efficient packet delivery in Flying Ad Hoc Networks (FANETs) are significant challenges due to underlying environment constraints, such as dynamic nature, mobility, and limited connectivity. With the increasing number of machine learning (ML) applications in wireless networks, FANETs can benefit from these data-driven predictions. This letter proposes a Packet Arrival Prediction (PAP) routing protocol to improve transmission link reliability. Primarily, we apply a Long Short-Term Memory (LSTM) model to predict the packet arrival of each UAV, seeking to avoid the high-traffic UAVs, which cause packet loss significantly. Then, we formulate the routing decision issue as an optimization problem, which attempts to find an appropriate path by a proposed constrained sorting approach, in order to make joint yet fast routing decisions. The simulation results demonstrate that the PAP routing protocol outperforms the existing manifold protocols in the aspects of Packet Delivery Ratio (PDR) and delay.},
keywords={Routing;Routing protocols;Computer architecture;Reliability;Packet loss;Ad hoc networks;Autonomous aerial vehicles;Routing;Unmanned Aerial Vehicles (UAVs);Flying Ad Hoc Networks (FANETs);Packet arrival prediction;Long Short-Term Memory (LSTM)},
doi={10.1109/LCOMM.2022.3152832},
ISSN={1558-2558},
month={},}
@INPROCEEDINGS{8639306,
author={Sarwar, Farah and Griffin, Anthony and Periasamy, Priyadharsini and Portas, Kurt and Law, Jim},
booktitle={2018 15th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS)}, title={Detecting and Counting Sheep with a Convolutional Neural Network},
year={2018},
volume={},
number={},
pages={1-6},
abstract={Counting livestock is generally done only during major events, such as drenching, shearing or loading, and thus farmers get stock numbers sporadically throughout the year. More accurate and timely stock information would enable farmers to manage their herds better. Additionally, prompt response to any stock in distress is extremely valuable, both in terms of animal welfare and the avoidance of financial loss. In this regard, the evolution of deep learning algorithms and Unmanned Aerial Vehicles (UAVs) is forging a new research area for remote monitoring and counting of different animal species under various climatic conditions. In this paper, we focus on detecting and counting sheep in a paddock from UAV video. Sheep are counted using a model based on Region-based Convolutional Neural Networks and the results are then compared with other techniques to evaluate their performance.},
keywords={Animals;Training;Training data;Unmanned aerial vehicles;Task analysis;Testing;Agriculture},
doi={10.1109/AVSS.2018.8639306},
ISSN={},
month={Nov},}
@INPROCEEDINGS{9376551,
author={Surmann, Hartmut and Kaiser, Tiffany and Leinweber, Artur and Senkowski, Gerhard and Slomma, Dominik and Thurow, Marc},
booktitle={2021 7th International Conference on Automation, Robotics and Applications (ICARA)}, title={Small Commercial UAVs for Indoor Search and Rescue Missions},
year={2021},
volume={},
number={},
pages={106-113},
abstract={This technical report is about the architecture and integration of very small commercial UAVs (<; 40 cm diagonal) in indoor Search and Rescue missions. One UAV is manually controlled by only one single human operator delivering live video streams and image series for later 3D scene modelling and inspection. In order to assist the operator who has to simultaneously observe the environment and navigate through it we use multiple deep neural networks to provide guided autonomy, automatic object detection and classification and local 3D scene modelling. Our methods help to reduce the cognitive load of the operator. We describe a framework for quick integration of new methods from the field of Deep Learning, enabling for rapid evaluation in real scenarios, including the interaction of methods.},
keywords={Solid modeling;Three-dimensional displays;Two dimensional displays;Streaming media;Inspection;Writing;Load modeling;Search and Rescue Robots;Unmanned Aerial Vehicles;Artificial Intelligence;Deep Learning;Autonomous Robots},
doi={10.1109/ICARA51699.2021.9376551},
ISSN={},
month={Feb},}
@INPROCEEDINGS{9389305,
author={Langenkämper, Daniel and Möller, Torben and Brün, Daniel and Wilhelm Nattkemper, Tim},
booktitle={Global Oceans 2020: Singapore – U.S. Gulf Coast}, title={Efficient visual monitoring of offshore windmill installations with online image annotation and deep learning computer vision},
year={2020},
volume={},
number={},
pages={1-6},
abstract={The number of offshore windmills keeps growing around the world since they are an essential part of any strategy to produce energy without using nuclear power plants or burning fossil resources. Due to the growing number of installations new monitoring and inspection strategies and routines need to be developed that are not only effective but efficient. In this work we will present first results from a joint project of industry partners and academia that aims at the development of new approaches making use of modern imaging technologies and new methods from artificial intelligence and computer vision research. We investigate three different strategies for collecting digital photos or video and posterior computational analysis using Convolutional Neural Networks (CNN). Our results indicate, that patterns of interest like rust or coating damage can be detected and classified with F1 scores between 0.80 and 0.94 in photos collected by inspectors. In videos collected with unmanned aerial vehicles (UAV) rust patterns, oils spills and coating damage were detected with F1= 0.91. To support users in the time-consuming task of visual data exploration, we present a new visualization method referred to as “virtual twin”. Using hand - recorded image collections, a data-driven 3D model of a windmill is generated, that can be used to investigate damage patterns in the full context of the windmill and in full detail. Altogether our results indicate, that although each single approach has its limitations, a combination of different imaging methods, deep learning computer vision algorithms and sophisticated visual data exploration by experienced users appears to have potential to overcome the bottleneck in data analysis, interpretation and decision making in the context of the future inspections of offshore windmills, platforms or other constructions.},
keywords={Visualization;Computer vision;Data visualization;Training data;Inspection;Unmanned aerial vehicles;Monitoring;Inspection;Offshore windmill;Offshore wind turbine;Unmanned Aerial Vehicles;Computer vision;Deep Learning;Artificial Intelligence},
doi={10.1109/IEEECONF38699.2020.9389305},
ISSN={0197-7385},
month={Oct},}
@INPROCEEDINGS{9182686,
author={Junfei, Chen and Kunyi, Lu and Jiaxin, Wang},
booktitle={2020 IEEE International Conference on Artificial Intelligence and Computer Applications (ICAICA)}, title={Research on UAV Image Recognition Based on Convolutional Neural Network},
year={2020},
volume={},
number={},
pages={819-823},
abstract={As an important visual function of drones, image recognition has helped drones accomplish a variety of tasks in complex environments. At present, most of drone image detection uses the traditional method of artificial feature extraction. It is difficult to meet the increasing accuracy requirements. Based on this, this paper applies convolutional neural networks to UAV image recognition to meet high-precision requirements. This article first introduced the development process of convolutional neural networks to facilitate their overall integration. And then summarized the “visual function” of the drone, then analyzed the future development trend of the drone image recognition technology, expounded the key technology of the drone image recognition, and finally explained the image recognition technology based on convolutional neural network, discussed its recognition process and recognition method, and it has a certain significance for deepening the research of UAV image recognition.},
keywords={Drones;Feature extraction;Image recognition;Sensors;Target recognition;Convolutional neural networks;Task analysis;convolutional neural network;drone;image recognition;SSD algorithm},
doi={10.1109/ICAICA50127.2020.9182686},
ISSN={},
month={June},}
@INPROCEEDINGS{8783410,
author={Sherstjuk, Vladimir and Zharikova, Maryna},
booktitle={2019 IEEE 39th International Conference on Electronics and Nanotechnology (ELNANO)}, title={Evaluation of Fire Intensity Based on Neural Networks in a Forest-Fire Monitoring System},
year={2019},
volume={},
number={},
pages={802-807},
abstract={This work presents a method of fire intensity evaluation based on uncertain observations obtained by a forest fire monitoring system using jointly UAVs, remote sensing, and image processing. The proposed method uses two backpropagation neural networks to smoke and flame recognition. Flame color features, as well as dynamic shape/edge changing features, are trained using neural networks. Smoke and precipitation considered as the noise, various factors such as weather, light, features of sensors used in UAV were taken into account. The developed method provides sufficient performance to fulfill the requirements of credibility and efficiency.},
keywords={Monitoring;Fires;Forestry;Cameras;Sensors;Remote sensing;Image processing;unmanned air vehicle;fire monitoring;fire intensity;remote sensing;image processing;flame;smoke},
doi={10.1109/ELNANO.2019.8783410},
ISSN={},
month={April},}
@ARTICLE{9437345,
author={Feng, Luwei and Zhang, Zhou and Ma, Yuchi and Sun, Yazhou and Du, Qingyun and Williams, Parker and Drewry, Jessica and Luck, Brian},
journal={IEEE Geoscience and Remote Sensing Letters}, title={Multitask Learning of Alfalfa Nutritive Value From UAV-Based Hyperspectral Images},
year={2022},
volume={19},
number={},
pages={1-5},
abstract={Alfalfa is a valuable and widely adapted forage crop, and its nutritive value directly affects animal performance and ultimately affects the profitability of livestock production. Traditional nutritive value measurement method is labor-intensive and time-consuming and thus hinders the determination of alfalfa nutritive values over large fields. The adoption of unmanned aerial vehicles (UAVs) facilitates the generation of images with high spatial and temporal resolutions for field-level agricultural research. Additionally, compared with other imaging modalities, hyperspectral data usually consist of hundreds of narrow spectral bands and allow the accurate detection, identification, and quantification of crop quality. Although various machine-learning methods have been developed for alfalfa quality prediction, they were all single-task models that learned independently for each quality trait and failed to utilize the underlying relatedness between each task. Inspired by the idea of multitask learning (MTL), this study aims to develop an approach that simultaneously predicts multiple quality traits. The algorithm first extracts shared information through a long short-term memory (LSTM)-based common hidden layer. To enhance the model flexibility, it is then divided into multiple branches, each containing the same or different number of task-specific fully connected hidden layers. Through comparison with multiple mainstream single-task machine-learning models, the effectiveness of the model is illustrated based on the measured alfalfa quality data and multitemporal UAV-based hyperspectral imagery.},
keywords={Task analysis;Hyperspectral imaging;Mathematical model;Agriculture;Predictive models;Computer architecture;Logic gates;Alfalfa;hyperspectral imagery;multitask learning;nutritive value;unmanned aerial vehicle (UAV)},
doi={10.1109/LGRS.2021.3079317},
ISSN={1558-0571},
month={},}
@INPROCEEDINGS{7733537,
author={Manukyan, Anush and Olivares-Mendez, Miguel A. and Bissyandé, Tegawendé F. and Voos, Holger and Le Traon, Yves},
booktitle={2016 IEEE 21st International Conference on Emerging Technologies and Factory Automation (ETFA)}, title={UAV degradation identification for pilot notification using machine learning techniques},
year={2016},
volume={},
number={},
pages={1-8},
abstract={Unmanned Aerial Vehicles are currently investigated as an important sub-domain of robotics, a fast growing and truly multidisciplinary research field. UAVs are increasingly deployed in real-world settings for missions in dangerous environments or in environments which are challenging to access. Combined with autonomous flying capabilities, many new possibilities, but also challenges, open up. To overcome the challenge of early identification of degradation, machine learning based on flight features is a promising direction. Existing approaches build classifiers that consider their features to be correlated. This prevents a fine-grained detection of degradation for the different hardware components. This work presents an approach where the data is considered uncorrelated and, using machine learning techniques, allows the precise identification of UAV's damages.},
keywords={Time series analysis;Degradation;Sensors;Machine learning algorithms;Robots;Heuristic algorithms;Unmanned aerial vehicles},
doi={10.1109/ETFA.2016.7733537},
ISSN={},
month={Sep.},}
@INPROCEEDINGS{9584666,
author={Baktiyar, Akzhol and Baizhan, Darkhan and Bagheri, Mehdi and Zollanvari, Amin and Murzabulatov, Alimzhan and Serikbay, Arailym},
booktitle={2021 IEEE International Conference on Environment and Electrical Engineering and 2021 IEEE Industrial and Commercial Power Systems Europe (EEEIC / I CPS Europe)}, title={Remote Monitoring of Outdoor High Voltage Insulator using Deep Learning-based Image Processing},
year={2021},
volume={},
number={},
pages={1-6},
abstract={The outdoor high voltage insulators are some of the essential parts for electrical and mechanical assistance of transmission lines. Monitoring the insulators’ health frequently on a regular basis is an indispensable routine for ensuring uninterrupted power transmission. Traditionally, the monitoring is accomplished manually by linemen, which is time-consuming and implies additional logistics costs due to the long distances and various terrains associated with transmission lines. One of the most economic solutions can be condition monitoring by analysis of insulators’ images using Unmanned Aerial Vehicles (UAVs). In this regard, this study focuses on outdoor high-voltage insulators’ health monitoring by deep learning-based classification of hazardous surface conditions. To this end, Convolutional Neural Networks (CNNs) with hyperparameter optimization as well as fine-tuning pretrained deep learning models are employed to classify insulator surface conditions into one of the following four categories: clean, or covered either with snow, ice, or dust. Applying cross-validation external to the CNN hyperparameter optimization and the fine-tuning process of pretrained models yielded remarkable accuracies of 92.07% and 97.80%, respectively.},
keywords={Surface cleaning;Deep learning;Power transmission lines;Costs;Biological system modeling;Image processing;High-voltage techniques;High-voltage insulator;insulator surface condition;deep learning;transfer learning;convolutional neural networks},
doi={10.1109/EEEIC/ICPSEurope51590.2021.9584666},
ISSN={},
month={Sep.},}
@ARTICLE{8897093,
author={St-Onge, David and Kaufmann, Marcel and Panerati, Jacopo and Ramtoula, Benjamin and Cao, Yanjun and Coffey, Emily B.J. and Beltrame, Giovanni},
journal={IEEE Robotics Automation Magazine}, title={Planetary Exploration With Robot Teams: Implementing Higher Autonomy With Swarm Intelligence},
year={2020},
volume={27},
number={2},
pages={159-168},
abstract={Since the beginning of space exploration, Mars and the moon have been examined via orbiters, landers, and rovers. More than 40 missions have targeted Mars, and over 100 have been sent to the moon. Space agencies continue to focus on developing novel strategies and technologies for probing celestial bodies. Multirobot systems are particularly promising for planetary exploration, as they are more robust to individual failure and have the potential to examine larger areas; however, there are limits to how many robots an operator can control individually. We recently took part in the European Space Agency's (ESA's) interdisciplinary equipment test campaign (PANGAEA-X) at a lunar/Mars analog site in Lanzarote, Spain. We used a heterogeneous fleet of unmanned aerial vehicles (UAVs)-a swarm-to study the interplay of systems operations and human factors. Human operators directed the swarm via ad hoc networks and data-sharing protocols to explore unknown areas under two control modes: in one, the operator instructed each robot separately; in the other, the operator provided general guidance to the swarm, which self-organized via a combination of distributed decision making and consensus building. We assessed cognitive load via pupillometry for each condition and perceived task demand and intuitiveness via selfreport. Our results show that implementing higher autonomy with swarm intelligence can reduce workload, freeing the operator for other tasks such as overseeing strategy and communication. Future work will further leverage advances in swarm intelligence for exploration missions.},
keywords={Robot kinematics;Task analysis;Robot sensing systems;Safety;Global Positioning System;Moon;Mobile robots},
doi={10.1109/MRA.2019.2940413},
ISSN={1558-223X},
month={June},}
@INPROCEEDINGS{8085049,
author={Cisek, Daniel and Mahajan, M. and Dale, Jedidiah and Pepper, Susan and Lin, Yuewei and Yoo, Shinjae},
booktitle={2017 New York Scientific Data Summit (NYSDS)}, title={A transfer learning approach to parking lot classification in aerial imagery},
year={2017},
volume={},
number={},
pages={1-5},
abstract={The importance of satellite imagery analysis has increased dramatically over the last several years, keeping pace with the rapid improvements seen in both remote sensing platforms and sensors. As this field expands, so too does the interest in using machine learning methods to automate parts of the imagery analyst's workflow. In this paper we address one aspect of this challenge: the development of a method for the automatic extraction of parking lots from aerial imagery. To the best of our knowledge, there has been no prior work conducted on the development of an end-to-end pipeline for this particular task. Due to the limited size of our dataset and to accommodate the potentially limited size of future datasets, we propose a deep learning approach using transfer learning. This process hinges upon the use of state of the art Convolutional Neural Networks (CNNs), trained on general image classification datasets. These networks were then fine-tuned on our custom dataset, to establish a comprehensive benchmark for this task. Our method exhibits promising results for automatic parking lot extraction, and is generalizable enough to work with different input types, including high resolution aerial orthoimagery, satellite imagery, full motion video (FMV), and UAV imagery.},
keywords={Training;Neural networks;Machine learning;Satellites;Object recognition;Visualization;Deep Learning;Neural Network;Geospatial;Automation;Satellite Imagery},
doi={10.1109/NYSDS.2017.8085049},
ISSN={},
month={Aug},}
@INPROCEEDINGS{8936091,
author={Bah, M. Dian and Hafiane, Adel and Canals, Raphael and Emile, Bruno},
booktitle={2019 Ninth International Conference on Image Processing Theory, Tools and Applications (IPTA)}, title={Deep features and One-class classification with unsupervised data for weed detection in UAV images},
year={2019},
volume={},
number={},
pages={1-5},
abstract={With the raise of the world population, increasing agricultural productivity has become a necessity for farmers. One way to reduce the cost of chemicals and environmental impact is to allocate the right doses of herbicide to the right place and at the right time (precision agriculture). Nowadays, automatic weeds detection is one of the most challenging problem for precision agriculture. However, weeds and crop are hard to discriminate because of their strong similarities. One of the approaches used for weed detection is machine learning. The main common point between machine learning algorithms is the need of training data. In this article we propose to use deep features and one-class classification on unsupervised data for weed detection in UAV images. The results show that one-class classification can be comparable to the literature and also to a deep learning model trained with supervised training data labeling. Results obtained on all test datasets can be up to 90% depending on the data used for the training.},
keywords={Agriculture;Feature extraction;Image segmentation;Training;Support vector machines;Training data;Deep learning;Weeds detection;One-class SVM;Deep features;Unmanned aerial vehicle;Image processing;Precision agriculture},
doi={10.1109/IPTA.2019.8936091},
ISSN={2154-512X},
month={Nov},}
@INPROCEEDINGS{8997447,
author={Xu, Guangyan and Zhao, Yang and Liu, Hao},
booktitle={2019 Chinese Automation Congress (CAC)}, title={Pursuit and evasion game between UVAs based on multi-agent reinforcement learning},
year={2019},
volume={},
number={},
pages={1261-1266},
abstract={Pursuit and evasion game between UVAs is a typical differential game. Differential games are usually difficult to obtain the optimal solutions because of the complex bilateral extremum problems. Reinforcement learning has superiorities in solving differential games with the advantages such as it does not need accurate controlled models and a lot of training data. In this paper, a multi-agent reinforcement learning model is established for UAV pursuit and evasion game. The relative motion state equation is used to describe the state to simplify the state set, and the pursuit and evasion game is transformed into a zero-sum game which is solved by Minimax-Q learning. The reinforcement learning model established in this paper reduces the complexity of solving problem and guarantees the convergence speed. Finally, the simulation results verify the rationality of the obtained control policy which makes both the pursuer and the evader tend to be advantageous to their own direction in the course of the countermeasures.},
keywords={Games;Learning (artificial intelligence);Mathematical model;Game theory;Convergence;Optimal control;Atmospheric modeling;pursuit and evasion game;differential game;multi-agent reinforcement learning;Minimax-Q learning},
doi={10.1109/CAC48633.2019.8997447},
ISSN={2688-0938},
month={Nov},}
@ARTICLE{9205392,
author={Pawełczyk, Maciej Ł. and Wojtyra, Marek},
journal={IEEE Access}, title={Real World Object Detection Dataset for Quadcopter Unmanned Aerial Vehicle Detection},
year={2020},
volume={8},
number={},
pages={174394-174409},
abstract={Recent years have shown a noticeable rise in the number of incidents with drones, related to both civilian and military installations. While drone neutralization techniques have become increasingly effective, detection most often relies on professional equipment, which is too expensive to be used for all critical nodes and applications. Therefore, there is a need for drone detection systems that could work on low performance hardware. Its critical component consists of an object detection system. In this article, we introduce a new object detection dataset, built entirely to train computer vision based object detection machine learning algorithms for a task of binary object detection to enable automated, industrial camera based detection of multiple drone objects using camera feed. The dataset expands existing multiclass image classification and object detection datasets (ImageNet, MS-COCO, PASCAL VOC, anti-UAV) with a diversified dataset of drone images. In order to maximize the effectiveness of the model, real world footage was utilized, transformed into images and hand-labelled to create a custom set of 56821 images and 55539 bounding boxes. Additionally, semi-automated labelling was proposed, tested and proved to be very useful for object detection applications. The dataset was divided into train and test subsets for further processing and used to generate 603 easily deployable Haar Cascades as well as 819 high performing Deep Neural Networks based models. They were used to test different object detection methods to determine the long term feasibility of a large scale drone detection system utilizing machine learning algorithms. The study has shown that Haar Cascade can be used as the Minimum Viable Product model for mediocre performance but fails to scale up effectively for a larger dataset compared to the Deep Neural Network model.},
keywords={Drones;Object detection;Task analysis;Computational modeling;Machine learning;Machine learning algorithms;Aerospace engineering;aerospace safety;artificial intelligence;computer vision;databases;image processing;unmanned aerial vehicles},
doi={10.1109/ACCESS.2020.3026192},
ISSN={2169-3536},
month={},}
@INPROCEEDINGS{9253816,
author={Opitz, Felix and Mohrdieck, Camilla and Dästner, Kaeye and Corcuera, Juan Jose Navarro and Schmid, Elke and Roseneckh-Köhler, Bastian von Hassler zu},
booktitle={2020 21st International Radar Symposium (IRS)}, title={Data Analytics, Machine Learning and Risk Assessment for Surveillance and Situation Awareness},
year={2020},
volume={},
number={},
pages={173-178},
abstract={Modern surveillance networks are able to provide trajectories of all kinds for aircrafts and vessels worldwide or at least in extended areas of the airspace or earth surface. Best known are Automatic Dependent Surveillance - Broadcast (ADS-B) and (Satellite-) Automatic Identification System (AIS) used in air and maritime surveillance. Both of them are cooperative systems. Besides these sources, sensors based on ground installations or mounted on airborne and space-based platforms deliver object trajectories independently of any transponders. This is done by advanced tracking and fusion algorithms generating trajectories out of sensor measurements. Examples include GMTI radar-based systems operating on UAV platforms or imaging systems based on high altitude pseudo satellites (HAPS) and satellites. These surveillance systems enable a continuous extraction of mid- and long-term trajectories of objects. Besides the trajectory generation, the challenge will be to place them into the right context and to provide situational awareness. This includes the estimation of the intents of the tracked objects, activity-based intelligence, and the determination of patterns of life. Otherwise, even modern surveillance systems are not able to take a real advantage of the gathered data. Therefore, trajectories are further processed by data analytics and machine learning. Unsupervised machine learning offers techniques to cluster and to partition trajectories, extract highly frequented routes and points of interest, predict object movement and identify anomalous behaviour. On the other hand, transponder and broadcast systems provide additional attributes of the tracked trajectories. These labels pave the way for numerous supervised machine learning methods. The derived predictors realise the determination of object types and activities. Finally, these new data analytic techniques have to be integrated in existing near real time surveillance systems. This requires specific system architectures as well as a completely new software and hardware landscape. In summary, trajectory-based data analytics, machine learning and risk assessment are embedded on local or global clouds and use dedicated mechanisms for distributed and parallel processing.},
keywords={Data analysis;Surveillance;Machine learning;Radar tracking;Trajectory;Sensors;Transponders;Radar;ADS-B;AIS;Data Analytics;Machine Learning;Activity based Intelligence;Data Fusion},
doi={10.23919/IRS48640.2020.9253816},
ISSN={2155-5753},
month={Oct},}
@INPROCEEDINGS{9391509,
author={Xu, Chengtao and Zhang, Kai and Song, Houbing},
booktitle={2020 IEEE 39th International Performance Computing and Communications Conference (IPCCC)}, title={UAV Swarm Communication Aware Formation Control via Deep Q Network},
year={2020},
volume={},
number={},
pages={1-2},
abstract={We propose a DQN based reinforcement learning method in swarm communication constraint based formation control with target searching function. A decentralized communication performance indicator is applied in evaluating the UAV's formation control in simulating a more realistic wireless communication environment between each UAV. A target searching model based on communication aware formation control is presented. The simulation results show that the trained model with state observation space and one thrust action space could be applied in the larger swarm system's group formation and target point tracking.},
keywords={Wireless communication;Training;Target tracking;Software packages;Simulation;Aerospace electronics;Mathematical model;Communication Aware Formation Control;Deep Q Network;Target tracking;Rescuing},
doi={10.1109/IPCCC50635.2020.9391509},
ISSN={2374-9628},
month={Nov},}
@INPROCEEDINGS{9605017,
author={Shahbazi, Arzhang and Di Renzo, Marco},
booktitle={2021 IEEE 4th 5G World Forum (5GWF)}, title={Learning-based Localization of Mobile Users for Throughput Maximization in UAV Networks},
year={2021},
volume={},
number={},
pages={130-134},
abstract={In this paper, we design a new UAV-assisted communication system relying on the shortest flight path of the UAV while maximizing the amount of data transmitted to mobile devices. In the considered system, we assume that UAV does not have the knowledge of user’s location except their initial position. We propose a framework which is based on the likelihood of mobile users presence in a grid with respect to their probability distribution. Then, a deep reinforcement learning technique is developed for finding the trajectory to maximize the throughput in a specific coverage area. Numerical results are presented to highlight how our technique strike a balance between the throughput achieved, trajectory, and the complexity.},
keywords={Location awareness;Communication systems;5G mobile communication;Reinforcement learning;Throughput;Probability distribution;Mobile handsets;Mobility;throughput;reinforcement learning;unmanned aerial vehicles},
doi={10.1109/5GWF52925.2021.00030},
ISSN={},
month={Oct},}
@INPROCEEDINGS{9024644,
author={Krijestorac, Enes and Hanna, Samer and Cabric, Danijela},
booktitle={2019 IEEE Globecom Workshops (GC Wkshps)}, title={UAV Access Point Placement for Connectivity to a User with Unknown Location Using Deep RL},
year={2019},
volume={},
number={},
pages={1-6},
abstract={In recent years, unmanned aerial vehicles (UAVs) have been considered for telecommunications purposes as relays, caches, or IoT data collectors. In addition to being easy to deploy, their maneuverability allows them to adjust their location to optimize the capacity of the link to the user equipment on the ground or of the link to the basestation. The majority of the previous work that analyzes the optimal placement of such a UAV makes at least one of two assumptions: the channel can be predicted using a simple model or the locations of the users on the ground are known. In this paper, we use deep reinforcement learning (deep RL) to optimally place a UAV serving a ground user in an urban environment, without the previous knowledge of the channel or user location. Our algorithm relies on signal-to-interference-plus- noise ratio (SINR) measurements and a 3D map of the topology to account for blockage and scatterers. Furthermore, it is designed to operate in any urban environment. Results in conditions simulated by a ray tracing software show that with the constraint on the maximum number of iterations our algorithm has a 90% success rate in converging to a target SINR.},
keywords={Learning (artificial intelligence);Signal to noise ratio;Interference;Topology;Unmanned aerial vehicles;Urban areas;Three-dimensional displays},
doi={10.1109/GCWkshps45667.2019.9024644},
ISSN={},
month={Dec},}
@INPROCEEDINGS{9348200,
author={Patrizi, Nathan and Fragkos, Georgios and Tsiropoulou, Eirini Eleni and Papavassiliou, Symeon},
booktitle={GLOBECOM 2020 - 2020 IEEE Global Communications Conference}, title={Contract-Theoretic Resource Control in Wireless Powered Communication Public Safety Systems},
year={2020},
volume={},
number={},
pages={1-6},
abstract={Recent technological advances in the use of Unmanned Aerial Vehicles (UAVs) and Wireless Powered Communications (WPC) have enabled the energy efficient operation of the Public Safety Networks (PSN) during disaster scenarios. In this paper, an energy efficient information flow and energy harvesting framework capturing users' risk-aware characteristics is introduced based on the principles of Contract Theory. To better support the operational effectiveness of the proposed framework, users are clustered in rescue groups following a socio-physical-aware group formation mechanism, while rescue leaders for each group are selected. A reinforcement learning approach is applied to enable the optimal matching between the UAVs and the rescue leaders in a distributed and efficient manner. The proposed contract-theoretic framework models the UAVs-victims relation based on a labor market setting via offering rewards to the users (incentives) in order to compensate them for their invested labor (reporting information). Detailed numerical results demonstrate the benefits and superiority of the proposed framework under different settings.},
keywords={Wireless communication;Reinforcement learning;Energy efficiency;Unmanned aerial vehicles;Safety;Numerical models;Contracts;Contract Theory;Reinforcement Learning;Public Safety Systems;Resource Control},
doi={10.1109/GLOBECOM42002.2020.9348200},
ISSN={2576-6813},
month={Dec},}
@INPROCEEDINGS{9213856,
author={Bhagat, Sarthak and Sujit, P.B.},
booktitle={2020 International Conference on Unmanned Aircraft Systems (ICUAS)}, title={UAV Target Tracking in Urban Environments Using Deep Reinforcement Learning},
year={2020},
volume={},
number={},
pages={694-701},
abstract={Persistent target tracking in urban environments using UAV is a difficult task due to the limited field of view, visibility obstruction from obstacles and uncertain target motion. The vehicle needs to plan intelligently in 3D such that the target visibility is maximized. In this paper, we introduce Target Following DQN (TF-DQN), a deep reinforcement learning technique based on Deep Q-Networks with a curriculum training framework for the UAV to persistently track the target in the presence of obstacles and target motion uncertainty. The algorithm is evaluated through simulations. The results show that the UAV tracks the target persistently in diverse environments while avoiding obstacles on the trained environments as well as on unseen environments.},
keywords={Target tracking;Urban areas;Unmanned aerial vehicles;Training;Uncertainty;Cameras},
doi={10.1109/ICUAS48674.2020.9213856},
ISSN={2575-7296},
month={Sep.},}
@ARTICLE{9475975,
author={Zhang, Zhicai and Zhang, Qian and Miao, Jiansong and Yu, F. Richard and Fu, Fang and Du, Jianbo and Wu, Tuan},
journal={IEEE Transactions on Green Communications and Networking}, title={Energy-Efficient Secure Video Streaming in UAV-Enabled Wireless Networks: A Safe-DQN Approach},
year={2021},
volume={5},
number={4},
pages={1892-1905},
abstract={Unmanned aerial vehicles (UAVs) are anticipated to be integrated into the next generation wireless networks as new aerial mobile nodes, which can provide various live streaming applications such as surveillance, reconnaissance, etc. For such applications, due to the dynamic characteristics of traffic and wireless channels, how to guarantee the quality of service (QoS) is a challenging task. In this paper, with recent advances in scalable video coding (SVC), we study energy-efficient secure video streaming in rotary-wing UAV-enabled wireless networks. By jointly optimizing video levels selection, power allocation, and the UAV’s trajectory, we intend to maximize the long-term energy efficiency that is defined as the ratio of video quality to power consumption. Meanwhile, secrecy timeout probability is considered as a constraint cost to guarantee time delays requirements in a long run perspective. Our problem is modeled as a constrained Markov decision process (CMDP) and solved by safe deep Q-learning network (safe-DQN), where a safe policies set induced by constructing a Lyapunov function is dynamically adjusted to satisfy the constraint conditions of the CMDP. Extensive simulation results with different system parameters show the effectiveness of the proposed algorithm compared with other existing reinforcement learning algorithms.},
keywords={Streaming media;Trajectory;Wireless communication;Communication system security;Wireless networks;Resource management;Static VAr compensators;UAV;video streaming;resource allocation;physical layer security;trajectory design;safe-DQN},
doi={10.1109/TGCN.2021.3095315},
ISSN={2473-2400},
month={Dec},}
@INPROCEEDINGS{9569429,
author={Wu, Mengjie and Chi, Huijia and Gan, Shuying and Wang, Xijun and Xu, Chao},
booktitle={2021 IEEE 32nd Annual International Symposium on Personal, Indoor and Mobile Radio Communications (PIMRC)}, title={AoI optimal UAV trajectory planning: A Deep Recurrent Reinforcement Learning Approach},
year={2021},
volume={},
number={},
pages={1-6},
abstract={In this paper, we consider an unmanned aerial vehicles (UAV)-assisted IoT network and study the trajectory planning problem to optimize the information freshness, in terms of age of information (AoI), where the update arrivals at IoT devices are stochastic and are not known to the UAV. To this end, we first formulate the dynamic UAV trajectory planning problem as a Partially Observable Markov Decision Process (POMDP) with non-uniform time steps, where the set of valid actions is coupled with the agent's observations. Then, a deep recurrent reinforcement learning (DRRL) algorithm is devised to find the policy minimizing the expectation of the weighted average AoI, in which a modified discount mechanism is utilized to deal with the challenge from non-uniform time steps and an action elimination mechanism is introduced to address the coupling between the valid actions and observations. Finally, simulations are conducted to validate the effectiveness of our proposed algorithm by comparing it with baseline strategies.},
keywords={Couplings;Trajectory planning;Heuristic algorithms;Simulation;Reinforcement learning;Markov processes;Information age},
doi={10.1109/PIMRC50174.2021.9569429},
ISSN={2166-9589},
month={Sep.},}
@INPROCEEDINGS{9594355,
author={Xu, Chengtao and Song, Houbing},
booktitle={2021 IEEE/AIAA 40th Digital Avionics Systems Conference (DASC)}, title={Mixed Initiative Balance of Human-Swarm Teaming in Surveillance via Reinforcement learning},
year={2021},
volume={},
number={},
pages={1-10},
abstract={Human-machine teaming (HMT) operates in a context defined by the mission. Varying from the complexity and disturbance in the cooperation between humans and machines, a single machine has difficulty handling work with humans in the scales of efficiency and workload. Swarm of machines provides a more feasible solution in such a mission. Human-swarm teaming (HST) extends the concept of HMT in the mission, such as persistent surveillance, search-and-rescue, warfare. Bringing the concept of HST faces several scientific challenges. For example, the strategies of allocation on the high-level decision making. Here, human usually plays the supervisory or decision making role. Performance of such fixed structure of HST in actual mission operation could be affected by the supervisor’s status from many aspects, which could be considered in three general parts: workload, situational awareness, and trust towards the robot swarm teammate and mission performance. Besides, the complexity of a single human operator in accessing multiple machine agents increases the work burdens. An interface between swarm teammates and human operators to simplify the interaction process is desired in the HST.In this paper, instead of purely considering the workload of human teammates, we propose the computational model of human swarm interaction (HSI) in the simulated map surveillance mission. UAV swarm and human supervisor are both assigned in searching a predefined area of interest (AOI). The workload allocation of map monitoring is adjusted based on the status of the human worker and swarm teammate. Workload, situation awareness ability, trust are formulated as independent models, which affect each other. A communication-aware UAV swarm persistent surveillance algorithm is assigned in the swarm autonomy portion. With the different surveillance task loads, the swarm agent’s thrust parameter adjusts the autonomy level to fit the human operator’s needs. Reinforcement learning is applied in seeking the relative balance of workload in both human and swarm sides. Metrics such as mission accomplishment rate, human supervisor performance, mission performance of UAV swarm are evaluated in the end. The simulation results show that the algorithm could learn the human-machine trust interaction to seek the workload balance to reach better mission execution performance. This work inspires us to leverage a more comprehensive HST model in more practical HMT application scenarios.},
keywords={Surveillance;Computational modeling;Simulation;Decision making;Reinforcement learning;Complexity theory;Resource management;Human-Swarm Teaming;Mixed Initiative Balance;Robust Persistent Surveillance;Reinforcement Learning},
doi={10.1109/DASC52595.2021.9594355},
ISSN={2155-7209},
month={Oct},}
@ARTICLE{8600371,
author={Wang, Chao and Wang, Jian and Shen, Yuan and Zhang, Xudong},
journal={IEEE Transactions on Vehicular Technology}, title={Autonomous Navigation of UAVs in Large-Scale Complex Environments: A Deep Reinforcement Learning Approach},
year={2019},
volume={68},
number={3},
pages={2124-2136},
abstract={In this paper, we propose a deep reinforcement learning (DRL)-based method that allows unmanned aerial vehicles (UAVs) to execute navigation tasks in large-scale complex environments. This technique is important for many applications such as goods delivery and remote surveillance. The problem is formulated as a partially observable Markov decision process (POMDP) and solved by a novel online DRL algorithm designed based on two strictly proved policy gradient theorems within the actor-critic framework. In contrast to conventional simultaneous localization and mapping-based or sensing and avoidance-based approaches, our method directly maps UAVs' raw sensory measurements into control signals for navigation. Experiment results demonstrate that our method can enable UAVs to autonomously perform navigation in a virtual large-scale complex environment and can be generalized to more complex, larger-scale, and three-dimensional environments. Besides, the proposed online DRL algorithm addressing POMDPs outperforms the state-of-the-art.},
keywords={Navigation;Aerospace electronics;Sensors;Markov processes;Reinforcement learning;Path planning;Autonomous navigation;deep reinforcement learning;partially observable Markov decision process},
doi={10.1109/TVT.2018.2890773},
ISSN={1939-9359},
month={March},}
@INPROCEEDINGS{9590178,
author={Xue, Zhihan and Gonsalves, Tad},
booktitle={2021 2nd International Conference on Innovative and Creative Information Technology (ICITech)}, title={Monocular Vision Obstacle Avoidance UAV: A Deep Reinforcement Learning Method},
year={2021},
volume={},
number={},
pages={1-6},
abstract={In this paper, a method based on deep reinforcement learning (DRL) is proposed, which allows unmanned aerial vehicles (UAVs) to complete obstacle avoidance tasks only through vision in an environment full of common indoor obstacles. This technology is very important for indoor UAVs, due to the limited GPS signal and overcrowding of obstacles compared to the outdoor environment. We use Variational Autoencoder (VAE) to compress image information combined with the policy-based DRL model to implement the visual obstacle avoidance of VAVs. Simulation experiments have demonstrated that this method can make the UAV master obstacle avoidance in a continuous action space with a fixed direction. Compared with the traditional policy-based DRL visual obstacle avoidance algorithms, it can converge faster.},
keywords={Training;Visualization;Adaptation models;Reinforcement learning;Unmanned aerial vehicles;Data models;Collision avoidance;Drone;Deep Reinforcement Learning;VAE;Obstacle Avoidance},
doi={10.1109/ICITech50181.2021.9590178},
ISSN={},
month={Sep.},}
@INPROCEEDINGS{8928110,
author={Han, Xiao and Wang, Jing and Xue, Jiayin and Zhang, Qinyu},
booktitle={2019 11th International Conference on Wireless Communications and Signal Processing (WCSP)}, title={Intelligent Decision-Making for 3-Dimensional Dynamic Obstacle Avoidance of UAV Based on Deep Reinforcement Learning},
year={2019},
volume={},
number={},
pages={1-6},
abstract={With the growing utilization of UAV in reconnaissance, agriculture, logistics and entertainment, Autonomous collision avoidance during flight has become a necessary capability for modern UAV to detect the surrounding environment and guarantee their own safety. Autonomous obstacle avoidance is a typical agent decision-making problem. Unfortunately, existing traditional decision-making methods perform poorly in this specific realm, In particular, it is unable to meet the requirements of three-dimensional obstacle avoidance of UAV, so we introduce the deep reinforcement learning (DRL) technique into autonomous obstacle avoidance. We model the obstacle avoidance process as a Markov Decision Process and introduce a structure composed of double joint neural network estimators as the decision-maker, whose input is omnidirectional sonar readings and whose output is a value function estimating future rewards. Also, we propose an adaption in the procedure of memory replay to optimize the sampling, where we assign weights to the transitions and sample them accordingly. Our method is applied in a 3-dimensional physic environment, which contains both random dynamic obstacles and floating bouncing obstacles. The goal of the drone is to reach the terminal point without crash. Double Q Learning method with priority sampling, by comparison, achieves the most excellent performance in our simulation. Compared with the traditional algorithms, the proposed algorithm not only ensures the quality of decision making, enabling the agent to learn the optimal strategy, but also effectively improves the performance of the task and the efficiency of decision making. Simulation results demonstrate its effectiveness.},
keywords={Collision avoidance;Unmanned aerial vehicles;Neural networks;Decision making;Machine learning;Heuristic algorithms;Training;moving obstacles avoidance;UAV;agent decision;deep Q learning;double DQN;experience replay},
doi={10.1109/WCSP.2019.8928110},
ISSN={2472-7628},
month={Oct},}
@INPROCEEDINGS{8795855,
author={Eslamiat, Hossein and Li, Yilan and Wang, Ningshan and Sanyal, Amit K. and Qiu, Qinru},
booktitle={2019 18th European Control Conference (ECC)}, title={Autonomous Waypoint Planning, Optimal Trajectory Generation and Nonlinear Tracking Control for Multi-rotor UAVs},
year={2019},
volume={},
number={},
pages={2695-2700},
abstract={A framework for autonomous waypoint planning, trajectory generation through waypoints, and trajectory tracking for multi-rotor unmanned aerial vehicles (UAVs) is proposed in this work. Safe and effective operations of these UAVs is a problem that demands obstacle avoidance strategies and advanced trajectory planning and control schemes for stability and energy efficiency. To address this problem, a two-level optimization strategy is used for trajectory generation, then the trajectory is tracked in a stable manner. The framework given here consists of the following components: (a) a deep reinforcement learning (DRL)-based algorithm for optimal waypoint planning while minimizing control energy and avoiding obstacles in a given environment; (b) an optimal, smooth trajectory generation algorithm through waypoints, that minimizes a combination of velocity, acceleration, jerk and snap; and (c) a stable tracking control law that determines a control thrust force for an UAV to track the generated trajectory.},
keywords={},
doi={10.23919/ECC.2019.8795855},
ISSN={},
month={June},}
@INPROCEEDINGS{8689187,
author={Cao, Yang and Zhang, Lin and Liang, Ying-Chang},
booktitle={2018 IEEE International Conference on Communication Systems (ICCS)}, title={Deep Reinforcement Learning for User Access Control in UAV Networks},
year={2018},
volume={},
number={},
pages={297-302},
abstract={Unmanned Aerial Vehicles (UAV) are recently proposed as the flying base stations (BS), namely, UAV-BS, to boost the capacity as well as extend the coverage of the current wireless network. Nevertheless, the mobility of UAV-BS leads to a highly dynamic network environment, which poses new challenges on the access control of the users on the ground. Two key challenges are the acquisition of the global network information at each user and frequent handovers. Motivated by recent works, which show preferable performance of the deep reinforcement learning (DRL) in the dynamic network environment, we propose a DRL framework to help the user make access decisions. With the proposed DRL framework, the user is able to intelligently make access decisions and maximize the long-term throughput with partial network information, meanwhile avoid frequent handovers. Simulation results have validated the effectiveness of the proposed algorithm and shown the advantage of the proposed DRL framework over the state of arts.},
keywords={},
doi={10.1109/ICCS.2018.8689187},
ISSN={},
month={Dec},}
@INPROCEEDINGS{9727879,
author={Li, Baowei and Li, Shuai and Wang, Chen and Fan, Ruifeng and Shao, Jinyan and Xie, Guangming},
booktitle={2021 China Automation Congress (CAC)}, title={Distributed Circle Formation Control for Quadrotors Based on Multi-agent Deep Reinforcement Learning},
year={2021},
volume={},
number={},
pages={4750-4755},
abstract={Multi-rotor unmanned aerial vehicles (UAVs) have been increasingly used in both civil and military applications in recent years, and it is difficult for a single multi-rotor UAV to accomplish a specific task due to the load and range limitations. In this paper, we take the most commonly used quadrotor among multi-rotor UAVs as the research object, and study the formation control problems such as formation generation, formation transformation and collision avoidance. We design a distributed circle formation algorithm based on deep reinforcement learning, which is combined with an artificial potential based law to ensure collision avoidance. In order to simulate the real environments, a multi-quadrotor simulator is built based on ROS and gazebo. The algorithm is trained and tested in the simulator, whose results show the effectiveness of the proposed algorithm.},
keywords={Automation;Reinforcement learning;Autonomous aerial vehicles;Collision avoidance;Task analysis;quadrotor;formation;deep reinforcement learning;distributed},
doi={10.1109/CAC53003.2021.9727879},
ISSN={2688-0938},
month={Oct},}
@INPROCEEDINGS{6907000,
author={Allamaraju, Rakshit and Kingravi, Hassan and Axelrod, Allan and Chowdhary, Girish and Grande, Robert and How, Jonathan P. and Crick, Christopher and Sheng, Weihua},
booktitle={2014 IEEE International Conference on Robotics and Automation (ICRA)}, title={Human aware UAS path planning in urban environments using nonstationary MDPs},
year={2014},
volume={},
number={},
pages={1161-1167},
abstract={A growing concern with deploying Unmanned Aerial Vehicles (UAVs) in urban environments is the potential violation of human privacy, and the backlash this could entail. Therefore, there is a need for UAV path planning algorithms that minimize the likelihood of invading human privacy. We formulate the problem of human-aware path planning as a nonstationary Markov Decision Process, and provide a novel model-based reinforcement learning solution that leverages Gaussian process clustering. Our algorithm is flexible enough to accommodate changes in human population densities by employing Bayesian nonparametrics, and is real-time computable. The approach is validated experimentally on a large-scale long duration experiment with both simulated and real UAVs.},
keywords={Clustering algorithms;Data models;Computational modeling;Sociology;Statistics;Path planning;Kernel},
doi={10.1109/ICRA.2014.6907000},
ISSN={1050-4729},
month={May},}
@INPROCEEDINGS{8645103,
author={Bayerlein, Harald and Gangula, Rajeev and Gesbert, David},
booktitle={2018 52nd Asilomar Conference on Signals, Systems, and Computers}, title={Learning to Rest: A Q-Learning Approach to Flying Base Station Trajectory Design with Landing Spots},
year={2018},
volume={},
number={},
pages={724-728},
abstract={We consider the problem of trajectory optimization for an autonomous UAV-mounted base station that provides communication services to ground users with the aid of landing spots (LSs). Recently, the concept of LSs was introduced to alleviate the problem of short mission durations arising from the limited on-board battery budget of the UAV, which severely limits network performance. In this work, using Q-learning, a model-free reinforcement learning (RL) technique, we train a neural network (NN) to make movement decisions for the UAV that maximize the data collected from the ground users while minimizing power consumption by exploiting the landing spots. We show that the system intelligently integrates landing spots into the trajectory to extend flying time and is able to learn the topology of the network over several flying epochs without any explicit information about the environment.},
keywords={Artificial neural networks;Training;Batteries;Drones;Power demand;Quality of service;Trajectory},
doi={10.1109/ACSSC.2018.8645103},
ISSN={2576-2303},
month={Oct},}
@INPROCEEDINGS{9739235,
author={Zhou, Xuan and Chen, Yi and Liu, Yaohua and Hu, Jinxing},
booktitle={2021 IEEE International Conference on Robotics and Biomimetics (ROBIO)}, title={A Novel Sensor Fusion Method Based on Invariant Extended Kalman Filter for Unmanned Aerial Vehicle},
year={2021},
volume={},
number={},
pages={1111-1116},
abstract={With the development and popularization of the Artificial Intelligence technology, unmanned aerial vehicles (UAV) are widely used to executing more challenging tasks in complex urban environments, such as delivery, inspection and monitoring. Meanwhile, these complex tasks put forward higher demands for the Navigation system of UAV, and the traditional single sensor such as global positioning system (GPS) and inertial navigation system (INS) have been unable to meet the requirements. In this paper, we derive and implement a novel sensor fusion method based on Invariant Extended Kalman filter (InEKF) with left invariant error (LIEKF) for UAV localization in MATLAB, which inertial measurement unit (IMU) data is used for prediction and GPS data is used for correction. The proposed filter is applied to the simulated data that we generated and also to the Zurich Urban Dataset. By comparing the estimated position to the ground truth, LIEKF has outperformed that of the tradition EKF in both attitude and position in simulated data. It also achieved a better tracking effect and more stable performance in Zurich Urban Dataset, the uniaxial Standard Deviation errors of LIEKF are lower than the traditional EKF.},
keywords={Urban areas;Switches;Sensor fusion;Autonomous aerial vehicles;Robot sensing systems;Kalman filters;Task analysis;Attitude algorithm;position estimation;GPS;IMU;UAV},
doi={10.1109/ROBIO54168.2021.9739235},
ISSN={},
month={Dec},}
@INPROCEEDINGS{7257064,
author={Rodriguez-Fernandez, Victor and Ramirez-Atencia, Cristian and Camacho, David},
booktitle={2015 IEEE Congress on Evolutionary Computation (CEC)}, title={A multi-UAV mission planning videogame-based framework for player analysis},
year={2015},
volume={},
number={},
pages={1490-1497},
abstract={The problem of Mission Planning for a large number of Unmanned Air Vehicles (UAVs) comprises a set of locations to visit in different time windows, and the actions that the vehicle can perform based on its features, such as sensors, speed or fuel consumption. Although this problem is increasingly more supported by Artificial Intelligence systems, nowadays human factors are still critical to guarantee the success of the designed plan. Studying and analyzing how humans solve this problem is sometimes difficult due to the complexity of the problem and the lack of data available. To overcome this problem, we have developed an analysis framework for Multi-UAV Cooperative Mission Planning Problem (MCMPP) based on a videogame that gamifies the problem and allows a player to design plans for multiple UAVs intuitively. On the other hand, we have also developed a mission planner algorithm based on Constraint Satisfaction Problems (CSPs) and solved with a Multi-Objective Branch & Bound (MOBB) method which optimizes the objective variables of the problem and gets the best solutions in the Pareto Optimal Frontier (POF). To prove the environment potential, we have performed a comparative study between the plans generated by a heterogenous group of human players and the solutions obtained by this planner.},
keywords={Games;Fuels;Planning;Vehicles;Sensor phenomena and characterization;Computer architecture},
doi={10.1109/CEC.2015.7257064},
ISSN={1941-0026},
month={May},}
@INPROCEEDINGS{9622944,
author={Gao, Kunyu and Wang, Jinbo and Wang, Bin and Wang, Ruixue and Jia, Jiao},
booktitle={2021 8th International Conference on Dependable Systems and Their Applications (DSA)}, title={UAV Test Data Generation Method based on CycleGAN},
year={2021},
volume={},
number={},
pages={338-343},
abstract={Unmanned aerial vehicles (UAV) have developed rapidly in recent years. With the popularity of artificial intelligence, UAV has been closely related to the military, economic and life fields. However, there are still security concerns with intelligent software. If these hidden dangers appear in reality, they will cause economic losses and even endanger people’s lives. Thus, intelligent software must be tested and verified before they can be put into service. To ensure the effectiveness of testing, we need to generate high-quality, large-scale and low-cost datasets. However, due to weather, technical conditions and other factors, the existing datasets are difficult to meet the demand. Accordingly, we propose a novel method to generate dataset for UAV software testing based on Cycle-Consistent Adversarial Networks (CycleGAN) in this paper. In addition, We conduct experiments and verification on the real dataset of Google Maps. The results show that even if the dataset is disturbed, the images we generate are still of high quality.},
keywords={Economics;Software testing;Autonomous aerial vehicles;Software;Internet;Security;Artificial intelligence;UAV;CycleGAN;Test data generation},
doi={10.1109/DSA52907.2021.00052},
ISSN={2767-6684},
month={Aug},}
@INPROCEEDINGS{7284027,
author={Czyba, Roman and Hecel, Michał and Jabłoński, Karol and Lemanowicz, Marcin and Płatek, Krzysztof},
booktitle={2015 20th International Conference on Methods and Models in Automation and Robotics (MMAR)}, title={Application of computer aided tools and methods for unmanned cargo aircraft design},
year={2015},
volume={},
number={},
pages={1068-1073},
abstract={Nowadays, novel construction materials, more efficient power supplies and advanced artificial intelligence algorithms allow one to use unmanned aerial vehicles (UAV) in various fields of life. One of the biggest events promoting this idea is the Air Cargo Challenge (ACC) competition. In this paper the motivation for ACC participation and the overall procedure of CAD aided UAV design are presented. The nonlinear aircraft model as well as Computational Fluid Dynamic simulations are discussed. Finally, some details concerning designed UAV prototype are revealed.},
keywords={Aircraft;Computational fluid dynamics;Aircraft propulsion;Aerodynamics;Atmospheric modeling;Computational modeling;Mathematical model;UAV;CAD;CFD;Rapid Prototyping},
doi={10.1109/MMAR.2015.7284027},
ISSN={},
month={Aug},}
@INPROCEEDINGS{8651831,
author={Usman, Muhammad Rehan and Usman, Muhammad Arslan and Yaq, Muhammad Azfar and Shin, Soo Young},
booktitle={2019 16th IEEE Annual Consumer Communications Networking Conference (CCNC)}, title={UAV Reconnaissance using Bio-Inspired Algorithms: Joint PSO and Penguin Search Optimization Algorithm (PeSOA) Attributes},
year={2019},
volume={},
number={},
pages={1-6},
abstract={Importance of bio-inspired algorithms (BIAs) is increasing exponentially because of their capability to optimization different problems in various fields like artificial intelligence, and medicine etc. Because of the autonomous nature, BIAs are now being used in unmanned aerial vehicles (UAVs) for applications areas like internet of things (IoT), autonomous area searching and reconnaissance etc. This paper presents a UAV reconnaissance strategy jointly using the particle swarm optimization (PSO) algorithm and a few attributes of the penguin search optimization algorithm (PeSOA). The strategy mainly focuses on finding the rescue targets utilizing UAVs by optimizing their movement using combined PSO and PeSOA attributes. The results are analyzed in terms of grouping and non-grouping scenarios with and without using PeSOA attributes.},
keywords={Reconnaissance;Fish;Optimization;Drones;Particle swarm optimization;Sociology;Bio inspired algorithms;particle swarm optimization (PSO);penguin search optimization (PeSOA);reconnaissance;UAV},
doi={10.1109/CCNC.2019.8651831},
ISSN={2331-9860},
month={Jan},}
@INPROCEEDINGS{9421639,
author={Yao, Peng Fei and Geng, Bo and Yang, Min and Cai, Ying Ming and Wang, Tao},
booktitle={2020 5th International Conference on Mechanical, Control and Computer Engineering (ICMCCE)}, title={Research on Technology of Autonomous Inspection System for UAV Based on Improved Yolov4},
year={2020},
volume={},
number={},
pages={664-668},
abstract={With the continuous expansion of the grid scale and the development of artificial intelligence, UAV inspection is gradually replacing manual inspections and has become a mainstream of transmission line inspections by its high efficiency, low cost and high safety, which has greatly improved the inspection efficiency and inspection accuracy of transmission lines. However, the existing UAV inspections mainly rely on manual methods, requiring staff to operate and perform a lot of interventions in the field. The operating specifications are not uniform, which brings a lot of difficulties to the subsequent intelligent identification. Therefore, this paper proposes an autonomous transmission line UAV inspection system based on the improved yolov4. First, a priori box is set through K-means clustering to enhance the size adaptability, and the improved yolov4 could identify the key structure of the transmission tower. Second, the system could move the PTZ to place the relevant structure in the center of the image to complete the collection of image information. The test results show that the system can collect relevant information of transmission line towers in a standardized manner, improve the accuracy of image collection, and expand the scope of application of autonomous drone inspections, and provide a new direction for subsequent intelligent inspections.},
keywords={Power transmission lines;Poles and towers;Manuals;Inspection;Safety;Artificial intelligence;Drones;UAV;yolov4;autonomous inspection;target detection},
doi={10.1109/ICMCCE51767.2020.00146},
ISSN={},
month={Dec},}
@INPROCEEDINGS{9058320,
author={Alshanbari, Reem and Khan, Sherjeel and El-Atab, Nazek and Mustafa Hussain, Muhammad},
booktitle={2019 IEEE National Aerospace and Electronics Conference (NAECON)}, title={AI Powered Unmanned Aerial Vehicle for Payload Transport Application},
year={2019},
volume={},
number={},
pages={420-424},
abstract={Recently unmanned aerial vehicles (UAV) have received a growing attention due to their wide range of applications. Here, we demonstrate UAVs with artificial intelligence (AI) capabilities for application in autonomous payload transport. An algorithm is developed for target detection with multiple phases on the ground, which once the target is detected, would trigger the release of the payload that is attached on the drone. The experimental results show that the average frame rate over x seconds achieved a 19.4010717352 fps (frame per second) detection speed. Releasing the payload is achieved using a 3D printed system based on rack and pinion gears. In addition, auto flight program is developed to enable the autonomous movement of the drone. As a proof-of-concept, a small drone known as "Phantom DJI" is used for .6 kg autonomous payload transport along a predefined route to a target location.},
keywords={Drones;Payloads;Global Positioning System;Gears;Image edge detection;Image color analysis;Artificial intelligence;UAV;robotics;color detection;payload.},
doi={10.1109/NAECON46414.2019.9058320},
ISSN={2379-2027},
month={July},}
@INPROCEEDINGS{8943841,
author={Yurchuk, Iryna and Kovdrya, Vladyslav and Bilyanska, Lolita},
booktitle={2019 IEEE 5th International Conference Actual Problems of Unmanned Aerial Vehicles Developments (APUAVD)}, title={Segmentation of Digital Images of Aerial Photography},
year={2019},
volume={},
number={},
pages={258-261},
abstract={For today, autonomous UAVs are a combination of artificial intelligence, mechanical devices, and navigational instruments. To save computing resources and improve the quality of their navigation, motion control systems, recognition, etc., real-time UAV's video has to be preprocessed by segmentation or clustering algorithms. In this work, the analysis of parameters of effective graph-based (EGB) and pyramidal segmentation algorithms (PSA) was obtained for digital images of aerial photography. The authors used RGB, Lab, and HSV (BHS) color models. According to the results of testing EGB algorithm is faster, but its result of segmentation is ordinary. Whereas, PSA produces a result that is closer to human perception but its disadvantage is a long processing time. Authors recommended Lab and HBS formats of image, since their segmentation results are more effective than, for example, at RGB.},
keywords={Image segmentation;Object segmentation;Quality assessment;Digital images;Clustering algorithms;Photography;Real-time systems;aerial photography;segmentation;graph-based algorithm;pyramidal algorithm},
doi={10.1109/APUAVD47061.2019.8943841},
ISSN={},
month={Oct},}
@INPROCEEDINGS{8845527,
author={Yongqiang, CHEN and Shaofang, LI and Hongmei, Liu and Pin, Tao and Yilin, CHEN},
booktitle={2019 14th International Conference on Computer Science Education (ICCSE)}, title={Application of Intelligent Technology in Animal Husbandry and Aquaculture Industry},
year={2019},
volume={},
number={},
pages={335-339},
abstract={with the popularization of wUAV technology, information technology, artificial intelligence and automation technology, it is a more realistic problem to apply these modern technological to the traditional animal husbandry and aquaculture industry. This will greatly liberate human resources, improve modern production efficiency, and will be of great help to improve the output, product quality and other conveniences. Applying artificial intelligence to modern animal husbandry and animal husbandry and aquaculture technology can intelligently identify animals of different weights and stages, feed differently, and improve the output rate of high-quality feeding animals. On the basis of investigation and Research on different types of sheep houses, the paper formulates optimization and improvement plan for the shortcomings of existing sheep houses, applies information technology in the field of animal husbandry science, improves the automation and intelligence level of goat houses, through the crossdisciplines of automated feeding, precision feeding, automatic door closure, photographic weighting, UAV sheep farm patrol, and herd behavior image analysis, etc. The research and development of new technology has developed a new sheep house for meat goats suitable for use in Agricultural Area, carried out research on microclimate environment regulation and control of different types of sheep houses, formulated corresponding control schemes, and carried out demonstration application in the project area to improve the health status of sheep and increase production efficiency.},
keywords={Animals;Internet of Things;Aquaculture;Production;Automation;Artificial intelligence;information technology;Animal husbandry and Aquaculture;Internet of things},
doi={10.1109/ICCSE.2019.8845527},
ISSN={2473-9464},
month={Aug},}
@INPROCEEDINGS{7129842,
author={Kurt, Gökhan and İnce, Gökhan},
booktitle={2015 23nd Signal Processing and Communications Applications Conference (SIU)}, title={Path planning in a 3D environment created using real world data},
year={2015},
volume={},
number={},
pages={395-398},
abstract={This document, demonstrates that web maps can be used to create a 3 dimensional environment model and a path finding mechanism can be developed to find path in this environment. Innovative feature of this work is that any place on Earth can be recreated and simulated as 3 dimensional model. Map and height data are obtained through the internet and the data is used to create environment model procedurally. Then, objects that can be obstacles to an artificial intelligence agent are determined and a path finding model is procedurally generated. In tests, it is demonstrated that two different artificial intelligence agents (mobile robot and UAV) can find shortest path depending on their features.},
keywords={Internet;Robots;Path planning;Three-dimensional displays;Navigation;Computational geometry;Computers;procedural content generation;navigation mesh;navmesh;path planning;pathfinding},
doi={10.1109/SIU.2015.7129842},
ISSN={2165-0608},
month={May},}
@INPROCEEDINGS{8343133,
author={El-Sayed, Hesham and Chaqfeh, Moumena},
booktitle={2018 International Conference on Information Networking (ICOIN)}, title={The deployment of mobile edges in vehicular environments},
year={2018},
volume={},
number={},
pages={322-324},
abstract={The provision of online traffic information and applications in vehicular environment can be offered via fixed ground Roadside Units (RSUs). Nevertheless, employing flying RSUs that are carried by Unmanned Aerial Vehicles (UAVs) would bring the capabilities of Mobile Edge Computing (MEC) to the vehicular environment, where they can be deployed dynamically in accordance to traffic safety events and congestion conditions. In this paper, we propose a novel method for the deployment of flying RSUs based on swarm intelligence. Our proposed method relies on two fundamental properties of the dynamic deployment of edges in vehicular environments, which are self-organization and the division of workload among RSUs. These two properties are necessary and sufficient to obtain a swarm intelligent behavior. The term “swarm” can refer to any restrained collection of interacting agents or individuals, which are - in this case - the travelling vehicles and RSUs.},
keywords={Heuristic algorithms;Roads;Vehicle dynamics;Optimization;Cloud computing;Particle swarm optimization;Intelligent Transportation Systems (ITS);Vehicular Environment;Flying RSUs;Deployment;Optimization},
doi={10.1109/ICOIN.2018.8343133},
ISSN={},
month={Jan},}
@INPROCEEDINGS{8715593,
author={Shinde, Chinmay and Lima, Rolif and Das, Kaushik},
booktitle={2019 Fifth Indian Control Conference (ICC)}, title={Multi-view Geometry and Deep Learning Based Drone Detection and Localization},
year={2019},
volume={},
number={},
pages={289-294},
abstract={A real-time vision based detection and 3D pose estimation of intruder Unmanned Aerial Vehicles (UAVs) is presented. Proposed method utilizes a cooperative team of UAVs mounted with monocular camera to detect the intruder UAV and simultaneously localize it. Detection is performed by using YOLOv2 deep learning network architecture while the position is obtained using multi-view geometry. General dynamics of the drone are considered to improve the target position estimate obtained from the image based estimate.},
keywords={Drones;Cameras;Target tracking;Object detection;Training;Sensors;Heuristic algorithms},
doi={10.1109/INDIANCC.2019.8715593},
ISSN={},
month={Jan},}
@INPROCEEDINGS{9205793,
author={Lee, Min-Fan Ricky and Nugroho, Asep and Le, Tuan-Tang and Bahrudin and Bastida, Saul Nieto},
booktitle={2020 International Conference on Advanced Robotics and Intelligent Systems (ARIS)}, title={Landing Area Recognition using Deep Learning for Unammaned Aerial Vehicles},
year={2020},
volume={},
number={},
pages={1-6},
abstract={The lack of an automated Unmanned Aerial Vehicles (UAV) landing site detection system has been identified as one of the main impediments to allow UAV flight over populated areas in civilian airspace to develop tasks in the logistical transport scenario. This research proposes landing area localization and obstruction detection for UAVs that are based on deep learning faster R-CNN and feature matching algorithm. Which output decides if the landing area is safe or not. The final result has been deployed on the Aerial Mobile Robot Platform and was successfully performed effectively.},
keywords={Training;Feature extraction;Drones;Testing;Object detection;Histograms;Machine learning;Convolutional Neural Network;Environment Classification;UAV;Object Detection;Feature Matching},
doi={10.1109/ARIS50834.2020.9205793},
ISSN={2572-6919},
month={Aug},}
@ARTICLE{9519838,
author={Wang, Chenxing and Tian, Jiangmin and Cao, Jiuwen and Wang, Xiaohong},
journal={IEEE Transactions on Geoscience and Remote Sensing}, title={Deep Learning-Based UAV Detection in Pulse-Doppler Radar},
year={2022},
volume={60},
number={},
pages={1-12},
abstract={With the popularity of unmanned aerial vehicles (UAVs), how to conduct automatic and effective detection to prevent unauthorized flying has become an important issue. The conventional constant false alarm rate (CFAR) detector based on radar signal has shown advantages in moving target detection. However, the CFAR-based detectors are strongly dependent on some manual experience, such as the ambient noise distribution estimation and the detection windows’ size selection, and usually suffered poor performance on small UAV detection due to the weak signal. Inspired by the success of deep learning (DL) on natural scene object detection, this article tries to explore a DL-based method for UAV detection in pulse-Doppler radar. Concretely, we propose a convolutional neural network (CNN) with two heads: one for the classification of the input range-Doppler map patch into target present or target absent and the other for the regression of offset between the target and the patch center. Then, based on the output of the network, a nonmaximum suppression (NMS) mechanism composed of probability-based initial recognition, distribution density-based recognition, and voting-based regression is developed to reduce false alarms as well as control the false alarms. Finally, experiments on both simulated data and real data are carried out, and it is shown that the proposed method can locate the target more accurately and achieve a much lower false alarm rate at a comparable detection rate than CFAR.},
keywords={Radar;Radar detection;Object detection;Radar cross-sections;Radar imaging;Detectors;Clutter;Convolutional neural network (CNN);moving target detection;nonmaximum suppression (NMS);range-Doppler (R-D) map;regression network},
doi={10.1109/TGRS.2021.3104907},
ISSN={1558-0644},
month={},}
@ARTICLE{9316698,
author={Yusefi, Abdullah and Durdu, Akif and Aslan, Muhammet Fatih and Sungur, Cemil},
journal={IEEE Access}, title={LSTM and Filter Based Comparison Analysis for Indoor Global Localization in UAVs},
year={2021},
volume={9},
number={},
pages={10054-10069},
abstract={Deep learning (DL) based localization and Simultaneous Localization and Mapping (SLAM) has recently gained considerable attention demonstrating remarkable results. Instead of constructing hand-crafted algorithms through geometric theories, DL based solutions provide a data-driven solution to the problem. Taking advantage of large amounts of training data and computing capacity, these approaches are increasingly developing into a new field that offers accurate and robust localization systems. In this work, the problem of global localization for unmanned aerial vehicles (UAVs) is analyzed by proposing a sequential, end-to-end, and multimodal deep neural network based monocular visual-inertial localization framework. More specifically, the proposed neural network architecture is three-fold; a visual feature extractor convNet network, a small IMU integrator bi-directional long short-term memory (LSTM), and a global pose regressor bi-directional LSTM network for pose estimation. In addition, by fusing the traditional IMU filtering methods instead of LSTM with the convNet, a more time-efficient deep pose estimation framework is presented. It is worth pointing out that the focus in this study is to evaluate the precision and efficiency of visual-inertial (VI) based localization approaches concerning indoor scenarios. The proposed deep global localization is compared with the various state-of-the-art algorithms on indoor UAV datasets, simulation environments and real-world drone experiments in terms of accuracy and time-efficiency. In addition, the comparison of IMU-LSTM and IMU-Filter based pose estimators is also provided by a detailed analysis. Experimental results show that the proposed filter-based approach combined with a DL approach has promising performance in terms of accuracy and time efficiency in indoor localization of UAVs.},
keywords={Location awareness;Cameras;Feature extraction;Visualization;Pose estimation;Simultaneous localization and mapping;Robot vision systems;Global localization;pose estimation;recurrent convolutional neural networks;bi-directional LSTM;VIO},
doi={10.1109/ACCESS.2021.3049896},
ISSN={2169-3536},
month={},}
@ARTICLE{9123345,
author={Rajagopal, Aghila and Ramachandran, A. and Shankar, K. and Khari, Manju and Jha, Sudan and Lee, Yongju and Joshi, Gyanendra Prasad},
journal={IEEE Access}, title={Fine-Tuned Residual Network-Based Features With Latent Variable Support Vector Machine-Based Optimal Scene Classification Model for Unmanned Aerial Vehicles},
year={2020},
volume={8},
number={},
pages={118396-118404},
abstract={In recent days, unmanned aerial vehicles (UAVs) becomes more familiar because of its versatility, automation abilities, and low cost. Dynamic scene classification gained significant interest among the UAV-based surveillance systems, e.g., high-voltage power line and forest fire monitoring, which facilitate the object detection, tracking process and drastically enhances the outcome of visual surveillance. This paper proposes a new optimal deep learning-based scene classification model captured by UAVs. The proposed model involves a residual network-based features extraction (RNBFE) which extracts features from the diverse convolution layers of a deep residual network. In addition, the several parameters in RNBFE lead to many configuration errors due to manual parameter tuning. So, self-adaptive global best harmony search (SGHS) algorithm is employed for tuning the parameters of the RNBFE. The resultant feature vectors undergo classification by the use of latent variable support vector machine (LVSVM) model. The presented optimal RNBFE (ORNBFE) model has been tested using two open access datasets namely UC Merced (UCM) Land Use Dataset and WHU-RS Dataset. The presented technique attains maximum scene classification accuracy over the other recently proposed methods.},
keywords={Feature extraction;Unmanned aerial vehicles;Training;Computational modeling;Support vector machines;Visualization;Image analysis;CNN;Harmony Search;LVSVM;residual network-based features extraction;RNBFE;scene classification;unmanned aerial vehicles},
doi={10.1109/ACCESS.2020.3004233},
ISSN={2169-3536},
month={},}
@ARTICLE{8907406,
author={Jiang, Feibo and Wang, Kezhi and Dong, Li and Pan, Cunhua and Xu, Wei and Yang, Kun},
journal={IEEE Internet of Things Journal}, title={Deep-Learning-Based Joint Resource Scheduling Algorithms for Hybrid MEC Networks},
year={2020},
volume={7},
number={7},
pages={6252-6265},
abstract={In this article, we consider a hybrid mobile edge computing (H-MEC) platform, which includes ground stations (GSs), ground vehicles (GVs), and unmanned aerial vehicles (UAVs), all with the mobile edge cloud installed to enable user equipments (UEs) or Internet of Things (IoT) devices with intensive computing tasks to offload. Our objective is to obtain an online offloading algorithm to minimize the energy consumption of all the UEs, by jointly optimizing the positions of GVs and UAVs, user association and resource allocation in real time, while considering the dynamic environment. To this end, we propose a hybrid deep-learning-based online offloading (H2O) framework where a large-scale path-loss fuzzy c-means (LS-FCM) algorithm is first proposed and used to predict the optimal positions of GVs and UAVs. Second, a fuzzy membership matrix U-based particle swarm optimization (U-PSO) algorithm is applied to solve the mixed-integer nonlinear programming (MINLP) problems and generate the sample data sets for the deep neural network (DNN) where the fuzzy membership matrix can capture the small-scale fading effects and the information of mutual interference. Third, a DNN with the scheduling layer is introduced to provide the user association and computing resource allocation under the practical latency requirement of the tasks and limited available computing resource of H-MEC. In addition, different from the traditional DNN predictor, we only input one UE's information to the DNN at one time, which will be suitable for the scenarios where the number of UE is varying and avoid the curse of dimensionality in DNN.},
keywords={Task analysis;Heuristic algorithms;Water;Resource management;Deep learning;Real-time systems;Internet of Things;Deep neural network (DNN);fuzzy c-means;mobile edge computing (MEC);particle swarm optimization (PSO);resource allocation;unmanned aerial vehicle (UAV)},
doi={10.1109/JIOT.2019.2954503},
ISSN={2327-4662},
month={July},}
@INPROCEEDINGS{8995948,
author={Wang, Changqing and Liang, Xinkai and Zhang, Shan and Shen, Chao},
booktitle={2019 IEEE International Conference on Unmanned Systems (ICUS)}, title={Motion Parallax Estimation for Ultra Low Altitude Obstacle Avoidance},
year={2019},
volume={},
number={},
pages={463-468},
abstract={By making full use of the curvature of the earth and ground clutter, the ultra-low altitude flight technique can significantly increase the difficulty of detecting and intercepting unmanned aerial vehicles (UAVs), and improve their penetration probabilities. However, unpredicted static/dynamic obstacles seriously threaten the flight safety of the ultra-low altitude UAVs. Therefore, fine autonomous spatial perception capability is essential for ultra-low altitude UAVs with limited loads and computing resources to avoid obstacles. To solve the difficult problem of spatial perception for ultra-low altitude obstacle avoidance, a motion parallax estimation algorithm is proposed by combing the deep learning and the epipolar geometry in this paper. By utilizing the deep neural network, the end-to-end mapping relationship from sequence images to depth values of pixels is constructed for spatial perception. At the same time, to overcome the interference caused by the image consistency hypothesis, the loss function is constructed based on the 3D geometric information of the scene rather than the re-projection error between images. Finally, the proposed algorithm is evaluated on the KITTI dataset and infrared image dataset to verify its effectiveness and generalization.},
keywords={Motion Parallax;Deep Learning;Epipolar Geometry component},
doi={10.1109/ICUS48101.2019.8995948},
ISSN={},
month={Oct},}
@INPROCEEDINGS{9096259,
author={Srigrarom, Sutthiphong and Lee, Shawndy Michael and Lee, Mengda and Shaohui, Foong and Ratsamee, Photchara},
booktitle={2020 5th International Conference on Control and Robotics Engineering (ICCRE)}, title={An Integrated Vision-based Detection-tracking-estimation System for Dynamic Localization of Small Aerial Vehicles},
year={2020},
volume={},
number={},
pages={152-158},
abstract={A unified detection-tracking-estimation vision navigation system and algorithms framework for position and pose estimation of small aerial vehicle (UAV) is proposed in conjunction with our recent 3D dynamic localization technique. The major contribution of this work is a novel combination of deep learning for detection of moving object as the small UAV, follow by the vision tracking and estimation of the spatial location in global frame. The system can be multiplied and that the extended systems would provide 3D coordinates of the UAV. The demonstrations in both indoor and outdoor were conducted and that the system was able to detect and locate the small aerial vehicle in 3D space.},
keywords={Cameras;Drones;Three-dimensional displays;Optical imaging;Two dimensional displays;Adaptive optics;Vehicle dynamics;dynamic detection;localization and tracking;small and fast moving object;multiple camera},
doi={10.1109/ICCRE49379.2020.9096259},
ISSN={},
month={April},}
@INPROCEEDINGS{9647199,
author={Su, Chunqing and Pan, Jun and Jiang, Lijun and Sun, Yehan and Yu, Wei and Cao, Yu},
booktitle={2021 IEEE 3rd International Conference on Frontiers Technology of Information and Computer (ICFTIC)}, title={Research on UAV Image Ship Recognition Based on Fine-grained Classification Data Set},
year={2021},
volume={},
number={},
pages={344-350},
abstract={Ship identification is of great significance in coastal area monitoring and port military reconnaissance. The characteristics of different types of ships in high-resolution images are highly similar, and the internal details of the target are clearer. In order to effectively use the target details in the high-resolution image for target recognition, based on the UAV images of Xingcheng wharf and bingjiawan in Huludao City, Liaoning Province, the UAV ship image data sets with coarse-grained and fine-grained classification modes are established respectively. Build a deep learning platform based on tensorflow, and use SSD algorithm to identify the ships in the data set. The recognition accuracy of ship image data set based on coarse-grained classification pattern is 90.87%; The accuracy of ship image data set based on fine-grained classification model is 94.63%. The results show that: SSD algorithm can realize ship recognition of UAV image and Image data set based on fine-grained classification pattern can effectively use the detailed features of high-resolution image targets, so as to improve the accuracy of ship recognition.},
keywords={Image recognition;Target recognition;Urban areas;Sea measurements;Seaports;Reconnaissance;Pattern recognition;component;SSD Algorithm;Ship Identification;Classification Mode;UAV Image;Image Dataset},
doi={10.1109/ICFTIC54370.2021.9647199},
ISSN={},
month={Nov},}
@INPROCEEDINGS{9550141,
author={Huang, Jing and Li, Mengna and Zhang, Youmin and Mu, Lingxia and Ao, Zihang and Gong, Haihua},
booktitle={2021 40th Chinese Control Conference (CCC)}, title={Fault Detection and Classification for Sensor Faults of UAV by Deep Learning and Time-Frequency Analysis},
year={2021},
volume={},
number={},
pages={4420-4424},
abstract={Sensor faults could occur in unmanned aerial vehicles (UAVs) during a mission of flight, which might deteriorate UAV’s performance or even cause catastrophe. Considering different types of sensor faults of a quadrotor UAV, a new fault detection and classification method based on time-frequency analysis (TFA) and deep learning (DL) technologies is proposed in this paper. Firstly, the data sets including different types of sensor fault in time-domain are generated randomly. The date sets are then transformed into time-frequency domain by short-time Fourier transform (STFT), resulting in time-frequency graph (TFG). Secondly, the time-frequency graph sets are used to train the deep network, by which the fault type can be rapidly classified with high accuracy. Finally, the simulations are carried out to verify the performance of the proposed algorithm and the accuracy reaches to 99.6%.},
keywords={Deep learning;Time-frequency analysis;Fourier transforms;Fault detection;Simulation;Unmanned aerial vehicles;Classification algorithms;Fault detection and classification;sensor faults classification;time-frequency analysis (TFA);deep learning},
doi={10.23919/CCC52363.2021.9550141},
ISSN={1934-1768},
month={July},}
@INPROCEEDINGS{9254816,
author={Haddad, Abdel Gafoor and Ahmed Humais, Muhammad and Werghi, Naoufel and Shoufan, Abdulhadi},
booktitle={IECON 2020 The 46th Annual Conference of the IEEE Industrial Electronics Society}, title={Long-Range Visual UAV Detection and Tracking System with Threat Level Assessment},
year={2020},
volume={},
number={},
pages={638-643},
abstract={Unmanned aerial vehicles (UAVs) can pose a serious threat to critical infrastructure which has motivated researchers to develop solutions for early detection. Nevertheless, the problem remains unsolved due to the limitations of the current detection techniques. In this paper, a vision-based approach using deep learning and a pan-tilt-zoom camera is proposed. In addition to detecting and tracking UAVs at long distances, the approach also assesses the threat level of the intruder UAVs based on their orientation. The proposed system offers long-range coverage while being cheap and practically feasible.},
keywords={Cameras;Radar tracking;Radar;Radar detection;Detectors;Unmanned aerial vehicles;Feature extraction;UAV detection and tracking;drone detection;UAV threat;airport security;counter-UAV technologies},
doi={10.1109/IECON43393.2020.9254816},
ISSN={2577-1647},
month={Oct},}
@ARTICLE{9234491,
author={Li, Minglei and Zhao, Xingke and Li, Jiasong and Nan, Liangliang},
journal={IEEE Transactions on Geoscience and Remote Sensing}, title={ComNet: Combinational Neural Network for Object Detection in UAV-Borne Thermal Images},
year={2021},
volume={59},
number={8},
pages={6662-6673},
abstract={We propose a deep learning-based method for object detection in UAV-borne thermal images that have the capability of observing scenes in both day and night. Compared with visible images, thermal images have lower requirements for illumination conditions, but they typically have blurred edges and low contrast. Using a boundary-aware salient object detection network, we extract the saliency maps of the thermal images to improve the distinguishability. Thermal images are augmented with the corresponding saliency maps through channel replacement and pixel-level weighted fusion methods. Considering the limited computing power of UAV platforms, a lightweight combinational neural network ComNet is used as the core object detection method. The YOLOv3 model trained on the original images is used as a benchmark and compared with the proposed method. In the experiments, we analyze the detection performances of the ComNet models with different image fusion schemes. The experimental results show that the average precisions (APs) for pedestrian and vehicle detection have been improved by 2%~5% compared with the benchmark without saliency map fusion and MobileNetv2. The detection speed is increased by over 50%, while the model size is reduced by 58%. The results demonstrate that the proposed method provides a compromise model, which has application potential in UAV-borne detection tasks.},
keywords={Object detection;Computational modeling;Feature extraction;Task analysis;Lighting;Neural networks;Image segmentation;Combinational neural networks;model compression;saliency map;thermal image},
doi={10.1109/TGRS.2020.3029945},
ISSN={1558-0644},
month={Aug},}
@ARTICLE{9248998,
author={Li, Xianghui and Li, Xinde and Pan, Hong},
journal={IEEE Access}, title={Multi-Scale Vehicle Detection in High-Resolution Aerial Images With Context Information},
year={2020},
volume={8},
number={},
pages={208643-208657},
abstract={Recently, unmanned aerial vehicles (UAV) are widely used in many fields due to the low cost and high flexibility. One of the most popular applications of UAV is vehicle detection in aerial images which plays an important role in traffic surveillance and urban planning. Although, many deep learning based detectors have achieved state-of-the-art (SOTA) performance in natural images, the significant variation in object scales caused by the altitude change of the UAV platform brings great challenges to these detectors for precise localization of vehicles in aerial images. To improve the detection performance for vehicles with different scales, we propose a novel detection algorithm which consists of three stages. In the first stage, to reduce the distortion of vehicles during image resizing and keep more information of aerial images, we utilize an image cropping strategy to divide the image into two patches. In the second stage, we combine the original image and two patches into a batch and detect vehicles with a Convolutional Neural Network (CNN). For feature representation in our detector, we propose Scale-specific Prediction to strengthen the multi-scale features of vehicles with context information. In the final stage, to fuse detections and suppress false alarms, we propose an Outlier-Aware Non-Maximum Suppression. Extensive experiments are conducted to demonstrate the superiority of the proposed algorithm by comparison with other SOTA solutions.},
keywords={Fuses;Vehicle detection;Urban planning;Detectors;Traffic control;Feature extraction;Unmanned aerial vehicles;Vehicle detection;scale-specific prediction;single shot detector;high-resolution aerial images},
doi={10.1109/ACCESS.2020.3036075},
ISSN={2169-3536},
month={},}
@INPROCEEDINGS{9236821,
author={Cao, Yu and Liang, Hongyu and Fang, Yujie and Peng, Wenliang},
booktitle={2020 IEEE 3rd International Conference on Information Systems and Computer Aided Education (ICISCAE)}, title={Research on Application of Computer Vision Assist Technology in High-precision UAV Navigation and Positioning},
year={2020},
volume={},
number={},
pages={453-458},
abstract={Traditional UAV human-computer interaction requires specialized equipment and professional training. Convenient and novel interaction methods are often more popular. Using ordinary cameras, the UAV gesture control system based on computer vision and deep learning is studied. Under this background, the paper proposes a new method for the navigation information extraction of UAV autonomous landing terminal based on monocular vision/INS integrated navigation; it only needs to detect two feature points on the runway and then combine the attitude of the inertial navigation system Angle information, you can directly calculate the position vector of the aircraft relative to the airport; because the straight line has obvious observability, for the feature points that are difficult to extract, you can detect the two runway edge lines and a landing threshold line, and then take the intersection of the threshold line and the edge of the runway is used as the feature point; the algorithm is deduced in detail based on the geometric principle of imaging. Finally, the landing experiment shows that the extraction and conversion of the method is feasible.},
keywords={Deep learning;Computer vision;Target recognition;Image edge detection;Feature extraction;Cameras;Aircraft navigation;Computer vision;landing navigation;feature points;route planning;drone navigation system},
doi={10.1109/ICISCAE51034.2020.9236821},
ISSN={},
month={Sep.},}
@INPROCEEDINGS{9445927,
author={Dong, Runze and Wang, Buhong and Cheng, Tiaohao},
booktitle={2021 International Conference on Communications, Information System and Computer Engineering (CISCE)}, title={Deep Learning Based Robust Beamforming for UAV Communication System},
year={2021},
volume={},
number={},
pages={771-776},
abstract={Unmanned aerial vehicles (UAVs) have shown its application potentiality in communication system because of its inherent mobility and ease of organization. In this paper, we develop a robust beamforming method for an UAV communication system by deep learning (DL), in which a eavesdropping UAV attempts to wiretap the confidential transmission. Specifically, by modeling the legitimate channel and eavesdropping channel undergo Rician fading, a robust beamforming neural network (RBNN) is trained to maximize the average secrecy rate. Both perfect and imperfect channel state information (CSI) are used to train the RBNN in the off-line train stage, then all weights are fixed for on-line deployment stage with only imperfect CSI. Simulation results verify that the proposed DL based beamforming method outperforms benchmark beamforming methods with imperfect legitimate CSI and eavesdropper CSI, and generalization ability of the trained RBNN is shown. Last but not least, the proposed beamforming method is still effective while the eavesdropper CSI is completely unknown.},
keywords={Deep learning;Array signal processing;Communication systems;Simulation;Neural networks;Rician channels;Organizations;UAV;communication;beamforming;DL;secrecy rate maximization},
doi={10.1109/CISCE52179.2021.9445927},
ISSN={},
month={May},}
@INPROCEEDINGS{8444340,
author={Chen, Xudong and Lin, Feng and Abdul Hamid, Mohamed Redhwan and Teo, Swee Huat and Phang, Swee King},
booktitle={2018 IEEE 14th International Conference on Control and Automation (ICCA)}, title={Real-Time Landing Spot Detection and Pose Estimation on Thermal Images Using Convolutional Neural Networks},
year={2018},
volume={},
number={},
pages={998-1003},
abstract={This paper presents a robust, accurate and real-time approach to detect landing spot position and orientation information using deep convolutional neural networks and image processing technique on thermal images. The proposed novel algorithm pipeline consists of two steps: ledge detection and orientation information extraction. The extracted pose information of the landing spot from thermal images could be used to facilitate autonomous operations of unmanned aerial vehicles (UAVs) in both of day and night time. In order to land on the narrow and long ledge, UAV requires accurate orientation information of the ledge. Moreover, the method is scale and rotation invariant and also robust to occlusion in certain special and unexpected situations. Our algorithm runs at 20 frames per second on NVIDIA GTX 1080Ti GPU with the real flight thermal image dataset captured by T-Lion UAV developed by Temasek Laboratories@NUS.},
keywords={Image segmentation;Feature extraction;Real-time systems;Convolutional neural networks;Unmanned aerial vehicles;Proposals;Information retrieval},
doi={10.1109/ICCA.2018.8444340},
ISSN={1948-3457},
month={June},}
@INPROCEEDINGS{7438511,
author={da Silva, Wanessa and Shiguemori, Elcio Hideiti and Vijaykumar, Nandamudi Lankalapalli and Fraga De Campos Velho, Haroldo},
booktitle={2015 9th International Conference on Sensing Technology (ICST)}, title={Estimation of UAV position with use of thermal infrared images},
year={2015},
volume={},
number={},
pages={828-833},
abstract={The use of Unmanned Aerial Vehicles has increased and become indispensable for many applications where human intervention is exhausting, dangerous or expensive. With this increase in UAV employment, autonomous navigation has been the subject of several studies. For this purpose, several systems have been used, among them, image processing, that is an alternative to the Global Positioning System. The employment of images in an autonomous navigation system has challenges, among them, the night flight. In this context, this article presents a study to estimate the UAV's geographical position with use of infrared images. From this image, a search is made in a georeferenced satellite image in the visible band. To automatically register between aerial and satellite images, edge information extracted by Artificial Neural Networks are used. The artificial neural network is automatically configured with use of Multiple Particle Collision Algorithm. Furthermore, the estimation of the UAV's position is obtained by calculating the correlation index. The results are promissing to be employed in night autonomous navigation.},
keywords={Satellites;Image edge detection;Satellite broadcasting;Artificial neural networks;Thermal sensors;Neurons},
doi={10.1109/ICSensT.2015.7438511},
ISSN={2156-8073},
month={Dec},}
@INPROCEEDINGS{9693740,
author={Gong, Jianye and Ma, Yajie and Jiang, Bin},
booktitle={2021 CAA Symposium on Fault Detection, Supervision, and Safety for Technical Processes (SAFEPROCESS)}, title={Minimum-Eigenvalue-Based Adaptive Fault-Tolerant Containment Control for Heterogeneous Multiagent Systems With Actuator Faults},
year={2021},
volume={},
number={},
pages={1-6},
abstract={This paper presents an adaptive fault-tolerant containment control scheme for a set of heterogeneous multiagent systems composed of multiple leader unmanned aerial vehicles (UAVs) and follower unmanned ground vehicles (UGVs) with actuator faults under a directed topology. The adaptive fault-tolerant controller is designed for the position subsystem of each leader UAV such that all leader can track their desired trajectories. Further, based on minimum eigenvalue approach, the distributed adaptive fault-tolerant containment controller is designed for each follower UGV to guarantee that all followers converge to the dynamic convex hull spanned by positions of the leader UAVs. The neural networks approximation is employed to estimate the unknown parameters and actuator faults. A simulation example is used to show that the containment errors converge to a small adjustable neighborhood of the origin.},
keywords={Fault tolerance;Actuators;Simulation;Fault tolerant systems;Autonomous aerial vehicles;Trajectory;Topology;fault-tolerant control;heterogeneous multiagent systems;containment control},
doi={10.1109/SAFEPROCESS52771.2021.9693740},
ISSN={},
month={Dec},}
@INPROCEEDINGS{6889370,
author={Tan, Fuxiao and Liu, Derong and Guan, Xinping and Luo, Bin},
booktitle={2014 International Joint Conference on Neural Networks (IJCNN)}, title={Unmanned aerial vehicles (UAV) heading optimal tracking control using online kernel-based HDP algorithm},
year={2014},
volume={},
number={},
pages={2683-2689},
abstract={UAV can work in places that are dangerous, or not easy to reach for humans. However, due to active control and operating difficulties, it is still a challenge to develop fully autonomous flight in complex environments. This paper applies a novel heuristic dynamic programming for the UAV heading optimal tracking controller design, using kernel-based heuristic dynamic programming (KHDP). Kernel-based HDP is developed by integrating kernel methods and approximately linear dependence (ALD) analysis with the critic learning of HDP algorithm. Compared with conventional HDP where neural networks are widely used and their features were manually designed, the proposed algorithm can obtain better generalization capability and learning efficiency through applying the sparse kernel machine into the critic learning process of HDP algorithm. Simulation and experimental results of UAV heading optimal tracking control problems demonstrate the effectiveness of the proposed kernel-based HDP algorithm.},
keywords={Kernel;Algorithm design and analysis;Heuristic algorithms;Equations;Vectors;Approximation algorithms;Mathematical model},
doi={10.1109/IJCNN.2014.6889370},
ISSN={2161-4407},
month={July},}
@INPROCEEDINGS{9560830,
author={Papaioannidis, Christos and Mademlis, Ioannis and Pitas, Ioannis},
booktitle={2021 IEEE International Conference on Robotics and Automation (ICRA)}, title={Autonomous UAV Safety by Visual Human Crowd Detection Using Multi-Task Deep Neural Networks},
year={2021},
volume={},
number={},
pages={11074-11080},
abstract={Camera-equipped UAVs, or drones, are increasingly employed in a wide range of applications. Thus, ensuring their safe flight in areas containing people is a top priority. In this paper, a deep neural network-based method is proposed for the task of visual human crowd detection from UAV footage, allowing a drone to rapidly extract semantic segmentation maps from captured video frames during flight. These maps can be exploited (e.g., by a path planner) to define no-fly zones over, or near human crowds and, hence, enhance UAV flight safety. To this end, a novel neural architecture for binary (crowd/non- crowd) semantic segmentation from single RGB images is proposed, based on Convolutional Neural Networks (CNNs). It consists of a semantic segmentation and an image-to-image translation (I2I) neural branch. The overall network is trained using a novel multi-task loss function that addresses both tasks by processing the output of the corresponding branch. During inference, information flows across branches through additional skip synapses to further assist the crowd detection task. In order to evaluate the proposed method, we introduce a real and a synthetic human crowd RGB image dataset. The proposed method outperforms previous aerial crowd detection methods by a large margin and without any post-processing. Moreover, it demonstrates increased generalization ability, while running at real-time and near-real-time speeds on a ground computer and on embedded AI hardware, respectively.},
keywords={Image segmentation;Visualization;Semantics;Computer architecture;Real-time systems;Safety;Convolutional neural networks},
doi={10.1109/ICRA48506.2021.9560830},
ISSN={2577-087X},
month={May},}
@ARTICLE{9691814,
author={Saini, Nitin and Bonetto, Elia and Price, Eric and Ahmad, Aamir and Black, Michael J.},
journal={IEEE Robotics and Automation Letters}, title={AirPose: Multi-View Fusion Network for Aerial 3D Human Pose and Shape Estimation},
year={2022},
volume={7},
number={2},
pages={4805-4812},
abstract={In this letter, we present a novel markerless 3D human motion capture (MoCap) system for unstructured, outdoor environments that uses a team of autonomous unmanned aerial vehicles (UAVs) with on-board RGB cameras and computation. Existing methods are limited by calibrated cameras and off-line processing. Thus, we present the first method (AirPose) to estimate human pose and shape using images captured by multiple extrinsically uncalibrated flying cameras. AirPose itself calibrates the cameras relative to the person instead of relying on any pre-calibration. It uses distributed neural networks running on each UAV that communicate viewpoint-independent information with each other about the person (i.e., their 3D shape and articulated pose). The person’s shape and pose are parameterized using the SMPL-X body model, resulting in a compact representation, that minimizes communication between the UAVs. The network is trained using synthetic images of realistic virtual environments, and fine-tuned on a small set of real images. We also introduce an optimization-based post-processing method (AirPose$^{+}$) for offline applications that require higher MoCap quality. We make our method’s code and data available for research at https://github.com/robot-perception-group/AirPose. A video describing the approach and results is available at https://youtu.be/xLYe1TNHsfs.},
keywords={Cameras;Three-dimensional displays;Shape;Autonomous aerial vehicles;Neural networks;Feature extraction;Residual neural networks;Aerial systems;deep learning for visual perception;datasets for human motion;human detection and tracking;perception and autonomy;sensor fusion},
doi={10.1109/LRA.2022.3145494},
ISSN={2377-3766},
month={April},}
@INPROCEEDINGS{9605390,
author={Araújo, Matheus S. and Andrade, João P. B. and Da Silva Junior, Thayanne F. and Da Costa, Leonardo F. and Junior, Raimundo J. C. F. and Melo, Gabriel F. L. and Da Silva, Douglas A. and De Campos, Gustavo A. L.},
booktitle={2021 Latin American Robotics Symposium (LARS), 2021 Brazilian Symposium on Robotics (SBR), and 2021 Workshop on Robotics in Education (WRE)}, title={Cooperative Observation of Malicious Targets in a 3D Urban Traffic Environment Using UAVs},
year={2021},
volume={},
number={},
pages={60-65},
abstract={The Cooperative Multi-Robot Observation of Multiple Moving Targets (CMOMMT) considers two types of robots, observers and targets, in a partially observable 2D environment. The observers’ task is to monitor the target robots under a limited radial range of the sensor, minimizing the total time the targets escape observation. The Cooperative Target Observation (CTO), a variant of the CMOMMT problem, considers the environment to be fully observable, where target agents cooperate with observers by reporting their locations. These problems are at the center of many issues that occur in surveillance situations. This work proposes an approach to the extended CTO problem. We call the CTO-URBAN3D problem: a simplified urban traffic scenario in three dimensions for the CTO, considering that suspect transport like cars or buses are targets and Unmanned Aerial Vehicles (UAVs) are observers agents. The approach employs genetic algorithms and recurrent deep neural networks to improve the performance of transport-targets robots and an observer organizational behavior hierarchical consolidated in the CTO literature for UAV-observers robots. The first results were promising, as the average number of transport-targets evasion increased, considering the other approaches to the problem. It raises the need to research new organizations for UAV robots.},
keywords={Solid modeling;Three-dimensional displays;Robot kinematics;Surveillance;Neural networks;Urban areas;Organizations;Cooperative Target Observation;Urban Traffic Monitoring;Genetic Algorithm;Deep Neural Networks},
doi={10.1109/LARS/SBR/WRE54079.2021.9605390},
ISSN={2643-685X},
month={Oct},}
@INPROCEEDINGS{9465325,
author={Mirzaei, Mehrdad and Kosari, Amirreza and Maghsoudi, Hossein},
booktitle={2021 IEEE International Conference on Automation/XXIV Congress of the Chilean Association of Automatic Control (ICA-ACCA)}, title={Optimal Path Planning For Two UAVs in a Pursuit-Evasion Game},
year={2021},
volume={},
number={},
pages={1-7},
abstract={In this paper a path planning technique will be introduced for the unmanned aerial vehicles (UAV) fly at low altitude using a synthetic approach based on game theory and artificial neural networks. The low altitude pursuit-evasion maneuver of two UAVs - is defined based on an optimal control approach. Moreover, it has been sought to utilize optimal control rules and Differential Games theory to calculate the most favorable trajectories for both UAVs - one as the pursuer and the other as an evader. Since producing the optimal trajectories through solving the related equations may be a time-consuming trend, an artificial neural network is utilized to predict the flyable trajectories. The multilayer perceptron networks are trained using a set of trajectories obtained based on the differential game theory approach and could locate the position where the evader is captured. Hence, choices could made in real times. Consequently, the comparison of neural network results with accurate data obtained previously in the optimal control section confirms the accuracy and performance of the proposed method.},
keywords={Optimal control;Games;Differential games;Artificial neural networks;Multilayer perceptrons;Market research;Unmanned aerial vehicles;Path Planning;Neural Network;Differential Game Theory;Optimal Control;Multilayer Perceptron},
doi={10.1109/ICAACCA51523.2021.9465325},
ISSN={},
month={March},}
@ARTICLE{9585472,
author={Zhu, Lingzhi and Zhang, Shuning and Chen, Kuiyu and Chen, Si and Wang, Xun and Wei, Dongxu and Zhao, Huichang},
journal={IEEE Transactions on Geoscience and Remote Sensing}, title={Low-SNR Recognition of UAV-to-Ground Targets Based on Micro-Doppler Signatures Using Deep Convolutional Denoising Encoders and Deep Residual Learning},
year={2022},
volume={60},
number={},
pages={1-13},
abstract={The rapid development of flight control technology has made unmanned aerial vehicles (UAVs) widely used in high-precision strikes on the battlefield. The premise of this is to achieve accurate target recognition using UAV-based radars. Aiming at three typical ground targets, including pedestrians, wheeled vehicles, and tracked vehicles, the micro-Doppler modulation caused by the random vibration of the UAV is analyzed in this article for the first time. To improve the recognition accuracy under low signal-to-noise ratios (SNRs), Doppler signals are transformed into time–frequency images, and a deep convolutional denoising encoder (DCDE) is designed to effectively remove the noise without suppressing micro-Doppler characteristics. To avoid the complicated micro-Doppler feature extraction, deep residual learning that can reduce the burden of network training and gain higher learning efficiency compared with traditional deep convolutional neural networks (DCNNs) is adopted. Recognition results under various occasions using denoised micro-Doppler images and designed residual learning network indicate that the proposed method has higher precision and better robustness than current methods. Even when the SNR is only −16 dB, the overall recognition accuracy still exceeds 90%.},
keywords={Doppler effect;Target recognition;Radar;Feature extraction;Modulation;Vibrations;Noise reduction;Deep convolutional denoising encoder (DCDE);deep residual learning;low-signal-to-noise-ratio (SNR) recognition;micro-Doppler;unmanned aerial vehicle (UAV)-to-ground targets},
doi={10.1109/TGRS.2021.3123109},
ISSN={1558-0644},
month={},}
@INPROCEEDINGS{8909502,
author={Fikri, Moh Yanni and Azzarkhiyah, Khafid and Firdaus, Muhammad Juan Al and Winarto, Tommy Andreas and Syai’in, Mat and Adhitya, Ryan Yudha and Endrasmono, Joko and Rahmat, Mohammad Basuki and Setiyoko, Annas Singgih and Fathulloh and Zuliari, Efrita Arfah and Budianto, Agus and Soeprijanto, Adi},
booktitle={2019 International Symposium on Electronics and Smart Devices (ISESD)}, title={Clustering green openspace using UAV (Unmanned Aerial Vehicle) with CNN (Convolutional Neural Network)},
year={2019},
volume={},
number={},
pages={1-5},
abstract={The latest in unmanned aerial vehicles (UAVs) and associated sensing systems make these increasingly attractive platforms to the remote sensing community. A large number of spatial details contained in these images opens the door for advanced monitoring applications. In this paper, we use this cost-effective and attractive technology for the automatic detection of green open spaces. Given a UAV image of trees acquired, then, we analyze these Convolutional Neural Networks (CNN) points of the prior classifier trained on a set of trees and no trees points. As output, CNN will mark each detected tree by super pixel. Then, in order to capture the shape of each tree, we propose to merge this pixel-level segmentation with a method based active contour on the Color threshold. Finally, we further analyze the texture of regions with pixel-level segmentation and use summing pixel to distinguish trees from other vegetation. Experimental results obtained in UAV images from extensive calculations using the program that has been made and the existing provisions get a result of error of 7.256% on the first trial, the second experiment is 5.156%, and the third experiment is 3.126%.},
keywords={Convolution;Image color analysis;Vegetation;Image segmentation;Training;Kernel;Green products;Unmanned Aerial Vehicles;Convolutional Neural Network;super pixel},
doi={10.1109/ISESD.2019.8909502},
ISSN={},
month={Oct},}
@INPROCEEDINGS{7162287,
author={Ren, Hao and Yu, Yao and Zhang, Lan and Sun, Changyin},
booktitle={The 27th Chinese Control and Decision Conference (2015 CCDC)}, title={Adaptive neural control for consensus of multiple UAVs with heterogeneous matching uncertainties under a directed graph},
year={2015},
volume={},
number={},
pages={2205-2210},
abstract={In this paper, the distributed consensus problem is investigated for multiple UAVs systems with nonlinear uncertainty and bounded disturbances under a directed graph. It is assumed that aerodynamic characteristics of UAV are nonlinear uncertainties, and the output of the leader is time-varying. UAV dynamics model can be divided into two parts, including completely known and the unknown nonlinear function. An adaptive neural controller is designed with backstepping design method. Neural networks are used as the function approximation technique to compensate unknown nonlinear terms. From the Lyapunov function, it is shown that the consensus error can converge to any small neighborhood of the origin with an arbitrary convergence rate. Simulations verify the effectiveness of the proposed protocol.},
keywords={Artificial neural networks;Function approximation;Protocols;Uncertainty;Multi-agent systems;Aerodynamics;multiple UAVs systems;consensus;uncertainty;adaptive neural control;graph theory;backstepping},
doi={10.1109/CCDC.2015.7162287},
ISSN={1948-9447},
month={May},}
@INPROCEEDINGS{9600024,
author={Cereda, Elia and Ferri, Marco and Mantegazza, Dario and Zimmerman, Nicky and Gambardella, Luca M. and Guzzi, Jérôme and Giusti, Alessandro and Palossi, Daniele},
booktitle={2021 17th International Conference on Distributed Computing in Sensor Systems (DCOSS)}, title={Improving the Generalization Capability of DNNs for Ultra-low Power Autonomous Nano-UAVs},
year={2021},
volume={},
number={},
pages={327-334},
abstract={Deep neural networks (DNNs) are becoming the first-class solution for autonomous unmanned aerial vehicles (UAVs) applications, especially for tiny, resource-constrained, nano-UAVs, with a few tens of grams in weight and subten centimeters in diameter. DNN visual pipelines have been proven capable of delivering high intelligence aboard nanoUAVs, efficiently exploiting novel multi-core microcontroller units. However, one severe limitation of this class of solutions is the generalization challenge, i.e., the visual cues learned on the specific training domain hardly predict with the same accuracy on different ones. Ultimately, it results in very limited applicability of State-of-the-Art (SoA) autonomous navigation DNNs outside controlled environments. In this work, we tackle this problem in the context of the human pose estimation task with a SoA vision-based DNN [1]. We propose a novel methodology that leverages synthetic domain randomization by applying a simple but effective image background replacement technique to augment our training dataset. Our results demonstrate how the augmentation forces the learning process to focus on what matters most: the pose of the human subject. Our approach reduces the DNN’s mean square error — vs. a non-augmented baseline — by up to 40%, on a never-seen-before testing environment. Since our methodology tackles the DNN’s training stage, the improved generalization capabilities come at zero-cost for the computational/memory burdens aboard the nano-UAV.},
keywords={Training;Visualization;Simultaneous localization and mapping;Pipelines;Pose estimation;Mean square error methods;Unmanned aerial vehicles;Deep Neural Network;Domain Generalization;Autonomous UAVs;Nano-drones},
doi={10.1109/DCOSS52077.2021.00060},
ISSN={2325-2944},
month={July},}
@ARTICLE{9492907,
author={Naren, N. and Chamola, Vinay and Baitragunta, Sainath and Chintanpalli, Ananthakrishna and Mishra, Puneet and Yenuganti, Sujan and Guizani, Mohsen},
journal={IEEE Internet of Things Magazine}, title={IoMT and DNN-Enabled Drone-Assisted Covid-19 Screening and Detection Framework for Rural Areas},
year={2021},
volume={4},
number={2},
pages={4-9},
abstract={Providing rapid testing and proper treatment has become highly challenging due to the rapid and highly unpredictable spread of the coronavirus disease (COVID-19). In most developing countries, rural areas lack adequate medical facilities and medical staff for effective diagnosis and treatment. Recently, there have been several technological advancements across various engineering disciplines such as the Internet of Things, unmanned aerial vehicles (UAVs) or drones, deep neural networks (DNNs), and intelligent robots. This work proposes a prototype that integrates these technologies to develop a payload deployable in a drone to help in providing rapid testing and healthcare. The proposed UAV prototype combines secure patient authentication, an automated disinfection system, and medical sensors as part of the UAV payload. It uses a DNN model for real-time COVID-19 detection. It uses intelligent flight path planning, operational management, battery recharge planning, disinfectant refilling, and strategic location planning to quickly disseminate testing kits and essential medical services to remote locations without direct human involvement.},
keywords={COVID-19;Drones;Medical services;Path planning;Medical treatment;Internet of Medical Things;Medical diagnostic imaging},
doi={10.1109/IOTM.0011.2100053},
ISSN={2576-3199},
month={June},}
@INPROCEEDINGS{9014313,
author={Duong, Trung Q. and Nguyen, Long D. and Tuan, Hoang Duong and Hanzo, Lajos},
booktitle={2019 IEEE Global Communications Conference (GLOBECOM)}, title={Learning-Aided Realtime Performance Optimisation of Cognitive UAV-Assisted Disaster Communication},
year={2019},
volume={},
number={},
pages={1-6},
abstract={In this work, we propose efficient optimisation methods for relay-assisted unmanned aerial vehicles (UAVs) in cognitive radio networks (CRNs) to cope with the network destruction in the event of a natural disaster. Our model considers real- time optimisation in embedded UAV-CRN communication involved in recovering wireless communication services. Particularly, by conceiving advanced optimisation techniques and training deep neural networks, our solutions become capable of supporting real-time applications in disaster recovery scenarios. Our algorithms impose low computational complexity, hence, have a low execution time in solving real- time optimisation problems. Numerical results demonstrate the benefits of our approaches proposed for UAV-CRN.},
keywords={Optimization;Interference;Quality of service;Real-time systems;Unmanned aerial vehicles;Cognitive radio},
doi={10.1109/GLOBECOM38437.2019.9014313},
ISSN={2576-6813},
month={Dec},}
@INPROCEEDINGS{9401928,
author={Bocanegra, Maria Gonzalez and Haddad, Rami J.},
booktitle={SoutheastCon 2021}, title={Convolutional Neural Network-Based Disaster Assessment Using Unmanned Aerial Vehicles},
year={2021},
volume={},
number={},
pages={1-6},
abstract={Natural disasters are recurrent weather phenomena whose occurrence has increased worldwide in the past few decades. These disasters cause devastating effects on transportation routes by causing significant damage and obstruction on frequently traveled roads. This research focuses on developing an autonomous network of unmanned aerial vehicles (UAVs) for transportation disaster management using convolutional neural networks (CNNs). The autonomous network of UAVs will allow first responders to optimize their rescue plans by providing relevant information on inaccessible roads. The autonomous UAV system development will increase the affected regions' recovery rate by identifying blocked transportation routes and associating them with their corresponding locations to update the virtual map in real-time. Live footage from the unmanned aerial vehicles is fed to ground control, where the CNN classifies the type of damage encountered and then updates a virtual map through the ArcGIs software. Preliminary results of the classification models such as AlexNet show average accuracy of 74.07%. Furthermore, transfer learning and cross-validation techniques were applied to the CNN models to obtain high confidence levels due to the small dataset size used to train and test the CNNs. To choose the best CNN model, a quantitative analysis was performed to measure the statistical precision, statistical recall, and F1 score on each model to optimize the classification.},
keywords={Analytical models;Statistical analysis;Roads;Transfer learning;Transportation;Disaster management;Unmanned aerial vehicles;CNN;Natural Disaster;Optimization;Cross Validation;Transfer Learning;Image Classification;Network Architecture;Statistical Recall;Statistical Precision;Deep Learning;Training Parameters;ArcGIS;Python},
doi={10.1109/SoutheastCon45413.2021.9401928},
ISSN={1558-058X},
month={March},}
@INPROCEEDINGS{8784844,
author={Al-Mahasneh, Ahmad Jobran and Anavatti, Sreenatha G and Ferdaus, Meftahul and Garratt, Matthew A},
booktitle={2019 IEEE International Conference on Industry 4.0, Artificial Intelligence, and Communications Technology (IAICT)}, title={Adaptive Neural Altitude Control and Attitude Stabilization of a Hexacopter with Uncertain Dynamics},
year={2019},
volume={},
number={},
pages={44-49},
abstract={Unmanned Aerial Vehicles (UAVs) are recently attracting significant research attention due to their potential applications in many fields. Hexacopter UAV offers higher payloads handling and faults tolerance than a quadcopter but its control is a demanding task. In this paper, an adaptive Neural Networks (NN) controller is proposed for altitude tracking and attitude stabilization of a hexacopter UAV with uncertain dynamics. The controller design, simulation and robustness against gust disturbances are discussed. Also, the controller performance is compared with a standard Filtered-Proportional-Derivative-Integrator (FPID) controller for different control scenarios.},
keywords={Uncertainty;Attitude control;Aerodynamics;Conferences;Industries;Artificial intelligence;Communications technology;Adaptive control;Hexacopter;altitude control;neural control;unmanned aerial vehicles},
doi={10.1109/ICIAICT.2019.8784844},
ISSN={},
month={July},}
@ARTICLE{9163143,
author={Yu, Ziquan and Zhang, Youmin and Jiang, Bin and Fu, Jun and Jin, Ying and Chai, Tianyou},
journal={IEEE Transactions on Systems, Man, and Cybernetics: Systems}, title={Composite Adaptive Disturbance Observer-Based Decentralized Fractional-Order Fault-Tolerant Control of Networked UAVs},
year={2022},
volume={52},
number={2},
pages={799-813},
abstract={This article considers the decentralized fractional-order fault-tolerant control problem for unmanned aerial vehicles (UAVs) against wind disturbances and actuator faults in a directed communication network. A new composite adaptive disturbance observer-based decentralized fractional-order fault-tolerant control (CADOB-DFO-FTC) scheme, which incorporates fractional-order (FO) sliding-mode surfaces, nonlinear disturbance observers (NDOs), fuzzy wavelet neural networks (FWNNs), and robust controllers, is developed to achieve the attitude tracking control of networked UAVs in a decentralized way. Based on the FO sliding-mode surfaces, the NDOs are first developed to estimate the lumped uncertainties due to the aerodynamic parameter perturbations, wind disturbances, and actuator faults. Then, adaptive FWNNs with updating weighting matrices, mean vectors, and deviation vectors are constructed to effectively attenuate the adverse effects induced by the NDO estimation errors. Furthermore, to compensate the FWNN approximation errors, robust controllers are integrated into the developed control scheme to enhance the approximation abilities. It is shown that by using Lyapunov methods, all UAVs can track their attitude references. Finally, comparative simulation results are presented to demonstrate the effectiveness of the proposed method.},
keywords={Aerodynamics;Uncertainty;Actuators;Perturbation methods;Calculus;Fault tolerance;Fault tolerant systems;Decentralized control;fault-tolerant control (FTC);fractional-order (FO) control;fuzzy wavelet neural network (FWNN);nonlinear disturbance observer (NDO);unmanned aerial vehicles (UAVs);wind disturbances},
doi={10.1109/TSMC.2020.3010678},
ISSN={2168-2232},
month={Feb},}
@INPROCEEDINGS{9417352,
author={Aksan, Yasin and Yuksel, Melda and Ozbayoglu, Ahmet},
booktitle={2021 IEEE Wireless Communications and Networking Conference (WCNC)}, title={Channel Characterization for Aircraft Integrated Antennas via Machine Learning},
year={2021},
volume={},
number={},
pages={1-6},
abstract={Wireless communication with unmanned aerial vehicles (UAVs) will become an integral part of future wireless communication systems. In UAVs real-time data transfer is very critical because UAVs need to be controlled from the ground and their data is also transferred in real time. However, aircraft antennas are prone to airframe shadowing. Aircraft surfaces, on which antennas are placed, obscure the main line-of-sight path. In addition, losses used in link budget analyses show great variability in real time. Therefore, observed end-to-end channels, including all impairments, are in general quite different from theoretical calculations in practice. In this work an end-to-end channel link budget, including all effects, is modelled by applying machine learning methods on measured data obtained during past flights. It is observed that ensemble bagged trees (EBT) and exponential Gaussian process regression (GPR) provide the two best results. Pre-processing data and utilizing raw data are also compared. EBT and exponential GPR can predict the amount of end-to-end losses with 7.49% and 8.07% sensitivity respectively using processed data. When raw data is used as input to the EBT method, it can predict the amount of end-to-end loss with a sensitivity of 2.79%, while a theoretical prediction error is 21.9%.},
keywords={Wireless communication;Sensitivity;Machine learning;Gaussian processes;Real-time systems;Unmanned aerial vehicles;Aircraft;Airframe shadowing;channel characterization;ensemble bagged trees;exponential Gaussian process regression;link budget analysis},
doi={10.1109/WCNC49053.2021.9417352},
ISSN={1558-2612},
month={March},}
@INPROCEEDINGS{7402558,
author={Bai, He and Cook, Kevin and Yu, Huili and Ingersoll, Kyle and Beard, Randy and Seppi, Kevin and Avadhanam, Sharath},
booktitle={2015 54th IEEE Conference on Decision and Control (CDC)}, title={Improving cooperative tracking of an urban target with target motion model learning},
year={2015},
volume={},
number={},
pages={2347-2352},
abstract={Tracking a ground urban target with multiple unmanned aerial vehicles (UAVs) is a challenging problem due to cluttered urban environments and coordination of nonholonomic UAV motion. Our previous work has demonstrated in simulation that machine learning can be used in such an environment to learn a model of target motion and thereby improve tracking performance. We extend this previous work by creating a more realistic simulation using road network and building height data extracted from downtown San Diego. We demonstrate effectiveness of target motion model learning in the new simulation environment. Additionally, we demonstrate performance improvement by extending the algorithm used to coordinate the UAVs for tracking the urban target.},
keywords={Target tracking;Path planning;Predictive models;Cities and towns;Buildings;Optimization},
doi={10.1109/CDC.2015.7402558},
ISSN={},
month={Dec},}
@INPROCEEDINGS{9685990,
author={Shehzad, Muhammad K. and Rose, Luca and Assaad, Mohamad},
booktitle={2021 IEEE Global Communications Conference (GLOBECOM)}, title={RNN-Based Twin Channel Predictors for CSI Acquisition in UAV-Assisted 5G+ Networks},
year={2021},
volume={},
number={},
pages={1-6},
abstract={Unmanned aerial vehicles (UAVs) evolution has gained an unabated interest for the use in several applications, such as agriculture, aerial surveillance, goods delivery, disaster recovery, intelligent transportation. The main features of this technology are high coverage, strong line-of-sight (LoS) links, promising throughput, cost-effective and flexible deployment. Currently, the Third Generation Partnership Project (3GPP) is working on the specification of release-17 (R-17) new radio (NR) for non-terrestrial networks (NTN). Therefore, owing to the drastic increase of UAV technology, in this paper, we propose channel state information (CSI) compression and its recovery with the aid of machine learning (ML)-based twin channel predictors. Due to the characteristic of gaining higher LoS communication paths in UAV network, the proposed strategy can bring potential benefits such as over-the-air (OTA)-overhead reduction, minimizing mean-squared-error (MSE) of a channel and maximizing precoding gain. Simulation-based results corroborate the validity of the proposed strategy, which can reap benefits in multiple factors.},
keywords={Surveillance;Precoding;Conferences;Neural networks;Transportation;Machine learning;Autonomous aerial vehicles;ML;CSI prediction;CSI compression;CSI reporting;MIMO;recurrent neural network (RNN);UAVs;5G/6G},
doi={10.1109/GLOBECOM46510.2021.9685990},
ISSN={},
month={Dec},}
@INPROCEEDINGS{9594202,
author={Osman, Anas and Alijani, Morteza},
booktitle={2021 26th International Conference on Automation and Computing (ICAC)}, title={Energy-Efficient Techniques for UAVs in Communication-based Applications},
year={2021},
volume={},
number={},
pages={1-6},
abstract={Unmanned Aerial Vehicles (UAVs), which are at the forefront of cutting-edge technology, have unmatched potential for pioneering applications in a wide range of disciplines. In particular, in the field of cognitive radio (CR), which is a key aspect in the implementation of the new 5G telecommunication technology. The integration between the drone and CR consolidates the drone’s capabilities at the heart of the remarkably promising Internet-of-Things (IoT) technology supported by CR. The highly dynamic network topologies, weakly networked communication links, reliable line-of-sight (LOS) communication links, and orbital or flight paths are characteristic features of UAV communication compared to terrestrial wireless networks. Nevertheless, the implementation of this system is constrained by several severe challenges, such as energy efficiency, battery power limitation, spectrum handover, propagation channel modeling, routing protocols, security policy, and delay setbacks. In this paper, we consider the impact of energy scarcity faced by the UAV in various CR applications. We also analyze the impact of energy scarcity on communication-based applications and present the general problem of battery limitation. Finally, we give an overview and comparison between recent solutions proposed by researchers both in the field of communication and based on batteries, and consider possible future directions according to the state of the art, such as novel Graph Signal Processing (GSP) and machine learning (ML).},
keywords={Wireless networks;Signal processing algorithms;Signal processing;Tools;Energy efficiency;Routing protocols;Batteries;Unmanned Aerial Vehicles (UAVs);Cognitive Radio (CR);Battery Constraints;Energy Efficiency (EE);5G networks},
doi={10.23919/ICAC50006.2021.9594202},
ISSN={},
month={Sep.},}
@INPROCEEDINGS{9014216,
author={Liu, Xiao and Liu, Yuanwei and Chen, Yue and Wang, Luhan and Lu, Zhaoming},
booktitle={2019 IEEE Global Communications Conference (GLOBECOM)}, title={Machine Learning Aided Trajectory Design and Power Control of Multi-UAV},
year={2019},
volume={},
number={},
pages={1-6},
abstract={A novel framework is proposed for the trajectory design of multiple unmanned aerial vehicles (UAVs) based on the prediction of users' mobility information. The problem of joint trajectory design and power control is formulated for maximizing the instantaneous sum transmit rate while satisfying the rate requirement of users. In an effort to solve this pertinent problem, a three-step approach is proposed which is based on machine learning techniques. Firstly, a multi-agent Q-learning based placement algorithm is proposed for determining the optimal positions of the UAVs based on the initial location of the users. Secondly, in an effort to determine the mobility information of users based on a real dateset, their position data is collected from Twitter to describe the anonymous user- trajectories in the physical world. In the meantime, an echo state network (ESN) based prediction algorithm is proposed for predicting the future positions of users based on the real dataset. Thirdly, a proposed multi-agent Q-learning based algorithm is invoked for predicting the position of UAVs in each time slot based on the movement of users. The algorithm is proved to be able to converge to an optimal state equation. Numerical results are provided to demonstrate that as the size of the reservoir pool increases, the proposed ESN approach improves the prediction accuracy. Finally, we demonstrate that throughput gains of about 17% are achieved.},
keywords={Trajectory;Power control;Twitter;Wireless communication;Throughput;Interference;Unmanned aerial vehicles},
doi={10.1109/GLOBECOM38437.2019.9014216},
ISSN={2576-6813},
month={Dec},}
@INPROCEEDINGS{8451385,
author={Karakostas, Iason and Mademlis, Ioannis and Nikolaidis, Nikos and Pitas, Ioannis},
booktitle={2018 25th IEEE International Conference on Image Processing (ICIP)}, title={UAV Cinematography Constraints Imposed by Visual Target Tracking},
year={2018},
volume={},
number={},
pages={76-80},
abstract={Camera-equipped drones have recently revolutionized aerial cinematography, allowing easy acquisition of impressive footage. Although they are currently manually operated, autonomous functionalities based on machine learning and computer vision are becoming popular. However, the emerging area of autonomous UAV filming has to face several challenges, especially when visually tracking fast and unpredictably moving targets. In the latter case, an important issue is how to determine the shot types that are achievable without risking failure of the 2D visual tracker. This paper studies the constraints imposed to cinematography decision-making during autonomous UAV shooting. It focuses on formalizing and geometrically modelling common target-following UAV motion types, in order to analytically determine the maximum permissible camera focal length (therefore, the range of feasible shot types) for avoiding visual target tracking failure.},
keywords={Cameras;Target tracking;Visualization;Cinematography;Drones;Two dimensional displays;UAV cinematography;shot type;autonomous drones;target tracking},
doi={10.1109/ICIP.2018.8451385},
ISSN={2381-8549},
month={Oct},}
@INPROCEEDINGS{8062740,
author={Yoo, Jaehyun and Lee, Seungjae and Kim, H. Jin and Johansson, Karl H.},
booktitle={2017 IEEE Conference on Control Technology and Applications (CCTA)}, title={Trajectory generation for networked UAVs using online learning for delay compensation},
year={2017},
volume={},
number={},
pages={1941-1946},
abstract={This paper presents a trajectory generation mechanism based on machine learning for a network of unmanned aerial vehicles (UAVs). For delay compensation, we apply an online regression technique to learn a pattern of network-induced effects on UAV maneuvers. Due to online learning, the control system not only adapts to changes to the environment, but also maintains a fixed amount of training data. The proposed algorithm is evaluated on a collaborative trajectory tracking task for two UAVs. Improved tracking is achieved in comparison to a conventional linear compensation algorithm.},
keywords={Delays;Trajectory;Training;Uplink;Downlink;Optimization;Adaptation models},
doi={10.1109/CCTA.2017.8062740},
ISSN={},
month={Aug},}
@INPROCEEDINGS{7487719,
author={Sarkar, Suproteem K. and Das, Jnaneshwar and Ehsani, Reza and Kumar, Vijay},
booktitle={2016 IEEE International Conference on Robotics and Automation (ICRA)}, title={Towards autonomous phytopathology: Outcomes and challenges of citrus greening disease detection through close-range remote sensing},
year={2016},
volume={},
number={},
pages={5143-5148},
abstract={Unmanned aerial vehicles (UAVs) have the potential to significantly impact early detection and monitoring of plant diseases. In this paper, we present preliminary work in developing a UAV-mounted sensor suite for detection of citrus greening disease, a major threat to Florida citrus production. We propose a depth-invariant sensing methodology for measuring reflectance of polarized amber light, a metric which has been found to measure starch accumulation in greening-infected leaves. We describe the implications of adding depth information to this method, including the use of machine learning models to discriminate between healthy and infected leaves with validation accuracies up to 93%. Additionally, we discuss stipulations and challenges of use of the system with UAV platforms. This sensing system has the potential to allow for rapid scanning of groves to determine the spread of the disease, especially in areas where infection is still in early stages, including citrus farms in California. Although presented in the context of citrus greening disease, the methods can be applied to a variety of plant pathology studies, enabling timely monitoring of plant health-impacting scientists, growers, and policymakers.},
keywords={Robot sensing systems;Cameras;Support vector machines;Diseases;Green products;Light emitting diodes;Standards},
doi={10.1109/ICRA.2016.7487719},
ISSN={},
month={May},}
@INPROCEEDINGS{9723671,
author={Konen, Kai and Hecking, Tobias},
booktitle={2021 IEEE Fourth International Conference on Artificial Intelligence and Knowledge Engineering (AIKE)}, title={Increased Robustness of Object Detection on Aerial Image Datasets using Simulated Imagery},
year={2021},
volume={},
number={},
pages={1-8},
abstract={Machine learning-based models for object detection rely on large datasets of labeled images, such as COCO or ImageNet. When models trained on these datasets are applied to aerial images recorded on Unmanned Aerial Vehicles (UAVs), the problem arises that the conditions under which the training images were created (for example, light, altitude, or angle) may be different in the environment where the UAVs are put into practice, leading to failed detections. This problem becomes even more pressing in safety critical applications where failures can have huge negative impacts and also constitutes an obstacle for certification of cognitive components in UAVs. Along a case study on car detection in low-altitude aerial imagery, we show that using, both, artificial and real images for model training has a positive effect on the performance of object detection algorithms when the trained model is applied on images from another domain. Since simulated images are easy to create and object labels are inherently given, the presented approach shows a promising direction for scenarios where adequate datasets are difficult to obtain, as well as for targeted exploration of weak points of object detection algorithms.},
keywords={Knowledge engineering;Conferences;Object detection;Pressing;Autonomous aerial vehicles;Robustness;Safety;Object Detection;Aerial Image Datasets;Simulation;UAVs;YoloV4},
doi={10.1109/AIKE52691.2021.00007},
ISSN={},
month={Dec},}
@INPROCEEDINGS{5747529,
author={de Croon, G.C.H.E. and De Wagter, C. and Remes, B.D.W. and Ruijsink, R.},
booktitle={2011 Aerospace Conference}, title={Sky Segmentation Approach to obstacle avoidance},
year={2011},
volume={},
number={},
pages={1-16},
abstract={The capability to visually discern possible obstacles from the sky would be a valuable asset to a UAV for avoiding both other flying vehicles and static obstacles in its environment. The main contribution of this article is the presentation of a feasible approach to obstacle avoidance based on the segmentation of camera images into sky and non-sky regions. The approach is named the Sky Segmentation Approach (SSA). The central concept is that potentially threatening static obstacles protrude from the horizon line. The main challenge for SSA is automatically interpreting the images robustly enough for use in various environments and fast enough for real-time performance. In order to achieve robust image segmentation, machine learning is applied to a large database of images with many different types of skies. From these images, different types of visual features are extracted, among which most of the features investigated in the literature. In the interest of execution speed and comprehensibility, decision trees are learned to map the feature values at an image location to a classification as sky or non-sky. The learned decision trees are fast enough to allow real-time execution on a Digital Signal Processor: it is run onboard a small UAV at ~ 30 Hz. Experiments in simulation and preliminary experiments on a small UAV show the potential of SSA for achieving robust obstacle avoidance in urban areas.},
keywords={Image segmentation;Feature extraction;Pixel;Cameras;Databases;Decision trees;Training},
doi={10.1109/AERO.2011.5747529},
ISSN={1095-323X},
month={March},}
@INPROCEEDINGS{8663930,
author={Kaidi, Yao and Zhaowei, Ma and Jinhong, Lei and Sibo, Shen and Yulin, Zhu},
booktitle={2018 IEEE 9th International Conference on Software Engineering and Service Science (ICSESS)}, title={Unsupervised Representation Learning Method for UAV's Scene Perception},
year={2018},
volume={},
number={},
pages={323-327},
abstract={In view of the application requirements for UAV in forest rescue and border patrol, this paper takes a single small UAV equipped with visual sensors as the research object. Combined the encoder and decoder structure in the field of deep learning, a deep coding algorithm for scene perception is put forward. Based on the autoencoder, the algorithm achieves the dimension reduction and scene reconstruction by increasing the number of layers in the coding network. Based on the ROS environment, this paper sets up a simulation experiment data acquisition system and verifies the effectiveness of the dimensionality reduction algorithm.},
keywords={Training;Image reconstruction;Data models;Forestry;Decoding;Optimization;Sensors;scene representation;deep autoencoder;UAV perception},
doi={10.1109/ICSESS.2018.8663930},
ISSN={2327-0594},
month={Nov},}
@INPROCEEDINGS{9620998,
author={Akter, Rubina and Golam, Mohtasin and Lee, Jae-Min and Kim, Dong-Seong},
booktitle={2021 International Conference on Information and Communication Technology Convergence (ICTC)}, title={Doppler Radar-based Real-Time Drone Surveillance System Using Convolution Neural Network},
year={2021},
volume={},
number={},
pages={474-476},
abstract={In recent years, the availability of commercial unmanned air vehicles (UAVs) or drones has enormously increased due to their device miniaturization and low cost. However, the abuse of UAVs can lead to serious security threats among civilians that need to be investigated and prevented. To alleviate these threats, this paper presents a residual convolution neural network-based surveillance system for drone detection. The network is designed with the two-dimensional and unit convolution layer to successively deal with the Doppler radar signatures. The network extracts generic features through the regular convolution layer, where the advanced features are extracted by the four blocks of the processing unit. Doppler radar database is available in the Kaggle repository used for performance evaluation of the proposed network. The empirical results demonstrate that the proposed model acquired 95.92% classification accuracy and outperform the other deep learning models.},
keywords={Deep learning;Convolution;Computational modeling;Surveillance;Simulation;Feature extraction;Doppler radar;Convolution neural network;drone detection;radar remote sensing;radar detection},
doi={10.1109/ICTC52510.2021.9620998},
ISSN={2162-1233},
month={Oct},}
@INPROCEEDINGS{7358813,
author={Kim, Hangeun and Kim, Donghoon and Sungwook Jung and Jungmo Koo and Shin, Jae-Uk and Myung, Hyun},
booktitle={2015 12th International Conference on Ubiquitous Robots and Ambient Intelligence (URAI)}, title={Development of a UAV-type jellyfish monitoring system using deep learning},
year={2015},
volume={},
number={},
pages={495-497},
abstract={At present, unmanned aerial vehicles (UAVs) are the primary platforms widely used for environmental monitoring. The advantage of the UAV-type surveillance system is its low-cost with high observation performance. Using this system, we can extend the workable area of the jellyfish removal system. The proposed system observes jellyfish on the surface of the sea while flying, and can recognize a herd of jellyfish using deep learning. The preliminary results of the proposed system show that the proposed system improves the jellyfish removal system for efficient operation.},
keywords={Robots;Sea surface;Surveillance;Machine learning;Global Positioning System;Clustering algorithms;Jellyfish removal;monitoring system;unmanned aerial vehicle},
doi={10.1109/URAI.2015.7358813},
ISSN={},
month={Oct},}
@INPROCEEDINGS{9554542,
author={Singh, Arun Kumar and Dwivedi, Arun Kant and Nahar, Nimish and Singh, Dharmendra},
booktitle={2021 IEEE International Geoscience and Remote Sensing Symposium IGARSS}, title={Railway Track Sleeper Detection in Low Altitude UAV Imagery Using Deep Convolutional Neural Network},
year={2021},
volume={},
number={},
pages={355-358},
abstract={Railway track sleepers are the most critical component that serves as the backbone for other supplementary components. Frequent monitoring of sleepers ensures better railway track health conditions that ensure the safety of goods and passengers. Recently railway explored various monitoring possibilities based on UAV for the robust, cost effective, and efficient inspection of railway track components. Deep learning based object detectors show promising results on large and small datasets due to increased computation resources. YOLO versions of object detection model are most superior on low altitude aerial images. This paper explores the possibility of railway track sleeper detection using a custom object detection model based on the YOLO v4 algorithm in low altitude UAV images.},
keywords={Deep learning;Computational modeling;Object detection;Detectors;Inspection;Rail transportation;Robustness;Computer vision;Deep CNN;YOLO v4;Object detection;Rail track sleepers;Unmanned aerial vehicle (UAV)},
doi={10.1109/IGARSS47720.2021.9554542},
ISSN={2153-7003},
month={July},}
@ARTICLE{9314128,
author={Kuru, Kaya},
journal={IEEE Access}, title={Planning the Future of Smart Cities With Swarms of Fully Autonomous Unmanned Aerial Vehicles Using a Novel Framework},
year={2021},
volume={9},
number={},
pages={6571-6595},
abstract={The autonomy of unmanned aerial vehicles (UAVs) - self-governing in the aerospace discipline has been a remarkable research area with the development of the advanced bespoke microcontrollers embedded with advanced AI techniques for the last several decades. The road forward about the operational environment is certain about the swarms of fully automated UAVs (FAUAVs), that is, urban areas. FAUAVs with self-learning and self-decision-making abilities by executing non-trivial sequences of events with decimetre-level accuracy based on a set of rules, control loops and constraints using dynamic flight plans and trajectories are taking their indispensable parts within smart cities (SCs). Therefore, their integration with the SC components using real-time data analytics is urgent. This is mainly required to establish a better swarm intelligence along with a safer and optimised harmonious smart ecosystem that enables cooperative FAUAV-SC automation systems with collaborative automated intelligence engaging in the concepts of Internet of Everything (IoE) and Automation of Everything (AoE). Planning the future of cities with swarms of FAUAVs is explored in this paper to optimise the use of FAUAVs with a diverse range of applications and a contemporary methodology is proposed using a holistic framework - FAUAVinSCF equipped with various effective and efficient techniques along with a novel FAUAV routing technique customisable to the constraints of FAUAVs and urban areas. With the methodology, the components of SC and FAUAVs involving recent and impending technological advancements are moulded together to make this inevitable transformation a harmonious part of the inhabitants contributing to the cities' liveability and sustainability. The framework consists of a decentralized agent-based control architecture that monitors and controls the swarms of resource-constraint FAUAVs for their real-time requirements in optimising their urban uses. The outcomes of the methodology suggest that the constraints of FAUAVs can be mitigated significantly in urban areas and consequently, their efficacy can be increased in realising their diverse range of missions.},
keywords={Task analysis;Automation;Drones;Particle swarm optimization;Real-time systems;Batteries;Internet of Things;Autonomous unmanned aerial vehicles (UAVs);smart city;Internet of Things (IoT);Internet-of-Drones (IoD);Internet of Everything (IoE);Automation of Everything (AoE)},
doi={10.1109/ACCESS.2020.3049094},
ISSN={2169-3536},
month={},}
@INPROCEEDINGS{9345125,
author={Gao, Mingsheng and Liu, Yuxiang and Wei, Pengfei},
booktitle={2020 IEEE 6th International Conference on Computer and Communications (ICCC)}, title={Opposite and Chaos Searching Genetic Algorithm Based for UAV Path Planning},
year={2020},
volume={},
number={},
pages={2364-2369},
abstract={One of the most challenges in Unmanned Aerial Vehicles (UAV) system is path planning, as it provides basic navigation for UAVs to accomplish various missions under different backgrounds. Genetic algorithm (GA) is an efficient swarm intelligence algorithm in solving combinational optimization problems. To realize more rapid and efficient path planning under the limitation of multiple obstacles, this paper presents a novel genetic algorithm, namely Opposite and Chaos searching Genetic Algorithm (OCGA). At initial stage, population are generated by opposite and chaos searching for better optimization ability. At iteration stage, the algorithm updates population with a crossover operator improved by teaching-learning based optimization's (TLBO) learning strategy to increase convergence and prevent local optima. Simulation results validate the performance of proposed algorithm is superior to Triple-colony Ant Optimization (TP-ACO) in terms of optimization ability and convergence speed.},
keywords={Chaos;Unmanned aerial vehicles;Path planning;Statistics;Optimization;Genetic algorithms;Convergence;UAV path planning;genetic algorithm;teaching-learning based optimization;opposite searching;chaos searching},
doi={10.1109/ICCC51575.2020.9345125},
ISSN={},
month={Dec},}
@INPROCEEDINGS{9071861,
author={Mazeh, Hussein and Sahili, Jihad},
booktitle={2019 7th International Conference on Robotics and Mechatronics (ICRoM)}, title={Fault - Tolerant Control of a Multirotor Unmanned Aerial Vehicle applying Particle Swarm Optimization},
year={2019},
volume={},
number={},
pages={619-624},
abstract={This paper proposes a fault tolerance control algorithm for multirotor Unmanned Aerial Vehicles UAVs based on a powerful swarm intelligence algorithm. A hexarotor UAV is utilized for examining the proposed strategy. Indeed, there is a nonlinear derivation for hexarotor motor control strategy. The proposed fault tolerance control algorithm presented here, is based on motors speed reconfiguration strategy by means of particle swarm optimization (PSO). Simulation is performed along with realistic outdoor experiments for validation. The results show a good time performance of the optimization algorithm and effectiveness of the applied recovery algorithm.},
keywords={Actuators;Brushless motors;Fault tolerance;Fault tolerant systems;Controllability;Attitude control;Particle swarm optimization;Particle Swarm Optimization;Unmanned Aerial Vehicle;Fault-Tolerant Control;PID;Back Stepping},
doi={10.1109/ICRoM48714.2019.9071861},
ISSN={2572-6889},
month={Nov},}
@INPROCEEDINGS{9432146,
author={Gladence, L.Mary and Anu, V.Maria and Anderson, A. and Stanley, Immanuel and Fernando J, Jithin Abhishek and Revathy, S},
booktitle={2021 5th International Conference on Intelligent Computing and Control Systems (ICICCS)}, title={Swarm Intelligence in Disaster Recovery},
year={2021},
volume={},
number={},
pages={1-8},
abstract={A disaster is something which occurs suddenly and causes enormous destruction. Disaster may be accidental or natural, but however both of these cannot be predicted. They are known as disaster because of their sudden and volatile nature. During a disaster the destruction is huge, while rescue and relief are always lagging due to the unpredictability and the destruction caused could only be identified after the disaster has shown its full rage. In order to get the information about the damage caused and other information about the disaster, we send a fleet of Unmanned Aerial Vehicles (UAVs), which are a swarm of aerial robots (drones) that work together to achieve a particular target. Each drone in the swarm will VOTL, or vertically hover, take off, and land. Every drone has a particular number of rotors that propel it forward. Swarm intelligence is the collective behavior of decentralized, natural or artificial self- organized systems. This behavior tends to work by leaning with artificial intelligence. A flood scenario is simulated. Drone swarm will investigate the affected place in clusters and give us collective information, about the amount of damage caused by the disaster.},
keywords={Rotors;Propulsion;Control systems;Floods;Particle swarm optimization;Artificial intelligence;Drones;Disaster;Swarm;Unpredictability;UAV;Drone;VOTL;Decentralized;Stimulation},
doi={10.1109/ICICCS51141.2021.9432146},
ISSN={},
month={May},}


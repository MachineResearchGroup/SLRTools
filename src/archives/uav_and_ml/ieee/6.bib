@ARTICLE{9078075,
author={Bao, Tingnan and Zhu, Jun and Yang, Hong-Chuan and Hasna, Mazen O.},
journal={IEEE Wireless Communications Letters}, title={Secrecy Outage Performance of Ground-to-Air Communications With Multiple Aerial Eavesdroppers and Its Deep Learning Evaluation},
year={2020},
volume={9},
number={9},
pages={1351-1355},
abstract={In this letter, we study the secure information transmission from a ground base station (GBS) to a legitimate unmanned aerial vehicle (UAV) user, in the presence of multiple UAV eavesdroppers. To enhance the secrecy performance, the GBS applies beamforming transmission while enforcing a protection zone around it. Utilizing the general κ-μ shadowed fading distribution to model the ground-to-air channel, we derive an exact expression of the secrecy outage probability (SOP). To further facilitate performance evaluation, we adopt a data-driven approach and develop a deep learning model that can predict the SOP performance with high accuracy and short computation time. Through selected numerical results, we examine the effect of different system parameters on the SOP performance.},
keywords={Unmanned aerial vehicles;Fading channels;Signal to noise ratio;Deep learning;Eavesdropping;Three-dimensional displays;Computational modeling;Physical layer security;UAV;κ-μ fading;stochastic geometry;deep learning},
doi={10.1109/LWC.2020.2990337},
ISSN={2162-2345},
month={Sep.},}
@INPROCEEDINGS{9317198,
author={Kannadaguli, Prashanth},
booktitle={2020 International Conference on Decision Aid Sciences and Application (DASA)}, title={YOLO v4 Based Human Detection System Using Aerial Thermal Imaging for UAV Based Surveillance Applications},
year={2020},
volume={},
number={},
pages={1213-1219},
abstract={This work is related to building a Human Detection system based on You Only Look Once (YOLO) v4. It is one of the most recent Deep Learning approaches primitively built using single shot detection proposal. Unlike the double stage region-based object detection schemes this technique do not follow semantic segmentation, it does not undergo loss of the object information such as disappearance of the gradients and it does not require pre-defined anchors. This technique comprises strong feature extractors and reinforce multi scale object detection and it is very quick in the multi-threaded GPU environments. Since our fundamental research is concentrated on object classification related to Unmanned Aerial Vehicle (UAV) applications, as a first step we choose to detect the humans from thermal dataset. Therefore, we used thermal images and videos possessed from thermal cameras of UAV 1m to 50m above ground level as our dataset in building the model and testing. The YOLO v4 uses ground truth bounding boxes to extract the features like Weighted Residual Connections (WRC), Cross Stage Partial Connections (CSP), Cross mini Batch Normalization (CmBN), Self-Adversarial Training (SAT), Mish Activation (MA), Mosaic Data Augmentation (MDA) and Drop Block Regularization (DBR). Finally, the performance analysis of these model in terms of mean Average Precision (mAP) indicates that the modelling using YOLO v4 performs in a promising way and it can be used in automatic human detection systems.},
keywords={Feature extraction;Unmanned aerial vehicles;Rats;Object detection;Training;Testing;Surveillance;YOLO v4;Deep Learning;Thermal Imaging;UAV;Object Detection;Smart City;Surveillance},
doi={10.1109/DASA51403.2020.9317198},
ISSN={},
month={Nov},}
@ARTICLE{9745588,
author={Raja, Gunasekaran and Saravanan, Gayathri},
journal={IEEE Transactions on Green Communications and Networking}, title={Eco-Friendly Disaster Evacuation Framework for 6G Connected and Autonomous Vehicular Networks},
year={2022},
volume={},
number={},
pages={1-1},
abstract={Crowd and evacuation management have been active areas of research and study over recent years. Connected Autonomous Vehicles (CAVs) could provide safe and vital life-saving reinforcement when evacuating populations from a large-scale disaster site. However, navigation in disaster-affected environments is vulnerable to the presence of unpredictable moving obstacles. Existing solutions perform optimal route determination while considering the presence of a single rescue vehicle. To optimize path planning and enhance energy efficiency in the presence of a fleet of rescue vehicles and Unmanned Aerial Vehicles (UAVs), multiple sources and target destinations, we propose a Multi-Agent Deep Reinforcement Dijkstra (MADRD) algorithm in a sixth generation (6G) assisted environment to achieve cooperative navigation in the Route Planning Framework. The MADRD algorithm allows vehicles to learn from the experiences and behavior of other CAVs to obtain an optimal path from the source to the affected target site. Route selection and throttle parameters are optimized to achieve efficient fuel consumption, reduced travel time and lower traffic congestion. We simulate the Route Planning Framework on a large-scale real-world road network. The experimental results indicate that MADRD achieves 40% less fuel consumption, 45% higher road throughput and 34% less evacuation time than its state-of-the-art counterparts.},
keywords={Planning;Fuels;Roads;Navigation;Adaptation models;Traffic congestion;Reinforcement learning;Connected Autonomous Vehicles;UAV;6G;Deep Reinforcement Learning;Multi-Agent Deep Deterministic Policy Gradient;Emergency Evacuation;Route Planning.},
doi={10.1109/TGCN.2022.3163764},
ISSN={2473-2400},
month={},}
@INPROCEEDINGS{8900246,
author={Di Martini, David Robledo and Tetila, Everton Castelão and Junior, José Marcato and Matsubara, Edson Takashi and Siqueira, Henrique and de Castro Junior, Amaury Antônio and Araujo, Márcio Santos and Monteiro, Carlos Henrique and Pistori, Hemerson and Liesenberg, Veraldo},
booktitle={IGARSS 2019 - 2019 IEEE International Geoscience and Remote Sensing Symposium}, title={Machine Learning Applied to Uav Imagery in Precision Agriculture and Forest Monitoring in Brazililian Savanah},
year={2019},
volume={},
number={},
pages={9364-9367},
abstract={The Brazilian Savanah is one of the most important biomes of South America. It has an area of 2,036,448 km2 (around 22% of the country). Several endangered tree species are protected by law and recently are threatened in the last years. In addition, the country is the second major producer of soybean in the world. However, some insect species have been causing great economic damage in the soybean fields, and the Integrated Pest Management is a key factor for the attack control of different species. We design and implement an end-to-end observing system based on UAV (Unmanned Aerial Vehicle) to support precision agriculture and the forest monitoring. The current research is one of the projects approved by GRSS Grand Challenge, and is under development. It was developed two UAVs, one for each problem. Machine learning techniques were used and the best accuracy obtained performance reaching a classification rate of 99.04%. Others preliminary results in both precision farming and forest monitoring applications are described in this paper.},
keywords={Agriculture;Forestry;Monitoring;Remote sensing;Proposals;Cameras;Machine learning;Remote Sensing;Soybean;Computer Vision;UAV;Machine Learning;Brazilian Savanah},
doi={10.1109/IGARSS.2019.8900246},
ISSN={2153-7003},
month={July},}
@ARTICLE{9693334,
author={Sun, Qiyu and Fang, Jinbao and Zheng, Wei Xing and Tang, Yang},
journal={IEEE Transactions on Industrial Electronics}, title={Aggressive Quadrotor Flight Using Curiosity-Driven Reinforcement Learning},
year={2022},
volume={},
number={},
pages={1-1},
abstract={The ability to perform aggressive movements, which are called aggressive flights, is important for quadrotors during navigation. However, aggressive quadrotor flights are still a great challenge to practical applications. The existing solutions to aggressive flights heavily rely on a predefined trajectory, which is a time-consuming preprocessing step. To avoid such path planning, we propose a curiosity-driven reinforcement learning method for aggressive flight missions and a similarity-based curiosity module is introduced to speed up the training procedure. A branch structure exploration (BSE) strategy is also applied to guarantee the robustness of the policy and to ensure the policy trained in simulations can be performed in real-world experiments directly. The experimental results in simulations demonstrate that our reinforcement learning algorithm performs well in aggressive flight tasks, speeds up the convergence process and improves the robustness of the policy. Besides, our algorithm shows a satisfactory simulated to real transferability and performs well in real-world experiments.},
keywords={Reinforcement learning;Training;Navigation;Trajectory;Trajectory planning;Task analysis;Planning;UAVs;Aggressive Flight;Reinforcement Learning},
doi={10.1109/TIE.2022.3144586},
ISSN={1557-9948},
month={},}
@ARTICLE{9718529,
author={Wang, Xueyuan and Gursoy, M. Cenk and Erpek, Tugba and Sagduyu, Yalin E.},
journal={IEEE Internet of Things Journal}, title={Learning-Based UAV Path Planning for Data Collection with Integrated Collision Avoidance},
year={2022},
volume={},
number={},
pages={1-1},
abstract={Unmanned aerial vehicles (UAVs) are expected to be an integral part of wireless networks, and determining collision-free trajectory in multi-UAV non-cooperative scenarios while collecting data from distributed Internet of Things (IoT) nodes is a challenging task. In this paper, we consider a path planning optimization problem to maximize the collected data from multiple IoT nodes under realistic constraints. The considered multi-UAV non-cooperative scenarios involve random number of other UAVs in addition to the typical UAV, and UAVs do not communicate or share information among each other. We translate the problem into a Markov decision process (MDP) with parameterized states, permissible actions, and detailed reward functions. Dueling double deep Q-network (D3QN) is proposed to learn the decision making policy for the typical UAV, without any prior knowledge of the environment (e.g., channel propagation model and locations of the obstacles) and other UAVs (e.g., their missions, movements, and policies). The proposed algorithm can adapt to various missions in various scenarios, e.g., different numbers and positions of IoT nodes, different amount of data to be collected, and different numbers and positions of other UAVs. Numerical results demonstrate that real-time navigation can be efficiently performed with high success rate, high data collection rate, and low collision rate.},
keywords={Autonomous aerial vehicles;Data collection;Collision avoidance;Path planning;Internet of Things;Distributed databases;Prediction algorithms;Data collection;multi-UAV scenarios;path planning;collision avoidance;deep reinforcement learning.},
doi={10.1109/JIOT.2022.3153585},
ISSN={2327-4662},
month={},}
@ARTICLE{9745385,
author={Qi, Weijing and Song, Qingyang and Guo, Lei and Jamalipour, Abbas},
journal={IEEE Transactions on Vehicular Technology}, title={Energy-Efficient Resource Allocation for UAV-Assisted Vehicular Networks with Spectrum Sharing},
year={2022},
volume={},
number={},
pages={1-1},
abstract={Vehicular networks are envisioned to deliver data transmission services ubiquitously, especially in the upcoming autonomous driving era. Accordingly, the high data traffic load poses a heavy burden to the terrestrial network infrastructure. Unmanned Aerial Vehicles (UAVs) show enormous potential to assist vehicular networks in providing services. In a dense UAV-assisted vehicular network with a large number of users, spectrum sharing is leveraged for alleviating the spectrum scarcity. However, the increasing data traffic still leads to the UAV energy consumption problem. This paper considers a specific network scenario where a UAV transmits its cached content files to vehicular users over UAV-to-vehicle (U2V) links while vehicle-to-vehicle (V2V) links reuse the U2V spectrum for safety-critical message exchanges. To improve the UAV's energy efficiency while guaranteeing users quality of service (QoS), we jointly optimize content placement, spectrum allocation, co-channel link pairing, and power control, which are the key factors affecting energy efficiency and QoS. The joint optimization problem is formulated as a mixed-integer nonlinear programming (MINLP) problem, which is solved by combining Hungarian and DDQN. We perform system performance evaluations, demonstrating that our approach can not only improve the UAV's energy efficiency while satisfying the users' QoS requirements but also increase the timeliness of making decisions.},
keywords={Resource management;Quality of service;Optimization;Autonomous aerial vehicles;Interference;Delays;Throughput;UAV;vehicular networks;spectrum sharing;resource allocation;reinforcement learning},
doi={10.1109/TVT.2022.3163430},
ISSN={1939-9359},
month={},}
@INPROCEEDINGS{9696380,
author={Song, Sirui and Zhang, Yuanhang and Qin, Xi and Saunders, Kirk and Liu, Jundong},
booktitle={NAECON 2021 - IEEE National Aerospace and Electronics Conference}, title={Vision-guided Collision Avoidance Through Deep Reinforcement Learning},
year={2021},
volume={},
number={},
pages={191-194},
abstract={Collision avoidance is a crucial task in vision-guided autonomous navigation. Traditional solutions tend to be computationally expensive and difficult to adapt to new environments. In this work, we propose a novel collision avoidance solution for autonomous drones. Formulated under a deep reinforcement learning framework, our model relies on a pair of margin reward functions to ensure the drones fly smoothly while greatly reducing the chance of collision. Additional reward functions are designed to attract the drones to fly towards their destinations, as well as to follow predefined routes. Experiments using indoor simulation environments demonstrate the effectiveness of our overall design and the individual components.},
keywords={Conferences;Reinforcement learning;Robustness;Indoor environment;Collision avoidance;Task analysis;Drones;UAV;Autonomy;Navigation;Deep Reinforcement Learning;AirSim},
doi={10.1109/NAECON49338.2021.9696380},
ISSN={2379-2027},
month={Aug},}
@INPROCEEDINGS{9114828,
author={Gusland, Daniel and Rolfsjord, Sigmund and Torvik, Børge},
booktitle={2020 IEEE International Radar Conference (RADAR)}, title={Deep temporal detection - A machine learning approach to multiple-dwell target detection},
year={2020},
volume={},
number={},
pages={203-207},
abstract={Detecting small targets, such as an Unmanned Aerial Vehicle (UAV) in high clutter and non-homogeneous environments is challenging for a radar system. Traditional Constant False Alarm Rate (CFAR) detectors have suboptimal performance in many scenarios. In this paper, we attempt a new approach to radar detection, based on machine learning, to increase the $P_{D}$ while retaining a low $F_{FA}$. We propose two approaches, using a Convolutional Neural Network (CNN) on the range-Doppler images and stacking multiple range-Doppler images as layers, called the Temporal CNN detector. The models are trained and tested solely on measured radar data by using the estimated position and velocity from a collaborative target UAV. It is shown that training a model based solely on measured data is achievable and performance metrics calculated from the testing data shows that both models outperform the Cell-Averaging Constant False Alarm Rate (CA-CFAR) by having higher $P_{D}$ with the same $P_{FA}$. The current test results indicate that the temporal CNN is able to increase the detection distance close to 30%, while retaining the same $P_{FA}$ as the CA-CFAR.},
keywords={Training;Radar detection;Detectors;Machine learning;Position measurement;Autonomous aerial vehicles;Data models;Radar;detection;UAV;deep learning;CNN;CFAR;non-homogeneous},
doi={10.1109/RADAR42522.2020.9114828},
ISSN={2640-7736},
month={April},}
@INPROCEEDINGS{9602967,
author={Chen, Wei-Ting and Huang, Cheng-Sen and Wang, Li-Chun},
booktitle={2021 30th Wireless and Optical Communications Conference (WOCC)}, title={Cooperative Deep Learning-Based Uplink Distributed Fair Resource Allocation for Aerial Reconfigurable Intelligent Surfaces Wireless Networks},
year={2021},
volume={},
number={},
pages={11-15},
abstract={In this paper, we present a cooperative distributed learning based resource allocation scheme for an unmanned aerial vehicle (UAV)-assisted wireless communication framework equipped with reconfigurable intelligent surfaces (RIS), aiming to dynamically allocate the amount of the resource block(RB) to ensure the fairness and efficiency from the end-to-end communications system perspective. We suggest a novel, but simple fairness-efficiency metrics (FE metrics) to measure the performance of resource allocating, and to compare various resource allocation policies, including our proposed cooperative deep learning approaches, other rule-based and centralized methods. The proposed cooperative distributed learning framework has the advantages of making decisions by considering information about the entire environment, so that cooperation provides better overall performance and reliability. Moreover, it enables double parallel computing and reduces execution time dramatically. The simulation result shows that our cooperative deep learning algorithm ensures excellent convergence and low time complexity during the execution in the complex Aerial RIS system to reduce communication delays, improve communication quality, and ensure fairness.},
keywords={Deep learning;Measurement;Computer aided instruction;Distance learning;Wireless networks;Reconfigurable intelligent surfaces;Unmanned aerial vehicles;UAV-assisted Wireless Communication;Reconfigurable Intelligent Surfaces;Deep Learning;Uplink resource allocation},
doi={10.1109/WOCC53213.2021.9602967},
ISSN={2379-1276},
month={Oct},}
@INPROCEEDINGS{9274972,
author={Zhen, Chen and De-rong, Chen and Jiu-lu, Gong},
booktitle={2020 3rd International Conference on Unmanned Systems (ICUS)}, title={A Deep Learning Based Distributed Compressive Video Sensing Reconstruction Algorithm for Small Reconnaissance UAV},
year={2020},
volume={},
number={},
pages={668-672},
abstract={Distributed compressive video sensing (DCVS) is an effective method for small reconnaissance Unmanned Aerial Vehicle(UAV) to obtain high-quality videos on the battlefield. However, the existing reconstruction algorithms based on deep learning fail to make full use of the temporal correlation of videos, resulting in low reconstruction quality. In this paper, a measurement information compensation network called MCINet is used to compensate for the information in non-key frame measurements with the help of key frame measurements before initial recovery. At joint reconstruction stage, a neural network with autoencoder mix with recurrent neural network (RNN) structure called ECLDNet which makes full use of high-quality key frames is adopted, the encoder extracts temporal-spatial features from key and non-key frames, the RNN uses features of key frame to compensate for missing details in non-key frame features, the decoder reconstructs images in a symmetrical way with encoder. Experimental results indicate that our model can get an additional performance gain of more than 1.5 dB peak signal-noise ratio (PSNR) without any changes at the encoding end. The reconstruction runtime of our model increases slightly, but is still much less than iterative reconstruction algorithms due to the non-iterative nature of deep learning.},
keywords={Image reconstruction;Feature extraction;Image quality;Correlation;Convolution;Decoding;Reconnaissance;small reconnaissance UAV;distributed compressive video sensing;deep learning;temporal correlation},
doi={10.1109/ICUS50048.2020.9274972},
ISSN={},
month={Nov},}
@INPROCEEDINGS{8998066,
author={Xu, Jie and Guo, Qing and Xiao, Lei and Li, Zhaoyi and Zhang, Gaowei},
booktitle={2019 IEEE 4th Advanced Information Technology, Electronic and Automation Control Conference (IAEAC)}, title={Autonomous Decision-Making Method for Combat Mission of UAV based on Deep Reinforcement Learning},
year={2019},
volume={1},
number={},
pages={538-544},
abstract={Improving of the autonomous decision-making ability of UAV has become a key factor for UAV to seize the initiative of future battlefield. At present, UAV's tasks mainly depend on pre-planning, which is difficult to adapt to the complexity and dynamics of future battlefield. Aiming at this problem, in view of typical mission scenarios of UAV regional reconnaissance and air-to-air confrontation, this paper adopts Deep Learning method to develop autonomous decision-making method for UAV, constructs mission decision-making model of Deep Belief Network (DBN) and Q-Learning algorithm, and then optimizes the decision-making model based on genetic algorithm to realize "off-line learning" and "online decision-making" provide effective support. The simulation results verify that the method can effectively deal with typical tasks of UAV regional reconnaissance and air-to-air confrontation, and it is an effective attempt to carry out autonomous decision-making of UAV.},
keywords={Decision making;Reconnaissance;Task analysis;Training;Planning;Feature extraction;Machine learning;Deep Learning;UAV;Autonomous Control;Deep Belief Network (DBN);Q-Learning},
doi={10.1109/IAEAC47372.2019.8998066},
ISSN={2381-0947},
month={Dec},}
@ARTICLE{7875131,
author={Chen, Mingzhe and Mozaffari, Mohammad and Saad, Walid and Yin, Changchuan and Debbah, Mérouane and Hong, Choong Seon},
journal={IEEE Journal on Selected Areas in Communications}, title={Caching in the Sky: Proactive Deployment of Cache-Enabled Unmanned Aerial Vehicles for Optimized Quality-of-Experience},
year={2017},
volume={35},
number={5},
pages={1046-1061},
abstract={In this paper, the problem of proactive deployment of cache-enabled unmanned aerial vehicles (UAVs) for optimizing the quality-of-experience (QoE) of wireless devices in a cloud radio access network is studied. In the considered model, the network can leverage human-centric information, such as users' visited locations, requested contents, gender, job, and device type to predict the content request distribution, and mobility pattern of each user. Then, given these behavior predictions, the proposed approach seeks to find the user-UAV associations, the optimal UAVs' locations, and the contents to cache at UAVs. This problem is formulated as an optimization problem whose goal is to maximize the users' QoE while minimizing the transmit power used by the UAVs. To solve this problem, a novel algorithm based on the machine learning framework of conceptor-based echo state networks (ESNs) is proposed. Using ESNs, the network can effectively predict each user's content request distribution and its mobility pattern when limited information on the states of users and the network is available. Based on the predictions of the users' content request distribution and their mobility patterns, we derive the optimal locations of UAVs as well as the content to cache at UAVs. Simulation results using real pedestrian mobility patterns from BUPT and actual content transmission data from Youku show that the proposed algorithm can yield 33.3% and 59.6% gains, respectively, in terms of the average transmit power and the percentage of the users with satisfied QoE compared with a benchmark algorithm without caching and a benchmark solution without UAVs.},
keywords={Prediction algorithms;Base stations;Mobile communication;Wireless communication;Predictive models;Unmanned aerial vehicles;CRAN;UAV;unmanned aerial vehciles;drones;QoE;caching;machine learning;conceptor-based echo state networks},
doi={10.1109/JSAC.2017.2680898},
ISSN={1558-0008},
month={May},}
@INPROCEEDINGS{8373497,
author={Zahran, S. and Moussa, A. and El-Sheimy, N.},
booktitle={2018 IEEE/ION Position, Location and Navigation Symposium (PLANS)}, title={Enhanced UAV navigation in GNSS denied environment using repeated dynamics pattern recognition},
year={2018},
volume={},
number={},
pages={1135-1142},
abstract={This paper presents an innovative approach to enhance the navigation of UAVs in GNSS denied environments. Considering the limited space, power, and size of small UAVs, the proposed approach does not require any sensors on the UAV. The typical repeated dynamic patterns of such UAVs are related to the actuators to offer a useful information for estimating the UAV navigation states. Machine learning (ML) classifier has been employed to detect these repeated dynamic patterns, then according to the detected pattern, an appropriate constraint/update is utilized to enhance the navigation solution through EKF to obtain a better estimate of the UAV states. Different test scenarios where conducted to verify the ability of the proposed approach to aid the INS solution during GNSS signal outages. The solution after fusing the Vheicle Model (VM) is enhaced by 98% compared to low cost stand-alone IMU solution.},
keywords={Mathematical model;Global navigation satellite system;Vehicle dynamics;Unmanned aerial vehicles;Sensors;Covariance matrices;Extended Kalman Filter (EKF);vehicle modeling (VM);machine learning (ML);classification;Global Navigation Satellite System (GNSS);Inertial Measurement Unit (IMU);Unmanned Aerial Vehicles (UAVs)},
doi={10.1109/PLANS.2018.8373497},
ISSN={2153-3598},
month={April},}
@INPROCEEDINGS{9488469,
author={Massaro, Alessandro and Dipierro, Giovanni and Selicato, Sergio and Cannella, Emanuele and Galiano, Angelo and Saponaro, Annamaria},
booktitle={2021 IEEE International Workshop on Metrology for Industry 4.0 IoT (MetroInd4.0 IoT)}, title={Intelligent Quarry Production Monitoring Risks and Quality by Artificial Intelligence},
year={2021},
volume={},
number={},
pages={242-247},
abstract={The presented work discusses the results of an industry project oriented on the development of a web platform aimed at monitoring the quality of the quarry production processes and related risks. The platform is oriented mainly on the predictive maintenance of quarry crusher and conveyor belts. Artificial Intelligence (AI) algorithms such as Multilayer Perceptron (MLP), Artificial Neural Network (ANN) and Long Short-Term Memory (LSTM) are applied for brakeage prediction of crushers and the conveyor belt carpet. The dataset is obtained thanks to the several cameras and accelerometers installed in different check points of the quarry, sending data in real time to the platform. The system maps also risk conditions based on the combined analysis of the 3D quarry morphological reconstruction performed by photogrammetry and of the radargrams acquired by an Unmanned Aerial Vehicle (UAV) equipped with a Ground Penetrating Radar (GPR) antenna.},
keywords={Industries;Artificial neural networks;Production;Belts;Prediction algorithms;Cameras;Unmanned aerial vehicles;Artificial Intelligence;LSTM;MLP ANN;UAV;GPR;Quarry Risk Production;Predictive Maintenance},
doi={10.1109/MetroInd4.0IoT51437.2021.9488469},
ISSN={},
month={June},}
@INPROCEEDINGS{9277542,
author={Albuquerque, Caio K. G. and Polimante, Sergio and Torre-Neto, André and Prati, Ronaldo C.},
booktitle={2020 IEEE International Workshop on Metrology for Agriculture and Forestry (MetroAgriFor)}, title={Water spray detection for smart irrigation systems with Mask R-CNN and UAV footage},
year={2020},
volume={},
number={},
pages={236-240},
abstract={While the world's population rises, demand for food grows accordingly. Smart agriculture emerges as a viable solution to increase the quality and efficiency of crops. Irrigation plays an essential role in the grade and productivity of harvests, while also being a crucial factor in the cost-effectiveness of food production. Smart irrigation uses technology to improve watering, such as the Internet of Things (IoT) applications and Machine Learning algorithms. The correct functioning of irrigation nozzles is critical to ensure that the hydration plan is deployed correctly to the crop field. This paper presents a Machine Learning algorithm that can automatically recognize water from aerial footage of irrigation systems. This automatic recognition can help in the irrigation system inspection, potentially reducing time and cost in system maintenance. Initial results show that it is possible to identify water on image frames captured by an Unmanned Aerial Vehicle (UAV) using the Mask R-CNN Neural Network. The goal is to identify malfunctioning irrigation systems that can lead to under or overwatering, compromising the irrigation plan's correct implementation.},
keywords={Irrigation;Videos;Training;Agriculture;Unmanned aerial vehicles;Neural networks;Water resources;Smart Irrigation;Deep Learning;Mask R-CNN;System Inspection;UAV imaging},
doi={10.1109/MetroAgriFor50201.2020.9277542},
ISSN={},
month={Nov},}
@INPROCEEDINGS{9473572,
author={Liu, Zhenrong and Zeng, Yuan and Zhang, Wei and Gong, Yi},
booktitle={2021 IEEE International Conference on Communications Workshops (ICC Workshops)}, title={Trajectory Design for UAV Communications with No-Fly Zones by Deep Reinforcement Learning},
year={2021},
volume={},
number={},
pages={1-5},
abstract={This paper studies the trajectory design problem for the cellular-connected unmanned aerial vehicle (UAV) with limited energy, which aims at maximizing the uplink transmission rate from multiple ground users in urban environments with no-fly zones (NFZs). We first argue that the successive convex approximation-based (SCA-based) conventional trajectory design method via formulating and solving optimization problems face challenges, and then we formulate the trajectory design problem for rate maximization as a Markov Decision Process and propose a deep reinforcement learning-based (DRL-based) solution. Simulation results show that the proposed DRL has similar performance to the SCA-based conventional method with regularly shaped NFZ constraints. Moreover, simulation results in a scenario with an irregular NFZ show that the designed trajectories of the proposed DRL can effectively serve users and detour the NFZ.},
keywords={Wireless communication;Simulation;Design methodology;Conferences;Urban areas;Reinforcement learning;Unmanned aerial vehicles;UAV communications;trajectory design;no-fly zones;deep reinforcement learning},
doi={10.1109/ICCWorkshops50388.2021.9473572},
ISSN={2694-2941},
month={June},}
@INPROCEEDINGS{9722679,
author={Bhandarkar, Adhitya Bantwal and Jayaweera, Sudharman K. and Lane, Steven A.},
booktitle={2022 International Conference on Artificial Intelligence in Information and Communication (ICAIIC)}, title={User Coverage Maximization for a UAV-mounted Base Station Using Reinforcement Learning and Greedy Methods},
year={2022},
volume={},
number={},
pages={351-356},
abstract={This paper proposes two methods to maximize the coverage of distinct ground users by an unmanned aerial vehicle (UAV) -mounted mobile base station: a deep reinforcement learning (DRL) approach, and a reward-based greedy approach. The performance of the proposed methods are evaluated based on two aspects: the number of distinct ground users covered, and the delay experienced by a user until it first receives coverage. The distribution of ground users is modelled as a Gaussian Mixture Model (GMM) with fixed and time-varying means with the latter scenario mimicking the mobility of users. Simulation results show that both proposed methods lead to efficient coverage and latency performance with the DRL based approach significantly outperforming the rewards-based greedy algorithm, especially when ground users are allowed to be mobile.},
keywords={Greedy algorithms;Wireless communication;Base stations;Simulation;Reinforcement learning;Autonomous aerial vehicles;Delays;Optimal trajectory learning;Unmanned Aerial Vehicles (UAVs);wireless user coverage;Deep Reinforcement Learning (DRL);Deep Q-Network (DQN);greedy algorithm},
doi={10.1109/ICAIIC54071.2022.9722679},
ISSN={},
month={Feb},}
@INPROCEEDINGS{8023651,
author={Zhou, Dinale and Zhou, Jinglun and Zhang, Maojun and Xiang, Dao and Zhong, Zhiwei},
booktitle={2017 18th International Conference on Advanced Robotics (ICAR)}, title={Deep learning for unmanned aerial vehicles landing carrier in different conditions},
year={2017},
volume={},
number={},
pages={469-475},
abstract={With the rapid development of unmanned aerial vehicles (UAVs) technology, it is necessary to ensure the safe and stable landing on the carrier. In this paper, we present a deep learning for UAVs Landing carrier in different conditions. Firstly it analysis of different sea conditions deck motion, constructs a simulation model of the system. The waves motion, deck motion, and then to the aircraft landing motion models are simulation. Then according to a large number of previous land runway, mobile landing platform experimental data, UAV model, wind model and deck motion model build aircraft carrier simulation system. That is based on deep learning, to estimate the safety conditions of contact carrier aircraft and deck. Then, it simulate the deck in different sea conditions and wave motion under the harsh conditions of motion, to testing the deck can withstand the landing limit to make feasibility analysis. Finally, using there simulation data use for UAVs landing on river platform. Simulation results show that the sea conditions with effective longitudinal deviation and lateral deviation of the ship is the most significant. Level 4, level 5, and level 6 sea conditions idea landing condition success rate are 98%, 70.8%, 63%. And it successful uses for landing in river platform.},
keywords={Atmospheric modeling;Aircraft;Unmanned aerial vehicles;Marine vehicles;Machine learning;Data models;Mathematical model;Deep learning;UAV;Automatic landing;Sea condition;Deck motion},
doi={10.1109/ICAR.2017.8023651},
ISSN={},
month={July},}
@INPROCEEDINGS{9594321,
author={Fraser, Benjamin and Al-Rubaye, Saba and Aslam, Sohaib and Tsourdos, Antonios},
booktitle={2021 IEEE/AIAA 40th Digital Avionics Systems Conference (DASC)}, title={Enhancing the Security of Unmanned Aerial Systems using Digital-Twin Technology and Intrusion Detection},
year={2021},
volume={},
number={},
pages={1-10},
abstract={In this paper the general susceptibilities of Unmanned Aerial Vehicles (UAVs) against modern-cyber threats are explored and potential solutions proposed. This is achieved by applying digital-twin architectures and data-driven methods to UAVs to facilitate identification of real-time intrusions and anomalies. These concepts are validated by performing novelty detection on open access UAV flight data with GPS spoofing attacks, which represents a typical system use-case. Multiple machine learning models are trained to demonstrate the feasibility of detecting modern cyber-intrusions and anomalies using the digital-twin architecture. This includes both classical and deep learning techniques to help identify the most suitable model types for the proposed design. The overall results are positive and help highlight the potential of digital-twin architectures for the UAV contexts.},
keywords={Adaptation models;Analytical models;Prototypes;Unmanned aerial vehicles;Data models;Real-time systems;Security;Digital-twin;Machine Learning;Novelty Detection;UAV;UAS;Intrusion Detection;Cyber-security},
doi={10.1109/DASC52595.2021.9594321},
ISSN={2155-7209},
month={Oct},}
@INPROCEEDINGS{8923217,
author={Almeida, Eduardo Nuno and Fernandes, Kelwin and Andrade, Francisco and Silva, Pedro and Campos, Rui and Ricardo, Manuel},
booktitle={2019 International Conference on Wireless and Mobile Computing, Networking and Communications (WiMob)}, title={A Machine Learning Based Quality of Service Estimator for Aerial Wireless Networks},
year={2019},
volume={},
number={},
pages={1-6},
abstract={Unmanned Aerial Vehicles (UAVs) acting as aerial Wi-Fi Access Points or cellular Base Stations are being considered to deploy on-demand network capacity in order to serve traffic demand surges or replace Base Stations. The ability to estimate the Quality of Service (QoS) for a given network setup may help in solving UAV placement problems. This paper proposes a Machine Learning (ML) based QoS estimator, based on convolutional neural networks, which estimates the QoS for a given network by considering the UAV positions, the user positions and their offered traffic. The ML-based QoS estimator represents a novel paradigm for estimating the QoS in aerial wireless networks. It provides fast and accurate estimations with reduced computational complexity. We demonstrate the usefulness and applicability of the proposed QoS estimator using the ideal UAV placement algorithm. Simulation results show the QoS estimator has an average prediction error lower than 5%.},
keywords={Quality of service;Topology;Wireless networks;Unmanned aerial vehicles;Estimation;Base stations;Measurement;Aerial wireless networks;Machine learning;Placement algorithm;QoS estimator;UAV},
doi={10.1109/WiMOB.2019.8923217},
ISSN={2160-4894},
month={Oct},}
@INPROCEEDINGS{9720830,
author={Slimane, Hadjar Ould and Benouadah, Selma and Khoei, Tala Talaei and Kaabouch, Naima},
booktitle={2022 IEEE 12th Annual Computing and Communication Workshop and Conference (CCWC)}, title={A Light Boosting-based ML Model for Detecting Deceptive Jamming Attacks on UAVs},
year={2022},
volume={},
number={},
pages={0328-0333},
abstract={Advances made in Unmanned Aircraft Vehicles (UAVs) have increased rapidly in the last decade resulting in new applications in both civil and military spheres. However, with the growth in the usage of these systems, various cybersecurity challenges arose unveiling the vulnerabilities of UAV wireless networks. Among the attacks that threaten the network's availability and reduce their performance are jamming attacks. Several approaches have been proposed to address this problem; however, most of them are not suitable for UAVs due to their reduced size, weight, and power constraints. In this paper, we propose a lightweight machine learning technique, LightGBM, to detect deceptive jamming attacks on UAV networks. The performance of this model is compared to that of three boosting and bagging-based machine learning models namely, XGBoost, Gradient Boost, and Random Forest. The results show that, although the LightGBM model has slightly lower accuracy (98.4%) than Gradient Boost (99%) and Random Forest (98.87%), it is 21 times faster and occupies two times less memory during the prediction than Gradient Boost and Random Forest.},
keywords={Conferences;Computational modeling;Wireless networks;Memory management;Predictive models;Military aircraft;Boosting;UAV;jamming attacks;detection techniques;machine learning;LightGBM;deceptive jamming;wireless networks},
doi={10.1109/CCWC54503.2022.9720830},
ISSN={},
month={Jan},}
@ARTICLE{8736996,
author={Chakareski, Jacob},
journal={IEEE Transactions on Image Processing}, title={UAV-IoT for Next Generation Virtual Reality},
year={2019},
volume={28},
number={12},
pages={5977-5990},
abstract={We investigate UAV-IoT data capture and networking for remote scene virtual reality (VR) immersion. We characterize the delivered immersion fidelity as a function of the assigned UAV-IoT capture/network rates and study the optimization problem of maximizing it, for given system/application constraints. We explore fast reinforcement learning to discover the best dynamic UAV-IoT network placement over the scene of interest to maximize the expected remote immersion fidelity. We design scalable source-channel viewpoint coding to maximize the expected reconstruction fidelity of the data captured at every UAV location at the ground-based aggregation point. Finally, we explore layered directional networking and rate-distortion-power optimized embedded scheduling methods to effectively transmit the encoded data and overcome network transients that lead to packet buffering, which represent the fourth system component of our framework. Experimental results demonstrate considerable performance efficiency gains enabled by each system component over the respective state-of-the-art reference methods, in delivered VR immersion fidelity, application interactivity/play-out latency, and transmission power consumption.},
keywords={Servers;Navigation;Streaming media;Image coding;Virtual reality;Reinforcement learning;Image reconstruction;UAV-IoT data capture and networking;virtual reality;reinforcement learning;remote immersion},
doi={10.1109/TIP.2019.2921869},
ISSN={1941-0042},
month={Dec},}
@INPROCEEDINGS{9550712,
author={Wang, Guanzheng and Liu, Zhihong and Xiao, Kun and Xu, Yinbo and Yang, Lingjie and Wang, Xiangke},
booktitle={2021 40th Chinese Control Conference (CCC)}, title={Collision Detection and Avoidance for Multi-UAV based on Deep Reinforcement Learning},
year={2021},
volume={},
number={},
pages={7783-7789},
abstract={In recent years, the demand for improving the autonomy of UAVs has continued to increase in the civilian and military fields. Collision detection and avoidance is one of the key technologies to this end. In this paper, we propose a fully-distributed collision detection and avoidance method for multi-UAV based on deep reinforcement learning. Different from traditional methods, we implement an end-to-end control, which takes the information of sensor, UAV status and destination as inputs, and directly outputs the control references. Besides, based on the PPO algorithm and the paradigm of centralized training and decentralized execution, we provide the design of the deep reinforcement leaning network and the policy update strategy. In addition, we build a series of training and verification environments, including 2D Stage scenes and 3D Gazebo scenes. The experiment results show that our method can successfully avoid the obstacles and achieve no collision between UAVs.},
keywords={Training;Three-dimensional displays;Reinforcement learning;Markov processes;Aerospace electronics;Reliability;Collision avoidance;Multi-UAV;Collision Detection and Avoidance;Fully-distributed;Deep Reinforcement Learning},
doi={10.23919/CCC52363.2021.9550712},
ISSN={1934-1768},
month={July},}
@ARTICLE{9195795,
author={Chen, Yu-Jia and Chang, Deng-Kai and Zhang, Cheng},
journal={IEEE Transactions on Vehicular Technology}, title={Autonomous Tracking Using a Swarm of UAVs: A Constrained Multi-Agent Reinforcement Learning Approach},
year={2020},
volume={69},
number={11},
pages={13702-13717},
abstract={In this paper, we aim to design an autonomous tracking system for a swarm of unmanned aerial vehicles (UAVs) to localize a radio frequency (RF) mobile target. In the system, UAVs equipped with omnidirectional received signal strength (RSS) sensors can cooperatively search the target with a specified tracking accuracy. To achieve fast localization and tracking in the highly dynamic channel environment (e.g., time-varying transmit power and intermittent signal), we formulate a flight decision problem as a constrained Markov decision process (CMDP) with the main objective of avoiding redundant UAV flight path. Then, we propose an enhanced multi-agent reinforcement learning to coordinate multiple UAVs performing real-time target tracking. The core of the proposed scheme is a feedback control system that takes into account the uncertainty of the channel estimate. We prove that the proposed algorithm can converge to the optimal decision. Our simulation results show that the proposed scheme outperforms standard Q-learning and multi-agent Q-learning algorithms in terms of searching time and successful localization probability.},
keywords={Target tracking;Robots;Radio frequency;Sensors;Real-time systems;Path planning;Multi-agent reinforcement learning;unmanned aerial vehicles (UAVs);localization and tracking;constrained Markov decision process},
doi={10.1109/TVT.2020.3023733},
ISSN={1939-9359},
month={Nov},}
@INPROCEEDINGS{8693023,
author={Islam, Shafkat and Razi, Abolfazl},
booktitle={2019 53rd Annual Conference on Information Sciences and Systems (CISS)}, title={A Path Planning Algorithm for Collective Monitoring Using Autonomous Drones},
year={2019},
volume={},
number={},
pages={1-6},
abstract={This paper presents a novel mission-oriented path planning algorithm for a team of Unmanned Aerial Vehicles (UAVs). In the proposed algorithm, each UAV takes autonomous decisions to find its flight path towards a designated mission area while avoiding collisions to stationary and mobile obstacles. The main distinction with similar algorithms is that the target destination for each UAV is not apriori fixed and the UAVs locate themselves such that they collectively cover a potentially time-varying mission area. One potential application for this algorithm is deploying a team of autonomous drones to collectively cover an evolving forest wildfire and provide virtual reality for fire fighters. We formulated the algorithm based on Reinforcement Learning (RL) with a new method to accommodate continuous state space for adjacent locations. To consider more realistic scenario, we assess the impact of localization errors on the performance of the proposed algorithm. Simulation results show that success probability for this algorithm is about 80% when the observation error variance is as high as 100 (SNR:-6dB).},
keywords={Drones;Path planning;Monitoring;Reinforcement learning;Mathematical model;Simulation;UAV networks;Reinforcement Learning;Virtual Reality;Wildfire Monitoring},
doi={10.1109/CISS.2019.8693023},
ISSN={},
month={March},}
@ARTICLE{8984371,
author={Li, Bohao and Wu, Yunjie},
journal={IEEE Access}, title={Path Planning for UAV Ground Target Tracking via Deep Reinforcement Learning},
year={2020},
volume={8},
number={},
pages={29064-29074},
abstract={In this paper, we focus on the study of UAV ground target tracking under obstacle environments using deep reinforcement learning, and an improved deep deterministic policy gradient (DDPG) algorithm is presented. A reward function based on line of sight and artificial potential field is constructed to guide the behavior of UAV to achieve target tracking, and a penalty term of action makes the trajectory smooth. In order to improve the exploration ability, multiple UAVs, which controlled by the same policy network, are used to perform tasks in each episode. Taking into account that the history observations have a great degree of correlation with the policy, long short-term memory networks are used to approximate the state of environments, which improve the approximation accuracy and the efficiency of data utilization. The simulation results show that the propose method can make the UAV keep target tracking and obstacle avoidance effectively.},
keywords={Target tracking;Unmanned aerial vehicles;Collision avoidance;Path planning;Heuristic algorithms;Sensors;Reinforcement learning;DDPG;deep reinforcement learning;obstacle avoidance;target tracking;UAV},
doi={10.1109/ACCESS.2020.2971780},
ISSN={2169-3536},
month={},}
@ARTICLE{7372409,
author={Hung, Shao-Ming and Givigi, Sidney N.},
journal={IEEE Transactions on Cybernetics}, title={A Q-Learning Approach to Flocking With UAVs in a Stochastic Environment},
year={2017},
volume={47},
number={1},
pages={186-197},
abstract={In the past two decades, unmanned aerial vehicles (UAVs) have demonstrated their efficacy in supporting both military and civilian applications, where tasks can be dull, dirty, dangerous, or simply too costly with conventional methods. Many of the applications contain tasks that can be executed in parallel, hence the natural progression is to deploy multiple UAVs working together as a force multiplier. However, to do so requires autonomous coordination among the UAVs, similar to swarming behaviors seen in animals and insects. This paper looks at flocking with small fixed-wing UAVs in the context of a model-free reinforcement learning problem. In particular, Peng's Q(λ)$with a variable learning rate is employed by the followers to learn a control policy that facilitates flocking in a leader-follower topology. The problem is structured as a Markov decision process, where the agents are modeled as small fixed-wing UAVs that experience stochasticity due to disturbances such as winds and control noises, as well as weight and balance issues. Learned policies are compared to ones solved using stochastic optimal control (i.e., dynamic programming) by evaluating the average cost incurred during flight according to a cost function. Simulation results demonstrate the feasibility of the proposed learning approach at enabling agents to learn how to flock in a leader-follower topology, while operating in a nonstationary stochastic environment.},
keywords={Stochastic processes;Robot kinematics;Adaptation models;Computational modeling;Topology;Unmanned aerial vehicles;Flocking;Q-learning;reinforcement learning (RL);unmanned aerial vehicles (UAVs)},
doi={10.1109/TCYB.2015.2509646},
ISSN={2168-2275},
month={Jan},}
@ARTICLE{9585312,
author={Yuan, Tingting and Rothenberg, Christian Esteve and Obraczka, Katia and Barakat, Chadi and Turletti, Thierry},
journal={IEEE Transactions on Network and Service Management}, title={Harnessing UAVs for Fair 5G Bandwidth Allocation in Vehicular Communication via Deep Reinforcement Learning},
year={2021},
volume={18},
number={4},
pages={4063-4074},
abstract={Terrestrial infrastructure-based wireless networks do not always guarantee their resources will be shared uniformly by nodes in vehicular networks. This is due mainly to the uneven and dynamic geographical distribution of vehicles and path loss effects. In this paper, we leverage multiple fifth-generation (5G) unmanned aerial vehicles (UAVs) to enhance fairness in network resource allocation among vehicles by positioning UAVs on-demand as “flying communication infrastructure”. We propose a deep reinforcement learning (DRL) approach to determine UAVs’ position to improve network resource allocation fairness and efficiency while considering the UAVs’ flying range, communication range, and energy constraints. We use a parametric fairness function to attain a number of resource allocation objectives ranging from maximizing the total throughput of vehicles, maximizing minimum throughput, and achieving proportional bandwidth allocation. Simulation results show that the proposed DRL approach to UAV positioning can improve network resource allocation according to the targeted fairness objective.},
keywords={5G mobile communication;Wireless networks;Simulation;Reinforcement learning;Channel allocation;Autonomous aerial vehicles;Throughput;Unmanned aerial vehicles (UAV);fifth-generation (5G);fairness;deep reinforcement learning (DRL)},
doi={10.1109/TNSM.2021.3122505},
ISSN={1932-4537},
month={Dec},}
@INPROCEEDINGS{9145194,
author={Susarla, Praneeth and Deng, Yansha and Destino, Giuseppe and Saloranta, Jani and Mahmoodi, Toktam and Juntti, Markku and Sílven, Olli},
booktitle={2020 IEEE International Conference on Communications Workshops (ICC Workshops)}, title={Learning-Based Trajectory Optimization for 5G mmWave Uplink UAVs},
year={2020},
volume={},
number={},
pages={1-7},
abstract={A Connectivity-constrained based path planning for unmanned aerial vehicles (UAVs) is proposed within the coverage area of a 5G NR Base Station (BS) that uses mmWave technology. We consider an uplink communication between UAV and BS under multipath channel conditions for this problem. The objective is to guide a UAV, starting from a random location and reaching its destination within the BS coverage area, by learning a trajectory alongside achieving better connectivity. We propose simultaneous learning-based path planning of UAV and beam tracking at the BS side under urban macro-cellular(UMa) pathloss conditions, to reduce its sweeping time with apriori computational overhead using the deep reinforcement learning method such as Deep Q-Network (DQN). Our results show that our proposed learning-based joint path planning and beam tracking method is on par with the learning-based shortest path planning, besides beam tracking comparable to heuristic exhaustive beam searching method.},
keywords={Unmanned aerial vehicles;Uplink;5G mobile communication;Trajectory;Array signal processing;Base stations;5G;mmWave;reinforcement learning;UAVs;path planning;beamforming},
doi={10.1109/ICCWorkshops49005.2020.9145194},
ISSN={2474-9133},
month={June},}
@INPROCEEDINGS{9549299,
author={Zhou, Huan and Zhang, Senyu and Sun, Chu and Ru, Changjian},
booktitle={2021 40th Chinese Control Conference (CCC)}, title={Intelligent Maneuver Decision Method of UAV based on Reinforcement Learning and Neural Network},
year={2021},
volume={},
number={},
pages={8544-8549},
abstract={The efficiency of UAV maneuver decision-making based on the traditional maneuver control quantity is the key to restrict the improvement of UAV autonomous air combat game ability in complex battlefield environment. By refining pilots' combat training and air combat thinking experience, the intelligent maneuver decision-making method for UAV autonomous air combat can effectively improve the UAV autonomous air combat efficiency. Aiming at the problem of maneuver decision-making in continuous state space, this paper designs an autonomous maneuver decision-making model based on actor critical reinforcement learning theory, adopts NRBF neural network as the value function approximator, the action controller outputs continuous control variables, and introduces Gaussian random action variables to balance the problem of "exploration utilization" in strategy learning A state space adaptive adjustment method based on relative entropy distance is proposed to simplify the network structure and enhance the learning ability of the network. The simulation results show that the proposed method has the ability of air combat confrontation, the output control quantity is smooth, and the strategy learning efficiency is higher.},
keywords={Training;Adaptive systems;Simulation;Decision making;Neural networks;Refining;Reinforcement learning;UAV;Intelligent Decision;Reinforcement Learning;Neural Network and Autonomous Air Combat},
doi={10.23919/CCC52363.2021.9549299},
ISSN={1934-1768},
month={July},}
@INPROCEEDINGS{9492638,
author={Grasso, Christian and Raftopoulos, Raoul and Schembra, Giovanni},
booktitle={2021 IEEE 7th International Conference on Network Softwarization (NetSoft)}, title={Deep Q-Learning for Job Offloading Orchestration in a Fleet of MEC UAVs in 5G Environments},
year={2021},
volume={},
number={},
pages={186-190},
abstract={The fifth generation (5G) of mobile networks has the goal of providing ultra-high-speed access everywhere and enabling connectivity of massive number of devices in an ultra-reliable and affordable way. However, in many environments that are considered strategic for 5G applications, a structured network is not available. A solution to extend the features provided by Multi-access Edge Computing (MEC), one of the main enabler of 5G, in these contexts, is to use fleets of MEC UAVs, each equipped with a computing element (CE), and organized in Flying Ad-hoc Networks (FANET).In this paper, we propose a FANET platform with “horizontal” offload from the most overloaded UAVs to the least overloaded ones, aimed at balancing load among UAVs. A decision policy called UAV Smart Offloading (USO), based on Deep Reinforcement Learning, is also defined to optimize performance in terms of delay perceived by the ground devices connected to the FANET. A numerical analysis is introduced to evaluate performance achieved by the proposed platform.},
keywords={Performance evaluation;5G mobile communication;Numerical analysis;Conferences;Computational modeling;Reinforcement learning;Ad hoc networks;5G;Edge Computing;UAVs;Deep Reinforcement Learning;Markov Models},
doi={10.1109/NetSoft51509.2021.9492638},
ISSN={2693-9789},
month={June},}
@ARTICLE{9366889,
author={Seid, Abegaz Mohammed and Boateng, Gordon Owusu and Anokye, Stephen and Kwantwi, Thomas and Sun, Guolin and Liu, Guisong},
journal={IEEE Internet of Things Journal}, title={Collaborative Computation Offloading and Resource Allocation in Multi-UAV-Assisted IoT Networks: A Deep Reinforcement Learning Approach},
year={2021},
volume={8},
number={15},
pages={12203-12218},
abstract={In the fifth-generation (5G) wireless networks, Edge-Internet-of-Things (EIoT) devices are envisioned to generate huge amounts of data. Due to the limitation of computation capacity and battery life of devices, all tasks cannot be processed by these devices. However, mobile-edge computing (MEC) is a very promising solution enabling offloading of tasks to nearby MEC servers to improve quality of service. Also, during emergency situations in areas where network failure exists, unmanned aerial vehicles (UAVs) can be deployed to restore the network by acting as Aerial Base Stations and computational nodes for the edge network. In this article, we consider a central network controller who trains observations and broadcasts the trained data to a multi-UAV cluster network. Each UAV cluster head acts as an agent and autonomously allocates resources to EIoT devices in a decentralized fashion. We propose model-free deep reinforcement learning (DRL)-based collaborative computation offloading and resource allocation (CCORA-DRL) scheme in an aerial to ground (A2G) network for emergency situations, which can control the continuous action space. Each agent learns efficient computation offloading policies independently in the network and checks the statuses of the UAVs through Jain's Fairness index. The objective is minimizing task execution delay and energy consumption and acquiring an efficient solution by adaptive learning from the dynamic A2G network. Simulation results reveal that our scheme through deep deterministic policy gradient, effectively learns the optimal policy, outperforming A3C, deep Q-network and greedy-based offloading for local computation in stochastic dynamic environments.},
keywords={Task analysis;Internet of Things;Resource management;Unmanned aerial vehicles;Quality of service;Computational modeling;Energy consumption;Collaborative computation offloading;deep reinforcement learning (DRL);Edge Internet of Things (EIoT);IoT network;multi-UAV network;resource allocation},
doi={10.1109/JIOT.2021.3063188},
ISSN={2327-4662},
month={Aug},}
@INPROCEEDINGS{9723260,
author={Gu, Jerry and Soltani, Nasim and Naderi, M. Yousof and Chowdhury, Kaushik R.},
booktitle={2021 55th Asilomar Conference on Signals, Systems, and Computers}, title={It’s a Bird, It’s a Plane, It’s "That" UAV: RF Fingerprinting During Flight},
year={2021},
volume={},
number={},
pages={300-304},
abstract={UAVs are being rapidly deployed in many surveillance-related and monitoring applications worldwide. Thus, identifying a known UAV in a larger pool of devices is important. This task is often complicated in dense urban environments or low-level flight deployment cases where traditional radar-based detection becomes difficult. In this work, we describe deep convolutional neural network architectures and pre-processing steps suitable for capturing RF signals from in-flight UAVs for detection of the type of the UAV. Our objective is to leverage subtle discriminative features that may be embedded in the signal transmissions through RF fingerprinting for identifying (i) if the test signal comes from an unseen UAV (with respect to the training set), and (ii) if it is from a seen UAV, then we identify the label used during training time. Unlike static data collections, the mobile scenario is more challenging due to the rapid fluctuations in the wireless channel and Doppler effects which impair successful classification. We study the efficacy of our approach under different distances, flight/mobility patterns, interference conditions to emulate real-world situations with high fidelity. Our experimental dataset contains signals from seven different make/models, collected within an RF anechoic chamber.},
keywords={Radio frequency;Training;Wireless communication;Urban areas;Computer architecture;Fingerprint recognition;Object recognition;UAV RF Fingerprinting;Convolutional Neural Networks;New UAV Detection},
doi={10.1109/IEEECONF53345.2021.9723260},
ISSN={2576-2303},
month={Oct},}
@INPROCEEDINGS{6778130,
author={Awan, Asad Ullah},
booktitle={Proceedings of 2014 11th International Bhurban Conference on Applied Sciences Technology (IBCAST) Islamabad, Pakistan, 14th - 18th January, 2014}, title={Output feedback dynamic surface controller for quadrotor UAV with actuator dynamics},
year={2014},
volume={},
number={},
pages={97-102},
abstract={In this work, we develop an output feedback altitude-attitude controller for quadrotor UAV in the presence of uncertainties in UAV and actuator dynamics. Controller design for the quadrotor UAV is a difficult task due to its uncertain nonlinear dynamics. Unlike most previous works, we also consider uncertain actuator dynamics into the model construction of the UAV. For state estimation, a nonlinear observer using neural networks is designed. For the controller, the dynamic surface control technique has been used, which has the advantage of less complexity as compared to the conventional backstepping technique. The closed loop stability is proved using Lyapunov stability analysis. Unlike previously published techniques, we do not assume actuator signals are available for measurement in the observer/controller design. Simulation results are presented to demonstrate the effectiveness of the controller in presence of uncertainties in quadrotor UAV and actuator dynamics.},
keywords={Actuators;Observers;Robots;Neural networks;Adaptation models;Output feedback;Stability analysis;Quadrotor;UAV;Output feedback;Actuator;Dynamic Surface Control;Neural Networks},
doi={10.1109/IBCAST.2014.6778130},
ISSN={2151-1411},
month={Jan},}
@ARTICLE{9130726,
author={Jardine, Peter T. and Givigi, Sidney N. and Yousefi, Shahram},
journal={IEEE Systems Journal}, title={Leveraging Data Engineering to Improve Unmanned Aerial Vehicle Control Design},
year={2021},
volume={15},
number={2},
pages={2595-2606},
abstract={The potential benefits of big data and machine learning techniques are yet to be fully realized in real-time, safety-critical applications like unmanned aerial vehicle control. This is because of challenges related to interpretation, error susceptibility, and resources requirements. Due to their robustness and reliability, traditional model-based design techniques still dominate this landscape. However, a growing body of research in adaptive control has demonstrated the potential benefits of merging these two distinct design philosophies. This article investigates the benefits of using a combination of machine learning techniques to automatically tune parameters within a strictly defined model predictive control architecture. Fast orthogonal search and finite action-set learning automata are used to tune model coefficients and objective function weights, respectively. The strategy is validated experimentally on an actual Quanser Qball2 quadcopter and through several simulations of a Parrot AR.drone. Results demonstrate that the proposed approach improves performance while reducing design effort.},
keywords={Unmanned aerial vehicles;Vehicle dynamics;Reinforcement learning;Adaptive control;Control systems;Real-time systems;Analytical models;Model predictive control (MPC);reinforcement learning;unmanned aerial vehicles (UAVs)},
doi={10.1109/JSYST.2020.3003203},
ISSN={1937-9234},
month={June},}
@INPROCEEDINGS{9497627,
author={Přihodová, Kateřina and Jech, Jakub},
booktitle={2021 International Conference on Information and Digital Technologies (IDT)}, title={Gender recognition using thermal images from UAV},
year={2021},
volume={},
number={},
pages={83-88},
abstract={Gender recognition is one of the issues that computer vision deals with. It is useful for analysing human behaviour, intelligent tracking, or human-robot interaction. The aim of this paper is to recognise the gender of people in outdoor areas, where it is very difficult or impossible to guard all access roads to the place, even in poor lighting conditions or in the dark. In this paper, a model will be designed and tested using a controlled UAV flight, during which images of people were obtained. The sensor is a thermal camera located on the UAV, which is not dependent on ambient lighting, and deep learning methods are used for subsequent image processing and classification. These are convolutional neural networks (AlexNet, GoogLeNet), which will be used to solve binary classification. Optimized networks achieve classification accuracy of 81.6 %% (GoogLeNet) and 82.3% (AlexNet). A freely available database [21] was used to learn CNNs, and a self-created database (images obtained with a thermal camera attached to a UAV) was used to test the networks.},
keywords={Image recognition;Image resolution;Databases;Face recognition;Roads;Lighting;Thermal sensors;gender recognition;thermal image;UAV;convolutional neural networks},
doi={10.1109/IDT52577.2021.9497627},
ISSN={2575-677X},
month={June},}
@INPROCEEDINGS{7894058,
author={Kim, Juhyun and Park, Cheonbok and Ahn, Jinwoo and Ko, Youlim and Park, Junghyun and Gallagher, John C.},
booktitle={2017 IEEE Sensors Applications Symposium (SAS)}, title={Real-time UAV sound detection and analysis system},
year={2017},
volume={},
number={},
pages={1-5},
abstract={In this paper, we present a real-time drone detection and monitoring system, that users can easily utilize in daily life to detect drones using sound data. This system performs FFT on the sampled real-time data and performs drone detection using the transformed data through two different methods, Plotted Image Machine Learning (PIL) and K Nearest Neighbors (KNN). The PIL uses image data from the visualized FFT graph to detect robust points, and compares the average image similarity with a reference FFT template associated with a target of interest. Whereas, the KNN uses FFT-format csv files to compare the average distance similarity. Experiments were performed with the two methods. As a result, the accuracy rate of 83% and 61% was shown in each of PIL and KNN. The major deliverables of this work are a software package framework one may use to experiment with various sound samples and classifiers via modifiable classifier modules and initial testing of two classifiers. Future work, enabled by the software framework developed, can employ more capable classifiers.},
keywords={Drones;Real-time systems;Electronic mail;Testing;Monitoring;Machine learning algorithms;Bars;Audio categorization;Audio classification;k-nn;UAV categorization;UAV analysis;Machine learning;Structural similarity index},
doi={10.1109/SAS.2017.7894058},
ISSN={},
month={March},}
@INPROCEEDINGS{9367568,
author={Hashima, Sherief and Hatano, Kohei and Mohamed, Ehab Mahmoud},
booktitle={2020 IEEE Globecom Workshops (GC Wkshps}, title={Multiagent Multi-Armed Bandit Schemes for Gateway Selection in UAV Networks},
year={2020},
volume={},
number={},
pages={1-6},
abstract={Lately, unmanned aerial vehicles (UAVs) communications acquired great attention because of its weighty new applications, particularly in rescue services. In such a case, access and gateway UAVS are spread to cover and fully support communications over disaster areas where the ground network is malfunctioned or wholly damaged. Each access UAV collects essential information from its assigned area, then flies and transfers it to the nearby gateway UAVs that deliver this collected information to the closest operating ground network. Meanwhile, collisions may occur as two or more access UAVs might target the same gateway UAV. This paper leverages and modifies two multi-armed bandit (MAB) based algorithms, namely, Kullback Leibler upper confidence bound (KLUCB) and minimax optimal stochastic strategy (MOSS) to formulate the gateway UAV selection issue. The issue is modeled as a budget-constrained multiagent MAB (MA-MAB) that maximizes data rates while considering access UAVs' flight battery consumption. Hence, MA battery aware KLUCB (MABA-KLUCB) and battery aware MOSS (MA-BA-MOSS) algorithms are proposed for efficient gateway UAV selection. The proposed MAB algorithms maximize the UAV network's total sum rate over the conventional selection techniques with assuring good convergence performance.},
keywords={Conferences;Stochastic processes;Logic gates;Unmanned aerial vehicles;Data models;Batteries;Convergence;Multiagent MAB;Machine learning;UAV;Gateway UAV selection;KLUCB;MOSS},
doi={10.1109/GCWkshps50303.2020.9367568},
ISSN={},
month={Dec},}
@INPROCEEDINGS{8875408,
author={Xu, Jianwen and Ota, Kaoru and Dong, Mianxiong},
booktitle={2019 International Conference on Internet of Things (iThings) and IEEE Green Computing and Communications (GreenCom) and IEEE Cyber, Physical and Social Computing (CPSCom) and IEEE Smart Data (SmartData)}, title={LUNA: Lightweight UAV Navigation Based on Airborne Vision for Disaster Management},
year={2019},
volume={},
number={},
pages={315-322},
abstract={Natural disasters such as earthquakes, typhoons are bringing huge casualties and property losses every year. As an emerging research hotspot, UAV technology has demonstrated its potential in many areas, including the issues within disaster management. In this paper, we focus on the problem of autonomous UAV navigation based on the airborne vision and deep learning. Facing the poor conditions in disasters, we often cannot expect drones with limited power supply and processing capacity to complete heavy operations. For the task of autonomous navigation, existed methods mainly rely on sophisticated multi-device collaboration which may be difficult to quickly be deployed in an emergency. As a result, we propose a lightweight navigation strategy based on gimbal camera and onboard processing module to help achieve autonomous path-finding of UAVs in the post-disaster scenario. Our solutions can take effect on miniature UAV while being assisted by task offloading device such as mobile phones. The simulation results show that our proposed LUNA system can enable UAVs to automatically sense the disaster environment and take corresponding measures of in-flight adjustment.},
keywords={Deep learning;Atmospheric modeling;Navigation;Disaster management;Task analysis;Image recognition;Cameras;UAV autonomous navigation;disaster management;deep learning;image recognition},
doi={10.1109/iThings/GreenCom/CPSCom/SmartData.2019.00073},
ISSN={},
month={July},}
@ARTICLE{9548052,
author={Lee, Harim and Kim, Myeung Un and Kim, Yeongjun and Lyu, Hyeonsu and Yang, Hyun Jong},
journal={IEEE Access}, title={Development of a Privacy-Preserving UAV System With Deep Learning-Based Face Anonymization},
year={2021},
volume={9},
number={},
pages={132652-132662},
abstract={In this paper, we develop a privacy-preserving UAV system that does not infringe on the privacy of people in the videos taken by UAVs. Instead of blurring or masking the face parts of the videos, we want to exquisitely modify only the face parts so that the people in the modified videos still look like humans, but they become anonymous. Doing so, the semantic information of the videos can be preserved even with the anonymization. Specifically, based on the latest generative adversarial network architecture, we propose a deep learning-based face-anonymization scheme so that each modified face part looks like the face of a person who does not actually exist. The trained face-anonymizer is then mounted on the UAV system we have implemented. Through experiments, we confirm that the developed privacy-preserving UAV system anonymizes UAV’s first-person videos so that the people in the video are not recognized as anyone in the dataset used. In addition, we show that even with such anonymized videos, the perception performance required for performing UAV’s essential functions such as simultaneous localization and mapping is not degraded.},
keywords={Face recognition;Faces;Videos;Training;Privacy;Unmanned aerial vehicles;Semantics;Privacy infringement;privacy-preserving vision;deep learning;security robot;UAV patrol system},
doi={10.1109/ACCESS.2021.3113186},
ISSN={2169-3536},
month={},}
@INPROCEEDINGS{9643249,
author={Raja, Ashok and Njilla, Laurent and Yuan, Jiawei},
booktitle={2021 IEEE 33rd International Conference on Tools with Artificial Intelligence (ICTAI)}, title={Blur the Eyes of UAV: Effective Attacks on UAV-based Infrastructure Inspection},
year={2021},
volume={},
number={},
pages={661-665},
abstract={Unmanned aerial vehicles (UAVs) are increasingly leveraged to perform infrastructure inspection tasks, especially with the support of rapidly evolving AI algorithms and hardware in recent years. While the integration of UAV and AI techniques enhances the efficiency and effectiveness of infrastructure inspection, it also raises security concerns due to the potential vulnerabilities existing in the underlying AI models. In this paper, we propose to investigate and discover these vulnerabilities with the case study on bridge inspection. In particular, we designed a two-stage approach that can construct effective adversarial perturbations that make the UAV miss the detection of risk-prone regions during the inspection. Spatial constraints, physical limits, as well as dynamic environmental changes are taken into consideration in our approach to make it practical in the physical world. We evaluate our approach using the COCO-Bridge dataset. Our experimental results demonstrate the effectiveness of our approach in both white-box attack and black-box attack settings.},
keywords={Bridges;Perturbation methods;Inspection;Autonomous aerial vehicles;Robustness;Hardware;Security;UAV Security;UAV-based Inspection;Deep Learning},
doi={10.1109/ICTAI52525.2021.00105},
ISSN={2375-0197},
month={Nov},}
@ARTICLE{9454157,
author={Chai, Shuqi and Lau, Vincent K. N.},
journal={IEEE Journal on Selected Areas in Communications}, title={Multi-UAV Trajectory and Power Optimization for Cached UAV Wireless Networks With Energy and Content Recharging-Demand Driven Deep Learning Approach},
year={2021},
volume={39},
number={10},
pages={3208-3224},
abstract={In this paper, we propose a novel joint trajectory and communication scheduling scheme for multiple unmanned aerial vehicles (UAVs) enabled wireless caching networks. To exploit the favorable propagation of air-to-ground channels, we consider an ultra dense UAVs enabled content-centric wireless transmission network, where massive UAVs are deployed to transmit cached contents to a group of random distributed ground users. We formulate the problem as an infinite horizon ergodic stochastic differential game (SDG) for optimizing the users' quality-of-experience (QoE). In particular, stochastic dynamics of channel states, UAVs' mobility, energy queues and content request queues are modeled in this game. To deal with the state coupling between the UAVs, we consider a limiting problem for large number of UAV based on mean field analysis. A reduced-complexity decentralized solution can be obtained through mean-field equilibrium analysis. To further reduce the solution complexity on each UAV, we propose a model-specific deep neural network (DNN) to learn the optimal control solution in an online manner. The DNN is not arbitrarily generated but tailored to the structural properties of the value function and stationary distribution based on the homotopy perturbation method analysis. Finally, simulation results are provided to show that the proposed solution can achieve significant gain over the existing baselines.},
keywords={Trajectory;Unmanned aerial vehicles;Wireless networks;Stochastic processes;Mathematical model;Couplings;Games;UAV caching networks;multi-UAV trajectory design;radio resource control;mean-field game;deep learning},
doi={10.1109/JSAC.2021.3088694},
ISSN={1558-0008},
month={Oct},}
@INPROCEEDINGS{9594332,
author={Simpson, Todd},
booktitle={2021 IEEE/AIAA 40th Digital Avionics Systems Conference (DASC)}, title={Real-Time Drone Surveillance System for Violent Crowd Behavior Unmanned Aircraft System (UAS) – Human Autonomy Teaming (HAT)},
year={2021},
volume={},
number={},
pages={1-9},
abstract={Unmanned Aerial Systems (UASs), or drones, continue to increase in capabilities and sophistication across a wide range of applications. UASs have high mobility, are easily deployed, and capable of real-time monitoring of crowd behavior by utilizing multi-sensor-based detection and remote sensing of objects. These capabilities make UASs a very useful tool for Human Autonomy Teaming (HAT) applications, such as Law Enforcement (LE), capitalizing on Human Factors (HF). This study examines the concept of leveraging drone technology together with Artificial Intelligence (AI) and Machine Learning (ML) methods to produce a UAS system that can assist LE in the monitoring and assessment of crowd behaviors during peaceful and non-peaceful events. LE agencies are increasingly being tasked with engaging in dynamic environments that exist at public events. Utilized as a force multiplier and autonomous tool, would benefit from an AI-UAS platform utilizing artificial intelligence assisting in identifying behavior of peaceful people as opposed to malevolent participants or instigators that may attempt to take control. AI-UASs of this type would allow LE to leverage existing resources within their organizational structures and provide increased situation awareness via a Live Virtual Constructive (LVC) broadcast and monitoring of these dynamic environments. Information provided from these AI-UAS systems would provide real-time information to field forces as well as command and control operations that may be remotely located. AI-UAS Sensors can be dynamically allocated as needed for monitoring/documenting crowd behavior and police actions. Video recordings would provide evidence in court as well counter truth-bending recordings published by professional protestors and agenda driven main-stream media outlets. The benefits and impact of this type of LE AI-UAS platform would be profound. Traditional visible light based sensors can be greatly influenced by environmental factors preventing their ability to determine variations regarding abnormal crowd behaviors. In order to overcome this challenge, this project proposes to utilize four types of collection methods, Multitask Cascading CNN (MC-CNN), ScatterNet Hybrid Deep Learning Network, multiscale infrared optical flow (MIR-OF), and Event Cameras such as Event-based Vision, and Event Camera SLAM (Simultaneous Localization and Mapping). AI methods will be developed to monitor crowd density, average ground speed, human pose estimations, and movement behaviors, as well as identification of primary violent instigators. This proposed system will detect violent individuals in real-time by leveraging onboard image processing as well as cloud processing. Fundamental research for this project is inspired and built upon recent Drone Surveillance System (DSS) publications from IEEE and MDPI.},
keywords={Simultaneous localization and mapping;Law enforcement;Surveillance;Dynamics;Tools;Aerospace electronics;Cameras;Unmanned Aerial Systems;UAS;UAV;Drone;Artificial Intelligence;Machine Learning;Human Autonomy Teaming;Crowd Behavior Prediction;Real-time Monitoring;Loihi;True North;Neuromorphic Computing;Crowd Control;Wright State University;Sinclair College;Human Factors},
doi={10.1109/DASC52595.2021.9594332},
ISSN={2155-7209},
month={Oct},}
@INPROCEEDINGS{9272196,
author={Calderón, Manolo Paredes and Calderón Merino, Marco and Marquínez, Josué Riquelme and Jiménez, Darwin Merizalde},
booktitle={2020 IEEE ANDESCON}, title={Multipurpose unmanned system: an efficient solution to increase the capabilities of the UAVs},
year={2020},
volume={},
number={},
pages={1-6},
abstract={The results of this research propose the implementation of a system that significantly increases the capacity of unmanned vehicles, turning them into multifunctional vehicles. The system has a logistics dispatch module and a video analytics module. The first module allows the delivery of medical, food, smoke, disinfectant, etc. The module is practical, safe and economical, features that denote the feasibility of immediate implementation in unmanned vehicles of any rank and / or classification. Note that the implementation of the dispatch module does not require additional radio frequency systems. The second module includes a video analysis process in real time, an aspect that constitutes a significant contribution to the proposed solution, since it allows obtaining important information during the flight; it also reduces the risk in air operations and simultaneously increases the efficiency of themselves. Note that video analytics optimizes resources and avoids jeopardizing the lives of aircraft pilots and crews who traditionally should carry out these activities. In times of pandemic, this innovation avoids direct contact with an infected population and can guarantee the sanitary conditions required in certain circumstances. The solution increases the capabilities of unmanned vehicles and makes them useful tools in various scenarios, whether caused by natural or man-made disasters. Our proposal is very flexible, reliable, and scalable and can be adapted to various models and makes of unmanned vehicles. The system has been implemented on fixed-wing and rotary-wing unmanned vehicles, showing satisfactory results.},
keywords={Real-time systems;Visual analytics;Pandemics;Streaming media;Meters;Logistics;Neural networks;artificial intelligence;control systems;deep learning;Pandemic;image processing;UAVs;video analytics},
doi={10.1109/ANDESCON50619.2020.9272196},
ISSN={},
month={Oct},}
@INPROCEEDINGS{8358297,
author={Shijith, N and Poornachandran, Prabaharan and Sujadevi, V G and Dharmana, Meher Madhu},
booktitle={2017 Recent Developments in Control, Automation Power Engineering (RDCAPE)}, title={Breach detection and mitigation of UAVs using deep neural network},
year={2017},
volume={},
number={},
pages={360-365},
abstract={Unmanned Aerial Vehicles (UAV) has become ubiquitous. While there are several applications for UAV, it is also considered as a threat to the privacy and physical security. In this work we attempt to detect the invading UAV's with a goal of disabling them when they are invading a physical space. Identification of the UAV is performed by analyzing the live video feeds from cameras that are from Fixed CCTV cameras and surveillance drones. We propose to use image processing using convolutional neural network (CNN) for detecting the presence of the drones. Once the invading drone is identified, the information is sent to the Signal Jammer system. Our prototype shows very promising results that encourages us to pursue in building a real-world system.},
keywords={Drones;Training;Jamming;Convolutional neural networks;Cameras;UAV;Object detection;Artificial Intelligence;Convolutional Neural Network;CNN;Deep Learning;Signal jamming},
doi={10.1109/RDCAPE.2017.8358297},
ISSN={},
month={Oct},}
@INPROCEEDINGS{9248139,
author={Liu, Hansen and Fan, Kuanaana and He, Bing},
booktitle={2020 15th IEEE Conference on Industrial Electronics and Applications (ICIEA)}, title={Acoustic Source Localization for Anti-UAV Based on Machine Learning in Wireless Sensor Networks},
year={2020},
volume={},
number={},
pages={1142-1147},
abstract={Unmanned aerial vehicles (UAVs) have developed rapidly and are widely used in many fields. This phenomenon also causes security problems that urgently need to be addressed by anti-UAV technique. The localization of UAV plays an important role in anti-UAV system. An acoustic source localization scheme based on machine learning (ML) in wireless sensor networks is proposed in this study. Five ML algorithms, namely, artificial neural network (ANN), Naive Bayes, decision tree (DT), K nearest neighbors (KNN) and random forest (RF), are designed to estimate the coordinate of a single UAV. The acoustic energy decay model is constructed to simulate the attenuation and distortion caused by the ambient noise and changing surroundings. We use both received signal strength (RSS) based on acoustic energy and the difference of RSS as the input. Our experiments show that ML algorithms perform well except ANN. For ambient noise case, the ones with the input we propose achieve better localization accuracy than those only using RSS. KNN and RF are more suitable and reliable models for localization.},
keywords={Radio frequency;Wireless sensor networks;Maximum likelihood estimation;Machine learning algorithms;Artificial neural networks;Acoustics;Unmanned aerial vehicles;acoustic source localization;anti-UAV;machine learning;received signal strength;wireless sensor networks},
doi={10.1109/ICIEA48937.2020.9248139},
ISSN={2158-2297},
month={Nov},}
@ARTICLE{9609973,
author={Galkin, Boris and Fonseca, Erika and Amer, Ramy and A. DaSilva, Luiz and Dusparic, Ivana},
journal={IEEE Transactions on Vehicular Technology}, title={REQIBA: Regression and Deep Q-Learning for Intelligent UAV Cellular User to Base Station Association},
year={2022},
volume={71},
number={1},
pages={5-20},
abstract={Unmanned Aerial Vehicles (UAVs) are emerging as important users of next-generation cellular networks. By operating in the sky, UAV users experience very different radio conditions than terrestrial users, due to factors such as strong Line-of-Sight (LoS) channels (and interference) and Base Station (BS) antenna misalignment. As a consequence, the UAVs may experience significant degradation to their received quality of service, particularly when they are moving and are subject to frequent handovers. The solution is to allow the UAV to be aware of its surrounding environment, and intelligently connect into the cellular network taking advantage of this awareness. In this paper we present REgression and deep Q-learning for Intelligent UAV cellular user to Base station Association (REQIBA), a solution that allows a UAV flying over an urban area to intelligently connect to underlying BSs, using information about the received signal powers, the BS locations, and the surrounding building topology. We demonstrate how REQIBA can as much as double the total UAV throughput, when compared to heuristic association schemes similar to those commonly used by terrestrial users. We also evaluate how environmental factors such as UAV height, building density, and throughput loss due to handovers impact the performance of our solution.},
keywords={Trajectory;Handover;Unmanned aerial vehicles;Interference;Cellular networks;Throughput;Buildings;Cellular-connected UAVs;machine learning;reinforcement learning},
doi={10.1109/TVT.2021.3126536},
ISSN={1939-9359},
month={Jan},}
@ARTICLE{9740222,
author={Guo, Hongzhi and Zhou, Xiaoyi and Wang, Yutao and Liu, Jiajia},
journal={IEEE Internet of Things Journal}, title={Achieve Load Balancing in Multi-UAV Edge Computing IoT Networks: A Dynamic Entry and Exit Mechanism},
year={2022},
volume={},
number={},
pages={1-1},
abstract={With the gradual commercialization of 5G, especially the widespread application of AI technology, the Internet of Things (IoT) continues to expand and has integrated into every aspect of our lives. While enjoying the convenience brought by IoT, we also face unprecedented challenges including ubiquitous and unpredictable demands for communication and computing resources. In consideration of their flexible deployment, low cost, and easy expansion, UAV edge computing IoT networks (UECIN), which adopt UAVs to provide fast communication and computing services, have emerged as a promising solution. Note that there have been a number of studies focusing on UAV’s position deployment and trajectory design, resource allocation in UECIN. However, most existing works proposed short-term service provisioning systems with a fixed number of UAVs, ignoring the problem of UAVs’ limited battery power and the possible changes of ground users’ number, locations and resource requirements. To address these issues, we present a dynamic UECIN framework with autonomous prediction characteristics, aiming to stably provide mobile edge computing services for ground users in a certain area over a long period of time. This framework cannot only support UAV’s dynamic entry and exit according to the real-time needs of ground users, but also update their position deployment based on the distribution of ground users. As we know, we are the first to propose UECIN with a dynamic entry and exit mechanism. Besides, an efficient and load-balancing task allocation scheme is further given, and extensive analysis and numerical results corroborate the feasibility and superior performance of our framework.},
keywords={Autonomous aerial vehicles;Task analysis;Internet of Things;Batteries;Load management;Vehicle dynamics;Resource management;Multi-UAV;IoT networks;mobile edge computing;entry and exit mechanism;load balancing;neural networks.},
doi={10.1109/JIOT.2022.3161703},
ISSN={2327-4662},
month={},}
@INPROCEEDINGS{7869856,
author={El Dakrory, Ahmed M. and Tawfik, Mohammad},
booktitle={2016 International Workshop on Recent Advances in Robotics and Sensor Technology for Humanitarian Demining and Counter-IEDs (RST)}, title={Identifying the attitude of dynamic systems using neuralnetwork},
year={2016},
volume={},
number={},
pages={1-4},
abstract={Modeling of dynamic systems using system identification became an important discipline as it overrides the errors that may be introduced by traditional modelling techniques. There are two methodologies for identification of systems' models; statistical and deterministic methods. Identification algorithms are proposed in this paper using deterministic neural network and compare the results with regression method. Here the authors are interested in identifying the input output relation of many dynamic systems such as satellites, UAV, Quadcopters etc.....},
keywords={Artificial neural networks;Unmanned aerial vehicles;Control systems;Computational modeling;Data models;System identification;neural networks;quadcopter;uav;narx;system;regression;raspberry pi},
doi={10.1109/RST.2016.7869856},
ISSN={},
month={Oct},}
@INPROCEEDINGS{9323702,
author={Gebrehiwot, Asmamaw and Hashemi-Beni, Leila},
booktitle={IGARSS 2020 - 2020 IEEE International Geoscience and Remote Sensing Symposium}, title={Automated Indunation Mapping: Comparison of Methods},
year={2020},
volume={},
number={},
pages={3265-3268},
abstract={High-resolution imagery is increasingly used to detect flooded areas during a crisis situation. The article presents a comparison of four image classification methods for flood extent mapping. The methods include Random Forest (RF), support vector machine (SVM), fully convolutional network (FCN), and normalized difference water index (NDWI). High-resolution UAV imagery collected during Hurricane Matthew (2016) flood events were used to evaluate the classification methods for generating an accurate flood extent map. In this study, a fully convolutional network fine-tuned to segment the inundation areas. RF, SVM, and NDWI are implemented using the same dataset used for mapping flood extents. The results show that the FCN achieved an overall accuracy of 97.72%, followed by NDWI with 96.0%, SVM with 88.9%, and 87.8 % of RF. The results imply that FCN is more efficient than RF, SVM, and NDWI on generating real-time flood extent maps.},
keywords={Floods;Support vector machines;Radio frequency;Training;Remote sensing;Indexes;Feature extraction;Flood;Remote Sensing;Convolutional Neural Networks;Fine-tuning;UAV;Data Analytic},
doi={10.1109/IGARSS39084.2020.9323702},
ISSN={2153-7003},
month={Sep.},}
@INPROCEEDINGS{8441366,
author={Ichim, Loretta and Popescu, Dan},
booktitle={2018 41st International Conference on Telecommunications and Signal Processing (TSP)}, title={Road Detection and Segmentation from Aerial Images Using a CNN Based System},
year={2018},
volume={},
number={},
pages={1-5},
abstract={This paper proposes a system architecture based on deep convolutional neural network (CNN) for road detection and segmentation from aerial images. These images are acquired by an unmanned aerial vehicle implemented by the authors. The algorithm for image segmentation has two phases: the learning phase and the operating phase. The input aerial images are decomposed in their color components, preprocessed in Matlab on Hue channel and next partitioned in small boxes of dimension 33 × 33 pixels using a sliding box algorithm. These boxes are considered as inputs into a deep CNN. The CNN was designed using MatConvNet and has the following structure: four convolutional layers, four pooling layers, one ReLu layer, one full connected layer, and a Softmax layer. The whole network was trained using a number of 2,000 boxes. The CNN was implemented using programming in MATLAB on GPU and the results are promising. The proposed system has the advantage of processing speed and simplicity.},
keywords={Roads;Image segmentation;Training;Unmanned aerial vehicles;Image resolution;Convolutional neural networks;aerial images;convolutional neural networks;road detection;segmentation;unmanned aerial vehicles (UAV)},
doi={10.1109/TSP.2018.8441366},
ISSN={},
month={July},}
@INPROCEEDINGS{8804776,
author={Palossi, Daniele and Conti, Francesco and Benini, Luca},
booktitle={2019 15th International Conference on Distributed Computing in Sensor Systems (DCOSS)}, title={An Open Source and Open Hardware Deep Learning-Powered Visual Navigation Engine for Autonomous Nano-UAVs},
year={2019},
volume={},
number={},
pages={604-611},
abstract={Nano-size unmanned aerial vehicles (UAVs), with few centimeters of diameter and sub-10 Watts of total power budget, have so far been considered incapable of running sophisticated visual-based autonomous navigation software without external aid from base-stations, ad-hoc local positioning infrastructure, and powerful external computation servers. In this work, we present what is, to the best of our knowledge, the first 27g nano-UAV system able to run aboard an end-to-end, closed-loop visual pipeline for autonomous navigation based on a state-of-the-art deep-learning algorithm, built upon the open-source CrazyFlie 2.0 nano-quadrotor. Our visual navigation engine is enabled by the combination of an ultra-low power computing device (the GAP8 system-on-chip) with a novel methodology for the deployment of deep convolutional neural networks (CNNs). We enable onboard real-time execution of a state-of-the-art deep CNN at up to 18Hz. Field experiments demonstrate that the system's high responsiveness prevents collisions with unexpected dynamic obstacles up to a flight speed of 1.5m/s. In addition, we also demonstrate the capability of our visual navigation engine of fully autonomous indoor navigation on a 113m previously unseen path. To share our key findings with the embedded and robotics communities and foster further developments in autonomous nano-UAVs, we publicly release all our code, datasets, and trained networks.},
keywords={Navigation;Visualization;Engines;Task analysis;Microcontrollers;Robot sensing systems;Cameras;autonomous navigation, nano-size UAVs, deep learning, CNN, heterogeneous computing, parallel ultra-low power, bio-inspired},
doi={10.1109/DCOSS.2019.00111},
ISSN={2325-2944},
month={May},}
@INPROCEEDINGS{8396188,
author={Wang, Cong and Zhao, Rui and Yang, Xiao and Wu, Qi},
booktitle={2018 International Conference on Artificial Intelligence and Big Data (ICAIBD)}, title={Research of UAV target detection and flight control based on deep learning},
year={2018},
volume={},
number={},
pages={170-174},
abstract={Deep learning has attracted widespread attention and has achieved good recognition results in image recognition and detection. Based on the Faster R-CNN algorithm, this paper studies the application of deep learning in drones and verifies its effect on target detection. In the most of existing schemes, the drone compresses the image and transmits it to the ground station for further detection, and then the resulting control command is transmitted back to the drone. This requires high bandwidth and high transmission delay, which limits the response speed of the system. In order to overcome the above shortcomings, the system will use the embedded system mounted on the UAV for image processing and pattern recognition, which saves transmission bandwidth and shortens response time. Through the Faster R-CNN target recognition algorithm, the UAV's target detection and flight control based on deep learning is finally realized. We performed HITL simulations of Pixhawk based on Gazebo in the ROS environment, and finally verified the feasibility of the algorithm.},
keywords={Proposals;Drones;Feature extraction;Target recognition;Machine learning;Object detection;Cameras;UAV;deep learning;faster R-CNN;detection},
doi={10.1109/ICAIBD.2018.8396188},
ISSN={},
month={May},}
@INPROCEEDINGS{8756696,
author={Kinaneva, Diyana and Hristov, Georgi and Raychev, Jordan and Zahariev, Plamen},
booktitle={2019 42nd International Convention on Information and Communication Technology, Electronics and Microelectronics (MIPRO)}, title={Early Forest Fire Detection Using Drones and Artificial Intelligence},
year={2019},
volume={},
number={},
pages={1060-1065},
abstract={Forest and urban fires have been and still are serious problem for many countries in the world. Currently, there are many different solutions to fight forest fires. These solutions mainly aim to mitigate the damage caused by the fires, using methods for their early detection. In this paper, we discuss a new approach for fire detection and control, in which modern technologies are used. In particular, we propose a platform that uses Unmanned Aerial Vehicles (UAVs), which constantly patrol over potentially threatened by fire areas. The UAVs also utilize the benefits from Artificial Intelligence (AI) and are equipped with on-board processing capabilities. This allows them to use computer vision methods for recognition and detection of smoke or fire, based on the still images or the video input from the drone cameras. Several different scenarios for the possible use of the UAVs for forest fire detection are presented and analyse in the paper, including a solution with the use of a combination between a fixed and rotary-wing drones.},
keywords={early forest fire detection platform;drones;UAVs;artificial intelligence;computer vision},
doi={10.23919/MIPRO.2019.8756696},
ISSN={2623-8764},
month={May},}
@INPROCEEDINGS{5486961,
author={Pang Rui},
booktitle={2010 2nd International Conference on Advanced Computer Control}, title={Multi-UAV formation maneuvering control based on Q-Learning fuzzy controller},
year={2010},
volume={4},
number={},
pages={252-257},
abstract={On the basis of the relative motion relations of the formation flight, UAV longitudinal and lateral fuzzy controllers are designed to solve the multi-UAV formation control problem. The relative positions between adjacent UAVs are controlled to meet the desired commands and performance requirements. Q-Learning method, which is one kind of reinforcement learning, is used to tune the corresponding parameters in output membership functions of fuzzy controller. This auto-tuning avoids the complexity of manual tuning with expert experience and eliminates the steady state errors. Also, different conditions including coordinative turning, tense-loose shape changing, shape sequence changing and collision avoiding are simulated with the formation control methodology, which is comprised of centralized decision and decentralized control. The results prove the correctness of control method and formation control strategy under the circumstances of different formation maneuvering demands.},
keywords={Fuzzy control;Unmanned aerial vehicles;Shape control;Automatic control;Motion control;Learning;Adaptive control;Nonlinear control systems;Programmable control;Linear feedback control systems;Reinforcement learning;Q-learning;fuzzy control;UAVs;Formation Flight;Maneuvering},
doi={10.1109/ICACC.2010.5486961},
ISSN={},
month={March},}
@INPROCEEDINGS{9337696,
author={Ye, Shuai and Zhou, Ying-Jiang and Jiang, Guo-Ping and Lin, Qiong},
booktitle={2020 35th Youth Academic Annual Conference of Chinese Association of Automation (YAC)}, title={Optimization control of UAVs based on self-learning adaptive dynamic programming},
year={2020},
volume={},
number={},
pages={738-743},
abstract={In UAVs, optimal control has attracted more and more attention. In this paper, a self-learning adaptive dynamic programming (ADP) architecture based reinforcement learning (RL) is proposed to obtain optimal control for UAVs. 1 Compared with the traditional ADP architecture including two networks, one is used to make policy, and the other is used to evaluate policy, We propose to add a third network to replace external reward signals, that is, the agent can acquire reward signals by itself and do not need to interact with the environment. The proposed self-learning ADP method can improve the control performance by online learning while ensuring the state of the system stable at the equilibrium point. Finally, the proposed control algorithm is applied to quadrotor UAVs, and the experimental results show that the effectiveness of the algorithm.},
keywords={Automation;Heuristic algorithms;Optimal control;Reinforcement learning;Dynamic programming;PD control;Optimization;Adaptive dynamic programming;Self-learning adaptive dynamic programming;Reinforcement learning;UAVs;Online learning},
doi={10.1109/YAC51587.2020.9337696},
ISSN={},
month={Oct},}
@INPROCEEDINGS{9066121,
author={Huang, Haitao and Gu, Jingjing and Wang, Qiuhong and Zhuang, Yi},
booktitle={2019 15th International Conference on Mobile Ad-Hoc and Sensor Networks (MSN)}, title={An Autonomous UAV Navigation System for Unknown Flight Environment},
year={2019},
volume={},
number={},
pages={63-68},
abstract={Autonomous navigation systems on unmanned aerial vehicles (UAVs) equipped with multiple sensors are essential to various applications in the smart city and intelligent transportation. However, the general autonomous navigation models are markedly influenced by the prior knowledge from training environments, which in turn are not applicable in unknown environments. To address this issue, we propose an online autonomous UAV navigation system named as multi-sensor data-fusion-based autonomous navigation (MDFAN) system for unknown flight environments, including the collision avoidance and path planning. Specifically, first, the newly MDFAN system formulates the navigation problem as a decision-making path planning problem to reduce the dependence of prior knowledge of the flight environment. Secondly, we develop a multi-sensor data-fusion-based method to extract more effective local environment information for mining the inherent inter-relationship between the local environment information and the current state of the UAV. Thirdly, we propose a deep reinforcement learning method for handling uncertain situations of the unknown environment. Finally, we validated our method both on the simulated and real-world environments.},
keywords={Path planning;Decision making;Navigation;Training;Unmanned aerial vehicles;Sensor systems and applications;UAV based autonomous navigation system;Path planning;Deep reinforcement learning;Multi sensor data fusion},
doi={10.1109/MSN48538.2019.00025},
ISSN={},
month={Dec},}
@INPROCEEDINGS{9317445,
author={Mohammed, Abegaz and Nahom, Hayla and Tewodros, Ayall and Habtamu, Yasin and Hayelom, Gebrye},
booktitle={2020 17th International Computer Conference on Wavelet Active Media Technology and Information Processing (ICCWAMTIP)}, title={Deep Reinforcement Learning for Computation Offloading and Resource Allocation in Blockchain-Based Multi-UAV-Enabled Mobile Edge Computing},
year={2020},
volume={},
number={},
pages={295-299},
abstract={In the current fifth-generation (5G) and Beyond 5G (B5G) era, the Unmanned Aerial Vehicles (UAVs) have been playing a vital role and attracting interest in different application areas in the military, and civil applications such as communications, disaster management, search and rescue, security, control, agriculture, Internet of things (IoT), etc. In these networks, ultra-heterogeneous IoT devices generate time-sensitive traffic. However, those devices have limited resources to compute tasks. Recently, Mobile Edge Computation Offloading (MECO) has been considered as an encouraging model to enable the computation tasks of IoT devices to be performed by MEC servers and support ultra-low latency IoT applications to ensure Quality of services (QoS). However, terrestrial network failure due to natural and human-made disasters has been increasing, and difficult to provide reliable computation offloading and resource allocation services to IoT networks. Nowadays, UAVs have been promising technology to quickly deploy and recover the system to provide efficient services to edge nodes. The offloading and resource allocation problems in current network technology are complex, and offloading task to edge server is vulnerable to security risks. Hence, we utilize a deep reinforcement learning method to handle a complex problem for computation offloading and resource allocations in a dynamic environment. And also, we explore a blockchain-based multi-UAV-assisted MEC architecture in securing and optimizing the offloading problems.},
keywords={Internet of Things;Resource management;Cloud computing;Blockchain;Task analysis;Edge computing;Computer architecture;Blockchain;Deep Reinforcement Learning;Massive IoT;Mobile Computation Offloading;Multi-UAV},
doi={10.1109/ICCWAMTIP51612.2020.9317445},
ISSN={2576-8964},
month={Dec},}
@INPROCEEDINGS{9685774,
author={Esrafilian, Omid and Bayerlein, Harald and Gesbert, David},
booktitle={2021 IEEE Global Communications Conference (GLOBECOM)}, title={Model-aided Deep Reinforcement Learning for Sample-efficient UAV Trajectory Design in IoT Networks},
year={2021},
volume={},
number={},
pages={1-6},
abstract={Deep Reinforcement Learning (DRL) is gaining attention as a potential approach to design trajectories for autonomous unmanned aerial vehicles (UAV) used as flying access points in the context of cellular or Internet of Things (IoT) connectivity. DRL solutions offer the advantage of on-the-go learning hence relying on very little prior contextual information. A corresponding drawback however lies in the need for many learning episodes which severely restricts the applicability of such approach in real-world time- and energy-constrained missions. Here, we propose a model-aided deep Q-learning approach that, in contrast to previous work, considerably reduces the need for extensive training data samples, while still achieving the overarching goal of DRL, i.e to guide a battery-limited UAV on an efficient data harvesting trajectory, without prior knowledge of wireless channel characteristics and limited knowledge of wireless node locations. The key idea consists in using a small subset of nodes as anchors (i.e. with known location) and learning a model of the propagation environment while implicitly estimating the positions of regular nodes. Interaction with the model allows us to train a deep Q-network (DQN) to approximate the optimal UAV control policy. We show that in comparison with standard DRL approaches, the proposed model-aided approach requires at least one order of magnitude less training data samples to reach identical data collection performance, hence offering a first step towards making DRL a viable solution to the problem.},
keywords={Wireless communication;Wireless sensor networks;Q-learning;Training data;Data collection;Autonomous aerial vehicles;Data models;Deep reinforcement learning;UAV;IoT},
doi={10.1109/GLOBECOM46510.2021.9685774},
ISSN={},
month={Dec},}
@INPROCEEDINGS{9411153,
author={Omi, Saki and Shin, Hyo-Sang and Tsourdos, Antonios and Espeland, Joakim and Buchi, Andrian},
booktitle={2021 15th European Conference on Antennas and Propagation (EuCAP)}, title={Introduction to UAV swarm utilization for communication on the move terminals tracking evaluation with reinforcement learning technique},
year={2021},
volume={},
number={},
pages={1-5},
abstract={As the growth of communication and satellite industry, the demand of satellite antenna evaluation is increasing. Particularly Communication On The Move (COTM) terminal antenna, including electronically steerable antennas (ESA) and for the communication between new constellations on LEO and MEO, requires tracking accuracy test for the communication on moving vehicles. The measurement capability of conventional methodologies have been limited due to their location fixed facilities and non-adjustable sensor's positions during the measurement. To overcome this drawbacks, we will present how multi-agent system of UAVs could be utilized for COTM tracking accuracy evaluation. This measurement needs instant actions for UAVs to keep them navigating in order to achieve accurate and stable measurement. Reinforcement learning (RL) techniques are investigated for this purpose in this paper. The performance improvement is demonstrated with the system using RL technique to adjust UAVs with sensors during the measurement.},
keywords={Antenna measurements;Training;Satellite antennas;Satellites;Tracking;Navigation;Reinforcement learning;Index Terms;Communication On The Move;de-pointing;antenna measurements;UAV;multi-agent reinforcement learning},
doi={10.23919/EuCAP51087.2021.9411153},
ISSN={},
month={March},}
@ARTICLE{9409695,
author={Sacco, Alessio and Esposito, Flavio and Marchetto, Guido and Montuschi, Paolo},
journal={IEEE Transactions on Vehicular Technology}, title={Sustainable Task Offloading in UAV Networks via Multi-Agent Reinforcement Learning},
year={2021},
volume={70},
number={5},
pages={5003-5015},
abstract={The recent growth of IoT devices, along with edge computing, has revealed many opportunities for novel applications. Among them, Unmanned Aerial Vehicles (UAVs), which are deployed for surveillance and environmental monitoring, are attracting increasing attention. In this context, typical solutions must deal with events that may change the state of the network, providing a service that continuously maintains a high level of performance. In this paper, we address this problem by proposing a distributed architecture that leverages a Multi-Agent Reinforcement Learning (MARL) technique to dynamically offload tasks from UAVs to the edge cloud. Nodes of the system co-operate to jointly minimize the overall latency perceived by the user and the energy usage on UAVs by continuously learning from the environment the best action, which entails the decision of offloading and, in this case, the best transmission technology, i.e., Wi-Fi or cellular. Results validate our distributed architecture and show the effectiveness of the approach in reaching the above targets.},
keywords={Task analysis;Edge computing;Drones;Markov processes;Approximation algorithms;Cloud computing;Reinforcement learning;UAV;task offloading;multi-agent reinforcement learning},
doi={10.1109/TVT.2021.3074304},
ISSN={1939-9359},
month={May},}
@INPROCEEDINGS{9576806,
author={Khan, Fawad Salam and Mohd, Mohd Norzali Haji and Larik, Raja Masood and Khan, Muhammad Danial and Abbasi, Muhammad Inam and Bagchi, Susama},
booktitle={2021 IEEE International Conference on Signal and Image Processing Applications (ICSIPA)}, title={A Smart Flight Controller based on Reinforcement Learning for Unmanned Aerial Vehicle (UAV)},
year={2021},
volume={},
number={},
pages={203-208},
abstract={Traditional flight controllers consist of Proportional Integral Derivates (PID), that although have dominant stability control but required high human interventions. In this study, a smart flight controller is developed for controlling UAVs which produces operator less mechanisms for flight controllers. It uses a neural network that has been trained using reinforcement learning techniques. Engineered with a variety of actuators (pitch, yaw, roll, and speed), the next-generation flight controller is directly trained to control its own decisions in flight. It also optimizes learning algorithms different from the traditional Actor and Critic networks. The agent gets state information from the environment and calculates the reward function depending on the sensors data from the environment. The agent then receives the observations to identify the state and reward functions and the agent activates the algorithm to perform actions. It shows the performance of a trained neural network consisting of a reward function in both simulation and real-time UAV control. Experimental results show that it can respond with relative precision. Using the same framework shows that UAVs can reliably hover in the air, even under adverse initialization conditions with obstacles. Reward functions computed during the flight for 2500, 5000, 7500 and 10000 episodes between the normalized values 0 and −4000. The computation time observed during each episode is 15 micro sec.},
keywords={Image processing;Conferences;Neural networks;Reinforcement learning;Unmanned aerial vehicles;Stability analysis;Real-time systems;UAV;Reinforcement Learning;Smart flight controller;Reward Function},
doi={10.1109/ICSIPA52582.2021.9576806},
ISSN={2642-6471},
month={Sep.},}
@INPROCEEDINGS{9295725,
author={Meng, Yuan and Yang, Yan},
booktitle={2020 IEEE 20th International Conference on Communication Technology (ICCT)}, title={Opportunistic Spectrum Access for UAV-Enabled Edge Computing: A Multi-agent Reinforcement Learning Algorithm},
year={2020},
volume={},
number={},
pages={692-697},
abstract={This paper proposes a flexible spectrum access solution for unmanned aerial vehicles (UAVs) communications. The role of each UAV is defined as a secondary user and can effectively detect spectrum holes and opportunistically access the licensed spectrum band without exposing the primary user to harmful interference. We propose and formulate a multi-agent reinforcement learning method to sense the environment through which information about channel occupancy can be detected and used to gain opportunistic spectrum access. We construct a cooperative multi-agent Q-learning algorithm combined with game theory, in which each UAV acts as a learning agent that interacts with the environment through centralized control. Simulation results show that the proposed method of multi-agent learning works effectively, and the final unit channel capacity and the number of frame collisions are compared with the existing algorithms.},
keywords={Reinforcement learning;Base stations;Drones;Channel capacity;Rician channels;Manganese;Fading channels;multi-agent reinforcement learning;opportunistic spectrum access;cognitive radio;UAVs},
doi={10.1109/ICCT50939.2020.9295725},
ISSN={2576-7828},
month={Oct},}
@INPROCEEDINGS{9262162,
author={Wang, Zhaowei and Qin, Fei},
booktitle={2020 2nd International Conference on Industrial Artificial Intelligence (IAI)}, title={NOMA based Efficient Spectrum Sharing for Underwater UAV System with Multi-agent Reinforcement Learning},
year={2020},
volume={},
number={},
pages={1-5},
abstract={The underwater communications have been challenged by the long propagation delay as well as the limited utilizable bandwidth. As a result, although the underwater UAV system can benefit many applications, the communication performance still works as a barrier for its wide adoption. This paper proposes the utilization of non-orthogonal frequency division multiple access to increase the efficiency of underwater UAV networks, which will ideally avoid the negative effect from long propagation time, but rise multiuser interference problem. To solve this problem, this paper model the multi-user interference as a non-cooperative game, and resort the multiagent reinforcement learning to approach the Nash Equilibrium. This method can avoid the a priori constraint of scenario information, which usually cannot be obtained in the underwater UAV communications. A simple but descriptive simulation has validated the feasibility of proposed method.},
keywords={Interference;OFDM;Reinforcement learning;NOMA;Underwater communication;Downlink;Uplink;underwater UAV system;NOMA;multi-user interference;spectrum sharing;reinforcement learning},
doi={10.1109/IAI50351.2020.9262162},
ISSN={},
month={Oct},}
@INPROCEEDINGS{8845316,
author={Faraci, Giuseppe and Grasso, Christian and Schembra, Giovanni},
booktitle={IEEE INFOCOM 2019 - IEEE Conference on Computer Communications Workshops (INFOCOM WKSHPS)}, title={Reinforcement-Learning for Management of a 5G Network Slice Extension with UAVs},
year={2019},
volume={},
number={},
pages={732-737},
abstract={Some representative 5G application scenarios regard geographic areas very far from the structured core network, but are characterized by the need for processing huge amount of data that cannot be transmitted to multi-access edge (MEC) facilities installed at the edge of that network. To this purpose, this paper proposes to extend a 5G network slice with a fleet of UAVs, each providing computing facilities, and for this reason referred to as MEC UAVs. The paper proposes a cooperation between MEC UAVs belonging to the same fleet based on job offloading, aiming at minimizing power consumption due to active computer elements providing MEC, job loss probability and queueing delay. A Reinforcement Learning (RL) approach is used to support the System Controller in its decisions. A numerical analysis is presented to evaluate achieved performance.},
keywords={5G mobile communication;Unmanned aerial vehicles;Delays;Reinforcement learning;Markov processes;Power demand;Monitoring;5G;Network Slicing;UAV;Reinforcement Learning;Markov Decision Processes (MDP)},
doi={10.1109/INFCOMW.2019.8845316},
ISSN={},
month={April},}
@INPROCEEDINGS{9292613,
author={Peake, Ashley and McCalmon, Joe and Zhang, Yixin and Raiford, Benjamin and Alqahtani, Sarra},
booktitle={2020 IEEE International Symposium on Safety, Security, and Rescue Robotics (SSRR)}, title={Wilderness Search and Rescue Missions using Deep Reinforcement Learning},
year={2020},
volume={},
number={},
pages={102-107},
abstract={Wilderness Search and Rescue (WiSAR) requires navigating large regions - often in rugged, remote areas - searching for missing people or animals. Because of the large regions and potentially limited mobility of ground vehicles, WiSAR missions are frequently carried out with the help of Unmanned Aerial Vehicles (UAVs). However, the ability to autonomously execute WiSAR remains an unsolved challenge. In this paper, we take advantage of Deep Reinforcement Learning (DRL) to develop an autonomous WiSAR controller for UAVs. We improve the learning and understanding of a UAV agent to explore a partially observable environment in search of a victim trapped in the wild. The proposed approach breaks up this difficult problem into 4 sub-tasks: tractable mapping of the environment in small regions, region selection, target search, and region exploration. Quad-Tree is utilized offline to decompose the environment map into smaller, tractable maps. Then, an efficient cost function is repeatedly computed to determine the best target region to search in each iteration of the process. Recurrent-DDQN and A2C algorithms are trained to generate optimal policies for the target search and regions exploration tasks, respectively. We tested our approach against a baseline of a hard-coded policy of navigating the map in a zigzag fashion and another baseline of using the same sub-tasks but instead of using the DRL algorithms, randomly selecting an action at each time step. The results demonstrate that our proposed approach is capable of navigating through 25 randomly generated environments and finding the missing victim faster than the baselines by 46%.},
keywords={Navigation;Unmanned aerial vehicles;Reinforcement learning;Training;Task analysis;Markov processes;Security;Navigation;search;rescue;deep reinforcement learning;LSTM;UAVs},
doi={10.1109/SSRR50563.2020.9292613},
ISSN={2475-8426},
month={Nov},}
@INPROCEEDINGS{9231577,
author={Chen, Yun and González-Prelcic, Nuria and Heath, Robert W.},
booktitle={2020 IEEE 30th International Workshop on Machine Learning for Signal Processing (MLSP)}, title={Collision-Free UAV Navigation with a Monocular Camera Using Deep Reinforcement Learning},
year={2020},
volume={},
number={},
pages={1-6},
abstract={Small unmanned aerial vehicles (UAV) with reduced sensing and communication capabilities can support potential use cases in different indoor environments such as automated factories or commercial buildings. In this context, we consider the problem of collision-free autonomous UAV navigation supported by a simple sensor. We propose a navigation system based on object detection and deep reinforcement learning (DRL) that only exploits sensing data obtained by a monocular camera mounted on the UAV. Object detection is incorporated into DRL training to reduce flight time and to maximize the probability of avoiding both current and future crashes. Moreover, object detection also helps to remove the impact of wrong predictions from the deep network. When compared to schemes using traditional RL methods, the proposed framework not only leads to collision- free trips, but it also reduces flying times towards given destinations by 25%, and cuts down 50% of unnecessary turns.},
keywords={Training;Servers;Navigation;Object detection;Sensors;Cameras;Unmanned aerial vehicles;Deep reinforcement learning;UAV navigation;Collision avoidance},
doi={10.1109/MLSP49062.2020.9231577},
ISSN={1551-2541},
month={Sep.},}
@INPROCEEDINGS{9256492,
author={Salvatore, Nikolaus and Mian, Sami and Abidi, Collin and George, Alan D},
booktitle={2020 AIAA/IEEE 39th Digital Avionics Systems Conference (DASC)}, title={A Neuro-inspired Approach to Intelligent Collision Avoidance and Navigation},
year={2020},
volume={},
number={},
pages={1-9},
abstract={This work presents both spiking and conventional neural network architectures, trained using reinforcement learning, for high-speed collision avoidance using dynamic vision sensors. Dynamic vision sensors are a novel class of event-based sensing equipment that enable extremely high sampling rates, but with unordinary, one-dimensional image data. A parallelized, event-stream simulation framework was developed to train reinforcement learning agents using the Microsoft AirSim UAV simulator. Event-stream data modeling output from a dynamic vision sensor was extrapolated from conventional frame-based camera feeds taken from the AirSim environment. Once trained, the spiking and conventional neural networks can be deployed to physical hardware with minimal modifications, as supported by previous work making use of the AirSim simulator.},
keywords={Robot sensing systems;Cameras;Collision avoidance;Voltage control;Training;Task analysis;Vision sensors;Unmanned aerial vehicles (UAV);Dynamic Vision Sensor;Spiking Neural Networks;Simulation;Sense and Avoid;High-speed Sensing},
doi={10.1109/DASC50938.2020.9256492},
ISSN={2155-7209},
month={Oct},}
@INPROCEEDINGS{9079122,
author={Zhao, Yubin and Zhang, Xiao and Fioranelli, Francesco},
booktitle={2019 International Radar Conference (RADAR)}, title={Initial results of Radar-based classification of commercial drone carrying small payloads},
year={2019},
volume={},
number={},
pages={1-4},
abstract={This student paper shows preliminary results on the possibility of using radar systems to identify small payloads carried by a commercial drone. This can be of great interest for traffic monitoring and situational awareness in near-future scenarios when drones are expected to be used for parcel delivery and many other applications. In this work, we consider a distributed and rather small payload, approximately 92g, carried by a commercial drone flying back and forth. Different combinations of features extracted from the micro-Doppler signatures and dwell time have been analyzed, showing promising results with median accuracy around 80% and maximum accuracy approaching 90% for the optimal case.},
keywords={radar classification;micro-Doppler;supervised machine learning;UAVs},
doi={10.1109/RADAR41533.2019.171305},
ISSN={2640-7736},
month={Sep.},}
@INPROCEEDINGS{9553286,
author={K, Anjana N. J. and Murugan, Deepak and Singh, Dharmendra},
booktitle={2021 IEEE International Geoscience and Remote Sensing Symposium IGARSS}, title={An Information Fusion Approach of UAV and Satellite Data for Intra Field Classification},
year={2021},
volume={},
number={},
pages={347-350},
abstract={Intra field classification of agriculture fields is challenging using dual pol sentinel 1 data due to its limited spatial information. With the use of sensors mountable on unmanned aerial vehicles (UAV) that has a fine spatial resolution, it is easy to obtain intra-field information. However, the use of drones is expensive and their coverage is limited. Therefore, an information fusion approach is used to make intelligent use of high-resolution drone and freely available Sentine1-1 data to provide intra-field classification at large scale for precision agriculture monitoring. Supervised random forest, support vector machine and k-nearest neighborhood classifiers were trained using the polarimetric parameters obtained from dual pol Sentine1-1 data for the classification of sparse and dense vegetation in a large sugarcane field. The overall accuracy of the proposed method is above 84% in segregating sparse and dense sugarcane fields.},
keywords={Support vector machines;Radio frequency;Training;Satellites;Vegetation mapping;Agriculture;Spatial resolution;UAV;Sentinel 1;sparse vegetation;dense vegetation;machine learning classification},
doi={10.1109/IGARSS47720.2021.9553286},
ISSN={2153-7003},
month={July},}
@INPROCEEDINGS{9516363,
author={Veerappan, Chandra Sekar and Keong, Peter Loh Kok and Balachandran, Vivek and Fadilah, Mohammad Shameel Bin Mohammad},
booktitle={2021 IEEE 16th Conference on Industrial Electronics and Applications (ICIEA)}, title={DRAT :A Penetration Testing Framework for Drones},
year={2021},
volume={},
number={},
pages={498-503},
abstract={As the usage of drones increases, attack vectors to exploit the vulnerabilities increases as well; particularly in commercial off-the-shelf Wi-Fi based drones. Hence, drones must be carefully evaluated and selected before deployment in the field. Penetration testing is a way to assess the vulnerabilities of drones, but it may require multiple commands, files or scripts and tools to generate and store the results. Many of these existing techniques and tools are dependent on human control and intervention. In this paper, we propose a Drone Pen-testing tool, which has integrated resources to conduct, organize the penetration tests and store the results. The tool has 3 main operation modes-Admin mode, User Mode and Machine learning mode. In Machine learning mode, the tool passively collects the network traffic from Wi-Fi drone access points for 60 seconds. The collected network traffic (in a pcap file) is used to analyze the IEEE 802.11 b/g/n protocol stack to identify a specific target among the surrounding Wi-Fi drones. This feature helps the user to launch a targeted attack quickly for a particular type of drone when the surrounding has many active drones. The paper explains the features of the scalable and easy to use, GUI (Graphical User Interface) based framework including details of its machine learning mode.},
keywords={Protocols;Machine learning;Telecommunication traffic;Tools;Security;Wireless fidelity;IEEE 802.11 Standard;Drone Security;UAV;penetration testing;vulnerability;framework;Wi-Fi;802.11 packets;Machine Learning in Drone Security},
doi={10.1109/ICIEA51954.2021.9516363},
ISSN={2158-2297},
month={Aug},}
@INPROCEEDINGS{8072363,
author={Yeh, Shihyuan and Chamberland, Jean-Francois and Huff, Gregory H.},
booktitle={2017 IEEE International Symposium on Antennas and Propagation USNC/URSI National Radio Science Meeting}, title={An investigation of geolocation-aware beamforming algorithms for swarming UAVs},
year={2017},
volume={},
number={},
pages={641-642},
abstract={Beamforming algorithms for UAV swarms are investigated. The swarm is modeled as a morphing volumetric random array and it is assumed that each element is enabled with orientation awareness. These algorithms are examined to improve the side lobe level for swarms operating as sparse arrays with small numbers of agents or large inter-agent distances. These are also examined to enable more complex beamforming operations for heterogeneous swarms composed of agents with different radiation patterns and/or polarizations. Simulated results based on amplitude tapering algorithms are presented to illustrate the concept, but experimental campaigns have demonstrated the utility of orientation awareness and its ability to provide side information that can enable complex beamforming operations.},
keywords={Phased arrays;Array signal processing;Aperture antennas;Antenna radiation patterns;Machine learning algorithms;Random arrays;UAVs;Swarms},
doi={10.1109/APUSNCURSINRSM.2017.8072363},
ISSN={1947-1491},
month={July},}
@INPROCEEDINGS{9730543,
author={Kim, Sujong and Han, Yunsung and Jeon, Soobin and Seo, Dongmhan},
booktitle={2022 IEEE International Conference on Consumer Electronics (ICCE)}, title={Improvement of Object Segmentation Accuracy in Aerial Images},
year={2022},
volume={},
number={},
pages={1-5},
abstract={With recent advances in UAV technology, research-based on UAV images is underway. UAVs can easily access places that are difficult for people to access and take a wide range of target areas. However, UAV images taken at high altitudes using a drone have object images with a tiny size in the entire background image, resulting in a more significant area error in the area of the detected objects. This paper proposes an accurate area measurement algorithm within an object based on image processing. Also, we evaluated the proposed algorithm by implementing it. The experimental results show that the average duplicate error rate decreased by 14% compared to mask instance segmentation. Finally, the proposed algorithm can more accurately extract small potholes in the images taken at high altitudes.},
keywords={Image segmentation;Error analysis;Conferences;Area measurement;Object segmentation;Autonomous aerial vehicles;Consumer electronics;a pothole;aerial image;UAV;machine learning},
doi={10.1109/ICCE53296.2022.9730543},
ISSN={2158-4001},
month={Jan},}
@INPROCEEDINGS{9554041,
author={Booysen, René and Lorenz, Sandra and Jackisch, Robert and Gloaguen, Richard and Madriz, Yuleika},
booktitle={2021 IEEE International Geoscience and Remote Sensing Symposium IGARSS}, title={How Can Drones Contribute to Mineral Exploration?},
year={2021},
volume={},
number={},
pages={1867-1870},
abstract={Drones are getting more and more used to replace piloted platforms to reduce the costs and increase safety of activities such as monitoring, delivery or warfare. So far though, drones have barely been used as more than single-sensor platforms. In order to be used in mineral exploration we need to ensure that the data acquired by drones are versatile, accurate and adapted to the tasks but also that the platforms are robust and low-maintenance to ensure an operational use in remote locations. During the last years we developed and tested a series of workflows to rapidly provide relevant information to exploration teams. It starts with multi-source data acquisition, data integration and preprocessing. We then use machine learning to process the data and generate relevant geological information.},
keywords={Ores;Geoscience and remote sensing;Machine learning;Tools;Safety;Data mining;Magnetics;Drones;UAS;UAV;hyperspectral;magnetics;machine learning;exploration},
doi={10.1109/IGARSS47720.2021.9554041},
ISSN={2153-7003},
month={July},}
@ARTICLE{9732978,
author={Jiang, Jiale and Zhang, Qiaofeng and Wang, Wenhui and Wu, Yapeng and Zheng, Hengbiao and Yao, Xia and Zhu, Yan and Cao, Weixing and Cheng, Tao},
journal={IEEE Transactions on Geoscience and Remote Sensing}, title={MACA: A relative radiometric correction method for multi-flight unmanned aerial vehicle images based on concurrent satellite imagery},
year={2022},
volume={},
number={},
pages={1-1},
abstract={Unmanned aerial vehicle (UAV) offers an unprecedented observing potential with ultra-high spatial and temporal resolutions and high flexibility. However, it remains difficult to solve the radiometric inconsistency of multi-flight UAV imagery. This study proposed a relative radiometric correction method for Multi-flight unmanned Aerial vehicle images based on Concurrent sAtellite imagery (MACA) consisting of two steps, i.e., cross-sensor spectral fitting (CSF) and fine-resolution spectral calibration (FSC). In CSF, relationships of multi-flight UAV reflectance and the concurrent satellite reflectance were established for generating the fine-resolution reference imagery. Subsequently, a relative radiometric correction model was constructed in the FSC step to correct multi-flight UAV imagery. The performance of MACA was evaluated using multi-flight UAV data sets acquired on six cropland sites and a concurrent Sentinel-2 image. Compared with four typical or state-of-the-art relative correction methods, the correction using MACA yielded better consistency between UAV and Sentinel-2 data, regardless of individual spectral bands (R2 = 0.79-0.86, RMSE = 0.004-0.019) or vegetation indices (R2 = 0.80-0.86, RMSE = 0.024-0.054). Moreover, the prediction of plant nitrogen accumulation based on the MACA-corrected UAV data had the highest accuracy and showed the spatial variation most significantly within and between fields for all sites. The results demonstrated that MACA was more robust in reducing spectral mismatch across sensors and eliminating the subjective error of pseudo-invariant features selection. MACA has the potential to be used to cross-calibrate multi-sensor data into a consistent standard, which will benefit multi-sensor synergies.},
keywords={Autonomous aerial vehicles;Radiometry;Satellite broadcasting;Reflectivity;Calibration;Remote sensing;Nitrogen;Unmanned aerial vehicles (UAV);Sentinel-2;Cubist;radiometric correction;machine learning;nitrogen},
doi={10.1109/TGRS.2022.3158644},
ISSN={1558-0644},
month={},}
@ARTICLE{9566769,
author={Li, Taotao and Hong, Zhen and Cai, Qianming and Yu, Li and Wen, Zhenyu and Yang, Renyu},
journal={IEEE Transactions on Knowledge and Data Engineering}, title={BISSIAM: Bispectrum Siamese Network Based Contrastive Learning for UAV Anomaly Detection},
year={2021},
volume={},
number={},
pages={1-1},
abstract={In recent years, a surging number of unmanned aerial vehicles (UAVs) are pervasively utilized in many areas. However, the increasing number of UAVs may cause privacy and security issues such as voyeurism and espionage. It is critical for individuals or organizations to manage their behaviors and proactively prevent the misbehaved invasion of unauthorized UAVs through effective anomaly detection. The UAV anomaly detection framework needs to cope with complex signals in noisy-prone environments and to function with very limited labeled samples. This paper proposes BISSIAM, a novel framework that is capable of identifying UAV presence, types, and operation modes. BISSIAM converts UAV signals to bispectrum as the input and exploits a siamese network-based contrastive learning model to learn the vector encoding. A sampling mechanism is proposed for optimizing the sample size involved in the model training whilst ensuring the model accuracy without compromising the training efficiency. Finally, we present a similarity-based fingerprint matching mechanism for detecting unseen UAVs without the need of retraining the whole model. Experimental results show that our approach outperforms other baselines and can reach 92.85% accuracy of UAV type detection in unsupervised learning scenarios, and 91.4% accuracy for detecting the UAV type of the out-of-sample UAVs.},
keywords={RF signals;Feature extraction;Anomaly detection;Training;Drones;Surveillance;Radio frequency;UAV anomaly detection;bispectrum;siamese network;unsupervised deep learning;contrastive learning},
doi={10.1109/TKDE.2021.3118727},
ISSN={1558-2191},
month={},}
@ARTICLE{9713997,
author={Tang, Xiao and Liu, Na and Zhang, Ruonan and Han, Zhu},
journal={IEEE Transactions on Vehicular Technology}, title={Deep Learning-Assisted Secure UAV-Relaying Networks with Channel Uncertainties},
year={2022},
volume={},
number={},
pages={1-1},
abstract={Unmanned aerial vehicles (UAVs) play a critical role for 5G/B5G communications. In this paper, we investigate the physical layer security issue for ground transmissions with the help of a UAV. Specifically, we consider the scenario without direct transmissions and employ the UAV as a mobile relay to amplify and forward the confidential information. Meanwhile, the receiver transmits cooperative jamming attempting to disrupt eavesdropping. We investigate the UAV deployment and receiver jamming strategy jointly for the optimized secrecy rate, while considering the channel uncertainties. In particular, for the case of complete channel state information (CSI), the jamming power is obtained by bi-section search, and we propose a data-trained deep neural network (DNN) to approximate the optimal UAV deployment. Meanwhile, for the case with partial CSI, we design a deep Q network (DQN) to learn the optimal UAV deployment, due to the increased complexity to determine the jamming strategy with channel statistics. Simulation results demonstrate that both the learned DQN and trained DNN model effectively approximate the optimal deployment of the UAV. Moreover, compared with the baselines, our proposal significantly improves the security performance of legitimate transmissions.},
keywords={Autonomous aerial vehicles;Jamming;Security;Relays;Trajectory;Optimization;Receivers;Physical layer security;UAV relaying;cooperative jamming;deep learning;channel uncertainties},
doi={10.1109/TVT.2022.3151471},
ISSN={1939-9359},
month={},}
@INPROCEEDINGS{8904014,
author={Sriram, P.R. and Ramani, Sandeep Kumar and Shrivatsav, Ram V and M.Mankiandan, Muthu and Ayyappaa, Nithin},
booktitle={2019 Third World Conference on Smart Trends in Systems Security and Sustainablity (WorldS4)}, title={Autonomous Drone for Defence Machinery Maintenance and Surveillance},
year={2019},
volume={},
number={},
pages={288-292},
abstract={This proposed research work focuses on the implementation of an autonomous unmanned aerial vehicle (UAV) which is controlled using a pix hawk flight controller. The Quad Copter is capable of navigating autonomously without any real-time input from the user and also programmed to follow a specified path autonomously. The algorithm enables a control technique by which quad copter is empowered to fly autonomously, trajectory tracking, graceful motion and accurate altitude hold performance. Surveillance and Machinery maintenance application are the primary applications designed for the Defense purposes in the Line Of Control and War-zones. This work is aimed to design a quad copter that will follow a command to fly through specified way points. The deep learning algorithm detects human motions and from data acquired camera and ultrasonic sensors to the cloud. On deviations from the standard protocol which is detected using a Sjcam 5000x elite Camera. Also, here a backup auxiliary mini drone is programmed to eject along with the data stored on the primary drone's memory on an unforeseen calamity or an attack that would damage the primary drone's ability to fly.},
keywords={Drones;Machinery;Cameras;Surveillance;Payloads;Protocols;Software;Autonomous Drone;Deep Learning;Wireless Communication;Auxiliary Drone;image Processing;Line Of Control;Sense Hat;UAV},
doi={10.1109/WorldS4.2019.8904014},
ISSN={},
month={July},}
@INPROCEEDINGS{9621115,
author={Masood, Arooj and Nguyen, The-Vi and Truong, Thanh Phung and Cho, Sungrae},
booktitle={2021 International Conference on Information and Communication Technology Convergence (ICTC)}, title={Content Caching in HAP-Assisted Multi-UAV Networks Using Hierarchical Federated Learning},
year={2021},
volume={},
number={},
pages={1160-1162},
abstract={High and low altitude platforms are expected to become an important component in current access infrastructure design to improve the radio access capability and support on-demand edge services. Caching popular contents at edge such as unmanned aerial vehicles (UAVs), can meet the requirements of mobile users that have the same content requirements, without duplicate transmissions through the backhaul links. Therefore, content access delay can be significantly reduced. In this paper, we propose an intelligent and collaborative popularity prediction method for content caching in high altitude platform (HAP)-assisted multi-UAV networks supported with a hierarchical federated learning algorithm. In this way, the proposed method also preserves the privacy of the contents of mobile users. Simulation results show that the proposed method achieves good prediction accuracy by reducing the prediction error significantly.},
keywords={Deep learning;Privacy;Simulation;Predictive models;Collaborative work;Prediction algorithms;Delays;Content caching;Multi-UAVs networks;Federated learning;Deep learning},
doi={10.1109/ICTC52510.2021.9621115},
ISSN={2162-1233},
month={Oct},}
@INPROCEEDINGS{8904837,
author={Cifola, L. and Harmanny, R. I. A.},
booktitle={2019 16th European Radar Conference (EuRAD)}, title={Target/clutter disentanglement using deep adversarial training on micro-Doppler signatures},
year={2019},
volume={},
number={},
pages={201-204},
abstract={In this manuscript we argue that, under certain conditions, machine learning techniques can help to increase the signal to background level of a target signal to aid the detection and classification process in the radar signal processing chain. Specifically, the deep adversarial training concept, through the use of Denoising Adversarial Autoencoders (DAEs), has been applied for the problem of separation the micro-Doppler signatures of wind-turbine and drones, in order to be able to extract the latter for further detection and classification purposes.},
keywords={micro-Doppler;Deep Learning;Adversarial training;wind-turbines;mini-UAVs;classification},
doi={},
ISSN={},
month={Oct},}
@INPROCEEDINGS{8404349,
author={Bıl, Dilek Başaran and Konukseven, Erhan İlhan},
booktitle={2018 26th Signal Processing and Communications Applications Conference (SIU)}, title={Fully autonomous mini/micro scale UAV field experiences and image processing applications},
year={2018},
volume={},
number={},
pages={1-4},
abstract={Fully autonomous mini/micro scale rotary and fixed wing UAV R&D works, while increasing their environmental and conditional awareness with the image processing techniques with some different results and experiences will shared within this paper. Field test experiences and lessons learned on autonomous mobile mini/micro scale UAV systems, some results and open fields on image processing techniques tried to be illustrated on the obtained image results. Finally critical and important points on image processing, power managment systems, autonomous motion, communication and data transfer will be presented to the developers working on the robotic fields.},
keywords={Nanoelectromechanical systems;Radio frequency;Image processing;Robots;Global Positioning System;Data transfer;Tracking;Autonomy;UAV;Robotics;Image;Classification;Detection;Tracking;RF;Communication;Deep Learning},
doi={10.1109/SIU.2018.8404349},
ISSN={},
month={May},}
@INPROCEEDINGS{8599403,
author={Xu, Zhi and Shi, Haochen and Li, Ning and Xiang, Chao and Zhou, Huiyu},
booktitle={2018 5th International Conference on Systems and Informatics (ICSAI)}, title={Vehicle Detection Under UAV Based on Optimal Dense YOLO Method},
year={2018},
volume={},
number={},
pages={407-411},
abstract={In this paper, a deep neural network model based on small target detection under UAV platform is designed. Due to the One-stage detection model like YOLO having novel structure and great industrial application potential, this paper proposes a new model of detection based on YOLOv2 structure. Faced with missed detection problem of small target, a series of improved schemes are proposed, which are suitable for small vehicles' detection under aerial view angle, and can achieve real-time detection, including dense topology and optimal pooling strategy.},
keywords={Feature extraction;Object detection;Unmanned aerial vehicles;Neural networks;Topology;Convolution;Adaptation models;vehicle detection;deep learning;YOLO;UAV},
doi={10.1109/ICSAI.2018.8599403},
ISSN={},
month={Nov},}
@INPROCEEDINGS{8898895,
author={Bazi, Yakoub},
booktitle={IGARSS 2019 - 2019 IEEE International Geoscience and Remote Sensing Symposium}, title={Two-Branch Neural Network for Learning Multi-label Classification in UAV Imagery},
year={2019},
volume={},
number={},
pages={2443-2446},
abstract={In this work, we propose a two-branch neural network architecture for multi-label classification in UAV imagery. Compared to single-label classification, the multi-label classification problem aims to assign multiple class labels to the image, which is more challenging. To deal with this issue, the proposed network optimizes in an end-to-end manner three loss functions related to image-label similarity, label discrimination, in addition to the number of labels present in the image. The experiments carried out on two UAV datasets with a spatial resolution of 2-cm confirm the promising capability of the proposed method.},
keywords={Unmanned aerial vehicles;Training;Image classification;Deep learning;Asphalt;Neural networks;Spatial resolution;UAV imagery;deep learning;multi-label image classification},
doi={10.1109/IGARSS.2019.8898895},
ISSN={2153-7003},
month={July},}
@INPROCEEDINGS{9051099,
author={Kim, Bobae and Jang, Beomhee and Lee, Donggeon and Im, Sungbin},
booktitle={2020 International Conference on Electronics, Information, and Communication (ICEIC)}, title={CNN-based UAV Detection with Short Time Fourier Transformed Acoustic Features},
year={2020},
volume={},
number={},
pages={1-3},
abstract={In this study, CNN (Convolutional Neural Network) is applied to the UAV detection, which is expanding its application in various fields, to compare the detection performance of the UAV against the noise of a small fan and the drum. In this study, the drum sound and the small fan sound are collected and compared with the UAV's hovering acoustic signal data. We evaluate the detection performance by using CNN for the features obtained by applying short-time Fourier transform to the samples. In the experiment, the UAV detection rate against the acoustic signal of the small fan is 99.74 % and the false detection rate is 0.39 %. For the drum sound, the detection rate is 99.98 % and the false detection rate is 0.20 %.},
keywords={Training;Fans;Time-frequency analysis;Fourier transforms;Propellers;Signal processing;Feature extraction;UAV;Detection;STFT;CNN;Deep Learning},
doi={10.1109/ICEIC49074.2020.9051099},
ISSN={},
month={Jan},}
@INPROCEEDINGS{9554610,
author={Tan, Weikai and Zhang, Dedong and Ma, Lingfei and Wang, Lanying and Qin, Nannan and Chen, Yiping and Li, Jonathan},
booktitle={2021 IEEE International Geoscience and Remote Sensing Symposium IGARSS}, title={Semantic Segmentation of UAV Lidar Point Clouds of a Stack Interchange with Deep Neural Networks},
year={2021},
volume={},
number={},
pages={582-585},
abstract={Stack interchanges are essential components of transportation systems. Mobile laser scanning (MLS) systems have been widely used in road infrastructure mapping, but accurate mapping of complicated multi-layer stack interchanges are still challenging. This study examined the point clouds collected by a new Unmanned Aerial Vehicle (UAV) Light Detection and Ranging (LiDAR) system to perform the semantic segmentation task of a stack interchange. An end-to-end supervised 3D deep learning framework was proposed to classify the point clouds. The proposed method has proven to capture 3D features in complicated interchange scenarios with stacked convolution and the result achieved over 93% classification accuracy. In addition, the new low-cost semi-solid-state LiDAR sensor Livox Mid-40 featuring a incommensurable rosette scanning pattern has demonstrated its potential in high-definition urban mapping.},
keywords={Deep learning;Surface reconstruction;Solid modeling;Three-dimensional displays;Laser radar;Roads;Semantics;LiDAR;UAV;mobile laser scanning;road infrastructure;deep learning;semantic segmentation},
doi={10.1109/IGARSS47720.2021.9554610},
ISSN={2153-7003},
month={July},}
@INPROCEEDINGS{9049609,
author={Togootogtokh, Enkhtogtokh and Huang, Sunan and Leong, Wai Lun and Swee Huat, Rodney Teo and Foresti, Gian Luca and Micheloni, Christian and Maritnel, Niki},
booktitle={2019 Twelfth International Conference on Ubi-Media Computing (Ubi-Media)}, title={An Efficient Artificial Intelligence Framework for UAV Systems},
year={2019},
volume={},
number={},
pages={47-53},
abstract={The recent breakthrough of artificial intelligence (AI) in many fields has recently shown its impact on drone technology as well. However, most of the provided solutions either entirely rely on commercial software or provide a weak integration interface which denies the development of additional techniques. This leads us to propose a novel and efficient frame-work for the drone technology. Specifically, we introduce the multi-layer AI (MLAI) framework which allows easy integration of ad-hoc AI applications. To demonstrate the benefits of the proposed framework, we implemented deep learning models to track and detect objects based on MLAI.},
keywords={Drones;Real-time systems;Deep learning;Object detection;Streaming media;Portable computers;UAV AI, Drone AI, Drone Object Detection, Drone Object Tracking, Deep Learning, AI Framework},
doi={10.1109/Ubi-Media.2019.00018},
ISSN={},
month={Aug},}
@INPROCEEDINGS{8962431,
author={Xing, Chen and Liang, Xi and Ma, Yanna},
booktitle={2019 IEEE 7th International Conference on Computer Science and Network Technology (ICCSNT)}, title={A Solution to Improve Object Detection for Images Captured by UAV-mounted Camera},
year={2019},
volume={},
number={},
pages={317-320},
abstract={Compare to traditional object detection, such as facial detection or general object recognition, the Unmanned Aerial Vehicle (UAV) object detection system is designed to detect and recognize targets with small scale from height. This paper proposes a solution combines neural network with multiscale feature maps and data augmentation to improve object detection for UAV using. The proposed network achieves 0.618 m AP and 16 fps on aerial image dataset.},
keywords={Object detection;Feature extraction;Unmanned aerial vehicles;Automobiles;Conferences;Computer vision;Cameras;Deep-learning;Object detection;Small object;UAV},
doi={10.1109/ICCSNT47585.2019.8962431},
ISSN={},
month={Oct},}
@ARTICLE{9598860,
author={Yu, Jiahui and Gao, Hongwei and Sun, Jian and Zhou, Dalin and Ju, Zhaojie},
journal={IEEE Transactions on Cognitive and Developmental Systems}, title={Spatial Cognition-driven Deep Learning for Car Detection in Unmanned Aerial Vehicle Imagery},
year={2021},
volume={},
number={},
pages={1-1},
abstract={Small object detection is the main challenge for image detection of unmanned aerial vehicles (UAVs), especially with small pixel ratios and blurred boundaries. In this paper, a one-stage detector (SF-SSD) is proposed with a new spatial cognition algorithm. The deconvolution operation is introduced to a feature fusion module, which enhances the representation of shallow features. These more representative features prove effective for small-scale object detection. Empowered by a spatial cognition method, the deep model can re-detect objects with less-reliable confidence scores. This enables the detector to improve detection accuracy significantly. Both between-class similarity and within-class similarity are fully exploited to suppress useless background information. This motivates the proposed model to take full use of semantic features in the detection process of multi-class small objects. A simplified network structure can improve the speed of object detection. The experiments are conducted on a newly collected dataset (SY-UAV) and the benchmark datasets (CARPK and PUCPR+). To further demonstrate the effectiveness of the spatial cognition module, a multi-class object detection experiment is conducted on the Stanford Drone dataset (SDD). The results show that the proposed model achieves high frame rates and better detection accuracies than the state-of-the-art methods, which are 90.1% (CAPPK), 90.8% (PUCPR+), and 91.2% (SDD).},
keywords={Detectors;Object detection;Feature extraction;Cognition;Automobiles;Task analysis;Training;UAV imagery;SSD;Feature fusion;Small object detection;Deep learning.},
doi={10.1109/TCDS.2021.3124764},
ISSN={2379-8939},
month={},}
@INPROCEEDINGS{9323613,
author={Wu, Haolin and Nie, Gaozhong and Fan, Xiwei},
booktitle={IGARSS 2020 - 2020 IEEE International Geoscience and Remote Sensing Symposium}, title={Classification of Building Structure Types Using UAV Optical Images},
year={2020},
volume={},
number={},
pages={1193-1196},
abstract={It is well know that for the same intensity areas, the buildings with different structure types can show different vulnerabilities. Thus, building structure type is one the key parameters for rapid estimation of casualties and injuries after earthquake, which is vital for emergency response and rescue. To estimate building structure types, the buildings are firstly extracted based on the spectrum, texture, and height information of UAV visible images. Then, the structure type of individual extracted buildings is classified using convolution neural network. To evaluate the accuracy of the proposed method, the images of Xuyi county, Huai'an City, Jiangsu Province are acquired using a small rotorcraft UAV. The results show that the user accuracy and cartography accuracy are 80.69% and 78.42%, respectively.},
keywords={Buildings;Earthquakes;Convolution;Feature extraction;Remote sensing;Image reconstruction;Training;Building classification;building structure type;UAV;deep learning;convolution neural network},
doi={10.1109/IGARSS39084.2020.9323613},
ISSN={2153-7003},
month={Sep.},}
@ARTICLE{9743410,
author={Dilshad, Naqqash and Ullah, Amin and Kim, Jaeho and Seo, Jeongwook},
journal={IEEE Internet of Things Journal}, title={LocateUAV: Unmanned Aerial Vehicle Location Estimation via Contextual Analysis in an IoT Environment},
year={2022},
volume={},
number={},
pages={1-1},
abstract={Object detection supported by Unmanned Aerial Vehicles (UAVs) has generated significant interest in recent years including applications such as surveillance, search for missing persons, traffic, and disaster management. Location awareness is a challenging task, particularly the deployment of UAVs in a Global Positioning System (GPS) restricted environment or GPS sensor failure. To mitigate this problem, we propose LocateUAV a novel location awareness framework, to detect UAV’s location by processing the data from the visual sensor in real-time using a lightweight Convolutional Neural Network (CNN). Assuming that the drone is in an IoT environment, first, the object detection technique is applied to detect the Object of Interest (OOI) namely, signboard. Subsequently, Optical Character Recognition (OCR) is applied to extract useful contextual information. In the final step, the extracted information is forwarded to the map Application Programming Interface (API) to locate the UAV. We also present a newly created dataset for LocateUAV, which comprises challenging scenarios for context analysis. Moreover, we also compress an existing lightweight model up to 45MB for efficient processing over UAV, which is 19.5% when compared with the size of the original model. Finally, an in-depth comparison of various trained and efficient object detection and OCR techniques is presented to facilitate future research on the development of flex-drone that can extract information from the surroundings of a location in a GPS-restricted environment.},
keywords={Autonomous aerial vehicles;Visualization;Optical character recognition software;Object detection;Global Positioning System;Drones;Task analysis;Optical Character Recognition;Deep Learning;Intelligent Drones;Edge Devices;Embedded Vision;IoT;Location Estimation;Object Detection;Scene Understanding;UAV.},
doi={10.1109/JIOT.2022.3162300},
ISSN={2327-4662},
month={},}
@INPROCEEDINGS{8494201,
author={Chen, Po-Heng and Lee, Chen-Yi},
booktitle={2018 International Conference on Intelligent Autonomous Systems (ICoIAS)}, title={UAVNet: An Efficient Obstacel Detection Model for UAV with Autonomous Flight},
year={2018},
volume={},
number={},
pages={217-220},
abstract={Autonomous navigation for large Unmanned Aerial Vehicles(UAVs) is straight-forward to implement, just employ expensive and sophisticated sensors and monitoring devices. On the contrary, usual small quadrotor UAV still have the challenge on obstacle avoidance since this kind of UAV can only carry very light weight sensors such as cameras. Given the above reason, making autonomous navigation over obstacles on small UAV is much more challenging. In this paper, we focus on proposing a novel and memory efficient deep network architecture named UAVNet for small UAV to achieve obstacle detection in the urban environment. Compared with state-of-the-art DNN architecture, UAVNet has only 2.23M parameters(which is half compared with MobileNet) and 141 MFLOPs complexity. Though the parameters are fewer than usual, the accuracy is acceptable, about 80% validated on ImageNet-2102 dataset. To further justify the utility of UAVNet, we also implement the architecture on Nvidia TX2 in real environment using NCTU campus dataset. The experiment shows the proposed UAVNet can detect obstacles to 15 fps, which is a real-time application.},
keywords={Convolution;Unmanned aerial vehicles;Computer architecture;Standards;Complexity theory;Computational modeling;Sensors;UAV;deep learning;model reduction;obstacle detection;autonomous flight},
doi={10.1109/ICoIAS.2018.8494201},
ISSN={},
month={March},}
@INPROCEEDINGS{9275994,
author={Zhou, Tong and Huang, Cheng},
booktitle={2020 International Conference on Computing and Data Science (CDS)}, title={UAV Automatic Docking Technology Based on Deep Learning},
year={2020},
volume={},
number={},
pages={448-453},
abstract={Deep learning was widely used in various fields in recent times. The effect it has shown in some areas even surpassed experts in the field. In this paper, we used deep learning technology and applied it to the drone automatic docking technology. The realization of this technology is conducive to people's intelligent and efficient daily life in the future. The parking lots of the data set we used was taken in the Northern Arizona University, Flagstaff, USA. For some images in the data set, we also used data enhancement methods to improve our training efficiency. The final result of our experiment fully proved the correctness and effectiveness of our method. The recognition rate of the parking lot is as high as 96.7% including different weather, lighting conditions, and more, on this basis, the accuracy of the automatic docking technology of the drone that it introduces is 63.2%. And behind this, we sealed the technology of the automatic recognition of parking spaces in the drone into an application.},
keywords={6G mobile communication;Germanium;Data science;Artificial intelligence;deep learning;CNN;UAV automatic docking;object detection},
doi={10.1109/CDS49703.2020.00094},
ISSN={},
month={Aug},}
@INPROCEEDINGS{9707202,
author={S, Girisha and Pai, M.M Manohara and Verma, Ujjwal and Pai, Radhika M. and S, Shreesha},
booktitle={TENCON 2021 - 2021 IEEE Region 10 Conference (TENCON)}, title={Anomaly Detection Using Classification CNN Models: A Video Analytic Approach},
year={2021},
volume={},
number={},
pages={923-928},
abstract={Video anomaly detection has gained much attention in the computer vision community due to its wide applications in security. Specifically, the focus has been on feature extraction and the design of inference algorithms. The extraction of features to model the normality is challenging due to the scarcity of data and supervision. To this end, current computer vision technologies use reconstruction based methods that relied on auto-encoders to reconstruct normal events in an unsupervised manner. Higher reconstruction errors are often used to detect anomalies. However, the use of multiple auto-encoders to extract features (temporal and appearance) is redundant and expensive for videos. In this context, the present study proposes a novel feature extractor that uses a single CNN architecture to extract both temporal and appearance features. Also, this model is trained for classification tasks which are adapted as feature extractors in anomaly detection. The training of this model is easy and can be deployed efficiently due to its lightweight architecture. Further, the proposed model has been quantitatively evaluated on the UCSD ped 2 dataset and found to perform competitively with an AUC of 0.958.},
keywords={Training;Adaptation models;Computer vision;Visual analytics;Computer architecture;Feature extraction;Inference algorithms;Deep learning;Anomaly detection;UAV videos},
doi={10.1109/TENCON54134.2021.9707202},
ISSN={2159-3450},
month={Dec},}
@INPROCEEDINGS{9696056,
author={Xie, Xiaozhu and Lu, Gang},
booktitle={2021 2nd International Conference on Big Data Artificial Intelligence Software Engineering (ICBASE)}, title={A Research of object detection on UAVs aerial images},
year={2021},
volume={},
number={},
pages={342-345},
abstract={Object detection has a key application in the field of UAV aerial photography, and its research is of great significance for the expansion of unmanned aerial vehicles (UAVs) application scenarios. In view of the characteristics of UAVs aerial images, the commonly used algorithms in this field are mainly single-stage object detection, which have good performance in balancing detection speed and detection accuracy. In recent years, a series of progress has been made in object detection, and research in the field of UAVs has gradually become hot. This paper describes the research progress of object detection, analyzes the advantages and disadvantages of related algorithms, and lists representative UAVs aerial photography object detection algorithms for introduction and analysis. It is of great significance to the development of object detection in the field of UAVs.},
keywords={Photography;Software algorithms;Object detection;Autonomous aerial vehicles;Software engineering;UAV;deep learning;CNN;object detection;onestage detection},
doi={10.1109/ICBASE53849.2021.00070},
ISSN={},
month={Sep.},}
@ARTICLE{8640094,
author={Zhu, Lingzhi and Zhang, Shuning and Zhao, Huichang and Chen, Si and Wei, Dongxu and Lu, Xiangyu},
journal={IEEE Access}, title={Classification of UAV-to-Ground Vehicles Based on Micro-Doppler Signatures Using Singular Value Decomposition and Deep Convolutional Neural Networks},
year={2019},
volume={7},
number={},
pages={22133-22143},
abstract={Attack from the unmanned aerial vehicles (UAVs) has been the main means of high-precision strike. Therefore, classifying ground vehicles from the UAV with high accuracy is of great significance. In order to avoid the complex feature extracting process and realize the classification of UAV-to-ground vehicles in different situations, this paper proposed a method based on micro-Doppler signatures using singular value decomposition (SVD) and deep convolutional neural networks (DCNNs). First, models of UAV-to-ground vehicles are built to analyze the micro-Doppler components and Doppler signals in five different cases are given. Second, time-frequency spectrums of Doppler signals with low signal-to-noise ratios are improved after removing noise using SVD. Third, transfer-learning of pre-trained DCNNs is achieved using measured data and classification under various conditions is realized using the new-trained network. When there is no noise, the overall classification accuracy of two types of Doppler signals, three types of Doppler signals, four types of Doppler signals and five types of Doppler signals has reached 100%, 97%, 97%, and 96%, respectively. Comparison with current methods which need to extract micro-Doppler features by time-frequency techniques are also made. Outstanding performance proves the superiority and robustness of the proposed method.},
keywords={Wheels;Doppler effect;Feature extraction;Radar tracking;Time-frequency analysis;Singular value decomposition;Classification;UAV-to-ground vehicles;micro-doppler signatures;singular value decomposition;deep convolutional neural networks},
doi={10.1109/ACCESS.2019.2898642},
ISSN={2169-3536},
month={},}
@INPROCEEDINGS{9256455,
author={Yang, Yupeng and Zhang, Kai and Liu, Dahai and Song, Houbing},
booktitle={2020 AIAA/IEEE 39th Digital Avionics Systems Conference (DASC)}, title={Autonomous UAV Navigation in Dynamic Environments with Double Deep Q-Networks},
year={2020},
volume={},
number={},
pages={1-7},
abstract={With the rapidly increasing number and complexity of unmanned aircraft systems (UAS), enabling high-density operations becomes the most important goal for UAS operations in congested airspace. However, it is difficult to capture the global environment information such as geolocation of other unmanned aerial vehicles (UAVs) and the steep terrain in real-time. As a result, avoiding dynamic obstacles rather than static ones is challenging. Previous work demonstrates the feasibility of using traditional Q-learning to solve the navigation problem in a static environment, but this method is problematic when facing a dynamic environment because it usually causes the overestimation of action values. To address this challenge, this paper presents a framework based on double deep Q-network with priority experience replay (DDQN-PER) which allows the UAVs to navigate and avoid obstacles in a dynamic environment. The model is built upon convolutional neural networks (CNNs) whose input is raw pixels of the local known environment and whose output is an action after estimating future rewards. We set up multiple experimental scenarios with static and moving obstacles for different tasks which are ranging from single-agent navigation to multi-agent navigation. Then this model is applied to other pre-defined environments, without adjustment of the architecture or learning algorithm, to validate its generalization. Experimental results demonstrate that our proposed models can allow the UAVs reach the goal successfully in new dynamic environments.},
keywords={Navigation;Heuristic algorithms;Training;Vehicle dynamics;Neural networks;Mathematical model;Aerodynamics;UAV;autonomous navigation;deep reinforcement learning},
doi={10.1109/DASC50938.2020.9256455},
ISSN={2155-7209},
month={Oct},}
@INPROCEEDINGS{9235599,
author={Jackson, Derek and Belakaria, Syrine and Cao, Yue and Rao Doppa, Janardhan and Lu, Xiaonan},
booktitle={2020 IEEE Energy Conversion Congress and Exposition (ECCE)}, title={Machine Learning Enabled Fast Multi-Objective Optimization for Electrified Aviation Power System Design},
year={2020},
volume={},
number={},
pages={6385-6390},
abstract={With the rise of more electric and all-electric aviation power systems, engineering efforts of system optimization shift to the electrical domain. A substantial amount of time and resources are dedicated to finding the best system architecture and design specifications to meet energy efficiency goals and physical constraints. Current processes utilize models of power system components to determine the optimal designs. However, such modeling is computationally expensive as numerous iterations are required to settle on an optimal design. This paper proposes a machine learning (ML) enabled constrained multi-objective optimization solver to drastically reduce the amount of design iterations required for Pareto set discovery for power systems. The process contributes significantly to design automation. A heavy-duty vertical-takeoff-landing (VTOL) unmanned aerial vehicle (UAV) power system is selected to demonstrate the efficacy and limitation of ML enabled optimization. Two extreme trials were run: 1) a search throughout the entire design space with only 9% valid designs within constraints; 2) a search throughout the valid design space. While Trial 1 was unsuccessful in discovering the Pareto front, Trial 2 uncovered all Pareto optimal designs with a 99% reduction of iterations compared to a brute force method.},
keywords={Force;Torque;Inverters;Batteries;Data aggregation;Erbium;Optimization;Power Electronics;Power System Design;Machine Learning;Multi-Objective Optimization;Design Automation;Pareto Front;Aviation;UAV;VTOL},
doi={10.1109/ECCE44975.2020.9235599},
ISSN={2329-3748},
month={Oct},}
@ARTICLE{9068423,
author={Comşa, Ioan-Sorin and Muntean, Gabriel-Miro and Trestian, Ramona},
journal={IEEE Transactions on Broadcasting}, title={An Innovative Machine-Learning-Based Scheduling Solution for Improving Live UHD Video Streaming Quality in Highly Dynamic Network Environments},
year={2021},
volume={67},
number={1},
pages={212-224},
abstract={The latest advances in terms of network technologies open up new opportunities for high-end applications, including using the next generation video streaming technologies. As mobile devices become more affordable and powerful, an increasing range of rich media applications could offer a highly realistic and immersive experience to mobile users. However, this comes at the cost of very stringent Quality of Service (QoS) requirements, putting significant pressure on the underlying networks. In order to accommodate these new rich media applications and overcome their associated challenges, this paper proposes an innovative Machine Learning-based scheduling solution which supports increased quality for live omnidirectional (360°) video streaming. The proposed solution is deployed in a highly dynamic Unmanned Aerial Vehicle (UAV)-based environment to support immersive live omnidirectional video streaming to mobile users. The effectiveness of the proposed method is demonstrated through simulations and compared against three state-of-the-art scheduling solutions, such as: static Prioritization (SP), Required Activity Detection Scheduler (RADS) and Frame Level Scheduler (FLS). The results show that the proposed solution outperforms the other schemes involved in terms of PSNR, throughput and packet loss rate.},
keywords={Streaming media;Quality of service;5G mobile communication;Bandwidth;Quality of experience;Dynamic scheduling;Throughput;Omnidirectional video;live streaming;QoS;machine learning;radio resource management;UAV},
doi={10.1109/TBC.2020.2983298},
ISSN={1557-9611},
month={March},}
@INPROCEEDINGS{8897854,
author={Delgado, Cristhian and Benitez, Hernan and Cruz, Maribel and Selvaraj, Michael},
booktitle={IGARSS 2019 - 2019 IEEE International Geoscience and Remote Sensing Symposium}, title={Digital Disease Phenotyping},
year={2019},
volume={},
number={},
pages={5702-5705},
abstract={Precise and rapid methods of plant disease detection and evaluation are key factors to accelerate resistant variety development in the rice breeding program. Conventional methods for the disease detection and evaluation is mainly carried out using standard visual estimation by trained experts which is slow and prone to high level of subjectivity. Rigorous research has recently recognized innovative, sensor-based methods for the detection and evaluation of plant diseases. Among different type of sensors, aerial multispectral imaging provides a fast and nondestructive way of scanning plants in diseased regions and has been used by various researchers to classify symptom levels on the spectral profile of a plant. In this paper, we developed machine learning models to classify rice breeding lines infected by rice Hoja Blanca virus (RHBV) using multispectral images collected from UAV (unmanned aerial vehicle). Our results revealed that, the Support Vector Machine (SVM) and Random Forest (RF) methods were not significantly different in their ability to separate susceptible from non-susceptible classes, but SVM best classifiers showed a better sensitivity rates 0.74 (SVM) versus 0.71 (RF). The tool developed from this study will allow rice breeders to characterize Hoja Blanca virus resistant varieties considerably earlier, and subsequent in reduced costs.},
keywords={Calibration;Diseases;Cameras;Feature extraction;Unmanned aerial vehicles;Immune system;Viruses (medical);Machine Learning (ML);Unmaned Aerial Vehicle (UAV);Rice Hoja Blanca Virus (RHBV);Hight Troughtput Phenotyping (HTP)},
doi={10.1109/IGARSS.2019.8897854},
ISSN={2153-7003},
month={July},}


@article{HOSSAIN2020158,
title = {UAV image analysis for leakage detection in district heating systems using machine learning},
journal = {Pattern Recognition Letters},
volume = {140},
pages = {158-164},
year = {2020},
issn = {0167-8655},
doi = {https://doi.org/10.1016/j.patrec.2020.05.024},
url = {https://www.sciencedirect.com/science/article/pii/S0167865520302038},
author = {Kabir Hossain and Frederik Villebro and Søren Forchhammer},
keywords = {CNN, SVM, RF, Adaboost, Energy leakage detection, District heating systems},
abstract = {In this paper, we propose automatic energy leakage detection in underground pipes of district heating systems based on Infrared (IR) images, captured by an Unmanned Aerial Vehicle (UAV). Hot water or steam is distributed to homes and industries through underground pipes from a central power plan. Leakages in underground pipes pose a very common problem, which can occur for many reasons, e.g. unprofessional installation and end of service life. Potentially, a leakage remains undiscovered for a very long period of time. Therefore, it is of great interest for power supply companies to monitor district heating networks to identify leakages. In this paper, the original IR images are captured in a 16 bit format by a UAV. On ground, potential leakages are extracted using a region extraction algorithm. Thereafter a Convolutional Neural Network (CNN) as well as eight conventional Machine Learning (ML) classifiers are applied on these regions to classify whether or not it is a leakage. In total, twelve UAV sequences are captured at different cities in Denmark. Based on these, around 13.4 million samples of image patches of district heating systems are extracted. Eleven sequences are used for training and the remaining one for testing. This was performed on all splits in the leave-one-out testing. The deep learning CNN achieved an average weighted accuracy of 0.872 with a false positive and negative rate of 12.7 % and 10.4 %, respectively. This CNN model detected around 98.6 % of the true leakages. In comparison, conventional ML classifiers, i.e. Adaboost (AB), Random Forest (RF), etc. provide lower average weighted accuracy, but on the other hand they require less computational resources. We have compared our method with a state-of-art method and the result shows that the proposed method is very competitive.}
}
@article{YANG2021386,
title = {Image recognition of wind turbine blade damage based on a deep learning model with transfer learning and an ensemble learning classifier},
journal = {Renewable Energy},
volume = {163},
pages = {386-397},
year = {2021},
issn = {0960-1481},
doi = {https://doi.org/10.1016/j.renene.2020.08.125},
url = {https://www.sciencedirect.com/science/article/pii/S0960148120313707},
author = {Xiyun Yang and Yanfeng Zhang and Wei Lv and Dong Wang},
keywords = {Wind turbine blades, Defect recognition, Deep learning, Transfer learning, Ensemble learning classifier},
abstract = {An image recognition model based on a deep learning network is proposed for the automatic extraction of image features and the accurate and efficient detection of wind turbine blade damage. The Otsu threshold segmentation method is used to segment the blade image to eliminate the influence of the image background on the detection task. In order to improve the recognition performance of the proposed deep learning model, transfer learning and an ensemble learning classifier are used in a convolutional neural network model. Transfer learning is used to enhance the ability of the proposed model to extract abstract features and accelerate the convergence efficiency, whereas the random forest-based ensemble learning classifier is used to improve the accuracy of detecting the blade defects. The performance of the proposed model is verified by using unmanned aerial vehicle (UAV) images of the wind turbine blades. The proposed model provided better performance than the support vector machine (SVM) method, the basic deep learning model and the deep learning model combined with the ensemble learning approach.}
}
@article{WU2022,
title = {Fixed-time Neuroadaptive Practical Tracking Control Based on Extended State/Disturbance Observer for a QUAV with external disturbances and Time-varying Parameters},
journal = {Journal of the Franklin Institute},
year = {2022},
issn = {0016-0032},
doi = {https://doi.org/10.1016/j.jfranklin.2022.03.018},
url = {https://www.sciencedirect.com/science/article/pii/S0016003222001843},
author = {Xueli Wu and Wenbo Fei and Xiaojing Wu and Ran Zhen},
keywords = {Dual-power approaching rate, fixed-time control, non-singular fast terminal sliding mode function, quadrotor UAVs, radial basis function neural network},
abstract = {This paper investigates the fixed-time neural network adaptive (FNNA) tracking control of a quadrotor unmanned aerial vehicle (QUAV) to achieve flight safety and high efficiency. By combining radial basis function neural network (RBFNN) with fixed time adaptive sliding mode algorithm, a novel radial basis function neural network adaptive law is proposed. In addition, an extended state/disturbance observer (ESDO) is proposed to solve the problem of unmeasurable state and external interference, which can obtain reliable state feedback and interference input. Unlike most other ESO applications, this paper does not set the uncertainty model and external disturbances as total disturbances. Instead, the external disturbances are observed by extending the states and the observed states are fed back to the controller to cancel the disturbances. In view of the time-varying resistance coefficient and inertia torque in the QUAV model, the neural network is introduced so that the controller does not need to consider these nonlinear uncertainties. Finally, a numerical example is given to verify the effectiveness of the coupled non-simplified QUAV model.}
}
@article{XU2020121,
title = {A cascade adaboost and CNN algorithm for drogue detection in UAV autonomous aerial refueling},
journal = {Neurocomputing},
volume = {408},
pages = {121-134},
year = {2020},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2019.10.115},
url = {https://www.sciencedirect.com/science/article/pii/S0925231220303404},
author = {Xiaobin Xu and Haibin Duan and Yanjie Guo and Yimin Deng},
keywords = {Autonomous aerial refueling, Cascade adaboost, Tiny convolutional neural networks, Improved focal loss},
abstract = {To promote the combat capability of unmanned aerial vehicles (UAVs) in the future battlefield, the autonomous aerial refueling (AAR) technology becomes a challenging research issue. An accurate position relationship between the tanker and the receiver is significant for AAR. A novel drogue detection method is presented in this paper. The Adaptive boosting (Adaboost) and the convolutional neural networks (CNN) classifier with the improved focal loss (IFL) function are utilized to detect the drogue in complex environments. The sample imbalance during the training stage of the CNN classifier is solved by the IFL function. The PyTorch deep learning framework is employed to implement the software system with the graphics processing units (GPUs). Real scenario images with a mimetic drogue on the tanker are captured for training and testing dataset by the airborne camera on the receiver. The experimental results indicate that the presented algorithm can accelerate the detection speed and improve the detection accuracy.}
}
@article{ALHILO2021100391,
title = {A cooperative approach for content caching and delivery in UAV-assisted vehicular networks},
journal = {Vehicular Communications},
volume = {32},
pages = {100391},
year = {2021},
issn = {2214-2096},
doi = {https://doi.org/10.1016/j.vehcom.2021.100391},
url = {https://www.sciencedirect.com/science/article/pii/S2214209621000607},
author = {Ahmed Al-Hilo and Moataz Samir and Chadi Assi and Sanaa Sharafeddine and Dariush Ebrahimi},
keywords = {UAVs, Vehicular networks, Reinforcement learning, Optimization, Content caching},
abstract = {Given the advent of Intelligent Transportation Systems (ITSs), drivers and passengers could now spend more of their time enjoying entertainment applications, e.g., watching TV or streaming movies. However, such services can drastically increase the traffic load on the existing network infrastructure (i.e. Roadside Units (RSU) and Cellular Base Stations (CBS)). Recently, Unmanned Aerial Vehicles (UAVs) have been playing a remarkable role in offloading terrestrial networks and providing cellular services thanks to their agility and flexibility. Hence, this paper explores a cooperative approach for content caching and delivery in the context of internet of connected vehicles, where a RSU, having access to a library of contents but with limited communication coverage, collaborates with a UAV to deliver contents to vehicles on a road segment. In this context, the connected RSU is responsible for delivering contents to the UAV cache unit by leveraging passing by vehicles. The RSU loads the contents on these vehicles that in turn upload them to the UAV cache unit. We model this cooperation problem mathematically as a mixed integer non-linear programming (MINLP) problem with the objective to maximize the number of served vehicles. Owing to the complexity of solving this problem, it is alternatively cast as an MDP whose solution is obtained through a Dual-Task Reinforcement Learning method (DTDRL). Simulation results show the superiority of our proposed collaborative solution over non-collaborative methods.}
}
@article{CHENG201953,
title = {Finite Time Fault Tolerant Control Design for UAV Attitude Control Systems with Actuator Fault and Actuator Saturation⁎⁎This work is jointly supported by the National Natural Science Foundation of China under Grant No.61573186 and No.61773214.},
journal = {IFAC-PapersOnLine},
volume = {52},
number = {24},
pages = {53-58},
year = {2019},
note = {5th IFAC Symposium on Telematics Applications TA 2019},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2019.12.380},
url = {https://www.sciencedirect.com/science/article/pii/S2405896319322803},
author = {Peng Cheng and Chenxiao Cai and Yun Zou},
keywords = {Unmanned aerial vehicle, attitude control systems, fault tolerant control},
abstract = {This paper presents a novel fault tolerant control (FTC) strategy for an unmanned aerial vehicle (UAV) subject to multiple constraints of actuator fault, actuator saturation and external disturbance. First, a radial basis function neural network (RBFNN)-based fault estimation observer is developed to obtain the accurate value of actuator fault. Second, an attitude stabilization FTC approach is established with combining the non-singular fast terminal sliding mode (NFTSM) technology, which could tolerate the estimated loss of effectiveness fault. Third, it is discussed asymptotically stability and stabilization of UAV attitude systems in finite time by Lyapunov method and the improved FTC scheme. Finally, the simulation is carried out to verify the fault tolerant capability of the designed algorithm.}
}
@article{BOUTEMEDJET2019464,
title = {UAV aerodynamic design involving genetic algorithm and artificial neural network for wing preliminary computation},
journal = {Aerospace Science and Technology},
volume = {84},
pages = {464-483},
year = {2019},
issn = {1270-9638},
doi = {https://doi.org/10.1016/j.ast.2018.09.043},
url = {https://www.sciencedirect.com/science/article/pii/S1270963818302359},
author = {Abdelwahid Boutemedjet and Marija Samardžić and Lamine Rebhi and Zoran Rajić and Takieddine Mouada},
keywords = {Unmanned aerial vehicle, Preliminary aerodynamic design, Wing design, Genetic algorithm optimization, Computational Fluid Dynamic, Wind tunnel testing},
abstract = {In this paper, the aerodynamic design procedure of a mini unmanned aerial vehicle, intended to perform aerial reconnaissance at low altitude and low Reynolds number, was summarized. Design process was divided into two major parts: conceptual design phase and preliminary design phase. During the conceptual design, classical procedures and data from similar unmanned aerial vehicles already designed were employed to define the requirements related to unmanned aerial vehicle design. The preliminary design was performed using panel method where the emphasis was given on the design of the UAV wing, fuselage design and empennage. The wing planform parameters were determined through an aerodynamic optimization process using both genetic algorithms and artificial neural networks. Finally an aerodynamic analysis using panel method, Computational Fluid Dynamic simulations and wind tunnel testing was carried out. Unmanned aerial vehicle full configuration design process was consistent, where a comparison between the final obtained results was carried out and showed an agreement in terms of lift, drag and pitch moment coefficients.}
}
@article{SINGHAL2019100235,
title = {Chlorophyll estimation using multi-spectral unmanned aerial system based on machine learning techniques},
journal = {Remote Sensing Applications: Society and Environment},
volume = {15},
pages = {100235},
year = {2019},
issn = {2352-9385},
doi = {https://doi.org/10.1016/j.rsase.2019.100235},
url = {https://www.sciencedirect.com/science/article/pii/S2352938519300989},
author = {Gaurav Singhal and Babankumar Bansod and Lini Mathew and Jonali Goswami and B.U. Choudhury and P.L.N. Raju},
keywords = {Unmanned aerial vehicle, Leaf chlorophyll concentration, Machine learning},
abstract = {Remote sensing for precision agriculture is a proven tool for efficient management of crop inputs. High spatial and temporal resolutions are requisite for accurate and timely estimate of crop parameters. We made an attempt to estimatetheleaf chlorophyll concentration of standing maize plant from high resolution (5 cm) multi-spectral Unmanned Aerial Vehicle (UAV) images. The UAV images in Green, Red, Red-Edge and NIR bands of standing maize fields under various nutrient induced abiotic stresses were acquired by flying a hexacopter at an elevation of 60  m at ICAR Research Complex for NEH Region, Meghalaya. A handheld spectroradiometer was also used to record the spectra in 1024 bands, ranging from 350 nm to 2500 nm to support the UAV study. We evaluated advanced machine learning algorithms combined with spectral data and ground truth chlorophyll to model the chlorophyll estimates. Algorithms included Support vector regression, Relevance vector regression, Gaussian process regression, Kernel ridge regression and Random forest with K-fold cross validation. The multivariate analysis applied on spectroradiometer and UAV data showed the dominance of Red-band for chlorophyll prediction with R2 values greater than 0.80. Among the machine learning algorithms, we found the Kernel-Ridge regression was most robust method for developing chlorophyll estimation model with minimal RMSE (0.057 mg/gm) and regression coefficient of determination (R2 = 0.904). The relevance vector machine also predicted chlorophyll concentration satisfactorily (R2 = 0.87 with RMSE of 0.06 mg/gm), but took larger training time. The optimization and hybridisation of kernel based algorithms is further needed to enhance the reliability of models for prediction of leaf chlorophyll concentrations.}
}
@article{LI2022108614,
title = {Learning residue-aware correlation filters and refining scale for real-time UAV tracking},
journal = {Pattern Recognition},
volume = {127},
pages = {108614},
year = {2022},
issn = {0031-3203},
doi = {https://doi.org/10.1016/j.patcog.2022.108614},
url = {https://www.sciencedirect.com/science/article/pii/S0031320322000954},
author = {Shuiwang Li and Yuting Liu and Qijun Zhao and Ziliang Feng},
keywords = {Residue-aware correlation filters, Discriminative scale estimation, GrabCut, Unmanned aerial vehicle (UAV) tracking},
abstract = {Unmanned aerial vehicle (UAV)-based tracking finds its applications in agriculture, aviation, navigation, transportation and public security, etc and develops rapidly recently. However, due to limitations of computing resources, battery capacity, requirement of low power and maximum load of UAV, the deployment of deep learning-based tracking algorithms in UAV is currently not feasible and therefore discriminative correlation filters (DCF)-based trackers have stood out in UAV tracking community for their high efficiency and appealing robustness on a single CPU. But confronted with difficult challenges the efficiency and accuracy of existing DCF-based approaches is still not satisfying. Inspired by the good optimization properties associated with residue representation, in this paper we exploit the residue nature inherent to videos and propose residue-aware correlation filters which demonstrate better convergence properties in filter learning. In addition, we propose a scale refinement strategy to improve the wildly adopted discriminative scale estimation in DCF-based trackers, which, in fact, greatly impacts the precision and accuracy of the trackers since accumulated scale error degrades the appearance model as online updating goes on. Extensive experiments are conducted on four UAV benchmarks, namely, UAV123@10fps, DTB70, UAVDT and Vistrone2018 (VisDrone2018-test-dev). The results show that our method achieves state-of-the-art performance in UAV tracking.}
}
@article{AMIRRUDDIN2022106646,
title = {Synthetic Minority Over-sampling TEchnique (SMOTE) and Logistic Model Tree (LMT)-Adaptive Boosting algorithms for classifying imbalanced datasets of nutrient and chlorophyll sufficiency levels of oil palm (Elaeis guineensis) using spectroradiometers and unmanned aerial vehicles},
journal = {Computers and Electronics in Agriculture},
volume = {193},
pages = {106646},
year = {2022},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2021.106646},
url = {https://www.sciencedirect.com/science/article/pii/S0168169921006633},
author = {Amiratul Diyana Amirruddin and Farrah Melissa Muharam and Mohd Hasmadi Ismail and Ngai Paing Tan and Mohd Firdaus Ismail},
keywords = {Nutrient, Chlorophyll, UAV, Spectroradiometer, Machine learning},
abstract = {The conventional method to quantify leaf biochemical properties (nutrients and chlorophylls) is tedious, labour-intensive, and impractical for vast oil palm plantation areas. Spectral analysis retrieved from a spectroradiometer and an unmanned aerial vehicle (UAV) and imbalanced approaches such as the Synthetic Minority Over-sampling TEchnique (SMOTE) and machine learning have given promising results for monitoring plant biochemical properties. However, the integration of these methods is not widely explored for oil palm. There are three primary aims of the current study. We evaluate the effectiveness of the integration of SMOTE, Logistic Model Tree (LMT), and Adaptive Boosting (AdaBoost) to address data imbalance problems for the assessment of the oil palm nutrients and chlorophylls status. The performance of the raw band and vegetation index (VI) extracted from the UAV in assessing leaf biochemical properties of mature oil palms is also addressed. Finally, we compare the competency of the spectral model retrieved from the spectroradiometer and UAV. In the study, nitrogen (N) treatments varying between 0 and 6 kg palm−1 were applied to mature Tenera palms. The integration of SMOTE with LMT and AdaBoost (LMT-SMOTEBoost) outperformed other approaches in classifying the leaf biochemical sufficiency status of mature oil palm. The VIs outperformed the raw band in discriminating the leaf biochemical properties at the canopy level. Both leaf and canopy spectral models obtained from spectroradiometer and UAV were comparable and produced good performance with balanced accuracy (BAcc) above 0.77. Using these techniques may provide palm oil plantation owners with a cost-effective way to monitor nutrient levels in palms more efficiently and comprehensively to ensure greater harvests and tree health.}
}
@article{CHENG2022107530,
title = {Estimation of soil moisture content under high maize canopy coverage from UAV multimodal data and machine learning},
journal = {Agricultural Water Management},
volume = {264},
pages = {107530},
year = {2022},
issn = {0378-3774},
doi = {https://doi.org/10.1016/j.agwat.2022.107530},
url = {https://www.sciencedirect.com/science/article/pii/S0378377422000774},
author = {Minghan Cheng and Xiyun Jiao and Yadong Liu and Mingchao Shao and Xun Yu and Yi Bai and Zixu Wang and Siyu Wang and Nuremanguli Tuohuti and Shuaibing Liu and Lei Shi and Dameng Yin and Xiao Huang and Chenwei Nie and Xiuliang Jin},
keywords = {Remote sensing, Soil moisture, Multimodality, Data fusion, UAV-based},
abstract = {An accurate in-field estimate of soil moisture content (SMC) is critical for precision irrigation management. Current ground methods to measure SMC were limited by the disadvantages of small-scale monitoring and high cost. The development of unmanned aerial vehicle (UAV) platforms now provides a cost-effective means for measuring SMC on a large scale. However, previous studies have considered only single-sensor estimates of SMC, so the combination of multiple sensors has yet to be thoroughly discussed. Additionally, the way in which soil depth, canopy coverage, and crop cultivars affect the SMC-estimation accuracy remains unclear. Therefore, the objectives of this study were to (1) evaluate the SMC-estimation accuracy provided by multimodal data fusion and four machine learning algorithms: partial least squares regression, K nearest neighbor, random forest regression (RFR), and backpropagation neural network (BPNN); (2) discuss the accuracy of the remote-sensing approach for estimating SMC at different soil depths, and (3) explore how canopy coverage and crop cultivars affect the accuracy of SMC estimation. The following results were obtained: (1) Data from multispectral sensors provided the most accurate SMC estimates regardless of which of the four machine learning algorithms was used. (2) Multimodal data fusion improved the SMC estimation accuracy, especially when combining multispectral and thermal data. (3) The RFR algorithm provided more accurate SMC estimates than the other three algorithms, with the highest accuracy obtained by combining data from RGB, multispectral, and thermal sensors with an R2 = 0.78 (0.78) and a relative root-mean-square error of 11.2% (9.6%) for 10-cm-deep (20-cm-deep) soil. (4) UAV-based SMC-estimation methods provided similar, stable performance for SMC estimates at various depths and even yielded smaller relative error for deeper estimates (20 cm). (5) The RFR and BPNN machine learning algorithms both provided relatively accurate SMC estimates for modest canopy coverage (0.2–0.4) but relatively poor estimates for higher (>0.4) or lower (<0.2) canopy coverage. (6) The SMC-estimation accuracy for different maize cultivars (JNK728 and ZD958) did not differ significantly (P < 0.01). These results indicate that UAV-based multimodal data fusion combined with machine learning algorithms can provide relatively accurate and repeatable SMC estimates. This approach can thus be used to monitor SMC and design precision irrigation systems.}
}
@article{FU2021104116,
title = {Learning dynamic regression with automatic distractor repression for real-time UAV tracking},
journal = {Engineering Applications of Artificial Intelligence},
volume = {98},
pages = {104116},
year = {2021},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2020.104116},
url = {https://www.sciencedirect.com/science/article/pii/S0952197620303560},
author = {Changhong Fu and Fangqiang Ding and Yiming Li and Jin Jin and Chen Feng},
keywords = {Unmanned aerial vehicle, Visual object tracking, Discriminative correlation filter, Learning dynamic regression, Local maximums repression},
abstract = {With high efficiency and efficacy, the trackers based on the discriminative correlation filter have experienced rapid development in the field of unmanned aerial vehicle (UAV) over the past decade. In literature, these trackers aim at solving a regression problem in which the circulated samples are mapped into a Gaussian label for online filter training. However, the fixed target label for regression makes trackers lose adaptivity in uncertain tracking scenarios. One of the typical failure cases is that the distractors, e.g., background clutter, camouflage, and similar object, are prone to confuse these trackers. In this work, an efficient approach to instantly monitor the local maximums of the response map for discovering distractors automatically is proposed. In addition, the regression target is accordingly learned, i.e., the location possessing local maximum indicates latent distractor and thus should be repressed by reducing its target response value in filter training. Qualitative and quantitative experiments performed on three challenging well-known benchmarks demonstrate that the presented method not only outperforms the state-of-the-art handcrafted feature-based trackers but also exhibits comparable performance compared to deep learning-based approaches. Specifically, the presented tracker has phenomenal practicability in real-time UAV applications with an average speed of ∼50 frames per second on an affordable CPU.}
}
@article{ELHOUMMAIDI2021e08154,
title = {Using unmanned aerial systems and deep learning for agriculture mapping in Dubai},
journal = {Heliyon},
volume = {7},
number = {10},
pages = {e08154},
year = {2021},
issn = {2405-8440},
doi = {https://doi.org/10.1016/j.heliyon.2021.e08154},
url = {https://www.sciencedirect.com/science/article/pii/S240584402102257X},
author = {Lala {El Hoummaidi} and Abdelkader Larabi and Khan Alam},
keywords = {Agriculture mapping, Deep learning, GIS, Drone mapping, Precision agriculture, Multispectral images, UAV, UAS},
abstract = {As part of the sustainable future vision, sustainable agriculture has become an essential pillar of the food security strategies formulated by the Dubai Government. Therefore, the Dubai Emirate began relying on new technology to increase productivity and efficiency. Agriculture applications also depend on accurate land monitoring for timely food security control and support actions. However, traditional monitoring requires field surveys to be performed by experts, which is costly, slow, and rare. Agriculture monitoring systems must be furnished with sustainable land use monitoring solutions, starting with remote sensing using drone surveys for affordable, efficient, and time-sensitive agriculture mapping. Hence, the Dubai Municipality is currently using Unmanned Aerial Vehicles (UAVs) to map the farming areas all over the Emirate, support locating lands conducive to cultivation, and create an accurate agriculture database contributing to the decision-making process in determining areas suitable for crop growth. This study used a novel object detection method coupled with geospatial analysis as an integrated workflow to detect individual crops. The UAV flights were executed using a Trimble UX5 (HP) over twelve communities across the Dubai Emirate for six months. Detection methods were applied to high-resolution drone images, consisting of RGB and near-infrared (NIR) bands. Advanced geoprocessing tools were also used to analyze, evaluate, and enhance the results. The performance of detection of the selected deep learning models are discussed (vegetation cover accuracy = 85.4%, F1-scores for date palms and ghaf trees = 96.03% and 94.54% respectively, with respect to visual interpretation ground truth); moreover, sample images from the datasets are used for demonstrations. The main aim is to offer specialists a solution for measuring and assessing living green vegetation cover derived from the processed images that is integrated. The results provide insight into using UAS and deep learning algorithms as a solution for sustainable agricultural mapping on a large scale.}
}
@article{GONZALOMARTIN2021106179,
title = {Improving deep learning sorghum head detection through test time augmentation},
journal = {Computers and Electronics in Agriculture},
volume = {186},
pages = {106179},
year = {2021},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2021.106179},
url = {https://www.sciencedirect.com/science/article/pii/S0168169921001964},
author = {Consuelo Gonzalo-Martín and Angel García-Pedrero and Mario Lillo-Saavedra},
keywords = {Object detection, Deep learning, Test time augmentation, Unmanned aerial vehicle imagery},
abstract = {The continuous growth of the world’s population requires immediate action to ensure food security. Sorghum is among the five most-produced cereals and is a dietary staple in many developing countries. Therefore, it is of great importance to obtain precise information for improving cereal productivity. An indicator for estimating sorghum yields is the number of crop heads in different branching arrangements. Approaches based on image processing and artificial intelligence have proved useful for automatically and efficiently obtaining this type of information for different crops. However, their application to sorghum crops presents some additional challenges owing to differences in the shape and color of sorghum heads. In this study, a methodology to detect sorghum heads in unmanned aerial vehicle imagery was investigated, and its performance was evaluated using a standard quality index in object detection problems (mean average precision). Specifically, test-time-augmentation (TTA) techniques have been implemented using a set of geometrical and color transformations selected according to the sorghum plant imagery requiring analysis, as well as four different ensemble learning methods. Because these methods are weighted, two different approaches for calculating these weights to improve sorghum head detection have been proposed. The results show that in sorghum head detection, TTA strategies outperform detection based only on individual transformed testing sets. Moreover, these results were improved by the use of different weights during the ensemble of TTA results.}
}
@article{MUALLA2019344,
title = {Agent-based simulation of unmanned aerial vehicles in civilian applications: A systematic literature review and research directions},
journal = {Future Generation Computer Systems},
volume = {100},
pages = {344-364},
year = {2019},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2019.04.051},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X18328462},
author = {Yazan Mualla and Amro Najjar and Alaa Daoud and Stéphane Galland and Christophe Nicolle and Ansar-Ul-Haque Yasar and Elhadi Shakshuki},
keywords = {Multi-agent systems, Agent-based simulation, Unmanned aerial vehicle, Systematic literature review, Civilian applications},
abstract = {Recently, the civilian applications of Unmanned Aerial Vehicles (UAVs) are gaining more interest in several domains. Due to operational costs, safety concerns, and legal regulations, Agent-Based Simulation (ABS) is commonly used to design models and conduct tests. This has resulted in numerous research works addressing ABS in civilian UAV applications. This paper aims to provide a comprehensive overview of the ABS contribution in civilian UAV applications by conducting a Systematic Literature Review (SLR) on the relevant research in the previous ten years. Following the SLR methodology, this objective is broken down into several research questions aiming to (i) understand the evolution of ABS use in civilian UAV applications and identify the related hot research topics, (ii) identify the underlying artificial intelligence systems used in the literature, (iii) understand how and when ABS is integrated in broader and more complex internet of things & ubiquitous computing environments, and (iv) identity the communication technologies, tools, and evaluation techniques used to design, implement, and test the proposed ABS models. From the SLR results, key research directions are highlighted including problems related to autonomy, explainability, security, flight duration, integration within smart cities, regulations, and validation & verification of the UAV behavior.}
}
@article{ZHAO2019407,
title = {C-loss based extreme learning machine for estimating power of small-scale turbojet engine},
journal = {Aerospace Science and Technology},
volume = {89},
pages = {407-419},
year = {2019},
issn = {1270-9638},
doi = {https://doi.org/10.1016/j.ast.2019.04.023},
url = {https://www.sciencedirect.com/science/article/pii/S1270963818319242},
author = {Yong-Ping Zhao and Jian-Feng Tan and Jian-Jun Wang and Zhe Yang},
keywords = {Machine learning, Single layer feedforward neural networks, Small-scale turbojet engine, Unmanned aerial vehicles},
abstract = {As a high-efficiency training method for single layer feedforward neural networks, extreme learning machine (ELM) has drawn much interest recently, but its robustness is not good due to the adoption of the square loss function. Hence, the convex loss function in ELM is replaced with a nonconvex loss function, i.e., the C-loss function, so a novel algorithm, called C-loss based ELM (CELM), is proposed in this paper. According to the experimental results on a toy example and two benchmark data sets, CELM performs better than the other algorithms with respect to the generalization performance. To be more important, when CELM is used to estimate power of small-scale turbojet engine, it also dominates the other algorithms, which makes the development of the potential control structure, viz., the direct power control, for the unmanned aerial vehicles more feasible.}
}
@article{CHEN2021103555,
title = {Modular composite building in urgent emergency engineering projects: A case study of accelerated design and construction of Wuhan Thunder God Mountain/Leishenshan hospital to COVID-19 pandemic},
journal = {Automation in Construction},
volume = {124},
pages = {103555},
year = {2021},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2021.103555},
url = {https://www.sciencedirect.com/science/article/pii/S0926580521000066},
author = {Ling-Kun Chen and Rui-Peng Yuan and Xing-Jun Ji and Xing-Yu Lu and Jiang Xiao and Jun-Bo Tao and Xin Kang and Xin Li and Zhen-Hua He and Shu Quan and Li-Zhong Jiang},
keywords = {Wuhan Leishenshan hospital, Modular composite building, Off-site building modular units, Light steel structure, Accelerated design and construction, Building information model (BIM) technology, Unmanned aerial vehicles (UAVs)},
abstract = {Wuhan Leishenshan/Leishenshan (“Leishenshan” for short) hospital is a makeshift emergency hospital for treating patients diagnosed with the novel coronavirus-infected pneumonia (NCIP). Engineering construction uses modular composite building finished products to the greatest extent, which reduces the workload of field operations and saves a lot of time. The building information model (BIM) technology assists in design and construction work to meet rapid construction requirements. Besides, based on the unmanned aerial vehicles (UAVs) data analysis and application platform, digitization and intelligence in engineering construction are improved. Simultaneously, on-site construction and overall hoisting were carried out to achieve maximum efficiency. This article aims to take the construction of Leishenshan Hospital as an example to illustrate how to adopt BIM technology and other high-tech technology such as big data, artificial intelligence, drones, and 5G for the fast construction of the fabricated steel structure systems in emergency engineering projects.}
}
@article{HAO2021112,
title = {Automated tree-crown and height detection in a young forest plantation using mask region-based convolutional neural network (Mask R-CNN)},
journal = {ISPRS Journal of Photogrammetry and Remote Sensing},
volume = {178},
pages = {112-123},
year = {2021},
issn = {0924-2716},
doi = {https://doi.org/10.1016/j.isprsjprs.2021.06.003},
url = {https://www.sciencedirect.com/science/article/pii/S0924271621001611},
author = {Zhenbang Hao and Lili Lin and Christopher J. Post and Elena A. Mikhailova and Minghui Li and Yan Chen and Kunyong Yu and Jian Liu},
keywords = {Deep learning, Instance segmentation, Tree-crown delineation, Tree height, UAV imagery, Plantation forest},
abstract = {Tree-crown and height are primary tree measurements in forest inventory. Convolutional neural networks (CNNs) are a class of neural networks, which can be used in forest inventory; however, no prior studies have developed a CNN model to detect tree crown and height simultaneously. This study is the first-of-its-kind that explored training a mask region-based convolutional neural network (Mask R-CNN) for automatically and concurrently detecting discontinuous tree crown and height of Chinese fir (Cunninghamia lanceolata (Lamb) Hook) in a plantation. A DJI Phantom4-Multispectral Unmanned Aerial Vehicle (UAV) was used to obtain high-resolution images of the study site, Shunchang County, China. Tree crown and height of Chinese fir was manually delineated and derived from this UAV imagery. A portion of the ground-truthed tree height values were used as a test set, and the remaining measurements were used as the model training data. Six different band combinations and derivations of the UAV imagery were used to detect tree crown and height, respectively (Multi band-DSM, RGB-DSM, NDVI-DSM, Multi band-CHM, RGB-CHM, and NDVI-CHM combination). The Mask R-CNN model with the NDVI-CHM combination achieved superior performance. The accuracy of Chinese fir’s individual tree-crown detection was considerable (F1 score = 84.68%), the Intersection over Union (IoU) of tree crown delineation was 91.27%, and tree height estimates were highly correlated with the height from UAV imagery (R2 = 0.97, RMSE = 0.11 m, rRMSE = 4.35%) and field measurement (R2 = 0.87, RMSE = 0.24 m, rRMSE = 9.67%). Results demonstrate that the input image with an CHM achieves higher accuracy of tree crown delineation and tree height assessment compared to an image with a DSM. The accuracy and efficiency of Mask R-CNN has a great potential to assist the application of remote sensing in forests.}
}
@article{ODONKOR201952,
title = {Distributed operation of collaborating unmanned aerial vehicles for time-sensitive oil spill mapping},
journal = {Swarm and Evolutionary Computation},
volume = {46},
pages = {52-68},
year = {2019},
issn = {2210-6502},
doi = {https://doi.org/10.1016/j.swevo.2019.01.005},
url = {https://www.sciencedirect.com/science/article/pii/S2210650217309288},
author = {Philip Odonkor and Zachary Ball and Souma Chowdhury},
keywords = {Anomaly detection, Distributed decision-making, Oil spill mapping, Swarm intelligence, Unmanned aerial vehicles (UAV)},
abstract = {Multiple simple agents working together to achieve a common complex goal embodies the underlying theme of swarm concepts, with decentralized decision-making serving as the new frontier for tackling challenges associated with scalability, fault tolerance, and communication constraints. This paper builds on this emerging paradigm to develop a distributed approach (called PSOil) for off-shore oil spill mapping using a team of unmanned aerial vehicles or UAVs. In-flight waypoint planning is achieved via a new particle swarm mechanics-inspired technique, employing a novel combination of anomaly detection for knowledge extraction, and a stochastic occupancy grid approach for timely processing and frugal sharing of knowledge (with net communications <1.7 KB/UAV every 10 waypoints). A total of ten real-world oil spill images, encapsulating complexities such as non-convex arbitrary shapes and disjointed segments, are studied in this work. Overall, the algorithm registered 55–90% completeness in mapping oil-covered areas. PSOil required around one-third the time necessary for an exhaustive survey and was found to be superior compared to a typical random walk and a spiral search approach w.r.t. mapping performance and efficiency, respectively. Further tests simulating increasing UAV team sizes (to deal with larger search areas) and the random loss of team members respectively illustrate the scalability and fault-tolerance characteristics of PSOil.}
}
@article{LI2022107309,
title = {Low-Reynolds-number airfoil design optimization using deep-learning-based tailored airfoil modes},
journal = {Aerospace Science and Technology},
volume = {121},
pages = {107309},
year = {2022},
issn = {1270-9638},
doi = {https://doi.org/10.1016/j.ast.2021.107309},
url = {https://www.sciencedirect.com/science/article/pii/S1270963821008191},
author = {Jichao Li and Mengqi Zhang and Chien Ming Jonathan Tay and Ningyu Liu and Yongdong Cui and Siou Chye Chew and Boo Cheong Khoo},
keywords = {UAV, Low-Reynolds-number airfoil, Deep learning, Aerodynamic shape optimization, Modal parameterization, Geometric filtering},
abstract = {Low-Reynolds-number high-lift airfoil design is critical to the performance of unmanned aerial vehicles (UAV). However, since laminar-to-turbulent transition dominates the aerodynamic performance of low-Reynolds-number airfoils and the transition position may exhibit an abrupt change even with a small geometric deformation, aerodynamic coefficient functions become discontinuous in this regime, which brings significant difficulties to the application of conventional aerodynamic design optimization methods. To efficiently perform low-Reynolds-number airfoil design, we present a tailored airfoil modal parameterization method, which reasonably defines the desired design space using deep-learning techniques. Coupled with surrogate-based optimization, the proposed method has shown to be effective and efficient in low-Reynolds-number high-lift airfoil design. It is found that it is necessary to consider laminar-to-turbulent transition and to perform multi-point optimization in practical low-Reynolds-number airfoil design. The maximal lift coefficient is an active constraint influencing the selection of the optimal cruise lift coefficient. The results show the complexity of low-Reynolds-number high-lift airfoil design and highlight the significance of the proposed method in the improvement of optimization efficiency.}
}
@article{YU2020181,
title = {Distributed adaptive fault-tolerant close formation flight control of multiple trailing fixed-wing UAVs},
journal = {ISA Transactions},
volume = {106},
pages = {181-199},
year = {2020},
issn = {0019-0578},
doi = {https://doi.org/10.1016/j.isatra.2020.07.005},
url = {https://www.sciencedirect.com/science/article/pii/S0019057820302780},
author = {Ziquan Yu and Youmin Zhang and Bin Jiang and Xiang Yu and Jun Fu and Ying Jin and Tianyou Chai},
keywords = {Unmanned aerial vehicle (UAV), Distributed control, Close formation control, Fault-tolerant control (FTC), Actuator fault, Wake vortices},
abstract = {This paper considers the reliable control problem for multiple trailing fixed-wing unmanned aerial vehicles (UAVs) against actuator faults and wake vortices. A distributed adaptive fault-tolerant control (FTC) scheme is proposed by using a distributed sliding-mode estimator, dynamic surface control architecture, neural networks, and disturbance observers. The proposed control scheme can make all trailing fixed-wing UAVs converge to the leading UAV with pre-defined time-varying relative positions even when all trailing UAVs encounter the wake vortices generated by the leading UAV and a portion of trailing UAVs is subjected to the actuator faults. It is shown that under the proposed distributed FTC scheme, the tracking errors of all trailing UAVs with respect to their desired positions are bounded. Comparative simulation results are provided to illustrate the effectiveness of the proposed control scheme.}
}
@article{LI2021106465,
title = {Fast detection and location of longan fruits using UAV images},
journal = {Computers and Electronics in Agriculture},
volume = {190},
pages = {106465},
year = {2021},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2021.106465},
url = {https://www.sciencedirect.com/science/article/pii/S0168169921004828},
author = {Denghui Li and Xiaoxuan Sun and Hamza Elkhouchlaa and Yuhang Jia and Zhongwei Yao and Peiyi Lin and Jun Li and Huazhong Lu},
keywords = {UAV, Image analysis, Convolutional neural network, RGB-D image, Detection and location of longan},
abstract = {In agriculture, fruit picking robots on the ground have difficulty adapting to the terrain conditions of mountain orchards and cannot pick longan fruit from tall longan trees. In this paper, aiming to allow picking of longan fruit by unmanned aerial vehicles (UAVs), a deep learning-based scheme to quickly and accurately detect and locate suitable picking points on fruit branches is proposed. The scheme includes a UAV fuzzy image preprocessing method, longan detection based on a convolutional neural network (CNN), red, green, blue and depth (RGB-D) information fusion and an accurate target location strategy. First, the UAV is equipped with an Intel Realsense D455 camera, which collects longan images from the front for training and testing the model. Second, the lightweight MobileNet backbone network is used to improve the performance of the You Only Look Once version 4 (YOLOv4) model in feature extraction. The results for the test set show that compared with the classical feature pyramid network (FPN), YOLOv3 and YOLOv4 models, this model reduces the computation, parameters and detection time of the model. Compared with MobileNet single-shot multibox detector (MobileNet-SSD) and YOLOv4-tiny, this model exhibits improved detection accuracy. Third, according to the target detection result map, a strategy is formulated to accurately determine the suitable picking point on the main branch of the result. Finally, the performance of the improved model and picking platform in the harvest scene is evaluated by performing picking experiments in a longan orchard. In summary, we fully exploit the advantages of the combination of UAVs, RGB-D cameras and CNNs to improve the speed and accuracy of target detection and location for longan picking by UAVs based on vision.}
}
@article{GRUSZCZYNSKI20191,
title = {Application of convolutional neural networks for low vegetation filtering from data acquired by UAVs},
journal = {ISPRS Journal of Photogrammetry and Remote Sensing},
volume = {158},
pages = {1-10},
year = {2019},
issn = {0924-2716},
doi = {https://doi.org/10.1016/j.isprsjprs.2019.09.014},
url = {https://www.sciencedirect.com/science/article/pii/S0924271619302254},
author = {Wojciech Gruszczyński and Edyta Puniach and Paweł Ćwiąkała and Wojciech Matwij},
keywords = {Unmanned aerial vehicle, Digital elevation model, Ground filter, Convolutional neural networks},
abstract = {The main advantage of using unmanned aerial vehicles (UAVs) is the relatively low cost of collecting data, especially when using photogrammetry on images of relatively small areas. Additionally, they have high operational flexibility and the results have a high spatial and temporal resolution. To further facilitate the use of UAVs in photogrammetry, we developed an algorithm to filter out points that indicate areas covered in low vegetation (grass, crops) from the generated point cloud. This paper presents a three-layer filtering algorithm based on convolutional neural networks (CNNs) created for this specific purpose. The modular structure of the algorithm makes it easy to expand on and improve. The proposed solution allows errors in the height of digital elevation model (DEM) points caused by the influence of vegetation to be reduced by as much as 60–70% in relation to height errors from the raw data of high grass. At the same time, the solution presented here is practical for low grass because it does not weaken the model. The algorithm significantly reduces the errors in the DEM, as well as the products derived from the DEM.}
}
@article{GEVAERT2020102117,
title = {Monitoring household upgrading in unplanned settlements with unmanned aerial vehicles},
journal = {International Journal of Applied Earth Observation and Geoinformation},
volume = {90},
pages = {102117},
year = {2020},
issn = {0303-2434},
doi = {https://doi.org/10.1016/j.jag.2020.102117},
url = {https://www.sciencedirect.com/science/article/pii/S0303243419309900},
author = {Caroline M. Gevaert and Claudio Persello and Richard Sliuzas and George Vosselman},
keywords = {Change detection algorithms, Image analysis, Unmanned aerial vehicles, Urban planning, Informal settlements},
abstract = {In-situ slum upgrading projects include infrastructural improvements such as new roads, which are perceived to improve the quality of life for the residents and encourage structural improvements at a household level. Although these physical changes are easily visible in satellite imagery, it is more difficult to track incremental improvements undertaken by the residents – which are perhaps more closely linked to the socio-economic development of the households themselves. The improved detail provided by imagery obtained from Unmanned Aerial Vehicles (UAVs) has the potential to monitor these more subtle changes in a settlement. This paper provides a framework which takes advantage of high-resolution imagery and a detailed elevation model from UAVs to detect changes in informal settlements. The proposed framework leverages expert knowledge to provide training labels for deep learning and thus avoids the cost of manual labelling. The semantic classification is then used to interpret a change mask and identify: new buildings, the creation of open spaces, and incremental roof upgrading in an informal settlement. The methodology is demonstrated on UAV imagery of an informal settlement in Kigali, Rwanda, successfully identifying changes between 2015 and 2017 with an Overall Accuracy of 95 % and correctly interpreting changes with an Overall Accuracy of 91 %. Results reveal that almost half the buildings in the settlement show visible changes in the roofing material, and 61 % of these changed less than 1m². This demonstrates the incremental nature of housing improvements in the settlement.}
}
@article{LAN2020105234,
title = {Comparison of machine learning methods for citrus greening detection on UAV multispectral images},
journal = {Computers and Electronics in Agriculture},
volume = {171},
pages = {105234},
year = {2020},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2020.105234},
url = {https://www.sciencedirect.com/science/article/pii/S0168169919313857},
author = {Yubin Lan and Zixiao Huang and Xiaoling Deng and Zihao Zhu and Huasheng Huang and Zheng Zheng and Bizhen Lian and Guoliang Zeng and Zejing Tong},
keywords = {Citrus HLB detection, UAV, Multispectral images, Machine learning},
abstract = {Citrus Huanglongbing (HLB), also known as citrus greening, is the most destructive disease in the citrus industry. Detecting this disease as early as possible and eradicating the roots of HLB-infected trees can control its spread. Ground diagnosis is time-consuming and laborious. Large area monitoring method of citrus orchard with high accuracy is rare. This study evaluates the feasibility of large area detection of citrus HLB by low altitude remote sensing and commits to improve the accuracy of large-area detection. A commercial multispectral camera (ADC-lite) mounted on DJI M100 UAV(unmanned Aerial Vehicle) was used to collect green, red and near-infrared multispectral image of large area citrus orchard, a linear-stretch was performed to remove noise pixel, vegetation indices (VIs) were calculated followed by correlation analysis and feature compression using PCA (principal components analysis) and AutoEncoder to discover potential features. Several machine learning algorithms, such as support vector machine (SVM), k-nearest neighbour (kNN), logistic regression (LR), naive Bayes and ensemble learning, were compared to model the healthy and HLB-infected samples after parameter optimization. The results showed that the feature of PCA features of VIs combining with original DN (digital numbers) value generally have highest accuracy and agreement in all models, and the ensemble learning and neural network approaches had strong robustness and the best classification results (100% in AdaBoost and 97.28% in neural network) using threshold strategy.}
}
@article{WANG2020106150,
title = {Tracking a dynamic invading target by UAV in oilfield inspection via an improved bat algorithm},
journal = {Applied Soft Computing},
volume = {90},
pages = {106150},
year = {2020},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2020.106150},
url = {https://www.sciencedirect.com/science/article/pii/S1568494620300909},
author = {Yi’an Wang and Kun Li and Ying Han and Fawei Ge and Wensu Xu and Liang Liu},
keywords = {Oilfield inspection, UAV, Dynamic target tracking, Trajectory prediction and optimization, Swarm intelligence},
abstract = {A novel dynamic invading target tracking method for the oilfield inspection by unmanned aerial vehicle (UAV) is presented in this paper. In this study the quad-rotor UAV is used to track an invading target, because the traditional manual inspection method and fixed-points video monitoring method has some drawbacks such as low efficiency, high cost, blind spot, and so on. A trajectory prediction method for the ground dynamic invading target is firstly proposed to predict the moving trajectory of the invading target. Then, the swarm intelligence based optimization algorithm is used to optimize the tracking trajectory of UAV, which in order to keep the distance between the UAV and the target closing to the desired distance during tracking process. In order to overcome some drawbacks such as easily being fallen into the local optimal solution and poor stability of the optimization, an improved bat algorithm (named FOBA) is proposed to improve the local searching ability of the bat algorithm (BA), which uses a food searching mechanism in the fruit fly optimization algorithm (FOA). Case studies are conducted with the desired distance is 50m between the UAV and the target, and experimental results show that the FOBA algorithm can effectively keep the tracking distance between the UAV and the target being about 55m, which is better than some other methods.}
}
@article{MARTIN2021116730,
title = {Enabling a large-scale assessment of litter along Saudi Arabian red sea shores by combining drones and machine learning},
journal = {Environmental Pollution},
volume = {277},
pages = {116730},
year = {2021},
issn = {0269-7491},
doi = {https://doi.org/10.1016/j.envpol.2021.116730},
url = {https://www.sciencedirect.com/science/article/pii/S0269749121003109},
author = {Cecilia Martin and Qiannan Zhang and Dongjun Zhai and Xiangliang Zhang and Carlos M. Duarte},
keywords = {Unmanned aerial vehicles, Deep neural network, Beach litter, Plastic, Marine debris},
abstract = {Beach litter assessments rely on time inefficient and high human cost protocols, mining the attainment of global beach litter estimates. Here we show the application of an emerging technique, the use of drones for acquisition of high-resolution beach images coupled with machine learning for their automatic processing, aimed at achieving the first national-scale beach litter survey completed by only one operator. The aerial survey had a time efficiency of 570 ± 40 m2 min−1 and the machine learning reached a mean (±SE) detection sensitivity of 59 ± 3% with high resolution images. The resulting mean (±SE) litter density on Saudi Arabian shores of the Red Sea is of 0.12 ± 0.02 litter items m−2, distributed independently of the population density in the area around the sampling station. Instead, accumulation of litter depended on the exposure of the beach to the prevailing wind and litter composition differed between islands and the main shore, where recreational activities are the major source of anthropogenic debris.}
}
@article{MIYANO2020100205,
title = {Multi-UAV Allocation Framework for Predictive Crime Deterrence and Data Acquisition},
journal = {Internet of Things},
volume = {11},
pages = {100205},
year = {2020},
issn = {2542-6605},
doi = {https://doi.org/10.1016/j.iot.2020.100205},
url = {https://www.sciencedirect.com/science/article/pii/S254266052030041X},
author = {Kosei Miyano and Ryoichi Shinkuma and Narushige Shiode and Shino Shiode and Takehiro Sato and Eiji Oki},
keywords = {unmanned aerial vehicle, surveillance, crime prediction, crime deterrence, sensor data acquisition, machine learning},
abstract = {The recent decline in the number of police and security force personnel has raised a serious security issue that could lead to reduced public safety and delayed response to crimes in urban areas. This may be alleviated in part by utilizing micro or small unmanned aerial vehicles (UAVs) and their high-mobility on-board sensors in conjunction with machine-learning techniques such as neural networks to offer better performance in predicting times and places that are high-risk and deterring crimes. The key to the success of such operation lies in the suitable placement of UAVs. This paper proposes a multi-UAV allocation framework for predictive crime deterrence and data acquisition that consists of the overarching methodology, a problem formulation, and an allocation method that work with a prediction model using a machine learning approach. In contrast to previous studies, our framework provides the most effective arrangement of UAVs for maximizing the chance to apprehend offenders whilst also acquiring data that will help improve the performance of subsequent crime prediction. This paper presents the system architecture assumed in this study, followed by a detailed description of the methodology, the formulation of the problem, and the UAV allocation method of the proposed framework. Our framework is tested using a real-world crime dataset to evaluate its performance with respect to the expected number of crimes deterred by the UAV patrol. Furthermore, to address the engineering practice of the proposed framework, we discuss the feasibility of the simulated deployment scenario in terms of energy consumption and the relationship between data analysis and crime prediction.}
}
@article{PANG2020105766,
title = {Improved crop row detection with deep neural network for early-season maize stand count in UAV imagery},
journal = {Computers and Electronics in Agriculture},
volume = {178},
pages = {105766},
year = {2020},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2020.105766},
url = {https://www.sciencedirect.com/science/article/pii/S0168169920311376},
author = {Yan Pang and Yeyin Shi and Shancheng Gao and Feng Jiang and Arun-Narenthiran Veeranampalayam-Sivakumar and Laura Thompson and Joe Luck and Chao Liu},
keywords = {Plant population, Deep learning, RCNN, Remote sensing, UAS},
abstract = {Stand counts is one of the most common ways farmers assess plant growth conditions and management practices throughout the season. The conventional method for early-season stand count is through manual inspection, which is time-consuming, laborious, and spatially limited in scope. In recent years, Unmanned Aerial Vehicles (UAV) based remote sensing has been widely used in agriculture to provide low-altitude, high spatial resolution imagery to assist decision making. In this project, we designed a system that uses geometric descriptor information with deep neural networks to determine early-season maize stands from relatively low spatial resolution (10 to 25 mm) aerial data, which covers a relatively large area (10 to 25 hectares). Instead of detecting individual crops in a row, we process the entire row at one time, which significantly reduces the requirements for the clarity of the crops. Besides, our new MaxArea Mask Scoring RCNN algorithm could segment crop-rows out in each patch image, regardless of the terrain conditions. The robustness of our scheme was tested on data collected at two different fields in different years. The accuracy of the estimated emergence rate reached up to 95.8%. Due to the high processing speed of the system, it has the potential for real-time applications in the future.}
}
@article{MARTIN2018662,
title = {Use of unmanned aerial vehicles for efficient beach litter monitoring},
journal = {Marine Pollution Bulletin},
volume = {131},
pages = {662-673},
year = {2018},
issn = {0025-326X},
doi = {https://doi.org/10.1016/j.marpolbul.2018.04.045},
url = {https://www.sciencedirect.com/science/article/pii/S0025326X18302765},
author = {Cecilia Martin and Stephen Parkes and Qiannan Zhang and Xiangliang Zhang and Matthew F. McCabe and Carlos M. Duarte},
keywords = {Marine debris, Plastic pollution, Coastline, UAV, Machine learning},
abstract = {A global beach litter assessment is challenged by use of low-efficiency methodologies and incomparable protocols that impede data integration and acquisition at a national scale. The implementation of an objective, reproducible and efficient approach is therefore required. Here we show the application of a remote sensing based methodology using a test beach located on the Saudi Arabian Red Sea coastline. Litter was recorded via image acquisition from an Unmanned Aerial Vehicle, while an automatic processing of the high volume of imagery was developed through machine learning, employed for debris detection and classification in three categories. Application of the method resulted in an almost 40 times faster beach coverage when compared to a standard visual-census approach. While the machine learning tool faced some challenges in correctly detecting objects of interest, first classification results are promising and motivate efforts to further develop the technique and implement it at much larger scales.}
}
@article{GUAN2021106987,
title = {UAV-lidar aids automatic intelligent powerline inspection},
journal = {International Journal of Electrical Power & Energy Systems},
volume = {130},
pages = {106987},
year = {2021},
issn = {0142-0615},
doi = {https://doi.org/10.1016/j.ijepes.2021.106987},
url = {https://www.sciencedirect.com/science/article/pii/S0142061521002271},
author = {Hongcan Guan and Xiliang Sun and Yanjun Su and Tianyu Hu and Haitao Wang and Heping Wang and Chigang Peng and Qinghua Guo},
keywords = {Powerline inspection, Intelligent, Unmanned aerial vehicle, Deep learning, Lidar},
abstract = {In recent decades, a substantial increase in electricity demand has put pressure on powerline systems to ensure an uninterrupted power supply. In order to prevent power failures, timely and thorough powerline inspections are needed to detect possible anomalies in advance. In the past few years, the emerging unmanned aerial vehicle (UAV)-mounted sensors (e.g. light detection and ranging/lidar, optical cameras, infrared cameras, and ultraviolet cameras) have provided rich data sources for comprehensive and accurate powerline inspections. A challenge that still hinders the use of UAVs in powerline inspection is that their operation is highly dependent on the pilot’s experience, which may pose risks to the safety of the powerline system and reduce inspection efficiency. An intelligent automatic inspection solution could overcome the limitations of current UAV-based inspection solutions. The main objective of this paper is to provide a contemporary look at the current state-of-the-art UAV-based inspections as well as to discuss a potential lidar-supported intelligent powerline inspection concept. Overall, standardized protocols for lidar-supported intelligent powerline inspections include four data analysis steps, i.e., point cloud classification, key point extraction, route generation, and fault detection. To demonstrate the feasibility of the proposed concept, we implemented a workflow using a dataset of 3536 powerline spans, showing that the inspection of a single powerline span could be completed in 10 min with only one or two technicians. This demonstrates that lidar-supported intelligent inspection can be used to inspect a powerline system with extremely high efficiency and low costs.}
}
@article{MADHUANAND20211,
title = {Self-supervised monocular depth estimation from oblique UAV videos},
journal = {ISPRS Journal of Photogrammetry and Remote Sensing},
volume = {176},
pages = {1-14},
year = {2021},
issn = {0924-2716},
doi = {https://doi.org/10.1016/j.isprsjprs.2021.03.024},
url = {https://www.sciencedirect.com/science/article/pii/S0924271621000952},
author = {Logambal Madhuanand and Francesco Nex and Michael Ying Yang},
keywords = {Depth estimation, Monocular, UAV video, Self-supervised learning, Scene Understanding},
abstract = {Unmanned Aerial Vehicles (UAVs) have become an essential photogrammetric measurement as they are affordable, easily accessible and versatile. Aerial images captured from UAVs have applications in small and large scale texture mapping, 3D modelling, object detection tasks, Digital Terrain Model (DTM) and Digital Surface Model (DSM) generation etc. Photogrammetric techniques are routinely used for 3D reconstruction from UAV images where multiple images of the same scene are acquired. Developments in computer vision and deep learning techniques have made Single Image Depth Estimation (SIDE) a field of intense research. Using SIDE techniques on UAV images can overcome the need for multiple images for 3D reconstruction. This paper aims to estimate depth from a single UAV aerial image using deep learning. We follow a self-supervised learning approach, Self-Supervised Monocular Depth Estimation (SMDE), which does not need ground truth depth or any extra information other than images for learning to estimate depth. Monocular video frames are used for training the deep learning model which learns depth and pose information jointly through two different networks, one each for depth and pose. The predicted depth and pose are used to reconstruct one image from the viewpoint of another image utilising the temporal information from videos. We propose a novel architecture with two 2D Convolutional Neural Network (CNN) encoders and a 3D CNN decoder for extracting information from consecutive temporal frames. A contrastive loss term is introduced for improving the quality of image generation. Our experiments are carried out on the public UAVid video dataset. The experimental results demonstrate that our model outperforms the state-of-the-art methods in estimating the depths.}
}
@article{MOHAMADI2021115529,
title = {Efficient algorithms for decision making and coverage deployment of connected multi-low-altitude platforms},
journal = {Expert Systems with Applications},
volume = {184},
pages = {115529},
year = {2021},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2021.115529},
url = {https://www.sciencedirect.com/science/article/pii/S0957417421009374},
author = {Houssem Eddine Mohamadi and Nadjia Kara and Mohand Lagha},
keywords = {Unmanned aerial vehicle, Low-altitude platform, Multi-criteria decision-making, Coverage optimization problem, Genetic algorithm},
abstract = {Unmanned aerial vehicles (UAVs) have gained significantly in popularity in recent years, and they are coupled with the emerging Internet-of-Things, 5G, and mobile edge computing. Their application domains will continue to expand. UAVs can deliver various IoT-driven applications (e.g., video surveillance UAVs-based applications) anytime and anywhere. Indeed, the rapid deployment of such applications in different environments (e.g., urban or wildlife surveillance/sensing environments) is one of the critical factors to support the emergence of new services and applications (e.g., 5G/B5G UAVs base station, civil and commercial IoT applications). However, several research challenges need to be addressed before the latter can be deployed in the real world. In this paper, we propose a novel approach that enables efficient coverage using a set of UAVs. We define two multi-objective sub-problems. The first sub-problem allows selecting a minimum number of appropriate UAVs for deployment as Low-Altitude-Platforms (LAP) over an area of interest from an extensive collection of options. We model this sub-problem as multi-criteria decision-making (MCDM) problem considering various UAV features and user constraints and solve it using a novel multi-criteria selection algorithm named SAGA. The second sub-problem is a coverage optimization problem that enables controlling UAVs’ hover locations and use gimbal-mounted rotating cameras or multi-lens cameras to increase the coverage accordingly. We propose a strategy aiming at optimizing hovering locations of UAVs and then rotating their cameras. The process comprises two techniques to solve the latter sub-problem: (1) an improved preference-guided genetic algorithm named NSPGGA; (2) a hybrid heuristic DCXGA built upon three algorithmic techniques: divide-and-conquer, greedy search, and exhaustive search. We carried out comparative analyses with seven MCDM methods and ten multi-objective evolutionary/swarm intelligence algorithms. The proposed algorithms outperformed the benchmarking techniques and showed remarkable results, e.g., the selection algorithm SAGA exhibits a high success rate, accuracy, and consistency. The preference-guided genetic algorithm NSPGGA achieves better efficiency, and it is four times faster than the famed NSGA-II. Finally, the hybrid heuristic DCXGA allows having more significant imaging coverages with few camera rotations. The aforementioned vital results are validated through diverse and intensive simulation scenarios.}
}
@article{BEHJAT2019103270,
title = {Learning reciprocal actions for cooperative collision avoidance in quadrotor unmanned aerial vehicles},
journal = {Robotics and Autonomous Systems},
volume = {121},
pages = {103270},
year = {2019},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2019.103270},
url = {https://www.sciencedirect.com/science/article/pii/S0921889019301617},
author = {Amir Behjat and Steve Paul and Souma Chowdhury},
keywords = {Bio-inspired, Collision avoidance, Learning, Optimization, Unmanned Aerial Vehicle (UAV)},
abstract = {The ability to avoid collisions with each other is one of the fundamental requirements for autonomous unmanned aerial vehicles (UAVs) to be safely integrated into the civilian airspace, and for the viability of multi-UAV operations. This paper introduces a new approach for online cooperative collision avoidance between quadcopters, involving reciprocal maneuvers, i.e., coherent maneuvers without requiring any real-time consensus. Two maneuver strategies are presented, where UAVs respectively change their speed or heading to avoid a collision. A learning-based framework that trains these reciprocal actions for collision evasion (called TRACE) is developed. The primary elements of this framework include: 1) designing simulated experiments that cover a variety of UAV–UAV approach scenarios; 2) performing optimization to identify speed/heading change actions that satisfy safety constraints while minimizing the energy cost of the maneuver; and 3) using the offline optimization outcomes to train classifier (via ensemble bagged tree) and function approximation (via neural networks and Kriging) models for respectively selecting and encoding the avoidance actions. Trajectory generation and dynamics/controls are incorporated in the simulation environment used for training and testing. Over 90% accuracy in action prediction and over 95% success in avoiding collisions is observed when the trained models are applied to simulated unseen test scenarios.}
}
@article{BAI2022108166,
title = {Learning-based resilience guarantee for multi-UAV collaborative QoS management},
journal = {Pattern Recognition},
volume = {122},
pages = {108166},
year = {2022},
issn = {0031-3203},
doi = {https://doi.org/10.1016/j.patcog.2021.108166},
url = {https://www.sciencedirect.com/science/article/pii/S0031320321003538},
author = {Chengchao Bai and Peng Yan and Xiaoqiang Yu and Jifeng Guo},
keywords = {Unmanned business, Communication service, Multi-UAV, Deep reinforcement learning, QoS-aware, System resilience},
abstract = {Unmanned and intelligent technologies are the future development trend in the business field. It is of great significance for the connotation analysis and application characterization of massive interactive data. Particularly, during major epidemics or disasters, how to provide business services safely and securely is crucial. Specifically, providing users with resilient and guaranteed communication services is a challenging business task when the communication facilities are damaged. Unmanned aerial vehicles (UAVs), with flexible deployment and high maneuverability, can be used to serve as aerial base stations (BSs) to establish emergency networks. However, it is challenging to control multiple UAVs to provide efficient and fair communication quality of service (QoS) to users due to their limited communication service capabilities. In this paper, we propose a learning-based resilience guarantee framework for multi-UAV collaborative QoS management. We formulate this problem as a partial observable Markov decision process and solve it with proximal policy optimization (PPO), which is a policy-based deep reinforcement learning method. A centralized training and decentralized execution paradigm is used, where the experience collected by all UAVs is used to train the shared control policy. Each UAV takes actions based on the partial environment information it observes. In addition, the design of the reward function considers the average and variance of the communication QoS of all users. Extensive simulations are conducted for performance evaluation. The simulation results indicate that (1) the trained policies can adapt to different scenarios and provide resilient and guaranteed communication QoS to users, (2) increasing the number of UAVs can compensate for the lack of service capabilities of UAVs, (3) when UAVs have local communication service capabilities, the policies trained with PPO have better performance compared with the policies trained with other algorithms.}
}
@article{WANG2020103330,
title = {Measurement for cracks at the bottom of bridges based on tethered creeping unmanned aerial vehicle},
journal = {Automation in Construction},
volume = {119},
pages = {103330},
year = {2020},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2020.103330},
url = {https://www.sciencedirect.com/science/article/pii/S0926580520309109},
author = {Hui-Feng Wang and Lei Zhai and He Huang and Li-Min Guan and Ke-Nan Mu and Gui-ping Wang},
keywords = {Instrumentation technology, Tethered creeping UAV, Feature matching, Maximum spanning tree, Multi-band blending, Image stitching},
abstract = {The detection of bridge bottom cracks is required for bridge maintenance. In order to realise the requirement of automatic real-time detection of a bridge structure, an image detection method for cracks in the bottom of the bridge structure using a tethered creeping unmanned aerial vehicle (UAV) is proposed. A high-precision unlimited endurance detection plan based on the tethered creeping UAV is designed to use for the bottom cracks of the bridge structure. The detection scheme applies a high-precision image stitching measurement algorithm for cracks at the bottom of the beam body, which is able to restore a panoramic image. All mainstream filtering methods were evaluated, and it turned out that they are practicable/applicable in various crack images of different shapes. The method is applied to the crack detection in the bottom of bridge structures to ensure the accuracy and efficiency of the system measurement. According to the actual measurement by the laboratory platform, the measurement error using this method is less than 0.1 mm, which meets the requirements of measurement automation. The results of the research represent an initial step towards developing an automatic bridge health monitoring and evaluating system.}
}
@article{ZHENG2021539,
title = {An intelligent target detection method of UAV swarms based on improved KM algorithm},
journal = {Chinese Journal of Aeronautics},
volume = {34},
number = {2},
pages = {539-553},
year = {2021},
issn = {1000-9361},
doi = {https://doi.org/10.1016/j.cja.2020.07.021},
url = {https://www.sciencedirect.com/science/article/pii/S1000936120303423},
author = {Xiangming ZHENG and Chunyao MA},
keywords = {3D probability map, Kuhn-Munkres algorithm, Path planning, Real-time control, Swarm intelligence, Target detection, Unmanned aerial vehicle (UAV)},
abstract = {Complete and efficient detection of unknown targets is the most popular application of UAV swarms. Under most situations, targets have directional characteristics so that they can only be successfully detected within specific angles. In such cases, how to coordinate UAVs and allocate optimal paths for them to efficiently detect all the targets is the primary issue to be solved. In this paper, an intelligent target detection method is proposed for UAV swarms to achieve real-time detection requirements. First, a target-feature-information-based disintegration method is built up to divide the search space into a set of cubes. Theoretically, when the cubes are traversed, all the targets can be detected. Then, a Kuhn-Munkres (KM)-algorithm-based path planning method is proposed for UAVs to traverse the cubes. Finally, to further improve search efficiency, a 3D real-time probability map is established over the search space which estimates the possibility of detecting new targets at each point. This map is adopted to modify the weights in KM algorithm, thereby optimizing the UAVs’ paths during the search process. Simulation results show that with the proposed method, all targets, with detection angle limitations, can be found by UAVs. Moreover, by implementing the 3D probability map, the search efficiency is improved by 23.4%–78.1%.}
}
@article{SACCO2020769,
title = {An architecture for adaptive task planning in support of IoT-based machine learning applications for disaster scenarios},
journal = {Computer Communications},
volume = {160},
pages = {769-778},
year = {2020},
issn = {0140-3664},
doi = {https://doi.org/10.1016/j.comcom.2020.07.011},
url = {https://www.sciencedirect.com/science/article/pii/S0140366419316779},
author = {Alessio Sacco and Matteo Flocco and Flavio Esposito and Guido Marchetto},
keywords = {Network of queues, Machine Learning},
abstract = {The proliferation of the Internet of Things (IoT) in conjunction with edge computing has recently opened up several possibilities for several new applications. Typical examples are Unmanned Aerial Vehicles (UAV) that are deployed for rapid disaster response, photogrammetry, surveillance, and environmental monitoring. To support the flourishing development of Machine Learning assisted applications across all these networked applications, a common challenge is the provision of a persistent service, i.e., a service capable of consistently maintaining a high level of performance, facing possible failures. To address these service resilient challenges, we propose APRON, an edge solution for distributed and adaptive task planning management in a network of IoT devices, e.g., drones. Exploiting Jackson’s network model, our architecture applies a novel planning strategy to better support control and monitoring operations while the states of the network evolve. To demonstrate the functionalities of our architecture, we also implemented a deep-learning based audio-recognition application using the APRON NorthBound interface, to detect human voices in challenged networks. The application’s logic uses Transfer Learning to improve the audio classification accuracy and the runtime of the UAV-based rescue operations.}
}
@article{KAKO2020111127,
title = {Estimation of plastic marine debris volumes on beaches using unmanned aerial vehicles and image processing based on deep learning},
journal = {Marine Pollution Bulletin},
volume = {155},
pages = {111127},
year = {2020},
issn = {0025-326X},
doi = {https://doi.org/10.1016/j.marpolbul.2020.111127},
url = {https://www.sciencedirect.com/science/article/pii/S0025326X20302459},
author = {Shin'ichiro Kako and Shohei Morita and Tetsuya Taneda},
keywords = {Plastic marine debris, UAV, Image processing, Deep learning},
abstract = {Plastic marine debris (PMD) is of global concern. To help address this problem, a novel approach for estimating PMD volumes using a combination of unmanned aerial vehicle (UAV) surveys and image processing based on deep learning is proposed. A three-dimensional model and orthoscopic image of a beach, constructed via Structure from Motion software using UAV-derived data, enabled PMD volumes to be computed by edge detection through image processing. The accuracy of the method was verified by estimating the volumes of test debris placed on a beach in known sizes and shapes. The proposed approach shows potential for estimating PMD volumes with an error of <5%. Compared with subjective methods based on beach surveys, this approach can accurately, rapidly, and objectively calculate the PMD volume on a beach and can be used to improve the efficiency of beach surveys and identify beaches that need preferential cleaning.}
}
@article{MA2018108,
title = {A saliency-based reinforcement learning approach for a UAV to avoid flying obstacles},
journal = {Robotics and Autonomous Systems},
volume = {100},
pages = {108-118},
year = {2018},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2017.10.009},
url = {https://www.sciencedirect.com/science/article/pii/S0921889017301136},
author = {Zhaowei Ma and Chang Wang and Yifeng Niu and Xiangke Wang and Lincheng Shen},
keywords = {UAV, Flying obstacle avoidance, Convolution neural networks based saliency detection, Reinforcement learning},
abstract = {Obstacle avoidance is a necessary behavior to guarantee the safety of an unmanned aerial vehicle (UAV). However, it is a challenge for the UAV to detect and avoid high-speed flying obstacles such as other UAVs or birds. In this paper, we propose a generic framework that integrates an autonomous obstacle detection module and a reinforcement learning (RL) module to develop reactive obstacle avoidance behavior for a UAV. In the obstacle detection module, we design a saliency detection algorithm using deep convolution neural networks (CNNs) to extract monocular visual cues. The algorithm imitates human’s visual detection system, and it can accurately estimate the location of obstacles in the field of view (FOV). The RL module uses an actor–critic structure that chooses the RBF neural network to approximate the value function and control policy in continuous state and action spaces. We have tested the effectiveness of the proposed learning framework in a semi-physical experiment. The results show that the proposed saliency detection algorithm performs better than state-of-the-art, and the RL algorithm can learn the avoidance behavior from the manual experiences.}
}
@article{ZHAO2022110734,
title = {Attitude-Induced error modeling and compensation with GRU networks for the polarization compass during UAV orientation},
journal = {Measurement},
volume = {190},
pages = {110734},
year = {2022},
issn = {0263-2241},
doi = {https://doi.org/10.1016/j.measurement.2022.110734},
url = {https://www.sciencedirect.com/science/article/pii/S0263224122000380},
author = {Donghua Zhao and Yueze Liu and Xindong Wu and Hao Dong and Chenguang Wang and Jun Tang and Chong Shen and Jun Liu},
keywords = {UAV orientation, Polarization navigation, Error processing, Neural Networks},
abstract = {The polarization compass used for unmanned aerial vehicle (UAV) navigation is usually hypothesized to be arranged horizontally in conventional heading measurement, which leads to a noticeable heading error due to the inevitable tilts called the pitch angle and the roll angle during UAV flight process. In addition, we found that the coupling of the angle between the solar meridian and the body axis of a carrier (A-SMBA) and tilted-angles will produce more remarkable heading errors. Consequently, we first introduce a comprehensive analysis of heading error in terms of variable attitude angles of the compass including the A-SMBA, the pitch angle and the roll angle. A novel heading error modeling and compensation for attitude-changed of the polarization compass by gated recurrent unit (GRU) neural network is developed subsequently. The experimental results demonstrate the proposed heading error modeling and compensation method performs best compared to state-of-the-art algorithms in predicting the UAV orientation.}
}
@article{GUO2021102435,
title = {Integrating spectral and textural information for identifying the tasseling date of summer maize using UAV based RGB images},
journal = {International Journal of Applied Earth Observation and Geoinformation},
volume = {102},
pages = {102435},
year = {2021},
issn = {0303-2434},
doi = {https://doi.org/10.1016/j.jag.2021.102435},
url = {https://www.sciencedirect.com/science/article/pii/S0303243421001422},
author = {Yahui Guo and Yongshuo H. Fu and Shouzhi Chen and Christopher {Robin Bryant} and Xinxi Li and J. Senthilnath and Hongyong Sun and Shuxin Wang and Zhaofei Wu and Kirsten {de Beurs}},
keywords = {UAV, Spectral information, Textural information, Phenology extraction},
abstract = {The extraction of phenological events in forest and agriculture commonly relies on Vegetation Indices (VI) composed by visible and near infrared bands from satellite images. However, the textural information playing an important role in image fusion, image classification and change detection is commonly ignored. In this study, high-throughput images collected from an Unmanned Aerial Vehicle (UAV) platform during the growth stages of summer maize were used to identify the Tasseling Date (TD) based on both spectral and textural information. The spectral and textural information were extracted using various VI and the Gray Level Co-occurrence Matrix (GLCM), respectively. The results showed that the Normalized Green Blue Difference Index (NGBDI), and the Green Blue Difference Index (GBDI) of VI and the Contrast Information (Contrast) of GLCM performed better than other variables. A new index was generated by integrating spectral and textural information using the Improved Adaptive Feature Weighting Method (IAFWM), and then the TDs were identified for each plot. The Root Mean Square Error (RMSE) of new index was 5.77 days and it was the lowest among all variables. The potential ability of more advanced machine learning and deep learning in integrating the spectral and textural information should be investigated.}
}
@article{DASHPUREV2021108331,
title = {A cost-effective method to monitor vegetation changes in steppes ecosystems: A case study on remote sensing of fire and infrastructure effects in eastern Mongolia},
journal = {Ecological Indicators},
volume = {132},
pages = {108331},
year = {2021},
issn = {1470-160X},
doi = {https://doi.org/10.1016/j.ecolind.2021.108331},
url = {https://www.sciencedirect.com/science/article/pii/S1470160X21009961},
author = {Batnyambuu Dashpurev and Karsten Wesche and Yun Jäschke and Khurelpurev Oyundelger and Thanh Noi Phan and Jörg Bendix and Lukas W. Lehnert},
keywords = {PlanetScope, Unmanned aerial vehicle, Steppe fire, Plant functional group, Land degradation, Remote sensing, Random forest},
abstract = {Land degradation is a major environmental and social issue in temperate steppes. It is commonly determined from vegetation cover using remote sensing techniques. Steppes in eastern Mongolia are subject to resource extraction activities, such as mining and oil extraction, which affect land degradation. Recent technological progress in remote sensing has facilitated the acquirement of high-resolution data by, for example, the CubeSat satellite or unmanned aerial vehicles (UAV), providing data for detailed maps of vegetation cover and plant functional groups (PFGs). Traditional methods for monitoring vegetation cover often face typical scale issues, such as the upscaling of vegetation parameters if plot-scale field measurements are integrated to satellite data. Here, we studied the spatial distribution of PFG using machine learning and a combination of field measurements, UAV imagery (spatial resolution: 2 cm), and PlanetScope multi-temporal imagery. We provide two products at two spatial resolutions: one for UAV data, which is restricted to comparatively small areas around field measurements, and one for PlanetScope, which covers large parts of northeastern Mongolia. The results showed that the overall accuracies of UAV classification were 91–95%, whereas those of PlanetScope were 78–95%. In integrating the classified UAV data to the PlaneScope data, our proposed model minimized the scale issue that often impedes classification. Importantly, our findings revealed that the ecological effects of dirt road and railroad extended up to 60–120 m into the adjacent, otherwise less degraded steppe vegetation. A comparison between burned and unburned areas in different years indicates that wildfires affect the composition of PFG in reducing the fractional cover of graminoids and forbs, and that increasing cover of bare ground leads to a distinct and patchy mosaic of different vegetation types.}
}
@article{NAKSHMI20201981,
title = {Optimizing Quality and Outputs by Improving Variable Rate Prescriptions in Agriculture using UAVs},
journal = {Procedia Computer Science},
volume = {167},
pages = {1981-1990},
year = {2020},
note = {International Conference on Computational Intelligence and Data Science},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2020.03.229},
url = {https://www.sciencedirect.com/science/article/pii/S1877050920306955},
author = {J V N Nakshmi and K S Hemanth and J Bharath},
keywords = {Agriculture, UAVs, Machine Learning, Deep Learning, Optimization},
abstract = {Agriculture was the most prominent occupation in India once upon a time. Nowadays due to various changes in technology, living style, trends, environment, and climate changes 80% of the population are not willing to be a farmer anymore. If this continues what could be the state of tomorrow’s world. In today’s world, the same technology can be implemented in the agriculture sectors for optimizing the output and fetching the quality crop. For retrieving best harvest some solutions based on images taken by satellites can be analyzed and appropriate prescriptions are given for the crops. This work proposes a system to identify the quality of the crop, fungus detection and infected areas by surveying based on image pattern recognition by collecting the pictures are taken by UAVs (Unmanned Aerial Vehicle); these images are very close to the crops for detecting weeds, differentiating the dried, healthy leaves and identifying the ripen fruits with different levels of intersections. This solution achieves a 50% growth in the harvest and quality of the crop. These technologies should again pave a way for agriculture to be a major occupation in India.}
}
@article{GARILLI2021103477,
title = {Automatic detection of stone pavement's pattern based on UAV photogrammetry},
journal = {Automation in Construction},
volume = {122},
pages = {103477},
year = {2021},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2020.103477},
url = {https://www.sciencedirect.com/science/article/pii/S0926580520310578},
author = {Erika Garilli and Nazarena Bruno and Federico Autelitano and Riccardo Roncella and Felice Giuliani},
keywords = {Pavement management system, Stone pavement, Segmental pavement, Automatic classification, Deep learning, Convolutional neural network},
abstract = {Pavement management system (PMS) is a set of tools that assist road agencies in finding optimal strategies for maintaining pavements in a serviceable condition over a period of time. Usually, municipalities base their PMS on the deterioration monitoring through a visual survey but the distresses identification is complex and the operations are based on visual and instrumental inspections. As regards natural stone pavements, which are very widespread in the road heritage of cities, in literature there are very few studies. The authors analyzed two supervised classification approaches (Semi-Automatic Classification Plugin for QGIS and a Convolutional Neural Network (CNN)), based on Unmanned Aerial Vehicle (UAV) photogrammetry, to detect stone pavement's pattern. This study showed that using a U-Net CNN on images obtained from UAV is an excellent alternative to the traditional manual inspection and can be implemented for other types of stone pavements, also with the aim of distress identification.}
}
@article{WU2020105504,
title = {Extracting apple tree crown information from remote imagery using deep learning},
journal = {Computers and Electronics in Agriculture},
volume = {174},
pages = {105504},
year = {2020},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2020.105504},
url = {https://www.sciencedirect.com/science/article/pii/S0168169920301605},
author = {Jintao Wu and Guijun Yang and Hao Yang and Yaohui Zhu and Zhenhai Li and Lei Lei and Chunjiang Zhao},
keywords = {UAV, Apple tree, Deep learning, Computer vision, Detection, Segmentation},
abstract = {Manual measurement and visual inspection is a common practice for acquiring crop data in orchards and is a labor-intensive, time-consuming, and costly task. Accurate and rapid acquisition of crop data is vital for monitoring the dynamics of tree growth and optimizing farm management. In this work, we present a technique for orchard data acquisition and analysis that uses remote imagery acquired from unmanned aerial vehicles (UAVs) combined with deep learning convolutional neural networks to automatically detect and segment individual trees and measure the crown width, perimeter, and crown projection area of apple trees. By using an UAV platform, 50 high-resolution images of apple trees were collected from an orchard during dormancy (bare branches), and then each apple tree was detected by using a Faster R-CNN object detector. Based on these results, each tree was segmented by using a U-Net deep learning network. After convex tree boundaries were extracted from the semantic segmentation results by using an efficient pruning strategy, the crown parameters were automatically calculated, and the accuracy was compared with that obtained by manual delineation. The results show that the proposed remote sensing technique can be used to detect and count apple trees with precision and recall of 91.1% and 94.1%, respectively, segment their branches with an overall accuracy of 97.1%, and estimate crown parameter with an overall accuracy exceeding 92%. We conclude that this method not only saves labor by avoiding field measurements but also allows growers to dynamically monitor the growth of orchard trees.}
}
@article{BARRETO2021106493,
title = {Automatic UAV-based counting of seedlings in sugar-beet field and extension to maize and strawberry},
journal = {Computers and Electronics in Agriculture},
volume = {191},
pages = {106493},
year = {2021},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2021.106493},
url = {https://www.sciencedirect.com/science/article/pii/S016816992100510X},
author = {Abel Barreto and Philipp Lottes and Facundo Ramón {Ispizua Yamati} and Stephen Baumgarten and Nina Anastasia Wolf and Cyrill Stachniss and Anne-Katrin Mahlein and Stefan Paulus},
keywords = {Deep learning, FCN, UAV, Sugar beet, Plant segmentation, Time-series, Intra-row distance, Growth stage},
abstract = {Counting crop seedlings is a time-demanding activity involved in diverse agricultural practices like plant cultivating, experimental trials, plant breeding procedures, and weed control. Unmanned Aerial Vehicles (UAVs) carrying RGB cameras are novel tools for automatic field mapping, and the analysis of UAV images by deep learning methods can provide relevant agronomic information. UAV-based camera systems and a deep learning image analysis pipeline are implemented for a fully automated plant counting in sugar beet, maize, and strawberry fields in the present study. Five locations were monitored at different growth stages, and the crop number per plot was automatically predicted by using a fully convolutional network (FCN) pipeline. Our FCN-based approach is a single model for jointly determining both the exact stem location of crop and weed plants and a pixel-wise plant classification considering crop, weed, and soil. To determinate the approach performance, predicted crop counting was compared to visually assessed ground truth data. Results show that UAV-based counting of sugar-beet plants delivers forecast errors lower than 4.6%, and the main factors for performance are related to the intra-row distance and the growth stage. The pipeline’s extension to other crops is possible; the errors of the predictions are lower than 4% under practical field conditions for maize and strawberry fields. This work highlight the feasibility of automatic crop counting, which can reduce manual effort to the farmers.}
}
@article{LEE2022104138,
title = {Bounding-box object augmentation with random transformations for automated defect detection in residential building façades},
journal = {Automation in Construction},
volume = {135},
pages = {104138},
year = {2022},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2022.104138},
url = {https://www.sciencedirect.com/science/article/pii/S0926580522000115},
author = {Kisu Lee and Sanghyo Lee and Ha Young Kim},
keywords = {Data augmentation, Multi-class defect detection, Bounding box, Efficient maintenance strategy, Residential building façade, Unmanned aerial vehicles},
abstract = {This study proposes a novel bounding-box object augmentation (BoxAug) method to improve the performance of deep learning models in detecting defects in residential building façades. The most significant characteristic of the method is that it augments objects in images, rather than augmenting images, to solve the data imbalance problem. Moreover, it employs the bounding-box form for object detection, instead of the segmentation mask form. To evaluate the method, 7635 images obtained using unmanned aerial vehicles were utilized as the original training dataset. The faster region-based convolutional neural network model trained with the augmented training dataset using the method exhibited better performance than the model trained with the original dataset. Particularly, the class with the least objects in the original dataset displayed a markedly improved performance. Thus, the method can serve as an auxiliary method for effectively augmenting real-world image datasets with an unbalanced number of objects.}
}
@article{YANG2019140,
title = {Application of reinforcement learning in UAV cluster task scheduling},
journal = {Future Generation Computer Systems},
volume = {95},
pages = {140-148},
year = {2019},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2018.11.014},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X18325299},
author = {Jun Yang and Xinghui You and Gaoxiang Wu and Mohammad Mehedi Hassan and Ahmad Almogren and Joze Guna},
keywords = {Reinforcement learning, UAV cluster, Task scheduling},
abstract = {Recently, unmanned aerial vehicle (UAV) clusters have been widely used in various applications due to its high flexibility, large coverage and reliable transmission efficiency. In order to achieve the collaboration of multiple UAV tasks within a UAV cluster, we propose a task-scheduling algorithm based on reinforcement learning in this paper, which enables the UAV to adjust its task strategy automatically and dynamically using its calculation of task performance efficiency. As the UAV needs to perform real-time tasks while working in a dynamic environment without centralized control, it needs to learn tasks according to real-time data. Reinforcement learning has the ability to carry out real-time learning and decision making based on the environment, which is an appropriate and feasible method for the task scheduling of UAV clusters. From this perspective, we discuss reinforcement learning that solves the channel allocation problem existing in UAV cluster task scheduling. Finally, this paper also discusses several research problems that may be faced by the further application of UAV cluster task scheduling.}
}
@article{DOU2022,
title = {Event-triggered-based Adaptive Dynamic Programming for Distributed Formation Control of Multi-UAV},
journal = {Journal of the Franklin Institute},
year = {2022},
issn = {0016-0032},
doi = {https://doi.org/10.1016/j.jfranklin.2022.02.034},
url = {https://www.sciencedirect.com/science/article/pii/S0016003222001491},
author = {Liqian Dou and Siyuan Cai and Xiuyun Zhang and Xiaotong Su and Ruilong Zhang},
keywords = {Adaptive dynamic programming, Event triggering, Optimal formation tracking control, Quadrotor UAV},
abstract = {This paper is concerned with the distributed formation control problem of multi-quadrotor unmanned aerial vehicle (UAV) in the framework of event triggering. First, for the position loop, an adaptive dynamic programming based on event triggering is developed to design the formation controller. The critic-only network structure is adopted to approximate the optimal cost function. The merit of the proposed algorithm lies in that the event triggering mechanism is incorporated the neural network (NN) to reduce calculations and actions of the multi-UAV system, which is significant for the practical application. What’s more, a new weight update law based on the gradient descent technology is proposed for the critic NN, which can ensure that the solution converges to the optimal value online. Then, a finite-time attitude tracking controller is adopted for the attitude loop to achieve rapid attitude tracking. Finally, the efficiency of the proposed method is illustrated by numerical simulations and experimental verification.}
}
@article{GUO2021107127,
title = {Learning-based collision-free coordination for a team of uncertain quadrotor UAVs},
journal = {Aerospace Science and Technology},
volume = {119},
pages = {107127},
year = {2021},
issn = {1270-9638},
doi = {https://doi.org/10.1016/j.ast.2021.107127},
url = {https://www.sciencedirect.com/science/article/pii/S1270963821006374},
author = {Yaohua Guo and Gang Chen and Tao Zhao},
keywords = {Learning-based coordination, Uncertain UAVs, Collision avoidance},
abstract = {This paper investigates the safe coordination problem for a team of quadrotor unmanned air vehicles (UAVs) in the presence of model uncertainties and polygonal obstacles. Firstly, collision avoidance potential functions (PFs) related with both positions and velocities are utilized to construct the basic and bounded controller for achieving collision-free coordination. Then, in order to enhance the tracking performance under model uncertainties, an complementary control is developed via approximate dynamic programming (ADP), where the unknown dynamics of UAVs are accurately estimated in finite-time. Through using stored data in learning-based ADP, the approximated error of the weights in critic neural network converges with finitely excited signal. The sufficient conditions of the closed-loop system stability and collision avoidance are derived. The performance of the learning-based coordination methodology is demonstrated via simulation results.}
}
@article{HU2021187,
title = {Relevant experience learning: A deep reinforcement learning method for UAV autonomous motion planning in complex unknown environments},
journal = {Chinese Journal of Aeronautics},
volume = {34},
number = {12},
pages = {187-204},
year = {2021},
issn = {1000-9361},
doi = {https://doi.org/10.1016/j.cja.2020.12.027},
url = {https://www.sciencedirect.com/science/article/pii/S100093612030594X},
author = {Zijian HU and Xiaoguang GAO and Kaifang WAN and Yiwei ZHAI and Qianglong WANG},
keywords = {Autonomous Motion Planning (AMP), Deep Deterministic Policy Gradient (DDPG), Deep Reinforcement Learning (DRL), Sampling method, UAV},
abstract = {Unmanned Aerial Vehicles (UAVs) play a vital role in military warfare. In a variety of battlefield mission scenarios, UAVs are required to safely fly to designated locations without human intervention. Therefore, finding a suitable method to solve the UAV Autonomous Motion Planning (AMP) problem can improve the success rate of UAV missions to a certain extent. In recent years, many studies have used Deep Reinforcement Learning (DRL) methods to address the AMP problem and have achieved good results. From the perspective of sampling, this paper designs a sampling method with double-screening, combines it with the Deep Deterministic Policy Gradient (DDPG) algorithm, and proposes the Relevant Experience Learning-DDPG (REL-DDPG) algorithm. The REL-DDPG algorithm uses a Prioritized Experience Replay (PER) mechanism to break the correlation of continuous experiences in the experience pool, finds the experiences most similar to the current state to learn according to the theory in human education, and expands the influence of the learning process on action selection at the current state. All experiments are applied in a complex unknown simulation environment constructed based on the parameters of a real UAV. The training experiments show that REL-DDPG improves the convergence speed and the convergence result compared to the state-of-the-art DDPG algorithm, while the testing experiments show the applicability of the algorithm and investigate the performance under different parameter conditions.}
}
@article{LIU2022101496,
title = {A greedy-model-based reinforcement learning algorithm for Beyond-5G cooperative data collection},
journal = {Physical Communication},
volume = {50},
pages = {101496},
year = {2022},
issn = {1874-4907},
doi = {https://doi.org/10.1016/j.phycom.2021.101496},
url = {https://www.sciencedirect.com/science/article/pii/S1874490721002305},
author = {Xinyu Liu and Qingfeng Zhou and Chi-Tsun Cheng and Chanzi Liu},
keywords = {Data collection, Cooperative, Mobile sink, UAVs, Beyond-5G, Intelligent communication, Reinforcement learning},
abstract = {Data collection is an essential part of Beyond-5G and Internet of Things applications. In urban area, heterogeneous access points such as Wi-Fi routers and base stations can meet the required communication coverage and bandwidth in data collection processes. However, in remote area, without communication infrastructures, it is hard to guarantee the communication quality of a large-scale data aggregation network. An existing approach is to use an unmanned aerial vehicle (UAV) to act as a mobile sink to perform data collection and increase the coverage of intelligent wireless sensing and communications. The efficiency and the reliability of such a UAV-assisted data collection system can be significantly enhanced with an intelligent cooperative strategy for the sensors deployed in the field to communicate with the UAV. Furthermore, an energy-efficient trajectory planning algorithm is crucial to address the physical limitations of the UAV in this application. In this paper, a data collection process is modeled as a Markov decision process (MDP). The paper begins with proposing two heuristic greedy algorithms, namely distance-greedy (DG) algorithm and rate-greedy (RG) algorithm, which are designed based on prior knowledge of the system and can guarantee the completion of the data collection process in a remote area without the help of fixed communication infrastructures. Based on the outcomes, a multi-agent greedy-model-based reinforcement learning (MG-RL) algorithm is proposed, which specifically designs the environmental state and the reward scheme, and introduces multiple UAVs with different parameters to explore environments in parallel to accelerate the training. In conclusion, the two proposed greedy algorithms have lower complexity of implementation while the proposed MG-RL algorithm yields practical UAVs’ flight trajectories and shortens the time for completing a data collection task.}
}
@article{ABDULRIDHA2020135,
title = {Detecting powdery mildew disease in squash at different stages using UAV-based hyperspectral imaging and artificial intelligence},
journal = {Biosystems Engineering},
volume = {197},
pages = {135-148},
year = {2020},
issn = {1537-5110},
doi = {https://doi.org/10.1016/j.biosystemseng.2020.07.001},
url = {https://www.sciencedirect.com/science/article/pii/S1537511020301926},
author = {Jaafar Abdulridha and Yiannis Ampatzidis and Pamela Roberts and Sri Charan Kakarla},
keywords = {Disease detection, Vegetation indices, Remote sensing, Machine learning},
abstract = {In this study hyperspectral imaging (380–1020 nm) and machine learning were utilised to develop a technique for detecting different disease development stages (asymptomatic, early, intermediate, and late disease stage) of powdery mildew (PM) in squash. Data were collected in the laboratory as well as in the field using an unmanned aerial vehicle (UAV). Radial basis function (RBF) was used to discriminate between healthy and diseased plants, and to classify the severity level (disease stage) of a plant; the most significant bands to differentiate between healthy and different stages of disease development were selected (388 nm, 591 nm, 646 nm, 975 nm, and 1012 nm). Furthermore, 29 spectral vegetation indices (VIs) were tested and evaluated for their ability to detect and classify healthy and PM-infected plants; the M value was used to evaluate the VIs. The water index (WI) and the photochemical reflectance index (PRI) were able to accurately detect and classify PM in asymptomatic, early, and late development stages under laboratory conditions. Under field conditions (UAV-based), the spectral ratio of 761 (SR761) accurately detected PM in early stages, and the chlorophyll index green (CI green), the normalised difference of 750/705 (ND 750/705), the green normalised difference vegetation index (GNDVI), and the spectral ratio of 850 (SR850) in late stages. The classification results, by using RBF, in laboratory conditions for the asymptomatic and late stage was 82% and 99% respectively, while in field conditions it was 89% and 96% in early and late disease development stages, respectively.}
}
@article{KOLLE2021100001,
title = {The Hessigheim 3D (H3D) benchmark on semantic segmentation of high-resolution 3D point clouds and textured meshes from UAV LiDAR and Multi-View-Stereo},
journal = {ISPRS Open Journal of Photogrammetry and Remote Sensing},
volume = {1},
pages = {100001},
year = {2021},
issn = {2667-3932},
doi = {https://doi.org/10.1016/j.ophoto.2021.100001},
url = {https://www.sciencedirect.com/science/article/pii/S2667393221000016},
author = {Michael Kölle and Dominik Laupheimer and Stefan Schmohl and Norbert Haala and Franz Rottensteiner and Jan Dirk Wegner and Hugo Ledoux},
keywords = {Semantic segmentation, UAV Laser scanning, Multi-View-Stereo, 3D point cloud, 3D textured mesh, Multi-modality, Multi-temporality},
abstract = {Automated semantic segmentation and object detection are of great importance in geospatial data analysis. However, supervised machine learning systems such as convolutional neural networks require large corpora of annotated training data. Especially in the geospatial domain, such datasets are quite scarce. Within this paper, we aim to alleviate this issue by introducing a new annotated 3D dataset that is unique in three ways: i) The dataset consists of both an Unmanned Aerial Vehicle (UAV) laser scanning point cloud and a 3D textured mesh. ii) The point cloud features a mean point density of about 800 ​pts/m2 and the oblique imagery used for 3D mesh texturing realizes a ground sampling distance of about 2–3 ​cm. This enables the identification of fine-grained structures and represents the state of the art in UAV-based mapping. iii) Both data modalities will be published for a total of three epochs allowing applications such as change detection. The dataset depicts the village of Hessigheim (Germany), henceforth referred to as H3D - either represented as 3D point cloud H3D(PC) or 3D mesh H3D(Mesh). It is designed to promote research in the field of 3D data analysis on one hand and to evaluate and rank existing and emerging approaches for semantic segmentation of both data modalities on the other hand. Ultimately, we hope that H3D will become a widely used benchmark dataset in company with the well-established ISPRS Vaihingen 3D Semantic Labeling Challenge benchmark (V3D). The dataset can be downloaded from https://ifpwww.ifp.uni-stuttgart.de/benchmark/hessigheim/default.aspx.}
}
@article{ALTINORS2021108325,
title = {A sound based method for fault detection with statistical feature extraction in UAV motors},
journal = {Applied Acoustics},
volume = {183},
pages = {108325},
year = {2021},
issn = {0003-682X},
doi = {https://doi.org/10.1016/j.apacoust.2021.108325},
url = {https://www.sciencedirect.com/science/article/pii/S0003682X21004199},
author = {Ayhan Altinors and Ferhat Yol and Orhan Yaman},
keywords = {UAV motors, Statistical feature extraction, Machine learning, Sound-based fault detection},
abstract = {The motors of the Unmanned Aerial Vehicle are critical parts, especially when used in applications such as military and defense systems. The fact that the brushless DC (BLDC) motors used in UAVs operate at high speed causes malfunctions. In this study, propeller, eccentric and bearing failures, which are frequently seen in UAV motors, were created. Then the fault diagnosis was made by applying the recommended method on the sound data received from the motors. Signal pre-processing, feature extraction, and machine learning methods were applied to the obtained sound dataset. Decision tree (DT), Support Vector Machines (SVM), and k Nearest Neighbor (KNN) algorithms are used for machine learning. The results have been obtained using three different UAV motors of 1400 KV, 2200 KV, and 2700 KV. For the 2200 KV motor, the accuracy of 99.16%, 99.75%, and 99.75% was calculated in DT, SVM, and KNN algorithms, respectively. The high accuracy of the proposed method indicates that the study will contribute to the studies in the relevant field. Another advantage is that the method is fast and able to work in real-time on embedded systems.}
}
@article{ZHU2020105786,
title = {Estimating leaf chlorophyll content of crops via optimal unmanned aerial vehicle hyperspectral data at multi-scales},
journal = {Computers and Electronics in Agriculture},
volume = {178},
pages = {105786},
year = {2020},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2020.105786},
url = {https://www.sciencedirect.com/science/article/pii/S0168169920314423},
author = {Wanxue Zhu and Zhigang Sun and Ting Yang and Jing Li and Jinbang Peng and Kangying Zhu and Shiji Li and Huarui Gong and Yun Lyu and Binbin Li and Xiaohan Liao},
keywords = {Unmanned aerial vehicle (UAV), Hyperspectral, Chlorophyll, Machine learning, Precision agriculture},
abstract = {Leaf chlorophyll content (LCC) is a crucial indicator of nutrition in crop plants and can be applied to assess the adequacy of nitrogen (N) fertilizer for crops while reducing N losses to farmland. This study estimated the LCC of maize and wheat, and comprehensively examined the effects of the spectral information and spatial scale of unmanned aerial vehicle (UAV) imagery, and the effects of phenotype and phenology on LCC estimation. A Cubert S185 hyperspectral camera onboard a DJI M600 Pro was used to conduct six flight missions over a long-term experimental field with five N applications (0, 70, 140, 210, and 280 kg N ha−1) and two irrigation levels (60% and 80% field water capacity) during the growing seasons of wheat and maize in 2019. Four regression algorithms, that is, multi-variable linear regression, random forest, backpropagation neural network, and support vector machine, were used for modeling. Leaf, canopy, and hybrid scale hyperspectral variables (H-variables) were used as inputs for the statistical LCC models. Optimal H-variables for modeling were determined by Pearson correlation filtering followed by a recursive feature elimination procedure. The results showed that (1) H-variables at the canopy- and leaf-scales were appropriate for wheat and maize LCC estimation, respectively; (2) the robustness of LCC estimation was in the order of the flowering stage > heading stage > grain filling stage for wheat and early grain filling stage > flowering stage > jointing stage for maize; (3) the reflectance of the red edge, green, and blue bands were the most important inputs for LCC modeling, and the optimal vegetation indices differed for the various growth stages and crops; and (4) all four algorithms maintained an acceptable accuracy with respect to LCC estimation, although random forest and support vector machine were slightly better. This study is valuable for the design of appropriate schemes for the spectral and scale issues of UAV sensors for LCC estimation regarding specific crop phenotype and phenology periods, and further boosts the applications of UAVs in precision agriculture.}
}
@article{ZAHMATKESH2020102139,
title = {Fog computing for sustainable smart cities in the IoT era: Caching techniques and enabling technologies - an overview},
journal = {Sustainable Cities and Society},
volume = {59},
pages = {102139},
year = {2020},
issn = {2210-6707},
doi = {https://doi.org/10.1016/j.scs.2020.102139},
url = {https://www.sciencedirect.com/science/article/pii/S2210670720301268},
author = {Hadi Zahmatkesh and Fadi Al-Turjman},
keywords = {IoT, Fog computing, Smart-cities, Caching, UAV, Machine learning},
abstract = {In recent decade, the number of devices involved with the Internet of Things (IoT) phenomena has increased dramatically. Parallel to this, fog computing paradigm has been introduced in order to support the computational demand of latency-sensitive and real-time IoT applications. The main support the fog paradigm can provide for these applications is through enabling computing at the edge of the network closer to the end users and IoT devices. Moreover, in sustainable smart cities, fog computing can be utilized as an efficient framework to reduce delays and enhance energy efficiency of the system. This article considers possible fog computing applications and potential enabling technologies towards sustainable smart cities in the IoT environments. In addition, different caching techniques and the use of Unmanned Aerial Vehicles (UAVs), and various Artificial Intelligence (AI) and Machine Learning (ML) techniques in caching data for fog-based IoT systems are comprehensively discussed. Finally, the potential and challenges of such systems are also highlighted.}
}
@article{ISHENGOMA2021106124,
title = {Identification of maize leaves infected by fall armyworms using UAV-based imagery and convolutional neural networks},
journal = {Computers and Electronics in Agriculture},
volume = {184},
pages = {106124},
year = {2021},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2021.106124},
url = {https://www.sciencedirect.com/science/article/pii/S0168169921001423},
author = {Farian Severine Ishengoma and Idris A. Rai and Rutabayiro Ngoga Said},
keywords = {UAV, Faw, CNN, Maize, VGG16, VGG19, InceptionV2, MobileNetV2},
abstract = {Precision farming technologies are important for a stable supply of healthy food. Every year farmers harvest a few amounts of crops because of the pests and diseases. Automatic detection of crop health from images helps to increase yield and profit to farmers while reducing input cost and time. In this study, the aim was to precisely detect maize leaves that have been infected by fall armyworms (faw) by using automatic recognition algorithm models based on the convolution neural network (CNN) namely, VGG16, VGG19, InceptionV3 and MobileNetV2. These models were used to investigate the infected maize leaves that were captured using an unmanned aerial vehicle (UAV) remote-sensing technologies. The models were simulated with original images and modified images obtained by applying Shi-Tomas corner detection techniques. In both cases, the CNN models we considered outperformed the previously proposed models in terms of accuracy. Besides, the performance of the models trained with modified images has been significantly improved such that the accuracy of VGG16, VGG19, InceptionV3 and MobilenetV2 increased from 96%, 93.08%, 96.75% and 98.25% to 99.92%, 99.67%, 100% and 100%, respectively.}
}
@article{KUMAR2021100198,
title = {Velocity controllers for a swarm of unmanned aerial vehicles},
journal = {Journal of Industrial Information Integration},
volume = {22},
pages = {100198},
year = {2021},
issn = {2452-414X},
doi = {https://doi.org/10.1016/j.jii.2020.100198},
url = {https://www.sciencedirect.com/science/article/pii/S2452414X2030073X},
author = {Sandeep A. Kumar and J. Vanualailai and B. Sharma and A. Prasad},
keywords = {Unmanned aerial vehicles, Path planning, Find-path problem, Lyapunov stability, Swarm intelligence, Lagrangian swarm, Collision avoidance, Artificial potential field method},
abstract = {The biological concept of a swarm’s emergent behavior resulting from the self-organization of the individuals in a swarm is an important piece of information that can be integrated into industrial manufacturing of unmanned ground or aerial vehicles. In this paper, we present a Lyapunov-based path planner that organizes the individuals, governed by a simple rigid-body model, of a swarm into formations which ensure a safe collision-free path for the swarm to its target in obstacle-cluttered environments. Via the Direct Method of Lyapunov that establishes the swarm system’s stability, we propose the instantaneous velocity function for each individual. The velocity functions could be easily integrated into industrial designs for the individuals of a swarm of unmanned ground or aerial vehicles. As an application, we consider the planar formation of a swarm of unmanned aerial vehicles (UAVs) using their kinematic models for simplicity. Via computer simulations, we illustrate several self-organization such as elliptic and linear formations, split/rejoin, and tunneling maneuvers for obstacle avoidance and helical trajectory for milling. In particular, the linear formations have been proposed as suitable for the surveillance of large areas such as the Exclusive Economic Zones.}
}
@article{ZHANG2020658,
title = {Power cognition: Enabling intelligent energy harvesting and resource allocation for solar-powered UAVs},
journal = {Future Generation Computer Systems},
volume = {110},
pages = {658-664},
year = {2020},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2019.05.068},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X19308349},
author = {Jing Zhang and Minhao Lou and Lin Xiang and Long Hu},
keywords = {Solar-powered unmanned aerial vehicle, Power cognition, Resource allocation, Reinforcement learning},
abstract = {Solar-powered unmanned aerial vehicles (SUAVs) are a promising solution to increase the flight time of unmanned aerial vehicles (UAVs) in the sky, reducing human interventions for battery charging. Exploiting networked SUAVs for providing long-duration wireless communication cannot only improve the signal transmission reliability but realize energy autonomy. To reap these benefits, in this article, we propose an efficient energy and radio resource management framework based on intelligent power cognition at the SUAVs. Thereby, power-cognitive SUAVs can learn the environment including the spatial distributions of solar energy density, the channel state evolution, and the traffic patterns of wireless communication applications in adaption to the environment changes. These SUAVs intelligently adjust the energy harvesting, information transmission, and flight trajectory to improve the utilization of solar energy for two primary goals: staying aloft over a long time period and achieving high communication performance. We adopt reinforcement learning to compute the optimal decisions for maximization of the total system throughput within the lifetime of the SUAV. Simulation results show that the proposed power cognition scheme can simultaneously improve the communication throughput and the harvested energy for SUAVs.}
}
@article{WANG20208342,
title = {Predictive control of air-fuel ratio in aircraft engine on fuel-powered unmanned aerial vehicle using fuzzy-RBF neural network},
journal = {Journal of the Franklin Institute},
volume = {357},
number = {13},
pages = {8342-8363},
year = {2020},
issn = {0016-0032},
doi = {https://doi.org/10.1016/j.jfranklin.2020.03.016},
url = {https://www.sciencedirect.com/science/article/pii/S0016003220301903},
author = {Yixuan Wang and Yan Shi and Maolin Cai and Weiqing Xu},
abstract = {Air-fuel ratio control is important for optimizing the performance and reducing the exhaust emission of fuel-powered unmanned aerial vehicles 0(UAVs). However, previous studies on engine air-fuel ratio control neglect the fuel injection process and load of UAV propellers, and traditional methods could not satisfy the control requirement of an air-fuel ratio error of less than  ± 2% when a UAV operates in different conditions. Here, to optimize the control performance, the mean value model of a fuel-powered aircraft engine is improved and an adaptive fuzzy radial basis function (RBF) neural network is used to perform predictive control. The simulation results are compared with the traditional control and some previous studies, and engine control experiments are implemented for demonstration. The simulation and experimental results indicate that, through predictive control using a fuzzy-RBF neural network, the air-fuel ratio of the aircraft engine can be controlled within  ± 1% bounds of the stoichiometric value (14.7), and the highest error can be reduced by 68 to 75% compared with that in the previous work and the traditional neural network model, traditional PID method, and second-order sliding mode strategy. This research can be considered as a reference for intelligent algorithm applications on the power system of fuel-powered UAVs.}
}
@article{TESKE2019226,
title = {Optimised dispensing of predatory mites by multirotor UAVs in wind: A distribution pattern modelling approach for precision pest management},
journal = {Biosystems Engineering},
volume = {187},
pages = {226-238},
year = {2019},
issn = {1537-5110},
doi = {https://doi.org/10.1016/j.biosystemseng.2019.09.009},
url = {https://www.sciencedirect.com/science/article/pii/S1537511019308311},
author = {April L. Teske and Gang Chen and Christian Nansen and Zhaodan Kong},
keywords = {Unmanned aerial vehicle, Precision pest management, Machine learning, Natural enemies, Precision agriculture, Predatory mites},
abstract = {Multirotor unmanned aerial vehicles (UAVs), or drones, are increasingly being used to spray liquid pesticides to control emerging pest infestations in field crops. In recent years, UAVs have been used to release predatory mites and other natural enemies to optimise and promote sustainable pest management practices by relying less on conventional insecticides. Drone dispensed samples of predatory mites are typically mixed with a granular material, vermiculite, which serves as a filler. The low density of the vermiculite and weather conditions (mainly wind), influences the distribution pattern of predatory mites when delivered by a UAV-based system. The purpose of this paper is to present a data-driven methodology to develop a mathematical model that can be used to optimise UAV-based autonomous dispensing of predatory mites. The model characterises the distribution of vermiculite as a function of wind speed and direction, and the UAVs altitude and forward speed. The model is constructed by first conducting outdoor experiments and then using machine-learning techniques on the collected data. The constructed model produced an average generalisation error of 12.8%, RMSE. Due to its parametric and predictive nature, the model is amenable for the future design of UAV flight controllers that can compensate for the targeting error caused by wind. The proposed modelling methodology could be useful not only for the dispensing of predatory mites, but also for other UAV dispensing applications, such as liquid or granular pesticide deliveries.}
}
@article{WENG2014134,
title = {Immune network-based swarm intelligence and its application to unmanned aerial vehicle (UAV) swarm coordination},
journal = {Neurocomputing},
volume = {125},
pages = {134-141},
year = {2014},
note = {Advances in Neural Network Research and Applications Advances in Bio-Inspired Computing: Techniques and Applications},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2012.06.053},
url = {https://www.sciencedirect.com/science/article/pii/S0925231213001653},
author = {Liguo Weng and Qingshan Liu and Min Xia and Y.D. Song},
keywords = {Swarm intelligence, Immune network, Swarm coordination, UAVs},
abstract = {In this paper, we first investigate the fundamentals of the immune system and the principles of the antibodies and how antibodies work cooperatively to achieve swarm coordination and hence a successful immune response. Based on the study, we propose a multi-agent cooperative operation strategy for the immune system based on the immune network theory. In order to achieve successful swarm coordination, we design each agent to select its favorable strategy according to distributed sensing through local communication. Experiments show that this Immunology-inspired Cooperative Operation strategy performs well even under dynamically changing environment. Its effectiveness is also verified by numerical simulation on multiple unmanned aerial vehicle (UAV) coordination.}
}
@article{SILVA2019147,
title = {Cooperative unmanned aerial vehicles with privacy preserving deep vision for real-time object identification and tracking},
journal = {Journal of Parallel and Distributed Computing},
volume = {131},
pages = {147-160},
year = {2019},
issn = {0743-7315},
doi = {https://doi.org/10.1016/j.jpdc.2019.04.009},
url = {https://www.sciencedirect.com/science/article/pii/S0743731518308839},
author = {Samuel Henrique Silva and Paul Rad and Nicole Beebe and Kim-Kwang Raymond Choo and Mahesh Umapathy},
keywords = {Object tracking, Re-identification, Unmanned aerial vehicles, Deep learning, Facial recognition},
abstract = {Human tracking is an important challenge in a wide variety of applications, including but not limited to, surveillance, military operations, and disaster relief services. Unmanned Aerial Vehicles (UAVs) allow the surveying of dangerous or impassable areas from a safe distance. They also provide a machine-based capability, which may not only solve resource constraint issues, but can also improve effectiveness and efficiency in the tracking task. The effectiveness of tracking is directly related to the angle of view and degree of freedom of the camera system. In this paper, we introduce a decentralized, distributed deep learning algorithm for Real-Time Privacy-preserving Target Tracking Re-Identification (RPTT-ReID) used by cooperative UAVs in complex and adversarial environments involving motion, crowded scenes, and varied camera angles. The efficiency of RPTT-ReID makes it amenable to edge computing applications. The proposed algorithmic approach resolves shortfalls with current tracking algorithms, specifically challenges in maintaining tracking when subjects cross paths, switch identity, or are occluded in a frame of view. We demonstrate the power of our approach both in single and multi-UAV scenarios to track movable targets by extracting the facial embedding information in crowds, in order to ensure the privacy of individuals captured by the UAVs without compromising the capability for target re-identification. We validate RPTT-ReID on a challenging video dataset of crowded scenes. Our experimental evaluation shows that the proposed approach is capable of tracking and re-identifying people in crowds despite blended trajectories with minimum and maximum accuracy of 79.91 ± 0.2% and 93.27 ± 0.1% respectively. The proposed approach is 18% faster than previous methods for tracking in crowded urban environments.}
}
@article{YU2020105939,
title = {Decentralized fractional-order backstepping fault-tolerant control of multi-UAVs against actuator faults and wind effects},
journal = {Aerospace Science and Technology},
volume = {104},
pages = {105939},
year = {2020},
issn = {1270-9638},
doi = {https://doi.org/10.1016/j.ast.2020.105939},
url = {https://www.sciencedirect.com/science/article/pii/S1270963820306210},
author = {Ziquan Yu and Youmin Zhang and Bin Jiang and Chun-Yi Su and Jun Fu and Ying Jin and Tianyou Chai},
keywords = {Unmanned aerial vehicles, Fault-tolerant control, Fractional-order control, Actuator faults, Wind effects},
abstract = {Concurrent occurrences of actuator faults and wind effects can significantly threaten the flight safety of multiple unmanned aerial vehicles (multi-UAVs). To address this difficult control problem against actuator faults and wind effects, a composite decentralized fractional-order (FO) backstepping adaptive neural fault-tolerant control (FTC) method is presented for the attitude synchronization tracking of multi-UAVs, which is integrated with neural networks (NNs), disturbance observers (DOs), FO calculus, and high-order sliding-mode differentiators (HOSMDs). The distinctive feature of this work is addressing the attitude synchronization tracking control problem with actuator faults and wind effects in a decentralized framework and proposing a composite approximation method for multi-UAVs. It is shown that by using Lyapunov methods the synchronization tracking control is achieved even when multi-UAVs simultaneously encounter wind effects and actuator faults. Comparative simulation results illustrate the theoretical feasibility.}
}
@article{SIERRA201870,
title = {Modelling engineering systems using analytical and neural techniques: Hybridization},
journal = {Neurocomputing},
volume = {271},
pages = {70-83},
year = {2018},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2016.11.099},
url = {https://www.sciencedirect.com/science/article/pii/S0925231217312250},
author = {J. Enrique Sierra and Matilde Santos},
keywords = {Identification, Adaptive neural networks, Neuro-fuzzy, Parametric techniques, Hybridization, Unmanned aerial vehicles (UAV)},
abstract = {From real input/output data, different control-oriented models of a quadrotor unmanned aerial vehicle (UAV) are obtained by applying different identification methods. Parametric techniques, neural networks, neuro-fuzzy inference systems, and the hybridization of some of them are applied. The identified models are analyzed and compared in the time and frequency domains. We conclude that the hybridization of analytical and intelligent techniques is a good choice to model of complex systems while keeping a good balance between accuracy and computational cost. In addition, off-line trained neural networks and adaptive networks with on-line learning are analyzed, and their advantages and disadvantages regarding modelling are presented. The influence of the partition of the training and validation dataset on the model error is also discussed.}
}
@article{WANG2022126416,
title = {Convolutional neural-network-based automatic dam-surface seepage defect identification from thermograms collected from UAV-mounted thermal imaging camera},
journal = {Construction and Building Materials},
volume = {323},
pages = {126416},
year = {2022},
issn = {0950-0618},
doi = {https://doi.org/10.1016/j.conbuildmat.2022.126416},
url = {https://www.sciencedirect.com/science/article/pii/S095006182200109X},
author = {Zheng-fang Wang and Yan-fei Yu and Jing Wang and Jian-qing Zhang and Hong-liang Zhu and Peng Li and Lei Xu and Hao-nan Jiang and Qing-mei Sui and Lei Jia and Jiang-ping Chen},
keywords = {Convolutional neural network, Dam inspection, Seepage defect, Unmanned aerial vehicles},
abstract = {Seepage inspections are vitally important for delineating damage zones and ensuring the long-term safe operation of dams. However, vegetation, complex backgrounds, and low signal-to-noise ratio and poor thermogram resolution impose significant adverse effects on automated results. In this study, a novel convolutional neural network is proposed to automatically identify dam-surface seepage from thermograms collected by an unmanned aerial vehicle carrying a thermal imaging camera. An auxiliary input branch with two specially designed modules (i.e., a region-of-key-temperature fusion unit and a convolutional block attention module) are added to a U-Net frame to reduce the false-alarm rate caused by “seepage-like” background interference on the dams and accurately identify seepage profiles with clear boundaries from the low-resolution thermograms. The method is utilized on actual dams, and experimental results confirm its superiority, even with interference. The Dice coefficient score and intersection-over-union metrics of the proposed network are 87.58 and 78.12 %, respectively: an increase of 3.67 and 4.80% over U-Net and 1.18 and 1.43 % over Mobile DeepLabv3. Under the same computing environment and dataset, the training time of the proposed network in this paper is 8 min and 57 s, U-Net is 3 min and 13 s, Mobile DeepLabv3 is 12 min and 44 s. This study provides a promising and cost-effective automatic dam-surface seepage inspection method.}
}
@article{AMORIM2020113437,
title = {Assessing a swarm-GAP based solution for the task allocation problem in dynamic scenarios},
journal = {Expert Systems with Applications},
volume = {152},
pages = {113437},
year = {2020},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2020.113437},
url = {https://www.sciencedirect.com/science/article/pii/S095741742030261X},
author = {Junier Caminha Amorim and Vander Alves and Edison Pignaton {de Freitas}},
keywords = {Unmanned aerial vehicles, Task allocation, Swarm intelligence, Replication, Dynamic},
abstract = {Swarm-GAP is a heuristic that combines a swarm intelligence strategy with the generalized assignment problem (GAP) method. This approach is especially appropriate when there are agents engaged in a collaborative task, but in general, heuristics have drawbacks to optimize resource allocation. A previous work proposed the usage of three swarm-GAP variants to solve the task allocation problem among agents representing a group of Unmanned Aerial Vehicles (UAVs) aiming at the optimization of their resources usage applied in the context of static environments. However, there is a lack of empirical assessment of these algorithms in dynamic scenarios, i.e., with some attributes changing along the system execution. Such changes represent important features of real-world application scenarios, such as in military operations in which a number of non-expected events may happen, e.g., loss of members of the UAV-team or onboard sensor failure. Therefore, the contributions of this work are the performance evaluation of the original algorithms in dynamic context, and the extension of these algorithms to properly address more realistic dynamic scenarios. Considering changes in some attributes of the environment, a trade-off in terms of the quality in the mission performance and the overhead in the communication among the UAVs is explored. The empirical assessment of the original algorithms and the proposed extensions were performed by conducting independent replications in a scenario where the number of agents (UAVs) changes at runtime and adaptations occur autonomously to maintain the mission execution. The acquired results provide evidence that the proposed solution is capable of dealing with dynamic scenarios, covering the gap left by other works in the literature, and enriching the realism of applications in autonomous intelligent systems.}
}
@article{APOLOAPOLO2020126030,
title = {Deep learning techniques for estimation of the yield and size of citrus fruits using a UAV},
journal = {European Journal of Agronomy},
volume = {115},
pages = {126030},
year = {2020},
issn = {1161-0301},
doi = {https://doi.org/10.1016/j.eja.2020.126030},
url = {https://www.sciencedirect.com/science/article/pii/S1161030120300381},
author = {O.E. Apolo-Apolo and J. Martínez-Guanter and G. Egea and P. Raja and M. Pérez-Ruiz},
keywords = {Fruit detection, Machine learning, Citrus, Neural networks, Harvest, Fruit size, Yield estimation},
abstract = {Accurate and early estimation of citrus yields is important for both producers and agricultural cooperatives to be competitive and make informed decisions when selling their products. Yield estimation is key for predicting stock volumes, avoiding stock ruptures and planning harvesting operations. Visual yield estimations have traditionally been employed, resulting in inaccurate and misleading information. The main goal of this study was to develop an automated image processing methodology to detect, count and estimate the size of citrus fruits on individual trees using deep learning techniques. During 3 consecutive annual campaigns, a total of 20 trees from a commercial citrus grove were monitored using images captured from an unmanned aerial vehicle (UAV). These trees were harvested manually, and fruit sizes were measured. A Faster R-CNN Deep Learning model was trained using a custom dataset to detect oranges in the obtained images. An average standard error (SE) of 6.59 % was obtained between visual counting and the model’s fruit detection. Using the detected fruits, fruit size estimation was also performed. The promising results obtained indicate that this size estimation method can be employed for size discrimination prior to harvest. A model based on Long Short-term Memory (LSTM) was trained for yield estimation per tree and for a total yield estimation. The actual and estimated yields per tree were compared, resulting in an approximate error of SE = 4.53 % and a standard deviation of SD = 0.97 Kg. The actual total yield, the estimated total yield and the total yield estimated by an expert technician were compared. The error in the estimation by the technician was SE = 13.74 %, while the errors in the model were SE = 7.22 % and SD = 4083.58 Kg. These promising results demonstrate the potential of the present technique to provide yield estimates for citrus fruits or even other types of fruit.}
}
@article{YOUME2021361,
title = {Deep Learning and Remote Sensing: Detection of Dumping Waste Using UAV},
journal = {Procedia Computer Science},
volume = {185},
pages = {361-369},
year = {2021},
note = {Big Data, IoT, and AI for a Smarter Future},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2021.05.037},
url = {https://www.sciencedirect.com/science/article/pii/S1877050921011224},
author = {Ousmane Youme and Theophile Bayet and Jean Marie Dembele and Christophe Cambier},
keywords = {Deep Learning, Remote Sensing, Convolutional Neuron Network, Single shot Detector},
abstract = {An important success and use of Deep Learning in recent years has been in the field of image processing. Research on Deep Learning has shown that these architectures particularly convolution neuron network (CNN) can learn solutions with human-level capability for certain visual tasks. These techniques have been used in particular in remote sensing image analysis tasks, including object detection on images, image fusion, image recording, scene classification, segmentation, object-based image analysis, land use and land cover classification (LULC). In this paper we present an automatic solution for the detection of clandestine waste dumps using unmanned aerial vehicle (UAV) images in the Saint Louis area of Senegal, West Africa. This is a challenging task given the very high spatial resolution of UAV images (on the order of a few centimeters) and the extremely high level of detail, which require suitable automatic analysis methods. Our proposed method begins by 1) segmenting image into four (4) regions, which can be used as an input image 2) Reduce size of input images into 300x300x3 for the CNN entries 3) Labelling the image by determining region of interest. Next Single shot detector SSD is used to mine highly descriptive features from these datasets. The results show that the model recognizes well the areas concerned but presents difficulties on some areas lacking clear ground truths.}
}
@article{YANG2020105817,
title = {Adaptive autonomous UAV scouting for rice lodging assessment using edge computing with deep learning EDANet},
journal = {Computers and Electronics in Agriculture},
volume = {179},
pages = {105817},
year = {2020},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2020.105817},
url = {https://www.sciencedirect.com/science/article/pii/S0168169920319542},
author = {Ming-Der Yang and Jayson G. Boubin and Hui Ping Tsai and Hsin-Hung Tseng and Yu-Chun Hsu and Christopher C. Stewart},
keywords = {Autonomous UAV, Deep learning, Edge computing, Rice lodging, Adaptive},
abstract = {Rice is a globally important crop that will continue to play an essential role in feeding our world as we grapple with climate change and population growth. Lodging is a primary threat to rice production, decreasing rice yield, and quality. Lodging assessment is a tedious task and requires heavy labor and a long duration due to the vast land areas involved. Newly developed autonomous crop scouting techniques have shown promise in mapping crop fields without any human interaction. By combining autonomous scouting and lodged rice detection with edge computing, it is possible to estimate rice lodging faster and at a much lower cost than previous methods. This study presents an adaptive crop scouting mechanism for Autonomous Unmanned Aerial Vehicles (UAV). We simulate UAV crop scouting of rice fields at multiple levels using deep neural networks and real UAV energy profiles, focusing on areas with high lodging. Using the proposed method, we can scout rice fields 36% faster than conventional scouting methods at 99.25% accuracy.}
}
@article{WANG20202877,
title = {Multi-UAV coordination control by chaotic grey wolf optimization based distributed MPC with event-triggered strategy},
journal = {Chinese Journal of Aeronautics},
volume = {33},
number = {11},
pages = {2877-2897},
year = {2020},
note = {SI: Emerging Technologies of Unmanned Aerial Vehicles},
issn = {1000-9361},
doi = {https://doi.org/10.1016/j.cja.2020.04.028},
url = {https://www.sciencedirect.com/science/article/pii/S1000936120302387},
author = {Yingxun WANG and Tian ZHANG and Zhihao CAI and Jiang ZHAO and Kun WU},
keywords = {Chaotic Grey Wolf Optimization (CGWO), Coordination control, Distributed Model Predictive Control (MPC), Event-triggered strategy, Multi-UAV},
abstract = {The paper proposes a new swarm intelligence-based distributed Model Predictive Control (MPC) approach for coordination control of multiple Unmanned Aerial Vehicles (UAVs). First, a distributed MPC framework is designed and each member only shares the information with neighbors. The Chaotic Grey Wolf Optimization (CGWO) method is developed on the basis of chaotic initialization and chaotic search to solve the local Finite Horizon Optimal Control Problem (FHOCP). Then, the distributed cost function is designed and integrated into each FHOCP to achieve multi-UAV formation control and trajectory tracking with no-fly zone constraint. Further, an event-triggered strategy is proposed to reduce the computational burden for the distributed MPC approach, which considers the predicted state errors and the convergence of cost function. Simulation results show that the CGWO-based distributed MPC approach is more computationally efficient to achieve multi-UAV coordination control than traditional method.}
}
@article{CORTE2020105815,
title = {Forest inventory with high-density UAV-Lidar: Machine learning approaches for predicting individual tree attributes},
journal = {Computers and Electronics in Agriculture},
volume = {179},
pages = {105815},
year = {2020},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2020.105815},
url = {https://www.sciencedirect.com/science/article/pii/S0168169920308838},
author = {Ana Paula Dalla Corte and Deivison Venicio Souza and Franciel Eduardo Rex and Carlos Roberto Sanquetta and Midhun Mohan and Carlos Alberto Silva and Angelica Maria Almeyda Zambrano and Gabriel Prata and Danilo Roberti {Alves de Almeida} and Jonathan William Trautenmüller and Carine Klauberg and Anibal {de Moraes} and Mateus N. Sanquetta and Ben Wilkinson and Eben North Broadbent},
keywords = {Forest variables, Support Vector Regression, Random forest, Artificial Neural Networks, Extreme Gradient Boosting, Forest attributes},
abstract = {The high dimensionality of data generated by Unmanned Aerial Vehicle(UAV)-Lidar makes it difficult to use classical statistical techniques to design accurate predictive models from these data for conducting forest inventories. Machine learning techniques have the potential to solve this problem of modeling forest attributes from remotely sensed data. This work tests four different machine learning approaches - namely Support Vector Regression, Random Forest, Artificial Neural Networks, and Extreme Gradient Boosting - on high-density GatorEye UAV-Lidar point clouds for indirect estimation of individual tree dendrometric metrics (field-derived) such as diameter at breast height, total height, and timber volume. A total of 370 trees had their dbh and height measured for validation purposes. Using LAStools we generated normalized Light Detection and Ranging (Lidar) point clouds and created a raster canopy height model at a 0.5x0.5 m spatial resolution following the construction of a digital terrain model and a digital surface model. The R package ‘lidR’ was set with the functions tree_detection (local maximum filter algorithm) and lastrees. Subsequently, we applied the function tree_metrics to extract individual metrics. Machine learning techniques were applied to the derived metrics to estimate dendrometric field measures. The machine learning models (MLM) with optimal hyperparameters showed similar predictive performances for modeling the variables diameter, height, and volume. All models had a rRMSE below 15% (for diameter at breast height), 9% (for height) and 29% (for volume). The Support Vector Regression algorithm showed the best performance. Our work demonstrates that all tested machine learning models are adequate and robust to handle the high dimensionality of UAV-Lidar data for the estimation of individual attributes, with Support Vector Regression model being the best performer in terms of minimal error rates.}
}
@article{BRAVO2021101692,
title = {Automatic detection of potential mosquito breeding sites from aerial images acquired by unmanned aerial vehicles},
journal = {Computers, Environment and Urban Systems},
volume = {90},
pages = {101692},
year = {2021},
issn = {0198-9715},
doi = {https://doi.org/10.1016/j.compenvurbsys.2021.101692},
url = {https://www.sciencedirect.com/science/article/pii/S0198971521000995},
author = {Daniel Trevisan Bravo and Gustavo Araujo Lima and Wonder Alexandre Luz Alves and Vitor Pessoa Colombo and Luc Djogbénou and Sergio Vicente Denser Pamboukian and Cristiano Capellani Quaresma and Sidnei Alves de Araujo},
keywords = {Vector control, Mosquito, Unmanned aerial vehicle, Objects detection, Convolutional neural network, Support vector machine, Bag of visual words},
abstract = {The World Health Organization (WHO) has stated that effective vector control measures are critical to achieving and sustaining reduction of vector-borne infectious disease incidence. Unmanned aerial vehicles (UAVs), popularly known as drones, can be an important technological tool for health surveillance teams to locate and eliminate mosquito breeding sites in areas where vector-borne diseases such as dengue, zika, chikungunya or malaria are endemic, since they allow the acquisition of aerial images with high spatial and temporal resolution. Currently, though, such images are often analyzed through manual processes that are excessively time-consuming when implementing vector control interventions. In this work we propose computational approaches for the automatic identification of objects and scenarios suspected of being potential mosquito breeding sites from aerial images acquired by drones. These approaches were developed using convolutional neural networks (CNN) and Bag of Visual Words combined with the Support Vector Machine classifier (BoVW + SVM), and their performances were evaluated in terms of mean Average Precision - mAP-50. In the detection of objects using a CNN YOLOv3 model the rate of 0.9651 was obtained for the mAP-50. In the detection of scenarios, in which the performances of BoVW+SVM and a CNN YOLOv3 were compared, the respective rates of 0.6453 and 0.9028 were obtained. These findings indicate that the proposed CNN-based approaches can be used to identify potential mosquito breeding sites from images acquired by UAVs, providing substantial improvements in vector control programs aiming the reduction of mosquito-breeding sources in the environment.}
}
@article{XIONG2020261,
title = {Visual detection of green mangoes by an unmanned aerial vehicle in orchards based on a deep learning method},
journal = {Biosystems Engineering},
volume = {194},
pages = {261-272},
year = {2020},
issn = {1537-5110},
doi = {https://doi.org/10.1016/j.biosystemseng.2020.04.006},
url = {https://www.sciencedirect.com/science/article/pii/S1537511020300970},
author = {Juntao Xiong and Zhen Liu and Shumian Chen and Bolin Liu and Zhenhui Zheng and Zhuo Zhong and Zhengang Yang and Hongxing Peng},
keywords = {Unmanned aerial vehicle, Green mango, Deep learning method, Visual detection},
abstract = {In this paper, a visual detection method by a UAV (unmanned aerial vehicle) was proposed to detect green mangoes on the surface of the tree crown rapidly and meet the need of estimating the number of mango fruits in orchards. The YOLOv2 model was used for quick detection of mango images captured by a UAV. First, mango images were collected by a UAV. These images were marked manually and used to build a training set and a test set. The parameters of the model were determined by experiments. The resolution of the images was 544 × 544 pixels. The batch size was 64, and the initial learning rate was 0.01. The mAP (mean average precision) of the trained model on the training set was 86.4%. Good detection results were achieved on images containing different fruit numbers and different lighting conditions with a precision of 96.1% and a recall rate of 89.0%. Finally, an experiment was conducted to estimate the actual number of green mango fruits. A method of generating an image of the whole mango tree was designed. The fruit numbers estimation model for green mango was obtained by linear fitting between the actual number and the detected number of mangoes. From the comparison of the fruit numbers of 10 mango trees determined by manual calculation and model prediction, an estimation error rate of 1.1% was achieved. The result demonstrated that the algorithm was effective for green mango detection and provided a methodological reference for quick estimation of the number of green mango fruits in orchards.}
}
@article{DAI2020346,
title = {Automatic obstacle avoidance of quadrotor UAV via CNN-based learning},
journal = {Neurocomputing},
volume = {402},
pages = {346-358},
year = {2020},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2020.04.020},
url = {https://www.sciencedirect.com/science/article/pii/S0925231220305853},
author = {Xi Dai and Yuxin Mao and Tianpeng Huang and Na Qin and Deqing Huang and Yanan Li},
keywords = {Obstacle avoidance, Unmanned aerial vehicle, Convolutional neural network, Collision probability},
abstract = {In this paper, a CNN-based learning scheme is proposed to enable a quadrotor unmanned aerial vehicle (UAV) to avoid obstacles automatically in unknown and unstructured environments. In order to reduce the decision delay and to improve the robustness for the UAV, a two-stage end-to-end obstacle avoidance architecture is designed, where a forward-facing monocular camera is used only. In the first stage, a convolutional neural network (CNN)-based model is adopted as the prediction mechanism. Utilizing three effective operations, namely depthwise convolution, group convolution and channel split, the model predicts the steering angle and the collision probability simultaneously. In the second stage, the control mechanism maps the steering angle to an instruction that changes the yaw angle of the UAV. Consequently, when the UAV encounters an obstacle, it can avoid collision by steering automatically. Meanwhile, the collision probability is mapped as a forward speed to maintain the flight or stop going forward. The presented automatic obstacle avoidance scheme of quadrotor UAV is verified by several indoor/outdoor tests, where the feasibility and efficacy have been demonstrated clearly. The novelties of the method lie in its low sensor requirement, light-weight network structure, strong learning ability and environmental adaptability.}
}
@article{NOGUERA20211,
title = {Nutritional status assessment of olive crops by means of the analysis and modelling of multispectral images taken with UAVs},
journal = {Biosystems Engineering},
volume = {211},
pages = {1-18},
year = {2021},
issn = {1537-5110},
doi = {https://doi.org/10.1016/j.biosystemseng.2021.08.035},
url = {https://www.sciencedirect.com/science/article/pii/S1537511021002191},
author = {Miguel Noguera and Arturo Aquino and Juan M. Ponce and António Cordeiro and José Silvestre and Rocío Arias-Calderón and Maria da Encarnação Marcelo and Pedro Jordão and José M. Andújar},
keywords = {Multispectral, Nitrogen, Phosphorus, Potassium, Artificial Neural Network (ANN), Unmanned Aerial Vehicle (UAV), Precision agriculture},
abstract = {This research was aimed at developing an efficient method for Nitrogen, Phosphorus, and Potassium (NPK) foliar content retrieval in olive trees by means of the analysis and modelling multispectral images taken by an unmanned aerial vehicle (UAV) under field conditions. To this end, an experiment was carried out in a super hight density olive orchard. The fertirrigation system of the experimental area was sectorized to obtain plots with different status of NPK. The orchard was overflown with a UAV equipped with a multispectral camera that photographed the entire experimental surface. A new image analysis approach was developed for integrating all the spectral images gathered during the flight in orthomosaics from which to automatically extract information from discrete points. Finally, several retrieval techniques (partial least squares regression, artificial neural network (ANN), support vector regression and Gaussian process regression) were evaluated for NPK leaf content retrieval by using the spectral data as input variables, and the results of chemical analyses as reference. Among all, the best results were obtained by ANN approach (N (R2 = 0.63), P (R2 = 0.89), K (R2 = 0.93)). These results showed the suitability of the proposed image processing approach and indicate ANN as the best recovery technique for the experimental conditions evaluated. However, the approach must be validated under other environmental conditions, olive varieties and plant vegetative stages before making fertilization recommendations.}
}
@article{WANNURAZWINSYAZWANI20221265,
title = {Automated image identification, detection and fruit counting of top-view pineapple crown using machine learning},
journal = {Alexandria Engineering Journal},
volume = {61},
number = {2},
pages = {1265-1276},
year = {2022},
issn = {1110-0168},
doi = {https://doi.org/10.1016/j.aej.2021.06.053},
url = {https://www.sciencedirect.com/science/article/pii/S111001682100418X},
author = {R. {Wan Nurazwin Syazwani} and H. {Muhammad Asraf} and M.A. {Megat Syahirul Amin} and K.A. {Nur Dalila}},
keywords = {Pineapple crown, Crop recognition, Image processing, Precision agriculture, Yield counting},
abstract = {Automated fruit identification or recognition using image processing is a key element in precision agriculture for performing object detection in large crop plots. Automation of fruit recognition for the captured top-view of RGB based images using an unmanned aerial vehicle (UAV) is a challenge. Image analysis demonstrated the difficulty of processing the captured image under variant illumination in natural environment and with textured objects of non-ideal geometric shapes. However, this is subjected to certain consideration settings and image-processing algorithms. The study presents an automatic method for identifying and recognising the pineapple’s crown images in the designated plot using image processing and further counts the detected images using machine learning classifiers namely artificial neural network (ANN), support vector machine (SVM), random forest (RF), naive Bayes (NB), decision trees (DT) and k-nearest neighbours (KNN). The high spatial-resolution aerial images were pre-processed and segmented, and its extracted features were analysed according to shape, colour and texture for recognising the pineapple crown before classifying it as fruit or non-fruit. Feature fusion using one-way analysis of variance (ANOVA) was incorporated in this study to optimise the performance of machine learning classifier. The algorithm was quantitatively analysed and validated for performance via accuracy, specificity, sensitivity and precision. The detection for the pineapple’s crown images with ANN-GDX classification has demonstrated best performance fruit counting with accuracy of 94.4% and has thus demonstrated clear potential application of an effective RGB images analysis for the pineapple industry.}
}
@article{YOO201713216,
title = {Learning communication delay patterns for remotely controlled UAV networks**This work has been supported in part by the Knut and Alice Wallenberg Foundation the Swedish Research Council (VR) and the Swedish Foundation for Strategic Research, including the SSF-NRF Sweden-Korea research program.},
journal = {IFAC-PapersOnLine},
volume = {50},
number = {1},
pages = {13216-13221},
year = {2017},
note = {20th IFAC World Congress},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2017.08.1954},
url = {https://www.sciencedirect.com/science/article/pii/S2405896317325843},
author = {Jaehyun Yoo and Karl H. Johansson},
keywords = {Networked robotics, unmanned aerial vehicles, time-delay systems, machine learning},
abstract = {This paper deals with collaborative unmanned aerial vehicles (UAVs) that are remotely controlled from a cloud server. The main contribution is to apply machine learning technique to find a pattern of network-induced effects on maneuvers of UAVs, in order to compensate for time delays and packet losses in remote communication. As machine learning technique, a Gaussian process (GP) based approach is employed due to its computational simplicity and flexibility in modelling complex expressions using a small number of parameters. We combine a deterministic compensation for an enhanced GP model to overcome a problem of the lack of training data at the beginning of training phase. This is done by defining training data input as a set of delayed observation and the deterministic compensation term, and by training the GP on residual between the true state and the input set. The proposed algorithm is evaluated to collaborative trajectory tracking of two UAVs. Simulations are performed for various delays and tracking scenarios. It is shown that the better tracking results are achieved compared to a conventional linear compensation algorithm.}
}
@article{DAI2019114,
title = {The multi-objective deployment optimization of UAV-mounted cache-enabled base stations},
journal = {Physical Communication},
volume = {34},
pages = {114-120},
year = {2019},
issn = {1874-4907},
doi = {https://doi.org/10.1016/j.phycom.2019.03.007},
url = {https://www.sciencedirect.com/science/article/pii/S1874490718303033},
author = {Haibo Dai and Haiyang Zhang and Baoyun Wang and Luxi Yang},
keywords = {Unmanned aerial vehicle, Deployment, Reinforcement learning, Caching, Multi-objective optimization},
abstract = {The deployment of unmanned aerial vehicle (UAV)-mounted base stations is emerging as an effective solution for providing wireless communication service to ground terminals (GTs) which have failed to be associated with ground base stations for some reason. Meanwhile, with the propose of reducing the transmission latency and easing the load of backhaul links between UAVs and the core network, UAVs are equipped with the ability of caching popular contents in the storage of base stations. In this paper, we investigate the efficient deployment problem of UAVs (such as transmitting power, number of UAVs, locations and caching) while guaranteeing the quality of service requirements. In this case, the UAV plays the role of a coordinator to provide high-quality communication service for GTs as well as maximize the benefit of caching. However, there exists an intractable issue that UAVs need to consider the optimization problem of multiple performance metrics with various types of optimization variables. To tackle the challenge, we propose a reinforcement learning-based approach to solve the multi-objective deployment problem while maintaining the optimal tradeoff between power consumption and backhaul saving. Numerical results evaluate the performance of the proposed algorithm.}
}
@article{ZHOU2021100001,
title = {Strawberry Maturity Classification from UAV and Near-Ground Imaging Using Deep Learning},
journal = {Smart Agricultural Technology},
volume = {1},
pages = {100001},
year = {2021},
issn = {2772-3755},
doi = {https://doi.org/10.1016/j.atech.2021.100001},
url = {https://www.sciencedirect.com/science/article/pii/S2772375521000010},
author = {Xue Zhou and Won Suk Lee and Yiannis Ampatzidis and Yang Chen and Natalia Peres and Clyde Fraisse},
keywords = {Strawberry maturity classification, UAV imaging, Near-ground imaging, Deep learning},
abstract = {Strawberry is ranked third in the value of production of the crops in Florida, USA. Classifying strawberry maturity and monitoring strawberry growth status in the field is very critical for accurate strawberry yield prediction, efficient strawberry field management, and achieving the highest crop production. The traditional method of distinguishing strawberry maturity is based on either physical appearance or internal chemical substance content. However, the traditional method is time-consuming and costly. In this research, an automatic strawberry maturity classification system was developed for the rapid and accurate classification of different strawberry maturity stages. A state-of-the-art deep learning method, You Only Look Once (YOLOv3), which is good at small object detection, was trained and applied to detect strawberry flowers and strawberry fruit at different maturity stages. Two strawberry image acquisition methods, aerial imaging and near-ground imaging, were compared by using the same deep learning image processing method. As a result, three and seven strawberry maturity stages were classified for unmanned aerial vehicle (UAV) images and near-ground digital camera images, respectively. For UAV images, the highest mean average precision (mAP) of strawberry maturity classification was 0.88 for a test data set at 2 m, and the highest classification average precision (AP) was 0.93 for fully matured fruit. For near-ground digital camera images, the mAP of strawberry maturity classification was 0.89, and the highest classification AP was 0.94 for fully matured fruit as well. The result shows that YOLOv3 is an excellent approach for strawberry maturity classification on both image types.}
}
@article{YU2021119493,
title = {Early detection of pine wilt disease using deep learning algorithms and UAV-based multispectral imagery},
journal = {Forest Ecology and Management},
volume = {497},
pages = {119493},
year = {2021},
issn = {0378-1127},
doi = {https://doi.org/10.1016/j.foreco.2021.119493},
url = {https://www.sciencedirect.com/science/article/pii/S037811272100582X},
author = {Run Yu and Youqing Luo and Quan Zhou and Xudong Zhang and Dewei Wu and Lili Ren},
keywords = {Pine wilt disease, Early detection, Multispectral imagery, Deep learning, Faster R-CNN, YOLOv4},
abstract = {Pine wilt disease (PWD) is a global devastating threat to forest ecosystems. Therefore, a feasible and effective approach to precisely monitor PWD infection is indispensable, especially at the early stages. However, a precise definition of “early stage” and a rapid and high-efficiency method to detect PWD infection have not been well established. In this study, we systematically divided the PWD infection into green, early, middle, and late stages based on the needle color, the resin secretion, and whether the pine wood nematode (PWN) was carried. Simultaneously, an unmanned aerial vehicle (UAV) equipped with multispectral cameras was used to obtain images. Two target detection algorithms (Faster R-CNN and YOLOv4) and two traditional machine learning algorithms based on feature extraction (random forest and support vector machine) were employed to realize the recognition of infected pine trees. Moreover, we took into consideration of the influence of green broad-leaved trees on the identification of pine trees at the early stage of PWD infection. We obtained the following results: (1) the accuracy of Faster R-CNN (60.98–66.7%) was higher than that of YOLOv4 (57.07–63.55%), but YOLOv4 outperformed in terms of model size, processing speed, training time, and testing time; (2) although the traditional machine learning models had higher accuracy (73.28–79.64%), they were not able to directly identify the object from the images; (3) the accuracy of early detection of PWD infection showed an increase of 3.72–4.29%, from 42.36–44.59% to 46.08–48.88%, when broad-leaved trees were considered. In this study, the combination of UAV-based multispectral images and target detection algorithms allowed us to monitor the occurrence of PWD and obtain the distribution of infected trees at an early stage, which can provide technical support for the prevention and control of PWD.}
}
@article{LIANG2019100763,
title = {An improved sensing method using radio frequency detection},
journal = {Physical Communication},
volume = {36},
pages = {100763},
year = {2019},
issn = {1874-4907},
doi = {https://doi.org/10.1016/j.phycom.2019.100763},
url = {https://www.sciencedirect.com/science/article/pii/S1874490719302678},
author = {Xiaolin Liang and Yongling Jiang and Thomas Aaron Gulliver},
keywords = {Micro unmanned aerial vehicle (MUAV), Artificial neural network (ANN), Radio frequency (RF), Singular value decomposition (SVD), Higher order cumulant (HOC), Region of interest (ROI)},
abstract = {Easy-to-pilot unmanned aerial vehicles (UAVs) are now readily available off the shelf. This has created the problem of micro unmanned aerial vehicle (MUAV) in private or sensitive areas which can represent a personal or public threat. An improved MUAV detection method is proposed in this paper using artificial neural network (ANN) based feature extraction and reconstruction. The clutters form static/non-static objects in the collected radio frequency (RF) signals are suppressed via employing the background estimate method and suppressing the linear trend. Then principal component of the RF signals are extracted based on the singular value decomposition (SVD) method. The higher order cumulant (HOC) algorithm is utilized to improve the signal to noise ratio (SNR) of the RF signals, which can make Gaussian noise prone to zero. Hilbert spectrums of the analyzed features are considered to determine if one MUAV is present in the detection area using ANN. Finally, the region of interest (ROI) containing RF signals is defined to estimate the azimuth and first frequency of MUAV. Detection results in real-life scenarios are obtained which show the effectiveness of the proposed technique in detecting MUAV.}
}
@article{AKTER2021108519,
title = {CNN-SSDI: Convolution neural network inspired surveillance system for UAVs detection and identification},
journal = {Computer Networks},
volume = {201},
pages = {108519},
year = {2021},
issn = {1389-1286},
doi = {https://doi.org/10.1016/j.comnet.2021.108519},
url = {https://www.sciencedirect.com/science/article/pii/S1389128621004503},
author = {Rubina Akter and Van-Sang Doan and Jae-Min Lee and Dong-Seong Kim},
keywords = {Convolution neural network, Drone detection and identification, Radio frequency signal},
abstract = {In recent years, the availability of commercial unmanned air vehicles (UAVs) has increased enormously because of device miniaturization and low cost. However, the abuse of UAVs needs to be investigated to prevent serious security threats for civilians. Therefore, this paper presents a convolutional neural network-based surveillance system for drone detection and its type identification, namely CNN-SSDI. The network architecture is cleverly designed based on deep convolution layers to successfully learn all intrinsic feature maps of radio-frequency signals that are collected from three different types of drones. Further, a detailed comparative analysis of various kernel impairments of the convolution layer structure was investigated under various performance metrics evaluation and higher accuracy in drone surveillance systems. According to the empirical results, CNN-SSDI can detect a UAV with 99.8% accuracy and recognize drone types with an accuracy of 94.5%, which outperforms other existing drone detection and identification techniques.}
}
@article{NI2022101575,
title = {A Generative adversarial learning strategy for enhanced lightweight crack delineation networks},
journal = {Advanced Engineering Informatics},
volume = {52},
pages = {101575},
year = {2022},
issn = {1474-0346},
doi = {https://doi.org/10.1016/j.aei.2022.101575},
url = {https://www.sciencedirect.com/science/article/pii/S1474034622000477},
author = {Futao Ni and Zhili He and Shang Jiang and Weiguo Wang and Jian Zhang},
keywords = {Deep learning, Generative Adversarial Network, Dense block, Crack detection},
abstract = {Traditional manual crack detection has been gradually replaced by unmanned aerial vehicles (UAVs) since automation and intelligence became the inevitable trends in routine bridge maintenance. Deep learning-based real-time crack detection is an important link in this automation process. However, due to the limitations of the field of view and airborne computer performance, it is challenging to balance crack detection accuracy and efficiency at the same time. To address this issue, a novel Generative Adversarial Network (GAN)-based strategy is proposed in this paper. Different from the traditional ways, the GAN-based strategy can introduce the morphological difference between the predictions and the manual labels into training process, further improving the network performance while ensuring detection efficiency. Three lightweight networks with different depths are designed based on the Dense Block to analyze the impact of the proposed method. Novel Fault-Tolerance (FT) indexes are proposed to reflect the morphological differences in predictions. Finally, the effectiveness and robustness of the proposed method are verified by the crack detection of highway bridge piers. Results show that the proposed method can effectively improve the detection scores of UAV-captured images under limited network parameters.}
}
@article{HOSSEINALIZADEH20191554,
title = {How can statistical and artificial intelligence approaches predict piping erosion susceptibility?},
journal = {Science of The Total Environment},
volume = {646},
pages = {1554-1566},
year = {2019},
issn = {0048-9697},
doi = {https://doi.org/10.1016/j.scitotenv.2018.07.396},
url = {https://www.sciencedirect.com/science/article/pii/S0048969718328924},
author = {Mohsen Hosseinalizadeh and Narges Kariminejad and Omid Rahmati and Saskia Keesstra and Mohammad Alinejad and Ali {Mohammadian Behbahani}},
keywords = {Piping collapse, Unmanned aerial vehicle (UAV), Susceptibility map, Machine learning algorithms, Loess plateau},
abstract = {It is of fundamental importance to model the relationship between geo-environmental factors and piping erosion because of the environmental degradation attributed to soil loss. Methods that identify areas prone to piping erosion at the regional scale are limited. The main objective of this research is to develop a novel modeling approach by using three machine learning algorithms—mixture discriminant analysis (MDA), flexible discriminant analysis (FDA), and support vector machine (SVM) in addition to an unmanned aerial vehicle (UAV) images to map susceptibility to piping erosion in the loess-covered hilly region of Golestan Province, Northeast Iran. In this research, we have used 22 geo-environmental indices/factors and 345 identified pipes as predictors and dependent variables. The piping susceptibility maps were assessed by the area under the ROC curve (AUC). Validation of the results showed that the AUC for the three mentioned algorithms varied from 90.32% to 92.45%. We concluded that the proposed approach could efficiently produce a piping susceptibility map.}
}
@article{KALANTAR2020105748,
title = {A deep learning system for single and overall weight estimation of melons using unmanned aerial vehicle images},
journal = {Computers and Electronics in Agriculture},
volume = {178},
pages = {105748},
year = {2020},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2020.105748},
url = {https://www.sciencedirect.com/science/article/pii/S0168169920304804},
author = {Aharon Kalantar and Yael Edan and Amit Gur and Iftach Klapp},
keywords = {Precision agriculture, Deep convolutional neural network, Machine learning, Yield estimation, Weight estimation},
abstract = {Generation of yield maps enables making agronomic decisions related to resource management and marketing, leading to improved production and breeding processes. Estimating melon yield production before harvest at single-melon resolution is a labor-intensive task, requiring a detailed account of accumulated yield and general yield distribution, as well as detailed measurements of melon size and location. This study presents an algorithmic pipeline for detection and yield estimation of melons from top-view color images acquired by a digital camera mounted on an unmanned aerial vehicle. The yield estimation provides both the number of melons and the weight of each melon. The system includes three main stages: melon detection, geometric feature extraction, and individual melon yield estimation. The melon-detection process was based on the RetinaNet deep convolutional neural network. Transfer learning was used for the training to detect small objects in high-resolution images successfully. The detection process achieved an average precision score of 0.92 with a F1 score of more than 0.9 in a variety of agricultural environments. For each detected melon, feature extraction was applied using the Chan–Vese active contour algorithm and principal component analysis ellipse-fitting method. A regression model that ties the ellipse features to the melon’s weight is presented. The modified (adjusted) RAdj2 value of the regression model was 0.94. The system results for estimating the weight of a single melon measured by the mean absolute percentage error index achieved 16%. The analysis revealed that this could be decreased to 12% error with more accurate geometrical feature extraction. Overall yield estimation derived by summing the weights of all melons in the field resulted in only a 3% underestimation of the actual total yield.}
}
@article{YAN2020103594,
title = {Fixed-Wing UAVs flocking in continuous spaces: A deep reinforcement learning approach},
journal = {Robotics and Autonomous Systems},
volume = {131},
pages = {103594},
year = {2020},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2020.103594},
url = {https://www.sciencedirect.com/science/article/pii/S0921889020304346},
author = {Chao Yan and Xiaojia Xiang and Chang Wang},
keywords = {Fixed-wing UAV, Flocking, Reinforcement learning, Actor–critic},
abstract = {Fixed-Wing UAVs (Unmanned Aerial Vehicles) flocking is still a challenging problem due to the kinematics complexity and environmental dynamics. In this paper, we solve the leader–followers flocking problem using a novel deep reinforcement learning algorithm that can generate roll angle and velocity commands by training an end-to-end controller in continuous state and action spaces. Specifically, we choose CACLA (Continuous Actor–Critic Learning Automation) as the base algorithm and we use the multi-layer perceptron to represent both the actor and the critic. Besides, we further improve the learning efficiency by using the experience replay technique that stores the training data in the experience memory and samples from the memory as needed. We have compared the performance of the proposed CACER (Continuous Actor–Critic with Experience Replay) algorithm with benchmark algorithms such as DDPG and double DQN in numerical simulation, and we have demonstrated the performance of the learned optimal policy in semi-physical simulation without any parameter tuning.}
}
@article{LI2021585,
title = {Deep learning enabled localization for UAV autolanding},
journal = {Chinese Journal of Aeronautics},
volume = {34},
number = {5},
pages = {585-600},
year = {2021},
issn = {1000-9361},
doi = {https://doi.org/10.1016/j.cja.2020.11.011},
url = {https://www.sciencedirect.com/science/article/pii/S1000936120305641},
author = {Minghui LI and Tianjiang HU},
keywords = {Deep learning, Localization, Safe landing, Stereo vision, UAV autolanding},
abstract = {This article concentrates on ground vision guided autonomous landing of a fixed-wing Unmanned Aerial Vehicle (UAV) within Global Navigation Satellite System (GNSS) denied environments. Cascaded deep learning models are developed and employed into image detection and its accuracy promoting for UAV autolanding, respectively. Firstly, we design a target bounding box detection network BboxLocate-Net to extract its image coordinate of the flying object. Secondly, the detected coordinate is fused into spatial localization with an extended Kalman filter estimator. Thirdly, a point regression network PointRefine-Net is developed for promoting detection accuracy once the flying vehicle’s motion continuity is checked unacceptable. The proposed approach definitely accomplishes the closed-loop mutual inspection of spatial positioning and image detection, and automatically improves the inaccurate coordinates within a certain range. Experimental results demonstrate and verify that our method outperforms the previous works in terms of accuracy, robustness and real-time criterions. Specifically, the newly developed BboxLocate-Net attaches over 500 fps, almost five times the published state-of-the-art in this field, with comparable localization accuracy.}
}
@article{CHEN2021108434,
title = {Machine learning-based inversion of water quality parameters in typical reach of the urban river by UAV multispectral data},
journal = {Ecological Indicators},
volume = {133},
pages = {108434},
year = {2021},
issn = {1470-160X},
doi = {https://doi.org/10.1016/j.ecolind.2021.108434},
url = {https://www.sciencedirect.com/science/article/pii/S1470160X21010992},
author = {Botao Chen and Xi Mu and Peng Chen and Biao Wang and Jaewan Choi and Honglyun Park and Sheng Xu and Yanlan Wu and Hui Yang},
keywords = {UAV remote sensing, Water quality inversion, Machine learning, Urban river},
abstract = {Urban rivers play an essential role in the human environment and urban development; because of their narrow and long characteristics, challenging for general remote sensing data sources to meet the monitoring requirements. In order to solve the problem of insufficient application of remote sensing water quality monitoring in urban rivers. In this paper, based on unmanned aerial vehicles (UAV) images and measured water quality data, the genetic algorithm_extreme gradient boosting (GA_XGBoost) algorithm is used to model water quality parameters in the study area, combined with its characteristics of supporting urban river polymorphism learning and semantic feature analysis. The results show that the coefficient of determination (R2) of GA_XGBoost algorithm for chlorophyll a (Chla), total phosphorous (TP), total nitrogen (TN), ammonia–nitrogen (NH3-N) and turbidity (TUB) is 0.855, 0.699, 0.787, 0.694, and 0.597, respectively, indicating a high precision and the predicted results are consistent with the measured data. Meanwhile, this paper compares the GA_XGBoost model with other algorithms: Deep Neural Network (DNN), Random Forest, genetic algorithm_RandomForest (GA_RandomForest), adaptive boosting (AdaBoost) and genetic algorithm_adaptive boosting (GA_AdaBoost), and the performance of the GA_XGBoost model is better. At the same time, data from different periods have been added to verify the model’s applicability. Moreover, based on the inversion results, analyze from the point of view of point source pollution, non-point source pollution, etc., to further investigate the influencing factors that cause urban river pollution. The current method has important practical significance for promoting the intelligent and automatic level of water environment monitoring technology in ecological environmental protection and urban water resources protection.}
}
@article{BYCROFT201984,
title = {Comparing random forests and convoluted neural networks for mapping ghost crab burrows using imagery from an unmanned aerial vehicle},
journal = {Estuarine, Coastal and Shelf Science},
volume = {224},
pages = {84-93},
year = {2019},
issn = {0272-7714},
doi = {https://doi.org/10.1016/j.ecss.2019.04.050},
url = {https://www.sciencedirect.com/science/article/pii/S0272771418309697},
author = {Rachel Bycroft and Javier X. Leon and David Schoeman},
keywords = {Machine-learning, Sandy beach, Object-based image analysis, Drones},
abstract = {Sandy beaches are important ecosystems that line a third of the world's ice-free coastlines. Unfortunately, these environments and the life they support are often threatened by various anthropogenic and natural factors. Monitoring sandy beach health is important to aid in appropriate management decisions. One such method of quantifying environmental health is using bioindicators. Ghost crabs are a commonly used sandy beach bioindicator. Current techniques for assessing ghost crab abundance and distribution data involve manually counting each individual burrow opening, which can intrusive and timely for a large area. The aim of this study was to assesses the use of imagery from an unmanned aerial vehicle and machine-learning algorithms as an alternative approach to monitoring ghost crab burrows. The accuracy and transferability of random forest (RF) and convolutional neural networks (CNN) classifiers within an Object-Based Image Analysis (OBIA) framework were tested using hyper-resolution (0.04 m) orthomosaics from four different dates. CNN was a more robust classifier with higher accuracies (max F-score 0.84). Transferability of rule sets and models was limited for both classifiers, particularly when applied to sub-optimal imagery. Overall, we present a feasible workflow that provides ecologist and environmental managers with a cost-effective and less invasive alternative to mapping ghost crab burrows.}
}
@article{PSIROUKIS2021100002,
title = {Monitoring of free-range rabbits using aerial thermal imaging},
journal = {Smart Agricultural Technology},
volume = {1},
pages = {100002},
year = {2021},
issn = {2772-3755},
doi = {https://doi.org/10.1016/j.atech.2021.100002},
url = {https://www.sciencedirect.com/science/article/pii/S2772375521000022},
author = {Vasilis Psiroukis and Ioannis Malounas and Nikolaos Mylonas and Konstantinos-Elenos Grivakis and Spyros Fountas and Ioannis Hadjigeorgiou},
keywords = {UAV, Thermal_images, Deep_learning, Animal_population, Animal_detection, Free-range_rabbits},
abstract = {Unmanned Aerial Vehicles (UAV) imagery is a mature technology, which has found use in a number of applications in agriculture and environmental sciences. However, its application for monitoring and classification of livestock and wild animals has not yet been developed. This study presents a robust methodology to count wild and free-range rabbits and monitor their population. The aims of this study were to 1) test the capacity of the methodology in counting small nocturnal animals such as rabbits in the field, 2) assess the rabbit's density at different sites and different periods of the year and 3) record the temporal pattern of rabbits’ activity during the night hours, with the overall aim to provide a reliable and accurate tool in management studies. For this purpose, a UAV equipped with a thermal camera was used to perform night flights on the island of Lemnos, scanning selected sites and collecting aerial nadir thermal imagery data of the ground. The derived thermal images were analysed using deep learning techniques towards counting the individual animals in each image and the results were compared with manual counting conducted by a researcher. The results revealed that the deep learning approach for automated counting and rabbit recognition overall achieved comparable results to physical counting, with the final model yielding an F1-score of 0.87. However, there were differences between seasons in the methods’ accuracy. This method could be a helpful tool in assessing populations of small nocturnal animals and other free-range livestock animals.}
}
@article{MAO2021108511,
title = {Deep Learning (DL)-based adaptive transport layer control in UAV Swarm Networks},
journal = {Computer Networks},
volume = {201},
pages = {108511},
year = {2021},
issn = {1389-1286},
doi = {https://doi.org/10.1016/j.comnet.2021.108511},
url = {https://www.sciencedirect.com/science/article/pii/S1389128621004473},
author = {Qian Mao and Lin Zhang and Fei Hu and Elizabeth Serena Bentley and Sunil Kumar},
keywords = {Congestion control, Deep Learning (DL), Network coding, Transport Layer, UAV Networks},
abstract = {This paper focuses on the congestion control issues in Unmanned Aerial Vehicle (UAV) Swarm Networks (USNs). In a USN, many network factors can cause segment loss, including dynamic swarming, high mobility, and link fading loss. With traditional transport layer protocols such as Transmission Control Protocol (TCP), these losses are interpreted as congestion events and will cause the data sending rate being decreased dramatically, therefore impacting throughput. In this paper, a learning-based adaptive network coding scheme is proposed to handle segment loss. In this scheme, a certain amount of redundancy is attached to the original data. If the segment loss is caused by random factors (such as radio interference), the lost segments are retrieved by decoding. However, if the loss is caused by congestion, the sender will retransmit the lost segments and decrease the sending rate. The coding rate is a critical factor, which should guarantee that the random loss can be retrieved by decoding while the congestion loss triggers retransmission and sending rate deduction. To achieve this goal, a Deep Learning (DL) algorithm is proposed, which comprehensively considers the wireless network conditions and dynamically optimizes the coding rate. Our experimental results show that the DL-based network coding scheme provides improved throughput and end-to-end delay compared to the TCP and general network coding schemes.}
}
@article{ELEFTHEROGLOU2019113677,
title = {Intelligent data-driven prognostic methodologies for the real-time remaining useful life until the end-of-discharge estimation of the Lithium-Polymer batteries of unmanned aerial vehicles with uncertainty quantification},
journal = {Applied Energy},
volume = {254},
pages = {113677},
year = {2019},
issn = {0306-2619},
doi = {https://doi.org/10.1016/j.apenergy.2019.113677},
url = {https://www.sciencedirect.com/science/article/pii/S0306261919313649},
author = {Nick Eleftheroglou and Sina Sharif Mansouri and Theodoros Loutas and Petros Karvelis and George Georgoulas and George Nikolakopoulos and Dimitrios Zarouchas},
keywords = {Remaining useful life, Data-driven prognostics, UAVs, Li-Po batteries, End of discharge, Machine learning},
abstract = {In this paper, the discharge voltage is utilized as a critical indicator towards the probabilistic estimation of the Remaining Useful Life until the End-of-Discharge of the Lithium-Polymer batteries of unmanned aerial vehicles. Several discharge voltage histories obtained during actual flights constitute the in-house developed training dataset. Three data-driven prognostic methodologies are presented based on state-of-the-art as well as innovative mathematical models i.e. Gradient Boosted Trees, Bayesian Neural Networks and Non-Homogeneous Hidden Semi Markov Models. The training and testing process of all models is described in detail. Remaining Useful Life prognostics in unseen data are obtained from all three methodologies. Beyond the mean estimates, the uncertainty associated with the point predictions is quantified and upper/lower confidence bounds are also provided. The Remaining Useful Life prognostics during six random flights starting from fully charged batteries are presented, discussed and the pros and cons of each methodology are highlighted. Several special metrics are utilized to assess the performance of the prognostic algorithms and conclusions are drawn regarding their prognostic capabilities and potential.}
}
@article{PEARSE2020156,
title = {Detecting and mapping tree seedlings in UAV imagery using convolutional neural networks and field-verified data},
journal = {ISPRS Journal of Photogrammetry and Remote Sensing},
volume = {168},
pages = {156-169},
year = {2020},
issn = {0924-2716},
doi = {https://doi.org/10.1016/j.isprsjprs.2020.08.005},
url = {https://www.sciencedirect.com/science/article/pii/S0924271620302136},
author = {Grant D. Pearse and Alan Y.S. Tan and Michael S. Watt and Matthias O. Franz and Jonathan P. Dash},
keywords = {Deep learning, Convolutional networks, Tree seedlings, Unmanned aerial vehicles, Forest establishment, Object detection},
abstract = {Mapping of tree seedlings is useful for tasks ranging from monitoring natural succession and regeneration to effective silvicultural management. Development of methods that are both accurate and cost-effective is especially important considering the dramatic increase in tree planting that is required globally to mitigate the impacts of climate change. The combination of high-resolution imagery from unmanned aerial vehicles and object detection by convolutional neural networks (CNNs) is one promising approach. However, unbiased assessments of these models and methods to integrate them into geospatial workflows are lacking. In this study, we present a method for rapid, large-scale mapping of young conifer seedlings using CNNs applied to RGB orthomosaic imagery. Importantly, we provide an unbiased assessment of model performance by using two well-characterised trial sites together containing over 30,000 seedlings to assemble datasets with a high level of completeness. Our results showed CNN-based models trained on two sites detected seedlings with sensitivities of 99.5% and 98.8%. False positives due to tall weeds at one site and naturally regenerating seedlings of the same species led to slightly lower precision of 98.5% and 96.7%. A model trained on examples from both sites had 99.4% sensitivity and precision of 97%, showing applicability across sites. Additional testing showed that the CNN model was able to detect 68.7% of obscured seedlings missed during the initial annotation of the imagery but present in the field data. Finally, we demonstrate the potential to use a form of weakly supervised training and a tile-based processing chain to enhance the accuracy and efficiency of CNNs applied to large, high-resolution orthomosaics.}
}
@article{GOMEZSELVARAJ2020110,
title = {Detection of banana plants and their major diseases through aerial images and machine learning methods: A case study in DR Congo and Republic of Benin},
journal = {ISPRS Journal of Photogrammetry and Remote Sensing},
volume = {169},
pages = {110-124},
year = {2020},
issn = {0924-2716},
doi = {https://doi.org/10.1016/j.isprsjprs.2020.08.025},
url = {https://www.sciencedirect.com/science/article/pii/S0924271620302410},
author = {Michael {Gomez Selvaraj} and Alejandro Vergara and Frank Montenegro and Henry {Alonso Ruiz} and Nancy Safari and Dries Raymaekers and Walter Ocimati and Jules Ntamwira and Laurent Tits and Aman Bonaventure Omondi and Guy Blomme},
keywords = {Artificial Intelligence, Banana detection, Deep learning, Disease detection, High-resolution satellite image, Surveillance, UAV images},
abstract = {Front-line remote sensing tools, coupled with machine learning (ML), have a significant role in crop monitoring and disease surveillance. Crop type classification and a disease early warning system are some of these remote sensing applications that provide precise, timely, and cost-effective information at different spatial, temporal, and spectral resolutions. To our knowledge, most disease surveillance systems focus on a single-sensor based solutions and lagging the integration of multiple information sources. Moreover, monitoring larger landscapes using unmanned aerial vehicles (UAV) are challenging, and, therefore combining high resolution satellite imagery data with advanced machine learning (ML) models through the use of mobile apps could help detect and classify banana plants and provide more information on its overall health status. In this study, we classified banana under mixed-complex African landscapes through pixel-based classifications and ML models derived from multi-level satellite images (Sentinel 2, PlanetScope and WorldView-2) and UAV (MicaSense RedEdge) platforms. Our pixel-based classification from random forest (RF) model using combined features of vegetation indices (VIs) and principal component analysis (PCA) showed up to 97% overall accuracy (OA) with less than 10% omission and commission errors (OE and CE) and Kappa coefficient of 0.96 in high resolution multispectral images. We used UAV-RGB aerial images from DR Congo and Republic of Benin fields to develop a mixed-model system combining object detection model (RetinaNet) and a custom classifier for simultaneous banana localization and disease classification. Their accuracies were tested using different performance metrics. Our UAV-RGB mixed-model revealed that the developed object detection and classification model successfully classified healthy and diseased plants with 99.4%, 92.8%, 93.3% and 90.8% accuracy for the four classes: banana bunchy top disease (BBTD), Xanthomonas Wilt of Banana (BXW), healthy banana cluster and individual banana plants, respectively. These approaches of aerial image-based ML models have high potential to provide a decision support system for major banana diseases in Africa.}
}
@article{LIU2019105403,
title = {Novel docking controller for autonomous aerial refueling with probe direct control and learning-based preview method},
journal = {Aerospace Science and Technology},
volume = {94},
pages = {105403},
year = {2019},
issn = {1270-9638},
doi = {https://doi.org/10.1016/j.ast.2019.105403},
url = {https://www.sciencedirect.com/science/article/pii/S1270963819311496},
author = {Yiheng Liu and Honglun Wang and Jiaxuan Fan},
keywords = {Unmanned aerial vehicle (UAV), Autonomous aerial refueling (AAR), Probe control, Deep learning, Reinforcement learning, Preview control},
abstract = {Autonomous aerial refueling (AAR) has always been a hot research area due to its significant application and complicated control problem. In order to improve the docking precision of AAR, a novel docking controller with probe direct control and learning-based preview method is proposed. Firstly, the controlled object is transformed from receiver barycenter to probe tactfully. Then, a suitable probe direct controller designed via the combination of reference-observer-based tracking control method and the high order sliding mode control method is proposed for the probe direct control. Furthermore, a learning-based preview method is introduced to solve the tracking lag problem. The prediction of drogue motion is considered in the reference signal. Then, a novel learning algorithm, named deep learning and reinforcement learning (DLRL), which combines deep learning (DL) and reinforcement learning (RL) spatially rather than structurally like deep reinforcement learning (DRL) is proposed to generate the preview time adaptively. And a novel preview index is proposed to adapt for it. Through the combination of probe direct controller and learning-based preview method, the proposed docking controller could improve the tracking precision largely. Effectiveness of the proposed method is demonstrated by the simulations.}
}
@article{LI2021107406,
title = {Vehicle detection from road image sequences for intelligent traffic scheduling},
journal = {Computers & Electrical Engineering},
volume = {95},
pages = {107406},
year = {2021},
issn = {0045-7906},
doi = {https://doi.org/10.1016/j.compeleceng.2021.107406},
url = {https://www.sciencedirect.com/science/article/pii/S0045790621003712},
author = {Yaochen Li and Yuting Chen and Sheng Yuan and Jingle Liu and Xi Zhao and Yang Yang and Yuehu Liu},
keywords = {Intelligent transportation, Asymmetric convolution, Global context attention, Small object detection, Deep reinforcement learning},
abstract = {With the rapid development of unmanned aerial vehicle (UAV) technology, the UAV surveillance system has attracted extensive attention in the intelligent transportation community. In this paper, an object detection model with global context cross (YOLO-GCC) is proposed for identifying small sized traffic elements in UAV image sequences. The concept of the asymmetric convolution is introduced to increase the robustness of the object detection model. Moreover, a global context attention module is added to extract more efficient features to ensure the real-time performance while improving the detection accuracy of small objects. The evaluation and comparison results on multiple UAV datasets demonstrate the effectiveness of the proposed model. Furthermore, an intelligent traffic signal scheduling algorithm named Traffic Deep Q-Network(Traffic-DQN) using deep reinforcement learning is introduced, which utilizes the traffic flow data obtained from YOLO-GCC as the benchmark for traffic scheduling. The experimental results demonstrate that the proposed algorithm can effectively alleviate traffic congestion compared with other methods.}
}
@article{SCHIEFER2020205,
title = {Mapping forest tree species in high resolution UAV-based RGB-imagery by means of convolutional neural networks},
journal = {ISPRS Journal of Photogrammetry and Remote Sensing},
volume = {170},
pages = {205-215},
year = {2020},
issn = {0924-2716},
doi = {https://doi.org/10.1016/j.isprsjprs.2020.10.015},
url = {https://www.sciencedirect.com/science/article/pii/S0924271620302938},
author = {Felix Schiefer and Teja Kattenborn and Annett Frick and Julian Frey and Peter Schall and Barbara Koch and Sebastian Schmidtlein},
keywords = {Deep learning, Forest inventory, Convolutional neural networks, Tree species classification, Unmanned aerial systems, Temperate forests},
abstract = {The use of unmanned aerial vehicles (UAVs) in vegetation remote sensing allows a time-flexible and cost-effective acquisition of very high-resolution imagery. Still, current methods for the mapping of forest tree species do not exploit the respective, rich spatial information. Here, we assessed the potential of convolutional neural networks (CNNs) and very high-resolution RGB imagery from UAVs for the mapping of tree species in temperate forests. We used multicopter UAVs to obtain very high-resolution (<2 cm) RGB imagery over 51 ha of temperate forests in the Southern Black Forest region, and the Hainich National Park in Germany. To fully harness the end-to-end learning capabilities of CNNs, we used a semantic segmentation approach (U-net) that concurrently segments and classifies tree species from imagery. With a diverse dataset in terms of study areas, site conditions, illumination properties, and phenology, we accurately mapped nine tree species, three genus-level classes, deadwood, and forest floor (mean F1-score 0.73). A larger tile size during CNN training negatively affected the model accuracies for underrepresented classes. Additional height information from normalized digital surface models slightly increased the model accuracy but increased computational complexity and data requirements. A coarser spatial resolution substantially reduced the model accuracy (mean F1-score of 0.26 at 32 cm resolution). Our results highlight the key role that UAVs can play in the mapping of forest tree species, given that air- and spaceborne remote sensing currently does not provide comparable spatial resolutions. The end-to-end learning capability of CNNs makes extensive preprocessing partly obsolete. The use of large and diverse datasets facilitate a high degree of generalization of the CNN, thus fostering transferability. The synergy of high-resolution UAV imagery and CNN provide a fast and flexible yet accurate means of mapping forest tree species.}
}
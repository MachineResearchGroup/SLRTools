@article{ZHAO202281,
title = {Distributed coordinated control scheme of UAV swarm based on heterogeneous roles},
journal = {Chinese Journal of Aeronautics},
volume = {35},
number = {1},
pages = {81-97},
year = {2022},
issn = {1000-9361},
doi = {https://doi.org/10.1016/j.cja.2021.01.014},
url = {https://www.sciencedirect.com/science/article/pii/S1000936121000534},
author = {Jiang ZHAO and Jiaming SUN and Zhihao CAI and Yingxun WANG and Kun WU},
keywords = {Coordination strategy, Distributed control, Heterogeneous roles, Swarm intelligence, Unmanned Aerial Vehicles (UAV)},
abstract = {This paper proposes a new distributed coordinated control scheme based on heterogeneous roles for Unmanned Aerial Vehicle (UAV) swarm to achieve formation control. First, the framework of the distributed coordinated control scheme is designed on the basis of Distributed Model Predictive Control (DMPC). Then, the effect of heterogeneous roles including leader, coordinator and follower is discussed, and the role-based cost functions are developed to improve the performance of coordinated control for UAV swarm. Furthermore, a group of coordination strategies are proposed for UAVs with different roles to achieve swarm conflict resolution. Numerical simulations demonstrate that the presented distributed coordinated control scheme is effective to formulate and maintain the desired formation for the UAV swarm.}
}
@article{SCHWARZROCK201810,
title = {Solving task allocation problem in multi Unmanned Aerial Vehicles systems using Swarm intelligence},
journal = {Engineering Applications of Artificial Intelligence},
volume = {72},
pages = {10-20},
year = {2018},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2018.03.008},
url = {https://www.sciencedirect.com/science/article/pii/S0952197618300575},
author = {Janaína Schwarzrock and Iulisloi Zacarias and Ana L.C. Bazzan and Ricardo Queiroz {de Araujo Fernandes} and Leonardo Henrique Moreira and Edison Pignaton {de Freitas}},
keywords = {Unmanned Aerial Vehicles, Task allocation, Multi-agent systems, Swarm intelligence},
abstract = {The envisaged usage of multiple Unmanned Aerial Vehicles (UAVs) to perform cooperative tasks is a promising concept for future autonomous military systems. An important aspect to make this usage a reality is the solution of the task allocation problem in these cooperative systems. This paper addresses the problem of tasks allocation among agents representing UAVs, considering that the tasks are created by a central entity, in which the decision of which task will be performed by each agent is not decided by this central entity, but by the agents themselves. The assumption that tasks are created by a central entity is a reasonable one, given the way strategic planning is carried up in military operations. To enable the UAVs to have the ability to decide which tasks to perform, concepts from swarm intelligence and multi-agent system approach are used. Heuristic methods are commonly used to solve this problem, but they present drawbacks. For example, many tasks end up not begin performed even if the UAVs have enough resources to execute them. To cope with this problem, this paper proposes three algorithm variants that complement each other to form a new method aiming to increase the amount of performed tasks, so that a better task allocation is achieved. Through experiments in a simulated environment, the proposed method was evaluated, yielding enhanced results for the addressed problem compared to existing methods reported in the literature.}
}
@article{GUO2021479,
title = {UAV navigation in high dynamic environments: A deep reinforcement learning approach},
journal = {Chinese Journal of Aeronautics},
volume = {34},
number = {2},
pages = {479-489},
year = {2021},
issn = {1000-9361},
doi = {https://doi.org/10.1016/j.cja.2020.05.011},
url = {https://www.sciencedirect.com/science/article/pii/S1000936120302247},
author = {Tong GUO and Nan JIANG and Biyue LI and Xi ZHU and Ya WANG and Wenbo DU},
keywords = {Autonomous vehicles, Deep learning, Motion planning, Navigation, Reinforcement learning, Unmanned Aerial Vehicle (UAV)},
abstract = {Unmanned Aerial Vehicle (UAV) navigation is aimed at guiding a UAV to the desired destinations along a collision-free and efficient path without human interventions, and it plays a crucial role in autonomous missions in harsh environments. The recently emerging Deep Reinforcement Learning (DRL) methods have shown promise for addressing the UAV navigation problem, but most of these methods cannot converge due to the massive amounts of interactive data when a UAV is navigating in high dynamic environments, where there are numerous obstacles moving fast. In this work, we propose an improved DRL-based method to tackle these fundamental limitations. To be specific, we develop a distributed DRL framework to decompose the UAV navigation task into two simpler sub-tasks, each of which is solved through the designed Long Short-Term Memory (LSTM) based DRL network by using only part of the interactive data. Furthermore, a clipped DRL loss function is proposed to closely stack the two sub-solutions into one integral for the UAV navigation problem. Extensive simulation results are provided to corroborate the superiority of the proposed method in terms of the convergence and effectiveness compared with those of the state-of-the-art DRL methods.}
}
@article{LIU2021106435,
title = {Control-oriented UAV highly feasible trajectory planning: A deep learning method},
journal = {Aerospace Science and Technology},
volume = {110},
pages = {106435},
year = {2021},
issn = {1270-9638},
doi = {https://doi.org/10.1016/j.ast.2020.106435},
url = {https://www.sciencedirect.com/science/article/pii/S1270963820311172},
author = {Yiheng Liu and Honglun Wang and Jiaxuan Fan and Jianfa Wu and Tiancai Wu},
keywords = {Highly feasible trajectory planning, Trajectory-mapping network, Deep learning, Unmanned aerial vehicle},
abstract = {The highly feasible trajectory planning of unmanned aerial vehicle (UAV) is very important in some tasks but has not yet attracted sufficient study attention. Most current studies use simplified UAV model with some state constraints to plan the trajectory, but the feasibility is reduced, because the simplified model is very different from the actual UAV system, so that the tracking characteristics of UAV cannot be fully considered. In this paper, a novel control-oriented UAV highly feasible trajectory planning method is proposed. First, a UAV closed-loop model prediction method, which is the combination of a low-level controller and a UAV 6 DOF nonlinear model, is adopted in the trajectory planning phase to predict the flight trajectory. This complicated model is very similar to the actual UAV system because it comprehensively considers the controller performance and the detailed UAV model, but it also has poor efficiency. Therefore, a trajectory-mapping network (TMN) is proposed using a deep learning approach to improve the planning efficiency. Furthermore, a novel time-series convolutional neural network (TSCNN) is proposed for the TMN to further improve its computation speed and prediction accuracy. Finally, the flight trajectory predicted by the TMN is used to evaluate the planning cost. In this way, the planned trajectory will be highly feasible. The effectiveness of the proposed method is demonstrated by simulations.}
}
@article{WU2021118986,
title = {Application of conventional UAV-based high-throughput object detection to the early diagnosis of pine wilt disease by deep learning},
journal = {Forest Ecology and Management},
volume = {486},
pages = {118986},
year = {2021},
issn = {0378-1127},
doi = {https://doi.org/10.1016/j.foreco.2021.118986},
url = {https://www.sciencedirect.com/science/article/pii/S037811272100075X},
author = {Bizhi Wu and Anjie Liang and Huafeng Zhang and Tengfei Zhu and Zhiying Zou and Deming Yang and Wenyu Tang and Jian Li and Jun Su},
keywords = {Pine wilt disease, Early diagnosis, UAV, Deep learning, Faster R-CNN, YOLO},
abstract = {The early diagnosis of pine wilt disease (PWD) is crucial to its management. Substantial effort has been made to develop an accurate early diagnosis method. However, none of the existing methods are suitable for large-scale rapid screening in the field. In this study, an unmanned aerial vehicle (UAV) was used to collect a large number of images from a pine tree canopy in an early stage of infection for the generation of a training dataset. Owing to the inability to develop object detection models using nine regular machine learning classifiers, two advanced deep learning algorithms were employed, namely the Faster Region-based Convolutional Network (Faster R-CNN) and You Only Look Once version 3 (YOLOv3). Model performances were compared based on the precision (mAP), size, and processing speed. All four models possessed similar precision (0.602–0.64), but the YOLO-based models had a smaller size and faster processing speed than the Faster R-CNN-adapted models. The population of infected trees (in the early or late stage of infection) was predicted under different treatments (retaining or removing the dead trees from the forest) using these four models to explore their application. The results indicate that retaining dead trees after chopping them down results in fewer dead trees but more early infected trees the following year. We propose a cost-effective and high-throughput method for the early diagnosis of PWD in the field using UAV-based image processing and object detection (uses YOLOv3) based on deep learning.}
}
@article{KUMAR2021107819,
title = {SP2F: A secured privacy-preserving framework for smart agricultural Unmanned Aerial Vehicles},
journal = {Computer Networks},
volume = {187},
pages = {107819},
year = {2021},
issn = {1389-1286},
doi = {https://doi.org/10.1016/j.comnet.2021.107819},
url = {https://www.sciencedirect.com/science/article/pii/S1389128621000086},
author = {Randhir Kumar and Prabhat Kumar and Rakesh Tripathi and Govind P. Gupta and Thippa Reddy Gadekallu and Gautam Srivastava},
keywords = {Blockchain technology, Artificial intelligence, Deep learning, Intrusion detection system, Privacy-preservation, Smart agriculture, Unmanned Aerial Vehicles (UAVs)},
abstract = {The current advancement in Unmanned Aerial Vehicles (UAVs) and the proliferation of the Internet of Things (IoT) devices is revolutionizing conventional farming operations into precision agriculture. The agricultural UAVs combined with IoT use an open channel i.e., the Internet to assist cultivators with data collection, processing, monitoring, and making correct decisions on the farm. However, the use of the Internet opens up a wide range of challenges such as security (e.g., performing cyber-attacks), risk of data privacy (e.g., data poisoning and inference attacks), etc. The usage of current conventional centralized security measures has limitations in terms of a single point of failure, verifiability, traceability, and scalability. Motivated from the aforementioned challenges, we propose a Secured Privacy-Preserving Framework (SP2F) for smart agricultural UAVs. The proposed SP2F framework has two main engines, a two-level privacy engine, and a deep learning-based anomaly detection engine. In the two-level privacy engine, a blockchain, and smart contract-based enhanced Proof of Work (ePoW) is designed for data authentication, and to mitigate data poisoning attacks. A Sparse AutoEncoder (SAE) is applied for transforming data into a new encoded format for preventing inference attacks. In the anomaly detection engine, a Stacked Long-Short-Term Memory (SLSTM) is used to train and evaluate the results of the proposed two-level privacy engine using two publicly accessible IoT-based datasets, namely ToN-IoT and IoT Botnet. Finally, based on thorough analysis, and comparison, we identify that the SP2F framework outperforms several state-of-the-art techniques in both non-blockchain and blockchain frameworks.}
}
@article{YEN2022108590,
title = {Multi-sensory sound source enhancement for unmanned aerial vehicle recordings},
journal = {Applied Acoustics},
volume = {189},
pages = {108590},
year = {2022},
issn = {0003-682X},
doi = {https://doi.org/10.1016/j.apacoust.2021.108590},
url = {https://www.sciencedirect.com/science/article/pii/S0003682X21006848},
author = {Benjamin Yen and Yusuke Hioka and Gian Schmid and Brian Mace},
keywords = {Microphone array, unmanned aerial vehicle, source enhancement, power spectral density, rotor noise},
abstract = {A method to effectively perform sound source enhancement from an unmanned aerial vehicle (UAV)-mounted audio recording system is proposed. The objective of this study is to utilise audio recordings and non-acoustical UAV rotor characteristics to improve rotor noise power spectral density (PSD) estimation accuracy and robustness. The improved rotor noise PSD estimate in turn improves the effectiveness of the rotor noise postfilter, leading to improvement in source enhancement performance. The performance of the proposed source enhancement algorithm is evaluated via experiments, with recordings made in an outdoor environment with an in-flight UAV. Experiment results show PSD estimation accuracy to within 1.5 dB log spectral distortion regardless of the given input conditions, such as the presence of surrounding sound sources. The method also achieves a consistent ∼20–25 dB improvement in source enhancement performance, where the effects of rotor noise from the noisy microphone recordings are significantly reduced. The proposed method also outperforms existing state-of-the-art such as the beamformer with postfilter and speech distortion weighted multichannel Wiener filter frameworks.}
}
@article{ZHANG2022106682,
title = {Assessing the efficacy of machine learning techniques to characterize soybean defoliation from unmanned aerial vehicles},
journal = {Computers and Electronics in Agriculture},
volume = {193},
pages = {106682},
year = {2022},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2021.106682},
url = {https://www.sciencedirect.com/science/article/pii/S0168169921006992},
author = {Zichen Zhang and Sami Khanal and Amy Raudenbush and Kelley Tilmon and Christopher Stewart},
keywords = {Soybean leaf defoliation, Convolutional neural networks, Machine learning, Unmanned aerial vehicles, Deep learning},
abstract = {Severe crop defoliation caused by insects and pests is linked to low agricultural productivity. If the root cause is not addressed, severe defoliation spreads, damaging whole crop fields. Understanding which areas are afflicted by severe defoliation can help farmers manage crops. Unmanned Aerial Vehicles (UAV) can fly over whole crop fields capturing detailed images. However, it is hard to characterize crop defoliation from aerial images that include multiple, overlapping plants with confounding effects from shadows and lighting. This paper assesses the efficacy of machine learning techniques to characterize defoliation. Given an UAV image as input, these techniques detect if severe defoliation is present. We created a labeled data set on soybean defoliation that comprises over 97,000 UAV images. We compared machine learning techniques ranging from Naive Bayes to neural networks and assessed their efficacy for (1) correctly characterizing images that contain defoliated crops and (2) avoiding wrong characterizations of healthy crops as defoliated. None of the techniques studied achieved high efficacy on both questions. However, we created DefoNet, a convolutional neural network designed for detecting crop defoliation that produces models that can be efficacious for either question. If adopted in practice, DefoNet models can guide decision making for mitigating crop yield losses due to defoliating insects.}
}
@article{SU2021107286,
title = {Real-time hierarchical risk assessment for UAVs based on recurrent fusion autoencoder and dynamic FCE: A hybrid framework},
journal = {Applied Soft Computing},
volume = {106},
pages = {107286},
year = {2021},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2021.107286},
url = {https://www.sciencedirect.com/science/article/pii/S156849462100209X},
author = {Xuanyuan Su and Laifa Tao and Hongmei Liu and Lizhi Wang and Mingliang Suo},
keywords = {Hybrid framework, Hierarchical risk assessment, Recurrent fusion autoencoder, Dynamic fuzzy comprehensive evaluation, Unmanned aerial vehicles},
abstract = {Effective risk assessment is critical for unmanned aerial vehicles (UAVs) to ensure their safety and reliability. Up to now, the researchers have proposed quite a few methods for the above target. However, these methods are mainly based on path planning and collision theory, the risk caused by the abnormal status of UAVs themselves is generally ignored, which limits the further improvement on their performance. In practice, due to factors such as complicated compositions, variable condition monitoring (CM) data, and scarce failure records, etc., it is always a great challenge to implement the complete information fusion and accurate risk assessment for UAVs based on their real-time status. In this regard, a novel hybrid framework is proposed in this paper, which integrates the qualitative knowledge and the quantitative CM data, to evaluate the real-time hierarchical risk of UAVs. Specifically, the complicated UAV is firstly abstracted as a multi-level evaluating index system considering its qualitative logic compositions. Then, for each low-level index, given its multivariate CM data of several time instants, recurrent fusion autoencoder (RFA), a novel unsupervised neural network architecture, is proposed to extract their robust and complete feature embeddings automatically, where not only the information of variate dimension but also the information of time dimension can be fully fused. Furthermore, the risk of each low-level index is quantified by the adaptive Gaussian mixture model in a probabilistic way, which is truly data-driven with the help of the Bayesian hyperparameter optimization. Finally, the dynamic fuzzy comprehensive evaluation is utilized to evaluate the hierarchical risk of UAVs level by level, it should be noticed that our method can dynamically adjust the weights of each index employing the variable weight coefficients, which can capture the preliminary risk of UAVs more timely compared with the traditional methods. The proposed framework is validated on two typical datasets: the turbofan engine datasets (simulation) and the UAV flight datasets (real). The experimental results demonstrate the effectiveness and superiority of the hybrid framework on robust information fusion and accurate hierarchical risk assessment.}
}
@article{ZHAO2019588,
title = {Fast task allocation for heterogeneous unmanned aerial vehicles through reinforcement learning},
journal = {Aerospace Science and Technology},
volume = {92},
pages = {588-594},
year = {2019},
issn = {1270-9638},
doi = {https://doi.org/10.1016/j.ast.2019.06.024},
url = {https://www.sciencedirect.com/science/article/pii/S1270963818318704},
author = {Xinyi Zhao and Qun Zong and Bailing Tian and Boyuan Zhang and Ming You},
keywords = {Fast task allocation, Heterogeneous unmanned aerial vehicles, Reinforcement learning},
abstract = {A task allocation problem for heterogeneous unmanned aerial vehicles (UAVs) in the presence of environment uncertainty is studied in this paper. Generally, the process of finding efficient allocation scheme can be computationally prohibitive. This work presents a Q-learning based fast task allocation (FTA) algorithm through neural network approximation and prioritized experience replay, which effectively offloads the online computation to an offline learning procedure. Specifically, the proposed approach develops a Q network that encodes the allocation rules. The Q network not only considers the effect of environment uncertainty, but also is capable of handling total different tasks. Comparison simulations are provided to show the efficiency of the proposed algorithm.}
}
@article{WHELAN2022107784,
title = {Artificial intelligence for intrusion detection systems in Unmanned Aerial Vehicles},
journal = {Computers and Electrical Engineering},
volume = {99},
pages = {107784},
year = {2022},
issn = {0045-7906},
doi = {https://doi.org/10.1016/j.compeleceng.2022.107784},
url = {https://www.sciencedirect.com/science/article/pii/S0045790622000842},
author = {Jason Whelan and Abdulaziz Almehmadi and Khalil El-Khatib},
keywords = {Unmanned aerial vehicles, Intrusion detection, Machine learning, Novelty detection, Cyber–physical systems},
abstract = {Unmanned Aerial Vehicles (UAVs) are seeing increased use in critical operations for law enforcement, military, industrial control surveillance and more. These hostile operating environments combined with the UAVs reliance on wireless protocols produces an increased threat level. Many attacks against the UAV are becoming commonplace as they are simple to conduct with inexpensive hardware, such as spoofing and jamming. Unfortunately, as many of these vulnerabilities exist within underlying technologies, securing the UAV becomes a difficult task. A promising approach to identifying and mitigating these attacks is the development of an intelligent intrusion detection system (IDS). The proposed approach uses principal component analysis (PCA) and one-class classifiers to detect attacks. This allows for the use of flight logs for training data, providing a versatile and ubiquitous approach. The proposed detection method is integrated into a fully developed IDS called MAVIDS. This IDS operates onboard the UAV within a resource-constrained agent device, allowing it to detect and potentially mitigate attacks even when communication to the ground control station is lost from jamming. The approach shows to be effective against GPS spoofing and jamming with macro averaged F1 scores of 90.57% and 94.3% respectively.}
}
@article{MCILWAINE2021102279,
title = {JellyNet: The convolutional neural network jellyfish bloom detector},
journal = {International Journal of Applied Earth Observation and Geoinformation},
volume = {97},
pages = {102279},
year = {2021},
issn = {0303-2434},
doi = {https://doi.org/10.1016/j.jag.2020.102279},
url = {https://www.sciencedirect.com/science/article/pii/S0303243420309223},
author = {Ben Mcilwaine and Mónica {Rivas Casado}},
keywords = {Jellyfish bloom, Unmanned aerial vehicle, Machine learning, Convolution neural network, Remote sensing, Deep learning},
abstract = {Coastal industries face disruption on a global scale due to the threat of large blooms of jellyfish. They can decimate coastal fisheries and clog the water intake systems of desalination and nuclear power plants. This can lead to losses of revenue and power output. This paper presents JellyNet: a convolutional neural network (CNN) jellyfish bloom detection model trained on high resolution remote sensing imagery collected by unmanned aerial vehicles (UAVs). JellyNet provides the detection capability for an early (6–8 h) bloom warning system. 1539 images were collected from flights at 2 locations: Croabh Haven, UK and Pruth Bay, Canada. The training/test dataset was manually labelled, and split into two classes: ‘Bloom present’ and ‘No bloom present’. 500 × 500 pixel images were used to increase fine-grained pattern detection of the jellyfish blooms. Model testing was completed using a 75/25% training/test split with hyperparameters selected prior to model training using a held-out validation dataset. Transfer learning using VGG-16 architecture, and a jellyfish bloom specific binary classifier surpassed an accuracy of 90%. Test model performance peaked at 97.5% accuracy. This paper exhibits the first example of a high resolution, multi-sensor jellyfish bloom detection capability, with integrated robustness from two oceans to tackle real world detection challenges.}
}
@article{ISHENGOMA2022101502,
title = {Hybrid convolution neural network model for a quicker detection of infested maize plants with fall armyworms using UAV-based images},
journal = {Ecological Informatics},
volume = {67},
pages = {101502},
year = {2022},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2021.101502},
url = {https://www.sciencedirect.com/science/article/pii/S1574954121002934},
author = {Farian S. Ishengoma and Idris A. Rai and Said Rutabayiro Ngoga},
keywords = {Maize, Fall armyworms, Unmanned aerial vehicle, Convolutional neural network},
abstract = {Visual detection of plants diseases over a large area is time-consuming, and the results are prone to errors due to the subjective nature of human evaluations. Several automatic disease detection techniques that improve detection time and improve accuracy compared to visual methods exist, yet they are not suitable for immediate detection. In this paper, we propose a hybrid convolution neural network (CNN) model to speed up the detection of fall armyworms (faw) infested maize leaves. Specifically, the proposed system combines unmanned aerial vehicle (UAV) technology, to autonomously capture maize leaves, and a hybrid CNN model, which is based on a parallel structure specifically designed to take advantage of the benefits of both individual models, namely VGG16 and InceptionV3. We compare the performance of the proposed model in terms of accuracy and training time to four existing CNN models, namely VGG16, InceptionV3, XceptionNet, and Resnet50. The results show that compared to existing models, the proposed hybrid model reduces the training time by 16% to 44% compared to other models while exhibiting the most superior accuracy of 96.98%.}
}
@article{LIU2021127546,
title = {Unmanned aerial vehicle and artificial intelligence revolutionizing efficient and precision sustainable forest management},
journal = {Journal of Cleaner Production},
volume = {311},
pages = {127546},
year = {2021},
issn = {0959-6526},
doi = {https://doi.org/10.1016/j.jclepro.2021.127546},
url = {https://www.sciencedirect.com/science/article/pii/S0959652621017649},
author = {Tiedong Liu and Yuxin Sun and Cai Wang and Yangyang Zhang and Zixuan Qiu and Wenfeng Gong and Shuhan Lei and Xinyu Tong and Xuanyu Duan},
keywords = {Unmanned aerial vehicle, Artificial intelligence, Tropical forest, Forest ecological monitoring, Sustainable forest management},
abstract = {The ecological value of tropical forests in water conservation district has been of great interest because of their rich vegetation types and higher biomass density than any other land cover types, it is urgent to evaluate the ecological value of tropical forests in water conservation district. However, the monitoring of tropical forests in water conservation district is faced with many problems, such as high forest density, complexity and diversity of the forest structure, complex topography and climate conditions, and the difficulty of access for investigators. In order to solve the above difficulties, this study combined 3D point cloud reconstruction based on Unmanned Aerial Vehicle - Structure from Motion (UAV-SfM) technology with forest type classification based on the Convolutional Neural Network (CNN) method, combined with a small amount of forest permanent sample plot survey data, to accurately evaluate the forest biomass distribution and forest biodiversity in water conservation district. The results show that the overall classification accuracy of the 20 forest types in water conservation district based on the CNN method is 0.61, the overall Kappa coefficient is 0.59, and the conditional Kappa coefficient is concentrated in the range of 0.43–0.85. The Root Mean Square Error (RMSE) of the plane measurement of UAV-SfM technology is 0.432 m, and the RMSE of the elevation measurement is 0.989 m, the effect of this UAV technology in tropical forest monitoring is superior. Using the techniques mentioned above, this study can effectively and accurately monitor and evaluate the biomass distribution and biodiversity of tropical forests in the water conservation district. Based on the precision forest ecological monitoring data, this study can develop a scientific and reasonable sustainable forest management plan for the water conservation district according to the distribution of forest biomass and biodiversity. The combination of UAV-SfM technology and the CNN method is an innovative attempt, and the integration of UAV and artificial intelligence technology solves practical problems faced by sustainable forest management. UAV and artificial intelligence will also provide an important foundation for forest ecological environment sustainability assessment research.}
}
@article{ZHU2022103991,
title = {Pavement distress detection using convolutional neural networks with images captured via UAV},
journal = {Automation in Construction},
volume = {133},
pages = {103991},
year = {2022},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2021.103991},
url = {https://www.sciencedirect.com/science/article/pii/S0926580521004428},
author = {Junqing Zhu and Jingtao Zhong and Tao Ma and Xiaoming Huang and Weiguang Zhang and Yang Zhou},
keywords = {Asphalt pavement distress, Convolutional neural network (CNN), Object-detection algorithms, Unmanned aerial vehicle (UAV)},
abstract = {Pavement distress detection is crucial in the decision-making for maintenance planning. Unmanned aerial vehicles (UAVs) are helpful in collecting pavement images. This paper proposes the collection of pavement distress information using a UAV with a high-resolution camera. A UAV platform for pavement image collection was assembled, and the flight settings were studied for optimal image quality. The collected images were processed and annotated for model training. Three state-of-the-art object-detection algorithms—Faster R-CNN, YOLOv3, and YOLOv4, were used to train the dataset, and their prediction performances were compared. A pavement image dataset was established with six types of distress. YOLOv3 demonstrated the best performance of the three algorithms, with a mean average precision (MAP) of 56.6%. The findings of this study assist in the inspection of non-destructive automatic pavement conditions.}
}
@article{WANG2021107628,
title = {An Intelligent UAV based Data Aggregation Algorithm for 5G-enabled Internet of Things},
journal = {Computer Networks},
volume = {185},
pages = {107628},
year = {2021},
issn = {1389-1286},
doi = {https://doi.org/10.1016/j.comnet.2020.107628},
url = {https://www.sciencedirect.com/science/article/pii/S138912862031255X},
author = {Xiaoding Wang and Sahil Garg and Hui Lin and Georges Kaddoum and Jia Hu and Mohammed F. Alhamid},
keywords = {Unmanned Aerial Vehicle, 5G, Internet of Things, Data aggregation, Deep reinforcement learning},
abstract = {Unmanned Aerial Vehicle (UAV) has become a significant part of 5G or beyond 5G (B5G) paradigm, and is used in various scenarios, including cargo delivery, agricultural application, event surveillance, etc. Although plenty of studies have been proposed on UAV-based data aggregation, how to ensure security and energy-efficiency of the data aggregation process in 5G-enabled Internet of Things (IoT) is an open problem. In this paper, we propose an Intelligent UAV-based Data Aggregation Algorithm, named IDAA for 5G-Enabled IoT. Specifically, IDAA applies v-Support Vector Regression (v-svr) to predict the data collection rate. Then, a security level based task decomposition mechanism is designed that allows UAVs to accept the tasks of corresponding security levels. Finally, energy efficient routes for UAV are planned utilizing a deep reinforcement learning method to achieve the trade-off between the sinking ratio and the energy cost. The theoretical analysis and simulation results indicate that (i) IDAA improves the security of data aggregation; and (ii) IDAA enables UAVs to collect more data and consume less energy compared with baseline strategies.}
}
@article{LI2021106887,
title = {Trajectory planning of load transportation with multi-quadrotors based on reinforcement learning algorithm},
journal = {Aerospace Science and Technology},
volume = {116},
pages = {106887},
year = {2021},
issn = {1270-9638},
doi = {https://doi.org/10.1016/j.ast.2021.106887},
url = {https://www.sciencedirect.com/science/article/pii/S1270963821003977},
author = {Xiaoxuan Li and Jianlei Zhang and Jianda Han},
keywords = {Cable-suspended payload, Quadrotor, Reinforcement learning, Trajectory planning, Unmanned aerial vehicle},
abstract = {Unmanned aerial vehicles (UAVs) are playing more and more vital roles in transportation. In this work, a trajectory planning method based on a value-function approximation algorithm is proposed to address the problem of cable-suspended load transportation using three quadrotors. The purpose of trajectory planning is to reach the target position as soon as possible without the load swinging. In the proposed algorithm, the value function is approximated by parameter vector and problem-specific feature vector. The parameter vector is updated by batch method, and then the greedy strategy is used to generate the desired trajectory. Finally, the desired trajectory is passed to the quad-rotor controller for trajectory tracking. The simulation results show that the trained parameters can fit the value function. The suspended load can be transported smoothly from starting location to the different target locations. The value function in the greedy strategy finally converges to the maximum value, which proves the effectiveness and convergence of the proposed algorithm.}
}
@article{MEDAIYESE2022101569,
title = {Wavelet transform analytics for RF-based UAV detection and identification system using machine learning},
journal = {Pervasive and Mobile Computing},
volume = {82},
pages = {101569},
year = {2022},
issn = {1574-1192},
doi = {https://doi.org/10.1016/j.pmcj.2022.101569},
url = {https://www.sciencedirect.com/science/article/pii/S1574119222000219},
author = {Olusiji .O. Medaiyese and Martins Ezuma and Adrian P. Lauf and Ismail Guvenc},
keywords = {Interference, RF fingerprinting, Scattergram, Scalogram, SqueezeNet, UAVs, Wavelet transform},
abstract = {In this work, we performed a thorough comparative analysis on a radio frequency (RF) based drone detection and identification system (DDI) under wireless interference, such as WiFi and Bluetooth, by using machine learning algorithms, and a pre-trained convolutional neural network-based algorithm called SqueezeNet, as classifiers. In RF signal fingerprinting research, the transient and steady state of the signals can be used to extract a unique signature from an RF signal. By exploiting the RF control signals from unmanned aerial vehicles (UAVs) for DDI, we considered each state of the signals separately for feature extraction and compared the pros and cons for drone detection and identification. Using various categories of wavelet transforms (discrete wavelet transform, continuous wavelet transform, and wavelet scattering transform) for extracting features from the signals, we built different models using these features. We studied the performance of these models under different signal-to-noise ratio (SNR) levels. By using the wavelet scattering transform to extract signatures (scattergrams) from the steady state of the RF signals at 30 dB SNR, and using these scattergrams to train SqueezeNet, we achieved an accuracy of 98.9% at 10 dB SNR.}
}
@article{CHEN2021114505,
title = {Neighborhood global learning based flower pollination algorithm and its application to unmanned aerial vehicle path planning},
journal = {Expert Systems with Applications},
volume = {170},
pages = {114505},
year = {2021},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2020.114505},
url = {https://www.sciencedirect.com/science/article/pii/S0957417420311490},
author = {Yang Chen and Dechang Pi and Yue Xu},
keywords = {Flower pollination algorithm, Global optimization, Premature convergence, UAV path planning},
abstract = {Flower pollination algorithm (FPA) is a meta-heuristic optimization algorithm that imitates the pollination phenomenon of flowering plants in nature. Due to this algorithm is prone to premature convergence when solving complex optimization problems. So this paper introduces a neighborhood global learning based flower pollination algorithm(NGFPA). Firstly, we analyze the FPA using the constant coefficient differential equation and change the FPA’s global equation. Secondly, we build a neighborhood global learning to enhance population diversity. Finally, the population reconstruction mechanism is added to inhibit the population premature convergence. The convergence of NGFPA is proven using the knowledge of differential equations and stochastic function analysis. We test the performance of NGFPA by optimizing CEC2017. Experiment results show that NGFPA has better performance in comparison with other swarm intelligence algorithms. Furthermore, NGFPA is used to solve the problem of unmanned aerial vehicle (UAV) path planning. Simulation results indicate that NGFPA can obtain smoother paths in different obstacle environments. Therefore, NGFPA is effective and valuable.}
}
@article{DU2021103122,
title = {Cooperative pursuit of unauthorized UAVs in urban airspace via Multi-agent reinforcement learning},
journal = {Transportation Research Part C: Emerging Technologies},
volume = {128},
pages = {103122},
year = {2021},
issn = {0968-090X},
doi = {https://doi.org/10.1016/j.trc.2021.103122},
url = {https://www.sciencedirect.com/science/article/pii/S0968090X21001418},
author = {Wenbo Du and Tong Guo and Jun Chen and Biyue Li and Guangxiang Zhu and Xianbin Cao},
keywords = {Urban Air Mobility (UAM), Unmanned Aerial Vehicle (UAV), Multi-agent Reinforcement Learning (MARL)},
abstract = {Urban Air Mobility (UAM) is an emergent concept for future air transportation. With UAM, cargo and passengers will be transported on-demand in urban airspace. UAM has shown a promising prospect in mitigating ground congestion and providing people with an alternative mobility option. However, unauthorized unmanned aerial vehicles (UAVs) in urban airspace present a significant threat to safety of UAM, drawing significant attention from research communities recently. Among all solutions, cooperative pursuit using a team of UAVs is an effective countermeasure for unauthorized UAVs in urban airspace. In this paper, we model cooperative pursuit as a pursuit-evasion game problem (PEG) and propose a multi-agent reinforcement learning (MARL) based approach to solve the problem efficiently. The proposed approach incorporates novel cellular-enabled parameter sharing and curriculum learning schemes to enhance the capability of pursuer UAVs in capturing faster unauthorized UAVs in urban airspace. Extensive experiments have been conducted using simulated urban airspace in order to evaluate the performance of the proposed method. Experimental results demonstrate that by incorporating the parameter sharing scheme, the proposed methods provide much higher capturing rates in a shorter time. Such superiority is more evident when communication constraints are more stringent and/or unauthorized UAVs are faster.}
}
@article{LIU2020105671,
title = {Reinforcement learning based two-level control framework of UAV swarm for cooperative persistent surveillance in an unknown urban area},
journal = {Aerospace Science and Technology},
volume = {98},
pages = {105671},
year = {2020},
issn = {1270-9638},
doi = {https://doi.org/10.1016/j.ast.2019.105671},
url = {https://www.sciencedirect.com/science/article/pii/S1270963819309939},
author = {Yuxuan Liu and Hu Liu and Yongliang Tian and Cong Sun},
keywords = {UAV swarm, Reinforcement learning, Persistent surveillance, Autonomous manoeuvre control, Artificial neural network (ANN)},
abstract = {Persistent surveillance in a complex unknown urban area by an unmanned aerial vehicle (UAV) swarm is a low-cost, promising future application for anti-terrorism, disaster monitoring, and battlefield situational awareness. Based on over-simplified simulated surroundings and a UAV dynamic model, a few remarkable approaches have been proposed; however, they typically rely on non-sensor-based inputs and prior knowledge on the environment or targets. To overcome these limitations, based on simulated city blocks, a two-level quasi-distributed control framework is proposed for realizing the continuous control of a UAV swarm in two defined surveillance phases. With the support of a well-trained and corrected artificial neural network (ANN) in low-level UAV manoeuvre control for target homing and collision avoidance, several preliminary high-level target allocation strategies are designed for a cooperative overall objective based on the synchronization of local surveillance data. Then, via a series of numerical simulations, an optimal high-level strategy combination is identified. Finally, the surveillance performance of this strategy combination is evaluated under various swarm sizes and UAV launching patterns. The simulation results demonstrate that the proposed control framework is applicable for UAV swarm control in the persistent surveillance of unknown urban areas.}
}
@article{KYRIAKAKIS2021100956,
title = {Moving peak drone search problem: An online multi-swarm intelligence approach for UAV search operations},
journal = {Swarm and Evolutionary Computation},
volume = {66},
pages = {100956},
year = {2021},
issn = {2210-6502},
doi = {https://doi.org/10.1016/j.swevo.2021.100956},
url = {https://www.sciencedirect.com/science/article/pii/S2210650221001188},
author = {Nikolaos A. Kyriakakis and Magdalene Marinaki and Nikolaos Matsatsinis and Yannis Marinakis},
keywords = {Dynamic optimization, Moving peak benchmark, UAV, Swarm optimization, Humanitarian operations, Search and rescue},
abstract = {Many practical, real-world applications have dynamic features. This paper introduces a novel dynamic optimization problem applied to Unmanned Aerial Vehicle (UAV) search and rescue scenarios, named the Moving Peak Drone Search Problem (MPDSP). It utilizes the dynamic environment generator of the well-known Moving Peak Benchmark (MPB) and it is formulated as a maximization problem, with additional constraints imposed by the use of UAVs. For solving the MPDSP, a multi-swarm framework is proposed and seven optimization algorithms are tested. Five well known swarm intelligence algorithms and two algorithms effectively used in continuous and dynamic optimization problems. The implemented methods are evaluated and compared on 105 scenarios with 4 different UAV fleet configurations. Among the tested swarm intelligence variants, the Particle Swarm Optimization implementations proved to be the most effective for solving the MPDSP.}
}
@article{ZHOU2021,
title = {Improving multi-target cooperative tracking guidance for UAV swarms using multi-agent reinforcement learning},
journal = {Chinese Journal of Aeronautics},
year = {2021},
issn = {1000-9361},
doi = {https://doi.org/10.1016/j.cja.2021.09.008},
url = {https://www.sciencedirect.com/science/article/pii/S1000936121003423},
author = {Wenhong ZHOU and Jie LI and Zhihong LIU and Lincheng SHEN},
keywords = {Decentralized cooperation, Maximum reciprocal reward, Multi-agent actor-critic, Pointwise mutual information, Reinforcement learning},
abstract = {Multi-Target Tracking Guidance (MTTG) in unknown environments has great potential values in applications for Unmanned Aerial Vehicle (UAV) swarms. Although Multi-Agent Deep Reinforcement Learning (MADRL) is a promising technique for learning cooperation, most of the existing methods cannot scale well to decentralized UAV swarms due to their computational complexity or global information requirement. This paper proposes a decentralized MADRL method using the maximum reciprocal reward to learn cooperative tracking policies for UAV swarms. This method reshapes each UAV's reward with a regularization term that is defined as the dot product of the reward vector of all neighbor UAVs and the corresponding dependency vector between the UAV and the neighbors. And the dependence between UAVs can be directly captured by the Pointwise Mutual Information (PMI) neural network without complicated aggregation statistics. Then, the experience sharing Reciprocal Reward Multi-Agent Actor-Critic (MAAC-R) algorithm is proposed to learn the cooperative sharing policy for all homogeneous UAVs. Experiments demonstrate that the proposed algorithm can improve the UAVs’ cooperation more effectively than the baseline algorithms, and can stimulate a rich form of cooperative tracking behaviors of UAV swarms. Besides, the learned policy can better scale to other scenarios with more UAVs and targets.}
}
@article{MAZUMDAR2022107934,
title = {A buffer-aware dynamic UAV trajectory design for data collection in resource-constrained IoT frameworks},
journal = {Computers and Electrical Engineering},
volume = {100},
pages = {107934},
year = {2022},
issn = {0045-7906},
doi = {https://doi.org/10.1016/j.compeleceng.2022.107934},
url = {https://www.sciencedirect.com/science/article/pii/S0045790622002130},
author = {Nabajyoti Mazumdar and Saugata Roy and Amitava Nag and Jyoti Prakash Singh},
keywords = {Ant colony optimization (ACO), Buffer aware, Data collector, Internet of things (IoT), IoT node (IN), Unmanned aerial vehicle (UAV)},
abstract = {The emergence of unmanned aerial vehicle (UAV)-enabled technology in the Internet of Things (IoT) era leads to a significant reduction in data collection delays when accumulating sensory data from ground IoT nodes (INs). As a flying data collector, the UAV hovers at a limited number of Access Points (APs) to collect data, outperforming ground data collectors in terms of transmission energy consumption, data delivery reliability, and timeliness. However, the INs have a finite amount of buffer capacity to store the data that must be collected before they overflow. As a result, the data gathering route for UAVs should be adaptable to INs’ buffer deadline in order to minimize data loss. In this paper, a buffer-aware dynamic UAV trajectory design protocol is proposed for data collection from resource-constrained INs. A distributed AP nomination strategy is proposed in order to reduce UAV hovering latency. Furthermore, using machine learning approaches, a modified ant colony optimization algorithm is constructed to minimize the data loss penalty due to buffer overflow. Finally, the performance of the proposed scheme is evaluated against several state-of-the-art protocols with regards to parameters such as data loss penalty, packet delivery ratio, and network lifetime.}
}
@article{MARTINEZALPISTE2021114937,
title = {Search and rescue operation using UAVs: A case study},
journal = {Expert Systems with Applications},
volume = {178},
pages = {114937},
year = {2021},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2021.114937},
url = {https://www.sciencedirect.com/science/article/pii/S095741742100378X},
author = {Ignacio Martinez-Alpiste and Gelayol Golcarenarenji and Qi Wang and Jose Maria Alcaraz-Calero},
keywords = {Unmanned aerial vehicle, Search and rescue, Machine learning, Object detection, Human detection, YOLOv3},
abstract = {Many people go missing in the wild every year. In this paper, the Search and Rescue (SAR) mission is conducted using a novel system comprising an Unmanned Aerial Vehicle (UAV) coupled with real-time machine-learning-based object detection system embedded on a smartphone. Human detection from UAV in the wilderness is a challenging task, because of many constraints involved such as lack of computing and communication infrastructures. We proposed a novel combination of a robust architecture deployed on a smartphone and a novel Convolutional Neural Network (CNN) model to fulfil the goals of the project. Our approach achieved 94.73% of accuracy and 6.8 FPS on a smartphone. Our approach is highly portable, cost-effective, fast with high accuracy. This novel system is expected to contribute significantly to maximise chances of saving lives in the wild. This developed system has been recently launched by Police Scotland to facilitate the SAR teams to locate missing persons in Scotland wilderness.}
}
@article{BARNAWI2021119,
title = {Artificial intelligence-enabled Internet of Things-based system for COVID-19 screening using aerial thermal imaging},
journal = {Future Generation Computer Systems},
volume = {124},
pages = {119-132},
year = {2021},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2021.05.019},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X21001692},
author = {Ahmed Barnawi and Prateek Chhikara and Rajkumar Tekchandani and Neeraj Kumar and Bander Alzahrani},
keywords = {Computer vision, COVID-19, Face recognition, Object detection, Thermal imaging, Unmanned aerial vehicles},
abstract = {Internet of Things (IoT) has recently brought an influential research and analysis platform in a broad diversity of academic and industrial disciplines, particularly in healthcare. The IoT revolution is reshaping current healthcare practices by consolidating technological, economic, and social views. Since December 2019, the spreading of COVID-19 across the world has impacted the world’s economy. IoT technology integrated with Artificial Intelligence (AI) can help to address COVID-19. UAVs equipped with IoT devices can collect raw data that demands computing and analysis to make intelligent decision without human intervention. To mitigate the effect of COVID-19, in this paper, we propose an IoT-UAV-based scheme to collect raw data using onboard thermal sensors. The thermal image captured from the thermal camera is used to determine the potential people in the image (of the massive crowd in a city), which may have COVID-19, based on the temperature recorded. An efficient hybrid approach for a face recognition system is proposed to detect the people in the image having high body temperature from infrared images captured in a real-time scenario. Also, a face mask detection scheme is introduced, which detects whether a person has a mask on the face or not. The schemes’ performance evaluation is done using various machine learning and deep learning classifiers. We use the edge computing infrastructure (onboard sensors and actuators) for data processing to reduce the response time for real-time analytics and prediction. The proposed scheme has an average accuracy of  99.5% using various performance evaluation metrics indicating its practical applicability in real-time scenarios.}
}
@article{ZHANG2022108194,
title = {Autonomous navigation of UAV in multi-obstacle environments based on a Deep Reinforcement Learning approach},
journal = {Applied Soft Computing},
volume = {115},
pages = {108194},
year = {2022},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2021.108194},
url = {https://www.sciencedirect.com/science/article/pii/S1568494621010383},
author = {Sitong Zhang and Yibing Li and Qianhui Dong},
keywords = {UAV, Path planning, Twin delayed deep deterministic policy gradients, Two-stream Actor–Critic Network},
abstract = {Path planning is one of the most essential part in autonomous navigation. Most existing works suppose that the environment is static and fixed. However, path planning is widely used in random and dynamic environment (such as search and rescue, surveillance and other scenarios). In this paper, we propose a Deep Reinforcement Learning (DRL)-based method that enables unmanned aerial vehicles (UAVs) to execute navigation tasks in multi-obstacle environments with randomness and dynamics. The method is based on the Twin Delayed Deep Deterministic Policy Gradients (TD3) algorithm. In order to predict the impact of the environment on UAV, the change of environment observations is added into the Actor–Critic network input, and the two-stream Actor–Critic network structure is proposed to extract features of environment observations. Simulations are carried out to evaluate the performance of the algorithm and experiment results show that our method can enable the UAV to complete autonomous navigation tasks safely in multi-obstacle environments, which reflects the efficiency of our method. Moreover, compared to DDPG and the conventional TD3, our method has better generalization ability.}
}
@article{SABANCI2020107553,
title = {Artificial intelligence based power consumption estimation of two-phase brushless DC motor according to FEA parametric simulation},
journal = {Measurement},
volume = {155},
pages = {107553},
year = {2020},
issn = {0263-2241},
doi = {https://doi.org/10.1016/j.measurement.2020.107553},
url = {https://www.sciencedirect.com/science/article/pii/S0263224120300907},
author = {Kadir Sabanci},
keywords = {Brushless DC motor, Unmanned aerial vehicle, Artificial neural networks, Extreme machine learning, Support vector machine, FEA simulation},
abstract = {In this study, Artificial Neural Networks, Extreme Machine Learning and Support Vector Machine (SVM) are used to estimate power consumption of Brushless DC motor in Unmanned Aerial Vehicle (UAV). Durafly 3648 Brushless DC motor of UAV is modelled with the Finite Element Analysis software. Then it is simulated with Ansys-Rmxprt according to pulse degree, speed and battery voltage of the UAV. The training times and Mean Absolute Percentage Errors (MAPE) of the Artificial Intelligence Techniques (AITs) are calculated for motor input power estimation. The best result among the implemented AITs is achieved with the MAPE of 0.269% by the SVM model. Then the graphical user interface (GUI) is developed to easily obtain information about how efficient the battery can be used, and the flight time of UAVs. Thanks to the proposed GUI software, the input power of the motor can be estimated via input parameters without the long-time consuming simulations.}
}
@article{ONEATA2021106943,
title = {Multimodal speech recognition for unmanned aerial vehicles},
journal = {Computers & Electrical Engineering},
volume = {90},
pages = {106943},
year = {2021},
issn = {0045-7906},
doi = {https://doi.org/10.1016/j.compeleceng.2020.106943},
url = {https://www.sciencedirect.com/science/article/pii/S0045790620307904},
author = {Dan Oneață and Horia Cucu},
keywords = {Automatic speech recognition, Multimodal learning, Domain adaptation, Unmanned aerial vehicles},
abstract = {Unmanned aerial vehicles (UAVs) are becoming widespread with applications ranging from film-making and journalism to rescue operations and surveillance. Research communities (speech processing, computer vision, control) are starting to explore the limits of UAVs, but their efforts remain somewhat isolated. In this paper we unify multiple modalities (speech, vision, language) into a speech interface for UAV control. Our goal is to perform unconstrained speech recognition while leveraging the visual context. To this end, we introduce a multimodal evaluation dataset, consisting of spoken commands and associated images, which represent the visual context of what the UAV “sees” when the pilot utters the command. We provide baseline results and address two main research directions. First, we investigate the robustness of the system by (i) training it with a partial list of commands, and (ii) corrupting the recordings with outdoor noise. We perform a controlled set of experiments by varying the size of the training data and the signal-to-noise ratio. Second, we look at how to incorporate visual information into our model. We show that we can incorporate visual cues in the pipeline through the language model, which we implemented using a recurrent neural network. Moreover, by using gradient activation maps the system can provide visual feedback to the pilot regarding the UAV’s understanding of the command. Our conclusions are that multimodal speech recognition can be successfully used in this scenario and that visual information helps especially when the noise level is high. The dataset and our code are available at http://kite.speed.pub.ro.}
}
@article{KELLENBERGER2018139,
title = {Detecting mammals in UAV images: Best practices to address a substantially imbalanced dataset with deep learning},
journal = {Remote Sensing of Environment},
volume = {216},
pages = {139-153},
year = {2018},
issn = {0034-4257},
doi = {https://doi.org/10.1016/j.rse.2018.06.028},
url = {https://www.sciencedirect.com/science/article/pii/S0034425718303067},
author = {Benjamin Kellenberger and Diego Marcos and Devis Tuia},
keywords = {Animal census, Wildlife monitoring, Unmanned Aerial Vehicles, Object detection, Deep learning, Convolutional Neural Networks},
abstract = {Knowledge over the number of animals in large wildlife reserves is a vital necessity for park rangers in their efforts to protect endangered species. Manual animal censuses are dangerous and expensive, hence Unmanned Aerial Vehicles (UAVs) with consumer level digital cameras are becoming a popular alternative tool to estimate livestock. Several works have been proposed that semi-automatically process UAV images to detect animals, of which some employ Convolutional Neural Networks (CNNs), a recent family of deep learning algorithms that proved very effective in object detection in large datasets from computer vision. However, the majority of works related to wildlife focuses only on small datasets (typically subsets of UAV campaigns), which might be detrimental when presented with the sheer scale of real study areas for large mammal census. Methods may yield thousands of false alarms in such cases. In this paper, we study how to scale CNNs to large wildlife census tasks and present a number of recommendations to train a CNN on a large UAV dataset. We further introduce novel evaluation protocols that are tailored to censuses and model suitability for subsequent human verification of detections. Using our recommendations, we are able to train a CNN reducing the number of false positives by an order of magnitude compared to previous state-of-the-art. Setting the requirements at 90% recall, our CNN allows to reduce the amount of data required for manual verification by three times, thus making it possible for rangers to screen all the data acquired efficiently and to detect almost all animals in the reserve automatically.}
}
@article{LI2021457,
title = {Maneuvering target tracking of UAV based on MN-DDPG and transfer learning},
journal = {Defence Technology},
volume = {17},
number = {2},
pages = {457-466},
year = {2021},
issn = {2214-9147},
doi = {https://doi.org/10.1016/j.dt.2020.11.014},
url = {https://www.sciencedirect.com/science/article/pii/S2214914720304815},
author = {Bo Li and Zhi-peng Yang and Da-qing Chen and Shi-yang Liang and Hao Ma},
keywords = {UAVs, Maneuvering target tracking, Deep reinforcement learning, MN-DDPG, Mixed noises, Transfer learning},
abstract = {Tracking maneuvering target in real time autonomously and accurately in an uncertain environment is one of the challenging missions for unmanned aerial vehicles (UAVs). In this paper, aiming to address the control problem of maneuvering target tracking and obstacle avoidance, an online path planning approach for UAV is developed based on deep reinforcement learning. Through end-to-end learning powered by neural networks, the proposed approach can achieve the perception of the environment and continuous motion output control. This proposed approach includes: (1) A deep deterministic policy gradient (DDPG)-based control framework to provide learning and autonomous decision-making capability for UAVs; (2) An improved method named MN-DDPG for introducing a type of mixed noises to assist UAV with exploring stochastic strategies for online optimal planning; and (3) An algorithm of task-decomposition and pre-training for efficient transfer learning to improve the generalization capability of UAV’s control model built based on MN-DDPG. The experimental simulation results have verified that the proposed approach can achieve good self-adaptive adjustment of UAV’s flight attitude in the tasks of maneuvering target tracking with a significant improvement in generalization capability and training efficiency of UAV tracking controller in uncertain environments.}
}
@article{WEI2021108384,
title = {Estimating the spatial distribution of soil total arsenic in the suspected contaminated area using UAV-Borne hyperspectral imagery and deep learning},
journal = {Ecological Indicators},
volume = {133},
pages = {108384},
year = {2021},
issn = {1470-160X},
doi = {https://doi.org/10.1016/j.ecolind.2021.108384},
url = {https://www.sciencedirect.com/science/article/pii/S1470160X21010499},
author = {Lifei Wei and Yangxi Zhang and Qikai Lu and Ziran Yuan and Haibo Li and Qingbin Huang},
keywords = {Hyperspectral imagery, Soil total arsenic, Deep neural networks, Unmanned aerial vehicle (UAV)},
abstract = {The total arsenic (TAs) content in the soil is commonly used as an important indicator for evaluating soil pollution. However, the traditional methods for investigating TAs concentration in soil over a large area are always labor-intensive and costly. As a rapid and convenient technique, unmanned aerial vehicle (UAV) equipped with hyperspectral camera offers a promising way for estimating the distribution of TAs. In this study, we utilized UAV-borne hyperspectral data over the Daye city of China mining suspected contaminated area to establish the deep model for retrieval of TAs. Specifically, 74 soil samples were collected in situ from the study area, and their TAs contents were measured by using atomic fluorescence spectrometry(AFS). Meanwhile, use UAV captured hyperspectral imagery of the study area. We propose a novel method which deep neural networks with competitive adaptive reweighted sampling (DNN-CARS) for the estimation of soil TAs content and the spatial distribution. For two testing areas, the values of R2 are 0.90 and 0.87, and the value of RMSE are 0.33 and 0.52. Experiments demonstrated, that UAV hyperspectral imagery combined with DNN-CARS is an effective tool for the evaluation of TAs content and mapping its spatial distribution.}
}
@article{ASLAN2022111030,
title = {Visual-Inertial Image-Odometry Network (VIIONet): A Gaussian process regression-based deep architecture proposal for UAV pose estimation},
journal = {Measurement},
volume = {194},
pages = {111030},
year = {2022},
issn = {0263-2241},
doi = {https://doi.org/10.1016/j.measurement.2022.111030},
url = {https://www.sciencedirect.com/science/article/pii/S0263224122002974},
author = {Muhammet Fatih Aslan and Akif Durdu and Kadir Sabanci},
keywords = {Deep learning, Denoising, EuRoC, Gaussian process regression, Inertial image, Visual inertial odometry, UAV},
abstract = {This study estimates the pose of Unmanned Aerial Vehicle (UAV) through artificial intelligence-based approaches and combines visual-inertial information in a different way than previous studies. For an effective fusion, the inertial data between both frames is normalized after denoising with the Savitzky-Golay technique and finally converted from numerical value to image. To strengthen these inertial image features with the change of motion between two frames, frames of Optical Flow (OF) are obtained and OF frames are combined with inertial images. Simultaneously, a parallel thread combines this OF frame with two consecutive raw frames. After features are extracted from inertial and camera data via Inception-v3, these features are fused and actual UAV poses are estimated via Gaussian Process Regression (GPR). Thanks to the smoothing process applied to these estimated values, a more stable pose estimation is provided. This proposed method is applied to the EuRoC dataset and our dataset produced in the Gazebo environment. The pose estimation results reveal that the proposed method has high performance compared to many previous studies.}
}
@article{ALI2021103831,
title = {Real-time multiple damage mapping using autonomous UAV and deep faster region-based neural networks for GPS-denied structures},
journal = {Automation in Construction},
volume = {130},
pages = {103831},
year = {2021},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2021.103831},
url = {https://www.sciencedirect.com/science/article/pii/S092658052100282X},
author = {Rahmat Ali and Dongho Kang and Gahyun Suh and Young-Jin Cha},
keywords = {Deep learning, Damage detection, Vison-based, Autonomous UAV, Damage localization},
abstract = {An autonomous unmanned aerial vehicle (UAV) system integrated with a modified faster region-based convolutional neural network (Faster R-CNN) is proposed to identify various types of structural damage and to map the detected damage a GPS-denied environment. The proposed method reduces the number of false positives significantly using a real-time streaming protocol and multi-processing, particularly in the case of very small cracks in blurry videos due to the UAV vibrations. In comparative studies, the modified Faster R-CNN using ResNet-101 as the base network showed superior performance in detecting small and blurry defects with a mean average precision of 93.31% and mean intersection-over-union of 92.16% in video frames captured by the low-cost autonomous UAV. The autonomous flights of the UAV were tested in a real large-scale parking structure to account for the high wind effects during flight. The UAV successfully followed the desired trajectories, and the Faster R-CNN detected defects accurately.}
}
@article{KHAN2021108217,
title = {A blockchain-based decentralized machine learning framework for collaborative intrusion detection within UAVs},
journal = {Computer Networks},
volume = {196},
pages = {108217},
year = {2021},
issn = {1389-1286},
doi = {https://doi.org/10.1016/j.comnet.2021.108217},
url = {https://www.sciencedirect.com/science/article/pii/S1389128621002644},
author = {Ammar Ahmed Khan and Muhammad Mubashir Khan and Kashif Mehboob Khan and Junaid Arshad and Farhan Ahmad},
keywords = {Unmanned aerial vehicles, UAV, Blockchain, Machine learning, Decentralized machine learning, Collaborative intrusion detection},
abstract = {UAVs have numerous emerging applications in various domains of life. However, it is extremely challenging to gain the required level of public acceptance of UAVs without proving safety and security for human life. Conventional UAVs mostly depend upon the centralized server to perform data processing with complex machine learning algorithms. In fact, all the conventional cyber attacks are applicable on the transmission and storage of data in UAVs. While their impact is extremely serious because UAVs are highly dependent on smart systems that extensively utilize machine learning techniques in order to take decisions in human absence. In this regard, we propose to enhance the performance of UAVs with a decentralized machine learning framework based on blockchain. The proposed framework has the potential to significantly enhance the integrity and storage of data for intelligent decision making among multiple UAVs. We present the use of blockchain to achieve decentralized predictive analytics and present a framework that can successfully apply and share machine learning models in a decentralized manner. We evaluate our system using collaborative intrusion detection as a case-study in order to highlight the feasibility and effectiveness of using blockchain based decentralized machine learning approach in UAVs and other similar applications.}
}
@article{HUA2021107067,
title = {Research on many-to-many target assignment for unmanned aerial vehicle swarm in three-dimensional scenarios},
journal = {Computers & Electrical Engineering},
volume = {91},
pages = {107067},
year = {2021},
issn = {0045-7906},
doi = {https://doi.org/10.1016/j.compeleceng.2021.107067},
url = {https://www.sciencedirect.com/science/article/pii/S0045790621000811},
author = {Xiang Hua and Zhao Wang and Hongjuan Yao and Baohua Li and Chenglong Shi and Jiaxian Zuo},
keywords = {Unmanned aerial vehicle, Target assignment, Swarm intelligence optimization algorithm, Three-dimensional scenario},
abstract = {Target assignment for unmanned aerial vehicle (UAV) swarm has been a research hotspot in academic and industry communities. The current methods mainly focus on multiple targets assignment in planes or few targets assignment in solids. However, they ignore three-dimensional scenarios for UAV swarm and multiple targets characteristics for assignment problem. To solve these issues, we propose a multi-target intelligent assignment model. Firstly, we introduce damage cost and time cost to evaluate the system performance of swarm and time performance in three-dimensional scenarios. Then, we design a bio-inspired swarm intelligence optimization algorithm to find the optimal multiple targets assignment and to balance the two costs and multiple constraints simultaneously. This algorithm regards UAVs as several parallel biological sub-populations, which adopts the multi-layered optimization strategy to select the suitable assignment sequence. The simulation results demonstrate that the proposed method is effective for multi-target assignment in three-dimensional scenarios.}
}
@article{ALBANESE2022100725,
title = {Low-power deep learning edge computing platform for resource constrained lightweight compact UAVs},
journal = {Sustainable Computing: Informatics and Systems},
volume = {34},
pages = {100725},
year = {2022},
issn = {2210-5379},
doi = {https://doi.org/10.1016/j.suscom.2022.100725},
url = {https://www.sciencedirect.com/science/article/pii/S2210537922000609},
author = {Andrea Albanese and Matteo Nardello and Davide Brunelli},
keywords = {Deep Neural Networks, UAV, Sustainable computing, Edge inference, Visual navigation},
abstract = {Unmanned Aerial Vehicles (UAVs), which can operate autonomously in dynamic and complex environments, are becoming increasingly common. Deep learning techniques for motion control have recently taken a major qualitative step since vision-based inference tasks can be executed directly on edge. The goal is to fully integrate the machine learning (ML) element into small UAVs. However, given the limited payload capacity and energy available on small UAVs, integrating computing resources sufficient to host ML and vehicle control functions is still challenging. This paper presents a modular and generic system that can control the UAV by evaluating vision-based ML tasks directly inside the resource-constrained UAV. Two different vision-based navigation configurations were tested and demonstrated. The first configuration implements an autonomous landing site detection system, tested with two models based on LeNet-5 and MobileNetV2, respectively. This allows the UAV to change its planned path accordingly and approach the target to land. Moreover, a model for people detection based on a custom MobileNetV2 network was evaluated in the second configuration. Finally, the execution time and power consumption were measured and compared with a cloud computing approach. The results show the ability of the developed system to dynamically react to the environment to provide the necessary maneuver after detecting the target exploiting only the constrained computational resources of the UAV controller. Furthermore, we demonstrated that moving to the edge, instead of using cloud computing inference, decreases the energy requirement of the system without reducing the quality of service.}
}
@article{MILYAKOV2021628,
title = {Quadcopter active phased antenna array},
journal = {Procedia Computer Science},
volume = {186},
pages = {628-635},
year = {2021},
note = {14th International Symposium "Intelligent Systems},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2021.04.185},
url = {https://www.sciencedirect.com/science/article/pii/S187705092101022X},
author = {D.A. Milyakov and V.S. Verba and V.I. Merkulov and A.S. Plyashechnik},
keywords = {Active phased antenna aray, mobile radar, quadcopter, unmanned aerial vehicle, group control},
abstract = {Group use of unmanned aerial vehicles (UAVs) for various purposes allows obtaining many of advantages in various tasks solvation. New advantages of UAVs group use are due the difficulty of separate observation of the group members and, accordingly, the difficulties of tracking and target distribution; the inability to serve the entire large group with the number of participants exceeding the capacity of the information control system of the opposing side; the increase in the behavioral complexity of the UAV in solving various problems through the use of artificial intelligence; random change of the spatial position of individual UAVs within the group, preventing their detection and selection of virtually all types of information systems. The noted advantages of the UAVs groups are especially pronounced in the implementation of such a fundamentally new method for creating active antennas based on the use of a group of UAVs carrying antenna elements and therefore forming and use of temporary active phased antenna arrays (APAA) of large sizes based on multicopter for the implementation of long-range radar systems. In this regard, the purpose of the report is to present a variant of the algorithm for the formation of such an APAA. On the example of solving the task of maintaining an air object, the features of the operation of a radar with an APAA based on a group of UAVs are illustrated.}
}
@article{JEONG2022116791,
title = {UAV-aided bridge inspection protocol through machine learning with improved visibility images},
journal = {Expert Systems with Applications},
volume = {197},
pages = {116791},
year = {2022},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2022.116791},
url = {https://www.sciencedirect.com/science/article/pii/S0957417422002500},
author = {Euiseok Jeong and Junwon Seo and James P. Wacker},
keywords = {Drone, Bridge inspection, Damage quantification, Image processing, Visibility improvement, Computer vision, Machine learning, Convolutional Neural Network (CNN)},
abstract = {This paper aims to introduce a new bridge inspection protocol using Convolutional Neural Network (CNN)-based machine learning in conjunction with improved visibility images acquired by Unmanned Aerial Vehicles (UAVs). With two UAVs, separate inspections following the proposed protocol were initially performed indoor toquantify the damage state of three concrete columns and four Cross-Laminated Timber (CLT) beams.The protocol using the two UAVs was also adopted to inspect an in-service four-span timber bridge in Pipestone, Minnesota in the United States. During damage identification, various types of visually detected damage were classified through CNN-based machine learning. For image visibility improvement, each image with damage was processed with appropriate adjustment of brightness, contrast, and sharpness to identify and measure the damage in an efficient way. The proposed protocol was found to be capable of bridge damage identification and measurement with an average error of 9.12% when compared to the direct measurements.}
}
@article{ZHOU2021285,
title = {Multi-target tracking for unmanned aerial vehicle swarms using deep reinforcement learning},
journal = {Neurocomputing},
volume = {466},
pages = {285-297},
year = {2021},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2021.09.044},
url = {https://www.sciencedirect.com/science/article/pii/S0925231221014223},
author = {Wenhong Zhou and Zhihong Liu and Jie Li and Xin Xu and Lincheng Shen},
keywords = {UAV swarms, Multi-target tracking, Multi-agent reinforcement learning, Scalability, Feature representation},
abstract = {In recent years, deep reinforcement learning (DRL) has proved its great potential in multi-agent cooperation. However, how to apply DRL to multi-target tracking (MTT) problem for unmanned aerial vehicle (UAV) swarms is challenging: 1) the scale of UAVs may be large, but the existing multi-agent reinforcement learning (MARL) methods that rely on global or joint information of all agents suffer from the dimensionality curse; 2) the dimension of each UAV’s received information is variable, which is incompatible with the neural networks with fixed input dimensions; 3) the UAVs are homogeneous and interchangeable that each UAV’s policy should be irrelevant to the permutation of its received information. To this end, we propose a DRL method for UAV swarms to solve the MTT problem. Firstly, a decentralized swarm-oriented Markov Decision Process (MDP) model is presented for UAV swarms, which involves each UAV’s local communication and partial observation. Secondly, to achieve better scalability, a cartogram feature representation (FR) is proposed to integrate the variable-dimensional information set into a fixed-shape input variable, and the cartogram FR can also maintain the permutation irrelevance to the information. Then, the double deep Q-learning network with dueling architecture is adapted to the MTT problem, and the experience-sharing training mechanism is adopted to learn the shared cooperative policy for UAV swarms. Extensive experiments are provided and the results show that our method can successfully learn a cooperative tracking policy for UAV swarms and outperforms the baseline method in the tracking ratio and scalability.}
}
@article{RADMANESH2020105965,
title = {Towards a PDE-based large-scale decentralized solution for path planning of UAVs in shared airspace},
journal = {Aerospace Science and Technology},
volume = {105},
pages = {105965},
year = {2020},
issn = {1270-9638},
doi = {https://doi.org/10.1016/j.ast.2020.105965},
url = {https://www.sciencedirect.com/science/article/pii/S1270963820306477},
author = {Reza Radmanesh and Manish Kumar and Donald French and David Casbeer},
keywords = {Decentralized control, Trajectory planning, Partial Differential Equation (PDE) method, Unmanned Air Vehicles (UAVs), Large scale optimization},
abstract = {Recently, there has been a tremendous increase of interest in utilizing Unmanned Aerial Vehicles (UAVs) for a number of civilian applications. With this increased interest, it is imperative that these UAVs are able to operate in shared airspace for enhanced efficiency. Multi-UAV systems are inherently safety-critical systems, which means that safety guarantees must be made to ensure no undesirable configurations, such as collisions, occur. This paper proposes a decentralized method based on a Partial Differential Equation (PDE) to generate collision-free 3D trajectories for multiple UAVs operating in a shared airspace. This method exploits the dynamical properties of multi-phase fluids flowing through a porous medium by modeling the porosity values as a function of the risk of collision. To highlight the feasibility for on-board implementation, we propose propose a machine learning technique for obtaining computationally efficient solutions of the PDE describing flow movements in porous medium. This method has been compared via a simulation study to two other path planning strategies, centralized and sequential planning, and the advantages of this method are presented. Furthermore, results from an experiment using three UAVs have been presented to demonstrate the applicability of the proposed method to real-world implementation.}
}
@article{XU2021102511,
title = {Cotton yield estimation model based on machine learning using time series UAV remote sensing data},
journal = {International Journal of Applied Earth Observation and Geoinformation},
volume = {104},
pages = {102511},
year = {2021},
issn = {0303-2434},
doi = {https://doi.org/10.1016/j.jag.2021.102511},
url = {https://www.sciencedirect.com/science/article/pii/S030324342100218X},
author = {Weicheng Xu and Pengchao Chen and Yilong Zhan and Shengde Chen and Lei Zhang and Yubin Lan},
keywords = {UAV remote sensing, Multisource data fusion, Neural networks, Cotton yield forecast},
abstract = {Crop yield prediction is of great practical significance for farmers to make reasonable decisions, such as decisions on crop insurance, storage demand, cash flow budget, fertilizer, water and other input factors. The traditional yield measurement method is sampling surveys, which require a large area of destructive sampling of cotton fields and consume considerable time and labor costs. This study established a cotton yield estimation model based on time series Unmanned Aerial Vehicle (UAV) remote sensing data. The U-Net semantic segmentation network is used to recognize and extract the boll opening pixels in high-resolution visible images, and the boll opening pixel percentage (BOP) is calculated according to the network extraction results. By combining the multispectral images and the pixel coverage of cotton bolls, a Bayesian regularization BP (back propagation) neural network was used to predict cotton yields. In order to simplify the input parameters of the model, the stepwise sensitivity analysis method is used to eliminate redundant variables and obtain the optimal input feature set. The experimental results show that the R2 of the proposed model is 0.853 at the scale of 0.81 m2 (average results of ten-fold cross validation). This study provides a method that can simultaneously meet the requirements of large-area and small-scale forecasting of cotton yields and provides a new idea for cotton yield measurement and breeding screening.}
}
@article{PADUA2022106905,
title = {Vineyard classification using OBIA on UAV-based RGB and multispectral data: A case study in different wine regions},
journal = {Computers and Electronics in Agriculture},
volume = {196},
pages = {106905},
year = {2022},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2022.106905},
url = {https://www.sciencedirect.com/science/article/pii/S0168169922002228},
author = {Luís Pádua and Alessando Matese and Salvatore Filippo {Di Gennaro} and Raul Morais and Emanuel Peres and Joaquim J. Sousa},
keywords = {Precision viticulture, Aerial imagery, Object-based image analysis, Artificial neural network, Random forest, Support vector machine},
abstract = {Vineyard classification is an important process within viticulture-related decision-support systems. Indeed, it improves grapevine vegetation detection, enabling both the assessment of vineyard vegetative properties and the optimization of in-field management tasks. Aerial data acquired by sensors coupled to unmanned aerial vehicles (UAVs) may be used to achieve it. Flight campaigns were conducted to acquire both RGB and multispectral data from three vineyards located in Portugal and in Italy. Red, green, blue and near infrared orthorectified mosaics resulted from the photogrammetric processing of the acquired data. They were then used to calculate RGB and multispectral vegetation indices, as well as a crop surface model (CSM). Three different supervised machine learning (ML) approaches—support vector machine (SVM), random forest (RF) and artificial neural network (ANN)—were trained to classify elements present within each vineyard into one of four classes: grapevine, shadow, soil and other vegetation. The trained models were then used to classify vineyards objects, generated from an object-based image analysis (OBIA) approach, into the four classes. Classification outcomes were compared with an automatic point-cloud classification approach and threshold-based approaches. Results shown that ANN provided a better overall classification performance, regardless of the type of features used. Features based on RGB data showed better performance than the ones based only on multispectral data. However, a higher performance was achieved when using features from both sensors. The methods presented in this study that resort to data acquired from different sensors are suitable to be used in the vineyard classification process. Furthermore, they also may be applied in other land use classification scenarios.}
}
@article{BHOI2021103607,
title = {An Internet of Things assisted Unmanned Aerial Vehicle based artificial intelligence model for rice pest detection},
journal = {Microprocessors and Microsystems},
volume = {80},
pages = {103607},
year = {2021},
issn = {0141-9331},
doi = {https://doi.org/10.1016/j.micpro.2020.103607},
url = {https://www.sciencedirect.com/science/article/pii/S0141933120307560},
author = {Sourav Kumar Bhoi and Kalyan Kumar Jena and Sanjaya Kumar Panda and Hoang Viet Long and Raghvendra Kumar and P. Subbulakshmi and Haifa Bin Jebreen},
keywords = {Internet of Things, Unmanned Aerial Vehicle, Rice pest detection, Imagga cloud, Artificial intelligence, Confidence value},
abstract = {Rice is a very essential food for the survival of human society. Most of the people focus on production of rice for their financial gain as well as their survival in the society. Rice production means a lot, not only for the farmers, but also for the entire human society However, it is very difficult to protect the rice during and after the production due to several reasons, such as natural calamities, heavy rain fall, flood, earthquakes, damage of rice due to pests, etc. Damage of rice can occur during production and after the production due to several pests. So, it is very much essential to identify the pests in the rice so that preventive measures can be taken for its protection. In this paper, an Internet of Things (IoT) assisted Unmanned Aerial Vehicle (UAV) based rice pest detection model using Imagga cloud is proposed to identify the pests in the rice during its production in the field. The IoT assisted UAV focuses on artificial intelligence (AI) mechanism and Python programming paradigm for sending the rice pest images to the Imagga cloud and providing the pest information. The Imagga cloud detects the pest by finding the confidence values with the tags. The tag represents the object in that image. The tag with maximum confidence value and beyond threshold is selected as the target tag to identify the pest. If pest is detected then the information is sent to the owner for further actions. The proposed method can able to identify any kind of the pest that affects the rice during production. Alternatively, this paper attempts to minimize the wastage of rice during its production by monitoring the pests at regular intervals.}
}
@article{HAMYLTON2020102085,
title = {Evaluating techniques for mapping island vegetation from unmanned aerial vehicle (UAV) images: Pixel classification, visual interpretation and machine learning approaches},
journal = {International Journal of Applied Earth Observation and Geoinformation},
volume = {89},
pages = {102085},
year = {2020},
issn = {0303-2434},
doi = {https://doi.org/10.1016/j.jag.2020.102085},
url = {https://www.sciencedirect.com/science/article/pii/S0303243419310293},
author = {S.M. Hamylton and R.H. Morris and R.C. Carvalho and N. Roder and P. Barlow and K. Mills and L. Wang},
keywords = {Lomandra, Convolutional neural network, Five Islands nature reserve},
abstract = {We evaluate three approaches to mapping vegetation using images collected by an unmanned aerial vehicle (UAV) to monitor rehabilitation activities in the Five Islands Nature Reserve, Wollongong (Australia). Between April 2017 and July 2018, four aerial surveys of Big Island were undertaken to map changes to island vegetation following helicopter herbicide sprays to eradicate weeds, including the creeper Coastal Morning Glory (Ipomoea cairica) and Kikuyu Grass (Cenchrus clandestinus). The spraying was followed by a large scale planting campaign to introduce native plants, such as tussocks of Spiny-headed Mat-rush (Lomandra longifolia). Three approaches to mapping vegetation were evaluated, including: (i) a pixel-based image classification algorithm applied to the composite spectral wavebands of the images collected, (ii) manual digitisation of vegetation directly from images based on visual interpretation, and (iii) the application of a machine learning algorithm, LeNet, based on a deep learning convolutional neural network (CNN) for detecting planted Lomandra tussocks. The uncertainty of each approach was assessed via comparison against an independently collected field dataset. Each of the vegetation mapping approaches had a comparable accuracy; for a selected weed management and planting area, the overall accuracies were 82 %, 91 % and 85 % respectively for the pixel based image classification, the visual interpretation / digitisation and the CNN machine learning algorithm. At the scale of the whole island, statistically significant differences in the performance of the three approaches to mapping Lomandra plants were detected via ANOVA. The manual digitisation took a longer time to perform than others. The three approaches resulted in markedly different vegetation maps characterised by different digital data formats, which offered fundamentally different types of information on vegetation character. We draw attention to the need to consider how different digital map products will be used for vegetation management (e.g. monitoring the health individual species or a broader profile of the community). Where individual plants are to be monitored over time, a feature-based approach that represents plants as vector points is appropriate. The CNN approach emerged as a promising technique in this regard as it leveraged spatial information from the UAV images within the architecture of the learning framework by enforcing a local connectivity pattern between neurons of adjacent layers to incorporate the spatial relationships between features that comprised the shape of the Lomandra tussocks detected.}
}
@article{LI20181,
title = {On the estimation of tree mortality and liana infestation using a deep self-encoding network},
journal = {International Journal of Applied Earth Observation and Geoinformation},
volume = {73},
pages = {1-13},
year = {2018},
issn = {0303-2434},
doi = {https://doi.org/10.1016/j.jag.2018.05.025},
url = {https://www.sciencedirect.com/science/article/pii/S0303243418302848},
author = {Wei Li and Carlos Campos-Vargas and Philip Marzahn and Arturo Sanchez-Azofeifa},
keywords = {Unmanned aerial vehicle systems (UAVs), Tropical dry forests (TDFs), Multi-spectral images, Deep self-encoding network (DSEN)},
abstract = {Global environmental change leads to the variation in the relative coverage of dead trees, liana-infested and non-liana-infested trees in many tropical forests. Increase in the coverage of lianas had adverse effects on forested ecosystems such as decreasing tree growth rates and increasing tree mortality. This paper proposes a classification framework that integrates unmanned aerial vehicle systems (UAVs)-derived multi-spectral images and a Deep self-encoding network (DSEN) with the goal of monitoring and quantifying the relative coverage of dead trees, liana-infested, and non-liana-infested trees at high spatial scales. Today's UAVs-derived multi-spectral images provide the much necessary high resolution/quality data to monitor ecosystem-level processes at low cost and on demand. On the other hand, DSEN, a state-of-the-art classification approach that uses multiple layers to exploit abstract, invariant features from input data, has been proved to have the ability to acquire excellent results. This new classification framework, implemented at a tropical Dry Forest site in Costa Rica, provided accurate estimations of the relative coverage of dead trees, liana-infested trees, non-liana-infested trees, and non-forests. The approach opens the door to start exploring linkages between a booming UAVS industry and machine learning/Deep learning classifiers.}
}
@article{QIU2021106421,
title = {Estimation of nitrogen nutrition index in rice from UAV RGB images coupled with machine learning algorithms},
journal = {Computers and Electronics in Agriculture},
volume = {189},
pages = {106421},
year = {2021},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2021.106421},
url = {https://www.sciencedirect.com/science/article/pii/S0168169921004385},
author = {Zhengchao Qiu and Fei Ma and Zhenwang Li and Xuebin Xu and Haixiao Ge and Changwen Du},
keywords = {Rice, Nitrogen nutrition index, Unmanned aerial vehicle, Machine learning, Precision fertilization},
abstract = {Rapid and accurate estimation of rice Nitrogen Nutrition Index (NNI) is beneficial for management of nitrogen application in rice production. Traditional estimation methods required manual actual measurement data in the field, which was time-consuming and cost-expensive, and RGB images from unmanned aerial vehicle (UAV) provided an alternative option for nitrogen nutrition index (NNI) monitoring. In this study, RGB images from unmanned aerial vehicle (UAV) were obtained from each growth period of rice, and six machine learning (ML) algorithms, i.e., adaptive boosting (AB), artificial neural network (ANN), K-nearest neighbor (KNN), partial least squares (PLSR), random forest (RF) and support vector machine (SVM), were used to extract target information for estimating NNI as well as vegetation index (VI). Results showed that most UAV VIs were significantly correlated with rice NNI at the key growing periods; the estimation results of rice NNI using six ML algorithms showed that the RF algorithms performed the best at each growth period with the determination coefficient (R2) ranged from 0.88 to 0.96 and room mean square error (RMSE) ranged from 0.03 to 0.07, in which the estimation of NNI was the best in filling period and the early jointing stage. Rice NNI at the early jointing stage was significantly correlated with soil available nitrogen (AN) with the R2 of 0.84 in Pukou and 0.72 in Luhe, respectively, and rice NNI was significantly correlated with the yield with the R2 of more than 0.7 in Pukou at the whole period and more than 0.7 in Luhe from late jointing to maturity stage. Therefore, the combination of RGB images from UAV and ML algorithms was a scalable, simple and inexpensive method for rapid qualification of rice NNI, which effectively improved nitrogen use efficiency and provided guidance for precision fertilization in rice production.}
}
@article{ZHAO202245,
title = {Smart Unmanned Aerial Vehicles as base stations placement to improve the mobile network operations},
journal = {Computer Communications},
volume = {181},
pages = {45-57},
year = {2022},
issn = {0140-3664},
doi = {https://doi.org/10.1016/j.comcom.2021.09.016},
url = {https://www.sciencedirect.com/science/article/pii/S0140366421003534},
author = {Zhongliang Zhao and Pedro Cumino and Christian Esposito and Meng Xiao and Denis Rosário and Torsten Braun and Eduardo Cerqueira and Susana Sargento},
keywords = {Emergency and flash crowd situations, Unmanned Aerial Vehicles, Flying base stations, Artificial Intelligence},
abstract = {Future mobile communication networks need Unmanned Aerial Vehicles as Base Stations (UAVasBSs) with the fast-moving and long-term hovering capabilities to guarantee consistent network performance. UAVasBSs help 5G/B5G mobile communication systems to rapidly recover from emergency situations and handle the instant traffic of the flash crowd. In this context, multiple UAVs might form a flying ad-hoc network to establish a flying access network to enhance the network connectivity and service quality. Therefore, it is important to determine the optimal number and locations of UAVasBSs in a fast and efficient way to cover the target area to provide temporary yet reliable cellular connectivity. The use of Artificial Intelligence (AI) and network data analysis are key tools to fulfill the above issues. In this article, we propose a smart UAVasBS placement (SUAP) mechanism to improve the mobile network operations in flash crowd and emergency situations. We have modeled such an UAVasBS placement task as an optimization problem to obtain required network connectivity and system performance, and resolved it with a genetic algorithm using the network context information. Simulation results show that our proposal could cover 90% of mobile users, and it provides nearly 90% packet delivery ratio for users with a fast convergence rate.}
}
@article{SARWAR2021106219,
title = {Detecting sheep in UAV images},
journal = {Computers and Electronics in Agriculture},
volume = {187},
pages = {106219},
year = {2021},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2021.106219},
url = {https://www.sciencedirect.com/science/article/pii/S0168169921002362},
author = {Farah Sarwar and Anthony Griffin and Saeed Ur Rehman and Timotius Pasang},
keywords = {Deep learning, Object detection, Livestock, UAV},
abstract = {In the last decade, researchers have focused more on deep convolutional neural networks (CNNs) than other machine learning algorithms for object detection, localization, classification and segmentation. Such CNNs have achieved remarkable results in these fields and use the bounding boxes as the ground truth data. In this research article, we have used a fully connected network (FCN) for livestock detection in aerial images captured by an unmanned aerial vehicle (UAV), that used centroids as ground truth data. For performance evaluation and comparison, we have proposed a single-layered and a seven-layered CNN network in this article. These proposed networks are trained using state-of-the-art method, Region-based CNN. In addition, AlexNet, GoogLeNet, VGG16, VGG19 and ResNet50 were also fine-tuned for livestock detection. The results of the FCN and one of our proposed networks are then merged to improve the recall of the complete system from 90% to 98%.}
}
@article{WEI2021108439,
title = {Computation offloading over multi-UAV MEC network: A distributed deep reinforcement learning approach},
journal = {Computer Networks},
volume = {199},
pages = {108439},
year = {2021},
issn = {1389-1286},
doi = {https://doi.org/10.1016/j.comnet.2021.108439},
url = {https://www.sciencedirect.com/science/article/pii/S1389128621003984},
author = {Dawei Wei and Jianfeng Ma and Linbo Luo and Yunbo Wang and Lei He and Xinghua Li},
keywords = {Multi-UAV assisted MEC-enabled network, Computation offloading, Distributed reinforcement learning},
abstract = {Unmanned aerial vehicle (UAV)-assisted computation offloading allows mobile devices (MDs) to process computation-intensive and latency-sensitive tasks with limited or no-available infrastructures. To achieve long-term performance under changing environment, deep reinforcement-based methods have been applied to solve the UAV-assisted computation offloading problem. However, the deployment of multiple UAVs for computation offloading in mobile edge computing (MEC) network still faces the challenge of lacking flexible learning scheme to efficiently adjust computation offloading policy according to dynamic UAV mobility pattern and UAV failure. To this end, a distributed deep reinforcement learning (DRL)-based method with the cooperative exploring and prioritized experience replay (PER) is proposed in this paper. Our distributed exploring process achieves flexible learning scheme under UAV failure by allowing MDs to learning cost-efficient offloading policy cooperatively. Furthermore, PER allows MDs can explore the transitions with high TD-error, which can improve the performance under dynamic UAV mobility patterns. The efficiency of the proposed method is demonstrated by comparing with the existing computation offloading methods, and results show that the proposed method outperforms the compared methods in terms of convergence rate, energy-task efficiency and average processing time.}
}
@article{RAMACHANDRAN2021215,
title = {A review on object detection in unmanned aerial vehicle surveillance},
journal = {International Journal of Cognitive Computing in Engineering},
volume = {2},
pages = {215-228},
year = {2021},
issn = {2666-3074},
doi = {https://doi.org/10.1016/j.ijcce.2021.11.005},
url = {https://www.sciencedirect.com/science/article/pii/S2666307421000267},
author = {Anitha Ramachandran and Arun Kumar Sangaiah},
keywords = {Object detection, UAV, Drone, Deep learning, Precision agriculture, Security},
abstract = {Purpose
Computer vision in drones has gained a lot of attention from artificial intelligence researchers. Providing intelligence to drones will resolve many real-time problems. Computer vision tasks such as object detection, object tracking, and object counting are significant tasks for monitoring specified environments. However, factors such as altitude, camera angle, occlusion, and motion blur make it a more challenging task.
Methodology
In this paper, a detailed literature review has been conducted focusing on object detection and tracking using UAVs concerning different applications. This study summarizes the findings of existing research papers and identifies the research gaps.
Contribution
Object detection methods applied in UAV images are classified and elaborated. UAV datasets specific to object detection tasks are listed. Existing research works in different applications are summarized. Finally, a secure onboard processing system on a robust object detection framework in precision agriculture is proposed to mitigate identified research gaps.}
}
@article{LIU2021108397,
title = {Task offloading optimization of cruising UAV with fixed trajectory},
journal = {Computer Networks},
volume = {199},
pages = {108397},
year = {2021},
issn = {1389-1286},
doi = {https://doi.org/10.1016/j.comnet.2021.108397},
url = {https://www.sciencedirect.com/science/article/pii/S1389128621003741},
author = {Peng Liu and Han He and Tingting Fu and Huijuan Lu and Abdulhameed Alelaiwi and Md Wasif Islam Wasi},
keywords = {Unmanned aerial vehicles, Task offloading, Edge computing, Q-learning},
abstract = {Unmanned aerial vehicle (UAV) have been deployed in many applications, such as Power Grid inspection, forest fire prevention, and pollution surveillance. They often cruise along a fixed route above the target area. Due to the cost of remote communication and local computationally intensive tasks, resource-constrained drones tend to offload tasks to edge servers. In most cases, drones do not know the prior knowledge of user nodes and edge servers, and must reduce the altitude to provide services. Therefore, it is necessary to carefully decide when and where to collect and offload tasks to avoid unnecessary energy consumption and time delays. In this paper, we propose the benefit maximization problem under constraints such as time sensitivity, and propose an optimized task offloading strategy based on the reinforcement learning algorithm. We strive to directly solve the deficiencies in the profit maximization problem with modified Q-Learning algorithm. We test the performance under practical application scenarios with different environmental parameters. The experimental results prove that the solution proposed in this paper has better convergence and performance, as well as better reusability in similar application scenarios.}
}
@article{JAIMES2021274,
title = {An Incentive Mechanism for UAVs Crowdsensing Markets, a Negotiation Approach},
journal = {IFAC-PapersOnLine},
volume = {54},
number = {13},
pages = {274-279},
year = {2021},
note = {20th IFAC Conference on Technology, Culture, and International Stability TECIS 2021},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2021.10.458},
url = {https://www.sciencedirect.com/science/article/pii/S2405896321018954},
author = {Luis G Jaimes and Janar Kahr and Juan M. Calderon},
keywords = {Cost Oriented Automation, Intelligent Systems, Applications, Artificial intelligence, Deep Learning},
abstract = {In this paper, we present an incentive mechanism for Unmanned Aerial vehicles (UAVs) crowdsensing. In particular, we propose a solution to the problem of sensing coverage of lower regions of the atmosphere where a set of UAVs transverse it as part of their daily activities. We propose a UAV sensing market where data collection is an additional by-product that UAVs obtained while following their regular trajectories. In this model, participants use negotiation to compete and cooperate with each other while participating in data collection campaigns. Using the Virtual Robotics Environment (VRep) and extensive simulations, we show that our algorithm performs well in terms of sensing coverage, and participants retention while using a limited budget.}
}
@article{PERRY2020108048,
title = {Streamlined bridge inspection system utilizing unmanned aerial vehicles (UAVs) and machine learning},
journal = {Measurement},
volume = {164},
pages = {108048},
year = {2020},
issn = {0263-2241},
doi = {https://doi.org/10.1016/j.measurement.2020.108048},
url = {https://www.sciencedirect.com/science/article/pii/S0263224120305868},
author = {Brandon J. Perry and Yanlin Guo and Rebecca Atadero and John W. {van de Lindt}},
keywords = {Computer vision, Machine learning, Structural Health Monitoring (SHM), Unmanned Aerial Vehicles (UAVs), Bridge Information Model (BrIM), Bridge inspection},
abstract = {Recently, the rapid development of commercial unmanned aerial vehicles (UAVs) has made collecting images of bridge conditions trivial. Measuring the damage extent, growth, and location from the collected big image set, however, can be cumbersome. This paper proposes a streamlined bridge inspection system that offers advanced data analytics tools to automatically: (1) identify type, extent, growth, and 3D location of defects using computer vision techniques; (2) generate a 3D point-cloud model and segment structural elements using human-in-the-loop machine learning; and (3) establish a georeferenced element-wise as-built bridge information model to document and visualize damage information. This system allows bridge managers to better leverage UAV technologies in bridge inspection and conveniently monitor the health of a bridge through quantifying and visualizing the progression of damage for each structural element. The efficacy of the system is demonstrated using two bridges.}
}
@article{BARBOSA2021100010,
title = {UAV-based coffee yield prediction utilizing feature selection and deep learning},
journal = {Smart Agricultural Technology},
volume = {1},
pages = {100010},
year = {2021},
issn = {2772-3755},
doi = {https://doi.org/10.1016/j.atech.2021.100010},
url = {https://www.sciencedirect.com/science/article/pii/S2772375521000101},
author = {Brenon Diennevan Souza Barbosa and Gabriel Araújo e Silva Ferraz and Lucas Costa and Yiannis Ampatzidis and Vinay Vijayakumar and Luana Mendes {dos Santos}},
keywords = {Deep-learning, Remote sensing, UAV imagery, Yield prediction},
abstract = {Unmanned Aerial Vehicles (UAVs) combined with machine learning have a great potential for crop yield estimation. In this study, a UAV equipped with an RGB (Red, Green, Blue) camera and computer vision algorithms were used to estimate coffee tree height and crown diameter, and for the prediction of coffee yield. Data were collected for 144 trees between June 2017 and May 2018, in the Minas Gerais, Brazil. Six parameters (leaf area index - LAI, tree height, crown diameter, and the individual RGB band values) were used to develop UAV-based yield prediction models. First, a feature ranking was performed to identify the most significant parameter(s) and month(s) for data collection and yield prediction. Based on the feature rankings, the LAI and the crown diameter were determined as the most important parameters. Five algorithms were used to develop yield prediction models: (i) linear support vector machines (SVM), (ii) gradient boosting regression (GBR), (iii) random forest regression (RFR), (iv) partial least square regression (PLSR), and (v) neuroevolution of augmenting topologies (NEAT). The mean absolute percentage error (MAPE) was used to evaluate the yield prediction models. The best result was obtained by the NEAT algorithm (MAPE of 31.75%) for a reduced dataset containing only the most important features (LAI and the crown diameter) and the most important months (December 2017 and April 2018). The results suggest that a dataset of the most important month (December) could be used for the yield prediction model, reducing the need for extensive data collection (e.g., monthly data collection).}
}
@article{YU2022101582,
title = {UAV path design with connectivity constraint based on deep reinforcement learning},
journal = {Physical Communication},
volume = {52},
pages = {101582},
year = {2022},
issn = {1874-4907},
doi = {https://doi.org/10.1016/j.phycom.2021.101582},
url = {https://www.sciencedirect.com/science/article/pii/S1874490721002822},
author = {Lin Yu and Fahui Wu and Zhihai Xu and Zhigang Xie and Dingcheng Yang},
keywords = {Cellular-connected communication, Deep reinforcement learning, Trajectory optimization},
abstract = {Cellular networks are expected to communicate effectively with unmanned aerial vehicles (UAVs) and support various applications. However, existing cellular networks are primarily designed to cover users on the ground; thus, coverage holes in the sky will exist. In this paper, we investigate the problem of path design for cellular-connected UAVs, taking into account the interruption performance throughout the UAV mission to minimize the completion time. Two types of connectivity constraints requirements are assumed to be available. The first is defined as the maximum continuous time interval that the UAV loses connection with base stations (BSs) below a predefined threshold. For the second, we consider the sum outage of UAV is limited during the entire UAV mission. The UAV is tasked with flying from a starting location to a final destination while minimization the mission time, satisfying the two constraints, separately. The formulated path design problem which involves continues variables and a dynamic radio environment, is not convex and thus is extremely difficult to solve directly. To tackle this challenge, a deep reinforcement learning (DRL) based trajectory design algorithm is proposed, where the Dueling Double Deep Q Network(Dueling DDQN) with multi-steps learning method is applied. Simulation results demonstrate the effectiveness of the proposed DRL algorithm and achieve a trade-off between the trajectory length of the UAV and connection quality.}
}
@article{BANGUI2021877,
title = {Recent Advances in Machine-Learning Driven Intrusion Detection in Transportation: Survey},
journal = {Procedia Computer Science},
volume = {184},
pages = {877-886},
year = {2021},
note = {The 12th International Conference on Ambient Systems, Networks and Technologies (ANT) / The 4th International Conference on Emerging Data and Industry 4.0 (EDI40) / Affiliated Workshops},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2021.04.014},
url = {https://www.sciencedirect.com/science/article/pii/S1877050921007894},
author = {Hind Bangui and Barbora Buhnova},
keywords = {Machine learning, VANET, UAV, Intrusion Detection Systems, Trust, Security},
abstract = {Rapid developments in Intelligent Transportation Systems (ITSs) have emerged as a new research field for building sustainable smart cities. VANET (vehicular ad hoc network) is one of the emergent transportation technologies that has a great impact on ensuring mainly traffic management and road safety in urban areas by effciently using data sharing among vehicles. To further increase the security and safety of passengers and drivers, ITSs are continually striving to make the fusion of emergent network technologies to provide more reliable and effcient services. Relating VANET to UAV (unmanned aerial vehicle) is an example of this fusion, where UAVs act as an assistant to vehicles aiming to extend the network connectivity while effciently avoiding obstacles (e.g., Buildings) and providing high data delivery ratios. However, VANET and UAV are still critical security subjects that must be addressed. Advanced Machine Learning (e.g., Deep Learning) techniques have recently been used to protect VANET and UAV communications against various cyber attacks that deteriorate the integrity, confidentiality, and availability of vehicular data. Thus, in this paper, we focus on reviewing related work on machine learning techniques for intrusion detection systems in VANET- and UAV-aided networks. We also highlight the main open research challenges in literature and provide hints for improving security in ITSs.}
}
@article{GUO2018155,
title = {A hybrid feature model and deep learning based fault diagnosis for unmanned aerial vehicle sensors},
journal = {Neurocomputing},
volume = {319},
pages = {155-163},
year = {2018},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2018.08.046},
url = {https://www.sciencedirect.com/science/article/pii/S0925231218309962},
author = {Dingfei Guo and Maiying Zhong and Hongquan Ji and Yang Liu and Rui Yang},
keywords = {Model based fault diagnosis, Deep learning, Short-time fourier transform, Convolutional neural network, UAV sensors},
abstract = {Fault diagnosis plays an important role in guaranteeing system safety and reliability for unmanned aerial vehicles (UAVs). In this study, a hybrid feature model and deep learning based fault diagnosis for UAV sensors is proposed. The residual signals of different sensor faults, including global positioning system (GPS), inertial measurement unit (IMU), air data system (ADS), were collected. This paper used short time fourier transform (STFT) to transform the residual signal to the corresponding time-frequency map. Then, a convolutional neural network (CNN) was used to extract the feature of the map and the fault diagnosis of the UAV sensors was implemented. Finally, the performance of the proposed methodology is evaluated through flight experiments of the UAV. From the visualization, the sensor faults information can be extracted by CNN and the fault diagnosis logic between the residuals and the health status can be constructed successfully.}
}
@article{SU2022106873,
title = {LodgeNet: Improved rice lodging recognition using semantic segmentation of UAV high-resolution remote sensing images},
journal = {Computers and Electronics in Agriculture},
volume = {196},
pages = {106873},
year = {2022},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2022.106873},
url = {https://www.sciencedirect.com/science/article/pii/S0168169922001909},
author = {Zhongbin Su and Yue Wang and Qi Xu and Rui Gao and Qingming Kong},
keywords = {Deep learning, U-Net, Small sample data set, End-to-end neural network},
abstract = {Rice lodging not only causes difficulty in harvest operations, but also drastically reduces yield. Therefore, it is very important to identify rice lodging efficiently. For unmanned aerial vehicle (UAV) remote sensing images, this paper combines the advantages of dense block, DenseNet, attention mechanism, and jump connection on the basis of U-Net network to propose an end-to-end, pixel-to-pixel semantic segmentation method to identify rice lodging. And the method can process the input multi-band image. The accuracy of the model proposed in this paper was 97.30% on rice lodging images, which performed better than other comparison methods in the test. At the same time, it has good effect on small sample data set. The results show that it is feasible to use the improved U-Net network model to extract the lodging area of rice, which provide a useful reference for rice breeding and agricultural insurance claims.}
}
@article{AMPATZIDIS2020105457,
title = {Agroview: Cloud-based application to process, analyze and visualize UAV-collected data for precision agriculture applications utilizing artificial intelligence},
journal = {Computers and Electronics in Agriculture},
volume = {174},
pages = {105457},
year = {2020},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2020.105457},
url = {https://www.sciencedirect.com/science/article/pii/S0168169920304695},
author = {Yiannis Ampatzidis and Victor Partel and Lucas Costa},
keywords = {UAVs, Artificial intelligence, Machine learning, Smart agriculture, Precision agriculture, Neural networks, Cloud computing},
abstract = {Traditional sensing technologies in specialty crops production, for pest and disease detection and field phenotyping, rely on manual sampling and are time consuming and labor intensive. Since availability of personnel trained for field scouting is a major problem, small Unmanned Aerial Vehicles (UAVs) equipped with various sensors can simplify the surveying procedure, decrease data collection time, and reduce cost. To accurate and rapidly process, analyze and visualize data collected from UAVs and other platforms (e.g. small airplanes, satellites, ground platforms), a cloud and artificial intelligence (AI) based application (named Agroview) was developed. This interactive and user-friendly application can: (i) detect, count and geo-locate plants and plant gaps (locations with dead or no plants); (ii) measure plant height and canopy size (plant inventory); (iii) develop plant health (or stress) maps. In this study, the use of this Agroview application to evaluate phenotypic characteristics of citrus trees (as a case study) is presented. It was found, that this emerging technology detected citrus trees with mean absolute percentage error (MAPE) of 2.3% in a commercial citrus orchard with 175,977 trees (1,871 acres; 39 normal and high-density spacing blocks). Furthermore, it accurately estimated tree height with 4.5% and 12.93% MAPE for normal and high-density spacing respectively, and canopy size with MAPE of 12.9% and 34.6% for normal and high-density spacing respectively. It provides a consistent, more direct, cost-effective and rapid method for field survey and plant phenotyping.}
}
@article{GUO2020103124,
title = {Dense construction vehicle detection based on orientation-aware feature fusion convolutional neural network},
journal = {Automation in Construction},
volume = {112},
pages = {103124},
year = {2020},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2020.103124},
url = {https://www.sciencedirect.com/science/article/pii/S092658051930994X},
author = {Yapeng Guo and Yang Xu and Shunlong Li},
keywords = {Object detection, Dense multiple construction vehicles, Feature fusion, Orientation-aware bounding box, Unmanned aerial vehicle, Deep learning, Computer vision},
abstract = {During the construction process, many construction vehicles gather in a small area in a short period, thus the accurate identification of dense multiple vehicles is of great significance for ensuring the safety of construction sites. In this study, a novel end-to-end deep learning network, namely orientation-aware feature fusion single-stage detection (OAFF-SSD), is proposed for the precise detection of dense multiple construction vehicles using images from Unmanned Aerial Vehicle (UAV). The proposed OAFF-SSD consists of three main modules: (1) multi-level feature extraction, (2) novel feature fusion, and (3) new orientation-aware bounding box (OABB) proposal and regression. Meanwhile, specific strategies are designated for the fast convergence of training losses. The application of OAFF-SSD to real construction sites vehicle detection and comparison with the well-known SSD (a benchmark using traditional bounding box) and orientation-aware SSD (OA-SSD) demonstrate the efficiency and accuracy of the proposed method.}
}
@article{ALSAADE2022,
title = {A new neural network-based optimal mixed H2/H∞ control for a modified unmanned aerial vehicle subject to control input constraints},
journal = {Advances in Space Research},
year = {2022},
issn = {0273-1177},
doi = {https://doi.org/10.1016/j.asr.2022.02.012},
url = {https://www.sciencedirect.com/science/article/pii/S0273117722001016},
author = {Fawaz W. Alsaade and Hadi Jahanshahi and Qijia Yao and Mohammed S. Al-zahrani and Ali S. Alzahrani},
keywords = {UAV, Robust controller, H2/H∞ control, Neural network-based method},
abstract = {Unmanned aerial vehicles are subject to complex aerodynamic or hydrodynamic forces and various uncertainties, making their dynamic modeling difficult. Hence, in these systems, it is preferred to apply control techniques whose closed-loop systems can predict the system's uncertain dynamics and provide acceptable performance. To this end, this paper exploits a new neural network-based optimal mixed H2/H∞ control for a modified unmanned aerial vehicle to accomplish trajectory tracking missions. Firstly, the dynamic model of the modified unmanned aerial vehicles is presented. Then, the design procedure of the new controller is delineated. In this approach, H∞ attenuates the effect of uncertainties and through H2 the consumed control energy is minimized. Similar to real-world applications, it is supposed that there are control input constraints and external disturbances. The neural networks are also employed to estimate all uncertainties. The numerical simulations for two different desired paths are demonstrated. Simulation results illustrate the efficient performance of the proposed control technique in the presence of external disturbances, dynamic uncertainties, and control input constraints.}
}
@article{LIN2020135,
title = {Event-triggered reinforcement learning control for the quadrotor UAV with actuator saturation},
journal = {Neurocomputing},
volume = {415},
pages = {135-145},
year = {2020},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2020.07.042},
url = {https://www.sciencedirect.com/science/article/pii/S0925231220311504},
author = {Xiaobo Lin and Jian Liu and Yao Yu and Changyin Sun},
keywords = {Quadrotor, UAV, Reinforcement learning, Flight control, Event-triggered control, Actuator saturation},
abstract = {This paper proposes an event-triggered reinforcement learning (RL) control strategy to stabilize the quadrotor unmanned aerial vehicle (UAV) with actuator saturation. As the quadrotor UAV equips with a complex dynamic is difficult to be model accurately, a model free reinforcement learning scheme is designed. Due to the practical limitation of actuators, the end of controller is constrained with a bounded function. In order to reduce the calculation consumption for the onboard computer, an event-triggered mechanism is developed, which only update the controller when the triggered condition is satisfied. The proposed controller is implemented with two neural networks which are called critic and actor. Some advanced RL technologies are utilized for speeding up the train process, e.g. off-policy training, experience replay, etc. The stability of closed-loop system is proved by the Lyapunov analysis. The simulation results including a stability task and a tracking task verify the theoretical analysis, in which we find the updating frequency of controller is decreased greatly.}
}
@article{DENG2021,
title = {Learning-based joint UAV trajectory and power allocation optimization for secure IoT networks},
journal = {Digital Communications and Networks},
year = {2021},
issn = {2352-8648},
doi = {https://doi.org/10.1016/j.dcan.2021.07.007},
url = {https://www.sciencedirect.com/science/article/pii/S2352864821000481},
author = {Dan Deng and Xingwang Li and Varun Menon and Md Jalil Piran and Hui Chen and Mian Ahmad Jan},
keywords = {Unmanned aerial vehicle (UAV), NOMA, Reinforcement learning, Secure communications, Deep Q-learning},
abstract = {Non-Orthogonal Multiplex Access (NOMA) can be deployed in Unmanned Aerial Vehicle (UAV) networks to improve spectrum efficiency. Due to the broadcasting feature of NOMA-UAV networks, it is essential to focus on the security of the wireless system. This paper focuses on maximizing the secrecy sum-rate under the constraint of the achievable rate of the legitimate channels. To tackle the non-convexity optimization problem, a reinforcement learning-based alternative optimization algorithm is proposed. Firstly, with the help of successive convex approximations, the optimal power allocation scheme with a given UAV trajectory is obtained by using convex optimization tools. Afterwards, through plenty of explorations on the wireless environment, the Q-learning networks approach the optimal location transition strategy of the UAV, even without the wireless channel state information.}
}
@article{CHEN2020433,
title = {An intelligent task offloading algorithm (iTOA) for UAV edge computing network},
journal = {Digital Communications and Networks},
volume = {6},
number = {4},
pages = {433-443},
year = {2020},
issn = {2352-8648},
doi = {https://doi.org/10.1016/j.dcan.2020.04.008},
url = {https://www.sciencedirect.com/science/article/pii/S2352864819303037},
author = {Jienan Chen and Siyu Chen and Siyu Luo and Qi Wang and Bin Cao and Xiaoqian Li},
keywords = {Unmanned aerial vehicles (UAVs), Mobile edge computing (MEC), Intelligent task offloading algorithm (iTOA), Monte Carlo tree search (MCTS), Deep reinforcement learning, Splitting deep neural network (sDNN)},
abstract = {Unmanned Aerial Vehicle (UAV) has emerged as a promising technology for the support of human activities, such as target tracking, disaster rescue, and surveillance. However, these tasks require a large computation load of image or video processing, which imposes enormous pressure on the UAV computation platform. To solve this issue, in this work, we propose an intelligent Task Offloading Algorithm (iTOA) for UAV edge computing network. Compared with existing methods, iTOA is able to perceive the network’s environment intelligently to decide the offloading action based on deep Monte Calor Tree Search (MCTS), the core algorithm of Alpha Go. MCTS will simulate the offloading decision trajectories to acquire the best decision by maximizing the reward, such as lowest latency or power consumption. To accelerate the search convergence of MCTS, we also proposed a splitting Deep Neural Network (sDNN) to supply the prior probability for MCTS. The sDNN is trained by a self-supervised learning manager. Here, the training data set is obtained from iTOA itself as its own teacher. Compared with game theory and greedy search-based methods, the proposed iTOA improves service latency performance by 33% and 60%, respectively.}
}
@article{FALLATI2019133581,
title = {Anthropogenic Marine Debris assessment with Unmanned Aerial Vehicle imagery and deep learning: A case study along the beaches of the Republic of Maldives},
journal = {Science of The Total Environment},
volume = {693},
pages = {133581},
year = {2019},
issn = {0048-9697},
doi = {https://doi.org/10.1016/j.scitotenv.2019.133581},
url = {https://www.sciencedirect.com/science/article/pii/S0048969719335065},
author = {L. Fallati and A. Polidori and C. Salvatore and L. Saponari and A. Savini and P. Galli},
keywords = {Anthropogenic Marine-Debris, Unmanned Aerial Vehicles, Machine learning, Deep learning algorithms, Maldives, Beach},
abstract = {Anthropogenic Marine Debris (AMD) is one of the major environmental issues of our planet to date, and plastic accounts for 80% of total AMD. Beaches represent one of the main marine compartment where AMD accumulates, but few and scattered regional assessments are available from literature reporting quantitative estimation of AMD distributed on the shorelines. However, accessing information on the AMD accumulation rate on beaches, and the associated spatiotemporal oscillations, would be crucial to refining global estimation on the dispersal mechanisms. In our work, we address this issue by proposing an ad-hoc methodology for monitoring and automatically quantifying AMD, based on the combined use of a commercial Unmanned Aerial Vehicle (UAV) (equipped with an RGB high-resolution camera) and a deep-learning based software (i.e.: PlasticFinder). Remote areas were monitored by UAV and were inspected by operators on the ground to check and to categorise all AMD dispersed on the beach. The high-resolution images obtained from UAV allowed to visually detect a percentage of the objects on the shores higher than 87.8%, thus providing suitable images to populate training and testing datasets, as well as gold standards to evaluate the software performance. PlasticFinder reached a Sensitivity of 67%, with a Positive Predictive Value of 94%, in the automatic detection of AMD, but a limitation was found, due to reduced sunlight conditions, thus restricting to the use of the software in its present version. We, therefore, confirmed the efficiency of commercial UAVs as tools for AMD monitoring and demonstrated - for the first time - the potential of deep learning for the automatic detection and quantification of AMD.}
}
@article{CALOU2020115,
title = {The use of UAVs in monitoring yellow sigatoka in banana},
journal = {Biosystems Engineering},
volume = {193},
pages = {115-125},
year = {2020},
issn = {1537-5110},
doi = {https://doi.org/10.1016/j.biosystemseng.2020.02.016},
url = {https://www.sciencedirect.com/science/article/pii/S1537511020300568},
author = {Vinícius Bitencourt Campos Calou and Adunias dos Santos Teixeira and Luis Clenio Jario Moreira and Cristiano Souza Lima and Joaquim Branco {de Oliveira} and Marcio Regys Rabelo {de Oliveira}},
keywords = {Remote sensing, Machine learning, Unmanned aerial vehicle,  spp, , PhotoScan},
abstract = {Monitoring pests and diseases is an extremely important activity for increasing productivity in agriculture. In this scenario, remote sensing, coupled with techniques of machine learning, offer new prospects for monitoring and identifying characteristic specific patterns, such as manifestations of diseases, pests, and water and nutritional stress. The aim was to use high spatial resolution aerial images to monitor the extent of an attack of yellow sigatoka in a banana crop, following the basic assumptions of identification, classification, quantification and prediction of phenotypic factors. Monthly flights were carried out on a commercial banana plantation using an unmanned aerial vehicle, equipped with a 16-megapixel RGB camera (GSD of 0.016781 m pixel−1). Five classification algorithms were used to identify and quantify the disease while field evaluations were also made following traditional methodology. The results showed that, for September 2017, the Support Vector Machine algorithm achieved the best performance (99.28% overall accuracy and 97.13 Kappa Index), followed by the Artificial Neural Network and Minimum Distance algorithms. In quantifying the disease, the SVM algorithm was more effective than other algorithms compared to the conventional methodology used to estimate the extent of yellow sigatoka, demonstrating that the tools used for monitoring leaf spots can be handled by remote sensing, machine learning and high spatial-resolution RGB images.}
}
@article{YANG2021101314,
title = {Identification and micro-motion parameter estimation of non-cooperative UAV targets},
journal = {Physical Communication},
volume = {46},
pages = {101314},
year = {2021},
issn = {1874-4907},
doi = {https://doi.org/10.1016/j.phycom.2021.101314},
url = {https://www.sciencedirect.com/science/article/pii/S1874490721000513},
author = {Jiachen Yang and Zhuo Zhang and Wei Mao and Yue Yang},
keywords = {Radar cross section, UAV identification, Micro-motion, Deep learning},
abstract = {With the wide application of unmanned aerial vehicles (UAV) in industrial production, transportation, and entertainment, it is urgent to identify UAVs in time. Traditional UAV recognition mainly depends on wireless communication, which puts forward high requirements for a communication environment and has no way to deal with non-cooperative targets. Therefore, it is urgent to explore a UAV target recognition scheme based on perception. In this paper, aiming at the time series preprocessing method, a coding-based sequence preprocessing method is proposed. This method effectively improves the effect of the Deep Learning method in the identification task. In order to verify the ability of Deep Learning in radar time series data processing and the effectiveness of the proposed method, the Deep Learning method is used to analyze the radar signal time series of the target to realize the target recognition. Finally,considering the influence of micro-motion factors on UAV targets, the neural network is used to estimate UAV’s micro-motion parameters to enhance the ability of target recognition with the help of micro-motion information.}
}
@article{AMPATZIDIS2019104900,
title = {Citrus rootstock evaluation utilizing UAV-based remote sensing and artificial intelligence},
journal = {Computers and Electronics in Agriculture},
volume = {164},
pages = {104900},
year = {2019},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2019.104900},
url = {https://www.sciencedirect.com/science/article/pii/S0168169919311123},
author = {Yiannis Ampatzidis and Victor Partel and Bo Meyering and Ute Albrecht},
keywords = {UAV, Machine learning, Smart agriculture, Precision agriculture, Neural networks, Deep learning, Rootstock, Citrus},
abstract = {The implementation of breeding methods requires the creation of a large and genetically diverse training population. Large-scale experiments are needed for the rapid acquisition of phenotypic data to explore the correlation between genomic and phenotypic information. Traditional sensing technologies for field surveys and field phenotyping rely on manual sampling and are time consuming and labor intensive. Since availability of personnel trained for phenotyping is a major problem, small UAVs (unmanned aerial vehicles) equipped with various sensors can simplify the surveying procedure, decrease data collection time, and reduce cost. In this study, we evaluated the phenotypic characteristics of sweet orange trees grafted on 25 rootstock cultivars with different influences on plant growth and productivity utilizing a UAV-based high throughput phenotyping system. Data collected by UAV were compared with data collected manually according to standard horticultural procedures. The UAV-based technique was able to detect and count citrus trees with high precision (99.9%) in an orchard of 4931 trees and estimate tree canopy size with a high correlation (R = 0.84) with the manual collected data. No correlation of UAV-based data and manually collected data was observed for yield. The reason for the observed deviation is the influence of different rootstock cultivars on yield efficiency. Despite the low vigor-inducing effect of some rootstocks, they are highly productive, whilst others are high in vigor but produce less fruit. Our study demonstrates the high accuracy of the UAV technique to assess tree size. When using these techniques, it is essential to recognize the limitations imposed by the biological system.}
}
@article{SIERRAGARCIA2021115380,
title = {Intelligent control of an UAV with a cable-suspended load using a neural network estimator},
journal = {Expert Systems with Applications},
volume = {183},
pages = {115380},
year = {2021},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2021.115380},
url = {https://www.sciencedirect.com/science/article/pii/S095741742100806X},
author = {Jesús Enrique Sierra-García and Matilde Santos},
keywords = {Modelling, Intelligent control, Hybrid automata, Neural networks, Unmanned Aerial Vehicle (UAV), Cable-suspended load},
abstract = {Unmanned aerial vehicles (UAVs) have been proved very useful in civil and military sectors: defense, security, shipping, construction, agriculture, entertainment, etc. Some of these applications, especially those related to transport and logistic operations, require the use of suspended loads that may make the vehicle unstable. In order to deal with this non-linear complex system with a changing mass, further research on modelling and control must be developed. In this work, a new intelligent control strategy is proposed and applied to a quadrotor with a cable-suspended load. The UAV carrying a suspended load has two different dynamic behaviors, depending on the state of the cable. Thus, we proposed to model the complete system using the hybrid automata formalism. Using this novel UAV model approach, a hybrid control is designed based on feedback linearization controllers combined with an artificial neural network, which acts as an online estimator of the unknown mass. The suspended load is dealt with as an external disturbance. Simulation results show how the on-line learning control scheme increases the robustness of the control and it is able to stabilize the quadrotor without any information about neither the position of the load nor the tension of the cable. Additionally, the computational complexity of the proposal is studied to show the feasibility of the implementation of this intelligent control strategy on real hardware.}
}
@article{WANG20202930,
title = {Coactive design of explainable agent-based task planning and deep reinforcement learning for human-UAVs teamwork},
journal = {Chinese Journal of Aeronautics},
volume = {33},
number = {11},
pages = {2930-2945},
year = {2020},
note = {SI: Emerging Technologies of Unmanned Aerial Vehicles},
issn = {1000-9361},
doi = {https://doi.org/10.1016/j.cja.2020.05.001},
url = {https://www.sciencedirect.com/science/article/pii/S1000936120301229},
author = {Chang WANG and Lizhen WU and Chao YAN and Zhichao WANG and Han LONG and Chao YU},
keywords = {Coactive design, Deep reinforcement learning, Human-robot teamwork, Mixed-initiative, Multi-agent system, Task planning, UAV},
abstract = {Unmanned Aerial Vehicles (UAVs) are useful in dangerous and dynamic tasks such as search-and-rescue, forest surveillance, and anti-terrorist operations. These tasks can be solved better through the collaboration of multiple UAVs under human supervision. However, it is still difficult for human to monitor, understand, predict and control the behaviors of the UAVs due to the task complexity as well as the black-box machine learning and planning algorithms being used. In this paper, the coactive design method is adopted to analyze the cognitive capabilities required for the tasks and design the interdependencies among the heterogeneous teammates of UAVs or human for coherent collaboration. Then, an agent-based task planner is proposed to automatically decompose a complex task into a sequence of explainable subtasks under constrains of resources, execution time, social rules and costs. Besides, a deep reinforcement learning approach is designed for the UAVs to learn optimal policies of a flocking behavior and a path planner that are easy for the human operator to understand and control. Finally, a mixed-initiative action selection mechanism is used to evaluate the learned policies as well as the human’s decisions. Experimental results demonstrate the effectiveness of the proposed methods.}
}
@article{HU2020138,
title = {Recognition of diseased Pinus trees in UAV images using deep learning and AdaBoost classifier},
journal = {Biosystems Engineering},
volume = {194},
pages = {138-151},
year = {2020},
issn = {1537-5110},
doi = {https://doi.org/10.1016/j.biosystemseng.2020.03.021},
url = {https://www.sciencedirect.com/science/article/pii/S1537511020300842},
author = {Gensheng Hu and Cunjun Yin and Mingzhu Wan and Yan Zhang and Yi Fang},
keywords = {Diseased Pinus tree, Target recognition, UAV image, Deep learning, AdaBoost classifier},
abstract = {Recognition of diseased Pinus trees in unmanned aerial vehicle (UAV) images is beneficial to the dynamic monitoring and control of Pinus tree diseases in large areas. However, the low resolution and complex backgrounds of UAV images limit the accuracy of traditional machine learning methods in recognising diseased Pinus trees. This study presents a method for recognising diseased Pinus trees that combines deep convolutional neural networks (DCNNs), deep convolutional generative adversarial networks (DCGANs), and an AdaBoost classifier. DCGANs can expand the number of samples of diseased Pinus trees to solve the problem of insufficient training samples. DCNNs are used to remove fields, soils, roads, and rocks in images to reduce the impact of complex backgrounds on target recognition. The AdaBoost classifier distinguishes diseased Pinus trees from healthy Pinus trees and identifies shadows in background removal images. Experimental results show that the proposed method has better recognition performance than K-means clustering, support vector machine, AdaBoost classifier, backpropagation neural networks, Alexnet, VGG, and Inception_v3 networks.}
}
@article{ZHOU202190,
title = {Yield estimation of soybean breeding lines under drought stress using unmanned aerial vehicle-based imagery and convolutional neural network},
journal = {Biosystems Engineering},
volume = {204},
pages = {90-103},
year = {2021},
issn = {1537-5110},
doi = {https://doi.org/10.1016/j.biosystemseng.2021.01.017},
url = {https://www.sciencedirect.com/science/article/pii/S1537511021000180},
author = {Jing Zhou and Jianfeng Zhou and Heng Ye and Md Liakat Ali and Pengyin Chen and Henry T. Nguyen},
keywords = {Soybean breeding, drought stress, yield estimation, UAV multispectral imagery, convolutional neural network},
abstract = {Crop yield is a primary trait to select superior genotypes and evaluate breeding efficiency in breeding programs. Crops with high yield potential are usually selected from numerous breeding lines in multiple years and locations. However, the efficiency of conventional breeding programs is limited by the capacity of field phenotyping, which can be improved by developing high-throughput field phenotyping systems using emerging technologies, including Unmanned Aerial Vehicle (UAV) imagery and deep learning technologies. The goal of this study was to evaluate the performance of a UAV imaging system and convolutional neural network (CNN) in estimating yield of soybean breeding lines. In this study, 972 soybean breeding lines in three maturity groups were planted under rainfed conditions for testing their drought tolerance. Aerial images were taken at the late vegetation (V6), early (R1), and late reproductive (R6-R8) growth stages. Seven image features associated with plant height, canopy colour, and canopy texture were selected to estimate the yield of each breeding line. A mixed CNN model was built to estimate soybean yield by taking the seven image features and two categorical factors, i.e. maturity group and drought tolerance, as predictors. Results show that image features collected at the early and late reproductive growth stages are comparably promising in estimating soybean yield. The prediction model could explain 78% of the measured yield with a root mean square error of 391.0 kg·ha−1 (33.8% to the average yield), indicating that the UAV imagery and deep learning models are promising in estimating yield for soybean breeding purposes.}
}
@article{NASSER2022108672,
title = {A lightweight federated learning based privacy preserving B5G pandemic response network using unmanned aerial vehicles: A proof-of-concept},
journal = {Computer Networks},
volume = {205},
pages = {108672},
year = {2022},
issn = {1389-1286},
doi = {https://doi.org/10.1016/j.comnet.2021.108672},
url = {https://www.sciencedirect.com/science/article/pii/S1389128621005466},
author = {Nidal Nasser and Zubair Md Fadlullah and Mostafa M. Fouda and Asmaa Ali and Muhammad Imran},
keywords = {5G, Beyond 5G (B5G), Federated learning, Unmanned aerial vehicle (UAV), Pandemic, Artificial intelligence (AI), Edge computing},
abstract = {The concept of an intelligent pandemic response network is gaining momentum during the current novel coronavirus disease (COVID-19) era. A heterogeneous communication architecture is essential to facilitate collaborative and intelligent medical analytics in the fifth generation and beyond (B5G) networks to intelligently learn and disseminate pandemic-related information and diagnostic results. However, such a technique raises privacy issues pertaining to the health data of the patients. In this paper, we envision a privacy-preserving pandemic response network using a proof-of-concept, aerial–terrestrial network system serving mobile user entities/equipment (UEs). By leveraging the unmanned aerial vehicles (UAVs), a lightweight federated learning model is proposed to collaboratively yet privately learn medical (e.g., COVID-19) symptoms with high accuracy using the data collected by individual UEs using ambient sensors and wearable devices. An asynchronous weight updating technique is introduced in federated learning to avoid redundant learning and save precious networking as well as computing resources of the UAVs/UEs. A use-case where an Artificial Intelligence (AI)-based model is employed for COVID-19 detection from radiograph images is presented to demonstrate the effectiveness of our proposed approach.}
}
@article{SU2022106621,
title = {Spectral analysis and mapping of blackgrass weed by leveraging machine learning and UAV multispectral imagery},
journal = {Computers and Electronics in Agriculture},
volume = {192},
pages = {106621},
year = {2022},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2021.106621},
url = {https://www.sciencedirect.com/science/article/pii/S0168169921006384},
author = {Jinya Su and Dewei Yi and Matthew Coombes and Cunjia Liu and Xiaojun Zhai and Klaus McDonald-Maier and Wen-Hua Chen},
keywords = {Blackgrass weed, Guided filter, Random forest, Spectral Index (SI), Unmanned Aerial Vehicle (UAV)},
abstract = {Accurate weed mapping is a prerequisite for site-specific weed management to enable sustainable agriculture. This work aims to analyse (spectrally) and mapping blackgrass weed in wheat fields by integrating Unmanned Aerial Vehicle (UAV), multispectral imagery and machine learning techniques. 18 widely-used Spectral Indices (SIs) are generated from 5 raw spectral bands. Then various feature selection algorithms are adopted to improve model simplicity and empirical interpretability. Random Forest classifier with Bayesian hyperparameter optimization is preferred as the classification algorithm. Image spatial information is also incorporated into the classification map by Guided Filter. The developed framework is illustrated with an experimentation case in a naturally blackgrass infected wheat field in Nottinghamshire, United Kingdom, where multispectral images were captured by RedEdge on-board DJI S-1000 at an altitude of 20 m with a ground spatial resolution of 1.16 cm/pixel. Experimental results show that: (i) a good result (an average precision, recall and accuracy of 93.8%, 93.8%, 93.0%) is achieved by the developed system; (ii) the most discriminating SI is triangular greenness index (TGI) composed of Green-NIR, while wrapper feature selection can not only reduce feature number but also achieve a better result than using all 23 features; (iii) spatial information from Guided filter also helps improve the classification performance and reduce noises.}
}
@article{YU2021104861,
title = {Fractional order PID-based adaptive fault-tolerant cooperative control of networked unmanned aerial vehicles against actuator faults and wind effects with hardware-in-the-loop experimental validation},
journal = {Control Engineering Practice},
volume = {114},
pages = {104861},
year = {2021},
issn = {0967-0661},
doi = {https://doi.org/10.1016/j.conengprac.2021.104861},
url = {https://www.sciencedirect.com/science/article/pii/S0967066121001386},
author = {Ziquan Yu and Youmin Zhang and Bin Jiang and Chun-Yi Su and Jun Fu and Ying Jin and Tianyou Chai},
keywords = {Unmanned aerial vehicles (UAVs), Fault-tolerant cooperative control (FTCC), Fractional order control, Proportional–integral–derivative (PID), Actuator faults, Recurrent neural networks},
abstract = {This paper proposes an adaptive fault-tolerant cooperative control (FTCC) scheme for networked unmanned aerial vehicles (UAVs) in the presence of actuator faults and wind effects by artfully introducing fractional order calculus, proportional–integral–derivative (PID), and recurrent neural networks. Fractional order sliding-mode surface and PID-type error mapping are first utilized to transform the synchronization tracking errors of all UAVs into a new set of errors. Then, based on these newly constructed errors, an FTCC scheme is developed to synchronously track their references. Moreover, Butterworth low-pass filter (BLF) and recurrent neural network (RNN) learning strategies are assimilated to handle the unknown terms induced by the actuator faults and wind effects. Finally, theoretical analysis and comparative hardware-in-the-loop experimental demonstrations have shown the effectiveness of the proposed control scheme.}
}
@article{LIJIA201947,
title = {Adaptive observer-based fault detection and active tolerant control for unmanned aerial vehicles attitude system},
journal = {IFAC-PapersOnLine},
volume = {52},
number = {24},
pages = {47-52},
year = {2019},
note = {5th IFAC Symposium on Telematics Applications TA 2019},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2019.12.379},
url = {https://www.sciencedirect.com/science/article/pii/S2405896319322797},
author = {Cao Lijia and Tang Yu and Zhang Guo},
keywords = {unmanned aerial vehicle, adaptive observer, radial basis function neural network, fault-detection, fault-tolerant control},
abstract = {A robust adaptive observer combined with radial basis function neural network (RBFNN) is designed for the unmanned aerial vehicles (UAVs) fault-detection system is proposed in this paper. Firstly, the fault dynamics model with unknown disturbance of the unmanned aerial vehicle’s attitude system is established, and a robust adaptive observer combined with radial basis function neural network is designed for the vehicle’s fault-detection, then, the detected fault combined with a robust controller is applied to design the fault-tolerant controller. In the end, the stability and effective of the fault detection and tolerant system is proved by Lyapunov theory and simulation.}
}
@article{CHEN2021102913,
title = {Automated crack segmentation in close-range building façade inspection images using deep learning techniques},
journal = {Journal of Building Engineering},
volume = {43},
pages = {102913},
year = {2021},
issn = {2352-7102},
doi = {https://doi.org/10.1016/j.jobe.2021.102913},
url = {https://www.sciencedirect.com/science/article/pii/S2352710221007713},
author = {Kaiwen Chen and Georg Reichard and Xin Xu and Abiola Akanmu},
keywords = {Facade cracks, UAV-Images, CNN, UNet, Classification, Segmentation},
abstract = {Nowadays, unmanned aerial vehicles (UAVs) are frequently used for periodic visual inspection of building envelopes to detect unsafe conditions or vulnerable damages. Inspection practitioners have to manually examine the large amounts of high-resolution images collected by UAVs to identify anomalies or damages on building facades for reporting and repairs. The computer vision and deep learning technologies have emerged as promising solutions to automate the image-based inspection process. However, for the detection of façade cracks from UAV-captured images, existing deep learning solutions may not perform well due to the complicated background noises caused by different façade components and materials. Towards that end, this paper proposed a two-step deep learning method for the automated detection of façade cracks from UAV-captured images. In the first step, a convolutional neural network (CNN) model was designed and trained on 26,177 images to classify images in a patch-level size of 128 × 128 pixels into crack or non-crack. In the second step, a U-Net neural network model was trained on 2870 image sets to segment crack pixels within those patches classified as cracks. Experimental results show a high performance of 94% and 96% precision, 94% and 95% recall, and 94% and 96% F1-scores was achieved by the CNN model and the U-Net model respectively. The experimental results proved that the two-step method can improve the reliability and efficiency of detecting and differentiating façade cracks from complicated façade noises. The proposed method can also be extended to detect other types of façade anomalies (e.g., corrosion and joint failures), thus facilitating a comprehensive assessment of façade conditions for better decision-making for the maintenance of building facades during its service life.}
}
@article{KIEU202132,
title = {Remote sensing of coastal hydro-environment with portable unmanned aerial vehicles (pUAVs) a state-of-the-art review},
journal = {Journal of Hydro-environment Research},
volume = {37},
pages = {32-45},
year = {2021},
issn = {1570-6443},
doi = {https://doi.org/10.1016/j.jher.2021.04.003},
url = {https://www.sciencedirect.com/science/article/pii/S1570644321000289},
author = {Hieu Trung Kieu and Adrian Wing-Keung Law},
keywords = {UAV, Remote sensing, Coastal monitoring, Multispectral, Hyperspectral},
abstract = {Urbanization together with climate change is imposing growing stresses on the sustainable development of major coastal cities around the world, particularly in developing countries. Thus, the need for regular monitoring of coastal water quality is becoming increasingly vital, and remote sensing is deemed to be a viable approach particularly due to its cost-effectiveness. Over the past two decades, remote sensing using satellite imaging has already been adopted in various tasks related to the monitoring of coastal hydro-enviro nment, including the detection of oil spills, identification of turbid plumes, mapping of marine ecosystems, etc. Despite their usefulness, space-borne sensors are subjected to constraints such as low spatial resolution, clouds and atmospheric interference, sparse frequency, and inflexible scheduling. Recently, remote sensing with portable Unmanned Aerial Vehicles (pUAVs) is emerging as a promising alternative for high spatial-resolution monitoring of coastal hydro-environment, with the key advantages that they can minimize the effects of atmospheric disruptions and be implemented with a frequent schedule to perform on-demand monitoring. In addition, with the technological advances in the sensor's design, UAVs are now capable of capturing data with fine spectral resolutions, ranging from several (multispectral) to hundreds (hyperspectral) of spectral bands. Data analytic is also improving rapidly with the advancement in artificial intelligence (AI) and deep learning algorithms. In this paper, we present a systematic review of the recent developments in the utilization of UAV-based remote sensing for the sustainable development of the coastal hydro-environment, particularly with pUAVs. The key technical issues, including the design of UAV systems and the processing of data, are examined for specific applications. Future prospects for implementation are also discussed.}
}
@article{SIERRAGARCIA2021450,
title = {Switched learning adaptive neuro-control strategy},
journal = {Neurocomputing},
volume = {452},
pages = {450-464},
year = {2021},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2019.12.139},
url = {https://www.sciencedirect.com/science/article/pii/S0925231220316507},
author = {J. Enrique Sierra-García and Matilde Santos},
keywords = {Neuro-control, Adaptive control, Disturbance rejection, Online learning, Neural networks, Unmanned aerial vehicle (UAV)},
abstract = {The generalized learning algorithm can be efficiently used as control strategy, but it has some drawbacks such as: sensitivity to the training dataset, poor robustness against changes in the system, difficulty to generate the control signals without destabilising the plant, tuning of the controller, etc. To overcome some of these issues, in this work a new switched neural adaptive control strategy is proposed. It is based on the combination of an adaptive artificial neural network, a PID regulator, an estimated inverse model of the plant and two switches to route the signals properly in the control scheme. The technique is described using the hybrid automata formalism. In order to test the validity of this proposal, it is applied to the control of a quadrotor unmanned aerial vehicle (UAV), subjected to changes in its mass and wind disturbances. Simulation results show how the on-line learning increases the robustness of the controller, reducing the effects of the mass change and of the wind on the UAV stabilization, thus improving the UAV trajectory tracking.}
}
@article{TIAN2021292,
title = {A dual neural network for object detection in UAV images},
journal = {Neurocomputing},
volume = {443},
pages = {292-301},
year = {2021},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2021.03.016},
url = {https://www.sciencedirect.com/science/article/pii/S0925231221003660},
author = {Gangyi Tian and Jianran Liu and Wenyuan Yang},
keywords = {Machine learning, Deep learning, Object detection, UAV, Dual neural network detection},
abstract = {Computer vision analysis in Unmanned Aerial Vehicle (UAV) represents a major trend in the future development. Object detection in UAV images is one of the important techonlogies to analyze scene information. However, the UAV image includes small and dense targets, which easily leads to errors of missed detection. In this paper, we propose a dual neural network review method, which quickly screens the missed targets in the one-stage detection by classifying the secondary features of the suspected target regions, so as to achieve high quality detection of small targets. Firstly, the one-stage detector recognizes UAV images, and the result with confidence greater than or equal to the threshold is detected as the target. The result less than the threshold are considered as suspected areas containing missed targets. Secondly, the feature map of UAV image is extracted by VGG backbone. The feature map and the location information of the suspected areas are combined to secondary identification. Then, the features of the dual network are late fusion, and the re-identified results guide the initial confidence addition. After the addition, regions with confidence greater than the threshold are considered as targets. Finally, we synthesize the targets of initial detection and secondary identification to obtain the final detection results. Experimental results show that our method achieves breakthrough performance on VisDrone, UAVDT and MS COCO datasets.}
}
@article{KERKECH2020105446,
title = {Vine disease detection in UAV multispectral images using optimized image registration and deep learning segmentation approach},
journal = {Computers and Electronics in Agriculture},
volume = {174},
pages = {105446},
year = {2020},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2020.105446},
url = {https://www.sciencedirect.com/science/article/pii/S016816991932558X},
author = {Mohamed Kerkech and Adel Hafiane and Raphael Canals},
keywords = {Unmanned aerial vehicle (UAV), Image registration, Convolutional neural network, Precision agriculture, Disease mapping},
abstract = {One of the major goals of tomorrow’s agriculture is to increase agricultural productivity but above all the quality of production while significantly reducing the use of inputs. Meeting this goal is a real scientific and technological challenge. Smart farming is among the promising approaches that can lead to interesting solutions for vineyard management and reduce the environmental impact. Automatic vine disease detection can increase efficiency and flexibility in managing vineyard crops, while reducing the chemical inputs. This is needed today more than ever, as the use of pesticides is coming under increasing scrutiny and control. The goal is to map diseased areas in the vineyard for fast and precise treatment, thus guaranteeing the maintenance of a healthy state of the vine which is very important for yield management. To tackle this problem, a method is proposed here for Mildew disease detection in vine field using a deep learning segmentation approach on Unmanned Aerial Vehicle (UAV) images. The method is based on the combination of the visible and infrared images obtained from two different sensors. A new image registration method was developed to align visible and infrared images, enabling fusion of the information from the two sensors. A fully convolutional neural network approach uses this information to classify each pixel according to different instances, namely, shadow, ground, healthy and symptom. The proposed method achieved more than 92% of detection at grapevine-level and 87%at leaf level, showing promising perspectives for computer aided disease detection in vineyards.}
}
@article{LV2021108366,
title = {Beyond 5G for digital twins of UAVs},
journal = {Computer Networks},
volume = {197},
pages = {108366},
year = {2021},
issn = {1389-1286},
doi = {https://doi.org/10.1016/j.comnet.2021.108366},
url = {https://www.sciencedirect.com/science/article/pii/S1389128621003534},
author = {Zhihan Lv and Dongliang Chen and Hailing Feng and Ranran Lou and Huihui Wang},
keywords = {Unmanned aerial vehicle, B5G, Deep learning, Coordinated multi-point transmission, Physical layer security, Digital twins},
abstract = {The purpose is to explore the application effects and limitations of Unmanned Aerial Vehicle (UAV) in 5G/B5G (Beyond 5G) mobile and wireless communication. Based on 5Gcommunication, the deep learning (DL) algorithm is introduced to construct the UAV Digital Twins (DTs) communication channel model based on DL. The Coordinated Multi-point Transmission (COMP) technology is adopted to study the interference suppression of UAVs. The key algorithm in the physical layer security is employed to ensure information communication security. Finally, the model constructed is simulated and analyzed. The transmission error rates and transmission estimation accuracy of several algorithms, including the proposed algorithm and ordinary Deep Neural Networks (DNNs), are compared under different Signal-to-Noise Ratios (SNRs). Results find that the convergence speed and convergence effect of the proposed algorithm has prominent advantages, presenting strong robustness; the proposed algorithm's estimation accuracy is about 150 times higher than the traditional algorithms. Further analysis reveals that the proposed algorithm's accuracy reaches 82.39%, which increases by at least 3.2% than other classic machine algorithms. The indicators of Precision, Recall, and F1 are compared as well. Apparently, the Precision, Recall, and F1 values of the proposed algorithm are the highest, while the transmission delay is the smallest. Therefore, the constructed UAV DTs wireless communication channel model has strong robustness and further reduces UAV limitations, providing a reference for improving UAV system performance in the later stage.}
}
@article{NDONG2022,
title = {Towards a 3-tiered space-air-ground network with reinforcement learning},
journal = {Journal of King Saud University - Computer and Information Sciences},
year = {2022},
issn = {1319-1578},
doi = {https://doi.org/10.1016/j.jksuci.2022.03.025},
url = {https://www.sciencedirect.com/science/article/pii/S1319157822001094},
author = {Massa Ndong and Mohammad Hayajneh and Najah Abu Ali and Shayma Alkobaisi},
keywords = {SAGIN, Massive MIMO, Reinforcement Learning, UAV, Energy efficiency, Spectral Efficiency},
abstract = {A Space-Air-Ground Integrated Network (SAGIN) is a novel networking concept that integrates satellite networks, aerial networks and terrestrial networks as a 3-tiered network. It is developed as an adaptable computing and traffic model in the present decade. In addition to various benefits, there are some unprecedented challenges in SAGIN, and reliability is one among them. The wireless communication network requires stable communication between Unmanned Aerial Vehicles (UAVs) and Unmanned Ground Vehicles (UGVs). For ensuring reliable communication links, Massive Multiple-Input Multiple-Output (MaMIMO) is used with the deployed aerial vehicles, and the mobility of UGVs can be controlled by UAV, providing device-to-device (D2D) communication between vehicular nodes, with that no interruption can occur. This work involves developing a 3-Tier D2D Architecture, comprised of network links UGVs, network links UAVs, and the combined model of both and also links of the satellite groups at lower orbits. The UAV senses the environment and transmits the data to its operator for appropriate decision-making. This work focuses on incorporating D2D communications in SAGIN for ensuring reliability via Reinforcement Learning (RL) based on Markov process. We derive the optimal numbers of transmitting nodes used for communication links, represent the Markov State transition and provide the Bellman equation for our model. The main objective is to maximize Energy Efficiency (EE), under the limitations of Spectral Efficiency (SE). Performance evaluations are employed to assess reliability over the links in the corresponding proposed architecture. The simulation results with water-filling optimization show that the proposed model achieves enhanced EE and SE per D2D link.}
}
@article{KERKECH2018237,
title = {Deep leaning approach with colorimetric spaces and vegetation indices for vine diseases detection in UAV images},
journal = {Computers and Electronics in Agriculture},
volume = {155},
pages = {237-243},
year = {2018},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2018.10.006},
url = {https://www.sciencedirect.com/science/article/pii/S0168169918310044},
author = {Mohamed Kerkech and Adel Hafiane and Raphael Canals},
keywords = {Deep learning, CNN, UAV, Image processing, Color spaces, Vegetation indices, Precision agriculture},
abstract = {Detection of symptoms in grape leaves is a very important factor in preventing a serious disease. An epidemic spread in vineyards has huge economic consequences and therefore it is considered a major challenge for viticulture. Automatic detection of vine diseases can play an important role in addressing the issue of diseases management. This study deals with the problem of identifying infected areas of grapevines using Unmanned Aerial Vehicles (UAV) images in the visible domain. In this paper we propose a method based on Convolutional neural network (CNN) and color information to detect symptoms in the vine yards. We studied and compared performances of CNNs using different color spaces, vegetation indices, as well as the combination of both information. The obtained results showed that CNNs with YUV color space combined with ExGR vegetation index, and CNNs with a combination of ExG, ExR, ExGR vegetation indices yield the best results with accuracy more than 95.8%.}
}
@article{PANDEY2022106543,
title = {An intelligent system for crop identification and classification from UAV images using conjugated dense convolutional neural network},
journal = {Computers and Electronics in Agriculture},
volume = {192},
pages = {106543},
year = {2022},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2021.106543},
url = {https://www.sciencedirect.com/science/article/pii/S0168169921005603},
author = {Akshay Pandey and Kamal Jain},
keywords = {Conjugated Dense Convolutional Neural Network (CD-CNN), Crop identification, Image classification, SL-ReLU activation function (AF), Unmanned Aerial Vehicle (UAV)},
abstract = {Crop identification and classification is an important aspect for modern agricultural sector. With development of unmanned aerial vehicle (UAV) systems, crop identification from RGB images is experiencing a paradigm shift from conventional image processing techniques to deep learning strategies because of successful breakthrough in convolutional neural networks (CNNs). UAV images are quite trustworthy to identify different crops due to its higher spatial resolution. For precision agriculture crop identification is the primal criteria. Identifying a specific type of crop in a land is essential for performing proper farming and that also helps to estimate the net yield production of a particular crop. Previous works are limited to identify a single crop from the RGB images captured by UAVs and have not explored the chance of multi-crop classification by implementing deep learning techniques. Multi crop identification tool is highly needed as designing separate tool for each type of crop is a cumbersome job, but if a tool can successfully differentiate multiple crops then that will be helpful for the agro experts. In contrast with the previous existing techniques, this article elucidates a new conjugated dense CNN (CD-CNN) architecture with a new activation function named SL-ReLU for intelligent classification of multiple crops from RGB images captured by UAV. CD-CNN integrates data fusion and feature map extraction in conjunction with classification process. Initially a dense block architecture is proposed with a new activation function, called SL-ReLU, associated with the convolution operation to mitigate the chance of unbounded convolved output and gradient explosion. Dense block architecture concatenates all the previous layer features for determining the new features. This reduces the chance of losing important features due to deepening of the CNN module. Later, two dense blocks are conjugated with the help of a conversion block for obtaining better performance. Unlike traditional CNN, CD-CNN omits the use of fully connected layer and that reduces the chance of feature loss due to random weight initialization. The proposed CD-CNN achieves a strong distinguishing capability from several classes of crops. Raw UAV images of five different crops are captured from different parts of India and then small candidate crop regions are extracted from the raw images with the help of Arc GIS 10.3.1 software and then the candidate regions are fed to CD-CNN for proper training purpose. Experimental results show that the proposed module can achieve an accuracy of 96.2% for the concerned data. Further, superiority of the proposed network is established after comparing with other machine learning techniques viz. RF-200 and SVM, and standard CNN architectures viz. AlexNet, VGG-16, VGG-19 and ResNet-50.}
}
@article{HE2021107052,
title = {Explainable Deep Reinforcement Learning for UAV autonomous path planning},
journal = {Aerospace Science and Technology},
volume = {118},
pages = {107052},
year = {2021},
issn = {1270-9638},
doi = {https://doi.org/10.1016/j.ast.2021.107052},
url = {https://www.sciencedirect.com/science/article/pii/S1270963821005629},
author = {Lei He and Nabil Aouf and Bifeng Song},
keywords = {Unmanned Aerial Vehicles (UAVs), Autonomous navigation, Deep Reinforcement Learning (DRL), Explainable AI},
abstract = {Autonomous navigation in unknown environment is still a hard problem for small Unmanned Aerial Vehicles (UAVs). Recently, some neural network-based methods are proposed to tackle this problem, however, the trained network is opaque, non-intuitive and difficult for people to understand, which limits the real-world application. In this paper, a novel explainable deep neural network-based path planner is proposed for quadrotor to fly autonomously in unknown environment. The navigation problem is modelled as a Markov Decision Process (MDP) and the path planner is trained using Deep Reinforcement Learning (DRL) method in simulation environment. To get better understanding of the trained model, a novel model explanation method is proposed based on the feature attribution. Some easy-to-interpret textual and visual explanations are generated to allow end-users to understand what triggered a particular behaviour. Moreover, some global analyses are provided for experts to evaluate and improve the trained network. Finally, real-world flight tests are conducted to illustrate that our path planner trained in the simulation is robust enough to be applied in the real environment directly.}
}
@article{QU2020106099,
title = {A novel reinforcement learning based grey wolf optimizer algorithm for unmanned aerial vehicles (UAVs) path planning},
journal = {Applied Soft Computing},
volume = {89},
pages = {106099},
year = {2020},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2020.106099},
url = {https://www.sciencedirect.com/science/article/pii/S1568494620300399},
author = {Chengzhi Qu and Wendong Gai and Maiying Zhong and Jing Zhang},
keywords = {Unmanned aerial vehicles (UAVs), Three-dimensional path planning, Reinforcement learning, Grey wolf optimizer},
abstract = {Unmanned aerial vehicles (UAVs) have been used in wide range of areas, and a high-quality path planning method is needed for UAVs to satisfy their applications. However, many algorithms reported in the literature may not feasible or efficient, especially in the face of three-dimensional complex flight environment. In this paper, a novel reinforcement learning based grey wolf optimizer algorithm called RLGWO has been presented for solving this problem. In the proposed algorithm, the reinforcement learning is inserted that the individual is controlled to switch operations adaptively according to the accumulated performance. Considering that the proposed algorithm is designed to serve for UAVs path planning, four operations have been introduced for each individual: exploration, exploitation, geometric adjustment, and optimal adjustment. In addition, the cubic B-spline curve is used to smooth the generated flight route and make the planning path be suitable for the UAVs. The simulation experimental results show that the RLGWO algorithm can acquire a feasible and effective route successfully in complicated environment.}
}
@article{ZHANG2020555,
title = {Coarse-to-fine object detection in unmanned aerial vehicle imagery using lightweight convolutional neural network and deep motion saliency},
journal = {Neurocomputing},
volume = {398},
pages = {555-565},
year = {2020},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2019.03.102},
url = {https://www.sciencedirect.com/science/article/pii/S0925231219310422},
author = {Jing Zhang and Xi Liang and Meng Wang and Liheng Yang and Li Zhuo},
keywords = {Unmanned aerial vehicle (UAV) imagery, Object detection, Coarse-to-fine, Lightweight convolutional neural network (CNN), Deep motion saliency},
abstract = {Unmanned aerial vehicles (UAVs) have been widely applied to various fields, facing mass imagery data, object detection in UAV imagery is under extensive research for its significant status in both theoretical study and practical applications. In order to achieve the accurate object detection in UAV imagery on the premise of real-time processing, a coarse-to-fine object detection method for UAV imagery using lightweight convolutional neural network (CNN) and deep motion saliency is proposed in this paper. The proposed method includes three steps: (1) Key frame extraction using image similarity measurement is performed on the UAV imagery to accelerate the successive object detection procedure; (2) Deep features are extracted by PeleeNet, a lightweight CNN, to achieve the coarse object detection on the key frames; (3) LiteFlowNet and objects prior knowledge is utilized to analyze the deep motion saliency map, which further helps to refine the detection results. The detection results on key frames propagate to the temporally nearest non-key frames to achieve the fine detection. Five experiments are conducted to verify the effectiveness of the proposed method on Stanford drone dataset (SDD). The experimental results demonstrate that the proposed method can achieve comparable detection speed but superior accuracy to six state-of-the-art methods.}
}
@article{LYABAKH2021594,
title = {Improvement of Mathematical Tools for Controlling the Group of Unmanned Aerial Vehicles},
journal = {Transportation Research Procedia},
volume = {54},
pages = {594-601},
year = {2021},
note = {International Scientific Siberian Transport Forum - TransSiberia 2020},
issn = {2352-1465},
doi = {https://doi.org/10.1016/j.trpro.2021.02.111},
url = {https://www.sciencedirect.com/science/article/pii/S2352146521002854},
author = {Nikolay Lyabakh and Maksim Kolesnikov and Maksim Bakalov},
keywords = {Territory Connectivity, Unmanned Aerial Vehicles, Artificial Intelligence},
abstract = {The task of controlling unmanned aerial vehicles to solve the problems of territorial connectivity is updated. A complex of interrelated problems of organizing a joint flight of a group of aircrafts is formulated. A mathematical toolkit for calculating the control of an unmanned aerial vehicle that allows solving the problems of both the joint safe synchronous functioning of a group of aircrafts and their individual flight has been developed. To expand the intellectual capabilities of the designed technical system and to ensure human communication with it in natural language as well, it is proposed to use the apparatus of the theory of fuzzy sets that formalizes the operation with linguistic variables and fuzzy concepts. For immersion of flying objects into physical space the concepts of "friend", "foe" are introduced. Using the theory of pattern recognition, the mechanism of identification and operational response of aircrafts to various non-standard and force majeure situations is revealed. The concept of "traffic rules" for aircrafts is introduced and the meaning of their formation and use in airspace is revealed. The possibilities of using game theory for solving conflict situations are analyzed. The place of the catastrophe theory in mathematical description of the processes of aircrafts interaction with each other and with "nature" is indicated. The totality of flying vehicles is considered from the perspective of the theory of multi-agent systems and the theory of active systems that forms emergent (ant, swarm) intelligence in their environment.}
}
@article{KHAN201946,
title = {Unmanned Aerial Vehicle in the Machine Learning Environment},
journal = {Procedia Computer Science},
volume = {160},
pages = {46-53},
year = {2019},
note = {The 10th International Conference on Emerging Ubiquitous Systems and Pervasive Networks (EUSPN-2019) / The 9th International Conference on Current and Future Trends of Information and Communication Technologies in Healthcare (ICTH-2019) / Affiliated Workshops},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2019.09.442},
url = {https://www.sciencedirect.com/science/article/pii/S1877050919316576},
author = {Asharul Islam Khan and Yaseen Al-Mulla},
keywords = {unmanned aerial vehicle, drone, machine learning, deep learning, object detection, pattern recognition, neural network},
abstract = {Unmanned Aerial Vehicles and machine learning have started gaining attentions of academic and industrial research. The Unmanned Aerial Vehicles have extended the freedom to operate and monitor the activities from remote locations. This study retrieved and synthesized research on the use of Unmanned Aerial Vehicles along with machine learning and its algorithms in different areas and regions. The objective was to synthesize the scope and importance of machine learning models in enhancing Unmanned Aerial Vehicles capabilities, solutions to problems, and numerous application areas. The machine learning implementation has reduced numbers of challenges to Unmanned Aerial Vehicles besides enhancing the capabilities and opening the door to the different sectors. The Unmanned Aerial Vehicles and machine learning association has resulted in fast and reliable outputs. The combination of Unmanned Aerial Vehicles and machine learning has helped in real time monitoring, data collection and processing, and prediction in the computer/wireless networks, smart cities, military, agriculture, and mining.}
}
@article{DENG2022108054,
title = {Research on edge intelligent recognition method oriented to transmission line insulator fault detection},
journal = {International Journal of Electrical Power & Energy Systems},
volume = {139},
pages = {108054},
year = {2022},
issn = {0142-0615},
doi = {https://doi.org/10.1016/j.ijepes.2022.108054},
url = {https://www.sciencedirect.com/science/article/pii/S0142061522000965},
author = {Fangming Deng and Zhongxin Xie and Wei Mao and Bing Li and Yun Shan and Baoquan Wei and Han Zeng},
keywords = {Insulator self-explosion, Deep learning, MEC, Deep neural network, Partition strategy},
abstract = {Aiming at the problem of high delay in the existing centralized cloud insulator fault detection methods, an insulator self-explosion fault detection scheme integrating mobile edge computing(MEC) and deep learning is proposed in this paper. In order to run the deep neural network on the edge devices with limited computing resources, the lightweight network MobilieNetv3 is replaced by the backbone network CSPDarknet53 of YOLOv4, which can effectively reduce the network parameters. The model detection speed and generalization ability are further improved by improving the activation function of MobilieNetv3 network and the loss function of YOLOv4. In addition, in order to meet the real-time requirements of insulator fault detection and maximize the utilization of UAV (Unmanned Aerial Vehicle) computing resources, a deep neural network partition algorithm based on binary particle swarm optimization is proposed. The algorithm realizes the division of the optimal partition points of deep neural network under the constraints of UAV energy consumption and system delay. The experimental results show that the edge intelligent recognition method can realize the terminal level recognition of insulator self explosion. The detection accuracy of the proposed object detection algorithm can reach 94.5% and the detection speed is 58.5 frames/s. At the same time, the deep neural network partition algorithm proposed in this paper has a significant effect on reducing UAV energy consumption, system cost and network delay.}
}
@article{MENG2021102403,
title = {Investigation and evaluation of algorithms for unmanned aerial vehicle multispectral image registration},
journal = {International Journal of Applied Earth Observation and Geoinformation},
volume = {102},
pages = {102403},
year = {2021},
issn = {0303-2434},
doi = {https://doi.org/10.1016/j.jag.2021.102403},
url = {https://www.sciencedirect.com/science/article/pii/S0303243421001100},
author = {Lingxuan Meng and Ji Zhou and Shaomin Liu and Lirong Ding and Jirong Zhang and Shaofei Wang and Tianjie Lei},
keywords = {Homography estimation, Structural similarity, Multispectral image registration, UAV remote sensing},
abstract = {Automatically registration of unmanned aerial vehicle (UAV) multispectral images is fundamental for subsequent applications. Although many studies exist for visible camera images and satellite multispectral image registration, studies for UAV are still rare. Under this context, this study firstly evaluates the performance of several widely used traditional methods (i.e., SIFT, SURF, ORB, and CFOG) for visible camera and satellite images in UAV multispectral image registration. This study further proposes an unsupervised and end-to-end deep learning network (i.e., DSIM) for multispectral image registration. An evident feature of DSIM is to regress the homography parameters with convolutional neural networks and to use the pyramid structural similarity loss to optimize the network. 1200 groups of UAV multispectral images acquired over three different sites in four months are used to comprehensively test the aforementioned five methods. Results show that CFOG achieves the highest correct matching rate in the test set, followed by DSIM and SIFT. Nevertheless, DSIM is more robust in images with weak or repeated texture than CFOG and SIFT. In addition, performance of CFOG and SIFT is closely related to the number of the found matching points. Based on the findings, we propose a multi-method ensemble strategy to combine CFOG, DSIM, and SIFT according to the number of the found matching points. This strategy outperforms the individual methods with a correct matching rate of 96.2%. Lower correct matching rate of CFOG + SIFT confirms that DSIM and traditional methods are very complementary in UAV multispectral image registrations.}
}
@article{LIU2022108400,
title = {A residual convolutional neural network based approach for real-time path planning},
journal = {Knowledge-Based Systems},
volume = {242},
pages = {108400},
year = {2022},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2022.108400},
url = {https://www.sciencedirect.com/science/article/pii/S0950705122001629},
author = {Yang Liu and Zheng Zheng and Fangyun Qin and Xiaoyi Zhang and Haonan Yao},
keywords = {Unmanned aerial vehicles, Path planning, Real-time, Deep learning, Convolution neural network},
abstract = {Path planning for unmanned aerial vehicles (UAVs) has been widely considered in various tasks. Existing path planning algorithms, such as A* and Jump Point Search, have been proposed and achieved good performance in the static mode, that is, assuming the global environmental information is known and planning is conducted offline. However, in practice, only limited environmental information can be obtained by sensors, which requires a real-time path planning ability. This paper proposes a residual convolutional neural network based approach, denoted as Res-Planner, to address the real-time path planning problem of a UAV. Specifically, the approach generates various scenarios and paths by executing the conventional path planning algorithms in static mode, from which it collects state-behaviour demonstrations to train the proper behaviour in real-time path planning. The experimental results show that our approach can provide feasible paths with approximately the global optimal under limited environmental information conditions.}
}
@article{WANG2021101365,
title = {An adaptive deep learning-based UAV receiver design for coded MIMO with correlated noise},
journal = {Physical Communication},
volume = {47},
pages = {101365},
year = {2021},
issn = {1874-4907},
doi = {https://doi.org/10.1016/j.phycom.2021.101365},
url = {https://www.sciencedirect.com/science/article/pii/S1874490721001026},
author = {Zizhi Wang and Wenqi Zhou and Lunyuan Chen and Fasheng Zhou and Fusheng Zhu and Liseng Fan},
keywords = {UAV, MIMO, Correlated noise, Deep learning, CRC},
abstract = {In this paper, we propose an adaptive deep learning-based unmanned aerial vehicle (UAV) receiver design for coded multiple-input multiple-output (MIMO) systems, where the noise in the systems presents some correlation among time domain, which deteriorates the system transmission performance severely. To improve the system performance, we employ the linear convolutional code at the transmitter, and then propose an adaptive deep learning based iterative UAV receiver. The iterative UAV receiver contains three parts: the detector such as zero-forcing (ZF) or minimum mean square error (MMSE) detector, the deep convolutional neural network (DCNN) which can help suppress the noise by capturing the correlation characteristics among noise, and the decoder such as Viterbi decoding. In particular, the cyclic redundancy check (CRC) appended to the code can help control the iteration of the detection, DCNN and decoding, which leads to an adaptive implementation of receiver. Simulation results demonstrate that the proposed UAV receiver can achieve a much better bit error rate (BER) performance over conventional receivers with a reduced computational complexity.}
}
@article{NAVEENVENKATESH2022110786,
title = {Machine vision based fault diagnosis of photovoltaic modules using lazy learning approach},
journal = {Measurement},
volume = {191},
pages = {110786},
year = {2022},
issn = {0263-2241},
doi = {https://doi.org/10.1016/j.measurement.2022.110786},
url = {https://www.sciencedirect.com/science/article/pii/S0263224122000860},
author = {S {Naveen Venkatesh} and V Sugumaran},
keywords = {Fault diagnosis, Photovoltaic modules, Locally weighted learning, Convolutional neural networks, K-star classifier, Nearest neighbor, K-nearest neighbor},
abstract = {Machine Vision is an advanced and powerful imaging based technique that has been applied in various fields like robotics, inspection and process control. Machine vision, in industrial terms, is termed as a subcategory of computer vision. The primary aim of the proposed study is to distinguish various visual fault conditions that hinder the performance and life span of photovoltaic (PV) modules using computer vision and a machine learning approach. Literatures state that thermographic and electroluminescence images were used in deep learning for identifying faults in photovoltaic modules. However, the effectiveness of normal RGB images with the fusion of deep learning and machine learning techniques is less explored. This paper deals with the classification of normal RGB images of PV modules acquired using a fusion of deep learning and machine learning techniques. Visual faults like delamination, snail trail, burn marks, glass breakage and discoloration that occur in a photovoltaic module (PVM) were considered in the study. A machine learning approach was used to handle this problem which contains three stages: (i) feature extraction, (ii) feature selection and (iii) feature classification. Initially, the features from the aerial images of PVM (acquired from unmanned aerial vehicles (UAVs) equipped with digital cameras) were extracted using convolutional neural networks (CNN). Secondly, J48 decision tree algorithm was employed to select the features of utmost significance and dominance from the extracted image features. Finally, a set of lazy classifiers like locally weighted learning (LWL), K-star algorithm (KS), nearest neighbor (NN) and k-nearest neighbor (kNN) were adopted to execute the classification task on the selected image features. The classification accuracies of all the aforementioned classifiers were compared and it was found that the k-nearest neighbor classifier achieved a maximum accuracy of 98.95% with a lesser computational time of 0.04 s.}
}
@article{PAN2021105843,
title = {Beach wrack mapping using unmanned aerial vehicles for coastal environmental management},
journal = {Ocean & Coastal Management},
volume = {213},
pages = {105843},
year = {2021},
issn = {0964-5691},
doi = {https://doi.org/10.1016/j.ocecoaman.2021.105843},
url = {https://www.sciencedirect.com/science/article/pii/S0964569121003264},
author = {Yaoru Pan and Mogens Flindt and Peter Schneider-Kamp and Marianne Holmer},
keywords = {Beach wrack, Unmanned aerial vehicles, Object-based image analysis, Blue carbon ecosystems, Environmental management},
abstract = {As a common phenomenon along the global coastline, beach wrack, which is part of the blue carbon ecosystems (BCEs), has significant ecological values. However, the excessive accumulation of beach wrack can be a nuisance for local residents and tourism. Meanwhile, beach wrack can become a source of greenhouse gas due to the decomposition. Hence, effective monitoring of beach wrack has become a priority for coastal environmental management. As a cost- and labor-saving approach, unmanned aerial vehicles (UAVs) can perform customized flight tasks and achieve aerial images with sub-decimeter spatial resolution. This study investigated the feasibility of using UAVs to map wrack on three different types of beaches. The method of object-based image analysis (OBIA) was applied to classify the aerial images. Three typical machine learning methods, K-Nearest Neighbor (KNN), Support Vector Machine (SVM), and Random Forests (RF), were examined with different feature spaces at several segmentation levels. The results showed that the three machine learning methods performed well with the overall classification accuracy >75%. The tested algorithm, SVM with only RGB as feature space at the segmentation scale 50, was geographically transferable to beaches with different characteristics. This study demonstrated that UAVs can be developed as an applicable tool for beach wrack mapping and monitoring, which will help to better explore the role of beach wrack in BCEs and assist the local municipalities in environmental management of the coastal zone.}
}
@article{ZHANG2022e01999,
title = {A non-destructive method for rapid acquisition of grassland aboveground biomass for satellite ground verification using UAV RGB images},
journal = {Global Ecology and Conservation},
volume = {33},
pages = {e01999},
year = {2022},
issn = {2351-9894},
doi = {https://doi.org/10.1016/j.gecco.2022.e01999},
url = {https://www.sciencedirect.com/science/article/pii/S2351989422000014},
author = {Huifang Zhang and Zhonggang Tang and Binyao Wang and Baoping Meng and Yu Qin and Yi Sun and Yanyan Lv and Jianguo Zhang and Shuhua Yi},
keywords = {Grassland, Unmanned aerial vehicle, Aboveground biomass, Random forest, Vegetation, RGB image},
abstract = {Remote sensing has become an indispensable method for estimating the regional-scale collection of grassland aboveground biomass (AGB). However, the lack of ground verification samples often reduces the inversion accuracy. This paper aimed to find a non-destructive method to quickly obtain grassland AGB at quadrat-scale through unmanned aerial vehicles (UAVs) in a large area. Thus, we proposed and assessed the vertical and horizontal indices from UAV RGB images as predictors of grassland AGB using the random forest (RF) machine learning technique. By comparing the performance of different indices combinations, we found that the model combing the horizontal and vertical indices (RFVH) performed best (R2 = 0.78; RMSE = 24.80 g/m2), followed by the model using only horizontal indices (the RFH model; R2 =0.73; RMSE =26.54 g/m2), and the last was the model using only the vertical index. However, the RFVH model was unsuitable for collecting AGB samples in a large area because the UAVs with RGB cameras failed to obtain vegetation height information in areas with high vegetation coverage. In conclusion, the RFH model can be used to replace the traditional destructive method for collecting ground data over large regions for AGB satellite inversion.}
}
@article{JIAO20191300,
title = {A new approach to oil spill detection that combines deep learning with unmanned aerial vehicles},
journal = {Computers & Industrial Engineering},
volume = {135},
pages = {1300-1311},
year = {2019},
issn = {0360-8352},
doi = {https://doi.org/10.1016/j.cie.2018.11.008},
url = {https://www.sciencedirect.com/science/article/pii/S0360835218305485},
author = {Zeyu Jiao and Guozhu Jia and Yingjie Cai},
keywords = {Oil spill, Unmanned aerial vehicle, Deep convolutional neural network, Otsu algorithm, Maximally stable extremal regions, Intelligent control},
abstract = {This study presents a novel approach to automatic oil spill detection, using unmanned aerial vehicle (UAV) images to realize intelligent control in oil production. Despite considerable effort, oil spills still cannot be detected automatically and effectively due to the complexity of the real production environment, which forces oil enterprises to manually inspect facilities and detect oil spills. To solve the problem, we propose an approach consisting of UAVs, deep learning and traditional algorithms—an approach which divides the oil spill detection task into three independent sub-tasks. First, we constructed a model based on the deep convolutional neural network, which can quickly detect the suspected oil spill area in images to ensure there are no omissions. Second, to remove other obstacles in the images, we adjusted the Otsu algorithm to filter the detection results, which improves precision while not affecting the recall rate. Third, the Maximally Stable Extremal Regions algorithm was used to obtain the detail polygon region from the detection box, thus automatically evaluating the severity of the oil spill. Experiments showed that our method could solve problems effectively, reducing the cost of oil spill detection by 57.2% when compared with the traditional manual inspection process.}
}
@article{CHEN2021108249,
title = {Deep Q-Network based resource allocation for UAV-assisted Ultra-Dense Networks},
journal = {Computer Networks},
volume = {196},
pages = {108249},
year = {2021},
issn = {1389-1286},
doi = {https://doi.org/10.1016/j.comnet.2021.108249},
url = {https://www.sciencedirect.com/science/article/pii/S138912862100284X},
author = {Xin Chen and Xu Liu and Ying Chen and Libo Jiao and Geyong Min},
keywords = {Ultra-Dense Networks (UDN), Unmanned Aerial Vehicles (UAV), Resource allocation, Markov Decision Process (MDP), Deep Q-Network (DQN)},
abstract = {With the rapid development of the fifth-generation (5G) wireless communications, the number of users is increasing dramatically and Ultra-Dense Networks (UDN) are becoming more important for supporting numerous users and emerging mission-critical applications. In order to conquer the communication restrictions caused by natural disasters, an emergency communication system using Unmanned Aerial Vehicles (UAV) as a flying base station (BS) to assist UDN is proposed. By virtue of the resource allocation scheme of UAV-assisted UDN systems, communication resources can be reasonably and effectively allocated to improve the quality of user experience. Firstly, aiming to maximize the system energy efficiency (EE), a UDN system model including the BS selection is constructed. Secondly, Markov Decision Process (MDP) theory is applied to transform the system model into a stochastic optimization problem. Finally, by using deep reinforcement learning (DRL) technique, we propose a Deep Q-Network (DQN) based resource allocation scheme to maximize the system energy efficiency. Simulation results exhibit that the proposed DQN-based resource allocation scheme can significantly improve the system EE compared with the legacy Q-Learning, random and maximum resource allocation algorithms.}
}
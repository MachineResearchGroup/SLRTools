@inbook{10.1145/3394171.3413934,
author = {Mandal, Murari and Kumar, Lav Kush and Vipparthi, Santosh Kumar},
title = {MOR-UAV: A Benchmark Dataset and Baselines for Moving Object Recognition in UAV Videos},
year = {2020},
isbn = {9781450379885},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3394171.3413934},
abstract = {Visual data collected from Unmanned Aerial Vehicles (UAVs) has opened a new frontier of computer vision that requires automated analysis of aerial images/videos. However, the existing UAV datasets primarily focus on object detection. An object detector does not differentiate between the moving and non-moving objects. Given a real-time UAV video stream, how can we both localize and classify the moving objects, i.e. perform moving object recognition (MOR) The MOR is one of the essential tasks to support various UAV vision-based applications including aerial surveillance, search and rescue, event recognition, urban and rural scene understanding.To the best of our knowledge, no labeled dataset is available for MOR evaluation in UAV videos. Therefore, in this paper, we introduce MOR-UAV, a large-scale video dataset for MOR in aerial videos. We achieve this by labeling axis-aligned bounding boxes for moving objects which requires less computational resources than producing pixel-level estimates. We annotate 89,783 moving object instances collected from 30 UAV videos, consisting of 10,948 frames in various scenarios such as weather conditions, occlusion, changing flying altitude and multiple camera views. We assigned the labels for two categories of vehicles (car and heavy vehicle). Furthermore, we propose a deep unified framework MOR-UAVNet for MOR in UAV videos. Since, this is a first attempt for MOR in UAV videos, we present 16 baseline results based on the proposed framework over the MOR-UAV dataset through quantitative and qualitative experiments. We also analyze the motion-salient regions in the network through multiple layer visualizations. The MOR-UAVNet works online at inference as it requires only few past frames. Moreover, it doesn't require predefined target initialization from user. Experiments also demonstrate that the MOR-UAV dataset is quite challenging.},
booktitle = {Proceedings of the 28th ACM International Conference on Multimedia},
pages = {2626–2635},
numpages = {10}
}

@article{10.1145/3510027,
author = {Mukherjee, Arijit and Mondal, Jayeeta and Dey, Swarnava},
title = {Accelerated Fire Detection and Localization at Edge},
year = {2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1539-9087},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3510027},
doi = {10.1145/3510027},
abstract = {Fire-related incidents continue to be reported as a leading cause of life and property destruction. Automated fire detection and localization (AFDL) systems have grown in importance with the evolution of applied robotics, especially because use of robots in disaster situations can lead to avoidance of human fatality. The importance of AFDL on resource-constrained devices has further grown, as most unmanned vehicles (drones or ground vehicles) are battery operated with limited computational capacity, the disaster situations cannot guarantee uninterrupted communication with high end resources in the cloud, and yet faster response time is a prime necessity. Traditional computer-vision based techniques require hand-engineered features on a case-by-case basis. Deep Learning-based classifiers perform well for fire/no-fire classification due to the availability of large datasets for training, however, a dearth of good fire localization datasets renders the localization performance below par. We have tried to address both problems with a multi-task learned cascaded model that triggers localization workflow only if the presence of fire is detected, through a strong classifier trained on available large fire datasets. This presents only fire images to a relatively weaker localization model, reducing false positives, false negatives, and thereby improving overall AFDL accuracy. The multi-task learning (MTL) approach for end-to-end training of a stitched classifier and object localizer model on diverse datasets enabled us to build a strong fire classifier and feature extractor. It also resulted in a single unified model, capable of running on “on-board” compute infrastructure without compromising on accuracy. To achieve the target inference rate for the AFDL deployment, we have investigated the effect of quantization and compression due to hardware acceleration on an MTL model. This paper presents an approach to automate the hardware-software co-design to find the optimum parameter partitioning for a given MTL problem, especially when some parts of the model are hardware accelerated. We present combined evaluation results showing that our methodology and the corresponding AFDL model strikes a balance between the frames inferred per second and several accuracy metrics. We report fire localization accuracy in terms of mean average precision (object detection), that is not done earlier for embedded AFDL systems.},
note = {Just Accepted},
journal = {ACM Trans. Embed. Comput. Syst.},
month = {dec},
keywords = {neural networks, fire detection, UAV, on-board processing, drone, localization}
}

@inproceedings{10.1145/3349801.3349809,
author = {Plastiras, George and Kyrkou, Christos and Theocharides, Theocharis},
title = {EdgeNet: Balancing Accuracy and Performance for Edge-Based Convolutional Neural Network Object Detectors},
year = {2019},
isbn = {9781450371896},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3349801.3349809},
doi = {10.1145/3349801.3349809},
abstract = {Visual intelligence at the edge is becoming a growing necessity for low latency applications and situations where real-time decision is vital. Object detection, the first step in visual data analytics, has enjoyed significant improvements in terms of state-of-the-art accuracy due to the emergence of Convolutional Neural Networks (CNNs) and Deep Learning. However, such complex paradigms intrude increasing computational demands and hence prevent their deployment on resource-constrained devices. In this work, we propose a hierarchical framework that enables to detect objects in high-resolution video frames, and maintain the accuracy of state-of-the-art CNN-based object detectors while outperforming existing works in terms of processing speed when targeting a low-power embedded processor using an intelligent data reduction mechanism. Moreover, a use-case for pedestrian detection from Unmanned-Areal-Vehicle (UAV) is presented showing the impact that the proposed approach has on sensitivity, average processing time and power consumption when is implemented on different platforms. Using the proposed selection process our framework manages to reduce the processed data by 100x leading to under 4W power consumption on different edge devices.},
booktitle = {Proceedings of the 13th International Conference on Distributed Smart Cameras},
articleno = {8},
numpages = {6},
keywords = {Aerial Cameras, Convolutional Neural Networks, Object Detection, Pedestrian Detection},
location = {Trento, Italy},
series = {ICDSC 2019}
}

@inproceedings{10.1145/3243394.3243692,
author = {Plastiras, George and Kyrkou, Christos and Theocharides, Theocharis},
title = {Efficient ConvNet-Based Object Detection for Unmanned Aerial Vehicles by Selective Tile Processing},
year = {2018},
isbn = {9781450365116},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3243394.3243692},
doi = {10.1145/3243394.3243692},
abstract = {Many applications utilizing Unmanned Aerial Vehicles (UAVs) require the use of computer vision algorithms to analyze the information captured from their on-board camera. Recent advances in deep learning have made it possible to use single-shot Convolutional Neural Network (CNN) detection algorithms that process the input image to detect various objects of interest. To keep the computational demands low these neural networks typically operate on small image sizes which, however, makes it difficult to detect small objects. This is further emphasized when considering UAVs equipped with cameras where due to the viewing range, objects tend to appear relatively small. This paper therefore, explores the trade-offs involved when maintaining the resolution of the objects of interest by extracting smaller patches (tiles) from the larger input image and processing them using a neural network. Specifically, we introduce an attention mechanism to focus on detecting objects only in some of the tiles and a memory mechanism to keep track of information for tiles that are not processed. Through the analysis of different methods and experiments we show that by carefully selecting which tiles to process we can considerably improve the detection accuracy while maintaining comparable performance to CNNs that resize and process a single image which makes the proposed approach suitable for UAV applications.},
booktitle = {Proceedings of the 12th International Conference on Distributed Smart Cameras},
articleno = {3},
numpages = {6},
keywords = {Convolutional Neural Networks, Aerial Cameras, Pedestrian Detection, Object Detection},
location = {Eindhoven, Netherlands},
series = {ICDSC '18}
}

@article{10.1145/3360050,
author = {Grigorev, Aleksei and Liu, Shaohui and Tian, Zhihong and Xiong, Jianxin and Rho, Seungmin and Feng, Jiang},
title = {Delving Deeper in Drone-Based Person Re-Id by Employing Deep Decision Forest and Attributes Fusion},
year = {2020},
issue_date = {January 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {16},
number = {1s},
issn = {1551-6857},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3360050},
doi = {10.1145/3360050},
abstract = {Deep learning has revolutionized the field of computer vision and image processing. Its ability to extract the compact image representation has taken the person re-identification (re-id) problem to a new level. However, in most cases, researchers are focused on developing new approaches to extract more fruitful image representation and use it in the re-id task. The extra information about images is rarely taken into account because the traditional person re-id datasets usually do not have it. Nevertheless, the research in multimodal machine learning has demonstrated that the utilization of the information from different sources leads to better performance. In this work, we demonstrate how a person re-id problem can benefit from the utilization of multimodal data. We have used the UAV drone to collect and label the new person re-id dataset, which is composed of pedestrian images and its attributes. We have manually annotated this dataset with attributes, and in contrast to the recent research, we do not use the deep network to classify them. Instead, we employ the continuous bag-of-words model to extract the word embeddings from text descriptions and fuse it with features extracted from images. Then the deep neural decision forest is used for pedestrians classification. The extensive experiments on the collected dataset demonstrate the effectiveness of the proposed model.},
journal = {ACM Trans. Multimedia Comput. Commun. Appl.},
month = {apr},
articleno = {25},
numpages = {15},
keywords = {CBOW, neural decision forest, re-id, neural networks, word2vec, attributes, Datasets, drones}
}

@inproceedings{10.1145/3503047.3503070,
author = {Cai, Zhongxuan and Chang, Xuefeng and Li, Minglong},
title = {A Cost-Efficient Platform Design for Distributed UAV Swarm Research},
year = {2021},
isbn = {9781450385862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3503047.3503070},
doi = {10.1145/3503047.3503070},
abstract = {Unmanned Aerial Vehicles (UAVs) have been attracting more and more attention in research and education. Specifically, Swarm intelligence is a promising future technology of UAVs and the frontier of multi-agent system research. It has the characteristics of low individual cost, strong system flexibility and robustness, and has great potential in many tasks. However, due to the constraints of research conditions and cost, most of the current researches on large-scale swarm UAVs are carried out in the simulation environment. Building a low-cost open-source software and hardware platform for swarm UAVs is an important basis for promoting researches on swarm UAVs and multi-agent systems. In this paper, we propose a design of a UAV platform with common cost-efficient hardware and a rich open-source software ecosystem, and provide a software solution for swarm robots based on the open-source robot operating system ROS. These software packages support the rapid programming development of swarm behaviors and different communication topology. Experiments have been conducted for typical UAV tasks like flocking and formation, indicating the effectiveness of the proposed platform.},
booktitle = {2021 3rd International Conference on Advanced Information Science and System (AISS 2021)},
articleno = {22},
numpages = {6},
keywords = {UAV platform for research, UAV hardware and software, Unmanned aerial vehicles},
location = {Sanya, China},
series = {AISS 2021}
}

@inproceedings{10.1145/3480651.3480655,
author = {Zhao, Zhihao and Dao, Ronggui and Zhang, Haitao and Zhang, Fanwei and Zeng, Jianfeng and Chen, Chao},
title = {Method of Physical Inventory Checking on Cigarette Stereoscopic Warehouse Based on UAV},
year = {2021},
isbn = {9781450390392},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3480651.3480655},
doi = {10.1145/3480651.3480655},
abstract = {The elevated warehouse is the initial place of the cigarette end-product. It is an important link between the workshop and the delivery of cigarette. It undertakes large storage tasks of cigarette end-product in the limited space. The traditional manual inventory is difficult because of the large tunnel depth, high building height and dense distribution of goods. Based on the actual situation of the elevated warehouse of cigarette products, by learning the inventory management technology of advanced enterprises outside the tobacco industry, combined with the guidelines and policies of the tobacco industry, applying artificial intelligence technology, this paper puts forward a scheme of UAV inventory of cigarette end-product.},
booktitle = {2021 3rd International Conference on Pattern Recognition and Intelligent Systems},
pages = {15–19},
numpages = {5},
keywords = {cigarette, UAV, machine vision, inventory checking, stereoscopic warehouse},
location = {Bangkok, Thailand},
series = {PRIS 2021}
}

@inproceedings{10.1145/3456415.3456424,
author = {Zhang, Bingbing and Qian, Xiaojun and Yang, Rui and Xu, Zhen},
title = {Water Surface Target Detection Based on Improved YOLOv3 in UAV Images},
year = {2021},
isbn = {9781450389174},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3456415.3456424},
doi = {10.1145/3456415.3456424},
abstract = {In order to better manage and protect rivers and lakes, the most important requirement is to find the objects on the surface of rivers and lakes in time. Generally, image segmentation and target detection are used to detect water surface targets. The former is sensitive to the selection of target features, with poor generalization ability and slow detection speed. The latter has not yet been applied to surface target detection in UAV images. In view of this situation, this paper proposes a target detection model based on YOLOv3, which is used to detect surface targets in UAV images. In order to verify the performance of the model, the images collected in this paper include five types of surface targets. These images are then enhanced by rotation transform, brightness transform and mirror transform, and the enhanced images are used to generate data sets. In the YOLOv3 model, we use the inception module for multi-scale depth features to process the deep features of the network. The module can activate the multi-scale sensing field of the deep features, so as to fully utilize the deep features and improve the detection accuracy of small and medium targets in the UAV image. In addition, we optimize the loss function to train the network better. The experimental results show that the mAP of the proposed Yolov3-inception is 81%, the detection speed is 23 frames per second, and the overall performance is better than YOLOv3, Faster RCNN and SSD. Therefore, this method is suitable for surface target detection in UAV images.},
booktitle = {2021 9th International Conference on Communications and Broadband Networking},
pages = {47–53},
numpages = {7},
keywords = {image enhancement, deep learning, target detection, UAV images, YOLOv3},
location = {Shanghai, China},
series = {ICCBN 2021}
}

@inproceedings{10.1145/3444950.3444951,
author = {Corradi, Federico and Adriaans, Guido and Stuijk, Sander},
title = {Gyro: A Digital Spiking Neural Network Architecture for Multi-Sensory Data Analytics},
year = {2021},
isbn = {9781450389525},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3444950.3444951},
doi = {10.1145/3444950.3444951},
abstract = { Unmanned Aerial Vehicles (UAVs) that interact with the physical world in real-time make use of a multitude of sensors and often execute deep neural network workloads for perceiving the state of the environment. To increase UAV’s operations, it is required to execute these workloads in the most power-efficient manner. Spiking Neural Networks (SNNs) have been proposed as an alternative solution for the execution of deep neural networks in an energy-efficient way. We introduce Gyro, a digital event-driven architecture capable of executing spiking neural networks. The architecture is tailored towards sensory fusion applications and it is optimized for Field-Programmable Gate Arrays (FPGAs). In hardware, we demonstrate the performance of a sensory fusion task using a public dataset of bi-temporal optical-radar data for pixel-wise crop classification. We achieve an accuracy of 99,7%, a peak throughput of 31,82 Giga Synaptic Operations per Second (GSOPS) while consuming 50 pico Joule / Synaptic Operation (pJ/SO). },
booktitle = {Proceedings of the 2021 Drone Systems Engineering and Rapid Simulation and Performance Evaluation: Methods and Tools Proceedings},
pages = {9–15},
numpages = {7},
keywords = {fpga, embedded hardware, remote sensing, spiking neural networks, optical-radar sensory fusion},
location = {Budapest, Hungary},
series = {DroneSE and RAPIDO '21}
}

@inproceedings{10.1145/3503047.3503067,
author = {Cai, Zhongxuan and Li, Minglong},
title = {A Robust and Learning Approach for Multi-Phase Aerial Search with UAVs},
year = {2021},
isbn = {9781450385862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3503047.3503067},
doi = {10.1145/3503047.3503067},
abstract = {Unmanned aerial vehicles (UAVs) have been attracting more and more attention in the research and industry field. Aerial search is a common mission and is intrinsically fit for UAVs, e.g. disaster rescue, remote sensing and environmental monitoring. With the improvement of UAV hardware and software, UAVs tend to achieve better autonomy and accomplish more complex tasks. However, current UAV aerial search is usually hardcoded, which limits their adaptability, autonomy and robustness in realistic scenarios. In this paper, we propose to address this problem by leveraging reinforcement learning (RL) and a recent control architecture, behavior trees (BTs). We develop robust and adaptive UAV systems that can automatically conduct multi-phase complex aerial search, including search, communication and refueling. Experimental results in a 3D robot simulator verify the effectiveness and robustness of the proposed approach, which achieves better performance than the baseline.},
booktitle = {2021 3rd International Conference on Advanced Information Science and System (AISS 2021)},
articleno = {19},
numpages = {5},
keywords = {reinforcement learning, behavior trees, aerial search, Unmanned aerial vehicles},
location = {Sanya, China},
series = {AISS 2021}
}

@inproceedings{10.1145/3220228.3220242,
author = {Hru\v{s}ka, Jon\'{a}\v{s} and Ad\~{a}o, Telmo and P\'{a}dua, Lu\'{\i}s and Marques, Pedro and Cunha, Ant\'{o}nio and Peres, Emanuel and Sousa, Ant\'{o}nio and Morais, Raul and Sousa, Joaquim J.},
title = {Machine Learning Classification Methods in Hyperspectral Data Processing for Agricultural Applications},
year = {2018},
isbn = {9781450364454},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3220228.3220242},
doi = {10.1145/3220228.3220242},
abstract = {In agricultural applications hyperspectral imaging is used in cases where differences in spectral reflectance of the examined objects are small. However, the large amount of data generated by hyperspectral sensors requires advance processing methods. Machine learning approaches may play an important role in this task. They are known for decades, but they need high volume of data to compute accurate results. Until recently, the availability of hyperspectral data was a big drawback. It was first used in satellites, later in manned aircrafts and data availability from those platforms was limited because of logistics complexity and high price. Nowadays, hyperspectral sensors are available for unmanned aerial vehicles, which enabled to reach a high volume of data, thus overcoming these issues. This way, the aim of this paper is to present the status of the usage of machine learning approaches in the hyperspectral data processing, with a focus on agriculture applications. Nevertheless, there are not many studies available applying machine learning approach to hyperspectral data for agricultural applications. This apparent limitation was in fact the inspiration for making this survey. Preliminary results using UAV-based data are presented, showing the suitability of machine learning techniques in remote sensed data.},
booktitle = {Proceedings of the International Conference on Geoinformatics and Data Analysis},
pages = {137–141},
numpages = {5},
keywords = {machine learning, remote sensing, deep learning, agriculture, hyperspectral data},
location = {Prague, Czech Republic},
series = {ICGDA '18}
}

@inproceedings{10.1145/3289602.3293915,
author = {Chen, Yao and He, Jiong and Zhang, Xiaofan and Hao, Cong and Chen, Deming},
title = {Cloud-DNN: An Open Framework for Mapping DNN Models to Cloud FPGAs},
year = {2019},
isbn = {9781450361378},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3289602.3293915},
doi = {10.1145/3289602.3293915},
abstract = {The efficacy and effectiveness of Convolutional Neural Networks (CNNs) have been proven in a wide range of machine learning applications. However, the high computational complexity of CNNs presents a critical challenge towards their broader adoption in real-time and power-efficient scenarios. FPGAs are poised to take a significant role for high-performance and energy-efficient computation of CNNs for both mobile (e.g., UAVs, self-driving cars, and IoT devices) and cloud computing domains. However, implementing an effective CNN system onto FPGAs efficiently remains problematic. The current cloud-based FPGAs with unique design constraints and architectural characteristics further increase the challenges. To address these challenges, we propose a novel open-source automated tool chain called Cloud-DNN. Our tool chain takes trained CNN models specified in Caffe as input, performs a set of transformations, and maps the model to a cloud-based FPGA. Cloud-DNN can significantly improve the overall design productivity of CNNs on FPGAs while satisfying the emergent computational requirements. Our design provides an alternative solution compared to other cloud-based options (e.g., GPUs or TPUs) while offering flexible, and high performance DNN inferences. The unique features of Cloud-DNN include the optimizations with cloud-platform characteristics and the support of easier and streamlined implementation. Experimental results demonstrate up to 104.55x performance improvement when compared to CPU implementation and comparable usability, flexibility, and strong quality compared to other state-of-the-art DNN inference implementations on standalone FPGAs.},
booktitle = {Proceedings of the 2019 ACM/SIGDA International Symposium on Field-Programmable Gate Arrays},
pages = {73–82},
numpages = {10},
keywords = {cloud computing, reconfiguration, neural network, high-level synthesis, dnn accelerator, fpga},
location = {Seaside, CA, USA},
series = {FPGA '19}
}

@article{10.1145/3308897.3308964,
author = {Li, Rui and Zhang, Chaoyun and Patras, Paul and Stanica, Razvan and Valois, Fabrice},
title = {Learning Driven Mobility Control of Airborne Base Stations in Emergency Networks},
year = {2019},
issue_date = {December 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {46},
number = {3},
issn = {0163-5999},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3308897.3308964},
doi = {10.1145/3308897.3308964},
abstract = {Mobile base stations mounted on unmanned aerial vehicles (UAVs) provide viable wireless coverage solutions in challenging landscapes and conditions, where cellular/WiFi infrastructure is unavailable. Operating multiple such airborne base stations, to ensure reliable user connectivity, demands intelligent control of UAV movements, as poor signal strength and user outage can be catastrophic to mission critical scenarios. In this paper, we propose a deep reinforcement learning based solution to tackle the challenges of base stations mobility control. We design an Asynchronous Advantage Actor-Critic (A3C) algorithm that employs a custom reward function, which incorporates SINR and outage events information, and seeks to provide mobile user coverage with the highest possible signal quality. Preliminary results reveal that our solution converges after 4\texttimes{}105 steps of training, after which it outperforms a benchmark gradientbased alternative, as we attain 5dB higher median SINR during an entire test mission of 10,000 steps.},
journal = {SIGMETRICS Perform. Eval. Rev.},
month = {jan},
pages = {163–166},
numpages = {4},
keywords = {ai in networks, mobility control, emergency networks, deep reinforcement learning, airborne base stations}
}

@inproceedings{10.1145/3443467.3443805,
author = {Lv, XiaoLi and Ni, HongXia},
title = {Smart Fault Detection and Monitoring of Power Line by Drones},
year = {2020},
isbn = {9781450387811},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3443467.3443805},
doi = {10.1145/3443467.3443805},
abstract = {In this paper, we introduce a novel automatic power line inspection system based on automatic vision. This system uses UAV inspection as the main inspection method, optical images as the main data source, and deep learning as the backbone of data analysis. To facilitate the implementation of the system, we solve three major challenges of deep learning in vision-based power line inspection: (i) lack of training data; (ii) class imbalance; (iii) detection of small parts and faults. First, we create four medium-sized datasets for training component detection and classification models. Next, we apply a series of effective data enhancement techniques to balance the unbalanced classes. Finally, we propose a multi-stage component detection and classification method based on a single-shot multi-box detector and a deep residual network to detect small components and faults. The results show that the proposed system can quickly and accurately detect common failures of power line components, including the lack of a top cover, cracks on the rod and cross arm, woodpecker damage to the rod, and rot on the cross arm. Field tests show that our system has broad prospects in the Smart monitoring and inspection of power line components and the valuable addition of smart grids.},
booktitle = {Proceedings of the 2020 4th International Conference on Electronic Information Technology and Computer Engineering},
pages = {501–505},
numpages = {5},
keywords = {smart grids, Smart monitoring, deep learning, power line inspection, Drones, vision-based power line inspection},
location = {Xiamen, China},
series = {EITCE 2020}
}

@article{10.5555/3144645.3144674,
author = {Sedaghat-Pisheh, Hani and Rivera, Amaury Rodr\'{\i}guez and Biaz, Saad and Chapman, Richard},
title = {Collision Avoidance Algorithms for Unmanned Aerial Vehicles Using Computer Vision},
year = {2017},
issue_date = {December 2017},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {33},
number = {2},
issn = {1937-4771},
abstract = {We present a computer-vision-based approach to enable unmanned aerial vehicles (UAVs) to avoid collisions. To detect a moving obstacle, a machine learning algorithm, cascade classification, is used. Next, to track the obstacle, the camshift algorithm is implemented. These algorithms determine the coordinates of center of an object moving towards the UAV. Finally, to determine the distance of the object to the UAV, a stereo camera is used. Once an object is successfully tracked, the UAV will execute avoidance maneuvers if the path of the moving object conflicts with the UAV's path.},
journal = {J. Comput. Sci. Coll.},
month = {dec},
pages = {191–197},
numpages = {7}
}

@inproceedings{10.1145/3503047.3503063,
author = {Liu, Qinghe and Tian, Yinghong},
title = {An Improved GAIL Based on Object Detection, GRU, and Attention},
year = {2021},
isbn = {9781450385862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3503047.3503063},
doi = {10.1145/3503047.3503063},
abstract = {Imitation Learning (IL) learns expert behavior without any reinforcement signal. Thus, it is seen as a potential alternative to Reinforcement Learning (RL) in tasks where it is not easy to design reward functions. However, most models based on IL methods cannot work well when the demonstration is high dimension, and the tasks are complex. We set one realistic-like UAV race simulation environment on AirSim Drone Racing Lab (ADRL) to study the two problems. We propose a new model improves on Generative Adversarial Imitation Learning (GAIL). An object detection network trained by the expert dataset allows the model to use high-dimensional visual inputs while alleviating the data inefficiencies of GAIL. Benefit from the recurrent structure and attention mechanism, the model can control the drone cross the gates and complete the race as if it were an expert. Compared to the primitive GAIL structure, our improved structure showed a 70.6% improvement in average successful crossing over 2000 flight training sessions. The average missed crossing decreased by 18.8% and the average collision decreased by 14.1%.},
booktitle = {2021 3rd International Conference on Advanced Information Science and System (AISS 2021)},
articleno = {16},
numpages = {8},
keywords = {imitation learning, generative adversarial imitation learning, autonomous flight simulation, attention},
location = {Sanya, China},
series = {AISS 2021}
}

@inproceedings{10.1145/3396864.3399705,
author = {Qu, Chengyi and Morel, Alicia Esquivel and Dahlquist, Drew and Calyam, Prasad},
title = {DroneNet-Sim: A Learning-Based Trace Simulation Framework for Control Networking in Drone Video Analytics},
year = {2020},
isbn = {9781450380102},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3396864.3399705},
doi = {10.1145/3396864.3399705},
abstract = {Unmanned Aerial Vehicles (UAVs) or drones equipped with cameras are extensively used in different applications for environmental situational awareness such as: smart agriculture, border security, intelligent transportation. Realistic UAV testbed building for developing novel network control algorithms relating to video streaming/analytics is time-consuming and difficult. Challenges arise when executing high-scale drone video analytics experiments due to: constraints in drone manufacturing, government regulation restrictions, and limited energy resources. Also, developing algorithms requires ability to understand impact of network protocol selection to handle diverse UAV mobility models as well as dynamic network status during edge-network video processing. In this paper, we propose a novel learning-based trace simulation framework viz. "DroneNet-Sim" that integrates simulation on both drone and networking sides. It allows for experimentation with network protocol selection (i.e., TCP/HTTP, UDP/RTP, QUIC) and video properties selection (i.e., codec, resolution) to ensure satisfactory video quality delivery in different drone flight scenarios. Using machine learning models, we show how DroneNet-Sim can process real-world drone traces that include various mobility models, geospatial link information and on-time network status obtained from real-world data-gathering efforts. Trace-based experiments with our DroneNet-Sim shows how video quality delivery (i.e., PSNR) using suitable control networking matches real-world measurements in terms of machine learning model accuracy.},
booktitle = {Proceedings of the 6th ACM Workshop on Micro Aerial Vehicle Networks, Systems, and Applications},
articleno = {8},
numpages = {6},
keywords = {trace-based simulation, machine learning, drone video analytics, networking protocols},
location = {Toronto, Ontario, Canada},
series = {DroNet '20}
}

@inproceedings{10.1145/3384544.3384599,
author = {Aoki, Risako and Oki, Takuro and Miyamoto, Ryusuke},
title = {Accuracy Improvement of Human Tracking in Aerial Images Using Error Correction Based on Color Information},
year = {2020},
isbn = {9781450376655},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3384544.3384599},
doi = {10.1145/3384544.3384599},
abstract = {The authors are trying to construct a real-time vital sensing system during exercise where humans wearing sensor nodes move quickly and their density becomes sometimes higher. In this case, existing multi-hop networking using RSSI or GPS to gather vital signs exercisers may not work appropriately. To solve this problem, the authors are proposing image-assisted routing (shortly IAR) that estimates the locations of sensor nodes by image processing. This paper proposes a tracking scheme with error correction based on color information, which is indispensable for IAR. Experimental results using actual images taken from a UAV showed that the proposed scheme achieved accurate tracking using only simple operations without sophisticated state estimation and computationally exhaustive deep learning: MT reached 100% by the proposed scheme.},
booktitle = {Proceedings of the 2020 9th International Conference on Software and Computer Applications},
pages = {124–128},
numpages = {5},
keywords = {Error Correction, color Information, Visual Object Tracking, Simple Computation},
location = {Langkawi, Malaysia},
series = {ICSCA 2020}
}

@inproceedings{10.1145/3395260.3395263,
author = {Zhang, Sheng and Li, Jie and Yang, Chengwei and Yang, Yu and Hu, Xiaolin},
title = {Vision-Based UAV Positioning Method Assisted by Relative Attitude Classification},
year = {2020},
isbn = {9781450377072},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3395260.3395263},
doi = {10.1145/3395260.3395263},
abstract = {When the Unmanned Aerial Vehicle(UAV) is flying in formation, the common communication method is radio frequency(RF) communication. However, in practical applications, the way of RF communication is susceptible to interference from other factors such as electromagnetism. Therefore, in order to improve the anti-interference of the UAV cluster flight, it's necessary to use a positioning method which is based on visual information. Based on the above analysis, this paper proposes a vision-based UAV positioning method assisted by attitude classification. Firstly, the problem of solving the relative attitude of the UAV is transformed into a classification problem by the object recognition method, and a preliminary classification of the relative attitude of the friendly UAV is realized. Based on the principle of camera calibration, the pixel size and coordinates of the target UAV can be transform to the body coordinate system. Since the camera and the carrier UAV are fixedly connected, when the latitude and longitude coordinates of the carrier UAV are known, relative coordinate conversion can be performed to calculate the coordinates of the target UAV in the world coordinate system. Realize the positioning task of the target UAV. Simulation results are performed on the proposed method of the UAV relative attitude recognition accuracy exceeds 90%, and the average error in the distance simulation system of 2.56%. The final coordinate positioning accuracy exceeds 90% without losing the target.},
booktitle = {Proceedings of the 2020 5th International Conference on Mathematics and Artificial Intelligence},
pages = {154–160},
numpages = {7},
keywords = {relative attitude recognition, deep-learning, Computer-visual, target positioning, UAV formation, fixed-wing UAV},
location = {Chengdu, China},
series = {ICMAI 2020}
}

@inproceedings{10.1145/3377930.3389843,
author = {Qiu, Huanneng and Garratt, Matthew and Howard, David and Anavatti, Sreenatha},
title = {Towards Crossing the Reality Gap with Evolved Plastic Neurocontrollers},
year = {2020},
isbn = {9781450371285},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3377930.3389843},
doi = {10.1145/3377930.3389843},
abstract = {A critical issue in evolutionary robotics is the transfer of controllers learned in simulation to reality. This is especially the case for small Unmanned Aerial Vehicles (UAVs), as the platforms are highly dynamic and susceptible to breakage. Previous approaches often require simulation models with a high level of accuracy, otherwise significant errors may arise when the well-designed controller is being deployed onto the targeted platform. Here we try to overcome the transfer problem from a different perspective, by designing a spiking neurocontroller which uses synaptic plasticity to cross the reality gap via online adaptation. Through a set of experiments we show that the evolved plastic spiking controller can maintain its functionality by self-adapting to model changes that take place after evolutionary training, and consequently exhibit better performance than its non-plastic counterpart.},
booktitle = {Proceedings of the 2020 Genetic and Evolutionary Computation Conference},
pages = {130–138},
numpages = {9},
keywords = {evolutionary robotics, UAV control, spiking neural networks, neuroevolution, hebbian plasticity},
location = {Canc\'{u}n, Mexico},
series = {GECCO '20}
}

@inproceedings{10.1145/3414045.3415941,
author = {Wazid, Mohammad and Bera, Basudeb and Mitra, Ankush and Das, Ashok Kumar and Ali, Rashid},
title = {Private Blockchain-Envisioned Security Framework for AI-Enabled IoT-Based Drone-Aided Healthcare Services},
year = {2020},
isbn = {9781450381055},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3414045.3415941},
doi = {10.1145/3414045.3415941},
abstract = {Internet of Drones (IoD) architecture is designed to support a co-ordinated access for the airspace using the unmanned aerial vehicles (UAVs) known as drones. Recently, IoD communication environment is extremely useful for various applications in our daily activities. Artificial intelligence (AI)-enabled Internet of Things (IoT)-based drone-aided healthcare service is a specialized environment which can be used for different types of tasks, for instance, blood and urine samples collections, medicine delivery and for the delivery of other medical needs including the current pandemic of COVID-19. Due to wireless nature of communication among the deployed drones and their ground station server, several attacks (for example, replay, man-in-the-middle, impersonation and privileged-insider attacks) can be easily mounted by malicious attackers. To protect such attacks, the deployment of effective authentication, access control and key management schemes are extremely important in the IoD environment. Furthermore, combining the blockchain mechanism with deployed authentication make it more robust against various types of attacks. To mitigate such issues, we propose a private-blockchain based framework for secure communication in an IoT-enabled drone-aided healthcare environment. The blockchain-based simulation of the proposed framework has been carried out to measure its impact on various performance parameters.},
booktitle = {Proceedings of the 2nd ACM MobiCom Workshop on Drone Assisted Wireless Communications for 5G and Beyond},
pages = {37–42},
numpages = {6},
keywords = {healthcare, privacy, internet of drones (IoD), security, authentication, blockchain},
location = {London, United Kingdom},
series = {DroneCom '20}
}

@article{10.1109/TNET.2020.2970744,
author = {Zhong, Xijian and Guo, Yan and Li, Ning and Chen, Yancheng},
title = {Joint Optimization of Relay Deployment, Channel Allocation, and Relay Assignment for UAVs-Aided D2D Networks},
year = {2020},
issue_date = {April 2020},
publisher = {IEEE Press},
volume = {28},
number = {2},
issn = {1063-6692},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1109/TNET.2020.2970744},
doi = {10.1109/TNET.2020.2970744},
abstract = {Unmanned aerial vehicles (UAVs) can be deployed in the air to provide high probabilities of line of sight (LoS) transmission, thus UAVs bring much gain for wireless communication systems. In this paper, we study a UAVs-aided self-organized device-to-device (D2D) network. Relay deployment, channel allocation and relay assignment are jointly optimized, aiming to maximize the capacity of the relay network. On account of the coupled relationship between the three optimization variables, an alternating optimization approach is proposed to solve this problem. The original problem is divided into two sub-problems. The first one is that of optimizing the channel allocation and relay assignment with fixed relay deployment. Considering without central controller, a reinforcement learning algorithm is proposed to solve this sub-problem. The second sub-problem is that of optimizing the relay deployment with fixed channel allocation and relay assignment. Assuming no knowledge of channel model and exact positions of the communication nodes, an online learning algorithm based on real-time capacity is proposed to solve this sub-problem. By solving the two sub-problems alternately and iteratively, the original problem is finally solved. Simulation results show that the UAVs-aided D2D network can achieve a high capacity via the joint optimization of relay deployment, channel allocation, and relay assignment.},
journal = {IEEE/ACM Trans. Netw.},
month = {apr},
pages = {804–817},
numpages = {14}
}

@inproceedings{10.1145/3341568.3342109,
author = {Callegaro, Davide and Baidya, Sabur and Levorato, Marco},
title = {A Measurement Study on Edge Computing for Autonomous UAVs},
year = {2019},
isbn = {9781450368797},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3341568.3342109},
doi = {10.1145/3341568.3342109},
abstract = {The ability to execute complex signal processing and machine learning tasks in real-time is the core of autonomy. In airborne devices such as Unmanned Aerial Vehicles (UAV), the hardware limitations imposed by the weight constraint make the continuous execution of these algorithms challenging. Edge and fog computing can mitigate such limitations and boost the system and mission-level performance of the UAVs. However, due to the UAVs motion characteristics and complex dynamics of urban environments, the performance of pipelines using interconnected, rather than onboard, resources can quickly degrade. Motivated by the development of Hydra, an architecture for the establishment of flexible sensing-analysis-control pipelines over autonomous airborne systems, this paper reports a preliminary measurement study on the performance of computing task offloading on available network technologies in this class of applications and systems.},
booktitle = {Proceedings of the ACM SIGCOMM 2019 Workshop on Mobile AirGround Edge Computing, Systems, Networks, and Applications},
pages = {29–35},
numpages = {7},
keywords = {Object detection, Wireless networks, Edge computing, Unmanned Aerial Vehicles},
location = {Beijing, China},
series = {MAGESys'19}
}

@inproceedings{10.1145/3501409.3501663,
author = {Hu, Yendo and Wu, Yiliang and Bai, Xue and Chen, Minghong and Guanglei, Zhuo and Shi, Zhipeng},
title = {A Low-Latency Control Path Design for Cloud Based Micro-Drones},
year = {2021},
isbn = {9781450384322},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3501409.3501663},
doi = {10.1145/3501409.3501663},
abstract = {Dynamic real-time control through a remote network is becoming a reality, given the drive of the latest generation of wireless networks. As cloud computing takes on an even stronger role in the industry, the desire to offload time critical processes into the network becomes a possibility. With the combination of cloud edge processing centers, and the UUL standardization for sub-millisecond delay over 5G networks, applications requiring dynamic time critical closed loop control is now an option. With the support of cloud edge processors, advanced complex analysis and processing algorithms, such deep learning engines or video-based approaches, miniature drones can achieve higher levels of capability without the weight or cost requirements. In this paper, we present wireless closed loop control system. The proposed framework is composed of a controller, drone flight receiver and motor control. The delay time from the issuance of the control command to the start of the execution of the control command is only about 4 ms. The proposed solution has been implemented and verified on the research UAV data link system.},
booktitle = {Proceedings of the 2021 5th International Conference on Electronic Information Technology and Computer Engineering},
pages = {1430–1435},
numpages = {6},
keywords = {low-latency path, Micro-drone control},
location = {Xiamen, China},
series = {EITCE 2021}
}

@inproceedings{10.1145/3377049.3377052,
author = {Gomes, Dipta and Saif, A. F. M. Saifuddin and Nandi, Dip},
title = {Robust Underwater Object Detection with Autonomous Underwater Vehicle: A Comprehensive Study},
year = {2020},
isbn = {9781450377782},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3377049.3377052},
doi = {10.1145/3377049.3377052},
abstract = {Underwater Object Detection had been one of the most challenging research fields of Computer Vision and Image Processing. Before Computer Vision techniques were used for underwater imaging, all the tasks associated with object detection had to be done manually by marine scientists making the task one of the most tedious and error prone. For this case, Underwater Autonomous Vehicles (UAV) has been developed to capture real time videos for specific object detection. Using different hardware improvements and using many varied forms of algorithms, classification of objects, mainly living objects had been carried with different AUVs and high-resolution cameras. Conventional object detection methods of Computer Vision fail to provide accurate detection results due to some challenges faced underwater. For such reasons, object detection underwater needs to be robust, real time and fast also being accurate, for which deep learning approaches are introduced. In this paper, all the works here all the trending underwater object detection techniques are discussed in details and a comprehensive comparative study is carried out.},
booktitle = {Proceedings of the International Conference on Computing Advancements},
articleno = {17},
numpages = {10},
keywords = {Image Processing and Underwater Autonomous Vehicle, Deep Learning, Underwater Object Detection, Image Enhancement},
location = {Dhaka, Bangladesh},
series = {ICCA 2020}
}

@inproceedings{10.1145/3467707.3467756,
author = {Jia, Weisheng and Cui, Jinling and Zheng, Xin and Wu, Qiang},
title = {Design and Implementation of Real-Time Semantic Segmentation Network Based on FPGA},
year = {2021},
isbn = {9781450389501},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3467707.3467756},
doi = {10.1145/3467707.3467756},
abstract = {With the rapid development of deep learning, the neural network of semantic segmentation has been developed towards the miniaturization of the network structure and the lightweight development of the network model. At the same time, FPGA-based neural network hardware accelerators have been proposed. The situation that the network module is too complex and computationally intensive to implement and apply on edge platforms is gradually being solved. However, the implementation of real-time processing network on the edge platform is still of great significance in many areas, such as robots, UAVs, driverless, etc. In this paper, a lightweight semantically segmented neural network Efficient neural network (E-Net) is designed and implemented on the image acquisition board with Zynq 7035 FPGA as processing unit, which achieves the frame rate of 32.9 FPS and meets the requirements of real-time processing.},
booktitle = {2021 7th International Conference on Computing and Artificial Intelligence},
pages = {321–325},
numpages = {5},
keywords = {Edge Computing, Field Programmable Gate Array (FPGA), Efficient neural network (E-Net), Zynq},
location = {Tianjin, China},
series = {ICCAI 2021}
}

@inproceedings{10.1145/3343031.3350933,
author = {Zhang, Haotian and Wang, Gaoang and Lei, Zhichao and Hwang, Jenq-Neng},
title = {Eye in the Sky: Drone-Based Object Tracking and 3D Localization},
year = {2019},
isbn = {9781450368896},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3343031.3350933},
doi = {10.1145/3343031.3350933},
abstract = {Drones, or general UAVs, equipped with a single camera have been widely deployed to a broad range of applications, such as aerial photography, fast goods delivery and most importantly, surveillance. Despite the great progress achieved in computer vision algorithms, these algorithms are not usually optimized for dealing with images or video sequences acquired by drones, due to various challenges such as occlusion, fast camera motion and pose variation. In this paper, a drone-based multi-object tracking and 3D localization scheme is proposed based on the deep learning based object detection. We first combine a multi-object tracking method called TrackletNet Tracker (TNT) which utilizes temporal and appearance information to track detected objects located on the ground for UAV applications. Then, we are also able to localize the tracked ground objects based on the group plane estimated from the Multi-View Stereo technique. The system deployed on the drone can not only detect and track the objects in a scene, but can also localize their 3D coordinates in meters with respect to the drone camera. The experiments have proved our tracker can reliably handle most of the detected objects captured by drones and achieve favorable 3D localization performance when compared with the state-of-the-art methods.},
booktitle = {Proceedings of the 27th ACM International Conference on Multimedia},
pages = {899–907},
numpages = {9},
keywords = {3d localization, drone, ground plane, multi-object tracking},
location = {Nice, France},
series = {MM '19}
}

@inproceedings{10.1145/3297280.3297408,
author = {Ahmad, Qadeer and Rafiq, Atif and Raja, Muhammad Adil and Javed, Noman},
title = {Evolving MIMO Multi-Layered Artificial Neural Networks Using Grammatical Evolution},
year = {2019},
isbn = {9781450359337},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3297280.3297408},
doi = {10.1145/3297280.3297408},
abstract = {In this paper, we propose a scheme for evolving multiple-input-multiple-output (MIMO) artificial neural networks (ANNs) using grammatical evolution (GE). GE is a well-known technique for program evolution. While it has also been used for the evolution of ANN structures in the past, little work is reported on the evolution of MIMO ANNs.MIMO ANNs are important for problems that have multiple outputs. Examples are controllers for autonomous systems such as unmanned aerial vehicles (UAVs) and driver-less cars that take in multiple inputs and are expected to produce multiple outputs simultaneously such as speed, steering etc. Certain regression problems are also MIMO in nature. Our results are promising.},
booktitle = {Proceedings of the 34th ACM/SIGAPP Symposium on Applied Computing},
pages = {1278–1285},
numpages = {8},
keywords = {neural networks, grammatical evolution},
location = {Limassol, Cyprus},
series = {SAC '19}
}

@inproceedings{10.5555/2772879.2772947,
author = {Ramchurn, Sarvapali D. and Huynh, Trung Dong and Ikuno, Yuki and Flann, Jack and Wu, Feng and Moreau, Luc and Jennings, Nicholas R. and Fischer, Joel E. and Jiang, Wenchao and Rodden, Tom and Simpson, Edwin and Reece, Steven and Roberts, Stephen J.},
title = {HAC-ER: A Disaster Response System Based on Human-Agent Collectives},
year = {2015},
isbn = {9781450334136},
publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
address = {Richland, SC},
abstract = {This paper proposes a novel disaster management system called HAC-ER that addresses some of the challenges faced by emergency responders by enabling humans and agents, using state-of-the-art algorithms, to collaboratively plan and carry out tasks in teams referred to as human-agent collectives. In particular, HAC-ER utilises crowdsourcing combined with machine learning to extract situational awareness information from large streams of reports posted by members of the public and trusted organisations. We then show how this information can inform human-agent teams in coordinating multi-UAV deployments as well as task planning for responders on the ground. Finally, HAC-ER incorporates a tool for tracking and analysing the provenance of information shared across the entire system. In summary, this paper describes a prototype system, validated by real-world emergency responders, that combines several state-of-the-art techniques for integrating humans and agents, and illustrates, for the first time, how such an approach can enable more effective disaster response operations.},
booktitle = {Proceedings of the 2015 International Conference on Autonomous Agents and Multiagent Systems},
pages = {533–541},
numpages = {9},
keywords = {disaster response, human and agents, innovative applications},
location = {Istanbul, Turkey},
series = {AAMAS '15}
}

@article{10.1145/3382756,
author = {Faraci, Giuseppe and Grasso, Christian and Schembra, Giovanni},
title = {Fog in the Clouds: UAVs to Provide Edge Computing to IoT Devices},
year = {2020},
issue_date = {August 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {20},
number = {3},
issn = {1533-5399},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3382756},
doi = {10.1145/3382756},
abstract = {Internet of Things (IoT) has emerged as a huge paradigm shift by connecting a versatile and massive collection of smart objects to the Internet, coming to play an important role in our daily lives. Data produced by IoT devices can generate a number of computational tasks that cannot be executed locally on the IoT devices. The most common solution is offloading these tasks to external devices with higher computational and storage capabilities, usually provided by centralized servers in remote clouds or on the edge by using the fog computing paradigm. Nevertheless, in some IoT scenarios there are remote or challenging areas where it is difficult to connect an IoT network to a fog platform with appropriate links, especially if IoT devices produce a lot of data that require processing in real-time. To this purpose, in this article, we propose to use unmanned aerial vehicles (UAVs) as fog nodes. Although this idea is not new, this is the first work that considers power consumption of the computing element installed on board UAVs, which is crucial, since it may influence flight mission duration. A System Controller (SC) is in charge of deciding the number of active CPUs at runtime by maximizing an objective function weighing power consumption, job loss probability, and processing latency. Reinforcement Learning (RL) is used to support SC in its decisions. A numerical analysis is carried out in a use case to show how to use the model introduced in the article to decide the computation power of the computing element in terms of number of available CPUs and CPU clock speed, and evaluate the achieved performance gain of the proposed framework.},
journal = {ACM Trans. Internet Technol.},
month = {aug},
articleno = {26},
numpages = {26},
keywords = {energy efficiency, Internet of Things, fog computing, performance evaluation, Reinforcement Learning}
}

@inproceedings{10.1145/3345770.3356740,
author = {Bouachir, Ouns and Aloqaily, Moayad and Garcia, Fabien and Larrieu, Nicolas and Gayraud, Thierry},
title = {Testbed of QoS Ad-Hoc Network Designed for Cooperative Multi-Drone Tasks},
year = {2019},
isbn = {9781450369053},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3345770.3356740},
doi = {10.1145/3345770.3356740},
abstract = {Thanks to technological advances in information and communications, Unmanned Aerial Vehicles (UAVs) (aka drones) technology has become one of the most important service delivery inventions these days. Equipped with sensors and cameras, these technologies can perform much on-demand critical application ranging from military and environmental to rescue operations. These UAVs devices, sometimes tiny, that can replace human and manned aircraft in several tasks, have been utilized to perform various types of services and applications more efciently. However, the deployment side of such emerging technology is still facing many issues and challenges. Using multi-drones or swarm of drones, together to accomplish one operation is one of these recent challenges. Such a system requires a high level of delicacy and cooperation to achieve the required autonomy and reduce human interaction as possible. Communication is one of the biggest challenges in these systems, since the devices should keep exchanging various types of messages with different Quality of Service (QoS) requirements. In this paper, a collaborative autonomous system of swarm drones based on deep learning has been proposed and a testbed of cooperative UAVs' mission to validate the performance of the dedicated QoS communication system using Paparazzi drones The proposed system is aware of the drones' requirements in term of QoS and able to meet with their dynamic demands.},
booktitle = {Proceedings of the 17th ACM International Symposium on Mobility Management and Wireless Access},
pages = {89–95},
numpages = {7},
keywords = {cooperation, drones, uavs, qos ad-hoc, testbed},
location = {Miami Beach, FL, USA},
series = {MobiWac '19}
}


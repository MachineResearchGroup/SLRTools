@inproceedings{10.1145/3487923.3487924,
author = {Ukaegbu, Uchechi F. and Tartibu, Lagouge K. and Okwu, Modestus O. and Olayode, Isaac O.},
title = {Integrating Unmanned Aerial Vehicle and Deep Learning Algorithm for Pipeline Monitoring and Inspection in the Oil and Gas Sector},
year = {2021},
isbn = {9781450385756},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3487923.3487924},
doi = {10.1145/3487923.3487924},
abstract = {Organizations invest heavily during the installation of pipeline facilities which spans across extensive geographical linkage. Also, the issue of pipeline protection and safety must be taken into consideration to have a free flow of oil and gas at inbound and outbound locations. This has necessitated the need for routine inspection and monitoring of pipelines for structural integrity, continued safe operations, and also to monitor intruders/potential trespassers at such locations. This research is focused on the elucidation of a modular unmanned aerial vehicle (UAV) integrated with deep learning algorithms for monitoring and security response to obtain very useful information around the oil and gas facility. The deep learning model employed in this study had training, validation and testing accuracies of 88.3%, 87.5%, and 83.3% respectively. Also, training and validation losses of 0.3583 and 0.3649 were obtained. The suggested integrated UAV has a low maintenance requirement, high endurance, and is cost-effective. It has a superior advantage over the manned aerial vehicles (MAV) currently in use since safety is greatly improved, the cost is reduced, adequate information is obtained and communication is enhanced.},
booktitle = {Proceedings of the International Conference on Artificial Intelligence and Its Applications},
articleno = {1},
numpages = {6},
keywords = {Monitoring, Deep learning algorithm, Unmanned aerial vehicle, Pipeline, Inspection},
location = {Virtual Event, Mauritius},
series = {icARTi '21}
}

@inproceedings{10.1145/3454127.3457637,
author = {Taberkit, Amine Mohammed and Kechida, Ahmed and Bouguettaya, Abdelmalek},
title = {Algerian Perspectives for UAV-Based Remote Sensing Technologies and Artificial Intelligence in Precision Agriculture},
year = {2021},
isbn = {9781450388719},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3454127.3457637},
doi = {10.1145/3454127.3457637},
abstract = { Unmanned Aerial Vehicles (UAVs) are considered emerging innovative technologies, equipped with different sensors they can offer various services and applications. It is possible to exploit unmanned aerial vehicles to capture high spatial resolution images and high temporal resolution images, which could be helpful in many smart farming applications. We expect that these innovations will revolutionize agriculture, enabling to take faster decisions, and promise major cost savings and production enhancements. Precision agriculture is based on the use of the right process, with the right quantities, at the proper place and time, according to the targeted application. In this paper, we address the prevalent applications of UAVs and artificial intelligence in precision agriculture and their benefits in Algeria.},
booktitle = {Proceedings of the 4th International Conference on Networking, Information Systems &amp; Security},
articleno = {61},
numpages = {9},
keywords = {Smart Farming, Remote Sensing., Unmanned Aerial Vehicle, Artificial Intelligence, Precision Agriculture},
location = {KENITRA, AA, Morocco},
series = {NISS2021}
}

@article{10.1145/3301273,
author = {Koch, William and Mancuso, Renato and West, Richard and Bestavros, Azer},
title = {Reinforcement Learning for UAV Attitude Control},
year = {2019},
issue_date = {April 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {3},
number = {2},
issn = {2378-962X},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3301273},
doi = {10.1145/3301273},
abstract = {Autopilot systems are typically composed of an “inner loop” providing stability and control, whereas an “outer loop” is responsible for mission-level objectives, such as way-point navigation. Autopilot systems for unmanned aerial vehicles are predominately implemented using Proportional-Integral-Derivative&nbsp;(PID) control systems, which have demonstrated exceptional performance in stable environments. However, more sophisticated control is required to operate in unpredictable and harsh environments. Intelligent flight control systems is an active area of research addressing limitations of PID control most recently through the use of reinforcement learning&nbsp;(RL), which has had success in other applications, such as robotics. Yet previous work has focused primarily on using RL at the mission-level controller. In this work, we investigate the performance and accuracy of the inner control loop providing attitude control when using intelligent flight control systems trained with state-of-the-art RL algorithms—Deep Deterministic Policy Gradient, Trust Region Policy Optimization, and Proximal Policy Optimization. To investigate these unknowns, we first developed an open source high-fidelity simulation environment to train a flight controller attitude control of a quadrotor through RL. We then used our environment to compare their performance to that of a PID controller to identify if using RL is appropriate in high-precision, time-critical flight control.},
journal = {ACM Trans. Cyber-Phys. Syst.},
month = {feb},
articleno = {22},
numpages = {21},
keywords = {reinforcement learning, machine learning, quadcopter, autopilot, PID, intelligent control, UAV, adaptive control, Attitude control}
}

@inproceedings{10.1145/3448891.3448919,
author = {Lee, Isabella and Babu, Vignesh and Caesar, Matthew and Nicol, David},
title = {Deep Reinforcement Learning for UAV-Assisted Emergency Response},
year = {2020},
isbn = {9781450388405},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3448891.3448919},
doi = {10.1145/3448891.3448919},
abstract = { In the aftermath of a disaster, the ability to reliably communicate and coordinate emergency response could make a meaningful difference in the number of lives saved or lost. However, post-disaster areas tend to have limited functioning communication network infrastructure while emergency response teams are carrying increasingly more devices, such as sensors and video transmitting equipment, which can be low-powered with limited transmission ranges. In such scenarios, unmanned aerial vehicles (UAVs) can be used as relays to connect these devices with each other. Since first responders are likely to be constantly mobile, the problem of where these UAVs are placed and how they move in response to the changing environment could have a large effect on the number of connections this UAV relay network is able to maintain. In this work, we propose DroneDR, a reinforcement learning framework for UAV positioning that uses information about connectivity requirements and user node positions to decide how to move each UAV in the network while maintaining connectivity between UAVs. The proposed approach is shown to outperform other greedy heuristics across a broad range of scenarios and demonstrates the potential in using reinforcement learning techniques to aid communication during disaster relief operations.},
booktitle = {MobiQuitous 2020 - 17th EAI International Conference on Mobile and Ubiquitous Systems: Computing, Networking and Services},
pages = {327–336},
numpages = {10},
keywords = {UAV network, IoT network, reinforcement learning, disaster relief},
location = {Darmstadt, Germany},
series = {MobiQuitous '20}
}

@inproceedings{10.1145/3507971.3507982,
author = {Li, Qingya and Guo, Li and Dong, Chao and Mu, Xidong},
title = {3D Trajectory Design of UAV Based on Deep Reinforcement Learning in Time-Varying Scenes},
year = {2021},
isbn = {9781450385190},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3507971.3507982},
doi = {10.1145/3507971.3507982},
abstract = { A joint framework is proposed for the 3D trajectory design of an unmanned aerial vehicle (UAV) as an flying base station under the time-varying scenarios of users’ mobility and communication request probability changes. The problem of 3D trajectory design is formulated for maximizing the throughput during a UAV’s flying period while satisfying the rate requirement of all ground users (GUEs). Specifically, we consider that GUEs change their positions and communication request probabilities at each time slot; the UAV needs to predict these changes so that it can design its 3D trajectory in advance to achieve the optimization target. In an effort to solve this pertinent problem, an echo state network (ESN) based prediction algorithm is first proposed for predicting the positions and communication request probabilities of GUEs. Based on these predictions, a Deep Reinforcement Learning (DRL) method is then invoked for finding the optimal deployment locations of UAV in each time slots. The proposed method 1) uses ESN based predictions to represent a part of DRL agent’s state; 2) designs the action and reward for DRL agent to learn the environment and its dynamics; 3) makes optimal strategy under the guidance of a double deep Q network (DDQN). The simulation results show that the UAV can dynamically adjust its trajectory to adapt to time-varying scenarios through our proposed algorithm and throughput gains of about 10.68% are achieved.},
booktitle = {2021 the 7th International Conference on Communication and Information Processing (ICCIP)},
pages = {56–62},
numpages = {7},
keywords = {Time-varying Scenes, echo state network (ESN), Deep Reinforcement Learning (DRL), UAV},
location = {Beijing, China},
series = {ICCIP 2021}
}

@inproceedings{10.1145/3447587.3447590,
author = {Symeonidis, Charalampos and Kakaletsis, Efstratios and Mademlis, Ioannis and Nikolaidis, Nikos and Tefas, Anastasios and Pitas, Ioannis},
title = {Vision-Based UAV Safe Landing Exploiting Lightweight Deep Neural Networks},
year = {2021},
isbn = {9781450389105},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3447587.3447590},
doi = {10.1145/3447587.3447590},
abstract = {Recent advances in artificial intelligence, control and sensing technologies have facilitated the development of autonomous Unmanned Aerial Vehicles (UAVs, or drones) able to self-navigate in various settings. Although these technologies have already entered a mature stage, ensuring flight safety in crowded areas or performing an emergency landing in case of malfunctions, while adhering to relevant legislation, is generally treated as an afterthought when designing autonomous UAV platforms for unstructured environments. This paper proposes a UAV safe landing navigation pipeline that relies on lightweight computer vision modules, able to be executed on the limited computational resources on-board a typical UAV. Pre-trained Deep Neural Networks (DNNs) are mainly employed as the underlying building blocks, since deep learning has made a major impact on robotic perception by drastically improving the performance of relevant tasks, such as object detection or tracking, semantic image segmentation, etc. Evaluation of the proposed pipeline on a simulated environment indicates highly favorable results.},
booktitle = {2021 The 4th International Conference on Image and Graphics Processing},
pages = {13–19},
numpages = {7},
keywords = {path planning, autonomous drones, robot navigation, object detection, semantic image segmentation, UAV safe landing},
location = {Sanya, China},
series = {ICIGP 2021}
}

@inproceedings{10.1145/3501409.3501673,
author = {Wu, Fan and Zong, Yantao and Zhao, Rui and Yu, Tianyi and Tang, Xiaqing and He, Ximing},
title = {Visual Odometery for UAV Navigation Based on Deep Learning},
year = {2021},
isbn = {9781450384322},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3501409.3501673},
doi = {10.1145/3501409.3501673},
abstract = {Taking UAV as the application background, this paper studies the visual odometery for deep learning in UAV navigation. Firstly, the dataset FLYING is made through UAV aerial photography. Secondly, pretraining and testing the established G-LSTM VO and attention VO models through the KITTI dataset. Thirdly, by means of transfer learning, training and testing the pre trained model based on FLYING dataset. Finally, the model is tested. The performance of the model in UAV mission is analyzed from the aspects of trajectory, pose estimation accuracy and algorithm time-consuming. The experimental results show that the monocular visual odometery method based on depth neural network is effective in the field of UAV navigation.},
booktitle = {Proceedings of the 2021 5th International Conference on Electronic Information Technology and Computer Engineering},
pages = {1493–1501},
numpages = {9},
keywords = {Visual odometery, Convolutional neural network, Recurrent neural network, Attention mechanism},
location = {Xiamen, China},
series = {EITCE 2021}
}

@inproceedings{10.1145/3396864.3399701,
author = {Venturini, Federico and Mason, Federico and Pase, Francesco and Chiariotti, Federico and Testolin, Alberto and Zanella, Andrea and Zorzi, Michele},
title = {Distributed Reinforcement Learning for Flexible UAV Swarm Control with Transfer Learning Capabilities},
year = {2020},
isbn = {9781450380102},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3396864.3399701},
doi = {10.1145/3396864.3399701},
abstract = {Over the past few years, the use of swarms of Unmanned Aerial Vehicles (UAVs) in monitoring and remote area surveillance applications has become economically efficient thanks to the price reduction and the increased capabilities of drones. The drones in the swarm need to cooperatively explore an unknown area, in order to identify and monitor interesting targets, while minimizing their movements. In this work, we propose a distributed Reinforcement Learning (RL) approach that scales to larger swarms without modifications. The proposed framework can easily deal with non-uniform distributions of targets, drawing from past experience to improve its performance. In particular, our experiments show that when agents are trained for a specific scenario, they can adapt to a new one with a minimal amount of additional training. We show that our RL approach achieves favorable performance compared to a computationally intensive look-ahead heuristic.},
booktitle = {Proceedings of the 6th ACM Workshop on Micro Aerial Vehicle Networks, Systems, and Applications},
articleno = {10},
numpages = {6},
keywords = {multi-agent RL, UAV networks, distributed deep RL, surveilling},
location = {Toronto, Ontario, Canada},
series = {DroNet '20}
}

@inproceedings{10.1145/3447587.3447598,
author = {Yi, JianWei and Guan, Banglei and Li, Pengcheng},
title = {Intelligent Highway Speed Monitoring UAV System Based on Deep Learning},
year = {2021},
isbn = {9781450389105},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3447587.3447598},
doi = {10.1145/3447587.3447598},
abstract = {At present, with economic development, traffic accidents occur frequently, and more than one-third of traffic accidents are caused by speeding. Current highway speed measurement devices have disadvantages such as high cost, inability to move, and low speed measurement accuracy. For these reasons, we propose an intelligent monitoring drone system for highway speed measurement based on deep learning. The system uses drones for monitoring, so the system is low-cost and flexible. First, the system's camera captures and recognizes vehicle movement and license plate information. Second, we propose algorithms based on the corners of the lane line speed measurement and the speed measurement based on the homography matrix to calculate the vehicle speed, and at the same time detect and recognize the license plate. Third, we propose to use ensemble learning methods to improve the accuracy of vehicle speed measurement, and finally obtain vehicle speed and speeding license plates. Experimental results prove that the proposed highway speed measurement UAV system can accurately identify and measure vehicle speed and record speeding license plates.},
booktitle = {2021 The 4th International Conference on Image and Graphics Processing},
pages = {73–79},
numpages = {7},
keywords = {Deep Learning, License Plate Recognition, Vehicle Speed Measurement},
location = {Sanya, China},
series = {ICIGP 2021}
}

@inproceedings{10.5555/3237383.3238121,
author = {Nguyen, Hung The and Garratt, Matthew and Bui, Lam Thu and Abbass, Hussein},
title = {Apprenticeship Bootstrapping: Inverse Reinforcement Learning in a Multi-Skill UAV-UGV Coordination Task},
year = {2018},
publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
address = {Richland, SC},
abstract = {Apprenticeship learning enables learning from human demonstrations performed on tasks. However, acquiring demonstrations in complex tasks where a human expert is not available can be a challenge. In this paper, we propose a new learning algorithm, called Apprenticeship bootstrapping via Inverse Reinforcement Learning using Deep Q-learning (ABS via IRL-DQN), to learn a complex task through using demonstrations performed on primitive sub-tasks. The algorithm is evaluated on an aerial and ground coordination scenario, where an Unmanned Aerial Vehicle (UAV) is required to maintain three Unmanned Ground Vehicles (UGVs) within a field of view of the UAV 's camera (FoV). The results show that performance of our proposed algorithm is comparable to that of a human, and competitive to the original IRL using expert demonstrations performed on the composite task.},
booktitle = {Proceedings of the 17th International Conference on Autonomous Agents and MultiAgent Systems},
pages = {2204–2206},
numpages = {3},
keywords = {ground-air interaction, deep q-learning, ugvs, inverse reinforcement learning, uavs, apprenticeship learning},
location = {Stockholm, Sweden},
series = {AAMAS '18}
}

@inproceedings{10.1145/3366194.3366251,
author = {Yang, Songyue and Meng, Zhijun and Chen, Xuzhi and Xie, Ronglei},
title = {Real-Time Obstacle Avoidance with Deep Reinforcement Learning Three-Dimensional Autonomous Obstacle Avoidance for UAV},
year = {2019},
isbn = {9781450372985},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3366194.3366251},
doi = {10.1145/3366194.3366251},
abstract = {At present, drones are rapidly developing in the aviation industry and are applied to all aspects of life. However, letting drones autonomously avoid obstacles is still the focus of research by aviation scholars at this stage. However, the current automation is mostly based on human experience to determine the obstacle avoidance strategy of UAV. And the method only rely on the machine to avoid obstacle is very few. In this paper, the UAV collect visual and distance sensor information to make autonomous obstacle avoidance decision through the deep reinforcement learning algorithm, and the algorithm is tested in the v-rep simulation environment.},
booktitle = {Proceedings of the 2019 International Conference on Robotics, Intelligent Control and Artificial Intelligence},
pages = {324–329},
numpages = {6},
keywords = {DQN, v-rep, aircraft, obstacle avoidance},
location = {Shanghai, China},
series = {RICAI 2019}
}

@inproceedings{10.1145/3374587.3374599,
author = {Sun, Jian and Zhang, Yingzhou},
title = {A Reinforcement Learning-Based Decentralized Method of Avoiding Multi-UAV Collision in 3-D Airspace},
year = {2019},
isbn = {9781450376273},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3374587.3374599},
doi = {10.1145/3374587.3374599},
abstract = {Recently, large-scale multi-UAV collaboration system have been proposed for mobile sensor network applications and the collision avoidance becomes the core of the scalable control for any multi-UAV system. We present a decentralized collision avoidance mechanism of cooperative unmanned aerial vehicles (UAVs) in three-dimensional airspace, which directly maps the observed environment information to a UAV's steer commands. We solve the problem on continuous state space and action space and design a multi-module reward function to decrease the collision rate of UAV-UAV and UAV-obstacle, deviation from the planned trajectory and the cost of turning angular velocity. Our method is based on the Distributed Proximal Policy Optimization (DPPO) algorithm with asynchronous training framework, which is a policy gradient of Reinforcement Learning algorithm to learn an optimal policy. Subsequently, we propose a multi-scenario multi-stage training process to our experiment as for a good convergence solution. After testing our method in non-stationary stochastic environments and conducting a contrast experiment, the result shows that our method is able to find collision-free policy for a large-scale multi-UAV swarm.},
booktitle = {Proceedings of the 2019 3rd International Conference on Computer Science and Artificial Intelligence},
pages = {77–82},
numpages = {6},
keywords = {Decentralized collision avoidance, DPPO, reinforcement learning, multi-module},
location = {Normal, IL, USA},
series = {CSAI2019}
}

@inproceedings{10.5555/1516744.1516964,
author = {Perron, Jimmy and Hogan, Jimmy and Moulin, Bernard and Berger, Jean and B\'{e}langer, Micheline},
title = {A Hybrid Approach Based on Multi-Agent Geosimulation and Reinforcement Learning to Solve a UAV Patrolling Problem},
year = {2008},
isbn = {9781424427086},
publisher = {Winter Simulation Conference},
abstract = {In this paper we address a dynamic distributed patrolling problem where a team of autonomous unmanned aerial vehicles (UAVs) patrolling moving targets over a large area must coordinate. We propose a hybrid approach combining multi-agent geosimulation and reinforcement learning enabling a group of agents to find near optimal solutions in realistic geo-referenced virtual environments. We present the COLMAS System which implements the proposed approach and show how a set of UAV can automatically find patrolling patterns in a dynamic environment characterized by unknown obstacles and moving targets. We also comment the value of the approach based on limited computational results.},
booktitle = {Proceedings of the 40th Conference on Winter Simulation},
pages = {1259–1267},
numpages = {9},
location = {Miami, Florida},
series = {WSC '08}
}

@inproceedings{10.1145/3467707.3467714,
author = {Wu, Qiang and Wu, Xuegang and Zheng, Xin and Yue, Bin},
title = {Research on UAV Detection of Threat Target around Oil Pipeline Based on Deep Learning},
year = {2021},
isbn = {9781450389501},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3467707.3467714},
doi = {10.1145/3467707.3467714},
abstract = {With the development of UAV, UAV has been applied to various projects with its advantages of low construction cost,low safety risk coefficient and convenient operation.In terms of UAV platform, currently composite wing and multi-rotor UAV are typically adopted, which can realize basic flight route. In terms of image detection, neural network is mainly used to classify and recognize the target in the image. In this paper, the YOLOV4 algorithm is improved to make it more suitable for UAV detection of ground targets.In the ground detection of UAV, most of them are small targets, so clustering method is used to redesign anchor for small targets. Because the features of small targets have more details in the shallow feature layer, the shallow feature is superimposed into the feature extraction layer, and the shallow feature and the deep feature are fused.In the data processing, data enhancement, color dithering, flipping, cutting of the data set for expansion. Through the test of the modified network, the following results are obtained: the overall mAP is improved by 9.3%, the detection mAP for small targets such as people is improved by 23.75%, and the detection mAP for working vehicles is improved by 15.4%. The detection efficiency of small targets is improved, and the speed can meet the real-time requirements, and it can be deployed in the UAV for UAV detection.},
booktitle = {2021 7th International Conference on Computing and Artificial Intelligence},
pages = {48–56},
numpages = {9},
keywords = {Pipeline Inspection, TargetDetection, YOLO UAV},
location = {Tianjin, China},
series = {ICCAI 2021}
}

@inbook{10.1109/ASONAM49781.2020.9381377,
author = {Aposporis, Panagiotis},
title = {Object Detection Methods for Improving UAV Autonomy and Remote Sensing Applications},
year = {2020},
isbn = {9781728110561},
publisher = {IEEE Press},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1109/ASONAM49781.2020.9381377},
abstract = {The last decades the Unmanned Aerial Systems (UASs) are being used in a variety of applications, such as civil protection, security, agriculture, armed forces, that need real time object detection of observed information by their sensors. Moreover, the development of fully autonomous UAS is heavily dependent on their capability to detect and track steady or moving objects in a robust, powerful and reliable manner. In this review, we present a comprehensive literature survey and discussion on object detection methodologies for improving UAV autonomy and remote sensing applications Emphasis is placed on Convolutional Neural Networks (CNN) implementing different object detectors and exploiting cloud processing. Based on these works, we provide a brief discussion and summary of related proposals for UAV-based object detection using different methodologies and approaches, share views for future research directions and draw conclusive remarks.},
booktitle = {Proceedings of the 12th IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining},
pages = {845–853},
numpages = {9}
}

@article{10.1145/3306346.3322940,
author = {Xu, Jie and Du, Tao and Foshey, Michael and Li, Beichen and Zhu, Bo and Schulz, Adriana and Matusik, Wojciech},
title = {Learning to Fly: Computational Controller Design for Hybrid UAVs with Reinforcement Learning},
year = {2019},
issue_date = {August 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {38},
number = {4},
issn = {0730-0301},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3306346.3322940},
doi = {10.1145/3306346.3322940},
abstract = {Hybrid unmanned aerial vehicles (UAV) combine advantages of multicopters and fixed-wing planes: vertical take-off, landing, and low energy use. However, hybrid UAVs are rarely used because controller design is challenging due to its complex, mixed dynamics. In this paper, we propose a method to automate this design process by training a mode-free, model-agnostic neural network controller for hybrid UAVs. We present a neural network controller design with a novel error convolution input trained by reinforcement learning. Our controller exhibits two key features: First, it does not distinguish among flying modes, and the same controller structure can be used for copters with various dynamics. Second, our controller works for real models without any additional parameter tuning process, closing the gap between virtual simulation and real fabrication. We demonstrate the efficacy of the proposed controller both in simulation and in our custom-built hybrid UAVs (Figure 1, 8). The experiments show that the controller is robust to exploit the complex dynamics when both rotors and wings are active in flight tests.},
journal = {ACM Trans. Graph.},
month = {jul},
articleno = {42},
numpages = {12},
keywords = {neural network controllers, hybrid UAVs}
}

@inproceedings{10.1145/3501409.3501697,
author = {Zhou, Huan and Zhang, Xiaoyan and Sun, Chu},
title = {Intelligent Maneuver Decision Method of Unmanned Aerial Vehicle},
year = {2021},
isbn = {9781450384322},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3501409.3501697},
doi = {10.1145/3501409.3501697},
abstract = {As the key link of airspace task execution, UAV maneuver decision-making is the core intelligence embodiment of UAV, which can best represent the intelligence of UAV "brain". This paper summarizes the intelligent maneuver decision-making methods of UAV. Firstly, the problem and application background of UAV intelligent maneuver decision-making are introduced. Then, the research status of maneuver decision-making methods at home and abroad is analyzed. Intelligent maneuver decision-making is divided into two aspects: maneuver decision-making based on game theory and artificial intelligence. Game theory focuses on differential game, matrix game and influence diagram, Artificial intelligence focuses on expert system, intelligent optimization theory and neural network. Finally, a new air combat intelligent maneuver decision-making method based on bird foraging search algorithm is designed and verified by simulation experiments. The summary of UAV intelligent maneuver decision-making methods will contribute to the innovative research in this field, so as to promote the rapid development of maneuver decision-making technology.},
booktitle = {Proceedings of the 2021 5th International Conference on Electronic Information Technology and Computer Engineering},
pages = {1634–1639},
numpages = {6},
keywords = {UAV, Reinforcement learning, Game theory, Maneuver decision, Artificial Intelligence},
location = {Xiamen, China},
series = {EITCE 2021}
}

@inproceedings{10.1145/3503047.3503128,
author = {Ding, Shengjie and Liu, Juan and Xie, Lingfu},
title = {UAV-Enabled Edge Computing for Virtual Reality},
year = {2021},
isbn = {9781450385862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3503047.3503128},
doi = {10.1145/3503047.3503128},
abstract = { 5G communication promotes the development of VR (Virtual Reality) applications, providing users with immersive experiences. To accomplish VR tasks with large computation and low delay demands, an unmanned aerial vehicle (UAV)-enabled MEC (Mobile Edge Computing) method is proposed to assist VR devices in the rendering process. Under the constraints imposed by the VR characteristics and the device energy, the UAV flight trajectory and the VR rendering mode are jointly optimized to maximize the rendering completion rate of the VR tasks. This problem is modeled as a Markov decision process. To find the optimal policy, a UAV aided rendering algorithm is proposed in the framework of deep reinforcement learning. Specifically, the TD3 (Twin Delayed Deep Deterministic Policy Gradient) algorithm is applied to schedule the UAV trajectory and VR rendering mode to meet the requirements of the randomly arriving VR tasks as much as possible. Simulation results show that the proposed method outperforms baseline strategies in both the rendering completion rate and the convergence speed.},
booktitle = {2021 3rd International Conference on Advanced Information Science and System (AISS 2021)},
articleno = {75},
numpages = {8},
keywords = {Virtual reality, TD3, mobile edge computing, UAV, deep reinforcement learning},
location = {Sanya, China},
series = {AISS 2021}
}

@inproceedings{10.1145/3416014.3424600,
author = {Martinez-Alpiste, Ignacio and Golcarenarenji, Gelayol and Wang, Qi and Alcaraz-Calero, Jose Maria},
title = {Real-Time Low-Pixel Infrared Human Detection From Unmanned Aerial Vehicles},
year = {2020},
isbn = {9781450381215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3416014.3424600},
doi = {10.1145/3416014.3424600},
abstract = {To improve the speed and accuracy in human detection in Search and Rescue (SAR) operations, this paper presents a novel and highly efficient machine learning empowered system by extending the You Only Look Once (YOLO) algorithm, which is designed and deployed on an embedded system. The proposed approach has been evaluated under real-world conditions on a Jetson AGX Xavier platform and the results have shown a well-balanced system in terms of accuracy, speed and portability. Moreover, the system demonstrates its resilience to perform low-pixel human detection on infrared images received from an Unmanned Aerial Vehicle (UAV) at low-light conditions, different altitudes and postures such as sitting, walking and running. The proposed approach has achieved in a constrained environment a total of 89.26% of accuracy and 24.6 FPS, surpassing the barrier of real-time object recognition.},
booktitle = {Proceedings of the 10th ACM Symposium on Design and Analysis of Intelligent Vehicular Networks and Applications},
pages = {9–15},
numpages = {7},
keywords = {YOLO, machine learning, Jetson AGX Xavier, thermal imagery, UAV},
location = {Alicante, Spain},
series = {DIVANet '20}
}

@inproceedings{10.1145/3265007.3265014,
author = {Malinao, Ronjie Mar L. and Hernandez, Alexander A.},
title = {Classifying Breadfruit Tree Using Artificial Neural Networks},
year = {2018},
isbn = {9781450365741},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3265007.3265014},
doi = {10.1145/3265007.3265014},
abstract = {This is a research-in-progress of designing an intelligent morphological analysis for Artocarpus Altilis or commonly called "breadfruit." This research applied image processing, artificial intelligence (AI) and system design. Using Unmanned Aerial Vehicle (UAV), images are captured, processed and fed to the artificial intelligence for classification. The initial result yields a 75% accuracy using the initial dataset. This study proves that using UAV combined with AI could substantially contribute to the agricultural industry in efficiently classifying breadfruit. This paper recommends further enhancement of the system.},
booktitle = {Proceedings of the 6th ACM/ACIS International Conference on Applied Computing and Information Technology},
pages = {27–31},
numpages = {5},
keywords = {Artificial Neural Networks, Image Processing, Breadfruit, Artocarpus},
location = {Kunming, China},
series = {ACIT 2018}
}

@inproceedings{10.1145/3351180.3351183,
author = {Zeng, Diqing and Zeng, Guigen and Kodom, Prince Owusu},
title = {Research on Recognition Technology of Vehicle Rolling Line Violation in Highway Based on Visual UAV},
year = {2019},
isbn = {9781450371834},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3351180.3351183},
doi = {10.1145/3351180.3351183},
abstract = {The recognition technology of vehicle illegal rolling line is an important part of intelligent transportation system. Aiming at the problems of traditional fixed monitoring and traditional rolling line detection algorithm, this paper designs a system model of vehicle illegal rolling line recognition based on visual UAV. Firstly, video data are collected by UAV patrol aerial photography, vehicle target detection is carried out by YOLOv3 algorithm based on deep learning, and then combined with lane line detection results based on closed angles average algorithm, according to whether the diagonal line of the bounding box of the vehicle intersects with the solid lane line to determine whether the vehicle is illegally compacted or not. The experimental results show that the accuracy and robustness of the proposed model are significantly improved compared with those of the traditional monitoring technology for illegal rolling. This provides an efficient and flexible monitoring mode for traffic monitoring and management.},
booktitle = {Proceedings of the 2019 4th International Conference on Robotics, Control and Automation},
pages = {198–204},
numpages = {7},
keywords = {Vehicle Illegal Rolling, Deep Learning Target Detection, Lane Line Detection, Unmanned Aerial Vehicle},
location = {Guangzhou, China},
series = {ICRCA 2019}
}

@inbook{10.1145/3458380.3458422,
author = {Zhao, Zhiwei and song, lili and han, jianfeng},
title = {An Improved Object Detection Model for Autonomous Pilot of Engineering Inspection},
year = {2021},
isbn = {9781450389365},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3458380.3458422},
abstract = {Previously, Engineering maintenance vehicle mainly through human operations, which has higher labor costs and lower efficiency. In order to obtain complete images needed in the field of engineering maintenance quickly and easily, auto pilot of engineering maintenance vehicle can play a huge role in engineering fields such as power maintenance and highway maintenance. Automatic ground key information detection is the most important part of auto pilot of engineering maintenance vehicle. In this study, we propose a new model that uses an improved form of the You Only Look Once (YOLO) model to enhance the real-time detection of key information problems. This model is mainly realized by optimizing the network structure of original YOLOv3 model. The experimental results show that in the highway center marking data set, the precision of the trained model is 95.76%, and an average accuracy of 90.43% for the test setup. By comparing with YOLOv3, the detection accuracy of the proposed improved method is mainly improved. At the same time, under GPU acceleration, the average detection speed is 29.20 frames/s, which can meet the real-time detection by the engineering maintenance vehicle platform.},
booktitle = {2021 5th International Conference on Digital Signal Processing},
pages = {243–248},
numpages = {6}
}

@inproceedings{10.1145/3059336.3059337,
author = {Jiang, Xiaowei and Zhou, Qiang and Ye, Ying},
title = {Method of Task Assignment for UAV Based on Particle Swarm Optimization in Logistics},
year = {2017},
isbn = {9781450347983},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3059336.3059337},
doi = {10.1145/3059336.3059337},
abstract = {In recent years, there are many research achievements in the fields of logistics and Unmanned Aerial Vehicle (UAV). But the research achievement of the combination of the two fields is few. Researching on the combination of the UAV filed and the logistics filed has theoretical significance. Effective logistics system and task assignment strategy play an important role in reducing the operation cost of logistics enterprise as well as improving transport efficiency. In this paper, according to the Vehicle Routing Problems with Time Windows (VRPTW), we establish the model of task assignment for UAV in logistics. This model takes multi-constraints (such as weight coefficients, time-windows constraints, the constraints of the UAV and so on ) into account. And then the task assignment problem with multiple constraints is solved by improved Particle Swarm Optimization (PSO) algorithm which is suitable for solving complex combinatorial optimization problems. Meanwhile, we make some modification for the PSO to suit for the acquirement of mutually exclusive. The basic principle and simulation steps of the improved PSO algorithm is described in detail. And a simulation example is given. Furthermore, we compare PSO with Genetic Algorithm. The simulation results show that this algorithm is efficient to solve the problem of task assignment for UAV.},
booktitle = {Proceedings of the 2017 International Conference on Intelligent Systems, Metaheuristics &amp; Swarm Intelligence},
pages = {113–117},
numpages = {5},
keywords = {logistics, PSO, VRPTW, task assignment, Unmanned Aerial Vehicle (UAV), swarm intelligence},
location = {Hong Kong, Hong Kong},
series = {ISMSI '17}
}

@inproceedings{10.1145/3309772.3309797,
author = {Gorobetz, Mikhail and Ribickis, Leonids and Levchenkov, Anatoly and Beinarovica, Anna},
title = {Machine Learning Algorithm of Immune Neuro-Fuzzy Anti-Collision Embedded System for Autonomous Unmanned Aerial Vehicles Team},
year = {2019},
isbn = {9781450360852},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3309772.3309797},
doi = {10.1145/3309772.3309797},
abstract = {This study is dedicated to solve a collision prevention task for autonomous unmanned aerial vehicles' (UAVs) team by Immune Neuro-Fuzzy Network (INFN) application. It is a part of the project aimed at the development of intelligent safety and optimal control systems of autonomous electric vehicles and transport in general.The goal of the current research is to develop the machine learning algorithm for autonomous UAV, that will give possibility for UAVs to train themselves without a teacher to avoid the collisions in the most effective way by changing the UAVs trajectory of the flight and without human intervention, i.e. the system should be self-organized. For this purpose, authors have improved previously developed immune neuro-fuzzy logic method to minimize collision probability. The experiments prove the workability and advantages of the developed algorithm.},
booktitle = {Proceedings of the 2nd International Conference on Applications of Intelligent Systems},
articleno = {25},
numpages = {8},
keywords = {vehicle's team, neural network, unmanned aerial vehicle, autonomous vehicle, machine learning, immune network, anti-collision system, fuzzy logic},
location = {Las Palmas de Gran Canaria, Spain},
series = {APPIS '19}
}

@inproceedings{10.1145/3427228.3427254,
author = {Xue, Nian and Niu, Liang and Hong, Xianbin and Li, Zhen and Hoffaeller, Larissa and P\"{o}pper, Christina},
title = {DeepSIM: GPS Spoofing Detection on UAVs Using Satellite Imagery Matching},
year = {2020},
isbn = {9781450388580},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3427228.3427254},
doi = {10.1145/3427228.3427254},
abstract = { Unmanned Aerial Vehicles (UAVs), better known as drones, have significantly advanced fields such as aerial surveillance, military reconnaissance, cadastral surveying, disaster monitoring, and delivery services. However, UAVs rely on civilian (unauthenticated) GPS for navigation which can be trivially spoofed. In this paper, we present DeepSIM, a satellite imagery matching approach to detect GPS spoofing attacks against UAVs based on deep learning. We make use of the camera(s) a typical UAV is equipped with, and present a system that compares historical satellite images of its GPS-based position (spaceborne photography) with real-time aerial images from its cameras (airborne imagery). Historical images are taken from, e.&nbsp;g., Google Earth or NASA WorldWind. To detect GPS spoofing attacks, we investigate different deep neural network models that compare the real-time camera images with the historical satellite images. To train and test the models, we have constructed the SatUAV dataset (consisting of 967 image pairs), partially by using real UAVs such as the DJI Phantom 4 Advanced. Real-world experimental results show that our best model has a success rate of about 95% in detecting GPS spoofing attacks within less than 100 milliseconds. Our approach does not require any modification of the existing GPS infrastructures and relies only on public satellite imagery, making it a practical solution for many everyday scenarios.},
booktitle = {Annual Computer Security Applications Conference},
pages = {304–319},
numpages = {16},
keywords = {deep learning, GPS spoofing detection, neural networks, UAV},
location = {Austin, USA},
series = {ACSAC '20}
}

@inproceedings{10.1145/3460268.3460276,
author = {Hou, Zhigang and Yan, Jin and Yang, Bowen and Ding, Zhiming},
title = {A Novel UAV Aerial Vehicle Detection Method Based on Attention Mechanism and Multi-Scale Feature Cross Fusion},
year = {2021},
isbn = {9781450389273},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3460268.3460276},
doi = {10.1145/3460268.3460276},
abstract = {With the rapid development of artificial intelligence science, more and more researchers try to use deep learning to train neural networks and have achieved great success in object detection. Vehicle detection based on UAV image is a special field of object detection. Due to the low resolution of the vehicle object, complex background, and less image information, it is challenging to extract robust visual and spatial features from the depth network and accurately locate the object in complex scenes. In this paper, combining the characteristics of vehicles in aerial images, we design a novel feature pyramid network called channel-spatial attention fused feature pyramid network (CSF-FPN) with Faster R-CNN as the basic framework. In CSF-FPN, a hybrid attention mechanism and feature cross-fusion module are introduced, so that feature maps can be generated with enhanced spatial and channel interdependence to extract richer semantic information. After our CSF-FPN is integrated into the Faster R-CNN network, the detection performance of small objects is greatly improved. The experimental results based on the VEDIA Dataset showed that the proposed framework could effectively detect the vehicle in large scene azimuth. Compared with the existing advanced methods, mAP and F1-score are improved.},
booktitle = {2021 2nd International Conference on Artificial Intelligence in Electronics Engineering},
pages = {51–59},
numpages = {9},
keywords = {feature pyramid, UAV image, vehicle detection, attention mechanism, deep learning},
location = {Phuket, Thailand},
series = {AIEE 2021}
}

@inproceedings{10.1145/3293663.3297155,
author = {Al Shibli, Murad and Marques, Pascual and Spiridon, Elena},
title = {Artificial Intelligent Drone-Based Encrypted Machine Learning of Image Extraction Using Pretrained Convolutional Neural Network (CNN)},
year = {2018},
isbn = {9781450366410},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3293663.3297155},
doi = {10.1145/3293663.3297155},
abstract = {Recently Pretrained Convolutional Neural Networks (CNNs) have proven its effectiveness in image extraction and classification. This powerful feature of CNNs in image processing is facilitated by machine learning to train and classify big data. Image capturing and security transformation are considered as a central necessity of remote sensing imagery of unmanned aerial vehicles (UAVs) and drones. This paper presents a novel artificial intelligent drone-based encrypted machine learning of image classification using a pertained CNN and image encryption-decryption by utilizing singular value decomposition (SVD) and XOR-Secret-Key block cipher cryptology. Initially, pretrained convolutional neural networks (CNN) are extensively used to extract and classify image features making advantage of machine learning training tools features. Training of partial set of image data can be performed to test, classify and label the untrained image data. Pretrained CNN can classify images into object categories. Afterward, the CNN the classified image output is transformed into a digital matrix using SVD and identifies its associated eigenvalues. These eigenvalues are then converted into a binary code. The image data encryption is implemented according to suggested keys. The first part applies the exclusive OR (XOR) operation of the eigenvalues with a selected cipher key. Meanwhile, the second part implements the XOR operation of the output of part one with a randomly generated key using Poisson distribution. The last step in the encryption will be obtained by generating a non-real SVD decomposition matrix; according to which a non-readable image will be resulted. The original image-matrix can be constructed by reversing the process using the security key-cipher block (Poisson Distribution Key and Stand-alone Cipher Code). Finally, SVD image processing results are demonstrated to verify the effectiveness and security of the applied approach that can be implemented for different images.},
booktitle = {Proceedings of the 2018 International Conference on Artificial Intelligence and Virtual Reality},
pages = {72–82},
numpages = {11},
keywords = {Drone, Image extraction, XOR, CNN, SVD, Machine learning, UAV, Artificial intelligent, Pretrained convolutional neural networks, Cryptology, Poisson Distribution},
location = {Nagoya, Japan},
series = {AIVR 2018}
}

@inproceedings{10.1145/3414045.3415947,
author = {Al-Hilo, Ahmed and Samir, Moataz and Assi, Chadi and Sharafeddine, Sanaa and Ebrahimi, Dariush},
title = {Cooperative Content Delivery in UAV-RSU Assisted Vehicular Networks},
year = {2020},
isbn = {9781450381055},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3414045.3415947},
doi = {10.1145/3414045.3415947},
abstract = {Intelligent Transportation Systems (ITS) are gaining substantial attention owing to the great benefits offered to the vehicle users. In ITS paradigm, content data is normally obtained from road side units (RSUs). However, in some scenarios, terrestrial networks are partially/temporarily out-of-service. Unmanned Aerial Vehicle (UAV) or drone cells are expected to be one of the pillars of future networks to assist the vehicular networks in such scenarios. To this end, we propose a collaborative framework between UAVs and in-service RSUs to partial service vehicles. Our objective is to maximize the amount of downloaded contents to vehicles while considering the dynamic nature of the network. Motivated by the success of machine learning (ML) techniques particularly deep Reinforcement learning in solving complex problems, we formulate the scheduling and content management policy problem as a Markov Decision Process (MDP) where the system state space considers the vehicular network dynamics. Proximal Policy Optimization (PPO) is utilized to govern the content decisions in the vehicular network. The simulation-based results show that during the mission time, the proposed algorithm learns the vehicular environment and its dynamics to handle the complex action space.},
booktitle = {Proceedings of the 2nd ACM MobiCom Workshop on Drone Assisted Wireless Communications for 5G and Beyond},
pages = {73–78},
numpages = {6},
keywords = {UAV, RSU, PPO, content delivery},
location = {London, United Kingdom},
series = {DroneCom '20}
}

@inbook{10.1145/3485190.3485232,
author = {Zhang, Lu and Yu, Xueying and Zhang, Shuyi},
title = {Research on Collaborative and Confrontation of UAV Swarms Based on SAC-OD Rules},
year = {2021},
isbn = {9781450384278},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3485190.3485232},
abstract = {With the introduction of the new generation of artificial intelligence technology into the military field, unmanned aerial vehicle (UAV) swarm operation, as an important form of intelligent operation, has attracted the attention of various countries. In this paper, we consider the problem of coordinated confrontation between UAV swarms in the plane area. An improved “SAC-OD” rules and combat strategy of UAV swarm are employed to establish the decision-making model for UAV swarm conflict where each UAV in the swarm is regarded as an independent individual. With the introduction of SAC-OD, each UAV keeps on interacting with its neighboring environment and the UAV swarm conflict is dynamic. Simulation experiments are conducted using MATLAB and the results demonstrate the effectiveness of the built decision-making model for UAV swarm conflict.},
booktitle = {2021 4th International Conference on Information Management and Management Science},
pages = {273–278},
numpages = {6}
}

@inproceedings{10.1145/3321408.3321414,
author = {Grewe, Lynne and Stevenson, Garrett},
title = {Seeing Eye Drone: A Deep Learning, Vision-Based UAV for Assisting the Visually Impaired with Mobility},
year = {2019},
isbn = {9781450371582},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3321408.3321414},
doi = {10.1145/3321408.3321414},
abstract = {Seeing Eye Drone assists low-vision persons with environment awareness performing exploration and obstacle detection. The modalities of 3D (stereo) and 2D vision on a drone are compared for this task. Different deep-learning systems are developed including 2D only and 3D+2D networks. Comparisons of retrained networks versus training from scratch are also made and approximately 34,000 samples were collected for training and the resulting SSD CNN architecture is used to determine a user's location and direction of travel. A second network identifies locations of common objects in the scene. The object locations are then compared with the user location/heading and depth data to determine whether they represent obstacles. Obstacles determined to be in the user's region of interest are communicated to the visually-impaired user via Text-to-Speech. Real data from outdoor drone flights that communicate with an Android based application are shown.},
booktitle = {Proceedings of the ACM Turing Celebration Conference - China},
articleno = {110},
numpages = {5},
keywords = {computer vision, blind/ low vision, machine learning, assistive technology, drone},
location = {Chengdu, China},
series = {ACM TURC '19}
}

@inproceedings{10.1145/3206185.3206188,
author = {Zhang, Xiaonan and Luo, Pengcheng and Hu, Xinwu},
title = {Defense Success Rate Evaluation for UAV Swarm Defense System},
year = {2018},
isbn = {9781450364126},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3206185.3206188},
doi = {10.1145/3206185.3206188},
abstract = {Unmanned aerial vehicle (UAV) swarms will play important roles in future warfare. Given the worldwide advances in unmanned systems, UAV swarms pose an increasing threat to traditional defensive methods. This paper addresses the concept of a defensive UAV swarm launched from a sea-based platform. To simulate and analyze this this system, an agent-based model is developed, and the defense success rate (DSR) is proposed as a metric of effectiveness, which can avoid inaccuracies of evaluation in a single simulation result. Then single-factor experiments are conducted to analyze the impacts of different design factors, and some reasonable and comprehensive suggestions are provided to improve the DSR. This paper showcases the important meaning of artificial intelligence in the study of UAV swarm combat and deeply analyzes the impacts of various factors on UAV swarm defense system which can be used for future engineering designs.},
booktitle = {Proceedings of the 2nd International Conference on Intelligent Systems, Metaheuristics &amp; Swarm Intelligence},
pages = {127–132},
numpages = {6},
keywords = {factorial experiments, DSR, evaluation, simulation, UAV swarm},
location = {Phuket, Thailand},
series = {ISMSI '18}
}

@inproceedings{10.1145/3457682.3457739,
author = {Cai, Tianxiao and Zhang, Sheng and Tan, Boyu},
title = {AEE-Net: An Efficient End-to-End Dehazing Network in UAV Imaging System},
year = {2021},
isbn = {9781450389310},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3457682.3457739},
doi = {10.1145/3457682.3457739},
abstract = {Because it can provide real-time images for the first time, UAV plays a massive role in disaster relief, environmental observation, and information collection. However, the quality of images collected by UAV is always affected by fog. Therefore, the research on how to remove the fog in the image becomes more and more critical. In recent years, the role of convolutional neural networks (CNN), which can automatically extract features and efficiently process high-dimensional data, has received more and more attention in many disciplines. To improve the imaging quality of UAV in a foggy environment, this paper proposes an image dehazing model built with a convolutional neural network (CNN), called an effective end-to-end dehazing Network (AEE-Net). Our proposed method has a faster running speed than traditional models due to the simple structure of the model and the design based on the modified atmospheric scattering model. Our method combines the characteristics of dehazing processes and the advantages of deep learning. Experimental results on the training set and raw images show that the proposed method has better performance than traditional methods. This method can improve the quality of UAV-captured images under foggy conditions and can meet the input requirements of UAV vision tasks.},
booktitle = {2021 13th International Conference on Machine Learning and Computing},
pages = {397–403},
numpages = {7},
keywords = {UAV, Atmosphere scattering model, CNN, Dehazing vessel, Image restoration, Machine learning},
location = {Shenzhen, China},
series = {ICMLC 2021}
}

@inproceedings{10.1145/3414045.3415940,
author = {Wang, Xiaoding and Hu, Jia and Lin, Hui},
title = {An Intelligent UAV Based Data Aggregation Strategy for IoT after Disaster Scenarios},
year = {2020},
isbn = {9781450381055},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3414045.3415940},
doi = {10.1145/3414045.3415940},
abstract = {The study on data aggregation in Internet of Things (IoT) has drawn a great attention in recent years. Since a large-scale disaster could damage the entire communication network and cut off data aggregation completely, an Intelligent UAV based Data Aggregation Strategy, named (IDAS), is proposed for after disaster scenarios in IoT. Specifically, IDAS first employs an task distribution mechanism to achieve the trade-off between the aggregation ratio and the energy cost. Then, a deep reinforcement learning method is developed for UAV route design to perform corresponding task. Thus, all data are aggregated toward the rescue headquarter by UAV deployment. The simulation results indicate that IDAS has a higher aggregation ratio and a lower energy cost while compared with contemporary strategies.},
booktitle = {Proceedings of the 2nd ACM MobiCom Workshop on Drone Assisted Wireless Communications for 5G and Beyond},
pages = {97–101},
numpages = {5},
keywords = {IoT, deep reinforcement learning, data aggregation, UAV},
location = {London, United Kingdom},
series = {DroneCom '20}
}

@inproceedings{10.1145/3503047.3503129,
author = {Xu, Li and Liu, Juan and Xie, Lingfu and He, Xiaofan},
title = {Multi-UAV Navigation and Recharging for Fair and Sustainable Coverage in Wireless Networks},
year = {2021},
isbn = {9781450385862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3503047.3503129},
doi = {10.1145/3503047.3503129},
abstract = { Unmanned aerial vehicles (UAVs) arouse considerable interest in coverage applications such as emergency communication. This paper attempts to address the multi-UAV navigation problem for fair coverage in wireless networks, where a charging station is deployed to recharge the UAVs. It is challenging to control each UAV to provide coverage collaboratively such that each point-of-interest in the target area is covered fairly for a reasonable time duration. The problem of joint multi-UAV navigation and recharging is formulated into a Markov decision process with the objective to maximize the fair coverage score per unit of energy with recharging reward. The state-of-the-art deep reinforcement learning method, coined by us as PPO-UNC (proximal strategy optimization for multi- UAV navigation and recharging), is employed to find the solution efficiently. Simulation results show the superiority of the proposed PPO-UNC strategy as compared to two baseline policies. },
booktitle = {2021 3rd International Conference on Advanced Information Science and System (AISS 2021)},
articleno = {76},
numpages = {6},
keywords = {UAV, Coverage, Fairness index, Deep Reinforcement Learning, PPO},
location = {Sanya, China},
series = {AISS 2021}
}

@inproceedings{10.1145/3487923.3487926,
author = {Ukaegbu, Uchechi F. and Tartibu, Lagouge K. and Okwu, Modestus O. and Olayode, Isaac O.},
title = {Deep Learning Application in Diverse Fields with Plant Weed Detection as a Case Study},
year = {2021},
isbn = {9781450385756},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3487923.3487926},
doi = {10.1145/3487923.3487926},
abstract = {Machine learning applications have gained popularity over the years as more advanced algorithms like the deep learning (DL) algorithm are being employed in signal identification, classification and detection of cracks or faults in structures. The DL algorithm has broader applications compared to other machine learning systems and it is a creative algorithm capable of processing data, creating pattern, interpreting information due to its high level of accuracy in pattern recognition under stochastic conditions. This research gives an exposition of DL in diverse areas of operations with a focus on plant weed detection which is inspired by the need to treat a specific class of weed with a particular herbicide. A Convolutional Neural Network (CNN) model was trained through transfer learning on a pre-trained ResNet50 model and the performance was evaluated using a random forest (RF) classifier, the trained model was deployed on a raspberry pi for prediction of the test data. Training accuracies of 99% and 93% were obtained for the CNN and RF classifier respectively. Some recommendations have been proffered to improve inference time such as the use of better embedded systems such as the Nvidia Jetson TX2, synchronizing DL hardware accelerators with appropriate optimization techniques. A prospect of this work would be to incorporate an embedded system, deployed with DL algorithms, on an unmanned aerial vehicle or ground vehicle. Overall, it is revealed from this study that DL is highly efficient in every sector and can improve the accuracy on automatic detection of systems in especially in this era of Industry 4.0.},
booktitle = {Proceedings of the International Conference on Artificial Intelligence and Its Applications},
articleno = {3},
numpages = {9},
keywords = {Random forest, Convolutional neural network, fourth industrial revolution, Deep learning algorithm, Agriculture},
location = {Virtual Event, Mauritius},
series = {icARTi '21}
}

@inproceedings{10.1145/3193025.3193051,
author = {Kim, Seongyong and Park, Seula and Yu, Kiyun},
title = {Proposal for a Method of Extracting Road Layers from Remote Sensing Images Using Conditional GANs},
year = {2018},
isbn = {9781450364027},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3193025.3193051},
doi = {10.1145/3193025.3193051},
abstract = {With the recent advances in unmanned aerial vehicle (UAV) technology, remote sensing images have become relatively easy to obtain and their accuracy has increased enough to be able to handle land information. Therefore, there is a growing demand to utilize remote sensing images for extracting semantic objects Conventional methods are mainly focused on pixel-based classification and recently people commonly use convolutional neural networks, which post processing is required to linearize roads that are cut off and accurately shape the contours of buildings. We propose the use of a generative model to carry out this post processing in the networks. Using conditional Generative Adversarial Network (GANs), we translate remote sensing images into map-based images from which roads are easily extracted, while retaining the underlying structure. Next, we extract road layers from the generated images. Through this approach, it is possible to achieve the same effect as if complicating post processing were done in the networks during the object extraction process.},
booktitle = {Proceedings of the 2nd International Conference on Digital Signal Processing},
pages = {84–87},
numpages = {4},
keywords = {Satellite images, Generative adversarial networks, Remote sensing, Deep learning, Extracting roads},
location = {Tokyo, Japan},
series = {ICDSP 2018}
}

@inproceedings{10.5555/2735522.2735579,
author = {Heinemann, Stephan and M\"{u}ller, Hausi A. and Suleman, Afzal},
title = {Smart Autoflight Control Systems},
year = {2014},
publisher = {IBM Corp.},
address = {USA},
abstract = {Current research envisions shifting the role of flight crews towards mission supervisors who make decisions at a very high level of abstraction -- decisions that guide complex systems automatically towards a defined goal.The applicable aircraft condition and contextual information towards the development of smarter Automatic Flight Control Systems (AFCSs) supporting this vision are highlighted. These include the aircraft's systems and capabilities state, the airspace structure, weather and traffic situation, the surrounding terrain and its population density, facilities, as well as human factors and operational aspects. The presented concept particularly aims at integrating Air Traffic Control (ATC) and the operational environment into the automatic decision making process.Suitable Artificial Intelligence (AI) methods and algorithms shall be studied and evaluated on a small commercially available Unmanned Air Vehicle (UAV). The Unmanned Aircraft System (UAS) will be extended to support simulated interactions with ATC and mission control. The resulting system shall be able to perform missions on the basis of abstract goal descriptions that may change during the flight and require revised online flight planning and an adapted aircraft systems configuration in a hard real-time environment constrained by bounded rationality and bounded reactivity.Such an UAS will enable higher-level command and control as well as increasingly flexible airborne missions.},
booktitle = {Proceedings of 24th Annual International Conference on Computer Science and Software Engineering},
pages = {343–346},
numpages = {4},
location = {Markham, Ontario, Canada},
series = {CASCON '14}
}

@inproceedings{10.1145/3414045.3415948,
author = {Chen, Yun and Lin, Xingqin and Khan, Talha and Mozaffari, Mohammad},
title = {A Deep Learning Approach to Efficient Drone Mobility Support},
year = {2020},
isbn = {9781450381055},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3414045.3415948},
doi = {10.1145/3414045.3415948},
abstract = {The growing deployment of drones in a myriad of applications relies on seamless and reliable wireless connectivity for safe control and operation of drones. Cellular technology is a key enabler for providing essential wireless services to drones flying in the sky. Existing cellular networks targeting terrestrial usage can support the initial deployment of low-altitude drone users, but there are challenges such as mobility support. In this paper, we propose a novel handover framework for providing efficient mobility support and reliable wireless connectivity to drones served by a terrestrial cellular network. Using tools from deep reinforcement learning, we develop a deep Q-learning algorithm to dynamically optimize handover decisions to ensure robust connectivity for drone users. Simulation results show that the proposed framework significantly reduces the number of handovers at the expense of a small loss in signal strength relative to the baseline case where a drone always connect to a base station that provides the strongest received signal strength.},
booktitle = {Proceedings of the 2nd ACM MobiCom Workshop on Drone Assisted Wireless Communications for 5G and Beyond},
pages = {67–72},
numpages = {6},
keywords = {non-terrestrial networks, handover, mobility management, UAV, drone, reinforcement learning, 5G, deep learning},
location = {London, United Kingdom},
series = {DroneCom '20}
}

@inbook{10.1145/3377812.3381398,
author = {Pyrgies, John},
title = {Towards DO-178C Certification of Adaptive Learning UAV Agents Designed with a Cognitive Architecture},
year = {2020},
isbn = {9781450371223},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3377812.3381398},
abstract = {Adaptive and Learning Agents (ALAs) bring computational intelligence to their Cyber Physical host systems to adapt to novel situations encountered in their complex operational environment. They do so by learning from their experience to improve their performance. RTCA DO-178C specifies a stringent certification process for airborne software which represents several challenges when applied to an ALA in regards of functional completeness, functional correctness, testability and adaptability. This research claims that it is possible to certify an Adaptive Learning Unmanned Aerial Vehicle (UAV) Agent designed as per a Cognitive Architecture with current DO-178C certification process when leveraging a qualified tool (DO-330), Model-Based Development and Verification (DO-331) and Formal Methods (DO-333). The research consists in developing, as a case study, an ALA embedded in a UAV aimed at neutralizing rogue UAVs in the vicinity of civil airports and test it in the field. This article is the plan to complete, by end 2022, a dissertation currently in its confirmation phase.},
booktitle = {Proceedings of the ACM/IEEE 42nd International Conference on Software Engineering: Companion Proceedings},
pages = {174–177},
numpages = {4}
}

@inproceedings{10.1145/3401895.3401931,
author = {de Sousa Paula, Patricia and Sarmento, Wellington W. Ferreira and Paillard, Gabriel A. Louis and de Castro, Miguel Franklin},
title = {Using Swarm Intelligence in Unmanned Aerial Vehicles for Unknown Location Fixed Target Search},
year = {2020},
isbn = {9781450377119},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3401895.3401931},
doi = {10.1145/3401895.3401931},
abstract = {The context of this research is the use of bioinspired algorithms applied to unmanned aerial vehicles (UAV) to search for a fixed target of unknown location. A target can be a lost human being or a broken vehicle, for example. Swarm algorithms used with UAVs can be adapted to perform better than a simple scanning algorithm such as Parallel Path Finder. The Particle Swarm Optimization and Bat Algorithm algorithms are compared using constraints such as UAV battery life and the size of the search area. Thus, the best solution to this problem is shown, among the adapted ones, considering the applied restrictions.},
booktitle = {Proceedings of the 10th Euro-American Conference on Telematics and Information Systems},
articleno = {20},
numpages = {8},
keywords = {mobile, bioinspired algorithms, UAV, swarm intelligence},
location = {Aveiro, Portugal},
series = {EATIS '20}
}

@article{10.1145/3418205,
author = {Garg, Prateek and Chakravarthy, Anirudh Srinivasan and Mandal, Murari and Narang, Pratik and Chamola, Vinay and Guizani, Mohsen},
title = {ISDNet: AI-Enabled Instance Segmentation of Aerial Scenes for Smart Cities},
year = {2021},
issue_date = {August 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {21},
number = {3},
issn = {1533-5399},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3418205},
doi = {10.1145/3418205},
abstract = {Aerial scenes captured by UAVs have immense potential in IoT applications related to urban surveillance, road and building segmentation, land cover classification, and so on, which are necessary for the evolution of smart cities. The advancements in deep learning have greatly enhanced visual understanding, but the domain of aerial vision remains largely unexplored. Aerial images pose many unique challenges for performing proper scene parsing such as high-resolution data, small-scaled objects, a large number of objects in the camera view, dense clustering of objects, background clutter, and so on, which greatly hinder the performance of the existing deep learning methods. In this work, we propose ISDNet (Instance Segmentation and Detection Network), a novel network to perform instance segmentation and object detection on visual data captured by UAVs. This work enables aerial image analytics for various needs in a smart city. In particular, we use dilated convolutions to generate improved spatial context, leading to better discrimination between foreground and background features. The proposed network efficiently reuses the segment-mask features by propagating them from early stages using residual connections. Furthermore, ISDNet makes use of effective anchors to accommodate varying object scales and sizes. The proposed method obtains state-of-the-art results in the aerial context.},
journal = {ACM Trans. Internet Technol.},
month = {aug},
articleno = {66},
numpages = {18},
keywords = {deep learning, aerial scenes, Smart cities, instance segmentation, object detection, UAVs}
}

@inproceedings{10.1145/3313151.3313163,
author = {Li, Yilan and Eslamiat, Hossein and Wang, Ningshan and Zhao, Ziyi and Sanyal, Amit K. and Qiu, Qinru},
title = {Autonomous Waypoints Planning and Trajectory Generation for Multi-Rotor UAVs},
year = {2019},
isbn = {9781450366991},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3313151.3313163},
doi = {10.1145/3313151.3313163},
abstract = {Autonomous trajectory generation in a complex environment is a challenging task for multi-rotor unmanned aerial vehicles (UAVs), which have high maneuverability in three-dimensional motion. Safe and effective operations for these UAVs demand obstacle avoidance strategies and advanced trajectory planning and control schemes for stability and energy efficiency. To solve those problems in one framework analytically is extremely challenging when the UAV needs to fly large distance in a complex environment. To address this challenge, a two-level optimization strategy is adopted. At the higher-level, a sequence of waypoints is selected that lead the UAV from its current position to the destination. At the lower-level, an optimal trajectory is generated between each pair of adjacent waypoints analytically. While the goal of trajectory generation is to maintain the stability of the UAV, the goal of the waypoints planning is to select waypoints with the lowest control thrust consumption throughout the entire trip while avoiding collisions with obstacles. The entire framework is implemented using deep reinforcement learning, which learns the highly complicated and non-linear interaction between those two levels, and the impact from the environment. A progressive learning strategy is investigated that not only reduces convergence time but also improves result quality. We further investigate and provide results regarding the tuning of gains in the optimal trajectory scheme using genetic algorithm. The experimental results demonstrate that our proposed approach is able to generate a list of obstacle-free waypoints with minimum control energy and develop an optimal trajectory with optimized platform velocity, acceleration, jerk and control thrust.},
booktitle = {Proceedings of the Workshop on Design Automation for CPS and IoT},
pages = {31–40},
numpages = {10},
keywords = {multi-rotor UAV, optimal trajectory generation, deep reinforcement learning, waypoints planning},
location = {Montreal, Quebec, Canada},
series = {DESTION '19}
}

@inproceedings{10.1145/3281548.3281556,
author = {Xu, Yingxiao and Pan, Long and Du, Chun and Li, Jun and Jing, Ning and Wu, Jiangjiang},
title = {Vision-Based UAVs Aerial Image Localization: A Survey},
year = {2018},
isbn = {9781450360364},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3281548.3281556},
doi = {10.1145/3281548.3281556},
abstract = {Unmanned aerial vehicles (UAVs) have been increasingly used in earth observation, public safety, military and civilian applications due to its portability, high mobility and flexibility. In some GPS-denied environments, accurate drone position cannot be obtained due to occlusion, multi-path interference and other factors. While understanding and localization the content of the images is vital for earth observation, map revision, multi-source image fusion, disaster relief, smart city and other applications. The progress of computer vision and convolutional neural networks(CNNs) in image processing provide a promising solution to locate UAVs aerial image and mapping to the large-scale reference image. Firstly, key localization techniques based on image retrieval-----image description, image matching and position mapping are summarized considering the characteristics of UAVs aerial images. And then, image localization based on extracting deep semantic features and image localization based on classification method by subdividing areas are recommended. Throughout this paper, we will have an insight into the prospect of the UAVs image localization and the challenges to be faced.},
booktitle = {Proceedings of the 2nd ACM SIGSPATIAL International Workshop on AI for Geographic Knowledge Discovery},
pages = {9–18},
numpages = {10},
keywords = {Deep Learning, Image Description, Semantic, UAVs Aerial Image, Vision-based Image Localization},
location = {Seattle, WA, USA},
series = {GeoAI'18}
}

@inbook{10.1145/3387168.3387202,
author = {Ayhan, Bulent and Kwan, Chiman},
title = {Practical Issues in Contingency Planning for UAVs with Engine Failures},
year = {2019},
isbn = {9781450376259},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3387168.3387202},
abstract = {Unmanned Air Vehicles (UAV), also known as Unmanned Air Systems (UAS), are gaining more attention in recent years. Some potential commercial applications with UAVs may include small cargo transport, search and rescue operations, drought and pest monitoring, etc. It is well-known that UAVs are less reliable as compared to manned aircraft. This is probably one of the consequential reasons that Federal Aviation Administration (FAA) is hesitant to open up the national airspace (NAS) and imposes tight restrictions to UAVs. Reliability of UAVs can be improved using engines and equipment with high quality and fault diagnostic algorithms using machine learning and artificial intelligence techniques, and robust and fault tolerant controllers. Despite the above measures, engine and equipment malfunctions may still appear in various applications. In this paper, we summarize some recent research results by us with respect to engine failures encountered in UAVs. Due to engine failure, there is limited hanging time and the mishap UAV needs to land preferably in an unpopulated area. In particular, we explicitly address some practical issues related to engine failures.},
booktitle = {Proceedings of the 3rd International Conference on Vision, Image and Signal Processing},
articleno = {50},
numpages = {6}
}

@inproceedings{10.1145/3378184.3378185,
author = {Greco, Antonio and Pironti, Christopher and Saggese, Alessia and Vento, Mario and Vigilante, Vincenzo},
title = {A Deep Learning Based Approach for Detecting Panels in Photovoltaic Plants},
year = {2020},
isbn = {9781450376303},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3378184.3378185},
doi = {10.1145/3378184.3378185},
abstract = {Photovoltaic (PV) panels are a clean and widespread way to produce renewable energy from sunlight; at the same time, such plants require maintenance, since solar panels can be affected by many types of damaging factors and have a limited yet variable lifespan. With the impressive growth of such PV installations, it is in the public eye the need of a cheap and effective way to continuously monitor the state of the plants and a standard technique designed to promptly replace broken modules, in order to prevent drops in the energy production. Since the faults mainly appear as Hot Spots on the surface of the PV panels, aerial thermal imaging can be used to diagnose such problems and also locate them in huge plants. To this aim, dedicated automatic Computer Vision methods are able to automatically find hot spots from thermal images, where they appear as white stains. In these methods a fundamental step is the segmentation of the PV panels, which allows to automatically detect each module.In this paper, we address the problem of PV Panel Detection using a Convolutional Neural Network framework called YOLO. We demonstrate that it is able to effectively and efficiently segment panels from an image. The method is quantitatively evaluated and compared to existing PV panel detection approaches on the biggest publicly available benchmark dataset; the experimental results confirm its robustness.},
booktitle = {Proceedings of the 3rd International Conference on Applications of Intelligent Systems},
articleno = {1},
numpages = {7},
keywords = {photovoltaic, UAV, deep learning, object detection},
location = {Las Palmas de Gran Canaria, Spain},
series = {APPIS 2020}
}

@inproceedings{10.1145/3414045.3415951,
author = {Moustafa, Nour and Jolfaei, Alireza},
title = {Autonomous Detection of Malicious Events Using Machine Learning Models in Drone Networks},
year = {2020},
isbn = {9781450381055},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3414045.3415951},
doi = {10.1145/3414045.3415951},
abstract = {Drone systems, the so-called Unmanned Autonomous Vehicles (UAVs), have been widely employed in military and civilian sectors. Drone systems have been used for cyber warfare, warfighting and surveillance purposes of modern military and civilian applications. However, they have increasingly suffered from sophisticated malicious activities that exploit their vulnerabilities through network communications. As drones comprise a complex infrastructure as piloted aircraft but without operators, they still need a reliable security control to assert their safe operations. This paper proposes an autonomous intrusion detection scheme for discovering advanced and sophisticated cyberattacks that exploit drone networks. A testbed was configured to launch malicious events against a drone network for collecting legitimate and malicious observations and evaluate the performances of machine learning in real-time. Machine learning algorithms, including decision tree, k-nearest neighbors, naive Bayes, support vector machine and deep learning multi-layer perceptron, were trained and evaluated using the data collections, with promising results in terms of detection accuracy, false alarm rates, and processing times.},
booktitle = {Proceedings of the 2nd ACM MobiCom Workshop on Drone Assisted Wireless Communications for 5G and Beyond},
pages = {61–66},
numpages = {6},
keywords = {network systems, drones, machine and deep learning algorithms, intrusion detection},
location = {London, United Kingdom},
series = {DroneCom '20}
}

@inbook{10.1145/3387168.3387179,
author = {Han, Seongkyun and Kwon, Juwon and Kwon, Soonchul},
title = {Real-Time Small Object Detection Model in the Bird-View UAV Imagery},
year = {2019},
isbn = {9781450376259},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3387168.3387179},
abstract = {Object detection is one of the most important parts of UAV applications. UAV imagery has object distortion and small-sized objects peculiarities. In this paper, we propose a D-RFB module which can enhance the expressive power of the feature map, and D-RFBNet300 attached D-RFB module so that detect small objects in the UAV imagery more accurately. And we propose the UAV-cars dataset including peculiarities of UAV imagery. Our D-RFBNet300 trained on MS COCO achieved 21% mAP with 45 FPS speed, which is the highest score among the other SSD type object detectors. In addition, our D-RFBNet300 trained on UAV-cars dataset achieved 99.24% AP at 10m altitude and highest AP at every test set altitude from 15m to 30m with 57FPS speed.},
booktitle = {Proceedings of the 3rd International Conference on Vision, Image and Signal Processing},
articleno = {47},
numpages = {7}
}

@inproceedings{10.1145/3338533.3366561,
author = {Yu, Hongyang and Li, Guorong and Zhang, Weigang and Yao, Hongxun and Huang, Qingming},
title = {Self-Balance Motion and Appearance Model for Multi-Object Tracking in UAV},
year = {2019},
isbn = {9781450368414},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3338533.3366561},
doi = {10.1145/3338533.3366561},
abstract = {Under the tracking-by-detection framework, multi-object tracking methods try to connect object detections with target trajectories by reasonable policy. Most methods represent objects by the appearance and motion. The inference of the association is mostly judged by a fusion of appearance similarity and motion consistency. However, the fusion ratio between appearance and motion are often determined by subjective setting. In this paper, we propose a novel self-balance method fusing appearance similarity and motion consistency. Extensive experimental results on public benchmarks demonstrate the effectiveness of the proposed method with comparisons to several state-of-the-art trackers.},
booktitle = {Proceedings of the ACM Multimedia Asia},
articleno = {12},
numpages = {6},
keywords = {Multi-object tracking, UAV, Neural networks},
location = {Beijing, China},
series = {MMAsia '19}
}

@inproceedings{10.5555/2499592.2499600,
author = {McCune, R. Ryan and Madey, Gregory R.},
title = {Agent-Based Simulation of Cooperative Hunting with UAVs},
year = {2013},
isbn = {9781627480291},
publisher = {Society for Computer Simulation International},
address = {San Diego, CA, USA},
abstract = {Swarm intelligent systems are simple but robust, capable of solving complex problems that no single agent could attempt. While technological advancements have driven development of multi-agent systems across disciplines, emergent behavior inherent to swarms is a desirable yet difficult property to exploit. Solutions utilizing swarm behavior have been proposed for the Cooperative Cleaning Problem, which is applicable to UAVs cooperatively searching for evasive targets. This work proposes a new agent behavior capable of partitioning a search area, and when combined with previous swarm solutions, forms an optimization problem of how to best assign swarms to a complex topology. Agent-based simulations are developed to test swarm solutions.},
booktitle = {Proceedings of the Agent-Directed Simulation Symposium},
articleno = {8},
numpages = {6},
keywords = {agent-based simulation, cooperative control, mission planning, UAV swarm, swarm intelligence},
location = {San Diego, California},
series = {ADSS 13}
}

@inproceedings{10.1145/3508546.3508620,
author = {Fang, Jiayong and Zhou, Zhongliang and Wang, Huanbin and Sheng, Sheng and Chen, Shitao},
title = {Modeling and Simulation of UAV Autonomous Obstacle Avoidance Based on DQN},
year = {2021},
isbn = {9781450385053},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3508546.3508620},
doi = {10.1145/3508546.3508620},
abstract = {During the obstacle avoidance process of UAV, the route planning and obstacle avoidance decision-making is dynamic and sequential due to the change of obstacles in real time, so it is difficult to build a dynamic and accurate route planning model. This paper breaks through the traditional research thinking of route modeling and optimization solution for UAV obstacle avoidance, and applies deep reinforcement learning to UAV autonomous obstacle avoidance decision-making; through designing the environment model, autonomous decision-making model and DQN algorithm model for UAV obstacle avoidance, four simulation experimental environments for UAV obstacle avoidance are constructed to verify the superiority and effectiveness of deep reinforcement learning in solving the decision-making problems related to dynamic model and timing sequence, and provide a new solution for future UAV route planning.},
booktitle = {2021 4th International Conference on Algorithms, Computing and Artificial Intelligence},
articleno = {74},
numpages = {6},
keywords = {Deep Q Network, Autonomous Obstacle Avoidance, Unmanned Aerial Vehicle},
location = {Sanya, China},
series = {ACAI'21}
}


@ARTICLE{9093954,
author={Zhang, Yin and Li, Yujie and Wang, Ranran and Hossain, M. Shamim and Lu, Huimin},
journal={IEEE Transactions on Intelligent Transportation Systems}, title={Multi-Aspect Aware Session-Based Recommendation for Intelligent Transportation Services},
year={2021},
volume={22},
number={7},
pages={4696-4705},
abstract={In the intelligent transportation system, the session data usually represents the users' demand. However, the traditional approaches only focus on the sequence information or the last item clicked by the user, which cannot fully represent user preferences. To address this issue, this paper proposes an Multi-aspect Aware Session-based Recommendation (MASR) model for intelligent transportation services, which comprehensively considers the user's personalized behavior from multiple aspects. In addition, it developed a concise and efficient transformer-style self-attention to analyze the sequence information of the current session, for accurately grasping the user's intention. Finally, the experimental results show that MASR is available to improve user satisfaction with more accurate and rapid recommendations, and reduce the number of user operations to decrease the safety risk during the transportation service.},
keywords={Transportation;Data models;Machine learning;Navigation;Recurrent neural networks;Safety;Multi-aspect;self-attention;session-based recommendation;intelligent transportation services},
doi={10.1109/TITS.2020.2990214},
ISSN={1558-0016},
month={July},}
@INPROCEEDINGS{9574743,
author={Lin, Yong-Ye and Chan, Fu-Chun and Wei, Min-Chi and Sun, Chi-Chia and Kuo, Wen-Kai and Chen, Chih-Yung},
booktitle={2021 IEEE 4th International Conference on Knowledge Innovation and Invention (ICKII)}, title={Application of Mm-Wave Radar Detection Technology and Artificial Intelligence Learning to Implement the Real-Time and Predictive Design of Parking Spaces},
year={2021},
volume={},
number={},
pages={20-23},
abstract={In modern cities, the number of vehicles is increasing day by day, which makes it difficult to find parking spaces during travel and takes a lot of time to drive at a slow speed. This not only causes local traffic chaos but also interferes with the driving efficiency of the entire roads. This phenomenon is a common problem faced by modern metropolitan areas. To reduce the time spent in finding parking spaces, fuel consumption, and carbon dioxide emissions, and to effectively improve overall driving efficiency, the systemization of urban roadside or off-street parking has become a key issue that needs attention and demonstration in so-called “smart” cities. In this paper, we have designed and applied an mm-Wave Radar to detect the presence or absence of available parking spaces, and the parking space data can be quickly uploaded to the cloud. Therefore, the status of the parking space can be updated in real-time. Based on this parking space status data, we build a Long Short-Term Memory (LSTM) model to conduct deep learning. The input data of this model includes parking space location, parking space status, and parking time factors. Using mm-Wave radar experiment with the trained LSTM output provides parking space status prediction which enables drivers to obtain parking space status before they arrive at the destination. This can save half of the drivers' time wasted in finding parking spaces and head to the smart cities.},
keywords={Space vehicles;Technological innovation;Smart cities;Spaceborne radar;Roads;Radar detection;Real-time systems;Long Short-Term Memory (LSTM);mm-Wave Radar;Smart City},
doi={10.1109/ICKII51822.2021.9574743},
ISSN={},
month={July},}
@INPROCEEDINGS{8397616,
author={Tsague, Hippolyte Djonon and Twala, Bheki},
booktitle={2017 IEEE SmartWorld, Ubiquitous Intelligence Computing, Advanced Trusted Computed, Scalable Computing Communications, Cloud Big Data Computing, Internet of People and Smart City Innovation (SmartWorld/SCALCOM/UIC/ATC/CBDCom/IOP/SCI)}, title={An electromagnetic approach to smart card instruction identification using machine learning techniques},
year={2017},
volume={},
number={},
pages={1-8},
abstract={Since the first publication, side channel leakage has been widely used for the purposes of extracting secret information, such as cryptographic keys, from embedded devices. However, in a few instances it has been utilized for extracting other information about the internal state of a computing device. In this paper, we show how to create a robust instruction-level side channel leakage profile of an embedded processor. Using the electromagnetic profile we show how to extract executed instructions from a smart card's leakage with good accuracy. In addition, we provide a comparison between several performance and recognition enhancement tools.},
keywords={Smart cards;Electromagnetics;Probes;Power demand;Microprocessors;Cryptography;Side Channel Leakage;Electromagnetic Templates;Principal Components Analysis;Linear Discriminant Analysis;Multivariate Gaussian Distribution;k-Nearest Neighbours Algorithm;Reverse Engineering},
doi={10.1109/UIC-ATC.2017.8397616},
ISSN={},
month={Aug},}
@INPROCEEDINGS{8650452,
author={Singh, Pranav Kumar and Kumar Jha, Suraj and Nandi, Sunit Kumar and Nandi, Sukumar},
booktitle={TENCON 2018 - 2018 IEEE Region 10 Conference}, title={ML-Based Approach to Detect DDoS Attack in V2I Communication Under SDN Architecture},
year={2018},
volume={},
number={},
pages={0144-0149},
abstract={The need for Internet-based services is increasing at a tremendous pace in smart cities. The driver and occupants of the vehicle access Internet, and different intelligent transportation system (ITS) related services such as real-time traffic information, parking space availability, downloading the map, etc., in a vehicle to infrastructure communication (V2I) mode. In a highly dynamic network environment like vehicular network, software-defined networking (SDN) promises to be an ideal solution. However, it also opens doors for various distributed denial of service (DDoS) attacks. An attacker can easily flood short-lived spoofed flows and exhaust network resources. This motivates us to find a solution to detect the attacks in a V2I communication under SDN. In this paper, we propose a machine learning (ML) based DDoS attack detection. The proposed system uses various ML schemes, and few of them found to be accurate with a high detection rate and a relatively low false alarm rate.},
keywords={Computer crime;Neural networks;IEEE Regions;Conferences;Vehicle-to-infrastructure;Vehicle dynamics;Machine learning},
doi={10.1109/TENCON.2018.8650452},
ISSN={2159-3450},
month={Oct},}
@INPROCEEDINGS{7366231,
author={Zehnder, Michael and Wache, Holger and Witschel, Hans-Friedrich and Zanatta, Danilo and Rodriguez, Miguel},
booktitle={2015 IEEE First International Smart Cities Conference (ISC2)}, title={Energy saving in smart homes based on consumer behavior: A case study},
year={2015},
volume={},
number={},
pages={1-6},
abstract={This paper presents a case study of a recommender system that can be used to save energy in smart homes without lowering the comfort of the inhabitants. We present an algorithm that mines consumer behavior data only and applies machine learning to suggest actions for inhabitants to reduce the energy consumption of their homes. The system looks for frequent and periodic patterns in the event data provided by the digitalSTROM home automation system. These patterns are converted into association rules, prioritized and compared with the current behavior of the inhabitants. If the system detects opportunities to save energy without decreasing the comfort level, it sends a recommendation to the inhabitants. The system was implemented and deployed to a set of test homes. The test participants were able to rate the impact of the recommendations on their comfort. This feedback was used to adjust the system parameters and make it more accurate during a second test phase. The historical data set provided by digitalSTROM contained 33 homes with 3521 devices and over 4 million events. The system produced 160 recommendations on the first phase and 120 on the second phase. The ratio of useful recommendations was close to 10%. We found out that a recommender system that uses an algorithm that mines patterns based on their confidence, independent of their frequency and periodicity, might achieve better results and a higher acceptance by users.},
keywords={Decision support systems;smart cities;smart homes;energy saving;recommender system;association rules;unsupervised learning;internet of things;IoT},
doi={10.1109/ISC2.2015.7366231},
ISSN={},
month={Oct},}
@INPROCEEDINGS{9466068,
author={Iksan, Luqmanul Hakim and Awal, Mahaputra Ilham and Fhamy, Rizky Zull and Pratama, Afis Asryullah and Basuki, Dwi Kurnia and Sukaridhoto, Sritrusta},
booktitle={2021 International Conference on Artificial Intelligence and Mechatronics Systems (AIMS)}, title={Implementation of Cloud Based Action Recognition Backend Platform},
year={2021},
volume={},
number={},
pages={1-6},
abstract={The Internet of Things (IoT) growth are rapidly in various fields such as industry 4.0, smart cities, and smart homes. Implementation of IoT for electronic assistance had been researched to increase the longevity of human life. However, not all IoT implementation as human life assistance provides action recognition monitoring on multiple elderly people, provide information such as real-time action monitoring, and real-time streaming in a mobile application. Therefore, this research intends to create a system that can receive and provide information on each elderly people who registered. The Action Recognition Backend Platform will be working as cloud computing to receive and manage input data from Edge Computing Action Recognition. This platform integrated Deep Learning, Data Analytics, Big Data Warehouse that implemented Extract, Transform, and Load (ETL) methods, communication services with MQTT, and Kafka Streaming Processor. The test result showed that the edge computing action recognition got better model accuracy performance from our last model [1], which can predict with 50,7% accuracy in 0.5 confidence threshold. Moreover, the backend platform had been successfully implemented a simple IoT paradigm and got an average delivery time of MQTT communication at 204ms, for streaming data process took an average delay of 680ms.},
keywords={Cloud computing;Computational modeling;Senior citizens;Smart homes;Predictive models;Real-time systems;Delays;Internet of Things;Cloud Computing;Edge Computing Backend Platform},
doi={10.1109/AIMS52415.2021.9466068},
ISSN={},
month={April},}
@ARTICLE{8960359,
author={Mills, Nishan and de Silva, Daswin and Alahakoon, Damminda},
journal={IEEE Internet of Things Journal}, title={Generating Situational Awareness of Pedestrian and Vehicular Movement in Urban Areas Using IoT Data Streams},
year={2020},
volume={7},
number={5},
pages={4395-4402},
abstract={Humans have continuously endeavored to enhance their sensory perception and awareness of the physical surroundings for the betterment of themselves as individuals as well as communities. Advancing this notion to the present day, the Internet of Things (IoT) provides a unique opportunity to attempt the same in an increasingly digital landscape. The prevalence and pervasiveness of IoT data streams gives us this ability to represent a situation with clarity and nuance, leading to a refined awareness of the environment. However, there are several challenges in managing the scale, velocity, and magnitude of IoT data streams, as well as the cohesive representation of these varied sources in a single frame of reference. In this article, we present a new algorithm, the deep growing self-organizing map (deep GSOM) algorithm that addresses these challenges. Deep GSOM incrementally generates a latent representation of situational awareness from high entropy to low entropy IoT data streams. It utilizes an implementation of the fuzzy integral to define a metric that can be moved across spatial and temporal situations to profile the density of congestion. We have also expanded deep GSOM into an IoT platform that can collate, aggregate, and process an entire network of IoT data streams. We demonstrate the workings of deep GSOM on the real-life scenario of profiling vehicular and pedestrian movement using IoT data streams of two highly urbanized cities. The results of these experiments confirm the validity and effectiveness of the proposed approach for generating situational awareness from multiple IoT data streams.},
keywords={Internet of Things;Entropy;Measurement;Smart cities;Machine learning algorithms;Self-organizing feature maps;Deep learning;growing self-organizing map;Internet-of-Things (IoT) data streams;situational awareness;smart traffic management;traffic congestion profiling},
doi={10.1109/JIOT.2020.2966792},
ISSN={2327-4662},
month={May},}
@ARTICLE{9447893,
author={Maciel, Hyuri and Ramos, Geymerson S. and Aquino, Andre L. L.},
journal={IEEE Sensors Letters}, title={A Sensor Network Solution to Detect Occupation in Smart Spaces in the Presence of Anomalous Readings},
year={2021},
volume={5},
number={7},
pages={1-4},
abstract={Smart cities should use computational systems to reduce human intervention in repetitive tasks as much as possible. Typically, solutions use adaptive applications to continuously and ubiquitously improve intelligent environments' services, optimizing the use of resources such as electricity or water. This letter evaluates different machine learning algorithms to detect occupancy in smart spaces in the presence of anomalous readings. Additionally, it presents a low-cost wireless sensor network (WSN) to collect the data and give the occupancy inference. We collect the environment data, with the presented WSN, in our university's laboratory. To verify the robustness of algorithms, we randomly insert anomalous sensor readings in the collected data through a Bernoulli distribution process. These anomalies represent different environment events or sensor failures. With these data, we evaluate the random forest (RF), classification and regression tree (Cart), and K-nearest neighbors (k-NN) algorithms. The best performing algorithms were RF and k-NN, presenting close to 99% of accuracy in data without anomalies and 97% in data with 10% of anomalies. However, we observe an average execution time of 2.34 s to k-NN against 25.65 s to RF. Thus, considering our evaluated scenarios, we elect the k-NN as the best algorithm to detect occupation in smart spaces.},
keywords={Sensors;Temperature sensors;Wireless sensor networks;Radio frequency;Temperature measurement;Smart spaces;Machine learning algorithms;Sensor systems, machine learning;occupation detection;smart spaces;wireless sensor networks (WSNs)},
doi={10.1109/LSENS.2021.3086962},
ISSN={2475-1472},
month={July},}
@INPROCEEDINGS{9604380,
author={Malladi, Venkata and Li, Yi Joy and Siddula, Madhuri and Seoand, Daehee and Huang, Yan},
booktitle={2021 IEEE SmartWorld, Ubiquitous Intelligence Computing, Advanced Trusted Computing, Scalable Computing Communications, Internet of People and Smart City Innovation (SmartWorld/SCALCOM/UIC/ATC/IOP/SCI)}, title={Decentralized Aggregation Design and Study of Federated Learning},
year={2021},
volume={},
number={},
pages={328-337},
abstract={The advent of machine learning techniques has given rise to modern devices with built-in models for decision making and providing rich content to users. This typically involves processing huge volumes of data in central servers and sending updated models to end-user devices. There are two main concerns on this server architecture, one is the privacy of data that is being transferred to a central server and the other is volumes of data sent over the network for the model update. Federated Learning helps solve these problems by training models on local data within the device and aggregating the model with other devices. Federated Learning involves a central server for the aggregation and the resulting updates to the clients, here only model parameters are shared with the central server not the data itself thereby preserving privacy. But all the applications are not being compatible with Federated Learning and also there is a privacy concern of models being shared to the central server which can be susceptible to malicious attacks. In this paper, central server free Federated Learning, which is decentralized Federated Learning is used, where the parameters will be exchanged between the clients one to one and get their models updated removing the need for a central server for aggregation. Peer-to-peer techniques are used for communicating between clients and different node architectures to achieve better accuracy. This happens when the clients meet another client in a connected social network environment. The results show that the communication happens between clients in a decentralized fashion and thereby achieving privacy in a more trusted manner.},
keywords={Training;Privacy;Data privacy;Technological innovation;Social networking (online);Smart cities;Collaborative work},
doi={10.1109/SWC50871.2021.00052},
ISSN={},
month={Oct},}
@INPROCEEDINGS{9604420,
author={Xu, Jingrou and Jia, Zhaoqian and Wang, Wenchao and Wang, Chunyu and Yin, Guangqiang},
booktitle={2021 IEEE SmartWorld, Ubiquitous Intelligence Computing, Advanced Trusted Computing, Scalable Computing Communications, Internet of People and Smart City Innovation (SmartWorld/SCALCOM/UIC/ATC/IOP/SCI)}, title={A Novel Neural Network for P300 Brain-Computer Interface Signal Recognition},
year={2021},
volume={},
number={},
pages={479-486},
abstract={P300 event-related potential (ERP) is of great significance to Brain-Computer Interface (BCI) research. Due to the low signal-to-noise ratio (SNR) of P300 electroencephalogram (EEG) signals and the difficulty in feature extraction, the improve of the recognition accuracy of the P300 ERP signal is limited. To address these issues, we propose a novel neural network for P300 signal recognition. Firstly, by using instance normalization, the internal data of each channel of EEG signals is normalized to eliminate distribution differences, which is conducive to the feature extraction of P300 signal. Secondly, we design the MultFeat module to extract the global features and channel features of the samples, and fuse them to enhance the feature representation ability. In addition, we also propose an EEG signal data preprocessing method, which can effectively improve the SNR of EEG signals and suppress sample imbalance. We conducted a lot of experiments, and the proposed network achieve an accuracy of 95% on the database II of BCI Competition III, which is better than the traditional machine learning method support vector machines. The results show that the method proposed in this paper can effectively recognize the P300 signals.},
keywords={Technological innovation;Convolution;Smart cities;Data preprocessing;Feature extraction;Electroencephalography;Brain-computer interfaces;P300;Neural network;Data processing;Feature extraction},
doi={10.1109/SWC50871.2021.00071},
ISSN={},
month={Oct},}
@INPROCEEDINGS{9604430,
author={Kounoudes, Alexia Dini and Kapitsaki, Georgia M. and Katakis, Ioannis and Milis, Marios},
booktitle={2021 IEEE SmartWorld, Ubiquitous Intelligence Computing, Advanced Trusted Computing, Scalable Computing Communications, Internet of People and Smart City Innovation (SmartWorld/SCALCOM/UIC/ATC/IOP/SCI)}, title={User-centred privacy inference detection for smart home devices},
year={2021},
volume={},
number={},
pages={210-218},
abstract={In the smart home, vast amounts of data are being collected via various interconnected devices. Although this assists in improving the quality of life at home, often the user is not aware of the details concerning data collection apart from the information available on the provider privacy policy. It is however important to put the user inside this loop of information, so that she is well informed on possible uses of the data and the potential risks that this may entail. Previous works have identified user activity inside the smart home and have pointed out privacy threats. In this work, we go one step further by offering data inference techniques and giving this information back to the user. We use a number of machine learning techniques to draw conclusions about the user routines or activities and we inform the user about our findings concerning data inferences through a dedicated web application. Our aim is toward user-centred privacy and is a proof of concept that can be reused by smart home and Internet of Things service providers in general in order to improve the services offered to the end-users. Our results indicate that a large number of data inferences are possible by using a combination of techniques.},
keywords={Performance evaluation;Data privacy;Privacy;Adaptation models;Technological innovation;Smart cities;Smart homes;smart home;privacy;user-centred privacy;inference detection},
doi={10.1109/SWC50871.2021.00037},
ISSN={},
month={Oct},}
@ARTICLE{9334448,
author={Zhao, Changfei and Wan, Can and Song, Yonghua},
journal={IEEE Transactions on Power Systems}, title={Operating Reserve Quantification Using Prediction Intervals of Wind Power: An Integrated Probabilistic Forecasting and Decision Methodology},
year={2021},
volume={36},
number={4},
pages={3701-3714},
abstract={Adequate reserves are urgently needed to hedge against wind power forecasting uncertainties in power systems. Traditional reserve quantification sequentially acquires statistical features of wind power and then determines reserve amounts. This paper establishes a novel integrated probabilistic forecasting and decision (IPFD) methodology to simultaneously optimize the wind power prediction intervals (PIs) and probabilistic reserve quantification. Upward and downward reserve quantities are defined to cover the wind power forecasting uncertainties within the PIs. A cost function evaluating the reserve provision payment and deficit penalty is elaborated to realize cost-benefit trade-offs of reserve decision. Nonparametric wind power PIs are constructed based on extreme learning machine, which minimizes the reserve cost function subject to eligible target coverage probability constraint. The confidence level and quantile proportions associated with wind power PIs can be jointly tuned to reduce the operational cost of reserves. Benefited from extreme learning machine, the IPFD model is reformulated as a mixed integer linear programming problem. A feasible region tightening strategy that shrinks the large constant coefficients and eliminates the redundant binary variables is proposed to accelerate model training. Numerical experiments based on actual wind power data demonstrate the remarkable cost-effective advantages of the IPFD based reserve quantification, as well as the high computational efficiency for online application.},
keywords={Wind power generation;Machine learning;Probabilistic logic;Uncertainty;Stochastic processes;Wind forecasting;Mixed integer linear programming;Operating reserve;prediction interval;probabilistic forecasting;wind power;machine learning;mixed integer linear programming},
doi={10.1109/TPWRS.2021.3053847},
ISSN={1558-0679},
month={July},}
@INPROCEEDINGS{8997251,
author={Chen, Rui and Zhang, Cai-xia and Guo, Jing and Wang, Xiang-dong},
booktitle={2019 Chinese Automation Congress (CAC)}, title={Application of Naive Bayesian Algorithms in E-mail Classification},
year={2019},
volume={},
number={},
pages={3933-3938},
abstract={In the context of the rapid development of today's society, high-tech information technology such as machine learning has played a very important role in promoting social, economic and technological development in all countries of the world. Bayesian classification algorithm is an important algorithm in the field of machine learning and data mining. Naive Bayesian algorithm is a basic and simple classification algorithm in Bayesian classification algorithm. The naive Bayesian algorithm has the advantages of high stability, simplicity, high efficiency and strong theoretical foundation. The classification quality of the naive Bayesian algorithm much depends on the choice of construction methods and the nature and quantity of the classification data. In fact, many problems in our life can be attributed to classification problems, such as risk prediction, medical diagnosis, e-mail classification, fraud detection, etc. [1]. Here, I will mainly explain the principle of naive Bayesian algorithm, classification process, the evaluation of classification results, and apply this algorithm to e-mail classification tasks. At the same time, I list some related examples. Finally, I will summarize the naive Bayesian algorithm.},
keywords={Dictionaries;Hidden Markov models;Postal services;Smart cities;Monitoring;Bayes methods;Data models;Machine learning;data mining;naive Bayesian algorithm;text classification;email classification},
doi={10.1109/CAC48633.2019.8997251},
ISSN={2688-0938},
month={Nov},}
@ARTICLE{9327478,
author={Liu, Yuxuan and Yixuan, Yuan and Liu, Ming},
journal={IEEE Robotics and Automation Letters}, title={Ground-Aware Monocular 3D Object Detection for Autonomous Driving},
year={2021},
volume={6},
number={2},
pages={919-926},
abstract={Estimating the 3D position and orientation of objects in the environment with a single RGB camera is a critical and challenging task for low-cost urban autonomous driving and mobile robots. Most of the existing algorithms are based on the geometric constraints in 2D-3D correspondence, which stems from generic 6D object pose estimation. We first identify how the ground plane provides additional clues in depth reasoning in 3D detection in driving scenes. Based on this observation, we then improve the processing of 3D anchors and introduce a novel neural network module to fully utilize such application-specific priors in the framework of deep learning. Finally, we introduce an efficient neural network embedded with the proposed module for 3D object detection. We further verify the power of the proposed module with a neural network designed for monocular depth prediction. The two proposed networks achieve state-of-the-art performances on the KITTI 3D object detection and depth prediction benchmarks, respectively.},
keywords={Three-dimensional displays;Cameras;Object detection;Two dimensional displays;Feature extraction;Convolution;Neural networks;Automation technologies for smart cities;deep learning for visual perception;object detection;segmentation and categorization},
doi={10.1109/LRA.2021.3052442},
ISSN={2377-3766},
month={April},}
@ARTICLE{9375484,
author={Sánchez, Pedro Miguel Sánchez and Valero, José María Jorquera and Celdrán, Alberto Huertas and Bovet, Gérôme and Pérez, Manuel Gil and Pérez, Gregorio Martínez},
journal={IEEE Communications Surveys Tutorials}, title={A Survey on Device Behavior Fingerprinting: Data Sources, Techniques, Application Scenarios, and Datasets},
year={2021},
volume={23},
number={2},
pages={1048-1077},
abstract={In the current network-based computing world, where the number of interconnected devices grows exponentially, their diversity, malfunctions, and cybersecurity threats are increasing at the same rate. To guarantee the correct functioning and performance of novel environments such as Smart Cities, Industry 4.0, or crowdsensing, it is crucial to identify the capabilities of their devices (e.g., sensors, actuators) and detect potential misbehavior that may arise due to cyberattacks, system faults, or misconfigurations. With this goal in mind, a promising research field emerged focusing on creating and managing fingerprints that model the behavior of both the device actions and its components. The article at hand studies the recent growth of the device behavior fingerprinting field in terms of application scenarios, behavioral sources, and processing and evaluation techniques. First, it performs a comprehensive review of the device types, behavioral data, and processing and evaluation techniques used by the most recent and representative research works dealing with two major scenarios: device identification and device misbehavior detection. After that, each work is deeply analyzed and compared, emphasizing its characteristics, advantages, and limitations. This article also provides researchers with a review of the most relevant characteristics of existing datasets as most of the novel processing techniques are based on Machine Learning and Deep Learning. Finally, it studies the evolution of these two scenarios in recent years, providing lessons learned, current trends, and future research challenges to guide new solutions in the area.},
keywords={Object recognition;Computer crime;Performance evaluation;Market research;Mobile handsets;Tutorials;Fingerprint recognition;Behavioral data;cyberattack detection;device behavior datasets;device behavior fingerprinting;device identification;processing and evaluation techniques},
doi={10.1109/COMST.2021.3064259},
ISSN={1553-877X},
month={Secondquarter},}
@INPROCEEDINGS{8258427,
author={Kawano, Makoto and Mikami, Kazuhiro and Yokoyama, Satoshi and Yonezawa, Takuro and Nakazawa, Jin},
booktitle={2017 IEEE International Conference on Big Data (Big Data)}, title={Road marking blur detection with drive recorder},
year={2017},
volume={},
number={},
pages={4092-4097},
abstract={Can we inspect the road condition at a low cost? City infrastructures, such as roads are very important for citizens to their city lives. Roads require constant inspection and repair due to deterioration, but it is expensive to do so with manual labor. Meanwhile, there are official city vehicles, especially garbage trucks that run through the entire area of a city every day and have cameras to record their driving. When we use these cameras, we can watch roads conditions anytime, anywhere. In our study, we focus on these cameras and attempt detecting the road damage, such as road marking blur. To achieve our goal, we explore the new system in this paper. This system adopts the object detection approach that is end-to-end learning and based on deep neural networks, which propose the blur region candidate and detect whether the road markings are blurred or not all at once. In our experiment, first, we obtain the drive recorder video from sanitation engineer and then annotate them. After annotation, we trained our models and calculate the mean average precision to evaluate our models. As a result, our model performs on our collected dataset.},
keywords={Roads;Urban areas;Cameras;Image color analysis;Inspection;Neural networks;Object detection;Object detection;Deep Learning;Road inspection;Automotive sensing;Smart cities},
doi={10.1109/BigData.2017.8258427},
ISSN={},
month={Dec},}
@INPROCEEDINGS{9569358,
author={Zhou, Hao and Elsayed, Medhat and Erol-Kantarci, Melike},
booktitle={2021 IEEE 32nd Annual International Symposium on Personal, Indoor and Mobile Radio Communications (PIMRC)}, title={RAN Resource Slicing in 5G Using Multi-Agent Correlated Q-Learning},
year={2021},
volume={},
number={},
pages={1179-1184},
abstract={5G is regarded as a revolutionary mobile network, which is expected to satisfy a vast number of novel services, ranging from remote health care to smart cities. However, heterogeneous Quality of Service (QoS) requirements of different services and limited spectrum make the radio resource allocation a challenging problem in 5G. In this paper, we propose a multi-agent reinforcement learning (MARL) method for radio resource slicing in 5G. We model each slice as an intelligent agent that competes for limited radio resources, and the correlated Q-learning is applied for inter-slice resource block (RB) allocation. The proposed correlated Q-learning based inter-slice RB allocation (COQRA) scheme is compared with Nash Q-learning (NQL), Latency-Reliability-Throughput Q-learning (LRTQ) methods, and the priority proportional fairness (PPF) algorithm. Our simulation results show that the proposed CO-QRA achieves 32.4% lower latency and 6.3% higher throughput when compared with LRTQ, and 5.8% lower latency and 5.9% higher throughput than NQL. Significantly higher throughput and lower packet drop rate (PDR) is observed in comparison to PPF.},
keywords={5G mobile communication;Smart cities;Simulation;Scalability;Quality of service;Reinforcement learning;Ultra reliable low latency communication;5G RAN slicing;resource allocation;Q-learning;correlated equilibrium},
doi={10.1109/PIMRC50174.2021.9569358},
ISSN={2166-9589},
month={Sep.},}
@INPROCEEDINGS{9589053,
author={Gayathri, Madhavi and Ariyaratne, Amanda and Kahawala, Sachin and Silva, Daswin De and Alahakoon, Damminda and Nanayakkara, Vishaka and Osipov, Evgeny and Yu, Xinghuo},
booktitle={IECON 2021 – 47th Annual Conference of the IEEE Industrial Electronics Society}, title={Learning Rule Optimization and Comparative Evaluation of Accelerated Self-Organizing Maps for Industrial Applications},
year={2021},
volume={},
number={},
pages={1-6},
abstract={The emergence of low latency and high bandwidth 5G networks, alongside localized computation and data storage of edge computing are enabling real-time applications in industrial settings, such as smart grid, smart cities, and smart factories. The resolution, frequency and variety of data streams generated by such applications are not effectively processed and analysed by contemporary machine learning algorithms. This challenge is further complicated by the unlabelled and non-deterministic nature of the data streams. Hardware accelerated machine learning has been proposed to address some of these challenges but limited work has been published on unsupervised learning from unlabelled data. In this paper, we extend the hardware accelerated Self Organizing Map (SOM) algorithm by optimizing the learning rule for computational efficiency, followed by a comparative empirical evaluation with two other variants, tri-state SOM and integer SOM. We have used two datasets representative of real-time industrial applications in 5G networks and smart grids, for this evaluation.},
keywords={Self-organizing feature maps;Industrial electronics;Machine learning algorithms;5G mobile communication;Real-time systems;Smart grids;Unsupervised learning},
doi={10.1109/IECON48115.2021.9589053},
ISSN={2577-1647},
month={Oct},}
@INPROCEEDINGS{9162888,
author={Raja, Gunasekaran and Dhanasekaran, Priyanka and Anbalagan, Sudha and Ganapathisubramaniyan, Aishwarya and Bashir, Ali Kashif},
booktitle={IEEE INFOCOM 2020 - IEEE Conference on Computer Communications Workshops (INFOCOM WKSHPS)}, title={SDN-enabled Traffic Alert System for IoV in Smart Cities},
year={2020},
volume={},
number={},
pages={1093-1098},
abstract={Intelligent Transportation System (ITS) are helping to enhance road safety and traffic management applications. Internet of Vehicles (IoV) plays a promising role in this field, which turns each vehicle into a smart object with its own compute, storage, and networking capabilities. Nowadays, accidents have been increased mainly due to un-notified alerts about other accidents, work-in-progress, and excessive motorized vehicles at peak times. This non-line of sight information can be efficiently delivered using vehicular communication. IoV network, however has its own challenges like high mobility and dynamic network topology. The above mentioned challenges are addressed with the assistance of a centralized Software Defined Network (SDN), which isolates the control plane from the data plane. In IoV, SDN provides logically centralized traffic management and improves the vehicular communication. In this paper, the Software Defined-Internet of Vehicles (SD-IoV) system is designed to manage heavy traffic and avoids broadcast storm problem with high packet delivery ratio. The proposed broadcast routing mechanism uses selective forwarding and neighbor awareness of the vehicle to efficiently broadcast emergency alert messages, thereby avoiding traffic jams and reducing travel time. On-Board Unit (OBU) in vehicles detects the accident and initializes the broadcast algorithm in SD-IoV system. The accident detection by OBU in vehicles is simulated using machine learning technique with an accuracy of 90%. Simulation performed in SUMO and OMNeT++ shows that with the help of the SDN controller, the IoV network achieves a high packet delivery ratio with minimal delay.},
keywords={Roads;Accidents;Vehicular ad hoc networks;Routing;Indexes;Delays;Peer-to-peer computing;IoV;VANET;Vehicle-to-Vehicle;Vehicle-to-Infrastructure;Software Defined Network;Broadcast storm},
doi={10.1109/INFOCOMWKSHPS50562.2020.9162888},
ISSN={},
month={July},}
@INPROCEEDINGS{9674960,
author={Asad, Syed Muhammad and Dashtipour, Kia and Rais, Rao Naveed Bin and Hussain, Sajjad and Abbasi, Qammer Hussain and Imran, Muhammad Ali},
booktitle={2021 International Conference on UK-China Emerging Technologies (UCET)}, title={Employing Machine Learning for Predicting Transportation Modes Under the COVID-19 Pandemic: A Mobility-Trends Analysis},
year={2021},
volume={},
number={},
pages={235-240},
abstract={With the advent of Coronavirus Disease 2019 (COVID-19), the world encountered an unprecedented health crisis due to the severe acute respiratory syndrome (SARS) pathogen. This impacted all of the sectors but more critically the transportation sector which required a strategy in the light of mobility trends using transportation modes and regions. We analyse a mobility prediction model for smart transportation by considering key indicators including data selection, processing and, integration of transportation modes, and data point normalisation in regional mobility. A Machine Learning (ML) driven classification has been performed to predict transportation modes efficiency and variations using driving, walking and transit. Additionally, regional mobility by considering Asia, Europe, Africa, Australasia, Middle-East, and America has also been analysed. In this regard, six ML algorithms have been applied for the precise assessment of transportation modes and regions. The initial experimental results demonstrate that the majority of the world's travelling dynamics have been contrastively shaped with the accuracy of 91.21% and 84.5% using Support Vector Machine (SVM) and Random Forest (RT) for different transportation modes and regions. This study will pave a new direction for the assessment of transportation modes affected by the pandemic to optimize economic benefits for smart transportation.},
keywords={COVID-19;Support vector machines;Pandemics;Smart cities;Transportation;Market research;Prediction algorithms;Artificial Intelligence;COVID-19;Intelligent Transport Systems;Mobility Management;Travelers-Tracing},
doi={10.1109/UCET54125.2021.9674960},
ISSN={},
month={Nov},}
@ARTICLE{8600316,
author={Ferdowsi, Aidin and Challita, Ursula and Saad, Walid},
journal={IEEE Vehicular Technology Magazine}, title={Deep Learning for Reliable Mobile Edge Analytics in Intelligent Transportation Systems: An Overview},
year={2019},
volume={14},
number={1},
pages={62-70},
abstract={Intelligent transportation systems (ITSs) will be a major component of tomorrow's smart cities. However, realizing the true potential of ITSs requires ultralow latency and reliable data analytics solutions that combine, in real time, a heterogeneous mix of data stemming from the ITS network and its environment. Such data analytics capabilities cannot be provided by conventional cloud-centric data processing techniques whose communication and computing latency can be high. Instead, edge-centric solutions that are tailored to the unique ITS environment must be developed. In this article, an edge analytics architecture for ITSs is introduced in which data is processed at the vehicle or roadside smart sensor level to overcome the ITS's latency and reliability challenges. With a higher capability of passengers' mobile devices and intravehicle processors, such a distributed edge computing architecture leverages deep-learning techniques for reliable mobile sensing in ITSs. In this context, the ITS mobile edge analytics challenges pertaining to heterogeneous data, autonomous control, vehicular platoon control, and cyberphysical security are investigated. Then, different deep-learning solutions for such challenges are revealed. The discussed deep-learning solutions enable ITS edge analytics by endowing the ITS devices with powerful computer vision and signal processing functions. Preliminary results show that the introduced edge analytics architecture, coupled with the power of deep-learning algorithms, provides a reliable, secure, and truly smart transportation environment.},
keywords={Cloud computing;Reliability;Image edge detection;Computer architecture;Intelligent sensors;Intelligent vehicles},
doi={10.1109/MVT.2018.2883777},
ISSN={1556-6080},
month={March},}
@ARTICLE{9520268,
author={Sun, Shuting and Mu, Lin and Feng, Ruyi and Wang, Lizhe and He, Jijun},
journal={IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing}, title={GAN-Based LUCC Prediction via the Combination of Prior City Planning Information and Land-Use Probability},
year={2021},
volume={14},
number={},
pages={10189-10198},
abstract={Currently, the world is in a period of urbanization that will accelerate the processes of land-use cover and ecological change. Thus, establishing a land-use and land-cover change (LUCC) prediction and simulation model is of great significance for understanding the process of urban change and assessing its ecological impact. In previous studies, LUCC prediction models have been mainly based on cellular automata structures that calculate a future state pixel by pixel through transition rules. Because these transition rules are usually based on the global state and each pixel is calculated according to these fixed rules, the results of these methods have room for improvement in terms of generating details and heterogeneity. In this article, a generative adversarial network (GAN)-based LUCC prediction model using multiscale local spatial information is proposed. The model is based on a pix2pix GAN and an attention structure that predicts future land use through multiscale local spatial information. To validate our model, Shenzhen, a region that is experiencing rapid urbanization, was chosen as the source of the experimental data. The results indicate that the proposed method achieved the highest accuracy in both short-time interval and long-time interval scenarios. In addition, the results of the proposed method were also closest to the ground truth from the perspective of the landscape pattern.},
keywords={Predictive models;Data models;Generative adversarial networks;Biological system modeling;Generators;Deep learning;Urban areas;Deep learning;generative adversarial network (GAN);LUCC simulation;remote sensing;smart city},
doi={10.1109/JSTARS.2021.3106481},
ISSN={2151-1535},
month={},}
@INPROCEEDINGS{7968132,
author={Pilgerstorfer, Peter and Pournaras, Evangelos},
booktitle={2017 IEEE/ACM 12th International Symposium on Software Engineering for Adaptive and Self-Managing Systems (SEAMS)}, title={Self-Adaptive Learning in Decentralized Combinatorial Optimization - A Design Paradigm for Sharing Economies},
year={2017},
volume={},
number={},
pages={54-64},
abstract={The democratization of Internet of Things and ubiquitous computing equips citizens with phenomenal new ways for online participation and decision-making in application domains of smart grids and smart cities. When agents autonomously self-determine the options from which they make choices, while these choices collectively have an overall system-wide impact, an optimal decision-making turns into a combinatorial optimization problem known to be NP-hard. This paper contributes a new generic self-adaptive learning algorithm for a fully decentralized combinatorial optimization: I-EPOS, the Iterative Economic Planning and Optimized Selections. In contrast to related algorithms that simply parallelize computations or big data and deep learning systems that often require personal data and overtake of control with implication on privacy-preservation and autonomy, I-EPOS relies on coordinated local decision-making via structured interactions over tree topologies that involve the exchange of entirely local and aggregated information. Strikingly, the cost-effectiveness of I-EPOS in regards to performance vs. computational and communication cost highly outperforms other related algorithms that involve non-local brute-force operations or exchange of full information. The algorithm is also evaluated using real-world data from two state-of-the-art pilot projects of participatory sharing economies: (i) energy management and (ii) bicycle sharing. The contribution of an I-EPOS open source software suite implemented as a paradigmatic artifact for community aspires to settle a knowledge exchange for the design of new algorithms and application scenarios of sharing economies towards highly participatory and sustainable digital societies.},
keywords={Decision making;Bicycles;Topology;Algorithm design and analysis;Cost function;Smart grids;learning;adaptation;optimization;decentralized system;network;sharing economy;smart grid;smart city},
doi={10.1109/SEAMS.2017.8},
ISSN={},
month={May},}
@ARTICLE{9050793,
author={Chiu, Po-Sheng and Chang, Jia-Wei and Lee, Ming-Che and Chen, Ching-Hui and Lee, Da-Sheng},
journal={IEEE Access}, title={Enabling Intelligent Environment by the Design of Emotionally Aware Virtual Assistant: A Case of Smart Campus},
year={2020},
volume={8},
number={},
pages={62032-62041},
abstract={With the advent of the 5G and Artificial Intelligence of Things (AIoT) era, related technologies such as the Internet of Things, big data analysis, cloud applications, and artificial intelligence have brought broad prospects to many application fields, such as smart homes, autonomous vehicles, smart cities, healthcare, and smart campus. At present, most university campus app is presented in the form of static web pages or app menus. This study mainly developed a Deep Neural Network (DNN) based emotionally aware campus virtual assistant. The main contributions of this research are: (1) This study introduces the Chinese Word Embedding to the robot dialogue system, effectively improving dialogue tolerance and semantic interpretation. (2) The traditional method of emotion identification must first tokenize the Chinese sentence, analyze the clauses and part of speech, and capture the emotional keywords before being interpreted by the expert system. Different from the traditional method, this study classifies the input directly through the convolutional neural network after the input sentence is converted into a spectrogram by Fourier Transform. (3) This study is presented in App mode, which is easier to use and economical. (4) This system provides a simple voice response interface, without the need for users to find information in complex web pages or app menus.},
keywords={Speech recognition;Mobile handsets;Deep learning;Emotion recognition;Neural networks;Education;Augmented reality;smart campus;convolutional neural network;recurrent neural network;emotional recognition;chinese word embedding},
doi={10.1109/ACCESS.2020.2984383},
ISSN={2169-3536},
month={},}
@INPROCEEDINGS{9020639,
author={Mendieta, Matías and Neff, Christopher and Lingerfelt, Daniel and Beam, Christopher and George, Anjus and Rogers, Sam and Ravindran, Arun and Tabkhi, Hamed},
booktitle={2019 SoutheastCon}, title={A Novel Application/Infrastructure Co-design Approach for Real-time Edge Video Analytics},
year={2019},
volume={},
number={},
pages={1-7},
abstract={Recent advances in machine learning and deep learning have enabled many existing applications in smart cities, autonomous systems, and wearable devices. These applications often demand scalable real-time cognitive intelligence and on-the-spot decision making. Current computer systems have been customized for a cloud computing paradigm which often does not meet latency constraints and scalability requirements. To address the limitations of the cloud computing paradigm, the general trend is toward shifting the computation next to data producers at the edge. However, the edge computing paradigm is in the very early stages. Many system-level aspects of edge computing, including algorithms mapping and partitioning across edge computing resources (edge server, and edge nodes) are unknown. New research is required to understand and quantify design dimensions for edge computing.This paper presents a novel edge computing infrastructure for distributed real-time video analytics. This paper presents a holistic solution for co-designing application and edge infrastructure, including edge nodes and edge servers, to enable scalable real-time Artificial Intelligence (AI)/Deep Learning (DL) video analytics across many cameras. For experimental results and evaluation, we focus on the case study of object re-identification across many cameras, which is composed of object detection/classification (TinyYOLOv3), feature extraction, local re-identification, and global re-identification kernels. We evaluate the edge system under three different task mapping and resource allocation configurations. The results present that with the edge nodes (video cameras) more than 32, the only scalable solution is to perform detection/classification (TinyYOLOv3), feature extraction, local re-identification on the edge nodes next to cameras, and execute global re-identification on edge server.},
keywords={Servers;Image edge detection;Cloud computing;Real-time systems;Machine learning;Scalability;Cameras},
doi={10.1109/SoutheastCon42311.2019.9020639},
ISSN={1558-058X},
month={April},}
@INPROCEEDINGS{9617182,
author={Bahaweres, Rizal Broer and Jumral, Detia and Hermadi, Irman and Suroso, Arif Imam and Arkeman, Yandra},
booktitle={2021 2nd International Conference On Smart Cities, Automation Intelligent Computing Systems (ICON-SONICS)}, title={Hybrid Software Defect Prediction Based on LSTM (Long Short Term Memory) and Word Embedding},
year={2021},
volume={},
number={},
pages={70-75},
abstract={Defects often occur in software so it can cause various problems for users. The running system may have defects, although they are not immediately apparent. Defects can be UI or display defects or defects in logic code. In predicting software defects several methods have been developed focusing on software metrics (Line of Code, Cyclomatic Complexity, etc.). But in capturing program syntax and semantics and the ability to build accurate predictive models, software metrics often fail. We propose a method that combines deep learning methods and word embedding to predict software defects. We will map tokens using an abstract syntax tree from the source code and then build an LSTM network to predict software defects. The dataset used is taken from an open source Java project, namely the Apache Project Repository. The evaluation results show that the LSTM method combined with word embedding can get accuracy 98%, precision 89%, recall 92% and f1-score 90%. This is greater than other software defect prediction methods.},
keywords={Deep learning;Java;Codes;Software metrics;Semantics;Focusing;Syntactics;Software Defect Prediction;Word Embedding;Long Short-Term Memory},
doi={10.1109/ICON-SONICS53103.2021.9617182},
ISSN={},
month={Oct},}
@ARTICLE{9340550,
author={Zhu, Dawei and Xu, Zhanyang and Xu, Xiaolong and Zhao, Qingzhan and Qi, Lianyong and Srivastava, Gautam},
journal={IEEE Transactions on Computational Social Systems}, title={Cognitive Analytics of Social Media Services for Edge Resource Pre-Allocation in Industrial Manufacturing},
year={2021},
volume={8},
number={2},
pages={500-511},
abstract={With the development of industrial intelligence, the resource requests of various social media services in smart cities are expanding rapidly. For hosting services, the edge computing (EC) platform for its low-latency resource provisioning is fully explored. However, the mapping between edge servers (ESs) and services affects the service latency. Meanwhile, the real-time dynamic distribution of resource requirements also impairs the load balance. Therefore, how to optimize the load balance of ESs while meeting the latency-critical requests remains challenging. To deal with the above challenge, in this article, we propose a resource pre-allocation (RPA) method for the social media services with cognitive analytics. Technically, the deep spatiotemporal residual network (ST-ResNet) is employed to complete the cognitive analytics of resource requests. Then based on the analysis results, the optimal resource allocation (ORA) scheme is designed with multiobjective optimization. Finally, the performance of RPA is evaluated by a real-world resource request data set.},
keywords={Social networking (online);Industrial Internet of Things;Industries;Resource management;Deep learning;Delays;Residual neural networks;Cognitive analytics;deep learning;multiobjective optimization;optimal resource allocation (ORA);social media},
doi={10.1109/TCSS.2021.3052231},
ISSN={2329-924X},
month={April},}
@INPROCEEDINGS{9208333,
author={Zhang, Yanyu and Alshaykh, Osama},
booktitle={2020 IEEE International Conference on Electro Information Technology (EIT)}, title={5G Utility Pole Planner Using Google Street View and Mask R-CNN},
year={2020},
volume={},
number={},
pages={309-312},
abstract={With the advances of fifth-generation (5G) [1] cellular networks technology, many studies and work have been carried out on how to build 5G networks for smart cities. In the previous research, street lighting poles and smart light poles are capable of being a 5G access point[2]. In order to determine the position of the points, this paper discusses a new way to identify poles based on Mask R-CNN[3], which extends Fast R-CNNs[4] by making it employ recursive Bayesian filtering and perform proposal propagation and reuse. The dataset contains 3,000 high-resolution images from google map. To make training faster, we used a very efficient GPU implementation of the convolution operation. We achieved a train error rate of 7.86% and a test error rate of 32.03%. At last, we used the immune algorithm [5] [6] to set 5G poles in the smart cities.},
keywords={DH-HEMTs;Hidden Markov models;FCC;Hafnium;5G;Mask R-CNN;immune algorithm;google map;machine learning},
doi={10.1109/EIT48999.2020.9208333},
ISSN={2154-0373},
month={July},}
@INPROCEEDINGS{9302549,
author={Kalajdjieski, Jovan and Mirceva, Georgina and Kalajdziski, Slobodan},
booktitle={2020 IEEE/ACM International Conference on Big Data Computing, Applications and Technologies (BDCAT)}, title={Attention Models for PM2.5 Prediction},
year={2020},
volume={},
number={},
pages={1-8},
abstract={Air pollution is becoming a rising and serious environmental problem, mainly as a result from the migrations in urban areas. By employing effective air pollution monitoring systems, the pollution could be closely monitored, but this is not enough to make a significant impact in decreasing the pollution. The most effective value obtained from these systems is the amount of data that can be used to build pollution prediction models. To date, there are lot of different attempts to tackle the problem of air pollution prediction, but there is no evidence of their successful implementation in decreasing air pollution. In the last years, with the recent advances of deep learning techniques, and the increasing amount of data available, there are lot of proposed models for tackling the problem. In this research paper, we propose two different attention based models for air pollution prediction. Our models differ from all previous proposed models by introducing different attention factors for the previous timesteps when making a prediction. The model learns the attention factors, allowing it to learn the optimal amount that previous timesteps affect the current prediction. Using this approach we could better learn the patterns and dependencies in the data and in turn build better prediction models. We show that our models outperform two state-of-the-art models by employing our novel architecture.},
keywords={Atmospheric modeling;Predictive models;Air pollution;Data models;Pollution;Meteorology;Numerical models;PM 2.5 prediction;air pollution prediction;smart city;deep learning;recurrent neural networks;attention model},
doi={10.1109/BDCAT50828.2020.00010},
ISSN={},
month={Dec},}
@INPROCEEDINGS{7083870,
author={Perera, Srinath},
booktitle={2014 14th International Conference on Advances in ICT for Emerging Regions (ICTer)}, title={Large scale data processing in real world: From analytics to predictions},
year={2014},
volume={},
number={},
pages={8-8},
abstract={Summary form only given. Large scale data processing analyses and makes sense of large amounts of data. Although the field itself is not new, it is finding many usecases under the theme "Bigdata" where Google itself, IBM Watson, and Google's Driverless car are some of success stories. Spanning many fields, Large scale data processing brings together technologies like Distributed Systems, Machine Learning, Statistics, and Internet of Things together. It is a multi-billion-dollar industry including use cases like targeted advertising, fraud detection, product recommendations, and market surveys. With new technologies like Internet of Things (IoT), these use cases are expanding to scenarios like Smart Cities, Smart health, and Smart Agriculture. Some usecases like Urban Planning can be slow, which is done in batch mode, while others like stock markets need results within Milliseconds, which are done in streaming fashion. There are different technologies for each case: MapReduce for batch processing and Complex Event Processing and Stream Processing for real-time usecases. Furthermore, the type of analysis range from basic statistics like mean to complicated prediction models based on machine Learning. In this talk, we will discuss data processing landscape: concepts, usecases, technologies and open questions while drawing examples from real world scenarios.},
keywords={},
doi={10.1109/ICTER.2014.7083870},
ISSN={},
month={Dec},}
@INPROCEEDINGS{8730849,
author={Edinger, Janick and Hofmann, Alexandra and Wachner, Anton and Becker, Christian and Raychoudhury, Vaskar and Krupitzer, Christian},
booktitle={2019 IEEE International Conference on Pervasive Computing and Communications Workshops (PerCom Workshops)}, title={WheelShare: Crowd-Sensed Surface Classification for Accessible Routing},
year={2019},
volume={},
number={},
pages={584-589},
abstract={Accessible path routing for wheeled mobility is an important problem given the permanent and temporary obstacles in the built environment. Existing research works have focused on identifying several obstacles as well as facilities such as crosswalks with traffic signals using smartphone based sensing or crowd-sourcing and used those knowledge to generate accessible routes. In this work, we propose WheelShare which generates an accessible route through the best possible surface depending on user and wheelchair requirements. It is 1) scalable, as it uses crowd-sensing to collect voluminous data, 2) dynamic, as the data gets constantly updated, and 3) objective, as it uses an empirical and data-centric approach.},
keywords={Routing;Wheelchairs;Sensors;Data models;Servers;Gyroscopes;Machine learning;accessibility;smart cities;accessible routing;machine learning},
doi={10.1109/PERCOMW.2019.8730849},
ISSN={},
month={March},}
@INPROCEEDINGS{9183040,
author={Sunny, K. and Sheikh, A. and Wagh, S. and Singh, N. M.},
booktitle={2020 28th Mediterranean Conference on Control and Automation (MED)}, title={Prediction and Classification of Temperature Data in Smart Building using Dynamic Mode Decomposition},
year={2020},
volume={},
number={},
pages={1074-1079},
abstract={With the recent trends of smart cities, the development in the sector of Smart Buildings has emerged tremendously which consists of multiple layers coordinating and interacting with each other with the help of a building management system (BMS). This interaction of different layers in the smart building with the help of a communication channel leads to exposure of layers to vulnerabilities (cyber attacks) which may lead to anomalies condition. This kind of anomalies can be avoided by proper prediction of data and coordination among different layers of the building operation. However, to develop the model for prediction of data is quite time consuming and hence, the paper proposes the concept of Dynamic Mode Decomposition (DMD) for predicting data with help of past available data even in absence of system model. In this paper temperature profile of heating, ventilation, and air conditioning (HVAC) system in BMS is predicted with the help of available past data. Once the prediction of the temperature profile is achieved the machine learning algorithm is used to classify and identify the data as normal or anomalies condition. The two-fold contribution of the paper in the prediction of temperature using DMD where all system states may not be observable and classification of data using machine learning is validated considering different test scenarios and results show the effectiveness of the DMD method in the prediction of data as well as classification using a machine learning algorithm.},
keywords={Smart buildings;Temperature distribution;Matrix decomposition;Data models;Predictive models;Eigenvalues and eigenfunctions;Building management system;Dynamic mode decomposition;Hankel matrix;HVAC;Machine learning;Persistence of excitation;Smart Building},
doi={10.1109/MED48518.2020.9183040},
ISSN={2473-3504},
month={Sep.},}
@INPROCEEDINGS{8653618,
author={Chen, Yin and Sakamura, Mina and Nakazawa, Jin and Yonezawa, Takuro and Tsuge, Akira and Hamada, Yuichi},
booktitle={2018 Eleventh International Conference on Mobile Computing and Ubiquitous Network (ICMU)}, title={OmimamoriNet: An Outdoor Positioning System Based on Wi-SUN FAN Network},
year={2018},
volume={},
number={},
pages={1-6},
abstract={We propose in this paper an outdoor positioning system based on Wi-SUN FAN network, the goal of which is to protect the elderly, young children and even pets via estimating their locations in a city. In order to achieve long-term portability and network-side positioning, the system does not directly rely on GPS receiver mounted on terminals but use machine learning for location estimation via the received signal strength indication (RSSI) measurements. In particular, the system consists of Wi-SUN beacons, Wi-SUN base-stations and vehicular devices. A beacon, attached to the one to be positioned, broadcasts wireless signal periodically so that its location can be estimated using machine learning algorithms from the RSSIs measured at multiple base-stations that are densely deployed over a city to construct an ad hoc network. Using the mobility of vehicles that roam over a city routinely, such like garbage collection trucks, buses and taxies. Vehicular devices containing both a Wi-SUN beacon and a GPS are used to collect RSSIs and the corresponding GPS coordinates to train the estimation models. We develop a prototype system consisting of 9 base-stations and deploy it to our university campus to conduct a field experiment to validate the proposed approach. Offline analysis on the data collected from the experiment showed that a RandomForest learner performs best among four selected learning algorithms using the default parameters of Weka 3.8, which achieves a mean absolute error of 35.43m and a root mean squared error of 44.21m, respectively. Evaluation on network performance is also conducted.},
keywords={Urban areas;Global Positioning System;Sensors;Fans;Estimation;Automotive engineering;Receivers;Positioning;Wi-SUN;Machine learning;Automotive sensing;Smart cities},
doi={10.23919/ICMU.2018.8653618},
ISSN={},
month={Oct},}
@INPROCEEDINGS{8947847,
author={Capodieci, Antonio and Mainetti, Luca and Panarese, Paolo},
booktitle={2018 International Conference on Computational Science and Computational Intelligence (CSCI)}, title={Ambient Assisted Living for Elderly People Using Smart Personal Assistants},
year={2018},
volume={},
number={},
pages={935-940},
abstract={The demand of innovative solutions to afford healthy and safe lifestyle, for elderly people, are increasing lead by the growth of the ageing population and age-related diseases. Moreover, the availability of smart devices based on IoT technologies for personal environments has evolved the demand for tools to monitor and remotely control the home equipment. A new generation of remote control is available: Electronic Personal Assistants. These devices could be controlled using natural user interfaces, help user to simplify the interaction with home automation and other smart devices. The personal assistants use machine learning strategies to interact with the user. The solutions available in the market are often expensive and, moreover, are limited and legacy since based on proprietary hardware and software. This paper aims to present Alfred, a flexible and modular smart personal assistant based on low-cost hardware and open source machine learning software, in the context of the City4Age, an H2020 Project, to provide Elderly-friendly ambient assisted living.},
keywords={Germanium;Scientific computing;Computational intelligence;Electronic Personal Assistant, IoT, Smart Cities, Open Source, Machine Learning},
doi={10.1109/CSCI46756.2018.00183},
ISSN={},
month={Dec},}
@ARTICLE{8734079,
author={Zhu, Ran and Xiao, Zhuoling and Li, Ying and Yang, Mingkun and Tan, Yawen and Zhou, Liang and Lin, Shuisheng and Wen, Hongkai},
journal={IEEE Access}, title={Efficient Human Activity Recognition Solving the Confusing Activities Via Deep Ensemble Learning},
year={2019},
volume={7},
number={},
pages={75490-75499},
abstract={The ubiquity of smartphones and their rich set of on-board sensors has created many exciting new opportunities, where smartphones are used as powerful computing platforms to sense and analyze pervasive data. One important application of mobile sensing is activity recognition based on smartphone inertial sensors, which is a fundamental building block for a variety of scenarios, such as indoor pedestrian tracking, mobile health care, and smart cities. Although many approaches have been proposed to address the human activity recognition problem, several challenges are still present: 1) people's motion modes are very different for different individuals; 2) there is only a very limited amount of training data; 3) human activities can be arbitrary and complex, thus handcrafted feature engineering often fails to work; and 4) the recognition accuracy tends to be limited due to confusing activities. To tackle those challenges, in this paper, we propose a human activity recognition framework based on convolutional neural networks (CNNs) with two convolutional layers using the smartphone-based accelerometer, gyroscope, and magnetometer. To solve the confusion between highly similar activities like going upstairs and walking, this paper presents a novel ensemble model of CNN to further improve the identification accuracy. The extensive experiments have been conducted using 235 977 sensory samples from a total of 100 subjects. The results have shown that the classification accuracy of the proposed model can be up to 96.11%, which proves the effectiveness of the proposed model.},
keywords={Feature extraction;Smart phones;Activity recognition;Hidden Markov models;Deep learning;Motion detection;Convolutional neural network;human activity recognition;sensor data;smartphone},
doi={10.1109/ACCESS.2019.2922104},
ISSN={2169-3536},
month={},}
@ARTICLE{9267792,
author={Dong, Peiran and Ning, Zhaolong and Ma, Rong and Wang, Xiaojie and Hu, Xiping and Hu, Bin},
journal={China Communications}, title={NOMA-based energy-efficient task scheduling in vehicular edge computing networks: A self-imitation learning-based approach},
year={2020},
volume={17},
number={11},
pages={1-11},
abstract={Mobile Edge Computing (MEC) is promising to alleviate the computation and storage burdens for terminals in wireless networks. The huge energy consumption of MEC servers challenges the establishment of smart cities and their service time powered by rechargeable batteries. In addition, Orthogonal Multiple Access (OMA) technique cannot utilize limited spectrum resources fully and efficiently. Therefore, Non-Orthogonal Multiple Access (NOMA)-based energy-efficient task scheduling among MEC servers for delay-constraint mobile applications is important, especially in highly-dynamic vehicular edge computing networks. The various movement patterns of vehicles lead to unbalanced offloading requirements and different load pressure for MEC servers. Self-Imitation Learning (SIL)-based Deep Reinforcement Learning (DRL) has emerged as a promising machine learning technique to break through obstacles in various research fields, especially in time-varying networks. In this paper, we first introduce related MEC technologies in vehicular networks. Then, we propose an energy-efficient approach for task scheduling in vehicular edge computing networks based on DRL, with the purpose of both guaranteeing the task latency requirement for multiple users and minimizing total energy consumption of MEC servers. Numerical results demonstrate that the proposed algorithm outperforms other methods.},
keywords={Task analysis;Servers;Delays;Energy efficiency;Energy consumption;Edge computing;NOMA;NOMA;energy-efficient scheduling;vehicular edge computing;imitation learning},
doi={10.23919/JCC.2020.11.001},
ISSN={1673-5447},
month={Nov},}
@INPROCEEDINGS{8530854,
author={Shi, Jia and Fan, Xiaoliang and Wu, Jinzhun and Chen, Jian and Chen, Wenbo},
booktitle={2018 Sixth International Conference on Advanced Cloud and Big Data (CBD)}, title={DeepDiagnosis: DNN-Based Diagnosis Prediction from Pediatric Big Healthcare Data},
year={2018},
volume={},
number={},
pages={287-292},
abstract={Mining electronic health records (EHRs) has been considered as a major decision-making tool for clinical diagnosis. In fact, it is difficult to extract the valuable information from EHRs due to free-text writing, incomplete description, and high variabilities of diseases. Especially for pediatric EHRs, the shortage of experienced pediatricians as well as complex environmental factors such as seasonal variations, cross infections from kindergartens, make it extremely challenging to conduct a precise diagnosis. To address those challenges, we proposed DeepDiagnosis, a novel deep neural network-based diagnosis prediction algorithm by mining massive pediatric EHRs. First, we pre-process the unstructured EHRs dataset in Chinese and transfer them into sentence vectors by natural language processing technologies. Second, we construct the bidirectional recurrent neural networks (BiRNN) model to catch the patients' clinical symptoms as well as their interaction. Finally, we train and evaluate our model using a real-world dataset containing 81,476 pediatric EHRs. Experimental results show that the proposed method outperforms many baseline methods.},
keywords={Diseases;Electronic medical records;Predictive models;Respiratory system;Data mining;Writing;Environmental factors;electronic health records, diagnosis prediction, deep neural networks},
doi={10.1109/CBD.2018.00058},
ISSN={},
month={Aug},}
@ARTICLE{8913526,
author={Hassib, Eslam Mohsen and El-Desouky, Ali Ibrahim and El-Kenawy, El-Sayed M. and El-Ghamrawy, Sally M.},
journal={IEEE Access}, title={An Imbalanced Big Data Mining Framework for Improving Optimization Algorithms Performance},
year={2019},
volume={7},
number={},
pages={170774-170795},
abstract={Big data is an important factor almost in all nowadays technologies, such as, social media, smart cities, and internet of things. Most of standard classifiers tends to be trapped in local optima problem when dealing with such massive datasets. Hence, investigating new techniques for dealing with such massive data sets is required. This paper presents a novel imbalanced big data mining framework for improving optimization algorithms performance by eliminating the local optima problem consists of three main stages. Firstly, the preprocessing stage, which uses the LSH-SMOTE algorithm for solving the class imbalance problem, then it uses the LSH algorithm for hashing the data set instances into buckets. Secondly, the bucket search stage, which uses the GWO for training bidirectional recurrent neural network BRNN and searching for the global optimum in each bucket. Lastly, the final tournament winner stage, which uses the GWO+BRNN for finding the global optimum of the whole data set among all global optimums from all buckets. Our proposed framework LSHGWOBRNN has been tested over 9 data sets one of them is big data set in terms of AUC, MSE, against seven well-known machine-learning algorithms (Naive Bayes, Random Tree, Decision Table, and AdaBoostM1, WOA+MLP, GWO+MLP, and WOA+BRNN), then, we tested our algorithm over four well-known data sets against GWO+MLP, ACO+MLP, GA+MLP, PSO+MLP, PBIL+MLP, and ES+MLP in terms of classification accuracy and MSE. Our experimental results have proved that our proposed framework LSHGWOBRNN has provided high local optima avoidance, and higher accuracy, less complexity and overhead.},
keywords={Big Data;Classification algorithms;Neurons;Data mining;Optimization;Deep learning;Social networking (online);Grey wolf optimizer;neural network;big data mining;deep learning;imbalanced data sets;optimization},
doi={10.1109/ACCESS.2019.2955983},
ISSN={2169-3536},
month={},}
@INPROCEEDINGS{8639168,
author={Eda, Takeharu and Muramatsu, Sanae and Mikami, Keita and Xu, Shi},
booktitle={2018 15th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS)}, title={A Practical Person Monitoring System for City Security},
year={2018},
volume={},
number={},
pages={1-6},
abstract={Recent progress in Deep Learning(DL) has brought many breakthroughs with incredible performance, which have not been achieved with traditional machine learning algorithms. In computer vision, DL-based methods have started to outperform humans in certain tasks and are going to impact our daily lives. We present our case study of an implementation and evaluation of our prototype real-time person-monitoring system using cutting-edge DL computer vision techniques. We used a fast and lightweight stream-processing engine for its flexibility and portability, packaged all of DL software stacks as docker containers for portability and ease of deployment, and evaluated our prototype's performance using realistic scenarios in which one hundred camera streams are gathered at centered GPU servers. We confirmed that our prototype system can monitor one hundred video streams in real-time. We also report lessons learned through our prototype implementation and discuss the future direction of person monitoring.},
keywords={Streaming media;Cameras;Servers;Prototypes;Pipelines;Monitoring;Graphics processing units},
doi={10.1109/AVSS.2018.8639168},
ISSN={},
month={Nov},}
@ARTICLE{8908558,
author={Chen, Ning and Qiu, Tie and Zhou, Xiaobo and Li, Keqiu and Atiquzzaman, Mohammed},
journal={IEEE Communications Magazine}, title={An Intelligent Robust Networking Mechanism for the Internet of Things},
year={2019},
volume={57},
number={11},
pages={91-95},
abstract={In smart cities, the Internet of Things (IoT) consists of many low-power smart nodes. Its robustness is essential for protection of communication in data science against node failures caused by energy shortage or cyber-attacks. Scale-free networking topology, widely applied in IoT, is effectively resilient to random attacks but is vulnerable to malicious ones in which high-degree nodes are made to fail. The prohibitively high computational cost of existing robustness optimization algorithms is an obstacle to efficient topology self-optimization. To solve this problem, a novel robust networking model based on artificial intelligence is proposed to improve IoT topology robustness to protect its communication. Using the Back-Propagation neural network learning algorithm, the model extracts topology features from a dataset by supervised training. The experimental results show that the model achieves better prediction accuracy, thereby optimizing the topology with minimal computation overhead.},
keywords={Machine learning;Network topology;Robustness;Training data;Mathematical model;Computational modeling;Neural networks},
doi={10.1109/MCOM.001.1900094},
ISSN={1558-1896},
month={November},}
@INPROCEEDINGS{9469581,
author={Olaya-Quiñones, Jose D. and Perafan-Villota, Juan C.},
booktitle={2021 IEEE Colombian Conference on Applications of Computational Intelligence (ColCACI)}, title={A smart algorithm for traffic lights intersections control in developing countries},
year={2021},
volume={},
number={},
pages={1-6},
abstract={Traffic jam is a problem that directly affects the quality of life of the population in large cities. This problem exacerbates at road intersections, where obsolete traffic control systems based on a static set of rules remain in use. We propose an algorithm that improves vehicular flow control at traffic-light intersections by optimizing a dynamic allocation of times. We train our own YOLO detector using a set of images captured from traffic cameras installed at a cross-road. Based on the number of vehicles detected in each intersection road, one set of rules was created and used by a fuzzy control. Since, at the local level, there are few traffic cameras installed on intersections. We build a simulated environment both to train our detector system and verify the efficiency of our algorithm.},
keywords={Roads;Heuristic algorithms;Urban areas;Sociology;Detectors;Traffic control;Cameras;Smart city;Traffic jam;Deep learning;Fuzzy Logic;YOLO;Unit3D},
doi={10.1109/ColCACI52978.2021.9469581},
ISSN={},
month={May},}
@INPROCEEDINGS{9564192,
author={Attoui, Seif-Eddine and Meddeb, Maroua},
booktitle={2021 IEEE 8th International Conference on Data Science and Advanced Analytics (DSAA)}, title={A generic framework for forecasting short-term traffic conditions on urban highways},
year={2021},
volume={},
number={},
pages={1-10},
abstract={With the emergence of Connected and Smart Cities, the need to predict traffic conditions has led to the development of a large variety of forecasting algorithms. In spite of various research efforts, the choice of models and techniques strongly depends on the use case, the highway infrastructure as well as the provided dataset. This study is launched as part of a project which aims to design an Intelligent Transport System (ITS) dedicated to highway supervisors to regulate traffic. This system needs to be supplied by continuous, real-time forecasting of short-term traffic congestions in order to make decisions accordingly. In this paper, we propose a general framework that, first, performs different data preprocessing techniques to improve data quality, and second, provides real-time multiple horizons predictions. Our framework uses different models combining Machine learning and Deep learning algorithms. Experiments results confirmed the necessity of the data preprocessing step, especially with highly dynamic data and heterogeneous mobility contexts. In addition, our methodology is tested in a real case study and shows very encouraging results.},
keywords={Machine learning algorithms;Smart cities;Data integrity;Data preprocessing;Transportation;Prediction algorithms;Real-time systems;Intelligent Transportation Systems;Traffic forecasting;Short-term;Data preprocessing;Data balancing},
doi={10.1109/DSAA53316.2021.9564192},
ISSN={},
month={Oct},}
@INPROCEEDINGS{8782429,
author={Akpinar, Kubra Nur and Ozgonenel, Okan},
booktitle={2019 7th International Istanbul Smart Grids and Cities Congress and Fair (ICSG)}, title={Optimization of Artificial Neural Network for Power Quality Disturbances Detection},
year={2019},
volume={},
number={},
pages={95-98},
abstract={The following topics are dealt with: smart power grids; power generation economics; distributed power generation; power engineering computing; wireless sensor networks; building management systems; power generation control; smart cities; power markets; Internet of Things.},
keywords={Artificial neural networks;Neurons;Power quality;Mathematical model;Training;Response surface methodology;Optimization;artificial neural network;box behnken design;optimization;power quality;response surface analysis},
doi={10.1109/SGCF.2019.8782429},
ISSN={},
month={April},}
@INPROCEEDINGS{8576131,
author={Ruffieux, Simon and Mugellini, Elena and Abou Khaled, Omar},
booktitle={2018 IEEE 30th International Conference on Tools with Artificial Intelligence (ICTAI)}, title={Bike Usage Forecasting for Optimal Rebalancing Operations in Bike-Sharing Systems},
year={2018},
volume={},
number={},
pages={854-858},
abstract={This article presents the first step of a project focusing on enhancing the management of bike-sharing systems. The objective of the project is to optimize the daily rebalancing operations that need to be performed by operators of bike-sharing systems using machine-learning algorithms and constraint programming. This study presents an evaluation of machine learning algorithms developed for forecasting the availability of bikes on three Swiss bike-sharing networks. The results demonstrate the superiority of the Multi-Layer Perceptron algorithm for forecasting available bikes at station-level for different prediction horizons and its applicability for real-time prediction generation.},
keywords={Prediction algorithms;Forecasting;Companies;Real-time systems;Urban areas;Measurement;Forestry;machine learning;forecasting;optimal rebalancing;bike-sharing systems;smart mobility;smart city},
doi={10.1109/ICTAI.2018.00133},
ISSN={2375-0197},
month={Nov},}
@INPROCEEDINGS{9654360,
author={Karaarslan, Enis and Babiker, Mohammed},
booktitle={2021 International Conference on Information Security and Cryptology (ISCTURKEY)}, title={Digital Twin Security Threats and Countermeasures: An Introduction},
year={2021},
volume={},
number={},
pages={7-11},
abstract={The digital twin is based on integrated technologies such as the Internet of Things (IoT), Cloud Computing, Machine Learning, and Artificial Intelligence. The digital twin has become an important method of the digital manufacturing processes for the fourth industrial revolution. The digital twin is driven by increased intelligence, digitization, and reliability of smart manufacturing assets. It has potential usage areas such as construction, smart cities, and healthcare. It could be used to increase the overall performance of the potential systems and to support the physical world. Although extensive benefits are recognized, the security risks for using the digital twin have yet to be explored. The physical world of various nodes communicates with the digital twin. The digital twins will also communicate with each other in the near future. This study investigates the risks and threats which target the components of digital twin, machine learning processes, and data communication. Potential countermeasures and also future work is given.},
keywords={Manufacturing processes;Smart cities;Digital twin;Information security;Machine learning;Medical services;Internet of Things;digital twin;digital twin security;digital twin threats;data communication;artificial intelligence},
doi={10.1109/ISCTURKEY53027.2021.9654360},
ISSN={},
month={Dec},}
@ARTICLE{8936853,
author={Wu, Zhengtian and Karimi, Hamid Reza and Dang, Chuangyin},
journal={IEEE Transactions on Neural Networks and Learning Systems}, title={A Deterministic Annealing Neural Network Algorithm for the Minimum Concave Cost Transportation Problem},
year={2020},
volume={31},
number={10},
pages={4354-4366},
abstract={In this article, a deterministic annealing neural network algorithm is proposed to solve the minimum concave cost transportation problem. Specifically, the algorithm is derived from two neural network models and Lagrange-barrier functions. The Lagrange function is used to handle linear equality constraints, and the barrier function is used to force the solution to move to the global or near-global optimal solution. In both neural network models, two descent directions are constructed, and an iterative procedure for the optimization of the neural network is proposed. As a result, two corresponding Lyapunov functions are naturally obtained from these two descent directions. Furthermore, the proposed neural network models are proved to be completely stable and converge to the stable equilibrium state, therefore, the proposed algorithm converges. At last, the computer simulations on several test problems are made, and the results indicate that the proposed algorithm always generates global or near-global optimal solutions.},
keywords={Transportation;Annealing;Optimization;Biological neural networks;Computational modeling;Linear programming;Annealing scheme;barrier function;combinatorial optimization;Lagrange multipliers;minimum concave cost transportation;neural network},
doi={10.1109/TNNLS.2019.2955137},
ISSN={2162-2388},
month={Oct},}
@INPROCEEDINGS{8908023,
author={George, Anjus and Ravindran, Arun},
booktitle={2019 IEEE 16th International Conference on Smart Cities: Improving Quality of Life Using ICT IoT and AI (HONET-ICT)}, title={Distributed Middleware for Edge Vision Systems},
year={2019},
volume={},
number={},
pages={193-194},
abstract={Recent advances in Deep Learning, have made possible distributed multi-camera vision analytics targeted at a variety of surveillance applications involving automated real-time analysis of events from multiple video perspectives. However, the latency critical nature of these applications necessitates computing at the Edge of the network, close to the cameras [1] . The required Edge computing infrastructure is necessarily distributed, with cloud like capabilities such as fault tolerance, scalability, multi-application tenancy, and security, while functioning at the unique operating environment of the Edge. Characteristics of the Edge include, highly heterogeneous hardware platforms with limited computational resources, variable latency wireless networks, and minimal physical security. To enable vision analytics at the Edge, application developers need a distributed middleware layer that provides a suitable abstraction of the Edge computing system, allowing cloud like DevOps workflow at the Edge. Middleware layers facilitate application development by providing suitable system abstractions thereby allowing the application programmers to focus on the applications needs rather than system details. In this poster, we present the requirements of such a middleware system. We propose a distributed messaging system with storage capabilities as a potential candidate for the middleware layer.},
keywords={Image edge detection;Middleware;Servers;Streaming media;Peer-to-peer computing;Machine vision;Tuning},
doi={10.1109/HONET.2019.8908023},
ISSN={1949-4106},
month={Oct},}
@INPROCEEDINGS{9124947,
author={Ali, Hamad Younis and El-Medany, Wael},
booktitle={2nd Smart Cities Symposium (SCS 2019)}, title={IoT security: A review of cybersecurity architecture and layers},
year={2019},
volume={},
number={},
pages={1-7},
abstract={With the fast advancement in Technology, it started to get in every aspect of our lives. Especially that these devices are getting smaller, low power consuming and connects to the internet along with other IoT devices most or all the time thus internet of things devices are becoming a major part and can be seen everywhere in consumers houses or businesses. With these devices several risks in term of security and privacy are emerging, especially with data becoming so valuable for spying or profiting. This paper will explain privacy, its aspect and meanings to obtain a clear definition of types and ways privacy is invaded or violated. There are several laws regarding information, data privacy and protection, example of old and recent court cases with corresponding rulings. For a better understanding of how they are violated thus what should be considered or protected. There are different Layers of IoT security architecture available and described in order to protect the availability, confidentiality and integrity of IoT devices, besides a few suggested areas that need to be considered or addressed. Types of data and information that can be collected, aspects and attacks to IoT devices in terms of machine and deep learning and the data yielded from them, also the solutions approached are recommended by the author.},
keywords={IoT;Security;Architecture;Privacy},
doi={10.1049/cp.2019.0191},
ISSN={},
month={March},}
@INPROCEEDINGS{8656659,
author={Torabi, Behnam and Wenkstern, Rym Z. and Saylor, Robert},
booktitle={2018 IEEE International Smart Cities Conference (ISC2)}, title={A Self-Adaptive Collaborative Multi-Agent based Traffic Signal Timing System},
year={2018},
volume={},
number={},
pages={1-8},
abstract={In this paper, we present DALI, a self-adaptive, collaborative multi-agent Traffic Signal Timing system (TST). Intersection controller agents collaborate with one another and adapt their timing plans based on the traffic conditions. Reinforcement learning is used to optimize values for the various thresholds necessary to dynamically determine the scope of collaboration between the agents. DALI was implement in MATISSE 3.0, a large-scale agent-based micro-simulator. Experimental results show an improvement over traditional and reinforcement learning TSTs.},
keywords={Urban areas;Collaboration;Delays;Optimization;Detectors;Adaptation models},
doi={10.1109/ISC2.2018.8656659},
ISSN={},
month={Sep.},}
@INPROCEEDINGS{9545684,
author={Hossain, M. and Haque, M. S. and Arifuzzaman, M. and Zakir Hossain, S. M.},
booktitle={3rd Smart Cities Symposium (SCS 2020)}, title={Artificial neural network based system for distorted image recognition},
year={2020},
volume={2020},
number={},
pages={503-508},
abstract={Artificial neural networks (ANNs) have been recognized as universal estimators and widely used in a range of fields starting from computer science, medical, neuroscience, engineering, remote sensing, artificial intelligence to business and stock markets. In this study the effectiveness of ANNs for recognition of character pattern as an example has been studied. A programming code has been developed to build ANN model system that utilized feedforward backpropagation methodology in learning session and subsequently recognized several predefined alphabet characters. Based on computational resources A 7×5 matrix bit map was achieved for a number of characters such as A, B, C, D, E and F. Backpropagation training was used to adjust the weights of the branches connecting the neuron layers. Thirty-five digitized values (0, 1) against each character were fed to the model as input variables and fetched to thirty-five input neurons of the as-modeled ANN system. The output was considered as specified codes for each character such as 01010, 01010, 01100, 01101, 01110 and 01111 respectively. The training continued till the predefined tolerance limit reached to less than 0.0001. Forward run of the ANN processing was observed capable enough to recognize some irregular pattern in the character. The results showed that with some modifications in the bit pattern the ANN model system could recognize the pattern of the exact character with maximum 37.5 % deformation. Such a model can be exploited to further advancement in pattern recognition system developments.},
keywords={},
doi={10.1049/icp.2021.0852},
ISSN={},
month={Sep.},}
@INPROCEEDINGS{9545848,
author={Al Asheeri, M. and Hammad, M.},
booktitle={3rd Smart Cities Symposium (SCS 2020)}, title={Improving software cost estimation process using feature selection technique},
year={2020},
volume={2020},
number={},
pages={89-95},
abstract={Software cost estimation is an important task in any software development cycle. It helps project and software engineers to do better planning and resource management. Mining historical data to predict the future cost is a commonly used approach. However, dataset used in software estimation models plays a crucial role in the model accuracy. In this paper, feature selection techniques applied to different datasets in order to improve the model accuracy, reduce data redundancy, and increase the model performance. Five types of evaluation criteria were used to compare the results of 13 machine-learning methods before and after applying the feature selection techniques. Results showed that feature selection techniques can obviously increase the accuracy of the prediction model.},
keywords={},
doi={10.1049/icp.2021.0856},
ISSN={},
month={Sep.},}
@INPROCEEDINGS{9545847,
author={Mahfoodh, H. and Hammad, M.},
booktitle={3rd Smart Cities Symposium (SCS 2020)}, title={Bug-fix time prediction using non-linear regression through neural network},
year={2020},
volume={2020},
number={},
pages={622-627},
abstract={Software bugs are considered inevitable in the software life cycle. Regardless of their cause, software stakeholders could benefit from knowing the time to fix them to enhance software management processes and liaise with developers to handle software pipeline tasks better. In this paper, we use neural network machine learning approach with non-linear regression model to conduct a prediction of bug-fix time retrieved from actual bug fixed records taken from 9 bugs reports from two open-source projects. The paper evaluates the bug-fix time prediction results by using four regression metrics. The result of the nonlinear regression testing showed a high correlation between the adjacent distributions of the bug samples time by giving high prediction accuracy rates. Additionally, we found that the module gave better results for samples with fewer bug records with the condition of fair distribution with respect to the fix time values.},
keywords={},
doi={10.1049/icp.2021.0871},
ISSN={},
month={Sep.},}
@INPROCEEDINGS{7828406,
author={Li, Yuxiang and Zhao, Yinliang and Wu, Qiangsheng},
booktitle={2016 IEEE 18th International Conference on High Performance Computing and Communications; IEEE 14th International Conference on Smart City; IEEE 2nd International Conference on Data Science and Systems (HPCC/SmartCity/DSS)}, title={A Graph-Based Thread Partition Approach in Speculative Multithreading},
year={2016},
volume={},
number={},
pages={406-413},
abstract={Speculative Multithreading (SpMT) is a thread level automatic parallelization technique to accelerate sequential programs. Conventional thread partition algorithms primarily include heuristic-based and machine learning-based. The existing heuristic-based approaches are only suitable for one kind of programs and can not guarantee to get the optimal solution of thread partitioning, and the existing machine learning-based approaches usually use vector-based characterization to represent a program, but easily ignore control information among basic blocks. In this paper, we present a novel graph-based thread partition approach to avoid these problems. It characterizes programs by graphs, integrating static and dynamic features, as well as data and control information. The graph-based partition approach learns partition knowledge and predicts partition for unseen programs. Prophet, which consists of an automatic parallelization compiler and a multi-core simulator, evaluates the performance of multithreaded programs. Olden benchmarks are used to realize the approach. Experiments show that our approach delivers a maximum performance improvement of 37.42% on a 16 core than heuristic-based approach, and 37.41% against conventional machine learning-based approach. These results suggest that our graph-based thread partition approach is effective for thread partition in Speculative Multithreading.},
keywords={Training;Partitioning algorithms;Feature extraction;Instruction sets;Prediction algorithms;Multithreading;Speculative Multithreading;graph-based thread partition;machine learning},
doi={10.1109/HPCC-SmartCity-DSS.2016.0065},
ISSN={},
month={Dec},}
@INPROCEEDINGS{8917286,
author={Chu, Kai-Fung and Lam, Albert Y.S. and Loo, Becky P.Y. and Li, Victor O.K.},
booktitle={2019 IEEE Intelligent Transportation Systems Conference (ITSC)}, title={Public Transport Waiting Time Estimation Using Semi-Supervised Graph Convolutional Networks},
year={2019},
volume={},
number={},
pages={2259-2264},
abstract={An effective transportation system is important for supporting various human activities in a modern smart city. The waiting time at various stations has great impacts on the overall transportation system efficiency and people's health like stress and anxiety. Knowing the waiting time at different locations in advance can assist the travelers to plan their trips. However, such waiting time may depend on many factors like crowdedness and the collective travel behaviors of the travellers involved. In general, it is very expensive to collect all the required data at every location. In this paper, a deep learning approach is proposed for determining the waiting time levels at public transport stations based on some proxy data and limited historical waiting time data at some stations. We formulate the public transportation network as a graph and develop a semi-supervised classification model based on Graph Convolutional Networks which can operate directly on the graph-structured data with limited labelled data. We conduct experiments for the mass transit railway in Hong Kong with real data and our proposed approach can achieve 89% accuracy of classifying the waiting time levels.},
keywords={Public transportation;Machine learning;Data models;Estimation;Convolution;Roads},
doi={10.1109/ITSC.2019.8917286},
ISSN={},
month={Oct},}
@INPROCEEDINGS{7034852,
author={Dia, Hussein and Panwai, Sakda},
booktitle={2014 IEEE Fourth International Conference on Big Data and Cloud Computing}, title={Intelligent Mobility for Smart Cities: Driver Behaviour Models for Assessment of Sustainable Transport},
year={2014},
volume={},
number={},
pages={625-632},
abstract={The convergence of physical and digital worlds is creating unprecedented opportunities to enhance the travel experience for millions of people every day. A key to the success of these systems is a good understanding of driver behaviour under the influence of travel information. This paper presents the application of a new generation of driver behaviour models, based on neural agent (neugent) techniques, to describe drivers' decisions and compliance with travel information. The new models enhance the capabilities of existing simulation tools in modelling the behaviour of heterogeneous drivers and dealing with the vagueness inherent in driver decision making and the information received from sensors and the road environment. This paper also describes the traffic simulation and practical applications of the new models and how they serve to assess the impacts of smart and sustainable transport interventions.},
keywords={Vehicles;Roads;Delays;Traffic control;Data models;Fuels;Accuracy;intelligent transport systems;sustainable transport;driver behaviour;artificial neural networks;neural agents;traffic simulation;incident management},
doi={10.1109/BDCloud.2014.50},
ISSN={},
month={Dec},}
@ARTICLE{9386249,
author={Tan, Ee-Leng and Karnapi, Furi Andi and Ng, Linus Junjia and Ooi, Kenneth and Gan, Woon-Seng},
journal={IEEE Internet of Things Journal}, title={Extracting Urban Sound Information for Residential Areas in Smart Cities Using an End-to-End IoT System},
year={2021},
volume={8},
number={18},
pages={14308-14321},
abstract={With rapid urbanization comes the increase of community, construction, and transportation noise in residential areas. The conventional approach of solely relying on sound pressure-level information to decide on the noise environment and to plan out noise control and mitigation strategies is inadequate. This article presents an end-to-end Internet-of-Things (IoT) system that extracts real-time urban sound metadata using edge devices, providing information on the sound type, location and duration, rate of occurrence, loudness, and azimuth of a dominant noise in nine residential areas. The collected metadata on environmental sound is transmitted to and aggregated in a cloud-based platform to produce detailed descriptive analytics and visualization. Our approach in integrating different building blocks, namely, hardware, software, cloud technologies, and signal processing algorithms to form our real-time IoT system is outlined. We demonstrate how some of the sound metadata extracted by our system are used to provide insights into the noise in residential areas. A scalable workflow to collect and prepare audio recordings from nine residential areas to construct our urban sound data set for training and evaluating a location-agnostic model is discussed. Some practical challenges of managing and maintaining a sensor network deployed at numerous locations are also addressed.},
keywords={Metadata;Cloud computing;Azimuth;Internet of Things;Acoustics;Monitoring;Image edge detection;Acoustic source event detection;deep neural networks (DNNs);edge analytics;edge-cloud architecture;Internet of Things (IoT)},
doi={10.1109/JIOT.2021.3068755},
ISSN={2327-4662},
month={Sep.},}
@INPROCEEDINGS{9547130,
author={Bertolusso, Marco and Spanu, Michele and Fadda, Mauro and Giusto, Daniele D.},
booktitle={2021 IEEE International Symposium on Broadband Multimedia Systems and Broadcasting (BMSB)}, title={A $\text{DAB}+$ Approach for Vehicular Tracking},
year={2021},
volume={},
number={},
pages={1-5},
abstract={This paper addresses vehicle tracking using an approach based on the $\mathbf{DAB }+$ standard, which is becoming increasingly popular in private vehicles as an alternative to the old FM radio standard. The digital standard allows the use of different contents useful to the driver. On the other hand, the bidirectional channel of the $\mathbf{DAB }+$ standard could allow the vehicle to transmit generic information. The aim of this work is to transmit some parameters of the radio channel to allow the identification and tracking of vehicle position. By means of a neural network it is possible to reconstruct the path of the vehicles through a maximum likelihood comparison between data contained in a data-set and the information offered by the vehicles in real time. Experimental tests conducted on the road have shown how it is possible to obtain a high accuracy of vehicle traffic in a transparent manner and with respect for the processing of personal data in accordance with current European legislation.},
keywords={Training;Performance evaluation;Maximum likelihood detection;Roads;Neural networks;Real-time systems;Multimedia communication;Digital Audio Broadcasting (DAB);Vehicular Mobility and Tracking;Broadcast applications to Smart Cities;Machine learning for communications},
doi={10.1109/BMSB53066.2021.9547130},
ISSN={2155-5052},
month={Aug},}
@ARTICLE{8741193,
author={Rossi, Alberto and Barlacchi, Gianni and Bianchini, Monica and Lepri, Bruno},
journal={IEEE Transactions on Intelligent Transportation Systems}, title={Modelling Taxi Drivers’ Behaviour for the Next Destination Prediction},
year={2020},
volume={21},
number={7},
pages={2980-2989},
abstract={In this paper, we study how to model taxi drivers' behavior and geographical information for an interesting and challenging task: the next destination prediction in a taxi journey. Predicting the next location is a well-studied problem in human mobility, which finds several applications in real-world scenarios, from optimizing the efficiency of electronic dispatching systems to predicting and reducing the traffic jam. This task is normally modeled as a multiclass classification problem, where the goal is to select, among a set of already known locations, the next taxi destination. We present a Recurrent Neural Network (RNN) approach that models the taxi drivers' behavior and encodes the semantics of visited locations by using geographical information from Location-Based Social Networks (LBSNs). In particular, the RNNs are trained to predict the exact coordinates of the next destination, overcoming the problem of producing, in output, a limited set of locations, seen during the training phase. The proposed approach was tested on the ECML/PKDD Discovery Challenge 2015 dataset-based on the city of Porto-, obtaining better results with respect to the competition winner, whilst using less information, and on Manhattan and San Francisco datasets.},
keywords={Public transportation;Urban areas;Trajectory;Predictive models;Recurrent neural networks;Task analysis;Vehicles;Taxi destination prediction;deep learning;LSTM;smart cities},
doi={10.1109/TITS.2019.2922002},
ISSN={1558-0016},
month={July},}
@INPROCEEDINGS{9097761,
author={Pashamokhtari, Arman and Gharakheili, Hassan Habibi and Sivaraman, Vijay},
booktitle={2020 Workshop on Emerging Technologies for Security in IoT (ETSecIoT)}, title={Progressive Monitoring of IoT Networks Using SDN and Cost-Effective Traffic Signatures},
year={2020},
volume={},
number={},
pages={1-6},
abstract={IoT networks continue to expand in various domains, from smart homes and campuses to smart cities and critical infrastructures. It has been shown that IoT devices typically lack appropriate security measures embedded, and hence are increasingly becoming the target of sophisticated cyber-attacks. Also, these devices are heterogeneous in their network communications that makes it difficult for operators of smart environments to manage them at scale. Existing monitoring solutions may perform well in certain environments, however, they do not scale cost-effectively and are inflexible to changes due to their static use of models. In this paper1, we use SDN to dynamically monitor a selected portion of IoT packets or flows, and develop specialized models to learn corresponding traffic signatures. Our first contribution develops a progressive inference pipeline, comprising a number of machine-learning models each is specialized in certain features of IoT traffic. Our inference engine dynamically obtains selected telemetry, including a subset of traffic or flow counters, using SDN techniques. Our second contribution develops three supervised multi-class classifiers, two are protocol specialists trained by packet-based features and one is flow-based model trained by behavioral characteristics of ten unidirectional flows. Our third contribution evaluates the performance of our scheme by replaying real traffic traces of 26 IoT devices on to an SDN switching simulator in conjunction with three trained Random Forest models. Our system yields an overall accuracy of 99.4%. We also integrate our system with an off-the-shelf IDS (Zeek) to flag TCP flood and reflection attacks by inspecting only the suspicious device network traffic.},
keywords={Pipelines;Inspection;Telemetry;Monitoring;Protocols;Feature extraction;Machine learning},
doi={10.1109/ETSecIoT50046.2020.00005},
ISSN={},
month={April},}
@INPROCEEDINGS{9407843,
author={Zhang, Yuchao and Wu, Shuang and Wang, Wendong and Zhang, Zhuoyun and Han, Yunbo},
booktitle={2020 IEEE 22nd International Conference on High Performance Computing and Communications; IEEE 18th International Conference on Smart City; IEEE 6th International Conference on Data Science and Systems (HPCC/SmartCity/DSS)}, title={HttpDNS: A Flexible Architecture for Edge Server Exploration and Selection in 5G Network},
year={2020},
volume={},
number={},
pages={1021-1029},
abstract={With the emerging and development of low-latency applications (such as autonomous driving, SmartCity, telemedicine), low-latency has become one of the key requirements of current network services, especially in edge computing and 5G network. While under the state-of-the-art architecture, the request resolution is provided by Internet Service Provider's localDNS, which assigns a specific edge server for each request, but this method is now suffering from inaccurate scheduling problem, and fails to adapt to network changes due to the relatively fixed allocation strategy. These drawbacks result in the long response latency, and are becoming more severe in nowadays 5G edge networks. In this paper, we propose a flexible HttpDNS architecture for 5G edge server exploration and selection, where the domain names of users' requests are resolved by HttpDNS instead of the traditional localDNS. Under such architecture, user's request is directly transmitted to HttpDNS servers, which will then allocate a specific edge server for this request. With a server scoring module, the proposed HttpDNS architecture can finally ensure user requests be guided to the optimal edge server. We implement a prototype of HttpDNS architecture and conduct a series of experiments, the results show that such architecture not only reduces at least 10% latency compared with the traditional localDNS, but also has higher stability when network changes.},
keywords={5G mobile communication;Processor scheduling;Telemedicine;Web and internet services;Computer architecture;Reinforcement learning;User experience;Edge Server;5G;DNS;HttpDNS},
doi={10.1109/HPCC-SmartCity-DSS50907.2020.00137},
ISSN={},
month={Dec},}
@INPROCEEDINGS{8870679,
author={Lee, Chaedeok},
booktitle={2019 IEEE 32nd International Conference on Micro Electro Mechanical Systems (MEMS)}, title={Sensor as a Solution: Recent Progress in Intelligent Sensors Development},
year={2019},
volume={},
number={},
pages={256-256},
abstract={Sensors by MEMS technology in smart portable devices play an important role in corresponding to five human sensory systems, enhancing user convenience, and enriching user experience. The versatility of usage has led to a recent rapid development of sensor technology, resulting in commoditized sensors with low cost and high performance. Along with the smart deployment of those sensors, new types of MEMS sensors are always required for application in emerging areas such as autonomous vehicles, smart factories and so on. Recently, edge computing with a deep learning accelerator enables data filtering and classification. Although it shows a primitive level of context awareness for inferencing and decision-making, we believe that it will be one of the most important core technologies to accomplish smart loT, smart factory, and smart city technology. In our presentation, sensor technology and its evolution from devices to sensor-based services will be presented.},
keywords={Micromechanical devices},
doi={10.1109/MEMSYS.2019.8870679},
ISSN={2160-1968},
month={Jan},}
@INPROCEEDINGS{8569391,
author={Sliwa, Benjamin and Piatkowski, Nico and Haferkamp, Marcus and Dorn, Dennis and Wietfeld, Christian},
booktitle={2018 21st International Conference on Intelligent Transportation Systems (ITSC)}, title={Leveraging the Channel as a Sensor: Real-time Vehicle Classification Using Multidimensional Radio-fingerprinting},
year={2018},
volume={},
number={},
pages={898-905},
abstract={Upcoming Intelligent Transportation Systems (ITSs) will transform roads from static resources to dynamic Cyber Physical Systems (CPSs) in order to satisfy the requirements of future vehicular traffic in smart city environments. Up-to-date information serves as the basis for changing street directions as well as guiding individual vehicles to a fitting parking slot. In this context, not only abstract indicators like traffic flow and density are required, but also data about mobility parameters and class information of individual vehicles. Consequently, accurate and reliable systems that are capable of providing these kinds of information in real-time are highly demanded. In this paper, we present a system for the classification of vehicles based on their radio-fingerprints which applies cutting-edge machine learning models and can be non-intrusively installed into the existing road infrastructure in an ad-hoc manner. In contrast to other approaches, it is able to provide accurate classification results without causing privacy-violations or being vulnerable to challenging weather conditions. Moreover, it is a promising candidate for large-scale city deployments due to its cost-efficient installation and maintenance properties. The proposed system is evaluated in a comprehensive field evaluation campaign within an experimental live deployment on a German highway, where it is able to achieve a binary classification success ratio of more than 99% and an overall accuracy of 89.15% for a fine-grained classification task with nine different classes.},
keywords={Radio link;Roads;Machine learning;Attenuation;Magnetoacoustic effects;Magnetometers;Automobiles},
doi={10.1109/ITSC.2018.8569391},
ISSN={2153-0017},
month={Nov},}
@INPROCEEDINGS{9676252,
author={Bhale, Yogiraj and Agrawal, Nikhil and Kelwa, Sachin},
booktitle={2021 10th International Conference on System Modeling Advancement in Research Trends (SMART)}, title={Mask Detection using Computer Vision},
year={2021},
volume={},
number={},
pages={53-58},
abstract={Covid-19, a pandemic caused by a noble coronavirus, has afflicted the world for the past two years Every aspect of development has been impacted by Covid-19 There were several problems with the healthcare system In the meanwhile, numerous methods have been made to lessen the spirit of this condition, one of which is the use of a mask on the face In this research, we offer a strategy for reducing covid-19 development by identifying persons who are not using masks or are not wearing them appropriately Closed-circuit television (CCTV) cameras are used in smart cities and public places When a person without a mask is identified, the city network informs the authorities The deep learning design is based on a data set that compares photos of individuals wearing and without wearing masks from a variety of sources For prior test information, the prepared design aided 97. 3 percent of existence on dysentery individuals with and without a facial mask It is anticipated that our research would prove to be a beneficial tool in protecting our people from diseases like these},
keywords={COVID-19;Deep learning;Computer vision;TV;Smart cities;Pandemics;Computational modeling},
doi={10.1109/SMART52563.2021.9676252},
ISSN={2767-7362},
month={Dec},}
@INPROCEEDINGS{8875922,
author={Salur, Mehmet Umut and Aydin, İlhan and Alghrsi, Shahed Alali},
booktitle={2019 International Artificial Intelligence and Data Processing Symposium (IDAP)}, title={SmartSenti: A Twitter-Based Sentiment Analysis System for the Smart Tourism in Turkey},
year={2019},
volume={},
number={},
pages={1-5},
abstract={Today, it is possible to see smart solutions based on artificial intelligence in almost every area such as smart homes, smart assistants, smart cities, smart campuses as well as smart tourism centers. Smart tourism centers are mainly tourism solutions that targets more visitors. Visitors, before traveling to any tourist center, conduct research on the social media application, and they are generally evaluating previous visitor comments. Considering that there are many social media platforms, evaluating these comments manually requires great effort and time. In this study, we have developed a SmartSenti application that sentiment analysis which was performed on Twitter posts about tourism centers using machine learning and transfer learning methods. We have collected tweets about five touristic place in Turkey. These tweets are classified as positive or negative after pre-processing and feature extracting phase. The classification results are shared visually with the users through the mobile application that we developed.},
keywords={Twitter;Sentiment analysis;Feature extraction;Task analysis;Machine learning;Sentiment analysis;smart tourism;transductive transfer learning;Twitter;machine learning},
doi={10.1109/IDAP.2019.8875922},
ISSN={},
month={Sep.},}
@INPROCEEDINGS{6945483,
author={Pérez, David and Villaverde, Mónica and Moreno, Félix and Nogar, Noemí and Ezcurra, Félix and Aznar, Ekaitz},
booktitle={2014 12th IEEE International Conference on Industrial Informatics (INDIN)}, title={Low-cost radar-based target identification prototype using an expert system},
year={2014},
volume={},
number={},
pages={54-59},
abstract={Smart and green cities are hot topics in current research because people are becoming more conscious about their impact on the environment and the sustainability of their cities as the population increases. Many researchers are searching for mechanisms that can reduce power consumption and pollution in the city environment. This paper addresses the issue of public lighting and how it can be improved in order to achieve a more energy efficient city. This work is focused on making the process of turning the streetlights on and off more intelligent so that they consume less power and cause less light pollution. The proposed solution is comprised of a radar device and an expert system implemented on a low-cost platform based on a DSP. By analyzing the radar echo in both the frequency and time domains, the system is able to detect and identify objects moving in front of it. This information is used to decide whether or not the streetlight should be turned on. Experimental results show that the proposed system can provide hit rates over 80% promising a good performance. In addition, the proposed solution could be useful in kind of other applications such as intelligent security and surveillance systems and home automation.},
keywords={Classification tree analysis;Radar;Correlation;Classification algorithms;Lighting;Cities and towns;Object recognition;green cities;smart cities;street lighting;radar target identification;expert system;classification tree;artificial intelligence;machine learning},
doi={10.1109/INDIN.2014.6945483},
ISSN={2378-363X},
month={July},}
@ARTICLE{8703733,
author={Danfeng, Yan and Jing, Wang},
journal={IEEE Access}, title={Subway Passenger Flow Forecasting With Multi-Station and External Factors},
year={2019},
volume={7},
number={},
pages={57415-57423},
abstract={With the rapid development of urban rail transit, more and more people choose to travel by subway. Therefore, accurate passenger flow forecasting is of great significance for passengers and municipal construction and contributes to smart city services. In this paper, we propose a multi-type attention-based network to forecast the subway passenger flow with multi-station and external factors. The proposed network has different types of attention mechanisms to adaptively extract relevant features, including multi-station, external factors, and historical data. In addition, the hierarchical attention mechanism is used to model the hierarchical relationship between subway lines and stations. In addition, the embedding method is applied to better combine the different kinds of data. The experiments on real subway passenger flow data in a city in China demonstrate that our method outperforms five baseline methods. Moreover, our method can visualize the impact of different stations and other factors on traffic, which plays an important role in passenger travel and subway dispatch.},
keywords={Public transportation;Forecasting;Time series analysis;Meteorology;Recurrent neural networks;Predictive models;Rails;Passenger flow forecasting;attention mechanism;recurrent neural networks},
doi={10.1109/ACCESS.2019.2914239},
ISSN={2169-3536},
month={},}
@INPROCEEDINGS{9231095,
author={Serrano, Will},
booktitle={2020 International Conference on Computing, Electronics Communications Engineering (iCCECE)}, title={The Random Neural Network with a Genetic algorithm in Intelligent Buildings},
year={2020},
volume={},
number={},
pages={182-188},
abstract={The Random Neural Network with a Genetic algorithm and its integration into an Intelligent Building: iBuilding is proposed in this paper. The presented biological method, founded on the Genome, codifies and transmits the information from the Intelligent Building. Furthermore, it also multiplexes its data entirely to generate Clusters of Buildings that are interconnected with each other. The key concept proposed in this paper is that the learned information obtained by iBuilding after its interaction with the environment is never lost when the building is decommissioned or retrofitted but transmitted to future iBuilding generations as distributed organisms. Data is codified in the network weights instead of the neurons, similar as the Genome, in order to enable an Artificial Intelligence evolution in iBuilding. The presented biological algorithm is inserted into an iBuilding model where sensorial neurons distributed within the Intelligent Building collect measurements about its environment and select relevant information. This proposed model has been validated with several research datasets that cover several key scenarios; experimental results demonstrate that the Random Neural Network Genetic Algorithm codifies, transmits and multiplexes iBuilding information to future generations with insignificant error, therefore, successfully creating a cluster of buildings.},
keywords={Buildings;Neurons;Genetic algorithms;Neural networks;Genomics;Bioinformatics;Organisms;Intelligent Building;Smart City;Genetic Algorithm;Neural Networks;Artificial Intelligence},
doi={10.1109/iCCECE49321.2020.9231095},
ISSN={},
month={Aug},}
@INPROCEEDINGS{9564229,
author={Khan, Md. Al-Masrur and Kee, Seong-Hoon and Sikder, Niloy and Al Mamun, Md. Abdullah and Zohora, Fatima Tuz and Hasan, Md. Tariq and Bairagi, Anupam Kumar and Nahid, Abdullah-Al},
booktitle={2021 Joint 10th International Conference on Informatics, Electronics Vision (ICIEV) and 2021 5th International Conference on Imaging, Vision Pattern Recognition (icIVPR)}, title={A Vision-Based Lane Detection Approach for Autonomous Vehicles Using a Convolutional Neural Network Architecture},
year={2021},
volume={},
number={},
pages={1-10},
abstract={Autonomous vehicles no longer belong to the realm of science fiction. They have become a prominent area of research in the last two decades because of the integration of Artificial Intelligence in the automobile industry. Apart from the development of various complex learning algorithms, the advancement of cameras, sensors, and geolocation technology as well as the escalation in the capacity of machines have played a crucial role in bringing this technology into reality. We have had significant breakthroughs in the development of autonomous cars within the last ten years. However, despite the success of multiple prototypes in navigating within the borders of a delimited area, researchers are yet to overcome several drawbacks before embodying them in the transport system; and one of those hurdles lies in the lane detection system of the cars. Therefore, in this article, we present an intelligent lane detection algorithm incorporating fully-connected Neural Networks with a secondary layer protection scheme to detect the borders of a lane. We achieved over 98% classification accuracy using the proposed lane detection model. We also implemented the model in a small prototype to take a look at its performance. Experimental results infer that the algorithm is capable of lane detection and ready for practical use.},
keywords={Lane detection;Roads;Prototypes;Lighting;Mathematical models;Classification algorithms;Pattern recognition;Autonomous cars;boundary protection;Convolutional Neural Network;lane detection},
doi={10.1109/ICIEVicIVPR52578.2021.9564229},
ISSN={},
month={Aug},}
@ARTICLE{9511315,
author={Guo, Haizhou and Zhang, Dian and Jiang, Landu and Poon, Kin-Wang and Lu, Kezhong},
journal={IEEE Internet of Things Journal}, title={ASTCN: An Attentive Spatial Temporal Convolutional Network for Flow Prediction},
year={2021},
volume={},
number={},
pages={1-1},
abstract={Flow prediction attracts intensive research interests, since it can offer essential support to many crucial problems in public safety and smart city, e.g., epidemic spread prediction, medical resource allocation optimization. Among all the models in flow prediction, deep learning models (e.g., Convolutional Neural Networks, Recurrent Neural Networks, and Graph Neural Networks) are popular and outperform other statistics and machine learning models, since they can learn intrinsic structures and extract features from spatial-temporal data. However, most of them set strict temporal periods in the prediction, or separate the interaction between spatial and temporal correlations. Therefore, the prediction accuracy is affected. To overcome the difficulties, we propose a flow prediction network ASTCN (Attentive Spatial Temporal Convolutional Network), which can effectively handle large-scale flow data and learn complex features. In ASTCN, we leverage attention mechanism to overcome previous problem of strict temporal periods, and can effectively fuse spatial-temporal data with multiple factors from different time-series sources. Furthermore, we propose a causal 3D convolutional layer based on Temporal Convolutional Networks (TCNs). It can simultaneously extract both spatial and temporal features to improve the prediction accuracy. We comprehensively conducted our experiments based on real-world datasets. Experimental results show that ASTCN outperforms the state-of-the-art methods by at least 3.78% in RMSE. Therefore, ASTCN is a potential solution to other large-scale spatial-temporal problems.},
keywords={Feature extraction;Predictive models;Solid modeling;Correlation;Data models;Three-dimensional displays;Convolution;Flow prediction;time series prediction;spatial-temporal data;neural networks.},
doi={10.1109/JIOT.2021.3100068},
ISSN={2327-4662},
month={},}
@INPROCEEDINGS{9060144,
author={Matsumoto, Toki and Nakamoto, Yukikazu and Yamamoto, Ryota and Honda, Shinya and Wakabayashi, Kazutoshi},
booktitle={2019 IEEE SmartWorld, Ubiquitous Intelligence Computing, Advanced Trusted Computing, Scalable Computing Communications, Cloud Big Data Computing, Internet of People and Smart City Innovation (SmartWorld/SCALCOM/UIC/ATC/CBDCom/IOP/SCI)}, title={Convolution Neural Network Development Support System using Approximation Methods to Evaluate Inference Accuracy and Memory Usage in an Embedded System},
year={2019},
volume={},
number={},
pages={1312-1317},
abstract={Convolution neural networks have become widely used in embedded systems such as automatic driving systems. In these cases, inference functions in convolution neural networks are implemented due to resource limitation in embedded systems. Field-programmable gate array implementation is preferable because of low power consumption and real-time response time in embedded systems. Parameters in a convolution neural network are floating-point numbers, and enormous floating-point calculation is required. This is a challenge because the field-programmable gate array has a limited floating processing unit and in-memory processing. One way to solve the problem is to approximate an enormous number of parameters and to perform efficient computation. In the approximation, floating-point numbers of parameters are implemented using smaller-size integers or numbers having fewer bits. However, the inference accuracy decreases in the approximation, leading to a tradeoff situation. In addition, which layer should be approximated in order to be effective is not clear. In order to solve these problems, we developed an approximation support system. The developed system approximates the parameters and calculates the accuracy of the parameters and the required memory size. Furthermore, using this system, we carry out experiments to evaluate the effectiveness of several approximation methods for a large-scale network and dataset.},
keywords={Field programmable gate arrays;Embedded systems;Convolution;Approximation methods;Neural networks;Hardware;Memory management;Convolution neural network, field programmable gate array, embedded systems, approximation},
doi={10.1109/SmartWorld-UIC-ATC-SCALCOM-IOP-SCI.2019.00242},
ISSN={},
month={Aug},}
@INPROCEEDINGS{8960769,
author={Tan, Tan and Chen, Ke and Lu, Weisheng and Xue, Fan},
booktitle={2019 IEEE International Conference on Signal Processing, Communications and Computing (ICSPCC)}, title={Semantic Enrichment for Rooftop Modeling using Aerial LiDAR Reflectance},
year={2019},
volume={},
number={},
pages={1-4},
abstract={As demanded by smart city applications, the recognition and enrichment of urban semantics from unstructured spatial big data became an emerging trend for the development of building information model (BIM) and city information model (CIM). Rooftop constructs the essential part of BIM and CIM and loads various new application practices and scenarios. The recognition and enrichment of rooftop elements represent the trending requirements. This study develops a new approach for semantic enrichment of aerial Light Detection and Ranging (LiDAR) point clouds. In this paper, machine learning models such as decision tree are applied to predict green roof elements based on the geometry and laser reflectance, and was validated in a pilot zone in the main campus of The University of Hong Kong. The recognized rooftop elements could provide a solid foundation for further research, such as rooftop landscape, rooftop energy, rooftop farming.},
keywords={Rooftop;building information model;city information model;LiDAR reflectance;decision tree},
doi={10.1109/ICSPCC46631.2019.8960769},
ISSN={},
month={Sep.},}
@INPROCEEDINGS{8098898,
author={Chen, Xin and Tam, Kam Weng and Chen, Biao},
booktitle={2017 IEEE International Conference on RFID Technology Application (RFID-TA)}, title={Moving object detection based on TV based passive radar and its application to RFID cane},
year={2017},
volume={},
number={},
pages={220-224},
abstract={Moving object detection is very important in the development of smart city for Visually Impaired People (VIP). In this paper, we propose a new methodology to realize a moving object detection system from TV based on passive radar which is applied to RFID Intelligent Cane in future. Image comparison and detection methods are also applied to complete the detection system. The innovation of our detection system is about the system architecture of the 920MHz UHF RFID, 700MHz band analogue TV based passive radar, image comparison and machine learning algorithms to realize the practical moving object detection system for UHF RFID Cane.},
keywords={TV;Object detection;Radiofrequency identification;Support vector machines;Passive radar;Calibration;Receivers;passive radar;RFID;intelligent cane;image comparison;moving object detection},
doi={10.1109/RFID-TA.2017.8098898},
ISSN={},
month={Sep.},}
@ARTICLE{9253636,
author={Sun, Rui and Wang, Guanyu and Cheng, Qi and Fu, Linxia and Chiang, Kai-Wei and Hsu, Li-Ta and Ochieng, Washington Yotto},
journal={IEEE Internet of Things Journal}, title={Improving GPS Code Phase Positioning Accuracy in Urban Environments Using Machine Learning},
year={2021},
volume={8},
number={8},
pages={7065-7078},
abstract={The accuracy of location information, mainly provided by the global positioning system (GPS) sensor, is critical for Internet-of-Things applications in smart cities. However, built environments attenuate GPS signals by reflecting or blocking them resulting in some cases multipath and non-line-of-sight (NLOS) reception. These effects cause range errors that degrade GPS positioning accuracy. Enhancements in the design of antennae and receivers deliver a level of reduction of multipath. However, NLOS signal reception and residual effects of multipath are still to be mitigated sufficiently for improvements in range errors and positioning accuracy. Recent machine learning-based methods have shown promise in improving pseudorange-based position solutions by considering multiple variables from raw GPS measurements. However, positioning accuracy is limited by low accuracy signal reception classification. Unlike the existing methods, which use machine learning to directly predict the signal reception classification, we use a gradient boosting decision tree (GBDT)-based method to predict the pseudorange errors by considering the signal strength, satellite elevation angle and pseudorange residuals. With the predicted pseudorange errors, two variations of the algorithm are proposed to improve positioning accuracy. The first corrects pseudorange errors and the other either corrects or excludes the signals determined to contain the effects of multipath and NLOS signals. The results for a challenging urban environment characterized by high-rise buildings on one side, show that the 3-D positioning accuracy of the pseudorange error correction-based positioning measured in terms of the root mean square error is 23.3 m, an improvement of more than 70% over the conventional methods.},
keywords={Satellites;Urban areas;Global Positioning System;Position measurement;Three-dimensional displays;Solid modeling;Predictive models;Global positioning system (GPS);gradient boosting decision tree (GBDT);multipath;non-line-of-sight (NLOS);urban positioning},
doi={10.1109/JIOT.2020.3037074},
ISSN={2327-4662},
month={April},}
@INPROCEEDINGS{8643128,
author={Forero, Mario Andres Varon},
booktitle={MOVICI-MOYCOT 2018: Joint Conference for Urban Mobility in the Smart City}, title={Detection of motorcycles and use of safety helmets with an algorithm using image processing techniques and artificial intelligence models},
year={2018},
volume={},
number={},
pages={1-9},
abstract={In Colombia, motorcyclists are the primary victims of traffic accidents. Between 2001 and 2014, there were about 28,000 deaths on the country's urban and rural roads; about half of these deaths occurred as a result of the lack of use of passive protection elements (safety helmets). This was accompanied by an increase in the number of motorcycles during those fourteen years of close to 445%. The large number of motorcycles and the absence of the transit authority from several municipalities have made it impossible to enforce compliance with traffic regulations for this population, and especially with the use of safety helmets. To solve this problem, an algorithm is proposed that uses image processing techniques in conjunction with artificial intelligence models for the detection of motorcycles and the use of helmets by the riders. The techniques used in this research for the detection of motorcycles within the vehicular flow include, among others, subtraction of the background, moment-preserving thresholding, morphological analysis and convolutional neural networks for the correct classification of the different objects found in the images. For the detection of helmets, a region of interest (ROI) is extracted from the original image and the contour is constructed within the posterior region of the ROI. Subsequently, the background of the image is subtracted and the H coordinate extracted from the HSB (hue, saturation and brightness) stack of the original RGB image. A classifier constructed using convolutional neural networks is used to determine the use of helmets by motorcyclists. The precision of motorcycle classification was 97.14%, whereas the precision of helmet detection was 85.29%. This algorithm, used with the equipment necessary for the identification of the vehicle's identity (i.e. LPR), can automatically assist in the enforcement task by public authorities in order to reduce the high mortality rate in this population group.},
keywords={motorcycle detection;safety helmet detection;image processing;artificial intelligence;deep learning},
doi={10.1049/ic.2018.0001},
ISSN={},
month={April},}
@ARTICLE{9046237,
author={Sliwa, Benjamin and Piatkowski, Nico and Wietfeld, Christian},
journal={IEEE Internet of Things Journal}, title={The Channel as a Traffic Sensor: Vehicle Detection and Classification Based on Radio Fingerprinting},
year={2020},
volume={7},
number={8},
pages={7392-7406},
abstract={Ubiquitously deployed Internet of Things (IoT)-based automatic vehicle classification systems will catalyze data-driven traffic flow optimization in future smart cities and will transform the road infrastructure itself into a dynamically sensing cyber-physical system. Although a wide range of different traffic sensing systems has been proposed, the existing solutions are not yet able to simultaneously satisfy the multitude of requirements, e.g., accuracy, robustness, cost efficiency, and privacy preservation. In this article, we present a novel approach, which exploits radio fingerprints-multidimensional attenuation patterns of wireless signals-for accurate and robust vehicle detection and classification. The proposed system can be deployed in a highly cost-efficient manner as it relies on off-the-shelf embedded devices which are installed into existing delineator posts. In a comprehensive field evaluation campaign, the performance of the radio fingerprinting-based approach is analyzed within an experimental live deployment on a German highway, where it is able to achieve a binary classification success ratio of more than 99% and an overall accuracy of 93.83% for a classification task with seven different classes.},
keywords={Sensor systems;Machine learning;Internet of Things;Vehicle detection;Roads;Wireless sensor networks;Automatic vehicle classification;intelligent transportation system (ITS);radio fingerprinting},
doi={10.1109/JIOT.2020.2983207},
ISSN={2327-4662},
month={Aug},}
@INPROCEEDINGS{9091772,
author={Kumar Reddy, K. Ravi and Ramesh, S.},
booktitle={2020 3rd International Conference on Emerging Technologies in Computer Engineering: Machine Learning and Internet of Things (ICETCE)}, title={Algorithmic Urban IoT Context and Convergence of Services Sensing and Planning Units (PUs)},
year={2020},
volume={},
number={},
pages={52-57},
abstract={Urban planning is a domain of visualizing various aspects of social and physical matters concerning the habitat. These are centered towards better living of social groups in a physical infrastructure momentum that is always dynamic with reference to delivering the betterment ever, thus requiring a well synchronized synergy between planning and delivery through plan management. The context of an urban scenario is always around supply dynamics of service infrastructure to the urban density. The situations of balanced supply of these services to spatial status of demand needing an efficient delivery system that can manage the service guarantee. Well-orchestrated service infrastructure enabled by IoT as a delivery mechanism with synchronized functioning for the planned and occasional dynamics of citizen support systems must evolve through bidirectional data sharing between the delivery systems and urban planning, thus opening a new domain of math programming and algorithms to solve some of the pertinent issues concerning the synthesis.},
keywords={Planning;Smart cities;Sensors;Capacity planning;Calibration;Automation;Configuration Items;Context;FOAK;IoT;Math Processing;Planning Units;Sensing;Service Management;Situational Intelligence;Socio-economics;Urban Infrastructure Services;Urban Systems},
doi={10.1109/ICETCE48199.2020.9091772},
ISSN={},
month={Feb},}
@INPROCEEDINGS{9564881,
author={Amaris, Marcos and Morais, Mayuri A. and De Camargo, Raphael Y.},
booktitle={2021 IEEE International Intelligent Transportation Systems Conference (ITSC)}, title={Efficient Prediction of Region-wide Traffic States in Public Bus Networks using LSTMs},
year={2021},
volume={},
number={},
pages={2215-2220},
abstract={Public bus systems are impacted by many factors, such as varying traffic conditions, passenger demand, and weather changes. One can combine all those factors that affect bus travel times into a single factor called link state, where a link represents part of a bus route. Several works exist that predict single link states using different statistical and machine learning approaches. More recently, deep learning techniques, such as LSTMs, started to be used to predict the state of entire bus routes. The main problem with this approach is that it uses extensive computational resources. In this work, we evaluate the use of LSTMs to predict the state of entire city regions instead of single routes. It has two advantages: (i) the state of each link is evaluated only once for all the bus routes that cross it, and (ii) information from buses from all routes can be used to determine future link states. Using a shallow bidirectional LSTM architecture produced accurate state predictions with an average MAPE of 12.5. Moreover, we show that it can be trained daily and used to predict link states in real-time for a large metropolis, like São Paulo.},
keywords={Deep learning;Smart cities;Conferences;Computational modeling;Computer architecture;Predictive models;Real-time systems},
doi={10.1109/ITSC48978.2021.9564881},
ISSN={},
month={Sep.},}
@ARTICLE{9018140,
author={Fan, Xiaochen and Xiang, Chaocan and Chen, Chao and Yang, Panlong and Gong, Liangyi and Song, Xudong and Nanda, Priyadarsi and He, Xiangjian},
journal={IEEE Transactions on Mobile Computing}, title={BuildSenSys: Reusing Building Sensing Data for Traffic Prediction With Cross-Domain Learning},
year={2021},
volume={20},
number={6},
pages={2154-2171},
abstract={With the rapid development of smart cities, smart buildings are generating a massive amount of building sensing data by the equipped sensors. Indeed, building sensing data provides a promising way to enrich a series of data-demanding and cost-expensive urban mobile applications. In this paper, as a preliminary exploration, we study how to reuse building sensing data to predict traffic volume on nearby roads. Compared with existing studies, reusing building sensing data has considerable merits of cost-efficiency and high-reliability. Nevertheless, it is non-trivial to achieve accurate prediction on such cross-domain data with two major challenges. First, relationships between building sensing data and traffic data are not unknown as prior, and the spatio-temporal complexities impose more difficulties to uncover the underlying reasons behind the above relationships. Second, it is even more daunting to accurately predict traffic volume with dynamic building-traffic correlations, which are cross-domain, non-linear, and time-varying. To address the above challenges, we design and implement BuildSenSys, a first-of-its-kind system for nearby traffic volume prediction by reusing building sensing data. Our work consists of two parts, i.e., Correlation Analysis and Cross-domain Learning. First, we conduct a comprehensive building-traffic analysis based on multi-source datasets, disclosing how and why building sensing data is correlated with nearby traffic volume. Second, we propose a novel recurrent neural network for traffic volume prediction based on cross-domain learning with two attention mechanisms. Specifically, a cross-domain attention mechanism captures the building-traffic correlations and adaptively extracts the most relevant building sensing data at each predicting step. Then, a temporal attention mechanism is employed to model the temporal dependencies of data across historical time intervals. The extensive experimental studies demonstrate that BuildSenSys outperforms all baseline methods with up to 65.3 percent accuracy improvement (e.g., 2.2 percent MAPE) in predicting nearby traffic volume. We believe that this work can open a new gate of reusing building sensing data for urban traffic sensing, thus establishing connections between smart buildings and intelligent transportation.},
keywords={Sensors;Roads;Correlation;Recurrent neural networks;Smart buildings;Reliability;Traffic prediction;building sensing data;machine learning;Internet of Things;cross-domain learning},
doi={10.1109/TMC.2020.2976936},
ISSN={1558-0660},
month={June},}
@INPROCEEDINGS{8855693,
author={Abed, Alshreef and Yuan, Jingling and Li, Lin and Mbyamm K., Mesmin Junior},
booktitle={2019 IEEE 21st International Conference on High Performance Computing and Communications; IEEE 17th International Conference on Smart City; IEEE 5th International Conference on Data Science and Systems (HPCC/SmartCity/DSS)}, title={Research on Adoption of Gene-Disease Identification and Recognition Phenotype Process in High-Performance Computing and Applications (HPCA) Research},
year={2019},
volume={},
number={},
pages={239-247},
abstract={The research contribution of High-Performance Computing and Applications (HPCA), combined with biomedical text related to generic and phenotypes, has been published at various levels to optimize user demand. However, there is still a huge challenge in eliminating ambiguities that occur in biomedical text mining due to the use of the same expression in the investigation of the genes disease. This article uses two combined approaches that represent identification and detection in high-performance computing and Applications (HPCA) system for the evaluation of gene-disease and phenotype processes in biomedicine. The Current approaches use machine learning as a positive training phrase P and a gene as the negative training set N for identification, but these approaches are only of the low-noise negative set which is the performance of the quality of the HPCA System affects, our first contribution paper proposes a new implementation based on positive unlabeled Disease gene Identification (PUDI) to construct our classifier. The second contribution we introduce high precision and recall values which achieve term classification accuracy between 0.96 and 0.99, precision values between 0.95 and 0.99, and recall values between 0.96 and 0.99. Definitively, the F-score value obtained confirmed outperformed results on the classifiers with high accuracy over a wide range of parameters.},
keywords={Diseases;Proteins;Feature extraction;Mathematical model;Ontologies;Machine learning;Conferences;HPCA;Named entity recognition;Data mining;HPCC;Biomedical;Gene;Disease},
doi={10.1109/HPCC/SmartCity/DSS.2019.00047},
ISSN={},
month={Aug},}
@INPROCEEDINGS{7840811,
author={Zhao, Kai and Tarkoma, Sasu and Liu, Siyuan and Vo, Huy},
booktitle={2016 IEEE International Conference on Big Data (Big Data)}, title={Urban human mobility data mining: An overview},
year={2016},
volume={},
number={},
pages={1911-1920},
abstract={Understanding urban human mobility is crucial for epidemic control, urban planning, traffic forecasting systems and, more recently, various mobile and network applications. Nowadays, a variety of urban human mobility data have been gathered and published. Pervasive GPS data can be collected by mobile phones. A mobile operator can track people's movement in cities based on their cellular network location. This urban human mobility data contains rich knowledge about locations and can help in addressing many urban challenges such as traffic congestion or air pollution problems. In this article, we survey recent literature on urban human mobility from a data mining view: from the data collection and cleaning, to the mobility models and the applications. First, we summarize recent public urban human mobility data sets and how to clean and preprocess such data. Second, we describe recent urban human mobility models and predictors, e.g., the deep learning predictor, for predicting urban human mobility. Third, we describe how to evaluate the models and predictors. We conclude by considering how applications can utilize the mobility models and predictive tools for addressing city challenges.},
keywords={Predictive models;Urban areas;Global Positioning System;Public transportation;Data mining;Data models;Computational modeling;human mobility;spatio-temporal data mining;machine learning;smart city},
doi={10.1109/BigData.2016.7840811},
ISSN={},
month={Dec},}
@INPROCEEDINGS{7037223,
author={Niu, Xiaoguang and Zhu, Ying and Zhang, Xining},
booktitle={2014 IEEE Global Communications Conference}, title={DeepSense: A novel learning mechanism for traffic prediction with taxi GPS traces},
year={2014},
volume={},
number={},
pages={2745-2750},
abstract={The urban road traffic flow condition prediction is a fundamental issue in the intelligent transportation management system. While extracting the high-dimensional, nonlinear and random features of the transportation network is a challenge, which is very useful to improve the accuracy of traffic prediction. In this paper, we propose DeepSense, a novel deep temporal-spatial traffic flow feature learning mechanism, with large scale Taxi GPS traces for traffic prediction. Deep-Sense includes two switchable feature learning approaches. DeepSense exploits a temporal-spatial deep learning approach for traffic flow prediction with the sufficient spatial and temporal taxi GPS traces in dynamic pattern. Meanwhile, Deep-Sense takes advantage of a supplementary temporal sequence segment matching approach with the temporal transformation of traffic flow state for a given road segment when there are not enough traffic traces. Experimental results show that DeepSense can achieve higher prediction accuracy with nearly 5% improvements compared with existing methods.},
keywords={Roads;Feature extraction;Global Positioning System;Accuracy;Support vector machines;Trajectory;traffic flow condition prediction;deep learning;smart city;temporal-spatial;intelligent transportation system},
doi={10.1109/GLOCOM.2014.7037223},
ISSN={1930-529X},
month={Dec},}
@ARTICLE{9093851,
author={Lu, Eric Hsueh-Chan and Lin, Zhan-Qing},
journal={IEEE Access}, title={Rental Prediction in Bicycle-Sharing System Using Recurrent Neural Network},
year={2020},
volume={8},
number={},
pages={92262-92274},
abstract={As the rapid development of smart city and Internet of Things (IoT), related research issues have attracted much attention from industry and academia around the world, and Bicycle-Sharing System (BSS) is one of the thriving applications of smart transportation system. BSS is a system that allows users to rent the bicycle from any automatic rental station. If there're some stations that don't have enough bicycles or free places, then it is usually handled by dedicated vehicles to rebalance the bicycles. Thus, predicting the rental (i.e. the number of renting or returning bicycles) from users in the future is important to improve the service quality. This research uses Recurrent Neural Network (RNN) to predict the rental from users. The RNN consists of three parts: period, closeness, and general. Each of them represents the historical records in different time intervals in the past time respectively. After inputting the historical rental data into RNN and the training process, we can predict the bicycle rental in the coming day by inputting the rental records of the past time into RNN. Finally, we compare the effectiveness among this and the method of Poisson by real YouBike data and prove that our model outperforms it.},
keywords={Bicycles;Mathematical model;Recurrent neural networks;Predictive models;Meteorology;Markov processes;Internet of Things;Bicycle-sharing system;rental prediction;recurrent neural network;deep learning},
doi={10.1109/ACCESS.2020.2994588},
ISSN={2169-3536},
month={},}
@INPROCEEDINGS{9110971,
author={Li, Kehan and Chen, Jiming and Yu, Baosheng and Shen, Zhangchong and Li, Chao and He, Shibo},
booktitle={2020 19th ACM/IEEE International Conference on Information Processing in Sensor Networks (IPSN)}, title={Supreme: Fine-grained Radio Map Reconstruction via Spatial-Temporal Fusion Network},
year={2020},
volume={},
number={},
pages={1-12},
abstract={Radio map, serving as an eﬃcient indicator of wireless environments, has been widely used in smart-city applications, including network monitoring/planning, anomaly signal detection, and indoor/outdoor localization. It is hard to maintain an update-to-date fine-grained radio map within a large area, since the radio map changes rapidly due to the internal and external factors. Previous studies usually relied on time-consuming site surveys at densely predefined reference points, leading to either coarse-grained or out-of-date radio maps. In this paper, we propose a fine-grained radio map reconstruction framework, called Supreme, based on crowd-sourced data in an image super-resolution manner. Specifically, Supreme explores spatial-temporal relationships in historical coarse-grained radio maps and builds a real-time fine-grained radio map using deep spatial-temporal reconstruction networks. Furthermore, a heterogeneous data fusion module is devised to make full use of external information. To evaluate the performance of Supreme, we conduct extensive experiments and ablation studies on a large-scale dataset with a total of six-month data collected from two university campuses. Besides, we investigate the transferability of Supreme in different locations and service networks, showing that the fine-tuned model can largely reduce the training time and achieve better performance. Experimental results demonstrate that our model outperforms state-of-the-art baselines and a case study on the localization is enhanced with marginal improvements on accuracy.},
keywords={Location awareness;Wireless communication;Training;Scalability;Transfer learning;Superresolution;Real-time systems;Information systems → Spatial-temporal systems;Computing methodologies → Neural networks.;Radio map;Spatial-temporal data;Deep learning},
doi={10.1109/IPSN48710.2020.00-51},
ISSN={},
month={April},}
@INPROCEEDINGS{9562877,
author={Wang, Shuo and Pu, Ziyuan and Li, Qianmu and Guo, Yaming and Li, Meng},
booktitle={2021 IEEE International Smart Cities Conference (ISC2)}, title={Edge Computing-Enabled Crowd Density Estimation based on Lightweight Convolutional Neural Network},
year={2021},
volume={},
number={},
pages={1-7},
abstract={In public areas, crowd stampedes and incidents generate huge negative impacts on public security. Accurate and efficient crowd density estimation is critical to monitor crowd status for developing evacuation strategies. The existing crowd density estimation methods are established based on complex deep-learning algorithms which are usually more accurate, but, on the other side, they require much more computational resources. Consequently, cloud-computing is the only option for deploying crowd density estimation algorithms, which needs tremendous resources for real-time video data transmission and the malfunction and delay of internet service may cause wrong and delayed estimation results. Edge computing is a novel concept of accomplishing computing tasks only relying on the computational resources of edge devices. Estimating crowd density on edge devices rather than conveying images to cloud server for further analysis has several advantages, including 1) reducing network bandwidth pressure from remote transmission; 2) avoiding risks of leaking privacy on images; and 3) improving computation efficient. This study designs an edge computing-enabled crowd density estimation model based on the residual bottleneck block and dilated convolution. The experiments are designed and conducted on public crowd data sets to verify accuracy, storage cost and computation efficiency of our model. According to the experimental results, the proposed model achieves a considerable improvement in operational efficiency, while keep the accuracy at the same level with the complex deep-learning algorithms. Furthermore, the proposed model is implemented on a real edge device to detect real-world crowd density in a Beijing subway station.},
keywords={Costs;Convolution;Computational modeling;Image edge detection;Estimation;Real-time systems;Data models;crowd density estimation;lightweight convolutional neural network;edge computing-enabled system},
doi={10.1109/ISC253183.2021.9562877},
ISSN={2687-8860},
month={Sep.},}
@INPROCEEDINGS{8851859,
author={Dinakaran, Ranjith and Easom, Philip and Zhang, Li and Bouridane, Ahmed and Jiang, Richard and Edirisinghe, Eran},
booktitle={2019 International Joint Conference on Neural Networks (IJCNN)}, title={Distant Pedestrian Detection in the Wild using Single Shot Detector with Deep Convolutional Generative Adversarial Networks},
year={2019},
volume={},
number={},
pages={1-7},
abstract={In this work, we examine the feasibility of applying Deep Convolutional Generative Adversarial Networks (DCGANs) with Single Shot Detector (SSD) as data-processing technique to handle with the challenge of pedestrian detection in the wild. Specifically, we attempted to use in-fill completion to generate random transformations of images with missing pixels to expand existing labelled datasets. In our work, GAN's been trained intensively on low resolution images, in order to neutralize the challenges of the pedestrian detection in the wild, and considered humans, and few other classes for detection in smart cities. The object detector experiment performed by training GAN model along with SSD provided a substantial improvement in the results. This approach presents a very interesting overview in the current state of art on GAN networks for object detection. We used Canadian Institute for Advanced Research (CIFAR), Caltech, KITTI data set for training and testing the network under different resolutions and the experimental results with comparison been showed between DCGAN cascaded with SSD and SSD itself.},
keywords={Feature extraction;Generative adversarial networks;Detectors;Image resolution;Task analysis;Generators;Object detection;Single Shot Detector;Pedestrian Detection;Deep Convolutional Generative Adversarial Networks;Smart Cities;Surveillance in the Wild.},
doi={10.1109/IJCNN.2019.8851859},
ISSN={2161-4407},
month={July},}
@ARTICLE{9324784,
author={Dong, Yunmeng and Xu, Gaochao and Zhang, Meng and Meng, Xiangyu},
journal={IEEE Access}, title={A High-Efficient Joint ’Cloud-Edge’ Aware Strategy for Task Deployment and Load Balancing},
year={2021},
volume={9},
number={},
pages={12791-12802},
abstract={Task deployment has become a research hotspot for load balancing in joint “cloud-edge” datacenter. In view of the problem that most of the hosts are overloaded in the current joint “cloud-edge” datacenter, which may cause unbalanced load in the center, existing research mainly pay attention to the problem of unilateral load balancing of cloud computing center or edge computing center. In order to realize efficient deployment of “cloud-edge” tasks and overall load balancing, on the basis of the deployment mode of joint “cloud-edge”, this paper proposes a resource management and task deployment strategy JCETD (Joint Cloud-Edge Task Deployment) based on pruning algorithm and deep reinforcement learning. The main idea consists of two parts: firstly, the set of “cloud-edge” hosts is pruned according to the attribute value of the physical host. Then, there will be a non-dominated set of joint hosts which reduces the computational complexity of the whole algorithm and improve the computational efficiency of the system. Secondly, the problem of task deployment is simulated as a deep reinforcement learning process under the “cloud-edge” model. Through the continuous exploration and utilization of the system environment, the tasks are reasonably and efficiently deployed in the cloud computing center and edge computing center. Finally, the “cloud-edge” system can achieve an efficient computing performance and overall load balancing. The experimental results show that the proposed algorithm significantly reduces the total completion time and average response time compared with the existing research, which effectively optimizes the service ability and realizes the load balancing of the joint “cloud-edge” system.},
keywords={Task analysis;Cloud computing;Load management;Reinforcement learning;Scheduling;Edge computing;Computational modeling;Task deployment;joint “cloud-edge”;pruning;deep reinforcement learning;load balancing},
doi={10.1109/ACCESS.2021.3051672},
ISSN={2169-3536},
month={},}
@INPROCEEDINGS{9579976,
author={M, Sandeep and Chandavarkar, B R},
booktitle={2021 12th International Conference on Computing Communication and Networking Technologies (ICCCNT)}, title={Data Processing in IoT, Sensor to Cloud: Survey},
year={2021},
volume={},
number={},
pages={1-7},
abstract={IoT is connecting Things over the Internet and the realization of the environment through smart things to create a responsive space. Many surveys predicted the growth of IoT devices is going to be around 50 billion and an average of 7 devices per person. IoT has shown promising future with its applications like smart city, connected factories, buildings, roadways, smart health and many more. To make the promise a reality IoT has to overcome many hurdles like scalability, connectivity, architectural, big data, analysis, security, and privacy. In this literature survey, an attempt has been made to identify current challenges faced by IoT implementation and possible solutions, future opportunities, and research openings. Further, the processing of sensed data at IoT device, edge/fog layer, and the cloud is discussed in detail. Keywords- IoT, IoT architecture, Machine learning, Deep},
keywords={Cloud computing;Data privacy;Smart cities;Scalability;Smart healthcare;Machine learning;Data processing;Learning;Edge computing;Cloud computing;IoT data},
doi={10.1109/ICCCNT51525.2021.9579976},
ISSN={},
month={July},}
@ARTICLE{9426913,
author={Zhu, Zheqi and Wan, Shuo and Fan, Pingyi and Letaief, Khaled B.},
journal={IEEE Internet of Things Journal}, title={Federated Multiagent Actor–Critic Learning for Age Sensitive Mobile-Edge Computing},
year={2022},
volume={9},
number={2},
pages={1053-1067},
abstract={As an emerging technique, mobile-edge computing (MEC) introduces a new scheme for various distributed communication-computing systems, such as industrial Internet of Things (IoT), vehicular communication, smart city, etc. In this work, we mainly focus on the timeliness of the MEC systems where the freshness of the data and computation tasks is significant. First, we formulate a kind of age-sensitive MEC models and define the average Age-of-Information (AoI) minimization problems of interests. Then, a novel mixed-policy-based multimodal deep reinforcement learning (RL) framework, called heterogeneous multiagent actor–critic (H-MAAC), is proposed as a paradigm for joint collaboration in the investigated MEC systems, where edge devices and center controller learn the interactive strategies through their own observations. To improve the system performance, we develop the corresponding online algorithm by introducing the edge federated learning mode into the multiagent cooperation whose advantages on learning convergence can be guaranteed theoretically. To the best of our knowledge, it is the first joint MEC collaboration algorithm that combines the edge federated mode with the multiagent actor–critic RL. Furthermore, we evaluate the proposed approach and compare it with popular RL-based methods. As a result, the proposed algorithm not only outperforms the baselines on average system age, but also promotes the stability of training process. Besides, the simulation outcomes provide several insights for collaboration designs over MEC systems.},
keywords={Collaboration;Reinforcement learning;Task analysis;Computational modeling;Distributed databases;Edge computing;Data models;Federated learning (FL);joint collaboration;mixed policies;mobile-edge computing (MEC);multiagent deep reinforcement learning (RL);multimodal learning},
doi={10.1109/JIOT.2021.3078514},
ISSN={2327-4662},
month={Jan},}
@INPROCEEDINGS{8661952,
author={Schmitt, Steven and Kandah, Farah I. and Brownell, Dylan},
booktitle={2019 IEEE International Conference on Consumer Electronics (ICCE)}, title={Intelligent Threat Hunting in Software-Defined Networking},
year={2019},
volume={},
number={},
pages={1-5},
abstract={The emergence of Software-Defined Networking (SDN) has brought along a wave of new technologies and developments in the field of networking with hopes of dealing with network resources more efficiently and providing a foundation of programmability. SDN allows for both flexibility and adaptability by separating the control and data planes in a network environment by virtualizing network hardware. We, in this work, present an advanced threat hunting model by combining the SDN infrastructure with threat hunting techniques and machine learning models aiming to intelligently handle network threats such as denial of Service, repeat, and main in the middle attacks. This advancement enables the handling of dynamic network traffic in areas such as smart cities and autonomous vehicles more efficiently by rapidly mitigating network threats.},
keywords={Machine learning;Data models;Quality of service;Predictive models;Security;Smart cities;Autonomous vehicles;Threat hunting;Software-defined networking;Pattern mining},
doi={10.1109/ICCE.2019.8661952},
ISSN={2158-4001},
month={Jan},}
@ARTICLE{8769959,
author={Pan, Shengli and Li, Peng and Zeng, Deze and Guo, Song and Hu, Guangmin},
journal={IEEE Internet of Things Journal}, title={A ${Q}$ -Learning Based Framework for Congested Link Identification},
year={2019},
volume={6},
number={6},
pages={9668-9678},
abstract={Network congestion will result in significant performance degradation or even failures of many bandwidth-hungry Internet of Things (IoT) applications. Accurate and efficient congested link identification has become a foundational issue to IoT applications like self-driving cars, digital health, smart city, and so on. However, directly monitoring the massive number of interior links often introduces high operation cost or even is infeasible in practice, giving rise to indirect monitoring techniques like network Boolean tomography. Nevertheless, in many networks, the number of their interior links is larger than their end-to-end paths, making it very challenging for network Boolean tomography to find a determined solution. To resolve this issue, most of current methods try to utilize some prerequisites, such as the link congestion probabilities. While these probabilities might be hard or even unable to be obtained accurately in dynamical networks, limiting the practical deployment. In this paper, we are motivated to design a framework of congested link identification without any prerequisite or assumption. We first novelly model the congested link identification procedures as a Markov decision processes (MDPs), and then employ a reinforcement learning technology, i.e., Q-learning, to solve this MDP. The simulation results show that our proposed scheme can autonomously and efficiently explore the unknown network environment, and is able to achieve better adaptivity and correctness, without any prior knowledge comparing to existing methods.},
keywords={Tomography;Monitoring;Internet of Things;Reinforcement learning;Loss measurement;Adaptation models;Cameras;Congested link identification;end-to-end;network management;network tomography;reinforcement learning},
doi={10.1109/JIOT.2019.2930459},
ISSN={2327-4662},
month={Dec},}
@ARTICLE{7933065,
author={Zhang, Qingxue and Zhou, Dian and Zeng, Xuan},
journal={IEEE Access}, title={HeartID: A Multiresolution Convolutional Neural Network for ECG-Based Biometric Human Identification in Smart Health Applications},
year={2017},
volume={5},
number={},
pages={11805-11816},
abstract={Body area networks, including smart sensors, are widely reshaping health applications in the new era of smart cities. To meet increasing security and privacy requirements, physiological signalbased biometric human identification is gaining tremendous attention. This paper focuses on two major impediments: the signal processing technique is usually both complicated and data-dependent and the feature engineering is time-consuming and can fit only specific datasets . To enable a data-independent and highly generalizable signal processing and feature learning process, a novel wavelet domain multiresolution convolutional neural network is proposed. Specifically, it allows for blindly selecting a physiological signal segment for identification purpose, avoiding the complicated signal fiducial characteristics extraction process. To enrich the data representation, the random chosen signal segment is then transformed to the wavelet domain, where multiresolution time-frequency representation is achieved. An auto-correlation operation is applied to the transformed data to remove the phase difference as the result of the blind segmentation operation. Afterward, a multiresolution 1-D-convolutional neural network (1-D-CNN) is introduced to automatically learn the intrinsic hierarchical features from the wavelet domain raw data without datadependent and heavy feature engineering, and perform the user identification task. The effectiveness of the proposed algorithm is thoroughly evaluated on eight electrocardiogram datasets with diverse behaviors, such as with or without severe heart diseases, and with different sensor placement methods. Our evaluation is much more extensive than the state-of-the-art works, and an average identification rate of 93.5% is achieved. The proposed multiresolution 1-D-CNN algorithm can effectively identify human subjects, even from randomly selected signal segments and without heavy feature engineering. This paper is expected to demonstrate the feasibility and effectiveness of applying the blind signal processing and deep learning techniques to biometric human identification, to enable a low algorithm engineering effort and also a high generalization ability.},
keywords={Electrocardiography;Signal resolution;Feature extraction;Heart rate variability;Convolution;Wavelet domain;Wavelet transforms;ECG;wavelet transformation;convolutional neural network;deep learning;machine learning;feature learning;blind signal processing;data representation},
doi={10.1109/ACCESS.2017.2707460},
ISSN={2169-3536},
month={},}
@INPROCEEDINGS{8551339,
author={Mehmood, Tajwar and Latif, Seemab and Malik, Sheheryaar},
booktitle={2018 15th International Conference on Smart Cities: Improving Quality of Life Using ICT IoT (HONET-ICT)}, title={Prediction Of Cloud Computing Resource Utilization},
year={2018},
volume={},
number={},
pages={38-42},
abstract={Efficient resource utilization leads cloud provider to low cost and high performance. Cloud Computing is a dynamic environment that provides on-demand services over the internet on pay as you go model. Cloud platform has a dynamic resource usage as it is shared among large number of users. Resource allocator provisions resources to dynamic demands of user from finite set of resources. There should be no over and under provisioning of resources. Underutilized resources causes resource wastage and more cost whereas over utilized resource can lead to service degradation. If Resource allocators can presume future resource usage they can take resource provisioning decision efficiently. A resource utilization prediction mechanism is required to assist resource allocator for optimum resource provisioning. Accurate prediction is a challenge in such a dynamic resource usage. Machine learning techniques can help in creating a model that yields accurate prediction results. In machine learning, Ensemble mechanisms are renowned for improving the prediction accuracy which uses a combination of learners rather than a single learner. In this study, an “Ensemble based workload prediction mechanism” is proposed that is based on stack generalization. Experiments are conducted in order to compare the proposed model with the individual and baseline prediction models. For comparison with baseline model, we have used Root Mean Square Error(RMSE) as results of baseline model were given in RMSE. Proposed mechanism has shown 6% and 17% reduction in RMSE in CPU usage and in Memory usage prediction respectively. For comparing our proposed ensemble with independent learner(K Nearest Neighbor, Neural Network, Decision Tree, Support Vector Machine and Naïve Bayes), we have used accuracy as evaluation parameter. The proposed ensemble has improved the prediction accuracy by ≈2%.},
keywords={Resource management;Cloud computing;Google;Task analysis;Dynamic scheduling;Predictive models;Stacking;Resource Usage Prediction;Cloud Computing;Enssemble;Google Cluster Trace},
doi={10.1109/HONET.2018.8551339},
ISSN={1949-4106},
month={Oct},}
@INPROCEEDINGS{8526996,
author={Yang, Qiong and Yu, Jun and Han, Jian-Min},
booktitle={2018 International Conference on Machine Learning and Cybernetics (ICMLC)}, title={Traffic Signals Timing Cycle Length Learning: Using Taxi Gps Trajectories},
year={2018},
volume={1},
number={},
pages={13-18},
abstract={Traffic signals timing information at intersections, including cycle length, lengths of green interval and red interval within a cycle, has great values in auto-driving, traffic control intelligent and various other intelligent transportation applications. A cycle length analysis approach based on GPS trajectory data was proposed in this paper, which consists of three stages: vehicle travelling behavior analysis based on GPS trajectories, green start events extraction, and cycle length estimation based on sparse observational data. The proposed approach was validated by a set of taxi GPS trajectories from Nanjing. The experimental results shows that the proposed method could effectively estimate the timing cycle length of traffic signals of given intersections.},
keywords={Trajectory;Global Positioning System;Public transportation;Timing;Estimation;Noise measurement;Roads;GPS trajectory dataTraffic signal;timing cycle},
doi={10.1109/ICMLC.2018.8526996},
ISSN={2160-1348},
month={July},}
@INPROCEEDINGS{8560305,
author={Luo, Luqing and Tang, Lulu and Yang, Zhi-Xin},
booktitle={2018 IEEE SmartWorld, Ubiquitous Intelligence Computing, Advanced Trusted Computing, Scalable Computing Communications, Cloud Big Data Computing, Internet of People and Smart City Innovation (SmartWorld/SCALCOM/UIC/ATC/CBDCom/IOP/SCI)}, title={Learning Combinatorial Global and Local Features on 3D Point Clouds},
year={2018},
volume={},
number={},
pages={1956-1961},
abstract={As deep learning methods won the huge success in 2D area, they're striding forward into 3D computer vision community during the last few years, meanwhile as point cloud data becoming ubiquitous with rapid development of 3D sensors, deep learning implemented on 3D point cloud steps into different scenarios as 3D classification, segmentation, object detection and reconstruction. However, processing 3D point cloud data by deep learning is a non-trivial job because of its naturally irregular data format. Some predecessors overcame the key issue by designing a direct deep network, left the problem neglecting implicit local feature relations as an open question, though. Our proposal network, dual-channel multi-layer perceptron deep network, or DualNet, aiming to take advantage of local features and to learn from combinatorial global and local features, thus to achieve both stable order invariance and high accuracy for 3D object classification tasks. A couple of experiments will be conducted to verify the performance of our proposal DualNet by comparing with state-of-the-art methods on major 3D point cloud database.},
keywords={Dual-channel network, neighboring points structure, local feature, 3D point cloud},
doi={10.1109/SmartWorld.2018.00327},
ISSN={},
month={Oct},}
@ARTICLE{9293326,
author={Wu, Fan and Xu, Tingfa and Guo, Jie and Huang, Bo and Xu, Chang and Wang, Jihui and Li, Xiangmin},
journal={IEEE Internet of Things Journal}, title={Deep Siamese Cross-Residual Learning for Robust Visual Tracking},
year={2021},
volume={8},
number={20},
pages={15216-15227},
abstract={The sixth-generation (6G) wireless technology contributes to the establishment of the Internet of Things (IoT). Recently, the IoT has become popular because of its smart architectures and various applications. Among these applications, intelligent urban surveillance systems for smart cities are becoming more and more important. Therefore, designing a robust visual tracking method has become an urgent task. Deep Siamese convolutional neural networks have been applied to visual tracking recently because of their advantageous abilities to learn a matching function between the template and the target candidate. Unlike traditional Siamese networks, which separately treat the two branches, we propose deep Siamese cross-residual learning to entangle the two branches from the beginning to the end of the Siamese network. This strategy can make the two branches exchange instance-specific information at different nodes of the network and learn a more compact representation of the target. In addition, we propose a combined loss function, which consists of two complementary tasks. One task is to learn a matching function directly and the other one is to learn a classification function. Moreover, our model does not need to load any pretrained weights and is trained with limited sequences from scratch. Plenty of experiments show that our tracker performs favorably against many state-of-the-art tracking methods.},
keywords={Target tracking;Visualization;Task analysis;Training;Internet of Things;Correlation;Feature extraction;Convolutional neural network (CNN);deep learning;Internet of Things (IoT);Siamese cross-residual learning;visual tracking},
doi={10.1109/JIOT.2020.3041052},
ISSN={2327-4662},
month={Oct},}
@ARTICLE{9091866,
author={Wang, Ruo-Qian and Hu, Yingjie and Zhou, Zikai and Yang, Kevin},
journal={IEEE Access}, title={Tracking Flooding Phase Transitions and Establishing a Passive Hotline With AI-Enabled Social Media Data},
year={2020},
volume={8},
number={},
pages={103395-103404},
abstract={Flooding management requires collecting real-time onsite information widely and rapidly. As an emerging data source, social media demonstrates an advantage of providing in-time, rich data in the format of texts and photos and can be used to improve flooding situation awareness. The present study shows that social media data, with additional information processed by Artificial Intelligence (AI) techniques, can be effectively used to track flooding phase transition and locate emergency incidents. To track phase transition, we train a computer vision model that can classify images embedded in social media data into four categories - preparedness, impact, response, and recovery - that can reflect the phases of disaster event development. To locate emergency incidents, we use a deep learning based natural language processing (NLP) model to recognize locations from textual content of tweets. The geographic coordinates of the recognized locations are assigned by searching through a dedicated local gazetteer rapidly compiled for the disaster affected region based on the GeoNames gazetteer and the US Census data. By combining image and text analysis, we filter the tweets that contain images of the “Impact” category and high-resolution locations to gain the most valuable situation information. We carry out a manual examination step to complement the automatic data processing and find that it can further strengthen the AI-processed results to support comprehensive situation awareness and to establish a passive hotline to inform rescue and search activities. The developed framework is applied to the flood of Hurricane Harvey in the Houston area.},
keywords={Social network services;Machine learning;Data mining;Real-time systems;Natural language processing;Disaster management;Computer vision;natural language processing;convolutional neural networks;pluvial flooding;disaster management;rescue and search;resilience},
doi={10.1109/ACCESS.2020.2994187},
ISSN={2169-3536},
month={},}
@ARTICLE{9160860,
author={Saračević, Muzafer H. and Adamović, Saša Z. and Miškovic, Vladislav A. and Elhoseny, Mohamed and Maček, Nemanja D. and Selim, Mahmoud Mohamed and Shankar, K.},
journal={IEEE Transactions on Reliability}, title={Data Encryption for Internet of Things Applications Based on Catalan Objects and Two Combinatorial Structures},
year={2021},
volume={70},
number={2},
pages={819-830},
abstract={This article presents a novel data encryption technique suitable for Internet of Things (IoT) applications. The cryptosystem is based on the application of a Catalan object (as a cryptographic key) that provides encryption based on combinatorial structures with noncrossing or nonnested matching. The experimental part of this article includes a comparative analysis of the proposed encryption method with the Catalan numbers and data encryption standard (DES) algorithm, which is performed with machine learning-based identification of the encryption method using ciphertext only. These tests showed that it is much more difficult to recognize ciphertext generated with the Catalan method than one made with the DES algorithm. System reliability depends on the quality of the key, therefore, statistical testing proposed by National Institute of Standards and Technology was also performed. Twelve standard tests, the approximate entropy measurement, and random digression complexity analysis are applied in order to evaluate the quality of the generated Catalan key. A proposal for applying this method in e-Health IoT is also given. Possibilities of applying this method in the IoT applications for smart cities data storage and processing are provided.},
keywords={Encryption;Internet of Things;Standards;Reliability;Complexity theory;Cryptography;data security;encryption;Internet of Things (IoT);machine learning;reliability},
doi={10.1109/TR.2020.3010973},
ISSN={1558-1721},
month={June},}
@ARTICLE{9050654,
author={Fernandes Lopes, Jessica and Santana, Everton Jose and Turrisi da Costa, Victor G. and Bogaz Zarpelão, Bruno and Barbon Junior, Sylvio},
journal={IEEE Transactions on Network and Service Management}, title={Evaluating the Four-Way Performance Trade-Off for Data Stream Classification in Edge Computing},
year={2020},
volume={17},
number={2},
pages={1013-1025},
abstract={Edge computing (EC) is a promising technology capable of bridging the gap between Cloud computing services and the demands of emerging technologies such as the Internet of Things (IoT). Most EC-based solutions, from wearable devices to smart cities architectures, benefit from Machine Learning (ML) methods to perform various tasks, such as classification. In these cases, ML solutions need to deal efficiently with a huge amount of data, while balancing predictive performance, memory and time costs, and energy consumption. The fact that these data usually come in the form of a continuous and evolving data stream makes the scenario even more challenging. Many algorithms have been proposed to cope with data stream classification, e.g., Very Fast Decision Tree (VFDT) and Strict VFDT (SVFDT). Recently, Online Local Boosting (OLBoost) has also been introduced to improve predictive performance without modifying the underlying structure of the decision tree produced by these algorithms. In this work, we compared the four-way relationship among time efficiency, energy consumption, predictive performance, and memory costs, tuning the hyperparameters of VFDT and the two versions of SVFDT with and without OLBoost. Experiments over 6 benchmark datasets using an EC device revealed that VFDT and SVFDT-I were the most energy-friendly algorithms, with SVFDT-I also significantly reducing memory consumption. OLBoost, as expected, improved the predictive performance, but caused a deterioration in memory and energy consumption.},
keywords={Prediction algorithms;Performance evaluation;Memory management;Energy consumption;Decision trees;Internet of Things;Servers;Machine learning;data stream mining;energy efficiency;Internet of Things;edge computing},
doi={10.1109/TNSM.2020.2983921},
ISSN={1932-4537},
month={June},}
@ARTICLE{9210129,
author={Ridhawi, Ismaeel Al and Otoum, Safa and Aloqaily, Moayad and Boukerche, Azzedine},
journal={IEEE Network}, title={Generalizing AI: Challenges and Opportunities for Plug and Play AI Solutions},
year={2021},
volume={35},
number={1},
pages={372-379},
abstract={Artificial Intelligence (AI) has revolutionized today's Internet of Things (IoT) applications and services by introducing significant technological enhancements across a multitude of domains. With the deployment of the fifth generation (5G) mobile communication network, smart city visions of fast, on-demand, intelligent user-specific services are now becoming a reality. The concept of connected IoT is evolving into connected intelligent things. The advancements of both AI techniques, coupled with the sophistication of edge devices, is now leading to a new era of connected intelligence. Moving the intelligence toward end devices must account for latency demands and simplicity of selecting the type of AI technique to be used. Moreover, since most AI techniques require learning from big data sets and reasoning using a multitude of classification patterns, new simplified and collaborative solutions are now necessary more than ever. As such, the concept of introducing decentralized and distributed `Plug and Play' (PnP) AI tools is now becoming more attractive given the vast numbers in edge devices, data volume and AI techniques. To this end, this article envisions a novel general AI solution that can be adapted to autonomously select the type of machine learning (ML) algorithm, the data set to be used, and provide reasoning in regards to data selection for optimal features extraction. Moreover, the solution performs the necessary training and all the necessary parameter fine-tunings to achieve the highest level of generality and simplicity for AI at the edge. We explore several aspects related to PnP-AI and its impact in the smart city ecosystem.},
keywords={Data models;Adaptation models;Machine learning;Training data;Machine learning algorithms;Support vector machines},
doi={10.1109/MNET.011.2000371},
ISSN={1558-156X},
month={January},}
@INPROCEEDINGS{8249106,
author={Wang, Yi and Saez, Brandon and Szczechowicz, Joseph and Ruisi, Jonathan and Kraft, Tyler and Toscano, Stephen and Vacco, Zachary and Nicolas, Kervins},
booktitle={2017 IEEE 8th Annual Ubiquitous Computing, Electronics and Mobile Communication Conference (UEMCON)}, title={A smart campus internet of things framework},
year={2017},
volume={},
number={},
pages={498-503},
abstract={Smart cities and communities (S&CC) are experiencing transformational change across the nation and globally with the proliferation deployment of Internet of Things (IoT). Smart campus is an important part of S&CC. We built a smart campus IoT framework to address functionality, energy consumption, security and safety in a user-centric perspective. To achieve these, machine learning algorithms are employed in the hardware-software co-design process. During experiment, we focused on energy consumption management using support vector machine to learn the classroom schedule, so that the system can respond to dynamic change of the schedules. The experimental results show that our proposed framework can recognize the classroom regular events and irregular events with high accuracy.},
keywords={Monitoring;Energy consumption;Safety;Schedules;Intelligent sensors;Security;smart campus;internet of things;machine learning;energy consumption},
doi={10.1109/UEMCON.2017.8249106},
ISSN={},
month={Oct},}

@article{LIN2019287,
title = {A Realization of Cyber-Physical Manufacturing Control System Through Industrial Internet of Things},
journal = {Procedia Manufacturing},
volume = {39},
pages = {287-293},
year = {2019},
note = {25th International Conference on Production Research Manufacturing Innovation: Cyber Physical Manufacturing August 9-14, 2019 | Chicago, Illinois (USA)},
issn = {2351-9789},
doi = {https://doi.org/10.1016/j.promfg.2020.01.449},
url = {https://www.sciencedirect.com/science/article/pii/S2351978920305217},
author = {Yu–Ju Lin and Ci-Bin Lan and Chin-Yin Huang},
keywords = {Cloud computing, Data analytics, Industrial Internet of Things, Micro control unit, Ontology},
abstract = {A Cyber-Physical System in Industry 4.0 is with interconnected elements of cyber and physical worlds. However, the interconnection relies on the success of communication among the equipment, sensors, controllers with different data and communication standards. (Protocols) This research takes an approach of applying Industrial Internet of Things (IIoT) to integrate the sensing data from various equipment and sources. Industrial Micro Control Unit (MCU) is applied to interface with the data sources, actuators, and equipment. The MCU transmits the sensing data/control commands back and forth with the cloud/fog computing platform. By deploying data analytics and reasoning for the manufacturing knowledge ontology in the cloud platform, the cyber world is able to recognize the situations and problems in the physical world. Thus, a decision of preventive or predicative actions can be made in the cyber world and then be implemented in the physical world. The results show that IIoT can eliminate the problems of heterogeneous protocols and databases in manufacturing data transmission. Based on IIoT, CPS is realized without the concerns or difficulties of data transmission}
}
@article{MORAWSKA2018286,
title = {Applications of low-cost sensing technologies for air quality monitoring and exposure assessment: How far have they gone?},
journal = {Environment International},
volume = {116},
pages = {286-299},
year = {2018},
issn = {0160-4120},
doi = {https://doi.org/10.1016/j.envint.2018.04.018},
url = {https://www.sciencedirect.com/science/article/pii/S0160412018302460},
author = {Lidia Morawska and Phong K. Thai and Xiaoting Liu and Akwasi Asumadu-Sakyi and Godwin Ayoko and Alena Bartonova and Andrea Bedini and Fahe Chai and Bryce Christensen and Matthew Dunbabin and Jian Gao and Gayle S.W. Hagler and Rohan Jayaratne and Prashant Kumar and Alexis K.H. Lau and Peter K.K. Louie and Mandana Mazaheri and Zhi Ning and Nunzio Motta and Ben Mullins and Md Mahmudur Rahman and Zoran Ristovski and Mahnaz Shafiei and Dian Tjondronegoro and Dane Westerdahl and Ron Williams},
keywords = {Low cost sensor/monitor, Air pollution sensing, Sensor data utilisation, Air sensor/monitor performance, Personal exposure monitoring},
abstract = {Over the past decade, a range of sensor technologies became available on the market, enabling a revolutionary shift in air pollution monitoring and assessment. With their cost of up to three orders of magnitude lower than standard/reference instruments, many avenues for applications have opened up. In particular, broader participation in air quality discussion and utilisation of information on air pollution by communities has become possible. However, many questions have been also asked about the actual benefits of these technologies. To address this issue, we conducted a comprehensive literature search including both the scientific and grey literature. We focused upon two questions: (1) Are these technologies fit for the various purposes envisaged? and (2) How far have these technologies and their applications progressed to provide answers and solutions? Regarding the former, we concluded that there is no clear answer to the question, due to a lack of: sensor/monitor manufacturers' quantitative specifications of performance, consensus regarding recommended end-use and associated minimal performance targets of these technologies, and the ability of the prospective users to formulate the requirements for their applications, or conditions of the intended use. Numerous studies have assessed and reported sensor/monitor performance under a range of specific conditions, and in many cases the performance was concluded to be satisfactory. The specific use cases for sensors/monitors included outdoor in a stationary mode, outdoor in a mobile mode, indoor environments and personal monitoring. Under certain conditions of application, project goals, and monitoring environments, some sensors/monitors were fit for a specific purpose. Based on analysis of 17 large projects, which reached applied outcome stage, and typically conducted by consortia of organizations, we observed that a sizable fraction of them (~ 30%) were commercial and/or crowd-funded. This fact by itself signals a paradigm change in air quality monitoring, which previously had been primarily implemented by government organizations. An additional paradigm-shift indicator is the growing use of machine learning or other advanced data processing approaches to improve sensor/monitor agreement with reference monitors. There is still some way to go in enhancing application of the technologies for source apportionment, which is of particular necessity and urgency in developing countries. Also, there has been somewhat less progress in wide-scale monitoring of personal exposures. However, it can be argued that with a significant future expansion of monitoring networks, including indoor environments, there may be less need for wearable or portable sensors/monitors to assess personal exposure. Traditional personal monitoring would still be valuable where spatial variability of pollutants of interest is at a finer resolution than the monitoring network can resolve.}
}
@article{VERMA201827,
title = {Cloud-centric IoT based disease diagnosis healthcare framework},
journal = {Journal of Parallel and Distributed Computing},
volume = {116},
pages = {27-38},
year = {2018},
note = {Towards the Internet of Data: Applications, Opportunities and Future Challenges},
issn = {0743-7315},
doi = {https://doi.org/10.1016/j.jpdc.2017.11.018},
url = {https://www.sciencedirect.com/science/article/pii/S0743731517303301},
author = {Prabal Verma and Sandeep K. Sood},
keywords = {User Diagnosis Result (UDR), Smart Student Interactive System (SSIS), Cloud computing, Internet of Things (IoT), m-health},
abstract = {In the last few years, the m-healthcare applications based on Internet of Things (IoT) have provided multi-dimensional features and real-time services. These applications provide a platform to millions of people to get health updates regularly for a healthier lifestyle. Induction of IoT devices in the healthcare environment have revitalized multiple features of these applications. The big data generated by IoT devices in healthcare domain is analyzed on the cloud instead of solely relying on limited storage and computation resources of handheld devices. Relative to this context, a cloud-centric IoT basedm-healthcare monitoring disease diagnosing framework is proposed which predicts the potential disease with its level of severity. Key terminologies are defined to generate user-oriented health measurements by exploring the concept of computational sciences. The architectural prototype for smart student healthcare is designed for application scenario. The results are computed after processing the health measurements in a specific context. In our case study, systematic student perspective health data is generated using UCI dataset and medical sensors to predict the student with different disease severity. Diagnosis schemes are applied using various state-of-the-art classification algorithms and the results are computed based on accuracy, sensitivity, specificity, and F-measure. Experimental results show that the proposed methodology outperforms the baseline methods for disease prediction.}
}
@article{WAHEED2021102205,
title = {Learning automata and reservation based secure smart parking system: Methodology and simulation analysis},
journal = {Simulation Modelling Practice and Theory},
volume = {106},
pages = {102205},
year = {2021},
issn = {1569-190X},
doi = {https://doi.org/10.1016/j.simpat.2020.102205},
url = {https://www.sciencedirect.com/science/article/pii/S1569190X20301441},
author = {Amtul Waheed and P. Venkata Krishna and Gitanjali J and Balqies Sadoun and Mohammad Obaidat},
keywords = {Simulation analysis, Learning automata, Smart parking system, Reservation, Markov model},
abstract = {The increase in the number of vehicles on roads has compounded the difficulty in parking them when people go out for movies, shopping, theatre, etc. Thus, this paper proposes smart parking system. The reservation of the parking slots can be made using this proposed smart parking system. Unlike the methods proposed in the existing research, the system proposed in this paper divides the parking area into 3 parts. One for conventional parking, one for vehicles with reservation and the other for the vehicles with and without reservation. Learning automata is used in the proposed system to determine the percentage of the parking area for conventional parking. In general, the proportionate of the slots for reserved parking, conventional parking and common slots need to be assumed. Learning Automata helps in determining this proportionate optimally. The AES-256 encryption algorithm is used to provide security for the details provided by the user during reservation process. Goodput value is maintained for each vehicle which increases or decreases the chances of getting a reservation. The time limit for the reservation of the parking slot is also maintained after which the reservation gets cancelled automatically. Markov Model is used to represent the system. The performance of the proposed algorithm, Learning Automata and Reservation based Secure Smart Parking System (LA-RSSPS) is simulated and evaluated in terms of average waiting time, search time, the probability with which the vehicles do not get parking slot when they do not have reservation and the probability with which the vehicles do not get reservation and is compared with ProNet and iERS. Results have shown that our scheme preforms better than the ProNet and iERS competing schemes. The comparison of analytical and simulations results are also presented.}
}
@article{FRANCO2020105389,
title = {Monitoring of Ocimum basilicum seeds growth with image processing and fuzzy logic techniques based on Cloudino-IoT and FIWARE platforms},
journal = {Computers and Electronics in Agriculture},
volume = {173},
pages = {105389},
year = {2020},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2020.105389},
url = {https://www.sciencedirect.com/science/article/pii/S0168169919322987},
author = {J. Diego Franco and Tania A. Ramirez-delReal and Daniel Villanueva and Araceli Gárate-García and Dagoberto Armenta-Medina},
keywords = {Monitoring system, , Image processing, Fuzzy logic, Cloudino-IoT-FIWARE},
abstract = {The monitoring systems on the climatic conditions in the agriculture industry are increasingly useful and applicable since they allow to improve the processes of growth in the plants. This paper develops a monitoring system for the germination of Ocimum basilicum seeds using image processing and fuzzy logic techniques. Besides, the system is based on the Cloudino-IoT and FIWARE platforms as a real-time monitoring alternative. Therefore, temperature and humidity parameters can be observed in real-time. On the one hand, the system controls the variables through fuzzy control techniques and image processing monitors the germination in the radicle seed, and on the other, context data is used by the Cloudino-IoT and FIWARE platforms. On the other hand, the use of these combined open-source platforms allows cloud computing to be enabled to maintain, specify, analyze the data and automate the environmental parameters that allow maintaining temperature and humidity levels at optimal levels to create a favorable germination environment. The performance of the set-point control is compared with experimental results and the function interconnection of the IoT devices.}
}
@article{REHMAN20171,
title = {Towards next-generation heterogeneous mobile data stream mining applications: Opportunities, challenges, and future research directions},
journal = {Journal of Network and Computer Applications},
volume = {79},
pages = {1-24},
year = {2017},
issn = {1084-8045},
doi = {https://doi.org/10.1016/j.jnca.2016.11.031},
url = {https://www.sciencedirect.com/science/article/pii/S1084804516302995},
author = {Muhammad Habib ur Rehman and Chee Sun Liew and Teh Ying Wah and Muhammad Khurram Khan},
keywords = {Frequent pattern mining, Classification, Clustering, Mobile computing, Cloud computing, Edge computing},
abstract = {The convergence of Internet of Things (IoTs), mobile computing, cloud computing, edge computing and big data has brought a paradigm shift in computing technologies. New computing systems, application models, and application areas are emerging to handle the massive growth of streaming data in mobile environments such as smartphones, IoTs, body sensor networks, and wearable devices, to name a few. However, the challenge arises about how and where to process the data streams in order to perform analytic operations and uncover useful knowledge patterns. The mobile data stream mining (MDSM) applications involve a number of operations for, 1) data acquisition from heterogeneous data sources, 2) data preprocessing, 3) data fusion, 4) data mining, and 5) knowledge management. This article presents a thorough review of execution platforms for MDSM applications. In addition, a detailed taxonomic discussion of heterogeneous MDSM applications is presented. Moreover, the article presents detailed literature review of methods that are used to handle heterogeneity at application and platform levels. Finally, the gap analysis is articulated and future research directions are presented to develop next-generation MDSM applications.}
}
@article{SANZ2021107249,
title = {A wrapper methodology to learn interval-valued fuzzy rule-based classification systems},
journal = {Applied Soft Computing},
volume = {104},
pages = {107249},
year = {2021},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2021.107249},
url = {https://www.sciencedirect.com/science/article/pii/S1568494621001721},
author = {Jose Antonio Sanz and Humberto Bustince},
keywords = {Classification problems, Evolutionary fuzzy systems, Fuzzy rule-based classification systems, Interval-valued fuzzy sets, Interval type-2 fuzzy sets},
abstract = {Learning an interval-valued fuzzy rule-based classification system is a challenge as its success directly depends on the interval-valued fuzzy partition used. In fact, the learning of an interval-valued fuzzy system usually starts by creating a partition composed of numerical fuzzy sets, which are used to build an initial fuzzy classifier. Then, it is augmented with interval-valued fuzzy sets whose shape is subsequently optimized to improve the system’s performance. However, as in this methodology the fuzzy rules are learned using numerical fuzzy sets, the benefits of the interval-valued fuzzy sets may not be fully exploited. In this paper we define a new learning methodology that avoids building the initial fuzzy classifier but directly learns interval-valued fuzzy rules. To do so, we define a wrapper methodology to learn the interval-valued fuzzy partitions such that they lead to an interval-valued fuzzy rule-based classification system as accurate as possible. Moreover, our new method allows one to represent each membership function using the most proper type of fuzzy set for the sake of modeling the uncertainty in the best possible manner. Consequently, the antecedents of the rules can be formed of only numerical fuzzy sets, only interval-valued fuzzy sets or a mixture of both. The quality of the proposal is compared versus four state-of-the-art fuzzy classifiers like FARC-HD, IVTURS, FURIA and FARC-HD using an inference based on a generalization of the Choquet integral. We also compare our new approach besides its numerical fuzzy counterpart to clearly show the benefits of the usage of interval-valued fuzzy sets. Specifically, the average accuracy rate of our new method is 81.17%, which is at least 0.66% better than the remainder state-of-the-art fuzzy classifiers.}
}
@article{YILDIZBASI2021183,
title = {Blockchain and renewable energy: Integration challenges in circular economy era},
journal = {Renewable Energy},
volume = {176},
pages = {183-197},
year = {2021},
issn = {0960-1481},
doi = {https://doi.org/10.1016/j.renene.2021.05.053},
url = {https://www.sciencedirect.com/science/article/pii/S0960148121007291},
author = {Abdullah Yildizbasi},
keywords = {Blockchain, Renewable energy, Circular economy, Energy policy, Pythagorean fuzzy AHP},
abstract = {Renewable energy technologies play a crucial role in reducing the energy consumption by exploiting natural energy resources. With the increase in the trend towards the use of renewable energy resources energy distribution networks have become more complex. As such, it is envisioned that efficient distribution of the generated energy, illegal energy use, unfair pricing, and individual energy producers' entry into the market will be the key issues that need be tackled in near future. In this study, we discuss in order to eliminate the problems experienced in the energy grid management process, the blockchain concept, and its integration with renewable energy systems. First, we develop a novel integration process of blockchain with the renewable energy systems under the circular economy perspective in order to ensure the sustainability of energy grid management systems, followed by discussions on the advantages of the proposed integration process for energy policy makers. Second, the challenges of blockchain faced during the integration to a circular economy are presented. In order to prioritize the challenges encountered in the integration process, a numerical analysis is conducted using the Pythagorean Fuzzy Analytical Hierarchy Process method based on expert opinions, and corresponding managerial implications are included.}
}
@article{AZIZI2021102673,
title = {Cost/comfort-oriented clustering-based extended time of use pricing},
journal = {Sustainable Cities and Society},
volume = {66},
pages = {102673},
year = {2021},
issn = {2210-6707},
doi = {https://doi.org/10.1016/j.scs.2020.102673},
url = {https://www.sciencedirect.com/science/article/pii/S221067072030888X},
author = {E. Azizi and A. {M. Shotorbani} and R. Ahmadiahangar and B. Mohammadi-Ivatloo and A. Rosin and R. Sadiq and K. Hewage},
keywords = {Electricity pricing, Time of use rates, Real-time pricing, Clustering},
abstract = {Real-time pricing (RTP), as the most effective electricity pricing method, has recently attracted significant attention in tackling the challenges of the evolving power grid such as peak shaving and shifting, as well as the emergence of energy prosumers. However, the realization of RTP schemes require an advanced metering infrastructure (AMI). Therefore, time-of-use (ToU) pricing is still in use in residential sectors. This paper presents a novel clustering-based extended time of use pricing (ETOU) algorithm as an intermediate solution, which combines the advantages of both RTP and ToU pricing methods, without a need for AMI, while considering consumers’ desired comfort level. The proposed ETOU is designed based on analyzing the consumption patterns and the real cost of energy generation. The proposed rates are defined considering the dominant consumption and energy cost values extracted by clustering. The effectiveness of the proposed ETOU is verified through numerical analysis of a residential building with an electrical thermal system modeled as a controllable load and an electrical vehicle modeled as a delay-tolerant demand. Results show that the proposed tariffs, in comparison with RTP and ToU rates, noticeably increase the load factor and energy flexibility and decrease the maximum power ramp and electricity costs, while providing the desired comfort level. Additionally, implementation of the proposed ETOU does not require AMI despite the RTP method.}
}
@article{ZHUANG2016858,
title = {Mixed noise removal based on a novel non-parametric Bayesian sparse outlier model},
journal = {Neurocomputing},
volume = {174},
pages = {858-865},
year = {2016},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2015.09.095},
url = {https://www.sciencedirect.com/science/article/pii/S0925231215014496},
author = {Peixian Zhuang and Yue Huang and Delu Zeng and Xinghao Ding},
keywords = {Mixed noise removal, Non-parametric Bayesian model, Spike-slab, Automatic parameter estimation},
abstract = {We develop a novel non-parametric Bayesian sparse outlier model for the problem of mixed noise removal. Based on the assumptions of sparse data and isolated outliers, the proposed model is considered for decomposing the observed data into three components of ideal data, Gaussian noise and outlier noise. Then the spike-slab prior is employed for outlier noise and sparse coefficients of ideal data. The proposed method can automatically infer noise statistics (e.g., Gaussian noise variance) from the training data without changing model hyper-parameter settings. It is also robust to initialization without using adaptive median filter as in other denoising methods. Experimental results demonstrate proposed model can achieve better objective and subjective performances on mixed noise removal than other state-of-the-art methods.}
}
@article{SHARMA2021100592,
title = {Scheduling computing loads for improved utilization of solar energy},
journal = {Sustainable Computing: Informatics and Systems},
volume = {32},
pages = {100592},
year = {2021},
issn = {2210-5379},
doi = {https://doi.org/10.1016/j.suscom.2021.100592},
url = {https://www.sciencedirect.com/science/article/pii/S2210537921000810},
author = {Divya Sharma and Shrisha Rao},
keywords = {Green energy, Brown energy, Ren-percent, Data centers, Renewable energy, Job scheduling, Solar energy, Computing load},
abstract = {The rise in the penetration of the internet across the world has led to a rapid increase in the consumption of energy at the data centers established by leading cloud data service providers. High power consumption by these data centers [DCs] leads to high operational costs and high carbon emissions into the environment. From a sustainability point of view, the ultimate goal is to maximize the productivity and efficiency of these data centers while keeping greenhouse gas emissions to the minimum and maximize data center productivity. This goal can be achieved by better resource utilization and replacing carbon-intensive approaches of energy production with green sources of energy. Due to the limited intermittent availability of renewable sources of energy, the ideal ‘Green’ design for the DCs, should incorporate inter-operability with both renewable and non-renewable sources of energy. In this paper, we propose a ren-aware scheduler to schedule computational workload by prioritizing their execution within the duration of green energy availability on the basis of the predicted hourly green energy and workload data of DCs. Our results demonstrate that our ren-aware scheduler can increase the green energy consumption by 51% compared to the conventional randomized scheduler that distributes load without considering green energy and load. It can also reduce the total energy consumption by 25% by putting the DCs to sleep during their idle time, as it saves 4.5 times more idle energy than the randomized scheduler. Additionally, the results also demonstrate how the role of time zones of the DCs and the duration of green energy availability in them is pivotal in our ren-aware scheduler's performance.}
}
@article{MUNOZVILLAMIZAR2021211,
title = {Study of urban-traffic congestion based on Google Maps API: the case of Boston},
journal = {IFAC-PapersOnLine},
volume = {54},
number = {1},
pages = {211-216},
year = {2021},
note = {17th IFAC Symposium on Information Control Problems in Manufacturing INCOM 2021},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2021.08.079},
url = {https://www.sciencedirect.com/science/article/pii/S2405896321008144},
author = {A. Muñoz-Villamizar and E.L. Solano-Charris and Mojdeh AzadDisfany and L. Reyes-Rubiano},
keywords = {Urban logistics, last-mile delivery, Google API, statistical analysis, case study},
abstract = {Urbanization growth, together with the limited capacity of the road network, has worsened traffic congestion inside the cities. To improve the urban traffic conditions, it is essential to better understand and measure urban-traffic behavior not only on different period time of a day (e.g., morning or evening peaks) but also on different days (i.e., Monday to Sunday). Using real and recent data from the Google Maps API, this paper proposes a new approach to estimate the speeds within defined geographical areas (i.e. zip codes) per daytime and per weekday. Using this input a statistical analysis including k-means clustering is adopted to classify and define different urban-congestion levels according to the estimated speeds the number of inhabitants the zone types and the type of roads in each zip code. In order to validate our approach, we conduct an experimental analysis in Boston, US. Our results provide managerial insights for key stakeholders (i.e., Carriers, Consumers, and Government) to improve the efficiency of the road network and reduce traffic congestion in cities.}
}
@article{LIU2016204,
title = {An Approach Based on Improved Grey Model for Predicting Maintenance Time of IPS2},
journal = {Procedia CIRP},
volume = {47},
pages = {204-209},
year = {2016},
note = {Product-Service Systems across Life Cycle},
issn = {2212-8271},
doi = {https://doi.org/10.1016/j.procir.2016.03.047},
url = {https://www.sciencedirect.com/science/article/pii/S2212827116300178},
author = {Yuji Liu and Yaoguang Hu and Rui Zhou and Jingqian Wen},
keywords = {maintenance service, IPSS, time prediction, grey theory},
abstract = {Maintenance service is the most important part in industrial product-service system (iPSS). To enhance the proactiveness of maintenance service, the failure time of product need to be predicted. This study provides insight into how the maintenance time can be predicted accurately for the service decision-making of IPSS based on the historical failure time data, avoiding the dependence on mechanical condition monitoring. An improved grey prediction model is introduced to obtain a predictive interval of maintenance service time which is used as basis for making a decision of proactive maintenance service. The method is applied in an instance of maintenance service for agricultural machinery. In three examples of different types of agricultural machinery, the predicted intervals of maintenance time are given and the fitted values have high accordance with the real ones. The result shows that this approach can be used effectively to predict production failure time. Moreover, the output results of this approach can provide the necessary support to make a decision for proactive maintenance service without the dependence on mechanical condition monitoring in a reliable way.}
}
@article{KOUSAR2021111024,
title = {First principles investigation of oxygen vacancies filaments in polymorphic Titania and their role in memristor's applications},
journal = {Chaos, Solitons & Fractals},
volume = {148},
pages = {111024},
year = {2021},
issn = {0960-0779},
doi = {https://doi.org/10.1016/j.chaos.2021.111024},
url = {https://www.sciencedirect.com/science/article/pii/S0960077921003787},
author = {Farhana Kousar and Umbreen Rasheed and R. M. Arif Khalil and Niaz Ahmad Niaz and Fayyaz Hussain and Muhammad Imran and Umema Shakoor and Hassan Algadi and Naeem Ashiq},
keywords = {RRAM, Memristors, Conducting filaments, Charge density, DFT},
abstract = {Inconsistency of resistive switching parameters in memristors is a major challenge in the development of memory devices. These variability issues can be resolved by using materials having capability of easily growing conducting filaments and less value of oxygen vacancy formation energy (OVFE). In this first principle study, device to device variability by the electronic modification subsequently with the creation of the oxygen vacancies in TiO2 phases have been investigated using density functional theory. The lattice constants, OVFE, density of states (DOS), partial density of states (PDOS), iso-surface charge density and integrated charge density are calculated to understand the structural and electronic properties of polytype TiO2 with single-, di- and tri-oxygen vacancy (Vo) at atomistic level. It is found that by introducing the Vos, defect states are formed within the band gap, which caused to increase the conductivity of crystalline phases of TiO2. The conductivity of the phases increased with increasing number of Vos resulting in low resistance state of the opted phase. Existence of various stages of CFs and formation energy at various concentration of Vos predicts the implementation of constructive role of noise to enhance the efficiency and stability of the Titania based memristors. On the basis of easily growing conducing filaments having higher concentration of Vos with lesser OVFE, it is predicted that brookite phase of TiO2 having 3Vos is more suitable in overcoming inconsistency issues related to resistive switching in low power consuming memristors devices.}
}
@article{SHIN2016837,
title = {Demystifying big data: Anatomy of big data developmental process},
journal = {Telecommunications Policy},
volume = {40},
number = {9},
pages = {837-854},
year = {2016},
issn = {0308-5961},
doi = {https://doi.org/10.1016/j.telpol.2015.03.007},
url = {https://www.sciencedirect.com/science/article/pii/S0308596115000567},
author = {Dong-Hee Shin},
keywords = {Big data, Data ecosystem, Normalization, Normalization process theory, Big data user, Big data user experience},
abstract = {This study seeks to understand big data ecology, how it is perceived by different stakeholders, the potential value and challenges, and the implications for the private sector and public organizations, as well as for policy makers. With Normalization Process Theory in place, this study conducts socio-technical evaluation on the big data phenomenon to understand the developmental processes through which new practices of thinking and enacting are implemented, embedded, and integrated in South Korea. It also undertakes empirical analyses of user modeling to explore the factors influencing users׳ adoption of big data by integrating cognitive motivations as well as user values as the primary determining factors. Based on the qualitative and quantitative findings, this study concludes that big data should be developed with user-centered ideas and that users should be the focus of big data design.}
}
@article{URIZ2020106399,
title = {FUZZ-EQ: A data equalizer for boosting the discrimination power of fuzzy classifiers},
journal = {Applied Soft Computing},
volume = {93},
pages = {106399},
year = {2020},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2020.106399},
url = {https://www.sciencedirect.com/science/article/pii/S1568494620303392},
author = {Mikel Uriz and Mikel Elkano and Humberto Bustince and Mikel Galar},
keywords = {Fuzzy partitioning, Preprocessing, Fuzzy rule-based classification systems, Fuzzy decision trees, Probability integral transform, Quantile function},
abstract = {The definition of linguistic terms is a critical part of the construction of any fuzzy classifier. Fuzzy partitioning methods (FPMs) range from simple uniform partitioning to sophisticated optimization algorithms. In this paper we present FUZZ-EQ, a preprocessing algorithm that facilitates the construction of meaningful fuzzy partitions regardless of the FPM used. The proposed approach is radically different from any existing FPM: instead of adjusting the fuzzy sets to the training data, FUZZ-EQ adjusts the training data to a hypothetical uniform partition before applying any FPM. To do so, the original data distribution is transformed into a uniform distribution by applying the probability integral transform. FUZZ-EQ allows FPMs to provide classifiers with more granularity on high density regions, increasing the overall discrimination capability. Additionally, we describe the procedure to reverse this transformation and recover the interpretability of linguistic terms. To assess the effectiveness of our proposal, we conducted an extensive empirical study consisting of 41 classification tasks and 9 fuzzy classifiers with different FPMs, rule induction algorithms, and rule structures. We also tested the scalability of FUZZ-EQ in Big Data classification problems such as HIGGS, with 11 million examples. Experimental results reveal that FUZZ-EQ significantly boosted the classification performance of those classifiers using the same linguistic terms for all rules, including state-of-the-art classifiers such as FARC-HD or IVTURS.}
}
@article{ORTIZ2022103550,
title = {Atmosphere: Context and situational-aware collaborative IoT architecture for edge-fog-cloud computing},
journal = {Computer Standards & Interfaces},
volume = {79},
pages = {103550},
year = {2022},
issn = {0920-5489},
doi = {https://doi.org/10.1016/j.csi.2021.103550},
url = {https://www.sciencedirect.com/science/article/pii/S0920548921000453},
author = {Guadalupe Ortiz and Meftah Zouai and Okba Kazar and Alfonso Garcia-de-Prado and Juan Boubeta-Puig},
keywords = {Collaborative Internet of Things, Edge computing, Smart data, Context and situational awareness, Agent-oriented software, Complex event processing},
abstract = {The Internet of Things (IoT) has grown significantly in popularity, accompanied by increased capacity and lower cost of communications, and overwhelming development of technologies. At the same time, big data and real-time data analysis have taken on great importance and have been accompanied by unprecedented interest in sharing data among citizens, public administrations and other organisms, giving rise to what is known as the Collaborative Internet of Things. This growth in data and infrastructure must be accompanied by a software architecture that allows its exploitation. Although there are various proposals focused on the exploitation of the IoT at edge, fog and/or cloud levels, it is not easy to find a software solution that exploits the three tiers together, taking maximum advantage not only of the analysis of contextual and situational data at each tier, but also of two-way communications between adjacent ones. In this paper, we propose an architecture that solves these deficiencies by proposing novel technologies which are appropriate for managing the resources of each tier: edge, fog and cloud. In addition, the fact that two-way communications along the three tiers of the architecture is allowed considerably enriches the contextual and situational information in each layer, and substantially assists decision making in real time. The paper illustrates the proposed software architecture through a case study of respiratory disease surveillance in hospitals. As a result, the proposed architecture permits efficient communications between the different tiers responding to the needs of these types of IoT scenarios.}
}
@article{KUANG2021102167,
title = {Cooperative computation offloading and resource allocation for delay minimization in mobile edge computing},
journal = {Journal of Systems Architecture},
volume = {118},
pages = {102167},
year = {2021},
issn = {1383-7621},
doi = {https://doi.org/10.1016/j.sysarc.2021.102167},
url = {https://www.sciencedirect.com/science/article/pii/S1383762121001181},
author = {Zhufang Kuang and Zhihao Ma and Zhe Li and Xiaoheng Deng},
keywords = {Mobile edge computing, Cooperative computation offloading, Delay minimization, Resource allocation},
abstract = {Mobile edge computing (MEC) is a promising paradigm, which brings computation resources in proximity to mobile devices and allows the tasks of mobile devices to be offloaded to MEC servers with low latency. The joint problem of cooperative computation task offloading and resource allocation is a challenging issue. The joint problem of cooperative computation task offloading scheme and resource assignment in MEC is investigated in this paper, where the vertical cooperation among mobile devices, mobile edge server nodes and mobile cloud server nodes is considered, and the horizontal computation cooperation between edge nodes is considered as well. A computation offloading decision, cooperative selection, power allocation and CPU cycle frequency assignment problem is formulated. The objective is to minimize the latency while guaranteeing the constraint of transmission power, energy consumption and CPU cycle frequency. The formulated latency optimization problem is a nonconvex mixed-integer problem in general, which has binary variables and continuous variables. In order to solve the formulated problem. A joint iterative algorithm based on the Lagrangian dual decomposition, ShengJin Formula method, and monotonic optimization method is proposed. The CPU cycle frequence allocation is handled by the ShengJin Formula method due to the cubic equation of one variable about the CPU frequence allocation. The transmission power assignment is handled by the monotonic optimization method. In the algorithm convergence with different number of tasks, the proposed algorithm can quickly and effectively reach the convergence state and getting the minimum task execution delay. Numerical results demonstrate that the proposed algorithm outperforms the Full MEC, Full Local and Full Cloud three schemes in terms of execution latency.}
}
@article{PRADHAN2021101878,
title = {A genetic algorithm based energy efficient group paging approach for IoT over 5G},
journal = {Journal of Systems Architecture},
volume = {113},
pages = {101878},
year = {2021},
issn = {1383-7621},
doi = {https://doi.org/10.1016/j.sysarc.2020.101878},
url = {https://www.sciencedirect.com/science/article/pii/S1383762120301557},
author = {Buddhadeb Pradhan and V. Vijayakumar and Sanjoy Pratihar and Deepak Kumar and K. Hemant Kumar Reddy and Diptendu Sinha Roy},
keywords = {Long-Term Evolution Advanced (LTE-A), Energy efficient communication, Group paging, 5G, Discontinuous Reception Mechanism (DRX)},
abstract = {Cellular networks are evolving to the era of 5th Generation (5G), where 5G new radio (NR) and Long-Term Evolution: Advanced (LTE-A) Pro technologies are being envisioned for enabling smart and innovative services of the Internet-of-Things (IoT). However, existing LTE-A Pro protocols such as the group paging approach is still heavily inclined towards human-to-human communications owing to the heterogeneous characteristics of a wide variety of IoT devices. Since most IoT devices are battery operated and their power consumption rate decides the battery lifetime, hence energy-efficient data transfer protocols are of paramount importance for next-generation IoT networks. Group paging is one such mechanism that has been widely accepted to improve energy efficiency of IoT networks. However, grouping approach for IoT devices is still not a much addressed topic, though a few novel group paging approaches have been studied that focus on varied IoT characteristics and mobility; though such approaches are not computationally efficient particularly for massive IoT deployments. Therefore, this paper proposes a novel multi-parameter evolutionary optimization, namely, genetic algorithm (GA) based grouping approach that also considers IoT features such as traffic patterns, delay requirements, and mobility patterns. Results obtained from simulations validate that our proposed method can significantly improve IoT devices’ energy efficiency over random grouping schemes and other approaches.}
}
@article{ZHANG2021101675,
title = {Factors influencing the use of artificial intelligence in government: Evidence from China},
journal = {Technology in Society},
volume = {66},
pages = {101675},
year = {2021},
issn = {0160-791X},
doi = {https://doi.org/10.1016/j.techsoc.2021.101675},
url = {https://www.sciencedirect.com/science/article/pii/S0160791X21001500},
author = {Weidong Zhang and Na Zuo and Wu He and Songtao Li and Lu Yu},
keywords = {Artificial intelligence (AI), Government, Application, Stakeholders, Decision-making, China},
abstract = {Some studies have discussed the potential and challenges related to the use of artificial intelligence (AI) in government. However, there are few empirical studies that have examined factors that influence the use of AI in government. By collecting policy documents and empirical data from the government, IT enterprises, and the public in China, we identified the influencing factors in the three stages of government adoption, implementation, and decision-making. The research results show that the influencing factors of government application of AI are different at different stages and with different stakeholders’ backgrounds.}
}
@article{DAVID2018758,
title = {Towards energy efficient buildings: how ICTs can convert advances?},
journal = {IFAC-PapersOnLine},
volume = {51},
number = {11},
pages = {758-763},
year = {2018},
note = {16th IFAC Symposium on Information Control Problems in Manufacturing INCOM 2018},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2018.08.410},
url = {https://www.sciencedirect.com/science/article/pii/S2405896318315362},
author = {M. David and A. Aubry and W. Derigent},
keywords = {Energy Control, Data Models, Networks, Information Technology, Decentralized Control},
abstract = {This work is a positioning research paper for energy efficient building based on ICT solutions. Through the literature about the solutions for energy control of buildings during operational phase, a 3-layers model is proposed to integrate these solutions: first level consists in communication technologies, second level is about data modelling and third level is related to decision-making tools. For each level, key research topics and remaining problems are identified in order to achieve a concrete step forward.}
}
@article{SINGH2019267,
title = {Blood Pressure Monitoring System using Wireless technologies},
journal = {Procedia Computer Science},
volume = {152},
pages = {267-273},
year = {2019},
note = {International Conference on Pervasive Computing Advances and Applications- PerCAA 2019},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2019.05.017},
url = {https://www.sciencedirect.com/science/article/pii/S1877050919306684},
author = {Bharat Singh and Shabana Urooj and Sakshi Mishra and Surojeet Haldar},
keywords = {Drug Delivery System, Fuzzy Inference System, Mean Arterial Blood Pressure, Sodium Nitroprusside, Maximum a posteriori estimators},
abstract = {This paper presents a simple solution for monitoring blood pressure in an economic and user-friendly method. Combining the concepts of Internet of Things with an Arduino microcontroller and a pressure sensor a Blood Pressure Monitoring System using Wireless Technologies are developed. The project aims to setup a network so that concerned people can remotely access patient’s blood pressure readings. Bluetooth and Wi-Fi technology are used to access results on hand held devices like mobiles, tabs, laptops etc. The project also incorporates a prediction algorithm via MATLAB software program. Readings can be recorded overtime manually and when into the program such a data log is passed, it predicts possible blood pressure values for the patient and as well as suggest medical assistance like dosage of medicines}
}
@article{JIA201815,
title = {NucPosPred: Predicting species-specific genomic nucleosome positioning via four different modes of general PseKNC},
journal = {Journal of Theoretical Biology},
volume = {450},
pages = {15-21},
year = {2018},
issn = {0022-5193},
doi = {https://doi.org/10.1016/j.jtbi.2018.04.025},
url = {https://www.sciencedirect.com/science/article/pii/S0022519318301929},
author = {Cangzhi Jia and Qing Yang and Quan Zou},
keywords = {Nucleosome positioning, Nucleotide composition, KNN, GBDT, SVM},
abstract = {The nucleosome is the basic structure of chromatin in eukaryotic cells, with essential roles in the regulation of many biological processes, such as DNA transcription, replication and repair, and RNA splicing. Because of the importance of nucleosomes, the factors that determine their positioning within genomes should be investigated. High-resolution nucleosome-positioning maps are now available for organisms including Saccharomyces cerevisiae, Drosophila melanogaster and Caenorhabditis elegans, enabling the identification of nucleosome positioning by application of computational tools. Here, we describe a novel predictor called NucPosPred, which was specifically designed for large-scale identification of nucleosome positioning in C. elegans and D. melanogaster genomes. NucPosPred was separately optimized for each species for four types of DNA sequence feature extraction, with consideration of two classification algorithms (gradient-boosting decision tree and support vector machine). The overall accuracy obtained with NucPosPred was 92.29% for C. elegans and 88.26% for D. melanogaster, outperforming previous methods and demonstrating the potential for species-specific prediction of nucleosome positioning. For the convenience of most experimental scientists, a web-server for the predictor NucPosPred is available at http://121.42.167.206/NucPosPred/index.jsp.}
}
@article{JOTHEESWARAN2018512,
title = {Hybrid video surveillance systems using P300 based computational cognitive threat signature library},
journal = {Procedia Computer Science},
volume = {145},
pages = {512-519},
year = {2018},
note = {Postproceedings of the 9th Annual International Conference on Biologically Inspired Cognitive Architectures, BICA 2018 (Ninth Annual Meeting of the BICA Society), held August 22-24, 2018 in Prague, Czech Republic},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2018.11.115},
url = {https://www.sciencedirect.com/science/article/pii/S1877050918324037},
author = {Jeevanandam Jotheeswaran and Anurag Singh and Sanjeev Pippal},
keywords = {Brain Computer Interface (BCI), Fast Independent Component Analysis (Fast ICA), Comprehensive Integrated Border Management System (CIBMS), Event Related Potentials (ERP), Human computer Interaction (HCI)},
abstract = {Comprehensive Integrated Border Management System (CIBMS) is aimed to reduce the infiltration at borders of countries and to overcome risk. It is an integration of manpower, sensor, networks, intelligence, command and control solutions. This research work is intended to create a reference library on threat signature using cognitive technology which will enhance the intelligence for CIBMS to reduce the human effort using cognitive science through Brain Computer Interface (BCI) application. The system proposes to use an Electroencephalogram (EEG) cap to monitor the operators brain signals when operator see any abnormal activity across border area and then records the exact video frame when the observer detects a threat. The combination of cognitive algorithm and EEG filtering not only reduces false alarms, it also helps operators to detect signs of threats that would be overlooked, such as flying birds, swaying branches or non threat object according the action recognition. This research aims to suggest a better optimization technique on P300 brain signals and build an operational library of threat signature which can be used for future automated surveillance system with more accuracy.}
}
@article{AVOINE2014682,
title = {Passengers information in public transport and privacy: Can anonymous tickets prevent tracking?},
journal = {International Journal of Information Management},
volume = {34},
number = {5},
pages = {682-688},
year = {2014},
issn = {0268-4012},
doi = {https://doi.org/10.1016/j.ijinfomgt.2014.05.004},
url = {https://www.sciencedirect.com/science/article/pii/S0268401214000620},
author = {Gildas Avoine and Luca Calderoni and Jonathan Delvaux and Dario Maio and Paolo Palmieri},
keywords = {Privacy, Public transport, Sensitive data management, Privacy preserving technology},
abstract = {Modern public transportation companies often record large amounts of information. Privacy can be safeguarded by discarding nominal tickets, or introducing anonymization techniques. But is anonymity at all possible when everything is recorded? In this paper we discuss travel information management in the public transport scenario and we present a revealing case study (relative to the city of Cesena, Italy), showing that even anonymous 10-ride bus tickets may betray a user's privacy expectations. We also propose a number of recommendations for the design and management of public transport information systems, aimed at preserving the users’ privacy, while retaining the useful analysis features enabled by the e-ticketing technology.}
}
@article{HASAN2020274,
title = {Software-defined application-specific traffic management for wireless body area networks},
journal = {Future Generation Computer Systems},
volume = {107},
pages = {274-285},
year = {2020},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2020.01.052},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X19322587},
author = {Khalid Hasan and Khandakar Ahmed and Kamanashis Biswas and Md. {Saiful Islam} and Omid {Ameri Sianaki}},
keywords = {WBAN, Application classification, SDN, SBD, SDWBAN},
abstract = {Wireless body area networks (WBANs) are usually used to collect and monitor health-related information for both critical and non-critical patients. However, the traditional WBAN communication framework is unable to guarantee the successful delivery of critical information due to a lack of administrative control and priority support for emergency data. To overcome these issues, this paper proposes a novel software-defined networking (SDN)-based WBAN (SDWBAN) framework for application-specific traffic management. An application classification algorithm and a packet flow mechanism are developed by incorporating SDN principles with WBAN to effectively manage complex and critical traffic in the network. Furthermore, a Sector-Based Distance (SBD) protocol is designed and utilized to facilitate the SDWBAN communication framework. Finally, the proposed SDWBAN framework is evaluated through the CASTALIA simulator in terms of Packet Delivery Ratio (PDR) and latency. The experimental outcomes show that the proposed system achieves high throughput and low latency for emergency traffic in SDWBANs.}
}
@article{EBRAHIMBANIHABIB2019101585,
title = {Extended linear and non-linear auto-regressive models for forecasting the urban water consumption of a fast-growing city in an arid region},
journal = {Sustainable Cities and Society},
volume = {48},
pages = {101585},
year = {2019},
issn = {2210-6707},
doi = {https://doi.org/10.1016/j.scs.2019.101585},
url = {https://www.sciencedirect.com/science/article/pii/S2210670718327161},
author = {Mohammad {Ebrahim Banihabib} and Pezhman Mousavi-Mirkalaei},
keywords = {ARIMA, Daily water consumption forecasting, Dew point, NARX, Sunshine hours, Population, Urban water supply},
abstract = {Accurate water consumption forecasting models are required for fast-growing cities in arid regions. In the present study, two forecasting models are proposed for urban-water consumption using extended Auto-Regressive Integrated Moving Average (ARIMA) and Nonlinear Auto-Regressive Exogenous (NARX) methods. Various extension of these models by adding new forecaster factors were tested to find superior linear and nonlinear models. The ARIMA and NARX model accuracy with and without additional forecaster factors (minimum, maximum and mean temperature, precipitation, mean relative humidity, sunshine hours, mean dew point temperature, mean wind speed, and population) were compared using accuracy indices. The ARIMA model which includes sunny hour in addition to the base model predictors was selected as the superior linear model and also the model NARX which includes sunny hours and population in addition to the base model’s predictors was selected as the superior nonlinear model. This infers that sunny hour has linear performance and population predictor has non-linear performance in forecasting water consumption. This shows adding sunny hours and population as forecaster factors can robust forecasting performance considerably. By extending the models with these additional forecasting factors, the precision of daily water consumption forecasts can be improved for providing a better urban water supply.}
}
@article{BASKAR202017,
title = {A dynamic and interoperable communication framework for controlling the operations of wearable sensors in smart healthcare applications},
journal = {Computer Communications},
volume = {149},
pages = {17-26},
year = {2020},
issn = {0140-3664},
doi = {https://doi.org/10.1016/j.comcom.2019.10.004},
url = {https://www.sciencedirect.com/science/article/pii/S0140366419306747},
author = {S. Baskar and P. {Mohamed Shakeel} and R. Kumar and M.A. Burhanuddin and R. Sampath},
keywords = {Data gathering, Healthcare data transmission, Scalable communication, Smart health care applications, Smart computing, Wearable sensors},
abstract = {In this manuscript, a dynamic and interoperable communication framework (DICF) for regulating the operations of wearable healthcare devices is introduced. The framework is responsible for monitoring, decision making and controlling the functionalities and operating time of the wearable sensors (WS) as a part of smart health care tracking applications. In this framework, the nature of the wireless sensing device and its intrinsic features are accounted to design a fully operative and automated seamless working of the sensing devices. The sensing devices operate in both autonomous and interconnected manner depending upon the sensed information and the observed body conditions of the patient. The frequency of operation and the time interval varies with the scheduled and random recommendations of the communication framework of the interconnected devices. The framework is designed to improve the interoperability of the devices acclimatized to adapt dynamic nature of different tracking healthcare applications to leverage its performance.}
}
@article{CHAMOLA2021102324,
title = {A Comprehensive Review of Unmanned Aerial Vehicle Attacks and Neutralization Techniques},
journal = {Ad Hoc Networks},
volume = {111},
pages = {102324},
year = {2021},
issn = {1570-8705},
doi = {https://doi.org/10.1016/j.adhoc.2020.102324},
url = {https://www.sciencedirect.com/science/article/pii/S1570870520306788},
author = {Vinay Chamola and Pavan Kotesh and Aayush Agarwal and  Naren and Navneet Gupta and Mohsen Guizani},
keywords = {UAV, Drone, Attacks, Neutralization, Jamming},
abstract = {Unmanned Aerial Vehicles (UAV) have revolutionized the aircraft industry in this decade. UAVs are now capable of carrying out remote sensing, remote monitoring, courier delivery, and a lot more. A lot of research is happening on making UAVs more robust using energy harvesting techniques to have a better battery lifetime, network performance and to secure against attackers. UAV networks are many times used for unmanned missions. There have been many attacks on civilian, military, and industrial targets that were carried out using remotely controlled or automated UAVs. This continued misuse has led to research in preventing unauthorized UAVs from causing damage to life and property. In this paper, we present a literature review of UAVs, UAV attacks, and their prevention using anti-UAV techniques. We first discuss the different types of UAVs, the regulatory laws for UAV activities, their use cases, recreational, and military UAV incidents. After understanding their operation, various techniques for monitoring and preventing UAV attacks are described along with case studies.}
}
@article{MCKENNA2022111845,
title = {Explaining daily energy demand in British housing using linked smart meter and socio-technical data in a bottom-up statistical model},
journal = {Energy and Buildings},
volume = {258},
pages = {111845},
year = {2022},
issn = {0378-7788},
doi = {https://doi.org/10.1016/j.enbuild.2022.111845},
url = {https://www.sciencedirect.com/science/article/pii/S0378778822000160},
author = {Eoghan McKenna and Jessica Few and Ellen Webborn and Ben Anderson and Simon Elam and David Shipworth and Adam Cooper and Martin Pullinger and Tadj Oreszczyn},
keywords = {Building, Energy, Heating, Gas, Electricity, Demand, Consumption, Household, Residential, Domestic, Smart meter, Daily, Longitudinal, Regression, Mixed effects, Random effects, Survey, Energy performance certificate, Weather, Temperature, Solar radiation, Building physics, Sociodemographic, Occupant, Behaviour, Attitudes},
abstract = {This paper investigates factors associated with variation in daily total (electricity and gas) energy consumption in domestic buildings using linked pre-COVID-19 smart meter, weather, building thermal characteristics, and socio-technical survey data covering appliance ownership, demographics, behaviours, and attitudes for two nested sub-samples of 1418 and 682 British households selected from the Smart Energy Research Laboratory (SERL) Observatory panel. Linear mixed effects modelling resulted in adjusted R2 between 63% and 80% depending on sample size and combinations of contextual data used. Increased daily energy consumption was significantly associated (p-value < 0.05, VIF < 5) with: households living in buildings with more rooms and bedrooms, that are older, more detached, have air-conditioning, and experience colder (more heating degree days) or less sunny weather; households with more adult occupants, more children, older adult occupants, higher heating temperature setpoints, and that do not try to save energy. The results demonstrate the value of smart meter data linked with contextual data for improving understanding of energy demand in British housing. Accredited UK researchers are invited to apply to access the data, which has recently been updated to include over 13,000 households from across Great Britain. This paper provides guidance on appropriate methods to use when analysing the data.}
}
@article{QU2021165727,
title = {A discrete-time sliding mode congestion controller for wireless sensor networks},
journal = {Optik},
volume = {225},
pages = {165727},
year = {2021},
issn = {0030-4026},
doi = {https://doi.org/10.1016/j.ijleo.2020.165727},
url = {https://www.sciencedirect.com/science/article/pii/S0030402620315552},
author = {Shaocheng Qu and Liang Zhao and Yao Chen and Wenqi Mao},
keywords = {Wireless Sensor Networks (WSNs), Traffic-based congestion control, Sliding mode control (SMC), Internet of Things (IoT), NS-2.35},
abstract = {Congestion is a challenging problem for Wireless Sensor Networks (WSNs) because it results in energy waste, packet loss, low throughput and short lifecycle. By regulating incoming and outgoing packets at a particular node, this paper first proposes a new traffic-based discrete congestion control model in WSNs. Then, based on this model, an exponential-reaching-law-based discrete-time sliding mode congestion controller (DSMC) is designed, which effectively adjusts bottleneck nodes’ queue length to desired value. Extensive NS-2.35 simulation results demonstrate that the proposed DSMC outperforms conventional control approaches (such as Fuzzy control, PID control and Fuzzy-PID), it significantly controls queue length and avoids congestion, and has better performance such as short delay, low packet loss rate, high throughput, long network lifetime, fast convergence and strong stability.}
}
@article{TAO20181040,
title = {Multi-layer cloud architectural model and ontology-based security service framework for IoT-based smart homes},
journal = {Future Generation Computer Systems},
volume = {78},
pages = {1040-1051},
year = {2018},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2016.11.011},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X16305775},
author = {Ming Tao and Jinglong Zuo and Zhusong Liu and Aniello Castiglione and Francesco Palmieri},
keywords = {Smart home, Heterogeneity, IoT, Cloud, Ontology, Security},
abstract = {The Smart Home concept, associated with the pervasiveness of network coverage and embedded computing technologies is assuming an ever-growing significance for people living in the highly developed areas. However, the heterogeneity of devices, services, communication protocols, standards and data formats involved in most of the available solutions developed by different vendors, is adversely affecting its widespread application. In this paper, promoted by several promising opportunities provided by the advances in Internet of Things (IoT) and Cloud Computing technologies for facing these challenges, a novel multi-layer cloud architectural model is developed to enable effective and seamless interactions/interoperations on heterogeneous devices/services provided by different vendors in IoT-based smart home. In addition, to better solve the heterogeneity issues in the presented layered cloud platform, ontology has been used as a promising way to address data representation, knowledge, and application heterogeneity, and an ontology-based security service framework is designed for supporting security and privacy preservation in the process of interactions/interoperations. Challenges and directions for future work on smart home management have been also discussed at the end of this paper.}
}
@article{RETTOREDEARAUJOZANELLA2020100048,
title = {Security challenges to smart agriculture: Current state, key issues, and future directions},
journal = {Array},
volume = {8},
pages = {100048},
year = {2020},
issn = {2590-0056},
doi = {https://doi.org/10.1016/j.array.2020.100048},
url = {https://www.sciencedirect.com/science/article/pii/S2590005620300333},
author = {Angelita {Rettore de Araujo Zanella} and Eduardo {da Silva} and Luiz Carlos {Pessoa Albini}},
keywords = {Smart agriculture, Security, Open-field agriculture},
abstract = {Smart agriculture integrates a set of technologies, devices, protocols, and computational paradigms to improve agricultural processes. Big data, artificial intelligence, cloud, and edge computing provide capabilities and solutions to keep, store, and analyze the massive data generated by components. However, smart agriculture is still emerging and has a low level of security features. Future solutions will demand data availability and accuracy as key points to help farmers, and security is crucial to building robust and efficient systems. Since smart agriculture comprises a wide variety and quantity of resources, security addresses issues such as compatibility, constrained resources, and massive data. Conventional protection schemes used in the traditional Internet or Internet of Things may not be useful for agricultural systems, creating extra demands and opportunities. This paper aims at reviewing the state-of-the art of smart agriculture security, particularly in open-field agriculture, discussing its architecture, describing security issues, presenting the major challenges and future directions.}
}
@article{AMIN202052,
title = {CFSec: Password based secure communication protocol in cloud-fog environment},
journal = {Journal of Parallel and Distributed Computing},
volume = {140},
pages = {52-62},
year = {2020},
issn = {0743-7315},
doi = {https://doi.org/10.1016/j.jpdc.2020.02.005},
url = {https://www.sciencedirect.com/science/article/pii/S0743731520301076},
author = {Ruhul Amin and Sourav Kunal and Arijit Saha and Debasis Das and Atif Alamri},
keywords = {Fog Devices, Cloud computing, Secure communication, Scyther Tool},
abstract = {With the growing needs of data across the world, it is almost hard to live without data a day. The fog computing concept is aiming to change the scenarios created by Cloud Computing environments and also to make the data-centric clouds decentralized and localized. Fog devices which aim to be at a shorter distance with the user, access data from the cloud itself. Hence, exchanging data between the cloud and fog device(s) is required and in this context security and privacy come into the picture to provide data confidentiality. This paper first shows an architecture for the data flow model between the cloud and fog computing and then designs an authentication protocol with proper key establishment between the cloud, fog, and user. We have simulated the proposed protocol using a popular simulator i.e., Scyther and proved that the parameters used in our protocol are strongly protected during protocol execution. Besides, our informal security analysis also confirms the robustness of the protocol. Our protocol achieves quick responses in comparison with state-of-the-art because of less computation overhead.}
}
@article{LIU20211382,
title = {China’s renewable energy strategy and industrial adjustment policy},
journal = {Renewable Energy},
volume = {170},
pages = {1382-1395},
year = {2021},
issn = {0960-1481},
doi = {https://doi.org/10.1016/j.renene.2021.02.045},
url = {https://www.sciencedirect.com/science/article/pii/S0960148121002135},
author = {Xiaohong Liu and Tong Zhao and Ching-Ter Chang and Changjui James Fu},
keywords = {Renewable energy strategy, Energy productivity, CO productivity},
abstract = {The rapid development of China’s economy has driven the growth of energy consumption. However, the domination of the energy structure by fossil energy not only increases carbon emissions but is also an important source of fog and haze in China. This will cause global warming and increase people’s lung diseases. To alleviate these problems, renewable energy (RE) development is crucial in reducing CO2 emissions, promoting economic development, and reducing fog and haze in China. Industry accounts for the highest proportion of energy consumption, so an efficient adjustment of the industrial structure will greatly contribute to overall energy development, economic development, and environmental protection. By analyzing the sales output value of China’s industrial subsectors, together with energy consumption and CO2 emissions, this paper determines which industries should be encouraged and which industries should be restricted in China. Finally, RE strategies and industrial policies are proposed for Chinese government references. The contributions of the paper are three-fold: (1) propose a novel framework for the development of China in the aspects of energy, economy, and environmental policies; (2) provide valuable information for the Chinese government to enable it to understand which industries should be encouraged to improve its economic competitiveness; and (3) use hybrid methods (e.g., entropy method and weighted sum method) to rank the energy and CO2 productivity, and the recommendations will provide strategic guidance for China’s energy development.}
}
@article{PALANCACASTAN2021e06268,
title = {Towards an interdisciplinary framework about intelligence},
journal = {Heliyon},
volume = {7},
number = {2},
pages = {e06268},
year = {2021},
issn = {2405-8440},
doi = {https://doi.org/10.1016/j.heliyon.2021.e06268},
url = {https://www.sciencedirect.com/science/article/pii/S240584402100373X},
author = {Nicolas Palanca-Castan and Beatriz {Sánchez Tajadura} and Rodrigo Cofré},
keywords = {Theoretical framework, Artificial intelligence, Philosophy, Non-human intelligence},
abstract = {In recent years, advances in science, technology, and the way in which we view our world have led to an increasingly broad use of the term “intelligence”. As we learn more about biological systems, we find more and more examples of complex and precise adaptive behavior in animals and plants. Similarly, as we build more complex computational systems, we recognize the emergence of highly sophisticated structures capable of solving increasingly complex problems. These behaviors show characteristics in common with the sort of complex behaviors and learning capabilities we find in humans, and therefore it is common to see them referred to as “intelligent”. These analogies are problematic as the term intelligence is inextricably associated with human-like capabilities. While these issues have been discussed by leading researchers of AI and renowned psychologists and biologists highlighting the commonalities and differences between AI and biological intelligence, there have been few rigorous attempts to create an interdisciplinary approach to the modern problem of intelligence. This article proposes a comparative framework to discuss what we call “purposeful behavior”, a characteristic shared by systems capable of gathering and processing information from their surroundings and modifying their actions in order to fulfill a series of implicit or explicit goals. Our aim is twofold: on the one hand, the term purposeful behavior allows us to describe the behavior of these systems without using the term “intelligence”, avoiding the comparison with human capabilities. On the other hand, we hope that our framework encourages interdisciplinary discussion to help advance our understanding of the relationships among different systems and their capabilities.}
}
@article{SCHOLL2021101613,
title = {The Digital Government Reference Library (DGRL) and its potential formative impact on Digital Government Research (DGR)},
journal = {Government Information Quarterly},
volume = {38},
number = {4},
pages = {101613},
year = {2021},
issn = {0740-624X},
doi = {https://doi.org/10.1016/j.giq.2021.101613},
url = {https://www.sciencedirect.com/science/article/pii/S0740624X21000496},
author = {Hans J. Scholl},
keywords = {Digital Government Research, Bibliometric analysis, DGRL, Digital Government Reference Library, DGRL review},
abstract = {The domain of Digital Government Research (DGR) emerged at the end of the 1990s at the intersection of several traditional academic disciplines such as information studies, information systems research, public administration studies, political science, computer science, and business administration among others. While due to their own boundary definitions none of these traditional disciplines could claim “ownership” to the emerging domain, the disciplines were jointly indispensable to provide their various perspectives. As a consequence, the study domain has evolved as a multi-disciplinary endeavor increasingly fostering interdisciplinary relationships. An important contributor to forming the Digital Government research domain in this way also appears to be attributable to the impact of the Digital Government Reference Library (DGRL), which has regularly recorded, updated, and published bibliographical references to the vast majority of peer-reviewed DG research published in the English language for over a decade and a half. Besides its original curatorial purpose of findability and ease of bibliographic organization of DGR-focused research, over the years the DGRL has increasingly also been used for the purpose of bibliometric studies of some kind and some range. This review captures and analyzes the resulting increasingly formative role of the DGRL in DGR, and it documents its increased uses.}
}
@article{PATEL20201399,
title = {”A Novel MQTT Security framework In Generic IoT Model”},
journal = {Procedia Computer Science},
volume = {171},
pages = {1399-1408},
year = {2020},
note = {Third International Conference on Computing and Network Communications (CoCoNet'19)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2020.04.150},
url = {https://www.sciencedirect.com/science/article/pii/S1877050920311297},
author = {Chintan Patel and Nishant Doshi},
keywords = {Internet of Things(IoT), MQTT, Authentication, Smart Home, Smart Grid},
abstract = {Internet of Things(IoT) emerges as a revolutionary technology since the last double decade. Internet of things has changed many aspects of the human. IoT has changed leaving styles and health care with the help of smart health care technologies like wearable devices. IoT has changed the power distribution mechanism in the smart grid environment where surplus renewable energy generated at the house or energy farm can also be distributed using a multi-dimensional grid and smart meters. One of the most beneficial aspects of IoT has emerged in the field of agriculture, wherewith the help of moisture and fertility sensor, the farmer can identify the need for fertilizer, quality of pesticides, quality of land, land moisture, and so on. Farmers can control the water distribution from home using smart sprinkling as well as pesticides sprinkling using IoT based drones. IoT makes use of light-weight communication with the motive of the reduction of extra overhead generated in regular internet communication. For to simplify and make faster communication IoT uses protocols like MQTT (Message queuing telemetry transport), COAP (Constrained Application Protocol), XMPP (Extensible Messaging and Presence Protocol), REST (Representational State Transfer) and so on. The most famous protocol in the IoT communication at the application layer is the MQTT protocol, which makes use of TCP as an underlying transport layer protocol for the transmission. TCP based interface makes it more reliable protocol as well as a small header of MQTT protocol makes it suitable for IoT Eco-system, In this chapter, We have discussed the IoT, industry 4.0, impact of IoT on industry 4.0, MQTT Protocol, MQTT security aspects, Survey on various protocols used for to make MQTT Communication in a secured manner. We have surveyed many recent advances that happened for the MQTT Security and list out significant challenges in the IoT based industry faces when it comes to securing devices from physical as well as logical attacks. MQTT based device authentication, access control of resources, and security of communicated data over the insecure channel are some of the significant challenges that are discussed in depth. Overall this chapter will contribute in-depth security survey of IoT based industry 4.0.}
}
@article{XU2020123839,
title = {Cascades in coupled map lattices with heterogeneous distribution of perturbations},
journal = {Physica A: Statistical Mechanics and its Applications},
volume = {547},
pages = {123839},
year = {2020},
issn = {0378-4371},
doi = {https://doi.org/10.1016/j.physa.2019.123839},
url = {https://www.sciencedirect.com/science/article/pii/S037843711932134X},
author = {Kai-Jun Xu and Chen Hong and Xu-Hong Zhang and Qing-Hua Sun and Ning He and Ming-Ming Xiao},
keywords = {Cascades, Coupled map lattices, Network robustness, Perturbation distribution},
abstract = {As an important aspect of network robustness, cascading failure in complex networks has attracted a tremendous amount of interest in recent years. In the paper, we propose a novel cascading failure model of coupled map lattices by introducing heterogeneous distribution of perturbations, where a number of nodes are perturbed at the initial attack. The performance of four general attacking strategies are explored, which shows that high-betweenness strategy outperforms three other attacking strategies when heterogeneous perturbation mechanism is adopted. The results also indicate that increasing the coupling strength on direct neighbors can make the network more vulnerable and accelerate the propagation speed of cascades. And a more compact network structure will restrain the range and the propagation speed of cascading failures. We verify the influence of the heterogeneous perturbation principle on two real-world networks. In general, the effect on two real networks is in good accordance with that of BA scale-free networks, which means that the model can serve as a powerful tool to study realistic network robustness against cascades. Our work gains insight into the robustness and vulnerability of complex networked systems with respect to cascading failures.}
}
@article{WALTON2021120576,
title = {Rethinking of Marxist perspectives on big data, artificial intelligence (AI) and capitalist economic development},
journal = {Technological Forecasting and Social Change},
volume = {166},
pages = {120576},
year = {2021},
issn = {0040-1625},
doi = {https://doi.org/10.1016/j.techfore.2021.120576},
url = {https://www.sciencedirect.com/science/article/pii/S0040162521000081},
author = {Nigel Walton and Bhabani Shankar Nayak},
keywords = {Platforms, Big data, Artificial intelligence, Internet-of-Things, Disintermediation, Sharing economy, Bourgeoisie, Proletariat, Labour power},
abstract = {AI and big data are not ideologically neutral scientific knowledge that drives economic development and social change. AI is a tool of capitalism which transforms our societies within an environment of technological singularity that helps in the expansion of the capitalist model of economic development. Such a development process ensures the precarity of labour. This article highlights the limits of traditional Marxist conceptualisation of labour, value, property and production relations. It argues for the rethinking of Marxist perspectives on AI led economic development by focusing on conceptual new interpretation of bourgeois and proletariat in the information driven data-based society. This is a conceptual paper which critically outlines different debates and challenges around AI driven big data and its implications. It particularly focuses on the theoretical challenges faced by labour theory of value and its social and economic implications from a critical perspective. It also offers alternatives by analysing future trends and developments for the sustainable use of AI. It argues for developing policies on the use of AI and big data to protect labour, advance human development and enhance social welfare by reducing risks.}
}
@article{SU2021102765,
title = {A novel social distancing analysis in urban public space: A new online spatio-temporal trajectory approach},
journal = {Sustainable Cities and Society},
volume = {68},
pages = {102765},
year = {2021},
issn = {2210-6707},
doi = {https://doi.org/10.1016/j.scs.2021.102765},
url = {https://www.sciencedirect.com/science/article/pii/S221067072100055X},
author = {Jie Su and Xiaohai He and Linbo Qing and Tong Niu and Yongqiang Cheng and Yonghong Peng},
keywords = {Visual social distancing, Hierarchical data association, Multi-pedestrian tracking, Spatio-temporal trajectory, Discrete Fréchet distance, Crowd gathering},
abstract = {Social distancing in public spaces plays a crucial role in controlling or slowing down the spread of coronavirus during the COVID-19 pandemic. Visual Social Distancing (VSD) offers an opportunity for real-time measuring and analysing the physical distance between pedestrians using surveillance videos in public spaces. It potentially provides new evidence for implementing effective prevention measures of the pandemic. The existing VSD methods developed in the literature are primarily based on frame-by-frame pedestrian detection, addressing the VSD problem from a static and local perspective. In this paper, we propose a new online multi-pedestrian tracking approach for spatio-temporal trajectory and its application to multi-scale social distancing measuring and analysis. Firstly, an online multi-pedestrian tracking method is proposed to obtain the trajectories of pedestrians in public spaces, based on hierarchical data association. Then, a new VSD method based on spatio-temporal trajectories is proposed. The proposed method not only considers the Euclidean distance between tracking objects frame-by-frame but also takes into account the discrete Fréchet distance between trajectories, hence forms a comprehensive solution from both static and dynamic, local and holistic perspectives. We evaluated the performance of the proposed tracking method using the public dataset MOT16 benchmark. We also collected our own pedestrian dataset “SCU-VSD” and designed a multi-scale VSD analysis scheme for benchmarking the performance of the social distancing monitoring in the crowd. Experiments have demonstrated that the proposed method achieved outstanding performance on the analysis of social distancing.}
}
@article{BERTIZZOLO2020107436,
title = {Arena: A 64-antenna SDR-based ceiling grid testing platform for sub-6 GHz 5G-and-Beyond radio spectrum research},
journal = {Computer Networks},
volume = {181},
pages = {107436},
year = {2020},
issn = {1389-1286},
doi = {https://doi.org/10.1016/j.comnet.2020.107436},
url = {https://www.sciencedirect.com/science/article/pii/S1389128620311257},
author = {Lorenzo Bertizzolo and Leonardo Bonati and Emrecan Demirors and Amani Al-shawabka and Salvatore D’Oro and Francesco Restuccia and Tommaso Melodia},
keywords = {Software-defined radios, Wireless testbed, Spectrum research, Antenna grid, Internet of things},
abstract = {Arena is an open-access wireless testing platform based on a grid of antennas mounted on the ceiling of a large office-space environment. Each antenna is connected to programmable software-defined radios (SDR) enabling sub-6 GHz 5G-and-beyond spectrum research. With 12 computational servers, 24 SDRs synchronized at the symbol level, and a total of 64 antennas, Arena provides the computational power and the scale to foster new technology development in some of the most crowded spectrum bands. Arena is based on a three-tier design, where the servers and the SDRs are housed in a double rack in a dedicated room, while the antennas are hung off the ceiling of a 2240 square feet office space and cabled to the radios through 100 ft-long cables. This ensures a reconfigurable, scalable, and repeatable real-time experimental evaluation in a real wireless indoor environment. In this paper, we introduce the architecture, capabilities, and system design choices of Arena, and provides details of the software and hardware implementation of various testbed components. Furthermore, we describe key capabilities by providing examples of published work that employed Arena for applications as diverse as synchronized MIMO transmission schemes, multi-hop ad hoc networking, multi-cell 5G networks, AI-powered Radio-Frequency fingerprinting, secure wireless communications, and spectrum sensing for cognitive radio.}
}
@article{PASIKDUNCAN2019184,
title = {Plain Talk on Stochastic Adaptive Control and Its Broader Impact Some Reflections from the IFAC Technical Board Liaison to Education.},
journal = {IFAC-PapersOnLine},
volume = {52},
number = {9},
pages = {184-189},
year = {2019},
note = {12th IFAC Symposium on Advances in Control Education ACE 2019},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2019.08.192},
url = {https://www.sciencedirect.com/science/article/pii/S2405896319305294},
author = {Bozenna Pasik-Duncan},
keywords = {stochastic systems, adaptive control, STEM education},
abstract = {This paper focuses on innovative methods of teaching stochastic adaptive control with students who represent all science, technology, engineering and mathematics (STEM) disciplines. The Stochastic Adaptive Control course has been developed based on the author’s research area and it demonstrates the power, beauty and excitement of stochastic adaptive control as a field that spans STEM. Teaching is shown as a stochastic process that changes in time. The course has been taught at the mathematics department for the last 20 years by the team of mathematics and engineering faculty. The course is very popular, attracts junior and senior undergraduate and graduate students, and leads towards honors theses for undergraduates, and masters and doctoral theses for graduate students. Best practices leading to the success are presented. This paper provides also a sample of plain talk on stochastic adaptive control and broader impact best practices of control. The formation of IFAC Technical Committee (TC) Liaisons to Education was based on the concept of integrating research and education at all levels.}
}
@article{YOUNUS201962,
title = {A survey on software defined networking enabled smart buildings: Architecture, challenges and use cases},
journal = {Journal of Network and Computer Applications},
volume = {137},
pages = {62-77},
year = {2019},
issn = {1084-8045},
doi = {https://doi.org/10.1016/j.jnca.2019.04.002},
url = {https://www.sciencedirect.com/science/article/pii/S1084804519301146},
author = {Muhammad Usman Younus and Saif ul Islam and Ihsan Ali and Suleman Khan and Muhammad Khurram Khan},
keywords = {Smart building, SDN, Smart devices, Internet of Things},
abstract = {The rapid advancement of information and communication technologies (ICT) has drastically augmented the connectivity of actuators, computational elements and smart devices to the physical world. In this context, smart building (SB) serves as a significant domain to automatically handle and control the temperature, humidity, ventilation, safety, lighting, and other building's operations. Moreover, it plays a vital role in implementing the standards of enhanced living environments (ELE) and ambient assisted living (AAL). However, the extensive use of ICT and inflexible architecture of SB pose many challenges including heterogeneity of applications and Internet of things (IoT) devices, security, efficient networking architectures and protocols, energy efficiency, reliability and quality of service (QoS) provisioning. In this perspective, software defined networking (SDN) has gained great attention since it is being evolved as a programmable, and flexible networking framework. This paper is devoted to surveying the research work conducted on the integration of SDN to SB. Consequently, it provides a comprehensive review on SDN enabled SB, its architecture, taxonomy, communication protocols, and challenges for an immersive and interactive experience. It also presents a basic architecture of SDN over traditional networking. Moreover, SDN applications are also exploited to handle the issues of the wireless network. Furthermore, this paper demonstrates the use cases to explain the impact of SDN paradigm on the SBs.}
}
@article{FENG20211954,
title = {An IoT-based Hierarchical Control Method for Greenhouse Seedling Production},
journal = {Procedia Computer Science},
volume = {192},
pages = {1954-1963},
year = {2021},
note = {Knowledge-Based and Intelligent Information & Engineering Systems: Proceedings of the 25th International Conference KES2021},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2021.08.201},
url = {https://www.sciencedirect.com/science/article/pii/S1877050921016975},
author = {Jingyuan Feng and Xiangpei Hu},
keywords = {Seedling production, Internet of things (IoT), Greenhouse control, Hierarchical model},
abstract = {The development of agriculture modernization leads to a flourish in high-tech equipment agricultural production, IoT-based greenhouse seedling production is the most presentative one. However, for the great majority of the seedling production factories, the data stream collected from IoT sensors only be applied for display, failing to assist the resource utilization and order target completion. To fill this gap, this paper provides an IoT-based system implementation architecture and a hierarchical control method for greenhouse seedling production, which make use of history monitoring data, real-time monitoring data, and seedling growth model, aiming at achieving the target growth along the predefined timeline as well as saving the additional energy cost. The proposed method is easy to implement in practical production and offers a valuable reference to other precise agricultural projects.}
}
@article{QUAN20196515,
title = {Smart Design for Sustainable Neighborhood Development},
journal = {Energy Procedia},
volume = {158},
pages = {6515-6520},
year = {2019},
note = {Innovative Solutions for Energy Transitions},
issn = {1876-6102},
doi = {https://doi.org/10.1016/j.egypro.2019.01.108},
url = {https://www.sciencedirect.com/science/article/pii/S1876610219301183},
author = {Steven Jige Quan},
keywords = {Smart Design, Sustainable Neighborhood Development, Design Decision Making, Multi-objective Optimization, Genetic Algorithms, Pareto optimal},
abstract = {This study proposes the Smart Design method to support the design decision making in the sustainable neighborhood development with multiple objectives. Instead of the “creative design” approach in the scenario making in traditional PSS and recent Geodesign frameworks, the Smart Design method applies the optimization algorithms to search for optimal design solutions in the design space. It integrates the design thinking, computational performance modeling and optimization techniques to efficiently and effectively approximate optimal designs. This method is applied to a hypothetical residential neighborhood design case study with three sustainability objectives: to maximize FAR, to minimize building energy use, and to minimize outdoor human discomfort. Based on the form parameterization, the Nondominated Sorting Genetic Algorithm II (NSGA-II) algorithm is utilized to guide the evolution of the neighborhood design throughout 80 generations, with neighborhood performance modeling tools. The Smart Design method is able to identify 38 representative design solutions as Pareto optimal which are equally optimal. Those solutions set a basis for discussions and negotiations among stake holders to make design decisions with the three objectives. Further research will be focused on addressing the challenges such as recursive objective definitions, parametrization of complex forms, quantification of performances and optimization uncertainties, from simple cases to more realistic and complex designs for sustainable neighborhood development.}
}
@article{KUMAR20201487,
title = {Satellite-based solar energy potential analysis for southern states of India},
journal = {Energy Reports},
volume = {6},
pages = {1487-1500},
year = {2020},
issn = {2352-4847},
doi = {https://doi.org/10.1016/j.egyr.2020.05.028},
url = {https://www.sciencedirect.com/science/article/pii/S2352484717303062},
author = {Deepak Kumar},
keywords = {Clean energy systems, Direct normal irradiance (DNI) & global horizontal irradiance (GHI), Solar insolation, Solar energy potential analysis},
abstract = {Numerous efforts have been taken to exhibit scientific advancement in solar energy analysis. The current study attempts to demonstrate an approach for the solar resource variability analysis at a spatial scale in the southern states of India. This work utilized the satellite-derived modelled solar insolation datasets due to the global unavailability of in-situ meteorological data sets (especially solar radiation data). The visualization of solar insolation components including direct normal irradiance (DNI) and global horizontal irradiance (GHI) provided an opportunity to understand the energy configurations and it’s potential. An average DNI variation of 5.21 kWh/m2 and GHI variation of 5.72 kWh/m2 was observed. The ancillary analysis presented a detailed map for southern states of India at a grid resolution of 100 km x 100 km. Thereafter DNI and GHI distribution map for selected random points were estimated. The precise summary statistics stated that maximum and minimum values of DNI range from 3.72 kWh/m2 to 5.59 kWh/m2 with an average value of 5.18 kWh/m2 and likewise maximum and minimum values of GHI ranges from 4.91 kWh/m2 to 5.99 kWh/m2 with an average value of 5.71 kWh/m2. It was observed that the states of Karnataka and Tamil Nadu have a better prospect for further applications. The obtained results provided datasets for further analysis to comprehend the spatial distribution at a regional or national level. These will be very much useful for better energy planning for sound decision making.}
}
@article{GUPTA2021101355,
title = {Blockchain and 5G integrated softwarized UAV network management: Architecture, solutions, and challenges},
journal = {Physical Communication},
volume = {47},
pages = {101355},
year = {2021},
issn = {1874-4907},
doi = {https://doi.org/10.1016/j.phycom.2021.101355},
url = {https://www.sciencedirect.com/science/article/pii/S1874490721000926},
author = {Rajesh Gupta and Sudeep Tanwar and Neeraj Kumar},
keywords = {Blockchain, Security, 5G, Unmanned aerial vehicle, SDN, NFV, Softwarization},
abstract = {Network management for unmanned aerial vehicles (UAVs) is challenging, keeping in view the high mobility of the vehicles. Hence, for smooth execution of various operations such as rescue, surveillance, and crowdsensing in a UAV environment, softwarization of UAV networks becomes essential, which separates control functions from hardware, i.e., data from the control plane. Using softwarization, various complex operations in the UAV environment can be executed with an increase in UAVs. However, with an increase in the complexity of UAV network management, secure communication among UAVs becomes a tedious task as most of the communication among UAVs takes place using an open network, i.e., the Internet. Software-defined networking (SDN) and network function virtualization (NFV) are the key softwarization enabling techniques in fifth-generation (5G) networks, which are used to manage secure network services with reduced capital and operating expenditures. However, different softwarization layers may suffer from controller hijacking, user authentication, access control, and resource consumption attack. Many solutions reported in the literature for this problem are centralized controlled that suffers from single-point of failure and also prone to various security attacks. Motivated from this, in this paper, a systematic and comprehensive survey is presented, which is based on blockchain (BC)-envisioned secure and trusted softwarized UAV network management. We also propose a BC-based softwarized UAV architecture to make the communication network secure and easily manageable. It can offer flexible and dynamic decision capabilities for network management services even in open 5G-enabled UAV networks. Finally, we analyzed the research challenges posed and future challenges in this area.}
}
@article{LI201932,
title = {Touch switch sensor for cognitive body sensor networks},
journal = {Computer Communications},
volume = {146},
pages = {32-38},
year = {2019},
issn = {0140-3664},
doi = {https://doi.org/10.1016/j.comcom.2019.07.019},
url = {https://www.sciencedirect.com/science/article/pii/S0140366419305675},
author = {Yujie Li and Huimin Lu and Hyoungseop Kim and Seiichi Serikawa},
keywords = {Touch switch sensor, Body sensor network, Data fusion},
abstract = {With the global popularity of Internet of Things (IoT) technology, increasingly numbers of digital mobile products have been developed, and they have increased the productivity of people’s daily lives. These electronic products are used in all aspects of life, such as medical care, office life, home services, and sports. However, most of these products are designed for healthy people with high literacy rates. For disabled people, these products cannot be widely used. In this paper, new, differently shaped touch sensors are proposed for body sensor network-based devices. This touch sensor can be formed into any shape because of the use of conductive fabric adhesive tape as a switch. That property is why the sensor can change positions in the body sensor network in which the human body is used as a trigger to safely activate the touch switch. The number of switch sensors can easily be increased or decreased without changing the wiring of the central controller. The number of sensors in a switch sensor system is greater than that in other touch switch systems, and the accuracy is higher.}
}
@article{JESSE2018486,
title = {Organizational Evolution - How Digital Disruption Enforces Organizational Agility},
journal = {IFAC-PapersOnLine},
volume = {51},
number = {30},
pages = {486-491},
year = {2018},
note = {18th IFAC Conference on Technology, Culture and International Stability TECIS 2018},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2018.11.310},
url = {https://www.sciencedirect.com/science/article/pii/S2405896318329835},
author = {Norbert Jesse},
keywords = {Disruption, Data Science, Organizational Agility, Chief Data Officer},
abstract = {The success of almost any business depends on the promotion of digital excellence. Disruptive technologies like Hadoop, IoT, Blockchain or DevOps pose completely new challenges for business development. While there is no doubt about the need for keeping pace with the technical progress it is blurry how much this affects leadership and organizational agility. At least in Germany, many analysts record a gap between the engineering innovativeness and an inadequate digital leadership. It is evident, that digitization leads to new occupational profiles and a specific stress on the organizational fabric. Many companies experiment with start-up culture, entrepreneurial responsibility and more flexible team patterns, but a consistent approach for manager is still missing. In this preliminary discussion we address three dimensions to increase a company’s agility in times of digital Darwinism: structural flexibility, software-driven occupational profiles and requirements for leadership.}
}
@article{TEKOUABOU2021164,
title = {Efficient forwarding strategy in HDRP protocol based Internet of Things},
journal = {Computer Communications},
volume = {170},
pages = {164-176},
year = {2021},
issn = {0140-3664},
doi = {https://doi.org/10.1016/j.comcom.2021.02.003},
url = {https://www.sciencedirect.com/science/article/pii/S0140366421000621},
author = {Stephane Cedric Koumetio Tekouabou and El Arbi Abdellaoui Alaoui and Antoine Gallais},
keywords = {Delay Tolerant Network ( DTN), Internet of Things (IoT), Forwarding strategy},
abstract = {The Internet of Things (IoT) includes a variety of heterogeneous wireless network technologies such as Delay Tolerant Networks (DTN) and all kinds of smart devices connected over a wireless network. The strong size and cost constraints of DTN nodes lead to corresponding constraints on resources such as energy, memory, communication speed and bandwidth, which in turn limits the contact between DTN nodes. DTN has emerged as a promising new network paradigm that aims to cope with the increasing number of heterogeneous networks and the need for efficient and robust data dissemination to be more stable. But one of the hindering bottlenecks the full applicability of such a DTN-based approach to the IoT, is that forwarding data in an environment could lose when the connection between nodes is intermittent. In this paper, we propose an effective bundle forwarding strategy for the IoT environment in which we control the number of bundle replications to balance energy consumption on the network. Simulation results demonstrate that the proposed solution performs better than other methods in terms of delivery delay and delivery rate (roughly 18% improvement).}
}
@article{MALIK2021102,
title = {Arduino Based Automatic Solar Panel Dust Disposition Estimation and Cloud Based Reporting},
journal = {Procedia Computer Science},
volume = {194},
pages = {102-113},
year = {2021},
note = {18th International Learning & Technology Conference 2021},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2021.10.063},
url = {https://www.sciencedirect.com/science/article/pii/S1877050921021049},
author = {Hebatullah Malik and Maha Alsabban and Saeed Mian Qaisar},
keywords = {Photovoltaic, Embedded Processing, Automatic Dust Disposition Estimation, Decision Support, Arduino, Cloud},
abstract = {Recent technological encroachments have evolved the usage of Internet of Things (IoT) and it is becoming an elementary part of our life. Regarding the photovoltaic (PV) renewable energy-based systems there is a lot of potential to integrate the IoT based solutions in order to enhance the generation capabilities and to diminish the energy losses in the electricity production. Energy losses can occur due to several causes in the case of PVs. This work deals with the photovoltaic energy losses caused by the dust deposition. The idea is to intelligently employ the IoT framework in this regard. The system is based on a modular design approach. Each module digitizes the status of a concerned PV panel by using an embedded front-end controller. The readings are conveyed to a specifically developed automatic maintenance decision algorithm. The intended PV module data is logged to cloud in a real- time fashion for post analysis. In parallel, the designed software analyzes the instantaneous open-voltage value of the PV panel and make real time decisions if a maintenance notification is required or not. In this fashion, they can efficiently act for the PV maintenance in order to get the most out of the PVs over the system lifecycle. The constructed prototype successfully achieved its goals of automatically detecting unexpected voltage drops from a PV panel due to dust disposition and reported it to the concerned parties.}
}
@article{LEYLIABADI2021176,
title = {Online common change-point detection in a set of nonstationary categorical time series},
journal = {Neurocomputing},
volume = {439},
pages = {176-196},
year = {2021},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2021.01.066},
url = {https://www.sciencedirect.com/science/article/pii/S0925231221001338},
author = {Milad Leyli-Abadi and Allou Samé and Latifa Oukhellou and Nicolas Cheifetz and Pierre Mandel and Cédric Féliers and Véronique Heim},
keywords = {Change detection, Nonstationary categorical time series, Nonhomogeneous Markov models, Water consumption behavior},
abstract = {Categorical sequences are widely used in various domains to describe the evolutionary state of the process under study. This article addresses the problem of behavioral change detection for multiple categorical time series. Relying on the sequential likelihood ratio test, an online change detection method is proposed based on the joint modeling of all the categorical sequences. To model the joint probability density, a nonhomogeneous Markov model is used. It allows modeling the transition dynamics over time and considering their dependence on some exogenous factors that may influence the behavior changes. An adaptive threshold is learned using Monte Carlo simulations to detect different changes and reduce false alarms. The performance of the proposed method is evaluated using two real-world and four synthetic datasets. It is compared with two state-of-the-art change detection methods, namely logistic regression and homogeneous Markov model. The experimentation using synthetic datasets highlights the proposed method’s effectiveness in terms of both the detection precision and the detection delay. The real-world data are issued from a water network and school-to-work transition. The analysis of the model estimated parameters allows us to characterize the detected changes in a real-world context.}
}
@article{DAROSARIGHI2018176,
title = {A lightweight plug-and-play elasticity service for self-organizing resource provisioning on parallel applications},
journal = {Future Generation Computer Systems},
volume = {78},
pages = {176-190},
year = {2018},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2017.02.023},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X17302339},
author = {Rodrigo {da Rosa Righi} and Vinicius Facco Rodrigues and Gustavo Rostirolla and Cristiano {André da Costa} and Eduardo Roloff and Philippe Olivier Alexandre Navaux},
keywords = {Cloud elasticity service, High-performance computing, Live Thresholding, Resource management, Self-organizing},
abstract = {Today cloud elasticity can bring benefits to parallel applications, besides the traditional targets including Web and critical-business demands. This consists in adapting the number of resources and processes at runtime, so users do not need to worry about the best choice for them beforehand. To accomplish this, the most common approaches use threshold-based reactive elasticity or time-consuming proactive elasticity. However, both present at least one problem related to the need of a previous user experience, lack on handling load peaks, completion of parameters or design for a specific infrastructure and workload setting. In this context, we developed a hybrid elasticity service for master–slave parallel applications named Helpar. The proposal presents a closed control loop elasticity architecture that adapts at runtime the values of lower and upper thresholds. The main scientific contribution is the proposition of the Live Thresholding (LT) technique for controlling elasticity. LT is based on the TCP congestion algorithm and automatically manages the value of the elasticity bounds to enhance better reactiveness on resource provisioning. The idea is to provide a lightweight plug-and-play service at the PaaS (Platform-as-a-Service) level of a cloud, in which users are completely unaware of the elasticity feature, only needing to compile their applications with Helpar prototype. For evaluation, we used a numerical integration application and OpenNebula to compare the Helpar execution against two scenarios: a set of static thresholds and a non-elastic application. The results present the lightweight feature of Helpar, besides highlighting its performance competitiveness in terms of application time (performance) and cost (performance × energy) metrics.}
}
@article{DING2021100629,
title = {Analysis of ground deformation induced by shield tunneling considering the effects of muck discharge and grouting},
journal = {Transportation Geotechnics},
volume = {30},
pages = {100629},
year = {2021},
issn = {2214-3912},
doi = {https://doi.org/10.1016/j.trgeo.2021.100629},
url = {https://www.sciencedirect.com/science/article/pii/S2214391221001197},
author = {Zhi Ding and Shu-Yu He and Wan-Huan Zhou and Tao Xu and Shao-Heng He and Xiao Zhang},
keywords = {Shield tunneling, Ground deformation, Construction parameters, Volume loss, Tail void grouting},
abstract = {Many methods have been proposed to predict ground deformation caused by shield tunneling, but few of them provide real-time prediction because the required input parameters are difficult to determine. In this paper, a new time-dependent model of ground movement with three accessible parameters is proposed. Those construction parameters are muck discharge rate, grouting rate, and grout loss factor. The volume losses due to different construction parameters are first estimated. Then the ground deformation induced by the volume losses is calculated. The calculated result shows a good agreement with the measurement. It appears that the ground deformation is significantly sensitive to the muck discharge rate and less sensitive to the grouting rate and grout loss factor. An equilibrium relationship was found between the grouting rate and the grout loss factor, which could minimize the ground deformation at the shield tail.}
}
@article{KIRAN2015974,
title = {Modelling Cities as a Collection of TeraSystems – Computational Challenges in Multi-Agent Approach},
journal = {Procedia Computer Science},
volume = {52},
pages = {974-979},
year = {2015},
note = {The 6th International Conference on Ambient Systems, Networks and Technologies (ANT-2015), the 5th International Conference on Sustainable Energy Information Technology (SEIT-2015)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2015.05.175},
url = {https://www.sciencedirect.com/science/article/pii/S1877050915009758},
author = {Mariam Kiran},
keywords = {Interdisciplinary resarch, socio-economic, Cloud computing, big data, agent-based models, city modelling},
abstract = {Agent-based modeling techniques are ideal for modeling massive complex systems such as insect colonies or biological cellular systems and even cities. However these models themselves are extremely complex to code, test, simulate and analyze. This paper discusses the challenges in using agent-based models to model complete cities as a complex system. In this paper we argue that Cities are actually a collection of various complex models which are themselves massive multiple systems, each of millions of agents, working together to form one system consisting of an order of a billion agents of different types – such as people, communities and technologies interacting together. Because of the agent numbers and complexity challenges, the present day hardware architectures are unable to cope with the simulations and processing of these models. To accommodate these issues, this paper proposes a Tera (to denote the order of millions)-modeling framework, which utilizes current technologies of Cloud computing and Big data processing, for modeling a city, by allowing infinite resources and complex interactions. This paper also lays the case for bringing together research communities for interdisciplinary research to build a complete reliable model of a city.}
}
@article{SHI2022112770,
title = {A reliable and adaptive spatiotemporal data fusion method for blending multi-spatiotemporal-resolution satellite images},
journal = {Remote Sensing of Environment},
volume = {268},
pages = {112770},
year = {2022},
issn = {0034-4257},
doi = {https://doi.org/10.1016/j.rse.2021.112770},
url = {https://www.sciencedirect.com/science/article/pii/S0034425721004909},
author = {Wenzhong Shi and Dizhou Guo and Hua Zhang},
keywords = {Spatiotemporal fusion, Reliability index, Temporal change, Local unmixing, Satellite images},
abstract = {Spatiotemporal image fusion is a potential way to resolve the constraint between the spatial and temporal resolutions of satellite images and has been developed rapidly in recent years. However, two key challenges related to fusion accuracy remain: a) reducing the uncertainty of image fusion caused by sensor differences and b) addressing strong temporal changes. To solve the above two issues, this paper presents the newly proposed Reliable and Adaptive Spatiotemporal Data Fusion (RASDF) method. In RASDF, the effects of four kinds of sensor differences on fusion are analyzed systematically. A reliability index is therefore proposed to describe the spatial distribution of the reliability in input data for image fusion. An optimization strategy based on the spatial distribution of the reliability quantified by the index is developed to improve the robustness of the fusion. In addition, an adaptive global unmixing model and an adaptive local unmixing model are constructed and utilized collaboratively to enhance the ability to retrieve strong temporal changes. The performance and robustness of RASDF were compared with six representative fusion methods for both real and simulated datasets covering both homogeneous and heterogeneous sites. Experimental results indicated that RASDF achieves a better performance and provides a more reliable image fusion solution in terms of reducing the impact of sensor differences on image fusion and retrieving strong temporal changes.}
}
@article{ALIC2019243,
title = {BIGSEA: A Big Data analytics platform for public transportation information},
journal = {Future Generation Computer Systems},
volume = {96},
pages = {243-269},
year = {2019},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2019.02.011},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X18304448},
author = {Andy S. Alic and Jussara Almeida and Giovanni Aloisio and Nazareno Andrade and Nuno Antunes and Danilo Ardagna and Rosa M. Badia and Tania Basso and Ignacio Blanquer and Tarciso Braz and Andrey Brito and Donatello Elia and Sandro Fiore and Dorgival Guedes and Marco Lattuada and Daniele Lezzi and Matheus Maciel and Wagner Meira and Demetrio Mestre and Regina Moraes and Fabio Morais and Carlos Eduardo Pires and Nádia P. Kozievitch and Walter dos Santos and Paulo Silva and Marco Vieira},
abstract = {Analysis of public transportation data in large cities is a challenging problem. Managing data ingestion, data storage, data quality enhancement, modelling and analysis requires intensive computing and a non-trivial amount of resources. In EUBra-BIGSEA (Europe–Brazil Collaboration of Big Data Scientific Research Through Cloud-Centric Applications) we address such problems in a comprehensive and integrated way. EUBra-BIGSEA provides a platform for building up data analytic workflows on top of elastic cloud services without requiring skills related to either programming or cloud services. The approach combines cloud orchestration, Quality of Service and automatic parallelisation on a platform that includes a toolbox for implementing privacy guarantees and data quality enhancement as well as advanced services for sentiment analysis, traffic jam estimation and trip recommendation based on estimated crowdedness. All developments are available under Open Source licenses (http://github.org/eubr-bigsea, https://hub.docker.com/u/eubrabigsea/).}
}
@article{HORANSKA2020415,
title = {Generalized decomposition integral},
journal = {Information Sciences},
volume = {538},
pages = {415-427},
year = {2020},
issn = {0020-0255},
doi = {https://doi.org/10.1016/j.ins.2020.05.081},
url = {https://www.sciencedirect.com/science/article/pii/S0020025520305089},
author = {L'ubomíra Horanská and Humberto Bustince and Javier Fernandez and Radko Mesiar},
keywords = {Decomposition integral, Capacity, Choquet integral, Shilkret integral},
abstract = {In this paper we propose two different generalizations of the decomposition integral introduced by Even and Lehrer. We modify the product operator merging a given capacity and the decomposition coefficients by some more general functions F and G and compare properties of the obtained functionals with properties of the original decomposition integral. Generalized decomposition integrals corresponding to the particular decomposition systems, being generalizations of Shilkret, Choquet and concave integrals, are studied and exemplified.}
}
@article{BARBAGONZALEZ2019543,
title = {BIGOWL: Knowledge centered Big Data analytics},
journal = {Expert Systems with Applications},
volume = {115},
pages = {543-556},
year = {2019},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2018.08.026},
url = {https://www.sciencedirect.com/science/article/pii/S0957417418305347},
author = {Cristóbal Barba-González and José García-Nieto and María del Mar Roldán-García and Ismael Navas-Delgado and Antonio J. Nebro and José F. Aldana-Montes},
keywords = {Ontology, Big Data analytics, Semantics, Knowledge extraction},
abstract = {Knowledge extraction and incorporation is currently considered to be beneficial for efficient Big Data analytics. Knowledge can take part in workflow design, constraint definition, parameter selection and configuration, human interactive and decision-making strategies. This paper proposes BIGOWL, an ontology to support knowledge management in Big Data analytics. BIGOWL is designed to cover a wide vocabulary of terms concerning Big Data analytics workflows, including their components and how they are connected, from data sources to the analytics visualization. It also takes into consideration aspects such as parameters, restrictions and formats. This ontology defines not only the taxonomic relationships between the different concepts, but also instances representing specific individuals to guide the users in the design of Big Data analytics workflows. For testing purposes, two case studies are developed, which consists in: first, real-world streaming processing with Spark of traffic Open Data, for route optimization in urban environment of New York city; and second, data mining classification of an academic dataset on local/cloud platforms. The analytics workflows resulting from the BIGOWL semantic model are validated and successfully evaluated.}
}
@article{SINGH2021100463,
title = {Container-based load balancing for energy efficiency in software-defined edge computing environment},
journal = {Sustainable Computing: Informatics and Systems},
volume = {30},
pages = {100463},
year = {2021},
issn = {2210-5379},
doi = {https://doi.org/10.1016/j.suscom.2020.100463},
url = {https://www.sciencedirect.com/science/article/pii/S2210537920301876},
author = {Amritpal Singh and Gagangeet Singh Aujla and Rasmeet Singh Bali},
keywords = {Container-as-a-service, Edge computing, Stackelberg game, Software defined networking, Resource optimization},
abstract = {The workload generated by the Internet of Things (IoT)-based infrastructure is often handled by the cloud data centers (DCs). However, in recent time, an exponential increase in the deployment of the IoT-based infrastructure has escalated the workload on the DCs. So, these DCs are not fully capable to meet the strict demand of IoT devices in regard to the lower latency as well as high data rate while provisioning IoT workloads. Therefore, to reinforce the latency-sensitive workloads, an intersection layer known as edge computing has successfully balanced the entire service provisioning landscape. In this IoT-edge-cloud ecosystem, large number of interactions and data transmissions among different layer can increase the load on underlying network infrastructure. So, software-defined edge computing has emerged as a viable solution to resolve these latency-sensitive workload issues. Additionally, energy consumption has been witnessed as a major challenge in resource-constrained edge systems. The existing solutions are not fully compatible in Software-defined Edge ecosystem for handling IoT workloads with an optimal trade-off between energy-efficiency and latency. Hence, this article proposes a lightweight and energy-efficient container-as-a-service (CaaS) approach based on the software-define edge computing to provision the workloads generated from the latency-sensitive IoT applications. A Stackelberg game is formulated for a two-period resource allocation between end-user/IoT devices and Edge devices considering the service level agreement. Furthermore, an energy-efficient ensemble for container allocation, consolidation and migration is also designed for load balancing in software-defined edge computing environment. The proposed approach is validated through a simulated environment with respect to CPU serve time, network serve time, overall delay, lastly energy consumption. The results obtained show the superiority of the proposed in comparison to the existing variants.}
}
@article{BRENNER2021128128,
title = {The perceived relationship between digitalization and ecological, economic, and social sustainability},
journal = {Journal of Cleaner Production},
volume = {315},
pages = {128128},
year = {2021},
issn = {0959-6526},
doi = {https://doi.org/10.1016/j.jclepro.2021.128128},
url = {https://www.sciencedirect.com/science/article/pii/S0959652621023465},
author = {Barbara Brenner and Barbara Hartl},
keywords = {Sustainability, Digitalization, Social representations theory, Framing theory, Multi-method empirical study, Triple bottom line},
abstract = {Sustainability, in terms of ecological, economic, and social sustainable development, and the advancing digitalization represent some of the most substantial societal challenges today. However, little is known about how different actors and decision-makers perceive the relationship of those two challenges. In our paper, by building upon framing theory and social representations theory, we address that gap by investigating how different actors perceive the interrelationship between digitalization and ecological, economic, and social sustainability. Such research is particularly important because understandings of digitalization and sustainability determine how different actors, including managers and policymakers, act in response to those imperatives. Following a multi-method approach, we combined media analysis with two experimental studies examining how various actors frame the relationship between digitalization and sustainability in media discourses and which dimension of sustainability—ecological, economic, or social—dominates. Building upon these results, the studies assess whether the extent of digitalization affects the perception of those three dimensions. Among our findings, perceptions of ecological and economic sustainability but not social sustainability seem to be affected by the extent of digitalization. For future research, those findings indicate the need for a more nuanced view on sustainability that accounts for its different dimensions, especially the social dimension and its relationship with digitalization. Beyond that, because the perceived link between digitalization and ecological, economic, and social sustainability guides how various actors, including managers and policymakers, respond to those imperatives, our work also has substantial practical implications as well.}
}
@article{FRIASPAREDES2017533,
title = {Assessing energy forecasting inaccuracy by simultaneously considering temporal and absolute errors},
journal = {Energy Conversion and Management},
volume = {142},
pages = {533-546},
year = {2017},
issn = {0196-8904},
doi = {https://doi.org/10.1016/j.enconman.2017.03.056},
url = {https://www.sciencedirect.com/science/article/pii/S0196890417302674},
author = {Laura Frías-Paredes and Fermín Mallor and Martín Gastón-Romeo and Teresa León},
keywords = {Energy forecasting accuracy, Temporal misalignment, Renewable energy, Temporal distortion index, Bidimensional error},
abstract = {Recent years have seen a growing trend in wind and solar energy generation globally and it is expected that an important percentage of total energy production comes from these energy sources. However, they present inherent variability that implies fluctuations in energy generation that are difficult to forecast. Thus, forecasting errors have a considerable role in the impacts and costs of renewable energy integration, management, and commercialization. This study presents an important advance in the task of analyzing prediction models, in particular, in the timing component of prediction error, which improves previous pioneering results. A new method to match time series is defined in order to assess energy forecasting accuracy. This method relies on a new family of step patterns, an essential component of the algorithm to evaluate the temporal distortion index (TDI). This family minimizes the mean absolute error (MAE) of the transformation with respect to the reference series (the real energy series) and also allows detailed control of the temporal distortion entailed in the prediction series. The simultaneous consideration of temporal and absolute errors allows the use of Pareto frontiers as characteristic error curves. Real examples of wind energy forecasts are used to illustrate the results.}
}
@article{THUNGTONG2021e08329,
title = {A web-based control system for traditional street lighting that uses high-pressure sodium lamps},
journal = {Heliyon},
volume = {7},
number = {11},
pages = {e08329},
year = {2021},
issn = {2405-8440},
doi = {https://doi.org/10.1016/j.heliyon.2021.e08329},
url = {https://www.sciencedirect.com/science/article/pii/S2405844021024324},
author = {Anurak Thungtong and Chanchai Chaichan and Korakot Suwannarat},
keywords = {Street lighting control, High pressure sodium lamp, Internet of things, NB-IoT, Microcontroller, Web application},
abstract = {Street lighting is a critical component of any city's infrastructure. On the other hand, the street lighting system consumes a significant amount of electricity. As a result, many technologies and studies are being developed to reduce the energy cost of street lighting. While the majority of the proposed ideas for reducing the energy cost of the street lighting system are based on light emitting diode lamps, they are not suitable for high-pressure sodium lamps, which continue to dominate in developing countries. Moreover, the high initial cost, difficulty of installation and maintenance, reliability, and service lifetime are all significant barriers to the practical implementation of these ideas. This paper presents a web-based control system for traditional street lighting systems that still employs high-pressure sodium lamps. The proposed idea converts existing modules of the conventional controller, which are photo switches, into IoT devices. The web application on the server then manages and controls the devices. The web application allows users to create a schedule for turning off the lights during the late-night hours to save energy. The system's advantages include its low cost, ease of installation, and maintenance. The proposed system is useful for roads or areas with low traffic density at late night. This system has been validated at Walailak University, Thailand.}
}
@article{SANEI2021105154,
title = {A link adaptation scheme for reliable downlink communications in narrowband IoT},
journal = {Microelectronics Journal},
volume = {114},
pages = {105154},
year = {2021},
issn = {0026-2692},
doi = {https://doi.org/10.1016/j.mejo.2021.105154},
url = {https://www.sciencedirect.com/science/article/pii/S0026269221001658},
author = {Farshid Sanei and Hamed Farbeh},
keywords = {Low-power WAN, Link adaptation, Narrowband internet of things, Repetition, Signaling},
abstract = {Narrowband Internet of Things (NB-IoT) is a new technology introduced by 3rd generation partnership project (3GPP) to meet low-power wide area networks (LPWAN) requirements. Accessing nodes with poor channel condition is of decisive importance in such networks. Repetition is a promising approach to enhance the network coverage in radio technologies suitable for machine-type communications including NB-IoT. This approach implies repeating the same transmission data or control signals back-to-back without getting feedback from the end point. Introducing this new feature raises the need for link adaptation in mainly two dimensions: 1) Selection of modulation and coding scheme (MCS) level and 2) Repetition number determination to guarantee the block error rate of less than 10%. In this paper, we propose a link adaptation scheme to minimize the transmission of control information for large packets that are segmented before sending. This is done by a new online SNR estimation scheme and adaptively sending downlink control information (DCI) only for necessary segments. According to the simulation results, our proposed scheme outperforms the conventional method by reducing the resource blocks consumption and active time by an average of 35% and 30%, respectively.}
}
@article{TCHOFFA2021103466,
title = {Alignment of the product lifecycle management federated interoperability framework with internet of things and virtual manufacturing},
journal = {Computers in Industry},
volume = {130},
pages = {103466},
year = {2021},
issn = {0166-3615},
doi = {https://doi.org/10.1016/j.compind.2021.103466},
url = {https://www.sciencedirect.com/science/article/pii/S0166361521000737},
author = {D. Tchoffa and N. Figay and P. Ghodous and H. Panetto and A. {El Mhamedi}},
keywords = {Internet of things, Product life cycle management, Virtual enterprises, Virtual manufacturing},
abstract = {The emergence of the Internet of Things (IoT), coupled with other capabilities such as Cloud Computing and many others, creates opportunities for the development of Cyber-Physical Systems (CPS) at the scale of a digital business ecosystem. It will impact the way engineers work when designing, developing, deploying, operating, or maintaining complex systems-of-systems, with increasing needs concerning security, agility, and interoperability. The Federated Interoperability Framework (FIF) has been developed for Aeronautic Space and Defence over the last years to prepare and build continuous operational Product Lifecycle Management (PLM) interoperability. This paper aims at illustrating, defining, and demonstrating the required evolutionary nature of the FIF from its genesis, by describing past, last, and future evolutions, in particular for the PLM Standards testbed, Virtual manufacturing and CPS. Then Evolvability is defined and discussed, and the provided presentation of the FIF evolutions used to demonstrate its evolutionary nature, making the FIF contributing to the State of the Art and the State of the Practice.}
}
@article{ALMAGRABI2021,
title = {A classification-based privacy-preserving decision-making for secure data sharing in Internet of Things assisted applications},
journal = {Digital Communications and Networks},
year = {2021},
issn = {2352-8648},
doi = {https://doi.org/10.1016/j.dcan.2021.09.003},
url = {https://www.sciencedirect.com/science/article/pii/S2352864821000638},
author = {Alaa Omran Almagrabi and A.K. Bashir},
keywords = {Classification learning, Data mining, IoT, Privacy-preserving, Resource replication},
abstract = {The introduction of the Internet of Things (IoT) paradigm serves as pervasive resource access and sharing platform for different real-time applications. Decentralized resource availability, access, and allocation provide a better quality of user experience regardless of the application type and scenario. However, privacy remains an open issue in this ubiquitous sharing platform due to massive and replicated data availability. In this paper, privacy-preserving decision-making for the data-sharing scheme is introduced. This scheme is responsible for improving the security in data sharing without the impact of replicated resources over the communicating users. In this scheme, classification learning is used for identifying replicas and accessing granted resources independently. Based on the trust score of the available resources, this classification is recurrently performed to improve the reliability of information sharing. The user-level decisions for information sharing and access are made using the classification of the resources at the time of availability. This proposed scheme is verified using the metrics access delay, success ratio, computation complexity, and sharing loss.}
}
@article{WANG2021233,
title = {Blockchain enabled verification for cellular-connected unmanned aircraft system networking},
journal = {Future Generation Computer Systems},
volume = {123},
pages = {233-244},
year = {2021},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2021.05.002},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X21001461},
author = {Jian Wang and Yongxin Liu and Shuteng Niu and Houbing Song and Weipeng Jing and Jiawei Yuan},
keywords = {Blockchain, Access authentication, UAS, Cellular networking, Verification},
abstract = {The emerging 5G New Radio (5G NR) stimulates the evolution of applications in many fields. Compared with 4G, 5G NR can provide much more reliable, efficient, flexible networking access services to mobile devices which can escalate the quality of services (QoS) for the users remarkably. The advantages of affordability, easy assembling and quick driving, allow the deployment of Unmanned Aircraft System (UAS) on a large scale, and provide the elevation for the industrial and the civilian implementations ubiquitously. With the enhancement of cellular networking, the control range of UAS can extend significantly which allows the controller finish their mission far away from workplace and prevents the threats derived from the hazards in the uncertain environment. The Base Stations (BSs) are vital to the cellular-connected UAS because the BSs can provide the Internet access for the UAS and the remote controllers that sends instructions to the UAS and backhauls the packets to the controllers precisely and timely. However, the malicious BSs are great threats to the cellular-connected UAS. Specifically, the malicious BSs are scattered in the legislative BSs and cannot provide formal networking access services to the UAS. What is worse, the attackers can leverage the malicious BSs to disclose the controllers’ privacy and set threats to the public property. In this paper, we propose a novel blockchain-based approach to mitigate the threats from accessing the malicious BSs. We implement the consensus construction on the authentication of networking access to enhance the efficiency of verification between BSs. To achieve the security of cellular connected UAS, we deploy blockchain to maintain the high online rate for accessing networking. Apart from the prevention of accessing malicious BSs, our approach can detect the malicious BSs and eliminate the proportion of the malicious BSs in the cellular networking. The evaluation shows that the proposed approach outperforms the conventional point-to-point authentication method. Concurrently, we enhanced the verification between BSs and the cellular-connected UAS. Our proposed blockchain enabled verification for cellular UAS networking has high potentials to rise the efficiency and the security of the UAS deployment on a large scale.}
}
@article{ZHANG2020102287,
title = {Enhanced Certificateless Auditing Protocols for Cloud Data Management and Transformative Computation},
journal = {Information Processing & Management},
volume = {57},
number = {6},
pages = {102287},
year = {2020},
issn = {0306-4573},
doi = {https://doi.org/10.1016/j.ipm.2020.102287},
url = {https://www.sciencedirect.com/science/article/pii/S0306457320307822},
author = {Jindan Zhang and Zhihu Li and Baocang Wang and Xu An Wang and Urszula Ogiela},
abstract = {Due the advent of new wireless communication, Internet of Things (IoT) and cloud computing, outsourcing the data processing and management to the cloud servers has become a typical transformative computing paradigm. In this context, a cloud auditing protocol is an effective way to check the data integrity for cloud data management. We present a cryptanalysis of two recently proposed certificateless public verifiable auditing protocols, the Zhang et al.’s protocol and the Kang et al.’s protocol. We argue that the tags in the Zhang et al.’s protocol and the semi-tags in the Kang et al.’s protocol can be forged, leading to insecure protocols. We propose improved versions of both protocols and analyze their security and efficiency. Our new protocols can be used as a very effective way for checking the integrity of outsourced cloud storage in the context of transformative computation.}
}
@article{GULL2020134,
title = {Reversible data hiding exploiting Huffman encoding with dual images for IoMT based healthcare},
journal = {Computer Communications},
volume = {163},
pages = {134-149},
year = {2020},
issn = {0140-3664},
doi = {https://doi.org/10.1016/j.comcom.2020.08.023},
url = {https://www.sciencedirect.com/science/article/pii/S0140366420319101},
author = {Solihah Gull and Shabir A. Parah and Khan Muhammad},
keywords = {Reversible data hiding, Huffman encoding, Hiding capacity, Image quality, Dual images, Security, Internet of Medical Things, Privacy},
abstract = {Continuous technological progressions and huge investments are made for the realization of the various goals in the Internet of Things (IoT) driven networks. Internet of Medical Things (IoMT) being a part of IoT has made human living smarter. It is revolutionizing the healthcare industry and is providing a smarter healthcare framework to the people. The generic IoMT framework consists of the major components i.e., data acquisition, communication gateways, and servers. Once the data is acquired, it is sent over the insecure channel where its authentication is essential before diagnosis. In this work, a dual image reversible data hiding technique with high capacity is proposed for IoMT based networks. First of all, the acquired secret data is preprocessed using the Huffman encoding strategy. Once Huffman coding is applied, a codebook of ‘d’ bits is generated for encoding the converted decimal values using indices. The value of these indices is divided into 2 parts and embedded into two visually similar images to obtain dual stego images. The scheme has provided a very high payload while maintaining good perceptual quality. The results obtained depict significant improvement compared to the state-of-the-art. The scheme provides an average (percentage) improvement in embedding capacity by 33.2%, with the improvisation of Peak Signal to Noise (PSNR) Ratio by 1.32%. The average value of the Structural Similarity Index (SSIM) is found to be 0.8873. The scheme is computationally efficient which makes it a better candidate to be used in IoMT driven networks.}
}
@article{KUANG2019161,
title = {Predicting duration of traffic accidents based on cost-sensitive Bayesian network and weighted K-nearest neighbor},
journal = {Journal of Intelligent Transportation Systems},
volume = {23},
number = {2},
pages = {161-174},
year = {2019},
note = {Vehicle Sensor Data-based Transportation Research: Modelling, Analysis, And Management},
issn = {1547-2450},
doi = {https://doi.org/10.1080/15472450.2018.1536978},
url = {https://www.sciencedirect.com/science/article/pii/S1547245022011513},
author = {Li Kuang and Han Yan and Yujia Zhu and Shenmei Tu and Xiaoliang Fan},
keywords = {Accident duration prediction, Bayesian network, cost-sensitive, KNN regression},
abstract = {With the development of urbanization, road congestion has become increasingly serious, and an important cause is the traffic accidents. In this article, we aim to predict the duration of traffic accidents given a set of historical records and the feature of the new accident, which can be collected from the vehicle sensors, in order to help guide the congestion and restore the road. Existing work on predicting the duration of accidents seldom consider the imbalance of samples, the interaction of attributes, and the cost-sensitive problem sufficiently. Therefore, in this article, we propose a two-level model, which consists of a cost-sensitive Bayesian network and a weighted K-nearest neighbor model, to predict the duration of accidents. After data preprocessing and variance analysis on the traffic accident data of Xiamen City in 2015, the model uses some important discrete attributes for classification, and then utilizes the remaining attributes for K-nearest neighbor regression prediction. The experiment results show that our proposed approach to predicting the duration of accidents achieves higher accuracy compared with classical models.}
}
@article{CAUTERUCCIO2020101223,
title = {An approach to compute the scope of a social object in a Multi-IoT scenario},
journal = {Pervasive and Mobile Computing},
volume = {67},
pages = {101223},
year = {2020},
issn = {1574-1192},
doi = {https://doi.org/10.1016/j.pmcj.2020.101223},
url = {https://www.sciencedirect.com/science/article/pii/S1574119220300808},
author = {Francesco Cauteruccio and Luca Cinelli and Giancarlo Fortino and Claudio Savaglio and Giorgio Terracina and Domenico Ursino and Luca Virgili},
keywords = {Scope, Smart objects, Internet of Things, Multi-ioT, Social ioT, Social network analysis, Impact Degree, Trust Degree},
abstract = {In the last few years, classical social networking is turning into the more complex social internetworking and is extending from human users to objects. Indeed, objects are becoming increasingly complex, smart and social so that several authors have recently started to investigate the Social Internet of Things (SIoT) and the Multiple IoT (MIoT) paradigms. SIoT is more oriented to the technological issues to be faced in presence of multiple IoT interacting with each other. Instead, MIoT addresses data-driven and semantics-based aspects because it considers the contents exchanged by smart objects during their transactions. In such a research context, the concept of scope in a Multi-IoT scenario can play an important role. In this paper, we investigate this issue. In particular, first we define the concept of scope in a Multi-IoT scenario. Then, we propose two formalizations of this concept allowing the computation of its values. Afterwards, we present two possible applications of scope. Finally, we describe a set of experiments performed for its evaluation; the last of them compares scope with diffusion degree and influence degree, two parameters already proposed in past literature.}
}
@article{SUN2018193,
title = {Detecting users’ anomalous emotion using social media for business intelligence},
journal = {Journal of Computational Science},
volume = {25},
pages = {193-200},
year = {2018},
issn = {1877-7503},
doi = {https://doi.org/10.1016/j.jocs.2017.05.029},
url = {https://www.sciencedirect.com/science/article/pii/S1877750317302879},
author = {Xiao Sun and Chen Zhang and Guoqiang Li and Daniel Sun and Fuji Ren and Albert Zomaya and Rajiv Ranjan},
keywords = {Business intelligence, Sentiment analysis, Anomaly detection, Multivariate Gaussian distribution, Decision making},
abstract = {Anomaly detection in sentiment analysis refers to detecting users’ abnormal opinions, sentiment patterns or special temporal aspects of such patterns. Users’ emotional state extracted from social media contains business information and business value for decision making. Social media platforms, such as Sina Weibo or Twitter, provide a vast source of information, which include user feedbacks, opinions and information on most issues. Many organizations also leverage social media platforms to publish information about events, products, services, policies and other topics frequently, analyzing social media data to identify abnormal events and make decisions in a timely manner is a beneficial topic. This paper adopts the multivariate Gauss distribution with the power-law distribution to model and analyze the users’ emotion of micro-blogs and detect abnormal emotion state. With the measure of joint probability density value and the validation of the corpus, anomaly detection accuracy of individual user is 83.49% and of different month is 87.84% by this method. Through the distribution test, the results show that individual users’ neutral, happy and sad emotions obey the normal distribution, but the surprised and angry emotions do not. Besides, emotions of micro-blogs released by groups obey power-law distribution, but the individual emotions do not. This paper proposes a quantitative method for abnormal emotion detection on social media, which automatically captures the correlation between different features of the emotions, and saves a certain amount of time by batch calculation of the joint probability density of data sets. The method can help the businesses and government organizations to make decisions according to the user's affective disposition, intervene early or adopt proper strategies if needed.}
}
@article{HIDALGO2017205,
title = {Self-adaptive processing graph with operator fission for elastic stream processing},
journal = {Journal of Systems and Software},
volume = {127},
pages = {205-216},
year = {2017},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2016.06.010},
url = {https://www.sciencedirect.com/science/article/pii/S0164121216300796},
author = {Nicolas Hidalgo and Daniel Wladdimiro and Erika Rosas},
keywords = {Stream processing, Self-adaptable graph, Elastic processing, Scalable processing, S4},
abstract = {Nowadays, information generated by the Internet interactions is growing exponentially, creating massive and continuous flows of events from the most diverse sources. These interactions contain valuable information for domains such as government, commerce, and banks, among others. Extracting information in near real-time from such data requires powerful processing tools to cope with the high-velocity and the high-volume stream of events. Specially designed distributed processing engines build a graph-based topology of a static number of processing operators creating bottlenecks and load balance problems when processing dynamic flows of events. In this work we propose a self-adaptive processing graph that provides elasticity and scalability by automatically increasing or decreasing the number of processing operators to improve performance and resource utilization of the system. Our solution uses a model that monitors, analyzes and changes the graph topology with a control algorithm that is both reactive and proactive to the flow of events. We have evaluated our solution with three stream processing applications and results show that our model can adapt the graph topology when receiving events at high rate with sudden peaks, producing very low costs of memory and CPU usage.}
}
@article{PENG2020133,
title = {Cross domain knowledge learning with dual-branch adversarial network for vehicle re-identification},
journal = {Neurocomputing},
volume = {401},
pages = {133-144},
year = {2020},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2020.02.112},
url = {https://www.sciencedirect.com/science/article/pii/S092523122030357X},
author = {Jinjia Peng and Huibing Wang and Fengqiang Xu and Xianping Fu},
keywords = {Domain adaptation, Dual-branch adversarial network, Vehicle re-identification},
abstract = {The widespread popularization of vehicles has facilitated all people’s life during the last decades. However, the emergence of a large number of vehicles poses the critical but challenging problem of vehicle re-identification (reID). Till now, for most vehicle reID algorithms, both the training and testing processes are conducted on the same annotated datasets under supervision. However, even a well-trained model will still cause fateful performance drop due to the severe domain bias between the trained dataset and the real-world scenes. To address this problem, this paper proposes a domain adaptation framework for vehicle reID (DAVR), which narrows the cross-domain bias by fully exploiting the labeled data from the source domain to adapt the target domain. DAVR develops an image-to-image translation network named Dual-branch Adversarial Network (DAN), which promotes the images from the source domain (well-labeled) to learn the style of the target domain (unlabeled). Specially, DAN doesn’t need any annotation and can preserve identity information from source domain before and after translation. Furthermore, the generated images are employed to train the vehicle reID model by a proposed attention-based feature learning network. Through the proposed framework, the well-trained reID model has better generalization ability for various scenes in real-world situations. Comprehensive experimental results have demonstrated that our proposed DAVR can achieve excellent performances on benchmark datasets VehicleID and VeRi-776.}
}
@article{RIZZO2021100287,
title = {Optimal strategies for floating anchored information with partial infrastructure support},
journal = {Vehicular Communications},
volume = {27},
pages = {100287},
year = {2021},
issn = {2214-2096},
doi = {https://doi.org/10.1016/j.vehcom.2020.100287},
url = {https://www.sciencedirect.com/science/article/pii/S2214209620300589},
author = {Gianluca Rizzo and Marco {Ajmone Marsan} and Torsten Braun and Gaetano Manzo},
keywords = {Ad-hoc networks, VANETS, Floating content, Delay tolerant networking, Distributed caching, Probabilistic spatial storage},
abstract = {Floating Content (FC) is a communication paradigm to locally share ephemeral content without direct support from infrastructure. It is based on constraining the opportunistic replication of content in a way that strikes a balance between minimizing resource usage and maximizing content availability among the intended recipients. However, existing approaches to management of FC schemes are unfit for realistic scenarios with non-uniform user distributions, resulting in heavy overdimensioning of resources allocated to FC. In this work, we propose a new version of FC, called Cellular Floating Content (CFC), which optimizes the use of bandwidth and memory by adapting the content replication and storage strategies to the spatial distribution of users, and to their mobility patterns. The main idea underlying our approach is to partition users into small “local communities”, and to optimally weight their contributions to the FC paradigm according to their specific mobility features, and to the resources required to achieve a target performance level. We characterize numerically the properties of the optimal strategies in a variety of mobility patterns and traffic conditions, showing the accuracy of our approach, and the significant savings it enables in the amount of resources necessary to run FC, which in a realistic setup can be as high as 27% with respect to traditional FC dimensioning strategies.}
}
@article{ADELSERHANI2020583,
title = {Self-adapting cloud services orchestration for fulfilling intensive sensory data-driven IoT workflows},
journal = {Future Generation Computer Systems},
volume = {108},
pages = {583-597},
year = {2020},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2020.02.066},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X19316231},
author = {M. {Adel Serhani} and Hadeel T. El-Kassabi and Khaled Shuaib and Alramzana N. Navaz and Boualem Benatallah and Amine Beheshti},
keywords = {IoT, Workflow, Sensors, Orchestration, Adaptation, Health monitoring},
abstract = {Cloud computing has been adopted to support among others the storage and processing of complex Internet of Things (IoT) workflows handling sensory streamed time-series data. IoT workflow is often composed following a set of procedures which makes it hard to self-adapt, self-configure to react to runtime environment changes. Therefore, declarative data-driven workflow composition will provision self-learning and self-configurable workflows such as those of IoT. This paper proposes a comprehensive architecture to support end-to-end workflow management processes including declarative specification and composition, configuration deployment, orchestration, execution, adaptation, and quality enforcement. The later provision runtime intelligence for IoT workflow orchestration; this is achieved through the automated monitoring and analysis of runtime cloud resource orchestration, the monitoring of workflows tasks execution, as well as through cloud resource utilization prediction and workflow adaptation. In addition, it supports other intelligent features that include: (1) integration of edge computing (sensor edge) for local data processing which is very crucial for life-critical IoT workflows, (2) data compression for fast data transmission, and data storage adaptation, and (3) customization of data reporting and visualization. All these features have been evaluated through a set of experiments that proved a significant gain in terms of workflow execution time, cost and optimum usage of cloud resources compared to baseline adaptation strategy.}
}
@article{MAJSTOROVIC2021188,
title = {Smart Manufacturing as a framework for Smart Mining},
journal = {Procedia CIRP},
volume = {104},
pages = {188-193},
year = {2021},
note = {54th CIRP CMS 2021 - Towards Digitalized Manufacturing 4.0},
issn = {2212-8271},
doi = {https://doi.org/10.1016/j.procir.2021.11.032},
url = {https://www.sciencedirect.com/science/article/pii/S2212827121009306},
author = {Vidosav Majstorovic and Vladimir Simeunovic and Zarko Miskovic and Radivoje Mitrovic and Dragan Stosic and Sonja Dimitrijevic},
keywords = {Smart manufacturing, Smart mining, Analogy, Case study},
abstract = {Based on the analogy between manufacturing and mining (i.e. ore ‘production’), smart mining has four dimensions: (i) advanced digital-oriented technologies (such as Cloud computing and the Internet of things) with automated Cyber-Physical Systems (CPSs), adaptable production processes (dependent on working conditions) and production volume control (with optimal resource consumption); (ii) smart maintenance of CPSs; (iii) new ways for workers to perform their activities, using advanced digital-oriented technologies; and (iv) smart supply-chain (procurement of materials and spare parts / products delivery). This paper presents a case study on the smart mining approach implemented at a coal mining system in Serbia.}
}
@article{ZHOU2019167,
title = {Multi-task emotion communication system with dynamic resource allocations},
journal = {Information Fusion},
volume = {52},
pages = {167-174},
year = {2019},
issn = {1566-2535},
doi = {https://doi.org/10.1016/j.inffus.2019.03.003},
url = {https://www.sciencedirect.com/science/article/pii/S1566253518308686},
author = {Ping Zhou and M. Shamim Hossain and Xiaofen Zong and Ghulam Muhammad and Syed Umar Amin and Iztok Humar},
keywords = {Emotion communication, Multi-task scheduling, The minimum task transmission rate, Dynamic optimal resource allocation},
abstract = {The research of long-distance emotion communication and interaction without time and space constraints is an important area in human-robot interaction (HRI) systems. Although many methods of emotion recognition have been studied for analyzing various emotion signals, the resource allocation of transmission for emotion communication signals of many pairs of users has not been fully considered nor solved at the same time. This paper proposes a new multi-task emotion communication system (MEmSys), where the transmission resources allocation issue is considered. Specifically, we firstly establish the architecture of MEmSys, and the entire emotion interaction process of the proposed system is introduced. By analyzing fairness and urgency of different tasks, the mathematical expressions of the minimum task transmission rates for all user pairs are derived. Then, a dynamic optimal resource allocation scheme is presented to maximize the sum of the task transmission rates in the proposed system. Moreover, simulation experiment results and performance analyses show that the resource utilization ratio of the proposed allocation scheme for multiple user pairs is significantly improved compared to the single user pair system. Finally, future works are discussed to provide insights for our next research.}
}
@article{MARTINS2021107080,
title = {Optimizing ride-sharing operations in smart sustainable cities: Challenges and the need for agile algorithms},
journal = {Computers & Industrial Engineering},
volume = {153},
pages = {107080},
year = {2021},
issn = {0360-8352},
doi = {https://doi.org/10.1016/j.cie.2020.107080},
url = {https://www.sciencedirect.com/science/article/pii/S0360835220307506},
author = {Leandro do C. Martins and Rocio {de la Torre} and Canan G. Corlu and Angel A. Juan and Mohamed A. Masmoudi},
keywords = {Ride-sharing optimization, Carpooling, Simulation, Metaheuristics, Real-time optimization, Smart sustainable cities},
abstract = {Mobility solutions like ride-sharing and carpooling are becoming popular in many urban and metropolitan areas around the globe. These solutions, however, create many operational challenges that need to be solved in order to make them more efficient and sustainable in time, e.g.: determining the number and location of parking slots, finding the optimal routes in terms of time or emissions, or developing synchronized schedules among ride-sharing users. This paper provides an updated review on car-sharing optimization studies (including ride-sharing and carpooling), compares different analytical approaches in this research area, and discusses the emerging concept of ‘agile’ algorithms as one of the approaches that might contribute to deal with the requirements of large-scale and dynamic car-sharing optimization problems.}
}
@article{CHEN201896,
title = {Secondhand seller reputation in online markets: A text analytics framework},
journal = {Decision Support Systems},
volume = {108},
pages = {96-106},
year = {2018},
issn = {0167-9236},
doi = {https://doi.org/10.1016/j.dss.2018.02.008},
url = {https://www.sciencedirect.com/science/article/pii/S016792361830037X},
author = {Runyu Chen and Yitong Zheng and Wei Xu and Minghao Liu and Jiayue Wang},
keywords = {Secondhand e-commerce, Reputation assessment, Text analytics, Aspect extraction},
abstract = {With the rapid development of e-commerce, a new type of secondhand e-commerce website has appeared in recent years. Any user can have his or her own shop and list superfluous items for sale online without much supervision. These secondhand e-commerce platforms maximize the economic value of secondhand markets online, but buyers risk conducting unpleasant transactions with low-reputation sellers. The main contribution of our research is the design of a text analytics framework to assess secondhand sellers' reputation. In addition, we develop a new aspect-extraction method that combines the results of domain ontology and topic modeling to extract topical features from product descriptions. We conduct our experiments based on a real-word dataset crawled from XianYu. The experimental results reveal that our ontology-based topic model method outperforms a traditional topic model method. Furthermore, the proposed framework performs well in different item categories. The managerial implication of our research is that potential buyers can prejudge the reputation of secondhand sellers when making purchase decisions. The results can support a more effective development of online secondhand markets.}
}
@article{WANG201966,
title = {Elastic-net regularized latent factor analysis-based models for recommender systems},
journal = {Neurocomputing},
volume = {329},
pages = {66-74},
year = {2019},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2018.10.046},
url = {https://www.sciencedirect.com/science/article/pii/S0925231218312359},
author = {Dexian Wang and Yanbin Chen and Junxiao Guo and Xiaoyu Shi and Chunlin He and Xin Luo and Huaqiang Yuan},
keywords = {Big data, Recommender systems, Collaborative filtering, Latent factor analysis, Elastic-net, Regularization, Latent factor distribution},
abstract = {Latent factor analysis (LFA)-based models are highly efficient in recommender systems. The problem of LFA is defined on high-dimensional and sparse (HiDS) matrices corresponding to relationships among numerous entities in industrial applications. It is ill-posed without a unique and optimal solution, making regularization vital in improving the generality of an LFA-based model. Current models mostly adopt l2-norm-based regularization, which cannot regularize the latent factor distributions. For addressing this issue, this work applies the elastic-net-based regularization to an LFA-based model, thereby achieving an elastic-net regularized latent factor analysis-based (ERLFA) model. We further adopt two efficient learning algorithms, i.e., forward-looking sub-gradients and forward-backward splitting and stochastic proximal gradient descent, to train desired latent factors in an ERLFA-based model, resulting in two novel ERLFA-based models relying on different learning schemes. Experimental results on four large industrial datasets show that by regularizing the latent factor distribution, the proposed ERLFA-based models are able to achieve high prediction accuracy for missing data of an HiDS matrix without additional computational burden.}
}
@article{MONOSTORI20149,
title = {Cyber-physical Production Systems: Roots, Expectations and R&D Challenges},
journal = {Procedia CIRP},
volume = {17},
pages = {9-13},
year = {2014},
note = {Variety Management in Manufacturing},
issn = {2212-8271},
doi = {https://doi.org/10.1016/j.procir.2014.03.115},
url = {https://www.sciencedirect.com/science/article/pii/S2212827114003497},
author = {László Monostori},
keywords = {Manufacturing systems, cyber-physical systems, distributed systems},
abstract = {One of the most significant directions in the development of computer science and information and communication technologies is represented by Cyber-Physical Systems (CPSs) which are systems of collaborating computational entities which are in intensive connection with the surrounding physical world and its on-going processes, providing and using, at the same time, data-accessing and data-processing services available on the internet. Cyber-Physical Production Systems (CPPSs), relying on the newest and foreseeable further developments of computer science, information and communication technologies on the one hand, and of manufacturing science and technology, on the other, may lead to the 4th Industrial Revolution, frequently noted as Industry 4.0. The key-note will underline that there are significant roots generally – and particularly in the CIRP community – which point towards CPPSs. Expectations and the related new R&D challenges will be outlined.}
}
@article{CHEN2021565,
title = {Neural symbolic reasoning with knowledge graphs: Knowledge extraction, relational reasoning, and inconsistency checking},
journal = {Fundamental Research},
volume = {1},
number = {5},
pages = {565-573},
year = {2021},
issn = {2667-3258},
doi = {https://doi.org/10.1016/j.fmre.2021.08.013},
url = {https://www.sciencedirect.com/science/article/pii/S266732582100159X},
author = {Huajun Chen and Shumin Deng and Wen Zhang and Zezhong Xu and Juan Li and Evgeny Kharlamov},
keywords = {Neural symbolic reasoning, Knowledge graph, Knowledge extraction, Relational reasoning, Inconsistency checking},
abstract = {Knowledge graphs (KGs) express relationships between entity pairs, and many real-life problems can be formulated as knowledge graph reasoning (KGR). Conventional approaches to KGR have achieved promising performance but still have some drawbacks. On the one hand, most KGR methods focus only on one phase of the KG lifecycle, such as KG completion or refinement, while ignoring reasoning over other stages, such as KG extraction. On the other hand, traditional KGR methods, broadly categorized as symbolic and neural, are unable to balance both scalability and interpretability. To resolve these two problems, we take a more comprehensive perspective of KGR with regard to the whole KG lifecycle, including KG extraction, completion, and refinement, which correspond to three subtasks: knowledge extraction, relational reasoning, and inconsistency checking. In addition, we propose the implementation of KGR using a novel neural symbolic framework, with regard to both scalability and interpretability. Experimental results demonstrate that our proposed methods outperform traditional neural symbolic models.}
}
@article{HUSSAIN2021e00182,
title = {Paradigm of technological convergence and digital transformation: The challenges of CH sectors in the global COVID-19 pandemic and commencing resilience-based structure for the post-COVID-19 era},
journal = {Digital Applications in Archaeology and Cultural Heritage},
volume = {21},
pages = {e00182},
year = {2021},
issn = {2212-0548},
doi = {https://doi.org/10.1016/j.daach.2021.e00182},
url = {https://www.sciencedirect.com/science/article/pii/S2212054821000114},
author = {Zahid Hussain},
keywords = {Cultural heritage, Digital transformation, Digital technologies, COVID-19 pandemic, Convergence innovation, Sustainable innovation},
abstract = {Technology and digitalization are vital for helping organizations to survive in the competitive marketplace. The global COVID-19 pandemic has fixated attention on the cultural heritage sectors. This study presents technological convergence and new digital platforms that require business societies to transform into new sustainable meanings. The concept of technological convergence to the autonomous ecosystem is supported by cutting-edge technologies, a distinctive life cycle for value-added creation. This study is based on a five-part conceptual context to examine the impact of pandemic on the cultural heritage sectors. The major impacts like institutional issues, financial limitations, data access policies, and stakeholders diverging views are fully addressed. An additional impression of this study is that it has comprehensively expressed the opportunities and capabilities of technological convergence in terms of competence, integration, impound and novelty for higher value creation most related to the cultural heritage sectors in the current and post COVID-19 pandemic era.}
}
@article{RAJENDRAN2021103358,
title = {Object Recommendation based Friendship Selection (ORFS) for navigating smarter social objects in SIoT},
journal = {Microprocessors and Microsystems},
volume = {80},
pages = {103358},
year = {2021},
issn = {0141-9331},
doi = {https://doi.org/10.1016/j.micpro.2020.103358},
url = {https://www.sciencedirect.com/science/article/pii/S0141933120305172},
author = {Subash Rajendran and R. Jebakumar},
keywords = {Friendship selection, Network navigability, Object recommendation, Relationship management, Social Internet of Things, Trust},
abstract = {Social Internet of Things (SIoT) paradigm contributes for the social relationship between the objects. SIoT autonomously handles diverse set of objects, performing similar responsibilities. Providing user friendly smarter objects for resource sharing is a prerequisite in any SIoT platform. An effective service discovery depends on multiple attributes of object centrality. In this work, an efficient Object Recommendation based Friendship Selection (ORFS) model for network navigability and social relationship management among smarter objects in SIoT is proposed. The proposed ORFS model empowers to create, communicate and manage trust based social objects. A Grey Wolf Algorithm based User Object Affiliation (GWA-UOA) mechanism for the Smarter Object Recommendation (SOR) is proposed. Then Object Friendship Selection (OFS) through network navigability using Maximum Ranked Neighborhood (MRN) approach is proposed. Finally, desired service is navigated through the established friendship link. The proposed social-driven relationship approach is validated using two distinct real-world datasets. Experimental results proved that the proposed ORFS model well performed for navigating smarter social objects in SIoT. ORFS model achieved an improved performance with various factors like MAE, RMSE, computational time, average path length, recall, precision and F1 score.}
}
@article{WEI2020270,
title = {Intent-based networks for 6G: Insights and challenges},
journal = {Digital Communications and Networks},
volume = {6},
number = {3},
pages = {270-280},
year = {2020},
issn = {2352-8648},
doi = {https://doi.org/10.1016/j.dcan.2020.07.001},
url = {https://www.sciencedirect.com/science/article/pii/S2352864820302418},
author = {Yiming Wei and Mugen Peng and Yaqiong Liu},
keywords = {Intent-based networks (IBNs), The sixth-generation wireless networks (6G), Artificial intelligence (AI)},
abstract = {Intent-Based Networks (IBNs), which are originally proposed to introduce Artificial Intelligence (AI) into the sixth-generation (6G) wireless networks, can effectively solve the challenges of traditional networks in terms of efficiency, flexibility, and security. IBNs are mainly used to transform users’ business intent into network configuration, operation, and maintenance strategies, which are prominent for designing the AI-enabled 6G networks. In particular, in order to meet the massive, intelligent service demands and overcome the time-varying radio propagation, IBNs can continuously learn and adapt to the time-varying network environment based on the massive collected network data in real-time. From the aspects of both the core network and radio access network, this article comprehensively surveys the architectures and key techniques of IBNs for 6G. In particular, the demonstration platforms of IBNs, such as the Apstra Operating System, Forward Networks Verification Platform, and One Convergence Service Interaction Platform, are presented. Moreover, the industrial development of IBNs is elaborated, including the emerging new products and startups to solve the problems of open data platforms, automated network operations, and preemptive network fault diagnosis. Finally, several open issues and challenges are identified as well to spur future researches.}
}
@article{ZHU2021101462,
title = {Quality of e-commerce agricultural products and the safety of the ecological environment of the origin based on 5G Internet of Things technology},
journal = {Environmental Technology & Innovation},
volume = {22},
pages = {101462},
year = {2021},
issn = {2352-1864},
doi = {https://doi.org/10.1016/j.eti.2021.101462},
url = {https://www.sciencedirect.com/science/article/pii/S2352186421001103},
author = {Zijiang Zhu and Yuehua Bai and Weihuang Dai and Dong Liu and Yi Hu},
keywords = {5G communication technology, Internet of Things technology, Agricultural products, E-commerce},
abstract = {The quality and safety of agricultural products is not only related to the consumption and health of residents, but also related to the sustainable development of agriculture. It is one of the hot spots for the government and residents. In addition to the rapid development of e-commerce and the continuous improvement of consumption levels of urban and rural populations, the quality and safety of agricultural products pose new risks and new hidden dangers. The purpose of this paper is to study the quality and safety of e-commerce agricultural products based on 5G Internet of Things technology. This paper mainly studies and uses the key technologies of 5G Internet of Things to build a circulation information system for agricultural products based on 5G Internet of Things, so as to realize the real-time positioning, information sharing and security of circulation in the supply chain of agricultural products. Experiments show that 5g Internet of things can not only provide agricultural producers, sellers and ordinary users with more efficient, convenient and accurate quality and safety information of agricultural products, but also improve the efficiency of agricultural products circulation and effectively reduce the cost of agricultural products circulation. In this paper, the RFID technology of 5G Internet of Things is used. The experimental result is that the revenue growth rate of the e-commerce business is 30%. We can see that the increase in e-commerce business revenue is due to the 5G Internet of Things improving the quality of e-commerce produce to some extent.}
}
@article{ZHANG2018494,
title = {Data driven business rule generation based on fog computing},
journal = {Future Generation Computer Systems},
volume = {89},
pages = {494-505},
year = {2018},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2018.07.003},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X18308781},
author = {Yifei Zhang and Hongming Cai and Boyi Xu and Athanasios T. Vasilakos and Chengxi Huang},
keywords = {Fog computing, Test cases, Software engineering, Text processing},
abstract = {With the rapid development of information technology, the growing number of software products lead to the high demand for software testing, which brings greater pressure and challenge to the software tester. At the same time, huge volumes of test case data which have been accumulated in enterprise information system are not completely used. In order to make full use of these historical test cases, the following three problems need to be solved: (1) data heterogeneity exists in test cases, (2) data fragmentation for certain function module, (3) network bandwidth pressure. A framework is purposed, which contains five models and a fog computing architecture with multi-layer fusion technology. Standard models are purposed to standardize test cases. The multilevel fusion method are used to deal with scattered data. And using fog computing method can reduce the pressure of server computing and network bandwidth. A test case system is developed to verify the effectiveness of our architecture. The result shows that our system can reduce bandwidth and latency, and help case testers write test cases as well.}
}
@article{REDONDO202083,
title = {A hybrid analysis of LBSN data to early detect anomalies in crowd dynamics},
journal = {Future Generation Computer Systems},
volume = {109},
pages = {83-94},
year = {2020},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2020.03.038},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X19309859},
author = {Rebeca P. Díaz Redondo and Carlos Garcia-Rubio and Ana Fernández Vilas and Celeste Campo and Alicia Rodriguez-Carrion},
keywords = {Location-based social network, Crowd dynamics, Entropy analysis, Density-based clustering, Instagram},
abstract = {Undoubtedly, Location-based Social Networks (LBSNs) provide an interesting source of geo-located data that we have previously used to obtain patterns of the dynamics of crowds throughout urban areas. According to our previous results, activity in LBSNs reflects the real activity in the city. Therefore, unexpected behaviors in the social media activity are a trustful evidence of unexpected changes of the activity in the city. In this paper we introduce a hybrid solution to early detect these changes based on applying a combination of two approaches, the use of entropy analysis and clustering techniques, on the data gathered from LBSNs. In particular, we have performed our experiments over a data set collected from Instagram for seven months in New York City, obtaining promising results.}
}
@article{VERDEJO2022103559,
title = {Assessment of sustainable development objectives in Smart Labs: technology and sustainability at the service of society},
journal = {Sustainable Cities and Society},
volume = {77},
pages = {103559},
year = {2022},
issn = {2210-6707},
doi = {https://doi.org/10.1016/j.scs.2021.103559},
url = {https://www.sciencedirect.com/science/article/pii/S2210670721008258},
author = {Ángeles Verdejo and Macarena Espinilla and Jose Luis López and Francisco Jurado Melguizo},
abstract = {ABSTRACT
Sustainable development is the working basis of engineering research and cities are becoming increasingly flexible, inclusive and intelligent. In this context, there is a need for environments that emulate real-life spaces in which cutting-edge technologies can be implemented for subsequent deployment in society. Smart Labs or Living Labs are spaces for innovation, research and experimentation that integrate systems, devices and methodologies focused on people and their environments. The technologies studied and developed in such labs can then be deployed in human spaces to provide intelligence, comfort, health and sustainability. Health and wellness, energy and environment, artificial intelligence, big data and digital rights are some of the disciplines being studied. At the same time, the UN 2030 Agenda provides a comprehensive framework to promote human well-being through the Sustainable Development Goals. In this work, an evaluation model of its indicators in smart environments is performed through a mixed review methodology. The objective of this work is the analysis and implementation of the SDGs in Smart Labs through a literature review and a case study of UJAmI, the smart laboratory of the University of Jaén. The results provide quantitative and qualitative data on the present and future of the smart devices implemented in the UJAmI lab, providing a roadmap for future developments.}
}
@article{ZHANG202031,
title = {Efficient scientific workflow scheduling for deadline-constrained parallel tasks in cloud computing environments},
journal = {Information Sciences},
volume = {531},
pages = {31-46},
year = {2020},
issn = {0020-0255},
doi = {https://doi.org/10.1016/j.ins.2020.04.039},
url = {https://www.sciencedirect.com/science/article/pii/S0020025520303479},
author = {Longxin Zhang and Liqian Zhou and Ahmad Salah},
keywords = {Cloud computing, Deadline, Directed acyclic graph (DAG), Makespan, Resource management},
abstract = {Data centers for cloud computing must accommodate numerous parallel task executions simultaneously. Therefore, data centers have many virtual machines (VMs). Minimizing the scheduling length of parallel task sets becomes a critical requirement in cloud computing systems. In this study, we propose an efficient priority and relative distance (EPRD) algorithm to minimize the task scheduling length for precedence constrained workflow applications without violating the end-to-end deadline constraint. This algorithm consists of two processes. First, a task priority queue is established. Then, a VM is mapped for a task in accordance with its relative distance. The proposed method can effectively improve VM utilization and scheduling performance. Extensive rigorous experiments based on randomly generated and real-world workflow applications demonstrate that the resource reduction rate and scheduling length of the EPRD algorithm significantly surpass those of existing algorithms.}
}
@article{BAKLANOV2020100610,
title = {Integrated urban services: Experience from four cities on different continents},
journal = {Urban Climate},
volume = {32},
pages = {100610},
year = {2020},
issn = {2212-0955},
doi = {https://doi.org/10.1016/j.uclim.2020.100610},
url = {https://www.sciencedirect.com/science/article/pii/S2212095519300537},
author = {Alexander Baklanov and Beatriz Cárdenas and Tsz-cheung Lee and Sylvie Leroyer and Valery Masson and Luisa T. Molina and Tanya Müller and Chao Ren and Felix R. Vogel and James A. Voogt},
abstract = {Rapid urbanization combined with climate change necessitates new types of urban services that make best use of science and technology. The Integrated Urban Hydro-Meteorological, Climate and Environmental Services and systems are a new initiative from the World Meteorological Organization (WMO) that seeks to provide science-based integrated urban services supporting safe, healthy and resilient cities. Various cities have already started development and implementation of such Integrated Urban Services and successfully test and use them following specific requirements of local stakeholders. This paper demonstrates the novel concept and approach of Integrated Urban Hydro-Meteorological, Climate and Environmental Services (IUS) from a set of four case study cities: Hong Kong, Toronto, Mexico City and Paris, that use different IUS configurations with good existing practice. These cities represent a range of countries, climates and geophysical settings. The aggregate main joint similarities of the IUS in these cities and synergy of the cities' experience, achievements and research findings are presented, as well as identification of existing gaps in knowledge and further research needs. A list of potential criteria for identifying and classifying IUS demonstration cities is proposed. It will aid future, more detailed analysis of the IUS experience, and selection of additional demonstration cities.}
}
@article{ANABITARTEGARCIA2021101399,
title = {Early diagnosis of frailty: Technological and non-intrusive devices for clinical detection},
journal = {Ageing Research Reviews},
volume = {70},
pages = {101399},
year = {2021},
issn = {1568-1637},
doi = {https://doi.org/10.1016/j.arr.2021.101399},
url = {https://www.sciencedirect.com/science/article/pii/S156816372100146X},
author = {Francisco Anabitarte-García and Luis Reyes-González and Luis Rodríguez-Cobo and Carlos Fernández-Viadero and Silvia Somonte-Segares and Sara Díez-del-Valle and Eneritz Mandaluniz and Roberto García-García and José M. López-Higuera},
keywords = {Frailty, Early detection, Sensors, Non-intrusive},
abstract = {This work analyses different concepts for frailty diagnosis based on affordable standard technology such as smartphones or wearable devices. The goal is to provide ideas that go beyond classical diagnostic tools such as magnetic resonance imaging or tomography, thus changing the paradigm; enabling the detection of frailty without expensive facilities, in an ecological way for both patients and medical staff and even with continuous monitoring. Fried's five-point phenotype model of frailty along with a model based on trials and several classical physical tests were used for device classification. This work provides a starting point for future researchers who will have to try to bridge the gap separating elderly people from technology and medical tests in order to provide feasible, accurate and affordable tools for frailty monitoring for a wide range of users.}
}
@article{ROOPA2021100311,
title = {DTCMS: Dynamic traffic congestion management in Social Internet of Vehicles (SIoV)},
journal = {Internet of Things},
volume = {16},
pages = {100311},
year = {2021},
issn = {2542-6605},
doi = {https://doi.org/10.1016/j.iot.2020.100311},
url = {https://www.sciencedirect.com/science/article/pii/S2542660520301426},
author = {M.S. Roopa and S. {Ayesha Siddiq} and Rajkumar Buyya and K.R. Venugopal and S.S. Iyengar and L.M. Patnaik},
keywords = {Dynamic traffic control, Traffic congestion management, Social Internet of Vehicles (SIoV), Social relationships},
abstract = {With the augmentation of traffic exponentially, we observe that traffic congestion does not guarantee road safety or enhance the driving experience. In the recent past, Social Internet of Vehicles (SIoV), a social network paradigm permits social relationships among every vehicle in the network or with any road infrastructure to render a radically useful environment. SIoV is beneficial for the drivers, in improving road safety, avoiding mishaps, and providing a friendly-driving experience. In this paper, we propose a traffic scheduling algorithm to gain the maximum throughput for the flow of vehicles at a road intersection with the formation of social relationships among the vehicles and with the Road Side Units (RSUs). The algorithm estimates the flow rate of vehicles for lanes at the intersections exploiting the volume of traffic moving through the given road. A condition matrix is designed for the consistent movement of traffic considering different routes on the road segments. Social relationships are devised on various aspects of travel needs for a safe, agile, and better driving experience. Simulation results illustrate the efficacy of the proposed scheme with high traffic throughput, service rate and reduce the total travelling time, delay time, and average waiting time in comparison with Dynamic Throughput Maximization Framework and Adaptive Traffic Control Algorithm.}
}
@article{KUMAR2021109558,
title = {Recent developments on target tracking problems: A review},
journal = {Ocean Engineering},
volume = {236},
pages = {109558},
year = {2021},
issn = {0029-8018},
doi = {https://doi.org/10.1016/j.oceaneng.2021.109558},
url = {https://www.sciencedirect.com/science/article/pii/S0029801821009471},
author = {Manav Kumar and Sharifuddin Mondal},
keywords = {AUV, UAV, AUAV, PUAV, MTT},
abstract = {Recent progresses in the target tracking technology have changed current unmanned systems into a realistic substitute to the conventional tracking systems. In this paper, existing algorithms on target tracking for both aerial and underwater application scenario are classified based on the active and passive modes of target tracking. These algorithms are analysed and compared in the form of mode, tracking technology and respective validation algorithm available in the literature. From this survey, the future directions and major challenges are edged to obtain higher level of tracking performance.}
}
@article{DUONG2022101532,
title = {UAV caching in 6G networks: A Survey on models, techniques, and applications},
journal = {Physical Communication},
volume = {51},
pages = {101532},
year = {2022},
issn = {1874-4907},
doi = {https://doi.org/10.1016/j.phycom.2021.101532},
url = {https://www.sciencedirect.com/science/article/pii/S1874490721002482},
author = {Trung Q. Duong and Kyeong Jin Kim and Zeeshan Kaleem and Minh-Phung Bui and Nguyen-Son Vo},
keywords = {6G networks, UAV communications with caching, UAV networks, UAV caching optimisation framework},
abstract = {The rapid development road map of 6G networks has posed a new set of challenges to both industrial and academic sectors. On the one hand, it needs more disruptive technologies and solutions for addressing the threefold issues including enhanced mobile broadband, massive machine-type communications, and ultra-reliable and low-latency communications. On the other hand, the ever-massive number of mobile users and Internet of Things devices conveys the huge volume of traffic throughout the 6G networks. In this context, caching is one of the most feasible technologies and solutions that does not require any system architecture changes nor costly investments, while significantly improve the system performance, i.e., quality of service and resource efficiency. Ground caching models deployed at macro base stations, small-cell base stations, and mobile devices have been successfully studied and currently extended to the air done by unmanned aerial vehicles (UAVs) to deal with the challenges of 6G networks. This paper provides a comprehensive survey of UAV caching models, techniques, and applications in 6G networks. In particular, we first investigate the entire picture of caching models moving from the ground to the air as well as the related surveys on UAV communications. Then, we introduce a typical UAV caching system and describe how it works in connection with all types of the transceivers, end users, and applications and services (A&Ss). After that, we present the recent advancements and analyses of the UAV caching models and common system performance metrics. Furthermore, the UAV caching with assisted techniques, UAV caching-enabled mechanisms, and UAV caching A&Ss are discussed to demonstrate the role of UAV caching system in 6G networks. Finally, we highlight the ongoing challenges and potential research directions toward UAV caching in 6G networks.}
}
@article{CHAND2021,
title = {Examining the macro-level factors affecting vehicle breakdown duration},
journal = {International Journal of Transportation Science and Technology},
year = {2021},
issn = {2046-0430},
doi = {https://doi.org/10.1016/j.ijtst.2021.03.003},
url = {https://www.sciencedirect.com/science/article/pii/S2046043021000101},
author = {Sai Chand and Zhuolin Li and Vinayak V. Dixit and S. {Travis Waller}},
keywords = {Breakdowns, Incidents, Duration, Hazard-based},
abstract = {A substantial part of traffic congestion is triggered by unplanned incidents such as crashes, breakdowns and hazards, reducing road capacity and increasing the delays, pollution, and productivity losses. Previous studies on incident duration have focussed on individual incidents and the influencing factors that could be obtained directly from the incident description. Consequently, the explanatory variables were more localized, and the impacts of broader macro-level factors were not explored. This contrasts with the studies on incident frequency, where the influencing factors are typically collected at a macro-level. Therefore, this study aims to explore the impact of various factors associated with reported vehicle breakdown duration at a macro-level. Street network characteristics such as connectivity, density, and hierarchy were included as covariates, in addition to the demographic, vehicle utilization, and environmental variables. The dataset contains over 72,000 vehicle breakdowns records within 4.5 years (January 2012 to June 2016) in Greater Sydney, Australia involving 44 SA3s (Statistical Area Level 3). After a principal component dimension reduction of independent variables, a fixed-parameters accelerated failure time (AFT) hazard-based model with underlying log-logistic, log-normal and Weibull distributions were used in this analysis. Weibull hazard distribution with gamma frailty and the latent class models were also considered to account for unobserved heterogeneity. The latent class model provides the best fit where road network connectivity, hierarchy, and familiarity factors are considered to have both positive and negative impact on duration; higher road network density, mixed land-use, and spatial disorientation of roads are associated with longer duration; and higher income and exposure (vehicle kilometres travelled) are associated with shorter duration. The results will help incident management agencies to better allocate current response resources and predict the resources required in the future. Besides, the results associated with network structure measures can provide valuable insights to community planning authorities to manage unplanned congestion.}
}
@article{WANG2020294,
title = {Cross-modality paired-images generation and augmentation for RGB-infrared person re-identification},
journal = {Neural Networks},
volume = {128},
pages = {294-304},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.05.008},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020301702},
author = {Guan’an Wang and Yang Yang and Tianzhu Zhang and Jian Cheng and Zengguang Hou and Prayag Tiwari and Hari Mohan Pandey},
keywords = {Person re-identification, Cross-modality, Feature disentanglement, Image generation, Adversarial learning},
abstract = {RGB-Infrared (IR) person re-identification is very challenging due to the large cross-modality variations between RGB and IR images. Considering no correspondence labels between every pair of RGB and IR images, most methods try to alleviate the variations with set-level alignment by reducing marginal distribution divergence between the entire RGB and IR sets. However, this set-level alignment strategy may lead to misalignment of some instances, which limit the performance for RGB–IR Re-ID. Different from existing methods, in this paper, we propose to generate cross-modality paired-images and perform both global set-level and fine-grained instance-level alignments. Our proposed method enjoys several merits. First, our method can perform set-level alignment by disentangling modality-specific and modality-invariant features. Compared with conventional methods, ours can explicitly remove the modality-specific features and the modality variation can be better reduced. Second, given cross-modality unpaired-images of a person, our method can generate cross-modality paired images from exchanged features. With them, we can directly perform instance-level alignment by minimizing distances of every pair of images. Third, our method learns a latent manifold space. In the space, we can random sample and generate lots of images of unseen classes. Training with those images, the learned identity feature space is more smooth can generalize better when test. Finally, extensive experimental results on two standard benchmarks demonstrate that the proposed model favorably against state-of-the-art methods.}
}
@article{JUYAL202110815,
title = {Security and privacy issues in unified IoT-based skin monitoring system},
journal = {Materials Today: Proceedings},
volume = {46},
pages = {10815-10820},
year = {2021},
note = {International Conference on Technological Advancements in Materials Science and Manufacturing},
issn = {2214-7853},
doi = {https://doi.org/10.1016/j.matpr.2021.01.718},
url = {https://www.sciencedirect.com/science/article/pii/S2214785321008154},
author = {Shuchi Juyal and Sachin Sharma and Amal {Shankar Shukla}},
keywords = {Skincare, IoT, Cloud, Security, Privacy},
abstract = {Healthcare Sector is one of the most benefitted areas among all which gets the benefit of Internet of things. It allows the healthcare industry to work in a system, were it become possible to provide real-time, on demand quick medical care and services based upon individual’s requirements. Skin Monitoring is one of the emerging field in healthcare, which is now been taken care of using IoT and Cloud integrated services. The systems permit skincare providers to diagnose and cure the disease by automatically collecting information from the advanced system. Fast decision making and preventive cure based on the data ensure early diagnosis and quick treatment. Connected devices in skin monitoring System can offer many advantages; however, being a part of network there is an increased risk to both to privacy and security. The paper proposes a layered architecture of a unified IoT-based skin monitoring system and discusses different outlooks towards existing security and privacy challenges within the systems.}
}
@article{REZAEI2022103484,
title = {A fast sliding-mode-based estimation of state-of-charge for Lithium-ion batteries for electric vehicle applications},
journal = {Journal of Energy Storage},
volume = {45},
pages = {103484},
year = {2022},
issn = {2352-152X},
doi = {https://doi.org/10.1016/j.est.2021.103484},
url = {https://www.sciencedirect.com/science/article/pii/S2352152X21011671},
author = {Omid Rezaei and Hossein Azizi Moghaddam and Behnaz Papari},
keywords = {Energy storage, State of charge, Estimation, Lithium-ion battery, Robust estimator, Sliding mode observer, Fast estimation},
abstract = {This paper present a 2- order fast embossing non-singular terminal sliding mode observer (2-FENSTSMO) for the state of charge (SoC) estimation of lithium-ion batteries. As these batteries have nonlinearities and uncertainties in their dynamic model, to estimate their SoC accurately a robust and nonlinear estimator is required. The sliding mode observers have chattering phenomena and prolong convergence time in their performance but the proposed observer tackles these problems and provides less chattering and convergence time. First, a second-order fast non-singular terminal manifold based on estimation error is defined, and then, according to the Lyapunov stability theory, in order to make a Lyapunov function descending, an appropriate control law is selected. An equivalent circuit model (ECM) for the battery including uncertainty is considered to design the proposed FNTSM observer. The stability of the proposed method is provided and the simulation and experimental results confirm the effectiveness of the proposed method.}
}
@article{MONTESANO2013153,
title = {Achieving accuracy requirements for forest biomass mapping: A spaceborne data fusion method for estimating forest biomass and LiDAR sampling error},
journal = {Remote Sensing of Environment},
volume = {130},
pages = {153-170},
year = {2013},
issn = {0034-4257},
doi = {https://doi.org/10.1016/j.rse.2012.11.016},
url = {https://www.sciencedirect.com/science/article/pii/S0034425712004488},
author = {P.M. Montesano and B.D. Cook and G. Sun and M. Simard and R.F. Nelson and K.J. Ranson and Z. Zhang and S. Luthcke},
keywords = {LiDAR, Biomass, Sampling error, SAR, Data fusion},
abstract = {The synergistic use of active and passive remote sensing (i.e., data fusion) demonstrates the ability of spaceborne light detection and ranging (LiDAR), synthetic aperture radar (SAR) and multispectral imagery for achieving the accuracy requirements of a global forest biomass mapping mission (±20Mgha−1 or 20%, the greater of the two, for at least 80% of grid cells). A data fusion approach also provides a means to extend 3D information from discrete spaceborne LiDAR measurements of forest structure across scales much larger than that of the LiDAR footprint. For estimating biomass, these measurements mix a number of errors including those associated with LiDAR footprint sampling over regional–global extents. A general framework for mapping above ground live forest biomass density (AGB) with a data fusion approach is presented and verified using data from NASA field campaigns near Howland, ME, USA, to assess AGB and LiDAR sampling errors across a regionally representative landscape. We combined SAR and Landsat-derived optical (passive optical) image data to identify contiguous areas (>0.5ha) that are relatively homogenous in remote sensing metrics (forest patches). We used this image-derived data with simulated spaceborne LiDAR derived from orbit and cloud cover simulations and airborne data from NASA's Laser Vegetation Imaging Sensor (LVIS) to compute AGB and estimate LiDAR sampling error for forest patches and 100m, 250m, 500m, and 1km grid cells. At both the patch and grid scales, we evaluated differences in AGB estimation and sampling error from the combined use of LiDAR with both SAR and passive optical and with either SAR or passive optical alone. First, this data fusion approach demonstrates that incorporating forest patches into the AGB mapping framework can provide sub-grid forest information for coarser grid-level AGB reporting. Second, a data fusion approach for estimating AGB using simulated spaceborne LiDAR with SAR and passive optical image combinations reduced forest AGB sampling errors 12%–38% from those where LiDAR is used with SAR or passive optical alone. In absolute terms, sampling errors were reduced from 14–40Mgha−1 to 11–28Mgha−1 across all grid scales and prediction methods, where minimum sampling errors were 11, 15, 18, and 22Mgha−1 for 1km, 500m, 250m, and 100m grid scales, respectively. Third, spaceborne global scale accuracy requirements were achieved whereby at least 80% of the grid cells at 100m, 250m, 500m, and 1km grid levels met AGB accuracy requirements using a combination of passive optical and SAR along with machine learning methods to predict vegetation structure metrics for forested areas without LiDAR samples. Finally, using either passive optical or SAR, accuracy requirements were met at the 500m and 250m grid level, respectively.}
}
@article{HAJIYEV2012189,
title = {Tracy–Widom distribution based fault detection approach: Application to aircraft sensor/actuator fault detection},
journal = {ISA Transactions},
volume = {51},
number = {1},
pages = {189-197},
year = {2012},
issn = {0019-0578},
doi = {https://doi.org/10.1016/j.isatra.2011.07.008},
url = {https://www.sciencedirect.com/science/article/pii/S0019057811000814},
author = {Ch. Hajiyev},
keywords = {Fault detection, Kalman filtering, Innovation covariance, Largest eigenvalue, Aircraft, Flight control system},
abstract = {The fault detection approach based on the Tracy–Widom distribution is presented and applied to the aircraft flight control system. An operative method of testing the innovation covariance of the Kalman filter is proposed. The maximal eigenvalue of the random Wishart matrix is used as the monitoring statistic, and the testing problem is reduced to determine the asymptotics for the largest eigenvalue of the Wishart matrix. As a result, an algorithm for testing the innovation covariance based on the Tracy–Widom distribution is proposed. In the simulations, the longitudinal and lateral dynamics of the F-16 aircraft model is considered, and detection of sensor and control surface faults in the flight control system which affect the innovation covariance, are examined.}
}
@article{LIMA20145709,
title = {Trajectory Tracking, Pose Regulation and Adaptive Formation Control of a Group of Nonholonomic Mobile Robots},
journal = {IFAC Proceedings Volumes},
volume = {47},
number = {3},
pages = {5709-5714},
year = {2014},
note = {19th IFAC World Congress},
issn = {1474-6670},
doi = {https://doi.org/10.3182/20140824-6-ZA-1003.02608},
url = {https://www.sciencedirect.com/science/article/pii/S1474667016425048},
author = {Aurelio Lima and Josiel A. Gouvea and Fernando Lizarralde and Liu Hsu},
keywords = {multiagent formation, adaptive control, formation orientation, tracking control},
abstract = {In this paper the formation and trajectory tracking control problem for multi-agent systems is presented. Initially, a control strategy for a group of holonomic robots is proposed. The proposed control is extended to the nonholonomic case. The control scheme is based on potential functions which make possible the design of decentralized formation control scheme while avoiding agents collisions. The trajectory tracking is achieved defining leaders which attract the formation to a desired trajectory. Furthermore, if at least two leaders are defined, the formation orientation tends to a desired pose (for the planar case). Assuming that the communication graph is always connected, a stability analysis using Lyapunov theory ensures the minimization of the potential function and the trajectory tracking. The control strategies are verified by simulation.}
}
@article{DAI201914,
title = {A scheduling algorithm for autonomous driving tasks on mobile edge computing servers},
journal = {Journal of Systems Architecture},
volume = {94},
pages = {14-23},
year = {2019},
issn = {1383-7621},
doi = {https://doi.org/10.1016/j.sysarc.2019.02.004},
url = {https://www.sciencedirect.com/science/article/pii/S1383762118304831},
author = {Hongjun Dai and Xiangyu Zeng and Zhilou Yu and Tingting Wang},
keywords = {Autonomous driving, Mobile edge computing, Task scheduling, Earliest deadline first},
abstract = {Autonomous driving has received widespread attention in recent years, while the limited battery life and computing capability of autonomous vehicles cannot support some necessary computation-intensive and urgent tasks with strict response time requirements. The results of the tasks would be useless and may cause serious safety hazards if the given time constraints are exceeded. On the other side, mobile edge computing (MEC) offers the possibility of autonomous vehicles to complete these time-constraint tasks due to its proximity and strong computing capabilities, with the faster 5G wireless networks to enable vehicles and MEC servers to exchange data in milliseconds. Then, it is a key issue to make the MEC servers to execute and complete these time-constraint autonomous-driving tasks as many as possible. So, we propose a task scheduling algorithm that can consider characteristics of autonomous-driving tasks and select more suitable MEC servers with task migration, based on an improved earliest deadline first algorithm through the replacement and recombination of tasks. From the experimental results, it can be concluded that the algorithm can schedule more tasks and benefit the urgent tasks effectively with the increase of the task amounts.}
}
@article{FAN2021108221,
title = {Temporal characterization of minute-level PM2.5 variation within a local monitoring network using DWT-DTW},
journal = {Building and Environment},
volume = {205},
pages = {108221},
year = {2021},
issn = {0360-1323},
doi = {https://doi.org/10.1016/j.buildenv.2021.108221},
url = {https://www.sciencedirect.com/science/article/pii/S0360132321006223},
author = {Yuli Fan and Qingming Zhan and Lujia Tang and Huimin Liu and Sihang Gao},
keywords = {Fine particulate matter, Urban, Wavelet, Dynamic time warping, Time series, Fine-grained},
abstract = {Meticulously understanding the local processes of particulate pollution can help evaluate and mitigate its impact on residents. However, this issue is not sufficiently addressed on intra-community scales, as the characterization and comparison of short-term variations in urban environment is challenged by dynamic misalignment. Our study integrates discrete wavelet transforms (DWT) and dynamic time warping (DTW) to tackle this problem, and formulate practical pollution process indicators from a time-domain perspective. Specifically, original PM2.5 series are decomposed into multi-scale wavelet approximates, which are temporally realigned using DTW. Then, background variation series is estimated by seeking commonality among the majority of stations on time and frequency domains. Indicators are calculated by comparing local PM2.5 variation and estimated background variation, thus describing the local processes of background pollution episodes and discovering possible local pollution incidents. On this basis, empirical analysis in a campus network identified distinct information conveyed on different temporal scales. Case study discovered four phases within a 3-day period based on changes in dominating temporal scale of the background series, which is consistent with known pollution processes. Respective investigations of each phase show good capability in reflecting the influence of terrain, meteorology and dominant emission sources. Inter-station comparisons suggest significant influence from micro-scale spatial environment even when subject to exterior emissions. In general, the method can provide pertinent indicators for evaluation, prediction and optimization efforts in local pollution mitigation. The empirical results imply potentials of urban design measures for such mitigation, on which our future studies will focus.}
}
@article{CAO2020105530,
title = {Discrete-time incremental backstepping controller for unmanned aircrafts subject to actuator constraints},
journal = {Aerospace Science and Technology},
volume = {96},
pages = {105530},
year = {2020},
issn = {1270-9638},
doi = {https://doi.org/10.1016/j.ast.2019.105530},
url = {https://www.sciencedirect.com/science/article/pii/S1270963819308387},
author = {Lijia Cao and Xiaofeng Li and Yu Hu and Mingtao Liu and Jiefu Li},
keywords = {Unmanned aircraft, Discrete-time incremental backstepping (DTIBS), Incremental nonlinear dynamic (INDI), Time-delayed control (TDC), Actuator constraints},
abstract = {In the study, a discrete-time incremental backstepping (DTIBS) controller is proposed for the aircrafts with unknown actuator dynamics. Taylor series and approximating discretization approach are used, and thus the second-order continuous-time nonlinear system is modified as a discrete-time nonlinear plant in which input is in an incremental form. The incremental control laws are designed by using the incremental nonlinear dynamic inversion (INDI) approach and time-delayed control (TDC) method incorporating the robust terms by applying a standard gradient-based adaption method and the chain-rule. The TDC is introduced to design the control law, and thus concrete prior knowledge of the control effectiveness matrix involving a few unknown aerodynamic coefficients is not required. Furthermore, the stable linear filters in the discrete-time form are designed to compensate for the filtered errors and actuator dynamics. A comparison of the numerical simulation results verifies that DTIBS with the robust terms can significantly improve tracking performance. Root mean square error of the whole tracking process (RMSEOTP) is defined to demonstrate the high tracking accuracy of the controller.}
}
@article{ALLGOWER2019147,
title = {Position paper on the challenges posed by modern applications to cyber-physical systems theory},
journal = {Nonlinear Analysis: Hybrid Systems},
volume = {34},
pages = {147-165},
year = {2019},
issn = {1751-570X},
doi = {https://doi.org/10.1016/j.nahs.2019.05.007},
url = {https://www.sciencedirect.com/science/article/pii/S1751570X19300603},
author = {Frank Allgöwer and João {Borges de Sousa} and James Kapinski and Pieter Mosterman and Jens Oehlerking and Patrick Panciatici and Maria Prandini and Akshay Rajhans and Paulo Tabuada and Philipp Wenzelburger},
keywords = {cyber–physical systems theory},
abstract = {Cyber-physical systems theory offers a powerful framework for modeling, analyzing, and designing real engineering systems integrating communication, control, and computation functionalities (the cyber part) within a natural and/or man-made system governed by the laws of physics (the physical part). New methodological developments in cyber-physical systems theory are required by traditional application domains such as manufacturing, transportation, and energy systems, which are currently experiencing significant and – to some extent – revolutionary changes to address the needs of our modern society. The goal of this position paper is to provide the cyber-physical systems community, and especially young researchers, a clear view on what are research directions worth pursuing motivated by the challenges posed by modern applications.}
}
@article{MU2020103433,
title = {The status and stability of permafrost carbon on the Tibetan Plateau},
journal = {Earth-Science Reviews},
volume = {211},
pages = {103433},
year = {2020},
issn = {0012-8252},
doi = {https://doi.org/10.1016/j.earscirev.2020.103433},
url = {https://www.sciencedirect.com/science/article/pii/S0012825220304797},
author = {Cuicui Mu and Benjamin W. Abbott and Adam J. Norris and Mei Mu and Chenyan Fan and Xu Chen and Lin Jia and Ruimin Yang and Tingjun Zhang and Kang Wang and Xiaoqing Peng and Qingbai Wu and Georg Guggenberger and Xiaodong Wu},
keywords = {Soil organic carbon, greenhouse gas, temperature sensitivity, thaw slumps, thermokarst lakes, permafrost, Tibetan Plateau},
abstract = {Permafrost regions at high latitudes and altitudes store about half of the Earth's soil organic carbon (SOC). These areas are also some of the most intensely affected by anthropogenic climate change. The Tibetan Plateau or Third Pole (TP) contains most of the world's alpine permafrost, yet there remains substantial uncertainty about the role of this region in regulating the overall permafrost climate feedback. Here, we review the thermal and biogeochemical status of permafrost on the TP, with a particular focus on SOC stocks and vulnerability in the face of climate warming. SOC storage in permafrost-affected regions of the TP is estimated to be 19.0±6.6 Pg to a depth of 2 m. The distribution of this SOC on the TP is strongly associated with active layer thickness, soil moisture, soil texture, topographic position, and thickness of weathered parent material. The mean temperature sensitivity coefficient (Q10) of SOC decomposition is 9.2±7.1 across different soil depths and under different land-cover types, suggesting that carbon on the TP is very vulnerable to climate change. While the TP ecosystem currently is a net carbon sink, climate change will likely increase ecosystem respiration and may weaken or reverse the sink function of this region in the future. Although the TP has less ground ice than high latitude permafrost regions, the rugged topography makes it vulnerable to widespread permafrost collapse and thermo-erosion (thermokarst), which accelerates carbon losses. To reduce uncertainty about SOC quantities and sensitivity to warming, future studies are needed that explain variation in Q10 (e.g. based on SOC source or depositional position) and quantify the role of nutrient availability in regulating SOC dynamics and ecosystem recovery following disturbance. Additionally, as for the high latitude permafrost region, soil moisture and thermokarst formation remain major challenges to predicting the permafrost climate feedback on the TP. We present a conceptual model for of greenhouse gas release from the TP and outline the empirical observations and modeling approaches needed to test it.}
}
@article{TAMKAYA2019105379,
title = {H∞-based model following method in autolanding systems},
journal = {Aerospace Science and Technology},
volume = {94},
pages = {105379},
year = {2019},
issn = {1270-9638},
doi = {https://doi.org/10.1016/j.ast.2019.105379},
url = {https://www.sciencedirect.com/science/article/pii/S1270963819305152},
author = {K. Tamkaya and L. Ucun and I. Ustoglu},
keywords = {Aircraft landing,  synthesis, Model following, Flare, Windshear, Linear Matrix Inequality (LMI)},
abstract = {Probably the most important part during a flight is the landing phase because most of the accidents occur in this phase. Automatic landing systems (ALS) take over the control during this phase to avoid potential pilot-induced risks. However, some external disturbances such as windshear can jeopardize the safe landing. In this paper, the flare part of ALS is handled in a different way. A combination of some useful design methods is brought together to improve the performance of the conventional ALS even under severe weather conditions. Model following method is combined with the H∞ synthesis method to find out the optimal solution for a given cost function. Resultant H∞ optimal control problem is solved using Linear Matrix Inequalities (LMIs) and then a dynamic controller is constructed. On the other hand, the overall system is formed into P-K configuration, thus the system can be reconfigured easily when there exists a change in the system such as addition or removal of disturbance, noise and so on. We achieved significant performance on the system without any disturbance. In addition to that, the robustness takes an important role for the flight systems and needs to be handled correctly. Therefore, two kinds of windshear are taken care of and their effects minimized in a way that the tracking performance remains unaffected. Thus, highly considerable results are obtained using the proposed method even under severe weather conditions.}
}
@article{ALQAYSI2018221,
title = {A review of disability EEG based wheelchair control system: Coherent taxonomy, open challenges and recommendations},
journal = {Computer Methods and Programs in Biomedicine},
volume = {164},
pages = {221-237},
year = {2018},
issn = {0169-2607},
doi = {https://doi.org/10.1016/j.cmpb.2018.06.012},
url = {https://www.sciencedirect.com/science/article/pii/S0169260718304620},
author = {Z.T. Al-qaysi and B.B. Zaidan and A.A. Zaidan and M.S. Suzani},
keywords = {EEG, Wheelchair, Control system, Brain–computer interface},
abstract = {Context
Intelligent wheelchair technology has recently been utilised to address several mobility problems. Techniques based on brain–computer interface (BCI) are currently used to develop electric wheelchairs. Using human brain control in wheelchairs for people with disability has elicited widespread attention due to its flexibility.
Objective
This study aims to determine the background of recent studies on wheelchair control based on BCI for disability and map the literature survey into a coherent taxonomy. The study intends to identify the most important aspects in this emerging field as an impetus for using BCI for disability in electric-powered wheelchair (EPW) control, which remains a challenge. The study also attempts to provide recommendations for solving other existing limitations and challenges.
Methods
We systematically searched all articles about EPW control based on BCI for disability in three popular databases: ScienceDirect, IEEE and Web of Science. These databases contain numerous articles that considerably influenced this field and cover most of the relevant theoretical and technical issues.
Results
We selected 100 articles on the basis of our inclusion and exclusion criteria. A large set of articles (55) discussed on developing real-time wheelchair control systems based on BCI for disability signals. Another set of articles (25) focused on analysing BCI for disability signals for wheelchair control. The third set of articles (14) considered the simulation of wheelchair control based on BCI for disability signals. Four articles designed a framework for wheelchair control based on BCI for disability signals. Finally, one article reviewed concerns regarding wheelchair control based on BCI for disability signals.
Discussion
Since 2007, researchers have pursued the possibility of using BCI for disability in EPW control through different approaches. Regardless of type, articles have focused on addressing limitations that impede the full efficiency of BCI for disability and recommended solutions for these limitations.
Conclusions
Studies on wheelchair control based on BCI for disability considerably influence society due to the large number of people with disability. Therefore, we aim to provide researchers and developers with a clear understanding of this platform and highlight the challenges and gaps in the current and future studies.}
}
@article{RITTGER2021112608,
title = {Multi-sensor fusion using random forests for daily fractional snow cover at 30 m},
journal = {Remote Sensing of Environment},
volume = {264},
pages = {112608},
year = {2021},
issn = {0034-4257},
doi = {https://doi.org/10.1016/j.rse.2021.112608},
url = {https://www.sciencedirect.com/science/article/pii/S003442572100328X},
author = {Karl Rittger and Mitchell Krock and William Kleiber and Edward H. Bair and Mary J. Brodzik and Thomas R. Stephenson and Balaji Rajagopalan and Kat J. Bormann and Thomas H. Painter},
keywords = {MODIS, Landsat, Fractional snow cover, Fusion, Downscaling, Spectral mixture analysis, Random forest},
abstract = {In addition to providing water for nearly 2 billion people, snow drives resource selection by wildlife and influences the behavior and demography of many species. Because snow cover is highly spatially and temporally variable, mapping its extent using currently available satellite data remains a challenge. At present, there are no sensors acquiring daily data of Earth's entire surface at fine spatial resolutions (< 30 m) in wavelengths required for snow cover retrieval, namely: visible, near-infrared, and shortwave infrared. Fine scale observations at 30 m from Landsat are available at 16-day intervals since 1982 and at 8-day intervals since 1999. However, over this duration, snow can accumulate, ablate, or both, making the Landsat data ineffective for many applications. Conversely, the Moderate Resolution Imaging Spectroradiometer (MODIS) atmospherically corrected daily reflectance data, have a coarse spatial resolution of 463 m and thus, are not ideal for snow cover mapping either. This spatial and temporal resolution tradeoff limits the use of these data for a wide range of snow cover applications and indicates a pressing need for data fusion. To address this need, we use a physically-based, spectral-mixture-analysis approach for mapping fractional snow cover (fSCA) and a two-stage random forest algorithm to produce daily 30 m fSCA. We test our algorithm in the US Sierra Nevada and find MODIS fSCA is the most important predictor. We cross validate using 170 Landsat scenes and while snow cover varies immensely in time we find little variation in errors between seasons, a small bias of 0.01, and an overall accuracy of 0.97 with slightly higher precision than recall. This technique for accurate, daily, high-resolution snow cover retrievals could be applied more broadly for analyses of regional energy budget, validating snow cover in global and regional models, and for quantifying changes in the availability of biotic resources in ecosystems.}
}
@article{SCANZIO2021103388,
title = {Heterogeneous and dependable networks in industry – A survey},
journal = {Computers in Industry},
volume = {125},
pages = {103388},
year = {2021},
issn = {0166-3615},
doi = {https://doi.org/10.1016/j.compind.2020.103388},
url = {https://www.sciencedirect.com/science/article/pii/S0166361520306229},
author = {Stefano Scanzio and Lukasz Wisniewski and Piotr Gaj},
keywords = {Industrial networks, Heterogeneity, Dependability, Interoperability, Real-time, Reliability, Ethernet, Wireless, Wi-Fi, WSAN, SDN, TSN, 5G, CPS, IIoT, I4.0},
abstract = {The real and effective ground of all new concepts dedicated to the current advanced factories, as well as to the future digital ones, is close cooperativity of scattered applications in highly heterogeneous systems. Communication is the key enabling component, and all new approaches are inspired in practice to the demanding characteristics of industrial networks. These kinds of computer networks, together with new technologies derived from distant application fields, are the main technological means to accelerate the fast evolution of modern factory systems. Due to various communication requirements coming from the plurality of structures, components and application contexts, communication subsystems must be increasingly heterogeneous. Let us say clearly: this evolution cannot be stopped at this stage, no special universal solution is possible, and thinking about monogamous networking is a kind of dreamland. This paper is an analysis of the state of the art in the matter of heterogeneous networking in industry. It deeply investigates both wired and wireless technologies from the point of view of technological aspects and relevant key performance indicators, such as those related to dependability, and it contains a prospective estimation of future trends.}
}
@article{MAGANCARRION201623,
title = {Optimal relay placement in multi-hop wireless networks},
journal = {Ad Hoc Networks},
volume = {46},
pages = {23-36},
year = {2016},
issn = {1570-8705},
doi = {https://doi.org/10.1016/j.adhoc.2016.03.007},
url = {https://www.sciencedirect.com/science/article/pii/S1570870516300841},
author = {Roberto Magán-Carrión and Rafael A. Rodríguez-Gómez and José Camacho and Pedro García-Teodoro},
keywords = {Node placement, Multi-hop route, Optimization process, Relay node, Wireless network},
abstract = {Relay node placement in wireless environments is a research topic recurrently studied in the specialized literature. A variety of network performance goals, such as coverage, data rate and network lifetime, are considered as criteria to lead the placement of the nodes. In this work, a new relay placement approach to maximize network connectivity in a multi-hop wireless network is presented. Here, connectivity is defined as a combination of inter-node reachability and network throughput. The nodes are placed following a two-step procedure: (i) initial distribution, and (ii) solution selection. Additionally, a third stage for placement optimization is optionally proposed to maximize throughput. This tries to be a general approach for placement, and several initialization, selection and optimization algorithms can be used in each of the steps. For experimentation purposes, a leave-one-out selection procedure and a PSO related optimization algorithm are employed and evaluated for second and third stages, respectively. Other node placement solutions available in the literature are compared with the proposed one in realistic simulated scenarios. The results obtained through the properly devised experiments show the improvements achieved by the proposed approach.}
}
@article{CAI2019201,
title = {Infrared and visible image fusion based on BEMSD and improved fuzzy set},
journal = {Infrared Physics & Technology},
volume = {98},
pages = {201-211},
year = {2019},
issn = {1350-4495},
doi = {https://doi.org/10.1016/j.infrared.2019.03.013},
url = {https://www.sciencedirect.com/science/article/pii/S135044951830793X},
author = {Huaiyu Cai and Liran Zhuo and Xiaodong Chen and Weiqian Zhang},
keywords = {Image fusion, Infrared and visible image, BEMD, Fuzzy set},
abstract = {This study proposes a new fusion framework to solve the problem of weak self-adaptation in traditional multiscale transformation. A non-subsampled shearlet transform (NSST) decomposes the source image in multiscales and multidirections through a non-subsampled pyramid and shearlet transform. There is a problem in that the filter bank needs to be designed independently. The characteristics of the source images cannot be fully utilized. Bidimensional empirical mode decomposition (BEMD) can obtain a set of intrinsic mode functions (IMFs) and a residue according to the characteristics of the image itself. The high-frequency and low-frequency information decomposed by BEMD are more suitable to the source image features. Thus, using BEMD instead of the non-subsampled pyramid in an NSST allows the fusion framework to analyze the characteristics of the image with better multiscale and multidirection adaptability. For the proposed fusion framework, the corresponding fusion rules are needed. In this study, an improved fuzzy set is used as the low-frequency fusion rule. A contrast analysis combined with Euclidean distance is used as the high-frequency fusion rule. The proposed fusion rules are designed to enhance the adaptability while preserving the details of the source image as much as possible. The experimental results demonstrate that compared with the traditional method, the fusion results obtained by the proposed method are more realistic, and the infrared targets are more evident. Furthermore, the objective evaluation metrics are better.}
}
@article{LAPKOVSKY2021631,
title = {An approach to finding sources of pollution to maintain stable air quality},
journal = {IFAC-PapersOnLine},
volume = {54},
number = {13},
pages = {631-635},
year = {2021},
note = {20th IFAC Conference on Technology, Culture, and International Stability TECIS 2021},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2021.10.521},
url = {https://www.sciencedirect.com/science/article/pii/S2405896321019583},
author = {Roman Yu. Lapkovsky and Vladimir A. Ivashchenko and Nikita V. Lugovoy and Iraida A. Stepanovskaya},
keywords = {Ecology, Environmental Stability, Monitoring, Measuring, Distributed Database, Analysis of Measuring Information, Air Pollution},
abstract = {Preparation of control actions carried out at various levels to maintain a stable quality of atmospheric air includes measures to identify pollution sources and assess their cumulative impact on atmospheric air quality. We propose an approach to searching for air pollution sources based on continuous observations in a unified environmental monitoring system. The method includes primary processing, storage, and referencing large amounts of measurement information to a time grid. The process provides a more accurate binding of the measurement information to a moment in time and a point in space to provide additional filtering of data and a compact form of storage of measurement information. The proposed approach includes methods for analyzing the accumulated measurement information, making it possible to identify individual terrain areas with potential pollution sources. Data from atmospheric air quality and meteorological parameters from various terrain points, integrated into a unified environmental monitoring system, are used as the initial data. We have developed a software and hardware complex, which forms the basis of environmental monitoring systems operating in several departments and enterprises of the Russian Federation. The proposed solutions are scaled by adding additional nodes and levels. The regional network integrates already existing local systems. The approach’s novelty lies in binding the measurement information to the time grid to store the data and its analysis approach. Managers could search for potential sources of pollution more effectively to further assess their cumulative impact on atmospheric air quality and determine the effects of reducing this impact on acceptable values.}
}
@article{FENG2021105565,
title = {Analysis of the attributes of rights to inferred information and China's choice of legal regulation},
journal = {Computer Law & Security Review},
volume = {41},
pages = {105565},
year = {2021},
issn = {0267-3649},
doi = {https://doi.org/10.1016/j.clsr.2021.105565},
url = {https://www.sciencedirect.com/science/article/pii/S0267364921000388},
author = {Fei Feng and Xia Wang and Tianxiang Chen},
keywords = {Inferred information, Right to personal information, Right to privacy, Intellectual property, Legal regulation},
abstract = {Researchers who study data collection, analysis, and use in the era of big data and algorithms are paying increased attention to inferred uses. The information inferred by an algorithm has distinct personality and property interests and challenges existing theories of personal information and privacy. However, a complete method of legal regulation for such information does not yet exist in China. This article focuses on how to recognize the nature of inferred information and how to carry out appropriate legal evaluation and regulation to better protect the legitimate rights and interests of relevant subjects in China. Based on China's social needs and judicial practice experience, the "contextual integrity" privacy theory developed by Professor Nissenbaum can be used to evaluate whether inferred information is infringed upon, and we believe that China is likely to adopt the US regulatory model.}
}
@article{ODRY2018569,
title = {Kalman filter for mobile-robot attitude estimation: Novel optimized and adaptive solutions},
journal = {Mechanical Systems and Signal Processing},
volume = {110},
pages = {569-589},
year = {2018},
issn = {0888-3270},
doi = {https://doi.org/10.1016/j.ymssp.2018.03.053},
url = {https://www.sciencedirect.com/science/article/pii/S088832701830181X},
author = {Ákos Odry and Róbert Fullér and Imre J. Rudas and Péter Odry},
keywords = {Adaptive filter, Attitude determination, Filter tuning, Inertial measurement unit, Kalman filter, Sensor fusion},
abstract = {This paper proposes two novel approaches to estimate accurately mobile robot attitudes based on the fusion of low-cost accelerometers and gyroscopes. The first part of the paper demonstrates the use of a special test bench that both enables simulations of various dynamic behaviors of wheeled robots and measures their real attitude angles along with the raw sensor data. These measurements are applied in a simulation environment and we outline an offline optimization of Kalman filter parameters. The second part of the paper introduces a novel adaptive Kalman filter structure that modifies the noise covariance values according to the system dynamics. The instantaneous dynamics are characterized regarding the magnitudes of both the instantaneous vibration and the external acceleration. The proposed adaptive solution measures these magnitudes and utilizes fuzzy-logic to modify the filter parameters in real time. The results show that the adaptive filter improves the overall filter convergence by a remarkable 10.9% over using the optimized Kalman filter, thereby demonstrating its efficacy as an accurate and robust attitude filter. The proposed filter performances are also benchmarked against other common methods indicating that the flexibility of the developed adaptive filter allowed it to compete and even outperform the benchmark filters.}
}
@article{THOMSON2020114670,
title = {Use of traditional, modern, and hybrid modelling approaches for in situ prediction of dry matter yield and nutritive characteristics of pasture using hyperspectral datasets},
journal = {Animal Feed Science and Technology},
volume = {269},
pages = {114670},
year = {2020},
issn = {0377-8401},
doi = {https://doi.org/10.1016/j.anifeedsci.2020.114670},
url = {https://www.sciencedirect.com/science/article/pii/S0377840120305745},
author = {Anna L. Thomson and Senani B. Karunaratne and Amy Copland and Danielle Stayches and Elizabeth Morse McNabb and Joe Jacobs},
keywords = {Hyperspectral data, Dairy pasture, Nutritive characteristics, Modelling method, Near-real time prediction, Non-destructive},
abstract = {To optimise grazing livestock nutrition, it is necessary to know both the available dry matter yield and the nutritive characteristics of pasture at the farm-scale in near real time. Previous studies have shown the potential of using field spectrophotometers that measure the reflectance of light across the visible to near infrared spectrums to gather information on pasture dry matter yield (DMY) and nutritive characteristics. This study sought to calibrate and validate new mathematical models for ten parameters including dry matter yield and nine nutritive characteristics of relevance to ruminant nutrition. As a part of the analysis process, two innovative approaches were tested: the use of a hybrid modelling approach where partial least squares regression (PLSR) outputs were used as support vector regression (SVR) inputs; and, the inclusion of covariate data. These approaches were compared with traditional stand-alone PLSR and SVR modelling approaches without covariates. The study was undertaken in six predominantly perennial ryegrass pastures on a single farm in the temperate zone of South-Eastern Australia. A total of 204 pasture samples were scanned with a field spectrophotometer over several spring growth stages in late 2019 and subsequently analysed by wet chemistry to obtain reference nutritive values. The raw reflectance spectra were initially pre-processed using a variety of techniques and then used to test the four kinds of chemometric models. In cross validation, hybrid models showed a superior fit for all variates in comparison to the other model types tested. However, the differential was reduced in independent validation where, out of 10 best-performing models for dry matter yield and key nutrient properties, six were produced by the hybrid modelling, three from SVR and one from PLSR. For every hybrid model that was built, adding covariate(s) consistently improved model performance but the increase was small (a reduction in normalised root mean square error (RMSE) of -0.36 % on average for all properties considered). The best performing models were comparable with other published literature with normalised RMSE of prediction ranging from 1.7 – 23.1 % (a mean of 9.7%). Well-predicted variates included metabolisable energy, digestible energy, DMY, and crude protein. Fibre fractions, ash and dry matter were less well-predicted but still had acceptable normalised RMSE values (< 10 %) while carbohydrate fractions were the poorest predicted variates. It was concluded that hybrid modelling in chemometric analyses can modestly improve accuracy and shows promise as an alternative to more traditional approaches. Using covariates also improved accuracy, but the additional time and effort to gather such information outweighed the minor benefits of inclusion.}
}
@article{KUMARGANTI2021122561,
title = {Environmental impact analysis and enhancement of factors affecting the photovoltaic (PV) energy utilization in mining industry by sparrow search optimization based gradient boosting decision tree approach},
journal = {Energy},
pages = {122561},
year = {2021},
issn = {0360-5442},
doi = {https://doi.org/10.1016/j.energy.2021.122561},
url = {https://www.sciencedirect.com/science/article/pii/S0360544221028103},
author = {Praful {Kumar Ganti} and Hrushikesh Naik and Mohanty {Kanungo Barada}},
keywords = {Mining industry, Solar photovoltaic system, Environmental impacts, Sparrow search algorithm, Gradient boosting decision tree},
abstract = {This paper proposes a hybrid technique to recover the efficiency of solar photovoltaic (PV) energy system from the environmental impacts. The proposed technique is the combination of both sparrow search algorithm and gradient boosting decision tree; thus it is named SSA-GBDT method. The purpose of the proposed technique is to improve the efficiency of solar PV energy system and maximization of power removal from PV arrays. The PV module voltage, current and power is measured by SSA and it creates possible database offline. Database with electric parameters is utilized to develop the model online using GBDT. The data set contains some parameters like particle size and dust weight input and maximal power value output variables. Then, the proposed technique is implemented on the MATLAB/Simulink platform and the performance is compared with existing techniques. The performance of PV under normal condition, dust accumulation condition, water drops condition and partial shading conditions are the considered cases. In the cases, photovoltaic reference irradiance and temperature, PV current, voltage and generated power, active and reactive power, grid current and voltage, inverter power is also evaluated. The efficiency comparison of PV power for solution processes like ANN, GBDT, SSA and proposed system are also analyzed.}
}
@article{ZHANG2021381,
title = {A dynamic scheduling method for self-organized AGVs in production logistics systems},
journal = {Procedia CIRP},
volume = {104},
pages = {381-386},
year = {2021},
note = {54th CIRP CMS 2021 - Towards Digitalized Manufacturing 4.0},
issn = {2212-8271},
doi = {https://doi.org/10.1016/j.procir.2021.11.064},
url = {https://www.sciencedirect.com/science/article/pii/S2212827121009628},
author = {Lixiang Zhang and Yan Yan and Yaoguang Hu and Weibo Ren},
keywords = {dynamic scheduling, automated guided vehicles, gene expression programming, production logistics system},
abstract = {Automated guided vehicles (AGV) with different carrying capacities are required for complex material handling in smart factories, which causes resource waste. To minimize the delay and reduce the cost of logistics systems, this paper proposes a dynamic scheduling method for self-organized AGVs (SAGV) in production logistics systems, where multiple identical SAGVs can communicate and freely combine with others as one vehicle to perform one task. Using an improved gene expression programming to learning dynamic dispatching rules, experimental results show that dispatching rules learned are efficient and the cost of logistic systems by using SAGVs is significantly reduced.}
}
@article{CASAL2020106814,
title = {Satellite-derived bathymetry in optically complex waters using a model inversion approach and Sentinel-2 data},
journal = {Estuarine, Coastal and Shelf Science},
volume = {241},
pages = {106814},
year = {2020},
issn = {0272-7714},
doi = {https://doi.org/10.1016/j.ecss.2020.106814},
url = {https://www.sciencedirect.com/science/article/pii/S0272771420302006},
author = {Gema Casal and John D. Hedley and Xavier Monteys and Paul Harris and Conor Cahalane and Tim McCarthy},
keywords = {Bathymetry, Atmospheric correction, Model inversion, Coastal monitoring},
abstract = {This study presents an assessment of a model inversion approach to derive shallow water bathymetry in optically complex waters, with the aim of both understanding localised capability and contributing to the global evaluation of Sentinel-2 for coastal monitoring. A dataset of 12 Sentinel-2 MSI images, in three different study areas along the Irish coast, has been analysed. Before the application of the bathymetric model two atmospheric correction procedures were tested: Deep Water Correction (DWC) and Case 2 Regional Coastal Color (C2RCC) processor. DWC outperformed C2RCC in the majority of the satellite images showing more consistent results. Using DWC for atmospheric correction before the application of the bathymetric model, the lowest average RMSE was found in Dublin Bay (RMSE = 1.60, bias = −0.51), followed by Mulroy Bay (RMSE = 1.66, bias = 1.30) while Brandon Bay showed the highest average error (RMSE = 2.43, bias = 1.86). However, when the optimal imagery selection was considered, depth estimations with a bias less than 0.1 m and a spread of ±1.40 m were achieved up to 10 m. These results were comparable to those achieved by empirical tuning methods, despite not relying on any in situ depth data. This conclusion is of particular relevance as model inversion approaches might allow future modifications in crucial parts of the processing chain leading to improved results. Atmospheric correction, the selection of optimal images (e.g. low turbidity), the definition of suitably limited ranges for the per-pixel occurrence of optical constituents (phytoplankton, CDOM, backscatter) and seabed reflectances, in combination with the understanding of the specifics characteristics at each particular site, were critical steps in the derivation of satellite bathymetry.}
}
@article{ZHANG2020275,
title = {Improved ecological development model for lower Yellow River floodplain, China},
journal = {Water Science and Engineering},
volume = {13},
number = {4},
pages = {275-285},
year = {2020},
issn = {1674-2370},
doi = {https://doi.org/10.1016/j.wse.2020.12.006},
url = {https://www.sciencedirect.com/science/article/pii/S1674237020300995},
author = {Jin-liang Zhang and Yi-zi Shang and Ji-xiang Liu and Jian Fu and Meng Cui},
keywords = {Ecological development, Lower Yellow River, Floodplain, Sediment, Eco-friendly construction model},
abstract = {In this study, a model for the development of the wide floodplain in the lower Yellow River Basin, in China was developed. This model includes flood control schemes using grading criteria, enables sediment deposition in partitioned zones, and allows free exchange between channel runoff and sediment. The wide floodplain located between the main channel and levees is divided into three typical regions: the tender, low, and high floodplains. Different ecological models should be applied when these floodplains are constructed. This paper describes the associated research ideas and methodology, and clarifies several key issues, including sediment prediction and regulation, land planning, land use, and a multi-dimensional framework of safeguard measures for industries on the lower Yellow River floodplain. A refined ecological development model is proposed for the lower Yellow River floodplain, and future work on ecological and sustainable development of the lower floodplain is suggested. To establish a comprehensive system integrating runoff and sediment resource regulation in the Yellow River Basin, future work should focus on runoff and sediment exchange mechanisms in the wandering lower reaches. Furthermore, it is necessary to improve theories on floodplain planning and ecological construction, and these theories should be integrated with the research findings on land development across the lower Yellow River floodplain.}
}
@article{SOUSA2020102594,
title = {A survey on QoE-oriented wireless resources scheduling},
journal = {Journal of Network and Computer Applications},
volume = {158},
pages = {102594},
year = {2020},
issn = {1084-8045},
doi = {https://doi.org/10.1016/j.jnca.2020.102594},
url = {https://www.sciencedirect.com/science/article/pii/S1084804520300680},
author = {Ivo Sousa and Maria Paula Queluz and António Rodrigues},
keywords = {Quality of experience (QoE), Scheduling, Radio resource management, Wireless networks},
abstract = {Future wireless systems are expected to provide a wide range of services to more and more users. Advanced scheduling strategies thus arise not only to perform efficient radio resource management, but also to provide fairness among the users. On the other hand, the users’ perceived quality, i.e., Quality of Experience (QoE), is becoming one of the main drivers within the schedulers design. In this context, this paper starts by providing a comprehension of what is QoE and an overview of the evolution of wireless scheduling techniques. Afterwards, a survey on the most recent QoE-based scheduling strategies for wireless systems is presented, highlighting the application/service of the different approaches reported in the literature, as well as the parameters that were taken into account for QoE optimization. Therefore, this paper aims at helping readers interested in learning the basic concepts of QoE-oriented wireless resources scheduling, as well as getting in touch with its current research frontier.}
}
@article{TULU2020102768,
title = {Influential nodes selection to enhance data dissemination in mobile social networks: A survey},
journal = {Journal of Network and Computer Applications},
volume = {169},
pages = {102768},
year = {2020},
issn = {1084-8045},
doi = {https://doi.org/10.1016/j.jnca.2020.102768},
url = {https://www.sciencedirect.com/science/article/pii/S1084804520302423},
author = {Muluneh Mekonnen Tulu and Mbazingwa E. Mkiramweni and Ronghui Hou and Sultan Feisso and Talha Younas},
keywords = {Influential nodes, Mobile social networks, Data dissemination, Wireless communications},
abstract = {Downloading of contents on mobile devices has been increasing rapidly since the introduction of mobile communication technologies. The huge traffic load presents a significant challenge to mobile network operators. Therefore, mobile social network (MSN) has been proposed to leverage cellular links by offloading mobile traffic via device-to-device communications. To do so, applying effective algorithm to identify influential spreader in MSN is of critical importance. Recently, various techniques have been proposed, each with its particular points of interest and impediments. In this paper, we provide a comprehensive survey of different techniques used to identify influential nodes in MSNs. In this regard, we discuss the advantages and disadvantages of the methods used to select initial seeds. We also review MSNs with regard to characteristics, platforms, classification, benefits, and challenges. In addition, we review data dissemination algorithms in MSNs. We then analyze and indicate the node selection complication in future networks. Finally, we outline possible future research directions and summarize the major challenges for on-going node selection in MSNs research.}
}
@article{CAO2020104,
title = {Real-time video stabilization via camera path correction and its applications to augmented reality on edge devices},
journal = {Computer Communications},
volume = {158},
pages = {104-115},
year = {2020},
issn = {0140-3664},
doi = {https://doi.org/10.1016/j.comcom.2020.05.007},
url = {https://www.sciencedirect.com/science/article/pii/S0140366420304539},
author = {Mingwei Cao and Liping Zheng and Wei Jia and Xiaoping Liu},
keywords = {Video stabilization, Augmented reality, Edge devices, Feature tracking, Camera motion estimation},
abstract = {With the rapid development of edge devices such as mobile phones, in the past decade, many videos have appeared on the professional video website and they are easy to retrieve. However, most of the videos captured by mobile cameras are jittery, and even motion blurred. These low-quality videos may affect the experience of users. Thus, the problem that how to eliminate the jittery issues, and make unstable video became stable one is very urgent. To enhance the stability of low-quality video, in this paper, we propose a novel method for video stabilization. The proposed method is called SimpleStab, and consists of motion estimation, trajectory smoothing, and compositing image. The SimpleStab is not only able to process offline videos but also can deal with live video streaming due to the novel architecture. We conduct a comprehensive experiment on the benchmarking dataset and make comparison with the state-of-the-art approaches. Experimental results show that the performance of SimpleStab is superior to the state-of-the-art methods.}
}
@article{HONG202015621,
title = {Integrated Global and Local Path Planning for Quadrotor Using Particle Swarm Optimization},
journal = {IFAC-PapersOnLine},
volume = {53},
number = {2},
pages = {15621-15625},
year = {2020},
note = {21st IFAC World Congress},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2020.12.2497},
url = {https://www.sciencedirect.com/science/article/pii/S2405896320332213},
author = {Youkyung Hong and Suseong Kim and Jihun Cha},
keywords = {Quadrotor, Path Planning, Particle Swarm Optimization, Minimum Snap Trajectory},
abstract = {This study proposes a new path planning method for quadrotors to determine a set of waypoints by considering both geometric constraints to avoid collisions with obstacles and dynamic constraints to reflect the dynamic characteristics of the quadrotor. The proposed path planning method can be formulated as a non-linear optimization problem that minimizes the Euclidean distance between waypoints while satisfying the geometric and dynamic constraints. Particle swarm optimization is utilized to solve the non-linear optimization problem efficiently. By utilizing the Gazebo simulator, the performance of the proposed path planning method is validated for a quadrotor.}
}
@article{ZOU2019461,
title = {Collaborative visual SLAM for multiple agents:A brief survey},
journal = {Virtual Reality & Intelligent Hardware},
volume = {1},
number = {5},
pages = {461-482},
year = {2019},
note = {3D Vision},
issn = {2096-5796},
doi = {https://doi.org/10.1016/j.vrih.2019.09.002},
url = {https://www.sciencedirect.com/science/article/pii/S2096579619300634},
author = {Danping Zou and Ping Tan and Wenxian Yu},
keywords = {Visual SLAM, Multiple agent, UAV swarm, Collaborative AR/VR},
abstract = {This article presents a brief survey to visual simultaneous localization and mapping (SLAM) systems applied to multiple independently moving agents, such as a team of ground or aerial vehicles, a group of users holding augmented or virtual reality devices. Such visual SLAM system, name as collaborative visual SLAM, is different from a typical visual SLAM deployed on a single agent in that information is exchanged or shared among different agents to achieve better robustness, efficiency, and accuracy. We review the representative works on this topic proposed in the past ten years and describe the key components involved in designing such a system including collaborative pose estimation and mapping tasks, as well as the emerging topic of decentralized architecture. We believe this brief survey could be helpful to someone who are working on this topic or developing multi-agent applications, particularly micro-aerial vehicle swarm or collaborative augmented/virtual reality.}
}
@article{HE2021824,
title = {Construction of carbonate reservoir knowledge base and its application in fracture-cavity reservoir geological modeling},
journal = {Petroleum Exploration and Development},
volume = {48},
number = {4},
pages = {824-834},
year = {2021},
issn = {1876-3804},
doi = {https://doi.org/10.1016/S1876-3804(21)60069-1},
url = {https://www.sciencedirect.com/science/article/pii/S1876380421600691},
author = {Zhiliang HE and Jianfang SUN and Panhong GUO and Hehua WEI and Xinrui LYU and Kelong HAN},
keywords = {knowledge management, reservoir knowledge base, fracture-cavity reservoir, geological modeling, carbonates, paleo-underground river system, Tahe oilfield, Tarim Basin},
abstract = {To improve the efficiency and accuracy of carbonate reservoir research, a unified reservoir knowledge base linking geological knowledge management with reservoir research is proposed. The reservoir knowledge base serves high-quality analysis, evaluation, description and geological modeling of reservoirs. The knowledge framework is divided into three categories: technical service standard, technical research method and professional knowledge and cases related to geological objects. In order to build a knowledge base, first of all, it is necessary to form a knowledge classification system and knowledge description standards; secondly, to sort out theoretical understandings and various technical methods for different geologic objects and work out a technical service standard package according to the technical standard; thirdly, to collect typical outcrop and reservoir cases, constantly expand the content of the knowledge base through systematic extraction, sorting and saving, and construct professional knowledge about geological objects. Through the use of encyclopedia based collaborative editing architecture, knowledge construction and sharing can be realized. Geological objects and related attribute parameters can be automatically extracted by using natural language processing (NLP) technology, and outcrop data can be collected by using modern fine measurement technology, to enhance the efficiency of knowledge acquisition, extraction and sorting. In this paper, the geological modeling of fracture-cavity reservoir in the Tarim Basin is taken as an example to illustrate the construction of knowledge base of carbonate reservoir and its application in geological modeling of fracture-cavity carbonate reservoir.}
}
@article{LAUFS2020102023,
title = {Security and the smart city: A systematic review},
journal = {Sustainable Cities and Society},
volume = {55},
pages = {102023},
year = {2020},
issn = {2210-6707},
doi = {https://doi.org/10.1016/j.scs.2020.102023},
url = {https://www.sciencedirect.com/science/article/pii/S221067072030010X},
author = {Julian Laufs and Hervé Borrion and Ben Bradford},
keywords = {Systematic review, Smart cities, Safe city, Security technologies, Security functions},
abstract = {The implementation of smart technology in cities is often hailed as the solution to many urban challenges such as transportation, waste management, and environmental protection. Issues of security and crime prevention, however, are in many cases neglected. Moreover, when researchers do introduce new smart security technologies, they rarely discuss their implementation or question how new smart city security might affect traditional policing and urban planning processes. This systematic review explores the recent literature concerned with new ‘smart city’ security technologies and aims to investigate to what extent these new interventions correspond with traditional functions of security interventions. Through an extensive literature search we compiled a list of security interventions for smart cities and suggest several changes to the conceptual status quo in the field. Ultimately, we propose three clear categories to categorise security interventions in smart cities: Those interventions that use new sensors but traditional actuators, those that seek to make old systems smart, and those that introduce entirely new functions. These themes are then discussed in detail and the importance of each group of interventions for the overall field of urban security and governance is assessed.}
}
@article{KHAN2020106522,
title = {Industrial internet of things: Recent advances, enabling technologies and open challenges},
journal = {Computers & Electrical Engineering},
volume = {81},
pages = {106522},
year = {2020},
issn = {0045-7906},
doi = {https://doi.org/10.1016/j.compeleceng.2019.106522},
url = {https://www.sciencedirect.com/science/article/pii/S0045790618329550},
author = {W.Z. Khan and M.H. Rehman and H.M. Zangoti and M.K. Afzal and N. Armi and K. Salah},
keywords = {Industrial internet of things, Industry 4.0, Cyber physical systems, Cloud computing, Blockchain, Artificial intelligence, Virtual reality},
abstract = {The adoption of emerging technological trends and applications of the Internet of Things (IoT) in the industrial systems is leading towards the development of Industrial IoT (IIoT). IIoT serves as a new vision of IoT in the industrial sector by automating smart objects for sensing, collecting, processing and communicating the real-time events in industrial systems. The major objective of IIoT is to achieve high operational efficiency, increased productivity, and better management of industrial assets and processes through product customization, intelligent monitoring applications for production floor shops and machine health, and predictive and preventive maintenance of industrial equipment. In this paper, we present a new and clear definition of IIoT, which can help the readers to understand the concept of IIoT. We have described the state-of-the-art research efforts in IIoT. Finally, we have highlighted the enabling technologies for IIoT and recent challenges faced by IIoT.}
}
@article{WANG20191805,
title = {The exposure of slums to high temperature: Morphology-based local scale thermal patterns},
journal = {Science of The Total Environment},
volume = {650},
pages = {1805-1817},
year = {2019},
issn = {0048-9697},
doi = {https://doi.org/10.1016/j.scitotenv.2018.09.324},
url = {https://www.sciencedirect.com/science/article/pii/S0048969718337811},
author = {Jiong Wang and Monika Kuffer and Richard Sliuzas and Divyani Kohli},
keywords = {Slums, Local scale, LST, Morphological patterns, MODIS, Ahmedabad, India},
abstract = {Heat exposure has become a global threat to human health and life with increasing temperatures and frequency of extreme heat events. Considering risk as a function of both heat vulnerability and hazard intensity, this study examines whether poor urban dwellers residing in slums are exposed to higher temperature, adding to their vulnerable demographic and health conditions. Instead of being restricted by sampling size of pixels or other land surface zones, this study follows the intrinsic latent patterns of the heat phenomenon to examine the association between small clusters of slums and heat patterns. Remotely sensed land surface temperature (LST) datasets of moderate resolution are employed to derive the morphological features of the temperature patterns in the city of Ahmedabad, India at the local scale. The optimal representations of temperature pattern morphology are learnt automatically from temporally adjacent images without manually choosing model hyper-parameters. The morphological features are then evaluated to identify the local scale temperature pattern at slum locations. Results show that in particular locations with slums are exposed to a locally high temperature. More specifically, larger slums tend to be exposed to a more intense locally high temperature compared to smaller slums. Due to the small size of slums in Ahmedabad, it is hard to conclude whether slums are impacting the locally high temperature, or slums are more likely to be located in poorly built places already with a locally high temperature. This study complements the missing dimension of hazard investigation to heat-related risk analysis of slums. The study developed a workflow of exploring the temperature patterns at the local scale and examination of heat exposure of slums. It extends the conventional city scale urban temperature analysis into local scales and introduces morphological measurements as new parameters to quantify temperature patterns at a more detailed level.}
}
@article{CHAPELACAMPA2020428,
title = {Understanding complex process models by abstracting infrequent behavior},
journal = {Future Generation Computer Systems},
volume = {113},
pages = {428-440},
year = {2020},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2020.07.030},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X19331206},
author = {David Chapela-Campa and Manuel Mucientes and Manuel Lama},
keywords = {Event abstraction, Model simplification, Log simplification, Process mining, Business process management},
abstract = {Process mining has become very popular in the last years as a way to analyze the behavior of an organization by offering techniques to discover, monitor and enhance real processes. A key point in process mining is to discover understandable process models. To achieve this goal in complex processes, several simplification techniques have been proposed, from the structural simplification of the model to the simplification of the log to discover simpler process models. However, obtaining a comprehensible model explaining the behavior of unstructured large processes (for instance containing hundreds of activities) is still an open challenge. In this paper, we introduce UBeA, a novel technique to abstract non-core behavior from a process model. We also present IBeA, a specific implementation of this proposal to simplify process models by abstracting infrequent behavior, using a frequent behavior extraction algorithm to detect the core behavior. IBeA has been validated with more than 10 complex real processes, most of them from the Business Process Intelligence Challenge (BPIC), showing that it simplifies the process obtaining a better process model than other simplification techniques.}
}
@article{SANGHAVI2021223,
title = {Early stage detection of Downey and Powdery Mildew grape disease using atmospheric parameters through sensor nodes},
journal = {Artificial Intelligence in Agriculture},
volume = {5},
pages = {223-232},
year = {2021},
issn = {2589-7217},
doi = {https://doi.org/10.1016/j.aiia.2021.10.001},
url = {https://www.sciencedirect.com/science/article/pii/S2589721721000283},
author = {Kainjan Sanghavi and Mahesh Sanghavi and Archana M. Rajurkar},
keywords = {Downey mildew, Powdery mildew, Grape diseases, Internet of things (IoT), Sensor},
abstract = {Grape diseases are major factors causing severe diminution in its fruit development. Unfavorable climatic conditions are one of the principal dangers for grape disease development. Downy Mildew, Powdery Mildew, Anthracnose, Stem borer, Black Rot, Leaf Blight are widespread grape leaf vermin and diseases, which cause stern monetary losses to the grape industry. Devices ready to quantify the climate conditions in real-time for disease onset are hence crucial to perform timely diagnosis and precise detection of grape leaf diseases. This will ensure the healthy growth of grape plants, further controlling the spread of diseases. This paper discusses the requirements for building a consistent grape disease detection framework that would encourage headways in agribusiness. The primary aim of this work is to adapt an Internet of Things (IoT) based approach to predict the occurrence of Downey and Powdery Mildew grape diseases at an early stage. The sensor values received are transmitted to the Central Server with the help of the IoT device NodeMCU. At the server side, an analysis is made based on weather conditions. Further notification to the farmer is sent if weather properties are conducive for disease onset. The exclusivity of the system lies in using a rain gauge sensor along with the temperature sensor to predict the occurrence of grape diseases. This system realizes an overall accuracy of 94.4% for Downey Mildew and 96% for Powdery Mildew. Experimental results suggest the projected model can proficiently recognize Downey and Powdery Mildew grape diseases.}
}
@article{RAMIREZPENA2020118789,
title = {Achieving a sustainable shipbuilding supply chain under I4.0 perspective},
journal = {Journal of Cleaner Production},
volume = {244},
pages = {118789},
year = {2020},
issn = {0959-6526},
doi = {https://doi.org/10.1016/j.jclepro.2019.118789},
url = {https://www.sciencedirect.com/science/article/pii/S0959652619336595},
author = {Magdalena Ramirez-Peña and Alejandro J. {Sánchez Sotano} and Víctor Pérez-Fernandez and Francisco J. Abad and Moises Batista},
keywords = {Shipbuilding, Industry 4.0, Supply chain, Green, Lean, Agile, Resilient},
abstract = {Industry 4.0 (I4.0) considers a number of changes in enterprises, including business models, to achieve the Smart Factory concept. This implies a complete communication network between different companies, factories, suppliers, resources, etc …, maximize in real time to achieve the highest efficiency of all parties involved. The goal is to improve the performance and sustainability of shipbuilding industry through the supply chain establishing a model that defines how the supply chain should be under the perspective of Industry 4.0. Thus, this article aims to connect each of the key enabling I4.0 technologies with the most significant supply chain paradigms: Lean, Agile, Resilience and Green to define what the Shipbuilding Supply Chain should be. This study shows the Green Supply Chain Paradigm connects the social aspects required at the performance I4.0 model. Likewise, Lean represents the most important paradigm, encompassing the Resilience one, besides considering Agile as an intrinsic property of the shipbuilding. At this form, identifying the key factors in the conceptual model, it is possible to conclude that the Shipbuilding Supply Chain should be Green and Lean.}
}
@article{CERPA201648,
title = {Evaluating different families of prediction methods for estimating software project outcomes},
journal = {Journal of Systems and Software},
volume = {112},
pages = {48-64},
year = {2016},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2015.10.011},
url = {https://www.sciencedirect.com/science/article/pii/S016412121500223X},
author = {Narciso Cerpa and Matthew Bardeen and César A. Astudillo and June Verner},
keywords = {Project outcome predictors, Classification techniques, AUC analysis},
abstract = {Software has been developed since the 1960s but the success rate of development projects is still low. Classification models have been used to predict defects and effort estimation, but little work has been done to predict the outcome of these projects. Previous research shows that it is possible to predict outcome using classifiers based on key variables during development, but it is not clear which techniques provide more accurate predictions. We benchmark classifiers from different families to determine the outcome of a software project and identify variables that influence it. A survey-based empirical investigation was used to examine variables contributing to project outcome. Classification models were built and tested to identify the best classifiers for this data by comparing their AUC values. We reduce the dimensionality of the data with Information Gain and build models with the same techniques. We use Information Gain and classification techniques to identify key attributes and their relative importance. We find that four classification techniques provide good results for survey data, regardless of dimensionality reduction. We conclude that Random Forest is the most appropriate technique for predicting project outcome. We identified key attributes which are related to communication, estimation, and process review.}
}
@article{DIN201853,
title = {Behavior-based swarm robotic search and rescue using fuzzy controller},
journal = {Computers & Electrical Engineering},
volume = {70},
pages = {53-65},
year = {2018},
issn = {0045-7906},
doi = {https://doi.org/10.1016/j.compeleceng.2018.06.003},
url = {https://www.sciencedirect.com/science/article/pii/S0045790618314216},
author = {Ahmad Din and Meh Jabeen and Kashif Zia and Abbas Khalid and Dinesh Kumar Saini},
keywords = {Behavior-based robotics, Swarm robotics, Search and rescue, Fuzzy controller, Virtual leader, Distributed search},
abstract = {Search and rescue (SAR) is one of the foremost issues in disaster management. A robust SAR mechanism can significantly reduce the number of causalities. This paper presents a behavior-based model for a swarm of small robots to perform an efficient SAR operation in an unknown environment. The swarm is guided by a dynamically selected virtual leader (VL). A self-contained dynamic goal-seeking mechanism, using behavior-based approach, is designed to search targets (victims). Under the leadership of VL, the proposed model retains the integrity of the swarm while driving it from its current position to referenced goals. Fuzzy logic has been used to design constituent behavioral modules, namely obstacle avoidance, alignment, and inter-robot cohesion. The model has been simulated to validate its efficiency and the findings reveal that robots moving as a swarm are more effective in the SAR process as compared to multiple single robots.}
}
@article{YAZDI2018157,
title = {New trends on moving object detection in video images captured by a moving camera: A survey},
journal = {Computer Science Review},
volume = {28},
pages = {157-177},
year = {2018},
issn = {1574-0137},
doi = {https://doi.org/10.1016/j.cosrev.2018.03.001},
url = {https://www.sciencedirect.com/science/article/pii/S1574013716301794},
author = {Mehran Yazdi and Thierry Bouwmans},
keywords = {Moving object detection, Moving camera, Background subtraction, Motion compensation},
abstract = {This paper presents a survey on the latest methods of moving object detection in video sequences captured by a moving camera. Although many researches and excellent works have reviewed the methods of object detection and background subtraction for a fixed camera, there is no survey which presents a complete review of the existing different methods in the case of moving camera. Most methods in this field can be classified into four categories; modeling based background subtraction, trajectory classification, low rank and sparse matrix decomposition, and object tracking. We discuss in details each category and present the main methods which proposed improvements in the general concept of the techniques. We also present challenges and main concerns in this field as well as performance metrics and some benchmark databases available to evaluate the performance of different moving object detection algorithms.}
}
@article{VAMVOUDAKISSTEFANOU20171888,
title = {Vibration-based damage detection for a population of nominally identical structures via Random Coefficient Gaussian Mixture AR model based methodology},
journal = {Procedia Engineering},
volume = {199},
pages = {1888-1893},
year = {2017},
note = {X International Conference on Structural Dynamics, EURODYN 2017},
issn = {1877-7058},
doi = {https://doi.org/10.1016/j.proeng.2017.09.123},
url = {https://www.sciencedirect.com/science/article/pii/S1877705817335622},
author = {K.J. Vamvoudakis-Stefanou and S.D. Fassois},
keywords = {Damage detection, uncertainty, population of structures, Random Coefficient models, Gaussian Mixture models, Structural Health Monitoring},
abstract = {Vibration-based damage detection for a population of nominally identical structures is characterized by considerable uncertainty which is caused by even slight dissimilarities among the population members, and is compounded with that of additional sources. In this work a response-only and unsupervised Random Coefficient Gaussian Mixture AR model based methodology is postulated for tackling the problem. Its effectiveness is experimentally assessed via damage detection for a population of composite beams. The results indicate significant performance improvement over a corresponding Random Coefficient Gaussian method, yet similar to that of a Multiple Model based method.}
}
@article{STONGE2017165,
title = {Control, localization and human interaction with an autonomous lighter-than-air performer},
journal = {Robotics and Autonomous Systems},
volume = {88},
pages = {165-186},
year = {2017},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2016.10.013},
url = {https://www.sciencedirect.com/science/article/pii/S0921889016306674},
author = {David St-Onge and Pierre-Yves Brèches and Inna Sharf and Nicolas Reeves and Ioannis Rekleitis and Patrick Abouzakhm and Yogesh Girdhar and Adam Harmat and Gregory Dudek and Philippe Giguère},
keywords = {Robotic blimp, Robotic art, Human–robot interaction, Dynamic modeling, Mobile robotics, Airship, Theater},
abstract = {Due to the recent technological progress, Human–RobotInteraction (HRI) has become a major field of research in both engineering and artistic realms, particularly so in the last decade. The mainstream interests are, however, extremely diverse: challenges are continuously shifting, the evolution of robot’ skills, as well as the advances in methods for understanding their environment radically impact the design and implementation of research prototypes. When directly deployed in a public installation or artistic performances, robots help foster the next level of understanding in HRI. To this effect, this paper presents a successful interdisciplinary art-science-technology project, the Aerostabiles, leading to a new way of conducting HRI research. The project consists of developing a mechatronic, intelligent platform embodied in multiple geometric blimps – cubes – that hover and move in the air. The artistic context of this project required a number of advances in engineering on the aspects of localization and control systems, flight dynamics, as well as interaction strategies, and their evolution through periods of collective activities called “research–creation residencies”. These events involve artists, engineers, and performers working in close collaboration, sometimes, over several weeks at a time. They generate fruitful exchanges between all researchers, but most of all, they present a unique and creative way to direct and focus the robotics development. This paper represents an overview of the technical contributions from a range of expertise through the artistic drive of the Aerostabiles project.}
}
@article{SAHUL2014192,
title = {A novel method on Disturbance Rejection PID Controller for Quadcopter based on Optimization algorithm},
journal = {IFAC Proceedings Volumes},
volume = {47},
number = {1},
pages = {192-199},
year = {2014},
note = {3rd International Conference on Advances in Control and Optimization of Dynamical Systems (2014)},
issn = {1474-6670},
doi = {https://doi.org/10.3182/20140313-3-IN-3024.00016},
url = {https://www.sciencedirect.com/science/article/pii/S1474667016326568},
author = {M.P.V. Sahul and V. Naveen Chander and Thomas Kurian},
abstract = {This paper presents a new method to design a Proportional-Integral-Derivative (PID) controller with optimal disturbance rejection for quadcopter pitch channel and roll channel. This is done by optimizing the disturbance sensitivity function to obtain the gains of PID controllers. The proposed PID controller is compared with the existing PID controller that is based on Linear-Quadratic-Regulator (LQR) through simulating the closed-loop system and experimentally testing it on an available quadcopter test bed. The results confirm the effectiveness of the proposed method.}
}
@article{TANG20202679,
title = {LPV modeling and controller design for body freedom flutter suppression subject to actuator saturation},
journal = {Chinese Journal of Aeronautics},
volume = {33},
number = {10},
pages = {2679-2693},
year = {2020},
issn = {1000-9361},
doi = {https://doi.org/10.1016/j.cja.2020.05.027},
url = {https://www.sciencedirect.com/science/article/pii/S1000936120302600},
author = {Wei TANG and Yu WANG and Jiawei GU and Zhiwei SUN},
keywords = {Anti-windup compensation, Flutter suppression, Linear parameter-varying interpolation, Model order reduction, Saturation},
abstract = {In recent years, the Active Flutter Suppression (AFS) employing Linear Parameter-Varying (LPV) framework has become a hot spot in the research field. Nevertheless, the flutter suppression technique is facing two severe challenges. On the one hand, due to the fatal risk of flight test near critical airspeed, it is hard to obtain the accurate mathematical model of the aeroelastic system from the testing data. On the other hand, saturation of the actuator may degrade the closed-loop performance, which was often neglected in the past work. To tackle these two problems, a new active controller design procedure is proposed to suppress flutter in this paper. Firstly, with the aid of LPV model order reduction method and State-space Model Interpolation of Local Estimates (SMILE) technique, a set of high-fidelity Linear Time-Invariant (LTI) models which are usually derived from flight tests at different subcritical airspeeds are reduced and interpolated to construct an LPV model of an aeroelastic system. And then, the unstable aeroelastic dynamics beyond critical airspeed are ‘predicted’ by extrapolating the resulting LPV model. Secondly, based on the control-oriented LPV model, an AFS controller in LPV framework which is composed of a nominal LPV controller and an LPV anti-windup compensator is designed to suppress the aeroelastic vibration and overcome the performance degradation caused by actuator saturation. Although the nominal LPV controller may have superior performance in linear simulation in which the saturation effect is ignored, the results of the numerical simulations show that the nominal LPV controller fails to suppress the Body Freedom Flutter (BFF) when encountering the actuator saturation. However, the LPV anti-windup compensator not only enhances the nominal controller’s performance but also helps the nominal controller to stabilize the unstable aeroelastic system when encountering serious actuator saturation.}
}
@article{PAPADAKIS20131373,
title = {Terrain traversability analysis methods for unmanned ground vehicles: A survey},
journal = {Engineering Applications of Artificial Intelligence},
volume = {26},
number = {4},
pages = {1373-1385},
year = {2013},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2013.01.006},
url = {https://www.sciencedirect.com/science/article/pii/S095219761300016X},
author = {Panagiotis Papadakis},
keywords = {Terrain traversability, Mobile robots, Unmanned ground vehicles, Survey},
abstract = {Motion planning for unmanned ground vehicles (UGV) constitutes a domain of research where several disciplines meet, ranging from artificial intelligence and machine learning to robot perception and computer vision. In view of the plurality of related applications such as planetary exploration, search and rescue, agriculture, mining and off-road exploration, the aim of the present survey is to review the field of 3D terrain traversability analysis that is employed at a preceding stage as a means to effectively and efficiently guide the task of motion planning. We identify that in the epicenter of all related methodologies, 3D terrain information is used which is acquired from LIDAR, stereo range data, color or other sensory data and occasionally combined with static or dynamic vehicle models expressing the interaction of the vehicle with the terrain. By taxonomizing the various directions that have been explored in terrain perception and analysis, this review takes a step toward agglomerating the dispersed contributions from individual domains by elaborating on a number of key similarities as well as differences, in order to stimulate research in addressing the open challenges and inspire future developments.}
}
@article{ZHANG20202907,
title = {Fully distributed time-varying formation tracking control for multiple quadrotor vehicles via finite-time convergent extended state observer},
journal = {Chinese Journal of Aeronautics},
volume = {33},
number = {11},
pages = {2907-2920},
year = {2020},
note = {SI: Emerging Technologies of Unmanned Aerial Vehicles},
issn = {1000-9361},
doi = {https://doi.org/10.1016/j.cja.2020.03.004},
url = {https://www.sciencedirect.com/science/article/pii/S1000936120301114},
author = {Wenqiang ZHANG and Chaoyang DONG and Maopeng RAN and Yang LIU},
keywords = {Directed interaction topology, Distributed control, Disturbance rejection, Finite-time convergent extended state observer (FTCESO), Formation tracking control, Multi-agent systems},
abstract = {This paper investigates a time-varying anti-disturbance formation problem for a group of quadrotor aircrafts with time-varying uncertainties and a directed interaction topology. A novel Finite-Time Convergent Extended State Observer (FTCESO) based fully-distributed formation control scheme is proposed to enhance the disturbance rejection and the formation tracking performances for networked quadrotors. By adopting the hierarchical control strategy, the multi-quadrotor system is separated into two subsystems: the outer-loop cooperative subsystem and the inner-loop attitude subsystem. In the outer-loop subsystem, with the estimation of disturbing forces and uncertain dynamics from FTCESOs, an adaptive consensus theory based cooperative controller is exploited to ensure the multiple quadrotors form and maintain a time-varying pattern relying only on the positions of the neighboring aircrafts. In the inner-loop subsystem, the desired attitude generated by the cooperative control law is stably tracked under a FTCESO-based attitude controller in a finite time. Based on a detailed algorithm to specify the cooperative control protocol, the feasibility condition to achieve the time-varying anti-disturbance formation tracking is derived and the rigorous analysis of the whole closed-loop multi-quadrotor system is given. Some numerical examples are conducted to intuitively demonstrate the effectiveness and the improvements of the proposed control framework.}
}
@article{GARRIDO2020114857,
title = {Thermographic methodologies used in infrastructure inspection: A review—Post-processing procedures},
journal = {Applied Energy},
volume = {266},
pages = {114857},
year = {2020},
issn = {0306-2619},
doi = {https://doi.org/10.1016/j.apenergy.2020.114857},
url = {https://www.sciencedirect.com/science/article/pii/S030626192030369X},
author = {I. Garrido and S. Lagüela and R. Otero and P. Arias},
keywords = {Infrared thermography, Data post-acquisition, Infrastructure, Inspection, Review},
abstract = {The different thermal behaviour between defects and unaltered zones allows the detection and thermal characterisation of superficial, and subsuperficial defects, which must be considered when maintaining a structure in optimal conditions. InfraRed Thermography is among the most appropriate Non-Destructive techniques to measure these thermal behaviours, represented on temperature maps of the infrastructure analysed by thermal images, regardless the size of the structure. In addition, InfraRed Thermography is also used for the thermal characterisation of structures for such important purposes as the energy study of buildings. Proof of the importance of InfraRed Thermography in infrastructure inspections are the continuous developments of new thermal image processing algorithms, where the post-processing stage is widely used to improve the inspection performance. In this work, an exhaustive review is performed regarding the most recent and important practical thermographic procedures for infrastructure applications, focusing on the post-acquisition stage, due to the lack of an in-depth analysis regarding the most recent and used algorithms. Specifically, the theory of these thermal image processing techniques is described, classifying them according to the corresponding theoretical post-acquisition approach used: qualitative and/or quantitative analysis. In addition, a discussion based on the advantages and disadvantages of each thermal data processing technique is performed, as well as a description of the latest IRT works related to each. Ending with a series of conclusions, this review paper confirms the maturity of InfraRed Thermography to face the greatest challenges in infrastructure inspection, although it also mentions the limitations to overcome and the future trends to follow.}
}
@article{ALAZZAWI2015134,
title = {A dendritic cell mechanism for detection, identification, and evaluation of aircraft failures},
journal = {Control Engineering Practice},
volume = {41},
pages = {134-148},
year = {2015},
issn = {0967-0661},
doi = {https://doi.org/10.1016/j.conengprac.2015.04.010},
url = {https://www.sciencedirect.com/science/article/pii/S0967066115000763},
author = {Dia {Al Azzawi} and Mario G. Perhinschi and Hever Moncayo and Andres Perez},
keywords = {Aircraft Safety, Intelligent Systems, Artificial Immune, Systems, Failure Detection, Diagnosis, Dendritic Cell},
abstract = {Successful fault-tolerant control strategies often require vital tools that can accurately detect the failure, identify its root cause, and evaluate its nature and severity. Most of the existing methodologies in the field of failure detection, identification, and evaluation are limited to few subsystems with reduced number of features. Due to the complexity and multidimensionality of the aircraft system, new methodologies that are robust, accurate, and fast enough need to be developed for such systems. The biological immune system is a natural system that possesses vigorous peculiarities in protecting the mammalian body from harmful intruders and, therefore, may represent a rich source of inspiration to solve anomaly problems. This paper presents a novel integrated scheme for aircraft sub-system failure detection, identification, and evaluation based on the functionality of the biological dendritic cells and their interactions with the various components of the immune system. The proposed approach relies on using the self/nonself discrimination principle with the hierarchical multiself strategy to overcome the multidimensionality issues. The information collected by the artificial dendritic cells is fused in a way that convert the identification and evaluation problem into a pattern recognition problem. The proposed scheme was successfully tested for a supersonic fighter aircraft in a motion-based flight simulator with high detection, identification, and evaluation rates and practically zero false alarms.}
}
@article{AYGUN20145085,
title = {Robust Image-based Visual Servo Control of an Uncertain Missile Airframe},
journal = {IFAC Proceedings Volumes},
volume = {47},
number = {3},
pages = {5085-5090},
year = {2014},
note = {19th IFAC World Congress},
issn = {1474-6670},
doi = {https://doi.org/10.3182/20140824-6-ZA-1003.02633},
url = {https://www.sciencedirect.com/science/article/pii/S1474667016424031},
author = {Murat T. Aygun and William MacKunis and Siddhartha Mehta},
keywords = {robust control, missiles, computer vision, visual servo control, image-based, guidance systems, autonomous, lyapunov stability},
abstract = {A nonlinear vision-based guidance law is presented in this paper for a missile-target scenario in the presence of model uncertainty and unknown target evasive maneuvers. To this end, projective geometric relationships are utilized to combine the image kinematics with the missile dynamics in an integrated visual dynamic system. The guidance law is designed using an image-based visual servo control method in conjunction with a sliding-mode control strategy, which is shown to achieve asymptotic target interception in the presence of the aforementioned uncertainties. A Lyapunov-based stability analysis is presented to prove the theoretical result, and numerical simulation results are provided to demonstrate the performance of the proposed robust controller for both stationary and non-stationary targets.}
}
@article{BONATI2020107516,
title = {Open, Programmable, and Virtualized 5G Networks: State-of-the-Art and the Road Ahead},
journal = {Computer Networks},
volume = {182},
pages = {107516},
year = {2020},
issn = {1389-1286},
doi = {https://doi.org/10.1016/j.comnet.2020.107516},
url = {https://www.sciencedirect.com/science/article/pii/S1389128620311786},
author = {Leonardo Bonati and Michele Polese and Salvatore D’Oro and Stefano Basagni and Tommaso Melodia},
keywords = {Software-defined Networking, 5G, Open Source, Network Function Virtualization, O-RAN, ONAP},
abstract = {Fifth generation (5G) cellular networks will serve a wide variety of heterogeneous use cases, including mobile broadband users, ultra-low latency services and massively dense connectivity scenarios. The resulting diverse communication requirements will demand networking with unprecedented flexibility, not currently provided by the monolithic black-box approach of 4G cellular networks. The research community and an increasing number of standardization bodies and industry coalitions have recognized softwarization, virtualization, and disaggregation of networking functionalities as the key enablers of the needed shift to flexibility. Particularly, software-defined cellular networks are heralded as the prime technology to satisfy the new application-driven traffic requirements and to support the highly time-varying topology and interference dynamics, because of their openness through well-defined interfaces, and programmability, for swift and responsive network optimization. Leading the technological innovation in this direction, several 5G software-based projects and alliances have embraced the open source approach, making new libraries and frameworks available to the wireless community. This race to open source softwarization, however, has led to a deluge of solutions whose interoperability and interactions are often unclear. This article provides the first cohesive and exhaustive compendium of recent open source software and frameworks for 5G cellular networks, with a full stack and end-to-end perspective. We detail their capabilities and functionalities focusing on how their constituting elements fit the 5G ecosystem, and unravel the interactions among the surveyed solutions. Finally, we review hardware and testbeds on which these frameworks can run, and provide a critical perspective on the limitations of the state-of-the-art, as well as feasible directions toward fully open source, programmable 5G networks.}
}
@article{FAN2021102612,
title = {High-integrity based cooperative file transmission at urban intersections using pure V2V communication},
journal = {Ad Hoc Networks},
volume = {122},
pages = {102612},
year = {2021},
issn = {1570-8705},
doi = {https://doi.org/10.1016/j.adhoc.2021.102612},
url = {https://www.sciencedirect.com/science/article/pii/S1570870521001396},
author = {Xiying Fan and Yuekun Lu and Baolin Liu and Di Liu and Shaojie Wen and Bin Fu},
keywords = {VANETs, V2V, File integrity, Cooperative file transmission},
abstract = {Vehicular Ad Hoc Networks (VANETs) provide safety management and entertainment services in smart city scenarios. However, due to the highly time-varying network topology caused by vehicles’ movement and non-line-of-sight (NLOS) areas in complex urban environment, the connection time between vehicles might be very short, leading to limited transmission capacity between vehicles. As a result, large file transmission such as online video sharing might be unavailable. To alleviate this issue, we study high-integrity based file transmission using pure vehicle-to-vehicle (V2V) communication at urban intersections. First, we develop the analytical models to evaluate file transmission at intersections, including vehicle mobility model, connection time prediction model, and V2V communication model. Then, we derive the relationship between transmission capacity and vehicles’ mobility. Based upon this analysis, we propose a cooperative file transmission strategy for the transmitting vehicle, which helps transmit the target file to the receiving vehicle. The proposed strategy includes three phases: transmission capacity evaluation, cluster establishment, and cooperative file transmission. By taking advantage of the cluster characteristics, the strategy can achieve file transmission with high integrity. Through extensive simulations, we demonstrate the accuracy of the proposed system model which matches our analysis well, and show the effectiveness of the proposed strategy by comparing with other file transmission strategies in aspects of transmission success rate and data transmission volume.}
}
@article{YAN20192299,
title = {Robust adaptive compensation control for unmanned autonomous helicopter with input saturation and actuator faults},
journal = {Chinese Journal of Aeronautics},
volume = {32},
number = {10},
pages = {2299-2310},
year = {2019},
issn = {1000-9361},
doi = {https://doi.org/10.1016/j.cja.2019.06.001},
url = {https://www.sciencedirect.com/science/article/pii/S1000936119302389},
author = {Kun YAN and Mou CHEN and Qingxian WU and Ronggang ZHU},
keywords = {Compensation control, Fault tolerant control, Input saturation, Tracking control, Unmanned autonomous helicopter},
abstract = {This paper studies a robust adaptive compensation Fault Tolerant Control (FTC) for the medium-scale Unmanned Autonomous Helicopter (UAH) in the presence of external disturbances, actuator faults and input saturation. To improve the disturbance rejection capacity of the UAH system in actuator healthy case, an adaptive control method is adopted to cope with the external disturbances and a nominal controller is proposed to stabilize the system. Meanwhile, compensation control inputs are designed to reduce the negative effects derived from actuator faults and input saturation. Based on the backstepping control and inner-outer loop control technologies, a robust adaptive FTC scheme is developed to guarantee the tracking errors convergence. Under the presented FTC controller, the uniform ultimate boundedness of all closed-loop signals is ensured via Lyapunov stability analysis. Simulation results demonstrate the effectiveness of the proposed control algorithm.}
}
@article{NIU2022173,
title = {Big data-driven scheduling optimization algorithm for Cyber–Physical Systems based on a cloud platform},
journal = {Computer Communications},
volume = {181},
pages = {173-181},
year = {2022},
issn = {0140-3664},
doi = {https://doi.org/10.1016/j.comcom.2021.10.020},
url = {https://www.sciencedirect.com/science/article/pii/S0140366421003984},
author = {Chao Niu and Lizhou Wang},
keywords = {Cloud platform, Big data-driven, Cyber–Physical Systems, Scheduling optimization algorithm},
abstract = {In this paper, we study big data-driven Cyber–Physical Systems (CPS) through cloud platforms and design scheduling optimization algorithms to improve the efficiency of the system. A task scheduling scheme for large-scale factory access under cloud–edge collaborative computing architecture is proposed. The method firstly merges the directed acyclic graphs on cloud-side servers and edge-side servers; secondly, divide the tasks using a critical path-based partitioning strategy to effectively improve the allocation accuracy; then achieves load balancing through reasonable processor allocation, and finally compares and analyses the proposed task scheduling algorithm through simulation experiments. The experimental system is thoroughly analysed, hierarchically designed, and modelled, simulated, and the experimental data analysed and compared with related methods. The experimental results prove the effectiveness and correctness of the worst-case execution time analysis method and the idea of big data-driven CPS proposed in this paper and show that big data knowledge can help improve the accuracy of worst-case execution time analysis. This paper implements a big data-driven scheduling optimization algorithm for Cyber–Physical Systems based on a cloud platform, which improves the accuracy and efficiency of the algorithm by about 15% compared to other related studies.}
}
@article{ALGHAMDI2021462,
title = {Data quality-aware task offloading in Mobile Edge Computing: An Optimal Stopping Theory approach},
journal = {Future Generation Computer Systems},
volume = {117},
pages = {462-479},
year = {2021},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2020.12.017},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X2033079X},
author = {Ibrahim Alghamdi and Christos Anagnostopoulos and Dimitrios P. Pezaros},
keywords = {Mobile edge computing, Tasks offloading, Data quality, Optimal stopping theory, Sequential decision making},
abstract = {An important use case of the Mobile Edge Computing (MEC) paradigm is task and data offloading. Computational offloading is beneficial for a wide variety of mobile applications on different platforms including autonomous vehicles and smartphones. With the envision deployment of MEC servers along the roads and while mobile nodes are moving and having certain tasks (or data) to be offloaded to edge servers, choosing an appropriate time and an ideally suited MEC server to guarantee the Quality of Service (QoS) is challenging. We tackle the data quality-aware offloading sequential decision making problem by adopting the principles of Optimal Stopping Theory (OST) to minimize the expected processing time. A variety of OST stochastic models and their applications to the offloading decision making problem are investigated and assessed. A performance evaluation is provided using simulation approach and real world data sets together with the assessment of baseline deterministic and stochastic offloading models. The results show that the proposed OST models can significantly minimize the expected processing time for analytics task execution and can be implemented in the mobile nodes efficiently.}
}
@article{HERNANDO2022105859,
title = {The importance of protected habitats and LiDAR data availability for assessing scenarios of land uses in forest areas},
journal = {Land Use Policy},
volume = {112},
pages = {105859},
year = {2022},
issn = {0264-8377},
doi = {https://doi.org/10.1016/j.landusepol.2021.105859},
url = {https://www.sciencedirect.com/science/article/pii/S0264837721005822},
author = {Ana Hernando and Iñigo Sobrini and Javier Velázquez and Antonio García-Abril},
keywords = {Forest land use, LiDAR, Tree heights, Protected habitats, Natura 2000, Urban capacity},
abstract = {Natura 2000 network is becoming increasingly important for ecosystem services but not all human activities are limited as long as they ensure protection of conservation values. Private owned areas should harmonize biodiversity conservation and other compatible land uses with human activities sustainability. The purpose of this study is to present a methodology for the assessment of urban use capacity considering restrictions presented in a Natura 2000 site in Central Spain (Madrid). This assessment takes the advantages of high-resolution images and point clouds LiDAR data using Object Based Images Analysis (OBIA). Considering different ranges of (i) tree height, (ii) slopes and (iii) the existing protected habitats, six scenarios of Urban use capacity were obtained. A canopy height vegetation was derived, and the maximum height was assigned to each delineated crown polygon tree. The implementation of this methodology proposes the largest potential urban area (Scenario 6) but priority habitats and habitats of Community interest were entirely removed from it. Finally, plots (1000 m 2) with greater or lesser capacity of vegetation coverage change were located. A total of 145 plots (6% of the whole property) with urban use low capacity were located. This methodology can be extrapolated to any protected area that seeks to harmonize biodiversity conservation and human activities.}
}
@article{KRITTER2019133,
title = {On the optimal placement of cameras for surveillance and the underlying set cover problem},
journal = {Applied Soft Computing},
volume = {74},
pages = {133-153},
year = {2019},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2018.10.025},
url = {https://www.sciencedirect.com/science/article/pii/S1568494618305829},
author = {Julien Kritter and Mathieu Brévilliers and Julien Lepagnot and Lhassane Idoumghar},
keywords = {Combinatorial optimisation, Optimal camera placement, Set cover problem, Survey},
abstract = {Given a delimited surveillance area, represented in either 2D or 3D, and a set of feasible camera locations and orientations, the optimal camera placement problem (OCP) is that of identifying camera configurations which optimise a predefined objective under a set of application-specific constraints. While this problem appears in many modern applications such as area surveillance, target tracking, photogrammetry or traffic and crowd analysis, it finds its roots in one of Karp’s 21 original NP-complete problems: set cover (SCP). If the two problems are often structurally identical, many papers dealing with optimal camera placement use this relationship implicitly, and a lot of the work done on the SCP has yet to find its way into the literature of the applied problem. In this survey, we review both in terms of problem modelling, preprocessing and solving approaches, and attempt to bring them together by suggesting open lines of research for future works.}
}
@article{GALCERAN20131258,
title = {A survey on coverage path planning for robotics},
journal = {Robotics and Autonomous Systems},
volume = {61},
number = {12},
pages = {1258-1276},
year = {2013},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2013.09.004},
url = {https://www.sciencedirect.com/science/article/pii/S092188901300167X},
author = {Enric Galceran and Marc Carreras},
keywords = {Coverage path planning, Path planning, Motion planning},
abstract = {Coverage Path Planning (CPP) is the task of determining a path that passes over all points of an area or volume of interest while avoiding obstacles. This task is integral to many robotic applications, such as vacuum cleaning robots, painter robots, autonomous underwater vehicles creating image mosaics, demining robots, lawn mowers, automated harvesters, window cleaners and inspection of complex structures, just to name a few. A considerable body of research has addressed the CPP problem. However, no updated surveys on CPP reflecting recent advances in the field have been presented in the past ten years. In this paper, we present a review of the most successful CPP methods, focusing on the achievements made in the past decade. Furthermore, we discuss reported field applications of the described CPP methods. This work aims to become a starting point for researchers who are initiating their endeavors in CPP. Likewise, this work aims to present a comprehensive review of the recent breakthroughs in the field, providing links to the most interesting and successful works.}
}
@article{ZHUANG2021107069,
title = {Robust adaptive sliding mode attitude control for aircraft systems based on back-stepping method},
journal = {Aerospace Science and Technology},
volume = {118},
pages = {107069},
year = {2021},
issn = {1270-9638},
doi = {https://doi.org/10.1016/j.ast.2021.107069},
url = {https://www.sciencedirect.com/science/article/pii/S1270963821005794},
author = {Huixuan Zhuang and Qinglin Sun and Zengqiang Chen and Xianyi Zeng},
keywords = {Robust adaptive, Sliding mode control, Attitude control, Aircraft systems, Back-stepping method},
abstract = {In this paper, the robust adaptive control and back-stepping method are considered for attitude control of aircraft systems. First, a non-linear aircraft model is introduced and converted to standard state space form. Then, an adaptive sliding mode controller is designed by using the back-stepping method. An adaptive law is designed to cooperate with sliding mode control (SMC) to compensate for the unknown and uncertain parts of the aircraft systems. This method does not need to know the physical parameters of the aircraft model accurately, but only uses the adaptive upper bound of the matrix model norm to ensure the robustness of the system under SMC. Next, the stability of the adaptive law and SMC is analyzed and proven theoretically. At last, the effectiveness of this method is illustrated by extensive comparative simulations. Furthermore, the disturbance term is introduced to test the anti-interference performance of the controller. The results acquired from simulation illustrate that SMC can achieve good control performance.}
}
@article{SCIANCALEPORE2021102892,
title = {Receivers location privacy in avionic crowdsourced networks: Issues and countermeasures},
journal = {Journal of Network and Computer Applications},
volume = {174},
pages = {102892},
year = {2021},
issn = {1084-8045},
doi = {https://doi.org/10.1016/j.jnca.2020.102892},
url = {https://www.sciencedirect.com/science/article/pii/S1084804520303544},
author = {Savio Sciancalepore and Saeif Alhazbi and Roberto {Di Pietro}},
keywords = {Crowd sensing and crowd sourcing, Location management, Security and privacy},
abstract = {The lack of message encryption characterizing wireless avionic protocols, including Automatic Dependent Surveillance - Broadcast (ADS-B), recently favored the rise of a few communities that, gathering data collected by receivers at the ground or in space, offer advanced services, while at the same time releasing the cited data to the public. In this context, hiding the location of an ADS-B receiver could be useful for several reasons, including military and privacy aspects. Therefore, taking into account these considerations, the data provided by a few antennas in one of the most popular crowdsourcing platforms, Opensky Network, are released removing any information that could lead to their direct location identification. In this manuscript, we investigate the effectiveness of protecting location privacy in avionic crowdsourced networks. As a worst-case scenario, we demonstrate that, when a feasible number of receivers are deployed in the same area of a protected one, due to the nature of involved ADS-B data, standard time-based localization schemes can identify the location of any protected receiver. Our model, applied to real data, can identify the location of a protected receiver with an error ranging from 0.9 km to 2.6 km, depending on the target sensor—while the location uncertainty induced by the anonymization technique was expected to be of approximately 450 km. Our findings, supported by an extensive experimental campaign run over real data, apply to a variety of potentially protected receivers. Moreover, we also provide effective countermeasures to increase receivers’ location privacy. Finally, we discuss the trade-offs implied by the cited countermeasures, showing that it is possible to increase location privacy while not decreasing data utility.}
}
@article{TANG20191,
title = {The strategic role of logistics in the industry 4.0 era},
journal = {Transportation Research Part E: Logistics and Transportation Review},
volume = {129},
pages = {1-11},
year = {2019},
issn = {1366-5545},
doi = {https://doi.org/10.1016/j.tre.2019.06.004},
url = {https://www.sciencedirect.com/science/article/pii/S1366554519306349},
author = {Christopher S. Tang and Lucas P. Veelenturf},
keywords = {Industry 4.0, Additive manufacturing, Blockchain, Drones, Artificial intelligence, Logistics, Transportation},
abstract = {By leveraging new technologies (Additive Manufacturing, Advanced Robotics, Artificial Intelligence, Autonomous Vehicles, Blockchain, Drones, Internet of Things, etc.), many companies are developing cyber-physical systems that can change the competition landscape. In the midst of this exciting development, we examine the strategic role of logistics and transportation services for creating economic, environmental and social values. Also, we discuss some new research directions.}
}
@article{CUBUKCUOGLU20191215,
title = {A Memetic Algorithm for the Bi-Objective Quadratic Assignment Problem},
journal = {Procedia Manufacturing},
volume = {39},
pages = {1215-1222},
year = {2019},
note = {25th International Conference on Production Research Manufacturing Innovation: Cyber Physical Manufacturing August 9-14, 2019 | Chicago, Illinois (USA)},
issn = {2351-9789},
doi = {https://doi.org/10.1016/j.promfg.2020.01.348},
url = {https://www.sciencedirect.com/science/article/pii/S2351978920304157},
author = {Cemre Cubukcuoglu and M. Fatih Tasgetiren and I. Sevil Sariyildiz and Liang Gao and Murat Kucukvar},
keywords = {multi-objective quadratic assignment problems, metaheuristics, memetic algorithm, local search, genetic algorithm},
abstract = {Recently, multi-objective evolutionary algorithms (MOEAs) have been extensively used to solve multi-objective optimization problems (MOPs) since they have the ability to approximate a set of non-dominated solutions in reasonable CPU times. In this paper, we consider the bi-objective quadratic assignment problem (bQAP), which is a variant of the classical QAP, which has been extensively investigated to solve several real-life problems. The bQAP can be deﬁned as having many input ﬂows with the same distances between the facilities, causing multiple cost functions that must be optimized simultaneously. In this study, we propose a memetic algorithm with effective local search and mutation operators to solve the bQAP. Local search is based on swap neighborhood structure whereas the mutation operator is based on ruin and recreate procedure. The experimental results show that our bi-objective memetic algorithm (BOMA) substantially outperforms all the island-based variants of the PASMOQAP algorithm proposed very recently in the literature.}
}
@article{FORSHAW2012166,
title = {Architecture and systems design of a reusable Martian twin rotor tailsitter},
journal = {Acta Astronautica},
volume = {80},
pages = {166-180},
year = {2012},
issn = {0094-5765},
doi = {https://doi.org/10.1016/j.actaastro.2012.05.008},
url = {https://www.sciencedirect.com/science/article/pii/S0094576512001993},
author = {Jason L. Forshaw and Vaios J. Lappas},
keywords = {Tailsitter, Transitional flight, VTOL, Martian exploration},
abstract = {A rapidly developing field is that of tailsitters, aircraft capable of transitioning between horizontal and vertical flight, a premise that supports a diverse range of applications. Tailsitters can effortlessly land and hover at will, yet can also move at high speed between destinations making them ideal in undertaking ‘multiple missions to land at multiple destinations far apart’. This paper considers how the concept of twin helicopter rotor tailsitters, such as QinetiQ's Eye-OnTM, can be adapted for use in a Martian environment. The mission architecture and system requirements for both reusable and single-use tailsitters are considered and 12 disparate subsystems or fields (including propulsion, power and aerodynamics) are designed using a high-level systems approach. The resulting tailsitter is capable of covering 100km and 450km in reusable and single-use architectures respectively. A docking station is also designed utilising a four stage process for deployment of the tailsitter.}
}
@article{GONZALEZ2018s246,
title = {Review: Precision nutrition of ruminants: approaches, challenges and potential gains},
journal = {Animal},
volume = {12},
pages = {s246-s261},
year = {2018},
issn = {1751-7311},
doi = {https://doi.org/10.1017/S1751731118002288},
url = {https://www.sciencedirect.com/science/article/pii/S1751731118002288},
author = {L.A. González and I. Kyriazakis and L.O. Tedeschi},
keywords = {sensors, prediction models, feeding, cattle},
abstract = {A plethora of sensors and information technologies with applications to the precision nutrition of herbivores have been developed and continue to be developed. The nutritional processes start outside of the animal body with the available feed (quantity and quality) and continue inside it once the feed is consumed, degraded in the gastrointestinal tract and metabolised by organs and tissues. Finally, some nutrients are wasted via urination, defecation and gaseous emissions through breathing and belching whereas remaining nutrients ensure maintenance and production. Nowadays, several processes can be monitored in real-time using new technologies, but although these provide valuable data ‘as is’, further gains could be obtained using this information as inputs to nutrition simulation models to predict unmeasurable variables in real-time and to forecast outcomes of interest. Data provided by sensors can create synergies with simulation models and this approach has the potential to expand current applications. In addition, data provided by sensors could be used with advanced analytical techniques such as data fusion, optimisation techniques and machine learning to improve their value for applications in precision animal nutrition. The present paper reviews technologies that can monitor different nutritional processes relevant to animal production, profitability, environmental management and welfare. We discussed the model-data fusion approach in which data provided by sensor technologies can be used as input of nutrition simulation models in near-real time to produce more accurate, certain and timely predictions. We also discuss some examples that have taken this model-data fusion approach to complement the capabilities of both models and sensor data, and provided examples such as predicting feed intake and methane emissions. Challenges with automatising the nutritional management of individual animals include monitoring and predicting of the flow of nutrients including nutrient intake, quantity and composition of body growth and milk production, gestation, maintenance and physical activities at the individual animal level. We concluded that the livestock industries are already seeing benefits from the development of sensor and information technologies, and this benefit is expected to grow exponentially soon with the integration of nutrition simulation models and techniques for big data analysis. However, this approach may need re-evaluating or performing new empirical research in both fields of animal nutrition and simulation modelling to accommodate a new type of data provided by the sensor technologies.}
}
@article{SAMAR2011844,
title = {Autonomous terrain-following for unmanned air vehicles},
journal = {Mechatronics},
volume = {21},
number = {5},
pages = {844-860},
year = {2011},
note = {Special Issue on Development of Autonomous Unmanned Aerial Vehicles},
issn = {0957-4158},
doi = {https://doi.org/10.1016/j.mechatronics.2010.09.010},
url = {https://www.sciencedirect.com/science/article/pii/S0957415810001686},
author = {Raza Samar and Abdur Rehman},
keywords = {Terrain-following, Decision making and autonomy, Altitude control, Mission planning, Guidance and control of UAVs, Trajectory tracking and path following, robust control applications, Eectromechanical actuators},
abstract = {This paper presents an integrated guidance and control design scheme for an unmanned air vehicle (UAV), and its flight test results. The paper focuses on the longitudinal control and guidance aspects, with particular emphasis on the terrain-following problem. An introduction to the mission, and the terrain-following problem is given first. Waypoints for climb and descent are defined. Computation of the reference trajectory in the vertical plane is discussed, including a terrain-following (TF) algorithm for real-time calculation of climb/descent points and altitudes. The algorithm is particularly suited for online computation and is therefore useful for autonomous flight. The algorithm computes the height at which the vehicle should fly so that a specified clearance from the underlying terrain is always maintained, while ensuring that the vehicle’s rate of climb and rate of descent constraints are not violated. The output of the terrain-following algorithm is used to construct a smooth reference trajectory for the vehicle to track. The design of a robust controller for altitude tracking and stability augmentation of the vehicle is then presented. The controller uses elevators for pitch control in the inner loop, while the reference pitch commands are generated by the outer altitude control loop. The controller tracks the reference trajectory computed by the terrain-following algorithm. The design of an electromechanical actuator for actuating the control surfaces of the vehicle during flight is also discussed. The entire guidance and control scheme is implemented on an actual experimental vehicle and flight test results are presented and discussed.}
}
@article{BRISCOE2020544,
title = {Artificial Scientific Intelligence and its Impact on National Security and Foreign Policy},
journal = {Orbis},
volume = {64},
number = {4},
pages = {544-554},
year = {2020},
issn = {0030-4387},
doi = {https://doi.org/10.1016/j.orbis.2020.08.004},
url = {https://www.sciencedirect.com/science/article/pii/S0030438720300442},
author = {Erica Briscoe and James Fairbanks},
abstract = {Recently, there has been a great deal of discussion on how artificial intelligence (AI) is likely to impact national security in the near and long term. These discussions take place with the backdrop of the United States facing a loss of technological and scientific superiority, as other countries, most notably the People's Republic of China, are increasing their research and development budgets. This article addresses a less obvious dimension of the future of AI, where increasingly intelligent automation is poised to revolutionize scientific research itself. We discuss how artificially intelligent approaches may upend the fundamentals of technological development and the potential implications of this disruption on U.S. national security.}
}
@article{HEETOABDULRAHMAN20211293,
title = {Determination of the local geoid model in Duhok Region, University of Duhok Campus as a Case study},
journal = {Ain Shams Engineering Journal},
volume = {12},
number = {2},
pages = {1293-1304},
year = {2021},
issn = {2090-4479},
doi = {https://doi.org/10.1016/j.asej.2020.10.004},
url = {https://www.sciencedirect.com/science/article/pii/S2090447920302306},
author = {Farsat {Heeto Abdulrahman}},
keywords = {Local Geoid Model, Geoid undulation, GPS-RTK, Orthometric height, Earth gravitational models (EGMs)},
abstract = {The height obtained through the GNSS method is the ellipsoidal height and to have an efficient application in surveying it has to be converted into orthometric height. This paper aims to determine a local geoid model for a part of Duhok region based on the known orthometric height using GPS/levelling and assessing the precision performance of the two Earth gravitational models (EGM1996 and EGM2008) in the study area. The EGMs were adjusted based on root mean square errors, calculated from the differences between two geoid heights, GPS/levelling and EGMs. The Kriging interpolation method was used for creating a local geoid model based on GPS/levelling. The result from the adjusted geoid models to the survey data at 54 points revealed that the mean accuracy of geoidal heights at 0.08 m level is attainable. The precision performance of EGM96 is more precise than EGM08 by 14 mm in the area of interest.}
}
@article{MOOMEN2019117954,
title = {Inadequate adaptation of geospatial information for sustainable mining towards agenda 2030 sustainable development goals},
journal = {Journal of Cleaner Production},
volume = {238},
pages = {117954},
year = {2019},
issn = {0959-6526},
doi = {https://doi.org/10.1016/j.jclepro.2019.117954},
url = {https://www.sciencedirect.com/science/article/pii/S0959652619328240},
author = {Abdul-Wadood Moomen and Michela Bertolotto and Pierre Lacroix and David Jensen},
keywords = {Mining, Agenda 2030, Sustainable development, Geospatial information, Remote sensing},
abstract = {For all the evolutionary ages of mineral resource development, there have not been concerns about sustainable mining until the 21st century. Thus, this paper explores the extent to which emerging geospatial technologies have been deliberately used in the mining industry activities to achieve the United Nations Agenda 2030 Sustainable Development Goals. Governments, the mining industry, Non-Governmental and International Organisations have various investments in geospatial programmes and technologies for Environmental and Social Impact Assessments and baseline studies to enhance the achievement of these goals. However, these efforts prove inadequate to link the social, environmental and economic baseline analysis of sustainable development goals. The observations in this paper, therefore, have been obtained largely from extensive literature review to gain a broad understanding of previous and current applications of emerging technologies in the field. The literature has been explored in two successive steps. First, the literature was broadly queried to find the most current works on sustainable mining for three decades (i.e. 1990 to 2019). Second, out of over 100 papers, reports, and books retrieved in the first step, a more specific search and analysis of existing academic and industry literature on the explicit applications of emerging geospatial technology for enhancing sustainable development in the mining sector was conducted. In spite of its ensemble of capabilities for multivariate analysis, analysis of the literature reveals that there is inadequate adaptation of emerging geospatial technologies, which can simultaneously measure and link generally acceptable social, economic and environmental costs and benefits of mining for sustainability considerations in a local setting. There is a dearth of literature that discuss this new approach in addressing sustainable mining. Findings of this paper shall, therefore, inform the scientific community, industry, Non-Governmental Organisations and consultants on emerging approaches to address salient issues of sustainable mining towards meeting the agenda 2030 SDGs.}
}
@article{XIAOBO2021106543,
title = {Efilter: An effective fault localization based on information entropy with unlabelled test cases},
journal = {Information and Software Technology},
volume = {134},
pages = {106543},
year = {2021},
issn = {0950-5849},
doi = {https://doi.org/10.1016/j.infsof.2021.106543},
url = {https://www.sciencedirect.com/science/article/pii/S095058492100029X},
author = {Yan Xiaobo and Liu Bin and Wang Shihai and An Dong and Zhu Feng and Yang Yelin},
keywords = {Fault localization, Software debugging, Test oracle, Unlabelled test cases, Information entropy},
abstract = {Context:
Automatic fault localization is essential to intelligent software system. Most fault localization techniques assume the test oracle is perfect before debugging, which is hard to exist in practice. In fact, the test suite would contain a number of unlabelled test cases which have been proved to be useful in fault localization. However, due to the execution diversity, not all unlabelled test cases are suitable for fault localization. Selecting inappropriate unlabelled test cases can even weaken the fault localization efficiency.
Objective:
To solve the problem of filtering unlabelled test cases, this work aims to construct a feasible framework to select suitable unlabelled test cases for better fault localization.
Method:
To address this issue, an entropy-based framework Efilter is constructed to filter unlabelled test cases. In Efilter, a Statement-based entropy and Testsuite-based entropy are constructed to measure the localization uncertainty of given test suite. The unlabelled test case with less Statement-based entropy or Testsuite-based entropy compared with its threshold would be selected. Further, the feature integration strategies for both Statement-based entropy and Testsuite-based entropy are given to calculate the suspiciousness of statements.
Results:
The Efilter efficiency is evaluated across 6 open-source programs and 3 spectrum-based fault localizations. The results reveal that Efilter can improve fault localization efficiency by 18.8% and 16.5% with the Statement-based entropy and the Testsuite-based entropy respectively compared with the strategy without Efilter from the perspective of EXAM score on average.
Conclusion:
Our results indicate that the Efilter with both the Statement-based entropy and the Testsuite-based entropy can improve the fault localization in the scenario lack of test oracles, serving as an enhancement for fault localization in practice.}
}
@article{JAMSRAN2019158,
title = {Applying a support vector model to assess land cover changes in the Uvs Lake Basin ecoregion in Mongolia},
journal = {Information Processing in Agriculture},
volume = {6},
number = {1},
pages = {158-169},
year = {2019},
issn = {2214-3173},
doi = {https://doi.org/10.1016/j.inpa.2018.07.007},
url = {https://www.sciencedirect.com/science/article/pii/S2214317318301914},
author = {Buyan-Erdene Jamsran and Chinsu Lin and Ishgaldan Byambakhuu and Jamsran Raash and Khaulenbek Akhmadi},
keywords = {Land suppression, Soil degradation, Forest reduction, Change analysis, Landscape ecology},
abstract = {The Uvs Lake Basin in western Mongolia is a natural world heritage site and is known for its diversity in landscape and wildlife. Recently, investigative research has shown that the protected pristine ecotone is suffering land degradation due to global warming. In order to obtain evidence of the changes over a long-term time scale, serial multi-temporal Landsat images obtained between 1995 and 2015 were used to classify land cover and land cover changes over the Basin ecoregion using a machine learning classification technique, support vector machine. Results showed that the forest land area in 1995 was 1888.48 km2 which was equivalent to 7.48% of the total area of the study site. The forest area showed considerable decrease by 301.36 km2 during the first decade (1995–2004) and 155.81 km2 during second decade (2004–2015). A total of 457.17 km2 or 24.21% of the forest land has been developed, most being changed into grassland. The major driver of such changes was illegal logging, forest fire, and pest damage. However grassland was changed primarily into bare land during the two decades. The area of glacier was decreased and primarily changed into water body. In contrast, the area of sand in the Basin ecoregion increased dramatically from 65.20 km2 in 1995 to 318.33 km2 in 2015 the increase being mostly from the transition of bare land. In summary, the drivers of the significant decrease of greenness coverage and increase of sand/bare land areas were the interaction of complicated disturbances in both anthropogenic and natural factors, in which logging, grazing, wind erosion, and global warming were the key causes.}
}
@article{SINGH2020102364,
title = {Convergence of blockchain and artificial intelligence in IoT network for the sustainable smart city},
journal = {Sustainable Cities and Society},
volume = {63},
pages = {102364},
year = {2020},
issn = {2210-6707},
doi = {https://doi.org/10.1016/j.scs.2020.102364},
url = {https://www.sciencedirect.com/science/article/pii/S2210670720305850},
author = {Saurabh Singh and Pradip Kumar Sharma and Byungun Yoon and Mohammad Shojafar and Gi Hwan Cho and In-Ho Ra},
keywords = {Blockchain, Artificial intelligence, Security, Internet of things, Sustainable smart city, Intelligence transport system},
abstract = {In the digital era, the smart city can become an intelligent society by utilizing advances in emerging technologies. Specifically, the rapid adoption of blockchain technology has led a paradigm shift to a new digital smart city ecosystem. A broad spectrum of blockchain applications promise solutions for problems in areas ranging from risk management and financial services to cryptocurrency, and from the Internet of Things (IoT) to public and social services. Furthermore, the convergence of Artificial Intelligence (AI) and blockchain technology is revolutionizing the smart city network architecture to build sustainable ecosystems. However, these advancements in technologies bring both opportunities and challenges when it comes to achieving the goals of creating a sustainable smart cities. This paper provides a comprehensive literature review of the security issues and problems that impact the deployment of blockchain systems in smart cities. This work presents a detailed discussion of several key factors for the convergence of Blockchain and AI technologies that will help form a sustainable smart society. We discuss blockchain security enhancement solutions, summarizing the key points that can be used for developing various blockchain-AI based intelligent transportation systems. Also, we discuss the issues that remain open and our future research direction, this includes new security suggestions and future guidelines for a sustainable smart city ecosystem.}
}
@article{LIU2021112303,
title = {Hyperspectral imagery to monitor crop nutrient status within and across growing seasons},
journal = {Remote Sensing of Environment},
volume = {255},
pages = {112303},
year = {2021},
issn = {0034-4257},
doi = {https://doi.org/10.1016/j.rse.2021.112303},
url = {https://www.sciencedirect.com/science/article/pii/S0034425721000213},
author = {Nanfeng Liu and Philip A. Townsend and Mack R. Naber and Paul C. Bethke and William B. Hills and Yi Wang},
keywords = {Imaging spectroscopy, Petiole nitrate, Foliar nitrogen, Tuber yield, Potato},
abstract = {Imaging spectroscopy provides the opportunity to monitor nutrient status of vegetation. In crops, prior studies have generally been limited in scope, either to a small wavelength range (e.g., 400–1300 nm), a small number of crop cultivars, a single growth stage or single growing season. Methods that are not time- or site-specific are needed to use imaging spectroscopy for routine monitoring of crop status. Using data from four cultivars of potatoes (Solanum tuberosum L.), three growth stages and two growing seasons, we demonstrate the capacity of full-range (400–2350 nm) imaging spectroscopy to quantify nutrient status (petiole nitrate, whole leaf and vine total nitrogen) and predict tuber yield in potatoes across cultivars, growth stages and growing seasons. We specifically tested the capabilities of: (1) ordinary least-squares regression (OLSR) using traditional hyperspectral vegetation indices (VIs); (2) partial least-squares regression (PLSR) using full spectrum (400–2350 nm), VNIR- (visible-to-near infrared: 400–1300 nm) or SWIR-only (shortwave infrared: 1400–2350 nm) wavelengths; (3) predictive models developed for one potato type or planting season on withheld data from a different type or season. Our results show that OLSR models produced poor predictions with data from all dates pooled together (validation R2 < 0.01). Single-date OLSR models performed better (R2 = 0.20–0.60, relative RMSE = 15–30%). PLSR models performed well and were comparable using different spectral regions (full-spectrum, VNIR-only and SWIR-only), with validation R2 = 0.68–0.82 and RRMSE = 12–25%. Testing across potato types, models produced reliable predictions (R2 = 0.45–0.75, RRMSE = 13–30%), but with some bias. Cross-season models had validation R2 = 0.46–0.75 and RRMSE = 17–100%, with a more significant bias than the cross-potato type models. To achieve models that are generalizable and robust, we recommend: (1) obtaining ground measurements that capture the full range of plant growth conditions and developmental stages, and (2) ensuring that image processing approaches minimize spectral discrepancies among dates.}
}
@article{LI2020372,
title = {Popularity prediction on vacation rental websites},
journal = {Neurocomputing},
volume = {412},
pages = {372-380},
year = {2020},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2020.05.092},
url = {https://www.sciencedirect.com/science/article/pii/S0925231220309498},
author = {Yang Li and Suhang Wang and Yukun Ma and Quan Pan and Erik Cambria},
keywords = {Vacation rental websites, Popularity prediction, Dual-gated recurrent unit, Inter-event time and rating score},
abstract = {In the personal house renting scenario, customers usually make quick assessments based on previous customers' reviews, which makes such reviews essential for the business. If the house is assessed as popular, a Matthew effect will be observed as more people will be willing to book it. Due to the lack of definition and quantity assessment measures, however, it is difficult to make a popularity evaluation and prediction. To solve this problem, the concept of house popularity is well defined in this paper. Specifically, the house popularity is decided by inter-event timeand rating score at the same time. To make a more effective prediction over these two correlated variables, a dual-gated recurrent unit (DGRU) is employed. Furthermore, an encoder-decoder framework with DGRU is proposed to perform popularity prediction. Empirical results show the effectiveness of the proposed DGRU and the encoder-decoder framework in two-correlated sequences prediction and popularity prediction, respectively.}
}
@article{KIM202128,
title = {High-resolution multi-beam tracking with low overhead for mmWave beamforming system},
journal = {ICT Express},
volume = {7},
number = {1},
pages = {28-35},
year = {2021},
issn = {2405-9595},
doi = {https://doi.org/10.1016/j.icte.2021.01.014},
url = {https://www.sciencedirect.com/science/article/pii/S240595952100014X},
author = {Seonyong Kim and Girim Kwon and Hyuncheol Park},
keywords = {Millimeter wave communication, Mobility, Beam tracking, Q-learning, Auxiliary beam pair},
abstract = {In millimeter wave communication, the beamforming technique with accurate angle information plays a key role to overcome the high path-loss and mitigate the interference. Particularly with multiple mobile stations (MSs), accurate multi-beam tracking without any knowledge of dynamic model is challenging. In this regard, we propose the model-free multi-beam tracking algorithm combining the Q-learning with auxiliary beam pair-based angle estimation in multi-MS environment. The proposed scheme benefits from low pilot overhead and high-resolution angle estimation. Simulation results show that the proposed scheme outperforms the conventional schemes in terms of the effective sum-rate.}
}
@article{BOGAWSKI20191485,
title = {Predicting the onset of Betula pendula flowering in Poznań (Poland) using remote sensing thermal data},
journal = {Science of The Total Environment},
volume = {658},
pages = {1485-1499},
year = {2019},
issn = {0048-9697},
doi = {https://doi.org/10.1016/j.scitotenv.2018.12.295},
url = {https://www.sciencedirect.com/science/article/pii/S004896971835174X},
author = {Paweł Bogawski and Łukasz Grewling and Bogdan Jackowiak},
keywords = {Phenology, Land surface temperature, Urban heat island, Pollen, Random forest, Silver birch},
abstract = {Due to the urban heat island effect, the time of plant pollination might markedly vary within the area of a city. However, existing pollen forecasts do not reflect the spatial variations in the pollen release time within a heterogeneous urban environment. The main objective of this study was to model the spatial pattern of flowering onset (and thus the moment of pollen release) in silver birch (Betula pendula Roth.) in Poznań (Western Poland) using land surface temperature (LST) data and in situ phenological observations. The onset of silver birch flowering was observed at 34 urban and rural sites (973 trees) in Poznań from 2012 to 2014. Forty-four thermal variables were retrieved from MODerate Resolution Imaging Spectroradiometer (MODIS) data. To predict the spatio-temporal distribution of B. pendula flowering onset dates in a city, the ordinary and partial least squares, support vector machine and random forest regression models were applied. The models' performance was examined by an internal repeated k-fold cross-validation and external validation with archival phenological data (2010). Birch flowering began significantly earlier in the urban sites compared to the rural sites (from −1.4 days in 2013, to −4.1 days in 2012). The maximum March LST difference between the urban and rural sites reached 2.4 °C in 2013 and 4.5 °C in 2012. The random forest model performed best at validation stage, i.e. the root mean square error between the predicted and observed onset dates was 1.461 days, and the determination coefficient was 0.829. A calibrated model for predicting the timing of flowering in a heterogeneous city area is an important step in developing a fine-scale forecasting system that can directly estimate pollen exposure in places where allergy sufferers live. Importantly, by incorporating only pre-flowering thermal data into the model, location-specific allergy forecasts can be delivered to the public before the actual flowering time.}
}
@article{OH2016314,
title = {PSO-based Optimal Task Allocation for Cooperative Timing Missions},
journal = {IFAC-PapersOnLine},
volume = {49},
number = {17},
pages = {314-319},
year = {2016},
note = {20th IFAC Symposium on Automatic Control in AerospaceACA 2016},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2016.09.054},
url = {https://www.sciencedirect.com/science/article/pii/S2405896316315269},
author = {Gyeongtaek Oh and Youdan Kim and Jaemyung Ahn and Han-Lim Choi},
keywords = {Task allocation, Multi-UAV planning, PSO, Cooperative timing mission, Cooperative control},
abstract = {An optimal task allocation algorithm based on Particle swarm optimization (PSO) is proposed for cooperative timing missions that require involvement of multiple agents. The optimal solution can be utilized in the centralized operation of multi-agent system as well as a benchmark solution of the decentralized task allocation algorithm. However, the optimal solution requires significant computations because this problem is known as NP-hard. Therefore, PSO-based approach can be an alternative because it can be used to obtain a near optimal solution with reduced computational load. In this study, the conventional PSO-based algorithm is modified by adopting graph theory. Numerical simulations are carried out to demonstrate the performance of the proposed algorithm.}
}
@article{YANG2021102412,
title = {Retrieving potassium levels in wheat blades using normalised spectra},
journal = {International Journal of Applied Earth Observation and Geoinformation},
volume = {102},
pages = {102412},
year = {2021},
issn = {0303-2434},
doi = {https://doi.org/10.1016/j.jag.2021.102412},
url = {https://www.sciencedirect.com/science/article/pii/S0303243421001197},
author = {Tiancheng Yang and Jingshan Lu and Feng Liao and Hao Qi and Xia Yao and Tao Cheng and Yan Zhu and Weixing Cao and Yongchao Tian},
keywords = {Wheat leaf potassium, Spectral normalisation, Regression model, Vegetation index, Partial least squares, Random forest},
abstract = {This work explored potassium nutrient retrieval in wheat blades using reflectance spectra. Spectral data were collected from wheat blades at different growth stages, in different cultivars, and following different fertilisation treatments from 2016 to 2019 using a leaf clip and halogen bulb with an ASD spectrometer. Reflectance data from 350 to 2500 nm were collected, and data of 400 to 2400 nm were used in the retrieval. Using a leaf clip to measure the reflectance of a narrow blade can cause bias, which can be corrected using a normalisation method, i.e. the reflectance of each band was divided by the average reflectance of all bands. Three such methods were employed: vegetation index (VI), partial least squares (PLS), and random forest (RF). The approach yielded leaf potassium content (LKC, %) and leaf potassium per area (LKA, g/m2). The results showed that newly developed VIs outperformed previously published indices. The model using a modified ratio spectral index, mRSI(2275, 1875), yielded LKC with a coefficient of determination (R2) of 0.61 and a root mean square error (RMSE) of 0.57%. Normalisation methods can eliminate multiplicative error in blade spectra, thereby correcting the underestimated reflectance of narrow blades, and improving the accuracy of potassium retrieval models. Among the three methods, PLS achieved the highest accuracy. The retrieval of LKC and LKA based on normalised spectra and the PLS method yielded R2 values of 0.74 and 0.65, respectively, and their corresponding RMSE values were 0.46% and 0.21 g/m2. LKC retrieval models had higher R2 values than LKA models. This comprehensive analysis of different methods revealed the importance of reflectance at 1883 nm and 2305 nm. In conclusion, it is feasible to retrieve wheat leaf potassium levels using spectral data.}
}
@article{SUBRAMANIAN20123603,
title = {A meta-cognitive sequential learning algorithm for neuro-fuzzy inference system},
journal = {Applied Soft Computing},
volume = {12},
number = {11},
pages = {3603-3614},
year = {2012},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2012.06.012},
url = {https://www.sciencedirect.com/science/article/pii/S1568494612002888},
author = {K. Subramanian and S. Suresh},
keywords = {Meta-cognition, Self-regulatory learning, Neuro-fuzzy inference systems, Time series prediction, Non-linear system identification, Classification},
abstract = {In this paper, we present a meta-cognitive sequential learning algorithm for a neuro-fuzzy inference system, referred to as, ‘Meta-Cognitive Neuro-Fuzzy Inference System’ (McFIS). McFIS has two components, viz., a cognitive component and a meta-cognitive component. The cognitive component employed is a Takagi–Sugeno–Kang type-0 neuro-fuzzy inference system. A self-regulatory learning mechanism that controls the learning process of the cognitive component, by deciding what-to-learn, when-to-learn and how-to-learn from sequential training data, forms the meta-cognitive component. McFIS realizes the above decision by employing sample deletion, sample reserve and sample learning strategy, respectively. The meta-cognitive component use the instantaneous error of the sample and spherical potential of the rule antecedents to select the best training strategy for the current sample. Also, in sample learning strategy, when a new rule is added the rule consequent is assigned such that the localization property of Gaussian rule is fully exploited. The performance of McFIS is evaluated on four regression and eight classification problems. The performance comparison shows the superior generalization performance of McFIS compared to existing algorithms.}
}
@article{BOZHINOSKI2019150,
title = {Safety for mobile robotic systems: A systematic mapping study from a software engineering perspective},
journal = {Journal of Systems and Software},
volume = {151},
pages = {150-179},
year = {2019},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2019.02.021},
url = {https://www.sciencedirect.com/science/article/pii/S0164121219300317},
author = {Darko Bozhinoski and Davide {Di Ruscio} and Ivano Malavolta and Patrizio Pelliccione and Ivica Crnkovic},
keywords = {Software, Safety for mobile robots, Systematic mapping study},
abstract = {Robotic research is making huge progress. However, existing solutions are facing a number of challenges preventing them from being used in our everyday tasks: (i) robots operate in unknown environments, (ii) robots collaborate with each other and even with humans, and (iii) robots shall never injure people or create damages. Researchers are targeting those challenges from various perspectives, producing a fragmented research landscape. We aim at providing a comprehensive and replicable picture of the state of the art from a software engineering perspective on existing solutions aiming at managing safety for mobile robotic systems. We apply the systematic mapping methodology on an initial set of 1274 potentially relevant research papers, we selected 58 primary studies and analyzed them according to a systematically-defined classification framework. This work contributes with (i) a classification framework for methods or techniques for managing safety when dealing with the software of mobile robotic systems (MSRs), (ii) a map of current software methods or techniques for software safety for MRSs, (iii) an elaboration on emerging challenges and implications for future research, and (iv) a replication package for independent replication and verification of this study. Our results confirm that generally existing solutions are not yet ready to be used in everyday life. There is the need of turn-key solutions ready to deal with all the challenges mentioned above.}
}
@article{LIU2015617,
title = {System of systems oriented flight vehicle conceptual design: Perspectives and progresses},
journal = {Chinese Journal of Aeronautics},
volume = {28},
number = {3},
pages = {617-635},
year = {2015},
issn = {1000-9361},
doi = {https://doi.org/10.1016/j.cja.2015.04.017},
url = {https://www.sciencedirect.com/science/article/pii/S1000936115000801},
author = {Hu Liu and Yongliang Tian and Yuan Gao and Jinpeng Bai and Jiangan Zheng},
keywords = {Conceptual design, Effectiveness, Flight vehicle, Modeling and simulation, System of systems},
abstract = {In order to obtain optimized flight vehicle concepts which meet system of systems (SoS) operation requirements, designers have to pay high attention to the impact of SoS at conceptual design stage since operation environment goes increasingly complex. Based on this tendency, perspectives and progresses of SoS oriented flight vehicle conceptual design, which is abbreviate as SoSed design, are reviewed in this paper. Such basic concepts of SoS as definition, characteristics, differences between systems engineering and SoS engineering, as well as SoSed design process are introduced, then SoS engineering process model for research and development of flight vehicles and SoSed design wheel model for conceptual design are proposed. Related literature is classified and analyzed in accordance with four major elements including requirements, design concept, design analysis, and trade studies and optimization: typical SoS architectures, description and quantization of indexes are introduced; Application of inverse design in designing concept is analyzed; Modeling and simulation (M&S)-based methods and their applications in SoSed effectiveness evaluation are highlighted; According to SoSed trade studies and optimization related research, the importance of such points as decision-making and using multidisciplinary design optimization for reference are emphasized. Finally, the value of SoSed design is concluded, and five directions which are worthy of attention in this field are presented.}
}
@article{PARK2021709,
title = {Scale gaps in landscape phenology: challenges and opportunities},
journal = {Trends in Ecology & Evolution},
volume = {36},
number = {8},
pages = {709-721},
year = {2021},
issn = {0169-5347},
doi = {https://doi.org/10.1016/j.tree.2021.04.008},
url = {https://www.sciencedirect.com/science/article/pii/S0169534721001087},
author = {Daniel S. Park and Erica A. Newman and Ian K. Breckheimer},
keywords = {climate change, environmental heterogeneity, landscape ecology, scaling, spatiotemporal resolution, statistical aggregation},
abstract = {Phenology, or the timing of life history events, can be heterogeneous across biological communities and landscapes and can vary across a wide variety of spatiotemporal scales. Here, we synthesize information from landscape phenology studies across different scales of measurement around a set of core concepts. We highlight why phenology is scale dependent and identify gaps in the spatiotemporal scales of phenological observations and inferences. We discuss the consequences of these gaps and describe opportunities to address the inherent sensitivities of phenological metrics to measurement scale. Although most studies we review and discuss are focused on plants, our work provides a broadly relevant overview of the role of observation scale in landscape phenology and a general approach for measuring and reporting scale dependence.}
}
@article{ZHANG20201,
title = {Learning salient features to prevent model drift for correlation tracking},
journal = {Neurocomputing},
volume = {418},
pages = {1-10},
year = {2020},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2019.12.006},
url = {https://www.sciencedirect.com/science/article/pii/S0925231219317059},
author = {Yu Zhang and Xingyu Gao and Zhenyu Chen and Huicai Zhong and Liang Li and Chenggang Yan and Tao Shen},
keywords = {Salient features, Drift prevention, Correlation tracking},
abstract = {Correlation Filter (CF) based algorithms play an important role in the field of Visual Object Tracking (VOT) due to their high accuracy and low computational complexity. While existing CF tracking algorithms suffer performance degradation due to inaccurate object modeling. In this paper, we improve the object modeling accuracy in both CF training stage and target detection procedure to preventing the drift problem. Specifically, we propose a multi-model structure for CF trackers to capture the target appearance changes, where different appearance models are trained with specific samples to catch the salient features of the target and reduce the computational cost. Furthermore, a space filter for detection features is designed to suppress the boundary effect under Gaussian motion prior, which contributes to improving the accuracy of position estimation. We deploy our method to three hand-crafted features based CF trackers to perform real-time visual tracking on popular benchmarks. The experimental results demonstrate the efficacy of our proposed scheme and the efficiency of our trackers. In addition, we provide a comprehensive analysis of the proposed method to facilitate application.}
}
@article{YU20213678,
title = {Stochastic control and time scheduling for irregular robots},
journal = {Journal of the Franklin Institute},
volume = {358},
number = {7},
pages = {3678-3700},
year = {2021},
issn = {0016-0032},
doi = {https://doi.org/10.1016/j.jfranklin.2021.03.005},
url = {https://www.sciencedirect.com/science/article/pii/S0016003221001691},
author = {Hongjun Yu and Yutong Liu and Lihua Liang},
abstract = {Vehicles of different sizes are difficult to navigate in close vicinity. In this paper, we propose multi-vehicle coordination strategy by stochastic control and time scheduling to guarantee no collisions. We use contours and relative motions of vehicles to calculate collision time and use it in multi-vehicle scheduling and reduce computation burden. The proposed strategy enables the vehicles to add calculation delay when vehicles are moving towards the destinations. To avoid complicated control rule design for motion-restricted irregular vehicles, we propose stochastic control to provide satisfactory performance. By changing the frequency of control update, a modification is proposed to take congestion into account. Simulation examples are given to demonstrate the effectiveness of the proposed approach.}
}
@article{WANG2022103914,
title = {Robotic odor source localization via adaptive bio-inspired navigation using fuzzy inference methods},
journal = {Robotics and Autonomous Systems},
volume = {147},
pages = {103914},
year = {2022},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2021.103914},
url = {https://www.sciencedirect.com/science/article/pii/S0921889021001998},
author = {Lingxiao Wang and Shuo Pang},
keywords = {Odor source localization, Behavior-based navigation methods, Fuzzy-inference theories},
abstract = {Robotic odor source localization (OSL) has been viewed as a challenging task due to the turbulent nature of airflows and the resulting odor plume characteristics. The key to solving an OSL problem is designing an effective olfactory-based navigation algorithm, which guides a plume-tracing robot to find the odor source via tracing emitted plumes. Inspired by the mate-seeking behaviors of male moths, this article presents a behavior-based navigation algorithm for using on a mobile robot to locate an odor source in an unknown environment. Unlike traditional bio-inspired algorithms, which use fixed parameters to formulate robot search trajectories, we design a fuzzy controller to perceive the environment and adjust trajectory parameters based on the current search situation. Therefore, the robot can automatically adapt the scale of search trajectories to fit environmental changes and balance the exploration and exploitation of the search. Simulation and on-vehicle results show that compared to two classical olfactory-based navigation algorithms, the proposed algorithm is more efficient and outperforms them in terms of the averaged search time and success rate.}
}
@article{MISHRA201825,
title = {Bayesian hierarchical model-based prognostics for lithium-ion batteries},
journal = {Reliability Engineering & System Safety},
volume = {172},
pages = {25-35},
year = {2018},
issn = {0951-8320},
doi = {https://doi.org/10.1016/j.ress.2017.11.020},
url = {https://www.sciencedirect.com/science/article/pii/S0951832017307494},
author = {Madhav Mishra and Jesper Martinsson and Matti Rantatalo and Kai Goebel},
keywords = {Bayesian hierarchical model, Prognostics, End of discharge, Lithium-ion battery},
abstract = {To optimise operation and maintenance, knowledge of the ability to perform the required functions is vital. The ability is governed by the usage of the system (operational issues) and availability aspects like reliability of different components. This paper proposes a Bayesian hierarchical model (BHM)-based prognostics approach applied to Li-ion batteries, where the goal is to analyse and predict the discharge behaviour of such batteries with variable load profiles and variable amounts of available discharge data. The BHM approach enables inferences for both individual batteries and groups of batteries. Estimates of the hierarchical model parameters and the individual battery parameters are presented, and dependencies on load cycles are inferred. A BHM approach where the operational and reliability aspects end of life (EoD) and end of life (EoL) is studied where its shown that predictions of EoD can be made accurately with a variable amount of battery data. Without access to measurements, e.g. predicting a new battery, the predictions are based only on the prior distributions describing the similarity within the group of batteries and their dependency on the load cycle. A discharge cycle dependency can also be identified in the result giving the opportunity to predict the battery reliability.}
}
@article{YAN2015295,
title = {Urban land cover classification using airborne LiDAR data: A review},
journal = {Remote Sensing of Environment},
volume = {158},
pages = {295-310},
year = {2015},
issn = {0034-4257},
doi = {https://doi.org/10.1016/j.rse.2014.11.001},
url = {https://www.sciencedirect.com/science/article/pii/S0034425714004374},
author = {Wai Yeung Yan and Ahmed Shaker and Nagwa El-Ashmawy},
keywords = {Airborne LiDAR, Laser scanning, LiDAR intensity, Land cover mapping, Land cover classification, Radiometric calibration, Radiometric correction, Full-waveform, Urban environment, Urban analysis},
abstract = {Distribution of land cover has a profound impact on the climate and environment; mapping the land cover patterns from global, regional to local scales are important for scientists and authorities to yield better monitoring of the changing world. Satellite remote sensing has been demonstrated as an efficient tool to monitor the land cover patterns for a large spatial extent. Nevertheless, the demand on land cover maps at a finer scale (especially in urban areas) has been raised with evidence by numerous biophysical and socio-economic studies. This paper reviews the small-footprint LiDAR sensor — one of the latest high resolution airborne remote sensing technologies, and its application on urban land cover classification. While most of the early researches focus on the analysis of geometric components of 3D LiDAR data point clouds, there has been an increasing interest in investigating the use of intensity data, waveform data and multi-sensor data to facilitate land cover classification and object recognition in urban environment. In this paper, the advancement of airborne LiDAR technology, including data configuration, feature spaces, classification techniques, and radiometric calibration/correction is reviewed and discussed. The review mainly focuses on the LiDAR studies conducted during the last decade with an emphasis on identification of the approach, analysis of pros and cons, investigating the overall accuracy of the technology, and how the classification results can serve as an input for different urban environmental analyses. Finally, several promising directions for future LiDAR research are highlighted, in hope that it will pave the way for the applications of urban environmental modeling and assessment at a finer scale and a greater extent.}
}
@article{MYGDALIS201970,
title = {Exploiting multiplex data relationships in Support Vector Machines},
journal = {Pattern Recognition},
volume = {85},
pages = {70-77},
year = {2019},
issn = {0031-3203},
doi = {https://doi.org/10.1016/j.patcog.2018.07.032},
url = {https://www.sciencedirect.com/science/article/pii/S0031320318302723},
author = {Vasileios Mygdalis and Anastasios Tefas and Ioannis Pitas},
keywords = {Multiplex data relationships, Support Vector Machine, Graph-based regularization, Multiple Kernel Learning},
abstract = {In this paper, a novel method for introducing multiplex data relationships to the SVM optimization process is presented. Different properties about the training data are encoded in graph structures, in the form of pairwise data relationships. Then, they are incorporated to the SVM optimization problem, as modified graph-regularized basekernels, each highlighting a different property about the training data. The contribution of each graph-regularized kernel to the SVM classification problem, is estimated automatically. Thereby, the solution of the proposed modified SVM optimization problem lies in a regularized space, where data similarity is expressed by a linear combination of multiple single-graph regularized kernels. The proposed method exploits and extends the findings of Multiple Kernel Learning and graph-based SVM method families. It is shown that the available kernel options for the former can be broadened, and the exhaustive parameter tuning for the latter can be eliminated. Moreover, both method families can be considered as special cases of the proposed formulation, hereafter. Our experimental evaluation in visual data classification problems denote the superiority of the proposed method. The obtained classification performance gains can be explained by the exploitation of multiplex data relationships, during the classifier optimization process.}
}
@article{LIU2021273,
title = {Robust feature matching via advanced neighborhood topology consensus},
journal = {Neurocomputing},
volume = {421},
pages = {273-284},
year = {2021},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2020.09.047},
url = {https://www.sciencedirect.com/science/article/pii/S0925231220314557},
author = {Yizhang Liu and Yanping Li and Luanyuan Dai and Changcai Yang and Lifang Wei and Taotao Lai and Riqing Chen},
keywords = {Feature matching, Outlier removal, Guided matching strategy, Neighborhood topology},
abstract = {Feature matching is one of the key techniques in many vision-based tasks, which aims to establish reliable correspondences between two sets of features. In this paper, we present a new feature matching method, which formulates the matching of two feature sets as a mathematical model based on two common consistency constraints. We first propose an advanced consensus of neighborhood topology, which can better exploit the consensus of topological structures to identify inliers. In order to have reliable neighborhood information for the feature points, a subset with high percentage inliers obtained by a guided matching strategy from the putative matches for the neighborhood construction is used. We demonstrate the advantages of our proposed method on various real image pairs. The results demonstrate that the proposed method is superior to the state-of-the-art feature matching methods.}
}
@article{LI20171,
title = {An inverted classroom approach to educate MATLAB in chemical process control},
journal = {Education for Chemical Engineers},
volume = {19},
pages = {1-12},
year = {2017},
issn = {1749-7728},
doi = {https://doi.org/10.1016/j.ece.2016.08.001},
url = {https://www.sciencedirect.com/science/article/pii/S1749772816300252},
author = {Xianhua Li and Zuyi (Jacky) Huang},
keywords = {Inverted-classroom, MATLAB, Simulink, ODE simulation, Laplace transform, Chemical process control},
abstract = {The inverted-classroom teaching format and the application of MATLAB/Simulink have recently generated considerable research interest in chemical engineering education. MATLAB/Simulink was introduced in mathematics-intensive courses due to its user-friendly interface for mathematical model simulations. Inverted classroom approach has been reported to be generally beneficial for engineering courses, but it has never been applied to MATLAB/Simulink education in a single course. The aim of our study is to examine the effectiveness of the inverted-classroom approach in developing MATLAB/Simulink skills of upper-division undergraduates in Villanova's chemical process control course. Teaching modules include solving ODE models, performing Laplace transform, and designing PID controllers. Surveys of students’ evaluation revealed that the three inverted-classroom teaching modules were effective in enhancing students’ understanding of mathematics-intensive process control concepts and improving their MATLAB simulation skills. Students’ overall feedback on the inverted-classroom format was positive as they gradually adapted to inverted-classroom learning format.}
}
@article{PALMA2020118528,
title = {Structural health monitoring of timber structures – Review of available methods and case studies},
journal = {Construction and Building Materials},
volume = {248},
pages = {118528},
year = {2020},
issn = {0950-0618},
doi = {https://doi.org/10.1016/j.conbuildmat.2020.118528},
url = {https://www.sciencedirect.com/science/article/pii/S095006182030533X},
author = {Pedro Palma and René Steiger},
keywords = {Timber structures, Health monitoring, Non-destructive testing, Review, Case studies, Survey},
abstract = {Significant developments in structural health monitoring (SHM) and in non-destructive testing (NDT) and damage identification techniques for structural timber elements have led to an increasing interest in the application of these technologies. However, specific aspects of timber structures (anisotropy, moisture dependency, high variability), the wide range and novelty of available systems, and the need to adapt them for each configuration, makes specifying and implementing a SHM system a non-trivial task, heavily dependent on previous experience. This article presents a comprehensive review of available SHM and NDT methods, case studies, and a survey on the implementation of SHM in timber structures.}
}
@article{PISHKENARI2011261,
title = {Optimum synthesis of fuzzy logic controller for trajectory tracking by differential evolution},
journal = {Scientia Iranica},
volume = {18},
number = {2},
pages = {261-267},
year = {2011},
issn = {1026-3098},
doi = {https://doi.org/10.1016/j.scient.2011.03.021},
url = {https://www.sciencedirect.com/science/article/pii/S1026309811000228},
author = {H. Nejat Pishkenari and S.H. Mahboobi and A. Alasty},
keywords = {Trajectory tracking, Mobile robot, Differential evolution, Genetic algorithm, Fuzzy membership functions},
abstract = {Differential Evolution (DE) and Genetic Algorithms (GA) are population based search algorithms that come under the category of evolutionary optimization techniques. In the present study, these evolutionary methods have been utilized to conduct the optimum design of a fuzzy controller for mobile robot trajectory tracking. Comparison between their performances has also been conducted. In this paper, we will present a fuzzy controller to the problem of mobile robot path tracking for a CEDRA rescue robot. After designing the fuzzy tracking controller, the membership functions will be optimized by evolutionary algorithms in order to obtain more acceptable results.}
}
@article{YUE2016389,
title = {Image super-resolution: The techniques, applications, and future},
journal = {Signal Processing},
volume = {128},
pages = {389-408},
year = {2016},
issn = {0165-1684},
doi = {https://doi.org/10.1016/j.sigpro.2016.05.002},
url = {https://www.sciencedirect.com/science/article/pii/S0165168416300536},
author = {Linwei Yue and Huanfeng Shen and Jie Li and Qiangqiang Yuan and Hongyan Zhang and Liangpei Zhang},
keywords = {Super resolution, Resolution enhancement, Regularized framework, Applications},
abstract = {Super-resolution (SR) technique reconstructs a higher-resolution image or sequence from the observed LR images. As SR has been developed for more than three decades, both multi-frame and single-frame SR have significant applications in our daily life. This paper aims to provide a review of SR from the perspective of techniques and applications, and especially the main contributions in recent years. Regularized SR methods are most commonly employed in the last decade. Technical details are discussed in this article, including reconstruction models, parameter selection methods, optimization algorithms and acceleration strategies. Moreover, an exhaustive summary of the current applications using SR techniques has been presented. Lastly, the article discusses the current obstacles for future research.}
}
@article{LIU2020103172,
title = {Intelligent rebar layout in RC building frames using artificial potential field},
journal = {Automation in Construction},
volume = {114},
pages = {103172},
year = {2020},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2020.103172},
url = {https://www.sciencedirect.com/science/article/pii/S0926580519304339},
author = {Jiepeng Liu and Chengran Xu and Zhou Wu and Y. Frank Chen},
keywords = {Rebar layout, Rebar constructability, Reinforced concrete design, Artificial potential field, Building information modeling},
abstract = {Reinforced concrete (RC) beam-column joints are the critical components of RC building frames. Congestion and even collision of reinforcing bars (rebars) encounter frequently in the core region of a joint. The building information modeling (BIM) technology is helpful to detect the rebar collision, which has to be revised manually. In this paper, inspired by collision-free capability of intelligent agent, an automatic rebar layout framework based on artificial potential field (APF) is proposed to solve the issues of rebar collision and congestion during the design stage. The rebars in a beam-column joint are regarded as agents, and a novel APF method is proposed to guide the moving trajectory of each agent. The APF method ensures that each rebar-agent can reach its goal point and escape from the trapping of local-minimum point. An Autodesk Revit add-in is developed to save modeling time and improve accuracy. Experiments on a two-story RC frame validate the applicability and efficiency of the intelligent rebar layout framework. It can be shown that the developed framework can avoid the rebar collision and congestion at beam-column joints quickly and effectively.}
}
@article{HUANG2011495,
title = {FERA in parameter identification with application in low speed wind tunnel test},
journal = {Aerospace Science and Technology},
volume = {15},
number = {6},
pages = {495-509},
year = {2011},
issn = {1270-9638},
doi = {https://doi.org/10.1016/j.ast.2010.10.002},
url = {https://www.sciencedirect.com/science/article/pii/S1270963810001379},
author = {Ching-Huei Huang and Chun-Liang Lin and Maw-Jy Chao},
keywords = {Fuzzy logic theory, System realization, Parameter identification},
abstract = {This paper presents a new approach which consists of a fuzzified eigensystem realization algorithm (FERA) to identify the parameters of the designed mini-UAV model performance in the low speed wind tunnel (LSWT) power on testing system. On the basis of the identification scheme, it is able to reduce system operational cost of wind tunnel tests and provide a tool for predicting results without resorting to on-site experiments. A variety of variables in model types and testing environment such as model profile, angle of attack, elevator, tunnel wind speed and power system (motor and propeller) are considered. The method based on logic devices is simple yet effective. The results obtained are compared to those obtained by the conventional wind-tunnel testing method. To verify effectiveness of the proposed methodology, both of simulations and real-world experiments are conducted. The results show that the working performance of the proposed method correlates well with expectation.}
}
@article{MATTYUS2016218,
title = {Aerial image sequence geolocalization with road traffic as invariant feature},
journal = {Image and Vision Computing},
volume = {52},
pages = {218-229},
year = {2016},
issn = {0262-8856},
doi = {https://doi.org/10.1016/j.imavis.2016.05.014},
url = {https://www.sciencedirect.com/science/article/pii/S0262885616301056},
author = {Gellért Máttyus and Friedrich Fraundorfer},
keywords = {Geolocalization, Georeferencing, Geotagging, Geometric hashing},
abstract = {The geolocalization of aerial images is important for extracting geospatial information (e.g. the position of buildings, streets, and cars) and for creating maps. The standard is to use an expensive aerial imaging system equipped with an accurate GPS and IMU and/or do laborious ground control point measurements. In this paper we present a novel method to recognize the geolocation of aerial images automatically without any GPS or IMU. We extract road segments in the image sequence by detecting and tracking cars. We search in a database created from a road network map for the best matches between the road database and the extracted road segments. Geometric hashing is used to retrieve a shortlist of matches. The matches in the shortlist are ranked by a verification process. The highest scoring match gives the location and orientation of the images. We show in the experiments that our method can correctly geolocalize the aerial images in various scenes: e.g. urban, suburban, and rural with motorway. Besides the current images only the road map is needed over the search area. We can search an area of 22,500km2 containing 32,000km of streets within minutes on a single cpu.}
}
@article{SANIN2019604,
title = {Experience based knowledge representation for Internet of Things and Cyber Physical Systems with case studies},
journal = {Future Generation Computer Systems},
volume = {92},
pages = {604-616},
year = {2019},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2018.01.062},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X17316965},
author = {Cesar Sanin and Zhang Haoxi and Imran Shafiq and Md Maqbool Waris and Caterine {Silva de Oliveira} and Edward Szczerbicki},
keywords = {Decisional DNA, Set of experience knowledge structure, Cyber Physical Systems, Internet of Things, Factory 4.0, Knowledge representation, Knowledge engineering, Decision making, Artificial intelligence, Virtual engineering object, Virtual engineering process, Virtual engineering factory},
abstract = {Cyber Physical Systems and Internet of Things have grown significant attention from industry and academia during the past decade. The main reason behind this interest is the capabilities of such technologies to revolutionize human life since they appear as seamlessly integrating classical networks, networked objects and people to create more efficient environments. However, enhancing these technologies with intelligent skills becomes an even more interesting and enticing scenario. In this paper, we propose and illustrate through a number of case studies how Decisional DNA, a multi-domain knowledge structure based on experience, can be implemented as a comprehensive embedded knowledge representation for Internet of Things and Cyber Physical Systems. Decisional DNA gathers explicit experiential knowledge based on formal decision events and uses this knowledge to support decision-making processes. The main advantages of using Decisional DNA are as follows: (i) offers a standardized form of the collected knowledge and experience, (ii) provides versatility and dynamicity of the knowledge structure, (iii) stipulates storage of day-to-day explicit experience in a single configuration, (iv) delivers transportability and shareability of the knowledge, and (v) provides predicting capabilities based on the collected experience. Consequently, test and results of the presented implementation of Decisional DNA case studies support it as a technology that can improve and be applied to the aforementioned technologies enhancing them with intelligence by predicting capabilities and facilitating knowledge engineering processes.}
}
@article{WANG2015478,
title = {Uncertain multiobjective traveling salesman problem},
journal = {European Journal of Operational Research},
volume = {241},
number = {2},
pages = {478-489},
year = {2015},
issn = {0377-2217},
doi = {https://doi.org/10.1016/j.ejor.2014.09.012},
url = {https://www.sciencedirect.com/science/article/pii/S0377221714007334},
author = {Zutong Wang and Jiansheng Guo and Mingfa Zheng and Ying Wang},
keywords = {Uncertainty modeling, Traveling salesman problem, Multiobjective optimization, Artificial bee colony algorithm},
abstract = {Traveling salesman problem is a fundamental combinatorial optimization model studied in the operations research community for nearly half a century, yet there is surprisingly little literature that addresses uncertainty and multiple objectives in it. A novel TSP variation, called uncertain multiobjective TSP (UMTSP) with uncertain variables on the arc, is proposed in this paper on the basis of uncertainty theory, and a new solution approach named uncertain approach is applied to obtain Pareto efficient route in UMTSP. Considering the uncertain and combinatorial nature of UMTSP, a new ABC algorithm inserted with reverse operator, crossover operator and mutation operator is designed to this problem, which outperforms other algorithms through the performance comparison on three benchmark TSPs. Finally, a new benchmark UMTSP case study is presented to illustrate the construction and solution of UMTSP, which shows that the optimal route in deterministic TSP can be a poor route in UMTSP.}
}
@article{STANLEY2021268,
title = {Metrics for aerial, urban lidar point clouds},
journal = {ISPRS Journal of Photogrammetry and Remote Sensing},
volume = {175},
pages = {268-281},
year = {2021},
issn = {0924-2716},
doi = {https://doi.org/10.1016/j.isprsjprs.2021.01.010},
url = {https://www.sciencedirect.com/science/article/pii/S0924271621000101},
author = {Michael H. Stanley and Debra F. Laefer},
keywords = {Remote sensing, LiDAR, urban aerial laser scanning, LiDAR density, LiDAR accuracy, registration error},
abstract = {This paper introduces five new density and accuracy metrics for aerial point clouds that address the complexity and objectives of modern, dense laser scans of urban scenes. The five metrics describe (1) vertical surface density (points per area on vertical surfaces); (2) vertical density as a function of horizontal density; (3) vertical surface accuracy; and a decomposition of error into (4) within-pass and (5) cross-pass components. Specifically considered is vertical surface coverage and the practice of overlapping flight passes to reduce the occlusions and achieve the vertical density needed for twenty-first-century use cases (e.g. curb and window detection). The application of these metrics to a quartet of recent urban flyovers demonstrates their relevance by establishing (1) the efficacy of considering sensor position and wall height when predicting point density on vertical surfaces; (2) that cross-pass registration accounts for a disproportionate amount of the vertical surface error (but not horizontal) and provides a meaningful parameter to compare high-density, urban point clouds; and (3) that compared to horizontal density and accuracy, the vertical counterparts are disproportionately impacted (positively for density and negatively for accuracy) by modern, optimized flight missions.}
}
@article{HEIDARI2019105521,
title = {Efficient boosted grey wolf optimizers for global search and kernel extreme learning machine training},
journal = {Applied Soft Computing},
volume = {81},
pages = {105521},
year = {2019},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2019.105521},
url = {https://www.sciencedirect.com/science/article/pii/S1568494619302911},
author = {Ali Asghar Heidari and Rahim {Ali Abbaspour} and Huiling Chen},
keywords = {Nature-inspired computing, Metaheuristic, Swarm intelligence, Optimization, Grey wolf optimizer},
abstract = {Grey wolf optimizer (GWO) is a new nature-inspired algorithm that simulates the predatory behaviors of grey wolves in nature. The GWO mainly divides the whole hunting process into three stages: encircling, hunting, and attacking when they are nearby the prey. Since its introduction, the GWO has found its applications in a wide range of engineering and science fields. However, when tackling more complex optimization problems, especially the high dimensional and multimodal tasks, GWO may easily fall into the local optima or be unsuccessful in finding the global best. In addition, convergence behaviors may not be very satisfying. In this study, the performance of basic GWO is enhanced using effective exploratory and exploitative mechanisms such as random leaders, opposition-based learning, levy fight patterns, random spiral-form motions, and greedy selection. These concepts are utilized to improve the global exploration and local exploitation capacities of the conventional technique and deepen the searching advantages of GWO in dealing with more complex problems. Also, the proposed mechanisms can ameliorate the convergence inclinations and the quality of the solutions. In order to verify the efficacy of the proposed method, which is called OBLGWO; it is compared to a comprehensive set of the new and state-of-the-art optimizers on 23 benchmark test sets and 30 well-known CEC problems. Additionally, the proposed OBLGWO is also applied to the tuning of the key parameters of kernel extreme learning machine (KELM) in dealing with two real-world problems. The experimental results and analysis demonstrate that the proposed OBLGWO can significantly outperform GWO, previous enhanced GWO variants and some of the other well-established algorithms in terms of convergence speed and the quality of solutions.}
}
@article{CHIANG2019181,
title = {Seamless navigation and mapping using an INS/GNSS/grid-based SLAM semi-tightly coupled integration scheme},
journal = {Information Fusion},
volume = {50},
pages = {181-196},
year = {2019},
issn = {1566-2535},
doi = {https://doi.org/10.1016/j.inffus.2019.01.004},
url = {https://www.sciencedirect.com/science/article/pii/S1566253518301350},
author = {K.W. Chiang and G.J. Tsai and H.W. Chang and C. Joly and N. EI-Sheimy},
keywords = {Mobile Mapping Systems, INS/GNSS, SLAM, GNSS-denied environments, LiDAR},
abstract = {Mobile Mapping Systems (MMS) with Inertial Navigation System / Global Navigation Satellite System (INS/GNSS) and mapping sensors have been widely developed in recent years. However current systems and results are still prone to errors, especially in GNSS-denied or multipath environments. To provide robust and stable navigation information, particularly for mapping in long-term GNSS-denied environments, we propose a semi-tightly coupled integration scheme which integrates INS/GNSS with grid-based Simultaneous Localization and Mapping (SLAM). Although traditional SLAM using LiDAR can map the GNSS-denied environment efficiently, it is only in local localization. The proposed integration scheme is based on the Extended Kalman Filter (EKF) with motion constraints. In this scheme, a measurement model for grid-based SLAM is aided by the heading and velocity information. A special innovation of this scheme is the improved fusion of GNSS/INS with the use of grid-based SLAM serves like virtual odometer and virtual compass, thus gaining reliable measurements and error models to maintain good performance during INS-only mode. In addition, the initial values for example position and heading, are given to solve global localization and loop closure problems in SLAM. Finally, a smoothing and multi-resolution map strategy are applied offline to increase the robustness and performance of the proposed grid-based SLAM. Evaluation based on experimental data shows the significant improvement by the proposed semi-tightly coupled integration scheme with low-cost INS/GNSS and LiDAR, which is able to achieve 1–2 m’ accuracy in terms of positioning and mapping. An approximately 60% improvement was achieved during long-term GNSS-denied environments using the proposed integration scheme.}
}
@article{SUN2020214,
title = {Fixed-time event-triggered synchronization of a multilayer Kuramoto-oscillator network},
journal = {Neurocomputing},
volume = {379},
pages = {214-226},
year = {2020},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2019.10.040},
url = {https://www.sciencedirect.com/science/article/pii/S0925231219314195},
author = {Jia Sun and Jian Liu and Yuanda Wang and Yao Yu and Changyin Sun},
keywords = {Kuramoto-oscillator, Complex network, Fixed-time control, Event-triggered control, Synchronization control},
abstract = {This paper investigates the synchronization problem of the Kuramoto-oscillator network with non-identical oscillators. The fixed-time event-triggered synchronization control strategies are developed for phase agreement and frequency synchronization under both continuous and intermittent communication. With the developed fixed-time controller, the synchronization can be achieved within a pre-defined time for any initial phase of each oscillator. The event-triggered mechanism avoids continuous controller update and data transmission, which significantly saves the computation and communication resources. Furthermore, theoretical analysis shows that the fixed-time convergence can be guaranteed and the Zeno behavior is avoided by the proposed methods. The numerical simulations of each situation also verify the effectiveness of the proposed synchronization control strategies.}
}
@article{CANNON2012367,
title = {Detection of temporal changes in psychophysiological data using statistical process control methods},
journal = {Computer Methods and Programs in Biomedicine},
volume = {107},
number = {3},
pages = {367-381},
year = {2012},
issn = {0169-2607},
doi = {https://doi.org/10.1016/j.cmpb.2011.01.003},
url = {https://www.sciencedirect.com/science/article/pii/S0169260711000137},
author = {Jordan Cannon and Pavlo A. Krokhmal and Yong Chen and Robert Murphey},
keywords = {Statistical process control, Control charts, Psychophysiological data, Electroencephalogram, Electrooculogram},
abstract = {We consider the problem of detecting temporal changes in the functional state of human subjects due to varying levels of cognitive load using real-time psychophysiological data. The proposed approach relies on monitoring several channels of electroencephalogram (EEG) and electrooculogram (EOG) signals using the methods of statistical process control. It is demonstrated that control charting methods are capable of detecting changes in psychophysiological signals that are induced by varying cognitive load with high accuracy and low false alarm rates, and are capable of accommodating subject-specific differences while being robust with respect to differences between different trials performed by the same subject.}
}
@article{RANDIN2020111626,
title = {Monitoring biodiversity in the Anthropocene using remote sensing in species distribution models},
journal = {Remote Sensing of Environment},
volume = {239},
pages = {111626},
year = {2020},
issn = {0034-4257},
doi = {https://doi.org/10.1016/j.rse.2019.111626},
url = {https://www.sciencedirect.com/science/article/pii/S0034425719306467},
author = {Christophe F. Randin and Michael B. Ashcroft and Janine Bolliger and Jeannine Cavender-Bares and Nicholas C. Coops and Stefan Dullinger and Thomas Dirnböck and Sandra Eckert and Erle Ellis and Néstor Fernández and Gregory Giuliani and Antoine Guisan and Walter Jetz and Stéphane Joost and Dirk Karger and Jonas Lembrechts and Jonathan Lenoir and Miska Luoto and Xavier Morin and Bronwyn Price and Duccio Rocchini and Michael Schaepman and Bernhard Schmid and Peter Verburg and Adam Wilson and Paul Woodcock and Nigel Yoccoz and Davnah Payne},
keywords = {Species distribution models, Remote sensing, Anthropocene, Monitoring, Terrestrial ecosystems, Sustainable development},
abstract = {In the face of the growing challenges brought about by human activities, effective planning and decision-making in biodiversity and ecosystem conservation, restoration, and sustainable development are urgently needed. Ecological models can play a key role in supporting this need and helping to safeguard the natural assets that underpin human wellbeing and support life on land and below water (United Nations Sustainable Development Goals; SDG 15 & 14). The urgency and complexity of safeguarding forest (SDG 15.2) and mountain ecosystems (SDG 15.4), for example, and halting decline in biodiversity (SDG 15.5) in the Anthropocene requires a re-envisioning of how ecological models can best support the comprehensive assessments of biodiversity and its change that are required for successful action. A key opportunity to advance ecological modeling for both predictive and explanatory purposes arises through a collaboration between ecologists and the Earth observation community, and a close integration of remote sensing and species distribution models. Remote sensing products have the capacity to provide continuous spatiotemporal information about key factors driving the distribution of organisms, therefore improving both the use and accuracy of these models for management and planning. Here we first survey the literature on remote sensing data products available to ecological modelers interested in improving predictions of species range dynamics under global change. We specifically explore the key biophysical processes underlying the distribution of species in the Anthropocene including climate variability, changes in land cover, and disturbances. We then discuss potential synergies between the ecological modeling and remote sensing communities, and highlight opportunities to close the data and conceptual gaps that currently impede a more effective application of remote sensing for the monitoring and modeling of ecological systems. Specific attention is given to how potential collaborations between the two communities could lead to new opportunities to report on progress towards global agendas - such as the Agenda 2030 for sustainable development of the United Nations or the Post-2020 Global Biodiversity Framework of the Convention for Biological Diversity, and help guide conservation and management strategies towards sustainability.}
}
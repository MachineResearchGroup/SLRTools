
@Article{rs13081508,
AUTHOR = {Kang, Yeseong and Nam, Jinwoo and Kim, Younggwang and Lee, Seongtae and Seong, Deokgyeong and Jang, Sihyeong and Ryu, Chanseok},
TITLE = {Assessment of Regression Models for Predicting Rice Yield and Protein Content Using Unmanned Aerial Vehicle-Based Multispectral Imagery},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {8},
ARTICLE-NUMBER = {1508},
URL = {https://www.mdpi.com/2072-4292/13/8/1508},
ISSN = {2072-4292},
ABSTRACT = {Unmanned aerial vehicle-based multispectral imagery including five spectral bands (blue, green, red, red-edge, and near-infrared) for a rice field in the ripening stage was used to develop regression models for predicting the rice yield and protein content and to select the most suitable regression analysis method for the year-invariant model: partial least squares regression, ridge regression, and artificial neural network (ANN). The regression models developed with six vegetation indices (green normalization difference vegetation index (GNDVI), normalization difference red-edge index (NDRE), chlorophyll index red edge (CIrededge), difference NIR/Green green difference vegetation index (GDVI), green-red NDVI (GRNDVI), and medium resolution imaging spectrometer terrestrial chlorophyll index (MTCI)), calculated from the spectral bands, were applied to single years (2018, 2019, and 2020) and multiple years (2018 + 2019, 2018 + 2020, 2019 + 2020, and all years). The regression models were cross-validated through mutual prediction against the vegetation indices in nonoverlapping years, and the prediction errors were evaluated via root mean squared error of prediction (RMSEP). The ANN model was reproducible, with low and sustained prediction errors of 24.2 kg/1000 m2 ≤ RMSEP ≤ 59.1 kg/1000 m2 in rice yield and 0.14% ≤ RMSEP ≤ 0.28% in rice-protein content in all single-year and multiple-year analyses. When the importance of each vegetation index of the regression models was evaluated, only the ANN model showed the same ranking in the vegetation index of the first (MTCI in both rice yield and protein content) and second importance (CIrededge in rice yield and GRNDVI in rice-protein content). Overall, this means that the ANN model has the highest potential for developing a year-invariant model with stable RMSEP and consistent variable ranking.},
DOI = {10.3390/rs13081508}
}



@Article{rs13081512,
AUTHOR = {Xiong, Quan and Di, Liping and Feng, Quanlong and Liu, Diyou and Liu, Wei and Zan, Xuli and Zhang, Lin and Zhu, Dehai and Liu, Zhe and Yao, Xiaochuang and Zhang, Xiaodong},
TITLE = {Deriving Non-Cloud Contaminated Sentinel-2 Images with RGB and Near-Infrared Bands from Sentinel-1 Images Based on a Conditional Generative Adversarial Network},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {8},
ARTICLE-NUMBER = {1512},
URL = {https://www.mdpi.com/2072-4292/13/8/1512},
ISSN = {2072-4292},
ABSTRACT = {Sentinel-2 images have been widely used in studying land surface phenomena and processes, but they inevitably suffer from cloud contamination. To solve this critical optical data availability issue, it is ideal to fuse Sentinel-1 and Sentinel-2 images to create fused, cloud-free Sentinel-2-like images for facilitating land surface applications. In this paper, we propose a new data fusion model, the Multi-channels Conditional Generative Adversarial Network (MCcGAN), based on the conditional generative adversarial network, which is able to convert images from Domain A to Domain B. With the model, we were able to generate fused, cloud-free Sentinel-2-like images for a target date by using a pair of reference Sentinel-1/Sentinel-2 images and target-date Sentinel-1 images as inputs. In order to demonstrate the superiority of our method, we also compared it with other state-of-the-art methods using the same data. To make the evaluation more objective and reliable, we calculated the root-mean-square-error (RSME), R2, Kling–Gupta efficiency (KGE), structural similarity index (SSIM), spectral angle mapper (SAM), and peak signal-to-noise ratio (PSNR) of the simulated Sentinel-2 images generated by different methods. The results show that the simulated Sentinel-2 images generated by the MCcGAN have a higher quality and accuracy than those produced via the previous methods.},
DOI = {10.3390/rs13081512}
}



@Article{agronomy11040771,
AUTHOR = {Liu, Li-Wei and Hsieh, Sheng-Hsin and Lin, Su-Ju and Wang, Yu-Min and Lin, Wen-Shin},
TITLE = {Rice Blast (Magnaporthe oryzae) Occurrence Prediction and the Key Factor Sensitivity Analysis by Machine Learning},
JOURNAL = {Agronomy},
VOLUME = {11},
YEAR = {2021},
NUMBER = {4},
ARTICLE-NUMBER = {771},
URL = {https://www.mdpi.com/2073-4395/11/4/771},
ISSN = {2073-4395},
ABSTRACT = {This study aimed to establish a machine learning (ML)-based rice blast predicting model to decrease the appreciable losses based on short-term environment data. The average, highest and lowest air temperature, average relative humidity, soil temperature and solar energy were selected for model development. The developed multilayer perceptron (MLP), support vector machine (SVM), Elman recurrent neural network (Elman RNN) and probabilistic neural network (PNN) were evaluated by F-measures. Finally, a sensitivity analysis (SA) was conducted for the factor importance assessment. The study result shows that the PNN performed best with the F-measure (β = 2) of 96.8%. The SA was conducted in the PNN model resulting in the main effect period is 10 days before the rice blast happened. The key factors found are minimum air temperature, followed by solar energy and equaled sensitivity of average relative humidity, maximum air temperature and soil temperature. The temperature phase lag in air and soil may cause a lower dew point and suitable for rice blast pathogens growth. Through this study’s results, rice blast warnings can be issued 10 days in advance, increasing the response time for farmers preparing related preventive measures, further reducing the losses caused by rice blast.},
DOI = {10.3390/agronomy11040771}
}



@Article{app11083547,
AUTHOR = {Hou, Xiaoyu and Zhang, Kunlin and Xu, Jihui and Huang, Wei and Yu, Xinmiao and Xu, Huaiyu},
TITLE = {Object Detection in Drone Imagery via Sample Balance Strategies and Local Feature Enhancement},
JOURNAL = {Applied Sciences},
VOLUME = {11},
YEAR = {2021},
NUMBER = {8},
ARTICLE-NUMBER = {3547},
URL = {https://www.mdpi.com/2076-3417/11/8/3547},
ISSN = {2076-3417},
ABSTRACT = {With the advent of drones, new potential applications have emerged for the unconstrained analysis of images and videos from aerial view cameras. Despite the tremendous success of the generic object detection methods developed using ground-based photos, a considerable performance drop is observed when these same methods are directly applied to images captured by Unmanned Aerial Vehicles (UAVs). Usually, most of the work goes into improving the performance of the detector in aspects such as design loss, training sample selection, feature enhancement, and so forth. This paper proposes a detection framework based on an anchor-free detector with several modules, including a sample balance strategies module and super-resolved generated feature module, to improve performance. We proposed the sample balance strategies module to optimize the imbalance among training samples, especially the imbalance between positive and negative, and easy and hard samples. Due to the high frequencies and noisy representation of the small objects in images captured by drones, the detection task is extraordinarily challenging. However, when compared with other algorithms of this kind, our method achieves better results. We also propose a super-resolved generated GAN (Generative Adversarial Network) module with center-ness weights to effectively enhance the local feature map. Finally, we demonstrate our method’s effectiveness with the proposed modules by carrying out a state-of-the-art performance on Visdrone2020 benchmarks.},
DOI = {10.3390/app11083547}
}



@Article{rs13081529,
AUTHOR = {Jiang, Yufeng and Zhang, Li and Yan, Min and Qi, Jianguo and Fu, Tianmeng and Fan, Shunxiang and Chen, Bowei},
TITLE = {High-Resolution Mangrove Forests Classification with Machine Learning Using Worldview and UAV Hyperspectral Data},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {8},
ARTICLE-NUMBER = {1529},
URL = {https://www.mdpi.com/2072-4292/13/8/1529},
ISSN = {2072-4292},
ABSTRACT = {Mangrove forests, as important ecological and economic resources, have suffered a loss in the area due to natural and human activities. Monitoring the distribution of and obtaining accurate information on mangrove species is necessary for ameliorating the damage and protecting and restoring mangrove forests. In this study, we compared the performance of UAV Rikola hyperspectral images, WorldView-2 (WV-2) satellite-based multispectral images, and a fusion of data from both in the classification of mangrove species. We first used recursive feature elimination‒random forest (RFE-RF) to select the vegetation’s spectral and texture feature variables, and then implemented random forest (RF) and support vector machine (SVM) algorithms as classifiers. The results showed that the accuracy of the combined data was higher than that of UAV and WV-2 data; the vegetation index features of UAV hyperspectral data and texture index of WV-2 data played dominant roles; the overall accuracy of the RF algorithm was 95.89% with a Kappa coefficient of 0.95, which is more accurate and efficient than SVM. The use of combined data and RF methods for the classification of mangrove species could be useful in biomass estimation and breeding cultivation.},
DOI = {10.3390/rs13081529}
}



@Article{s21082793,
AUTHOR = {Chao, Luomeng and Wu, Celimuge and Yoshinaga, Tsutomu and Bao, Wugedele and Ji, Yusheng},
TITLE = {A Brief Review of Multipath TCP for Vehicular Networks},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {8},
ARTICLE-NUMBER = {2793},
URL = {https://www.mdpi.com/1424-8220/21/8/2793},
PubMedID = {33921059},
ISSN = {1424-8220},
ABSTRACT = {Multipath TCP (MPTCP) is one of the most important extensions to TCP that enables the use of multiple paths in data transmissions for a TCP connection. In MPTCP, the end hosts transmit data across a number of TCP subflows simultaneously on one connection. MPTCP can sufficiently utilize the bandwidth resources to improve the transmission efficiency while providing TCP fairness to other TCP connections. Meanwhile, it also offers resilience due to multipath data transfers. MPTCP attracts tremendous attention from the academic and industry field due to the explosive data growth in recent times and limited network bandwidth for each single available communication interface. The vehicular Internet-of-Things systems, such as cooperative autonomous driving, require reliable high speed data transmission and robustness. MPTCP could be a promising approach to solve these challenges. In this paper, we first conduct a brief survey of existing MPTCP studies and give a brief overview to multipath routing. Then we discuss the significance technical challenges in applying MPTCP for vehicular networks and point out future research directions.},
DOI = {10.3390/s21082793}
}



@Article{rs13081528,
AUTHOR = {Song, Yongze and Wu, Peng},
TITLE = {Earth Observation for Sustainable Infrastructure: A Review},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {8},
ARTICLE-NUMBER = {1528},
URL = {https://www.mdpi.com/2072-4292/13/8/1528},
ISSN = {2072-4292},
ABSTRACT = {Infrastructure is a fundamental sector for sustainable development and Earth observation has great potentials for sustainable infrastructure development (SID). However, implementations of the timely, large–scale and multi–source Earth observation are still limited in satisfying the huge global requirements of SID. This study presents a systematical literature review to identify trends of Earth observation for sustainable infrastructure (EOSI), investigate the relationship between EOSI and Sustainable Development Goals (SDGs), and explore challenges and future directions of EOSI. Results reveal the close associations of infrastructure, urban development, ecosystems, climate, Earth observation and GIS in EOSI, and indicate their relationships. In addition, from the perspective of EOSI–SDGs relationship, the huge potentials of EOSI are demonstrated from the 70% of the infrastructure influenced targets that can be directly or indirectly derived from Earth observation data, but have not been included in current SDG indicators. Finally, typical EOSI cases are presented to indicate challenges and future research directions. This review emphasizes the contributions and potentials of Earth observation to SID and EOSI is a powerful pathway to deliver on SDGs.},
DOI = {10.3390/rs13081528}
}



@Article{rs13081534,
AUTHOR = {Zhang, Fan and Hu, Zhenqi and Yang, Kun and Fu, Yaokun and Feng, Zewei and Bai, Mingbo},
TITLE = {The Surface Crack Extraction Method Based on Machine Learning of Image and Quantitative Feature Information Acquisition Method},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {8},
ARTICLE-NUMBER = {1534},
URL = {https://www.mdpi.com/2072-4292/13/8/1534},
ISSN = {2072-4292},
ABSTRACT = {In order to effectively control the damage caused by surface cracks to a geological environment, we need to find a convenient, efficient, and accurate method to obtain crack information. The existing crack extraction methods based on unmanned air vehicle (UAV) images inevitably have some erroneous pixels because of the complexity of background information. At the same time, there are few researches on crack feature information. In view of this, this article proposes a surface crack extraction method based on machine learning of UAV images, the data preprocessing steps, and the content and calculation methods for crack feature information: length, width, direction, location, fractal dimension, number, crack rate, and dispersion rate. The results show that the method in this article can effectively avoid the interference by vegetation and soil crust. By introducing the concept of dispersion rate, the method combining crack rate and dispersion rate can describe the distribution characteristics of regional cracks more clearly. Compared to field survey data, the calculation result of the crack feature information in this article is close to the true value, which proves that this is a reliable method for obtaining quantitative crack feature information.},
DOI = {10.3390/rs13081534}
}



@Article{app11083586,
AUTHOR = {Xu, Gaofei and Guo, Wei and Zhao, Yang and Zhou, Yue and Zhang, Yinlong and Liu, Xinyu and Xu, Gaopeng and Li, Guangwei},
TITLE = {Online Learning Based Underwater Robotic Thruster Fault Detection},
JOURNAL = {Applied Sciences},
VOLUME = {11},
YEAR = {2021},
NUMBER = {8},
ARTICLE-NUMBER = {3586},
URL = {https://www.mdpi.com/2076-3417/11/8/3586},
ISSN = {2076-3417},
ABSTRACT = {This paper presents a novel online learning-based fault detection designed for underwater robotic thruster health monitoring. In the fault detection algorithm, we build a mathematical model between the control variable and the propeller speed by fitting collected online work status data to the model. To improve the accuracy of online modeling, a multi-center PSO algorithm with memory ability is utilized to optimize the modeling parameters. Additionally, a model online update mechanism is designed to accommodate the model to the change of thruster work status and sea environment. During the operation, propeller speed of the underwater robot is predicted through the online learning-based model, and the model residuals are used for thruster health monitoring. To avoid false alarm, an adaptive fault detection strategy is established based on model online update mechanism. The proposed method has been extensively evaluated using different underwater robotics, through a sea trial data simulation, a pool test fault detection experiment and a sea trial fault detection experiment. Compared with fixed model-based method, speed prediction MAE of the online learning model is at least 37.9% lower than that of the fixed model. The online learning-based method show no misdiagnosis in experiments, while the fixed model-based method is misdiagnosed. Experimental results show that the proposed method is competitive in terms of accuracy, adaptability, and robustness.},
DOI = {10.3390/app11083586}
}



@Article{s21082824,
AUTHOR = {Coluccia, Angelo and Fascista, Alessio and Schumann, Arne and Sommer, Lars and Dimou, Anastasios and Zarpalas, Dimitrios and Méndez, Miguel and de la Iglesia, David and González, Iago and Mercier, Jean-Philippe and Gagné, Guillaume and Mitra, Arka and Rajashekar, Shobha},
TITLE = {Drone vs. Bird Detection: Deep Learning Algorithms and Results from a Grand Challenge},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {8},
ARTICLE-NUMBER = {2824},
URL = {https://www.mdpi.com/1424-8220/21/8/2824},
PubMedID = {33923829},
ISSN = {1424-8220},
ABSTRACT = {Adopting effective techniques to automatically detect and identify small drones is a very compelling need for a number of different stakeholders in both the public and private sectors. This work presents three different original approaches that competed in a grand challenge on the “Drone vs. Bird” detection problem. The goal is to detect one or more drones appearing at some time point in video sequences where birds and other distractor objects may be also present, together with motion in background or foreground. Algorithms should raise an alarm and provide a position estimate only when a drone is present, while not issuing alarms on birds, nor being confused by the rest of the scene. In particular, three original approaches based on different deep learning strategies are proposed and compared on a real-world dataset provided by a consortium of universities and research centers, under the 2020 edition of the Drone vs. Bird Detection Challenge. Results show that there is a range in difficulty among different test sequences, depending on the size and the shape visibility of the drone in the sequence, while sequences recorded by a moving camera and very distant drones are the most challenging ones. The performance comparison reveals that the different approaches perform somewhat complementary, in terms of correct detection rate, false alarm rate, and average precision.},
DOI = {10.3390/s21082824}
}



@Article{drones5020028,
AUTHOR = {Li, Joan Y. Q. and Duce, Stephanie and Joyce, Karen E. and Xiang, Wei},
TITLE = {SeeCucumbers: Using Deep Learning and Drone Imagery to Detect Sea Cucumbers on Coral Reef Flats},
JOURNAL = {Drones},
VOLUME = {5},
YEAR = {2021},
NUMBER = {2},
ARTICLE-NUMBER = {28},
URL = {https://www.mdpi.com/2504-446X/5/2/28},
ISSN = {2504-446X},
ABSTRACT = {Sea cucumbers (Holothuroidea or holothurians) are a valuable fishery and are also crucial nutrient recyclers, bioturbation agents, and hosts for many biotic associates. Their ecological impacts could be substantial given their high abundance in some reef locations and thus monitoring their populations and spatial distribution is of research interest. Traditional in situ surveys are laborious and only cover small areas but drones offer an opportunity to scale observations more broadly, especially if the holothurians can be automatically detected in drone imagery using deep learning algorithms. We adapted the object detection algorithm YOLOv3 to detect holothurians from drone imagery at Hideaway Bay, Queensland, Australia. We successfully detected 11,462 of 12,956 individuals over 2.7ha with an average density of 0.5 individual/m2. We tested a range of hyperparameters to determine the optimal detector performance and achieved 0.855 mAP, 0.82 precision, 0.83 recall, and 0.82 F1 score. We found as few as ten labelled drone images was sufficient to train an acceptable detection model (0.799 mAP). Our results illustrate the potential of using small, affordable drones with direct implementation of open-source object detection models to survey holothurians and other shallow water sessile species.},
DOI = {10.3390/drones5020028}
}



@Article{s21082834,
AUTHOR = {Kazaz, Billur and Poddar, Subhadipto and Arabi, Saeed and Perez, Michael A. and Sharma, Anuj and Whitman, J. Blake},
TITLE = {Deep Learning-Based Object Detection for Unmanned Aerial Systems (UASs)-Based Inspections of Construction Stormwater Practices},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {8},
ARTICLE-NUMBER = {2834},
URL = {https://www.mdpi.com/1424-8220/21/8/2834},
PubMedID = {33920610},
ISSN = {1424-8220},
ABSTRACT = {Construction activities typically create large amounts of ground disturbance, which can lead to increased rates of soil erosion. Construction stormwater practices are used on active jobsites to protect downstream waterbodies from offsite sediment transport. Federal and state regulations require routine pollution prevention inspections to ensure that temporary stormwater practices are in place and performing as intended. This study addresses the existing challenges and limitations in the construction stormwater inspections and presents a unique approach for performing unmanned aerial system (UAS)-based inspections. Deep learning-based object detection principles were applied to identify and locate practices installed on active construction sites. The system integrates a post-processing stage by clustering results. The developed framework consists of data preparation with aerial inspections, model training, validation of the model, and testing for accuracy. The developed model was created from 800 aerial images and was used to detect four different types of construction stormwater practices at 100% accuracy on the Mean Average Precision (MAP) with minimal false positive detections. Results indicate that object detection could be implemented on UAS-acquired imagery as a novel approach to construction stormwater inspections and provide accurate results for site plan comparisons by rapidly detecting the quantity and location of field-installed stormwater practices.},
DOI = {10.3390/s21082834}
}



@Article{s21082839,
AUTHOR = {Poudel, Sabitri and Moh, Sangman},
TITLE = {Hybrid Path Planning for Efficient Data Collection in UAV-Aided WSNs for Emergency Applications},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {8},
ARTICLE-NUMBER = {2839},
URL = {https://www.mdpi.com/1424-8220/21/8/2839},
PubMedID = {33920627},
ISSN = {1424-8220},
ABSTRACT = {In unmanned aerial vehicle (UAV)-aided wireless sensor networks (UWSNs), a UAV is employed as a mobile sink to gather data from sensor nodes. Incorporating UAV helps prolong the network lifetime and avoid the energy-hole problem faced by sensor networks. In emergency applications, timely data collection from sensor nodes and transferal of the data to the base station (BS) is a prime requisite. The timely and safe path of UAV is one of the fundamental premises for effective UWSN operations. It is essential and challenging to identify a suitable path in an environment comprising various obstacles and to ensure that the path can efficiently reach the target point. This paper proposes a hybrid path planning (HPP) algorithm for efficient data collection by assuring the shortest collision-free path for UAV in emergency environments. In the proposed HPP scheme, the probabilistic roadmap (PRM) algorithm is used to design the shortest trajectory map and the optimized artificial bee colony (ABC) algorithm to improve different path constraints in a three-dimensional environment. Our simulation results show that the proposed HPP outperforms the PRM and conventional ABC schemes significantly in terms of flight time, energy consumption, convergence time, and flight path.},
DOI = {10.3390/s21082839}
}



@Article{rs13081562,
AUTHOR = {Ge, Xiangyu and Ding, Jianli and Jin, Xiuliang and Wang, Jingzhe and Chen, Xiangyue and Li, Xiaohang and Liu, Jie and Xie, Boqiang},
TITLE = {Estimating Agricultural Soil Moisture Content through UAV-Based Hyperspectral Images in the Arid Region},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {8},
ARTICLE-NUMBER = {1562},
URL = {https://www.mdpi.com/2072-4292/13/8/1562},
ISSN = {2072-4292},
ABSTRACT = {Unmanned aerial vehicle (UAV)-based hyperspectral remote sensing is an important monitoring technology for the soil moisture content (SMC) of agroecological systems in arid regions. This technology develops precision farming and agricultural informatization. However, hyperspectral data are generally used in data mining. In this study, UAV-based hyperspectral imaging data with a resolution o 4 cm and totaling 70 soil samples (0–10 cm) were collected from farmland (2.5 × 104 m2) near Fukang City, Xinjiang Uygur Autonomous Region, China. Four estimation strategies were tested: the original image (strategy I), first- and second-order derivative methods (strategy II), the fractional-order derivative (FOD) technique (strategy III), and the optimal fractional order combined with the optimal multiband indices (strategy IV). These strategies were based on the eXtreme Gradient Boost (XGBoost) algorithm, with the aim of building the best estimation model for agricultural SMC in arid regions. The results demonstrated that FOD technology could effectively mine information (with an absolute maximum correlation coefficient of 0.768). By comparison, strategy IV yielded the best estimates out of the methods tested (R2val = 0.921, RMSEP = 1.943, and RPD = 2.736) for the SMC. The model derived from the order of 0.4 within strategy IV worked relatively well among the different derivative methods (strategy I, II, and III). In conclusion, the combination of FOD technology and the optimal multiband indices generated a highly accurate model within the XGBoost algorithm for SMC estimation. This research provided a promising data mining approach for UAV-based hyperspectral imaging data.},
DOI = {10.3390/rs13081562}
}



@Article{jmmp5020038,
AUTHOR = {Peng, Xing and Kong, Lingbao and Fuh, Jerry Ying Hsi and Wang, Hao},
TITLE = {A Review of Post-Processing Technologies in Additive Manufacturing},
JOURNAL = {Journal of Manufacturing and Materials Processing},
VOLUME = {5},
YEAR = {2021},
NUMBER = {2},
ARTICLE-NUMBER = {38},
URL = {https://www.mdpi.com/2504-4494/5/2/38},
ISSN = {2504-4494},
ABSTRACT = {Additive manufacturing (AM) technology has rapidly evolved with research advances related to AM processes, materials, and designs. The advantages of AM over conventional techniques include an augmented capability to produce parts with complex geometries, operational flexibility, and reduced production time. However, AM processes also face critical issues, such as poor surface quality and inadequate mechanical properties. Therefore, several post-processing technologies are applied to improve the surface quality of the additively manufactured parts. This work aims to document post-processing technologies and their applications concerning different AM processes. Various types of post-process treatments are reviewed and their integrations with AM process are discussed.},
DOI = {10.3390/jmmp5020038}
}



@Article{app11083648,
AUTHOR = {Jimenez, Jose M. and Parra, Lorena and García, Laura and Lloret, Jaime and Mauri, Pedro V. and Lorenz, Pascal},
TITLE = {New Protocol and Architecture for a Wastewater Treatment System Intended for Irrigation},
JOURNAL = {Applied Sciences},
VOLUME = {11},
YEAR = {2021},
NUMBER = {8},
ARTICLE-NUMBER = {3648},
URL = {https://www.mdpi.com/2076-3417/11/8/3648},
ISSN = {2076-3417},
ABSTRACT = {Water quality may be affected by aspects such as pollution from industries, agricultural fertilizers and pesticides, and waste produced by humans. This contamination can affect the produce of the fields irrigated by untreated water. Therefore, it is necessary to add a treatment process in irrigation systems. In this paper, an architecture, communication protocol, and a data analysis algorithm for a wastewater treatment system intended for irrigation are presented. Our system includes a smart group-based wireless sensor network that is able to detect high salinity levels and pollution stains, such as oil spills. When contamination is detected, the water is led into auxiliary canals that perform the biosorption process to treat the water and dump it back into the main canal. Simulations were performed to assess the amount of data stored on the secure digital (SD) card, the consumed bandwidth, and the energy consumption of our proposal. The results show the system has a low bandwidth consumption with a maximum of 2.58 kbps for the setting of two daily data transmissions of the node in the last auxiliary canal. Furthermore, it can sustain the energy consumption in adverse conditions, where the node with the highest energy consumption reaches the lowest energy value of 12,320 mW/h.},
DOI = {10.3390/app11083648}
}



@Article{rs13081574,
AUTHOR = {Wang, Yuping and Shen, Zehao},
TITLE = {Comparing Luojia 1-01 and VIIRS Nighttime Light Data in Detecting Urban Spatial Structure Using a Threshold-Based Kernel Density Estimation},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {8},
ARTICLE-NUMBER = {1574},
URL = {https://www.mdpi.com/2072-4292/13/8/1574},
ISSN = {2072-4292},
ABSTRACT = {Nighttime light (NTL) data are increasingly used in urban studies and urban planning owing to their strong connection with human activities, although the detection capacity is limited by the spatial resolution of older data. In the present study, we comparedthe results of extractions of urban built-up areas using data obtained from the first professional NTL satellite Luojia 1-01 with a resolution of 130 m and the Visible Infrared Imaging Radiometer Suite (VIIRS). We applied an analyzing framework combing kernel density estimation (KDE) under different search radii and threshold-based extraction to detect the boundary and spatial structure of urban areas. The results showed that: (1) Benefiting from a higher spatial resolution, Luojia 1-01 data was more sensitive in detecting new emerging urban built-up areas, thus better reflected the spatial structure of urban system, and can achieve a higher extraction accuracy than that of VIIRS data; (2) Combining with a proper threshold, KDE improves the extraction accuracy of NTL data by making use of the spatial autocorrelation of nighttime light, thus better detects the scale of the spatial pattern of urban built-up areas; (3) A proper searching radius for KDE is critical for achieving the optimal result, which was 1000 m for Luojia 1-01 and 1600 m for VIIRS in this study. Our findings indicate the usefulness of the KDE method in applying the upcoming high-resolution NTL data such as Luojia 1-01 data in urban spatial analysis and planning.},
DOI = {10.3390/rs13081574}
}



@Article{su13084511,
AUTHOR = {Haque, Amlan and Islam, Nahina and Samrat, Nahidul Hoque and Dey, Shuvashis and Ray, Biplob},
TITLE = {Smart Farming through Responsible Leadership in Bangladesh: Possibilities, Opportunities, and Beyond},
JOURNAL = {Sustainability},
VOLUME = {13},
YEAR = {2021},
NUMBER = {8},
ARTICLE-NUMBER = {4511},
URL = {https://www.mdpi.com/2071-1050/13/8/4511},
ISSN = {2071-1050},
ABSTRACT = {Smart farming has the potential to overcome the challenge of 2050 to feed 10 billion people. Both artificial intelligence (AI) and the internet of things (IoT) have become critical prerequisites to smart farming due to their high interoperability, sensors, and cutting-edge technologies. Extending the role of responsible leadership, this paper proposes an AI and IoT based smart farming system in Bangladesh. With a comprehensive literature review, this paper counsels the need to go beyond the simple application of traditional farming and irrigation practices and recommends implementing smart farming enabling responsible leadership to uphold sustainable agriculture. It contributes to the current literature of smart farming in several ways. First, this paper helps to understand the prospect and challenges of both AI and IoT and the requirement of smart farming in a nonwestern context. Second, it clarifies the interventions of responsible leadership into Bangladesh’s agriculture sector and justifies the demand for sustainable smart farming. Third, this paper is a step forward to explore future empirical studies for the effective and efficient use of AI and IoT to adopt smart farming. Finally, this paper will help policymakers to take responsible initiatives to plan and apply smart farming in a developing economy like Bangladesh.},
DOI = {10.3390/su13084511}
}



@Article{s21082861,
AUTHOR = {Bukowiecki, Josephine and Rose, Till and Kage, Henning},
TITLE = {Sentinel-2 Data for Precision Agriculture?—A UAV-Based Assessment},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {8},
ARTICLE-NUMBER = {2861},
URL = {https://www.mdpi.com/1424-8220/21/8/2861},
PubMedID = {33921631},
ISSN = {1424-8220},
ABSTRACT = {An approach of exploiting and assessing the potential of Sentinel-2 data in the context of precision agriculture by using data from an unmanned aerial vehicle (UAV) is presented based on a four-year dataset. An established model for the estimation of the green area index (GAI) of winter wheat from a UAV-based multispectral camera was used to calibrate the Sentinel-2 data. Large independent datasets were used for evaluation purposes. Furthermore, the potential of the satellite-based GAI-predictions for crop monitoring and yield prediction was tested. Therefore, the total absorbed photosynthetic radiation between spring and harvest was calculated with satellite and UAV data and correlated with the final grain yield. Yield maps at the same resolution were generated by combining yield data on a plot level with a UAV-based crop coverage map. The best tested model for satellite-based GAI-prediction was obtained by combining the near-, infrared- and Red Edge-waveband in a simple ratio (R2 = 0.82, mean absolute error = 0.52 m2/m2). Yet, the Sentinel-2 data seem to depict average GAI-developments through the seasons, rather than to map site-specific variations at single acquisition dates. The results show that the lower information content of the satellite-based crop monitoring might be mainly traced back to its coarser Red Edge-band. Additionally, date-specific effects within the Sentinel-2 data were detected. Due to cloud coverage, the temporal resolution was found to be unsatisfactory as well. These results emphasize the need for further research on the applicability of the Sentinel-2 data and a cautious use in the context of precision agriculture.},
DOI = {10.3390/s21082861}
}



@Article{mca26020034,
AUTHOR = {Gibert Martínez, Isaac and Afonso, Frederico and Rodrigues, Simão and Lau, Fernando},
TITLE = {A Sequential Approach for Aerodynamic Shape Optimization with Topology Optimization of Airfoils},
JOURNAL = {Mathematical and Computational Applications},
VOLUME = {26},
YEAR = {2021},
NUMBER = {2},
ARTICLE-NUMBER = {34},
URL = {https://www.mdpi.com/2297-8747/26/2/34},
ISSN = {2297-8747},
ABSTRACT = {The objective of this work is to study the coupling of two efficient optimization techniques, Aerodynamic Shape Optimization (ASO) and Topology Optimization (TO), in 2D airfoils. To achieve such goal two open-source codes, SU2 and Calculix, are employed for ASO and TO, respectively, using the Sequential Least SQuares Programming (SLSQP) and the Bi-directional Evolutionary Structural Optimization (BESO) algorithms; the latter is well-known for allowing the addition of material in the TO which constitutes, as far as our knowledge, a novelty for this kind of application. These codes are linked by means of a script capable of reading the geometry and pressure distribution obtained from the ASO and defining the boundary conditions to be applied in the TO. The Free-Form Deformation technique is chosen for the definition of the design variables to be used in the ASO, while the densities of the inner elements are defined as design variables of the TO. As a test case, a widely used benchmark transonic airfoil, the RAE2822, is chosen here with an internal geometric constraint to simulate the wing-box of a transonic wing. First, the two optimization procedures are tested separately to gain insight and then are run in a sequential way for two test cases with available experimental data: (i) Mach 0.729 at α=2.31°; and (ii) Mach 0.730 at α=2.79°. In the ASO problem, the lift is fixed and the drag is minimized; while in the TO problem, compliance minimization is set as the objective for a prescribed volume fraction. Improvements in both aerodynamic and structural performance are found, as expected: the ASO reduced the total pressure on the airfoil surface in order to minimize drag, which resulted in lower stress values experienced by the structure.},
DOI = {10.3390/mca26020034}
}



@Article{app11083705,
AUTHOR = {Zeng, Jie and Roussis, Panayiotis C. and Mohammed, Ahmed Salih and Maraveas, Chrysanthos and Fatemi, Seyed Alireza and Armaghani, Danial Jahed and Asteris, Panagiotis G.},
TITLE = {Prediction of Peak Particle Velocity Caused by Blasting through the Combinations of Boosted-CHAID and SVM Models with Various Kernels},
JOURNAL = {Applied Sciences},
VOLUME = {11},
YEAR = {2021},
NUMBER = {8},
ARTICLE-NUMBER = {3705},
URL = {https://www.mdpi.com/2076-3417/11/8/3705},
ISSN = {2076-3417},
ABSTRACT = {This research examines the feasibility of hybridizing boosted Chi-Squared Automatic Interaction Detection (CHAID) with different kernels of support vector machine (SVM) techniques for the prediction of the peak particle velocity (PPV) induced by quarry blasting. To achieve this objective, a boosting-CHAID technique was applied to a big experimental database comprising six input variables. The technique identified four input parameters (distance from blast-face, stemming length, powder factor, and maximum charge per delay) as the most significant parameters affecting the prediction accuracy and utilized them to propose the SVM models with various kernels. The kernel types used in this study include radial basis function, polynomial, sigmoid, and linear. Several criteria, including mean absolute error (MAE), correlation coefficient (R), and gains, were calculated to evaluate the developed models’ accuracy and applicability. In addition, a simple ranking system was used to evaluate the models’ performance systematically. The performance of the R and MAE index of the radial basis function kernel of SVM in training and testing phases, respectively, confirm the high capability of this SVM kernel in predicting PPV values. This study successfully demonstrates that a combination of boosting-CHAID and SVM models can identify and predict with a high level of accuracy the most effective parameters affecting PPV values.},
DOI = {10.3390/app11083705}
}



@Article{rs13081599,
AUTHOR = {Seitsonen, Oula and Ikäheimo, Janne},
TITLE = {Detecting Archaeological Features with Airborne Laser Scanning in the Alpine Tundra of Sápmi, Northern Finland},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {8},
ARTICLE-NUMBER = {1599},
URL = {https://www.mdpi.com/2072-4292/13/8/1599},
ISSN = {2072-4292},
ABSTRACT = {Open access airborne laser scanning (ALS) data have been available in Finland for over a decade and have been actively applied by the Finnish archaeologists in that time. The low resolution of this laser scanning 2008–2019 dataset (0.5 points/m2), however, has hindered its usability for archaeological prospection. In the summer of 2020, the situation changed markedly, when the Finnish National Land Survey started a new countrywide ALS survey with a higher resolution of 5 points/m2. In this paper we present the first results of applying this newly available ALS material for archaeological studies. Finnish LIDARK consortium has initiated the development of semi-automated approaches for visualizing, detecting, and analyzing archaeological features with this new dataset. Our first case studies are situated in the Alpine tundra environment of Sápmi in northern Finland, and the assessed archaeological features range from prehistoric sites to indigenous Sámi reindeer herding features and Second Word War-era German military structures. Already the initial analyses of the new ALS-5p data show their huge potential for locating, mapping, and assessing archaeological material. These results also suggest an imminent burst in the number of known archaeological sites, especially in the poorly accessible and little studied northern wilderness areas, when more data become available.},
DOI = {10.3390/rs13081599}
}



@Article{app11093737,
AUTHOR = {Hrúz, Michal and Bugaj, Martin and Novák, Andrej and Kandera, Branislav and Badánik, Benedikt},
TITLE = {The Use of UAV with Infrared Camera and RFID for Airframe Condition Monitoring},
JOURNAL = {Applied Sciences},
VOLUME = {11},
YEAR = {2021},
NUMBER = {9},
ARTICLE-NUMBER = {3737},
URL = {https://www.mdpi.com/2076-3417/11/9/3737},
ISSN = {2076-3417},
ABSTRACT = {The new progressive smart technologies announced in the fourth industrial revolution in aviation—Aviation 4.0—represent new possibilities and big challenges in aircraft maintenance processes. The main benefit of these technologies is the possibility to monitor, transfer, store, and analyze huge datasets. Based on analysis outputs, there is a possibility to improve current preventive maintenance processes and implement predictive maintenance processes. These solutions lower the downtime, save manpower, and extend the components’ lifetime; thus, the maximum effectivity and safety is achieved. The article deals with the possible implementation of an unmanned aerial vehicle (UAV) with an infrared camera and Radio Frequency Identification (RFID) as two of the smart hangar technologies for airframe condition monitoring. The presented implementations of smart technologies follow up the specific results of a case study focused on trainer aircraft failure monitoring and its impact on maintenance strategy changes. The case study failure indexes show the critical parts of aircraft that are subjected to damage the most. The aim of the article was to justify the need for thorough monitoring of critical parts of the aircraft and then analyze and propose a more effective and the most suitable form of technical condition monitoring of aircraft critical parts. The article describes the whole process of visual inspection performed by an unmanned aerial vehicle (UAV) with an IR camera and its related processes; in addition, it covers the possible usage of RFID tags as a labeling tool supporting the visual inspection. The implementations criteria apply to the repair and overhaul small aircraft maintenance organization, and later, it can also increase operational efficiency. The final suggestions describe the possible usage of proposed solutions, their main benefits, and also the limitations of their implementations in maintenance of trainer aircraft.},
DOI = {10.3390/app11093737}
}



@Article{rs13091619,
AUTHOR = {Yan, Bin and Fan, Pan and Lei, Xiaoyan and Liu, Zhijie and Yang, Fuzeng},
TITLE = {A Real-Time Apple Targets Detection Method for Picking Robot Based on Improved YOLOv5},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {9},
ARTICLE-NUMBER = {1619},
URL = {https://www.mdpi.com/2072-4292/13/9/1619},
ISSN = {2072-4292},
ABSTRACT = {The apple target recognition algorithm is one of the core technologies of the apple picking robot. However, most of the existing apple detection algorithms cannot distinguish between the apples that are occluded by tree branches and occluded by other apples. The apples, grasping end-effector and mechanical picking arm of the robot are very likely to be damaged if the algorithm is directly applied to the picking robot. Based on this practical problem, in order to automatically recognize the graspable and ungraspable apples in an apple tree image, a light-weight apple targets detection method was proposed for picking robot using improved YOLOv5s. Firstly, BottleneckCSP module was improved designed to BottleneckCSP-2 module which was used to replace the BottleneckCSP module in backbone architecture of original YOLOv5s network. Secondly, SE module, which belonged to the visual attention mechanism network, was inserted to the proposed improved backbone network. Thirdly, the bonding fusion mode of feature maps, which were inputs to the target detection layer of medium size in the original YOLOv5s network, were improved. Finally, the initial anchor box size of the original network was improved. The experimental results indicated that the graspable apples, which were unoccluded or only occluded by tree leaves, and the ungraspable apples, which were occluded by tree branches or occluded by other fruits, could be identified effectively using the proposed improved network model in this study. Specifically, the recognition recall, precision, mAP and F1 were 91.48%, 83.83%, 86.75% and 87.49%, respectively. The average recognition time was 0.015 s per image. Contrasted with original YOLOv5s, YOLOv3, YOLOv4 and EfficientDet-D0 model, the mAP of the proposed improved YOLOv5s model increased by 5.05%, 14.95%, 4.74% and 6.75% respectively, the size of the model compressed by 9.29%, 94.6%, 94.8% and 15.3% respectively. The average recognition speeds per image of the proposed improved YOLOv5s model were 2.53, 1.13 and 3.53 times of EfficientDet-D0, YOLOv4 and YOLOv3 and model, respectively. The proposed method can provide technical support for the real-time accurate detection of multiple fruit targets for the apple picking robot.},
DOI = {10.3390/rs13091619}
}



@Article{rs13091629,
AUTHOR = {Kwak, Geun-Ho and Park, Chan-won and Lee, Kyung-do and Na, Sang-il and Ahn, Ho-yong and Park, No-Wook},
TITLE = {Potential of Hybrid CNN-RF Model for Early Crop Mapping with Limited Input Data},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {9},
ARTICLE-NUMBER = {1629},
URL = {https://www.mdpi.com/2072-4292/13/9/1629},
ISSN = {2072-4292},
ABSTRACT = {When sufficient time-series images and training data are unavailable for crop classification, features extracted from convolutional neural network (CNN)-based representative learning may not provide useful information to discriminate crops with similar spectral characteristics, leading to poor classification accuracy. In particular, limited input data are the main obstacles to obtain reliable classification results for early crop mapping. This study investigates the potential of a hybrid classification approach, i.e., CNN-random forest (CNN-RF), in the context of early crop mapping, that combines the automatic feature extraction capability of CNN with the superior discrimination capability of an RF classifier. Two experiments on incremental crop classification with unmanned aerial vehicle images were conducted to compare the performance of CNN-RF with that of CNN and RF with respect to the length of the time-series and training data sizes. When sufficient time-series images and training data were used for the classification, the accuracy of CNN-RF was slightly higher or comparable with that of CNN. In contrast, when fewer images and the smallest training data were used at the early crop growth stage, CNN-RF was substantially beneficial and the overall accuracy increased by maximum 6.7%p and 4.6%p in the two study areas, respectively, compared to CNN. This is attributed to its ability to discriminate crops from features with insufficient information using a more sophisticated classifier. The experimental results demonstrate that CNN-RF is an effective classifier for early crop mapping when only limited input images and training samples are available.},
DOI = {10.3390/rs13091629}
}



@Article{rs13091620,
AUTHOR = {Ge, Haixiao and Xiang, Haitao and Ma, Fei and Li, Zhenwang and Qiu, Zhengchao and Tan, Zhengzheng and Du, Changwen},
TITLE = {Estimating Plant Nitrogen Concentration of Rice through Fusing Vegetation Indices and Color Moments Derived from UAV-RGB Images},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {9},
ARTICLE-NUMBER = {1620},
URL = {https://www.mdpi.com/2072-4292/13/9/1620},
ISSN = {2072-4292},
ABSTRACT = {Estimating plant nitrogen concentration (PNC) has been conducted using vegetation indices (VIs) from UAV-based imagery, but color features have been rarely considered as additional variables. In this study, the VIs and color moments (color feature) were calculated from UAV-based RGB images, then partial least square regression (PLSR) and random forest regression (RF) models were established to estimate PNC through fusing VIs and color moments. The results demonstrated that the fusion of VIs and color moments as inputs yielded higher accuracies of PNC estimation compared to VIs or color moments as input; the RF models based on the combination of VIs and color moments (R2 ranging from 0.69 to 0.91 and NRMSE ranging from 0.07 to 0.13) showed similar performances to the PLSR models (R2 ranging from 0.68 to 0.87 and NRMSE ranging from 0.10 to 0.29); Among the top five important variables in the RF models, there was at least one variable which belonged to the color moments in different datasets, indicating the significant contribution of color moments in improving PNC estimation accuracy. This revealed the great potential of combination of RGB-VIs and color moments for the estimation of rice PNC.},
DOI = {10.3390/rs13091620}
}



@Article{jsan10020028,
AUTHOR = {Pourroostaei Ardakani, Saeid},
TITLE = {MINDS: Mobile Agent Itinerary Planning Using Named Data Networking in Wireless Sensor Networks},
JOURNAL = {Journal of Sensor and Actuator Networks},
VOLUME = {10},
YEAR = {2021},
NUMBER = {2},
ARTICLE-NUMBER = {28},
URL = {https://www.mdpi.com/2224-2708/10/2/28},
ISSN = {2224-2708},
ABSTRACT = {Mobile agents have the potential to offer benefits, as they are able to either independently or cooperatively move throughout networks and collect/aggregate sensory data samples. They are programmed to autonomously move and visit sensory data stations through optimal paths, which are established according to the application requirements. However, mobile agent routing protocols still suffer heavy computation/communication overheads, lack of route planning accuracy and long-delay mobile agent migrations. For this, mobile agent route planning protocols aim to find the best-fitted paths for completing missions (e.g., data collection) with minimised delay, maximised performance and minimised transmitted traffic. This article proposes a mobile agent route planning protocol for sensory data collection called MINDS. The key goal of this MINDS is to reduce network traffic, maximise data robustness and minimise delay at the same time. This protocol utilises the Hamming distance technique to partition a sensor network into a number of data-centric clusters. In turn, a named data networking approach is used to form the cluster-heads as a data-centric, tree-based communication infrastructure. The mobile agents utilise a modified version of the Depth-First Search algorithm to move through the tree infrastructure according to a hop-count-aware fashion. As the simulation results show, MINDS reduces path length, reduces network traffic and increases data robustness as compared with two conventional benchmarks (ZMA and TBID) in dense and large wireless sensor networks.},
DOI = {10.3390/jsan10020028}
}



@Article{electronics10090999,
AUTHOR = {Azar, Ahmad Taher and Koubaa, Anis and Ali Mohamed, Nada and Ibrahim, Habiba A. and Ibrahim, Zahra Fathy and Kazim, Muhammad and Ammar, Adel and Benjdira, Bilel and Khamis, Alaa M. and Hameed, Ibrahim A. and Casalino, Gabriella},
TITLE = {Drone Deep Reinforcement Learning: A Review},
JOURNAL = {Electronics},
VOLUME = {10},
YEAR = {2021},
NUMBER = {9},
ARTICLE-NUMBER = {999},
URL = {https://www.mdpi.com/2079-9292/10/9/999},
ISSN = {2079-9292},
ABSTRACT = {Unmanned Aerial Vehicles (UAVs) are increasingly being used in many challenging and diversified applications. These applications belong to the civilian and the military fields. To name a few; infrastructure inspection, traffic patrolling, remote sensing, mapping, surveillance, rescuing humans and animals, environment monitoring, and Intelligence, Surveillance, Target Acquisition, and Reconnaissance (ISTAR) operations. However, the use of UAVs in these applications needs a substantial level of autonomy. In other words, UAVs should have the ability to accomplish planned missions in unexpected situations without requiring human intervention. To ensure this level of autonomy, many artificial intelligence algorithms were designed. These algorithms targeted the guidance, navigation, and control (GNC) of UAVs. In this paper, we described the state of the art of one subset of these algorithms: the deep reinforcement learning (DRL) techniques. We made a detailed description of them, and we deduced the current limitations in this area. We noted that most of these DRL methods were designed to ensure stable and smooth UAV navigation by training computer-simulated environments. We realized that further research efforts are needed to address the challenges that restrain their deployment in real-life scenarios.},
DOI = {10.3390/electronics10090999}
}



@Article{inventions6020029,
AUTHOR = {Kashyap, Bhuwan and Kumar, Ratnesh},
TITLE = {Sensing Methodologies in Agriculture for Monitoring Biotic Stress in Plants Due to Pathogens and Pests},
JOURNAL = {Inventions},
VOLUME = {6},
YEAR = {2021},
NUMBER = {2},
ARTICLE-NUMBER = {29},
URL = {https://www.mdpi.com/2411-5134/6/2/29},
ISSN = {2411-5134},
ABSTRACT = {Reducing agricultural losses is an effective way to sustainably increase agricultural output efficiency to meet our present and future needs for food, fiber, fodder, and fuel. Our ever-improving understanding of the ways in which plants respond to stress, biotic and abiotic, has led to the development of innovative sensing technologies for detecting crop stresses/stressors and deploying efficient measures. This article aims to present the current state of the methodologies applied in the field of agriculture towards the detection of biotic stress in crops. Key sensing methodologies for plant pathogen (or phytopathogen), as well as herbivorous insects/pests are presented, where the working principles are described, and key recent works discussed. The detection methods overviewed for phytopathogen-related stress identification include nucleic acid-based methods, immunological methods, imaging-based techniques, spectroscopic methods, phytohormone biosensing methods, monitoring methods for plant volatiles, and active remote sensing technologies. Whereas the pest-related sensing techniques include machine-vision-based methods, pest acoustic-emission sensors, and volatile organic compound-based stress monitoring methods. Additionally, Comparisons have been made between different sensing techniques as well as recently reported works, where the strengths and limitations are identified. Finally, the prospective future directions for monitoring biotic stress in crops are discussed.},
DOI = {10.3390/inventions6020029}
}



@Article{rs13091661,
AUTHOR = {Gargees, Rasha S. and Scott, Grant J.},
TITLE = {Large-Scale, Multiple Level-of-Detail Change Detection from Remote Sensing Imagery Using Deep Visual Feature Clustering},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {9},
ARTICLE-NUMBER = {1661},
URL = {https://www.mdpi.com/2072-4292/13/9/1661},
ISSN = {2072-4292},
ABSTRACT = {In the era of big data, where massive amounts of remotely sensed imagery can be obtained from various satellites accompanied by the rapid change in the surface of the Earth, new techniques for large-scale change detection are necessary to facilitate timely and effective human understanding of natural and human-made phenomena. In this research, we propose a chip-based change detection method that is enabled by using deep neural networks to extract visual features. These features are transformed into deep orthogonal visual features that are then clustered based on land cover characteristics. The resulting chip cluster memberships allow arbitrary level-of-detail change analysis that can also support irregular geospatial extent based agglomerations. The proposed methods naturally support cross-resolution temporal scenes without requiring normalization of the pixel resolution across scenes and without requiring pixel-level coregistration processes. This is achieved with configurable spatial locality comparisons between years, where the aperture of a unit of measure can be a single chip, a small neighborhood of chips, or a large irregular geospatial region. The performance of our proposed method has been validated using various quantitative and statistical metrics in addition to presenting the visual geo-maps and the percentage of the change. The results show that our proposed method efficiently detected the change from a large scale area.},
DOI = {10.3390/rs13091661}
}




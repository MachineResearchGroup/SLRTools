
@Article{rs9030277,
AUTHOR = {Weinmann, Martin and Weinmann, Michael and Mallet, Clément and Brédif, Mathieu},
TITLE = {A Classification-Segmentation Framework for the Detection of Individual Trees in Dense MMS Point Cloud Data Acquired in Urban Areas},
JOURNAL = {Remote Sensing},
VOLUME = {9},
YEAR = {2017},
NUMBER = {3},
ARTICLE-NUMBER = {277},
URL = {https://www.mdpi.com/2072-4292/9/3/277},
ISSN = {2072-4292},
ABSTRACT = {In this paper, we present a novel framework for detecting individual trees in densely sampled 3D point cloud data acquired in urban areas. Given a 3D point cloud, the objective is to assign point-wise labels that are both class-aware and instance-aware, a task that is known as instance-level segmentation. To achieve this, our framework addresses two successive steps. The first step of our framework is given by the use of geometric features for a binary point-wise semantic classification with the objective of assigning semantic class labels to irregularly distributed 3D points, whereby the labels are defined as “tree points” and “other points”. The second step of our framework is given by a semantic segmentation with the objective of separating individual trees within the “tree points”. This is achieved by applying an efficient adaptation of the mean shift algorithm and a subsequent segment-based shape analysis relying on semantic rules to only retain plausible tree segments. We demonstrate the performance of our framework on a publicly available benchmark dataset, which has been acquired with a mobile mapping system in the city of Delft in the Netherlands. This dataset contains     10.13     M labeled 3D points among which     17.6    % are labeled as “tree points”. The derived results clearly reveal a semantic classification of high accuracy (up to     90.77    %) and an instance-level segmentation of high plausibility, while the simplicity, applicability and efficiency of the involved methods even allow applying the complete framework on a standard laptop computer with a reasonable processing time (less than     2.5     h).},
DOI = {10.3390/rs9030277}
}



@Article{rs9030280,
AUTHOR = {Xu, Fang and Liu, Jinghong and Sun, Mingchao and Zeng, Dongdong and Wang, Xuan},
TITLE = {A Hierarchical Maritime Target Detection Method for Optical Remote Sensing Imagery},
JOURNAL = {Remote Sensing},
VOLUME = {9},
YEAR = {2017},
NUMBER = {3},
ARTICLE-NUMBER = {280},
URL = {https://www.mdpi.com/2072-4292/9/3/280},
ISSN = {2072-4292},
ABSTRACT = {Maritime target detection from optical remote sensing images plays an important role in related military and civil applications and its weakness lies in its compromised performance under complex uncertain conditions. In this paper, a novel hierarchical ship detection method is proposed to overcome this issue. In the ship detection stage, based on Entropy information, we construct a combined saliency model with self-adaptive weights to prescreen ship candidates from across the entire maritime domain. To characterize ship targets and further reduce the false alarms, we introduce a novel and practical descriptor based on gradient features, and this descriptor is robust against clutter introduced by heavy clouds, islands, ship wakes as well as variation in target size. Furthermore, the proposed method is effective for not only color images but also gray images. The experimental results obtained using real optical remote sensing images have demonstrated that the locations and the number of ships can be determined accurately and that the false alarm rate is greatly decreased. A comprehensive comparison is performed between the proposed method and the state-of-the-art methods, which shows that the proposed method achieves higher accuracy and outperforms all the competing methods. Furthermore, the proposed method is robust under various backgrounds of maritime images and has great potential for providing more accurate target detection in engineering applications.},
DOI = {10.3390/rs9030280}
}



@Article{rs9030289,
AUTHOR = {Du, Mengmeng and Noguchi, Noboru},
TITLE = {Monitoring of Wheat Growth Status and Mapping of Wheat Yield’s within-Field Spatial Variations Using Color Images Acquired from UAV-camera System},
JOURNAL = {Remote Sensing},
VOLUME = {9},
YEAR = {2017},
NUMBER = {3},
ARTICLE-NUMBER = {289},
URL = {https://www.mdpi.com/2072-4292/9/3/289},
ISSN = {2072-4292},
ABSTRACT = {Applications of remote sensing using unmanned aerial vehicle (UAV) in agriculture has proved to be an effective and efficient way of obtaining field information. In this study, we validated the feasibility of utilizing multi-temporal color images acquired from a low altitude UAV-camera system to monitor real-time wheat growth status and to map within-field spatial variations of wheat yield for smallholder wheat growers, which could serve as references for site-specific operations. Firstly, eight orthomosaic images covering a small winter wheat field were generated to monitor wheat growth status from heading stage to ripening stage in Hokkaido, Japan. Multi-temporal orthomosaic images indicated straightforward sense of canopy color changes and spatial variations of tiller densities. Besides, the last two orthomosaic images taken from about two weeks prior to harvesting also notified the occurrence of lodging by visual inspection, which could be used to generate navigation maps guiding drivers or autonomous harvesting vehicles to adjust operation speed according to specific lodging situations for less harvesting loss. Subsequently orthomosaic images were geo-referenced so that further study on stepwise regression analysis among nine wheat yield samples and five color vegetation indices (CVI) could be conducted, which showed that wheat yield correlated with four accumulative CVIs of visible-band difference vegetation index (VDVI), normalized green-blue difference index (NGBDI), green-red ratio index (GRRI), and excess green vegetation index (ExG), with the coefficient of determination and RMSE as 0.94 and 0.02, respectively. The average value of sampled wheat yield was 8.6 t/ha. The regression model was also validated by using leave-one-out cross validation (LOOCV) method, of which root-mean-square error of predication (RMSEP) was 0.06. Finally, based on the stepwise regression model, a map of estimated wheat yield was generated, so that within-field spatial variations of wheat yield, which was usually seen as general information on soil fertility, water potential, tiller density, etc., could be better understood for applications of site-specific or variable-rate operations. Average yield of the studied field was also calculated according to the map of wheat yield as 7.2 t/ha.},
DOI = {10.3390/rs9030289}
}



@Article{rs9040309,
AUTHOR = {Yuan, Huanhuan and Yang, Guijun and Li, Changchun and Wang, Yanjie and Liu, Jiangang and Yu, Haiyang and Feng, Haikuan and Xu, Bo and Zhao, Xiaoqing and Yang, Xiaodong},
TITLE = {Retrieving Soybean Leaf Area Index from Unmanned Aerial Vehicle Hyperspectral Remote Sensing: Analysis of RF, ANN, and SVM Regression Models},
JOURNAL = {Remote Sensing},
VOLUME = {9},
YEAR = {2017},
NUMBER = {4},
ARTICLE-NUMBER = {309},
URL = {https://www.mdpi.com/2072-4292/9/4/309},
ISSN = {2072-4292},
ABSTRACT = {Leaf area index (LAI) is an important indicator of plant growth and yield that can be monitored by remote sensing. Several models were constructed using datasets derived from SRS and STR sampling methods to determine the optimal model for soybean (multiple strains) LAI inversion for the whole crop growth period and a single growth period. Random forest (RF), artificial neural network (ANN), and support vector machine (SVM) regression models were compared with a partial least-squares regression (PLS) model. The RF model yielded the highest precision, accuracy, and stability with V-R2, SDR2, V-RMSE, and SDRMSE values of 0.741, 0.031, 0.106, and 0.005, respectively, over the whole growth period based on STR sampling. The ANN model had the highest precision, accuracy, and stability (0.452, 0.132, 0.086, and 0.009, respectively) over a single growth phase based on STR sampling. The precision, accuracy, and stability of the RF, ANN, and SVM models were improved by inclusion of STR sampling. The RF model is suitable for estimating LAI when sample plots and variation are relatively large (i.e., the whole growth period or more than one growth period). The ANN model is more appropriate for estimating LAI when sample plots and variation are relatively low (i.e., a single growth period).},
DOI = {10.3390/rs9040309}
}



@Article{rs9040312,
AUTHOR = {Ammour, Nassim and Alhichri, Haikel and Bazi, Yakoub and Benjdira, Bilel and Alajlan, Naif and Zuair, Mansour},
TITLE = {Deep Learning Approach for Car Detection in UAV Imagery},
JOURNAL = {Remote Sensing},
VOLUME = {9},
YEAR = {2017},
NUMBER = {4},
ARTICLE-NUMBER = {312},
URL = {https://www.mdpi.com/2072-4292/9/4/312},
ISSN = {2072-4292},
ABSTRACT = {This paper presents an automatic solution to the problem of detecting and counting cars in unmanned aerial vehicle (UAV) images. This is a challenging task given the very high spatial resolution of UAV images (on the order of a few centimetres) and the extremely high level of detail, which require suitable automatic analysis methods. Our proposed method begins by segmenting the input image into small homogeneous regions, which can be used as candidate locations for car detection. Next, a window is extracted around each region, and deep learning is used to mine highly descriptive features from these windows. We use a deep convolutional neural network (CNN) system that is already pre-trained on huge auxiliary data as a feature extraction tool, combined with a linear support vector machine (SVM) classifier to classify regions into “car” and “no-car” classes. The final step is devoted to a fine-tuning procedure which performs morphological dilation to smooth the detected regions and fill any holes. In addition, small isolated regions are analysed further using a few sliding rectangular windows to locate cars more accurately and remove false positives. To evaluate our method, experiments were conducted on a challenging set of real UAV images acquired over an urban area. The experimental results have proven that the proposed method outperforms the state-of-the-art methods, both in terms of accuracy and computational time.},
DOI = {10.3390/rs9040312}
}



@Article{rs9040372,
AUTHOR = {Meng, Baoping and Ge, Jing and Liang, Tiangang and Yang, Shuxia and Gao, Jinglong and Feng, Qisheng and Cui, Xia and Huang, Xiaodong and Xie, Hongjie},
TITLE = {Evaluation of Remote Sensing Inversion Error for the Above-Ground Biomass of Alpine Meadow Grassland Based on Multi-Source Satellite Data},
JOURNAL = {Remote Sensing},
VOLUME = {9},
YEAR = {2017},
NUMBER = {4},
ARTICLE-NUMBER = {372},
URL = {https://www.mdpi.com/2072-4292/9/4/372},
ISSN = {2072-4292},
ABSTRACT = {It is not yet clear whether there is any difference in using remote sensing data of different spatial resolutions and filtering methods to improve the above-ground biomass (AGB) estimation accuracy of alpine meadow grassland. In this study, field measurements of AGB and spectral data at Sangke Town, Gansu Province, China, in three years (2013–2015) are combined to construct AGB estimation models of alpine meadow grassland based on these different remotely-sensed NDVI data: MODIS, HJ-1B CCD of China and Landsat 8 OLI (denoted as NDVIMOD, NDVICCD and NDVIOLI, respectively). This study aims to investigate the estimation errors of AGB from the three satellite sensors, to examine the influence of different filtering methods on MODIS NDVI for the estimation accuracy of AGB and to evaluate the feasibility of large-scale models applied to a small area. The results showed that: (1) filtering the MODIS NDVI using the Savitzky–Golay (SG), logistic and Gaussian approaches can reduce the AGB estimation error; in particular, the SG method performs the best, with the smallest errors at both the sample plot scale (250 m × 250 m) and the entire study area (33.9% and 34.9%, respectively); (2) the optimum estimation model of grassland AGB in the study area is the exponential model based on NDVIOLI, with estimation errors of 29.1% and 30.7% at the sample plot and the study area scales, respectively; and (3) the estimation errors of grassland AGB models previously constructed at different spatial scales (the Tibetan Plateau, Gannan Prefecture and Xiahe County) are higher than those directly constructed based on the small area of this study by 11.9%–36.4% and 5.3%–29.6% at the sample plot and study area scales, respectively. This study presents an improved monitoring algorithm of alpine natural grassland AGB estimation and provides a clear direction for future improvement of the grassland AGB estimation and grassland productivity from remote sensing technology.},
DOI = {10.3390/rs9040372}
}



@Article{app7050469,
AUTHOR = {Antonakis, Aristeidis and Nikolaidis, Theoklis and Pilidis, Pericles},
TITLE = {Multi-Objective Climb Path Optimization for Aircraft/Engine Integration Using Particle Swarm Optimization},
JOURNAL = {Applied Sciences},
VOLUME = {7},
YEAR = {2017},
NUMBER = {5},
ARTICLE-NUMBER = {469},
URL = {https://www.mdpi.com/2076-3417/7/5/469},
ISSN = {2076-3417},
ABSTRACT = {In this article, a new multi-objective approach to the aircraft climb path optimization problem, based on the Particle Swarm Optimization algorithm, is introduced to be used for aircraft–engine integration studies. This considers a combination of a simulation with a traditional Energy approach, which incorporates, among others, the use of a proposed path-tracking scheme for guidance in the Altitude–Mach plane. The adoption of population-based solver serves to simplify case setup, allowing for direct interfaces between the optimizer and aircraft/engine performance codes. A two-level optimization scheme is employed and is shown to improve search performance compared to the basic PSO algorithm. The effectiveness of the proposed methodology is demonstrated in a hypothetic engine upgrade scenario for the F-4 aircraft considering the replacement of the aircraft’s J79 engine with the EJ200; a clear advantage of the EJ200-equipped configuration is unveiled, resulting, on average, in 15% faster climbs with 20% less fuel.},
DOI = {10.3390/app7050469}
}



@Article{rs9050434,
AUTHOR = {Martin, R. Abraham and Blackburn, Landen and Pulsipher, Joshua and Franke, Kevin and Hedengren, John D.},
TITLE = {Potential Benefits of Combining Anomaly Detection with View Planning for UAV Infrastructure Modeling},
JOURNAL = {Remote Sensing},
VOLUME = {9},
YEAR = {2017},
NUMBER = {5},
ARTICLE-NUMBER = {434},
URL = {https://www.mdpi.com/2072-4292/9/5/434},
ISSN = {2072-4292},
ABSTRACT = {This paper presents a novel method for UAV-based 3D modeling of large infrastructure objects, such as pipelines, canals and levees, that combines anomaly detection with automatic on-board 3D view planning. The study begins by assuming that anomaly detections are possible and focuses on quantifying the potential benefits of the combined method and the view planning algorithm. A simulated canal environment is constructed, and several simulated anomalies are created and marked. The algorithm is used to plan inspection flights for the anomaly locations, and simulated images from the flights are rendered and processed to construct 3D models of the locations of interest. The new flights are compared to traditional flights in terms of flight time, data collected and 3D model accuracy. When compared to a low speed, low elevation traditional flight, the proposed method is shown in simulation to decrease total flight time by up to 55%, while reducing the amount of image data to be processed by 89% and maintaining 3D model accuracy at areas of interest.},
DOI = {10.3390/rs9050434}
}



@Article{rs9050441,
AUTHOR = {Li, Hongguang and Ding, Wenrui and Cao, Xianbin and Liu, Chunlei},
TITLE = {Image Registration and Fusion of Visible and Infrared Integrated Camera for Medium-Altitude Unmanned Aerial Vehicle Remote Sensing},
JOURNAL = {Remote Sensing},
VOLUME = {9},
YEAR = {2017},
NUMBER = {5},
ARTICLE-NUMBER = {441},
URL = {https://www.mdpi.com/2072-4292/9/5/441},
ISSN = {2072-4292},
ABSTRACT = {This study proposes a novel method for image registration and fusion via commonly used visible light and infrared integrated cameras mounted on medium-altitude unmanned aerial vehicles (UAVs).The innovation of image registration lies in three aspects. First, it reveals how complex perspective transformation can be converted to simple scale transformation and translation transformation between two sensor images under long-distance and parallel imaging conditions. Second, with the introduction of metadata, a scale calculation algorithm is designed according to spatial geometry, and a coarse translation estimation algorithm is presented based on coordinate transformation. Third, the problem of non-strictly aligned edges in precise translation estimation is solved via edge–distance field transformation. A searching algorithm based on particle swarm optimization is introduced to improve efficiency. Additionally, a new image fusion algorithm is designed based on a pulse coupled neural network and nonsubsampled contourlet transform to meet the special requirements of preserving color information, adding infrared brightness information, improving spatial resolution, and highlighting target areas for unmanned aerial vehicle (UAV) applications. A medium-altitude UAV is employed to collect datasets. The result is promising, especially in applications that involve other medium-altitude or high-altitude UAVs with similar system structures.},
DOI = {10.3390/rs9050441}
}



@Article{s17051104,
AUTHOR = {Calera, Alfonso and Campos, Isidro and Osann, Anna and D’Urso, Guido and Menenti, Massimo},
TITLE = {Remote Sensing for Crop Water Management: From ET Modelling to Services for the End Users},
JOURNAL = {Sensors},
VOLUME = {17},
YEAR = {2017},
NUMBER = {5},
ARTICLE-NUMBER = {1104},
URL = {https://www.mdpi.com/1424-8220/17/5/1104},
ISSN = {1424-8220},
ABSTRACT = {The experiences gathered during the past 30 years support the operational use of irrigation scheduling based on frequent multi-spectral image data. Currently, the operational use of dense time series of multispectral imagery at high spatial resolution makes monitoring of crop biophysical parameters feasible, capturing crop water use across the growing season, with suitable temporal and spatial resolutions. These achievements, and the availability of accurate forecasting of meteorological data, allow for precise predictions of crop water requirements with unprecedented spatial resolution. This information is greatly appreciated by the end users, i.e., professional farmers or decision-makers, and can be provided in an easy-to-use manner and in near-real-time by using the improvements achieved in web-GIS methodologies (Geographic Information Systems based on web technologies). This paper reviews the most operational and explored methods based on optical remote sensing for the assessment of crop water requirements, identifying strengths and weaknesses and proposing alternatives to advance towards full operational application of this methodology. In addition, we provide a general overview of the tools, which facilitates co-creation and collaboration with stakeholders, paying special attention to these approaches based on web-GIS tools.},
DOI = {10.3390/s17051104}
}



@Article{s17051127,
AUTHOR = {Zuo, Yujia and Liu, Jinghong and Bai, Guanbing and Wang, Xuan and Sun, Mingchao},
TITLE = {Airborne Infrared and Visible Image Fusion Combined with Region Segmentation},
JOURNAL = {Sensors},
VOLUME = {17},
YEAR = {2017},
NUMBER = {5},
ARTICLE-NUMBER = {1127},
URL = {https://www.mdpi.com/1424-8220/17/5/1127},
ISSN = {1424-8220},
ABSTRACT = {This paper proposes an infrared (IR) and visible image fusion method introducing region segmentation into the dual-tree complex wavelet transform (DTCWT) region. This method should effectively improve both the target indication and scene spectrum features of fusion images, and the target identification and tracking reliability of fusion system, on an airborne photoelectric platform. The method involves segmenting the region in an IR image by significance, and identifying the target region and the background region; then, fusing the low-frequency components in the DTCWT region according to the region segmentation result. For high-frequency components, the region weights need to be assigned by the information richness of region details to conduct fusion based on both weights and adaptive phases, and then introducing a shrinkage function to suppress noise; Finally, the fused low-frequency and high-frequency components are reconstructed to obtain the fusion image. The experimental results show that the proposed method can fully extract complementary information from the source images to obtain a fusion image with good target indication and rich information on scene details. They also give a fusion result superior to existing popular fusion methods, based on eithers subjective or objective evaluation. With good stability and high fusion accuracy, this method can meet the fusion requirements of IR-visible image fusion systems.},
DOI = {10.3390/s17051127}
}



@Article{rs9050492,
AUTHOR = {Ciriza, Raquel and Sola, Ion and Albizua, Lourdes and Álvarez-Mozos, Jesús and González-Audícana, María},
TITLE = {Automatic Detection of Uprooted Orchards Based on Orthophoto Texture Analysis},
JOURNAL = {Remote Sensing},
VOLUME = {9},
YEAR = {2017},
NUMBER = {5},
ARTICLE-NUMBER = {492},
URL = {https://www.mdpi.com/2072-4292/9/5/492},
ISSN = {2072-4292},
ABSTRACT = {Permanent crops, such as olive groves, vineyards and fruit trees, are important in European agriculture because of their spatial and economic relevance. Agricultural geographical databases (AGDBs) are commonly used by public bodies to gain knowledge of the extension covered by these crops and to manage related agricultural subsidies and inspections. However, the updating of these databases is mostly based on photointerpretation, and thus keeping this information up-to-date is very costly in terms of time and money. This paper describes a methodology for automatic detection of uprooted orchards (parcels where fruit trees have been eliminated) based on the textural classification of orthophotos with a spatial resolution of 0.25 m. The textural features used for this classification were derived from the grey level co-occurrence matrix (GLCM) and wavelet transform, and were selected through principal components (PCA) and separability analyses. Next, a Discriminant Analysis classification algorithm was used to detect uprooted orchards. Entropy, contrast and correlation were found to be the most informative textural features obtained from the co-occurrence matrix. The minimum and standard deviation in plane 3 were the selected features based on wavelet transform. The classification based on these features achieved a true positive rate (TPR) of over 80% and an accuracy (A) of over 88%. As a result, this methodology enabled reducing the number of fields to photointerpret by 60–85%, depending on the membership threshold value selected. The proposed approach could be easily adopted by different stakeholders and could increase significantly the efficiency of agricultural database updating tasks.},
DOI = {10.3390/rs9050492}
}



@Article{rs9050494,
AUTHOR = {Li, Feimo and Li, Shuxiao and Zhu, Chengfei and Lan, Xiaosong and Chang, Hongxing},
TITLE = {Cost-Effective Class-Imbalance Aware CNN for Vehicle Localization and Categorization in High Resolution Aerial Images},
JOURNAL = {Remote Sensing},
VOLUME = {9},
YEAR = {2017},
NUMBER = {5},
ARTICLE-NUMBER = {494},
URL = {https://www.mdpi.com/2072-4292/9/5/494},
ISSN = {2072-4292},
ABSTRACT = {Joint vehicle localization and categorization in high resolution aerial images can provide useful information for applications such as traffic flow structure analysis. To maintain sufficient features to recognize small-scaled vehicles, a regions with convolutional neural network features (R-CNN) -like detection structure is employed. In this setting, cascaded localization error can be averted by equally treating the negatives and differently typed positives as a multi-class classification task, but the problem of class-imbalance remains. To address this issue, a cost-effective network extension scheme is proposed. In it, the correlated convolution and connection costs during extension are reduced by feature map selection and bi-partite main-side network construction, which are realized with the assistance of a novel feature map class-importance measurement and a new class-imbalance sensitive main-side loss function. By using an image classification dataset established from a set of traditional real-colored aerial images with 0.13 m ground sampling distance which are taken from the height of 1000 m by an imaging system composed of non-metric cameras, the effectiveness of the proposed network extension is verified by comparing with its similarly shaped strong counter-parts. Experiments show an equivalent or better performance, while requiring the least parameter and memory overheads are required.},
DOI = {10.3390/rs9050494}
}



@Article{rs9060544,
AUTHOR = {Gnädinger, Friederike and Schmidhalter, Urs},
TITLE = {Digital Counts of Maize Plants by Unmanned Aerial Vehicles (UAVs)},
JOURNAL = {Remote Sensing},
VOLUME = {9},
YEAR = {2017},
NUMBER = {6},
ARTICLE-NUMBER = {544},
URL = {https://www.mdpi.com/2072-4292/9/6/544},
ISSN = {2072-4292},
ABSTRACT = {Precision phenotyping, especially the use of image analysis, allows researchers to gain information on plant properties and plant health. Aerial image detection with unmanned aerial vehicles (UAVs) provides new opportunities in precision farming and precision phenotyping. Precision farming has created a critical need for spatial data on plant density. The plant number reflects not only the final field emergence but also allows a more precise assessment of the final yield parameters. The aim of this work is to advance UAV use and image analysis as a possible high-throughput phenotyping technique. In this study, four different maize cultivars were planted in plots with different seeding systems (in rows and equidistantly spaced) and different nitrogen fertilization levels (applied at 50, 150 and 250 kg N/ha). The experimental field, encompassing 96 plots, was overflown at a 50-m height with an octocopter equipped with a 10-megapixel camera taking a picture every 5 s. Images were recorded between BBCH 13–15 (it is a scale to identify the phenological development stage of a plant which is here the 3- to 5-leaves development stage) when the color of young leaves differs from older leaves. Close correlations up to R2 = 0.89 were found between in situ and image-based counted plants adapting a decorrelation stretch contrast enhancement procedure, which enhanced color differences in the images. On average, the error between visually and digitally counted plants was ≤5%. Ground cover, as determined by analyzing green pixels, ranged between 76% and 83% at these stages. However, the correlation between ground cover and digitally counted plants was very low. The presence of weeds and blurry effects on the images represent possible errors in counting plants. In conclusion, the final field emergence of maize can rapidly be assessed and allows more precise assessment of the final yield parameters. The use of UAVs and image processing has the potential to optimize farm management and to support field experimentation for agronomic and breeding purposes.},
DOI = {10.3390/rs9060544}
}



@Article{geosciences7020040,
AUTHOR = {Agapiou, Athos and Lysandrou, Vasiliki and Sarris, Apostolos and Papadopoulos, Nikos and Hadjimitsis, Diofantos G.},
TITLE = {Fusion of Satellite Multispectral Images Based on Ground-Penetrating Radar (GPR) Data for the Investigation of Buried Concealed Archaeological Remains},
JOURNAL = {Geosciences},
VOLUME = {7},
YEAR = {2017},
NUMBER = {2},
ARTICLE-NUMBER = {40},
URL = {https://www.mdpi.com/2076-3263/7/2/40},
ISSN = {2076-3263},
ABSTRACT = {The paper investigates the superficial layers of an archaeological landscape based on the integration of various remote sensing techniques. It is well known in the literature that shallow depths may be rich in archeological remains, which generate different signal responses depending on the applied technique. In this study three main technologies are examined, namely ground-penetrating radar (GPR), ground spectroscopy, and multispectral satellite imagery. The study aims to propose a methodology to enhance optical remote sensing satellite images, intended for archaeological research, based on the integration of ground based and satellite datasets. For this task, a regression model between the ground spectroradiometer and GPR is established which is then projected to a high resolution sub-meter optical image. The overall methodology consists of nine steps. Beyond the acquirement of the in-situ measurements and their calibration (Steps 1–3), various regression models are examined for more than 70 different vegetation indices (Steps 4–5). The specific data analysis indicated that the red-edge position (REP) hyperspectral index was the most appropriate for developing a local fusion model between ground spectroscopy data and GPR datasets (Step 6), providing comparable results with the in situ GPR measurements (Step 7). Other vegetation indices, such as the normalized difference vegetation index (NDVI), have also been examined, providing significant correlation between the two datasets (R = 0.50). The model is then projected to a high-resolution image over the area of interest (Step 8). The proposed methodology was evaluated with a series of field data collected from the Vésztő-Mágor Tell in the eastern part of Hungary. The results were compared with in situ magnetic gradiometry measurements, indicating common interpretation results. The results were also compatible with the preliminary archaeological investigations of the area (Step 9). The overall outcomes document that fusion models between various types of remote sensing datasets frequently used to support archaeological research can further expand the current capabilities and applications for the detection of buried archaeological remains.},
DOI = {10.3390/geosciences7020040}
}



@Article{su9061010,
AUTHOR = {Ampatzidis, Yiannis and De Bellis, Luigi and Luvisi, Andrea},
TITLE = {iPathology: Robotic Applications and Management of Plants and Plant Diseases},
JOURNAL = {Sustainability},
VOLUME = {9},
YEAR = {2017},
NUMBER = {6},
ARTICLE-NUMBER = {1010},
URL = {https://www.mdpi.com/2071-1050/9/6/1010},
ISSN = {2071-1050},
ABSTRACT = {The rapid development of new technologies and the changing landscape of the online world (e.g., Internet of Things (IoT), Internet of All, cloud-based solutions) provide a unique opportunity for developing automated and robotic systems for urban farming, agriculture, and forestry. Technological advances in machine vision, global positioning systems, laser technologies, actuators, and mechatronics have enabled the development and implementation of robotic systems and intelligent technologies for precision agriculture. Herein, we present and review robotic applications on plant pathology and management, and emerging agricultural technologies for intra-urban agriculture. Greenhouse advanced management systems and technologies have been greatly developed in the last years, integrating IoT and WSN (Wireless Sensor Network). Machine learning, machine vision, and AI (Artificial Intelligence) have been utilized and applied in agriculture for automated and robotic farming. Intelligence technologies, using machine vision/learning, have been developed not only for planting, irrigation, weeding (to some extent), pruning, and harvesting, but also for plant disease detection and identification. However, plant disease detection still represents an intriguing challenge, for both abiotic and biotic stress. Many recognition methods and technologies for identifying plant disease symptoms have been successfully developed; still, the majority of them require a controlled environment for data acquisition to avoid false positives. Machine learning methods (e.g., deep and transfer learning) present promising results for improving image processing and plant symptom identification. Nevertheless, diagnostic specificity is a challenge for microorganism control and should drive the development of mechatronics and robotic solutions for disease management.},
DOI = {10.3390/su9061010}
}



@Article{environments4020042,
AUTHOR = {Stella, Alessandro and Caliendo, Gennaro and Melgani, Farid and Goller, Rino and Barazzuol, Maurizio and La Porta, Nicola},
TITLE = {Leaf Wetness Evaluation Using Artificial Neural Network for Improving Apple Scab Fight},
JOURNAL = {Environments},
VOLUME = {4},
YEAR = {2017},
NUMBER = {2},
ARTICLE-NUMBER = {42},
URL = {https://www.mdpi.com/2076-3298/4/2/42},
ISSN = {2076-3298},
ABSTRACT = {Precision agriculture represents a promising technological trend in which governments and local authorities are increasingly investing. In particular, optimising the use of pesticides and having localised models of plant disease are the most important goals for the farmers of the future. The Trentino province in Italy is known as a strong national producer of apples. Apple production has to face many issues, however, among which is apple scab. This disease depends mainly on leaf wetness data typically acquired by fixed sensors. Based on the exploitation of artificial neural networks, this work aims to spatially extend the measurements of such sensors across uncovered areas (areas deprived of sensors). Achieved results have been validated comparing the apple scab risk of the same zone using either real leaf wetness data and estimated data. Thanks to the proposed method, it is possible to get the most relevant parameter of apple scab risk in places where no leaf wetness sensor is available. Moreover, our method permits having a specific risk evaluation of apple scab infection for each orchard, leading to an optimization of the use of chemical pesticides.},
DOI = {10.3390/environments4020042}
}



@Article{jimaging3020021,
AUTHOR = {Radovic, Matija and Adarkwa, Offei and Wang, Qiaosong},
TITLE = {Object Recognition in Aerial Images Using Convolutional Neural Networks},
JOURNAL = {Journal of Imaging},
VOLUME = {3},
YEAR = {2017},
NUMBER = {2},
ARTICLE-NUMBER = {21},
URL = {https://www.mdpi.com/2313-433X/3/2/21},
ISSN = {2313-433X},
ABSTRACT = {There are numerous applications of unmanned aerial vehicles (UAVs) in the management of civil infrastructure assets. A few examples include routine bridge inspections, disaster management, power line surveillance and traffic surveying. As UAV applications become widespread, increased levels of autonomy and independent decision-making are necessary to improve the safety, efficiency, and accuracy of the devices. This paper details the procedure and parameters used for the training of convolutional neural networks (CNNs) on a set of aerial images for efficient and automated object recognition. Potential application areas in the transportation field are also highlighted. The accuracy and reliability of CNNs depend on the network’s training and the selection of operational parameters. This paper details the CNN training procedure and parameter selection. The object recognition results show that by selecting a proper set of parameters, a CNN can detect and classify objects with a high level of accuracy (97.5%) and computational efficiency. Furthermore, using a convolutional neural network implemented in the “YOLO” (“You Only Look Once”) platform, objects can be tracked, detected (“seen”), and classified (“comprehended”) from video feeds supplied by UAVs in real-time.},
DOI = {10.3390/jimaging3020021}
}



@Article{aerospace4020031,
AUTHOR = {Ru, Pengkai and Subbarao, Kamesh},
TITLE = {Nonlinear Model Predictive Control for Unmanned Aerial Vehicles},
JOURNAL = {Aerospace},
VOLUME = {4},
YEAR = {2017},
NUMBER = {2},
ARTICLE-NUMBER = {31},
URL = {https://www.mdpi.com/2226-4310/4/2/31},
ISSN = {2226-4310},
ABSTRACT = {This paper discusses the derivation and implementation of a nonlinear model predictive control law for tracking reference trajectories and constrained control of a quadrotor platform. The approach uses the state-dependent coefficient form to capture the system nonlinearities into a pseudo-linear system matrix. The state-dependent coefficient form is derived following a rigorous analysis of aerial vehicle dynamics that systematically accounts for the peculiarities of such systems. The same state-dependent coefficient form is exploited for obtaining a nonlinear equivalent of the model predictive control. The nonlinear model predictive control law is derived by first transforming the continuous system into a sampled-data form and and then using a sequential quadratic programming solver while accounting for input, output and state constraints. The boundedness of the tracking errors using the sampled-data implementation is shown explicitly. The performance of the nonlinear controller is illustrated through representative simulations showing the tracking of several aggressive reference trajectories with and without disturbances.},
DOI = {10.3390/aerospace4020031}
}



@Article{s17061428,
AUTHOR = {Domingues Franceschini, Marston Héracles and Bartholomeus, Harm and Van Apeldoorn, Dirk and Suomalainen, Juha and Kooistra, Lammert},
TITLE = {Intercomparison of Unmanned Aerial Vehicle and Ground-Based Narrow Band Spectrometers Applied to Crop Trait Monitoring in Organic Potato Production},
JOURNAL = {Sensors},
VOLUME = {17},
YEAR = {2017},
NUMBER = {6},
ARTICLE-NUMBER = {1428},
URL = {https://www.mdpi.com/1424-8220/17/6/1428},
ISSN = {1424-8220},
ABSTRACT = {Vegetation properties can be estimated using optical sensors, acquiring data on board of different platforms. For instance, ground-based and Unmanned Aerial Vehicle (UAV)-borne spectrometers can measure reflectance in narrow spectral bands, while different modelling approaches, like regressions fitted to vegetation indices, can relate spectra with crop traits. Although monitoring frameworks using multiple sensors can be more flexible, they may result in higher inaccuracy due to differences related to the sensors characteristics, which can affect information sampling. Also organic production systems can benefit from continuous monitoring focusing on crop management and stress detection, but few studies have evaluated applications with this objective. In this study, ground-based and UAV spectrometers were compared in the context of organic potato cultivation. Relatively accurate estimates were obtained for leaf chlorophyll (RMSE = 6.07 µg·cm−2), leaf area index (RMSE = 0.67 m2·m−2), canopy chlorophyll (RMSE = 0.24 g·m−2) and ground cover (RMSE = 5.5%) using five UAV-based data acquisitions, from 43 to 99 days after planting. These retrievals are slightly better than those derived from ground-based measurements (RMSE = 7.25 µg·cm−2, 0.85 m2·m−2, 0.28 g·m−2 and 6.8%, respectively), for the same period. Excluding observations corresponding to the first acquisition increased retrieval accuracy and made outputs more comparable between sensors, due to relatively low vegetation cover on this date. Intercomparison of vegetation indices indicated that indices based on the contrast between spectral bands in the visible and near-infrared, like OSAVI, MCARI2 and CIg provided, at certain extent, robust outputs that could be transferred between sensors. Information sampling at plot level by both sensing solutions resulted in comparable discriminative potential concerning advanced stages of late blight incidence. These results indicate that optical sensors, and their integration, have great potential for monitoring this specific organic cropping system.},
DOI = {10.3390/s17061428}
}



@Article{s17061431,
AUTHOR = {Xu, Qimin and Li, Xu and Chan, Ching-Yao},
TITLE = {A Cost-Effective Vehicle Localization Solution Using an Interacting Multiple Model−Unscented Kalman Filters (IMM-UKF) Algorithm and Grey Neural Network},
JOURNAL = {Sensors},
VOLUME = {17},
YEAR = {2017},
NUMBER = {6},
ARTICLE-NUMBER = {1431},
URL = {https://www.mdpi.com/1424-8220/17/6/1431},
ISSN = {1424-8220},
ABSTRACT = {In this paper, we propose a cost-effective localization solution for land vehicles, which can simultaneously adapt to the uncertain noise of inertial sensors and bridge Global Positioning System (GPS) outages. First, three Unscented Kalman filters (UKFs) with different noise covariances are introduced into the framework of Interacting Multiple Model (IMM) algorithm to form the proposed IMM-based UKF, termed as IMM-UKF. The IMM algorithm can provide a soft switching among the three UKFs and therefore adapt to different noise characteristics. Further, two IMM-UKFs are executed in parallel when GPS is available. One fuses the information of low-cost GPS, in-vehicle sensors, and micro electromechanical system (MEMS)-based reduced inertial sensor systems (RISS), while the other fuses only in-vehicle sensors and MEMS-RISS. The differences between the state vectors of the two IMM-UKFs are considered as training data of a Grey Neural Network (GNN) module, which is known for its high prediction accuracy with a limited amount of samples. The GNN module can predict and compensate position errors when GPS signals are blocked. To verify the feasibility and effectiveness of the proposed solution, road-test experiments with various driving scenarios were performed. The experimental results indicate that the proposed solution outperforms all the compared methods.},
DOI = {10.3390/s17061431}
}



@Article{aerospace4020032,
AUTHOR = {Yang, Yurong and Gong, Huajun and Wang, Xinhua and Sun, Peng},
TITLE = {Aerial Target Tracking Algorithm Based on Faster R-CNN Combined with Frame Differencing},
JOURNAL = {Aerospace},
VOLUME = {4},
YEAR = {2017},
NUMBER = {2},
ARTICLE-NUMBER = {32},
URL = {https://www.mdpi.com/2226-4310/4/2/32},
ISSN = {2226-4310},
ABSTRACT = {We propose a robust approach to detecting and tracking moving objects for a naval unmanned aircraft system (UAS) landing on an aircraft carrier. The frame difference algorithm follows a simple principle to achieve real-time tracking, whereas Faster Region-Convolutional Neural Network (R-CNN) performs highly precise detection and tracking characteristics. We thus combine Faster R-CNN with the frame difference method, which is demonstrated to exhibit robust and real-time detection and tracking performance. In our UAS landing experiments, two cameras placed on both sides of the runway are used to capture the moving UAS. When the UAS is captured, the joint algorithm uses frame difference to detect the moving target (UAS). As soon as the Faster R-CNN algorithm accurately detects the UAS, the detection priority is given to Faster R-CNN. In this manner, we also perform motion segmentation and object detection in the presence of changes in the environment, such as illumination variation or “walking persons”. By combining the 2 algorithms we can accurately detect and track objects with a tracking accuracy rate of up to 99% and a frame per second of up to 40 Hz. Thus, a solid foundation is laid for subsequent landing guidance.},
DOI = {10.3390/aerospace4020032}
}



@Article{s17071499,
AUTHOR = {Torres-Rua, Alfonso},
TITLE = {Vicarious Calibration of sUAS Microbolometer Temperature Imagery for Estimation of Radiometric Land Surface Temperature},
JOURNAL = {Sensors},
VOLUME = {17},
YEAR = {2017},
NUMBER = {7},
ARTICLE-NUMBER = {1499},
URL = {https://www.mdpi.com/1424-8220/17/7/1499},
ISSN = {1424-8220},
ABSTRACT = {In recent years, the availability of lightweight microbolometer thermal cameras compatible with small unmanned aerial systems (sUAS) has allowed their use in diverse scientific and management activities that require sub-meter pixel resolution. Nevertheless, as with sensors already used in temperature remote sensing (e.g., Landsat satellites), a radiance atmospheric correction is necessary to estimate land surface temperature. This is because atmospheric conditions at any sUAS flight elevation will have an adverse impact on the image accuracy, derived calculations, and study replicability using the microbolometer technology. This study presents a vicarious calibration methodology (sUAS-specific, time-specific, flight-specific, and sensor-specific) for sUAS temperature imagery traceable back to NIST-standards and current atmospheric correction methods. For this methodology, a three-year data collection campaign with a sUAS called “AggieAir”, developed at Utah State University, was performed for vineyards near Lodi, California, for flights conducted at different times (early morning, Landsat overpass, and mid-afternoon”) and seasonal conditions. From the results of this study, it was found that, despite the spectral response of microbolometer cameras (7.0 to 14.0 μm), it was possible to account for the effects of atmospheric and sUAS operational conditions, regardless of time and weather, to acquire accurate surface temperature data. In addition, it was found that the main atmospheric correction parameters (transmissivity and atmospheric radiance) significantly varied over the course of a day. These parameters fluctuated the most in early morning and partially stabilized in Landsat overpass and in mid-afternoon times. In terms of accuracy, estimated atmospheric correction parameters presented adequate statistics (confidence bounds under ±0.1 for transmissivity and ±1.2 W/m2/sr/um for atmospheric radiance, with a range of RMSE below 1.0 W/m2/sr/um) for all sUAS flights. Differences in estimated temperatures between original thermal image and the vicarious calibration procedure reported here were estimated from −5 °C to 10 °C for early morning, and from 0 to 20 °C for Landsat overpass and mid-afternoon times.},
DOI = {10.3390/s17071499}
}



@Article{en10070992,
AUTHOR = {Pau, Giovanni and Collotta, Mario and Maniscalco, Vincenzo},
TITLE = {Bluetooth 5 Energy Management through a Fuzzy-PSO Solution for Mobile Devices of Internet of Things},
JOURNAL = {Energies},
VOLUME = {10},
YEAR = {2017},
NUMBER = {7},
ARTICLE-NUMBER = {992},
URL = {https://www.mdpi.com/1996-1073/10/7/992},
ISSN = {1996-1073},
ABSTRACT = {Energy efficiency is a fundamental requirement for a wireless protocol to be suitable for use within the Internet of Things. New technologies are emerging aiming at an energy-efficient communication. Among them, Bluetooth Low Energy is an appealing solution. Recently, the specifications of Bluetooth 5 have been presented with the purpose to offer significant enhancements compared to the earlier versions of the protocol. Bluetooth 5 comes with new communication modes that differ in range, speed, and energy consumption. This paper proposes a fuzzy-based solution to cope with the selection of the communication mode, among those introduced with Bluetooth 5, that allows the best energy efficiency. This communication mode, used by mobile devices, is dynamically regulated by varying the transmission power, returned as the output of a Fuzzy Logic Controller (FLC). A Particle Swarm Optimization (PSO) algorithm is presented to achieve the optimal parameters of the proposed FLC, i.e., optimizing the triangular membership functions, by varying their range, to reach the best results concerning the battery life of mobile devices. The proposed FLC is based on triangular membership functions because they represent a good trade-off between computation cost and efficiency. The paper presents a detailed description of the FLC design, a logical analysis of the PSO algorithm for the derivation of best performance conditions values, and experimental assessments, obtained through testbed scenarios.},
DOI = {10.3390/en10070992}
}



@Article{rs9070726,
AUTHOR = {Danner, Martin and Berger, Katja and Wocher, Matthias and Mauser, Wolfram and Hank, Tobias},
TITLE = {Retrieval of Biophysical Crop Variables from Multi-Angular Canopy Spectroscopy},
JOURNAL = {Remote Sensing},
VOLUME = {9},
YEAR = {2017},
NUMBER = {7},
ARTICLE-NUMBER = {726},
URL = {https://www.mdpi.com/2072-4292/9/7/726},
ISSN = {2072-4292},
ABSTRACT = {The future German Environmental Mapping and Analysis Program (EnMAP) mission, due to launch in late 2019, will deliver high resolution hyperspectral data from space and will thus contribute to a better monitoring of the dynamic surface of the earth. Exploiting the satellite’s ±30° across-track pointing capabilities will allow for the collection of hyperspectral time-series of homogeneous quality. Various studies have shown the possibility to retrieve geo-biophysical plant variables, like leaf area index (LAI) or leaf chlorophyll content (LCC), from narrowband observations with fixed viewing geometry by inversion of radiative transfer models (RTM). In this study we assess the capability of the well-known PROSPECT 5B + 4SAIL (Scattering by Arbitrarily Inclined Leaves) RTM to estimate these variables from off-nadir observations obtained during a field campaign with respect to EnMAP-like sun–target–sensor-geometries. A novel approach for multiple inquiries of a large look-up-table (LUT) in hierarchical steps is introduced that accounts for the varying instances of all variables of interest. Results show that anisotropic effects are strongest for early growth stages of the winter wheat canopy which influences also the retrieval of the variables. RTM inversions from off-nadir spectra lead to a decreased accuracy for the retrieval of LAI with a relative root mean squared error (rRMSE) of 18% at nadir vs. 25% (backscatter) and 24% (forward scatter) at off-nadir. For LCC estimations, however, off-nadir observations yield improvements, i.e., rRMSE (nadir) = 24% vs. rRMSE (forward scatter) = 20%. It follows that for a variable retrieval through RTM inversion, the final user will benefit from EnMAP time-series for biophysical studies regardless of the acquisition angle and will thus be able to exploit the maximum revisit capability of the mission.},
DOI = {10.3390/rs9070726}
}



@Article{sym9070125,
AUTHOR = {Tseng, Hsiao-Ting and Hwang, Hsin-Ginn and Hsu, Wei-Yen and Chou, Pei-Chin and Chang, I-Chiu},
TITLE = {IoT-Based Image Recognition System for Smart Home-Delivered Meal Services},
JOURNAL = {Symmetry},
VOLUME = {9},
YEAR = {2017},
NUMBER = {7},
ARTICLE-NUMBER = {125},
URL = {https://www.mdpi.com/2073-8994/9/7/125},
ISSN = {2073-8994},
ABSTRACT = {Population ageing is an important global issue. The Taiwanese government has used various Internet of Things (IoT) applications in the “10-year long-term care program 2.0”. It is expected that the efficiency and effectiveness of long-term care services will be improved through IoT support. Home-delivered meal services for the elderly are important for home-based long-term care services. To ensure that the right meals are delivered to the right recipient at the right time, the runners need to take a picture of the meal recipient when the meal is delivered. This study uses the IoT-based image recognition system to design an integrated service to improve the management of image recognition. The core technology of this IoT-based image recognition system is statistical histogram-based k-means clustering for image segmentation. However, this method is time-consuming. Therefore, we proposed using the statistical histogram to obtain a probability density function of pixels of a figure and segmenting these with weighting for the same intensity. This aims to increase the computational performance and achieve the same results as k-means clustering. We combined histogram and k-means clustering in order to overcome the high computational cost for k-means clustering. The results indicate that the proposed method is significantly faster than k-means clustering by more than 10 times.},
DOI = {10.3390/sym9070125}
}



@Article{en10071063,
AUTHOR = {Zhou, Fang and Xiao, Feng and Chang, Cheng and Shao, Yulong and Song, Chuanxue},
TITLE = {Adaptive Model Predictive Control-Based Energy Management for Semi-Active Hybrid Energy Storage Systems on Electric Vehicles},
JOURNAL = {Energies},
VOLUME = {10},
YEAR = {2017},
NUMBER = {7},
ARTICLE-NUMBER = {1063},
URL = {https://www.mdpi.com/1996-1073/10/7/1063},
ISSN = {1996-1073},
ABSTRACT = {This paper deals with the energy management strategy (EMS) for an on-board semi-active hybrid energy storage system (HESS) composed of a Li-ion battery (LiB) and ultracapacitor (UC). Considering both the nonlinearity of the semi-active structure and driving condition uncertainty, while ensuring HESS operation within constraints, an adaptive model predictive control (AMPC) method is adopted to design the EMS. Within AMPC, LiB Ah-throughput is minimized online to extend its life. The proposed AMPC determines the optimal control action by solving a quadratic programming (QP) problem at each control interval, in which the QP solver receives control-oriented model matrices and current states for calculation. The control-oriented model is constructed by linearizing HESS online to approximate the original nonlinear model. Besides, a time-varying Kalman filter (TVKF) is introduced as the estimator to improve the state estimation accuracy. At the same time, sampling time, prediction horizon and scaling factors of AMPC are determined through simulation. Compared with standard MPC, TVKF reduces the estimation error by 1~3 orders of magnitude, and AMPC reduces LiB Ah-throughput by 4.3% under Urban Dynamometer Driving Schedule (UDDS) driving cycle condition, indicating superior model adaptivity. Furthermore, LiB Ah-throughput of AMPC under various classical driving cycles differs from that of dynamic programming by an average of 6.5% and reduces by an average of 10.6% compared to rule-based strategy of LiB Ah-throughput, showing excellent adaptation to driving condition uncertainty.},
DOI = {10.3390/en10071063}
}



@Article{s17081720,
AUTHOR = {Roldán, Juan Jesús and Peña-Tapia, Elena and Martín-Barrio, Andrés and Olivares-Méndez, Miguel A. and Del Cerro, Jaime and Barrientos, Antonio},
TITLE = {Multi-Robot Interfaces and Operator Situational Awareness: Study of the Impact of Immersion and Prediction},
JOURNAL = {Sensors},
VOLUME = {17},
YEAR = {2017},
NUMBER = {8},
ARTICLE-NUMBER = {1720},
URL = {https://www.mdpi.com/1424-8220/17/8/1720},
ISSN = {1424-8220},
ABSTRACT = {Multi-robot missions are a challenge for operators in terms of workload and situational awareness. These operators have to receive data from the robots, extract information, understand the situation properly, make decisions, generate the adequate commands, and send them to the robots. The consequences of excessive workload and lack of awareness can vary from inefficiencies to accidents. This work focuses on the study of future operator interfaces of multi-robot systems, taking into account relevant issues such as multimodal interactions, immersive devices, predictive capabilities and adaptive displays. Specifically, four interfaces have been designed and developed: a conventional, a predictive conventional, a virtual reality and a predictive virtual reality interface. The four interfaces have been validated by the performance of twenty-four operators that supervised eight multi-robot missions of fire surveillance and extinguishing. The results of the workload and situational awareness tests show that virtual reality improves the situational awareness without increasing the workload of operators, whereas the effects of predictive components are not significant and depend on their implementation.},
DOI = {10.3390/s17081720}
}



@Article{rs9080775,
AUTHOR = {Ahmed, Asmau M. and Duran, Olga and Zweiri, Yahya and Smith, Mike},
TITLE = {Hybrid Spectral Unmixing: Using Artificial Neural Networks for Linear/Non-Linear Switching},
JOURNAL = {Remote Sensing},
VOLUME = {9},
YEAR = {2017},
NUMBER = {8},
ARTICLE-NUMBER = {775},
URL = {https://www.mdpi.com/2072-4292/9/8/775},
ISSN = {2072-4292},
ABSTRACT = {Spectral unmixing is a key process in identifying spectral signature of materials and quantifying their spatial distribution over an image. The linear model is expected to provide acceptable results when two assumptions are satisfied: (1) The mixing process should occur at macroscopic level and (2) Photons must interact with single material before reaching the sensor. However, these assumptions do not always hold and more complex nonlinear models are required. This study proposes a new hybrid method for switching between linear and nonlinear spectral unmixing of hyperspectral data based on artificial neural networks. The neural networks was trained with parameters within a window of the pixel under consideration. These parameters are computed to represent the diversity of the neighboring pixels and are based on the Spectral Angular Distance, Covariance and a non linearity parameter. The endmembers were extracted using Vertex Component Analysis while the abundances were estimated using the method identified by the neural networks (Vertex Component Analysis, Fully Constraint Least Square Method, Polynomial Post Nonlinear Mixing Model or Generalized Bilinear Model). Results show that the hybrid method performs better than each of the individual techniques with high overall accuracy, while the abundance estimation error is significantly lower than that obtained using the individual methods. Experiments on both synthetic dataset and real hyperspectral images demonstrated that the proposed hybrid switch method is efficient for solving spectral unmixing of hyperspectral images as compared to individual algorithms.},
DOI = {10.3390/rs9080775}
}



@Article{s17081781,
AUTHOR = {Jawad, Haider Mahmood and Nordin, Rosdiadee and Gharghan, Sadik Kamel and Jawad, Aqeel Mahmood and Ismail, Mahamod},
TITLE = {Energy-Efficient Wireless Sensor Networks for Precision Agriculture: A Review},
JOURNAL = {Sensors},
VOLUME = {17},
YEAR = {2017},
NUMBER = {8},
ARTICLE-NUMBER = {1781},
URL = {https://www.mdpi.com/1424-8220/17/8/1781},
ISSN = {1424-8220},
ABSTRACT = {Wireless sensor networks (WSNs) can be used in agriculture to provide farmers with a large amount of information. Precision agriculture (PA) is a management strategy that employs information technology to improve quality and production. Utilizing wireless sensor technologies and management tools can lead to a highly effective, green agriculture. Based on PA management, the same routine to a crop regardless of site environments can be avoided. From several perspectives, field management can improve PA, including the provision of adequate nutrients for crops and the wastage of pesticides for the effective control of weeds, pests, and diseases. This review outlines the recent applications of WSNs in agriculture research as well as classifies and compares various wireless communication protocols, the taxonomy of energy-efficient and energy harvesting techniques for WSNs that can be used in agricultural monitoring systems, and comparison between early research works on agriculture-based WSNs. The challenges and limitations of WSNs in the agricultural domain are explored, and several power reduction and agricultural management techniques for long-term monitoring are highlighted. These approaches may also increase the number of opportunities for processing Internet of Things (IoT) data.},
DOI = {10.3390/s17081781}
}



@Article{s17081865,
AUTHOR = {Lopez-Franco, Carlos and Gomez-Avila, Javier and Alanis, Alma Y. and Arana-Daniel, Nancy and Villaseñor, Carlos},
TITLE = {Visual Servoing for an Autonomous Hexarotor Using a Neural Network Based PID Controller},
JOURNAL = {Sensors},
VOLUME = {17},
YEAR = {2017},
NUMBER = {8},
ARTICLE-NUMBER = {1865},
URL = {https://www.mdpi.com/1424-8220/17/8/1865},
ISSN = {1424-8220},
ABSTRACT = {In recent years, unmanned aerial vehicles (UAVs) have gained significant attention. However, we face two major drawbacks when working with UAVs: high nonlinearities and unknown position in 3D space since it is not provided with on-board sensors that can measure its position with respect to a global coordinate system. In this paper, we present a real-time implementation of a servo control, integrating vision sensors, with a neural proportional integral derivative (PID), in order to develop an hexarotor image based visual servo control (IBVS) that knows the position of the robot by using a velocity vector as a reference to control the hexarotor position. This integration requires a tight coordination between control algorithms, models of the system to be controlled, sensors, hardware and software platforms and well-defined interfaces, to allow the real-time implementation, as well as the design of different processing stages with their respective communication architecture. All of these issues and others provoke the idea that real-time implementations can be considered as a difficult task. For the purpose of showing the effectiveness of the sensor integration and control algorithm to address these issues on a high nonlinear system with noisy sensors as cameras, experiments were performed on the Asctec Firefly on-board computer, including both simulation and experimenta results.},
DOI = {10.3390/s17081865}
}



@Article{s17091940,
AUTHOR = {Hannink, Julius and Ollenschläger, Malte and Kluge, Felix and Roth, Nils and Klucken, Jochen and Eskofier, Bjoern M.},
TITLE = {Benchmarking Foot Trajectory Estimation Methods for Mobile Gait Analysis},
JOURNAL = {Sensors},
VOLUME = {17},
YEAR = {2017},
NUMBER = {9},
ARTICLE-NUMBER = {1940},
URL = {https://www.mdpi.com/1424-8220/17/9/1940},
ISSN = {1424-8220},
ABSTRACT = {Mobile gait analysis systems based on inertial sensing on the shoe are applied in a wide range of applications. Especially for medical applications, they can give new insights into motor impairment in, e.g., neurodegenerative disease and help objectify patient assessment. One key component in these systems is the reconstruction of the foot trajectories from inertial data. In literature, various methods for this task have been proposed. However, performance is evaluated on a variety of datasets due to the lack of large, generally accepted benchmark datasets. This hinders a fair comparison of methods. In this work, we implement three orientation estimation and three double integration schemes for use in a foot trajectory estimation pipeline. All methods are drawn from literature and evaluated against a marker-based motion capture reference. We provide a fair comparison on the same dataset consisting of 735 strides from 16 healthy subjects. As a result, the implemented methods are ranked and we identify the most suitable processing pipeline for foot trajectory estimation in the context of mobile gait analysis.},
DOI = {10.3390/s17091940}
}



@Article{s17091957,
AUTHOR = {Yan, Yiming and Tan, Zhichao and Su, Nan and Zhao, Chunhui},
TITLE = {Building Extraction Based on an Optimized Stacked Sparse Autoencoder of Structure and Training Samples Using LIDAR DSM and Optical Images},
JOURNAL = {Sensors},
VOLUME = {17},
YEAR = {2017},
NUMBER = {9},
ARTICLE-NUMBER = {1957},
URL = {https://www.mdpi.com/1424-8220/17/9/1957},
ISSN = {1424-8220},
ABSTRACT = {In this paper, a building extraction method is proposed based on a stacked sparse autoencoder with an optimized structure and training samples. Building extraction plays an important role in urban construction and planning. However, some negative effects will reduce the accuracy of extraction, such as exceeding resolution, bad correction and terrain influence. Data collected by multiple sensors, as light detection and ranging (LIDAR), optical sensor etc., are used to improve the extraction. Using digital surface model (DSM) obtained from LIDAR data and optical images, traditional method can improve the extraction effect to a certain extent, but there are some defects in feature extraction. Since stacked sparse autoencoder (SSAE) neural network can learn the essential characteristics of the data in depth, SSAE was employed to extract buildings from the combined DSM data and optical image. A better setting strategy of SSAE network structure is given, and an idea of setting the number and proportion of training samples for better training of SSAE was presented. The optical data and DSM were combined as input of the optimized SSAE, and after training by an optimized samples, the appropriate network structure can extract buildings with great accuracy and has good robustness.},
DOI = {10.3390/s17091957}
}



@Article{en10091286,
AUTHOR = {Morfin, Onofre A. and Castañeda, Carlos E. and Valderrabano-Gonzalez, Antonio and Hernandez-Gonzalez, Miguel and Valenzuela, Fredy A.},
TITLE = {A Real-Time SOSM Super-Twisting Technique for a Compound DC Motor Velocity Controller},
JOURNAL = {Energies},
VOLUME = {10},
YEAR = {2017},
NUMBER = {9},
ARTICLE-NUMBER = {1286},
URL = {https://www.mdpi.com/1996-1073/10/9/1286},
ISSN = {1996-1073},
ABSTRACT = {In this paper, a real-time robust closed-loop control scheme for controlling the velocity of a Direct Current (DC) motor in a compound connection is proposed. This scheme is based on the state-feedback linearization technique combined with a second-order sliding mode algorithm, named super-twisting, for stabilizing the system and achieving control goals. The control law is designed to track a periodic square reference signal, being one of the most severe tests applied to closed-loop systems. The DC motor drives a squirrel-cage induction generator which represents the load; this generator must work above the synchronous velocity to deliver the generated power towards the grid. A classical proportional-integral (PI) controller is designed for comparison purposes of the time-domain responses with the proposed second-order sliding mode (SOSM) super-twisting controller. This robust controller uses only a velocity sensor, as is the case of the PI controller, as the time derivative of the velocity tracking variable is estimated via a robust differentiator. Therefore, the measurements of field current and stator current, the signal from a load torque observer, and machine parameters are not necessary for the controller design. The validation and robustness test of the proposed controller is carried out experimentally in a laboratory, where the closed-loop system is subject to an external disturbance and a time-varying tracking signal. This test is performed in real time using a workbench consisting of a DC motor—Alternating Current (AC) generator group, a DC/AC electronic drive, and a dSPACE 1103 controller board.},
DOI = {10.3390/en10091286}
}



@Article{s17092007,
AUTHOR = {Alexandridis, Thomas K. and Tamouridou, Afroditi Alexandra and Pantazi, Xanthoula Eirini and Lagopodi, Anastasia L. and Kashefi, Javid and Ovakoglou, Georgios and Polychronos, Vassilios and Moshou, Dimitrios},
TITLE = {Novelty Detection Classifiers in Weed Mapping: Silybum marianum Detection on UAV Multispectral Images},
JOURNAL = {Sensors},
VOLUME = {17},
YEAR = {2017},
NUMBER = {9},
ARTICLE-NUMBER = {2007},
URL = {https://www.mdpi.com/1424-8220/17/9/2007},
ISSN = {1424-8220},
ABSTRACT = {In the present study, the detection and mapping of Silybum marianum (L.) Gaertn. weed using novelty detection classifiers is reported. A multispectral camera (green-red-NIR) on board a fixed wing unmanned aerial vehicle (UAV) was employed for obtaining high-resolution images. Four novelty detection classifiers were used to identify S. marianum between other vegetation in a field. The classifiers were One Class Support Vector Machine (OC-SVM), One Class Self-Organizing Maps (OC-SOM), Autoencoders and One Class Principal Component Analysis (OC-PCA). As input features to the novelty detection classifiers, the three spectral bands and texture were used. The S. marianum identification accuracy using OC-SVM reached an overall accuracy of 96%. The results show the feasibility of effective S. marianum mapping by means of novelty detection classifiers acting on multispectral UAV imagery.},
DOI = {10.3390/s17092007}
}



@Article{app7090907,
AUTHOR = {Lee, Keun Uk and Choi, Yoon Ho and Park, Jin Bae},
TITLE = {Inverse Optimal Design for Position Control of a Quadrotor},
JOURNAL = {Applied Sciences},
VOLUME = {7},
YEAR = {2017},
NUMBER = {9},
ARTICLE-NUMBER = {907},
URL = {https://www.mdpi.com/2076-3417/7/9/907},
ISSN = {2076-3417},
ABSTRACT = {In this paper, we propose an inverse optimal design method for the position control of a quadrotor. First, we derive the dynamics of a quadrotor using the Newton-Euler formulation. Second, we present the state transformation technique to derive the position dynamics from the kinematic and dynamic models of a quadrotor. Then, we present the nonlinear inverse optimal position control of a quadrotor. The stability analysis based on Lyapunov theorem shows that the proposed control method can realize a quadrotor system that is exponentially stabilized. In addition, we show the inverse optimality of the proposed inverse optimal controller for the position control of a quadrotor. The inverse optimality can simply and clearly be shown using the state transformation technique. Finally, we present some simulation results to verify the effectiveness of the proposed control method.},
DOI = {10.3390/app7090907}
}



@Article{s17092052,
AUTHOR = {Kim, Hyunjun and Lee, Junhwa and Ahn, Eunjong and Cho, Soojin and Shin, Myoungsu and Sim, Sung-Han},
TITLE = {Concrete Crack Identification Using a UAV Incorporating Hybrid Image Processing},
JOURNAL = {Sensors},
VOLUME = {17},
YEAR = {2017},
NUMBER = {9},
ARTICLE-NUMBER = {2052},
URL = {https://www.mdpi.com/1424-8220/17/9/2052},
ISSN = {1424-8220},
ABSTRACT = {Crack assessment is an essential process in the maintenance of concrete structures. In general, concrete cracks are inspected by manual visual observation of the surface, which is intrinsically subjective as it depends on the experience of inspectors. Further, it is time-consuming, expensive, and often unsafe when inaccessible structural members are to be assessed. Unmanned aerial vehicle (UAV) technologies combined with digital image processing have recently been applied to crack assessment to overcome the drawbacks of manual visual inspection. However, identification of crack information in terms of width and length has not been fully explored in the UAV-based applications, because of the absence of distance measurement and tailored image processing. This paper presents a crack identification strategy that combines hybrid image processing with UAV technology. Equipped with a camera, an ultrasonic displacement sensor, and a WiFi module, the system provides the image of cracks and the associated working distance from a target structure on demand. The obtained information is subsequently processed by hybrid image binarization to estimate the crack width accurately while minimizing the loss of the crack length information. The proposed system has shown to successfully measure cracks thicker than 0.1 mm with the maximum length estimation error of 7.3%.},
DOI = {10.3390/s17092052}
}



@Article{s17092106,
AUTHOR = {Hassan-Esfahani, Leila and Ebtehaj, Ardeshir M. and Torres-Rua, Alfonso and McKee, Mac},
TITLE = {Spatial Scale Gap Filling Using an Unmanned Aerial System: A Statistical Downscaling Method for Applications in Precision Agriculture},
JOURNAL = {Sensors},
VOLUME = {17},
YEAR = {2017},
NUMBER = {9},
ARTICLE-NUMBER = {2106},
URL = {https://www.mdpi.com/1424-8220/17/9/2106},
ISSN = {1424-8220},
ABSTRACT = {Applications of satellite-borne observations in precision agriculture (PA) are often limited due to the coarse spatial resolution of satellite imagery. This paper uses high-resolution airborne observations to increase the spatial resolution of satellite data for related applications in PA. A new variational downscaling scheme is presented that uses coincident aerial imagery products from “AggieAir”, an unmanned aerial system, to increase the spatial resolution of Landsat satellite data. This approach is primarily tested for downscaling individual band Landsat images that can be used to derive normalized difference vegetation index (NDVI) and surface soil moisture (SSM). Quantitative and qualitative results demonstrate promising capabilities of the downscaling approach enabling effective increase of the spatial resolution of Landsat imageries by orders of 2 to 4. Specifically, the downscaling scheme retrieved the missing high-resolution feature of the imageries and reduced the root mean squared error by 15, 11, and 10 percent in visual, near infrared, and thermal infrared bands, respectively. This metric is reduced by 9% in the derived NDVI and remains negligibly for the soil moisture products.},
DOI = {10.3390/s17092106}
}



@Article{s17092123,
AUTHOR = {Wang, Jingbin and Wang, Xiaohong and Wang, Lizhi},
TITLE = {Modeling of BN Lifetime Prediction of a System Based on Integrated Multi-Level Information},
JOURNAL = {Sensors},
VOLUME = {17},
YEAR = {2017},
NUMBER = {9},
ARTICLE-NUMBER = {2123},
URL = {https://www.mdpi.com/1424-8220/17/9/2123},
ISSN = {1424-8220},
ABSTRACT = {Predicting system lifetime is important to ensure safe and reliable operation of products, which requires integrated modeling based on multi-level, multi-sensor information. However, lifetime characteristics of equipment in a system are different and failure mechanisms are inter-coupled, which leads to complex logical correlations and the lack of a uniform lifetime measure. Based on a Bayesian network (BN), a lifetime prediction method for systems that combine multi-level sensor information is proposed. The method considers the correlation between accidental failures and degradation failure mechanisms, and achieves system modeling and lifetime prediction under complex logic correlations. This method is applied in the lifetime prediction of a multi-level solar-powered unmanned system, and the predicted results can provide guidance for the improvement of system reliability and for the maintenance and protection of the system.},
DOI = {10.3390/s17092123}
}



@Article{rs9090961,
AUTHOR = {Espinoza, Carlos Zúñiga and Khot, Lav R. and Sankaran, Sindhuja and Jacoby, Pete W.},
TITLE = {High Resolution Multispectral and Thermal Remote Sensing-Based Water Stress Assessment in Subsurface Irrigated Grapevines},
JOURNAL = {Remote Sensing},
VOLUME = {9},
YEAR = {2017},
NUMBER = {9},
ARTICLE-NUMBER = {961},
URL = {https://www.mdpi.com/2072-4292/9/9/961},
ISSN = {2072-4292},
ABSTRACT = {Precision irrigation management is based on the accuracy and feasibility of sensor data assessing the plant water status. Multispectral and thermal infrared images acquired from an unmanned aerial vehicle (UAV) were analyzed to evaluate the applicability of the data in the assessment of variants of subsurface irrigation configurations. The study was carried out in a Cabernet Sauvignon orchard located near Benton City, Washington. Plants were subsurface irrigated at a 30, 60, and 90 cm depth, with 15%, 30%, and 60% irrigation of the standard irrigation level as determined by the grower in commercial production management. Half of the plots were irrigated using pulse irrigation and the other half using continuous irrigation techniques. The treatments were compared to the control plots that received standard surface irrigation at a continuous rate. The results showed differences in fruit yield when the control was compared to deficit irrigated treatments (15%, 30%, 60% of standard irrigation), while no differences were found for comparisons of the techniques (pulse, continuous) or depths of irrigation (30, 60, 90 cm). Leaf stomatal conductance of control and 60% irrigation treatments were statistically different compared to treatments receiving 30% and 15% irrigation. The normalized difference vegetation index (NDVI), green normalized difference vegetation index (GNDVI), and canopy temperature were correlated to fruit yield and leaf stomatal conductance. Significant correlations (p &lt; 0.01) were observed between NDVI, GNDVI, and canopy temperature with fruit yield (Pearson’s correlation coefficient, r = 0.68, 0.73, and −0.83, respectively), and with leaf stomatal conductance (r = 0.56, 0.65, and −0.63, respectively) at 44 days before harvest. This study demonstrates the potential of using low-altitude multispectral and thermal imagery data in the assessment of irrigation techniques and relative degree of plant water stress. In addition, results provide a feasibility analysis of our hypothesis that thermal infrared images can be used as a rapid tool to estimate leaf stomatal conductance, indicative of the spatial variation in the vineyard. This is critically important, as such data will provide a near real-time crop stress assessment for better irrigation management/scheduling in wine grape production.},
DOI = {10.3390/rs9090961}
}



@Article{s17102173,
AUTHOR = {Ribeiro-Gomes, Krishna and Hernández-López, David and Ortega, José F. and Ballesteros, Rocío and Poblete, Tomás and Moreno, Miguel A.},
TITLE = {Uncooled Thermal Camera Calibration and Optimization of the Photogrammetry Process for UAV Applications in Agriculture},
JOURNAL = {Sensors},
VOLUME = {17},
YEAR = {2017},
NUMBER = {10},
ARTICLE-NUMBER = {2173},
URL = {https://www.mdpi.com/1424-8220/17/10/2173},
ISSN = {1424-8220},
ABSTRACT = {The acquisition, processing, and interpretation of thermal images from unmanned aerial vehicles (UAVs) is becoming a useful source of information for agronomic applications because of the higher temporal and spatial resolution of these products compared with those obtained from satellites. However, due to the low load capacity of the UAV they need to mount light, uncooled thermal cameras, where the microbolometer is not stabilized to a constant temperature. This makes the camera precision low for many applications. Additionally, the low contrast of the thermal images makes the photogrammetry process inaccurate, which result in large errors in the generation of orthoimages. In this research, we propose the use of new calibration algorithms, based on neural networks, which consider the sensor temperature and the digital response of the microbolometer as input data. In addition, we evaluate the use of the Wallis filter for improving the quality of the photogrammetry process using structure from motion software. With the proposed calibration algorithm, the measurement accuracy increased from 3.55 °C with the original camera configuration to 1.37 °C. The implementation of the Wallis filter increases the number of tie-point from 58,000 to 110,000 and decreases the total positing error from 7.1 m to 1.3 m.},
DOI = {10.3390/s17102173}
}



@Article{s17102210,
AUTHOR = {Rivas Casado, Mónica and González, Rocío Ballesteros and Ortega, José Fernando and Leinster, Paul and Wright, Ros},
TITLE = {Towards a Transferable UAV-Based Framework for River Hydromorphological Characterization},
JOURNAL = {Sensors},
VOLUME = {17},
YEAR = {2017},
NUMBER = {10},
ARTICLE-NUMBER = {2210},
URL = {https://www.mdpi.com/1424-8220/17/10/2210},
ISSN = {1424-8220},
ABSTRACT = {The multiple protocols that have been developed to characterize river hydromorphology, partly in response to legislative drivers such as the European Union Water Framework Directive (EU WFD), make the comparison of results obtained in different countries challenging. Recent studies have analyzed the comparability of existing methods, with remote sensing based approaches being proposed as a potential means of harmonizing hydromorphological characterization protocols. However, the resolution achieved by remote sensing products may not be sufficient to assess some of the key hydromorphological features that are required to allow an accurate characterization. Methodologies based on high resolution aerial photography taken from Unmanned Aerial Vehicles (UAVs) have been proposed by several authors as potential approaches to overcome these limitations. Here, we explore the applicability of an existing UAV based framework for hydromorphological characterization to three different fluvial settings representing some of the distinct ecoregions defined by the WFD geographical intercalibration groups (GIGs). The framework is based on the automated recognition of hydromorphological features via tested and validated Artificial Neural Networks (ANNs). Results show that the framework is transferable to the Central-Baltic and Mediterranean GIGs with accuracies in feature identification above 70%. Accuracies of 50% are achieved when the framework is implemented in the Very Large Rivers GIG. The framework successfully identified vegetation, deep water, shallow water, riffles, side bars and shadows for the majority of the reaches. However, further algorithm development is required to ensure a wider range of features (e.g., chutes, structures and erosion) are accurately identified. This study also highlights the need to develop an objective and fit for purpose hydromorphological characterization framework to be adopted within all EU member states to facilitate comparison of results.},
DOI = {10.3390/s17102210}
}



@Article{s17102307,
AUTHOR = {Tamouridou, Afroditi A. and Alexandridis, Thomas K. and Pantazi, Xanthoula E. and Lagopodi, Anastasia L. and Kashefi, Javid and Kasampalis, Dimitris and Kontouris, Georgios and Moshou, Dimitrios},
TITLE = {Application of Multilayer Perceptron with Automatic Relevance Determination on Weed Mapping Using UAV Multispectral Imagery},
JOURNAL = {Sensors},
VOLUME = {17},
YEAR = {2017},
NUMBER = {10},
ARTICLE-NUMBER = {2307},
URL = {https://www.mdpi.com/1424-8220/17/10/2307},
ISSN = {1424-8220},
ABSTRACT = {Remote sensing techniques are routinely used in plant species discrimination and of weed mapping. In the presented work, successful Silybum marianum detection and mapping using multilayer neural networks is demonstrated. A multispectral camera (green-red-near infrared) attached on a fixed wing unmanned aerial vehicle (UAV) was utilized for the acquisition of high-resolution images (0.1 m resolution). The Multilayer Perceptron with Automatic Relevance Determination (MLP-ARD) was used to identify the S. marianum among other vegetation, mostly Avena sterilis L. The three spectral bands of Red, Green, Near Infrared (NIR) and the texture layer resulting from local variance were used as input. The S. marianum identification rates using MLP-ARD reached an accuracy of 99.54%. Τhe study had an one year duration, meaning that the results are specific, although the accuracy shows the interesting potential of S. marianum mapping with MLP-ARD on multispectral UAV imagery.},
DOI = {10.3390/s17102307}
}



@Article{robotics6040028,
AUTHOR = {Recoskie, Steven and Lanteigne, Eric and Gueaieb, Wail},
TITLE = {A High-Fidelity Energy Efficient Path Planner for Unmanned Airships},
JOURNAL = {Robotics},
VOLUME = {6},
YEAR = {2017},
NUMBER = {4},
ARTICLE-NUMBER = {28},
URL = {https://www.mdpi.com/2218-6581/6/4/28},
ISSN = {2218-6581},
ABSTRACT = {This paper presents a comparative study on the effects of grid resolution, vehicle velocity, and wind vector fields on the trajectory planning of unmanned airships. A wavefront expansion trajectory planner that minimizes a multi-objective cost function consisting of flight time, energy consumption, and collision avoidance while respecting the differential constraints of the vehicle is presented. Trajectories are generated using a variety of test environments and flight conditions to demonstrate that the inclusion of a high terrain map resolution, a temporal vehicle velocity, and a spatial wind vector field yields significant improvements in trajectory feasibility and energy economy when compared to trajectories generated using only two of these three elements.},
DOI = {10.3390/robotics6040028}
}



@Article{jimaging3040047,
AUTHOR = {Ejofodomi, O’tega and Ofualagba, Godswill},
TITLE = {Detection and Classification of Land Crude Oil Spills Using Color Segmentation and Texture Analysis},
JOURNAL = {Journal of Imaging},
VOLUME = {3},
YEAR = {2017},
NUMBER = {4},
ARTICLE-NUMBER = {47},
URL = {https://www.mdpi.com/2313-433X/3/4/47},
ISSN = {2313-433X},
ABSTRACT = {Crude oil spills have negative consequences on the economy, environment, health and society in which they occur, and the severity of the consequences depends on how quickly these spills are detected once they begin. Several methods have been employed for spill detection, including real time remote surveillance by flying aircrafts with surveillance teams. Other methods employ various sensors, including visible sensors. This paper presents an algorithm to automatically detect the presence of crude oil spills in images acquired using visible light sensors. Images of crude oil spills used in the development of the algorithm were obtained from the Shell Petroleum Development Company (SPDC) Nigeria website The major steps of the detection algorithm are image preprocessing, crude oil color segmentation, sky elimination segmentation, Region of Interest (ROI) extraction, ROI texture feature extraction, and ROI texture feature analysis and classification. The algorithm was developed using 25 sample images containing crude oil spills and demonstrated a sensitivity of 92% and an FPI of 1.43. The algorithm was further tested on a set of 56 case images and demonstrated a sensitivity of 82% and an FPI of 0.66. This algorithm can be incorporated into spill detection systems that utilize visible sensors for early detection of crude oil spills.},
DOI = {10.3390/jimaging3040047}
}



@Article{rs9101067,
AUTHOR = {Hu, Zhongyang and Kuenzer, Claudia and Dietz, Andreas J. and Dech, Stefan},
TITLE = {The Potential of Earth Observation for the Analysis of Cold Region Land Surface Dynamics in Europe—A Review},
JOURNAL = {Remote Sensing},
VOLUME = {9},
YEAR = {2017},
NUMBER = {10},
ARTICLE-NUMBER = {1067},
URL = {https://www.mdpi.com/2072-4292/9/10/1067},
ISSN = {2072-4292},
ABSTRACT = {Cold regions affect global, regional and local climate; oftentimes they are relevant for water supply, host valuable ecosystems, and support human livelihood. They are thus eminently important for human society. In the context of ongoing climate change, monitoring and understanding cold region land surface dynamics is essential for environmental scientists, stakeholders and decision makers. However, the definition of cold regions remains inexplicit, and no up-to-date cold region maps or overarching spatial analyses exist. For example, Europe has densely populated cold regions, but hardly an article exists that provides a solid overview of Earth Observation (EO) based applications assessing cold region land surface dynamics in Europe. With this review article we aim at closing this gap by providing an overview of EO-based techniques for cold region observation in Europe, focusing on the dynamics of glaciers and snow. We present a novel spatial delineation of cold regions for Europe before analyzing the benefits and limitations of different EO sensor types and data processing methods for EO based cold region research. Furthermore, we identify research gaps and discuss challenges for future studies.},
DOI = {10.3390/rs9101067}
}



@Article{s17112472,
AUTHOR = {Bakr, Muhammad Abu and Lee, Sukhan},
TITLE = {Distributed Multisensor Data Fusion under Unknown Correlation and Data Inconsistency},
JOURNAL = {Sensors},
VOLUME = {17},
YEAR = {2017},
NUMBER = {11},
ARTICLE-NUMBER = {2472},
URL = {https://www.mdpi.com/1424-8220/17/11/2472},
ISSN = {1424-8220},
ABSTRACT = {The paradigm of multisensor data fusion has been evolved from a centralized architecture to a decentralized or distributed architecture along with the advancement in sensor and communication technologies. These days, distributed state estimation and data fusion has been widely explored in diverse fields of engineering and control due to its superior performance over the centralized one in terms of flexibility, robustness to failure and cost effectiveness in infrastructure and communication. However, distributed multisensor data fusion is not without technical challenges to overcome: namely, dealing with cross-correlation and inconsistency among state estimates and sensor data. In this paper, we review the key theories and methodologies of distributed multisensor data fusion available to date with a specific focus on handling unknown correlation and data inconsistency. We aim at providing readers with a unifying view out of individual theories and methodologies by presenting a formal analysis of their implications. Finally, several directions of future research are highlighted.},
DOI = {10.3390/s17112472}
}



@Article{s17112488,
AUTHOR = {Poblete, Tomas and Ortega-Farías, Samuel and Moreno, Miguel Angel and Bardeen, Matthew},
TITLE = {Artificial Neural Network to Predict Vine Water Status Spatial Variability Using Multispectral Information Obtained from an Unmanned Aerial Vehicle (UAV)},
JOURNAL = {Sensors},
VOLUME = {17},
YEAR = {2017},
NUMBER = {11},
ARTICLE-NUMBER = {2488},
URL = {https://www.mdpi.com/1424-8220/17/11/2488},
ISSN = {1424-8220},
ABSTRACT = {Water stress, which affects yield and wine quality, is often evaluated using the midday stem water potential (Ψstem). However, this measurement is acquired on a per plant basis and does not account for the assessment of vine water status spatial variability. The use of multispectral cameras mounted on unmanned aerial vehicle (UAV) is capable to capture the variability of vine water stress in a whole field scenario. It has been reported that conventional multispectral indices (CMI) that use information between 500–800 nm, do not accurately predict plant water status since they are not sensitive to water content. The objective of this study was to develop artificial neural network (ANN) models derived from multispectral images to predict the Ψstem spatial variability of a drip-irrigated Carménère vineyard in Talca, Maule Region, Chile. The coefficient of determination (R2) obtained between ANN outputs and ground-truth measurements of Ψstem were between 0.56–0.87, with the best performance observed for the model that included the bands 550, 570, 670, 700 and 800 nm. Validation analysis indicated that the ANN model could estimate Ψstem with a mean absolute error (MAE) of 0.1 MPa, root mean square error (RMSE) of 0.12 MPa, and relative error (RE) of −9.1%. For the validation of the CMI, the MAE, RMSE and RE values were between 0.26–0.27 MPa, 0.32–0.34 MPa and −24.2–25.6%, respectively.},
DOI = {10.3390/s17112488}
}



@Article{rs9111112,
AUTHOR = {Lv, ZhiYong and Shi, WenZhong and Zhou, XiaoCheng and Benediktsson, Jón Atli},
TITLE = {Semi-Automatic System for Land Cover Change Detection Using Bi-Temporal Remote Sensing Images},
JOURNAL = {Remote Sensing},
VOLUME = {9},
YEAR = {2017},
NUMBER = {11},
ARTICLE-NUMBER = {1112},
URL = {https://www.mdpi.com/2072-4292/9/11/1112},
ISSN = {2072-4292},
ABSTRACT = {Change detection is an increasingly important research topic in remote sensing application. Previous studies achieved land cover change detection (LCCD) using bi-temporal remote sensing images. However, many widely used methods detected change depending on a series of parameters, and determining parameters is time-consuming. Furthermore, numerous methods are data-dependent. Therefore, their degree of automation should be improved significantly. Three techniques, which consist of a semi-automatic change detection system, are proposed for LCCD to overcome the abovementioned drawbacks. The three techniques are as follows: (1) change magnitude image (CMI) noise reduction is based on Gaussian filter (GF), which is coupled with OTSU for reducing CMI noise automatically using an iterative optimization strategy; (2) a method based on histogram curve fitting is suggested to predict the threshold range for parameter determination; and (3) a modified region growing algorithm is built for iteratively constructing the final change detection map. The detection accuracies of the proposed system are investigated through four experiments with different bi-temporal image scenes. Compared with several widely used change detection methods, the proposed system can be applied to detect land cover change with high accuracy and flexibility. This work is an attempt to provide a change detection system that is compatible with remote sensing images with high and median-low spatial resolution.},
DOI = {10.3390/rs9111112}
}



@Article{ijgi6110332,
AUTHOR = {Zhang, Hongyue and Huang, Mingrui and Qing, Xiuling and Li, Guoqing and Tian, Chuanzhao},
TITLE = {Bibliometric Analysis of Global Remote Sensing Research during 2010–2015},
JOURNAL = {ISPRS International Journal of Geo-Information},
VOLUME = {6},
YEAR = {2017},
NUMBER = {11},
ARTICLE-NUMBER = {332},
URL = {https://www.mdpi.com/2220-9964/6/11/332},
ISSN = {2220-9964},
ABSTRACT = {Bibliometric analysis based on the Science Citation Index Expanded published by Thomson Scientific was carried out to identify the research status and future trends of remote sensing (RS) during 2010–2015. The analysis revealed the institutional, national, spatio-temporal, and categorical patterns in remote sensing research both from the WP (whole publications) viewpoint and the HCP (highly-cited publications) viewpoint. Statistical analysis results showed that remote sensing research almost doubled during 2010–2015. Environmental sciences comprised the most attractive subject category among remote sensing research. The International Journal of Remote Sensing was the most productive journal, and Remote Sensing of Environment published the most HCP among the 31 distributed journals. The productive ranking of countries was led by the U.S. both from the WP viewpoint and the HCP viewpoint, and CAS (Chinese Academy of Sciences) was the most productive institute both from the WP viewpoint and the HCP viewpoint with lower CPP (average number of citations per paper). Keyword analysis illustrated that model and algorithm research were the key points in RS during 2010–2015. RS data including Moderate-Resolution Imaging Spectroradiometer (MODIS), Landsat, synthetic aperture radar (SAR), and LiDAR (light detection and ranging) were the most frequently adopted, but the data usage of UAVs (unmanned aerial vehicles) and small satellites will be promoted in the future. With the development of data acquisition abilities, big data issues will become the challenges and hotspots of RS research, and new algorithms will continue to emerge.},
DOI = {10.3390/ijgi6110332}
}



@Article{s17112545,
AUTHOR = {Alirezaie, Marjan and Kiselev, Andrey and Längkvist, Martin and Klügl, Franziska and Loutfi, Amy},
TITLE = {An Ontology-Based Reasoning Framework for Querying Satellite Images for Disaster Monitoring},
JOURNAL = {Sensors},
VOLUME = {17},
YEAR = {2017},
NUMBER = {11},
ARTICLE-NUMBER = {2545},
URL = {https://www.mdpi.com/1424-8220/17/11/2545},
ISSN = {1424-8220},
ABSTRACT = {This paper presents a framework in which satellite images are classified and augmented with additional semantic information to enable queries about what can be found on the map at a particular location, but also about paths that can be taken. This is achieved by a reasoning framework based on qualitative spatial reasoning that is able to find answers to high level queries that may vary on the current situation. This framework called SemCityMap, provides the full pipeline from enriching the raw image data with rudimentary labels to the integration of a knowledge representation and reasoning methods to user interfaces for high level querying. To illustrate the utility of SemCityMap in a disaster scenario, we use an urban environment—central Stockholm—in combination with a flood simulation. We show that the system provides useful answers to high-level queries also with respect to the current flood status. Examples of such queries concern path planning for vehicles or retrieval of safe regions such as “find all regions close to schools and far from the flooded area”. The particular advantage of our approach lies in the fact that ontological information and reasoning is explicitly integrated so that queries can be formulated in a natural way using concepts on appropriate level of abstraction, including additional constraints.},
DOI = {10.3390/s17112545}
}



@Article{s17112557,
AUTHOR = {Yamamoto, Kyosuke and Togami, Takashi and Yamaguchi, Norio},
TITLE = {Super-Resolution of Plant Disease Images for the Acceleration of Image-based Phenotyping and Vigor Diagnosis in Agriculture},
JOURNAL = {Sensors},
VOLUME = {17},
YEAR = {2017},
NUMBER = {11},
ARTICLE-NUMBER = {2557},
URL = {https://www.mdpi.com/1424-8220/17/11/2557},
ISSN = {1424-8220},
ABSTRACT = {Unmanned aerial vehicles (UAVs or drones) are a very promising branch of technology, and they have been utilized in agriculture—in cooperation with image processing technologies—for phenotyping and vigor diagnosis. One of the problems in the utilization of UAVs for agricultural purposes is the limitation in flight time. It is necessary to fly at a high altitude to capture the maximum number of plants in the limited time available, but this reduces the spatial resolution of the captured images. In this study, we applied a super-resolution method to the low-resolution images of tomato diseases to recover detailed appearances, such as lesions on plant organs. We also conducted disease classification using high-resolution, low-resolution, and super-resolution images to evaluate the effectiveness of super-resolution methods in disease classification. Our results indicated that the super-resolution method outperformed conventional image scaling methods in spatial resolution enhancement of tomato disease images. The results of disease classification showed that the accuracy attained was also better by a large margin with super-resolution images than with low-resolution images. These results indicated that our approach not only recovered the information lost in low-resolution images, but also exerted a beneficial influence on further image analysis. The proposed approach will accelerate image-based phenotyping and vigor diagnosis in the field, because it not only saves time to capture images of a crop in a cultivation field but also secures the accuracy of these images for further analysis.},
DOI = {10.3390/s17112557}
}



@Article{s17112555,
AUTHOR = {Zou, Tengyue and Wang, Yuanxia and Wang, Mengyi and Lin, Shouying},
TITLE = {A Real-Time Smooth Weighted Data Fusion Algorithm for Greenhouse Sensing Based on Wireless Sensor Networks},
JOURNAL = {Sensors},
VOLUME = {17},
YEAR = {2017},
NUMBER = {11},
ARTICLE-NUMBER = {2555},
URL = {https://www.mdpi.com/1424-8220/17/11/2555},
ISSN = {1424-8220},
ABSTRACT = {Wireless sensor networks are widely used to acquire environmental parameters to support agricultural production. However, data variation and noise caused by actuators often produce complex measurement conditions. These factors can lead to nonconformity in reporting samples from different nodes and cause errors when making a final decision. Data fusion is well suited to reduce the influence of actuator-based noise and improve automation accuracy. A key step is to identify the sensor nodes disturbed by actuator noise and reduce their degree of participation in the data fusion results. A smoothing value is introduced and a searching method based on Prim’s algorithm is designed to help obtain stable sensing data. A voting mechanism with dynamic weights is then proposed to obtain the data fusion result. The dynamic weighting process can sharply reduce the influence of actuator noise in data fusion and gradually condition the data to normal levels over time. To shorten the data fusion time in large networks, an acceleration method with prediction is also presented to reduce the data collection time. A real-time system is implemented on STMicroelectronics STM32F103 and NORDIC nRF24L01 platforms and the experimental results verify the improvement provided by these new algorithms.},
DOI = {10.3390/s17112555}
}



@Article{rs9111166,
AUTHOR = {Li, Chang and Ma, Yong and Mei, Xiaoguang and Fan, Fan and Huang, Jun and Ma, Jiayi},
TITLE = {Sparse Unmixing of Hyperspectral Data with Noise Level Estimation},
JOURNAL = {Remote Sensing},
VOLUME = {9},
YEAR = {2017},
NUMBER = {11},
ARTICLE-NUMBER = {1166},
URL = {https://www.mdpi.com/2072-4292/9/11/1166},
ISSN = {2072-4292},
ABSTRACT = {Recently, sparse unmixing has received particular attention in the analysis of hyperspectral images (HSIs). However, traditional sparse unmixing ignores the different noise levels in different bands of HSIs, making such methods sensitive to different noise levels. To overcome this problem, the noise levels at different bands are assumed to be different in this paper, and a general sparse unmixing method based on noise level estimation (SU-NLE) under the sparse regression framework is proposed. First, the noise in each band is estimated on the basis of the multiple regression theory in hyperspectral applications, given that neighboring spectral bands are usually highly correlated. Second, the noise weighting matrix can be obtained from the estimated noise. Third, the noise weighting matrix is integrated into the sparse regression unmixing framework, which can alleviate the impact of different noise levels at different bands. Finally, the proposed SU-NLE is solved by the alternative direction method of multipliers. Experiments on synthetic datasets show that the signal-to-reconstruction error of the proposed SU-NLE is considerably higher than those of the corresponding traditional sparse regression unmixing methods without noise level estimation, which demonstrates the efficiency of integrating noise level estimation into the sparse regression unmixing framework. The proposed SU-NLE also shows promising results in real HSIs.},
DOI = {10.3390/rs9111166}
}



@Article{rs9111170,
AUTHOR = {Tang, Tianyu and Zhou, Shilin and Deng, Zhipeng and Lei, Lin and Zou, Huanxin},
TITLE = {Arbitrary-Oriented Vehicle Detection in Aerial Imagery with Single Convolutional Neural Networks},
JOURNAL = {Remote Sensing},
VOLUME = {9},
YEAR = {2017},
NUMBER = {11},
ARTICLE-NUMBER = {1170},
URL = {https://www.mdpi.com/2072-4292/9/11/1170},
ISSN = {2072-4292},
ABSTRACT = {Vehicle detection with orientation estimation in aerial images has received widespread interest as it is important for intelligent traffic management. This is a challenging task, not only because of the complex background and relatively small size of the target, but also the various orientations of vehicles in aerial images captured from the top view. The existing methods for oriented vehicle detection need several post-processing steps to generate final detection results with orientation, which are not efficient enough. Moreover, they can only get discrete orientation information for each target. In this paper, we present an end-to-end single convolutional neural network to generate arbitrarily-oriented detection results directly. Our approach, named Oriented_SSD (Single Shot MultiBox Detector, SSD), uses a set of default boxes with various scales on each feature map location to produce detection bounding boxes. Meanwhile, offsets are predicted for each default box to better match the object shape, which contain the angle parameter for oriented bounding boxes’ generation. Evaluation results on the public DLR Vehicle Aerial dataset and Vehicle Detection in Aerial Imagery (VEDAI) dataset demonstrate that our method can detect both the location and orientation of the vehicle with high accuracy and fast speed. For test images in the DLR Vehicle Aerial dataset with a size of     5616 × 3744    , our method achieves 76.1% average precision (AP) and 78.7% correct direction classification at 5.17 s on an NVIDIA GTX-1060.},
DOI = {10.3390/rs9111170}
}



@Article{s17112641,
AUTHOR = {Malek, Salim and Melgani, Farid and Mekhalfi, Mohamed Lamine and Bazi, Yakoub},
TITLE = {Real-Time Indoor Scene Description for the Visually Impaired Using Autoencoder Fusion Strategies with Visible Cameras},
JOURNAL = {Sensors},
VOLUME = {17},
YEAR = {2017},
NUMBER = {11},
ARTICLE-NUMBER = {2641},
URL = {https://www.mdpi.com/1424-8220/17/11/2641},
ISSN = {1424-8220},
ABSTRACT = {This paper describes three coarse image description strategies, which are meant to promote a rough perception of surrounding objects for visually impaired individuals, with application to indoor spaces. The described algorithms operate on images (grabbed by the user, by means of a chest-mounted camera), and provide in output a list of objects that likely exist in his context across the indoor scene. In this regard, first, different colour, texture, and shape-based feature extractors are generated, followed by a feature learning step by means of AutoEncoder (AE) models. Second, the produced features are fused and fed into a multilabel classifier in order to list the potential objects. The conducted experiments point out that fusing a set of AE-learned features scores higher classification rates with respect to using the features individually. Furthermore, with respect to reference works, our method: (i) yields higher classification accuracies, and (ii) runs (at least four times) faster, which enables a potential full real-time application.},
DOI = {10.3390/s17112641}
}



@Article{s17112666,
AUTHOR = {Fresno, José Manuel and Robles, Guillermo and Martínez-Tarifa, Juan Manuel and Stewart, Brian G.},
TITLE = {Survey on the Performance of Source Localization Algorithms},
JOURNAL = {Sensors},
VOLUME = {17},
YEAR = {2017},
NUMBER = {11},
ARTICLE-NUMBER = {2666},
URL = {https://www.mdpi.com/1424-8220/17/11/2666},
ISSN = {1424-8220},
ABSTRACT = {The localization of emitters using an array of sensors or antennas is a prevalent issue approached in several applications. There exist different techniques for source localization, which can be classified into multilateration, received signal strength (RSS) and proximity methods. The performance of multilateration techniques relies on measured time variables: the time of flight (ToF) of the emission from the emitter to the sensor, the time differences of arrival (TDoA) of the emission between sensors and the pseudo-time of flight (pToF) of the emission to the sensors. The multilateration algorithms presented and compared in this paper can be classified as iterative and non-iterative methods. Both standard least squares (SLS) and hyperbolic least squares (HLS) are iterative and based on the Newton–Raphson technique to solve the non-linear equation system. The metaheuristic technique particle swarm optimization (PSO) used for source localisation is also studied. This optimization technique estimates the source position as the optimum of an objective function based on HLS and is also iterative in nature. Three non-iterative algorithms, namely the hyperbolic positioning algorithms (HPA), the maximum likelihood estimator (MLE) and Bancroft algorithm, are also presented. A non-iterative combined algorithm, MLE-HLS, based on MLE and HLS, is further proposed in this paper. The performance of all algorithms is analysed and compared in terms of accuracy in the localization of the position of the emitter and in terms of computational time. The analysis is also undertaken with three different sensor layouts since the positions of the sensors affect the localization; several source positions are also evaluated to make the comparison more robust. The analysis is carried out using theoretical time differences, as well as including errors due to the effect of digital sampling of the time variables. It is shown that the most balanced algorithm, yielding better results than the other algorithms in terms of accuracy and short computational time, is the combined MLE-HLS algorithm.},
DOI = {10.3390/s17112666}
}



@Article{rs9111198,
AUTHOR = {Cai, Bowen and Jiang, Zhiguo and Zhang, Haopeng and Zhao, Danpei and Yao, Yuan},
TITLE = {Airport Detection Using End-to-End Convolutional Neural Network with Hard Example Mining},
JOURNAL = {Remote Sensing},
VOLUME = {9},
YEAR = {2017},
NUMBER = {11},
ARTICLE-NUMBER = {1198},
URL = {https://www.mdpi.com/2072-4292/9/11/1198},
ISSN = {2072-4292},
ABSTRACT = {Deep convolutional neural network (CNN) achieves outstanding performance in the field of target detection. As one of the most typical targets in remote sensing images (RSIs), airport has attracted increasing attention in recent years. However, the essential challenge for using deep CNN to detect airport is the great imbalance between the number of airports and background examples in large-scale RSIs, which may lead to over-fitting. In this paper, we develop a hard example mining and weight-balanced strategy to construct a novel end-to-end convolutional neural network for airport detection. The initial motivation of the proposed method is that backgrounds contain an overwhelming number of easy examples and a few hard examples. Therefore, we design a hard example mining layer to automatically select hard examples by their losses, and implement a new weight-balanced loss function to optimize CNN. Meanwhile, the cascade design of proposal extraction and object detection in our network releases the constraint on input image size and reduces spurious false positives. Compared with geometric characteristics and low-level manually designed features, the hard example mining based network could extract high-level features, which is more robust for airport detection in complex environment. The proposed method is validated on a multi-scale dataset with complex background collected from Google Earth. The experimental results demonstrate that our proposed method is robust, and superior to the state-of-the-art airport detection models.},
DOI = {10.3390/rs9111198}
}



@Article{mi8110340,
AUTHOR = {Yang, Hai and Li, Wei and Luo, Tao and Liang, Haibo and Zhang, He and Gu, Yaxiong and Luo, Chengming},
TITLE = {Research on the Strategy of Motion Constraint-Aided ZUPT for the SINS Positioning System of a Shearer},
JOURNAL = {Micromachines},
VOLUME = {8},
YEAR = {2017},
NUMBER = {11},
ARTICLE-NUMBER = {340},
URL = {https://www.mdpi.com/2072-666X/8/11/340},
PubMedID = {30400529},
ISSN = {2072-666X},
ABSTRACT = {The accurate measurement of position and orientation for shearers is a key technology in realizing an automated, fully-mechanized, coal mining face. Since Global Positioning System (GPS) signal cannot arrive at the coal mine underground, wireless sensor network positioning system cannot operate stably in the coal mine; thus a strap-down inertial navigation system (SINS) is used to measure the position and orientation of the shearer. Aiming at the problem of the SINS accumulative error, this paper proposes a positioning error correction method based on the motion constraint-aided SINS zero velocity updated (ZUPT) model. First of all, a stationary state detection model of the shearer is built with median filter based on the acceleration and angular rate measured by the SINS. Secondly, the motion of the shearer is analyzed using coal mining technology, then the motion constraint model of the shearer is established. In addition, the alternate action between the motion constraint model and the ZUPT model is analyzed at the process of movement and cessation of the shearer, respectively; hence, the motion constraint-aided SINS ZUPT model is built. Finally, by means of the experimental platform of the SINS for the shearer, the experimental results show that the maximum position error with the positioning model proposed in this paper is 1.6 m in 180 s, and increases by 92.0% and 88.1% compared with the single motion constraint model and single ZUPT model, respectively. It can then restrain the accumulative error of the SINS effectively.},
DOI = {10.3390/mi8110340}
}



@Article{s17122720,
AUTHOR = {Zhong, Jiandan and Lei, Tao and Yao, Guangle},
TITLE = {Robust Vehicle Detection in Aerial Images Based on Cascaded Convolutional Neural Networks},
JOURNAL = {Sensors},
VOLUME = {17},
YEAR = {2017},
NUMBER = {12},
ARTICLE-NUMBER = {2720},
URL = {https://www.mdpi.com/1424-8220/17/12/2720},
ISSN = {1424-8220},
ABSTRACT = {Vehicle detection in aerial images is an important and challenging task. Traditionally, many target detection models based on sliding-window fashion were developed and achieved acceptable performance, but these models are time-consuming in the detection phase. Recently, with the great success of convolutional neural networks (CNNs) in computer vision, many state-of-the-art detectors have been designed based on deep CNNs. However, these CNN-based detectors are inefficient when applied in aerial image data due to the fact that the existing CNN-based models struggle with small-size object detection and precise localization. To improve the detection accuracy without decreasing speed, we propose a CNN-based detection model combining two independent convolutional neural networks, where the first network is applied to generate a set of vehicle-like regions from multi-feature maps of different hierarchies and scales. Because the multi-feature maps combine the advantage of the deep and shallow convolutional layer, the first network performs well on locating the small targets in aerial image data. Then, the generated candidate regions are fed into the second network for feature extraction and decision making. Comprehensive experiments are conducted on the Vehicle Detection in Aerial Imagery (VEDAI) dataset and Munich vehicle dataset. The proposed cascaded detection model yields high performance, not only in detection accuracy but also in detection speed.},
DOI = {10.3390/s17122720}
}



@Article{s17122726,
AUTHOR = {Su, Jinya and Yi, Dewei and Liu, Cunjia and Guo, Lei and Chen, Wen-Hua},
TITLE = {Dimension Reduction Aided Hyperspectral Image Classification with a Small-sized Training Dataset: Experimental Comparisons},
JOURNAL = {Sensors},
VOLUME = {17},
YEAR = {2017},
NUMBER = {12},
ARTICLE-NUMBER = {2726},
URL = {https://www.mdpi.com/1424-8220/17/12/2726},
ISSN = {1424-8220},
ABSTRACT = {Hyperspectral images (HSI) provide rich information which may not be captured by other sensing technologies and therefore gradually find a wide range of applications. However, they also generate a large amount of irrelevant or redundant data for a specific task. This causes a number of issues including significantly increased computation time, complexity and scale of prediction models mapping the data to semantics (e.g., classification), and the need of a large amount of labelled data for training. Particularly, it is generally difficult and expensive for experts to acquire sufficient training samples in many applications. This paper addresses these issues by exploring a number of classical dimension reduction algorithms in machine learning communities for HSI classification. To reduce the size of training dataset, feature selection (e.g., mutual information, minimal redundancy maximal relevance) and feature extraction (e.g., Principal Component Analysis (PCA), Kernel PCA) are adopted to augment a baseline classification method, Support Vector Machine (SVM). The proposed algorithms are evaluated using a real HSI dataset. It is shown that PCA yields the most promising performance in reducing the number of features or spectral bands. It is observed that while significantly reducing the computational complexity, the proposed method can achieve better classification results over the classic SVM on a small training dataset, which makes it suitable for real-time applications or when only limited training data are available. Furthermore, it can also achieve performances similar to the classic SVM on large datasets but with much less computing time.},
DOI = {10.3390/s17122726}
}



@Article{rs9121220,
AUTHOR = {Guirado, Emilio and Tabik, Siham and Alcaraz-Segura, Domingo and Cabello, Javier and Herrera, Francisco},
TITLE = {Deep-learning Versus OBIA for Scattered Shrub Detection with Google Earth Imagery: Ziziphus lotus as Case Study},
JOURNAL = {Remote Sensing},
VOLUME = {9},
YEAR = {2017},
NUMBER = {12},
ARTICLE-NUMBER = {1220},
URL = {https://www.mdpi.com/2072-4292/9/12/1220},
ISSN = {2072-4292},
ABSTRACT = {There is a growing demand for accurate high-resolution land cover maps in many fields, e.g., in land-use planning and biodiversity conservation. Developing such maps has been traditionally performed using Object-Based Image Analysis (OBIA) methods, which usually reach good accuracies, but require a high human supervision and the best configuration for one image often cannot be extrapolated to a different image. Recently, deep learning Convolutional Neural Networks (CNNs) have shown outstanding results in object recognition in computer vision and are offering promising results in land cover mapping. This paper analyzes the potential of CNN-based methods for detection of plant species of conservation concern using free high-resolution Google Earth     TM     images and provides an objective comparison with the state-of-the-art OBIA-methods. We consider as case study the detection of Ziziphus lotus shrubs, which are protected as a priority habitat under the European Union Habitats Directive. Compared to the best performing OBIA-method, the best CNN-detector achieved up to 12% better precision, up to 30% better recall and up to 20% better balance between precision and recall. Besides, the knowledge that CNNs acquired in the first image can be re-utilized in other regions, which makes the detection process very fast. A natural conclusion of this work is that including CNN-models as classifiers, e.g., ResNet-classifier, could further improve OBIA methods. The provided methodology can be systematically reproduced for other species detection using our codes available through (https://github.com/EGuirado/CNN-remotesensing).},
DOI = {10.3390/rs9121220}
}



@Article{s17122742,
AUTHOR = {Zhang, Wei and Wei, Shilin and Teng, Yanbin and Zhang, Jianku and Wang, Xiufang and Yan, Zheping},
TITLE = {Dynamic Obstacle Avoidance for Unmanned Underwater Vehicles Based on an Improved Velocity Obstacle Method},
JOURNAL = {Sensors},
VOLUME = {17},
YEAR = {2017},
NUMBER = {12},
ARTICLE-NUMBER = {2742},
URL = {https://www.mdpi.com/1424-8220/17/12/2742},
ISSN = {1424-8220},
ABSTRACT = {In view of a dynamic obstacle environment with motion uncertainty, we present a dynamic collision avoidance method based on the collision risk assessment and improved velocity obstacle method. First, through the fusion optimization of forward-looking sonar data, the redundancy of the data is reduced and the position, size and velocity information of the obstacles are obtained, which can provide an accurate decision-making basis for next-step collision avoidance. Second, according to minimum meeting time and the minimum distance between the obstacle and unmanned underwater vehicle (UUV), this paper establishes the collision risk assessment model, and screens key obstacles to avoid collision. Finally, the optimization objective function is established based on the improved velocity obstacle method, and a UUV motion characteristic is used to calculate the reachable velocity sets. The optimal collision speed of UUV is searched in velocity space. The corresponding heading and speed commands are calculated, and outputted to the motion control module. The above is the complete dynamic obstacle avoidance process. The simulation results show that the proposed method can obtain a better collision avoidance effect in the dynamic environment, and has good adaptability to the unknown dynamic environment.},
DOI = {10.3390/s17122742}
}



@Article{rs9121244,
AUTHOR = {Chen, Suting and Li, Xin and Zhang, Yanyan and Feng, Rui and Zhang, Chuang},
TITLE = {Local Deep Hashing Matching of Aerial Images Based on Relative Distance and Absolute Distance Constraints},
JOURNAL = {Remote Sensing},
VOLUME = {9},
YEAR = {2017},
NUMBER = {12},
ARTICLE-NUMBER = {1244},
URL = {https://www.mdpi.com/2072-4292/9/12/1244},
ISSN = {2072-4292},
ABSTRACT = {Aerial images have features of high resolution, complex background, and usually require large amounts of calculation, however, most algorithms used in matching of aerial images adopt the shallow hand-crafted features expressed as floating-point descriptors (e.g., SIFT (Scale-invariant Feature Transform), SURF (Speeded Up Robust Features)), which may suffer from poor matching speed and are not well represented in the literature. Here, we propose a novel Local Deep Hashing Matching (LDHM) method for matching of aerial images with large size and with lower complexity or fast matching speed. The basic idea of the proposed algorithm is to utilize the deep network model in the local area of the aerial images, and study the local features, as well as the hash function of the images. Firstly, according to the course overlap rate of aerial images, the algorithm extracts the local areas for matching to avoid the processing of redundant information. Secondly, a triplet network structure is proposed to mine the deep features of the patches of the local image, and the learned features are imported to the hash layer, thus obtaining the representation of a binary hash code. Thirdly, the constraints of the positive samples to the absolute distance are added on the basis of the triplet loss, a new objective function is constructed to optimize the parameters of the network and enhance the discriminating capabilities of image patch features. Finally, the obtained deep hash code of each image patch is used for the similarity comparison of the image patches in the Hamming space to complete the matching of aerial images. The proposed LDHM algorithm evaluates the UltraCam-D dataset and a set of actual aerial images, simulation result demonstrates that it may significantly outperform the state-of-the-art algorithm in terms of the efficiency and performance.},
DOI = {10.3390/rs9121244}
}



@Article{s17122869,
AUTHOR = {Huang, Shiping and Wu, Zhifeng and Misra, Anil},
TITLE = {A Practical, Robust and Fast Method for Location Localization in Range-Based Systems},
JOURNAL = {Sensors},
VOLUME = {17},
YEAR = {2017},
NUMBER = {12},
ARTICLE-NUMBER = {2869},
URL = {https://www.mdpi.com/1424-8220/17/12/2869},
ISSN = {1424-8220},
ABSTRACT = {Location localization technology is used in a number of industrial and civil applications. Real time location localization accuracy is highly dependent on the quality of the distance measurements and efficiency of solving the localization equations. In this paper, we provide a novel approach to solve the nonlinear localization equations efficiently and simultaneously eliminate the bad measurement data in range-based systems. A geometric intersection model was developed to narrow the target search area, where Newton’s Method and the Direct Search Method are used to search for the unknown position. Not only does the geometric intersection model offer a small bounded search domain for Newton’s Method and the Direct Search Method, but also it can self-correct bad measurement data. The Direct Search Method is useful for the coarse localization or small target search domain, while the Newton’s Method can be used for accurate localization. For accurate localization, by utilizing the proposed Modified Newton’s Method (MNM), challenges of avoiding the local extrema, singularities, and initial value choice are addressed. The applicability and robustness of the developed method has been demonstrated by experiments with an indoor system.},
DOI = {10.3390/s17122869}
}



@Article{rs9121332,
AUTHOR = {Liang, Hui and Huang, Xiaodong and Sun, Yanhua and Wang, Yunlong and Liang, Tiangang},
TITLE = {Fractional Snow-Cover Mapping Based on MODIS and UAV Data over the Tibetan Plateau},
JOURNAL = {Remote Sensing},
VOLUME = {9},
YEAR = {2017},
NUMBER = {12},
ARTICLE-NUMBER = {1332},
URL = {https://www.mdpi.com/2072-4292/9/12/1332},
ISSN = {2072-4292},
ABSTRACT = {Moderate-resolution imaging spectroradiometer (MODIS) snow-cover products have relatively low accuracy over the Tibetan Plateau because of its complex terrain and shallow, fragmented snow cover. In this study, fractional snow-cover (FSC) mapping algorithms were developed using a linear regression model (LR), a linear spectral mixture analysis model (LSMA) and a back-propagation artificial neural network model (BP-ANN) based on MODIS data (version 006) and unmanned aerial vehicle (UAV) data. The accuracies of the three models were validated against Landsat 8 Operational Land Imager (OLI) snow-cover maps (Landsat 8 FSC) and compared with the MODIS global FSC product (MOD10A1 FSC, version 005) for the purpose of finding the optimal algorithm for FSC extraction for the Tibetan Plateau. The results showed that (1) the overall retrieval results of the LR and BP-ANN models based on MODIS and UAV data were relatively similar to the OLI snow-cover maps; the accuracy and stability were greatly improved, with even some reduction in errors; compared to the Landsat 8 FSC, the correlation coefficients (r) were 0.8222 and 0.8445 respectively and the root-mean-square errors (RMSEs) were 0.2304 and 0.2201, respectively. (2) The accuracy and stability of the fully constrained LSMA model using the pixel purity index (PPI) endmember extraction method based only on MODIS data suffered the worst performance of the three models; r was only 0.7921 and the RMSE was as large as 0.3485. There were some serious omission phenomena in the study area, specifically for the largest mean absolute error (MAE = 0.2755) and positive mean error (PME = 0.3411). (3) The accuracy of the MOD10A1 FSC product was much lower than that of the LR and BP-ANN models, although its accuracy slightly better that of the LSMA based on comprehensive evaluation of six accuracy indices. (4) The optimal model was the BP-ANN model with combined inputs of surface reflectivity data (R1–R7), elevation (DEM) and temperature (LST), which can easily incorporate auxiliary information (DEM and LST) on the basis of (R1–R7) during the relationship training period and can effectively improve the accuracy of snow area monitoring—it is the ideal algorithm for retrieving FSC for the Tibetan Plateau.},
DOI = {10.3390/rs9121332}
}



@Article{rs10010002,
AUTHOR = {Weinmann, Martin and Weinmann, Michael},
TITLE = {Geospatial Computer Vision Based on Multi-Modal Data—How Valuable Is Shape Information for the Extraction of Semantic Information?},
JOURNAL = {Remote Sensing},
VOLUME = {10},
YEAR = {2018},
NUMBER = {1},
ARTICLE-NUMBER = {2},
URL = {https://www.mdpi.com/2072-4292/10/1/2},
ISSN = {2072-4292},
ABSTRACT = {In this paper, we investigate the value of different modalities and their combination for the analysis of geospatial data of low spatial resolution. For this purpose, we present a framework that allows for the enrichment of geospatial data with additional semantics based on given color information, hyperspectral information, and shape information. While the different types of information are used to define a variety of features, classification based on these features is performed using a random forest classifier. To draw conclusions about the relevance of different modalities and their combination for scene analysis, we present and discuss results which have been achieved with our framework on the MUUFL Gulfport Hyperspectral and LiDAR Airborne Data Set.},
DOI = {10.3390/rs10010002}
}



@Article{s18010018,
AUTHOR = {Thanh Noi, Phan and Kappas, Martin},
TITLE = {Comparison of Random Forest, k-Nearest Neighbor, and Support Vector Machine Classifiers for Land Cover Classification Using Sentinel-2 Imagery},
JOURNAL = {Sensors},
VOLUME = {18},
YEAR = {2018},
NUMBER = {1},
ARTICLE-NUMBER = {18},
URL = {https://www.mdpi.com/1424-8220/18/1/18},
ISSN = {1424-8220},
ABSTRACT = {In previous classification studies, three non-parametric classifiers, Random Forest (RF), k-Nearest Neighbor (kNN), and Support Vector Machine (SVM), were reported as the foremost classifiers at producing high accuracies. However, only a few studies have compared the performances of these classifiers with different training sample sizes for the same remote sensing images, particularly the Sentinel-2 Multispectral Imager (MSI). In this study, we examined and compared the performances of the RF, kNN, and SVM classifiers for land use/cover classification using Sentinel-2 image data. An area of 30 × 30 km2 within the Red River Delta of Vietnam with six land use/cover types was classified using 14 different training sample sizes, including balanced and imbalanced, from 50 to over 1250 pixels/class. All classification results showed a high overall accuracy (OA) ranging from 90% to 95%. Among the three classifiers and 14 sub-datasets, SVM produced the highest OA with the least sensitivity to the training sample sizes, followed consecutively by RF and kNN. In relation to the sample size, all three classifiers showed a similar and high OA (over 93.85%) when the training sample size was large enough, i.e., greater than 750 pixels/class or representing an area of approximately 0.25% of the total study area. The high accuracy was achieved with both imbalanced and balanced datasets.},
DOI = {10.3390/s18010018}
}



@Article{rs10010024,
AUTHOR = {Pádua, Luís and Hruška, Jonáš and Bessa, José and Adão, Telmo and Martins, Luís M. and Gonçalves, José A. and Peres, Emanuel and Sousa, António M. R. and Castro, João P. and Sousa, Joaquim J.},
TITLE = {Multi-Temporal Analysis of Forestry and Coastal Environments Using UASs},
JOURNAL = {Remote Sensing},
VOLUME = {10},
YEAR = {2018},
NUMBER = {1},
ARTICLE-NUMBER = {24},
URL = {https://www.mdpi.com/2072-4292/10/1/24},
ISSN = {2072-4292},
ABSTRACT = {Due to strong improvements and developments achieved in the last decade, it is clear that applied research using remote sensing technology such as unmanned aerial vehicles (UAVs) can provide a flexible, efficient, non-destructive, and non-invasive means of acquiring geoscientific data, especially aerial imagery. Simultaneously, there has been an exponential increase in the development of sensors and instruments that can be installed in UAV platforms. By combining the aforementioned factors, unmanned aerial system (UAS) setups composed of UAVs, sensors, and ground control stations, have been increasingly used for remote sensing applications, with growing potential and abilities. This paper’s overall goal is to identify advantages and challenges related to the use of UAVs for aerial imagery acquisition in forestry and coastal environments for preservation/prevention contexts. Moreover, the importance of monitoring these environments over time will be demonstrated. To achieve these goals, two case studies using UASs were conducted. The first focuses on phytosanitary problem detection and monitoring of chestnut tree health (Padrela region, Valpaços, Portugal). The acquired high-resolution imagery allowed for the identification of tree canopy cover decline by means of multi-temporal analysis. The second case study enabled the rigorous and non-evasive registry process of topographic changes that occurred in the sandspit of Cabedelo (Douro estuary, Porto, Portugal) in different time periods. The obtained results allow us to conclude that the UAS constitutes a low-cost, rigorous, and fairly autonomous form of remote sensing technology, capable of covering large geographical areas and acquiring high precision data to aid decision support systems in forestry preservation and coastal monitoring applications. Its swift evolution makes it a potential big player in remote sensing technologies today and in the near future.},
DOI = {10.3390/rs10010024}
}



@Article{rs10010075,
AUTHOR = {Ji, Shunping and Zhang, Chi and Xu, Anjian and Shi, Yun and Duan, Yulin},
TITLE = {3D Convolutional Neural Networks for Crop Classification with Multi-Temporal Remote Sensing Images},
JOURNAL = {Remote Sensing},
VOLUME = {10},
YEAR = {2018},
NUMBER = {1},
ARTICLE-NUMBER = {75},
URL = {https://www.mdpi.com/2072-4292/10/1/75},
ISSN = {2072-4292},
ABSTRACT = {This study describes a novel three-dimensional (3D) convolutional neural networks (CNN) based method that automatically classifies crops from spatio-temporal remote sensing images. First, 3D kernel is designed according to the structure of multi-spectral multi-temporal remote sensing data. Secondly, the 3D CNN framework with fine-tuned parameters is designed for training 3D crop samples and learning spatio-temporal discriminative representations, with the full crop growth cycles being preserved. In addition, we introduce an active learning strategy to the CNN model to improve labelling accuracy up to a required threshold with the most efficiency. Finally, experiments are carried out to test the advantage of the 3D CNN, in comparison to the two-dimensional (2D) CNN and other conventional methods. Our experiments show that the 3D CNN is especially suitable in characterizing the dynamics of crop growth and outperformed the other mainstream methods.},
DOI = {10.3390/rs10010075}
}



@Article{s18010156,
AUTHOR = {Li, Hongguang and Shi, Yang and Zhang, Baochang and Wang, Yufeng},
TITLE = {Superpixel-Based Feature for Aerial Image Scene Recognition},
JOURNAL = {Sensors},
VOLUME = {18},
YEAR = {2018},
NUMBER = {1},
ARTICLE-NUMBER = {156},
URL = {https://www.mdpi.com/1424-8220/18/1/156},
ISSN = {1424-8220},
ABSTRACT = {Image scene recognition is a core technology for many aerial remote sensing applications. Different landforms are inputted as different scenes in aerial imaging, and all landform information is regarded as valuable for aerial image scene recognition. However, the conventional features of the Bag-of-Words model are designed using local points or other related information and thus are unable to fully describe landform areas. This limitation cannot be ignored when the aim is to ensure accurate aerial scene recognition. A novel superpixel-based feature is proposed in this study to characterize aerial image scenes. Then, based on the proposed feature, a scene recognition method of the Bag-of-Words model for aerial imaging is designed. The proposed superpixel-based feature that utilizes landform information establishes top-task superpixel extraction of landforms to bottom-task expression of feature vectors. This characterization technique comprises the following steps: simple linear iterative clustering based superpixel segmentation, adaptive filter bank construction, Lie group-based feature quantification, and visual saliency model-based feature weighting. Experiments of image scene recognition are carried out using real image data captured by an unmanned aerial vehicle (UAV). The recognition accuracy of the proposed superpixel-based feature is 95.1%, which is higher than those of scene recognition algorithms based on other local features.},
DOI = {10.3390/s18010156}
}



@Article{electronics7010006,
AUTHOR = {Shah, Namin and Czarkowski, Dariusz},
TITLE = {Supercapacitors in Tandem with Batteries to Prolong the Range of UGV Systems},
JOURNAL = {Electronics},
VOLUME = {7},
YEAR = {2018},
NUMBER = {1},
ARTICLE-NUMBER = {6},
URL = {https://www.mdpi.com/2079-9292/7/1/6},
ISSN = {2079-9292},
ABSTRACT = {The purpose of this study was to explore a novel approach to power hybridization in relation to its effectiveness in an unmanned ground vehicle (UGV). This hybridization method is modeled after the power distribution methods found in living organisms, which utilize glycogen stores and adipose tissue to optimize power and energy density strengths and weaknesses. A UGV rover was constructed with an appropriate distribution of power storage elements creating separate power buffers. The primary buffer consisted of a 10 W solar panel array and a 600 F, 5.4 V supercapacitor bank, and the secondary buffer consisted of a 3.7 V 6 Ah lithium-ion battery pack. The primary buffer provided virtually limitless charge cycles with a superior power density juxtaposed with a secondary buffer that provided superior energy density and volumetric versatility. The design of this rover is presented in this paper; it was tested under manual and autonomous modes. The rover was found to be capable of effectively operating solely on the primary power buffer in high to low luminous conditions while being able to carry out basic extravehicular activities. The rover could travel roughly 22 km without any input power on a full charge of both buffers, and could smoothly switch between its own power buffers during operation, all while transmitting live first person video (FPV) and network data. The introduction of control algorithms on the onboard microcontroller unit (MCU) was also explored in both manual and autonomous configurations. The latter integrated linear regression to intelligently manage power and locomotion based on sensory data from photoresistors.},
DOI = {10.3390/electronics7010006}
}



@Article{plants7010003,
AUTHOR = {Li, Bo and Lecourt, Julien and Bishop, Gerard},
TITLE = {Advances in Non-Destructive Early Assessment of Fruit Ripeness towards Defining Optimal Time of Harvest and Yield Prediction—A Review},
JOURNAL = {Plants},
VOLUME = {7},
YEAR = {2018},
NUMBER = {1},
ARTICLE-NUMBER = {3},
URL = {https://www.mdpi.com/2223-7747/7/1/3},
PubMedID = {29320410},
ISSN = {2223-7747},
ABSTRACT = {Global food security for the increasing world population not only requires increased sustainable production of food but a significant reduction in pre- and post-harvest waste. The timing of when a fruit is harvested is critical for reducing waste along the supply chain and increasing fruit quality for consumers. The early in-field assessment of fruit ripeness and prediction of the harvest date and yield by non-destructive technologies have the potential to revolutionize farming practices and enable the consumer to eat the tastiest and freshest fruit possible. A variety of non-destructive techniques have been applied to estimate the ripeness or maturity but not all of them are applicable for in situ (field or glasshouse) assessment. This review focuses on the non-destructive methods which are promising for, or have already been applied to, the pre-harvest in-field measurements including colorimetry, visible imaging, spectroscopy and spectroscopic imaging. Machine learning and regression models used in assessing ripeness are also discussed.},
DOI = {10.3390/plants7010003}
}



@Article{rs10010085,
AUTHOR = {Berger, Katja and Atzberger, Clement and Danner, Martin and D’Urso, Guido and Mauser, Wolfram and Vuolo, Francesco and Hank, Tobias},
TITLE = {Evaluation of the PROSAIL Model Capabilities for Future Hyperspectral Model Environments: A Review Study},
JOURNAL = {Remote Sensing},
VOLUME = {10},
YEAR = {2018},
NUMBER = {1},
ARTICLE-NUMBER = {85},
URL = {https://www.mdpi.com/2072-4292/10/1/85},
ISSN = {2072-4292},
ABSTRACT = {Upcoming satellite hyperspectral sensors require powerful and robust methodologies for making optimum use of the rich spectral data. This paper reviews the widely applied coupled PROSPECT and SAIL radiative transfer models (PROSAIL), regarding their suitability for the retrieval of biophysical and biochemical variables in the context of agricultural crop monitoring. Evaluation was carried out using a systematic literature review of 281 scientific publications with regard to their (i) spectral exploitation, (ii) vegetation type analyzed, (iii) variables retrieved, and (iv) choice of retrieval methods. From the analysis, current trends were derived, and problems identified and discussed. Our analysis clearly shows that the PROSAIL model is well suited for the analysis of imaging spectrometer data from future satellite missions and that the model should be integrated in appropriate software tools that are being developed in this context for agricultural applications. The review supports the decision of potential users to employ PROSAIL for their specific data analysis and provides guidelines for choosing between the diverse retrieval techniques.},
DOI = {10.3390/rs10010085}
}



@Article{rs10010072,
AUTHOR = {Kim, Sungho and Song, Woo-Jin and Kim, So-Hyun},
TITLE = {Double Weight-Based SAR and Infrared Sensor Fusion for Automatic Ground Target Recognition with Deep Learning},
JOURNAL = {Remote Sensing},
VOLUME = {10},
YEAR = {2018},
NUMBER = {1},
ARTICLE-NUMBER = {72},
URL = {https://www.mdpi.com/2072-4292/10/1/72},
ISSN = {2072-4292},
ABSTRACT = {This paper presents a novel double weight-based synthetic aperture radar (SAR) and infrared (IR) sensor fusion method (DW-SIF) for automatic ground target recognition (ATR). IR-based ATR can provide accurate recognition because of its high image resolution but it is affected by the weather conditions. On the other hand, SAR-based ATR shows a low recognition rate due to the noisy low resolution but can provide consistent performance regardless of the weather conditions. The fusion of an active sensor (SAR) and a passive sensor (IR) can lead to upgraded performance. This paper proposes a doubly weighted neural network fusion scheme at the decision level. The first weight (   α   ) can measure the offline sensor confidence per target category based on the classification rate for an evaluation set. The second weight (   β   ) can measure the online sensor reliability based on the score distribution for a test target image. The LeNet architecture-based deep convolution network (14 layers) is used as an individual classifier. Doubly weighted sensor scores are fused by two types of fusion schemes, such as the sum-based linear fusion scheme (    α β    -sum) and neural network-based nonlinear fusion scheme (    α β    -NN). The experimental results confirmed the proposed linear fusion method (    α β    -sum) to have the best performance among the linear fusion schemes available (SAR-CNN, IR-CNN,    α   -sum,    β   -sum,     α β    -sum, and Bayesian fusion). In addition, the proposed nonlinear fusion method (    α β    -NN) showed superior target recognition performance to linear fusion on the OKTAL-SE-based synthetic database.},
DOI = {10.3390/rs10010072}
}



@Article{rs10010099,
AUTHOR = {Bégué, Agnès and Arvor, Damien and Bellon, Beatriz and Betbeder, Julie and De Abelleyra, Diego and P. D. Ferraz, Rodrigo and Lebourgeois, Valentine and Lelong, Camille and Simões, Margareth and R. Verón, Santiago},
TITLE = {Remote Sensing and Cropping Practices: A Review},
JOURNAL = {Remote Sensing},
VOLUME = {10},
YEAR = {2018},
NUMBER = {1},
ARTICLE-NUMBER = {99},
URL = {https://www.mdpi.com/2072-4292/10/1/99},
ISSN = {2072-4292},
ABSTRACT = {For agronomic, environmental, and economic reasons, the need for spatialized information about agricultural practices is expected to rapidly increase. In this context, we reviewed the literature on remote sensing for mapping cropping practices. The reviewed studies were grouped into three categories of practices: crop succession (crop rotation and fallowing), cropping pattern (single tree crop planting pattern, sequential cropping, and intercropping/agroforestry), and cropping techniques (irrigation, soil tillage, harvest and post-harvest practices, crop varieties, and agro-ecological infrastructures). We observed that the majority of the studies were exploratory investigations, tested on a local scale with a high dependence on ground data, and used only one type of remote sensing sensor. Furthermore, to be correctly implemented, most of the methods relied heavily on local knowledge on the management practices, the environment, and the biological material. These limitations point to future research directions, such as the use of land stratification, multi-sensor data combination, and expert knowledge-driven methods. Finally, the new spatial technologies, and particularly the Sentinel constellation, are expected to improve the monitoring of cropping practices in the challenging context of food security and better management of agro-environmental issues.},
DOI = {10.3390/rs10010099}
}



@Article{s18010206,
AUTHOR = {Shen, Jieliang and Su, Yan and Liang, Qing and Zhu, Xinhua},
TITLE = {Calculation and Identification of the Aerodynamic Parameters for Small-Scaled Fixed-Wing UAVs},
JOURNAL = {Sensors},
VOLUME = {18},
YEAR = {2018},
NUMBER = {1},
ARTICLE-NUMBER = {206},
URL = {https://www.mdpi.com/1424-8220/18/1/206},
ISSN = {1424-8220},
ABSTRACT = {The establishment of the Aircraft Dynamic Model (ADM) constitutes the prerequisite for the design of the navigation and control system, but the aerodynamic parameters in the model could not be readily obtained especially for small-scaled fixed-wing UAVs. In this paper, the procedure of computing the aerodynamic parameters is developed. All the longitudinal and lateral aerodynamic derivatives are firstly calculated through semi-empirical method based on the aerodynamics, rather than the wind tunnel tests or fluid dynamics software analysis. Secondly, the residuals of each derivative are proposed to be identified or estimated further via Extended Kalman Filter(EKF), with the observations of the attitude and velocity from the airborne integrated navigation system. Meanwhile, the observability of the targeted parameters is analyzed and strengthened through multiple maneuvers. Based on a small-scaled fixed-wing aircraft driven by propeller, the airborne sensors are chosen and the model of the actuators are constructed. Then, real flight tests are implemented to verify the calculation and identification process. Test results tell the rationality of the semi-empirical method and show the improvement of accuracy of ADM after the compensation of the parameters.},
DOI = {10.3390/s18010206}
}



@Article{ijgi7020039,
AUTHOR = {Feng, Yu and Sester, Monika},
TITLE = {Extraction of Pluvial Flood Relevant Volunteered Geographic Information (VGI) by Deep Learning from User Generated Texts and Photos},
JOURNAL = {ISPRS International Journal of Geo-Information},
VOLUME = {7},
YEAR = {2018},
NUMBER = {2},
ARTICLE-NUMBER = {39},
URL = {https://www.mdpi.com/2220-9964/7/2/39},
ISSN = {2220-9964},
ABSTRACT = {In recent years, pluvial floods caused by extreme rainfall events have occurred frequently. Especially in urban areas, they lead to serious damages and endanger the citizens’ safety. Therefore, real-time information about such events is desirable. With the increasing popularity of social media platforms, such as Twitter or Instagram, information provided by voluntary users becomes a valuable source for emergency response. Many applications have been built for disaster detection and flood mapping using crowdsourcing. Most of the applications so far have merely used keyword filtering or classical language processing methods to identify disaster relevant documents based on user generated texts. As the reliability of social media information is often under criticism, the precision of information retrieval plays a significant role for further analyses. Thus, in this paper, high quality eyewitnesses of rainfall and flooding events are retrieved from social media by applying deep learning approaches on user generated texts and photos. Subsequently, events are detected through spatiotemporal clustering and visualized together with these high quality eyewitnesses in a web map application. Analyses and case studies are conducted during flooding events in Paris, London and Berlin.},
DOI = {10.3390/ijgi7020039}
}



@Article{s18020374,
AUTHOR = {Velazquez-Pupo, Roxana and Sierra-Romero, Alberto and Torres-Roman, Deni and Shkvarko, Yuriy V. and Santiago-Paz, Jayro and Gómez-Gutiérrez, David and Robles-Valdez, Daniel and Hermosillo-Reynoso, Fernando and Romero-Delgado, Misael},
TITLE = {Vehicle Detection with Occlusion Handling, Tracking, and OC-SVM Classification: A High Performance Vision-Based System},
JOURNAL = {Sensors},
VOLUME = {18},
YEAR = {2018},
NUMBER = {2},
ARTICLE-NUMBER = {374},
URL = {https://www.mdpi.com/1424-8220/18/2/374},
ISSN = {1424-8220},
ABSTRACT = {This paper presents a high performance vision-based system with a single static camera for traffic surveillance, for moving vehicle detection with occlusion handling, tracking, counting, and One Class Support Vector Machine (OC-SVM) classification. In this approach, moving objects are first segmented from the background using the adaptive Gaussian Mixture Model (GMM). After that, several geometric features are extracted, such as vehicle area, height, width, centroid, and bounding box. As occlusion is present, an algorithm was implemented to reduce it. The tracking is performed with adaptive Kalman filter. Finally, the selected geometric features: estimated area, height, and width are used by different classifiers in order to sort vehicles into three classes: small, midsize, and large. Extensive experimental results in eight real traffic videos with more than 4000 ground truth vehicles have shown that the improved system can run in real time under an occlusion index of 0.312 and classify vehicles with a global detection rate or recall, precision, and F-measure of up to 98.190%, and an F-measure of up to 99.051% for midsize vehicles.},
DOI = {10.3390/s18020374}
}



@Article{rs10020202,
AUTHOR = {Loggenberg, Kyle and Strever, Albert and Greyling, Berno and Poona, Nitesh},
TITLE = {Modelling Water Stress in a Shiraz Vineyard Using Hyperspectral Imaging and Machine Learning},
JOURNAL = {Remote Sensing},
VOLUME = {10},
YEAR = {2018},
NUMBER = {2},
ARTICLE-NUMBER = {202},
URL = {https://www.mdpi.com/2072-4292/10/2/202},
ISSN = {2072-4292},
ABSTRACT = {The detection of water stress in vineyards plays an integral role in the sustainability of high-quality grapes and prevention of devastating crop loses. Hyperspectral remote sensing technologies combined with machine learning provides a practical means for modelling vineyard water stress. In this study, we applied two ensemble learners, i.e., random forest (RF) and extreme gradient boosting (XGBoost), for discriminating stressed and non-stressed Shiraz vines using terrestrial hyperspectral imaging. Additionally, we evaluated the utility of a spectral subset of wavebands, derived using RF mean decrease accuracy (MDA) and XGBoost gain. Our results show that both ensemble learners can effectively analyse the hyperspectral data. When using all wavebands (p = 176), RF produced a test accuracy of 83.3% (KHAT (kappa analysis) = 0.67), and XGBoost a test accuracy of 80.0% (KHAT = 0.6). Using the subset of wavebands (p = 18) produced slight increases in accuracy ranging from 1.7% to 5.5% for both RF and XGBoost. We further investigated the effect of smoothing the spectral data using the Savitzky-Golay filter. The results indicated that the Savitzky-Golay filter reduced model accuracies (ranging from 0.7% to 3.3%). The results demonstrate the feasibility of terrestrial hyperspectral imagery and machine learning to create a semi-automated framework for vineyard water stress modelling.},
DOI = {10.3390/rs10020202}
}



@Article{s18020397,
AUTHOR = {Poblete, Tomas and Ortega-Farías, Samuel and Ryu, Dongryeol},
TITLE = {Automatic Coregistration Algorithm to Remove Canopy Shaded Pixels in UAV-Borne Thermal Images to Improve the Estimation of Crop Water Stress Index of a Drip-Irrigated Cabernet Sauvignon Vineyard},
JOURNAL = {Sensors},
VOLUME = {18},
YEAR = {2018},
NUMBER = {2},
ARTICLE-NUMBER = {397},
URL = {https://www.mdpi.com/1424-8220/18/2/397},
ISSN = {1424-8220},
ABSTRACT = {Water stress caused by water scarcity has a negative impact on the wine industry. Several strategies have been implemented for optimizing water application in vineyards. In this regard, midday stem water potential (SWP) and thermal infrared (TIR) imaging for crop water stress index (CWSI) have been used to assess plant water stress on a vine-by-vine basis without considering the spatial variability. Unmanned Aerial Vehicle (UAV)-borne TIR images are used to assess the canopy temperature variability within vineyards that can be related to the vine water status. Nevertheless, when aerial TIR images are captured over canopy, internal shadow canopy pixels cannot be detected, leading to mixed information that negatively impacts the relationship between CWSI and SWP. This study proposes a methodology for automatic coregistration of thermal and multispectral images (ranging between 490 and 900 nm) obtained from a UAV to remove shadow canopy pixels using a modified scale invariant feature transformation (SIFT) computer vision algorithm and Kmeans++ clustering. Our results indicate that our proposed methodology improves the relationship between CWSI and SWP when shadow canopy pixels are removed from a drip-irrigated Cabernet Sauvignon vineyard. In particular, the coefficient of determination (R2) increased from 0.64 to 0.77. In addition, values of the root mean square error (RMSE) and standard error (SE) decreased from 0.2 to 0.1 MPa and 0.24 to 0.16 MPa, respectively. Finally, this study shows that the negative effect of shadow canopy pixels was higher in those vines with water stress compared with well-watered vines.},
DOI = {10.3390/s18020397}
}



@Article{rs10020220,
AUTHOR = {Kycko, Marlena and Zagajewski, Bogdan and Lavender, Samantha and Romanowska, Elżbieta and Zwijacz-Kozica, Magdalena},
TITLE = {The Impact of Tourist Traffic on the Condition and Cell Structures of Alpine Swards},
JOURNAL = {Remote Sensing},
VOLUME = {10},
YEAR = {2018},
NUMBER = {2},
ARTICLE-NUMBER = {220},
URL = {https://www.mdpi.com/2072-4292/10/2/220},
ISSN = {2072-4292},
ABSTRACT = {This research focuses on the effect of trampling on vegetation in high-mountain ecosystems through the electromagnetic spectrum’s interaction with plant pigments, cell structure, water content and other substances that have a direct impact on leaf properties. The aim of the study was to confirm with the use of fluorescence methods of variability in the state of high-mountain vegetation previously measured spectrometrically. The most heavily visited part of the High Tatras in Poland was divided into polygons and, after selecting the dominant species within alpine swards, a detailed analysis of trampled and reference patterns was performed. The Analytical Spectral Devices (ASD) FieldSpec 3/4 were used to acquire high-resolution spectral properties of plants, their fluorescence and the leaf chlorophyll content with the difference between the plant surface temperature (ts), and the air temperature (ta) as well as fraction of Absorbed Photosynthetically Active Radiation (fAPAR) used as reference data. The results show that, along tourist trails, vegetation adapts to trampling with the impact depending on the species. A lower chlorophyll value was confirmed by a decrease in fluorescence, and the cellular structures were degraded in trampled compared to reference species, with a lower leaf reflectance. In addition, at the extreme, trampling can eliminate certain species such as Luzula alpino-pilosa, for which significant changes were noted due to trampling.},
DOI = {10.3390/rs10020220}
}



@Article{s18020548,
AUTHOR = {Li, Jincheng and Chen, Jie and Wang, Pengbo and Li, Chunsheng},
TITLE = {Sensor-Oriented Path Planning for Multiregion Surveillance with a Single Lightweight UAV SAR},
JOURNAL = {Sensors},
VOLUME = {18},
YEAR = {2018},
NUMBER = {2},
ARTICLE-NUMBER = {548},
URL = {https://www.mdpi.com/1424-8220/18/2/548},
ISSN = {1424-8220},
ABSTRACT = {In the surveillance of interested regions by unmanned aerial vehicle (UAV), system performance relies greatly on the motion control strategy of the UAV and the operation characteristics of the onboard sensors. This paper investigates the 2D path planning problem for the lightweight UAV synthetic aperture radar (SAR) system in an environment of multiple regions of interest (ROIs), the sizes of which are comparable to the radar swath width. Taking into account the special requirements of the SAR system on the motion of the platform, we model path planning for UAV SAR as a constrained multiobjective optimization problem (MOP). Based on the fact that the UAV route can be designed in the map image, an image-based path planner is proposed in this paper. First, the neighboring ROIs are merged by the morphological operation. Then, the parts of routes for data collection of the ROIs can be located according to the geometric features of the ROIs and the observation geometry of UAV SAR. Lastly, the route segments for ROIs surveillance are connected by a path planning algorithm named the sampling-based sparse A* search (SSAS) algorithm. Simulation experiments in real scenarios demonstrate that the proposed sensor-oriented path planner can improve the reconnaissance performance of lightweight UAV SAR greatly compared with the conventional zigzag path planner.},
DOI = {10.3390/s18020548}
}



@Article{rs10020285,
AUTHOR = {De Castro, Ana I. and Torres-Sánchez, Jorge and Peña, Jose M. and Jiménez-Brenes, Francisco M. and Csillik, Ovidiu and López-Granados, Francisca},
TITLE = {An Automatic Random Forest-OBIA Algorithm for Early Weed Mapping between and within Crop Rows Using UAV Imagery},
JOURNAL = {Remote Sensing},
VOLUME = {10},
YEAR = {2018},
NUMBER = {2},
ARTICLE-NUMBER = {285},
URL = {https://www.mdpi.com/2072-4292/10/2/285},
ISSN = {2072-4292},
ABSTRACT = {Accurate and timely detection of weeds between and within crop rows in the early growth stage is considered one of the main challenges in site-specific weed management (SSWM). In this context, a robust and innovative automatic object-based image analysis (OBIA) algorithm was developed on Unmanned Aerial Vehicle (UAV) images to design early post-emergence prescription maps. This novel algorithm makes the major contribution. The OBIA algorithm combined Digital Surface Models (DSMs), orthomosaics and machine learning techniques (Random Forest, RF). OBIA-based plant heights were accurately estimated and used as a feature in the automatic sample selection by the RF classifier; this was the second research contribution. RF randomly selected a class balanced training set, obtained the optimum features values and classified the image, requiring no manual training, making this procedure time-efficient and more accurate, since it removes errors due to a subjective manual task. The ability to discriminate weeds was significantly affected by the imagery spatial resolution and weed density, making the use of higher spatial resolution images more suitable. Finally, prescription maps for in-season post-emergence SSWM were created based on the weed maps—the third research contribution—which could help farmers in decision-making to optimize crop management by rationalization of the herbicide application. The short time involved in the process (image capture and analysis) would allow timely weed control during critical periods, crucial for preventing yield loss.},
DOI = {10.3390/rs10020285}
}



@Article{drones2010007,
AUTHOR = {Mueller, Markus S. and Jutzi, Boris},
TITLE = {UAS Navigation with SqueezePoseNet—Accuracy Boosting for Pose Regression by Data Augmentation},
JOURNAL = {Drones},
VOLUME = {2},
YEAR = {2018},
NUMBER = {1},
ARTICLE-NUMBER = {7},
URL = {https://www.mdpi.com/2504-446X/2/1/7},
ISSN = {2504-446X},
ABSTRACT = {The navigation of Unmanned Aerial Vehicles (UAVs) nowadays is mostly based on Global Navigation Satellite Systems (GNSSs). Drawbacks of satellite-based navigation are failures caused by occlusions or multi-path interferences. Therefore, alternative methods have been developed in recent years. Visual navigation methods such as Visual Odometry (VO) or visual Simultaneous Localization and Mapping (SLAM) aid global navigation solutions by closing trajectory gaps or performing loop closures. However, if the trajectory estimation is interrupted or not available, a re-localization is mandatory. Furthermore, the latest research has shown promising results on pose regression in 6 Degrees of Freedom (DoF) based on Convolutional Neural Networks (CNNs). Additionally, existing navigation methods can benefit from these networks. In this article, a method for GNSS-free and fast image-based pose regression by utilizing a small Convolutional Neural Network is presented. Therefore, a small CNN (SqueezePoseNet) is utilized, transfer learning is applied and the network is tuned for pose regression. Furthermore, recent drawbacks are overcome by applying data augmentation on a training dataset utilizing simulated images. Experiments with small CNNs show promising results for GNSS-free and fast localization compared to larger networks. By training a CNN with an extended data set including simulated images, the accuracy on pose regression is improved up to 61.7% for position and up to 76.0% for rotation compared to training on a standard not-augmented data set.},
DOI = {10.3390/drones2010007}
}



@Article{pr6020018,
AUTHOR = {Stan, Marius and Pana, Ion and Minescu, Mihail and Ichim, Adonis and Teodoriu, Catalin},
TITLE = {Centrifugal Pump Monitoring and Determination of Pump Characteristic Curves Using Experimental and Analytical Solutions},
JOURNAL = {Processes},
VOLUME = {6},
YEAR = {2018},
NUMBER = {2},
ARTICLE-NUMBER = {18},
URL = {https://www.mdpi.com/2227-9717/6/2/18},
ISSN = {2227-9717},
ABSTRACT = {Centrifugal pumps are widely used in the industry, especially in the oil and gas sector for fluids transport. Classically, these are designed to transfer single phase fluids (e.g., water) at high flow rates and relatively low pressures when compared with other pump types. As part of their constructive feature, centrifugal pumps rely on seals to prevent air entrapment into the rotor during its normal operation. Although this is a constructive feature, water should pass through the pump inlet even when the inlet manifold is damaged. Modern pumps are integrated in pumping units which consist of a drive (normally electric motor), a transmission (when needed), an electronic package (for monitoring and control), and the pump itself. The unit also has intake and outlet manifolds equipped with valves. Modern systems also include electronic components to measure and monitor pump working parameters such as pressure, temperature, etc. Equipment monitoring devices (vibration sensors, microphones) are installed on modern pumping units to help users evaluate the state of the machinery and detect deviations from the normal working condition. This paper addresses the influence of air-water two-phase mixture on the characteristic curve of a centrifugal pump; pump vibration in operation at various flow rates under these conditions; the possibilities of using the results of experimental investigations in the numerical simulations for design and training purposes, and the possibility of using vibration and sound analysis to detect changes in the equipment working condition. Conclusions show that vibration analysis provides accurate information about the pump’s functional state and the pumping process. Moreover, the acoustic emission also enables the evaluation of the pump status, but needs further improvements to better capture and isolate the usable sounds from the environment.},
DOI = {10.3390/pr6020018}
}



@Article{a11020023,
AUTHOR = {Dai, Hou-Ping and Chen, Dong-Dong and Zheng, Zhou-Shun},
TITLE = {Effects of Random Values for Particle Swarm Optimization Algorithm},
JOURNAL = {Algorithms},
VOLUME = {11},
YEAR = {2018},
NUMBER = {2},
ARTICLE-NUMBER = {23},
URL = {https://www.mdpi.com/1999-4893/11/2/23},
ISSN = {1999-4893},
ABSTRACT = {Particle swarm optimization (PSO) algorithm is generally improved by adaptively adjusting the inertia weight or combining with other evolution algorithms. However, in most modified PSO algorithms, the random values are always generated by uniform distribution in the range of [0, 1]. In this study, the random values, which are generated by uniform distribution in the ranges of [0, 1] and [−1, 1], and Gauss distribution with mean 0 and variance 1 (
          
            
              
                U
                
                  [
                  
                    0
                    ,
                    1
                  
                  ]
                
              
            
          
        , 
      
        
          
            U
            
              [
              
                −
                1
                ,
                1
              
              ]
            
          
        
      
     and 
      
        
          
            G
            (
            0
            ,
            1
            )
          
        
      
    ), are respectively used in the standard PSO and linear decreasing inertia weight (LDIW) PSO algorithms. For comparison, the deterministic PSO algorithm, in which the random values are set as 0.5, is also investigated in this study. Some benchmark functions and the pressure vessel design problem are selected to test these algorithms with different types of random values in three space dimensions (10, 30, and 100). The experimental results show that the standard PSO and LDIW-PSO algorithms with random values generated by 
      
        
          
            U
            
              [
              
                −
                1
                ,
                1
              
              ]
            
          
        
      
     or 
      
        
          
            G
            (
            0
            ,
            1
            )
          
        
      
     are more likely to avoid falling into local optima and quickly obtain the global optima. This is because the large-scale random values can expand the range of particle velocity to make the particle more likely to escape from local optima and obtain the global optima. Although the random values generated by 
      
        
          
            U
            
              [
              
                −
                1
                ,
                1
              
              ]
            
          
        
      
     or 
      
        
          
            G
            (
            0
            ,
            1
            )
          
        
      
     are beneficial to improve the global searching ability, the local searching ability for a low dimensional practical optimization problem may be decreased due to the finite particles.},
DOI = {10.3390/a11020023}
}



@Article{ijgi7020065,
AUTHOR = {Yang, Liping and MacEachren, Alan M. and Mitra, Prasenjit and Onorati, Teresa},
TITLE = {Visually-Enabled Active Deep Learning for (Geo) Text and Image Classification: A Review},
JOURNAL = {ISPRS International Journal of Geo-Information},
VOLUME = {7},
YEAR = {2018},
NUMBER = {2},
ARTICLE-NUMBER = {65},
URL = {https://www.mdpi.com/2220-9964/7/2/65},
ISSN = {2220-9964},
ABSTRACT = {This paper investigates recent research on active learning for (geo) text and image classification, with an emphasis on methods that combine visual analytics and/or deep learning. Deep learning has attracted substantial attention across many domains of science and practice, because it can find intricate patterns in big data; but successful application of the methods requires a big set of labeled data. Active learning, which has the potential to address the data labeling challenge, has already had success in geospatial applications such as trajectory classification from movement data and (geo) text and image classification. This review is intended to be particularly relevant for extension of these methods to GISience, to support work in domains such as geographic information retrieval from text and image repositories, interpretation of spatial language, and related geo-semantics challenges. Specifically, to provide a structure for leveraging recent advances, we group the relevant work into five categories: active learning, visual analytics, active learning with visual analytics, active deep learning, plus GIScience and Remote Sensing (RS) using active learning and active deep learning. Each category is exemplified by recent influential work. Based on this framing and our systematic review of key research, we then discuss some of the main challenges of integrating active learning with visual analytics and deep learning, and point out research opportunities from technical and application perspectives—for application-based opportunities, with emphasis on those that address big data with geospatial components.},
DOI = {10.3390/ijgi7020065}
}



@Article{rs10020320,
AUTHOR = {Meng, Baoping and Gao, Jinlong and Liang, Tiangang and Cui, Xia and Ge, Jing and Yin, Jianpeng and Feng, Qisheng and Xie, Hongjie},
TITLE = {Modeling of Alpine Grassland Cover Based on Unmanned Aerial Vehicle Technology and Multi-Factor Methods: A Case Study in the East of Tibetan Plateau, China},
JOURNAL = {Remote Sensing},
VOLUME = {10},
YEAR = {2018},
NUMBER = {2},
ARTICLE-NUMBER = {320},
URL = {https://www.mdpi.com/2072-4292/10/2/320},
ISSN = {2072-4292},
ABSTRACT = {Grassland cover and its temporal changes are key parameters in the estimation and monitoring of ecosystems and their functions, especially via remote sensing. However, the most suitable model for estimating grassland cover and the differences between models has rarely been studied in alpine meadow grasslands. In this study, field measurements of grassland cover in Gannan Prefecture, from 2014 to 2016, were acquired using unmanned aerial vehicle (UAV) technology. Single-factor parametric and multi-factor parametric/non-parametric cover inversion models were then constructed based on 14 factors related to grassland cover, and the dynamic variation of the annual maximum cover was analyzed. The results show that (1) nine out of 14 factors (longitude, latitude, elevation, the concentrations of clay and sand in the surface and bottom soils, temperature, precipitation, enhanced vegetation index (EVI) and normalized difference vegetation index (NDVI)) exert a significant effect on grassland cover in the study area. The logarithmic model based on EVI presents the best performance, with an R2 and RMSE of 0.52 and 16.96%, respectively. Single-factor grassland cover inversion models account for only 1–49% of the variation in cover during the growth season. (2) The optimum grassland cover inversion model is the artificial neural network (BP-ANN), with an R2 and RMSE of 0.72 and 13.38%, and SDs of 0.062% and 1.615%, respectively. Both the accuracy and the stability of the BP-ANN model are higher than those of the single-factor parametric models and multi-factor parametric/non-parametric models. (3) The annual maximum cover in Gannan Prefecture presents an increasing trend over 60.60% of the entire study area, while 36.54% is presently stable and 2.86% exhibits a decreasing trend.},
DOI = {10.3390/rs10020320}
}



@Article{rs10020351,
AUTHOR = {Bashmal, Laila and Bazi, Yakoub and AlHichri, Haikel and AlRahhal, Mohamad M. and Ammour, Nassim and Alajlan, Naif},
TITLE = {Siamese-GAN: Learning Invariant Representations for Aerial Vehicle Image Categorization},
JOURNAL = {Remote Sensing},
VOLUME = {10},
YEAR = {2018},
NUMBER = {2},
ARTICLE-NUMBER = {351},
URL = {https://www.mdpi.com/2072-4292/10/2/351},
ISSN = {2072-4292},
ABSTRACT = {In this paper, we present a new algorithm for cross-domain classification in aerial vehicle images based on generative adversarial networks (GANs). The proposed method, called Siamese-GAN, learns invariant feature representations for both labeled and unlabeled images coming from two different domains. To this end, we train in an adversarial manner a Siamese encoder–decoder architecture coupled with a discriminator network. The encoder–decoder network has the task of matching the distributions of both domains in a shared space regularized by the reconstruction ability, while the discriminator seeks to distinguish between them. After this phase, we feed the resulting encoded labeled and unlabeled features to another network composed of two fully-connected layers for training and classification, respectively. Experiments on several cross-domain datasets composed of extremely high resolution (EHR) images acquired by manned/unmanned aerial vehicles (MAV/UAV) over the cities of Vaihingen, Toronto, Potsdam, and Trento are reported and discussed.},
DOI = {10.3390/rs10020351}
}



@Article{rs10030360,
AUTHOR = {Zhu, Chenghao and Zhang, Xiaoli and Zhang, Ning and Hassan, Mohammed Abdelmanan and Zhao, Lin},
TITLE = {Assessing the Defoliation of Pine Forests in a Long Time-Series and Spatiotemporal Prediction of the Defoliation Using Landsat Data},
JOURNAL = {Remote Sensing},
VOLUME = {10},
YEAR = {2018},
NUMBER = {3},
ARTICLE-NUMBER = {360},
URL = {https://www.mdpi.com/2072-4292/10/3/360},
ISSN = {2072-4292},
ABSTRACT = {Pine forests (Pinus tabulaeformis) have been in danger of defoliation by a caterpillar in the west Liaoning province of China for more than thirty years. This paper aims to assess and predict the degree of damage to pine forests by using remote sensing and ancillary data. Through regression analysis of the pine foliage remaining ratios of field plots with several vegetation indexes of Landsat data, a feasible inversion model was obtained to detect the degree of damage using the Normalized Difference Infrared Index of 5th band (NDII5). After comparing the inversion result of the degree of damage to the pine in 29 years and the historical damage record, quantized results of damage assessment in a long time-series were accurately obtained. Based on the correlation analysis between meteorological variables and the degree of damage from 1984 to 2015, the average degree of damage was predicted in temporal scale. By adding topographic and other variables, a linear prediction model in spatiotemporal scale was constructed. The spatiotemporal model was based on 5015 public pine points for 24 years and reached 0.6169 in the correlation coefficient. This paper provided a feasible and quantitative method in the spatiotemporal prediction of forest pest occurrence by remote sensing.},
DOI = {10.3390/rs10030360}
}



@Article{s18030698,
AUTHOR = {Guo, Qiangliang and Xiao, Jin and Hu, Xiaoguang},
TITLE = {New Keypoint Matching Method Using Local Convolutional Features for Power Transmission Line Icing Monitoring},
JOURNAL = {Sensors},
VOLUME = {18},
YEAR = {2018},
NUMBER = {3},
ARTICLE-NUMBER = {698},
URL = {https://www.mdpi.com/1424-8220/18/3/698},
ISSN = {1424-8220},
ABSTRACT = {Power transmission line icing (PTLI) problems, which cause tremendous damage to the power grids, has drawn much attention. Existing three-dimensional measurement methods based on binocular stereo vision was recently introduced to measure the ice thickness in PTLI, but failed to meet requirements of practical applications due to inefficient keypoint matching in the complex PTLI scene. In this paper, a new keypoint matching method is proposed based on the local multi-layer convolutional neural network (CNN) features, termed Local Convolutional Features (LCFs). LCFs are deployed to extract more discriminative features than the conventional CNNs. Particularly in LCFs, a multi-layer features fusion scheme is exploited to boost the matching performance. Together with a location constraint method, the correspondence of neighboring keypoints is further refined. Our approach achieves 1.5%, 5.3%, 13.1%, 27.3% improvement in the average matching precision compared with SIFT, SURF, ORB and MatchNet on the public Middlebury dataset, and the measurement accuracy of ice thickness can reach 90.9% compared with manual measurement on the collected PTLI dataset.},
DOI = {10.3390/s18030698}
}



@Article{s18030712,
AUTHOR = {Zhao, Yi and Ma, Jiale and Li, Xiaohui and Zhang, Jie},
TITLE = {Saliency Detection and Deep Learning-Based Wildfire Identification in UAV Imagery},
JOURNAL = {Sensors},
VOLUME = {18},
YEAR = {2018},
NUMBER = {3},
ARTICLE-NUMBER = {712},
URL = {https://www.mdpi.com/1424-8220/18/3/712},
ISSN = {1424-8220},
ABSTRACT = {An unmanned aerial vehicle (UAV) equipped with global positioning systems (GPS) can provide direct georeferenced imagery, mapping an area with high resolution. So far, the major difficulty in wildfire image classification is the lack of unified identification marks, the fire features of color, shape, texture (smoke, flame, or both) and background can vary significantly from one scene to another. Deep learning (e.g., DCNN for Deep Convolutional Neural Network) is very effective in high-level feature learning, however, a substantial amount of training images dataset is obligatory in optimizing its weights value and coefficients. In this work, we proposed a new saliency detection algorithm for fast location and segmentation of core fire area in aerial images. As the proposed method can effectively avoid feature loss caused by direct resizing; it is used in data augmentation and formation of a standard fire image dataset ‘UAV_Fire’. A 15-layered self-learning DCNN architecture named ‘Fire_Net’ is then presented as a self-learning fire feature exactor and classifier. We evaluated different architectures and several key parameters (drop out ratio, batch size, etc.) of the DCNN model regarding its validation accuracy. The proposed architecture outperformed previous methods by achieving an overall accuracy of 98%. Furthermore, ‘Fire_Net’ guarantied an average processing speed of 41.5 ms per image for real-time wildfire inspection. To demonstrate its practical utility, Fire_Net is tested on 40 sampled images in wildfire news reports and all of them have been accurately identified.},
DOI = {10.3390/s18030712}
}



@Article{s18030737,
AUTHOR = {Cao, Xiaoguang and Wang, Peng and Meng, Cai and Bai, Xiangzhi and Gong, Guoping and Liu, Miaoming and Qi, Jun},
TITLE = {Region Based CNN for Foreign Object Debris Detection on Airfield Pavement},
JOURNAL = {Sensors},
VOLUME = {18},
YEAR = {2018},
NUMBER = {3},
ARTICLE-NUMBER = {737},
URL = {https://www.mdpi.com/1424-8220/18/3/737},
ISSN = {1424-8220},
ABSTRACT = {In this paper, a novel algorithm based on convolutional neural network (CNN) is proposed to detect foreign object debris (FOD) based on optical imaging sensors. It contains two modules, the improved region proposal network (RPN) and spatial transformer network (STN) based CNN classifier. In the improved RPN, some extra select rules are designed and deployed to generate high quality candidates with fewer numbers. Moreover, the efficiency of CNN detector is significantly improved by introducing STN layer. Compared to faster R-CNN and single shot multiBox detector (SSD), the proposed algorithm achieves better result for FOD detection on airfield pavement in the experiment.},
DOI = {10.3390/s18030737}
}



@Article{rs10030396,
AUTHOR = {Li, Jiaojiao and Xi, Bobo and Li, Yunsong and Du, Qian and Wang, Keyan},
TITLE = {Hyperspectral Classification Based on Texture Feature Enhancement and Deep Belief Networks},
JOURNAL = {Remote Sensing},
VOLUME = {10},
YEAR = {2018},
NUMBER = {3},
ARTICLE-NUMBER = {396},
URL = {https://www.mdpi.com/2072-4292/10/3/396},
ISSN = {2072-4292},
ABSTRACT = {With success of Deep Belief Networks (DBNs) in computer vision, DBN has attracted great attention in hyperspectral classification. Many deep learning based algorithms have been focused on deep feature extraction for classification improvement. Multi-features, such as texture feature, are widely utilized in classification process to enhance classification accuracy greatly. In this paper, a novel hyperspectral classification framework based on an optimal DBN and a novel texture feature enhancement (TFE) is proposed. Through band grouping, sample band selection and guided filtering, the texture features of hyperspectral data are improved. After TFE, the optimal DBN is employed on the hyperspectral reconstructed data for feature extraction and classification. Experimental results demonstrate that the proposed classification framework outperforms some state-of-the-art classification algorithms, and it can achieve outstanding hyperspectral classification performance. Furthermore, our proposed TFE method can play a significant role in improving classification accuracy.},
DOI = {10.3390/rs10030396}
}



@Article{app8030379,
AUTHOR = {Jin, Xue-Bo and Su, Ting-Li and Kong, Jian-Lei and Bai, Yu-Ting and Miao, Bei-Bei and Dou, Chao},
TITLE = {State-of-the-Art Mobile Intelligence: Enabling Robots to Move Like Humans by Estimating Mobility with Artificial Intelligence},
JOURNAL = {Applied Sciences},
VOLUME = {8},
YEAR = {2018},
NUMBER = {3},
ARTICLE-NUMBER = {379},
URL = {https://www.mdpi.com/2076-3417/8/3/379},
ISSN = {2076-3417},
ABSTRACT = {Mobility is a significant robotic task. It is the most important function when robotics is applied to domains such as autonomous cars, home service robots, and autonomous underwater vehicles. Despite extensive research on this topic, robots still suffer from difficulties when moving in complex environments, especially in practical applications. Therefore, the ability to have enough intelligence while moving is a key issue for the success of robots. Researchers have proposed a variety of methods and algorithms, including navigation and tracking. To help readers swiftly understand the recent advances in methodology and algorithms for robot movement, we present this survey, which provides a detailed review of the existing methods of navigation and tracking. In particular, this survey features a relation-based architecture that enables readers to easily grasp the key points of mobile intelligence. We first outline the key problems in robot systems and point out the relationship among robotics, navigation, and tracking. We then illustrate navigation using different sensors and the fusion methods and detail the state estimation and tracking models for target maneuvering. Finally, we address several issues of deep learning as well as the mobile intelligence of robots as suggested future research topics. The contributions of this survey are threefold. First, we review the literature of navigation according to the applied sensors and fusion method. Second, we detail the models for target maneuvering and the existing tracking based on estimation, such as the Kalman filter and its series developed form, according to their model-construction mechanisms: linear, nonlinear, and non-Gaussian white noise. Third, we illustrate the artificial intelligence approach—especially deep learning methods—and discuss its combination with the estimation method.},
DOI = {10.3390/app8030379}
}



@Article{w10030297,
AUTHOR = {Ridolfi, Elena and Manciola, Piergiorgio},
TITLE = {Water Level Measurements from Drones: A Pilot Case Study at a Dam Site},
JOURNAL = {Water},
VOLUME = {10},
YEAR = {2018},
NUMBER = {3},
ARTICLE-NUMBER = {297},
URL = {https://www.mdpi.com/2073-4441/10/3/297},
ISSN = {2073-4441},
ABSTRACT = {Unmanned Aerial Vehicles (UAVs) are now filling in the gaps between spaceborne and ground-based observations and enhancing the spatial resolution and temporal coverage of data acquisition. In the realm of hydrological observations, UAVs play a key role in quantitatively characterizing the surface flow, allowing for remotely accessing the water body of interest. In this paper, we propose a technology that uses a sensing platform encompassing a drone and a camera to determine the water level. The images acquired by means of the sensing platform are then analyzed using the Canny method to detect the edges of water level and of Ground Control Points (GCPs) used as reference points. The water level is then retrieved from images and compared to a benchmark value obtained by a traditional device. The method is tested at four locations in an artificial lake in central Italy. Results are encouraging, as the overall mean error between estimated and true water level values is around 0.05 m. This technology is well suited to improve hydraulic modeling and thus provides reliable support to flood mitigation strategies.},
DOI = {10.3390/w10030297}
}



@Article{info9030061,
AUTHOR = {Wei, Jian and Liu, Feng},
TITLE = {Online Learning of Discriminative Correlation Filter Bank for Visual Tracking},
JOURNAL = {Information},
VOLUME = {9},
YEAR = {2018},
NUMBER = {3},
ARTICLE-NUMBER = {61},
URL = {https://www.mdpi.com/2078-2489/9/3/61},
ISSN = {2078-2489},
ABSTRACT = {Accurate visual tracking is a challenging research topic in the field of computer vision. The challenge emanates from various issues, such as target deformation, background clutter, scale variations, and occlusion. In this setting, discriminative correlation filter (DCF)-based trackers have demonstrated excellent performance in terms of speed. However, existing correlation filter-based trackers cannot handle major changes in appearance due to severe occlusions, which eventually result in the development of a bounding box for target drift tracking. In this study, we use a set of DCFs called discriminative correlation filter bank (DCFB) for visual tracking to address the key causes of object occlusion and drift in a tracking-by-detection framework. In this work, we treat thxe current location of the target frame as the center, extract several samples around the target, and perform online learning of DCFB. The sliding window then extracts numerous samples within a large radius of the area where the object in the next frame is previously located. These samples are used for the DCFB to perform correlation operation in the Fourier domain to estimate the location of the new object; the coordinates of the largest correlation scores indicate the position of the new target. The DCFB is updated according to the location of the new target. Experimental results on the quantitative and qualitative evaluations on the challenging benchmark sequences show that the proposed framework improves tracking performance compared with several state-of-the-art trackers.},
DOI = {10.3390/info9030061}
}



@Article{s18030854,
AUTHOR = {Ning, Mingfeng and Zhang, Shijie and Wang, Shiqiang},
TITLE = {A Non-Cooperative Satellite Feature Point Selection Method for Vision-Based Navigation System},
JOURNAL = {Sensors},
VOLUME = {18},
YEAR = {2018},
NUMBER = {3},
ARTICLE-NUMBER = {854},
URL = {https://www.mdpi.com/1424-8220/18/3/854},
ISSN = {1424-8220},
ABSTRACT = {The number of feature points on the surface of a non-cooperative target satellite used for monocular vision-based relative navigation affects the onboard computational load. A feature point selection method called the quasi-optimal method is proposed to select a subset of feature points with a good geometric distribution. This method, with the assumption that all of the feature points are in a plane and have the same variance, is based on the fact that the scattered feature points can provide higher accuracy than that of them grouped together. The cost is defined as a function of the angle between two unit vectors from the projection center to feature points. The redundancy of a feature point is calculated by summing all costs associated with it. Firstly, the feature point with the most redundant information is removed. Then, redundancies are calculated again with the second feature point removed. The procedures above are repeated until the desired number of feature points is reached. Dilution of precision (DOP) represents the mapping relation between the observation variance and the estimated variance. In this paper, the DOP concept is used in a vision-based navigation system to verify the performance of the quasi-optimal method. Simulation results demonstrate the feasibility of calculating the relative position and attitude by using a subset of feature points with a good geometric distribution. It also shows that the feature points selected by the quasi-optimal method can provide a high accuracy with low computation time.},
DOI = {10.3390/s18030854}
}



@Article{rs10030457,
AUTHOR = {Liu, Tao and Abd-Elrahman, Amr},
TITLE = {An Object-Based Image Analysis Method for Enhancing Classification of Land Covers Using Fully Convolutional Networks and Multi-View Images of Small Unmanned Aerial System},
JOURNAL = {Remote Sensing},
VOLUME = {10},
YEAR = {2018},
NUMBER = {3},
ARTICLE-NUMBER = {457},
URL = {https://www.mdpi.com/2072-4292/10/3/457},
ISSN = {2072-4292},
ABSTRACT = {Fully Convolutional Networks (FCN) has shown better performance than other classifiers like Random Forest (RF), Support Vector Machine (SVM) and patch-based Deep Convolutional Neural Network (DCNN), for object-based classification using orthoimage only in previous studies; however, for further improving deep learning algorithm performance, multi-view data should be considered for training data enrichment, which has not been investigated for FCN. The present study developed a novel OBIA classification using FCN and multi-view data extracted from small Unmanned Aerial System (UAS) for mapping landcovers. Specifically, this study proposed three methods to automatically generate multi-view training samples from orthoimage training datasets to conduct multi-view object-based classification using FCN, and compared their performances with each other and also with RF, SVM, and DCNN classifiers. The first method does not consider the object surrounding information, while the other two utilized object context information. We demonstrated that all the three versions of FCN multi-view object-based classification outperformed their counterparts utilizing orthoimage data only. Furthermore, the results also showed that when multi-view training samples were prepared with consideration of object surroundings, FCN trained with these samples gave much better accuracy than FCN classification trained without context information. Similar accuracies were achieved from the two methods utilizing object surrounding information, although sample preparation was conducted using two different ways. When comparing FCN with RF, SVM, DCNN implies that FCN generally produced better accuracy than the other classifiers, regardless of using orthoimage or multi-view data.},
DOI = {10.3390/rs10030457}
}



@Article{su10030816,
AUTHOR = {Sung, Yunsick and Jin, Yong and Kwak, Jeonghoon and Lee, Sang-Geol and Cho, Kyungeun},
TITLE = {Advanced Camera Image Cropping Approach for CNN-Based End-to-End Controls on Sustainable Computing},
JOURNAL = {Sustainability},
VOLUME = {10},
YEAR = {2018},
NUMBER = {3},
ARTICLE-NUMBER = {816},
URL = {https://www.mdpi.com/2071-1050/10/3/816},
ISSN = {2071-1050},
ABSTRACT = {Recent research on deep learning has been applied to a diversity of fields. In particular, numerous studies have been conducted on self-driving vehicles using end-to-end approaches based on images captured by a single camera. End-to-end controls learn the output vectors of output devices directly from the input vectors of available input devices. In other words, an end-to-end approach learns not by analyzing the meaning of input vectors, but by extracting optimal output vectors based on input vectors. Generally, when end-to-end control is applied to self-driving vehicles, the steering wheel and pedals are controlled autonomously by learning from the images captured by a camera. However, high-resolution images captured from a car cannot be directly used as inputs to Convolutional Neural Networks (CNNs) owing to memory limitations; the image size needs to be efficiently reduced. Therefore, it is necessary to extract features from captured images automatically and to generate input images by merging the parts of the images that contain the extracted features. This paper proposes a learning method for end-to-end control that generates input images for CNNs by extracting road parts from input images, identifying the edges of the extracted road parts, and merging the parts of the images that contain the detected edges. In addition, a CNN model for end-to-end control is introduced. Experiments involving the Open Racing Car Simulator (TORCS), a sustainable computing environment for cars, confirmed the effectiveness of the proposed method for self-driving by comparing the accumulated difference in the angle of the steering wheel in the images generated by it with those of resized images containing the entire captured area and cropped images containing only a part of the captured area. The results showed that the proposed method reduced the accumulated difference by 0.839% and 0.850% compared to those yielded by the resized images and cropped images, respectively.},
DOI = {10.3390/su10030816}
}



@Article{e20030198,
AUTHOR = {Zhang, Zhen and Li, Yibing and Jin, Shanshan and Zhang, Zhaoyue and Wang, Hui and Qi, Lin and Zhou, Ruolin},
TITLE = {Modulation Signal Recognition Based on Information Entropy and Ensemble Learning},
JOURNAL = {Entropy},
VOLUME = {20},
YEAR = {2018},
NUMBER = {3},
ARTICLE-NUMBER = {198},
URL = {https://www.mdpi.com/1099-4300/20/3/198},
ISSN = {1099-4300},
ABSTRACT = {In this paper, information entropy and ensemble learning based signal recognition theory and algorithms have been proposed. We have extracted 16 kinds of entropy features out of 9 types of modulated signals. The types of information entropy used are numerous, including Rényi entropy and energy entropy based on S Transform and Generalized S Transform. We have used three feature selection algorithms, including sequence forward selection (SFS), sequence forward floating selection (SFFS) and RELIEF-F to select the optimal feature subset from 16 entropy features. We use five classifiers, including k-nearest neighbor (KNN), support vector machine (SVM), Adaboost, Gradient Boosting Decision Tree (GBDT) and eXtreme Gradient Boosting (XGBoost) to classify the original feature set and the feature subsets selected by different feature selection algorithms. The simulation results show that the feature subsets selected by SFS and SFFS algorithms are the best, with a 48% increase in recognition rate over the original feature set when using KNN classifier and a 34% increase when using SVM classifier. For the other three classifiers, the original feature set can achieve the best recognition performance. The XGBoost classifier has the best recognition performance, the overall recognition rate is 97.74% and the recognition rate can reach 82% when the signal to noise ratio (SNR) is −10 dB.},
DOI = {10.3390/e20030198}
}



@Article{s18030893,
AUTHOR = {Molina, Martin and Frau, Pedro and Maravall, Dario},
TITLE = {A Collaborative Approach for Surface Inspection Using Aerial Robots and Computer Vision},
JOURNAL = {Sensors},
VOLUME = {18},
YEAR = {2018},
NUMBER = {3},
ARTICLE-NUMBER = {893},
URL = {https://www.mdpi.com/1424-8220/18/3/893},
ISSN = {1424-8220},
ABSTRACT = {Aerial robots with cameras on board can be used in surface inspection to observe areas that are difficult to reach by other means. In this type of problem, it is desirable for aerial robots to have a high degree of autonomy. A way to provide more autonomy would be to use computer vision techniques to automatically detect anomalies on the surface. However, the performance of automated visual recognition methods is limited in uncontrolled environments, so that in practice it is not possible to perform a fully automatic inspection. This paper presents a solution for visual inspection that increases the degree of autonomy of aerial robots following a semi-automatic approach. The solution is based on human-robot collaboration in which the operator delegates tasks to the drone for exploration and visual recognition and the drone requests assistance in the presence of uncertainty. We validate this proposal with the development of an experimental robotic system using the software framework Aerostack. The paper describes technical challenges that we had to solve to develop such a system and the impact on this solution on the degree of autonomy to detect anomalies on the surface.},
DOI = {10.3390/s18030893}
}



@Article{s18030924,
AUTHOR = {Zhang, Duona and Ding, Wenrui and Zhang, Baochang and Xie, Chunyu and Li, Hongguang and Liu, Chunhui and Han, Jungong},
TITLE = {Automatic Modulation Classification Based on Deep Learning for Unmanned Aerial Vehicles},
JOURNAL = {Sensors},
VOLUME = {18},
YEAR = {2018},
NUMBER = {3},
ARTICLE-NUMBER = {924},
URL = {https://www.mdpi.com/1424-8220/18/3/924},
ISSN = {1424-8220},
ABSTRACT = {Deep learning has recently attracted much attention due to its excellent performance in processing audio, image, and video data. However, few studies are devoted to the field of automatic modulation classification (AMC). It is one of the most well-known research topics in communication signal recognition and remains challenging for traditional methods due to complex disturbance from other sources. This paper proposes a heterogeneous deep model fusion (HDMF) method to solve the problem in a unified framework. The contributions include the following: (1) a convolutional neural network (CNN) and long short-term memory (LSTM) are combined by two different ways without prior knowledge involved; (2) a large database, including eleven types of single-carrier modulation signals with various noises as well as a fading channel, is collected with various signal-to-noise ratios (SNRs) based on a real geographical environment; and (3) experimental results demonstrate that HDMF is very capable of coping with the AMC problem, and achieves much better performance when compared with the independent network.},
DOI = {10.3390/s18030924}
}



@Article{atmos9040119,
AUTHOR = {Wang, Rongxiao and Chen, Bin and Qiu, Sihang and Ma, Liang and Zhu, Zhengqiu and Wang, Yiping and Qiu, Xiaogang},
TITLE = {Hazardous Source Estimation Using an Artificial Neural Network, Particle Swarm Optimization and a Simulated Annealing Algorithm},
JOURNAL = {Atmosphere},
VOLUME = {9},
YEAR = {2018},
NUMBER = {4},
ARTICLE-NUMBER = {119},
URL = {https://www.mdpi.com/2073-4433/9/4/119},
ISSN = {2073-4433},
ABSTRACT = {Locating and quantifying the emission source plays a significant role in the emergency management of hazardous gas leak accidents. Due to the lack of a desirable atmospheric dispersion model, current source estimation algorithms cannot meet the requirements of both accuracy and efficiency. In addition, the original optimization algorithm can hardly estimate the source accurately, because of the difficulty in balancing the local searching with the global searching. To deal with these problems, in this paper, a source estimation method is proposed using an artificial neural network (ANN), particle swarm optimization (PSO), and a simulated annealing algorithm (SA). This novel method uses numerous pre-determined scenarios to train the ANN, so that the ANN can predict dispersion accurately and efficiently. Further, the SA is applied in the PSO to improve the global searching ability. The proposed method is firstly tested by a numerical case study based on process hazard analysis software (PHAST), with analysis of receptor configuration and measurement noise. Then, the Indianapolis field case study is applied to verify the effectiveness of the proposed method in practice. Results demonstrate that the hybrid SAPSO algorithm coupled with the ANN prediction model has better performances than conventional methods in both numerical and field cases.},
DOI = {10.3390/atmos9040119}
}



@Article{bios8020027,
AUTHOR = {Bucur, Bogdan and Munteanu, Florentina-Daniela and Marty, Jean-Louis and Vasilescu, Alina},
TITLE = {Advances in Enzyme-Based Biosensors for Pesticide Detection},
JOURNAL = {Biosensors},
VOLUME = {8},
YEAR = {2018},
NUMBER = {2},
ARTICLE-NUMBER = {27},
URL = {https://www.mdpi.com/2079-6374/8/2/27},
ISSN = {2079-6374},
ABSTRACT = {The intensive use of toxic and remanent pesticides in agriculture has prompted research into novel performant, yet cost-effective and fast analytical tools to control the pesticide residue levels in the environment and food. In this context, biosensors based on enzyme inhibition have been proposed as adequate analytical devices with the added advantage of using the toxicity of pesticides for detection purposes, being more “biologically relevant” than standard chromatographic methods. This review proposes an overview of recent advances in the development of biosensors exploiting the inhibition of cholinesterases, photosynthetic system II, alkaline phosphatase, cytochrome P450A1, peroxidase, tyrosinase, laccase, urease, and aldehyde dehydrogenase. While various strategies have been employed to detect pesticides from different classes (organophosphates, carbamates, dithiocarbamates, triazines, phenylureas, diazines, or phenols), the number of practical applications and the variety of environmental and food samples tested remains limited. Recent advances focus on enhancing the sensitivity and selectivity by using nanomaterials in the sensor assembly and novel mutant enzymes in array-type sensor formats in combination with chemometric methods for data analysis. The progress in the development of solar cells enriched the possibilities for efficient wiring of photosynthetic enzymes on different surfaces, opening new avenues for development of biosensors for photosynthesis-inhibiting herbicides.},
DOI = {10.3390/bios8020027}
}



@Article{rs10040511,
AUTHOR = {Gallego, Antonio-Javier and Pertusa, Antonio and Gil, Pablo},
TITLE = {Automatic Ship Classification from Optical Aerial Images with Convolutional Neural Networks},
JOURNAL = {Remote Sensing},
VOLUME = {10},
YEAR = {2018},
NUMBER = {4},
ARTICLE-NUMBER = {511},
URL = {https://www.mdpi.com/2072-4292/10/4/511},
ISSN = {2072-4292},
ABSTRACT = {The automatic classification of ships from aerial images is a considerable challenge. Previous works have usually applied image processing and computer vision techniques to extract meaningful features from visible spectrum images in order to use them as the input for traditional supervised classifiers. We present a method for determining if an aerial image of visible spectrum contains a ship or not. The proposed architecture is based on Convolutional Neural Networks (CNN), and it combines neural codes extracted from a CNN with a k-Nearest Neighbor method so as to improve performance. The kNN results are compared to those obtained with the CNN Softmax output. Several CNN models have been configured and evaluated in order to seek the best hyperparameters, and the most suitable setting for this task was found by using transfer learning at different levels. A new dataset (named MASATI) composed of aerial imagery with more than 6000 samples has also been created to train and evaluate our architecture. The experimentation shows a success rate of over 99% for our approach, in contrast with the 79% obtained with traditional methods in classification of ship images, also outperforming other methods based on CNNs. A dataset of images (MWPU VHR-10) used in previous works was additionally used to evaluate the proposed approach. Our best setup achieves a success ratio of 86% with these data, significantly outperforming previous state-of-the-art ship classification methods.},
DOI = {10.3390/rs10040511}
}



@Article{machines6020012,
AUTHOR = {Pappalardo, Carmine Maria and Guida, Domenico},
TITLE = {System Identification Algorithm for Computing the Modal Parameters of Linear Mechanical Systems},
JOURNAL = {Machines},
VOLUME = {6},
YEAR = {2018},
NUMBER = {2},
ARTICLE-NUMBER = {12},
URL = {https://www.mdpi.com/2075-1702/6/2/12},
ISSN = {2075-1702},
ABSTRACT = {The goal of this investigation is to construct a computational procedure for identifying the modal parameters of linear mechanical systems. The methodology employed in the paper is based on the Eigensystem Realization Algorithm implemented in conjunction with the Observer/Kalman Filter Identification method (ERA/OKID). This method represents an effective and efficient system identification numerical procedure based on the time domain. The algorithm developed in this work is tested by means of numerical experiments on a full-car vehicle model. To this end, the modal parameters necessary for the design of active and semi-active suspension systems are obtained for the vehicle system considered as an illustrative example. In order to analyze the performance of the methodology developed in this investigation, the system identification numerical procedure was tested considering two case studies, namely a full state measurement and an incomplete state measurement. As expected, the numerical results found for the identified dynamical model showed a good agreement with the modal parameters of the mechanical system model. Furthermore, numerical results demonstrated that the proposed method has good performance considering a scenario in which the signal-to-noise ratio of the input and output measurements is relatively high. The method developed in this paper can be effectively used for solving important engineering problems such as the design of control systems for road vehicles.},
DOI = {10.3390/machines6020012}
}



@Article{rs10040527,
AUTHOR = {Zhu, Xiaolin and Cai, Fangyi and Tian, Jiaqi and Williams, Trecia Kay-Ann},
TITLE = {Spatiotemporal Fusion of Multisource Remote Sensing Data: Literature Survey, Taxonomy, Principles, Applications, and Future Directions},
JOURNAL = {Remote Sensing},
VOLUME = {10},
YEAR = {2018},
NUMBER = {4},
ARTICLE-NUMBER = {527},
URL = {https://www.mdpi.com/2072-4292/10/4/527},
ISSN = {2072-4292},
ABSTRACT = {Satellite time series with high spatial resolution is critical for monitoring land surface dynamics in heterogeneous landscapes. Although remote sensing technologies have experienced rapid development in recent years, data acquired from a single satellite sensor are often unable to satisfy our demand. As a result, integrated use of data from different sensors has become increasingly popular in the past decade. Many spatiotemporal data fusion methods have been developed to produce synthesized images with both high spatial and temporal resolutions from two types of satellite images, frequent coarse-resolution images, and sparse fine-resolution images. These methods were designed based on different principles and strategies, and therefore show different strengths and limitations. This diversity brings difficulties for users to choose an appropriate method for their specific applications and data sets. To this end, this review paper investigates literature on current spatiotemporal data fusion methods, categorizes existing methods, discusses the principal laws underlying these methods, summarizes their potential applications, and proposes possible directions for future studies in this field.},
DOI = {10.3390/rs10040527}
}



@Article{s18041120,
AUTHOR = {Li, He and Liu, Gaohuan and Liu, Qingsheng and Chen, Zhongxin and Huang, Chong},
TITLE = {Retrieval of Winter Wheat Leaf Area Index from Chinese GF-1 Satellite Data Using the PROSAIL Model},
JOURNAL = {Sensors},
VOLUME = {18},
YEAR = {2018},
NUMBER = {4},
ARTICLE-NUMBER = {1120},
URL = {https://www.mdpi.com/1424-8220/18/4/1120},
ISSN = {1424-8220},
ABSTRACT = {Leaf area index (LAI) is one of the key biophysical parameters in crop structure. The accurate quantitative estimation of crop LAI is essential to verify crop growth and health. The PROSAIL radiative transfer model (RTM) is one of the most established methods for estimating crop LAI. In this study, a look-up table (LUT) based on the PROSAIL RTM was first used to estimate winter wheat LAI from GF-1 data, which accounted for some available prior knowledge relating to the distribution of winter wheat characteristics. Next, the effects of 15 LAI-LUT strategies with reflectance bands and 10 LAI-LUT strategies with vegetation indexes on the accuracy of the winter wheat LAI retrieval with different phenological stages were evaluated against in situ LAI measurements. The results showed that the LUT strategies of LAI-GNDVI were optimal and had the highest accuracy with a root mean squared error (RMSE) value of 0.34, and a coefficient of determination (R2) of 0.61 during the elongation stages, and the LUT strategies of LAI-Green were optimal with a RMSE of 0.74, and R2 of 0.20 during the grain-filling stages. The results demonstrated that the PROSAIL RTM had great potential in winter wheat LAI inversion with GF-1 satellite data and the performance could be improved by selecting the appropriate LUT inversion strategies in different growth periods.},
DOI = {10.3390/s18041120}
}



@Article{a11040044,
AUTHOR = {Zhang, Hong-Mei and Li, Ming-Long and Yang, Le},
TITLE = {Safe Path Planning of Mobile Robot Based on Improved A* Algorithm in Complex Terrains},
JOURNAL = {Algorithms},
VOLUME = {11},
YEAR = {2018},
NUMBER = {4},
ARTICLE-NUMBER = {44},
URL = {https://www.mdpi.com/1999-4893/11/4/44},
ISSN = {1999-4893},
ABSTRACT = {The A* algorithm has been widely investigated and applied in path planning problems, but it does not fully consider the safety and smoothness of the path. Therefore, an improved A* algorithm is presented in this paper. Firstly, a new environment modeling method is proposed in which the evaluation function of A* algorithm is improved by taking the safety cost into account. This results in a safer path which can stay farther away from obstacles. Then a new path smoothing method is proposed, which introduces a path evaluation mechanism into the smoothing process. This method is then applied to smoothing the path without safety reduction. Secondly, with respect to path planning problems in complex terrains, a complex terrain environment model is established in which the distance and safety cost of the evaluation function of the A* algorithm are converted into time cost. This results in a unification of units as well as a clarity in their physical meanings. The simulation results show that the improved A* algorithm can greatly improve the safety and smoothness of the planned path and the movement time of the robot in complex terrain is greatly reduced.},
DOI = {10.3390/a11040044}
}



@Article{computers7020023,
AUTHOR = {Bowkett, Mark and Thanapalan, Kary and Constant, Ewen},
TITLE = {Failure Detection of Composites with Control System Corrective Response in Drone System Applications},
JOURNAL = {Computers},
VOLUME = {7},
YEAR = {2018},
NUMBER = {2},
ARTICLE-NUMBER = {23},
URL = {https://www.mdpi.com/2073-431X/7/2/23},
ISSN = {2073-431X},
ABSTRACT = {The paper describes a novel method for the detection of damage in carbon composites as used in drone frames. When damage is detected a further novel corrective response is initiated in the quadcopter flight controller to switch from a four-arm control system to a three-arm control system. This is made possible as a symmetrical frame is utilized, which allows for a balanced weight distribution between both the undamaged quadcopter and the fallback tri-copter layout. The resulting work allows for continued flight where this was not previously possible. Further developing work includes improved flight stability with the aid of an underslung load model. This is beneficial to the quadcopter as a damaged arm attached to the main body by the motor wires behaves as an underslung load. The underslung load works are also transferable in a dual master and slave drone system where the master drone transports a smaller slave drone by a tether, which acts as an underslung load.},
DOI = {10.3390/computers7020023}
}



@Article{rs10040590,
AUTHOR = {Gu, Haiyan and Han, Yanshun and Yang, Yi and Li, Haitao and Liu, Zhengjun and Soergel, Uwe and Blaschke, Thomas and Cui, Shiyong},
TITLE = {An Efficient Parallel Multi-Scale Segmentation Method for Remote Sensing Imagery},
JOURNAL = {Remote Sensing},
VOLUME = {10},
YEAR = {2018},
NUMBER = {4},
ARTICLE-NUMBER = {590},
URL = {https://www.mdpi.com/2072-4292/10/4/590},
ISSN = {2072-4292},
ABSTRACT = {Remote sensing (RS) image segmentation is an essential step in geographic object-based image analysis (GEOBIA) to ultimately derive “meaningful objects”. While many segmentation methods exist, most of them are not efficient for large data sets. Thus, the goal of this research is to develop an efficient parallel multi-scale segmentation method for RS imagery by combining graph theory and the fractal net evolution approach (FNEA). Specifically, a minimum spanning tree (MST) algorithm in graph theory is proposed to be combined with a minimum heterogeneity rule (MHR) algorithm that is used in FNEA. The MST algorithm is used for the initial segmentation while the MHR algorithm is used for object merging. An efficient implementation of the segmentation strategy is presented using data partition and the “reverse searching-forward processing” chain based on message passing interface (MPI) parallel technology. Segmentation results of the proposed method using images from multiple sensors (airborne, SPECIM AISA EAGLE II, WorldView-2, RADARSAT-2) and different selected landscapes (residential/industrial, residential/agriculture) covering four test sites indicated its efficiency in accuracy and speed. We conclude that the proposed method is applicable and efficient for the segmentation of a variety of RS imagery (airborne optical, satellite optical, SAR, high-spectral), while the accuracy is comparable with that of the FNEA method.},
DOI = {10.3390/rs10040590}
}



@Article{drones2020015,
AUTHOR = {Polvara, Riccardo and Sharma, Sanjay and Wan, Jian and Manning, Andrew and Sutton, Robert},
TITLE = {Vision-Based Autonomous Landing of a Quadrotor on the Perturbed Deck of an Unmanned Surface Vehicle},
JOURNAL = {Drones},
VOLUME = {2},
YEAR = {2018},
NUMBER = {2},
ARTICLE-NUMBER = {15},
URL = {https://www.mdpi.com/2504-446X/2/2/15},
ISSN = {2504-446X},
ABSTRACT = {Autonomous landing on the deck of an unmanned surface vehicle (USV) is still a major challenge for unmanned aerial vehicles (UAVs). In this paper, a fiducial marker is located on the platform so as to facilitate the task since it is possible to retrieve its six-degrees of freedom relative-pose in an easy way. To compensate interruption in the marker’s observations, an extended Kalman filter (EKF) estimates the current USV’s position with reference to the last known position. Validation experiments have been performed in a simulated environment under various marine conditions. The results confirmed that the EKF provides estimates accurate enough to direct the UAV in proximity of the autonomous vessel such that the marker becomes visible again. Using only the odometry and the inertial measurements for the estimation, this method is found to be applicable even under adverse weather conditions in the absence of the global positioning system.},
DOI = {10.3390/drones2020015}
}



@Article{rs10040618,
AUTHOR = {Al-Saddik, Hania and Laybros, Anthony and Billiot, Bastien and Cointault, Frederic},
TITLE = {Using Image Texture and Spectral Reflectance Analysis to Detect Yellowness and Esca in Grapevines at Leaf-Level},
JOURNAL = {Remote Sensing},
VOLUME = {10},
YEAR = {2018},
NUMBER = {4},
ARTICLE-NUMBER = {618},
URL = {https://www.mdpi.com/2072-4292/10/4/618},
ISSN = {2072-4292},
ABSTRACT = {Plant diseases are one of the main reasons behind major economic and production losses in the agricultural field. Current research activities enable large fields monitoring and plant disease detection using innovative and robust technologies. French grapevines have a reputation for producing premium quality wines, however, these major fruit crops are susceptible to many diseases, including Esca, Downy mildew, Powdery mildew, Yellowing, and many others. In this study, we focused on two main infections (Esca and Yellowing), and data were gathered from fields that were located in Aquitaine and Burgundy regions, France. Since plant diseases can be diagnosed from the properties of the leaf, we acquired both Red-Green-Blue (RGB) digital image and hyperspectral reflectance data from infected and healthy leaves. Biophysical parameters that were produced by the PROSPECT model inversion together with texture parameters compiled from the literature were deduced. Then we investigated their relationship to damage caused by Yellowing and Esca. This study examined whether spectral and textural data can identify the two diseases through the use of Neural Networks. We obtained an overall accuracy of 99% for both of the diseases when textural and spectral data are combined. These results suggest that, first, biophysical parameters present a valid dimension reduction tool that could replace the use of complete hyperspectral data. Second, remote sensing using spectral reflectance and digital images can make an overall nondestructive, rapid, cost-effective, and reproducible technique to determine diseases in grapevines with a good level of accuracy.},
DOI = {10.3390/rs10040618}
}



@Article{rs10040620,
AUTHOR = {Cardim, Guilherme Pina and Silva, Erivaldo Antônio da and Dias, Mauricio Araújo and Bravo, Ignácio and Gardel, Alfredo},
TITLE = {Statistical Evaluation and Analysis of Road Extraction Methodologies Using a Unique Dataset from Remote Sensing},
JOURNAL = {Remote Sensing},
VOLUME = {10},
YEAR = {2018},
NUMBER = {4},
ARTICLE-NUMBER = {620},
URL = {https://www.mdpi.com/2072-4292/10/4/620},
ISSN = {2072-4292},
ABSTRACT = {In the scientific literature, multiple studies address the application of road extraction methodologies to a particular cartographic dataset. However, it is difficult for any study to perform a more reliable comparison among road extraction methodologies when their results come from different cartographic datasets. Therefore, aiming to enable a more reliable comparison among different road extraction methodologies from the scientific literature, this study proposed a statistical evaluation and analysis of road extraction methodologies using a common image dataset. To achieve this goal, we setup a dataset containing remote sensing images of three different road types, highways, cities network and rural paths, and a group of images from the ISPRS (International Society for Photogrammetry and Remote Sensing) dataset. Furthermore, three road extraction methodologies were selected from the literature, in accordance with their availability, to be processed and evaluated using well-known statistical metrics. The achieved results are encouraging and indicate that the proposed statistical evaluation and analysis can allow researchers to evaluate and compare road extraction methodologies using this common dataset extracting similar characteristics to obtain a more reliable comparison among them.},
DOI = {10.3390/rs10040620}
}



@Article{rs10040624,
AUTHOR = {Zhuo, Xiangyu and Fraundorfer, Friedrich and Kurz, Franz and Reinartz, Peter},
TITLE = {Optimization of OpenStreetMap Building Footprints Based on Semantic Information of Oblique UAV Images},
JOURNAL = {Remote Sensing},
VOLUME = {10},
YEAR = {2018},
NUMBER = {4},
ARTICLE-NUMBER = {624},
URL = {https://www.mdpi.com/2072-4292/10/4/624},
ISSN = {2072-4292},
ABSTRACT = {Building footprint information is vital for 3D building modeling. Traditionally, in remote sensing, building footprints are extracted and delineated from aerial imagery and/or LiDAR point cloud. Taking a different approach, this paper is dedicated to the optimization of OpenStreetMap (OSM) building footprints exploiting the contour information, which is derived from deep learning-based semantic segmentation of oblique images acquired by the Unmanned Aerial Vehicle (UAV). First, a simplified 3D building model of Level of Detail 1 (LoD 1) is initialized using the footprint information from OSM and the elevation information from Digital Surface Model (DSM). In parallel, a deep neural network for pixel-wise semantic image segmentation is trained in order to extract the building boundaries as contour evidence. Subsequently, an optimization integrating the contour evidence from multi-view images as a constraint results in a refined 3D building model with optimized footprints and height. Our method is leveraged to optimize OSM building footprints for four datasets with different building types, demonstrating robust performance for both individual buildings and multiple buildings regardless of image resolution. Finally, we compare our result with reference data from German Authority Topographic-Cartographic Information System (ATKIS). Quantitative and qualitative evaluations reveal that the original OSM building footprints have large offset, but can be significantly improved from meter level to decimeter level after optimization.},
DOI = {10.3390/rs10040624}
}



@Article{rs10040641,
AUTHOR = {Manfreda, Salvatore and McCabe, Matthew F. and Miller, Pauline E. and Lucas, Richard and Pajuelo Madrigal, Victor and Mallinis, Giorgos and Ben Dor, Eyal and Helman, David and Estes, Lyndon and Ciraolo, Giuseppe and Müllerová, Jana and Tauro, Flavia and De Lima, M. Isabel and De Lima, João L. M. P. and Maltese, Antonino and Frances, Felix and Caylor, Kelly and Kohv, Marko and Perks, Matthew and Ruiz-Pérez, Guiomar and Su, Zhongbo and Vico, Giulia and Toth, Brigitta},
TITLE = {On the Use of Unmanned Aerial Systems for Environmental Monitoring},
JOURNAL = {Remote Sensing},
VOLUME = {10},
YEAR = {2018},
NUMBER = {4},
ARTICLE-NUMBER = {641},
URL = {https://www.mdpi.com/2072-4292/10/4/641},
ISSN = {2072-4292},
ABSTRACT = {Environmental monitoring plays a central role in diagnosing climate and management impacts on natural and agricultural systems; enhancing the understanding of hydrological processes; optimizing the allocation and distribution of water resources; and assessing, forecasting, and even preventing natural disasters. Nowadays, most monitoring and data collection systems are based upon a combination of ground-based measurements, manned airborne sensors, and satellite observations. These data are utilized in describing both small- and large-scale processes, but have spatiotemporal constraints inherent to each respective collection system. Bridging the unique spatial and temporal divides that limit current monitoring platforms is key to improving our understanding of environmental systems. In this context, Unmanned Aerial Systems (UAS) have considerable potential to radically improve environmental monitoring. UAS-mounted sensors offer an extraordinary opportunity to bridge the existing gap between field observations and traditional air- and space-borne remote sensing, by providing high spatial detail over relatively large areas in a cost-effective way and an entirely new capacity for enhanced temporal retrieval. As well as showcasing recent advances in the field, there is also a need to identify and understand the potential limitations of UAS technology. For these platforms to reach their monitoring potential, a wide spectrum of unresolved issues and application-specific challenges require focused community attention. Indeed, to leverage the full potential of UAS-based approaches, sensing technologies, measurement protocols, postprocessing techniques, retrieval algorithms, and evaluation techniques need to be harmonized. The aim of this paper is to provide an overview of the existing research and applications of UAS in natural and agricultural ecosystem monitoring in order to identify future directions, applications, developments, and challenges.},
DOI = {10.3390/rs10040641}
}



@Article{rs10040649,
AUTHOR = {Ayrey, Elias and Hayes, Daniel J.},
TITLE = {The Use of Three-Dimensional Convolutional Neural Networks to Interpret LiDAR for Forest Inventory},
JOURNAL = {Remote Sensing},
VOLUME = {10},
YEAR = {2018},
NUMBER = {4},
ARTICLE-NUMBER = {649},
URL = {https://www.mdpi.com/2072-4292/10/4/649},
ISSN = {2072-4292},
ABSTRACT = {As light detection and ranging (LiDAR) technology becomes more available, it has become common to use these datasets to generate remotely sensed forest inventories across landscapes. Traditional methods for generating these inventories employ the use of height and proportion metrics to measure LiDAR returns and relate these back to field data using predictive models. Here, we employ a three-dimensional convolutional neural network (CNN), a deep learning technique that scans the LiDAR data and automatically generates useful features for predicting forest attributes. We test the accuracy in estimating forest attributes using the three-dimensional implementations of different CNN models commonly used in the field of image recognition. Using the best performing model architecture, we compared CNN performance to models developed using traditional height metrics. The results of this comparison show that CNNs produced 12% less prediction error when estimating biomass, 6% less in estimating tree count, and 2% less when estimating the percentage of needleleaf trees. We conclude that using CNNs can be a more accurate means of interpreting LiDAR data for forest inventories compared to standard approaches.},
DOI = {10.3390/rs10040649}
}



@Article{s18041292,
AUTHOR = {Guo, Siqiu and Zhang, Tao and Song, Yulong and Qian, Feng},
TITLE = {Color Feature-Based Object Tracking through Particle Swarm Optimization with Improved Inertia Weight},
JOURNAL = {Sensors},
VOLUME = {18},
YEAR = {2018},
NUMBER = {4},
ARTICLE-NUMBER = {1292},
URL = {https://www.mdpi.com/1424-8220/18/4/1292},
ISSN = {1424-8220},
ABSTRACT = {This paper presents a particle swarm tracking algorithm with improved inertia weight based on color features. The weighted color histogram is used as the target feature to reduce the contribution of target edge pixels in the target feature, which makes the algorithm insensitive to the target non-rigid deformation, scale variation, and rotation. Meanwhile, the influence of partial obstruction on the description of target features is reduced. The particle swarm optimization algorithm can complete the multi-peak search, which can cope well with the object occlusion tracking problem. This means that the target is located precisely where the similarity function appears multi-peak. When the particle swarm optimization algorithm is applied to the object tracking, the inertia weight adjustment mechanism has some limitations. This paper presents an improved method. The concept of particle maturity is introduced to improve the inertia weight adjustment mechanism, which could adjust the inertia weight in time according to the different states of each particle in each generation. Experimental results show that our algorithm achieves state-of-the-art performance in a wide range of scenarios.},
DOI = {10.3390/s18041292}
}



@Article{s18041298,
AUTHOR = {He, Kun and Yang, Zhijun and Bai, Yun and Long, Jianyu and Li, Chuan},
TITLE = {Intelligent Fault Diagnosis of Delta 3D Printers Using Attitude Sensors Based on Support Vector Machines},
JOURNAL = {Sensors},
VOLUME = {18},
YEAR = {2018},
NUMBER = {4},
ARTICLE-NUMBER = {1298},
URL = {https://www.mdpi.com/1424-8220/18/4/1298},
ISSN = {1424-8220},
ABSTRACT = {Health condition is a vital factor affecting printing quality for a 3D printer. In this work, an attitude monitoring approach is proposed to diagnose the fault of the delta 3D printer using support vector machines (SVM). An attitude sensor was mounted on the moving platform of the printer to monitor its 3-axial attitude angle, angular velocity, vibratory acceleration and magnetic field intensity. The attitude data of the working printer were collected under different conditions involving 12 fault types and a normal condition. The collected data were analyzed for diagnosing the health condition. To this end, the combination of binary classification, one-against-one with least-square SVM, was adopted for fault diagnosis modelling by using all channels of attitude monitoring data in the experiment. For comparison, each one channel of the attitude monitoring data was employed for model training and testing. On the other hand, a back propagation neural network (BPNN) was also applied to diagnose fault using the same data. The best fault diagnosis accuracy (94.44%) was obtained when all channels of the attitude monitoring data were used with SVM modelling. The results indicate that the attitude monitoring with SVM is an effective method for the fault diagnosis of delta 3D printers.},
DOI = {10.3390/s18041298}
}



@Article{rs10050661,
AUTHOR = {Krylov, Vladimir A. and Kenny, Eamonn and Dahyot, Rozenn},
TITLE = {Automatic Discovery and Geotagging of Objects from Street View Imagery},
JOURNAL = {Remote Sensing},
VOLUME = {10},
YEAR = {2018},
NUMBER = {5},
ARTICLE-NUMBER = {661},
URL = {https://www.mdpi.com/2072-4292/10/5/661},
ISSN = {2072-4292},
ABSTRACT = {Many applications, such as autonomous navigation, urban planning, and asset monitoring, rely on the availability of accurate information about objects and their geolocations. In this paper, we propose the automatic detection and computation of the coordinates of recurring stationary objects of interest using street view imagery. Our processing pipeline relies on two fully convolutional neural networks: the first segments objects in the images, while the second estimates their distance from the camera. To geolocate all the detected objects coherently we propose a novel custom Markov random field model to estimate the objects&rsquo; geolocation. The novelty of the resulting pipeline is the combined use of monocular depth estimation and triangulation to enable automatic mapping of complex scenes with the simultaneous presence of multiple, visually similar objects of interest. We validate experimentally the effectiveness of our approach on two object classes: traffic lights and telegraph poles. The experiments report high object recall rates and position precision of approximately 2 m, which is approaching the precision of single-frequency GPS receivers.},
DOI = {10.3390/rs10050661}
}



@Article{machines6020018,
AUTHOR = {De Simone, Marco Claudio and Rivera, Zandra Betzabe and Guida, Domenico},
TITLE = {Obstacle Avoidance System for Unmanned Ground Vehicles by Using Ultrasonic Sensors},
JOURNAL = {Machines},
VOLUME = {6},
YEAR = {2018},
NUMBER = {2},
ARTICLE-NUMBER = {18},
URL = {https://www.mdpi.com/2075-1702/6/2/18},
ISSN = {2075-1702},
ABSTRACT = {Artificial intelligence is the ability of a computer to perform the functions and reasoning typical of the human mind. In its purely informatic aspect, it includes the theory and techniques for the development of algorithms that allow machines to show an intelligent ability and/or perform an intelligent activity, at least in specific areas. In particular, there are automatic learning algorithms based on the same mechanisms that are thought to be the basis of all the cognitive processes developed by the human brain. Such a powerful tool has already started to produce a new class of self-driving vehicles. With the projections of population growth that will increase until the year 2100 up to 11.2 billion, research on innovating agricultural techniques must be continued. In order to improve the efficiency regarding precision agriculture, the use of autonomous agricultural machines must become an important issue. For this reason, it was decided to test the use of the &ldquo;Neural Network Toolbox&rdquo; tool already present in MATLAB to design an artificial neural network with supervised learning suitable for classification and pattern recognition by using data collected by an ultrasonic sensor. The idea is to use such a protocol to retrofit kits for agricultural machines already present on the market.},
DOI = {10.3390/machines6020018}
}



@Article{a11050056,
AUTHOR = {Senthilnath, J. and Simha C, Sumanth and G, Nagaraj and Thapa, Meenakumari and M, Indiramma},
TITLE = {BELMKN: Bayesian Extreme Learning Machines Kohonen Network},
JOURNAL = {Algorithms},
VOLUME = {11},
YEAR = {2018},
NUMBER = {5},
ARTICLE-NUMBER = {56},
URL = {https://www.mdpi.com/1999-4893/11/5/56},
ISSN = {1999-4893},
ABSTRACT = {This paper proposes the Bayesian Extreme Learning Machine Kohonen Network (BELMKN) framework to solve the clustering problem. The BELMKN framework uses three levels in processing nonlinearly separable datasets to obtain efficient clustering in terms of accuracy. In the first level, the Extreme Learning Machine (ELM)-based feature learning approach captures the nonlinearity in the data distribution by mapping it onto a d-dimensional space. In the second level, ELM-based feature extracted data is used as an input for Bayesian Information Criterion (BIC) to predict the number of clusters termed as a cluster prediction. In the final level, feature-extracted data along with the cluster prediction is passed to the Kohonen Network to obtain improved clustering accuracy. The main advantage of the proposed method is to overcome the problem of having a priori identifiers or class labels for the data; it is difficult to obtain labels in most of the cases for the real world datasets. The BELMKN framework is applied to 3 synthetic datasets and 10 benchmark datasets from the UCI machine learning repository and compared with the state-of-the-art clustering methods. The experimental results show that the proposed BELMKN-based clustering outperforms other clustering algorithms for the majority of the datasets. Hence, the BELMKN framework can be used to improve the clustering accuracy of the nonlinearly separable datasets.},
DOI = {10.3390/a11050056}
}



@Article{s18051379,
AUTHOR = {Chen, Xi and Kopsaftopoulos, Fotis and Wu, Qi and Ren, He and Chang, Fu-Kuo},
TITLE = {Flight State Identification of a Self-Sensing Wing via an Improved Feature Selection Method and Machine Learning Approaches},
JOURNAL = {Sensors},
VOLUME = {18},
YEAR = {2018},
NUMBER = {5},
ARTICLE-NUMBER = {1379},
URL = {https://www.mdpi.com/1424-8220/18/5/1379},
ISSN = {1424-8220},
ABSTRACT = {In this work, a data-driven approach for identifying the flight state of a self-sensing wing structure with an embedded multi-functional sensing network is proposed. The flight state is characterized by the structural vibration signals recorded from a series of wind tunnel experiments under varying angles of attack and airspeeds. A large feature pool is created by extracting potential features from the signals covering the time domain, the frequency domain as well as the information domain. Special emphasis is given to feature selection in which a novel filter method is developed based on the combination of a modified distance evaluation algorithm and a variance inflation factor. Machine learning algorithms are then employed to establish the mapping relationship from the feature space to the practical state space. Results from two case studies demonstrate the high identification accuracy and the effectiveness of the model complexity reduction via the proposed method, thus providing new perspectives of self-awareness towards the next generation of intelligent air vehicles.},
DOI = {10.3390/s18051379}
}



@Article{rs10050706,
AUTHOR = {Moy de Vitry, Matthew and Schindler, Konrad and Rieckermann, Jörg and Leitão, João P.},
TITLE = {Sewer Inlet Localization in UAV Image Clouds: Improving Performance with Multiview Detection},
JOURNAL = {Remote Sensing},
VOLUME = {10},
YEAR = {2018},
NUMBER = {5},
ARTICLE-NUMBER = {706},
URL = {https://www.mdpi.com/2072-4292/10/5/706},
ISSN = {2072-4292},
ABSTRACT = {Sewer and drainage infrastructure are often not as well catalogued as they should be, considering the immense investment they represent. In this work, we present a fully automatic framework for localizing sewer inlets from image clouds captured from an unmanned aerial vehicle (UAV). The framework exploits the high image overlap of UAV imaging surveys with a multiview approach to improve detection performance. The framework uses a Viola–Jones classifier trained to detect sewer inlets in aerial images with a ground sampling distance of 3–3.5 cm/pixel. The detections are then projected into three-dimensional space where they are clustered and reclassified to discard false positives. The method is evaluated by cross-validating results from an image cloud of 252 UAV images captured over a 0.57-km2 study area with 228 sewer inlets. Compared to an equivalent single-view detector, the multiview approach improves both recall and precision, increasing average precision from 0.65 to 0.73. The source code and case study data are publicly available for reuse.},
DOI = {10.3390/rs10050706}
}



@Article{s18051427,
AUTHOR = {Shamwell, E. Jared and Nothwang, William D. and Perlis, Donald},
TITLE = {An Embodied Multi-Sensor Fusion Approach to Visual Motion Estimation Using Unsupervised Deep Networks},
JOURNAL = {Sensors},
VOLUME = {18},
YEAR = {2018},
NUMBER = {5},
ARTICLE-NUMBER = {1427},
URL = {https://www.mdpi.com/1424-8220/18/5/1427},
ISSN = {1424-8220},
ABSTRACT = {Aimed at improving size, weight, and power (SWaP)-constrained robotic vision-aided state estimation, we describe our unsupervised, deep convolutional-deconvolutional sensor fusion network, Multi-Hypothesis DeepEfference (MHDE). MHDE learns to intelligently combine noisy heterogeneous sensor data to predict several probable hypotheses for the dense, pixel-level correspondence between a source image and an unseen target image. We show how our multi-hypothesis formulation provides increased robustness against dynamic, heteroscedastic sensor and motion noise by computing hypothesis image mappings and predictions at 76&ndash;357 Hz depending on the number of hypotheses being generated. MHDE fuses noisy, heterogeneous sensory inputs using two parallel, inter-connected architectural pathways and n (1&ndash;20 in this work) multi-hypothesis generating sub-pathways to produce n global correspondence estimates between a source and a target image. We evaluated MHDE on the KITTI Odometry dataset and benchmarked it against the vision-only DeepMatching and Deformable Spatial Pyramids algorithms and were able to demonstrate a significant runtime decrease and a performance increase compared to the next-best performing method.},
DOI = {10.3390/s18051427}
}



@Article{geosciences8050165,
AUTHOR = {Yu, Manzhu and Yang, Chaowei and Li, Yun},
TITLE = {Big Data in Natural Disaster Management: A Review},
JOURNAL = {Geosciences},
VOLUME = {8},
YEAR = {2018},
NUMBER = {5},
ARTICLE-NUMBER = {165},
URL = {https://www.mdpi.com/2076-3263/8/5/165},
ISSN = {2076-3263},
ABSTRACT = {Undoubtedly, the age of big data has opened new options for natural disaster management, primarily because of the varied possibilities it provides in visualizing, analyzing, and predicting natural disasters. From this perspective, big data has radically changed the ways through which human societies adopt natural disaster management strategies to reduce human suffering and economic losses. In a world that is now heavily dependent on information technology, the prime objective of computer experts and policy makers is to make the best of big data by sourcing information from varied formats and storing it in ways that it can be effectively used during different stages of natural disaster management. This paper aimed at making a systematic review of the literature in analyzing the role of big data in natural disaster management and highlighting the present status of the technology in providing meaningful and effective solutions in natural disaster management. The paper has presented the findings of several researchers on varied scientific and technological perspectives that have a bearing on the efficacy of big data in facilitating natural disaster management. In this context, this paper reviews the major big data sources, the associated achievements in different disaster management phases, and emerging technological topics associated with leveraging this new ecosystem of Big Data to monitor and detect natural hazards, mitigate their effects, assist in relief efforts, and contribute to the recovery and reconstruction processes.},
DOI = {10.3390/geosciences8050165}
}



@Article{rs10050719,
AUTHOR = {Chen, Guanzhou and Zhang, Xiaodong and Tan, Xiaoliang and Cheng, Yufeng and Dai, Fan and Zhu, Kun and Gong, Yuanfu and Wang, Qing},
TITLE = {Training Small Networks for Scene Classification of Remote Sensing Images via Knowledge Distillation},
JOURNAL = {Remote Sensing},
VOLUME = {10},
YEAR = {2018},
NUMBER = {5},
ARTICLE-NUMBER = {719},
URL = {https://www.mdpi.com/2072-4292/10/5/719},
ISSN = {2072-4292},
ABSTRACT = {Scene classification, aiming to identify the land-cover categories of remotely sensed image patches, is now a fundamental task in the remote sensing image analysis field. Deep-learning-model-based algorithms are widely applied in scene classification and achieve remarkable performance, but these high-level methods are computationally expensive and time-consuming. Consequently in this paper, we introduce a knowledge distillation framework, currently a mainstream model compression method, into remote sensing scene classification to improve the performance of smaller and shallower network models. Our knowledge distillation training method makes the high-temperature softmax output of a small and shallow student model match the large and deep teacher model. In our experiments, we evaluate knowledge distillation training method for remote sensing scene classification on four public datasets: AID dataset, UCMerced dataset, NWPU-RESISC dataset, and EuroSAT dataset. Results show that our proposed training method was effective and increased overall accuracy (3% in AID experiments, 5% in UCMerced experiments, 1% in NWPU-RESISC and EuroSAT experiments) for small and shallow models. We further explored the performance of the student model on small and unbalanced datasets. Our findings indicate that knowledge distillation can improve the performance of small network models on datasets with lower spatial resolution images, numerous categories, as well as fewer training samples.},
DOI = {10.3390/rs10050719}
}



@Article{s18051457,
AUTHOR = {Fontanella, Rita and Accardo, Domenico and Moriello, Rosario Schiano Lo and Angrisani, Leopoldo and Simone, Domenico De},
TITLE = {An Innovative Strategy for Accurate Thermal Compensation of Gyro Bias in Inertial Units by Exploiting a Novel Augmented Kalman Filter},
JOURNAL = {Sensors},
VOLUME = {18},
YEAR = {2018},
NUMBER = {5},
ARTICLE-NUMBER = {1457},
URL = {https://www.mdpi.com/1424-8220/18/5/1457},
ISSN = {1424-8220},
ABSTRACT = {This paper presents an innovative model for integrating thermal compensation of gyro bias error into an augmented state Kalman filter. The developed model is applied in the Zero Velocity Update filter for inertial units manufactured by exploiting Micro Electro-Mechanical System (MEMS) gyros. It is used to remove residual bias at startup. It is a more effective alternative to traditional approach that is realized by cascading bias thermal correction by calibration and traditional Kalman filtering for bias tracking. This function is very useful when adopted gyros are manufactured using MEMS technology. These systems have significant limitations in terms of sensitivity to environmental conditions. They are characterized by a strong correlation of the systematic error with temperature variations. The traditional process is divided into two separated algorithms, i.e., calibration and filtering, and this aspect reduces system accuracy, reliability, and maintainability. This paper proposes an innovative Zero Velocity Update filter that just requires raw uncalibrated gyro data as input. It unifies in a single algorithm the two steps from the traditional approach. Therefore, it saves time and economic resources, simplifying the management of thermal correction process. In the paper, traditional and innovative Zero Velocity Update filters are described in detail, as well as the experimental data set used to test both methods. The performance of the two filters is compared both in nominal conditions and in the typical case of a residual initial alignment bias. In this last condition, the innovative solution shows significant improvements with respect to the traditional approach. This is the typical case of an aircraft or a car in parking conditions under solar input.},
DOI = {10.3390/s18051457}
}



@Article{s18051474,
AUTHOR = {Kamminga, Jacob and Ayele, Eyuel and Meratnia, Nirvana and Havinga, Paul},
TITLE = {Poaching Detection Technologies—A Survey},
JOURNAL = {Sensors},
VOLUME = {18},
YEAR = {2018},
NUMBER = {5},
ARTICLE-NUMBER = {1474},
URL = {https://www.mdpi.com/1424-8220/18/5/1474},
ISSN = {1424-8220},
ABSTRACT = {Between 1960 and 1990, 95% of the black rhino population in the world was killed. In South Africa, a rhino was killed every 8 h for its horn throughout 2016. Wild animals, rhinos and elephants, in particular, are facing an ever increasing poaching crisis. In this paper, we review poaching detection technologies that aim to save endangered species from extinction. We present requirements for effective poacher detection and identify research challenges through the survey. We describe poaching detection technologies in four domains: perimeter based, ground based, aerial based, and animal tagging based technologies. Moreover, we discuss the different types of sensor technologies that are used in intruder detection systems such as: radar, magnetic, acoustic, optic, infrared and thermal, radio frequency, motion, seismic, chemical, and animal sentinels. The ultimate long-term solution for the poaching crisis is to remove the drivers of demand by educating people in demanding countries and raising awareness of the poaching crisis. Until prevention of poaching takes effect, there will be a continuous urgent need for new (combined) approaches that take up the research challenges and provide better protection against poaching in wildlife areas.},
DOI = {10.3390/s18051474}
}



@Article{ijgi7050182,
AUTHOR = {Deng, Zhipeng and Sun, Hao and Zhou, Shilin},
TITLE = {Semi-Supervised Ground-to-Aerial Adaptation with Heterogeneous Features Learning for Scene Classification},
JOURNAL = {ISPRS International Journal of Geo-Information},
VOLUME = {7},
YEAR = {2018},
NUMBER = {5},
ARTICLE-NUMBER = {182},
URL = {https://www.mdpi.com/2220-9964/7/5/182},
ISSN = {2220-9964},
ABSTRACT = {Currently, huge quantities of remote sensing images (RSIs) are becoming available. Nevertheless, the scarcity of labeled samples hinders the semantic understanding of RSIs. Fortunately, many ground-level image datasets with detailed semantic annotations have been collected in the vision community. In this paper, we attempt to exploit the abundant labeled ground-level images to build discriminative models for overhead-view RSI classification. However, images from the ground-level and overhead view are represented by heterogeneous features with different distributions; how to effectively combine multiple features and reduce the mismatch of distributions are two key problems in this scene-model transfer task. Specifically, a semi-supervised manifold-regularized multiple-kernel-learning (SMRMKL) algorithm is proposed for solving these problems. We employ multiple kernels over several features to learn an optimal combined model automatically. Multi-kernel Maximum Mean Discrepancy (MK-MMD) is utilized to measure the data mismatch. To make use of unlabeled target samples, a manifold regularized semi-supervised learning process is incorporated into our framework. Extensive experimental results on both cross-view and aerial-to-satellite scene datasets demonstrate that: (1) SMRMKL has an appealing extension ability to effectively fuse different types of visual features; and (2) manifold regularization can improve the adaptation performance by utilizing unlabeled target samples.},
DOI = {10.3390/ijgi7050182}
}



@Article{rs10050745,
AUTHOR = {Ma, Dandan and Yuan, Yuan and Wang, Qi},
TITLE = {Hyperspectral Anomaly Detection via Discriminative Feature Learning with Multiple-Dictionary Sparse Representation},
JOURNAL = {Remote Sensing},
VOLUME = {10},
YEAR = {2018},
NUMBER = {5},
ARTICLE-NUMBER = {745},
URL = {https://www.mdpi.com/2072-4292/10/5/745},
ISSN = {2072-4292},
ABSTRACT = {Most hyperspectral anomaly detection methods directly utilize all the original spectra to recognize anomalies. However, the inherent characteristics of high spectral dimension and complex spectral correlation commonly make their detection performance unsatisfactory. Therefore, an effective feature extraction technique is necessary. To this end, this paper proposes a novel anomaly detection method via discriminative feature learning with multiple-dictionary sparse representation. Firstly, a new spectral feature selection framework based on sparse presentation is designed, which is closely guided by the anomaly detection task. Then, the representative spectra which can significantly enlarge anomaly’s deviation from background are picked out by minimizing residues between background spectrum reconstruction error and anomaly spectrum recovery error. Finally, through comprehensively considering the virtues of different groups of representative features selected from multiple dictionaries, a global multiple-view detection strategy is presented to improve the detection accuracy. The proposed method is compared with ten state-of-the-art methods including LRX, SRD, CRD, LSMAD, RSAD, BACON, BACON-target, GRX, GKRX, and PCA-GRX on three real-world hyperspectral images. Corresponding to each competitor, it has the average detection performance improvement of about     9.9 %    ,     7.4 %    ,     24.2 %    ,     10.1 %    ,     26.2 %    ,     20.1 %    ,     5.1 %    ,     19.3 %    ,     10.7 %    , and     2.0 %     respectively. Extensive experiments demonstrate its superior performance in effectiveness and efficiency.},
DOI = {10.3390/rs10050745}
}



@Article{rs10050761,
AUTHOR = {Louargant, Marine and Jones, Gawain and Faroux, Romain and Paoli, Jean-Noël and Maillot, Thibault and Gée, Christelle and Villette, Sylvain},
TITLE = {Unsupervised Classification Algorithm for Early Weed Detection in Row-Crops by Combining Spatial and Spectral Information},
JOURNAL = {Remote Sensing},
VOLUME = {10},
YEAR = {2018},
NUMBER = {5},
ARTICLE-NUMBER = {761},
URL = {https://www.mdpi.com/2072-4292/10/5/761},
ISSN = {2072-4292},
ABSTRACT = {In agriculture, reducing herbicide use is a challenge to reduce health and environmental risks while maintaining production yield and quality. Site-specific weed management is a promising way to reach this objective but requires efficient weed detection methods. In this paper, an automatic image processing has been developed to discriminate between crop and weed pixels combining spatial and spectral information extracted from four-band multispectral images. Image data was captured at 3 m above ground, with a camera (multiSPEC 4C, AIRINOV, Paris) mounted on a pole kept manually. For each image, the field of view was approximately 4 m × 3 m and the resolution was 6 mm/pix. The row crop arrangement was first used to discriminate between some crop and weed pixels depending on their location inside or outside of crop rows. Then, these pixels were used to automatically build the training dataset concerning the multispectral features of crop and weed pixel classes. For each image, a specific training dataset was used by a supervised classifier (Support Vector Machine) to classify pixels that cannot be correctly discriminated using only the initial spatial approach. Finally, inter-row pixels were classified as weed and in-row pixels were classified as crop or weed depending on their spectral characteristics. The method was assessed on 14 images captured on maize and sugar beet fields. The contribution of the spatial, spectral and combined information was studied with respect to the classification quality. Our results show the better ability of the spatial and spectral combination algorithm to detect weeds between and within crop rows. They demonstrate the improvement of the weed detection rate and the improvement of its robustness. On all images, the mean value of the weed detection rate was 89% for spatial and spectral combination method, 79% for spatial method, and 75% for spectral method. Moreover, our work shows that the plant in-line sowing can be used to design an automatic image processing and classification algorithm to detect weed without requiring any manual data selection and labelling. Since the method required crop row identification, the method is suitable for wide-row crops and high spatial resolution images (at least 6 mm/pix).},
DOI = {10.3390/rs10050761}
}



@Article{rs10050779,
AUTHOR = {Tao, Yiting and Xu, Miaozhong and Lu, Zhongyuan and Zhong, Yanfei},
TITLE = {DenseNet-Based Depth-Width Double Reinforced Deep Learning Neural Network for High-Resolution Remote Sensing Image Per-Pixel Classification},
JOURNAL = {Remote Sensing},
VOLUME = {10},
YEAR = {2018},
NUMBER = {5},
ARTICLE-NUMBER = {779},
URL = {https://www.mdpi.com/2072-4292/10/5/779},
ISSN = {2072-4292},
ABSTRACT = {Deep neural networks (DNNs) face many problems in the very high resolution remote sensing (VHRRS) per-pixel classification field. Among the problems is the fact that as the depth of the network increases, gradient disappearance influences classification accuracy and the corresponding increasing number of parameters to be learned increases the possibility of overfitting, especially when only a small amount of VHRRS labeled samples are acquired for training. Further, the hidden layers in DNNs are not transparent enough, which results in extracted features not being sufficiently discriminative and significant amounts of redundancy. This paper proposes a novel depth-width-reinforced DNN that solves these problems to produce better per-pixel classification results in VHRRS. In the proposed method, densely connected neural networks and internal classifiers are combined to build a deeper network and balance the network depth and performance. This strengthens the gradients, decreases negative effects from gradient disappearance as the network depth increases and enhances the transparency of hidden layers, making extracted features more discriminative and reducing the risk of overfitting. In addition, the proposed method uses multi-scale filters to create a wider neural network. The depth of the filters from each scale is controlled to decrease redundancy and the multi-scale filters enable utilization of joint spatio-spectral information and diverse local spatial structure simultaneously. Furthermore, the concept of network in network is applied to better fuse the deeper and wider designs, making the network operate more smoothly. The results of experiments conducted on BJ02, GF02, geoeye and quickbird satellite images verify the efficacy of the proposed method. The proposed method not only achieves competitive classification results but also proves that the network can continue to be robust and perform well even while the amount of labeled training samples is decreasing, which fits the small training samples situation faced by VHRRS per-pixel classification.},
DOI = {10.3390/rs10050779}
}



@Article{s18051611,
AUTHOR = {Karimi, Hadi and Skovsen, Søren and Dyrmann, Mads and Nyholm Jørgensen, Rasmus},
TITLE = {A Novel Locating System for Cereal Plant Stem Emerging Points’ Detection Using a Convolutional Neural Network},
JOURNAL = {Sensors},
VOLUME = {18},
YEAR = {2018},
NUMBER = {5},
ARTICLE-NUMBER = {1611},
URL = {https://www.mdpi.com/1424-8220/18/5/1611},
ISSN = {1424-8220},
ABSTRACT = {Determining the individual location of a plant, besides evaluating sowing performance, would make subsequent treatment for each plant across a field possible. In this study, a system for locating cereal plant stem emerging points (PSEPs) has been developed. In total, 5719 images were gathered from several cereal fields. In 212 of these images, the PSEPs of the cereal plants were marked manually and used to train a fully-convolutional neural network. In the training process, a cost function was made, which incorporates predefined penalty regions and PSEPs. The penalty regions were defined based on fault prediction of the trained model without penalty region assignment. By adding penalty regions to the training, the network&rsquo;s ability to precisely locate emergence points of the cereal plants was enhanced significantly. A coefficient of determination of about 87 percent between the predicted PSEP number of each image and the manually marked one implies the ability of the system to count PSEPs. With regard to the obtained results, it was concluded that the developed model can give a reliable clue about the quality of PSEPs&rsquo; distribution and the performance of seed drills in fields.},
DOI = {10.3390/s18051611}
}



@Article{f9050275,
AUTHOR = {Li, Dan and Gu, Xingfa and Pang, Yong and Chen, Bowei and Liu, Luxia},
TITLE = {Estimation of Forest Aboveground Biomass and Leaf Area Index Based on Digital Aerial Photograph Data in Northeast China},
JOURNAL = {Forests},
VOLUME = {9},
YEAR = {2018},
NUMBER = {5},
ARTICLE-NUMBER = {275},
URL = {https://www.mdpi.com/1999-4907/9/5/275},
ISSN = {1999-4907},
ABSTRACT = {Forest aboveground biomass (AGB) and leaf area index (LAI) are two important parameters for evaluating forest growth and health. It is of great significance to estimate AGB and LAI accurately using remote sensing technology. Considering the temporal resolution and data acquisition costs, digital aerial photographs (DAPs) from a digital camera mounted on an unmanned aerial vehicle or light, small aircraft have been widely used in forest inventory. In this study, the aerial photograph data was acquired on 5 and 9 June, 2017 by a Hasselblad60 digital camera of the CAF-LiCHy system in a Y-5 aircraft in the Mengjiagang forest farm of Northeast China, and the digital orthophoto mosaic (DOM) and photogrammetric point cloud (PPC) were generated from an aerial overlap photograph. Forest red-green-blue (RGB) vegetation indices and textural factors were extracted from the DOM. Forest vertical structure features and canopy cover were extracted from normalized PPC. Regression analysis was carried out considering only DOM data, only PPC data, and a combination of both. A recursive feature elimination (RFE) method using a random forest was used for variable selection. Four different machine-learning (ML) algorithms (random forest, k-nearest neighbor, Cubist and supporting vector machine) were used to build regression models. Experimental results showed that PPC data alone could estimate AGB, and DOM data alone could estimate LAI with relatively high accuracy. The combination of features from DOM and PPC data was the most effective, in all the experiments considered, for the estimation of AGB and LAI. The results showed that the height and coverage variables of PPC, texture mean value, and the visible differential vegetation index (VDVI) of the DOM are significantly related to the estimated AGB (R2 = 0.73, RMSE = 20 t/ha). The results also showed that the canopy cover of PPC and green red ratio index (GRRI) of DOM are the most strongly related to the estimated LAI, and the height and coverage variables of PPC, the texture mean value and visible atmospherically resistant index (VARI), and the VDVI of DOM followed (R2 = 0.79, RMSE = 0.48).},
DOI = {10.3390/f9050275}
}



@Article{s18051659,
AUTHOR = {Feng, Wenguang and Liu, Shibin},
TITLE = {A Nonlinear Calibration Algorithm Based on Harmonic Decomposition for Two-Axis Fluxgate Sensors},
JOURNAL = {Sensors},
VOLUME = {18},
YEAR = {2018},
NUMBER = {5},
ARTICLE-NUMBER = {1659},
URL = {https://www.mdpi.com/1424-8220/18/5/1659},
ISSN = {1424-8220},
ABSTRACT = {Nonlinearity is a prominent limitation to the calibration performance for two-axis fluxgate sensors. In this paper, a novel nonlinear calibration algorithm taking into account the nonlinearity of errors is proposed. In order to establish the nonlinear calibration model, the combined effort of all time-invariant errors is analyzed in detail, and then harmonic decomposition method is utilized to estimate the compensation coefficients. Meanwhile, the proposed nonlinear calibration algorithm is validated and compared with a classical calibration algorithm by experiments. The experimental results show that, after the nonlinear calibration, the maximum deviation of magnetic field magnitude is decreased from 1302 nT to 30 nT, which is smaller than 81 nT after the classical calibration. Furthermore, for the two-axis fluxgate sensor used as magnetic compass, the maximum error of heading is corrected from 1.86&deg; to 0.07&deg;, which is approximately 11% in contrast with 0.62&deg; after the classical calibration. The results suggest an effective way to improve the calibration performance of two-axis fluxgate sensors.},
DOI = {10.3390/s18051659}
}



@Article{electronics7060078,
AUTHOR = {Liu, Xiaofei and Yang, Tao and Li, Jing},
TITLE = {Real-Time Ground Vehicle Detection in Aerial Infrared Imagery Based on Convolutional Neural Network},
JOURNAL = {Electronics},
VOLUME = {7},
YEAR = {2018},
NUMBER = {6},
ARTICLE-NUMBER = {78},
URL = {https://www.mdpi.com/2079-9292/7/6/78},
ISSN = {2079-9292},
ABSTRACT = {An infrared sensor is a commonly used imaging device. Unmanned aerial vehicles, the most promising moving platform, each play a vital role in their own field, respectively. However, the two devices are seldom combined in automatic ground vehicle detection tasks. Therefore, how to make full use of them&mdash;especially in ground vehicle detection based on aerial imagery&ndash;has aroused wide academic concern. However, due to the aerial imagery&rsquo;s low-resolution and the vehicle detection&rsquo;s complexity, how to extract remarkable features and handle pose variations, view changes as well as surrounding radiation remains a challenge. In fact, these typical abstract features extracted by convolutional neural networks are more recognizable than the engineering features, and those complex conditions involved can be learned and memorized before. In this paper, a novel approach towards ground vehicle detection in aerial infrared images based on a convolutional neural network is proposed. The UAV and the infrared sensor used in this application are firstly introduced. Then, a novel aerial moving platform is built and an aerial infrared vehicle dataset is unprecedentedly constructed. We publicly release this dataset (NPU_CS_UAV_IR_DATA), which can be used for the following research in this field. Next, an end-to-end convolutional neural network is built. With large amounts of recognized features being iteratively learned, a real-time ground vehicle model is constructed. It has the unique ability to detect both the stationary vehicles and moving vehicles in real urban environments. We evaluate the proposed algorithm on some low&ndash;resolution aerial infrared images. Experiments on the NPU_CS_UAV_IR_DATA dataset demonstrate that the proposed method is effective and efficient to recognize the ground vehicles. Moreover it can accomplish the task in real-time while achieving superior performances in leak and false alarm ratio.},
DOI = {10.3390/electronics7060078}
}



@Article{s18061703,
AUTHOR = {Nguyen, Phong Ha and Arsalan, Muhammad and Koo, Ja Hyung and Naqvi, Rizwan Ali and Truong, Noi Quang and Park, Kang Ryoung},
TITLE = {LightDenseYOLO: A Fast and Accurate Marker Tracker for Autonomous UAV Landing by Visible Light Camera Sensor on Drone},
JOURNAL = {Sensors},
VOLUME = {18},
YEAR = {2018},
NUMBER = {6},
ARTICLE-NUMBER = {1703},
URL = {https://www.mdpi.com/1424-8220/18/6/1703},
ISSN = {1424-8220},
ABSTRACT = {Autonomous landing of an unmanned aerial vehicle or a drone is a challenging problem for the robotics research community. Previous researchers have attempted to solve this problem by combining multiple sensors such as global positioning system (GPS) receivers, inertial measurement unit, and multiple camera systems. Although these approaches successfully estimate an unmanned aerial vehicle location during landing, many calibration processes are required to achieve good detection accuracy. In addition, cases where drones operate in heterogeneous areas with no GPS signal should be considered. To overcome these problems, we determined how to safely land a drone in a GPS-denied environment using our remote-marker-based tracking algorithm based on a single visible-light-camera sensor. Instead of using hand-crafted features, our algorithm includes a convolutional neural network named lightDenseYOLO to extract trained features from an input image to predict a marker&rsquo;s location by visible light camera sensor on drone. Experimental results show that our method significantly outperforms state-of-the-art object trackers both using and not using convolutional neural network in terms of both accuracy and processing time.},
DOI = {10.3390/s18061703}
}



@Article{s18061796,
AUTHOR = {Wang, Baoxian and Zhao, Weigang and Gao, Po and Zhang, Yufeng and Wang, Zhe},
TITLE = {Crack Damage Detection Method via Multiple Visual Features and Efficient Multi-Task Learning Model},
JOURNAL = {Sensors},
VOLUME = {18},
YEAR = {2018},
NUMBER = {6},
ARTICLE-NUMBER = {1796},
URL = {https://www.mdpi.com/1424-8220/18/6/1796},
ISSN = {1424-8220},
ABSTRACT = {This paper proposes an effective and efficient model for concrete crack detection. The presented work consists of two modules: multi-view image feature extraction and multi-task crack region detection. Specifically, multiple visual features (such as texture, edge, etc.) of image regions are calculated, which can suppress various background noises (such as illumination, pockmark, stripe, blurring, etc.). With the computed multiple visual features, a novel crack region detector is advocated using a multi-task learning framework, which involves restraining the variability for different crack region features and emphasizing the separability between crack region features and complex background ones. Furthermore, the extreme learning machine is utilized to construct this multi-task learning model, thereby leading to high computing efficiency and good generalization. Experimental results of the practical concrete images demonstrate that the developed algorithm can achieve favorable crack detection performance compared with traditional crack detectors.},
DOI = {10.3390/s18061796}
}



@Article{s18061846,
AUTHOR = {Chen, Luzhao and Wu, Peilin and Zhu, Wanhua and Feng, Yongqiang and Fang, Guangyou},
TITLE = {A Novel Strategy for Improving the Aeromagnetic Compensation Performance of Helicopters},
JOURNAL = {Sensors},
VOLUME = {18},
YEAR = {2018},
NUMBER = {6},
ARTICLE-NUMBER = {1846},
URL = {https://www.mdpi.com/1424-8220/18/6/1846},
ISSN = {1424-8220},
ABSTRACT = {An aeromagnetic survey is an important method in magnetic anomaly detection and geophysical prospecting. The magnetic field is typically measured by optically pumped magnetometers (OPM) installed on the aircraft. The measurement accuracy of the OPM is easily affected by the platform-generated magnetic fields. Therefore, aeromagnetic compensation is necessary. The traditional compensation model only considers the permanent, induced, and eddy current interference magnetic field of the aircraft platform. However, the interference field produced by the avionics system, and the relative motion between the aircraft and the magnetometer, are still not taken into account. To address this issue, we proposed a novel strategy to eliminate the additional interference of the platform with two OPMs. Among them, the OPM located farther away from the aircraft serves as a sensing magnetometer, whereas the near OPM serves as a reference magnetometer. The coherent noise suppression method is used to process the residual magnetic field interference after compensation. By establishing the interference magnetic transfer function between the two sensors, the interference field can be suppressed. The results of the experiments demonstrate the effectiveness of the novel strategy, and the standard deviation of residual interference drops from 0.065 nT to 0.045 nT.},
DOI = {10.3390/s18061846}
}



@Article{rs10060887,
AUTHOR = {Zhu, Jiasong and Sun, Ke and Jia, Sen and Lin, Weidong and Hou, Xianxu and Liu, Bozhi and Qiu, Guoping},
TITLE = {Bidirectional Long Short-Term Memory Network for Vehicle Behavior Recognition},
JOURNAL = {Remote Sensing},
VOLUME = {10},
YEAR = {2018},
NUMBER = {6},
ARTICLE-NUMBER = {887},
URL = {https://www.mdpi.com/2072-4292/10/6/887},
ISSN = {2072-4292},
ABSTRACT = {Vehicle behavior recognition is an attractive research field which is useful for many computer vision and intelligent traffic analysis tasks. This paper presents an all-in-one behavior recognition framework for moving vehicles based on the latest deep learning techniques. Unlike traditional traffic analysis methods which rely on low-resolution videos captured by road cameras, we capture 4K (    3840 × 2178    ) traffic videos at a busy road intersection of a modern megacity by flying a unmanned aerial vehicle (UAV) during the rush hours. We then manually annotate locations and types of road vehicles. The proposed method consists of the following three steps: (1) vehicle detection and type recognition based on deep neural networks; (2) vehicle tracking by data association and vehicle trajectory modeling; (3) vehicle behavior recognition by nearest neighbor search and by bidirectional long short-term memory network, respectively. This paper also presents experimental results of the proposed framework in comparison with state-of-the-art approaches on the 4K testing traffic video, which demonstrated the effectiveness and superiority of the proposed method.},
DOI = {10.3390/rs10060887}
}



@Article{rs10060888,
AUTHOR = {Guo, Long and Linderman, Marc and Shi, Tiezhu and Chen, Yiyun and Duan, Lijun and Zhang, Haitao},
TITLE = {Exploring the Sensitivity of Sampling Density in Digital Mapping of Soil Organic Carbon and Its Application in Soil Sampling},
JOURNAL = {Remote Sensing},
VOLUME = {10},
YEAR = {2018},
NUMBER = {6},
ARTICLE-NUMBER = {888},
URL = {https://www.mdpi.com/2072-4292/10/6/888},
ISSN = {2072-4292},
ABSTRACT = {The rapid monitoring and accurate estimation of dynamic changes in soil organic carbon (SOC) can make great efforts in understanding the global carbon cycle. Traditional field survey is the main approach to obtain soil data and measure SOC content. However, the limited number of soil samples and the sampling cost hinder the quality of digital soil mapping. This research aims to explore the sensitive of sampling density in digital soil mapping, and then design a suitable soil sampling plan based on a series of sampling indices. Headwall hyperspectral images (400&ndash;1700 nm) were used to estimate the SOC map by partial least squares regression (PLSR) and PLSR kriging (PLSRK). Three traditional soil sampling methods (random, grid, and Latin hypercube sampling) with 10 classes of sampling densities (6.26, 2.79, 1.57, 1.01, 0.69, 0.53, 0.39, 0.30, 0.26, and 0.20 ha&minus;1) were designed. The R2, root mean square error (RMSE) and ratio of standard deviation to RMSE (RPD) were used to evaluate the prediction accuracy in digital soil mapping by ordinary kriging. Three new indices, namely, the ratio of sampling efficiency to performance (RSEP), the density of soil samples index and the comprehensive evaluation index of prediction accuracy, were used to select a suitable soil sampling plan. Results showed that (1) the prediction accuracy of PLSRK (RPD = 2.00) was higher by approximately 11.73% than that of PLSR (RPD = 1.79), and the hyperspectral images provided an actual referential SOC map for the study of soil sampling; (2) the grid sampling plan performed better than the random and Latin hypercube sampling methods, and the quality of SOC map improves with the increase of the sampling density, and (3) the computer simulation and field verification indicated that RSEP is one feasible index in designing a suitable soil sampling plan.},
DOI = {10.3390/rs10060888}
}



@Article{s18061871,
AUTHOR = {Mao , Keming and Lu , Duo and E , Dazhi and Tan , Zhenhua},
TITLE = {A Case Study on Attribute Recognition of Heated Metal Mark Image Using Deep Convolutional Neural Networks},
JOURNAL = {Sensors},
VOLUME = {18},
YEAR = {2018},
NUMBER = {6},
ARTICLE-NUMBER = {1871},
URL = {https://www.mdpi.com/1424-8220/18/6/1871},
ISSN = {1424-8220},
ABSTRACT = {Heated metal mark is an important trace to identify the cause of fire. However, traditional methods mainly focus on the knowledge of physics and chemistry for qualitative analysis and make it still a challenging problem. This paper presents a case study on attribute recognition of the heated metal mark image using computer vision and machine learning technologies. The proposed work is composed of three parts. Material is first generated. According to national standards, actual needs and feasibility, seven attributes are selected for research. Data generation and organization are conducted, and a small size benchmark dataset is constructed. A recognition model is then implemented. Feature representation and classifier construction methods are introduced based on deep convolutional neural networks. Finally, the experimental evaluation is carried out. Multi-aspect testings are performed with various model structures, data augments, training modes, optimization methods and batch sizes. The influence of parameters, recognitio efficiency and execution time are also analyzed. The results show that with a fine-tuned model, the recognition rate of attributes metal type, heating mode, heating temperature, heating duration, cooling mode, placing duration and relative humidity are 0.925, 0.908, 0.835, 0.917, 0.928, 0.805 and 0.92, respectively. The proposed method recognizes the attribute of heated metal mark with preferable effect, and it can be used in practical application.},
DOI = {10.3390/s18061871}
}



@Article{s18061881,
AUTHOR = {Kim, In-Ho and Jeon, Haemin and Baek, Seung-Chan and Hong, Won-Hwa and Jung, Hyung-Jo},
TITLE = {Application of Crack Identification Techniques for an Aging Concrete Bridge Inspection Using an Unmanned Aerial Vehicle},
JOURNAL = {Sensors},
VOLUME = {18},
YEAR = {2018},
NUMBER = {6},
ARTICLE-NUMBER = {1881},
URL = {https://www.mdpi.com/1424-8220/18/6/1881},
ISSN = {1424-8220},
ABSTRACT = {Bridge inspection using unmanned aerial vehicles (UAV) with high performance vision sensors has received considerable attention due to its safety and reliability. As bridges become obsolete, the number of bridges that need to be inspected increases, and they require much maintenance cost. Therefore, a bridge inspection method based on UAV with vision sensors is proposed as one of the promising strategies to maintain bridges. In this paper, a crack identification method by using a commercial UAV with a high resolution vision sensor is investigated in an aging concrete bridge. First, a point cloud-based background model is generated in the preliminary flight. Then, cracks on the structural surface are detected with the deep learning algorithm, and their thickness and length are calculated. In the deep learning method, region with convolutional neural networks (R-CNN)-based transfer learning is applied. As a result, a new network for the 384 collected crack images of 256 &times; 256 pixel resolution is generated from the pre-trained network. A field test is conducted to verify the proposed approach, and the experimental results proved that the UAV-based bridge inspection is effective at identifying and quantifying the cracks on the structures.},
DOI = {10.3390/s18061881}
}



@Article{designs2020019,
AUTHOR = {Angelini, Gino and Bonanni, Tommaso and Corsini, Alessandro and Delibra, Giovanni and Tieghi, Lorenzo and Volponi, David},
TITLE = {On Surrogate-Based Optimization of Truly Reversible Blade Profiles for Axial Fans},
JOURNAL = {Designs},
VOLUME = {2},
YEAR = {2018},
NUMBER = {2},
ARTICLE-NUMBER = {19},
URL = {https://www.mdpi.com/2411-9660/2/2/19},
ISSN = {2411-9660},
ABSTRACT = {Open literature offers a wide canvas of techniques for surrogate-based multi-objective optimization. The large majority of works focus on methodological and theoretical aspects and are applied to simple mathematical functions. The present work aims at defining and assessing surrogate-based techniques used in complex optimization problems pertinent to the aerodynamics of reversible aerofoils. Specifically, it addresses the following questions: how meta-model techniques affect the results of the multi-objective optimization problem, and how these meta-models should be exploited in an optimization test-bed. The multi-objective optimization problem (MOOP) is solved using genetic optimization based on non-dominated sorting genetic algorithm (NSGA)-II. The paper explores the possibility to reduce the computational cost of multi-objective evolutionary algorithms (MOEA) using two different surrogate models (SM): a least square method (LSM), and an artificial neural network (ANN). SMs were tested in two optimization approaches with different levels of computational effort. In the end, the paper provides a critical analysis of the results obtained with the methodologies under scrutiny and the impact of SMs on MOEA. The results demonstrate how surrogate model incorporation into MOEAs influences the effectiveness of the optimization process itself, and establish a methodology for aerodynamic optimization tasks in the fan industry.},
DOI = {10.3390/designs2020019}
}



@Article{s18071985,
AUTHOR = {Wang, Ruihua and Xiao, Xiongwu and Guo, Bingxuan and Qin, Qianqing and Chen, Ruizhi},
TITLE = {An Effective Image Denoising Method for UAV Images via Improved Generative Adversarial Networks},
JOURNAL = {Sensors},
VOLUME = {18},
YEAR = {2018},
NUMBER = {7},
ARTICLE-NUMBER = {1985},
URL = {https://www.mdpi.com/1424-8220/18/7/1985},
ISSN = {1424-8220},
ABSTRACT = {Unmanned aerial vehicles (UAVs) are an inexpensive platform for collecting remote sensing images, but UAV images suffer from a content loss problem caused by noise. In order to solve the noise problem of UAV images, we propose a new methods to denoise UAV images. This paper introduces a novel deep neural network method based on generative adversarial learning to trace the mapping relationship between noisy and clean images. In our approach, perceptual reconstruction loss is used to establish a loss equation that continuously optimizes a min-max game theoretic model to obtain better UAV image denoising results. The generated denoised images by the proposed method enjoy clearer ground objects edges and more detailed textures of ground objects. In addition to the traditional comparison method, denoised UAV images and corresponding original clean UAV images were employed to perform image matching based on local features. At the same time, the classification experiment on the denoised images was also conducted to compare the denoising results of UAV images with others. The proposed method had achieved better results in these comparison experiments.},
DOI = {10.3390/s18071985}
}



@Article{robotics7030032,
AUTHOR = {Leite, André and Pinto, Andry and Matos, Aníbal},
TITLE = {A Safety Monitoring Model for a Faulty Mobile Robot},
JOURNAL = {Robotics},
VOLUME = {7},
YEAR = {2018},
NUMBER = {3},
ARTICLE-NUMBER = {32},
URL = {https://www.mdpi.com/2218-6581/7/3/32},
ISSN = {2218-6581},
ABSTRACT = {The continued development of mobile robots (MR) must be accompanied by an increase in robotics&rsquo; safety measures. Not only must MR be capable of detecting and diagnosing faults, they should also be capable of understanding when the dangers of a mission, to themselves and the surrounding environment, warrant the abandonment of their endeavors. Analysis of fault detection and diagnosis techniques helps shed light on the challenges of the robotic field, while also showing a lack of research in autonomous decision-making tools. This paper proposes a new skill-based architecture for mobile robots, together with a novel risk assessment and decision-making model to overcome the difficulties currently felt in autonomous robot design.},
DOI = {10.3390/robotics7030032}
}



@Article{s18072013,
AUTHOR = {Zhou, Yi and Zhang, Rui and Wang, Shixin and Wang, Futao},
TITLE = {Feature Selection Method Based on High-Resolution Remote Sensing Images and the Effect of Sensitive Features on Classification Accuracy},
JOURNAL = {Sensors},
VOLUME = {18},
YEAR = {2018},
NUMBER = {7},
ARTICLE-NUMBER = {2013},
URL = {https://www.mdpi.com/1424-8220/18/7/2013},
ISSN = {1424-8220},
ABSTRACT = {With the advent of high spatial resolution remote sensing imagery, numerous image features can be utilized. Applying a reasonable feature selection approach is critical to effectively reduce feature redundancy and improve the efficiency and accuracy of classification. This paper proposes a novel feature selection approach, in which ReliefF, genetic algorithm, and support vector machine (RFGASVM) are integrated to extract buildings. We adopt the ReliefF algorithm to preliminary filter high-dimensional features in the feature database. After eliminating the sorted features, the feature subset and the C and &gamma; parameters of support vector machine (SVM) are encoded into the chromosome of the genetic algorithm. A fitness function is constructed considering the sample identification accuracy, the number of selected features, and the feature cost. The proposed method was applied to high-resolution images obtained from different sensors, GF-2, BJ-2, and unmanned aerial vehicles (UAV). The confusion matrix, precision, recall and F1-score were applied to assess the accuracy. The results showed that the proposed method achieved feature reduction, and the overall accuracy (OA) was more than 85%, with Kappa coefficient values of 0.80, 0.83 and 0.85, respectively. The precision of each image was more than 85%. The time efficiency of the proposed method was two-fold greater than SVM with all the features. The RFGASVM method has the advantages of large feature reduction and high extraction performance and can be applied in feature selection.},
DOI = {10.3390/s18072013}
}



@Article{app8071028,
AUTHOR = {Wu, Yunpeng and Qin, Yong and Wang, Zhipeng and Jia, Limin},
TITLE = {A UAV-Based Visual Inspection Method for Rail Surface Defects},
JOURNAL = {Applied Sciences},
VOLUME = {8},
YEAR = {2018},
NUMBER = {7},
ARTICLE-NUMBER = {1028},
URL = {https://www.mdpi.com/2076-3417/8/7/1028},
ISSN = {2076-3417},
ABSTRACT = {Rail surface defects seriously affect the safety of railway systems. At present, human inspection and rail vehicle inspection are the main approaches for the detection of rail surface defects. However, there are many shortcomings to these approaches, such as low efficiency, high cost, and so on. This paper presents a novel visual inspection approach based on unmanned aerial vehicle (UAV) images, and focuses on two key issues of UAV-based rail images: image enhancement and defects segmentation. With regards to the first aspect, a novel image enhancement algorithm named Local Weber-like Contrast (LWLC) is proposed to enhance rail images. The rail surface defects and backgrounds can be highlighted and homogenized under various sunlight intensity by LWLC, due to its illuminance independent, local nonlinear and other advantages. With regards to the second, a new threshold segmentation method named gray stretch maximum entropy (GSME) is presented in this paper. The proposed GSME method emphasizes gray stretch and de-noising on UAV-based rail images, and selects an optimal segmentation threshold for defects detection. Two visual comparison experiments were carried out to demonstrate the efficiency of the proposed methods. Finally, a quantitative comparison experiment shows the LWLC-GSME model achieves a recall of 93.75% for T-I defects and of 94.26% for T-II defects. Therefore, LWLC for image enhancement, in conjunction with GSME for defects segmentation, is efficient and feasible for the detection of rail surface defects based on UAV Images.},
DOI = {10.3390/app8071028}
}



@Article{s18072048,
AUTHOR = {Rivas, Alberto and Chamoso, Pablo and González-Briones, Alfonso and Corchado, Juan Manuel},
TITLE = {Detection of Cattle Using Drones and Convolutional Neural Networks},
JOURNAL = {Sensors},
VOLUME = {18},
YEAR = {2018},
NUMBER = {7},
ARTICLE-NUMBER = {2048},
URL = {https://www.mdpi.com/1424-8220/18/7/2048},
ISSN = {1424-8220},
ABSTRACT = {Multirotor drones have been one of the most important technological advances of the last decade. Their mechanics are simple compared to other types of drones and their possibilities in flight are greater. For example, they can take-off vertically. Their capabilities have therefore brought progress to many professional activities. Moreover, advances in computing and telecommunications have also broadened the range of activities in which drones may be used. Currently, artificial intelligence and information analysis are the main areas of research in the field of computing. The case study presented in this article employed artificial intelligence techniques in the analysis of information captured by drones. More specifically, the camera installed in the drone took images which were later analyzed using Convolutional Neural Networks (CNNs) to identify the objects captured in the images. In this research, a CNN was trained to detect cattle, however the same training process could be followed to develop a CNN for the detection of any other object. This article describes the design of the platform for real-time analysis of information and its performance in the detection of cattle.},
DOI = {10.3390/s18072048}
}



@Article{s18072071,
AUTHOR = {Guerra, Edmundo and Munguía, Rodrigo and Grau, Antoni},
TITLE = {UAV Visual and Laser Sensors Fusion for Detection and Positioning in Industrial Applications},
JOURNAL = {Sensors},
VOLUME = {18},
YEAR = {2018},
NUMBER = {7},
ARTICLE-NUMBER = {2071},
URL = {https://www.mdpi.com/1424-8220/18/7/2071},
ISSN = {1424-8220},
ABSTRACT = {This work presents a solution to localize Unmanned Autonomous Vehicles with respect to pipes and other cylindrical elements found in inspection and maintenance tasks both in industrial and civilian infrastructures. The proposed system exploits the different features of vision and laser based sensors, combining them to obtain accurate positioning of the robot with respect to the cylindrical structures. A probabilistic (RANSAC-based) procedure is used to segment possible cylinders found in the laser scans, and this is used as a seed to accurately determine the robot position through a computer vision system. The priors obtained from the laser scan registration help to solve the problem of determining the apparent contour of the cylinders. In turn this apparent contour is used in a degenerate quadratic conic estimation, enabling to visually estimate the pose of the cylinder.},
DOI = {10.3390/s18072071}
}



@Article{s18072113,
AUTHOR = {Huang, Huasheng and Lan, Yubin and Deng, Jizhong and Yang, Aqing and Deng, Xiaoling and Zhang, Lei and Wen, Sheng},
TITLE = {A Semantic Labeling Approach for Accurate Weed Mapping of High Resolution UAV Imagery},
JOURNAL = {Sensors},
VOLUME = {18},
YEAR = {2018},
NUMBER = {7},
ARTICLE-NUMBER = {2113},
URL = {https://www.mdpi.com/1424-8220/18/7/2113},
ISSN = {1424-8220},
ABSTRACT = {Weed control is necessary in rice cultivation, but the excessive use of herbicide treatments has led to serious agronomic and environmental problems. Suitable site-specific weed management (SSWM) is a solution to address this problem while maintaining the rice production quality and quantity. In the context of SSWM, an accurate weed distribution map is needed to provide decision support information for herbicide treatment. UAV remote sensing offers an efficient and effective platform to monitor weeds thanks to its high spatial resolution. In this work, UAV imagery was captured in a rice field located in South China. A semantic labeling approach was adopted to generate the weed distribution maps of the UAV imagery. An ImageNet pre-trained CNN with residual framework was adapted in a fully convolutional form, and transferred to our dataset by fine-tuning. Atrous convolution was applied to extend the field of view of convolutional filters; the performance of multi-scale processing was evaluated; and a fully connected conditional random field (CRF) was applied after the CNN to further refine the spatial details. Finally, our approach was compared with the pixel-based-SVM and the classical FCN-8s. Experimental results demonstrated that our approach achieved the best performance in terms of accuracy. Especially for the detection of small weed patches in the imagery, our approach significantly outperformed other methods. The mean intersection over union (mean IU), overall accuracy, and Kappa coefficient of our method were 0.7751, 0.9445, and 0.9128, respectively. The experiments showed that our approach has high potential in accurate weed mapping of UAV imagery.},
DOI = {10.3390/s18072113}
}



@Article{sym10070250,
AUTHOR = {Le, Tuong and Hoang Son, Le and Vo, Minh Thanh and Lee, Mi Young and Baik, Sung Wook},
TITLE = {A Cluster-Based Boosting Algorithm for Bankruptcy Prediction in a Highly Imbalanced Dataset},
JOURNAL = {Symmetry},
VOLUME = {10},
YEAR = {2018},
NUMBER = {7},
ARTICLE-NUMBER = {250},
URL = {https://www.mdpi.com/2073-8994/10/7/250},
ISSN = {2073-8994},
ABSTRACT = {Bankruptcy prediction has been a popular and challenging research topic in both computer science and economics due to its importance to financial institutions, fund managers, lenders, governments, as well as economic stakeholders in recent years. In a bankruptcy dataset, the problem of class imbalance, in which the number of bankruptcy companies is smaller than the number of normal companies, leads to a standard classification algorithm that does not work well. Therefore, this study proposes a cluster-based boosting algorithm as well as a robust framework using the CBoost algorithm and Instance Hardness Threshold (RFCI) for effective bankruptcy prediction of a financial dataset. This framework first resamples the imbalance dataset by the undersampling method using Instance Hardness Threshold (IHT), which is used to remove the noise instances having large IHT value in the majority class. Then, this study proposes a Cluster-based Boosting algorithm, namely CBoost, for dealing with the class imbalance. In this algorithm, the majority class will be clustered into a number of clusters. The distance from each sample to its closest centroid will be used to initialize its weight. This algorithm will perform several iterations for finding weak classifiers and combining them to create a strong classifier. The resample set resulting from the previous module, will be used to train CBoost, which will be used to predict bankruptcy for the validation set. The proposed framework is verified by the Korean bankruptcy dataset (KBD), which has a very small balancing ratio in both the training and the testing phases. The experimental results of this research show that the proposed framework achieves 86.8% in AUC (area under the ROC curve) and outperforms several methods for dealing with the imbalanced data problem for bankruptcy prediction such as GMBoost algorithm, the oversampling-based method using SMOTEENN, and the clustering-based undersampling method for bankruptcy prediction in the experimental dataset.},
DOI = {10.3390/sym10070250}
}



@Article{rs10071041,
AUTHOR = {Guo, Xingjian and Shao, Quanqin and Li, Yuzhe and Wang, Yangchun and Wang, Dongliang and Liu, Jiyuan and Fan, Jiangwen and Yang, Fan},
TITLE = {Application of UAV Remote Sensing for a Population Census of Large Wild Herbivores—Taking the Headwater Region of the Yellow River as an Example},
JOURNAL = {Remote Sensing},
VOLUME = {10},
YEAR = {2018},
NUMBER = {7},
ARTICLE-NUMBER = {1041},
URL = {https://www.mdpi.com/2072-4292/10/7/1041},
ISSN = {2072-4292},
ABSTRACT = {We used unmanned aerial vehicles (UAVs) to carry out a relatively complete population census of large wild herbivores in Maduo County on the Tibetan Plateau in the spring of 2017. The effective area covered by aerial surveys was 326.6 km2, and 23,784 images were acquired. Interpretation tag libraries for UAV images were created for wild animals, including Kiang (Equus kiang), Tibetan gazelle (Procapra picticaudata), and blue sheep (Pseudois nayaur), as well as livestock, including yaks and Tibetan sheep. Large wild herbivores in the survey transect were identified through manual imagery interpretation. Densities ranged from 1.15/km2 for Kiang, 0.61/km2 for Tibetan gazelle, 0.62/km2 for blue sheep, 4.12/km2 for domestic yak, and 7.34/km2 for domestic sheep. A method based on meadows in the cold and warm seasons was used for estimating the densities and numbers of large wild herbivores and livestock, and was verified against records of livestock numbers. Population estimates for Kiang, Tibetan gazelle, blue sheep, domestic yak, and domestic sheep were 17,109, 15,961, 9324, 70,846, and 102,194, respectively. Based on published consumption estimates, the results suggest that domestic stock consume 4.5 times the amount of vegetation of large wild herbivores. Compared with traditional ground survey methods, performance of UAV remote sensing surveys of large wild herbivore populations was fast, economical and reliable, providing an effective future method for surveying wild animals.},
DOI = {10.3390/rs10071041}
}



@Article{geosciences8070244,
AUTHOR = {Buscombe, Daniel and Ritchie, Andrew C.},
TITLE = {Landscape Classification with Deep Neural Networks},
JOURNAL = {Geosciences},
VOLUME = {8},
YEAR = {2018},
NUMBER = {7},
ARTICLE-NUMBER = {244},
URL = {https://www.mdpi.com/2076-3263/8/7/244},
ISSN = {2076-3263},
ABSTRACT = {The application of deep learning, specifically deep convolutional neural networks (DCNNs), to the classification of remotely-sensed imagery of natural landscapes has the potential to greatly assist in the analysis and interpretation of geomorphic processes. However, the general usefulness of deep learning applied to conventional photographic imagery at a landscape scale is, at yet, largely unproven. If DCNN-based image classification is to gain wider application and acceptance within the geoscience community, demonstrable successes need to be coupled with accessible tools to retrain deep neural networks to discriminate landforms and land uses in landscape imagery. Here, we present an efficient approach to train/apply DCNNs with/on sets of photographic images, using a powerful graphical method called a conditional random field (CRF), to generate DCNN training and testing data using minimal manual supervision. We apply the method to several sets of images of natural landscapes, acquired from satellites, aircraft, unmanned aerial vehicles, and fixed camera installations. We synthesize our findings to examine the general effectiveness of transfer learning to landscape-scale image classification. Finally, we show how DCNN predictions on small regions of images might be used in conjunction with a CRF for highly accurate pixel-level classification of images.},
DOI = {10.3390/geosciences8070244}
}



@Article{s18072184,
AUTHOR = {Ismail, Adiel and Bagula, Bigomokero Antoine and Tuyishimire, Emmanuel},
TITLE = {Internet-Of-Things in Motion: A UAV Coalition Model for Remote Sensing in Smart Cities},
JOURNAL = {Sensors},
VOLUME = {18},
YEAR = {2018},
NUMBER = {7},
ARTICLE-NUMBER = {2184},
URL = {https://www.mdpi.com/1424-8220/18/7/2184},
ISSN = {1424-8220},
ABSTRACT = {Unmanned aerial vehicles (UAVs) or drones are increasingly used in cities to provide service tasks that are too dangerous, expensive or difficult for human beings. Drones are also used in cases where a task can be performed more economically and or more efficiently than if done by humans. These include remote sensing tasks where drones can be required to form coalitions by pooling their resources to meet the service requirements at different locations of interest in a city. During such coalition formation, finding the shortest path from a source to a location of interest is key to efficient service delivery. For fixed-wing UAVs, Dubins curves can be applied to find the shortest flight path. When a UAV flies to a location of interest, the angle or orientation of the UAV upon its arrival is often not important. In such a case, a simplified version of the Dubins curve consisting of two instead of three parts can be used. This paper proposes a novel model for UAV coalition and an algorithm derived from basic geometry that generates a path derived from the original Dubins curve for application in remote sensing missions of fixed-wing UAVs. The algorithm is tested by incorporating it into three cooperative coalition formation algorithms. The performance of the model is evaluated by varying the number of types of resources and the sensor ranges of the UAVs to reveal the relevance and practicality of the proposed model.},
DOI = {10.3390/s18072184}
}



@Article{s18072194,
AUTHOR = {Bachmann, Daniel and Weichert, Frank and Rinkenauer, Gerhard},
TITLE = {Review of Three-Dimensional Human-Computer Interaction with Focus on the Leap Motion Controller},
JOURNAL = {Sensors},
VOLUME = {18},
YEAR = {2018},
NUMBER = {7},
ARTICLE-NUMBER = {2194},
URL = {https://www.mdpi.com/1424-8220/18/7/2194},
ISSN = {1424-8220},
ABSTRACT = {Modern hardware and software development has led to an evolution of user interfaces from command-line to natural user interfaces for virtual immersive environments. Gestures imitating real-world interaction tasks increasingly replace classical two-dimensional interfaces based on Windows/Icons/Menus/Pointers (WIMP) or touch metaphors. Thus, the purpose of this paper is to survey the state-of-the-art Human-Computer Interaction (HCI) techniques with a focus on the special field of three-dimensional interaction. This includes an overview of currently available interaction devices, their applications of usage and underlying methods for gesture design and recognition. Focus is on interfaces based on the Leap Motion Controller (LMC) and corresponding methods of gesture design and recognition. Further, a review of evaluation methods for the proposed natural user interfaces is given.},
DOI = {10.3390/s18072194}
}



@Article{s18072244,
AUTHOR = {De Oliveira, Diulhio Candido and Wehrmeister, Marco Aurelio},
TITLE = {Using Deep Learning and Low-Cost RGB and Thermal Cameras to Detect Pedestrians in Aerial Images Captured by Multirotor UAV},
JOURNAL = {Sensors},
VOLUME = {18},
YEAR = {2018},
NUMBER = {7},
ARTICLE-NUMBER = {2244},
URL = {https://www.mdpi.com/1424-8220/18/7/2244},
ISSN = {1424-8220},
ABSTRACT = {The use of Unmanned Aerial Vehicles (UAV) has been increasing over the last few years in many sorts of applications due mainly to the decreasing cost of this technology. One can see the use of the UAV in several civilian applications such as surveillance and search and rescue. Automatic detection of pedestrians in aerial images is a challenging task. The computing vision system must deal with many sources of variability in the aerial images captured with the UAV, e.g., low-resolution images of pedestrians, images captured at distinct angles due to the degrees of freedom that a UAV can move, the camera platform possibly experiencing some instability while the UAV flies, among others. In this work, we created and evaluated different implementations of Pattern Recognition Systems (PRS) aiming at the automatic detection of pedestrians in aerial images captured with multirotor UAV. The main goal is to assess the feasibility and suitability of distinct PRS implementations running on top of low-cost computing platforms, e.g., single-board computers such as the Raspberry Pi or regular laptops without a GPU. For that, we used four machine learning techniques in the feature extraction and classification steps, namely Haar cascade, LBP cascade, HOG + SVM and Convolutional Neural Networks (CNN). In order to improve the system performance (especially the processing time) and also to decrease the rate of false alarms, we applied the Saliency Map (SM) and Thermal Image Processing (TIP) within the segmentation and detection steps of the PRS. The classification results show the CNN to be the best technique with 99.7% accuracy, followed by HOG + SVM with 92.3%. In situations of partial occlusion, the CNN showed 71.1% sensitivity, which can be considered a good result in comparison with the current state-of-the-art, since part of the original image data is missing. As demonstrated in the experiments, by combining TIP with CNN, the PRS can process more than two frames per second (fps), whereas the PRS that combines TIP with HOG + SVM was able to process 100 fps. It is important to mention that our experiments show that a trade-off analysis must be performed during the design of a pedestrian detection PRS. The faster implementations lead to a decrease in the PRS accuracy. For instance, by using HOG + SVM with TIP, the PRS presented the best performance results, but the obtained accuracy was 35 percentage points lower than the CNN. The obtained results indicate that the best detection technique (i.e., the CNN) requires more computational resources to decrease the PRS computation time. Therefore, this work shows and discusses the pros/cons of each technique and trade-off situations, and hence, one can use such an analysis to improve and tailor the design of a PRS to detect pedestrians in aerial images.},
DOI = {10.3390/s18072244}
}



@Article{rs10071120,
AUTHOR = {Lausch, Angela and Borg, Erik and Bumberger, Jan and Dietrich, Peter and Heurich, Marco and Huth, Andreas and Jung, András and Klenke, Reinhard and Knapp, Sonja and Mollenhauer, Hannes and Paasche, Hendrik and Paulheim, Heiko and Pause, Marion and Schweitzer, Christian and Schmulius, Christiane and Settele, Josef and Skidmore, Andrew K. and Wegmann, Martin and Zacharias, Steffen and Kirsten, Toralf and Schaepman, Michael E.},
TITLE = {Understanding Forest Health with Remote Sensing, Part III: Requirements for a Scalable Multi-Source Forest Health Monitoring Network Based on Data Science Approaches},
JOURNAL = {Remote Sensing},
VOLUME = {10},
YEAR = {2018},
NUMBER = {7},
ARTICLE-NUMBER = {1120},
URL = {https://www.mdpi.com/2072-4292/10/7/1120},
ISSN = {2072-4292},
ABSTRACT = {Forest ecosystems fulfill a whole host of ecosystem functions that are essential for life on our planet. However, an unprecedented level of anthropogenic influences is reducing the resilience and stability of our forest ecosystems as well as their ecosystem functions. The relationships between drivers, stress, and ecosystem functions in forest ecosystems are complex, multi-faceted, and often non-linear, and yet forest managers, decision makers, and politicians need to be able to make rapid decisions that are data-driven and based on short and long-term monitoring information, complex modeling, and analysis approaches. A huge number of long-standing and standardized forest health inventory approaches already exist, and are increasingly integrating remote-sensing based monitoring approaches. Unfortunately, these approaches in monitoring, data storage, analysis, prognosis, and assessment still do not satisfy the future requirements of information and digital knowledge processing of the 21st century. Therefore, this paper discusses and presents in detail five sets of requirements, including their relevance, necessity, and the possible solutions that would be necessary for establishing a feasible multi-source forest health monitoring network for the 21st century. Namely, these requirements are: (1) understanding the effects of multiple stressors on forest health; (2) using remote sensing (RS) approaches to monitor forest health; (3) coupling different monitoring approaches; (4) using data science as a bridge between complex and multidimensional big forest health (FH) data; and (5) a future multi-source forest health monitoring network. It became apparent that no existing monitoring approach, technique, model, or platform is sufficient on its own to monitor, model, forecast, or assess forest health and its resilience. In order to advance the development of a multi-source forest health monitoring network, we argue that in order to gain a better understanding of forest health in our complex world, it would be conducive to implement the concepts of data science with the components: (i) digitalization; (ii) standardization with metadata management after the FAIR (Findability, Accessibility, Interoperability, and Reusability) principles; (iii) Semantic Web; (iv) proof, trust, and uncertainties; (v) tools for data science analysis; and (vi) easy tools for scientists, data managers, and stakeholders for decision-making support.},
DOI = {10.3390/rs10071120}
}



@Article{s18072386,
AUTHOR = {Liu, Chunsheng and Li, Shuang and Chang, Faliang and Dong, Wenhui},
TITLE = {Supplemental Boosting and Cascaded ConvNet Based Transfer Learning Structure for Fast Traffic Sign Detection in Unknown Application Scenes},
JOURNAL = {Sensors},
VOLUME = {18},
YEAR = {2018},
NUMBER = {7},
ARTICLE-NUMBER = {2386},
URL = {https://www.mdpi.com/1424-8220/18/7/2386},
ISSN = {1424-8220},
ABSTRACT = {With rapid calculation speed and relatively high accuracy, the AdaBoost-based detection framework has been successfully applied in some real applications of machine vision-based intelligent systems. The main shortcoming of the AdaBoost-based detection framework is that the off-line trained detector cannot be transfer retrained to adapt to unknown application scenes. In this paper, a new transfer learning structure based on two novel methods of supplemental boosting and cascaded ConvNet is proposed to address this shortcoming. The supplemental boosting method is proposed to supplementally retrain an AdaBoost-based detector for the purpose of transferring a detector to adapt to unknown application scenes. The cascaded ConvNet is designed and attached to the end of the AdaBoost-based detector for improving the detection rate and collecting supplemental training samples. With the added supplemental training samples provided by the cascaded ConvNet, the AdaBoost-based detector can be retrained with the supplemental boosting method. The detector combined with the retrained boosted detector and cascaded ConvNet detector can achieve high accuracy and a short detection time. As a representative object detection problem in intelligent transportation systems, the traffic sign detection problem is chosen to show our method. Through experiments with the public datasets from different countries, we show that the proposed framework can quickly detect objects in unknown application scenes.},
DOI = {10.3390/s18072386}
}



@Article{robotics7030040,
AUTHOR = {Nafia, Nabil and El Kari, Abdeljalil and Ayad, Hassan and Mjahed, Mostafa},
TITLE = {Robust Interval Type-2 Fuzzy Sliding Mode Control Design for Robot Manipulators},
JOURNAL = {Robotics},
VOLUME = {7},
YEAR = {2018},
NUMBER = {3},
ARTICLE-NUMBER = {40},
URL = {https://www.mdpi.com/2218-6581/7/3/40},
ISSN = {2218-6581},
ABSTRACT = {This paper develops a new robust tracking control design for n-link robot manipulators with dynamic uncertainties, and unknown disturbances. The procedure is conducted by designing two adaptive interval type-2 fuzzy logic systems (AIT2-FLSs) to better approximate the parametric uncertainties on the system nominal. Then, in order to achieve the best tracking control performance and to enhance the system robustness against approximation errors and unknown disturbances, a new control algorithm, which uses a new synthesized AIT2 fuzzy sliding mode control (AIT2-FSMC) law, has been proposed. To deal with the chattering phenomenon without deteriorating the system robustness, the AIT2-FSMC has been designed so as to generate three adaptive control laws that provide the optimal gains value of the global control law. The adaptation laws have been designed in the sense of the Lyapunov stability theorem. Mathematical proof shows that the closed loop control system is globally asymptotically stable. Finally, a 2-link robot manipulator is used as case study to illustrate the effectiveness of the proposed control approach.},
DOI = {10.3390/robotics7030040}
}



@Article{data3030028,
AUTHOR = {Gopalakrishnan, Kasthurirangan},
TITLE = {Deep Learning in Data-Driven Pavement Image Analysis and Automated Distress Detection: A Review},
JOURNAL = {Data},
VOLUME = {3},
YEAR = {2018},
NUMBER = {3},
ARTICLE-NUMBER = {28},
URL = {https://www.mdpi.com/2306-5729/3/3/28},
ISSN = {2306-5729},
ABSTRACT = {Deep learning, more specifically deep convolutional neural networks, is fast becoming a popular choice for computer vision-based automated pavement distress detection. While pavement image analysis has been extensively researched over the past three decades or so, recent ground-breaking achievements of deep learning algorithms in the areas of machine translation, speech recognition, and computer vision has sparked interest in the application of deep learning to automated detection of distresses in pavement images. This paper provides a narrative review of recently published studies in this field, highlighting the current achievements and challenges. A comparison of the deep learning software frameworks, network architecture, hyper-parameters employed by each study, and crack detection performance is provided, which is expected to provide a good foundation for driving further research on this important topic in the context of smart pavement or asset management systems. The review concludes with potential avenues for future research; especially in the application of deep learning to not only detect, but also characterize the type, extent, and severity of distresses from 2D and 3D pavement images.},
DOI = {10.3390/data3030028}
}



@Article{ijgi7080294,
AUTHOR = {Chabot, Dominique and Dillon, Christopher and Shemrock, Adam and Weissflog, Nicholas and Sager, Eric P. S.},
TITLE = {An Object-Based Image Analysis Workflow for Monitoring Shallow-Water Aquatic Vegetation in Multispectral Drone Imagery},
JOURNAL = {ISPRS International Journal of Geo-Information},
VOLUME = {7},
YEAR = {2018},
NUMBER = {8},
ARTICLE-NUMBER = {294},
URL = {https://www.mdpi.com/2220-9964/7/8/294},
ISSN = {2220-9964},
ABSTRACT = {High-resolution drone aerial surveys combined with object-based image analysis are transforming our capacity to monitor and manage aquatic vegetation in an era of invasive species. To better exploit the potential of these technologies, there is a need to develop more efficient and accessible analysis workflows and focus more efforts on the distinct challenge of mapping submerged vegetation. We present a straightforward workflow developed to monitor emergent and submerged invasive water soldier (Stratiotes aloides) in shallow waters of the Trent-Severn Waterway in Ontario, Canada. The main elements of the workflow are: (1) collection of radiometrically calibrated multispectral imagery including a near-infrared band; (2) multistage segmentation of the imagery involving an initial separation of above-water from submerged features; and (3) automated classification of features with a supervised machine-learning classifier. The approach yielded excellent classification accuracy for emergent features (overall accuracy = 92%; kappa = 88%; water soldier producer&rsquo;s accuracy = 92%; user&rsquo;s accuracy = 91%) and good accuracy for submerged features (overall accuracy = 84%; kappa = 75%; water soldier producer&rsquo;s accuracy = 71%; user&rsquo;s accuracy = 84%). The workflow employs off-the-shelf graphical software tools requiring no programming or coding, and could therefore be used by anyone with basic GIS and image analysis skills for a potentially wide variety of aquatic vegetation monitoring operations.},
DOI = {10.3390/ijgi7080294}
}



@Article{s18082424,
AUTHOR = {Zhao, Yong and Du, Jingli and Bao, Hong and Xu, Qian},
TITLE = {Optimal Sensor Placement Based on Eigenvalues Analysis for Sensing Deformation of Wing Frame Using iFEM},
JOURNAL = {Sensors},
VOLUME = {18},
YEAR = {2018},
NUMBER = {8},
ARTICLE-NUMBER = {2424},
URL = {https://www.mdpi.com/1424-8220/18/8/2424},
ISSN = {1424-8220},
ABSTRACT = {For real time monitoring of the wing state, in this paper, the inverse Finite Element Method (iFEM) is applied, which describes the displacement field of beam according to the Timoshenko theory, to sense the wing frame deformation. In order to maintain the accuracy and stability of frame deformation sensing with iFEM, an optimal placement model of strain sensors based on eigenvalue analysis is constructed. Through the model solution with the Particle Swarm Optimization (PSO) algorithm, two different optimal placement schemes of sensors are obtained. Finally, a simulation is performed on a simple cantilever beam and a static load experiment is conducted on an aluminum alloy wing frame. The results demonstrate that the iFEM is able to accurately sense the deformation of the wing frame, when the two optimal placement schemes of sensors are used.},
DOI = {10.3390/s18082424}
}



@Article{app8081269,
AUTHOR = {Seo, Dae Kyo and Kim, Yong Hyun and Eo, Yang Dam and Park, Wan Yong},
TITLE = {Learning-Based Colorization of Grayscale Aerial Images Using Random Forest Regression},
JOURNAL = {Applied Sciences},
VOLUME = {8},
YEAR = {2018},
NUMBER = {8},
ARTICLE-NUMBER = {1269},
URL = {https://www.mdpi.com/2076-3417/8/8/1269},
ISSN = {2076-3417},
ABSTRACT = {Image colorization assigns colors to a grayscale image, which is an important yet difficult image-processing task encountered in various applications. In particular, grayscale aerial image colorization is a poorly posed problem that is affected by the sun elevation angle, seasons, sensor parameters, etc. Furthermore, since different colors may have the same intensity, it is difficult to solve this problem using traditional methods. This study proposes a novel method for the colorization of grayscale aerial images using random forest (RF) regression. The algorithm uses one grayscale image for input and one-color image for reference, both of which have similar seasonal features at the same location. The reference color image is then converted from the Red-Green-Blue (RGB) color space to the CIE L*a*b (Lab) color space in which the luminance is used to extract training pixels; this is done by performing change detection with the input grayscale image, and color information is used to establish color relationships. The proposed method directly establishes color relationships between features of the input grayscale image and color information of the reference color image based on the corresponding training pixels. The experimental results show that the proposed method outperforms several state-of-the-art algorithms in terms of both visual inspection and quantitative evaluation.},
DOI = {10.3390/app8081269}
}



@Article{s18082484,
AUTHOR = {Zhang, Weixing and Witharana, Chandi and Li, Weidong and Zhang, Chuanrong and Li, Xiaojiang and Parent, Jason},
TITLE = {Using Deep Learning to Identify Utility Poles with Crossarms and Estimate Their Locations from Google Street View Images},
JOURNAL = {Sensors},
VOLUME = {18},
YEAR = {2018},
NUMBER = {8},
ARTICLE-NUMBER = {2484},
URL = {https://www.mdpi.com/1424-8220/18/8/2484},
ISSN = {1424-8220},
ABSTRACT = {Traditional methods of detecting and mapping utility poles are inefficient and costly because of the demand for visual interpretation with quality data sources or intense field inspection. The advent of deep learning for object detection provides an opportunity for detecting utility poles from side-view optical images. In this study, we proposed using a deep learning-based method for automatically mapping roadside utility poles with crossarms (UPCs) from Google Street View (GSV) images. The method combines the state-of-the-art DL object detection algorithm (i.e., the RetinaNet object detection algorithm) and a modified brute-force-based line-of-bearing (LOB, a LOB stands for the ray towards the location of the target [UPC at here] from the original location of the sensor [GSV mobile platform]) measurement method to estimate the locations of detected roadside UPCs from GSV. Experimental results indicate that: (1) both the average precision (AP) and the overall accuracy (OA) are around 0.78 when the intersection-over-union (IoU) threshold is greater than 0.3, based on the testing of 500 GSV images with a total number of 937 objects; and (2) around 2.6%, 47%, and 79% of estimated locations of utility poles are within 1 m, 5 m, and 10 m buffer zones, respectively, around the referenced locations of utility poles. In general, this study indicates that even in a complex background, most utility poles can be detected with the use of DL, and the LOB measurement method can estimate the locations of most UPCs.},
DOI = {10.3390/s18082484}
}



@Article{s18082488,
AUTHOR = {Crispoltoni, Michele and Fravolini, Mario Luca and Balzano, Fabio and D’Urso, Stephane and Napolitano, Marcello Rosario},
TITLE = {Interval Fuzzy Model for Robust Aircraft IMU Sensors Fault Detection},
JOURNAL = {Sensors},
VOLUME = {18},
YEAR = {2018},
NUMBER = {8},
ARTICLE-NUMBER = {2488},
URL = {https://www.mdpi.com/1424-8220/18/8/2488},
ISSN = {1424-8220},
ABSTRACT = {This paper proposes a data-based approach for a robust fault detection (FD) of the inertial measurement unit (IMU) sensors of an aircraft. Fuzzy interval models (FIMs) have been introduced for coping with the significant modeling uncertainties caused by poorly modeled aerodynamics. The proposed FIMs are used to compute robust prediction intervals for the measurements provided by the IMU sensors. Specifically, a nonlinear neural network (NN) model is used as central prediction of the sensor response while the uncertainty around the central estimation is captured by the FIM model. The uncertainty has been also modelled using a conventional linear Interval Model (IM) approach; this allows a quantitative evaluation of the benefits provided by the FIM approach. The identification of the IMs and of the FIMs was formalized as a linear matrix inequality (LMI) optimization problem using as cost function the (mean) amplitude of the prediction interval and as optimization variables the parameters defining the amplitudes of the intervals of the IMs and FIMs. Based on the identified models, FD validation tests have been successfully conducted using actual flight data of a P92 Tecnam aircraft by artificially injecting additive fault signals on the fault free IMU readings.},
DOI = {10.3390/s18082488}
}



@Article{rs10081216,
AUTHOR = {Dash, Jonathan P. and Pearse, Grant D. and Watt, Michael S.},
TITLE = {UAV Multispectral Imagery Can Complement Satellite Data for Monitoring Forest Health},
JOURNAL = {Remote Sensing},
VOLUME = {10},
YEAR = {2018},
NUMBER = {8},
ARTICLE-NUMBER = {1216},
URL = {https://www.mdpi.com/2072-4292/10/8/1216},
ISSN = {2072-4292},
ABSTRACT = {The development of methods that can accurately detect physiological stress in forest trees caused by biotic or abiotic factors is vital for ensuring productive forest systems that can meet the demands of the Earth&rsquo;s population. The emergence of new sensors and platforms presents opportunities to augment traditional practices by combining remotely-sensed data products to provide enhanced information on forest condition. We tested the sensitivity of multispectral imagery collected from time-series unmanned aerial vehicle (UAV) and satellite imagery to detect herbicide-induced stress in a carefully controlled experiment carried out in a mature Pinus radiata D. Don plantation. The results revealed that both data sources were sensitive to physiological stress in the study trees. The UAV data were more sensitive to changes at a finer spatial resolution and could detect stress down to the level of individual trees. The satellite data tested could only detect physiological stress in clusters of four or more trees. Resampling the UAV imagery to the same spatial resolution as the satellite imagery revealed that the differences in sensitivity were not solely the result of spatial resolution. Instead, vegetation indices suited to the sensor characteristics of each platform were required to optimise the detection of physiological stress from each data source. Our results define both the spatial detection threshold and the optimum vegetation indices required to implement monitoring of this forest type. A comparison between time-series datasets of different spectral indices showed that the two sensors are compatible and can be used to deliver an enhanced method for monitoring physiological stress in forest trees at various scales. We found that the higher resolution UAV imagery was more sensitive to fine-scale instances of herbicide induced physiological stress than the RapidEye imagery. Although less sensitive to smaller phenomena the satellite imagery was found to be very useful for observing trends in physiological stress over larger areas.},
DOI = {10.3390/rs10081216}
}



@Article{computers7030041,
AUTHOR = {Da Silva, Bruno and Braeken, An and Touhafi, Abdellah},
TITLE = {FPGA-Based Architectures for Acoustic Beamforming with Microphone Arrays: Trends, Challenges and Research Opportunities},
JOURNAL = {Computers},
VOLUME = {7},
YEAR = {2018},
NUMBER = {3},
ARTICLE-NUMBER = {41},
URL = {https://www.mdpi.com/2073-431X/7/3/41},
ISSN = {2073-431X},
ABSTRACT = {Over the past decades, many systems composed of arrays of microphones have been developed to satisfy the quality demanded by acoustic applications. Such microphone arrays are sound acquisition systems composed of multiple microphones used to sample the sound field with spatial diversity. The relatively recent adoption of Field-Programmable Gate Arrays (FPGAs) to manage the audio data samples and to perform the signal processing operations such as filtering or beamforming has lead to customizable architectures able to satisfy the most demanding computational, power or performance acoustic applications. The presented work provides an overview of the current FPGA-based architectures and how FPGAs are exploited for different acoustic applications. Current trends on the use of this technology, pending challenges and open research opportunities on the use of FPGAs for acoustic applications using microphone arrays are presented and discussed.},
DOI = {10.3390/computers7030041}
}



@Article{rs10081222,
AUTHOR = {Wang, Yanjun and Chen, Qi and Liu, Lin and Li, Xiong and Sangaiah, Arun Kumar and Li, Kai},
TITLE = {Systematic Comparison of Power Line Classification Methods from ALS and MLS Point Cloud Data},
JOURNAL = {Remote Sensing},
VOLUME = {10},
YEAR = {2018},
NUMBER = {8},
ARTICLE-NUMBER = {1222},
URL = {https://www.mdpi.com/2072-4292/10/8/1222},
ISSN = {2072-4292},
ABSTRACT = {Power lines classification is important for electric power management and geographical objects extraction using LiDAR (light detection and ranging) point cloud data. Many supervised classification approaches have been introduced for the extraction of features such as ground, trees, and buildings, and several studies have been conducted to evaluate the framework and performance of such supervised classification methods in power lines applications. However, these studies did not systematically investigate all of the relevant factors affecting the classification results, including the segmentation scale, feature selection, classifier variety, and scene complexity. In this study, we examined these factors systematically using airborne laser scanning and mobile laser scanning point cloud data. Our results indicated that random forest and neural network were highly suitable for power lines classification in forest, suburban, and urban areas in terms of the precision, recall, and quality rates of the classification results. In contrast to some previous studies, random forest yielded the best results, while Na&iuml;ve Bayes was the worst classifier in most cases. Random forest was the more robust classifier with or without feature selection for various LiDAR point cloud data. Furthermore, the classification accuracies were directly related to the selection of the local neighborhood, classifier, and feature set. Finally, it was suggested that random forest should be considered in most cases for power line classification.},
DOI = {10.3390/rs10081222}
}



@Article{rs10081229,
AUTHOR = {Zhao, Qi and Zhang, Boxue and Lyu, Shuchang and Zhang, Hong and Sun, Daniel and Li, Guoqiang and Feng, Wenquan},
TITLE = {A CNN-SIFT Hybrid Pedestrian Navigation Method Based on First-Person Vision},
JOURNAL = {Remote Sensing},
VOLUME = {10},
YEAR = {2018},
NUMBER = {8},
ARTICLE-NUMBER = {1229},
URL = {https://www.mdpi.com/2072-4292/10/8/1229},
ISSN = {2072-4292},
ABSTRACT = {The emergence of new wearable technologies, such as action cameras and smart glasses, has driven the use of the first-person perspective in computer applications. This field is now attracting the attention and investment of researchers aiming to develop methods to process first-person vision (FPV) video. The current approaches present particular combinations of different image features and quantitative methods to accomplish specific objectives, such as object detection, activity recognition, user&ndash;machine interaction, etc. FPV-based navigation is necessary in some special areas, where Global Position System (GPS) or other radio-wave strength methods are blocked, and is especially helpful for visually impaired people. In this paper, we propose a hybrid structure with a convolutional neural network (CNN) and local image features to achieve FPV pedestrian navigation. A novel end-to-end trainable global pooling operator, called AlphaMEX, has been designed to improve the scene classification accuracy of CNNs. A scale-invariant feature transform (SIFT)-based tracking algorithm is employed for movement estimation and trajectory tracking of the person through each frame of FPV images. Experimental results demonstrate the effectiveness of the proposed method. The top-1 error rate of the proposed AlphaMEX-ResNet outperforms the original ResNet (k = 12) by 1.7% on the ImageNet dataset. The CNN-SIFT hybrid pedestrian navigation system reaches 0.57 m average absolute error, which is an adequate accuracy for pedestrian navigation. Both positions and movements can be well estimated by the proposed pedestrian navigation algorithm with a single wearable camera.},
DOI = {10.3390/rs10081229}
}



@Article{rs10081234,
AUTHOR = {Fu, Zhitao and Qin, Qianqing and Luo, Bin and Sun, Hong and Wu, Chun},
TITLE = {HOMPC: A Local Feature Descriptor Based on the Combination of Magnitude and Phase Congruency Information for Multi-Sensor Remote Sensing Images},
JOURNAL = {Remote Sensing},
VOLUME = {10},
YEAR = {2018},
NUMBER = {8},
ARTICLE-NUMBER = {1234},
URL = {https://www.mdpi.com/2072-4292/10/8/1234},
ISSN = {2072-4292},
ABSTRACT = {Local region description of multi-sensor images remains a challenging task in remote sensing image analysis and applications due to the non-linear radiation variations between images. This paper presents a novel descriptor based on the combination of the magnitude and phase congruency information of local regions to capture the common features of images with non-linear radiation changes. We first propose oriented phase congruency maps (PCMs) and oriented magnitude binary maps (MBMs) using the multi-oriented phase congruency and magnitude information of log-Gabor filters. The two feature vectors are then quickly constructed based on the convolved PCMs and MBMs. Finally, a dense descriptor named the histograms of oriented magnitude and phase congruency (HOMPC) is developed by combining the histograms of oriented phase congruency (HPC) and the histograms of oriented magnitude (HOM) to capture the structure and shape properties of local regions. HOMPC was evaluated with three datasets composed of multi-sensor remote sensing images obtained from unmanned ground vehicle, unmanned aerial vehicle, and satellite platforms. The descriptor performance was evaluated by recall, precision, F1-measure, and area under the precision-recall curve. The experimental results showed the advantages of the HOM and HPC combination and confirmed that HOMPC is far superior to the current state-of-the-art local feature descriptors.},
DOI = {10.3390/rs10081234}
}



@Article{rs10081238,
AUTHOR = {Cui, Guoqing and Lv, Zhiyong and Li, Guangfei and Atli Benediktsson, Jón and Lu, Yudong},
TITLE = {Refining Land Cover Classification Maps Based on Dual-Adaptive Majority Voting Strategy for Very High Resolution Remote Sensing Images},
JOURNAL = {Remote Sensing},
VOLUME = {10},
YEAR = {2018},
NUMBER = {8},
ARTICLE-NUMBER = {1238},
URL = {https://www.mdpi.com/2072-4292/10/8/1238},
ISSN = {2072-4292},
ABSTRACT = {Land cover classification that uses very high resolution (VHR) remote sensing images is a topic of considerable interest. Although many classification methods have been developed, the accuracy and usability of classification systems can still be improved. In this paper, a novel post-processing approach based on a dual-adaptive majority voting strategy (D-AMVS) is proposed to improve the performance of initial classification maps. D-AMVS defines a strategy for refining each label of a classified map that is obtained by different classification methods from the same original image, and fusing the different refined classification maps to generate a final classification result. The proposed D-AMVS contains three main blocks. (1) An adaptive region is generated by gradually extending the region around a central pixel based on two predefined parameters (T1 and T2) to utilize the spatial feature of ground targets in a VHR image. (2) For each classified map, the label of the central pixel is refined according to the majority voting rule within the adaptive region. This is defined as adaptive majority voting. Each initial classified map is refined in this manner pixel by pixel. (3) Finally, the refined classified maps are used to generate a final classification map, and the label of the central pixel in the final classification map is determined by applying AMV again. Each entire classified map is scanned and refined pixel by pixel based on the proposed D-AMVS. The accuracies of the proposed D-AMVS approach are investigated with two remote sensing images with high spatial resolutions of 1.0 m and 1.3 m. Compared with the classical majority voting method and a relatively new post-processing method called the general post-classification framework, the proposed D-AMVS can achieve a land cover classification map with less noise and higher classification accuracies.},
DOI = {10.3390/rs10081238}
}



@Article{rs10081248,
AUTHOR = {Sun, Hua and Wang, Qing and Wang, Guangxing and Lin, Hui and Luo, Peng and Li, Jiping and Zeng, Siqi and Xu, Xiaoyu and Ren, Lanxiang},
TITLE = {Optimizing kNN for Mapping Vegetation Cover of Arid and Semi-Arid Areas Using Landsat Images},
JOURNAL = {Remote Sensing},
VOLUME = {10},
YEAR = {2018},
NUMBER = {8},
ARTICLE-NUMBER = {1248},
URL = {https://www.mdpi.com/2072-4292/10/8/1248},
ISSN = {2072-4292},
ABSTRACT = {Land degradation and desertification in arid and semi-arid areas is of great concern. Accurately mapping percentage vegetation cover (PVC) of the areas is critical but challenging because the areas are often remote, sparsely vegetated, and rarely populated, and it is difficult to collect field observations of PVC. Traditional methods such as regression modeling cannot provide accurate predictions of PVC in the areas. Nonparametric constant k-nearest neighbors (Cons_kNN) has been widely used in estimation of forest parameters and is a good alternative because of its flexibility. However, using a globally constant k value in Cons_kNN limits its ability of increasing prediction accuracy because the spatial variability of PVC in the areas leads to spatially variable k values. In this study, a novel method that spatially optimizes determining the spatially variable k values of Cons_kNN, denoted with Opt_kNN, was proposed to map the PVC in both Duolun and Kangbao County located in Inner Mongolia and Hebei Province of China, respectively, using Landsat 8 images and sample plot data. The Opt_kNN was compared with Cons_kNN, a linear stepwise regression (LSR), a geographically weighted regression (GWR), and random forests (RF) to improve the mapping for the study areas. The results showed that (1) most of the red and near infrared band relevant vegetation indices derived from the Landsat 8 images had significant contributions to improving the mapping accuracy; (2) compared with LSR, GWR, RF and Cons_kNN, Opt_kNN resulted in consistently higher prediction accuracies of PVC and decreased relative root mean square errors by 5%, 11%, 5%, and 3%, respectively, for Duolun, and 12%, 1%, 23%, and 9%, respectively, for Kangbao. The Opt_kNN also led to spatially variable and locally optimal k values, which made it possible to automatically and locally optimize k values; and (3) the RF that has become very popular in recent years did not perform the predictions better than the Opt_kNN for the both areas. Thus, the proposed method is very promising to improve mapping the PVC in the arid and semi-arid areas.},
DOI = {10.3390/rs10081248}
}



@Article{s18082640,
AUTHOR = {Gallo, Mariano and De Luca, Giuseppina},
TITLE = {Spatial Extension of Road Traffic Sensor Data with Artificial Neural Networks},
JOURNAL = {Sensors},
VOLUME = {18},
YEAR = {2018},
NUMBER = {8},
ARTICLE-NUMBER = {2640},
URL = {https://www.mdpi.com/1424-8220/18/8/2640},
ISSN = {1424-8220},
ABSTRACT = {This paper proposes a method for estimating traffic flows on some links of a road network knowing the data on other links that are monitored with sensors. In this way, it is possible to obtain more information on traffic conditions without increasing the number of monitored links. The proposed method is based on artificial neural networks (ANNs), wherein the input data are the traffic flows on some monitored road links and the output data are the traffic flows on some unmonitored links. We have implemented and tested several single-layer feed-forward ANNs that differ in the number of neurons and the method of generating datasets for training. The proposed ANNs were trained with a supervised learning approach where input and output example datasets were generated through traffic simulation techniques. The proposed method was tested on a real-scale network and gave very good results if the travel demand patterns were known and used for generating example datasets, and promising results if the demand patterns were not considered in the procedure. Numerical results have underlined that the ANNs with few neurons were more effective than the ones with many neurons in this specific problem.},
DOI = {10.3390/s18082640}
}



@Article{s18082674,
AUTHOR = {Liakos, Konstantinos G. and Busato, Patrizia and Moshou, Dimitrios and Pearson, Simon and Bochtis, Dionysis},
TITLE = {Machine Learning in Agriculture: A Review},
JOURNAL = {Sensors},
VOLUME = {18},
YEAR = {2018},
NUMBER = {8},
ARTICLE-NUMBER = {2674},
URL = {https://www.mdpi.com/1424-8220/18/8/2674},
ISSN = {1424-8220},
ABSTRACT = {Machine learning has emerged with big data technologies and high-performance computing to create new opportunities for data intensive science in the multi-disciplinary agri-technologies domain. In this paper, we present a comprehensive review of research dedicated to applications of machine learning in agricultural production systems. The works analyzed were categorized in (a) crop management, including applications on yield prediction, disease detection, weed detection crop quality, and species recognition; (b) livestock management, including applications on animal welfare and livestock production; (c) water management; and (d) soil management. The filtering and classification of the presented articles demonstrate how agriculture will benefit from machine learning technologies. By applying machine learning to sensor data, farm management systems are evolving into real time artificial intelligence enabled programs that provide rich recommendations and insights for farmer decision support and action.},
DOI = {10.3390/s18082674}
}



@Article{rs10081284,
AUTHOR = {Zhang, Zhiqiang and Zhang, Xinchang and Sun, Ying and Zhang, Pengcheng},
TITLE = {Road Centerline Extraction from Very-High-Resolution Aerial Image and LiDAR Data Based on Road Connectivity},
JOURNAL = {Remote Sensing},
VOLUME = {10},
YEAR = {2018},
NUMBER = {8},
ARTICLE-NUMBER = {1284},
URL = {https://www.mdpi.com/2072-4292/10/8/1284},
ISSN = {2072-4292},
ABSTRACT = {The road networks provide key information for a broad range of applications such as urban planning, urban management, and navigation. The fast-developing technology of remote sensing that acquires high-resolution observational data of the land surface offers opportunities for automatic extraction of road networks. However, the road networks extracted from remote sensing images are likely affected by shadows and trees, making the road map irregular and inaccurate. This research aims to improve the extraction of road centerlines using both very-high-resolution (VHR) aerial images and light detection and ranging (LiDAR) by accounting for road connectivity. The proposed method first applies the fractal net evolution approach (FNEA) to segment remote sensing images into image objects and then classifies image objects using the machine learning classifier, random forest. A post-processing approach based on the minimum area bounding rectangle (MABR) is proposed and a structure feature index is adopted to obtain the complete road networks. Finally, a multistep approach, that is, morphology thinning, Harris corner detection, and least square fitting (MHL) approach, is designed to accurately extract the road centerlines from the complex road networks. The proposed method is applied to three datasets, including the New York dataset obtained from the object identification dataset, the Vaihingen dataset obtained from the International Society for Photogrammetry and Remote Sensing (ISPRS) 2D semantic labelling benchmark and Guangzhou dataset. Compared with two state-of-the-art methods, the proposed method can obtain the highest completeness, correctness, and quality for the three datasets. The experiment results show that the proposed method is an efficient solution for extracting road centerlines in complex scenes from VHR aerial images and light detection and ranging (LiDAR) data.},
DOI = {10.3390/rs10081284}
}



@Article{s18082693,
AUTHOR = {Huh, Jun-Ho},
TITLE = {PLC-Integrated Sensing Technology in Mountain Regions for Drone Landing Sites: Focusing on Software Technology},
JOURNAL = {Sensors},
VOLUME = {18},
YEAR = {2018},
NUMBER = {8},
ARTICLE-NUMBER = {2693},
URL = {https://www.mdpi.com/1424-8220/18/8/2693},
ISSN = {1424-8220},
ABSTRACT = {In the Republic of Korea, one of the most widely discussed subjects related to future logistics technology is the drone-based delivery (transportation) system. Much (around 75%) of Korea&rsquo;s territory consists of mountainous areas; however, the costs of installing internet facilities for drone landing sites are very high compared to other countries. Therefore, this paper proposes the power-line communication (PLC) system introduced in the author&rsquo;s previous study as an alternative solution. For the system design, a number of lightning rods are used together with a monitoring system. The system algorithm performs substantial data analysis. Also, as the author found that instantaneous high-voltage currents were a major cause of fire incidents, a three-phase three-wire connection was used for the installation of the lightning rods (Bipolar Conventional Air Terminal). Thus, based on the PLC technology, an artificial intelligence (AI) which avoids lightning strikes at the drone landing site by interworking with a closed-circuit television (CCTV) monitoring system when a drone flies over the mountain regions is proposed in this paper. The algorithm was implemented with C++ and Unity/C#, whereas the application for the part concerning the integrated sensing was developed with Java Android.},
DOI = {10.3390/s18082693}
}



@Article{s18092751,
AUTHOR = {Xue, Xizhe and Li, Ying and Shen, Qiang},
TITLE = {Unmanned Aerial Vehicle Object Tracking by Correlation Filter with Adaptive Appearance Model},
JOURNAL = {Sensors},
VOLUME = {18},
YEAR = {2018},
NUMBER = {9},
ARTICLE-NUMBER = {2751},
URL = {https://www.mdpi.com/1424-8220/18/9/2751},
ISSN = {1424-8220},
ABSTRACT = {With the increasing availability of low-cost, commercially available unmanned aerial vehicles (UAVs), visual tracking using UAVs has become more and more important due to its many new applications, including automatic navigation, obstacle avoidance, traffic monitoring, search and rescue, etc. However, real-world aerial tracking poses many challenges due to platform motion and image instability, such as aspect ratio change, viewpoint change, fast motion, scale variation and so on. In this paper, an efficient object tracking method for UAV videos is proposed to tackle these challenges. We construct the fused features to capture the gradient information and color characteristics simultaneously. Furthermore, cellular automata is introduced to update the appearance template of target accurately and sparsely. In particular, a high confidence model updating strategy is developed according to the stability function. Systematic comparative evaluations performed on the popular UAV123 dataset show the efficiency of the proposed approach.},
DOI = {10.3390/s18092751}
}



@Article{rs10091339,
AUTHOR = {Liu, Shuo and Ding, Wenrui and Liu, Chunhui and Liu, Yu and Wang, Yufeng and Li, Hongguang},
TITLE = {ERN: Edge Loss Reinforced Semantic Segmentation Network for Remote Sensing Images},
JOURNAL = {Remote Sensing},
VOLUME = {10},
YEAR = {2018},
NUMBER = {9},
ARTICLE-NUMBER = {1339},
URL = {https://www.mdpi.com/2072-4292/10/9/1339},
ISSN = {2072-4292},
ABSTRACT = {The semantic segmentation of remote sensing images faces two major challenges: high inter-class similarity and interference from ubiquitous shadows. In order to address these issues, we develop a novel edge loss reinforced semantic segmentation network (ERN) that leverages the spatial boundary context to reduce the semantic ambiguity. The main contributions of this paper are as follows: (1) we propose a novel end-to-end semantic segmentation network for remote sensing, which involves multiple weighted edge supervisions to retain spatial boundary information; (2) the main representations of the network are shared between the edge loss reinforced structures and semantic segmentation, which means that the ERN simultaneously achieves semantic segmentation and edge detection without significantly increasing the model complexity; and (3) we explore and discuss different ERN schemes to guide the design of future networks. Extensive experimental results on two remote sensing datasets demonstrate the effectiveness of our approach both in quantitative and qualitative evaluation. Specifically, the semantic segmentation performance in shadow-affected regions is significantly improved.},
DOI = {10.3390/rs10091339}
}



@Article{s18092770,
AUTHOR = {Tamouridou, Afroditi Alexandra and Pantazi, Xanthoula Eirini and Alexandridis, Thomas and Lagopodi, Anastasia and Kontouris, Giorgos and Moshou, Dimitrios},
TITLE = {Spectral Identification of Disease in Weeds Using Multilayer Perceptron with Automatic Relevance Determination},
JOURNAL = {Sensors},
VOLUME = {18},
YEAR = {2018},
NUMBER = {9},
ARTICLE-NUMBER = {2770},
URL = {https://www.mdpi.com/1424-8220/18/9/2770},
ISSN = {1424-8220},
ABSTRACT = {Microbotryum silybum, a smut fungus, is studied as an agent for the biological control of Silybum marianum (milk thistle) weed. Confirmation of the systemic infection is essential in order to assess the effectiveness of the biological control application and assist decision-making. Nonetheless, in situ diagnosis is challenging. The presently demonstrated research illustrates the identification process of systemically infected S. marianum plants by means of field spectroscopy and the multilayer perceptron/automatic relevance determination (MLP-ARD) network. Leaf spectral signatures were obtained from both healthy and infected S. marianum plants using a portable visible and near-infrared spectrometer (310&ndash;1100 nm). The MLP-ARD algorithm was applied for the recognition of the infected S. marianum plants. Pre-processed spectral signatures served as input features. The spectra pre-processing consisted of normalization, and second derivative and principal component extraction. MLP-ARD reached a high overall accuracy (90.32%) in the identification process. The research results establish the capacity of MLP-ARD to precisely identify systemically infected S. marianum weeds during their vegetative growth stage.},
DOI = {10.3390/s18092770}
}



@Article{rs10091347,
AUTHOR = {Chen, Ting and Pennisi, Andrea and Li, Zhi and Zhang, Yanning and Sahli, Hichem},
TITLE = {A Hierarchical Association Framework for Multi-Object Tracking in Airborne Videos},
JOURNAL = {Remote Sensing},
VOLUME = {10},
YEAR = {2018},
NUMBER = {9},
ARTICLE-NUMBER = {1347},
URL = {https://www.mdpi.com/2072-4292/10/9/1347},
ISSN = {2072-4292},
ABSTRACT = {Multi-Object Tracking (MOT) in airborne videos is a challenging problem due to the uncertain airborne vehicle motion, vibrations of the mounted camera, unreliable detections, changes of size, appearance and motion of the moving objects and occlusions caused by the interaction between moving and static objects in the scene. To deal with these problems, this work proposes a four-stage hierarchical association framework for multiple object tracking in airborne video. The proposed framework combines Data Association-based Tracking (DAT) methods and target tracking using a compressive tracking approach, to robustly track objects in complex airborne surveillance scenes. In each association stage, different sets of tracklets and detections are associated to efficiently handle local tracklet generation, local trajectory construction, global drifting tracklet correction and global fragmented tracklet linking. Experiments with challenging airborne videos show significant tracking improvement compared to existing state-of-the-art methods.},
DOI = {10.3390/rs10091347}
}



@Article{electronics7090160,
AUTHOR = {Kung, Chien-Chun},
TITLE = {Study on Consulting Air Combat Simulation of Cluster UAV Based on Mixed Parallel Computing Framework of Graphics Processing Unit},
JOURNAL = {Electronics},
VOLUME = {7},
YEAR = {2018},
NUMBER = {9},
ARTICLE-NUMBER = {160},
URL = {https://www.mdpi.com/2079-9292/7/9/160},
ISSN = {2079-9292},
ABSTRACT = {This paper combines matrix game theory with negotiating theory and uses U-solution to study the framework of the consulting air combat of UAV cluster. The processes to determine the optimal strategy in this paper follow three points: first, the UAV cluster are grouped into fleets; second, the best paring for the joint operations of the fleet member with the enemy fleet members are calculated; thirdly, consultations within the fleet are conducted to discuss the problems of optimal tactic, roles of main/assistance, and situational assessment within the fleet. In order to improve the computing efficiency of the framework, this article explores the use of the NVIDIA graphics processor programmed through MATLAB mixed C++/CUDA toolkit to accelerate the calculations of equations of motion of unmanned aerial vehicles, the prediction of superiority values and U values, computations of consultation, the evaluation of situational assessment and the optimal strategies. The effectiveness evaluation of GPGPU and CPU can be observed by the simulation results. When the number of team air combat is small, the CPU alone has better efficiency; however, when the number of air combat clusters exceeds 6 to 6, the architecture presented in this article can provide higher performance improvements and run faster than optimized CPU-only code.},
DOI = {10.3390/electronics7090160}
}



@Article{s18092793,
AUTHOR = {Ahn, Eunjong and Kim, Hyunjun and Sim, Sung-Han and Shin, Sung Woo and Popovics, John S. and Shin, Myoungsu},
TITLE = {Surface-Wave Based Model for Estimation of Discontinuity Depth in Concrete},
JOURNAL = {Sensors},
VOLUME = {18},
YEAR = {2018},
NUMBER = {9},
ARTICLE-NUMBER = {2793},
URL = {https://www.mdpi.com/1424-8220/18/9/2793},
ISSN = {1424-8220},
ABSTRACT = {In this paper, we propose an accurate and practical model for the estimation of surface-breaking discontinuity (i.e., crack) depth in concrete through quantitative characterization of surface-wave transmission across the discontinuity. The effects of three different mixture types (mortar, normal strength concrete, and high strength concrete) and four different simulated crack depths on surface-wave transmission were examined through experiments carried out on lab-scale concrete specimens. The crack depth estimation model is based on a surface-wave spectral energy approach that is capable of taking into account a wide range of wave frequencies. The accuracy of the proposed crack depth estimation model is validated by root mean square error analysis of data from repeated spectral energy transmission ratio measurements for each specimen.},
DOI = {10.3390/s18092793}
}



@Article{en11092226,
AUTHOR = {Li, Ming-Wei and Geng, Jing and Hong, Wei-Chiang and Zhang, Yang},
TITLE = {Hybridizing Chaotic and Quantum Mechanisms and Fruit Fly Optimization Algorithm with Least Squares Support Vector Regression Model in Electric Load Forecasting},
JOURNAL = {Energies},
VOLUME = {11},
YEAR = {2018},
NUMBER = {9},
ARTICLE-NUMBER = {2226},
URL = {https://www.mdpi.com/1996-1073/11/9/2226},
ISSN = {1996-1073},
ABSTRACT = {Compared with a large power grid, a microgrid electric load (MEL) has the characteristics of strong nonlinearity, multiple factors, and large fluctuation, which lead to it being difficult to receive more accurate forecasting performances. To solve the abovementioned characteristics of a MEL time series, the least squares support vector machine (LS-SVR) hybridizing with meta-heuristic algorithms is applied to simulate the nonlinear system of a MEL time series. As it is known that the fruit fly optimization algorithm (FOA) has several embedded drawbacks that lead to problems, this paper applies a quantum computing mechanism (QCM) to empower each fruit fly to possess quantum behavior during the searching processes, i.e., a QFOA algorithm. Eventually, the cat chaotic mapping function is introduced into the QFOA algorithm, namely CQFOA, to implement the chaotic global perturbation strategy to help fruit flies to escape from the local optima while the population&rsquo;s diversity is poor. Finally, a new MEL forecasting method, namely the LS-SVR-CQFOA model, is established by hybridizing the LS-SVR model with CQFOA. The experimental results illustrate that, in three datasets, the proposed LS-SVR-CQFOA model is superior to other alternative models, including BPNN (back-propagation neural networks), LS-SVR-CQPSO (LS-SVR with chaotic quantum particle swarm optimization algorithm), LS-SVR-CQTS (LS-SVR with chaotic quantum tabu search algorithm), LS-SVR-CQGA (LS-SVR with chaotic quantum genetic algorithm), LS-SVR-CQBA (LS-SVR with chaotic quantum bat algorithm), LS-SVR-FOA, and LS-SVR-QFOA models, in terms of forecasting accuracy indexes. In addition, it passes the significance test at a 97.5% confidence level.},
DOI = {10.3390/en11092226}
}



@Article{s18092852,
AUTHOR = {Dai, Cui-Qin and Song, Qingyang and Guo, Lei},
TITLE = {An Intelligent Computing Method for Contact Plan Design in the Multi-Layer Spatial Node-Based Internet of Things},
JOURNAL = {Sensors},
VOLUME = {18},
YEAR = {2018},
NUMBER = {9},
ARTICLE-NUMBER = {2852},
URL = {https://www.mdpi.com/1424-8220/18/9/2852},
ISSN = {1424-8220},
ABSTRACT = {Computational Intelligence (CI) has been addressed as a great challenge in recent years, particularly the aspects of routing, task scheduling, and other high-complexity issues. Especially for the Contact Plan Design (CPD) that schedules contacts in dynamic and resource-constrained networks, a suitable CI algorithm can be exchanged for a high-quality Contact Plan (CP) with the appropriate computational overhead. Previous works on CPD mainly focused on the optimization of satellite network connectivity, but most of them ignored network topology characteristics. In this paper, we study the CPD issue in the spatial node based Internet of Things (IoT), which enables the spatial nodes to deliver data cooperatively via intelligent networking. Specifically, we first introduce a Multi-Layer Space Communication Network (MLSCN) model consisting of satellites, High Altitude Platforms (HAPs), Unmanned Aerial Vehicles (UAVs), and ground stations, on which a Time-Evolving Graph (TEG) is used to illustrate the CPD process. Then, according to the characteristics of each layer in the MLSCN, we design the corresponding CPs for the inter-layer contacts and intra-layer contacts. After that, a CI algorithm named as Multidirectional Particle Swarm Optimization (MPSO) is proposed for inter-layer CPD, which utilizes a grid-based initialization strategy to expand the diversity of individuals, in which a quaternary search method and quaternary optimization are introduced to improve efficiency of particle swarms in iterations and to ensure the continuous search ability, respectively. Furthermore, an optimized scheme is implemented for the intra-layer CPD to reduce congestion and improve transmission efficiency. Simulation results show that the proposed CPD scheme can realize massive data transmission with high efficiency in the multi-layer spatial node-based IoT.},
DOI = {10.3390/s18092852}
}



@Article{drones2030030,
AUTHOR = {Jafari, Mohammad and Xu, Hao},
TITLE = {Intelligent Control for Unmanned Aerial Systems with System Uncertainties and Disturbances Using Artificial Neural Network},
JOURNAL = {Drones},
VOLUME = {2},
YEAR = {2018},
NUMBER = {3},
ARTICLE-NUMBER = {30},
URL = {https://www.mdpi.com/2504-446X/2/3/30},
ISSN = {2504-446X},
ABSTRACT = {Stabilizing the Unmanned Aircraft Systems (UAS) under complex environment including system uncertainties, unknown noise and/or disturbance is so challenging. Therefore, this paper proposes an adaptive neural network based intelligent control method to overcome these challenges. Based on a class of artificial neural network, named Radial Basis Function (RBF) networks an adaptive neural network controller is designed. To handle the unknown dynamics and uncertainties in the system, firstly, we develop a neural network based identifier. Then, a neural network based controller is generated based on both the identified model of the system and the linear or nonlinear controller. To ensure the stability of the system during its online training phase, the linear or nonlinear controller is utilized. The learning capability of the proposed intelligent controller makes it a promising approach to take system uncertainties, noises and/or disturbances into account. The satisfactory performance of the proposed intelligent controller is validated based on the computer based simulation results of a benchmark UAS with system uncertainties and disturbances, such as wind gusts disturbance.},
DOI = {10.3390/drones2030030}
}



@Article{s18092869,
AUTHOR = {Wang, Yanzhao and Xiu, Chundi and Zhang, Xuanli and Yang, Dongkai},
TITLE = {WiFi Indoor Localization with CSI Fingerprinting-Based Random Forest},
JOURNAL = {Sensors},
VOLUME = {18},
YEAR = {2018},
NUMBER = {9},
ARTICLE-NUMBER = {2869},
URL = {https://www.mdpi.com/1424-8220/18/9/2869},
ISSN = {1424-8220},
ABSTRACT = {WiFi fingerprinting indoor positioning systems have extensive applied prospects. However, a vast amount of data in a particular environment has to be gathered to establish a fingerprinting database. Deficiencies of these systems are the lack of universality of multipath effects and a burden of heavy workload on fingerprint storage. Thus, this paper presents a novel Random Forest fingerprinting localization (RFFP) method using channel state information (CSI), which utilizes the Random Forest model trained in the offline stage as fingerprints in order to economize memory space and possess a good anti-multipath characteristic. Furthermore, a series of specific experiments are conducted in a microwave anechoic chamber and an office to detail the localization performance of RFFP with different wireless channel circumstances, system parameters, algorithms, and input datasets. In addition, compared with other algorithms including K-Nearest-Neighbor (KNN), Weighted K-Nearest-Neighbor (WKNN), REPTree, CART, and J48, the RFFP method provides far greater classification accuracy as well as lower mean location error. The proposed method offers outstanding comprehensive performance including accuracy, robustness, low workload, and better anti-multipath-fading.},
DOI = {10.3390/s18092869}
}



@Article{s18092874,
AUTHOR = {Wang, Ruihua and Ma, Guorui and Qin, Qianqing and Shi, Qiang and Huang, Juntao},
TITLE = {Blind UAV Images Deblurring Based on Discriminative Networks},
JOURNAL = {Sensors},
VOLUME = {18},
YEAR = {2018},
NUMBER = {9},
ARTICLE-NUMBER = {2874},
URL = {https://www.mdpi.com/1424-8220/18/9/2874},
ISSN = {1424-8220},
ABSTRACT = {Unmanned aerial vehicles (UAVs) have become an important technology for acquiring high-resolution remote sensing images. Because most space optical imaging systems of UAVs work in environments affected by vibrations, the optical axis motion and image plane jitter caused by these vibrations easily result in blurring of UAV images. In the paper; we propose an advanced UAV image deblurring method based on a discriminative model comprising a classifier for blurred and sharp UAV images which is embedded into the maximum a posteriori framework as a regularization term that constantly optimizes ill-posed problem of blind image deblurring to obtain sharper UAV images. Compared with other methods, the results show that in image deblurring experiments using both simulated and real UAV images the proposed method delivers sharper images of various ground objects.},
DOI = {10.3390/s18092874}
}



@Article{brainsci8090166,
AUTHOR = {Cavazza, Marc},
TITLE = {A Motivational Model of BCI-Controlled Heuristic Search},
JOURNAL = {Brain Sciences},
VOLUME = {8},
YEAR = {2018},
NUMBER = {9},
ARTICLE-NUMBER = {166},
URL = {https://www.mdpi.com/2076-3425/8/9/166},
PubMedID = {30200321},
ISSN = {2076-3425},
ABSTRACT = {Several researchers have proposed a new application for human augmentation, which is to provide human supervision to autonomous artificial intelligence (AI) systems. In this paper, we introduce a framework to implement this proposal, which consists of using Brain&ndash;Computer Interfaces (BCI) to influence AI computation via some of their core algorithmic components, such as heuristic search. Our framework is based on a joint analysis of philosophical proposals characterising the behaviour of autonomous AI systems and recent research in cognitive neuroscience that support the design of appropriate BCI. Our framework is defined as a motivational approach, which, on the AI side, influences the shape of the solution produced by heuristic search using a BCI motivational signal reflecting the user&rsquo;s disposition towards the anticipated result. The actual mapping is based on a measure of prefrontal asymmetry, which is translated into a non-admissible variant of the heuristic function. Finally, we discuss results from a proof-of-concept experiment using functional near-infrared spectroscopy (fNIRS) to capture prefrontal asymmetry and control the progression of AI computation of traditional heuristic search problems.},
DOI = {10.3390/brainsci8090166}
}



@Article{s18092886,
AUTHOR = {Lee, Jungshin and Bang, Hyochoong},
TITLE = {A Robust Terrain Aided Navigation Using the Rao-Blackwellized Particle Filter Trained by Long Short-Term Memory Networks},
JOURNAL = {Sensors},
VOLUME = {18},
YEAR = {2018},
NUMBER = {9},
ARTICLE-NUMBER = {2886},
URL = {https://www.mdpi.com/1424-8220/18/9/2886},
ISSN = {1424-8220},
ABSTRACT = {Terrain-aided navigation (TAN) is a technology that estimates the position of the vehicle by comparing the altitude measured by an altimeter and height from the digital elevation model (DEM). The particle filter (PF)-based TAN has been commonly used to obtain stable real-time navigation solutions in cases where the unmanned aerial vehicle (UAV) operates at a high altitude. Even though TAN performs well on rough and unique terrains, its performance degrades in flat and repetitive terrains. In particular, in the case of PF-based TAN, there has been no verified technique for deciding its terrain validity. Therefore, this study designed a Rao-Blackwellized PF (RBPF)-based TAN, used long short-term memory (LSTM) networks to endure flat and repetitive terrains, and trained the noise covariances and measurement model of RBPF. LSTM is a modified recurrent neural network (RNN), which is an artificial neural network that recognizes patterns from time series data. Using this, this study tuned the noise covariances and measurement model of RBPF to minimize the navigation errors in various flight trajectories. This paper designed a TAN algorithm based on combining RBPF and LSTM and confirmed that it can enable a more precise navigation performance than conventional RBPF based TAN through simulations.},
DOI = {10.3390/s18092886}
}



@Article{s18092905,
AUTHOR = {Yu, Lingli and Shao, Xuanya and Wei, Yadong and Zhou, Kaijun},
TITLE = {Intelligent Land-Vehicle Model Transfer Trajectory Planning Method Based on Deep Reinforcement Learning},
JOURNAL = {Sensors},
VOLUME = {18},
YEAR = {2018},
NUMBER = {9},
ARTICLE-NUMBER = {2905},
URL = {https://www.mdpi.com/1424-8220/18/9/2905},
ISSN = {1424-8220},
ABSTRACT = {To address the problem of model error and tracking dependence in the process of intelligent vehicle motion planning, an intelligent vehicle model transfer trajectory planning method based on deep reinforcement learning is proposed, which is able to obtain an effective control action sequence directly. Firstly, an abstract model of the real environment is extracted. On this basis, a deep deterministic policy gradient (DDPG) and a vehicle dynamic model are adopted to jointly train a reinforcement learning model, and to decide the optimal intelligent driving maneuver. Secondly, the actual scene is transferred to an equivalent virtual abstract scene using a transfer model. Furthermore, the control action and trajectory sequences are calculated according to the trained deep reinforcement learning model. Thirdly, the optimal trajectory sequence is selected according to an evaluation function in the real environment. Finally, the results demonstrate that the proposed method can deal with the problem of intelligent vehicle trajectory planning for continuous input and continuous output. The model transfer method improves the model&rsquo;s generalization performance. Compared with traditional trajectory planning, the proposed method outputs continuous rotation-angle control sequences. Moreover, the lateral control errors are also reduced.},
DOI = {10.3390/s18092905}
}



@Article{ijgi7090367,
AUTHOR = {Tianyang, Dong and Jian, Zhang and Sibin, Gao and Ying, Shen and Jing, Fan},
TITLE = {Single-Tree Detection in High-Resolution Remote-Sensing Images Based on a Cascade Neural Network},
JOURNAL = {ISPRS International Journal of Geo-Information},
VOLUME = {7},
YEAR = {2018},
NUMBER = {9},
ARTICLE-NUMBER = {367},
URL = {https://www.mdpi.com/2220-9964/7/9/367},
ISSN = {2220-9964},
ABSTRACT = {Traditional single-tree detection methods usually need to set different thresholds and parameters manually according to different forest conditions. As a solution to the complicated detection process for non-professionals, this paper presents a single-tree detection method for high-resolution remote-sensing images based on a cascade neural network. In this method, we firstly calibrated the tree and non-tree samples in high-resolution remote-sensing images to train a classifier with the backpropagation (BP) neural network. Then, we analyzed the differences in the first-order statistic features, such as energy, entropy, mean, skewness, and kurtosis of the tree and non-tree samples. Finally, we used these features to correct the BP neural network model and build a cascade neural network classifier to detect a single tree. To verify the validity and practicability of the proposed method, six forestlands including two areas of oil palm in Thailand, and four areas of small seedlings, red maples, or longan trees in China were selected as test areas. The results from different methods, such as the region-growing method, template-matching method, BP neural network, and proposed cascade-neural-network method were compared considering these test areas. The experimental results show that the single-tree detection method based on the cascade neural network exhibited the highest root mean square of the matching rate (RMS_Rmat = 90%) and matching score (RMS_M = 68) in all the considered test areas.},
DOI = {10.3390/ijgi7090367}
}



@Article{app8091575,
AUTHOR = {Tao, Xian and Zhang, Dapeng and Ma, Wenzhi and Liu, Xilong and Xu, De},
TITLE = {Automatic Metallic Surface Defect Detection and Recognition with Convolutional Neural Networks},
JOURNAL = {Applied Sciences},
VOLUME = {8},
YEAR = {2018},
NUMBER = {9},
ARTICLE-NUMBER = {1575},
URL = {https://www.mdpi.com/2076-3417/8/9/1575},
ISSN = {2076-3417},
ABSTRACT = {Automatic metallic surface defect inspection has received increased attention in relation to the quality control of industrial products. Metallic defect detection is usually performed against complex industrial scenarios, presenting an interesting but challenging problem. Traditional methods are based on image processing or shallow machine learning techniques, but these can only detect defects under specific detection conditions, such as obvious defect contours with strong contrast and low noise, at certain scales, or under specific illumination conditions. This paper discusses the automatic detection of metallic defects with a twofold procedure that accurately localizes and classifies defects appearing in input images captured from real industrial environments. A novel cascaded autoencoder (CASAE) architecture is designed for segmenting and localizing defects. The cascading network transforms the input defect image into a pixel-wise prediction mask based on semantic segmentation. The defect regions of segmented results are classified into their specific classes via a compact convolutional neural network (CNN). Metallic defects under various conditions can be successfully detected using an industrial dataset. The experimental results demonstrate that this method meets the robustness and accuracy requirements for metallic defect detection. Meanwhile, it can also be extended to other detection applications.},
DOI = {10.3390/app8091575}
}



@Article{rs10091423,
AUTHOR = {Sa, Inkyu and Popović, Marija and Khanna, Raghav and Chen, Zetao and Lottes, Philipp and Liebisch, Frank and Nieto, Juan and Stachniss, Cyrill and Walter, Achim and Siegwart, Roland},
TITLE = {WeedMap: A Large-Scale Semantic Weed Mapping Framework Using Aerial Multispectral Imaging and Deep Neural Network for Precision Farming},
JOURNAL = {Remote Sensing},
VOLUME = {10},
YEAR = {2018},
NUMBER = {9},
ARTICLE-NUMBER = {1423},
URL = {https://www.mdpi.com/2072-4292/10/9/1423},
ISSN = {2072-4292},
ABSTRACT = {The ability to automatically monitor agricultural fields is an important capability in precision farming, enabling steps towards more sustainable agriculture. Precise, high-resolution monitoring is a key prerequisite for targeted intervention and the selective application of agro-chemicals. The main goal of this paper is developing a novel crop/weed segmentation and mapping framework that processes multispectral images obtained from an unmanned aerial vehicle (UAV) using a deep neural network (DNN). Most studies on crop/weed semantic segmentation only consider single images for processing and classification. Images taken by UAVs often cover only a few hundred square meters with either color only or color and near-infrared (NIR) channels. Although a map can be generated by processing single segmented images incrementally, this requires additional complex information fusion techniques which struggle to handle high fidelity maps due to their computational costs and problems in ensuring global consistency. Moreover, computing a single large and accurate vegetation map (e.g., crop/weed) using a DNN is non-trivial due to difficulties arising from: (1) limited ground sample distances (GSDs) in high-altitude datasets, (2) sacrificed resolution resulting from downsampling high-fidelity images, and (3) multispectral image alignment. To address these issues, we adopt a stand sliding window approach that operates on only small portions of multispectral orthomosaic maps (tiles), which are channel-wise aligned and calibrated radiometrically across the entire map. We define the tile size to be the same as that of the DNN input to avoid resolution loss. Compared to our baseline model (i.e., SegNet with 3 channel RGB (red, green, and blue) inputs) yielding an area under the curve (AUC) of [background=0.607, crop=0.681, weed=0.576], our proposed model with 9 input channels achieves [0.839, 0.863, 0.782]. Additionally, we provide an extensive analysis of 20 trained models, both qualitatively and quantitatively, in order to evaluate the effects of varying input channels and tunable network hyperparameters. Furthermore, we release a large sugar beet/weed aerial dataset with expertly guided annotations for further research in the fields of remote sensing, precision agriculture, and agricultural robotics.},
DOI = {10.3390/rs10091423}
}



@Article{rs10091425,
AUTHOR = {Liu, Xuefeng and Sun, Qiaoqiao and Meng, Yue and Fu, Min and Bourennane, Salah},
TITLE = {Hyperspectral Image Classification Based on Parameter-Optimized 3D-CNNs Combined with Transfer Learning and Virtual Samples},
JOURNAL = {Remote Sensing},
VOLUME = {10},
YEAR = {2018},
NUMBER = {9},
ARTICLE-NUMBER = {1425},
URL = {https://www.mdpi.com/2072-4292/10/9/1425},
ISSN = {2072-4292},
ABSTRACT = {Recent research has shown that spatial-spectral information can help to improve the classification of hyperspectral images (HSIs). Therefore, three-dimensional convolutional neural networks (3D-CNNs) have been applied to HSI classification. However, a lack of HSI training samples restricts the performance of 3D-CNNs. To solve this problem and improve the classification, an improved method based on 3D-CNNs combined with parameter optimization, transfer learning, and virtual samples is proposed in this paper. Firstly, to optimize the network performance, the parameters of the 3D-CNN of the HSI to be classified (target data) are adjusted according to the single variable principle. Secondly, in order to relieve the problem caused by insufficient samples, the weights in the bottom layers of the parameter-optimized 3D-CNN of the target data can be transferred from another well trained 3D-CNN by a HSI (source data) with enough samples and the same feature space as the target data. Then, some virtual samples can be generated from the original samples of the target data to further alleviate the lack of HSI training samples. Finally, the parameter-optimized 3D-CNN with transfer learning can be trained by the training samples consisting of the virtual and the original samples. Experimental results on real-world hyperspectral satellite images have shown that the proposed method has great potential prospects in HSI classification.},
DOI = {10.3390/rs10091425}
}



@Article{rs10091435,
AUTHOR = {Lotte, Rodolfo Georjute and Haala, Norbert and Karpina, Mateusz and Aragão, Luiz Eduardo Oliveira e Cruz de and Shimabukuro, Yosio Edemir},
TITLE = {3D Façade Labeling over Complex Scenarios: A Case Study Using Convolutional Neural Network and Structure-From-Motion},
JOURNAL = {Remote Sensing},
VOLUME = {10},
YEAR = {2018},
NUMBER = {9},
ARTICLE-NUMBER = {1435},
URL = {https://www.mdpi.com/2072-4292/10/9/1435},
ISSN = {2072-4292},
ABSTRACT = {Urban environments are regions in which spectral variability and spatial variability are extremely high, with a huge range of shapes and sizes, and they also demand high resolution images for applications involving their study. Due to the fact that these environments can grow even more over time, applications related to their monitoring tend to turn to autonomous intelligent systems, which together with remote sensing data could help or even predict daily life situations. The task of mapping cities by autonomous operators was usually carried out by aerial optical images due to its scale and resolution; however new scientific questions have arisen, and this has led research into a new era of highly-detailed data extraction. For many years, using artificial neural models to solve complex problems such as automatic image classification was commonplace, owing much of their popularity to their ability to adapt to complex situations without needing human intervention. In spite of that, their popularity declined in the mid-2000s, mostly due to the complex and time-consuming nature of their methods and workflows. However, newer neural network architectures have brought back the interest in their application for autonomous classifiers, especially for image classification purposes. Convolutional Neural Networks (CNN) have been a trend for pixel-wise image segmentation, showing flexibility when detecting and classifying any kind of object, even in situations where humans failed to perceive differences, such as in city scenarios. In this paper, we aim to explore and experiment with state-of-the-art technologies to semantically label 3D urban models over complex scenarios. To achieve these goals, we split the problem into two main processing lines: first, how to correctly label the fa&ccedil;ade features in the 2D domain, where a supervised CNN is used to segment ground-based fa&ccedil;ade images into six feature classes, roof, window, wall, door, balcony and shop; second, a Structure-from-Motion (SfM) and Multi-View-Stereo (MVS) workflow is used to extract the geometry of the fa&ccedil;ade, wherein the segmented images in the previous stage are then used to label the generated mesh by a &ldquo;reverse&rdquo; ray-tracing technique. This paper demonstrates that the proposed methodology is robust in complex scenarios. The fa&ccedil;ade feature inferences have reached up to 93% accuracy over most of the datasets used. Although it still presents some deficiencies in unknown architectural styles and needs some improvements to be made regarding 3D-labeling, we present a consistent and simple methodology to handle the problem.},
DOI = {10.3390/rs10091435}
}



@Article{s18093017,
AUTHOR = {Choi, Jongseong and Yeum, Chul Min and Dyke, Shirley J. and Jahanshahi, Mohammad R.},
TITLE = {Computer-Aided Approach for Rapid Post-Event Visual Evaluation of a Building Façade},
JOURNAL = {Sensors},
VOLUME = {18},
YEAR = {2018},
NUMBER = {9},
ARTICLE-NUMBER = {3017},
URL = {https://www.mdpi.com/1424-8220/18/9/3017},
ISSN = {1424-8220},
ABSTRACT = {After a disaster strikes an urban area, damage to the fa&ccedil;ades of a building may produce dangerous falling hazards that jeopardize pedestrians and vehicles. Thus, building fa&ccedil;ades must be rapidly inspected to prevent potential loss of life and property damage. Harnessing the capacity to use new vision sensors and associated sensing platforms, such as unmanned aerial vehicles (UAVs) would expedite this process and alleviate spatial and temporal limitations typically associated with human-based inspection in high-rise buildings. In this paper, we have developed an approach to perform rapid and accurate visual inspection of building fa&ccedil;ades using images collected from UAVs. An orthophoto corresponding to any reasonably flat region on the building (e.g., a fa&ccedil;ade or building side) is automatically constructed using a structure-from-motion (SfM) technique, followed by image stitching and blending. Based on the geometric relationship between the collected images and the constructed orthophoto, high-resolution region-of-interest are automatically extracted from the collected images, enabling efficient visual inspection. We successfully demonstrate the capabilities of the technique using an abandoned building of which a fa&ccedil;ade has damaged building components (e.g., window panes or external drainage pipes).},
DOI = {10.3390/s18093017}
}




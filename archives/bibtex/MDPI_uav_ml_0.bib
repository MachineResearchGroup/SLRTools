
@Article{s21248253,
AUTHOR = {Balestrieri, Eulalia and Daponte, Pasquale and De Vito, Luca and Picariello, Francesco and Tudosa, Ioan},
TITLE = {Sensors and Measurements for UAV Safety: An Overview},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {24},
ARTICLE-NUMBER = {8253},
URL = {https://www.mdpi.com/1424-8220/21/24/8253},
PubMedID = {34960347},
ISSN = {1424-8220},
ABSTRACT = {Unmanned aerial vehicles&rsquo; (UAVs) safety has gained great research interest due to the increase in the number of UAVs in circulation and their applications, which has inevitably also led to an increase in the number of accidents in which these vehicles are involved. The paper presents a classification of UAV safety solutions that can be found in the scientific literature, putting in evidence the fundamental and critical role of sensors and measurements in the field. Proposals from research on each proposed class concerning flight test procedures, in-flight solutions including soft propeller use, fault and damage detection, collision avoidance and safe landing, as well as ground solution including testing and injury and damage quantification measurements are discussed.},
DOI = {10.3390/s21248253}
}



@Article{fi13120313,
AUTHOR = {Kapassa, Evgenia and Themistocleous, Marinos and Christodoulou, Klitos and Iosif, Elias},
TITLE = {Blockchain Application in Internet of Vehicles: Challenges, Contributions and Current Limitations},
JOURNAL = {Future Internet},
VOLUME = {13},
YEAR = {2021},
NUMBER = {12},
ARTICLE-NUMBER = {313},
URL = {https://www.mdpi.com/1999-5903/13/12/313},
ISSN = {1999-5903},
ABSTRACT = {Blockchain technology is highly coupled with cryptocurrencies; however, it provides several other potential use cases, related to energy and sustainability, Internet of Things (IoT), smart cities, smart mobility and more. Blockchain can offer security for Electric Vehicle (EV) transactions in the Internet of Vehicles (IoV) concept, allowing electricity trading to be performed in a decentralized, transparent and secure way. Additionally, blockchain provides the necessary functionalities for IoV decentralized application development, such as data exchange, personal digital identity, sharing economy and optimized charging pattern. Moreover, blockchain technology has the potential to significantly increase energy efficiency, decrease management costs and guarantee the effective use of the energy recourses. Therefore, its application in the IoV concept provides secure, autonomous and automated energy trading between EVs. While several studies on blockchain technology in smart grids have been conducted, insufficient attention has been given to conducting a detailed review and state-of-the-art analysis of blockchain application in the IoV domain. To this end, this work provides a systematic literature review of blockchain-based applications in the IoV domain. The aim is to investigate the current challenges of IoV and to highlight how blockchain characteristics can contribute to this emerging paradigm. In addition, limitations and future research directions related to the integration of blockchain technology within the IoV are discussed. To this end, this study incorporates the theoretical foundations of several research articles published in scientific publications over the previous five years, as a method of simplifying our assessment and capturing the ever-expanding blockchain area. We present a comprehensive taxonomy of blockchain-enabled applications in the IoV domain, such as privacy and security, data protection and management, vehicle management, charging optimization and P2P energy trading, based on a structured, systematic review and content analysis of the discovered literature, and we identify key trends and emerging areas for research. The contribution of this article is two-fold: (a) we highlight the limitations presented in the relevant literature, particularly the barriers of blockchain technology and how they influence its integration into the IoV and (b) we present a number of research gaps and suggest future exploratory areas.},
DOI = {10.3390/fi13120313}
}



@Article{land10121365,
AUTHOR = {Agapiou, Athos and Vionis, Athanasios and Papantoniou, Giorgos},
TITLE = {Detection of Archaeological Surface Ceramics Using Deep Learning Image-Based Methods and Very High-Resolution UAV Imageries},
JOURNAL = {Land},
VOLUME = {10},
YEAR = {2021},
NUMBER = {12},
ARTICLE-NUMBER = {1365},
URL = {https://www.mdpi.com/2073-445X/10/12/1365},
ISSN = {2073-445X},
ABSTRACT = {Mapping surface ceramics through systematic pedestrian archaeological survey is considered a consistent method to recover the cultural biography of sites within a micro-region. Archaeologists nowadays conduct surface survey equipped with navigation devices counting, documenting, and collecting surface archaeological potsherds within a set of plotted grids. Recent advancements in unmanned aerial vehicles (UAVs) and image processing analysis can be utilised to support such surface archaeological investigations. In this study, we have implemented two different artificial intelligence image processing methods over two areas of interest near the present-day village of Kophinou in Cyprus, in the Xeros River valley. We have applied a random forest classifier through the Google Earth Engine big data cloud platform and a Single Shot Detector neural network in the ArcGIS Pro environment. For the first case study, the detection was based on red&ndash;green&ndash;blue (RGB) high-resolution orthophotos. In contrast, a multispectral camera covering both the visible and the near-infrared parts of the spectrum was used in the second area of investigation. The overall results indicate that such an approach can be used in the future as part of ongoing archaeological pedestrian surveys to detect scattered potsherds in areas of archaeological interest, even if pottery shares a very high spectral similarity with the surface.},
DOI = {10.3390/land10121365}
}



@Article{rs13245027,
AUTHOR = {Bastos, Leonardo M. and Froes de Borja Reis, Andre and Sharda, Ajay and Wright, Yancy and Ciampitti, Ignacio A.},
TITLE = {Current Status and Future Opportunities for Grain Protein Prediction Using On- and Off-Combine Sensors: A Synthesis-Analysis of the Literature},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {24},
ARTICLE-NUMBER = {5027},
URL = {https://www.mdpi.com/2072-4292/13/24/5027},
ISSN = {2072-4292},
ABSTRACT = {The spatial information about crop grain protein concentration (GPC) can be an important layer (i.e., a map that can be utilized in a geographic information system) with uses from nutrient management to grain marketing. Recently, on- and off-combine harvester sensors have been developed for creating spatial GPC layers. The quality of these GPC layers, as measured by the coefficient of determination (R2) and the root mean squared error (RMSE) of the relationship between measured and predicted GPC, is affected by different sensing characteristics. The objectives of this synthesis analysis were to (i) contrast GPC prediction R2 and RMSE for different sensor types (on-combine, off-combine proximal and remote); (ii) contrast and discuss the best spatial, temporal, and spectral resolutions and features, and the best statistical approach for off-combine sensors; and (iii) review current technology limitations and provide future directions for spatial GPC research and application. On-combine sensors were more accurate than remote sensors in predicting GPC, yet with similar precision. The most optimal conditions for creating reliable GPC predictions from off-combine sensors were sensing near anthesis using multiple spectral features that include the blue and green bands, and that are analyzed by complex statistical approaches. We discussed sensor choice in regard to previously identified uses of a GPC layer, and further proposed new uses with remote sensors including same season fertilizer management for increased GPC, and in advance segregated harvest planning related to field prioritization and farm infrastructure. Limitations of the GPC literature were identified and future directions for GPC research were proposed as (i) performing GPC predictive studies on a larger variety of crops and water regimes; (ii) reporting proper GPC ground-truth calibrations; (iii) conducting proper model training, validation, and testing; (iv) reporting model fit metrics that express greater concordance with the ideal predictive model; and (v) implementing and benchmarking one or more uses for a GPC layer.},
DOI = {10.3390/rs13245027}
}



@Article{rs13245024,
AUTHOR = {Pan, Jiao and Li, Liang and Yamaguchi, Hiroshi and Hasegawa, Kyoko and Thufail, Fadjar I. and Brahmantara and Tanaka, Satoshi},
TITLE = {Integrated High-Definition Visualization of Digital Archives for Borobudur Temple},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {24},
ARTICLE-NUMBER = {5024},
URL = {https://www.mdpi.com/2072-4292/13/24/5024},
ISSN = {2072-4292},
ABSTRACT = {The preservation and analysis of tangible cultural heritage sites have attracted enormous interest worldwide. Recently, establishing three-dimensional (3D) digital archives has emerged as a critical strategy for the permanent preservation and digital analysis of cultural sites. For extant parts of cultural sites, 3D scanning is widely used for efficient and accurate digitization. However, in many historical sites, many parts that have been damaged or lost by natural or artificial disasters are unavailable for 3D scanning. The remaining available data sources for these destroyed parts are photos, computer-aided design (CAD) drawings, written descriptions, etc. In this paper, we achieve an integrated digital archive of a UNESCO World Heritage site, namely, the Borobudur temple, in which buried reliefs and internal foundations are not available for 3D scanning. We introduce a digitizing framework to integrate three different kinds of data sources and to create a unified point-cloud-type digital archive. This point-based integration enables us to digitally record the entire 3D structure of the target cultural heritage site. Then, the whole site is visualized by stochastic point-based rendering (SPBR) precisely and comprehensibly. The proposed framework is widely applicable to other large-scale cultural sites.},
DOI = {10.3390/rs13245024}
}



@Article{rs13245025,
AUTHOR = {Bi, Kaiyi and Niu, Zheng and Xiao, Shunfu and Bai, Jie and Sun, Gang and Wang, Ji and Han, Zeying and Gao, Shuai},
TITLE = {Non-Destructive Monitoring of Maize Nitrogen Concentration Using a Hyperspectral LiDAR: An Evaluation from Leaf-Level to Plant-Level},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {24},
ARTICLE-NUMBER = {5025},
URL = {https://www.mdpi.com/2072-4292/13/24/5025},
ISSN = {2072-4292},
ABSTRACT = {Advanced remote sensing techniques for estimating crop nitrogen (N) are crucial for optimizing N fertilizer management. Hyperspectral LiDAR (HSL) data, with both spectral and spatial information of the targets, can extract more plant properties than traditional LiDAR and hyperspectral imaging systems. In this study, we tested the ability of HSL in terms of estimating maize N concentration at the leaf-level by using spectral indices and partial least squares regression (PLSR) methods. Subsequently, the N estimation was scaled up to the plant-level based on HSL point clouds. Biomass, extracted with structural proxies, was utilized to exhibit its supplemental effect on N concentration. The results show that HSL has the ability to extract N concentrations at both the leaf-level and the canopy-level, and PLSR showed better performance (R2 &gt; 0.6) than the single spectral index (R2 &gt; 0.4). In comparison to the stem height and maximum canopy width, the plant height had the strongest ability (R2 = 0.88) to estimate biomass. Future research should utilize larger datasets to test the viability of using HSL to monitor the N concentration of crops, which is beneficial for precision agriculture.},
DOI = {10.3390/rs13245025}
}



@Article{f12121747,
AUTHOR = {Liu, Wenjian and Li, Yanjie and Liu, Jun and Jiang, Jingmin},
TITLE = {Estimation of Plant Height and Aboveground Biomass of Toona sinensis under Drought Stress Using RGB-D Imaging},
JOURNAL = {Forests},
VOLUME = {12},
YEAR = {2021},
NUMBER = {12},
ARTICLE-NUMBER = {1747},
URL = {https://www.mdpi.com/1999-4907/12/12/1747},
ISSN = {1999-4907},
ABSTRACT = {Rapid and accurate plant growth and biomass estimation is essential for formulating and implementing targeted forest cultivation measures. In this study, RGB-D imaging technology was used to obtain the RGB and depth imaging data for a Toona sinensis seedling canopy to estimate plant growth and aboveground biomass (AGB). Three hundred T. sinensis seedlings from 20 varieties were planted under five different drought stress treatments. The U-Net model was applied first to achieve highly accurate segmentation of plants from complex backgrounds. Simple linear regression (SLR) was used for plant height prediction, and the other three models, including multivariate linear (ML), random forest (RF) and multilayer perceptron (MLP) regression, were applied to predict the AGB and compared for optimal model selection. The results showed that the SLR model yields promising and reliable results for the prediction of plant height, with R2 and RMSE values of 0.72 and 1.89 cm, respectively. All three regression methods perform well in the prediction of AGB estimation. MLP yields the highest accuracy in predicting dry and fresh aboveground biomass compared to the other two regression models, with R2 values of 0.77 and 0.83, respectively. The combination of Gray, Green minus red (GMR) and Excess green index (ExG) was identified as the key predictor by RReliefF for predicting dry AGB. GMR was the most important in predicting fresh AGB. This study demonstrated that the merits of RGB-D and machine learning models are effective phenotyping techniques for plant height and AGB prediction, and can be used to assist dynamic responses to drought stress for breeding selection.},
DOI = {10.3390/f12121747}
}



@Article{rs13245035,
AUTHOR = {Jozdani, Shahab and Chen, Dongmei and Chen, Wenjun and Leblanc, Sylvain G. and Lovitt, Julie and He, Liming and Fraser, Robert H. and Johnson, Brian Alan},
TITLE = {Evaluating Image Normalization via GANs for Environmental Mapping: A Case Study of Lichen Mapping Using High-Resolution Satellite Imagery},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {24},
ARTICLE-NUMBER = {5035},
URL = {https://www.mdpi.com/2072-4292/13/24/5035},
ISSN = {2072-4292},
ABSTRACT = {Illumination variations in non-atmospherically corrected high-resolution satellite (HRS) images acquired at different dates/times/locations pose a major challenge for large-area environmental mapping and monitoring. This problem is exacerbated in cases where a classification model is trained only on one image (and often limited training data) but applied to other scenes without collecting additional samples from these new images. In this research, by focusing on caribou lichen mapping, we evaluated the potential of using conditional Generative Adversarial Networks (cGANs) for the normalization of WorldView-2 (WV2) images of one area to a source WV2 image of another area on which a lichen detector model was trained. In this regard, we considered an extreme case where the classifier was not fine-tuned on the normalized images. We tested two main scenarios to normalize four target WV2 images to a source 50 cm pansharpened WV2 image: (1) normalizing based only on the WV2 panchromatic band, and (2) normalizing based on the WV2 panchromatic band and Sentinel-2 surface reflectance (SR) imagery. Our experiments showed that normalizing even based only on the WV2 panchromatic band led to a significant lichen-detection accuracy improvement compared to the use of original pansharpened target images. However, we found that conditioning the cGAN on both the WV2 panchromatic band and auxiliary information (in this case, Sentinel-2 SR imagery) further improved normalization and the subsequent classification results due to adding a more invariant source of information. Our experiments showed that, using only the panchromatic band, F1-score values ranged from 54% to 88%, while using the fused panchromatic and SR, F1-score values ranged from 75% to 91%.},
DOI = {10.3390/rs13245035}
}



@Article{plants10122726,
AUTHOR = {Xu, Yaping and Shrestha, Vivek and Piasecki, Cristiano and Wolfe, Benjamin and Hamilton, Lance and Millwood, Reginald J. and Mazarei, Mitra and Stewart, Charles Neal},
TITLE = {Sustainability Trait Modeling of Field-Grown Switchgrass (Panicum virgatum) Using UAV-Based Imagery},
JOURNAL = {Plants},
VOLUME = {10},
YEAR = {2021},
NUMBER = {12},
ARTICLE-NUMBER = {2726},
URL = {https://www.mdpi.com/2223-7747/10/12/2726},
PubMedID = {34961199},
ISSN = {2223-7747},
ABSTRACT = {Unmanned aerial vehicles (UAVs) provide an intermediate scale of spatial and spectral data collection that yields increased accuracy and consistency in data collection for morphological and physiological traits than satellites and expanded flexibility and high-throughput compared to ground-based data collection. In this study, we used UAV-based remote sensing for automated phenotyping of field-grown switchgrass (Panicum virgatum), a leading bioenergy feedstock. Using vegetation indices calculated from a UAV-based multispectral camera, statistical models were developed for rust disease caused by Puccinia novopanici, leaf chlorophyll, nitrogen, and lignin contents. For the first time, UAV remote sensing technology was used to explore the potentials for multiple traits associated with sustainable production of switchgrass, and one statistical model was developed for each individual trait based on the statistical correlation between vegetation indices and the corresponding trait. Also, for the first time, lignin content was estimated in switchgrass shoots via UAV-based multispectral image analysis and statistical analysis. The UAV-based models were verified by ground-truthing via correlation analysis between the traits measured manually on the ground-based with UAV-based data. The normalized difference red edge (NDRE) vegetation index outperformed the normalized difference vegetation index (NDVI) for rust disease and nitrogen content, while NDVI performed better than NDRE for chlorophyll and lignin content. Overall, linear models were sufficient for rust disease and chlorophyll analysis, but for nitrogen and lignin contents, nonlinear models achieved better results. As the first comprehensive study to model switchgrass sustainability traits from UAV-based remote sensing, these results suggest that this methodology can be utilized for switchgrass high-throughput phenotyping in the field.},
DOI = {10.3390/plants10122726}
}



@Article{drones5040148,
AUTHOR = {Yazid, Yassine and Ez-Zazi, Imad and Guerrero-González, Antonio and El Oualkadi, Ahmed and Arioua, Mounir},
TITLE = {UAV-Enabled Mobile Edge-Computing for IoT Based on AI: A Comprehensive Review},
JOURNAL = {Drones},
VOLUME = {5},
YEAR = {2021},
NUMBER = {4},
ARTICLE-NUMBER = {148},
URL = {https://www.mdpi.com/2504-446X/5/4/148},
ISSN = {2504-446X},
ABSTRACT = {Unmanned aerial vehicles (UAVs) are becoming integrated into a wide range of modern IoT applications. The growing number of networked IoT devices generates a large amount of data. However, processing and memorizing this massive volume of data at local nodes have been deemed critical challenges, especially when using artificial intelligence (AI) systems to extract and exploit valuable information. In this context, mobile edge computing (MEC) has emerged as a way to bring cloud computing (CC) processes within reach of users, to address computation-intensive offloading and latency issues. This paper provides a comprehensive review of the most relevant research works related to UAV technology applications in terms of enabled or assisted MEC architectures. It details the utility of UAV-enabled MEC architecture regarding emerging IoT applications and the role of both deep learning (DL) and machine learning (ML) in meeting various limitations related to latency, task offloading, energy demand, and security. Furthermore, throughout this article, the reader gains an insight into the future of UAV-enabled MEC, the advantages and the critical challenges to be tackled when using AI.},
DOI = {10.3390/drones5040148}
}



@Article{agronomy11122526,
AUTHOR = {Morella, Paula and Lambán, María Pilar and Royo, Jesús and Sánchez, Juan Carlos},
TITLE = {Study and Analysis of the Implementation of 4.0 Technologies in the Agri-Food Supply Chain: A State of the Art},
JOURNAL = {Agronomy},
VOLUME = {11},
YEAR = {2021},
NUMBER = {12},
ARTICLE-NUMBER = {2526},
URL = {https://www.mdpi.com/2073-4395/11/12/2526},
ISSN = {2073-4395},
ABSTRACT = {Industry 4.0 is changing the industrial environment. Particularly, the emerging Industry 4.0 technologies can improve the agri-food supply chain throughout all its stages. This study aims to highlight the benefits of implementing Industry 4.0 in the agri-food supply chain. First, it presents how technologies enhance the agri-food supply chain development. Then, it identifies and highlights the most common challenges that Industry 4.0 implementation faces in agri-food&rsquo;s environment. After that, it proposes key performance indicators to measure the advantages of this implementation. To achieve this, a systematic literature review was conducted. It combined conceptual and bibliometric analyses of 78 papers. As a result, the most suitable technologies were identified, e.g., Internet of Things, Big Data, blockchain and cyber physical systems. The most used indicators are proposed and the challenges of implementation were detected and classified in three groups, i.e., technical, educational and governmental. This paper highlights and exemplifies the benefits of implementing Industry 4.0 facing the lack of knowledge that exists nowadays. Moreover, it fulfils the gaps in literature, i.e., the lack of information about the implementation of technologies 4.0 or the description of the most relevant indicators for Industry 4.0 implementation.},
DOI = {10.3390/agronomy11122526}
}



@Article{s21248320,
AUTHOR = {Diro, Abebe and Chilamkurti, Naveen and Nguyen, Van-Doan and Heyne, Will},
TITLE = {A Comprehensive Study of Anomaly Detection Schemes in IoT Networks Using Machine Learning Algorithms},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {24},
ARTICLE-NUMBER = {8320},
URL = {https://www.mdpi.com/1424-8220/21/24/8320},
PubMedID = {34960414},
ISSN = {1424-8220},
ABSTRACT = {The Internet of Things (IoT) consists of a massive number of smart devices capable of data collection, storage, processing, and communication. The adoption of the IoT has brought about tremendous innovation opportunities in industries, homes, the environment, and businesses. However, the inherent vulnerabilities of the IoT have sparked concerns for wide adoption and applications. Unlike traditional information technology (I.T.) systems, the IoT environment is challenging to secure due to resource constraints, heterogeneity, and distributed nature of the smart devices. This makes it impossible to apply host-based prevention mechanisms such as anti-malware and anti-virus. These challenges and the nature of IoT applications call for a monitoring system such as anomaly detection both at device and network levels beyond the organisational boundary. This suggests an anomaly detection system is strongly positioned to secure IoT devices better than any other security mechanism. In this paper, we aim to provide an in-depth review of existing works in developing anomaly detection solutions using machine learning for protecting an IoT system. We also indicate that blockchain-based anomaly detection systems can collaboratively learn effective machine learning models to detect anomalies.},
DOI = {10.3390/s21248320}
}



@Article{infrastructures6120176,
AUTHOR = {Mousa, Mohammed Abbas and Yussof, Mustafasanie M. and Udi, Ufuoma Joseph and Nazri, Fadzli Mohamed and Kamarudin, Mohd Khairul and Parke, Gerard A. R. and Assi, Lateef N. and Ghahari, Seyed Ali},
TITLE = {Application of Digital Image Correlation in Structural Health Monitoring of Bridge Infrastructures: A Review},
JOURNAL = {Infrastructures},
VOLUME = {6},
YEAR = {2021},
NUMBER = {12},
ARTICLE-NUMBER = {176},
URL = {https://www.mdpi.com/2412-3811/6/12/176},
ISSN = {2412-3811},
ABSTRACT = {A vision-based approach has been employed in Structural Health Monitoring (SHM) of bridge infrastructure. The approach has many advantages: non-contact, non-destructive, long-distance, high precision, immunity from electromagnetic interference, and multiple-target monitoring. This review aims to summarise the vision- and Digital Image Correlation (DIC)-based SHM methods for bridge infrastructure because of their strategic significance and security concerns. Four different bridge types were studied: concrete, suspension, masonry, and steel bridge. DIC applications in SHM have recently garnered attention in aiding to assess the bridges&rsquo; structural response mechanisms under loading. Different non-destructive diagnostics methods for SHM in civil infrastructure have been used; however, vision-based techniques like DIC were only developed over the last two decades, intending to facilitate damage detection in bridge systems with prompt and accurate data for efficient and sustainable operation of the bridge structure throughout its service life. Research works reviewed in this article demonstrated the DIC capability to detect damage such as cracks, spalling, and structural parameters such as deformation, strains, vibration, deflection, and rotation. In addition, the reviewed works indicated that the DIC as an efficient and reliable technique could provide sustainable monitoring solutions for different bridge infrastructures.},
DOI = {10.3390/infrastructures6120176}
}



@Article{rs13245053,
AUTHOR = {Wang, Jiaxi and Zhang, Yan and Deng, Jiayong and Yu, Shuangwu and Zhao, Yiyang},
TITLE = {Long-Term Gully Erosion and Its Response to Human Intervention in the Tableland Region of the Chinese Loess Plateau},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {24},
ARTICLE-NUMBER = {5053},
URL = {https://www.mdpi.com/2072-4292/13/24/5053},
ISSN = {2072-4292},
ABSTRACT = {The gully erosion process is influenced by both natural conditions and human activities on the tableland region, the Chinese Loess Plateau, which is a densely populated agricultural area with unique topography. For the purpose of assessing long-term gully growth rates, the influencing factors and potential of gully growth, KH-4B satellite images, Quickbird-2 images, and unmanned aerial vehicle (UAV) images were used to assess gully erosion from 1969 to 2019. The effects of runoff, topography and human activities were analyzed with information derived from historical and present images. Ninety-five investigated gullies were classified into four types: 45 growing, 25 stable, 21 infilled and four excavated gullies. The rates (RA) of 45 growing gullies ranged from 0.50 to 20.94 m2&middot;yr&minus;1, with an average of 5.66 m2&middot;yr&minus;1 from 1969 to 2010. The present drainage area, local slope, average drainage slope, annual runoff, and ratio of the terraced area were all significantly different between the stable and growing gullies. The long-term gully growth rate could be estimated using a nonlinear regression model with annual runoff (Qa) and the slope of the drainage area (Sd) as predictors (RA = 0.301Qa0.562Sd, R2 = 0.530). Based on the Sg-A and Sg-Qa relationship that was used to reveal the threshold conditions for gully growth, all growing gullies still have the potential to keep growing, but soil and water conservation measures, including terraces, could change the threshold condition by reducing the effective drainage area. The results of this study could be helpful for preventing further gully erosion by dealing with gullies far above the threshold line.},
DOI = {10.3390/rs13245053}
}



@Article{s21248331,
AUTHOR = {Pathmakumar, Thejus and Elara, Mohan Rajesh and Gómez, Braulio Félix and Ramalingam, Balakrishnan},
TITLE = {A Reinforcement Learning Based Dirt-Exploration for Cleaning-Auditing Robot},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {24},
ARTICLE-NUMBER = {8331},
URL = {https://www.mdpi.com/1424-8220/21/24/8331},
PubMedID = {34960425},
ISSN = {1424-8220},
ABSTRACT = {Cleaning is one of the fundamental tasks with prime importance given in our day-to-day life. Moreover, the importance of cleaning drives the research efforts towards bringing leading edge technologies, including robotics, into the cleaning domain. However, an effective method to assess the quality of cleaning is an equally important research problem to be addressed. The primary footstep towards addressing the fundamental question of &ldquo;How clean is clean&rdquo; is addressed using an autonomous cleaning-auditing robot that audits the cleanliness of a given area. This research work focuses on a novel reinforcement learning-based experience-driven dirt exploration strategy for a cleaning-auditing robot. The proposed approach uses proximal policy approximation (PPO) based on-policy learning method to generate waypoints and sampling decisions to explore the probable dirt accumulation regions in a given area. The policy network is trained in multiple environments with simulated dirt patterns. Experiment trials have been conducted to validate the trained policy in both simulated and real-world environments using an in-house developed cleaning audit robot called BELUGA.},
DOI = {10.3390/s21248331}
}



@Article{agronomy11122534,
AUTHOR = {Fernández-Novales, Juan and Barrio, Ignacio and Diago, María Paz},
TITLE = {Non-Invasive Monitoring of Berry Ripening Using On-the-Go Hyperspectral Imaging in the Vineyard},
JOURNAL = {Agronomy},
VOLUME = {11},
YEAR = {2021},
NUMBER = {12},
ARTICLE-NUMBER = {2534},
URL = {https://www.mdpi.com/2073-4395/11/12/2534},
ISSN = {2073-4395},
ABSTRACT = {Hyperspectral imaging offers enormous potential for measuring grape composition with a high degree of representativity, allowing all exposed grapes from the cluster to be examined non-destructively. On-the-go hyperspectral images were acquired using a push broom hyperspectral camera (400&ndash;100 nm) that was mounted in the front part of a motorized platform moving at 5 km/h in a commercial Tempranillo vineyard in La Rioja, Spain. Measurements were collected on three dates during grape ripening in 2018 on the east side of the canopy, which was defoliated in the basal fruiting zone. A total of 144 grape clusters were measured for Total soluble solids (TSS), Titratable acidity (TA), pH, Tartaric and Malic acid, Anthocyanins and Total polyphenols, using standard wet chemistry reference methods, throughout the entire experiment. Partial Least Squares (PLS) regression was used to build calibration, cross validation and prediction models for the grape composition parameters. The best performances returned determination coefficients values of external validation (R2p) of 0.82 for TSS, 0.81 for Titratable acidity, 0.61 for pH, 0.62 for Tartaric acid, 0.84 for Malic acid, 0.88 for Anthocyanins and 0.55 for Total polyphenols. The promising results exposed in this work disclosed a notable methodology on-the-go for the non-destructive, in-field assessment of grape quality composition parameters along the ripening period.},
DOI = {10.3390/agronomy11122534}
}



@Article{sym13122417,
AUTHOR = {Zhu, Pengxing and Fang, Xi},
TITLE = {Multi-UAV Cooperative Task Assignment Based on Half Random Q-Learning},
JOURNAL = {Symmetry},
VOLUME = {13},
YEAR = {2021},
NUMBER = {12},
ARTICLE-NUMBER = {2417},
URL = {https://www.mdpi.com/2073-8994/13/12/2417},
ISSN = {2073-8994},
ABSTRACT = {Unmanned aerial vehicle (UAV) clusters usually face problems such as complex environments, heterogeneous combat subjects, and realistic interference factors in the course of mission assignment. In order to reduce resource consumption and improve the task execution rate, it is very important to develop a reasonable allocation plan for the tasks. Therefore, this paper constructs a heterogeneous UAV multitask assignment model based on several realistic constraints and proposes an improved half-random Q-learning (HR Q-learning) algorithm. The algorithm is based on the Q-learning algorithm under reinforcement learning, and by changing the way the Q-learning algorithm selects the next action in the process of random exploration, the probability of obtaining an invalid action in the random case is reduced, and the exploration efficiency is improved, thus increasing the possibility of obtaining a better assignment scheme, this also ensures symmetry and synergy in the distribution process of the drones. Simulation experiments show that compared with Q-learning algorithm and other heuristic algorithms, HR Q-learning algorithm can improve the performance of task execution, including the ability to improve the rationality of task assignment, increasing the value of gains by 12.12%, this is equivalent to an average of one drone per mission saved, and higher success rate of task execution. This improvement provides a meaningful attempt for UAV task assignment.},
DOI = {10.3390/sym13122417}
}



@Article{f12121768,
AUTHOR = {Hua, Yiying and Zhao, Xuesheng},
TITLE = {Multi-Model Estimation of Forest Canopy Closure by Using Red Edge Bands Based on Sentinel-2 Images},
JOURNAL = {Forests},
VOLUME = {12},
YEAR = {2021},
NUMBER = {12},
ARTICLE-NUMBER = {1768},
URL = {https://www.mdpi.com/1999-4907/12/12/1768},
ISSN = {1999-4907},
ABSTRACT = {In remote sensing, red edge bands are important indicators for monitoring vegetation growth. To examine the application potential of red edge bands in forest canopy closure estimation, three types of commonly used models&mdash;empirical statistical models (multiple stepwise regression (MSR)), machine learning models (back propagation neural network (BPNN)) and physical models (Li&ndash;Strahler geometric-optical (Li&ndash;Strahler GO) models)&mdash;were constructed and verified based on Sentinel-2 data, DEM data and measured data. In addition, we set up a comparative experiment without red edge bands. The relative error (ER) values of the BPNN model, MSR model, and Li&ndash;Strahler GO model with red edge bands were 16.97%, 20.76% and 24.83%, respectively. The validation accuracy measures of these models were higher than those of comparison models. For comparative experiments, the ER values of the MSR, Li&ndash;Strahler GO and BPNN models were increased by 13.07%, 4% and 1.22%, respectively. The experimental results demonstrate that red edge bands can effectively improve the accuracy of forest canopy closure estimation models to varying degrees. These findings provide a reference for modeling and estimating forest canopy closure using red edge bands based on Sentinel-2 images.},
DOI = {10.3390/f12121768}
}



@Article{e23121678,
AUTHOR = {Yang, Shubo and Luo, Yang and Miao, Wang and Ge, Changhao and Sun, Wenjian and Luo, Chunbo},
TITLE = {RF Signal-Based UAV Detection and Mode Classification: A Joint Feature Engineering Generator and Multi-Channel Deep Neural Network Approach},
JOURNAL = {Entropy},
VOLUME = {23},
YEAR = {2021},
NUMBER = {12},
ARTICLE-NUMBER = {1678},
URL = {https://www.mdpi.com/1099-4300/23/12/1678},
PubMedID = {34945985},
ISSN = {1099-4300},
ABSTRACT = {With the proliferation of Unmanned Aerial Vehicles (UAVs) to provide diverse critical services, such as surveillance, disaster management, and medicine delivery, the accurate detection of these small devices and the efficient classification of their flight modes are of paramount importance to guarantee their safe operation in our sky. Among the existing approaches, Radio Frequency (RF) based methods are less affected by complex environmental factors. The similarities between UAV RF signals and the diversity of frequency components make accurate detection and classification a particularly difficult task. To bridge this gap, we propose a joint Feature Engineering Generator (FEG) and Multi-Channel Deep Neural Network (MC-DNN) approach. Specifically, in FEG, data truncation and normalization separate different frequency components, the moving average filter reduces the outliers in the RF signal, and the concatenation fully exploits the details of the dataset. In addition, the multi-channel input in MC-DNN separates multiple frequency components and reduces the interference between them. A novel dataset that contains ten categories of RF signals from three types of UAVs is used to verify the effectiveness. Experiments show that the proposed method outperforms the state-of-the-art UAV detection and classification approaches in terms of 98.4% and F1 score of 98.3%.},
DOI = {10.3390/e23121678}
}



@Article{s21248352,
AUTHOR = {Zhang, Junrong and Tang, Huiming and Tannant, Dwayne D. and Lin, Chengyuan and Xia, Ding and Wang, Yankun and Wang, Qianyun},
TITLE = {A Novel Model for Landslide Displacement Prediction Based on EDR Selection and Multi-Swarm Intelligence Optimization Algorithm},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {24},
ARTICLE-NUMBER = {8352},
URL = {https://www.mdpi.com/1424-8220/21/24/8352},
PubMedID = {34960445},
ISSN = {1424-8220},
ABSTRACT = {With the widespread application of machine learning methods, the continuous improvement of forecast accuracy has become an important task, which is especially crucial for landslide displacement predictions. This study aimed to propose a novel prediction model to improve accuracy in landslide prediction, based on the combination of multiple new algorithms. The proposed new method includes three parts: data preparation, multi-swarm intelligence (MSI) optimization, and displacement prediction. In the data preparation, the complete ensemble empirical mode decomposition (CEEMD) is adopted to separate the trend and periodic displacements from the observed cumulative landslide displacement. The frequency component and residual component of reconstructed inducing factors that related to landslide movements are also extracted by the CEEMD and t-test, and then picked out with edit distance on real sequence (EDR) as input variables for the support vector regression (SVR) model. MSI optimization algorithms are used to optimize the SVR model in the MSI optimization; thus, six predictions models can be obtained that can be used in the displacement prediction part. Finally, the trend and periodic displacements are predicted by six optimized SVR models, respectively. The trend displacement and periodic displacement with the highest prediction accuracy are added and regarded as the final prediction result. The case study of the Shiliushubao landslide shows that the prediction results match the observed data well with an improvement in the aspect of average relative error, which indicates that the proposed model can predict landslide displacements with high precision, even when the displacements are characterized by stepped curves that under the influence of multiple time-varying factors.},
DOI = {10.3390/s21248352}
}



@Article{rs13245084,
AUTHOR = {Torres, Daliana Lobo and Turnes, Javier Noa and Soto Vega, Pedro Juan and Feitosa, Raul Queiroz and Silva, Daniel E. and Marcato Junior, Jose and Almeida, Claudio},
TITLE = {Deforestation Detection with Fully Convolutional Networks in the Amazon Forest from Landsat-8 and Sentinel-2 Images},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {24},
ARTICLE-NUMBER = {5084},
URL = {https://www.mdpi.com/2072-4292/13/24/5084},
ISSN = {2072-4292},
ABSTRACT = {The availability of remote-sensing multisource data from optical-based satellite sensors has created new opportunities and challenges for forest monitoring in the Amazon Biome. In particular, change-detection analysis has emerged in recent decades to monitor forest-change dynamics, supporting some Brazilian governmental initiatives such as PRODES and DETER projects for biodiversity preservation in threatened areas. In recent years fully convolutional network architectures have witnessed numerous proposals adapted for the change-detection task. This paper comprehensively explores state-of-the-art fully convolutional networks such as U-Net, ResU-Net, SegNet, FC-DenseNet, and two DeepLabv3+ variants on monitoring deforestation in the Brazilian Amazon. The networks&rsquo; performance is evaluated experimentally in terms of Precision, Recall, F1-score, and computational load using satellite images with different spatial and spectral resolution: Landsat-8 and Sentinel-2. We also include the results of an unprecedented auditing process performed by senior specialists to visually evaluate each deforestation polygon derived from the network with the highest accuracy results for both satellites. This assessment allowed estimation of the accuracy of these networks simulating a process &ldquo;in nature&rdquo; and faithful to the PRODES methodology. We conclude that the high resolution of Sentinel-2 images improves the segmentation of deforestation polygons both quantitatively (in terms of F1-score) and qualitatively. Moreover, the study also points to the potential of the operational use of Deep Learning (DL) mapping as products to be consumed in PRODES.},
DOI = {10.3390/rs13245084}
}



@Article{drones5040149,
AUTHOR = {Raval, Divy and Hunter, Emily and Hudson, Sinclair and Damini, Anthony and Balaji, Bhashyam},
TITLE = {Convolutional Neural Networks for Classification of Drones Using Radars},
JOURNAL = {Drones},
VOLUME = {5},
YEAR = {2021},
NUMBER = {4},
ARTICLE-NUMBER = {149},
URL = {https://www.mdpi.com/2504-446X/5/4/149},
ISSN = {2504-446X},
ABSTRACT = {The ability to classify drones using radar signals is a problem of great interest. In this paper, we apply convolutional neural networks (CNNs) to the Short-Time Fourier Transform (STFT) spectrograms of the simulated radar signals reflected from the drones. The drones vary in many ways that impact the STFT spectrograms, including blade length and blade rotation rates. Some of these physical parameters are captured in the Martin and Mulgrew model which was used to produce the datasets. We examine the data under X-band and W-band radar simulation scenarios and show that a CNN approach leads to an F1 score of 0.816&plusmn;0.011 when trained on data with a signal-to-noise ratio (SNR) of 10 dB. The neural network which was trained on data from an X-band radar with 2 kHz pulse repetition frequency was shown to perform better than the CNN trained on the aforementioned W-band radar. It remained robust to the drone blade pitch and its performance varied directly in a linear fashion with the SNR.},
DOI = {10.3390/drones5040149}
}



@Article{rs13245092,
AUTHOR = {Qin, Qiming and Wu, Zihua and Zhang, Tianyuan and Sagan, Vasit and Zhang, Zhaoxu and Zhang, Yao and Zhang, Chengye and Ren, Huazhong and Sun, Yuanheng and Xu, Wei and Zhao, Cong},
TITLE = {Optical and Thermal Remote Sensing for Monitoring Agricultural Drought},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {24},
ARTICLE-NUMBER = {5092},
URL = {https://www.mdpi.com/2072-4292/13/24/5092},
ISSN = {2072-4292},
ABSTRACT = {By effectively observing the land surface and obtaining farmland conditions, satellite remote sensing has played an essential role in agricultural drought monitoring over past decades. Among all remote sensing techniques, optical and thermal remote sensing have the most extended history of being utilized in drought monitoring. The primary goal of this paper is to illustrate how optical and thermal remote sensing have been and will be applied in the monitoring, assessment, and prediction of agricultural drought. We group the methods into four categories: optical, thermal, optical and thermal, and multi-source. For each category, a concise explanation is given to show the inherent mechanisms. We pay special attention to solar-induced chlorophyll fluorescence, which has great potential in early drought detection. Finally, we look at the future directions of agricultural drought monitoring, including (1) early detection; (2) spatio-temporal resolution; (3) organic combination of multi-source data; and (4) smart prediction and assessment based on deep learning and cloud computing.},
DOI = {10.3390/rs13245092}
}



@Article{app112411938,
AUTHOR = {Zherdev, Denis and Zherdeva, Larisa and Agapov, Sergey and Sapozhnikov, Anton and Nikonorov, Artem and Chaplygin, Sergej},
TITLE = {Producing Synthetic Dataset for Human Fall Detection in AR/VR Environments},
JOURNAL = {Applied Sciences},
VOLUME = {11},
YEAR = {2021},
NUMBER = {24},
ARTICLE-NUMBER = {11938},
URL = {https://www.mdpi.com/2076-3417/11/24/11938},
ISSN = {2076-3417},
ABSTRACT = {Human poses and the behaviour estimation for different activities in (virtual reality/augmented reality) VR/AR could have numerous beneficial applications. Human fall monitoring is especially important for elderly people and for non-typical activities with VR/AR applications. There are a lot of different approaches to improving the fidelity of fall monitoring systems through the use of novel sensors and deep learning architectures; however, there is still a lack of detail and diverse datasets for training deep learning fall detectors using monocular images. The issues with synthetic data generation based on digital human simulation were implemented and examined using the Unreal Engine. The proposed pipeline provides automatic &ldquo;playback&rdquo; of various scenarios for digital human behaviour simulation, and the result of a proposed modular pipeline for synthetic data generation of digital human interaction with the 3D environments is demonstrated in this paper. We used the generated synthetic data to train the Mask R-CNN-based segmentation of the falling person interaction area. It is shown that, by training the model with simulation data, it is possible to recognize a falling person with an accuracy of 97.6% and classify the type of person&rsquo;s interaction impact. The proposed approach also allows for covering a variety of scenarios that can have a positive effect at a deep learning training stage in other human action estimation tasks in an VR/AR environment.},
DOI = {10.3390/app112411938}
}



@Article{rs13245095,
AUTHOR = {Li, Yinshuai and Chang, Chunyan and Wang, Zhuoran and Qi, Guanghui and Dong, Chao and Zhao, Gengxing},
TITLE = {Upscaling Remote Sensing Inversion Model of Wheat Field Cultivated Land Quality in the Huang-Huai-Hai Agricultural Region, China},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {24},
ARTICLE-NUMBER = {5095},
URL = {https://www.mdpi.com/2072-4292/13/24/5095},
ISSN = {2072-4292},
ABSTRACT = {It is an objective demand for sustainable agricultural development to realize fast and accurate cultivated land quality assessment. In this paper, Tengzhou city (county-scale hilly area: scale A), Shanghe county (county-scale plain area: scale B), and Huang-Huai-Hai region (including large-scale hilly and plain area: scale C and D) were taken as research areas. Through the conversion of evaluation systems, the inversion models at the county-scale were constructed. Then, the image scale conversion was carried out based on the numerical regression method, and the upscaling inversion was realized. The results showed that: (1) the conversion models of evaluation systems (CMES) are Y = 1.021x &minus; 4.989 (CMESA&minus;B), Y = 0.801x + 16.925 (CMESA&minus;C), and Y = 0.959x + 3.458 (CMESC&minus;D); (2) the booting stage is the best inversion phase; (3) the back propagation neural network model based on the combination index group (CI-BPNN) is the best inversion model, with the R2 are 0.723 (modeling set) and 0.722 (verification set). CI-BPNN and CI-BPNN-CMESA&minus;B models are suitable for the hilly and plain areas at the county-scale, and the level area ratio difference is less than 4.87%. Furthermore, (4) the reflectance conversion model of short-wave infrared 2 is cubic, and the rest are quadratic. CI-BPNN-CMESA&minus;C and CI-BPNN-CMESA&minus;C-CMESC&minus;D models realized upscaling inversion in the hilly and plain areas, with the maximum level area ratio difference being 1.60%. Additionally, (5) the wheat field quality has improved steadily since 2001 in the Huang-Huai-Hai region. This study proposes an upscaling inversion method of wheat field quality, which provides a scientific basis for cultivated land management and agricultural production in large areas.},
DOI = {10.3390/rs13245095}
}



@Article{rs13245098,
AUTHOR = {Melancon, Alexander M. and Molthan, Andrew L. and Griffin, Robert E. and Mecikalski, John R. and Schultz, Lori A. and Bell, Jordan R.},
TITLE = {Random Forest Classification of Inundation Following Hurricane Florence (2018) via L-Band Synthetic Aperture Radar and Ancillary Datasets},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {24},
ARTICLE-NUMBER = {5098},
URL = {https://www.mdpi.com/2072-4292/13/24/5098},
ISSN = {2072-4292},
ABSTRACT = {In response to Hurricane Florence of 2018, NASA JPL collected quad-pol L-band SAR data with the Uninhabited Aerial Vehicle Synthetic Aperture Radar (UAVSAR) instrument, observing record-setting river stages across North and South Carolina. Fully-polarized SAR images allow for mapping of inundation extent at a high spatial resolution with a unique advantage over optical imaging, stemming from the sensor&rsquo;s ability to penetrate cloud cover and dense vegetation. This study used random forest classification to generate maps of inundation from L-band UAVSAR imagery processed using the Freeman&ndash;Durden decomposition method. An average overall classification accuracy of 87% is achieved with this methodology, with areas of both under- and overprediction for the focus classes of open water and inundated forest. Fuzzy logic operations using hydrologic variables are used to reduce the number of small noise-like features and false detections in areas unlikely to retain water. Following postclassification refinement, estimated flood extents were combined to an event maximum for societal impact assessments. Results from the Hurricane Florence case study are discussed in addition to the limitations of available validation data for accuracy assessments.},
DOI = {10.3390/rs13245098}
}



@Article{su132413907,
AUTHOR = {Wang, Xin and Atkin, Jason and Bazmohammadi, Najmeh and Bozhko, Serhiy and Guerrero, Josep M.},
TITLE = {Optimal Load and Energy Management of Aircraft Microgrids Using Multi-Objective Model Predictive Control},
JOURNAL = {Sustainability},
VOLUME = {13},
YEAR = {2021},
NUMBER = {24},
ARTICLE-NUMBER = {13907},
URL = {https://www.mdpi.com/2071-1050/13/24/13907},
ISSN = {2071-1050},
ABSTRACT = {Safety issues related to the electrification of more electric aircraft (MEA) need to be addressed because of the increasing complexity of aircraft electrical power systems and the growing number of safety-critical sub-systems that need to be powered. Managing the energy storage systems and the flexibility in the load-side plays an important role in preserving the system&rsquo;s safety when facing an energy shortage. This paper presents a system-level centralized operation management strategy based on model predictive control (MPC) for MEA to schedule battery systems and exploit flexibility in the demand-side while satisfying time-varying operational requirements. The proposed online control strategy aims to maintain energy storage (ES) and prolong the battery life cycle, while minimizing load shedding, with fewer switching activities to improve devices lifetime and to avoid unnecessary transients. Using a mixed-integer linear programming (MILP) formulation, different objective functions are proposed to realize the control targets, with soft constraints improving the feasibility of the model. In addition, an evaluation framework is proposed to analyze the effects of various objective functions and the prediction horizon on system performance, which provides the designers and users of MEA and other complex systems with new insights into operation management problem formulation.},
DOI = {10.3390/su132413907}
}



@Article{app112411996,
AUTHOR = {Lu, Yingtong and Ma, Yaofei and Wang, Jiangyun},
TITLE = {Multi-Population Parallel Wolf Pack Algorithm for Task Assignment of UAV Swarm},
JOURNAL = {Applied Sciences},
VOLUME = {11},
YEAR = {2021},
NUMBER = {24},
ARTICLE-NUMBER = {11996},
URL = {https://www.mdpi.com/2076-3417/11/24/11996},
ISSN = {2076-3417},
ABSTRACT = {The effectiveness of the Wolf Pack Algorithm (WPA) in high-dimensional discrete optimization problems has been verified in previous studies; however, it usually takes too long to obtain the best solution. This paper proposes the Multi-Population Parallel Wolf Pack Algorithm (MPPWPA), in which the size of the wolf population is reduced by dividing the population into multiple sub-populations that optimize independently at the same time. Using the approximate average division method, the population is divided into multiple equal mass sub-populations whose better individuals constitute an elite sub-population. Through the elite-mass population distribution, those better individuals are optimized twice by the elite sub-population and mass sub-populations, which can accelerate the convergence. In order to maintain the population diversity, population pretreatment is proposed. The sub-populations migrate according to a constant migration probability and the migration of sub-populations are equivalent to the re-division of the confluent population. Finally, the proposed algorithm is carried out in a synchronous parallel system. Through the simulation experiments on the task assignment of the UAV swarm in three scenarios whose dimensions of solution space are 8, 30 and 150, the MPPWPA is verified as being effective in improving the optimization performance.},
DOI = {10.3390/app112411996}
}



@Article{machines9120360,
AUTHOR = {Yang, Pu and Wen, Chenwan and Geng, Huilin and Liu, Peng},
TITLE = {Intelligent Fault Diagnosis Method for Blade Damage of Quad-Rotor UAV Based on Stacked Pruning Sparse Denoising Autoencoder and Convolutional Neural Network},
JOURNAL = {Machines},
VOLUME = {9},
YEAR = {2021},
NUMBER = {12},
ARTICLE-NUMBER = {360},
URL = {https://www.mdpi.com/2075-1702/9/12/360},
ISSN = {2075-1702},
ABSTRACT = {This paper introduces a new intelligent fault diagnosis method based on stack pruning sparse denoising autoencoder and convolutional neural network (sPSDAE-CNN). This method processes the original input data by using a stack denoising autoencoder. Different from the traditional autoencoder, stack pruning sparse denoising autoencoder includes a fully connected autoencoding network, the features extracted from the front layer of the network are used for the operation of the subsequent layer, which means that some new connections will appear between the front and rear layers of the network, reduce the loss of information, and obtain more effective features. Firstly, a one-dimensional sliding window is introduced for data enhancement. In addition, transforming one-dimensional time-domain data into the two-dimensional gray image can further improve the deep learning (DL) ability of models. At the same time, pruning operation is introduced to improve the training efficiency and accuracy of the network. The convolutional neural network model with sPSDAE has a faster training speed, strong adaptability to noise interference signals, and can also suppress the over-fitting problem of the convolutional neural network to a certain extent. Actual experiments show that for the fault of unmanned aerial vehicle (UAV) blade damage, the sPSDAE-CNN model we use has better stability and reliable prediction accuracy than traditional convolutional neural networks. At the same time, For noise signals, better results can be obtained. The experimental results show that the sPSDAE-CNN model still has a good diagnostic accuracy rate in a high-noise environment. In the case of a signal-to-noise ratio of &minus;4, it still has an accuracy rate of 90%.},
DOI = {10.3390/machines9120360}
}



@Article{w13243627,
AUTHOR = {Magidi, James and van Koppen, Barbara and Nhamo, Luxon and Mpandeli, Sylvester and Slotow, Rob and Mabhaudhi, Tafadzwanashe},
TITLE = {Informing Equitable Water and Food Policies through Accurate Spatial Information on Irrigated Areas in Smallholder Farming Systems},
JOURNAL = {Water},
VOLUME = {13},
YEAR = {2021},
NUMBER = {24},
ARTICLE-NUMBER = {3627},
URL = {https://www.mdpi.com/2073-4441/13/24/3627},
ISSN = {2073-4441},
ABSTRACT = {Accurate information on irrigated areas&rsquo; spatial distribution and extent are crucial in enhancing agricultural water productivity, water resources management, and formulating strategic policies that enhance water and food security and ecologically sustainable development. However, data are typically limited for smallholder irrigated areas, which is key to achieving social equity and equal distribution of financial resources. This study addressed this gap by delineating disaggregated smallholder and commercial irrigated areas through the random forest algorithm, a non-parametric machine learning classifier. Location within or outside former apartheid &ldquo;homelands&rdquo; was taken as a proxy for smallholder, and commercial irrigation. Being in a medium rainfall area, the huge irrigation potential of the Inkomati-Usuthu Water Management Area (UWMA) is already well developed for commercial crop production outside former homelands. However, information about the spatial distribution and extent of irrigated areas within former homelands, which is largely informal, was missing. Therefore, we first classified cultivated lands in 2019 and 2020 as a baseline, from where the Normalised Difference Vegetation Index (NDVI) was used to distinguish irrigated from rainfed, focusing on the dry winter period when crops are predominately irrigated. The mapping accuracy of 84.9% improved the efficacy in defining the actual spatial extent of current irrigated areas at both smallholder and commercial spatial scales. The proportion of irrigated areas was high for both commercial (92.5%) and smallholder (96.2%) irrigation. Moreover, smallholder irrigation increased by over 19% between 2019 and 2020, compared to slightly over 7% in the commercial sector. Such information is critical for policy formulation regarding equitable and inclusive water allocation, irrigation expansion, land reform, and food and water security in smallholder farming systems.},
DOI = {10.3390/w13243627}
}



@Article{rs13245123,
AUTHOR = {Qian, Liyong and Wu, Decheng and Liu, Dong and Song, Shalei and Shi, Shuo and Gong, Wei and Wang, Le},
TITLE = {Parameter Simulation and Design of an Airborne Hyperspectral Imaging LiDAR System},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {24},
ARTICLE-NUMBER = {5123},
URL = {https://www.mdpi.com/2072-4292/13/24/5123},
ISSN = {2072-4292},
ABSTRACT = {With continuous technological development, the future development trend of LiDAR in the field of remote sensing and mapping is to obtain the elevation and spectral information of ground targets simultaneously. Airborne hyperspectral imaging LiDAR inherits the advantages of active and passive remote sensing detection. This paper presents a simulation method to determine the design parameters of an airborne hyperspectral imaging LiDAR system. In accordance with the hyperspectral imaging LiDAR equation and optical design principles, the atmospheric transmission model and the reflectance spectrum of specific ground targets are utilized. The design parameters and laser emission spectrum of the hyperspectral LiDAR system are considered, and the signal-to-noise ratio of the system is obtained through simulation. Without considering the effect of detector gain and electronic amplification on the signal-to-noise ratio, three optical fibers are coupled into a detection channel, and the power spectral density emitted by the supercontinuum laser is simulated by assuming that the signal-to-noise ratio is equal to 1. The power spectral density emitted by the laser must not be less than 15 mW/nm in the shortwave direction. During the simulation process, the design parameters of the hyperspectral LiDAR system are preliminarily demonstrated, and the feasibility of the hyperspectral imaging LiDAR system design is theoretically guaranteed in combination with the design requirements of the supercontinuum laser. The spectral resolution of a single optical fiber of the hyperspectral LiDAR system is set to 2.5 nm. In the actual prototype system, multiple optical fibers can be coupled into a detection channel in accordance with application needs to further improve the signal-to-noise ratio of hyperspectral LiDAR system detection.},
DOI = {10.3390/rs13245123}
}



@Article{app112412018,
AUTHOR = {Mora-Soto, Manuel Eduardo and Maldonado-Romo, Javier and Rodríguez-Molina, Alejandro and Aldape-Pérez, Mario},
TITLE = {Building a Realistic Virtual Simulator for Unmanned Aerial Vehicle Teleoperation},
JOURNAL = {Applied Sciences},
VOLUME = {11},
YEAR = {2021},
NUMBER = {24},
ARTICLE-NUMBER = {12018},
URL = {https://www.mdpi.com/2076-3417/11/24/12018},
ISSN = {2076-3417},
ABSTRACT = {Unmanned Aerial Vehicles (UAVs) support humans in performing an increasingly varied number of tasks. UAVs need to be remotely operated by a human pilot in many cases. Therefore, pilots require repetitive training to master the UAV movements. Nevertheless, training with an actual UAV involves high costs and risks. Fortunately, simulators are alternatives to face these difficulties. However, existing simulators lack realism, do not present flight information intuitively, and sometimes do not allow natural interaction with the human operator. This work addresses these issues through a framework for building realistic virtual simulators for the human operation of UAVs. First, the UAV is modeled in detail to perform a dynamic simulation in this framework. Then, the information of the above simulation is utilized to manipulate the elements in a virtual 3D operation environment developed in Unity 3D. Therefore, the interaction with the human operator is introduced with a proposed teleoperation algorithm and an input device. Finally, a meta-heuristic optimization procedure provides realism to the simulation. In this procedure, the flight information obtained from an actual UAV is used to optimize the parameters of the teleoperation algorithm. The quadrotor is adopted as the study case to show the proposal&rsquo;s effectiveness.},
DOI = {10.3390/app112412018}
}



@Article{machines9120361,
AUTHOR = {Ritter, Noah and Straub, Jeremy},
TITLE = {Implementation of Hardware-Based Expert Systems and Comparison of Their Performance to Software-Based Expert Systems},
JOURNAL = {Machines},
VOLUME = {9},
YEAR = {2021},
NUMBER = {12},
ARTICLE-NUMBER = {361},
URL = {https://www.mdpi.com/2075-1702/9/12/361},
ISSN = {2075-1702},
ABSTRACT = {Expert systems are a form of highly understandable artificial intelligence that allow humans to trace the decision-making processes that are used. While they are typically software implemented and use an iterative algorithm for rule-fact network processing, this is not the only possible implementation approach. This paper implements and evaluates the use of hardware-based expert systems. It shows that they work accurately and can be developed to parallel software implementations. It also compares the processing speed of software and hardware-based expert systems, showing that hardware-based systems typically operate two orders of magnitude faster than the software ones. The potential applications that hardware-based expert systems can be used for and the capabilities that they can provide are discussed.},
DOI = {10.3390/machines9120361}
}



@Article{rs13245129,
AUTHOR = {Zhang, Xinyu and Yuan, Yaxin and Zhu, Zequn and Ma, Qingshan and Yu, Hongyan and Li, Meng and Ma, Jianhai and Yi, Shuhua and He, Xiongzhao and Sun, Yi},
TITLE = {Predicting the Distribution of Oxytropis ochrocephala Bunge in the Source Region of the Yellow River (China) Based on UAV Sampling Data and Species Distribution Model},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {24},
ARTICLE-NUMBER = {5129},
URL = {https://www.mdpi.com/2072-4292/13/24/5129},
ISSN = {2072-4292},
ABSTRACT = {Oxytropis ochrocephala Bunge is an herbaceous perennial poisonous weed. It severely affects the production of local animal husbandry and ecosystem stability in the source region of Yellow River (SRYR), China. To date, however, the spatiotemporal distribution of O. ochrocephala is still unclear, mainly due to lack of high-precision observation data and effective methods at a regional scale. In this study, an efficient sampling method, based on unmanned aerial vehicle (UAV), was proposed to supply basic sampling data for species distribution models (SDMs, BIOMOD in this study). A total of 3232 aerial photographs were obtained, from 2018 to 2020, in SRYR, and the potential and future distribution of O. ochrocephala were predicted by an ensemble model, consisting of six basic models of BIOMOD. The results showed that: (1) O. ochrocephala mainly distributed in the southwest, middle, and northeast of the SRYR, and the high suitable habitat of O. ochrocephala accounted for 3.19%; (2) annual precipitation and annual mean temperature were the two most important factors that affect the distribution of O. ochrocephala, with a cumulative importance of 60.45%; and (3) the distribution probability of O. ochrocephala tends to increase from now to the 2070s, while spatial distribution ranges will remain in the southwest, middle, and northeast of the SRYR. This study shows that UAVs can potentially be used to obtain the basic data for species distribution modeling; the results are both beneficial to establishing reasonable management practices and animal husbandry in alpine grassland systems.},
DOI = {10.3390/rs13245129}
}



@Article{rs13245128,
AUTHOR = {Zhang, Xinyue and Leng, Chengcai and Hong, Yameng and Pei, Zhao and Cheng, Irene and Basu, Anup},
TITLE = {Multimodal Remote Sensing Image Registration Methods and Advancements: A Survey},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {24},
ARTICLE-NUMBER = {5128},
URL = {https://www.mdpi.com/2072-4292/13/24/5128},
ISSN = {2072-4292},
ABSTRACT = {With rapid advancements in remote sensing image registration algorithms, comprehensive imaging applications are no longer limited to single-modal remote sensing images. Instead, multi-modal remote sensing (MMRS) image registration has become a research focus in recent years. However, considering multi-source, multi-temporal, and multi-spectrum input introduces significant nonlinear radiation differences in MMRS images for which researchers need to develop novel solutions. At present, comprehensive reviews and analyses of MMRS image registration methods are inadequate in related fields. Thus, this paper introduces three theoretical frameworks: namely, area-based, feature-based and deep learning-based methods. We present a brief review of traditional methods and focus on more advanced methods for MMRS image registration proposed in recent years. Our review or comprehensive analysis is intended to provide researchers in related fields with advanced understanding to achieve further breakthroughs and innovations.},
DOI = {10.3390/rs13245128}
}



@Article{plants10122804,
AUTHOR = {Murcia, Harold F. and Tilaguy, Sebastian and Ouazaa, Sofiane},
TITLE = {Development of a Low-Cost System for 3D Orchard Mapping Integrating UGV and LiDAR},
JOURNAL = {Plants},
VOLUME = {10},
YEAR = {2021},
NUMBER = {12},
ARTICLE-NUMBER = {2804},
URL = {https://www.mdpi.com/2223-7747/10/12/2804},
PubMedID = {34961275},
ISSN = {2223-7747},
ABSTRACT = {Growing evaluation in the early stages of crop development can be critical to eventual yield. Point clouds have been used for this purpose in tasks such as detection, characterization, phenotyping, and prediction on different crops with terrestrial mapping platforms based on laser scanning. 3D model generation requires the use of specialized measurement equipment, which limits access to this technology because of their complex and high cost, both hardware elements and data processing software. An unmanned 3D reconstruction mapping system of orchards or small crops has been developed to support the determination of morphological indices, allowing the individual calculation of the height and radius of the canopy of the trees to monitor plant growth. This paper presents the details on each development stage of a low-cost mapping system which integrates an Unmanned Ground Vehicle UGV and a 2D LiDAR to generate 3D point clouds. The sensing system for the data collection was developed from the design in mechanical, electronic, control, and software layers. The validation test was carried out on a citrus crop section by a comparison of distance and canopy height values obtained from our generated point cloud concerning the reference values obtained with a photogrammetry method. A 3D crop map was generated to provide a graphical view of the density of tree canopies in different sections which led to the determination of individual plant characteristics using a Python-assisted tool. Field evaluation results showed plant individual tree height and crown diameter with a root mean square error of around 30.8 and 45.7 cm between point cloud data and reference values.},
DOI = {10.3390/plants10122804}
}



@Article{app112412093,
AUTHOR = {Pérez-González, Andrés and Benítez-Montoya, Nelson and Jaramillo-Duque, Álvaro and Cano-Quintero, Juan Bernardo},
TITLE = {Coverage Path Planning with Semantic Segmentation for UAV in PV Plants},
JOURNAL = {Applied Sciences},
VOLUME = {11},
YEAR = {2021},
NUMBER = {24},
ARTICLE-NUMBER = {12093},
URL = {https://www.mdpi.com/2076-3417/11/24/12093},
ISSN = {2076-3417},
ABSTRACT = {Solar energy is one of the most strategic energy sources for the world&rsquo;s economic development. This has caused the number of solar photovoltaic plants to increase around the world; consequently, they are installed in places where their access and manual inspection are arduous and risky tasks. Recently, the inspection of photovoltaic plants has been conducted with the use of unmanned aerial vehicles (UAV). Although the inspection with UAVs can be completed with a drone operator, where the UAV flight path is purely manual or utilizes a previously generated flight path through a ground control station (GCS). However, the path generated in the GCS has many restrictions that the operator must supply. Due to these restrictions, we present a novel way to develop a flight path automatically with coverage path planning (CPP) methods. Using a DL server to segment the region of interest (RoI) within each of the predefined PV plant images, three CPP methods were also considered and their performances were assessed with metrics. The UAV energy consumption performance in each of the CPP methods was assessed using two different UAVs and standard metrics. Six experiments were performed by varying the CPP width, and the consumption metrics were recorded in each experiment. According to the results, the most effective and efficient methods are the exact cellular decomposition boustrophedon and grid-based wavefront coverage, depending on the CPP width and the area of the PV plant. Finally, a relationship was established between the size of the photovoltaic plant area and the best UAV to perform the inspection with the appropriate CPP width. This could be an important result for low-cost inspection with UAVs, without high-resolution cameras on the UAV board, and in small plants.},
DOI = {10.3390/app112412093}
}



@Article{rs13245159,
AUTHOR = {Mongus, Domen and Brumen, Matej and Žlaus, Danijel and Kohek, Štefan and Tomažič, Roman and Kerin, Uroš and Kolmanič, Simon},
TITLE = {A Complete Environmental Intelligence System for LiDAR-Based Vegetation Management in Power-Line Corridors},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {24},
ARTICLE-NUMBER = {5159},
URL = {https://www.mdpi.com/2072-4292/13/24/5159},
ISSN = {2072-4292},
ABSTRACT = {This paper presents the first complete approach to achieving environmental intelligence support in the management of vegetation within electrical power transmission corridors. Contrary to the related studies that focused on the mapping of power lines, together with encroaching vegetation risk assessment, we realised predictive analytics with vegetation growth simulation. This was achieved by following the JDL/DFIG data fusion model for complementary feature extraction from Light Detection and Ranging (LiDAR) derived data products and auxiliary thematic maps that feed an ensemble regression model. The results indicate that improved vegetation growth prediction accuracy is obtained by segmenting training samples according to their contextual similarities that relate to their ecological niches. Furthermore, efficient situation assessment was then performed using a rasterised parametrically defined funnel-shaped volumetric filter. In this way, RMSE&asymp;1 m was measured when considering tree growth simulation, while a 0.37 m error was estimated in encroaching vegetation detection, demonstrating significant improvements over the field observations.},
DOI = {10.3390/rs13245159}
}



@Article{electronics10243175,
AUTHOR = {Mourtzis, Dimitris and Angelopoulos, John and Panopoulos, Nikos},
TITLE = {Smart Manufacturing and Tactile Internet Based on 5G in Industry 4.0: Challenges, Applications and New Trends},
JOURNAL = {Electronics},
VOLUME = {10},
YEAR = {2021},
NUMBER = {24},
ARTICLE-NUMBER = {3175},
URL = {https://www.mdpi.com/2079-9292/10/24/3175},
ISSN = {2079-9292},
ABSTRACT = {For many applications deployed in manufacturing networks, communication latency has been a significant barrier. Despite the constant development of improved communication protocols and standards during Industry 4.0, the latency problem persists, lowering quality of services (QoS) and quality of experience (QoE). Tactile internet (TI), with its high availability, security, and ultra-low latency, will add a new dimension to human-machine interaction (HMI) by enabling haptic and tactile sensations. The tactile internet (TI) is a cutting-edge technology that uses 5G and beyond (B5G) communications to enable real-time interaction of haptic data over the internet between tactile ends. This emerging TI technology is regarded as the next evolutionary step for the Internet of Things (IoT) and is expected to bring about massive changes towards Society 5.0 and to address complex issues in current society. To that end, the 5G mobile communication systems will support the TI at the wireless edge. As a result, TI can be used as a backbone for delay mitigation in conjunction with 5G networks, allowing for ultra-reliable low latency applications like Smart Manufacturing, virtual reality, and augmented reality. Consequently, the purpose of this paper is to present the current state of 5G and TI, as well as the challenges and future trends for 5G networks beyond 2021, as well as a conceptual framework for integrating 5G and TI into existing industrial case studies, with a focus on the design aspects and layers of TI, such as the master, network, and slave layers. Finally, the key publications focused on the key enabling technologies of TI are summarized and the beyond 5G era towards Society 5.0 based on cyber-physical systems is discussed.},
DOI = {10.3390/electronics10243175}
}



@Article{rs13245166,
AUTHOR = {Wang, Jianjun and Zhou, Qi and Shang, Jiali and Liu, Chang and Zhuang, Tingxuan and Ding, Junjie and Xian, Yunyu and Zhao, Lingtian and Wang, Weiling and Zhou, Guisheng and Tan, Changwei and Huo, Zhongyang},
TITLE = {UAV- and Machine Learning-Based Retrieval of Wheat SPAD Values at the Overwintering Stage for Variety Screening},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {24},
ARTICLE-NUMBER = {5166},
URL = {https://www.mdpi.com/2072-4292/13/24/5166},
ISSN = {2072-4292},
ABSTRACT = {In recent years, the delay in sowing has become a major obstacle to high wheat yield in Jiangsu Province, one of the major wheat producing areas in China; hence, it is necessary to screen wheat varieties are resilient for late sowing. This study aimed to provide an effective, fast, and non-destructive monitoring method of soil plant analysis development (SPAD) values, which can represent leaf chlorophyll contents, for late-sown winter wheat variety screening. This study acquired multispectral images using an unmanned aerial vehicle (UAV) at the overwintering stage of winter wheat growth, and further processed these images to extract reflectance of five single spectral bands and calculated 26 spectral vegetation indices. Based on these 31 variables, this study combined three variable selection methods (i.e., recursive feature elimination (RFE), random forest (RF), and Pearson correlation coefficient (r)) with four machine learning algorithms (i.e., random forest regression (RFR), linear kernel-based support vector regression (SVR), radial basis function (RBF) kernel-based SVR, and sigmoid kernel-based SVR), resulted in seven SVR models (i.e., RFE-SVR_linear, RF-SVR_linear, RF-SVR_RBF, RF-SVR_sigmoid, r-SVR_linear, r-SVR_RBF, and r-SVR_sigmoid) and three RFR models (i.e., RFE-RFR, RF-RFR, and r-RFR). The performances of the 10 machine learning models were evaluated and compared with each other according to the achieved coefficient of determination (R2), residual prediction deviation (RPD), root mean square error (RMSE), and relative RMSE (RRMSE) in SPAD estimation. Of the 10 models, the best one was the RF-SVR_sigmoid model, which was the combination of the RF variable selection method and the sigmoid kernel-based SVR algorithm. It achieved high accuracy in estimating SPAD values of the wheat canopy (R2 = 0.754, RPD = 2.017, RMSE = 1.716 and RRMSE = 4.504%). The newly developed UAV- and machine learning-based model provided a promising and real time method to monitor chlorophyll contents at the overwintering stage, which can benefit late-sown winter wheat variety screening.},
DOI = {10.3390/rs13245166}
}



@Article{rs13245173,
AUTHOR = {Cao, Xiaofeng and Liu, Yulin and Yu, Rui and Han, Dejun and Su, Baofeng},
TITLE = {A Comparison of UAV RGB and Multispectral Imaging in Phenotyping for Stay Green of Wheat Population},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {24},
ARTICLE-NUMBER = {5173},
URL = {https://www.mdpi.com/2072-4292/13/24/5173},
ISSN = {2072-4292},
ABSTRACT = {High throughput phenotyping (HTP) for wheat (Triticum aestivum L.) stay green (SG) is expected in field breeding as SG is a beneficial phenotype for wheat high yield and environment adaptability. The RGB and multispectral imaging based on the unmanned aerial vehicle (UAV) are widely popular multi-purpose HTP platforms for crops in the field. The purpose of this study was to compare the potential of UAV RGB and multispectral images (MSI) in SG phenotyping of diversified wheat germplasm. The multi-temporal images of 450 samples (406 wheat genotypes) were obtained and the color indices (CIs) from RGB and MSI and spectral indices (SIs) from MSI were extracted, respectively. The four indices (CIs in RGB, CIs in MSI, SIs in MSI, and CIs + SIs in MSI) were used to detect four SG stages, respectively, by machine learning classifiers. Then, all indices&rsquo; dynamics were analyzed and the indices that varied monotonously and significantly were chosen to calculate wheat temporal stay green rates (SGR) to quantify the SG in diverse genotypes. The correlations between indices&rsquo; SGR and wheat yield were assessed and the dynamics of some indices&rsquo; SGR with different yield correlations were tracked in three visual observed SG grades samples. In SG stage detection, classifiers best average accuracy reached 93.20&ndash;98.60% and 93.80&ndash;98.80% in train and test set, respectively, and the SIs containing red edge or near-infrared band were more effective than the CIs calculated only by visible bands. Indices&rsquo; temporal SGR could quantify SG changes on a population level, but showed some differences in the correlation with yield and in tracking visual SG grades samples. In SIs, the SGR of Normalized Difference Red-edge Index (NDRE), Red-edge Chlorophyll Index (CIRE), and Normalized Difference Vegetation Index (NDVI) in MSI showed high correlations with yield and could track visual SG grades at an earlier stage of grain filling. In CIs, the SGR of Normalized Green Red Difference Index (NGRDI), the Green Leaf Index (GLI) in RGB and MSI showed low correlations with yield and could only track visual SG grades at late grain filling stage and that of Norm Red (NormR) in RGB images failed to track visual SG grades. This study preliminarily confirms the MSI is more available and reliable than RGB in phenotyping for wheat SG. The index-based SGR in this study could act as HTP reference solutions for SG in diversified wheat genotypes.},
DOI = {10.3390/rs13245173}
}



@Article{s21248501,
AUTHOR = {Mehmood, Abid},
TITLE = {LightAnomalyNet: A Lightweight Framework for Efficient Abnormal Behavior Detection},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {24},
ARTICLE-NUMBER = {8501},
URL = {https://www.mdpi.com/1424-8220/21/24/8501},
PubMedID = {34960594},
ISSN = {1424-8220},
ABSTRACT = {The continuous development of intelligent video surveillance systems has increased the demand for enhanced vision-based methods of automated detection of anomalies within various behaviors found in video scenes. Several methods have appeared in the literature that detect different anomalies by using the details of motion features associated with different actions. To enable the efficient detection of anomalies, alongside characterizing the specificities involved in features related to each behavior, the model complexity leading to computational expense must be reduced. This paper provides a lightweight framework (LightAnomalyNet) comprising a convolutional neural network (CNN) that is trained using input frames obtained by a computationally cost-effective method. The proposed framework effectively represents and differentiates between normal and abnormal events. In particular, this work defines human falls, some kinds of suspicious behavior, and violent acts as abnormal activities, and discriminates them from other (normal) activities in surveillance videos. Experiments on public datasets show that LightAnomalyNet yields better performance comparative to the existing methods in terms of classification accuracy and input frames generation.},
DOI = {10.3390/s21248501}
}



@Article{rs13245182,
AUTHOR = {Etienne, Aaron and Ahmad, Aanis and Aggarwal, Varun and Saraswat, Dharmendra},
TITLE = {Deep Learning-Based Object Detection System for Identifying Weeds Using UAS Imagery},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {24},
ARTICLE-NUMBER = {5182},
URL = {https://www.mdpi.com/2072-4292/13/24/5182},
ISSN = {2072-4292},
ABSTRACT = {Current methods of broadcast herbicide application cause a negative environmental and economic impact. Computer vision methods, specifically those related to object detection, have been reported to aid in site-specific weed management procedures for targeted herbicide application within a field. However, a major challenge to developing a weed detection system is the requirement for a properly annotated database to differentiate between weeds and crops under field conditions. This research involved creating an annotated database of 374 red, green, and blue (RGB) color images organized into monocot and dicot weed classes. The images were acquired from corn and soybean research plots located in north-central Indiana using an unmanned aerial system (UAS) flown at 30 and 10 m heights above ground level (AGL). A total of 25,560 individual weed instances were manually annotated. The annotated database consisted of four different subsets (Training Image Sets 1&ndash;4) to train the You Only Look Once version 3 (YOLOv3) deep learning model for five separate experiments. The best results were observed with Training Image Set 4, consisting of images acquired at 10 m AGL. For monocot and dicot weeds, respectively, an average precision (AP) score of 91.48 % and 86.13% was observed at a 25% IoU threshold (AP @ T = 0.25), as well as 63.37% and 45.13% at a 50% IoU threshold (AP @ T = 0.5). This research has demonstrated a need to develop large, annotated weed databases to evaluate deep learning models for weed identification under field conditions. It also affirms the findings of other limited research studies utilizing object detection for weed identification under field conditions.},
DOI = {10.3390/rs13245182}
}



@Article{app112412164,
AUTHOR = {Li, Changchun and Wang, Yilin and Ma, Chunyan and Chen, Weinan and Li, Yacong and Li, Jingbo and Ding, Fan and Xiao, Zhen},
TITLE = {Improvement of Wheat Grain Yield Prediction Model Performance Based on Stacking Technique},
JOURNAL = {Applied Sciences},
VOLUME = {11},
YEAR = {2021},
NUMBER = {24},
ARTICLE-NUMBER = {12164},
URL = {https://www.mdpi.com/2076-3417/11/24/12164},
ISSN = {2076-3417},
ABSTRACT = {Crop growth and development is a dynamic and complex process, and the essence of yield formation is the continuous accumulation of photosynthetic products from multiple fertility stages. In this study, a new stacking method for integrating multiple growth stages information was proposed to improve the performance of the winter wheat grain yield (GY) prediction model. For this purpose, crop canopy hyperspectral reflectance and leaf area index (LAI) data were obtained at the jointing, flagging, anthesis and grain filling stages. In this case, 15 vegetation indices and LAI were used as input features of the elastic network to construct GY prediction models for single growth stage. Based on Stacking technique, the GY prediction results of four single growth stages were integrated to construct the ensemble learning framework. The results showed that vegetation indices coupled LAI could effectively overcome the spectral saturation phenomenon, the validated R2 of each growth stage was improved by 10%, 22.5%, 3.6% and 10%, respectively. The stacking method provided more stable information with higher prediction accuracy than the individual fertility results (R2 = 0.74), and the R2 of the model validation phase improved by 236%, 51%, 27.6%, and 12.1%, respectively. The study can provide a reference for GY prediction of other crops.},
DOI = {10.3390/app112412164}
}



@Article{foods11010008,
AUTHOR = {Ekramirad, Nader and Khaled, Alfadhl Y. and Doyle, Lauren E. and Loeb, Julia R. and Donohue, Kevin D. and Villanueva, Raul T. and Adedeji, Akinbode A.},
TITLE = {Nondestructive Detection of Codling Moth Infestation in Apples Using Pixel-Based NIR Hyperspectral Imaging with Machine Learning and Feature Selection},
JOURNAL = {Foods},
VOLUME = {11},
YEAR = {2022},
NUMBER = {1},
ARTICLE-NUMBER = {8},
URL = {https://www.mdpi.com/2304-8158/11/1/8},
PubMedID = {35010134},
ISSN = {2304-8158},
ABSTRACT = {Codling moth (CM) (Cydia pomonella L.), a devastating pest, creates a serious issue for apple production and marketing in apple-producing countries. Therefore, effective nondestructive early detection of external and internal defects in CM-infested apples could remarkably prevent postharvest losses and improve the quality of the final product. In this study, near-infrared (NIR) hyperspectral reflectance imaging in the wavelength range of 900&ndash;1700 nm was applied to detect CM infestation at the pixel level for three organic apple cultivars, namely Gala, Fuji and Granny Smith. An effective region of interest (ROI) acquisition procedure along with different machine learning and data processing methods were used to build robust and high accuracy classification models. Optimal wavelength selection was implemented using sequential stepwise selection methods to build multispectral imaging models for fast and effective classification purposes. The results showed that the infested and healthy samples were classified at pixel level with up to 97.4% total accuracy for validation dataset using a gradient tree boosting (GTB) ensemble classifier, among others. The feature selection algorithm obtained a maximum accuracy of 91.6% with only 22 selected wavelengths. These findings indicate the high potential of NIR hyperspectral imaging (HSI) in detecting and classifying latent CM infestation in apples of different cultivars.},
DOI = {10.3390/foods11010008}
}



@Article{su14010046,
AUTHOR = {Fuentes, Jose Eduardo and Garcia, Cesar Edwin and Olaya, Robin Alexis},
TITLE = {Estimation of the Setting and Infrastructure Criterion of the UI GreenMetric Ranking Using Unmanned Aerial Vehicles},
JOURNAL = {Sustainability},
VOLUME = {14},
YEAR = {2022},
NUMBER = {1},
ARTICLE-NUMBER = {46},
URL = {https://www.mdpi.com/2071-1050/14/1/46},
ISSN = {2071-1050},
ABSTRACT = {This study presents a methodology to estimate the seven indicators of the Setting and Infrastructure criterion of the UI GreenMetric World University Ranking based on three-dimensional data from a point cloud taken from an unmanned aerial vehicle (UAV). This study also estimated the potential aerial biomass, C and CO2, stored in the green spaces of a university campus using photogrammetric data analyzed in a Geographic Information System (GIS). The method was based on isolating classified point clouds using digital surface models (DSMs) and ground control points (GCPs) considering the canopy height model (CHM), the allometric equation (DBH, p, h), the biomass conversion factor, and carbon dioxide equivalents (CO2-e). The results confirmed that the national models for estimating the potential C reserves in natural forests are very close to reality and that the open space and green areas available to people on campus are adequate. The use of photogrammetric data facilitated the estimation of UI GreenMetric indicators from a highly detailed, low-cost three-dimensional model. The results of a case study revealed that the campus assimilates the CO2 emissions it produces and generates a surplus.},
DOI = {10.3390/su14010046}
}



@Article{info13010002,
AUTHOR = {Avola, Danilo and Cinque, Luigi and Di Mambro, Angelo and Diko, Anxhelo and Fagioli, Alessio and Foresti, Gian Luca and Marini, Marco Raoul and Mecca, Alessio and Pannone, Daniele},
TITLE = {Low-Altitude Aerial Video Surveillance via One-Class SVM Anomaly Detection from Textural Features in UAV Images},
JOURNAL = {Information},
VOLUME = {13},
YEAR = {2022},
NUMBER = {1},
ARTICLE-NUMBER = {2},
URL = {https://www.mdpi.com/2078-2489/13/1/2},
ISSN = {2078-2489},
ABSTRACT = {In recent years, small-scale Unmanned Aerial Vehicles (UAVs) have been used in many video surveillance applications, such as vehicle tracking, border control, dangerous object detection, and many others. Anomaly detection can represent a prerequisite of many of these applications thanks to its ability to identify areas and/or objects of interest without knowing them a priori. In this paper, a One-Class Support Vector Machine (OC-SVM) anomaly detector based on customized Haralick textural features for aerial video surveillance at low-altitude is presented. The use of a One-Class SVM, which is notoriously a lightweight and fast classifier, enables the implementation of real-time systems even when these are embedded in low-computational small-scale UAVs. At the same time, the use of textural features allows a vision-based system to detect micro and macro structures of an analyzed surface, thus allowing the identification of small and large anomalies, respectively. The latter aspect plays a key role in aerial video surveillance at low-altitude, i.e., 6 to 15 m, where the detection of common items, e.g., cars, is as important as the detection of little and undefined objects, e.g., Improvised Explosive Devices (IEDs). Experiments obtained on the UAV Mosaicking and Change Detection (UMCD) dataset show the effectiveness of the proposed system in terms of accuracy, precision, recall, and F1-score, where the model achieves a 100% precision, i.e., never misses an anomaly, but at the expense of a reasonable trade-off in its recall, which still manages to reach up to a 71.23% score. Moreover, when compared to classical Haralick textural features, the model obtains significantly higher performances, i.e., &asymp;20% on all metrics, further demonstrating the approach effectiveness.},
DOI = {10.3390/info13010002}
}



@Article{su14010071,
AUTHOR = {Kumar, Arun and Sharma, Sharad and Singh, Aman and Alwadain, Ayed and Choi, Bong-Jun and Manual-Brenosa, Jose and Ortega-Mansilla, Arturo and Goyal, Nitin},
TITLE = {Revolutionary Strategies Analysis and Proposed System for Future Infrastructure in Internet of Things},
JOURNAL = {Sustainability},
VOLUME = {14},
YEAR = {2022},
NUMBER = {1},
ARTICLE-NUMBER = {71},
URL = {https://www.mdpi.com/2071-1050/14/1/71},
ISSN = {2071-1050},
ABSTRACT = {The Internet of Things (IoT) has changed the worldwide network of people, smart devices, intelligent things, data, and information as an emergent technology. IoT development is still in its early stages, and numerous interrelated challenges must be addressed. IoT is the unifying idea of embedding everything. The Internet of Things offers a huge opportunity to improve the world&rsquo;s accessibility, integrity, availability, scalability, confidentiality, and interoperability. However, securing the Internet of Things is a difficult issue. The IoT aims to connect almost everything within the framework of a common infrastructure. This helps in controlling devices and, will allow device status to be updated everywhere and at any time. To develop technology via IoT, several critical scientific studies and inquiries have been carried out. However, many obstacles and problems remain to be tackled in order to reach IoT&rsquo;s maximum potential. These problems and concerns must be taken into consideration in different areas of the IoT, such as implementation in remote areas, threats to the system, development support, social and environmental impacts, etc. This paper reviews the current state of the art in different IoT architectures, with a focus on current technologies, applications, challenges, IoT protocols, and opportunities. As a result, a detailed taxonomy of IoT is presented here which includes interoperability, scalability, security and energy efficiency, among other things. Moreover, the significance of blockchains and big data as well as their analysis in relation to IoT, is discussed. This article aims to help readers and researchers understand the IoT and its applicability to the real world.},
DOI = {10.3390/su14010071}
}



@Article{s22010031,
AUTHOR = {Feng, Ziheng and Song, Li and Duan, Jianzhao and He, Li and Zhang, Yanyan and Wei, Yongkang and Feng, Wei},
TITLE = {Monitoring Wheat Powdery Mildew Based on Hyperspectral, Thermal Infrared, and RGB Image Data Fusion},
JOURNAL = {Sensors},
VOLUME = {22},
YEAR = {2022},
NUMBER = {1},
ARTICLE-NUMBER = {31},
URL = {https://www.mdpi.com/1424-8220/22/1/31},
PubMedID = {35009575},
ISSN = {1424-8220},
ABSTRACT = {Powdery mildew severely affects wheat growth and yield; therefore, its effective monitoring is essential for the prevention and control of the disease and global food security. In the present study, a spectroradiometer and thermal infrared cameras were used to obtain hyperspectral signature and thermal infrared images data, and thermal infrared temperature parameters (TP) and texture features (TF) were extracted from the thermal infrared images and RGB images of wheat with powdery mildew, during the wheat flowering and filling periods. Based on the ten vegetation indices from the hyperspectral data (VI), TF and TP were integrated, and partial least square regression, random forest regression (RFR), and support vector machine regression (SVR) algorithms were used to construct a prediction model for a wheat powdery mildew disease index. According to the results, the prediction accuracy of RFR was higher than in other models, under both single data source modeling and multi-source data modeling; among the three data sources, VI was the most suitable for powdery mildew monitoring, followed by TP, and finally TF. The RFR model had stable performance in multi-source data fusion modeling (VI&amp;TP&amp;TF), and had the optimal estimation performance with 0.872 and 0.862 of R2 for calibration and validation, respectively. The application of multi-source data collaborative modeling could improve the accuracy of remote sensing monitoring of wheat powdery mildew, and facilitate the achievement of high-precision remote sensing monitoring of crop disease status.},
DOI = {10.3390/s22010031}
}



@Article{drones6010004,
AUTHOR = {Sharma, Manjula and Gupta, Akshita and Gupta, Sachin Kumar and Alsamhi, Saeed Hamood and Shvetsov, Alexey V.},
TITLE = {Survey on Unmanned Aerial Vehicle for Mars Exploration: Deployment Use Case},
JOURNAL = {Drones},
VOLUME = {6},
YEAR = {2022},
NUMBER = {1},
ARTICLE-NUMBER = {4},
URL = {https://www.mdpi.com/2504-446X/6/1/4},
ISSN = {2504-446X},
ABSTRACT = {In recent years, the area of Unmanned Aerial Vehicles (UAVs) has seen rapid growth. There has been a trend to build and produce UAVs that can carry out planetary exploration throughout the past decade. The technology of UAVs has tremendous potential to support various successful space mission solutions. In general, different techniques for observing space objects are available, such as telescopes, probes, and flying spacecraft, orbiters, landers, and rovers. However, a detailed analysis has been carried out due to the benefits of UAVs relative to other planetary exploration techniques. The deployment of UAVs to other solar bodies has been considered by numerous space agencies worldwide, including NASA. This article contributes to investigating the types of UAVs that have been considered for various planetary explorations. This study further investigates the behaviour of UAV prototypes on Mars&rsquo; surface in particular. It has been discovered that a prototype UAV flight on Mars has a higher chance of success. In this research, a prototype UAV has been successfully simulated to fly on Mars&rsquo; surface. This article discusses the opportunities, challenges, and future scope of deploying UAVs on Mars.},
DOI = {10.3390/drones6010004}
}



@Article{drones6010003,
AUTHOR = {Chaschatzis, Christos and Karaiskou, Chrysoula and Mouratidis, Efstathios G. and Karagiannis, Evangelos and Sarigiannidis, Panagiotis G.},
TITLE = {Detection and Characterization of Stressed Sweet Cherry Tissues Using Machine Learning},
JOURNAL = {Drones},
VOLUME = {6},
YEAR = {2022},
NUMBER = {1},
ARTICLE-NUMBER = {3},
URL = {https://www.mdpi.com/2504-446X/6/1/3},
ISSN = {2504-446X},
ABSTRACT = {Recent technological developments in the primary sector and machine learning algorithms allow the combined application of many promising solutions in precision agriculture. For example, the YOLOv5 (You Only Look Once) and ResNet Deep Learning architecture provide high-precision real-time identifications of objects. The advent of datasets from different perspectives provides multiple benefits, such as spheric view of objects, increased information, and inference results from multiple objects detection per image. However, it also raises crucial obstacles such as total identifications (ground truths) and processing concerns that can lead to devastating consequences, including false-positive detections with other erroneous conclusions or even the inability to extract results. This paper introduces experimental results from the machine learning algorithm (Yolov5) on a novel dataset based on perennial fruit crops, such as sweet cherries, aiming to enhance precision agriculture resiliency. Detection is oriented on two points of interest: (a) Infected leaves and (b) Infected branches. It is noteworthy that infected leaves or branches indicate stress, which may be due to either a stress/disease (e.g., Armillaria for sweet cherries trees, etc.) or other factors (e.g., water shortage, etc). Correspondingly, the foliage of a tree shows symptoms, while this indicates the stages of the disease.},
DOI = {10.3390/drones6010003}
}



@Article{s22010052,
AUTHOR = {Shine, Philip and Murphy, Michael D.},
TITLE = {Over 20 Years of Machine Learning Applications on Dairy Farms: A Comprehensive Mapping Study},
JOURNAL = {Sensors},
VOLUME = {22},
YEAR = {2022},
NUMBER = {1},
ARTICLE-NUMBER = {52},
URL = {https://www.mdpi.com/1424-8220/22/1/52},
PubMedID = {35009593},
ISSN = {1424-8220},
ABSTRACT = {Machine learning applications are becoming more ubiquitous in dairy farming decision support applications in areas such as feeding, animal husbandry, healthcare, animal behavior, milking and resource management. Thus, the objective of this mapping study was to collate and assess studies published in journals and conference proceedings between 1999 and 2021, which applied machine learning algorithms to dairy farming-related problems to identify trends in the geographical origins of data, as well as the algorithms, features and evaluation metrics and methods used. This mapping study was carried out in line with PRISMA guidelines, with six pre-defined research questions (RQ) and a broad and unbiased search strategy that explored five databases. In total, 129 publications passed the pre-defined selection criteria, from which relevant data required to answer each RQ were extracted and analyzed. This study found that Europe (43% of studies) produced the largest number of publications (RQ1), while the largest number of articles were published in the Computers and Electronics in Agriculture journal (21%) (RQ2). The largest number of studies addressed problems related to the physiology and health of dairy cows (32%) (RQ3), while the most frequently employed feature data were derived from sensors (48%) (RQ4). The largest number of studies employed tree-based algorithms (54%) (RQ5), while RMSE (56%) (regression) and accuracy (77%) (classification) were the most frequently employed metrics used, and hold-out cross-validation (39%) was the most frequently employed evaluation method (RQ6). Since 2018, there has been more than a sevenfold increase in the number of studies that focused on the physiology and health of dairy cows, compared to almost a threefold increase in the overall number of publications, suggesting an increased focus on this subdomain. In addition, a fivefold increase in the number of publications that employed neural network algorithms was identified since 2018, in comparison to a threefold increase in the use of both tree-based algorithms and statistical regression algorithms, suggesting an increasing utilization of neural network-based algorithms.},
DOI = {10.3390/s22010052}
}



@Article{s22010059,
AUTHOR = {Huang, Heqing and Huang, Tongbin and Li, Zhen and Lyu, Shilei and Hong, Tao},
TITLE = {Design of Citrus Fruit Detection System Based on Mobile Platform and Edge Computer Device},
JOURNAL = {Sensors},
VOLUME = {22},
YEAR = {2022},
NUMBER = {1},
ARTICLE-NUMBER = {59},
URL = {https://www.mdpi.com/1424-8220/22/1/59},
PubMedID = {35009602},
ISSN = {1424-8220},
ABSTRACT = {Citrus fruit detection can provide technical support for fine management and yield determination of citrus orchards. Accurate detection of citrus fruits in mountain orchards is challenging because of leaf occlusion and citrus fruit mutual occlusion of different fruits. This paper presents a citrus detection task that combines UAV data collection, AI embedded device, and target detection algorithm. The system used a small unmanned aerial vehicle equipped with a camera to take full-scale pictures of citrus trees; at the same time, we extended the state-of-the-art model target detection algorithm, added the attention mechanism and adaptive fusion feature method, improved the model&rsquo;s performance; to facilitate the deployment of the model, we used the pruning method to reduce the amount of model calculation and parameters. The improved target detection algorithm is ported to the edge computing end to detect the data collected by the unmanned aerial vehicle. The experiment was performed on the self-made citrus dataset, the detection accuracy was 93.32%, and the processing speed at the edge computing device was 180 ms/frame. This method is suitable for citrus detection tasks in the mountainous orchard environment, and it can help fruit growers to estimate their yield.},
DOI = {10.3390/s22010059}
}



@Article{rs14010040,
AUTHOR = {Koukouraki, Eftychia and Vanneschi, Leonardo and Painho, Marco},
TITLE = {Few-Shot Learning for Post-Earthquake Urban Damage Detection},
JOURNAL = {Remote Sensing},
VOLUME = {14},
YEAR = {2022},
NUMBER = {1},
ARTICLE-NUMBER = {40},
URL = {https://www.mdpi.com/2072-4292/14/1/40},
ISSN = {2072-4292},
ABSTRACT = {Among natural disasters, earthquakes are recorded to have the highest rates of human loss in the past 20 years. Their unexpected nature has severe consequences on both human lives and material infrastructure, demanding urgent action to be taken. For effective emergency relief, it is necessary to gain awareness about the level of damage in the affected areas. The use of remotely sensed imagery is popular in damage assessment applications; however, it requires a considerable amount of labeled data, which are not always easy to obtain. Taking into consideration the recent developments in the fields of Machine Learning and Computer Vision, this study investigates and employs several Few-Shot Learning (FSL) strategies in order to address data insufficiency and imbalance in post-earthquake urban damage classification. While small datasets have been tested against binary classification problems, which usually divide the urban structures into collapsed and non-collapsed, the potential of limited training data in multi-class classification has not been fully explored. To tackle this gap, four models were created, following different data balancing methods, namely cost-sensitive learning, oversampling, undersampling and Prototypical Networks. After a quantitative comparison among them, the best performing model was found to be the one based on Prototypical Networks, and it was used for the creation of damage assessment maps. The contribution of this work is twofold: we show that oversampling is the most suitable data balancing method for training Deep Convolutional Neural Networks (CNN) when compared to cost-sensitive learning and undersampling, and we demonstrate the appropriateness of Prototypical Networks in the damage classification context.},
DOI = {10.3390/rs14010040}
}



@Article{agronomy12010014,
AUTHOR = {Guo, Jiawei and Jin, Yu and Ye, Huichun and Huang, Wenjiang and Zhao, Jinling and Cui, Bei and Liu, Fucheng and Deng, Jiajian},
TITLE = {Recognition of Areca Leaf Yellow Disease Based on PlanetScope Satellite Imagery},
JOURNAL = {Agronomy},
VOLUME = {12},
YEAR = {2022},
NUMBER = {1},
ARTICLE-NUMBER = {14},
URL = {https://www.mdpi.com/2073-4395/12/1/14},
ISSN = {2073-4395},
ABSTRACT = {Areca yellow leaf disease is a major attacker of the planting and production of arecanut. The continuous expansion of arecanut (Areca catechu L.) planting areas in Hainan has placed a great need to strengthen the monitoring of this disease. At present, there is little research on the monitoring of areca yellow leaf disease. PlanetScope imagery can achieve daily global coverage at a high spatial resolution (3 m) and is thus suitable for the high-precision monitoring of plant pest and disease. In this paper, PlanetScope images were employed to extract spectral features commonly used in disease, pest and vegetation growth monitoring for primary models. In this paper, 13 spectral features commonly used in vegetation growth and pest monitoring were selected to form the initial feature space, followed by the implementation of the Correlation Analysis (CA) and independent t-testing to optimize the feature space. Then, the Random Forest (RF), Backward Propagation Neural Network (BPNN) and AdaBoost algorithms based on feature space optimization to construct double-classification (healthy, diseased) monitoring models for the areca yellow leaf disease. The results indicated that the green, blue and red bands, and plant senescence reflectance index (PSRI) and enhanced vegetation index (EVI) exhibited highly significant differences and strong correlations with healthy and diseased samples. The RF model exhibits the highest overall recognition accuracy for areca yellow leaf disease (88.24%), 2.95% and 20.59% higher than the BPNN and AdaBoost models, respectively. The commission and omission errors were lowest with the RF model for both healthy and diseased samples. This model also exhibited the highest Kappa coefficient at 0.765. Our results exhibit the feasible application of PlanetScope imagery for the regional large-scale monitoring of areca yellow leaf disease, with the RF method identified as the most suitable for this task. Our study provides a reference for the monitoring, a rapid assessment of the area affected and the management planning of the disease in the agricultural and forestry industries.},
DOI = {10.3390/agronomy12010014}
}



@Article{nitrogen3010001,
AUTHOR = {Yu, Jody and Wang, Jinfei and Leblon, Brigitte and Song, Yang},
TITLE = {Nitrogen Estimation for Wheat Using UAV-Based and Satellite Multispectral Imagery, Topographic Metrics, Leaf Area Index, Plant Height, Soil Moisture, and Machine Learning Methods},
JOURNAL = {Nitrogen},
VOLUME = {3},
YEAR = {2022},
NUMBER = {1},
PAGES = {1--25},
URL = {https://www.mdpi.com/2504-3129/3/1/1},
ISSN = {2504-3129},
ABSTRACT = {To improve productivity, reduce production costs, and minimize the environmental impacts of agriculture, the advancement of nitrogen (N) fertilizer management methods is needed. The objective of this study is to compare the use of Unmanned Aerial Vehicle (UAV) multispectral imagery and PlanetScope satellite imagery, together with plant height, leaf area index (LAI), soil moisture, and field topographic metrics to predict the canopy nitrogen weight (g/m2) of wheat fields in southwestern Ontario, Canada. Random Forests (RF) and support vector regression (SVR) models, applied to either UAV imagery or satellite imagery, were evaluated for canopy nitrogen weight prediction. The top-performing UAV imagery-based validation model used SVR with seven selected variables (plant height, LAI, four VIs, and the NIR band) with an R2 of 0.80 and an RMSE of 2.62 g/m2. The best satellite imagery-based validation model was RF, which used 17 variables including plant height, LAI, the four PlanetScope bands, and 11 VIs, resulting in an R2 of 0.92 and an RMSE of 1.75 g/m2. The model information can be used to improve field nitrogen predictions for the effective management of N fertilizer.},
DOI = {10.3390/nitrogen3010001}
}



@Article{s22010071,
AUTHOR = {Xia, Zhiyu and Xu, Zhengyi and Li, Dan and Wei, Jianming},
TITLE = {A Novel Method for Source Tracking of Chemical Gas Leakage: Outlier Mutation Optimization Algorithm},
JOURNAL = {Sensors},
VOLUME = {22},
YEAR = {2022},
NUMBER = {1},
ARTICLE-NUMBER = {71},
URL = {https://www.mdpi.com/1424-8220/22/1/71},
PubMedID = {35009615},
ISSN = {1424-8220},
ABSTRACT = {Chemical industrial parks, which act as critical infrastructures in many cities, need to be responsive to chemical gas leakage accidents. Once a chemical gas leakage accident occurs, risks of poisoning, fire, and explosion will follow. In order to meet the primary emergency response demands in chemical gas leakage accidents, source tracking technology of chemical gas leakage has been proposed and evolved. This paper proposes a novel method, Outlier Mutation Optimization (OMO) algorithm, aimed to quickly and accurately track the source of chemical gas leakage. The OMO algorithm introduces a random walk exploration mode and, based on Swarm Intelligence (SI), increases the probability of individual mutation. Compared with other optimization algorithms, the OMO algorithm has the advantages of a wider exploration range and more convergence modes. In the algorithm test session, a series of chemical gas leakage accident application examples with random parameters are first assumed based on the Gaussian plume model; next, the qualitative experiments and analysis of the OMO algorithm are conducted, based on the application example. The test results show that the OMO algorithm with default parameters has superior comprehensive performance, including the extremely high average calculation accuracy: the optimal value, which represents the error between the final objective function value obtained by the optimization algorithm and the ideal value, reaches 2.464e-15 when the number of sensors is 16; 2.356e-13 when the number of sensors is 9; and 5.694e-23 when the number of sensors is 4. There is a satisfactory calculation time: 12.743 s/50 times when the number of sensors is 16; 10.304 s/50 times when the number of sensors is 9; and 8.644 s/50 times when the number of sensors is 4. The analysis of the OMO algorithm&rsquo;s characteristic parameters proves the flexibility and robustness of this method. In addition, compared with other algorithms, the OMO algorithm can obtain an excellent leakage source tracing result in the application examples of 16, 9 and 4 sensors, and the accuracy exceeds the direct search algorithm, evolutionary algorithm, and other swarm intelligence algorithms.},
DOI = {10.3390/s22010071}
}



@Article{rs14010046,
AUTHOR = {Wei, Lele and Luo, Yusen and Xu, Lizhang and Zhang, Qian and Cai, Qibing and Shen, Mingjun},
TITLE = {Deep Convolutional Neural Network for Rice Density Prescription Map at Ripening Stage Using Unmanned Aerial Vehicle-Based Remotely Sensed Images},
JOURNAL = {Remote Sensing},
VOLUME = {14},
YEAR = {2022},
NUMBER = {1},
ARTICLE-NUMBER = {46},
URL = {https://www.mdpi.com/2072-4292/14/1/46},
ISSN = {2072-4292},
ABSTRACT = {In this paper, UAV (unmanned aerial vehicle, DJI Phantom4RTK) and YOLOv4 (You Only Look Once) target detection deep neural network methods were employed to collected mature rice images and detect rice ears to produce a rice density prescription map. The YOLOv4 model was used for rice ear quick detection of rice images captured by a UAV. The Kriging interpolation algorithm was used in ArcGIS to make rice density prescription maps. Mature rice images collected by a UAV were marked manually and used to build the training and testing datasets. The resolution of the images was 300 &times; 300 pixels. The batch size was 2, and the initial learning rate was 0.01, and the mean average precision (mAP) of the best trained model was 98.84%. Exceptionally, the network ability to detect rice in different health states was also studied with a mAP of 95.42% in the no infection rice images set, 98.84% in the mild infection rice images set, 94.35% in the moderate infection rice images set, and 93.36% in the severe infection rice images set. According to the severity of rice sheath blight, which can cause rice leaves to wither and turn yellow, the blighted grain percentage increased and the thousand-grain weight decreased, the rice images were divided into these four infection levels. The ability of the network model (R2 = 0.844) was compared with traditional image processing segmentation methods (R2 = 0.396) based on color and morphology features and machine learning image segmentation method (Support Vector Machine, SVM R2 = 0.0817, and K-means R2 = 0.1949) for rice ear counting. The results highlight that the CNN has excellent robustness, and can generate a wide range of rice density prescription maps.},
DOI = {10.3390/rs14010046}
}



@Article{rs14010050,
AUTHOR = {He, Haiqing and Yu, Jing and Cheng, Penggen and Wang, Yuqian and Zhu, Yufeng and Lin, Taiqing and Dai, Guoqiang},
TITLE = {Automatic, Multiview, Coplanar Extraction for CityGML Building Model Texture Mapping},
JOURNAL = {Remote Sensing},
VOLUME = {14},
YEAR = {2022},
NUMBER = {1},
ARTICLE-NUMBER = {50},
URL = {https://www.mdpi.com/2072-4292/14/1/50},
ISSN = {2072-4292},
ABSTRACT = {Most 3D CityGML building models in street-view maps (e.g., Google, Baidu) lack texture information, which is generally used to reconstruct real-scene 3D models by photogrammetric techniques, such as unmanned aerial vehicle (UAV) mapping. However, due to its simplified building model and inaccurate location information, the commonly used photogrammetric method using a single data source cannot satisfy the requirement of texture mapping for the CityGML building model. Furthermore, a single data source usually suffers from several problems, such as object occlusion. We proposed a novel approach to achieve CityGML building model texture mapping by multiview coplanar extraction from UAV remotely sensed or terrestrial images to alleviate these problems. We utilized a deep convolutional neural network to filter out object occlusion (e.g., pedestrians, vehicles, and trees) and obtain building-texture distribution. Point-line-based features are extracted to characterize multiview coplanar textures in 2D space under the constraint of a homography matrix, and geometric topology is subsequently conducted to optimize the boundary of textures by using a strategy combining Hough-transform and iterative least-squares methods. Experimental results show that the proposed approach enables texture mapping for building fa&ccedil;ades to use 2D terrestrial images without the requirement of exterior orientation information; that is, different from the photogrammetric method, a collinear equation is not an essential part to capture texture information. In addition, the proposed approach can significantly eliminate blurred and distorted textures of building models, so it is suitable for automatic and rapid texture updates.},
DOI = {10.3390/rs14010050}
}



@Article{s22010085,
AUTHOR = {Guo, Lingli and Jia, Zhenhong and Yang, Jie and Kasabov, Nikola K.},
TITLE = {Detail Preserving Low Illumination Image and Video Enhancement Algorithm Based on Dark Channel Prior},
JOURNAL = {Sensors},
VOLUME = {22},
YEAR = {2022},
NUMBER = {1},
ARTICLE-NUMBER = {85},
URL = {https://www.mdpi.com/1424-8220/22/1/85},
PubMedID = {35009629},
ISSN = {1424-8220},
ABSTRACT = {In low illumination situations, insufficient light in the monitoring device results in poor visibility of effective information, which cannot meet practical applications. To overcome the above problems, a detail preserving low illumination video image enhancement algorithm based on dark channel prior is proposed in this paper. First, a dark channel refinement method is proposed, which is defined by imposing a structure prior to the initial dark channel to improve the image brightness. Second, an anisotropic guided filter (AnisGF) is used to refine the transmission, which preserves the edges of the image. Finally, a detail enhancement algorithm is proposed to avoid the problem of insufficient detail in the initial enhancement image. To avoid video flicker, the next video frames are enhanced based on the brightness of the first enhanced frame. Qualitative and quantitative analysis shows that the proposed algorithm is superior to the contrast algorithm, in which the proposed algorithm ranks first in average gradient, edge intensity, contrast, and patch-based contrast quality index. It can be effectively applied to the enhancement of surveillance video images and for wider computer vision applications.},
DOI = {10.3390/s22010085}
}



@Article{sym14010023,
AUTHOR = {Li, Yuping and Quinn, Brady K. and Gielis, Johan and Li, Yirong and Shi, Peijian},
TITLE = {Evidence That Supertriangles Exist in Nature from the Vertical Projections of Koelreuteria paniculata Fruit},
JOURNAL = {Symmetry},
VOLUME = {14},
YEAR = {2022},
NUMBER = {1},
ARTICLE-NUMBER = {23},
URL = {https://www.mdpi.com/2073-8994/14/1/23},
ISSN = {2073-8994},
ABSTRACT = {Many natural radial symmetrical shapes (e.g., sea stars) follow the Gielis equation (GE) or its twin equation (TGE). A supertriangle (three triangles arranged around a central polygon) represents such a shape, but no study has tested whether natural shapes can be represented as/are supertriangles or whether the GE or TGE can describe their shape. We collected 100 pieces of Koelreuteria paniculata fruit, which have a supertriangular shape, extracted the boundary coordinates for their vertical projections, and then fitted them with the GE and TGE. The adjusted root mean square errors (RMSEadj) of the two equations were always less than 0.08, and &gt;70% were less than 0.05. For 57/100 fruit projections, the GE had a lower RMSEadj than the TGE, although overall differences in the goodness of fit were non-significant. However, the TGE produces more symmetrical shapes than the GE as the two parameters controlling the extent of symmetry in it are approximately equal. This work demonstrates that natural supertriangles exist, validates the use of the GE and TGE to model their shapes, and suggests that different complex radially symmetrical shapes can be generated by the same equation, implying that different types of biological symmetry may result from the same biophysical mechanisms.},
DOI = {10.3390/sym14010023}
}



@Article{s22010094,
AUTHOR = {Murguia-Cozar, Alvaro and Macedo-Cruz, Antonia and Fernandez-Reynoso, Demetrio Salvador and Salgado Transito, Jorge Arturo},
TITLE = {Recognition of Maize Phenology in Sentinel Images with Machine Learning},
JOURNAL = {Sensors},
VOLUME = {22},
YEAR = {2022},
NUMBER = {1},
ARTICLE-NUMBER = {94},
URL = {https://www.mdpi.com/1424-8220/22/1/94},
PubMedID = {35009637},
ISSN = {1424-8220},
ABSTRACT = {The scarcity of water for agricultural use is a serious problem that has increased due to intense droughts, poor management, and deficiencies in the distribution and application of the resource. The monitoring of crops through satellite image processing and the application of machine learning algorithms are technological strategies with which developed countries tend to implement better public policies regarding the efficient use of water. The purpose of this research was to determine the main indicators and characteristics that allow us to discriminate the phenological stages of maize crops (Zea mays L.) in Sentinel 2 satellite images through supervised classification models. The training data were obtained by monitoring cultivated plots during an agricultural cycle. Indicators and characteristics were extracted from 41 Sentinel 2 images acquired during the monitoring dates. With these images, indicators of texture, vegetation, and colour were calculated to train three supervised classifiers: linear discriminant (LD), support vector machine (SVM), and k-nearest neighbours (kNN) models. It was found that 45 of the 86 characteristics extracted contributed to maximizing the accuracy by stage of development and the overall accuracy of the trained classification models. The characteristics of the Moran&rsquo;s I local indicator of spatial association (LISA) improved the accuracy of the classifiers when applied to the L*a*b* colour model and to the near-infrared (NIR) band. The local binary pattern (LBP) increased the accuracy of the classification when applied to the red, green, blue (RGB) and NIR bands. The colour ratios, leaf area index (LAI), RGB colour model, L*a*b* colour space, LISA, and LBP extracted the most important intrinsic characteristics of maize crops with regard to classifying the phenological stages of the maize cultivation. The quadratic SVM model was the best classifier of maize crop phenology, with an overall accuracy of 82.3%.},
DOI = {10.3390/s22010094}
}



@Article{land11010024,
AUTHOR = {Czapiewski, Sebastian and Szumińska, Danuta},
TITLE = {An Overview of Remote Sensing Data Applications in Peatland Research Based on Works from the Period 2010&ndash;2021},
JOURNAL = {Land},
VOLUME = {11},
YEAR = {2022},
NUMBER = {1},
ARTICLE-NUMBER = {24},
URL = {https://www.mdpi.com/2073-445X/11/1/24},
ISSN = {2073-445X},
ABSTRACT = {In the 21st century, remote sensing (RS) has become increasingly employed in many environmental studies. This paper constitutes an overview of works utilising RS methods in studies on peatlands and investigates publications from the period 2010&ndash;2021. Based on fifty-nine case studies from different climatic zones (from subarctic to subtropical), we can indicate an increase in the use of RS methods in peatland research during the last decade, which is likely a result of the greater availability of new remote sensing data sets (Sentinel 1 and 2; Landsat 8; SPOT 6 and 7) paired with the rapid development of open-source software (ESA SNAP; QGIS and SAGA GIS). In the studied works, satellite data analyses typically encompassed the following elements: land classification/identification of peatlands, changes in water conditions in peatlands, monitoring of peatland state, peatland vegetation mapping, Gross Primary Productivity (GPP), and the estimation of carbon resources in peatlands. The most frequently employed research methods, on the other hand, included: vegetation indices, soil moisture indices, water indices, supervised classification and machine learning. Remote sensing data combined with field research is deemed helpful for peatland monitoring and multi-proxy studies, and they may offer new perspectives on research at a regional level.},
DOI = {10.3390/land11010024}
}



@Article{s22010098,
AUTHOR = {Shakhnoza, Muksimova and Sabina, Umirzakova and Sevara, Mardieva and Cho, Young-Im},
TITLE = {Novel Video Surveillance-Based Fire and Smoke Classification Using Attentional Feature Map in Capsule Networks},
JOURNAL = {Sensors},
VOLUME = {22},
YEAR = {2022},
NUMBER = {1},
ARTICLE-NUMBER = {98},
URL = {https://www.mdpi.com/1424-8220/22/1/98},
PubMedID = {35009641},
ISSN = {1424-8220},
ABSTRACT = {A fire is an extraordinary event that can damage property and have a notable effect on people&rsquo;s lives. However, the early detection of smoke and fire has been identified as a challenge in many recent studies. Therefore, different solutions have been proposed to approach the timely detection of fire events and avoid human casualties. As a solution, we used an affordable visual detection system. This method is possibly effective because early fire detection is recognized. In most developed countries, CCTV surveillance systems are installed in almost every public location to take periodic images of a specific area. Notwithstanding, cameras are used under different types of ambient light, and they experience occlusions, distortions of view, and changes in the resulting images from different camera angles and the different seasons of the year, all of which affect the accuracy of currently established models. To address these problems, we developed an approach based on an attention feature map used in a capsule network designed to classify fire and smoke locations at different distances outdoors, given only an image of a single fire and smoke as input. The proposed model was designed to solve two main limitations of the base capsule network input and the analysis of large-sized images, as well as to compensate the absence of a deep network using an attention-based approach to improve the classification of the fire and smoke results. In term of practicality, our method is comparable with prior strategies based on machine learning and deep learning methods. We trained and tested the proposed model using our datasets collected from different sources. As the results indicate, a high classification accuracy in comparison with other modern architectures was achieved. Further, the results indicate that the proposed approach is robust and stable for the classification of images from outdoor CCTV cameras with different viewpoints given the presence of smoke and fire.},
DOI = {10.3390/s22010098}
}



@Article{rs14010065,
AUTHOR = {Zhang, Yuxi and Walker, Jeffrey P. and Pauwels, Valentijn R. N. and Sadeh, Yuval},
TITLE = {Assimilation of Wheat and Soil States into the APSIM-Wheat Crop Model: A Case Study},
JOURNAL = {Remote Sensing},
VOLUME = {14},
YEAR = {2022},
NUMBER = {1},
ARTICLE-NUMBER = {65},
URL = {https://www.mdpi.com/2072-4292/14/1/65},
ISSN = {2072-4292},
ABSTRACT = {Optimised farm crop productivity requires careful management in response to the spatial and temporal variability of yield. Accordingly, combination of crop simulation models and remote sensing data provides a pathway for providing the spatially variable information needed on current crop status and the expected yield. An ensemble Kalman filter (EnKF) data assimilation framework was developed to assimilate plant and soil observations into a prediction model to improve crop development and yield forecasting. Specifically, this study explored the performance of assimilating state observations into the APSIM-Wheat model using a dataset collected during the 2018/19 wheat season at a farm near Cora Lynn in Victoria, Australia. The assimilated state variables include (1) ground-based measurements of Leaf Area Index (LAI), soil moisture throughout the profile, biomass, and soil nitrate-nitrogen; and (2) remotely sensed observations of LAI and surface soil moisture. In a baseline scenario, an unconstrained (open-loop) simulation greatly underestimated the wheat grain with a relative difference (RD) of &minus;38.3%, while the assimilation constrained simulations using ground-based LAI, ground-based biomass, and remotely sensed LAI were all found to improve the RD, reducing it to &minus;32.7%, &minus;9.4%, and &minus;7.6%, respectively. Further improvements in yield estimation were found when: (1) wheat states were assimilated in phenological stages 4 and 5 (end of juvenile to flowering), (2) plot-specific remotely sensed LAI was used instead of the field average, and (3) wheat phenology was constrained by ground observations. Even when using parameters that were not accurately calibrated or measured, the assimilation of LAI and biomass still provided improved yield estimation over that from an open-loop simulation.},
DOI = {10.3390/rs14010065}
}



@Article{horticulturae8010021,
AUTHOR = {Wang, Jizhang and Gao, Zhiheng and Zhang, Yun and Zhou, Jing and Wu, Jianzhi and Li, Pingping},
TITLE = {Real-Time Detection and Location of Potted Flowers Based on a ZED Camera and a YOLO V4-Tiny Deep Learning Algorithm},
JOURNAL = {Horticulturae},
VOLUME = {8},
YEAR = {2022},
NUMBER = {1},
ARTICLE-NUMBER = {21},
URL = {https://www.mdpi.com/2311-7524/8/1/21},
ISSN = {2311-7524},
ABSTRACT = {In order to realize the real-time and accurate detection of potted flowers on benches, in this paper we propose a method based on the ZED 2 stereo camera and the YOLO V4-Tiny deep learning algorithm for potted flower detection and location. First, an automatic detection model of flowers was established based on the YOLO V4-Tiny convolutional neural network (CNN) model, and the center points on the pixel plane of the flowers were obtained according to the prediction box. Then, the real-time 3D point cloud information obtained by the ZED 2 camera was used to calculate the actual position of the flowers. The test results showed that the mean average precision (MAP) and recall rate of the training model was 89.72% and 80%, respectively, and the real-time average detection frame rate of the model deployed under Jetson TX2 was 16 FPS. The results of the occlusion experiment showed that when the canopy overlap ratio between the two flowers is more than 10%, the recognition accuracy will be affected. The mean absolute error of the flower center location based on 3D point cloud information of the ZED 2 camera was 18.1 mm, and the maximum locating error of the flower center was 25.8 mm under different light radiation conditions. The method in this paper establishes the relationship between the detection target of flowers and the actual spatial location, which has reference significance for the machinery and automatic management of potted flowers on benches.},
DOI = {10.3390/horticulturae8010021}
}



@Article{rs14010067,
AUTHOR = {Kwong, Ivan H. Y. and Wong, Frankie K. K. and Fung, Tung and Liu, Eric K. Y. and Lee, Roger H. and Ng, Terence P. T.},
TITLE = {A Multi-Stage Approach Combining Very High-Resolution Satellite Image, GIS Database and Post-Classification Modification Rules for Habitat Mapping in Hong Kong},
JOURNAL = {Remote Sensing},
VOLUME = {14},
YEAR = {2022},
NUMBER = {1},
ARTICLE-NUMBER = {67},
URL = {https://www.mdpi.com/2072-4292/14/1/67},
ISSN = {2072-4292},
ABSTRACT = {Identification and mapping of various habitats with sufficient spatial details are essential to support environmental planning and management. Considering the complexity of diverse habitat types in a heterogeneous landscape, a context-dependent mapping framework is expected to be superior to traditional classification techniques. With the aim to produce a territory-wide habitat map in Hong Kong, a three-stage mapping procedure was developed to identify 21 habitats by combining very-high-resolution satellite images, geographic information system (GIS) layers and knowledge-based modification rules. In stage 1, several classification methods were tested to produce initial results with 11 classes from a WorldView-2/3 image mosaic using a combination of spectral, textural, topographic and geometric variables. In stage 2, modification rules were applied to refine the classification results based on contextual properties and ancillary data layers. Evaluation of the classified maps showed that the highest overall accuracy was obtained from pixel-based random forest classification (84.0%) and the implementation of modification rules led to an average 8.8% increase in the accuracy. In stage 3, the classification scheme was expanded to all 21 habitats through the adoption of additional rules. The resulting habitat map achieved &gt;80% accuracy for most of the evaluated classes and &gt;70% accuracy for the mixed habitats when validated using field-collected points. The proposed mapping framework was able to utilize different information sources in a systematic and controllable workflow. While transitional mixed habitats were mapped using class membership probabilities and a soft classification method, the identification of other habitats benefited from the hybrid use of remote-sensing classification and ancillary data. Adaptive implementation of classification procedures, development of appropriate rules and combination with spatial data are recommended when producing an integrated and accurate map.},
DOI = {10.3390/rs14010067}
}



@Article{drones6010005,
AUTHOR = {Munawar, Hafiz Suliman and Ullah, Fahim and Heravi, Amirhossein and Thaheem, Muhammad Jamaluddin and Maqsoom, Ahsen},
TITLE = {Inspecting Buildings Using Drones and Computer Vision: A Machine Learning Approach to Detect Cracks and Damages},
JOURNAL = {Drones},
VOLUME = {6},
YEAR = {2022},
NUMBER = {1},
ARTICLE-NUMBER = {5},
URL = {https://www.mdpi.com/2504-446X/6/1/5},
ISSN = {2504-446X},
ABSTRACT = {Manual inspection of infrastructure damages such as building cracks is difficult due to the objectivity and reliability of assessment and high demands of time and costs. This can be automated using unmanned aerial vehicles (UAVs) for aerial imagery of damages. Numerous computer vision-based approaches have been applied to address the limitations of crack detection but they have their limitations that can be overcome by using various hybrid approaches based on artificial intelligence (AI) and machine learning (ML) techniques. The convolutional neural networks (CNNs), an application of the deep learning (DL) method, display remarkable potential for automatically detecting image features such as damages and are less sensitive to image noise. A modified deep hierarchical CNN architecture has been used in this study for crack detection and damage assessment in civil infrastructures. The proposed architecture is based on 16 convolution layers and a cycle generative adversarial network (CycleGAN). For this study, the crack images were collected using UAVs and open-source images of mid to high rise buildings (five stories and above) constructed during 2000 in Sydney, Australia. Conventionally, a CNN network only utilizes the last layer of convolution. However, our proposed network is based on the utility of multiple layers. Another important component of the proposed CNN architecture is the application of guided filtering (GF) and conditional random fields (CRFs) to refine the predicted outputs to get reliable results. Benchmarking data (600 images) of Sydney-based buildings damages was used to test the proposed architecture. The proposed deep hierarchical CNN architecture produced superior performance when evaluated using five methods: GF method, Baseline (BN) method, Deep-Crack BN, Deep-Crack GF, and SegNet. Overall, the GF method outperformed all other methods as indicated by the global accuracy (0.990), class average accuracy (0.939), mean intersection of the union overall classes (IoU) (0.879), precision (0.838), recall (0.879), and F-score (0.8581) values. Overall, the proposed CNN architecture provides the advantages of reduced noise, highly integrated supervision of features, adequate learning, and aggregation of both multi-scale and multilevel features during the training procedure along with the refinement of the overall output predictions.},
DOI = {10.3390/drones6010005}
}



@Article{aerospace9010011,
AUTHOR = {Yan, Zhen and Yang, Hongyu and Li, Fan and Lin, Yi},
TITLE = {A Deep Learning Approach for Short-Term Airport Traffic Flow Prediction},
JOURNAL = {Aerospace},
VOLUME = {9},
YEAR = {2022},
NUMBER = {1},
ARTICLE-NUMBER = {11},
URL = {https://www.mdpi.com/2226-4310/9/1/11},
ISSN = {2226-4310},
ABSTRACT = {Airport traffic flow prediction is a fundamental research topic in the field of air traffic flow management. Most existing works focus on the single airport traffic flow prediction with temporal dynamics but fail to consider the influence of the topological airport network. In this paper, a novel deep learning-based framework, called airport traffic flow prediction network (ATFPNet), is proposed to capture spatial-temporal dependencies of the historical airport traffic flow (departure and arrival) for the multiple-step situational (network-level) arrival flow prediction. Firstly, considering the nature of the airport distribution and the context of air transportation, a special semantic graph built on the flight schedule is applied to represent the airport network, which is the key to encoding the situational airport traffic flow into a single representation. Then, the graph convolution operator and the gated recurrent unit are combined to extract high-level transition patterns of airport traffic flow in the spatial and temporal dimensions. Finally, a real-world airport traffic flow dataset is applied to validate the effectiveness of the proposed model, and the experimental results demonstrate that the ATFPNet outperforms other baselines on different prediction horizons. Specifically, the proposed method achieves up to 17% MAE improvement compared to baselines. Based on the proposed approach, efficient traffic planning is expected to be achieved for airport management.},
DOI = {10.3390/aerospace9010011}
}



@Article{rs14010075,
AUTHOR = {Reder, Stefan and Mund, Jan-Peter and Albert, Nicole and Waßermann, Lilli and Miranda, Luis},
TITLE = {Detection of Windthrown Tree Stems on UAV-Orthomosaics Using U-Net Convolutional Networks},
JOURNAL = {Remote Sensing},
VOLUME = {14},
YEAR = {2022},
NUMBER = {1},
ARTICLE-NUMBER = {75},
URL = {https://www.mdpi.com/2072-4292/14/1/75},
ISSN = {2072-4292},
ABSTRACT = {The increasing number of severe storm events is threatening European forests. Besides the primary damages directly caused by storms, there are secondary damages such as bark beetle outbreaks and tertiary damages due to negative effects on the market. These subsequent damages can be minimized if a detailed overview of the affected area and the amount of damaged wood can be obtained quickly and included in the planning of clearance measures. The present work utilizes UAV-orthophotos and an adaptation of the U-Net architecture for the semantic segmentation and localization of windthrown stems. The network was pre-trained with generic datasets, randomly combining stems and background samples in a copy&ndash;paste augmentation, and afterwards trained with a specific dataset of a particular windthrow. The models pre-trained with generic datasets containing 10, 50 and 100 augmentations per annotated windthrown stems achieved F1-scores of 73.9% (S1Mod10), 74.3% (S1Mod50) and 75.6% (S1Mod100), outperforming the baseline model (F1-score 72.6%), which was not pre-trained. These results emphasize the applicability of the method to correctly identify windthrown trees and suggest the collection of training samples from other tree species and windthrow areas to improve the ability to generalize. Further enhancements of the network architecture are considered to improve the classification performance and to minimize the calculative costs.},
DOI = {10.3390/rs14010075}
}



@Article{rs14010092,
AUTHOR = {El-Behaedi, Raghda},
TITLE = {Detection and 3D Modeling of Potential Buried Archaeological Structures Using WorldView-3 Satellite Imagery},
JOURNAL = {Remote Sensing},
VOLUME = {14},
YEAR = {2022},
NUMBER = {1},
ARTICLE-NUMBER = {92},
URL = {https://www.mdpi.com/2072-4292/14/1/92},
ISSN = {2072-4292},
ABSTRACT = {Throughout the world, cultural heritage sites are under the direct threat of damage or destruction due to developing environmental and anthropogenic hazards, such as urban expansion, looting, and rising water levels. Exacerbating this problem is the fact that many of the most vulnerable sites&rsquo; exact locations and/or full spatial extents have yet to be uncovered, making any attempts at their protection exceedingly difficult. However, the utilization of earth observation data has recently emerged as an unmatched tool in the exploration and (digital) preservation of endangered archaeological sites. The presented research employs very high-resolution WorldView-3 satellite imagery (~30 cm) for identifying and delineating previously unknown subsurface archaeological structures at the ancient Egyptian site of Hermopolis (el-Ashmunein). A particular emphasis is placed on the application of spectral indices, specifically those looking at vegetation cropmarks and iron oxide levels. Through this analysis, seven promising structures were identified, including three elongated installations, which may have been utilized for storage purposes, and a potential casemate foundation structure. As 2D outlines of structures are often difficult to visualize, the newly identified archaeological features were expanded into a realistic, georeferenced 3D model using the computer programs, SketchUp Pro and Chaos V-Ray. The goal of this 3D model is to ensure that the results derived from this research are more accessible (and tangible) to a wider audience&mdash;the scientific community and the public alike. The methodological scheme presented in this article is highly adaptable and with some minor modifications can be replicated for other archaeological sites worldwide.},
DOI = {10.3390/rs14010092}
}



@Article{agronomy12010043,
AUTHOR = {Ponce, Juan Manuel and Aquino, Arturo and Tejada, Diego and Al-Hadithi, Basil Mohammed and Andújar, José Manuel},
TITLE = {A Methodology for the Automated Delineation of Crop Tree Crowns from UAV-Based Aerial Imagery by Means of Morphological Image Analysis},
JOURNAL = {Agronomy},
VOLUME = {12},
YEAR = {2022},
NUMBER = {1},
ARTICLE-NUMBER = {43},
URL = {https://www.mdpi.com/2073-4395/12/1/43},
ISSN = {2073-4395},
ABSTRACT = {The popularisation of aerial remote sensing using unmanned aerial vehicles (UAV), has boosted the capacities of agronomists and researchers to offer farmers valuable data regarding the status of their crops. This paper describes a methodology for the automated detection and individual delineation of tree crowns in aerial representations of crop fields by means of image processing and analysis techniques, providing accurate information about plant population and canopy coverage in intensive-farming orchards with a row-based plant arrangement. To that end, after pre-processing initial aerial captures by means of photogrammetry and morphological image analysis, a resulting binary representation of the land plot surveyed is treated at connected component-level in order to separate overlapping tree crown projections. Then, those components are morphologically transformed into a set of seeds with which tree crowns are finally delineated, establishing the boundaries between them when they appear overlapped. This solution was tested on images from three different orchards, achieving semantic segmentations in which more than 94% of tree canopy-belonging pixels were correctly classified, and more than 98% of trees were successfully detected when assessing the methodology capacities for estimating the overall plant population. According to these results, the methodology represents a promising tool for automating the inventorying of plants and estimating individual tree-canopy coverage in intensive tree-based orchards.},
DOI = {10.3390/agronomy12010043}
}



@Article{rs14010093,
AUTHOR = {Santos, Adão F. and Lacerda, Lorena N. and Rossi, Chiara and Moreno, Leticia de A. and Oliveira, Mailson F. and Pilon, Cristiane and Silva, Rouverson P. and Vellidis, George},
TITLE = {Using UAV and Multispectral Images to Estimate Peanut Maturity Variability on Irrigated and Rainfed Fields Applying Linear Models and Artificial Neural Networks},
JOURNAL = {Remote Sensing},
VOLUME = {14},
YEAR = {2022},
NUMBER = {1},
ARTICLE-NUMBER = {93},
URL = {https://www.mdpi.com/2072-4292/14/1/93},
ISSN = {2072-4292},
ABSTRACT = {Using UAV and multispectral images has contributed to identifying field variability and improving crop management through different data modeling methods. However, knowledge on application of these tools to manage peanut maturity variability is still lacking. Therefore, the objective of this study was to compare and validate linear and multiple linear regression with models using artificial neural networks (ANN) for estimating peanut maturity under irrigated and rainfed conditions. The models were trained (80% dataset) and tested (20% dataset) using results from the 2018 and 2019 growing seasons from irrigated and rainfed fields. In each field, plant reflectance was collected weekly from 90 days after planting using a UAV-mounted multispectral camera. Images were used to develop vegetation indices (VIs). Peanut pods were collected on the same dates as the UAV flights for maturity assessment using the peanut maturity index (PMI). The precision and accuracy of the linear models to estimate PMI using VIs were, in general, greater in irrigated fields with R2 &gt; 0.40 than in rainfed areas, which had a maximum R2 value of 0.21. Multiple linear regressions combining adjusted growing degree days (aGDD) and VIs resulted in decreased RMSE for both irrigated and rainfed conditions and increased R2 in irrigated areas. However, these models did not perform successfully in the test process. On the other hand, ANN models that included VIs and aGDD showed accuracy of R2 = 0.91 in irrigated areas, regardless of using Multilayer Perceptron (MLP; RMSE = 0.062) or Radial Basis Function (RBF; RMSE = 0.065), as well as low tendency (1:1 line). These results indicated that, regardless of the ANN architecture used to predict complex and non-linear variables, peanut maturity can be estimated accurately through models with multiple inputs using VIs and aGDD. Although the accuracy of the MLP or RBF models for irrigated and rainfed areas separately was high, the overall ANN models using both irrigated and rainfed areas can be used to predict peanut maturity with the same precision.},
DOI = {10.3390/rs14010093}
}



@Article{ijerph19010237,
AUTHOR = {Rizk, Hamada and Nishimur, Yukako and Yamaguchi, Hirozumi and Higashino, Teruo},
TITLE = {Drone-Based Water Level Detection in Flood Disasters},
JOURNAL = {International Journal of Environmental Research and Public Health},
VOLUME = {19},
YEAR = {2022},
NUMBER = {1},
ARTICLE-NUMBER = {237},
URL = {https://www.mdpi.com/1660-4601/19/1/237},
PubMedID = {35010497},
ISSN = {1660-4601},
ABSTRACT = {Japan was hit by typhoon Hagibis, which came with torrential rains submerging almost eight-thousand buildings. For fast alleviation of and recovery from flood damage, a quick, broad, and accurate assessment of the damage situation is required. Image analysis provides a much more feasible alternative than on-site sensors due to their installation and maintenance costs. Nevertheless, most state-of-art research relies on only ground-level images that are inevitably limited in their field of vision. This paper presents a water level detection system based on aerial drone-based image recognition. The system applies the R-CNN learning model together with a novel labeling method on the reference objects, including houses and cars. The proposed system tackles the challenges of the limited and wild data set of flood images from the top view with data augmentation and transfer-learning overlaying Mask R-CNN for the object recognition model. Additionally, the VGG16 network is employed for water level detection purposes. We evaluated the proposed system on realistic images captured at disaster time. Preliminary results show that the system can achieve a detection accuracy of submerged objects of 73.42% with as low as only 21.43 cm error in estimating the water level.},
DOI = {10.3390/ijerph19010237}
}



@Article{app12010209,
AUTHOR = {Chang, Yeong-Hwa and Chen, Yen-Jen and Huang, Ren-Hung and Yu, Yi-Ting},
TITLE = {Enhanced Image Captioning with Color Recognition Using Deep Learning Methods},
JOURNAL = {Applied Sciences},
VOLUME = {12},
YEAR = {2022},
NUMBER = {1},
ARTICLE-NUMBER = {209},
URL = {https://www.mdpi.com/2076-3417/12/1/209},
ISSN = {2076-3417},
ABSTRACT = {Automatically describing the content of an image is an interesting and challenging task in artificial intelligence. In this paper, an enhanced image captioning model&mdash;including object detection, color analysis, and image captioning&mdash;is proposed to automatically generate the textual descriptions of images. In an encoder&ndash;decoder model for image captioning, VGG16 is used as an encoder and an LSTM (long short-term memory) network with attention is used as a decoder. In addition, Mask R-CNN with OpenCV is used for object detection and color analysis. The integration of the image caption and color recognition is then performed to provide better descriptive details of images. Moreover, the generated textual sentence is converted into speech. The validation results illustrate that the proposed method can provide more accurate description of images.},
DOI = {10.3390/app12010209}
}



@Article{rs14010102,
AUTHOR = {Li, Xin and Li, Tao and Chen, Ziqi and Zhang, Kaiwen and Xia, Runliang},
TITLE = {Attentively Learning Edge Distributions for Semantic Segmentation of Remote Sensing Imagery},
JOURNAL = {Remote Sensing},
VOLUME = {14},
YEAR = {2022},
NUMBER = {1},
ARTICLE-NUMBER = {102},
URL = {https://www.mdpi.com/2072-4292/14/1/102},
ISSN = {2072-4292},
ABSTRACT = {Semantic segmentation has been a fundamental task in interpreting remote sensing imagery (RSI) for various downstream applications. Due to the high intra-class variants and inter-class similarities, inflexibly transferring natural image-specific networks to RSI is inadvisable. To enhance the distinguishability of learnt representations, attention modules were developed and applied to RSI, resulting in satisfactory improvements. However, these designs capture contextual information by equally handling all the pixels regardless of whether they around edges. Therefore, blurry boundaries are generated, rising high uncertainties in classifying vast adjacent pixels. Hereby, we propose an edge distribution attention module (EDA) to highlight the edge distributions of leant feature maps in a self-attentive fashion. In this module, we first formulate and model column-wise and row-wise edge attention maps based on covariance matrix analysis. Furthermore, a hybrid attention module (HAM) that emphasizes the edge distributions and position-wise dependencies is devised combing with non-local block. Consequently, a conceptually end-to-end neural network, termed as EDENet, is proposed to integrate HAM hierarchically for the detailed strengthening of multi-level representations. EDENet implicitly learns representative and discriminative features, providing available and reasonable cues for dense prediction. The experimental results evaluated on ISPRS Vaihingen, Potsdam and DeepGlobe datasets show the efficacy and superiority to the state-of-the-art methods on overall accuracy (OA) and mean intersection over union (mIoU). In addition, the ablation study further validates the effects of EDA.},
DOI = {10.3390/rs14010102}
}



@Article{s22010139,
AUTHOR = {Miao, Yu and Hunter, Alan and Georgilas, Ioannis},
TITLE = {An Occupancy Mapping Method Based on K-Nearest Neighbours},
JOURNAL = {Sensors},
VOLUME = {22},
YEAR = {2022},
NUMBER = {1},
ARTICLE-NUMBER = {139},
URL = {https://www.mdpi.com/1424-8220/22/1/139},
PubMedID = {35009685},
ISSN = {1424-8220},
ABSTRACT = {OctoMap is an efficient probabilistic mapping framework to build occupancy maps from point clouds, representing 3D environments with cubic nodes in the octree. However, the map update policy in OctoMap has limitations. All the nodes containing points will be assigned with the same probability regardless of the points being noise, and the probability of one such node can only be increased with a single measurement. In addition, potentially occupied nodes with points inside but traversed by rays cast from the sensor to endpoints will be marked as free. To overcome these limitations in OctoMap, the current work presents a mapping method using the context of neighbouring points to update nodes containing points, with occupancy information of a point represented by the average distance from a point to its k-Nearest Neighbours. A relationship between the distance and the change in probability is defined with the Cumulative Density Function of average distances, potentially decreasing the probability of a node despite points being present inside. Experiments are conducted on 20 data sets to compare the proposed method with OctoMap. Results show that our method can achieve up to 10% improvement over the optimal performance of OctoMap.},
DOI = {10.3390/s22010139}
}



@Article{rs14010103,
AUTHOR = {Yan, Dongchuan and Zhang, Hao and Li, Guoqing and Li, Xiangqiang and Lei, Hua and Lu, Kaixuan and Zhang, Lianchong and Zhu, Fuxiao},
TITLE = {Improved Method to Detect the Tailings Ponds from Multispectral Remote Sensing Images Based on Faster R-CNN and Transfer Learning},
JOURNAL = {Remote Sensing},
VOLUME = {14},
YEAR = {2022},
NUMBER = {1},
ARTICLE-NUMBER = {103},
URL = {https://www.mdpi.com/2072-4292/14/1/103},
ISSN = {2072-4292},
ABSTRACT = {The breaching of tailings pond dams may lead to casualties and environmental pollution; therefore, timely and accurate monitoring is an essential aspect of managing such structures and preventing accidents. Remote sensing technology is suitable for the regular extraction and monitoring of tailings pond information. However, traditional remote sensing is inefficient and unsuitable for the frequent extraction of large volumes of highly precise information. Object detection, based on deep learning, provides a solution to this problem. Most remote sensing imagery applications for tailings pond object detection using deep learning are based on computer vision, utilizing the true-color triple-band data of high spatial resolution imagery for information extraction. The advantage of remote sensing image data is their greater number of spectral bands (more than three), providing more abundant spectral information. There is a lack of research on fully harnessing multispectral band information to improve the detection precision of tailings ponds. Accordingly, using a sample dataset of tailings pond satellite images from the Gaofen-1 high-resolution Earth observation satellite, we improved the Faster R-CNN deep learning object detection model by increasing the inputs from three true-color bands to four multispectral bands. Moreover, we used the attention mechanism to recalibrate the input contributions. Subsequently, we used a step-by-step transfer learning method to improve and gradually train our model. The improved model could fully utilize the near-infrared (NIR) band information of the images to improve the precision of tailings pond detection. Compared with that of the three true-color band input models, the tailings pond detection average precision (AP) and recall notably improved in our model, with the AP increasing from 82.3% to 85.9% and recall increasing from 65.4% to 71.9%. This research could serve as a reference for using multispectral band information from remote sensing images in the construction and application of deep learning models.},
DOI = {10.3390/rs14010103}
}



@Article{s22010146,
AUTHOR = {Shafi, Uferah and Mumtaz, Rafia and Haq, Ihsan Ul and Hafeez, Maryam and Iqbal, Naveed and Shaukat, Arslan and Zaidi, Syed Mohammad Hassan and Mahmood, Zahid},
TITLE = {Wheat Yellow Rust Disease Infection Type Classification Using Texture Features},
JOURNAL = {Sensors},
VOLUME = {22},
YEAR = {2022},
NUMBER = {1},
ARTICLE-NUMBER = {146},
URL = {https://www.mdpi.com/1424-8220/22/1/146},
PubMedID = {35009689},
ISSN = {1424-8220},
ABSTRACT = {Wheat is a staple crop of Pakistan that covers almost 40% of the cultivated land and contributes almost 3% in the overall Gross Domestic Product (GDP) of Pakistan. However, due to increasing seasonal variation, it was observed that wheat is majorly affected by rust disease, particularly in rain-fed areas. Rust is considered the most harmful fungal disease for wheat, which can cause reductions of 20&ndash;30% in wheat yield. Its capability to spread rapidly over time has made its management most challenging, becoming a major threat to food security. In order to counter this threat, precise detection of wheat rust and its infection types is important for minimizing yield losses. For this purpose, we have proposed a framework for classifying wheat yellow rust infection types using machine learning techniques. First, an image dataset of different yellow rust infections was collected using mobile cameras. Six Gray Level Co-occurrence Matrix (GLCM) texture features and four Local Binary Patterns (LBP) texture features were extracted from grayscale images of the collected dataset. In order to classify wheat yellow rust disease into its three classes (healthy, resistant, and susceptible), Decision Tree, Random Forest, Light Gradient Boosting Machine (LightGBM), Extreme Gradient Boosting (XGBoost), and CatBoost were used with (i) GLCM, (ii) LBP, and (iii) combined GLCM-LBP texture features. The results indicate that CatBoost outperformed on GLCM texture features with an accuracy of 92.30%. This accuracy can be further improved by scaling up the dataset and applying deep learning models. The development of the proposed study could be useful for the agricultural community for the early detection of wheat yellow rust infection and assist in taking remedial measures to contain crop yield.},
DOI = {10.3390/s22010146}
}



@Article{electronics11010073,
AUTHOR = {Avazov, Kuldoshbay and Mukhiddinov, Mukhriddin and Makhmudov, Fazliddin and Cho, Young Im},
TITLE = {Fire Detection Method in Smart City Environments Using a Deep-Learning-Based Approach},
JOURNAL = {Electronics},
VOLUME = {11},
YEAR = {2022},
NUMBER = {1},
ARTICLE-NUMBER = {73},
URL = {https://www.mdpi.com/2079-9292/11/1/73},
ISSN = {2079-9292},
ABSTRACT = {In the construction of new smart cities, traditional fire-detection systems can be replaced with vision-based systems to establish fire safety in society using emerging technologies, such as digital cameras, computer vision, artificial intelligence, and deep learning. In this study, we developed a fire detector that accurately detects even small sparks and sounds an alarm within 8 s of a fire outbreak. A novel convolutional neural network was developed to detect fire regions using an enhanced You Only Look Once (YOLO) v4network. Based on the improved YOLOv4 algorithm, we adapted the network to operate on the Banana Pi M3 board using only three layers. Initially, we examined the originalYOLOv4 approach to determine the accuracy of predictions of candidate fire regions. However, the anticipated results were not observed after several experiments involving this approach to detect fire accidents. We improved the traditional YOLOv4 network by increasing the size of the training dataset based on data augmentation techniques for the real-time monitoring of fire disasters. By modifying the network structure through automatic color augmentation, reducing parameters, etc., the proposed method successfully detected and notified the incidence of disastrous fires with a high speed and accuracy in different weather environments&mdash;sunny or cloudy, day or night. Experimental results revealed that the proposed method can be used successfully for the protection of smart cities and in monitoring fires in urban areas. Finally, we compared the performance of our method with that of recently reported fire-detection approaches employing widely used performance matrices to test the fire classification results achieved.},
DOI = {10.3390/electronics11010073}
}



@Article{s22010150,
AUTHOR = {Kang, Cheongwoong and Park, Bumjin and Choi, Jaesik},
TITLE = {Scheduling PID Attitude and Position Control Frequencies for Time-Optimal Quadrotor Waypoint Tracking under Unknown External Disturbances},
JOURNAL = {Sensors},
VOLUME = {22},
YEAR = {2022},
NUMBER = {1},
ARTICLE-NUMBER = {150},
URL = {https://www.mdpi.com/1424-8220/22/1/150},
PubMedID = {35009692},
ISSN = {1424-8220},
ABSTRACT = {Recently, the use of quadrotors has increased in numerous applications, such as agriculture, rescue, transportation, inspection, and localization. Time-optimal quadrotor waypoint tracking is defined as controlling quadrotors to follow the given waypoints as quickly as possible. Although PID control is widely used for quadrotor control, it is not adaptable to environmental changes, such as various trajectories and dynamic external disturbances. In this work, we discover that adjusting PID control frequencies is necessary for adapting to environmental changes by showing that the optimal control frequencies can be different for different environments. Therefore, we suggest a method to schedule the PID position and attitude control frequencies for time-optimal quadrotor waypoint tracking. The method includes (1) a Control Frequency Agent (CFA) that finds the best control frequencies in various environments, (2) a Quadrotor Future Predictor (QFP) that predicts the next state of a quadrotor, and (3) combining the CFA and QFP for time-optimal quadrotor waypoint tracking under unknown external disturbances. The experimental results prove the effectiveness of the proposed method by showing that it reduces the travel time of a quadrotor for waypoint tracking.},
DOI = {10.3390/s22010150}
}



@Article{math10010083,
AUTHOR = {Cho, Sung-Won and Park, Jin-Hyoung and Park, Hyun-Ji and Kim, Seongmin},
TITLE = {Multi-UAV Coverage Path Planning Based on Hexagonal Grid Decomposition in Maritime Search and Rescue},
JOURNAL = {Mathematics},
VOLUME = {10},
YEAR = {2022},
NUMBER = {1},
ARTICLE-NUMBER = {83},
URL = {https://www.mdpi.com/2227-7390/10/1/83},
ISSN = {2227-7390},
ABSTRACT = {In the event of a maritime accident, surveying the maximum area efficiently in the least amount of time is crucial for rescuing survivors. Increasingly, unmanned aerial vehicles (UAVs) are being used in search and rescue operations. This study proposes a method to generate a search path that covers all generated nodes in the shortest amount of time with multiple heterogeneous UAVs. The proposed model, which is a mixed-integer linear programming (MILP) model based on a hexagonal grid-based decomposition method, was verified through a simulation analysis based on the performance of an actual UAV. This study presents both the optimization technique&rsquo;s calculation time as a function of the search area size and the various UAV routes derived as the search area grows. The results of this study can have wide-ranging applications for emergency search and rescue operations.},
DOI = {10.3390/math10010083}
}



@Article{app12010229,
AUTHOR = {Matuzevičius, Dalius and Serackis, Artūras},
TITLE = {Three-Dimensional Human Head Reconstruction Using Smartphone-Based Close-Range Video Photogrammetry},
JOURNAL = {Applied Sciences},
VOLUME = {12},
YEAR = {2022},
NUMBER = {1},
ARTICLE-NUMBER = {229},
URL = {https://www.mdpi.com/2076-3417/12/1/229},
ISSN = {2076-3417},
ABSTRACT = {Creation of head 3D models from videos or pictures of the head by using close-range photogrammetry techniques has many applications in clinical, commercial, industrial, artistic, and entertainment areas. This work aims to create a methodology for improving 3D head reconstruction, with a focus on using selfie videos as the data source. Then, using this methodology, we seek to propose changes for the general-purpose 3D reconstruction algorithm to improve the head reconstruction process. We define the improvement of the 3D head reconstruction as an increase of reconstruction quality (which is lowering reconstruction errors of the head and amount of semantic noise) and reduction of computational load. We proposed algorithm improvements that increase reconstruction quality by removing image backgrounds and by selecting diverse and high-quality frames. Algorithm modifications were evaluated on videos of the mannequin head. Evaluation results show that baseline reconstruction is improved 12 times due to the reduction of semantic noise and reconstruction errors of the head. The reduction of computational demand was achieved by reducing the frame number needed to process, reducing the number of image matches required to perform, reducing an average number of feature points in images, and still being able to provide the highest precision of the head reconstruction.},
DOI = {10.3390/app12010229}
}



@Article{electronics11010088,
AUTHOR = {Maaruf, Muhammad and Khalid, Muhammad},
TITLE = {Global Sliding-Mode Control with Fractional-Order Terms for the Robust Optimal Operation of a Hybrid Renewable Microgrid with Battery Energy Storage},
JOURNAL = {Electronics},
VOLUME = {11},
YEAR = {2022},
NUMBER = {1},
ARTICLE-NUMBER = {88},
URL = {https://www.mdpi.com/2079-9292/11/1/88},
ISSN = {2079-9292},
ABSTRACT = {The efficiency of hybrid microgrid systems is drastically affected by the number of power electronics converters interfacing with its components. Integrating distributed energy sources with microgrids with the optimal number of converters is crucial to minimizing the switching losses and power conversion stages, thereby improving the efficiency of the systems. This paper considers an efficient and economical configuration for a wind/solar photovoltaic (PV) system integrated with a battery energy storage system (BES). The PV system is connected directly to the DC-link, thus lowering the losses and cost by eliminating the PV boost converter. In the literature, only a few publications have investigated this effective microgrid configuration. In addition, none of the publications have developed a nonlinear control approach for the microgrid configuration. Due to the greater flexibility of fractional calculus in speeding up the system response and improving the robustness, this article proposes a global sliding-mode control method with fractional-order terms (GSMCFO) to enhance the transient, steady-state, and robust operation of the hybrid microgrid. This controller provides the maximum power point tracking (MPPT) of both the solar PV and wind power generators, regulates the DC-link voltage, ensures proper power transfer to the grid, and maintains the power balance. In addition, the GSMCFO guarantees the global stability of the hybrid microgrid. Furthermore, considering the simplicity, robustness, few control variables, and fast convergence rate of the differential evolution (DE) optimization method, it is utilized to optimize the performance of the GSMCFO. The proposed hybrid microgrid configuration under the action of the GSMCFO was simulated in MATLAB/SIMULINK. Various scenarios were investigated to illustrate the feasibility of the proposed scheme. The simulation results show that the GSMCFO can achieve superior dynamic performances than the proportional&ndash;integral (PI) controller with zero overshoot, a shorter settling time, and stronger robustness, thus improving the power balance of the hybrid microgrid.},
DOI = {10.3390/electronics11010088}
}



@Article{s22010189,
AUTHOR = {Besada, Juan A. and Campaña, Ivan and Carramiñana, David and Bergesio, Luca and de Miguel, Gonzalo},
TITLE = {Review and Simulation of Counter-UAS Sensors for Unmanned Traffic Management},
JOURNAL = {Sensors},
VOLUME = {22},
YEAR = {2022},
NUMBER = {1},
ARTICLE-NUMBER = {189},
URL = {https://www.mdpi.com/1424-8220/22/1/189},
PubMedID = {35009730},
ISSN = {1424-8220},
ABSTRACT = {Noncollaborative surveillance of airborne UAS (Unmanned Aerial System) is a key enabler to the safe integration of UAS within a UTM (Unmanned Traffic Management) ecosystem. Thus, a wide variety of new sensors (known as Counter-UAS sensors) are being developed to provide real-time UAS tracking, ranging from radar, RF analysis and image-based detection to even sound-based sensors. This paper aims to discuss the current state-of-the art technology in this wide variety of sensors (both academically and commercially) and to propose a set of simulation models for them. Thus, the review is focused on identifying the key parameters and processes that allow modeling their performance and operation, which reflect the variety of measurement processes. The resulting simulation models are designed to help evaluate how sensors&rsquo; performances affect UTM systems, and specifically the implications in their tracking and tactical services (i.e., tactical conflicts with uncontrolled drones). The simulation models cover probabilistic detection (i.e., false alarms and probability of detection) and measurement errors, considering equipment installation (i.e., monostatic vs. multistatic configurations, passive sensing, etc.). The models were integrated in a UTM simulation platform and simulation results are included in the paper for active radars, passive radars, and acoustic sensors.},
DOI = {10.3390/s22010189}
}



@Article{s22010208,
AUTHOR = {Muntean, Maria Viorela},
TITLE = {Multi-Agent System for Intelligent Urban Traffic Management Using Wireless Sensor Networks Data},
JOURNAL = {Sensors},
VOLUME = {22},
YEAR = {2022},
NUMBER = {1},
ARTICLE-NUMBER = {208},
URL = {https://www.mdpi.com/1424-8220/22/1/208},
PubMedID = {35009750},
ISSN = {1424-8220},
ABSTRACT = {Intelligent traffic management is an important issue for smart cities. City councils try to implement the newest techniques and performant technologies in order to avoid traffic congestion, to optimize the use of traffic lights, to efficiently use car parking, etc. To find the best solution to this problem, Birmingham City Council decided to allow open-source predictive traffic forecasting by making the real-time datasets available. This paper proposes a multi-agent system (MAS) approach for intelligent urban traffic management in Birmingham using forecasting and classification techniques. The designed agents have the following tasks: forecast the occupancy rates for traffic flow, road junctions and car parking; classify the faults; control and monitor the entire process. The experimental results show that k-nearest neighbor forecasts with high accuracy rates for the traffic data and decision trees build the most accurate model for classifying the faults for their detection and repair in the shortest possible time. The whole learning process is coordinated by a monitoring agent in order to automate Birmingham city&rsquo;s traffic management.},
DOI = {10.3390/s22010208}
}



@Article{s22010207,
AUTHOR = {Chen, Qi and Zhang, Yuanyi and Li, Xinyuan and Tao, Pengjie},
TITLE = {Extracting Rectified Building Footprints from Traditional Orthophotos: A New Workflow},
JOURNAL = {Sensors},
VOLUME = {22},
YEAR = {2022},
NUMBER = {1},
ARTICLE-NUMBER = {207},
URL = {https://www.mdpi.com/1424-8220/22/1/207},
PubMedID = {35009755},
ISSN = {1424-8220},
ABSTRACT = {Deep learning techniques such as convolutional neural networks have largely improved the performance of building segmentation from remote sensing images. However, the images for building segmentation are often in the form of traditional orthophotos, where the relief displacement would cause non-negligible misalignment between the roof outline and the footprint of a building; such misalignment poses considerable challenges for extracting accurate building footprints, especially for high-rise buildings. Aiming at alleviating this problem, a new workflow is proposed for generating rectified building footprints from traditional orthophotos. We first use the facade labels, which are prepared efficiently at low cost, along with the roof labels to train a semantic segmentation network. Then, the well-trained network, which employs the state-of-the-art version of EfficientNet as backbone, extracts the roof segments and the facade segments of buildings from the input image. Finally, after clustering the classified pixels into instance-level building objects and tracing out the roof outlines, an energy function is proposed to drive the roof outline to maximally align with the building footprint; thus, the rectified footprints can be generated. The experiments on the aerial orthophotos covering a high-density residential area in Shanghai demonstrate that the proposed workflow can generate obviously more accurate building footprints than the baseline methods, especially for high-rise buildings.},
DOI = {10.3390/s22010207}
}



@Article{su14010327,
AUTHOR = {Tuśnio, Norbert and Wróblewski, Wojciech},
TITLE = {The Efficiency of Drones Usage for Safety and Rescue Operations in an Open Area: A Case from Poland},
JOURNAL = {Sustainability},
VOLUME = {14},
YEAR = {2022},
NUMBER = {1},
ARTICLE-NUMBER = {327},
URL = {https://www.mdpi.com/2071-1050/14/1/327},
ISSN = {2071-1050},
ABSTRACT = {The use of unmanned aerial systems (UAS) is becoming increasingly frequent during search and rescue (SAR) operations conducted to find missing persons. These systems have proven to be particularly useful for operations executed in the wilderness, i.e., in open and mountainous areas. The successful implementation of those systems is possible thanks to the potential offered by unmanned aerial vehicles (UAVs), which help achieve a considerable reduction in operational times and consequently allow a much quicker finding of lost persons. This is crucial to enhance their chances of survival in extreme conditions (withholding hydration, food and medicine, and hypothermia). The paper presents the results of a preliminary assessment of a search and rescue method conducted in an unknown terrain, where groups were coordinated with the use of UAVs and a ground control station (GCS) workstation. The conducted analysis was focused on assessing conditions that would help minimise the time of arrival of the rescue team to the target, which in real conditions could be a missing person identified on aerial images. The results of executed field tests have proven that the time necessary to reach injured persons can be substantially shortened if imaging recorded by UAV is deployed, as it considerably enhances the chance of survival in an emergency situation. The GCS workstation is also one of the crucial components in the search system, which assures image transmission from the UAV to participants of the search operation and radio signal amplification in a difficult terrain. The effectiveness of the search system was tested by comparing the arrival times of teams equipped with GPS and a compass and those not equipped with such equipment. The article also outlined the possibilities of extending the functionality of the search system with the SARUAV module, which was used to find a missing person in Poland.},
DOI = {10.3390/su14010327}
}



@Article{rs14010132,
AUTHOR = {Nigon, Tyler and Paiao, Gabriel Dias and Mulla, David J. and Fernández, Fabián G. and Yang, Ce},
TITLE = {The Influence of Aerial Hyperspectral Image Processing Workflow on Nitrogen Uptake Prediction Accuracy in Maize},
JOURNAL = {Remote Sensing},
VOLUME = {14},
YEAR = {2022},
NUMBER = {1},
ARTICLE-NUMBER = {132},
URL = {https://www.mdpi.com/2072-4292/14/1/132},
ISSN = {2072-4292},
ABSTRACT = {A meticulous image processing workflow is oftentimes required to derive quality image data from high-resolution, unmanned aerial systems. There are many subjective decisions to be made during image processing, but the effects of those decisions on prediction model accuracy have never been reported. This study introduced a framework for quantifying the effects of image processing methods on model accuracy. A demonstration of this framework was performed using high-resolution hyperspectral imagery (&lt;10 cm pixel size) for predicting maize nitrogen uptake in the early to mid-vegetative developmental stages (V6&ndash;V14). Two supervised regression learning estimators (Lasso and partial least squares) were trained to make predictions from hyperspectral imagery. Data for this use case were collected from three experiments over two years (2018&ndash;2019) in southern Minnesota, USA (four site-years). The image processing steps that were evaluated include (i) reflectance conversion, (ii) cropping, (iii) spectral clipping, (iv) spectral smoothing, (v) binning, and (vi) segmentation. In total, 648 image processing workflow scenarios were evaluated, and results were analyzed to understand the influence of each image processing step on the cross-validated root mean squared error (RMSE) of the estimators. A sensitivity analysis revealed that the segmentation step was the most influential image processing step on the final estimator error. Across all workflow scenarios, the RMSE of predicted nitrogen uptake ranged from 14.3 to 19.8 kg ha&minus;1 (relative RMSE ranged from 26.5% to 36.5%), a 38.5% increase in error from the lowest to the highest error workflow scenario. The framework introduced demonstrates the sensitivity and extent to which image processing affects prediction accuracy. It allows remote sensing analysts to improve model performance while providing data-driven justification to improve the reproducibility and objectivity of their work, similar to the benefits of hyperparameter tuning in machine learning applications.},
DOI = {10.3390/rs14010132}
}



@Article{agronomy12010075,
AUTHOR = {Pérez-Méndez, Néstor and Miguel-Rojas, Cristina and Jimenez-Berni, Jose Antonio and Gomez-Candon, David and Pérez-de-Luque, Alejandro and Fereres, Elias and Catala-Forner, Mar and Villegas, Dolors and Sillero, Josefina C.},
TITLE = {Plant Breeding and Management Strategies to Minimize the Impact of Water Scarcity and Biotic Stress in Cereal Crops under Mediterranean Conditions},
JOURNAL = {Agronomy},
VOLUME = {12},
YEAR = {2022},
NUMBER = {1},
ARTICLE-NUMBER = {75},
URL = {https://www.mdpi.com/2073-4395/12/1/75},
ISSN = {2073-4395},
ABSTRACT = {Wheat and rice are two main staple food crops that may suffer from yield losses due to drought episodes that are increasingly impacted by climate change, in addition to new epidemic outbreaks. Sustainable intensification of production will rely on several strategies, such as efficient use of water and variety improvement. This review updates the latest findings regarding complementary approaches in agronomy, genetics, and phenomics to cope with climate change challenges. The agronomic approach focuses on a case study examining alternative rice water management practices, with their impact on greenhouse gas emissions and biodiversity for ecosystem services. The genetic approach reviews in depth the latest technologies to achieve fungal disease resistance, as well as the use of landraces to increase the genetic diversity of new varieties. The phenomics approach explores recent advances in high-throughput remote sensing technologies useful in detecting both biotic and abiotic stress effects on breeding programs. The complementary nature of all these technologies indicates that only interdisciplinary work will ensure significant steps towards a more sustainable agriculture under future climate change scenarios.},
DOI = {10.3390/agronomy12010075}
}



@Article{en15010217,
AUTHOR = {Velusamy, Parthasarathy and Rajendran, Santhosh and Mahendran, Rakesh Kumar and Naseer, Salman and Shafiq, Muhammad and Choi, Jin-Ghoo},
TITLE = {Unmanned Aerial Vehicles (UAV) in Precision Agriculture: Applications and Challenges},
JOURNAL = {Energies},
VOLUME = {15},
YEAR = {2022},
NUMBER = {1},
ARTICLE-NUMBER = {217},
URL = {https://www.mdpi.com/1996-1073/15/1/217},
ISSN = {1996-1073},
ABSTRACT = {Agriculture is the primary source of income in developing countries like India. Agriculture accounts for 17 percent of India&rsquo;s total GDP, with almost 60 percent of the people directly or indirectly employed. While researchers and planters focus on a variety of elements to boost productivity, crop loss due to disease is one of the most serious issues they confront. Crop growth monitoring and early detection of pest infestations are still a problem. With the expansion of cultivation to wider fields, manual intervention to monitor and diagnose insect and pest infestations is becoming increasingly difficult. Failure to apply on time fertilizers and pesticides results in more crop loss and so lower output. Farmers are putting in greater effort to conserve crops, but they are failing most of the time because they are unable to adequately monitor the crops when they are infected by pests and insects. Pest infestation is also difficult to predict because it is not evenly distributed. In the recent past, modern equipment, tools, and approaches have been used to replace manual involvement. Unmanned aerial vehicles serve a critical role in crop disease surveillance and early detection in this setting. This research attempts to give a review of the most successful techniques to have precision-based crop monitoring and pest management in agriculture fields utilizing unmanned aerial vehicles (UAVs) or unmanned aircraft. The researchers&rsquo; reports on the various types of UAVs and their applications to early detection of agricultural diseases are rigorously assessed and compared. This paper also discusses the deployment of aerial, satellite, and other remote sensing technologies for disease detection, as well as their Quality of Service (QoS).},
DOI = {10.3390/en15010217}
}



@Article{drones6010008,
AUTHOR = {Basan, Elena and Basan, Alexandr and Nekrasov, Alexey and Fidge, Colin and Sushkin, Nikita and Peskova, Olga},
TITLE = {GPS-Spoofing Attack Detection Technology for UAVs Based on Kullback&ndash;Leibler Divergence},
JOURNAL = {Drones},
VOLUME = {6},
YEAR = {2022},
NUMBER = {1},
ARTICLE-NUMBER = {8},
URL = {https://www.mdpi.com/2504-446X/6/1/8},
ISSN = {2504-446X},
ABSTRACT = {Here, we developed a method for detecting cyber security attacks aimed at spoofing the Global Positioning System (GPS) signal of an Unmanned Aerial Vehicle (UAV). Most methods for detecting UAV anomalies indicative of an attack use machine learning or other such methods that compare normal behavior with abnormal behavior. Such approaches require large amounts of data and significant &ldquo;training&rdquo; time to prepare and implement the system. Instead, we consider a new approach based on other mathematical methods for detecting UAV anomalies without the need to first collect a large amount of data and describe normal behavior patterns. Doing so can simplify the process of creating an anomaly detection system, which can further facilitate easier implementation of intrusion detection systems in UAVs. This article presents issues related to ensuring the information security of UAVs. Development of the GPS spoofing detection method for UAVs is then described, based on a preliminary study that made it possible to form a mathematical apparatus for solving the problem. We then explain the necessary analysis of parameters and methods of data normalization, and the analysis of the Kullback&mdash;Leibler divergence measure needed to detect anomalies in UAV systems.},
DOI = {10.3390/drones6010008}
}



@Article{rs14010148,
AUTHOR = {Chen, Yang and Ma, Lixia and Yu, Dongsheng and Feng, Kaiyue and Wang, Xin and Song, Jie},
TITLE = {Improving Leaf Area Index Retrieval Using Multi-Sensor Images and Stacking Learning in Subtropical Forests of China},
JOURNAL = {Remote Sensing},
VOLUME = {14},
YEAR = {2022},
NUMBER = {1},
ARTICLE-NUMBER = {148},
URL = {https://www.mdpi.com/2072-4292/14/1/148},
ISSN = {2072-4292},
ABSTRACT = {The leaf area index (LAI) is a key indicator of the status of forest ecosystems that is important for understanding global carbon and water cycles as well as terrestrial surface energy balances and the impacts of climate change. Machine learning (ML) methods offer promising ways of generating spatially explicit LAI data covering large regions based on optical images. However, there have been few efforts to analyze the LAI in heterogeneous subtropical forests with complex terrain by fusing high-resolution multi-sensor data from the Sentinel-1 Synthetic Aperture Radar (SAR), Sentinel-2 Multi Spectral Instrument (MSI), and Advanced Land Observing Satellite-1 digital elevation model (DEM). Here, forest LAI mapping was performed by integrating the MSI, SAR, and DEM data using a stacking learning (SL) approach that incorporates distinct predictions from a set of optimized individual ML algorithms. The method&rsquo;s performance was evaluated by comparison to field forest LAI measurements acquired in Xingguo and Gandong of subtropical China. The results showed that the addition of the SAR and DEM images using the SL model compared to the inputs of only optical images reduced the mean absolute error (MAE) and root mean square error (RMSE) by 26% and 18%, respectively, in Xingguo, and by 12% and 8%, respectively, in Gandong. Furthermore, the combination of all images had the best prediction performance. SL was found to be more robust and accurate than conventional individual ML models, while the MAE and RMSE were decreased by 71% and 64%, respectively, in Xingguo, and by 68% and 59%, respectively, in Gandong. Therefore, the SL model using the three-source data combination produced satisfied prediction accuracy with the coefficients of determination (R2), MAE, and RMSE of 0.96, 0.17, and 0.28, respectively, in Xingguo and 0.94, 0.30, and 0.47, respectively, in Gandong. This study revealed the potential of the SL algorithm for retrieving the forest LAI using multi-sensor data in areas with complex terrain.},
DOI = {10.3390/rs14010148}
}



@Article{s22010251,
AUTHOR = {Rani, Pooja and Kavita,  and Verma, Sahil and Kaur, Navneet and Wozniak, Marcin and Shafi, Jana and Ijaz, Muhammad Fazal},
TITLE = {Robust and Secure Data Transmission Using Artificial Intelligence Techniques in Ad-Hoc Networks},
JOURNAL = {Sensors},
VOLUME = {22},
YEAR = {2022},
NUMBER = {1},
ARTICLE-NUMBER = {251},
URL = {https://www.mdpi.com/1424-8220/22/1/251},
ISSN = {1424-8220},
ABSTRACT = {The paper presents a new security aspect for a Mobile Ad-Hoc Network (MANET)-based IoT model using the concept of artificial intelligence. The Black Hole Attack (BHA) is considered one of the most affecting threats in the MANET in which the attacker node drops the entire data traffic and hence degrades the network performance. Therefore, it necessitates the designing of an algorithm that can protect the network from the BHA node. This article introduces Ad-hoc On-Demand Distance Vector (AODV), a new updated routing protocol that combines the advantages of the Artificial Bee Colony (ABC), Artificial Neural Network (ANN), and Support Vector Machine (SVM) techniques. The combination of the SVM with ANN is the novelty of the proposed model that helps to identify the attackers within the discovered route using the AODV routing mechanism. Here, the model is trained using ANN but the selection of training data is performed using the ABC fitness function followed by SVM. The role of ABC is to provide a better route for data transmission between the source and the destination node. The optimized route, suggested by ABC, is then passed to the SVM model along with the node&rsquo;s properties. Based on those properties ANN decides whether the node is a normal or an attacker node. The simulation analysis performed in MATLAB shows that the proposed work exhibits an improvement in terms of Packet Delivery Ratio (PDR), throughput, and delay. To validate the system efficiency, a comparative analysis is performed against the existing approaches such as Decision Tree and Random Forest that indicate that the utilization of the SVM with ANN is a beneficial step regarding the detection of BHA attackers in the MANET-based IoT networks.},
DOI = {10.3390/s22010251}
}



@Article{rs14010150,
AUTHOR = {You, Jie and Zhang, Ruirui and Lee, Joonwhoan},
TITLE = {A Deep Learning-Based Generalized System for Detecting Pine Wilt Disease Using RGB-Based UAV Images},
JOURNAL = {Remote Sensing},
VOLUME = {14},
YEAR = {2022},
NUMBER = {1},
ARTICLE-NUMBER = {150},
URL = {https://www.mdpi.com/2072-4292/14/1/150},
ISSN = {2072-4292},
ABSTRACT = {Pine wilt is a devastating disease that typically kills affected pine trees within a few months. In this paper, we confront the problem of detecting pine wilt disease. In the image samples that have been used for pine wilt disease detection, there is high ambiguity due to poor image resolution and the presence of &ldquo;disease-like&rdquo; objects. We therefore created a new dataset using large-sized orthophotographs collected from 32 cities, 167 regions, and 6121 pine wilt disease hotspots in South Korea. In our system, pine wilt disease was detected in two stages: n the first stage, the disease and hard negative samples were collected using a convolutional neural network. Because the diseased areas varied in size and color, and as the disease manifests differently from the early stage to the late stage, hard negative samples were further categorized into six different classes to simplify the complexity of the dataset. Then, in the second stage, we used an object detection model to localize the disease and &ldquo;disease-like&rdquo; hard negative samples. We used several image augmentation methods to boost system performance and avoid overfitting. The test process was divided into two phases: a patch-based test and a real-world test. During the patch-based test, we used the test-time augmentation method to obtain the average prediction of our system across multiple augmented samples of data, and the prediction results showed a mean average precision of 89.44% in five-fold cross validation, thus representing an increase of around 5% over the alternative system. In the real-world test, we collected 10 orthophotographs in various resolutions and areas, and our system successfully detected 711 out of 730 potential disease spots.},
DOI = {10.3390/rs14010150}
}



@Article{agronomy12010081,
AUTHOR = {Sinde-González, Izar and Gómez-López, Josselyn Paola and Tapia-Navarro, Stalin Alejandro and Murgueitio, Erika and Falconí, César and Benítez, Fatima L. and Toulkeridis, Theofilos},
TITLE = {Determining the Effects of Nanonutrient Application in Cabbage (Brassica oleracea var. capitate L.) Using Spectrometry and Biomass Estimation with UAV},
JOURNAL = {Agronomy},
VOLUME = {12},
YEAR = {2022},
NUMBER = {1},
ARTICLE-NUMBER = {81},
URL = {https://www.mdpi.com/2073-4395/12/1/81},
ISSN = {2073-4395},
ABSTRACT = {Geospatial technologies are presented as an alternative for the monitoring and control of crops, as demonstrated through the analysis of spectral responses (SR) of each species. In this study, it was intended to determine the effects of the application of nanonutrients (Zn and Mn) in cabbage (Brassica oleracea var. capitate L.) by analyzing the relationship between the vegetation indices (VI) NDVI, GNDVI, NGRDI, RVI, GVI, CCI RARSa and the content of chlorophyll (CC), from two trials established in the field and in the greenhouse, together with the calculation of dry biomass production in the field through the use of digital models and its further validation. The results indicated that for greenhouse experiments no significant differences were found between the VIs in the implemented treatments, rather for their phenological states. Whereas in the field assays it was evidenced that there were significant differences between the VIs for the treatments, as well as for the phenological states. The SR issued in the field allowed the evaluation of the behavior of the crop due to the application of nanonutrients, which did not occur in the greenhouse, in the same way. The SR also enabled the spectral characterization of the crop in its phenological states in the two trials. All this information was stored in a digital format, which allowed the creation of a spectral library which was published on a web server. The validation of the dry biomass allowed, by statistical analysis, the efficiency of the method used for its estimation to be confirmed.},
DOI = {10.3390/agronomy12010081}
}



@Article{jcm11010192,
AUTHOR = {Lin, Cheng-Yu and Wang, Yi-Wen and Setiawan, Febryan and Trang, Nguyen Thi Hoang and Lin, Che-Wei},
TITLE = {Sleep Apnea Classification Algorithm Development Using a Machine-Learning Framework and Bag-of-Features Derived from Electrocardiogram Spectrograms},
JOURNAL = {Journal of Clinical Medicine},
VOLUME = {11},
YEAR = {2022},
NUMBER = {1},
ARTICLE-NUMBER = {192},
URL = {https://www.mdpi.com/2077-0383/11/1/192},
PubMedID = {35011934},
ISSN = {2077-0383},
ABSTRACT = {Background: Heart rate variability (HRV) and electrocardiogram (ECG)-derived respiration (EDR) have been used to detect sleep apnea (SA) for decades. The present study proposes an SA-detection algorithm using a machine-learning framework and bag-of-features (BoF) derived from an ECG spectrogram. Methods: This study was verified using overnight ECG recordings from 83 subjects with an average apnea&ndash;hypopnea index (AHI) 29.63 (/h) derived from the Physionet Apnea-ECG and National Cheng Kung University Hospital Sleep Center database. The study used signal preprocessing to filter noise and artifacts, ECG time&ndash;frequency transformation using continuous wavelet transform (CWT), BoF feature generation, machine-learning classification using support vector machine (SVM), ensemble learning (EL), k-nearest neighbor (KNN) classification, and cross-validation. The time length of the spectrogram was set as 10 and 60 s to examine the required minimum spectrogram window time length to achieve satisfactory accuracy. Specific frequency bands of 0.1&ndash;50, 8&ndash;50, 0.8&ndash;10, and 0&ndash;0.8 Hz were also extracted to generate the BoF to determine the band frequency best suited for SA detection. Results: The five-fold cross-validation accuracy using the BoF derived from the ECG spectrogram with 10 and 60 s time windows were 90.5% and 91.4% for the 0.1&ndash;50 Hz and 8&ndash;50 Hz frequency bands, respectively. Conclusion: An SA-detection algorithm utilizing BoF and a machine-learning framework was successfully developed in this study with satisfactory classification accuracy and high temporal resolution.},
DOI = {10.3390/jcm11010192}
}



@Article{agronomy12010090,
AUTHOR = {Issaoui, Wissal and Alexakis, Dimitrios D. and Nasr, Imen Hamdi and Argyriou, Athanasios V. and Alevizos, Evangelos and Papadopoulos, Nikos and Inoubli, Mohamed Hédi},
TITLE = {Monitoring Olive Oil Mill Wastewater Disposal Sites Using Sentinel-2 and PlanetScope Satellite Images: Case Studies in Tunisia and Greece},
JOURNAL = {Agronomy},
VOLUME = {12},
YEAR = {2022},
NUMBER = {1},
ARTICLE-NUMBER = {90},
URL = {https://www.mdpi.com/2073-4395/12/1/90},
ISSN = {2073-4395},
ABSTRACT = {Mediterranean countries are known worldwide for their significant contribution to olive oil production, which generates large amounts of olive mill wastewater (OMW) that degrades land and water environments near the disposal sites. OMW consists of organic substances with high concentrations of phenolic compounds along with inorganic particles. The aim of this study is to assess the effectiveness of satellite image analysis techniques using multispectral satellite data with high (PlanetScope, 3 &times; 3 m) and medium (Sentinel-2, 10 &times; 10 m) spatial resolution to detect Olive Mill Wastewater (OMW) disposal sites, both in the SidiBouzid region (Tunisia) and in the broader Rethymno region on the island of Crete, (Greece). Documentation of the sites was carried out by collecting spectral signatures of OMW at temporal periods. The study integrates the application of a variety of spectral vegetation indices (VIs), such as the Normalized Difference Vegetation Index (NDVI), in order to evaluate their efficiency in detecting OMW disposal areas. Furthermore, a set of image-processing methods was applied on satellite images to improve the monitoring of OMW ponds including the false-color composites (FCC), the Principal Component Analysis (PCA), and image fusion. Finally, different classification algorithms, such as the ISODATA, the maximum likelihood (ML), and the Support Vector Machine (SVM) were applied to both satellite images in order to assist in the overall approach to effectively detect the sites. The results obtained from different approaches were compared, evaluating the efficiency of Sentinel-2 and PlanetScope images to detect and monitor OMW disposal areas under different morphological environments.},
DOI = {10.3390/agronomy12010090}
}



@Article{electronics11010121,
AUTHOR = {Tanveer, Jawad and Haider, Amir and Ali, Rashid and Kim, Ajung},
TITLE = {Machine Learning for Physical Layer in 5G and beyond Wireless Networks: A Survey},
JOURNAL = {Electronics},
VOLUME = {11},
YEAR = {2022},
NUMBER = {1},
ARTICLE-NUMBER = {121},
URL = {https://www.mdpi.com/2079-9292/11/1/121},
ISSN = {2079-9292},
ABSTRACT = {Fifth-generation (5G) technology will play a vital role in future wireless networks. The breakthrough 5G technology will unleash a massive Internet of Everything (IoE), where billions of connected devices, people, and processes will be simultaneously served. The services provided by 5G include several use cases enabled by the enhanced mobile broadband, massive machine-type communications, and ultra-reliable low-latency communication. Fifth-generation networks potentially merge multiple networks on a single platform, providing a landscape for seamless connectivity, particularly for high-mobility devices. With their enhanced speed, 5G networks are prone to various research challenges. In this context, we provide a comprehensive survey on 5G technologies that emphasize machine learning-based solutions to cope with existing and future challenges. First, we discuss 5G network architecture and outline the key performance indicators compared to the previous and upcoming network generations. Second, we discuss next-generation wireless networks and their characteristics, applications, and use cases for fast connectivity to billions of devices. Then, we confer physical layer services, functions, and issues that decrease the signal quality. We also present studies on 5G network technologies, 5G propelling trends, and architectures that help to achieve the goals of 5G. Moreover, we discuss signaling techniques for 5G massive multiple-input and multiple-output and beam-forming techniques to enhance data rates with efficient spectrum sharing. Further, we review security and privacy concerns in 5G and standard bodies&rsquo; actionable recommendations for policy makers. Finally, we also discuss emerging challenges and future directions.},
DOI = {10.3390/electronics11010121}
}



@Article{ijgi11010023,
AUTHOR = {Akcay, Ozgun and Kinaci, Ahmet Cumhur and Avsar, Emin Ozgur and Aydar, Umut},
TITLE = {Semantic Segmentation of High-Resolution Airborne Images with Dual-Stream DeepLabV3+},
JOURNAL = {ISPRS International Journal of Geo-Information},
VOLUME = {11},
YEAR = {2022},
NUMBER = {1},
ARTICLE-NUMBER = {23},
URL = {https://www.mdpi.com/2220-9964/11/1/23},
ISSN = {2220-9964},
ABSTRACT = {In geospatial applications such as urban planning and land use management, automatic detection and classification of earth objects are essential and primary subjects. When the significant semantic segmentation algorithms are considered, DeepLabV3+ stands out as a state-of-the-art CNN. Although the DeepLabV3+ model is capable of extracting multi-scale contextual information, there is still a need for multi-stream architectural approaches and different training approaches of the model that can leverage multi-modal geographic datasets. In this study, a new end-to-end dual-stream architecture that considers geospatial imagery was developed based on the DeepLabV3+ architecture. As a result, the spectral datasets other than RGB provided increments in semantic segmentation accuracies when they were used as additional channels to height information. Furthermore, both the given data augmentation and Tversky loss function which is sensitive to imbalanced data accomplished better overall accuracies. Also, it has been shown that the new dual-stream architecture using Potsdam and Vaihingen datasets produced 88.87% and 87.39% overall semantic segmentation accuracies, respectively. Eventually, it was seen that enhancement of the traditional significant semantic segmentation networks has a great potential to provide higher model performances, whereas the contribution of geospatial data as the second stream to RGB to segmentation was explicitly shown.},
DOI = {10.3390/ijgi11010023}
}



@Article{rs14010166,
AUTHOR = {Zhang, Xuan and Zhu, Chun and He, Manchao and Dong, Menglong and Zhang, Guangcheng and Zhang, Faming},
TITLE = {Failure Mechanism and Long Short-Term Memory Neural Network Model for Landslide Risk Prediction},
JOURNAL = {Remote Sensing},
VOLUME = {14},
YEAR = {2022},
NUMBER = {1},
ARTICLE-NUMBER = {166},
URL = {https://www.mdpi.com/2072-4292/14/1/166},
ISSN = {2072-4292},
ABSTRACT = {Rockslides along a stepped failure surface have characteristics of stepped deformation characteristic and it is difficult to predict the failure time. In this study, the deformation characteristics and disaster prediction model of the Fengning granite rockslide were analyzed based on field surveys and monitoring data. To evaluate the stability, the shear strength parameters of the sliding surface were determined based on the back-propagation neural network and three-dimensional discrete element numerical method. Through the correlation analysis of deformation monitoring results with rainfall and blasting, it is shown that the landslide was triggered by excavation, rainfall, and blasting vibrations. The landslide displacement prediction model was established by using long short-term memory neural network (LSTM) based on the monitoring data, and the prediction results are compared with those using the BP model, SVM model and ARMA model. Results show that the LSTM model has strong advantages and good reliability for the stepped landslide deformation with short-term influence, and the predicted LSTM values were very consistent with the measured values, with a correlation coefficient of 0.977. Combined with the distribution characteristics of joints, the damage influence scope of the landslide was simulated by three-dimensional discrete element, which provides decision-making basis for disaster warning after slope instability. The method proposed in this paper can provide references for early warning and treatment of geological disasters.},
DOI = {10.3390/rs14010166}
}



@Article{electronics11010128,
AUTHOR = {Tehseen, Aqsa and Zafar, Nazir Ahmad and Ali, Tariq and Jameel, Fatima and Alkhammash, Eman H.},
TITLE = {Formal Modeling of IoT and Drone-Based Forest Fire Detection and Counteraction System},
JOURNAL = {Electronics},
VOLUME = {11},
YEAR = {2022},
NUMBER = {1},
ARTICLE-NUMBER = {128},
URL = {https://www.mdpi.com/2079-9292/11/1/128},
ISSN = {2079-9292},
ABSTRACT = {Forests are an enduring component of the natural world and perform a vital role in protecting the environment. Forests are valuable resources to control global warming and provide oxygen for the survival of human life, including wood for households. Forest fires have recently emerged as a major threat to biological processes and the ecosystem. Unfortunately, almost every year, fire damages millions of hectares of forest land due to late and inefficient detection of fire. However, it is important to identify the forest fire at the initial level before it spreads to vast areas and destroys natural resources. In this paper, a formal model of the Internet of Things (IoT) and drone-based forest fire detection and counteraction system is presented. The proposed system comprises network maintenance. Sensor deployment is on trees, the ground, and animals in the form of subnets to transmit sensed data to the control room. All subnets are connected to the control room through gateway nodes. Alarms are being used to alert human beings and animals to save their lives, which will help to initially protect them from fire. The embedded sensors collect the information and transfer it to the gateways. Drones are being used for real-time visualization of fire-affected areas and to perform actions to control fires because they play a vital role in disasters. Graph theory is used to construct an efficient model and to show the connectivity of the network. To identify failures and develop recovery procedures, the algorithm is designed through the graph-based model. The model is developed by the Vienna Development Method-Specification Language (VDM-SL), and the correctness of the model is ensured using various VDM-SL toolbox facilities.},
DOI = {10.3390/electronics11010128}
}



@Article{ijerph19010437,
AUTHOR = {Szurgacz, Dawid and Zhironkin, Sergey and Pokorný, Jiří and Spearing, A. J. S. (Sam) and Vöth, Stefan and Cehlár, Michal and Kowalewska, Izabela},
TITLE = {Development of an Active Training Method for Belt Conveyor},
JOURNAL = {International Journal of Environmental Research and Public Health},
VOLUME = {19},
YEAR = {2022},
NUMBER = {1},
ARTICLE-NUMBER = {437},
URL = {https://www.mdpi.com/1660-4601/19/1/437},
PubMedID = {35010694},
ISSN = {1660-4601},
ABSTRACT = {The global situation related to the COVID-19 pandemic has forced employers to find an adequate way to conduct training in order to ensure work safety. The underground mining industry is one of the industries which, due to its nature, was not able to switch to remote work. Conducting traditional training risked spreading the virus among workers. For this purpose, it was necessary to start a search for a form of training that would be safe and would not cause additional stress for employees. Research on the development of an active employee training method and testing of the method itself was conducted online. In order to develop a method of active training, one of the most important workstations was selected, which is the operation of the conveyor belt. The training method comprises four training modules. The modules cover questions related to the operation of the conveyor belt, emergencies, its assembly and disassembly, repair and maintenance. The developed issues also take into account questions concerning natural hazards and work safety. The entire training course lasts 10 days. Every day, an employee receives a set of eight questions sent to their email address, which they must answer before starting work. The article describes the methodology and implementation of the training.},
DOI = {10.3390/ijerph19010437}
}



@Article{machines10010028,
AUTHOR = {Piratelo, Paulo Henrique Martinez and de Azeredo, Rodrigo Negri and Yamao, Eduardo Massashi and Bianchi Filho, Jose Francisco and Maidl, Gabriel and Lisboa, Felipe Silveira Marques and de Jesus, Laercio Pereira and Penteado Neto, Renato de Arruda and Coelho, Leandro dos Santos and Leandro, Gideon Villar},
TITLE = {Blending Colored and Depth CNN Pipelines in an Ensemble Learning Classification Approach for Warehouse Application Using Synthetic and Real Data},
JOURNAL = {Machines},
VOLUME = {10},
YEAR = {2022},
NUMBER = {1},
ARTICLE-NUMBER = {28},
URL = {https://www.mdpi.com/2075-1702/10/1/28},
ISSN = {2075-1702},
ABSTRACT = {Electric companies face flow control and inventory obstacles such as reliability, outlays, and time-consuming tasks. Convolutional Neural Networks (CNNs) combined with computational vision approaches can process image classification in warehouse management applications to tackle this problem. This study uses synthetic and real images applied to CNNs to deal with classification of inventory items. The results are compared to seek the neural networks that better suit this application. The methodology consists of fine-tuning several CNNs on Red&ndash;Green&ndash;Blue (RBG) and Red&ndash;Green&ndash;Blue-Depth (RGB-D) synthetic and real datasets, using the best architecture of each domain in a blended ensemble approach. The proposed blended ensemble approach was not yet explored in such an application, using RGB and RGB-D data, from synthetic and real domains. The use of a synthetic dataset improved accuracy, precision, recall and f1-score in comparison with models trained only on the real domain. Moreover, the use of a blend of DenseNet and Resnet pipelines for colored and depth images proved to outperform accuracy, precision and f1-score performance indicators over single CNNs, achieving an accuracy measurement of 95.23%. The classification task is a real logistics engineering problem handled by computer vision and artificial intelligence, making full use of RGB and RGB-D images of synthetic and real domains, applied in an approach of blended CNN pipelines.},
DOI = {10.3390/machines10010028}
}



@Article{mi13010072,
AUTHOR = {Li, Dengshan and Wang, Rujing and Chen, Peng and Xie, Chengjun and Zhou, Qiong and Jia, Xiufang},
TITLE = {Visual Feature Learning on Video Object and Human Action Detection: A Systematic Review},
JOURNAL = {Micromachines},
VOLUME = {13},
YEAR = {2022},
NUMBER = {1},
ARTICLE-NUMBER = {72},
URL = {https://www.mdpi.com/2072-666X/13/1/72},
ISSN = {2072-666X},
ABSTRACT = {Video object and human action detection are applied in many fields, such as video surveillance, face recognition, etc. Video object detection includes object classification and object location within the frame. Human action recognition is the detection of human actions. Usually, video detection is more challenging than image detection, since video frames are often more blurry than images. Moreover, video detection often has other difficulties, such as video defocus, motion blur, part occlusion, etc. Nowadays, the video detection technology is able to implement real-time detection, or high-accurate detection of blurry video frames. In this paper, various video object and human action detection approaches are reviewed and discussed, many of them have performed state-of-the-art results. We mainly review and discuss the classic video detection methods with supervised learning. In addition, the frequently-used video object detection and human action recognition datasets are reviewed. Finally, a summarization of the video detection is represented, e.g., the video object and human action detection methods could be classified into frame-by-frame (frame-based) detection, extracting-key-frame detection and using-temporal-information detection; the methods of utilizing temporal information of adjacent video frames are mainly the optical flow method, Long Short-Term Memory and convolution among adjacent frames.},
DOI = {10.3390/mi13010072}
}



@Article{rs14010199,
AUTHOR = {Carbonell-Rivera, Juan Pedro and Torralba, Jesús and Estornell, Javier and Ruiz, Luis Ángel and Crespo-Peremarch, Pablo},
TITLE = {Classification of Mediterranean Shrub Species from UAV Point Clouds},
JOURNAL = {Remote Sensing},
VOLUME = {14},
YEAR = {2022},
NUMBER = {1},
ARTICLE-NUMBER = {199},
URL = {https://www.mdpi.com/2072-4292/14/1/199},
ISSN = {2072-4292},
ABSTRACT = {Modelling fire behaviour in forest fires is based on meteorological, topographical, and vegetation data, including species&rsquo; type. To accurately parameterise these models, an inventory of the area of analysis with the maximum spatial and temporal resolution is required. This study investigated the use of UAV-based digital aerial photogrammetry (UAV-DAP) point clouds to classify tree and shrub species in Mediterranean forests, and this information is key for the correct generation of wildfire models. In July 2020, two test sites located in the Natural Park of Sierra Calderona (eastern Spain) were analysed, registering 1036 vegetation individuals as reference data, corresponding to 11 shrub and one tree species. Meanwhile, photogrammetric flights were carried out over the test sites, using a UAV DJI Inspire 2 equipped with a Micasense RedEdge multispectral camera. Geometrical, spectral, and neighbour-based features were obtained from the resulting point cloud generated. Using these features, points belonging to tree and shrub species were classified using several machine learning methods, i.e., Decision Trees, Extra Trees, Gradient Boosting, Random Forest, and MultiLayer Perceptron. The best results were obtained using Gradient Boosting, with a mean cross-validation accuracy of 81.7% and 91.5% for test sites 1 and 2, respectively. Once the best classifier was selected, classified points were clustered based on their geometry and tested with evaluation data, and overall accuracies of 81.9% and 96.4% were obtained for test sites 1 and 2, respectively. Results showed that the use of UAV-DAP allows the classification of Mediterranean tree and shrub species. This technique opens a wide range of possibilities, including the identification of species as a first step for further extraction of structure and fuel variables as input for wildfire behaviour models.},
DOI = {10.3390/rs14010199}
}



@Article{rs14010201,
AUTHOR = {Lin, Qigen and Ci, Tianyu and Wang, Leibin and Mondal, Sanjit Kumar and Yin, Huaxiang and Wang, Ying},
TITLE = {Transfer Learning for Improving Seismic Building Damage Assessment},
JOURNAL = {Remote Sensing},
VOLUME = {14},
YEAR = {2022},
NUMBER = {1},
ARTICLE-NUMBER = {201},
URL = {https://www.mdpi.com/2072-4292/14/1/201},
ISSN = {2072-4292},
ABSTRACT = {The rapid assessment of building damage in earthquake-stricken areas is of paramount importance for emergency response. The development of remote sensing technology has aided in deriving reliable and precise building damage assessments of extensive areas following disasters. It is well documented that convolutional neural network methods have superior performance in earthquake building damage assessment compared with traditional machine learning methods. However, deep learning models require a large number of samples, and sufficient numbers of samples are usually not available in the newly earthquake-stricken areas rapidly enough. At the same time, the historical samples inevitably differ from the new earthquake-affected areas due to the discrepancy of regional building characteristics. For this purpose, this study proposes a data transfer algorithm for evaluating the impact of a single historical training sample on the model performance. Then, beneficial samples are selected to transfer knowledge from the historical data for facilitating the calibration of the new model. Four models are designed with two earthquake damage building datasets and the performance of the models is compared and evaluated. The results show that the data transfer algorithm proposed in this work improves the reliability of the building damage assessment model significantly by filtering samples from the historical data that are suitable for the new task. The performance of the model built based on the data transfer method on the test set of new earthquakes task is approximately 8% higher in overall accuracy compared with the model trained directly with the new earthquake samples when the training data for the new task is only 10% of the historical data and is operating under the objective of four classes of building damage. The proposed data transfer algorithm has effectively enhanced the precision of the seismic building damage assessment in a data-limited context. Thus, it could be applicable to the building damage assessment of new disasters.},
DOI = {10.3390/rs14010201}
}



@Article{f13010048,
AUTHOR = {Kamarulzaman, Aisyah Marliza Muhmad and Wan Mohd Jaafar, Wan Shafrina and Abdul Maulud, Khairul Nizam and Saad, Siti Nor Maizah and Omar, Hamdan and Mohan, Midhun},
TITLE = {Integrated Segmentation Approach with Machine Learning Classifier in Detecting and Mapping Post Selective Logging Impacts Using UAV Imagery},
JOURNAL = {Forests},
VOLUME = {13},
YEAR = {2022},
NUMBER = {1},
ARTICLE-NUMBER = {48},
URL = {https://www.mdpi.com/1999-4907/13/1/48},
ISSN = {1999-4907},
ABSTRACT = {Selective logging can cause significant impacts on the residual stands, affecting biodiversity and leading to environmental changes. Proper monitoring and mapping of the impacts from logging activities, such as the stumps, felled logs, roads, skid trails, and forest canopy gaps, are crucial for sustainable forest management operations. The purpose of this study is to assess the indicators of selective logging impacts by detecting the individual stumps as the main indicators, evaluating the performance of classification methods to assess the impacts and identifying forest gaps from selective logging activities. The combination of forest inventory field plots and unmanned aerial vehicle (UAV) RGB and overlapped imaged were used in this study to assess these impacts. The study area is located in Ulu Jelai Forest Reserve in the central part of Peninsular Malaysia, covering an experimental study area of 48 ha. The study involved the integration of template matching (TM), object-based image analysis (OBIA), and machine learning classification&mdash;support vector machine (SVM) and artificial neural network (ANN). Forest features and tree stumps were classified, and the canopy height model was used for detecting forest canopy gaps in the post selective logging region. Stump detection using the integration of TM and OBIA produced an accuracy of 75.8% when compared with the ground data. Forest classification using SVM and ANN methods were adopted to extract other impacts from logging activities such as skid trails, felled logs, roads and forest canopy gaps. These methods provided an overall accuracy of 85% and kappa coefficient value of 0.74 when compared with conventional classifier. The logging operation also caused an 18.6% loss of canopy cover. The result derived from this study highlights the potential use of UAVs for efficient post logging impact analysis and can be used to complement conventional forest inventory practices.},
DOI = {10.3390/f13010048}
}



@Article{agronomy12010118,
AUTHOR = {Monteiro, António and Santos, Sérgio},
TITLE = {Sustainable Approach to Weed Management: The Role of Precision Weed Management},
JOURNAL = {Agronomy},
VOLUME = {12},
YEAR = {2022},
NUMBER = {1},
ARTICLE-NUMBER = {118},
URL = {https://www.mdpi.com/2073-4395/12/1/118},
ISSN = {2073-4395},
ABSTRACT = {In the last few decades, the increase in the world&rsquo;s population has created a need to produce more food, generating, consequently, greater pressure on agricultural production. In addition, problems related to climate change, water scarcity or decreasing amounts of arable land have serious implications for farming sustainability. Weeds can affect food production in agricultural systems, decreasing the product quality and productivity due to the competition for natural resources. On the other hand, weeds can also be considered to be valuable indicators of biodiversity because of their role in providing ecosystem services. In this sense, there is a need to carry out an effective and sustainable weed management process, integrating the various control methods (i.e., cultural, mechanical and chemical) in a harmonious way, without harming the entire agrarian ecosystem. Thus, intensive mechanization and herbicide use should be avoided. Herbicide resistance in some weed biotypes is a major concern today and must be tackled. On the other hand, the recent development of weed control technologies can promote higher levels of food production, lower the amount of inputs needed and reduce environmental damage, invariably bringing us closer to more sustainable agricultural systems. In this paper, we review the most common conventional and non-conventional weed control strategies from a sustainability perspective, highlighting the application of the precision and automated weed control technologies associated with precision weed management (PWM).},
DOI = {10.3390/agronomy12010118}
}



@Article{electronics11010148,
AUTHOR = {Sharma, Mayuri and Nath, Keshab and Sharma, Rupam Kumar and Kumar, Chandan Jyoti and Chaudhary, Ankit},
TITLE = {Ensemble Averaging of Transfer Learning Models for Identification of Nutritional Deficiency in Rice Plant},
JOURNAL = {Electronics},
VOLUME = {11},
YEAR = {2022},
NUMBER = {1},
ARTICLE-NUMBER = {148},
URL = {https://www.mdpi.com/2079-9292/11/1/148},
ISSN = {2079-9292},
ABSTRACT = {Computer vision-based automation has become popular in detecting and monitoring plants&rsquo; nutrient deficiencies in recent times. The predictive model developed by various researchers were so designed that it can be used in an embedded system, keeping in mind the availability of computational resources. Nevertheless, the enormous popularity of smart phone technology has opened the door of opportunity to common farmers to have access to high computing resources. To facilitate smart phone users, this study proposes a framework of hosting high end systems in the cloud where processing can be done, and farmers can interact with the cloud-based system. With the availability of high computational power, many studies have been focused on applying convolutional Neural Networks-based Deep Learning (CNN-based DL) architectures, including Transfer learning (TL) models on agricultural research. Ensembling of various TL architectures has the potential to improve the performance of predictive models by a great extent. In this work, six TL architectures viz. InceptionV3, ResNet152V2, Xception, DenseNet201, InceptionResNetV2, and VGG19 are considered, and their various ensemble models are used to carry out the task of deficiency diagnosis in rice plants. Two publicly available datasets from Mendeley and Kaggle are used in this study. The ensemble-based architecture enhanced the highest classification accuracy to 100% from 99.17% in the Mendeley dataset, while for the Kaggle dataset; it was enhanced to 92% from 90%.},
DOI = {10.3390/electronics11010148}
}



@Article{app12010458,
AUTHOR = {Amaral, Julyanne Braga Cruz and Lopes, Fernando Bezerra and Magalhães, Ana Caroline Messias de and Kujawa, Sebastian and Taniguchi, Carlos Alberto Kenji and Teixeira, Adunias dos Santos and Lacerda, Claudivan Feitosa de and Queiroz, Thales Rafael Guimarães and Andrade, Eunice Maia de and Araújo, Isabel Cristina da Silva and Niedbała, Gniewko},
TITLE = {Quantifying Nutrient Content in the Leaves of Cowpea Using Remote Sensing},
JOURNAL = {Applied Sciences},
VOLUME = {12},
YEAR = {2022},
NUMBER = {1},
ARTICLE-NUMBER = {458},
URL = {https://www.mdpi.com/2076-3417/12/1/458},
ISSN = {2076-3417},
ABSTRACT = {Although hyperspectral remote sensing techniques have increasingly been used in the nutritional quantification of plants, it is important to understand whether the method shows a satisfactory response during the various phenological stages of the crop. The aim of this study was to quantify the levels of phosphorus (P), potassium (K), calcium (Ca) and zinc (Zn) in the leaves of Vigna Unguiculata (L.) Walp using spectral data obtained by a spectroradiometer. A randomised block design was used, with three treatments and twenty-five replications. The crop was evaluated at three growth stages: V4, R6 and R9. Single-band models were fitted using simple correlations. For the band ratio models, the wavelengths were selected by 2D correlation. For the models using partial least squares regression (PLSR), the stepwise method was used. The model showing the best fit was used to estimate the phosphorus content in the single-band (R&sup2; = 0.62; RMSE = 0.54 and RPD = 1.61), band ratio (R&sup2; = 0.66; RMSE = 0.65 and RPD = 1.52) and PLSR models, using data from each of the phenological stages (R&sup2; = 0.80; RMSE = 0.47 and RPD = 1.66). Accuracy in modelling leaf nutrients depends on the phenological stage, as well as the amount of data used, and is more accurate with a larger number of samples.},
DOI = {10.3390/app12010458}
}



@Article{rs14010219,
AUTHOR = {James, Dorothée and Collin, Antoine and Mury, Antoine and Qin, Rongjun},
TITLE = {Satellite&ndash;Derived Topography and Morphometry for VHR Coastal Habitat Mapping: The Pleiades&ndash;1 Tri&ndash;Stereo Enhancement},
JOURNAL = {Remote Sensing},
VOLUME = {14},
YEAR = {2022},
NUMBER = {1},
ARTICLE-NUMBER = {219},
URL = {https://www.mdpi.com/2072-4292/14/1/219},
ISSN = {2072-4292},
ABSTRACT = {The evolution of the coastal fringe is closely linked to the impact of climate change, specifically increases in sea level and storm intensity. The anthropic pressure that is inflicted on these fragile environments strengthens the risk. Therefore, numerous research projects look into the possibility of monitoring and understanding the coastal environment in order to better identify its dynamics and adaptation to the major changes that are currently taking place in the landscape. This new study aims to improve the habitat mapping/classification at Very High Resolution (VHR) using Pleiades&ndash;1&ndash;derived topography, its morphometric by&ndash;products, and Pleiades&ndash;1&ndash;derived imageries. A tri&ndash;stereo dataset was acquired and processed by image pairing to obtain nine digital surface models (DSM) that were 0.50 m pixel size using the free software RSP (RPC Stereo Processor) and that were calibrated and validated with the 2018&ndash;LiDAR dataset that was available for the study area: the Emerald Coast in Brittany (France). Four morphometric predictors that were derived from the best of the nine generated DSMs were calculated via a freely available software (SAGA GIS): slope, aspect, topographic position index (TPI), and TPI&ndash;based landform classification (TPILC). A maximum likelihood classification of the area was calculated using nine classes: the salt marsh, dune, rock, urban, field, forest, beach, road, and seawater classes. With an RMSE of 4 m, the DSM#2&ndash;3_1 (from images #2 and #3 with one ground control point) outperformed the other DSMs. The classification results that were computed from the DSM#2&ndash;3_1 demonstrate the importance of the contribution of the morphometric predictors that were added to the reference Red&ndash;Green&ndash;Blue (RGB, 76.37% in overall accuracy, OA). The best combination of TPILC that was added to the RGB + DSM provided a gain of 13% in the OA, reaching 89.37%. These findings will help scientists and managers who are tasked with coastal risks at VHR.},
DOI = {10.3390/rs14010219}
}



@Article{math10010151,
AUTHOR = {Díaz-González, Vicente and Rojas-Palma, Alejandro and Carrasco-Benavides, Marcos},
TITLE = {How Does Irrigation Affect Crop Growth? A Mathematical Modeling Approach},
JOURNAL = {Mathematics},
VOLUME = {10},
YEAR = {2022},
NUMBER = {1},
ARTICLE-NUMBER = {151},
URL = {https://www.mdpi.com/2227-7390/10/1/151},
ISSN = {2227-7390},
ABSTRACT = {This article presents a qualitative mathematical model to simulate the relationship between supplied water and plant growth. A novel aspect of the construction of this phenomenological model is the consideration of a structure of three phases: (1) The soil water availability, (2) the available water inside the plant for its growth, and (3) the plant size or amount of dry matter. From these phases and their interactions, a model based on a three-dimensional nonlinear dynamic system was proposed. The results obtained showed the existence of a single equilibrium point, global and exponentially stable. Additionally, considering the framework of the perturbation theory, this model was perturbed by incorporating irrigation to the available soil water, obtaining some stability results under different assumptions. Later through the control theory, it was demonstrated that the proposed system was controllable. Finally, a numerical simulation of the proposed model was carried out, to depict the soil water content and plant growth dynamic and its agreement with the results of the mathematical analysis. In addition, a specific calibration for field data from an experiment with wheat was considered, and these parameters were then used to test the proposed model, obtaining an error of about 6% in the soil water content estimation.},
DOI = {10.3390/math10010151}
}



@Article{agriculture12010062,
AUTHOR = {Sun, Zhu and Guo, Xiangyu and Xu, Yang and Zhang, Songchao and Cheng, Xiaohui and Hu, Qiong and Wang, Wenxiang and Xue, Xinyu},
TITLE = {Image Recognition of Male Oilseed Rape (Brassica napus) Plants Based on Convolutional Neural Network for UAAS Navigation Applications on Supplementary Pollination and Aerial Spraying},
JOURNAL = {Agriculture},
VOLUME = {12},
YEAR = {2022},
NUMBER = {1},
ARTICLE-NUMBER = {62},
URL = {https://www.mdpi.com/2077-0472/12/1/62},
ISSN = {2077-0472},
ABSTRACT = {To ensure the hybrid oilseed rape (OSR, Brassica napus) seed production, two important things are necessary, the stamen sterility on the female OSR plants and the effective pollen spread onto the pistil from the OSR male plants to the OSR female plants. The unmanned agricultural aerial system (UAAS) has developed rapidly in China. It has been used on supplementary pollination and aerial spraying during the hybrid OSR seed production. This study developed a new method to rapidly recognize the male OSR plants and extract the row center line for supporting the UAAS navigation. A male OSR plant recognition model was constructed based on the convolutional neural network (CNN). The sequence images of male OSR plants were extracted, the feature regions and points were obtained from the images through morphological and boundary process methods and horizontal segmentation, respectively. The male OSR plant image recognition accuracies of different CNN structures and segmentation sizes were discussed. The male OSR plant row center lines were fitted using the least-squares method (LSM) and Hough transform. The results showed that the segmentation algorithm could segment the male OSR plants from the complex background. The highest average recognition accuracy was 93.54%, and the minimum loss function value was 0.2059 with three convolutional layers, one fully connected layer, and a segmentation size of 40 pix &times; 40 pix. The LSM is better for center line fitting. The average recognition model accuracies of original input images were 98% and 94%, and the average root mean square errors (RMSE) of angle were 3.22&deg; and 1.36&deg; under cloudy day and sunny day lighting conditions, respectively. The results demonstrate the potential of using digital imaging technology to recognize the male OSR plant row for UAAS visual navigation on the applications of hybrid OSR supplementary pollination and aerial spraying, which would be a meaningful supplement in precision agriculture.},
DOI = {10.3390/agriculture12010062}
}



@Article{agronomy12010127,
AUTHOR = {Rehman, Amjad and Saba, Tanzila and Kashif, Muhammad and Fati, Suliman Mohamed and Bahaj, Saeed Ali and Chaudhry, Huma},
TITLE = {A Revisit of Internet of Things Technologies for Monitoring and Control Strategies in Smart Agriculture},
JOURNAL = {Agronomy},
VOLUME = {12},
YEAR = {2022},
NUMBER = {1},
ARTICLE-NUMBER = {127},
URL = {https://www.mdpi.com/2073-4395/12/1/127},
ISSN = {2073-4395},
ABSTRACT = {With the rise of new technologies, such as the Internet of Things, raising the productivity of agricultural and farming activities is critical to improving yields and cost-effectiveness. IoT, in particular, can improve the efficiency of agriculture and farming processes by eliminating human intervention through automation. The fast rise of Internet of Things (IoT)-based tools has changed nearly all life sectors, including business, agriculture, surveillance, etc. These radical developments are upending traditional agricultural practices and presenting new options in the face of various obstacles. IoT aids in collecting data that is useful in the farming sector, such as changes in climatic conditions, soil fertility, amount of water required for crops, irrigation, insect and pest detection, bug location disruption of creatures to the sphere, and horticulture. IoT enables farmers to effectively use technology to monitor their forms remotely round the clock. Several sensors, including distributed WSNs (wireless sensor networks), are utilized for agricultural inspection and control, which is very important due to their exact output and utilization. In addition, cameras are utilized to keep an eye on the field from afar. The goal of this research is to evaluate smart agriculture using IoT approaches in depth. The paper demonstrates IoT applications, benefits, current obstacles, and potential solutions in smart agriculture. This smart agricultural system aims to find existing techniques that may be used to boost crop yield and save time, such as water, pesticides, irrigation, crop, and fertilizer management.},
DOI = {10.3390/agronomy12010127}
}



@Article{rs14010228,
AUTHOR = {Khan, Asim and Asim, Warda and Ulhaq, Anwaar and Robinson, Randall W.},
TITLE = {A Multiview Semantic Vegetation Index for Robust Estimation of Urban Vegetation Cover},
JOURNAL = {Remote Sensing},
VOLUME = {14},
YEAR = {2022},
NUMBER = {1},
ARTICLE-NUMBER = {228},
URL = {https://www.mdpi.com/2072-4292/14/1/228},
ISSN = {2072-4292},
ABSTRACT = {Urban vegetation growth is vital for developing sustainable and liveable cities in the contemporary era since it directly helps people&rsquo;s health and well-being. Estimating vegetation cover and biomass is commonly done by calculating various vegetation indices for automated urban vegetation management and monitoring. However, most of these indices fail to capture robust estimation of vegetation cover due to their inherent focus on colour attributes with limited viewpoint and ignore seasonal changes. To solve this limitation, this article proposed a novel vegetation index called the Multiview Semantic Vegetation Index (MSVI), which is robust to color, viewpoint, and seasonal variations. Moreover, it can be applied directly to RGB images. This Multiview Semantic Vegetation Index (MSVI) is based on deep semantic segmentation and multiview field coverage and can be integrated into any vegetation management platform. This index has been tested on Google Street View (GSV) imagery of Wyndham City Council, Melbourne, Australia. The experiments and training achieved an overall pixel accuracy of 89.4% and 92.4% for FCN and U-Net, respectively. Thus, the MSVI can be a helpful instrument for analysing urban forestry and vegetation biomass since it provides an accurate and reliable objective method for assessing the plant cover at street level.},
DOI = {10.3390/rs14010228}
}



@Article{s22010394,
AUTHOR = {Narayana, Mannam Veera and Jalihal, Devendra and Nagendra, S. M. Shiva},
TITLE = {Establishing A Sustainable Low-Cost Air Quality Monitoring Setup: A Survey of the State-of-the-Art},
JOURNAL = {Sensors},
VOLUME = {22},
YEAR = {2022},
NUMBER = {1},
ARTICLE-NUMBER = {394},
URL = {https://www.mdpi.com/1424-8220/22/1/394},
PubMedID = {35009933},
ISSN = {1424-8220},
ABSTRACT = {Low-cost sensors (LCS) are becoming popular for air quality monitoring (AQM). They promise high spatial and temporal resolutions at low-cost. In addition, citizen science applications such as personal exposure monitoring can be implemented effortlessly. However, the reliability of the data is questionable due to various error sources involved in the LCS measurement. Furthermore, sensor performance drift over time is another issue. Hence, the adoption of LCS by regulatory agencies is still evolving. Several studies have been conducted to improve the performance of low-cost sensors. This article summarizes the existing studies on the state-of-the-art of LCS for AQM. We conceptualize a step by step procedure to establish a sustainable AQM setup with LCS that can produce reliable data. The selection of sensors, calibration and evaluation, hardware setup, evaluation metrics and inferences, and end user-specific applications are various stages in the LCS-based AQM setup we propose. We present a critical analysis at every step of the AQM setup to obtain reliable data from the low-cost measurement. Finally, we conclude this study with future scope to improve the availability of air quality data.},
DOI = {10.3390/s22010394}
}



@Article{math10010164,
AUTHOR = {Li, Yan and Zhao, Mengyu and Zhang, Huazhi and Qu, Yuanyuan and Wang, Suyu},
TITLE = {A Multi-Agent Motion Prediction and Tracking Method Based on Non-Cooperative Equilibrium},
JOURNAL = {Mathematics},
VOLUME = {10},
YEAR = {2022},
NUMBER = {1},
ARTICLE-NUMBER = {164},
URL = {https://www.mdpi.com/2227-7390/10/1/164},
ISSN = {2227-7390},
ABSTRACT = {A Multi-Agent Motion Prediction and Tracking method based on non-cooperative equilibrium (MPT-NCE) is proposed according to the fact that some multi-agent intelligent evolution methods, like the MADDPG, lack adaptability facing unfamiliar environments, and are unable to achieve multi-agent motion prediction and tracking, although they own advantages in multi-agent intelligence. Featured by a performance discrimination module using the time difference function together with a random mutation module applying predictive learning, the MPT-NCE is capable of improving the prediction and tracking ability of the agents in the intelligent game confrontation. Two groups of multi-agent prediction and tracking experiments are conducted and the results show that compared with the MADDPG method, in the aspect of prediction ability, the MPT-NCE achieves a prediction rate at more than 90%, which is 23.52% higher and increases the whole evolution efficiency by 16.89%; in the aspect of tracking ability, the MPT-NCE promotes the convergent speed by 11.76% while facilitating the target tracking by 25.85%. The proposed MPT-NCE method shows impressive environmental adaptability and prediction and tracking ability.},
DOI = {10.3390/math10010164}
}



@Article{w14010128,
AUTHOR = {Cui, Mengying and Sun, Yonghua and Huang, Chen and Li, Mengjun},
TITLE = {Water Turbidity Retrieval Based on UAV Hyperspectral Remote Sensing},
JOURNAL = {Water},
VOLUME = {14},
YEAR = {2022},
NUMBER = {1},
ARTICLE-NUMBER = {128},
URL = {https://www.mdpi.com/2073-4441/14/1/128},
ISSN = {2073-4441},
ABSTRACT = {The water components affecting turbidity are complex and changeable, and the spectral response mechanism of each water quality parameter is different. Therefore, this study mainly aimed at the turbidity monitoring by unmanned aerial vehicle (UAV) hyperspectral technology, and establishes a set of turbidity retrieval models through the artificial control experiment, and verifies the model&rsquo;s accuracy through UAV flight and water sample data in the same period. The results of this experiment can also be extended to different inland waters for turbidity retrieval. Retrieval of turbidity values of small inland water bodies can provide support for the study of the degree of water pollution. We collected the images and data of aquaculture ponds and irrigation ditches in Dawa District, Panjin City, Liaoning Province. Twenty-nine standard turbidity solutions with different concentration gradients (concentration from 0 to 360 NTU&mdash;the abbreviation of Nephelometric Turbidity Unit, which stands for scattered turbidity.) were established through manual control and we simultaneously collected hyperspectral data from the spectral values of standard solutions. The sensitive band to turbidity was obtained after analyzing the spectral information. We established four kinds of retrieval, including the single band, band ratio, normalized ratio, and the partial least squares (PLS) models. We selected the two models with the highest R2 for accuracy verification. The band ratio model and PLS model had the highest accuracy, and R2 was, respectively, 0.65 and 0.72. The hyperspectral image data obtained by UAV were combined with the PLS model, which had the highest R2 to estimate the spatial distribution of water turbidity. The turbidity of the water areas in the study area was 5&ndash;300 NTU, and most of which are 5&ndash;80 NTU. It shows that the PLS models can retrieve the turbidity with high accuracy of aquaculture ponds, irrigation canals, and reservoirs in Dawa District of Panjin City, Liaoning Province. The experimental results are consistent with the conclusions of the field investigation.},
DOI = {10.3390/w14010128}
}



@Article{rs14010235,
AUTHOR = {Tijerín-Triviño, Julián and Moreno-Fernández, Daniel and Zavala, Miguel A. and Astigarraga, Julen and García, Mariano},
TITLE = {Identifying Forest Structural Types along an Aridity Gradient in Peninsular Spain: Integrating Low-Density LiDAR, Forest Inventory, and Aridity Index},
JOURNAL = {Remote Sensing},
VOLUME = {14},
YEAR = {2022},
NUMBER = {1},
ARTICLE-NUMBER = {235},
URL = {https://www.mdpi.com/2072-4292/14/1/235},
ISSN = {2072-4292},
ABSTRACT = {Forest structure is a key driver of forest functional processes. The characterization of forest structure across spatiotemporal scales is essential for forest monitoring and management. LiDAR data have proven particularly useful for cost-effectively estimating forest structural attributes. This paper evaluates the ability of combined forest inventory data and low-density discrete return airborne LiDAR data to discriminate main forest structural types in the Mediterranean-temperate transition ecotone. Firstly, we used six structural variables from the Spanish National Forest Inventory (SNFI) and an aridity index in a k-medoids algorithm to define the forest structural types. These variables were calculated for 2770 SNFI plots. We identified the main species for each structural type using the SNFI. Secondly, we developed a Random Forest model to predict the spatial distribution of structural types and create wall-to-wall maps from LiDAR data. The k-medoids clustering algorithm enabled the identification of four clusters of forest structures. A total of six out of forty-one potential LiDAR metrics were utilized in our Random Forest, after evaluating their importance in the Random Forest model. Selected metrics were, in decreasing order of importance, the percentage of all returns above 2 m, mean height of the canopy profile, the difference between the 90th and 50th height percentiles, the area under the canopy curve, and the 5th and the 95th percentile of the return heights. The model yielded an overall accuracy of 64.18%. The producer&rsquo;s accuracy ranged between 36.11% and 88.93%. Our results confirm the potential of this approximation for the continuous monitoring of forest structures, which is key to guiding forest management in this region.},
DOI = {10.3390/rs14010235}
}



@Article{rs14020242,
AUTHOR = {Pang, Haiyang and Zhang, Aiwu and Yin, Shengnan and Zhang, Jiaxin and Dong, Gang and He, Nianpeng and Qin, Wenxuan and Wei, Dandan},
TITLE = {Estimating Carbon, Nitrogen, and Phosphorus Contents of West&ndash;East Grassland Transect in Inner Mongolia Based on Sentinel-2 and Meteorological Data},
JOURNAL = {Remote Sensing},
VOLUME = {14},
YEAR = {2022},
NUMBER = {2},
ARTICLE-NUMBER = {242},
URL = {https://www.mdpi.com/2072-4292/14/2/242},
ISSN = {2072-4292},
ABSTRACT = {Estimating the carbon (C), nitrogen (N), and phosphorus (P) contents of a large-span grassland transect is essential for evaluating ecosystem functioning and monitoring biogeochemical cycles. However, the field measurements are scattered, such that they cannot indicate the continuous gradient change in the grassland transect. Although remote sensing methods have been applied for the estimation of nutrient elements at the local scale in recent years, few studies have considered the effective estimation of C, N, and P contents over large-span grassland transects with complex environment including a variety of grassland types (i.e., meadow, typical grassland, and desert grassland). In this paper, an information enhancement algorithm (involving spectral enhancement, regional enhancement, and feature enhancement) is used to extract the weak information related to C, N, and P. First, the spectral simulation algorithm is used to enhance the spectral information of Sentinel-2 imagery. Then, the enhanced spectra and meteorological data are fused to express regional characteristics and the fractional differential (FD) algorithm is used to extract sensitive spectral features related to C, N, and P, in order to construct a partial least-squares regression (PLSR) model. Finally, the C, N, and P contents are estimated over a West&ndash;East grassland transect in Inner Mongolia, China. The results demonstrate that: (i) the contents of C, N, and P in large-span transects can be effectively estimated through use of the information enhancement method involving spectral enhancement, regional feature enhancement, and information enhancement, for which the estimation accuracies (R2) were 0.88, 0.78, and 0.85, respectively. Compared with the estimation results of raw Sentinel-2 imagery, the RMSE was reduced by 3.42 g/m2, 0.14 g/m2, and 13.73 mg/m2, respectively; and (ii) the continuous change trend and spatial distribution characteristics of C, N, and P contents in the west&ndash;east transect of the Inner Mongolia Plateau were obtained, which showed decreasing trends in C, N, and P contents from east to west and the characteristics of meadow &gt; typical grassland &gt; desert grassland. Thus, the information enhancement algorithm can help to improve estimates of C, N, and P contents when considering large-span grassland transects.},
DOI = {10.3390/rs14020242}
}



@Article{rs14020244,
AUTHOR = {Guo, Yahui and Chen, Shouzhi and Fu, Yongshuo H. and Xiao, Yi and Wu, Wenxiang and Wang, Hanxi and Beurs, Kirsten de},
TITLE = {Comparison of Multi-Methods for Identifying Maize Phenology Using PhenoCams},
JOURNAL = {Remote Sensing},
VOLUME = {14},
YEAR = {2022},
NUMBER = {2},
ARTICLE-NUMBER = {244},
URL = {https://www.mdpi.com/2072-4292/14/2/244},
ISSN = {2072-4292},
ABSTRACT = {Accurately identifying the phenology of summer maize is crucial for both cultivar breeding and fertilizer controlling in precision agriculture. In this study, daily RGB images covering the entire growth of summer maize were collected using phenocams at sites in Shangqiu (2018, 2019 and 2020) and Nanpi (2020) in China. Four phenological dates, including six leaves, booting, heading and maturity of summer maize, were pre-defined and extracted from the phenocam-based images. The spectral indices, textural indices and integrated spectral and textural indices were calculated using the improved adaptive feature-weighting method. The double logistic function, harmonic analysis of time series, Savitzky&ndash;Golay and spline interpolation were applied to filter these indices and pre-defined phenology was identified and compared with the ground observations. The results show that the DLF achieved the highest accuracy, with the coefficient of determination (R2) and the root-mean-square error (RMSE) being 0.86 and 9.32 days, respectively. The new index performed better than the single usage of spectral and textural indices, of which the R2 and RMSE were 0.92 and 9.38 days, respectively. The phenological extraction using the new index and double logistic function based on the PhenoCam data was effective and convenient, obtaining high accuracy. Therefore, it is recommended the adoption of the new index by integrating the spectral and textural indices for extracting maize phenology using PhenoCam data.},
DOI = {10.3390/rs14020244}
}



@Article{app12020545,
AUTHOR = {Liu, Yicheng and Li, Zhipeng and Zhan, Bixiong and Han, Ju and Liu, Yan},
TITLE = {A Super-Resolution Reconstruction Driven Helmet Detection Workflow},
JOURNAL = {Applied Sciences},
VOLUME = {12},
YEAR = {2022},
NUMBER = {2},
ARTICLE-NUMBER = {545},
URL = {https://www.mdpi.com/2076-3417/12/2/545},
ISSN = {2076-3417},
ABSTRACT = {The degrading of input images due to the engineering environment decreases the performance of helmet detection models so as to prevent their application in practice. To overcome this problem, we propose an end-to-end helmet monitoring system, which implements a super-resolution (SR) reconstruction driven helmet detection workflow to detect helmets for monitoring tasks. The monitoring system consists of two modules, the super-resolution reconstruction module and the detection module. The former implements the SR algorithm to produce high-resolution images, the latter performs the helmet detection. Validations are performed on both a public dataset as well as the realistic dataset obtained from a practical construction site. The results show that the proposed system achieves a promising performance and surpasses the competing methods. It will be a promising tool for construction monitoring and is easy to be extended to corresponding tasks.},
DOI = {10.3390/app12020545}
}



@Article{agriculture12010074,
AUTHOR = {Huang, Linsheng and Liu, Yong and Huang, Wenjiang and Dong, Yingying and Ma, Huiqin and Wu, Kang and Guo, Anting},
TITLE = {Combining Random Forest and XGBoost Methods in Detecting Early and Mid-Term Winter Wheat Stripe Rust Using Canopy Level Hyperspectral Measurements},
JOURNAL = {Agriculture},
VOLUME = {12},
YEAR = {2022},
NUMBER = {1},
ARTICLE-NUMBER = {74},
URL = {https://www.mdpi.com/2077-0472/12/1/74},
ISSN = {2077-0472},
ABSTRACT = {Appropriate modeling methods and feature selection algorithms must be selected to improve the accuracy of early and mid-term remote sensing detection of wheat stripe rust. In the current study, we explored the effectiveness of the random forest (RF) algorithm combined with the extreme gradient boosting (XGboost) method for early and mid-term wheat stripe rust detection based on the vegetation indices extracted from canopy level hyperspectral measurements. Initially, 21 vegetation indices that were related to the early and mid-term winter wheat stripe rust were calculated on the basis of canopy level hyperspectral reflectance. Subsequently, the optimal vegetation index combination for disease detection was determined using correlation analysis (CA) combined with RF algorithms. Then, the disease severity detection model of early and mid-term winter wheat stripe rust was constructed using XGBoost method based on the optimal vegetation index combination. For the evaluation and comparison of the initial results, three commonly used classification methods, namely, RF, backpropagation neural network (BPNN), and support vector machine (SVM), were utilized. The vegetation index combinations determined by the single CA algorithm were also used to construct detection models. Compared with the detection models based on the vegetation index combination obtained using the single CA algorithm, the overall accuracy of the four detection models based on the optimal vegetation index combination based on CA combined with RF algorithms increased by 16.1% (XGBoost), 9.7% (RF), 8.1% (SVM), and 8.1% (BPNN). Among the eight models, the XGBoost detection model based on the optimal vegetation index combination using CA combined with RF algorithms, CA-RF-XGBoost, achieved the highest overall accuracy of 87.1% and the highest kappa coefficient of 0.798. Our results indicate that the RF combined with XGBoost can improve the detection accuracy of early and mid-term winter wheat stripe rust effectively at canopy scale.},
DOI = {10.3390/agriculture12010074}
}



@Article{rs14020255,
AUTHOR = {Gao, Xin and Ram, Sundaresh and Philip, Rohit C. and Rodríguez, Jeffrey J. and Szep, Jeno and Shao, Sicong and Satam, Pratik and Pacheco, Jesús and Hariri, Salim},
TITLE = {Selecting Post-Processing Schemes for Accurate Detection of Small Objects in Low-Resolution Wide-Area Aerial Imagery},
JOURNAL = {Remote Sensing},
VOLUME = {14},
YEAR = {2022},
NUMBER = {2},
ARTICLE-NUMBER = {255},
URL = {https://www.mdpi.com/2072-4292/14/2/255},
ISSN = {2072-4292},
ABSTRACT = {In low-resolution wide-area aerial imagery, object detection algorithms are categorized as feature extraction and machine learning approaches, where the former often requires a post-processing scheme to reduce false detections and the latter demands multi-stage learning followed by post-processing. In this paper, we present an approach on how to select post-processing schemes for aerial object detection. We evaluated combinations of each of ten vehicle detection algorithms with any of seven post-processing schemes, where the best three schemes for each algorithm were determined using average F-score metric. The performance improvement is quantified using basic information retrieval metrics as well as the classification of events, activities and relationships (CLEAR) metrics. We also implemented a two-stage learning algorithm using a hundred-layer densely connected convolutional neural network for small object detection and evaluated its degree of improvement when combined with the various post-processing schemes. The highest average F-scores after post-processing are 0.902, 0.704 and 0.891 for the Tucson, Phoenix and online VEDAI datasets, respectively. The combined results prove that our enhanced three-stage post-processing scheme achieves a mean average precision (mAP) of 63.9% for feature extraction methods and 82.8% for the machine learning approach.},
DOI = {10.3390/rs14020255}
}



@Article{ijerph19020629,
AUTHOR = {Wang, Yuting and Wang, Shujian and Xu, Ming},
TITLE = {Landscape Perception Identification and Classification Based on Electroencephalogram (EEG) Features},
JOURNAL = {International Journal of Environmental Research and Public Health},
VOLUME = {19},
YEAR = {2022},
NUMBER = {2},
ARTICLE-NUMBER = {629},
URL = {https://www.mdpi.com/1660-4601/19/2/629},
ISSN = {1660-4601},
ABSTRACT = {This paper puts forward a new method of landscape recognition and evaluation by using aerial video and EEG technology. In this study, seven typical landscape types (forest, wetland, grassland, desert, water, farmland, and city) were selected. Different electroencephalogram (EEG) signals were generated through different inner experiences and feelings felt by people watching video stimuli of the different landscape types. The electroencephalogram (EEG) features were extracted to obtain the mean amplitude spectrum (MAS), power spectrum density (PSD), differential entropy (DE), differential asymmetry (DASM), rational asymmetry (RASM), and differential caudality (DCAU) in the five frequency bands of delta, theta, alpha, beta, and gamma. According to electroencephalogram (EEG) features, four classifiers including the back propagation (BP) neural network, k-nearest neighbor classification (KNN), random forest (RF), and support vector machine (SVM) were used to classify the landscape types. The results showed that the support vector machine (SVM) classifier and the random forest (RF) classifier had the highest accuracy of landscape recognition, which reached 98.24% and 96.72%, respectively. Among the six classification features selected, the classification accuracy of MAS, PSD, and DE with frequency domain features were higher than those of the spatial domain features of DASM, RASM and DCAU. In different wave bands, the average classification accuracy of all subjects was 98.24% in the gamma band, 94.62% in the beta band, and 97.29% in the total band. This study identifies and classifies landscape perception based on multi-channel EEG signals, which provides a new idea and method for the quantification of human perception.},
DOI = {10.3390/ijerph19020629}
}



@Article{s22020418,
AUTHOR = {Al-Sa’d, Mohammad and Kiranyaz, Serkan and Ahmad, Iftikhar and Sundell, Christian and Vakkuri, Matti and Gabbouj, Moncef},
TITLE = {A Social Distance Estimation and Crowd Monitoring System for Surveillance Cameras},
JOURNAL = {Sensors},
VOLUME = {22},
YEAR = {2022},
NUMBER = {2},
ARTICLE-NUMBER = {418},
URL = {https://www.mdpi.com/1424-8220/22/2/418},
ISSN = {1424-8220},
ABSTRACT = {Social distancing is crucial to restrain the spread of diseases such as COVID-19, but complete adherence to safety guidelines is not guaranteed. Monitoring social distancing through mass surveillance is paramount to develop appropriate mitigation plans and exit strategies. Nevertheless, it is a labor-intensive task that is prone to human error and tainted with plausible breaches of privacy. This paper presents a privacy-preserving adaptive social distance estimation and crowd monitoring solution for camera surveillance systems. We develop a novel person localization strategy through pose estimation, build a privacy-preserving adaptive smoothing and tracking model to mitigate occlusions and noisy/missing measurements, compute inter-personal distances in the real-world coordinates, detect social distance infractions, and identify overcrowded regions in a scene. Performance evaluation is carried out by testing the system&rsquo;s ability in person detection, localization, density estimation, anomaly recognition, and high-risk areas identification. We compare the proposed system to the latest techniques and examine the performance gain delivered by the localization and smoothing/tracking algorithms. Experimental results indicate a considerable improvement, across different metrics, when utilizing the developed system. In addition, they show its potential and functionality for applications other than social distancing.},
DOI = {10.3390/s22020418}
}



@Article{ijerph19020648,
AUTHOR = {Yang, Miaomiao and Zhang, Keli and Huang, Chenlu and Yang, Qinke},
TITLE = {Effects of Content of Soil Rock Fragments on Soil Erodibility in China},
JOURNAL = {International Journal of Environmental Research and Public Health},
VOLUME = {19},
YEAR = {2022},
NUMBER = {2},
ARTICLE-NUMBER = {648},
URL = {https://www.mdpi.com/1660-4601/19/2/648},
ISSN = {1660-4601},
ABSTRACT = {Soil erosion is serious in China&mdash;the soil in plateau and mountain areas contain a large of rock fragments, and their content and distribution have an important influence on soil erosion. However, there are still no complete results for calculating soil erodibility factor (K) that have corrected rock fragments in China. In this paper, the data available on rock fragments in the soil profile (RFP); rock fragments on the surface of the soil (RFS); and environmental factors such as elevation, terrain relief, slope, vegetation coverage (characterised by normalised difference vegetation index, NDVI), land use, precipitation, temperature, and soil type were used to explore the effects of content of soil rock fragments on calculating of K in China. The correlation analysis, typical sampling area analysis, and redundancy analysis were applied to analyse the effects of content of soil rock fragments on calculating of K and its relationship with environment factors. The results showed that (1) The rock fragments in the soil profile (RFP) increased K. The rock fragments on the surface (RFS) of the soil reduced K. The effect of both RFP and RFS reduced K. (2) The effect of rock fragments on K was most affected by elevation, followed by terrain relief, NDVI, slope, soil type, temperature, and precipitation, but had little correlation with land use. (3) The result of redundancy analysis showed elevation to be the main predominant factor of the effect of rock fragments on K. This study fully considered the effect of rock fragments on calculating of K and carried out a quantitative analysis of the factors affecting the effect of rock fragments on K, so as to provide necessary scientific basis for estimating K and evaluating soil erosion status in China more accurately.},
DOI = {10.3390/ijerph19020648}
}



@Article{s22020423,
AUTHOR = {Tomita, Ko and Chew, Michael Yit Lin},
TITLE = {A Review of Infrared Thermography for Delamination Detection on Infrastructures and Buildings},
JOURNAL = {Sensors},
VOLUME = {22},
YEAR = {2022},
NUMBER = {2},
ARTICLE-NUMBER = {423},
URL = {https://www.mdpi.com/1424-8220/22/2/423},
ISSN = {1424-8220},
ABSTRACT = {This paper provides a comprehensive review on the use of infrared thermography to detect delamination on infrastructures and buildings. Approximately 200 pieces of relevant literature were evaluated, and their findings were summarized. The factors affecting the accuracy and detectability of infrared thermography were consolidated and discussed. Necessary measures to effectively capture latent defects at the early stage of delamination before crack formation were investigated. The results of this study could be used as the benchmarks for setting standardized testing criteria as well as for comparison of results for future works on the use of infrared thermography for detection of delamination on infrastructures and buildings.},
DOI = {10.3390/s22020423}
}



@Article{rs14020265,
AUTHOR = {Wang, Yanjun and Li, Shaochun and Teng, Fei and Lin, Yunhao and Wang, Mengjie and Cai, Hengfan},
TITLE = {Improved Mask R-CNN for Rural Building Roof Type Recognition from UAV High-Resolution Images: A Case Study in Hunan Province, China},
JOURNAL = {Remote Sensing},
VOLUME = {14},
YEAR = {2022},
NUMBER = {2},
ARTICLE-NUMBER = {265},
URL = {https://www.mdpi.com/2072-4292/14/2/265},
ISSN = {2072-4292},
ABSTRACT = {Accurate roof information of buildings can be obtained from UAV high-resolution images. The large-scale accurate recognition of roof types (such as gabled, flat, hipped, complex and mono-pitched roofs) of rural buildings is crucial for rural planning and construction. At present, most UAV high-resolution optical images only have red, green and blue (RGB) band information, which aggravates the problems of inter-class similarity and intra-class variability of image features. Furthermore, the different roof types of rural buildings are complex, spatially scattered, and easily covered by vegetation, which in turn leads to the low accuracy of roof type identification by existing methods. In response to the above problems, this paper proposes a method for identifying roof types of complex rural buildings based on visible high-resolution remote sensing images from UAVs. First, the fusion of deep learning networks with different visual features is investigated to analyze the effect of the different feature combinations of the visible difference vegetation index (VDVI) and Sobel edge detection features and UAV visible images on model recognition of rural building roof types. Secondly, an improved Mask R-CNN model is proposed to learn more complex features of different types of images of building roofs by using the ResNet152 feature extraction network with migration learning. After we obtained roof type recognition results in two test areas, we evaluated the accuracy of the results using the confusion matrix and obtained the following conclusions: (1) the model with RGB images incorporating Sobel edge detection features has the highest accuracy and enables the model to recognize more and more accurately the roof types of different morphological rural buildings, and the model recognition accuracy (Kappa coefficient (KC)) compared to that of RGB images is on average improved by 0.115; (2) compared with the original Mask R-CNN, U-Net, DeeplabV3 and PSPNet deep learning models, the improved Mask R-CNN model has the highest accuracy in recognizing the roof types of rural buildings, with F1-score, KC and OA averaging 0.777, 0.821 and 0.905, respectively. The method can obtain clear and accurate profiles and types of rural building roofs, and can be extended for green roof suitability evaluation, rooftop solar potential assessment, and other building roof surveys, management and planning.},
DOI = {10.3390/rs14020265}
}



@Article{app12020576,
AUTHOR = {Kim, Joseph and Atkins, Ella},
TITLE = {Airspace Geofencing and Flight Planning for Low-Altitude, Urban, Small Unmanned Aircraft Systems},
JOURNAL = {Applied Sciences},
VOLUME = {12},
YEAR = {2022},
NUMBER = {2},
ARTICLE-NUMBER = {576},
URL = {https://www.mdpi.com/2076-3417/12/2/576},
ISSN = {2076-3417},
ABSTRACT = {Airspace geofencing is a key capability for low-altitude Unmanned Aircraft System (UAS) Traffic Management (UTM). Geofenced airspace volumes can be allocated to safely contain compatible UAS flight operations within a fly-zone (keep-in geofence) and ensure the avoidance of no-fly zones (keep-out geofences). This paper presents the application of three-dimensional flight volumization algorithms to support airspace geofence management for UTM. Layered polygon geofence volumes enclose user-input waypoint-based 3-D flight trajectories, and a family of flight trajectory solutions designed to avoid keep-out geofence volumes is proposed using computational geometry. Geofencing and path planning solutions are analyzed in an accurately mapped urban environment. Urban map data processing algorithms are presented. Monte Carlo simulations statistically validate our algorithms, and runtime statistics are tabulated. Benchmark evaluation results in a Manhattan, New York City low-altitude environment compare our geofenced dynamic path planning solutions against a fixed airway corridor design. A case study with UAS route deconfliction is presented, illustrating how the proposed geofencing pipeline supports multi-vehicle deconfliction. This paper contributes to the nascent theory and the practice of dynamic airspace geofencing in support of UTM.},
DOI = {10.3390/app12020576}
}



@Article{s22020448,
AUTHOR = {Kim, Yumi and Paik, Mincheol and Kim, Bokyeong and Ko, Haneul and Kim, Seung-Yeon},
TITLE = {Neighbor-Aware Non-Orthogonal Multiple Access Scheme for Energy Harvesting Internet of Things},
JOURNAL = {Sensors},
VOLUME = {22},
YEAR = {2022},
NUMBER = {2},
ARTICLE-NUMBER = {448},
URL = {https://www.mdpi.com/1424-8220/22/2/448},
ISSN = {1424-8220},
ABSTRACT = {In a non-orthogonal multiple access (NOMA) environment, an Internet of Things (IoT) device achieves a high data rate by increasing its transmission power. However, excessively high transmission power can cause an energy outage of an IoT device and have a detrimental effect on the signal-to-interference-plus-noise ratio of neighbor IoT devices. In this paper, we propose a neighbor-aware NOMA scheme (NA-NOMA) where each IoT device determines whether to transmit data to the base station and the transmission power at each time epoch in a distributed manner with the consideration of its energy level and other devices&rsquo; transmission powers. To maximize the aggregated data rate of IoT devices while keeping an acceptable average energy outage probability, a constrained stochastic game model is formulated, and the solution of the model is obtained using a best response dynamics-based algorithm. Evaluation results show that NA-NOMA can increase the average data rate up to 22% compared with a probability-based scheme while providing a sufficiently low energy outage probability (e.g., 0.05).},
DOI = {10.3390/s22020448}
}



@Article{rs14020269,
AUTHOR = {Wang, Yong and Zeng, Xiangqiang and Liao, Xiaohan and Zhuang, Dafang},
TITLE = {B-FGC-Net: A Building Extraction Network from High Resolution Remote Sensing Imagery},
JOURNAL = {Remote Sensing},
VOLUME = {14},
YEAR = {2022},
NUMBER = {2},
ARTICLE-NUMBER = {269},
URL = {https://www.mdpi.com/2072-4292/14/2/269},
ISSN = {2072-4292},
ABSTRACT = {Deep learning (DL) shows remarkable performance in extracting buildings from high resolution remote sensing images. However, how to improve the performance of DL based methods, especially the perception of spatial information, is worth further study. For this purpose, we proposed a building extraction network with feature highlighting, global awareness, and cross level information fusion (B-FGC-Net). The residual learning and spatial attention unit are introduced in the encoder of the B-FGC-Net, which simplifies the training of deep convolutional neural networks and highlights the spatial information representation of features. The global feature information awareness module is added to capture multiscale contextual information and integrate the global semantic information. The cross level feature recalibration module is used to bridge the semantic gap between low and high level features to complete the effective fusion of cross level information. The performance of the proposed method was tested on two public building datasets and compared with classical methods, such as UNet, LinkNet, and SegNet. Experimental results demonstrate that B-FGC-Net exhibits improved profitability of accurate extraction and information integration for both small and large scale buildings. The IoU scores of B-FGC-Net on WHU and INRIA Building datasets are 90.04% and 79.31%, respectively. B-FGC-Net is an effective and recommended method for extracting buildings from high resolution remote sensing images.},
DOI = {10.3390/rs14020269}
}



@Article{rs14020273,
AUTHOR = {Li, Mengyao and Zhang, Rui and Luo, Hongxia and Gu, Songwei and Qin, Zili},
TITLE = {Crop Mapping in the Sanjiang Plain Using an Improved Object-Oriented Method Based on Google Earth Engine and Combined Growth Period Attributes},
JOURNAL = {Remote Sensing},
VOLUME = {14},
YEAR = {2022},
NUMBER = {2},
ARTICLE-NUMBER = {273},
URL = {https://www.mdpi.com/2072-4292/14/2/273},
ISSN = {2072-4292},
ABSTRACT = {In recent years, the scale of rural land transfer has gradually expanded, and the phenomenon of non-grain-oriented cultivated land has emerged. Obtaining crop planting information is of the utmost importance to guaranteeing national food security; however, the acquisition of the spatial distribution of crops in large-scale areas often has the disadvantages of excessive calculation and low accuracy. Therefore, the IO-Growth method, which takes the growth stage every 10 days as the index and combines the spectral features of crops to refine the effective interval of conventional wavebands for object-oriented classification, was proposed. The results were as follows: (1) the IO-Growth method obtained classification results with an overall accuracy and F1 score of 0.92, and both values increased by 6.98% compared to the method applied without growth stages; (2) the IO-Growth method reduced 288 features to only 5 features, namely Sentinel-2: Red Edge1, normalized difference vegetation index, Red, short-wave infrared2, and Aerosols, on the 261st to 270th days, which greatly improved the utilization rate of the wavebands; (3) the rise of geographic data processing platforms makes it simple to complete computations with massive data in a short time. The results showed that the IO-Growth method is suitable for large-scale vegetation mapping.},
DOI = {10.3390/rs14020273}
}



@Article{app12020586,
AUTHOR = {Mahdavisharif, Mahsa and Cagliano, Anna Corinna and Rafele, Carlo},
TITLE = {Investigating the Integration of Industry 4.0 and Lean Principles on Supply Chain: A Multi-Perspective Systematic Literature Review},
JOURNAL = {Applied Sciences},
VOLUME = {12},
YEAR = {2022},
NUMBER = {2},
ARTICLE-NUMBER = {586},
URL = {https://www.mdpi.com/2076-3417/12/2/586},
ISSN = {2076-3417},
ABSTRACT = {The development of digital technologies in all aspects of human life leads to increasing the necessity for investigating them in the Supply Chain (SC) as the main channel to provide products. Moreover, Lean principles, with the aim of reducing wastes, could be one of the main research streams in SC in recent years. Therefore, it is valuable to figure out the mutual effects of Lean principles and digital technologies as two growing areas in SC. Previous works did not pay attention to investigating this relationship at the SC level and were more focused on the production level. However, the present work addresses this issue by conducting a multi-perspective Systematic Literature Review (SLR). Additionally, in the present SLR, the impact of individual Industry 4.0 technologies in relation to Lean principles was investigated from various SC perspectives. The results reveal the necessity of studying single SC processes in Lean Digital SC. Moreover, the applicability of each technology should be illustrated to alleviate SC operational and organizational issues. The results provide useful insights about applying single digital technologies as well as a combination of them to each SC process to solve specific issues.},
DOI = {10.3390/app12020586}
}



@Article{rs14020274,
AUTHOR = {Anuar, Mohamed Marzhar and Halin, Alfian Abdul and Perumal, Thinagaran and Kalantar, Bahareh},
TITLE = {Aerial Imagery Paddy Seedlings Inspection Using Deep Learning},
JOURNAL = {Remote Sensing},
VOLUME = {14},
YEAR = {2022},
NUMBER = {2},
ARTICLE-NUMBER = {274},
URL = {https://www.mdpi.com/2072-4292/14/2/274},
ISSN = {2072-4292},
ABSTRACT = {In recent years complex food security issues caused by climatic changes, limitations in human labour, and increasing production costs require a strategic approach in addressing problems. The emergence of artificial intelligence due to the capability of recent advances in computing architectures could become a new alternative to existing solutions. Deep learning algorithms in computer vision for image classification and object detection can facilitate the agriculture industry, especially in paddy cultivation, to alleviate human efforts in laborious, burdensome, and repetitive tasks. Optimal planting density is a crucial factor for paddy cultivation as it will influence the quality and quantity of production. There have been several studies involving planting density using computer vision and remote sensing approaches. While most of the studies have shown promising results, they have disadvantages and show room for improvement. One of the disadvantages is that the studies aim to detect and count all the paddy seedlings to determine planting density. The defective paddy seedlings&rsquo; locations are not pointed out to help farmers during the sowing process. In this work we aimed to explore several deep convolutional neural networks (DCNN) models to determine which one performs the best for defective paddy seedling detection using aerial imagery. Thus, we evaluated the accuracy, robustness, and inference latency of one- and two-stage pretrained object detectors combined with state-of-the-art feature extractors such as EfficientNet, ResNet50, and MobilenetV2 as a backbone. We also investigated the effect of transfer learning with fine-tuning on the performance of the aforementioned pretrained models. Experimental results showed that our proposed methods were capable of detecting the defective paddy rice seedlings with the highest precision and an F1-Score of 0.83 and 0.77, respectively, using a one-stage pretrained object detector called EfficientDet-D1 EficientNet.},
DOI = {10.3390/rs14020274}
}



@Article{s22020450,
AUTHOR = {Abreha, Haftay Gebreslasie and Hayajneh, Mohammad and Serhani, Mohamed Adel},
TITLE = {Federated Learning in Edge Computing: A Systematic Survey},
JOURNAL = {Sensors},
VOLUME = {22},
YEAR = {2022},
NUMBER = {2},
ARTICLE-NUMBER = {450},
URL = {https://www.mdpi.com/1424-8220/22/2/450},
ISSN = {1424-8220},
ABSTRACT = {Edge Computing (EC) is a new architecture that extends Cloud Computing (CC) services closer to data sources. EC combined with Deep Learning (DL) is a promising technology and is widely used in several applications. However, in conventional DL architectures with EC enabled, data producers must frequently send and share data with third parties, edge or cloud servers, to train their models. This architecture is often impractical due to the high bandwidth requirements, legalization, and privacy vulnerabilities. The Federated Learning (FL) concept has recently emerged as a promising solution for mitigating the problems of unwanted bandwidth loss, data privacy, and legalization. FL can co-train models across distributed clients, such as mobile phones, automobiles, hospitals, and more, through a centralized server, while maintaining data localization. FL can therefore be viewed as a stimulating factor in the EC paradigm as it enables collaborative learning and model optimization. Although the existing surveys have taken into account applications of FL in EC environments, there has not been any systematic survey discussing FL implementation and challenges in the EC paradigm. This paper aims to provide a systematic survey of the literature on the implementation of FL in EC environments with a taxonomy to identify advanced solutions and other open problems. In this survey, we review the fundamentals of EC and FL, then we review the existing related works in FL in EC. Furthermore, we describe the protocols, architecture, framework, and hardware requirements for FL implementation in the EC environment. Moreover, we discuss the applications, challenges, and related existing solutions in the edge FL. Finally, we detail two relevant case studies of applying FL in EC, and we identify open issues and potential directions for future research. We believe this survey will help researchers better understand the connection between FL and EC enabling technologies and concepts.},
DOI = {10.3390/s22020450}
}



@Article{rs14020279,
AUTHOR = {Wu, Qiong and Li, Zhaoyi and Yang, Changbao and Li, Hongqing and Gong, Liwei and Guo, Fengxiang},
TITLE = {On the Scale Effect of Relationship Identification between Land Surface Temperature and 3D Landscape Pattern: The Application of Random Forest},
JOURNAL = {Remote Sensing},
VOLUME = {14},
YEAR = {2022},
NUMBER = {2},
ARTICLE-NUMBER = {279},
URL = {https://www.mdpi.com/2072-4292/14/2/279},
ISSN = {2072-4292},
ABSTRACT = {Urbanization processes greatly change urban landscape patterns and the urban thermal environment. Significant multi-scale correlation exists between the land surface temperature (LST) and landscape pattern. Compared with traditional linear regression methods, the regression model based on random forest has the advantages of higher accuracy and better learning ability, and can remove the linear correlation between regression features. Taking Beijing&rsquo;s metropolitan area as an example, this paper conducted multi-scale relationship analysis between 3D landscape patterns and LST using Pearson Correlation Coefficient (PCC), Multiple Linear Regression and Random Forest Regression (RFR). The results indicated that LST was relatively high in the central area of Beijing, and decreased from the center to the surrounding areas. The interpretation effect of 3D landscape metrics on LST was more obvious than that of the 2D landscape metrics, and 3D landscape diversity and evenness played more important roles than the other metrics in the change of LST. The multi-scale relationship between LST and the landscape pattern was discovered in the fourth ring road of Beijing, the effect of the extent of change on the landscape pattern is greater than that of the grain size change, and the interpretation effect and correlation of landscape metrics on LST increase with the increase in the rectangle size. Impervious surfaces significantly increased the LST, while the impervious surfaces located at low building areas were more likely to increase LST than those located at tall building areas. It seems that increasing the distance between buildings to improve the rate of energy exchange between urban and rural areas can effectively decrease LST. Vegetation and water can effectively reduce LST, but large, clustered and irregularly shaped patches have a better effect on land surface cooling than small and discrete patches. The Coefficients of Rectangle Variation (CORV) power function fitting results of landscape metrics showed that the optimal rectangle size for studying the relationship between the 3D landscape pattern and LST is about 700 m. Our study is useful for future urban planning and provides references to mitigate the daytime urban heat island (UHI) effect.},
DOI = {10.3390/rs14020279}
}



@Article{s22020464,
AUTHOR = {Nepal, Upesh and Eslamiat, Hossein},
TITLE = {Comparing YOLOv3, YOLOv4 and YOLOv5 for Autonomous Landing Spot Detection in Faulty UAVs},
JOURNAL = {Sensors},
VOLUME = {22},
YEAR = {2022},
NUMBER = {2},
ARTICLE-NUMBER = {464},
URL = {https://www.mdpi.com/1424-8220/22/2/464},
ISSN = {1424-8220},
ABSTRACT = {In-flight system failure is one of the major safety concerns in the operation of unmanned aerial vehicles (UAVs) in urban environments. To address this concern, a safety framework consisting of following three main tasks can be utilized: (1) Monitoring health of the UAV and detecting failures, (2) Finding potential safe landing spots in case a critical failure is detected in step 1, and (3) Steering the UAV to a safe landing spot found in step 2. In this paper, we specifically look at the second task, where we investigate the feasibility of utilizing object detection methods to spot safe landing spots in case the UAV suffers an in-flight failure. Particularly, we investigate different versions of the YOLO objection detection method and compare their performances for the specific application of detecting a safe landing location for a UAV that has suffered an in-flight failure. We compare the performance of YOLOv3, YOLOv4, and YOLOv5l while training them by a large aerial image dataset called DOTA in a Personal Computer (PC) and also a Companion Computer (CC). We plan to use the chosen algorithm on a CC that can be attached to a UAV, and the PC is used to verify the trends that we see between the algorithms on the CC. We confirm the feasibility of utilizing these algorithms for effective emergency landing spot detection and report their accuracy and speed for that specific application. Our investigation also shows that the YOLOv5l algorithm outperforms YOLOv4 and YOLOv3 in terms of accuracy of detection while maintaining a slightly slower inference speed.},
DOI = {10.3390/s22020464}
}



@Article{rs14020285,
AUTHOR = {Zhang, Tao and Jiang, Xiaodong and Jiang, Linlin and Li, Xuran and Yang, Shenbin and Li, Yingxue},
TITLE = {Hyperspectral Reflectance Characteristics of Rice Canopies under Changes in Diffuse Radiation Fraction},
JOURNAL = {Remote Sensing},
VOLUME = {14},
YEAR = {2022},
NUMBER = {2},
ARTICLE-NUMBER = {285},
URL = {https://www.mdpi.com/2072-4292/14/2/285},
ISSN = {2072-4292},
ABSTRACT = {To analyze the hyperspectral reflectance characteristics of rice canopies under changes in diffuse radiation fraction, experiments using different cover materials were performed in Nanjing, China, during 2016 and 2017. Each year, two treatments with different reduction ratios of diffuse radiation fraction but with similar shading rates were set in the field experiment: In T1, total solar radiation shading rate was 14.10%, and diffuse radiation fraction was 31.09%; in T2, total solar radiation shading rate was 14.42%, and diffuse radiation fraction was 39.98%, respectively. A non-shading treatment was included as a control (CK). Canopy hyperspectral reflectance, soil and plant analyzer development (SPAD), and leaf area index (LAI) were measured under shading treatments on different days after heading. The red-edge parameters (position, &lambda;0; maximum amplitude, D&lambda;; area, &alpha;0; width, &sigma;) were calculated, as well as the area, depth, and width of three absorption bands. The location of the first absorption band appeared in the range of 553&ndash;788 nm, and the second and third absorption bands appeared in the range of 874&ndash;1257 nm. The results show that the shading treatment had a significant effect on the rice canopy&rsquo;s hyperspectral reflectance. Compared with CK, the canopy reflectance of T1 (the diffuse radiation fraction was 31.09%) and T2 (the diffuse radiation fraction was 39.98%) decreased in the visible light range (350&ndash;760 nm) and increased in the near-infrared range (800&ndash;1350 nm), while the red-edge parameters (&lambda;0, D&lambda;, &alpha;0), SPAD, and LAI increased. On the other hand, under shading treatment, the increase in diffuse radiation fraction also had a significant impact on the hyperspectral spectra of the rice canopy, especially at 14 days after heading. Compared with T1, the green peak (550 nm) of T2 reduced by 16.12%, and the average reflectance at 800&ndash;900 nm increased by 10%. Based on correlation analysis, it was found that these hyperspectral reflectance characteristics were mainly due to the increase in SPAD (2.31%) and LAI (7.62%), which also led to the increase in D&lambda; (8.70%) and &alpha;0 (13.89%). Then, the second and third absorption features of T2 were significantly different from that of T1, which suggests that the change in diffuse radiation fraction could affect the process of water vapor absorption by rice.},
DOI = {10.3390/rs14020285}
}



@Article{drones6010015,
AUTHOR = {Restás, Ágoston},
TITLE = {Drone Applications Fighting COVID-19 Pandemic&mdash;Towards Good Practices},
JOURNAL = {Drones},
VOLUME = {6},
YEAR = {2022},
NUMBER = {1},
ARTICLE-NUMBER = {15},
URL = {https://www.mdpi.com/2504-446X/6/1/15},
ISSN = {2504-446X},
ABSTRACT = {Of the recent epidemics, the impact of the COVID-19 pandemic has been particularly severe, not only putting our health at risk, but also negatively affecting our daily lives. As there are no developed algorithms for the use of drones in epidemiological situations, it is ideal to analyze the experience gained on drones so far and outline the effective methods for future good practice. The author relies on a method of analyzing widely available open information, such as images and videos available on the Internet, reports from drone users, announcements by drone manufacturers and the contents of newspaper articles. Furthermore, the author has relied on the results of the relevant literature, as well as previous experience as a drone user and fire commander. The study reveals numerous possibilities associated with drone usage in epidemic related situations, but previous applications are based on previous experience gained during a non-epidemic situation, without developed algorithms. Applications can be divided into different types of groups: drones can collect data for management and provide information to the public, perform general or special logistical tasks to support health care and disinfect to reduce the risk of spreading the epidemic.},
DOI = {10.3390/drones6010015}
}



@Article{ijgi11010043,
AUTHOR = {Cira, Calimanut-Ionut and Kada, Martin and Manso-Callejo, Miguel-Ángel and Alcarria, Ramón and Bordel Sanchez, Borja},
TITLE = {Improving Road Surface Area Extraction via Semantic Segmentation with Conditional Generative Learning for Deep Inpainting Operations},
JOURNAL = {ISPRS International Journal of Geo-Information},
VOLUME = {11},
YEAR = {2022},
NUMBER = {1},
ARTICLE-NUMBER = {43},
URL = {https://www.mdpi.com/2220-9964/11/1/43},
ISSN = {2220-9964},
ABSTRACT = {The road surface area extraction task is generally carried out via semantic segmentation over remotely-sensed imagery. However, this supervised learning task is often costly as it requires remote sensing images labelled at the pixel level, and the results are not always satisfactory (presence of discontinuities, overlooked connection points, or isolated road segments). On the other hand, unsupervised learning does not require labelled data and can be employed for post-processing the geometries of geospatial objects extracted via semantic segmentation. In this work, we implement a conditional Generative Adversarial Network to reconstruct road geometries via deep inpainting procedures on a new dataset containing unlabelled road samples from challenging areas present in official cartographic support from Spain. The goal is to improve the initial road representations obtained with semantic segmentation models via generative learning. The performance of the model was evaluated on unseen data by conducting a metrical comparison where a maximum Intersection over Union (IoU) score improvement of 1.3% was observed when compared to the initial semantic segmentation result. Next, we evaluated the appropriateness of applying unsupervised generative learning using a qualitative perceptual validation to identify the strengths and weaknesses of the proposed method in very complex scenarios and gain a better intuition of the model&rsquo;s behaviour when performing large-scale post-processing with generative learning and deep inpainting procedures and observed important improvements in the generated data.},
DOI = {10.3390/ijgi11010043}
}



@Article{pr10010131,
AUTHOR = {Luo, Wei and Han, Wenlong and Fu, Ping and Wang, Huijuan and Zhao, Yunfeng and Liu, Ke and Liu, Yuyan and Zhao, Zihui and Zhu, Mengxu and Xu, Ruopeng and Wei, Guosheng},
TITLE = {A Water Surface Contaminants Monitoring Method Based on Airborne Depth Reasoning},
JOURNAL = {Processes},
VOLUME = {10},
YEAR = {2022},
NUMBER = {1},
ARTICLE-NUMBER = {131},
URL = {https://www.mdpi.com/2227-9717/10/1/131},
ISSN = {2227-9717},
ABSTRACT = {Water surface plastic pollution turns out to be a global issue, having aroused rising attention worldwide. How to monitor water surface plastic waste in real time and accurately collect and analyze the relevant numerical data has become a hotspot in water environment research. (1) Background: Over the past few years, unmanned aerial vehicles (UAVs) have been progressively adopted to conduct studies on the monitoring of water surface plastic waste. On the whole, the monitored data are stored in the UAVS to be subsequently retrieved and analyzed, thereby probably causing the loss of real-time information and hindering the whole monitoring process from being fully automated. (2) Methods: An investigation was conducted on the relationship, function and relevant mechanism between various types of plastic waste in the water surface system. On that basis, this study built a deep learning-based lightweight water surface plastic waste detection model, which was capable of automatically detecting and locating different water surface plastic waste. Moreover, a UAV platform-based edge computing architecture was built. (3) Results: The delay of return task data and UAV energy consumption were effectively reduced, and computing and network resources were optimally allocated. (4) Conclusions: The UAV platform based on airborne depth reasoning is expected to be the mainstream means of water environment monitoring in the future.},
DOI = {10.3390/pr10010131}
}



@Article{w14020178,
AUTHOR = {Jamali, Ali and Mahdianpari, Masoud},
TITLE = {Swin Transformer for Complex Coastal Wetland Classification Using the Integration of Sentinel-1 and Sentinel-2 Imagery},
JOURNAL = {Water},
VOLUME = {14},
YEAR = {2022},
NUMBER = {2},
ARTICLE-NUMBER = {178},
URL = {https://www.mdpi.com/2073-4441/14/2/178},
ISSN = {2073-4441},
ABSTRACT = {The emergence of deep learning techniques has revolutionized the use of machine learning algorithms to classify complicated environments, notably in remote sensing. Convolutional Neural Networks (CNNs) have shown considerable promise in classifying challenging high-dimensional remote sensing data, particularly in the classification of wetlands. State-of-the-art Natural Language Processing (NLP) algorithms, on the other hand, are transformers. Despite the fact that transformers have been utilized for a few remote sensing applications, they have not been compared to other well-known CNN networks in complex wetland classification. As such, for the classification of complex coastal wetlands in the study area of Saint John city, located in New Brunswick, Canada, we modified and employed the Swin Transformer algorithm. Moreover, the developed transformer classifier results were compared with two well-known deep CNNs of AlexNet and VGG-16. In terms of average accuracy, the proposed Swin Transformer algorithm outperformed the AlexNet and VGG-16 techniques by 14.3% and 44.28%, respectively. The proposed Swin Transformer classifier obtained F-1 scores of 0.65, 0.71, 0.73, 0.78, 0.82, 0.84, and 0.84 for the recognition of coastal marsh, shrub, bog, fen, aquatic bed, forested wetland, and freshwater marsh, respectively. The results achieved in this study suggest the high capability of transformers over very deep CNN networks for the classification of complex landscapes in remote sensing.},
DOI = {10.3390/w14020178}
}



@Article{aerospace9010031,
AUTHOR = {Samadzadegan, Farhad and Dadrass Javan, Farzaneh and Ashtari Mahini, Farnaz and Gholamshahi, Mehrnaz},
TITLE = {Detection and Recognition of Drones Based on a Deep Convolutional Neural Network Using Visible Imagery},
JOURNAL = {Aerospace},
VOLUME = {9},
YEAR = {2022},
NUMBER = {1},
ARTICLE-NUMBER = {31},
URL = {https://www.mdpi.com/2226-4310/9/1/31},
ISSN = {2226-4310},
ABSTRACT = {Drones are becoming increasingly popular not only for recreational purposes but also in a variety of applications in engineering, disaster management, logistics, securing airports, and others. In addition to their useful applications, an alarming concern regarding physical infrastructure security, safety, and surveillance at airports has arisen due to the potential of their use in malicious activities. In recent years, there have been many reports of the unauthorized use of various types of drones at airports and the disruption of airline operations. To address this problem, this study proposes a novel deep learning-based method for the efficient detection and recognition of two types of drones and birds. Evaluation of the proposed approach with the prepared image dataset demonstrates better efficiency compared to existing detection systems in the literature. Furthermore, drones are often confused with birds because of their physical and behavioral similarity. The proposed method is not only able to detect the presence or absence of drones in an area but also to recognize and distinguish between two types of drones, as well as distinguish them from birds. The dataset used in this work to train the network consists of 10,000 visible images containing two types of drones as multirotors, helicopters, and also birds. The proposed deep learning method can directly detect and recognize two types of drones and distinguish them from birds with an accuracy of 83%, mAP of 84%, and IoU of 81%. The values of average recall, average accuracy, and average F1-score were also reported as 84%, 83%, and 83%, respectively, in three classes.},
DOI = {10.3390/aerospace9010031}
}



@Article{rs14020302,
AUTHOR = {Li, Chunchao and Tang, Xuebin and Shi, Lulu and Peng, Yuanxi and Tang, Yuhua},
TITLE = {A Two-Staged Feature Extraction Method Based on Total Variation for Hyperspectral Images},
JOURNAL = {Remote Sensing},
VOLUME = {14},
YEAR = {2022},
NUMBER = {2},
ARTICLE-NUMBER = {302},
URL = {https://www.mdpi.com/2072-4292/14/2/302},
ISSN = {2072-4292},
ABSTRACT = {Effective feature extraction (FE) has always been the focus of hyperspectral images (HSIs). For aerial remote-sensing HSIs processing and its land cover classification, in this article, an efficient two-staged hyperspectral FE method based on total variation (TV) is proposed. In the first stage, the average fusion method was used to reduce the spectral dimension. Then, the anisotropic TV model with different regularization parameters was utilized to obtain featured blocks of different smoothness, each containing multi-scale structure information, and we stacked them as the next stage&rsquo;s input. In the second stage, equipped with singular value transformation to reduce the dimension again, we followed an isotropic TV model based on split Bregman algorithm for further detail smoothing. Finally, the feature-extracted block was fed to the support vector machine for classification experiments. The results, with three hyperspectral datasets, demonstrate that our proposed method can competitively outperform state-of-the-art methods in terms of its classification accuracy and computing time. Also, our proposed method delivers robustness and stability by comprehensive parameter analysis.},
DOI = {10.3390/rs14020302}
}



@Article{app12020670,
AUTHOR = {Tursunboev, Jamshid and Kang, Yong-Sung and Huh, Sung-Bum and Lim, Dong-Woo and Kang, Jae-Mo and Jung, Heechul},
TITLE = {Hierarchical Federated Learning for Edge-Aided Unmanned Aerial Vehicle Networks},
JOURNAL = {Applied Sciences},
VOLUME = {12},
YEAR = {2022},
NUMBER = {2},
ARTICLE-NUMBER = {670},
URL = {https://www.mdpi.com/2076-3417/12/2/670},
ISSN = {2076-3417},
ABSTRACT = {Federated learning (FL) allows UAVs to collaboratively train a globally shared machine learning model while locally preserving their private data. Recently, the FL in edge-aided unmanned aerial vehicle (UAV) networks has drawn an upsurge of research interest due to a bursting increase in heterogeneous data acquired by UAVs and the need to build the global model with privacy; however, a critical issue is how to deal with the non-independent and identically distributed (non-i.i.d.) nature of heterogeneous data while ensuring the convergence of learning. To effectively address this challenging issue, this paper proposes a novel and high-performing FL scheme, namely, the hierarchical FL algorithm, for the edge-aided UAV network, which exploits the edge servers located in base stations as intermediate aggregators with employing commonly shared data. Experiment results demonstrate that the proposed hierarchical FL algorithm outperforms several baseline FL algorithms and exhibits better convergence behavior.},
DOI = {10.3390/app12020670}
}



@Article{s22020532,
AUTHOR = {Hoskere, Vedhus and Narazaki, Yasutaka and Spencer, Billie F.},
TITLE = {Physics-Based Graphics Models in 3D Synthetic Environments as Autonomous Vision-Based Inspection Testbeds},
JOURNAL = {Sensors},
VOLUME = {22},
YEAR = {2022},
NUMBER = {2},
ARTICLE-NUMBER = {532},
URL = {https://www.mdpi.com/1424-8220/22/2/532},
ISSN = {1424-8220},
ABSTRACT = {Manual visual inspection of civil infrastructure is high-risk, subjective, and time-consuming. The success of deep learning and the proliferation of low-cost consumer robots has spurred rapid growth in research and application of autonomous inspections. The major components of autonomous inspection include data acquisition, data processing, and decision making, which are usually studied independently. However, for robust real-world applicability, these three aspects of the overall process need to be addressed concurrently with end-to-end testing, incorporating scenarios such as variations in structure type, color, damage level, camera distance, view angle, lighting, etc. Developing real-world datasets that span all these scenarios is nearly impossible. In this paper, we propose a framework to create a virtual visual inspection testbed using 3D synthetic environments that can enable end-to-end testing of autonomous inspection strategies. To populate the 3D synthetic environment with virtual damaged buildings, we propose the use of a non-linear finite element model to inform the realistic and automated visual rendering of different damage types, the damage state, and the material textures of what are termed herein physics-based graphics models (PBGMs). To demonstrate the benefits of the autonomous inspection testbed, three experiments are conducted with models of earthquake damaged reinforced concrete buildings. First, we implement the proposed framework to generate a new large-scale annotated benchmark dataset for post-earthquake inspections of buildings termed QuakeCity. Second, we demonstrate the improved performance of deep learning models trained using the QuakeCity dataset for inference on real data. Finally, a comparison of deep learning-based damage state estimation for different data acquisition strategies is carried out. The results demonstrate the use of PBGMs as an effective testbed for the development and validation of strategies for autonomous vision-based inspections of civil infrastructure.},
DOI = {10.3390/s22020532}
}



@Article{rs14020317,
AUTHOR = {Hardy, Andy and Oakes, Gregory and Hassan, Juma and Yussuf, Yussuf},
TITLE = {Improved Use of Drone Imagery for Malaria Vector Control through Technology-Assisted Digitizing (TAD)},
JOURNAL = {Remote Sensing},
VOLUME = {14},
YEAR = {2022},
NUMBER = {2},
ARTICLE-NUMBER = {317},
URL = {https://www.mdpi.com/2072-4292/14/2/317},
ISSN = {2072-4292},
ABSTRACT = {Drones have the potential to revolutionize malaria vector control initiatives through rapid and accurate mapping of potential malarial mosquito larval habitats to help direct field Larval Source Management (LSM) efforts. However, there are no clear recommendations on how these habitats can be extracted from drone imagery in an operational context. This paper compares the results of two mapping approaches: supervised image classification using machine learning and Technology-Assisted Digitising (TAD) mapping that employs a new region growing tool suitable for non-experts. These approaches were applied concurrently to drone imagery acquired at seven sites in Zanzibar, United Republic of Tanzania. Whilst the two approaches were similar in processing time, the TAD approach significantly outperformed the supervised classification approach at all sites (t = 5.1, p &lt; 0.01). Overall accuracy scores (mean overall accuracy 62%) suggest that a supervised classification approach is unsuitable for mapping potential malarial mosquito larval habitats in Zanzibar, whereas the TAD approach offers a simple and accurate (mean overall accuracy 96%) means of mapping these complex features. We recommend that this approach be used alongside targeted ground-based surveying (i.e., in areas inappropriate for drone surveying) for generating precise and accurate spatial intelligence to support operational LSM programmes.},
DOI = {10.3390/rs14020317}
}



@Article{app12020691,
AUTHOR = {Zhong, Jiwei and Xiang, Ziru and Li, Cheng},
TITLE = {Synchronized Assessment of Bridge Structural Damage and Moving Force via Truncated Load Shape Function},
JOURNAL = {Applied Sciences},
VOLUME = {12},
YEAR = {2022},
NUMBER = {2},
ARTICLE-NUMBER = {691},
URL = {https://www.mdpi.com/2076-3417/12/2/691},
ISSN = {2076-3417},
ABSTRACT = {Moving load and structural damage assessment has always been a crucial topic in bridge health monitoring, as it helps analyze the daily operating status of bridges and provides fundamental information for bridge safety evaluation. However, most studies and research consider these issues as two separate problems. In practice, unknown moving loads and damage usually coexist and influence the bridge vibration synergically. This paper proposes an innovative synchronized assessment method that determines structural damages and moving forces simultaneously. The method firstly improves the virtual distortion method, which shifts the structural damage into external virtual forces and hence transforms the damage assessment as well as the moving force identification to a multi-force reconstruction problem. Secondly, a truncated load shape function (TLSF) technique is developed to solve the forces in the time domain. As the technique smoothens the pulse function via a limited number of TLSF, the singularity and dimension of the system matrix in the force reconstruction is largely reduced. A continuous beam and a three-dimensional truss bridge are simulated as examples. Case studies show that the method can effectively identify various speeds and numbers of moving loads, as well as different levels of structural damages. The calculation efficiency and robustness to white noise are also impressive.},
DOI = {10.3390/app12020691}
}



@Article{s22020549,
AUTHOR = {Song, Xiaoyu and Yang, Guijun and Xu, Xingang and Zhang, Dongyan and Yang, Chenghai and Feng, Haikuan},
TITLE = {Winter Wheat Nitrogen Estimation Based on Ground-Level and UAV-Mounted Sensors},
JOURNAL = {Sensors},
VOLUME = {22},
YEAR = {2022},
NUMBER = {2},
ARTICLE-NUMBER = {549},
URL = {https://www.mdpi.com/1424-8220/22/2/549},
ISSN = {1424-8220},
ABSTRACT = {A better understanding of wheat nitrogen status is important for improving N fertilizer management in precision farming. In this study, four different sensors were evaluated for their ability to estimate winter wheat nitrogen. A Gaussian process regression (GPR) method with the sequential backward feature removal (SBBR) routine was used to identify the best combinations of vegetation indices (VIs) sensitive to wheat N indicators for different sensors. Wheat leaf N concentration (LNC), plant N concentration (PNC), and the nutrition index (NNI) were estimated by the VIs through parametric regression (PR), multivariable linear regression (MLR), and Gaussian process regression (GPR). The study results reveal that the optical fluorescence sensor provides more accurate estimates of winter wheat N status at a low-canopy coverage condition. The Dualex Nitrogen Balance Index (NBI) is the best leaf-level indicator for wheat LNC, PNC and NNI at the early wheat growth stage. At the early growth stage, Multiplex indices are the best canopy-level indicators for LNC, PNC, and NNI. At the late growth stage, ASD VIs provide accurate estimates for wheat N indicators. This study also reveals that the GPR with SBBR analysis method provides more accurate estimates of winter wheat LNC, PNC, and NNI, with the best VI combinations for these sensors across the different winter wheat growth stages, compared with the MLR and PR methods.},
DOI = {10.3390/s22020549}
}



@Article{s22020546,
AUTHOR = {Yu, Xinyang and Chang, Chunyan and Song, Jiaxuan and Zhuge, Yuping and Wang, Ailing},
TITLE = {Precise Monitoring of Soil Salinity in China&rsquo;s Yellow River Delta Using UAV-Borne Multispectral Imagery and a Soil Salinity Retrieval Index},
JOURNAL = {Sensors},
VOLUME = {22},
YEAR = {2022},
NUMBER = {2},
ARTICLE-NUMBER = {546},
URL = {https://www.mdpi.com/1424-8220/22/2/546},
ISSN = {1424-8220},
ABSTRACT = {Monitoring salinity information of salinized soil efficiently and precisely using the unmanned aerial vehicle (UAV) is critical for the rational use and sustainable development of arable land resources. The sensitive parameter and a precise retrieval method of soil salinity, however, remain unknown. This study strived to explore the sensitive parameter and construct an optimal method for retrieving soil salinity. The UAV-borne multispectral image in China&rsquo;s Yellow River Delta was acquired to extract band reflectance, compute vegetation indexes and soil salinity indexes. Soil samples collected from 120 different study sites were used for laboratory salt content measurements. Grey correlation analysis and Pearson correlation coefficient methods were employed to screen sensitive band reflectance and indexes. A new soil salinity retrieval index (SSRI) was then proposed based on the screened sensitive reflectance. The Partial Least Squares Regression (PLSR), Multivariable Linear Regression (MLR), Back Propagation Neural Network (BPNN), Support Vector Machine (SVM), and Random Forest (RF) methods were employed to construct retrieval models based on the sensitive indexes. The results found that green, red, and near-infrared (NIR) bands were sensitive to soil salinity, which can be used to build SSRI. The SSRI-based RF method was the optimal method for accurately retrieving the soil salinity. Its modeling determination coefficient (R2) and Root Mean Square Error (RMSE) were 0.724 and 1.764, respectively; and the validation R2, RMSE, and Residual Predictive Deviation (RPD) were 0.745, 1.879, and 2.211.},
DOI = {10.3390/s22020546}
}



@Article{aerospace9010035,
AUTHOR = {Bakar, Abu and Li, Ke and Liu, Haobo and Xu, Ziqi and Alessandrini, Marco and Wen, Dongsheng},
TITLE = {Multi-Objective Optimization of Low Reynolds Number Airfoil Using Convolutional Neural Network and Non-Dominated Sorting Genetic Algorithm},
JOURNAL = {Aerospace},
VOLUME = {9},
YEAR = {2022},
NUMBER = {1},
ARTICLE-NUMBER = {35},
URL = {https://www.mdpi.com/2226-4310/9/1/35},
ISSN = {2226-4310},
ABSTRACT = {The airfoil is the prime component of flying vehicles. For low-speed flights, low Reynolds number airfoils are used. The characteristic of low Reynolds number airfoils is a laminar separation bubble and an associated drag rise. This paper presents a framework for the design of a low Reynolds number airfoil. The contributions of the proposed research are twofold. First, a convolutional neural network (CNN) is designed for the aerodynamic coefficient prediction of low Reynolds number airfoils. Data generation is discussed in detail and XFOIL is selected to obtain aerodynamic coefficients. The performance of the CNN is evaluated using different learning rate schedulers and adaptive learning rate optimizers. The trained model can predict the aerodynamic coefficients with high accuracy. Second, the trained model is used with a non-dominated sorting genetic algorithm (NSGA-II) for multi-objective optimization of the low Reynolds number airfoil at a specific angle of attack. A similar optimization is performed using NSGA-II directly calling XFOIL, to obtain the aerodynamic coefficients. The Pareto fronts of both optimizations are compared, and it is concluded that the proposed CNN can replicate the actual Pareto in considerably less time.},
DOI = {10.3390/aerospace9010035}
}



@Article{su14020810,
AUTHOR = {Yigitcanlar, Tan and Regona, Massimo and Kankanamge, Nayomi and Mehmood, Rashid and D’Costa, Justin and Lindsay, Samuel and Nelson, Scott and Brhane, Adiam},
TITLE = {Detecting Natural Hazard-Related Disaster Impacts with Social Media Analytics: The Case of Australian States and Territories},
JOURNAL = {Sustainability},
VOLUME = {14},
YEAR = {2022},
NUMBER = {2},
ARTICLE-NUMBER = {810},
URL = {https://www.mdpi.com/2071-1050/14/2/810},
ISSN = {2071-1050},
ABSTRACT = {Natural hazard-related disasters are disruptive events with significant impact on people, communities, buildings, infrastructure, animals, agriculture, and environmental assets. The exponentially increasing anthropogenic activities on the planet have aggregated the climate change and consequently increased the frequency and severity of these natural hazard-related disasters, and consequential damages in cities. The digital technological advancements, such as monitoring systems based on fusion of sensors and machine learning, in early detection, warning and disaster response systems are being implemented as part of the disaster management practice in many countries and presented useful results. Along with these promising technologies, crowdsourced social media disaster big data analytics has also started to be utilized. This study aims to form an understanding of how social media analytics can be utilized to assist government authorities in estimating the damages linked to natural hazard-related disaster impacts on urban centers in the age of climate change. To this end, this study analyzes crowdsourced disaster big data from Twitter users in the testbed case study of Australian states and territories. The methodological approach of this study employs the social media analytics method and conducts sentiment and content analyses of location-based Twitter messages (n = 131,673) from Australia. The study informs authorities on an innovative way to analyze the geographic distribution, occurrence frequency of various disasters and their damages based on the geo-tweets analysis.},
DOI = {10.3390/su14020810}
}



@Article{en15020522,
AUTHOR = {Kuznetsov, Geniy and Kopylov, Nikolay and Sushkina, Elena and Zhdanova, Alena},
TITLE = {Adaptation of Fire-Fighting Systems to Localization of Fires in the Premises: Review},
JOURNAL = {Energies},
VOLUME = {15},
YEAR = {2022},
NUMBER = {2},
ARTICLE-NUMBER = {522},
URL = {https://www.mdpi.com/1996-1073/15/2/522},
ISSN = {1996-1073},
ABSTRACT = {Fire protection is a basic safety issue for all categories of buildings. The criteria for effective fire suppression and the characteristics of extinguishing systems in insulated areas depend on a combination of factors. The main influences include the type of combustible material, ambient temperature, type of spray extinguisher, air inflow and outflow conditions, and space geometry. This article analyzes the most widely used fire-extinguishing technologies in different locations. The main aspects of using the pulsed delivery technology of extinguishing liquid are considered. Based on the analysis of publications from the last decade, it is possible to develop intelligent systems for recording fires and extinguishing fires in the premises.},
DOI = {10.3390/en15020522}
}



@Article{technologies10010007,
AUTHOR = {Sevastopoulos, Christos and Konstantopoulos, Stasinos and Balaji, Keshav and Zaki Zadeh, Mohammad and Makedon, Fillia},
TITLE = {A Simulated Environment for Robot Vision Experiments},
JOURNAL = {Technologies},
VOLUME = {10},
YEAR = {2022},
NUMBER = {1},
ARTICLE-NUMBER = {7},
URL = {https://www.mdpi.com/2227-7080/10/1/7},
ISSN = {2227-7080},
ABSTRACT = {Training on simulation data has proven invaluable in applying machine learning in robotics. However, when looking at robot vision in particular, simulated images cannot be directly used no matter how realistic the image rendering is, as many physical parameters (temperature, humidity, wear-and-tear in time) vary and affect texture and lighting in ways that cannot be encoded in the simulation. In this article we propose a different approach for extracting value from simulated environments: although neither of the trained models can be used nor are any evaluation scores expected to be the same on simulated and physical data, the conclusions drawn from simulated experiments might be valid. If this is the case, then simulated environments can be used in early-stage experimentation with different network architectures and features. This will expedite the early development phase before moving to (harder to conduct) physical experiments in order to evaluate the most promising approaches. In order to test this idea we created two simulated environments for the Unity engine, acquired simulated visual datasets, and used them to reproduce experiments originally carried out in a physical environment. The comparison of the conclusions drawn in the physical and the simulated experiments is promising regarding the validity of our approach.},
DOI = {10.3390/technologies10010007}
}



@Article{agronomy12010183,
AUTHOR = {Denora, Michele and Fiorentini, Marco and Zenobi, Stefano and Deligios, Paola A. and Orsini, Roberto and Ledda, Luigi and Perniola, Michele},
TITLE = {Validation of Rapid and Low-Cost Approach for the Delineation of Zone Management Based on Machine Learning Algorithms},
JOURNAL = {Agronomy},
VOLUME = {12},
YEAR = {2022},
NUMBER = {1},
ARTICLE-NUMBER = {183},
URL = {https://www.mdpi.com/2073-4395/12/1/183},
ISSN = {2073-4395},
ABSTRACT = {Proximal soil sensors are receiving strong attention from several disciplinary fields, and this has led to a rise in their availability in the market in the last two decades. The aim of this work was to validate agronomically a zone management delineation procedure from electromagnetic induction (EMI) maps applied to two different rainfed durum wheat fields. The k-means algorithm was applied based on the gap statistic index for the identification of the optimal number of management zones and their positions. Traditional statistical analysis was performed to detect significant differences in soil characteristics and crop response of each management zones. The procedure showed the presence of two management zones at both two sites under analysis, and it was agronomically validated by the significant difference in soil texture (+24.17%), bulk density (+6.46%), organic matter (+39.29%), organic carbon (+39.4%), total carbonates (+25.34%), total nitrogen (+30.14%), protein (+1.50%) and yield data (+1.07 t ha&minus;1). Moreover, six unmanned aerial vehicle (UAV) flight missions were performed to investigate the relationship between five vegetation indexes and the EMI maps. The results suggest performing the multispectral images acquisition during the flowering phenological stages to attribute the crop spatial variability to different soil proprieties.},
DOI = {10.3390/agronomy12010183}
}



@Article{rs14020341,
AUTHOR = {Letard, Mathilde and Collin, Antoine and Corpetti, Thomas and Lague, Dimitri and Pastol, Yves and Ekelund, Anders},
TITLE = {Classification of Land-Water Continuum Habitats Using Exclusively Airborne Topobathymetric Lidar Green Waveforms and Infrared Intensity Point Clouds},
JOURNAL = {Remote Sensing},
VOLUME = {14},
YEAR = {2022},
NUMBER = {2},
ARTICLE-NUMBER = {341},
URL = {https://www.mdpi.com/2072-4292/14/2/341},
ISSN = {2072-4292},
ABSTRACT = {Coastal areas host highly valuable ecosystems that are increasingly exposed to the threats of global and local changes. Monitoring their evolution at a high temporal and spatial scale is therefore crucial and mostly possible through remote sensing. This article demonstrates the relevance of topobathymetric lidar data for coastal and estuarine habitat mapping by classifying bispectral data to produce 3D maps of 21 land and sea covers at very high resolution. Green lidar full waveforms are processed to retrieve tailored features corresponding to the signature of those habitats. These features, along with infrared intensities and elevations, are used as predictors for random forest classifications, and their respective contribution to the accuracy of the results is assessed. We find that green waveform features, infrared intensities, and elevations are complimentary and yield the best classification results when used in combination. With this configuration, a classification accuracy of 90.5% is achieved for the segmentation of our dual-wavelength lidar dataset. Eventually, we produce an original mapping of a coastal site under the form of a point cloud, paving the way for 3D classification and management of land and sea covers.},
DOI = {10.3390/rs14020341}
}



@Article{drones6010021,
AUTHOR = {Zhang, Ruohao and Condomines, Jean-Philippe and Lochin, Emmanuel},
TITLE = {A Multifractal Analysis and Machine Learning Based Intrusion Detection System with an Application in a UAS/RADAR System},
JOURNAL = {Drones},
VOLUME = {6},
YEAR = {2022},
NUMBER = {1},
ARTICLE-NUMBER = {21},
URL = {https://www.mdpi.com/2504-446X/6/1/21},
ISSN = {2504-446X},
ABSTRACT = {The rapid development of Internet of Things (IoT) technology, together with mobile network technology, has created a never-before-seen world of interconnection, evoking research on how to make it vaster, faster, and safer. To support the ongoing fight against the malicious misuse of networks, in this paper we propose a novel algorithm called AMDES (unmanned aerial system multifractal analysis intrusion detection system) for spoofing attack detection. This novel algorithm is based on both wavelet leader multifractal analysis (WLM) and machine learning (ML) principles. In earlier research on unmanned aerial systems (UAS), intrusion detection systems (IDS) based on multifractal (MF) spectral analysis have been used to provide accurate MF spectrum estimations of network traffic. Such an estimation is then used to detect and characterize flooding anomalies that can be observed in an unmanned aerial vehicle (UAV) network. However, the previous contributions have lacked the consideration of other types of network intrusions commonly observed in UAS networks, such as the man in the middle attack (MITM). In this work, this promising methodology has been accommodated to detect a spoofing attack within a UAS. This methodology highlights a robust approach in terms of false positive performance in detecting intrusions in a UAS location reporting system.},
DOI = {10.3390/drones6010021}
}



@Article{rs14020349,
AUTHOR = {Abdi, Omid and Uusitalo, Jori and Kivinen, Veli-Pekka},
TITLE = {Logging Trail Segmentation via a Novel U-Net Convolutional Neural Network and High-Density Laser Scanning Data},
JOURNAL = {Remote Sensing},
VOLUME = {14},
YEAR = {2022},
NUMBER = {2},
ARTICLE-NUMBER = {349},
URL = {https://www.mdpi.com/2072-4292/14/2/349},
ISSN = {2072-4292},
ABSTRACT = {Logging trails are one of the main components of modern forestry. However, spotting the accurate locations of old logging trails through common approaches is challenging and time consuming. This study was established to develop an approach, using cutting-edge deep-learning convolutional neural networks and high-density laser scanning data, to detect logging trails in different stages of commercial thinning, in Southern Finland. We constructed a U-Net architecture, consisting of encoder and decoder paths with several convolutional layers, pooling and non-linear operations. The canopy height model (CHM), digital surface model (DSM), and digital elevation models (DEMs) were derived from the laser scanning data and were used as image datasets for training the model. The labeled dataset for the logging trails was generated from different references as well. Three forest areas were selected to test the efficiency of the algorithm that was developed for detecting logging trails. We designed 21 routes, including 390 samples of the logging trails and non-logging trails, covering all logging trails inside the stands. The results indicated that the trained U-Net using DSM (k = 0.846 and IoU = 0.867) shows superior performance over the trained model using CHM (k = 0.734 and IoU = 0.782), DEMavg (k = 0.542 and IoU = 0.667), and DEMmin (k = 0.136 and IoU = 0.155) in distinguishing logging trails from non-logging trails. Although the efficiency of the developed approach in young and mature stands that had undergone the commercial thinning is approximately perfect, it needs to be improved in old stands that have not received the second or third commercial thinning.},
DOI = {10.3390/rs14020349}
}



@Article{s22020587,
AUTHOR = {Segura, David and Khatib, Emil J. and Barco, Raquel},
TITLE = {Dynamic Packet Duplication for Industrial URLLC},
JOURNAL = {Sensors},
VOLUME = {22},
YEAR = {2022},
NUMBER = {2},
ARTICLE-NUMBER = {587},
URL = {https://www.mdpi.com/1424-8220/22/2/587},
ISSN = {1424-8220},
ABSTRACT = {The fifth-generation (5G) network is presented as one of the main options for Industry 4.0 connectivity. To comply with critical messages, 5G offers the Ultra-Reliable and Low latency Communications (URLLC) service category with a millisecond end-to-end delay and reduced probability of failure. There are several approaches to achieve these requirements; however, these come at a cost in terms of redundancy, particularly the solutions based on multi-connectivity, such as Packet Duplication (PD). Specifically, this paper proposes a Machine Learning (ML) method to predict whether PD is required at a specific data transmission to successfully send a URLLC message. This paper is focused on reducing the resource usage with respect to pure static PD. The concept was evaluated on a 5G simulator, comparing between single connection, static PD and PD with the proposed prediction model. The evaluation results show that the prediction model reduced the number of packets sent with PD by 81% while maintaining the same level of latency as a static PD technique, which derives from a more efficient usage of the network resources.},
DOI = {10.3390/s22020587}
}



@Article{rs14020353,
AUTHOR = {Ruan, Mengying and Hu, Zhenqi and Duan, Xinyi and Zhou, Tao and Nie, Xinran},
TITLE = {Using UAV and Field Measurement Technology to Monitor the Impact of Coal Gangue Pile Temperature on Vegetation Ecological Construction},
JOURNAL = {Remote Sensing},
VOLUME = {14},
YEAR = {2022},
NUMBER = {2},
ARTICLE-NUMBER = {353},
URL = {https://www.mdpi.com/2072-4292/14/2/353},
ISSN = {2072-4292},
ABSTRACT = {Coal gangue is an inevitable product in coal mining and processing and is the most important source of pollution in mines. Vegetation restoration of coal gangue piles must consider its special site conditions. Therefore, we conducted unmanned air vehicle (UAV) temperature monitoring, field investigation and experimental analysis on spontaneous combustion coal gangue piles in Lu&rsquo;an mining area. In the vegetation construction of coal gangue piles, high-temperature stress affects plant survival. The spontaneous combustion coal gangue piles have abnormal temperature, high surface temperature and few vegetation types. The plant community species diversity index (Shannon&ndash;Wiener index, Pielou&rsquo;s index and Species abundance index) is small, the plant community is single and the plant diversity is low. Spontaneous combustion of coal gangue leads to soil acidification, reducing soil water content, soil organic carbon (SOM), available nitrogen (AN), available potassium (AK) and available phosphorus (AP). These factors are single or interactive in plants and have an impact on plant survival and growth. The research results are of great significance to the vegetation restoration of spontaneous combustion coal gangue piles, ecological reconstruction and the improvement of the ecological environment of coal mine areas.},
DOI = {10.3390/rs14020353}
}



@Article{s22020601,
AUTHOR = {Sharma, Prakriti and Leigh, Larry and Chang, Jiyul and Maimaitijiang, Maitiniyazi and Caffé, Melanie},
TITLE = {Above-Ground Biomass Estimation in Oats Using UAV Remote Sensing and Machine Learning},
JOURNAL = {Sensors},
VOLUME = {22},
YEAR = {2022},
NUMBER = {2},
ARTICLE-NUMBER = {601},
URL = {https://www.mdpi.com/1424-8220/22/2/601},
ISSN = {1424-8220},
ABSTRACT = {Current strategies for phenotyping above-ground biomass in field breeding nurseries demand significant investment in both time and labor. Unmanned aerial vehicles (UAV) can be used to derive vegetation indices (VIs) with high throughput and could provide an efficient way to predict forage yield with high accuracy. The main objective of the study is to investigate the potential of UAV-based multispectral data and machine learning approaches in the estimation of oat biomass. UAV equipped with a multispectral sensor was flown over three experimental oat fields in Volga, South Shore, and Beresford, South Dakota, USA, throughout the pre- and post-heading growth phases of oats in 2019. A variety of vegetation indices (VIs) derived from UAV-based multispectral imagery were employed to build oat biomass estimation models using four machine-learning algorithms: partial least squares (PLS), support vector machine (SVM), Artificial neural network (ANN), and random forest (RF). The results showed that several VIs derived from the UAV collected images were significantly positively correlated with dry biomass for Volga and Beresford (r = 0.2&ndash;0.65), however, in South Shore, VIs were either not significantly or weakly correlated with biomass. For Beresford, approximately 70% of the variance was explained by PLS, RF, and SVM validation models using data collected during the post-heading phase. Likewise for Volga, validation models had lower coefficient of determination (R2 = 0.20&ndash;0.25) and higher error (RMSE = 700&ndash;800 kg/ha) than training models (R2 = 0.50&ndash;0.60; RMSE = 500&ndash;690 kg/ha). In South Shore, validation models were only able to explain approx. 15&ndash;20% of the variation in biomass, which is possibly due to the insignificant correlation values between VIs and biomass. Overall, this study indicates that airborne remote sensing with machine learning has potential for above-ground biomass estimation in oat breeding nurseries. The main limitation was inconsistent accuracy in model prediction across locations. Multiple-year spectral data, along with the inclusion of textural features like crop surface model (CSM) derived height and volumetric indicators, should be considered in future studies while estimating biophysical parameters like biomass.},
DOI = {10.3390/s22020601}
}



@Article{drones6010023,
AUTHOR = {Zhang, Tong and Liu, Chunjiang and Li, Jiaqi and Pang, Minghui and Wang, Mingang},
TITLE = {A New Visual Inertial Simultaneous Localization and Mapping (SLAM) Algorithm Based on Point and Line Features},
JOURNAL = {Drones},
VOLUME = {6},
YEAR = {2022},
NUMBER = {1},
ARTICLE-NUMBER = {23},
URL = {https://www.mdpi.com/2504-446X/6/1/23},
ISSN = {2504-446X},
ABSTRACT = {In view of traditional point-line feature visual inertial simultaneous localization and mapping (SLAM) system, which has weak performance in accuracy so that it cannot be processed in real time under the condition of weak indoor texture and light and shade change, this paper proposes an inertial SLAM method based on point-line vision for indoor weak texture and illumination. Firstly, based on Bilateral Filtering, we apply the Speeded Up Robust Features (SURF) point feature extraction and Fast Nearest neighbor (FLANN) algorithms to improve the robustness of point feature extraction result. Secondly, we establish a minimum density threshold and length suppression parameter selection strategy of line feature, and take the geometric constraint line feature matching into consideration to improve the efficiency of processing line feature. And the parameters and biases of visual inertia are initialized based on maximum posterior estimation method. Finally, the simulation experiments are compared with the traditional tightly-coupled monocular visual&ndash;inertial odometry using point and line features (PL-VIO) algorithm. The simulation results demonstrate that the proposed an inertial SLAM method based on point-line vision for indoor weak texture and illumination can be effectively operated in real time, and its positioning accuracy is 22% higher on average and 40% higher in the scenario that illumination changes and blurred image.},
DOI = {10.3390/drones6010023}
}



@Article{rs14020361,
AUTHOR = {Salles, Roberto Neves and Campos Velho, Haroldo Fraga de and Shiguemori, Elcio Hideiti},
TITLE = {Automatic Position Estimation Based on Lidar &times; Lidar Data for Autonomous Aerial Navigation in the Amazon Forest Region},
JOURNAL = {Remote Sensing},
VOLUME = {14},
YEAR = {2022},
NUMBER = {2},
ARTICLE-NUMBER = {361},
URL = {https://www.mdpi.com/2072-4292/14/2/361},
ISSN = {2072-4292},
ABSTRACT = {In this paper we post-process and evaluate the position estimation of pairs of template windows and geo-referenced images generated from LiDAR cloud point data using the Normalized Cross-Correlation (NCC) method. We created intensity, surface and terrain pairs of images for use with template matching, with 5 m pixel spacing, through binning. We evaluated square and circular binning approaches, without filtering the original data. Template matching achieved approximately 7 m root mean square error (RMSE) on intensity and surface templates on the respective geo-referenced images, while on terrain templates it had many mismatches due to insufficient terrain features over the assumed flight transect. Analysis of NCC showed the possibility of rejecting bad matches of intensity and surface templates, but terrain templates required an additional criteria of flatness for rejection. The combined NCC of intensity, surface and terrain proved stable for rejection of bad matches and had the lowest RMSE. Filtering outliers from surface images changed very little the accuracy of the matches, but greatly improved correlation values, indicating that the forest canopy might have the best features for geo-localization with template matching. Position estimation is essential for autonomous navigation of aerial vehicles and the these experiments with LiDAR data show potential for localization over densely forested regions where methods using optical camera data may fail to acquire distinguishable features.},
DOI = {10.3390/rs14020361}
}



@Article{app12020826,
AUTHOR = {Yuan, Jing and Yu, Bo and Yan, Changxiang and Zhang, Junqiang and Ding, Ning and Dong, Youzhi},
TITLE = {Strategies for the Efficient Estimation of Soil Moisture through Spectroscopy: Sensitive Wavelength Algorithm, Spectral Resampling and Signal-to-Noise Ratio Selection},
JOURNAL = {Applied Sciences},
VOLUME = {12},
YEAR = {2022},
NUMBER = {2},
ARTICLE-NUMBER = {826},
URL = {https://www.mdpi.com/2076-3417/12/2/826},
ISSN = {2076-3417},
ABSTRACT = {It is found that the remote sensing parameters such as spectral range, spectral resolution and signal-to-noise ratio directly affect the estimation accuracy of soil moisture content. However, the lack of research on the relationship between the parameters and estimation accuracy restricts the prolongation of application. Therefore, this study took the demand for this application as the foothold for developing spectrometry. Firstly, a method based on sensitivity analysis of soil radiative transfer model-successive projection algorithm (SA-SPA) was proposed to select sensitive wavelengths. Then, the spectral resampling method was used to select the best spectral resolution in the corresponding sensitive wavelengths. Finally, the noise-free spectral data simulated by the soil radiative transfer model was added with Gaussian random noise to change the signal-to-noise ratio, so as to explore the influence of signal-to-noise ratio on the estimation accuracy. The research results show that the estimation accuracy obtained through the SA-SPA (RMSEP &lt; 12.1 g kg&minus;1) is generally superior to that from full-spectrum data (RMSEP &lt; 14 g kg&minus;1). At selected sensitive wavelengths, the best spectral resolution is 34 nm, and the applicable signal-to-noise ratio ranges from 150 to 350. This study provides technical support for the efficient estimation of soil moisture content and the development of spectrometry, which comprehensively considers the common influence of spectral range, spectral resolution and signal-to-noise ratio on the estimation accuracy of soil moisture content.},
DOI = {10.3390/app12020826}
}



@Article{horticulturae8010077,
AUTHOR = {Höing, Christian and Raut, Sharvari and Nasirahmadi, Abozar and Sturm, Barbara and Hensel, Oliver},
TITLE = {Development of an Optical System Based on Spectral Imaging Used for a Slug Control Robot},
JOURNAL = {Horticulturae},
VOLUME = {8},
YEAR = {2022},
NUMBER = {1},
ARTICLE-NUMBER = {77},
URL = {https://www.mdpi.com/2311-7524/8/1/77},
ISSN = {2311-7524},
ABSTRACT = {The state-of-the-art technique to control slug pests in agriculture is the spreading of slug pellets. This method has some downsides, because slug pellets also harm beneficials and often fail because their efficiency depends on the prevailing weather conditions. This study is part of a research project which is developing a pest control robot to monitor the field, detect slugs, and eliminate them. Robots represent a promising alternative to slug pellets. They work independent of weather conditions and can distinguish between pests and beneficials. As a prerequisite, a robot must be able to reliably identify slugs irrespective of the characteristics of the surrounding conditions. In this context, the utilization of computer vision and image analysis methods are challenging, because slugs look very similar to the soil, particularly in color images. Therefore, the goal of this study was to develop an optical filter-based system that distinguishes between slugs and soil. In this context, the spectral characteristics of both slugs and soil in the visible and visible near-infrared (VNIR) wavebands were measured. Conspicuous maxima followed by conspicuous local minima were found for the reflection spectra of slugs in the near infrared range from 850 nm to 990 nm]. Thus, this enabled differentiation between slugs and soils; soils showed a monotonic increase in the intensity of the relative reflection for this wavelength. The extrema determined in the reflection spectra of slugs were used to develop and set up a slug detector device consisting of a monochromatic camera, a filter changer and two narrow bandpass filters with nominal wavelengths of 925 nm and 975 nm. The developed optical system takes two photographs of the target area at night. By subtracting the pixel values of the images, the slugs are highlighted, and the soil is removed in the image due to the properties of the reflection spectra of soils and slugs. In the resulting image, the pixels of slugs were, on average, 12.4 times brighter than pixels of soil. This enabled the detection of slugs by a threshold method.},
DOI = {10.3390/horticulturae8010077}
}



@Article{rs14020380,
AUTHOR = {Putzenlechner, Birgitta and Marzahn, Philip and Koal, Philipp and Sánchez-Azofeifa, Arturo},
TITLE = {Fractional Vegetation Cover Derived from UAV and Sentinel-2 Imagery as a Proxy for In Situ FAPAR in a Dense Mixed-Coniferous Forest?},
JOURNAL = {Remote Sensing},
VOLUME = {14},
YEAR = {2022},
NUMBER = {2},
ARTICLE-NUMBER = {380},
URL = {https://www.mdpi.com/2072-4292/14/2/380},
ISSN = {2072-4292},
ABSTRACT = {The fraction of absorbed photosynthetic active radiation (FAPAR) is an essential climate variable for assessing the productivity of ecosystems. Satellite remote sensing provides spatially distributed FAPAR products, but their accurate and efficient validation is challenging in forest environments. As the FAPAR is linked to the canopy structure, it may be approximated by the fractional vegetation cover (FCOVER) under the assumption that incoming radiation is either absorbed or passed through gaps in the canopy. With FCOVER being easier to retrieve, FAPAR validation activities could benefit from a priori information on FCOVER. Spatially distributed FCOVER is available from satellite remote sensing or can be retrieved from imagery of Unmanned Aerial Vehicles (UAVs) at a centimetric resolution. We investigated remote sensing-derived FCOVER as a proxy for in situ FAPAR in a dense mixed-coniferous forest, considering both absolute values and spatiotemporal variability. Therefore, direct FAPAR measurements, acquired with a Wireless Sensor Network, were related to FCOVER derived from UAV and Sentinel-2 (S2) imagery at different seasons. The results indicated that spatially aggregated UAV-derived FCOVER was close (RMSE = 0.02) to in situ FAPAR during the peak vegetation period when the canopy was almost closed. The S2 FCOVER product underestimated both the in situ FAPAR and UAV-derived FCOVER (RMSE &gt; 0.3), which we attributed to the generic nature of the retrieval algorithm and the coarser resolution of the product. We concluded that UAV-derived FCOVER may be used as a proxy for direct FAPAR measurements in dense canopies. As another key finding, the spatial variability of the FCOVER consistently surpassed that of the in situ FAPAR, which was also well-reflected in the S2 FAPAR and FCOVER products. We recommend integrating this experimental finding as consistency criteria in the context of ECV quality assessments. To facilitate the FAPAR sampling activities, we further suggest assessing the spatial variability of UAV-derived FCOVER to benchmark sampling sizes for in situ FAPAR measurements. Finally, our study contributes to refining the FAPAR sampling protocols needed for the validation and improvement of FAPAR estimates in forest environments.},
DOI = {10.3390/rs14020380}
}



@Article{quat5010005,
AUTHOR = {Howland, Matthew D. and Tamberino, Anthony and Liritzis, Ioannis and Levy, Thomas E.},
TITLE = {Digital Deforestation: Comparing Automated Approaches to the Production of Digital Terrain Models (DTMs) in Agisoft Metashape},
JOURNAL = {Quaternary},
VOLUME = {5},
YEAR = {2022},
NUMBER = {1},
ARTICLE-NUMBER = {5},
URL = {https://www.mdpi.com/2571-550X/5/1/5},
ISSN = {2571-550X},
ABSTRACT = {This paper tests the suitability of automated point cloud classification tools provided by the popular image-based modeling (IBM) software package Agisoft Metashape for the generation of digital terrain models (DTMs) at moderately-vegetated archaeological sites. DTMs are often required for various forms of archaeological mapping and analysis. The suite of tools provided by Agisoft are relatively user-friendly as compared to many point cloud classification algorithms and do not require the use of additional software. Based on a case study from the Mycenaean site of Kastrouli, Greece, the mostly-automated, geometric classification tool &ldquo;Classify Ground Points&rdquo; provides the best results and produces a quality DTM that is sufficient for mapping and analysis. Each of the methods tested in this paper can likely be improved through manual editing of point cloud classification.},
DOI = {10.3390/quat5010005}
}



@Article{agronomy12010202,
AUTHOR = {Li, Zongpeng and Chen, Zhen and Cheng, Qian and Duan, Fuyi and Sui, Ruixiu and Huang, Xiuqiao and Xu, Honggang},
TITLE = {UAV-Based Hyperspectral and Ensemble Machine Learning for Predicting Yield in Winter Wheat},
JOURNAL = {Agronomy},
VOLUME = {12},
YEAR = {2022},
NUMBER = {1},
ARTICLE-NUMBER = {202},
URL = {https://www.mdpi.com/2073-4395/12/1/202},
ISSN = {2073-4395},
ABSTRACT = {Winter wheat is a widely-grown cereal crop worldwide. Using growth-stage information to estimate winter wheat yields in a timely manner is essential for accurate crop management and rapid decision-making in sustainable agriculture, and to increase productivity while reducing environmental impact. UAV remote sensing is widely used in precision agriculture due to its flexibility and increased spatial and spectral resolution. Hyperspectral data are used to model crop traits because of their ability to provide continuous rich spectral information and higher spectral fidelity. In this study, hyperspectral image data of the winter wheat crop canopy at the flowering and grain-filling stages was acquired by a low-altitude unmanned aerial vehicle (UAV), and machine learning was used to predict winter wheat yields. Specifically, a large number of spectral indices were extracted from the spectral data, and three feature selection methods, recursive feature elimination (RFE), Boruta feature selection, and the Pearson correlation coefficient (PCC), were used to filter high spectral indices in order to reduce the dimensionality of the data. Four major basic learner models, (1) support vector machine (SVM), (2) Gaussian process (GP), (3) linear ridge regression (LRR), and (4) random forest (RF), were also constructed, and an ensemble machine learning model was developed by combining the four base learner models. The results showed that the SVM yield prediction model, constructed on the basis of the preferred features, performed the best among the base learner models, with an R2 between 0.62 and 0.73. The accuracy of the proposed ensemble learner model was higher than that of each base learner model; moreover, the R2 (0.78) for the yield prediction model based on Boruta&rsquo;s preferred characteristics was the highest at the grain-filling stage.},
DOI = {10.3390/agronomy12010202}
}



@Article{s22020662,
AUTHOR = {Talaei Khoei, Tala and Ismail, Shereen and Kaabouch, Naima},
TITLE = {Dynamic Selection Techniques for Detecting GPS Spoofing Attacks on UAVs},
JOURNAL = {Sensors},
VOLUME = {22},
YEAR = {2022},
NUMBER = {2},
ARTICLE-NUMBER = {662},
URL = {https://www.mdpi.com/1424-8220/22/2/662},
ISSN = {1424-8220},
ABSTRACT = {Unmanned aerial vehicles are prone to several cyber-attacks, including Global Positioning System spoofing. Several techniques have been proposed for detecting such attacks. However, the recurrence and frequent Global Positioning System spoofing incidents show a need for effective security solutions to protect unmanned aerial vehicles. In this paper, we propose two dynamic selection techniques, Metric Optimized Dynamic selector and Weighted Metric Optimized Dynamic selector, which identify the most effective classifier for the detection of such attacks. We develop a one-stage ensemble feature selection method to identify and discard the correlated and low importance features from the dataset. We implement the proposed techniques using ten machine-learning models and compare their performance in terms of four evaluation metrics: accuracy, probability of detection, probability of false alarm, probability of misdetection, and processing time. The proposed techniques dynamically choose the classifier with the best results for detecting attacks. The results indicate that the proposed dynamic techniques outperform the existing ensemble models with an accuracy of 99.6%, a probability of detection of 98.9%, a probability of false alarm of 1.56%, a probability of misdetection of 1.09%, and a processing time of 1.24 s.},
DOI = {10.3390/s22020662}
}



@Article{rs14020396,
AUTHOR = {Shi, Yue and Han, Liangxiu and Kleerekoper, Anthony and Chang, Sheng and Hu, Tongle},
TITLE = {Novel CropdocNet Model for Automated Potato Late Blight Disease Detection from Unmanned Aerial Vehicle-Based Hyperspectral Imagery},
JOURNAL = {Remote Sensing},
VOLUME = {14},
YEAR = {2022},
NUMBER = {2},
ARTICLE-NUMBER = {396},
URL = {https://www.mdpi.com/2072-4292/14/2/396},
ISSN = {2072-4292},
ABSTRACT = {The accurate and automated diagnosis of potato late blight disease, one of the most destructive potato diseases, is critical for precision agricultural control and management. Recent advances in remote sensing and deep learning offer the opportunity to address this challenge. This study proposes a novel end-to-end deep learning model (CropdocNet) for accurate and automated late blight disease diagnosis from UAV-based hyperspectral imagery. The proposed method considers the potential disease-specific reflectance radiation variance caused by the canopy&rsquo;s structural diversity and introduces multiple capsule layers to model the part-to-whole relationship between spectral&ndash;spatial features and the target classes to represent the rotation invariance of the target classes in the feature space. We evaluate the proposed method with real UAV-based HSI data under controlled and natural field conditions. The effectiveness of the hierarchical features is quantitatively assessed and compared with the existing representative machine learning/deep learning methods on both testing and independent datasets. The experimental results show that the proposed model significantly improves accuracy when considering the hierarchical structure of spectral&ndash;spatial features, with average accuracies of 98.09% for the testing dataset and 95.75% for the independent dataset, respectively.},
DOI = {10.3390/rs14020396}
}



@Article{rs14020397,
AUTHOR = {Zhang, Fangfang and Wang, Changkun and Pan, Kai and Guo, Zhiying and Liu, Jie and Xu, Aiai and Ma, Haiyi and Pan, Xianzhang},
TITLE = {The Simultaneous Prediction of Soil Properties and Vegetation Coverage from Vis-NIR Hyperspectral Data with a One-Dimensional Convolutional Neural Network: A Laboratory Simulation Study},
JOURNAL = {Remote Sensing},
VOLUME = {14},
YEAR = {2022},
NUMBER = {2},
ARTICLE-NUMBER = {397},
URL = {https://www.mdpi.com/2072-4292/14/2/397},
ISSN = {2072-4292},
ABSTRACT = {Remote sensing of land surface mostly obtains a mixture of spectral information of soil and vegetation. It is thus of great value if soil and vegetation information can be acquired simultaneously from one model. In this study, we designed a laboratory experiment to simulate land surface compositions, including various soil types with varying soil moisture and vegetation coverage. A model of a one-dimensional convolutional neural network (1DCNN) was established to simultaneously estimate soil properties (organic matter, soil moisture, clay, and sand) and vegetation coverage based on the hyperspectral data measured in the experiment. The results showed that the model achieved excellent predictions for soil properties (R2 = 0.88&ndash;0.91, RPIQ = 4.01&ndash;5.78) and vegetation coverage (R2 = 0.95, RPIQ = 7.75). Compared with the partial least-squares regression (PLSR), the prediction accuracy of 1DCNN improved 42.20%, 45.82%, 43.32%, and 36.46% in terms of the root-mean-squared error (RMSE) for predicting soil organic matter, sand, clay, and soil moisture, respectively. The improvement might be caused by the fact that the spectral preprocessing and spectral features useful for predicting soil properties were successfully identified in the 1DCNN model. For the prediction of vegetation coverage, although the prediction accuracy by 1DCNN was excellent, its performance (R2 = 0.95, RPIQ = 7.75, RMSE = 3.92%) was lower than the PLSR model (R2 = 0.98, RPIQ = 12.57, RMSE = 2.41%). These results indicate that 1DCNN can simultaneously predict soil properties and vegetation coverage. However, the factors such as surface roughness and vegetation type that could affect the prediction accuracy should be investigated in the future.},
DOI = {10.3390/rs14020397}
}



@Article{biology11010149,
AUTHOR = {Paux, Etienne and Lafarge, Stéphane and Balfourier, François and Derory, Jérémy and Charmet, Gilles and Alaux, Michael and Perchet, Geoffrey and Bondoux, Marion and Baret, Frédéric and Barillot, Romain and Ravel, Catherine and Sourdille, Pierre and Le Gouis, Jacques and on behalf of the BREEDWHEAT Consortium},
TITLE = {Breeding for Economically and Environmentally Sustainable Wheat Varieties: An Integrated Approach from Genomics to Selection},
JOURNAL = {Biology},
VOLUME = {11},
YEAR = {2022},
NUMBER = {1},
ARTICLE-NUMBER = {149},
URL = {https://www.mdpi.com/2079-7737/11/1/149},
ISSN = {2079-7737},
ABSTRACT = {There is currently a strong societal demand for sustainability, quality, and safety in bread wheat production. To address these challenges, new and innovative knowledge, resources, tools, and methods to facilitate breeding are needed. This starts with the development of high throughput genomic tools including single nucleotide polymorphism (SNP) arrays, high density molecular marker maps, and full genome sequences. Such powerful tools are essential to perform genome-wide association studies (GWAS), to implement genomic and phenomic selection, and to characterize the worldwide diversity. This is also useful to breeders to broaden the genetic basis of elite varieties through the introduction of novel sources of genetic diversity. Improvement in varieties particularly relies on the detection of genomic regions involved in agronomical traits including tolerance to biotic (diseases and pests) and abiotic (drought, nutrient deficiency, high temperature) stresses. When enough resolution is achieved, this can result in the identification of candidate genes that could further be characterized to identify relevant alleles. Breeding must also now be approached through in silico modeling to simulate plant development, investigate genotype &times; environment interactions, and introduce marker&ndash;trait linkage information in the models to better implement genomic selection. Breeders must be aware of new developments and the information must be made available to the world wheat community to develop new high-yielding varieties that can meet the challenge of higher wheat production in a sustainable and fluctuating agricultural context. In this review, we compiled all knowledge and tools produced during the BREEDWHEAT project to show how they may contribute to face this challenge in the coming years.},
DOI = {10.3390/biology11010149}
}



@Article{rs14020415,
AUTHOR = {Ilniyaz, Osman and Kurban, Alishir and Du, Qingyun},
TITLE = {Leaf Area Index Estimation of Pergola-Trained Vineyards in Arid Regions Based on UAV RGB and Multispectral Data Using Machine Learning Methods},
JOURNAL = {Remote Sensing},
VOLUME = {14},
YEAR = {2022},
NUMBER = {2},
ARTICLE-NUMBER = {415},
URL = {https://www.mdpi.com/2072-4292/14/2/415},
ISSN = {2072-4292},
ABSTRACT = {The leaf area index (LAI), a valuable variable for assessing vine vigor, reflects nutrient concentrations in vineyards and assists in precise management, including fertilization, improving yield, quality, and vineyard uniformity. Although some vegetation indices (VIs) have been successfully used to assess LAI variations, they are unsuitable for vineyards of different types and structures. By calibrating the light extinction coefficient of a digital photography algorithm for proximal LAI measurements, this study aimed to develop VI-LAI models for pergola-trained vineyards based on high-resolution RGB and multispectral images captured by an unmanned aerial vehicle (UAV). The models were developed by comparing five machine learning (ML) methods, and a robust ensemble model was proposed using the five models as base learners. The results showed that the ensemble model outperformed the base models. The highest R2 and lowest RMSE values that were obtained using the best combination of VIs with multispectral data were 0.899 and 0.434, respectively; those obtained using the RGB data were 0.825 and 0.547, respectively. By improving the results by feature selection, ML methods performed better with multispectral data than with RGB images, and better with higher spatial resolution data than with lower resolution data. LAI variations can be monitored efficiently and accurately for large areas of pergola-trained vineyards using this framework.},
DOI = {10.3390/rs14020415}
}



@Article{rs14020420,
AUTHOR = {Qi, Guanqiu and Zhang, Yuanchuan and Wang, Kunpeng and Mazur, Neal and Liu, Yang and Malaviya, Devanshi},
TITLE = {Small Object Detection Method Based on Adaptive Spatial Parallel Convolution and Fast Multi-Scale Fusion},
JOURNAL = {Remote Sensing},
VOLUME = {14},
YEAR = {2022},
NUMBER = {2},
ARTICLE-NUMBER = {420},
URL = {https://www.mdpi.com/2072-4292/14/2/420},
ISSN = {2072-4292},
ABSTRACT = {As one type of object detection, small object detection has been widely used in daily-life-related applications with many real-time requirements, such as autopilot and navigation. Although deep-learning-based object detection methods have achieved great success in recent years, they are not effective in small object detection and most of them cannot achieve real-time processing. Therefore, this paper proposes a single-stage small object detection network (SODNet) that integrates the specialized feature extraction and information fusion techniques. An adaptively spatial parallel convolution module (ASPConv) is proposed to alleviate the lack of spatial information for target objects and adaptively obtain the corresponding spatial information through multi-scale receptive fields, thereby improving the feature extraction ability. Additionally, a split-fusion sub-module (SF) is proposed to effectively reduce the time complexity of ASPConv. A fast multi-scale fusion module (FMF) is proposed to alleviate the insufficient fusion of both semantic and spatial information. FMF uses two fast upsampling operators to first unify the resolution of the multi-scale feature maps extracted by the network and then fuse them, thereby effectively improving the small object detection ability. Comparative experimental results prove that the proposed method considerably improves the accuracy of small object detection on multiple benchmark datasets and achieves a high real-time performance.},
DOI = {10.3390/rs14020420}
}



@Article{rs14020424,
AUTHOR = {He, Yibo and Hu, Zhenqi and Fu, Yaokun and Yang, Kun and Wang, Rui and Shi, Guomou and Feng, Zhanjie and Yang, Qirang and Yu, Liang},
TITLE = {Underground Morphological Detection of Ground Fissures in Collapsible Loess Area Based on Three-Dimensional Laser Scanning Technology},
JOURNAL = {Remote Sensing},
VOLUME = {14},
YEAR = {2022},
NUMBER = {2},
ARTICLE-NUMBER = {424},
URL = {https://www.mdpi.com/2072-4292/14/2/424},
ISSN = {2072-4292},
ABSTRACT = {Underground coal mining inevitably causes ground fissures, especially permanent cracks that cannot be closed at the boundary of the working face. Studying the underground three-dimensional morphology of the permanent cracks allows one to accurately constrain the formation and development of the ground fissures. This information will contribute to reducing mine disasters and is also a prerequisites to avoid environmental pollution. We selected the Zhangjiamao coal mine (China), which is situated in a collapsible loess area, as a case study for deciphering the formation of permanent cracks. After injecting gypsum slurry into the mine, a three-dimensional model of the ground fissures is obtained by three-dimensional (3D) laser scanner technology that records the 3D underground morphology. Integrating the geological context of a collapsible loess area, the characteristics and main processes of the ground fissure development are constrained: (1) The width of the ground fissure decreases to 0 with increasing depth and is strongly affected by the soil composition. (2) Along the vertical extension direction, the ground fissures are generally inclined to the inner-side of the working face, but the direction remains uncertain at different depths. (3) The transverse propagation direction of the ground fissure becomes more complex with increasing depth. (4) Under the influence of soil texture and water, loose soil fills the bottom of the ground fissure, thus affecting the underground 3D morphology.},
DOI = {10.3390/rs14020424}
}



@Article{drones6010027,
AUTHOR = {Savkin, Andrey V. and Verma, Satish Chandra and Anstee, Stuart},
TITLE = {Optimal Navigation of an Unmanned Surface Vehicle and an Autonomous Underwater Vehicle Collaborating for Reliable Acoustic Communication with Collision Avoidance},
JOURNAL = {Drones},
VOLUME = {6},
YEAR = {2022},
NUMBER = {1},
ARTICLE-NUMBER = {27},
URL = {https://www.mdpi.com/2504-446X/6/1/27},
ISSN = {2504-446X},
ABSTRACT = {This paper focuses on safe navigation of an unmanned surface vehicle in proximity to a submerged autonomous underwater vehicle so as to maximise short-range, through-water data transmission while minimising the probability that the two vehicles will accidentally collide. A sliding mode navigation law is developed, and a rigorous proof of optimality of the proposed navigation law is presented. The developed navigation algorithm is relatively computationally simple and easily implementable in real time. Illustrative examples with extensive computer simulations demonstrate the effectiveness of the proposed method.},
DOI = {10.3390/drones6010027}
}



@Article{wevj13020023,
AUTHOR = {Zhang, Shiyu and Yang, Qing and Gao, Yuchen and Gao, Dexin},
TITLE = {Real-Time Fire Detection Method for Electric Vehicle Charging Stations Based on Machine Vision},
JOURNAL = {World Electric Vehicle Journal},
VOLUME = {13},
YEAR = {2022},
NUMBER = {2},
ARTICLE-NUMBER = {23},
URL = {https://www.mdpi.com/2032-6653/13/2/23},
ISSN = {2032-6653},
ABSTRACT = {During the charging process of electric vehicles (EV), the circuit inside the charger plug is connected in series, the charger input voltage does not match the rated input voltage, the temperature caused by the severe heating of the charging time is too high for too long, and other factors are very likely to trigger a fire in the vehicle charging pile. In this paper, an improved You Only Look Once v4 (YOLOv4) real-time target detection algorithm based on machine vision is proposed to monitor the site based on existing monitoring equipment, transmit live video information in real-time, expand the monitoring range, and significantly reduce the cost of use. During the experiment, the improved neural network model was trained by a homemade fire video image dataset, and a K-means clustering algorithm iwasintroduced to recalculate the anchor frame size for the specific object of flame; the existing dataset was used to perform multiple divisions by using a tenfold cross-validation algorithm, thus avoiding the selection of chance hyperparameters and models that do not have generalization ability because of special divisions. The experimental results show that the improved algorithm is fast and accurate in detecting large-size flames in real-time and small-size flames at the beginning of a fire, with a detection speed of 43 fps/s, mAP value of 91.53%, and F1 value of 0.91. Compared with YOLOv3 and YOLOv4 models, the improved model is sensitive to detecting different sizes of flames. It can suppress false alarms well in a variety of complex lighting environments. The prediction frame size fits the area where the target is located, the detection accuracy remains stable, and the comprehensive performance of the network model is significantly improved to meet the demand of real-time monitoring. It is significant for developing the EV industry and enhancing emergency response capability.},
DOI = {10.3390/wevj13020023}
}



@Article{app12030943,
AUTHOR = {Kiani, Farzad and Seyyedabbasi, Amir and Nematzadeh, Sajjad and Candan, Fuat and Çevik, Taner and Anka, Fateme Aysin and Randazzo, Giovanni and Lanza, Stefania and Muzirafuti, Anselme},
TITLE = {Adaptive Metaheuristic-Based Methods for Autonomous Robot Path Planning: Sustainable Agricultural Applications},
JOURNAL = {Applied Sciences},
VOLUME = {12},
YEAR = {2022},
NUMBER = {3},
ARTICLE-NUMBER = {943},
URL = {https://www.mdpi.com/2076-3417/12/3/943},
ISSN = {2076-3417},
ABSTRACT = {The increasing need for food in recent years means that environmental protection and sustainable agriculture are necessary. For this, smart agricultural systems and autonomous robots have become widespread. One of the most significant and persistent problems related to robots is 3D path planning, which is an NP-hard problem, for mobile robots. In this paper, efficient methods are proposed by two metaheuristic algorithms (Incremental Gray Wolf Optimization (I-GWO) and Expanded Gray Wolf Optimization (Ex-GWO)). The proposed methods try to find collision-free optimal paths between two points for robots without human intervention in an acceptable time with the lowest process costs and efficient use of resources in large-scale and crowded farmlands. Thanks to the methods proposed in this study, various tasks such as tracking crops can be performed efficiently by autonomous robots. The simulations are carried out using three methods, and the obtained results are compared with each other and analyzed. The relevant results show that in the proposed methods, the mobile robots avoid the obstacles successfully and obtain the optimal path cost from source to destination. According to the simulation results, the proposed method based on the Ex-GWO algorithm has a better success rate of 55.56% in optimal path cost.},
DOI = {10.3390/app12030943}
}



@Article{agriculture12020124,
AUTHOR = {Song, Xiaoxin and Wu, Fei and Lu, Xiaotong and Yang, Tianle and Ju, Chengxin and Sun, Chengming and Liu, Tao},
TITLE = {The Classification of Farming Progress in Rice&ndash;Wheat Rotation Fields Based on UAV RGB Images and the Regional Mean Model},
JOURNAL = {Agriculture},
VOLUME = {12},
YEAR = {2022},
NUMBER = {2},
ARTICLE-NUMBER = {124},
URL = {https://www.mdpi.com/2077-0472/12/2/124},
ISSN = {2077-0472},
ABSTRACT = {Extraction of farming progress information in rice&ndash;wheat rotation regions is an important topic in smart field research. In this study, a new method for the classification of farming progress types using unmanned aerial vehicle (UAV) RGB images and the proposed regional mean (RM) model is presented. First, RGB information was extracted from the images to create and select the optimal color indices. After index classification, we compared the brightness reflection of the corresponding grayscale map, the classification interval, and the standard deviation of each farming progress type. These comparisons showed that the optimal classification color indices were the normalized red&ndash;blue difference index (NRBDI), the normalized green&ndash;blue difference index (NGBDI), and the modified red&ndash;blue difference index (MRBDI). Second, the RM model was built according to the whole-field farming progress classification requirements to achieve the final classification. We verified the model accuracy, and the Kappa coefficients obtained by combining the NRBDI, NGBDI, and MRBDI with the RM model were 0.86, 0.82, and 0.88, respectively. The proposed method was then applied to predict UAV RGB images of unharvested wheat, harvested wheat, and tilled and irrigated fields. The results were compared with those obtained with traditional machine learning methods, that is, the support vector machine, maximum likelihood classification, and random forest methods. The NRBDI, NGBDI, and MRBDI were combined with the RM model to monitor farming progress of ground truth ROIs, and the Kappa coefficients obtained were 0.9134, 0.8738, and 0.9179, respectively, while traditional machine learning methods all produced a Kappa coefficient less than 0.7. The results indicate a significantly higher accuracy of the proposed method than those of the traditional machine learning classification methods for the identification of farming progress type. The proposed work provides an important reference for the application of UAV to the field classification of progress types.},
DOI = {10.3390/agriculture12020124}
}



@Article{electronics11030294,
AUTHOR = {Wang, Hao and Li, Guoqing and Hou, Jie and Chen, Lianyun and Hu, Nailian},
TITLE = {A Path Planning Method for Underground Intelligent Vehicles Based on an Improved RRT* Algorithm},
JOURNAL = {Electronics},
VOLUME = {11},
YEAR = {2022},
NUMBER = {3},
ARTICLE-NUMBER = {294},
URL = {https://www.mdpi.com/2079-9292/11/3/294},
ISSN = {2079-9292},
ABSTRACT = {Path planning is one of the key technologies for unmanned driving of underground intelligent vehicles. Due to the complexity of the drift environment and the vehicle structure, some improvements should be made to adapt to underground mining conditions. This paper proposes a path planning method based on an improved RRT* (Rapidly-Exploring Random Tree Star) algorithm for solving the problem of path planning for underground intelligent vehicles based on articulated structure and drift environment conditions. The kinematics of underground intelligent vehicles are realized by vectorized map and dynamic constraints. The RRT* algorithm is selected for improvement, including dynamic step size, steering angle constraints, and optimal tree reconnection. The simulation case study proves the effectiveness of the algorithm, with a lower path length, lower node count, and 100% steering angle efficiency.},
DOI = {10.3390/electronics11030294}
}



@Article{s22030721,
AUTHOR = {Cui, Xue-Zhi and Feng, Quan and Wang, Shu-Zhi and Zhang, Jian-Hua},
TITLE = {Monocular Depth Estimation with Self-Supervised Learning for Vineyard Unmanned Agricultural Vehicle},
JOURNAL = {Sensors},
VOLUME = {22},
YEAR = {2022},
NUMBER = {3},
ARTICLE-NUMBER = {721},
URL = {https://www.mdpi.com/1424-8220/22/3/721},
ISSN = {1424-8220},
ABSTRACT = {To find an economical solution to infer the depth of the surrounding environment of unmanned agricultural vehicles (UAV), a lightweight depth estimation model called MonoDA based on a convolutional neural network is proposed. A series of sequential frames from monocular videos are used to train the model. The model is composed of two subnetworks&mdash;the depth estimation subnetwork and the pose estimation subnetwork. The former is a modified version of U-Net that reduces the number of bridges, while the latter takes EfficientNet-B0 as its backbone network to extract the features of sequential frames and predict the pose transformation relations between the frames. The self-supervised strategy is adopted during the training, which means the depth information labels of frames are not needed. Instead, the adjacent frames in the image sequence and the reprojection relation of the pose are used to train the model. Subnetworks&rsquo; outputs (depth map and pose relation) are used to reconstruct the input frame, then a self-supervised loss between the reconstructed input and the original input is calculated. Finally, the loss is employed to update the parameters of the two subnetworks through the backward pass. Several experiments are conducted to evaluate the model&rsquo;s performance, and the results show that MonoDA has competitive accuracy over the KITTI raw dataset as well as our vineyard dataset. Besides, our method also possessed the advantage of non-sensitivity to color. On the computing platform of our UAV&rsquo;s environment perceptual system NVIDIA JETSON TX2, the model could run at 18.92 FPS. To sum up, our approach provides an economical solution for depth estimation by using monocular cameras, which achieves a good trade-off between accuracy and speed and can be used as a novel auxiliary depth detection paradigm for UAVs.},
DOI = {10.3390/s22030721}
}



@Article{s22030717,
AUTHOR = {Pang, Alexis and Chang, Melissa W L and Chen, Yang},
TITLE = {Evaluation of Random Forests (RF) for Regional and Local-Scale Wheat Yield Prediction in Southeast Australia},
JOURNAL = {Sensors},
VOLUME = {22},
YEAR = {2022},
NUMBER = {3},
ARTICLE-NUMBER = {717},
URL = {https://www.mdpi.com/1424-8220/22/3/717},
ISSN = {1424-8220},
ABSTRACT = {Wheat accounts for more than 50% of Australia&rsquo;s total grain production. The capability to generate accurate in-season yield predictions is important across all components of the agricultural value chain. The literature on wheat yield prediction has motivated the need for more novel works evaluating machine learning techniques such as random forests (RF) at multiple scales. This research applied a Random Forest Regression (RFR) technique to build regional and local-scale yield prediction models at the pixel level for three southeast Australian wheat-growing paddocks, each located in Victoria (VIC), New South Wales (NSW) and South Australia (SA) using 2018 yield maps from data supplied by collaborating farmers. Time-series Normalized Difference Vegetation Index (NDVI) data derived from Planet&rsquo;s high spatio-temporal resolution imagery, meteorological variables and yield data were used to train, test and validate the models at pixel level using Python libraries for (a) regional-scale three-paddock composite and (b) individual paddocks. The composite region-wide RF model prediction for the three paddocks performed well (R2 = 0.86, RMSE = 0.18 t ha&minus;1). RF models for individual paddocks in VIC (R2 = 0.89, RMSE = 0.15 t ha&minus;1) and NSW (R2 = 0.87, RMSE = 0.07 t ha&minus;1) performed well, but moderate performance was seen for SA (R2 = 0.45, RMSE = 0.25 t ha&minus;1). Generally, high values were underpredicted and low values overpredicted. This study demonstrated the feasibility of applying RF modeling on satellite imagery and yielded &lsquo;big data&rsquo; for regional as well as local-scale yield prediction.},
DOI = {10.3390/s22030717}
}



@Article{w14030299,
AUTHOR = {Kseňak, Ľubomír and Pukanská, Katarína and Bartoš, Karol and Blišťan, Peter},
TITLE = {Assessment of the Usability of SAR and Optical Satellite Data for Monitoring Spatio-Temporal Changes in Surface Water: Bodrog River Case Study},
JOURNAL = {Water},
VOLUME = {14},
YEAR = {2022},
NUMBER = {3},
ARTICLE-NUMBER = {299},
URL = {https://www.mdpi.com/2073-4441/14/3/299},
ISSN = {2073-4441},
ABSTRACT = {Mapping watercourses and their surroundings through remote sensing methods is a fast, continuous, and effective method and is a crucial tool for capturing change and possibly predicting hazards. Thanks to Synthetic Aperture Radar (SAR) technology and the ability of its backscattered and emitted radiation to penetrate the atmosphere under any conditions, this type of mapping of water surfaces is of particular importance. This paper presents the possibility of using SAR technology for long-term observations of changes in the behaviour of rivers and river systems, combined with optical multispectral images Sentinel-2. Additionally, it aims to demonstrate the suitability of satellite SAR and multispectral data implementation for mapping changes in watercourses, caused not only by their natural development but especially by inundation processes in their catchment area. Appropriate Sentinel-1 image processing evaluation procedures demonstrate that the usage of vertical-vertical (VV) type polarisation configuration is a suitable methodology for documenting water bodies, and a Lee filter is an acceptable tool for radar noise filtering. The extraction process of water surfaces is based on the determination of threshold values using the &ldquo;Otsu&rdquo; principle. Subsequently, the comparison of the results is realised by the spectral indices of water&mdash;the Normalized Difference Water Index (NDWI), Modified Normalized Difference Water Index (MNDWI), a pair of Automated Water Extraction Index (AWEI) indices, and supervised classification method Maximum Likelihood Classification (MLC). The results are numerical and graphical evaluated. In assessing the accuracy of SAR extraction, the highest values achieved in Overall Accuracy (OA) were a maximum of 98.6%. On average, the lower values were in User Accuracy (UA) with a maximum of 93.1%, where VV polarisation also dominates. However, vertical-horizontal (VH) polarisation dominates in Producer Accuracy (PA) with a maximum of 84.9%.},
DOI = {10.3390/w14030299}
}



@Article{rs14030476,
AUTHOR = {Chen, Guang and Shang, Yi},
TITLE = {Transformer for Tree Counting in Aerial Images},
JOURNAL = {Remote Sensing},
VOLUME = {14},
YEAR = {2022},
NUMBER = {3},
ARTICLE-NUMBER = {476},
URL = {https://www.mdpi.com/2072-4292/14/3/476},
ISSN = {2072-4292},
ABSTRACT = {The number of trees and their spatial distribution are key information for forest management. In recent years, deep learning-based approaches have been proposed and shown promising results in lowering the expensive labor cost of a forest inventory. In this paper, we propose a new efficient deep learning model called density transformer or DENT for automatic tree counting from aerial images. The architecture of DENT contains a multi-receptive field convolutional neural network to extract visual feature representation from local patches and their wide context, a transformer encoder to transfer contextual information across correlated positions, a density map generator to generate spatial distribution map of trees, and a fast tree counter to estimate the number of trees in each input image. We compare DENT with a variety of state-of-art methods, including one-stage and two-stage, anchor-based and anchor-free deep neural detectors, and different types of fully convolutional regressors for density estimation. The methods are evaluated on a new large dataset we built and an existing cross-site dataset. DENT achieves top accuracy on both datasets, significantly outperforming most of the other methods. We have released our new dataset, called Yosemite Tree Dataset, containing a 10 km2 rectangular study area with around 100k trees annotated, as a benchmark for public access.},
DOI = {10.3390/rs14030476}
}



@Article{app12031047,
AUTHOR = {Aslan, Muhammet Fatih and Durdu, Akif and Sabanci, Kadir and Ropelewska, Ewa and Gültekin, Seyfettin Sinan},
TITLE = {A Comprehensive Survey of the Recent Studies with UAV for Precision Agriculture in Open Fields and Greenhouses},
JOURNAL = {Applied Sciences},
VOLUME = {12},
YEAR = {2022},
NUMBER = {3},
ARTICLE-NUMBER = {1047},
URL = {https://www.mdpi.com/2076-3417/12/3/1047},
ISSN = {2076-3417},
ABSTRACT = {The increasing world population makes it necessary to fight challenges such as climate change and to realize production efficiently and quickly. However, the minimum cost, maximum income, environmental pollution protection and the ability to save water and energy are all factors that should be taken into account in this process. The use of information and communication technologies (ICTs) in agriculture to meet all of these criteria serves the purpose of precision agriculture. As unmanned aerial vehicles (UAVs) can easily obtain real-time data, they have a great potential to address and optimize solutions to the problems faced by agriculture. Despite some limitations, such as the battery, load, weather conditions, etc., UAVs will be used frequently in agriculture in the future because of the valuable data that they obtain and their efficient applications. According to the known literature, UAVs have been carrying out tasks such as spraying, monitoring, yield estimation, weed detection, etc. In recent years, articles related to agricultural UAVs have been presented in journals with high impact factors. Most precision agriculture applications with UAVs occur in outdoor environments where GPS access is available, which provides more reliable control of the UAV in both manual and autonomous flights. On the other hand, there are almost no UAV-based applications in greenhouses where all-season crop production is available. This paper emphasizes this deficiency and provides a comprehensive review of the use of UAVs for agricultural tasks and highlights the importance of simultaneous localization and mapping (SLAM) for a UAV solution in the greenhouse.},
DOI = {10.3390/app12031047}
}



@Article{rs14030477,
AUTHOR = {Carpenter, Stephen and Byfield, Val and Felgate, Stacey L. and Price, David M. and Andrade, Valdemar and Cobb, Eliceo and Strong, James and Lichtschlag, Anna and Brittain, Hannah and Barry, Christopher and Fitch, Alice and Young, Arlene and Sanders, Richard and Evans, Claire},
TITLE = {Using Unoccupied Aerial Vehicles (UAVs) to Map Seagrass Cover from Sentinel-2 Imagery},
JOURNAL = {Remote Sensing},
VOLUME = {14},
YEAR = {2022},
NUMBER = {3},
ARTICLE-NUMBER = {477},
URL = {https://www.mdpi.com/2072-4292/14/3/477},
ISSN = {2072-4292},
ABSTRACT = {Seagrass habitats are ecologically valuable and play an important role in sequestering and storing carbon. There is, thus, a need to estimate seagrass percentage cover in diverse environments in support of climate change mitigation, marine spatial planning and coastal zone management. In situ approaches are accurate but time-consuming, expensive and may not represent the larger spatial units collected by satellite imaging. Hence, there is a need for a consistent methodology that uses accurate point-based field surveys to deliver high-quality mapping of percentage seagrass cover at large spatial scales. Here, we develop a three-step approach that combines in situ (quadrats), aerial (unoccupied aerial vehicle&mdash;UAV) and satellite data to map percentage seagrass cover at Turneffe Atoll, Belize, the largest atoll in the northern hemisphere. First, the optical bands of four UAV images were used to calculate seagrass cover, in combination with in situ data. The seagrass cover calculated from the UAV was then used to develop training and validation datasets to estimate seagrass cover in Sentinel-2 pixels. Next, non-seagrass areas were identified in the Sentinel-2 data and removed by object-based classification, followed by a pixel-based regression to calculate seagrass percentage cover. Using this approach, percentage seagrass cover was mapped using UAVs (R2 = 0.91 between observed and mapped distributions) and using Sentinel-2 data (R2 = 0.73). This work provides the first openly available and explorable map of seagrass percentage cover across Turneffe Atoll, where we estimate approximately 242 km2 of seagrass above 10% cover is located. We estimate that this approach offers 30 times more data for training satellite data than traditional methods, therefore presenting a substantial reduction in cost-per-point for data. Furthermore, the increase in data helps deliver a high-quality seagrass cover map, suitable for resolving trends of deteriorating, stable or recovering seagrass environments at 10 m2 resolution to underpin evidence-based management and conservation of seagrass.},
DOI = {10.3390/rs14030477}
}



@Article{f13020153,
AUTHOR = {Krisanski, Sean and Taskhiri, Mohammad Sadegh and Montgomery, James and Turner, Paul},
TITLE = {Design and Testing of a Novel Unoccupied Aircraft System for the Collection of Forest Canopy Samples},
JOURNAL = {Forests},
VOLUME = {13},
YEAR = {2022},
NUMBER = {2},
ARTICLE-NUMBER = {153},
URL = {https://www.mdpi.com/1999-4907/13/2/153},
ISSN = {1999-4907},
ABSTRACT = {Unoccupied Aircraft Systems (UAS) are beginning to replace conventional forest plot mensuration through their use as low-cost and powerful remote sensing tools for monitoring growth, estimating biomass, evaluating carbon stocks and detecting weeds; however, physical samples remain mostly collected through time-consuming, expensive and potentially dangerous conventional techniques. Such conventional techniques include the use of arborists to climb the trees to retrieve samples, shooting branches with firearms from the ground, canopy cranes or the use of pole-mounted saws to access lower branches. UAS hold much potential to improve the safety, efficiency, and reduce the cost of acquiring canopy samples. In this work, we describe and demonstrate four iterations of 3D printed canopy sampling UAS. This work includes detailed explanations of designs and how each iteration informed the design decisions in the subsequent iteration. The fourth iteration of the aircraft was tested for the collection of 30 canopy samples from three tree species: eucalyptus pulchella, eucalyptus globulus and acacia dealbata trees. The collection times ranged from 1 min and 23 s, up to 3 min and 41 s for more distant and challenging to capture samples. A vision for the next iteration of this design is also provided. Future work may explore the integration of advanced remote sensing techniques with UAS-based canopy sampling to progress towards a fully-automated and holistic forest information capture system.},
DOI = {10.3390/f13020153}
}



@Article{oceans3010003,
AUTHOR = {Teague, Jonathan and Megson-Smith, David A. and Allen, Michael J. and Day, John C.C. and Scott, Thomas B.},
TITLE = {A Review of Current and New Optical Techniques for Coral Monitoring},
JOURNAL = {Oceans},
VOLUME = {3},
YEAR = {2022},
NUMBER = {1},
PAGES = {30--45},
URL = {https://www.mdpi.com/2673-1924/3/1/3},
ISSN = {2673-1924},
ABSTRACT = {Monitoring the health of coral reefs is essential to understanding the damaging impacts of anthropogenic climate change as such non-invasive methods to survey coral reefs are the most desirable. Optics-based surveys, ranging from simple photography to multispectral satellite imaging are well established. Herein, we review these techniques, focusing on their value for coral monitoring and health diagnosis. The techniques are broadly separated by the primary method in which data are collected: by divers and/or robots directly within the environment or by remote sensing where data are captured above the water&rsquo;s surface by planes, drones, or satellites. The review outlines a new emerging technology, low-cost hyperspectral imagery, which is capable of simultaneously producing hyperspectral and photogrammetric outputs, thereby providing integrated information of the reef structure and physiology in a single data capture.},
DOI = {10.3390/oceans3010003}
}



@Article{rs14030480,
AUTHOR = {Price, David M. and Felgate, Stacey L. and Huvenne, Veerle A. I. and Strong, James and Carpenter, Stephen and Barry, Chris and Lichtschlag, Anna and Sanders, Richard and Carrias, Abel and Young, Arlene and Andrade, Valdemar and Cobb, Eliceo and Le Bas, Tim and Brittain, Hannah and Evans, Claire},
TITLE = {Quantifying the Intra-Habitat Variation of Seagrass Beds with Unoccupied Aerial Vehicles (UAVs)},
JOURNAL = {Remote Sensing},
VOLUME = {14},
YEAR = {2022},
NUMBER = {3},
ARTICLE-NUMBER = {480},
URL = {https://www.mdpi.com/2072-4292/14/3/480},
ISSN = {2072-4292},
ABSTRACT = {Accurate knowledge of the spatial extent of seagrass habitats is essential for monitoring and management purposes given their ecological and economic significance. Extent data are typically presented in binary (presence/absence) or arbitrary, semi-quantitative density bands derived from low-resolution satellite imagery, which cannot resolve fine-scale features and intra-habitat variability. Recent advances in consumer-grade unoccupied aerial vehicles (UAVs) have advanced our ability to survey large areas at higher resolution and at lower cost. This has improved the accessibility of mapping technologies to developing coastal nations, where a large proportion of the world&rsquo;s seagrass habitats are found. Here, we present the application of UAV-gathered imagery to determine seagrass habitat extent and percent of canopy cover. Four contrasting sites were surveyed in the Turneffe Atoll Marine Reserve, Belize, and seagrass canopy cover was ground truthed from in situ quadrats. Orthomosaic images were created for each site from the UAV-gathered imagery. Three modelling techniques were tested to extrapolate the findings from quadrats to spatial information, producing binary (random forest) and canopy cover (random forest regression and beta regression) habitat maps. The most robust model (random forest regression) had an average absolute error of 6.8&ndash;11.9% (SE of 8.2&ndash;14), building upon previous attempts at mapping seagrass density from satellite imagery, which achieved errors between 15&ndash;20% approximately. The resulting maps exhibited great intra-habitat heterogeneity and different levels of patchiness, which were attributed to site energetics and, possibly, species composition. The extra information in the canopy cover maps provides greater detail and information for key management decisions and provides the basis for future spatial studies and monitoring programmes.},
DOI = {10.3390/rs14030480}
}



@Article{app12031061,
AUTHOR = {Xu, Biaoyi and Liang, Dong and Li, Ling and Quan, Rong and Zhang, Mingguang},
TITLE = {An Effectively Finite-Tailed Updating for Multiple Object Tracking in Crowd Scenes},
JOURNAL = {Applied Sciences},
VOLUME = {12},
YEAR = {2022},
NUMBER = {3},
ARTICLE-NUMBER = {1061},
URL = {https://www.mdpi.com/2076-3417/12/3/1061},
ISSN = {2076-3417},
ABSTRACT = {Multiple Object Tracking (MOT) focuses on tracking all the objects in a video. Most MOT solutions follow a tracking-by-detection or a joint detection tracking paradigm to generate the object trajectories by exploiting the correlations between the detected objects in consecutive frames. However, according to our observations, considering only the correlations between the objects in the current frame and the objects in the previous frame will lead to an exponential information decay over time, thus resulting in a misidentification of the object, especially in scenes with dense crowds and occlusions. To address this problem, we propose an effectively finite-tailed updating (FTU) strategy to generate the appearance template of the object in the current frame by exploiting its local temporal context in videos. To be specific, we model the appearance template for the object in the current frame on the appearance templates of the objects in multiple earlier frames and dynamically combine them to obtain a more effective representation. Extensive experiments have been conducted, and the experimental results show that our tracker outperforms the state-of-the-art methods on MOT Challenge Benchmark. We have achieved 73.7% and 73.0% IDF1, and 46.1% and 45.0% MT on the MOT16 and MOT17 datasets, which are 0.9% and 0.7% IDFI higher, and 1.4% and 1.8% MT higher than FairMOT repsectively.},
DOI = {10.3390/app12031061}
}



@Article{rs14030492,
AUTHOR = {Yang, Qichi and Wang, Lihui and Huang, Jinliang and Lu, Lijie and Li, Yang and Du, Yun and Ling, Feng},
TITLE = {Mapping Plant Diversity Based on Combined SENTINEL-1/2 Data&mdash;Opportunities for Subtropical Mountainous Forests},
JOURNAL = {Remote Sensing},
VOLUME = {14},
YEAR = {2022},
NUMBER = {3},
ARTICLE-NUMBER = {492},
URL = {https://www.mdpi.com/2072-4292/14/3/492},
ISSN = {2072-4292},
ABSTRACT = {Plant diversity is an important parameter in maintaining forest ecosystem services, functions and stability. Timely and accurate monitoring and evaluation of large-area wall-to-wall maps on plant diversity and its spatial heterogeneity are crucial for the conservation and management of forest resources. However, traditional botanical field surveys designed to estimate plant diversity are usually limited in their spatiotemporal resolutions. Using Sentinel-1 (S-1) and Sentinel-2 (S-2) data at high spatiotemporal scales, combined with and referenced to botanical field surveys, may be the best choice to provide accurate plant diversity distribution information over a large area. In this paper, we predicted and mapped plant diversity in a subtropical forest using 24 months of freely and openly available S-1 and S-2 images (10 m &times; 10 m) data over a large study area (15,290 km2). A total of 448 quadrats (10 m &times; 10 m) of forestry field surveys were captured in a subtropical evergreen-deciduous broad-leaved mixed forest to validate a machine learning algorithm. The objective was to link the fine Sentinel spectral and radar data to several ground-truthing plant diversity indices in the forests. The results showed that: (1) The Simpson and Shannon-Wiener diversity indices were the best predicted indices using random forest regression, with &#531;2 of around 0.65; (2) The use of S-1 radar data can enhance the accuracy of the predicted heterogeneity indices in the forests by approximately 0.2; (3) As for the mapping of Simpson and Shannon-Wiener, the overall accuracy was 67.4% and 64.2% respectively, while the texture diversity&rsquo;s overall accuracy was merely 56.8%; (4) From the evaluation and prediction map information, the Simpson, Shannon-Wiener and texture diversity values (and its confidence interval values) indicate spatial heterogeneity in pixel level. The large-area forest plant diversity indices maps add spatially explicit information to the ground-truthing data. Based on the results, we conclude that using the time-series of S-1 and S-2 radar and spectral characteristics, when coupled with limited ground-truthing data, can provide reasonable assessments of plant spatial heterogeneity and diversity across wide areas. It could also help promote forest ecosystem and resource conservation activities in the forestry sector.},
DOI = {10.3390/rs14030492}
}



@Article{telecom3010005,
AUTHOR = {Tsipi, Lefteris and Karavolos, Michail and Vouyioukas, Demosthenes},
TITLE = {An Unsupervised Machine Learning Approach for UAV-Aided Offloading of 5G Cellular Networks},
JOURNAL = {Telecom},
VOLUME = {3},
YEAR = {2022},
NUMBER = {1},
PAGES = {86--102},
URL = {https://www.mdpi.com/2673-4001/3/1/5},
ISSN = {2673-4001},
ABSTRACT = {Today&rsquo;s terrestrial cellular communications networks face difficulties in serving coexisting users and devices due to the enormous demands of mass connectivity. Further, natural disasters and unexpected events lead to an unpredictable amount of data traffic, thus causing congestion to the network. In such cases, the addition of on-demand network entities, such as fixed or aerial base stations, has been proposed as a viable solution for managing high data traffic and offloading the existing terrestrial infrastructure. This paper presents an unmanned aerial vehicles (UAVs) aided offloading strategy of the terrestrial network, utilizing an unsupervised machine learning method for the best placement of UAVs in sites with high data traffic. The proposed scheme forms clusters of users located in the affected area using the k-medoid algorithm. Followingly, based on the number of available UAVs, a cluster selection scheme is employed to select the available UAVs that will be deployed to achieve maximum offloading in the system. Comparisons with traditional offloading strategies integrating terrestrial picocells and other UAV-aided schemes show that significant offloading, throughput, spectral efficiency, and sum rate gains can be harvested through the proposed method under a varying number of UAVs.},
DOI = {10.3390/telecom3010005}
}



@Article{rs14030498,
AUTHOR = {Seydi, Seyd Teymoor and Amani, Meisam and Ghorbanian, Arsalan},
TITLE = {A Dual Attention Convolutional Neural Network for Crop Classification Using Time-Series Sentinel-2 Imagery},
JOURNAL = {Remote Sensing},
VOLUME = {14},
YEAR = {2022},
NUMBER = {3},
ARTICLE-NUMBER = {498},
URL = {https://www.mdpi.com/2072-4292/14/3/498},
ISSN = {2072-4292},
ABSTRACT = {Accurate and timely mapping of crop types and having reliable information about the cultivation pattern/area play a key role in various applications, including food security and sustainable agriculture management. Remote sensing (RS) has extensively been employed for crop type classification. However, accurate mapping of crop types and extents is still a challenge, especially using traditional machine learning methods. Therefore, in this study, a novel framework based on a deep convolutional neural network (CNN) and a dual attention module (DAM) and using Sentinel-2 time-series datasets was proposed to classify crops. A new DAM was implemented to extract informative deep features by taking advantage of both spectral and spatial characteristics of Sentinel-2 datasets. The spectral and spatial attention modules (AMs) were respectively applied to investigate the behavior of crops during the growing season and their neighborhood properties (e.g., textural characteristics and spatial relation to surrounding crops). The proposed network contained two streams: (1) convolution blocks for deep feature extraction and (2) several DAMs, which were employed after each convolution block. The first stream included three multi-scale residual convolution blocks, where the spectral attention blocks were mainly applied to extract deep spectral features. The second stream was built using four multi-scale convolution blocks with a spatial AM. In this study, over 200,000 samples from six different crop types (i.e., alfalfa, broad bean, wheat, barley, canola, and garden) and three non-crop classes (i.e., built-up, barren, and water) were collected to train and validate the proposed framework. The results demonstrated that the proposed method achieved high overall accuracy and a Kappa coefficient of 98.54% and 0.981, respectively. It also outperformed other state-of-the-art classification methods, including RF, XGBOOST, R-CNN, 2D-CNN, 3D-CNN, and CBAM, indicating its high potential to discriminate different crop types.},
DOI = {10.3390/rs14030498}
}



@Article{rs14030501,
AUTHOR = {Li, Huayu and Wan, Jianhua and Liu, Shanwei and Sheng, Hui and Xu, Mingming},
TITLE = {Wetland Vegetation Classification through Multi-Dimensional Feature Time Series Remote Sensing Images Using Mahalanobis Distance-Based Dynamic Time Warping},
JOURNAL = {Remote Sensing},
VOLUME = {14},
YEAR = {2022},
NUMBER = {3},
ARTICLE-NUMBER = {501},
URL = {https://www.mdpi.com/2072-4292/14/3/501},
ISSN = {2072-4292},
ABSTRACT = {Efficient methodologies for vegetation-type mapping are significant for wetland&rsquo;s management practices and monitoring. Nowadays, dynamic time warping (DTW) based on remote sensing time series has been successfully applied to vegetation classification. However, most of the previous related studies only focused on Normalized Difference Vegetation Index (NDVI) time series while ignoring multiple features in each period image. In order to further improve the accuracy of wetland vegetation classification, Mahalanobis Distance-based Dynamic Time Warping (MDDTW) using multi-dimensional feature time series was employed in this research. This method extends the traditional DTW algorithm based on single-dimensional features to multi-dimensional features and solves the problem of calculating similarity distance between multi-dimensional feature time series. Vegetation classification experiments were carried out in the Yellow River Delta (YRD). Compared with different classification methods, the results show that the K-Nearest Neighbors (KNN) algorithm based on MDDTW (KNN-MDDTW) has achieved better classification accuracy; the overall accuracy is more than 90%, and kappa is more than 0.9.},
DOI = {10.3390/rs14030501}
}



@Article{rs14030518,
AUTHOR = {Brewer, Kiara and Clulow, Alistair and Sibanda, Mbulisi and Gokool, Shaeden and Naiken, Vivek and Mabhaudhi, Tafadzwanashe},
TITLE = {Predicting the Chlorophyll Content of Maize over Phenotyping as a Proxy for Crop Health in Smallholder Farming Systems},
JOURNAL = {Remote Sensing},
VOLUME = {14},
YEAR = {2022},
NUMBER = {3},
ARTICLE-NUMBER = {518},
URL = {https://www.mdpi.com/2072-4292/14/3/518},
ISSN = {2072-4292},
ABSTRACT = {Smallholder farmers depend on healthy and productive crop yields to sustain their socio-economic status and ensure livelihood security. Advances in South African precision agriculture in the form of unmanned aerial vehicles (UAVs) provide spatially explicit near-real-time information that can be used to assess crop dynamics and inform smallholder farmers. The use of UAVs with remote-sensing techniques allows for the acquisition of high spatial resolution data at various spatio-temporal planes, which is particularly useful at the scale of fields and farms. Specifically, crop chlorophyll content is assessed as it is one of the best known and reliable indicators of crop health, due to its biophysical pigment and biochemical processes that indicate plant productivity. In this regard, the study evaluated the utility of multispectral UAV imagery using the random forest machine learning algorithm to estimate the chlorophyll content of maize through the various growth stages. The results showed that the near-infrared and red-edge wavelength bands and vegetation indices derived from these wavelengths were essential for estimating chlorophyll content during the phenotyping of maize. Furthermore, the random forest model optimally estimated the chlorophyll content of maize over the various phenological stages. Particularly, maize chlorophyll was best predicted during the early reproductive, late vegetative, and early vegetative growth stages to RMSE accuracies of 40.4 &micro;mol/m&minus;2, 39 &micro;mol/m&minus;2, and 61.6 &micro;mol/m&minus;2, respectively. The least accurate chlorophyll content results were predicted during the mid-reproductive and late reproductive growth stages to RMSE accuracies of 66.6 &micro;mol/m&minus;2 and 69.6 &micro;mol/m&minus;2, respectively, as a consequence of a hailstorm. A resultant chlorophyll variation map of the maize growth stages captured the spatial heterogeneity of chlorophyll within the maize field. Therefore, the study&rsquo;s findings demonstrate that the use of remotely sensed UAV imagery with a robust machine algorithm is a critical tool to support the decision-making and management in smallholder farms.},
DOI = {10.3390/rs14030518}
}



@Article{rs14030522,
AUTHOR = {Peng, Baochai and Ren, Dong and Zheng, Cheng and Lu, Anxiang},
TITLE = {TRDet: Two-Stage Rotated Detection of Rural Buildings in Remote Sensing Images},
JOURNAL = {Remote Sensing},
VOLUME = {14},
YEAR = {2022},
NUMBER = {3},
ARTICLE-NUMBER = {522},
URL = {https://www.mdpi.com/2072-4292/14/3/522},
ISSN = {2072-4292},
ABSTRACT = {Fast and accurate acquisition of the outline of rural buildings on remote sensing images is an efficient method to monitor illegal rural buildings. The traditional object detection method produces useless background information when detecting rural buildings; the semantic segmentation method cannot accurately segment the contours between buildings; the instance segmentation method cannot obtain regular building contours. The rotated object detection methods can effectively solve the problem that the traditional artificial intelligence method cannot accurately extract the outline of buildings. However, the rotated object detection methods are easy to lose location information of small objects in advanced feature maps and are sensitive to noise. To resolve these problems, this paper proposes a two-stage rotated object detection network for rural buildings (TRDet) by using a deep feature fusion network (DFF-Net) and a pixel attention module (PAM). Specifically, TRDet first fuses low-level location and high-level semantic information through the DFF-Net and then reduces the interference of noise information to the network through the PAM. The experimental results show that the mean average precession (mAP), precision, recall rate, and F1 score of the proposed TRDet are 83.57%, 91.11%, 86.5%, and 88.74%, respectively, which outperform the R2CNN model by 15%, 15.54%, 4.01%, and 9.87%. The results demonstrate that the TRDet can achieve better detection in small rural buildings and dense rural buildings.},
DOI = {10.3390/rs14030522}
}



@Article{aerospace9020056,
AUTHOR = {Perk, Baris Eren and Inalhan, Gokhan},
TITLE = {Safe Motion Planning and Learning for Unmanned Aerial Systems},
JOURNAL = {Aerospace},
VOLUME = {9},
YEAR = {2022},
NUMBER = {2},
ARTICLE-NUMBER = {56},
URL = {https://www.mdpi.com/2226-4310/9/2/56},
ISSN = {2226-4310},
ABSTRACT = {To control unmanned aerial systems, we rarely have a perfect system model. Safe and aggressive planning is also challenging for nonlinear and under-actuated systems. Expert pilots, however, demonstrate maneuvers that are deemed at the edge of plane envelope. Inspired by biological systems, in this paper, we introduce a framework that leverages methods in the field of control theory and reinforcement learning to generate feasible, possibly aggressive, trajectories. For the control policies, Dynamic Movement Primitives (DMPs) imitate pilot-induced primitives, and DMPs are combined in parallel to generate trajectories to reach original or different goal points. The stability properties of DMPs and their overall systems are analyzed using contraction theory. For reinforcement learning, Policy Improvement with Path Integrals (PI2) was used for the maneuvers. The results in this paper show that PI2 updated policies are a feasible and parallel combination of different updated primitives transfer the learning in the contraction regions. Our proposed methodology can be used to imitate, reshape, and improve feasible, possibly aggressive, maneuvers. In addition, we can exploit trajectories generated by optimization methods, such as Model Predictive Control (MPC), and a library of maneuvers can be instantly generated. For application, 3-DOF (degrees of freedom) Helicopter and 2D-UAV (unmanned aerial vehicle) models are utilized to demonstrate the main results.},
DOI = {10.3390/aerospace9020056}
}



@Article{s22030845,
AUTHOR = {Dai, Huatong and Chen, Pengzhan and Yang, Hui},
TITLE = {Metalearning-Based Fault-Tolerant Control for Skid Steering Vehicles under Actuator Fault Conditions},
JOURNAL = {Sensors},
VOLUME = {22},
YEAR = {2022},
NUMBER = {3},
ARTICLE-NUMBER = {845},
URL = {https://www.mdpi.com/1424-8220/22/3/845},
ISSN = {1424-8220},
ABSTRACT = {Using reinforcement learning (RL) for torque distribution of skid steering vehicles has attracted increasing attention recently. Various RL-based torque distribution methods have been proposed to deal with this classical vehicle control problem, achieving a better performance than traditional control methods. However, most RL-based methods focus only on improving the performance of skid steering vehicles, while actuator faults that may lead to unsafe conditions or catastrophic events are frequently omitted in existing control schemes. This study proposes a meta-RL-based fault-tolerant control (FTC) method to improve the tracking performance of vehicles in the case of actuator faults. Based on meta deep deterministic policy gradient (meta-DDPG), the proposed FTC method has a representative gradient-based metalearning algorithm workflow, which includes an offline stage and an online stage. In the offline stage, an experience replay buffer with various actuator faults is constructed to provide data for training the metatraining model; then, the metatrained model is used to develop an online meta-RL update method to quickly adapt its control policy to actuator fault conditions. Simulations of four scenarios demonstrate that the proposed FTC method can achieve a high performance and adapt to actuator fault conditions stably.},
DOI = {10.3390/s22030845}
}




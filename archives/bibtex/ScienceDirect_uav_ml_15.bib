@article{SUBEESH2021278,
title = {Automation and digitization of agriculture using artificial intelligence and internet of things},
journal = {Artificial Intelligence in Agriculture},
volume = {5},
pages = {278-291},
year = {2021},
issn = {2589-7217},
doi = {https://doi.org/10.1016/j.aiia.2021.11.004},
url = {https://www.sciencedirect.com/science/article/pii/S2589721721000350},
author = {A. Subeesh and C.R. Mehta},
keywords = {Agriculture automation, Artificial intelligence, Deep learning, Internet of things, Smart farm machinery},
abstract = {The growing population and effect of climate change have put a huge responsibility on the agriculture sector to increase food-grain production and productivity. In most of the countries where the expansion of cropland is merely impossible, agriculture automation has become the only option and is the need of the hour. Internet of things and Artificial intelligence have already started capitalizing across all the industries including agriculture. Advancement in these digital technologies has made revolutionary changes in agriculture by providing smart systems that can monitor, control, and visualize various farm operations in real-time and with comparable intelligence of human experts. The potential applications of IoT and AI in the development of smart farm machinery, irrigation systems, weed and pest control, fertilizer application, greenhouse cultivation, storage structures, drones for plant protection, crop health monitoring, etc. are discussed in the paper. The main objective of the paper is to provide an overview of recent research in the area of digital technology-driven agriculture and identification of the most prominent applications in the field of agriculture engineering using artificial intelligence and internet of things. The research work done in the areas during the last 10 years has been reviewed from the scientific databases including PubMed, Web of Science, and Scopus. It has been observed that the digitization of agriculture using AI and IoT has matured from their nascent conceptual stage and reached the execution phase. The technical details of artificial intelligence, IoT, and challenges related to the adoption of these digital technologies are also discussed. This will help in understanding how digital technologies can be integrated into agriculture practices and pave the way for the implementation of AI and IoT-based solutions in the farms.}
}
@article{KARIM2020177,
title = {Modeling and Simulation of a Robotic Bridge Inspection System},
journal = {Procedia Computer Science},
volume = {168},
pages = {177-185},
year = {2020},
note = {“Complex Adaptive Systems”Malvern, PennsylvaniaNovember 13-15, 2019},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2020.02.276},
url = {https://www.sciencedirect.com/science/article/pii/S1877050920304154},
author = {Muhammad Monjurul Karim and Cihan H. Dagli and Ruwen Qin},
keywords = {Simulation modeling, bridge inspection, UAV, cellular automata, deep learning, discrete-event simulation, AnyLogic},
abstract = {Inspection and preservation of the aging bridges to extend their service life has been recognized as one of the important tasks of the State Departments of Transportation. Yet manual inspection procedure is not efficient to determine the safety status of the bridges in order to facilitate the implementation of appropriate maintenance. In this paper, a complex model involving a remotely controlled robotic platform is proposed to inspect the safety status of the bridges which will eliminate labor-intensive inspection. Mobile cameras from unmanned airborne vehicles (UAV) are used to collect bridge inspection data in order to record the periodic changes of bridge components. All the UAVs are controlled via a control station and continuously feed image data to a deep learning-based detection algorithm to analyze the data to detect critical structural components. A cellular automata-based pattern recognition algorithm is used to find the pattern of structural damage. A simulation model is developed to validate the proposed method by knowing the frequency and time required for each task involved in bridge inspection and maintenance. The effectiveness of the model is demonstrated by simulating the bridge inspection and maintenance with the proposed model for five years in AnyLogic. The simulated result shows around 80% of man-hour can be saved with the proposed approach.}
}
@article{WANG2021103786,
title = {Semi-supervised semantic segmentation network for surface crack detection},
journal = {Automation in Construction},
volume = {128},
pages = {103786},
year = {2021},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2021.103786},
url = {https://www.sciencedirect.com/science/article/pii/S0926580521002375},
author = {Wenjun Wang and Chao Su},
keywords = {Deep learning, Convolutional neural network, Semi-supervised network, Crack detection, Pixel-wise segmentation},
abstract = {The detection of surface crack is essential to ensure the safety and the serviceability of civil infrastructure. The automatic method is highly efficient and the test results are objective, which makes it gradually replace conventical manual inspection. Recently, semantic segmentation algorithms based on deep learning have shown excellent performance in crack detection tasks. However, the commonly used fully supervised segmentation method requires manual annotation of large amounts of data, which is time-consuming. In order to solve this problem, we propose a semi-supervised semantic segmentation network for crack detection. The proposed method consists of student model and teacher model. The two models have the same network structure and use the EfficientUNet to extract multi-scale crack feature information, reducing the loss of image information. The student model updates weights through the gradient descent of loss function, and the teacher model uses the exponential moving average weights of the student model. During training, the robustness of the model is improved by adding noise to the input data. When using only 60% of the annotated data, our method achieves an F1 score of 0.6540 on the concrete crack dataset and 0.8321 on the Crack500 dataset. The results show that our method can greatly reduce the workload of annotation while maintaining high accuracy.}
}
@article{SINGH2016396,
title = {Landmarks based path planning for UAVs in GPS-denied areas∗∗This work is partially funded by FCT grant SFRH/BPD/103962/2014.},
journal = {IFAC-PapersOnLine},
volume = {49},
number = {1},
pages = {396-400},
year = {2016},
note = {4th IFAC Conference on Advances in Control and Optimization of Dynamical Systems ACODS 2016},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2016.03.086},
url = {https://www.sciencedirect.com/science/article/pii/S2405896316300866},
author = {Shreya Singh and P.B. Sujit},
keywords = {Path planning, UAV, GPS-denied areas, navigation},
abstract = {In this paper, we propose a UAV path planner travelling from a given source to goal location in GPS-denied areas. The environment consists of a set of cellular towers which are treated as landmarks having finite communication range. The vehicle has to perform dead reckoning in regions where landmarks are not available. Therefore, the objective is to determine a time optimal path taking the presence of landmarks into account while ensuring the covariance due to dead-reckoning is within a given bound. Solving the stochastic optimal control problem to determine a path in the continuous domain is very difficult and hence we discrete the path as a set of way points and optimize the location of these way points to obtain a time optimal path satisfying the covariance bounds. We use a particle swarm optimization technique coupled with a rabbit-carrot based path following technique to determine a near-optimal path. Numerical results are presented to show that our approach produces feasible paths that are near-optimal and satisfy the covariance bounds.}
}
@article{ZHANG2022470,
title = {LISU: Low-light indoor scene understanding with joint learning of reflectance restoration},
journal = {ISPRS Journal of Photogrammetry and Remote Sensing},
volume = {183},
pages = {470-481},
year = {2022},
issn = {0924-2716},
doi = {https://doi.org/10.1016/j.isprsjprs.2021.11.010},
url = {https://www.sciencedirect.com/science/article/pii/S0924271621003087},
author = {Ning Zhang and Francesco Nex and Norman Kerle and George Vosselman},
keywords = {Semantic segmentation, Deep learning, Intrinsic image decomposition, Low-light},
abstract = {Semantic segmentation using convolutional neural networks (CNNs) achieves higher accuracy than traditional methods, but it fails to yield satisfactory results under illumination variants when the training set is limited. In this paper we present a new data set containing both real and rendered images and a novel cascade network to study semantic segmentation in low-light indoor environments. Specifically, the network decomposes a low-light image into illumination and reflectance components, and then a multi-tasking learning scheme is built. One branch learns to reduce noise and restore information on the reflectance (reflectance restoration branch). Another branch learns to segment the reflectance map (semantic segmentation branch). The CNN features from two tasks are concatenated together so as to improve the segmentation accuracy by embedding the illumination-invariant features. We compare our approach with other CNN-based segmentation frameworks, including the state-of-the-art DeepLab v3+, on the proposed real data set, and our approach achieves the highest mIoU (47.6%). The experimental results also show that the semantic information supports the restoration of a sharper reflectance map, thus further improving the segmentation. Besides, we pre-train a model with the proposed large-scale rendered images and then fine-tune it on the real images. The pre-training results in an improvement of mIoU by 7.2%. Our models and data set are publicly available for research. This research is part of the EU project INGENIOUS11https://ingenious-first-responders.eu/. Our data sets and models are available on our website22https://github.com/noahzn/LISU.}
}
@article{SHIRZADEH201734,
title = {Vision-based control of a quadrotor utilizing artificial neural networks for tracking of moving targets},
journal = {Engineering Applications of Artificial Intelligence},
volume = {58},
pages = {34-48},
year = {2017},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2016.10.016},
url = {https://www.sciencedirect.com/science/article/pii/S0952197616301993},
author = {Masoud Shirzadeh and Hamed Jabbari Asl and Abdollah Amirkhani and Ali Akbar Jalali},
keywords = {Image based visual servoing, Quadrotor, Moving target, Perspective image features, RBF},
abstract = {This paper investigates the application of an image based visual servoing (IBVS) mechanism for controlling the translational and rotational movements of a quadrotor helicopter; via this scheme, the helicopter can track a moving target by means of a camera installed underneath. The image features chosen for this purpose are the perspective image features. A direct adaptive neural controller was designed to control transitional motion. The controller makes use of neural network controller radial basis function (RBF) to deal with the image dynamic uncertainties. These uncertainties relate to the depth of visual information and the movement of the considered target. Moreover, a sliding mode controller designed by using the image features has been presented for controlling the rotational movement of the helicopter. Also, due to the lack of accurate image velocity and the Euler angles, appropriate observers have been designed and used. The designed scheme needs no geometric information from the object followed by the quadrotor; therefore, this method can be employed in unknown environments. The simulation results for ideal and non-ideal conditions indicate that, in spite of the problems such as the uncertainty of the image depth and the mobility of the target, both in the rotational and translational motions, the helicopter has been able to reach the desired altitude and to properly track the moving target.}
}
@article{YANG2021,
title = {Federated Learning for 6G: Applications, Challenges, and Opportunities},
journal = {Engineering},
year = {2021},
issn = {2095-8099},
doi = {https://doi.org/10.1016/j.eng.2021.12.002},
url = {https://www.sciencedirect.com/science/article/pii/S2095809921005245},
author = {Zhaohui Yang and Mingzhe Chen and Kai-Kit Wong and H. Vincent Poor and Shuguang Cui},
keywords = {Federated learning, 6G, Reconfigurable intelligent surface, Semantic communication, Sensing, communication and computing},
abstract = {Standard machine-learning approaches involve the centralization of training data in a data center, where centralized machine-learning algorithms can be applied for data analysis and inference. However, due to privacy restrictions and limited communication resources in wireless networks, it is often undesirable or impractical for the devices to transmit data to parameter sever. One approach to mitigate these problems is federated learning (FL), which enables the devices to train a common machine learning model without data sharing and transmission. This paper provides a comprehensive overview of FL applications for envisioned sixth generation (6G) wireless networks. In particular, the essential requirements for applying FL to wireless communications are first described. Then potential FL applications in wireless communications are detailed. The main problems and challenges associated with such applications are discussed. Finally, a comprehensive FL implementation for wireless communications is described.}
}
@article{LECHNER2020405,
title = {Applications in Remote Sensing to Forest Ecology and Management},
journal = {One Earth},
volume = {2},
number = {5},
pages = {405-412},
year = {2020},
issn = {2590-3322},
doi = {https://doi.org/10.1016/j.oneear.2020.05.001},
url = {https://www.sciencedirect.com/science/article/pii/S2590332220302062},
author = {Alex M. Lechner and Giles M. Foody and Doreen S. Boyd},
abstract = {Remote sensing provides valuable insights into pressing environmental challenges and is a critical tool for driving solutions. In this Primer, we briefly introduce the important role of remote sensing in forest ecology and management, which includes applications as diverse as mapping the distribution of forest ecosystems and characterizing the three-dimensional structure of forests. We describe six key reasons why remote sensing has become an important data source and introduce the different types of sensors (e.g., multispectral and synthetic aperture radar) and platforms (e.g., unmanned aerial vehicles and satellites) that have been used for mapping a diversity of forest variables. The rapid advancement in remote-sensing technology, techniques, and platforms is likely to result in a greater democratization of remote-sensing data to support forest management and conservation in parts of the world where environmental issues are the most urgent.}
}
@article{CALDERS2020112102,
title = {Terrestrial laser scanning in forest ecology: Expanding the horizon},
journal = {Remote Sensing of Environment},
volume = {251},
pages = {112102},
year = {2020},
issn = {0034-4257},
doi = {https://doi.org/10.1016/j.rse.2020.112102},
url = {https://www.sciencedirect.com/science/article/pii/S0034425720304752},
author = {Kim Calders and Jennifer Adams and John Armston and Harm Bartholomeus and Sebastien Bauwens and Lisa Patrick Bentley and Jerome Chave and F. Mark Danson and Miro Demol and Mathias Disney and Rachel Gaulton and Sruthi M. {Krishna Moorthy} and Shaun R. Levick and Ninni Saarinen and Crystal Schaaf and Atticus Stovall and Louise Terryn and Phil Wilkes and Hans Verbeeck},
keywords = {Terrestrial laser scanning, Ground-based LiDAR, Forest ecology, Forest plot measurement, Tree structure, Remote sensing},
abstract = {Terrestrial laser scanning (TLS) was introduced for basic forest measurements, such as tree height and diameter, in the early 2000s. Recent advances in sensor and algorithm development have allowed us to assess in situ 3D forest structure explicitly and revolutionised the way we monitor and quantify ecosystem structure and function. Here, we provide an interdisciplinary focus to explore current developments in TLS to measure and monitor forest structure. We argue that TLS data will play a critical role in understanding fundamental ecological questions about tree size and shape, allometric scaling, metabolic function and plasticity of form. Furthermore, these new developments enable new applications such as radiative transfer modelling with realistic virtual forests, monitoring of urban forests and larger scale ecosystem monitoring through long-range scanning. Finally, we discuss upscaling of TLS data through data fusion with unmanned aerial vehicles, airborne and spaceborne data, as well as the essential role of TLS in validation of spaceborne missions that monitor ecosystem structure.}
}
@article{MUKHERJEE2021107438,
title = {QoS-aware 6G-enabled ultra low latency edge-assisted Internet of Drone Things for real-time stride analysis},
journal = {Computers & Electrical Engineering},
volume = {95},
pages = {107438},
year = {2021},
issn = {0045-7906},
doi = {https://doi.org/10.1016/j.compeleceng.2021.107438},
url = {https://www.sciencedirect.com/science/article/pii/S0045790621003980},
author = {Amartya Mukherjee and Prateeti Mukherjee and Debashis De and Nilanjan Dey},
keywords = {Internet of Drone Things, Gait, Randomized search, Software Defined Networks, 6G, Time-series analysis},
abstract = {Internet of Things (IoT) concepts constitute a predominant area of research in e-healthcare applications, owing to the plethora of opportunities in medical diagnosis. In this work, a ubiquitous computing and communication architecture is proposed through the amalgamation of Internet of Healthcare and Internet of Drone things by leveraging a 5G/6G communication framework. Gait information is aggregated via a smart shoe and the processing is carried out on a set of edge-enabled Unmanned Aerial Vehicles (UAVs). To transfer the data within the edge and cloud layers, a Software Defined Network (SDN) is modeled. Further, a classifier is designed to analyze the records and make predictions on possible neurological disorders at the edge level. Experimental results suggest a 98% classification accuracy for abnormal gait diagnosis at 20% CPU utilization. The findings further reveal a latency of 335 ms. at QoS 2, and 50 msg/s bandwidth utilization with a Connected Client Ratio and SDN Coverage Ratio of 0.99 and 0.95, respectively.}
}
@article{MARTIN2018121,
title = {CANDYMAN: Classifying Android malware families by modelling dynamic traces with Markov chains},
journal = {Engineering Applications of Artificial Intelligence},
volume = {74},
pages = {121-133},
year = {2018},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2018.06.006},
url = {https://www.sciencedirect.com/science/article/pii/S0952197618301374},
author = {Alejandro Martín and Víctor Rodríguez-Fernández and David Camacho},
keywords = {Android malware, Dynamic analysis, Classification, Deep Learning, Markov chains},
abstract = {Malware writers are usually focused on those platforms which are most used among common users, with the aim of attacking as many devices as possible. Due to this reason, Android has been heavily attacked for years. Efforts dedicated to combat Android malware are mainly concentrated on detection, in order to prevent malicious software to be installed in a target device. However, it is equally important to put effort into an automatic classification of the type, or family, of a malware sample, in order to establish which actions are necessary to mitigate the damage caused. In this paper, we present CANDYMAN, a tool that classifies Android malware families by combining dynamic analysis and Markov chains. A dynamic analysis process allows to extract representative information of a malware sample, in form of a sequence of states, while a Markov chain allows to model the transition probabilities between the states of the sequence, which will be used as features in the classification process. The space of features built is used to train classical Machine Learning, including methods for imbalanced learning, and Deep Learning algorithms, over a dataset of malware samples from different families, in order to evaluate the proposed method. Using a collection of 5,560 malware samples grouped into 179 different families (extracted from the Drebin dataset), and once made a selection based on a minimum number of relevant and valid samples, a final set of 4,442 samples grouped into 24 different malware families was used. The experimental results indicate a precision performance of 81.8% over this dataset.}
}
@article{ALGHAWLI2022549,
title = {Complex methods detect anomalies in real time based on time series analysis},
journal = {Alexandria Engineering Journal},
volume = {61},
number = {1},
pages = {549-561},
year = {2022},
issn = {1110-0168},
doi = {https://doi.org/10.1016/j.aej.2021.06.033},
url = {https://www.sciencedirect.com/science/article/pii/S1110016821003951},
author = {Abed Saif Alghawli},
keywords = {Anomaly detection, Abnormal traffic, Machine learning, Signature analysis, Entropy analysis, Multifractal analysis, Recurrence analysis},
abstract = {Real time anomaly detection is important to performance and efficiency in many areas. This paper offers a complex method for detecting abnormal telecommunication traffic. The proposed method includes components based on entropy analysis, signature analysis and machine-learning detection of anomalies using fractal and recurrence analysis. Datasets containing realizations of normal traffic and realizations of attacks of different types were used as input data. Traffic containing the attack is considered to be abnormal. The multifractal and recurrence methods are briefly described. The results of multifractal and recurrence analysis of data-set traffic showed significant differences between normal and attacked realizations. Based on the obtained results, machine-learning algorithms are proposed. The classifiers random forest and neural network were used and showed good classification accuracy. The methods signature and entropy analysis are briefly described, and the results of their application showed a high degree of anomaly detection. The complex anomaly detection method combines entropy analysis, signature analysis, and machine-learning using the multifractal and recurrence analysis. The proposed complex method is tested on virtual network and is compared pervious methods. Simulation results showed that the proposed complex method has the highest percentage of detected attacks, the lowest percentage of undetected attacks and lost data.}
}
@article{LEE2012194,
title = {Predictive Control for Soaring of Unpowered Autonomous UAVs},
journal = {IFAC Proceedings Volumes},
volume = {45},
number = {17},
pages = {194-199},
year = {2012},
note = {4th IFAC Conference on Nonlinear Model Predictive Control},
issn = {1474-6670},
doi = {https://doi.org/10.3182/20120823-5-NL-3013.00021},
url = {https://www.sciencedirect.com/science/article/pii/S1474667016314495},
author = {Darren Lee and Stefano Longo and Eric C. Kerrigan},
abstract = {We design an autonomous soaring controller for an unpowered UAV in a nonlinear MPC framework. The UAV is controlled with the aim of extracting the maximum amount of potential/kinetic energy from the environment's updrafts. We focus on conceptual feasibility at this stage and make the realistic assumption that the UAV obtains updraft information only along the flight trajectory. The surrounding updraft distribution is then recursively estimated (online) by combining the measurements from the optimal trajectory with a heuristic search, if necessary. A variation of the standard grid search is used such that the grid spacing is altered depending on the updraft information along the UAV's flight path. Results from both standard and adaptive grid search approaches are presented. In abstract terms, this work can be viewed as finding optimal paths in uncertain vector fields.}
}
@article{ZHANG201944,
title = {Adaptive neural networks-based visual servoing control for manipulator with visibility constraint and dead-zone input},
journal = {Neurocomputing},
volume = {332},
pages = {44-55},
year = {2019},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2018.11.058},
url = {https://www.sciencedirect.com/science/article/pii/S0925231218314024},
author = {Yu Zhang and Changchun Hua and Yafeng Li and Xinping Guan},
keywords = {Adaptive control, Visual servoing, Barrier Lyapunov function, Neural networks, Dead-zone input, Visibility constraints},
abstract = {This paper proposed an online image-based visual servoing (IBVS) controller for manipulator systems with dead-zone input. The adaptive neural networks (NNs) are used to approximate the unknown nonlinear dynamics. The Barrier Lyapunov Function (BLF) is constructed to overcome the visibility constraint problem, in which both the constant symmetric barriers and time-varying asymmetric barriers are considered. With the proposed control method, it is proved that all the signals in the closed-loop system are semi-globally uniformly bounded and the image error is remained in a bounded compact set. Finally, simulation examples are given to illustrate the effectiveness of the proposed control method.}
}
@article{REJEB2021100434,
title = {Humanitarian Drones: A Review and Research Agenda},
journal = {Internet of Things},
volume = {16},
pages = {100434},
year = {2021},
issn = {2542-6605},
doi = {https://doi.org/10.1016/j.iot.2021.100434},
url = {https://www.sciencedirect.com/science/article/pii/S2542660521000780},
author = {Abderahman Rejeb and Karim Rejeb and Steve Simske and Horst Treiblmaier},
keywords = {drones, unmanned aerial vehicles, unmanned aerial system, humanitarian logistics, literature review, research agenda},
abstract = {This study investigates the capabilities, performance outcomes, and barriers of drones applied to humanitarian logistics (HL). A systematic literature review was conducted to synthesize prior research on drones and cumulatively identify current knowledge gaps which require further investigation. In order to identify the relevant literature on the topic, a rigorous research protocol was applied for the retrieval and selection processes. In total, 142 publications fulfilled the selection criteria and were thoroughly analyzed. The findings of this review paper summarize the capabilities, barriers and performance outcomes of humanitarian drones applied to logistics operations, management, and governance in a comprehensive framework. More specifically, three important capabilities (i.e., transportation and delivery; surveying and monitoring; communication and integration), three performance outcomes (i.e., flexibility and responsiveness; cost reduction; sustainability) and adoption barriers in three areas (i.e., technology; organization; environment) were identified. Based on these findings, future research directions are derived for the capabilities of humanitarian drones, their performance outcomes, and their respective barriers. This study analyzes potential applications of drones in the humanitarian field and presents a comprehensive agenda that structures and guides further research on the topic.}
}
@article{ZHU2021131,
title = {Multi-sensing paradigm based urban air quality monitoring and hazardous gas source analyzing: a review},
journal = {Journal of Safety Science and Resilience},
volume = {2},
number = {3},
pages = {131-145},
year = {2021},
issn = {2666-4496},
doi = {https://doi.org/10.1016/j.jnlssr.2021.08.004},
url = {https://www.sciencedirect.com/science/article/pii/S2666449621000323},
author = {Zhengqiu Zhu and Bin Chen and Yong Zhao and Yatai Ji},
keywords = {Urban air quality monitoring and source analyzing system, MAsmed framework, Wireless sensor networks, Mobile crowdsensing, Air quality management},
abstract = {Effectively monitoring urban air quality, and analyzing the source terms of the main atmospheric pollutants is important for public authorities to take air quality management actions. Previous works, such as long-term observations by monitoring stations, cannot provide customized data services and in-time emergency response under urgent situations (gas leakage incidents). Therefore, we first review the up-to-date approaches (often machine learning and optimization methods) with respect to urban air quality monitoring and hazardous gas source analysis. To bridge the gap between present solutions and practical requirements, we design a conceptual framework, namely MAsmed (Multi-Agents for sensing, monitoring, estimating and determining), to provide fine-grained concentration maps, customized data services, and on-demand emergency management. In this framework, we leverage the hybrid design of wireless sensor networks (WSNs) and mobile crowdsensing (MCS) to sense urban air quality and relevant data (e.g. traffic data, meteorological data, etc.); Using the sensed data, we can create a fine-grained air quality map for the authorities and relevant stakeholders, and provide on-demand source term estimation and source searching methods to estimate, seek, and determine the sources, thereby aiding decision-makers in emergency response (e.g. for evacuation). In this paper, we also identify several potential opportunities for future research.}
}
@article{SUI2022195,
title = {Study on the resolution of multi-aircraft flight conflicts based on an IDQN},
journal = {Chinese Journal of Aeronautics},
volume = {35},
number = {2},
pages = {195-213},
year = {2022},
issn = {1000-9361},
doi = {https://doi.org/10.1016/j.cja.2021.03.015},
url = {https://www.sciencedirect.com/science/article/pii/S1000936121001060},
author = {Dong SUI and Weiping XU and Kai ZHANG},
keywords = {Air traffic control, Conflict resolution, Multi-agent system, Multi-aircraft flight conflict, Reinforcement learning},
abstract = {With the rapid growth of flight flow, the workload of controllers is increasing daily, and handling flight conflicts is the main workload. Therefore, it is necessary to provide more efficient conflict resolution decision-making support for controllers. Due to the limitations of existing methods, they have not been widely used. In this paper, a Deep Reinforcement Learning (DRL) algorithm is proposed to resolve multi-aircraft flight conflict with high solving efficiency. First, the characteristics of multi-aircraft flight conflict problem are analyzed and the problem is modeled based on Markov decision process. Thus, the Independent Deep Q Network (IDQN) algorithm is used to solve the model. Simultaneously, a ‘downward-compatible’ framework that supports dynamic expansion of the number of conflicting aircraft is designed. The model ultimately shows convergence through adequate training. Finally, the test conflict scenarios and indicators were used to verify the validity. In 700 scenarios, 85.71% of conflicts were successfully resolved, and 71.51% of aircraft can reach destinations within 150 s around original arrival times. By contrast, conflict resolution algorithm based on DRL has great advantages in solution speed. The method proposed offers the possibility of decision-making support for controllers and reduce workload of controllers in future high-density airspace environment.}
}
@article{WANGJIAN2019157,
title = {Optimal input design for multi UAVs formation anomaly detection},
journal = {ISA Transactions},
volume = {91},
pages = {157-165},
year = {2019},
issn = {0019-0578},
doi = {https://doi.org/10.1016/j.isatra.2019.01.027},
url = {https://www.sciencedirect.com/science/article/pii/S0019057819300394},
author = {Hong Wang-jian},
keywords = {Multi UAVs formation, Anomaly detection, Optimal input design, Dynamic programming},
abstract = {As the input signal must be informative enough, so that the resulting dataset is enough informative to excite the identification experiment for multi UAVs formation anomaly detection. Based on our previous work on multi UAVs formation anomaly detection, the optimal input signals are designed for two identification strategies, i.e. least squares estimation and improved sparse estimation. Using the variance of the asymptotic distribution corresponding to the unknown parameters, the common trace operation is chosen to construct one numerical optimization problem, whose solution is corresponded to the optimal power spectral. After giving the detailed minimization process, we see that the power spectral corresponding to the optimal input signal is a constant. In addition, for the sake of completeness, one dynamic programming technique in multi UAVs formation anomaly detection is added to complete our early research. Finally, one numerical example illustrates the effectiveness of our proposed theories.}
}
@article{MONICASUBASHINI20143965,
title = {Pulse coupled neural networks and its applications},
journal = {Expert Systems with Applications},
volume = {41},
number = {8},
pages = {3965-3974},
year = {2014},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2013.12.027},
url = {https://www.sciencedirect.com/science/article/pii/S0957417413010026},
author = {M. {Monica Subashini} and Sarat Kumar Sahoo},
keywords = {PCNN model, Modifications, Applications in image processing, Miscellaneous applications},
abstract = {This paper surveys the extensive usage of pulse coupled neural networks. The visual cortex system of mammalians was the backbone for the development of pulse coupled neural network. PCNN (Pulse Coupled Neural Networks) is unique from other techniques due to its synchronous pulsed output, adjustable threshold and controllable parameters. is Hence the uniqueness of this network utilized in the fields of image processing. The basic model of PCNN and the consecutive changes implemented, to strengthen the pulse coupled neural network are discussed initially. Then the applications of PCNN are broadly discussed. The other miscellaneous applications utilizing pulse coupled neural networks are thrown light in the last section.}
}
@article{ABDELLATIF2022406,
title = {Communication-efficient hierarchical federated learning for IoT heterogeneous systems with imbalanced data},
journal = {Future Generation Computer Systems},
volume = {128},
pages = {406-419},
year = {2022},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2021.10.016},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X2100412X},
author = {Alaa Awad Abdellatif and Naram Mhaisen and Amr Mohamed and Aiman Erbad and Mohsen Guizani and Zaher Dawy and Wassim Nasreddine},
keywords = {Distributed deep learning, Edge computing, Non-IID data, Internet of Things (IoT), Intelligent health systems},
abstract = {Federated Learning (FL) is a distributed learning methodology that allows multiple nodes to cooperatively train a deep learning model, without the need to share their local data. It is a promising solution for telemonitoring systems that demand intensive data collection, for detection, classification, and prediction of future events, from different locations while maintaining a strict privacy constraint. Due to privacy concerns and critical communication bottlenecks, it can become impractical to send the FL updated models to a centralized server. Thus, this paper studies the potential of hierarchical FL in Internet of Things (IoT) heterogeneous systems. In particular, we propose an optimized solution for user assignment and resource allocation over hierarchical FL architecture for IoT heterogeneous systems. This work focuses on a generic class of machine learning models that are trained using gradient-descent-based schemes while considering the practical constraints of non-uniformly distributed data across different users. We evaluate the proposed system using two real-world datasets, and we show that it outperforms state-of-the-art FL solutions. Specifically, our numerical results highlight the effectiveness of our approach and its ability to provide 4–6% increase in the classification accuracy, with respect to hierarchical FL schemes that consider distance-based user assignment. Furthermore, the proposed approach could significantly accelerate FL training and reduce communication overhead by providing 75–85% reduction in the communication rounds between edge nodes and the centralized server, for the same model accuracy.}
}
@article{ENTZINGER2010118,
title = {Modeling of the visual approach to landing using neural networks and fuzzy supervisory control},
journal = {Aerospace Science and Technology},
volume = {14},
number = {2},
pages = {118-125},
year = {2010},
issn = {1270-9638},
doi = {https://doi.org/10.1016/j.ast.2009.10.002},
url = {https://www.sciencedirect.com/science/article/pii/S1270963809000649},
author = {Jorg Onno Entzinger and Shinji Suzuki},
keywords = {Pilot modeling, Aircraft landing, Visual perception, Neural networks, Fuzzy logic},
abstract = {During the visual approach to landing of a fixed wing aircraft, a human pilot bases control and timing of subsequent maneuvers mainly on the out-the-window view, as there is not sufficient time to read all instruments. The skill of making smooth and soft landings is acquired mainly through experience. Research has been done to identify the most important features in the visual scene (cues) for two phases of the visual approach to landing: glide slope tracking and the flare maneuver. Using simulator and real flight data, neural networks have been trained for both phases to mimic the pilot's control based on the visual cues available. By using the γ operator in neuron transfer functions, a transparent model is obtained. Fuzzy supervisory control is proposed to couple the networks and thus provide insight in the pilot's decision making process with respect to timing the flare initiation.}
}
@article{SHANG2020113535,
title = {A co-optimal coverage path planning method for aerial scanning of complex structures},
journal = {Expert Systems with Applications},
volume = {158},
pages = {113535},
year = {2020},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2020.113535},
url = {https://www.sciencedirect.com/science/article/pii/S0957417420303596},
author = {Zhexiong Shang and Justin Bradley and Zhigang Shen},
keywords = {Coverage path planning, Unmanned aerial vehicle, Particle swarm optimization, Viewpoint quality},
abstract = {The utilization of unmanned aerial vehicles (UAVs) in survey and inspection of civil infrastructure has been growing rapidly. However, computationally efficient solvers that find optimal flight paths while ensuring high-quality data acquisition of the complete 3D structure remains a difficult problem. Existing solvers typically prioritize efficient flight paths, or coverage, or reducing computational complexity of the algorithm – but these objectives are not co-optimized holistically. In this work we introduce a co-optimal coverage path planning (CCPP) method that simultaneously co-optimizes the UAV path, the quality of the captured images, and reducing computational complexity of the solver all while adhering to safety and inspection requirements. The result is a highly parallelizable algorithm that produces more efficient paths where quality of the useful image data is improved. The path optimization algorithm utilizes a particle swarm optimization (PSO) framework which iteratively optimizes the coverage paths without needing to discretize the motion space or simplify the sensing models as is done in similar methods. The core of the method consists of a cost function that measures both the quality and efficiency of a coverage inspection path, and a greedy heuristic for the optimization enhancement by aggressively exploring the viewpoints search spaces. To assess the proposed method, a coverage path quality evaluation method is also presented in this research, which can be utilized as the benchmark for assessing other CPP methods for structural inspection purpose. The effectiveness of the proposed method is demonstrated by comparing the quality and efficiency of the proposed approach with the state-of-art through both synthetic and real-world scenes. The experiments show that our method enables significant performance improvement in coverage inspection quality while preserving the path efficiency on different test geometries.}
}
@article{NAZERDEYLAMI2021105478,
title = {Autonomous litter surveying and human activity monitoring for governance intelligence in coastal eco-cyber-physical systems},
journal = {Ocean & Coastal Management},
volume = {200},
pages = {105478},
year = {2021},
issn = {0964-5691},
doi = {https://doi.org/10.1016/j.ocecoaman.2020.105478},
url = {https://www.sciencedirect.com/science/article/pii/S0964569120303859},
author = {Arezoo Nazerdeylami and Babak Majidi and Ali Movaghar},
keywords = {Coastal management, Smart beach, Litter management, Artificial intelligence, Eco cyber physical systems},
abstract = {The human impact on the coastal ecosystems is a global environmental concern. Due to the growing urbanization, industrialization, and transportation, this impact on the living and non-living components of the coastal area is expected to further increase in the coming years. Artificial intelligence based automation of the coastal monitoring, including data collection, analysis and decision making, provides real-time insights and opportunities for large-scale coastal management and governance. In this paper, a framework for autonomous litter surveying and human activity monitoring for governance intelligence in coastal eco-cyber-physical systems (ecoCystem) is presented. A large dataset of more than 20,000 images focused on smart coastal management is collected to model the real world scenarios. A combination of various artificial intelligence based methods are used for automatic detection and classification of various litter in the coastal environment. Furthermore, the proposed framework is capable of autonomous monitoring of humans activities and detection of illegal entry of vehicles and boats to the beach area. The accuracy of the proposed autonomous system is 87% for correct classification of fully visible litter and 95% for fully visible vehicles. The experimental results show that the application of computer vision and machine learning for autonomous litter classification shows promising results for increasing the speed and scale of litter surveying in the coastal area. Further training of the artificial intelligence models is necessary for increasing the accuracy of the proposed framework and real-world deployment in the coastal environment. The proposed human activity monitoring system can be used for autonomous coastal law enforcement and real-time and active protection of the coastal zones.}
}
@article{SATHEESHKUMAR20211813,
title = {Analysis of Connected Word Recognition systems using Levenberg Marquardt Algorithm for cockpit control in unmanned aircrafts},
journal = {Materials Today: Proceedings},
volume = {37},
pages = {1813-1819},
year = {2021},
note = {International Conference on Newer Trends and Innovation in Mechanical Engineering: Materials Science},
issn = {2214-7853},
doi = {https://doi.org/10.1016/j.matpr.2020.07.399},
url = {https://www.sciencedirect.com/science/article/pii/S2214785320355097},
author = {S. {Satheesh Kumar} and R. Sowmya and B. {Maruthi Shankar} and N. Lingaraj and S.A. Sivakumar},
keywords = {Continuous Word Recognition system, Multimodal interactions, Cockpit control, Levenberg Marquardt Algorithm, Neural networks},
abstract = {Due to advances in computation, the computer system needs sufficient input data, and it allows it a better computer tool for efficient operation of the human-computer, such as the fast-moving Automatic Speech Recognition System. This paper aims in particular to provide an insight into the contact distance between humans and computers in unmanned aircraft vehicles. While there are several algorithms, a critical analysis of algorithms suitable for large-scale applications is still important. The aircraft without a human pilot on board is an unmanned aerial vehicle. Continuous Word Recognition systems for voice enhancement (commanding) based cockpit control are commonly used in unmanned aircraft. The goal is to evaluate the efficiency of the Levenberg Marquardt algorithm by using these recognition systems. To do this, optimal preparation can be selected using neural networks to increase the machine recognition effectiveness. MATLAB verify simulated findings and tests show that a high accuracy of recognition of over 87 percent is obtained.}
}
@article{MINHDANG2020107561,
title = {Sensor-based and vision-based human activity recognition: A comprehensive survey},
journal = {Pattern Recognition},
volume = {108},
pages = {107561},
year = {2020},
issn = {0031-3203},
doi = {https://doi.org/10.1016/j.patcog.2020.107561},
url = {https://www.sciencedirect.com/science/article/pii/S0031320320303642},
author = {L. {Minh Dang} and Kyungbok Min and Hanxiang Wang and Md. {Jalil Piran} and Cheol {Hee Lee} and Hyeonjoon Moon},
keywords = {Human activity recognition, Action recognition, Sensors, Vision, Human-centric sensing, Deep learning, Context-awareness},
abstract = {Human activity recognition (HAR) technology that analyzes data acquired from various types of sensing devices, including vision sensors and embedded sensors, has motivated the development of various context-aware applications in emerging domains, e.g., the Internet of Things (IoT) and healthcare. Even though a considerable number of HAR surveys and review articles have been conducted previously, the major/overall HAR subject has been ignored, and these studies only focus on particular HAR topics. Therefore, a comprehensive review paper that covers major subjects in HAR is imperative. This survey analyzes the latest state-of-the-art research in HAR in recent years, introduces a classification of HAR methodologies, and shows advantages and weaknesses for methods in each category. Specifically, HAR methods are classified into two main groups, which are sensor-based HAR and vision-based HAR, based on the generated data type. After that, each group is divided into subgroups that perform different procedures, including the data collection, pre-processing methods, feature engineering, and the training process. Moreover, an extensive review regarding the utilization of deep learning in HAR is also conducted. Finally, this paper discusses various challenges in the current HAR topic and offers suggestions for future research.}
}
@article{PATEL2019141,
title = {Passive Fault Tolerant Control System Using Feed-forward Neural Network for Two-Tank Interacting Conical Level Control System Against Partial Actuator Failures and Disturbances ⁎⁎Research work carried out at Instrumentation & Control Engineering Dept., D. D. University, Nadiad, Gujarat, India.},
journal = {IFAC-PapersOnLine},
volume = {52},
number = {14},
pages = {141-146},
year = {2019},
note = {18th IFAC Symposium on Control, Optimization and Automation in Mining, Mineral and Metal Processing, MMM 2019},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2019.09.178},
url = {https://www.sciencedirect.com/science/article/pii/S2405896319308109},
author = {Himanshukumar R. Patel and Vipul A. Shah},
keywords = {Actuator fault, back-propagation algorithm, conical tank, disturbances, Feed-forward Neural Network, fault-tolerant control, PI control},
abstract = {A novel approach for passive fault-tolerant control (PFTC) system design against actuator faults is proposed. The scheme is based on Feed-forward Neural Network (FFNN) plus conventional PI controller, during the fault occurred into system FFNN will give additional control output to the system according to fault magnitude. The FFNN will trained using back-propagation algorithm. To eliminate the steady-state tracking error, the PI controller is also incorporated. The following fault type and input signals are considered: abrupt, step, sine, and trapezoidal trajectory inputs. The effectiveness and the superiority of the proposed approach are demonstrated using Two-Tank Interacting Conical Level Control System (TTICLCS) example. The simulation performed in MATLAB Simulink platform, also different integral errors like IAE, ISE and IATE are presented to validate the proposed approach.}
}
@article{ZEFRI2021100576,
title = {In-depth investigation of applied digital photogrammetry to imagery-based RGB and thermal infrared aerial inspection of large-scale photovoltaic installations},
journal = {Remote Sensing Applications: Society and Environment},
volume = {23},
pages = {100576},
year = {2021},
issn = {2352-9385},
doi = {https://doi.org/10.1016/j.rsase.2021.100576},
url = {https://www.sciencedirect.com/science/article/pii/S2352938521001129},
author = {Yahya Zefri and Imane Sebari and Hicham Hajji and Ghassane Aniba},
keywords = {Photovoltaics, Photogrammetry, Unmanned aerial vehicle, RGB, Thermal infrared},
abstract = {We conduct a comprehensive in-depth investigation of applied digital aerial photogrammetry to imagery-based inspection of large-scale photovoltaic installations. A varied collection of RGB and thermal datasets are collected and processed with different parameters, then analyzed based on multiple evaluation metrics. The analysis focuses on the image matching and camera parameters calibration phases, which constitute the backbone of the photogrammetric post-acquisition workflow ahead of defects detection. We emphasize the imbalance between RGB and thermal imagery, and how it leads to relatively very low computed and matched keypoints on thermal images. The keypoints t-distributed Stochastic Neighbor Embedding (t-SNE) from sample images highlights the repetitiveness of PV patterns, which increases the likelihood of image mismatching. The calibration of thermal datasets ends up with several inconsistencies in the optimization of the internal and external camera parameters. These inconsistencies produce flawed posterior results, which compromise the use of the photogrammetric approach. We develop state-of-art guidelines to adopt for image acquisition and processing, propose several research avenues to pursue for future work, and demonstrate the advantages that digital photogrammetry offers over conventional imagery-based inspection workflows.}
}
@article{KIM2020105099,
title = {Machine vision-based automatic disease symptom detection of onion downy mildew},
journal = {Computers and Electronics in Agriculture},
volume = {168},
pages = {105099},
year = {2020},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2019.105099},
url = {https://www.sciencedirect.com/science/article/pii/S0168169919312384},
author = {Wan-Soo Kim and Dae-Hyun Lee and Yong-Joo Kim},
keywords = {Crop disease, Onion downy mildew, Monitoring system, Deep learning, Weakly supervised learning},
abstract = {The effective crop management is major issue in recent agriculture because the cultivation area per farmer is increasing consistently while the aging-related reductions in the labor force. To manage crop cultivation effectively, it needs automatic monitoring in farmland. This paper presents an image-based field monitoring system for automatically crop monitoring and consists of constructing field monitoring system for periodic capturing of onion field images, training the deep neural network model for detecting the disease symptom, and evaluating performance of the developed system. The field monitoring system was composed of a PTZ camera, a motor system, wireless transceiver, and image logging module. The deep learning model was trained based on weakly supervised learning method that can classify and localize objects only with image-level annotation. It is effective to recognize crop disease symptom which has ambiguous boundary. The model was trained using captured onion images using the filed monitoring system, and 6 classes including the disease symptom were classified. The detected disease symptom was localized from background through thresholding of the class activation map. The 60% of maximum value in class activation map was determined as an Optimal threshold for disease symptom localization. Identification performance of disease symptom was evaluated using mAP metric by IoU. The results show that the mAP at IoU criteria 0.5, which should have over 50% overlap, was the highest in all models from 74.1 to 87.2. The results showed that the developed field monitoring system could automatically detect onion disease symptoms in real-time.}
}
@article{SHIN2020113064,
title = {Reward-driven U-Net training for obstacle avoidance drone},
journal = {Expert Systems with Applications},
volume = {143},
pages = {113064},
year = {2020},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2019.113064},
url = {https://www.sciencedirect.com/science/article/pii/S095741741930781X},
author = {Sang-Yun Shin and Yong-Won Kang and Yong-Guk Kim},
keywords = {Autonomous drone, Reward-driven training, Actor Critic networks, U-Net, Policy gradient method, Reinforcement learning},
abstract = {Along with the fast progress in deep learning, an autonomous drone with obstacle avoidance capability has been studied mainly by two machine learning paradigms, i.e. supervised learning, and reinforcement learning. The former has some advantages since the trained network is light and fast, but it needs a large amount of data that requires laborious manual labeling. With the latter, such a drawback can be overcome as an agent learns by itself in a simulated environment, although the gap between the real and simulated one has to be minimized in the end. This study proposes a new framework where a supervised segmentation network is trained with labels made by an actor-critic network in a reward-driven manner, wherein this U-Net based network infers the next moving direction from the sequence of input images. For the actor-critic part, several recent policy gradient algorithms have been tested for controlling the drone with the continuous action space. After training in the Airsim simulation environment, the model is transferred to a Bebop drone flying in the real environment, built as a reconfigurable maze using panels and a hoop. The result suggests that our network enables the drone to navigate through the obstacles using only monocular RGB input in the trained environment as well as in the reconfigured ones without retraining.}
}
@article{ABIOYE2021103299,
title = {Artificial intelligence in the construction industry: A review of present status, opportunities and future challenges},
journal = {Journal of Building Engineering},
volume = {44},
pages = {103299},
year = {2021},
issn = {2352-7102},
doi = {https://doi.org/10.1016/j.jobe.2021.103299},
url = {https://www.sciencedirect.com/science/article/pii/S2352710221011578},
author = {Sofiat O. Abioye and Lukumon O. Oyedele and Lukman Akanbi and Anuoluwapo Ajayi and Juan Manuel {Davila Delgado} and Muhammad Bilal and Olugbenga O. Akinade and Ashraf Ahmed},
keywords = {Artificial intelligence, Machine learning, AI challenges, AI opportunities, Construction industry, Robotics},
abstract = {The growth of the construction industry is severely limited by the myriad complex challenges it faces such as cost and time overruns, health and safety, productivity and labour shortages. Also, construction industry is one the least digitized industries in the world, which has made it difficult for it to tackle the problems it currently faces. An advanced digital technology, Artificial Intelligence (AI), is currently revolutionising industries such as manufacturing, retail, and telecommunications. The subfields of AI such as machine learning, knowledge-based systems, computer vision, robotics and optimisation have successfully been applied in other industries to achieve increased profitability, efficiency, safety and security. While acknowledging the benefits of AI applications, numerous challenges which are relevant to AI still exist in the construction industry. This study aims to unravel AI applications, examine AI techniques being used and identify opportunites and challenges for AI applications in the construction industry. A critical review of available literature on AI applications in the construction industry such as activity monitoring, risk management, resource and waste optimisation was conducted. Furthermore, the opportunities and challenges of AI applications in construction were identified and presented in this study. This study provides insights into key AI applications as it applies to construction-specific challenges, as well as the pathway to realise the acrueable benefits of AI in the construction industry.}
}
@article{VARSHNEY20211124,
title = {Fast-forward breeding for a food-secure world},
journal = {Trends in Genetics},
volume = {37},
number = {12},
pages = {1124-1136},
year = {2021},
issn = {0168-9525},
doi = {https://doi.org/10.1016/j.tig.2021.08.002},
url = {https://www.sciencedirect.com/science/article/pii/S0168952521002262},
author = {Rajeev K. Varshney and Abhishek Bohra and Manish Roorkiwal and Rutwik Barmukh and Wallace A. Cowling and Annapurna Chitikineni and Hon-Ming Lam and Lee T. Hickey and Janine S. Croser and Philipp E. Bayer and David Edwards and José Crossa and Wolfram Weckwerth and Harvey Millar and Arvind Kumar and Michael W. Bevan and Kadambot H.M. Siddique},
keywords = {crop improvement, food security, haplotype, genome editing, genetic gain, speed breeding},
abstract = {Crop production systems need to expand their outputs sustainably to feed a burgeoning human population. Advances in genome sequencing technologies combined with efficient trait mapping procedures accelerate the availability of beneficial alleles for breeding and research. Enhanced interoperability between different omics and phenotyping platforms, leveraged by evolving machine learning tools, will help provide mechanistic explanations for complex plant traits. Targeted and rapid assembly of beneficial alleles using optimized breeding strategies and precise genome editing techniques could deliver ideal crops for the future. Realizing desired productivity gains in the field is imperative for securing an adequate future food supply for 10 billion people.}
}
@article{FU2021126241,
title = {An overview of crop nitrogen status assessment using hyperspectral remote sensing: Current status and perspectives},
journal = {European Journal of Agronomy},
volume = {124},
pages = {126241},
year = {2021},
issn = {1161-0301},
doi = {https://doi.org/10.1016/j.eja.2021.126241},
url = {https://www.sciencedirect.com/science/article/pii/S1161030121000137},
author = {Yuanyuan Fu and Guijun Yang and Ruiliang Pu and Zhenhai Li and Heli Li and Xingang Xu and Xiaoyu Song and Xiaodong Yang and Chunjiang Zhao},
keywords = {Hyperspectral remote sensing, Crop N status, N-related hyperspectral vegetation index, Machine learning algorithm, Feature mining},
abstract = {Nitrogen (N) is significantly related to crop photosynthetic capacity. Over-and-under-application of N fertilizers not only limits crop productivity but also leads to negative environment impacts. With such a dilemma, a feasible solution is to match N supply with crop needs across time and space. Hyperspectral remote sensing has been gradually regarded as a cost-effective alternative to traditional destructive field sampling and laboratory testing for crop N status determination. Hyperspectral vegetation indices (VIs) and linear nonparametric regression have been the dominant techniques used to estimate crop N status. Machine learning algorithms have gradually exerted advantages in modelling the non-linear relationships between spectral data and crop N. Physically-based methods were rarely used due to the lack of radiative transfer models directly involving N. The existing crop N retrieval methods rely heavily on the relationship between chlorophyll and N. The underlying mechanisms of using protein as a proxy of N and crop protein retrieval from canopy hyperspectral data need further exploration. A comprehensive survey of the existing N-related hyperspectral VIs was made with the aim to provide guidance in VI selection for practical application. The combined use of feature mining and machine learning algorithms was emphasized in the overview. Some feature mining methods applied in the field of classification and chemometrics might be adapted for extracting crop N-related features. The deep learning algorithms need further exploration in crop N status assessment from canopy hyperspectral data. Finally, the major challenges and further development direction in crop N status assessment were discussed. The overview could provide a theoretical and technical support to promote applications of hyperspectral remote sensing in crop N status assessment.}
}
@article{KOKER2013528,
title = {A genetic algorithm approach to a neural-network-based inverse kinematics solution of robotic manipulators based on error minimization},
journal = {Information Sciences},
volume = {222},
pages = {528-543},
year = {2013},
note = {Including Special Section on New Trends in Ambient Intelligence and Bio-inspired Systems},
issn = {0020-0255},
doi = {https://doi.org/10.1016/j.ins.2012.07.051},
url = {https://www.sciencedirect.com/science/article/pii/S0020025512005233},
author = {Raşit Köker},
keywords = {Robotics, Neural networks, Elman networks, Genetic algorithms, Inverse kinematics problem, 6-Degree-of-freedom robot},
abstract = {The solution of the inverse kinematics problem is fundamental in robot control. Many traditional inverse kinematics problem solutions, such as the geometric, iterative, and algebraic approaches, are inadequate for redundant robots. Recently, much attention has been focused on a neural-network-based inverse kinematics problem solution in robotics. However, the precision of the result obtained from a neural network requires improvement for certain sensitive tasks. In this paper, neural network and genetic algorithms are used together to solve the inverse kinematics problem of a six-joint Stanford robotic manipulator to minimize the error at the end effector. The proposed hybrid approach combines the characteristics of neural networks and evolutionary techniques to obtain more precise solutions. Three Elman neural networks were trained using separate training sets because one of the sets yields better results than the other two. The floating-point portions of each network were placed in the initial population of the genetic algorithm with the floating-point portions from randomly generated solutions. The end-effector position error was defined as the fitness function, and the genetic algorithm was implemented. Using this approach, the floating-point portion of the neural-network result was improved by up to ten significant digits using a genetic algorithm, and the error was reduced to micrometer levels. These results were compared with those from studies in the literature and found to be significantly better.}
}
@article{FUST2020108380,
title = {Development perspectives for the application of autonomous, unmanned aerial systems (UASs) in wildlife conservation},
journal = {Biological Conservation},
volume = {241},
pages = {108380},
year = {2020},
issn = {0006-3207},
doi = {https://doi.org/10.1016/j.biocon.2019.108380},
url = {https://www.sciencedirect.com/science/article/pii/S0006320719310973},
author = {Pascal Fust and Jacqueline Loos},
abstract = {Conservation management requires reliable and up-to-date data on land use, wildlife population sizes and resource distribution across highly variable ecosystems. Simultaneously, limited funding in conservation often restrict the assessment and interpretation of these datasets. Unmanned aerial systems (UASs) appear as promising and cost-efficient tools to deliver high-quality data, especially when combined with advanced sensor technologies, e.g. based on specific light features such as spectral signature, short-wave infrared (SWIR) reflection and/or polarization. However, their application rates for conservation purposes remain low, partly because of current technology's inaptitude to extrapolate findings onto large spatial scales due to limited flight ranges of the vehicles and difficulties in animal detection and identification. Particularly, using SWIR cameras and polarization filters combined with thermal cameras may improve animal detection, but only few tests have so far investigated the reliability of these technologies. The analysis of large datasets e.g. from hyperspectral cameras requires skills and time, whereas most interest lies in the results of these surveys. Additionally, legal constraints and high initial investment costs confront their application. Overcoming these challenges requires advancing technological robustness of the tool as well as defining the applicability of unmanned aerial vehicles (UAVs) within conservation management. Moreover, its application needs validation in contrast to ground and/or aerial surveys to recommend protocols in different ecological settings and for different management questions. We conclude that UAVs may not serve as panaceas for monitoring land use changes and wildlife trends, but as additional, intermediary data collection tools to support management decisions.}
}
@article{HU2020762,
title = {3D multi-UAV cooperative velocity-aware motion planning},
journal = {Future Generation Computer Systems},
volume = {102},
pages = {762-774},
year = {2020},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2019.09.030},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X19313597},
author = {Yujiao Hu and Yuan Yao and Qian Ren and Xingshe Zhou},
keywords = {Motion planning, Velocity-aware, A algorithm, Multi-UAV coordination},
abstract = {Motion planning is a crucial topic with multi-UAV applications of search and rescue missions, transportation missions, etc. The concerns of motion planning focus on path planning and inter-UAV collision avoidance. Model based on Lyapunov present great solutions. However, setting reasonable parameters for the model is usually based on experience. Moreover, UAVs controlled by the models usually converge to destinations slowly. Heuristic planning algorithms are also mainstream approaches to guide UAVs. However, they hardly consider kinetics of UAVs. This paper proposes distributed velocity-aware algorithm and collision avoidance algorithm to serve motion planning of multiple UAVs. The velocity-aware algorithm generates paths with acceleration vectors that converge to the predefined destinations. The collision avoidance algorithm will be triggered to protect UAVs from collisions when path conflicts are predicted. Compared with hierarchical control model and Lyapunov-like control laws, our approach could improve success possibility of mission achievement for UAVs. At the same time, the algorithms help UAVs take shorter paths and less time to move to destinations safely.}
}
@article{GAO2017666,
title = {Sliding mode adaptive neural network control for hybrid visual servoing of underwater vehicles},
journal = {Ocean Engineering},
volume = {142},
pages = {666-675},
year = {2017},
issn = {0029-8018},
doi = {https://doi.org/10.1016/j.oceaneng.2017.07.015},
url = {https://www.sciencedirect.com/science/article/pii/S0029801817303852},
author = {Jian Gao and Xuman An and Alison Proctor and Colin Bradley},
keywords = {Underwater vehicles, Hybrid visual servoing, Neural networks, Adaptive sliding mode control, Dynamic uncertainties},
abstract = {In this paper, a hybrid visual servo (HVS) controller is proposed for underwater vehicles, in which a combination of the vehicle's 3-D Cartesian pose and the 2-D image coordinates of a single feature is exploited. A dynamic inversion-based sliding mode adaptive neural network control (DI-SMANNC) method is developed for tracking the HVS reference trajectory generated from a constant target pose. A single hidden-layer (SHL) feedforward neural network, in conjunction with an adaptive sliding mode controller, is utilized to compensate for dynamic uncertainties. The adaptation laws of neural network weight matrices and control gains are designed to ensure the asymptotical stability of tracking errors and the ultimate uniform boundedness (UUB) of neural network weight matrices. The main advantage of the proposed DI-SMANNC over conventional sliding model neural network controllers lies in the fact that the knowledge of the bounds on system uncertainties and neural approximation errors is not required to be previously known. Simulation results are presented to validate the effectiveness of the developed controller, especially the robustness with respect to dynamic modeling uncertainties and camera calibration errors.}
}
@article{GURSOY2010277,
title = {Long Term Learning Adaptive Neural Network Estimator Based Limit Detection},
journal = {IFAC Proceedings Volumes},
volume = {43},
number = {10},
pages = {277-281},
year = {2010},
note = {10th IFAC Workshop on the Adaptation and Learning in Control and Signal Processing},
issn = {1474-6670},
doi = {https://doi.org/10.3182/20100826-3-TR-4015.00052},
url = {https://www.sciencedirect.com/science/article/pii/S1474667015323788},
author = {Gonenc Gursoy and Ilkay Yavrucuk},
keywords = {Limit detection, limit avoidance, pilot cueing},
abstract = {Dynamic adaptive models are commonly used to estimate allowable control travel and the proximity to a limiting flight condition in the design of advanced envelope protection algorithms for fly by wire aircraft. In this paper linear models are compensated with adaptive neural networks to build adaptive models of relevant aircraft dynamics. A stack of data collected during flight is used to update the network weights online. The data stack is made up of instantaneously measured data and recorded data during simulations. It is observed that by using recorded data in a stack can cancel out new modeling errors in a short time and results with better predictions of approaching limits compared to using instantaneous data only.}
}
@article{BAYOMI2021110648,
title = {Building envelope modeling calibration using aerial thermography},
journal = {Energy and Buildings},
volume = {233},
pages = {110648},
year = {2021},
issn = {0378-7788},
doi = {https://doi.org/10.1016/j.enbuild.2020.110648},
url = {https://www.sciencedirect.com/science/article/pii/S0378778820334344},
author = {Norhan Bayomi and Shreshth Nagpal and Tarek Rakha and John E. Fernandez},
keywords = {Unmanned Aerial Vehicles (UAVs), Energy modelling, Built environment, Building simulation, Infrared imaging, Building envelope},
abstract = {Built environments contribute significantly to mitigating climate change. However, existing buildings, which form most urban infrastructures, do not typically meet contemporary stringent energy efficiency standards. They are naturally continuously deteriorating, making them a continuous negative contributor to their surrounding environments, which keeps getting worse. Therefore, there is a need to develop performance diagnosis frameworks and approaches for accurate Building Energy Model (BEM) simulations to develop impactful retrofitting design solutions that could make existing buildings perform closer to current efficiency measures. This paper reports on research that focuses explicitly on calibrating envelopes of existing BEMs using drones equipped with thermography sensors. The study specifically focuses on the automation of on-the-fly envelope U-value estimations and verification of calibrated envelope BEMs. The paper examines a renovated campus building in Boston, MA., representing material degradation, thermal bridging, and insulation failures using thermal imaging. A BEM is then calibrated, and post-renovation metered and modeled wintertime heating energy are compared. Goodness of fit measures showcase BEM performance improvement from 21.8%to 0.9%, which demonstrates the utility of the proposed framework. Further research is recommended to expand the focus on anomalies in the envelope and increase the scope from the building scale to the neighborhood scale.}
}
@article{ZADEH2019760,
title = {An efficient metamodel-based multi-objective multidisciplinary design optimization framework},
journal = {Applied Soft Computing},
volume = {74},
pages = {760-782},
year = {2019},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2018.09.014},
url = {https://www.sciencedirect.com/science/article/pii/S1568494618305313},
author = {Parviz Mohammad Zadeh and Mohsen Sayadi and Amirreza Kosari},
keywords = {Multi-objective optimization, Particle swarm optimization (PSO), Metamodel, Multidisciplinary design optimization (MDO), Unmanned aerial vehicles (UAV)},
abstract = {This paper presents an efficient metamodel-based multi-objective multidisciplinary design optimization (MDO) architecture for solving multi-objective high fidelity MDO problems. One of the important features of the proposed method is the development of an efficient surrogate model-based multi-objective particle swarm optimization (EMOPSO) algorithm, which is integrated with a computationally efficient metamodel-based MDO architecture. The proposed EMOPSO algorithm is based on sorted Pareto front crowding distance, utilizing star topology. In addition, a constraint-handling mechanism in non-domination appointment and fuzzy logic is also introduced to overcome feasibility complexity and rapid identification of optimum design point on the Pareto front. The proposed algorithm is implemented on a metamodel-based collaborative optimization architecture. The proposed method is evaluated and compared with existing multi-objective optimization algorithms such as multi-objective particle swarm optimization (MOPSO) and non-dominated sorting genetic algorithm II (NSGA-II), using a number of well-known benchmark problems. One of the important results observed is that the proposed EMOPSO algorithm provides high diversity with fast convergence speed as compared to other algorithms. The proposed method is also applied to a multi-objective collaborative optimization of unmanned aerial vehicle wing based on high fidelity models involving structures and aerodynamics disciplines. The results obtained show that the proposed method provides an effective way of solving multi-objective multidisciplinary design optimization problem using high fidelity models.}
}
@article{KHAN2021130,
title = {Robustness of AI-based prognostic and systems health management},
journal = {Annual Reviews in Control},
volume = {51},
pages = {130-152},
year = {2021},
issn = {1367-5788},
doi = {https://doi.org/10.1016/j.arcontrol.2021.04.001},
url = {https://www.sciencedirect.com/science/article/pii/S1367578821000195},
author = {Samir Khan and Seiji Tsutsumi and Takehisa Yairi and Shinichi Nakasuka},
keywords = {Prognostics and system health management, Robust AI, Machine learning, PHM, Fault diagnosis},
abstract = {Prognostic and systems Health Management (PHM) is an integral part of a system. It is used for solving reliability problems that often manifest due to complexities in design, manufacturing, operating environment and system maintenance. For safety-critical applications, using a model-based development process for complex systems might not always be ideal but it is equally important to establish the robustness of the solution. The information revolution has allowed data-driven methods to diffuse within this field to construct the requisite process (or system models) to cope with the so-called big data phenomenon. This is supported by large datasets that help machine-learning models achieve impressive accuracy. AI technologies are now being integrated into many PHM related applications including aerospace, automotive, medical robots and even autonomous weapon systems. However, with such rapid growth in complexity and connectivity, a systems’ behaviour is influenced in unforeseen ways by cyberattacks, human errors, working with incorrect or incomplete models and even adversarial phenomena. Many of these models depend on the training data and how well the data represents the test data. These issues require fine-tuning and even retraining the models when there is even a small change in operating conditions or equipment. Yet, there is still ambiguity associated with their implementation, even if the learning algorithms classify accordingly. Uncertainties can lie in any part of the AI-based PHM model, including in the requirements, assumptions, or even in the data used for training and validation. These factors lead to sub-optimal solutions with an open interpretation as to why the requirements have not been met. This warrants the need for achieving a level of robustness in the implemented PHM, which is a challenging task in a machine learning solution. This article aims to present a framework for testing the robustness of AI-based PHM. It reviews some key milestones achieved in the AI research community to deal with three particular issues relevant for AI-based PHM in safety-critical applications: robustness to model errors, robustness to unknown phenomena and empirical evaluation of robustness during deployment. To deal with model errors, many techniques from probabilistic inference and robust optimisation are often used to provide some robustness guarantee metric. In the case of unknown phenomena, techniques include anomaly detection methods, using causal models, the construction of ensembles and reinforcement learning. It elicits from the authors’ work on fault diagnostics and robust optimisation via machine learning techniques to offer guidelines to the PHM research community. Finally, challenges and future directions are also examined; on how to better cope with any uncertainties as they appear during the operating life of an asset.}
}
@article{FANG2020100980,
title = {Computer vision for behaviour-based safety in construction: A review and future directions},
journal = {Advanced Engineering Informatics},
volume = {43},
pages = {100980},
year = {2020},
issn = {1474-0346},
doi = {https://doi.org/10.1016/j.aei.2019.100980},
url = {https://www.sciencedirect.com/science/article/pii/S1474034619305531},
author = {Weili Fang and Peter E.D. Love and Hanbin Luo and Lieyun Ding},
keywords = {Behaviour-based safety, Unsafe behaviour, Computer vision, Deep learning, Convolutional neural network},
abstract = {The process of identifying and bringing to the fore people’s unsafe behaviour is a core function of implementing a behaviour-based safety (BBS) program in construction. This can be a labour-intensive and challenging process but is needed to enable people to reflect and learn about how their unsafe actions can jeopardise not only their safety but that of their co-workers. With advances being made in computer vision, the capability exists to automatically capture and identify unsafe behaviour and hazards in real-time from two-dimensional (2D) digital images/videos. The corollary developments in computer vision have stimulated a wealth of research in construction to examine its potential application to practice. Hindering the application of computer vision in construction has been its inability to accurately, and generalise the detection of objects. To address this shortcoming, developments in deep learning have provided computer vision with the ability to improve the accuracy, reliability and ability to generalise object detection and therefore its usage in construction. In this paper we review the developments of computer vision studies that have been used to identify unsafe behaviour from 2D images that arises on construction sites. Then, in light of advances made with deep learning, we examine and discuss its integration with computer vision to support BBS. We also suggest that future computer-vision research should aim to support BBS by being able to: (1) observe and record unsafe behaviour; (2) understand why people act unsafe behaviour; (3) learn from unsafe behaviour; and (4) predict unsafe behaviour.}
}
@article{WEN2020102288,
title = {Distributed optimization via primal and dual decompositions for delay-constrained FANETs},
journal = {Ad Hoc Networks},
volume = {109},
pages = {102288},
year = {2020},
issn = {1570-8705},
doi = {https://doi.org/10.1016/j.adhoc.2020.102288},
url = {https://www.sciencedirect.com/science/article/pii/S1570870520306491},
author = {Shaojie Wen and Lianbing Deng and Yuhang Liu},
keywords = {Flying ad hoc networks, Distributed optimization, Primal and dual decomposition, Delay constraint},
abstract = {This paper aims to optimize the different network parameters in a distributed manner for delay-constrained flying ad hoc networks (FANETs) without the global network topology information. To this end, each Unmanned Aerial Vehicle (UAV) calculates the average interference level during a certain time period to indicate the channel states. Next, we formulate the distributed optimization problem as a utility maximization problem, which jointly optimizes power control, rate allocation and delay-constrained routing. To obtain a distributed solution, a dual method is proposed to eliminate the link capacity constraint, and a primal decomposition method is employed to decouple the end-to-end delay constraint. Built on these two methods above, a distributed optimization algorithm is proposed in this work by considering the estimated one-hop delay for each transmission, which only uses the local channel information to optimize the sub-problems and limit the end-to-end delay. Finally, we deduce the relationship between the primal and dual solutions to underpin the advantage of the proposed algorithm. Experiments on simulate (and real) data demonstrate that the proposed algorithm effectively can improve network performances in terms of energy efficiency, packet timeout ratio and network throughput.}
}
@article{SWARNKAR2016579,
title = {A Simplified Adaptive Backstepping Control of Aircraft Lateral/Directional Dynamics},
journal = {IFAC-PapersOnLine},
volume = {49},
number = {1},
pages = {579-584},
year = {2016},
note = {4th IFAC Conference on Advances in Control and Optimization of Dynamical Systems ACODS 2016},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2016.03.117},
url = {https://www.sciencedirect.com/science/article/pii/S2405896316301173},
author = {Swati Swarnkar and Mangal Kothari},
keywords = {Flight control system, Nonlinear control, State feedback, Backstepping, Lyapunov stability, Adaptive control},
abstract = {A simple approach is proposed in this paper to control lateral/directional dynamics of Unmanned Aerial Vehicles (UAVs). The approach uses backstepping technique to design a lateral/directional controller. As the aerodynamics coefficients are not accurately available for the whole flight regime, we propose an adaptive design to learn and control unknown dynamics. The proposed approach provides satisfactory performance in tracking reference in roll rate using aileron and in maintaining sideslip angle to zero value using rudder. The design is validated on the six degrees of freedom model with the effect of actuator saturation.}
}
@article{AGAND20171,
title = {Adaptive recurrent neural network with Lyapunov stability learning rules for robot dynamic terms identification},
journal = {Engineering Applications of Artificial Intelligence},
volume = {65},
pages = {1-11},
year = {2017},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2017.07.009},
url = {https://www.sciencedirect.com/science/article/pii/S0952197617301574},
author = {Pedram Agand and Mahdi Aliyari Shoorehdeli and Ali Khaki-Sedigh},
keywords = {Neural networks, Recurrent networks, Lyapunov function, Adaptive learning algorithms, Helicopter},
abstract = {In this paper, a recurrent neural network coupled with Kalman filter is proposed to identify dynamic terms of robotic manipulator. By cooperating some inherent characteristics of robot, this network has the capability to individually identify nonlinear terms using Weighted Augmentation Error (WAE). To present the infrastructure of architecture, an adaptive scheme based on the conventional Back Propagation (BP) is firstly driven using the Gradient Descent (GD) method. Additionally, a stable adaptive updating rule is extracted from the discrete time Lyapunov candidate as an approach for the general nonlinear system identification. Then, this approach is applied to the predefined network. To experimentally validate the computational efficiency and control applicability of the proposed method, Adaptive Neural Network Based Inverse Dynamic Control (ANN-Based-IDC) is employed on a laboratory-scaled twin-rotor CE-150 helicopter. This experiment illustrates enhancement of steady-state performance from 2-to-3 times more in compared with simple PID. Moreover, disturbance rejection and robustness tests admit capability of the method for online dynamic identification in the presence of output and dynamic perturbation.}
}
@article{REN2020107509,
title = {Design and construction of the knowledge base system for geological outfield cavities classifications: An example of the fracture-cavity reservoir outfield in Tarim basin, NW China},
journal = {Journal of Petroleum Science and Engineering},
volume = {194},
pages = {107509},
year = {2020},
issn = {0920-4105},
doi = {https://doi.org/10.1016/j.petrol.2020.107509},
url = {https://www.sciencedirect.com/science/article/pii/S0920410520305805},
author = {Qiqiang Ren and Qiang Jin and Jianwei Feng and He Du},
keywords = {UAV scanning, 3D digital model, Multiple linear regression, Discriminant classification, Fracture-cavity reservoir},
abstract = {Tahe oilfield, located in NW Tarim Basin, is one of the largest and most difficult fracture cavity reservoirs in the world. Different fracture cavities, different generated mechanisms, and different oil production capacities. In order to study the significant parameters that can characterize the categories of facture-cavity. This research adopted outfield manual measurement, 3D digital modeling technique to obtain characterization parameters. According to experienced geological survey, typical outcrops were selected, then scanned by UAV (Unmanned aerial vehicle). Consequently, 3D digital models, including real coordinates and parameter information, were established by Agisoft Photoscan. Through geological testing results, various combination characteristic patterns of relative categories were analyzed. By using digital measure tool, combined with manually measured data, the parameters were extracted from the 3D digital model (DM). Then an initial geological database was established. For furtherly analyzing the database, the mathematic statistics methods of multiple linear regression (MLR), neural network technique (NNT) and discriminative classification technique (DCT) were applied. Using software of SPSS statistics 17.0, more than 200 groups of geological data (various categories of fracture-cavity) were optimally processed. Consequently, the significant characteristic parameters were interpreted to determine diverse categories. The results showed that: (1) cavity width, height, fracture length and cavity aspect ratio were significant parameters to classify runoff cavity categories. (2) Fault-controlled cavities could be accurately classified by fracture length and fracture density. (3) The main cavity categories could be distinguished by cavity width, cavity height and fracture density. Performances of the approach have been examined with 10 percentages of the samples, and a good agreement performed in the simulated results, and anastomosis rate was more than 80%. The researched results have critical guiding significance to evaluate types of fracture-cavity, develop and explore of fracture-cavity reservoirs. The construction technique of knowledge base can be applied for diverse fracture-cavity reservoirs in the various formations in different areas in the world.}
}
@article{ZHAO2020111605,
title = {A robust spectral-spatial approach to identifying heterogeneous crops using remote sensing imagery with high spectral and spatial resolutions},
journal = {Remote Sensing of Environment},
volume = {239},
pages = {111605},
year = {2020},
issn = {0034-4257},
doi = {https://doi.org/10.1016/j.rse.2019.111605},
url = {https://www.sciencedirect.com/science/article/pii/S003442571930625X},
author = {Ji Zhao and Yanfei Zhong and Xin Hu and Lifei Wei and Liangpei Zhang},
keywords = {Conditional random fields, Land cover, Image classification, Hyperspectral imagery, Smallholder agriculture, Spectral-spatial classification},
abstract = {Heterogeneous crop identification has been the subject of much concern, since smallholder farms less than 1 ha are the main agricultural form in many areas, especially China. Remote sensing with high spectral and spatial resolutions via aerial platforms such as unmanned aerial vehicles (UAV) provides a potential alternative technique for the monitoring of heterogeneous crops in smallholder agriculture. Although this new type of remote sensing data with high spectral and spatial resolutions provides the possibility of fine classification, it also brings some challenges, such as bands contaminated with severe noise, the nonuniform distribution of the discriminative spectral information, and the spectral variability of crops. In this study, we attempted to resolve these problems by developing a robust spectral-spatial agricultural crop mapping method based on conditional random fields (SCRF), which learns the sensitive spectral information of the crops by a spectrally weighted kernel, and uses the spatial interaction of pixels to improve the classification performance. Data from a manned aircraft platform and a UAV platform were chosen to validate the effectiveness of the proposed algorithm. The experimental results showed that the proposed algorithm can effectively use the relative utility of each spectral band to detect the bands contaminated with severe noise, and it uses the spectrally weighted kernel to consider the sensitive spectral information of the crops. The algorithm with only a spectrally weighted kernel showed an improvement of more than 4% over the classical support vector machine and random forest methods. Moreover, the spatial information was proved to be of crucial importance for crop classification, and both the object-oriented method and the proposed SCRF method can improve the classification performance in terms of both visualization and the quantitative metrics by considering the spatial information. Compared with the object-oriented method, SCRF can deliver a better classification performance, with an accuracy improvement of more than 2%.}
}
@article{TAURO2022112771,
title = {Latent heat flux variability and response to drought stress of black poplar: A multi-platform multi-sensor remote and proximal sensing approach to relieve the data scarcity bottleneck},
journal = {Remote Sensing of Environment},
volume = {268},
pages = {112771},
year = {2022},
issn = {0034-4257},
doi = {https://doi.org/10.1016/j.rse.2021.112771},
url = {https://www.sciencedirect.com/science/article/pii/S0034425721004910},
author = {Flavia Tauro and Antonino Maltese and Roberto Giannini and Antoine Harfouche},
keywords = {Evapotranspiration, Multi-platform, multi-resolution, Priestley-Taylor equation, satellite remote sensing, UAV remote sensing},
abstract = {High-throughput mapping of latent heat flux (λET) is critical to efforts to optimize water resources management and to accelerate forest tree breeding for improved drought tolerance. Ideally, investigation of the energy response at the tree level may promote tailored irrigation strategies and, thus, maximize crop biomass productivity. However, data availability is limited and planning experimental campaigns in the field can be highly operationally complex. To this end, a multi-platform multi-sensor observational approach is herein developed to dissect the λET signature of a black poplar (Populus nigra) breeding population (“POP6”) at the canopy level. POP6 comprised more than 4600 trees representing 503 replicated genotypes, whose parents were derived from contrasting environmental conditions. Trees were trialed in two adjacent plots where different irrigation treatments (moderate drought [mDr] and well-watered [WW]) were applied. Data collected from satellite and unmanned aerial vehicles (UAVs) remote sensing as well as from ground-based proximal sensors were integrated at consistent spatial aggregation and combined to compute the surface energy balance of the trees through a modified Priestley-Taylor method. Here, we demonstrated that λET response was significantly different between WW and mDr trees, whereby genotypes in mDr conditions exhibited larger standard deviations. Importantly, genotypes classified as drought tolerant based on the stress susceptibility index (SSI) presented λET values significantly higher than the rest of the population. This study confirmed that water limitation in mDr settings led to reduced soil moisture in the tree root zone and, thus, to lower λET. These results pave the way to breeding poplar and other bioenergy crops with this underexploited trait for higher λET. Most notably, the illustrated work demonstrates a multi-platform multi-sensor data fusion approach to tackle the global challenge of monitoring landscape-scale ecosystem processes at fine resolution.}
}
@article{YUCESAN2021101404,
title = {A survey of modeling for prognosis and health management of industrial equipment},
journal = {Advanced Engineering Informatics},
volume = {50},
pages = {101404},
year = {2021},
issn = {1474-0346},
doi = {https://doi.org/10.1016/j.aei.2021.101404},
url = {https://www.sciencedirect.com/science/article/pii/S1474034621001567},
author = {Yigit A. Yucesan and Arinan Dourado and Felipe A.C. Viana},
keywords = {Prognosis and health management, Services engineering, Applied machine learning},
abstract = {Prognosis and health management plays an important role in the control of costs associated with operating large industrial equipment, such as wind turbines and aircraft. It is only fair that engineers and scientists have vastly researched modeling approaches to support decision making. Motivated by the growing availability of data and computational power as well as the advances in algorithms and methods, modeling frameworks often merge elements of physics, machine learning, and statistical learning. In this paper, we present a review on modeling in support of prognosis and health management of industrial equipment. This survey complements the existing prognosis and health management literature by discussing how modeling strategies are influenced by industry-specific aspects such as maintenance approaches (e.g., reactive, proactive, and predictive), implementation factors (e.g., industry, business model, purpose, development, and deployment), as well as supporting technologies (sensing, repair, and modeling itself). We use the onshore wind energy and civil aviation industries to illustrate how these aforementioned aspects can influence modeling and implementation of prognosis and health management. The literature review is broad and covers contributions over the past 40 years. We close the paper with few topics that can motive research going forward.}
}
@article{AQUILANI2022100429,
title = {Review: Precision Livestock Farming technologies in pasture-based livestock systems},
journal = {Animal},
volume = {16},
number = {1},
pages = {100429},
year = {2022},
issn = {1751-7311},
doi = {https://doi.org/10.1016/j.animal.2021.100429},
url = {https://www.sciencedirect.com/science/article/pii/S1751731121002755},
author = {C. Aquilani and A. Confessore and R. Bozzi and F. Sirtori and C. Pugliese},
keywords = {Accelerometer, Extensive, Remote sensing, Ruminants, Virtual fencing},
abstract = {Precision Livestock Farming (PLF) encompasses the combined application of single technologies or multiple tools in integrated systems for real-time and individual monitoring of livestock. In grazing systems, some PLF applications could substantially improve farmers’ control of livestock by overcoming issues related to pasture utilisation and management, and animal monitoring and control. A focused literature review was carried out to identify technologies already applied or at an advanced stage of development for livestock management in pastures, specifically cattle, sheep, goats, pigs, poultry. Applications of PLF in pasture-based systems were examined for cattle, sheep, goats, pigs, and poultry. The earliest technology applied to livestock was the radio frequency identification tag, allowing the identification of individuals, but also for retrieving important information such as maternal pedigree. Walk-over-weigh platforms were used to record individual and flock weights. Coupled with automatic drafting systems, they were tested to divide the animals according to their needs. Few studies have dealt with remote body temperature assessment, although the use of thermography is spreading to monitor both intensively reared and wild animals. Global positioning system and accelerometers are among the most applied technologies, with several solutions available on the market. These tools are used for several purposes, such as animal location, theft prevention, assessment of activity budget, behaviour, and feed intake of grazing animals, as well as for reproduction monitoring (i.e., oestrus, calving, or lambing). Remote sensing by satellite images or unmanned aerial vehicles (UAVs) seems promising for biomass assessment and herd management based on pasture availability, and some attempts to use UAVs to monitor, track, or even muster animals have been reported recently. Virtual fencing is among the upcoming technologies aimed at grazing management. This system allows the management of animals at pasture without physical fences but relies on associative learning between audio cues and an electric shock delivered if the animal does not change direction after the acoustic warning. Regardless of the different technologies applied, some common constraints have been reported on the application of PLF in grazing systems, especially when compared with indoor or confined livestock systems. Battery lifespan, transmission range, service coverage, storage capacity, and economic affordability were the main factors. However, even if the awareness of the existence and the potential of these upcoming tools are still limited, farmers’ and researchers’ demands are increasing, and positive outcomes in terms of rangeland conservation, animal welfare, and labour optimisation are expected from the spread of PLF in grazing systems.}
}
@article{ZOU2019221,
title = {CNN-based statistics and location estimation of missing components in routine inspection of historic buildings},
journal = {Journal of Cultural Heritage},
volume = {38},
pages = {221-230},
year = {2019},
issn = {1296-2074},
doi = {https://doi.org/10.1016/j.culher.2019.02.002},
url = {https://www.sciencedirect.com/science/article/pii/S1296207418306757},
author = {Zheng Zou and Xuefeng Zhao and Peng Zhao and Fei Qi and Niannian Wang},
keywords = {Historic building, Deep learning, CNN, Faster R-CNN, Missing components, Object detection, Intelligent inspection},
abstract = {Ancient buildings have a high cultural and historical value. In the process of their protection and maintenance, it is crucial to conduct regular routine inspections on them. During the regular routine inspections, the identification and statistics for components on historic buildings are of great significance to conservators, managers and visitors. However, the current identification and statistics work is almost carried out by human eyes, which is time consuming and labor intensive. Actually, this work can be done by artificial intelligence. In order to promote the intelligent development of routine inspections of historic buildings, this paper proposes a methodology in the case of the Forbidden City to identify and count the numbers of intact and impaired components based on Convolutional Neural Network. The applied algorithm is Faster R-CNN, which is an effective object detection algorithm for 2D images. In addition, the positions of the missing components can be inferred and marked in the images as their regularity of the positional arrangement. This methodology can lay the foundation for the subsequent intelligent inspection system of the historic buildings.}
}
@article{SUN2021106638,
title = {Flight quality characteristics and observer-based anti-windup finite-time terminal sliding mode attitude control of aileron-free full-wing configuration UAV},
journal = {Aerospace Science and Technology},
volume = {112},
pages = {106638},
year = {2021},
issn = {1270-9638},
doi = {https://doi.org/10.1016/j.ast.2021.106638},
url = {https://www.sciencedirect.com/science/article/pii/S1270963821001486},
author = {Ruijie Sun and Zhou Zhou and Xiaoping Zhu},
keywords = {Aileron-free full-wing configuration UAV, Flight quality characteristics, Finite-time terminal sliding mode control, Anti-windup compensator, Adaptive super-twisting disturbance observer, Control allocation},
abstract = {This paper evaluates the flight quality of an aileron-free full-wing configuration UAV and proposes a highly robust attitude controller considering the typical control problems (i.e., manipulation saturation, coupling, susceptibility to the disturbance, nonlinearity, and uncertainty) of the aileron-free full-wing configuration UAV. First, the flight quality characteristics are analyzed through the change of the flight modes at different trim state points in the flight envelope. Then, the back-stepping method is introduced for decoupling and systematic control law design. Based on the Lagrange multiplier approach, the pseudoinverse control allocation is adopted to realize command decoupling and acquire the minimal 2-norm control output. In order to improve the robustness and control accuracy of the controller, a novel continuous finite-time terminal sliding mode control scheme with adaptive law is designed, which has the virtue of suppressing the chattering and avoiding singularity. In addition, an anti-windup compensator (AWC) is developed to ensure the stability of the flight state under manipulation saturation and make the manipulation output exit the saturation region quickly. To further solve the problem that the aileron-free full-wing configuration UAV is susceptible to disturbances, an adaptive super-twisting disturbance observer (ASTDO) is designed to estimate and compensate the uncertain compound disturbance including the uncertain time-varying disturbance and nonlinear dynamic term to improve control performance. The proposed observer can suppress chattering, adjust gain parameters adaptively and have high observation accuracy. Based on the Lyapunov stability theorem, the anti-windup compensation variable in the AWC and the disturbance estimation error in the ASTDO can gradually converge to neighborhoods of the equilibrium points in finite time. Moreover, the practical finite-time stability of the closed-loop control system is proved. According to the flight quality evaluation, the aileron-free full-wing configuration UAV has poor flight quality at the boundary of the flight envelope and exhibits inherent longitudinal high-frequency oscillation characteristics. The simulation results demonstrate that the designed ASTDO-AWFTTSMC guarantees strong robustness, high accuracy, and fast convergence speed for attitude tracking, solves the saturation problem and realizes state decoupling and manipulation decoupling. Moreover, the designed controller overcomes the adverse effects of disturbance, nonlinearity, and uncertainty, greatly suppresses the longitudinal high-frequency oscillation and still exhibits excellent control performance at the flight state points on the flight envelope boundary.}
}
@article{WALHA201372,
title = {Video Stabilization for Aerial Video Surveillance},
journal = {AASRI Procedia},
volume = {4},
pages = {72-77},
year = {2013},
note = {2013 AASRI Conference on Intelligent Systems and Control},
issn = {2212-6716},
doi = {https://doi.org/10.1016/j.aasri.2013.10.012},
url = {https://www.sciencedirect.com/science/article/pii/S2212671613000139},
author = {Ahlem Walha and Ali Wali and Adel M. Alimi},
keywords = {Aerial Video stabilization, kalman filtering, Motion estimation, Scal Invariant feature transform},
abstract = {Aerial video stabilization system aims to remove undesired motion in aerial v deo. This motion is the result of undesired movement of mobile sensor. In this article we present a new video stabilization system for Unmanned Aerial Vehicles (UAV). Our system is based on keypoints tracking. We use Scale Invariant Feature Transform (SIFT) keypoint detection, and matching to estimate parameters of affine transformation model. Then, Kalman filter with median filter is applied to remove video noise. A number of real aerials videos surveillances demonstrate that this method can achieve good performance.}
}
@article{SARPAL2022104447,
title = {AgriWealth: IoT based Farming System},
journal = {Microprocessors and Microsystems},
pages = {104447},
year = {2022},
issn = {0141-9331},
doi = {https://doi.org/10.1016/j.micpro.2022.104447},
url = {https://www.sciencedirect.com/science/article/pii/S0141933122000217},
author = {Deepika Sarpal and Raka Sinha and Madhavi Jha and T.N. Padmini},
keywords = {AgriWealth (AW), Internet of Things(IoT), Embedded Systems, Machine Learning(ML), Smart Farming System (SFS), Android Application, Firebase},
abstract = {ABSTRACT
The agricultural sector in India accounts for a significant part of the country's GDP and is the primary income source for many farmers in rural areas. While it creates employment opportunities and offers food security for the entire nation, the lack of infrastructure and resources might be limiting its potential to thrive further. One of the aspects addressed in this paper is low yield production. With the aid of a sensor-based irrigation model, data is collected and analyzed in the cloud to enable real-time monitoring. It is then integrated with an Android application for displaying results in an user-friendly interface. Through the application, farmers can control the farm manually, or with a timer in minutes. The Machine Learning model predicts the suitable crops, in accordance with varying weather parameters. The application has a classified portal for farmers and customers to buy/sell directly, eliminating any involvement of mediators. One of the novelties in this research includes monitoring/controlling farm equipment and predicting field crops from a locally installed LCD display and keypad present in farmer's respective homes. The proposed work aims to create an energy-efficient, user-friendly framework for the agricultural workforce, yielding better crop production, improving farmers' living standards, and contributing effectively to the nation's economic growth. The prototype shows a reduction of water usage in fields by more than 60%. In order to incorporate the model with the best behaviour in Android Application, different Machine Learning algorithms have been studied, among which Random Forest has been selected with a test accuracy of 91.59%.}
}
@article{OUBBATI201729,
title = {A survey on position-based routing protocols for Flying Ad hoc Networks (FANETs)},
journal = {Vehicular Communications},
volume = {10},
pages = {29-56},
year = {2017},
issn = {2214-2096},
doi = {https://doi.org/10.1016/j.vehcom.2017.10.003},
url = {https://www.sciencedirect.com/science/article/pii/S2214209617300529},
author = {Omar Sami Oubbati and Abderrahmane Lakas and Fen Zhou and Mesut Güneş and Mohamed Bachir Yagoubi},
keywords = {Flying Ad hoc Networks (FANETs), Vehicular Ad hoc Networks (VANET), Routing protocols, Unmanned Aerial Vehicles (UAVs), Geographical position},
abstract = {The last decade has seen a growing interest in the use of Unmanned Aerial Vehicles (UAVs) for various applications and services. UAVs, or drones as referred to, have shown to be efficient in completing complex tasks when organized as ad hoc connected groups, thus forming a Flying Ad hoc Network (FANET). Although similar to Mobile Ad hoc Network (MANET) and Vehicular Ad hoc Network (VANET), FANETs have their own characteristics. One of the main difference is the fact that UAVs in general, but particularly when organized are FANETs, are mission-based, and their mobility models are often dictated by the purpose of their mission and the nature of the task they plan to accomplish. Therefore, routing protocols for FANETs should take into consideration the nature of the applications and services that the UAVs are deployed for, and factor in the mobility models. However, designing routing protocols for FANETs is not an easy task given the highly dynamic topology of FANETs and the flying constraints they are subjected to. Compared to topology-based routing, position-based routing demonstrated high efficiency and resilience to handle the high mobility of FANET nodes. To this end, in this paper, we propose a comprehensive survey of position-based routing protocols for FANETs with their various categories. We propose a classification and a taxonomy of these protocols, including a detailed description of the routing schemes used in each category. We propose a comparative study based on various criteria, and discuss the advantages and weaknesses of each protocol. Furthermore, new challenges for future research are presented, which introduce a new kind of coordination between UAVs and existing VANETs on the ground. The originality of this survey is that it complements the existing surveys on the same theme by providing more details on some aspects that have been addressed only ostensibly by other surveys in the literature.}
}
@article{CHEN2021102450,
title = {Identification of outcropping strata from UAV oblique photogrammetric data using a spatial case-based reasoning model},
journal = {International Journal of Applied Earth Observation and Geoinformation},
volume = {103},
pages = {102450},
year = {2021},
issn = {0303-2434},
doi = {https://doi.org/10.1016/j.jag.2021.102450},
url = {https://www.sciencedirect.com/science/article/pii/S0303243421001574},
author = {Jianhua Chen and Bingqian Wang and Feng Wang and Mingcai Hou and Zuowei Hu},
keywords = {Stratum identification, Oblique photogrammetric data, Spatial features, Similarity reasoning, Object extraction},
abstract = {Due to the large scale and complex terrain of some outcrops, it is difficult to carry out comprehensive and detailed stratum identification using traditional geological methods. The emergence of oblique photogrammetry technology provides a new way to construct high-precision 3D models of outcrops, but the existing object extraction methods of 3D models cannot be applied to the differentiation of strata in an outcrop. Therefore, this paper proposes a novel identification method for outcropping strata from oblique photogrammetric data using a spatial case-based reasoning (SCBR) model. The method includes (a) constructing point cloud of the outcrop based on the photogrammetric data; (b) segmenting the point cloud into voxels; (c) creating an integrated expression of the spatial and attribute features of a stratum case; (d) creating an integrated similarity reasoning model of the spatial and attribute features; and (e) dividing the strata after reasoning. Furthermore, this study carried out stratum identification experiments on two cases of study in Fugu, Shaanxi, China. After Performing the SCBR model, the overall accuracies were found to reach 94%. After the stratum division after reasoning was carried out, the verification accuracies were found to exceed 99%. Based on the results of the manual stratum differentiation, the differentiation results of the proposed SCBR model were found to be much more consistent with the actual situation. The experiments show that the proposed method is very effective for differentiating outcropping strata and provides a new approach for the extraction of 3D objects generated with oblique photogrammetric data.}
}
@article{CHEN2014436,
title = {Robust tracking control for uncertain MIMO nonlinear systems with input saturation using RWNNDO},
journal = {Neurocomputing},
volume = {144},
pages = {436-447},
year = {2014},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2014.04.032},
url = {https://www.sciencedirect.com/science/article/pii/S0925231214006195},
author = {Mou Chen and Yanlong Zhou and William W. Guo},
keywords = {Nonlinear system, Unmanned aerial vehicle, Input saturation, Recurrent wavelet neural network, Disturbance observer, Dynamic surface control},
abstract = {In this paper, the robust tracking control scheme is proposed for a class of uncertain multi-input and multi-output (MIMO) nonlinear systems with input saturation and unknown external disturbance based on the recurrent wavelet neural network disturbance observer (RWNNDO) and the backstepping technique. And then, the developed robust tracking control scheme is applied to an unmanned aerial vehicle (UAV) system. To handle the input saturation, a hyperbolic tangent function and a Nussbaum function are employed, and the dynamic surface method is applied to solve the problem of “explosion of complexity” in backstepping control. It is proved that the proposed control scheme can guarantee that all signals of the closed-loop system are bounded through the Lyapunov analysis. Simulation results are presented to demonstrate the effectiveness of the proposed control scheme for uncertain MIMO nonlinear systems.}
}
@article{ROMINGER2021126020,
title = {Using drone imagery analysis in rare plant demographic studies},
journal = {Journal for Nature Conservation},
volume = {62},
pages = {126020},
year = {2021},
issn = {1617-1381},
doi = {https://doi.org/10.1016/j.jnc.2021.126020},
url = {https://www.sciencedirect.com/science/article/pii/S1617138121000674},
author = {Kody R. Rominger and Alyson DeNittis and Susan E. Meyer},
keywords = {, Dwarf bear poppy, Population monitoring, Rare plant conservation, Unmanned aerial vehicle (UAV)},
abstract = {For plant species of conservation concern, knowledge of changes in abundance through time is a minimum requirement for informed management. This information is usually acquired through on-the-ground monitoring, which entails counting individuals in defined areas over multiple years. Demographic studies, which involve tracking individual plants through time, are usually carried out at limited spatial scales and over shorter time frames than monitoring, but are more useful to management. In this study we explored the use of drone (UAV or unmanned aerial vehicle) imagery analysis as a tool for collecting demographic data for dwarf bear poppy (Arctomecon humilis), an endangered species restricted to gypsum outcrops in the northeastern Mojave Desert, USA. We obtained imagery at 15 m altitude during peak flowering at four populations in spring 2019. Each poppy plant in the imagery was georeferenced, measured and scored for flowering. To estimate reproductive output, we developed independent data sets relating plant diameter to flower number, then sampled to determine mean fruit set per flower and seeds per fruit. We used these relationships along with plant diameter and reproductive status for each plant in the drone imagery to estimate seed rain on an area basis across nine 0.6 ha demography plots at each population. This method enabled us to collect demographic data on >3,000 plants, including estimated production of ca. 3.7 million seeds, across >20 ha of habitat. We also analyzed imagery acquired in both 2018 and 2019 at two of the four populations and quantified recruitment, growth, and mortality of individual georeferenced plants. Our study is among the first to demonstrate the utility of drone imagery analysis in plant demographic studies. The method is most applicable for non-clonal perennial species with distinctive morphology that occur in habitats with low vegetative cover.}
}
@article{HOU2020105716,
title = {Nonsingular terminal sliding mode control for a quadrotor UAV with a total rotor failure},
journal = {Aerospace Science and Technology},
volume = {98},
pages = {105716},
year = {2020},
issn = {1270-9638},
doi = {https://doi.org/10.1016/j.ast.2020.105716},
url = {https://www.sciencedirect.com/science/article/pii/S1270963819316414},
author = {Zhiwei Hou and Peng Lu and Zhangjie Tu},
keywords = {Quadrotor UAV, Terminal sliding mode control, Fault-tolerant control, Model uncertainty, Wind disturbance},
abstract = {Based on nonsingular terminal sliding mode control (NTSMC), a flight controller is proposed in this paper for a quadrotor with a total rotor failure. The proposed method is a finite-time position and attitude tracking approach with strong robustness. At first, the fault-tolerant controller for the quadrotor with a total rotor failure is derived, and the model uncertainties and wind disturbances are considered. The dynamic model of the quadrotor is introduced and divided into two control loops: the inner control loop and the outer control loop. Based on the division of the control system, the NTSMC based inner controller is designed which makes the attitude dynamics converge to the desired attitude in finite-time. And the NTSMC based outer controller is derived which generates the desired attitude for the inner controller and makes the dynamics converge to the desired position in finite-time. The stability of the closed-loop system is analyzed by Lyapunov theory and the stability conditions are obtained. Then, in order to improve the practicability of the control algorithm, a flight controller for a fault-free quadrotor is proposed which has a similar structure compared with the fault-tolerant one. A fault detection and isolation method is applied to detect the fault and reconfigure the flight controllers. Moreover, two estimation methods for external disturbance and model uncertainties are applied to enhance the robustness of the proposed flight controller. The estimated wind disturbances results are introduced into the outer controller to compensate for the effect of disturbance while the model uncertainties estimator is applied in the inner control loop. Finally, numerical simulation results show the great performance of the proposed flight control method.}
}
@article{ABID2021108583,
title = {A survey on recent contention-free MAC protocols for static and mobile wireless decentralized networks in IoT},
journal = {Computer Networks},
volume = {201},
pages = {108583},
year = {2021},
issn = {1389-1286},
doi = {https://doi.org/10.1016/j.comnet.2021.108583},
url = {https://www.sciencedirect.com/science/article/pii/S1389128621004886},
author = {Khaled Abid and Hicham Lakhlef and Abdelmadjid Bouabdallah},
keywords = {IoT, Wireless networks, Decentralized network, Communicating things, MANET, VANET, FANET, UAV, Slot-access, Contention-free, Medium Access Control, TDMA, FDMA, Network mobility, Distributed learning, Game theory, Self-organizing network, Delay tolerant network},
abstract = {Medium Access Control (MAC) protocols for wireless decentralized networks in IoT have attracted a lot of attention in both academic and industrial fields. They aim to coordinate access among IoT devices to the shared wireless medium. More specifically, contention-free MAC protocols are known to be more efficient than contention-based ones in the case of high traffic load and dense networks. To face the main communication challenges between IoT devices such as collisions and conflicts as well as mobility, it is crucial to design an efficient MAC protocol. To do so, several solutions have been proposed in the literature. Among recent proposed solutions, Machine Learning (ML) algorithms and game theory models were used to revolutionize the communication in IoT networks, especially for devices with high mobility degree. In our survey, we first start by studying the challenges and requirements of communication in wireless networks. Then, we provide a comprehensive survey on recent contention-free MAC protocols existing in the literature. Next, we compare these solutions based on important metrics such as QoS, robustness, fairness etc., and discuss the relationship between MAC protocols, network type and network mobility. Finally, we investigate a future research direction to solve a major problem, which is the network disruption and delay tolerance in IoT wireless mobile networks.}
}
@article{YOU2020106490,
title = {Target tracking strategy using deep deterministic policy gradient},
journal = {Applied Soft Computing},
volume = {95},
pages = {106490},
year = {2020},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2020.106490},
url = {https://www.sciencedirect.com/science/article/pii/S1568494620304294},
author = {Shixun You and Ming Diao and Lipeng Gao and Fulong Zhang and Huan Wang},
keywords = {Deep deterministic policy gradient, Cognitive electronic warfare, Reinforcement learning, Motion planning, Target tracking},
abstract = {To address the challenge of maintaining high robustness of target tracking in a 3D dynamic high-altitude scenario, this paper presents a method to formulate continuous strategic maneuvers for unmanned combat air vehicles (UCAVs) based on deep deterministic policy gradient (DDPG). DDPG is an efficient reinforcement learning approach that helps UCAV perform a variety of navigation tasks in real-time in a dynamic and random electronic warfare environment, and therefore possesses clear advantages over other technologies. First, create a target tracking simulator, Tracker, in the cognitive electronic warfare framework, and conduct a theoretical analysis of maneuvering bias produced by environmental observational errors. Tracker can automatically correlate the maximum physical overload with UCAV’s attitude angles and desired movement commands. Second, shape the agent’s behavior rewards under the inspiration of vector-based navigation to ensure that the DDPG’s output is reliable. Finally, a DRL-based navigation decision framework is employed to validate the simulation for target tracking tasks in different environments and bring excellent results. In terms of behavior assessment, the agile maneuvers mastered by the agent are dissected by time segmentation of high-quality trajectories.}
}
@article{WANG2022199,
title = {Joint resource management for mobility supported federated learning in Internet of Vehicles},
journal = {Future Generation Computer Systems},
volume = {129},
pages = {199-211},
year = {2022},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2021.11.020},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X2100457X},
author = {Ge Wang and Fangmin Xu and Hengsheng Zhang and Chenglin Zhao},
keywords = {Internet of Vehicles, Federated learning, Multi-access Edge Computing, Distributed dynamic resource management, Multi-agent deep reinforcement learning},
abstract = {In recent years, the powerful combination of Multi-access Edge Computing (MEC) and Artificial Intelligence (AI), called edge intelligence, promotes the development of Intelligent Transportation Systems (ITS). However, there is a mismatch between the ever-increasing consumer privacy awareness and the data leakage risk in centralized AI training solutions in vehicular edge scenarios, which has become a new obstacle to satisfying the user experience. As a promising privacy-preserving paradigm, federated learning synthesizes a global model only with the parameters of decentralized trained local models, avoiding the exposure of sensitive data. Given this, we introduce federated learning into the proposed two-level MEC-assisted vehicular network framework. This paper aims to address the challenges posed by adopting federated learning into the Internet of Vehicles (IoV) scenario. Firstly, as the entity of the participant (the local model training node of federated learning), vehicles have high mobility. We design a mobility supported federated learning participant decision algorithm to pick out participants from candidate vehicles. Secondly, federated learning is rather resource-consuming, inevitably incurring considerable costs to participants. We focus on the joint resource allocation problem to optimize the federated learning cost. Finally, considering the limitations of centralized resource allocation, we propose a fully distributed resource allocation method inspired by multi-agent deep reinforcement learning. Simulation results are presented to demonstrate the feasibility and effectiveness of the proposed schemes.}
}
@article{ZHANG20201,
title = {Finite horizon state estimation for time-varying neural networks with sensor failure and energy constraint},
journal = {Neurocomputing},
volume = {372},
pages = {1-7},
year = {2020},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2019.09.006},
url = {https://www.sciencedirect.com/science/article/pii/S0925231219312664},
author = {Bin Zhang and Hongxia Rao and Yunsong Deng and Hao Wu and Yinxia Zhu},
keywords = {Time-varying neural networks, State estimator, Sensor failure, Sensor energy constraint, Packet dropouts},
abstract = {This work studies state estimation for time-varying neural networks (NNs) with sensor failure and energy constraint over finite horizon. The diagonal matrices are introduced to describe the phenomenon of sensor failure, it is then handled by transformed into norm bounded uncertainty. In order to reduce the energy cost, a new transmission strategy is proposed, that is, the measurements firstly transmit using low energy with high packet dropout rate, if the measurements are dropped then the high energy is employed to reduce the packet dropout rate. Sufficient conditions are obtained to ensure that the augmented system satisfies the l2−l∞ performance over finite-horizon, and the estimator gain design algorithm is proposed. At last, a numerical example is shown to verify the derived results.}
}
@article{WOO2021120852,
title = {Understanding the long-term emergence of autonomous vehicles technologies},
journal = {Technological Forecasting and Social Change},
volume = {170},
pages = {120852},
year = {2021},
issn = {0040-1625},
doi = {https://doi.org/10.1016/j.techfore.2021.120852},
url = {https://www.sciencedirect.com/science/article/pii/S0040162521002845},
author = {Seokkyun Woo and Jan Youtie and Ingrid Ott and Fenja Scheu},
keywords = {Autonomous vehicles, Emerging technologies, Technology emergence indicator, Word-embedding},
abstract = {Identifying emerging technologies has been of long-standing interest to many scholars and practitioners. Previous studies have introduced methods to capture the concept of emergence from bibliographic records, including the recently proposed Technology Emergence Indicator (Carley et al. 2018). This indicator method has shown to be applicable to various technological fields. However, the indicator uses a limited time window, which can overlook the potential long-term evolution of emerging technologies. Moreover, the existing method suffers from interpretability, because it can be difficult to understand the context in which identified emerging terms are used. In this paper, we propose an improved version of the Technology Emergence Indicator that addresses these issues. In doing so, we examine emerging topics within the field of autonomous vehicles technologies during the period of 1991-2018, guided by a proposition about the long-term diffusion of an emerging technology topic. The results show that different autonomous vehicle technology topics emerge during each of the three 10-year periods under analysis, including an initial period of understanding the surrounding environment and path planning, a second period marked by DARPA Grand Challenge motivated factors associated with the urban environment and communication technologies, and a third period relating to machine learning and object detection. This association with certain emerging technology topics in each decade is also characterized by different trajectories of continued or cyclical carryover across the decades. The results suggest a methodology that practitioners can use in examining research areas to understand which topics are likely to persist into the future.}
}
@article{LU2019537,
title = {Functions of traditional ponds in altering sediment budgets in the hilly area of the Three Gorges Reservoir, China},
journal = {Science of The Total Environment},
volume = {658},
pages = {537-549},
year = {2019},
issn = {0048-9697},
doi = {https://doi.org/10.1016/j.scitotenv.2018.12.017},
url = {https://www.sciencedirect.com/science/article/pii/S0048969718348575},
author = {Mingquan Lü and Maohua Ma and Yu Wang and Chundi Chen and Jilong Chen and Shengjun Wu},
keywords = {Sediment yield, Multi-pond system, WaTEM/SEDEM, Three Gorges reservoir area, Unmanned aerial vehicles imagery},
abstract = {The landscape pattern will affect the sediment transport process. The cluster of ponds is a common landscape, which has traditionally been used for irrigation in the hilly area of the Three Gorges Reservoir (TGR). However, little is known about how the landscape elements temporally changed over the past decades and if the ponds can be applied to function in balancing watershed sediments against soil erosion. The Jinglingxi watershed, covering 20.5 km2, was selected as the study area. The changes in pond number, surface area, and drainage catchment were analyzed with aid of high-resolution typographical map and unmanned aerial vehicles imagery. The spatial WaTEM/SEDEM model was developed to simulate watershed soil erosion and sediment deposition under the absence and presence of water bodies scenarios. Results from different simulation scenarios were compared and revealed the trapping effects of the multi-pond system. From 1983 to 2016, the number and total area of ponds roughly doubled. The density reached 30 ponds/km2. From 1983 to 2016, the total drainage area of ponds increased from 13.22% to 35.4% of the whole watershed. The sediments deposited at the bottom of ponds can indicate the past specific sediment yield (SSY) in drainage catchments. Our results suggest that the multi-pond system not only reduce watershed sediment export but also alter the sediment deposition in different land uses. The reduced sediments export is expected to prolong the service life of downstream reservoirs at the expectancy of ponds' storage capacities. The ecological compensation from downstream reservoirs' revenues to upstream regions should be established to drive dredging actions for the upstream ponds.}
}
@article{MOHDDAUD202230,
title = {Applications of drone in disaster management: A scoping review},
journal = {Science & Justice},
volume = {62},
number = {1},
pages = {30-42},
year = {2022},
issn = {1355-0306},
doi = {https://doi.org/10.1016/j.scijus.2021.11.002},
url = {https://www.sciencedirect.com/science/article/pii/S1355030621001477},
author = {Sharifah Mastura Syed {Mohd Daud} and Mohd Yusmiaidil Putera {Mohd Yusof} and Chong Chin Heo and Lay See Khoo and Mansharan Kaur {Chainchel Singh} and Mohd Shah Mahmood and Hapizah Nawawi},
keywords = {Disaster, Drones, UAV, Humanitarian aid},
abstract = {The use of drones has rapidly evolved over the past decade involving a variety of fields ranging from agriculture, commercial and becoming increasingly used in disaster management or humanitarian aid. Unfortunately, the evidence of its use in mass disasters is still unclear and scarce. This article aims to evaluate the current drone feasibility projects and to discuss a number of challenges related to the deployment of drones in mass disasters in the hopes of empowering and inspiring possible future work. This research follows Arksey and O'Malley framework and updated by Joanna Briggs Institute Framework for Scoping Reviews methodology to summarise the results of 52 research papers over the past ten years, from 2009 to 2020, outlining the research trend of drone application in disaster. A literature search was performed in Medline, CINAHL, Scopus, individual journals, grey literature and google search with assessment based on their content and significance. Potential application of drones in disaster are broad. Based on articles identified, drone application in disasters are classified into four categories; (1) mapping or disaster management which has shown the highest contribution, (2) search and rescue, (3) transportation and (4) training. Although there is a significant increase in the number of publications on use of drone in disaster within the last five years, there is however limited discussion to address post-disaster healthcare situation especially with regards to disaster victim identification. It is evident that drone applications need to be further explored; to focus more on drone assistance to humans especially in victim identification. It is envisaged that with sufficient development, the application of drones appears to be promising and will improve their effectiveness especially in disaster management.}
}
@article{JACKSON2020658,
title = {Season, Classifier, and Spatial Resolution Impact Honey Mesquite and Yellow Bluestem Detection using an Unmanned Aerial System},
journal = {Rangeland Ecology & Management},
volume = {73},
number = {5},
pages = {658-672},
year = {2020},
issn = {1550-7424},
doi = {https://doi.org/10.1016/j.rama.2020.06.010},
url = {https://www.sciencedirect.com/science/article/pii/S1550742420300762},
author = {Matthew Jackson and Carlos Portillo-Quintero and Robert Cox and Glen Ritchie and Mark Johnson and Kamal Humagain and Mukti Ram Subedi},
keywords = {Honey mesquite, Rangelands, Remote sensing, Texas, UAV, Yellow bluestem},
abstract = {In Texas, mesquite and yellow-bluestem invasions are widespread. Identifying and monitoring juvenile and adult plants using high-resolution imagery from airborne sensors while they colonize new areas across the landscape can help land managers prioritize locations for treatment and eradication. In this study, we evaluated how data collection design using an unmanned aerial system (UAS) can affect plant detection and mapping. We used a Phantom 3 Professional unmanned aerial vehicle with a Parrot Sequoia multispectral camera for detecting and mapping native honey mesquite (Prosopis glandulosa) and non-native yellow bluestem (Bothriochloa ischaemum) at a rangeland site in northwest Texas. Flights were conducted seasonally during the period from summer 2017 to fall 2018 to test the seasonal impact of detecting plant species. Flights were conducted at altitudes of 30, 60, and 100 m, and four image classification techniques were tested to determine their viability of detecting distinct plant species. Results suggest that flights at 100-m aircraft altitude during the spring season are more effective (>80% user accuracies) for mapping mesquite canopies based on reflectance values and image segmentation information. Yellow bluestem mapping accuracies were low (< 20% user accuracies). Lower spatial resolution (100-m altitude flights, 12-cm pixel resolution) provided less noise and more generalization capabilities for the image classification methods. Overall, random forests and Support Vector Machine classification algorithms outperformed probability-based image classifiers. Land owners and rangeland ecologists using their own UAS in rangeland management can use this information to plan their data collection campaigns before the application of chemical treatments or manual eradication.}
}
@article{LIU2021101213,
title = {Identification of plant species in an alpine steppe of Northern Tibet using close-range hyperspectral imagery},
journal = {Ecological Informatics},
volume = {61},
pages = {101213},
year = {2021},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2021.101213},
url = {https://www.sciencedirect.com/science/article/pii/S1574954121000042},
author = {Enqin Liu and Hui Zhao and Shuhui Zhang and Jing He and Xin Yang and Xiangming Xiao},
keywords = {Plant species, Spectral indices, Alpine steppe, Random Forest, Northern Tibet},
abstract = {The identification of plant species in alpine steppes of Northern Tibet is of great significance for revealing community structures and for monitoring vegetation degradation and restoration from remote sensing images. Plants in the alpine steppe of Northern Tibet are short, sparse, and highly heterogeneous in spatial distribution. This peculiarity makes the plant species identification here much more difficult than the identification of plants with high spatial homogeneity. We aimed to explore the potential of close-range hyperspectral imaging for plant species identification in alpine steppe under field conditions. Specifically, we assessed which spectral bands are effective and which classification methods are suitable for plant species identification. A close-range hyperspectral image of grassland in Nagqu, Tibet were acquired in August 2018. Four methods, including derivatives, continuum removal, spectral indices, and principal components were used to enhance the differences in spectral characteristics between plant species. Then, two band selection methods, including Mahalanobis distance and variable importance evaluations based on a random forest (RF) were used to reduce dimensionality and select indicators beneficial for identifying grass species. Four datasets were constructed based on those indicators and were used as the input data for four classifiers, support vector machine (SVM), RF, artificial neural network (ANN), and spectral angle mapper (SAM). We found that (1) bands selected using Mahalanobis distance and variable importance evaluation method showed that the red bands, red edge bands, and spectral indices were important for plant species identification; (2) among the four classifiers, the ANN classifier had the highest overall classification accuracy on Dataset 3 of the reflectance images, which was 94.73%, and the Kappa coefficient was 0.93; (3) the machine learning algorithms RF and ANN performed well for identifying plant species, with an overall accuracy more than 91.59% and kappa coefficient above 0.89. These results suggest that close-range hyperspectral image and machine-learning classifiers, such as RF and ANN, can be used to effectively identify plant species in alpine steppe.}
}
@article{BARUCH2017104,
title = {Complex-valued neural network topology and learning applied for identification and control of nonlinear systems},
journal = {Neurocomputing},
volume = {233},
pages = {104-115},
year = {2017},
note = {SI: CCE 2015},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2016.09.109},
url = {https://www.sciencedirect.com/science/article/pii/S0925231216314205},
author = {Ieroham S. Baruch and Victor A. Quintana and Edmundo P. Reynaud},
keywords = {Complex-valued backpropagation, Complex-valued Levenberg-Marquard, Adaptive neural control, Recurrent complex-valued neural network, Nonlinear oscillatory plants},
abstract = {In this paper we present a Complex-Valued Recurrent Neural Network (CVRNN), trained with a recursive Levenberg-Marquardt (LM) learning algorithm in the complex domain, applying it to the problem of dynamic system identification, and to an adaptive neural control scheme of a nonlinear oscillatory plant. This methodology is applied to two different CVRNN topologies with different kinds of activation functions. Furthermore, we applied the CVRNN identification and control for a particular case of a nonlinear, oscillatory mechanical plant to validate the performance of the adaptive neural controller using the LM algorithm developed throughout this work, compared to a complex-valued Backpropagation learning algorithm. The obtained comparative simulation results using a flexible robot arm gives a good performance of the derived control schemes. The results show some priority of the recursive LM learning over the BP learning, and the use of constructed activation functions in the neural network topology.}
}
@article{ATMEH2016367,
title = {A Dynamic Neural Network with Feedback for Trajectory Generation},
journal = {IFAC-PapersOnLine},
volume = {49},
number = {1},
pages = {367-372},
year = {2016},
note = {4th IFAC Conference on Advances in Control and Optimization of Dynamical Systems ACODS 2016},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2016.03.081},
url = {https://www.sciencedirect.com/science/article/pii/S2405896316300817},
author = {Ghassan Atmeh and Kamesh Subbarao},
keywords = {Neural Networks, Dynamic Neural Networks, Recurrent Neural Networks, Trajectory planning, Path planning},
abstract = {A Dynamic Neural Network (DNN), comprising of a Recurrent Neural Network (RNN) and two Feedforward Neural Networks (FFNN), is detailed in this paper. This neuro-dynamic system is used to adaptively solve the problem of trajectory generation; planning a path connecting a locus of points as a function of time. The RNN is designed to exhibit a desired dynamic behavior which drives the output FFNN to generate a specific trajectory. To make the system adaptive, a feedback FFNN is introduced to generate inputs to the RNN based on the outputs of the output FFNN. Simulations conducted for generation of different types of trajectories show the capabilities of the DNN with feedback in solving the trajectory generation problem.}
}
@article{TRAVIS2020100092,
title = {Neural networks to locate and quantify fugitive natural gas leaks for a MIR detection system},
journal = {Atmospheric Environment: X},
volume = {8},
pages = {100092},
year = {2020},
issn = {2590-1621},
doi = {https://doi.org/10.1016/j.aeaoa.2020.100092},
url = {https://www.sciencedirect.com/science/article/pii/S2590162120300320},
author = {Bryan Travis and Manvendra Dubey and Jeremy Sauer},
keywords = {Neural network, Methane, Emission, Laser, Sensor, METEC},
abstract = {Fugitive natural gas leaks from abnormal operations or failed containment at oil and gas production fields and gas supply chains are a significant source of atmospheric methane (CH4), a potent greenhouse gas. This realization of significant CH4 leaks has stimulated efforts at mitigation using cost effective detection methods. US DOE's ARPA-E MONITOR program has supported transformational research to locate and quantify fugitive methane leaks at natural gas facilities in order to achieve a 90% reduction in CH4 emissions. This paper describes the development, application, and evaluation of a MONITOR program sponsored source attribution technology solution, wherein an artificial neural network (ANN) infers as outputs, a leak location and release rate given inputs of measured sonic anemometer wind velocities and methane sensor time series. We discuss development of our ANN model, its training, computational implementation and use to design effective sampling strategies over a range of source and sensor locations, and meteorological conditions. We report on the deployment and performance of our ALFaLDS in blind tests at Colorado State University's METEC well pad facility in Ft. Collins. Test results demonstrate that our ALFaLDS locates the engineered methane leaks to better than 8% of the domain length scale and has the ability to quantify fluxes, more accurately at high flux rates, less so at low rates. Our ANN overestimates leak source rates by an average scale factor of about 1.83 for small pads and by an average of 1.77 for larger domains. The scale factor can be used operationally but needs more research to assess its generality. This capability of leak location with high skill, speed and accuracy at moderate cost promises new automatic affordable sampling of fugitive gas leaks at well pads and oil and gas fields.}
}
@article{BARNETSON2019101909,
title = {Mapping woody vegetation cover across Australia's arid rangelands: Utilising a machine-learning classification and low-cost Remotely Piloted Aircraft System},
journal = {International Journal of Applied Earth Observation and Geoinformation},
volume = {83},
pages = {101909},
year = {2019},
issn = {0303-2434},
doi = {https://doi.org/10.1016/j.jag.2019.101909},
url = {https://www.sciencedirect.com/science/article/pii/S0303243418311644},
author = {J. Barnetson and S. Phinn and P. Scarth},
keywords = {Remotely Piloted Aircraft System (RPAS), Sentinel2, Planet Dove, Ortho-mosaic, Drone, Landsat},
abstract = {Knowledge of the extent and degree of wooded vegetation cover in the arid parts of Australia is essential for land-holders and management agencies. The balance between wooded and ground-cover vegetation is important to livestock production and landscape health. Adequate mapping of changes in wooded vegetation cover allows the assessment of its expansion and contraction as input for improved management of production and conservation. The aim of this study was to develop a method to accurately map the extent and degree of wooded tree and shrub cover across an area of arid rangeland in central Australia. Its open and sparse distribution throughout the landscape and its adaptation to an arid environment present challenges to obtaining both representative field measurements and scale appropriate remotely sensed imagery. Recent advancements and access to high spatial resolution satellite imagery provide opportunities for improved mapping. The rapid development of Remotely Piloted Aircraft Systems (RPAS) or drones also provides further opportunities to improve the accuracy of field measurements used in the classification of wooded vegetation. An optimised machine-learning classification was developed using high resolution Planet Dove cube-sat and Sentinel2 imagery and compared to medium resolution Landsat8 imagery. An efficient method of collecting plot scale (ha) wooded vegetation cover estimates for the training and assessment of the satellite image classification was also developed using the RPAS. It was comparable to other field based measurements. The results of the classifications showed a moderate degree of accuracy in distinguishing wooded cover from non-wooded cover, highest with the Planet Dove imagery. An improved accuracy in distinguishing between wooded cover classes was also seen in the Sentinel2 classification. The mapping and subsequent monitoring of wooded vegetation in these landscapes has been shown to be improved with higher resolution satellite imagery.}
}
@article{AHMED2021107282,
title = {A comprehensive comparison of recent developed meta-heuristic algorithms for streamflow time series forecasting problem},
journal = {Applied Soft Computing},
volume = {105},
pages = {107282},
year = {2021},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2021.107282},
url = {https://www.sciencedirect.com/science/article/pii/S1568494621002052},
author = {Ali Najah Ahmed and To {Van Lam} and Nguyen Duy Hung and Nguyen {Van Thieu} and Ozgur Kisi and Ahmed El-Shafie},
keywords = {Metaheuristics, Swarm-based optimization, Evolutionary-based algorithms, Physics-inspired meta-heuristics, Equilibrium Optimization (EO), Henry Gases Solubility Optimization (HGSO), Nuclear Reaction Optimization (NRO), Multi-Layer Perceptron (MLP), Streamflow estimation},
abstract = {Hydrological models play a crucial role in water planning and decision making. Machine Learning-based models showed several drawbacks for frequent high and a wide range of streamflow records. These models also experience problems during the training process such as over-fitting or trapping in searching for global optima To overcome these limitations, the current study attempts to hybridize the recently developed physics-inspired metaheuristic algorithms (MHAs) such as Equilibrium Optimization (EO), Henry Gases Solubility Optimization (HGSO), and Nuclear Reaction Optimization(NRO) with Multi-layer Perceptron (MLP). These models’ accuracy will be inspected to solve the streamflow forecasting problem where the streamflow dataset was collected through 130 years from a station located on the High Aswan Dam (HAD). The performance of proposed models then will be compared with two traditional neural network models(MLP and RNN), and nine well-known hybrid MLP-based models belong to the different branches of the metaheuristic field (evolutionary group, swarm group, and physics group). The internal parameters of the proposed models will be initialized and optimized. Different performance metrics will be used to examine the performance of the proposed models. The stability of the proposed models and the convergence speed will be evaluated. Finally, ranking these models based on different performance evaluations will be carried out. The results show that the models in the group of Physics-MLP are more reliable in capturing the streamflow patterns, followed by the Swarm-MLP group and then by the Evolutionary-MLP group. Finally, among the all employed methods, the NRO has the best accuracy with the lowest RMSE(2.35), MAE(1.356), MAPE(16.747), and the highest WI(0.957), R(0.924), and confidence in forecasting the streamflow of Aswan High Dam. It can be concluded that augmenting the NRO algorithm with MLP can be a reliable tool in forecasting the monthly streamflow with a high level of precision, speed convergence, and high constancy level.}
}
@article{LIU20181373,
title = {A New Strategy of Adaptive Observer Based Fault Isolation⁎⁎This work is partially supported by the National Natural Science Foundation of China (Grant No. 61333005, 61733009, 61703244), Research Fund for the Taishan Scholar Project of Shangdong Province of China},
journal = {IFAC-PapersOnLine},
volume = {51},
number = {24},
pages = {1373-1378},
year = {2018},
note = {10th IFAC Symposium on Fault Detection, Supervision and Safety for Technical Processes SAFEPROCESS 2018},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2018.09.555},
url = {https://www.sciencedirect.com/science/article/pii/S240589631832247X},
author = {Hai Liu and Maiying Zhong and Yang Liu},
keywords = {fault isolation, adaptive observer, contribution analysis, nonlinear system},
abstract = {The problem of fault isolation (FI) for a kind of nonlinear discrete time varying (NDTV) systems is investigated. A bank of adaptive observers are designed for the considered system with different potential faults, and the isolation work is transformed into finding out which observer matches the current system best. The idea of reconstruction-based contribution (RBC) analysis is introduced to construct indicator variables for all of the observers and the one with the largest indicator variable is declared as the isolation result. In this method, knowledge of the system model is fully used, while the idea of contribution analysis is typically data-driven. Finally, simulation study is carried out with a nonlinear unmanned aerial vehicle (UAV) model, and the results demonstrate that the proposed method provides us with a new promising strategy for FI.}
}
@article{KHANNA201982,
title = {A mutual exclusion algorithm for flying Ad Hoc networks},
journal = {Computers & Electrical Engineering},
volume = {76},
pages = {82-93},
year = {2019},
issn = {0045-7906},
doi = {https://doi.org/10.1016/j.compeleceng.2019.03.005},
url = {https://www.sciencedirect.com/science/article/pii/S0045790618320834},
author = {Ashish Khanna and Joel J.P.C. Rodrigues and Naman Gupta and Abhishek Swaroop and Deepak Gupta and Kashif Saleem and Victor Hugo C. {de Albuquerque}},
keywords = {Mutual exclusion, Distributed systems, VANET, FANET, MANET},
abstract = {Mutual exclusion (ME) is a highly researched problem in distributed computing systems. In the mutual exclusion problem, no two nodes can use critical resource simultaneously. Numerous protocols have been proposed for various types of static as well as mobile distributed systems, namely, Mobile Ad Hoc Networks (MANET), Vehicular Ad Hoc Networks (VANET) and cellular networks. The flying ad hoc networks (FANET) is an interesting variant of distributed systems and, to the best of our knowledge, no protocol exists in the literature for mutual exclusion in FANETs. In FANETs, the critical resource is mounted on an unmanned aerial vehicle (UAV) and user nodes are assumed in the transmission range of the UAV. Ours is the first algorithm to ensure ME in FANETs. The algorithm is token-based and we name it Mobile Resource Mutual Exclusion (MRME) algorithm. Unlike other ad hoc networks, due to swift mobility of nodes as well as resource, the FANETs topology is highly dynamic and fault prone. The MRME algorithm handles it successfully. Further, we present the correctness proof, complexity analysis and simulation results. The worst-case complexity of MRME is O(n) and synchronization delay is T, where T is message propagation delay.}
}
@article{JARDINE20172341,
title = {Parameter Tuning for Prediction-based Quadcopter Trajectory Planning using Learning Automata},
journal = {IFAC-PapersOnLine},
volume = {50},
number = {1},
pages = {2341-2346},
year = {2017},
note = {20th IFAC World Congress},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2017.08.420},
url = {https://www.sciencedirect.com/science/article/pii/S240589631730770X},
author = {Peter T. Jardine and Sidney Givigi and Shahram Yousefi},
keywords = {Model Predictive Control, Quadcopter, Reinforcement Learning},
abstract = {This paper presents a target tracking technique for a quadcopter based on Model Predictive Control (MPC) tuned using machine learning. Specifically, it uses learning automata to select the weighting parameters of the objective function such that they minimize tracking error. It develops an approximate linear state-space model for the quadcopter dynamics by linearizing around a hover condition. The optimum sequence of control actions is expressed as perturbations on a stabilizing feedback law expanded over a finite prediction horizon. Simulation results demonstrate the learned weighting parameters can be used to provide optimized trajectories when implemented as receding horizon MPC. Furthermore, a comparison with previous work demonstrates improved tracking performance.}
}
@article{HU2019104852,
title = {A low shot learning method for tea leaf’s disease identification},
journal = {Computers and Electronics in Agriculture},
volume = {163},
pages = {104852},
year = {2019},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2019.104852},
url = {https://www.sciencedirect.com/science/article/pii/S0168169919300407},
author = {Gensheng Hu and Haoyu Wu and Yan Zhang and Mingzhu Wan},
keywords = {Tea leaf’s disease, Disease identification, Support vector machine, Generative adversarial networks, Deep learning},
abstract = {Tea leaf’s diseases seriously affect the yield and quality of tea. This paper presents a low shot learning method for tea leaf’s disease identification in order to prevent and control tea leaf’s diseases timely. By extracting the color and texture features, disease spots on tea leaf's disease images are segmented by using support vector machine (SVM) method. With segmented disease spot images as input, new training samples are generated by the improved conditional deep convolutional generative adversarial networks (C-DCGAN) for data augmentation, which are used to train VGG16 deep learning model to identify the tea leaf's diseases. Experimental results show that, SVM can segment disease spot images on the condition of low shot learning while retaining the edge information well, improved C-DCGAN can generate augmented images with the same data distribution as real disease spot images, the VGG16 deep learning model trained with augmented disease spot images can identify tea leaf’s diseases accurately, and the average identification accuracy of the proposed method reaches 90%, far exceeding classical low shot learning methods.}
}
@article{VURAL2018446,
title = {Passive Fault Tolerant Lateral Controller Design For an UAV},
journal = {IFAC-PapersOnLine},
volume = {51},
number = {30},
pages = {446-451},
year = {2018},
note = {18th IFAC Conference on Technology, Culture and International Stability TECIS 2018},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2018.11.320},
url = {https://www.sciencedirect.com/science/article/pii/S240589631832994X},
author = {Sıtkı Yenal Vural and Janset Dasdemir and Chingiz Hajiyev},
keywords = {Fault-tolerant control, UAVs, Robust control, UAV control, Actuator failure},
abstract = {In this study a passive lateral fault tolerant controller for an UAV is designed using dynamic inversion (DI) method and robust integral of the signum of the error (RISE) techniques. The details of the methods are summarized. As the reference model of the tracking controller, UAV controlled by feedback type controller is used and the control method used for this design is explained. The loss in control effectiveness is modeled as changes in the control distribution matrix. Simulations are made to show the effectiveness of the passive fault tolerant controller in maintaining the lateral control in case of actuator effectiveness loss.}
}
@article{WANG2018232,
title = {A GNSS/INS Integrated Navigation Algorithm Based on Kalman Filter},
journal = {IFAC-PapersOnLine},
volume = {51},
number = {17},
pages = {232-237},
year = {2018},
note = {6th IFAC Conference on Bio-Robotics BIOROBOTICS 2018},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2018.08.151},
url = {https://www.sciencedirect.com/science/article/pii/S2405896318312692},
author = {Guangqi Wang and Yu Han and Jian Chen and Shubo Wang and Zichao Zhang and Nannan Du and Yongjun Zheng},
keywords = {GNSS/INS integrated navigation, feedback emendation, centralized filter, loose coupling, discrete Kalman filter},
abstract = {GNSS/INS (Global Navigation Satellite System/ Inertial Navigation System) integrated navigation system can be applied to agricultural UAV (unmanned aerial vehicle) with the following two requirements: (1) After working for a long time, the precision of navigation parameters will not decrease; (2) The integrated navigation algorithm is simple and reliable, which requires low processing capacity for airborne chips. Aiming at satisfying above two requirements, firstly, the centralized Kalman filter method is used to fuse GPS (Global Position System) and INS systems under the premise of loose coupling. The combination is compact, which greatly reduces the amount of computing in the system and simplifies the complexity of the system. Secondly, the error of INS system navigation parameters estimated by discrete Kalman filter algorithm is fed back into INS system by feedback emendation method, which overcomes the problem that the navigation accuracy will decline after long time work. Finally, the simulations of velocity and position error after filtering are demonstrated respectively. The stability and effectiveness of proposed algorithms are verified.}
}
@article{INZERILLO2018457,
title = {Image-based 3D reconstruction using traditional and UAV datasets for analysis of road pavement distress},
journal = {Automation in Construction},
volume = {96},
pages = {457-469},
year = {2018},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2018.10.010},
url = {https://www.sciencedirect.com/science/article/pii/S0926580518304047},
author = {Laura Inzerillo and Gaetano {Di Mino} and Ronald Roberts},
keywords = {Road pavement distresses, Low-cost technologies, Structure from motion, 3D models, Pavement management},
abstract = {On local and urban networks, the enduring issue of scarce resources for Maintenance, Rehabilitation, and Reconstruction strategies (MR&R) has led, in many cases, to using unadjusted or poor techniques for road pavement distress detection and analysis, yielding ineffective or even counterproductive results. Therefore, it is necessary to have tools that can carry out quick, reliable and low-cost assessment surveys. This paper aims at validating the use of innovative and low-cost technologies for road pavement analysis, assessing their potentialities for improving the automation and reliability of distress detection. A Structure from Motion (SfM) technique is analyzed at different altitudes. The technique was applied on a distressed road pavement inside the University Campus in Palermo. The models obtained were compared with a terrestrial laser scanned 3D model to analyze the technique's metric accuracy and reliability. The results have shown that the technique accurately replicates pavement distresses, inciting an integrated approach to optimize pavement management strategies.}
}
@article{HASSIJA202051,
title = {Scheduling drone charging for multi-drone network based on consensus time-stamp and game theory},
journal = {Computer Communications},
volume = {149},
pages = {51-61},
year = {2020},
issn = {0140-3664},
doi = {https://doi.org/10.1016/j.comcom.2019.09.021},
url = {https://www.sciencedirect.com/science/article/pii/S014036641930948X},
author = {Vikas Hassija and Vikas Saxena and Vinay Chamola},
keywords = {Directed Acyclic Graph, Unmanned Aerial Vehicles, Internet of drones, Distributed applications, Consensus, Smart charging, Blockchain},
abstract = {Drones or Unmanned Aerial Vehicles (UAVs) can be highly efficient in various applications like hidden area exploration, delivery, or surveillance and can enhance the quality of experience (QoE) for end-users. However, the number of drone-based applications are not very high due to the constrained flight time. The weights of the drones need to be kept less, and intuitively they cannot be loaded with big batteries. Frequent recharging and battery replacement processes limit the appropriate use of drones in most applications. A peer-to-peer distributed network of drones and charging stations is a highly promising solution to empower drones to be used in multiple applications by increasing their flight time. The charging stations are limited, and therefore, an adequate, fair, and cost-optimal scheduling algorithm is required to serve the most needed drone first. The proposed model allows the drones to enter into the network and request for a charging time slot from the station. The stations are also the part of the same network, this work proposes a scheduling algorithm for drones who compete for charging slots with constraints of optimizing criticality and task deadline. A game-theoretic approach is used to model the energy trading between the drones and charging station in a cost-optimal manner. Numerical results based on simulations show that the proposed model provides a better price for the drones to get charged and better revenue for the charging stations simultaneously.}
}
@article{LIU2021153,
title = {Emergency response facility location in transportation networks: A literature review},
journal = {Journal of Traffic and Transportation Engineering (English Edition)},
volume = {8},
number = {2},
pages = {153-169},
year = {2021},
note = {Transportation Planning and Operations for COVID-19 Epidemic and Other Emergencies},
issn = {2095-7564},
doi = {https://doi.org/10.1016/j.jtte.2021.03.001},
url = {https://www.sciencedirect.com/science/article/pii/S2095756421000222},
author = {Yang Liu and Yun Yuan and Jieyi Shen and Wei Gao},
keywords = {Transportation engineering, Emergency facility location, Transportation networks, Travel time, Machine learning},
abstract = {Emergency response activity relies on transportation networks. Emergency facility location interacts with transportation networks clearly. This review is aimed to provide a combined framework for emergency facility location in transportation networks. The article reveals emergency response activities research clusters, issues, and objectives according to keywords co-occurrence analysis. Four classes of spatial separation models in transportation networks, including distance, routing, accessibility, and travel time are introduced. The stochastic and time-dependent characteristics of travel time are described. Travel time estimation and prediction method, travel time under emergency vehicle preemption, transportation network equilibrium method, and travel time in degradable networks are demonstrated. The emergency facilities location models interact with transportation networks, involving location-routing model, location models embedded with accessibility, location models embedded with travel time, and location models employing mathematical program with equilibrium constraints are reviewed. We then point out the-state-of-art challenges: ilities-oriented, evolution landscape and sequential decision modelling, data-driven optimization approach, and machine learning-based algorithms.}
}
@article{YAN2021112728,
title = {Modeling the radiation regime of a discontinuous canopy based on the stochastic radiative transport theory: Modification, evaluation and validation},
journal = {Remote Sensing of Environment},
volume = {267},
pages = {112728},
year = {2021},
issn = {0034-4257},
doi = {https://doi.org/10.1016/j.rse.2021.112728},
url = {https://www.sciencedirect.com/science/article/pii/S003442572100448X},
author = {Kai Yan and Yiman Zhang and Yiyi Tong and Yelu Zeng and Jiabin Pu and Si Gao and Linyuan Li and Xihan Mu and Guangjian Yan and Miina Rautiainen and Yuri Knyazikhin and Ranga B. Myneni},
keywords = {Stochastic radiative transfer (SRT), Radiation regime, Vegetation canopy, Evaluation and validation, Hotspot effect},
abstract = {Canopy radiative transfer (RT) modeling is critical for the quantitative retrieval of vegetation biophysical parameters and has been under intensive research over the decades. RT models of discontinuous canopies, such as three-dimensional (3D) RT models, posed challenges for the early one-dimensional (1D) hypothesis. Although 3D RT models have higher accuracy, theoretically, they suffer from two problems: detailed scene parameters and complex computational steps. To overcome these problems, the stochastic radiative transfer (SRT) theory, which is known to have the accuracy of 3D RT while being as simple as 1D RT, has been adapted from atmospheric research to the study of vegetation canopies. While the SRT model has been adopted into the operational production of vegetation parameters, its accuracy needs further improvement because of the insufficient consideration of hotspot effects. Additionally, the evaluation and validation of SRT process are still preliminary, which hinders its further development and application. To provide the community with missing information and a scientific basis for subsequent model improvement, we modified, evaluated, and validated the SRT model in this study. First, we proposed the new version of SRT model to better achieve the coupling of SRT process and hotspot effect by dividing the previous SRT into four subproblems. Then, we evaluated the performance of the modified SRT by comparing multiple intermediate variables in the SRT process with 3D computer simulations, and analyzed the model sensitivity to key input parameters as well as the spatial distribution and conservation of radiation energy. Our findings reconfirmed that the SRT theory can well describe the radiation regime of discontinuous canopies with balanced efficiency and accuracy. Moreover, the newly proposed coupling scheme of hotspot effect further improves the model performance in the hotspot regions. Finally, the unmanned aerial vehicle (UAV) observations served as a reference to validate the modeled canopy reflectance, which shows a high concordance. These results provide a detailed theoretical basis for applications and further improvements of the SRT model.}
}
@article{TRIPATHI20141119,
title = {Reactive Collision Avoidance of UAVs with Stereovision Camera Sensors using UKF},
journal = {IFAC Proceedings Volumes},
volume = {47},
number = {1},
pages = {1119-1125},
year = {2014},
note = {3rd International Conference on Advances in Control and Optimization of Dynamical Systems (2014)},
issn = {1474-6670},
doi = {https://doi.org/10.3182/20140313-3-IN-3024.00171},
url = {https://www.sciencedirect.com/science/article/pii/S147466701632794X},
author = {Amit K. Tripathi and Ramsingh G. Raja and Radhakant Padhi},
keywords = {Collision cone, Obstacle, State estimation, Stereo-vision, Point mass model, UKF, Aiming point},
abstract = {An effective reactive collision avoidance algorithm is presented in this paper for Unmanned Ariel Vehicles(UAVs) based on stereovision sensing of the obstacles. Vision sensors detection range is limited and state measurements are noisy. Unscented Kalman Filter(UKF) based sensor state estimation is proposed to extract the accurate information from the sensors through a geometrical formulation. This formulation is capable of estimating the range information of the obstacle. The first order differential of the nonlinear sensor dynamics is used to compute obstacle's velocity estimate. In the case of imminent collision, UAV is guided towards an 'Aiming point' which is computed for point obstacle with safety ball and using the collision cone approach. The velocity vector of the UAV is steered away towards this point by using 'Differential Geometry Guidance'(DGG). Simulations show that this guidance strategy is quite effective in avoiding popup obstacles within a very short time and hence can be useful for reactive collision avoidance.}
}
@article{DJERIDA2021103258,
title = {Development of scale and illumination invariant feature detector with application to UAV attitude estimation},
journal = {Journal of Visual Communication and Image Representation},
volume = {79},
pages = {103258},
year = {2021},
issn = {1047-3203},
doi = {https://doi.org/10.1016/j.jvcir.2021.103258},
url = {https://www.sciencedirect.com/science/article/pii/S1047320321001681},
author = {Achraf Djerida and Zhonghua Zhao and Jiankang Zhao},
keywords = {Feature detection, Scale invariance, Illumination invariance, UAV attitude estimation},
abstract = {Feature detection has great importance in many applications such as vision navigation. Examining the developed detectors, it is found in many recent studies that most of the scale-invariant detectors are sensitive to illumination. In this work, we propose a novel detector that has good robustness to both scale and illumination. Motivated by the good robustness of Log-Gabor kernels toward light changes, we employ these kernels as a basis to construct the scale space. To detect potential features, we develop an effective interest points measure which is motivated by the concept of the autocorrelation and Hessian matrices. To confirm the good performance of our detector, we hold experiments on many datasets and with comparisons to common state-of-the-art methods. Furthermore, we evaluate the saliency of the detected features on a UAV attitude estimation task.}
}
@article{ROSA201952,
title = {Adaptive hierarchical formation control for uncertain Euler–Lagrange systems using distributed inverse dynamics},
journal = {European Journal of Control},
volume = {48},
pages = {52-65},
year = {2019},
note = {Advanced Control Theory and Applications for Next-Generation Engineered Systems},
issn = {0947-3580},
doi = {https://doi.org/10.1016/j.ejcon.2018.11.001},
url = {https://www.sciencedirect.com/science/article/pii/S0947358018302851},
author = {Muhammad Ridho Rosa and Simone Baldi and Ximan Wang and Maolong Lv and Wenwu Yu},
keywords = {Adaptive hierarchical formation control, Euler–Lagrange systems, Heterogeneous uncertain systems, Inverse dynamics control},
abstract = {This paper establishes a novel adaptive hierarchical formation control method for uncertain heterogeneous nonlinear agents described by Euler–Lagrange (EL) dynamics. Formation control is framed as a synchronization problem where a distributed model reference adaptive control is used to synchronize the EL systems. The idea behind the proposed adaptive formation algorithm is that each agent must converge to the model defined by its hierarchically superior neighbors. Using a distributed inverse dynamics structure, we prove that distributed nonlinear matching conditions between connected agents hold, so that matching gains exist to make the entire formation converge to same homogeneous dynamics: to compensate for the presence of uncertainties, estimation laws are devised for such matching gains, leading to adaptive synchronization. An appropriately designed distributed Lyapunov function is used to derive asymptotic convergence of the synchronization error. The effectiveness of the proposed methodology is supported by simulations of a formation of Unmanned Aerial Vehicles (UAVs).}
}
@article{KUANG20211,
title = {Application and development trend of artificial intelligence in petroleum exploration and development},
journal = {Petroleum Exploration and Development},
volume = {48},
number = {1},
pages = {1-14},
year = {2021},
issn = {1876-3804},
doi = {https://doi.org/10.1016/S1876-3804(21)60001-0},
url = {https://www.sciencedirect.com/science/article/pii/S1876380421600010},
author = {Lichun KUANG and He LIU and Yili REN and Kai LUO and Mingyu SHI and Jian SU and Xin LI},
keywords = {artificial intelligence, logging interpretation, seismic exploration, reservoir engineering, drilling and completion, surface facility engineering},
abstract = {Aiming at the actual demands of petroleum exploration and development, this paper describes the research progress and application of artificial intelligence (AI) in petroleum exploration and development, and discusses the applications and development directions of AI in the future. Machine learning has been preliminarily applied in lithology identification, logging curve reconstruction, reservoir parameter estimation, and other logging processing and interpretation, exhibiting great potential. Computer vision is effective in picking of seismic first breaks, fault identification, and other seismic processing and interpretation. Deep learning and optimization technology have been applied to reservoir engineering, and realized the real-time optimization of waterflooding development and prediction of oil and gas production. The application of data mining in drilling, completion, and surface facility engineering etc. has resulted in intelligent equipment and integrated software. The potential development directions of artificial intelligence in petroleum exploration and development are intelligent production equipment, automatic processing and interpretation, and professional software platform. The highlights of development will be digital basins, fast intelligent imaging logging tools, intelligent seismic nodal acquisition systems, intelligent rotary-steering drilling, intelligent fracturing technology and equipment, real-time monitoring and control of zonal injection and production.}
}
@article{SINGHAL2020107163,
title = {A domain adaptation approach to solve inverse problems in imaging via coupled deep dictionary learning},
journal = {Pattern Recognition},
volume = {100},
pages = {107163},
year = {2020},
issn = {0031-3203},
doi = {https://doi.org/10.1016/j.patcog.2019.107163},
url = {https://www.sciencedirect.com/science/article/pii/S0031320319304637},
author = {Vanika Singhal and Angshul Majumdar},
keywords = {Dictionary learning, Deep learning, Domain adaptation, Inverse problems},
abstract = {In this work, we focus on solving four standard inverse problems in imaging – denoising, deblurring, super-resolution, and reconstruction. All these problems are usually associated with image acquisition. Traditionally, signal processing techniques are used to solve such problems. However, such techniques are computationally expensive. In many applications today, when the requirement is to compute on the edge, such expensive inversion techniques are not viable solutions. Thus, one resorts to machine learning based solutions. In the past few years, variants of neural networks were developed to ‘learn’ the inversion operation. Although the learning was computationally expensive, the learnt model was light-weight and portable; suitable for deployment on leaner platforms. This work is based on the same concept, however, instead of using neural networks we treat inversion as a domain adaptation problem – a transfer from corrupted space to clean space. Our work is based on the developing field of coupled representation learning. We propose a deep version of the well known coupled dictionary learning technique; but instead of learning a single layer of dictionary, we learn multiple layers. Experimental results on standard datasets against state-of-the-art solutions for each problem, show that our method yields the best results both in terms of accuracy and speed.}
}
@article{BOCCADORO2022102749,
title = {Water quality prediction on a Sigfox-compliant IoT device: The road ahead of WaterS},
journal = {Ad Hoc Networks},
volume = {126},
pages = {102749},
year = {2022},
issn = {1570-8705},
doi = {https://doi.org/10.1016/j.adhoc.2021.102749},
url = {https://www.sciencedirect.com/science/article/pii/S157087052100233X},
author = {Pietro Boccadoro and Vitanio Daniele and Pietro {Di Gennaro} and Domenico Lofù and Pietro Tedeschi},
keywords = {Sigfox, Internet of Things, Water quality, Deep learning},
abstract = {Water pollution is a critical issue that affects the entire ecosystem, with non-negligible consequences on humans’ health, thus inducing economic and social concerns. This paper focuses on an Internet of Things water quality prediction system, namely WaterS, that remotely communicates gathered measurements leveraging the Sigfox communication technology. The solution addresses the water pollution problem while considering the peculiar Internet of Things constraints such as energy efficiency and autonomy. The proposal demonstrateshow it is possible to detect and predict water quality parameters such as pH, conductivity, oxygen, and temperature by using WaterS, the Tiziano Project dataset, and a Deep Learning algorithm based on a Long Short-Term Memory recurrent neural network. The discussed water quality measurements are referred to the dataset that belongs to the Tiziano Project, in a period of time spanning from 2008 to 2012. The Long Short-Term Memory applied to predict the water quality parameters achieves high accuracy and a low Mean Absolute Error of 0.20, a Mean Square Error of 0.092, and finally a Cosine Proximity of 0.94. The obtained results are analyzed in terms of protocol suitability of the current architecture toward large-scale deployments. From a networking perspective, with an increasing number of Sigfox-enabled end-devices, the Packet Error Rate increases as well up to 4% with the largest envisioned deployment. Finally, the source code of WaterS ecosystem has been released as open-source, to encourage and promote research activities from both Industry and Academia.}
}
@article{ZHAO2020101199,
title = {The technology of adversarial attacks in signal recognition},
journal = {Physical Communication},
volume = {43},
pages = {101199},
year = {2020},
issn = {1874-4907},
doi = {https://doi.org/10.1016/j.phycom.2020.101199},
url = {https://www.sciencedirect.com/science/article/pii/S1874490720302767},
author = {Haojun Zhao and Qiao Tian and Lei Pan and Yun Lin},
keywords = {Adversarial attack, Signal recognition, Deep learning, Wireless security},
abstract = {The wide application of contour stellar images has helped researchers transform signal classification problems into image classification problems to solve signal recognition based on deep learning. However, deep neural networks (DNN) are quite vulnerable to adversarial examples, thus simply evaluating the adversarial attack performance on the signal sequence recognition model cannot meet the current security requirements. From the perspective of an attacker, this study converts individual signals into stellar contour images, and then generates adversarial examples to evaluate the adversarial attack impacts. The results show that whether the current input sample is a signal sequence or a converted image, the DNN is vulnerable to the threat of adversarial examples. In the selected methods, whether it is under different perturbations or signal-to-noise ratio (SNRs), the momentum iteration method has the best performance among them, and under the perturbation of 0.01, the attack performance is more than 10% higher than the fast gradient sign method. Also, to measure the invisibility of adversarial examples, the contour stellar images before and after the attack were compared to maintain a balance between the attack success rate and the attack concealment.}
}
@article{BUSCH2021106007,
title = {Dynamic tree branch tracking for aerial canopy sampling using stereo vision},
journal = {Computers and Electronics in Agriculture},
volume = {182},
pages = {106007},
year = {2021},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2021.106007},
url = {https://www.sciencedirect.com/science/article/pii/S0168169921000259},
author = {Christopher Alexander Maximilian Busch and Karl A. Stol and Wannes {van der Mark}},
keywords = {UAV, Canopy sampling, Stereo vision, Tracking},
abstract = {Maintaining the massive forests of the forestry industry requires physical samples from the tree canopy to enable breeding, genetics research and monitoring of diseases. An autonomous Unmanned Aerial Vehicle (UAV) canopy sampling solution requires locating and tracking a highly unstructured, moving object against a dynamic, cluttered background. The developed algorithm utilises stereo vision techniques to reconstruct a 3D point cloud of the target branch and subsequently estimate the intercept point location. The optimal parameters are selected by quantifying the accuracy against ground truth obtained from motion capture. Since wind will likely affect the tree canopy during sampling, the branch will exhibit some sway motion which can be modelled as simple harmonic motion. Hence, a linear Kalman filter is formulated to estimate the sway parameters. With the branch 1m from the camera, the average error is 41mm for sway amplitudes between 50mm and 250mm with a plain background. When tested with a cluttered background, the reduced contrast results in higher standard deviations. Overall, the developed Kalman filter significantly reduces the intercept point error standard deviation, averaging 17% and 33% reductions for plain and cluttered backgrounds respectively. Subsequent outdoor testing verified the capability of the developed algorithm to estimate the branch trajectory to well within the maximum gripper opening of 115mm.}
}
@article{WU2020102091,
title = {Inter-comparison of remote sensing platforms for height estimation of mango and avocado tree crowns},
journal = {International Journal of Applied Earth Observation and Geoinformation},
volume = {89},
pages = {102091},
year = {2020},
issn = {0303-2434},
doi = {https://doi.org/10.1016/j.jag.2020.102091},
url = {https://www.sciencedirect.com/science/article/pii/S0303243419308608},
author = {Dan Wu and Kasper Johansen and Stuart Phinn and Andrew Robson and Yu-Hsuan Tu},
keywords = {Horticulture, Tree crops, Canopy height, Remote sensing, Laser scanning, UAV, Satellite stereo imagery},
abstract = {To support the adoption of precision agricultural practices in horticultural tree crops, prior research has investigated the relationship between crop vigour (height, canopy density, health) as measured by remote sensing technologies, to fruit quality, yield and pruning requirements. However, few studies have compared the accuracy of different remote sensing technologies for the estimation of tree height. In this study, we evaluated the accuracy, flexibility, aerial coverage and limitations of five techniques to measure the height of two types of horticultural tree crops, mango and avocado trees. Canopy height estimates from Terrestrial Laser Scanning (TLS) were used as a reference dataset against height estimates from Airborne Laser Scanning (ALS) data, WorldView-3 (WV-3) stereo imagery, Unmanned Aerial Vehicle (UAV) based RGB and multi-spectral imagery, and field measurements. Overall, imagery obtained from the UAV platform were found to provide tree height measurement comparable to that from the TLS (R2 = 0.89, RMSE = 0.19 m and rRMSE = 5.37 % for mango trees; R2 = 0.81, RMSE = 0.42 m and rRMSE = 4.75 % for avocado trees), although coverage area is limited to 1–10 km2 due to battery life and line-of-sight flight regulations. The ALS data also achieved reasonable accuracy for both mango and avocado trees (R2 = 0.67, RMSE = 0.24 m and rRMSE = 7.39 % for mango trees; R2 = 0.63, RMSE = 0.43 m and rRMSE = 5.04 % for avocado trees), providing both optimal point density and flight altitude, and therefore offers an effective platform for large areas (10 km2–100 km2). However, cost and availability of ALS data is a consideration. WV-3 stereo imagery produced the lowest accuracies for both tree crops (R2 = 0.50, RMSE = 0.84 m and rRMSE = 32.64 % for mango trees; R2 = 0.45, RMSE = 0.74 m and rRMSE = 8.51 % for avocado trees) when compared to other remote sensing platforms, but may still present a viable option due to cost and commercial availability when large area coverage is required. This research provides industries and growers with valuable information on how to select the most appropriate approach and the optimal parameters for each remote sensing platform to assess canopy height for mango and avocado trees.}
}
@article{LIN2020364,
title = {Novel up-scale feature aggregation for object detection in aerial images},
journal = {Neurocomputing},
volume = {411},
pages = {364-374},
year = {2020},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2020.06.011},
url = {https://www.sciencedirect.com/science/article/pii/S0925231220309784},
author = {Hu Lin and Jingkai Zhou and Yanfen Gan and Chi-Man Vong and Qiong Liu},
keywords = {Object detection, Aerial images, Feature aggregation, Up-sampling},
abstract = {Object detection is a pivotal task for many unmanned aerial vehicle (UAV) applications. Compared to general scenes, the objects in aerial images are typically much smaller. For this reason, most general object detectors suffer from two critical challenges while dealing with aerial images: 1) The widely exploited Feature Pyramid Network works by integrating high-level features to lower levels progressively. However, this manner does not transfer equivalent information from each level of backbone network to the generated features, and the shared detection head faces an unbalanced sources of information flow, damaging the detection accuracy. 2) Up-sampling is commonly used to expand feature resolution for feature fusion or feature aggregation. However, existing up-sampling methods are ineffective to reconstruct high resolution feature maps. To address these two challenges, two works are proposed: 1) An up-scale feature aggregation framework that fully utilizes multi-scale complementary information, and 2) a novel up-sampling method that further improve detection accuracy. These two proposals are integrated into an end-to-end single-stage object detector namely HawkNet. Extensive experiments are conducted on VisDrone-DET2018, UAVDT and DIOR datasets. Compared to the RetinaNet baseline, our HawkNet achieves absolute gains of 6.0%, 1.2% and 5.9% in average precision (AP) on VisDrone-DET2018, UAVDT and DIOR datasets, respectively. For a 800 × 1333 input on the UAVDT dataset, HawkNet with ResNet-50 backbone surpasses existing methods for single-scale inference and achieves the best performance (37.4 AP), while operating at 10.6 frames per second on a single Nvidia GTX 1080Ti GPU.}
}
@article{XU2021100179,
title = {Artificial intelligence: A powerful paradigm for scientific research},
journal = {The Innovation},
volume = {2},
number = {4},
pages = {100179},
year = {2021},
issn = {2666-6758},
doi = {https://doi.org/10.1016/j.xinn.2021.100179},
url = {https://www.sciencedirect.com/science/article/pii/S2666675821001041},
author = {Yongjun Xu and Xin Liu and Xin Cao and Changping Huang and Enke Liu and Sen Qian and Xingchen Liu and Yanjun Wu and Fengliang Dong and Cheng-Wei Qiu and Junjun Qiu and Keqin Hua and Wentao Su and Jian Wu and Huiyu Xu and Yong Han and Chenguang Fu and Zhigang Yin and Miao Liu and Ronald Roepman and Sabine Dietmann and Marko Virta and Fredrick Kengara and Ze Zhang and Lifu Zhang and Taolan Zhao and Ji Dai and Jialiang Yang and Liang Lan and Ming Luo and Zhaofeng Liu and Tao An and Bin Zhang and Xiao He and Shan Cong and Xiaohong Liu and Wei Zhang and James P. Lewis and James M. Tiedje and Qi Wang and Zhulin An and Fei Wang and Libo Zhang and Tao Huang and Chuan Lu and Zhipeng Cai and Fang Wang and Jiabao Zhang},
keywords = {artificial intelligence, machine learning, deep learning, information science, mathematics, medical science, materials science, geoscience, life science, physics, chemistry},
abstract = {Artificial intelligence (AI) coupled with promising machine learning (ML) techniques well known from computer science is broadly affecting many aspects of various fields including science and technology, industry, and even our day-to-day life. The ML techniques have been developed to analyze high-throughput data with a view to obtaining useful insights, categorizing, predicting, and making evidence-based decisions in novel ways, which will promote the growth of novel applications and fuel the sustainable booming of AI. This paper undertakes a comprehensive survey on the development and application of AI in different aspects of fundamental sciences, including information science, mathematics, medical science, materials science, geoscience, life science, physics, and chemistry. The challenges that each discipline of science meets, and the potentials of AI techniques to handle these challenges, are discussed in detail. Moreover, we shed light on new research trends entailing the integration of AI into each scientific discipline. The aim of this paper is to provide a broad research guideline on fundamental sciences with potential infusion of AI, to help motivate researchers to deeply understand the state-of-the-art applications of AI-based fundamental sciences, and thereby to help promote the continuous development of these fundamental sciences.}
}
@article{HU2021103973,
title = {Machine vision-based surface crack analysis for transportation infrastructure},
journal = {Automation in Construction},
volume = {132},
pages = {103973},
year = {2021},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2021.103973},
url = {https://www.sciencedirect.com/science/article/pii/S0926580521004246},
author = {Wenbo Hu and Weidong Wang and Chengbo Ai and Jin Wang and Wenjuan Wang and Xuefei Meng and Jun Liu and Haowen Tao and Shi Qiu},
keywords = {Machine vision, Surface crack analysis, Deep learning, Transportation infrastructure},
abstract = {Cracks undermine the structural health of transportation infrastructure. Machine vision-based surface crack analysis is to process infrastructure inspection data collected by imaging devices for identifying the presence, location, and extent of cracks, classifying the corresponding severity levels, and eventually predicting their growth. Unlike the fragmented qualitative discussions on machine vision-based crack analysis methods in existing studies, this paper reviews the state of the art and practice of various machine vision solutions under different operating conditions in a fine-grained quantitative way, systematically describing the strengths and limitations of deep learning over other solutions. Moreover, the applicability assessment is implemented to describe the deployment and optimization of deep learning in five crack analysis tasks: image classification, object detection, pixel segmentation, geometric scale quantification, and growth prediction. At last, the challenges faced and corresponding breakthrough directions are summarized, respectively, driving further development of deep learning to assist more sophisticated maintenance decisions.}
}
@article{ZHANG2022347,
title = {Smart objects recommendation based on pre-training with attention and the thing–thing​ relationship in social Internet of things},
journal = {Future Generation Computer Systems},
volume = {129},
pages = {347-357},
year = {2022},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2021.11.006},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X21004350},
author = {Hongfei Zhang and Li Zhu and Liwen Zhang and Tao Dai and Xi Feng and Li Zhang and Kaiqi Zhang and Yutian Yan},
keywords = {Smart object recommendation, BERT, Bi-LSTM, Attention mechanism, Deep learning},
abstract = {In Internet of things (IoT) and Social Internet of things (SIoT), how to select or recommend suitable smart objects from an ocean of smart objects has become an increasingly critical issue. In this paper, we propose a novel neural network model called BLA (BERT and Bi-LSTM with attention) for smart objects scoring tasks to make recommendations in social Internet of things. The model uses a BERT network to obtain the sentence vectors for a smart object related text, and then uses Bi-LSTM with two types of attention mechanisms to extract representations of the smart object vectors. The devised attention mechanism contains a self-attention (SA) layer and a global-attention (GA) layer. The SA layer is able to estimate the importance of sentences or fields, which in a certain sense can substitute for manually defined features at the sentence and field level. The GA layer can measure the relationships between sentences (or fields) and user requirements, which further helps the model obtain more effective smart object vectors. The thing–thing relationship of Internet of things is introduced into the model to inprove the recommendation effect. Experimental results on the datasets demonstrate that our model outperforms other baseline methods.}
}
@article{ABAUNZA20209354,
title = {Cylindrical Bounded Quaternion Control for Tracking and Surrounding a Ground Target Using UAVs⁎⁎Research Supported by the Ministére de L’Education Nationale, de l’Enseignement Supérieur et de La Recherche, the National Network of Robotics Platforms (ROBOTEX), the Conseil Regional de Lorraine, from France, and the CONACYT from Mexico.},
journal = {IFAC-PapersOnLine},
volume = {53},
number = {2},
pages = {9354-9359},
year = {2020},
note = {21st IFAC World Congress},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2020.12.2392},
url = {https://www.sciencedirect.com/science/article/pii/S2405896320330639},
author = {Hernan Abaunza and Pedro Castillo and Didier Theilliol and Adel Belkadi and Laurent Ciarletta},
keywords = {Flying robots, Guidance navigation, control, Autonomous robotic systems, Bounded Control, Quadrotors, Quaternions, Multi-robot systems},
abstract = {A cooperative tracking algorithm for multiple quadrotors autonomously tracking and surrounding a target ground vehicle is presented in this paper. A nonlinear bounded controller is proposed using geometrical functions to stabilize the translational and rotational dynamics using bounded 3-dimensional control inputs, employing quaternion properties and operators in its design, Lyapunov theory is used to prove system stability. The navigation challenge is tackled by proposing a cost function based on the desired behavior of the aerial vehicles for tracking and surrounding the target, which is solved by finding the optimal solution with a Particle Swarm Optimization algorithm. Simulations and experimental results corroborate the good performance of the scheme.}
}
@article{ZHANG2020100050,
title = {When Autonomous Systems Meet Accuracy and Transferability through AI: A Survey},
journal = {Patterns},
volume = {1},
number = {4},
pages = {100050},
year = {2020},
issn = {2666-3899},
doi = {https://doi.org/10.1016/j.patter.2020.100050},
url = {https://www.sciencedirect.com/science/article/pii/S2666389920300611},
author = {Chongzhen Zhang and Jianrui Wang and Gary G. Yen and Chaoqiang Zhao and Qiyu Sun and Yang Tang and Feng Qian and Jürgen Kurths},
keywords = {autonomous systems, artificial intelligence, transferability, deep learning, generative adversarial networks, reinforcement learning, meta-learning},
abstract = {With widespread applications of artificial intelligence (AI), the capabilities of the perception, understanding, decision-making, and control for autonomous systems have improved significantly in recent years. When autonomous systems consider the performance of accuracy and transferability, several AI methods, such as adversarial learning, reinforcement learning (RL), and meta-learning, show their powerful performance. Here, we review the learning-based approaches in autonomous systems from the perspectives of accuracy and transferability. Accuracy means that a well-trained model shows good results during the testing phase, in which the testing set shares a same task or a data distribution with the training set. Transferability means that when a well-trained model is transferred to other testing domains, the accuracy is still good. Firstly, we introduce some basic concepts of transfer learning and then present some preliminaries of adversarial learning, RL, and meta-learning. Secondly, we focus on reviewing the accuracy or transferability or both of these approaches to show the advantages of adversarial learning, such as generative adversarial networks, in typical computer vision tasks in autonomous systems, including image style transfer, image super-resolution, image deblurring/dehazing/rain removal, semantic segmentation, depth estimation, pedestrian detection, and person re-identification. We furthermore review the performance of RL and meta-learning from the aspects of accuracy or transferability or both of them in autonomous systems, involving pedestrian tracking, robot navigation, and robotic manipulation. Finally, we discuss several challenges and future topics for the use of adversarial learning, RL, and meta-learning in autonomous systems.}
}
@article{WITSIL2020104494,
title = {Analyzing continuous infrasound from Stromboli volcano, Italy using unsupervised machine learning},
journal = {Computers & Geosciences},
volume = {140},
pages = {104494},
year = {2020},
issn = {0098-3004},
doi = {https://doi.org/10.1016/j.cageo.2020.104494},
url = {https://www.sciencedirect.com/science/article/pii/S0098300420300352},
author = {Alex J.C. Witsil and Jeffrey B. Johnson},
keywords = {Volcano infrasound, Volcano monitoring, Unsupervised machine learning, Clustering, Puffing, Stromboli volcano},
abstract = {Infrasound data are used by scientists and monitoring observatories to track shifts in eruptive behavior, identify signs of unrest, and ultimately help forecast major eruptions. However, infrasound analyses are often limited to a catalog of discrete or high-amplitude transient events, which can leave lower-amplitude emergent or continuous signals within the datastream unexplored. This study classifies continuous volcano infrasound data using unsupervised learning in order to better constrain eruptive behavior through time. Data were recorded from 9 through 12 September (2018) at Stromboli, Italy by three infrasound arrays sampling at 200 Hz and deployed within 400 m of the active vents. Recorded pressure amplitudes were synthesized into a set of characteristic features extracted from the time and frequency domains of five second overlapping windows. Features were then clustered via the k-means algorithm resulting in a time-series of discrete labels that track the evolutionary behavior during the three-day experiment. Waveforms associated with each cluster relate to commonly recorded volcanic signals including Strombolian events, puffing activity, and sustained degassing. Infrasound radiated predominantly from six vent regions, each of which exhibit temporal variability in their degassing behavior. The three-day history of activity reveals an exchange of function across multiple vents indicating potential linkages in the plumbing system.}
}
@article{REN2020124,
title = {Distributed cooperative learning over time-varying random networks using a gossip-based communication protocol},
journal = {Fuzzy Sets and Systems},
volume = {394},
pages = {124-145},
year = {2020},
note = {Neurofuzzy Systems and Learning},
issn = {0165-0114},
doi = {https://doi.org/10.1016/j.fss.2019.05.009},
url = {https://www.sciencedirect.com/science/article/pii/S0165011419302647},
author = {Pengfei Ren and Hao Dai and Weisheng Chen},
keywords = {Machine learning, Distributed cooperative learning (DCL), Consensus, Gossip-based communication protocol, Fuzzy logic systems},
abstract = {Motivated by applications of distributed estimation and distributed decision making in wireless sensor networks (WSNs) and unmanned aerial vehicle (UAV) networks, we study a distributed learning problem over time-varying undirected random networks. Using a gossip-based communication protocol, a novel distributed cooperative learning (DCL) algorithm, termed the gossip-based DCL (GBDCL) algorithm, is presented to solve the problem by training the raw data distributed and blocked throughout different nodes. Exploiting the robustness of the gossip-based protocol, each node is guaranteed to build the same learning model in theory against random disconnections and communication route variations in the network topology. It is proved that the GBDCL algorithm converges to the optimal consensus asymptotically. The correctness and effectiveness of the presented GBDCL algorithm are verified in the theoretical analysis and simulations.}
}
@article{BISCHOFF2021105922,
title = {Technological support for detection and prediction of plant diseases: A systematic mapping study},
journal = {Computers and Electronics in Agriculture},
volume = {181},
pages = {105922},
year = {2021},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2020.105922},
url = {https://www.sciencedirect.com/science/article/pii/S0168169920331276},
author = {Vinicius Bischoff and Kleinner Farias and Juliano Paulo Menzen and Gustavo Pessin},
keywords = {Systematic review, Disease detection, Machine learning, Sensors},
abstract = {The field of plant disease diagnosis and epidemiology seeks to assess symptoms caused by pathogens. Different infectious and non-infectious agents can cause similar symptoms in plant organs. Diagnosing diseases is crucial, but it remains an inherently manual and error-prone task. Many works have been proposed to diagnose plant diseases, mainly using machine learning approaches. Even though this field affects agribusiness areas, little has been done to classify and map the current literature. This article presents a comprehensive overview of the current literature, and draw some research gaps, trends, and challenges that are worth investigating. A systematic mapping of the literature was carried out in pairs, following well-established practice guidelines. In total, 56 primary studies were carefully selected from a sample of 668 papers, which were retrieved from 9 widely recognized electronic databases. They were analyzed and categorized to answer seven research questions. The results show that 41% of primary studies applied machine learning techniques to detect diseases, 32% used image sensors to identify symptoms related to plant diseases, 30% focused on proposing new models of machine learning to detect diseases 34% were evaluation studies, and 71% were published in scientific journals. The association between computer vision and neural networks appears as a promising field of research for the detection of diseases. Finally, this article can serve as a starting point for upcoming studies, providing insights from a systematic map of the literature.}
}
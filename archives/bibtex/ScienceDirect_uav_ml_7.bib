@article{WANG2022104458,
title = {Review on deep learning techniques for marine object recognition: Architectures and algorithms},
journal = {Control Engineering Practice},
volume = {118},
pages = {104458},
year = {2022},
issn = {0967-0661},
doi = {https://doi.org/10.1016/j.conengprac.2020.104458},
url = {https://www.sciencedirect.com/science/article/pii/S0967066120300964},
author = {Ning Wang and Yuanyuan Wang and Meng Joo Er},
keywords = {Deep learning, Marine object recognition, Marine vehicles, Learning architecture},
abstract = {Due to the rapid development of deep learning techniques, numerous frameworks including convolutional neural networks (CNNs), deep belief networks (DBNs) and auto-encoder (AE), etc., have been established. In this context, advances in marine object recognition have been dramatically boosted, especially in the past decade. In this paper, we exclusively focus on an intensive review on deep-learning-based object recognition for both surface and underwater targets. To facilitate a comprehensive review, key concepts and typical architectures are firstly summarized in a unified framework. Accordingly, popular/benchmark datasets for marine object recognition are thoroughly collected and deep learning methodologies are comprehensively analyzed with intensive comparisons. Moreover, experimental results and futuristic trends in marine object recognition are intensively discussed. Finally, conclusions on state-of-the-art marine object recognition using deep learning techniques are drawn.}
}
@article{YUAN2021114417,
title = {A review of deep learning methods for semantic segmentation of remote sensing imagery},
journal = {Expert Systems with Applications},
volume = {169},
pages = {114417},
year = {2021},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2020.114417},
url = {https://www.sciencedirect.com/science/article/pii/S0957417420310836},
author = {Xiaohui Yuan and Jianfang Shi and Lichuan Gu},
keywords = {Semantic image segmentation, Deep neural networks, Remote sensing imagery},
abstract = {Semantic segmentation of remote sensing imagery has been employed in many applications and is a key research topic for decades. With the success of deep learning methods in the field of computer vision, researchers have made a great effort to transfer their superior performance to the field of remote sensing image analysis. This paper starts with a summary of the fundamental deep neural network architectures and reviews the most recent developments of deep learning methods for semantic segmentation of remote sensing imagery including non-conventional data such as hyperspectral images and point clouds. In our review of the literature, we identified three major challenges faced by researchers and summarize the innovative development to address them. As tremendous efforts have been devoted to advancing pixel-level accuracy, the emerged deep learning methods demonstrated much-improved performance on several public data sets. As to handling the non-conventional, unstructured point cloud and rich spectral imagery, the performance of the state-of-the-art methods is, on average, inferior to that of the satellite imagery. Such a performance gap also exists in learning from small data sets. In particular, the limited non-conventional remote sensing data sets with labels is an obstacle to developing and evaluating new deep learning methods.}
}
@article{ASADZADEH2022109633,
title = {UAV-based remote sensing for the petroleum industry and environmental monitoring: State-of-the-art and perspectives},
journal = {Journal of Petroleum Science and Engineering},
volume = {208},
pages = {109633},
year = {2022},
issn = {0920-4105},
doi = {https://doi.org/10.1016/j.petrol.2021.109633},
url = {https://www.sciencedirect.com/science/article/pii/S0920410521012675},
author = {Saeid Asadzadeh and Wilson José de Oliveira and Carlos Roberto de {Souza Filho}},
keywords = {UAV, UAS, Drone remote sensing, Oil and gas industry, Detection and inspection, Petroleum exploration and mapping},
abstract = {An unmanned aerial vehicle (UAV), popularly known as a drone, is an aircraft without a human pilot aboard. Recent developments in sensor technology and navigation systems have made drones a powerful and reliable basis for professional data acquisition. Today, the use of UAVs has expanded massively in the civil and commercial sectors and this technology has found its way into almost every industrial sector including the petroleum industry. Drone technology offers a great potential to revolutionize the mapping, monitoring, inspection, and surveillance procedures of the petroleum industry by providing a faster, safer, and more cost-efficient way of mass data collection. This article offers a review of the common UAV platforms and sensor systems and highlights the state-of-the-art and application examples of drone remote sensing in the oil and gas industry. Six broad areas are recognized comprising offshore oil spill detection, oil leakage detection, pipeline monitoring, gas emission sensing, remote facility inspection, petroleum exploration (i.e., land surveying, geologic mapping, and petroleum exploration), and environmental monitoring. Research gaps and open issues along with opportunities for further developments in each of these areas are highlighted.}
}
@article{KUMAR2021115409,
title = {Physics-guided deep neural network to characterize non-Newtonian fluid flow for optimal use of energy resources},
journal = {Expert Systems with Applications},
volume = {183},
pages = {115409},
year = {2021},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2021.115409},
url = {https://www.sciencedirect.com/science/article/pii/S0957417421008307},
author = {Abhishek Kumar and Syahrir Ridha and Marneni Narahari and Suhaib Umer Ilyas},
keywords = {Deep neural network, Energy conservation, Machine learning, Non-Newtonian fluid, Navier-Stokes equation},
abstract = {Numerical simulations of non-Newtonian fluids are indispensable for optimization and monitoring of several industrial processes such as crude oil transportation, nuclear cooling, geothermal and fossil fuel production. The governing equations derived for non-Newtonian fluid models result in nonlinear differential equations. Thus, increasing the complexity even for simple geometries. The cumbersome numerical computation and rudimentary empirical solutions hinder faster analysis over a wide range of parameters. However, machine and deep learning methods have higher accuracy but rely heavily on the quality and amount of training data, and the solution may become inconclusive if data is sparse. In this research, a novel algorithm (Herschel Bulkley Network) is introduced to simulate the non-Newtonian fluid flow in a pipe using data redundant deep neural network (DNN) for fully developed, laminar, and incompressible flow conditions. The objective of this investigation is to develop a physics dominated DNN solely driven by minimizing residuals from the Navier-Stokes based governing equations, establishing benchmark research. Herschel-Bulkley model is used to approximate the complex rheological behavior of a non-Newtonian fluid. The proposed DNN algorithm is structured to incorporate initial/boundary conditions in cylindrical coordinates and approximate the solution without the aid of any simulated or training data. The simulated results and analysis demonstrate an excellent agreement between the proposed algorithm and non-Newtonian fluids flow attributes. The detailed parametric analysis exhibits the competency of the proposed algorithm to explain the rheological features. Monte-Carlo simulation is performed by propagating uncertainty to investigate the dominant parameters affecting simulated results. The uncertainty in fluid consistency index is responsible for higher variance in the calculated flow rate, while the least variation is observed due to fluid behavior index uncertainty. The performance of the algorithm is validated with experimental datasets. The statistical error estimation exhibits a mean absolute error of 11.5%, and root mean squared error of 0.87. A comprehensive analysis on training unsupervised DNN and adjusted hyperparameters is also highlighted to achieve expedite convergence.}
}
@article{HASSAN201995,
title = {A rapid monitoring of NDVI across the wheat growth cycle for grain yield prediction using a multi-spectral UAV platform},
journal = {Plant Science},
volume = {282},
pages = {95-103},
year = {2019},
note = {The 4th International Plant Phenotyping Symposium},
issn = {0168-9452},
doi = {https://doi.org/10.1016/j.plantsci.2018.10.022},
url = {https://www.sciencedirect.com/science/article/pii/S0168945217310208},
author = {Muhammad Adeel Hassan and Mengjiao Yang and Awais Rasheed and Guijun Yang and Matthew Reynolds and Xianchun Xia and Yonggui Xiao and Zhonghu He},
keywords = {High throughput phenotyping, Multi-spectral imaging, Normalized difference vegetation index, Unmanned aerial vehicle},
abstract = {Wheat improvement programs require rapid assessment of large numbers of individual plots across multiple environments. Vegetation indices (VIs) that are mainly associated with yield and yield-related physiological traits, and rapid evaluation of canopy normalized difference vegetation index (NDVI) can assist in-season selection. Multi-spectral imagery using unmanned aerial vehicles (UAV) can readily assess the VIs traits at various crop growth stages. Thirty-two wheat cultivars and breeding lines grown in limited irrigation and full irrigation treatments were investigated to monitor NDVI across the growth cycle using a Sequoia sensor mounted on a UAV. Significant correlations ranging from R2 = 0.38 to 0.90 were observed between NDVI detected from UAV and Greenseeker (GS) during stem elongation (SE) to late grain gilling (LGF) across the treatments. UAV-NDVI also had high heritabilities at SE (h2 = 0.91), flowering (F)(h2 = 0.95), EGF (h2 = 0.79) and mid grain filling (MGF) (h2 = 0.71) under the full irrigation treatment, and at booting (B) (h2 = 0.89), EGF (h2 = 0.75) in the limited irrigation treatment. UAV-NDVI explained significant variation in grain yield (GY) at EGF (R2 = 0.86), MGF (R2 = 0.83) and LGF (R2 = 0.89) stages, and results were consistent with GS-NDVI. Higher correlations between UAV-NDVI and GY were observed under full irrigation at three different grain-filling stages (R2 = 0.40, 0.49 and 0.45) than the limited irrigation treatment (R2 = 0.08, 0.12 and 0.14) and GY was calculated to be 24.4% lower under limited irrigation conditions. Pearson correlations between UAV-NDVI and GY were also low ranging from r = 0.29 to 0.37 during grain-filling under limited irrigation but higher than GS-NDVI data. A similar pattern was observed for normalized difference red-edge (NDRE) and normalized green red difference index (NGRDI) when correlated with GY. Fresh biomass estimated at late flowering stage had significant correlations of r = 0.30 to 0.51 with UAV-NDVI at EGF. Some genotypes Nongda 211, Nongda 5181, Zhongmai 175 and Zhongmai 12 were identified as high yielding genotypes using NDVI during grain-filling. In conclusion, a multispectral sensor mounted on a UAV is a reliable high-throughput platform for NDVI measurement to predict biomass and GY and grain-filling stage seems the best period for selection.}
}
@article{SHAHID2021103751,
title = {Machine learning research towards combating COVID-19: Virus detection, spread prevention, and medical assistance},
journal = {Journal of Biomedical Informatics},
volume = {117},
pages = {103751},
year = {2021},
issn = {1532-0464},
doi = {https://doi.org/10.1016/j.jbi.2021.103751},
url = {https://www.sciencedirect.com/science/article/pii/S1532046421000800},
author = {Osama Shahid and Mohammad Nasajpour and Seyedamin Pouriyeh and Reza M. Parizi and Meng Han and Maria Valero and Fangyu Li and Mohammed Aledhari and Quan Z. Sheng},
keywords = {COVID-19, Machine learning, Artificial intelligence, Healthcare, Drug development, Predictive analysis},
abstract = {COVID-19 was first discovered in December 2019 and has continued to rapidly spread across countries worldwide infecting thousands and millions of people. The virus is deadly, and people who are suffering from prior illnesses or are older than the age of 60 are at a higher risk of mortality. Medicine and Healthcare industries have surged towards finding a cure, and different policies have been amended to mitigate the spread of the virus. While Machine Learning (ML) methods have been widely used in other domains, there is now a high demand for ML-aided diagnosis systems for screening, tracking, predicting the spread of COVID-19 and finding a cure against it. In this paper, we present a journey of what role ML has played so far in combating the virus, mainly looking at it from a screening, forecasting, and vaccine perspective. We present a comprehensive survey of the ML algorithms and models that can be used on this expedition and aid with battling the virus.}
}
@article{YANG2021106092,
title = {Estimation of corn yield based on hyperspectral imagery and convolutional neural network},
journal = {Computers and Electronics in Agriculture},
volume = {184},
pages = {106092},
year = {2021},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2021.106092},
url = {https://www.sciencedirect.com/science/article/pii/S0168169921001101},
author = {Wei Yang and Tyler Nigon and Ziyuan Hao and Gabriel {Dias Paiao} and Fabián G. Fernández and David Mulla and Ce Yang},
keywords = {CNN, Deep learning theory, Hyperspectral Image, Corn yield},
abstract = {Corn is an important food crop in the world, widely distributed in many countries because of its excellent environmental adaptability. Moreover, corn is an important feed source for animal production and it is an indispensable raw material for many different industries. With increasing human population and decreasing arable land, there is an increased focus on increasing yield of corn. Convolutional neural network (CNN) analysis can be used for non-destructive yield prediction and is well suited for classification and feature extraction. The overall objective of this experiment was to use hyperspectral imagery to train a CNN classification model to estimate corn grain yield. High resolution hyperspectral imagery was captured at five corn growth stages - V5 (five leaves with visible leaf collars), V8 (eight leaves with visible leaf collars), V10 (ten leaves with visible leaf collars), V12 (12 leaves with visible leaf collars), and R2 (blister stage). Hyperspectral imagery was denoised using the wavelet analysis method, then was used to train and validate the CNN model. The spectral information reflecting the internal characteristics and the spatial information provided by the color image (red, green and blue bands extracted from hyperspectral image) reflecting the external characteristics of corn growth are extracted for modelling and verification. The results show that the spectral and color image-based integrated CNN model has a classification accuracy of 75.50%. In contrast, the accuracy of a one-dimensional CNN model based only on spectral information or a two-dimensional CNN model based only on color image information were 60.39% and 32.17%, respectively. The integrated CNN model (spectral information plus color image information) is better than results of the individual one-dimensional CNN or two-dimensional CNN models. In addition. The Kappa coefficient of integrated CNN model is 0.69, which indicates a high consistency of classification. Comprehensive use of spectral information and color image information, which represent information about the inner and outer corn canopy can provide more accurate corn yield prediction than one-dimensional or two-dimensional CNN models.}
}
@article{YU202011830,
title = {Decentralized finite-time adaptive fault-tolerant synchronization tracking control for multiple UAVs with prescribed performance},
journal = {Journal of the Franklin Institute},
volume = {357},
number = {16},
pages = {11830-11862},
year = {2020},
note = {Finite-Time Stability Analysis and Synthesis of Complex Dynamic Systems},
issn = {0016-0032},
doi = {https://doi.org/10.1016/j.jfranklin.2019.11.056},
url = {https://www.sciencedirect.com/science/article/pii/S0016003219308609},
author = {Ziquan Yu and Youmin Zhang and Zhixiang Liu and Yaohong Qu and Chun-Yi Su and Bin Jiang},
abstract = {This paper is concerned with the decentralized finite-time fault-tolerant attitude synchronization tracking control problem for multiple unmanned aerial vehicles (multi-UAVs) with prescribed performance. Failure to counteract actuator faults in the formation flight of multi-UAVs in a limited time may lead to catastrophic consequences. By integrating the prescribed performance functions into the synchronization tracking errors, a new set of errors is defined. Based on the transformed errors, a finite-time attitude synchronization tracking control scheme is developed by using neural networks and finite-time differentiator techniques. The neural networks are utilized to identify the unknown nonlinear terms induced by uncertainties and actuator faults. To reduce the computational burden caused by estimating the weight vectors, the norms of weight vectors are used for the estimation, such that the number of adaptive parameters is significantly reduced and independent from the number of neurons. The finite-time differentiators are utilized to estimate the intermediate control signals and their derivatives. Moreover, auxiliary dynamic signals with explicit consideration of differentiator estimation errors are introduced into the control scheme to guarantee the finite-time convergences of the synchronized tracking errors. Furthermore, it is shown that by using the Lyapunov method, all UAVs can track their individual attitude references, while the synchronized tracking errors among UAVs are all bounded in finite time and confined within the prescribed performance bounds. Finally, comparative simulation studies on multi-UAVs are conducted to verify the effectiveness of the proposed scheme.}
}
@article{FERNANDEZGUISURAGA2022114373,
title = {Monitoring post-fire neighborhood competition effects on pine saplings under different environmental conditions by means of UAV multispectral data and structure-from-motion photogrammetry},
journal = {Journal of Environmental Management},
volume = {305},
pages = {114373},
year = {2022},
issn = {0301-4797},
doi = {https://doi.org/10.1016/j.jenvman.2021.114373},
url = {https://www.sciencedirect.com/science/article/pii/S030147972102435X},
author = {José Manuel Fernández-Guisuraga and Leonor Calvo and Susana Suárez-Seoane},
keywords = {Competition, Fire, Object-based image analysis, Pine, Shrub, Unmanned aerial vehicle},
abstract = {In burned landscapes, the recruitment success of the tree dominant species mainly depends on plant competition mechanisms operating at fine spatial scale, that may hinder resource availability during the former years after the disturbance. Data acquisition at very high spatial resolution from unmanned aerial vehicles (UAV) have promoted new opportunities for understanding context-dependent competition processes in post-fire environments. Here, we explored the potentiality of UAV-borne data for assessing inter-specific competition effects of understory woody vegetation on pine saplings, as well as intra-specific interactions of neighboring saplings, across three burned landscapes located along a climatic/productivity gradient in the Iberian Peninsula. Geographic object-based image analysis (GEOBIA), including multiresolution segmentation and support vector machine (SVM) classification, was used to map pine saplings and understory shrubs at species level. Input data were, on the one hand, multispectral (11.31 cm·pixel−1) and Structure-from-Motion (SfM) canopy height model (CHM) data fusion, hereafter MS-CHM, and, on the other, RGB (3.29 cm·pixel−1) and CHM data fusion, hereafter RGB-CHM. A Random Forest (RF) regression algorithm was used to evaluate the effects of neighborhood competition on the relative growth in height of 50 pine saplings randomly sampled across the MS-CHM classified map. Circular plots of 3 m radius were set from the centroid of each target pine sapling to measure percentage cover, mean height of all individuals in the plot and mean height of individuals contacting the target sapling. Competing shrub species were differentiated according to their fire-adaptive traits (i.e. seeders vs resprouters). Object-based image classification applied on MS-CHM yielded higher overall accuracy for the three sites (83.67% ± 3.06%) than RGB-CHM (74.33% ± 3.21%). Intra-specific competitive effects were not detected, whereas increasing cover and height of shrub neighbors had a significant non-linear impact on the growth on pine saplings across the study sites. The strongest competitive effects of seeder shrubs occurred in open areas with low vegetation cover and fuel continuity, following a gap-dependent model. The non-linear relationships evidenced in this study between the structure of neighboring shrubs and the growth of pine seedlings/saplings have profound implications for considering possible competing thresholds in post-fire decision-making processes. These results endorse the use of UAV multispectral and SfM photogrammetry as a valuable post-fire management tool for measuring accurately the effect of competition in heterogeneous burned landscapes.}
}
@article{DUO2021100387,
title = {Robust 3D trajectory and power design in probabilistic LoS channel for UAV-enabled cooperative jamming},
journal = {Vehicular Communications},
volume = {32},
pages = {100387},
year = {2021},
issn = {2214-2096},
doi = {https://doi.org/10.1016/j.vehcom.2021.100387},
url = {https://www.sciencedirect.com/science/article/pii/S2214209621000565},
author = {Bin Duo and Hao Hu and Yilian Li and Yanmei Hu and Xing Zhu},
keywords = {UAV communication, Physical-layer security, Cooperative jamming, Probabilistic LoS channel, Trajectory design, Power control},
abstract = {This paper proposes a mobile unmanned aerial vehicle (UAV)-enabled jamming scheme under the probabilistic line-of-sight (LoS) channel model to improve the secrecy of ground wiretap channels in urban areas, where a friendly UAV is deployed to cooperatively transmit jamming signals to confuse the suspicious ground eavesdroppers. Our goal is to maximize the average (expected) secrecy rate by jointly optimizing the user scheduling, the source's transmit power, the UAV's jamming power and its three-dimensional (3D) trajectory for a given flight time. Since the expected secrecy rate is highly complicated with respect to the 3D UAV trajectory, we derive a more tractable lower bound for it. Nevertheless, the resulting optimization problem is still non-convex and difficult to solve optimally due to the imperfect location information of the eavesdroppers. To tackle such an intractable problem, we first derive a worst-case (expected) secrecy rate, and then we propose an efficient iterative algorithm to obtain a suboptimal solution to it by applying the block coordinate descent (BCD) and successive convex approximation (SCA) techniques. Simulation results show that the proposed algorithm under the probabilistic LoS channel model significantly outperforms various benchmark algorithms.}
}
@article{PENG2020364,
title = {Wild animal survey using UAS imagery and deep learning: modified Faster R-CNN for kiang detection in Tibetan Plateau},
journal = {ISPRS Journal of Photogrammetry and Remote Sensing},
volume = {169},
pages = {364-376},
year = {2020},
issn = {0924-2716},
doi = {https://doi.org/10.1016/j.isprsjprs.2020.08.026},
url = {https://www.sciencedirect.com/science/article/pii/S0924271620302409},
author = {Jinbang Peng and Dongliang Wang and Xiaohan Liao and Quanqin Shao and Zhigang Sun and Huanyin Yue and Huping Ye},
keywords = {Wild animal survey, Deep learning, Object detection, Unmanned aircraft systems (UAS)},
abstract = {Wild animal surveys play a critical role in wild animal conservation and ecosystem management. Unmanned aircraft systems (UASs), with advantages in safety, convenience and inexpensiveness, have been increasingly used in wild animal surveys. However, manually reviewing wild animals from thousands of images generated by UASs is tedious and inefficient. To support wild animal detection in UAS images, researchers have developed various automatic and semiautomatic algorithms. Among these algorithms, deep learning techniques achieve outstanding performances in wild animal detection, but have some practical issues (e.g., limited animal pixels and sparse animal samples). Based on a typical deep learning pipeline, faster region based convolutional neural networks (Faster R-CNN), this study adopted several tactics, including feature stride shortening, anchor size optimization, and hard negative class, to overcome the practical issues in wild animal detection in UAS images. In this study, a kiang survey was conducted in UAS datasets (23,748 images) obtained by 14 flight campaigns in the eastern Tibetan Plateau. The validation experiments of our adopted tactics revealed the following: (1) feature stride shortening and anchor size optimization improved small animal detection performance in the animal patch set, increasing the F1 score from 0.84 to 0.86 and from 0.86 to 0.92, respectively; and (2) the hard negative class significantly suppressed false positives in the full UAS image set, increasing the F1 score from 0.44 to 0.86. The test results in the full UAS image set showed that the modified model with the adopted tactics can be applied to either a semiautomatic survey to accelerate manual verification by 25 times or an automatic survey with an F1 score of approximately 0.90. This study demonstrates that the combination of UAS and deep learning techniques can enable automatic/semiautomatic, accurate, inexpensive, and efficient wild animal surveys.}
}
@article{SANKEY2021112223,
title = {Quantifying plant-soil-nutrient dynamics in rangelands: Fusion of UAV hyperspectral-LiDAR, UAV multispectral-photogrammetry, and ground-based LiDAR-digital photography in a shrub-encroached desert grassland},
journal = {Remote Sensing of Environment},
volume = {253},
pages = {112223},
year = {2021},
issn = {0034-4257},
doi = {https://doi.org/10.1016/j.rse.2020.112223},
url = {https://www.sciencedirect.com/science/article/pii/S0034425720305964},
author = {Joel B. Sankey and Temuulen T. Sankey and Junran Li and Sujith Ravi and Guan Wang and Joshua Caster and Alan Kasprak},
keywords = {Airborne data, Drone, Unmanned aerial system (UAS), Unmanned aerial vehicle (UAV), Terrestrial laser scanning, Photogrammetry, Structure from motion (SFM), Lidar, Hyperspectral, Machine learning, Digital elevation model (DEM), Digital elevation model of difference (DOD), Change detection, Rangeland, Shrub, Grass, Soil, Nutrient, Fire, Islands of fertility},
abstract = {Rangelands cover 70% of the world's land surface, and provide critical ecosystem services of primary production, soil carbon storage, and nutrient cycling. These ecosystem services are governed by very fine-scale spatial patterning of soil carbon, nutrients, and plant species at the centimeter-to-meter scales, a phenomenon known as “islands of fertility”. Such fine-scale dynamics are challenging to detect with most satellite and manned airborne platforms. Remote sensing from unmanned aerial vehicles (UAVs) provides an alternative option for detecting fine-scale soil nutrient and plant species changes in rangelands tn0020 smaller extents. We demonstrate that a model incorporating the fusion of UAV multispectral and structure-from-motion photogrammetry classifies plant functional types and bare soil cover with an overall accuracy of 95% in rangelands degraded by shrub encroachment and disturbed by fire. We further demonstrate that employing UAV hyperspectral and LiDAR fusion greatly improves upon these results by classifying 9 different plant species and soil fertility microsite types (SFMT) with an overall accuracy of 87%. Among them, creosote bush and black grama, the most important native species in the rangeland, have the highest producer's accuracies at 98% and 94%, respectively. The integration of UAV LiDAR-derived plant height differences was critical in these improvements. Finally, we use synthesis of the UAV datasets with ground-based LiDAR surveys and lab characterization of soils to estimate that the burned rangeland potentially lost 1474 kg/ha of C and 113 kg/ha of N owing to soil erosion processes during the first year after a prescribed fire. However, during the second-year post-fire, grass and plant-interspace SFMT functioned as net sinks for sediment and nutrients and gained approximately 175 kg/ha C and 14 kg/ha N, combined. These results provide important site-specific insight that is relevant to the 423 Mha of grasslands and shrublands that are burned globally each year. While fire, and specifically post-fire erosion, can degrade some rangelands, post-fire plant-soil-nutrient dynamics might provide a competitive advantage to grasses in rangelands degraded by shrub encroachment. These novel UAV and ground-based LiDAR remote sensing approaches thus provide important details towards more accurate accounting of the carbon and nutrients in the soil surface of rangelands.}
}
@article{SATHEESHKUMAR20217925,
title = {Blockchain based peer to peer communication in autonomous drone operation},
journal = {Energy Reports},
volume = {7},
pages = {7925-7939},
year = {2021},
issn = {2352-4847},
doi = {https://doi.org/10.1016/j.egyr.2021.08.073},
url = {https://www.sciencedirect.com/science/article/pii/S2352484721006752},
author = {M. {Satheesh Kumar} and S. Vimal and N.Z. Jhanjhi and Shanmuga Sundar Dhanabalan and Hesham A. Alhumyani},
keywords = {Cyber security, Unmanned Aerial Vehicles (UAVs), GNSS, GPS spoofing, Energy trading, Blockchain, Integrity},
abstract = {With the prevalence of Aerospace Technologies, the regulations of cybersecurity are becoming smarter, assured, and long-lasting. Modern communication network technologies have enormous growth in the cyber threats and masquerading attacks to steal data. Hence concepts and mechanisms are built and made into regulations for a safer environment. Unmanned aerial vehicles (UAVs), often known as drones, are becoming increasingly common, posing new problems in areas such as monitoring, agriculture, weather prediction, surveillance and other fields. This includes a large number of devices that, owing to a lack of energy or a system shutdown, might occasionally send incorrect signals and must be monitored autonomously by drones in remote regions. In this paper, we propose a energy intensive blockchain-based platform for controlling drone operations while ensuring trust and security for all parties involved. The goal of this paper is to explore the extent of Unmanned Aerial Vehicle (UAV) vulnerability to deceptive (Global Navigation Satellite System) GNSS signals by establishing the necessary conditions for UAV via GPS (Global Positioning System) spoofing. The existing algorithms used to mitigate spoofing attacks have unbounded long-term errors, which increase in time during its performance. An innovative idea is necessitating to eliminate those errors, thereby in the proposed work, Ethereum Blockchain has been implemented to create a blockchain network to mitigate the spoofing attacks. Blockchains are incredibly popular nowadays and is the basic technology for cryptocurrencies. Blockchain technology greatly impacts the applications in UAVs. The proposed methodology uses the network that has to be registered in the aerospace components through the ledger associated with relevant data communication in the Blockchain. When an intruder gets acquired with the data in the network with a single block, it cannot affect the entire network due to the data integrity in the ledgers that has been cryptographically assigned. The blockchain network intermittently verifies the geolocation data so that any outlying data would be detected and eliminated quickly. The data that has been verified is made available for the view of aviation and spacecraft operations through the distributed network. The proposed methodology outperforms the existing methods in intense drift error and, in the case of confidentiality and integrity, it has very low risk when compared to existing methods.}
}
@article{ZHANG2019105052,
title = {Bayesian calibration of AquaCrop model for winter wheat by assimilating UAV multi-spectral images},
journal = {Computers and Electronics in Agriculture},
volume = {167},
pages = {105052},
year = {2019},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2019.105052},
url = {https://www.sciencedirect.com/science/article/pii/S0168169919313468},
author = {Tianxiang Zhang and Jinya Su and Cunjia Liu and Wen-Hua Chen},
keywords = {Unmanned Aerial Vehicle (UAV), Multispectral image, Machine learning, Model calibration, Bayesian inference},
abstract = {Crop growth model plays a paramount role in smart farming management, which not only provides quantitative information on crop development but also evaluates various management strategies. A reliable model is desirable but challenging due to the presence of unknown and uncertain parameters; therefore, crop model calibration is significant to achieve its potentials. This work is focused on the calibration of AquaCrop model by leveraging advanced Bayesian inference algorithms and UAV multi-spectral images at field scales. In particular, aerial images with high spatial-temporal resolutions are first applied to obtain Canopy Cover (CC) value by using machine learning based classification. The CC is then assimilated into AquaCrop model and uncertain parameters could be inferred by Markov Chain Monte Carlo (MCMC). Both simulation and experimental validation are performed. The experimental aerial images of winter wheat at Yangling district from Oct/2017 to June/2018 are applied to validate the proposed method against the conventional optimisation based approach by Simulated Annealing (SA). 100 Monte Carlo simulations show that the root mean squared error (RMSE) of Bayesian approach yields a smaller parameter estimation error than optimisation approach. While the experimental results show that: (i) a good wheat/background classification result is obtained for the accurate calculation of CC; (ii) the predicted CC values by Bayesian approach are consistent with measurements by 4-fold cross validation, where the RMSE is 0.0271 smaller than optimisation approach (0.0514); (iii) in addition to parameter estimation, their distribution information is also obtained in the developed Bayesian approach, reflecting the prediction confidence. It is believed that the Bayesian model calibration, although is developed for AquaCrop model, can find a wide range of applications to various simulation models in agriculture and forestry.}
}
@article{SHAHZADI2021103114,
title = {UAV assisted 5G and beyond wireless networks: A survey},
journal = {Journal of Network and Computer Applications},
volume = {189},
pages = {103114},
year = {2021},
issn = {1084-8045},
doi = {https://doi.org/10.1016/j.jnca.2021.103114},
url = {https://www.sciencedirect.com/science/article/pii/S108480452100134X},
author = {Rizwana Shahzadi and Mudassar Ali and Humayun Zubair Khan and Muhammad Naeem},
abstract = {There is a huge technological advancement in the field of wireless communication in the last few decades. Technology has revolutionized from voice communication to interactive multimedia applications. A tremendous increase in high data rate and connectivity demanding user equipment is observed. There is an immense need for new technological trends to satisfy the cutting edge requirements of 5G and beyond wireless communication networks. Mobility, manoeuvrability, low cost and Line of sight (LOS) communication makes unmanned aerial vehicle (UAV) as a promising candidate for future wireless communication networks. Despite numerous benefits of UAV’s assisted wireless networks several challenges also exist, which need to be addressed. Among those challenges Optimized 3D placement and resource allocation, state of the artwork, solution and future research directions are presented in this article.}
}
@article{ZHAO2019407,
title = {C-loss based extreme learning machine for estimating power of small-scale turbojet engine},
journal = {Aerospace Science and Technology},
volume = {89},
pages = {407-419},
year = {2019},
issn = {1270-9638},
doi = {https://doi.org/10.1016/j.ast.2019.04.023},
url = {https://www.sciencedirect.com/science/article/pii/S1270963818319242},
author = {Yong-Ping Zhao and Jian-Feng Tan and Jian-Jun Wang and Zhe Yang},
keywords = {Machine learning, Single layer feedforward neural networks, Small-scale turbojet engine, Unmanned aerial vehicles},
abstract = {As a high-efficiency training method for single layer feedforward neural networks, extreme learning machine (ELM) has drawn much interest recently, but its robustness is not good due to the adoption of the square loss function. Hence, the convex loss function in ELM is replaced with a nonconvex loss function, i.e., the C-loss function, so a novel algorithm, called C-loss based ELM (CELM), is proposed in this paper. According to the experimental results on a toy example and two benchmark data sets, CELM performs better than the other algorithms with respect to the generalization performance. To be more important, when CELM is used to estimate power of small-scale turbojet engine, it also dominates the other algorithms, which makes the development of the potential control structure, viz., the direct power control, for the unmanned aerial vehicles more feasible.}
}
@article{SALUDHEEN20216839,
title = {Carbon fibre composite development for in-ground UAV’s with NACA0012 aerofoil wing},
journal = {Materials Today: Proceedings},
volume = {47},
pages = {6839-6848},
year = {2021},
note = {International Conference on Advances in Design, Materials and Manufacturing},
issn = {2214-7853},
doi = {https://doi.org/10.1016/j.matpr.2021.05.142},
url = {https://www.sciencedirect.com/science/article/pii/S2214785321037184},
author = {Ajanas Saludheen and Firaz {Muhammed Zakariya} and M Ankith and Nirmal Nandakumar and Jais George and Godwin Thankachen and R Renjith and A {Ajith Kumar} and A. Viswanath and P.N Jithin},
keywords = {Carbon fibre reinforced polymer, Unmanned aerial vehicles, Weighted average method, Monocoque, Genetic Algorithm},
abstract = {A carbon fibre reinforced polymer is designed for NACA0012 airfoil wing using a finite element model to determine the stresses and deformation by considering the aerodynamic loads from wind tunnel testing. The composite airfoil is designed for the use in morphing wings which are known to increase the aerodynamic efficiency of unmanned aerial vehicles. This paper deals with the design procedures of modelling a composite wing using different design variables in conformance to the first order shear deformation theory using ANSYS® 19.2 and optimizing the design by using a fourth degree polynomial found by surface fitting and genetic algorithm in MATLAB® R2020a. The analysis is carried out on 125 samples consisting of different materials, orientation and thickness. The pressure loads found from the wind tunnel testing was converted using weighted average method and applied in ANSYS® 19.2. While designing the airfoil, monocoque concept is used for structural integrity and this is implemented by the usage of Styrene acrylonitrile at the leading and trailing edges which has high strength to weight ratio. The composite laminae with a certain orientation and thickness is found to have the lowest deformation of 158 nm in response to the aerodynamic load.}
}
@article{XI2022117962,
title = {Accurate and reliable state of charge estimation of lithium ion batteries using time-delayed recurrent neural networks through the identification of overexcited neurons},
journal = {Applied Energy},
volume = {305},
pages = {117962},
year = {2022},
issn = {0306-2619},
doi = {https://doi.org/10.1016/j.apenergy.2021.117962},
url = {https://www.sciencedirect.com/science/article/pii/S0306261921012691},
author = {Zhimin Xi and Rui Wang and Yuhong Fu and Chris Mi},
keywords = {Lithium ion battery, State of charge, Time-delayed recurrent neural network, Overexcited neurons, Equivalent circuit models},
abstract = {Various neural network models have been adopted for lithium ion battery state of charge (SOC) estimation with good accuracy. However, problems for battery states estimation from neural networks were usually not reported, which is mainly due to the lack of effective solutions other than a trial and error training process. This paper firstly proposes time-delayed recurrent neural network for lithium ion battery modeling and SOC estimation. Both exceptional performances and unexpected overfitting or poor performances are reported with in-depth analysis of the root cause. With explicit formulation of the network, each hidden neuron’s output is examined. It is discovered that overexcited neurons could be the root cause for unexpected poor performances of the neural network. Without overexcited neurons, expectational SOC estimation accuracy is consistently obtained with estimation error being less than 1% for lithium ion magnesium phosphate (LiFeMgPO4) batteries considering a fair comparison in literature.}
}
@article{ALMEGREN201888,
title = {A Multi-UAV Task Allocation Algorithm Combatting Red Palm Weevil Infestation},
journal = {Procedia Computer Science},
volume = {141},
pages = {88-95},
year = {2018},
note = {The 9th International Conference on Emerging Ubiquitous Systems and Pervasive Networks (EUSPN-2018) / The 8th International Conference on Current and Future Trends of Information and Communication Technologies in Healthcare (ICTH-2018) / Affiliated Workshops},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2018.10.153},
url = {https://www.sciencedirect.com/science/article/pii/S1877050918318039},
author = {Shiroq Al-Megren and Heba Kurdi and Munirah F. Aldaood},
keywords = {Unmanned aerial vehicles, multi-UAV, bio-inspired algorithms, bacteria, red palm weevil, task allocation},
abstract = {The spread of red palm weevil (RPW) infestation of palm trees is prevalent in many countries, causing tremendous economic losses estimated at multi-millions of dollars annually. The utilization of a swarm of multiple unmanned aerial vehicles (UAVs) with suitable equipment has the potential to support RPW detect and treat (DAT) missions. Nevertheless, this approach raises a challenge regarding the efficient distribution of UAVs during search and detect tasks within the constraints of a mission. This paper proposes a new autonomous bio-inspired approach for efficiently allocating tasks among multiple UAVs during DAT missions. The new approach is inspired by the autonomous behaviour of bacteria as they forage for food. The performance of the proposed algorithm was benchmarked against two long-standing multi-UAV task allocation paradigms: opportunistic task allocation and auction-based heuristics, which were thoroughly tested in simulated DAT mission scenarios to comparatively assess their performance. The experimental results demonstrated the superior performance of the proposed algorithm, as it detected more infestations at shorter runtimes. These results validate the high flexibility, scalability, and sustainability of the proposed approach.}
}
@article{LIU2022102734,
title = {Towards a robust FANET: Distributed node importance estimation-based connectivity maintenance for UAV swarms},
journal = {Ad Hoc Networks},
volume = {125},
pages = {102734},
year = {2022},
issn = {1570-8705},
doi = {https://doi.org/10.1016/j.adhoc.2021.102734},
url = {https://www.sciencedirect.com/science/article/pii/S1570870521002213},
author = {Chao Liu and Zhongshan Zhang},
keywords = {Flying ad hoc network, Algebraic connectivity, Node importance ranking, Connectivity maintenance, Distributed algorithm},
abstract = {The emergence of unmanned aerial vehicle (UAV) swarms has brought a variety of critical challenges to solve. Among them, connectivity maintenance has been the subject of numerous investigations. Especially in a network whose topology dynamically changes, such as the flying ad hoc network (FANET), the connectivity is prone to be lost when topology changes. Besides, the network connectivity tends to deteriorate when node failure occurs. In this paper, a distributed connectivity maintenance framework that considers the vulnerability of nodes and the robustness of a network, is proposed. Firstly, a distributed neighbor selection rule to determine the neighbor set of each node in the network is designed. Secondly, a distributed connectivity maintenance strategy to evaluate the impact of the removal of a node is developed. Based on the perturbation of algebraic connectivity (AC), a distributed node importance evaluation algorithm is designed to approximate the AC measure of the resulting network. Finally, numerical simulation results are presented to validate the effectiveness of the proposed framework.}
}
@article{LOPEZSANCHEZ2021243,
title = {Adaptive trajectory tracking control for quadrotors with disturbances by using generalized regression neural networks},
journal = {Neurocomputing},
volume = {460},
pages = {243-255},
year = {2021},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2021.06.079},
url = {https://www.sciencedirect.com/science/article/pii/S0925231221010092},
author = {Ivan Lopez-Sanchez and Francisco Rossomando and Ricardo Pérez-Alcocer and Carlos Soria and Ricardo Carelli and Javier Moreno-Valenzuela},
keywords = {Generalized regression neural network, Adaptive control, Quadrotor, Real-time experiments},
abstract = {In this document, the development and experimental validation of a nonlinear controller with an adaptive disturbance compensation system applied on a quadrotor are presented. The introduced scheme relies on a generalized regression neural network (GRNN). The proposed scheme has a structure consisting of an inner control loop inaccessible to the user (i.e., an embedded controller) and an outer control loop which generates commands for the inner control loop. The adaptive GRNN is applied in the outer control loop. The proposed approach lies in the aptitude of the GRNN to estimate the disturbances and unmodeled dynamic effects without requiring accurate knowledge of the quadrotor parameters. The adaptation laws are deduced from a rigorous convergence analysis ensuring asymptotic trajectory tracking. The proposed control scheme is implemented on the QBall 2 quadrotor. Comparisons with respect to a PD-based control, an adaptive model regressor-based scheme, and an adaptive neural-network controller are carried out. The experimental results validate the functionality of the novel control scheme and show a performance improvement since smaller tracking error values are produced.}
}
@article{ALNAJI2021e06078,
title = {Soil color analysis based on a RGB camera and an artificial neural network towards smart irrigation: A pilot study},
journal = {Heliyon},
volume = {7},
number = {1},
pages = {e06078},
year = {2021},
issn = {2405-8440},
doi = {https://doi.org/10.1016/j.heliyon.2021.e06078},
url = {https://www.sciencedirect.com/science/article/pii/S2405844021001833},
author = {Ali Al-Naji and Ahmed Bashar Fakhri and Sadik Kamel Gharghan and Javaan Chahl},
keywords = {Smart irrigation, Computer vision system, RGB color analysis, Artificial neural network, Feed-forward back propagation neural network},
abstract = {Irrigation operations in agriculture are one of the largest water consumers in the world, and it has been increasing due to rising population and consequent increased demand for food. The development of advanced irrigation technologies based on modern techniques is of utmost necessity to ensure efficient use of water. Smart irrigation based on computer vision could help in achieving optimum water-utilization in agriculture using a highly available digital technology. This paper presents a non-contact vision system based on a standard video camera to predict the irrigation requirements for loam soils using a feed-forward back propagation neural network. The study relies on analyzing the differences in soil color captured by a video camera at different distances, times and illumination levels obtained from loam soil over four weeks of data acquisition. The proposed system used this color information as input to an artificial neural network (ANN) system to make a decision as to whether to irrigate the soil or not. The proposed system was very accurate, achieving a mean square error (MSE) of 1.616 × 10−6 (training), 1.004 × 10−5 (testing) and 1.809 × 10−5 (validation). The proposed system is simple, robust and affordable making it promising technology to support precision agriculture.}
}
@article{SABANCI2020107553,
title = {Artificial intelligence based power consumption estimation of two-phase brushless DC motor according to FEA parametric simulation},
journal = {Measurement},
volume = {155},
pages = {107553},
year = {2020},
issn = {0263-2241},
doi = {https://doi.org/10.1016/j.measurement.2020.107553},
url = {https://www.sciencedirect.com/science/article/pii/S0263224120300907},
author = {Kadir Sabanci},
keywords = {Brushless DC motor, Unmanned aerial vehicle, Artificial neural networks, Extreme machine learning, Support vector machine, FEA simulation},
abstract = {In this study, Artificial Neural Networks, Extreme Machine Learning and Support Vector Machine (SVM) are used to estimate power consumption of Brushless DC motor in Unmanned Aerial Vehicle (UAV). Durafly 3648 Brushless DC motor of UAV is modelled with the Finite Element Analysis software. Then it is simulated with Ansys-Rmxprt according to pulse degree, speed and battery voltage of the UAV. The training times and Mean Absolute Percentage Errors (MAPE) of the Artificial Intelligence Techniques (AITs) are calculated for motor input power estimation. The best result among the implemented AITs is achieved with the MAPE of 0.269% by the SVM model. Then the graphical user interface (GUI) is developed to easily obtain information about how efficient the battery can be used, and the flight time of UAVs. Thanks to the proposed GUI software, the input power of the motor can be estimated via input parameters without the long-time consuming simulations.}
}
@article{NI2022101562,
title = {An effective hybrid V2V/V2I transmission latency method based on LSTM neural network},
journal = {Physical Communication},
volume = {51},
pages = {101562},
year = {2022},
issn = {1874-4907},
doi = {https://doi.org/10.1016/j.phycom.2021.101562},
url = {https://www.sciencedirect.com/science/article/pii/S1874490721002688},
author = {Yiyang Ni and Xiaoqing Li and Haitao Zhao and Jie Yang and Wenchao Xia and Guan Gui},
keywords = {Hybrid V2V/V2I, Vehicle arrival rate, Transmission latency, Neural networks},
abstract = {We propose an effective hybrid vehicle-to-vehicle/vehicle-to-infrastructure (V2V/V2I) transmission latency method based on a long short-term memory (LSTM) neural network to address transmission latency in the internet of vehicles. First, a traffic model is established, and the LSTM artificial neural network is used to predict the vehicle arrival rate in the road section. Second, the vehicle arrival rate function is used to construct an objective function, i.e., the problem of minimizing system transmission the overall latency. The hybrid V2V/V2I transmission method determines the communication transmission mode of the vehicles to minimize transmission latency. The simulation results show that the overall transmission latency is substantially lower for the hybrid V2V/V2I transmission method than the pure V2I transmission method with the transmission packet size and vehicle speed varying.}
}
@article{SEDJELMACI2019101970,
title = {An efficient cyber defense framework for UAV-Edge computing network},
journal = {Ad Hoc Networks},
volume = {94},
pages = {101970},
year = {2019},
issn = {1570-8705},
doi = {https://doi.org/10.1016/j.adhoc.2019.101970},
url = {https://www.sciencedirect.com/science/article/pii/S1570870519302136},
author = {Hichem Sedjelmaci and Aymen Boudguiga and Inès Ben Jemaa and Sidi Mohammed Senouci},
keywords = {UAV-Edge computing, Detection, Stackelberg game, Energy consumption, Computation overhead},
abstract = {Mobile Edge Computing (MEC) is usually deployed in energy and delay constrained networks, such as internet of things networks and transportation systems to address the issues of energy consumption, computation capacity and network delay. In this work, we focus on a special case, which is Unmanned Aerial Vehicle Edge Computing (UEC) network. Addressing the security issues in UAV-Edge Computing network is mandatory due to the criticality of UEC services, such as network traffic monitoring, or search and rescue operations. However, cyber defense and protection of UEC network have not yet received sufficient research attention. Thereby, we propose and develop a cyber-defense solution based on a non-cooperative game to protect the UEC from network and offloading attacks, while taking into account nodes’ energy constraints and computation overhead. Simulation results show that, the deployment of our cyber defense system in UEC network requires low energy consumption and low computation overhead to obtain a high protection rate.}
}
@article{SIKERIDIS201869,
title = {Wireless powered Public Safety IoT: A UAV-assisted adaptive-learning approach towards energy efficiency},
journal = {Journal of Network and Computer Applications},
volume = {123},
pages = {69-79},
year = {2018},
issn = {1084-8045},
doi = {https://doi.org/10.1016/j.jnca.2018.09.003},
url = {https://www.sciencedirect.com/science/article/pii/S108480451830290X},
author = {Dimitrios Sikeridis and Eirini Eleni Tsiropoulou and Michael Devetsikiotis and Symeon Papavassiliou},
keywords = {Public Safety Networks, Internet of Things, UAV, Wireless powered communication, Minority games, Reinforcement learning, Game theory, Energy efficiency},
abstract = {Public Safety Networks (PSN) provide resilient communication paradigms under disaster recovery scenarios. In this context, the increased integration of Internet of Things (IoT) architectures can further support critical and massive information flows. In this paper, we propose a framework that combines Unmanned Aerial Vehicle (UAV)-support with wireless powered communication (WPC) techniques to further improve energy efficiency in a distributed non-orthogonal multiple access (NOMA) PSN. The IoT devices form coalitions by initially choosing their role (coalition head or coalition member) in the network independently and in a distributed fashion, following the theory of Minority Games (MG). Subsequently, the member nodes act as stochastic learning automata to associate with a coalition head using a reinforcement learning technique. Towards extending the PSN's lifetime, we utilize a harvest-transmit-store WPC mechanism, where the IoT nodes harvest energy from the mobile UAV before transmitting their information. The UAV optimal positioning in the Euclidean 3D space is determined through an optimization problem of maximizing the coalition head's total energy availability, as these nodes play a critical role within the PSN acting as emergency gateways. Finally, a non-cooperative game-theoretic approach is adopted to determine the optimal uplink transmission power of each IoT node in a distributed manner and the existence of a unique Nash equilibrium is shown. The performance evaluation of the proposed framework is achieved via modeling and simulation, and the numerical results demonstrate its energy efficiency, robustness, and scalability.}
}
@article{JASIM2020106010,
title = {A robust controller for multi rotor UAVs},
journal = {Aerospace Science and Technology},
volume = {105},
pages = {106010},
year = {2020},
issn = {1270-9638},
doi = {https://doi.org/10.1016/j.ast.2020.106010},
url = {https://www.sciencedirect.com/science/article/pii/S1270963820306921},
author = {Omar A. Jasim and Sandor M. Veres},
keywords = {Robust control, Nonlinear dynamic inversion, Multi-rotor unmanned aerial vehicles},
abstract = {Unmanned aerial vehicles (UAVs) are safety-critical systems that often need to fly near buildings and over people under adverse wind conditions and hence require high manoeuvrability, accuracy, fast response abilities to ensure safety. Under extreme conditions, the dynamics of these systems are strongly nonlinear and are exposed to disturbances, which need a robust controller to keep the UAV and its environment safe. In this paper a novel robust nonlinear multi-rotor controller is introduced based on essential modifications of standard dynamic inversion control, which makes it insensitive to payload changes and also to large wind gusts. First a robust attitude controller is established, followed by lateral and vertical position control in a customary outer loop. The controllers take into account thrust limitations of the aircraft and theoretical proof is provided for robust performance. The control scheme is illustrated in simulation with a realistic nonlinear dynamical model of an aircraft that includes rotor dynamics and their speed limitations to show robustness. Lyapunov stability methods are used to prove the stability of the robust control system.}
}
@article{GUPTA2020406,
title = {Machine Learning Models for Secure Data Analytics: A taxonomy and threat model},
journal = {Computer Communications},
volume = {153},
pages = {406-440},
year = {2020},
issn = {0140-3664},
doi = {https://doi.org/10.1016/j.comcom.2020.02.008},
url = {https://www.sciencedirect.com/science/article/pii/S0140366419318493},
author = {Rajesh Gupta and Sudeep Tanwar and Sudhanshu Tyagi and Neeraj Kumar},
keywords = {Big data, Secure Data Analytics, Data reduction, Machine learning models, Threat model, Data security and privacy},
abstract = {In recent years, rapid technological advancements in smart devices and their usage in a wide range of applications exponentially increases the data generated from these devices. So, the traditional data analytics techniques may not be able to handle this extreme volume of data known as Big Data (BD) generated by different devices. However, this exponential increase of data opens the doors for the different type of attackers to launch various attacks by exploiting various vulnerabilities (SQL injection, OS fingerprinting, malicious code execution, etc.) during data analytics. Motivated from the aforementioned discussion, in this paper, we explored Machine Learning (ML) and Deep Learning (DL)-based models and techniques which are capable off to identify and mitigate both the known as well as unknown attacks. ML and DL-based techniques have the capabilities to learn from the traffic pattern using training and testing datasets in the extensive network domains to make intelligent decisions concerning attack identification and mitigation. We also proposed a DL and ML-based Secure Data Analytics (SDA) architecture to classify normal or attack input data. A detailed taxonomy of SDA is abstracted into a threat model. This threat model addresses various research challenges in SDA using multiple parameters such as-efficiency, latency, accuracy, reliability, and attacks launched by the attackers. Finally, a comparison of existing SDA proposals with respect to various parameters is presented, which allows the end users to select one of the SDA proposals in comparison to its merits over the others.}
}
@article{LHAZMIR2020102102,
title = {A decision-making analysis in UAV-enabled wireless power transfer for IoT networks},
journal = {Simulation Modelling Practice and Theory},
volume = {103},
pages = {102102},
year = {2020},
issn = {1569-190X},
doi = {https://doi.org/10.1016/j.simpat.2020.102102},
url = {https://www.sciencedirect.com/science/article/pii/S1569190X2030040X},
author = {Safae Lhazmir and Omar Ait Oualhaj and Abdellatif Kobbane and Lynda Mokdad},
keywords = {Wireless energy transfer, Internet of Things, Unmanned aerial vehicle, GMDP},
abstract = {We consider an IoT network with energy-harvesting capabilities. To extend the network lifetime, we propose a novel unmanned aerial vehicle (UAV)- enabled wireless power transfer (WPT) system, where UAVs move among IoT devices and act as data aggregators and wireless power providers. This paper addresses the decision-making problem since the limited buffer and energy resources constrain all nodes. Each IoT node must decide on whether to request a data transmission, to ask for a wireless energy transfer or to abstain and not take any action. When a UAV receives a request from an IoT device, either for data reception or wireless energy transmission, it has to accept or decline. In this paper, we aim to find a proper packet delivery and energy transfer policy according to the system state that maximizes the data transmission efficiency of the system. We first formulate the problem as a Markov Decision Process (MDP) to tackle the successive decision issues, to optimize a utility for each node upon a casual environment. As the MDP formalism achieves its limits when the interactions between different nodes are considered, we formulate the problem as a Graph-based MDP (GMDP). The transition functions and rewards are then decomposed into local functions, and a graph illustrates the dependency’ relations among the nodes. To obtain the optimal policy despite the system’s variations, Mean-Field Approximation (MFA) and Approximate linear-programming (ALP) algorithms were proposed to solve the GMDP problem.}
}
@article{GASPAROVIC2020105385,
title = {An automatic method for weed mapping in oat fields based on UAV imagery},
journal = {Computers and Electronics in Agriculture},
volume = {173},
pages = {105385},
year = {2020},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2020.105385},
url = {https://www.sciencedirect.com/science/article/pii/S016816991930359X},
author = {Mateo Gašparović and Mladen Zrinjski and Đuro Barković and Dorijan Radočaj},
keywords = {UAV, Imagery classification, Weed mapping, Oats, Precision agriculture},
abstract = {The accurate detection and treatment of weeds in agricultural fields is a necessary procedure for managing crop yield and avoiding herbicide pollution. With the emergence of unmanned aerial vehicles (UAV), the ability to acquire spatial data at the desired spatial and temporal resolution became available, and the resulting input data met high standards for weed management. In this paper, we tested four independent classification algorithms for the creation of weed maps, combining automatic and manual methods, as well as object-based and pixel-based classification approaches, which were used separately on two subsets. Input UAV data were collected using a low-cost RGB camera due to its affordability compared to multispectral cameras. Classification algorithms were based on the random forest machine learning algorithm for weed and bare soil extraction, following an unsupervised classification with the K-means algorithm for further estimation of weeds and bare soil presence in non-weed and non-soil areas. Of the four classification algorithms tested, the automatic object-based classification method achieved the highest classification accuracy, resulting in an overall accuracy of 89.0% for subset A and 87.1% for subset B. Automatic classification methods were robustly developed, using at least 0.25% of the scene size as the training data set in all circumstances anticipated for the random forest classification algorithm to operate. The use of the algorithm resulted in weed maps consisting of zoned classes and covering areas with similar biological properties, making them ready for use as inputs in weed treatments that use agricultural machinery.}
}
@article{LI2021116278,
title = {Transmission line detection in aerial images: An instance segmentation approach based on multitask neural networks},
journal = {Signal Processing: Image Communication},
volume = {96},
pages = {116278},
year = {2021},
issn = {0923-5965},
doi = {https://doi.org/10.1016/j.image.2021.116278},
url = {https://www.sciencedirect.com/science/article/pii/S092359652100117X},
author = {Bo Li and Cheng Chen and Shiwen Dong and Junfeng Qiao},
keywords = {Transmission line detection, Deep neural networks, Convolutional neural networks},
abstract = {Camera-based transmission line detection (TLD) is a fundamental and crucial task for automatically patrolling powerlines by aircraft. Motivated by instance segmentation, a TLD algorithm is proposed in this paper with a novel deep neural network, i.e., CableNet. The network structure is designed based on fully convolutional networks (FCNs) with two major improvements, considering the specific appearance characteristics of transmission lines. First, overlaying dilated convolutional layers and spatial convolutional layers are configured to better represent continuous long and thin cable shapes. Second, two branches of outputs are arranged to generate multidimensional feature maps for instance segmentation. Thus, cable pixels can be detected and assigned cable IDs simultaneously. Multiple experiments are conducted on aerial images, and the results show that the proposed algorithm obtains reliable detection performance and is superior to traditional TLD methods. Meanwhile, segmented pixels can be accurately identified as cable instances, contributing to line fitting for further applications.}
}
@article{DING2020102069,
title = {A deep reinforcement learning for user association and power control in heterogeneous networks},
journal = {Ad Hoc Networks},
volume = {102},
pages = {102069},
year = {2020},
issn = {1570-8705},
doi = {https://doi.org/10.1016/j.adhoc.2019.102069},
url = {https://www.sciencedirect.com/science/article/pii/S1570870519310546},
author = {Hui Ding and Feng Zhao and Jie Tian and Dongyang Li and Haixia Zhang},
keywords = {Heterogeneous networks, User association, Power control, Reinforcement learning, Deep Q-learning network},
abstract = {Heterogeneous network (HetNet) is a promising solution to satisfy the unprecedented demand for higher data rate in the next generation mobile networks. Different from the traditional single-layer cellular networks, how to provide the best service to the user equipments (UEs) under the limited resource is an urgent problem to solve. In order to efficiently address the above challenge and strive towards high network energy efficiency, the joint optimization problem of user association and power control in orthogonal frequency division multiple access (OFDMA) based uplink HetNets is studied. Considering the non-convex and non-linear characteristics of the problem, a multi-agent deep Q-learning Network (DQN) method is studied to solve the problem. Different from the traditional methods, such as game theory, fractional programming and convex optimization, which need more and accurate network information in practice, the multi-agent DQN method requires less communication information of the environment. Moreover, for the communication environment dynamics, the maximum long-term overall network utility with a new reward function while ensuring the UE’s quality of service (QoS) requirements is achieved by using the multi-agent DQN method. Then, according to the application scenario, the action space, state space and reward function of the multi-agent DQN based framework are redefined and formulated. Simulation results demonstrate that the multi-agent DQN method has the best performance on convergence and energy efficiency compared with the traditional reinforcement learning (Q-learning).}
}
@article{VARELA201454,
title = {Autonomous UAV based search operations using Constrained Sampling Evolutionary Algorithms},
journal = {Neurocomputing},
volume = {132},
pages = {54-67},
year = {2014},
note = {Innovations in Nature Inspired Optimization and Learning Methods Machines learning for Non-Linear Processing},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2013.03.060},
url = {https://www.sciencedirect.com/science/article/pii/S0925231213010904},
author = {Gervasio Varela and Pilar Caamaño and Félix Orjales and Álvaro Deibe and Fernando López-Peña and Richard J. Duro},
keywords = {Evolutionary algorithms, Swarm intelligence, UAV, Team coordination, Robot coordination, Unmanned Aerial Vehicles},
abstract = {This paper introduces and studies the application of Constrained Sampling Evolutionary Algorithms in the framework of an UAV based search and rescue scenario. These algorithms have been developed as a way to harness the power of Evolutionary Algorithms (EA) when operating in complex, noisy, multimodal optimization problems and transfer the advantages of their approach to real time real world problems that can be transformed into search and optimization challenges. These types of problems are denoted as Constrained Sampling problems and are characterized by the fact that the physical limitations of reality do not allow for an instantaneous determination of the fitness of the points present in the population that must be evolved. A general approach to address these problems is presented and a particular implementation using Differential Evolution as an example of CS-EA is created and evaluated using teams of UAVs in search and rescue missions. The results are compared to those of a Swarm Intelligence based strategy in the same type of problem as this approach has been widely used within the UAV path planning field in different variants by many authors.}
}
@article{BOURGOIN2020106386,
title = {UAV-based canopy textures assess changes in forest structure from long-term degradation},
journal = {Ecological Indicators},
volume = {115},
pages = {106386},
year = {2020},
issn = {1470-160X},
doi = {https://doi.org/10.1016/j.ecolind.2020.106386},
url = {https://www.sciencedirect.com/science/article/pii/S1470160X2030323X},
author = {Clément Bourgoin and Julie Betbeder and Pierre Couteron and Lilian Blanc and Hélène Dessard and Johan Oszwald and Renan {Le Roux} and Guillaume Cornu and Louis Reymondin and Lucas Mazzei and Plinio Sist and Peter Läderach and Valéry Gond},
keywords = {Canopy structure, Forest degradation, Remote sensing, Texture, Tropical forest, Unmanned aerial vehicle},
abstract = {Degraded tropical forests dominate agricultural frontiers and their management is becoming an urgent priority. This calls for a better understanding of the different forest cover states and cost-efficient techniques to quantify the impact of degradation on forest structure. Canopy texture analyses based on Very High Spatial Resolution (VHSR) optical imagery provide proxies to assess forest structures but the mechanisms linking them with degradation have rarely been investigated. To address this gap, we used a lightweight Unmanned Aerial Vehicle (UAV) to map 739 ha of degraded forests and acquire both canopy VHSR images and height model. Thirty-three years of degradation history from Landsat archives allowed us to sample 40 plots in undisturbed, logged, over-logged and burned and regrowth forests in tropical forested landscapes (Paragominas, Pará, Brazil). Fourier (FOTO) and lacunarity textures were used to assess forest canopy structure and to build a typology linking degradation history and current states. Texture metrics capture canopy grain, heterogeneity and openness gradients and correlate with forest structure variability (R2 = 0.58). Similar structures share common degradation history and can be discriminated on the basis of canopy texture alone (accuracy = 55%). Over-logging causes a lowering in forest height, which brings homogeneous textures and of finer grain. We identified the major changes in structures due to fire following logging which changes heterogeneous and intermediate grain into coarse textures. Our findings highlight the potential of canopy texture metrics to characterize degraded forests and thus be used as indicators for forest management and degradation mitigation. Inexpensive and agile UAV open promising perspectives at the interface between field inventory and satellite characterization of forest structure using texture metrics.}
}
@article{MILYAKOV2021628,
title = {Quadcopter active phased antenna array},
journal = {Procedia Computer Science},
volume = {186},
pages = {628-635},
year = {2021},
note = {14th International Symposium "Intelligent Systems},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2021.04.185},
url = {https://www.sciencedirect.com/science/article/pii/S187705092101022X},
author = {D.A. Milyakov and V.S. Verba and V.I. Merkulov and A.S. Plyashechnik},
keywords = {Active phased antenna aray, mobile radar, quadcopter, unmanned aerial vehicle, group control},
abstract = {Group use of unmanned aerial vehicles (UAVs) for various purposes allows obtaining many of advantages in various tasks solvation. New advantages of UAVs group use are due the difficulty of separate observation of the group members and, accordingly, the difficulties of tracking and target distribution; the inability to serve the entire large group with the number of participants exceeding the capacity of the information control system of the opposing side; the increase in the behavioral complexity of the UAV in solving various problems through the use of artificial intelligence; random change of the spatial position of individual UAVs within the group, preventing their detection and selection of virtually all types of information systems. The noted advantages of the UAVs groups are especially pronounced in the implementation of such a fundamentally new method for creating active antennas based on the use of a group of UAVs carrying antenna elements and therefore forming and use of temporary active phased antenna arrays (APAA) of large sizes based on multicopter for the implementation of long-range radar systems. In this regard, the purpose of the report is to present a variant of the algorithm for the formation of such an APAA. On the example of solving the task of maintaining an air object, the features of the operation of a radar with an APAA based on a group of UAVs are illustrated.}
}
@article{RADMANESH2020105965,
title = {Towards a PDE-based large-scale decentralized solution for path planning of UAVs in shared airspace},
journal = {Aerospace Science and Technology},
volume = {105},
pages = {105965},
year = {2020},
issn = {1270-9638},
doi = {https://doi.org/10.1016/j.ast.2020.105965},
url = {https://www.sciencedirect.com/science/article/pii/S1270963820306477},
author = {Reza Radmanesh and Manish Kumar and Donald French and David Casbeer},
keywords = {Decentralized control, Trajectory planning, Partial Differential Equation (PDE) method, Unmanned Air Vehicles (UAVs), Large scale optimization},
abstract = {Recently, there has been a tremendous increase of interest in utilizing Unmanned Aerial Vehicles (UAVs) for a number of civilian applications. With this increased interest, it is imperative that these UAVs are able to operate in shared airspace for enhanced efficiency. Multi-UAV systems are inherently safety-critical systems, which means that safety guarantees must be made to ensure no undesirable configurations, such as collisions, occur. This paper proposes a decentralized method based on a Partial Differential Equation (PDE) to generate collision-free 3D trajectories for multiple UAVs operating in a shared airspace. This method exploits the dynamical properties of multi-phase fluids flowing through a porous medium by modeling the porosity values as a function of the risk of collision. To highlight the feasibility for on-board implementation, we propose propose a machine learning technique for obtaining computationally efficient solutions of the PDE describing flow movements in porous medium. This method has been compared via a simulation study to two other path planning strategies, centralized and sequential planning, and the advantages of this method are presented. Furthermore, results from an experiment using three UAVs have been presented to demonstrate the applicability of the proposed method to real-world implementation.}
}
@article{ANTONIOTOLEDO2018549,
title = {Real-Time Integral Backstepping with Sliding Mode Control for a Quadrotor UAV},
journal = {IFAC-PapersOnLine},
volume = {51},
number = {13},
pages = {549-554},
year = {2018},
note = {2nd IFAC Conference on Modelling, Identification and Control of Nonlinear Systems MICNON 2018},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2018.07.337},
url = {https://www.sciencedirect.com/science/article/pii/S2405896318310929},
author = {M. Elena Antonio-Toledo and Edgar N. Sanchez and Alma Y. Alanis and J.A. Flórez and Marco A. Perez-Cisneros},
keywords = {UAVs, Quadrotor, integral backstepping, trajectory tracking, experimental test},
abstract = {This paper presents a nonlinear control of a quadrotor unmanned aerial vehicle(UAV) for trajectory tracking. The dynamical model is obtained by the Euler- Lagrange methodology. In this paper, the proposed control strategy is based on the integral backstepping technique with sliding mode control (SMC) for altitude and lateral motion. In addition, an inner loop control is used to stabilize the vehicle orientation. The implementation is applied to the Qball-X4 prototype of Quanser Inc. which has OptiTrackTM cameras to provide the vehicle lateral position and a sonar sensor gives the altitude measurement. The experimental test results illustrate the effectiveness on the quadrotor of the proposed control scheme.}
}
@article{ALLRED2020106036,
title = {Overall results and key findings on the use of UAV visible-color, multispectral, and thermal infrared imagery to map agricultural drainage pipes},
journal = {Agricultural Water Management},
volume = {232},
pages = {106036},
year = {2020},
issn = {0378-3774},
doi = {https://doi.org/10.1016/j.agwat.2020.106036},
url = {https://www.sciencedirect.com/science/article/pii/S0378377419317597},
author = {Barry Allred and Luis Martinez and Melake K. Fessehazion and Greg Rouse and Tanja N. Williamson and DeBonne Wishart and Triven Koganti and Robert Freeland and Neal Eash and Adam Batschelet and Robert Featheringill},
keywords = {Agricultural drainage pipes, Unmanned aerial vehicles (UAVs), Visible-color (VIS-C) imagery, Multispectral (MS) imagery, Thermal infrared (TIR) imagery},
abstract = {Effective and efficient methods are needed to map agricultural subsurface drainage systems. Visible-color (VIS-C), multispectral (MS), and thermal infrared (TIR) imagery obtained by unmanned aerial vehicles (UAVs) may provide a means for determining drainage pipe locations. Aerial surveys using a UAV with VIS-C, MS, and TIR cameras were conducted at 29 agricultural field sites in the Midwest U.S.A. to evaluate the potential of this technology for mapping buried drainage pipes. Overall results show VIS-C imagery detected at least some drain lines at 48 % of the sites (14 out of 29), MS imagery detected drain lines at 59 % of the sites (17 out of 29), and TIR imagery detected drain lines at 69 % of the sites (20 out of 29). Three key findings, listed as follows and emphasized in this article by site examples, were extracted from the overall results. (1) Although TIR generally worked best, there were sites where either VIS-C or MS proved more effective than TIR for mapping subsurface drainage systems. Consequently, to ensure the greatest chance for successfully determining drainage pipe patterns in a field, UAV surveys need to be carried out with all three types of cameras, VIS-C, MS, and TIR. (2) Timing of UAV surveys relative to recent rainfall can sometimes have an important impact on drainage pipe detection results. (3) Linear features representing drain lines and farm field operations can be confused with one another and are often both depicted on site aerial imagery. Knowledge of subsurface drainage system installation and farm field operations can be employed to distinguish linear features representing drain lines from those representing farm field operations. The overall results and extracted key findings from this study clearly indicate that VIS-C, MS, and TIR imagery obtained with UAVs have significant potential for use in mapping agricultural drainage pipe systems.}
}
@article{FU20211531,
title = {Bidirectional parallel multi-branch convolution feature pyramid network for target detection in aerial images of swarm UAVs},
journal = {Defence Technology},
volume = {17},
number = {4},
pages = {1531-1541},
year = {2021},
issn = {2214-9147},
doi = {https://doi.org/10.1016/j.dt.2020.09.018},
url = {https://www.sciencedirect.com/science/article/pii/S2214914720304542},
author = {Lei Fu and Wen-bin Gu and Wei Li and Liang Chen and Yong-bao Ai and Hua-lei Wang},
keywords = {Aerial images, Object detection, Feature pyramid networks, Multi-scale feature fusion, Swarm UAVs},
abstract = {In this paper, based on a bidirectional parallel multi-branch feature pyramid network (BPMFPN), a novel one-stage object detector called BPMFPN Det is proposed for real-time detection of ground multi-scale targets by swarm unmanned aerial vehicles (UAVs). First, the bidirectional parallel multi-branch convolution modules are used to construct the feature pyramid to enhance the feature expression abilities of different scale feature layers. Next, the feature pyramid is integrated into the single-stage object detection framework to ensure real-time performance. In order to validate the effectiveness of the proposed algorithm, experiments are conducted on four datasets. For the PASCAL VOC dataset, the proposed algorithm achieves the mean average precision (mAP) of 85.4 on the VOC 2007 test set. With regard to the detection in optical remote sensing (DIOR) dataset, the proposed algorithm achieves 73.9 mAP. For vehicle detection in aerial imagery (VEDAI) dataset, the detection accuracy of small land vehicle (slv) targets reaches 97.4 mAP. For unmanned aerial vehicle detection and tracking (UAVDT) dataset, the proposed BPMFPN Det achieves the mAP of 48.75. Compared with the previous state-of-the-art methods, the results obtained by the proposed algorithm are more competitive. The experimental results demonstrate that the proposed algorithm can effectively solve the problem of real-time detection of ground multi-scale targets in aerial images of swarm UAVs.}
}
@article{WOO2019155,
title = {Deep reinforcement learning-based controller for path following of an unmanned surface vehicle},
journal = {Ocean Engineering},
volume = {183},
pages = {155-166},
year = {2019},
issn = {0029-8018},
doi = {https://doi.org/10.1016/j.oceaneng.2019.04.099},
url = {https://www.sciencedirect.com/science/article/pii/S0029801819302203},
author = {Joohyun Woo and Chanwoo Yu and Nakwan Kim},
keywords = {Deep reinforcement learning, Path following, Unmanned surface vehicle, Learning-based control, Artificial intelligence},
abstract = {In this paper, a deep reinforcement learning (DRL)-based controller for path following of an unmanned surface vehicle (USV) is proposed. The proposed controller can self-develop a vehicle’s path following capability by interacting with the nearby environment. A deep deterministic policy gradient (DDPG) algorithm, which is an actor-critic-based reinforcement learning algorithm, was adapted to capture the USV’s experience during the path-following trials. A Markov decision process model, which includes the state, action, and reward formulation, specially designed for the USV path-following problem is suggested. The control policy was trained with repeated trials of path-following simulation. The proposed method’s path-following and self-learning capabilities were validated through USV simulation and a free-running test of the full-scale USV.}
}
@article{MAJCHROWSKA2022274,
title = {Deep learning-based waste detection in natural and urban environments},
journal = {Waste Management},
volume = {138},
pages = {274-284},
year = {2022},
issn = {0956-053X},
doi = {https://doi.org/10.1016/j.wasman.2021.12.001},
url = {https://www.sciencedirect.com/science/article/pii/S0956053X21006474},
author = {Sylwia Majchrowska and Agnieszka Mikołajczyk and Maria Ferlin and Zuzanna Klawikowska and Marta A. Plantykow and Arkadiusz Kwasigroch and Karol Majek},
keywords = {Object detection, Semi-supervised learning, Waste classification benchmarks, Waste detection benchmarks, Waste localization, Waste recognition},
abstract = {Waste pollution is one of the most significant environmental issues in the modern world. The importance of recycling is well known, both for economic and ecological reasons, and the industry demands high efficiency. Current studies towards automatic waste detection are hardly comparable due to the lack of benchmarks and widely accepted standards regarding the used metrics and data. Those problems are addressed in this article by providing a critical analysis of over ten existing waste datasets and a brief but constructive review of the existing Deep Learning-based waste detection approaches. This article collects and summarizes previous studies and provides the results of authors’ experiments on the presented datasets, all intended to create a first replicable baseline for litter detection. Moreover, new benchmark datasets detect-waste and classify-waste are proposed that are merged collections from the above-mentioned open-source datasets with unified annotations covering all possible waste categories: bio, glass, metal and plastic, non-recyclable, other, paper, and unknown. Finally, a two-stage detector for litter localization and classification is presented. EfficientDet-D2 is used to localize litter, and EfficientNet-B2 to classify the detected waste into seven categories. The classifier is trained in a semi-supervised fashion making the use of unlabeled images. The proposed approach achieves up to 70% of average precision in waste detection and around 75% of classification accuracy on the test dataset. The code and annotations used in the studies are publicly available online11https://github.com/wimlds-trojmiasto/detect-waste..}
}
@article{WANG2020324,
title = {Agent-enabled task offloading in UAV-aided mobile edge computing},
journal = {Computer Communications},
volume = {149},
pages = {324-331},
year = {2020},
issn = {0140-3664},
doi = {https://doi.org/10.1016/j.comcom.2019.10.021},
url = {https://www.sciencedirect.com/science/article/pii/S0140366419306292},
author = {Rui Wang and Yong Cao and Adeeb Noor and Thamer A Alamoudi and Redhwan Nour},
keywords = {Agent, Task offloading, MEC, UMEC},
abstract = {With the appearance of various mobile applications, such as automatic driving and augmented reality, it is difficult for the power and computing ability of mobile terminals to satisfy user demands. Therefore, an increasing number of terminal devices are requesting computing resources on the edge cloud. Because an unmanned aerial vehicle (UAV) is quite flexible and closer to the user side, an UAV can be adopted to assist mobile edge computing (MEC) while executing task offloading, which may reduce the pressure on edge clouds. However, it is unreasonable for users to make blind requests for resources due to the information asymmetry between a user and a service provider, and thus the quality of experience of user may be reduced. In this paper, an agent is introduced into the offloading of computing tasks, and a novel framework of agent-enabled task offloading in UAV-aided MEC(UMEC) is put forth to help the user, UAV, and edge cloud execute the offloading of computing tasks. With the intelligence and perceptibility of an agent, a system model is formulated in this paper to guide the agent in obtaining the optimum computing offloading plan, with minimum task execution delay and energy consumption. Simulation results showed that the introduction of an agent may significantly reduce delay and energy consumption, and the effectiveness of agent has been illustrated.}
}
@article{ZHAO20202835,
title = {Adaptive level of autonomy for human-UAVs collaborative surveillance using situated fuzzy cognitive maps},
journal = {Chinese Journal of Aeronautics},
volume = {33},
number = {11},
pages = {2835-2850},
year = {2020},
note = {SI: Emerging Technologies of Unmanned Aerial Vehicles},
issn = {1000-9361},
doi = {https://doi.org/10.1016/j.cja.2020.03.031},
url = {https://www.sciencedirect.com/science/article/pii/S1000936120302181},
author = {Zhe ZHAO and Yifeng NIU and Lincheng SHEN},
keywords = {Adaptive LOA, Cognitive Model, Human-UAVs collaboration, Situated Fuzzy Cognitive Map (SiFCM), Time series learning},
abstract = {Collaborating with a squad of Unmanned Aerial Vehicles (UAVs) is challenging for a human operator in a cooperative surveillance task. In this paper, we propose a cognitive model that can dynamically adjust the Levels of Autonomy (LOA) of the human-UAVs team according to the changes in task complexity and human cognitive states. Specifically, we use the Situated Fuzzy Cognitive Map (SiFCM) to model the relations among tasks, situations, human states and LOA. A recurrent structure has been used to learn the strategy of adjusting the LOA, while the collaboration task is separated into a perception routine and a control routine. Experiment results have shown that the workload of the human operator is well balanced with the task efficiency.}
}
@article{SINGH2021105407,
title = {Highway 4.0: Digitalization of highways for vulnerable road safety development with intelligent IoT sensors and machine learning},
journal = {Safety Science},
volume = {143},
pages = {105407},
year = {2021},
issn = {0925-7535},
doi = {https://doi.org/10.1016/j.ssci.2021.105407},
url = {https://www.sciencedirect.com/science/article/pii/S0925753521002514},
author = {Rajesh Singh and Rohit Sharma and Shaik {Vaseem Akram} and Anita Gehlot and Dharam Buddhi and Praveen Kumar Malik and Rajeev Arya},
keywords = {Highway, DL, Vulnerable Road Safety, Smart city, IoT, Renewable energy, And vision node},
abstract = {According to United Nations (UN) 2030 agenda, the transportation system needs to be enhanced for the establishment of access to safe, affordable, accessible, and sustainable transport systems along with enhanced road safety. The highway road transport system is one of the transport systems that enables to transits goods and humans from one location to another location. The agenda of UN 2030 for the transport system will be accomplished with the assistance of digital technologies like the internet of things (IoT) and artificial intelligence (AI). The implementation of these digital technologies on highways empowers to provide reliable, smarter, intelligent, and renewable energy sources experience to the users travelling along the highways. This study discusses the significance of the digitalization of highways that supporting and realizing a sustainable environment on the highways. To discuss the significance of digitalization, the study has categorized digitalization into five subcomponents namely smart highway lighting system, smart traffic and emergency management system, renewable energy sources on highways, smart display and AI in highways. An architecture-for smart highway lighting, smart traffic, and emergency management are proposed and discussed in the study. The significance of implementing smart display boards and renewable sources with real-time applications is also addressed in this study. Moreover, the integration of AI in highways is addressed with the perspective of enhancing road safety. The integration of deep learning (DL) in the edge-based vision node for predicting the patterns of traffic flow, highway road safety, and maintenance of quality roads have been addressed in the discussion section. Embedding the deep learning techniques in the vison node at the traffic junction and the highway lighting controller is able to deliver an intelligent system that provides sustained experience and management of the highways. Smart reflectors, adoption of renewable energy, developing vehicle-to-vehicle communication in vehicles, and smart lamppost are the few recommendations for the implementation of digitalizing highways.}
}
@article{GUO2021107127,
title = {Learning-based collision-free coordination for a team of uncertain quadrotor UAVs},
journal = {Aerospace Science and Technology},
volume = {119},
pages = {107127},
year = {2021},
issn = {1270-9638},
doi = {https://doi.org/10.1016/j.ast.2021.107127},
url = {https://www.sciencedirect.com/science/article/pii/S1270963821006374},
author = {Yaohua Guo and Gang Chen and Tao Zhao},
keywords = {Learning-based coordination, Uncertain UAVs, Collision avoidance},
abstract = {This paper investigates the safe coordination problem for a team of quadrotor unmanned air vehicles (UAVs) in the presence of model uncertainties and polygonal obstacles. Firstly, collision avoidance potential functions (PFs) related with both positions and velocities are utilized to construct the basic and bounded controller for achieving collision-free coordination. Then, in order to enhance the tracking performance under model uncertainties, an complementary control is developed via approximate dynamic programming (ADP), where the unknown dynamics of UAVs are accurately estimated in finite-time. Through using stored data in learning-based ADP, the approximated error of the weights in critic neural network converges with finitely excited signal. The sufficient conditions of the closed-loop system stability and collision avoidance are derived. The performance of the learning-based coordination methodology is demonstrated via simulation results.}
}
@article{ALLISON2020105699,
title = {Wind estimation using quadcopter motion: A machine learning approach},
journal = {Aerospace Science and Technology},
volume = {98},
pages = {105699},
year = {2020},
issn = {1270-9638},
doi = {https://doi.org/10.1016/j.ast.2020.105699},
url = {https://www.sciencedirect.com/science/article/pii/S1270963819324034},
author = {Sam Allison and He Bai and Balaji Jayaraman},
keywords = {Wind estimation, UAS, Machine learning},
abstract = {In this article, we study the well known problem of wind estimation in atmospheric turbulence using small unmanned aerial systems (sUAS). We present a machine learning approach to wind velocity estimation based on quadcopter state measurements without a wind sensor. We accomplish this by training a long short-term memory (LSTM) neural network (NN) on roll and pitch angles and quadcopter position inputs with forcing wind velocities as the targets. The datasets are generated using a simulated quadcopter in turbulent wind fields. The trained neural network is deployed to estimate the turbulent winds as generated by the Dryden gust model as well as a realistic large eddy simulation (LES) of a near-neutral atmospheric boundary layer (ABL) over flat terrain. The resulting NN predictions are compared to a wind triangle approach that uses tilt angle as an approximation of airspeed. Results from this study indicate that the LSTM-NN based approach predicts lower errors in both the mean and variance of the local wind field as compared to the wind triangle approach. The work reported in this article demonstrates the potential of machine learning for sensor-less wind estimation and has strong implications to large-scale low-altitude atmospheric sensing using sUAS for environmental and autonomous navigation applications.}
}
@article{LIU2021194,
title = {Heterogeneous formation control of multiple rotorcrafts with unknown dynamics by reinforcement learning},
journal = {Information Sciences},
volume = {558},
pages = {194-207},
year = {2021},
issn = {0020-0255},
doi = {https://doi.org/10.1016/j.ins.2021.01.011},
url = {https://www.sciencedirect.com/science/article/pii/S002002552100013X},
author = {Hao Liu and Fachun Peng and Hamidreza Modares and Bahare Kiumarsi},
keywords = {Formation control, Multi-agent systems, Heterogeneous systems, Reinforcement learning, Rotorcrafts},
abstract = {In this paper, a distributed model-free solution based on reinforcement learning is proposed for the leader–follower formation control problem of heterogeneous multi-agent systems. The multi-agent system consists of multiple rotorcrafts involving a virtual leader and multiple followers, where the dynamics of leaders and followers is unknown. The formation control problem is firstly formulated as an optimal output regulation problem. A discounted performance function is then introduced to guarantee that the tracking error asymptotically converges to zero, and an online off-policy reinforcement learning algorithm is proposed to solve the optimal output problem online using the data generated along the trajectories of the agents. A simulation example is provided to validate the effectiveness of the proposed control method.}
}
@article{JAMALI2021373,
title = {Improving land use land cover mapping of a neural network with three optimizers of multi-verse optimizer, genetic algorithm, and derivative-free function},
journal = {The Egyptian Journal of Remote Sensing and Space Science},
volume = {24},
number = {3, Part 1},
pages = {373-390},
year = {2021},
issn = {1110-9823},
doi = {https://doi.org/10.1016/j.ejrs.2020.07.001},
url = {https://www.sciencedirect.com/science/article/pii/S1110982320300697},
author = {Ali Jamali},
keywords = {LULC, Machine learning, Image classification, Multi-layer perceptron, MVO, GA},
abstract = {For land management and planning, information on the Land Use Land Cover (LULC) is vital. In this research, three optimizers of the Multi-Verse Optimizer (MVO), Genetic Algorithm (GA), and Derivative-free Function (DF) are developed in MATLAB programming language to improve the accuracy of remote sensing image classification using a Small-sized Neural Network (SNN). The results are compared to a Medium-sized Neural Network (MNN) developed in MATLAB programming language. Based on the test data, the MNN has the best performance with the Overall Accuracy (OA) of 92.64% for the object-based Landsat-8 imagery with a spatial resolution of 15 m. Based on the test data, the Derivative-free Function Multi-layer Perceptron (DFMLP) for the pixel-based Landsat-8 imagery with a spatial resolution of 15 m has the best performance with the OA of 89.31%. The Genetic Algorithm Multi-layer Perceptron (GAMLP) for the pixel-based Landsat-8 imagery with a spatial resolution of 30 m has the least performance with a value of 74.47% for the OA. The most significant improvement was for the pixel-based Landsat-8 imagery with a spatial resolution of 15 m where the DF and GA optimizers have improved the results of the SNN classifier with 7.37% and ~8% for the OA index, respectively.}
}
@article{RADOGLOUGRAMMATIKIS2020107148,
title = {A compilation of UAV applications for precision agriculture},
journal = {Computer Networks},
volume = {172},
pages = {107148},
year = {2020},
issn = {1389-1286},
doi = {https://doi.org/10.1016/j.comnet.2020.107148},
url = {https://www.sciencedirect.com/science/article/pii/S138912862030116X},
author = {Panagiotis Radoglou-Grammatikis and Panagiotis Sarigiannidis and Thomas Lagkas and Ioannis Moscholios},
keywords = {Precision agriculture (PA), Remote sensing (RS), Unmanned aerial vehicle (UAV)},
abstract = {Climate change has introduced significant challenges that can affect multiple sectors, including the agricultural one. In particular, according to the Food and Agriculture Organization of the United Nations (FAO) and the International Telecommunication Union (ITU), the world population has to find new solutions to increase the food production by 70% by 2050. The answer to this crucial challenge is the suitable adoption and utilisation of the Information and Communications Technology (ICT) services, offering capabilities that can increase the productivity of the agrochemical products, such as pesticides and fertilisers and at the same time, they should minimise the functional cost. More detailed, the advent of the Internet of Things (IoT) and specifically, the rapid evolution of the Unmanned Aerial Vehicles (UAVs) and Wireless Sensor Networks (WSNs) can lead to valuable and at the same time economic Precision Agriculture (PA) applications, such as aerial crop monitoring and smart spraying tasks. In this paper, we provide a survey regarding the potential use of UAVs in PA, focusing on 20 relevant applications. More specifically, first, we provide a detailed overview of PA, by describing its various aspects and technologies, such as soil mapping and production mapping as well as the role of the Global Positioning Systems (GPS) and Geographical Information Systems (GIS). Then, we discriminate and analyse the various types of UAVs based on their technical characteristics and payload. Finally, we investigate in detail 20 UAV applications that are devoted to either aerial crop monitoring processes or spraying tasks. For each application, we examine the methodology adopted, the proposed UAV architecture, the UAV type, as well as the UAV technical characteristics and payload.}
}
@article{LIU2021102531,
title = {Study on transfer learning ability for classifying marsh vegetation with multi-sensor images using DeepLabV3+ and HRNet deep learning algorithms},
journal = {International Journal of Applied Earth Observation and Geoinformation},
volume = {103},
pages = {102531},
year = {2021},
issn = {0303-2434},
doi = {https://doi.org/10.1016/j.jag.2021.102531},
url = {https://www.sciencedirect.com/science/article/pii/S0303243421002385},
author = {Man Liu and Bolin Fu and Donglin Fan and Pingping Zuo and Shuyu Xie and Hongchang He and Lilong Liu and Liangke Huang and Ertao Gao and Min Zhao},
keywords = {Marsh vegetation classification, Satellite images, Multi-scale segmentation, Transfer learning, DeepLabV3+ algorithm, HRNet algorithm},
abstract = {The verification of the transfer learning ability of the convolutional neural network in the classification of natural vegetation is relatively lacking. In this paper, 16 combination scenarios of multispectral images in marsh vegetation were constructed. The influence of the combination with different spatial resolution gradients and spectral dimensions on the classification accuracy of marsh vegetation was systematically studied. Multi-sensor images were used to evaluate the transfer learning ability of DeepLabV3+ and HRNet algorithms in marsh vegetation, and analyse the transfer learning effect of two algorithms in different spatial resolution and spectral ranges. The majority voting method was used to fuse the classifications of high, medium and low spatial resolution images. Based on the largest area method, the fusion results were integrated with multi-scale segmentation to explore the classification ability of the integration of pixel-based classification and object-based classification. The average accuracies of different spatial resolutions to vegetation in multispectral images were statistically analysed in order to quantitatively study the classification ability of spatial resolution to marsh vegetation. The results indicated that: (1) image combination improved the classification accuracy of marsh vegetation in low-resolution images, and decreased the classification accuracy of vegetation in high- and medium-resolution images based on DeepLabV3+ and HRNet algorithms; (2) when GF-1 and Sentinel-2A images were used for combination, the spectral range increased by 1565–1655 nm and 2100–2280 nm from 450–900 nm, the classification accuracy of GF-1 image improved by 0.93–1.77%, and the classification accuracy of Sentinel-2A image decreased by 2.34–4.15%; (3) DeepLabV3+ and HRNet algorithms both have good transfer learning capabilities in the classification of marsh vegetation, but the transfer learning ability was better in images with different spatial resolutions in similar spectral ranges than in images with different spectral ranges; (4) the integration of object-based segmentation and pixel-based classifications (DeepLabV3+ and HRNet algorithms) improved the accuracy, and the growth rate of overall accuracy reached 4.45–5%; (5) the classification of water in images with different spatial resolution gradients had the largest difference, and the accuracy of deep-water marsh vegetation was lower than that of shrub and shallow-water marsh vegetation.}
}
@article{ISHIDA201880,
title = {A novel approach for vegetation classification using UAV-based hyperspectral imaging},
journal = {Computers and Electronics in Agriculture},
volume = {144},
pages = {80-85},
year = {2018},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2017.11.027},
url = {https://www.sciencedirect.com/science/article/pii/S0168169917310499},
author = {Tetsuro Ishida and Junichi Kurihara and Fra Angelico Viray and Shielo Baes Namuco and Enrico C. Paringit and Gay Jane Perez and Yukihiro Takahashi and Joel Joseph Marciano},
keywords = {Liquid crystal tunable filter, Unmanned aerial vehicle, Vegetation classification, Machine learning},
abstract = {The use of unmanned aerial vehicle (UAV)-based spectral imaging offers considerable advantages in high-resolution remote-sensing applications. However, the number of sensors mountable on a UAV is limited, and selecting the optimal combination of spectral bands is complex but crucial for conventional UAV-based multispectral imaging systems. To overcome these limitations, we adopted a liquid crystal tunable filter (LCTF), which can transmit selected wavelengths without the need to exchange optical filters. For calibration and validation of the LCTF-based hyperspectral imaging system, a field campaign was conducted in the Philippines during March 28–April 3, 2016. In this campaign, UAV-based hyperspectral imaging was performed in several vegetated areas, and the spectral reflectances of 14 different ground objects were measured. Additionally, the machine learning (ML) approach using a support vector machine (SVM) model was applied to the obtained dataset, and a high-resolution classification map was then produced from the aerial hyperspectral images. The results clearly showed that a large amount of misclassification occurred in shaded areas due to the difference in spectral reflectance between sunlit and shaded areas. It was also found that the classification accuracy was drastically improved by training the SVM model with both sunlit and shaded spectral data. As a result, we achieved a classification accuracy of 94.5% in vegetated areas.}
}
@article{PEREZMONTENEGRO2018110,
title = {A Mission Coordinator Approach for a Fleet of UAVs in Urban Scenarios},
journal = {Transportation Research Procedia},
volume = {35},
pages = {110-119},
year = {2018},
note = {INAIR 2018AVIATION ON THE GROWTH PATH},
issn = {2352-1465},
doi = {https://doi.org/10.1016/j.trpro.2018.12.018},
url = {https://www.sciencedirect.com/science/article/pii/S2352146518303582},
author = {Carlos Perez-Montenegro and Matteo Scanavino and Nicoletta Bloise and Elisa Capello and Giorgio Guglieri and Alessandro Rizzo},
keywords = {Smart City, UAVs, Urban Mission, Mission Coordinator},
abstract = {The use of Unmanned Aerial Vehicles (UAVs) is now common, but although they have been for various applications, there are still a lot of challenges that need to be overcome. One key issue is related to standardizing the use of these vehicles in urban environments and guaranteeing a minimum risk level for the population. To rise to these challenges, autonomous strategies that optimize and coordinate vehicles in cooperative missions and avoid human operators should be developed. The novelty of this paper is the development of an autonomous urban mission coordinator, which is responsible for the high-level logistics of a fleet of heterogeneous vehicles. A multi-variable weighted algorithm based on a tree optimization method is also proposed.}
}
@article{TANG2021107913,
title = {A joint global and local path planning optimization for UAV task scheduling towards crowd air monitoring},
journal = {Computer Networks},
volume = {193},
pages = {107913},
year = {2021},
issn = {1389-1286},
doi = {https://doi.org/10.1016/j.comnet.2021.107913},
url = {https://www.sciencedirect.com/science/article/pii/S1389128621000682},
author = {Yuan Tang and Yiming Miao and Ahmed Barnawi and Bander Alzahrani and Reem Alotaibi and Kai Hwang},
keywords = {Crowd air monitoring, Joint optimization, Path planning, Task scheduling, Unmanned aerial vehicle},
abstract = {Large-scale crowd management systems are used to monitor and manage crowds in various industries aspects by utilizing relevant innovative technologies. In order to overcome the shortcomings of traditional CCTV equipment in shooting angle and deployment, some scholars propose to use unmanned ariel vehicle (UAV) carried appropriate optical sensory equipment to perform aerial scene surveillance. However, UAV flight missions have problems such as poor adaptability of single-mode path planning to site conditions space and complex cluster scheduling systems. Therefore, we combine the improved particle swarm optimization(PSO) algorithm, the optimized artificial potential algorithm, path exploration switching mode and energy-based task scheduling mechanism to propose a joint global and local path planning optimization for UAV task scheduling towards crowd air monitoring (JGLPP-UTS). In this model, the PSO algorithm is improved based on mutation mechanism and iterative number dependent adaptive inertia weight, we add a path smoothing mechanism. Then, we optimize the artificial potential algorithm for the problem of the target point unreachable and the local minimum. The proposed model switches the path planning mode according to the global and local obstacle environment. Finally, our model comprehensively considers the information of the site to realize the surveillance task scheduling of the UAV. Experiments show that our proposed algorithm can effectively improve the ability of global and local path planning. Compared with the standard PSO path length, the global path is reduced by 8.92%, and the adaptive value is reduced by 82.9%. After the smoothing operation, we also report that the path length can be further reduced. Moreover, the task scheduling strategy can realize the effective use of airborne resources.}
}
@article{MLIKI2020107140,
title = {Human activity recognition from UAV-captured video sequences},
journal = {Pattern Recognition},
volume = {100},
pages = {107140},
year = {2020},
issn = {0031-3203},
doi = {https://doi.org/10.1016/j.patcog.2019.107140},
url = {https://www.sciencedirect.com/science/article/pii/S0031320319304418},
author = {Hazar Mliki and Fatma Bouhlel and Mohamed Hammami},
keywords = {Scene stabilization, Human detection, Human activity recognition, Deep learning, Convolutional neural networks, UAV},
abstract = {This research paper introduces a new approach for human activity recognition from UAV-captured video sequences. The proposed approach involves two phases: an offline phase and an inference phase. A scene stabilization step is performed together with these two phases. The offline phase aims to generate the human/non-human model as well as a human activity model using a convolutional neural network. The inference phase makes use of the already generated models in order to detect humans and recognize their activities. Our main contribution lies in adapting the convolutional neural networks, normally dedicated to the classification task, to detect humans. In addition, the classification of human activities is carried out according to two scenarios: An instant classification of video frames and an entire classification of the video sequences. Relying on an experimental evaluation of the proposed methods for human detection and human activity classification on the UCF-ARG dataset, we validated not only these contributions but also the performance of our methods compared to the existing ones.}
}
@article{PINTO2021112594,
title = {Detecting stranded macro-litter categories on drone orthophoto by a multi-class Neural Network},
journal = {Marine Pollution Bulletin},
volume = {169},
pages = {112594},
year = {2021},
issn = {0025-326X},
doi = {https://doi.org/10.1016/j.marpolbul.2021.112594},
url = {https://www.sciencedirect.com/science/article/pii/S0025326X21006287},
author = {Luis Pinto and Umberto Andriolo and Gil Gonçalves},
keywords = {Drone, Machine learning, Beach pollution, Remote sensing, Coastal monitoring},
abstract = {The use of Unmanned Aerial Systems (UAS, aka drones) images for mapping macro-litter in the environment have been exponentially increasing in the recent years. In this work, we developed a multi-class Neural Network (NN) to automatically identify stranded plastic litter categories on an UAS-derived orthophoto. The best results were assessed for items that did not have substantial intra-class colour variability, such as octopus pots and fishing ropes (F-score = 61%, on average). Instead, performance was poor (37%) for plastic bottles and fragments, due to their changing intra-class colours. On average, the performance improved 24% when the binary detection (litter/non-litter, F-Score = 73%) was considered, however this approach did not discriminate the litter categories. This work gives a new perspective for the automated litter detection on drone images, suggesting that colour-based approach can be used to improve the categorization of stranded litter on UAS orthophoto.}
}
@article{DU2021232,
title = {Hybrid beamforming NOMA for mmWave half-duplex UAV relay-assisted B5G/6G IoT networks},
journal = {Computer Communications},
volume = {180},
pages = {232-242},
year = {2021},
issn = {0140-3664},
doi = {https://doi.org/10.1016/j.comcom.2021.09.025},
url = {https://www.sciencedirect.com/science/article/pii/S0140366421003625},
author = {Jianhe Du and Yang Zhang and Yuanzhi Chen and Xingwang Li and Yuan Cheng and M.V. Rajesh},
keywords = {B5G/6G, IoT, UAV-aided relay, MmWave, NOMA},
abstract = {Mobile wireless data collection in beyond 5G (B5G)/6G cellular internet of things (IoT) networks can be achieved by unmanned aerial vehicle (UAV) with high flexible mobility and low cost. In this paper, a half-duplex UAV relay is exploited to improve the achievable rate of downlink millimeter-wave (mmWave) massive multi-user multiple-input and multiple-output (MU-MIMO) networks. To improve the spectrum efficiency and mitigate the inter-beam interference, the hybrid beamforming (HB) designs of the base station (BS), the UAV and multiusers are taken into account simultaneously. To maximize the achievable rate from the BS to the multiusers, a two-stage design approach which tries to design the two stages jointly by avoiding the loss of information is proposed. Assuming multiusers are alignment in different beams, the strong effective channel-based non-orthogonal multiple access (NOMA) in the power domain is employed to assign power efficiently for each user, thereby increasing the number of users. Simulation results validate the proposed HB-NOMA approach can achieve good achievable rate performance in both uniform linear array and uniform planar array.}
}
@article{YANG2022403,
title = {A hierarchical approach for refining point cloud quality of a low cost UAV LiDAR system in the urban environment},
journal = {ISPRS Journal of Photogrammetry and Remote Sensing},
volume = {183},
pages = {403-421},
year = {2022},
issn = {0924-2716},
doi = {https://doi.org/10.1016/j.isprsjprs.2021.11.022},
url = {https://www.sciencedirect.com/science/article/pii/S0924271621003208},
author = {Bisheng Yang and Jianping Li},
keywords = {Low cost, Unmanned aerial vehicle (UAV), Light detection and ranging (LiDAR), Point clouds, Matching},
abstract = {Insufficient accuracies of the low end position and orientation system (POS) used in low cost UAV LiDAR systems (ULSs) cause the direct georeferencing data to lead to poor point cloud quality. Trajectory correction and scan-to-map matching are two commonly used strategies for point cloud quality refinement. The existing trajectory correction strategies work with the assumption that POS errors can be modeled as a time-variant function, which cannot be applied to the low end POS. The existing scan-to-map matching methods have difficulty refining the ULS point clouds due to the large gaps between scan lines. This paper proposes HR-ULS, hierarchical refinement for low cost ULS point cloud quality in the urban environment, to solve these challenges. HR-ULS separated the raw laser scanning point clouds into a set of scan-blocks and refined the point cloud quality with a hierarchical strategy, resulting in local and global optimization, respectively. First, the internal scan-block matching (ISBM) estimated multiscale distributions for each laser frame and calculated relative motions iteratively to achieve local map consistency in each scan-block. Second, the multiview scan-block matching (MSBM) took inertial, Global Navigation Satellite System (GNSS), and laser measurements into a unified adjustment framework to correct the trajectory, achieving global map consistency between scan-blocks. Comprehensive experiments evaluated the proposed HR-ULS with the point clouds captured by a low-cost ULS in three typical urban areas. They showed that the average plane fitting RMSE of the ULS point clouds was improved from 0.34 m to 0.09 m, and the average checkpoint offset was improved from 1.86 m to 0.21 m, achieving an identical level of accuracy with that of direct georeferencing using a high end POS, APX-15-UAV.}
}
@article{GARCIA2020105826,
title = {A systematic literature review on the use of machine learning in precision livestock farming},
journal = {Computers and Electronics in Agriculture},
volume = {179},
pages = {105826},
year = {2020},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2020.105826},
url = {https://www.sciencedirect.com/science/article/pii/S0168169920317099},
author = {Rodrigo García and Jose Aguilar and Mauricio Toro and Angel Pinto and Paul Rodríguez},
keywords = {Precision livestock farming, Animal health, Grazing, Artificial intelligence, Machine learning, Big data analytics, Industry 4.0},
abstract = {This article presents a systematic literature review of recent works on the use of machine learning (ML) in precision livestock farming (PLF), focusing on two areas of interest: grazing and animal health. This review: (i) highlights opportunities for ML in the livestock sector; (ii) shows the current sensors, software and techniques for data analysis; (iii) details the increasing openness of data sources. It was found that the use of ML in PLF is in a stage of development and has several research challenges. Examples of such challenges are: (i) to develop hybrid models for diagnosis and prescription as a tool for the prevention and control of animal diseases; (ii) to bring together the grazing and animal health issues; (iii) to give autonomy to PLF using autonomous cycles of data analysis tasks and meta-learning; and (iv) to bring together soil and pasture variables because, for both, animal health and animal grazing, the variables used are only behavioral and environmental.}
}
@article{LIU2018392,
title = {Deep learning based trajectory optimization for UAV aerial refueling docking under bow wave},
journal = {Aerospace Science and Technology},
volume = {80},
pages = {392-402},
year = {2018},
issn = {1270-9638},
doi = {https://doi.org/10.1016/j.ast.2018.07.024},
url = {https://www.sciencedirect.com/science/article/pii/S127096381830823X},
author = {Yiheng Liu and Honglun Wang and Zikang Su and Jiaxuan Fan},
keywords = {Autonomous aerial refueling (AAR), Receiver trajectory optimization, Deep learning, Bow wave, Drogue motion prediction},
abstract = {In the autonomous aerial refueling (AAR) docking process, the bow wave generated by the receiver has a strong effect on the drogue, which affects the docking success rate greatly. Thus, a deep learning based trajectory optimization method which aims to decrease the bow wave effect on the drogue is proposed in this paper. There are mainly three parts in the proposed trajectory optimization method. Firstly, a precise bow wave model based on deep learning is presented to estimate the bow wave effect on the drogue. Furthermore, due to the dynamic characteristic of the drogue, a simple and practical drogue motion prediction model under multiple disturbances is carried out to provide a precise prediction of the drogue position at the next time. Moreover, considering the strict attitude constraints requirements in the AAR docking process, a novel reference observer is designed to estimate the receiver attitude from the optimized trajectory under wind perturbations. Then, the proposed trajectory optimization method could not only diminish the bow wave effect on the drogue largely but also satisfy the attitude constraints of the receiver. Finally, the effectiveness of the proposed method is demonstrated by the simulations.}
}
@article{MUTHUGALA2022115940,
title = {Toward energy-efficient online Complete Coverage Path Planning of a ship hull maintenance robot based on Glasius Bio-inspired Neural Network},
journal = {Expert Systems with Applications},
volume = {187},
pages = {115940},
year = {2022},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2021.115940},
url = {https://www.sciencedirect.com/science/article/pii/S095741742101294X},
author = {M.A. Viraj J. Muthugala and S.M. Bhagya P. Samarakoon and Mohan Rajesh Elara},
keywords = {Complete area coverage, Energy efficiency, Glasius Bio-inspired Neural Network, Maintenance robotics, Ship maintenance},
abstract = {Regular Ship hull maintenance is an essential for sustainability. The maintenance work of ship hulls that involve human labor suffers from many shortcomings. Maintenance robots have been introduced for drydocks to eliminate these shortcomings. An energy-efficient Complete Coverage Path Planning (CCPP) is a crucial requirement from a ship hull maintenance robot. This paper proposes a novel energy-efficient CCPP method based on Glasius Bioinspired Neural Network (GBNN) for a ship hull inspection robot. The proposed method accounts for a comprehensive energy model for path planning. This energy model reflects the energy usage of a ship hull maintenance robot due to changes in direction, distance, and vertical position. Furthermore, the proposed method is effective for dynamic workspaces since it performs online path planning. These are the major contributions made to state of the art by the work proposed in this paper. The behavior and the performance of the proposed method have been compared against state of the art through simulations considering Hornbill, a multipurpose ship hull maintenance robot. The validation confirms the ability of the proposed in realizing a complete coverage of a given dynamic workspace. According to the statistical outcomes of the comparison, the performance of the proposed method significantly surpasses that of the state-of-the-art methods in terms of energy usage. Therefore, the proposed method contributes to the development of energy-efficient CCPP methods for a ship hull maintenance robot.}
}
@article{HOSSEINALIZADEH2019184,
title = {Spatial modelling of gully headcuts using UAV data and four best-first decision classifier ensembles (BFTree, Bag-BFTree, RS-BFTree, and RF-BFTree)},
journal = {Geomorphology},
volume = {329},
pages = {184-193},
year = {2019},
issn = {0169-555X},
doi = {https://doi.org/10.1016/j.geomorph.2019.01.006},
url = {https://www.sciencedirect.com/science/article/pii/S0169555X19300066},
author = {Mohsen Hosseinalizadeh and Narges Kariminejad and Wei Chen and Hamid Reza Pourghasemi and Mohammad Alinejad and Ali {Mohammadian Behbahani} and John P. Tiefenbacher},
keywords = {Gully headcut, Unmanned aerial vehicle, Ensemble modelling, Sensitivity analysis, Iran, Iky Aghzly sub-watershed},
abstract = {Despite the importance of delineating spatial modelling of gully headcuts (GHs) in erosion-prone environments, assessments of the factors that control the occurrence of headcuts is lacking. To fill this gap in the research, we identified 129 GHS field surveys. These 129 cases were randomly divided into two groups: 90 GHs (70%) for model training and 39 GHs (30%) for model validation. Subsequently, new unmanned aerial vehicle (UAV) imagery is used to develop spatial modelling to predict the location of GHs at sites prone to soil erosion in Golestan Province, Iran. Mapping GHs enables evaluation of 4 machine-learning techniques (or ensembles) – best-first decision tree (BFTree), bagging best-first decision tree (Bag-BFTree), random-subspace best-first decision tree (RS-BFTree), and rotation-forest best-first decision tree (RF-BFTree) – for modelling GHs. We use the information-gain ratio method to analyze the relationships between GHS and 22 GH conditioning factors. The 4 ensemble outputs are validated using a receiver operating characteristic (ROC) curve. The areas under the curves (AUCs) for prediction rates of the ensemble methods applied to the training group are BFTree – 88.3%, Bag-BFTree – 92.7%, RS-BFTree – 95.7%, and RF-BFTree – 93.2%. The AUCs for the model-validation group cases, however, are 84.9%, 94.1%, 97.4%, and 9.18%, respectively. Therefore, RS-BFTree is, statistically, the most effective ensemble method for accurate modelling of GHs. Variable-importance analyses using information-gain ratio indicate that out of 22 GH-influential factors, land use, slope degree, and slope-length are of more importance in developing of GH occurrence. Finally, to address the need for detailed observations and highly accurate erosion data in the field, UAV image-acquisition technologies are demonstrated.}
}
@article{LEE2022104981,
title = {Semi-automatic calculation of joint trace length from digital images based on deep learning and data structuring techniques},
journal = {International Journal of Rock Mechanics and Mining Sciences},
volume = {149},
pages = {104981},
year = {2022},
issn = {1365-1609},
doi = {https://doi.org/10.1016/j.ijrmms.2021.104981},
url = {https://www.sciencedirect.com/science/article/pii/S1365160921003634},
author = {Yong-Ki Lee and Jineon Kim and Chae-Soon Choi and Jae-Joon Song},
keywords = {Joint trace, Digital image, Deep learning, Semantic segmentation, Three-dimensional data structuring},
abstract = {A new semi-automated method is proposed in this study that detects joint traces from digital images and calculates the length distribution through three-dimensional data structuring. The method comprises detecting the pixels corresponding to the joint trace in digital images and calculating the length distribution through three-dimensional data structuring of the pixels detected as the joint trace. Semantic segmentation based on deep learning techniques is applied to the detection of joint trace pixels to overcome the limitations of rule-based image processing techniques. For training a deep learning network, various rock joint images were sampled and labeled, following which the data sets for training, validation, and testing were prepared through classification and augmentation. Using the prepared datasets, the performance of the classifiers based on widely used semantic segmentation networks, namely U-Net (University of Freiburg, Germany) network and DeepLabV3+ (Google, USA) network, was compared. The classifier based on the DeepLabV3+ network was ultimately selected and applied. The trained classifier successfully detected pixels corresponding to the joint trace in images of both flat and uneven rock surfaces, indicating that the deep learning technique could be applied effectively to joint trace detection from digital images. Further, a data structuring technique is proposed to calculate the joint trace length using pixelwise data detected through the trained classifier. This technique uses point cloud data obtained by photogrammetry, and comprises two-dimensional thinning and segmentation, three-dimensional projection, segmentation, and segment linking. The entire proposed method, from detecting the joint trace pixels to three-dimensional data structuring, was verified by applying it to both simple flat and uneven rock surface models.}
}
@article{TEAGUE2021100027,
title = {Time series classification of radio signal strength for qualitative estimate of UAV motion},
journal = {Machine Learning with Applications},
volume = {4},
pages = {100027},
year = {2021},
issn = {2666-8270},
doi = {https://doi.org/10.1016/j.mlwa.2021.100027},
url = {https://www.sciencedirect.com/science/article/pii/S2666827021000086},
author = {Samuel Teague and Javaan Chahl},
keywords = {LSTM, Received signal strength, UAV, Navigation},
abstract = {Many common navigation solutions fall short when an aircraft’s GPS signal is either jammed or spoofed. This is typically due to the iterative nature of the estimation process, which requires an acceptably accurate initial estimate, or due to the accumulated error of inertial sensors, which are unable to directly observe the position of an aircraft. A mechanism is presented in this paper which operates on qualitative information, allowing an aircraft to remain within a vicinity despite an absence of precision localization. A long-short-term-memory neural network was used for time series classification of radio signal strength data on a light weight fixed wing UAV. Simulation results show that the two class classifier is able to determine the motion of an aircraft with respect to a radio beacon with 97.73% accuracy. The classes used for classification represent motion as either towards, or away from a beacon. A simple high level controller was designed to use the classification output and converge on a beacon. Results from this paper indicate that this unique application of qualitative navigation by the application of time series classification offers a viable alternative to aircraft navigation in GPS denied environments.}
}
@article{FELTUS2020516,
title = {Current and Future RL’s Contribution to Emerging Network Security},
journal = {Procedia Computer Science},
volume = {177},
pages = {516-521},
year = {2020},
note = {The 11th International Conference on Emerging Ubiquitous Systems and Pervasive Networks (EUSPN 2020) / The 10th International Conference on Current and Future Trends of Information and Communication Technologies in Healthcare (ICTH 2020) / Affiliated Workshops},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2020.10.071},
url = {https://www.sciencedirect.com/science/article/pii/S1877050920323413},
author = {Christophe Feltus},
keywords = {Artificial Intelligence, Reinforcement Learning, Security, Network Security, Malware Detection, Literature Review},
abstract = {Reinforcement learning is a machine-learning paradigm, which learns the best actions an agent needs to perform to maximize its rewards in a particular environment. Research into RL has been proven to have made a real contribution to the protection of emerging network systems against malware. In this paper, a systematic review of this research was performed in regard to various attacks and an analysis of the trends and future fields of interest for the RL-based research in network security was completed.}
}
@article{MA2022116226,
title = {Towards improved accuracy of UAV-based wheat ears counting: A transfer learning method of the ground-based fully convolutional network},
journal = {Expert Systems with Applications},
volume = {191},
pages = {116226},
year = {2022},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2021.116226},
url = {https://www.sciencedirect.com/science/article/pii/S0957417421015396},
author = {Juncheng Ma and Yunxia Li and Hongjie Liu and Yongfeng Wu and Lingxian Zhang},
keywords = {Number of wheat ears, UAV, Digital images, Convolutional neural network, Transfer learning},
abstract = {In order to achieve accurate UAV-based wheat ear counting, a transfer learning method of the ground-based fully convolutional network, i.e., EarDensityNet, was proposed in this study. The EarDensityNet, which integrated the filter pyramid block and dilated convolution, was designed to map the wheat canopy images to ear density maps generated by dot annotations. The wheat ear counting can be obtained by summing all the pixel values of the corresponding ear density map. Results showed strong correlations could be observed between the actual number of wheat ears to those estimated by the EarDensityNet, with high coefficient of determination (R2 = 0.9179) and low Root-Mean-Square-Error (RMSE = 17.61 ears, NRMSE = 4.47%), outperforming the compared methods. Ground resolution of canopy images had a significant impact on the performance of the EarDensityNet. Transfer learning of the ground-based EarDensityNet could take full advantage of the rich details presented by the ground-based images with high pixel resolution, thus effectively alleviating the degradation of counting performance caused by the decreased ground resolution. Therefore, obtained results showed the fine-tuned EarDensityNet more accurate UAV-based wheat ear counting (R2 = 0.9570, RMSE = 801.34, and NRMSE = 22.06%) than one learned from scratch, demonstrating the superiority and applicability. Border effect from splitting digital images with high pixel resolution into sub-images did not make a major problem to the EarDensityNet, demonstrating great potentials to be generalized from plot-wise to field-wise. Wheat ear counting was recommended after the flowering stage since the textures of wheat ears were more obvious for EarDensityNet to learn complex feature representations.}
}
@article{SINDEGONZALEZ2021102355,
title = {Biomass estimation of pasture plots with multitemporal UAV-based photogrammetric surveys},
journal = {International Journal of Applied Earth Observation and Geoinformation},
volume = {101},
pages = {102355},
year = {2021},
issn = {0303-2434},
doi = {https://doi.org/10.1016/j.jag.2021.102355},
url = {https://www.sciencedirect.com/science/article/pii/S0303243421000623},
author = {Izar Sinde-González and Mariluz Gil-Docampo and Marcos Arza-García and José Grefa-Sánchez and Diana Yánez-Simba and Patricio Pérez-Guerrero and Víctor Abril-Porras},
keywords = {Cultivated pastures, CSM, Precision agriculture, DTM, Aboveground biomass},
abstract = {Pastures account for more than 56% of the total agricultural area of Ecuador and constitute the main food source for livestock. Hence, the agile, affordable, and reliable quantification of aboveground biomass (AGB) is an essential task in grazing utilization and management. In this paper, a method to estimate the AGB via aerial photogrammetry with a low-cost UAV multirotor is proposed. Digital terrain models and crop surface models were generated from data captured during two flights at different times, and the volume between them was calculated. An empirical relationship between volume and dry biomass was obtained by harvesting and weighing some samples and deriving a density factor (DF). The method was tested over 54 plots with different types of forage under differential fertilization treatments. Fertilized annual ryegrass exhibited the best growth and highest biomass (2632 kg/ha). The estimation and calculation of the crop volume via UAV-based photogrammetry saves time and generates notably precise (R2 = 0.78) information on the dry biomass.}
}
@article{SIRELKHATEM2021,
title = {Robust LQR and LQR-PI control strategies based on adaptive weighting matrix selection for a UAV position and attitude tracking control},
journal = {Alexandria Engineering Journal},
year = {2021},
issn = {1110-0168},
doi = {https://doi.org/10.1016/j.aej.2021.11.057},
url = {https://www.sciencedirect.com/science/article/pii/S1110016821007900},
author = {Aisha {Sir Elkhatem} and Seref {Naci Engin}},
keywords = {UAV, LQR, LQR-PI, Weighting matrices, Mass uncertainty, Actuator fault},
abstract = {Unmanned aerial vehicles (UAVs) are subject to the wind and other environmental disturbances that can destabilize them. The high performance and robustness of the Linear Quadratic Regulator (LQR) controllers ensure the ability to reduce the deviations in state trajectories with minimum control effort. In this paper, the weighting matrices are adjusted automatically via a novel method implemented through state variables matrix of the quadrotor together with a preference factor. This proposed factor is determined by the designer via penalizing or rewarding a certain state of the quadrotor out of others so that the model insufficiencies against disturbances are compensated. The effectiveness of the proposed method of selecting these matrices is evaluated for the cases of LQR and LQR with a PI controller. They were evaluated with respect to the convergence of state variables to their reference values within a specific time and compliance with their desired performance characteristics. The experimental results revealed that both control strategies could stabilize the quadrotor in the desired position and attitude with better performance and robustness characteristics. The results also showed that the LQR-PI control method is a more reliable and effective approach in achieving higher tracking performances compared to the LQR only.}
}
@article{ZHAO20202465,
title = {Fault-Tolerant Control for the Formation of Multiple Unknown Nonlinear Quadrotors via Reinforcement Learning⁎⁎This work was supported by the National Natural Science Foundation of China under Grants 61873012, 61503012, and 61633007, and the Office of Naval Research under Grant N00014-17-1-2239.},
journal = {IFAC-PapersOnLine},
volume = {53},
number = {2},
pages = {2465-2470},
year = {2020},
note = {21st IFAC World Congress},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2020.12.194},
url = {https://www.sciencedirect.com/science/article/pii/S2405896320304596},
author = {Wanbing Zhao and Hao Liu and Frank L. Lewis},
keywords = {Fault-tolerant control, formation control, reinforcement learning, model-free, quadrotor system},
abstract = {In this paper, the fault-tolerant control problem for the formation of unknown quadrotor team with nonlinearities, couplings, and actuator faults in the dynamics is investigated. A distributed observer is designed to estimate the position references for each quadrotor. A hierarchical control scheme is constructed including a fault-tolerant position controller to achieve the desired formation and a fault-tolerant attitude controller to track the attitude references. Reinforcement learning algorithms are designed to learn the optimal control policies of the position and attitude controllers. Simulation results are given to illustrate the effectiveness of the proposed controller.}
}
@article{ASAD2020535,
title = {Weed detection in canola fields using maximum likelihood classification and deep convolutional neural network},
journal = {Information Processing in Agriculture},
volume = {7},
number = {4},
pages = {535-545},
year = {2020},
issn = {2214-3173},
doi = {https://doi.org/10.1016/j.inpa.2019.12.002},
url = {https://www.sciencedirect.com/science/article/pii/S2214317319302355},
author = {Muhammad Hamza Asad and Abdul Bais},
keywords = {Weed detection, Semantic segmentation, Variable rate herbicide, Maximum likelihood classification},
abstract = {Herbicide use is rising globally to enhance food production, causing harm to environment and the ecosystem. Precision agriculture suggests variable-rate herbicide application based on weed densities to mitigate adverse effects of herbicides. Accurate weed density estimation using advanced computer vision techniques like deep learning requires large labelled agriculture data. Labelling large agriculture data at pixel level is a time-consuming and tedious job. In this paper, a methodology is developed to accelerate manual labelling of pixels using a two-step procedure. In the first step, the background and foreground are segmented using maximum likelihood classification, and in the second step, the weed pixels are manually labelled. Such labelled data is used to train semantic segmentation models, which classify crop and background pixels as one class, and all other vegetation as the second class. This paper evaluates the proposed methodology on high-resolution colour images of canola fields and makes performance comparison of deep learning meta-architectures like SegNet and UNET and encoder blocks like VGG16 and ResNet-50. ResNet-50 based SegNet model has shown the best results with mean intersection over union value of 0.8288 and frequency weighted intersection over union value of 0.9869.}
}
@article{FEI2022306,
title = {A Novel deep neural network-based emotion analysis system for automatic detection of mild cognitive impairment in the elderly},
journal = {Neurocomputing},
volume = {468},
pages = {306-316},
year = {2022},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2021.10.038},
url = {https://www.sciencedirect.com/science/article/pii/S0925231221015186},
author = {Zixiang Fei and Erfu Yang and Leijian Yu and Xia Li and Huiyu Zhou and Wenju Zhou},
keywords = {Mild cognitive impairment, Facial expression analysis, Deep convolution network, MobileNet},
abstract = {A significant number of people are suffering from cognitive impairment all over the world. Early detection of cognitive impairment is of great importance to both patients and caregivers. However, existing approaches have their shortages, such as time consumption and financial expenses involved in clinics and the neuroimaging stage. It has been found that patients with cognitive impairment show abnormal emotion patterns. In this paper, we present a novel deep neural network-based system to detect the cognitive impairment through the analysis of the evolution of facial emotions while participants are watching designed video stimuli. In our proposed system, a novel facial expression recognition algorithm is developed using layers from MobileNet and Support Vector Machine (SVM), which showed satisfactory performance in 3 datasets. To verify the proposed system in detecting cognitive impairment, 61 elderly people including patients with cognitive impairment and healthy people as a control group have been invited to participate in the experiments and a dataset was built accordingly. With this dataset, the proposed system has successfully achieved the detection accuracy of 73.3%.}
}
@article{LI2020161,
title = {Above-ground biomass estimation and yield prediction in potato by using UAV-based RGB and hyperspectral imaging},
journal = {ISPRS Journal of Photogrammetry and Remote Sensing},
volume = {162},
pages = {161-172},
year = {2020},
issn = {0924-2716},
doi = {https://doi.org/10.1016/j.isprsjprs.2020.02.013},
url = {https://www.sciencedirect.com/science/article/pii/S0924271620300538},
author = {Bo Li and Xiangming Xu and Li Zhang and Jiwan Han and Chunsong Bian and Guangcun Li and Jiangang Liu and Liping Jin},
keywords = {Unmanned aerial vehicle, Hyperspectral imaging, Potato, Above-ground biomass, Yield prediction},
abstract = {Rapid and accurate biomass and yield estimation facilitates efficient plant phenotyping and site-specific crop management. A low altitude unmanned aerial vehicle (UAV) was used to acquire RGB and hyperspectral imaging data for a potato crop canopy at two growth stages to estimate the above-ground biomass and predict crop yield. Field experiments included six cultivars and multiple treatments of nitrogen, potassium, and mixed compound fertilisers. Crop height was estimated using the difference between digital surface model and digital elevation models derived from RGB imagery. Combining with two narrow-band vegetation indices selected by the RReliefF feature selection algorithm. Random Forest regression models demonstrated high prediction accuracy for both fresh and dry above-ground biomass, with a coefficient of determination (r2) > 0.90. Crop yield was predicted using four narrow-band vegetation indices and crop height (r2 = 0.63) with imagery data obtained 90 days after planting. A Partial Least Squares regression model based on the full wavelength spectra demonstrated improved yield prediction (r2 = 0.81). This study demonstrated the merits of UAV-based RGB and hyperspectral imaging for estimating the above-ground biomass and yield of potato crops, which can be used to assist in site-specific crop management.}
}
@article{ANAGNOSTIS2021105998,
title = {A deep learning approach for anthracnose infected trees classification in walnut orchards},
journal = {Computers and Electronics in Agriculture},
volume = {182},
pages = {105998},
year = {2021},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2021.105998},
url = {https://www.sciencedirect.com/science/article/pii/S0168169921000168},
author = {A. Anagnostis and A.C. Tagarakis and G. Asiminari and E. Papageorgiou and D. Kateris and D. Moshou and D. Bochtis},
keywords = {Precision agriculture, Disease detection, Machine learning, Computer vision, Object detection},
abstract = {This paper presents a novel approach for the detection of disease-infected leaves on trees with the use of deep learning. Focus of this study was to build an accurate and fast object detection system that can identify anthracnose-infected leaves on walnut trees, in order to be used in real agricultural environments. Similar studies in the literature address the disease identification issue; however, so far, the detection was performed on single leaves which had been removed from trees, using images taken in controlled environment with clear background. A gap has been identified in the detection of infected leaves on tree-level in real-field conditions, an issue which is tackled in our study. Deep learning is an area of machine learning that can be proved particularly useful in the development of such systems. The latest developments in deep learning and object detection, points us towards utilizing and adapting the state-of-the-art single shot detector (SSD) algorithm. An object detector was trained to recognize anthracnose-infected walnut leaves and the trained model was applied to detect diseased trees in a 4 ha commercial walnut orchard. The orchard was initially inspected by domain experts identifying the infected trees to be used as ground truth information. Out of the 379 trees of the orchard, 100 were randomly selected to train the object detector and the remaining 279 trees were used to examine the effectiveness and robustness of the detector comparing the experts’ classification with the predicted classes of the system. The best inputs and hyper-parameter configuration for the trained model provided an average precision of 63% for the object detector, which correctly classified 87% of the validation tree dataset. These encouraging results indicate that the detector shows great potential for direct application in commercial orchards, to detect infected leaves on tree level in real field conditions, and categorize the trees into infected or healthy in real time. Thus, this system can consist an applicable solution for real-time scouting, monitoring, and decision making.}
}
@article{DAS2022101540,
title = {Building of an edge enabled drone network ecosystem for bird species identification},
journal = {Ecological Informatics},
volume = {68},
pages = {101540},
year = {2022},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2021.101540},
url = {https://www.sciencedirect.com/science/article/pii/S1574954121003319},
author = {Nabanita Das and Neelamadhab Padhy and Nilanjan Dey and Amartya Mukherjee and Ananjan Maiti},
keywords = {Edge computing, Random forest, Songbird, Drone network, Bioacoustics monitoring},
abstract = {The behavioral study of animals and especially avians, and the way of their immunization are highly needed to understand the environment in a better way. Automatically classifying bird species by their vocalization is of crucial relevance for the research of ornithologists and ecologists. It was observed that impartial survey information for songbird species is inherently challenging due to observer biases, habitat insurance biases, and logistical constraints. To get to the bottom of all the challenges, ecologists are trying a machine that let them decide the distribution and density of species, which are essential baseline facts for conservation. For this reason, the utilization of a network of unmanned aerial vehicles is introduced for monitoring and capturing the data of a wide variety of terrestrial and aquatic species. In this study, an edge-enabled drone network has been engineered that amalgamated with the mobile edge computing framework within the drone network and the machine learning models to predict the bird species. The experiment has been performed in two geographic regions. The research reported 98.2% and 96.9% accuracy of random forest classifier with the, 0.07 and 0.4 log loss by utilizing 1.4% of CPU and 329.14 Mb of buffer memory of the edge device with an execution time of 45 milliseconds.}
}
@article{DUAN2021108148,
title = {Remote estimation of grain yield based on UAV data in different rice cultivars under contrasting climatic zone},
journal = {Field Crops Research},
volume = {267},
pages = {108148},
year = {2021},
issn = {0378-4290},
doi = {https://doi.org/10.1016/j.fcr.2021.108148},
url = {https://www.sciencedirect.com/science/article/pii/S0378429021000940},
author = {Bo Duan and Shenghui Fang and Yan Gong and Yi Peng and Xianting Wu and Renshan Zhu},
keywords = {Remote sensing, Grain yield estimation, Rice, Vegetation index, Phenotyping},
abstract = {Timely and accurate estimation of grain yield is valuable for crop monitoring and breeding, and plays an important role in precision agriculture. In this study, we developed a method to predict grain yield based entirely on unmanned aerial vehicle (UAV) data in different rice cultivars under two contrasting climatic regions. Vegetation indices (VIs), which were derived from canopy reflectance collected by UAV, were used to correlate with rice phenotyping and estimate grain yield. It is found that the two-band enhanced vegetation index (EVI2) closely related to leaf area index (LAI) as well as canopy chlorophyll content (CCC), and the red edge chlorophyll index (CIrededge) related to above ground biomass (AGB). Thus, the phenotyping-related VIs – EVI2 and CIrededge were exploited to develop yield estimation model. Results showed that the single stage VIs weakly correlated with grain yield of different rice cultivars and was not able to estimate grain yield. By contrast, the multi-temporal VIs can be used to estimate grain yield in different rice cultivars with the estimation error below 7.1 %. In addition, the rice growth duration differed in different climatic zones, which may decrease the estimation accuracy of grain yield by using multi-temporal VIs. After adjusting the phenological stage of multi-temporal VIs used in estimation model, the estimation accuracy of grain yield in different climatic zones increased. In conclusion, this study demonstrated that the UAV-based multi-temporal VIs were reliable for grain yield estimation in different rice cultivars under contrasting climatic zones.}
}
@article{ALI201775,
title = {Unsupervised feature learning and automatic modulation classification using deep learning model},
journal = {Physical Communication},
volume = {25},
pages = {75-84},
year = {2017},
issn = {1874-4907},
doi = {https://doi.org/10.1016/j.phycom.2017.09.004},
url = {https://www.sciencedirect.com/science/article/pii/S1874490717300435},
author = {Afan Ali and Fan Yangyu},
keywords = {Deep learning networks, Automatic modulation classification, Digital modulation, Autoencoders},
abstract = {Recently, deep learning has received a lot of attention in many machine learning applications for its superior classification performance in speech recognition, natural language understanding and image processing. However, it still lacks attention in automatic modulation classification (AMC) until now. Here, we introduce the application of deep learning in AMC. We propose a fully connected 2 layer feed-forward deep neural network (DNN) with layerwise unsupervised pretraining for the classification of digitally modulated signals in various channel conditions. The system uses independent autoencoders (AEs) for feature learning with multiple hidden nodes. Signal information from the received samples is extracted and preprocessed via I and Q components, and formed into training input to 1st AE layer. A probabilistic based method is employed at the output layer to detect the correct modulation signal. Simulation results show that a significant improvement can be achieved compared to the other conventional machine learning methods in the literature. Moreover, we also show that our proposed method can extract the features from cyclic-stationary data samples. A good classification accuracy was achieved, even when the proposed deep network is trained and tested at different SNRs. This shows the future potential of the deep learning model for application to AMC.}
}
@article{TIAN20202283,
title = {Application of hyperbolic partial differential equations in global optimal scheduling of UAV},
journal = {Alexandria Engineering Journal},
volume = {59},
number = {4},
pages = {2283-2289},
year = {2020},
note = {New trends of numerical and analytical methods for engineering problems},
issn = {1110-0168},
doi = {https://doi.org/10.1016/j.aej.2020.02.013},
url = {https://www.sciencedirect.com/science/article/pii/S1110016820300685},
author = {Chong Tian and Kuo-Chi Chang and JinSong Chen},
keywords = {Hyperbolic partial differential equations, Global optimal scheduling, Wave combination, UAV, Convergence},
abstract = {The global optimal scheduling of UAV(unmanned aerial vehicle)navigation channel is studied. Firstly, a multi-channel optimal scheduling mathematical model based on the HPDEs (hyperbolic partial differential equations) wave combination optimization is proposed. Secondly, the pseudo arc length method is applied to solve the HPDEs, and the form of the spatial transformation of the global pseudo arc length method and its mesh adaptive properties are given. Finally, the results show that the mathematical model is used to achieve better convergence of the UAV's channel scheduling, and the scheduling delay error is lower, which has better reliability and robustness.}
}
@article{ZHANG2018229,
title = {Social-class pigeon-inspired optimization and time stamp segmentation for multi-UAV cooperative path planning},
journal = {Neurocomputing},
volume = {313},
pages = {229-246},
year = {2018},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2018.06.032},
url = {https://www.sciencedirect.com/science/article/pii/S0925231218307689},
author = {Daifeng Zhang and Haibin Duan},
keywords = {Multi-UAV cooperative path planning, Time stamp segmentation, Swarm intelligence optimization, Social-class strategy, Pigeon-inspired optimization},
abstract = {Path planning is a significant issue for the safe flight of unmanned aerial vehicles (UAVs). In the situation of multiple UAVs, the problem is even more challenging due to the tough manipulation of coordination and constrains. In this paper, a novel multi-UAV path planning model is developed which is based on the time stamp segmentation (TSS) technique. Other than the traditional methods, the TSS model utilizes the common time bases to simplify the handling of multi-UAV coordination cost. Then, a novel social-class pigeon-inspired optimization (SCPIO) algorithm is proposed as the solver of optimal search on the TSS model. The social-class strategy is utilized to enhance the convergence capabilities of the standard PIO. The efficiency of the proposed method is verified through the comparative experiments and the performance profiles (PP). Integrated experiment in a 3D environment demonstrates the reliability of the proposed system.}
}
@article{SONG2021,
title = {Topology tracking of dynamic UAV wireless networks},
journal = {Chinese Journal of Aeronautics},
year = {2021},
issn = {1000-9361},
doi = {https://doi.org/10.1016/j.cja.2021.08.012},
url = {https://www.sciencedirect.com/science/article/pii/S1000936121002892},
author = {Yehui SONG and Guoru DING and Jiachen SUN and Jinghua LI and Yitao XU},
keywords = {Dynamic topology inference, Event detection, Hawkes process, UAV swarm, Wireless networks},
abstract = {Wireless network is the communication foundation that supports the intelligentization of Unmanned Aerial Vehicle (UAV) swarm. The topology of UAV communication network is the key to understanding and analyzing the behavior of UAV swarm, thus supporting the further prediction of UAV operations. However, the UAV swarm network topology varies over time due to the high mobility and diversified mission requirements of UAVs. Therefore, it is important but challenging to research dynamic topology inference for tracking the topology changes of the UAV network, especially in non-cooperative manner. In this paper, we study the problem of inferring UAV swarm network topology based on external observations, and propose a dynamic topology inference method. First, we establish a sensing framework for acquiring the communication behavior of the target network over time. Then, we expand the multi-dimensional dynamic Hawkes process to model the communication event sequence in a dynamic wireless network. Finally, combining the sliding time window mechanism, the maximum weighted likelihood estimation is applied to inferring the network topology. Extensive simulation results demonstrate the effectiveness of the proposed method.}
}
@article{XIE2019106609,
title = {Model predictive ship collision avoidance based on Q-learning beetle swarm antenna search and neural networks},
journal = {Ocean Engineering},
volume = {193},
pages = {106609},
year = {2019},
issn = {0029-8018},
doi = {https://doi.org/10.1016/j.oceaneng.2019.106609},
url = {https://www.sciencedirect.com/science/article/pii/S0029801819307310},
author = {Shuo Xie and Vittorio Garofano and Xiumin Chu and Rudy R. Negenborn},
keywords = {Collision avoidance, Multi-ship encounters, Predictive control, Beetle swarm antennas search, Neural networks},
abstract = {Real-time collision avoidance with full consideration of ship maneuverability, collision risks and International Regulations for Preventing Collisions at Sea (COLREGs) is difficult in multi-ship encounters. To deal with this problem, a novel method is proposed based on model predictive control (MPC), an improved Q-learning beetle swarm antenna search (I-Q-BSAS) algorithm and neural networks. The main idea of this method is to use a neural network to approximate an inverse model based on decisions made with MPC for collision avoidance. Firstly, the predictive collision avoidance strategy is established following the MPC concept incorporating an I-Q-BSAS algorithm to solve the optimization problem. Meanwhile, the relative collision motion states in typical encounters are collected for training an inverse neural network model, which is used as an approximated optimal policy of MPC. Moreover, to deal with uncertain dynamics, the obtained policy is reinforced by long-term retraining based on an aggregation of on-policy and off-policy data. Ship collision avoidance in multi-ship encounters can be achieved by weighting the outputs of the neural network model with respect to different target ships. Simulation experiments under several typical and multi-ship encounters are carried out using the KVLCC2 ship model to verify the effectiveness of the proposed method.}
}
@article{XIA2022108062,
title = {Dynamics estimator based robust fault-tolerant control for VTOL UAVs trajectory tracking},
journal = {Mechanical Systems and Signal Processing},
volume = {162},
pages = {108062},
year = {2022},
issn = {0888-3270},
doi = {https://doi.org/10.1016/j.ymssp.2021.108062},
url = {https://www.sciencedirect.com/science/article/pii/S0888327021004519},
author = {Kewei Xia and Wonmo Chung and Hungsun Son},
keywords = {VTOL Unmanned aerial vehicles, Robust control, Fault-tolerant, Trajectory tracking, Non-singularity},
abstract = {This paper investigates the control issue of the trajectory tracking of vertical take-off and landing (VTOL) unmanned aerial vehicles (UAVs) in the presence of partial propeller fault and external disturbance. In particular, a robust passive fault-tolerant control strategy is proposed by introducing a first-order filter based dynamics estimator. First, a bounded force command is exploited by employing a new smooth saturation function in the output of the estimator. A sufficient condition in terms of a specified parameter selection criteria is provided to ensure the non-singularity extraction of the command attitude. Then, a torque command is applied to the attitude loop tracking. Since there is merely one filter parameter involved in the dynamics estimator, the practical implementation and parameter tuning can be significantly simplified. Stability analysis indicates that the proposed control strategy guarantees the semi-globally ultimately bounded tracking of VTOL UAVs subject to partial propeller fault and external disturbance. Simulation and experiment results with comparison examples are performed to validate the effectiveness of the proposed strategy. Experimental results show that the proposed strategy achieves the trajectory tracking with a good performance (mean deviation 0.0074 m and standard deviation 0.1202 m) in the presence of 35% propeller fault and 4 m/s persistent wind disturbance.}
}
@article{BASTIAN2019102134,
title = {Visual inspection and characterization of external corrosion in pipelines using deep neural network},
journal = {NDT & E International},
volume = {107},
pages = {102134},
year = {2019},
issn = {0963-8695},
doi = {https://doi.org/10.1016/j.ndteint.2019.102134},
url = {https://www.sciencedirect.com/science/article/pii/S096386951930060X},
author = {Blossom Treesa Bastian and Jaspreeth N and S. Kumar Ranjith and C.V. Jiji},
keywords = {Water/oil pipelines, Corrosion detection, Optical inspection, Deep learning, Convolutional neural networks},
abstract = {In this paper, we proposed a computer vision based approach to detect corrosion in water, oil and gas pipelines. For this, we created a dataset containing more than 140,000 optical images of pipelines with different levels of corrosion. A custom designed convolutional neural network (CNN) was applied to classify the images of pipelines based on their corrosion level. This in-house fabricated CNN has very few parameters to be learned in comparison with the existing CNN classifiers. However, it produced significantly higher classification accuracy (98.8%) with an ability to discriminate between images of corroded pipelines and images without corrosion but having patterns similar to corroded pipelines. The proposed network surpassed most of the state-of-the-art classifiers in its performance. In addition, we proposed a localisation algorithm based on a recursive region-based method, to selectively identify the corroded regions in a given image with higher precision. The proposed deep learning approach effectively wards off the need for manual inspection and other non-vision based non-destructive evaluation techniques for pipeline corrosion which are cost ineffective and interrupts the functioning of pipelines.}
}
@article{RILEY20211061,
title = {Utilising Assured Multi-Agent Reinforcement Learning within Safety-Critical Scenarios},
journal = {Procedia Computer Science},
volume = {192},
pages = {1061-1070},
year = {2021},
note = {Knowledge-Based and Intelligent Information & Engineering Systems: Proceedings of the 25th International Conference KES2021},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2021.08.109},
url = {https://www.sciencedirect.com/science/article/pii/S1877050921015970},
author = {Joshua Riley and Radu Calinescu and Colin Paterson and Daniel Kudenko and Alec Banks},
keywords = {Reinforcement Learning, Multi-Agent Systems, Quantitative Verification, Assurance, Multi-Agent Reinforcement Learning, Safety-Critical Scenarios, Safe Multi-Agent Reinforcement Learning, Assured Multi-Agent Reinforcement Learning},
abstract = {Multi-agent reinforcement learning allows a team of agents to learn how to work together to solve complex decision-making problems in a shared environment. However, this learning process utilises stochastic mechanisms, meaning that its use in safety-critical domains can be problematic. To overcome this issue, we propose an Assured Multi-Agent Reinforcement Learning (AMARL) approach that uses a model checking technique called quantitative verification to provide formal guarantees of agent compliance with safety, performance, and other non-functional requirements during and after the reinforcement learning process. We demonstrate the applicability of our AMARL approach in three different patrolling navigation domains in which multi-agent systems must learn to visit key areas by using different types of reinforcement learning algorithms (temporal difference learning, game theory, and direct policy search). Furthermore, we compare the effectiveness of these algorithms when used in combination with and without our approach. Our extensive experiments with both homogeneous and heterogeneous multi-agent systems of different sizes show that the use of AMARL leads to safety requirements being consistently satisfied and to better overall results than standard reinforcement learning.}
}
@article{JAISWAL2016296,
title = {Adaptive Longitudinal Control of UAVs with Direct Lift Control},
journal = {IFAC-PapersOnLine},
volume = {49},
number = {1},
pages = {296-301},
year = {2016},
note = {4th IFAC Conference on Advances in Control and Optimization of Dynamical Systems ACODS 2016},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2016.03.069},
url = {https://www.sciencedirect.com/science/article/pii/S2405896316300696},
author = {Ravi Jaiswal and Abhishek Shastry and Swati Swarnkar and Mangal Kothari},
keywords = {DLC, Flap, Dynamic inversion, Adaptive control, Neural network},
abstract = {In this paper, a nonlinear control technique based on Direct Lift Control (DLC) is proposed to control the longitudinal dynamics of unmanned aerial vehicles. The baseline controller is designed using a nonlinear dynamic inversion technique. As the effectiveness of the baseline controller depends on the knowledge of aircraft dynamic model and aerodynamic coefficients, which is difficult to be found accurately for the whole flight regime, the baseline controller is augmented with a neuro-adaptive controller. The approach uses a single layer neural network to learn the unknown dynamics and an adaptive law is employed to ensure that the UAV behaves in the desired manner. Lyapunov theory is used to show that the approximated dynamics remains bounded. Simulations results are presented to demonstrate the effectiveness of the proposed design on a six degrees of freedom model.}
}
@article{MISHRA2020107451,
title = {A survey on cellular-connected UAVs: Design challenges, enabling 5G/B5G innovations, and experimental advancements},
journal = {Computer Networks},
volume = {182},
pages = {107451},
year = {2020},
issn = {1389-1286},
doi = {https://doi.org/10.1016/j.comnet.2020.107451},
url = {https://www.sciencedirect.com/science/article/pii/S1389128620311324},
author = {Debashisha Mishra and Enrico Natalizio},
keywords = {Cellular-connected UAV, 5G/B5G, UAV communications, UAV integration},
abstract = {As an emerging field of aerial robotics, Unmanned Aerial Vehicles (UAVs) have gained significant research interest within the wireless networking research community. As soon as national legislations allow UAVs to fly autonomously, we will see swarms of UAV populating the sky of our smart cities to accomplish different missions: parcel delivery, infrastructure monitoring, event filming, surveillance, tracking, etc. The UAV ecosystem can benefit from 5G/B5G cellular networks, which can be exploited in different ways to enhance UAV communications. Because of the inherent characteristics of UAV pertaining to flexible mobility in 3D space, autonomous operation and intelligent placement, these smart devices cater to wide range of wireless applications and use cases. This work aims at presenting an in-depth exploration of integration synergies between 5G/B5G cellular systems and UAV technology, where the UAV is integrated as a new aerial User Equipment (UE) to already deployed cellular networks. In this integration, the UAVs perform the role of flying users within cellular coverage, thus they are termed as cellular-connected UAVs. The main focus of this work is to present an extensive study of integration challenges along with key 5G/B5G technological innovations and ongoing efforts in design prototyping and field trials corroborating cellular-connected UAVs. This study highlights recent progress updates with respect to 3GPP standardization and emphasizes socio-economic concerns that must be accounted before successful adoption of this promising technology. Various open problems paving the path to future research opportunities are also discussed.}
}
@article{BAYRAKTAR20201,
title = {A low-cost UAV framework towards ornamental plant detection and counting in the wild},
journal = {ISPRS Journal of Photogrammetry and Remote Sensing},
volume = {167},
pages = {1-11},
year = {2020},
issn = {0924-2716},
doi = {https://doi.org/10.1016/j.isprsjprs.2020.06.012},
url = {https://www.sciencedirect.com/science/article/pii/S0924271620301696},
author = {Ertugrul Bayraktar and Muhammed Enes Basarkan and Numan Celebi},
keywords = {Object counting, Plant detection, Remote sensing, Aerial imagery, Geometrical relations},
abstract = {Object detection still keeps its role as one of the fundamental challenges within the computer vision territory. In particular, achieving satisfying results concerning object detection from outdoor images occupies a considerable space. In this study, in addition to comparing handcrafted feature detector/descriptor performance with deep learning methods over ornamental plant images at the outdoor, we propose a framework to improve the detection of these plants. Firstly, we take query images in the RGB format from the onboard UAV camera. Secondly, our model classifies the scene as a planting or an urban area. Thirdly, if the images are from planting area, thirdly, we filter the field according to the color and acquire only the green parts. Lastly, we feed the object detector model with the filtered area and obtain the category and localization of the plants as a result. In parallel, we also estimate the number of interested plants using the geometrical relations and predefined average plant size, then we verify the outputs of the object detector with this results. The conducted experiments show that deep learning based object detection methods overtake conventional feature detector/descriptor techniques in terms of accuracy, recall, precision, and sensitivity rates. The field classifier model, VGGNet, achieves a 98.17% accuracy for this task, whilst YoloV3 achieves 91.6% accuracy with 0.12 IOU for object detection as the best method. The proposed framework also improves the overall performance of these algorithms by 1.27% for accuracy and 0.023 for IOU. By specifying the limits thoroughly and developing task-dependent approaches, we reveal the great potential of our framework plant detection and counting in the wild consisting of basic image preprocessing techniques, geometrical operations, and deep neural network.}
}
@article{ANDARU2021107255,
title = {The use of UAV remote sensing for observing lava dome emplacement and areas of potential lahar hazards: An example from the 2017–2019 eruption crisis at Mount Agung in Bali},
journal = {Journal of Volcanology and Geothermal Research},
volume = {415},
pages = {107255},
year = {2021},
issn = {0377-0273},
doi = {https://doi.org/10.1016/j.jvolgeores.2021.107255},
url = {https://www.sciencedirect.com/science/article/pii/S0377027321000846},
author = {Ruli Andaru and Jiann-Yeou Rau and Devy Kamil Syahbana and Ardy Setya Prayoga and Heruningtyas Desi Purnamasari},
keywords = {UAV remote sensing, Lava dome emplacement, Mount Agung, Potential lahar hazard, Eruptive crisis},
abstract = {Mount Agung (the highest volcano in Bali, Indonesia) began to erupt on November 21, 2017, after having been dormant for 53 years. More than 100,000 people were evacuated within the hazard zone between September 2017 (when the highest volcanic alert was issued) and early 2018. The eruptions continued until June 2019, accompanied by at least 110 explosions. During the eruptive crisis, the observation of the lava dome's emplacement was essential for mitigating the potential hazard. Details of the lava dome growth, including the volumetric changes and effusion rates, provide valuable information about potential eruption scenarios and lahar depositions. In this paper, the essential role of multi-temporal unmanned aerial vehicle (UAV) images in the monitoring of Mt. Agung's lava dome, and in determining the areas of potential lahar hazards during the crisis between 2017 and 2019 is described. A fixed-wing UAV was launched outside the hazard zone to photograph the lava dome on five occasions. Image enhancement, machine learning, and photogrammetry were combined to improve image quality, remove point clouds outliers, and generate digital terrain models (DTMs) and orthoimages. The analysis of the obtained DTMs and orthoimages resulted in qualitative and quantitative data highlighting the changes inside the crater and on the surrounding slopes. These results reveal that, from November 25 to December 16, 2017, the lava dome grew vertically by 126 m and reached a volume of 26.86 ± 0.64 × 106 m3. In addition, its surface experienced a maximal uplift of approximately 52 m until July 2019 with the emergence of a new dome with a volume estimated at 9.52 ± 0.086 × 106 m3. The difference between the DTMs of 2017 and 2019 reveals the total volume of erupted material (886,100 ± 8000 m3) that was deposited on the surrounding slopes. According to the lahar inundation simulation, the deposited material may cause dangerous lahars in 21 drainages, which extend in the north (N), north-east (N-E), south (S), south-east (S-E), and south-west (S-W) sectors of the volcano. This paper presents the use of UAV remote sensing for the production of high-spatial resolution DTMs, which can be used to both observe the emplacement of a lava dome, and to identify areas with potential lahar risk during a volcano crisis.}
}
@article{ZHANG2021107760,
title = {Visual place recognition: A survey from deep learning perspective},
journal = {Pattern Recognition},
volume = {113},
pages = {107760},
year = {2021},
issn = {0031-3203},
doi = {https://doi.org/10.1016/j.patcog.2020.107760},
url = {https://www.sciencedirect.com/science/article/pii/S003132032030563X},
author = {Xiwu Zhang and Lei Wang and Yan Su},
keywords = {Visual place recognition, Deep learning, Visual SLAM, Survey},
abstract = {Visual place recognition has attracted widespread research interest in multiple fields such as computer vision and robotics. Recently, researchers have employed advanced deep learning techniques to tackle this problem. While an increasing number of studies have proposed novel place recognition methods based on deep learning, few of them has provided a whole picture about how and to what extent deep learning has been utilized for this issue. In this paper, by delving into over 200 references, we present a comprehensive survey that covers various aspects of place recognition from deep learning perspective. We first present a brief introduction of deep learning and discuss its opportunities for recognizing places. After that, we focus on existing approaches built upon convolutional neural networks, including off-the-shelf and specifically designed models as well as novel image representations. We also discuss challenging problems in place recognition and present an extensive review of the corresponding datasets. To explore the future directions, we describe open issues and some new tools, for instance, generative adversarial networks, semantic scene understanding and multi-modality feature learning for this research topic. Finally, a conclusion is drawn for this paper.}
}
@article{SU2018157,
title = {Wheat yellow rust monitoring by learning from multispectral UAV aerial imagery},
journal = {Computers and Electronics in Agriculture},
volume = {155},
pages = {157-166},
year = {2018},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2018.10.017},
url = {https://www.sciencedirect.com/science/article/pii/S0168169918312584},
author = {Jinya Su and Cunjia Liu and Matthew Coombes and Xiaoping Hu and Conghao Wang and Xiangming Xu and Qingdong Li and Lei Guo and Wen-Hua Chen},
keywords = {Wheat yellow rust, Multispectral image, Spectral vegetation index (SVI), Unmanned Aerial Vehicle (UAV), Random forest},
abstract = {The use of a low-cost five-band multispectral camera (RedEdge, MicaSense, USA) and a low-altitude airborne platform is investigated for the detection of plant stress caused by yellow rust disease in winter wheat for sustainable agriculture. The research is mainly focused on: (i) determining whether or not healthy and yellow rust infected wheat plants can be discriminated; (ii) selecting spectral band and Spectral Vegetation Index (SVI) with a strong discriminating capability; (iii) developing a low-cost yellow rust monitoring system for use at farmland scales. An experiment was carefully designed by infecting winter wheat with different levels of yellow rust inoculum, where aerial multispectral images under different developmental stages of yellow rust were captured by an Unmanned Aerial Vehicle at an altitude of 16–24 m with a ground resolution of 1–1.5 cm/pixel. An automated yellow rust detection system is developed by learning (via random forest classifier) from labelled UAV aerial multispectral imagery. Experimental results indicate that: (i) good classification performance (with an average Precision, Recall and Accuracy of 89.2%, 89.4% and 89.3%) was achieved by the developed yellow rust monitoring at a diseased stage (45 days after inoculation); (ii) the top three SVIs for separating healthy and yellow rust infected wheat plants are RVI, NDVI and OSAVI; while the top two spectral bands are NIR and Red. The learnt system was also applied to the whole farmland of interest with a promising monitoring result. It is anticipated that this study by seamlessly integrating low-cost multispectral camera, low-altitude UAV platform and machine learning techniques paves the way for yellow rust monitoring at farmland scales.}
}
@article{KAMILARIS201870,
title = {Deep learning in agriculture: A survey},
journal = {Computers and Electronics in Agriculture},
volume = {147},
pages = {70-90},
year = {2018},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2018.02.016},
url = {https://www.sciencedirect.com/science/article/pii/S0168169917308803},
author = {Andreas Kamilaris and Francesc X. Prenafeta-Boldú},
keywords = {Deep learning, Agriculture, Survey, Convolutional Neural Networks, Recurrent Neural Networks, Smart farming, Food systems},
abstract = {Deep learning constitutes a recent, modern technique for image processing and data analysis, with promising results and large potential. As deep learning has been successfully applied in various domains, it has recently entered also the domain of agriculture. In this paper, we perform a survey of 40 research efforts that employ deep learning techniques, applied to various agricultural and food production challenges. We examine the particular agricultural problems under study, the specific models and frameworks employed, the sources, nature and pre-processing of data used, and the overall performance achieved according to the metrics used at each work under study. Moreover, we study comparisons of deep learning with other existing popular techniques, in respect to differences in classification or regression performance. Our findings indicate that deep learning provides high accuracy, outperforming existing commonly used image processing techniques.}
}
@article{WU2020124,
title = {Densely pyramidal residual network for UAV-based railway images dehazing},
journal = {Neurocomputing},
volume = {371},
pages = {124-136},
year = {2020},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2019.06.076},
url = {https://www.sciencedirect.com/science/article/pii/S0925231219309841},
author = {Yunpeng Wu and Yong Qin and Zhipeng Wang and Xiaoping Ma and Zhiwei Cao},
keywords = {Images dehazing, UAV images degradation, Railway inspection, Image recognition, Densely residual network, SSIM},
abstract = {On purpose of aiding detection and recognition for railway infrastructure and dramatic changes in the environment around railways, visual inspection based on unmanned aerial vehicle (UAV) images is a highlight. However, UAV images often suffer from degradation for fog or haze, which limits the inspection efficiency. Most existing methods depend on a suboptimal two-step network with much more redundant procedures where transmission map and atmospheric light are estimated at first, and then haze-free images can be acquired using a dehazing model. This paper presents a novel end-to-end network for UAV-based railway images dehazing, and focuses on two key issues: network architecture and loss function. With regards to the first aspect, based on a pyramidal network structure, densely pyramidal residual network (DPRnet) consists of dense residual block and enhanced residual blocks, which heavily exploits the feature maps of all preceding layers and considerably increased depth at different scale, respectively. With regards to the second, a new loss function introducing structural similarity index is proposed to preserve more structural information, thereby restore the appealing perceptual quality of the hazy images. Finally, quantitative and qualitative evaluations illustrate that the DPRnet achieves better performance over the classic methods, yet remains efficient and convenient.}
}
@article{CHEN2021101205,
title = {Bottom-up image detection of water channel slope damages based on superpixel segmentation and support vector machine},
journal = {Advanced Engineering Informatics},
volume = {47},
pages = {101205},
year = {2021},
issn = {1474-0346},
doi = {https://doi.org/10.1016/j.aei.2020.101205},
url = {https://www.sciencedirect.com/science/article/pii/S1474034620301749},
author = {Junjie Chen and Donghai Liu},
keywords = {Mega infrastructure, Image detection, Unmanned aerial vehicles (UAV), Slope damages, Machine learning, Superpixel segmentation},
abstract = {The operation of water supply channels is threatened by the occasionally occurred slope damages. Timely detection of their occurrence is critical for the rapid enforcement of mitigation measures. However, current practices based on routine inspection and structural heath monitoring are inefficient, laborious and tend to be biased. As an attempt to address the limitations, this paper proposes a bottom-up image detection approach for slope damages, which includes four steps, i.e. superpixel segmentation, feature handcrafting, superpixel classification based on support vector machine (SVM), and slope damage recognition. The approach employs a bottom-up strategy to infer the upper-level slope condition from the classification results of individual superpixels in the bottom level. Experiments were conducted to demonstrate the effectiveness of the approach. The handcrafted feature “LBP + HSV” was demonstrated to be effective in characterizing the image features of slope damages. An SVM model with “LBP + HSV” as input can reliably identify the slope condition in superpixels. Based on the SVM model, the bottom-up strategy achieved high recognition performance, of which the overall accuracy can be up to 91.7%. The proposed approach has potential to facilitate the early and comprehensive awareness of slope damages along the entire route of water channel by the integration with unmanned aerial vehicles.}
}
@article{GRUNBLATT2022102,
title = {A distributed antenna orientation solution for optimizing communications in a fleet of UAVs},
journal = {Computer Communications},
volume = {181},
pages = {102-115},
year = {2022},
issn = {0140-3664},
doi = {https://doi.org/10.1016/j.comcom.2021.09.020},
url = {https://www.sciencedirect.com/science/article/pii/S0140366421003571},
author = {Rémy Grünblatt and Isabelle {Guérin Lassous} and Olivier Simonin},
keywords = {UAV, Wireless, Mobility, Simulation, ns-3},
abstract = {In this article, we describe how a fleet of unmanned aerial vehicles (UAVs) can optimize communication performances by having its members independently change their orientations. This distributed solution, based on a hill-climbing approach, relies on information available locally at each node, namely the reception power of the received frames. The solution is evaluated using the ns–3 network simulator, whose source code is modified to be able to deal with non-isotropic antennas in the context of Wi-Fi networks, as well as simulate angular movements. As isotropic antennas are only theoretical objects, this step is mandatory in order to increase the realism of network simulations. The results, obtained using realistic antenna models, highlight that controlled mobility, in particular controlled orientation needs to be considered in order for UAV networks to provide better performances.}
}
@article{PSIROUKIS2021100002,
title = {Monitoring of free-range rabbits using aerial thermal imaging},
journal = {Smart Agricultural Technology},
volume = {1},
pages = {100002},
year = {2021},
issn = {2772-3755},
doi = {https://doi.org/10.1016/j.atech.2021.100002},
url = {https://www.sciencedirect.com/science/article/pii/S2772375521000022},
author = {Vasilis Psiroukis and Ioannis Malounas and Nikolaos Mylonas and Konstantinos-Elenos Grivakis and Spyros Fountas and Ioannis Hadjigeorgiou},
keywords = {UAV, Thermal_images, Deep_learning, Animal_population, Animal_detection, Free-range_rabbits},
abstract = {Unmanned Aerial Vehicles (UAV) imagery is a mature technology, which has found use in a number of applications in agriculture and environmental sciences. However, its application for monitoring and classification of livestock and wild animals has not yet been developed. This study presents a robust methodology to count wild and free-range rabbits and monitor their population. The aims of this study were to 1) test the capacity of the methodology in counting small nocturnal animals such as rabbits in the field, 2) assess the rabbit's density at different sites and different periods of the year and 3) record the temporal pattern of rabbits’ activity during the night hours, with the overall aim to provide a reliable and accurate tool in management studies. For this purpose, a UAV equipped with a thermal camera was used to perform night flights on the island of Lemnos, scanning selected sites and collecting aerial nadir thermal imagery data of the ground. The derived thermal images were analysed using deep learning techniques towards counting the individual animals in each image and the results were compared with manual counting conducted by a researcher. The results revealed that the deep learning approach for automated counting and rabbit recognition overall achieved comparable results to physical counting, with the final model yielding an F1-score of 0.87. However, there were differences between seasons in the methods’ accuracy. This method could be a helpful tool in assessing populations of small nocturnal animals and other free-range livestock animals.}
}
@article{GEVAERT2018106,
title = {A deep learning approach to DTM extraction from imagery using rule-based training labels},
journal = {ISPRS Journal of Photogrammetry and Remote Sensing},
volume = {142},
pages = {106-123},
year = {2018},
issn = {0924-2716},
doi = {https://doi.org/10.1016/j.isprsjprs.2018.06.001},
url = {https://www.sciencedirect.com/science/article/pii/S0924271618301643},
author = {C.M. Gevaert and C. Persello and F. Nex and G. Vosselman},
keywords = {Digital Terrain Models (DTM), Unmanned Aerial Vehicles (UAV), Aerial photogrammetry, Deep learning, Fully Convolutional Networks (FCN)},
abstract = {Existing algorithms for Digital Terrain Model (DTM) extraction still face difficulties due to data outliers and geometric ambiguities in the scene such as contiguous off-ground areas or sloped environments. We postulate that in such challenging cases, the radiometric information contained in aerial imagery may be leveraged to distinguish between ground and off-ground objects. We propose a method for DTM extraction from imagery which first applies morphological filters to the Digital Surface Model to obtain candidate ground and off-ground training samples. These samples are used to train a Fully Convolutional Network (FCN) in the second step, which can then be used to identify ground samples for the entire dataset. The proposed method harnesses the power of state-of-the-art deep learning methods, while showing how they can be adapted to the application of DTM extraction by (i) automatically selecting and labelling dataset-specific samples which can be used to train the network, and (ii) adapting the network architecture to consider a larger surface area without unnecessarily increasing the computational burden. The method is successfully tested on four datasets, indicating that the automatic labelling strategy can achieve an accuracy which is comparable to the use of manually labelled training samples. Furthermore, we demonstrate that the proposed method outperforms two reference DTM extraction algorithms in challenging areas.}
}
@article{ELAVARASAN2018257,
title = {Forecasting yield by integrating agrarian factors and machine learning models: A survey},
journal = {Computers and Electronics in Agriculture},
volume = {155},
pages = {257-282},
year = {2018},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2018.10.024},
url = {https://www.sciencedirect.com/science/article/pii/S0168169918311529},
author = {Dhivya Elavarasan and Durai Raj Vincent and Vishal Sharma and Albert Y. Zomaya and Kathiravan Srinivasan},
keywords = {Climatic parameters, Decision trees, Random forests, Support vector machines, Bayesian networks, Artificial neural networks, Markov chain process, K-means clustering, Expectation maximization, Density-Based Spatial Clustering for Applications with noise (DBSCAN), Apriori algorithm},
abstract = {The advancement in science and technology has led to a substantial amount of data from various fields of agriculture to be incremented in the public domain. Hence a desideratum arises from the investigation of the available data and integrating them with a process like a crop improvement, yield prediction, crop disease analysis, identifying water stress, and so on. Computing techniques like Machine learning is a new advent for the analysis and resoluteness of these intricate issues. Various analytical models like Decision Trees, Random Forests, Support Vector Machines, Bayesian Networks, and Artificial Neural Networks, and so on, have been utilized for engendering the models and analyze the results. These methods enable to analyze soil, climate, and water regime which are significantly involved in crop growth and precision farming. This survey incorporates an overview of some of the existing supervised and unsupervised machine learning models associated with the crop yield in literature. Moreover, this survey compares one approach with other using various error measures like Root Mean Square Error (RMSE), Relative Root Mean Square Error (RRMSE), Mean Absolute Error (MAE), and Coefficient of Determination (R2).}
}
@article{ZHOU2020105576,
title = {Classification of soybean leaf wilting due to drought stress using UAV-based imagery},
journal = {Computers and Electronics in Agriculture},
volume = {175},
pages = {105576},
year = {2020},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2020.105576},
url = {https://www.sciencedirect.com/science/article/pii/S0168169920307195},
author = {Jing Zhou and Jianfeng Zhou and Heng Ye and Md Liakat Ali and Henry T. Nguyen and Pengyin Chen},
keywords = {Soybean breeding, Slow-wilting, Drought tolerance, UAV-based imagery, Machine learning},
abstract = {Drought stress is one of the major limiting factors in soybean growth and productivity. Canopy leaf wilting (i.e. fast- and slow-wilting) is considered as an important visible symptom of soybeans under drought conditions. In soybean breeding programs, genotypes with the slow-wilting trait have been identified as drought-tolerant cultivars. Traditional method measures canopy leaf wilting traits using visual observations, which is subjective and time-consuming. Recent developments of field high-throughput phenotyping technology using Unmanned Aerial Vehicle (UAV)-based imagery have shown great potential in quantifying crop traits and detecting crop responses to abiotic and biotic stresses. The goal of this study was to investigate the potential use of UAV-based imagery in classifying soybean genotypes with fast- and slow-wilting traits. A UAV imaging system consisting of an RGB (Red-Green-Blue) camera, an infrared thermal camera, and a multispectral camera was used to collect imagery data of 116 soybean genotypes planted in a rain-fed breeding field at the reproductive stage. Visual-based canopy wilting scores were collected by breeders in the same day of imagery data collection. Seven image features were extracted, namely normalized difference vegetation index (NDVI), green-based NDVI (gNDVI), temperature, color hue, color saturation, canopy size and plant height for quantifying canopy wilting trait. Results show that all image features significantly (p-value < 0.01) correlated with soybean yield under drought. A Support Vector Machine model was developed to classify the two wilting traits using the images features and achieved an average classification accuracy of 0.8 with the highest one of 0.9. Slow-wilting genotypes had significantly (p-value < 0.01) higher NDVI, hue, saturation, canopy size, height, and lower temperature than fast-wilting genotypes. The significant broad-sense heritability (H2) indicates the dominating genetic factors in the variations of the image features. The study demonstrates the good potential use of UAV-based imagery technologies in the selection of soybeans genotypes with drought tolerance.}
}
@article{ZHEN20192706,
title = {Distributed intelligent self-organized mission planning of multi-UAV for dynamic targets cooperative search-attack},
journal = {Chinese Journal of Aeronautics},
volume = {32},
number = {12},
pages = {2706-2716},
year = {2019},
issn = {1000-9361},
doi = {https://doi.org/10.1016/j.cja.2019.05.012},
url = {https://www.sciencedirect.com/science/article/pii/S1000936119302456},
author = {Ziyang ZHEN and Ping ZHU and Yixuan XUE and Yuxuan JI},
keywords = {Ant Colony Optimization (ACO), Cooperative control, Mission planning, Search-attack integration, Self-organized, Unmanned Aerial Vehicle (UAV)},
abstract = {This article studies the cooperative search-attack mission problem with dynamic targets and threats, and presents a Distributed Intelligent Self-Organized Mission Planning (DISOMP) algorithm for multiple Unmanned Aerial Vehicles (multi-UAV). The DISOMP algorithm can be divided into four modules: a search module designed based on the distributed Ant Colony Optimization (ACO) algorithm, an attack module designed based on the Parallel Approach (PA) scheme, a threat avoidance module designed based on the Dubins Curve (DC) and a communication module designed for information exchange among the multi-UAV system and the dynamic environment. A series of simulations of multi-UAV searching and attacking the moving targets are carried out, in which the search-attack mission completeness, execution efficiency and system suitability of the DISOMP algorithm are analyzed. The simulation results exhibit that the DISOMP algorithm based on online distributed down-top strategy is characterized by good flexibility, scalability and adaptability, in the dynamic targets searching and attacking problem.}
}
@article{BAEK201976,
title = {UAV-based measurements of spatio-temporal concentration distributions of fluorescent tracers in open channel flows},
journal = {Advances in Water Resources},
volume = {127},
pages = {76-88},
year = {2019},
issn = {0309-1708},
doi = {https://doi.org/10.1016/j.advwatres.2019.03.007},
url = {https://www.sciencedirect.com/science/article/pii/S0309170818308637},
author = {Donghae Baek and Il Won Seo and Jun Song Kim and Jonathan M. Nelson},
keywords = {Pollutant mixing, Tracer test, Spatio-temporal distribution,  measurement, Remote measurement, Artificial neural network},
abstract = {A new method of unmanned aerial vehicle (UAV)-based tracer tests using RGB (red, green, blue) images was developed in order to acquire the spatio-temporal concentration distribution of tracer clouds in open channel flows. Tracer tests using Rhodamine WT were conducted to collect the RGB images using a commercial digital camera mounted on a UAV, and the concentration of Rhodamine WT using in-situ fluorometric probes. The correlation analysis showed that the in-situ measured concentrations of Rhodamine WT were strongly correlated with the digital number (DN) of the RGB images, even though the response of DN to the concentration was spatially heterogeneous. The empirical relationship between the DN values and the Rhodamine WT concentration data was estimated using artificial neural network (ANN) models. The trained ANN models, which consider the effect of water depth and river bed, accurately retrieved the detailed spatio-temporal concentration distributions of all study areas that had an R2 higher than 0.9. The acquired spatio-temporal concentration distributions by the proposed method based on the UAV images gave general as well as detailed views of the tracer cloud moving dynamically in open channel flows that cannot be easily observed using conventional in-situ measurements.}
}
@article{REN2021107709,
title = {A three-step classification framework to handle complex data distribution for radar UAV detection},
journal = {Pattern Recognition},
volume = {111},
pages = {107709},
year = {2021},
issn = {0031-3203},
doi = {https://doi.org/10.1016/j.patcog.2020.107709},
url = {https://www.sciencedirect.com/science/article/pii/S0031320320305124},
author = {Jianfeng Ren and Xudong Jiang},
keywords = {Radar UAV detection, Micro-Doppler signature, Greedy subspace clustering, Multi-Gaussian subspace reliability analysis, Subspace fusion},
abstract = {Unmanned aerial vehicles (UAVs) have been used in a wide range of applications and become an increasingly important radar target. To better model radar data and to tackle the curse of dimensionality, a three-step classification framework is proposed for UAV detection. First we propose to utilize the greedy subspace clustering to handle potential outliers and the complex sample distribution of radar data. Parameters of the resulting multi-Gaussian model, especially the covariance matrices, could not be reliably estimated due to insufficient training samples and the high dimensionality. Thus, in the second step, a multi-Gaussian subspace reliability analysis is proposed to handle the unreliable feature dimensions of these covariance matrices. To address the challenges of classifying samples using the complex multi-Gaussian model and to fuse the distances of a sample to different clusters at different dimensionalities, a subspace-fusion scheme is proposed in the third step. The proposed approach is validated on a large benchmark dataset, which significantly outperforms the state-of-the-art approaches.}
}
@article{TENG2021310,
title = {A low-cost physical location discovery scheme for large-scale Internet of Things in smart city through joint use of vehicles and UAVs},
journal = {Future Generation Computer Systems},
volume = {118},
pages = {310-326},
year = {2021},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2021.01.032},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X2100042X},
author = {Haojun Teng and Mianxiong Dong and Yuxin Liu and Wang Tian and Xuxun Liu},
keywords = {Smart city, Internet of Things, Physical location discovery, Unmanned aerial vehicle, Mobile vehicles, Low cost},
abstract = {With the development of Information and Communication Technology (ICT), the construction of the smart city came into being. Compared with the traditional city, a smart city can reduce resource consumption, improve energy efficiency, reduce environmental pollution, reduce traffic congestion, reduce potential safety hazards, improve the quality of life of citizens, etc. In order to collect a large amount of data to provide accurate decision-making recommendations for the management of smart cities, a large-scale Internet of Things (IoT) system needs to be built as the basis. For most applications in smart cities, it is very important to obtain the physical location information of the data during the data collection. However, it is a challenging issue for most sensor devices in the IoT system, because sensor devices are hard to equip positioning equipment as limited by cost. To tackle this, a Low-Cost Physical Locations Discovery (LCPLD) Scheme is proposed in this paper. In LCPLD scheme, mobile vehicles and unmanned aerial vehicles (UAVs) are used for physical location discovery on the wireless sensor networks which are the important component of the IoT system in a smart city. In order to further reduce cost, we propose a task application mechanism to reduce the cost of vehicle broadcasting and the Adaptive UAV Flight Path Planning (AUPPP) algorithm to reduce UAV flight cost. In order to reduce localization error, the Large Error Rejection (LER) algorithm and the UAV Same Position Broadcast Repeat (USPBR) algorithm are proposed in this paper. After simulation experiments based on real vehicle driving data, the experimental results prove the effectiveness of the proposed scheme: Compared with the comparison scheme, the LCPLD scheme proposed has a cost reduction of 16.58% ∼19.88%, an average reduction of 78.80% in positioning error, and an average reduction of 99.88% in the variance of positioning error.}
}
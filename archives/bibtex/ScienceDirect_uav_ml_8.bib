@article{GAO2021106447,
title = {Cubature rule-based distributed optimal fusion with identification and prediction of kinematic model error for integrated UAV navigation},
journal = {Aerospace Science and Technology},
volume = {109},
pages = {106447},
year = {2021},
issn = {1270-9638},
doi = {https://doi.org/10.1016/j.ast.2020.106447},
url = {https://www.sciencedirect.com/science/article/pii/S1270963820311299},
author = {Bingbing Gao and Gaoge Hu and Yongmin Zhong and Xinhe Zhu},
keywords = {Cubature rule, Distributed optimal fusion, Kinematic model error, Integrated MIMU/GNSS/CNS, UAV navigation},
abstract = {Integrated MIMU/GNSS/CNS (micro-electro-mechanical system-based inertial measurement unit/global navigation satellite system/celestial navigation system) is a promising strategy for UAV (unmanned aerial vehicle) navigation. However, given its strong nonlinearity and involvement of kinematic model error, integrated MIMU/GNSS/CNS UAV navigation presents the difficulty in achieving optimal navigation solutions. This paper presents a method of cubature rule-based distributed optimal fusion combined with identification and prediction of kinematic model error to address the above problem in nonlinear integrated MIMU/GNSS/CNS. This method is in a distributed structure to simultaneously process observations from integrated MIMU/GNSS and MIMU/CNS subsystems for the subsequent global fusion. A theory for identification of kinematic model error is established using the concept of Mahalanobis distance. Further, the standard cubature Kalman filter is modified with the model prediction filter to serve as the local filters in integrated MIMU/GNSS and MIMU/CNS subsystems to hinder the disturbance of kinematic model error. Based on the above, an optimal fusion technique is developed to fuse the filtering results of each subsystem for achieving globally optimal state estimation in the sense of mean square error. Simulations and experimental results as well as comparison analysis demonstrate that the proposed distributed optimal fusion method can effectively identify and predict kinematic model error and further achieve globally optimal fusion results, leading to improved performance for integrated MIMU/GNSS/CNS UAV navigation.}
}
@article{GHORBANI2021117884,
title = {Monitoring offshore oil pollution using multi-class convolutional neural networks},
journal = {Environmental Pollution},
volume = {289},
pages = {117884},
year = {2021},
issn = {0269-7491},
doi = {https://doi.org/10.1016/j.envpol.2021.117884},
url = {https://www.sciencedirect.com/science/article/pii/S0269749121014664},
author = {Zahra Ghorbani and Amir H. Behzadan},
keywords = {Convolutional neural networks, Drone, Image classification, Instance segmentation, Object detection, Oil pollution},
abstract = {Oil and gas production operations are a major source of environmental pollution that expose people and habitats in many coastal communities around the world to adverse health effects. Detecting oil spills in a timely and precise manner can help improve the oil spill response process and channel required resources more effectively to affected regions. In this research, convolutional neural networks, a branch of artificial intelligence (AI), are trained on a visual dataset of oil spills containing images from different altitudes and geographical locations. In particular, a VGG16 model is adopted through transfer learning for oil spill classification (i.e., detecting if there is oil spill in an image) with an accuracy of 92%. Next, Mask R–CNN and PSPNet models are used for oil spill segmentation (i.e., pixel-level detection of oil spill boundaries) with a mean intersection over union (IoU) of 49% and 68%, respectively. Lastly, to determine if there is an oil rig or vessel in the vicinity of a detected oil spill and provide a holistic view of the oil spill surroundings, a YOLOv3 model is trained and used, yielding a maximum mean average precision (mAP) of ~71%. Findings of this research can improve the current practices of oil pollution cleanup and predictive maintenance, ultimately leading to more resilient and healthy coastal communities.}
}
@article{DOSSANTOSFERREIRA2019104963,
title = {Unsupervised deep learning and semi-automatic data labeling in weed discrimination},
journal = {Computers and Electronics in Agriculture},
volume = {165},
pages = {104963},
year = {2019},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2019.104963},
url = {https://www.sciencedirect.com/science/article/pii/S0168169919313237},
author = {Alessandro {dos Santos Ferreira} and Daniel Matte Freitas and Gercina Gonçalves {da Silva} and Hemerson Pistori and Marcelo Theophilo Folhes},
keywords = {Deep learning, Unsupervised clustering, Weed discrimination, Semi-automatic labeling},
abstract = {In recent years, supervised Deep Neural Networks have achieved the state-of-the-art in image recognition and this success has spread in many areas. In agricultural field, several researches have been conducted using architectures such as Convolutional Neural Networks. Despite this success, these works are still highly dependent on very time–costly manual data labeling. In contrast to this scenario, Unsupervised Deep Learning has no dependency on data labeling and is targeted as the future of the area, but after a promising start has been obfuscated by the success of supervised networks. Meanwhile, the low-cost of acquisition of field crop imagery using Unnamed Aerial Vehicles could be largely boosted in real-world applications if these images could be annotated without the need for a human specialist. In this work, we tested two recent unsupervised deep clustering algorithms, Joint Unsupervised Learning of Deep Representations and Image Clusters (JULE) and Deep Clustering for Unsupervised Learning of Visual Features (DeepCluster), using two public weed datasets. The first dataset was captured in a soybean plantation in Brazil and discriminates weeds between grass and broadleaf. The second dataset consists of 17,509 labeled images of eight nationally significant weed species native to Australia. We evaluated the purely unsupervised clustering performance using the NMI and Unsupervised Clustering Accuracy metrics and analysed the effects of techniques like data augmentation and transfer learning to improve clustering quality in a broad discussion that can be useful for unsupervised deep clustering in general. We also propose the usage of semi-automatic data labeling which greatly reduces the cost of manual data labeling and can be easily replicated to different datasets. This approach achieved 97% accuracy in discrimination of grass and broadleaf while reducing the number of manual annotations by 100 times, using a custom set of training images, without images labeled using inaccurate clusters.}
}
@article{ULLAH2019425,
title = {UAV-enabled healthcare architecture: Issues and challenges},
journal = {Future Generation Computer Systems},
volume = {97},
pages = {425-432},
year = {2019},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2019.01.028},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X18318247},
author = {Sana Ullah and Ki-Il Kim and Kyong Hoon Kim and Muhammad Imran and Pervez Khan and Eduardo Tovar and Farman Ali},
keywords = {Unmanned Aerial Vehicles, Body Area Network, IoV, Smart healthcare, Industry},
abstract = {Unmanned Aerial Vehicles (UAVs) have great potential to revolutionize the future of automotive, energy, and healthcare sectors by working as wireless relays to improve connectivity with ground networks. They are able to collect and process real-time information by connecting existing network infrastructures including Internet of Medical Things (e.g., Body Area Networks (BANs)) and Internet of Vehicles with clouds or remote servers. In this article, we advocate and promote the notion of employing UAVs as data collectors. To demonstrate practicality of the idea, we propose a UAV-based architecture to communicate with BANs in a reliable and power-efficient manner. The proposed architecture adopts the concept of wakeup-radio based communication between a UAV and multiple BANs. We analyze the performance of the proposed protocol in terms of throughput and delay by allocating different priorities to the hubs or gateways. The proposed architecture may be useful in remote or disaster areas, where BANs have poor or no access to conventional wireless communication infrastructure, and may even assist vehicular networks by monitoring driver’s physiological conditions through BANs. We further highlight open research issues and challenges that are important for developing efficient protocols for UAV-based data collection in smart healthcare systems.}
}
@article{AGRAWAL20201221,
title = {A Novel Controller of Multi-Agent System Navigation and Obstacle Avoidance},
journal = {Procedia Computer Science},
volume = {171},
pages = {1221-1230},
year = {2020},
note = {Third International Conference on Computing and Network Communications (CoCoNet'19)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2020.04.131},
url = {https://www.sciencedirect.com/science/article/pii/S1877050920311091},
author = {Anuj Agrawal and Aniket Gupta and Joyraj Bhowmick and Anurag Singh and Raghava Nallanthighal},
keywords = {Swarm, Unmanned Aerial Vehicles, Formation Control, Multi-agent system, Obstacle Avoidance},
abstract = {This paper presents a method for a minimalistic approach to tackle complex swarm behavior in Unmanned Aerial Vehicles (UAV). Here an extended decentralized consensus-based control of multi-agent system is proposed. The approach comprises three main objectives; Formation Control, Waypoint Following, Static and Dynamic Obstacle Avoidance that is independent of the count of UAVs connected together. The controller’s performance is evaluated in a MATLAB environment and finally validated on a hardware platform in the real-world which demonstrated the effectiveness of the controller and system architecture.}
}
@article{CHOUDHARY201959,
title = {Sustainable and secure trajectories for the military Internet of Drones (IoD) through an efficient Medium Access Control (MAC) protocol},
journal = {Computers & Electrical Engineering},
volume = {74},
pages = {59-73},
year = {2019},
issn = {0045-7906},
doi = {https://doi.org/10.1016/j.compeleceng.2019.01.007},
url = {https://www.sciencedirect.com/science/article/pii/S0045790618321712},
author = {Gaurav Choudhary and Vishal Sharma and Ilsun You},
keywords = {Internet of Drones, UAVs, Trajectory, Security, MAC Protocol, Deep neural networks, Link durations},
abstract = {Internet of Drones (IoD) involves cooperation and policing amongst Unmanned Aerial Vehicles (UAVs) based on waypoints generated through a series of algorithms. The dynamic reconfigurability of conveyances in IoD demands a secure trajectory and channel accessibility which is procurable through an efficient Medium Access Control (MAC) protocol. The majority of existing works considers the security of UAV-trajectories as a part of cryptographic and channel accessibility only, whereas the proposed approach idealizes link stability as one of the essential components for attaining secure trajectories. Furthermore, this paper proposes a deep neural network-based security framework, which embeds an efficient MAC protocol controlled by Macaulay’s duration. The proposed approach fortifies that an extensive control over links provides an adequate duration for enhancing the security aspects of IoD and launching countermeasures against any known cyber attacks.}
}
@article{KARAKOSTAS2020273,
title = {Shot type constraints in UAV cinematography for autonomous target tracking},
journal = {Information Sciences},
volume = {506},
pages = {273-294},
year = {2020},
issn = {0020-0255},
doi = {https://doi.org/10.1016/j.ins.2019.08.011},
url = {https://www.sciencedirect.com/science/article/pii/S0020025519307455},
author = {Iason Karakostas and Ioannis Mademlis and Nikos Nikolaidis and Ioannis Pitas},
keywords = {UAV Cinematography, Shot type, Target tracking, Autonomous drones},
abstract = {During the past years, camera-equipped Unmanned Aerial Vehicles (UAVs) have revolutionized aerial cinematography, allowing easy acquisition of impressive footage. In this context, autonomous functionalities based on machine learning and computer vision modules are gaining ground. During live coverage of outdoor events, an autonomous UAV may visually track and follow a specific target of interest, under a specific desired shot type, mainly adjusted by choosing appropriate focal length and UAV/camera trajectory relative to the target. However, the selected UAV/camera trajectory and the object tracker requirements (which impose limits on the maximum allowable focal length) affect the range of feasible shot types, thus constraining cinematography planning. Therefore, this paper explores the interplay between cinematography and computer vision in the area of autonomous UAV filming. UAV target-tracking trajectories are formalized and geometrically modeled, so as to analytically compute maximum allowable focal length per scenario, to avoid 2D visual tracker failure. Based on this constraint, formulas for estimating the appropriate focal length to achieve the desired shot type in each situation are extracted, so as to determine shot feasibility. Such rules can be embedded into practical UAV intelligent shooting systems, in order to enhance their robustness by facilitating on-the-fly adjustment of the cinematography plan.}
}
@article{LOPEZ2021102274,
title = {A framework for registering UAV-based imagery for crop-tracking in Precision Agriculture},
journal = {International Journal of Applied Earth Observation and Geoinformation},
volume = {97},
pages = {102274},
year = {2021},
issn = {0303-2434},
doi = {https://doi.org/10.1016/j.jag.2020.102274},
url = {https://www.sciencedirect.com/science/article/pii/S030324342030917X},
author = {Alfonso López and Juan M. Jurado and Carlos J. Ogayar and Francisco R. Feito},
keywords = {Image registration, Multispectral imagery, Thermal imagery, Tree recognition},
abstract = {Multiple types of images provide useful information about a crop, but image fusion is still a challenge in Precision Agriculture (PA). We describe a framework which manages a multi-layer registration model of heterogeneous images obtained by an unmanned aerial vehicle (UAV) by proposing pair-to-pair steps through a registration method invariant to intensity differences, allowing us to connect different aerial images with significant differences. Correction of deformed images is treated as a first step to end up with our registration algorithms. These methods conform the base of more advanced systems that combine 2D and spatial information, therefore it represents the link of several types of images. The evaluation shows the flexibility of our framework when dealing with different requirements. Effectiveness of the Enhanced Correlation Coefficient method is proved and thus shown as a suitable method for the registration of heterogeneous images.}
}
@article{CHEN2020103975,
title = {Application of the best evacuation model of deep learning in the design of public structures},
journal = {Image and Vision Computing},
volume = {102},
pages = {103975},
year = {2020},
issn = {0262-8856},
doi = {https://doi.org/10.1016/j.imavis.2020.103975},
url = {https://www.sciencedirect.com/science/article/pii/S0262885620301074},
author = {Yan Chen and Shenjian Hu and He Mao and Wei Deng and Xin Gao},
keywords = {Evacuation, Deep learning, VR video tracking method, YOLO-based recursive neural network model, Simulation},
abstract = {Evacuation behavior is an important factor which must be considered in the design of public structures. With the continuous complexity of structure, more and more factors should be considered in evacuation. The traditional design based on experience may have some limitations in practice. Based on the deep neural network model, the evacuation design simulation for subway station buildings is implemented. VR video tracking technologies such as auxiliary image data pre-training algorithm, tracking sequence pre-training algorithm, and recursive neural network model based on You Only Look Once (YOLO) are introduced. Compared with the convolutional neural network (CNN) model, the classified data set pre-training model, and YOLO algorithm, the accuracy and training speed of the model algorithm are verified. In simulation, the Zhujiang New Town Station in Guangzhou is taken as the object. The initial evacuation test point is selected according to the structure of the subway platform, and the test personnel are selected according to the test requirements. The average evacuation time and the average satisfaction score of the testers under the influence factors such as gender, age, subway frequency, and familiarity with VR equipment, as well as under the initial starting points of different evacuation tests. The results show that the accuracy of the algorithm is lower than that of the CNN, but the training speed is faster. The accuracy of the model based on YOLO recurrent neural network is the highest. Although the training speed is 19 ms, which is higher than other models, the overall performance is the best. Differences in factors such as gender, age, frequency of subway ride, and familiarity with VR devices will result in different differences in average evacuation time and average satisfaction score. When the platform center is used as the initial evacuation point, the average evacuation time is the shortest, and the average satisfaction score of the testers is the highest. In conclusion, through VR video tracking technology, the actual situation of subway station buildings can be well simulated, and further design schemes can be made according to the simulated situation, which has practical reference significance.}
}
@article{WANG2021126958,
title = {Urban forest monitoring based on multiple features at the single tree scale by UAV},
journal = {Urban Forestry & Urban Greening},
volume = {58},
pages = {126958},
year = {2021},
issn = {1618-8667},
doi = {https://doi.org/10.1016/j.ufug.2020.126958},
url = {https://www.sciencedirect.com/science/article/pii/S1618866720307755},
author = {Xiaofeng Wang and Yi Wang and Chaowei Zhou and Lichang Yin and Xiaoming Feng},
keywords = {Aerial photogrammetry, Multiple features, Random forest classification, Single tree segmentation, Tree height, UAV},
abstract = {Fine monitoring of tree species is essential to supporting the urban forest management. Data acquired from unmanned aerial vehicles (UAVs) not only have very high spatiotemporal resolution, but also contain the vertical structure of trees which is important in the fine recognition of vegetation types. However, the research of combining multi-dimensional features in classification is still very limited. In our study, we extracted the spectral information, vegetation morphological parameters, texture information, and vegetation indexes based on UAV ultrahigh resolution images to build an object-oriented-based random forest (RF) classifier at the single tree scale. Establishing 6 classification scenarios that combines multiple data sources, multi-dimensional features, and multiple classification algorithms, our results show that: (1) UAV images can effectively detect surface fragments. The accuracy of RF classification based on UAV multiple features was high at 91.3 %, which was 20.5 % higher than the results by using high-resolution Baidu maps; (2) for mapping the tree species of urban forest, tree morphological characteristics, texture information, and vegetation indexes improved the classification accuracy by 2.9 %, 1.9 %, and 7.1 %, respectively, resulting in meaningful improvement of classification effects; and (3) the accuracy of RF classification based on UAV data was much higher than the maximum likelihood classification (MLC) results. Compared with the latter, the former can effectively avoid salt and pepper noise. The workflow of information extraction and urban forest classification based on UAV images in this paper yields high performance, which has important significance as a reference for future relevant research.}
}
@article{WU2019151,
title = {TDPP-Net: Achieving three-dimensional path planning via a deep neural network architecture},
journal = {Neurocomputing},
volume = {357},
pages = {151-162},
year = {2019},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2019.05.001},
url = {https://www.sciencedirect.com/science/article/pii/S092523121930606X},
author = {Keyu Wu and Mahdi {Abolfazli Esfahani} and Shenghai Yuan and Han Wang},
keywords = {Deep neural network, Path planning, Deep learning, Real-time autonomous navigation, Autonomous unmanned vehicles},
abstract = {Path planning plays a significant role in autonomous navigation for robots in complex environments and hence has been extensively studied for decades. However, the computational time of most existing methods are dependent on the scale and complexity of environment, which leads to the compromise between time efficiency and path quality. To tackle this challenge, deep neural network based (DNN-based) planning methods have been actively explored. However, despite the success of DNN-based 2D planner, 3D path planning, which is a significant primitive for quite a few autonomous robots, is rarely handled by DNNs. In this paper, we propose a novel end-to-end neural network architecture named Three-Dimensional Path Planning Network (TDPP-Net) to realize DNN-based 3D path planning. Embedding the action decomposition and composition concept, our network predicts 3D actions merely through 2D convolutional neural networks (CNNs). Besides, the computational time of TDPP-Net is almost independent of environmental scale and complexity for each action prediction. The experimental results demonstrate that our approach exhibits remarkable performance for planning real-time paths in unseen 3D environments.}
}
@article{ZHEN2019105336,
title = {Multivariable adaptive control based consensus flight control system for UAVs formation},
journal = {Aerospace Science and Technology},
volume = {93},
pages = {105336},
year = {2019},
issn = {1270-9638},
doi = {https://doi.org/10.1016/j.ast.2019.105336},
url = {https://www.sciencedirect.com/science/article/pii/S1270963816313979},
author = {Ziyang Zhen and Gang Tao and Yue Xu and Ge Song},
keywords = {Multivariable adaptive control, Consensus flight control, UAVs formation},
abstract = {Formation flight contributes to improving the attack, reconnaissance and survival ability of the multiple unmanned aerial vehicles (UAVs). This paper studies a multivariable adaptive control based consensus flight method for UAVs formation. A majority of existing research is focused on the leader-following consensus problem assuming that only the parameters of followers are uncertain. However, they do not consider the leader dynamic uncertainty and the unknown external disturbances. Therefore, this paper addresses the problem of the UAVs consensus flight control with parametric uncertainties and unknown external disturbances for both the leader and follower. A multivariable model reference adaptive control (MRAC) based consensus flight control scheme is designed for UAVs formation, which enables the follower UAV to track the leader UAV. The stability of the multivariable MRAC based consensus flight control system is analyzed. Simulation results show that the proposed adaptive consensus flight control scheme has stronger robustness and adaptivity than the fixed control scheme.}
}
@article{CHENG2018155,
title = {Automated detection of sewer pipe defects in closed-circuit television images using deep learning techniques},
journal = {Automation in Construction},
volume = {95},
pages = {155-171},
year = {2018},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2018.08.006},
url = {https://www.sciencedirect.com/science/article/pii/S0926580518303273},
author = {Jack C.P. Cheng and Mingzhu Wang},
keywords = {Sewer pipe inspection, Defect detection, Deep learning, Computer vision, Faster region-based convolutional neural network (faster R-CNN), Object detection},
abstract = {Sanitary sewer systems are designed to collect and transport sanitary wastewater and stormwater. Pipe inspection is important in identifying both the type and location of pipe defects to maintain the normal sewer operations. Closed-circuit television (CCTV) has been commonly utilized for sewer pipe inspection. Currently, interpretation of the CCTV images is mostly conducted manually to identify the defect type and location, which is time-consuming, labor-intensive and inaccurate. Conventional computer vision techniques are explored for automated interpretation of CCTV images, but such process requires large amount of image pre-processing and the design of complex feature extractor for certain cases. In this study, an automated approach is developed for detecting sewer pipe defects based on a deep learning technique namely faster region-based convolutional neural network (faster R-CNN). The detection model is trained using 3000 images collected from CCTV inspection videos of sewer pipes. After training, the model is evaluated in terms of detection accuracy and computation cost using mean average precision (mAP), missing rate, detection speed and training time. The proposed approach is demonstrated to be applicable for detecting sewer pipe defects accurately with high accuracy and fast speed. In addition, a new model is constructed and several hyper-parameters are adjusted to study the influential factors of the proposed approach. The experiment results demonstrate that dataset size, initialization network type and training mode, and network hyper-parameters have influence on model performance. Specifically, the increase of dataset size and convolutional layers can improve the model accuracy. The adjustment of hyper-parameters such as filter dimensions or stride values contributes to higher detection accuracy, achieving an mAP of 83%. The study lays the foundation for applying deep learning techniques in sewer pipe defect detection as well as addressing similar issues for construction and facility management.}
}
@article{LUO20202815,
title = {Comparison of machine learning algorithms for mapping mango plantations based on Gaofen-1 imagery},
journal = {Journal of Integrative Agriculture},
volume = {19},
number = {11},
pages = {2815-2828},
year = {2020},
issn = {2095-3119},
doi = {https://doi.org/10.1016/S2095-3119(20)63208-7},
url = {https://www.sciencedirect.com/science/article/pii/S2095311920632087},
author = {Hong-xia LUO and Sheng-pei DAI and Mao-fen LI and En-ping LIU and Qian ZHENG and Ying-ying HU and Xiao-ping YI},
keywords = {mango plantations, GLCM texture, SVM, RF, GF-1},
abstract = {Mango is a commercial crop on Hainan Island, China, that is cultivated to develop the tropical rural economy. The development of accurate and up-to-date maps of the spatial distribution of mango plantations is necessary for agricultural monitoring and decision management by the local government. Pixel-based and object-oriented image analysis methods for mapping mango plantations were compared using two machine learning algorithms (support vector machine (SVM) and Random Forest (RF)) based on Chinese high-resolution Gaofen-1 (GF-1) imagery in parts of Hainan Island. To assess the importance of different features on classification accuracy, a combined layer of four original bands, 32 gray-level co-occurrence (GLCM) texture indices, and 10 vegetation indices were used as input features. Then five different sets of variables (5, 10, 20, and 30 input variables and all 46 variables) were classified with the two machine learning algorithms at object-based level. Results of the feature optimization suggested that homogeneity and variance were very important variables for distinguishing mango plantations patches. The object-based classifiers could significantly improve overall accuracy between 2–7% when compared to pixel-based classifiers. When there were 5 and 10 input variables, SVM showed higher classification accuracy than RF, and when the input variables exceeded 20, RF showed better performances. After the accuracy achieved saturation points, there were only slightly classification accuracy improvements along with the numbers of feature increases for both of SVM and RF classifiers. The results indicated that GF-1 imagery can be successfully applied to mango plantation mapping in tropical regions, which would provide a useful framework for accurate tropical agriculture land management.}
}
@article{XUE2020106227,
title = {Adaptive fault-tolerant control for carrier-based UAV with actuator failures},
journal = {Aerospace Science and Technology},
volume = {107},
pages = {106227},
year = {2020},
issn = {1270-9638},
doi = {https://doi.org/10.1016/j.ast.2020.106227},
url = {https://www.sciencedirect.com/science/article/pii/S1270963820309093},
author = {Y.X. Xue and Z.Y. Zhen and L.Q. Yang and L.D. Wen},
keywords = {UAV, Adaptive fault-tolerant control, Automatic carrier landing system},
abstract = {An adaptive fault-tolerant control (AFTC)1 method is developed for an automatic carrier landing system (ACLS)2 with actuator failures. First, an actuator fault model is added to the linear unmanned aerial vehicle (UAV)3 model. Then, an AFTC algorithm based on the output feedback designs for output tracking is raised to solve the theoretical problem extracted through the practical automatic carrier landing process. The σ-modification based robust adaptive update law is used for both parameterized and unparameterized fault. Then the stability of the system is verified by Lyapunov function method. Finally, the ACLS simulation is conducted, which includes the guidance law designed by PID method, the flight controller designed by the proposed AFTC method and a deck motion prediction and compensation based on auto-regression (AR)4 model. The comparison result shows that the improved robust AFTC can effectively deal with both parameterized and unparameterized fault, as well as external disturbances.}
}
@article{ZHU2015493,
title = {Model of Collaborative UAV Swarm Toward Coordination and Control Mechanisms Study},
journal = {Procedia Computer Science},
volume = {51},
pages = {493-502},
year = {2015},
note = {International Conference On Computational Science, ICCS 2015},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2015.05.274},
url = {https://www.sciencedirect.com/science/article/pii/S1877050915010820},
author = {Xueping Zhu and Zhengchun Liu and Jun Yang},
keywords = {Multi-agent system, Unmanned aerial vehicles, Flight formation, Coordination},
abstract = {In recent years, thanks to the low cost of deploying, maintaining an Unmanned Aerial Vehicle (UAV) system and the possibility to operating them in areas inaccessible or dangerous for human pilots, UAVs have attracted much research attention both in the military field and civilian application. In order to deal with more sophisticated tasks, such as searching survival points, multiple target monitoring and tracking, the application of UAV swarms is forseen. This requires more complex control, communication and coordination mechanisms. However, these mechanisms are difficult to test and analyze under flight dynamic conditions. These multi- UAV scenarios are by their nature well suited to be modeled and simulated as multi-agent systems. The first step of modeling an multi-agent system is to construct the model of agent, namely accurate model to represent its behavior, constraints and uncertainties of UAVs. In this paper we introduce our approach to model an UAV as an agent in terms of multi-agent system principle. Construction of the model to satisfy the need for a simulation environment that researchers can use to evaluate and analyze swarm control mechanisms. Simulations results of a case study is provided to demonstrate one potential use of this approach.}
}
@article{PAN2020103357,
title = {A spatial-channel hierarchical deep learning network for pixel-level automated crack detection},
journal = {Automation in Construction},
volume = {119},
pages = {103357},
year = {2020},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2020.103357},
url = {https://www.sciencedirect.com/science/article/pii/S0926580520309377},
author = {Yue Pan and Gaowei Zhang and Limao Zhang},
keywords = {Computer vision, Automated crack detection, Deep learning, Convolution neural networks, Attention mechanism},
abstract = {This research develops a novel computer vision approach named a spatial-channel hierarchical network (SCHNet), which is feasible to support the automated and reliable concrete crack segmentation at the pixel level. Specifically, SCHNet with a base net Visual Geometry Group 19 (VGG19) contains a self-attention mechanism, which is realized by three parallel modules, including the feature pyramid attention module, the spatial attention module, and the channel attention module. It can not only consider the semantic interdependencies in spatial and channel dimensions, but also adaptively integrate local features into their global dependencies. The segmentation performance is evaluated by a metric named Mean Intersection over Union (IoU) in a public dataset containing 11,000 cracked and non-cracked images with a unified resolution at 256 × 256 pixels (px). The experimental results confirm the effectiveness of the three attention modules, since they can individually increase Mean IoU by 1.62% (74.16%–72.54%), 5.15% (79.31%–74.16%), and 5.76% (79.92%–74.16%), respectively. With the help of new strategies like the data augmentation and multi-grid method, SCHNet can boost Mean IoU to 85.31%. In a comparison of the state-of-the-art models (i.e. U-net, DeepLab-v2, PSPNet, Ding, Dilated FCN) on the test dataset, SCHNet can outperform others with an improvement of at least 7.51% in Mean IoU. Moreover, SCHNet is robust to noises with a better generalization ability under various conditions, including shadows, roughness surfaces, and holes. Overall, this research contributes to developing SCHNet to integrate spatial and channel information in feature extraction, resulting in a more accurate and efficient crack detection process.}
}
@article{KURDI2019105643,
title = {Adaptive task allocation for multi-UAV systems based on bacteria foraging behaviour},
journal = {Applied Soft Computing},
volume = {83},
pages = {105643},
year = {2019},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2019.105643},
url = {https://www.sciencedirect.com/science/article/pii/S1568494619304235},
author = {Heba Kurdi and Munirah F. AlDaood and Shiroq Al-Megren and Ebtesam Aloboud and Abdulrahman S. Aldawood and Kamal Youcef-Toumi},
keywords = {Task allocation, Unmanned aerial vehicles, Distributed systems, Multi-UAV systems, Bacteria inspiration, Optimisation problem, Red palm weevil},
abstract = {The foraging behaviour of bacteria in colonies exhibits motility patterns that are simple and reasoned by stimuli. Notwithstanding its simplicity, bacteria behaviour demonstrates a level of intelligence that can feasibly inspire the creation of solutions to address numerous optimisation problems. One such challenge is the optimal allocation of tasks across multiple unmanned aerial vehicles (multi-UAVs) to perform cooperative tasks for future autonomous systems. In light of this, this paper proposes a bacteria-inspired heuristic for the efficient distribution of tasks amongst deployed UAVs. The usage of multi-UAVs is a promising concept to combat the spread of the red palm weevil (RPW) in palm plantations. For that purpose, the proposed bacteria-inspired heuristic was utilised to resolve the multi-UAV task allocation problem when combating RPW infestation. The performance of the proposed algorithm was benchmarked in simulated detect-and-treat missions against three long-standing multi-UAV task allocation strategies, namely opportunistic task allocation, auction-based scheme, and the max-sum algorithm, and a recently introduced locust-inspired algorithm for the allocation of multi-UAVs. The experimental results demonstrated the superior performance of the proposed algorithm, as it substantially improved the net throughput and maintained a steady runtime performance under different scales of fleet sizes and number of infestations, thereby expressing the high flexibility, scalability, and sustainability of the proposed bacteria-inspired approach.}
}
@article{PEREIRA201516,
title = {Embedded Image Processing Systems for Automatic Recognition of Cracks using UAVs},
journal = {IFAC-PapersOnLine},
volume = {48},
number = {10},
pages = {16-21},
year = {2015},
note = {2nd IFAC Conference on Embedded Systems, Computer Intelligence and Telematics CESCIT 2015},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2015.08.101},
url = {https://www.sciencedirect.com/science/article/pii/S2405896315009684},
author = {Fábio Celestino Pereira and Carlos Eduardo Pereira},
keywords = {Unmanned Aerial Vehicle, Image Processing, Embedded System, Cracks detection},
abstract = {Aiming at the use of Unmanned Aerial Vehicle (UAV) in civil construction for autonomous inspection of building pathologies, this paper discusses some implementation alternatives of image processing algorithms for the detection of cracks in building facades. These algorithms should run in an embedded computing platform installed on UAVs. Two image processing algorithms for crack detection and classification were selected and different embedded system implementations were evaluated. A version of the algorithms running in a Matlab environment on a desktop computer, which can be used in an approach on which the image processing is done in the ground and the UAV is only applied for image acquisition, was used as a baseline for the comparison. This baseline is compared with implementations running on an embedded processor (a Raspberry PI, running a distribution of Debian ARM operating system) and with implementations on a Xilinx FPGA-board installed in the UAV. Different scenarios for the execution of a inspection task of building facades were defined and the obtained results are presented in the paper.}
}
@article{JIANG2021,
title = {DeepPOSE: Detecting GPS spoofing attack via deep recurrent neural network},
journal = {Digital Communications and Networks},
year = {2021},
issn = {2352-8648},
doi = {https://doi.org/10.1016/j.dcan.2021.09.006},
url = {https://www.sciencedirect.com/science/article/pii/S2352864821000663},
author = {Peng Jiang and Hongyi Wu and Chunsheng Xin},
keywords = {GPS spoofing attack, Position estimation, Recurrent neural network},
abstract = {The Global Positioning System (GPS) has become a foundation for most location-based services and navigation systems, such as autonomous vehicles, drones, ships, and wearable devices. However, it is a challenge to verify if the reported geographic locations are valid due to various GPS spoofing tools. Pervasive tools, such as Fake GPS, Lockito, and software-defined radio, enable ordinary users to hijack and report fake GPS coordinates and cheat the monitoring server without being detected. Furthermore, it is also a challenge to get accurate sensor readings on mobile devices because of the high noise level introduced by commercial motion sensors. To this end, we propose DeepPOSE, a deep learning model, to address the noise introduced in sensor readings and detect GPS spoofing attacks on mobile platforms. Our design uses a convolutional and recurrent neural network to reduce the noise, to recover a vehicle's real-time trajectory from multiple sensor inputs. We further propose a novel scheme to map the constructed trajectory from sensor readings onto the Google map, to smartly eliminate the accumulation of errors on the trajectory estimation. The reconstructed trajectory from sensors is then used to detect the GPS spoofing attack. Compared with the existing method, the proposed approach demonstrates a significantly higher degree of accuracy for detecting GPS spoofing attacks.}
}
@article{XIA2021126995,
title = {Development of a system for assessing the quality of urban street-level greenery using street view images and deep learning},
journal = {Urban Forestry & Urban Greening},
volume = {59},
pages = {126995},
year = {2021},
issn = {1618-8667},
doi = {https://doi.org/10.1016/j.ufug.2021.126995},
url = {https://www.sciencedirect.com/science/article/pii/S1618866721000200},
author = {Yixi Xia and Nobuyoshi Yabuki and Tomohiro Fukuda},
keywords = {Deep learning, Green View Index (GVI), Image segmentation, Panoramic View Green View Index (PVGVI), Street view images, Urban green space},
abstract = {Street greenery has long played a vital role in the quality of urban landscapes and is closely related to people’s physical and mental health. Also, the level of street greenery is an important indicator of urban environmental quality. However, despite extensive research into environmental assessment methods for urban greenery, plant identification and greenery index calculations are still mostly done manually. In this research, we developed a method based on semantic segmentation processing of street view images to calculate the Green View Index of urban streets, and the Panoramic View Green View Index (PVGVI) is proposed for measuring the visible street-level greenery. We validated the results by comparison with those of manual inspection and the Pyramid Scene Parsing Network method. The vegetation detection rate of our method is very close to the ground truth value, which means it can distinguish almost all of the vegetation information from the street view images, and based on it we can calculate the PVGVI which is reliable. In addition, we conducted a case study of street-level greenery using the PVGVI and confirmed that this method can better visualize urban street-level greenery. The proposed method is scalable and automatable, and it contributes to the growing trend of integrating large freely available street view image datasets with semantic segmentation to inform urban planners.}
}
@article{VERMA2022103243,
title = {Optimizing the quality of information of networked machine learning agents},
journal = {Journal of Network and Computer Applications},
volume = {197},
pages = {103243},
year = {2022},
issn = {1084-8045},
doi = {https://doi.org/10.1016/j.jnca.2021.103243},
url = {https://www.sciencedirect.com/science/article/pii/S1084804521002411},
author = {Gunjan Verma and Kelvin Marcus and Kevin S. Chan},
keywords = {Quality of information, Network utility maximization, Machine learning, Resource allocation, Software-defined networking},
abstract = {Quality of information (QoI) and quality of experience (QoE) are related notions that capture the general idea that a network’s finite resources should be allocated in a manner that optimizes the goals of its users. Importantly, these goals depend not merely on low-level network statistics (like bit rate) but also the semantics and context of the information, as well as the subjective preferences of its users. The difficulty of accurately modeling human-relevant subjectivity and semantics has complicated the realization of QoE/QoI concepts in a rigorous network optimization algorithm. However, modern networks are increasingly comprised of a large number of non-human actors including intelligent and adaptive machine learning (ML) agents. These agents aim to optimize some complex learning or inference objective. In contrast to human actors, the relevant utility functions that such ML agents seek to maximize are in fact readily quantified and naturally depend on the semantic content and context of the data being communicated. Capitalizing on this insight, in this work we argue that for networks whose data producers and consumers are ML agents, QoI can in fact be operationalized within a network utility maximization (NUM) framework. NUM is a classical framework for constrained network utility optimization over a resource-constrained network, but has traditionally been applied only in settings where the utility functions are hand-designed and semantically agnostic, i.e., functions of low-level network metrics alone, such as latency or bit-rate. We show that when the users of the network are ML agents, the NUM framework can be easily extended to be semantically aware, which in turn enables resource allocations which outperform their semantically agnostic counterparts. We illustrate the value of our approach with experiments with object detection and localization in streaming video over a software-defined network (SDN).}
}
@article{LI2022108066,
title = {Hydrodynamics with complex boundary motions by non-inertial SPH method and its application in attitude-liquid-control coupled dynamics of a liquid-filled quadrotor UAV},
journal = {Mechanical Systems and Signal Processing},
volume = {163},
pages = {108066},
year = {2022},
issn = {0888-3270},
doi = {https://doi.org/10.1016/j.ymssp.2021.108066},
url = {https://www.sciencedirect.com/science/article/pii/S0888327021004556},
author = {Jipeng Li and Dengqing Cao and Kai Pan},
keywords = {Liquid sloshing, Attitude-liquid-control coupling dynamics, Non-inertial SPH, Backstepping control, Quadrotor UAV},
abstract = {Smoothed Particle Hydrodynamics (SPH) is a fully Lagrangian method that does not require the use of any mesh. Due to its advantages, SPH method is usually adopted to simulate flows with free surfaces. Based on traditional SPH, non-inertial SPH as a new method is proposed recently to deal with cases when the liquid is subjected to inertial force for the motion of reference frame. This study finds that the transport velocity of liquid particles has additional effects on the solution of momentum equation in Navier-Stokes equations. Comparisons and validations are conducted to quantificationally investigate this influence in this paper. Furthermore, the modified non-inertial SPH method is applied to simulate the attitude-liquid-control coupled dynamics of a liquid-filled quadrotor unmanned aerial vehicle (UAV). Parallelization technology and particle searching method based on KD-tree algorithm are used to speed up the simulation. Coupled model of the liquid-filled quadrotor is built firstly, and the liquid sloshing effect on the position & attitude of UAV and the control output of power system are then simulated and discussed. Results prove that the liquid sloshing will deteriorate the trajectory tracking performance, especially the tracking error and rotor output.}
}
@article{XU2019339,
title = {A deep learning methodology for automatic extraction and discovery of technical intelligence},
journal = {Technological Forecasting and Social Change},
volume = {146},
pages = {339-351},
year = {2019},
issn = {0040-1625},
doi = {https://doi.org/10.1016/j.techfore.2019.06.004},
url = {https://www.sciencedirect.com/science/article/pii/S0040162518320389},
author = {Jianguo Xu and Lixiang Guo and Jiang Jiang and Bingfeng Ge and Mengjun Li},
keywords = {Technical intelligence, CRF-BiLSTM, Deep learning, Intelligence monitoring},
abstract = {It is imperative and arduous to acquire product and business intelligence of global technical market. In this paper, a deep learning methodology is proposed to automatically extract and discover vital technical information from large-scale news dataset. More specifically, six kinds of technical elements are first defined to provide the concrete syntax information. Next, the CRF-BiLSTM approach is used to automatically extract technical entities, in which a conditional random field (CRF) layer is added on top of bidirectional long short-term memory (BiLSTM) layer. Then, three indicators including timeliness, influence and innovativeness are designed to evaluate the value of intelligence comprehensively. Finally, as a case study, technical news on three military-related websites is utilized to illustrate the efficiency and effectiveness of the foregoing methodology with the result of 80.82 (F-score) in comparison to four other models. In more detail, data on unmanned systems are extracted to summarize the state-of-the-art, and track up-to-the-minute innovations and developments in this field.}
}
@article{YU2020106209,
title = {A constrained differential evolution algorithm to solve UAV path planning in disaster scenarios},
journal = {Knowledge-Based Systems},
volume = {204},
pages = {106209},
year = {2020},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2020.106209},
url = {https://www.sciencedirect.com/science/article/pii/S0950705120304263},
author = {Xiaobing Yu and Chenliang Li and JiaFang Zhou},
keywords = {UAV path planning, Disaster emergency management, Differential evolution algorithm, Constrained optimization},
abstract = {Disasters have caused significant losses to humans in the past decades. It is essential to learn about the disaster situation so that rescue works can be conducted as soon as possible. Unmanned aerial vehicle (UAV) is a very useful and effective tool to improve the capacity of disaster situational awareness for responders. In the paper, UAV path planning is modelled as the optimization problem, in which fitness functions include travelling distance and risk of UAV, three constraints involve the height of UAV, angle of UAV, and limited UAV slope. An adaptive selection mutation constrained differential evolution algorithm is put forward to solve the problem. In the proposed algorithm, individuals are selected depending on their fitness values and constraint violations. The better the individual is, the higher the chosen probability it has. These selected individuals are used to make mutation, and the algorithm searches around the best individual among the selected individuals. The well-designed mechanism improves the exploitation and maintains the exploration. The experimental results have indicated that the proposed algorithm is competitive compared with the state-of-art algorithms, which makes it more suitable in the disaster scenario.}
}
@article{CHEN2021103970,
title = {Extracting water channels from aerial videos based on image-to-BIM registration and spatio-temporal continuity},
journal = {Automation in Construction},
volume = {132},
pages = {103970},
year = {2021},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2021.103970},
url = {https://www.sciencedirect.com/science/article/pii/S0926580521004210},
author = {Junjie Chen and Donghai Liu and Xin Li},
keywords = {Water supply infrastructure, Unmanned aerial vehicle (UAV), Region of interest, Building information model (BIM), Computer vision, Image-to-BIM registration},
abstract = {Unmanned aerial vehicles (UAV) are increasingly being used in water supply infrastructure inspection, resulting in a large volume of aerial visual assets (static photographs or videos). How to efficiently extract water channels from such assets for the benefits of hazard detection remains a challenge. This paper provides an aerial video processing approach for the extraction of various water channel structures, which includes a main algorithm based on the registration of video frames into a building information model (BIM), and a complementary algorithm enabled by aerial video spatio-temporal continuity. Experimental results demonstrate the effectiveness of the proposed approach, which can reliably extract water channels with least manual intervention. The results reveal the promise of exploiting readily-available information from BIM to automate aerial video processing. Future research is suggested to further explore the generalizability of the approach concerning variant flight settings and external environments.}
}
@article{PHUNG2021107376,
title = {Safety-enhanced UAV path planning with spherical vector-based particle swarm optimization},
journal = {Applied Soft Computing},
volume = {107},
pages = {107376},
year = {2021},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2021.107376},
url = {https://www.sciencedirect.com/science/article/pii/S1568494621002994},
author = {Manh Duong Phung and Quang Phuc Ha},
keywords = {Path planning, Particle swarm optimization, UAV},
abstract = {This paper presents a new algorithm named spherical vector-based particle swarm optimization (SPSO) to deal with the problem of path planning for unmanned aerial vehicles (UAVs) in complicated environments subjected to multiple threats. A cost function is first formulated to convert the path planning into an optimization problem that incorporates requirements and constraints for the feasible and safe operation of the UAV. SPSO is then used to find the optimal path that minimizes the cost function by efficiently searching the configuration space of the UAV via the correspondence between the particle position and the speed, turn angle and climb/dive angle of the UAV. To evaluate the performance of SPSO, eight benchmarking scenarios have been generated from real digital elevation model maps. The results show that the proposed SPSO outperforms not only other particle swarm optimization (PSO) variants including the classic PSO, phase angle-encoded PSO and quantum-behave PSO but also other state-of-the-art metaheuristic optimization algorithms including the genetic algorithm (GA), artificial bee colony (ABC), and differential evolution (DE) in most scenarios. In addition, experiments have been conducted to demonstrate the validity of the generated paths for real UAV operations. Source code of the algorithm can be found at https://github.com/duongpm/SPSO.}
}
@article{PARK2020119096,
title = {Concrete crack detection and quantification using deep learning and structured light},
journal = {Construction and Building Materials},
volume = {252},
pages = {119096},
year = {2020},
issn = {0950-0618},
doi = {https://doi.org/10.1016/j.conbuildmat.2020.119096},
url = {https://www.sciencedirect.com/science/article/pii/S0950061820311016},
author = {Song Ee Park and Seung-Hyun Eem and Haemin Jeon},
keywords = {Structural health monitoring, Crack, Detection, Quantification, Deep leaning, Structured light},
abstract = {Considering the deterioration of civil infrastructures, the evaluation of structural safety by detecting cracks is becoming increasingly essential. In this paper, the advanced technologies of deep learning and structured light composed of vision and two laser sensors have been applied to detect and quantify cracks on surfaces of concrete structures. The YOLO (You Only Look Once) algorithm has been used for real-time detection, and the sizes of the detected cracks have been calculated based on the positions of the projected laser beams on the structural surface. Since laser beams may not be projected in parallel due to installation or manufacturing errors, the laser alignment correction algorithm with a specially designed jig module and a distance sensor is applied to increase the accuracy of the size measurement. The performance of the algorithm has been verified through simulations and experimental tests, and the results show that the cracks on the structural surfaces can be detected and quantified with high accuracy in real-time.}
}
@article{CHENG2021106172,
title = {UAV photogrammetry-based remote sensing and preliminary assessment of the behavior of a landslide in Guizhou, China},
journal = {Engineering Geology},
volume = {289},
pages = {106172},
year = {2021},
issn = {0013-7952},
doi = {https://doi.org/10.1016/j.enggeo.2021.106172},
url = {https://www.sciencedirect.com/science/article/pii/S0013795221001836},
author = {Zhan Cheng and Wenping Gong and Huiming Tang and C. Hsein Juang and Qinglu Deng and Jun Chen and Xiongfei Ye},
keywords = {UAV, Landslide, Failure mechanism, Crack recognition, Geohazards assessment},
abstract = {Unmanned Aerial Vehicle (UAV) technique has been widely utilized in geohazards assessment. In this work, the effectiveness of the UAV photogrammetry in the remote sensing and assessment of the landslide behavior is demonstrated through a case study of a landslide that occurred in Guizhou, China on 10 June 2018. The post-landslide assessments were conducted through a field investigation by a team of experts; and, two UAV photogrammetry-based surveys were carried out. On the basis of a detailed inspection of the high-resolution aerial photographs collected from the UAV photogrammetry and historical satellite imagery, subsurface stratigraphic configuration revealed from borehole explorations and the local rainfall data collected, the failure mechanism of this landslide is investigated. The occurrence of this landslide is probably attributed to the combined influence of the long-term rainfall and the engineering activities at this site. An automatic landslide cracks recognition model, which is based on the deep learning-based image recognition technique of RetinaNet, is further developed to map the cracks at the landslide site. The effectiveness of this automatic crack recognition model is validated through quantitative comparisons between the landslide cracks recognized and the field survey results. Based upon the landslide cracks identified on two different dates after this landslide event (by the field survey and automatic crack recognition model) and the subsurface displacement revealed from a drilled hole, the evolution behavior of this landslide is analyzed. The results show that the stability of this landslide was not achieved during the first slide in June 2018 and the limit of the landslide was increased much from June to November 2018. In such a situation, the elements at risk in the zones that are potentially impacted by this landslide are identified (with the aid of the UAV images collected), and a preliminary consequence assessment is conducted.}
}
@article{YANO2016415,
title = {Identification of weeds in sugarcane fields through images taken by UAV and Random Forest classifier},
journal = {IFAC-PapersOnLine},
volume = {49},
number = {16},
pages = {415-420},
year = {2016},
note = {5th IFAC Conference on Sensing, Control and Automation Technologies for Agriculture AGRICONTROL 2016},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2016.10.076},
url = {https://www.sciencedirect.com/science/article/pii/S2405896316316391},
author = {Inacio H. Yano and Jose R. Alves and Wesley E. Santiago and Barbara J.T. Mederos},
keywords = {weed, pattern recognition, machine learning, images, UAV, sugarcane},
abstract = {Abstract:
Sugarcane is one of the most important cultures in the world. The productivity of sugarcane is affected by many factors, among them weeds can cause several problems. Weed control is made usually by herbicides application because sugarcane occupies extensive areas, and due to the same reason, the decision about herbicide type and dosage has been done by sampling. This work mode does not allow variation and causes problems of herbicide application, since the presence and weed type may not be uniform in whole field. There are some solutions based on satellite image analysis that allow the coverage of the entire field, solving the problem caused by sampling sense, but this solution depends on high weed infestation and a clear sky for good results. This work proposes a system for weed surveying, based on image pattern recognition with pictures taken by a UAV (Unmanned Aerial Vehicle); this alternative can take pictures very close to the plants, which allows species recognition in lower infestation levels and without clouds interference. This solution achieved an overall accuracy of 82 % and kappa coefficient of 0.73 in preliminary tests.}
}
@article{TRUONG2020101822,
title = {Using machine learning algorithms to predict the risk of small Unmanned Aircraft System violations in the National Airspace System},
journal = {Journal of Air Transport Management},
volume = {86},
pages = {101822},
year = {2020},
issn = {0969-6997},
doi = {https://doi.org/10.1016/j.jairtraman.2020.101822},
url = {https://www.sciencedirect.com/science/article/pii/S0969699719305575},
author = {Dothang Truong and Woojin Choi},
keywords = {Small unmanned aircraft system, National airspace system, Aviation safety, Risk prediction, Machine learning, Data mining},
abstract = {The increasing number of small Unmanned Aircraft System (sUAS) encounters with manned aircraft or airports increases the risk of collision in the National Airspace System. The purpose of this research is to develop and test predictive models for sUAS violation incidents in NAS using machine learning. This research uses machine learning algorithms to predict the risk of sUAS violation incidents using the FAA's UAS sighting data with a sample size of 2088. Three sUAS violation types are identified: flying above 400 feet, flying with 5 miles from an airport, and flying in restricted airspace. Seven machine learning algorithms were used, including classification regression, decision tree, neural network, gradient boosting, random forest, Bayesian networks, and Memory-Based Reasoning. The results show that Gradient boosting produces the best predictive model. This model can predict the sUAS violation incidents with an accuracy of 95.7 percent. Location, distance to the airport, state, sUAs altitude, airport type, and aircraft type are the most influential predictors to the sUAS violation incidents.}
}
@article{DARYAEI2020105686,
title = {Fine-scale detection of vegetation in semi-arid mountainous areas with focus on riparian landscapes using Sentinel-2 and UAV data},
journal = {Computers and Electronics in Agriculture},
volume = {177},
pages = {105686},
year = {2020},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2020.105686},
url = {https://www.sciencedirect.com/science/article/pii/S0168169920312862},
author = {Ardalan Daryaei and Hormoz Sohrabi and Clement Atzberger and Markus Immitzer},
keywords = {Sentinel-2, UAV, Random forest classification, Mono- and multi-temporal, Riparian landscapes},
abstract = {Sparse vegetation such as riparian forests and trees outside forests (TOF) cover only small areas but present various ecological advantages. The detection of these vegetation types in semi-arid mountainous areas is challenging as trees are heavily mixed with other land cover types. Their mapping requires therefore high-resolution imagery. We propose to leverage the advantages and synergies of freely available Sentinel-2 data and a light-weight consumer-grade unmanned aerial vehicle (UAV) with a simple red–greenblue (RGB) camera to detect these vegetation types. In our approach, an object-based random forest land cover classification is first developed over smaller sites using very high-resolution UAV data. The resulting maps are afterwards used as training data for multi-temporal Sentinel-2 based classifications at regional scale. We tested the approach in five different riparian landscapes of a semi-arid mountainous area in Iran. For comparison, mono- and multi-temporal Sentinel-2 data were also used alone – without support from UAV data – to build pixel-based random forest classification models at regional scale. Our results show that compared to the best mono-temporal results, the multi-temporal classification approach improved the overall accuracy and Kappa values of Sentinel-2 classifications from 77.0% to 83.9% and 0.72 to 0.81, respectively. The producer’s and user’s accuracy of the riparian forest class were also improved from 64.0% to 70.0% and 57.1% to 73.7%, respectively. Combining UAV and Sentinel-2 data improved the overall accuracy only slightly, but enabled a much better detection of Persian oak stands – for this class, the producer’s accuracy increased by 13.0 percentage points. Overall, we recommend the combined use of UAV and multi-temporal Sentinel-2 data to detect Persian oak forest stands.}
}
@article{SWARUP202165,
title = {Energy Efficient Task Scheduling in Fog Environment using Deep Reinforcement Learning Approach},
journal = {Procedia Computer Science},
volume = {191},
pages = {65-75},
year = {2021},
note = {The 18th International Conference on Mobile Systems and Pervasive Computing (MobiSPC), The 16th International Conference on Future Networks and Communications (FNC), The 11th International Conference on Sustainable Energy Information Technology},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2021.07.012},
url = {https://www.sciencedirect.com/science/article/pii/S1877050921014046},
author = {Shashank Swarup and Elhadi M. Shakshuki and Ansar Yasar},
keywords = {Cloud computing, Fog computing, Task scheduling, Clipped Double Deep Q-learning, energy-efficient, cost, service delay, parallel queue, dual queue},
abstract = {The users of cloud span to several types of tasks for various purposes, such as users who need to accomplish tasks that utilize cloud based on as Infrastructure as a Service. These tasks are usually of high latency. There are some tasks that require immediate response. That is, ultra-low latency tasks like IoT device requirements. It is not feasible to always depend on a far cloud datacenter. Unlike traditional cloud computing, it is possible to place edge and fog nodes can be placed close to the IoT devices provides noticeable reduction in latency. The emerging fog computing technology is characterized by ultra-low latency response, which benefits several time-sensitive services and applications. Nodes in fog are deployed in less centralized. In a fog layer, the computing equipment dedicates parts of its limited resources to process IoT application tasks. Therefore, efficient utilization of computing resources is essential and requires an optimal and intelligent strategy for task scheduling. This paper focuses on scheduling IoT tasks in a fog-based environment with the aim to minimizing energy, cost, and service delay. Towards this end, a deep reinforcement learning based algorithm named Clipped Double Deep Q-learning using target networks and experience replay techniques is proposed. To ensure there is no lag in using resources optimally, a parallel queueing is utilized. One of the important factors in cloud (and fog) computing research is to address the problem of long waiting time of the task in the virtual machine queue. This paper proposes a dual queue method.}
}
@article{HASSIJA2021102537,
title = {A blockchain and deep neural networks-based secure framework for enhanced crop protection},
journal = {Ad Hoc Networks},
volume = {119},
pages = {102537},
year = {2021},
issn = {1570-8705},
doi = {https://doi.org/10.1016/j.adhoc.2021.102537},
url = {https://www.sciencedirect.com/science/article/pii/S1570870521000883},
author = {Vikas Hassija and Siddharth Batra and Vinay Chamola and Tanmay Anand and Poonam Goyal and Navneet Goyal and Mohsen Guizani},
keywords = {Neural networks, Smart contract, Blockchain, Farmers, Plant pathology},
abstract = {The problem faced by one farmer can also be the problem of some other farmer in other regions. Providing information to farmers and connecting them has always been a challenge. Crowdsourcing and community building are considered as useful solutions to these challenges. However, privacy concerns and inactivity of users can make these models inefficient. To tackle these challenges, we present a cost-efficient and blockchain-based secure framework for building a community of farmers and crowdsourcing the data generated by them to help the farmers’ community. Apart from ensuring privacy and security of data, a revenue model is also incorporated to provide incentives to farmers. These incentives would act as a motivating factor for the farmers to willingly participate in the process. Through integration of a deep neural network-based model to our proposed framework, prediction of any abnormalities present within the crops and their predicted possible solutions would be much more coherent. The simulation results demonstrate that the prediction of plant pathology model is highly accurate.}
}
@article{WANG2020115412,
title = {Ensemble machine-learning-based framework for estimating total nitrogen concentration in water using drone-borne hyperspectral imagery of emergent plants: A case study in an arid oasis, NW China},
journal = {Environmental Pollution},
volume = {266},
pages = {115412},
year = {2020},
issn = {0269-7491},
doi = {https://doi.org/10.1016/j.envpol.2020.115412},
url = {https://www.sciencedirect.com/science/article/pii/S0269749120361005},
author = {Jingzhe Wang and Tiezhu Shi and Danlin Yu and Dexiong Teng and Xiangyu Ge and Zipeng Zhang and Xiaodong Yang and Hanxi Wang and Guofeng Wu},
keywords = {Water resources, Remote sensing, Total nitrogen, Hyperspectral imagery, Machine learning, Bootstrap},
abstract = {In arid and semi-arid regions, water-quality problems are crucial to local social demand and human well-being. However, the conventional remote sensing-based direct detection of water quality parameters, especially using spectral reflectance of water, must satisfy certain preconditions (e.g., flat water surface and ideal radiation geometry). In this study, we hypothesized that drone-borne hyperspectral imagery of emergent plants could be better applied to retrieval total nitrogen (TN) concentration in water regardless of preconditions possibly due to the spectral responses of emergent plants on nitrogen removal and water purification. To test this hypothesis, a total of 200 groups of bootstrap samples were used to examine the relationship between the extracted TN concentrations from the drone-borne hyperspectral imagery of emergent plants and the experimentally measured TN concentrations in Ebinur Lake Oasis using four machine learning (ML) models (Partial Least Squares (PLS), Random Forest (RF), Extreme Learning Machine (ELM), and Gaussian Process (GP)). Through the introduction of the fractional order derivative (FOD), we build a decision-level fusion (DLF) model to minimize the regression results’ biases of individual ML models. For individual ML model, GP performed the best. Still, the amount of uncertainty in individual ML models renders their performance to be subpar. The introduction of the DLF model greatly minimizes the regression results’ biases. The DLF model allows to reduce potential uncertainties without sacrificing accuracy. In conclusion, the spectral response caused by nitrogen removal and water purification on emergent plants could be used to retrieve TN concentration in water with a DLF model framework. Our study offers a new perspective and a basic scientific support for water quality monitoring in arid regions.}
}
@article{MOHAMADI2021115529,
title = {Efficient algorithms for decision making and coverage deployment of connected multi-low-altitude platforms},
journal = {Expert Systems with Applications},
volume = {184},
pages = {115529},
year = {2021},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2021.115529},
url = {https://www.sciencedirect.com/science/article/pii/S0957417421009374},
author = {Houssem Eddine Mohamadi and Nadjia Kara and Mohand Lagha},
keywords = {Unmanned aerial vehicle, Low-altitude platform, Multi-criteria decision-making, Coverage optimization problem, Genetic algorithm},
abstract = {Unmanned aerial vehicles (UAVs) have gained significantly in popularity in recent years, and they are coupled with the emerging Internet-of-Things, 5G, and mobile edge computing. Their application domains will continue to expand. UAVs can deliver various IoT-driven applications (e.g., video surveillance UAVs-based applications) anytime and anywhere. Indeed, the rapid deployment of such applications in different environments (e.g., urban or wildlife surveillance/sensing environments) is one of the critical factors to support the emergence of new services and applications (e.g., 5G/B5G UAVs base station, civil and commercial IoT applications). However, several research challenges need to be addressed before the latter can be deployed in the real world. In this paper, we propose a novel approach that enables efficient coverage using a set of UAVs. We define two multi-objective sub-problems. The first sub-problem allows selecting a minimum number of appropriate UAVs for deployment as Low-Altitude-Platforms (LAP) over an area of interest from an extensive collection of options. We model this sub-problem as multi-criteria decision-making (MCDM) problem considering various UAV features and user constraints and solve it using a novel multi-criteria selection algorithm named SAGA. The second sub-problem is a coverage optimization problem that enables controlling UAVs’ hover locations and use gimbal-mounted rotating cameras or multi-lens cameras to increase the coverage accordingly. We propose a strategy aiming at optimizing hovering locations of UAVs and then rotating their cameras. The process comprises two techniques to solve the latter sub-problem: (1) an improved preference-guided genetic algorithm named NSPGGA; (2) a hybrid heuristic DCXGA built upon three algorithmic techniques: divide-and-conquer, greedy search, and exhaustive search. We carried out comparative analyses with seven MCDM methods and ten multi-objective evolutionary/swarm intelligence algorithms. The proposed algorithms outperformed the benchmarking techniques and showed remarkable results, e.g., the selection algorithm SAGA exhibits a high success rate, accuracy, and consistency. The preference-guided genetic algorithm NSPGGA achieves better efficiency, and it is four times faster than the famed NSGA-II. Finally, the hybrid heuristic DCXGA allows having more significant imaging coverages with few camera rotations. The aforementioned vital results are validated through diverse and intensive simulation scenarios.}
}
@article{ASHAPURE2020180,
title = {Developing a machine learning based cotton yield estimation framework using multi-temporal UAS data},
journal = {ISPRS Journal of Photogrammetry and Remote Sensing},
volume = {169},
pages = {180-194},
year = {2020},
issn = {0924-2716},
doi = {https://doi.org/10.1016/j.isprsjprs.2020.09.015},
url = {https://www.sciencedirect.com/science/article/pii/S0924271620302628},
author = {Akash Ashapure and Jinha Jung and Anjin Chang and Sungchan Oh and Junho Yeom and Murilo Maeda and Andrea Maeda and Nothabo Dube and Juan Landivar and Steve Hague and Wayne Smith},
keywords = {Precision agriculture, Cotton genotype selection, UAS, ANN},
abstract = {In this research a machine learning framework was developed for cotton yield estimation using multi-temporal remote sensing data collected from unmanned aircraft system (UAS). The proposed machine learning model was based on an artificial neural network (ANN) and used three types of crop features derived from UAS data to predict the yield, namely; multi-temporal features including canopy cover, canopy height, canopy volume, normalized difference vegetation index (NDVI), excessive greenness index (ExG); non-temporal features including cotton boll count, boll size and boll volume, and irrigation status as a qualitative feature. The model provided low residual values with predicted yield values close to the observed yield values (R2 ~ 0.9). ANN model performance was compared with support vector regression (SVR) and random forest regression (RFR). Comparison results revealed that ANN model outperforms SVR and RFR. Additionally, redundant features were removed using correlation analysis, and an optimal subset of features was obtained that included canopy volume, ExG, boll count, boll volume and irrigation status. Moreover, the relative significance of each feature in the optimal input feature subset was determined using sensitivity analysis. It was found that canopy volume and ExG contributed around 50% towards the corresponding yield. Finally, further analysis was performed to investigate how early in the growing season the model can accurately predict yield. It was observed that even at 70 days after planting the model predicted yield with reasonable accuracy (R2 of 0.72 over test set). This study revealed that UAS derived multi-temporal data along with non-temporal and qualitative data can be combined within a machine learning framework to provide a reliable estimation of crop yield and provide effective understanding for crop management.}
}
@article{AHMAD2021106081,
title = {Performance of deep learning models for classifying and detecting common weeds in corn and soybean production systems},
journal = {Computers and Electronics in Agriculture},
volume = {184},
pages = {106081},
year = {2021},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2021.106081},
url = {https://www.sciencedirect.com/science/article/pii/S0168169921000995},
author = {Aanis Ahmad and Dharmendra Saraswat and Varun Aggarwal and Aaron Etienne and Benjamin Hancock},
keywords = {Site-Specific Weed Management, Weed identification, Image classification, Object detection},
abstract = {Knowing precise location and having accurate information about weed species is a prerequisite for developing an effective site-specific weed management (SSWM) system. Due to the effectiveness of deep learning techniques for vision-based tasks such as image classification and object detection, its use for discriminating between weeds and crops is gaining acceptance among the agricultural research community. However, limited studies have used deep learning for identifying multiple weeds in a single image and most of the studies have not compared the effectiveness of deep learning based image classification and object detection by using a common, annotated imagery dataset of early season weeds under field conditions. This study addresses the research gap by evaluating comparative performance of three different pre-trained image classification models for classifying weed species and also assesses the performance of an object detection model for locating and identifying weed species. The image classification models were trained on two commonly used deep learning frameworks i.e., Keras and PyTorch, to assess any performance differential due to the choice of framework. An annotated dataset comprising of RGB images of four, early season weeds, found in corn and soybean production system in the Midwest US, namely, cocklebur (Xanthium strumarium), foxtail (Setaria viridis), redroot pigweed (Amaranthus retroflexus), and giant ragweed (Ambrosia trifida) was used in this study. VGG16, ResNet50, and InceptionV3 pre-trained models were used for image classification. The object detection model, based on the You Only Look Once (YOLOv3) library, was trained to locate and identify different weed species within an image. The performance of image classification models was assessed using testing accuracy and F1-score metrics. Average precision (AP) and mean average precision (mAP) were used to assess the performance of the object detection model. The best performing image classification model was VGG16 with an accuracy of 98.90% and an F1-score of 99%. Faster training times and higher accuracies were observed with PyTorch. The detection model helped locate and identify multiple weeds within an image with AP scores of 43.28%, 26.30%, 89.89%, and 57.80% for cocklebur, foxtail, redroot pigweed, and giant ragweed respectively and an overall mAP score of 54.3%. The results suggest that under field conditions, use of pre-trained models for image classification and YOLOv3 for object detection are promising for identifying single and multiple weeds, respectively, given that sufficient data is available. Additionally, unlike image classification, the localization capabilities of object detection are desirable for developing a system for SSWM.}
}
@article{JIANG2022107314,
title = {UAV path planning and collision avoidance in 3D environments based on POMPD and improved grey wolf optimizer},
journal = {Aerospace Science and Technology},
volume = {121},
pages = {107314},
year = {2022},
issn = {1270-9638},
doi = {https://doi.org/10.1016/j.ast.2021.107314},
url = {https://www.sciencedirect.com/science/article/pii/S1270963821008245},
author = {Wei Jiang and Yongxi Lyu and Yongfeng Li and Yicong Guo and Weiguo Zhang},
keywords = {GWO, Constrained optimization, UAVs, Path planning, POMDP},
abstract = {Due to the complexity and uncertain factors of the environment, a 3D path planning algorithm is urgently needed. This paper presents a 3D optimal feasible flight path generation and collision avoidance algorithms based on partially observable Markov decision process (POMDP) and improved grey wolf optimizer (GWO) for an unmanned aerial vehicle (UAV). Firstly, a novel algorithm based on the GWO is proposed to deal with constrained optimization problem (COP) and utilized to plan a flyable path. The designed variant is called improved GWO with level comparison (GWOLC), which combines the communication mechanism and the ε-level comparison method at the same time. Secondly, aircraft collision avoidance is modeled as a Partially Observable Markov Decision Process (POMDP) and the Monte-Carlo tree search (MCTS) algorithm is used to solve it. We introduce a novel algorithm, Information Particle Filter Tree (IPFT), to solve the problem of belief update in continuous domain. Thirdly, simulation experiments are conducted in 3D environment, and numerical results showed the proposed algorithm offers good performance as measured by effectiveness, robustness, convergence, and constraint handling capabilities.}
}
@article{ZHENG2021539,
title = {An intelligent target detection method of UAV swarms based on improved KM algorithm},
journal = {Chinese Journal of Aeronautics},
volume = {34},
number = {2},
pages = {539-553},
year = {2021},
issn = {1000-9361},
doi = {https://doi.org/10.1016/j.cja.2020.07.021},
url = {https://www.sciencedirect.com/science/article/pii/S1000936120303423},
author = {Xiangming ZHENG and Chunyao MA},
keywords = {3D probability map, Kuhn-Munkres algorithm, Path planning, Real-time control, Swarm intelligence, Target detection, Unmanned aerial vehicle (UAV)},
abstract = {Complete and efficient detection of unknown targets is the most popular application of UAV swarms. Under most situations, targets have directional characteristics so that they can only be successfully detected within specific angles. In such cases, how to coordinate UAVs and allocate optimal paths for them to efficiently detect all the targets is the primary issue to be solved. In this paper, an intelligent target detection method is proposed for UAV swarms to achieve real-time detection requirements. First, a target-feature-information-based disintegration method is built up to divide the search space into a set of cubes. Theoretically, when the cubes are traversed, all the targets can be detected. Then, a Kuhn-Munkres (KM)-algorithm-based path planning method is proposed for UAVs to traverse the cubes. Finally, to further improve search efficiency, a 3D real-time probability map is established over the search space which estimates the possibility of detecting new targets at each point. This map is adopted to modify the weights in KM algorithm, thereby optimizing the UAVs’ paths during the search process. Simulation results show that with the proposed method, all targets, with detection angle limitations, can be found by UAVs. Moreover, by implementing the 3D probability map, the search efficiency is improved by 23.4%–78.1%.}
}
@article{P20201642,
title = {Vehicle Data Aggregation from Highway Video of Madurai City Using Convolution Neural Network},
journal = {Procedia Computer Science},
volume = {171},
pages = {1642-1650},
year = {2020},
note = {Third International Conference on Computing and Network Communications (CoCoNet'19)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2020.04.176},
url = {https://www.sciencedirect.com/science/article/pii/S1877050920311571},
author = {Priyadharshini P and Karthikeyan P},
keywords = {Image Identification, Convolution Neural Network, Vehicle Data Aggregation, Traffic Data Set},
abstract = {Traffic is one of the key issues in highly populated countries like India. There are many research works going on in the areas of the travel and transportation sector. These sectors having challenges such as traffic monitoring, routing assistance, personalized driving. Nowadays, smart city is one of the Government mission which includes traffic management, crowd management etc. In the recent past, there are many cities received funds from the government of India under the smart city scheme. In this paper, the vehicle data aggregation process is proposed using deep Convolution Neural Network (CNN) particularly, in and around the areas of Madurai city, Tamilnadu, India. The purpose of the location chosen is Madurai city also received funds under a smart city scheme from Indian government. There are certain works are already going on in Madurai city under the smart city project. The real-time traffic video capturing used to raspberry pi B modules camera. To support further into the work, a data aggregation technique is proposed in this work to create a vehicle dataset for the Madurai city to help traffic management, driver assistance, and routing guidance through automation system. In this work, the CNN algorithm detected the different vehicles with 92.9% accuracy. This will be compared with region based CNN algorithm, which detected with 96.4% accurately. Hence it is proven that the region based CNN performs better in vehicle detection. The vehicle data are tabulated from some of the sample videos captured in and around Madurai highways using CNN through MATLAB.}
}
@article{MAMMADOV201883,
title = {Reconfigurable Fault Tolerant Flight Control for UAV with Pseudo-Inverse Technique},
journal = {IFAC-PapersOnLine},
volume = {51},
number = {30},
pages = {83-88},
year = {2018},
note = {18th IFAC Conference on Technology, Culture and International Stability TECIS 2018},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2018.11.253},
url = {https://www.sciencedirect.com/science/article/pii/S2405896318329264},
author = {H. Mammadov and Ch. Hajiyev},
keywords = {Fault detection, Fault isolation, Reconfigurable flight control, Pseudo-Inverse Technique, Kalman filters, Estimation, Aerospace},
abstract = {In this study, the parameter identification based fault tolerant control of an unmanned aerial vehicle (UAV) dynamics is presented. When faults occur in the actuator, then the elements of the control distribution matrix (control derivatives) change. The augmented Kalman filter (KF) is used in order to identify the control distribution matrix elements; thus, the control reconfiguration is carried out using this identified control distribution matrix. A reconfigurable pseudo-inverse controller is designed for the modeled UAV. The control derivatives are identified by the augmented KF and pseudo-inverse controller is reconfigured for the identified control distribution matrix. In simulations, the linearized model of longitudinal dynamics of ZAGI UAV is considered, and the performance of the proposed system identification and reconfigurable control techniques are examined for this model. For this purpose the control derivatives related to elevator and thrust are changed in accordance with faulty system condition and the augmented KF based reconfigurable control algorithm using pseudo-inverse technique is investigated.}
}
@article{LI20181,
title = {On the estimation of tree mortality and liana infestation using a deep self-encoding network},
journal = {International Journal of Applied Earth Observation and Geoinformation},
volume = {73},
pages = {1-13},
year = {2018},
issn = {0303-2434},
doi = {https://doi.org/10.1016/j.jag.2018.05.025},
url = {https://www.sciencedirect.com/science/article/pii/S0303243418302848},
author = {Wei Li and Carlos Campos-Vargas and Philip Marzahn and Arturo Sanchez-Azofeifa},
keywords = {Unmanned aerial vehicle systems (UAVs), Tropical dry forests (TDFs), Multi-spectral images, Deep self-encoding network (DSEN)},
abstract = {Global environmental change leads to the variation in the relative coverage of dead trees, liana-infested and non-liana-infested trees in many tropical forests. Increase in the coverage of lianas had adverse effects on forested ecosystems such as decreasing tree growth rates and increasing tree mortality. This paper proposes a classification framework that integrates unmanned aerial vehicle systems (UAVs)-derived multi-spectral images and a Deep self-encoding network (DSEN) with the goal of monitoring and quantifying the relative coverage of dead trees, liana-infested, and non-liana-infested trees at high spatial scales. Today's UAVs-derived multi-spectral images provide the much necessary high resolution/quality data to monitor ecosystem-level processes at low cost and on demand. On the other hand, DSEN, a state-of-the-art classification approach that uses multiple layers to exploit abstract, invariant features from input data, has been proved to have the ability to acquire excellent results. This new classification framework, implemented at a tropical Dry Forest site in Costa Rica, provided accurate estimations of the relative coverage of dead trees, liana-infested trees, non-liana-infested trees, and non-forests. The approach opens the door to start exploring linkages between a booming UAVS industry and machine learning/Deep learning classifiers.}
}
@article{LI201813,
title = {A novel distributed architecture for UAV indoor navigation},
journal = {Transportation Research Procedia},
volume = {35},
pages = {13-22},
year = {2018},
note = {INAIR 2018AVIATION ON THE GROWTH PATH},
issn = {2352-1465},
doi = {https://doi.org/10.1016/j.trpro.2018.12.003},
url = {https://www.sciencedirect.com/science/article/pii/S2352146518303430},
author = {Yuntian Li and Matteo Scanavino and Elisa Capello and Fabrizio Dabbene and Giorgio Guglieri and Andrea Vilardi},
keywords = {Quadcopter, Indoor navigation, ROS},
abstract = {In the last decade, different indoor flight navigation systems for small Unmanned Aerial Vehicles (UAVs) have been investigated, with a special focus on different configurations and on sensor technologies. The main idea of this paper is to propose a distributed Guidance Navigation and Control (GNC) system architecture, based on Robotic Operation System (ROS) for light weight UAV autonomous indoor flight. The proposed framework is shown to be more robust and flexible than common configurations. A flight controller and companion computer running ROS for control and navigation are also included in the section. Both hardware and software diagrams are given to show the complete architecture. Further works will be based on the experimental validation of the proposed configuration by indoor flight tests.}
}
@article{DAMAJ2021,
title = {Intelligent transportation systems: A survey on modern hardware devices for the era of machine learning},
journal = {Journal of King Saud University - Computer and Information Sciences},
year = {2021},
issn = {1319-1578},
doi = {https://doi.org/10.1016/j.jksuci.2021.07.020},
url = {https://www.sciencedirect.com/science/article/pii/S1319157821001877},
author = {Issam Damaj and Salwa K. {Al Khatib} and Tarek Naous and Wafic Lawand and Zainab Z. Abdelrazzak and Hussein T. Mouftah},
keywords = {Intelligent transportation systems, Machine learning, Hardware devices, Performance evaluation, Taxonomy},
abstract = {The increasing complexity of Intelligent Transportation Systems (ITS), that comprise a wide variety of applications and services, has imposed a necessity for high-performance Modern Hardware Devices (MHDs). The performance challenge has become more noticeable with the integration of Machine Learning (ML) techniques deployed in large-scale settings. ML has effectively supported the field of ITS by providing efficient and optimized solutions to problems that were otherwise tackled using traditional statistical and analytical approaches. Addressing the hardware deployment needs of ITS in the era of ML is a challenging problem that involves temporal, spatial, environmental, and economical factors. This survey reviews the recent literature of ML-driven ITS, in which MHDs were utilized, with a focus on performance indicators. A taxonomy is then synthesized, giving a complete representation of what the current capabilities of the surveyed ITS rely on in terms of ML techniques and technological infrastructure. To alleviate the difficulties faced in the non-trivial task of selecting suitable ML techniques and MHDs for an ITS with a specific complexity level, a performance evaluation framework is proposed. The presented survey sets the basis for developing suitable hardware, facilitating the integration of ML within ITS, and bridging the gap between research and real-world deployments.}
}
@article{YU2018274,
title = {Fault-Tolerant Control for Autonomous Aerial Refueling against Actuator Fault in Receiver UAV⁎⁎This work was supported in part by National Natural Science Foundation of China (No. 61473229 and 61573282), Shaanxi Province Natural Science Foundation (No. 2015JZ020), and Natural Sciences and Engineering Research Council of Canada.},
journal = {IFAC-PapersOnLine},
volume = {51},
number = {24},
pages = {274-279},
year = {2018},
note = {10th IFAC Symposium on Fault Detection, Supervision and Safety for Technical Processes SAFEPROCESS 2018},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2018.09.588},
url = {https://www.sciencedirect.com/science/article/pii/S2405896318322985},
author = {Ziquan Yu and Youmin Zhang and Yaohong Qu},
keywords = {Fault-tolerant control (FTC), autonomous aerial refueling (AAR), actuator fault, disturbance observer},
abstract = {This paper investigates the fault-tolerant control problem of a receiver unmanned aerial vehicle (UAV) against actuator fault and wake vortex induced by the tanker aircraft under the aerial refueling formation flight conditions. In autonomous aerial refueling (AAR), the relative distance of the receiver UAV with respect to the tanker aircraft/UAV is essential for the flight safety of the receiver UAV and the tanker aircraft/UAV. To design the fault-tolerant controller for the receiver UAV, disturbance observer technique is used to estimate the lumped uncertainties including wake vortex and actuator fault. Based on the estimated lumped uncertainties, backstepping architecture is utilized to construct the control scheme. Furthermore, it is shown that the relative forward distance and the relative perpendicular distance tracking errors are uniformly ultimately bounded. Finally, simulations are presented to show the effectiveness of the proposed fault-tolerant control scheme.}
}
@article{ALVAREZVANHARD2020111780,
title = {Can UAVs fill the gap between in situ surveys and satellites for habitat mapping?},
journal = {Remote Sensing of Environment},
volume = {243},
pages = {111780},
year = {2020},
issn = {0034-4257},
doi = {https://doi.org/10.1016/j.rse.2020.111780},
url = {https://www.sciencedirect.com/science/article/pii/S0034425720301504},
author = {Emilien Alvarez-Vanhard and Thomas Houet and Cendrine Mony and Lucie Lecoq and Thomas Corpetti},
keywords = {Unmanned aerial vehicle, Sensor synergy, Endmember, Wetlands, Spectral unmixing, Habitat mapping, LTSER Armorique},
abstract = {Habitat mapping is an essential descriptor to monitor and manage natural or semi-natural ecosystems. Habitats integrate both the environmental conditions and the related biodiversity. However, it remains challenging to map certain habitats such as inland wetlands due to spectral, spatial and temporal variability in the vegetation cover. Currently, no satellite constellations optimize the spectral, spatial and temporal resolutions required to map wetlands according to the habitats discriminated from in situ surveys. Our approach aims to combine satellite and unmanned aerial vehicle (UAV) data to exceed their respective limitations. Both data sources were combined through a spectral unmixing algorithm with the hypothesis that endmembers from UAV data are pure enough to enhance plant community abundances estimated from satellite data. The experiment was conducted on the regional preserve of the Sougéal marsh, a wet grassland of 174 ha located upstream of the Mont-Saint-Michel Bay. Two satellite data sources - Sentinel-2 and Pleiades - and three acquisition periods - November 2017, April 2018 and May 2018 - were considered. A reference map of plant community distribution was produced from UAV multitemporal data and floristic surveys to validate the unmixing of satellite data. This study shows innovative results and perspectives: while UAV can improve habitat discrimination, results vary among acquisition periods and habitats. Results illustrate well the great potential of combined UAV and satellite data but also demonstrate the influence of endmembers on the unmixing process and technical limitations (e.g. spectral mismatches between sensors), which can be overcome using domain adaptation.}
}
@article{ZAHMATKESH2020102139,
title = {Fog computing for sustainable smart cities in the IoT era: Caching techniques and enabling technologies - an overview},
journal = {Sustainable Cities and Society},
volume = {59},
pages = {102139},
year = {2020},
issn = {2210-6707},
doi = {https://doi.org/10.1016/j.scs.2020.102139},
url = {https://www.sciencedirect.com/science/article/pii/S2210670720301268},
author = {Hadi Zahmatkesh and Fadi Al-Turjman},
keywords = {IoT, Fog computing, Smart-cities, Caching, UAV, Machine learning},
abstract = {In recent decade, the number of devices involved with the Internet of Things (IoT) phenomena has increased dramatically. Parallel to this, fog computing paradigm has been introduced in order to support the computational demand of latency-sensitive and real-time IoT applications. The main support the fog paradigm can provide for these applications is through enabling computing at the edge of the network closer to the end users and IoT devices. Moreover, in sustainable smart cities, fog computing can be utilized as an efficient framework to reduce delays and enhance energy efficiency of the system. This article considers possible fog computing applications and potential enabling technologies towards sustainable smart cities in the IoT environments. In addition, different caching techniques and the use of Unmanned Aerial Vehicles (UAVs), and various Artificial Intelligence (AI) and Machine Learning (ML) techniques in caching data for fog-based IoT systems are comprehensively discussed. Finally, the potential and challenges of such systems are also highlighted.}
}
@article{YAN2021130,
title = {An adaptive nonlinear filter for integrated navigation systems using deep neural networks},
journal = {Neurocomputing},
volume = {446},
pages = {130-144},
year = {2021},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2021.03.046},
url = {https://www.sciencedirect.com/science/article/pii/S0925231221004203},
author = {Fei Yan and Sheng Li and Enze Zhang and Jian Guo and Qingwei Chen},
keywords = {Adaptive nonlinear filter, Deep neural networks, Sensor analyzer, Integrated navigation systems},
abstract = {This paper presents a novel nonlinear adaptive sensor fusion method for integrated navigation systems with varying noise parameters. The innovation is utilizing deep neural networks to mine the noise-related patterns of specific sensors and combining it with conventional nonlinear filters. This hybrid approach improves the feasibility and robustness of adaptive filtering by achieving an effective estimation of the originally weakly observable noise parameters. The specific sensors are defined as α-type sensors whose errors are entirely generated by themselves. The mathematical model for analyzing α-type sensors output sequence and the deep neural network for mining the patterns of interest are established. All adaptive filtering systems using α-type sensors can benefit from this paper. Specifically, it is applied to inertial and satellite integrated navigation system. The numerical experiments indicate that the proposed filter achieves promising accuracy and robustness improvement as compared to conventional nonlinear filters. And the comparisons between different nonlinear approximation algorithms indicate that the first-order approximation is accurate enough for our application.}
}
@article{LIAO2021105910,
title = {Optical flow estimation combining with illumination adjustment and edge refinement in livestock UAV videos},
journal = {Computers and Electronics in Agriculture},
volume = {180},
pages = {105910},
year = {2021},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2020.105910},
url = {https://www.sciencedirect.com/science/article/pii/S016816992033115X},
author = {Bin Liao and Jinlong Hu and Rick O. Gilmore},
keywords = {Optical flow estimation, Illumination adjustment, Edge refinement, Livestock UAV video analysis},
abstract = {The performance of optical flow estimation is affected by many factors. The impact of illumination changes and video quality degradation in unmanned aerial vehicles videos on optical flow estimation cannot be ignored. Inspired by the human retina’s visual adaptation mechanism, we propose a mechanism for illumination adjustment that imitates retinal processing in order to reduce illumination variation. We further introduce an edge refinement mechanism into optical flow estimation that is based on a weighted neighborhood filtering. The experimental results on public benchmarks inlcuding KITTI 2012, KITTI 2015, MPI Sintel and Middlebury show that the proposed approach is robust on illumination and preserves accurate motion details. Further, experiments on outdoor livestock UAV videos show that the proposed approach implements illumination robustness and preserves the accurate detection of motion edges in other types of video. The performance of the proposed method on public benchmarks and livestock UAV videos demonstrates that the proposed approach improves motion edge accuracy of optical flow fields in varying illumination.}
}
@article{SHIN2011109,
title = {Adaptive support vector regression for UAV flight control},
journal = {Neural Networks},
volume = {24},
number = {1},
pages = {109-120},
year = {2011},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2010.09.011},
url = {https://www.sciencedirect.com/science/article/pii/S0893608010001851},
author = {Jongho Shin and H. {Jin Kim} and Youdan Kim},
keywords = {Support vector regression, Feedback linearization, Unmanned aerial vehicle},
abstract = {This paper explores an application of support vector regression for adaptive control of an unmanned aerial vehicle (UAV). Unlike neural networks, support vector regression (SVR) generates global solutions, because SVR basically solves quadratic programming (QP) problems. With this advantage, the input–output feedback-linearized inverse dynamic model and the compensation term for the inversion error are identified off-line, which we call I-SVR (inversion SVR) and C-SVR (compensation SVR), respectively. In order to compensate for the inversion error and the unexpected uncertainty, an online adaptation algorithm for the C-SVR is proposed. Then, the stability of the overall error dynamics is analyzed by the uniformly ultimately bounded property in the nonlinear system theory. In order to validate the effectiveness of the proposed adaptive controller, numerical simulations are performed on the UAV model.}
}
@article{LADOSZ2019292,
title = {Performance Evaluation of Learning-Based Channel Prediction for Communication Relay UAVs in Urban Environments *⁎This work was supported by the Basic Science Research Program through the Lockheed Martin Corporation Republic of Korea Science, Technology, Research (RoKST&R) Initiative and the National Research Foundation of Korea (NRF) funded by the Ministry of Education (2017R1D1A1B03029992).},
journal = {IFAC-PapersOnLine},
volume = {52},
number = {12},
pages = {292-297},
year = {2019},
note = {21st IFAC Symposium on Automatic Control in Aerospace ACA 2019},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2019.11.258},
url = {https://www.sciencedirect.com/science/article/pii/S2405896319312091},
author = {Pawel Ladosz and Jongyun Kim and Hyondong Oh and Wen-Hua Chen},
keywords = {Unmanned Aerial Vehicles, Communication relay, Gaussian Process regression, Wireless communication model, Urban environment},
abstract = {This paper presents the performance evaluation of the communication channel prediction method based on Gaussian process (GP) regression for relay missions in urban environments. Considering restrictions from outdoor urban flight experiments, a way to simulate complex urban environments at an indoor room scale is introduced. Since water significantly absorbs wireless communication signal, water containers are utilized to replace buildings in a real-world city. To evaluate the performance of the GP-based channel prediction approach, several indoor experiments in an artificial urban environment are conducted. The performance of the GP-based and empirical model-based prediction methods for a relay mission is evaluated by measuring and comparing the communication signal strength at the optimal relay position obtained from each method. The GP-based prediction approach shows an advantage over the model-based one as it provides a reasonable performance without a need for a priori information of the environment (e.g. 3-D map of the city and communication model parameters) in dynamic urban environments.}
}
@article{RAUF2022111903,
title = {Machine learning in state of health and remaining useful life estimation: Theoretical and technological development in battery degradation modelling},
journal = {Renewable and Sustainable Energy Reviews},
volume = {156},
pages = {111903},
year = {2022},
issn = {1364-0321},
doi = {https://doi.org/10.1016/j.rser.2021.111903},
url = {https://www.sciencedirect.com/science/article/pii/S1364032121011692},
author = {Huzaifa Rauf and Muhammad Khalid and Naveed Arshad},
keywords = {Battery degradation modelling, SOH Estimation, RUL Prediction, Li-ion Batteries, Electric vehicles, Machine learning},
abstract = {Designing and deployment of state-of-the-art electric vehicles (EVs) in terms of low cost and high driving range with appropriate reliability and security are identified as the key towards decarbonization of the transportation sector. Nevertheless, the utilization of lithium-ion batteries face a core difficulty associated with environmental degradation factors, capacity fade, aging-induced degradation, and end-of-life repurposing. These factors play a pivotal role in the field of EVs. In this regard, state-of-health (SOH) and remaining useful life (RUL) estimation outlines the efficacy of the batteries as well as facilitate in the development and testing of numerous EV optimizations with identification of parameters that will enhance and further improve their efficiency. Both indices give an accurate estimation of the battery performance, maintenance, prognostics, and health management. Accordingly, machine learning (ML) techniques provide a significant developmental scope as best parameters and approaches cannot be identified for these estimations. ML strategies comparatively provide a non-invasive approach with low computation and high accuracy considering the scalability and timescale issues of battery degradation. This paper objectively provides an inclusively extensive review on these topics based on the research conducted over the past decade. An in-depth introductory is provided for SOH and RUL estimation highlighting their process and significance. Furthermore, numerous ML techniques are thoroughly and independently investigated based on each category and sub-category implemented for SOH and RUL measurement. Finally, applications-oriented discussion that explicates the advantages in terms of accuracy and computation is presented that targets to provide an insight for further development in this field of research.}
}
@article{PUTRA2021110482,
title = {Evaluating in-situ maize chlorophyll content using an external optical sensing system coupled with conventional statistics and deep neural networks},
journal = {Measurement},
pages = {110482},
year = {2021},
issn = {0263-2241},
doi = {https://doi.org/10.1016/j.measurement.2021.110482},
url = {https://www.sciencedirect.com/science/article/pii/S026322412101366X},
author = {Bayu Taruna Widjaja Putra and Hendra Cipta Wirayuda and Wahyu Nurkholis Hadi Syahputra and Erwin Prastowo},
keywords = {Chlorophyll, Leaf greenness, Android, External camera, Deep neural network, Zoning maps},
abstract = {Plant conditions can be monitored by direct-leaf measurements. For this purpose, several researchers have developed applications based on smartphone cameras, but the variable quality of smartphone cameras, even those of the same brand, produces non-standardized results. The present study describes a new and reliable technique that measures the chlorophyll content of maize leaves for plant monitoring on any smartphone. To check the accuracy of the data generated by the developed handheld optical sensing system, the obtained data were compared against those of an established chlorophyll-monitoring meter (a SPAD-502 monitor). The required SPAD, RGB, and global positioning system data were collected from maize fields (∼2 ha) at the research farm of the Indonesian Coffee and Cocoa Research Institute. The collected data were analyzed using conventional statistics/regression analysis and a deep neural network (DNN). The inverse-distance weighted outputs were interpolated to generate zoning maps. In a conventional statistics/regression analysis, the chlorophyll levels were significantly correlated with the SPAD values (R2 = 0.82–0.84, root mean squared error [RMSE] = 2.95–3.05). However, after applying the DNN with 12 extracted input features, four hidden layers, and 637 parameters, the chlorophyll content estimation was significantly improved (R2 and RMSE = 0.89 and 2.6, respectively), and the zoning map generated by the developed system was nearly aligned with the SPAD zoning map. The findings confirm that this technique is applicable to all types of smartphones regardless of their camera properties and provides the light-aided intensity necessary for direct-leaves measurement. The locations of the collected leaves were simultaneously monitored in real-time to generate the mapping results.}
}
@article{MORIYA2021106298,
title = {Detection and mapping of trees infected with citrus gummosis using UAV hyperspectral data},
journal = {Computers and Electronics in Agriculture},
volume = {188},
pages = {106298},
year = {2021},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2021.106298},
url = {https://www.sciencedirect.com/science/article/pii/S016816992100315X},
author = {Érika Akemi Saito Moriya and Nilton Nobuhiro Imai and Antonio Maria Garcia Tommaselli and Adilson Berveglieri and Guilherme Henrique Santos and Márcio Augusto Soares and Marcelo Marino and Thiago Tiedtke Reis},
keywords = {Citrus gummosis, Remote sensing, Precision agriculture, Health map},
abstract = {Monitoring citrus diseases and pests in early stages is fundamental to ensure the efficiency of phytosanitary control and plant health. The various diseases caused by fungi, bacteria, viruses, and pests limit citrus production. Citrus gummosis disease, caused by the fungus Phytophthora spp., is the main fungal disease of citrus in Brazil. The lesions caused to the trunk and roots by Phytophthora spp. lead losses in production, foot and root rot, brown fruit rot, canopy discoloration and leaf yellowing. Remote sensing is a nondestructive detection technology, that has been used to detect phytosanitary problems in agricultural crops. Multi and hyperspectral sensors on board unmanned aerial vehicles (UAVs) have been extensively applied in agriculture. In this study, the capability for the detection of citrus gummosis was evaluated in two data sets. The first one considered hyperspectral images acquired with a 25 band sensor covering a spectral range from 500 nm to 840 nm, and the second data set was a simulated 3 band of multispectral sensor. The results indicated a better performance for the detection of citrus gummosis with the hyperspectral images than with three bands multispectral images. The high dimensionality of the hyperspectral data and the detailed spectral information allowed a more accurate classification of citrus gummosis infected plants. The classification maps were validated with field data and achieved an accuracy of 0.79 (F-score = 0.55) for the health map produced with multispectral data and an accuracy of 0.94 (F-score = 0.85) for the health map produced by the hyperspectral data.}
}
@article{CHEN2021103503,
title = {Geo-registering UAV-captured close-range images to GIS-based spatial model for building façade inspections},
journal = {Automation in Construction},
volume = {122},
pages = {103503},
year = {2021},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2020.103503},
url = {https://www.sciencedirect.com/science/article/pii/S0926580520310839},
author = {Kaiwen Chen and Georg Reichard and Abiola Akanmu and Xin Xu},
keywords = {UAV, Building façade inspection, Close-range images, Geo-registration, GIS-based spatial model},
abstract = {There is a growing trend in the application of Unmanned Aerial Vehicle (UAV) systems for visual inspection of building facades. Current practices remain at a low efficiency to manage the large amount of UAV-collected close-range façade images to support the inspection and documentation of façade anomalies such as cracks and corrosions. This paper proposes a GIS-based two-step procedure to streamline the process of the management of UAV-collected images for supporting building façade inspection. First, a 2D GIS spatial model of building façades is created by net-unfolding façade surfaces around the building footprint in GIS to store the geometric and geographic information of building façades. Then, the UAV-collected images are automatically geo-registered to the 2D GIS spatial model through computer vision techniques applied in GIS. An experimental case study is also presented to demonstrate the process and evaluate the performance of the proposed method. It is demonstrated that the GIS-based spatial model of net-unfolded building façades allows for an efficient and effective registration of UAV-captured close-range façade images without apparent loss of pixel data. Provided with image data processing capabilities to detect and assess facade anomalies, the proposed GIS-based workflow can contribute to an automated documentation of UAV-based façade inspections to support the decision-making of further maintenance actions.}
}
@article{PETROVIC2021104398,
title = {Fair classification via Monte Carlo policy gradient method},
journal = {Engineering Applications of Artificial Intelligence},
volume = {104},
pages = {104398},
year = {2021},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2021.104398},
url = {https://www.sciencedirect.com/science/article/pii/S0952197621002463},
author = {Andrija Petrović and Mladen Nikolić and Miloš Jovanović and Miloš Bijanić and Boris Delibašić},
keywords = {Fairness, Reinforcement learning, REINFORCE, Deep learning, Combinatorial optimization},
abstract = {Artificial intelligence is steadily increasing its impact on everyday life. Therefore, the societal issues of artificial intelligence have become an important concern in the AI research. The presence of data that reflects human biases towards historically discriminated groups defined by sensitive features such as race and gender, results in machine learning models which discriminate against these groups. In order to tackle the impact of bias in data, researchers developed a variety of specialized machine learning algorithms which are able to satisfy different fairness constraints imposed on the model. Group fairness constraints do not fit standard machine learning formulations easily due to their non-differentiable nature. In this paper we developed a technique for learning a fair classifier by Monte Carlo policy gradient method which naturally deals with such non-differentiable constraints. Our methodology focuses on direct optimization of both group fairness metric and predictive performance of the model. In addition, we propose two different variance reduction techniques of gradient estimation. We compare our models to seven other related and state-of-the-art models and demonstrate that they are able to achieve better trade-off between accuracy and unfairness. To the best of our knowledge, this is the first fair classification algorithm which solves the issue of non-differentiable constraints by reinforcement learning techniques.}
}
@article{ZHOU2019305,
title = {Scale adaptive image cropping for UAV object detection},
journal = {Neurocomputing},
volume = {366},
pages = {305-313},
year = {2019},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2019.07.073},
url = {https://www.sciencedirect.com/science/article/pii/S092523121931080X},
author = {Jingkai Zhou and Chi-Man Vong and Qiong Liu and Zhenyu Wang},
keywords = {Data enhancement, UAV aerial imagery, Object detection, Deep neural network},
abstract = {Although deep learning methods have made significant breakthroughs in generic object detection, their performance on aerial images is not satisfactory. Unlike generic images, aerial images have smaller object relative scales (ORS), more low-resolution objects, and serious object scale diversity. Most researches focus on modifying network structures to address these challenges, while few studies pay attention to data enhancement which can be used in combination with model modification to further improve detection accuracy. In this work, a novel data enhancement method called scale adaptive image cropping (SAIC) is proposed to address these three challenges. Specifically, SAIC consists three steps: ORS estimation in which a specific neural network is designed to estimate ORS levels of images; image resizing in which a GAN-based super-resolution method is adopted to up-sample images with the smallest ORS level, easing low-resolution object detection; image cropping in which three cropping strategies are proposed to crop resized images, adjusting ORS. Extensive experiments are conducted to demonstrate the effectiveness of our method. SAIC improves the accuracy of feature pyramid network (FPN) by 9.65% (or relatively 37.06%). Without any major modification, FPN trained with SAIC won the 3rd rank on 2018 VisDrone challenge detection task.}
}
@article{LIU2021112308,
title = {Change detection using deep learning approach with object-based image analysis},
journal = {Remote Sensing of Environment},
volume = {256},
pages = {112308},
year = {2021},
issn = {0034-4257},
doi = {https://doi.org/10.1016/j.rse.2021.112308},
url = {https://www.sciencedirect.com/science/article/pii/S0034425721000262},
author = {Tao Liu and Lexie Yang and Dalton Lunga},
keywords = {Change detection, OBIA, Deep learning, Pixel-based, Feature fusion},
abstract = {In their applications, both deep learning techniques and object-based image analysis (OBIA) have shown better performance separately than conventional methods on change detection tasks. However, efforts to investigate the effect of combining these two techniques for advancing change detection techniques are unexplored in current literature. This study proposes a novel change detection method implementing change feature extraction using convolutional neural networks under an OBIA framework. To demonstrate the effectiveness of our proposed method, we compare the proposed method against benchmark pixel-based counterparts on aerial images for the task of multi-class change detection. To thoroughly assess the performance of our proposed method, this study also for the first time compared three common feature fusion schemes for change detection architecture: concatenation, differencing, and Long Short-Term Memory (LSTM). The proposed method was also tested on simulated misregistered images to evaluate its robustness, a factor that plays an important role in compromising change detection accuracy but has not been investigated for supervised change detection methods in the literature. Finally, the proposed change detection method was also tested using very high resolution (VHR) satellite images for binary class change detection to map an impacted area caused by natural disaster and the result was evaluated using reference data from the Federal Emergency Management Agency (FEMA). With the experimental results from these two sets of experiments, we showed that (1) our proposed method achieved substantially higher accuracy and computational efficiency when compared to pixel-based methods, (2) three feature fusion schemes did not show a significant difference for overall accuracy, (3) our proposed method was robust in image misregistration in both testing and training data, (4) we demonstrate the potential impact of automation to decision making by deploying our method to map a large geographic area affected by a recent natural disaster.}
}
@article{ZHANG2021339,
title = {A novel voting convergent difference neural network for diagnosing breast cancer},
journal = {Neurocomputing},
volume = {437},
pages = {339-350},
year = {2021},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2021.01.083},
url = {https://www.sciencedirect.com/science/article/pii/S0925231221001594},
author = {Zhijun Zhang and Bozhao Chen and Songqing Xu and Guangqiang Chen and Jilong Xie},
keywords = {Neural dynamic algorithm, Convergent difference neural network, Mapping function, Voting strategy, Breast cancer diagnosis},
abstract = {Breast cancer is one of the most frequently occurred cancers for females, and thus diagnosing breast cancer is very important. Neural dynamic algorithm (NDA) has been successfully applied in many fields with the characteristics of parallel computing and exponential convergence. However, there is no research on applying NDA-based neural network for pattern classification. In this paper, a novel voting convergent difference neural network (V-CDNN) is proposed. To do so, samples are firstly handled by feature selection, feature weighting and sample normalization. Secondly, the preprocessed samples are used to simultaneously and independently train several convergent difference neural networks in different types of mapping functions. Thirdly, in the testing process, voting strategy for these networks is applied to make diagnosis results more accurate and convincing. Being different from most existing neural networks, the proposed V-CDNN adopts neural dynamic learning algorithm, which greatly improves computation efficiency and increases accuracy rate of diagnosis. Experimental results verify that the proposed V-CDNN can achieve 100% average diagnosis accuracy, which is the highest among existing state-of-the-art methods on the open data set.}
}
@article{ZHOU2021107076,
title = {Diagnosis of winter-wheat water stress based on UAV-borne multispectral image texture and vegetation indices},
journal = {Agricultural Water Management},
volume = {256},
pages = {107076},
year = {2021},
issn = {0378-3774},
doi = {https://doi.org/10.1016/j.agwat.2021.107076},
url = {https://www.sciencedirect.com/science/article/pii/S0378377421003413},
author = {Yongcai Zhou and Congcong Lao and Yalong Yang and Zhitao Zhang and Haiying Chen and Yinwen Chen and Junying Chen and Jifeng Ning and Ning Yang},
keywords = {Unmanned aerial vehicle, Vegetation indices, Image texture, Stomatal conductance, Water stress},
abstract = {Timely and accurate detection of crop water stress is vital for precision irrigation. Whether the accuracy of the prevailing diagnosis of crop water stress using vegetation indices (VIs) and spectral reflectance can be improved still remains to be investigated. The crop surface characteristics such as grayscale or color vary under different water stress, so in this study one more variable, image texture, was utilized together to diagnose water stress. For this end, the canopy image of winter wheat in bloom was obtained by unmanned aerial vehicle (UAV) equipped with multispectral sensor, and the effect of soil background was eliminated using vegetation index threshold method. On this basis, Grey level co-occurrence matrix (GLCM) was used to calculate the mean (MEA), variance (VAR), homogeneity (HOM), contrast (CON), dissimilarity (DIS), entropy (ENT), second moment (SEC) and correlation (COR) of the image texture under different spatial resolutions (0.008 m, 0.01 m, 0.02 m, 0.05 m, 0.1 m and 0.2 m). Next, the canopy vegetation indices were obtained by mathematical transformation of canopy reflectance, and then sensitive image texture and vegetation indices by full subset regression method. Finally, Cubist, BPNN (Back Propagation Neural Network) and ELM (Extreme Learning Machine) methods were adopted to build the estimation models of the stomatal conductance (Gs) of winter wheat (between the sensitive image texture and Gs, and between vegetation index and Gs), and the water stress map was plotted based on the optimal Gs estimation model. The result showed: (i) the image texture obtained from the high-resolution multispectral image had a high correlation with Gs, and the image texture (VAR, HOM, CON, DIS, ENT and SEC) at 550 nm had the most significant correlation; (ii) the higher the ground resolution, the higher the correlation between the Gs and the image texture, the vegetation indices, respectively. The image texture with a ground resolution of 0.008 m combined with VIs and Gs had the highest correlation, and combining image texture and vegetation index can significantly improve the estimation accuracy of winter wheat Gs; (iii) Among the three estimation models, the BPNN model constructed by combining the image texture and VIs (MEA, VAR, ENT, DWSI and EXG) had the best estimation performance (Calibration:Rc2 = 0.899, RMSEc = 0.01, MAEc = 0.006; Validation:Rc2 = 0.834, RMSEv =;0.018, MAEv = 0.014), and an accurate estimation could even be achieved at a lower Gs value. Compared with the BPNN model solely based on VIs or image texture, the Rc2 of the BPNN model based on the combined variables increased by 24% and 22.48%, respectively. Therefore, combining UAV multispectral image texture and VIs to estimate Gs provides a feasible and accurate method for water stress diagnosis of winter wheat.}
}
@article{XU2021102466,
title = {Joint trajectory and transmission optimization for energy efficient UAV enabled eLAA network},
journal = {Ad Hoc Networks},
volume = {116},
pages = {102466},
year = {2021},
issn = {1570-8705},
doi = {https://doi.org/10.1016/j.adhoc.2021.102466},
url = {https://www.sciencedirect.com/science/article/pii/S1570870521000354},
author = {Chan Xu and Deshi Li and Qimei Chen and Mingliu Liu and Kaitao Meng},
keywords = {UAV communications, LAA, Energy efficiency, Trajectory optimization},
abstract = {Unmanned aerial vehicle (UAV) as a carrier of small cell base station (SBS) becomes a promising solution to reduce infrastructure deployment cost. At the same time, Licensed-assisted Access (LAA) is proposed by 3GPP to apply the Long Term Evolution (LTE) technology into the unlicensed spectrum to expand the available bandwidth. To enhance and supplement the next generation 5G wireless network, this paper integrates LAA technology into UAV network to provide communication service for high-density mobile users. An enhanced LAA (eLAA) network is adopted to coordinate unlicensed band for LTE and WiFi by leveraging IEEE 802.11e protocol. The limited on-board energy is the main challenge for UAV to support mobility and communication. Under the UAV enabled eLAA network, we propose a joint trajectory design and transmission optimization algorithm to maximize the energy efficiency (EE) of the UAV. Firstly, for single UAV network, the formulated nonlinear fractional problem is solved by block coordinate descent (BCD) method and Dinkelbach-type algorithm. Our algorithm is proved to converge to a stationary point of the original nonconvex problem. Then, the proposed algorithm is extended to multi-UAV network through the sum-of-ratios algorithm. Numerical results demonstrate that the EE performance is significantly improved by UAV mobility. Based on the optimal trajectories, frequency reuse among multiple UAVs can further improve the EE performance.}
}
@article{WANG20221494,
title = {Mapping mangrove species using combined UAV-LiDAR and Sentinel-2 data: Feature selection and point density effects},
journal = {Advances in Space Research},
volume = {69},
number = {3},
pages = {1494-1512},
year = {2022},
issn = {0273-1177},
doi = {https://doi.org/10.1016/j.asr.2021.11.020},
url = {https://www.sciencedirect.com/science/article/pii/S0273117721008693},
author = {Dezhi Wang and Bo Wan and Penghua Qiu and Xiang Tan and Quanfa Zhang},
keywords = {Mangrove species, LiDAR, Sentinel-2, Feature selection, Point density},
abstract = {Mapping mangrove species is important for mangrove conservation and rehabilitation. However, due to the similar spectral signatures of most mangrove species, accurately mapping mangrove species remains an ongoing challenge. Unmanned aerial vehicles paired with light detection and ranging sensors (UAV-LiDAR) have the potential to increase separability between mangrove species by providing vertical structure information with high flexibility and low cost and could be complementary to optical imagery. In this study, we combined UAV-LiDAR and Sentinel-2 data to classify mangrove species in two representative mangrove forests in China. Moreover, an architecture diagram of important features for discriminating mangrove species was first constructed using a modified recursive feature elimination method and a proposed step-by-step method, including hierarchical clustering, scatterplots, and boxplots. This architecture diagram could indicate the specific role of each feature (or group) in demarcating specific mangrove species and help other mangrove studies prepare candidate features. The combined UAV-LiDAR and Sentinel-2 data produced the highest overall accuracies of 85.60% and 91.61% in the Dongzhaigang National Nature Reserve and Qinglangang Provincial Nature Reserve areas, respectively, compared to those of the Sentinel-2 (80.00% and 80.42%, respectively) and UAV-LiDAR (77.60% and 75.52%, respectively) data alone by using the novel canonical correlation forest algorithm. Important LiDAR features included metrics describing the top, bottom, and overall (e.g., Hstd and GM2nd) morphological characteristics of the mangrove canopy, which characterized the vertical stratification and shape of the canopy. The added value of the UAV-LiDAR data mainly lies in improving the separability between shrub-like mangroves and arbor mangroves that had similar spectral signatures, such as A. marina and R. stylosa. The point density might have little effect on feature selection and classification accuracy, while 10% of the initial point density (∼10 pts/m2) could produce similar accuracy (differences less than 0.5%). This study suggests that the combined UAV-LiDAR and Sentinel-2 data provide a cost-efficient and accurate approach for mangrove species classification.}
}
@article{AMORIM2020113437,
title = {Assessing a swarm-GAP based solution for the task allocation problem in dynamic scenarios},
journal = {Expert Systems with Applications},
volume = {152},
pages = {113437},
year = {2020},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2020.113437},
url = {https://www.sciencedirect.com/science/article/pii/S095741742030261X},
author = {Junier Caminha Amorim and Vander Alves and Edison Pignaton {de Freitas}},
keywords = {Unmanned aerial vehicles, Task allocation, Swarm intelligence, Replication, Dynamic},
abstract = {Swarm-GAP is a heuristic that combines a swarm intelligence strategy with the generalized assignment problem (GAP) method. This approach is especially appropriate when there are agents engaged in a collaborative task, but in general, heuristics have drawbacks to optimize resource allocation. A previous work proposed the usage of three swarm-GAP variants to solve the task allocation problem among agents representing a group of Unmanned Aerial Vehicles (UAVs) aiming at the optimization of their resources usage applied in the context of static environments. However, there is a lack of empirical assessment of these algorithms in dynamic scenarios, i.e., with some attributes changing along the system execution. Such changes represent important features of real-world application scenarios, such as in military operations in which a number of non-expected events may happen, e.g., loss of members of the UAV-team or onboard sensor failure. Therefore, the contributions of this work are the performance evaluation of the original algorithms in dynamic context, and the extension of these algorithms to properly address more realistic dynamic scenarios. Considering changes in some attributes of the environment, a trade-off in terms of the quality in the mission performance and the overhead in the communication among the UAVs is explored. The empirical assessment of the original algorithms and the proposed extensions were performed by conducting independent replications in a scenario where the number of agents (UAVs) changes at runtime and adaptations occur autonomously to maintain the mission execution. The acquired results provide evidence that the proposed solution is capable of dealing with dynamic scenarios, covering the gap left by other works in the literature, and enriching the realism of applications in autonomous intelligent systems.}
}
@article{MAZZIA2021106091,
title = {DeepWay: A Deep Learning waypoint estimator for global path generation},
journal = {Computers and Electronics in Agriculture},
volume = {184},
pages = {106091},
year = {2021},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2021.106091},
url = {https://www.sciencedirect.com/science/article/pii/S0168169921001095},
author = {Vittorio Mazzia and Francesco Salvetti and Diego Aghi and Marcello Chiaberge},
keywords = {Deep learning, Unmanned ground vehicles, Precision agriculture, Global path planning},
abstract = {Agriculture 3.0 and 4.0 have gradually introduced service robotics and automation into several agricultural processes, mostly improving crops quality and seasonal yield. Row-based crops are the perfect settings to test and deploy smart machines capable of monitoring and manage the harvest. In this context, global path generation is essential either for ground or aerial vehicles, and it is the starting point for every type of mission plan. Nevertheless, little attention has been currently given to this problem by the research community and global path generation automation is still far to be solved. In order to generate a viable path for an autonomous machine, the presented research proposes a feature learning fully convolutional model capable of estimating waypoints given an occupancy grid map. In particular, we apply the proposed data-driven methodology to the specific case of row-based crops with the general objective to generate a global path able to cover the extension of the crop completely. Extensive experimentation with a custom made synthetic dataset and real satellite-derived images of different scenarios have proved the effectiveness of our methodology and demonstrated the feasibility of an end-to-end and completely autonomous global path planner.}
}
@article{ZICHEN2021102573,
title = {Comparison of the backpropagation network and the random forest algorithm based on sampling distribution effects consideration for estimating nonphotosynthetic vegetation cover},
journal = {International Journal of Applied Earth Observation and Geoinformation},
volume = {104},
pages = {102573},
year = {2021},
issn = {0303-2434},
doi = {https://doi.org/10.1016/j.jag.2021.102573},
url = {https://www.sciencedirect.com/science/article/pii/S0303243421002804},
author = {Guo Zi–chen and Wang Tao and Liu Shu–lin and Kang Wen–ping and Chen Xiang and Feng Kun and Zhi Ying},
keywords = {UAV, Nonphotosynthetic vegetation cover, Mu Us sandy land, Random forests, Backpropagation neural network, The sampling distribution},
abstract = {Non–photosynthetic vegetation (NPV) plays a crucial role in arid and semi-arid ecosystems. Remote sensing methods can extract NPV information accurately and quantitatively, which helps in studying the water use, community health, and climate response of vegetation communities. This study used the backpropagation network (BP) and random forest (RF) methods to test NPV cover extraction from Landsat 8-OLI images in Mu Us Sandy Land. Pixel-level NPV cover, photosynthetic vegetation (PV) cover, and bare soil (BS) cover from unmanned aerial vehicle (UAV) field sampling data were used to model the BP and RF. After the generalisation ability of the NPV detection model of BP and RF was evaluated using ten-fold cross-validation, the influence of the distribution of sampling data on BP and RF fitting results was also evaluated. The results were as follows: 1. Considering the selection of appropriate parameters and input layers, both BP and RF exhibited high accuracy in detecting NPV, and the detection accuracy of the RF algorithm for PV and BS was slightly higher than that of the BP algorithm (R2RF-NPV = 0.8426, R2BP-NPV = 0.8277, R2RF-PV = 0.8606, R2BP-PV = 0.8514, R2RF-BS = 0.8123, R2BP-BS = 0.7396). 2. When the BP and RF algorithms were used for geospatial continuous value prediction, the distribution of samples affected the final prediction results. The RF algorithm is less sensitive to the sample data distribution. 3. The random sampling method is the best method for collecting training samples. Even with uniform sampling, when there was a large difference between the distribution of the sampling value and the distribution of the real value, the fitting result would have a large deviation. This paper provides suggestions for the fitting of nonphotosynthetic vegetation in arid and semi-arid regions and provides a new method for evaluating the results of remote sensing regression fitting.}
}
@article{PEREZORTIZ201685,
title = {Selecting patterns and features for between- and within- crop-row weed mapping using UAV-imagery},
journal = {Expert Systems with Applications},
volume = {47},
pages = {85-94},
year = {2016},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2015.10.043},
url = {https://www.sciencedirect.com/science/article/pii/S0957417415007472},
author = {María Pérez-Ortiz and José Manuel Peña and Pedro Antonio Gutiérrez and Jorge Torres-Sánchez and César Hervás-Martínez and Francisca López-Granados},
keywords = {Remote sensing, Unmanned aerial vehicles (UAV), Weed detection, Object based image analysis},
abstract = {This paper approaches the problem of weed mapping for precision agriculture, using imagery provided by Unmanned Aerial Vehicles (UAVs) from sunflower and maize crops. Precision agriculture referred to weed control is mainly based on the design of early post-emergence site-specific control treatments according to weed coverage, where one of the most important challenges is the spectral similarity of crop and weed pixels in early growth stages. Our work tackles this problem in the context of object-based image analysis (OBIA) by means of supervised machine learning methods combined with pattern and feature selection techniques, devising a strategy for alleviating the user intervention in the system while not compromising the accuracy. This work firstly proposes a method for choosing a set of training patterns via clustering techniques so as to consider a representative set of the whole field data spectrum for the classification method. Furthermore, a feature selection method is used to obtain the best discriminating features from a set of several statistics and measures of different nature. Results from this research show that the proposed method for pattern selection is suitable and leads to the construction of robust sets of data. The exploitation of different statistical, spatial and texture metrics represents a new avenue with huge potential for between and within crop-row weed mapping via UAV-imagery and shows good synergy when complemented with OBIA. Finally, there are some measures (specially those linked to vegetation indexes) that are of great influence for weed mapping in both sunflower and maize crops.}
}
@article{JIANG201935,
title = {Outage probability optimization for UAV-enabled wireless relay networks in fading channels},
journal = {Physical Communication},
volume = {33},
pages = {35-45},
year = {2019},
issn = {1874-4907},
doi = {https://doi.org/10.1016/j.phycom.2018.12.013},
url = {https://www.sciencedirect.com/science/article/pii/S1874490718304658},
author = {Xu Jiang and Zhendong Yin and Zhilu Wu and Zhutian Yang and Jinlong Sun},
keywords = {Decode-and-forward (DF), Mobile relay, Outage probability, Time and power allocation, Unmanned aerial vehicle (UAV)},
abstract = {In this paper, we consider a mobile wireless relaying system, where a fixed-wing unmanned aerial vehicle (UAV) flies in a circular manner to provide continuous relaying between two disconnected ground stations. The system employs a UAV to ferry data from source to destination in a time division (TD) manner with limited energy budget. To improve the outage performance of this system in fading channels, we develop time and power allocation schemes for the source and relay nodes. Our approach does not depend on instantaneous channel state information. Instead, we assume that only channel statistics (i.e., mean and variance) are known at the transmitters. In Rayleigh fading channel, we show that the outage probability optimization problem is a convex optimization problem, which can be solved by standard convex optimization techniques. In Rician fading channel, we develop an asymptotic optimal time and power allocation scheme to minimize the outage probability in high signal-to-noise ratio (SNR) regime. Our derivation indicates that the proposed time and power allocation schemes in Rayleigh channel and Rician channel are identical. Numerical results show that significant improvement can be obtained through the proposed time and power allocation schemes.}
}
@article{ALSAMHI2021102505,
title = {Green internet of things using UAVs in B5G networks: A review of applications and strategies},
journal = {Ad Hoc Networks},
volume = {117},
pages = {102505},
year = {2021},
issn = {1570-8705},
doi = {https://doi.org/10.1016/j.adhoc.2021.102505},
url = {https://www.sciencedirect.com/science/article/pii/S1570870521000639},
author = {S.H. Alsamhi and Fatemeh Afghah and Radhya Sahal and Ammar Hawbani and Mohammed A.A. Al-qaness and B. Lee and Mohsen Guizani},
keywords = {Green IoT, Energy efficiency, UAVs, B5G, Information and communication technology (ICT), IoT, Pollution monitoring, Industry 4.0, Smart cities},
abstract = {Recently, Unmanned Aerial Vehicles (UAVs) present a promising advanced technology that can enhance people life quality and smartness of cities dramatically and increase overall economic efficiency. UAVs have attained a significant interest in supporting many applications such as surveillance, agriculture, communication, transportation, pollution monitoring, disaster management, public safety, healthcare, and environmental preservation. Industry 4.0 applications are conceived of intelligent things that can automatically and collaboratively improve beyond 5G (B5G). Therefore, the Internet of Things (IoT) is required to ensure collaboration between the vast multitude of things efficiently anywhere in real-world applications that are monitored in real-time. However, many IoT devices consume a significant amount of energy when transmitting the collected data from surrounding environments. Due to a drone's capability to fly closer to IoT, UAV technology plays a vital role in greening IoT by transmitting collected data to achieve a sustainable, reliable, eco-friendly Industry 4.0. This survey presents an overview of the techniques and strategies proposed recently to achieve green IoT using UAVs infrastructure for a reliable and sustainable smart world. This survey is different from other attempts in terms of concept, focus, and discussion. Finally, various use cases, challenges, and opportunities regarding green IoT using UAVs are presented.}
}
@article{MOUSAVI201926,
title = {Use of a quantum genetic algorithm for coalition formation in large-scale UAV networks},
journal = {Ad Hoc Networks},
volume = {87},
pages = {26-36},
year = {2019},
issn = {1570-8705},
doi = {https://doi.org/10.1016/j.adhoc.2018.11.008},
url = {https://www.sciencedirect.com/science/article/pii/S1570870518303044},
author = {Sajad Mousavi and Fatemeh Afghah and Jonathan D. Ashdown and Kurt Turck},
keywords = {Unmanned aerial vehicles, Coalition formation, Task allocation, Evolutionary algorithms, Quantum genetic algorithm},
abstract = {Task allocation among a network of heterogeneous resource-constrained Unmanned Aerial Vehicles (UAVs) in an unknown and remote environment is still a challenging problem noting the limited available information about highly dynamic environment, lack of continuous and reliable communication network, and the limited energy and resources available at the UAVs. One solution for this such allocation problem is to form several efficient coalitions of the UAVs, where a complex task is assigned to a group of agents (i.e., a coalition) carrying the required resources/capabilities to perform this task. In this paper, inspired by Quantum Evolutionary Algorithms, we propose a leader-follower coalition formation algorithm in a large-scale UAV network to form the best possible coalitions of agents to accomplish the detected tasks in an unknown environment. Three main objectives have been considered in this coalition formation: (i) minimizing resource consumption in completing the assigned tasks on time; (ii) enhancing the reliability of the coalitions; and (iii) considering the most trustworthy UAVs amid the self-interested UAVs in forming the coalitions. The simulation results demonstrate the superior performances of the proposed model in different scenarios with large number of UAVs compared to existing coalition formation algorithms such as merge-and-split and a famous multi-objective genetic algorithm called NSGA-II.11DISTRIBUTION A. Approved for public release: distribution unlimited. Case Number: 88ABW-2018-0096. Dated 10 Jan 2018.22An earlier version of this work was presented at 2018 INFOCOM Workshop on WISARN: Wireless Sensor, Robot and UAV Networks, Honolulu, HI.}
}
@article{XU2022181,
title = {Path planning and dynamic collision avoidance algorithm under COLREGs via deep reinforcement learning},
journal = {Neurocomputing},
volume = {468},
pages = {181-197},
year = {2022},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2021.09.071},
url = {https://www.sciencedirect.com/science/article/pii/S0925231221014491},
author = {Xinli Xu and Peng Cai and Zahoor Ahmed and Vidya Sagar Yellapu and Weidong Zhang},
keywords = {Unmanned surface vehicle, COLREGs, Dynamic collision avoidance, DDPG, Cumulative priority sampling mechanism},
abstract = {As one of the core technologies of the automatic control system for unmanned surface vehicles (USVs), autonomous collision avoidance algorithm is the key to ensure the safe navigation of USVs. In this paper, path planning and dynamic collision avoidance (PPDC) algorithm which obeys COLREGs is proposed for USVs. In order to avoid unnecessary collision avoidance actions, the risk assessment model is developed, which is used to determine the switching time of path planning and dynamic collision avoidance. In order to train the algorithm which complies with the COLREGs, the encounter situation is divided quantitatively, which is regarded as the input state of the system, so that the high-dimensional input is successfully avoided. The state space of the USV is defined by relative parameters to improve the generalization ability of the algorithm, meanwhile, a network structure based on DDPG is designed to achieve the continuous output of thrust and rudder angle. Combined with path planning, collision avoidance, compliance with COLREGs and smooth arrival task, four kinds of reward functions are designed. In order to solve the problem of low training efficiency of experience replay mechanism in DDPG, cumulative priority sampling mechanism is proposed. Through the simulation and verification in a variety of scenarios, it is proved that PPDC algorithm has the function of path planning and dynamic collision avoidance in compliance with COLREGs, which has good real-time performance and security.}
}
@article{PYO2020116349,
title = {Using convolutional neural network for predicting cyanobacteria concentrations in river water},
journal = {Water Research},
volume = {186},
pages = {116349},
year = {2020},
issn = {0043-1354},
doi = {https://doi.org/10.1016/j.watres.2020.116349},
url = {https://www.sciencedirect.com/science/article/pii/S004313542030885X},
author = {JongCheol Pyo and Lan Joo Park and Yakov Pachepsky and Sang-Soo Baek and Kyunghyun Kim and Kyung Hwa Cho},
keywords = {Convolutional neural network, EFDC, Synthetic data, Microcystis, Prediction},
abstract = {Machine learning modeling techniques have emerged as a potential means for predicting algal blooms. In this study, synthetic spatio-temporal water quality data for a river section were generated with a 3D water quality model and used to investigate the capability of a convolutional neural network (CNN) for predicting harmful cyanobacterial blooms. The CNN model displayed a reasonable capacity for short-term predictions of cyanobacteria (Microcystis) biomass. In the nowcasting of Microcystis, the CNN performance had a Nash-Sutcliffe Efficiency (NSE) of 0.87. An increase in the forecast lead time resulted in a decrease in the prediction accuracy, reducing the NSE from 0.87 to 0.58. As the spatial observation density increased from 20% to 100% of the input image grids, the CNN prediction NSE had improved from 0.70 to 0.84. Adding noise to the data resulted in accuracy deterioration, but even at the noise amplitude of 10%, the accuracy was acceptable for some applications, with NSE = 0.76. Visualization of the CNN results characterized its performance variations across the studied river reach. Overall, this study successfully demonstrated the capability of the CNN model for cyanobacterial bloom prediction using high temporal frequency images.}
}
@article{LI2018313,
title = {Training a robust reinforcement learning controller for the uncertain system based on policy gradient method},
journal = {Neurocomputing},
volume = {316},
pages = {313-321},
year = {2018},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2018.08.007},
url = {https://www.sciencedirect.com/science/article/pii/S0925231218309226},
author = {Zhan Li and Shengri Xue and Weiyang Lin and Mingsi Tong},
keywords = {Robust controller, Reinforcement learning, Policy gradient},
abstract = {The target of this paper is to design a model-free robust controller for uncertain systems. The uncertainties of the control system mainly consists of model uncertainty and external disturbance, which widely exist in the practical utilization. These uncertainties will negatively influence the system performance and this motivates us to train a model-free controller to solve this problem. Reinforcement learning is an important branch of machine learning and is able to achieve well performed control results by optimizing a policy without the knowledge of mathematical plant model. In this paper, we construct a reward function module to describe the specific environment of the concerned system, taking uncertainties into account. Then we utilize a new policy gradient method to optimize the policy and implement this algorithm with the actor-critic structure neuro networks. These two networks are our reinforcement learning controllers. Finally, we illustrate the applicability and efficiency of the proposed method by applying it on an experimental helicopter platform model, which includes model uncertainties and external disturbances.}
}
@article{LUNGU2020105526,
title = {Backstepping and dynamic inversion combined controller for auto-landing of fixed wing UAVs},
journal = {Aerospace Science and Technology},
volume = {96},
pages = {105526},
year = {2020},
issn = {1270-9638},
doi = {https://doi.org/10.1016/j.ast.2019.105526},
url = {https://www.sciencedirect.com/science/article/pii/S1270963819305139},
author = {Mihai Lungu},
keywords = {UAV, Landing, Backstepping control, Dynamic inversion, Wind gusts, Sensor errors},
abstract = {Landing of unmanned aerial vehicles (UAVs) is a difficult problem because of their light weight, external disturbances, and strong coupling between the longitudinal and lateral modes. This paper presents the design of a new automatic landing system for fixed wing UAVs subject to wind gusts and errors of the measurement sensors. Using the airplane nonlinear model, a new control approach is proposed. It unifies the backstepping and the dynamic inversion methods to directly control the roll and the yaw angles of the UAV, the flight altitude and the speed (longitudinal plane) by ensuring a constant forward velocity during all the three landing stages. The wind gusts and the three components of the UAV velocity are estimated with a disturbance observer, as part of the auto-landing system. The novel control architecture is software implemented and validated by complex numerical simulations. The obtained characteristics prove the finite time stability and robustness of the new automatic landing system even in the case of landing affected by wind gusts and errors of the sensors.}
}
@article{ALSHAHRANI2021101452,
title = {An automated deep learning based satellite imagery analysis for ecology management},
journal = {Ecological Informatics},
volume = {66},
pages = {101452},
year = {2021},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2021.101452},
url = {https://www.sciencedirect.com/science/article/pii/S1574954121002430},
author = {Haya Mesfer Alshahrani and Fahd N. Al-Wesabi and Mesfer {Al Duhayyim} and Nadhem Nemri and Seifedine Kadry and Bassam A.Y. Alqaralleh},
keywords = {Ecology, Biodiversity, Satellite imagery, Deep learning, CNN, Environment planning},
abstract = {Ecology is the methodical study of biodiversity which affecting natural life and habitats. Due to the anthropogenic pressure on the atmosphere, there is an upraised threat to wild animals and other habitats of the ecological atmosphere. So, there is a need for efficient ecology management models to map and save nature resources. At the same time, the use of satellite imagery analysis is an effective tool for determining important details on earth resources and the platform. It finds useful for proficient ecology management, such as land use detection, forest fire detection, environment planning, and so on. Earlier satellite imagery classification approaches mainly depend upon feature coding approaches which has limited capabilities and yield mediocre outcomes. The recent developments of deep learning models made the image classification highly effective. In this view, this paper presents a new parameter tuned deep learning based EfficientNet model with Variational Autoencoder (PTDLEN-VAE) model for satellite imagery analysis on ecology management. The presented PTDLEN-VAE model includes a series of operations namely pre-processing, feature extraction, and classification. Primarily, the satellite images are preprocessed to improve the contrast level of the image. Followed by, the PTDLEN based feature extractor is utilized to derive a useful set of feature vectors from the aerial image. Besides, the improved krill herd optimization (IKHO) algorithm is applied for the parameter tuning of the EfficientNet model. Finally, the classification of aerial images using the derived feature vectors takes place by the use of the VAE model. The efficacy of the PTDLEN-VAE model is validated using a benchmark aerial image dataset and the resultant experimental values highlighted the effectiveness of the PTDLEN-VAE model interms of precision, recall, F1-score, F2-score, and computation time.}
}
@article{YANG2022108419,
title = {A VI-based phenology adaptation approach for rice crop monitoring using UAV multispectral images},
journal = {Field Crops Research},
volume = {277},
pages = {108419},
year = {2022},
issn = {0378-4290},
doi = {https://doi.org/10.1016/j.fcr.2021.108419},
url = {https://www.sciencedirect.com/science/article/pii/S0378429021003658},
author = {Qi Yang and Liangsheng Shi and Jingye Han and Zhuowei Chen and Jin Yu},
keywords = {Rice crop monitoring, UAV, PAI estimation, Phenology adaptation, Biomass estimation},
abstract = {Accurate monitoring of crop biophysical parameters such as the plant area index (PAI) is essential for regional crop growth simulations and crop management. Many efforts have been made to estimate PAI by vegetation index (VI)-based methods, such as the widely used single empirical regression method and the piecewise relationship method. However, model structure error is inherent to the single-relationship method since it neglects the influence of phenology, and the discontinuity of the piecewise method can result in abrupt changes in estimates in the stage-transition period. Here we introduce a generalized and more accurate approach, termed the VI-based phenology adaptation (VPA) method, to estimate PAI of rice (Oryza sativa L.) using unmanned aerial vehicle (UAV)-based multispectral data. The VPA method automatically adapted the VI-PAI relationship at each observation time by bridging the VI, phenology and PAI into a continuous model. Moreover, the capability to monitor aboveground biomass of rice via the VPA method was evaluated. Intensive aerial and ground experiments were conducted in the controlled experimental plots and the randomly selected farmer-managed plots during two consecutive years (one year for calibration and another year for testing). The trajectory of the anchor-point that linked the discrete VI-PAI/biomass relationship for each phenological stage was developed and parameterized. The estimates of the single-relationship method were scattered when PAI was high, and this method failed to estimate PAI for the entire growing season. Significant underestimation was observed at the flowering stage (BBCH 64) for the piecewise methods. In contrast, the VPA approach outperformed the other methods for both controlled plots (R2 of 0.799 and RMSE of 0.536) and farmer-managed plots (R2 of 0.543 and RMSE of 0.671). Moreover, the VPA method exhibited superior generality for estimating other crop biophysical parameters such as biomass. Compared with the piecewise methods, the proposed method best estimated aboveground biomass, with 93% of biomass variation captured. The results demonstrated the steady performance of the VPA method for estimating various biophysical parameters throughout the entire growing season, indicating the promising potential of this method for cross-year and cross-site crop status monitoring.}
}
@article{ABBASPOUR2017317,
title = {Neural adaptive observer-based sensor and actuator fault detection in nonlinear systems: Application in UAV},
journal = {ISA Transactions},
volume = {67},
pages = {317-329},
year = {2017},
issn = {0019-0578},
doi = {https://doi.org/10.1016/j.isatra.2016.11.005},
url = {https://www.sciencedirect.com/science/article/pii/S0019057816306656},
author = {Alireza Abbaspour and Payam Aboutalebi and Kang K. Yen and Arman Sargolzaei},
keywords = {Adaptive fault detection, Sensor and actuator faults, Unmanned aerial vehicle, Nonlinear dynamic model},
abstract = {A new online detection strategy is developed to detect faults in sensors and actuators of unmanned aerial vehicle (UAV) systems. In this design, the weighting parameters of the Neural Network (NN) are updated by using the Extended Kalman Filter (EKF). Online adaptation of these weighting parameters helps to detect abrupt, intermittent, and incipient faults accurately. We apply the proposed fault detection system to a nonlinear dynamic model of the WVU YF-22 unmanned aircraft for its evaluation. The simulation results show that the new method has better performance in comparison with conventional recurrent neural network-based fault detection strategies.}
}
@article{ZHANG2018368,
title = {Intelligent GNSS/INS integrated navigation system for a commercial UAV flight control system},
journal = {Aerospace Science and Technology},
volume = {80},
pages = {368-380},
year = {2018},
issn = {1270-9638},
doi = {https://doi.org/10.1016/j.ast.2018.07.026},
url = {https://www.sciencedirect.com/science/article/pii/S127096381830600X},
author = {Guohao Zhang and Li-Ta Hsu},
keywords = {UAV, GPS, Navigation, Kalman filter, Adaptive tuning, Machine learning},
abstract = {Owing to the increase in civil applications using quadcopters, commercial flight control systems such as Pixhawk are a popular solution to provide the sensing and control functions of an unmanned aerial vehicle (UAV). A low-cost global navigation satellite system (GNSS) receiver is crucial for the low-cost flight control system. However, the accuracy of GNSS positioning is severely degraded by the notorious multipath effect in mega-urbanized cities. The multipath effect cannot be eliminated but can be mitigated; hence, the GNSS/inertial navigation system (INS) integrated navigation is a popular approach to reduce this error. This study proposes an adaptive Kalman filter for adjusting the noise covariance of GNSS measurements under different positioning accuracies. The adaptive tuning is based on a proposed accuracy classification model trained by a supervised machine-learning method. First, principal component analysis is employed to identify the significant GNSS accuracy related features. Subsequently, the positioning accuracy model is trained based on a random forest learning algorithm with the labeled real GNSS dataset encompassing most scenarios concerning modern urban areas. To reduce the cases of misclassifying the GNSS accuracy, a fuzzy logic algorithm is employed to consider the GNSS accuracy propagation. Additionally, the process noise covariance of the INS is determined using the Allan variance analysis. The positioning performance of the proposed adaptive Kalman filter is compared with both a conventional Kalman filter and the positioning solution provided by the commercial flight control system, Pixhawk 2. The results show that the proposed adaptive Kalman filter using random forest with fuzzy logic can achieve a better classification of GNSS accuracy compared to the others. The overall positioning result improved by approximately 50% compared with the onboard solution.}
}
@article{ULLAH2021,
title = {Fractional order adaptive robust formation control of multiple quad-rotor UAVs with parametric uncertainties and wind disturbances},
journal = {Chinese Journal of Aeronautics},
year = {2021},
issn = {1000-9361},
doi = {https://doi.org/10.1016/j.cja.2021.10.012},
url = {https://www.sciencedirect.com/science/article/pii/S1000936121003745},
author = {Nasim ULLAH and Yasir MEHMOOD and Jawad ASLAM and Shaoping WANG and Khamphe PHOUNGTHONG},
keywords = {Adaptive robust control, Fractional order control, Nonlinear control, Quad-rotor UAVs, Swarm formation control},
abstract = {In recent times[1]–[49], multiple Unmanned Aerial Vehicles (UAVs) are being widely utilized in several areas of applications such as agriculture, surveillance, disaster management, search and rescue operations. Degree of robustness of applied control schemes determines how accurate a swarm of UAVs accomplish group tasks. Formation and trajectory tracking controllers are required for the swarm of multiple UAVs. Factors like external environmental effects, parametric uncertainties and wind gusts make the controller design process as a challenging task. This article proposes fractional order formation and trajectory tacking controllers for multiple quad-rotors using Super Twisting Sliding Mode Control (STSMC) technique. To compensate the effects of the disturbances due to parametric uncertainties and wind gusts, Lyapunov function based adaptive controllers are formulated. Moreover, Lyapunov theorem is used to guarantee the stability of the proposed controllers. Three types of controllers, namely fixed gain Super Twisting Sliding Mode Control (STSMC), integer order Adaptive Super Twisting Sliding Mode Control (ASTSMC) and fractional order ASTSMC methods are tested for the swarm of UAVs by performing the numerical simulations in MATLAB/Simulink environment. From the presented results, it is verified that in presence of wind disturbances and parametric uncertainties, the proposed fractional order ASTSMC technique showed improved robustness as compared to the fixed gain STSMC and integer order ASTSMC.}
}
@article{LI2021126201,
title = {A UAV-based framework for crop lodging assessment},
journal = {European Journal of Agronomy},
volume = {123},
pages = {126201},
year = {2021},
issn = {1161-0301},
doi = {https://doi.org/10.1016/j.eja.2020.126201},
url = {https://www.sciencedirect.com/science/article/pii/S1161030120302082},
author = {Xiaohan Li and Xuezhang Li and Wen Liu and Benhui Wei and Xianli Xu},
keywords = {Crop lodging assessment, UAV visible imagery, Feature selection, Boruta algorithm},
abstract = {Crop lodging assessment needs to be carried out timely and accurately to ensure valuable information about the location and area where lodging occurs. Many applications have been explored and tested for unmanned aerial vehicle (UAV) visible imagery in agricultural management due to the ability of providing high-space-resolution information. However, there still face many challenges in extracting lodging information using UAV visible imagery, and lacks consensus on an appropriate way to assess crop lodging. The main purpose of this study was to proposed an efficient framework to identify crop lodging at the field scale using UAV visible imagery. This framework contained a two-phase procedure. Meanwhile, three methods were evaluated by providing the appropriate feature subset for objected-based classification to determine the best feature selection method. The results showed that the proposed framework provided high accuracy (94.0 %) for identification of sugarcane lodging. Furthermore, the Boruta algorithm yielded the best feature subset compared with statistical indicators and the RFE algorithm. Thus, the proposed framework based on UAV visible imagery is promising to identify crop lodging precisely, and has great application potential in precision agriculture.}
}
@article{CAO2021110586,
title = {MULTI-SENSOR FUSION AND DATA ANALYSIS FOR OPERATING CONDITIONS OF LOW POWER TRANSMISSION LINES},
journal = {Measurement},
pages = {110586},
year = {2021},
issn = {0263-2241},
doi = {https://doi.org/10.1016/j.measurement.2021.110586},
url = {https://www.sciencedirect.com/science/article/pii/S0263224121014585},
author = {Shipeng Cao and Qiao Fan and Wan {Jin YU} and Li {Tao Wang} and  ShaNi and  JieChen},
keywords = {Low power transmission line, Big data, Fusion algorithm},
abstract = {The research of the safety distance among drones and cable attracted wide attention with the rising deployment of unmanned aerial vehicle (UAV) to check for high-voltage overhead power systems. To increase the inspection operation's dependability and guarantee a safe and stable functioning of the transmission grid and inspections equipment, it is essential to determine the safety distance among the UAV and the driveway. Due to UAV patrol safety distances from overhead power lines, it is difficult to offer precise surfing information because of the lack of quantitative assistance. The author of the relevant study uses multi-sensor fusion data analysis (MFDA-LPTL). There have been discussions on the properties of large data sets, smart networks, and gigantic data sets before the emergence of low-cost power transmission lines and the benefits they may give. For example, using the adaptive weighted fusional method, which combines first-level data on homogenous sensor input based on critical UAV-influencing factors such as maximum inspection speed, wind speed, positioning error, and drone size, can help achieve this goal. As a secondary benefit, the theory makes use of more robust evidence than before. However, the use of big data analytics in present smart grids must be expanded due to numerous challenges, such as the need for new technologies and increased public awareness. The experimental analysis shows that the proposed MFDA-LPTL model increases the performance ratio of 98.9%, efficiency ratio of 97.2%, reduces the detection failure analysis of 10.2%, processing time of 7.8%, positioning error rate of 12.3% compared to other existing methods.}
}
@article{FAUST2017381,
title = {Automated aerial suspended cargo delivery through reinforcement learning},
journal = {Artificial Intelligence},
volume = {247},
pages = {381-398},
year = {2017},
note = {Special Issue on AI and Robotics},
issn = {0004-3702},
doi = {https://doi.org/10.1016/j.artint.2014.11.009},
url = {https://www.sciencedirect.com/science/article/pii/S0004370214001416},
author = {Aleksandra Faust and Ivana Palunko and Patricio Cruz and Rafael Fierro and Lydia Tapia},
keywords = {Reinforcement learning, UAVs, Aerial cargo delivery, Probabilistic roadmaps, Motion planning, Trajectory planning, Robotics, Rotorcraft},
abstract = {Cargo-bearing unmanned aerial vehicles (UAVs) have tremendous potential to assist humans by delivering food, medicine, and other supplies. For time-critical cargo delivery tasks, UAVs need to be able to quickly navigate their environments and deliver suspended payloads with bounded load displacement. As a constraint balancing task for joint UAV-suspended load system dynamics, this task poses a challenge. This article presents a reinforcement learning approach for aerial cargo delivery tasks in environments with static obstacles. We first learn a minimal residual oscillations task policy in obstacle-free environments using a specifically designed feature vector for value function approximation that allows generalization beyond the training domain. The method works in continuous state and discrete action spaces. Since planning for aerial cargo requires very large action space (over 106 actions) that is impractical for learning, we define formal conditions for a class of robotics problems where learning can occur in a simplified problem space and successfully transfer to a broader problem space. Exploiting these guarantees and relying on the discrete action space, we learn the swing-free policy in a subspace several orders of magnitude smaller, and later develop a method for swing-free trajectory planning along a path. As an extension to tasks in environments with static obstacles where the load displacement needs to be bounded throughout the trajectory, sampling-based motion planning generates collision-free paths. Next, a reinforcement learning agent transforms these paths into trajectories that maintain the bound on the load displacement while following the collision-free path in a timely manner. We verify the approach both in simulation and in experiments on a quadrotor with suspended load and verify the method's safety and feasibility through a demonstration where a quadrotor delivers an open container of liquid to a human subject. The contributions of this work are two-fold. First, this article presents a solution to a challenging, and vital problem of planning a constraint-balancing task for an inherently unstable non-linear system in the presence of obstacles. Second, AI and robotics researchers can both benefit from the provided theoretical guarantees of system stability on a class of constraint-balancing tasks that occur in very large action spaces.}
}
@article{LOBIANCO2020103623,
title = {Joint semantic segmentation of road objects and lanes using Convolutional Neural Networks},
journal = {Robotics and Autonomous Systems},
volume = {133},
pages = {103623},
year = {2020},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2020.103623},
url = {https://www.sciencedirect.com/science/article/pii/S0921889020304632},
author = {Leonardo Cabrera {Lo Bianco} and Jorge Beltrán and Gerardo Fernández López and Fernando García and Abdulla Al-Kaff},
keywords = {Semantic segmentation, Neural networks, Lane segmentation, Object segmentation},
abstract = {This paper presents a multi-task instance segmentation neural network able to provide both road lane and road participants detection. The multi-task approach, ERFNet-based, allows feature sharing and reduces the computational requirements of the overall detection architecture, allowing real time performance even in configurations with limited hardware. The proposed method includes an ad-hoc training procedure and automatic dataset creation mechanism that is also introduced in this paper. The proposed solution has been tested and validated through a newly generated public dataset derived from the BDD100K of 19K images, and in real scenarios. The results obtained prove the viability of the work for road application and its real time performance.}
}
@article{ZHANG20147100,
title = {Chaotic biogeography-based optimization approach to target detection in UAV surveillance},
journal = {Optik},
volume = {125},
number = {23},
pages = {7100-7105},
year = {2014},
issn = {0030-4026},
doi = {https://doi.org/10.1016/j.ijleo.2014.08.093},
url = {https://www.sciencedirect.com/science/article/pii/S0030402614010882},
author = {Qifu Zhang and Haibin Duan},
keywords = {Biogeography-based optimization (BBO), Unmanned aerial vehicle (UAV), Image matching},
abstract = {This paper describes a novel chaotic biogeography-based optimization (CBBO) algorithm for target detection by means of template matching to meet the request of unmanned aerial vehicle (UAV) surveillance. Template matching has been widely applied in movement tracking and other fields and makes excellent performances in visual navigation. Biogeography-based optimization (BBO) algorithm emerges as a new kind of optimization method on the basis of biogeography concept. The idea of migration and mutation strategy of species in BBO contributes to solving optimization problems. Our work adds chaotic searching strategy into BBO and applies CBBO in template matching. By utilizing chaotic strategy, the population ergodicity and global searching ability are improved, thus avoiding local optimal solutions during evolution. Applying the algorithm to resolving template matching problem overcomes the defects of common image matching. Series of experimental results demonstrate the feasibility and effectiveness of our modified approach over other algorithms in solving template matching problems. Our modified BBO algorithm performs better in terms of convergence property and robustness when compared with basic BBO.}
}
@article{ZHANG2022108352,
title = {Learning target-aware background-suppressed correlation filters with dual regression for real-time UAV tracking},
journal = {Signal Processing},
volume = {191},
pages = {108352},
year = {2022},
issn = {0165-1684},
doi = {https://doi.org/10.1016/j.sigpro.2021.108352},
url = {https://www.sciencedirect.com/science/article/pii/S0165168421003893},
author = {Fei Zhang and Shiping Ma and Zhuling Qiu and Tao Qi},
keywords = {Discriminative correlation filter, Unmanned aerial vehicle, Dual regression, Background suppression, Saliency detection, Spatial regularization},
abstract = {Traditional discriminative correlation filters have been rapidly developed in UAV tracking field due to their effectiveness and computational efficiency. Unfortunately, these methods are limited by unwanted boundary effects, which decrease the discriminative power between the target and background. Besides, due to the fast target appearance change and complex scenarios, such as background clutter and similar object, there often exists distractors around the response peak, which may cause tracking drift or even failure. In this paper, we propose a novel correlation filter method with dual regression, which aims at obtaining high-quality and reliable response maps for more robust tracking. Specifically, benefiting from a saliency detection method, the target feature is efficiently acquired from the global feature. Then, employing the dual regression strategy, these features are used to regress dual filters, that is, the target filter and the global filter. Response maps generated by dual filters, i.e., the target and global response maps, are merged in the detection phase to increase the response value of the target. Furthermore, a novel response-level background suppression regularization is proposed to solve boundary effects. Through the mutual restriction between the target and global response maps, the discrimination of dual filters can be promoted. We perform extensive and comprehensive analysis on three challenging UAV tracking benchmarks. Results confirm that the dual regression strategy and the background suppression regularization can facilitate the tracking accuracy improvement. The proposed tracker has comparable performance against other 27 state-of-the-art trackers while running at ∼34 FPS on a single CPU.}
}
@article{YAO202140,
title = {Improved Glasius bio-inspired neural network for target search by multi-agents},
journal = {Information Sciences},
volume = {568},
pages = {40-53},
year = {2021},
issn = {0020-0255},
doi = {https://doi.org/10.1016/j.ins.2021.03.056},
url = {https://www.sciencedirect.com/science/article/pii/S0020025521003078},
author = {Peng Yao and Zhiyao Zhao},
keywords = {Multi-agent cooperative target search, Cumulative detection reward, Glasius bio-inspired neural network (GBNN), Gaussian mixture model (GMM)},
abstract = {This paper focuses on solving the multi-agent cooperative target search problem with the demand for obtaining the maximal cumulative detection reward, given the prior target probability map and the sensor detection ability under various constraints. First, a topologically organized model of Glasius bio-inspired neural network (GBNN) is constructed individually for each agent in order to represent the searching environment. The neural activities are determined not only by the activity propagation among neurons, but also by the external input containing the single detection reward and various constraints synthetically. Then, the agent’s searching motion can be selected greedily based on the dynamic activity landscape of GBNN. With the disadvantages of propagation time delay and activity attenuation, however, the relatively global mechanism in GBNN may lead to unsatisfactory performance or even fail to avoid the local optimal problem. Hence the Gaussian mixture model (GMM) is utilized to extract the high-value subregions and compute the future detection reward quantitatively, which can be introduced into the neuron’s external excitatory input of GBNN directly. The simulation results verify the high efficiency and strong robustness of GBNN-GMM in the searching scenarios.}
}
@article{MCCUNE20132537,
title = {Swarm Control of UAVs for Cooperative Hunting with DDDAS},
journal = {Procedia Computer Science},
volume = {18},
pages = {2537-2544},
year = {2013},
note = {2013 International Conference on Computational Science},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2013.05.436},
url = {https://www.sciencedirect.com/science/article/pii/S1877050913005796},
author = {R. Ryan McCune and Gregory R. Madey},
keywords = {DDDAS, Swarm Intelligence, Agent-Based Simulation},
abstract = {Swarm control is a problem of increasing importance with technological advancements. Recently, governments have begun employing UAVs for reconnaissance, including swarms of drones searching for evasive targets. An agent-based simulation for dynamic cooperative cleaning is augmented with additional behaviors and implemented into a Dynamic Data-Driven Applica- tion System (DDDAS) framework for dynamic swarm control.}
}
@article{GRANZIG2021102281,
title = {Mapping the fractional coverage of the invasive shrub Ulex europaeus with multi-temporal Sentinel-2 imagery utilizing UAV orthoimages and a new spatial optimization approach},
journal = {International Journal of Applied Earth Observation and Geoinformation},
volume = {96},
pages = {102281},
year = {2021},
issn = {0303-2434},
doi = {https://doi.org/10.1016/j.jag.2020.102281},
url = {https://www.sciencedirect.com/science/article/pii/S0303243420309247},
author = {Tobias Gränzig and Fabian Ewald Fassnacht and Birgit Kleinschmit and Michael Förster},
keywords = {Invasive species, Remote sensing, Unmanned aerial vehicles (UAV), Sentinel-2, Co-registration, UAV vegetation indices, UAV texture parameters, Time-series, Plant phenology, Chile},
abstract = {Mapping the occurrence patterns of invasive plant species and understanding their invasion dynamics is a crucial requirement for preventing further spread to so far unaffected regions. An established approach to map invasive species across large areas is based on the combination of satellite or aerial remote sensing data with ground truth data from fieldwork. Unmanned aerial vehicles (UAV, also referred to as unmanned aerial systems (UAS)) may represent an interesting and low-cost alternative to labor-intensive fieldwork. Despite the increasing use of UAVs in the field of remote sensing in the last years, operational methods to combine UAV and satellite data are still sparse. Here, we present a new methodological framework to estimate the fractional coverage (FC%) of the invasive shrub species Ulex europaeus (common gorse) on Chiloé Island (south-central Chile), based on ultra-high-resolution UAV images and a medium resolution intra-annual time-series of Sentinel-2. Our framework is based on three steps: 1) Land cover classification of the UAV orthoimages, 2) reduce the spatial shift between UAV-based land cover classification maps and Sentinel-2 imagery and 3) identify optimal satellite acquisition dates for estimating the actual distribution of Ulex europaeus. In Step 2 we translate the challenging co-registration task between two datasets with very different spatial resolutions into an (machine learning) optimization problem where the UAV-based land cover classification maps obtained in Step 1 are systematically shifted against the satellite images. Based on several Random Forest (RF) models, an optimal fit between varying land cover fractions and the spectral information of Sentinel-2 is identified to correct the spatial offset between both datasets. Considering the spatial shifts of the UAV orthoimages and using optimally timed Sentinel-2 acquisitions led to a significant improvement for the estimation of the current distribution of Ulex europaeus. Furthermore, we found that the Sentinel-2 acquisition from November (flowering time of Ulex europaeus) was particularly important in distinguishing Ulex europaeus from other plant species. Our mapping results could support local efforts in controlling Ulex europaeus. Furthermore, the proposed workflow should be transferable to other use cases where individual target species that are visually detectable in UAV imagery are considered. These findings confirm and underline the great potential of UAV-based groundtruth data for detecting invasive species.}
}
@article{FERREIRA2021101302,
title = {Accurate mapping of Brazil nut trees (Bertholletia excelsa) in Amazonian forests using WorldView-3 satellite images and convolutional neural networks},
journal = {Ecological Informatics},
volume = {63},
pages = {101302},
year = {2021},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2021.101302},
url = {https://www.sciencedirect.com/science/article/pii/S1574954121000935},
author = {Matheus Pinheiro Ferreira and Rodolfo Georjute Lotte and Francisco V. D'Elia and Christos Stamatopoulos and Do-Hyung Kim and Adam R. Benjamin},
keywords = {Deep learning, Tree species discrimination, Amazon, Very-high-resolution},
abstract = {The commercialization of Brazil nuts, seeds of Bertholletia excelsa Bonpl. (Lecythidaceae), represents one of the main income-generation activities for local and indigenous people from the Brazilian Amazon region. Because trees of B. excelsa grow and bear fruit almost exclusively in natural forests, information on their spatial distribution is crucial for nut harvest planning. However, this information is difficult to obtain with traditional approaches such as ground-based surveys. Here, we show the potential of convolutional neural networks (CNNs) and WorldView-3 satellite images (pixel size = 30 cm) to map individual tree crowns (ITCs) and groves of B. excelsa in Amazonian forests. First, we manually outlined B. excelsa ITCs in the WorldView-3 images using field-acquired geolocation information. Then, based on ITC boundaries, we sequentially extracted image patches and selected 80% of them for training and 20% for testing. We trained the DeepLabv3+ architecture with three backbones: ResNet-18, ResNet-50, and MobileNetV2. The average producer's accuracy was 93.87 ± 0.85%, 93.89 ± 1.6% and 93.47 ± 3.6% for ResNet-18, ResNet-50 and MobileNetV2, respectively. We then developed a new random patch extraction training strategy and assessed how a reduction in the percentage of training patches impacted the classification accuracy. To illustrate the robustness of the new training strategy, similar F1-scores were achieved whether 80% or 10% of the total number of patches were used to train the CNN model. By analyzing the feature maps derived from ResNet-18, we found that the shadow of emergent B. excelsa trees are important for their discrimination. Geometric distortions in the WorldView-3 images resulting from extreme off-nadir viewing angles compromise the presence of shadows, thus potentially hampering B. excelsa detection. Our results show that ITCs and groves of B. excelsa can be mapped by integrating CNNs and very-high-resolution (VHR) satellite images, paving the way for monitoring this important tree species in large tracts of Amazonian forests.}
}
@article{AKHTER2021,
title = {Precision agriculture using IoT data analytics and machine learning},
journal = {Journal of King Saud University - Computer and Information Sciences},
year = {2021},
issn = {1319-1578},
doi = {https://doi.org/10.1016/j.jksuci.2021.05.013},
url = {https://www.sciencedirect.com/science/article/pii/S1319157821001282},
author = {Ravesa Akhter and Shabir Ahmad Sofi},
keywords = {Internet of things (IoT), Data analytics (DA), Machine learning (ML)},
abstract = {In spite of the insight commonality may have concerning agrarian practice, fact is that nowadays agricultural science diligence is accurate, precise, data-driven, and vigorous than ever. The emanation of the technologies based on Internet of Things (IoT) has reformed nearly each industry like smart city, smart health, smart grid, smart home, including “smart agriculture or precision agriculture”. Applying machine learning using the IoT data analytics in agricultural sector will rise new benefits to increase the quantity and quality of production from the crop fields to meet the increasing food demand. Such world-shattering advancements are rocking the current agrarian approaches and generating novel and best chances besides a number of limitations. This paper climaxes the power and capability of computing techniques including internet of things, wireless sensor networks, data analytics and machine learning in agriculture. The paper proposed the prediction model of Apple disease in the apple orchards of Kashmir valley using data analytics and Machine learning in IoT system. Furthermore, a local survey was conducted to know from the farmers about the trending technologies and their effect in precision agriculture. Finally, the paper discusses the challenges faced when incorporating these technologies in the traditional farming approaches.}
}
@article{REY2017341,
title = {Detecting animals in African Savanna with UAVs and the crowds},
journal = {Remote Sensing of Environment},
volume = {200},
pages = {341-351},
year = {2017},
issn = {0034-4257},
doi = {https://doi.org/10.1016/j.rse.2017.08.026},
url = {https://www.sciencedirect.com/science/article/pii/S0034425717303942},
author = {Nicolas Rey and Michele Volpi and Stéphane Joost and Devis Tuia},
keywords = {Animal conservation, Wildlife monitoring, Object detection, Active learning, Crowd-sourcing data, Unmanned aerial vehicles, Very high resolution},
abstract = {Unmanned aerial vehicles (UAVs) offer new opportunities for wildlife monitoring, with several advantages over traditional field-based methods. They have readily been used to count birds, marine mammals and large herbivores in different environments, tasks which are routinely performed through manual counting in large collections of images. In this paper, we propose a semi-automatic system able to detect large mammals in semi-arid Savanna. It relies on an animal-detection system based on machine learning, trained with crowd-sourced annotations provided by volunteers who manually interpreted sub-decimeter resolution color images. The system achieves a high recall rate and a human operator can then eliminate false detections with limited effort. Our system provides good perspectives for the development of data-driven management practices in wildlife conservation. It shows that the detection of large mammals in semi-arid Savanna can be approached by processing data provided by standard RGB cameras mounted on affordable fixed wings UAVs.}
}
@article{ZHU2020104002,
title = {Multi-level prediction Siamese network for real-time UAV visual tracking},
journal = {Image and Vision Computing},
volume = {103},
pages = {104002},
year = {2020},
issn = {0262-8856},
doi = {https://doi.org/10.1016/j.imavis.2020.104002},
url = {https://www.sciencedirect.com/science/article/pii/S0262885620301347},
author = {Mu Zhu and Hui Zhang and Jing Zhang and Li Zhuo},
keywords = {UAV tracking, Small target, Feature fusion, Multi-level prediction},
abstract = {Existing deployed Unmanned Aerial Vehicles (UAVs) visual trackers are usually based on the correlation filter framework. Although these methods have certain advantages of low computational complexity, the tracking performance of small targets and fast motion scenarios is not satisfactory. In this paper, we present a novel multi-level prediction Siamese network (MLPS) for object tracking in UAV videos, which consists of Siamese feature extraction module and multi-level prediction module. The multi-level prediction module can make full use of the characteristics of each layer features to achieve robust evaluation of targets with different scales. Meanwhile, for small-size target tracking, we design a residual feature fusion block, which is used to constrain the low-level feature representation by using high-level abstract semantics, and obtain the improvement of the tracker's ability to distinguish scene details. In addition, we propose a layer attention fusion block which is sensitive to the informative features of each layers to achieve adaptive fusion of different levels of correlation responses by dynamically balancing the multi-layer features. Sufficient experiments on several UAV tracking benchmarks demonstrate that MLPS achieves state-of-the-art performance and runs at a speed over 97 FPS.}
}
@article{EBEID201811,
title = {A survey of Open-Source UAV flight controllers and flight simulators},
journal = {Microprocessors and Microsystems},
volume = {61},
pages = {11-20},
year = {2018},
issn = {0141-9331},
doi = {https://doi.org/10.1016/j.micpro.2018.05.002},
url = {https://www.sciencedirect.com/science/article/pii/S0141933118300930},
author = {Emad Ebeid and Martin Skriver and Kristian Husum Terkildsen and Kjeld Jensen and Ulrik Pagh Schultz},
keywords = {Unmanned Aerial Vehicle (UAV), Drones, Flight controllers, Drone simulators, Open platforms, Survey},
abstract = {The current disruptive innovation in civilian drone (UAV) applications has led to an increased need for research and development in UAV technology. The key challenges currently being addressed are related to UAV platform properties such as functionality, reliability, fault tolerance, and endurance, which are all tightly linked to the UAV flight controller hardware and software. The lack of standardization of flight controller architectures and the use of proprietary closed-source flight controllers on many UAV platforms, however, complicates this work: solutions developed for one flight controller may be difficult to port to another without substantial extra development and testing. Using open-source flight controllers mitigates some of these challenges and enables other researchers to validate and build upon existing research. This paper presents a survey of the publicly available open-source drone platform elements that can be used for research and development. The survey covers open-source hardware, software, and simulation drone platforms and compares their main features.}
}
@article{SHEIKH20213891,
title = {Corrosion detection and severity level prediction using acoustic emission and machine learning based approach},
journal = {Ain Shams Engineering Journal},
volume = {12},
number = {4},
pages = {3891-3903},
year = {2021},
issn = {2090-4479},
doi = {https://doi.org/10.1016/j.asej.2021.03.024},
url = {https://www.sciencedirect.com/science/article/pii/S2090447921001970},
author = {Muhammad Fahad Sheikh and Khurram Kamal and Faheem Rafique and Salman Sabir and Hassan Zaheer and Kashif Khan},
keywords = {Acoustic emission, Corrosion detection, Accelerated corrosion testing, Machine learning classifiers, Severity level prediction},
abstract = {Failure caused by corrosion in industries are the major cause of breakdown maintenance. Acoustic emission during the accelerated corrosion testing is a reliable method for corrosion detection, however, classification of these acoustic emission signals by machine learning techniques is still in its infancy. Proposed approach uses a hybrid technique that combines the detection of corrosion through acoustic emission signals from accelerated corrosion testing with machine learning techniques to accurately predict the corrosion severity levels. Laboratory based experimentation setup was established for accelerated corrosion testing of mild steel samples for different time spans and mass loss of samples were recorded. Acoustic emission signals were acquired at high frequency sampling rate with Sound Well AE sensor, NI Elvis kit and NI Labview software. AE mean, AE RMS, AE energy, and kurtosis were selected as distinct features as they represent a linear relationship with the corrosion process. For multi-class problem, five Corrosion severity levels have been made based on mass loss occurred during accelerated corrosion testing for which Naive Bayes, BP-NN and RBF-NN showed accuracy of 90.4%, 94.57%, and 100% respectively.}
}
@article{LIU2020282,
title = {Predictor-based model reference adaptive roll and yaw control of a quad-tiltrotor UAV},
journal = {Chinese Journal of Aeronautics},
volume = {33},
number = {1},
pages = {282-295},
year = {2020},
issn = {1000-9361},
doi = {https://doi.org/10.1016/j.cja.2019.08.001},
url = {https://www.sciencedirect.com/science/article/pii/S1000936119302973},
author = {Ningjun LIU and Zhihao CAI and Jiang ZHAO and Yingxun WANG},
keywords = {Adaptive control, Flight control, Tiltrotor, UAV, VTOL},
abstract = {An attempt is made to apply modern control technology to the roll and yaw control of a rudderless quad-tiltrotor Unmanned Aerial Vehicle (UAV) in the latter part of the flight mode transition, where aerodynamic forces on the tiltrotor’s wings start to take effect. A predictor-based adaptive roll and yaw controller is designed to compensate for system uncertainties and parameter changes. A dynamics model of the tiltrotor is built. A Radial-Basis Function (RBF) neural network and offline adaptation method are used to reduce flight controller workload and cope with the nonlinearities in the controls. Simulations are conducted to verify the reference model response tracking and yaw-roll control decoupling ability of the adaptive controller, as well as the validity of the offline adaptation method. Flight tests are conducted to confirm the ability of the adaptive controller to track different roll and yaw reference model responses. The decoupling of roll and yaw controls is also tested in flight via coordinated turn maneuvers with different rotor tilt angles.}
}
@article{SALCEDOSANZ2020256,
title = {Machine learning information fusion in Earth observation: A comprehensive review of methods, applications and data sources},
journal = {Information Fusion},
volume = {63},
pages = {256-272},
year = {2020},
issn = {1566-2535},
doi = {https://doi.org/10.1016/j.inffus.2020.07.004},
url = {https://www.sciencedirect.com/science/article/pii/S1566253520303171},
author = {S. Salcedo-Sanz and P. Ghamisi and M. Piles and M. Werner and L. Cuadra and A. Moreno-Martínez and E. Izquierdo-Verdiguier and J. Muñoz-Marí and Amirhosein Mosavi and G. Camps-Valls},
keywords = {Earth science, Earth observation, Information fusion, Data fusion, Machine learning, Cloud computing, Gap filling, Remote sensing, Multisensor fusion, Data blending, Social networks},
abstract = {This paper reviews the most important information fusion data-driven algorithms based on Machine Learning (ML) techniques for problems in Earth observation. Nowadays we observe and model the Earth with a wealth of observations, from a plethora of different sensors, measuring states, fluxes, processes and variables, at unprecedented spatial and temporal resolutions. Earth observation is well equipped with remote sensing systems, mounted on satellites and airborne platforms, but it also involves in-situ observations, numerical models and social media data streams, among other data sources. Data-driven approaches, and ML techniques in particular, are the natural choice to extract significant information from this data deluge. This paper produces a thorough review of the latest work on information fusion for Earth observation, with a practical intention, not only focusing on describing the most relevant previous works in the field, but also the most important Earth observation applications where ML information fusion has obtained significant results. We also review some of the most currently used data sets, models and sources for Earth observation problems, describing their importance and how to obtain the data when needed. Finally, we illustrate the application of ML data fusion with a representative set of case studies, as well as we discuss and outlook the near future of the field.}
}
@article{GUO2021107654,
title = {UAV flight control sensing enhancement with a data-driven adaptive fusion model},
journal = {Reliability Engineering & System Safety},
volume = {213},
pages = {107654},
year = {2021},
issn = {0951-8320},
doi = {https://doi.org/10.1016/j.ress.2021.107654},
url = {https://www.sciencedirect.com/science/article/pii/S0951832021001952},
author = {Kai Guo and Zhisheng Ye and Datong Liu and Xiyuan Peng},
keywords = {Unmanned aerial vehicles (UAVs), Sensing enhancement, Fusion state space model, Multi-output Gaussian process regression (GPR)},
abstract = {Accurate sensing is essential for achieving reliable control of unmanned aerial vehicles (UAVs). In prior works, the unscented Kalman filter (UKF) has shown superior performance in both estimation accuracy and computation efficiency, which makes it suitable for onboard sensing enhancement. However, the prediction accuracy of existing filter-based statistical models is generally assumed to be invariant of the flight conditions. To avoid deterioration in the estimation performance, this paper proposes a novel data-driven adaptive fusion state space model for quantifying the prediction uncertainty of the system model. Based on the multi-output Gaussian process regression (GPR), a rule for tuning the noise parameter of the statistical model is provided based on the estimated variance. The sparse GPR model is utilized to incorporate available features and obtain high estimation accuracy under dynamic operation conditions. Simulation results have illustrated the superior performance of the proposed approach in state estimation for the UAV.}
}
@article{BOUHLEL2021318,
title = {Suspicious Person Retrieval from UAV-sensors based on part level deep features},
journal = {Procedia Computer Science},
volume = {192},
pages = {318-327},
year = {2021},
note = {Knowledge-Based and Intelligent Information & Engineering Systems: Proceedings of the 25th International Conference KES2021},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2021.08.033},
url = {https://www.sciencedirect.com/science/article/pii/S1877050921015209},
author = {Fatma Bouhlel and Hazar Mliki and Mohamed Hammami},
keywords = {Video Surveillance, UAV, Scene stabilization, Person detection, Person retrieval, Deep learning, Part-Level Deep Features.},
abstract = {Intelligent video surveillance systems represent a potent tool for preserving human security in public places. Indeed, these surveillance systems are requested in several real-life scenarios, in order to assist security guards by alerting them in abnormal situations and helping them to retrieve a suspicious person. Especially, intelligent video surveillance systems based on UAV-sensors have the asset of monitoring large as well as difficult access spaces. In this scope, we introduce a new approach for suspicious person retrieval from UAV-sensors. The proposed approach implies two complementary phases which are an offline phase and an inference phase. Within these phases, a scene stabilization step is carried out. The offline phase allows building the non-person/person model as well as the person retrieval model. Nonetheless, the inference phase enables to detect persons and retrieve suspicious ones using the already generated models. The main contribution of the proposed approach is the use of part-level deep features in order to retrieve persons. The experimental results validate the contributions of our approach compared to the state-of-the-art approaches.}
}
@article{KATAEV2020234,
title = {Method to estimate pedestrian traffic using convolutional neural network},
journal = {Transportation Research Procedia},
volume = {50},
pages = {234-241},
year = {2020},
note = {XIV International Conference on Organization and Traffic Safety Management in Large Cities (OTS-2020)},
issn = {2352-1465},
doi = {https://doi.org/10.1016/j.trpro.2020.10.029},
url = {https://www.sciencedirect.com/science/article/pii/S2352146520307754},
author = {Georgii Kataev and Vitalii Varkentin and Kseniia Nikolskaia},
keywords = {system analysis, efficiency, stochastic approach, traffic safety},
abstract = {This study describes a neural network approach to collecting pedestrian traffic statistics from street surveillance cameras. Collecting and processing pedestrian traffic is one of the most important areas in the development of smart cities. To solve the problem of collecting pedestrian traffic statistics, a modern system of object detection in real time, YOLOv3, was used. To train the neural network, a data set of 750 labeled frames with pedestrians was used, which amounted to 20,000 objects. According to the results of the system testing, the recognition accuracy was 79%. The presented data set can be used by other researchers in their studies.}
}
@article{SABZEVARI2020101950,
title = {Separation of movement direction concepts based on independent component analysis algorithm, linear discriminant analysis, deep belief network, artificial and fuzzy neural networks},
journal = {Biomedical Signal Processing and Control},
volume = {62},
pages = {101950},
year = {2020},
issn = {1746-8094},
doi = {https://doi.org/10.1016/j.bspc.2020.101950},
url = {https://www.sciencedirect.com/science/article/pii/S1746809420301063},
author = {Mohammadamin Sabzevari and Ehsan Imani},
keywords = {Brain signals, Independent component analysis, Linear discriminant analysis, Artificial neural network, Fuzzy neural network, Deep belief network},
abstract = {Brain signals have various scientific and practical applications, such as Medical Science, Cognitive Science, Neuroscience, and Brain Computer Interfaces. Brain signal analysis is faced with complex challenges including small sample size, high dimensionality and noisy signals. Because of the non-stationarity of brain signals and the impacts of mental states on brain function, brain signals are associated with an inherent uncertainty. In this study, it is tried to present a plausible method for detecting and distinguishing the directions from EEG signals. Recording single-polarized signals was carried out utilizing a 19-channel cap Micromed device with the use of Cz as reference electrode. The statistical population used involved ten 25–35 year old male volunteers. The designed task consisted of 24 slides of up, down, left and right directions. After preprocessing level, ICA algorithm was employed to extract artifacts, to decrease signal dimension and to determine the target signal. In feature extraction section, AR coefficients extracted to feed the ANN, FNN and LDA. Data for Deep Belief Network provided from Autoregressive power spectral density estimate with order of 20 employed on the data set. Classifiers’ results reveal that 2.5 s time window leads to the best separation accuracy. DBN surprisingly leads to the highest level of accuracy in comparison to the other proposed methods. Based on the 10-fold Cross Validation, the performance of the classifiers measured in terms of accuracy, sensitivity and specificity. The obtained average accuracies for LDA, ANN, FNN and DBN respectively are 61.86 ± 1.69 %, 57.18 ± 1.88 %, 66.79 ± 2.14 % and 91.06 ± 0.68.}
}
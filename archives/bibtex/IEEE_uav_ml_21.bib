@INPROCEEDINGS{9295716,
author={Wang, Jian and Zhang, Qianyi and Feng, Gang and Qin, Shuang and Zhou, Jianhong and Cheng, Lei},
booktitle={2020 IEEE 20th International Conference on Communication Technology (ICCT)}, title={Clustering Strategy of UAV Network Based on Deep Q-learning},
year={2020},
volume={},
number={},
pages={1684-1689},
abstract={In recent years, with the development and wide application of unmanned aerial vehicle (UAV) technology, the key technology of unmanned aerial vehicle network has become a new research focus. Compared with traditional networks, UAV networks have the characteristics of dynamic topology and limited energy. These characteristics have brought new challenges to the design and implementation of UAV communication systems. We need to redesign the organizational structure of the UAV network to reduce network power consumption, extend network operation time, and improve network stability. In this paper, we have studied the clustering of UAV networks and designed a clustering strategy. First, calculate the best number of clusters in the current network based on bandwidth balance, then use the K-means algorithm to quickly cluster the entire network, and finally implement a cluster head selection algorithm based on Deep Q-learning (DQN) in each cluster . We simulated the clustering strategy and analyzed the average link retention time, average cluster head retention time, network energy consumption, etc., which proved the efficiency and correctness of the algorithm proposed in this paper.},
keywords={Clustering algorithms;Unmanned aerial vehicles;Heuristic algorithms;Bandwidth;Markov processes;Maintenance engineering;Energy consumption;UAV networks;clustering strategy;reinforcement learning},
doi={10.1109/ICCT50939.2020.9295716},
ISSN={2576-7828},
month={Oct},}
@INPROCEEDINGS{9525022,
author={Kurunathan, Harrison and Li, Kai and Ni, Wei and Tovar, Eduardo and Dressler, Falko},
booktitle={2021 IEEE 46th Conference on Local Computer Networks (LCN)}, title={Deep Reinforcement Learning for Persistent Cruise Control in UAV-aided Data Collection},
year={2021},
volume={},
number={},
pages={347-350},
abstract={Autonomous UAV cruising is gaining attention due to its flexible deployment in remote sensing, surveillance, and reconnaissance. A critical challenge in data collection with the autonomous UAV is the buffer overflows at the ground sensors and packet loss due to lossy airborne channels. Trajectory planning of the UAV is vital to alleviate buffer overflows as well as channel fading. In this work, we propose a Deep Deterministic Policy Gradient based Cruise Control (DDPG-CC) to reduce the overall packet loss through online training of headings and cruise velocity of the UAV, as well as the selection of the ground sensors for data collection. Preliminary performance evaluation demonstrates that DDPG-CC reduces the packet loss rate by under 5% when sufficient training is provided to the UAV.},
keywords={Training;Wireless sensor networks;Trajectory planning;Packet loss;Reinforcement learning;Buffer overflows;Data collection;UAV-aided WSN;Autonomous UAV;Cruise control;Deep reinforcement learning},
doi={10.1109/LCN52139.2021.9525022},
ISSN={0742-1303},
month={Oct},}
@ARTICLE{9528844,
author={Liu, Lingshan and Xiong, Ke and Cao, Jie and Lu, Yang and Fan, Pingyi and Letaief, Khaled Ben},
journal={IEEE Internet of Things Journal}, title={Average AoI Minimization in UAV-assisted Data Collection with RF Wireless Power Transfer: A Deep Reinforcement Learning Scheme},
year={2021},
volume={},
number={},
pages={1-1},
abstract={This paper studies the UAV-assisted wireless powered network, where a UAV is dispatched to wirelessly charge multiple ground nodes (GNs) by using radio frequency (RF) energy transfer and then the GNs use their harvested energy to upload the sensed information to the UAV. At each moment, the UAV is scheduled to charge the GNs or only one GN is scheduled to upload its data. An optimization problem is formulated to minimize the average age of information (AoI) of the GNs by jointly optimizing the trajectory of the UAV and the scheduling of information transmission and energy harvesting of GNs. As the problem is a combinational optimization problem with a set of binary variables, it is difficult to be solved. Thus, it is modeled as a Markov problem with large state spaces and a deep Q network (DQN)-based scheme is proposed to find its near optimal solution on the basis of the deep reinforcement learning (DRL) framework. Two nets are structured with artificial neural network (ANN), where one is for evaluating the reward of the action performed in current state, and the other is for predicting realistic action. The corresponding state spaces, the efficient action spaces and reward function are designed. Simulation results demonstrate the convergence of the proposed DQN scheme, which also show that the proposed DQN scheme gets much smaller average AoI than the three other known schemes. Moreover, by involving the energy punishment in the reward, the UAV may save its energy but yield higher AoI. Additionally, the effects of the packet size, the transmit power, and the distribution area of GNs on the GNs’ average AoI are also discussed, which are expected to provide some useful insights.},
keywords={Trajectory;Radio frequency;Internet of Things;Wireless networks;Wireless sensor networks;Reinforcement learning;Energy consumption;UAV;Age of Information;Deep Reinforcement Learning;Wireless Power Transmission.},
doi={10.1109/JIOT.2021.3110138},
ISSN={2327-4662},
month={},}
@ARTICLE{9277627,
author={Liu, Xiao and Liu, Yuanwei and Chen, Yue},
journal={IEEE Journal on Selected Areas in Communications}, title={Machine Learning Empowered Trajectory and Passive Beamforming Design in UAV-RIS Wireless Networks},
year={2021},
volume={39},
number={7},
pages={2042-2055},
abstract={A novel framework is proposed for integrating reconfigurable intelligent surfaces (RIS) in unmanned aerial vehicle (UAV) enabled wireless networks, where an RIS is deployed for enhancing the service quality of the UAV. Non-orthogonal multiple access (NOMA) technique is invoked to further improve the spectrum efficiency of the network, while mobile users (MUs) are considered as roaming continuously. The energy consumption minimizing problem is formulated by jointly designing the movement of the UAV, phase shifts of the RIS, power allocation policy from the UAV to MUs, as well as determining the dynamic decoding order. A decaying deep Q-network (D-DQN) based algorithm is proposed for tackling this pertinent problem. In the proposed D-DQN based algorithm, the central controller is selected as an agent for periodically observing the state of UAV-enabled wireless network and for carrying out actions to adapt to the dynamic environment. In contrast to the conventional DQN algorithm, the decaying learning rate is leveraged in the proposed D-DQN based algorithm for attaining a tradeoff between accelerating training speed and converging to the local optimal. Numerical results demonstrate that: 1) In contrast to the conventional Q-learning algorithm, which cannot converge when being adopted for solving the formulated problem, the proposed D-DQN based algorithm is capable of converging with minor constraints; 2) The energy dissipation of the UAV can be significantly reduced by integrating RISs in UAV-enabled wireless networks; 3) By designing the dynamic decoding order and power allocation policy, the RIS-NOMA case consumes 11.7% less energy than the RIS-OMA case.},
keywords={Heuristic algorithms;Array signal processing;Wireless networks;Trajectory;Unmanned aerial vehicles;Resource management;Decoding;Non-orthogonal multiple access;reconfigurable intelligent surfaces;reinforcement learning;trajectory design;unmanned aerial vehicle},
doi={10.1109/JSAC.2020.3041401},
ISSN={1558-0008},
month={July},}
@INPROCEEDINGS{9348719,
author={Aftab, Asad and Ashraf, Nouman and Qureshi, Hassaan Khaliq and Ali Hassan, Syed and Jangsher, Sobia},
booktitle={2020 IEEE 92nd Vehicular Technology Conference (VTC2020-Fall)}, title={BLOCK-ML: Blockchain and Machine Learning for UAV-BSs Deployment},
year={2020},
volume={},
number={},
pages={1-5},
abstract={Unmanned aerial vehicles (UAVs) are expected to be extensively used as an integral part in the future generations of communication networks, to provide ubiquitous connectivity. The mobile nature of UAVs make them a tempting candidate to provide seamless connectivity in environments where the installation of conventional terrestrial base stations (BS) is not feasible. Nonetheless, there are major deployment issues related to optimal placement of UAV-mounted base stations (UAV-BSs) due to limited number of UAV-BSs, limited energy availability and trade-off between coverage area and its altitude. In this paper, we address UAV-BSs placement issues by proposing a novel Machine learning (ML) based intelligent deployment mechanism. More specifically, for intelligent deployment of UAV-BSs based on energy, computational power, nature of available data and criticality of the scenario, we use two different approaches: Support Vector Machine (SVM) and Deep Learning (DL), which is composed of sequential time series learning process. Moreover, to address the security and privacy challenges emanating from the wireless connectivity and untrusted broadcast nature of UAV-BSs, we propose a Blockchain-based novel information-sharing scheme. To evaluate the performance of our combined secure and intelligent proposed approach, we have improved energy consumption by almost twice in contrast with the normal deployment of UAV-BSs.},
keywords={Support vector machines;Wireless communication;Base stations;Vehicular and wireless technologies;Time series analysis;Blockchain;Security;Machine Learning;Deep Learning;Blockchain;UAV-BSs},
doi={10.1109/VTC2020-Fall49728.2020.9348719},
ISSN={2577-2465},
month={Nov},}
@ARTICLE{8494742,
author={Hu, Jingzhi and Zhang, Hongliang and Song, Lingyang},
journal={IEEE Internet of Things Journal}, title={Reinforcement Learning for Decentralized Trajectory Design in Cellular UAV Networks With Sense-and-Send Protocol},
year={2019},
volume={6},
number={4},
pages={6177-6189},
abstract={Recently, the unmanned aerial vehicles (UAVs) have been widely used in real-time sensing applications over cellular networks. The performance of a UAV is determined by both its sensing and transmission processes, which are influenced by the trajectory of the UAV. However, it is challenging for the UAV to determine its trajectory, since it works in a dynamic environment, where other UAVs determine their trajectories dynamically and compete for the limited spectrum resources in the same time. To tackle this challenge, we adopt the reinforcement learning to solve the UAV trajectory design problem in a decentralized manner. To coordinate multiple UAVs performing real-time sensing tasks, we first propose a sense-and-send protocol, and analyze the probability for successful valid data transmission using nested Markov chains. Then, we propose an enhanced multi-UAV Q-learning algorithm to solve the decentralized UAV trajectory design problem. Simulation results show that the proposed algorithm converges faster and achieves higher utilities for the UAVs, compared to traditional singleand multi-agent Q-learning algorithms.},
keywords={Sensors;Task analysis;Trajectory;Real-time systems;Protocols;Unmanned aerial vehicles;Learning (artificial intelligence);Reinforcement learning;sense-and-send protocol;trajectory design;unmanned aerial vehicle (UAV)},
doi={10.1109/JIOT.2018.2876513},
ISSN={2327-4662},
month={Aug},}
@INPROCEEDINGS{8885504,
author={Martinez-Alpiste, Ignacio and Casaseca-de-la-Higuera, Pablo and Alcaraz-Calero, Jose and Grecos, Christos and Wang, Qi},
booktitle={2019 IEEE Wireless Communications and Networking Conference (WCNC)}, title={Benchmarking Machine-Learning-Based Object Detection on a UAV and Mobile Platform},
year={2019},
volume={},
number={},
pages={1-6},
abstract={Object detection systems mounted on Unmanned Aerial Vehicles (UAVs) have gained momentum in recent years in light of the widespread use cases enabled by such systems in public safety and other areas. Machine learning has emerged as an enabler for improving the performance of object detection. However, there is little existing work that has studied the performance of the machine learning approach, which is computationally resource demanding, in a portable mobile platform for UAV based object detection in user mobility scenarios. This paper evaluates an integrated real-world testbed for this scenario, by employing commercial-off-the-shelf devices including a UAV system and a machine-learning-enabled mobile platform. It presents benchmarking results about the performance of popular machine learning and computer vision frameworks such as TensorFlow and OpenCV and the associated algorithms such as YOLO, embedded in a smartphone execution environment of limited resources. The results highlight opportunities and provide insights into technical gaps to be filled to realize real-time machine-learning-based object detection on a mobile platform with constrained resources.},
keywords={Drones;Object detection;Machine learning;Machine learning algorithms;Benchmark testing;Streaming media;Machine learning;object detection;image processing;mobile platform;UAV},
doi={10.1109/WCNC.2019.8885504},
ISSN={1558-2612},
month={April},}
@INPROCEEDINGS{8898061,
author={Yang, Qi and Shi, Liangsheng and Lin, Lin},
booktitle={IGARSS 2019 - 2019 IEEE International Geoscience and Remote Sensing Symposium}, title={Plot-scale rice grain yield estimation using UAV-based remotely sensed images via CNN with time-invariant deep features decomposition},
year={2019},
volume={},
number={},
pages={7180-7183},
abstract={Crop growth models and vegetation index (VI) based methods have been commonly used to estimate rice grain yield. However, the complicated model calibration procedure and the narrow time window limit the application of these two methods, respectively. The convolutional neural network (CNN) performs better than VI-based approaches on yield estimation at the ripening stage, but the generalization of CNN still needs to be improved. The objective of this study is to improve the generality of CNN in estimating plot-scale rice grain yield using high-resolution UAV-based RGB images. A new deep learning architecture with deep features decomposition is proposed. The results showed that the proposed network is more robust than the network without deep features decomposition when the phenological stage of the test set is different from the training set. The results indicate that the time-invariant features which only relate to rice yield can be decomposed by the proposed network, and demonstrate the stable performance of proposed CNN in a wider time window for rice grain yield forecasting.},
keywords={Yield estimation;Training;Agriculture;Feature extraction;Remote sensing;Convolutional neural networks;Deep learning;UAV;deep learning;CNN;rice crop;yield estimation},
doi={10.1109/IGARSS.2019.8898061},
ISSN={2153-7003},
month={July},}
@INPROCEEDINGS{9352109,
author={Trong, Tuan Do and Tran Hai, Quan and Duc, Nam Tran and Trong Thanh, Han},
booktitle={2020 IEEE Eighth International Conference on Communications and Electronics (ICCE)}, title={A Novelty Approach to Emulate Field Data Captured by Unmanned Aerial Vehicles for Training Deep Learning Algorithms Used for Search-and-Rescue Activities at Sea},
year={2021},
volume={},
number={},
pages={288-293},
abstract={Nowadays, unmanned aerial vehicle (UAV) is gradually becoming popular and has applications in many fields of life and protection of national sovereignty over islands and sea. In particular, along with the increase in economic exploitation activities in the exclusive economic zones and climate change, the need for rescue and safety in the marine environment is urgent more than ever. The integration of deep learning algorithms into UAVs is a new trend to help finding the victim's location at sea faster as well as increase the chances of the victim being rescued. This paper proposes an method for detection of humans on the surface of the sea together with the GPS location of the victim and the algorithm to search for the victims in the orbit of concentric circles using deep learning algorithms. The novelty of the proposed system is to build a simulated marine environment to provide a diverse number of dataset for training in deep learning algorithms and simulated rescue scenarios. Thereby the costs and risks in training could be reduced as comparing to actions taking place in real marine environments.},
keywords={Deep learning;Training;Economics;Sea surface;Unmanned aerial vehicles;Safety;Global Positioning System;Unmanned Aerial Vehicle;Deep Learning;Search and Rescue},
doi={10.1109/ICCE48956.2021.9352109},
ISSN={},
month={Jan},}
@INPROCEEDINGS{8996086,
author={Cheng, Yang and Shui, Zunshi and Xu, Cheng and Feng, Tianyu and Jiang, Yiyang},
booktitle={2019 IEEE International Conference on Unmanned Systems (ICUS)}, title={Cross-cycle iterative unmanned aerial vehicle reentry guidance based on reinforcement learning},
year={2019},
volume={},
number={},
pages={587-592},
abstract={The traditional predictive correction algorithm requires a large number of iterative calculations for the predicted trajectory, which greatly occupies a large amount of computing resources, so that the real-time solution of the guidance command can not be guaranteed, and the guidance accuracy will have a large impact. And the prediction correction guidance requires the algorithm to have the ability of selfadaptation and intelligent learning. Therefore, this paper proposes a cross-cycle iterative hypersonic UAV predictive correction guidance method based on reinforcement learning. The parametric control variable (CVP) method is used to construct the parametric model of the guidance command. The actor-critic-based reinforcement learning method is used to solve the guidance command in real time, and the guidance information is effectively transmitted in the adjacent guidance solution cycle. The guidance error converges to within the allowable accuracy range during the cross-cycle iteration. Monte Carlo simulation shows that the proposed method has good adaptability to initial conditions and flight parameter uncertainty, and can guarantee the real-time performance of the guidance command while achieving high-precision guidance.},
keywords={Trajectory;Aircraft;Atmospheric modeling;Earth;Mathematical model;Iterative algorithms;Prediction algorithms;Reentry UAV;reinforcement learning;cross-cycle guidance;Monte Carlo simulation},
doi={10.1109/ICUS48101.2019.8996086},
ISSN={},
month={Oct},}
@ARTICLE{9374461,
author={Wu, Fanyi and Zhang, Hongliang and Wu, Jianjun and Han, Zhu and Poor, H. Vincent and Song, Lingyang},
journal={IEEE Transactions on Communications}, title={UAV-to-Device Underlay Communications: Age of Information Minimization by Multi-Agent Deep Reinforcement Learning},
year={2021},
volume={69},
number={7},
pages={4461-4475},
abstract={In recent years, unmanned aerial vehicles (UAVs) have unlocked numerous sensing applications, which are expected to add billions of dollars to the world economy in the next decade. To further improve the Quality-of-Service in these applications, the 3rd Generation Partnership Project has considered the use of terrestrial cellular networks to support UAV sensing services, also known as the cellular Internet of UAVs. In this paper, we consider a cellular Internet of UAVs, where the sensory data can be transmitted either to the base station via cellular links, or to the mobile devices by underlay UAV-to-Device (U2D) communications. To evaluate the freshness of the sensory data, the concept of age of information (AoI) is adopted, in which a lower AoI implies fresher data. Since UAVs' AoIs are determined by their trajectories during sensing and transmission, we investigate the AoI minimization problem for UAVs by designing their trajectories. This problem is a Markov decision problem with an infinite state-action space, and thus we utilize multi-agent deep reinforcement learning to approximate the state-action space. Then, we propose a multi-UAV trajectory design algorithm to solve this problem. Simulation results show that our proposed algorithm can achieve a lower AoI than a greedy algorithm, policy gradient algorithm, and overlay U2D scheme.},
keywords={Sensors;Unmanned aerial vehicles;Internet;Trajectory;Mobile handsets;Minimization;Task analysis;UAV-to-Device communication;cellular Internet of UAVs;age of information;multi-agent deep reinforcement learning},
doi={10.1109/TCOMM.2021.3065135},
ISSN={1558-0857},
month={July},}
@ARTICLE{9174950,
author={Li, Kai and Ni, Wei and Tovar, Eduardo and Guizani, Mohsen},
journal={IEEE Internet of Things Journal}, title={Joint Flight Cruise Control and Data Collection in UAV-Aided Internet of Things: An Onboard Deep Reinforcement Learning Approach},
year={2021},
volume={8},
number={12},
pages={9787-9799},
abstract={Employing unmanned aerial vehicles (UAVs) as aerial data collectors in Internet-of-Things (IoT) networks is a promising technology for large-scale environment sensing. A key challenge in UAV-aided data collection is that UAV maneuvering gives rise to buffer overflow at the IoT node and unsuccessful transmission due to lossy airborne channels. This article formulates a joint optimization of flight cruise control and data collection schedule to minimize network data loss as a partially observable Markov decision process (POMDP), where the states of individual IoT nodes can be obscure to the UAV. The problem can be optimally solvable by reinforcement learning, but suffers from the curse of dimensionality and becomes rapidly intractable with the growth in the number of IoT nodes. In practice, a UAV-aided IoT network contains a large number of network states and actions in POMDP while the up-to-date knowledge is not available at the UAV. We propose an onboard deep Q-network-based flight resource allocation scheme (DQN-FRAS) to optimize the online flight cruise control of the UAV and data scheduling given outdated knowledge on the network states. Numerical results demonstrate that DQN-FRAS reduces the packet loss by over 51%, as compared to existing nonlearning heuristics.},
keywords={Trajectory;Unmanned aerial vehicles;Data collection;Machine learning;Cruise control;Internet of Things;Resource management;Communication decisions;deep reinforcement learning;flight cruise control;Internet of Things (IoT);unmanned aerial vehicles (UAVs)},
doi={10.1109/JIOT.2020.3019186},
ISSN={2327-4662},
month={June},}
@INPROCEEDINGS{5544109,
author={Jevtić, Aleksandar and Andina, Diego and Jaimes, Aldo and Gomez, Jose and Jamshidi, Mo},
booktitle={2010 5th International Conference on System of Systems Engineering}, title={Unmanned Aerial Vehicle route optimization using ant system algorithm},
year={2010},
volume={},
number={},
pages={1-6},
abstract={Unmanned Aerial Vehicle (UAV) is defined as aircraft without the onboard presence of pilots. UAVs have been used to perform intelligence, surveillance, and reconnaissance missions. The UAVs are not limited to military operations, they can also be used in commercial applications such as telecommunications, ground traffic control, search and rescue operations, crop monitoring, etc. In this paper, we propose a swarm intelligence-based method for UAVs' route optimization. The team of UAVs is used for area coverage with the defined set of waypoints. The problem can be interpreted as a well-known Traveling Salesman Problem where the task is to find the route of minimal length such that all the waypoints are visited only once. We applied the Ant System algorithm and compared it with the Nearest Neighbor Search. The experimental results confirm the effectiveness of our method, especially for a large number of waypoints.},
keywords={Unmanned aerial vehicles;Military aircraft;Air traffic control;Surveillance;Reconnaissance;Military communication;Traffic control;Crops;Monitoring;Particle swarm optimization;Unmanned aerial vehicle;traveling salesman problem;swarm intelligence;ant colony optimization},
doi={10.1109/SYSOSE.2010.5544109},
ISSN={},
month={June},}
@INPROCEEDINGS{9425090,
author={Cleary, Alison and Yoo, Kristopher and Samuel, Paul and George, Sean and Sun, Fei and Israel, Steven A.},
booktitle={2020 IEEE Applied Imagery Pattern Recognition Workshop (AIPR)}, title={Machine Learning on Small UAVs},
year={2020},
volume={},
number={},
pages={1-5},
abstract={Commonly, machine learning (ML) workflows for training and inferencing occur in resource rich environments. Draper Laboratory is pushing ML to the edge. This paper shows the concept of operations (CONOPs), design parameters, and constraints the team faced for edge implementation. The overarching requirement is to fully integrate the machine learning element into the small unmanned aerial vehicle (UAV) or drone. Given the limited payload capacity and power available on small UAVs, integration of computing resources sufficient to host both ML and Autonomy functions is a challenge. Past efforts have relied on an Intel NUC as the primary processing unit. However, recent advances in GPUs provide greater computational power at low-SWaP, compatibility with ML algorithms, and sufficient CPU resources to host the UAVs autonomy element. More recently developed processing units, designed specifically for ML applications at the edge, enable scaled down variants of the algorithms for integration onto significantly smaller platforms. In this paper, we identify a common software architecting strategy that enables a micro UAV (~ 150 grams) supported by a traditional CPU and a small UAV (3 kg) configured with a GPU. Draper's automation strategy leverages the open-source Robotic Operating System (ROS). The ML models were built using open-source Python Pytorch libraries. We provide the flight test results for a vehicle detection algorithm. Future applications will include visual navigation and tracking.},
keywords={Training;Visualization;Operating systems;Vehicle detection;Software algorithms;Machine learning;Central Processing Unit;UAV;Machine Learning;On-board Processing;Workflow;Robotic Operating System (ROS)},
doi={10.1109/AIPR50011.2020.9425090},
ISSN={2332-5615},
month={Oct},}
@INPROCEEDINGS{8865525,
author={Hu, Yuanyuan and Wu, Xinjian and Zheng, Guangdi and Liu, Xiaofei},
booktitle={2019 Chinese Control Conference (CCC)}, title={Object Detection of UAV for Anti-UAV Based on Improved YOLO v3},
year={2019},
volume={},
number={},
pages={8386-8390},
abstract={While unmanned aerial vehicle (UAV) technology brings convenience to modern life, it also leads to some problems. To achieve anti-UAV, the object detection technology of UAV is the key. YOLO v3, one of single-stage detectors, has the best detection performance for balancing the accuracy and speed through capturing deep and high-level features. In the basis of YOLO v3, this paper improves it to detect UAV more precisely and it's the first time to introduce YOLO v3 based algorithm to UAV object detection for anti-UAV. It adopts last four scales of feature maps instead of last three scales of feature maps to predict bounding boxes of objects, which can obtain more texture and contour information to detect small objects. At the same time, to reduce the calculation, the size of UAV in four scales feature maps is calculated according to input data, and then the number of anchor boxes is also adjusted. The experimental results demonstrate that the proposed approach achieves better detection accuracy and obtains more accurate bounding boxes of UAV with similar speed. Therefore, the proposed UAV detection technology can be applied in the field of anti-UAV.},
keywords={Unmanned aerial vehicles;Feature extraction;Object detection;Testing;Prediction algorithms;Neural networks;Proposals;Object detection;UAV;convolution neural network;YOLO v3},
doi={10.23919/ChiCC.2019.8865525},
ISSN={1934-1768},
month={July},}
@ARTICLE{7885056,
author={Zeggada, Abdallah and Melgani, Farid and Bazi, Yakoub},
journal={IEEE Geoscience and Remote Sensing Letters}, title={A Deep Learning Approach to UAV Image Multilabeling},
year={2017},
volume={14},
number={5},
pages={694-698},
abstract={In this letter, we face the problem of multilabeling unmanned aerial vehicle (UAV) imagery, typically characterized by a high level of information content, by proposing a novel method based on convolutional neural networks. These are exploited as a means to yield a powerful description of the query image, which is analyzed after subdividing it into a grid of tiles. The multilabel classification task of each tile is performed by the combination of a radial basis function neural network and a multilabeling layer (ML) composed of customized thresholding operations. Experiments conducted on two different UAV image data sets demonstrate the promising capability of the proposed method compared to the state of the art, at the expense of a higher but still contained computation time.},
keywords={Unmanned aerial vehicles;Training;Neural networks;Feature extraction;Histograms;Image segmentation;Computer architecture;Convolutional neural networks (CNNs);image multilabeling;Otsu’s algorithm;unmanned aerial vehicles (UAVs);urban monitoring},
doi={10.1109/LGRS.2017.2671922},
ISSN={1558-0571},
month={May},}
@INPROCEEDINGS{9378640,
author={Sun, Qin and Li, Hongxu and Zhang, Yingchao and Xie, Yuxian and Liu, Chengyu},
booktitle={2021 IEEE 19th World Symposium on Applied Machine Intelligence and Informatics (SAMI)}, title={A Baseline Assessment Method of UAV Swarm Resilience Based on Complex Networks*},
year={2021},
volume={},
number={},
pages={000083-000086},
abstract={Preliminary progress has been made in the assessment of unmanned aerial vehicle (UAV) swarm resilience based on complex networks. However, the evaluation results mostly use the initial performance state as the evaluation baseline, which is unreasonable. When UAV swarm performs a mission, as long as the network performance during the life cycle is sufficient to meet the mission requirements, it can be considered that UAV swarm has the resilience required to complete the mission. Therefore, a baseline assessment method of UAV swarm resilience based on complex networks is proposed in this paper. First, the baseline assessment method of UAV swarm resilience based on complex networks is characterized and investigated. Second, the effectiveness of the baseline assessment method is verified by simulation. The result shows that the baseline evaluation can effectively relax the evaluation result in a mission-oriented manner, and no longer use the initial state as the standard performance to measure the completion of the mission of UAV swarm. When UAV swarm performs a mission, it only needs to maintain or restore the resilience needed to complete the mission.},
keywords={Complex networks;Maintenance engineering;Unmanned aerial vehicles;Proposals;Task analysis;Standards;Resilience;baseline assessment;resilience;UAV swarm;complex networks},
doi={10.1109/SAMI50585.2021.9378640},
ISSN={},
month={Jan},}
@ARTICLE{8064733,
author={Chen, Yuting and Liu, Lihua and Gong, Zhiqiang and Zhong, Ping},
journal={IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing}, title={Learning CNN to Pair UAV Video Image Patches},
year={2017},
volume={10},
number={12},
pages={5752-5768},
abstract={Pairing image patches is to decide whether two image patches belong to the same scene but taken from different imaging conditions. It is a key procedure in the applications of unmanned aerial vehicle (UAV) video images. The challenges in pairing UAV image patches derive from the complex imaging conditions on UAV platforms such as jitter, frequent undefined motion, viewpoint changes, and illumination changes. Available popular methods usually follow the flowchart: preprocess images at first, then extract hand-crafted features, and finally match the extracted features through evaluating an independently predefined similarity metric. These methods could only handle part of negative factors from the complex imaging conditions and thus cannot effectively handle the challenges in pairing UAV image patches. This study aims to handle the challenges through automatically and simultaneously learning more representative features and accurate metric. Especially, this study proposes a deep learning method to jointly learn the feature representations and similarity metric over the training samples obtained from various imaging conditions. The model structure of the proposed pairing system consists of three parts: two stream convolutional neural networks (CNNs), one similarity metric layer and one softmax layer. They are jointly trained through the usual back propagation algorithm. Moreover, to further improve the performance, this study develops a transfer learning strategy for the proposed deep model. Two new training datasets from satellite scenes and UAV scenes, respectively, are built to evaluate the proposed pairing system, and the experimental results show that our method outperforms the most recent approaches in pairing UAV video image patches.},
keywords={Feature extraction;Unmanned aerial vehicles;Image processing;Convolutional neural networks;Convolutional neural network (CNN);image patch pairing;joint learning;similarity metric;transfer learning;unmanned aerial vehicle (UAV)},
doi={10.1109/JSTARS.2017.2740898},
ISSN={2151-1535},
month={Dec},}
@INPROCEEDINGS{9124759,
author={Ghavimi, Fayezeh and Jantti, Riku},
booktitle={2020 IEEE Wireless Communications and Networking Conference Workshops (WCNCW)}, title={Energy-Efficient UAV Communications with Interference Management: Deep Learning Framework},
year={2020},
volume={},
number={},
pages={1-6},
abstract={In this paper, an interference-aware energy- efficient scheme for a network of coexisting aerial-terrestrial cellular users is proposed. In particular, each aerial user aims at achieving a trade-off between maximizing energy efficiency and spectral efficiency while minimizing the incurred interference on the terrestrial users along its path. To provide a solution, we first formulate the energy efficiency problem for UAVs as an optimization problem by considering different key performance indicators (KPIs) for the network, coexisting terrestrial users, and UAVs as aerial users. Then, leveraging tools from deep learning, we transform this problem into a deep queue learning problem and present a learning-powered solution that incorporates the KPIs of interest in the design of the reward function to solve energy efficiency maximization for aerial users while minimizing interference to terrestrial users. A broad set of simulations have been conducted in order to investigate how the altitude of UAVs, and the tolerable level of interference, shape the optimal energy-efficient policy in the network. Simulation results show that the proposed scheme achieves better energy and spectral efficiency for UAV and less interference to terrestrial users incurred from aerial users. The obtained results further provide insights on the benefits of leveraging intelligent energy-efficient scheme. For example, a significant increase in the energy efficiency of aerial users with respect to increases in their spectral efficiency, while a considerable decrease in incurred interference to the terrestrial users is achieved in comparison to the non-learning scheme.},
keywords={Energy efficiency;unmanned aerial vehicle (UAV);drone;cellular networks;machine learning;deep reinforcement learning;interference management},
doi={10.1109/WCNCW48565.2020.9124759},
ISSN={},
month={April},}
@INPROCEEDINGS{9448710,
author={Lin, Ju-Shan and Chiu, Hsiao-Ting and Gau, Rung-Hung},
booktitle={2021 IEEE 93rd Vehicular Technology Conference (VTC2021-Spring)}, title={Decentralized Planning-Assisted Deep Reinforcement Learning for Collision and Obstacle Avoidance in UAV Networks},
year={2021},
volume={},
number={},
pages={1-7},
abstract={In this paper, we propose using a decentralized planning-assisted approach of deep reinforcement learning for collision and obstacle avoidance in UAV networks. We focus on a UAV network where there are multiple UAVs and multiple static obstacles. To avoid hitting obstacles without severely deviating from the ideal UAV trajectories, we propose merging adjacent obstacles based on convex hulls and design a novel trajectory planning algorithm. For UAVs to efficiently avoid collisions in a distributed manner, we propose using a decentralized multi-agent deep reinforcement learning approach based on policy gradients. In addition, we propose using a priority-based algorithm for avoiding collisions without reducing the speeds of UAVs too much. Simulation results show that the proposed decentralized planning-assisted deep reinforcement learning approach outperforms a number of baseline approaches in terms of the probability that all UAVs successfully reach their goals within the deadline.},
keywords={Vehicular and wireless technologies;Trajectory planning;Simulation;Conferences;Merging;Neural networks;Reinforcement learning;unmanned aerial vehicles;collision and obstacle avoidance;deep reinforcement learning;optimal trajectory planning},
doi={10.1109/VTC2021-Spring51267.2021.9448710},
ISSN={2577-2465},
month={April},}
@ARTICLE{9285214,
author={Abedin, Sarder Fakhrul and Munir, Md. Shirajum and Tran, Nguyen H. and Han, Zhu and Hong, Choong Seon},
journal={IEEE Transactions on Intelligent Transportation Systems}, title={Data Freshness and Energy-Efficient UAV Navigation Optimization: A Deep Reinforcement Learning Approach},
year={2021},
volume={22},
number={9},
pages={5994-6006},
abstract={In this paper, we design a navigation policy for multiple unmanned aerial vehicles (UAVs) where mobile base stations (BSs) are deployed to improve the data freshness and connectivity to the Internet of Things (IoT) devices. First, we formulate an energy-efficient trajectory optimization problem in which the objective is to maximize the energy efficiency by optimizing the UAV-BS trajectory policy. We also incorporate different contextual information such as energy and age of information (AoI) constraints to ensure the data freshness at the ground BS. Second, we propose an agile deep reinforcement learning with experience replay model to solve the formulated problem concerning the contextual constraints for the UAV-BS navigation. Moreover, the proposed approach is well-suited for solving the problem, since the state space of the problem is extremely large and finding the best trajectory policy with useful contextual features is too complex for the UAV-BSs. By applying the proposed trained model, an effective real-time trajectory policy for the UAV-BSs captures the observable network states over time. Finally, the simulation results illustrate the proposed approach is 3.6% and 3.13% more energy efficient than those of the greedy and baseline deep Q Network (DQN) approaches.},
keywords={Trajectory;Navigation;Unmanned aerial vehicles;Measurement;Data integrity;5G mobile communication;Resource management;Unmanned aerial vehicle;age of information;deep reinforcement learning;trajectory optimization},
doi={10.1109/TITS.2020.3039617},
ISSN={1558-0016},
month={Sep.},}
@INPROCEEDINGS{9348212,
author={Zhang, Xinruo and Zheng, Gan and Lambotharan, Sangarapillai},
booktitle={GLOBECOM 2020 - 2020 IEEE Global Communications Conference}, title={Trajectory Design for UAV-Assisted Emergency Communications: A Transfer Learning Approach},
year={2020},
volume={},
number={},
pages={1-6},
abstract={This paper studies the problem of trajectory design for unmanned aerial vehicle (UAV)-assisted emergency communications, where the ground base station (BS) may be no longer functioning and the UAV acts as an aerial BS to provide emergency communication services to the ground users. In the event of emergency situations, the user distribution and the geographical features of the target area may have changed dramatically while urgent demand for communications are raised by the surviving ground users. In this paper, we model UAV trajectory design problem as a deep reinforcement learning (DRL) process and propose to adopt transfer learning to leverage previously learned knowledge so as to boost up the learning procedure. Simulation results validate that with limited interactions with the environment, the UAV can rapidly and effectively adapt its trajectory to the new environment and achieve much faster convergence speed than DRL based design.},
keywords={Simulation;Transfer learning;Reinforcement learning;Emergency services;Unmanned aerial vehicles;Trajectory;Global communication;Double deep Q network;deep reinforcement learning;transfer learning;UAV trajectory design},
doi={10.1109/GLOBECOM42002.2020.9348212},
ISSN={2576-6813},
month={Dec},}
@ARTICLE{8993742,
author={Wang, Chao and Wang, Jian and Wang, Jingjing and Zhang, Xudong},
journal={IEEE Internet of Things Journal}, title={Deep-Reinforcement-Learning-Based Autonomous UAV Navigation With Sparse Rewards},
year={2020},
volume={7},
number={7},
pages={6180-6190},
abstract={Unmanned aerial vehicles (UAVs) have the potential in delivering Internet-of-Things (IoT) services from a great height, creating an airborne domain of the IoT. In this article, we address the problem of autonomous UAV navigation in large-scale complex environments by formulating it as a Markov decision process with sparse rewards and propose an algorithm named deep reinforcement learning (RL) with nonexpert helpers (LwH). In contrast to prior RL-based methods that put huge efforts into reward shaping, we adopt the sparse reward scheme, i.e., a UAV will be rewarded if and only if it completes navigation tasks. Using the sparse reward scheme ensures that the solution is not biased toward potentially suboptimal directions. However, having no intermediate rewards hinders the agent from efficient learning since informative states are rarely encountered. To handle the challenge, we assume that a prior policy (nonexpert helper) that might be of poor performance is available to the learning agent. The prior policy plays the role of guiding the agent in exploring the state space by reshaping the behavior policy used for environmental interaction. It also assists the agent in achieving goals by setting dynamic learning objectives with increasing difficulty. To evaluate our proposed method, we construct a simulator for UAV navigation in large-scale complex environments and compare our algorithm with several baselines. Experimental results demonstrate that LwH significantly outperforms the state-of-the-art algorithms handling sparse rewards and yields impressive navigation policies comparable to those learned in the environment with dense rewards.},
keywords={Navigation;Internet of Things;Unmanned aerial vehicles;Task analysis;Reinforcement learning;Space exploration;Heuristic algorithms;Deep reinforcement learning (RL);prior information;sparse reward;unmanned aerial vehicle (UAV) navigation},
doi={10.1109/JIOT.2020.2973193},
ISSN={2327-4662},
month={July},}
@INPROCEEDINGS{9609875,
author={New, Wee Kiat and Leow, Chee Yen},
booktitle={2021 26th IEEE Asia-Pacific Conference on Communications (APCC)}, title={Unmanned Aerial Vehicle (UAV) in Future Communication System},
year={2021},
volume={},
number={},
pages={217-222},
abstract={Unmanned aerial vehicle (UAV) is increasingly becoming a promising tool in communication system. On one hand, UAV has been used as an aerial communication platform to provide wireless communications. On the other hand, UAV has been employed as an aerial user equipment to perform arbitrary missions. Both of these applications are promising in terms of cost, flexibility, and automation. Nevertheless, existing works usually consider these applications separately. This limits the role of UAV in future communication system. Thus, in this paper, we relax this limitation and further visualize what UAV might provide us in the future. Specifically, we present a vision of UAV in future communication system along with new applications and capabilities. This vision provides a blueprint on how engineers can design the future communication system with UAVs playing prominent roles. We then review the current advances of UAV communications to understand the gap between vision and reality. Lastly, we outline the critical issues, challenges, and future directions toward this vision.},
keywords={Wireless communication;6G mobile communication;Visualization;Costs;Automation;Conferences;Tools;6G communications;Unmanned aerial vehicle (UAV);Drone;Artificial intelligence (AI);Machine learning (ML);Smart radio environment;Space-aerial-terrestrial-underwater integrated network (SATWIN)},
doi={10.1109/APCC49754.2021.9609875},
ISSN={2163-0771},
month={Oct},}
@INPROCEEDINGS{9348522,
author={Luong, Phuong and Gagnon, François and Labeau, Fabrice},
booktitle={2020 IEEE 92nd Vehicular Technology Conference (VTC2020-Fall)}, title={Resource Allocation in UAV-Assisted Wireless Networks Using Reinforcement Learning},
year={2020},
volume={},
number={},
pages={1-6},
abstract={In this work, we consider the downlink of an unmanned aerial vehicle (UAV) assisted cellular network consisting of multiple cooperative UAVs, whose operations are coordinated by a central ground controller using the fronthaul communications, to serve multiple ground users. A problem of jointly designing UAV's location, transmit beamforming, as well as UAV-user association is formulated in the form of mixed integer nonlinear programming (MINLP) to maximize the sum user achievable rate while considering the constraints of limited fronthaul capacity. Solving the formulated problem is computationally hard owing to the its non-convex nature and the unavailability of channel state information (CSI) due to the undetermined and flexible movement of UAVs. To tackle these effects, we propose a novel algorithm exploiting the deep Q-learning approach to take the hassles of unavailable CSI for determining UAV's location and invoking the difference of convex (DC) based optimization method to efficiently solve for the UAV's transmit beamforming and UAV-user association given the determined UAV's location. The algorithm recursively solves the formulated problem until convergence. Numerical results show that our design outperforms the existing work in terms of algorithmic convergence and network performance and achieve a gain of up to 70% compared to the existing algorithms.},
keywords={Vehicular and wireless technologies;Array signal processing;Wireless networks;Downlink;Unmanned aerial vehicles;Resource management;Convergence;Beamforming;user association;UAV placement;limited fronthaul;optimization;reinforcement learning},
doi={10.1109/VTC2020-Fall49728.2020.9348522},
ISSN={2577-2465},
month={Nov},}
@ARTICLE{9614346,
author={Shen, Gaoqing and Lei, Lei and Li, Zhilin and Cai, Shengsuo and Zhang, Lijuan and Cao, Pan and Liu, Xiaojiao},
journal={IEEE Internet of Things Journal}, title={Deep Reinforcement Learning for Flocking Motion of Multi-UAV systems: Learn from a Digital Twin},
year={2021},
volume={},
number={},
pages={1-1},
abstract={Over the past decades, unmanned aerial vehicles (UAVs) have been widely used in both military and civilian fields. In these applications, flocking motion is a fundamental but crucial operation of multi-UAV systems. Traditional flocking motion methods usually designed for a specific environment. However, the real environment is mostly unknown and stochastic, which greatly reduces the practicality of these methods. In this paper, deep reinforcement learning (DRL) is used to realize the flocking motion of multi-UAV systems. Considering that the sim-to-real problem restricts the application of DRL to the flocking motion scenario, a digital twin (DT) enabled DRL training framework is proposed to solve this problem. The DRL model can learn from DT and be quickly deployed on the real-world UAV with the help of DT. Under this training framework, this paper proposes an actor-critic DRL algorithm named behavior-coupling deep deterministic policy gradient (BCDDPG) for the flocking motion problem, which is inspired by the flocking behavior of animals. Extensive simulations are conducted to evaluate the performance of BCDDPG. Simulation results show that BCDDPG achieves a higher average reward and performs better in terms of arrival rate and collision rate compared with existing methods.},
keywords={Training;Navigation;Computational modeling;Digital twin;Reinforcement learning;Unmanned aerial vehicles;Stochastic processes;multi-UAV systems;flocking motion;deep reinforcement learning;digital twin.},
doi={10.1109/JIOT.2021.3127873},
ISSN={2327-4662},
month={},}
@ARTICLE{9356600,
author={Hajiakhondi-Meybodi, Zohreh and Mohammadi, Arash and Abouei, Jamshid},
journal={IEEE Access}, title={Deep Reinforcement Learning for Trustworthy and Time-Varying Connection Scheduling in a Coupled UAV-Based Femtocaching Architecture},
year={2021},
volume={9},
number={},
pages={32263-32281},
abstract={The paper is motivated by the urgent need, imposed by the COVID-19 pandemic, for trustworthy access to secure communication systems with the highest achievable availability and minimum latency. In this regard, we focus on an ultra-dense wireless network consisting of Femto Access Points (FAPs) and Unmanned Aerial Vehicles (UAVs), known as caching nodes, where there are more than one possible caching node to handle user's request. To efficiently cope with the dynamic topology of wireless networks and time-varying behavior of ground users, our focus is to develop an efficient connection scheduling framework, where ground users are autonomously trained to determine the optimal caching node, i.e., UAV or FAP. Our aim is to minimize users' access delay by maintaining a trade-off between the energy consumption of UAVs and the occurrence of handovers. To achieve these objectives, we formulate a multi-objective optimization problem and propose the Convolutional Neural Network (CNN) and Q-Network-based Connection Scheduling (CQN-CS) framework. More specifically, to solve the constructed multi-objective connection scheduling problem, a deep Q-Network model is developed as an efficient Reinforcement Learning (RL) approach to train ground users to handle their requests in an optimal and trustworthy fashion within the coupled UAV-based femtocaching network. The effectiveness of the proposed CQN-CS framework is evaluated in terms of the cache-hit ratio, user's access delay, energy consumption of UAVs, handover, lifetime of the network, and cumulative rewards. Based on the simulation results, the proposed CQN-CS framework illustrates significant performance improvements in companion to Q-learning and Deep Q-Network (DQN) schemes across all the aforementioned aspects.},
keywords={Delays;Handover;Energy consumption;Wireless networks;Quality of service;Unmanned aerial vehicles;Job shop scheduling;Caching;cache-hit-ratio;connection scheduling;femtocaching;femto access point (FAP);reinforcement learning;unmanned aerial vehicle (UAV)},
doi={10.1109/ACCESS.2021.3060323},
ISSN={2169-3536},
month={},}
@ARTICLE{8871183,
author={Zhu, Shichao and Gui, Lin and Cheng, Nan and Sun, Fei and Zhang, Qi},
journal={IEEE Internet of Things Journal}, title={Joint Design of Access Point Selection and Path Planning for UAV-Assisted Cellular Networks},
year={2020},
volume={7},
number={1},
pages={220-233},
abstract={Unmanned aerial vehicle (UAV)-assisted communication is envisioned as a potential solution to the data traffic explosion in the massive machine-type communications (mMTC) scenario. In this article, we investigate the UAV-assisted cellular networks, where a UAV acts as a flying relay to offload part of the data traffic from the overloaded cell to another. We utilize the practical spatial distribution of data traffic and a convincing air-to-ground channel model. The quality of service (QoS) is defined as a UAV utility function which is designed based on a packet loss ratio (PLR)-related users' cost function to represent the performance improvements brought by the UAV. We formulate a joint optimization problem to maximize the UAV utility function and then decompose it into the subproblems about the access point selection and the UAV path planning, which influence the PLR by influencing the packet collision rate and channel state. Since the access point selection subproblem is NP-hard, a game-theory-based distributed algorithm is proposed, instructing the users to select the base station (BS) or the UAV as the access point autonomously. To achieve the most superior channel state, we solve the UAV path planning subproblem by a deep reinforcement learning (DRL)-based approach, instructing the UAV to take the optimal action in each position. The simulation results show that the proposed access point selection scheme can significantly reduce the average cost of users and the proposed UAV path planning method can achieve a path with smaller average channel pathloss compared with other approaches.},
keywords={Cellular networks;Quality of service;Resource management;Trajectory;Internet of Things;Unmanned aerial vehicles;Access point selection;deep reinforcement learning (DRL);game theory;path planning;quality of service (QoS);unmanned aerial vehicle (UAV)},
doi={10.1109/JIOT.2019.2947718},
ISSN={2327-4662},
month={Jan},}
@INPROCEEDINGS{9440608,
author={Qiming, Zhu and Husheng, Wu and Zhaowang, Fu},
booktitle={2021 11th International Conference on Information Science and Technology (ICIST)}, title={A review of intelligent optimization algorithm applied to unmanned aerial vehicle swarm search task},
year={2021},
volume={},
number={},
pages={383-393},
abstract={Collaborative search is one of the key application fields of UAV swarm, Efficient and accurate algorithm is very important to complete the task of UAV swarm search, and the dynamic and real-time uncertainty of unmanned aerial vehicle swarm search task makes the problem very difficult. Therefore, in the past few years, a large number of scholars have shown strong interest in the problem of UAV swarm search task. With the rapid development of computer technology and Intelligent optimization algorithm, many Intelligent optimization algorithm have been proposed to solve this problem. However, the research on cooperative control and search algorithm is still not comprehensive, and there is a lack of induction and summary of recent research results. The purpose of this paper is to introduce the mathematical model of the search task and give a comprehensive review of the intelligence algorithms used in the swarm search task in recent years and their improvement. In addition, the results and efficiency of each algorithm to solve UAV search tasks are compared, and the advantages and disadvantages of different swarm intelligence algorithms applied to UAV swarm search tasks are summarized and summarized, so as to provide useful reference for UAV swarm to complete search tasks in the future.},
keywords={Uncertainty;Heuristic algorithms;Search problems;Unmanned aerial vehicles;Real-time systems;Task analysis;Vehicle dynamics;UAV swarm;Collaborative search;Intelligent optimization algorithm},
doi={10.1109/ICIST52614.2021.9440608},
ISSN={2573-3311},
month={May},}
@ARTICLE{9327466,
author={Liu, Wei and Xu, Jiawei and Guo, Zihui and Li, Erzhu and Li, Xing and Zhang, Lianpeng and Liu, Wensong},
journal={IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing}, title={Building Footprint Extraction From Unmanned Aerial Vehicle Images Via PRU-Net: Application to Change Detection},
year={2021},
volume={14},
number={},
pages={2236-2248},
abstract={As the manual detection of building footprint is inefficient and labor-intensive, this study proposed a method of building footprint extraction and change detection based on deep convolutional neural networks. The study modified the existing U-Net model to develop the “PRU-Net” model. PRU-Net incorporates pyramid scene parsing (PSP) to allow multiscale scene parsing, a residual block (RB) in ResNet for feature extraction, and focal loss to address sample imbalance. Within the proposed method, building footprint extraction is conducted as follows: 1) unmanned aerial vehicle images are cropped, denoised, and semantically marked, and datasets are created (including training/validation and prediction datasets); 2) the training/validation and prediction datasets are input into the full convolutional neural network PRU-Net for model training/validation and prediction. Compared with the U-Net, PSP+U-Net (PU-Net), and U-Net++ models, PRU-Net offers improved footprint extraction of buildings with a range of sizes and shapes. The large-scale experimental results demonstrated the effectiveness of the PSP module for multiscale scene analysis and the RB module for feature extraction. After demonstrating the improvements in building extraction offered by PRU-Net, the building footprint results were further processed to generate a building change map.},
keywords={Feature extraction;Buildings;Licenses;Semantics;Predictive models;Image segmentation;Data mining;Building footprint change detection;deep convolutional neural network (DCNN);U-Net;unmanned aerial vehicle (UAV) image},
doi={10.1109/JSTARS.2021.3052495},
ISSN={2151-1535},
month={},}
@INPROCEEDINGS{9500579,
author={Tao, Xi and Hafid, Abdelhakim Senhaji},
booktitle={ICC 2021 - IEEE International Conference on Communications}, title={Trajectory Design in UAV-Aided Mobile Crowdsensing: A Deep Reinforcement Learning Approach},
year={2021},
volume={},
number={},
pages={1-6},
abstract={Mobile crowdsensing (MCS) is a method of data collection by recruiting mobile devices to accomplish various sensing tasks. The mobility and intelligence of mobile devices enable an efficient solution to large-scale sensing, e.g., smart city. Unmanned aerial vehicles (UAVs), as mobile devices, can be used in MCS to perform many sensing tasks (e.g., monitoring). In addition, UAVs provide new business opportunities (e.g., package delivery) with its rapid increasing number. We aim to leverage the package delivery activities of UAVs to solve the task allocation problem of MCS. In the package delivery activities, UAVs must deliver the assigned packages to their destinations. During the package delivery, UAVs travel around to perform sensing tasks with time windows. In this case, the task allocation problem of MCS is considered as a trajectory design problem of UAVs. To plan the trajectories of UAVs, we propose a deep reinforcement learning approach, specifically, double deep Q-network with prioritized experience replay (DDQN-PER). Finally, the results of our numerical simulations show that our proposed solution outperforms two baseline solutions in terms of profit and number of completed tasks.},
keywords={Performance evaluation;Smart cities;Reinforcement learning;Numerical simulation;Mobile handsets;Unmanned aerial vehicles;Sensors;Mobile crowdsensing;unmanned aerial vehicle;trajectory design;deep reinforcement learning},
doi={10.1109/ICC42927.2021.9500579},
ISSN={1938-1883},
month={June},}
@ARTICLE{8710234,
author={Dai, Fei and Chen, Ming and Wei, Xianglin and Wang, Huibin},
journal={IEEE Access}, title={Swarm Intelligence-Inspired Autonomous Flocking Control in UAV Networks},
year={2019},
volume={7},
number={},
pages={61786-61796},
abstract={The collaboration of multiple unmanned aerial vehicles (UAVs) has stimulated the emergence of a novel wireless network paradigm named UAV network. UAV network, compared with uncoordinated UAV systems could provide wider coverage, better monitoring, and understanding of the interested area, and smarter decision-making. However, realizing the full potential of UAV network in dynamic environments poses great challenges in topology/flocking control, energy conservation, and quality of service guarantee. In this backdrop, this paper proposes a swarm intelligence-inspired autonomous flocking control scheme for UAV networks. First, based on the concept of intelligent emergence of swarm agents, a swarm intelligence-inspired multi-layer flocking control scheme is built for the flocking control problem. Second, an integrated sensing and communication method is put forward to regulate how a UAV can calculate its distances to its neighbors and its deflection angle. Finally, a series of experiments are conducted on our simulator developed on OMNeT++ and the flocking prototype to evaluate the effectiveness of the proposed scheme. The simulation and experimental results have shown that the proposed scheme could realize efficient flocking control with low energy consumption and satisfied the quality of service.},
keywords={Quality of service;Unmanned aerial vehicles;Wireless communication;Wireless sensor networks;Ad hoc networks;Energy consumption;Sensors;UAV network;swarm intelligent;flocking control;energy},
doi={10.1109/ACCESS.2019.2916004},
ISSN={2169-3536},
month={},}
@INPROCEEDINGS{9556271,
author={Khalil, Alvi Ataur and Byrne, Alexander J and Rahman, Mohammad Ashiqur and Manshaei, Mohammad Hossein},
booktitle={2021 IEEE International Conference on Smart Computing (SMARTCOMP)}, title={REPlanner: Efficient UAV Trajectory-Planning using Economic Reinforcement Learning},
year={2021},
volume={},
number={},
pages={153-160},
abstract={Advances in the unmanned aerial vehicle (UAV) design and capability, as well as decreases in the manufacturing cost, have opened up applications of UAVs in various fields, including surveillance, firefighting, cellular networks, and delivery purposes. The uniqueness of UAVs in systems creates a novel set of trajectory or path planning and coordination problems. Environments include many more points of interest (POIs) than UAVs, with obstacles and no-fly zones. We introduce REPlanner, a novel multi-agent reinforcement learning algorithm inspired by economic transactions to distribute tasks among UAVs. This system revolves around an economic theory, in particular an auction mechanism where UAVs trade assigned POIs. We formulate the path planning problem as a multi-agent economic game, where agents can cooperate and compete for resources. We then translate the problem into a partially observable Markov decision process (POMDP), which is solved using a reinforcement learning (RL) model deployed on each agent. As the system computes task distributions via UAV cooperation, it is highly resilient to any change in the swarm size. Our proposed network and economic game architecture can effectively coordinate the swarm as an emergent phenomenon while maintaining the swarm’s operation. Evaluation results prove that REPlanner efficiently outperforms conventional RL-based trajectory search.},
keywords={Economics;Training;Surveillance;Reinforcement learning;Games;Markov processes;Unmanned aerial vehicles;Unmanned aerial vehicles;reinforcement learning;path planning;trajectory optimization;swarm robotics},
doi={10.1109/SMARTCOMP52413.2021.00041},
ISSN={2693-8340},
month={Aug},}
@INPROCEEDINGS{9149196,
author={Zhao, Nan and Cheng, Yiqiang and Pei, Yiyang and Liang, Ying-Chang and Niyato, Dusit},
booktitle={ICC 2020 - 2020 IEEE International Conference on Communications (ICC)}, title={Deep Reinforcement Learning for Trajectory Design and Power Allocation in UAV Networks},
year={2020},
volume={},
number={},
pages={1-6},
abstract={Unmanned aerial vehicle (UAV) is considered to be a key component in the next-generation cellular networks. Considering the non-convex characteristic of the trajectory design and power allocation problem, it is difficult to obtain the optimal joint strategy in UAV-assisted cellular networks. In this paper, a reinforcement learning-based approach is proposed to obtain the maximum long-term network utility while meeting with user equipments' quality of service requirement. The Markov decision process (MDP) is formulated with the design of state, action space, and reward function. In order to achieve the joint optimal policy of trajectory design and power allocation, deep reinforcement learning approach is investigated. Due to the continuous action space of the MDP model, deep deterministic policy gradient approach is presented. Simulation results show that the proposed algorithm outperforms other approaches on overall network utility performance with higher system capacity and faster processing speed.},
keywords={Optimization;Trajectory;Resource management;Cellular networks;Quality of service;Interference;Wireless communication;UAV networks;trajectory design;power allocation;deep reinforcement learning},
doi={10.1109/ICC40277.2020.9149196},
ISSN={1938-1883},
month={June},}
@INPROCEEDINGS{9149151,
author={Guo, Weisi},
booktitle={ICC 2020 - 2020 IEEE International Conference on Communications (ICC)}, title={Partially Explainable Big Data Driven Deep Reinforcement Learning for Green 5G UAV},
year={2020},
volume={},
number={},
pages={1-7},
abstract={UAV enabled terrestrial wireless networks enables targeted user-centric service provisioning to en-richen both deep urban coverage and target various rural challenge areas. However, UAVs have to balance the energy consumption of flight with the benefits of wireless capacity delivery via a high dimensional optimisation problem. Classic reinforcement learning (RL) cannot meet this challenge and here, we propose to use deep reinforcement learning (DRL) to optimise both aggregate and minimum service provisioning. In order to achieve a trusted autonomy, the DRL agents have to be able to explain its actions for transparent human-machine interrogation. We design a Double Dueling Deep Q-learning Neural Network (DDDQN) with Prioritised Experience Replay (PER) and fixed Q-targets to achieve stable performance and avoid over-fitting, offering performance gains over naive DQN algorithms. We then use a big data driven case study and found that UAVs battery size determines the nature of its autonomous mission, ranging from an efficient exploiter of one hotspot (100% reward gain) to a stochastic explorer of many hotspots (60-150% reward gain). Using a variety of telecom and social media data, we infer driving Quality-of-Experience (QoE) and Quality-of-Service (QoS) metrics that are in contention with UAV power and communication constraints. Our greener UAVs (30-40% energy saved) address both quantitative QoS and qualitative QoE issues. Partial interpretability in the reinforcement learning is achieved using data features extracted in the hidden layers, offering an initial step for explainable AI (XAI) connecting machine intelligence with human expertise.},
keywords={5G mobile communication;Batteries;Wireless communication;Big Data;Machine learning;Optimization;big data;machine learning;deep reinforcement learning;radio resource management;UAV;energy efficiency;XAI},
doi={10.1109/ICC40277.2020.9149151},
ISSN={1938-1883},
month={June},}
@ARTICLE{8755391,
author={Goudos, Sotirios K. and Athanasiadou, Georgia},
journal={IEEE Antennas and Wireless Propagation Letters}, title={Application of an Ensemble Method to UAV Power Modeling for Cellular Communications},
year={2019},
volume={18},
number={11},
pages={2340-2344},
abstract={In this letter, we apply ensemble learning methods for the prediction of the ground (cellular base station) to air (flying node) received signal strength (RSS) at different heights, for future mobile communications. We model the RSS using different ensemble methods. Moreover, we propose a new ensemble method that combines results from five different methods. The proposed method also uses a recently introduced evolutionary algorithm, the Salp Swarm Algorithm, for weight optimization. The proposed method outperforms all the other methods and common ensemble methods. In this context, the produced results are compared to measurements using representative performance indices and exhibit satisfactory accuracy.},
keywords={Bagging;Sociology;Statistics;Machine learning;Training;Predictive models;Learning systems;Bagging;boosting;ensemble learning;machine learning;mobile communications;unmanned aerial vehicle (UAV)},
doi={10.1109/LAWP.2019.2926784},
ISSN={1548-5757},
month={Nov},}
@INPROCEEDINGS{8614163,
author={Vlahov, Bogdan and Squires, Eric and Strickland, Laura and Pippin, Charles},
booktitle={2018 17th IEEE International Conference on Machine Learning and Applications (ICMLA)}, title={On Developing a UAV Pursuit-Evasion Policy Using Reinforcement Learning},
year={2018},
volume={},
number={},
pages={859-864},
abstract={We present an approach for learning a reactive maneuver policy for a UAV involved in a close-quarters one-on-one aerial engagement. Specifically, UAVs with behaviors learned through reinforcement learning can match or improve upon simple, but effective behaviors for intercept. In this paper, a framework for developing reactive policies that can learn to exploit behaviors is discussed. In particular, the A3C algorithm with a deep neural network is applied to the aerial combat domain. The efficacy of the learned policy is demonstrated in Monte Carlo experiments. An architecture that can transfer the learned policy from simulation to an actual aircraft and its effectiveness in live-flight are also demonstrated.},
keywords={Aircraft;Atmospheric modeling;Training;Testing;Neural networks;Reinforcement learning;Games;UAV;A3C;reinforcement learning;real-world experiments},
doi={10.1109/ICMLA.2018.00138},
ISSN={},
month={Dec},}
@INPROCEEDINGS{9200931,
author={Yuan, Yaxiong and Lei, Lei and Vu, Thang X. and Chatzinotas, Symeon and Ottersten, Björn},
booktitle={2020 European Conference on Networks and Communications (EuCNC)}, title={Actor-Critic Deep Reinforcement Learning for Energy Minimization in UAV-Aided Networks},
year={2020},
volume={},
number={},
pages={348-352},
abstract={In this paper, we investigate a user-timeslot scheduling problem for downlink unmanned aerial vehicle (UAV)-aided networks, where the UAV serves as an aerial base station. We formulate an optimization problem by jointly determining user scheduling and hovering time to minimize UAV's transmission and hovering energy. An offline algorithm is proposed to solve the problem based on the branch and bound method and the golden section search. However, executing the offline algorithm suffers from the exponential growth of computational time. Therefore, we apply a deep reinforcement learning (DRL) method to design an online algorithm with less computational time. To this end, we first reformulate the original user scheduling problem to a Markov decision process (MDP). Then, an actor-critic-based RL algorithm is developed to determine the scheduling policy under the guidance of two deep neural networks. Numerical results show the proposed online algorithm obtains a good tradeoff between performance gain and computational time.},
keywords={Unmanned aerial vehicles;Minimization;Optimization;Processor scheduling;Approximation algorithms;Rotors;Europe;UAV-aided networks;deep reinforcement learning;actor-critic;user scheduling;energy minimization},
doi={10.1109/EuCNC48522.2020.9200931},
ISSN={2575-4912},
month={June},}
@INPROCEEDINGS{9558907,
author={Taş, Mehmet Bilge Han and Irmak, Muhammed Coşkun and Turan, Sedat and Haşıloğlu, Abdulsamet},
booktitle={2021 6th International Conference on Computer Science and Engineering (UBMK)}, title={Real-Time Puddle Detection Using Convolutional Neural Networks with Unmanned Aerial Vehicles},
year={2021},
volume={},
number={},
pages={598-602},
abstract={The study was carried out in order to enable systems with weak processing power and motion to detect objects using cloud services. In addition, the dataset is expanded by continuous labeling to create big data. In the study, it is aimed to detect objects using cloud-based deep learning methods with an unmanned aerial vehicle (UAV). In the study, training processes were carried out with Google Colaboratory, a cloud service provider. The training processes are a YOLO-based system, and a convolutional neural network was created by revising the parameters in line with the needs. The convolutional neural network model provides communication between neurons in the convolutional layers by bringing the image data to the desired pixel ranges. Unlabeled pictures are included in the training by being tagged. In this way, it is possible to continuously enlarge the data pool. Since the microcomputers used in UAVs are insufficient for these processes, a cloud-based training model has been created. As a result of the study, cloud-based deep learning models work as desired. It is possible to show the accuracy of the model with the low losses seen in the loss functions and the mAP value. Graphic cards with high processing power are needed to provide training. It is essential to use powerful graphics cards when working on image data. Cost reduced by using cloud services. The training was accelerated and high-rate object detections were made. YOLOv5x was used in the study. It is preferred because of its fast training and high frame rate. Recall 80% Precision 93% mAP 82.6% values were taken.},
keywords={Training;Graphics;Deep learning;Neurons;Object detection;Microcomputers;Unmanned aerial vehicles;cloud based deep learning;unmanned aerial vehicle;real time object detection;puddle detection;YOLOv5;convolutional neural network},
doi={10.1109/UBMK52708.2021.9558907},
ISSN={2521-1641},
month={Sep.},}
@ARTICLE{9099309,
author={Zhang, Jian and Yu, Zhitao and Mao, Shiwen and Periaswamy, Senthilkumar C. G. and Patton, Justin and Xia, Xue},
journal={IEEE Access}, title={IADRL: Imitation Augmented Deep Reinforcement Learning Enabled UGV-UAV Coalition for Tasking in Complex Environments},
year={2020},
volume={8},
number={},
pages={102335-102347},
abstract={Recent developments in Unmanned Aerial Vehicles (UAVs) and Unmanned Ground Vehicles (UGVs) have made them highly useful for various tasks. However, they both have their respective constraints that make them incapable of completing intricate tasks alone in many scenarios. For example, a UGV is unable to reach high places, while a UAV is limited by its power supply and payload capacity. In this paper, we propose an Imitation Augmented Deep Reinforcement Learning (IADRL) model that enables a UGV and UAV to form a coalition that is complementary and cooperative for completing tasks that they are incapable of achieving alone. IADRL learns the underlying complementary behaviors of UGVs and UAVs from a demonstration dataset that is collected from some simple scenarios with non-optimized strategies. Based on observations from the UGV and UAV, IADRL provides an optimized policy for the UGV-UAV coalition to work in an complementary way while minimizing the cost. We evaluate the IADRL approach in an visual game-based simulation platform, and conduct experiments that show how it effectively enables the coalition to cooperatively and cost-effectively accomplish tasks.},
keywords={Task analysis;Unmanned aerial vehicles;Machine learning;Navigation;Resource management;Gallium nitride;Land vehicles;Unmanned aerial vehicle (UAV);unmanned ground vehicle (UGV);coalition;deep reinforcement learning (DRL);imitation learning},
doi={10.1109/ACCESS.2020.2997304},
ISSN={2169-3536},
month={},}
@INPROCEEDINGS{9322761,
author={Matsui, Kai and Shirai, Hikaru and Kageyama, Yoichi and Yokoyama, Hiroshi},
booktitle={2020 Joint 11th International Conference on Soft Computing and Intelligent Systems and 21st International Symposium on Advanced Intelligent Systems (SCIS-ISIS)}, title={Learning Data Conditions for Resolution Improvement Using UAV Data},
year={2020},
volume={},
number={},
pages={1-2},
abstract={This study investigates a resolution improvement method using the visible range and its band ratio of remote sensing data. In this paper, we examined the conditions of learning data to improve the accuracy of the resolution improvement method through the band ratio of unmanned aerial vehicle data. Results obtained using the dataset with a large standard deviation had greater accuracy than those using the dataset with a small standard deviation for 72.2 % of the band ratio in the test data.},
keywords={Standards;Water quality;Unmanned aerial vehicles;Remote sensing;Training data;Training;Lakes;remote sensing;unmanned aerial vehicle;machine learning;resolution improvement},
doi={10.1109/SCISISIS50064.2020.9322761},
ISSN={},
month={Dec},}
@ARTICLE{9470972,
author={Yan, Chao and Wang, Chang and Xiang, Xiaojia and Lan, Zhen and Jiang, Yuna},
journal={IEEE Transactions on Industrial Informatics}, title={Deep Reinforcement Learning of Collision-Free Flocking Policies for Multiple Fixed-Wing UAVs Using Local Situation Maps},
year={2022},
volume={18},
number={2},
pages={1260-1270},
abstract={The evolution of artificial intelligence and Internet of Things (IoT) envision a highly integrated artificial IoT (AIoT) network. Flocking and cooperation with multiple unmanned aerial vehicles (UAVs) are expected to play a vital role in industrial AIoT networks. In this article, we formulate the collision-free flocking problem of fixed-wing UAVs as a Markov decision process and solve it in the deep reinforcement learning (DRL) framework. Our method can deal with a variable number of followers by encoding the dynamic environmental state into a fixed-length embedding tensor. Specifically, each follower constructs a fixed-size local situation map that describes the collision risks with other followers nearby. The local situation maps are used by a proposed DRL algorithm to learn the collision-free flocking behavior. To further improve the learning efficiency, we design a reference-point-based action selection strategy and an adaptive mechanism. We compare the proposed MA2D3QN algorithm with several benchmark DRL algorithms through numerical simulation, and we verify its advantages in learning efficiency and performance. Finally, we demonstrate the scalability and adaptability of MA2D3QN in a semiphysical simulation experiment.},
keywords={Collision avoidance;Informatics;Internet of Things;Unmanned aerial vehicles;Reinforcement learning;Sensors;Vehicle dynamics;Artificial Internet of Things (AIoT);collision avoidance;deep $Q$ -network (DQN);deep reinforcement learning (DRL);unmanned aerial vehicle (UAV) flocking},
doi={10.1109/TII.2021.3094207},
ISSN={1941-0050},
month={Feb},}
@INPROCEEDINGS{9641386,
author={Huang, Lizhen and Liu, Chunhui and Dong, Zanliang},
booktitle={2021 IEEE International Conference on Unmanned Systems (ICUS)}, title={Deep Reinforcement Learning Based Collaborative Optimization of Communication Resource and Route for UAV Cluster},
year={2021},
volume={},
number={},
pages={69-73},
abstract={To solve the communication service quality reduction and real-time route planning difficulty issues caused by inter-node interference in typical logistics environments, this paper proposes a deep reinforcement learning based method to realize the collaborative optimization of communication resource allocation and route planning for the UAV cluster. Simulation experiments show that the communication agents among UAV nodes can effectively learn to minimize the communication transmission interference while ensuring the latency constraint. The system communication capacity obtained by the proposed approach is about 2.15 times of the random resource allocation method. Meanwhile, a reasonable route is planned for each UAV node to facilitate the completion rate of logistics distribution tasks to reach 81.25%.},
keywords={Simulation;Collaboration;Reinforcement learning;Interference;Real-time systems;Planning;Resource management;UAV Cluster System;Communication Resource Allocation;Route Planning;Deep Reinforcement Learning},
doi={10.1109/ICUS52573.2021.9641386},
ISSN={},
month={Oct},}
@ARTICLE{9082162,
author={Samir, Moataz and Ebrahimi, Dariush and Assi, Chadi and Sharafeddine, Sanaa and Ghrayeb, Ali},
journal={IEEE Transactions on Mobile Computing}, title={Leveraging UAVs for Coverage in Cell-Free Vehicular Networks: A Deep Reinforcement Learning Approach},
year={2021},
volume={20},
number={9},
pages={2835-2847},
abstract={The success in transitioning towards smart cities relies on the availability of information and communication technologies that meet the demands of this transformation. The terrestrial infrastructure presents itself as a preeminent component in this change. Unmanned aerial vehicles (UAVs) empowered with artificial intelligence (AI) are expected to become an integral component of future smart cities that provide seamless coverage for vehicles on highways with poor cellular infrastructure. Motivated by the above, in this paper, we introduce UAVs cell-free network for providing coverage to vehicles entering a highway that is not covered by other infrastructure. However, UAVs have limited energy resources and cannot serve the entire highway all the time. Furthermore, the deployed UAVs have insufficient knowledge about the environment (e.g., the vehicles' instantaneous location). Therefore, it is challenging to control a swarm of UAVs to achieve efficient communication coverage. To address these challenges, we formulate the trajectories decisions making as a Markov decision process (MDP) where the system state space considers the vehicular network dynamics. Then, we leverage deep reinforcement learning (DRL) to propose an approach for learning the optimal trajectories of the deployed UAVs to efficiently maximize the vehicular coverage, where we adopt Actor-Critic algorithm to learn the vehicular environment and its dynamics to handle the complex continuous action space. Finally, simulations results are provided to verify our findings and demonstrate the effectiveness of the proposed design and show that during the mission time, the deployed UAVs adapt their velocities in order to cover the vehicles.},
keywords={Trajectory;Road transportation;Reinforcement learning;Vehicle dynamics;Aerospace electronics;Wireless networks;Task analysis;UAV coverage;deep reinforcement learning;UAVs’ trajectories;drive-thru;actor-critic algorithm;vehicular networks},
doi={10.1109/TMC.2020.2991326},
ISSN={1558-0660},
month={Sep.},}
@INPROCEEDINGS{9120668,
author={Li, Xuan and Wang, Qiang and Liu, Jie and Zhang, Wenqi},
booktitle={2020 IEEE Wireless Communications and Networking Conference (WCNC)}, title={Trajectory Design and Generalization for UAV Enabled Networks:A Deep Reinforcement Learning Approach},
year={2020},
volume={},
number={},
pages={1-6},
abstract={In this paper, an unmanned aerial vehicle (UAV) flies as a base station (BS) to provide wireless communication service. We propose two algorithms for designing the trajectory of the UAV and analyze the impact of different training approaches on transferring to new environments. When the UAV is used to track users that move along some specific paths, we propose a proximal policy optimization (PPO) -based algorithm to maximize the instantaneous sum rate (MSR-PPO). The UAV is modeled as a deep reinforcement learning (DRL) agent to learn how to move by interacting with the environment. When the UAV serves users along unknown paths for emergencies, we propose a random training proximal policy optimization (RT-PPO) algorithm which can transfer the pre-trained model to new tasks to achieve quick deployment. Unlike classical DRL algorithms that the agent is trained on the same task to learn its actions, RT-PPO randomizes the features of tasks to get the ability to transfer to new tasks. Numerical results reveal that MSR-PPO achieves a remarkable improvement and RT-PPO shows an effective generalization performance.},
keywords={Training;Wireless communication;Q-learning;Tracking;Conferences;Autonomous aerial vehicles;Trajectory;unmanned aerial vehicle;trajectory design;generalization;deep reinforcement learning},
doi={10.1109/WCNC45663.2020.9120668},
ISSN={1558-2612},
month={May},}
@ARTICLE{9573512,
author={Jiang, San and Jiang, Wanshou and Guo, Bingxuan and Li, Lelin and Wang, Lizhe},
journal={IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing}, title={Learned Local Features for Structure From Motion of UAV Images: A Comparative Evaluation},
year={2021},
volume={14},
number={},
pages={10583-10597},
abstract={Unmanned aerial vehicle (UAV) images have become the main remote sensing data sources for varying applications, and structure from motion (SfM) is the golden standard for resuming camera poses. Matching local feature descriptors is the prerequisite for the accurate and complete orientation of UAV images. Recently, some newly proposed learned methods have been shown to outperform the hand-crafted methods, such as the scale invariant feature transform (SIFT) and its variants, and almost all learned methods have been trained and evaluated by using images from the internet with varying focal lengths and varying size. It is of interest to investigate the performance of these learned methods with their pretrained models for feature detection and description in the context of the SfM-based orientation. Thus, this article conducts a comprehensive evaluation of both advanced hand-crafted and newly proposed learned detectors and descriptors by using four UAV datasets. The performance of these selected methods is compared in the context of feature matching and the SfM and (multiview stereo) MVS-based reconstruction. Experimental results demonstrate that the learned descriptors combined with the SIFT-like detectors can provide accurate and complete feature correspondences and achieve better or competitive performance in the SfM and MVS-based reconstruction. For UAV image orientation, the learned descriptors can be an alternative to the existing hand-crafted descriptors without their model retraining. The source codes of this evaluation would be made publicly available.},
keywords={Feature extraction;Detectors;Measurement;Pipelines;Neural networks;Convolutional neural networks;Unmanned aerial vehicles;Three-dimensional (3-D) reconstruction;convolutional neural network (CNN);local feature matching;multiview stereo (MVS);structure-from-motion (SfM);unmanned aerial vehicle (UAV)},
doi={10.1109/JSTARS.2021.3119990},
ISSN={2151-1535},
month={},}
@ARTICLE{9679714,
author={Jinqiang, Hu and Husheng, Wu and Renjun, Zhan and Rafik, Menassel and Xuanwu, Zhou},
journal={Journal of Systems Engineering and Electronics}, title={Self-organized search-attack mission planning for UAV swarm based on wolf pack hunting behavior},
year={2021},
volume={32},
number={6},
pages={1463-1476},
abstract={Cooperative search-attack is an important application of unmanned aerial vehicle (UAV) swarm in military field. The coupling between path planning and task allocation, the heterogeneity of UAVs, and the dynamic nature of task environment greatly increase the complexity and difficulty of the UAV swarm cooperative search-attack mission planning problem. Inspired by the collaborative hunting behavior of wolf pack, a distributed self-organizing method for UAV swarm search-attack mission planning is proposed. First, to solve the multi-target search problem in unknown environments, a wolf scouting behavior-inspired cooperative search algorithm for UAV swarm is designed. Second, a distributed self-organizing task allocation algorithm for UAV swarm cooperative attacking of targets is proposed by analyzing the flexible labor division behavior of wolves. By abstracting the UAV as a simple artificial wolf agent, the flexible motion planning and group task coordinating for UAV swarm can be realized by self-organizing. The effectiveness of the proposed method is verified by a set of simulation experiments, the stability and scalability are evaluated, and the integrated solution for the coupled path planning and task allocation problems for the UAV swarm cooperative search-attack task can be well performed.},
keywords={Task analysis;Autonomous aerial vehicles;Search problems;Resource management;Planning;Scalability;Path planning;search-attack mission planning;unmanned aerial vehicle (UAV) swarm;wolf pack;hunting behavior;swarm intelligence;labor division},
doi={10.23919/JSEE.2021.000124},
ISSN={1004-4132},
month={Dec},}
@INPROCEEDINGS{9549299,
author={Zhou, Huan and Zhang, Senyu and Sun, Chu and Ru, Changjian},
booktitle={2021 40th Chinese Control Conference (CCC)}, title={Intelligent Maneuver Decision Method of UAV based on Reinforcement Learning and Neural Network},
year={2021},
volume={},
number={},
pages={8544-8549},
abstract={The efficiency of UAV maneuver decision-making based on the traditional maneuver control quantity is the key to restrict the improvement of UAV autonomous air combat game ability in complex battlefield environment. By refining pilots' combat training and air combat thinking experience, the intelligent maneuver decision-making method for UAV autonomous air combat can effectively improve the UAV autonomous air combat efficiency. Aiming at the problem of maneuver decision-making in continuous state space, this paper designs an autonomous maneuver decision-making model based on actor critical reinforcement learning theory, adopts NRBF neural network as the value function approximator, the action controller outputs continuous control variables, and introduces Gaussian random action variables to balance the problem of "exploration utilization" in strategy learning A state space adaptive adjustment method based on relative entropy distance is proposed to simplify the network structure and enhance the learning ability of the network. The simulation results show that the proposed method has the ability of air combat confrontation, the output control quantity is smooth, and the strategy learning efficiency is higher.},
keywords={Training;Adaptive systems;Simulation;Decision making;Neural networks;Refining;Reinforcement learning;UAV;Intelligent Decision;Reinforcement Learning;Neural Network and Autonomous Air Combat},
doi={10.23919/CCC52363.2021.9549299},
ISSN={1934-1768},
month={July},}
@INPROCEEDINGS{9341802,
author={Kumar, Ashish and Vohra, Mohit and Prakash, Ravi and Behera, L.},
booktitle={2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)}, title={Towards Deep Learning Assisted Autonomous UAVs for Manipulation Tasks in GPS-Denied Environments},
year={2020},
volume={},
number={},
pages={1613-1620},
abstract={In this work, we present a pragmatic approach to enable unmanned aerial vehicle (UAVs) to autonomously perform highly complicated tasks of object pick and place. This paper is largely inspired by challenge-2 of MBZIRC 2020 and is primarily focused on the task of assembling large 3D structures in outdoors and GPS-denied environments. Primary contributions of this system are: (i) a novel computationally efficient deep learning based unified multi-task visual perception system for target localization, part segmentation, and tracking, (ii) a novel deep learning based grasp state estimation, (iii) a retracting electromagnetic gripper design, (iv) a remote computing approach which exploits state-of-the-art MIMO based high speed (5000Mb/s) wireless links to allow the UAVs to execute compute intensive tasks on remote high end compute servers, and (v) system integration in which several system components are weaved together in order to develop an optimized software stack. We use DJI Matrice-600 Pro, a hexrotor UAV and interface it with the custom designed gripper. Our framework is deployed on the specified UAV in order to report the performance analysis of the individual modules. Apart from the manipulation system, we also highlight several hidden challenges associated with the UAVs in this context.},
keywords={Deep learning;Wireless communication;State feedback;Unmanned aerial vehicles;Task analysis;Grippers;Visual perception},
doi={10.1109/IROS45743.2020.9341802},
ISSN={2153-0866},
month={Oct},}
@INPROCEEDINGS{9348556,
author={Chen, Wei and Chang, Deng-Kai and Chen, Yu-Jia},
booktitle={2020 IEEE 92nd Vehicular Technology Conference (VTC2020-Fall)}, title={Combating the Impact of Jittering in UAV-based Sensing Systems Using Deep Denoising Network},
year={2020},
volume={},
number={},
pages={1-3},
abstract={In this paper, we exploit the deep learning based technologies to mitigate the impact of unmanned aerial vehicle (UAV) jittering on wireless sensing performance. In recent years, UAV has been widely utilized for remote sensing applications due to its high flexibility and maneuverability. However, the mobility and vibration of the UAV's body may cause the jittering effect which can severely degrade the sensing performance. To our best knowledge, the impact of UAV jittering has not been fully examined in literature so far. To alleviate this problem, we propose to leverage adversarial denoising autoencoder (ADAE) for corrupted signal reconstruction. To validate the effectiveness of our proposed scheme, we consider a device-free human sensing scenario in which a UAV is used to sense surrounding human activity by analyzing the received signal strength (RSS). Experiments demonstrate that the proposed ADAE based scheme can effectively reduce the impact of UAV jittering, recovering up to 97% of the performance loss due to the UAV jittering.},
keywords={Performance evaluation;Wireless communication;Vibrations;Wireless sensor networks;Noise reduction;Unmanned aerial vehicles;Sensors;Unmanned aerial vehicles (UAVs);wireless sensing;jittering},
doi={10.1109/VTC2020-Fall49728.2020.9348556},
ISSN={2577-2465},
month={Nov},}
@ARTICLE{9520121,
author={Zhong, Ruikang and Liu, Xiao and Liu, Yuanwei and Chen, Yue},
journal={IEEE Transactions on Wireless Communications}, title={Multi-Agent Reinforcement Learning in NOMA-aided UAV Networks for Cellular Offloading},
year={2021},
volume={},
number={},
pages={1-1},
abstract={A novel framework is proposed for cellular offloading with the aid of multiple unmanned aerial vehicles (UAVs), while non-orthogonal multiple access (NOMA) technique is employed at each UAV to further improve the spectrum efficiency of the wireless network. The optimization problem of joint three-dimensional (3D) trajectory design and power allocation is formulated for maximizing the throughput. Since ground mobile users are considered as roaming continuously, the UAVs need to be re-deployed timely based on the movement of users. In an effort to solve this pertinent dynamic problem, a K-means based clustering algorithm is first adopted for periodically partitioning users. Afterward, a mutual deep Q-network (MDQN) algorithm is proposed to jointly determine the optimal 3D trajectory and power allocation of UAVs. In contrast to the conventional deep Q-network (DQN) algorithm, the MDQN algorithm enables the experience of multi-agent to be input into a shared neural network to shorten the training time with the assistance of state abstraction. Numerical results demonstrate that: 1) the proposed MDQN algorithm is capable of converging under minor constraints and has a faster convergence rate than the conventional DQN algorithm in the multi-agent case; 2) The achievable sum rate of the NOMA enhanced UAV network is 23% superior to the case of orthogonal multiple access (OMA); 3) By designing the optimal 3D trajectory of UAVs with the MDON algorithm, the sum rate of the network enjoys 142% and 56% gains than invoking the circular trajectory and the 2D trajectory, respectively.},
keywords={Trajectory;NOMA;Resource management;Unmanned aerial vehicles;Heuristic algorithms;Cellular networks;Base stations;Deep Q-network;non-orthogonal multiple access;reinforcement learning;unmanned aerial vehicle},
doi={10.1109/TWC.2021.3104633},
ISSN={1558-2248},
month={},}
@INPROCEEDINGS{8482830,
author={Xu, Yinbo and Liu, Zhihong and Wang, Xiangke},
booktitle={2018 37th Chinese Control Conference (CCC)}, title={Monocular Vision based Autonomous Landing of Quadrotor through Deep Reinforcement Learning},
year={2018},
volume={},
number={},
pages={10014-10019},
abstract={An improved deep reinforcement learning (DRL) method is proposed to solve autonomous landing problem of quadrotor. Autonomous landing is a significant function for unmanned aerial vehicle (UAV) such as quadrotor. Previous solutions are mainly based on relative position calculation or the landmark detection, which either needs massive additional sensors or lacks intelligence. In this paper, we focus on realizing autonomous landing through DRL method. Whole landing process is implemented by an improved deep Q-learning network (DQN) based end-to-end control scheme. Only one down-looking camera is used to capture raw images directly as input states. An Aruco tag is placed at the landing region for feature extraction. Double network and the dueling architecture are applied to improve DQN algorithm. Besides, the reward function is well designed to fit the auto-landing scenario. The experiments show that the improved DQN can make the quadrotor land on the landmark successfully and achieve better performance while comparing to the original deep Q-learning solution.},
keywords={Training;Computer architecture;Machine learning;Cameras;Feature extraction;Neural networks;Unmanned aerial vehicles;Unmanned Aerial Vehicle (UAV);Autonomous Landing;Deep Reinforcement Learning (DRL);DQN},
doi={10.23919/ChiCC.2018.8482830},
ISSN={1934-1768},
month={July},}
@ARTICLE{9638979,
author={Zhu, Botao and Bedeer, Ebrahim and Nguyen, Ha H. and Barton, Robert and Henry, Jerome},
journal={IEEE Internet of Things Journal}, title={Joint Cluster Head Selection and Trajectory Planning in UAV-Aided IoT Networks by Reinforcement Learning with Sequential Model},
year={2021},
volume={},
number={},
pages={1-1},
abstract={Employing unmanned aerial vehicles (UAVs) has attracted growing interests and emerged as the state-of-the-art technology for data collection in Internet-of-Things (IoT) networks. In this paper, with the objective of minimizing the total energy consumption of the UAV-IoT system, we formulate the problem of jointly designing the UAV’s trajectory and selecting cluster heads in the IoT network as a constrained combinatorial optimization problem which is classified as NP-hard, and challenging to solve. We propose a novel deep reinforcement learning (DRL) with a sequential model strategy that can effectively learn the policy represented by a sequence-to-sequence neural network for the UAV’s trajectory design in an unsupervised manner. Through extensive simulations, the obtained results show that the proposed DRL method can find the UAV’s trajectory that requires much less energy consumption when compared to other baseline algorithms and achieves close-to-optimal performance. In addition, simulation results show that the trained model by our proposed DRL algorithm has an excellent generalization ability to larger problem sizes without the need to retrain the model.},
keywords={Energy consumption;Trajectory;Machine learning algorithms;Wireless sensor networks;Trajectory planning;Internet of Things;Clustering algorithms;Deep reinforcement learning;Internet-of-Things;UAV;cluster head selection;trajectory planning.},
doi={10.1109/JIOT.2021.3133278},
ISSN={2327-4662},
month={},}
@ARTICLE{9171468,
author={Ding, Ruijin and Gao, Feifei and Shen, Xuemin Sherman},
journal={IEEE Transactions on Wireless Communications}, title={3D UAV Trajectory Design and Frequency Band Allocation for Energy-Efficient and Fair Communication: A Deep Reinforcement Learning Approach},
year={2020},
volume={19},
number={12},
pages={7796-7809},
abstract={Unmanned Aerial Vehicle (UAV)-assisted communication has drawn increasing attention recently. In this paper, we investigate 3D UAV trajectory design and band allocation problem considering both the UAV's energy consumption and the fairness among the ground users (GUs). Specifically, we first formulate the energy consumption model of a quad-rotor UAV as a function of the UAV's 3D movement. Then, based on the fairness and the total throughput, the fair throughput is defined and maximized within limited energy. We propose a deep reinforcement learning (DRL)-based algorithm, named as EEFC-TDBA (energy-efficient fair communication through trajectory design and band allocation) that chooses the state-of-the-art DRL algorithm, deep deterministic policy gradient (DDPG), as its basis. EEFC-TDBA allows the UAV to: 1) adjust the flight speed and direction so as to enhance the energy efficiency and reach the destination before the energy is exhausted; and 2) allocate frequency band to achieve fair communication service. Simulation results are provided to demonstrate that EEFC-TDBA outperforms the baseline methods in terms of the fairness, the total throughput, as well as the minimum throughput.},
keywords={Mathematical model;Maintenance engineering;Biological system modeling;Numerical models;Weibull distribution;Unmanned aerial vehicles;Atmospheric modeling;3D UAV trajectory;band allocation;energy-efficient;fair communication;deep reinforcement learning},
doi={10.1109/TWC.2020.3016024},
ISSN={1558-2248},
month={Dec},}
@ARTICLE{9453123,
author={Ho, Tai Manh and Nguyen, Kim-Khoa and Cheriet, Mohamed},
journal={IEEE Transactions on Vehicular Technology}, title={UAV Control for Wireless Service Provisioning in Critical Demand Areas: A Deep Reinforcement Learning Approach},
year={2021},
volume={70},
number={7},
pages={7138-7152},
abstract={In this paper, we investigate the problem of wireless service provisioning through a rotary-wing UAV which can serve as an aerial base station (BS) to communicate with multiple ground terminals (GTs) in a boost demand area. Our objective is to optimize the UAV control for maximizing the UAV.s energy efficiency, in which both aerodynamic energy and communication energy are considered while ensuring the communication requirements for each GT and backhaul link between the UAV and the terrestrial BS. The mobility of the UAV and GTs lead to time-varying channel conditions that make the environment dynamic. We formulate a nonconvex optimization for controlling the UAV considering the practical angle-dependent Rician fading channels between the UAV and GTs, and between the UAV and the terrestrial BS. Traditional optimization approaches are not able to handle the dynamic environment and high complexity of the problem in real-time. We propose to use a deep reinforcement learning-based approach namely Deep Deterministic Policy Gradient (DDPG) to solve the formulated nonconvex problem of UAV control with continuous action space that takes into account the real-time of the environment including time-varying UAV-ground channel conditions, available onboard energy of the UAV, and the communication requirement of the GTs. However, the DDPG method may not achieve good performance in an unstable environment and will face a large number of hyperparameters. We extend our approach to use the Trust Region Policy Optimization (TRPO) method that can improve the performance of the UAV compared to the DDPG method in such a dynamic environment.},
keywords={Energy consumption;Wireless communication;Propulsion;Trajectory;Optimization;Unmanned aerial vehicles;Vehicle dynamics;5 G;airbone;UAV control;deep reinforcement learning;trust region policy optimization},
doi={10.1109/TVT.2021.3088129},
ISSN={1939-9359},
month={July},}
@ARTICLE{8536405,
author={Zhu, Jiasong and Sun, Ke and Jia, Sen and Li, Qingquan and Hou, Xianxu and Lin, Weidong and Liu, Bozhi and Qiu, Guoping},
journal={IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing}, title={Urban Traffic Density Estimation Based on Ultrahigh-Resolution UAV Video and Deep Neural Network},
year={2018},
volume={11},
number={12},
pages={4968-4981},
abstract={This paper presents an advanced urban traffic density estimation solution using the latest deep learning techniques to intelligently process ultrahigh-resolution traffic videos taken from an unmanned aerial vehicle (UAV). We first capture nearly an hour-long ultrahigh-resolution traffic video at five busy road intersections of a modern megacity by flying a UAV during the rush hours. We then randomly sampled over 17 K 512×512 pixel image patches from the video frames and manually annotated over 64 K vehicles to form a dataset for this paper, which will also be made available to the research community for research purposes. Our innovative urban traffics analysis solution consists of an advanced deep neural network (DNN) based vehicle detection and localization, type (car, bus, and truck) recognition, tracking, and vehicle counting over time. We will present extensive experimental results to demonstrate the effectiveness of our solution. We will show that our enhanced single shot multibox detector (Enhanced-SSD) outperforms other DNN-based techniques and that deep learning techniques are more effective than traditional computer vision techniques in traffic video analysis. We will also show that ultrahigh-resolution video provides more information that enables more accurate vehicle detection and recognition than lower resolution contents. This paper not only demonstrates the advantages of using the latest technological advancements (ultrahigh-resolution video and UAV), but also provides an advanced DNN-based solution for exploiting these technological advancements for urban traffic density estimation.},
keywords={Neural networks;Traffic control;Unmanned aerial vehicles;Vehicle detection;Urban areas;Road traffic;Deep neural networks (DNNs);road traffic monitoring;traffic density estimation;unmanned aerial vehicle (UAV);vehicle counting;vehicle detection;vehicle tracking},
doi={10.1109/JSTARS.2018.2879368},
ISSN={2151-1535},
month={Dec},}
@ARTICLE{9143143,
author={Yuan, Weijie and Liu, Chang and Liu, Fan and Li, Shuangyang and Ng, Derrick Wing Kwan},
journal={IEEE Wireless Communications Letters}, title={Learning-Based Predictive Beamforming for UAV Communications With Jittering},
year={2020},
volume={9},
number={11},
pages={1970-1974},
abstract={As a promising technique for realizing future wireless networks, unmanned aerial vehicle (UAV) communications have drawn numerous attentions. The performance of practical UAV communication systems is limited by the presence of inevitable jittering due to the inherent random wind gusts. The jittering introduces angle ambiguity which is challenging for aligning the information beams between the UAV-mounted base station (BS) and the user equipment (UE). This letter develops a learning-based predictive beamforming scheme to address the beam misalignment caused by UAV jittering. In particular, a deep learning approach is adopted to predict the angles between the UAV and the UE. By doing so, the UAV and the UE can prepare the transmit and receive beams in advance, which enables reliable UAV-based communication. Simulation results verify that the communication performance of the proposed scheme is robust to the presence of UAV jittering.},
keywords={Array signal processing;Unmanned aerial vehicles;Machine learning;Reliability;Prediction algorithms;Signal to noise ratio;Communication systems;UAV jittering;deep learning;predictive beamforming},
doi={10.1109/LWC.2020.3009951},
ISSN={2162-2345},
month={Nov},}
@INPROCEEDINGS{9322358,
author={Kim, Hyeong Tae and Kim, Hwangnam},
booktitle={GLOBECOM 2020 - 2020 IEEE Global Communications Conference}, title={Precise Localization of a UAV with Single Vision Camera and Deep Learning},
year={2020},
volume={},
number={},
pages={1-6},
abstract={This paper suggests a novel method of detecting and estimating the position of Unmanned Aerial Vehicle (UAV) with a single monocular camera only. As the leverage of UAV is keep on increasing, the related research has been extremely developed. To successfully use a UAV in a variety of missions, a precise localization technique is essential. However, there is still a lack of research to accurately measure the vehicle's present altitude. Thus, this study conducted a simple but accurate altitude measurement method using a camera. First, UAV detection is initially proceeded by using a deep learning approach. After determining that the object displayed in the image is UAV, the altitude is calculated with a distance measuring formula using the camera's Field of View (FOV). Besides, zooming, cropping, and some image processing are performed to enhance the accuracy of the altitude value. As a result, average errors of less than 5% and errors of up to 60cm were obtained, which is an improvement over previous altitude measurement techniques. This method can calibrate the altitude of the UAV immediately in a relatively inexpensive and simple way.},
keywords={Cameras;Drones;Mathematical model;Estimation;Global Positioning System;Object detection;Location awareness;UAV;Localization;Altitude;FOV;Deep learning},
doi={10.1109/GLOBECOM42002.2020.9322358},
ISSN={2576-6813},
month={Dec},}
@INPROCEEDINGS{9274875,
author={Zhen, Yan and Hao, Mingrui and Sun, Wendi},
booktitle={2020 3rd International Conference on Unmanned Systems (ICUS)}, title={Deep Reinforcement Learning Attitude Control of Fixed-Wing UAVs},
year={2020},
volume={},
number={},
pages={239-244},
abstract={The fixed-wing UAV is a non-linear and strongly coupled system. Controlling UAV attitude stability is the basis for ensuring flight safety and performing tasks successfully. The non-linear characteristic of the UAV is the main reason for the difficulty of attitude stabilization. Deep reinforcement learning for the UAV attitude control is a new method to design controller. The algorithm learns the nonlinear characteristics of the system from the training data. Due to the good performance, the PPO algorithm is the mainly algorithm of reinforcement learning. The PPO algorithm interacts with the reinforcement learning training environment by gazebo, and improve attitude controller, different from the traditional PID control method, the attitude controller based on deep reinforcement learning uses the neural network to generate control signals and controls the rotation of rudder directly.},
keywords={Intelligent agents;Complex systems;Reinforcement learning;Training;TV;Research and development;Phase shift keying;aircraft;reinforcement learning;controller;attitude;policy},
doi={10.1109/ICUS50048.2020.9274875},
ISSN={},
month={Nov},}
@INPROCEEDINGS{9322539,
author={Wu, Fanyi and Zhang, Hongliang and Wu, Jianjun and Song, Lingyang and Han, Zhu and Poor, H. Vincent},
booktitle={GLOBECOM 2020 - 2020 IEEE Global Communications Conference}, title={AoI Minimization for UAV-to-Device Underlay Communication by Multi-agent Deep Reinforcement Learning},
year={2020},
volume={},
number={},
pages={1-6},
abstract={In this paper, we consider a cellular Internet of UAVs, where the sensory data can be transmitted either to the base station via cellular links, or to the mobile devices by underlay UAV-to-Device communications. To evaluate the freshness of the sensory data, the age of information (AoI) is adopted, in which a lower AoI implies fresher data. Since UAVs' AoIs are determined by their trajectories during sensing and transmission, we aim to minimize the AoIs of UAVs by designing their trajectories. This problem is a Markov decision problem with an infinite state-action space, and thus, we propose a multi-UAV trajectory design algorithm by leveraging multi-agent deep reinforcement learning to solve it. Simulation results show that our proposed algorithm outperforms both a greedy algorithm and a policy gradient algorithm.},
keywords={Sensors;Internet;Trajectory;Mobile handsets;Throughput;Resource management;Protocols;UAV-to-Device communication;cellular Internet of UAVs;multi-agent deep reinforcement learning},
doi={10.1109/GLOBECOM42002.2020.9322539},
ISSN={2576-6813},
month={Dec},}
@INPROCEEDINGS{7726139,
author={Sugimoto, Takuya and Gouko, Manabu},
booktitle={2016 3rd International Conference on Information Science and Control Engineering (ICISCE)}, title={Acquisition of Hovering by Actual UAV Using Reinforcement Learning},
year={2016},
volume={},
number={},
pages={148-152},
abstract={In this study, we applied reinforcement learning to actual quadrotor unmanned aerial vehicles (UAVs). It is expected that UAVs will contribute to multiple fields (e.g., rescue, sports, and entertainment). However, the autonomous control of UAVs is still a difficult problem to solve. We applied reinforcement learning to a UAV to achieve stable hovering. Q-learning, a common reinforcement learning method, was used in our study. Several previous studies on learning controllers for UAVs have been conducted. However, most of these studies only carried out computer simulations to verify the effectiveness of the learning method. Conversely, we conducted our experiment using an actual quadrotor UAV. The experimental results demonstrate that the UAV can acquire knowledge to achieve stable hovering over a marker placed on the ground. We also compared the performances of a trained UAV (using the learning method) and a UAV controlled by a PID controller. The result indicates that a trained UAV can hover as stably as one controlled by the PID.},
keywords={Drones;Learning (artificial intelligence);Cameras;Robots;Computers;Learning systems;Unmanned aerial vehicles;reinforcement learning},
doi={10.1109/ICISCE.2016.42},
ISSN={},
month={July},}
@ARTICLE{8894381,
author={Huang, Hongji and Yang, Yuchun and Wang, Hong and Ding, Zhiguo and Sari, Hikmet and Adachi, Fumiyuki},
journal={IEEE Transactions on Vehicular Technology}, title={Deep Reinforcement Learning for UAV Navigation Through Massive MIMO Technique},
year={2020},
volume={69},
number={1},
pages={1117-1121},
abstract={Unmanned aerial vehicles (UAVs) technique has been recognized as a promising solution in future wireless connectivity from the sky, and UAV navigation is one of the most significant open research problems, which has attracted wide interest in the research community. However, the current UAV navigation schemes are unable to capture the UAV motion and select the best UAV-ground links in real-time, and these weaknesses overwhelm the UAV navigation performance. To tackle these fundamental limitations, in this paper, we merge the state-of-the-art deep reinforcement learning with the UAV navigation through massive multiple-input-multiple-output (MIMO) technique. To be specific, we carefully design a deep Q-network (DQN) for optimizing the UAV navigation by selecting the optimal policy, and then we propose a learning mechanism for processing the DQN. The DQN is trained so that the agent is capable of making decisions based on the received signal strengths for navigating the UAVs with the aid of the powerful Q-learning. Simulation results are provided to corroborate the superiority of the proposed schemes in terms of the coverage and convergence compared with those of the other schemes.},
keywords={Navigation;Reinforcement learning;Wireless communication;Unmanned aerial vehicles;Signal to noise ratio;Massive multiple-input-multiple-output (MIMO);deep reinforcement learning;UAV navigation},
doi={10.1109/TVT.2019.2952549},
ISSN={1939-9359},
month={Jan},}
@INPROCEEDINGS{9448887,
author={Mammeri, Abdelhamid and Jabbar Siddiqui, Abdul and Zhao, Yiheng},
booktitle={2021 IEEE 93rd Vehicular Technology Conference (VTC2021-Spring)}, title={UAV-assisted Railway Track Segmentation based on Convolutional Neural Networks},
year={2021},
volume={},
number={},
pages={1-7},
abstract={In the railway sector, track inspections are regularly needed to monitor the track conditions for potential hazards in order to ensure safety and security of life and property. Recently, conducting infrastructure inspections and monitoring using UAVs has gained attention in various industries including the railways. The rapid development of advanced deep learning and machine vision techniques have given rise to automated railway hazard detection systems based on UAV-based imagery. A major task in such systems is to localize or segment the railway tracks in UAV-based images. This paper investigates the effectiveness of a fully convolutional encoder-decoder type segmentation network called U-Net for the task of segmenting rail track regions from UAV-based images. Through experimental evaluations using a proprietary real-world dataset, we demonstrate U-Net's effectiveness in terms of mean Intersection over Union (IoU). Such methods of rail track segmentation are particularly useful in applications such as automated UAV navigation along rail tracks.},
keywords={Rails;Training;Image segmentation;Object segmentation;Inspection;Rail transportation;Hazards;Railway Track Segmentation;UAV Imagery;UAV-based Inspections},
doi={10.1109/VTC2021-Spring51267.2021.9448887},
ISSN={2577-2465},
month={April},}
@INPROCEEDINGS{9066764,
author={Zhang, Song and Chen, Bin and Wang, Renshu and Wang, Jiayu and Zhong, Linlin and Gao, Bingtuan},
booktitle={2019 IEEE 9th Annual International Conference on CYBER Technology in Automation, Control, and Intelligent Systems (CYBER)}, title={Unmanned Aerial Vehicle (UAV) Vision-based Detection of Power Line Poles by CPU-based Deep Learning Method},
year={2019},
volume={},
number={},
pages={1630-1634},
abstract={More and more power supply companies use Unmanned Aerial Vehicles (UAV) for power line inspection. UAVs allow almost immediate inspection of power lines after extreme weather events. However, the current UAV vision based damage assessments have still been performed manually, which is time-consuming, poor efficient, and low accurate. In this work, a fast CPU-based detection model is presented for detecting normal and abnormal power line poles from the UAV vision data after typhoon striking. Three types of poles including two types of normal poles and one type of abnormal poles are considered. The detection process is designed in two stages. The first stage is to generate candidate boxes of poles based on the YOLO-Lite model, and the second stage is to filter the background candidate boxes based on the classification model of the SPP (Spatial Pyramid Pooling) network structure. The combined model achieves a detection precision of 75.80%, an increase of 26.85% compared to the YOLO-Lite model alone, and reaches a recall of 57.33%. The combined poles detection model runs at 9 FPS (Frames Per Second) on a CPU-only computer.},
keywords={Testing;Training;Pattern analysis;Computer vision;Conferences;Automation;Control systems},
doi={10.1109/CYBER46603.2019.9066764},
ISSN={2379-7711},
month={July},}
@INPROCEEDINGS{8623737,
author={Guo, Lu and Li, Xin-Rui and Huang, He and Jing, Song and He, Yong-Chao and Wang, Cheng-Zhuang},
booktitle={2018 Chinese Automation Congress (CAC)}, title={Intelligent Penetration of UAV Based on Moth Suppression Algorithm},
year={2018},
volume={},
number={},
pages={4044-4049},
abstract={Aiming at the large number of planning constraints faced by UAV's in low-altitude penetration, ambiguity and strong coupling among various factors, an intelligent UAV penetration algorithm based on moth fire suppression optimization algorithm is proposed. MFO algorithm is a novel swarm intelligence optimization algorithm. The main inspiration of this algorithm comes from the flying mode of the moth, which is called lateral positioning in nature. As a new bionic swarm intelligence optimization algorithm, the algorithm analyzes the biological principle of the moth fire suppression optimization algorithm, establishes a mathematical model for the algorithm implementation process, and simulates the algorithm through typical function optimization. The simulation experiment and comparative analysis show that the moth fire suppression optimization algorithm can reduce the overall voyage cost of the UAV's low-altitude penetration path planning, and the calculation speed is faster, besides, the stability and effectiveness can be guaranteed, which could effectively avoid the threat source and perform the low-altitude penetration of UAV.},
keywords={X-ray scattering;UAV;Group intelligent algorithm;Route plan;computer simulation},
doi={10.1109/CAC.2018.8623737},
ISSN={},
month={Nov},}
@INPROCEEDINGS{8107763,
author={Zhang, Jian-Shu and Cao, Jie and Mao, Bo},
booktitle={2017 International Conference on Machine Learning and Cybernetics (ICMLC)}, title={Application of deep learning and unmanned aerial vehicle technology in traffic flow monitoring},
year={2017},
volume={1},
number={},
pages={189-194},
abstract={Intelligent video surveillance technology has been increasingly used in the field of transportation. Real-timely capturing traffic video data through the UAV is a new way to get road condition. In this paper, we set the statistics of road traffic flow as the starting point. After analyzing the characteristics of videos shot by the UAV, we choose to use the deep learning framework based on Faster-RCNN to train a vehicle detection model to detect vehicle targets in videos. The motion track of vehicles in the shooting scene were drawn according to the result of object detection. In the end, analyzing the track and calculating the traffic flow. From the experimental results, it can be seen that deep learning method can achieve a high detection accuracy and based on this, we can calculate the traffic flow well.},
keywords={Machine learning;Target tracking;Object detection;Monitoring;Training;Roads;Traffic flow;UAV;Object detection;Deep learning},
doi={10.1109/ICMLC.2017.8107763},
ISSN={2160-1348},
month={July},}
@INPROCEEDINGS{9314848,
author={LIU, Jianmin and WANG, Qi and HE, Chentao and XU, Yongjun},
booktitle={2020 IEEE 45th Conference on Local Computer Networks (LCN)}, title={ARdeep: Adaptive and Reliable Routing Protocol for Mobile Robotic Networks with Deep Reinforcement Learning},
year={2020},
volume={},
number={},
pages={465-468},
abstract={The mobile robotic network consisting multiple robotic devices such as unmanned aerial vehicles (UAVs) is a high-speed mobile wireless network. Existing mobile ad hoc protocols cannot meet the demands of mobile robotic networks due to intermittently connected links and frequent topology changes. This paper proposes a deep reinforcement learning based adaptive and reliable routing protocol, ARdeep. We formulate routing decisions with a Markov Decision Process model to automatically characterize the network variations. To better infer network environment, the link status is considered when making routing decisions. Simulation results demonstrate that ARdeep outperforms the existing good performing QGeo and conventional GPSR.},
keywords={Routing;Robots;Routing protocols;Network topology;Topology;Reinforcement learning;Markov processes;Adaptive routing;Deep reinforcement learning;Deep Q-Network (DQN);Mobile robotic devices},
doi={10.1109/LCN48667.2020.9314848},
ISSN={0742-1303},
month={Nov},}
@INPROCEEDINGS{9177797,
author={Hernandez-Hernandez, Rolando A. and Martinez-Hernandez, Uriel and Rubio-Solis, Adrian},
booktitle={2020 IEEE International Conference on Fuzzy Systems (FUZZ-IEEE)}, title={Multilayer Fuzzy Extreme Learning Machine Applied to Active classification and Transport of objects using an Unmanned Aerial Vehicle},
year={2020},
volume={},
number={},
pages={1-8},
abstract={Based on hierarchical Multilayer Extreme Learning Machine (ML-ELM) and Fuzzy Logic theory (FL), in this paper a Multilayer Fuzzy Extreme Learning Machine (ML-FELM) has been developed with an application to active classification and transport of objects using an indoors Unmanned Aerial Vehicle (UAV). The learning approach that follows the proposed ML-FELM is a forward two-step hierarchical methodology. First, by stacking a number of Fuzzy Autoencoders (FAEs), input data is projected into a feature representation space. Each FAE is functionally equivalent to a Mamdani Fuzzy Logic System of type-1 (T1 FLS). Finally, in the second stage, features achieved by stacking a number of FAEs are classified by using a Fuzzy ELM (FELM) based on T1 FLS theory and ELM. To evaluate the effectiveness of the proposed ML-FELM, a number of other existing machine learning approaches were employed for the active classification and transport of four different geometrical objects. To further ensure the efficiency of the ML-ELM, a number of popular benchmark data sets for classification problems are also suggested. Based on our experimental results and compared to other deep learning strategies, the ML-FELM not only represents a fast machine learning approach, but also produces a high model accuracy for image classification.},
keywords={Fuzzy logic;Nonhomogeneous media;Unmanned aerial vehicles;Machine learning;Stacking;Neural networks;MIMO communication;Multilayer Learning;Extreme Learning Machine;Fuzzy Logic;Image processing;Neural Networks},
doi={10.1109/FUZZ48607.2020.9177797},
ISSN={1558-4739},
month={July},}
@INPROCEEDINGS{9348105,
author={Lee, Ju-Hyung and Park, Jihong and Bennis, Mehdi and Ko, Young-Chai},
booktitle={GLOBECOM 2020 - 2020 IEEE Global Communications Conference}, title={Integrating LEO Satellite and UAV Relaying via Reinforcement Learning for Non-Terrestrial Networks},
year={2020},
volume={},
number={},
pages={1-6},
abstract={A mega-constellation of low-earth orbit (LEO) satellites has the potential to enable long-range communication with low latency. Integrating this with burgeoning unmanned aerial vehicle (UAV) assisted non-terrestrial networks will be a disruptive solution for beyond 5G systems provisioning large-scale three-dimensional connectivity. In this article, we study the problem of forwarding packets between two faraway ground terminals, through an LEO satellite selected from an orbiting constellation and a mobile high-altitude platform (HAP) such as a fixed-wing UAV. To maximize the end-to-end data rate, the satellite association and HAP location should be optimized, which is challenging due to a huge number of orbiting satellites and the resulting time-varying network topology. We tackle this problem using deep reinforcement learning (DRL) with a novel action dimension reduction technique. Simulation results corroborate that our proposed method achieves up to 5.74x higher average data rate compared to a direct communication baseline without SAT and HAP.},
keywords={Satellites;Network topology;Simulation;Low earth orbit satellites;Reinforcement learning;Unmanned aerial vehicles;Orbits},
doi={10.1109/GLOBECOM42002.2020.9348105},
ISSN={2576-6813},
month={Dec},}
@INPROCEEDINGS{7016203,
author={Bandala, Argel A. and Vicerra, Ryan Rhay P. and Dadios, Elmer P.},
booktitle={2014 International Conference on Humanoid, Nanotechnology, Information Technology, Communication and Control, Environment and Management (HNICEM)}, title={Adaptive aggregation algorithm for target enclosure implemented in quadrotor unmanned aerial vehicle (QUAV) swarm},
year={2014},
volume={},
number={},
pages={1-5},
abstract={This paper presents aggregation behavior algorithm that will be applied for unmanned aerial vehicle quadrotors (QUAV). The most basic behavior for natural swarms is aggregation. Other swarm or social behaviors are derived from the aggregation behavior. Due to the concept of independence, each swarm members are required to collect themselves together to perform a certain task. However the swarm faces different environments thus this behavior is very complex to accomplish. This is the reason why the researchers developed this paper for multi robotic systems. Simulations were done to test the said algorithm and the researchers garnered the accuracy of 90.85%.},
keywords={Robot kinematics;Conferences;Convergence;Accuracy;Nanotechnology;Information technology;Swarm Robotics;Swarm Intelligence;Social Behaviors;Unmanned Aerial Vehicles. (key words)},
doi={10.1109/HNICEM.2014.7016203},
ISSN={},
month={Nov},}
@INPROCEEDINGS{8870103,
author={Minarik, Vaclav and Kratky, Miroslav},
booktitle={2019 International Conference on Military Technologies (ICMT)}, title={Cybernetics Fight against the UAV},
year={2019},
volume={},
number={},
pages={1-4},
abstract={This article deals with the problem of the elimination of Unmanned Aerial Vehicles (UAV) by non-destructive methods, especially in the area of cyberspace. The aim is to introduce certain methods of detection and elimination in complex environment and terrain e.g. in the urban environment, with the possibility of finding the position of the control device and the UAV itself. The neural network, cyber penetration elements and the wireless network scanning program are used to address this problem. The output of the article is the creation of a concept of a comprehensive solution, which can be implemented into a complex system of electronic defence against UAV. Conclusions will be further used for a comprehensive solution of the above issues at the authors' workplace within the framework of the long-term project and the elaboration of the related work of the students of the doctoral study program.},
keywords={Password;Unmanned aerial vehicles;Wireless fidelity;Cybernetics;Biological neural networks;Dictionaries;Unmanned Aerial System –;UAS, Unmanned Aerial Vehicle –;UAV, air defence, electronic warfare, cybernetics, neural network.},
doi={10.1109/MILTECHS.2019.8870103},
ISSN={},
month={May},}
@INPROCEEDINGS{9587687,
author={Prasad, Nelapati Lava and Babu, K Ajay and Ramkumar, Barathram},
booktitle={2021 2nd Global Conference for Advancement in Technology (GCAT)}, title={Automatic Classification of Wireless Fading Channels for UAV with CR Applications},
year={2021},
volume={},
number={},
pages={1-6},
abstract={Unmanned aerial vehicle (UAV) with cognitive radio (CR) technology provides advantages such as coverage area, faster data rate, and improved traffic management. Conventional communication network suffers from ground reflections and to mitigate this, UAVs are used to serve the users. However, the non-line of sight paths in UAV based communication creates problems with channel effects. Hence it is essential to understand the type of fading that occurs in UAV based communication. Generally, the transmitted signal is affected by any one of the fading types such as flat fading, doubly selective fading, and frequency selective fading. In this work, wireless fading channels are classified using deep learning techniques. I and Q values of the modulation schemes are used as features for training and testing the models. Basic convolutional neural network (CNN) model and long short term memory (LSTM) are utilized for the classification and found that LSTM results better accuracy compared to basic CNN model. Computer simulations of proposed classification models are compared with conventional cumulants based classification results.},
keywords={Fading channels;Deep learning;Training;Frequency modulation;Computational modeling;Unmanned aerial vehicles;Reflection;Unmanned aerial vehicle (UAV);cognitive radio (CR);fading;CNN;LSTM},
doi={10.1109/GCAT52182.2021.9587687},
ISSN={},
month={Oct},}
@INPROCEEDINGS{9500582,
author={Feng, Wanmei and Tang, Jie and Zhao, Nan and Zhang, Xiuyin and Wang, Xianbin and Wong, Kai-Kit},
booktitle={ICC 2021 - IEEE International Conference on Communications}, title={A Deep Learning-Based Approach to Resource Allocation in UAV-aided Wireless Powered MEC Networks},
year={2021},
volume={},
number={},
pages={1-6},
abstract={Beamforming and non-orthogonal multiple access (NOMA) are two key techniques for achieving spectral efficient communication in the fifth generation and beyond wireless networks. In this paper, we jointly apply a hybrid beamforming and NOMA techniques to an unmanned aerial vehicle (UAV)-carried wireless-powered mobile edge computing (MEC) system, within which the UAV is mounted with a wireless power charger and the MEC platform delivers energy and computing services to Internet of Things (IoT) devices. We aim to maximize the sum computation rate at all IoT devices whilst satisfying the constraint of energy harvesting and coverage. The considered optimization problem is non-convex involving joint optimization of the UAV’s 3D placement and hybrid beamforming matrices as well as computation resource allocation in partial offloading pattern, and thus is quite difficult to tackle directly. By applying the polyhedral annexation method and the deep deterministic policy gradient (DDPG) algorithm, we propose an effective algorithm to derive the closed-form solution for the optimal 3D deployment of the UAV, and find the solution for the hybrid beamformer. A resource allocation algorithm for partial offloading pattern is thereby proposed. Simulation results demonstrate that our designed algorithm yields a significant computation performance enhancement as compared to the benchmark schemes.},
keywords={Performance evaluation;NOMA;Three-dimensional displays;Array signal processing;Wireless networks;Benchmark testing;Unmanned aerial vehicles;Hybrid beamforming;mobile edge computing;non-orthogonal multiple access;unmanned aerial vehicle},
doi={10.1109/ICC42927.2021.9500582},
ISSN={1938-1883},
month={June},}
@INPROCEEDINGS{8956271,
author={Karra, Despoina and Goudos, Sotirios K. and Tsoulos, George V. and Athanasiadou, Georgia},
booktitle={2019 Panhellenic Conference on Electronics Telecommunications (PACET)}, title={Prediction of Received Signal Power in Mobile Communications Using Different Machine Learning Algorithms:A Comparative Study},
year={2019},
volume={},
number={},
pages={1-4},
abstract={In this paper, we apply and compare various machine learning techniques to predict the received signal strength (RSS) in cellular communications. We generate the training set using experimental measurements from an unmanned aerial vehicle (UAV). We make a prediction model for the RSS using five base learners. We create a new ensemble method that averages the results from these five base learners. The proposed model outperforms all the original base learners. The obtained numerical results are compared with the original data from the test dataset using representative performance indicators and exhibit good precision.},
keywords={cellular communications;UAV;machine learning;ensemble learning;voting regressor},
doi={10.1109/PACET48583.2019.8956271},
ISSN={},
month={Nov},}
@ARTICLE{9039589,
author={Brik, Bouziane and Ksentini, Adlen and Bouaziz, Maha},
journal={IEEE Access}, title={Federated Learning for UAVs-Enabled Wireless Networks: Use Cases, Challenges, and Open Problems},
year={2020},
volume={8},
number={},
pages={53841-53849},
abstract={The use of Unmanned Aerial Vehicles (UAVs) for wireless networks is rapidly growing as key enablers of new applications, including: surveillance and monitoring, military, delivery of medical supplies, telecommunications, etc. In particular, due to their unique proprieties such as flexibility, mobility, and adaptive altitude, UAVs can act as mobile base stations to improve capacity, coverage, and energy efficiency of wireless networks. On the other hand, UAVs can operate as mobile terminals to enable many applications such as item delivery and real-time video streaming. In such context, data-driven Deep Learning-assisted (DL) approaches are gaining a growing interest to not only exploit the huge amount of generated data, but also to optimize the network operations, and hence ensure the QoS requirements of these emerging wireless networks. However, UAVs are resource-constrained devices especially in terms of computing and power resources, and traditional DL-assisted schemes are cloud-centric, which require UAVs' data to be sent and stored in a centralized server. This represents a critical issue since it generates a huge network communication overhead to send raw data towards the centralized entity, and hence may lead to network bandwidth and energy inefficiency of UAV devices. In addition, the transferred data may contain personnel data such as UAVs' localization and identity, which can directly affect UAVs' privacy concerns. As a solution, Federated Deep Learning (FDL), or distributed DL, was introduced, where the basic idea is to keep raw data where it is generated, while sending only users' local trained DL models to the centralized entity for aggregation. Due to its privacy-preserving and low communication overhead and latency, FDL is much more adequate for many UAVs-enabled wireless applications. In this work, we provide a general introduction of FDL application for UAV-enabled wireless networks. We first introduce the FDL concept and its fundamentals. Then, we highlight the possible applications of FDL in UAVs-enabled wireless networks by addressing the suitability and how to use FDL to deal with target challenges. Finally, we discuss about key technical challenges, open issues, and future research directions on FDL-based approaches in such context.},
keywords={Wireless networks;Data models;Deep learning;Servers;Solid modeling;Wireless sensor networks;Deep learning;federated deep learning;UAVs-based wireless networks;wireless communications},
doi={10.1109/ACCESS.2020.2981430},
ISSN={2169-3536},
month={},}
@INPROCEEDINGS{7958795,
author={Tang, Tianyu and Deng, Zhipeng and Zhou, Shilin and Lei, Lin and Zou, Huanxin},
booktitle={2017 International Workshop on Remote Sensing with Intelligent Processing (RSIP)}, title={Fast vehicle detection in UAV images},
year={2017},
volume={},
number={},
pages={1-5},
abstract={Fast and accurate vehicle detection in unmanned aerial vehicle (UAV) images remains a challenge, due to its very high spatial resolution and very few annotations. Although numerous vehicle detection methods exist, most of them cannot achieve real-time detection for different scenes. Recently, deep learning algorithms has achieved fantastic detection performance in computer vision, especially regression based convolutional neural networks YOLOv2. It's good both at accuracy and speed, outperforming other state-of-the-art detection methods. This paper for the first time aims to investigate the use of YOLOv2 for vehicle detection in UAV images, as well as to explore the new method for data annotation. Our method starts with image annotation and data augmentation. CSK tracking method is used to help annotate vehicles in images captured from simple scenes. Subsequently, a regression based single convolutional neural network YOLOv2 is used to detect vehicles in UAV images. To evaluate our method, UAV video images were taken over several urban areas, and experiments were conducted on this dataset and Stanford Drone dataset. The experimental results have proven that our data preparation strategy is useful, and YOLOv2 is effective for real-time vehicle detection of UAV video images.},
keywords={Training;Unmanned aerial vehicles;Vehicle detection;Remote sensing;Neural networks;Automobiles;Geoscience;CNN;UAV;vehicle detection;CSK;YOLOv2},
doi={10.1109/RSIP.2017.7958795},
ISSN={},
month={May},}
@INPROCEEDINGS{5873344,
author={Lei, Gang and Dong, Min-zhou and Xu, Tao and Wang, Liang},
booktitle={2011 3rd International Workshop on Intelligent Systems and Applications}, title={Multi-Agent Path Planning for Unmanned Aerial Vehicle Based on Threats Analysis},
year={2011},
volume={},
number={},
pages={1-4},
abstract={This paper focuses on the flight path planning process with multi-agent for Unmanned Aerial Vehicle (UAV) based on threats analysis and path length constraint. Path planner agent searches the path with global view considering path length constraint and information collector agent deals with path planning in the zone of threats. Scoring function is presented based on analysis the threats' attributes. We consider the path planning process as the multi-agent cooperation in a dynamic and non-stationarity environment. In order to perfectly adapt agents to environment changing, we restructure the traditional Q-value learning algorithm into a dynamic reinforcement learning algorithm by introducing current beliefs and recency based exploration bonus. The simulation results show that the proposed method converges rapidly and can be used in flight path planning.},
keywords={Path planning;Learning;Heuristic algorithms;Planning;Simulation;Unmanned aerial vehicles;Learning systems},
doi={10.1109/ISA.2011.5873344},
ISSN={},
month={May},}
@INPROCEEDINGS{9473768,
author={Cicek, Cihan Tugrul},
booktitle={2021 IEEE International Conference on Communications Workshops (ICC Workshops)}, title={A Reinforcement Learning Algorithm for Data Collection in UAV-aided IoT Networks with Uncertain Time Windows},
year={2021},
volume={},
number={},
pages={1-6},
abstract={Unmanned aerial vehicles (UAVs) have been considered as an efficient solution to collect data from ground sensor nodes in Internet-of-Things (IoT) networks due to their several advantages such as flexibility, quick deployment and maneuverability. Studies on this subject have been mainly focused on problems where limited UAV battery is introduced as a tight constraint that shortens the mission time in the models, which significantly undervalues the UAV potential. Moreover, the sensors in the network are typically assumed to have deterministic working times during which the data is uploaded. In this study, we revisit the UAV trajectory planning problem with a different approach and revise the battery constraint by allowing UAVs to swap their batteries at fixed stations and continue their data collection task, hence, the planning horizon can be extended. In particular, we develop a discrete time Markov process (DTMP) in which the UAV trajectory and battery swapping times are jointly determined to minimize the total data loss in the network, where the sensors have uncertain time windows for uploading. Due to the so-called curse-of-dimensionality, we propose a reinforcement learning (RL) algorithm in which the UAV is trained as an agent to explore the network. The computational study shows that our proposed algorithm outperforms two benchmark approaches and achieves significant reduction in data loss.},
keywords={Trajectory planning;Conferences;Heuristic algorithms;Reinforcement learning;Data collection;Benchmark testing;Unmanned aerial vehicles;UAV;internet-of-things;reinforcement learning;battery swapping;time windows;uncertainty},
doi={10.1109/ICCWorkshops50388.2021.9473768},
ISSN={2694-2941},
month={June},}
@ARTICLE{9411725,
author={Zhang, Liang and Celik, Abdulkadir and Dang, Shuping and Shihada, Basem},
journal={IEEE Transactions on Mobile Computing}, title={Energy-Efficient Trajectory Optimization for UAV-Assisted IoT Networks},
year={2021},
volume={},
number={},
pages={1-1},
abstract={In this paper, we propose and study an energy-efficient trajectory optimization scheme for unmanned aerial vehicle (UAV) assisted Internet of Things (IoT) networks. In such networks, a single UAV is powered by both solar energy and charging stations (CSs), resulting in sustainable communication services, while avoiding energy outage. In particular, we optimize the trajectory design of UAV by jointly considering the average data rate, the total energy consumption, and the fairness of coverage for the IoT terminals. A dynamic spatial-temporal configuration scheme is operated for terminals working in the discontinuous reception (DRX) mode. The module-free, action-confined on-policy and off-policy reinforcement learning approaches are proposed and jointly applied to solve the formulated optimization problem in this paper. We evaluate the effectiveness of the proposed strategy by comparing it with other dynamic benchmark algorithms. The extensive simulation results provided in this paper reveal that the proposed scheme outperforms the benchmarks in terms of data transmission, energy efficiency and adaptivity of avoiding battery depletion. By deploying the proposed trajectory scheme, the UAV is able to adapt itself according to the temporal and dynamic conditions of communication networks.},
keywords={Unmanned aerial vehicles;Cascading style sheets;Batteries;Optimization;Data communication;Trajectory optimization;Quality of service;Unmanned aerial vehicle (UAV);Internet of Things (IoT);energy harvesting;reinforcement learning (RL);trajectory optimization},
doi={10.1109/TMC.2021.3075083},
ISSN={1558-0660},
month={},}
@INPROCEEDINGS{9323322,
author={Zheng, Lijuan and Ai, Ping and Wu, Yu},
booktitle={IGARSS 2020 - 2020 IEEE International Geoscience and Remote Sensing Symposium}, title={Building Recognition of UAV Remote Sensing Images by Deep Learning},
year={2020},
volume={},
number={},
pages={1185-1188},
abstract={The automatic detection and identification of buildings has always been a hotspot research in the field of remote sensing image processing. In recent years, unmanned aerial vehicles (UAV) have developed rapidly and provided high-resolution remote sensing images to detect and identify surface targets. At the same time, the deep learning method has achieved great success in the fields of speech recognition, image recognition, information retrieval, etc., becoming an effective tool for classification and recognition. This paper presents the method of building recognition by deep learning for UAV remote sensing. The Faster RCNN model is applied to identify the UAV remote sensing images, the experiments show that the recognition accuracy is 93.2% for this dataset with an average processing time of 74ms on the image recognition. The results suggest the effectiveness and efficiency of the building recognition applications of UAV remote sensing images by deep learning network.},
keywords={Buildings;Remote sensing;Feature extraction;Image recognition;Deep learning;Training;Computational modeling;deep learning;UAV remote sensing images;building recognition},
doi={10.1109/IGARSS39084.2020.9323322},
ISSN={2153-7003},
month={Sep.},}
@ARTICLE{9530723,
author={Tian, Jiwei and Wang, Buhong and Guo, Rongxiao and Wang, Zhen and Cao, Kunrui and Wang, Xiaodong},
journal={IEEE Internet of Things Journal}, title={Adversarial Attacks and Defenses for Deep Learning-based Unmanned Aerial Vehicles},
year={2021},
volume={},
number={},
pages={1-1},
abstract={The introduction of deep learning technology can improve the performance of cyber-physical systems (CPSs) in many ways. However, this also brings new security issues. To tackle these challenges, this paper explores the vulnerabilities of deep learning-based unmanned aerial vehicles (UAVs), which are typical CPSs. Although many research works have been reported previously on adversarial attacks of deep learning models, only few of them are concerned about safety-critical CPSs, especially regression models in such systems. In this paper, we analyze the problem of adversarial attacks against deep learning-based UAVs and propose two adversarial attack methods against regression models in UAVs. Experiments demonstrate that the proposed non-targeted and targeted attack methods both can craft imperceptible adversarial images and pose a considerable threat to the navigation and control of UAVs. To address this problem, adversarial training and defensive distillation methods are further investigated and evaluated, increasing the robustness of deep learning models in UAVs. To our knowledge, this is the first study on adversarial attacks and defenses against deep learning-based UAVs, which calls for more attention to the security and safety of such safety-critical applications.},
keywords={Navigation;Internet of Things;Training;Cameras;Security;Deep learning;Task analysis;Adversarial example;adversarial training;defensive distillation;deep learning;unmanned aerial vehicle.},
doi={10.1109/JIOT.2021.3111024},
ISSN={2327-4662},
month={},}
@INPROCEEDINGS{8711867,
author={Zahid, Komal and Nafees, Ushna and Parveen, Shazia and Afzal, Uzma},
booktitle={2019 International Conference on Engineering and Emerging Technologies (ICEET)}, title={Using Neural Network to Predict Unmanned Aerial Vehicle Strikes in Pakistan},
year={2019},
volume={},
number={},
pages={1-6},
abstract={Unmanned Aerial Vehicles (UAVs) are pilotless aircrafts which were originally introduced for military purposes. They play a significant role in US war-on-terrorism. Since 2004, US has attacked many targets in Pakistan using UAVs. Pakistan condemns these attacks and denies the allegation of their hidden approval. In this context, we propose a neural network based model to minimize the adverse effects of these illegal attacks by predicting their frequency along with the number of militant killed, civilian causalities and number of injuries. The predictive model is trained using Pakistan UAV strikes data and results show that the proposed model predicts these variables with good accuracy and small RMSE (Root Mean Square Error).},
keywords={Biological neural networks;Artificial neural networks;Neurons;Training;Predictive models;Injuries;Unmanned Aerial Vehicle;Drone;Neural Network;Forecasting;TensorFlow},
doi={10.1109/CEET1.2019.8711867},
ISSN={2409-2983},
month={Feb},}
@INPROCEEDINGS{9145249,
author={Tong, Peng and Liu, Juan and Wang, Xijun and Bai, Bo and Dai, Huaiyu},
booktitle={2020 IEEE International Conference on Communications Workshops (ICC Workshops)}, title={Deep Reinforcement Learning for Efficient Data Collection in UAV-Aided Internet of Things},
year={2020},
volume={},
number={},
pages={1-6},
abstract={In the Internet of Things (IoTs), unmanned aerial vehicle (UAV) has been considered as an efficient solution to collect information from ground sensor nodes (SNs) due to its controllable mobility and high maneuverability. In this paper, we study a UAV-aided efficient data collection problem for IoTs, where SNs sample information with fixed or random rates and cache the sampled update packets under a sample-and-replace policy. An energy-constrained UAV is deployed to collect data from each SN when it flies over this SN. The UAV's flight trajectory is optimized to minimize the SNs' average age-ofinformation (AoI) while preserving their packet drop rate as low as possible. Toward this end, we model the UAV-aided data collection problem as a finite-horizon Markov decision process (MDP) with finite state and action spaces. Then, we develop a deep reinforcement learning algorithm to find an asymptotically optimal policy. Simulation results demonstrate that the proposed learning algorithm can significantly reduce the AoI and packet drop rate, compared to the baseline greedy algorithms.},
keywords={Trajectory;Data collection;Unmanned aerial vehicles;Energy consumption;Internet of Things;Machine learning;Wireless sensor networks},
doi={10.1109/ICCWorkshops49005.2020.9145249},
ISSN={2474-9133},
month={June},}
@ARTICLE{9058679,
author={Wu, Fanyi and Zhang, Hongliang and Wu, Jianjun and Song, Lingyang},
journal={IEEE Transactions on Communications}, title={Cellular UAV-to-Device Communications: Trajectory Design and Mode Selection by Multi-Agent Deep Reinforcement Learning},
year={2020},
volume={68},
number={7},
pages={4175-4189},
abstract={In the current unmanned aircraft systems (UASs) for sensing services, unmanned aerial vehicles (UAVs) transmit their sensory data to terrestrial mobile devices over the unlicensed spectrum. However, the interference from surrounding terminals is uncontrollable due to the opportunistic channel access. In this paper, we consider a cellular Internet of UAVs to guarantee the Quality-of-Service (QoS), where the sensory data can be transmitted to the mobile devices either by UAV-to-Device (U2D) communications over cellular networks, or directly through the base station (BS). Since UAVs' sensing and transmission may influence their trajectories, we study the trajectory design problem for UAVs in consideration of their sensing and transmission. This is a Markov decision problem (MDP) with a large state-action space, and thus, we utilize multi-agent deep reinforcement learning (DRL) to approximate the state-action space, and then propose a multi-UAV trajectory design algorithm to solve this problem. Simulation results show that our proposed algorithm can achieve a higher total utility than policy gradient algorithm and single-agent algorithm.},
keywords={Sensors;Mobile handsets;Trajectory;Internet;Quality of service;Cellular networks;Machine learning;UAV-to-Device communications;cellular Internet of UAVs;trajectory design;deep reinforcement learning},
doi={10.1109/TCOMM.2020.2986289},
ISSN={1558-0857},
month={July},}
@ARTICLE{9319135,
author={Nguyen, Minh-Hien T. and Garcia-Palacios, Emiliano and Do-Duy, Tan and Nguyen, Long D. and Mai, Son T. and Duong, Trung Q.},
journal={IEEE Access}, title={Spectrum-Sharing UAV-Assisted Mission-Critical Communication: Learning-Aided Real-Time Optimisation},
year={2021},
volume={9},
number={},
pages={11622-11632},
abstract={We propose an unmanned aerial vehicle (UAV) communications scheme with spectrum-sharing mechanism to provide mission-critical services such as disaster recovery and public safety. Specifically, the UAVs can serve as flying base stations to provide extended network coverage for the affected area under spectrum-sharing cognitive radio networks (CRNs). To cope with the effects of network destruction in a disaster, we propose a real-time optimisation framework for resource allocation (e.g., power and number of UAVs) for CRNs assisted by UAV relays. The proposed optimisation scheme aims at optimising the network throughput of primary and secondary networks under the stringent constraint of maximum tolerable interference impinged on the primary users. We also propose a deep neural network (DNN) model to significantly reduce the execution time under real-time solution of mixed-integer UAV deployment problems. For both primary and secondary networks, our real-time optimisation algorithms impose low computational complexity, hence, have a low execution time in solving throughput optimisation problems, which demonstrates the benefit of our approached proposed for spectrum-sharing UAV-assisted mission-critical services.},
keywords={Optimization;Throughput;Real-time systems;Resource management;Unmanned aerial vehicles;Mission critical systems;Interference;Real-time optimisation;unmanned aerial vehicle (UAV);spectrum sharing;machine learning;mission-critical communications},
doi={10.1109/ACCESS.2021.3050522},
ISSN={2169-3536},
month={},}
@INPROCEEDINGS{9301968,
author={Yang, Runfeng and Wang, Xi},
booktitle={2020 IEEE Eurasia Conference on IOT, Communication and Engineering (ECICE)}, title={UAV Landmark Detection Based on Convolutional Neural Network},
year={2020},
volume={},
number={},
pages={5-8},
abstract={The extensive use application of visual perception technology in Unmanned Aerial Vehicle (UAV) has brought great changes to the application of UAV in various fields. It is challenge to detect in landmark images for UAV. During UAV flight in different environments, the performance of landmark detection to deteriorate seriously have been caused by the uncertainty of landmark orientation, the diversity of landmark types and the similarities. This paper presents landmark detection of UAV based on Convolutional Neural Network (CNN). Theoretical analysis and experimental results demonstrate landmark recognition with an accuracy of at least 96% to match deployed in UAV, and the proposed CNN can make a correct classification.},
keywords={Unmanned aerial vehicles;Three-dimensional displays;Training;Kernel;Animation;Real-time systems;Convolutional neural networks;UAV;convolutional neural network;recognition},
doi={10.1109/ECICE50847.2020.9301968},
ISSN={},
month={Oct},}
@ARTICLE{8982070,
author={Abeywickrama, Hasini Viranga and He, Ying and Dutkiewicz, Eryk and Jayawickrama, Beeshanga Abewardana and Mueck, Markus},
journal={IEEE Open Journal of Vehicular Technology}, title={A Reinforcement Learning Approach for Fair User Coverage Using UAV Mounted Base Stations Under Energy Constraints},
year={2020},
volume={1},
number={},
pages={67-81},
abstract={Unmanned Aerial Vehicles (UAVs) are gaining popularity in many aspects of wireless communication systems. UAV-mounted mobile base stations (UAV-BSs) are an effective and cost-efficient solution for providing wireless connectivity where fixed infrastructure is not available or destroyed. However, UAV-BSs have their limitations and complications, for instance, limited available energy. In addition, when several UAV-BSs are deployed to provide coverage to a specific area, the possibility of inter-UAV collisions and the interference to ground users increase. We propose Reinforcement Learning (RL) and Deep Reinforcement Learning (DRL) based methods to deploy UAV-BSs under energy constraints to provide efficient and fair coverage to the ground users, while minimising inter-UAV collisions and interference to ground users. The proposed methods outperform the baseline methods by an average increase of 38.94% in system fairness, 42.54% in individual user coverage, and 15.04% in total system coverage, in comparison with the baseline methods.},
keywords={Wireless communication;Interference;Reinforcement learning;Unmanned aerial vehicles;Base stations;Three-dimensional displays;Clustering algorithms;Unmanned aerial vehicles (UAVs);wireless coverage;reinforcement learning},
doi={10.1109/OJVT.2020.2971594},
ISSN={2644-1330},
month={},}
@ARTICLE{9314108,
author={Zhu, Shichao and Gui, Lin and Zhao, Dongmei and Cheng, Nan and Zhang, Qi and Lang, Xiupu},
journal={IEEE Transactions on Vehicular Technology}, title={Learning-Based Computation Offloading Approaches in UAVs-Assisted Edge Computing},
year={2021},
volume={70},
number={1},
pages={928-944},
abstract={Technological evolutions in unmanned aerial vehicle (UAV) industry have granted UAVs more computing and storage resources, leading to the vision of UAVs-assisted edge computing, in which the computing missions can be offloaded from a cellular network to a UAV cloudlet. In this paper, we propose a UAVs-assisted computation offloading paradigm, where a group of UAVs fly around, while providing value-added edge computing services. The complex computing missions are decomposed as some typical task-flows with inter-dependencies. By taking into consideration the inter-dependencies of the tasks, dynamic network states, and energy constraints of the UAVs, we formulate the average mission response time minimization problem and then model it as a Markov decision process. Specifically, each time a mission arrives or a task execution finishes, we should decide the target helper for the next task execution and the fraction of the bandwidth allocated to the communication. To separate the evaluation of the integrated decision, we propose multi-agent reinforcement learning (MARL) algorithms, where the target helper and the bandwidth allocation are determined by two agents. We design respective advantage evaluation functions for the agents to solve the multi-agent credit assignment challenge, and further extend the on-policy algorithm to off-policy. Simulation results show that the proposed MARL-based approaches have desirable convergence property, and can adapt to the dynamic environment. The proposed approaches can significantly reduce the average mission response time compared with other benchmark approaches.},
keywords={Task analysis;Resource management;Edge computing;Reinforcement learning;Heuristic algorithms;Vehicle dynamics;Time factors;Bandwidth allocation;computation offloading;inter-dependencies;multi-agent reinforcement learning;UAV},
doi={10.1109/TVT.2020.3048938},
ISSN={1939-9359},
month={Jan},}
@ARTICLE{9622267,
author={Hong, Zhonghua and Yang, Fan and Pan, Haiyan and Zhou, Ruyan and Zhang, Yun and Han, Yanling and Wang, Jing and Yang, Shuhu and Chen, Peng and Tong, Xiaohua and Liu, Jun},
journal={IEEE Geoscience and Remote Sensing Letters}, title={Highway Crack Segmentation From Unmanned Aerial Vehicle Images Using Deep Learning},
year={2022},
volume={19},
number={},
pages={1-5},
abstract={Highway crack segmentation is a critical task for highway infrastructure monitoring and maintenance. While imagery from unmanned aerial vehicles (UAVs) is applied to the task of highway crack segmentation, it has great prospects in terms of speed and range. However, it is difficult to accurately identify road cracks from UAV remote sensing images, because the cracks are very narrow and small, often containing only a few pixels. To improve the segmentation of road cracks in UAV images, this study proposed an improved identification technique based on the U-Net architecture enhanced with a convolutional block attention module, an improved encoder, and the strategy of fusing long and short skip connections. A public road crack dataset was relabelled for network training and a UAV remote sensing road crack dataset containing 1157 images was used to verify the generalization ability of the enhanced network model. Results showed that the proposed method could effectively predict highway cracks in UAV images, with mean intersection over union (mIoU) of 77.47% and crack accuracy of 68.38%, which was better than the traditional U-Net model and some traditional semantic segmentation models. The proposed network is trained quickly by public dataset and can predict the road cracks on the new UAV images with high crack accuracy. This study provides an effective solution for the need to quickly grasp the damage status of roads over a wide area in the case of earthquake and other natural disasters. The highway crack segmentation benchmark dataset has been open sourced at: https://github.com/zhhongsh/UAV-Benchmark-Dataset-for-Highway-Crack-Segmentation.},
keywords={Image segmentation;Unmanned aerial vehicles;Roads;Object segmentation;Training;Task analysis;Image edge detection;Deep learning;highway crack;semantic segmentation;U-Net;unmanned aerial vehicle (UAV)},
doi={10.1109/LGRS.2021.3129607},
ISSN={1558-0571},
month={},}
@INPROCEEDINGS{9340934,
author={Theile, Mirco and Bayerlein, Harald and Nai, Richard and Gesbert, David and Caccamo, Marco},
booktitle={2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)}, title={UAV Coverage Path Planning under Varying Power Constraints using Deep Reinforcement Learning},
year={2020},
volume={},
number={},
pages={1444-1449},
abstract={Coverage path planning (CPP) is the task of designing a trajectory that enables a mobile agent to travel over every point of an area of interest. We propose a new method to control an unmanned aerial vehicle (UAV) carrying a camera on a CPP mission with random start positions and multiple options for landing positions in an environment containing no-fly zones. While numerous approaches have been proposed to solve similar CPP problems, we leverage end-to-end reinforcement learning (RL) to learn a control policy that generalizes over varying power constraints for the UAV. Despite recent improvements in battery technology, the maximum flying range of small UAVs is still a severe constraint, which is exacerbated by variations in the UAV's power consumption that are hard to predict. By using map-like input channels to feed spatial information through convolutional network layers to the agent, we are able to train a double deep Q-network (DDQN) to make control decisions for the UAV, balancing limited power budget and coverage goal. The proposed method can be applied to a wide variety of environments and harmonizes complex goal structures with system constraints.},
keywords={Training;Power demand;Transfer learning;Reinforcement learning;Unmanned aerial vehicles;Trajectory;Task analysis},
doi={10.1109/IROS45743.2020.9340934},
ISSN={2153-0866},
month={Oct},}
@ARTICLE{9465215,
author={Cheng, Hai and Bertizzolo, Lorenzo and D’oro, Salvatore and Buczek, John and Melodia, Tommaso and Bentley, Elizabeth Serena},
journal={IEEE Open Journal of the Communications Society}, title={Learning to Fly: A Distributed Deep Reinforcement Learning Framework for Software-Defined UAV Network Control},
year={2021},
volume={2},
number={},
pages={1486-1504},
abstract={Control and performance optimization of wireless networks of Unmanned Aerial Vehicles (UAVs) require scalable approaches that go beyond architectures based on centralized network controllers. At the same time, the performance of model-based optimization approaches is often limited by the accuracy of the approximations and relaxations necessary to solve the UAV network control problem through convex optimization or similar techniques, and by the accuracy of the channel network models used. To address these challenges, this article introduces a new architectural framework to control and optimize UAV networks based on Deep Reinforcement Learning (DRL). Furthermore, it proposes a virtualized, `ready-to-fly' emulation environment to generate the extensive wireless data traces necessary to train DRL algorithms, which are notoriously hard to generate and collect on battery-powered UAV networks. The training environment integrates previously developed wireless protocol stacks for UAVs into the CORE/EMANE emulation tool. Our `ready-to-fly' virtual environment guarantees scalable collection of high-fidelity wireless traces that can be used to train DRL agents. The proposed DRL architecture enables distributed data-driven optimization (with up to 3.7 × throughput improvement and 0.2 × latency reduction in reported experiments), facilitates network reconfiguration, and provides a scalable solution for large UAV networks.},
keywords={Optimization;Ad hoc networks;Protocols;Drones;Emulation;Wireless sensor networks;Virtual environments;UAV networks;non-terrestrial netoworks;deep reinforcement learning;AI for wireless networks;6G},
doi={10.1109/OJCOMS.2021.3092690},
ISSN={2644-125X},
month={},}
@ARTICLE{9497328,
author={Zhang, Meng and Fu, Shu and Fan, Qilin},
journal={IEEE Wireless Communications Letters}, title={Joint 3D Deployment and Power Allocation for UAV-BS: A Deep Reinforcement Learning Approach},
year={2021},
volume={10},
number={10},
pages={2309-2312},
abstract={Due to its high mobility and low cost, unmanned aerial vehicle mounted base station (UAV-BS) can be deployed in a fast and cost-efficient manner for providing wireless services in areas where traditional terrestrial infrastructures cannot be laid for technical and economic reasons. In this letter, we investigate the problem of joint three-dimensional (3D) deployment and power allocation for maximizing the system throughput in a UAV-BS system. To solve this non-convex problem, we propose a deep deterministic policy gradient (DDPG) based algorithm. The proposed algorithm allows the UAV-BS to explore in continuous state and action spaces to learn the optimal 3D hovering location and power allocation. Simulation results show that the proposed algorithm outperforms the traditional deep Q-learning-based method and genetic algorithm.},
keywords={Resource management;Three-dimensional displays;Throughput;Wireless communication;Unmanned aerial vehicles;Optimization;Simulation;Unmanned aerial vehicle;3D deployment;power allocation;deep reinforcement learning},
doi={10.1109/LWC.2021.3100388},
ISSN={2162-2345},
month={Oct},}
@INPROCEEDINGS{9498845,
author={Yang, Yuzhou and Jing, Xiaojun and Mu, Junsheng and Gao, Haitao},
booktitle={2021 International Wireless Communications and Mobile Computing (IWCMC)}, title={SNR Estimation of UAV Control Signal Based on Convolutional Neural Network},
year={2021},
volume={},
number={},
pages={780-784},
abstract={The signal-to-noise ratio (SNR) is an effective evaluation index for channel status and communication quality, and plays an important role in signal analysis. Under the gradual complexity of the unmanned aerial vehicle (UAV) remote control signal environment and the rapid development of neural network models in deep learning, this paper proposes a convolutional neural network (CNN) model-based SNR estimation method of UAV remote control signal environment. We construct a simulation dataset of UAV remote control signal with different SNRs, then train the model and its parameters, save the model with better performance and use the test set to verify the performance of the algorithm finally. The experimental result shows that the performance of the algorithm is improved compared to the two known algorithm.},
keywords={Deep learning;Wireless communication;Neural networks;Estimation;Unmanned aerial vehicles;Classification algorithms;Convolutional neural networks;UAV;Deep learning;SNR estimation},
doi={10.1109/IWCMC51323.2021.9498845},
ISSN={2376-6506},
month={June},}
@INPROCEEDINGS{9482383,
author={Luo, Kai and Luo, Rongjian and Zhou, Youwei},
booktitle={2021 IEEE 4th Advanced Information Management, Communicates, Electronic and Automation Control Conference (IMCEC)}, title={UAV detection based on rainy environment},
year={2021},
volume={4},
number={},
pages={1207-1210},
abstract={Based on the UAV detection is under the rainy day will remove the rain to UAV for the front-end process highlighted in depth study methods. Target detection technology has made great progress in recent years. But when it comes to low-flying drones, especially in the case of environmental impacts such as rain and fog. the accuracy and robustness can not meet the real-time requirement. Based on the existing results, this paper uses deep convolutional neural network to detect UAV. First,. introduce the current image fog removal, rain removal related algorithms, using the basic DID-MDN algorithm to achieve rain removal. Second, introduce the algorithm of target detection, and YOLOv5 based on deep learning is used for target detection.},
keywords={Deep learning;Rain;Object detection;Unmanned aerial vehicles;Real-time systems;Robustness;Information management;Rain streak removal;UAV detection;Neiwork contrast;Network cascade},
doi={10.1109/IMCEC51613.2021.9482383},
ISSN={2693-2776},
month={June},}
@INPROCEEDINGS{9553232,
author={Marques, Ademir and Racolte, Graciela and de Souza, Eniuce Menezes and Domingos, Hiduino Venâncio and Horota, Rafael Kenji and Motta, João Gabriel and Zanotta, Daniel Capella and Cazarin, Caroline Lessio and Gonzaga, Luiz and Veronez, Maurício Roberto},
booktitle={2021 IEEE International Geoscience and Remote Sensing Symposium IGARSS}, title={Deep Learning Application for Fracture Segmentation Over Outcrop Images from UAV-Based Digital Photogrammetry},
year={2021},
volume={},
number={},
pages={4692-4695},
abstract={Fractures affect the intrinsic properties of permeability and porosity of reservoir geobodies, making its network characterization an important task for fluid flow modeling. Direct acquisition of data on reservoirs is labor-intensive and generally produces sparse information. Thus, the study of analogue outcrops with similar characteristics is often carried out by using unmanned aerial vehicle image acquisition and digital photogrammetry. However, the accurate automatic recognition of the fractures network over the outcrop images remains a challenge. Image segmentation methods based on convolution neural networks (CNNs) were successfully applied in medicine, biology, and other areas, however, not yet in geological fracture detection. This work proposes the validation of two popular CNNs - Segnet and Unet - for pixel-to-pixel segmentation targeting fracture detection. Initial results showed acceptable scores of the metrics mean intersection over union (mIoU) and dice intersection (F1) in both CNNs.},
keywords={Measurement;Image segmentation;Image recognition;Geology;Neural networks;Geoscience and remote sensing;Reservoirs;Fracture detection;CNN;Unet;Segnet;UAV;Photogrammetry;Segmentation},
doi={10.1109/IGARSS47720.2021.9553232},
ISSN={2153-7003},
month={July},}
@ARTICLE{8522052,
author={Song, Yongduan and He, Liu and Zhang, Dong and Qian, Jiye and Fu, Jin},
journal={IEEE Transactions on Neural Networks and Learning Systems}, title={Neuroadaptive Fault-Tolerant Control of Quadrotor UAVs: A More Affordable Solution},
year={2019},
volume={30},
number={7},
pages={1975-1983},
abstract={This paper investigates the position and attitude tracking control problem of a quadrotor unmanned aerial vehicle subject to modeling uncertainties and actuator failures. A comprehensive mathematical model reflecting the nonlinearity and state-space coupling of the dynamics as well as actuation faults and external disturbances is derived. By combining the radial basis function neural networks (NNs) with virtual parameter estimating algorithms, an indirect NN-based adaptive fault-tolerant control scheme is developed, which exhibits several attractive features as compared with most existing methods: 1) it is not only robust and adaptive to nonparametric uncertainties but also tolerant to unexpected actuation faults; 2) it ensures stable tracking without the need for precise information on system model; and 3) it only involves one lumped parameter adaptation, thus is structurally simpler and computationally less expensive, rendering the resultant scheme less demanding in programming and more affordable for onboard implementation. The effectiveness and benefits of the proposed method are confirmed via computer simulation.},
keywords={Aerodynamics;Vehicle dynamics;Rotors;Heuristic algorithms;Artificial neural networks;Uncertainty;Fault tolerance;Actuation faults;fault-tolerant control (FTC);indirect neuroadaptive;unmanned aerial vehicle (UAV)},
doi={10.1109/TNNLS.2018.2876130},
ISSN={2162-2388},
month={July},}
@ARTICLE{7061535,
author={Lai, Guanyu and Liu, Zhi and Zhang, Yun and Chen, C. L. Philip},
journal={IEEE Transactions on Neural Networks and Learning Systems}, title={Adaptive Position/Attitude Tracking Control of Aerial Robot With Unknown Inertial Matrix Based on a New Robust Neural Identifier},
year={2016},
volume={27},
number={1},
pages={18-31},
abstract={This paper presents a novel adaptive controller for controlling an autonomous helicopter with unknown inertial matrix to asymptotically track the desired trajectory. To identify the unknown inertial matrix included in the attitude dynamic model, this paper proposes a new structural identifier that differs from those previously proposed in that it additionally contains a neural networks (NNs) mechanism and a robust adaptive mechanism, respectively. Using the NNs to compensate the unknown aerodynamic forces online and the robust adaptive mechanism to cancel the combination of the overlarge NNs compensation error and the external disturbances, the new robust neural identifier exhibits a better identification performance in the complex flight environment. Moreover, an optimized algorithm is included in the NNs mechanism to alleviate the burdensome online computation. By the strict Lyapunov argument, the asymptotic convergence of the inertial matrix identification error, position tracking error, and attitude tracking error to arbitrarily small neighborhood of the origin is proved. The simulation and implementation results are provided to evaluate the performance of the proposed controller.},
keywords={Aerodynamics;Symmetric matrices;Artificial neural networks;Helicopters;Robustness;Attitude control;Trajectory;Aerial robot;inertial matrix identifier;neural networks (NNs);robust adaptive control;unmanned aerial vehicle (UAV).;Aerial robot;inertial matrix identifier;neural networks (NNs);robust adaptive control;unmanned aerial vehicle (UAV)},
doi={10.1109/TNNLS.2015.2406812},
ISSN={2162-2388},
month={Jan},}
@INPROCEEDINGS{8441965,
author={Bashmal, Laila and Bazi, Yakoub},
booktitle={2018 1st International Conference on Computer Applications Information Security (ICCAIS)}, title={Learning Robust Deep Features for Efficient Classification of UAV Imagery},
year={2018},
volume={},
number={},
pages={1-4},
abstract={This paper presents a deep learning approach for the classification of Unmanned Aerial Vehicle (UAV) images acquired by different sensors and different locations of the earth surface. In a first step, the labeled and unlabeled UAV images under analysis are fed to a pretrained convolutional neural network (CNN) for generating initial deep feature representations. Then in second step, we learn robust domain-invariant features using an additional network composed of two fully connected layers. This network aims to tackle the data-shift problem by reducing the discrepancy between the labeled and unlabeled data distributions. For such purpose, the first layer projects the labeled data to the space of the unlabeled data, while the second layer maintains the discrimination ability between the different land-cover classes. Experimental results obtained on two datasets acquired over the cities of Trento and Toronto with spatial resolutions of 2 cm and 15 cm, respectively, are reported and discussed.},
keywords={Feature extraction;Training;Unmanned aerial vehicles;Urban areas;Spatial resolution;Machine learning;Image analysis;Scene classification;deep features;domain adaptation;convolutional Neural Network (CNN)},
doi={10.1109/CAIS.2018.8441965},
ISSN={},
month={April},}
@ARTICLE{9359491,
author={Menshchikov, Alexander and Shadrin, Dmitrii and Prutyanov, Viktor and Lopatkin, Daniil and Sosnin, Sergey and Tsykunov, Evgeny and Iakovlev, Evgeny and Somov, Andrey},
journal={IEEE Transactions on Computers}, title={Real-Time Detection of Hogweed: UAV Platform Empowered by Deep Learning},
year={2021},
volume={70},
number={8},
pages={1175-1188},
abstract={The Hogweed of Sosnowskyi (lat. Heracleum sosnówskyi) is poisonous for humans, dangerous for farming crops, and local ecosystems. This plant is fast-growing and has already spread all over Eurasia: from Germany to the Siberian part of Russia, and its distribution expands year-by-year. In-situ detection of this harmful plant is a tremendous challenge for many countries. Meanwhile, there are no automatic systems for detection and localization of hogweed. In this article, we report on an approach for fast and accurate detection of hogweed. The approach includes the Unmanned Aerial Vehicle (UAV) with an embedded system on board running various Fully Convolutional Neural Networks (FCNN). We propose the optimal architecture of FCNN for the embedded system relying on the trade-off between the detection quality and frame rate. We propose a model that achieves ROC AUC 0.96 in the hogweed segmentation task, which can process 4K frames at 0.46 FPS on NVIDIA Jetson Nano. The developed system can recognize the hogweed on the scale of individual plants and leaves. This system opens up a wide vista for obtaining comprehensive and relevant data about the spreading of harmful plants allowing for the elimination of their expansion.},
keywords={Agriculture;Monitoring;Task analysis;Satellites;Image segmentation;Embedded systems;Cameras;Deep learning;edge computing;aerial imagery;unmanned aerial vehicles;precision agriculture;plant phenotype},
doi={10.1109/TC.2021.3059819},
ISSN={1557-9956},
month={Aug},}
@ARTICLE{9343737,
author={Zheng, Ye and Chen, Zhang and Lv, Dailin and Li, Zhixing and Lan, Zhenzhong and Zhao, Shiyu},
journal={IEEE Robotics and Automation Letters}, title={Air-to-Air Visual Detection of Micro-UAVs: An Experimental Evaluation of Deep Learning},
year={2021},
volume={6},
number={2},
pages={1020-1027},
abstract={This letter studies the problem of air-to-air visual detection of micro unmanned aerial vehicles (UAVs) by monocular cameras. This problem is important for many applications such as vision-based swarming of UAVs, malicious UAV detection, and see-and-avoid systems for UAVs. Although deep learning methods have exhibited superior performance in many object detection tasks, their potential for UAV detection has not been well explored. As the first main contribution of this letter, we present a new dataset, named Det-Fly, which consists of more than 13 000 images of a flying target UAV acquired by another flying UAV. Compared to the existing datasets, the proposed one is more comprehensive in the sense that it covers a wide range of practical scenarios with different background scenes, viewing angles, relative distance, flying altitude, and lightning conditions. The second main contribution of this letter is to present an experimental evaluation of eight representative deep-learning algorithms based on the proposed dataset. To the best of our knowledge, this is the first comprehensive experimental evaluation of deep learning algorithms for the task of visual UAV detection so far. The evaluation results highlight some key challenges in the problem of air-to-air UAV detection and suggest potential ways to develop new algorithms in the future. The dataset is available at https://github.com/Jake-WU/Det-Fly.},
keywords={Unmanned aerial vehicles;Feature extraction;Deep learning;Cameras;Visualization;Task analysis;Object detection;Deep learning;UAV detection;visual detection},
doi={10.1109/LRA.2021.3056059},
ISSN={2377-3766},
month={April},}
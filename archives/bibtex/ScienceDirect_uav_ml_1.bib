@article{SHARMA2021102685,
title = {Role of machine learning and deep learning in securing 5G-driven industrial IoT applications},
journal = {Ad Hoc Networks},
volume = {123},
pages = {102685},
year = {2021},
issn = {1570-8705},
doi = {https://doi.org/10.1016/j.adhoc.2021.102685},
url = {https://www.sciencedirect.com/science/article/pii/S1570870521001906},
author = {Parjanay Sharma and Siddhant Jain and Shashank Gupta and Vinay Chamola},
keywords = {Industrial internet of things, Security, Machine learning, Deep learning, Artificial intelligence, Block chain, Smart city},
abstract = {The Internet of Things (IoT) connects millions of computing devices and has set a stage for future technology where industrial use cases like smart cities and smart houses will operate with minimal human intervention. IoT’s cross-domain amalgamations with emergent technologies like 5G and blockchain affects human life. Hence, increase in reliance over IoT necessitates focus on its privacy and security concerns. Implementing security through encryption, authentication, access control and communication security is the need of the hour. These needs can be best catered with the use of machine learning (ML) and deep learning (DL) that can help in realizing secure intelligent systems. In this work, the authors present a comprehensive review for securing Industrial-IoT (I-IoT) devices to contribute to the development of security methods for I-IoT deployed over 5G and blockchain. The survey provides a general analysis of the state-of-the-art security implementation and further assesses the product life cycle of IoT devices. The authors present numerous virtues as well as faults in the machine learning and deep learning algorithms deployed over the fog architecture in context with the security solutions. The potential security algorithms can help overcome many challenges in the IoT security and pave way for implementation with emerging technologies like 5G, blockchain, edge computing, fog computing and their use cases for creating smart environments.}
}
@article{SHAO201715289,
title = {Disturbance observer-based discrete-time neural control for unmanned aerial vehicles with uncertainties and disturbances **This work is supported by National Natural Science Foundation of China (No. 61573184), 333 Talents Project in Jiangsu Province (No. BRA2015359) and Jiangsu Innovation Program for Graduate Education (No. KYLX16 0375).},
journal = {IFAC-PapersOnLine},
volume = {50},
number = {1},
pages = {15289-15294},
year = {2017},
note = {20th IFAC World Congress},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2017.08.2439},
url = {https://www.sciencedirect.com/science/article/pii/S2405896317333086},
author = {Shuyi Shao and Mou Chen and Rong Mei},
keywords = {UAV, disturbance observer, neural network, backstepping, tracking control},
abstract = {In this paper, a disturbance observer-based discrete-time neural control problem is studied for unmanned aerial vehicle (UAV) in the presence of external disturbances and system uncertainties. To estimate the external disturbance, a nonlinear discrete-time disturbance observer (DTDO) is designed. Furthermore, the system uncertainties are approximated by employing neural network (NN). Then, a discrete-time neural tracking control scheme is proposed based on the designed DTDO, the discrete-time tracking differentiator and the backstepping technique. Under the discrete-time Lyapunov analysis, the boundness of all the closed-loop system signals are proven. Finally, numerical simulation results are shown to demonstrate the effectiveness of the proposed control scheme.}
}
@article{HOSSAIN2020158,
title = {UAV image analysis for leakage detection in district heating systems using machine learning},
journal = {Pattern Recognition Letters},
volume = {140},
pages = {158-164},
year = {2020},
issn = {0167-8655},
doi = {https://doi.org/10.1016/j.patrec.2020.05.024},
url = {https://www.sciencedirect.com/science/article/pii/S0167865520302038},
author = {Kabir Hossain and Frederik Villebro and Søren Forchhammer},
keywords = {CNN, SVM, RF, Adaboost, Energy leakage detection, District heating systems},
abstract = {In this paper, we propose automatic energy leakage detection in underground pipes of district heating systems based on Infrared (IR) images, captured by an Unmanned Aerial Vehicle (UAV). Hot water or steam is distributed to homes and industries through underground pipes from a central power plan. Leakages in underground pipes pose a very common problem, which can occur for many reasons, e.g. unprofessional installation and end of service life. Potentially, a leakage remains undiscovered for a very long period of time. Therefore, it is of great interest for power supply companies to monitor district heating networks to identify leakages. In this paper, the original IR images are captured in a 16 bit format by a UAV. On ground, potential leakages are extracted using a region extraction algorithm. Thereafter a Convolutional Neural Network (CNN) as well as eight conventional Machine Learning (ML) classifiers are applied on these regions to classify whether or not it is a leakage. In total, twelve UAV sequences are captured at different cities in Denmark. Based on these, around 13.4 million samples of image patches of district heating systems are extracted. Eleven sequences are used for training and the remaining one for testing. This was performed on all splits in the leave-one-out testing. The deep learning CNN achieved an average weighted accuracy of 0.872 with a false positive and negative rate of 12.7 % and 10.4 %, respectively. This CNN model detected around 98.6 % of the true leakages. In comparison, conventional ML classifiers, i.e. Adaboost (AB), Random Forest (RF), etc. provide lower average weighted accuracy, but on the other hand they require less computational resources. We have compared our method with a state-of-art method and the result shows that the proposed method is very competitive.}
}
@article{YAO2019455,
title = {An iterative strategy for task assignment and path planning of distributed multiple unmanned aerial vehicles},
journal = {Aerospace Science and Technology},
volume = {86},
pages = {455-464},
year = {2019},
issn = {1270-9638},
doi = {https://doi.org/10.1016/j.ast.2019.01.061},
url = {https://www.sciencedirect.com/science/article/pii/S1270963818315785},
author = {Weiran Yao and Naiming Qi and Neng Wan and Yongbei Liu},
keywords = {Task assignment and path planning, Iterative strategy, Multi-UAV, Auction algorithm},
abstract = {In this paper, we propose an iterative strategy to enhance the performance of task assignment and path planning in applications of distributed multiple unmanned aerial vehicles (Multi-UAV). As an improvement of the conventional management of airborne computation and communication resources of UAVs, our strategy overcomes difficulties caused by the information coupling between task assignment and path planning. A distributed mission planning framework is presented with the strategy, in which the UAVs re-evaluate unreasonable assignment results and overvalued tasks during the planning process. The proposed strategy has advantages in algorithm stability and complexity, as it controls the task valuation error within a certain range via computation with limited complexity. Compared to the conventional methods, our strategy with the framework can achieve better performance of planning results and consume less computing resources. Simulation results show the effectiveness of the proposed strategy in terms of the computational efficiency and the mission execution reward.}
}
@article{DIMILILER2021103613,
title = {Deep learning, machine learning and internet of things in geophysical engineering applications: An overview},
journal = {Microprocessors and Microsystems},
volume = {80},
pages = {103613},
year = {2021},
issn = {0141-9331},
doi = {https://doi.org/10.1016/j.micpro.2020.103613},
url = {https://www.sciencedirect.com/science/article/pii/S0141933120307602},
author = {Kamil Dimililer and Hilmi Dindar and Fadi Al-Turjman},
keywords = {Machine learning, Deep learning, Iot, Earthquakes, Natural Hazards},
abstract = {The earthquakes in Eastern Mediterranean are mostly tectonic. The earthquakes that are 60 km deep in the ground are called Shallow earthquakes. The earthquakes in the eastern Mediterranean are generally shallow-orientated, and their depth often varies between 0 and 30 km. When there is a sudden plate movement within the earth's crust, increasing friction between two plates can result in earthquakes, which are harmful to human lives, buildings and the economy. With the technological developments in the world over the years, more information has been accessible and reliable. The Internet of things (IoT) and crowdsourcing have proven to be effective in predicting and preparing for the future natural hazards when combined with Machine Learning or Deep Learning. Machine learning does not require human interaction, as the machines automatically gets information and distributes in real-time to prevent major or severe damages, which are low-cost, has lower power consumption with reliable information. Short Message Service and Global Positioning System are still functional, even though powerlines and mobile beacons, were cut during recent massive earthquakes in some countries of Asia. The Seismic Alert System (SAS) is another design to prevent and reduce earthquake damages. The SAS was designed in 1996, to be effective with real time data from seismograms. The Earth cloud uses geophones which uses MEMS (micro electro-mechanical system). Geophones have an accelerometer and seismometers to detect the earth movement. Therefore, usage of sensors and the Internet of Things (IoT) to monitor earthquakes and send early warning signals to prevent destruction of buildings and loss of life play a significant role.}
}
@article{ZHOU2019100770,
title = {Mobile and redundant access point reduction for indoor unmanned aerial vehicle positioning using WLAN crowdsourcing fingerprints},
journal = {Physical Communication},
volume = {36},
pages = {100770},
year = {2019},
issn = {1874-4907},
doi = {https://doi.org/10.1016/j.phycom.2019.100770},
url = {https://www.sciencedirect.com/science/article/pii/S1874490719301843},
author = {Mu Zhou and Hui Yuan and Liangbo Xie and Weiqiang Tan and Zengshan Tian},
keywords = {Unmanned aerial vehicles, Indoor positioning, WLAN fingerprint, Crowdsourcing, Neighborhood rough set},
abstract = {In recent years, due to the rapid development of indoor Unmanned Aerial Vehicles (UAVs), the positioning of indoor UAVs has played a significant role in UAVs applications. Among the existing approaches, the Wireless Local Area Network (WLAN) based positioning approach is recognized as an effective way by the benefit from the widely-deployed WLAN. At the same time, the continued expansion of WLAN is accompanied by the numerous types of Access Points (APs) such as mobile phones and tablets. In this circumstance, the existence of mobile APs reduces the location dependency of Received Signal Strength (RSS) data, and meanwhile the large number of APs results in huge storage and computational overhead to the positioning. In response to these compelling problems, we propose a joint judgment criterion by which the WLAN crowdsourcing fingerprints are applied to detect mobile APs. After that, we use the neighborhood rough set reduction algorithm to calculate the weight of each AP and then remove the APs with zero weight. Finally, we rely on the fingerprints from remaining APs to construct a fingerprint database for the positioning. The extensive experimental results show that the proposed approach can precisely detect mobile APs as well as guarantee the satisfactory positioning accuracy under the redundant APs removal.}
}
@article{WU2021108004,
title = {Deep reinforcement learning for blockchain in industrial IoT: A survey},
journal = {Computer Networks},
volume = {191},
pages = {108004},
year = {2021},
issn = {1389-1286},
doi = {https://doi.org/10.1016/j.comnet.2021.108004},
url = {https://www.sciencedirect.com/science/article/pii/S1389128621001213},
author = {Yulei Wu and Zehua Wang and Yuxiang Ma and Victor C.M. Leung},
keywords = {Blockchain, Industrial Internet-of-Things, Consensus, Storage, Communication, Security},
abstract = {With the ambitious plans of renewal and expansion of industrialization in many countries, the efficiency, agility and cost savings potentially resulting from the application of industrial Internet of Things (IIoT) are drawing attentions. Although blockchain and machine learning technologies (especially deep learning and deep reinforcement learning) may provide the next promising use case for IIoT, they are working in an adversarial way to some extent. While blockchain facilitates the data collection that is critical for machine learning under the premise of data regulation rules like privacy protection, it may suffer from privacy leakage due to big data analytics with the help of machine learning. To make machine learning and blockchain useful and practical for diversified services in industrial sectors, it is of paramount importance to have a comprehensive understanding of the development of both technologies in the context of IIoT. To this end, in this paper we summarize and analyze the applications of blockchain and machine learning in IIoT from three important aspects, i.e., consensus mechanism, storage and communication. This survey provides a deeper understanding on the security and privacy risks of the key components of a blockchain from the perspective of machine learning, which is useful in the design of practical blockchain solutions for IIoT. In addition, we provide useful guidance for future research in the area by identifying interesting open problems that need to be addressed before large-scale deployments of IIoT applications are practicable.}
}
@article{KC2021105903,
title = {Integration of RGB-based vegetation index, crop surface model and object-based image analysis approach for sugarcane yield estimation using unmanned aerial vehicle},
journal = {Computers and Electronics in Agriculture},
volume = {180},
pages = {105903},
year = {2021},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2020.105903},
url = {https://www.sciencedirect.com/science/article/pii/S0168169920331082},
author = {Sumesh K.C. and Sarawut Ninsawat and Jaturong Som-ard},
keywords = {Sugarcane, Spatial variability, UAV, OBIA, Yield estimation},
abstract = {Estimation of yield is a major challenge in the production of many agricultural crops, including sugarcane. Mapping the spatial variability of plant height (PH) and the stalk density is important for accurate sugarcane yield estimation, and this estimation can aid in the planning of upcoming labor- and cost-intensive actions like harvesting, milling, and forward selling decisions. The objective of this research is to assess the potential of a consumer-grade red-green-blue (RGB) camera mounted on an unmanned aerial vehicle (UAV) for sugarcane yield estimation with minimal field dataset. The study mapped the spatial variability of PH and stalk density at the grid level (4 m × 4 m) on a farm. The average PH was estimated at the grid level by masking the sugarcane area. An object-based image analysis (OBIA) approach was used to extract the sugarcane area by integrating the plant height model (PHM), extracted by subtracting the digital elevation model (DEM) from the crop surface model (CSM). Both CSM and DEM were generated from UAV images, where CSM was produced approximately one month before the harvest and the DEM after the sugarcane was harvested. The PHM improved the overall accuracy of classification from 61.98% to 87.45%. The UAV estimated PH showed a high correlation (r = 0.95) with ground observed PH, with an average overestimation of 0.10 m. An ordinary least square (OLS) linear regression model was developed to estimate millable stalk height (MSH) from PH, weight from estimated MSH, and stalk density from vegetation indices (VIs) at the grid-level. Excess green (ExG) derived from RGB showed R2 of 0.754 with the stalk density. Likewise, R2 of 0.798 and 0.775 were obtained between MSH and PH, and weight and MSH. Eventually, the yield was estimated by integrating the variability of PH and stalk density and weight information. The estimated yield from ExG (200.66 tons) was close to the actual harvest yield (192.1 tons). The very high-resolution RGB-based images from the UAV and OBIA approach demonstrate significant potential for mapping the spatial variability of PH and stalk density and for estimating sugarcane yield. This can aid growers and millers in decision making.}
}
@article{MCILWAINE2021102279,
title = {JellyNet: The convolutional neural network jellyfish bloom detector},
journal = {International Journal of Applied Earth Observation and Geoinformation},
volume = {97},
pages = {102279},
year = {2021},
issn = {0303-2434},
doi = {https://doi.org/10.1016/j.jag.2020.102279},
url = {https://www.sciencedirect.com/science/article/pii/S0303243420309223},
author = {Ben Mcilwaine and Mónica {Rivas Casado}},
keywords = {Jellyfish bloom, Unmanned aerial vehicle, Machine learning, Convolution neural network, Remote sensing, Deep learning},
abstract = {Coastal industries face disruption on a global scale due to the threat of large blooms of jellyfish. They can decimate coastal fisheries and clog the water intake systems of desalination and nuclear power plants. This can lead to losses of revenue and power output. This paper presents JellyNet: a convolutional neural network (CNN) jellyfish bloom detection model trained on high resolution remote sensing imagery collected by unmanned aerial vehicles (UAVs). JellyNet provides the detection capability for an early (6–8 h) bloom warning system. 1539 images were collected from flights at 2 locations: Croabh Haven, UK and Pruth Bay, Canada. The training/test dataset was manually labelled, and split into two classes: ‘Bloom present’ and ‘No bloom present’. 500 × 500 pixel images were used to increase fine-grained pattern detection of the jellyfish blooms. Model testing was completed using a 75/25% training/test split with hyperparameters selected prior to model training using a held-out validation dataset. Transfer learning using VGG-16 architecture, and a jellyfish bloom specific binary classifier surpassed an accuracy of 90%. Test model performance peaked at 97.5% accuracy. This paper exhibits the first example of a high resolution, multi-sensor jellyfish bloom detection capability, with integrated robustness from two oceans to tackle real world detection challenges.}
}
@article{MEKRACHE2022100398,
title = {Deep reinforcement learning techniques for vehicular networks: Recent advances and future trends towards 6G},
journal = {Vehicular Communications},
volume = {33},
pages = {100398},
year = {2022},
issn = {2214-2096},
doi = {https://doi.org/10.1016/j.vehcom.2021.100398},
url = {https://www.sciencedirect.com/science/article/pii/S221420962100067X},
author = {Abdelkader Mekrache and Abbas Bradai and Emmanuel Moulay and Samir Dawaliby},
keywords = {Vehicular networks, Reinforcement learning, Deep reinforcement learning, 6G wireless networks},
abstract = {Employing machine learning into 6G vehicular networks to support vehicular application services is being widely studied and a hot topic for the latest research works in the literature. This article provides a comprehensive review of research works that integrated reinforcement and deep reinforcement learning algorithms for vehicular networks management with an emphasis on vehicular telecommunications issues. Vehicular networks have become an important research area due to their specific features and applications such as standardization, efficient traffic management, road safety, and infotainment. In such networks, network entities need to make decisions to maximize network performance under uncertainty. To achieve this goal, Reinforcement Learning (RL) can effectively solve decision-making problems. However, the state and action spaces are massive and complex in large-scale wireless networks. Hence, RL may not be able to find the best strategy in a reasonable time. Therefore, Deep Reinforcement Learning (DRL) has been developed to combine RL with Deep Learning (DL) to overcome this issue. In this survey, we first present vehicular networks and give a brief overview of RL and DRL concepts. Then we review RL and especially DRL approaches to address emerging issues in 6G vehicular networks. We finally discuss and highlight some unresolved challenges for further study.}
}
@article{VONG2021106214,
title = {Early corn stand count of different cropping systems using UAV-imagery and deep learning},
journal = {Computers and Electronics in Agriculture},
volume = {186},
pages = {106214},
year = {2021},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2021.106214},
url = {https://www.sciencedirect.com/science/article/pii/S0168169921002313},
author = {Chin Nee Vong and Lance S. Conway and Jianfeng Zhou and Newell R. Kitchen and Kenneth A. Sudduth},
keywords = {Corn, Cropping systems, Deep learning, Stand count, UAV imagery},
abstract = {Optimum plant stand density and uniformity is vital in order to maximize corn (Zea mays L.) yield potential. Assessment of stand density can occur shortly after seedlings begin to emerge, allowing for timely replant decisions. The conventional methods for evaluating an early plant stand rely on manual measurement and visual observation, which are time consuming, subjective because of the small sampling areas used, and unable to capture field-scale spatial variability. This study aimed to evaluate the feasibility of an unmanned aerial vehicle (UAV)-based imaging system for estimating early corn stand count in three cropping systems (CS) with different tillage and crop rotation practices. A UAV equipped with an on-board RGB camera was used to collect imagery of corn seedlings (~14 days after planting) of CS, i.e., minimum-till corn-soybean rotation (MTCS), no-till corn-soybean rotation (NTCS), and no-till corn-corn rotation with cover crop implementation (NTCC). An image processing workflow based on a deep learning (DL) model, U-Net, was developed for plant segmentation and stand count estimation. Results showed that the DL model performed best in segmenting seedlings in MTCS, followed by NTCS and NTCC. Similarly, accuracy for stand count estimation was highest in MTCS (R2 = 0.95), followed by NTCS (0.94) and NTCC (0.92). Differences by CS were related to amount and distribution of soil surface residue cover, with increasing residue generally reducing the performance of the proposed method in stand count estimation. Thus, the feasibility of using UAV imagery and DL modeling for estimating early corn stand count is qualified influenced by soil and crop management practices.}
}
@article{ALTURJMAN202027,
title = {Optimized Unmanned Aerial Vehicles Deployment for Static and Mobile Targets’ Monitoring},
journal = {Computer Communications},
volume = {149},
pages = {27-35},
year = {2020},
issn = {0140-3664},
doi = {https://doi.org/10.1016/j.comcom.2019.10.001},
url = {https://www.sciencedirect.com/science/article/pii/S0140366419306954},
author = {Fadi Al-Turjman and Hadi Zahmatkesh and Ibrhaim Al-Oqily and Reda Daboul},
keywords = {Smart city, Unmanned Aerial Vehicle (UAV), Drone, Internet of Things (IoT)},
abstract = {In the recent decade, drones or Unmanned Aerial Vehicles (UAVs) are getting increasing attention by both industry and academia. Due to the support of advanced technologies, they might be soon an integral part of any smart-cities related project. In this paper, we propose a cost-effective framework related to the optimal placement of drones in order to monitor a set of static and/or dynamic targets in the IoT era. The main objective of this study is to minimize the total number of drones required to monitor an environment while providing the maximum coverage, which in turn leads to significant reduction in cost. Our simulation results show that by increasing the battery capacity of the drones, the drones’ visibility range would also increase and thus, the number of drones would be reduced. Moreover, when the targets are sparsely distributed across a large number of different regions, a further increase to the targets does not require an increase in the number of drones needed to monitor them.}
}
@article{TIAN2021146816,
title = {Aboveground mangrove biomass estimation in Beibu Gulf using machine learning and UAV remote sensing},
journal = {Science of The Total Environment},
volume = {781},
pages = {146816},
year = {2021},
issn = {0048-9697},
doi = {https://doi.org/10.1016/j.scitotenv.2021.146816},
url = {https://www.sciencedirect.com/science/article/pii/S0048969721018842},
author = {Yichao Tian and Hu Huang and Guoqing Zhou and Qiang Zhang and Jin Tao and Yali Zhang and Junliang Lin},
keywords = {Machine learning method, UAV remote sensing, Aboveground biomass, LiDAR point cloud, Mangrove forests, Beibu Gulf},
abstract = {On the basis of canopy height variables, vegetation index, texture index, and laser point cloud index measured with unmanned aerial vehicle (UAV) low altitude remote sensing, we used eight machine learning (ML) models to estimate the aboveground biomass of different species of mangroves in Beibu Gulf and compared the accuracy of different ML models for these estimations. The main species of typical mangrove communities in Kangxiling were Aegiceras corniculata and Sonneratia apetala. The trunks of Sonneratia apetala were thicker, with an average height of 11.82 m, whereas Aegiceras corniculata trees were shorter, with an average height of 2.58 m. The XGBoost regressor (XGBR) model had the highest accuracy in estimating mangrove aboveground biomass (R2 = 0.8319, RMSE = 22.7638 Mg/ha), followed by the random forest regressor model (R2 = 0.7887, RMSE = 25.5193 Mg/ha). Support vector regression, decision tree regressor, and extra trees regressor had poor fitting effects. Mangrove texture index ranked first in importance for the model, followed by the mangrove laser point cloud height index, and the laser point cloud intensity index performed the worst in the model. Mangrove aboveground biomass in the study area is high in the north and low in the south, ranging from 38.23 to 171.80 Mg/ha, with an average value of 94.37 Mg/ha. Generally, the XGBR method can better estimate the aboveground biomass of mangroves based on the measured mangrove plot data and UAV low-altitude remote sensing data.}
}
@article{LEI20191488,
title = {State of art on energy management strategy for hybrid-powered unmanned aerial vehicle},
journal = {Chinese Journal of Aeronautics},
volume = {32},
number = {6},
pages = {1488-1503},
year = {2019},
issn = {1000-9361},
doi = {https://doi.org/10.1016/j.cja.2019.03.013},
url = {https://www.sciencedirect.com/science/article/pii/S1000936119301268},
author = {Tao LEI and Zhou YANG and Zicun LIN and Xiaobin ZHANG},
keywords = {Energy management strategy (EMS), Hybrid power system (HPS), New energy sources, Optimization algorithms, UAV},
abstract = {New energy sources such as solar energy and hydrogen energy have been applied to the Unmanned Aerial Vehicle (UAV), which could be formed as the hybrid power sources due to the requirement of miniaturization, lightweight, and environmental protection issue for UAV. Hybrid electrical propulsion technology has been used in UAV and it further enforces this trend for the evolution to the Hybrid-Powered System (HPS). In order to realize long endurance flight mission and improve the energy efficiency of UAV, many researching works are focused on the Energy Management Strategy (EMS) of the HPS with digital simulation, ground demonstration platforms and a few flight tests for the UAV in recent years. energy management strategy, in which off-line or on-line control algorithms acted as the core part, could optimize dynamic electrical power distribution further and directly affect the efficiency and fuel economy of hybrid-powered system onboard. In order to give the guideline for this emerging technology for UAV, this paper presents a review of the topic highlighting energy optimal management strategies of UAV. The characteristics of typical new energy sources applied in UAV are summarized firstly, and then the classification and analysis of the architecture for hybrid power systems in UAV are presented. In the context of new energy sources and configuration of energy system, a comprehensive comparison and analysis for the state of art of EMS are presented, and the various levels of complexity and accuracy of EMS are considered in terms of real time, computational burden and optimization performance based on the optimal control and operational modes of UAV. Finally, the tendency and challenges of energy management strategy applied to the UAV have been forecasted.}
}
@article{LI2021106887,
title = {Trajectory planning of load transportation with multi-quadrotors based on reinforcement learning algorithm},
journal = {Aerospace Science and Technology},
volume = {116},
pages = {106887},
year = {2021},
issn = {1270-9638},
doi = {https://doi.org/10.1016/j.ast.2021.106887},
url = {https://www.sciencedirect.com/science/article/pii/S1270963821003977},
author = {Xiaoxuan Li and Jianlei Zhang and Jianda Han},
keywords = {Cable-suspended payload, Quadrotor, Reinforcement learning, Trajectory planning, Unmanned aerial vehicle},
abstract = {Unmanned aerial vehicles (UAVs) are playing more and more vital roles in transportation. In this work, a trajectory planning method based on a value-function approximation algorithm is proposed to address the problem of cable-suspended load transportation using three quadrotors. The purpose of trajectory planning is to reach the target position as soon as possible without the load swinging. In the proposed algorithm, the value function is approximated by parameter vector and problem-specific feature vector. The parameter vector is updated by batch method, and then the greedy strategy is used to generate the desired trajectory. Finally, the desired trajectory is passed to the quad-rotor controller for trajectory tracking. The simulation results show that the trained parameters can fit the value function. The suspended load can be transported smoothly from starting location to the different target locations. The value function in the greedy strategy finally converges to the maximum value, which proves the effectiveness and convergence of the proposed algorithm.}
}
@article{WU2021104410,
title = {Simulations of spatial patterns and species distributions in sandy land using unmanned aerial vehicle images},
journal = {Journal of Arid Environments},
volume = {186},
pages = {104410},
year = {2021},
issn = {0140-1963},
doi = {https://doi.org/10.1016/j.jaridenv.2020.104410},
url = {https://www.sciencedirect.com/science/article/pii/S0140196320303098},
author = {Yin Wu and Jing Zhang and Feng Wang and Yongyu Song and Jie Ji},
keywords = {UAV, Vegetation pattern, Micro-topography, 2D Poisson simulation, Otindag sandy land},
abstract = {The spatial distribution of vegetation in sandy lands is closely related to micro-topography. Point pattern analysis of vegetation distribution from ground surveys and satellite images is a commonly used method but does not capture the influence of spatial heterogeneity at small scales. This study examined long-term ecological observation sites of elm (Ulmus pumila) sparse forest in the Otindag Sandy Land, China. Elevation models from unmanned aerial vehicles (UAVs) and ground survey data on vegetation structure from 3768 elms were used to classify the terrain of sampled sites using a decision tree classification. It combined terrain factors, including slope, aspect, and small-scale altitude differences. Plots were divided into five topographic types: sand flat (53%), sand lowland (17%), sunny slope (13%), shady slope (10%), and sandy ridges (7%). Elm densities varied from 141.7 trees hm−2 on shady slopes to 17.0 trees hm−2 on sand lowland. A 2D Poisson fitting method was applied to the diameter at breast height, crown width, and other vegetation growth characteristics to simulate and verify the distribution of elms in the plots. Multivariate analysis was undertaken to confirm the effect of topographic factors on variation of tree characteristics. The integrated terrain approach could better characterize the spatial distribution of sparse forests. This research demonstrated that UAVs were a useful tool to measure spatial heterogeneity of sand micro-topography. Simulations of the distribution of plant characteristics indicated that the terrain classification matched the spatial pattern analysis of elms in semi-arid regions. Simulation of vegetation distribution is a useful technique for analyzing arid regions. This study will assist with further research on ecological restoration and vegetation protection in semi-arid areas.}
}
@article{ODONKOR201952,
title = {Distributed operation of collaborating unmanned aerial vehicles for time-sensitive oil spill mapping},
journal = {Swarm and Evolutionary Computation},
volume = {46},
pages = {52-68},
year = {2019},
issn = {2210-6502},
doi = {https://doi.org/10.1016/j.swevo.2019.01.005},
url = {https://www.sciencedirect.com/science/article/pii/S2210650217309288},
author = {Philip Odonkor and Zachary Ball and Souma Chowdhury},
keywords = {Anomaly detection, Distributed decision-making, Oil spill mapping, Swarm intelligence, Unmanned aerial vehicles (UAV)},
abstract = {Multiple simple agents working together to achieve a common complex goal embodies the underlying theme of swarm concepts, with decentralized decision-making serving as the new frontier for tackling challenges associated with scalability, fault tolerance, and communication constraints. This paper builds on this emerging paradigm to develop a distributed approach (called PSOil) for off-shore oil spill mapping using a team of unmanned aerial vehicles or UAVs. In-flight waypoint planning is achieved via a new particle swarm mechanics-inspired technique, employing a novel combination of anomaly detection for knowledge extraction, and a stochastic occupancy grid approach for timely processing and frugal sharing of knowledge (with net communications <1.7 KB/UAV every 10 waypoints). A total of ten real-world oil spill images, encapsulating complexities such as non-convex arbitrary shapes and disjointed segments, are studied in this work. Overall, the algorithm registered 55–90% completeness in mapping oil-covered areas. PSOil required around one-third the time necessary for an exhaustive survey and was found to be superior compared to a typical random walk and a spiral search approach w.r.t. mapping performance and efficiency, respectively. Further tests simulating increasing UAV team sizes (to deal with larger search areas) and the random loss of team members respectively illustrate the scalability and fault-tolerance characteristics of PSOil.}
}
@article{HOCRAFFER201766,
title = {A meta-analysis of human-system interfaces in unmanned aerial vehicle (UAV) swarm management},
journal = {Applied Ergonomics},
volume = {58},
pages = {66-80},
year = {2017},
issn = {0003-6870},
doi = {https://doi.org/10.1016/j.apergo.2016.05.011},
url = {https://www.sciencedirect.com/science/article/pii/S0003687016300989},
author = {Amy Hocraffer and Chang S. Nam},
keywords = {Unmanned aerial vehicle (UAV), Swarm, Multi-robot systems, Human factors, Human-system interface, Human-robot interaction, Human-swarm interaction},
abstract = {A meta-analysis was conducted to systematically evaluate the current state of research on human-system interfaces for users controlling semi-autonomous swarms composed of groups of drones or unmanned aerial vehicles (UAVs). UAV swarms pose several human factors challenges, such as high cognitive demands, non-intuitive behavior, and serious consequences for errors. This article presents findings from a meta-analysis of 27 UAV swarm management papers focused on the human-system interface and human factors concerns, providing an overview of the advantages, challenges, and limitations of current UAV management interfaces, as well as information on how these interfaces are currently evaluated. In general allowing user and mission-specific customization to user interfaces and raising the swarm’s level of autonomy to reduce operator cognitive workload are beneficial and improve situation awareness (SA). It is clear more research is needed in this rapidly evolving field.}
}
@article{YANG2021,
title = {Robust cascaded horizontal-plane trajectory tracking for fixed-wing unmanned aerial vehicles},
journal = {Journal of the Franklin Institute},
year = {2021},
issn = {0016-0032},
doi = {https://doi.org/10.1016/j.jfranklin.2021.12.021},
url = {https://www.sciencedirect.com/science/article/pii/S0016003221007468},
author = {Wenlong Yang and Jintao Chen and Zonggang Zhang and Zongying Shi and Yisheng Zhong},
abstract = {This paper investigates the problem of horizontal-plane trajectory tracking for fixed-wing unmanned aerial vehicles(UAVs) subjected to external disturbances and uncertainties including coupling and unmodeled dynamics. Under the assumption there exist ideal inner-loop controllers, the 12-state model is reduced to a 6-state translational motion model, which is described by a group of simplified nonlinear equations with equivalent disturbances via introducing general aerodynamic models. Then a new cascaded control structure consisting of an outer-loop controller for position control and inner-loop controllers for attitude and thrust control is proposed. Based on feedback linearization technology and signal compensation theory, the proposed controller applied for position control incorporates a nominal linear time-invariant controller and a robust compensator, the latter of which is introduced to restrain the effects of uncertainties and disturbances. The robust performance of the closed-loop system is proved. Actual experimental results conducted on a small fixed-wing aircraft demonstrate that the proposed control approach is effective.}
}
@article{LIU2020105671,
title = {Reinforcement learning based two-level control framework of UAV swarm for cooperative persistent surveillance in an unknown urban area},
journal = {Aerospace Science and Technology},
volume = {98},
pages = {105671},
year = {2020},
issn = {1270-9638},
doi = {https://doi.org/10.1016/j.ast.2019.105671},
url = {https://www.sciencedirect.com/science/article/pii/S1270963819309939},
author = {Yuxuan Liu and Hu Liu and Yongliang Tian and Cong Sun},
keywords = {UAV swarm, Reinforcement learning, Persistent surveillance, Autonomous manoeuvre control, Artificial neural network (ANN)},
abstract = {Persistent surveillance in a complex unknown urban area by an unmanned aerial vehicle (UAV) swarm is a low-cost, promising future application for anti-terrorism, disaster monitoring, and battlefield situational awareness. Based on over-simplified simulated surroundings and a UAV dynamic model, a few remarkable approaches have been proposed; however, they typically rely on non-sensor-based inputs and prior knowledge on the environment or targets. To overcome these limitations, based on simulated city blocks, a two-level quasi-distributed control framework is proposed for realizing the continuous control of a UAV swarm in two defined surveillance phases. With the support of a well-trained and corrected artificial neural network (ANN) in low-level UAV manoeuvre control for target homing and collision avoidance, several preliminary high-level target allocation strategies are designed for a cooperative overall objective based on the synchronization of local surveillance data. Then, via a series of numerical simulations, an optimal high-level strategy combination is identified. Finally, the surveillance performance of this strategy combination is evaluated under various swarm sizes and UAV launching patterns. The simulation results demonstrate that the proposed control framework is applicable for UAV swarm control in the persistent surveillance of unknown urban areas.}
}
@article{BACANLI202076,
title = {Energy-efficient unmanned aerial vehicle scanning approach with node clustering in opportunistic networks},
journal = {Computer Communications},
volume = {161},
pages = {76-85},
year = {2020},
issn = {0140-3664},
doi = {https://doi.org/10.1016/j.comcom.2020.07.010},
url = {https://www.sciencedirect.com/science/article/pii/S0140366419314525},
author = {Salih Safa Bacanli and Damla Turgut},
abstract = {The opportunistic networks are challenging due to their inherent characteristics of intermittent and unreliable communication between nodes. In order to alleviate the communication issues, the unmanned aerial vehicles (UAVs) can be used for delivering packets within the opportunistic networks. This paper investigates how to leverage the UAVs in Unmanned Aerial Vehicle aided Opportunistic Networks (UAON). The UAVs are considered responsible for relaying the messages generated by the nodes on the ground. The simulation study is conducted on the real-world datasets of the nodes moving around Orlando and Korea Advanced Institute of Science & Technology (KAIST). Our proposed approach, State-based Campus Routing (SCR) with Density-based spatial clustering of applications with noise (DBSCAN), meander, random, and random spiral scanning approaches, as well as SCR and Epidemic protocols without UAV usage, have been evaluated on both datasets. The simulation metrics included the success rate, the message delay, the number of packets sent, and the distance traveled by the UAVs. SCR with DBSCAN and meander scan approaches were also tested with two UAVs using the Orlando dataset. Furthermore, spiral density and message creation frequency parameters were evaluated for SCR with DBSCAN protocol on North Carolina State University (NCSU) dataset. The simulation results showed improvements in terms of message delay and success rate when the UAVs were used in an opportunistic network setting. The proposed approach showed around 12% less total number of packets sent by the UAVs and the nodes. Similarly, the message delay distributions of the SCR with the DBSCAN achieve 90% of the message delay results, whereas the message delay distributions of random scanning form only 70% in less than an hour.}
}
@article{GRUSZCZYNSKI20191,
title = {Application of convolutional neural networks for low vegetation filtering from data acquired by UAVs},
journal = {ISPRS Journal of Photogrammetry and Remote Sensing},
volume = {158},
pages = {1-10},
year = {2019},
issn = {0924-2716},
doi = {https://doi.org/10.1016/j.isprsjprs.2019.09.014},
url = {https://www.sciencedirect.com/science/article/pii/S0924271619302254},
author = {Wojciech Gruszczyński and Edyta Puniach and Paweł Ćwiąkała and Wojciech Matwij},
keywords = {Unmanned aerial vehicle, Digital elevation model, Ground filter, Convolutional neural networks},
abstract = {The main advantage of using unmanned aerial vehicles (UAVs) is the relatively low cost of collecting data, especially when using photogrammetry on images of relatively small areas. Additionally, they have high operational flexibility and the results have a high spatial and temporal resolution. To further facilitate the use of UAVs in photogrammetry, we developed an algorithm to filter out points that indicate areas covered in low vegetation (grass, crops) from the generated point cloud. This paper presents a three-layer filtering algorithm based on convolutional neural networks (CNNs) created for this specific purpose. The modular structure of the algorithm makes it easy to expand on and improve. The proposed solution allows errors in the height of digital elevation model (DEM) points caused by the influence of vegetation to be reduced by as much as 60–70% in relation to height errors from the raw data of high grass. At the same time, the solution presented here is practical for low grass because it does not weaken the model. The algorithm significantly reduces the errors in the DEM, as well as the products derived from the DEM.}
}
@article{GEVAERT2020102117,
title = {Monitoring household upgrading in unplanned settlements with unmanned aerial vehicles},
journal = {International Journal of Applied Earth Observation and Geoinformation},
volume = {90},
pages = {102117},
year = {2020},
issn = {0303-2434},
doi = {https://doi.org/10.1016/j.jag.2020.102117},
url = {https://www.sciencedirect.com/science/article/pii/S0303243419309900},
author = {Caroline M. Gevaert and Claudio Persello and Richard Sliuzas and George Vosselman},
keywords = {Change detection algorithms, Image analysis, Unmanned aerial vehicles, Urban planning, Informal settlements},
abstract = {In-situ slum upgrading projects include infrastructural improvements such as new roads, which are perceived to improve the quality of life for the residents and encourage structural improvements at a household level. Although these physical changes are easily visible in satellite imagery, it is more difficult to track incremental improvements undertaken by the residents – which are perhaps more closely linked to the socio-economic development of the households themselves. The improved detail provided by imagery obtained from Unmanned Aerial Vehicles (UAVs) has the potential to monitor these more subtle changes in a settlement. This paper provides a framework which takes advantage of high-resolution imagery and a detailed elevation model from UAVs to detect changes in informal settlements. The proposed framework leverages expert knowledge to provide training labels for deep learning and thus avoids the cost of manual labelling. The semantic classification is then used to interpret a change mask and identify: new buildings, the creation of open spaces, and incremental roof upgrading in an informal settlement. The methodology is demonstrated on UAV imagery of an informal settlement in Kigali, Rwanda, successfully identifying changes between 2015 and 2017 with an Overall Accuracy of 95 % and correctly interpreting changes with an Overall Accuracy of 91 %. Results reveal that almost half the buildings in the settlement show visible changes in the roofing material, and 61 % of these changed less than 1m². This demonstrates the incremental nature of housing improvements in the settlement.}
}
@article{MARTINEZALPISTE2021114937,
title = {Search and rescue operation using UAVs: A case study},
journal = {Expert Systems with Applications},
volume = {178},
pages = {114937},
year = {2021},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2021.114937},
url = {https://www.sciencedirect.com/science/article/pii/S095741742100378X},
author = {Ignacio Martinez-Alpiste and Gelayol Golcarenarenji and Qi Wang and Jose Maria Alcaraz-Calero},
keywords = {Unmanned aerial vehicle, Search and rescue, Machine learning, Object detection, Human detection, YOLOv3},
abstract = {Many people go missing in the wild every year. In this paper, the Search and Rescue (SAR) mission is conducted using a novel system comprising an Unmanned Aerial Vehicle (UAV) coupled with real-time machine-learning-based object detection system embedded on a smartphone. Human detection from UAV in the wilderness is a challenging task, because of many constraints involved such as lack of computing and communication infrastructures. We proposed a novel combination of a robust architecture deployed on a smartphone and a novel Convolutional Neural Network (CNN) model to fulfil the goals of the project. Our approach achieved 94.73% of accuracy and 6.8 FPS on a smartphone. Our approach is highly portable, cost-effective, fast with high accuracy. This novel system is expected to contribute significantly to maximise chances of saving lives in the wild. This developed system has been recently launched by Police Scotland to facilitate the SAR teams to locate missing persons in Scotland wilderness.}
}
@article{LAN2020105234,
title = {Comparison of machine learning methods for citrus greening detection on UAV multispectral images},
journal = {Computers and Electronics in Agriculture},
volume = {171},
pages = {105234},
year = {2020},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2020.105234},
url = {https://www.sciencedirect.com/science/article/pii/S0168169919313857},
author = {Yubin Lan and Zixiao Huang and Xiaoling Deng and Zihao Zhu and Huasheng Huang and Zheng Zheng and Bizhen Lian and Guoliang Zeng and Zejing Tong},
keywords = {Citrus HLB detection, UAV, Multispectral images, Machine learning},
abstract = {Citrus Huanglongbing (HLB), also known as citrus greening, is the most destructive disease in the citrus industry. Detecting this disease as early as possible and eradicating the roots of HLB-infected trees can control its spread. Ground diagnosis is time-consuming and laborious. Large area monitoring method of citrus orchard with high accuracy is rare. This study evaluates the feasibility of large area detection of citrus HLB by low altitude remote sensing and commits to improve the accuracy of large-area detection. A commercial multispectral camera (ADC-lite) mounted on DJI M100 UAV(unmanned Aerial Vehicle) was used to collect green, red and near-infrared multispectral image of large area citrus orchard, a linear-stretch was performed to remove noise pixel, vegetation indices (VIs) were calculated followed by correlation analysis and feature compression using PCA (principal components analysis) and AutoEncoder to discover potential features. Several machine learning algorithms, such as support vector machine (SVM), k-nearest neighbour (kNN), logistic regression (LR), naive Bayes and ensemble learning, were compared to model the healthy and HLB-infected samples after parameter optimization. The results showed that the feature of PCA features of VIs combining with original DN (digital numbers) value generally have highest accuracy and agreement in all models, and the ensemble learning and neural network approaches had strong robustness and the best classification results (100% in AdaBoost and 97.28% in neural network) using threshold strategy.}
}
@article{KELLENBERGER2018139,
title = {Detecting mammals in UAV images: Best practices to address a substantially imbalanced dataset with deep learning},
journal = {Remote Sensing of Environment},
volume = {216},
pages = {139-153},
year = {2018},
issn = {0034-4257},
doi = {https://doi.org/10.1016/j.rse.2018.06.028},
url = {https://www.sciencedirect.com/science/article/pii/S0034425718303067},
author = {Benjamin Kellenberger and Diego Marcos and Devis Tuia},
keywords = {Animal census, Wildlife monitoring, Unmanned Aerial Vehicles, Object detection, Deep learning, Convolutional Neural Networks},
abstract = {Knowledge over the number of animals in large wildlife reserves is a vital necessity for park rangers in their efforts to protect endangered species. Manual animal censuses are dangerous and expensive, hence Unmanned Aerial Vehicles (UAVs) with consumer level digital cameras are becoming a popular alternative tool to estimate livestock. Several works have been proposed that semi-automatically process UAV images to detect animals, of which some employ Convolutional Neural Networks (CNNs), a recent family of deep learning algorithms that proved very effective in object detection in large datasets from computer vision. However, the majority of works related to wildlife focuses only on small datasets (typically subsets of UAV campaigns), which might be detrimental when presented with the sheer scale of real study areas for large mammal census. Methods may yield thousands of false alarms in such cases. In this paper, we study how to scale CNNs to large wildlife census tasks and present a number of recommendations to train a CNN on a large UAV dataset. We further introduce novel evaluation protocols that are tailored to censuses and model suitability for subsequent human verification of detections. Using our recommendations, we are able to train a CNN reducing the number of false positives by an order of magnitude compared to previous state-of-the-art. Setting the requirements at 90% recall, our CNN allows to reduce the amount of data required for manual verification by three times, thus making it possible for rangers to screen all the data acquired efficiently and to detect almost all animals in the reserve automatically.}
}
@article{XIE20202921,
title = {Optimal video communication strategy for intelligent video analysis in unmanned aerial vehicle applications},
journal = {Chinese Journal of Aeronautics},
volume = {33},
number = {11},
pages = {2921-2929},
year = {2020},
note = {SI: Emerging Technologies of Unmanned Aerial Vehicles},
issn = {1000-9361},
doi = {https://doi.org/10.1016/j.cja.2020.06.009},
url = {https://www.sciencedirect.com/science/article/pii/S1000936120302867},
author = {Yongqiang XIE and Zhongbo LI and Jin QI and Kai ZHANG and Bixuan ZHANG and Feng QI},
keywords = {Forward error correction, Intelligent video analysis, Multi-Object Tracking (MOT), Optimal strategies, UAVs, Video communication},
abstract = {For Unmanned Aerial Vehicles (UAV), the intelligent video analysis is a key technology in intelligent autonomous control, real-time navigation and surveillance. However, poor UAV wireless links would degrade the quality of video communication, leading to difficulties in video analysis. To meet the challenges of packet-loss and limited bandwidth in adverse UAV channel environments, this paper proposes a parameter optimization mechanism for UAV intelligent video analysis. In the proposed method, an Optimal Strategy Library (OSL) is designed to optimize the parameters for video encoding and forward error correction. Adapted to the packet-loss rate and bandwidth in practical UAV wireless network, the proposed OSL can facilitate the encoding of video sequences and the recovery of degraded videos with optimal performance. Experimental results demonstrate that the proposed solution can keep intelligent video analysis working efficiently with adverse UAV wireless links, and is capable of maximizing the inference accuracy of Multi-Object Tracking (MOT) algorithms in various scenarios.}
}
@article{PANG2020105766,
title = {Improved crop row detection with deep neural network for early-season maize stand count in UAV imagery},
journal = {Computers and Electronics in Agriculture},
volume = {178},
pages = {105766},
year = {2020},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2020.105766},
url = {https://www.sciencedirect.com/science/article/pii/S0168169920311376},
author = {Yan Pang and Yeyin Shi and Shancheng Gao and Feng Jiang and Arun-Narenthiran Veeranampalayam-Sivakumar and Laura Thompson and Joe Luck and Chao Liu},
keywords = {Plant population, Deep learning, RCNN, Remote sensing, UAS},
abstract = {Stand counts is one of the most common ways farmers assess plant growth conditions and management practices throughout the season. The conventional method for early-season stand count is through manual inspection, which is time-consuming, laborious, and spatially limited in scope. In recent years, Unmanned Aerial Vehicles (UAV) based remote sensing has been widely used in agriculture to provide low-altitude, high spatial resolution imagery to assist decision making. In this project, we designed a system that uses geometric descriptor information with deep neural networks to determine early-season maize stands from relatively low spatial resolution (10 to 25 mm) aerial data, which covers a relatively large area (10 to 25 hectares). Instead of detecting individual crops in a row, we process the entire row at one time, which significantly reduces the requirements for the clarity of the crops. Besides, our new MaxArea Mask Scoring RCNN algorithm could segment crop-rows out in each patch image, regardless of the terrain conditions. The robustness of our scheme was tested on data collected at two different fields in different years. The accuracy of the estimated emergence rate reached up to 95.8%. Due to the high processing speed of the system, it has the potential for real-time applications in the future.}
}
@article{MARTIN2018662,
title = {Use of unmanned aerial vehicles for efficient beach litter monitoring},
journal = {Marine Pollution Bulletin},
volume = {131},
pages = {662-673},
year = {2018},
issn = {0025-326X},
doi = {https://doi.org/10.1016/j.marpolbul.2018.04.045},
url = {https://www.sciencedirect.com/science/article/pii/S0025326X18302765},
author = {Cecilia Martin and Stephen Parkes and Qiannan Zhang and Xiangliang Zhang and Matthew F. McCabe and Carlos M. Duarte},
keywords = {Marine debris, Plastic pollution, Coastline, UAV, Machine learning},
abstract = {A global beach litter assessment is challenged by use of low-efficiency methodologies and incomparable protocols that impede data integration and acquisition at a national scale. The implementation of an objective, reproducible and efficient approach is therefore required. Here we show the application of a remote sensing based methodology using a test beach located on the Saudi Arabian Red Sea coastline. Litter was recorded via image acquisition from an Unmanned Aerial Vehicle, while an automatic processing of the high volume of imagery was developed through machine learning, employed for debris detection and classification in three categories. Application of the method resulted in an almost 40 times faster beach coverage when compared to a standard visual-census approach. While the machine learning tool faced some challenges in correctly detecting objects of interest, first classification results are promising and motivate efforts to further develop the technique and implement it at much larger scales.}
}
@article{WANG2020100620,
title = {Current technologies and challenges of applying fuel cell hybrid propulsion systems in unmanned aerial vehicles},
journal = {Progress in Aerospace Sciences},
volume = {116},
pages = {100620},
year = {2020},
issn = {0376-0421},
doi = {https://doi.org/10.1016/j.paerosci.2020.100620},
url = {https://www.sciencedirect.com/science/article/pii/S0376042120300324},
author = {Bin Wang and Dan Zhao and Weixuan Li and Zhiyu Wang and Yue Huang and Yancheng You and Sid Becker},
keywords = {Unmanned aerial vehicles, Fuel cell, Hybrid propulsion systems, Energy management, Flight factors, Propulsion efficiency},
abstract = {Recent developments in fuel cell (FC) technologies show great potential to increase flight duration of unmanned aerial vehicles (UAVs) with satisfactory fuel economy. The three most common FCs used to power UAVs are: 1) polymer electrolyte membrane FC, 2) direct methanol FC, and 3) solid oxide FC. Because of the power performance limitation of pure FC propulsion systems, hybrid propulsion systems that integrate FCs with other power sources such as batteries, supercapacitors, solar cells, and conventional internal combustion engines are recommended for UAVs. This paper reviews the current developments in FC hybrid propulsion systems applied to UAVs. The topics covered include the operating principles and characteristics of three typical FCs, issues faced by FC-powered UAVs, specific roles of other electric power sources, pure electric hybrid constructions of FC hybrid propulsion systems, hybrid engine-electric FC hybrid propulsion systems, potential impacts of various flight factors, energy management strategies of FC hybrid propulsion systems, and similarities/differences of FC hybrid propulsion systems in other vehicle applications. Finally, future trends and challenges of FC hybrid propulsion systems are discussed, which could be valuable for the development of next-generation UAVs.}
}
@article{MONDRAGON2010809,
title = {Omnidirectional vision applied to Unmanned Aerial Vehicles (UAVs) attitude and heading estimation},
journal = {Robotics and Autonomous Systems},
volume = {58},
number = {6},
pages = {809-819},
year = {2010},
note = {Omnidirectional Robot Vision},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2010.02.012},
url = {https://www.sciencedirect.com/science/article/pii/S0921889010000576},
author = {Iván F. Mondragón and Pascual Campoy and Carol Martinez and Miguel Olivares},
keywords = {Omnidirectional images, Catadioptric systems, Unmanned Aerial Vehicles (UAV), Sky segmentation},
abstract = {This paper presents an aircraft attitude and heading estimator using catadioptric images as a principal sensor for UAV or as a redundant system for IMU (Inertial Measure Unit) and gyro sensors. First, we explain how the unified theory for central catadioptric cameras is used for attitude and heading estimation, explaining how the skyline is projected on the catadioptric image and how it is segmented and used to calculate the UAV’s attitude. Then, we use appearance images to obtain a visual compass, and we calculate the relative rotation and heading of the aerial vehicle. Finally the tests and results using the UAV COLIBRI platform and the validation of them in real flights are presented, comparing the estimated data with the inertial values measured on board.}
}
@article{RENDUCHINTALA201952,
title = {A comprehensive micro unmanned aerial vehicle (UAV/Drone) forensic framework},
journal = {Digital Investigation},
volume = {30},
pages = {52-72},
year = {2019},
issn = {1742-2876},
doi = {https://doi.org/10.1016/j.diin.2019.07.002},
url = {https://www.sciencedirect.com/science/article/pii/S1742287619300799},
author = {Ankit Renduchintala and Farha Jahan and Raghav Khanna and Ahmad Y. Javaid},
keywords = {Drone forensics, Flight logs, Interactive visualization, Unmanned aerial vehicles},
abstract = {In the early 1990s, unmanned aerial vehicles (UAV) were used exclusively in military applications by various developed countries. Now with its ease of availability and affordability in the electronic device market, this aerial vehicular technology has augmented its familiarity in public and has expanded its usage to countries all over the world. However, expanded use of UAVs, colloquially known as drones, is raising understandable security concerns. With the increasing possibility of drones' misuse and their abilities to get close to critical targets, drones are prone to potentially committing crimes and, therefore, investigation of such activities is a much-needed facet. This motivated us to devise a comprehensive drone forensic framework that includes hardware/physical and digital forensics, proficient enough for the post-flight investigation of drone's activity. For hardware/physical forensics, we propose a model for investigating drone components at the crime scene. Additionally, we propose a robust digital drone forensic application with a primary focus on analyzing the essential log parameters of drones through a graphical user interface (GUI) developed using JavaFX 8.0. This application interface would allow users to extract and examine onboard flight information. It also includes a file converter created for easy and effective 3D flight trajectory visualization. We used two popular drones for conducting this research; namely, DJI Phantom 4 and Yuneec Typhoon H. The interface also provides a visual representation of the sensor recordings from which pieces of evidence could be acquired. Our research is intended to offer the forensic science community a powerful approach for investigating drone-related crimes effectively.}
}
@article{CHEN2020105708,
title = {Early detection of bacterial wilt in peanut plants through leaf-level hyperspectral and unmanned aerial vehicle data},
journal = {Computers and Electronics in Agriculture},
volume = {177},
pages = {105708},
year = {2020},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2020.105708},
url = {https://www.sciencedirect.com/science/article/pii/S0168169920311133},
author = {Tingting Chen and Weiguang Yang and Huajian Zhang and Bingyu Zhu and Ruier Zeng and Xinyue Wang and Shuaibin Wang and Leidi Wang and Haixia Qi and Yubin Lan and Lei Zhang},
keywords = { L., Bacterial wilt disease, Leaf reflectance, Unmanned aerial vehicle, Infection detection},
abstract = {Bacterial wilt (BW) caused by Ralstonia solanacearum is the most serious peanut diseases in South China. Its timely and accurate detection is important to opportunely implement disease management practices. This study aimed to establish and select the most appropriate leaf-level reflectance-based vegetation indices for BW detection and to determine whether these new indices can be used in UAV multispectral imaging for peanut BW detection. ANOVA, multilayer perception, and the reduced sampling method were used to analyze the spectral data. The most effective detection wavelengths, 730 nm and 790 nm, were used for developing new peanut BW detection indices. The 15 hyperspectral indices with highest correlation coefficients (R > 0.80) were obtained based on 46 hyperspectral indices and the BW severity results from Experiment 1. By testing the above vegetation indices at the leaf level and in UAV images using different methods and the results from Experiment 2, it was found that four of the developed indices (BWI1, BWI3, BWI4, and BWI6) performed appropriately (P < 0.01, M > 1.0), as they could distinguish between healthy and BW infected peanut plants, even if the plant presented minimal external symptoms. Our findings confirmed the potential of hyperspectral remote sensing including leaf-level and UAV images for peanut BW detection at early disease stages and discrimination of different BW severity levels based on vegetation indices derived from leaf-level reflectance. Timely BW severity determination based on our results could provide farmers with useful information to control peanut BW disease.}
}
@article{NIU2021106414,
title = {Estimating fractional vegetation cover of maize under water stress from UAV multispectral imagery using machine learning algorithms},
journal = {Computers and Electronics in Agriculture},
volume = {189},
pages = {106414},
year = {2021},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2021.106414},
url = {https://www.sciencedirect.com/science/article/pii/S0168169921004312},
author = {Yaxiao Niu and Wenting Han and Huihui Zhang and Liyuan Zhang and Haipeng Chen},
keywords = {Threshold method, Regression algorithms, UAV RGB images, Model suitability, FVC maps},
abstract = {Crop water stress is an inevitable and increasing challenge for agriculture. To improve crop water use efficiency, management of water stress and accurate estimation of crop traits were required. Among crop traits used to detect crop growth status and predict yield, fractional vegetation cover (FVC) is of great significance. We conducted studies in a maize field located in Inner Mongolia, China with different irrigation levels during 2018 and 2019 growing seasons. UAV RGB imagery was captured to investigate the effect of image sensors on thresholds obtained by the fixed-threshold method (proposed in our recent study), and to provide reference FVC (FVCUAV_R) for FVC models based on UAV multispectral imagery. Five vegetation indices (VIs), calculated from UAV multispectral imagery, and three regression algorithms (RF: random forest, ANN: artificial neural network, and MLR: multivariate linear regression) were used to build the FVC model suitable for different growing seasons, growth stages, and crop water stress. The results showed that there was a change in thresholds obtained using the fixed-threshold method based on different image sensors, but this change did not make a big difference on the accuracy of FVCUAV_R, with the R2 difference of 0.01 and the RMSE difference of 0.01. As for the three FVC regression models, RF model was the most suitable model when these models established in 2018 were used to estimate maize FVC in 2019 for different growth stages and water stress. The low estimation accuracy for high FVC levels was the reason why MLR model could not be used in the other maize growing season. This study provides a low cost and easy way to estimate maize FVC and its inter-field variability under various water status in different maize growing seasons or growth stages.}
}
@article{CASTELLANOSGALINDO2019108282,
title = {Habitat mapping of remote coasts: Evaluating the usefulness of lightweight unmanned aerial vehicles for conservation and monitoring},
journal = {Biological Conservation},
volume = {239},
pages = {108282},
year = {2019},
issn = {0006-3207},
doi = {https://doi.org/10.1016/j.biocon.2019.108282},
url = {https://www.sciencedirect.com/science/article/pii/S0006320719308092},
author = {Gustavo A. Castellanos-Galindo and Elisa Casella and Juan Carlos Mejía-Rentería and Alessio Rovere},
keywords = {Drones, Mangrove cover, Intertidal topographical complexity, Coral reef mapping, MPAs, Coastal monitoring, Tropical eastern pacific, Colombia},
abstract = {Unmanned aerial vehicles (UAVs) have the potential to be an important tool providing low-cost but sufficiently precise mapping products to support environmental management. In this study, we present possible applications of UAVs to map and monitor three representative coastal tropical habitats: mangroves, rocky shores and coral reefs. We conducted UAVs surveys in a Marine Protected Area (MPA) of the tropical eastern Pacific region to investigate the suitability and usefulness of using this tool in a remote area for a variety of management and monitoring purposes. For mangrove ecosystems, we evaluated the potential of UAV-derived data to estimate canopy cover. On an intertidal rocky shore, we evaluated the potential of UAVs to obtain a detailed relative topographic position index that can be used to correlate the distribution patterns of resident and transient fauna. Finally, we compared the standard diver-based coral reef mapping approach used at the MPA with the use of a map produced with the UAV. Our results suggest that the use of UAVs by conservation practitioners in MPAs with diverse habitats, such as in the tropics, is likely to improve the knowledge of the MPAs environments and provide highly detailed information for monitoring helping to understand the nursery function of these inter-connected tropical habitats, at a reduced cost. This tool, therefore, has the potential to support conservation measures in a more effective way.}
}
@article{WANG2020103330,
title = {Measurement for cracks at the bottom of bridges based on tethered creeping unmanned aerial vehicle},
journal = {Automation in Construction},
volume = {119},
pages = {103330},
year = {2020},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2020.103330},
url = {https://www.sciencedirect.com/science/article/pii/S0926580520309109},
author = {Hui-Feng Wang and Lei Zhai and He Huang and Li-Min Guan and Ke-Nan Mu and Gui-ping Wang},
keywords = {Instrumentation technology, Tethered creeping UAV, Feature matching, Maximum spanning tree, Multi-band blending, Image stitching},
abstract = {The detection of bridge bottom cracks is required for bridge maintenance. In order to realise the requirement of automatic real-time detection of a bridge structure, an image detection method for cracks in the bottom of the bridge structure using a tethered creeping unmanned aerial vehicle (UAV) is proposed. A high-precision unlimited endurance detection plan based on the tethered creeping UAV is designed to use for the bottom cracks of the bridge structure. The detection scheme applies a high-precision image stitching measurement algorithm for cracks at the bottom of the beam body, which is able to restore a panoramic image. All mainstream filtering methods were evaluated, and it turned out that they are practicable/applicable in various crack images of different shapes. The method is applied to the crack detection in the bottom of bridge structures to ensure the accuracy and efficiency of the system measurement. According to the actual measurement by the laboratory platform, the measurement error using this method is less than 0.1 mm, which meets the requirements of measurement automation. The results of the research represent an initial step towards developing an automatic bridge health monitoring and evaluating system.}
}
@article{MAES2019152,
title = {Perspectives for Remote Sensing with Unmanned Aerial Vehicles in Precision Agriculture},
journal = {Trends in Plant Science},
volume = {24},
number = {2},
pages = {152-164},
year = {2019},
issn = {1360-1385},
doi = {https://doi.org/10.1016/j.tplants.2018.11.007},
url = {https://www.sciencedirect.com/science/article/pii/S1360138518302693},
author = {Wouter H. Maes and Kathy Steppe},
keywords = {thermal, hyperspectral, multispectral, UAV, agriculture, drone},
abstract = {Remote sensing with unmanned aerial vehicles (UAVs) is a game-changer in precision agriculture. It offers unprecedented spectral, spatial, and temporal resolution, but can also provide detailed vegetation height data and multiangular observations. In this article, we review the progress of remote sensing with UAVs in drought stress, in weed and pathogen detection, in nutrient status and growth vigor assessment, and in yield prediction. To transfer this knowledge to everyday practice of precision agriculture, future research should focus on exploiting the complementarity of hyperspectral or multispectral data with thermal data, on integrating observations into robust transfer or growth models rather than linear regression models, and on combining UAV products with other spatially explicit information.}
}
@article{GERASTA2018661,
title = {Design of Unmanned Aerial Vehicle Based Remote Time Domain Reflectory},
journal = {IFAC-PapersOnLine},
volume = {51},
number = {28},
pages = {661-665},
year = {2018},
note = {10th IFAC Symposium on Control of Power and Energy Systems CPES 2018},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2018.11.779},
url = {https://www.sciencedirect.com/science/article/pii/S2405896318335006},
author = {Olga Joy L. Gerasta and Jonathan Maglasang and Chi-Fang Huang},
keywords = {UAV, Time Domain Reflectory},
abstract = {This manuscript presents remote Time Domain Reflectory (TDR) system to measure soil moisture through electromagnetic wave signal aboard in Unmanned Aerial Vehicle (UAV) platform. The UAV-based remote TDR design is significant in obtaining spatial resolution in different soil types. The proposed UAV software is equipped with several digital signal processing techniques. It has database structure feature to facilitate creation of machine learning dataset from different soil type. It also has capacity to automatically create interpolated model for estimation which is very significant in further training. To verify the results quantitatively, the set-up was investigated using one-way ANOVA test at 0.05 significance level applied in both onsite testing and derived model measurements. The results have shown that there is no significant difference on the mean of data measured in any point locations and the derived model, which simply confirms that the derived model is effective and the designed and developed systems worked well as intended.}
}
@article{MITTAL2020104046,
title = {Deep learning-based object detection in low-altitude UAV datasets: A survey},
journal = {Image and Vision Computing},
volume = {104},
pages = {104046},
year = {2020},
issn = {0262-8856},
doi = {https://doi.org/10.1016/j.imavis.2020.104046},
url = {https://www.sciencedirect.com/science/article/pii/S0262885620301785},
author = {Payal Mittal and Raman Singh and Akashdeep Sharma},
keywords = {Deep learning, Object detection, Unmanned aerial vehicles, Computer vision, Low-altitude aerial datasets},
abstract = {Deep learning-based object detection solutions emerged from computer vision has captivated full attention in recent years. The growing UAV market trends and interest in potential applications such as surveillance, visual navigation, object detection, and sensors-based obstacle avoidance planning have been holding good promises in the area of deep learning. Object detection algorithms implemented in deep learning framework have rapidly became a method for processing of moving images captured from drones. The primary objective of the paper is to provide a comprehensive review of the state of the art deep learning based object detection algorithms and analyze recent contributions of these algorithms to low altitude UAV datasets. The core focus of the studies is low-altitude UAV datasets because relatively less contribution was seen in the literature when compared with standard or remote-sensing based datasets. The paper discusses the following algorithms: Faster RCNN, Cascade RCNN, R-FCN etc. into two-stage, YOLO and its variants, SSD, RetinaNet into one-stage and CornerNet, Objects as Point etc. under advanced stages in deep learning based detectors. Further, one-two and advanced stages of detectors are studied in detail focusing on low-altitude UAV datasets. The paper provides a broad summary of low altitude datasets along with their respective literature in detection algorithms for the potential use of researchers. Various research gaps and challenges for object detection and classification in UAV datasets that need to deal with for improving the performance are also listed.}
}
@article{DESNITSKY2021102244,
title = {Simulation and assessment of battery depletion attacks on unmanned aerial vehicles for crisis management infrastructures},
journal = {Simulation Modelling Practice and Theory},
volume = {107},
pages = {102244},
year = {2021},
issn = {1569-190X},
doi = {https://doi.org/10.1016/j.simpat.2020.102244},
url = {https://www.sciencedirect.com/science/article/pii/S1569190X20301751},
author = {Vasily Desnitsky and Igor Kotenko},
keywords = {Battery depletion attacks, Drone, Crisis management, Simulation},
abstract = {The article discusses the problem of simulation and assessment of battery depletion attacks on unmanned aerial vehicles (UAVs) in crisis management systems. These devices operate in security sensitive infrastructures, thus, they are subject to accidental incidents or intentional ones performed by an attacker, such as natural disasters, terrorist attacks or sabotage accidents. The drones are particularly subject to battery depletion attacks, which exploit their autonomy, their physical movements in space, their wire and wireless communication channels, or even all together. The article classifies, first, various battery depletion attacks on an UAV and presents their analysis. Next, we describe how we adapted a Parrot AR.Drone 2.0 to the needs of a crisis management scenario by adding specific hardware control and monitoring units as well as made empirical studies on it. Simulation and experiments allowed us to confirm the feasibility of such attacks in practice, evaluate and compare their effect.}
}
@article{MA2018108,
title = {A saliency-based reinforcement learning approach for a UAV to avoid flying obstacles},
journal = {Robotics and Autonomous Systems},
volume = {100},
pages = {108-118},
year = {2018},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2017.10.009},
url = {https://www.sciencedirect.com/science/article/pii/S0921889017301136},
author = {Zhaowei Ma and Chang Wang and Yifeng Niu and Xiangke Wang and Lincheng Shen},
keywords = {UAV, Flying obstacle avoidance, Convolution neural networks based saliency detection, Reinforcement learning},
abstract = {Obstacle avoidance is a necessary behavior to guarantee the safety of an unmanned aerial vehicle (UAV). However, it is a challenge for the UAV to detect and avoid high-speed flying obstacles such as other UAVs or birds. In this paper, we propose a generic framework that integrates an autonomous obstacle detection module and a reinforcement learning (RL) module to develop reactive obstacle avoidance behavior for a UAV. In the obstacle detection module, we design a saliency detection algorithm using deep convolution neural networks (CNNs) to extract monocular visual cues. The algorithm imitates human’s visual detection system, and it can accurately estimate the location of obstacles in the field of view (FOV). The RL module uses an actor–critic structure that chooses the RBF neural network to approximate the value function and control policy in continuous state and action spaces. We have tested the effectiveness of the proposed learning framework in a semi-physical experiment. The results show that the proposed saliency detection algorithm performs better than state-of-the-art, and the RL algorithm can learn the avoidance behavior from the manual experiences.}
}
@article{BHOI2021103607,
title = {An Internet of Things assisted Unmanned Aerial Vehicle based artificial intelligence model for rice pest detection},
journal = {Microprocessors and Microsystems},
volume = {80},
pages = {103607},
year = {2021},
issn = {0141-9331},
doi = {https://doi.org/10.1016/j.micpro.2020.103607},
url = {https://www.sciencedirect.com/science/article/pii/S0141933120307560},
author = {Sourav Kumar Bhoi and Kalyan Kumar Jena and Sanjaya Kumar Panda and Hoang Viet Long and Raghvendra Kumar and P. Subbulakshmi and Haifa Bin Jebreen},
keywords = {Internet of Things, Unmanned Aerial Vehicle, Rice pest detection, Imagga cloud, Artificial intelligence, Confidence value},
abstract = {Rice is a very essential food for the survival of human society. Most of the people focus on production of rice for their financial gain as well as their survival in the society. Rice production means a lot, not only for the farmers, but also for the entire human society However, it is very difficult to protect the rice during and after the production due to several reasons, such as natural calamities, heavy rain fall, flood, earthquakes, damage of rice due to pests, etc. Damage of rice can occur during production and after the production due to several pests. So, it is very much essential to identify the pests in the rice so that preventive measures can be taken for its protection. In this paper, an Internet of Things (IoT) assisted Unmanned Aerial Vehicle (UAV) based rice pest detection model using Imagga cloud is proposed to identify the pests in the rice during its production in the field. The IoT assisted UAV focuses on artificial intelligence (AI) mechanism and Python programming paradigm for sending the rice pest images to the Imagga cloud and providing the pest information. The Imagga cloud detects the pest by finding the confidence values with the tags. The tag represents the object in that image. The tag with maximum confidence value and beyond threshold is selected as the target tag to identify the pest. If pest is detected then the information is sent to the owner for further actions. The proposed method can able to identify any kind of the pest that affects the rice during production. Alternatively, this paper attempts to minimize the wastage of rice during its production by monitoring the pests at regular intervals.}
}
@article{ZHANG2020106199,
title = {Monocular vision based obstacle avoidance trajectory planning for Unmanned Aerial Vehicle},
journal = {Aerospace Science and Technology},
volume = {106},
pages = {106199},
year = {2020},
issn = {1270-9638},
doi = {https://doi.org/10.1016/j.ast.2020.106199},
url = {https://www.sciencedirect.com/science/article/pii/S1270963820308816},
author = {Zhouyu Zhang and Yunfeng Cao and Meng Ding and Likui Zhuang and Jiang Tao},
keywords = {Unmanned Aerial Vehicle, Sense and Avoid, Monocular vision, Rolling horizon, Trajectory planning},
abstract = {In recent years, monocular vision has been considered as an effective Unmanned Aerial Vehicle (UAV) onboard obstacle perception solution with applications to Sense and Avoid (SAA). However, with the limitations of monocular optical measurement, monocular vision based obstacle localization ability is insufficient for collision avoidance. Therefore, an obstacle collision avoidance trajectory planning scheme is proposed in this paper with considerations of monocular optical measurement characteristic. Firstly, two obstacle localization modes are defined in this paper to assist with obstacle collision avoidance, namely relative range based Mode 1 and relative angle based Mode 2. Obstacle localization observability of Mode 2 is analyzed, and coordinate systems for obstacle localization are constructed based on the analysis results. Given coordinate systems, Orthogonal Iteration (OI) is further adopted for obstacle localization. Secondly, due to the lack of global knowledge caused by monocular vision based localization capability, a rolling horizon based safe trajectory planning method is presented. In each time segment, the trajectory is optimized with considerations of: 1) objective functions including minimum trajectory length, elapsed time and energy consumption; 2) constraints including Mode 1 and 2 based obstacle collision avoidance constrains and UAV flight constraints. Finally, simulation results indicate the proposed obstacle collision avoidance trajectory planning scheme enhances UAV safety level and can achieve favorable performance when compared with geometric based obstacle collision avoidance and collision avoidance with global knowledge.}
}
@article{MA2021103858,
title = {Deep learning for geological hazards analysis: Data, models, applications, and opportunities},
journal = {Earth-Science Reviews},
volume = {223},
pages = {103858},
year = {2021},
issn = {0012-8252},
doi = {https://doi.org/10.1016/j.earscirev.2021.103858},
url = {https://www.sciencedirect.com/science/article/pii/S0012825221003597},
author = {Zhengjing Ma and Gang Mei},
keywords = {Geological hazards, Earth observation data, Deep learning, Landslide detection, Seismic phase picking},
abstract = {As natural disasters are induced by geodynamic activities or abnormal changes in the environment, geological hazards tend to wreak havoc on the environment and human society. Recently, the dramatic increase in the volume of various types of Earth observation ‘big data’ from multiple sources, and the rapid development of deep learning as a state-of-the-art data analysis tool, have enabled novel advances in geological hazard analysis, with the ultimate aim to mitigate the devastation associated with these hazards. Motivated by numerous applications, this paper presents an overview of the advances in the utilization of deep learning for geological hazard analysis. First, six commonly available Earth observation data sources are described, e.g., unmanned aerial vehicles, satellite platforms, and in-situ monitoring systems. Second, the deep learning background and six typical deep learning models are introduced, such as convolutional neural networks and recurrent neural networks. Third, focusing on six typical geological hazards, i.e., landslides, debris flows, rockfalls, avalanches, earthquakes, and volcanoes, the deep learning applications for geological hazard analysis are reviewed, and common application paradigms are summarized. Finally, the challenges and opportunities for the application of deep learning models for geological hazard analysis are highlighted, with the aim to inspire further related research.}
}
@article{ZHONG201849,
title = {Assessment of the feasibility of detecting concrete cracks in images acquired by unmanned aerial vehicles},
journal = {Automation in Construction},
volume = {89},
pages = {49-57},
year = {2018},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2018.01.005},
url = {https://www.sciencedirect.com/science/article/pii/S0926580517311366},
author = {Xingu Zhong and Xiong Peng and Shengkun Yan and Mingyan Shen and Yinyin Zhai},
keywords = {Unmanned aerial vehicle, Image recognition, Crack width},
abstract = {An 8-rotor unmanned aerial vehicle is used as a working platform. Its motion characteristics in a hovering state are obtained using a non-contact measurement instrument, which, along with the modulation transfer function of its airborne images, indicates the reliability of the airborne images of unmanned aerial vehicles in a hovering state. By installing a laser range finder on the cradle synchronized with the camera shutter to measure the object distance, the pixel resolution of the object distance is obtained. The airborne images are then processed using the MATLAB image processing toolbox, from which the pixels of concrete cracks are extracted. Compared to a static image and direct manual measurements, the airborne image of the unmanned aerial vehicle has higher precision, indicating its wide potential applications as an alternative of the conventional inspection methods of bridge-inspection vehicle and working platforms.}
}
@article{BOUKOBERINE2019113823,
title = {A critical review on unmanned aerial vehicles power supply and energy management: Solutions, strategies, and prospects},
journal = {Applied Energy},
volume = {255},
pages = {113823},
year = {2019},
issn = {0306-2619},
doi = {https://doi.org/10.1016/j.apenergy.2019.113823},
url = {https://www.sciencedirect.com/science/article/pii/S0306261919315107},
author = {Mohamed Nadir Boukoberine and Zhibin Zhou and Mohamed Benbouzid},
keywords = {UAV, Power supply, Energy management, Swapping, Laser-beam inflight recharging, Tethered UAV},
abstract = {The interest in electric unmanned aerial vehicles (UAVs) is rapidly growing in recent years. The reason is that UAVs have abilities to perform some difficult or dangerous tasks, with high mobility, safety, and low cost. It should be noted that UAVs are revolutionizing many public services including real time monitoring, search and rescue, wildlife surveys, delivery services, wireless coverage, and precision agriculture. To increase endurance and achieve good performance, UAVs generally use a hybrid power supply system architecture. A hybrid power architecture may combine several power sources such as fuel cell, battery, solar cells, and supercapacitor. The choice of a suitable power source hybridization architecture with an optimal energy management system are therefore crucial to enable an efficient operation of advanced UAVs. In the context of battery-powered UAV platforms, including new technologies such as swapping laser-beam inflight recharging and tethering, this paper proposes a comprehensive and critical state of the art review on power supply configurations and energy management systems to find out gaps and to provide insights and recommendations for future research.}
}
@article{POOZESH2022107337,
title = {Event-triggered fractional-order sliding mode control technique for stabilization of disturbed quadrotor unmanned aerial vehicles},
journal = {Aerospace Science and Technology},
pages = {107337},
year = {2022},
issn = {1270-9638},
doi = {https://doi.org/10.1016/j.ast.2022.107337},
url = {https://www.sciencedirect.com/science/article/pii/S1270963822000116},
author = {Mohsen Poozesh and Saleh Mobayen},
keywords = {Event-triggered control, Sliding mode control, Fractional-order surface, Quadrotor, Aerial vehicle},
abstract = {In this study, an event-trigger-based fractional-order sliding mode control strategy is expanded as an implementation technique for the stabilization of quadrotor unmanned aerial vehicles in the existence of external random/time-varying disturbances. The planned control approach ensures the altitude and position tracking of the desired dynamics in the finite time, according to the Lyapunov technique. Moreover, thanks to the use of the event-triggering condition which is employed for the fractional-order sliding mode control technique, the control tasks avoid the frequent periodic execution and reduce the computing cost to achieve the best possible functionality of system. The performance of the suggested control algorithm is investigated through several numerical simulations. The tracking performances in the simulation outcomes illustrate the efficiency and applicability of the designed control procedure in comparison with other control techniques.}
}
@article{YANG2019140,
title = {Application of reinforcement learning in UAV cluster task scheduling},
journal = {Future Generation Computer Systems},
volume = {95},
pages = {140-148},
year = {2019},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2018.11.014},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X18325299},
author = {Jun Yang and Xinghui You and Gaoxiang Wu and Mohammad Mehedi Hassan and Ahmad Almogren and Joze Guna},
keywords = {Reinforcement learning, UAV cluster, Task scheduling},
abstract = {Recently, unmanned aerial vehicle (UAV) clusters have been widely used in various applications due to its high flexibility, large coverage and reliable transmission efficiency. In order to achieve the collaboration of multiple UAV tasks within a UAV cluster, we propose a task-scheduling algorithm based on reinforcement learning in this paper, which enables the UAV to adjust its task strategy automatically and dynamically using its calculation of task performance efficiency. As the UAV needs to perform real-time tasks while working in a dynamic environment without centralized control, it needs to learn tasks according to real-time data. Reinforcement learning has the ability to carry out real-time learning and decision making based on the environment, which is an appropriate and feasible method for the task scheduling of UAV clusters. From this perspective, we discuss reinforcement learning that solves the channel allocation problem existing in UAV cluster task scheduling. Finally, this paper also discusses several research problems that may be faced by the further application of UAV cluster task scheduling.}
}
@article{HU2021187,
title = {Relevant experience learning: A deep reinforcement learning method for UAV autonomous motion planning in complex unknown environments},
journal = {Chinese Journal of Aeronautics},
volume = {34},
number = {12},
pages = {187-204},
year = {2021},
issn = {1000-9361},
doi = {https://doi.org/10.1016/j.cja.2020.12.027},
url = {https://www.sciencedirect.com/science/article/pii/S100093612030594X},
author = {Zijian HU and Xiaoguang GAO and Kaifang WAN and Yiwei ZHAI and Qianglong WANG},
keywords = {Autonomous Motion Planning (AMP), Deep Deterministic Policy Gradient (DDPG), Deep Reinforcement Learning (DRL), Sampling method, UAV},
abstract = {Unmanned Aerial Vehicles (UAVs) play a vital role in military warfare. In a variety of battlefield mission scenarios, UAVs are required to safely fly to designated locations without human intervention. Therefore, finding a suitable method to solve the UAV Autonomous Motion Planning (AMP) problem can improve the success rate of UAV missions to a certain extent. In recent years, many studies have used Deep Reinforcement Learning (DRL) methods to address the AMP problem and have achieved good results. From the perspective of sampling, this paper designs a sampling method with double-screening, combines it with the Deep Deterministic Policy Gradient (DDPG) algorithm, and proposes the Relevant Experience Learning-DDPG (REL-DDPG) algorithm. The REL-DDPG algorithm uses a Prioritized Experience Replay (PER) mechanism to break the correlation of continuous experiences in the experience pool, finds the experiences most similar to the current state to learn according to the theory in human education, and expands the influence of the learning process on action selection at the current state. All experiments are applied in a complex unknown simulation environment constructed based on the parameters of a real UAV. The training experiments show that REL-DDPG improves the convergence speed and the convergence result compared to the state-of-the-art DDPG algorithm, while the testing experiments show the applicability of the algorithm and investigate the performance under different parameter conditions.}
}
@article{FERREIRA2020118397,
title = {Individual tree detection and species classification of Amazonian palms using UAV images and deep learning},
journal = {Forest Ecology and Management},
volume = {475},
pages = {118397},
year = {2020},
issn = {0378-1127},
doi = {https://doi.org/10.1016/j.foreco.2020.118397},
url = {https://www.sciencedirect.com/science/article/pii/S037811272031166X},
author = {Matheus Pinheiro Ferreira and Danilo Roberti Alves de Almeida and Daniel de Almeida Papa and Juliano Baldez Silva Minervino and Hudson Franklin Pessoa Veras and Arthur Formighieri and Caio Alexandre Nascimento Santos and Marcio Aurélio Dantas Ferreira and Evandro Orfanó Figueiredo and Evandro José Linhares Ferreira},
keywords = {Drone, DeepLabv3+, Amazon forest, Açaí, },
abstract = {Information regarding the spatial distribution of palm trees in tropical forests is crucial for commercial exploitation and management. However, spatially continuous knowledge of palms occurrence is scarce and difficult to obtain with conventional approaches such as field inventories. Here, we developed a new method to map Amazonian palm species at the individual tree crown (ITC) level using RGB images acquired by a low-cost unmanned aerial vehicle (UAV). Our approach is based on morphological operations performed in the score maps of palm species derived from a fully convolutional neural network model. We first constructed a labeled dataset by dividing the study area (135 ha within an old-growth Amazon forest) into 28 plots of 250 m × 150 m. Then, we manually outlined all palm trees seen in RGB images with 4 cm pixels. We identified three palm species: Attalea butyracea, Euterpe precatoria and Iriartea deltoidea. We randomly selected 22 plots (80%) for training and six plots (20%) for testing. We changed the plots for training and testing to evaluate the variability in the classification accuracy and assess model generalization. Our method outperformed the average producer’s accuracy of conventional patch-wise semantic segmentation (CSS) in 4.7%. Moreover, our method correctly identified, on average, 34.7 percentage points more ITCs than CSS, which tended to merge trees that are close to each other. The producer’s accuracy of A. butyracea, E. precatoria and I. deltoidea was 78.6 ± 5.5%, 98.6 ± 1.4% and 96.6 ± 3.4%, respectively. Fortunately, one of the most exploited and commercialized palm species in the Amazon (E. precatoria, a.k.a, Açaí) was mapped with the highest classification accuracy. Maps of E. precatoria derived from low-cost UAV systems can support management projects and community-based forest monitoring programs in the Amazon.}
}
@article{MATSUI2021101276,
title = {Improving the resolution of UAV-based remote sensing data of water quality of Lake Hachiroko, Japan by neural networks},
journal = {Ecological Informatics},
volume = {62},
pages = {101276},
year = {2021},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2021.101276},
url = {https://www.sciencedirect.com/science/article/pii/S1574954121000674},
author = {Kai Matsui and Hikaru Shirai and Yoichi Kageyama and Hiroshi Yokoyama},
keywords = {Remote sensing, Unmanned aerial vehicle, Neural network algorithm, Water area, Resolution aerial image},
abstract = {Remote sensing techniques for periodically collecting global data have been widely used for water quality monitoring. Satellites with a ground resolution of 10 to 30 m obtain information over broad areas, making it difficult to use them to evaluate local water quality. Methods for improving satellite data resolution allow for water quality monitoring over both wide and local areas. However, previous studies have failed to target water bodies that undergo drastic changes; moreover, they have not sufficiently examined features contributing to resolution improvement. This study proposes a resolution improvement method using a neural network, which performs learning so that the output matches the high-resolution data when the target pixel and its surrounding pixels in the low-resolution data are input. Moreover, the band ratio of data obtained from an unmanned aerial vehicle was used in the learning process as an input feature. We investigated the (i) band ratio providing highly accurate resolution improvement and (ii) application of a new resolution improvement method to the estimation of suspended solid conditions for water quality parameters. Finally, the proposed method was compared with the bicubic method for validation. The results indicate that the estimated map at the band ratio B/R in the resolution improvement data created via the proposed method can be used to greatly improve the resolution in areas with high levels of suspended solids, compared to the water quality estimation maps created using the bicubic method.}
}
@article{TROTTA2020107425,
title = {BEE-DRONES: Ultra low-power monitoring systems based on unmanned aerial vehicles and wake-up radio ground sensors},
journal = {Computer Networks},
volume = {180},
pages = {107425},
year = {2020},
issn = {1389-1286},
doi = {https://doi.org/10.1016/j.comnet.2020.107425},
url = {https://www.sciencedirect.com/science/article/pii/S1389128620311142},
author = {Angelo Trotta and Marco Di Felice and Luca Perilli and Eleonora Franchi Scarselli and Tullio Salmon Cinotti},
keywords = {Wireless sensor networks, Unmanned aerial vehicle, Wake-Up radio},
abstract = {Nowadays, Unmanned Aerial Vehicles (UAVs) represent a significant aid on scenarios where fixed, ground infrastructures are temporarily or permanently not available; this is the case of large-scale applications of the Internet of Things (IoTs), e.g. smart city and agriculture 3.0, where the UAVs can be employed as mobile data mules and gather the data from Wireless Ground Sensors (WGSs). UAV-aided wireless sensor networks (WSNs) introduce considerable advantages both in terms of performance and costs since they avoid the need of error-prone multi-hop communications, and also the installation of static gateways; at the same time, they pose formidable research challenges for their implementation, like the synchronization issue between the UAV and the WGS and the path planning, which should take into account the extremely limited flight autonomy of the UAVs. In this paper, we address both the issues above by proposing BEE-DRONES, a novel framework for large-scale, ultra low-power UAV-aided WSNs. In order to mitigate the synchronization problem, we investigate the utilization of passive Wake-up Radio (WR) technology on the WGSs, and of wireless power transfer from the UAVs: by harvesting the energy from the UAV hovering over it, the WGS is activated only for the short time required to transfer the data toward the mobile sink, while it experiences zero-consumption in sleep mode. We investigate the performance of passive WR-based WGS through real measurements, under different WGS-UAV distances and antenna orientations. Then, based on such results, we formulate the joint WGS scheduling and UAV path planning problem, where the goal is to determine the optimal trajectory of the UAVs activating the WR-based WGSs while taking into account the Value of the Sensing (VoS) as well as the total lifetime of the WSN. The original problem is transformed into a multi-commodity flow problem, and both centralized and distributed heuristics over the multi-graph are proposed. Finally, we evaluate the proposed algorithms through extensive OMNeT++ simulations; the results demonstrate the gain of BEE-DRONES in terms of extended lifetime compared to traditional, non WR-based solutions (e.g. duty-cycle), and in terms of reduced data-correlation compared to non VoS-aware path planning solutions.}
}
@article{ZEFRI2022102652,
title = {Developing a deep learning-based layer-3 solution for thermal infrared large-scale photovoltaic module inspection from orthorectified big UAV imagery data},
journal = {International Journal of Applied Earth Observation and Geoinformation},
volume = {106},
pages = {102652},
year = {2022},
issn = {0303-2434},
doi = {https://doi.org/10.1016/j.jag.2021.102652},
url = {https://www.sciencedirect.com/science/article/pii/S0303243421003597},
author = {Yahya Zefri and Imane Sebari and Hicham Hajji and Ghassane Aniba},
keywords = {Digital photogrammetry, Unmanned Aerial Vehicle, Thermography, Photovoltaics, Big imagery data, Deep learning},
abstract = {The increasing adoption of photovoltaic(PV) technology highlights the need for efficient and large-scale deployment-ready inspection solutions. In the thermal infrared imagery-based inspection framework, we develop a robust and versatile deep learning model for the classification of defect-related patterns on PV modules. The model is developed from big UAV imagery data, and designed as a layer-3 building block that can be implemented on top of any two-stage PV inspection workflow comprising: (1)An aerial Structure from Motion– MultiView Stereo (SfM-MVS) photogrammetric acquisition/processing stage, at which a georeferenced thermal orthomosaic of an inspected PV site is generated, and which enables to locate precisely defective modules on field; then (2)an instance segmentation stage that extracts the images of modules. Orthomosaics from 28 different PV sites were produced, comprising 93220 modules with various types, layouts and thermal patterns. Modules were extracted through a developed semi-automatic workflow, then labeled into six classes. Data augmentation and balancing techniques were used to prepare a highly representative and balanced deep learning-ready dataset. The dataset was used to train, cross-validate and test the developed classifier, as well as benchmarking with the VGG16 architecture. The developed model achieves the state-of-art performance and versatility on the addressed classification problem, with a mean F1-score of94.52%. The proposed three-layer solution resolves the issues of conventional imagery-based workflows. It ensures highly accurate and versatile defect detection, and can be efficiently deployed to real-world large-scale applications.}
}
@article{ALTINORS2021108325,
title = {A sound based method for fault detection with statistical feature extraction in UAV motors},
journal = {Applied Acoustics},
volume = {183},
pages = {108325},
year = {2021},
issn = {0003-682X},
doi = {https://doi.org/10.1016/j.apacoust.2021.108325},
url = {https://www.sciencedirect.com/science/article/pii/S0003682X21004199},
author = {Ayhan Altinors and Ferhat Yol and Orhan Yaman},
keywords = {UAV motors, Statistical feature extraction, Machine learning, Sound-based fault detection},
abstract = {The motors of the Unmanned Aerial Vehicle are critical parts, especially when used in applications such as military and defense systems. The fact that the brushless DC (BLDC) motors used in UAVs operate at high speed causes malfunctions. In this study, propeller, eccentric and bearing failures, which are frequently seen in UAV motors, were created. Then the fault diagnosis was made by applying the recommended method on the sound data received from the motors. Signal pre-processing, feature extraction, and machine learning methods were applied to the obtained sound dataset. Decision tree (DT), Support Vector Machines (SVM), and k Nearest Neighbor (KNN) algorithms are used for machine learning. The results have been obtained using three different UAV motors of 1400 KV, 2200 KV, and 2700 KV. For the 2200 KV motor, the accuracy of 99.16%, 99.75%, and 99.75% was calculated in DT, SVM, and KNN algorithms, respectively. The high accuracy of the proposed method indicates that the study will contribute to the studies in the relevant field. Another advantage is that the method is fast and able to work in real-time on embedded systems.}
}
@article{VILLARREAL2021100292,
title = {Workflow for capturing information and characterizing difficult-to-access geological outcrops using unmanned aerial vehicle-based digital photogrammetric data},
journal = {Journal of Industrial Information Integration},
pages = {100292},
year = {2021},
issn = {2452-414X},
doi = {https://doi.org/10.1016/j.jii.2021.100292},
url = {https://www.sciencedirect.com/science/article/pii/S2452414X21000893},
author = {Carlos Alberto Villarreal and Carlos Guillermo Garzón and Jose Pedro Mora and Julián David Rojas and Carlos Alberto Ríos},
keywords = {Photogrammetry, Unmanned aerial vehicles, Software, Geology, Geological outcrops},
abstract = {This paper aims to present a methodological approach for capturing information and characterizing difficult-to-access geological outcrops using unmanned aerial vehicle-based digital photogrammetric data, which has been growing in importance as a three-dimensional modeling method along with the use of 3D geomodelling, geological, stratigraphic and structural software packages, and specialized programmed algorithms in complex geological cases. In this way, it is possible to document rock outcrops, geological structures, stratification or foliation plans, geometry of outcropping lithologies, underground and surface mining works, karst systems, etc. The data obtained will then serve as a basis for the geomodelling of the geological structure of mineral deposits and oil and gas. Traditionally, the photogrammetry technique in Geosciences has been limited to simplifying and improving the work of surface mapping, topography, cartography, interferometry patterns, surface geomorphology and spectral analysis of high-resolution satellite images. However, currently, the evaluation of the discontinuities of a rock massif can be carried out, the structural domains with high precision, in a short time and in a complete way remotely, taking the information gathered in outcrops to other scenarios so that the work be interactive.}
}
@article{LIU202066,
title = {Unmanned aerial vehicle for internet of everything: Opportunities and challenges},
journal = {Computer Communications},
volume = {155},
pages = {66-83},
year = {2020},
issn = {0140-3664},
doi = {https://doi.org/10.1016/j.comcom.2020.03.017},
url = {https://www.sciencedirect.com/science/article/pii/S0140366419318754},
author = {Yalin Liu and Hong-Ning Dai and Qubeijian Wang and Mahendra K. Shukla and Muhammad Imran},
keywords = {Unmanned aerial vehicles, Internet of everything, Internet of things, Edge intelligence, Multi-UAV Ad Hoc networks, Trajectory optimization},
abstract = {The recent advances in information and communication technology (ICT) have further extended Internet of Things (IoT) from the sole “things” aspect to the omnipotent role of “intelligent connection of things”. Meanwhile, the concept of internet of everything (IoE) is presented as such an omnipotent extension of IoT. However, the IoE realization meets critical challenges including the restricted network coverage and the limited resource of existing network technologies. Recently, Unmanned Aerial Vehicles (UAVs) have attracted significant attentions attributed to their high mobility, low cost, and flexible deployment. Thus, UAVs may potentially overcome the challenges of IoE. This article presents a comprehensive survey on opportunities and challenges of UAV-enabled IoE. We first present three critical expectations of IoE: (1) scalability requiring a scalable network architecture with ubiquitous coverage, (2) intelligence requiring a global computing plane enabling intelligent things, (3) diversity requiring provisions of diverse applications. Thereafter, we review the enabling technologies to achieve these expectations and discuss four intrinsic constraints of IoE (i.e., coverage constraint, battery constraint, computing constraint, and security issues). We then present an overview of UAVs. We next discuss the opportunities brought by UAV to IoE. Additionally, we introduce a UAV-enabled IoE (Ue-IoE) solution by exploiting UAVs’s mobility, in which we show that Ue-IoE can greatly enhance the scalability, intelligence and diversity of IoE. Finally, we outline the future directions in Ue-IoE.}
}
@article{DENG2021,
title = {Learning-based joint UAV trajectory and power allocation optimization for secure IoT networks},
journal = {Digital Communications and Networks},
year = {2021},
issn = {2352-8648},
doi = {https://doi.org/10.1016/j.dcan.2021.07.007},
url = {https://www.sciencedirect.com/science/article/pii/S2352864821000481},
author = {Dan Deng and Xingwang Li and Varun Menon and Md Jalil Piran and Hui Chen and Mian Ahmad Jan},
keywords = {Unmanned aerial vehicle (UAV), NOMA, Reinforcement learning, Secure communications, Deep Q-learning},
abstract = {Non-Orthogonal Multiplex Access (NOMA) can be deployed in Unmanned Aerial Vehicle (UAV) networks to improve spectrum efficiency. Due to the broadcasting feature of NOMA-UAV networks, it is essential to focus on the security of the wireless system. This paper focuses on maximizing the secrecy sum-rate under the constraint of the achievable rate of the legitimate channels. To tackle the non-convexity optimization problem, a reinforcement learning-based alternative optimization algorithm is proposed. Firstly, with the help of successive convex approximations, the optimal power allocation scheme with a given UAV trajectory is obtained by using convex optimization tools. Afterwards, through plenty of explorations on the wireless environment, the Q-learning networks approach the optimal location transition strategy of the UAV, even without the wireless channel state information.}
}
@article{FU2018593,
title = {Adaptive robust backstepping attitude control for a multi-rotor unmanned aerial vehicle with time-varying output constraints},
journal = {Aerospace Science and Technology},
volume = {78},
pages = {593-603},
year = {2018},
issn = {1270-9638},
doi = {https://doi.org/10.1016/j.ast.2018.05.021},
url = {https://www.sciencedirect.com/science/article/pii/S1270963818304292},
author = {Chunyang Fu and Wei Hong and Huiqiu Lu and Lei Zhang and Xiaojun Guo and Yantao Tian},
keywords = {Multi-rotor unmanned aerial vehicle, Attitude control, Asymmetric time-varying output constraints, Asymmetric time-varying barrier Lyapunov function, Adaptive neural network, Backstepping dynamic surface control},
abstract = {Output constraints and uncertainties are the main factors that degrade the control performance of the multi-rotor unmanned aerial vehicle (MUAV). In this paper, an adaptive neural network backstepping dynamic surface control algorithm based on asymmetric time-varying Barrier Lyapunov Function is proposed for the attitude system of a novel MUAV under asymmetric time-varying output constraints, model uncertainties and external disturbances. The asymmetric time-varying Barrier Lyapunov Function, which will grow infinite when its arguments approach some limit, is introduced to keep the output under time-varying asymmetric constraints. Considering the derivation problem of the virtual control function in backstepping, the dynamic surface control is applied to simplify the algorithm. The adaptive neural network is used to approximate the dynamic model of the attitude system, and the minimal learning parameters are employed at the same time to reduce online computation burden. In order to balance out the external disturbance and further reduce the approximate error of the adaptive neural network, a robust term is designed to compensate the above negative impacts. The proposed algorithm guarantees that all the signals of the closed-loop system bounded by Lyapunov theory. Finally, some contrast simulation experiments are given to illustrate the effectiveness and superiority of the control scheme.}
}
@article{ISHENGOMA2021106124,
title = {Identification of maize leaves infected by fall armyworms using UAV-based imagery and convolutional neural networks},
journal = {Computers and Electronics in Agriculture},
volume = {184},
pages = {106124},
year = {2021},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2021.106124},
url = {https://www.sciencedirect.com/science/article/pii/S0168169921001423},
author = {Farian Severine Ishengoma and Idris A. Rai and Rutabayiro Ngoga Said},
keywords = {UAV, Faw, CNN, Maize, VGG16, VGG19, InceptionV2, MobileNetV2},
abstract = {Precision farming technologies are important for a stable supply of healthy food. Every year farmers harvest a few amounts of crops because of the pests and diseases. Automatic detection of crop health from images helps to increase yield and profit to farmers while reducing input cost and time. In this study, the aim was to precisely detect maize leaves that have been infected by fall armyworms (faw) by using automatic recognition algorithm models based on the convolution neural network (CNN) namely, VGG16, VGG19, InceptionV3 and MobileNetV2. These models were used to investigate the infected maize leaves that were captured using an unmanned aerial vehicle (UAV) remote-sensing technologies. The models were simulated with original images and modified images obtained by applying Shi-Tomas corner detection techniques. In both cases, the CNN models we considered outperformed the previously proposed models in terms of accuracy. Besides, the performance of the models trained with modified images has been significantly improved such that the accuracy of VGG16, VGG19, InceptionV3 and MobilenetV2 increased from 96%, 93.08%, 96.75% and 98.25% to 99.92%, 99.67%, 100% and 100%, respectively.}
}
@article{KHAN2019105650,
title = {Unsupervised anomaly detection in unmanned aerial vehicles},
journal = {Applied Soft Computing},
volume = {83},
pages = {105650},
year = {2019},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2019.105650},
url = {https://www.sciencedirect.com/science/article/pii/S1568494619304302},
author = {Samir Khan and Chun Fui Liew and Takehisa Yairi and Richard McWilliam},
keywords = {System health monitioring, Machine learning, Isolation forest, Fault diagnostics and isolation},
abstract = {A real-time anomaly detection solution indicates a continuous stream of operational and labelled data that must satisfy several resources and latency requirements. Traditional solutions to the problem rely heavily on well-defined features and prior supervised knowledge, where most techniques refer to hand-crafted rules derived from known conditions. While successful in controlled situations, these rules assume that good data is available for them to detect anomalies; indicating that these rules will fail to generalise beyond known scenarios. To investigate these issues, current literature is examined for solutions that can be used to detect known and unknown anomalous instances whilst functioning as an out-of-the-box approach for efficient decision-making. The applicability of the isolation forest is discussed for engineering applications using the Aero-Propulsion System Simulation dataset as a benchmark where it is shown to outperform other unsupervised distance-based approaches. Also, the authors have carried out real-time experiments on an unmanned aerial vehicle to highlight further applications of the method. Finally, some conclusions are drawn concerning its simplicity and robustness in handling diagnostic problems.}
}
@article{SILVA2019147,
title = {Cooperative unmanned aerial vehicles with privacy preserving deep vision for real-time object identification and tracking},
journal = {Journal of Parallel and Distributed Computing},
volume = {131},
pages = {147-160},
year = {2019},
issn = {0743-7315},
doi = {https://doi.org/10.1016/j.jpdc.2019.04.009},
url = {https://www.sciencedirect.com/science/article/pii/S0743731518308839},
author = {Samuel Henrique Silva and Paul Rad and Nicole Beebe and Kim-Kwang Raymond Choo and Mahesh Umapathy},
keywords = {Object tracking, Re-identification, Unmanned aerial vehicles, Deep learning, Facial recognition},
abstract = {Human tracking is an important challenge in a wide variety of applications, including but not limited to, surveillance, military operations, and disaster relief services. Unmanned Aerial Vehicles (UAVs) allow the surveying of dangerous or impassable areas from a safe distance. They also provide a machine-based capability, which may not only solve resource constraint issues, but can also improve effectiveness and efficiency in the tracking task. The effectiveness of tracking is directly related to the angle of view and degree of freedom of the camera system. In this paper, we introduce a decentralized, distributed deep learning algorithm for Real-Time Privacy-preserving Target Tracking Re-Identification (RPTT-ReID) used by cooperative UAVs in complex and adversarial environments involving motion, crowded scenes, and varied camera angles. The efficiency of RPTT-ReID makes it amenable to edge computing applications. The proposed algorithmic approach resolves shortfalls with current tracking algorithms, specifically challenges in maintaining tracking when subjects cross paths, switch identity, or are occluded in a frame of view. We demonstrate the power of our approach both in single and multi-UAV scenarios to track movable targets by extracting the facial embedding information in crowds, in order to ensure the privacy of individuals captured by the UAVs without compromising the capability for target re-identification. We validate RPTT-ReID on a challenging video dataset of crowded scenes. Our experimental evaluation shows that the proposed approach is capable of tracking and re-identifying people in crowds despite blended trajectories with minimum and maximum accuracy of 79.91 ± 0.2% and 93.27 ± 0.1% respectively. The proposed approach is 18% faster than previous methods for tracking in crowded urban environments.}
}
@article{WU202130,
title = {Composite prescribed performance control of small unmanned aerial vehicles using modified nonlinear disturbance observer},
journal = {ISA Transactions},
volume = {116},
pages = {30-45},
year = {2021},
issn = {0019-0578},
doi = {https://doi.org/10.1016/j.isatra.2021.01.032},
url = {https://www.sciencedirect.com/science/article/pii/S0019057821000343},
author = {Zhonghua Wu and Junkang Ni and Wei Qian and Xuhui Bu and Bojun Liu},
keywords = {Prescribed performance control, Nonlinear disturbance observer, UAV, Predefined-time},
abstract = {An integrated control scheme composed of modified nonlinear disturbance observer and predefined-time prescribed performance control is proposed to address the high-accuracy tracking problem of the unmanned aerial vehicles (UAVs) subjected to external mismatched disturbances. By utilizing the transformation technique that incorporates the desired performance characteristic and the newly predefined-time performance function, the original controlled system can be transformed into a new unconstrained one to achieve the fixed-time convergence of the tracking error. Then, by virtual of the transformed unconstrained system, a modified nonlinear disturbance observer (NDO) which possesses fast convergence speed is established to estimate the external disturbance. With the application of the precise estimation value to compensate the normal control design in each back-stepping step, a novel composite control scheme is constructed. The light spot of the proposed scheme is that it not only has the superior capability to attenuate unknown mismatched disturbances, but also can guarantee that the output tracking errors converge to their prescribed regions within predefined time. Finally, simulation studies verify the effectiveness of the proposed control scheme.}
}
@article{AGGARWAL2020270,
title = {Path planning techniques for unmanned aerial vehicles: A review, solutions, and challenges},
journal = {Computer Communications},
volume = {149},
pages = {270-299},
year = {2020},
issn = {0140-3664},
doi = {https://doi.org/10.1016/j.comcom.2019.10.014},
url = {https://www.sciencedirect.com/science/article/pii/S0140366419308539},
author = {Shubhani Aggarwal and Neeraj Kumar},
keywords = {Unmanned aerial vehicles (UAVs) communications, Path planning techniques, Space-air-ground integrated networks, Coverage and connectivity, Security},
abstract = {Path planning is one of the most important problems to be explored in unmanned aerial vehicles (UAVs) for finding an optimal path between source and destination. Although, in literature, a lot of research proposals exist on the path planning problems of UAVs but still issues of target location and identification persist keeping in view of the high mobility of UAVs. To solve these issues in UAVs path planning, optimal decisions need to be taken for various mission-critical operations performed by UAVs. These decisions require a map or graph of the mission environment so that UAVs are aware of their locations with respect to the map or graph. Keeping focus on the aforementioned points, this paper analyzes various UAVs path planning techniques used over the past many years. The aim of path planning techniques is not only to find an optimal and shortest path but also to provide the collision-free environment to the UAVs. It is important to have path planning techniques to compute a safe path in the shortest possible time to the final destination. In this paper, various path planning techniques for UAVs are classified into three broad categories, i.e., representative techniques, cooperative techniques, and non-cooperative techniques. With these techniques, coverage and connectivity of the UAVs network communication are discussed and analyzed. Based on each category of UAVs path planning, a critical analysis of the existing proposals has also been done. For better understanding, various comparison tables using parameters such as-path length, optimality, completeness, cost-efficiency, time efficiency, energy-efficiency, robustness and collision avoidance are also included in the text. In addition, a number of open research problems based on UAVs path planning and UAVs network communication are explored to provide deep insights to the readers.}
}
@article{CAO2021126204,
title = {Wheat yield predictions at a county and field scale with deep learning, machine learning, and google earth engine},
journal = {European Journal of Agronomy},
volume = {123},
pages = {126204},
year = {2021},
issn = {1161-0301},
doi = {https://doi.org/10.1016/j.eja.2020.126204},
url = {https://www.sciencedirect.com/science/article/pii/S1161030120302112},
author = {Juan Cao and Zhao Zhang and Yuchuan Luo and Liangliang Zhang and Jing Zhang and Ziyue Li and Fulu Tao},
keywords = {Winter wheat, Machine learning, Deep learning, Google earth engine (GEE), Yield estimation},
abstract = {To meet the challenges of climate change, increasing population and food demand, a timely, accurate and reliable estimation of crop yield at a large scale is more imperative than ever for crop management, food security evaluation, food trade and policy-making. In this study, taking the major winter wheat production regions of China as an example, we compared a traditional machine learning method (random forest, RF) and three deep learning (DL) models, including DNN (deep neural networks), 1D-CNN (1D convolutional neural networks), and LSTM (long short-term memory networks) to predict crop yields by integrating publicly available data within the GEE (Google Earth Engine) platform, including climate, satellite, soil properties, and spatial information data. The results showed that all four models could capture winter wheat yield variations in all the county-years, with R2 of recorded and simulated yields ranging from 0.83 to 0.90 and RMSE ranging from 561.18 to 959.62 kg/ha. They all performed well for winter wheat yield prediction at a county level from 2011 to 2015, with mean R2≥0.85 and RMSE ≤ 768 kg/ha. At a field level, the spatial pattern of estimated winter wheat yield could capture the spatial heterogeneity and yield differences between individual fields across a county fairly well. However, only the DNN and RF models had relatively good performance at the field level, with mean R2 values of 0.71, 0.66 and RMSE values of 1127 kg/ha and 956 kg/ha, respectively. The model comparisons showed that the performance of RF was not always worse than DL at both the county and field levels. Our findings demonstrated a scalable, simple and inexpensive framework for estimating crop yields at various scales in a timely manner and with reliable accuracy, which has important implications for crop yield forecasting, agricultural disaster monitoring, food trade policy, and food security warning.}
}
@article{LUNGU2019194,
title = {Auto-landing of fixed wing unmanned aerial vehicles using the backstepping control},
journal = {ISA Transactions},
volume = {95},
pages = {194-210},
year = {2019},
issn = {0019-0578},
doi = {https://doi.org/10.1016/j.isatra.2019.05.019},
url = {https://www.sciencedirect.com/science/article/pii/S0019057819302411},
author = {Mihai Lungu},
keywords = {UAV, Landing, Backstepping control, Dynamic inversion, Wind},
abstract = {The control of the unmanned aerial vehicles is a difficult problem because of their light weight and the strong coupling between the longitudinal and lateral modes. Motivated by this, a backstepping and dynamic inversion-based automatic landing system is designed in this paper for the flight control of a fixed wing unmanned aerial vehicle subject to wind shears, atmospheric disturbances, and wind gusts. Two backstepping-based controllers are designed for the stabilization of the attitude angles, while the controller associated to the forward velocity uses the dynamic inversion technique to obtain a constant forward velocity during all the three stages of landing. To provide an estimation of the wind shears, atmospheric turbulences, and wind gusts, a nonlinear disturbance observer is introduced in the control architecture. The lateral deviation with respect to the runway is canceled while the unmanned aerial vehicle maintains its desired trajectory slope angle. The novel adaptive automatic landing system is software implemented and validated by complex numerical simulations; the results of the numerical simulations prove the stability and robustness of the new control architecture for different initial conditions and wind type disturbances.}
}
@article{MOEINIZADE2022100233,
title = {An applied deep learning approach for estimating soybean relative maturity from UAV imagery to aid plant breeding decisions},
journal = {Machine Learning with Applications},
volume = {7},
pages = {100233},
year = {2022},
issn = {2666-8270},
doi = {https://doi.org/10.1016/j.mlwa.2021.100233},
url = {https://www.sciencedirect.com/science/article/pii/S2666827021001171},
author = {Saba Moeinizade and Hieu Pham and Ye Han and Austin Dobbels and Guiping Hu},
keywords = {Soybean relative maturity, Prediction, Deep learning, Time series, Convolutional neural networks},
abstract = {For a global breeding organization, identifying the next generation of superior crops is vital for its success. Recognizing new genetic varieties requires years of in-field testing to gather data about the crop’s yield, pest resistance, heat resistance, etc. At the conclusion of the growing season, organizations need to determine which varieties will be advanced to the next growing season (or sold to farmers) and which ones will be discarded from the candidate pool. Specifically for soybeans, identifying their relative maturity is a vital piece of information used for advancement decisions. However, this trait needs to be physically observed, and there are resource limitations (time, money, etc.) that bottleneck the data collection process. To combat this, breeding organizations are moving towards advanced image capturing devices. In this paper, we develop a robust and automatic approach for estimating the relative maturity of soybeans using a time series of UAV images. An end-to-end hybrid model combining Convolutional Neural Networks (CNN) and Long Short-Term Memory (LSTM) is proposed to extract features and capture the sequential behavior of time series data. The proposed deep learning model was tested on six different environments across the United States Results suggest the effectiveness of our proposed CNN-LSTM model compared to the local regression method. Furthermore, we demonstrate how this newfound information can be used to aid in plant breeding advancement decisions.}
}
@article{APOLOAPOLO2020126030,
title = {Deep learning techniques for estimation of the yield and size of citrus fruits using a UAV},
journal = {European Journal of Agronomy},
volume = {115},
pages = {126030},
year = {2020},
issn = {1161-0301},
doi = {https://doi.org/10.1016/j.eja.2020.126030},
url = {https://www.sciencedirect.com/science/article/pii/S1161030120300381},
author = {O.E. Apolo-Apolo and J. Martínez-Guanter and G. Egea and P. Raja and M. Pérez-Ruiz},
keywords = {Fruit detection, Machine learning, Citrus, Neural networks, Harvest, Fruit size, Yield estimation},
abstract = {Accurate and early estimation of citrus yields is important for both producers and agricultural cooperatives to be competitive and make informed decisions when selling their products. Yield estimation is key for predicting stock volumes, avoiding stock ruptures and planning harvesting operations. Visual yield estimations have traditionally been employed, resulting in inaccurate and misleading information. The main goal of this study was to develop an automated image processing methodology to detect, count and estimate the size of citrus fruits on individual trees using deep learning techniques. During 3 consecutive annual campaigns, a total of 20 trees from a commercial citrus grove were monitored using images captured from an unmanned aerial vehicle (UAV). These trees were harvested manually, and fruit sizes were measured. A Faster R-CNN Deep Learning model was trained using a custom dataset to detect oranges in the obtained images. An average standard error (SE) of 6.59 % was obtained between visual counting and the model’s fruit detection. Using the detected fruits, fruit size estimation was also performed. The promising results obtained indicate that this size estimation method can be employed for size discrimination prior to harvest. A model based on Long Short-term Memory (LSTM) was trained for yield estimation per tree and for a total yield estimation. The actual and estimated yields per tree were compared, resulting in an approximate error of SE = 4.53 % and a standard deviation of SD = 0.97 Kg. The actual total yield, the estimated total yield and the total yield estimated by an expert technician were compared. The error in the estimation by the technician was SE = 13.74 %, while the errors in the model were SE = 7.22 % and SD = 4083.58 Kg. These promising results demonstrate the potential of the present technique to provide yield estimates for citrus fruits or even other types of fruit.}
}
@article{YOUME2021361,
title = {Deep Learning and Remote Sensing: Detection of Dumping Waste Using UAV},
journal = {Procedia Computer Science},
volume = {185},
pages = {361-369},
year = {2021},
note = {Big Data, IoT, and AI for a Smarter Future},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2021.05.037},
url = {https://www.sciencedirect.com/science/article/pii/S1877050921011224},
author = {Ousmane Youme and Theophile Bayet and Jean Marie Dembele and Christophe Cambier},
keywords = {Deep Learning, Remote Sensing, Convolutional Neuron Network, Single shot Detector},
abstract = {An important success and use of Deep Learning in recent years has been in the field of image processing. Research on Deep Learning has shown that these architectures particularly convolution neuron network (CNN) can learn solutions with human-level capability for certain visual tasks. These techniques have been used in particular in remote sensing image analysis tasks, including object detection on images, image fusion, image recording, scene classification, segmentation, object-based image analysis, land use and land cover classification (LULC). In this paper we present an automatic solution for the detection of clandestine waste dumps using unmanned aerial vehicle (UAV) images in the Saint Louis area of Senegal, West Africa. This is a challenging task given the very high spatial resolution of UAV images (on the order of a few centimeters) and the extremely high level of detail, which require suitable automatic analysis methods. Our proposed method begins by 1) segmenting image into four (4) regions, which can be used as an input image 2) Reduce size of input images into 300x300x3 for the CNN entries 3) Labelling the image by determining region of interest. Next Single shot detector SSD is used to mine highly descriptive features from these datasets. The results show that the model recognizes well the areas concerned but presents difficulties on some areas lacking clear ground truths.}
}
@article{YANG2020105817,
title = {Adaptive autonomous UAV scouting for rice lodging assessment using edge computing with deep learning EDANet},
journal = {Computers and Electronics in Agriculture},
volume = {179},
pages = {105817},
year = {2020},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2020.105817},
url = {https://www.sciencedirect.com/science/article/pii/S0168169920319542},
author = {Ming-Der Yang and Jayson G. Boubin and Hui Ping Tsai and Hsin-Hung Tseng and Yu-Chun Hsu and Christopher C. Stewart},
keywords = {Autonomous UAV, Deep learning, Edge computing, Rice lodging, Adaptive},
abstract = {Rice is a globally important crop that will continue to play an essential role in feeding our world as we grapple with climate change and population growth. Lodging is a primary threat to rice production, decreasing rice yield, and quality. Lodging assessment is a tedious task and requires heavy labor and a long duration due to the vast land areas involved. Newly developed autonomous crop scouting techniques have shown promise in mapping crop fields without any human interaction. By combining autonomous scouting and lodged rice detection with edge computing, it is possible to estimate rice lodging faster and at a much lower cost than previous methods. This study presents an adaptive crop scouting mechanism for Autonomous Unmanned Aerial Vehicles (UAV). We simulate UAV crop scouting of rice fields at multiple levels using deep neural networks and real UAV energy profiles, focusing on areas with high lodging. Using the proposed method, we can scout rice fields 36% faster than conventional scouting methods at 99.25% accuracy.}
}
@article{ZHANG2019215,
title = {New research methods for vegetation information extraction based on visible light remote sensing images from an unmanned aerial vehicle (UAV)},
journal = {International Journal of Applied Earth Observation and Geoinformation},
volume = {78},
pages = {215-226},
year = {2019},
issn = {0303-2434},
doi = {https://doi.org/10.1016/j.jag.2019.01.001},
url = {https://www.sciencedirect.com/science/article/pii/S0303243418306305},
author = {Xianlong Zhang and Fei Zhang and Yaxiao Qi and Laifei Deng and Xiaolong Wang and Shengtian Yang},
keywords = {Iterative threshold method, Unmanned aerial vehicle (UAV), Visible light images, Vegetation information extraction, Construction of NGRVI},
abstract = {Currently, many remote sensing images of the vegetation index being used have disadvantages, because of high cost, long cycles, and low resolution. Thus, it is difficult to extract and analyse vegetation information in the field. A vegetation index based on visible light images from an unmanned aerial vehicle (UAV) has the advantages of fast image acquisition and high ground resolution, which is superior to traditional remote sensing. However, the vegetation coverage in arid and semi-arid areas is low, and the soil background has a great impact on the common visible vegetation index. The real-time extraction and analysis of the index vegetation information can easily result in big errors. Therefore, according to the construction principle of the green-red vegetation index (GRVI) and modified green-red vegetation index (MGRVI), a new green-red vegetation index (NGRVI) is proposed in this study. First, the newly constructed index and several published indices are used to extract visible light images and generate greyscale images for each of the visible light vegetation indices. Then, the threshold of vegetation and non-vegetation pixel classification is established according to the method of iterative threshold, and the optimal threshold is used to extract the vegetation information from the greyscale images of each of the visible light vegetation indices. Finally, the accuracy difference in vegetation information extraction between the newly constructed and several published indices is compared. The results show that the precision of vegetation information extraction by NGRVI is higher than that of other visible light band vegetation indices; the kappa coefficient is 0.82, and the classification accuracy reaches near-complete consistency. To verify the accuracy of the NGRVI, one image from the same period was selected, and the vegetation information was extracted using the same method. The NGRVI based on UAV visible light images can accurately extract the vegetation information in arid and semi-arid areas, and the extraction accuracy can reach more than 90%. To summarize, NGRVI can accurately and effectively reflect the vegetation information in arid and semi-arid areas and become an important technical means for retrieving biological and physical parameters using visible light images.}
}
@article{CHEN2021102913,
title = {Automated crack segmentation in close-range building façade inspection images using deep learning techniques},
journal = {Journal of Building Engineering},
volume = {43},
pages = {102913},
year = {2021},
issn = {2352-7102},
doi = {https://doi.org/10.1016/j.jobe.2021.102913},
url = {https://www.sciencedirect.com/science/article/pii/S2352710221007713},
author = {Kaiwen Chen and Georg Reichard and Xin Xu and Abiola Akanmu},
keywords = {Facade cracks, UAV-Images, CNN, UNet, Classification, Segmentation},
abstract = {Nowadays, unmanned aerial vehicles (UAVs) are frequently used for periodic visual inspection of building envelopes to detect unsafe conditions or vulnerable damages. Inspection practitioners have to manually examine the large amounts of high-resolution images collected by UAVs to identify anomalies or damages on building facades for reporting and repairs. The computer vision and deep learning technologies have emerged as promising solutions to automate the image-based inspection process. However, for the detection of façade cracks from UAV-captured images, existing deep learning solutions may not perform well due to the complicated background noises caused by different façade components and materials. Towards that end, this paper proposed a two-step deep learning method for the automated detection of façade cracks from UAV-captured images. In the first step, a convolutional neural network (CNN) model was designed and trained on 26,177 images to classify images in a patch-level size of 128 × 128 pixels into crack or non-crack. In the second step, a U-Net neural network model was trained on 2870 image sets to segment crack pixels within those patches classified as cracks. Experimental results show a high performance of 94% and 96% precision, 94% and 95% recall, and 94% and 96% F1-scores was achieved by the CNN model and the U-Net model respectively. The experimental results proved that the two-step method can improve the reliability and efficiency of detecting and differentiating façade cracks from complicated façade noises. The proposed method can also be extended to detect other types of façade anomalies (e.g., corrosion and joint failures), thus facilitating a comprehensive assessment of façade conditions for better decision-making for the maintenance of building facades during its service life.}
}
@article{LIU2019106493,
title = {Evolution-algorithm-based unmanned aerial vehicles path planning in complex environment},
journal = {Computers & Electrical Engineering},
volume = {80},
pages = {106493},
year = {2019},
issn = {0045-7906},
doi = {https://doi.org/10.1016/j.compeleceng.2019.106493},
url = {https://www.sciencedirect.com/science/article/pii/S0045790618328416},
author = {Xiaolei Liu and Xiaojiang Du and Xiaosong Zhang and Qingxin Zhu and Mohsen Guizani},
keywords = {UAV, Dynamic planning, Path planning, Evolution algorithm},
abstract = {With the wide application of Unmanned Aerial Vehicles (UAVs) in production and life, more and more attention has been paid to the autonomous track planning of UAVs. When UAV path planning algorithm is dealing with flying in an unknown complex environment, there are some problems, such as inability to dynamically plan the track and slow speed to calculate the path. This paper proposes a dynamic path planning based on an improved evolutionary optimization algorithm. The experimental results show that the evolutionary optimization algorithm based on improved t-distribution can effectively deal with the problems of high computational complexity and low search efficiency encountered in UAV dynamic track planning. It has strong robustness and can dynamically plan the appropriate track.}
}
@article{GAO2019916,
title = {Diagnostic Feed Values of Natural Grasslands Based on Multispectral Images Acquired by Small Unmanned Aerial Vehicle},
journal = {Rangeland Ecology & Management},
volume = {72},
number = {6},
pages = {916-922},
year = {2019},
issn = {1550-7424},
doi = {https://doi.org/10.1016/j.rama.2019.06.005},
url = {https://www.sciencedirect.com/science/article/pii/S1550742418302823},
author = {Rui Gao and Qingming Kong and Hongguang Wang and Zhongbin Su},
keywords = {feed value, grassland, UAV, vegetation index},
abstract = {Grasslands are the largest renewable source of terrestrial chlorophytes. Furthermore, grasslands can be both fiber sources and the primary metabolizable energy source for ruminants. Therefore, rapid, accurate, and large-scale monitoring of grassland ecosystems is important to provide spatial information on forage quality control and rangeland management. In this experiment, 100 grassland sites were randomly selected in two study areas. A multiaxis unmanned aerial vehicle (UAV) made 26 flights over those areas to capture spectral images during August 2016, which enabled the acquisition of vegetation index values of the grassland sites. Next, grassland plots were harvested and the nutritional composition of the grass was determined. After selecting the most sensitive spectral information for each nutritional value, retrieval models for grassland nutrition were constructed. Predictor variables of the models were then tested on the samples. The results demonstrate that there are correlations between nutritional values and vegetation indices. The predicted values of the coefficient of determination (R2-P) and root mean square error (RMSE) for dry matter (DM) were 0.676% and 4.719%. The same values for crude protein (CP) were 0.653% and 1.361%. The R2-P and RMSE values for in vitro DM digestibility (IVDMD) prediction models were weak, but they could be improved by more sensitive wavelengths and improved mathematical models to fit the data. The results show that UAV remote sensing can be used to estimate the feed values of natural grassland and that this sensing approach provides a rapid, flexible, and efficient method of estimating feed values. Although the prediction models for nutritional values need to be improved, they still opened perspectives for the use of UAV-based remote sensing in rangeland management and grassland husbandry.}
}
@article{CORTE2020105815,
title = {Forest inventory with high-density UAV-Lidar: Machine learning approaches for predicting individual tree attributes},
journal = {Computers and Electronics in Agriculture},
volume = {179},
pages = {105815},
year = {2020},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2020.105815},
url = {https://www.sciencedirect.com/science/article/pii/S0168169920308838},
author = {Ana Paula Dalla Corte and Deivison Venicio Souza and Franciel Eduardo Rex and Carlos Roberto Sanquetta and Midhun Mohan and Carlos Alberto Silva and Angelica Maria Almeyda Zambrano and Gabriel Prata and Danilo Roberti {Alves de Almeida} and Jonathan William Trautenmüller and Carine Klauberg and Anibal {de Moraes} and Mateus N. Sanquetta and Ben Wilkinson and Eben North Broadbent},
keywords = {Forest variables, Support Vector Regression, Random forest, Artificial Neural Networks, Extreme Gradient Boosting, Forest attributes},
abstract = {The high dimensionality of data generated by Unmanned Aerial Vehicle(UAV)-Lidar makes it difficult to use classical statistical techniques to design accurate predictive models from these data for conducting forest inventories. Machine learning techniques have the potential to solve this problem of modeling forest attributes from remotely sensed data. This work tests four different machine learning approaches - namely Support Vector Regression, Random Forest, Artificial Neural Networks, and Extreme Gradient Boosting - on high-density GatorEye UAV-Lidar point clouds for indirect estimation of individual tree dendrometric metrics (field-derived) such as diameter at breast height, total height, and timber volume. A total of 370 trees had their dbh and height measured for validation purposes. Using LAStools we generated normalized Light Detection and Ranging (Lidar) point clouds and created a raster canopy height model at a 0.5x0.5 m spatial resolution following the construction of a digital terrain model and a digital surface model. The R package ‘lidR’ was set with the functions tree_detection (local maximum filter algorithm) and lastrees. Subsequently, we applied the function tree_metrics to extract individual metrics. Machine learning techniques were applied to the derived metrics to estimate dendrometric field measures. The machine learning models (MLM) with optimal hyperparameters showed similar predictive performances for modeling the variables diameter, height, and volume. All models had a rRMSE below 15% (for diameter at breast height), 9% (for height) and 29% (for volume). The Support Vector Regression algorithm showed the best performance. Our work demonstrates that all tested machine learning models are adequate and robust to handle the high dimensionality of UAV-Lidar data for the estimation of individual attributes, with Support Vector Regression model being the best performer in terms of minimal error rates.}
}
@article{KHALLAF2021103760,
title = {Classification and analysis of deep learning applications in construction: A systematic literature review},
journal = {Automation in Construction},
volume = {129},
pages = {103760},
year = {2021},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2021.103760},
url = {https://www.sciencedirect.com/science/article/pii/S0926580521002119},
author = {Rana Khallaf and Mohamed Khallaf},
keywords = {Systematic literature review, Deep learning, Construction, Damage detection},
abstract = {In recent years, the construction industry has experienced an expansion in the multitude of projects and emergent information. With the advent of deep learning, new opportunities have emerged for utilizing this vast amount of data to solve construction-related issues. While the use of deep learning has been increasing in construction, there has been no review on these applications to date. Therefore, this paper presents a Systematic Literature Review on the use of deep learning applications in construction. A total of 80 journal papers were identified and analyzed. Among these papers, six application-based topics were identified: equipment tracking, crack detection, construction work management, sewer assessment, 3D point cloud enhancement, and miscellaneous topics. Analysis shows that deep learning has been beneficial in leveraging data in areas such as crack detection and segmentation of infrastructure and sewers; equipment and worker detection and; and analysis and reporting on construction-related operations. Additionally, a discussion of the various deep learning techniques is provided as well as a contrast between deep learning, machine learning, and artificial intelligence.}
}
@article{DIAZGONZALEZ2022108517,
title = {Machine learning and remote sensing techniques applied to estimate soil indicators – Review},
journal = {Ecological Indicators},
volume = {135},
pages = {108517},
year = {2022},
issn = {1470-160X},
doi = {https://doi.org/10.1016/j.ecolind.2021.108517},
url = {https://www.sciencedirect.com/science/article/pii/S1470160X21011821},
author = {Freddy A. Diaz-Gonzalez and Jose Vuelvas and Carlos A. Correa and Victoria E. Vallejo and D. Patino},
keywords = {Remote sensing, Machine learning, Soil quality indicators, Agricultural systems},
abstract = {The demand for food based on intensive agriculture has decreased soil quality, posing great challenges such as increasing agricultural productivity and promoting environmental sustainability. Thus, researchers have focused on developing models for estimating soil quality based on artificial intelligence techniques for the processing of multidimensional data from agro-industrial systems, which provide useful information for farmers about soil management and crop conditions. However, a model for the application of these new technologies in medium and low-scale agricultural systems has not been identified. Therefore, a review of recent studies of crop yield prediction based on the estimation of chemical, physical, and biological soil quality indicators (SQI), which incorporate different machine learning (ML) techniques to process data from remote sensing (RS) systems, is presented. The advantages and disadvantages are also analyzed for: SQI estimates at regional and local scale, spectral bands used for analysis of plowed soils (bare soils) of cultivation plots, selection of minimun data set (MDS), use of unmanned aerial vehicle (UAV) and satellite platforms, data pre-processing, and selection of ML algorithms for processing biological systems databases (agro-industrial systems). Finally, we present a model to help estimate soil quality in agricultural systems at a local scale, based on ML to process RS data, in the model the inputs to the ML unit come from four different class data sets (RS, SQI, environmental data and crop management data). Crop management uses the production of the ML unit to adjust agricultural management practices and therefore improve crop yield.}
}
@article{WANG2019107665,
title = {Landscape-level vegetation classification and fractional woody and herbaceous vegetation cover estimation over the dryland ecosystems by unmanned aerial vehicle platform},
journal = {Agricultural and Forest Meteorology},
volume = {278},
pages = {107665},
year = {2019},
issn = {0168-1923},
doi = {https://doi.org/10.1016/j.agrformet.2019.107665},
url = {https://www.sciencedirect.com/science/article/pii/S0168192319302734},
author = {Haozhou Wang and Dong Han and Yue Mu and Lina Jiang and Xueling Yao and Yongfei Bai and Qi Lu and Feng Wang},
keywords = {Dryland vegetation, Machine learning, Decision tree model, Digital orthophoto map, Otindag sandy land, Semi-arid ecosystem, Classification and regression tree ()},
abstract = {The change of fraction vegetation cover (FVC) is the key ecological index for vegetation dynamics of dryland ecosystem. However, it is difficult to directly map woody vegetation and herbaceous vegetation in the dryland from the satellite images due to the mixture of their distribution at small scale. Emerging UAV remote sensing provides a good opportunity to capture and quantify the distribution of the sparse vegetation in the drylands ecosystem. In this study, we proposed a new method to classify woody vegetation and herbaceous vegetation and calculate their FVC based on the high-resolution orthomosaic generated from UAV images by the machine learning algorithm of classification and regression tree (CART). This proposed method was validated and evaluated by visual interpretation, the detailed ground measurement dataset of 4832 trees and 18,798 shrubs and three popular machine learning algorithms of Support Vector Machine(SVM), Random Forest(RF), Gradient Boosting Decision Tree(GBDT). The overall assessments showed good overall accuracy (0.78), average accuracy (0.76), and the Kappa coefficient (0.64). The FVC of woody vegetation calculated from orthomosaic agreed well with that estimated from ground measurements. Both group of FVC have a stable linear relationship over different spatial scales. The proposed method showed higher efficiency of 166%, 111% and 290% than SVM, RF, GBDT respectively. A new optimized model was developed to reduce the workload of vegetation investigation and to design more efficient sampling strategies. The proposed method was incorporated into an interactive web-based software “UAV- High Resolution imagery Analysis Platform” (UAV-HiRAP, http://www.uav-hirap.org). Our study demonstrates that UAV-HiRAP combined with UAV platform can be a powerful tool to classify woody vegetation and herbaceous vegetation and calculate their FVC for sparse vegetation in the drylands. The new optimization model will inspire researchers to design more effective sampling strategies for future field investigation.}
}
@article{KERKECH2020105446,
title = {Vine disease detection in UAV multispectral images using optimized image registration and deep learning segmentation approach},
journal = {Computers and Electronics in Agriculture},
volume = {174},
pages = {105446},
year = {2020},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2020.105446},
url = {https://www.sciencedirect.com/science/article/pii/S016816991932558X},
author = {Mohamed Kerkech and Adel Hafiane and Raphael Canals},
keywords = {Unmanned aerial vehicle (UAV), Image registration, Convolutional neural network, Precision agriculture, Disease mapping},
abstract = {One of the major goals of tomorrow’s agriculture is to increase agricultural productivity but above all the quality of production while significantly reducing the use of inputs. Meeting this goal is a real scientific and technological challenge. Smart farming is among the promising approaches that can lead to interesting solutions for vineyard management and reduce the environmental impact. Automatic vine disease detection can increase efficiency and flexibility in managing vineyard crops, while reducing the chemical inputs. This is needed today more than ever, as the use of pesticides is coming under increasing scrutiny and control. The goal is to map diseased areas in the vineyard for fast and precise treatment, thus guaranteeing the maintenance of a healthy state of the vine which is very important for yield management. To tackle this problem, a method is proposed here for Mildew disease detection in vine field using a deep learning segmentation approach on Unmanned Aerial Vehicle (UAV) images. The method is based on the combination of the visible and infrared images obtained from two different sensors. A new image registration method was developed to align visible and infrared images, enabling fusion of the information from the two sensors. A fully convolutional neural network approach uses this information to classify each pixel according to different instances, namely, shadow, ground, healthy and symptom. The proposed method achieved more than 92% of detection at grapevine-level and 87%at leaf level, showing promising perspectives for computer aided disease detection in vineyards.}
}
@article{LV2021108366,
title = {Beyond 5G for digital twins of UAVs},
journal = {Computer Networks},
volume = {197},
pages = {108366},
year = {2021},
issn = {1389-1286},
doi = {https://doi.org/10.1016/j.comnet.2021.108366},
url = {https://www.sciencedirect.com/science/article/pii/S1389128621003534},
author = {Zhihan Lv and Dongliang Chen and Hailing Feng and Ranran Lou and Huihui Wang},
keywords = {Unmanned aerial vehicle, B5G, Deep learning, Coordinated multi-point transmission, Physical layer security, Digital twins},
abstract = {The purpose is to explore the application effects and limitations of Unmanned Aerial Vehicle (UAV) in 5G/B5G (Beyond 5G) mobile and wireless communication. Based on 5Gcommunication, the deep learning (DL) algorithm is introduced to construct the UAV Digital Twins (DTs) communication channel model based on DL. The Coordinated Multi-point Transmission (COMP) technology is adopted to study the interference suppression of UAVs. The key algorithm in the physical layer security is employed to ensure information communication security. Finally, the model constructed is simulated and analyzed. The transmission error rates and transmission estimation accuracy of several algorithms, including the proposed algorithm and ordinary Deep Neural Networks (DNNs), are compared under different Signal-to-Noise Ratios (SNRs). Results find that the convergence speed and convergence effect of the proposed algorithm has prominent advantages, presenting strong robustness; the proposed algorithm's estimation accuracy is about 150 times higher than the traditional algorithms. Further analysis reveals that the proposed algorithm's accuracy reaches 82.39%, which increases by at least 3.2% than other classic machine algorithms. The indicators of Precision, Recall, and F1 are compared as well. Apparently, the Precision, Recall, and F1 values of the proposed algorithm are the highest, while the transmission delay is the smallest. Therefore, the constructed UAV DTs wireless communication channel model has strong robustness and further reduces UAV limitations, providing a reference for improving UAV system performance in the later stage.}
}
@article{KHOSHBORESHMASOULEH2019172,
title = {Development and evaluation of a deep learning model for real-time ground vehicle semantic segmentation from UAV-based thermal infrared imagery},
journal = {ISPRS Journal of Photogrammetry and Remote Sensing},
volume = {155},
pages = {172-186},
year = {2019},
issn = {0924-2716},
doi = {https://doi.org/10.1016/j.isprsjprs.2019.07.009},
url = {https://www.sciencedirect.com/science/article/pii/S0924271619301765},
author = {Mehdi {Khoshboresh Masouleh} and Reza Shah-Hosseini},
keywords = {UAV-based thermal infrared imagery, Ground vehicle, Semantic segmentation, Deep learning, Gaussian-Bernoulli Restricted Boltzmann Machine},
abstract = {Real-time unmanned aerial vehicles (UAVs)-based thermal infrared images processing, due to high spatial resolution and knowledge of the various infrared radiant energy level distribution of solid bodies, has important applications such as monitoring and control of the various phenomena in different natural situations. One of these applications is monitoring the ground vehicles in cities by using detection or semantic segmentation of them in the thermal images. In this research, our purpose is to improve the performance of deep learning combined model by using Gaussian-Bernoulli Restricted Boltzmann Machine (GB-RBM) specifications for the segmentation of the ground vehicles from UAV-based thermal infrared imagery. The proposed model is studied in three steps. First, designing the proposed model by using an encoder-decoder structure and addition of extracted features from convolutional layers and restricted Boltzmann machine in the network. Second, the implementation of the research goals on four sets of UAV-based thermal infrared imagery named NPU_CS_UAV_IR_DATA that was collected from some streets of China by using FLIR TAU2 thermal infrared sensor in 2017. Finally, analyzing the performance of the proposed model by using five state-of-the-art models in semantic segmentation. The results evaluated the performance of the proposed model as a robust model with the average precision and average processing time of approximately 0.97, and 19.73 s for all datasets, respectively.}
}
@article{NOVAK2020160,
title = {Use of Unmanned Aerial Vehicles in Aircraft Maintenance},
journal = {Transportation Research Procedia},
volume = {51},
pages = {160-170},
year = {2020},
note = {INAIR 2020 - CHALLENGES OF AVIATION DEVELOPMENT},
issn = {2352-1465},
doi = {https://doi.org/10.1016/j.trpro.2020.11.018},
url = {https://www.sciencedirect.com/science/article/pii/S2352146520308711},
author = {Andrej Novák and Alena Novák Sedláčková and Martin Bugaj and Branislav Kandera and Tomasz Lusiak},
keywords = {UAV, Smart Hangar, Aircraft maintenance},
abstract = {The article deals with the issue of unmanned aerial vehicles, and their use in aircraft maintenance as a tool for visual inspection of the airframe. There are quite a few factors in the maintenance process that can affect its quality and safety. In the process of reducing the risk of human influence in aircraft maintenance, it is necessary to set up tools and processes so that human factor failure can be eliminated as much as possible. Example of such a concept can be a "Smart Hangar" system, which introduces digitization into processes in a certified commercial aircraft Maintenance, Repair and Overhaul organization (MRO) as well as in a Continuing Airworthiness Management Organization (CAMO). The article discusses the problem of using UAVs in the maintenance process and identifies the risks associated with this activity. On a practical example, it discusses the advantages and disadvantages of introducing UAVs in the maintenance process in small MRO organizations.}
}
@article{MALBOUBI2021107785,
title = {PAveMENT: a framework for the intelligent and safe navigation of unmanned aerial vehicles over optimal PAths in MobilE NeTworks},
journal = {Computer Networks},
volume = {186},
pages = {107785},
year = {2021},
issn = {1389-1286},
doi = {https://doi.org/10.1016/j.comnet.2020.107785},
url = {https://www.sciencedirect.com/science/article/pii/S1389128620313591},
author = {Mehdi Malboubi and Abhijeet Bhorkar and Frank Jiang},
keywords = {Unmanned aerial vehicle, Drone, Path planning, Navigation, LTE networks},
abstract = {The demand for using Unmanned Aerial Vehicles (UAV) is increasing in different applications, such as delivery, environmental monitoring, media, and wireless internet access. In these applications, UAVs are enabled by a cellular device and act as aerial users that need to be served by the underlying mobile-wireless network. The large-scale and low-cost usage of UAVs in such applications/services requires a framework that enables the safe and optimal navigation of UAVs over wide areas. Current cellular mobile networks have the infrastructure and the capability for implementing such frameworks. In contrast to other related work [6,15], in this paper, we propose a framework, called PAveMENT, that provides safe and optimal paths for navigating UAVs where: a) they experience reliable and high-quality communications with the underlying cellular network; b) UAVs cannot fly over no-flying zones and interrupt public/private services, and c) UAVs have minimal impact on the ground users of the mobile network. These are important factors from the perspective of a cellular service provider, as the main enabler for navigating UAVs over wide areas. In this framework, providing safe-optimal paths are performed by constructing a graph around the local area of interest to fly over and computing a least-cost path from the source to the destination. In addition, unlike other related work, we use real network performance indicators, and practical path-loss models with proprietary operational parameters to evaluate the performance of this framework.}
}
@article{YU2021106857,
title = {A knee-guided differential evolution algorithm for unmanned aerial vehicle path planning in disaster management},
journal = {Applied Soft Computing},
volume = {98},
pages = {106857},
year = {2021},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2020.106857},
url = {https://www.sciencedirect.com/science/article/pii/S156849462030795X},
author = {Xiaobing Yu and Chenliang Li and Gary G. Yen},
keywords = {Path planning, Multiobjective optimization problem, Knee solution, Differential evolution},
abstract = {Unmanned aerial vehicles are instrumental in monitoring and analyzing information and searching for people in disaster relief scenarios. In this paper, path planning is constructed as a multiobjective optimization problem with constraints in a three-dimensional terrain disaster scenario. The objective functions involve the distance and risk of the path, which are calculated based on Bézier theory. The constraints include the turning angle and flight altitude. To solve this problem in an effective and efficient manner, a differential evolution algorithm that is based solely on the knee point is proposed, in which the knee solution would guide the search direction of the algorithm. According to the minimal Manhattan distance approach, the algorithm can quickly identify an optimal solution to generating a smooth path for decision-makers. Experimental results have confirmed the superiority of the proposed algorithm, and the rankings of the minimal Manhattan distance approach are consistent with multicriteria decision-making methods.}
}
@article{JAGANNATHAN2021101412,
title = {Deep learning for the prediction and classification of land use and land cover changes using deep convolutional neural network},
journal = {Ecological Informatics},
volume = {65},
pages = {101412},
year = {2021},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2021.101412},
url = {https://www.sciencedirect.com/science/article/pii/S157495412100203X},
author = {J. Jagannathan and C. Divya},
keywords = {Land use, Land cover, Changes, Satellite, Encoding, Decoding, HEVGG, Classification, Prediction},
abstract = {The importance of timely and accurate information about the land resources and the natural resources increased rapidly. Due to the impact of urbanization, the we face hasty climatic change. To mitigate the urban heat island in the developed and developing cities, a very accurate land cover classification has to be developed. Through which we can identify the changes in build-up areas, water bodies and vegetation index. In this paper, a hybrid hot encoding VGG19 deep learning method has been proposed. And a transfer learning method has been used to transfer the training data trained by the RestNet50 method to the proposed HGVGG19 method. The satellite images and aerial images are collected from various sources and classified based on the features. And the image dataset has been pre-processed using the image augmentation technique. Through which the image has been resized and processed for training it with the proposed mode. The categorical data cannot be processed directly, so we use one hot encoding method to find the borders of the class. Then the data has been trained using VGG19 method. Then using the MLR classifier we classify the images and using decision tree the class prediction has been predicted. After testing the model an accuracy of 98.5% has been achieved. Using the proposed algorithm, the analysis has been made with the historical images of many regions. And eight different class values have been obtained and stored as the textual data. Using the data, the land cover changes and the prediction of the land cover has been obtained with an accuracy of 98.5%.}
}
@article{YAN2020103594,
title = {Fixed-Wing UAVs flocking in continuous spaces: A deep reinforcement learning approach},
journal = {Robotics and Autonomous Systems},
volume = {131},
pages = {103594},
year = {2020},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2020.103594},
url = {https://www.sciencedirect.com/science/article/pii/S0921889020304346},
author = {Chao Yan and Xiaojia Xiang and Chang Wang},
keywords = {Fixed-wing UAV, Flocking, Reinforcement learning, Actor–critic},
abstract = {Fixed-Wing UAVs (Unmanned Aerial Vehicles) flocking is still a challenging problem due to the kinematics complexity and environmental dynamics. In this paper, we solve the leader–followers flocking problem using a novel deep reinforcement learning algorithm that can generate roll angle and velocity commands by training an end-to-end controller in continuous state and action spaces. Specifically, we choose CACLA (Continuous Actor–Critic Learning Automation) as the base algorithm and we use the multi-layer perceptron to represent both the actor and the critic. Besides, we further improve the learning efficiency by using the experience replay technique that stores the training data in the experience memory and samples from the memory as needed. We have compared the performance of the proposed CACER (Continuous Actor–Critic with Experience Replay) algorithm with benchmark algorithms such as DDPG and double DQN in numerical simulation, and we have demonstrated the performance of the learned optimal policy in semi-physical simulation without any parameter tuning.}
}
@article{LI2021585,
title = {Deep learning enabled localization for UAV autolanding},
journal = {Chinese Journal of Aeronautics},
volume = {34},
number = {5},
pages = {585-600},
year = {2021},
issn = {1000-9361},
doi = {https://doi.org/10.1016/j.cja.2020.11.011},
url = {https://www.sciencedirect.com/science/article/pii/S1000936120305641},
author = {Minghui LI and Tianjiang HU},
keywords = {Deep learning, Localization, Safe landing, Stereo vision, UAV autolanding},
abstract = {This article concentrates on ground vision guided autonomous landing of a fixed-wing Unmanned Aerial Vehicle (UAV) within Global Navigation Satellite System (GNSS) denied environments. Cascaded deep learning models are developed and employed into image detection and its accuracy promoting for UAV autolanding, respectively. Firstly, we design a target bounding box detection network BboxLocate-Net to extract its image coordinate of the flying object. Secondly, the detected coordinate is fused into spatial localization with an extended Kalman filter estimator. Thirdly, a point regression network PointRefine-Net is developed for promoting detection accuracy once the flying vehicle’s motion continuity is checked unacceptable. The proposed approach definitely accomplishes the closed-loop mutual inspection of spatial positioning and image detection, and automatically improves the inaccurate coordinates within a certain range. Experimental results demonstrate and verify that our method outperforms the previous works in terms of accuracy, robustness and real-time criterions. Specifically, the newly developed BboxLocate-Net attaches over 500 fps, almost five times the published state-of-the-art in this field, with comparable localization accuracy.}
}
@article{HAN2020696,
title = {An effective approach to unmanned aerial vehicle navigation using visual topological map in outdoor and indoor environments},
journal = {Computer Communications},
volume = {150},
pages = {696-702},
year = {2020},
issn = {0140-3664},
doi = {https://doi.org/10.1016/j.comcom.2019.12.026},
url = {https://www.sciencedirect.com/science/article/pii/S0140366419307868},
author = {Tao Han and Jefferson S. Almeida and Suane Pires P. {da Silva} and Paulo Honório Filho and Antonio W. {de Oliveira Rodrigues} and Victor Hugo C. {de Albuquerque} and Pedro P. {Rebouças Filho}},
keywords = {Unmanned aerial vehicles, UAV navigation, Computer vision, Topological maps},
abstract = {Unmanned Aerial Vehicles are constantly being using in professional activities that require higher precision in navigating and positioning the aircraft during operation. Advanced location technologies such as Global Navigation Satellite System and Real-Time Kinematic are widely used, however, they depend on an area with transmission coverage. In this approach, this article presents a visual navigation methodology based on topological maps. We compared the performance of consolidated classifiers such as Bayesian classifier, k-nearest neighbor, Multilayer Perceptron, Optimal Path Forest and Support Vector Machines (SVM). They are evaluated with attributes returned by last generation resource extractors such as Fourier, Gray Level Co-Occurrence and Local Binary Patterns (LBP). After analyzing the results we found that the combination of LBP and SVM obtained the best values in the evaluation metrics considered, among them, 99.99% Specificity and 99.98% Precision in the navigation process. SVM reached 5.49787 s in combination with LBP completes the training in 5.49787 s. Concerning the testing time, SVM achieving 80.91 ms in association with LBP.}
}
@article{HATAMLEH2015457,
title = {Unmanned Aerial Vehicles parameter estimation using Artificial Neural Networks and Iterative Bi-Section Shooting method},
journal = {Applied Soft Computing},
volume = {36},
pages = {457-467},
year = {2015},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2015.06.031},
url = {https://www.sciencedirect.com/science/article/pii/S1568494615003804},
author = {Khaled S. Hatamleh and Mohammad Al-Shabi and Adnan Al-Ghasem and Asad A. Asad},
keywords = {UAV, Parameter Estimation, ANN, IBSS},
abstract = {Quadrotor Unmanned Aerial Vehicles (UAVs) can perform numerous tasks fearless of unnecessary loss of human life. Lately, to enhance UAV control performance, system identification and states estimation has been an active field of research. This work presents a simulation study that investigates unknown dynamics model parameters estimation of a Quadrotor UAV under presence of noisy feedback signals. The latter constitute a challenge for UAV control performance especially with the presence of uncertainties. Therefore, estimation techniques are usually used to reduce the effect of such uncertainties. In this paper, three estimation methods are presented to estimate unknown parameters of the “OS4” Quadrotor. Those methods are Iterative Bi-Section Shooting method “IBSS”, Artificial Neural Network method “ANN”, and “Hybrid ANN_IBSS”, which is a novel method that integrates ANN with IBSS. The “Hybrid ANN_IBSS” is the main contribution of this work. Percentage error of the estimated parameters is used to evaluate accuracy of the aforementioned methods. Results show that IBSS and ANN are capable of estimating most of the parameters even with the presence of noisy feedback signals. However, their performance lacks accuracy when estimating small-value parameters. On the other hand, Hybrid ANN_IBSS achieved higher estimation accuracy compared to the other two methods. Accurate parameter estimation is expected to enhance reliability of the “OS4” dynamics model and hence improve control quality.}
}
@article{GHAFFARIAN2022106631,
title = {Machine learning-based farm risk management: A systematic mapping review},
journal = {Computers and Electronics in Agriculture},
volume = {192},
pages = {106631},
year = {2022},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2021.106631},
url = {https://www.sciencedirect.com/science/article/pii/S0168169921006487},
author = {Saman Ghaffarian and Mariska {van der Voort} and João Valente and Bedir Tekinerdogan and Yann {de Mey}},
keywords = {Farm risk management, Machine learning, Crop management, Dairy farm, Systematic mapping review},
abstract = {Farms face various risks such as uncertainties in the natural growth process, obtaining adequate financing, volatile input and output prices, unpredictable changes in farm-related policy and regulations, and farmers‘ personal health problems. Accordingly, farmers have to make decisions to be prepared for such situations under risk or mitigate their impacts to maintain essential functions. Increasingly, a data-driven perspective is warranted where machine learning (ML) has become an essential tool for automatic extraction of useful information to support decision-making in farm management as well as risk management. ML’s role in farm risk management (FRM) has recently increased with advances in technology and digitalization. This paper provides a literature review in the form of a systematic mapping study to identify the publications, trends, active research communities, and detailed reviews on the use of ML methods for FRM. Accordingly, nine research/mapping questions are designed to extract the required information. In total, we retrieved 1819 papers, of which 746 papers were selected based on the defined exclusion criteria for a detailed review. We categorized the studies based on the addressed risk types (e.g., production risk), assessments that addressed risk components (e.g., resilience), used ML types (e.g., supervised learning) and algorithms ranging from regression modeling to deep learning, addressed ML tasks (e.g., classification), data types (e.g., images), and farm types (e.g., crop-based farm). The results reveal that there is a significant increase in employing ML methods including deep learning and convolutional neural networks for FRM in recent years. The production risk and impact/damage assessment are the most frequently addressed risk type and assessment that addressed risk components in ML-FRM, respectively. In addition, research gaps and open problems are identified and accordingly insights and recommendations from risk management and machine learning perspectives are provided for future studies including the need for ML methods for different risk types (e.g., financial risk), assessments addressing different risk components (e.g., resilience assessment), and developing more advanced ML methods (e.g., reinforcement learning) for FRM.}
}
@article{ELEFTHEROGLOU2019113677,
title = {Intelligent data-driven prognostic methodologies for the real-time remaining useful life until the end-of-discharge estimation of the Lithium-Polymer batteries of unmanned aerial vehicles with uncertainty quantification},
journal = {Applied Energy},
volume = {254},
pages = {113677},
year = {2019},
issn = {0306-2619},
doi = {https://doi.org/10.1016/j.apenergy.2019.113677},
url = {https://www.sciencedirect.com/science/article/pii/S0306261919313649},
author = {Nick Eleftheroglou and Sina Sharif Mansouri and Theodoros Loutas and Petros Karvelis and George Georgoulas and George Nikolakopoulos and Dimitrios Zarouchas},
keywords = {Remaining useful life, Data-driven prognostics, UAVs, Li-Po batteries, End of discharge, Machine learning},
abstract = {In this paper, the discharge voltage is utilized as a critical indicator towards the probabilistic estimation of the Remaining Useful Life until the End-of-Discharge of the Lithium-Polymer batteries of unmanned aerial vehicles. Several discharge voltage histories obtained during actual flights constitute the in-house developed training dataset. Three data-driven prognostic methodologies are presented based on state-of-the-art as well as innovative mathematical models i.e. Gradient Boosted Trees, Bayesian Neural Networks and Non-Homogeneous Hidden Semi Markov Models. The training and testing process of all models is described in detail. Remaining Useful Life prognostics in unseen data are obtained from all three methodologies. Beyond the mean estimates, the uncertainty associated with the point predictions is quantified and upper/lower confidence bounds are also provided. The Remaining Useful Life prognostics during six random flights starting from fully charged batteries are presented, discussed and the pros and cons of each methodology are highlighted. Several special metrics are utilized to assess the performance of the prognostic algorithms and conclusions are drawn regarding their prognostic capabilities and potential.}
}
@article{PEARSE2020156,
title = {Detecting and mapping tree seedlings in UAV imagery using convolutional neural networks and field-verified data},
journal = {ISPRS Journal of Photogrammetry and Remote Sensing},
volume = {168},
pages = {156-169},
year = {2020},
issn = {0924-2716},
doi = {https://doi.org/10.1016/j.isprsjprs.2020.08.005},
url = {https://www.sciencedirect.com/science/article/pii/S0924271620302136},
author = {Grant D. Pearse and Alan Y.S. Tan and Michael S. Watt and Matthias O. Franz and Jonathan P. Dash},
keywords = {Deep learning, Convolutional networks, Tree seedlings, Unmanned aerial vehicles, Forest establishment, Object detection},
abstract = {Mapping of tree seedlings is useful for tasks ranging from monitoring natural succession and regeneration to effective silvicultural management. Development of methods that are both accurate and cost-effective is especially important considering the dramatic increase in tree planting that is required globally to mitigate the impacts of climate change. The combination of high-resolution imagery from unmanned aerial vehicles and object detection by convolutional neural networks (CNNs) is one promising approach. However, unbiased assessments of these models and methods to integrate them into geospatial workflows are lacking. In this study, we present a method for rapid, large-scale mapping of young conifer seedlings using CNNs applied to RGB orthomosaic imagery. Importantly, we provide an unbiased assessment of model performance by using two well-characterised trial sites together containing over 30,000 seedlings to assemble datasets with a high level of completeness. Our results showed CNN-based models trained on two sites detected seedlings with sensitivities of 99.5% and 98.8%. False positives due to tall weeds at one site and naturally regenerating seedlings of the same species led to slightly lower precision of 98.5% and 96.7%. A model trained on examples from both sites had 99.4% sensitivity and precision of 97%, showing applicability across sites. Additional testing showed that the CNN model was able to detect 68.7% of obscured seedlings missed during the initial annotation of the imagery but present in the field data. Finally, we demonstrate the potential to use a form of weakly supervised training and a tile-based processing chain to enhance the accuracy and efficiency of CNNs applied to large, high-resolution orthomosaics.}
}
@article{ALLADI2020100249,
title = {Applications of blockchain in unmanned aerial vehicles: A review},
journal = {Vehicular Communications},
volume = {23},
pages = {100249},
year = {2020},
issn = {2214-2096},
doi = {https://doi.org/10.1016/j.vehcom.2020.100249},
url = {https://www.sciencedirect.com/science/article/pii/S2214209620300206},
author = {Tejasvi Alladi and Vinay Chamola and Nishad Sahu and Mohsen Guizani},
keywords = {Unmanned Aerial Vehicle (UAV) network, Security and privacy, Blockchain technology, Internet of Things (IoT)},
abstract = {The recent advancement in Unmanned Aerial Vehicles (UAVs) in terms of manufacturing processes, and communication and networking technology has led to a rise in their usage in civilian and commercial applications. The regulations of the Federal Aviation Administration (FAA) in the US had earlier limited the usage of UAVs to military applications. However more recently, the FAA has outlined new enforcement that will also expand the usage of UAVs in civilian and commercial applications. Due to being deployed in open atmosphere, UAVs are vulnerable to being lost, destroyed or physically hijacked. With the UAV technology becoming ubiquitous, various issues in UAV networks such as intra-UAV communication, UAV security, air data security, data storage and management, etc. need to be addressed. Blockchain being a distributed ledger protects the shared data using cryptography techniques such as hash functions and public key encryption. It can also be used for assuring the truthfulness of the information stored and for improving the security and transparency of the UAVs. In this paper, we review various applications of blockchain in UAV networks such as network security, decentralized storage, inventory management, surveillance, etc., and discuss some broader perspectives in this regard. We also discuss various challenges to be addressed in the integration of blockchain and UAVs and suggest some future research directions.}
}
@article{GE2021106885,
title = {A trajectory optimization method for reducing magnetic disturbance of an internal combustion engine powered unmanned aerial vehicle},
journal = {Aerospace Science and Technology},
volume = {116},
pages = {106885},
year = {2021},
issn = {1270-9638},
doi = {https://doi.org/10.1016/j.ast.2021.106885},
url = {https://www.sciencedirect.com/science/article/pii/S1270963821003953},
author = {Jiahao Ge and Li Liu and Xinxin Dong and Yuntao He},
keywords = {ICE-powered UAV, Magnetic disturbance, Lithium battery magnetic field, Trajectory optimization, Hp-adaptive Radau pseudospectral method},
abstract = {Magnetic disturbance generated by an unmanned aerial vehicle (UAV) is the leading cause of magnetic airborne detector (MAD) misjudgment in UAV underwater magnetic survey. Different from traditional schemes, a new method of reducing magnetic disturbance from the perspective of trajectory optimization is proposed in this paper. First, the magnetic disturbance on UAV is analyzed and classified. Then the magnetic disturbance model of airframe coupled with 6 degrees of freedom (DoF) UAV dynamic model is established. Second, this paper proposes a mechanism model of lithium battery magnetic field. Third, the optimal control problem and its solution framework are constructed. The hp-adaptive Radau pseudospectral method and optimization of lithium battery setting angle are proposed to solve this optimal control problem. Objective function linearization and model-based variable reduction strategy are proposed to improve the method and help the results converge. Finally, aeromagnetic survey scenes of “point-to-point” and “regional coverage” are simulated. The results showed that the impact of UAV magnetic disturbance at MAD could be effectively reduced.}
}
@article{GUO2018818,
title = {Fault detection and isolation for Unmanned Aerial Vehicle sensors by using extended PMI filter},
journal = {IFAC-PapersOnLine},
volume = {51},
number = {24},
pages = {818-823},
year = {2018},
note = {10th IFAC Symposium on Fault Detection, Supervision and Safety for Technical Processes SAFEPROCESS 2018},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2018.09.669},
url = {https://www.sciencedirect.com/science/article/pii/S2405896318323875},
author = {Dingfei Guo and Yulin Wang and Maiying Zhong and Yan Zhao},
keywords = {Unmanned aerial vehicles, kinematics model, proportional multiple integral, sensors fault detection, isolation},
abstract = {Fault detection and isolation (FDI) plays an important role in guaranteeing system safety and reliability for unmanned aerial vehicles (UAVs). This paper focuses on developing a method for detecting UAV sensor faults by using existing sensors, such as pitot tube, gyro, accelerometer and wind angle sensor. We formulate the kinematics as a nonlinear state space system, which requires no dynamic information and thus is applicable to all aircraft. To illustrate the method, we investigate five fault-detection scenarios, namely, faulty pitot tube, angle-of-attack sensor, sideslip sensor, accelerometer and gyro, and design a FDI structure including five faulty sensors. Then, considering the unknown disturbance, the proportional and multiple integral (PMI) fault detection filter (FDF) is proposed for the state and input estimation. A structure including two residuals are employed to detect and isolate the faults of the proposed faulty sensors. Finally, the performance of the proposed methodology is evaluated through flight experiments of the UAV.}
}
@article{GUO2021102239,
title = {Biomass and vegetation coverage survey in the Mu Us sandy land - based on unmanned aerial vehicle RGB images},
journal = {International Journal of Applied Earth Observation and Geoinformation},
volume = {94},
pages = {102239},
year = {2021},
issn = {0303-2434},
doi = {https://doi.org/10.1016/j.jag.2020.102239},
url = {https://www.sciencedirect.com/science/article/pii/S0303243420308825},
author = {Zi-chen Guo and Tao Wang and Shu-lin Liu and Wen-ping Kang and Xiang Chen and Kun Feng and Xue-qin Zhang and Ying Zhi},
keywords = {UAV, Vegetation coverage, Aboveground biomass, Net aboveground biomass, Shrub, Mu Us sandy land},
abstract = {Accurate detection of vegetation cover and biomass of shrub communities in sandy area is beneficial for evaluating ecosystem, improving remote sensing models, and assessing the accuracy of remote sensing. Unmanned aerial vehicles (UAVs) have replaced traditional measurement methods in biomass and fraction of vegetation coverage (FVC) detection owing to the high spatial resolution of their imagery, their high positioning accuracy, and their ease of use. The existing methods of detecting biomass via UAVs, however, are not suitable for surface fluctuations, dwarf shrubs, and herbs. Futhermore, the method of calculating FVC using UAV RGB images has not yet been tested in sandy areas. To accurately extract FVC data, aboveground biomass (ABS) and net aboveground biomass (NABS) of shrub communities in the desert regions, UAV RGB images of 87 sample plots in the Mu Us sandy land were collected and used to obtain the FVC and biomass information via the object-based classification method, single shrub canopy biomass model and vegetation index-based method. The results are as follows: (1) the method of calculating ABS and NABS based on shrub canopy width extraction can be used in desert shrub communities, and results show that the ABS and NABS of vegetation communities increases from 15 to 800 g/m2 and 10–250 g/m2, respectively, in the Mu Us sandy land; and (2) the lowest value of ABS (NABS) appeared in the mobile sandy dunes and the highest value appeared in the semi-fixed sandy dunes; (3) under fixed thresholds conditions, the FVC can be extracted accurately using the excess green method, visible atmospherically resistant index, vegetative index, green red vegetation index and red green blue vegetation index (RGBVI); and (4) the correlation between the FVC calculated by the five RGB vegetation indexes and NABS in this study is greater than that between FVC and ABS (e.g. R2NABS - RGBVI = 0.734, R2ABS - RGBVI = 0.666), and the FVC calculated by RGBVI can be used to estimate NABS in the Mu Us sandy land. This study will provide new insights for field investigations of the ABS, NABS, and FVC in sandy areas.}
}
@article{TAHIR2019100106,
title = {Swarms of Unmanned Aerial Vehicles — A Survey},
journal = {Journal of Industrial Information Integration},
volume = {16},
pages = {100106},
year = {2019},
issn = {2452-414X},
doi = {https://doi.org/10.1016/j.jii.2019.100106},
url = {https://www.sciencedirect.com/science/article/pii/S2452414X18300086},
author = {Anam Tahir and Jari Böling and Mohammad-Hashem Haghbayan and Hannu T. Toivonen and Juha Plosila},
keywords = {Swarm of drones, Swarm of Unmanned Aerial Vehicles},
abstract = {The unmanned aerial vehicles or drones come in a great diversity depending upon the basic frameworks with their particular specifications. The purpose of this study is to analyse the core characteristics of the swarming drones and measure the public awareness levels with respect to these swarms. To achieve these goals, the functionality, problems, and importance of drones are highlighted. The results of an experimental survey from a bunch of academic population are also presented, which demonstrate that the swarms of drones are fundamental future agenda and will be adopted with the passage of time.}
}
@article{REESE2021105413,
title = {Deep learning artificial neural networks for non-destructive archaeological site dating},
journal = {Journal of Archaeological Science},
volume = {132},
pages = {105413},
year = {2021},
issn = {0305-4403},
doi = {https://doi.org/10.1016/j.jas.2021.105413},
url = {https://www.sciencedirect.com/science/article/pii/S0305440321000832},
author = {Kelsey M. Reese},
keywords = {Machine learning, Deep learning, Artificial neural network, Dating, Demography, Mesa verde, US Southwest},
abstract = {This article introduces artificial neural networks as a computational tool to utilize legacy archaeological data for precisely and accurately estimating dates of residential site occupation. The implementation of this deep learning algorithm can provide high-resolution demographic reconstructions of a study area from non-collection, non-invasive, and non-destructive data collection methods that only record frequencies of artifact types on the contemporary ground surface. The utility of this deep learning algorithm is presented through an example from the central Mesa Verde region in the northern US Southwest. Results show a properly trained artificial neural network predicts annual residential occupation with an average 92.8% accuracy from AD 450–1300. An annual demographic reconstruction of the central Mesa Verde region using occupation predictions from the artificial neural network is also presented.}
}
@article{SCHIEFER2020205,
title = {Mapping forest tree species in high resolution UAV-based RGB-imagery by means of convolutional neural networks},
journal = {ISPRS Journal of Photogrammetry and Remote Sensing},
volume = {170},
pages = {205-215},
year = {2020},
issn = {0924-2716},
doi = {https://doi.org/10.1016/j.isprsjprs.2020.10.015},
url = {https://www.sciencedirect.com/science/article/pii/S0924271620302938},
author = {Felix Schiefer and Teja Kattenborn and Annett Frick and Julian Frey and Peter Schall and Barbara Koch and Sebastian Schmidtlein},
keywords = {Deep learning, Forest inventory, Convolutional neural networks, Tree species classification, Unmanned aerial systems, Temperate forests},
abstract = {The use of unmanned aerial vehicles (UAVs) in vegetation remote sensing allows a time-flexible and cost-effective acquisition of very high-resolution imagery. Still, current methods for the mapping of forest tree species do not exploit the respective, rich spatial information. Here, we assessed the potential of convolutional neural networks (CNNs) and very high-resolution RGB imagery from UAVs for the mapping of tree species in temperate forests. We used multicopter UAVs to obtain very high-resolution (<2 cm) RGB imagery over 51 ha of temperate forests in the Southern Black Forest region, and the Hainich National Park in Germany. To fully harness the end-to-end learning capabilities of CNNs, we used a semantic segmentation approach (U-net) that concurrently segments and classifies tree species from imagery. With a diverse dataset in terms of study areas, site conditions, illumination properties, and phenology, we accurately mapped nine tree species, three genus-level classes, deadwood, and forest floor (mean F1-score 0.73). A larger tile size during CNN training negatively affected the model accuracies for underrepresented classes. Additional height information from normalized digital surface models slightly increased the model accuracy but increased computational complexity and data requirements. A coarser spatial resolution substantially reduced the model accuracy (mean F1-score of 0.26 at 32 cm resolution). Our results highlight the key role that UAVs can play in the mapping of forest tree species, given that air- and spaceborne remote sensing currently does not provide comparable spatial resolutions. The end-to-end learning capability of CNNs makes extensive preprocessing partly obsolete. The use of large and diverse datasets facilitate a high degree of generalization of the CNN, thus fostering transferability. The synergy of high-resolution UAV imagery and CNN provide a fast and flexible yet accurate means of mapping forest tree species.}
}
@article{DAPOLITO2021251,
title = {Flight Control of a Multicopter using Reinforcement Learning},
journal = {IFAC-PapersOnLine},
volume = {54},
number = {13},
pages = {251-255},
year = {2021},
note = {20th IFAC Conference on Technology, Culture, and International Stability TECIS 2021},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2021.10.454},
url = {https://www.sciencedirect.com/science/article/pii/S2405896321018917},
author = {Francesco d’Apolito and Christoph Sulzbachner},
keywords = {Artificial Intelligence, Applications, Intelligent Systems, Robotics, Handling Devices, Models, Simulation, Mechatronic Systems},
abstract = {Machine Learning, and in particular Reinforcement Learning, is a persistent trend in automation and robotics in recent years. Many researchers worldwide are developing intelligent controllers using Reinforcement Learning techniques. This paper aims to present a proof-of-concept Reinforcement Learning flight controller for a multicopter. The agent has been trained in the Airsim simulation environment to achieve stable flight conditions by controlling its roll, pitch, yaw and throttle. After training, the agent has been tested on the same environment to prove its ability to maintain stable flight conditions while following a determined route.}
}
@article{CHEN2021108249,
title = {Deep Q-Network based resource allocation for UAV-assisted Ultra-Dense Networks},
journal = {Computer Networks},
volume = {196},
pages = {108249},
year = {2021},
issn = {1389-1286},
doi = {https://doi.org/10.1016/j.comnet.2021.108249},
url = {https://www.sciencedirect.com/science/article/pii/S138912862100284X},
author = {Xin Chen and Xu Liu and Ying Chen and Libo Jiao and Geyong Min},
keywords = {Ultra-Dense Networks (UDN), Unmanned Aerial Vehicles (UAV), Resource allocation, Markov Decision Process (MDP), Deep Q-Network (DQN)},
abstract = {With the rapid development of the fifth-generation (5G) wireless communications, the number of users is increasing dramatically and Ultra-Dense Networks (UDN) are becoming more important for supporting numerous users and emerging mission-critical applications. In order to conquer the communication restrictions caused by natural disasters, an emergency communication system using Unmanned Aerial Vehicles (UAV) as a flying base station (BS) to assist UDN is proposed. By virtue of the resource allocation scheme of UAV-assisted UDN systems, communication resources can be reasonably and effectively allocated to improve the quality of user experience. Firstly, aiming to maximize the system energy efficiency (EE), a UDN system model including the BS selection is constructed. Secondly, Markov Decision Process (MDP) theory is applied to transform the system model into a stochastic optimization problem. Finally, by using deep reinforcement learning (DRL) technique, we propose a Deep Q-Network (DQN) based resource allocation scheme to maximize the system energy efficiency. Simulation results exhibit that the proposed DQN-based resource allocation scheme can significantly improve the system EE compared with the legacy Q-Learning, random and maximum resource allocation algorithms.}
}
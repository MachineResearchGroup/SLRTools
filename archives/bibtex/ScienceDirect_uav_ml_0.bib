@article{SCHWARZROCK201810,
title = {Solving task allocation problem in multi Unmanned Aerial Vehicles systems using Swarm intelligence},
journal = {Engineering Applications of Artificial Intelligence},
volume = {72},
pages = {10-20},
year = {2018},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2018.03.008},
url = {https://www.sciencedirect.com/science/article/pii/S0952197618300575},
author = {Janaína Schwarzrock and Iulisloi Zacarias and Ana L.C. Bazzan and Ricardo Queiroz {de Araujo Fernandes} and Leonardo Henrique Moreira and Edison Pignaton {de Freitas}},
keywords = {Unmanned Aerial Vehicles, Task allocation, Multi-agent systems, Swarm intelligence},
abstract = {The envisaged usage of multiple Unmanned Aerial Vehicles (UAVs) to perform cooperative tasks is a promising concept for future autonomous military systems. An important aspect to make this usage a reality is the solution of the task allocation problem in these cooperative systems. This paper addresses the problem of tasks allocation among agents representing UAVs, considering that the tasks are created by a central entity, in which the decision of which task will be performed by each agent is not decided by this central entity, but by the agents themselves. The assumption that tasks are created by a central entity is a reasonable one, given the way strategic planning is carried up in military operations. To enable the UAVs to have the ability to decide which tasks to perform, concepts from swarm intelligence and multi-agent system approach are used. Heuristic methods are commonly used to solve this problem, but they present drawbacks. For example, many tasks end up not begin performed even if the UAVs have enough resources to execute them. To cope with this problem, this paper proposes three algorithm variants that complement each other to form a new method aiming to increase the amount of performed tasks, so that a better task allocation is achieved. Through experiments in a simulated environment, the proposed method was evaluated, yielding enhanced results for the addressed problem compared to existing methods reported in the literature.}
}
@article{GUO2021479,
title = {UAV navigation in high dynamic environments: A deep reinforcement learning approach},
journal = {Chinese Journal of Aeronautics},
volume = {34},
number = {2},
pages = {479-489},
year = {2021},
issn = {1000-9361},
doi = {https://doi.org/10.1016/j.cja.2020.05.011},
url = {https://www.sciencedirect.com/science/article/pii/S1000936120302247},
author = {Tong GUO and Nan JIANG and Biyue LI and Xi ZHU and Ya WANG and Wenbo DU},
keywords = {Autonomous vehicles, Deep learning, Motion planning, Navigation, Reinforcement learning, Unmanned Aerial Vehicle (UAV)},
abstract = {Unmanned Aerial Vehicle (UAV) navigation is aimed at guiding a UAV to the desired destinations along a collision-free and efficient path without human interventions, and it plays a crucial role in autonomous missions in harsh environments. The recently emerging Deep Reinforcement Learning (DRL) methods have shown promise for addressing the UAV navigation problem, but most of these methods cannot converge due to the massive amounts of interactive data when a UAV is navigating in high dynamic environments, where there are numerous obstacles moving fast. In this work, we propose an improved DRL-based method to tackle these fundamental limitations. To be specific, we develop a distributed DRL framework to decompose the UAV navigation task into two simpler sub-tasks, each of which is solved through the designed Long Short-Term Memory (LSTM) based DRL network by using only part of the interactive data. Furthermore, a clipped DRL loss function is proposed to closely stack the two sub-solutions into one integral for the UAV navigation problem. Extensive simulation results are provided to corroborate the superiority of the proposed method in terms of the convergence and effectiveness compared with those of the state-of-the-art DRL methods.}
}
@article{FENG2021106033,
title = {A comprehensive review on recent applications of unmanned aerial vehicle remote sensing with various sensors for high-throughput plant phenotyping},
journal = {Computers and Electronics in Agriculture},
volume = {182},
pages = {106033},
year = {2021},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2021.106033},
url = {https://www.sciencedirect.com/science/article/pii/S016816992100051X},
author = {Lei Feng and Shuangshuang Chen and Chu Zhang and Yanchao Zhang and Yong He},
keywords = {Unmanned aerial vehicle, Remote sensing, High-throughput phenotyping, Sensors, Applications review},
abstract = {High-throughput phenotyping has been widely studied in plant science to monitor plant growth and analyze the influence of genotypes and environment on plant growth. To meet the demand of large-scale high-throughput phenotyping, unmanned aerial vehicles (UAVs) have been developed for near-ground remote sensing. UAVs based remote sensing has been used for high-throughput phenotyping of various traits of plants. This review focused on the applications of UAVs based remote sensing of different traits with different phenotyping sensors. In this review, the UAVs platforms and the phenotyping sensors were briefly introduced. The applications of UAVs to obtain and analyze plant phenotype traits were introduced and summarized by the traits in a more comprehensive way. A comparison of different phenotyping sensors was conducted. Furthermore, the challenges and future prospects of phenotype information acquisition and data analysis using UAVs as remote sensing platforms were also discussed. Since the current studies from various countries and researchers were fragmented to just explore the feasibility of UAVs based high-throughput phenotyping, this review aimed to provide the researchers and readers the current applications of UAVs for high-throughput phenotyping and how the studies were conducted, provide guidelines for future studies.}
}
@article{LIU2021106435,
title = {Control-oriented UAV highly feasible trajectory planning: A deep learning method},
journal = {Aerospace Science and Technology},
volume = {110},
pages = {106435},
year = {2021},
issn = {1270-9638},
doi = {https://doi.org/10.1016/j.ast.2020.106435},
url = {https://www.sciencedirect.com/science/article/pii/S1270963820311172},
author = {Yiheng Liu and Honglun Wang and Jiaxuan Fan and Jianfa Wu and Tiancai Wu},
keywords = {Highly feasible trajectory planning, Trajectory-mapping network, Deep learning, Unmanned aerial vehicle},
abstract = {The highly feasible trajectory planning of unmanned aerial vehicle (UAV) is very important in some tasks but has not yet attracted sufficient study attention. Most current studies use simplified UAV model with some state constraints to plan the trajectory, but the feasibility is reduced, because the simplified model is very different from the actual UAV system, so that the tracking characteristics of UAV cannot be fully considered. In this paper, a novel control-oriented UAV highly feasible trajectory planning method is proposed. First, a UAV closed-loop model prediction method, which is the combination of a low-level controller and a UAV 6 DOF nonlinear model, is adopted in the trajectory planning phase to predict the flight trajectory. This complicated model is very similar to the actual UAV system because it comprehensively considers the controller performance and the detailed UAV model, but it also has poor efficiency. Therefore, a trajectory-mapping network (TMN) is proposed using a deep learning approach to improve the planning efficiency. Furthermore, a novel time-series convolutional neural network (TSCNN) is proposed for the TMN to further improve its computation speed and prediction accuracy. Finally, the flight trajectory predicted by the TMN is used to evaluate the planning cost. In this way, the planned trajectory will be highly feasible. The effectiveness of the proposed method is demonstrated by simulations.}
}
@article{WU2021118986,
title = {Application of conventional UAV-based high-throughput object detection to the early diagnosis of pine wilt disease by deep learning},
journal = {Forest Ecology and Management},
volume = {486},
pages = {118986},
year = {2021},
issn = {0378-1127},
doi = {https://doi.org/10.1016/j.foreco.2021.118986},
url = {https://www.sciencedirect.com/science/article/pii/S037811272100075X},
author = {Bizhi Wu and Anjie Liang and Huafeng Zhang and Tengfei Zhu and Zhiying Zou and Deming Yang and Wenyu Tang and Jian Li and Jun Su},
keywords = {Pine wilt disease, Early diagnosis, UAV, Deep learning, Faster R-CNN, YOLO},
abstract = {The early diagnosis of pine wilt disease (PWD) is crucial to its management. Substantial effort has been made to develop an accurate early diagnosis method. However, none of the existing methods are suitable for large-scale rapid screening in the field. In this study, an unmanned aerial vehicle (UAV) was used to collect a large number of images from a pine tree canopy in an early stage of infection for the generation of a training dataset. Owing to the inability to develop object detection models using nine regular machine learning classifiers, two advanced deep learning algorithms were employed, namely the Faster Region-based Convolutional Network (Faster R-CNN) and You Only Look Once version 3 (YOLOv3). Model performances were compared based on the precision (mAP), size, and processing speed. All four models possessed similar precision (0.602–0.64), but the YOLO-based models had a smaller size and faster processing speed than the Faster R-CNN-adapted models. The population of infected trees (in the early or late stage of infection) was predicted under different treatments (retaining or removing the dead trees from the forest) using these four models to explore their application. The results indicate that retaining dead trees after chopping them down results in fewer dead trees but more early infected trees the following year. We propose a cost-effective and high-throughput method for the early diagnosis of PWD in the field using UAV-based image processing and object detection (uses YOLOv3) based on deep learning.}
}
@article{YEN2022108590,
title = {Multi-sensory sound source enhancement for unmanned aerial vehicle recordings},
journal = {Applied Acoustics},
volume = {189},
pages = {108590},
year = {2022},
issn = {0003-682X},
doi = {https://doi.org/10.1016/j.apacoust.2021.108590},
url = {https://www.sciencedirect.com/science/article/pii/S0003682X21006848},
author = {Benjamin Yen and Yusuke Hioka and Gian Schmid and Brian Mace},
keywords = {Microphone array, unmanned aerial vehicle, source enhancement, power spectral density, rotor noise},
abstract = {A method to effectively perform sound source enhancement from an unmanned aerial vehicle (UAV)-mounted audio recording system is proposed. The objective of this study is to utilise audio recordings and non-acoustical UAV rotor characteristics to improve rotor noise power spectral density (PSD) estimation accuracy and robustness. The improved rotor noise PSD estimate in turn improves the effectiveness of the rotor noise postfilter, leading to improvement in source enhancement performance. The performance of the proposed source enhancement algorithm is evaluated via experiments, with recordings made in an outdoor environment with an in-flight UAV. Experiment results show PSD estimation accuracy to within 1.5 dB log spectral distortion regardless of the given input conditions, such as the presence of surrounding sound sources. The method also achieves a consistent ∼20–25 dB improvement in source enhancement performance, where the effects of rotor noise from the noisy microphone recordings are significantly reduced. The proposed method also outperforms existing state-of-the-art such as the beamformer with postfilter and speech distortion weighted multichannel Wiener filter frameworks.}
}
@article{KUMAR2021107819,
title = {SP2F: A secured privacy-preserving framework for smart agricultural Unmanned Aerial Vehicles},
journal = {Computer Networks},
volume = {187},
pages = {107819},
year = {2021},
issn = {1389-1286},
doi = {https://doi.org/10.1016/j.comnet.2021.107819},
url = {https://www.sciencedirect.com/science/article/pii/S1389128621000086},
author = {Randhir Kumar and Prabhat Kumar and Rakesh Tripathi and Govind P. Gupta and Thippa Reddy Gadekallu and Gautam Srivastava},
keywords = {Blockchain technology, Artificial intelligence, Deep learning, Intrusion detection system, Privacy-preservation, Smart agriculture, Unmanned Aerial Vehicles (UAVs)},
abstract = {The current advancement in Unmanned Aerial Vehicles (UAVs) and the proliferation of the Internet of Things (IoT) devices is revolutionizing conventional farming operations into precision agriculture. The agricultural UAVs combined with IoT use an open channel i.e., the Internet to assist cultivators with data collection, processing, monitoring, and making correct decisions on the farm. However, the use of the Internet opens up a wide range of challenges such as security (e.g., performing cyber-attacks), risk of data privacy (e.g., data poisoning and inference attacks), etc. The usage of current conventional centralized security measures has limitations in terms of a single point of failure, verifiability, traceability, and scalability. Motivated from the aforementioned challenges, we propose a Secured Privacy-Preserving Framework (SP2F) for smart agricultural UAVs. The proposed SP2F framework has two main engines, a two-level privacy engine, and a deep learning-based anomaly detection engine. In the two-level privacy engine, a blockchain, and smart contract-based enhanced Proof of Work (ePoW) is designed for data authentication, and to mitigate data poisoning attacks. A Sparse AutoEncoder (SAE) is applied for transforming data into a new encoded format for preventing inference attacks. In the anomaly detection engine, a Stacked Long-Short-Term Memory (SLSTM) is used to train and evaluate the results of the proposed two-level privacy engine using two publicly accessible IoT-based datasets, namely ToN-IoT and IoT Botnet. Finally, based on thorough analysis, and comparison, we identify that the SP2F framework outperforms several state-of-the-art techniques in both non-blockchain and blockchain frameworks.}
}
@article{OSCO2021102456,
title = {A review on deep learning in UAV remote sensing},
journal = {International Journal of Applied Earth Observation and Geoinformation},
volume = {102},
pages = {102456},
year = {2021},
issn = {0303-2434},
doi = {https://doi.org/10.1016/j.jag.2021.102456},
url = {https://www.sciencedirect.com/science/article/pii/S030324342100163X},
author = {Lucas Prado Osco and José {Marcato Junior} and Ana Paula {Marques Ramos} and Lúcio André {de Castro Jorge} and Sarah Narges Fatholahi and Jonathan {de Andrade Silva} and Edson Takashi Matsubara and Hemerson Pistori and Wesley Nunes Gonçalves and Jonathan Li},
keywords = {Convolutional neural networks, Remote sensing imagery, Unmanned aerial vehicles},
abstract = {Deep Neural Networks (DNNs) learn representation from data with an impressive capability, and brought important breakthroughs for processing images, time-series, natural language, audio, video, and many others. In the remote sensing field, surveys and literature revisions specifically involving DNNs algorithms’ applications have been conducted in an attempt to summarize the amount of information produced in its subfields. Recently, Unmanned Aerial Vehicle (UAV)-based applications have dominated aerial sensing research. However, a literature revision that combines both “deep learning” and “UAV remote sensing” thematics has not yet been conducted. The motivation for our work was to present a comprehensive review of the fundamentals of Deep Learning (DL) applied in UAV-based imagery. We focused mainly on describing the classification and regression techniques used in recent applications with UAV-acquired data. For that, a total of 232 papers published in international scientific journal databases was examined. We gathered the published materials and evaluated their characteristics regarding the application, sensor, and technique used. We discuss how DL presents promising results and has the potential for processing tasks associated with UAV-based image data. Lastly, we project future perspectives, commentating on prominent DL paths to be explored in the UAV remote sensing field. This revision consisting of an approach to introduce, commentate, and summarize the state-of-the-art in UAV-based image applications with DNNs algorithms in diverse subfields of remote sensing, grouping it in the environmental, urban, and agricultural contexts.}
}
@article{XIONG2020102994,
title = {Automated regional seismic damage assessment of buildings using an unmanned aerial vehicle and a convolutional neural network},
journal = {Automation in Construction},
volume = {109},
pages = {102994},
year = {2020},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2019.102994},
url = {https://www.sciencedirect.com/science/article/pii/S0926580519304224},
author = {Chen Xiong and Qiangsheng Li and Xinzheng Lu},
keywords = {Regional seismic damage assessment, GIS, UAV, Convolutional neural network},
abstract = {A rapid assessment of the seismic damage to buildings can facilitate improved emergency response and timely relief in earthquake-prone areas. In this study, an automated building seismic damage assessment method using an unmanned aerial vehicle (UAV) and a convolutional neural network (CNN) is introduced. The method consists of three parts: (1) data preparation, (2) building image segmentation, and (3) CNN-based building seismic damage assessment. First, a three-dimensional (3D) building model, aerial images, and camera data are used for the following simulation. Next, a building image segmentation method is proposed using the 3D building model as georeference, through which multi-view segmented building images can be obtained. Subsequently, a CNN model based on VGGNet is adopted to assess the seismic damage of each building. The CNN model is fine-tuned based on manually tagged building images obtained from the Internet. Finally, a case study of the old Beichuan town is used to demonstrate the effectiveness of the proposed method. The damage distribution of the area is obtained with an accuracy of 89.39%.}
}
@article{ZHAO2019588,
title = {Fast task allocation for heterogeneous unmanned aerial vehicles through reinforcement learning},
journal = {Aerospace Science and Technology},
volume = {92},
pages = {588-594},
year = {2019},
issn = {1270-9638},
doi = {https://doi.org/10.1016/j.ast.2019.06.024},
url = {https://www.sciencedirect.com/science/article/pii/S1270963818318704},
author = {Xinyi Zhao and Qun Zong and Bailing Tian and Boyuan Zhang and Ming You},
keywords = {Fast task allocation, Heterogeneous unmanned aerial vehicles, Reinforcement learning},
abstract = {A task allocation problem for heterogeneous unmanned aerial vehicles (UAVs) in the presence of environment uncertainty is studied in this paper. Generally, the process of finding efficient allocation scheme can be computationally prohibitive. This work presents a Q-learning based fast task allocation (FTA) algorithm through neural network approximation and prioritized experience replay, which effectively offloads the online computation to an offline learning procedure. Specifically, the proposed approach develops a Q network that encodes the allocation rules. The Q network not only considers the effect of environment uncertainty, but also is capable of handling total different tasks. Comparison simulations are provided to show the efficiency of the proposed algorithm.}
}
@article{ISHENGOMA2022101502,
title = {Hybrid convolution neural network model for a quicker detection of infested maize plants with fall armyworms using UAV-based images},
journal = {Ecological Informatics},
volume = {67},
pages = {101502},
year = {2022},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2021.101502},
url = {https://www.sciencedirect.com/science/article/pii/S1574954121002934},
author = {Farian S. Ishengoma and Idris A. Rai and Said Rutabayiro Ngoga},
keywords = {Maize, Fall armyworms, Unmanned aerial vehicle, Convolutional neural network},
abstract = {Visual detection of plants diseases over a large area is time-consuming, and the results are prone to errors due to the subjective nature of human evaluations. Several automatic disease detection techniques that improve detection time and improve accuracy compared to visual methods exist, yet they are not suitable for immediate detection. In this paper, we propose a hybrid convolution neural network (CNN) model to speed up the detection of fall armyworms (faw) infested maize leaves. Specifically, the proposed system combines unmanned aerial vehicle (UAV) technology, to autonomously capture maize leaves, and a hybrid CNN model, which is based on a parallel structure specifically designed to take advantage of the benefits of both individual models, namely VGG16 and InceptionV3. We compare the performance of the proposed model in terms of accuracy and training time to four existing CNN models, namely VGG16, InceptionV3, XceptionNet, and Resnet50. The results show that compared to existing models, the proposed hybrid model reduces the training time by 16% to 44% compared to other models while exhibiting the most superior accuracy of 96.98%.}
}
@article{LIU2021127546,
title = {Unmanned aerial vehicle and artificial intelligence revolutionizing efficient and precision sustainable forest management},
journal = {Journal of Cleaner Production},
volume = {311},
pages = {127546},
year = {2021},
issn = {0959-6526},
doi = {https://doi.org/10.1016/j.jclepro.2021.127546},
url = {https://www.sciencedirect.com/science/article/pii/S0959652621017649},
author = {Tiedong Liu and Yuxin Sun and Cai Wang and Yangyang Zhang and Zixuan Qiu and Wenfeng Gong and Shuhan Lei and Xinyu Tong and Xuanyu Duan},
keywords = {Unmanned aerial vehicle, Artificial intelligence, Tropical forest, Forest ecological monitoring, Sustainable forest management},
abstract = {The ecological value of tropical forests in water conservation district has been of great interest because of their rich vegetation types and higher biomass density than any other land cover types, it is urgent to evaluate the ecological value of tropical forests in water conservation district. However, the monitoring of tropical forests in water conservation district is faced with many problems, such as high forest density, complexity and diversity of the forest structure, complex topography and climate conditions, and the difficulty of access for investigators. In order to solve the above difficulties, this study combined 3D point cloud reconstruction based on Unmanned Aerial Vehicle - Structure from Motion (UAV-SfM) technology with forest type classification based on the Convolutional Neural Network (CNN) method, combined with a small amount of forest permanent sample plot survey data, to accurately evaluate the forest biomass distribution and forest biodiversity in water conservation district. The results show that the overall classification accuracy of the 20 forest types in water conservation district based on the CNN method is 0.61, the overall Kappa coefficient is 0.59, and the conditional Kappa coefficient is concentrated in the range of 0.43–0.85. The Root Mean Square Error (RMSE) of the plane measurement of UAV-SfM technology is 0.432 m, and the RMSE of the elevation measurement is 0.989 m, the effect of this UAV technology in tropical forest monitoring is superior. Using the techniques mentioned above, this study can effectively and accurately monitor and evaluate the biomass distribution and biodiversity of tropical forests in the water conservation district. Based on the precision forest ecological monitoring data, this study can develop a scientific and reasonable sustainable forest management plan for the water conservation district according to the distribution of forest biomass and biodiversity. The combination of UAV-SfM technology and the CNN method is an innovative attempt, and the integration of UAV and artificial intelligence technology solves practical problems faced by sustainable forest management. UAV and artificial intelligence will also provide an important foundation for forest ecological environment sustainability assessment research.}
}
@article{AMIRRUDDIN2022106646,
title = {Synthetic Minority Over-sampling TEchnique (SMOTE) and Logistic Model Tree (LMT)-Adaptive Boosting algorithms for classifying imbalanced datasets of nutrient and chlorophyll sufficiency levels of oil palm (Elaeis guineensis) using spectroradiometers and unmanned aerial vehicles},
journal = {Computers and Electronics in Agriculture},
volume = {193},
pages = {106646},
year = {2022},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2021.106646},
url = {https://www.sciencedirect.com/science/article/pii/S0168169921006633},
author = {Amiratul Diyana Amirruddin and Farrah Melissa Muharam and Mohd Hasmadi Ismail and Ngai Paing Tan and Mohd Firdaus Ismail},
keywords = {Nutrient, Chlorophyll, UAV, Spectroradiometer, Machine learning},
abstract = {The conventional method to quantify leaf biochemical properties (nutrients and chlorophylls) is tedious, labour-intensive, and impractical for vast oil palm plantation areas. Spectral analysis retrieved from a spectroradiometer and an unmanned aerial vehicle (UAV) and imbalanced approaches such as the Synthetic Minority Over-sampling TEchnique (SMOTE) and machine learning have given promising results for monitoring plant biochemical properties. However, the integration of these methods is not widely explored for oil palm. There are three primary aims of the current study. We evaluate the effectiveness of the integration of SMOTE, Logistic Model Tree (LMT), and Adaptive Boosting (AdaBoost) to address data imbalance problems for the assessment of the oil palm nutrients and chlorophylls status. The performance of the raw band and vegetation index (VI) extracted from the UAV in assessing leaf biochemical properties of mature oil palms is also addressed. Finally, we compare the competency of the spectral model retrieved from the spectroradiometer and UAV. In the study, nitrogen (N) treatments varying between 0 and 6 kg palm−1 were applied to mature Tenera palms. The integration of SMOTE with LMT and AdaBoost (LMT-SMOTEBoost) outperformed other approaches in classifying the leaf biochemical sufficiency status of mature oil palm. The VIs outperformed the raw band in discriminating the leaf biochemical properties at the canopy level. Both leaf and canopy spectral models obtained from spectroradiometer and UAV were comparable and produced good performance with balanced accuracy (BAcc) above 0.77. Using these techniques may provide palm oil plantation owners with a cost-effective way to monitor nutrient levels in palms more efficiently and comprehensively to ensure greater harvests and tree health.}
}
@article{ZHU2022103991,
title = {Pavement distress detection using convolutional neural networks with images captured via UAV},
journal = {Automation in Construction},
volume = {133},
pages = {103991},
year = {2022},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2021.103991},
url = {https://www.sciencedirect.com/science/article/pii/S0926580521004428},
author = {Junqing Zhu and Jingtao Zhong and Tao Ma and Xiaoming Huang and Weiguang Zhang and Yang Zhou},
keywords = {Asphalt pavement distress, Convolutional neural network (CNN), Object-detection algorithms, Unmanned aerial vehicle (UAV)},
abstract = {Pavement distress detection is crucial in the decision-making for maintenance planning. Unmanned aerial vehicles (UAVs) are helpful in collecting pavement images. This paper proposes the collection of pavement distress information using a UAV with a high-resolution camera. A UAV platform for pavement image collection was assembled, and the flight settings were studied for optimal image quality. The collected images were processed and annotated for model training. Three state-of-the-art object-detection algorithms—Faster R-CNN, YOLOv3, and YOLOv4, were used to train the dataset, and their prediction performances were compared. A pavement image dataset was established with six types of distress. YOLOv3 demonstrated the best performance of the three algorithms, with a mean average precision (MAP) of 56.6%. The findings of this study assist in the inspection of non-destructive automatic pavement conditions.}
}
@article{SRIVASTAVA2021102152,
title = {A survey of deep learning techniques for vehicle detection from UAV images},
journal = {Journal of Systems Architecture},
volume = {117},
pages = {102152},
year = {2021},
issn = {1383-7621},
doi = {https://doi.org/10.1016/j.sysarc.2021.102152},
url = {https://www.sciencedirect.com/science/article/pii/S1383762121001107},
author = {Srishti Srivastava and Sarthak Narayan and Sparsh Mittal},
keywords = {Review, Drone, “Unmanned aerial vehicle” (UAV), Deep learning, Vehicle detection, Object detection},
abstract = {“Unmanned aerial vehicles” (UAVs) are now being used for a wide range of surveillance applications. Specifically, the detection of on-ground vehicles from UAV images has attracted significant attention due to its potential in applications such as traffic management, parking lot management, and facilitating rescue operations in disaster zones and rugged terrains. This paper presents a survey of deep learning techniques for performing on-ground vehicle detection from aerial imagery captured using UAVs (also known as drones). We review the works in terms of their approach to improve accuracy and reduce computation overhead and their optimization objective. We show the similarities and differences of various techniques and also highlight the future challenges in this area. This survey will benefit researchers in the area of artificial intelligence, traffic surveillance, and applications of UAVs.}
}
@article{BOURSIANIS2020100187,
title = {Internet of Things (IoT) and Agricultural Unmanned Aerial Vehicles (UAVs) in smart farming: A comprehensive review},
journal = {Internet of Things},
pages = {100187},
year = {2020},
issn = {2542-6605},
doi = {https://doi.org/10.1016/j.iot.2020.100187},
url = {https://www.sciencedirect.com/science/article/pii/S2542660520300238},
author = {Achilles D. Boursianis and Maria S. Papadopoulou and Panagiotis Diamantoulakis and Aglaia Liopa-Tsakalidi and Pantelis Barouchas and George Salahas and George Karagiannidis and Shaohua Wan and Sotirios K. Goudos},
keywords = {Internet of Things, Unmanned Aerial Vehicles, Smart Farming, Wireless Sensor Networks, Agriculture, Survey},
abstract = {Internet of Things (IoT) and Unmanned Aerial Vehicles (UAVs) are two hot technologies utilized in cultivation fields, which transform traditional farming practices into a new era of precision agriculture. In this paper, we perform a survey of the last research on IoT and UAV technology applied in agriculture. We describe the main principles of IoT technology, including intelligent sensors, IoT sensor types, networks and protocols used in agriculture, as well as IoT applications and solutions in smart farming. Moreover, we present the role of UAV technology in smart agriculture, by analyzing the applications of UAVs in various scenarios, including irrigation, fertilization, use of pesticides, weed management, plant growth monitoring, crop disease management, and field-level phenotyping. Furthermore, the utilization of UAV systems in complex agricultural environments is also analyzed. Our conclusion is that IoT and UAV are two of the most important technologies that transform traditional cultivation practices into a new perspective of intelligence in precision agriculture.}
}
@article{FOTOHI2020100267,
title = {An agent-based self-protective method to secure communication between UAVs in unmanned aerial vehicle networks},
journal = {Vehicular Communications},
volume = {26},
pages = {100267},
year = {2020},
issn = {2214-2096},
doi = {https://doi.org/10.1016/j.vehcom.2020.100267},
url = {https://www.sciencedirect.com/science/article/pii/S2214209620300383},
author = {Reza Fotohi and Eslam Nazemi and Fereidoon {Shams Aliee}},
keywords = {Unmanned aerial vehicle networks (UAVNs), Secure communication, Agent-based self-protective, Self-adaptive, UAV},
abstract = {UAVNs (unmanned aerial vehicle networks) may become vulnerable to threats and attacks due to their characteristic features such as highly dynamic network topology, open-air wireless environments, and high mobility. Since previous work has focused on classical and metaheuristic-based approaches, none of these approaches have a self-adaptive approach. In this paper, the challenges and weaknesses of previous methods are examined in the form of a table. Furthermore, we propose an agent-based self-protective method (ASP-UAVN) for UAVNs that is based on the Human Immune System (HIS). In ASP-UAS, the safest route from the source UAV to the destination UAV is chosen according to a self-protective system. In this method, a multi-agent system using an Artificial Immune System (AIS) is employed to detect the attacking UAV and choose the safest route. In the proposed ASP-UAVN, the route request packet (RREQ) is initially transmitted from the source UAV to the destination UAV to detect the existing routes. Then, once the route reply packet (RREP) is received, a self-protective method using agents and the knowledge base is employed to choose the safest route and detect the attacking UAVs. The proposed ASP-UAVN has been validated and evaluated in two ways: simulation and theoretical analysis. The results of simulation evaluation and theory analysis showed that the ASP-UAS increases the Packet Delivery Rate (PDR) by more than 17.4, 20.8, and 25.91%, and detection rate by more than 17.2, 23.1, and 29.3%, and decreases the Packet Loss Rate (PLR) by more than 14.4, 16.8, and 20.21%, the false-positive and false-negative rate by more than 16.5, 25.3, and 31.21% those of SUAS-HIS, SFA and BRUIDS methods, respectively.}
}
@article{SHAHALAM2021115091,
title = {A survey of safe landing zone detection techniques for autonomous unmanned aerial vehicles (UAVs)},
journal = {Expert Systems with Applications},
volume = {179},
pages = {115091},
year = {2021},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2021.115091},
url = {https://www.sciencedirect.com/science/article/pii/S0957417421005327},
author = {Md {Shah Alam} and Jared Oluoch},
keywords = {UAV, Zone Detection, Camera Vision, LiDAR, Image Analysis, DEM, Path Planning},
abstract = {The age of automation is upon us. Few decades earlier, nearly all the flying vehicles were human-controlled. Nowadays, almost every air vehicle is partially automated or getting closer to full automation. This race towards full automation has led to the introduction of features like autopilot. Unmanned aerial vehicles (UAVs) are the tiniest version of all types of air vehicles. The widespread usage of autonomous UAVs has spawned the need for safe landing zone (SLZ) detection techniques for UAV landing. A SLZ detection becomes an important face of a mission when the UAV needs emergency landing due to the technical difficulties or adverse weather conditions on the way of its operation. Before directly proceeding for landing, a UAV has to decide whether the landing zones are safe or not. On-board visual sensors provide potential information of the ground surface in the form of image or signal. Different image processing and safe landing area detection (SLAD) algorithms are then used to identify the best possible landing sites from the input data. In this survey, we discuss indoor and outdoor landing zone detection techniques. We further classify outdoor landing zones as either static or dynamic and discuss existing literature in the specific categories. We critique the shortcomings of existing SLZ detection techniques while also acknowledging their contributions. Further, we point to potential areas of improvement and future directions of the safe landing zone detection algorithms we surveyed. This survey paper may be a useful tutorial for understanding the types of landing zones and landing zone detection techniques for the UAVs, the strengths of zone detection algorithms, and the open areas for future improvement and research.}
}
@article{ATITALLAH2021573,
title = {An Enhanced Randomly Initialized Convolutional Neural Network for Columnar Cactus Recognition in Unmanned Aerial Vehicle imagery},
journal = {Procedia Computer Science},
volume = {192},
pages = {573-581},
year = {2021},
note = {Knowledge-Based and Intelligent Information & Engineering Systems: Proceedings of the 25th International Conference KES2021},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2021.08.059},
url = {https://www.sciencedirect.com/science/article/pii/S1877050921015465},
author = {Safa Ben Atitallah and Maha Driss and Wadii Boulila and Anis Koubaa and Nesrine Atitallah and Henda Ben Ghézala},
keywords = {Convolutional neural networks, Weight initialization, Randomization, Remote sensing images, Recognition, Columnar cactus},
abstract = {Recently, Convolutional Neural Networks (CNNs) have made a great performance for remote sensing image classification. Plant recognition using CNNs is one of the active deep learning research topics due to its added-value in different related fields, especially environmental conservation and natural areas preservation. Automatic recognition of plants in protected areas helps in the surveillance process of these zones and ensures the sustainability of their ecosystems. In this work, we propose an Enhanced Randomly Initialized Convolutional Neural Network (ERI-CNN) for the recognition of columnar cactus, which is an endemic plant that exists in the Tehuacán-Cuicatlán Valley in southeastern Mexico. We used a public dataset created by a group of researchers that consists of more than 20000 remote sensing images. The experimental results confirm the effectiveness of the proposed model compared to other models reported in the literature like InceptionV3 and the modified LeNet-5 CNN. Our ERI-CNN provides 98% of accuracy, 97% of precision, 97% of recall, 97.5% as f1-score, and 0.056 loss.}
}
@article{ALCANTARA2021103778,
title = {Optimal trajectory planning for cinematography with multiple Unmanned Aerial Vehicles},
journal = {Robotics and Autonomous Systems},
volume = {140},
pages = {103778},
year = {2021},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2021.103778},
url = {https://www.sciencedirect.com/science/article/pii/S0921889021000634},
author = {Alfonso Alcántara and Jesús Capitán and Rita Cunha and Aníbal Ollero},
keywords = {Optimal trajectory planning, UAV cinematography, Multi-UAV coordination},
abstract = {This paper presents a method for planning optimal trajectories with a team of Unmanned Aerial Vehicles (UAVs) performing autonomous cinematography. The method is able to plan trajectories online and in a distributed manner, providing coordination between the UAVs. We propose a novel non-linear formulation for this challenging problem of computing multi-UAV optimal trajectories for cinematography; integrating UAVs dynamics and collision avoidance constraints, together with cinematographic aspects like smoothness, gimbal mechanical limits and mutual camera visibility. We integrate our method within a hardware and software architecture for UAV cinematography that was previously developed within the framework of the MultiDrone project; and demonstrate its use with different types of shots filming a moving target outdoors. We provide extensive experimental results both in simulation and field experiments. We analyze the performance of the method and prove that it is able to compute online smooth trajectories, reducing jerky movements and complying with cinematography constraints.}
}
@article{CHEN2021114505,
title = {Neighborhood global learning based flower pollination algorithm and its application to unmanned aerial vehicle path planning},
journal = {Expert Systems with Applications},
volume = {170},
pages = {114505},
year = {2021},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2020.114505},
url = {https://www.sciencedirect.com/science/article/pii/S0957417420311490},
author = {Yang Chen and Dechang Pi and Yue Xu},
keywords = {Flower pollination algorithm, Global optimization, Premature convergence, UAV path planning},
abstract = {Flower pollination algorithm (FPA) is a meta-heuristic optimization algorithm that imitates the pollination phenomenon of flowering plants in nature. Due to this algorithm is prone to premature convergence when solving complex optimization problems. So this paper introduces a neighborhood global learning based flower pollination algorithm(NGFPA). Firstly, we analyze the FPA using the constant coefficient differential equation and change the FPA’s global equation. Secondly, we build a neighborhood global learning to enhance population diversity. Finally, the population reconstruction mechanism is added to inhibit the population premature convergence. The convergence of NGFPA is proven using the knowledge of differential equations and stochastic function analysis. We test the performance of NGFPA by optimizing CEC2017. Experiment results show that NGFPA has better performance in comparison with other swarm intelligence algorithms. Furthermore, NGFPA is used to solve the problem of unmanned aerial vehicle (UAV) path planning. Simulation results indicate that NGFPA can obtain smoother paths in different obstacle environments. Therefore, NGFPA is effective and valuable.}
}
@article{DU2021103122,
title = {Cooperative pursuit of unauthorized UAVs in urban airspace via Multi-agent reinforcement learning},
journal = {Transportation Research Part C: Emerging Technologies},
volume = {128},
pages = {103122},
year = {2021},
issn = {0968-090X},
doi = {https://doi.org/10.1016/j.trc.2021.103122},
url = {https://www.sciencedirect.com/science/article/pii/S0968090X21001418},
author = {Wenbo Du and Tong Guo and Jun Chen and Biyue Li and Guangxiang Zhu and Xianbin Cao},
keywords = {Urban Air Mobility (UAM), Unmanned Aerial Vehicle (UAV), Multi-agent Reinforcement Learning (MARL)},
abstract = {Urban Air Mobility (UAM) is an emergent concept for future air transportation. With UAM, cargo and passengers will be transported on-demand in urban airspace. UAM has shown a promising prospect in mitigating ground congestion and providing people with an alternative mobility option. However, unauthorized unmanned aerial vehicles (UAVs) in urban airspace present a significant threat to safety of UAM, drawing significant attention from research communities recently. Among all solutions, cooperative pursuit using a team of UAVs is an effective countermeasure for unauthorized UAVs in urban airspace. In this paper, we model cooperative pursuit as a pursuit-evasion game problem (PEG) and propose a multi-agent reinforcement learning (MARL) based approach to solve the problem efficiently. The proposed approach incorporates novel cellular-enabled parameter sharing and curriculum learning schemes to enhance the capability of pursuer UAVs in capturing faster unauthorized UAVs in urban airspace. Extensive experiments have been conducted using simulated urban airspace in order to evaluate the performance of the proposed method. Experimental results demonstrate that by incorporating the parameter sharing scheme, the proposed methods provide much higher capturing rates in a shorter time. Such superiority is more evident when communication constraints are more stringent and/or unauthorized UAVs are faster.}
}
@article{CHEN2022101545,
title = {An efficient multi-objective ant colony optimization for task allocation of heterogeneous unmanned aerial vehicles},
journal = {Journal of Computational Science},
volume = {58},
pages = {101545},
year = {2022},
issn = {1877-7503},
doi = {https://doi.org/10.1016/j.jocs.2021.101545},
url = {https://www.sciencedirect.com/science/article/pii/S1877750321002015},
author = {Lizhi Chen and Wei-Li Liu and Jinghui Zhong},
keywords = {Unmanned aerial vehicles, Cooperative task allocation, Multi-objective Optimization, Ant colony optimization},
abstract = {Unmanned aerial vehicles (UAVs) have become powerful tools in modern military combat. How to properly allocate the tasks of heterogeneous UAVs in a combat is a fundamental and challenging problem. In this paper, we formulate the cooperative task allocation of heterogeneous UAVs as a constrained multi-objective optimization problem. To efficiently resolve the formulated problem, we further propose a multi-objective ant colony optimization (MOACO) algorithm with a new pheromone updating mechanism and four newly defined heuristic information. Simulation results on test cases with different scales and characteristics have shown that the proposed methods can perform better than several recently published algorithms, in terms of convergence speed, solution quality and solution diversity.}
}
@article{ZHENG202195,
title = {Growing status observation for oil palm trees using Unmanned Aerial Vehicle (UAV) images},
journal = {ISPRS Journal of Photogrammetry and Remote Sensing},
volume = {173},
pages = {95-121},
year = {2021},
issn = {0924-2716},
doi = {https://doi.org/10.1016/j.isprsjprs.2021.01.008},
url = {https://www.sciencedirect.com/science/article/pii/S0924271621000083},
author = {Juepeng Zheng and Haohuan Fu and Weijia Li and Wenzhao Wu and Le Yu and Shuai Yuan and Wai Yuk William Tao and Tan Kian Pang and Kasturi Devi Kanniah},
keywords = {Individual tree detection, Growing status, Oil palm, UAV images, Deep learning},
abstract = {For both the positive economic benefit and the negative ecological impact of the rapid expansion of oil palm plantations in tropical developing countries, it is significant to achieve accurate detection for oil palm trees in large-scale areas. Especially, growing status observation and smart oil palm plantation management enabled by such accurate detections would improve plantation planning, oil palm yield, and reduce manpower and consumption of fertilizer. Although existing studies have already reached a high accuracy in oil palm tree detection, rare attention has been paid to automated observation of each single oil palm tree’s growing status. Nowadays, with its high spatial resolution and low cost, Unmanned Aerial Vehicle (UAV) has become a promising tool for monitoring the growing status of individual oil palms. However, the accuracy is still a challenging issue because of the extreme imbalance and high similarity between different classes. In this paper, we propose a Multi-class Oil PAlm Detection approach (MOPAD) to reap both accurate detection of oil palm trees and accurate monitoring of their growing status. Based on Faster RCNN, MOPAD combines a Refined Pyramid Feature (RPF) module and a hybrid class-balanced loss module to achieve satisfying observation of the growing status for individual oil palms. The former takes advantage of multi-level features to distinguish similar classes and detect small oil palms, and the latter effectively resolves the problem of extremely imbalanced samples. Moreover, we elaborately analyze the distribution of different kinds of oil palms, and propose a practical workflow for detecting oil palm vacancy. We evaluate MOPAD using three large-scale UAV images photographed in two sites in Indonesia (denoted by Site 1 and Site 2), containing 363,877 oil palms of five categories: healthy palms, dead palms, mismanaged palms, smallish palms and yellowish palms. Our proposed MOPAD achieves an F1-score of 87.91% (Site 1) and 99.04% (Site 2) for overall oil palm tree detection, and outperforms other state-of-the-art object detection methods by a remarkable margin of 10.37–17.09% and 8.14%-21.32% with respect to the average F1-score for multi-class oil palm detection in Site 1 and Site 2, respectively. Our method demonstrates excellent potential for individual oil palm tree detection and observation of growing status from UAV images, leading to more precise and efficient management of oil palm plantations.}
}
@article{ULLAH2020107478,
title = {UAVs joint optimization problems and machine learning to improve the 5G and Beyond communication},
journal = {Computer Networks},
volume = {182},
pages = {107478},
year = {2020},
issn = {1389-1286},
doi = {https://doi.org/10.1016/j.comnet.2020.107478},
url = {https://www.sciencedirect.com/science/article/pii/S1389128620311518},
author = {Zaib Ullah and Fadi Al-Turjman and Uzair Moatasim and Leonardo Mostarda and Roberto Gagliardi},
keywords = {5G and B5G communication, UAVs, Artificial intelligence, Machine learning, Mobile edge computing, Software-defined networks, Internet of Things, mmWave communication, Smart city, Joint optimization},
abstract = {Recently, unmanned aerial vehicles (UAVs) have gained notable interest in various applications such as wireless coverage, aerial surveillance, precision agriculture, construction, power lines monitoring and blood delivery, etc. The UAVs implicit attributes e.g., rapid deployment, quick mobility, increase in flight duration, improvements in payload capacities, etc. , place it as an effective candidate for many applications in 5G and Beyond communications. The UAVs-assisted next-generation communications are determined to be highly influenced by various techniques and technologies like artificial intelligence (AI), machine learning (ML), deep reinforcement learning (DRL), mobile edge computing (MEC), and software-defined networks (SDN). In this article, we develop a review to investigate the UAVs joint optimization problems to enhance system efficiency. We classify the joint optimization problems based on the number of parameters used in proposed optimization problems. Moreover, we explore the impact of AI, ML, DRL, MEC, and SDN over UAVs joint optimization problems and present future research challenges and directions.}
}
@article{KYRIAKAKIS2021100956,
title = {Moving peak drone search problem: An online multi-swarm intelligence approach for UAV search operations},
journal = {Swarm and Evolutionary Computation},
volume = {66},
pages = {100956},
year = {2021},
issn = {2210-6502},
doi = {https://doi.org/10.1016/j.swevo.2021.100956},
url = {https://www.sciencedirect.com/science/article/pii/S2210650221001188},
author = {Nikolaos A. Kyriakakis and Magdalene Marinaki and Nikolaos Matsatsinis and Yannis Marinakis},
keywords = {Dynamic optimization, Moving peak benchmark, UAV, Swarm optimization, Humanitarian operations, Search and rescue},
abstract = {Many practical, real-world applications have dynamic features. This paper introduces a novel dynamic optimization problem applied to Unmanned Aerial Vehicle (UAV) search and rescue scenarios, named the Moving Peak Drone Search Problem (MPDSP). It utilizes the dynamic environment generator of the well-known Moving Peak Benchmark (MPB) and it is formulated as a maximization problem, with additional constraints imposed by the use of UAVs. For solving the MPDSP, a multi-swarm framework is proposed and seven optimization algorithms are tested. Five well known swarm intelligence algorithms and two algorithms effectively used in continuous and dynamic optimization problems. The implemented methods are evaluated and compared on 105 scenarios with 4 different UAV fleet configurations. Among the tested swarm intelligence variants, the Particle Swarm Optimization implementations proved to be the most effective for solving the MPDSP.}
}
@article{ZHOU2021,
title = {Improving multi-target cooperative tracking guidance for UAV swarms using multi-agent reinforcement learning},
journal = {Chinese Journal of Aeronautics},
year = {2021},
issn = {1000-9361},
doi = {https://doi.org/10.1016/j.cja.2021.09.008},
url = {https://www.sciencedirect.com/science/article/pii/S1000936121003423},
author = {Wenhong ZHOU and Jie LI and Zhihong LIU and Lincheng SHEN},
keywords = {Decentralized cooperation, Maximum reciprocal reward, Multi-agent actor-critic, Pointwise mutual information, Reinforcement learning},
abstract = {Multi-Target Tracking Guidance (MTTG) in unknown environments has great potential values in applications for Unmanned Aerial Vehicle (UAV) swarms. Although Multi-Agent Deep Reinforcement Learning (MADRL) is a promising technique for learning cooperation, most of the existing methods cannot scale well to decentralized UAV swarms due to their computational complexity or global information requirement. This paper proposes a decentralized MADRL method using the maximum reciprocal reward to learn cooperative tracking policies for UAV swarms. This method reshapes each UAV's reward with a regularization term that is defined as the dot product of the reward vector of all neighbor UAVs and the corresponding dependency vector between the UAV and the neighbors. And the dependence between UAVs can be directly captured by the Pointwise Mutual Information (PMI) neural network without complicated aggregation statistics. Then, the experience sharing Reciprocal Reward Multi-Agent Actor-Critic (MAAC-R) algorithm is proposed to learn the cooperative sharing policy for all homogeneous UAVs. Experiments demonstrate that the proposed algorithm can improve the UAVs’ cooperation more effectively than the baseline algorithms, and can stimulate a rich form of cooperative tracking behaviors of UAV swarms. Besides, the learned policy can better scale to other scenarios with more UAVs and targets.}
}
@article{ZHANG2021107004,
title = {Hybrid FWPS cooperation algorithm based unmanned aerial vehicle constrained path planning},
journal = {Aerospace Science and Technology},
volume = {118},
pages = {107004},
year = {2021},
issn = {1270-9638},
doi = {https://doi.org/10.1016/j.ast.2021.107004},
url = {https://www.sciencedirect.com/science/article/pii/S1270963821005149},
author = {Xiangyin Zhang and Shuang Xia and Tian Zhang and Xiuzhi Li},
keywords = {Path planning, Fireworks algorithm, Particle swarm optimization, Constraint optimization problem, Unmanned aerial vehicle},
abstract = {This paper considers the unmanned aerial vehicle (UAV) global path planning as an optimization problem with multiple constraints and proposes an improved fireworks algorithm (FWA) and particle swarm optimization (PSO) cooperation algorithm to generate an optimal path. The objective function of the UAV flight path is modeled to have the shortest length satisfying strict multiple threat area constraints. The α constrained method using the level comparison strategy is integrated into both FWA and PSO to enhance their superior constraint-handling ability. To increase the population diversity, the whole population is divided to fireworks and particles, which perform search operation in parallel. A new mutation strategy in the fireworks is adopted to avoid falling into the local optimum. Information sharing mechanism between fireworks and particles is established to make the population achieve the excellent global optimization performance. Several numerical simulations are carried out and the results show that our proposed algorithm performs well in obtaining high quality solutions and handling constraints.}
}
@article{ZHANG2022108194,
title = {Autonomous navigation of UAV in multi-obstacle environments based on a Deep Reinforcement Learning approach},
journal = {Applied Soft Computing},
volume = {115},
pages = {108194},
year = {2022},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2021.108194},
url = {https://www.sciencedirect.com/science/article/pii/S1568494621010383},
author = {Sitong Zhang and Yibing Li and Qianhui Dong},
keywords = {UAV, Path planning, Twin delayed deep deterministic policy gradients, Two-stream Actor–Critic Network},
abstract = {Path planning is one of the most essential part in autonomous navigation. Most existing works suppose that the environment is static and fixed. However, path planning is widely used in random and dynamic environment (such as search and rescue, surveillance and other scenarios). In this paper, we propose a Deep Reinforcement Learning (DRL)-based method that enables unmanned aerial vehicles (UAVs) to execute navigation tasks in multi-obstacle environments with randomness and dynamics. The method is based on the Twin Delayed Deep Deterministic Policy Gradients (TD3) algorithm. In order to predict the impact of the environment on UAV, the change of environment observations is added into the Actor–Critic network input, and the two-stream Actor–Critic network structure is proposed to extract features of environment observations. Simulations are carried out to evaluate the performance of the algorithm and experiment results show that our method can enable the UAV to complete autonomous navigation tasks safely in multi-obstacle environments, which reflects the efficiency of our method. Moreover, compared to DDPG and the conventional TD3, our method has better generalization ability.}
}
@article{ONEATA2021106943,
title = {Multimodal speech recognition for unmanned aerial vehicles},
journal = {Computers & Electrical Engineering},
volume = {90},
pages = {106943},
year = {2021},
issn = {0045-7906},
doi = {https://doi.org/10.1016/j.compeleceng.2020.106943},
url = {https://www.sciencedirect.com/science/article/pii/S0045790620307904},
author = {Dan Oneață and Horia Cucu},
keywords = {Automatic speech recognition, Multimodal learning, Domain adaptation, Unmanned aerial vehicles},
abstract = {Unmanned aerial vehicles (UAVs) are becoming widespread with applications ranging from film-making and journalism to rescue operations and surveillance. Research communities (speech processing, computer vision, control) are starting to explore the limits of UAVs, but their efforts remain somewhat isolated. In this paper we unify multiple modalities (speech, vision, language) into a speech interface for UAV control. Our goal is to perform unconstrained speech recognition while leveraging the visual context. To this end, we introduce a multimodal evaluation dataset, consisting of spoken commands and associated images, which represent the visual context of what the UAV “sees” when the pilot utters the command. We provide baseline results and address two main research directions. First, we investigate the robustness of the system by (i) training it with a partial list of commands, and (ii) corrupting the recordings with outdoor noise. We perform a controlled set of experiments by varying the size of the training data and the signal-to-noise ratio. Second, we look at how to incorporate visual information into our model. We show that we can incorporate visual cues in the pipeline through the language model, which we implemented using a recurrent neural network. Moreover, by using gradient activation maps the system can provide visual feedback to the pilot regarding the UAV’s understanding of the command. Our conclusions are that multimodal speech recognition can be successfully used in this scenario and that visual information helps especially when the noise level is high. The dataset and our code are available at http://kite.speed.pub.ro.}
}
@article{CHAMOLA2021102324,
title = {A Comprehensive Review of Unmanned Aerial Vehicle Attacks and Neutralization Techniques},
journal = {Ad Hoc Networks},
volume = {111},
pages = {102324},
year = {2021},
issn = {1570-8705},
doi = {https://doi.org/10.1016/j.adhoc.2020.102324},
url = {https://www.sciencedirect.com/science/article/pii/S1570870520306788},
author = {Vinay Chamola and Pavan Kotesh and Aayush Agarwal and  Naren and Navneet Gupta and Mohsen Guizani},
keywords = {UAV, Drone, Attacks, Neutralization, Jamming},
abstract = {Unmanned Aerial Vehicles (UAV) have revolutionized the aircraft industry in this decade. UAVs are now capable of carrying out remote sensing, remote monitoring, courier delivery, and a lot more. A lot of research is happening on making UAVs more robust using energy harvesting techniques to have a better battery lifetime, network performance and to secure against attackers. UAV networks are many times used for unmanned missions. There have been many attacks on civilian, military, and industrial targets that were carried out using remotely controlled or automated UAVs. This continued misuse has led to research in preventing unauthorized UAVs from causing damage to life and property. In this paper, we present a literature review of UAVs, UAV attacks, and their prevention using anti-UAV techniques. We first discuss the different types of UAVs, the regulatory laws for UAV activities, their use cases, recreational, and military UAV incidents. After understanding their operation, various techniques for monitoring and preventing UAV attacks are described along with case studies.}
}
@article{GAUTAM2021102993,
title = {A Model-based dehazing scheme for unmanned aerial vehicle system using radiance boundary constraint and graph model},
journal = {Journal of Visual Communication and Image Representation},
volume = {74},
pages = {102993},
year = {2021},
issn = {1047-3203},
doi = {https://doi.org/10.1016/j.jvcir.2020.102993},
url = {https://www.sciencedirect.com/science/article/pii/S1047320320302108},
author = {Sidharth Gautam and Tapan Kumar Gandhi and B.K. Panigrahi},
keywords = {Remote sensing, Satellite imaging, Unmanned aerial vehicle imaging, Image restoration, Image enhancement, Image dehazing},
abstract = {Unmanned aerial vehicle system (UAVs) imaging has become a challenging area of research due to the dynamic atmospheric environment. The images captured by UAVs are often deteriorated by factors such as clouds occlusion, poor atmospheric illumination, and limited capability of the imaging system. To tackle problems, this paper presents a novel visibility restoration scheme for UAVs images by considering the following two assumptions: (1) The actual scene radiance of a UAVs image is bounded. (2) Pixels sharing the same appearance must have the same transmission value in a local neighborhood. Inspired by above assumptions, an image boundary constraint utilizing the median filter has been imposed on the RGB channel for the rough estimation of transmission-map in aerial images. Furthermore, a graph-model based optimization technique has been used for the transmission-map refinement. The experimental results demonstrate the efficiency of the proposed method in terms of metrics correspond to the human-visual-system (HVS).}
}
@article{RIBEIRO2020104813,
title = {Remote inspection of RC structures using unmanned aerial vehicles and heuristic image processing},
journal = {Engineering Failure Analysis},
volume = {117},
pages = {104813},
year = {2020},
issn = {1350-6307},
doi = {https://doi.org/10.1016/j.engfailanal.2020.104813},
url = {https://www.sciencedirect.com/science/article/pii/S1350630720305227},
author = {D. Ribeiro and R. Santos and A. Shibasaki and P. Montenegro and H. Carvalho and R. Calçada},
keywords = {Remote structural inspection, UAV, Digital image processing, Heuristic feature-extraction, BIM},
abstract = {This article describes an innovative methodology for remote inspection of reinforced concrete (RC) structures using Unmanned Aerial Vehicles (UAVs) and based on advanced digital image processing. The use of specific heuristic feature-extraction methods, developed in MATLAB©, allows the automatic identification of various types of RC pathologies, particularly, biological colonies, efflorescences, cracks and exposed steel rebars. The developed inspection methodology is applied to the Monte da Virgem telecommunications tower, which has a total height of 177 m and is the highest structure of this kind in Portugal. The results demonstrate the efficiency and robustness of the methodology in: i) its ability to accurately locate and characterize the existing pathologies, ii) visualizing the full extent of pathologies in 3D photogrammetric reconstitutions of the structure, and iii) integrating the identified pathologies into a Building Information Modeling (BIM) model. The regular use of the proposed methodology over time will allow accurate monitoring of the evolution of pathologies to assess the condition of the structure. Additionally, the integration of the inspection results into BIM digital models will help infrastructure managers to decide on the implementation of the most adequate facility management strategies in order to optimize the scheduling of maintenance, rehabilitation and retrofitting interventions.}
}
@article{WEI2021108384,
title = {Estimating the spatial distribution of soil total arsenic in the suspected contaminated area using UAV-Borne hyperspectral imagery and deep learning},
journal = {Ecological Indicators},
volume = {133},
pages = {108384},
year = {2021},
issn = {1470-160X},
doi = {https://doi.org/10.1016/j.ecolind.2021.108384},
url = {https://www.sciencedirect.com/science/article/pii/S1470160X21010499},
author = {Lifei Wei and Yangxi Zhang and Qikai Lu and Ziran Yuan and Haibo Li and Qingbin Huang},
keywords = {Hyperspectral imagery, Soil total arsenic, Deep neural networks, Unmanned aerial vehicle (UAV)},
abstract = {The total arsenic (TAs) content in the soil is commonly used as an important indicator for evaluating soil pollution. However, the traditional methods for investigating TAs concentration in soil over a large area are always labor-intensive and costly. As a rapid and convenient technique, unmanned aerial vehicle (UAV) equipped with hyperspectral camera offers a promising way for estimating the distribution of TAs. In this study, we utilized UAV-borne hyperspectral data over the Daye city of China mining suspected contaminated area to establish the deep model for retrieval of TAs. Specifically, 74 soil samples were collected in situ from the study area, and their TAs contents were measured by using atomic fluorescence spectrometry(AFS). Meanwhile, use UAV captured hyperspectral imagery of the study area. We propose a novel method which deep neural networks with competitive adaptive reweighted sampling (DNN-CARS) for the estimation of soil TAs content and the spatial distribution. For two testing areas, the values of R2 are 0.90 and 0.87, and the value of RMSE are 0.33 and 0.52. Experiments demonstrated, that UAV hyperspectral imagery combined with DNN-CARS is an effective tool for the evaluation of TAs content and mapping its spatial distribution.}
}
@article{ALI2021103831,
title = {Real-time multiple damage mapping using autonomous UAV and deep faster region-based neural networks for GPS-denied structures},
journal = {Automation in Construction},
volume = {130},
pages = {103831},
year = {2021},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2021.103831},
url = {https://www.sciencedirect.com/science/article/pii/S092658052100282X},
author = {Rahmat Ali and Dongho Kang and Gahyun Suh and Young-Jin Cha},
keywords = {Deep learning, Damage detection, Vison-based, Autonomous UAV, Damage localization},
abstract = {An autonomous unmanned aerial vehicle (UAV) system integrated with a modified faster region-based convolutional neural network (Faster R-CNN) is proposed to identify various types of structural damage and to map the detected damage a GPS-denied environment. The proposed method reduces the number of false positives significantly using a real-time streaming protocol and multi-processing, particularly in the case of very small cracks in blurry videos due to the UAV vibrations. In comparative studies, the modified Faster R-CNN using ResNet-101 as the base network showed superior performance in detecting small and blurry defects with a mean average precision of 93.31% and mean intersection-over-union of 92.16% in video frames captured by the low-cost autonomous UAV. The autonomous flights of the UAV were tested in a real large-scale parking structure to account for the high wind effects during flight. The UAV successfully followed the desired trajectories, and the Faster R-CNN detected defects accurately.}
}
@article{KHAN2021108217,
title = {A blockchain-based decentralized machine learning framework for collaborative intrusion detection within UAVs},
journal = {Computer Networks},
volume = {196},
pages = {108217},
year = {2021},
issn = {1389-1286},
doi = {https://doi.org/10.1016/j.comnet.2021.108217},
url = {https://www.sciencedirect.com/science/article/pii/S1389128621002644},
author = {Ammar Ahmed Khan and Muhammad Mubashir Khan and Kashif Mehboob Khan and Junaid Arshad and Farhan Ahmad},
keywords = {Unmanned aerial vehicles, UAV, Blockchain, Machine learning, Decentralized machine learning, Collaborative intrusion detection},
abstract = {UAVs have numerous emerging applications in various domains of life. However, it is extremely challenging to gain the required level of public acceptance of UAVs without proving safety and security for human life. Conventional UAVs mostly depend upon the centralized server to perform data processing with complex machine learning algorithms. In fact, all the conventional cyber attacks are applicable on the transmission and storage of data in UAVs. While their impact is extremely serious because UAVs are highly dependent on smart systems that extensively utilize machine learning techniques in order to take decisions in human absence. In this regard, we propose to enhance the performance of UAVs with a decentralized machine learning framework based on blockchain. The proposed framework has the potential to significantly enhance the integrity and storage of data for intelligent decision making among multiple UAVs. We present the use of blockchain to achieve decentralized predictive analytics and present a framework that can successfully apply and share machine learning models in a decentralized manner. We evaluate our system using collaborative intrusion detection as a case-study in order to highlight the feasibility and effectiveness of using blockchain based decentralized machine learning approach in UAVs and other similar applications.}
}
@article{HUA2021107067,
title = {Research on many-to-many target assignment for unmanned aerial vehicle swarm in three-dimensional scenarios},
journal = {Computers & Electrical Engineering},
volume = {91},
pages = {107067},
year = {2021},
issn = {0045-7906},
doi = {https://doi.org/10.1016/j.compeleceng.2021.107067},
url = {https://www.sciencedirect.com/science/article/pii/S0045790621000811},
author = {Xiang Hua and Zhao Wang and Hongjuan Yao and Baohua Li and Chenglong Shi and Jiaxian Zuo},
keywords = {Unmanned aerial vehicle, Target assignment, Swarm intelligence optimization algorithm, Three-dimensional scenario},
abstract = {Target assignment for unmanned aerial vehicle (UAV) swarm has been a research hotspot in academic and industry communities. The current methods mainly focus on multiple targets assignment in planes or few targets assignment in solids. However, they ignore three-dimensional scenarios for UAV swarm and multiple targets characteristics for assignment problem. To solve these issues, we propose a multi-target intelligent assignment model. Firstly, we introduce damage cost and time cost to evaluate the system performance of swarm and time performance in three-dimensional scenarios. Then, we design a bio-inspired swarm intelligence optimization algorithm to find the optimal multiple targets assignment and to balance the two costs and multiple constraints simultaneously. This algorithm regards UAVs as several parallel biological sub-populations, which adopts the multi-layered optimization strategy to select the suitable assignment sequence. The simulation results demonstrate that the proposed method is effective for multi-target assignment in three-dimensional scenarios.}
}
@article{BEHJAT2019103270,
title = {Learning reciprocal actions for cooperative collision avoidance in quadrotor unmanned aerial vehicles},
journal = {Robotics and Autonomous Systems},
volume = {121},
pages = {103270},
year = {2019},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2019.103270},
url = {https://www.sciencedirect.com/science/article/pii/S0921889019301617},
author = {Amir Behjat and Steve Paul and Souma Chowdhury},
keywords = {Bio-inspired, Collision avoidance, Learning, Optimization, Unmanned Aerial Vehicle (UAV)},
abstract = {The ability to avoid collisions with each other is one of the fundamental requirements for autonomous unmanned aerial vehicles (UAVs) to be safely integrated into the civilian airspace, and for the viability of multi-UAV operations. This paper introduces a new approach for online cooperative collision avoidance between quadcopters, involving reciprocal maneuvers, i.e., coherent maneuvers without requiring any real-time consensus. Two maneuver strategies are presented, where UAVs respectively change their speed or heading to avoid a collision. A learning-based framework that trains these reciprocal actions for collision evasion (called TRACE) is developed. The primary elements of this framework include: 1) designing simulated experiments that cover a variety of UAV–UAV approach scenarios; 2) performing optimization to identify speed/heading change actions that satisfy safety constraints while minimizing the energy cost of the maneuver; and 3) using the offline optimization outcomes to train classifier (via ensemble bagged tree) and function approximation (via neural networks and Kriging) models for respectively selecting and encoding the avoidance actions. Trajectory generation and dynamics/controls are incorporated in the simulation environment used for training and testing. Over 90% accuracy in action prediction and over 95% success in avoiding collisions is observed when the trained models are applied to simulated unseen test scenarios.}
}
@article{JIANG2021115690,
title = {A diversified group teaching optimization algorithm with segment-based fitness strategy for unmanned aerial vehicle route planning},
journal = {Expert Systems with Applications},
volume = {185},
pages = {115690},
year = {2021},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2021.115690},
url = {https://www.sciencedirect.com/science/article/pii/S0957417421010757},
author = {Yuxin Jiang and Qing Wu and Guozhong Zhang and Shenke Zhu and Wei Xing},
keywords = {Unmanned aerial vehicle, Group teaching optimization algorithm, Three-dimensional route planning},
abstract = {The complexity and diversity of the flight environment pose great challenges to unmanned aerial vehicle route planning, which demands feasible flight strategies and efficient route planning algorithms. To address the issue, this paper constructs a 3-D flight environment model with multiple obstacles, and designs a novel diversified group teaching optimization algorithm for the generation of flight routes of unmanned aerial vehicles. In the environment model, a variety of obstacles are taken into consideration to make the flying scenarios more realistic, including mountain, cuboid, cylinder and triangular prism, and corresponding strategies are presented for unmanned aerial vehicles to safely avoid these obstacles. In the proposed algorithm, three novel teaching methods are introduced to balance the exploitation and exploration phases. Besides, a novel constrained optimization strategy is adopted, in which constraints are incrementally added to the fitness function to avoid the premature phenomenon in the initial iteration stage of algorithm. The experimental results show that compared with several state-of-the-art optimization algorithms, the proposed algorithm is significantly superior and can always generate the optimal flight route in complicated environments.}
}
@article{ZHOU2021285,
title = {Multi-target tracking for unmanned aerial vehicle swarms using deep reinforcement learning},
journal = {Neurocomputing},
volume = {466},
pages = {285-297},
year = {2021},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2021.09.044},
url = {https://www.sciencedirect.com/science/article/pii/S0925231221014223},
author = {Wenhong Zhou and Zhihong Liu and Jie Li and Xin Xu and Lincheng Shen},
keywords = {UAV swarms, Multi-target tracking, Multi-agent reinforcement learning, Scalability, Feature representation},
abstract = {In recent years, deep reinforcement learning (DRL) has proved its great potential in multi-agent cooperation. However, how to apply DRL to multi-target tracking (MTT) problem for unmanned aerial vehicle (UAV) swarms is challenging: 1) the scale of UAVs may be large, but the existing multi-agent reinforcement learning (MARL) methods that rely on global or joint information of all agents suffer from the dimensionality curse; 2) the dimension of each UAV’s received information is variable, which is incompatible with the neural networks with fixed input dimensions; 3) the UAVs are homogeneous and interchangeable that each UAV’s policy should be irrelevant to the permutation of its received information. To this end, we propose a DRL method for UAV swarms to solve the MTT problem. Firstly, a decentralized swarm-oriented Markov Decision Process (MDP) model is presented for UAV swarms, which involves each UAV’s local communication and partial observation. Secondly, to achieve better scalability, a cartogram feature representation (FR) is proposed to integrate the variable-dimensional information set into a fixed-shape input variable, and the cartogram FR can also maintain the permutation irrelevance to the information. Then, the double deep Q-learning network with dueling architecture is adapted to the MTT problem, and the experience-sharing training mechanism is adopted to learn the shared cooperative policy for UAV swarms. Extensive experiments are provided and the results show that our method can successfully learn a cooperative tracking policy for UAV swarms and outperforms the baseline method in the tracking ratio and scalability.}
}
@article{KAKO2020111127,
title = {Estimation of plastic marine debris volumes on beaches using unmanned aerial vehicles and image processing based on deep learning},
journal = {Marine Pollution Bulletin},
volume = {155},
pages = {111127},
year = {2020},
issn = {0025-326X},
doi = {https://doi.org/10.1016/j.marpolbul.2020.111127},
url = {https://www.sciencedirect.com/science/article/pii/S0025326X20302459},
author = {Shin'ichiro Kako and Shohei Morita and Tetsuya Taneda},
keywords = {Plastic marine debris, UAV, Image processing, Deep learning},
abstract = {Plastic marine debris (PMD) is of global concern. To help address this problem, a novel approach for estimating PMD volumes using a combination of unmanned aerial vehicle (UAV) surveys and image processing based on deep learning is proposed. A three-dimensional model and orthoscopic image of a beach, constructed via Structure from Motion software using UAV-derived data, enabled PMD volumes to be computed by edge detection through image processing. The accuracy of the method was verified by estimating the volumes of test debris placed on a beach in known sizes and shapes. The proposed approach shows potential for estimating PMD volumes with an error of <5%. Compared with subjective methods based on beach surveys, this approach can accurately, rapidly, and objectively calculate the PMD volume on a beach and can be used to improve the efficiency of beach surveys and identify beaches that need preferential cleaning.}
}
@article{XU2021102511,
title = {Cotton yield estimation model based on machine learning using time series UAV remote sensing data},
journal = {International Journal of Applied Earth Observation and Geoinformation},
volume = {104},
pages = {102511},
year = {2021},
issn = {0303-2434},
doi = {https://doi.org/10.1016/j.jag.2021.102511},
url = {https://www.sciencedirect.com/science/article/pii/S030324342100218X},
author = {Weicheng Xu and Pengchao Chen and Yilong Zhan and Shengde Chen and Lei Zhang and Yubin Lan},
keywords = {UAV remote sensing, Multisource data fusion, Neural networks, Cotton yield forecast},
abstract = {Crop yield prediction is of great practical significance for farmers to make reasonable decisions, such as decisions on crop insurance, storage demand, cash flow budget, fertilizer, water and other input factors. The traditional yield measurement method is sampling surveys, which require a large area of destructive sampling of cotton fields and consume considerable time and labor costs. This study established a cotton yield estimation model based on time series Unmanned Aerial Vehicle (UAV) remote sensing data. The U-Net semantic segmentation network is used to recognize and extract the boll opening pixels in high-resolution visible images, and the boll opening pixel percentage (BOP) is calculated according to the network extraction results. By combining the multispectral images and the pixel coverage of cotton bolls, a Bayesian regularization BP (back propagation) neural network was used to predict cotton yields. In order to simplify the input parameters of the model, the stepwise sensitivity analysis method is used to eliminate redundant variables and obtain the optimal input feature set. The experimental results show that the R2 of the proposed model is 0.853 at the scale of 0.81 m2 (average results of ten-fold cross validation). This study provides a method that can simultaneously meet the requirements of large-area and small-scale forecasting of cotton yields and provides a new idea for cotton yield measurement and breeding screening.}
}
@article{HAMYLTON2020102085,
title = {Evaluating techniques for mapping island vegetation from unmanned aerial vehicle (UAV) images: Pixel classification, visual interpretation and machine learning approaches},
journal = {International Journal of Applied Earth Observation and Geoinformation},
volume = {89},
pages = {102085},
year = {2020},
issn = {0303-2434},
doi = {https://doi.org/10.1016/j.jag.2020.102085},
url = {https://www.sciencedirect.com/science/article/pii/S0303243419310293},
author = {S.M. Hamylton and R.H. Morris and R.C. Carvalho and N. Roder and P. Barlow and K. Mills and L. Wang},
keywords = {Lomandra, Convolutional neural network, Five Islands nature reserve},
abstract = {We evaluate three approaches to mapping vegetation using images collected by an unmanned aerial vehicle (UAV) to monitor rehabilitation activities in the Five Islands Nature Reserve, Wollongong (Australia). Between April 2017 and July 2018, four aerial surveys of Big Island were undertaken to map changes to island vegetation following helicopter herbicide sprays to eradicate weeds, including the creeper Coastal Morning Glory (Ipomoea cairica) and Kikuyu Grass (Cenchrus clandestinus). The spraying was followed by a large scale planting campaign to introduce native plants, such as tussocks of Spiny-headed Mat-rush (Lomandra longifolia). Three approaches to mapping vegetation were evaluated, including: (i) a pixel-based image classification algorithm applied to the composite spectral wavebands of the images collected, (ii) manual digitisation of vegetation directly from images based on visual interpretation, and (iii) the application of a machine learning algorithm, LeNet, based on a deep learning convolutional neural network (CNN) for detecting planted Lomandra tussocks. The uncertainty of each approach was assessed via comparison against an independently collected field dataset. Each of the vegetation mapping approaches had a comparable accuracy; for a selected weed management and planting area, the overall accuracies were 82 %, 91 % and 85 % respectively for the pixel based image classification, the visual interpretation / digitisation and the CNN machine learning algorithm. At the scale of the whole island, statistically significant differences in the performance of the three approaches to mapping Lomandra plants were detected via ANOVA. The manual digitisation took a longer time to perform than others. The three approaches resulted in markedly different vegetation maps characterised by different digital data formats, which offered fundamentally different types of information on vegetation character. We draw attention to the need to consider how different digital map products will be used for vegetation management (e.g. monitoring the health individual species or a broader profile of the community). Where individual plants are to be monitored over time, a feature-based approach that represents plants as vector points is appropriate. The CNN approach emerged as a promising technique in this regard as it leveraged spatial information from the UAV images within the architecture of the learning framework by enforcing a local connectivity pattern between neurons of adjacent layers to incorporate the spatial relationships between features that comprised the shape of the Lomandra tussocks detected.}
}
@article{QIU2021106421,
title = {Estimation of nitrogen nutrition index in rice from UAV RGB images coupled with machine learning algorithms},
journal = {Computers and Electronics in Agriculture},
volume = {189},
pages = {106421},
year = {2021},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2021.106421},
url = {https://www.sciencedirect.com/science/article/pii/S0168169921004385},
author = {Zhengchao Qiu and Fei Ma and Zhenwang Li and Xuebin Xu and Haixiao Ge and Changwen Du},
keywords = {Rice, Nitrogen nutrition index, Unmanned aerial vehicle, Machine learning, Precision fertilization},
abstract = {Rapid and accurate estimation of rice Nitrogen Nutrition Index (NNI) is beneficial for management of nitrogen application in rice production. Traditional estimation methods required manual actual measurement data in the field, which was time-consuming and cost-expensive, and RGB images from unmanned aerial vehicle (UAV) provided an alternative option for nitrogen nutrition index (NNI) monitoring. In this study, RGB images from unmanned aerial vehicle (UAV) were obtained from each growth period of rice, and six machine learning (ML) algorithms, i.e., adaptive boosting (AB), artificial neural network (ANN), K-nearest neighbor (KNN), partial least squares (PLSR), random forest (RF) and support vector machine (SVM), were used to extract target information for estimating NNI as well as vegetation index (VI). Results showed that most UAV VIs were significantly correlated with rice NNI at the key growing periods; the estimation results of rice NNI using six ML algorithms showed that the RF algorithms performed the best at each growth period with the determination coefficient (R2) ranged from 0.88 to 0.96 and room mean square error (RMSE) ranged from 0.03 to 0.07, in which the estimation of NNI was the best in filling period and the early jointing stage. Rice NNI at the early jointing stage was significantly correlated with soil available nitrogen (AN) with the R2 of 0.84 in Pukou and 0.72 in Luhe, respectively, and rice NNI was significantly correlated with the yield with the R2 of more than 0.7 in Pukou at the whole period and more than 0.7 in Luhe from late jointing to maturity stage. Therefore, the combination of RGB images from UAV and ML algorithms was a scalable, simple and inexpensive method for rapid qualification of rice NNI, which effectively improved nitrogen use efficiency and provided guidance for precision fertilization in rice production.}
}
@article{WEI2021108439,
title = {Computation offloading over multi-UAV MEC network: A distributed deep reinforcement learning approach},
journal = {Computer Networks},
volume = {199},
pages = {108439},
year = {2021},
issn = {1389-1286},
doi = {https://doi.org/10.1016/j.comnet.2021.108439},
url = {https://www.sciencedirect.com/science/article/pii/S1389128621003984},
author = {Dawei Wei and Jianfeng Ma and Linbo Luo and Yunbo Wang and Lei He and Xinghua Li},
keywords = {Multi-UAV assisted MEC-enabled network, Computation offloading, Distributed reinforcement learning},
abstract = {Unmanned aerial vehicle (UAV)-assisted computation offloading allows mobile devices (MDs) to process computation-intensive and latency-sensitive tasks with limited or no-available infrastructures. To achieve long-term performance under changing environment, deep reinforcement-based methods have been applied to solve the UAV-assisted computation offloading problem. However, the deployment of multiple UAVs for computation offloading in mobile edge computing (MEC) network still faces the challenge of lacking flexible learning scheme to efficiently adjust computation offloading policy according to dynamic UAV mobility pattern and UAV failure. To this end, a distributed deep reinforcement learning (DRL)-based method with the cooperative exploring and prioritized experience replay (PER) is proposed in this paper. Our distributed exploring process achieves flexible learning scheme under UAV failure by allowing MDs to learning cost-efficient offloading policy cooperatively. Furthermore, PER allows MDs can explore the transitions with high TD-error, which can improve the performance under dynamic UAV mobility patterns. The efficiency of the proposed method is demonstrated by comparing with the existing computation offloading methods, and results show that the proposed method outperforms the compared methods in terms of convergence rate, energy-task efficiency and average processing time.}
}
@article{RAMACHANDRAN2021215,
title = {A review on object detection in unmanned aerial vehicle surveillance},
journal = {International Journal of Cognitive Computing in Engineering},
volume = {2},
pages = {215-228},
year = {2021},
issn = {2666-3074},
doi = {https://doi.org/10.1016/j.ijcce.2021.11.005},
url = {https://www.sciencedirect.com/science/article/pii/S2666307421000267},
author = {Anitha Ramachandran and Arun Kumar Sangaiah},
keywords = {Object detection, UAV, Drone, Deep learning, Precision agriculture, Security},
abstract = {Purpose
Computer vision in drones has gained a lot of attention from artificial intelligence researchers. Providing intelligence to drones will resolve many real-time problems. Computer vision tasks such as object detection, object tracking, and object counting are significant tasks for monitoring specified environments. However, factors such as altitude, camera angle, occlusion, and motion blur make it a more challenging task.
Methodology
In this paper, a detailed literature review has been conducted focusing on object detection and tracking using UAVs concerning different applications. This study summarizes the findings of existing research papers and identifies the research gaps.
Contribution
Object detection methods applied in UAV images are classified and elaborated. UAV datasets specific to object detection tasks are listed. Existing research works in different applications are summarized. Finally, a secure onboard processing system on a robust object detection framework in precision agriculture is proposed to mitigate identified research gaps.}
}
@article{PERRY2020108048,
title = {Streamlined bridge inspection system utilizing unmanned aerial vehicles (UAVs) and machine learning},
journal = {Measurement},
volume = {164},
pages = {108048},
year = {2020},
issn = {0263-2241},
doi = {https://doi.org/10.1016/j.measurement.2020.108048},
url = {https://www.sciencedirect.com/science/article/pii/S0263224120305868},
author = {Brandon J. Perry and Yanlin Guo and Rebecca Atadero and John W. {van de Lindt}},
keywords = {Computer vision, Machine learning, Structural Health Monitoring (SHM), Unmanned Aerial Vehicles (UAVs), Bridge Information Model (BrIM), Bridge inspection},
abstract = {Recently, the rapid development of commercial unmanned aerial vehicles (UAVs) has made collecting images of bridge conditions trivial. Measuring the damage extent, growth, and location from the collected big image set, however, can be cumbersome. This paper proposes a streamlined bridge inspection system that offers advanced data analytics tools to automatically: (1) identify type, extent, growth, and 3D location of defects using computer vision techniques; (2) generate a 3D point-cloud model and segment structural elements using human-in-the-loop machine learning; and (3) establish a georeferenced element-wise as-built bridge information model to document and visualize damage information. This system allows bridge managers to better leverage UAV technologies in bridge inspection and conveniently monitor the health of a bridge through quantifying and visualizing the progression of damage for each structural element. The efficacy of the system is demonstrated using two bridges.}
}
@article{LUNGU2022107261,
title = {Backstepping and dynamic inversion control techniques for automatic landing of fixed wing unmanned aerial vehicles},
journal = {Aerospace Science and Technology},
volume = {120},
pages = {107261},
year = {2022},
issn = {1270-9638},
doi = {https://doi.org/10.1016/j.ast.2021.107261},
url = {https://www.sciencedirect.com/science/article/pii/S1270963821007719},
author = {Mihai Lungu},
keywords = {Landing, Dynamic inversion, Backstepping, Atmospheric turbulence, Sensor errors, Lyapunov},
abstract = {The landing control of the unmanned aerial vehicles is a very difficult task having in mind both the external disturbances and their strong nonlinear dynamics with channel interferences. Motivated by this fact, this paper deals with the design of a novel automatic landing system (ALS) for a tailless and fixed blended wing unmanned aerial vehicle (UAV) having mobile centre of mass. By using the backstepping and the dynamic inversion control techniques, a novel auto-landing system is designed and software validated to control the aircraft during all the three landing phases (final approach, glide slope phase, flare) and handle the external disturbances such as the atmospheric turbulences and the errors of the measurement sensors. The dynamics of the aircraft involves the interconnection between the motions in the longitudinal and lateral-directional planes in contrast to other works where the dynamics has been separately linearized before developing of the control laws. The auto-landing system consists of two controllers (for the attitude angles and the forward speed of the UAV), an adaptive observer (for the estimation of the atmospheric turbulences), four reference models (to obtain the desired attitude angles and forward speed). This novel control architecture also uses the desired landing geometry and the operating conditions associated to a default trajectory defined by means of the calculated attitude angles and velocity of the UAV. The first controller (based on the backstepping control technique) provides the deflections of the three control surfaces, while the second one (based on the dynamic inversion technique) provides the throttle command to maintain a constant airspeed. The deviation of the UAV from the runway is cancelled and the desired landing trajectory is followed accurately. The results of the numerical simulations show the fulfilment of all the control objectives, including here the steady and the transient performances of the tracking errors, as well as the robustness relative to the atmospheric turbulences, the errors of the measurement sensors, and the motion of the mass centre.}
}
@article{BARBOSA2021100010,
title = {UAV-based coffee yield prediction utilizing feature selection and deep learning},
journal = {Smart Agricultural Technology},
volume = {1},
pages = {100010},
year = {2021},
issn = {2772-3755},
doi = {https://doi.org/10.1016/j.atech.2021.100010},
url = {https://www.sciencedirect.com/science/article/pii/S2772375521000101},
author = {Brenon Diennevan Souza Barbosa and Gabriel Araújo e Silva Ferraz and Lucas Costa and Yiannis Ampatzidis and Vinay Vijayakumar and Luana Mendes {dos Santos}},
keywords = {Deep-learning, Remote sensing, UAV imagery, Yield prediction},
abstract = {Unmanned Aerial Vehicles (UAVs) combined with machine learning have a great potential for crop yield estimation. In this study, a UAV equipped with an RGB (Red, Green, Blue) camera and computer vision algorithms were used to estimate coffee tree height and crown diameter, and for the prediction of coffee yield. Data were collected for 144 trees between June 2017 and May 2018, in the Minas Gerais, Brazil. Six parameters (leaf area index - LAI, tree height, crown diameter, and the individual RGB band values) were used to develop UAV-based yield prediction models. First, a feature ranking was performed to identify the most significant parameter(s) and month(s) for data collection and yield prediction. Based on the feature rankings, the LAI and the crown diameter were determined as the most important parameters. Five algorithms were used to develop yield prediction models: (i) linear support vector machines (SVM), (ii) gradient boosting regression (GBR), (iii) random forest regression (RFR), (iv) partial least square regression (PLSR), and (v) neuroevolution of augmenting topologies (NEAT). The mean absolute percentage error (MAPE) was used to evaluate the yield prediction models. The best result was obtained by the NEAT algorithm (MAPE of 31.75%) for a reduced dataset containing only the most important features (LAI and the crown diameter) and the most important months (December 2017 and April 2018). The results suggest that a dataset of the most important month (December) could be used for the yield prediction model, reducing the need for extensive data collection (e.g., monthly data collection).}
}
@article{NAVARRO2020111747,
title = {The application of Unmanned Aerial Vehicles (UAVs) to estimate above-ground biomass of mangrove ecosystems},
journal = {Remote Sensing of Environment},
volume = {242},
pages = {111747},
year = {2020},
issn = {0034-4257},
doi = {https://doi.org/10.1016/j.rse.2020.111747},
url = {https://www.sciencedirect.com/science/article/pii/S0034425720301176},
author = {Alejandro Navarro and Mary Young and Blake Allan and Paul Carnell and Peter Macreadie and Daniel Ierodiaconou},
keywords = {Mangrove, Unmanned aerial vehicle, Individual tree segmentation, Above-ground biomass, Cost-benefit analysis},
abstract = {Mangrove ecosystems are targeted for many conservation and rehabilitation efforts due to their ability to store large amounts of carbon in their living biomass and soil. Traditional methods to monitor above-ground biomass (AGB) rely on on-ground measurements, which are expensive, labour intensive and cover small spatial scales. Structure from Motion and Multi-View Stereo reconstructions from Unmanned Aerial Vehicles imagery (UAV-SfM) have the potential to increase fieldwork efficiency by providing a greater amount of spatial information in less time. However, there is still a need to assess the ability of UAV-SfM to retrieve structural information of mangrove forests, which could pose challenges in areas of high forest complexity and density. In this study we successfully used UAV-SfM data to estimate height, canopy diameter and AGB of natural and rehabilitated mangrove forests across two regions of the southeastern coast of Australia. We used a variable window filter algorithm to detect trees with an 80% detection rate when considering the top canopy. Individual tree canopy segmentation was performed using a marker-controlled watershed segmentation with two sets of constraining markers: treetops and a minimum height below which a pixel is not considered part of a tree. Direct comparison with on-ground measurements at the regional level showed no significant difference in tree height and AGB medians when only top canopy was considered. Similarly, median canopy diameters were not significantly different in natural areas of both regions, but significant differences were found in rehabilitated areas. UAV-SfM estimates of AGB were on average 15% lower in natural areas and 10% higher in rehabilitated areas when compared to on-ground measurements and followed a strong linear relationship close to the ideal one-to-one relationship. Additionally, we performed a cost-benefit analysis of the two methodologies. UAV-SfM methods can save almost AU$ 50,000 per ha when compared to on-ground measurements and become cost-effective (based on total costs) after just 15 days of surveys. The methods described in this study open the possibility for easily repeatable, low-cost UAV-SfM surveys for local managers by providing a faster, more cost-effective approach for monitoring mangrove forests over larger areas than traditional on-ground surveys while maintaining forest inventory data accuracy in both natural and rehabilitated mangrove forests.}
}
@article{YU2022101582,
title = {UAV path design with connectivity constraint based on deep reinforcement learning},
journal = {Physical Communication},
pages = {101582},
year = {2022},
issn = {1874-4907},
doi = {https://doi.org/10.1016/j.phycom.2021.101582},
url = {https://www.sciencedirect.com/science/article/pii/S1874490721002822},
author = {Lin Yu and Fahui Wu and Zhihai Xu and Zhigang Xie and Dingcheng Yang},
keywords = {Cellular-connected communication, Deep reinforcement learning, Trajectory optimization},
abstract = {Cellular networks are expected to communicate effectively with unmanned aerial vehicles (UAVs) and support various applications. However, existing cellular networks are primarily designed to cover users on the ground; thus, coverage holes in the sky will exist. In this paper, we investigate the problem of path design for cellular-connected UAVs, taking into account the interruption performance throughout the UAV mission to minimize the completion time. Two types of connectivity constraints requirements are assumed to be available. The first is defined as the maximum continuous time interval that the UAV loses connection with base stations (BSs) below a predefined threshold. For the second, we consider the sum outage of UAV is limited during the entire UAV mission. The UAV is tasked with flying from a starting location to a final destination while minimization the mission time, satisfying the two constraints, separately. The formulated path design problem which involves continues variables and a dynamic radio environment, is not convex and thus is extremely difficult to solve directly. To tackle this challenge, a deep reinforcement learning (DRL) based trajectory design algorithm is proposed, where the Dueling Double Deep Q Network(Dueling DDQN) with multi-steps learning method is applied. Simulation results demonstrate the effectiveness of the proposed DRL algorithm and achieve a trade-off between the trajectory length of the UAV and connection quality.}
}
@article{BANGUI2021877,
title = {Recent Advances in Machine-Learning Driven Intrusion Detection in Transportation: Survey},
journal = {Procedia Computer Science},
volume = {184},
pages = {877-886},
year = {2021},
note = {The 12th International Conference on Ambient Systems, Networks and Technologies (ANT) / The 4th International Conference on Emerging Data and Industry 4.0 (EDI40) / Affiliated Workshops},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2021.04.014},
url = {https://www.sciencedirect.com/science/article/pii/S1877050921007894},
author = {Hind Bangui and Barbora Buhnova},
keywords = {Machine learning, VANET, UAV, Intrusion Detection Systems, Trust, Security},
abstract = {Rapid developments in Intelligent Transportation Systems (ITSs) have emerged as a new research field for building sustainable smart cities. VANET (vehicular ad hoc network) is one of the emergent transportation technologies that has a great impact on ensuring mainly traffic management and road safety in urban areas by effciently using data sharing among vehicles. To further increase the security and safety of passengers and drivers, ITSs are continually striving to make the fusion of emergent network technologies to provide more reliable and effcient services. Relating VANET to UAV (unmanned aerial vehicle) is an example of this fusion, where UAVs act as an assistant to vehicles aiming to extend the network connectivity while effciently avoiding obstacles (e.g., Buildings) and providing high data delivery ratios. However, VANET and UAV are still critical security subjects that must be addressed. Advanced Machine Learning (e.g., Deep Learning) techniques have recently been used to protect VANET and UAV communications against various cyber attacks that deteriorate the integrity, confidentiality, and availability of vehicular data. Thus, in this paper, we focus on reviewing related work on machine learning techniques for intrusion detection systems in VANET- and UAV-aided networks. We also highlight the main open research challenges in literature and provide hints for improving security in ITSs.}
}
@article{GUO2018155,
title = {A hybrid feature model and deep learning based fault diagnosis for unmanned aerial vehicle sensors},
journal = {Neurocomputing},
volume = {319},
pages = {155-163},
year = {2018},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2018.08.046},
url = {https://www.sciencedirect.com/science/article/pii/S0925231218309962},
author = {Dingfei Guo and Maiying Zhong and Hongquan Ji and Yang Liu and Rui Yang},
keywords = {Model based fault diagnosis, Deep learning, Short-time fourier transform, Convolutional neural network, UAV sensors},
abstract = {Fault diagnosis plays an important role in guaranteeing system safety and reliability for unmanned aerial vehicles (UAVs). In this study, a hybrid feature model and deep learning based fault diagnosis for UAV sensors is proposed. The residual signals of different sensor faults, including global positioning system (GPS), inertial measurement unit (IMU), air data system (ADS), were collected. This paper used short time fourier transform (STFT) to transform the residual signal to the corresponding time-frequency map. Then, a convolutional neural network (CNN) was used to extract the feature of the map and the fault diagnosis of the UAV sensors was implemented. Finally, the performance of the proposed methodology is evaluated through flight experiments of the UAV. From the visualization, the sensor faults information can be extracted by CNN and the fault diagnosis logic between the residuals and the health status can be constructed successfully.}
}
@article{ZHENG2020105223,
title = {Early season detection of rice plants using RGB, NIR-G-B and multispectral images from unmanned aerial vehicle (UAV)},
journal = {Computers and Electronics in Agriculture},
volume = {169},
pages = {105223},
year = {2020},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2020.105223},
url = {https://www.sciencedirect.com/science/article/pii/S0168169919305009},
author = {Hengbiao Zheng and Xiang Zhou and Jiaoyang He and Xia Yao and Tao Cheng and Yan Zhu and Weixing Cao and Yongchao Tian},
keywords = {Plant detection, UAV imagery, Texture feature, Spectral feature, Decision tree},
abstract = {Crop plant detection is vital for mapping crop planting area and extracting pure crop canopy information. In this study, three cameras (RGB, color infrared (NIR-G-B) and multispectral (MS) camera) were mounted on a multi-rotor unmanned aerial vehicle (UAV) to obtain images of rice canopy at the early growth stages (tillering, jointing and initial booting stages). We proposed a new decision tree (DT) combining texture features (mean and variance (C.V)) and spectral features (TS-DT) for rice plants detection within UAV images. First, the image was classified into the pure class and the mixed class based on the C.V value. Then the pure class was classified into rice plants and road by the DN or reflectance value in red band. The mixed class was classified into rice plants and background (soil, water and duckweed) through comparing each pixel value to the mean value within the moving window. The results showed that TS-DT exhibited an averaged high classification accuracy with overall accuracy (OA) and kappa coefficient (KC) of 91.25%, 0.86, 92.88%, 0.86 and 93.53%, 0.88 for RGB, NIR and MS image among the early three growth stages, respectively. The highest estimation accuracy was obtained at booting stage and the lowest was at tillering stage. Compared with the traditional classification methods, the TS-DT method achieved an improved estimation accuracy of 5.2–26.71% in OA and 0.06–0.40 in KC. Therefore, this TS-DT method is a reliable approach for crop plants detection using UAV imagery.}
}
@article{ZHU2020105786,
title = {Estimating leaf chlorophyll content of crops via optimal unmanned aerial vehicle hyperspectral data at multi-scales},
journal = {Computers and Electronics in Agriculture},
volume = {178},
pages = {105786},
year = {2020},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2020.105786},
url = {https://www.sciencedirect.com/science/article/pii/S0168169920314423},
author = {Wanxue Zhu and Zhigang Sun and Ting Yang and Jing Li and Jinbang Peng and Kangying Zhu and Shiji Li and Huarui Gong and Yun Lyu and Binbin Li and Xiaohan Liao},
keywords = {Unmanned aerial vehicle (UAV), Hyperspectral, Chlorophyll, Machine learning, Precision agriculture},
abstract = {Leaf chlorophyll content (LCC) is a crucial indicator of nutrition in crop plants and can be applied to assess the adequacy of nitrogen (N) fertilizer for crops while reducing N losses to farmland. This study estimated the LCC of maize and wheat, and comprehensively examined the effects of the spectral information and spatial scale of unmanned aerial vehicle (UAV) imagery, and the effects of phenotype and phenology on LCC estimation. A Cubert S185 hyperspectral camera onboard a DJI M600 Pro was used to conduct six flight missions over a long-term experimental field with five N applications (0, 70, 140, 210, and 280 kg N ha−1) and two irrigation levels (60% and 80% field water capacity) during the growing seasons of wheat and maize in 2019. Four regression algorithms, that is, multi-variable linear regression, random forest, backpropagation neural network, and support vector machine, were used for modeling. Leaf, canopy, and hybrid scale hyperspectral variables (H-variables) were used as inputs for the statistical LCC models. Optimal H-variables for modeling were determined by Pearson correlation filtering followed by a recursive feature elimination procedure. The results showed that (1) H-variables at the canopy- and leaf-scales were appropriate for wheat and maize LCC estimation, respectively; (2) the robustness of LCC estimation was in the order of the flowering stage > heading stage > grain filling stage for wheat and early grain filling stage > flowering stage > jointing stage for maize; (3) the reflectance of the red edge, green, and blue bands were the most important inputs for LCC modeling, and the optimal vegetation indices differed for the various growth stages and crops; and (4) all four algorithms maintained an acceptable accuracy with respect to LCC estimation, although random forest and support vector machine were slightly better. This study is valuable for the design of appropriate schemes for the spectral and scale issues of UAV sensors for LCC estimation regarding specific crop phenotype and phenology periods, and further boosts the applications of UAVs in precision agriculture.}
}
@article{OUTAY2020116,
title = {Applications of unmanned aerial vehicle (UAV) in road safety, traffic and highway infrastructure management: Recent advances and challenges},
journal = {Transportation Research Part A: Policy and Practice},
volume = {141},
pages = {116-129},
year = {2020},
issn = {0965-8564},
doi = {https://doi.org/10.1016/j.tra.2020.09.018},
url = {https://www.sciencedirect.com/science/article/pii/S096585642030728X},
author = {Fatma Outay and Hanan Abdullah Mengash and Muhammad Adnan},
keywords = {Unmanned aerial vehicles (UAVs), Road safety, Traffic monitoring, Highway infrastructure management, Applications},
abstract = {For next-generation smart cities, small UAVs (also known as drones) are vital to incorporate in airspace for advancing the transportation systems. This paper presents a review of recent developments in relation to the application of UAVs in three major domains of transportation, namely; road safety, traffic monitoring and highway infrastructure management. Advances in computer vision algorithms to extract key features from UAV acquired videos and images are discussed along with the discussion on improvements made in traffic flow analysis methods, risk assessment and assistance in accident investigation and damage assessments for bridges and pavements. Additionally, barriers associated with the wide-scale deployment of UAVs technology are identified and countermeasures to overcome these barriers are discussed, along with their implications.}
}
@article{LIN2020135,
title = {Event-triggered reinforcement learning control for the quadrotor UAV with actuator saturation},
journal = {Neurocomputing},
volume = {415},
pages = {135-145},
year = {2020},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2020.07.042},
url = {https://www.sciencedirect.com/science/article/pii/S0925231220311504},
author = {Xiaobo Lin and Jian Liu and Yao Yu and Changyin Sun},
keywords = {Quadrotor, UAV, Reinforcement learning, Flight control, Event-triggered control, Actuator saturation},
abstract = {This paper proposes an event-triggered reinforcement learning (RL) control strategy to stabilize the quadrotor unmanned aerial vehicle (UAV) with actuator saturation. As the quadrotor UAV equips with a complex dynamic is difficult to be model accurately, a model free reinforcement learning scheme is designed. Due to the practical limitation of actuators, the end of controller is constrained with a bounded function. In order to reduce the calculation consumption for the onboard computer, an event-triggered mechanism is developed, which only update the controller when the triggered condition is satisfied. The proposed controller is implemented with two neural networks which are called critic and actor. Some advanced RL technologies are utilized for speeding up the train process, e.g. off-policy training, experience replay, etc. The stability of closed-loop system is proved by the Lyapunov analysis. The simulation results including a stability task and a tracking task verify the theoretical analysis, in which we find the updating frequency of controller is decreased greatly.}
}
@article{FALLATI2019133581,
title = {Anthropogenic Marine Debris assessment with Unmanned Aerial Vehicle imagery and deep learning: A case study along the beaches of the Republic of Maldives},
journal = {Science of The Total Environment},
volume = {693},
pages = {133581},
year = {2019},
issn = {0048-9697},
doi = {https://doi.org/10.1016/j.scitotenv.2019.133581},
url = {https://www.sciencedirect.com/science/article/pii/S0048969719335065},
author = {L. Fallati and A. Polidori and C. Salvatore and L. Saponari and A. Savini and P. Galli},
keywords = {Anthropogenic Marine-Debris, Unmanned Aerial Vehicles, Machine learning, Deep learning algorithms, Maldives, Beach},
abstract = {Anthropogenic Marine Debris (AMD) is one of the major environmental issues of our planet to date, and plastic accounts for 80% of total AMD. Beaches represent one of the main marine compartment where AMD accumulates, but few and scattered regional assessments are available from literature reporting quantitative estimation of AMD distributed on the shorelines. However, accessing information on the AMD accumulation rate on beaches, and the associated spatiotemporal oscillations, would be crucial to refining global estimation on the dispersal mechanisms. In our work, we address this issue by proposing an ad-hoc methodology for monitoring and automatically quantifying AMD, based on the combined use of a commercial Unmanned Aerial Vehicle (UAV) (equipped with an RGB high-resolution camera) and a deep-learning based software (i.e.: PlasticFinder). Remote areas were monitored by UAV and were inspected by operators on the ground to check and to categorise all AMD dispersed on the beach. The high-resolution images obtained from UAV allowed to visually detect a percentage of the objects on the shores higher than 87.8%, thus providing suitable images to populate training and testing datasets, as well as gold standards to evaluate the software performance. PlasticFinder reached a Sensitivity of 67%, with a Positive Predictive Value of 94%, in the automatic detection of AMD, but a limitation was found, due to reduced sunlight conditions, thus restricting to the use of the software in its present version. We, therefore, confirmed the efficiency of commercial UAVs as tools for AMD monitoring and demonstrated - for the first time - the potential of deep learning for the automatic detection and quantification of AMD.}
}
@article{WANG20208342,
title = {Predictive control of air-fuel ratio in aircraft engine on fuel-powered unmanned aerial vehicle using fuzzy-RBF neural network},
journal = {Journal of the Franklin Institute},
volume = {357},
number = {13},
pages = {8342-8363},
year = {2020},
issn = {0016-0032},
doi = {https://doi.org/10.1016/j.jfranklin.2020.03.016},
url = {https://www.sciencedirect.com/science/article/pii/S0016003220301903},
author = {Yixuan Wang and Yan Shi and Maolin Cai and Weiqing Xu},
abstract = {Air-fuel ratio control is important for optimizing the performance and reducing the exhaust emission of fuel-powered unmanned aerial vehicles 0(UAVs). However, previous studies on engine air-fuel ratio control neglect the fuel injection process and load of UAV propellers, and traditional methods could not satisfy the control requirement of an air-fuel ratio error of less than  ± 2% when a UAV operates in different conditions. Here, to optimize the control performance, the mean value model of a fuel-powered aircraft engine is improved and an adaptive fuzzy radial basis function (RBF) neural network is used to perform predictive control. The simulation results are compared with the traditional control and some previous studies, and engine control experiments are implemented for demonstration. The simulation and experimental results indicate that, through predictive control using a fuzzy-RBF neural network, the air-fuel ratio of the aircraft engine can be controlled within  ± 1% bounds of the stoichiometric value (14.7), and the highest error can be reduced by 68 to 75% compared with that in the previous work and the traditional neural network model, traditional PID method, and second-order sliding mode strategy. This research can be considered as a reference for intelligent algorithm applications on the power system of fuel-powered UAVs.}
}
@article{KUMAR2021100198,
title = {Velocity controllers for a swarm of unmanned aerial vehicles},
journal = {Journal of Industrial Information Integration},
volume = {22},
pages = {100198},
year = {2021},
issn = {2452-414X},
doi = {https://doi.org/10.1016/j.jii.2020.100198},
url = {https://www.sciencedirect.com/science/article/pii/S2452414X2030073X},
author = {Sandeep A. Kumar and J. Vanualailai and B. Sharma and A. Prasad},
keywords = {Unmanned aerial vehicles, Path planning, Find-path problem, Lyapunov stability, Swarm intelligence, Lagrangian swarm, Collision avoidance, Artificial potential field method},
abstract = {The biological concept of a swarm’s emergent behavior resulting from the self-organization of the individuals in a swarm is an important piece of information that can be integrated into industrial manufacturing of unmanned ground or aerial vehicles. In this paper, we present a Lyapunov-based path planner that organizes the individuals, governed by a simple rigid-body model, of a swarm into formations which ensure a safe collision-free path for the swarm to its target in obstacle-cluttered environments. Via the Direct Method of Lyapunov that establishes the swarm system’s stability, we propose the instantaneous velocity function for each individual. The velocity functions could be easily integrated into industrial designs for the individuals of a swarm of unmanned ground or aerial vehicles. As an application, we consider the planar formation of a swarm of unmanned aerial vehicles (UAVs) using their kinematic models for simplicity. Via computer simulations, we illustrate several self-organization such as elliptic and linear formations, split/rejoin, and tunneling maneuvers for obstacle avoidance and helical trajectory for milling. In particular, the linear formations have been proposed as suitable for the surveillance of large areas such as the Exclusive Economic Zones.}
}
@article{SREENATH2020656,
title = {Assessment and Use of Unmanned Aerial Vehicle for Civil Structural Health Monitoring},
journal = {Procedia Computer Science},
volume = {170},
pages = {656-663},
year = {2020},
note = {The 11th International Conference on Ambient Systems, Networks and Technologies (ANT) / The 3rd International Conference on Emerging Data and Industry 4.0 (EDI40) / Affiliated Workshops},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2020.03.174},
url = {https://www.sciencedirect.com/science/article/pii/S1877050920306384},
author = {Sreehari Sreenath and Haroon Malik and Narman Husnu and Kanimozhi Kalaichelavan},
keywords = {Type your keywords here, separated by semicolons},
abstract = {Unmanned Aerial Vehicles or UAVs can be employed in a multitude of civil applications owing to their ease of use, low maintenance, affordability, high-mobility, and ability to hover. Such vehicles are being utilized for real-time monitoring of road traffic, providing wireless coverage, remote sensing, search and rescue operations, delivery of goods, security and surveillance, precision agriculture, and civil infrastructure inspection. They are the next big revolution in technology and civil infrastructure is expected to dominate their more than $45 Billion worth market. This paper surveys the UAV assisted Structural Health Monitoring or SHM literature over the last decade and categorizes UAVs based on their aerodynamics. Further, it presents the payload product line to facilitate the SHM tasks, details the different applications of UAVs exploited in the last decade to support civil structures and discusses the key challenges faced in its application across various domains.}
}
@article{WENG2014134,
title = {Immune network-based swarm intelligence and its application to unmanned aerial vehicle (UAV) swarm coordination},
journal = {Neurocomputing},
volume = {125},
pages = {134-141},
year = {2014},
note = {Advances in Neural Network Research and Applications Advances in Bio-Inspired Computing: Techniques and Applications},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2012.06.053},
url = {https://www.sciencedirect.com/science/article/pii/S0925231213001653},
author = {Liguo Weng and Qingshan Liu and Min Xia and Y.D. Song},
keywords = {Swarm intelligence, Immune network, Swarm coordination, UAVs},
abstract = {In this paper, we first investigate the fundamentals of the immune system and the principles of the antibodies and how antibodies work cooperatively to achieve swarm coordination and hence a successful immune response. Based on the study, we propose a multi-agent cooperative operation strategy for the immune system based on the immune network theory. In order to achieve successful swarm coordination, we design each agent to select its favorable strategy according to distributed sensing through local communication. Experiments show that this Immunology-inspired Cooperative Operation strategy performs well even under dynamically changing environment. Its effectiveness is also verified by numerical simulation on multiple unmanned aerial vehicle (UAV) coordination.}
}
@article{SIERRAGARCIA2021115380,
title = {Intelligent control of an UAV with a cable-suspended load using a neural network estimator},
journal = {Expert Systems with Applications},
volume = {183},
pages = {115380},
year = {2021},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2021.115380},
url = {https://www.sciencedirect.com/science/article/pii/S095741742100806X},
author = {Jesús Enrique Sierra-García and Matilde Santos},
keywords = {Modelling, Intelligent control, Hybrid automata, Neural networks, Unmanned Aerial Vehicle (UAV), Cable-suspended load},
abstract = {Unmanned aerial vehicles (UAVs) have been proved very useful in civil and military sectors: defense, security, shipping, construction, agriculture, entertainment, etc. Some of these applications, especially those related to transport and logistic operations, require the use of suspended loads that may make the vehicle unstable. In order to deal with this non-linear complex system with a changing mass, further research on modelling and control must be developed. In this work, a new intelligent control strategy is proposed and applied to a quadrotor with a cable-suspended load. The UAV carrying a suspended load has two different dynamic behaviors, depending on the state of the cable. Thus, we proposed to model the complete system using the hybrid automata formalism. Using this novel UAV model approach, a hybrid control is designed based on feedback linearization controllers combined with an artificial neural network, which acts as an online estimator of the unknown mass. The suspended load is dealt with as an external disturbance. Simulation results show how the on-line learning control scheme increases the robustness of the control and it is able to stabilize the quadrotor without any information about neither the position of the load nor the tension of the cable. Additionally, the computational complexity of the proposal is studied to show the feasibility of the implementation of this intelligent control strategy on real hardware.}
}
@article{BALLI2021114403,
title = {On-design and off-design operation performance assessmentsof an aero turboprop engine used on unmanned aerial vehicles (UAVs) in terms of aviation, thermodynamic, environmental and sustainability perspectives},
journal = {Energy Conversion and Management},
volume = {243},
pages = {114403},
year = {2021},
issn = {0196-8904},
doi = {https://doi.org/10.1016/j.enconman.2021.114403},
url = {https://www.sciencedirect.com/science/article/pii/S0196890421005793},
author = {Ozgur Balli and Hakan Caliskan},
keywords = {Energy, Environmental impact, Exergy, On-design and off-design, Turboprop, Unmanned aerial vehicle},
abstract = {In this study, a turboprop engine (TPE) of an unmanned aerial vehicle (UAV) is investigated for “on-design” and “off-design” conditions at maximum operation mode. One project point is chosen for on-design case for the cycle analysis. Other constraints and requirements are considered at off-design analysis in which cycle analysis is not affected. The off-design condition is generally used in emergency situation such as one-engine take-off, extreme flight speed, extreme altitude, and hot day operation. The aviation, energy, exergy, environmental, and sustainability analyses are performed to the TPE. For on-design and off-design conditions of the UAV TPE, the specific fuel consumptions are 0.287 kg/kW h and 0.282 kg/kW h, specific powers are 0.067 kW h/kg and 0.069 kW h/kg, thermal limiting ratios are 3.735 and 3.785, entalphy ratios are 4.482 and 4.555, energy efficiencies are 29.067% and 29.652%, exergy efficiencies are 27.38% and 27.93%, exergetic improvement potentials are 159.26 kW and 182.23 kW, ecological objective functions are −436.366 kW and −488.78 kW, environmental effect factors are 2.652 and 2.580, ecological effect factors are 3.652 and 3.580, exergetic sustainability indexes are 0.38 and 0.39, sustainable efficiency factors are 1.38 and 1.39, respectively. The results show that off-design condition has better fuel consumption, power, efficiency, improvement potential, environmental damage and sustainability than on-design condition. Also, the combustion chamber is the first component to be handled for the improvement of the overall system. UAVs are used for very deligant and important duties and their efficiency and sustainability play important role for their missions. UAV engines such as TPEs are the major power units to operate the overall system. Even a slight increase in efficiency and sustainability for the TPE engine can cause important feedback for the UAV mission. It is also important to assess the TPE for its environmental effects, because UAVs will play important role in the future for the transportation. As a result, this study is useful to assess turboprop engines of unmanned aerial vehicles in efficiency, sustainability and environmental aspects.}
}
@article{YU20221,
title = {A review on fault-tolerant cooperative control of multiple unmanned aerial vehicles},
journal = {Chinese Journal of Aeronautics},
volume = {35},
number = {1},
pages = {1-18},
year = {2022},
issn = {1000-9361},
doi = {https://doi.org/10.1016/j.cja.2021.04.022},
url = {https://www.sciencedirect.com/science/article/pii/S1000936121001771},
author = {Ziquan YU and Youmin ZHANG and Bin JIANG and Jun FU and Ying JIN},
keywords = {Cooperative Fault Detection and Diagnosis (CFDD), Cooperative/formation/swarm control, Fault Detection and Diagnosis (FDD), Fault-Tolerant Control (FTC), Fault-Tolerant Cooperative Control (FTCC), Unmanned Aerial Vehicles (UAVs)},
abstract = {This paper presents the recent developments in Fault-Tolerant Cooperative Control (FTCC) of multiple unmanned aerial vehicles (multi-UAVs). To facilitate the analyses of FTCC methods for multi-UAVs, the formation control strategies under fault-free flight conditions of multi-UAVs are first summarized and analyzed, including the leader-following, behavior-based, virtual structure, collision avoidance, algebraic graph-based, and close formation control methods, which are viewed as the cooperative control methods for multi-UAVs at the pre-fault stage. Then, by considering the various faults encountered by the multi-UAVs, the state-of-the-art developments on individual, leader-following, and distributed FTCC schemes for multi-UAVs are reviewed in detail. Finally, conclusions and challenging issues towards future developments are presented.}
}
@article{WANG20202930,
title = {Coactive design of explainable agent-based task planning and deep reinforcement learning for human-UAVs teamwork},
journal = {Chinese Journal of Aeronautics},
volume = {33},
number = {11},
pages = {2930-2945},
year = {2020},
note = {SI: Emerging Technologies of Unmanned Aerial Vehicles},
issn = {1000-9361},
doi = {https://doi.org/10.1016/j.cja.2020.05.001},
url = {https://www.sciencedirect.com/science/article/pii/S1000936120301229},
author = {Chang WANG and Lizhen WU and Chao YAN and Zhichao WANG and Han LONG and Chao YU},
keywords = {Coactive design, Deep reinforcement learning, Human-robot teamwork, Mixed-initiative, Multi-agent system, Task planning, UAV},
abstract = {Unmanned Aerial Vehicles (UAVs) are useful in dangerous and dynamic tasks such as search-and-rescue, forest surveillance, and anti-terrorist operations. These tasks can be solved better through the collaboration of multiple UAVs under human supervision. However, it is still difficult for human to monitor, understand, predict and control the behaviors of the UAVs due to the task complexity as well as the black-box machine learning and planning algorithms being used. In this paper, the coactive design method is adopted to analyze the cognitive capabilities required for the tasks and design the interdependencies among the heterogeneous teammates of UAVs or human for coherent collaboration. Then, an agent-based task planner is proposed to automatically decompose a complex task into a sequence of explainable subtasks under constrains of resources, execution time, social rules and costs. Besides, a deep reinforcement learning approach is designed for the UAVs to learn optimal policies of a flocking behavior and a path planner that are easy for the human operator to understand and control. Finally, a mixed-initiative action selection mechanism is used to evaluate the learned policies as well as the human’s decisions. Experimental results demonstrate the effectiveness of the proposed methods.}
}
@article{HU2020138,
title = {Recognition of diseased Pinus trees in UAV images using deep learning and AdaBoost classifier},
journal = {Biosystems Engineering},
volume = {194},
pages = {138-151},
year = {2020},
issn = {1537-5110},
doi = {https://doi.org/10.1016/j.biosystemseng.2020.03.021},
url = {https://www.sciencedirect.com/science/article/pii/S1537511020300842},
author = {Gensheng Hu and Cunjun Yin and Mingzhu Wan and Yan Zhang and Yi Fang},
keywords = {Diseased Pinus tree, Target recognition, UAV image, Deep learning, AdaBoost classifier},
abstract = {Recognition of diseased Pinus trees in unmanned aerial vehicle (UAV) images is beneficial to the dynamic monitoring and control of Pinus tree diseases in large areas. However, the low resolution and complex backgrounds of UAV images limit the accuracy of traditional machine learning methods in recognising diseased Pinus trees. This study presents a method for recognising diseased Pinus trees that combines deep convolutional neural networks (DCNNs), deep convolutional generative adversarial networks (DCGANs), and an AdaBoost classifier. DCGANs can expand the number of samples of diseased Pinus trees to solve the problem of insufficient training samples. DCNNs are used to remove fields, soils, roads, and rocks in images to reduce the impact of complex backgrounds on target recognition. The AdaBoost classifier distinguishes diseased Pinus trees from healthy Pinus trees and identifies shadows in background removal images. Experimental results show that the proposed method has better recognition performance than K-means clustering, support vector machine, AdaBoost classifier, backpropagation neural networks, Alexnet, VGG, and Inception_v3 networks.}
}
@article{BOUGUETTAYA2022108309,
title = {A review on early wildfire detection from unmanned aerial vehicles using deep learning-based computer vision algorithms},
journal = {Signal Processing},
volume = {190},
pages = {108309},
year = {2022},
issn = {0165-1684},
doi = {https://doi.org/10.1016/j.sigpro.2021.108309},
url = {https://www.sciencedirect.com/science/article/pii/S0165168421003467},
author = {Abdelmalek Bouguettaya and Hafed Zarzour and Amine Mohammed Taberkit and Ahmed Kechida},
keywords = {Computer vision, Deep learning, Aerial images processing, Wildfire detection system, Smoke detection system, Unmanned aerial vehicle},
abstract = {Wildfire is one of the most critical natural disasters that threaten wildlands and forest resources. Traditional firefighting systems, which are based on ground crew inspection, have several limits and can expose firefighters’ lives to danger. Thus, remote sensing technologies have become one of the most demanded strategies to fight against wildfires, especially UAV-based remote sensing technologies. They have been adopted to detect forest fires at their early stages, before becoming uncontrollable. Autonomous wildfire early detection from UAV-based visual data using different deep learning algorithms has attracted significant interest in the last few years. To this end, in this paper, we focused on wildfires detection at their early stages in forest and wildland areas, using deep learning-based computer vision algorithms to prevent and then reduce disastrous losses in terms of human lives and forest resources.}
}
@article{KUJAWSKI2021103004,
title = {Analysis and visualization of data obtained from camera mounted on unmanned aerial vehicle used in areas of urban transport},
journal = {Sustainable Cities and Society},
volume = {72},
pages = {103004},
year = {2021},
issn = {2210-6707},
doi = {https://doi.org/10.1016/j.scs.2021.103004},
url = {https://www.sciencedirect.com/science/article/pii/S2210670721002894},
author = {Artur Kujawski and Tomasz Dudek},
keywords = {Data acquisition, Data management, Unmanned aerial vehicle, Image processing, Image analysis, City transport, City logistics},
abstract = {Nowadays, it is practically impossible to find a public place, where a person or object would not be under constant camera observation (mainly used to monitor traffic and to increase safety). Interpretation of such repositories, due to the huge amount of data, is not an easy task. Thus there is a need to introduce an intelligent processing systems that, through algorithmic image analysis, are able to detect e.g. situations worth of attention. The article presents methods of data acquisition from cameras mounted on unmanned aerial vehicles (UAV) and their further analysis, which may be used to improve urban transportation systems and its sustainability. The worked out data concern the situation of urban transport in points of intersection of national and local roads. The analysis of the road traffic concerning local road restoration, causing road closure was achieved using image processing and analysis algorithms. The data was obtained from unmanned aerial vehicle flights in critical city locations. Result of this paper may be used in the future together with the data from existing intelligent transportation systems (a fusion of such data will be needed). The application of used methods will allow to extend and support the existing approaches to manage public and freight transport in cities.}
}
@article{ZHOU202190,
title = {Yield estimation of soybean breeding lines under drought stress using unmanned aerial vehicle-based imagery and convolutional neural network},
journal = {Biosystems Engineering},
volume = {204},
pages = {90-103},
year = {2021},
issn = {1537-5110},
doi = {https://doi.org/10.1016/j.biosystemseng.2021.01.017},
url = {https://www.sciencedirect.com/science/article/pii/S1537511021000180},
author = {Jing Zhou and Jianfeng Zhou and Heng Ye and Md Liakat Ali and Pengyin Chen and Henry T. Nguyen},
keywords = {Soybean breeding, drought stress, yield estimation, UAV multispectral imagery, convolutional neural network},
abstract = {Crop yield is a primary trait to select superior genotypes and evaluate breeding efficiency in breeding programs. Crops with high yield potential are usually selected from numerous breeding lines in multiple years and locations. However, the efficiency of conventional breeding programs is limited by the capacity of field phenotyping, which can be improved by developing high-throughput field phenotyping systems using emerging technologies, including Unmanned Aerial Vehicle (UAV) imagery and deep learning technologies. The goal of this study was to evaluate the performance of a UAV imaging system and convolutional neural network (CNN) in estimating yield of soybean breeding lines. In this study, 972 soybean breeding lines in three maturity groups were planted under rainfed conditions for testing their drought tolerance. Aerial images were taken at the late vegetation (V6), early (R1), and late reproductive (R6-R8) growth stages. Seven image features associated with plant height, canopy colour, and canopy texture were selected to estimate the yield of each breeding line. A mixed CNN model was built to estimate soybean yield by taking the seven image features and two categorical factors, i.e. maturity group and drought tolerance, as predictors. Results show that image features collected at the early and late reproductive growth stages are comparably promising in estimating soybean yield. The prediction model could explain 78% of the measured yield with a root mean square error of 391.0 kg·ha−1 (33.8% to the average yield), indicating that the UAV imagery and deep learning models are promising in estimating yield for soybean breeding purposes.}
}
@article{QARALLAH2021104587,
title = {Evaluating post-fire recovery of Latroon dry forest using Landsat ETM+, unmanned aerial vehicle and field survey data},
journal = {Journal of Arid Environments},
volume = {193},
pages = {104587},
year = {2021},
issn = {0140-1963},
doi = {https://doi.org/10.1016/j.jaridenv.2021.104587},
url = {https://www.sciencedirect.com/science/article/pii/S0140196321001531},
author = {Bassam Qarallah and Malik Al-Ajlouni and Ayman Al-Awasi and Mohammad Alkarmy and Emad Al-Qudah and Ahmad Bani Naser and Amani Al-Assaf and Caroline M. Gevaert and Yolla {Al Asmar} and Mariana Belgiu and Yahia A. Othman},
keywords = {Remote sensing, Forest fires, dNBR, Drones, UAV, },
abstract = {We evaluated the fire severity and recovery process of the Latroon dry forest in Jordan following the 2003 fire. A series of multi-temporal Landsat-ETM + data and the delta normalized burn ratio (dNBR) were used to map the fire severity immediately following the fire and 1,5,9,13 and 17 years after. In addition, combined field morpho-physiological measurements, unmanned aerial vehicle (UAV) were also used in 2020 to assess the forest recovery. Landsat-dNBR images revealed that about 65% of the forest was burned in 2003. In 2020, about 90% of the burned area recovered to condition before fire. UAV means were similar to ground measurement data across the severity classes and over the tested species. Landsat-dNBR images showed that most moderate and highly severe burned area in 2003 had recovered in 2020 but ground measurements showed that the severely burned area trees were significantly shorter (p < 0.001) than those from the moderate severity across the studied species. Therefore, Landsat-dNBR did not detect tree height changes. While UAV can potentially estimate the tree height, Landsat-ETM+ (near-infrared, chlorophyll; shortwave-infrared, water status) hold promise for estimating the physiology of the canopy. Overall, different remote sensing levels are required to track different kinds of changes in the recovered forests.}
}
@article{NASSER2021108672,
title = {A lightweight federated learning based privacy preserving B5G pandemic response network using unmanned aerial vehicles: A proof-of-concept},
journal = {Computer Networks},
pages = {108672},
year = {2021},
issn = {1389-1286},
doi = {https://doi.org/10.1016/j.comnet.2021.108672},
url = {https://www.sciencedirect.com/science/article/pii/S1389128621005466},
author = {Nidal Nasser and Zubair Md Fadlullah and Mostafa M. Fouda and Asmaa Ali and Muhammad Imran},
keywords = {5G, Beyond 5G (B5G), Federated learning, Unmanned aerial vehicle (UAV), Pandemic, Artificial intelligence (AI), Edge computing},
abstract = {The concept of an intelligent pandemic response network is gaining momentum during the current novel coronavirus disease (COVID-19) era. A heterogeneous communication architecture is essential to facilitate collaborative and intelligent medical analytics in the fifth generation and beyond (B5G) networks to intelligently learn and disseminate pandemic-related information and diagnostic results. However, such a technique raises privacy issues pertaining to the health data of the patients. In this paper, we envision a privacy-preserving pandemic response network using a proof-of-concept, aerial-terrestrial network system serving mobile user entities/equipment (UEs). By leveraging the unmanned aerial vehicles (UAVs), a lightweight federated learning model is proposed to collaboratively yet privately learn medical (e.g., COVID-19) symptoms with high accuracy using the data collected by individual UEs using ambient sensors and wearable devices. An asynchronous weight updating technique is introduced in federated learning to avoid redundant learning and save precious networking as well as computing resources of the UAVs/UEs. A use-case where an Artificial Intelligence (AI)-based model is employed for COVID-19 detection from radiograph images is presented to demonstrate the effectiveness of our proposed approach.}
}
@article{SU2022106621,
title = {Spectral analysis and mapping of blackgrass weed by leveraging machine learning and UAV multispectral imagery},
journal = {Computers and Electronics in Agriculture},
volume = {192},
pages = {106621},
year = {2022},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2021.106621},
url = {https://www.sciencedirect.com/science/article/pii/S0168169921006384},
author = {Jinya Su and Dewei Yi and Matthew Coombes and Cunjia Liu and Xiaojun Zhai and Klaus McDonald-Maier and Wen-Hua Chen},
keywords = {Blackgrass weed, Guided filter, Random forest, Spectral Index (SI), Unmanned Aerial Vehicle (UAV)},
abstract = {Accurate weed mapping is a prerequisite for site-specific weed management to enable sustainable agriculture. This work aims to analyse (spectrally) and mapping blackgrass weed in wheat fields by integrating Unmanned Aerial Vehicle (UAV), multispectral imagery and machine learning techniques. 18 widely-used Spectral Indices (SIs) are generated from 5 raw spectral bands. Then various feature selection algorithms are adopted to improve model simplicity and empirical interpretability. Random Forest classifier with Bayesian hyperparameter optimization is preferred as the classification algorithm. Image spatial information is also incorporated into the classification map by Guided Filter. The developed framework is illustrated with an experimentation case in a naturally blackgrass infected wheat field in Nottinghamshire, United Kingdom, where multispectral images were captured by RedEdge on-board DJI S-1000 at an altitude of 20 m with a ground spatial resolution of 1.16 cm/pixel. Experimental results show that: (i) a good result (an average precision, recall and accuracy of 93.8%, 93.8%, 93.0%) is achieved by the developed system; (ii) the most discriminating SI is triangular greenness index (TGI) composed of Green-NIR, while wrapper feature selection can not only reduce feature number but also achieve a better result than using all 23 features; (iii) spatial information from Guided filter also helps improve the classification performance and reduce noises.}
}
@article{PUSTOKHINA2021108214,
title = {Energy Efficient Neuro-Fuzzy Cluster based Topology Construction with Metaheuristic Route Planning Algorithm for Unmanned Aerial Vehicles},
journal = {Computer Networks},
volume = {196},
pages = {108214},
year = {2021},
issn = {1389-1286},
doi = {https://doi.org/10.1016/j.comnet.2021.108214},
url = {https://www.sciencedirect.com/science/article/pii/S1389128621002632},
author = {Irina V. Pustokhina and Denis A. Pustokhin and E. Laxmi Lydia and Mohamed Elhoseny and K. Shankar},
keywords = {Clustering, Route planning, Energy efficiency, Metaheuristics, Unmanned aerial vehicles},
abstract = {At present times, unmanned aerial vehicles (UAVs) received significant attention among several application areas and services in both defense and civilian domains. The existence of many UAVs performs difficult process effectually when they are arranged in an adhoc way. The restricted battery capacity of the UAVs, rapid mobility, and high dynamic nature of the UAVs necessities the design of energy efficient clustering and routing protocols. With its motivation, this paper develops an Energy Efficient Neuro-Fuzzy Cluster based Topology Construction with Metaheuristic Route Planning (EENFC-MRP) algorithm for UAVs. The presented model involves EENFC based clustering and MRP based routing processes. The EENFC model make use of three input parameters namely Residual Energy in UAV, Average Distance to Nearby UAVs, and UAV Degree for the cluster construction. In addition, Quantum Ant Lion Optimization (QALO) based MRP is applied to choose an optimal set of routes for intercluster UAV communication. In order to investigate the energy efficient outcome of the EENFC-MRP algorithm, a series of simulation processes were carried out and the results are examined under several aspects. The resultant experimental values ensured the betterment of the EENFC-MRP algorithm over the existing models interms of energy efficiency, throughput, network lifetime, and average delay.}
}
@article{YU2021104861,
title = {Fractional order PID-based adaptive fault-tolerant cooperative control of networked unmanned aerial vehicles against actuator faults and wind effects with hardware-in-the-loop experimental validation},
journal = {Control Engineering Practice},
volume = {114},
pages = {104861},
year = {2021},
issn = {0967-0661},
doi = {https://doi.org/10.1016/j.conengprac.2021.104861},
url = {https://www.sciencedirect.com/science/article/pii/S0967066121001386},
author = {Ziquan Yu and Youmin Zhang and Bin Jiang and Chun-Yi Su and Jun Fu and Ying Jin and Tianyou Chai},
keywords = {Unmanned aerial vehicles (UAVs), Fault-tolerant cooperative control (FTCC), Fractional order control, Proportional–integral–derivative (PID), Actuator faults, Recurrent neural networks},
abstract = {This paper proposes an adaptive fault-tolerant cooperative control (FTCC) scheme for networked unmanned aerial vehicles (UAVs) in the presence of actuator faults and wind effects by artfully introducing fractional order calculus, proportional–integral–derivative (PID), and recurrent neural networks. Fractional order sliding-mode surface and PID-type error mapping are first utilized to transform the synchronization tracking errors of all UAVs into a new set of errors. Then, based on these newly constructed errors, an FTCC scheme is developed to synchronously track their references. Moreover, Butterworth low-pass filter (BLF) and recurrent neural network (RNN) learning strategies are assimilated to handle the unknown terms induced by the actuator faults and wind effects. Finally, theoretical analysis and comparative hardware-in-the-loop experimental demonstrations have shown the effectiveness of the proposed control scheme.}
}
@article{LIJIA201947,
title = {Adaptive observer-based fault detection and active tolerant control for unmanned aerial vehicles attitude system},
journal = {IFAC-PapersOnLine},
volume = {52},
number = {24},
pages = {47-52},
year = {2019},
note = {5th IFAC Symposium on Telematics Applications TA 2019},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2019.12.379},
url = {https://www.sciencedirect.com/science/article/pii/S2405896319322797},
author = {Cao Lijia and Tang Yu and Zhang Guo},
keywords = {unmanned aerial vehicle, adaptive observer, radial basis function neural network, fault-detection, fault-tolerant control},
abstract = {A robust adaptive observer combined with radial basis function neural network (RBFNN) is designed for the unmanned aerial vehicles (UAVs) fault-detection system is proposed in this paper. Firstly, the fault dynamics model with unknown disturbance of the unmanned aerial vehicle’s attitude system is established, and a robust adaptive observer combined with radial basis function neural network is designed for the vehicle’s fault-detection, then, the detected fault combined with a robust controller is applied to design the fault-tolerant controller. In the end, the stability and effective of the fault detection and tolerant system is proved by Lyapunov theory and simulation.}
}
@article{KIEU202132,
title = {Remote sensing of coastal hydro-environment with portable unmanned aerial vehicles (pUAVs) a state-of-the-art review},
journal = {Journal of Hydro-environment Research},
volume = {37},
pages = {32-45},
year = {2021},
issn = {1570-6443},
doi = {https://doi.org/10.1016/j.jher.2021.04.003},
url = {https://www.sciencedirect.com/science/article/pii/S1570644321000289},
author = {Hieu Trung Kieu and Adrian Wing-Keung Law},
keywords = {UAV, Remote sensing, Coastal monitoring, Multispectral, Hyperspectral},
abstract = {Urbanization together with climate change is imposing growing stresses on the sustainable development of major coastal cities around the world, particularly in developing countries. Thus, the need for regular monitoring of coastal water quality is becoming increasingly vital, and remote sensing is deemed to be a viable approach particularly due to its cost-effectiveness. Over the past two decades, remote sensing using satellite imaging has already been adopted in various tasks related to the monitoring of coastal hydro-enviro nment, including the detection of oil spills, identification of turbid plumes, mapping of marine ecosystems, etc. Despite their usefulness, space-borne sensors are subjected to constraints such as low spatial resolution, clouds and atmospheric interference, sparse frequency, and inflexible scheduling. Recently, remote sensing with portable Unmanned Aerial Vehicles (pUAVs) is emerging as a promising alternative for high spatial-resolution monitoring of coastal hydro-environment, with the key advantages that they can minimize the effects of atmospheric disruptions and be implemented with a frequent schedule to perform on-demand monitoring. In addition, with the technological advances in the sensor's design, UAVs are now capable of capturing data with fine spectral resolutions, ranging from several (multispectral) to hundreds (hyperspectral) of spectral bands. Data analytic is also improving rapidly with the advancement in artificial intelligence (AI) and deep learning algorithms. In this paper, we present a systematic review of the recent developments in the utilization of UAV-based remote sensing for the sustainable development of the coastal hydro-environment, particularly with pUAVs. The key technical issues, including the design of UAV systems and the processing of data, are examined for specific applications. Future prospects for implementation are also discussed.}
}
@article{TIAN2021292,
title = {A dual neural network for object detection in UAV images},
journal = {Neurocomputing},
volume = {443},
pages = {292-301},
year = {2021},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2021.03.016},
url = {https://www.sciencedirect.com/science/article/pii/S0925231221003660},
author = {Gangyi Tian and Jianran Liu and Wenyuan Yang},
keywords = {Machine learning, Deep learning, Object detection, UAV, Dual neural network detection},
abstract = {Computer vision analysis in Unmanned Aerial Vehicle (UAV) represents a major trend in the future development. Object detection in UAV images is one of the important techonlogies to analyze scene information. However, the UAV image includes small and dense targets, which easily leads to errors of missed detection. In this paper, we propose a dual neural network review method, which quickly screens the missed targets in the one-stage detection by classifying the secondary features of the suspected target regions, so as to achieve high quality detection of small targets. Firstly, the one-stage detector recognizes UAV images, and the result with confidence greater than or equal to the threshold is detected as the target. The result less than the threshold are considered as suspected areas containing missed targets. Secondly, the feature map of UAV image is extracted by VGG backbone. The feature map and the location information of the suspected areas are combined to secondary identification. Then, the features of the dual network are late fusion, and the re-identified results guide the initial confidence addition. After the addition, regions with confidence greater than the threshold are considered as targets. Finally, we synthesize the targets of initial detection and secondary identification to obtain the final detection results. Experimental results show that our method achieves breakthrough performance on VisDrone, UAVDT and MS COCO datasets.}
}
@article{XIONG2020261,
title = {Visual detection of green mangoes by an unmanned aerial vehicle in orchards based on a deep learning method},
journal = {Biosystems Engineering},
volume = {194},
pages = {261-272},
year = {2020},
issn = {1537-5110},
doi = {https://doi.org/10.1016/j.biosystemseng.2020.04.006},
url = {https://www.sciencedirect.com/science/article/pii/S1537511020300970},
author = {Juntao Xiong and Zhen Liu and Shumian Chen and Bolin Liu and Zhenhui Zheng and Zhuo Zhong and Zhengang Yang and Hongxing Peng},
keywords = {Unmanned aerial vehicle, Green mango, Deep learning method, Visual detection},
abstract = {In this paper, a visual detection method by a UAV (unmanned aerial vehicle) was proposed to detect green mangoes on the surface of the tree crown rapidly and meet the need of estimating the number of mango fruits in orchards. The YOLOv2 model was used for quick detection of mango images captured by a UAV. First, mango images were collected by a UAV. These images were marked manually and used to build a training set and a test set. The parameters of the model were determined by experiments. The resolution of the images was 544 × 544 pixels. The batch size was 64, and the initial learning rate was 0.01. The mAP (mean average precision) of the trained model on the training set was 86.4%. Good detection results were achieved on images containing different fruit numbers and different lighting conditions with a precision of 96.1% and a recall rate of 89.0%. Finally, an experiment was conducted to estimate the actual number of green mango fruits. A method of generating an image of the whole mango tree was designed. The fruit numbers estimation model for green mango was obtained by linear fitting between the actual number and the detected number of mangoes. From the comparison of the fruit numbers of 10 mango trees determined by manual calculation and model prediction, an estimation error rate of 1.1% was achieved. The result demonstrated that the algorithm was effective for green mango detection and provided a methodological reference for quick estimation of the number of green mango fruits in orchards.}
}
@article{BRAVO2021101692,
title = {Automatic detection of potential mosquito breeding sites from aerial images acquired by unmanned aerial vehicles},
journal = {Computers, Environment and Urban Systems},
volume = {90},
pages = {101692},
year = {2021},
issn = {0198-9715},
doi = {https://doi.org/10.1016/j.compenvurbsys.2021.101692},
url = {https://www.sciencedirect.com/science/article/pii/S0198971521000995},
author = {Daniel Trevisan Bravo and Gustavo Araujo Lima and Wonder Alexandre Luz Alves and Vitor Pessoa Colombo and Luc Djogbénou and Sergio Vicente Denser Pamboukian and Cristiano Capellani Quaresma and Sidnei Alves de Araujo},
keywords = {Vector control, Mosquito, Unmanned aerial vehicle, Objects detection, Convolutional neural network, Support vector machine, Bag of visual words},
abstract = {The World Health Organization (WHO) has stated that effective vector control measures are critical to achieving and sustaining reduction of vector-borne infectious disease incidence. Unmanned aerial vehicles (UAVs), popularly known as drones, can be an important technological tool for health surveillance teams to locate and eliminate mosquito breeding sites in areas where vector-borne diseases such as dengue, zika, chikungunya or malaria are endemic, since they allow the acquisition of aerial images with high spatial and temporal resolution. Currently, though, such images are often analyzed through manual processes that are excessively time-consuming when implementing vector control interventions. In this work we propose computational approaches for the automatic identification of objects and scenarios suspected of being potential mosquito breeding sites from aerial images acquired by drones. These approaches were developed using convolutional neural networks (CNN) and Bag of Visual Words combined with the Support Vector Machine classifier (BoVW + SVM), and their performances were evaluated in terms of mean Average Precision - mAP-50. In the detection of objects using a CNN YOLOv3 model the rate of 0.9651 was obtained for the mAP-50. In the detection of scenarios, in which the performances of BoVW+SVM and a CNN YOLOv3 were compared, the respective rates of 0.6453 and 0.9028 were obtained. These findings indicate that the proposed CNN-based approaches can be used to identify potential mosquito breeding sites from images acquired by UAVs, providing substantial improvements in vector control programs aiming the reduction of mosquito-breeding sources in the environment.}
}
@article{LI2021102467,
title = {Improving the spatial and temporal estimating of daytime variation in maize net primary production using unmanned aerial vehicle-based remote sensing},
journal = {International Journal of Applied Earth Observation and Geoinformation},
volume = {103},
pages = {102467},
year = {2021},
issn = {0303-2434},
doi = {https://doi.org/10.1016/j.jag.2021.102467},
url = {https://www.sciencedirect.com/science/article/pii/S0303243421001744},
author = {Chaoqun Li and Wenting Han and Manman Peng},
keywords = {Carbon flux, Maize ecosystem, UAV remote sensing, Vegetation indices, Rectangular hyperbola model, NPP variation},
abstract = {Crop net primary productivity (NPP) represents the carbon uptake capacity in the agroecosystem carbon cycle. The chamber method is most commonly used to measure crop NPP at the canopy scale. However, the method is highly labor intensive and inefficient, especially when many measurements are required to determine hourly NPP daytime variation. The chamber method also only measures plot-scale NPP and cannot reflect whole-field NPP with high spatial resolution. In this study, the daytime variation in maize (Zea mays L.) NPP in a semiarid area was measured using the chamber method, and the spectral reflectance of the maize field at noon was measured by using an unmanned aerial vehicle (UAV) multispectral system. The objective of this study was to establish a model of daytime NPP variation and then upscale the level of NPP observations based on a UAV multispectral system. Maize maximum NPP (NPPmax) was calculated using a rectangular hyperbola model, and important vegetation indices (VIs) were calculated on the basis of multispectral imagery data. The ratio vegetation index and the red-edge chlorophyll index accounted for 65.3% and 70.3% of the variation in NPPmax, respectively. The multiple regression model with important VIs explained more than 90.4% of the variation in NPPmax. The factor photosynthetically active radiation (PAR) × NPPmax accounted for more than 84.2% of daytime variation in NPP, and when the multiple regression NPPmax model replaced NPPmax, 82.2% of the variation was still explained. The VIs, NPPmax and the PAR × NPPmax were used to obtain a multiple regression daytime NPP variation model, and when the multiple regression NPPmax model replaced NPPmax, the multiple regression model can explain 83.0% of daytime variation in NPP.}
}
@article{ZHOU2021100001,
title = {Strawberry Maturity Classification from UAV and Near-Ground Imaging Using Deep Learning},
journal = {Smart Agricultural Technology},
volume = {1},
pages = {100001},
year = {2021},
issn = {2772-3755},
doi = {https://doi.org/10.1016/j.atech.2021.100001},
url = {https://www.sciencedirect.com/science/article/pii/S2772375521000010},
author = {Xue Zhou and Won Suk Lee and Yiannis Ampatzidis and Yang Chen and Natalia Peres and Clyde Fraisse},
keywords = {Strawberry maturity classification, UAV imaging, Near-ground imaging, Deep learning},
abstract = {Strawberry is ranked third in the value of production of the crops in Florida, USA. Classifying strawberry maturity and monitoring strawberry growth status in the field is very critical for accurate strawberry yield prediction, efficient strawberry field management, and achieving the highest crop production. The traditional method of distinguishing strawberry maturity is based on either physical appearance or internal chemical substance content. However, the traditional method is time-consuming and costly. In this research, an automatic strawberry maturity classification system was developed for the rapid and accurate classification of different strawberry maturity stages. A state-of-the-art deep learning method, You Only Look Once (YOLOv3), which is good at small object detection, was trained and applied to detect strawberry flowers and strawberry fruit at different maturity stages. Two strawberry image acquisition methods, aerial imaging and near-ground imaging, were compared by using the same deep learning image processing method. As a result, three and seven strawberry maturity stages were classified for unmanned aerial vehicle (UAV) images and near-ground digital camera images, respectively. For UAV images, the highest mean average precision (mAP) of strawberry maturity classification was 0.88 for a test data set at 2 m, and the highest classification average precision (AP) was 0.93 for fully matured fruit. For near-ground digital camera images, the mAP of strawberry maturity classification was 0.89, and the highest classification AP was 0.94 for fully matured fruit as well. The result shows that YOLOv3 is an excellent approach for strawberry maturity classification on both image types.}
}
@article{YU2021119493,
title = {Early detection of pine wilt disease using deep learning algorithms and UAV-based multispectral imagery},
journal = {Forest Ecology and Management},
volume = {497},
pages = {119493},
year = {2021},
issn = {0378-1127},
doi = {https://doi.org/10.1016/j.foreco.2021.119493},
url = {https://www.sciencedirect.com/science/article/pii/S037811272100582X},
author = {Run Yu and Youqing Luo and Quan Zhou and Xudong Zhang and Dewei Wu and Lili Ren},
keywords = {Pine wilt disease, Early detection, Multispectral imagery, Deep learning, Faster R-CNN, YOLOv4},
abstract = {Pine wilt disease (PWD) is a global devastating threat to forest ecosystems. Therefore, a feasible and effective approach to precisely monitor PWD infection is indispensable, especially at the early stages. However, a precise definition of “early stage” and a rapid and high-efficiency method to detect PWD infection have not been well established. In this study, we systematically divided the PWD infection into green, early, middle, and late stages based on the needle color, the resin secretion, and whether the pine wood nematode (PWN) was carried. Simultaneously, an unmanned aerial vehicle (UAV) equipped with multispectral cameras was used to obtain images. Two target detection algorithms (Faster R-CNN and YOLOv4) and two traditional machine learning algorithms based on feature extraction (random forest and support vector machine) were employed to realize the recognition of infected pine trees. Moreover, we took into consideration of the influence of green broad-leaved trees on the identification of pine trees at the early stage of PWD infection. We obtained the following results: (1) the accuracy of Faster R-CNN (60.98–66.7%) was higher than that of YOLOv4 (57.07–63.55%), but YOLOv4 outperformed in terms of model size, processing speed, training time, and testing time; (2) although the traditional machine learning models had higher accuracy (73.28–79.64%), they were not able to directly identify the object from the images; (3) the accuracy of early detection of PWD infection showed an increase of 3.72–4.29%, from 42.36–44.59% to 46.08–48.88%, when broad-leaved trees were considered. In this study, the combination of UAV-based multispectral images and target detection algorithms allowed us to monitor the occurrence of PWD and obtain the distribution of infected trees at an early stage, which can provide technical support for the prevention and control of PWD.}
}
@article{SHI2021104340,
title = {A review on communication protocols for autonomous unmanned aerial vehicles for inspection application},
journal = {Microprocessors and Microsystems},
volume = {86},
pages = {104340},
year = {2021},
issn = {0141-9331},
doi = {https://doi.org/10.1016/j.micpro.2021.104340},
url = {https://www.sciencedirect.com/science/article/pii/S014193312100497X},
author = {Liping Shi and Néstor J. Hernández Marcano and Rune Hylsberg Jacobsen},
keywords = {Wireless communication, Mesh network, Robot operating system (ROS), Unmanned Aerial Vehicle (UAV)},
abstract = {The communication system is a critical part of the system design for the autonomous Unmanned Aerial Vehicle (UAV). It has to address different considerations, including efficiency, reliability and mobility of the UAV. In addition, a multi-UAV system requires a communication system to assist information sharing, task allocation and collaboration in a team of UAVs. In this paper, we review communication solutions for supporting a team of UAVs while considering an application in the power line inspection industry. We provide a review of candidate wireless communication technologies for supporting communication in UAV applications. Performance measurements and UAV-related channel modeling of those candidate technologies are reviewed. A discussion of current technologies for building UAV mesh networks is presented. We then analyze the structure, interface and performance of robotic communication middleware, ROS and ROS2. Based on our review, the features and dependencies of candidate solutions in each layer of the communication system are presented.}
}
@article{PANDEY2022106543,
title = {An intelligent system for crop identification and classification from UAV images using conjugated dense convolutional neural network},
journal = {Computers and Electronics in Agriculture},
volume = {192},
pages = {106543},
year = {2022},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2021.106543},
url = {https://www.sciencedirect.com/science/article/pii/S0168169921005603},
author = {Akshay Pandey and Kamal Jain},
keywords = {Conjugated Dense Convolutional Neural Network (CD-CNN), Crop identification, Image classification, SL-ReLU activation function (AF), Unmanned Aerial Vehicle (UAV)},
abstract = {Crop identification and classification is an important aspect for modern agricultural sector. With development of unmanned aerial vehicle (UAV) systems, crop identification from RGB images is experiencing a paradigm shift from conventional image processing techniques to deep learning strategies because of successful breakthrough in convolutional neural networks (CNNs). UAV images are quite trustworthy to identify different crops due to its higher spatial resolution. For precision agriculture crop identification is the primal criteria. Identifying a specific type of crop in a land is essential for performing proper farming and that also helps to estimate the net yield production of a particular crop. Previous works are limited to identify a single crop from the RGB images captured by UAVs and have not explored the chance of multi-crop classification by implementing deep learning techniques. Multi crop identification tool is highly needed as designing separate tool for each type of crop is a cumbersome job, but if a tool can successfully differentiate multiple crops then that will be helpful for the agro experts. In contrast with the previous existing techniques, this article elucidates a new conjugated dense CNN (CD-CNN) architecture with a new activation function named SL-ReLU for intelligent classification of multiple crops from RGB images captured by UAV. CD-CNN integrates data fusion and feature map extraction in conjunction with classification process. Initially a dense block architecture is proposed with a new activation function, called SL-ReLU, associated with the convolution operation to mitigate the chance of unbounded convolved output and gradient explosion. Dense block architecture concatenates all the previous layer features for determining the new features. This reduces the chance of losing important features due to deepening of the CNN module. Later, two dense blocks are conjugated with the help of a conversion block for obtaining better performance. Unlike traditional CNN, CD-CNN omits the use of fully connected layer and that reduces the chance of feature loss due to random weight initialization. The proposed CD-CNN achieves a strong distinguishing capability from several classes of crops. Raw UAV images of five different crops are captured from different parts of India and then small candidate crop regions are extracted from the raw images with the help of Arc GIS 10.3.1 software and then the candidate regions are fed to CD-CNN for proper training purpose. Experimental results show that the proposed module can achieve an accuracy of 96.2% for the concerned data. Further, superiority of the proposed network is established after comparing with other machine learning techniques viz. RF-200 and SVM, and standard CNN architectures viz. AlexNet, VGG-16, VGG-19 and ResNet-50.}
}
@article{HE2021107052,
title = {Explainable Deep Reinforcement Learning for UAV autonomous path planning},
journal = {Aerospace Science and Technology},
volume = {118},
pages = {107052},
year = {2021},
issn = {1270-9638},
doi = {https://doi.org/10.1016/j.ast.2021.107052},
url = {https://www.sciencedirect.com/science/article/pii/S1270963821005629},
author = {Lei He and Nabil Aouf and Bifeng Song},
keywords = {Unmanned Aerial Vehicles (UAVs), Autonomous navigation, Deep Reinforcement Learning (DRL), Explainable AI},
abstract = {Autonomous navigation in unknown environment is still a hard problem for small Unmanned Aerial Vehicles (UAVs). Recently, some neural network-based methods are proposed to tackle this problem, however, the trained network is opaque, non-intuitive and difficult for people to understand, which limits the real-world application. In this paper, a novel explainable deep neural network-based path planner is proposed for quadrotor to fly autonomously in unknown environment. The navigation problem is modelled as a Markov Decision Process (MDP) and the path planner is trained using Deep Reinforcement Learning (DRL) method in simulation environment. To get better understanding of the trained model, a novel model explanation method is proposed based on the feature attribution. Some easy-to-interpret textual and visual explanations are generated to allow end-users to understand what triggered a particular behaviour. Moreover, some global analyses are provided for experts to evaluate and improve the trained network. Finally, real-world flight tests are conducted to illustrate that our path planner trained in the simulation is robust enough to be applied in the real environment directly.}
}
@article{QU2020106099,
title = {A novel reinforcement learning based grey wolf optimizer algorithm for unmanned aerial vehicles (UAVs) path planning},
journal = {Applied Soft Computing},
volume = {89},
pages = {106099},
year = {2020},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2020.106099},
url = {https://www.sciencedirect.com/science/article/pii/S1568494620300399},
author = {Chengzhi Qu and Wendong Gai and Maiying Zhong and Jing Zhang},
keywords = {Unmanned aerial vehicles (UAVs), Three-dimensional path planning, Reinforcement learning, Grey wolf optimizer},
abstract = {Unmanned aerial vehicles (UAVs) have been used in wide range of areas, and a high-quality path planning method is needed for UAVs to satisfy their applications. However, many algorithms reported in the literature may not feasible or efficient, especially in the face of three-dimensional complex flight environment. In this paper, a novel reinforcement learning based grey wolf optimizer algorithm called RLGWO has been presented for solving this problem. In the proposed algorithm, the reinforcement learning is inserted that the individual is controlled to switch operations adaptively according to the accumulated performance. Considering that the proposed algorithm is designed to serve for UAVs path planning, four operations have been introduced for each individual: exploration, exploitation, geometric adjustment, and optimal adjustment. In addition, the cubic B-spline curve is used to smooth the generated flight route and make the planning path be suitable for the UAVs. The simulation experimental results show that the RLGWO algorithm can acquire a feasible and effective route successfully in complicated environment.}
}
@article{ZHANG2020555,
title = {Coarse-to-fine object detection in unmanned aerial vehicle imagery using lightweight convolutional neural network and deep motion saliency},
journal = {Neurocomputing},
volume = {398},
pages = {555-565},
year = {2020},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2019.03.102},
url = {https://www.sciencedirect.com/science/article/pii/S0925231219310422},
author = {Jing Zhang and Xi Liang and Meng Wang and Liheng Yang and Li Zhuo},
keywords = {Unmanned aerial vehicle (UAV) imagery, Object detection, Coarse-to-fine, Lightweight convolutional neural network (CNN), Deep motion saliency},
abstract = {Unmanned aerial vehicles (UAVs) have been widely applied to various fields, facing mass imagery data, object detection in UAV imagery is under extensive research for its significant status in both theoretical study and practical applications. In order to achieve the accurate object detection in UAV imagery on the premise of real-time processing, a coarse-to-fine object detection method for UAV imagery using lightweight convolutional neural network (CNN) and deep motion saliency is proposed in this paper. The proposed method includes three steps: (1) Key frame extraction using image similarity measurement is performed on the UAV imagery to accelerate the successive object detection procedure; (2) Deep features are extracted by PeleeNet, a lightweight CNN, to achieve the coarse object detection on the key frames; (3) LiteFlowNet and objects prior knowledge is utilized to analyze the deep motion saliency map, which further helps to refine the detection results. The detection results on key frames propagate to the temporally nearest non-key frames to achieve the fine detection. Five experiments are conducted to verify the effectiveness of the proposed method on Stanford drone dataset (SDD). The experimental results demonstrate that the proposed method can achieve comparable detection speed but superior accuracy to six state-of-the-art methods.}
}
@article{LYABAKH2021594,
title = {Improvement of Mathematical Tools for Controlling the Group of Unmanned Aerial Vehicles},
journal = {Transportation Research Procedia},
volume = {54},
pages = {594-601},
year = {2021},
note = {International Scientific Siberian Transport Forum - TransSiberia 2020},
issn = {2352-1465},
doi = {https://doi.org/10.1016/j.trpro.2021.02.111},
url = {https://www.sciencedirect.com/science/article/pii/S2352146521002854},
author = {Nikolay Lyabakh and Maksim Kolesnikov and Maksim Bakalov},
keywords = {Territory Connectivity, Unmanned Aerial Vehicles, Artificial Intelligence},
abstract = {The task of controlling unmanned aerial vehicles to solve the problems of territorial connectivity is updated. A complex of interrelated problems of organizing a joint flight of a group of aircrafts is formulated. A mathematical toolkit for calculating the control of an unmanned aerial vehicle that allows solving the problems of both the joint safe synchronous functioning of a group of aircrafts and their individual flight has been developed. To expand the intellectual capabilities of the designed technical system and to ensure human communication with it in natural language as well, it is proposed to use the apparatus of the theory of fuzzy sets that formalizes the operation with linguistic variables and fuzzy concepts. For immersion of flying objects into physical space the concepts of "friend", "foe" are introduced. Using the theory of pattern recognition, the mechanism of identification and operational response of aircrafts to various non-standard and force majeure situations is revealed. The concept of "traffic rules" for aircrafts is introduced and the meaning of their formation and use in airspace is revealed. The possibilities of using game theory for solving conflict situations are analyzed. The place of the catastrophe theory in mathematical description of the processes of aircrafts interaction with each other and with "nature" is indicated. The totality of flying vehicles is considered from the perspective of the theory of multi-agent systems and the theory of active systems that forms emergent (ant, swarm) intelligence in their environment.}
}
@article{KALANTAR2020105748,
title = {A deep learning system for single and overall weight estimation of melons using unmanned aerial vehicle images},
journal = {Computers and Electronics in Agriculture},
volume = {178},
pages = {105748},
year = {2020},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2020.105748},
url = {https://www.sciencedirect.com/science/article/pii/S0168169920304804},
author = {Aharon Kalantar and Yael Edan and Amit Gur and Iftach Klapp},
keywords = {Precision agriculture, Deep convolutional neural network, Machine learning, Yield estimation, Weight estimation},
abstract = {Generation of yield maps enables making agronomic decisions related to resource management and marketing, leading to improved production and breeding processes. Estimating melon yield production before harvest at single-melon resolution is a labor-intensive task, requiring a detailed account of accumulated yield and general yield distribution, as well as detailed measurements of melon size and location. This study presents an algorithmic pipeline for detection and yield estimation of melons from top-view color images acquired by a digital camera mounted on an unmanned aerial vehicle. The yield estimation provides both the number of melons and the weight of each melon. The system includes three main stages: melon detection, geometric feature extraction, and individual melon yield estimation. The melon-detection process was based on the RetinaNet deep convolutional neural network. Transfer learning was used for the training to detect small objects in high-resolution images successfully. The detection process achieved an average precision score of 0.92 with a F1 score of more than 0.9 in a variety of agricultural environments. For each detected melon, feature extraction was applied using the Chan–Vese active contour algorithm and principal component analysis ellipse-fitting method. A regression model that ties the ellipse features to the melon’s weight is presented. The modified (adjusted) RAdj2 value of the regression model was 0.94. The system results for estimating the weight of a single melon measured by the mean absolute percentage error index achieved 16%. The analysis revealed that this could be decreased to 12% error with more accurate geometrical feature extraction. Overall yield estimation derived by summing the weights of all melons in the field resulted in only a 3% underestimation of the actual total yield.}
}
@article{KHAN201946,
title = {Unmanned Aerial Vehicle in the Machine Learning Environment},
journal = {Procedia Computer Science},
volume = {160},
pages = {46-53},
year = {2019},
note = {The 10th International Conference on Emerging Ubiquitous Systems and Pervasive Networks (EUSPN-2019) / The 9th International Conference on Current and Future Trends of Information and Communication Technologies in Healthcare (ICTH-2019) / Affiliated Workshops},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2019.09.442},
url = {https://www.sciencedirect.com/science/article/pii/S1877050919316576},
author = {Asharul Islam Khan and Yaseen Al-Mulla},
keywords = {unmanned aerial vehicle, drone, machine learning, deep learning, object detection, pattern recognition, neural network},
abstract = {Unmanned Aerial Vehicles and machine learning have started gaining attentions of academic and industrial research. The Unmanned Aerial Vehicles have extended the freedom to operate and monitor the activities from remote locations. This study retrieved and synthesized research on the use of Unmanned Aerial Vehicles along with machine learning and its algorithms in different areas and regions. The objective was to synthesize the scope and importance of machine learning models in enhancing Unmanned Aerial Vehicles capabilities, solutions to problems, and numerous application areas. The machine learning implementation has reduced numbers of challenges to Unmanned Aerial Vehicles besides enhancing the capabilities and opening the door to the different sectors. The Unmanned Aerial Vehicles and machine learning association has resulted in fast and reliable outputs. The combination of Unmanned Aerial Vehicles and machine learning has helped in real time monitoring, data collection and processing, and prediction in the computer/wireless networks, smart cities, military, agriculture, and mining.}
}
@article{MENG2021102403,
title = {Investigation and evaluation of algorithms for unmanned aerial vehicle multispectral image registration},
journal = {International Journal of Applied Earth Observation and Geoinformation},
volume = {102},
pages = {102403},
year = {2021},
issn = {0303-2434},
doi = {https://doi.org/10.1016/j.jag.2021.102403},
url = {https://www.sciencedirect.com/science/article/pii/S0303243421001100},
author = {Lingxuan Meng and Ji Zhou and Shaomin Liu and Lirong Ding and Jirong Zhang and Shaofei Wang and Tianjie Lei},
keywords = {Homography estimation, Structural similarity, Multispectral image registration, UAV remote sensing},
abstract = {Automatically registration of unmanned aerial vehicle (UAV) multispectral images is fundamental for subsequent applications. Although many studies exist for visible camera images and satellite multispectral image registration, studies for UAV are still rare. Under this context, this study firstly evaluates the performance of several widely used traditional methods (i.e., SIFT, SURF, ORB, and CFOG) for visible camera and satellite images in UAV multispectral image registration. This study further proposes an unsupervised and end-to-end deep learning network (i.e., DSIM) for multispectral image registration. An evident feature of DSIM is to regress the homography parameters with convolutional neural networks and to use the pyramid structural similarity loss to optimize the network. 1200 groups of UAV multispectral images acquired over three different sites in four months are used to comprehensively test the aforementioned five methods. Results show that CFOG achieves the highest correct matching rate in the test set, followed by DSIM and SIFT. Nevertheless, DSIM is more robust in images with weak or repeated texture than CFOG and SIFT. In addition, performance of CFOG and SIFT is closely related to the number of the found matching points. Based on the findings, we propose a multi-method ensemble strategy to combine CFOG, DSIM, and SIFT according to the number of the found matching points. This strategy outperforms the individual methods with a correct matching rate of 96.2%. Lower correct matching rate of CFOG + SIFT confirms that DSIM and traditional methods are very complementary in UAV multispectral image registrations.}
}
@article{WANG2021101365,
title = {An adaptive deep learning-based UAV receiver design for coded MIMO with correlated noise},
journal = {Physical Communication},
volume = {47},
pages = {101365},
year = {2021},
issn = {1874-4907},
doi = {https://doi.org/10.1016/j.phycom.2021.101365},
url = {https://www.sciencedirect.com/science/article/pii/S1874490721001026},
author = {Zizhi Wang and Wenqi Zhou and Lunyuan Chen and Fasheng Zhou and Fusheng Zhu and Liseng Fan},
keywords = {UAV, MIMO, Correlated noise, Deep learning, CRC},
abstract = {In this paper, we propose an adaptive deep learning-based unmanned aerial vehicle (UAV) receiver design for coded multiple-input multiple-output (MIMO) systems, where the noise in the systems presents some correlation among time domain, which deteriorates the system transmission performance severely. To improve the system performance, we employ the linear convolutional code at the transmitter, and then propose an adaptive deep learning based iterative UAV receiver. The iterative UAV receiver contains three parts: the detector such as zero-forcing (ZF) or minimum mean square error (MMSE) detector, the deep convolutional neural network (DCNN) which can help suppress the noise by capturing the correlation characteristics among noise, and the decoder such as Viterbi decoding. In particular, the cyclic redundancy check (CRC) appended to the code can help control the iteration of the detection, DCNN and decoding, which leads to an adaptive implementation of receiver. Simulation results demonstrate that the proposed UAV receiver can achieve a much better bit error rate (BER) performance over conventional receivers with a reduced computational complexity.}
}
@article{BYCROFT201984,
title = {Comparing random forests and convoluted neural networks for mapping ghost crab burrows using imagery from an unmanned aerial vehicle},
journal = {Estuarine, Coastal and Shelf Science},
volume = {224},
pages = {84-93},
year = {2019},
issn = {0272-7714},
doi = {https://doi.org/10.1016/j.ecss.2019.04.050},
url = {https://www.sciencedirect.com/science/article/pii/S0272771418309697},
author = {Rachel Bycroft and Javier X. Leon and David Schoeman},
keywords = {Machine-learning, Sandy beach, Object-based image analysis, Drones},
abstract = {Sandy beaches are important ecosystems that line a third of the world's ice-free coastlines. Unfortunately, these environments and the life they support are often threatened by various anthropogenic and natural factors. Monitoring sandy beach health is important to aid in appropriate management decisions. One such method of quantifying environmental health is using bioindicators. Ghost crabs are a commonly used sandy beach bioindicator. Current techniques for assessing ghost crab abundance and distribution data involve manually counting each individual burrow opening, which can intrusive and timely for a large area. The aim of this study was to assesses the use of imagery from an unmanned aerial vehicle and machine-learning algorithms as an alternative approach to monitoring ghost crab burrows. The accuracy and transferability of random forest (RF) and convolutional neural networks (CNN) classifiers within an Object-Based Image Analysis (OBIA) framework were tested using hyper-resolution (0.04 m) orthomosaics from four different dates. CNN was a more robust classifier with higher accuracies (max F-score 0.84). Transferability of rule sets and models was limited for both classifiers, particularly when applied to sub-optimal imagery. Overall, we present a feasible workflow that provides ecologist and environmental managers with a cost-effective and less invasive alternative to mapping ghost crab burrows.}
}
@article{CHEN2021108434,
title = {Machine learning-based inversion of water quality parameters in typical reach of the urban river by UAV multispectral data},
journal = {Ecological Indicators},
volume = {133},
pages = {108434},
year = {2021},
issn = {1470-160X},
doi = {https://doi.org/10.1016/j.ecolind.2021.108434},
url = {https://www.sciencedirect.com/science/article/pii/S1470160X21010992},
author = {Botao Chen and Xi Mu and Peng Chen and Biao Wang and Jaewan Choi and Honglyun Park and Sheng Xu and Yanlan Wu and Hui Yang},
keywords = {UAV remote sensing, Water quality inversion, Machine learning, Urban river},
abstract = {Urban rivers play an essential role in the human environment and urban development; because of their narrow and long characteristics, challenging for general remote sensing data sources to meet the monitoring requirements. In order to solve the problem of insufficient application of remote sensing water quality monitoring in urban rivers. In this paper, based on unmanned aerial vehicles (UAV) images and measured water quality data, the genetic algorithm_extreme gradient boosting (GA_XGBoost) algorithm is used to model water quality parameters in the study area, combined with its characteristics of supporting urban river polymorphism learning and semantic feature analysis. The results show that the coefficient of determination (R2) of GA_XGBoost algorithm for chlorophyll a (Chla), total phosphorous (TP), total nitrogen (TN), ammonia–nitrogen (NH3-N) and turbidity (TUB) is 0.855, 0.699, 0.787, 0.694, and 0.597, respectively, indicating a high precision and the predicted results are consistent with the measured data. Meanwhile, this paper compares the GA_XGBoost model with other algorithms: Deep Neural Network (DNN), Random Forest, genetic algorithm_RandomForest (GA_RandomForest), adaptive boosting (AdaBoost) and genetic algorithm_adaptive boosting (GA_AdaBoost), and the performance of the GA_XGBoost model is better. At the same time, data from different periods have been added to verify the model’s applicability. Moreover, based on the inversion results, analyze from the point of view of point source pollution, non-point source pollution, etc., to further investigate the influencing factors that cause urban river pollution. The current method has important practical significance for promoting the intelligent and automatic level of water environment monitoring technology in ecological environmental protection and urban water resources protection.}
}
@article{MAO2021108511,
title = {Deep Learning (DL)-based adaptive transport layer control in UAV Swarm Networks},
journal = {Computer Networks},
volume = {201},
pages = {108511},
year = {2021},
issn = {1389-1286},
doi = {https://doi.org/10.1016/j.comnet.2021.108511},
url = {https://www.sciencedirect.com/science/article/pii/S1389128621004473},
author = {Qian Mao and Lin Zhang and Fei Hu and Elizabeth Serena Bentley and Sunil Kumar},
keywords = {Congestion control, Deep Learning (DL), Network coding, Transport Layer, UAV Networks},
abstract = {This paper focuses on the congestion control issues in Unmanned Aerial Vehicle (UAV) Swarm Networks (USNs). In a USN, many network factors can cause segment loss, including dynamic swarming, high mobility, and link fading loss. With traditional transport layer protocols such as Transmission Control Protocol (TCP), these losses are interpreted as congestion events and will cause the data sending rate being decreased dramatically, therefore impacting throughput. In this paper, a learning-based adaptive network coding scheme is proposed to handle segment loss. In this scheme, a certain amount of redundancy is attached to the original data. If the segment loss is caused by random factors (such as radio interference), the lost segments are retrieved by decoding. However, if the loss is caused by congestion, the sender will retransmit the lost segments and decrease the sending rate. The coding rate is a critical factor, which should guarantee that the random loss can be retrieved by decoding while the congestion loss triggers retransmission and sending rate deduction. To achieve this goal, a Deep Learning (DL) algorithm is proposed, which comprehensively considers the wireless network conditions and dynamically optimizes the coding rate. Our experimental results show that the DL-based network coding scheme provides improved throughput and end-to-end delay compared to the TCP and general network coding schemes.}
}
@article{CUI2021106833,
title = {Adaptive super-twisting trajectory tracking control for an unmanned aerial vehicle under gust winds},
journal = {Aerospace Science and Technology},
volume = {115},
pages = {106833},
year = {2021},
issn = {1270-9638},
doi = {https://doi.org/10.1016/j.ast.2021.106833},
url = {https://www.sciencedirect.com/science/article/pii/S1270963821003436},
author = {Lei Cui and Ruizhi Zhang and Hongjiu Yang and Zhiqiang Zuo},
keywords = {Unmanned aerial vehicles (UAVs), Adaptive super-twisting control, Sliding mode control, Extended state observer (ESO), Gust winds},
abstract = {In this paper, an adaptive control strategy is investigated on trajectory tracking for an unmanned aerial vehicle with four rotors under gust winds. There exist external disturbances in horizontal positions for the reason of the gust winds which are estimated by an adaptive super-twisting extended state observer. An adaptive super-twisting sliding mode controller is designed to track a desired trajectory for the unmanned aerial vehicle with four rotors. Finite-time convergency is shown for the adaptive super-twisting extended state observer and the adaptive super-twisting sliding mode controller. Effectiveness of the adaptive control strategy is shown in experimental results for the unmanned aerial vehicle with four rotors under gust winds.}
}
@article{PAN2021105843,
title = {Beach wrack mapping using unmanned aerial vehicles for coastal environmental management},
journal = {Ocean & Coastal Management},
volume = {213},
pages = {105843},
year = {2021},
issn = {0964-5691},
doi = {https://doi.org/10.1016/j.ocecoaman.2021.105843},
url = {https://www.sciencedirect.com/science/article/pii/S0964569121003264},
author = {Yaoru Pan and Mogens Flindt and Peter Schneider-Kamp and Marianne Holmer},
keywords = {Beach wrack, Unmanned aerial vehicles, Object-based image analysis, Blue carbon ecosystems, Environmental management},
abstract = {As a common phenomenon along the global coastline, beach wrack, which is part of the blue carbon ecosystems (BCEs), has significant ecological values. However, the excessive accumulation of beach wrack can be a nuisance for local residents and tourism. Meanwhile, beach wrack can become a source of greenhouse gas due to the decomposition. Hence, effective monitoring of beach wrack has become a priority for coastal environmental management. As a cost- and labor-saving approach, unmanned aerial vehicles (UAVs) can perform customized flight tasks and achieve aerial images with sub-decimeter spatial resolution. This study investigated the feasibility of using UAVs to map wrack on three different types of beaches. The method of object-based image analysis (OBIA) was applied to classify the aerial images. Three typical machine learning methods, K-Nearest Neighbor (KNN), Support Vector Machine (SVM), and Random Forests (RF), were examined with different feature spaces at several segmentation levels. The results showed that the three machine learning methods performed well with the overall classification accuracy >75%. The tested algorithm, SVM with only RGB as feature space at the segmentation scale 50, was geographically transferable to beaches with different characteristics. This study demonstrated that UAVs can be developed as an applicable tool for beach wrack mapping and monitoring, which will help to better explore the role of beach wrack in BCEs and assist the local municipalities in environmental management of the coastal zone.}
}
@article{HUANG2021107160,
title = {Accuracy evaluation of a new generic Trajectory Prediction model for Unmanned Aerial Vehicles},
journal = {Aerospace Science and Technology},
volume = {119},
pages = {107160},
year = {2021},
issn = {1270-9638},
doi = {https://doi.org/10.1016/j.ast.2021.107160},
url = {https://www.sciencedirect.com/science/article/pii/S1270963821006702},
author = {Mingyang Huang and Washington Yotto Ochieng and Jose Javier {Escribano Macias} and Yi Ding},
keywords = {Unmanned Aerial Vehicle, Trajectory Prediction, Accuracy, Error budget, Validation},
abstract = {Unmanned Aerial Vehicles (UAVs) attract much attention, and they require trajectory information for planning and tactical operations. Based on the current trajectory data obtained by navigation systems, appropriate Trajectory Prediction (TP) models are required to determine future UAV trajectories. Regardless of the disparity of the models, the knowledge of TP accuracy and its performance evaluation are of paramount importance. After the review of extensive literature on current TP models, this paper develops a more accurate TP model by creating valid methodologies for error budgeting and mitigation. This is followed by the specification for quantifying TP accuracy and sub-functional testing employed in the process of model development. The new model is tested and validated by three credible case studies in relation to the most stringent UAV applications. The validation evidence demonstrates that the new model improves TP accuracy based on previous models.}
}
@article{JIAO20191300,
title = {A new approach to oil spill detection that combines deep learning with unmanned aerial vehicles},
journal = {Computers & Industrial Engineering},
volume = {135},
pages = {1300-1311},
year = {2019},
issn = {0360-8352},
doi = {https://doi.org/10.1016/j.cie.2018.11.008},
url = {https://www.sciencedirect.com/science/article/pii/S0360835218305485},
author = {Zeyu Jiao and Guozhu Jia and Yingjie Cai},
keywords = {Oil spill, Unmanned aerial vehicle, Deep convolutional neural network, Otsu algorithm, Maximally stable extremal regions, Intelligent control},
abstract = {This study presents a novel approach to automatic oil spill detection, using unmanned aerial vehicle (UAV) images to realize intelligent control in oil production. Despite considerable effort, oil spills still cannot be detected automatically and effectively due to the complexity of the real production environment, which forces oil enterprises to manually inspect facilities and detect oil spills. To solve the problem, we propose an approach consisting of UAVs, deep learning and traditional algorithms—an approach which divides the oil spill detection task into three independent sub-tasks. First, we constructed a model based on the deep convolutional neural network, which can quickly detect the suspected oil spill area in images to ensure there are no omissions. Second, to remove other obstacles in the images, we adjusted the Otsu algorithm to filter the detection results, which improves precision while not affecting the recall rate. Third, the Maximally Stable Extremal Regions algorithm was used to obtain the detail polygon region from the detection box, thus automatically evaluating the severity of the oil spill. Experiments showed that our method could solve problems effectively, reducing the cost of oil spill detection by 57.2% when compared with the traditional manual inspection process.}
}
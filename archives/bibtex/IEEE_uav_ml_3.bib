@INPROCEEDINGS{9197140,
author={Zein, Mohammad Kassem and Sidaoui, Abbas and Asmar, Daniel and Elhajj, Imad H.},
booktitle={2020 IEEE International Conference on Robotics and Automation (ICRA)}, title={Enhanced Teleoperation Using Autocomplete},
year={2020},
volume={},
number={},
pages={9178-9184},
abstract={Controlling and manning robots from a remote location is difficult because of the limitations one faces in perception and available degrees of actuation. Although humans can become skilled teleoperators, the amount of training time required to acquire such skills is typically very high. In this paper, we propose a novel solution (named Autocomplete) to aid novice teleoperators in manning robots adroitly. At the input side, Autocomplete relies on machine learning to detect and categorize human inputs as one from a group of motion primitives. Once a desired motion is recognized, at the actuation side an automated command replaces the human input in performing the desired action. So far, Autocomplete can recognize and synthesize lines, arcs, full circles, 3-D helices, and sine trajectories. Autocomplete was tested in simulation on the teleoperation of an unmanned aerial vehicle, and results demonstrate the advantages of the proposed solution versus manual steering.},
keywords={Task analysis;Trajectory;Robots;Training;Support vector machines;Manuals;Drones},
doi={10.1109/ICRA40945.2020.9197140},
ISSN={2577-087X},
month={May},}
@INPROCEEDINGS{8575743,
author={Manderson, Travis and Holliday, Andrew and Dudek, Gregory},
booktitle={2018 15th Conference on Computer and Robot Vision (CRV)}, title={Gaze Selection for Enhanced Visual Odometry During Navigation},
year={2018},
volume={},
number={},
pages={110-117},
abstract={We present an approach to enhancing visual odometry and Simultaneous Localization and Mapping (SLAM) in the context of robot navigation by actively modulating the gaze direction to enhance the quality of the odometric estimates that are returned. We focus on two quality factors: i) stability of the visual features, and ii) consistency of the visual features with respect to robot motion and the associated correspondence between frames. We assume that local texture measures are associated with underlying scene content and thus with the quality of the visual features for the associated region of the scene. Based on this assumption, we train a machine-learning system to score different regions of an image based on their texture and then guide the robot's gaze toward high scoring image regions. Our work is targeted towards motion estimation and SLAM for small, lightweight, and autonomous air vehicles where computational resources are constrained in weight, size, and power. However, we believe that our work is also applicable to other types of robotic systems. Our experimental validation consists of simulations, constrained tests, and outdoor flight experiments on an unmanned aerial vehicle. We find that modulating gaze direction can improve localization accuracy by up to 62 percent.},
keywords={Cameras;Simultaneous localization and mapping;Visual odometry;Visualization;Real-time systems;Motion estimation;active sensing;robotics;vision;SLAM},
doi={10.1109/CRV.2018.00025},
ISSN={},
month={May},}
@ARTICLE{8405592,
author={Li, Yan and Pan, Chaofeng and Cao, Xianbin and Wu, Dapeng},
journal={IEEE Transactions on Emerging Topics in Computational Intelligence}, title={Power Line Detection by Pyramidal Patch Classification},
year={2019},
volume={3},
number={6},
pages={416-426},
abstract={Obstacle recognition, especially power line detection, is very important for the safety of unmanned aerial vehicle flight. Current methods for power line detection mainly rely on the assistance of spatial context, such as tower-line correlation. These methods tend to produce low detection rates without auxiliaries while high false alarm rates due to heavy clutters caused by complicated backgrounds. In this paper, we propose a pyramidal patch classification framework that explicitly excludes the clutters without any extra auxiliaries. This framework enables good balance between detection precision and time-critical requirement; thanks to the proposed hierarchical patches partition and selection strategy. Accordingly, we design a new spatial grid pooling layer for our convolutional-neural-networks-based classifier, which is trained on the set of pyramidal patches. The final power lines are obtained by line detection in each patch of the smallest size, coupled with a line-line correlation procedure. Our experiments show that the proposed method can eliminate most false alarms and obtain a high detection rate with low computational cost.},
keywords={Image segmentation;Feature extraction;Correlation;Detection algorithms;Safety;Unmanned aerial vehicles;Time factors;Power line detection;aerial images;pyramidal patch classification;spatial grid pooling},
doi={10.1109/TETCI.2018.2849414},
ISSN={2471-285X},
month={Dec},}
@INPROCEEDINGS{8056589,
author={Maltezos, Evangelos and Doulamis, Anastasios and Ioannidis, Charalabos},
booktitle={2017 9th International Conference on Virtual Worlds and Games for Serious Applications (VS-Games)}, title={Improving the visualisation of 3D textured models via shadow detection and removal},
year={2017},
volume={},
number={},
pages={161-164},
abstract={Although shadows in images have a constructive role providing a natural view of features of the scene, they also have a destructive role in image processing by hiding significant information. Improving the quality of 3D textured models for serious games and augmented reality applications via shadow detection and removal remains challenging due to the complexity of an image scene. This paper proposes an efficient shadow detection and removal framework based on deep Convolutional Neural Networks (CNNs) and enhanced morphological operations. An orthoimage generated from high resolution RGB/UAV images, and a dense image matching digital surface model of a complex urban area of Santorini island in Greece, was used as a test dataset. First, the orthoimage is converted into the invariant to shadow color space of HSV. Then, a binary shadow mask is extracted applying the CNN which is trained using the HSV image and training samples polygons of shadows and nonshadow areas. To recover the shadowed areas of the orthoimage, a shadow removal process is applied via enhanced morphological operations. Finally, the corresponding 3D textured model colored by the final recovered orthoimage is extracted. The shadow detection and removal results illustrate the robustness, efficiency and the flexibility of the proposed framework.},
keywords={Feature extraction;Training;Image color analysis;Machine learning;Support vector machines;Visualization;Three-dimensional displays;Shadow detection;3D textured modelling;visualization},
doi={10.1109/VS-GAMES.2017.8056589},
ISSN={2474-0489},
month={Sep.},}
@INPROCEEDINGS{8101984,
author={Akram, Raja Naeem and Markantonakis, Konstantinos and Mayes, Keith and Habachi, Oussama and Sauveron, Damien and Steyven, Andreas and Chaumette, Serge},
booktitle={2017 IEEE/AIAA 36th Digital Avionics Systems Conference (DASC)}, title={Security, privacy and safety evaluation of dynamic and static fleets of drones},
year={2017},
volume={},
number={},
pages={1-12},
abstract={Interconnected everyday objects, either via public or private networks, are gradually becoming reality in modern life — often referred to as the Internet of Things (IoT) or Cyber-Physical Systems (CPS). One stand-out example are those systems based on Unmanned Aerial Vehicles (UAVs). Fleets of such vehicles (drones) are prophesied to assume multiple roles from mundane to high-sensitive applications, such as prompt pizza or shopping deliveries to the home, or to deployment on battlefields for battlefield and combat missions. Drones, which we refer to as UAVs in this paper, can operate either individually (solo missions) or as part of a fleet (group missions), with and without constant connection with a base station. The base station acts as the command centre to manage the drones' activities; however, an independent, localised and effective fleet control is necessary, potentially based on swarm intelligence, for several reasons: 1) an increase in the number of drone fleets; 2) fleet size might reach tens of UAVs; 3) making time-critical decisions by such fleets in the wild; 4) potential communication congestion and latency; and 5) in some cases, working in challenging terrains that hinders or mandates limited communication with a control centre, e.g. operations spanning long period of times or military usage of fleets in enemy territory. This self-aware, mission-focused and independent fleet of drones may utilise swarm intelligence for a), air-traffic or flight control management, b) obstacle avoidance, c) self-preservation (while maintaining the mission criteria), d) autonomous collaboration with other fleets in the wild, and e) assuring the security, privacy and safety of physical (drones itself) and virtual (data, software) assets. In this paper, we investigate the challenges faced by fleet of drones and propose a potential course of action on how to overcome them.},
keywords={Drones;Particle swarm optimization;Security;Privacy;Robot sensing systems;Safety},
doi={10.1109/DASC.2017.8101984},
ISSN={2155-7209},
month={Sep.},}
@INPROCEEDINGS{9447127,
author={Raman, Ramakrishnan and Jeppu, Yogananda},
booktitle={2021 IEEE International Systems Conference (SysCon)}, title={Does The Complex SoS Have Negative Emergent Behavior? Looking For Violations Formally},
year={2021},
volume={},
number={},
pages={1-7},
abstract={A complex system is characterized by emergence of global properties. These emergent properties are very difficult to anticipate just from complete knowledge of component behaviors. Characteristics of complex systems discussed in literature include emergence, hierarchical organization and numerosity. Recently, there has been an increase on the adoption of various neural network-based machine learning models to govern the functionality and behavior of systems. With this increasing system complexity, there is increasing challenge in attaining confidence in systems. The ease with which systems are getting interconnected is permeating numerous system-of-systems (SoS), wherein multiple independent systems are expected to interact and collaborate to achieve unparalleled levels of functionality. Traditional verification and validation approaches are often inadequate to bring in the nuances of potential emergent behavior in a system-of-system, which may be positive or negative. In this paper, we look for violations formally in the emergent behavior of a complex SoS. The case study pertains to a swarm of autonomous UAVs flying in a formation, and dynamically changing the shape of the formation, to support varying mission scenarios. We use a tool called CBMC which is a bounded model checker that looks at properties in a small defined region and bound and argues on its correctness. The effectiveness and performance of the approach are quantified.},
keywords={Shape;Conferences;Organizations;Machine learning;Tools;Complexity theory;Complex systems},
doi={10.1109/SysCon48628.2021.9447127},
ISSN={2472-9647},
month={April},}
@INPROCEEDINGS{8629174,
author={Hameed, Sarmad and Junejo, Faraz and Zai, Mehtab Anwar Yousuf and Amin, Imran},
booktitle={2018 IEEE 5th International Conference on Engineering Technologies and Applied Sciences (ICETAS)}, title={Prediction of Civilians Killing in the Upcoming Drone Attack},
year={2018},
volume={},
number={},
pages={1-5},
abstract={Terrorism, is use of violence systematic and unlawfully. After the attack on World trade Center on 9th November 2001, Pentagon decided to launch fight against terrorism operations in Afghanistan. The operation started in Afghanistan in 2001 and then with the passage of time the scope of operation was increased to northwest part of Pakistan. Remarkable results have been achieved with this technology but there are also some disadvantages of this technology. The negative impact of using the drone technology is that civilians are also affected by the strikes. First drone attack happened in Waziristan in November 2004, which resulted in the killing of militant's commander, and his companions with civilians were martyred. To minimize the deaths of such local innocent civilians different predictive systems for finding the location and time of next drone strike have been created by the researchers.In this research paper we have designed a predictive system using neural network that how many civilians will be affected by the next drone strike. This system has been designed on the basis of the available data about the drone strikes in Pakistan. Realistic results have been achieved and we are hopeful that this system can save some innocent lives.},
keywords={Drones;Organizations;Terrorism;Biological neural networks;Prediction algorithms;Urban areas;Video surveillance;Drone strikes;UAVs;War;Artificial Neural Networks;predictions},
doi={10.1109/ICETAS.2018.8629174},
ISSN={},
month={Nov},}
@INPROCEEDINGS{9665549,
author={Lakis, Mohammad Jawad and Daher, Naseem},
booktitle={2021 IEEE 3rd International Multidisciplinary Conference on Engineering Technology (IMCET)}, title={A Simple Neural Network for Efficient Real-time Generation of Dynamically-Feasible Quadrotor Trajectories},
year={2021},
volume={},
number={},
pages={113-118},
abstract={In this work, we study the problem of efficiently generating dynamically-feasible trajectories for quadrotors in real-time. A supervised learning approach is used to train a simple neural network with two hidden layers. The training data is generated from a well-established trajectory generation method for quadrotors that minimizes jerk given a fixed time interval. More than a million dynamically-feasible trajectories between two random points in the three-dimensional (3D) space are generated and used as training data. The input of the neural network is a vector composed of initial and desired states, along with the final trajectory time. The output of the neural network generates the motion primitives of the trajectories, as well as the duration or final time of a segment. Simulation results show extremely fast generation of dynamically-feasible trajectories by the proposed learning algorithm, which makes it suitable for real-time implementation.},
keywords={Three-dimensional displays;Motion segmentation;Simulation;Heuristic algorithms;Neural networks;Supervised learning;Training data;Neural Networks;Supervised Learning;Trajectory Generation;Quadrotor UAVs},
doi={10.1109/IMCET53404.2021.9665549},
ISSN={},
month={Dec},}
@INPROCEEDINGS{7337945,
author={Maslim, Reinaldo and He Chaoyi and Zeng Yixi and Jin Linhao and Kocer, Basaran Bahadir and Kayacan, Erdal},
booktitle={2015 IEEE International Conference on Fuzzy Systems (FUZZ-IEEE)}, title={Performance evaluation of adaptive and nonadaptive fuzzy structures for 4D trajectory tracking of quadrotors: A comparative study},
year={2015},
volume={},
number={},
pages={1-7},
abstract={On one hand, we are aware of the fact that quadrotors have been becoming a part of our daily life day to day; on the other hand, their control is still a challenging task as, unlike from the ground vehicles, they do not have enough friction forces to stabilize their motion. What is more, quadrotor's six DOF motion (three translational and three rotational) is controlled by varying only the speeds of its four independent rotors, resulting in under-actuated, highly nonlinear and coupled dynamics. In this paper, conventional proportional-derivative (PD), Mamdani-type fuzzy and TSK-type fuzzy neural network-based controllers have been designed, and their performance have been compared based on both control accuracy and control effort. A realistic trajectory, which is feasible regarding the input constraints of the quadrotor, is generated to test the accuracy and efficiency of the proposed methods. Realistic uncertainties, such as wind and gust conditions, are also given to the system to demonstrate the robustness of the controllers in real-time operation. The adaptive fuzzy-neural controller gives the most accurate trajectory tracking results for a 4D trajectory reducing the error by a factor of 4 when compared to the conventional PD and fuzzy controller although the control effort increases only by 10%.},
keywords={Rotors;Mathematical model;Fuzzy logic;Fuzzy neural networks;Fuzzy control;Acceleration;Accuracy;Quadrotor;UAV;aerial vehicles;fuzzy logic controller;fuzzy neural networks},
doi={10.1109/FUZZ-IEEE.2015.7337945},
ISSN={},
month={Aug},}
@INPROCEEDINGS{9554868,
author={Jin, Pu and Mou, Lichao and Hua, Yuansheng and Xia, Gui-Song and Zhu, Xiao Xiang},
booktitle={2021 IEEE International Geoscience and Remote Sensing Symposium IGARSS}, title={Temporal Relations Matter: A Two-Pathway Network for Aerial Video Recognition},
year={2021},
volume={},
number={},
pages={8221-8224},
abstract={With the increasing volume of aerial videos, the demand for automatically parsing these videos is surging. To achieve this, current researches mainly focus on extracting a holistic feature with convolutions along both spatial and temporal dimensions. However, these methods are limited by small temporal receptive fields and cannot adequately capture long-term temporal dependencies which are important for describing complicated dynamics. In this paper, we propose a novel two-pathway network to model not only holistic features, but also temporal relations for aerial video classification. More specially, our model employs a two-pathway architecture: (1) a holistic representation pathway to learn a general feature of frame appearances and short-term temporal variations and (2) a temporal relation pathway to capture multi-scale temporal relations across arbitrary frames, providing long-term temporal dependencies. Our model is evaluated on event recognition dataset, ERA, and achieves the state-of-the-art results. This demonstrates its effectiveness and good generalization capacity.},
keywords={Three-dimensional displays;Fuses;Neural networks;Feature extraction;Remote sensing;Videos;Aerial video classification;convolutional neural networks (CNNs);holistic features;temporal relations;two-pathway;unmanned aerial vehicles (UAVs)},
doi={10.1109/IGARSS47720.2021.9554868},
ISSN={2153-7003},
month={July},}
@INPROCEEDINGS{8815387,
author={Kurtz, Vince and Lin, Hai},
booktitle={2019 American Control Conference (ACC)}, title={Toward Verifiable Real-Time Obstacle Motion Prediction for Dynamic Collision Avoidance},
year={2019},
volume={},
number={},
pages={2633-2638},
abstract={Next generation Unmanned Aerial Vehicles (UAVs) must reliably avoid moving obstacles. Existing dynamic collision avoidance methods are effective where obstacle trajectories are linear or known, but such restrictions are not accurate to many real-world UAV applications. We propose an efficient method of predicting an obstacle's motion based only on recent observations, via online training of an LSTM neural network. Given such predictions, we define a Nonlinear Probabilistic Velocity Obstacle (NPVO), which can be used select a velocity that is collision free with a given probability. We take a step towards formal verification of our approach, using statistical model checking to approximate the probability that our system will mispredict an obstacle's motion. Given such a probability, we prove upper bounds on the probability of collision in multiagent and reciprocal collision avoidance scenarios. Furthermore, we demonstrate in simulation that our method avoids collisions where state-of-the-art methods fail.},
keywords={Prediction algorithms;Collision avoidance;Training;Probabilistic logic;Uncertainty;Neural networks},
doi={10.23919/ACC.2019.8815387},
ISSN={2378-5861},
month={July},}
@INPROCEEDINGS{8581130,
author={Cirneanu, Andrada Livia and Popescu, Dan and Ichim, Loretta},
booktitle={2018 15th International Conference on Control, Automation, Robotics and Vision (ICARCV)}, title={CNN based on LBP for Evaluating Natural Disasters},
year={2018},
volume={},
number={},
pages={568-573},
abstract={This paper presents a novel evaluation method of areas affected by natural disasters with the purpose of managing these crisis situations. Since it is necessary to have a real overview of a specific area in the shortest time, our methodology proposes a neural network with backpropagation approach for flood detection from UAV images. For this, the Local Binary Pattern (LBP) texture operator is used for areas classification. The LBP operator labels each pixel of the analyzed image by comparing it with its neighbors, which ends with the computation of a binary number that it is converted to decimal format named LBP code. Thus, based on the generated LBP codes, a histogram type feature is computed and used in both training and testing phases of the proposed neural network. Over 50 images obtained with the aid of UAV technology were tested with the proposed neural network and good results in terms of accuracy for flood areas detection were obtained.},
keywords={Training;Biological neural networks;Histograms;Backpropagation;Testing;Training data},
doi={10.1109/ICARCV.2018.8581130},
ISSN={},
month={Nov},}
@ARTICLE{8337902,
author={Yue, Xuejun and Liu, Yongxin and Wang, Jian and Song, Houbing and Cao, Huiru},
journal={IEEE Communications Magazine}, title={Software Defined Radio and Wireless Acoustic Networking for Amateur Drone Surveillance},
year={2018},
volume={56},
number={4},
pages={90-97},
abstract={The advancement of the micro-electro-mechanical sensory industry and open source autopilot stacks, have dramatically reduced the cost and difficulty of making highly maneuverable UAVs. Such ease in flying drones has caused concerns about privacy, public safety, and security. One of the major threats is inadequate control of flying small drones over sensitive areas. In this research, we address this problem through a dual approach: detection and eviction. We propose a distributed system to identify the appearance and the approximate position of unwelcome drones using a wireless acoustic sensor network and machine learning algorithms. Next, we integrate software defined radio transceivers along with machine learning algorithm into a framework to specify and decode the UAV's telemetry protocols. Using decoded information, we can then send control commands to evict the trespassing drone away before sending aggressive surveillance UAVs.},
keywords={Drones;Acoustics;Surveillance;Telemetry;Wireless sensor networks;Acoustic sensors;Wireless communication},
doi={10.1109/MCOM.2018.1700423},
ISSN={1558-1896},
month={April},}
@INPROCEEDINGS{7860044,
author={Mukadam, Kausar and Sinh, Aishwarya and Karani, Ruhina},
booktitle={2016 International Conference on Computing Communication Control and automation (ICCUBEA)}, title={Detection of landing areas for unmanned aerial vehicles},
year={2016},
volume={},
number={},
pages={1-5},
abstract={Unmanned aerial vehicles (UAV), also referred to as drones, are a growing field in computer science with applications in military systems, delivery services, emergency relief and evacuation. One of the primary obstructions to the allowance of UAV journeys over populated areas is the lack of sophisticated automated systems that detect drone landing sites. In this paper, we propose a landing area detection system using machine learning and image processing. This system compares the suitability of various features (RGB Color Model, HSV Color Model, LBP, Edge Density) in determining a suitable drop-off point. Classification on these features has been carried out using Support Vector Machines (Linear, Polynomial and RBF Kernel).},
keywords={Image edge detection;Image color analysis;Support vector machines;Feature extraction;Kernel;Unmanned aerial vehicles;Computers;Support Vector Machines;RGB Colour Model;Sobel Edge Detection;HSV Colour Model;Canny Edge Detection;Local Binary Pattern},
doi={10.1109/ICCUBEA.2016.7860044},
ISSN={},
month={Aug},}
@INPROCEEDINGS{9148044,
author={Liu, Wansong and Chen, Zhu and Zheng, Minghui},
booktitle={2020 American Control Conference (ACC)}, title={An Audio-Based Fault Diagnosis Method for Quadrotors Using Convolutional Neural Network and Transfer Learning},
year={2020},
volume={},
number={},
pages={1367-1372},
abstract={Quadrotor unmanned aerial vehicles (UAVs) have been developed and applied into several types of workplaces, such as warehouses, which usually involve human workers. The co-existence of human and UAVs brings new challenges to UAVs: potential failure of UAVs may cause risk and danger to surrounding human. Effective and efficient detection of such failure may provide early warning to the surrounding human workers and reduce such risk to human beings as much as possible. One of the most common reasons that cause the failure of the UAV's flight is the physical damage to the propellers. This paper presents a method to detect the propellers damage only based on the audio noise caused by the UAV's flight. The diagnostic model is developed based on convolutional neural network (CNN) and transfer learning techniques. The audio data is collected from the UAVs in real time, transformed into the time-frequency spectrogram, and used to train the CNN-based diagnostic model. The developed model is able to detect the abnormal features of the spectrogram and thus the physical damage of the propellers. To reduce the data dependence on the UAV's dynamic models and enable the utilization of the training data from UAVs with different dynamic models, the CNN-based diagnostic model is further augmented by transfer learning. As such, the refinement of the well-trained diagnostic model ground on other UAVs only requires a small amount of UAV's training data. Experimental tests are conducted to validate the diagnostic model with an accuracy of higher than 90%.},
keywords={Propellers;Spectrogram;Time-frequency analysis;Fault diagnosis;Feature extraction;Neural networks;Data models},
doi={10.23919/ACC45564.2020.9148044},
ISSN={2378-5861},
month={July},}
@INPROCEEDINGS{9191266,
author={WuDunn, Marc and Dunn, James and Zakhor, Avideh},
booktitle={2020 IEEE International Conference on Image Processing (ICIP)}, title={Point Cloud Segmentation using RGB Drone Imagery},
year={2020},
volume={},
number={},
pages={2750-2754},
abstract={In recent years, the ubiquity of drones equipped with RGB cameras has made aerial 3D model generation significantly more cost effective than traditional aerial LiDAR-based methods. Most existing aerial 3D point cloud segmentation approaches use geometric methods and are tailored to 3D LiDAR data. In this paper, we propose a pipeline for semantic segmentation of 3D point clouds obtained via photogrammetry from aerial RGB camera images. Our basic approach is to directly apply deep learning segmentation methods to the very RGB images used to create the point cloud itself, followed by back-projecting the pixel class in segmented images onto the 3D points. This is a particularly attractive solution, since deep learning methods for image segmentation are more mature and advanced as compared to 3D point cloud segmentation. Furthermore, GPU engines for 2D image convolutions are likely to result in higher processing speeds than could be achieved using 3D point cloud data. We demonstrate our segmentation approach on two RGB Drone image datasets captured in Alameda, California, and compare its performance with manually labelled ground truth data. We use F1 and Jaccard similarity coefficient scores to show that our methodology outperforms existing methods such as PointNet++ and commercially available packages such as Pix4D.},
keywords={Three-dimensional displays;Image segmentation;Cameras;Two dimensional displays;Pipelines;Buildings;Semantics;UAV Imaging;Drone;Occlusion;Photogrammetry;Semantic Segmentation;Point Cloud},
doi={10.1109/ICIP40778.2020.9191266},
ISSN={2381-8549},
month={Oct},}
@INPROCEEDINGS{9117374,
author={Ho, Ming-Jui and Lin, Yu-Chin and Hsu, Hsin-Chuan and Sun, Tsung-Ying},
booktitle={2019 8th International Conference on Innovation, Communication and Engineering (ICICE)}, title={An Efficient Recognition Method for Watermelon using Faster R-CNN with Post-Processing},
year={2019},
volume={},
number={},
pages={86-89},
abstract={This study proposes a deep learning based recognition approach from aerial photographs for estimating the yield of watermelons. The precise quantity estimation of the yield is favorable for farmers to negotiate prices at marketing and distribution channel. First of all, obtain high-resolution aerial photograph of watermelon field, Faster R-CNN is used as the deep learning architecture, then label samples for training to get the trained model. Next, detect watermelons on the aerial photograph of watermelon field. But the result is not as satisfactory that there are some watermelons didn't be recognized. Therefore, adding two post-processing to improve the results. With cross scanning, the missing rate reduced from 30% to 18%. After filter by HSV color space, the error rate reduced from 6.1% to 1.4%. Testing different amount of samples, the two approaches can provide higher decrease rate in smaller quantities. This study can get well recognition and yield estimation of watermelon from aerial photographs, and saving considerable time than manually label but also has highly accurate.},
keywords={Object detection;Faster-RCNN algorithm;Agriculture;Machine vision;Watermelon Recognition;UAV},
doi={10.1109/ICICE49024.2019.9117374},
ISSN={},
month={Oct},}
@INPROCEEDINGS{9101833,
author={Xiang, Li and Xiaoqin, Liu and Yaohua, Liu},
booktitle={2019 14th IEEE International Conference on Electronic Measurement Instruments (ICEMI)}, title={Attitude estimation based on recurrent neural network and vector observations for attitude and heading reference system},
year={2019},
volume={},
number={},
pages={1382-1387},
abstract={Attitude and heading reference system (AHRS) is indispensible in miniature unmanned aerial vehicles (UAV).Data fusion for magnetometer, accelerometer, and gyroscope in AHRS is usually implemented using extended Kalman filter (EKF) or complementary filter (CF). But due to the curse of dimensionality, sensor error compensation is difficult to be fully included in the design of EKF or CF. In this paper, a novel attitude estimator based on recurrent neural network (RNN) is introduced. This algorithm takes the observations of gravity vector, geomagnetic vector, and angular velocity vector as its inputs, and it can eliminate sensor errors while implementing dynamic attitude estimation. Simulation and experiment results of the proposed algorithm prove its effectiveness.},
keywords={Estimation;Recurrent neural networks;Magnetic separation;Magnetometers;Accelerometers;Kalman filters;Error compensation;Attitude estimation;vector observation;recurrent neural network},
doi={10.1109/ICEMI46757.2019.9101833},
ISSN={},
month={Nov},}
@INPROCEEDINGS{6987738,
author={Motonaka, Kimiko and Watanabe, Keigo and Maeyama, Shoichi},
booktitle={2014 14th International Conference on Control, Automation and Systems (ICCAS 2014)}, title={3-dimensional kinodynamic motion planning for an X4-Flyer using 2-dimensional harmonic potential fields},
year={2014},
volume={},
number={},
pages={1181-1184},
abstract={In this research, it is aimed at guiding an X4-Flyer, which is a VTOL type UAV, to an arbitrary target point. In the previous research, we proposed a controller for an X4-Flyer to move on the X-Y plane by using a 2-dimensional harmonic potential field (HPF), assuming that the X4-Flyer keeps its altitude constantly. In this paper, the controller guides the X4-Flyer to an arbitrary target point in a 3-dimensional space by switching some 2-dimensional HPFs appropriately. It is confirmed on the simulation that the X4-Flyer can reach the arbitrary target point in the 3-dimensional space by using the proposed method.},
keywords={Planning;Switches;Gravity;Robots;Artificial neural networks;Kinodynamics;Potential field;Aerial robots},
doi={10.1109/ICCAS.2014.6987738},
ISSN={2093-7121},
month={Oct},}
@INPROCEEDINGS{8629137,
author={Hameed, Sarmad and Amin, Imran},
booktitle={2018 IEEE 5th International Conference on Engineering Technologies and Applied Sciences (ICETAS)}, title={Detection of Weed and Wheat Using Image Processing},
year={2018},
volume={},
number={},
pages={1-5},
abstract={As the increase in the world population the demand of the wheat is also increases. In order to increase the growth wheat in the wheat crop it is necessary to detect the weed in the wheat crop and the barren land to minimize the growth of weed so that the growth of the wheat can be increased. Weed detection is the important factor to be analyzed. Unmanned Air Vehicle (UAV) is used for data acquisition of wheat crop in different phases so that high quality of RGB images can be captured. The proposed method facilitates the extraction of weed, wheat, and barren land in the wheat crop field using background subtraction. The result shows that background subtraction method is good for detection the weed, barren land, and wheat.},
keywords={Agriculture;Image color analysis;Drones;Neural networks;Meters;Phantoms;Agriculture;computer vision;Automation;Weed detection;Barren land detection;Wheat detection},
doi={10.1109/ICETAS.2018.8629137},
ISSN={},
month={Nov},}
@INPROCEEDINGS{5767317,
author={Kitt, Wong Wei and Chekima, Ali and Dargham, Jamal A. and Wong, Farrah and Tabet, Tamer A.},
booktitle={2010 1st International Conference on Energy, Power and Control (EPC-IQ)}, title={Soft computing control system of an unmanned airship},
year={2010},
volume={},
number={},
pages={22-27},
abstract={Soft computing control systems have been applied in various applications particularly in the fields of robotics controls. The advantage of having a soft computing control methods is that it enable more flexibility to the control system compared with conventional model based controls system. Firstly, soft computing methods enable a transfer of human controls and thinking into the machine via training. Secondly it is more robust to error compared to conventional model based system. In this paper, a UAV airship is controlled using fuzzy logic for its propulsion and steering system. The airship is tested on a simulation level before test flight. The prototype airship has on board GPS and compass for telemetry and transmitted to the ground control system via a wireless link.},
keywords={Control systems;Global Positioning System;Atmospheric modeling;Target tracking;Artificial neural networks;Decision making;Fuzzy logic},
doi={},
ISSN={},
month={Nov},}
@INPROCEEDINGS{9553056,
author={Wang, Minghui and Li, Qingpeng and Pan, Junjun and Gu, Yunchao},
booktitle={2021 IEEE International Geoscience and Remote Sensing Symposium IGARSS}, title={SCSF-Net: Single Class Scale Fixed Network for Object Detection in Optical Remote Sensing Images on Limited Hardware},
year={2021},
volume={},
number={},
pages={4184-4187},
abstract={The detection of objects such as vehicle, airplane and ship is a fundamental problem in optical remote-sensing(ORS) image process. Despite a great success has achieved by migrating nature image detection methods to the remote sensing field, some challenges in hardware limit environments still remain to be solved, e.g., space-borne hardware and UAV-borne hardware. We proposed a low-computational network by digging several prior knowledge in the remote sensing field. By focusing on certain ground sample distance(gsd) and single target class, the proposed method gains high performance with only less than 1% parameters and less than 1% computation used comparing with the state-of-the-art detection method. Detection result on public available vehicle dataset demonstrates the effectiveness of the proposed method. Meanwhile, the ship and airplane detection results of two private datasets are also shown. Our vehicle detection code on limited hardware is now available at https://github.com/minghuicode/scsf-detector.},
keywords={Knowledge engineering;Airplanes;Vehicle detection;Object detection;Optical fiber networks;Optical imaging;Hardware;optical remote sensing(ORS) image;small object detection;vehicle detection;limit hardware;deep learning},
doi={10.1109/IGARSS47720.2021.9553056},
ISSN={2153-7003},
month={July},}
@INPROCEEDINGS{9613180,
author={Wang, Zheng and Yu, Hui and Zhu, Shichao and Yang, Bo},
booktitle={2021 13th International Conference on Wireless Communications and Signal Processing (WCSP)}, title={Curriculum Reinforcement Learning-Based Computation Offloading Approach in Space-Air-Ground Integrated Network},
year={2021},
volume={},
number={},
pages={1-6},
abstract={Space-air-ground integrated network (SAGIN) is emerging as a prominent framework supporting the ever-growing Internet of Things (IoT) applications in the areas without infrastructures. In this paper, we investigate the problem of IoT task offloading under the SAGIN scenario where multiple IoT devices cooperatively use computing resources. We formulate the task offloading problem of minimizing the processing delay of all tasks, taking into account the dynamics of tasks generated by each IoT device, the mobility of unmanned aerial vehicle (UAV), and the difference in computing power between the UAV and the low earth orbit (LEO) satellite. Then the problem is formulated as a Markov decision process (MDP). To cope with the dynamics and complexity of the system, as well as the training difficulties caused by the large number of agents, we propose a curriculum learning-multi-agent deep deterministic policy gradient (CL-MADDPG) approach to learn the near-optimal offloading strategy. Simulation results show that the proposed method has satisfactory convergency and can significantly reduce the average task processing delay.},
keywords={Wireless communication;Satellites;Simulation;Low earth orbit satellites;Signal processing algorithms;Autonomous aerial vehicles;Delays;Edge computing;SAGIN;MDP;offloading},
doi={10.1109/WCSP52459.2021.9613180},
ISSN={2472-7628},
month={Oct},}
@INPROCEEDINGS{9588193,
author={Chen, Long and Hu, Jingyi and Li, Xuanfu and Quan, Fengyu and Chen, Haoyao},
booktitle={2021 IEEE 11th Annual International Conference on CYBER Technology in Automation, Control, and Intelligent Systems (CYBER)}, title={Onboard Real-time Object Detection for UAV with Embedded NPU},
year={2021},
volume={},
number={},
pages={192-197},
abstract={Unmanned aerial vehicles (UAVs) endowed with the function of computer vision are widely applied. There is an urgent need to implement real-time object detection. However, the limited memory and computing capacity of current embedded devices prevent the deployment of deep learning on UAVs. Therefore, this paper proposes an efficient onboard object detection system based on an embedded NPU device. It can be deployed on a UAV to perform real-time scenario analysis. Firstly, a deep-learning network structure based on YOLOV3-Tiny is designed for object detection. Then it is compressed by a novel pruning strategy to obtain a “slim” object detector. Finally, a detection-reinitialization mechanism is introduced to realize the robust output of detection. The experimental results demonstrate that our model and algorithm achieve efficient performance of detection compared to the unoptimized benchmark. The proposed model achieves up to 0.591 mAP with a 6M parameter size. The complete system is tested in both simulation and real environments of the aerial manipulator grasping task. The effective detection frame ratio reaches 90%, and FPS achieves about 25.},
keywords={Performance evaluation;Visualization;Object detection;Grasping;Manipulators;Real-time systems;Unmanned aerial vehicles},
doi={10.1109/CYBER53097.2021.9588193},
ISSN={2642-6633},
month={July},}
@INPROCEEDINGS{7848380,
author={Faelden, Gerard Ely and Maningo, Jose Martin and Nakano, Reiichiro Christian and Bandala, Argel and Vicerra, Ryan Rhay and Dadios, Elmer},
booktitle={2016 IEEE Region 10 Conference (TENCON)}, title={Implementation of swarm aggregation in quadrotor swarms using an artificial potential function model},
year={2016},
volume={},
number={},
pages={2021-2026},
abstract={Swarm robotics is one of the novel approaches being explored in multiple quadrotor. It aims to mimic social behaviors of animals and insects. This paper presents the physical implementation of the swarm behavior aggregation in a quadrotor swarm. It is implemented over a quadrotor swarm testbed that makes use of external motion capture cameras. The completed algorithm makes use of the artificial potential function model with a linear attraction and bounded repulsion. Results show successful demonstration of the aggregation algorithm with minimal error in position. It is tested for an increasing number of quadrotors and errors are seen to increase with swarm size. Results show an error of 3.293 cm from the individual target position for aggregation. It also shows and average aggregation speed of 1.896 secs for all test while having an increase in aggregation speed of about 1.772 sec per increase in swarm size. The time in aggregate is seen to be at an average of 98.5405% of the time. All the tests show successful demonstration of the swarming behavior which can now mark the start of development of implementation of more complex swarming behaviors.},
keywords={Robot kinematics;Particle swarm optimization;Mathematical model;Insects;Aggregates;Swarm Intelligence;Swarm Behaviors;Aggregation;Artificial Potential Function;Quadrotors},
doi={10.1109/TENCON.2016.7848380},
ISSN={2159-3450},
month={Nov},}
@INPROCEEDINGS{9058018,
author={Mekky, Ahmed and Alberts, Thomas E. and González, Oscar R.},
booktitle={2019 IEEE National Aerospace and Electronics Conference (NAECON)}, title={Experimental Implementation of an ANN Controller for Quadrotor Trajectory Control in Confined Environment},
year={2019},
volume={},
number={},
pages={573-580},
abstract={This paper presents the experimental results of the trajectory control of a Qball-X4 quadrotor in confined environments and with the presence of model uncertainties. The presented controller utilizes Artificial-Neural-Networks to adjust for aerodynamic and model uncertainties on-line. The provided experimental results show the robustness and effectiveness of the developed ANN controller when applied to the Qball X4 quadrotor.},
keywords={Experimental Implementation;Real-Time Quadrotor Control;Artificial Neural Networks Control;Stochastic Basis Function;Quadrotor Control;Nonlinear Control;Robust Control;UAV},
doi={10.1109/NAECON46414.2019.9058018},
ISSN={2379-2027},
month={July},}
@INPROCEEDINGS{7905967,
author={Pan, Chaofeng and Cao, Xianbin and Wu, Dapeng},
booktitle={2016 IEEE Global Conference on Signal and Information Processing (GlobalSIP)}, title={Power line detection via background noise removal},
year={2016},
volume={},
number={},
pages={871-875},
abstract={Tiny target detections, especially power line detection, have received great attention due to its critical role in ensuring the flight safety of low-flying unmanned aerial vehicles (UAVs). In this paper, an accurate and robust power line detection method is proposed, wherein background noise is mitigated by an embedded convolution neural network (CNN) classifier before conducting the final power line extractions. Our proposed method operates in three steps: 1) extract edge features of power lines from a testing image, 2) employ a CNN classifier to remove the background noise, 3) use a Hough-Transform (HT) based fine-selection module to locate power lines. Comprehensive experiments demonstrate the superiority of the proposed method, compared to the state-of-the-art methods.},
keywords={Image edge detection;Feature extraction;Noise measurement;Transforms;Testing;Reliability;Correlation;power line detection;image processing;machine learning;classification;edge feature},
doi={10.1109/GlobalSIP.2016.7905967},
ISSN={},
month={Dec},}
@ARTICLE{9635801,
author={Shao, Shikai and Shi, Weilong and Zhao, Yuanjie and Du, Yun},
journal={IEEE Access}, title={A New Method of Solving UAV Trajectory Planning Under Obstacles and Multi-Constraint},
year={2021},
volume={9},
number={},
pages={161161-161180},
abstract={Multi-constraint trajectory planning for unmanned aerial vehicles (UAVs) has been widely used in military and civil fields. The existing path planning methods, such as swarm intelligence algorithm and graph-based algorithm, cannot incorporate the flying time and UAV kinematic model into evolution. To overcome such disadvantage, a method of solving trajectory planning under obstacles and multi-constraint is investigated in this paper. Firstly, the flying time is discretized as a certain number of Chebyshev points which are the optimized moments of control variable, and they can reduce the computational burden. The process of solution is divided into multi-phase, i.e., two points as a phase to generate the trajectory. Then, angular velocity is taken as control variable, and function of angular velocity is solved by cubic spline interpolation. Besides, functions of angle and position are obtained by integration. The results are substituted into the model consisted by particle swarm optimization (PSO) and the UAV kinematic model to optimize. On this basis, the angular velocity, angle and position are calculated according to the allocated moments. Finally, Monte-Carlo simulation and comparison with existed method are carried out in obstacle environment. All the results illustrate that the multi-phase method can calculate the kinematic parameters of UAV accurately and plan smooth trajectories. Meanwhile, the proposed method is easier to meet the complicated constraints than the single-phase method. In addition, the dimensionality of solution is also enriched effectively.},
keywords={Trajectory planning;Kinematics;Trajectory;Autonomous aerial vehicles;Heuristic algorithms;Computational modeling;Splines (mathematics);Unmanned aerial vehicles;trajectory planning;kinematic model;particles warm optimization;cubic spline interpolation},
doi={10.1109/ACCESS.2021.3132650},
ISSN={2169-3536},
month={},}
@INPROCEEDINGS{6871963,
author={Collotta, Mario and Pau, Giovanni and Caponetto, Riccardo},
booktitle={2014 International Symposium on Power Electronics, Electrical Drives, Automation and Motion}, title={A real-time system based on a neural network model to control hexacopter trajectories},
year={2014},
volume={},
number={},
pages={222-227},
abstract={Modern aerospace vehicles are expected to have non-conventional flight envelopes and, in order to operate in uncertain environments, they must guarantee a high level of robustness and adaptability. A Neural Networks (NN) controller, with real-time learning capability, can be used in applications with manned or unmanned aerial vehicles. In this paper we propose a realtime system, based on a NN model, in order to control the trajectories of a hexacopter. The paper shows a performance evaluation, through a real experimental testbed, of the proposed approach in terms of error measures and obtained coordinates of the hexacopter.},
keywords={Real-time systems;Artificial neural networks;Control systems;Training;Sensors;Kernel;Flight Controller;Neural Network;Real-time Systems;UAV},
doi={10.1109/SPEEDAM.2014.6871963},
ISSN={},
month={June},}
@ARTICLE{9585603,
author={Elhousni, Mahdi and Zhang, Ziming and Huang, Xinming},
journal={IEEE Access}, title={Height Prediction and Refinement From Aerial Images With Semantic and Geometric Guidance},
year={2021},
volume={9},
number={},
pages={145638-145647},
abstract={Deep learning provides a powerful new approach to many computer vision tasks. Height prediction from aerial images is one of those tasks which benefited greatly from the deployment of deep learning, thus replacing traditional multi-view geometry techniques. This manuscript proposes a two-stage approach to solve this task, where the first stage is a multi-task neural network whose main branch is used to predict the height map resulting from a single RGB aerial input image, while being augmented with semantic and geometric information from two additional branches. The second stage is a refinement step, where a denoising autoencoder is used to correct some errors in the first stage prediction results, producing a more accurate height map. Experiments on two publicly available datasets show that the proposed method is able to outperform state-of-the-art computer vision based and deep learning-based height prediction methods. Code is publicly available at: https://github.com/melhousni/DSMNet.},
keywords={Semantics;Task analysis;Noise reduction;Deep learning;Three-dimensional displays;Pipelines;Image reconstruction;UAV;height;DSM;CNN;autoencoders;multi-task},
doi={10.1109/ACCESS.2021.3122894},
ISSN={2169-3536},
month={},}
@INPROCEEDINGS{8766391,
author={Kao, Yu-Wei and Samani, Hooman and Tasi, Shu-Chiao and Jalaian, Brian and Suri, Niranjan and Lee, Mike},
booktitle={2019 Global IoT Summit (GIoTS)}, title={Intelligent Search, Rescue, and Disaster Recovery via Internet of Things},
year={2019},
volume={},
number={},
pages={1-7},
abstract={In this paper, we study the challenge of enabling an intelligent search, rescue, and disaster recovery operation via Internet of Things (IoT). This paper i) provides a practical research framework to study intelligent search, rescue, and disaster recovery missions, ii) reviews necessary fundamental machine learning algorithms required in object detection and path planning for intelligent search and rescue missions, and iii) demonstrates the feasibility of the proposed architecture using a proof-of-concept hardware-in-the-loop (HIL) simulator framework to support a specific rescue mission scenario. We present the IoT architecture for search, rescue, and disaster recovery missions and verify it by developing a proof-of-concept prototype.},
keywords={Internet of Things;Drones;Atmospheric modeling;Image color analysis;Wiener filters;Colored noise;Path planning;Internet of Things;Machine Learning;Object Detection;Path Planning;Resource Allocation;UAV},
doi={10.1109/GIOTS.2019.8766391},
ISSN={},
month={June},}
@INPROCEEDINGS{9615405,
author={Lutsky, Maksim G. and Sineglazov, Viktor M. and Ishchenko, Vitaly S.},
booktitle={2021 IEEE 6th International Conference on Actual Problems of Unmanned Aerial Vehicles Development (APUAVD)}, title={Suppression of Noise in Visual Navigation Systems},
year={2021},
volume={},
number={},
pages={7-10},
abstract={In this work atmosphere noise influence is considered. Such weather effects on the images greatly decrease accuracy of visual navigation systems, which recognize landmarks to determine current coordinates of unmanned aerial vehicle. It is very important to filter noise on images to increase accuracy of visual navigation system. To filter bad weather conditions on the images using convolution neural networks is proposed. Also math models of different noises on the images is reviewed. Visual navigation system provides autonomous flight of unmanned aerial vehicle in areas where are Global Positioning System signals is absent. For this reason providing best quality of the images due to noise and bad weather conditions filtering is very important for visual navigation system accuracy and performance. Modern computer vision algorithms can't remove full noise on the image. In this case convolution neural networks have a significant advantage and approach is considered.},
keywords={Visualization;Image recognition;Navigation;Convolution;Neural networks;Interference;Unmanned aerial vehicles;quadrocopter;visual navigation system;neural network;computer vision;noise reduction;image filtering;math models of the noise},
doi={10.1109/APUAVD53804.2021.9615405},
ISSN={},
month={Oct},}
@ARTICLE{8962227,
author={Teixeira, Lucas and Oswald, Martin R. and Pollefeys, Marc and Chli, Margarita},
journal={IEEE Robotics and Automation Letters}, title={Aerial Single-View Depth Completion With Image-Guided Uncertainty Estimation},
year={2020},
volume={5},
number={2},
pages={1055-1062},
abstract={On the pursuit of autonomous flying robots, the scientific community has been developing onboard real-time algorithms for localisation, mapping and planning. Despite recent progress, the available solutions still lack accuracy and robustness in many aspects. While mapping for autonomous cars had a substantive boost using deep-learning techniques to enhance LIDAR measurements using image-based depth completion, the large viewpoint variations experienced by aerial vehicles are still posing major challenges for learning-based mapping approaches. In this letter, we propose a depth completion and uncertainty estimation approach that better handles the challenges of aerial platforms, such as large viewpoint and depth variations, and limited computing resources. The core of our method is a novel compact network that performs both depth completion and confidence estimation using an image-guided approach. Real-time performance onboard a GPU suitable for small flying robots is achieved by sharing deep features between both tasks. Experiments demonstrate that our network outperforms the state-of-the-art in depth completion and uncertainty estimation for single-view methods on mobile GPUs. We further present a new photorealistic aerial depth completion dataset that exhibits more challenging depth completion scenarios than the established indoor and car driving datasets. The dataset includes an open-source, visual-inertial UAV simulator for photo-realistic data generation. Our results show that our network trained on this dataset can be directly deployed on real-world outdoor aerial public datasets without fine-tuning or style transfer.},
keywords={Estimation;Simultaneous localization and mapping;Uncertainty;Three-dimensional displays;Task analysis;Training;Aerial systems: perception and autonomy;deep learning in robotics and automation},
doi={10.1109/LRA.2020.2967296},
ISSN={2377-3766},
month={April},}
@INPROCEEDINGS{9613287,
author={Wang, Hongxing and Huang, Zheng and Chen, Yuquan and Zhang, Xin and Shen, Jie and Mao, Weiping and Hao, Zhenyang},
booktitle={2021 13th International Conference on Wireless Communications and Signal Processing (WCSP)}, title={Defect Detection from Power Line Images using Advanced Deep Detectors},
year={2021},
volume={},
number={},
pages={1-5},
abstract={Automatic defect detection from power line images captured by unmanned aerial vehicles (UAV), e.g., drones, using deep learning is an important research topic with significant applications. In this paper, we first collect a large-scale high-resolution power line image dataset and manually annotate the defect bounding boxes. Then, we apply the state-of-the-art deep learning detectors, such as Faster R-CNN, YOLOv4 and FCOS, on this dataset. By applying suitable pre-processing and multi-crop training, we obtain impressive power line defect detection results and provide extensive analysis on the results. The research in this paper can provide a strong baseline for future studies on this challenging computer vision application problem.},
keywords={Deep learning;Wireless communication;Training;Signal processing algorithms;Detectors;Object detection;Signal processing;Defect Detection;Power Line;Deep Learning;Faster R-CNN;FCOS;Baseline},
doi={10.1109/WCSP52459.2021.9613287},
ISSN={2472-7628},
month={Oct},}
@ARTICLE{9321735,
author={Callegaro, Davide and Levorato, Marco},
journal={IEEE Transactions on Vehicular Technology}, title={Optimal Edge Computing for Infrastructure-Assisted UAV Systems},
year={2021},
volume={70},
number={2},
pages={1782-1792},
abstract={The ability of Unmanned Aerial Vehicles (UAV) to autonomously operate is constrained by the severe limitations of their on-board resources. The limited processing capacity and energy storage of these devices inevitably makes the real-time analysis of complex signals – the key to autonomy – challenging. In urban environments, the UAVs can leverage the communication and computation resources of the surrounding city-wide Internet of Things infrastructure to enhance their capabilities. For instance, the UAVs can interconnect with edge computing resources and offload computation tasks to improve response time to sensor input and reduce energy consumption. However, the complexity of the urban topology and large number of devices and data streams competing for the same network and computation resources create an extremely dynamic environment, where poor channel conditions and edge server congestion may penalize the performance of task offloading. This paper develops a framework enabling optimal offloading decisions as a function of network and computation load parameters and current state. The optimization is formulated as an optimal stopping time problem over a semi-Markov process. We solve the optimization problem using Dynamic Programming and Deep Reinforcement learning at different levels of abstraction and prior knowledge of the system underlying stochastic processes. We validate our results in a realistic scenario, where a UAV performs a building inspection task while connected to an edge server.},
keywords={Task analysis;Servers;Unmanned aerial vehicles;Urban areas;Optimization;Internet of Things;Delays;Edge computing;Urban internet of things;Unmanned aerial vehicles;Autonomous systems},
doi={10.1109/TVT.2021.3051378},
ISSN={1939-9359},
month={Feb},}
@ARTICLE{9543551,
author={Akter, Rubina and Doan, Van-Sang and Huynh-The, Thien and Kim, Dong-Seong},
journal={IEEE Transactions on Vehicular Technology}, title={RFDOA-Net: An Efficient ConvNet for RF-Based DOA Estimation in UAV Surveillance Systems},
year={2021},
volume={70},
number={11},
pages={12209-12214},
abstract={This paper presents a convolution neural network (CNN)-based direction of arrival (DOA) estimation method for radio frequency (RF) signals acquired by a nonuniform linear antenna array (NULA) in unmanned aerial vehicle (UAV) localization systems. The proposed deep CNN, namely RFDOA-Net, is designed with three primary processing modules, such as collective feature extraction, multi-scaling feature processing, and complexity-accuracy trade-off, to learn the multi-scale intrinsic characteristics for multi-class angle classification. In several specific modules, the regular convolutional and grouped convolutional layers are leveraged with different filter sizes to enrich diversified features and reduce network complexity besides adopting residual connection to prevent vanishing gradient. For performance evaluation, we generate a synthetic signal dataset for DOA estimation under the multipath propagation channel with the presence of additive noise, propagation attenuation and delay. In simulations, the effectiveness of RFDOA-Net is investigated comprehensively with various processing modules and antenna configurations. Compared with several state-of-the-art deep learning-based models, RFDOA-Net shows the superiority in terms of accuracy with over 94% accuracy at 5 dB signal-to-noise ratio (SNR) with cost-efficiency.},
keywords={Direction-of-arrival estimation;Estimation;Feature extraction;Array signal processing;Linear antenna arrays;Convolution;Antenna arrays;Convolution neural network;direction of arrival estimation;nonuniform linear antenna array},
doi={10.1109/TVT.2021.3114058},
ISSN={1939-9359},
month={Nov},}
@INPROCEEDINGS{8891204,
author={Liu, Mushuang and Wan, Yan and Li, Songwei and Lewis, Frank L.},
booktitle={2019 IEEE 90th Vehicular Technology Conference (VTC2019-Fall)}, title={Learning and Uncertainty-Exploited Directional Antenna Control for Robust Aerial Networking},
year={2019},
volume={},
number={},
pages={1-5},
abstract={Aerial communication using directional antennas (ACDA) is a promising solution to enable long-distance and broad-band unmanned aerial vehicle (UAV)-to-UAV communication. The automatic alignment of directional antennas allows transmission energy to focus in certain direction and hence significantly extends communication range and rejects interference. In this paper, we develop reinforcement learning (RL)-based on-line directional antennas control solutions for the ACDA system. The novel stochastic optimal control algorithm integrates RL, an effective uncertainty evaluation method called multivariate probabilistic collocation method (MPCM), and unscented Kalman Filter (UKF) for the nonlinear random switching dynamics. Simulation studies are conducted to illustrate and validate the proposed solutions.},
keywords={Directional antennas;Switches;Optimal control;Transmitting antennas;Stochastic processes;Atmospheric modeling;Unmanned aerial vehicles},
doi={10.1109/VTCFall.2019.8891204},
ISSN={2577-2465},
month={Sep.},}
@INPROCEEDINGS{9057865,
author={Zhang, Shiqi and Stewart, Christopher},
booktitle={2019 IEEE National Aerospace and Electronics Conference (NAECON)}, title={Computational Thinking Curriculum for Unmanned Aerial Systems},
year={2019},
volume={},
number={},
pages={122-125},
abstract={Unmanned aerial systems (UAS) can explore common, vast and unsafe places at low cost. They could transform multiple sectors from photography to farming to city planning. However, the software underlying UAS is complex and requires multiple distinct programming skills, e.g., AI, machine learning and flight control. Few programmers encompass these skills, hampering software development and dampening the impact of UAS. We contend that early exposure to UAS software could help align workforce skills. However, early exposure requires curriculum that (1) captures the breadth of UAS software, (2) supports multiple levels of depth for diverse programming backgrounds and (3) fits within resource and institutional challenges. We propose a computational thinking framework. In our approach, lessons fit within 20-30 minute instructional blocks, making them usable in short workshop and extended classroom settings. UAV topics and computational thinking depth link lessons. Teachers can trade breadth for in-depth coding and vice versa. In early work, we presented an autonomous UAS to middle school students. Our 1 hour workshop focused on breadth and was received well.},
keywords={Software;Conferences;Artificial intelligence;Drones;Face;Password;FAA},
doi={10.1109/NAECON46414.2019.9057865},
ISSN={2379-2027},
month={July},}
@INPROCEEDINGS{7926512,
author={Lee, Jangwon and Wang, Jingya and Crandall, David and Šabanović, Selma and Fox, Geoffrey},
booktitle={2017 First IEEE International Conference on Robotic Computing (IRC)}, title={Real-Time, Cloud-Based Object Detection for Unmanned Aerial Vehicles},
year={2017},
volume={},
number={},
pages={36-43},
abstract={Real-time object detection is crucial for many applications of Unmanned Aerial Vehicles (UAVs) such as reconnaissance and surveillance, search-and-rescue, and infrastructure inspection. In the last few years, Convolutional Neural Networks (CNNs) have emerged as a powerful class of models for recognizing image content, and are widely considered in the computer vision community to be the de facto standard approach for most problems. However, object detection based on CNNs is extremely computationally demanding, typically requiring high-end Graphics Processing Units (GPUs) that require too much power and weight, especially for a lightweight and low-cost drone. In this paper, we propose moving the computation to an off-board computing cloud, while keeping low-level object detection and short-term navigation onboard. We apply Faster Regions with CNNs (R-CNNs), a state-of-the-art algorithm, to detect not one or two but hundreds of object types in near real-time.},
keywords={Object detection;Drones;Cloud computing;Cameras;Robots;Real-time systems;Estimation;Robot Vision;Object Detection;Unmanned Aerial Systems;Convolutional Neural Networks},
doi={10.1109/IRC.2017.77},
ISSN={},
month={April},}
@INPROCEEDINGS{8798039,
author={Verberne, Johannes and Moncayo, Hever},
booktitle={2019 International Conference on Unmanned Aircraft Systems (ICUAS)}, title={Robust Control Architecture for Wind Rejection in Quadrotors},
year={2019},
volume={},
number={},
pages={152-161},
abstract={Current efforts at the Advanced Dynamics and Control Laboratory (ADCL) at Embry-Riddle Aeronautical University (ERAU) are focusing on the implementation of robust control laws for disturbance rejection in quadrotors. This paper describes the development of two types of control architectures in an effort to reject or minimize wind effects in quadrotor UAVs. The design of a novel extension of the classic Non-Linear Dynamic Inversion (NLDI) control architecture for wind disturbance rejection is presented. This is followed by the application of adaptive artificial neural networks (ANN) to augment the classic NLDI control law designed to correct inversion errors caused by wind disturbance. Models are presented along with a simulation environment for various wind generated forces and moments. Monte Carlo numerical simulations are performed to analyze the performance of the classic NLDI, extended NLDI and NLDI with ANN augmentation under wind conditions. Results show that the NLDI with ANN augmentation outperforms the classic and extended NLDI controllers.},
keywords={Drag;Vehicle dynamics;Artificial neural networks;Blades;Propellers;Force;Wind},
doi={10.1109/ICUAS.2019.8798039},
ISSN={2575-7296},
month={June},}
@INPROCEEDINGS{9062792,
author={Boubin, Jayson and Jones, Aaron M. and Bihl, Trevor},
booktitle={2019 IEEE Vehicular Networking Conference (VNC)}, title={NeuroWav: Toward Real-Time Waveform Design for VANETs using Neural Networks},
year={2019},
volume={},
number={},
pages={1-4},
abstract={Vehicular Ad-Hoc networks depend on clear communication between vehicles using radio frequency in order to operate effectively. Interference from existing technologies using the RF spectrum, e.g. IoT devices, UAV, mobile systems, calls into question the feasibility of future VANET systems without an ability to cut through the noise. One approach to overcome interference is to use waveform design to provide this capability. Regrettably, most traditional algorithms are too computationally complex to perform efficiently in real-time. In this paper, we present early work on NeuroWav: a neural network based approach to waveform design to combat the effects of interference at low latency. NeuroWav is low size, weight, and power, executes 10X faster than the fastest extant waveform design algorithms, and provides performance results comparable with a high fidelity waveform design algorithm. Simulation results are provided that corroborate the theoretical expectations.},
keywords={Interference;Signal to noise ratio;Real-time systems;Neural networks;Convergence;Radio frequency;Feature extraction},
doi={10.1109/VNC48660.2019.9062792},
ISSN={2157-9865},
month={Dec},}
@INPROCEEDINGS{7158930,
author={Abuleil, Ammar M. and Taylor, Graham W. and Moussa, Medhat},
booktitle={2015 12th Conference on Computer and Robot Vision}, title={An Integrated System for Mapping Red Clover Ground Cover Using Unmanned Aerial Vehicles: A Case Study in Precision Agriculture},
year={2015},
volume={},
number={},
pages={277-284},
abstract={In the field of precision agriculture (PA), Un-manned Aerial Vehicles (UAVs) are creating new opportunities for remotely assessing various characteristics of crops. In this paper, we present two main contributions that were evaluated on a novel application: mapping red clover ground cover (RCGC). First, we develop an integrated system for collecting, pre-processing and analyzing aerial data for the mapping of RCGC at a patch-level. Second, we collected, ground-trusted, and pre-processed a RCGC dataset that we make public for further analysis. We evaluated several different machine learning classifiers for mapping image patches to discrete clover coverage levels, reaching an accuracy of 91%.},
keywords={Hyperspectral sensors;Agriculture;Support vector machines;Sensors;Global Positioning System;Accuracy;Data collection;precision agriculture;remote sensing;machine learning;red clover;ground cover;classification},
doi={10.1109/CRV.2015.43},
ISSN={},
month={June},}
@INPROCEEDINGS{9568788,
author={Stache, Felix and Westheider, Jonas and Magistri, Federico and Popović, Marija and Stachniss, Cyrill},
booktitle={2021 European Conference on Mobile Robots (ECMR)}, title={Adaptive Path Planning for UAV-based Multi-Resolution Semantic Segmentation},
year={2021},
volume={},
number={},
pages={1-6},
abstract={In this paper, we address the problem of adaptive path planning for accurate semantic segmentation of terrain using unmanned aerial vehicles (UAVs). The usage of UAVs for terrain monitoring and remote sensing is rapidly gaining momentum due to their high mobility, low cost, and flexible deployment. However, a key challenge is planning missions to maximize the value of acquired data in large environments given flight time limitations. To address this, we propose an online planning algorithm which adapts the UAV paths to obtain high-resolution semantic segmentations necessary in areas on the terrain with fine details as they are detected in incoming images. This enables us to perform close inspections at low altitudes only where required, without wasting energy on exhaustive mapping at maximum resolution. A key feature of our approach is a new accuracy model for deep learning-based architectures that captures the relationship between UAV altitude and semantic segmentation accuracy. We evaluate our approach on the application of crop/weed segmentation in precision agriculture using real-world field data.},
keywords={Image segmentation;Shape;Semantics;Performance gain;Unmanned aerial vehicles;Path planning;Agriculture},
doi={10.1109/ECMR50962.2021.9568788},
ISSN={},
month={Aug},}
@ARTICLE{9365701,
author={Xiao, Rong and Wang, Yuze and Tao, Chao},
journal={IEEE Geoscience and Remote Sensing Letters}, title={Fine-Grained Road Scene Understanding From Aerial Images Based on Semisupervised Semantic Segmentation Networks},
year={2022},
volume={19},
number={},
pages={1-5},
abstract={High-precision electronic maps are required to provide more detailed and accurate information than traditional maps. With the rapid development of high-resolution remote sensing technology, it has become possible to extract fine-grained road scene information such as vehicles, road lines, zebra crossings, ground signs, and lane widths of roads from unmanned aerial vehicle (UAV) remote sensing images, which opens up opportunities for automatic mapping high-precision maps. The traditional method of deciphering remote sensing images is often obtained through manual visual interpretation. Due to the high cost and long lead time of this method, it leads to inefficiencies in updating large amounts of information. To address this problem, this letter models the fine-grained road scene understanding task as an image semantic segmentation problem and innovatively proposes a semisupervised fully convolutional neural network to extract the information efficiently at a low cost. Compared with the traditional supervised full convolutional neural network, this method can simultaneously optimize the standard supervised classification loss on labeled samples and the unsupervised consistency loss on unlabeled samples by using an integrated prediction technology and then input them to the end-to-end semantic segmentation network for training. This method is designed to effectively improve the classification accuracy of the semantic segmentation network and validly alleviates overfitting problems in the case of small numbers of labeled samples. In order to verify the effectiveness of this method, we constructed a data set for experimental, which is used to verify the effect of a variable number of unlabeled samples on model performance. Experimental results show that our method can efficiently complete the extraction of fine-grained road scene information such as vehicles, road lines, zebra crossings, ground signs, and lane widths of roads with a small number of labeled samples.},
keywords={Roads;Semantics;Training;Image segmentation;Data models;Task analysis;Feature extraction;Deep learning;road scene understanding;semisupervised learning (SSL);UAV remote sensing},
doi={10.1109/LGRS.2021.3059708},
ISSN={1558-0571},
month={},}
@INPROCEEDINGS{9061541,
author={Van Dinh, Dzung and Yoon, Byeong-Nam and Le, Hung Ngoc and Nguyen, Uy Quoc and Phan, Khoa Dang and Pham, Lam Dinh},
booktitle={2020 22nd International Conference on Advanced Communication Technology (ICACT)}, title={ICT Enabling Technologies for Smart Cities},
year={2020},
volume={},
number={},
pages={1180-1192},
abstract={A smart city adjusts its social, business, and natural needs, improving the assets it has accessible. Information and Communications Technology (ICT) for shrewd urban areas is to give city answers for encourage an improvement and manageability of a city for the advantage of its population, its economy, and the greater ecosystem in the city. It is to gauge a keen city as far as the enhancements in personal satisfaction and monetary prosperity that are accomplished through applying ICT innovations to design, outline, fabricate, and work the city foundation. In smart city applications, the initial phase in the information's voyage through the application is its gathering by the diverse advancements conveyed all through the city. This paper surveys data acquisition technologies such as Sensor Networks, MANETs, Unmanned Aerial Vehicles (UAVs), Vehicular Ad hoc Networks (VANETs), Internet of Things (IoT), Software-Defined Networking(SDN), Network Functions Virtualization (NFV), 5G. Next, it demonstrates information processing technologies, for example, Cloud Platform, IoT Platform, Big Data Platform, Machine Learning, Deep Learning, and IoT Analytics. Encouraging data spread between various nodes is vital to savvy city acknowledgment. Last, because of the presence of various types of end users (e.g., residents, organizations, government offices, and so forth.) requiring distinctive levels of nature of management, the paper exhibits a proposed testbed solution and recent associated experiments.},
keywords={Wireless sensor networks;Smart cities;Ad hoc networks;Unmanned aerial vehicles;Mobile computing;5G mobile communication;IoT;SDN;NFV;5G;Cloud Platform;IoT Platform;Big Data Platform;IoT Analytics},
doi={10.23919/ICACT48636.2020.9061541},
ISSN={1738-9445},
month={Feb},}
@INPROCEEDINGS{8247496,
author={Loayza, Kleber and Lucas, Pedro and Peláez, Enrique},
booktitle={2017 IEEE Second Ecuador Technical Chapters Meeting (ETCM)}, title={A centralized control of movements using a collision avoidance algorithm for a swarm of autonomous agents},
year={2017},
volume={},
number={},
pages={1-6},
abstract={This work proposes a method for moving a swarm of autonomous Unmanned Aerial Vehicles to accomplish an specific task. The approach uses a centralized strategy which considers a trajectory calculation and collision avoidance. The solution was implemented in a simulated scenario as well as in a real controlled environment using a swarm of nano drones, together with a setup supported by a motion capture system. The solution was tested while planting virtual seeds in a field composed by a grid of points that represent the places to be sown. Experiments were performed for measuring completion times and attempts to prevent impacts in order to test the effectiveness, scalability and stability of the solution as well as the robustness of the collision avoidance algorithm while increasing the number of agents to perform the task.},
keywords={Drones;Collision avoidance;Agriculture;Robustness;Trajectory;agents behavior;swarm systems;collision avoidance;farming automation;UAV},
doi={10.1109/ETCM.2017.8247496},
ISSN={},
month={Oct},}
@ARTICLE{9543650,
author={Wan, Fang and Zhang, Xiaorong},
journal={IEEE Access}, title={Super Resolution Reconstruction Algorithm of UAV Image Based on Residual Neural Network},
year={2021},
volume={9},
number={},
pages={140372-140382},
abstract={With the development of convolutional neural network, video super-resolution algorithm has achieved remarkable success. Because the dependence between frames is complex, traditional methods lack the ability to model the complex dependence, and it is difficult to estimate and compensate the motion accurately in the process of video super-resolution reconstruction. Therefore, a reconstruction network based on optical flow residuals is proposed. In low resolution space, the dense residual network is used to obtain the complementary information of adjacent video frames, and then the optical flow of high-resolution video frames is predicted through the pyramid structure, and then the low resolution video frames are transformed into high-resolution video frames through the sub-pixel convolution layer, The high-resolution video frame is compensated with the predicted high-resolution optical flow. Finally, it is input into the super-resolution fusion network to get better effect. A new loss function training network is proposed to better constrain the network. Experimental results on public data sets show that the reconstruction effect is improved in PSNR, structural similarity and subjective visual effect.},
keywords={Superresolution;Feature extraction;Optical flow;Image resolution;Image reconstruction;Convolution;Convolutional neural networks;Super resolution;optical flow estimation;dense residual block},
doi={10.1109/ACCESS.2021.3114437},
ISSN={2169-3536},
month={},}
@INPROCEEDINGS{9043930,
author={Zhang, Qiuyan and Yang, Zhong and Jiang, Yuhong and Li, Jinsong and Xu, Hao and Xu, Changliang and Zeng, Huarong and Han, Jiaming and Lai, Shangxiang and Li, Hongchen and Xu, Xiangrong},
booktitle={2019 IEEE International Conference on Real-time Computing and Robotics (RCAR)}, title={Attitude Control for Quadcopter with Tilting Rotors using RBFNN-based Adaptive Terminal Sliding Mode Controller},
year={2019},
volume={},
number={},
pages={778-785},
abstract={The traditional quadcopter with four actuators is an under-actuated system, cannot achieve decoupling of line motion and angular motion. Quadcopter with tilting rotors can achieve 6-degree-of-freedom decoupling thanks to the mechanical structure where the motor base allows the motor to rotate around the arm axis, which greatly expands the application scenario of the quadcopter. In this paper, the rigid body dynamics model of the quadcopter with tilting rotors is deduced. In order to solve the non-unique of actuator action caused by over-actuated, a new linear control allocate scheme is adopted. A terminal sliding mode attitude controller(TSMC) based on RBF neural network uncertainty compensator is proposed, and the finite time convergence and global asymptotic stability of the closed-loop system are proved. Parameters of TSMC and RBF are optimized by particle swarm intelligence algorithm with two fitness functions. The main advantage of the proposed method is the ability to observe unknown bounded lumped uncertainties accurately and quickly. Simulation experiments demonstrate the effectiveness and robustness of the proposed controller.},
keywords={Rotors;Mathematical model;Actuators;Attitude control;Force;Resource management;Drones},
doi={10.1109/RCAR47638.2019.9043930},
ISSN={},
month={Aug},}
@INPROCEEDINGS{8667172,
author={Abbas, Ghulam and Nawaz, Menaa and Kamran, Farrukh},
booktitle={2019 16th International Bhurban Conference on Applied Sciences and Technology (IBCAST)}, title={Performance Comparison of NARX amp; RNN-LSTM Neural Networks for LiFePO4 Battery State of Charge Estimation},
year={2019},
volume={},
number={},
pages={463-468},
abstract={The purpose of this research is to evaluate the performance of NARX network and an improved RNN with LSTM artificial neural networks to estimate the SOC of LiFePO4 batteries used in EVs, HEVs, UAVs, UUVs and energy storage systems for power electronics and solar power systems. Due to unequal self-discharge rates, difference in current leakage and temperature under repeated charge discharge cycles of the battery pack, made by series and parallel combinations of different cells to increase the power rating for different applications, the SOC of each battery cell mismatched with respect to others. Therefore, an accurate estimation of SOC is required for optimal power use of Li-Ion battery pack. In this research two neural network models for SOC estimation of LiFePO4 batteries are designed and their performance is evaluated on different parameters. These models are trained by optimal selection of hyper parameters using real time data of voltage, current and battery pack temperature as input and SOC as output of the models. The input dataset has been preprocessed as multivariate time series forecasting problem for RNN-LSTM neural network. The tested results showed that accurate results with an RMSE lower than 0.001 is achieved in NARX and lower than 0.002 is achieved in RNN-LSTM at different test datasets. However, RNN-LSTM has better performance than NARX in multivariate time series in seq2seq future forecasting configuration with an RMSE lower than 0.003 at different test datasets with a temperature range of 5 to 25°C.},
keywords={State of charge;Batteries;Estimation;Delays;Training;Neurons;Data models;Nonlinear Autoregressive with Exogenous input;Recurrent Neural Network;Long Short Time Memory;State of charge},
doi={10.1109/IBCAST.2019.8667172},
ISSN={2151-1411},
month={Jan},}
@INPROCEEDINGS{6908370,
author={Jin, Jonghoon and Gokhale, Vinayak and Dundar, Aysegul and Krishnamurthy, Bharadwaj and Martini, Berin and Culurciello, Eugenio},
booktitle={2014 IEEE 57th International Midwest Symposium on Circuits and Systems (MWSCAS)}, title={An efficient implementation of deep convolutional neural networks on a mobile coprocessor},
year={2014},
volume={},
number={},
pages={133-136},
abstract={In this paper we present a hardware accelerated real-time implementation of deep convolutional neural networks (DCNNs). DCNNs are becoming popular because of advances in the processing capabilities of general purpose processors. However, DCNNs produce hundreds of intermediate results whose constant memory accesses result in inefficient use of general purpose processor hardware. By using an efficient routing strategy, we are able to maximize utilization of available hardware resources but also obtain high performance in real world applications. Our system, consisting of an ARM Cortex-A9 processor and a coprocessor, is capable of a peak performance of 40 G-ops/s while consuming less than 4W of power. The entire platform is in a small form factor which, combined with its high performance at low power consumption makes it feasible to use this hardware in applications like micro-UAVs, surveillance systems and autonomous robots.},
keywords={Program processors;Mobile communication;Robots;Robustness},
doi={10.1109/MWSCAS.2014.6908370},
ISSN={1558-3899},
month={Aug},}
@ARTICLE{8681121,
author={Li, Shuai and Xu, Yuelei and Zhu, Mingming and Ma, Shiping and Tang, Hong},
journal={IEEE Geoscience and Remote Sensing Letters}, title={Remote Sensing Airport Detection Based on End-to-End Deep Transferable Convolutional Neural Networks},
year={2019},
volume={16},
number={10},
pages={1640-1644},
abstract={Rapid intelligent detection of airports from remote sensing images is required to accomplish autonomous intelligent landing of unmanned aerial vehicles (UAVs) and other tasks. To address the insufficiency of traditional models in detecting airports under complicated backgrounds from remote sensing images, we propose an end-to-end remote sensing airport hierarchical expression and detection model based on deep transferable convolutional neural networks. Based on transfer learning, we solve the fundamental problem of overfitting due to the inadequate number of labeled remote sensing images by transferring the network model from natural image source domain to remote sensing image target domain. In addition, we introduce a cascade region proposal network with soft-decision nonmaximal suppression to improve the network structure and the performance of our method under complex backgrounds. Moreover, we use skip-layer feature fusion and hard example mining methods to improve the object expression ability and the training efficiency. Finally, the experimental results demonstrate that the method established in this letter can quickly and effectively detect different types of airports over complex backgrounds and obtain better detection performance than the other detection methods.},
keywords={Airports;Feature extraction;Remote sensing;Atmospheric modeling;Training;Nonhomogeneous media;Task analysis;Airport detection;convolutional neural network;feature fusion;region proposal network (RPN);remote sensing images;transfer learning},
doi={10.1109/LGRS.2019.2904076},
ISSN={1558-0571},
month={Oct},}
@INPROCEEDINGS{9573912,
author={Parvatha, R Sruthi and Ramya, T and Aparanji, G S and Mamtha, M V and Gupta, Anjali and Tom, Rijo Jackson},
booktitle={2021 International Conference on Recent Trends on Electronics, Information, Communication Technology (RTEICT)}, title={Signature Based Radar Target Classification},
year={2021},
volume={},
number={},
pages={873-879},
abstract={This study attempts to categorize ten aerial targets, including fighter jets, missiles, military helicopters, and unmanned aerial vehicles (UAVs). A large dataset comprising of simulations of aerial targets at various aspect angles is taken rather than real-time data in order to attain higher accuracy and better classification. This study proposes a highly accurate multi-model radar target classification system that performs a comparative analysis of machine learning and deep learning algorithms such as Random Forests, Support Vector Classifier (SVC), k-Nearest Neighbors (KNN), Convolutional Neural Networks (CNN), Long Short Term Recurrent Neural Networks (LSTM RNN).},
keywords={Training;Recurrent neural networks;Target recognition;Static VAr compensators;Radar;Data models;Unmanned aerial vehicles;Radar;HRRP;Ensemble Learning;Multi-Voting Classifier;LSTM-RNN;CNN},
doi={10.1109/RTEICT52294.2021.9573912},
ISSN={},
month={Aug},}
@ARTICLE{8836495,
author={Chang, Ming and You, Xuqun and Cao, Zhengyang},
journal={IEEE Access}, title={Bidimensional Empirical Mode Decomposition for SAR Image Feature Extraction With Application to Target Recognition},
year={2019},
volume={7},
number={},
pages={135720-135731},
abstract={This study introduces a target recognition algorithm for synthetic aperture radar (SAR) images based on the features extracted by bidimensional empirical mode decomposition (BEMD). BEMD provides an adaptive and empirical way to process signals, which generates bidimensional intrinsic mode functions (BIMFs) to describe the details of SAR images. Therefore, the generated BIMFs are complementary to the original image and their joint use could probably improve the recognition performance. In order to fully exploit the discrimination of these components, the joint sparse representation (JSR) is employed during the classification. JSR operates as multi-task learning algorithm, which represents each component numerically while considering their inner correlations. The original image together with the generated BIMFs are simultaneously represented by JSR to determine the target label according to the output reconstruction errors. Experimental results on the Moving and Stationary Target Acquisition and Recognition (MSTAR) data set demonstrate the validity of the proposed method under different operating conditions. In comparison with some baseline algorithms, the superiority of the proposed method is furtherly validated.},
keywords={Radar polarimetry;Feature extraction;Target recognition;Synthetic aperture radar;Two dimensional displays;Support vector machines;Deep learning;Synthetic aperture radar (SAR);target recognition;bidimensional empirical mode decomposition (BEMD);joint sparse representation (JSR)},
doi={10.1109/ACCESS.2019.2941397},
ISSN={2169-3536},
month={},}
@INPROCEEDINGS{7152376,
author={Saska, Martin},
booktitle={2015 International Conference on Unmanned Aircraft Systems (ICUAS)}, title={MAV-swarms: Unmanned aerial vehicles stabilized along a given path using onboard relative localization},
year={2015},
volume={},
number={},
pages={894-903},
abstract={A novel approach for stabilization and navigation of swarms of Micro Aerial Vehicles (MAVs) along a predefined path through a complex environment with obstacles is introduced in this paper. The method enables to control large MAV swarms (in literature also called UAV swarms) based only on onboard sensors and without any inter-vehicle communication. The proposed method relies on visual localization modules carried by all MAVs, which provide estimation of the relative positions of neighbours in the swarm. Guess on the positions of the neighbouring MAVs and information on the relative positions of obstacles are integrated into swarm stabilization via Reynolds' Boids model. The performance of the complex system is shown in various numerical simulations and in experiments with a fleet of MAVs in the paper. Presented experimental results with the multi-MAV swarm were conducted in indoor and outdoor environment, and without using any external global localization system such as Vicon motion capture system or GPS localization.},
keywords={Robots;Collision avoidance;Vehicles;Force;Visualization;Shape;Navigation},
doi={10.1109/ICUAS.2015.7152376},
ISSN={},
month={June},}
@INBOOK{8786861,
author={Imran, Muhammad Ali and Sambo, Yusuf Abdulrahman and Abbasi, Qammer H.},
booktitle={Enabling 5G Communication Systems to Support Vertical Industries}, title={Intelligent Positioning of UAVs for Future Cellular Networks},
year={2019},
volume={},
number={},
pages={217-232},
abstract={This chapter provides the use of intelligent algorithms to determine the best position of unmanned aerial vehicles (UAVs) which can be used to enhance the capabilities of existing cellular networks. It presents an intelligent positioning algorithm based on reinforcement learning (RL) and evaluates its performance in an emergency communication network (ECN) scenario. The chapter also presents future applications of UAVs in cellular networks and the state‐of‐the‐art of positioning systems for UAVs in communication networks. It contains a brief summary of how RL works and results of simulations in an ECN scenario. It is clear from the simulations that using intelligent positioning algorithms based on RL is a viable strategy for that. However, more research is needed to design intelligent solutions which can improve multiple KPIs and generalize from past experiences at the same time.},
keywords={Cellular networks;Communication networks;IEEE Sections;Uplink;Computer architecture;Wireless sensor networks;Microprocessors},
doi={10.1002/9781119515579.ch10},
ISSN={},
publisher={IEEE},
isbn={9781119515555},
url={https://ieeexplore-ieee-org.ez294.periodicos.capes.gov.br/document/8786861},}
@INPROCEEDINGS{9594472,
author={Jeon, Byoung-Ju and Petrunin, Ivan and Tsourdos, Antonios},
booktitle={2021 IEEE/AIAA 40th Digital Avionics Systems Conference (DASC)}, title={Recurrent Neural Network based Sensor Fusion Algorithm for Alternative Position, Navigation and Timing},
year={2021},
volume={},
number={},
pages={1-7},
abstract={A new sensor fusion algorithm for Alternative Position, Navigation and Timing (APNT) is designed with deep Recurrent Neural Network (RNN) using Long Short-Term Memory (LSTM). The proposed deep RNN for APNT estimates the position of the Unmanned Aerial Vehicle (UAV) using the UAV position measurements from the holographic radar and the Radio Positioning System (RPS). For the training dataset generation, flight simulations with multiple episodes are conducted with the measurement models of the holographic radar and the RPS. The testing results of the well-trained deep RNN are provided for verification and validation of the proposed deep RNN. The advantage of the proposed deep RNN over the Extended Kalman Filter (EKF) which is a conventional sensor fusion algorithm is demonstrated by comparing their testing results.},
keywords={Training;Recurrent neural networks;Radar measurements;Radio navigation;Aerospace simulation;Radar;Sensor fusion;RNN;LSTM;Sensor fusion;APNT},
doi={10.1109/DASC52595.2021.9594472},
ISSN={2155-7209},
month={Oct},}
@INBOOK{9509953,
author={Basha, Elizabeth and To‐Tran, Jason and Young, Davis and Thalken, Sean and Uramoto, Christopher},
booktitle={Autonomous Airborne Wireless Networks}, title={Airborne Systems and Underwater Monitoring},
year={2021},
volume={},
number={},
pages={237-260},
abstract={Wetlands monitoring requires accurate topographic and bathymetric maps. Regular creation of these with minimal cost and reduced environmental impact, can be achieved using unmanned aerial vehicles (UAVs). This chapter introduces a set of systems needed to create this automation starting with an automatic image labeling system, an online classification system for differentiating land and water, offline bathymetric map creation, and online bathymetric map creation. All systems have been implemented, simulated, and field tested where possible.},
keywords={Classification algorithms;Winches;Wetlands;Unmanned aerial vehicles;Testing;Metals;Machine learning algorithms},
doi={10.1002/9781119751717.ch12},
ISSN={},
publisher={IEEE},
isbn={9781119751694},
url={https://ieeexplore-ieee-org.ez294.periodicos.capes.gov.br/document/9509953},}
@INPROCEEDINGS{9091773,
author={Pandey, Shubha and Sharma, Ritu and Singh, Ghanapriya},
booktitle={2020 3rd International Conference on Emerging Technologies in Computer Engineering: Machine Learning and Internet of Things (ICETCE)}, title={Implementation of 5-Block Convolutional Neural Network (CNN) for Saliency Improvement on Flying Object Detection in Videos},
year={2020},
volume={},
number={},
pages={1-6},
abstract={In this paper an algorithm for detecting a flying object is proposed from the recorded videos using stationary as well as moving camera. Firstly the methods which required less computational power and have less complexity are used. The signature saliency which performs very well and there are very few misses of object detection is used. At the last stage only if required the CNN block is called when the false positive result from previous stages is more.},
keywords={Videos;Object detection;Cameras;Image edge detection;Drones;Video sequences;Training;Flying Object;Drones;UAV;Saliency;CNN;VGG19.},
doi={10.1109/ICETCE48199.2020.9091773},
ISSN={},
month={Feb},}
@INPROCEEDINGS{8301781,
author={Saha, Himadri Nath and Das, Nisith K and Pal, Susanta K and Basu, Srijita and Auddy, Supratim and Dey, Ratul and Nandy, Arnab and Pal, Debjit and Roy, Nirjhar and Mitra, Dipanjan and Biswas, Saunak and Maity, Tamanna},
booktitle={2018 IEEE 8th Annual Computing and Communication Workshop and Conference (CCWC)}, title={A cloud based autonomous multipurpose system with self-communicating bots and swarm of drones},
year={2018},
volume={},
number={},
pages={649-653},
abstract={The concept of Cloud based automated multipurpose system with self-communicating bots controlled by swarm of drones is a comprehensive and layered framework that caters to the needs of multiple facets of an application based project. Swarm robotics is an associate approach to the coordination of multi-robot systems that incorporates massive numbers of individual physical robots. A collective behaviour emerges from the interactions between the robots and interactions of robots with the atmosphere. This approach emerged on the sphere of artificial swarm intelligence influenced by the biological studies of insects, ants and alternative fields in nature, wherever swarm behaviour occurs. A key-component of this design is that the communication between the members of the cluster that build a system of constant feedback. Here the swarm intelligence has been used to devise a system of drones and bots intended for a set of tasks.},
keywords={Drones;Robot kinematics;Cloud computing;Mathematical model;Robot sensing systems;Automation;Swarm;Bots;Master Drone;Defence;Disaster Management;UAV},
doi={10.1109/CCWC.2018.8301781},
ISSN={},
month={Jan},}
@INPROCEEDINGS{9620998,
author={Akter, Rubina and Golam, Mohtasin and Lee, Jae-Min and Kim, Dong-Seong},
booktitle={2021 International Conference on Information and Communication Technology Convergence (ICTC)}, title={Doppler Radar-based Real-Time Drone Surveillance System Using Convolution Neural Network},
year={2021},
volume={},
number={},
pages={474-476},
abstract={In recent years, the availability of commercial unmanned air vehicles (UAVs) or drones has enormously increased due to their device miniaturization and low cost. However, the abuse of UAVs can lead to serious security threats among civilians that need to be investigated and prevented. To alleviate these threats, this paper presents a residual convolution neural network-based surveillance system for drone detection. The network is designed with the two-dimensional and unit convolution layer to successively deal with the Doppler radar signatures. The network extracts generic features through the regular convolution layer, where the advanced features are extracted by the four blocks of the processing unit. Doppler radar database is available in the Kaggle repository used for performance evaluation of the proposed network. The empirical results demonstrate that the proposed model acquired 95.92% classification accuracy and outperform the other deep learning models.},
keywords={Deep learning;Convolution;Computational modeling;Surveillance;Simulation;Feature extraction;Doppler radar;Convolution neural network;drone detection;radar remote sensing;radar detection},
doi={10.1109/ICTC52510.2021.9620998},
ISSN={2162-1233},
month={Oct},}
@ARTICLE{8323305,
author={Salvati, Daniele and Drioli, Carlo and Foresti, Gian Luca},
journal={IEEE Transactions on Emerging Topics in Computational Intelligence}, title={Exploiting CNNs for Improving Acoustic Source Localization in Noisy and Reverberant Conditions},
year={2018},
volume={2},
number={2},
pages={103-116},
abstract={This paper discusses the application of convolutional neural networks (CNNs) to minimum variance distortionless response localization schemes. We investigate the direction of arrival estimation problems in noisy and reverberant conditions using a uniform linear array (ULA). CNNs are used to process the multichannel data from the ULA and to improve the data fusion scheme, which is performed in the steered response power computation. CNNs improve the incoherent frequency fusion of the narrowband response power by weighting the components, reducing the deleterious effects of those components affected by artifacts due to noise and reverberation. The use of CNNs avoids the necessity of previously encoding the multichannel data into selected acoustic cues with the advantage to exploit its ability in recognizing geometrical pattern similarity. Experiments with both simulated and real acoustic data demonstrate the superior localization performance of the proposed SRP beamformer with respect to other state-ofthe-art techniques.},
keywords={Acoustics;Narrowband;Direction-of-arrival estimation;Noise measurement;Estimation;Array signal processing;Microphones;Convolutional neural networks;source localization;direction of arrival estimation;broadband steered response power;acoustic analysis;microphone array},
doi={10.1109/TETCI.2017.2775237},
ISSN={2471-285X},
month={April},}
@INPROCEEDINGS{9448699,
author={Aledhari, Mohammed and Razzak, Rehma and Parizi, Reza M. and Srivastava, Gautam},
booktitle={2021 IEEE 93rd Vehicular Technology Conference (VTC2021-Spring)}, title={Sensor Fusion for Drone Detection},
year={2021},
volume={},
number={},
pages={1-7},
abstract={With the rapid development of commercial drones, drone detection and classification have emerged and grown recently. Drone detection works to detect unmanned aerial vehicles (UAVs). Usually, systems for drone detection utilize a combination of one or more sensors and some methodology. Many unique technologies and methods are used to detect drones. However, each type of technology offers its benefits and limitations. Most approaches use computer vision or machine learning, but one methodology that has not been given much attention is Sensor Fusion. Sensor Fusion has less uncertainty than most methods, making it suitable for drone detection. In this paper, we propose an artificial neural network-based detection system that uses a deep neural network (DNN) to process the RF data and a convolutional neural network (CNN) to process image data. The features from CNNs and DNNs are concatenated and input into another DNN, which outputs a single prediction score of drone presence. Our model achieved a validation accuracy of 75% that shows the feasibility of a sensor fusion based technique for drone detection.},
keywords={Radio frequency;Vehicular and wireless technologies;Uncertainty;Conferences;Machine learning;Sensor fusion;Sensor systems;DNN;CNN;multi-sensor;data fusion;drone;UAVs},
doi={10.1109/VTC2021-Spring51267.2021.9448699},
ISSN={2577-2465},
month={April},}
@ARTICLE{9208685,
author={Yao, Peng and Zhu, Qian and Zhao, Rui},
journal={IEEE Transactions on Cybernetics}, title={Gaussian Mixture Model and Self-Organizing Map Neural-Network-Based Coverage for Target Search in Curve-Shape Area},
year={2020},
volume={},
number={},
pages={1-13},
abstract={This article focuses on the target search problem in a curve-shape area using multiple unmanned aerial vehicles (UAVs), with the demand for obtaining the maximum cumulative detection reward, as well as the constraint of maneuverability and obstacle avoidance. First, the prior target probability map of the curve-shape area, generated by Parzen windows with Gaussian kernels, is approximated by the 1-D Gaussian mixture model (GMM) in order to extract some high-value curve segments corresponding to Gaussian components. Based on the parameterized curve segments from GMM, the self-organizing map (SOM) neural network is then established to achieve the coverage search. The step of winner neuron selection in SOM will prioritize and allocate the curve segments to UAVs, with the comprehensive consideration of multiple evaluation factors and allocation balance. The following step of neuron weight update will plan the UAV paths under the constraint of maneuverability and obstacle avoidance, using the modified Dubins guidance vector field. Finally, the good performance of GMM-SOM is evaluated on a coastline map.},
keywords={Self-organizing feature maps;Search problems;Collision avoidance;Biological neural networks;Gaussian mixture model;Neurons;Curve-shape area;Gaussian mixture model (GMM);modified Dubins guidance vector field;self-organizing map (SOM) neural network;target search;unmanned aerial vehicles (UAVs)},
doi={10.1109/TCYB.2020.3019255},
ISSN={2168-2275},
month={},}
@ARTICLE{9416288,
author={Arzo, Sisay Tadesse and Naiga, Claire and Granelli, Fabrizio and Bassoli, Riccardo and Devetsikiotis, Michael and Fitzek, Frank H. P.},
journal={IEEE Internet of Things Journal}, title={A Theoretical Discussion and Survey of Network Automation for IoT: Challenges and Opportunity},
year={2021},
volume={8},
number={15},
pages={12021-12045},
abstract={The introduction of the Internet of Things (IoT) and massive machine-type communications has implied an increase in network size and complexity. In particular, there is already a huge number of IoT devices in the market in various sectors, such as smart agriculture, smart city, smart home, smart transportation, etc. The IoT interconnectivity technologies are also increasing. Therefore, these are increasingly overwhelming the efforts of network administrators as they try to design, reconfigure and manage such networks. Relying on humans to manage such complex and dynamic networks is becoming unsustainable. Network automation promises to reduce the cost of administration and maintenance of network infrastructure, by offering networks the capability to manage themselves. Network automation is the ability of the network to manage itself. Various standardization organizations are taking the initiative in introducing network automation, such as European Telecommunication Standardization Institute (ETSI). ETSI is leading the standardization activities for network automation. It has provided different versions of reference architecture called generic autonomic network architecture (GANA), which describes a four-level abstraction for network-management decision elements (DEs), protocol level, function level, node level, and network level. In this article, we review and survey the existing works before and after the introduction of software-defined networking (SDN) and network-function-virtualization (NFV). We relate the main trending paradigms being followed, such as SDN, NFV, machine learning (ML), microservices, multiagent system (MAS), containerization, and cloudification, as a pivotal enabler of full network automation. We also discuss the autonomic architectures proposed in the literature. Finally, we presented possible future research directions and challenges that need to be tackled to progress in achieving full network automation.},
keywords={Automation;Internet of Things;Computer architecture;Market research;Software;Monitoring;Cloud computing;Autonomic networking;machine learning;multiagent system (MAS);network function virtualization;network management system (NMS);network softwarization;software-defined networking (SDN)},
doi={10.1109/JIOT.2021.3075901},
ISSN={2327-4662},
month={Aug},}
@ARTICLE{8612450,
author={Kato, Nei and Fadlullah, Zubair Md. and Tang, Fengxiao and Mao, Bomin and Tani, Shigenori and Okamura, Atsushi and Liu, Jiajia},
journal={IEEE Wireless Communications}, title={Optimizing Space-Air-Ground Integrated Networks by Artificial Intelligence},
year={2019},
volume={26},
number={4},
pages={140-147},
abstract={It is widely acknowledged that the development of traditional terrestrial communication technologies cannot provide all users with fair and high quality services due to scarce network resources and limited coverage areas. To complement the terrestrial connection, especially for users in rural, disaster-stricken, or other difficult-to-serve areas, satellites, UAVs, and balloons have been utilized to relay communication signals. On this basis, SAGINs have been proposed to improve the users' QoE. However, compared with existing networks such as ad hoc networks and cellular networks, SAGINs are much more complex due to the various characteristics of three network segments. To improve the performance of SAGINs, researchers are facing many unprecedented challenges. In this article, we propose the AI technique to optimize SAGINs, as the AI technique has shown its predominant advantages in many applications. We first analyze several main challenges of SAGINs and explain how these problems can be solved by AI. Then, we consider the satellite traffic balance as an example and propose a deep learning based method to improve traffic control performance. Simulation results evaluate that the deep learning technique can be an efficient tool to improve the performance of SAGINs.},
keywords={Deep learning;Satellite broadcasting;Satellites;Security;Delays;Quality of experience},
doi={10.1109/MWC.2018.1800365},
ISSN={1558-0687},
month={August},}
@INPROCEEDINGS{8476785,
author={Kuzmin, Alexander and Znak, Evgeny},
booktitle={2018 IEEE International Conference on Service Operations and Logistics, and Informatics (SOLI)}, title={Blockchain-base structures for a secure and operate network of semi-autonomous Unmanned Aerial Vehicles},
year={2018},
volume={},
number={},
pages={32-37},
abstract={Unmanned Aerial Vehicles - UAVs, or drones - are now being operated by several military forces and currently, to a more limited extent, by civilian organizations. These latter operations, however, may eventually expand to exceed, in number and diversity, those of the military. Further expected development in battery capacity, construction materials and software, especially regarding machine learning algorithms and drone integration, will definitely increase UAVs' autonomous. Unique risks associated with UAVs like risk of hackers' attacks to intercept the control are also increasing. More incidents likely will occur once regulations are finalized that encourage more use that is widespread. Such incidents could result in multi-million dollar claims against businesses, operators and manufacturers. Blockchain is the basis technology for cryptocurrencies. However, Blockchain can have far larger applications in the field of UAVs, because Blockchain is highly distributed and publically viewable system of sequentially linked cryptographically. This paper presents a concept of application, where each UAV in the UAVNet is a Blockchain node, has on-board functionality for creating and reading transactions from the block, as well as communication tools for exchanging transactions with other UAVs.},
keywords={Drones;Jamming;Cryptography;Air traffic control;cyber security;drones;unmanned aerial vehicles;UAVNet;blockchain;integrity;consensus mechanisms},
doi={10.1109/SOLI.2018.8476785},
ISSN={},
month={July},}
@INPROCEEDINGS{7502678,
author={Ramasamy, Manickam and Ghose, Debasish},
booktitle={2016 International Conference on Unmanned Aircraft Systems (ICUAS)}, title={Learning-based preferential surveillance algorithm for persistent surveillance by unmanned aerial vehicles},
year={2016},
volume={},
number={},
pages={1032-1040},
abstract={In this paper, we present an algorithm called Learning-based Preferential Surveillance Algorithm (LPSA), which is specific to the problem of persistent surveillance by unmanned aerial vehicles. The novelty of the algorithm lies in providing the capability to a UAV to increase the probability of target detection through learning. The algorithm considers the neighborhood of a localized target as potential additional targets and motivates the UAV to verify if this is indeed true. Once a target is located in any of the neighborhood grid points, that point is visited more often than other points. Moreover, this technique uses the risk calculation method of an existing geometric reinforcement learning algorithm to reduce the frequency of visits to risky regions. Simulation results are used to demonstrate the effectiveness of the algorithm.},
keywords={Surveillance;Object detection;Unmanned aerial vehicles;Urban areas;Planning;Target tracking;persistent surveillance;preferential surveillance;learning;target detection;UAV},
doi={10.1109/ICUAS.2016.7502678},
ISSN={},
month={June},}
@INPROCEEDINGS{8728602,
author={Emaletdinova, L.Yu. and Kabirova, A.N.},
booktitle={2018 International Conference on Industrial Engineering, Applications and Manufacturing (ICIEAM)}, title={Development of Neural Network Model of Regulator for Automatic Control System of Technical Object in Absence of Mathematical Model of Object},
year={2018},
volume={},
number={},
pages={1-5},
abstract={The article discusses the problem of constructing a neural network model of the regulator for controlling a technical object with a monotonous smooth behavior that does not have a mathematical description. To solve this problem, we propose a method of construction of a technical object inverse model in the form of a neural emulator - perceptron. In this article we describe the algorithm for determining a number of the intermediate layers of the perceptron and the values of its weights, also the method of forming the training samples on the basis of knowledge of the only known required behaviors of the object without carrying out experimental studies. The construction of neural networks is performed using the nntool package in the Matlab environment. The validation of neural networks is carried out using the model of the automatic control system in the environment of visual modeling Simulink (Matlab). Finally, we consider the results of the suggested methods by the example of a one-dimensional control of the roll angle of an unmanned aerial vehicle.},
keywords={Mathematical model;Training;Regulators;Testing;Biological neural networks;Neurons;neural network;neural emulator;neural network model of the regulator;multilayer perceptron;automatic control system},
doi={10.1109/ICIEAM.2018.8728602},
ISSN={},
month={May},}
@INPROCEEDINGS{9584624,
author={Serikbay, Arailym and Bagheri, Mehdi and Zollanvari, Amin},
booktitle={2021 IEEE International Conference on Environment and Electrical Engineering and 2021 IEEE Industrial and Commercial Power Systems Europe (EEEIC / I CPS Europe)}, title={High Voltage Insulators Condition Analysis using Convolutional Neural Network},
year={2021},
volume={},
number={},
pages={1-5},
abstract={High voltage insulators are nonconductive materials that are in use to isolate the conductor from the earthed transmission tower. However, they are regularly subjected to operational environmental contamination and detrimental electrical or mechanical stress. Undesirable operational conditions can cause insulations’ failure and ultimately the power transmission line outage. Therefore, monitoring and condition analysis of the insulators are essential tasks for the utility operators as well as transmission companies. With the widespread applications of deep learning techniques in engineering, in this study, we propose Convolutional Neural Network (CNN) as the backbone data analysis method and aerial images as the primary dataset. We conducted a model selection through an exhaustive search within a limited hyperparameter space based on our computational resources. We show that the constructed CNN classifier achieved a remarkable accuracy of 83.3% in classifying a clean insulator surface from the one covered with water droplets.},
keywords={Surface cleaning;Power transmission lines;Surface contamination;High-voltage techniques;Companies;Insulators;Water pollution;condition monitoring;Convolutional Neural Network;outdoor insulator;TensorFlow;Unmanned Aerial Vehicle},
doi={10.1109/EEEIC/ICPSEurope51590.2021.9584624},
ISSN={},
month={Sep.},}
@INPROCEEDINGS{9274913,
author={Wang, Zhichao and Wang, Chang and Niu, Yifeng},
booktitle={2020 3rd International Conference on Unmanned Systems (ICUS)}, title={Mixed-initiative Manned-unmanned Teamwork Using Coactive Design and Graph Neural Network},
year={2020},
volume={},
number={},
pages={538-543},
abstract={Mixed-initiative decision making is a flexible and effective way for coherent manned-unmanned teamwork (MUT). It allows the autonomous adjustment of levels of autonomy (LOA) and the human-robot collaboration modes according to the task requirements as well as the states of environments, robots and the human operator. However, it is still difficult for humans and robots to understand each other's intentions and motivations due to the challenges of cognition representation and behavior reasoning. In this paper, we propose a novel mixed-initiative MUT approach using coactive design and graph neural networks (GNN) towards explainable human-robot collaboration. First, an interdependence analysis table is designed for a specific manned-unmanned aerial vehicle task following the coactive design principles of observability, predictability and directablity. Then, a multi-agent dynamic task assignment system is designed based on a task model with key decision-making points. Finally, we have used the Graph Network Library to design a GNN model for adjusting the LOA among the MAV and UAVs in the given task.},
keywords={Task analysis;Man-machine systems;Libraries;mixed-initiative;coactive design;dynamic task assignment;graph neural network;levels of autonomy},
doi={10.1109/ICUS50048.2020.9274913},
ISSN={},
month={Nov},}
@ARTICLE{9305246,
author={Praveen, Bishwas and Menon, Vineetha},
journal={IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing}, title={Study of Spatial–Spectral Feature Extraction Frameworks With 3-D Convolutional Neural Network for Robust Hyperspectral Imagery Classification},
year={2021},
volume={14},
number={},
pages={1717-1727},
abstract={Advances in hyperspectral remote sensing have instigated multitude of applications for better understanding of our planet through remote data acquisition and observation of natural phenomena such as weather monitoring and prediction to include tornado, wild fires, global warming, etc. For this, data analysis methods that exploit the rich spectral and spatial information in hyperspectral data are often employed to gain insights about the natural phenomenon. This work presents a new deep learning based hyperspectral data analysis framework, which efficiently utilizes both spatial and spectral information present in the data to achieve superior classification performance. Gabor filtering is used for spatial feature extraction in conjunction with sparse random projections for spectral feature extraction and dimensionality reduction. Finally, supervised classification using a 3-D convolutional neural network was employed to perform a volumetric hyperspectral data analysis. Experimental results reveal that the proposed spatial-spectral hyperspectral data analysis frameworks outperform the conventional 2-D convolution neural network-based spectral-spatial feature extraction techniques.},
keywords={Hyperspectral imaging;Feature extraction;Data analysis;Principal component analysis;Two dimensional displays;Data mining;Three-dimensional displays;3-D convolutional neural network (3-D CNN);deep learning;dimensionality reduction (DR);feature extraction;Gabor filtering;Gaussian filtering;hyperspectral classification;principal component analysis (PCA);sparse random projection (RP);support vector machine (SVM)},
doi={10.1109/JSTARS.2020.3046414},
ISSN={2151-1535},
month={},}
@INPROCEEDINGS{8101662,
author={Junoh, Shahmi and Aouf, Nabil},
booktitle={2017 Workshop on Research, Education and Development of Unmanned Aerial Systems (RED-UAS)}, title={Person classification leveraging Convolutional Neural Network for obstacle avoidance via Unmanned Aerial Vehicles},
year={2017},
volume={},
number={},
pages={168-173},
abstract={Obstacle avoidance capability for Unmanned Aerial Vehicles (UAVs) remains an active research in order to provide a better sense-and-avoid technology. More severely, in an environment where it contains and involves humans, the capability required is of high reliability and robustness. Prior to avoiding obstacles during mission, having a high performance of obstacle detection is deemed important. We first tackled the detection problem by solving the classification task. In this work, humans were treated as a special type of obstacles in indoor environment by which they may potentially cooperate with UAVs in indoor setting. While existing works have long been focusing on using classical computer vision techniques that suffer from substantial disadvantages with respect to robustness, studies on the use of deep learning approach i.e. Convolutional Neural Network (CNN) to achieve this purpose are still scarce. Using this approach for binary person classification task has revealed improved performance of more than 99% both for True Positive Rate (TPR) and True Negative Rate (TNR), hence, is promising for realizing robust obstacle avoidance.},
keywords={Training;Cameras;Robustness;Collision avoidance;Machine learning;Convergence},
doi={10.1109/RED-UAS.2017.8101662},
ISSN={},
month={Oct},}
@INPROCEEDINGS{9581488,
author={Juan, He and Longxiang, Wang and Hongxia, Ye},
booktitle={2021 International Applied Computational Electromagnetics Society (ACES-China) Symposium}, title={A new Wavelet Prediction method for GPR clutter elimination Based on LSTM network},
year={2021},
volume={},
number={},
pages={1-2},
abstract={Ground penetrating radar (GPR) wavelet greatly affects the inversion results of underground structures. This paper presents a new wavelet extraction method based on the LSTM neural network. The simulation data with FDTD method and the measured data collected by the self-built unmanned aerial vehicle ground penetrating radar (UAV-GPR) are used for test, and the predicted wavelets are almost all offset by the wavelet components of the original data. The results show that the LSTM neural network can effectively predict the wavelets and their tailing oscillations for different detection scenes.},
keywords={Ground penetrating radar;Computational modeling;Neural networks;Time series analysis;Predictive models;Data models;Unmanned aerial vehicles;Ground penetrating radar;Long short-term memory network;wavelet extraction},
doi={10.23919/ACES-China52398.2021.9581488},
ISSN={},
month={July},}
@INPROCEEDINGS{9088601,
author={Kovbasiuk, Serhiy and Kanevskyy, Leonid and Chernyshuk, Sergiy and Romanchuk, Mykola},
booktitle={2020 IEEE 15th International Conference on Advanced Trends in Radioelectronics, Telecommunications and Computer Engineering (TCSET)}, title={Detection of vehicles on images obtained from unmanned aerial vehicles using instance segmentation},
year={2020},
volume={},
number={},
pages={267-271},
abstract={In recent years, developing and improving of methods for automatic processing of imagery pictures taken from air with unmanned aerial vehicles (UAV) for ground vehicles detection have received priority. One of the most perspective approach in this direction is application of neural networks. However, UAV imagery has some distinctive features compared to normal images namely high resolution, complex image background, unequal distribution by size and quantity of training data, image bending due to flight-performance changes caused by air environment conditions. These factors compromise and make much more complicated detection of fine-graded objects by standard models of neural networks and in some cases renders automated processing of such images impossible. For the purpose of automatic detection of vehicles in images taken from UAV the analysis of existing methods of automated images processing and models of neural networks as the basis for these methods was conducted. The results of analysis allowed to highlight a multistage pipeline of aerial image, that combines approaches to detection, instance and semantic segmentation. The model of segmentation cascade was improved through considering objects geometrical dimensions and their ratio as well as scale changing and survey conditions. Application of suggested model of segmentation cascade for automated vehicle detection on aerial images allows to increase the accuracy of localization and detection of such objects.},
keywords={unmanned aerial vehicles;object detection;aerial images;instance segmentation;unbalanced data;focal loss},
doi={10.1109/TCSET49122.2020.235437},
ISSN={},
month={Feb},}
@INPROCEEDINGS{9470420,
author={Rauch, Jonas and Doer, Christopher and Trommer, Gert F.},
booktitle={2021 28th Saint Petersburg International Conference on Integrated Navigation Systems (ICINS)}, title={Object Detection on Thermal Images for Unmanned Aerial Vehicles Using Domain Adaption Through Fine-Tuning},
year={2021},
volume={},
number={},
pages={1-4},
abstract={This work addresses state-of-the-art object detection methods using deep learning on thermal images for application on Unmanned Aerial Vehicles (UAVs). For this purpose, fine-tuning is performed using a custom dataset. Special focus is given to the generation of this dataset, as the annotations for the thermal images are automatically generated from simultaneously acquired visual images. The bounding boxes found on visual images using state-of-the-art object detection methods are applied as annotations to the thermal images. Furthermore, it is shown how the fine-tuned models can be executed in real-time on the drone's embedded PC, which is limited in its computing power, by using additional accelerator hardware.},
keywords={Deep learning;Training;Visualization;Annotations;Computational modeling;Pose estimation;Object detection;Real-time object detection;Domain adaption;Fine-tuning;Thermal imaging},
doi={10.23919/ICINS43216.2021.9470420},
ISSN={},
month={May},}
@ARTICLE{9310671,
author={Yu, Ping and Zhao, Xiao and Jiao, Jian},
journal={IEEE Geoscience and Remote Sensing Letters}, title={An Aeromagnetic Compensation Algorithm Based on a Deep Autoencoder},
year={2022},
volume={19},
number={},
pages={1-5},
abstract={Magnetic compensation is a necessary step in the aeromagnetic data processing. While the aeromagnetic compensation model is a linear regression model, the multicollinearity of the variables in the model reduces the accuracy of the compensation model. To solve this problem, we propose a deep autoencoder (DAE) aeromagnetic compensation algorithm. The DAE searches the direction of maximum change in the data by using the gradient descent backpropagation algorithm. The special structure of the encoder can compress the representation of the coefficient matrix and extract data features, thereby weakening the correlation between the coefficient matrix variables. The features obtained after dimension reduction are used in the compensation calculation. We validate the DAE algorithm by applying it to data collected by an unmanned aerial vehicle and demonstrate that the DAE magnetic compensation results are better than those of the principal component analysis algorithm.},
keywords={Principal component analysis;Mathematical model;Interference;Neural networks;Atmospheric modeling;Magnetometers;Aircraft;Aeromagnetic compensation;deep autoencoder (DAE);linear regression;multicollinearity;unmanned aerial vehicles (UAVs)},
doi={10.1109/LGRS.2020.3044999},
ISSN={1558-0571},
month={},}
@ARTICLE{9210014,
author={Cué La Rosa, Laura Elena and Oliveira, Dário A. B. and Zortea, Maciel and Holtz Gemignani, Bruno and Queiroz Feitosa, Raul},
journal={IEEE Geoscience and Remote Sensing Letters}, title={Learning Geometric Features for Improving the Automatic Detection of Citrus Plantation Rows in UAV Images},
year={2022},
volume={19},
number={},
pages={1-5},
abstract={Unmanned aerial vehicles (UAVs) allow on-demand imaging of orchards at an unprecedented level of detail. The automated detection of plantation rows in the images helps in the successive analysis steps, such as the detection of individual fruit trees and planting gaps, aiding producers with inventory and planting operations. Citrus trees can be planted in curved rows that form intricate geometric patterns in aerial images, requiring robust detection approaches. While deep learning methods rank among state-of-the-art methods for segmenting images with particular geometrical patterns, they struggle to hold their performance when testing data differs much from training data (e.g., image intensity differences, image artifacts, vegetation characteristics, and landscape conditions). In this letter, we propose a method to learn geometric features of orchards in UAV images and use them to improve the detection of plantation rows. First, we train a detection encoder–decoder network (DetED) to segment planting rows in RGB images. Then, with labeled data, we train an encoder–decoder correction network (CorrED) that learns to map binary masks with spurious row segmentation geometries into corrected ones. Finally, we use the CorrED network to fix geometric inconsistencies in DetED outcome. Our experiments with commercial plantations of orange trees show that the proposed CorrED postprocessing can restore missing segments of plantation rows and improve detection accuracy in testing data.},
keywords={Image segmentation;Geometry;Vegetation;Training;Testing;Decoding;Feature extraction;Encoder–decoder networks;geometric patterns;plantation rows detection;postprocessing},
doi={10.1109/LGRS.2020.3024641},
ISSN={1558-0571},
month={},}
@INPROCEEDINGS{9497841,
author={Adke, Diksha and Karnik, Atharva and Berman, Honey and Mathi, Shyamala},
booktitle={2021 International Conference on Artificial Intelligence and Computer Science Technology (ICAICST)}, title={Detection and Blur-Removal of Single Motion Blurred Image using Deep Convolutional Neural Network},
year={2021},
volume={},
number={},
pages={79-83},
abstract={This paper proposes a simple and efficient motion blur detection and removal method based on Deep CNN. The domain of computer vision has gained significant importance in recent years due to insurgence in the fields of self-driving cars, UAVs, medical image processing, etc. Due to low light conditions and the camera's fast motion, a large portion of image data generated is wasted. Such motion-blurred images impose a great challenge to the algorithms used for decision-making in machine vision. Although there have been significant improvements in denoising such image data, these methods are challenged by time constraints, insufficient data to train, reconstructed image quality, etc. The proposed paper employs a learning method to detect and deblur the single input image even in the absence of a ground-truth sharp image. We have used a synthetic dataset for experimental evaluation. This synthetic dataset that we have created and used for training the DCNN model has been made available for open source on Kaggle at the following link: https://www.kaggle.com/dikshaadke/motionblurdataset},
keywords={Learning systems;Training;Computer vision;Computational modeling;Machine vision;Noise reduction;Real-time systems;Deep Convolutional Neural Network;Deep Learning;Supervised Learning;Computer Vision in Robotics;Motion Blur;Automation},
doi={10.1109/ICAICST53116.2021.9497841},
ISSN={},
month={June},}
@INPROCEEDINGS{9213872,
author={Giernacki, Wojciech and Kozierski, Piotr and Michalski, Jacek and Retinger, Marek and Madonski, Rafal and Campoy, Pascual},
booktitle={2020 International Conference on Unmanned Aircraft Systems (ICUAS)}, title={Bebop 2 Quadrotor as a Platform for Research and Education in Robotics and Control Engineering},
year={2020},
volume={},
number={},
pages={1733-1741},
abstract={In conducting research and teaching in fields related to unmanned aerial vehicles (UAVs), it is particularly important to select a universal, safe, open research platform and tools for rapid prototyping. Ready-to-use, low-cost micro-class UAVs such as Bebop 2 are successfully used in that regard. This article presents how to use the potential of this flying robot with Robot Operating System (ROS). The most important software solutions for the developed experimental testbed FlyBebop are characterized here. Their capabilities in research and education are exemplified using three distinct cases: 1) research results on the method of optimal, in-flight, iterative self-tuning of UAV position controller parameters (based only on current measurements), 2) the use of the reinforcement learning method in the autonomous landing of a single drone on a moving vehicle, 3) planning the movement of UAVs for autonomous video recording along the planned path in the arrangement: "cameraman drone" and "lighting technician drones".},
keywords={Drones;Robots;Education;Cameras;Sensors;Tools},
doi={10.1109/ICUAS48674.2020.9213872},
ISSN={2575-7296},
month={Sep.},}
@INPROCEEDINGS{9600048,
author={Rashid, Md Tahmid and Zhang, Daniel Yue and Wang, Dong},
booktitle={2021 17th International Conference on Distributed Computing in Sensor Systems (DCOSS)}, title={HeteroSAS: A Heterogeneous Resource Management Framework for "All-in-the-Air" Social Airborne Sensing in Disaster Response},
year={2021},
volume={},
number={},
pages={132-139},
abstract={Social airborne sensing (SAS) is emerging as a new sensing paradigm that leverages the complementary aspects of social sensing and airborne sensing (i.e., UAVs) for reliable information collection. In this paper, we present HeteroSAS, a heterogeneous resource management framework for "all-in-the-air" SAS in disaster response applications. Current SAS approaches use UAVs to only capture data, but carry out computation on ground-based processing nodes that may be unavailable in disaster scenarios and thus consider a single model of UAV along with only one type of task (i.e., data capture). In this paper, we explore the opportunity to exploit the complementary strengths of different UAV models to accomplish all stages of sensing tasks (i.e., data capturing, maneuvering, and computation) exclusively "in-the-air". However, several challenges exist in developing such a resource management framework: i) handling the uncertain social signals in presence of the heterogeneity of UAVs and tasks; and ii) adapting to constantly changing cyber-physical-social environments. The HeteroSAS framework addresses these challenges by building a novel resource management framework that observes the environment and learns the optimal strategy for each UAV using techniques from multi-agent reinforcement learning, game theory, and ensemble learning. The evaluation with a real-world case study shows that HeteroSAS outperforms the state-of-the-art in terms of detection effectiveness, deadline hit rate, and robustness on heterogeneity.},
keywords={Social networking (online);Computational modeling;Reinforcement learning;Robustness;Data models;Sensor systems;Sensors},
doi={10.1109/DCOSS52077.2021.00034},
ISSN={2325-2944},
month={July},}
@INPROCEEDINGS{9585261,
author={Vu, Hoai Nam and Nguyen, Huong Mai and Pham, Cuong Duc and Tran, Anh Dat and Trong, Khanh Nguyen and Pham, Cuong and Nguyen, Viet Hung},
booktitle={2021 International Conference on Multimedia Analysis and Pattern Recognition (MAPR)}, title={Landslide Detection with Unmanned Aerial Vehicles},
year={2021},
volume={},
number={},
pages={1-7},
abstract={Landslide is one of the most dangerous disasters, especially for countries with large mountainous terrain. It causes a great damage to lives, infrastructure and environments, such as traffic congestion and high accidents. Therefore, automated landslide detection is an important task for warning and reducing its consequences such as blocked traffic or traffic accidents. For instance, people approaching the disaster area can adjust their routes to avoid blocked roads, or dangerous traffic signs can be positioned in time to warn the traffic participants to avoid the interrupted road ahead. This paper proposes a method to detect blocked roads caused by landslide by utilizing images captured from Unmanned Aerial Vehicles (UAV). The proposed method comprises of three components: road segmentation, blocked road candidate extraction, and blocked road classification, which is leveraged by a multi-stage convolutional neural network model. Our experiments demonstrate that the proposed method can surpass over several state-of-the art methods on our self-collected dataset of 400 images captured with an UAV.},
keywords={Image segmentation;Art;Roads;Unmanned aerial vehicles;Terrain factors;Pattern recognition;Convolutional neural networks;Convolutional neural network;UAV;Landslide detection},
doi={10.1109/MAPR53640.2021.9585261},
ISSN={},
month={Oct},}
@INPROCEEDINGS{9401928,
author={Bocanegra, Maria Gonzalez and Haddad, Rami J.},
booktitle={SoutheastCon 2021}, title={Convolutional Neural Network-Based Disaster Assessment Using Unmanned Aerial Vehicles},
year={2021},
volume={},
number={},
pages={1-6},
abstract={Natural disasters are recurrent weather phenomena whose occurrence has increased worldwide in the past few decades. These disasters cause devastating effects on transportation routes by causing significant damage and obstruction on frequently traveled roads. This research focuses on developing an autonomous network of unmanned aerial vehicles (UAVs) for transportation disaster management using convolutional neural networks (CNNs). The autonomous network of UAVs will allow first responders to optimize their rescue plans by providing relevant information on inaccessible roads. The autonomous UAV system development will increase the affected regions' recovery rate by identifying blocked transportation routes and associating them with their corresponding locations to update the virtual map in real-time. Live footage from the unmanned aerial vehicles is fed to ground control, where the CNN classifies the type of damage encountered and then updates a virtual map through the ArcGIs software. Preliminary results of the classification models such as AlexNet show average accuracy of 74.07%. Furthermore, transfer learning and cross-validation techniques were applied to the CNN models to obtain high confidence levels due to the small dataset size used to train and test the CNNs. To choose the best CNN model, a quantitative analysis was performed to measure the statistical precision, statistical recall, and F1 score on each model to optimize the classification.},
keywords={Analytical models;Statistical analysis;Roads;Transfer learning;Transportation;Disaster management;Unmanned aerial vehicles;CNN;Natural Disaster;Optimization;Cross Validation;Transfer Learning;Image Classification;Network Architecture;Statistical Recall;Statistical Precision;Deep Learning;Training Parameters;ArcGIS;Python},
doi={10.1109/SoutheastCon45413.2021.9401928},
ISSN={1558-058X},
month={March},}
@INPROCEEDINGS{8095044,
author={Lysenko, Vitalii and Opryshko, Oleksiy and Komarchuk, Dmytro and Pasichnyk, Nadiia and Zaets, Nataliia and Dudnyk, Alla},
booktitle={2017 9th IEEE International Conference on Intelligent Data Acquisition and Advanced Computing Systems: Technology and Applications (IDAACS)}, title={Usage of flying robots for monitoring nitrogen in wheat crops},
year={2017},
volume={1},
number={},
pages={30-34},
abstract={The article deals with the application of remote sensing of agricultural plantations for assessment of their nitrogen fertilizer provision. The basic technologies of remote sensing used today, their advantages and disadvantages are described. A new calibration method for images obtained from sensors placed on the platform of UAV in unstable illumination based on EXIFF data file, such as size Light Value, is proposed. In terms of agrochemical permanent study area, I have received experimental data on the spectral characteristics of wheat and verified the proposed method. The expediency of development of specialized vegetation index during the use of UAVs in the visible range of the spectrum is justified. Based on the results, a neural network has been created that determines the content of nitrogen under the image with regard to the developed method.},
keywords={Nitrogen;Image color analysis;Monitoring;Optical imaging;Artificial neural networks;Neurons;Remote sensing;remote sensing;UAV;NDVI;VI;EXIFF;fertilizers;drones},
doi={10.1109/IDAACS.2017.8095044},
ISSN={},
month={Sep.},}
@INPROCEEDINGS{9650334,
author={Wang, Meixia and Lei, Yuan and Liang, Yuni and Lv, Xuejing and Mo, Weipeng},
booktitle={2021 IEEE International Conference on Data Science and Computer Application (ICDSCA)}, title={A Support Vector Machine Model based on Mixed Time Series Prediction},
year={2021},
volume={},
number={},
pages={47-51},
abstract={With the rapid development of the national economy, the power system has higher and higher requirements for power supply stability. The traditional manual inspection method is dangerous, inefficient, and has poor data timeliness. Therefore, more and more people study how to put UAVs into power grid inspection. However, there is no good method to effectively process and predict the data collected by UAVs. To solve this problem, this paper uses the combination of mixed data prediction and support vector machine to predict the environmental data and judge the sensor state. For the final performance of the model, this paper chooses ACC as the standard. Experiments show that the prediction result of the model is indeed more accurate.},
keywords={Computational modeling;Time series analysis;Support vector machine classification;Predictive models;Inspection;Power system stability;Power grids;Machine Learning;UAV;Power Line Patrol;Forecast;Mixed prediction},
doi={10.1109/ICDSCA53499.2021.9650334},
ISSN={},
month={Oct},}
@INPROCEEDINGS{9150902,
author={Cai, Enyu and Baireddy, Sriram and Yang, Changye and Crawford, Melba and Delp, Edward J.},
booktitle={2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)}, title={Deep Transfer Learning For Plant Center Localization},
year={2020},
volume={},
number={},
pages={277-284},
abstract={Plant phenotyping focuses on the measurement of plant characteristics throughout the growing season, typically with the goal of evaluating genotypes for plant breeding. Estimating plant location is important for identifying genotypes which have low emergence, which is also related to the environment and management practices such as fertilizer applications. The goal of this paper is to investigate methods that estimate plant locations for afield-based crop using RGB aerial images captured using Unmanned Aerial Vehicles (UAVs). Deep learning approaches provide promising capability for locating plants observed in RGB images, but they require large quantities of labeled data (ground truth) for training. Using a deep learning architecture fine-tuned on a single field or a single type of crop on fields in other geographic areas or with other crops may not have good results. The problem of generating ground truth for each new field is labor-intensive and tedious. In this paper, we propose a method for estimating plant centers by transferring an existing model to a new scenario using limited ground truth data. We describe the use of transfer learning using a model fine-tuned for a single field or a single type of plant on a varied set of similar crops and fields. We show that transfer learning provides promising results for detecting plant locations.},
keywords={Training;Machine learning;Task analysis;Agriculture;Data models;Training data;Shape},
doi={10.1109/CVPRW50498.2020.00039},
ISSN={2160-7516},
month={June},}
@INPROCEEDINGS{9591837,
author={Thalluri, Lakshmi Narayana and Adapa, Sai Divya and D, Priyanka and N, Sri Nithya and Yasmeen and Narayana Sarma, Addepalli V S Y and Venkat, Srikhakolanu Naga},
booktitle={2021 2nd International Conference on Smart Electronics and Communication (ICOSEC)}, title={Drone Technology Enabled Leaf Disease Detection and Analysis system for Agriculture Applications},
year={2021},
volume={},
number={},
pages={1079-1085},
abstract={Drone technology is an emerging technology that is being used for many commercial and survey purposes. This research work has designed a drone technology to develop leaf disease detection and analysis system for agricultural applications. In general, UAV is also known as 'DRONE'. A drone is a device operated without a human pilot and can be remotely controlled with the help of a computer and radio frequency transmitter-receiver system. Identification of plant diseases plays a crucial role in preventing the loss of the yield and quantity of agriculture. A visually observable pattern on leaves helps to study the diseases in plants. Agricultural drones are highly efficient and their usage has been expanded to many areas in agriculture including fertilizer spraying, sowing seeds, growth monitoring, and mapping. This system includes the process of capturing images of the leaves automatically by using a drone with a raspberry pi-camera interface, so that it captures the images for image processing and analysis of leaf properties which would help to detect disease. The suitable algorithms of machine learning (ML) are used after performing feature extraction in the image processing techniques. The edge detection and histogram equalization techniques are used to extract features from the leaf. Drones can also be used in various agricultural applications to reduce human efforts and work time. With the help of GSM, information regarding leaf disease can also be given to the farmer at an early stage and avoid loss in crop production.},
keywords={Histograms;Machine learning algorithms;Plants (biology);Image edge detection;Spraying;Production;Feature extraction;Drone;leaf diseases;Edge detection;disease detection;feature extraction;GSM module;machine learning(ML);Raspberry Pi},
doi={10.1109/ICOSEC51865.2021.9591837},
ISSN={},
month={Oct},}
@INPROCEEDINGS{9163788,
author={Asti, Irfin Sandra and Agustinah, Trihastuti and Santoso, Ari},
booktitle={2020 International Seminar on Intelligent Technology and Its Applications (ISITIA)}, title={Obstacle Avoidance with Energy Efficiency and Distance Deviation Using KNN Algorithm for Quadcopter},
year={2020},
volume={},
number={},
pages={285-291},
abstract={A Quadcopter is one type of UAV specifically widely used for search, rescue, reconnaissance, and others. The obstacle avoidance system in a navigation of quadcopter is needed to minimize human supervision. Obstacle avoidance systems can be created with dimension information of obstacle to choose avoidance directions. Due to power limitations in quadcopter flights, the choice of avoidance direction must consider energy efficiency. In this paper, the obstacle avoidance system in quadcopter navigation that flies in the 3D environment not only considers the dimensions of the obstacle, but also consumption energy and the distance between the quadcopter and the obstacle to choose avoidance direction (right, left or top). Efficient avoidance decisions are generated from KNN (K-Nearest Neighbor) machine learning with 96.6 % accuracy and require 0.0068s computing time. Simulation show that the quadcopter can reach the target point without colliding with static obstacles. Quadcopter can also choose the efficient avoidance direction when obstacles are detected.},
keywords={Machine learning;Training data;Collision avoidance;Three-dimensional displays;Navigation;Unmanned aerial vehicles;Classification algorithms;Obstacle Avoidance;3D Navigation;avoidance direction;Energy Efficient;Quadcopter;Machine Learning;KNN},
doi={10.1109/ISITIA49792.2020.9163788},
ISSN={},
month={July},}
@ARTICLE{9552619,
author={Lv, Zhihan and Chen, Dongliang and Feng, Hailin and Zhu, Hu and Lv, Haibin},
journal={IEEE Transactions on Intelligent Transportation Systems}, title={Digital Twins in Unmanned Aerial Vehicles for Rapid Medical Resource Delivery in Epidemics},
year={2021},
volume={},
number={},
pages={1-9},
abstract={The purposes are to explore the effect of Digital Twins (DTs) in Unmanned Aerial Vehicles (UAVs) on providing medical resources quickly and accurately during COVID-19 prevention and control. The feasibility of UAV DTs during COVID-19 prevention and control is analyzed. Deep Learning (DL) algorithms are introduced. A UAV DTs information forecasting model is constructed based on improved AlexNet, whose performance is analyzed through simulation experiments. As end-users and task proportion increase, the proposed model can provide smaller transmission delays, lesser energy consumption in throughput demand, shorter task completion time, and higher resource utilization rate under reduced transmission power than other state-of-art models. Regarding forecasting accuracy, the proposed model can provide smaller errors and better accuracy in Signal-to-Noise Ratio (SNR), bit quantizer, number of pilots, pilot pollution coefficient, and number of different antennas. Specifically, its forecasting accuracy reaches 95.58% and forecasting velocity stabilizes at about 35 Frames-Per-Second (FPS). Hence, the proposed model has stronger robustness, making more accurate forecasts while minimizing the data transmission errors. The research results can reference the precise input of medical resources for COVID-19 prevention and control.},
keywords={COVID-19;Epidemics;Unmanned aerial vehicles;Predictive models;Forecasting;Inspection;Artificial intelligence;Unmanned aerial vehicles;digital twins;epidemic;deep learning;medical resource;COVID-19 prevention and control.},
doi={10.1109/TITS.2021.3113787},
ISSN={1558-0016},
month={},}
@ARTICLE{8820002,
author={Cao, Ningyuan and Chang, Muya and Raychowdhury, Arijit},
journal={IEEE Journal of Solid-State Circuits}, title={A 65-nm 8-to-3-b 1.0–0.36-V 9.1–1.1-TOPS/W Hybrid-Digital-Mixed-Signal Computing Platform for Accelerating Swarm Robotics},
year={2020},
volume={55},
number={1},
pages={49-59},
abstract={Low-power edge-intelligence is leading to spectacular advances in smart sensors, actuators, and human-machine interfaces. In particular, energy efficiency is driving key advances in robotics, where low-power computation is augmented with smart control and mechanical systems to enable small-sized and intelligent drones, unmanned aerial vehicles (UAVs), micro-sized cars, and so on with applications in surveillance, disaster relief, and reconnaissance. Furthermore, for a variety of tasks, swarms of robots are often used as opposed to the individual robots. This article presents an energy-efficient computing platform that can enable a sample class of algorithms for swarm robotics. We demonstrate that both physical-model-based algorithms as well as learning-based algorithms can be supported on the same computing platform. We also demonstrate that with changing swarm sizes, the number of bits required to compute also scales. We take advantage of this observation to propose a hybrid-digital-mixed-signal computing platform, whose energy efficiency scales with the resolution of the data path and hence the swarm size. Measurements on a 65-nm CMOS test-chip demonstrate a peak energy efficiency of 9.1 TOPS/W at a 3-b resolution, and it scales down to 1.1 TOPS/W at an 8-b resolution.},
keywords={Robot kinematics;Mathematical model;Swarm robotics;Energy resolution;Hardware;Sensors;Machine learning;mixed signal;robotics;swarm intelligence},
doi={10.1109/JSSC.2019.2935533},
ISSN={1558-173X},
month={Jan},}
@INPROCEEDINGS{9230274,
author={Zhao, Dongyang and Chen, Yuqing and Yu, Shuanghe},
booktitle={2020 5th International Conference on Automation, Control and Robotics Engineering (CACRE)}, title={Tracking and Speed Estimation of Ground Vehicles Using Aerial-view Videos},
year={2020},
volume={},
number={},
pages={597-601},
abstract={With the rapid technology development in autonomous navigation of Unmanned Aerial Vehicles (UAVs) and robust object detection based on deep neural networks, the field of traffic analysis through aerial video has attracted widespread attention. In this paper, we investigate the problems of ground vehicle tracking and speed estimation using aerial view videos. At the first stage, the vehicle detection is performed through the YOLOv3 network, which is the state-of-the-art object detector. Then, a tracking-by-detection method is designed to tracking the traffic vehicles. Furthermore, in order to estimate the vehicle speed in traffic while the UAV navigating in different heights, the least square algorithm is utilized to fit the measurement data and determine the power function mapping relationship between the vehicle pixel distance and the actual distance, which further improves the accuracy of speed estimation effectively.},
keywords={Vehicle detection;Videos;Estimation;Radar tracking;Tracking;Cameras;Fitting;UAV;vehicle tracking;speed estimation},
doi={10.1109/CACRE50138.2020.9230274},
ISSN={},
month={Sep.},}
@INPROCEEDINGS{9594332,
author={Simpson, Todd},
booktitle={2021 IEEE/AIAA 40th Digital Avionics Systems Conference (DASC)}, title={Real-Time Drone Surveillance System for Violent Crowd Behavior Unmanned Aircraft System (UAS) – Human Autonomy Teaming (HAT)},
year={2021},
volume={},
number={},
pages={1-9},
abstract={Unmanned Aerial Systems (UASs), or drones, continue to increase in capabilities and sophistication across a wide range of applications. UASs have high mobility, are easily deployed, and capable of real-time monitoring of crowd behavior by utilizing multi-sensor-based detection and remote sensing of objects. These capabilities make UASs a very useful tool for Human Autonomy Teaming (HAT) applications, such as Law Enforcement (LE), capitalizing on Human Factors (HF). This study examines the concept of leveraging drone technology together with Artificial Intelligence (AI) and Machine Learning (ML) methods to produce a UAS system that can assist LE in the monitoring and assessment of crowd behaviors during peaceful and non-peaceful events. LE agencies are increasingly being tasked with engaging in dynamic environments that exist at public events. Utilized as a force multiplier and autonomous tool, would benefit from an AI-UAS platform utilizing artificial intelligence assisting in identifying behavior of peaceful people as opposed to malevolent participants or instigators that may attempt to take control. AI-UASs of this type would allow LE to leverage existing resources within their organizational structures and provide increased situation awareness via a Live Virtual Constructive (LVC) broadcast and monitoring of these dynamic environments. Information provided from these AI-UAS systems would provide real-time information to field forces as well as command and control operations that may be remotely located. AI-UAS Sensors can be dynamically allocated as needed for monitoring/documenting crowd behavior and police actions. Video recordings would provide evidence in court as well counter truth-bending recordings published by professional protestors and agenda driven main-stream media outlets. The benefits and impact of this type of LE AI-UAS platform would be profound. Traditional visible light based sensors can be greatly influenced by environmental factors preventing their ability to determine variations regarding abnormal crowd behaviors. In order to overcome this challenge, this project proposes to utilize four types of collection methods, Multitask Cascading CNN (MC-CNN), ScatterNet Hybrid Deep Learning Network, multiscale infrared optical flow (MIR-OF), and Event Cameras such as Event-based Vision, and Event Camera SLAM (Simultaneous Localization and Mapping). AI methods will be developed to monitor crowd density, average ground speed, human pose estimations, and movement behaviors, as well as identification of primary violent instigators. This proposed system will detect violent individuals in real-time by leveraging onboard image processing as well as cloud processing. Fundamental research for this project is inspired and built upon recent Drone Surveillance System (DSS) publications from IEEE and MDPI.},
keywords={Simultaneous localization and mapping;Law enforcement;Surveillance;Dynamics;Tools;Aerospace electronics;Cameras;Unmanned Aerial Systems;UAS;UAV;Drone;Artificial Intelligence;Machine Learning;Human Autonomy Teaming;Crowd Behavior Prediction;Real-time Monitoring;Loihi;True North;Neuromorphic Computing;Crowd Control;Wright State University;Sinclair College;Human Factors},
doi={10.1109/DASC52595.2021.9594332},
ISSN={2155-7209},
month={Oct},}
@INPROCEEDINGS{8314893,
author={Ben Moussa Sellali, Brahim and Allali, Abderrazek},
booktitle={2017 18th International Conference on Sciences and Techniques of Automatic Control and Computer Engineering (STA)}, title={Neuro — Fuzzy methods coupled to operational PID, to improve the flight parameters of a drone},
year={2017},
volume={},
number={},
pages={314-319},
abstract={The Neuro-Fuzzy (NF) technique makes it possible to exploit the learning capabilities of neural networks on the one hand and the reasoning capabilities of fuzzy logic on the other hand. It is extremely convenient because it incorporates all the benefits of both algorithms and makes the whole system more robust. We apprehend the simulation of our system by the PID regulation real test accompanied by NF algorithm. We find that the operational PID control coupled by ANFIS is more robust and gives better results compared to PID regulation alone. The simulation results generated by Matlab / Simulink, which provides a complete set of tools. Flight parameters UAVmodel with ANFIS controller coupled PID is simulated to verify the capability of the system. Finally, the results are validated by F450's drone.},
keywords={Drones;Noise measurement;Time factors;PI control;PD control;Simulation;Matlab;neuro-fuzzy;drone;ANFIS;simulation;PID control system;flight parameters},
doi={10.1109/STA.2017.8314893},
ISSN={2573-539X},
month={Dec},}
@ARTICLE{8839973,
author={Shu, Feng and Shen, Tong and Xu, Ling and Qin, Yaolu and Wan, Siming and Jin, Shi and You, Xiaohu and Wang, Jiangzhou},
journal={IEEE Network}, title={Directional Modulation: A Physical-Layer Security Solution to B5G and Future Wireless Networks},
year={2020},
volume={34},
number={2},
pages={210-216},
abstract={Directional modulation (DM), as an efficient secure transmission method, offers security through its directive property and is suitability for LoP channels such as millimeter wave, UAV, satellite communication, and smart transportation. If the direction angle of the desired user is known, the desired channel gain vector is obtainable. Thus, in advance, the DM transmitter knows the values of the directional angles of the desired user and eavesdropper, or their DOAs because the BVCM andANPM are mainly determined by the directional angles of the desired user and eavesdropper. For a DM transceiver, working as a receiver, the first step is to measure the DOAs of the desired user and eavesdropper. Then, in the second step, using the measured DOAs, the BVCM and ANPM are designed. In this article, we describe DOA measurement methods, power allocation, and beamforming in DM networks. A machine learning-based DOA measurement method is proposed to make a substantial secrecy rate (SR) performance gain compared to single-snapshot measurement without machine learning for a given null-space projection beamforming scheme. However, for a conventional DM network, there still exists a serious security issue: the eavesdropper moves inside the main beam of the desired user and may intercept the CMs intended for the desired users because the BVCM and ANPM are only angle-dependent. To address this problem, we present a new concept of SPWT, where the transmit waveform has two-dimensional dependency by using DM, random subcarrier selection with randomization procedure, and phase alignment at the DM transmitter.},
keywords={Direction-of-arrival estimation;Transmitters;Array signal processing;Measurement errors;Measurement uncertainty;Antenna arrays;Machine learning},
doi={10.1109/MNET.001.1900258},
ISSN={1558-156X},
month={March},}
@INPROCEEDINGS{6907000,
author={Allamaraju, Rakshit and Kingravi, Hassan and Axelrod, Allan and Chowdhary, Girish and Grande, Robert and How, Jonathan P. and Crick, Christopher and Sheng, Weihua},
booktitle={2014 IEEE International Conference on Robotics and Automation (ICRA)}, title={Human aware UAS path planning in urban environments using nonstationary MDPs},
year={2014},
volume={},
number={},
pages={1161-1167},
abstract={A growing concern with deploying Unmanned Aerial Vehicles (UAVs) in urban environments is the potential violation of human privacy, and the backlash this could entail. Therefore, there is a need for UAV path planning algorithms that minimize the likelihood of invading human privacy. We formulate the problem of human-aware path planning as a nonstationary Markov Decision Process, and provide a novel model-based reinforcement learning solution that leverages Gaussian process clustering. Our algorithm is flexible enough to accommodate changes in human population densities by employing Bayesian nonparametrics, and is real-time computable. The approach is validated experimentally on a large-scale long duration experiment with both simulated and real UAVs.},
keywords={Clustering algorithms;Data models;Computational modeling;Sociology;Statistics;Path planning;Kernel},
doi={10.1109/ICRA.2014.6907000},
ISSN={1050-4729},
month={May},}
@INPROCEEDINGS{9624533,
author={Wang, Tingjun and Chang, Zhanyuan and Zhang, Wen and Zhang, Jie and Sun, Yunlong},
booktitle={2021 International Conference on Control, Automation and Information Sciences (ICCAIS)}, title={Research on the Integrated Positioning Method of Inertial/ Visual Aided by Convolutional Neural Network},
year={2021},
volume={},
number={},
pages={221-227},
abstract={This subject studies the vision/inertial combined system assisted by neural network, and realizes the function of suppressing the accumulation of inertial device errors in the environment of Global Navigation Satellite System (GNSS) signal rejection. This topic is first improved on the basis of the VGGNet model, and a more efficient model for landmark recognition is obtained. The template matching method is used to obtain the continuous time-location information for the distance update of the visual odometry. In order to reduce the complexity of the system this study uses a simplified integration of inertial sensors, 3D Reduced Inertial Sensor System (3DRISS). Compared with the Inertial Measurement Unit (IMU), the system reduces 2 gyroscopes and 1 accelerometer, and adds an odometry that uses an accelerometer instead of a gyroscope to calculate the pitch and roll angle of the carrier. In this study, with the introduction of vision, visual odometry (VO) is used to participate in the RISS system, forming the VO-3DRISS system. Finally, the feasibility of the system was verified through outdoor experiments},
keywords={Accelerometers;Visualization;Global navigation satellite system;Three-dimensional displays;Navigation;Inertial sensors;Neural networks;Integrated navigation system;Inertial Navigation System (INS);Monocular vision positioning;Convolutional Neural Network (CNN);Visual Odometry (VO)},
doi={10.1109/ICCAIS52680.2021.9624533},
ISSN={2475-7896},
month={Oct},}
@ARTICLE{8681390,
author={Nogueira, Keiller and dos Santos, Jefersson A. and Menini, Nathalia and Silva, Thiago S. F. and Morellato, Leonor Patricia C. and Torres, Ricardo da S.},
journal={IEEE Geoscience and Remote Sensing Letters}, title={Spatio-Temporal Vegetation Pixel Classification by Using Convolutional Networks},
year={2019},
volume={16},
number={10},
pages={1665-1669},
abstract={Plant phenology studies rely on long-term monitoring of life cycles of plants. High-resolution unmanned aerial vehicles (UAVs) and near-surface technologies have been used for plant monitoring, demanding the creation of methods capable of locating, and identifying plant species through time and space. However, this is a challenging task given the high volume of data, the constant data missing from temporal dataset, the heterogeneity of temporal profiles, the variety of plant visual patterns, and the unclear definition of individuals' boundaries in plant communities. In this letter, we propose a novel method, suitable for phenological monitoring, based on convolutional networks (ConvNets) to perform spatio-temporal vegetation pixel classification on high-resolution images. We conducted a systematic evaluation using high-resolution vegetation image datasets associated with the Brazilian Cerrado biome. Experimental results show that the proposed approach is effective, overcoming other spatio-temporal pixel-classification strategies.},
keywords={Vegetation mapping;Neurons;Convolution;Kernel;Deep learning;Data mining;Cameras;Deep learning;near surface;phenology;pixel classification;unmanned aerial vehicles},
doi={10.1109/LGRS.2019.2903194},
ISSN={1558-0571},
month={Oct},}
@INPROCEEDINGS{8993024,
author={Arnold, Ross and Carey, Kevin and Abruzzo, Benjamin and Korpela, Christopher},
booktitle={2019 IEEE 10th Annual Ubiquitous Computing, Electronics Mobile Communication Conference (UEMCON)}, title={What is A Robot Swarm: A Definition for Swarming Robotics},
year={2019},
volume={},
number={},
pages={0074-0081},
abstract={The swarm, a type of multi-agent system, has enjoyed a recent surge in popularity within the autonomous robotics field. Despite a variety of theoretical and simulated research work in the area of swarm theory and multi-agent artificial intelligence, the practical use of swarms remains limited. Though many limiting factors lie on the technical front, one limiting factor may be a lack of appreciation for swarm capabilities and applications as opposed to those of conventional robotics. To help address the latter limiting factor, this paper proposes a definition of a swarm in the context of autonomous robotics, describes many real-world problems that can be addressed through use of swarms, and details current applications of swarming robotic systems.},
keywords={Swarm;autonomous system;UAV;swarm intelligence;unmanned aircraft system;robot control},
doi={10.1109/UEMCON47517.2019.8993024},
ISSN={},
month={Oct},}
@INPROCEEDINGS{7491805,
author={Maistrenko, Vasily A. and Alexey, Leonov V. and Danil, Volkov A.},
booktitle={2016 International Siberian Conference on Control and Communications (SIBCON)}, title={Experimental estimate of using the ant colony optimization algorithm to solve the routing problem in FANET},
year={2016},
volume={},
number={},
pages={1-10},
abstract={FANETs are ad hoc networks based on unmanned aerial vehicles. Such nets are characterized by high mobility of nodes, dynamically changing topology and 3-D movement. Routing in FANET is a complex task. Different methods of routing in FANET are given in this paper. The review of intelligent routing methods in MANETs based on ant algorithm is presented. To confirm possibility of effective usage of protocols based on ant colony algorithm to solve routing tasks in MANETs, the experimental analysis has been performed.},
keywords={Routing;Ad hoc networks;Routing protocols;Finite element analysis;Peer-to-peer computing;Mobile computing;MANET;VANET;FANET;UAVs;Routing protocols;Swarm Intelligence;Ant Colony Optimization;ACO;Network simulation},
doi={10.1109/SIBCON.2016.7491805},
ISSN={2380-6516},
month={May},}
@INPROCEEDINGS{9071826,
author={Motlagh, Hamid Didari Khamseh and Lotfi, Faraz and Taghirad, Hamid D. and Germi, Saeed Bakhshi},
booktitle={2019 7th International Conference on Robotics and Mechatronics (ICRoM)}, title={Position Estimation for Drones based on Visual SLAM and IMU in GPS-denied Environment},
year={2019},
volume={},
number={},
pages={120-124},
abstract={Due to the increased rate of drone usage in various commercial and industrial fields, the need for their autonomous operation is rapidly increasing. One major aspect of autonomous movement is the ability to operate safely in an unknown environment. The majority of current works are persistently using a global positioning system (GPS) to directly find the absolute position of the drone. However, GPS accuracy might be not suitable in some applications and this solution is not applicable to all situations. In this paper, a positioning system based on monocular SLAM and inertial measurement unit (IMU) is presented. The position is calculated through the semi-direct visual odometry (SVO) method alongside IMU data, and is integrated with an extended Kalman filter (EKF) to enhance the efficiency of the algorithm. The data is then employed to control the drone without any requirement to any source of external input. The experiment results for long-distance flying paths is very promising.},
keywords={Position estimation;Kalman filtering;SLAM;monocular camera;UAV},
doi={10.1109/ICRoM48714.2019.9071826},
ISSN={2572-6889},
month={Nov},}
@INPROCEEDINGS{8729285,
author={Li, Ang and Ruan, Xiaogang and Huang, Jing and Zhu, Xiaoqing and Wang, Fei},
booktitle={2019 IEEE 3rd Information Technology, Networking, Electronic and Automation Control Conference (ITNEC)}, title={Review of vision-based Simultaneous Localization and Mapping},
year={2019},
volume={},
number={},
pages={117-123},
abstract={Vision-based simultaneous localization and mapping (VSLAM) which uses visual sensor to make a robot locate itself in an unknown environment while simultaneously construct a map of the environment. With the continuous development of computer vision and robotics, VSLAM has become a supporting technology for popular fields such as unmanned aerial vehicle, virtual reality and unmanned driving. In this paper, the classical framework of visual SLAM is introduced briefly. On this basis, the key technologies and latest research progress of VSLAM from indirect and direct methods are surveyed. Then the research progress of deep learning techniques applied to VSLAM is reviewed. Finally, the development tendency of VSLAM is discussed.},
keywords={Feature extraction;Cameras;Simultaneous localization and mapping;Optimization;Visualization;visual simultaneous localization and mapping;robot;visual odometry;graph optimization;loop closure detection},
doi={10.1109/ITNEC.2019.8729285},
ISSN={},
month={March},}

@Article{ijgi7110428,
AUTHOR = {Kuffer, Monika and Wang, Jiong and Nagenborg, Michael and Pfeffer, Karin and Kohli, Divyani and Sliuzas, Richard and Persello, Claudio},
TITLE = {The Scope of Earth-Observation to Improve the Consistency of the SDG Slum Indicator},
JOURNAL = {ISPRS International Journal of Geo-Information},
VOLUME = {7},
YEAR = {2018},
NUMBER = {11},
ARTICLE-NUMBER = {428},
URL = {https://www.mdpi.com/2220-9964/7/11/428},
ISSN = {2220-9964},
ABSTRACT = {The continuous increase in deprived living conditions in many cities of the Global South contradicts efforts to make cities inclusive, safe, resilient, and sustainable places. Using examples of Asian, African, and Latin American cities, this study shows the scope and limits of earth observation (EO)-based mapping of deprived living conditions in support of providing consistent global information for the SDG indicator 11.1.1 “proportion of urban population living in slums, informal settlements or inadequate housing”. At the technical level, we compare several EO-based methods and imagery for mapping deprived living conditions, discussing their ability to map such areas including differences in terms of accuracy and performance at the city scale. At the operational level, we compare available municipal maps showing identified deprived areas with the spatial extent of morphological mapped areas of deprived living conditions (using EO) at the city scale, discussing the reasons for inconsistencies between municipal and EO-based maps. We provide an outlook on how EO-based mapping of deprived living conditions could contribute to a global spatial information base to support targeting of deprived living conditions in support of the SDG Goal 11.1.1 indicator, when uncertainties and ethical considerations on data provision are well addressed.},
DOI = {10.3390/ijgi7110428}
}



@Article{s18113731,
AUTHOR = {Yuan, Wenan and Li, Jiating and Bhatta, Madhav and Shi, Yeyin and Baenziger, P. Stephen and Ge, Yufeng},
TITLE = {Wheat Height Estimation Using LiDAR in Comparison to Ultrasonic Sensor and UAS},
JOURNAL = {Sensors},
VOLUME = {18},
YEAR = {2018},
NUMBER = {11},
ARTICLE-NUMBER = {3731},
URL = {https://www.mdpi.com/1424-8220/18/11/3731},
ISSN = {1424-8220},
ABSTRACT = {As one of the key crop traits, plant height is traditionally evaluated manually, which can be slow, laborious and prone to error. Rapid development of remote and proximal sensing technologies in recent years allows plant height to be estimated in more objective and efficient fashions, while research regarding direct comparisons between different height measurement methods seems to be lagging. In this study, a ground-based multi-sensor phenotyping system equipped with ultrasonic sensors and light detection and ranging (LiDAR) was developed. Canopy heights of 100 wheat plots were estimated five times during a season by the ground phenotyping system and an unmanned aircraft system (UAS), and the results were compared to manual measurements. Overall, LiDAR provided the best results, with a root-mean-square error (RMSE) of 0.05 m and an R2 of 0.97. UAS obtained reasonable results with an RMSE of 0.09 m and an R2 of 0.91. Ultrasonic sensors did not perform well due to our static measurement style. In conclusion, we suggest LiDAR and UAS are reliable alternative methods for wheat height evaluation.},
DOI = {10.3390/s18113731}
}



@Article{s18113751,
AUTHOR = {Valentino, Rico and Jung, Woo-Sung and Ko, Young-Bae},
TITLE = {A Design and Simulation of the Opportunistic Computation Offloading with Learning-Based Prediction for Unmanned Aerial Vehicle (UAV) Clustering Networks},
JOURNAL = {Sensors},
VOLUME = {18},
YEAR = {2018},
NUMBER = {11},
ARTICLE-NUMBER = {3751},
URL = {https://www.mdpi.com/1424-8220/18/11/3751},
ISSN = {1424-8220},
ABSTRACT = {Drones have recently become extremely popular, especially in military and civilian applications. Examples of drone utilization include reconnaissance, surveillance, and packet delivery. As time has passed, drones’ tasks have become larger and more complex. As a result, swarms or clusters of drones are preferred, because they offer more coverage, flexibility, and reliability. However, drone systems have limited computing power and energy resources, which means that sometimes it is difficult for drones to finish their tasks on schedule. A solution to this is required so that drone clusters can complete their work faster. One possible solution is an offloading scheme between drone clusters. In this study, we propose an opportunistic computational offloading system, which allows for a drone cluster with a high intensity task to borrow computing resources opportunistically from other nearby drone clusters. We design an artificial neural network-based response time prediction module for deciding whether it is faster to finish tasks by offloading them to other drone clusters. The offloading scheme is conducted only if the predicted offloading response time is smaller than the local computing time. Through simulation results, we show that our proposed scheme can decrease the response time of drone clusters through an opportunistic offloading process.},
DOI = {10.3390/s18113751}
}



@Article{rs10111735,
AUTHOR = {Rehush, Nataliia and Abegg, Meinrad and Waser, Lars T. and Brändli, Urs-Beat},
TITLE = {Identifying Tree-Related Microhabitats in TLS Point Clouds Using Machine Learning},
JOURNAL = {Remote Sensing},
VOLUME = {10},
YEAR = {2018},
NUMBER = {11},
ARTICLE-NUMBER = {1735},
URL = {https://www.mdpi.com/2072-4292/10/11/1735},
ISSN = {2072-4292},
ABSTRACT = {Tree-related microhabitats (TreMs) play an important role in maintaining forest biodiversity and have recently received more attention in ecosystem conservation, forest management and research. However, TreMs have until now only been assessed by experts during field surveys, which are time-consuming and difficult to reproduce. In this study, we evaluate the potential of close-range terrestrial laser scanning (TLS) for semi-automated identification of different TreMs (bark, bark pockets, cavities, fungi, ivy and mosses) in dense TLS point clouds using machine learning algorithms, including deep learning. To classify the TreMs, we applied: (1) the Random Forest (RF) classifier, incorporating frequently used local geometric features and two additional self-developed orientation features, and (2) a deep Convolutional Neural Network (CNN) trained using rasterized multiview orthographic projections (MVOPs) containing top view, front view and side view of the point&rsquo;s local 3D neighborhood. The results confirmed that using local geometric features is beneficial for identifying the six groups of TreMs in dense tree-stem point clouds, but the rasterized MVOPs are even more suitable. Whereas the overall accuracy of the RF was 70%, that of the deep CNN was substantially higher (83%). This study reveals that close-range TLS is promising for the semi-automated identification of TreMs for forest monitoring purposes, in particular when applying deep learning techniques.},
DOI = {10.3390/rs10111735}
}



@Article{rs10111744,
AUTHOR = {Splinter, Kristen D. and Harley, Mitchell D. and Turner, Ian L.},
TITLE = {Remote Sensing Is Changing Our View of the Coast: Insights from 40 Years of Monitoring at Narrabeen-Collaroy, Australia},
JOURNAL = {Remote Sensing},
VOLUME = {10},
YEAR = {2018},
NUMBER = {11},
ARTICLE-NUMBER = {1744},
URL = {https://www.mdpi.com/2072-4292/10/11/1744},
ISSN = {2072-4292},
ABSTRACT = {Narrabeen-Collaroy Beach, located on the Northern Beaches of Sydney along the Pacific coast of southeast Australia, is one of the longest continuously monitored beaches in the world. This paper provides an overview of the evolution and international scientific impact of this long-term beach monitoring program, from its humble beginnings over 40 years ago using the rod and tape measure Emery field survey method; to today, where the application of remote sensing data collection including drones, satellites and crowd-sourced smartphone images, are now core aspects of this continuing and much expanded monitoring effort. Commenced in 1976, surveying at this beach for the first 30 years focused on in-situ methods, whereby the growing database of monthly beach profile surveys informed the coastal science community about fundamental processes such as beach state evolution and the role of cross-shore and alongshore sediment transport in embayment morphodynamics. In the mid-2000s, continuous (hourly) video-based monitoring was the first application of routine remote sensing at the site, providing much greater spatial and temporal resolution over the traditional monthly surveys. This implementation of video as the first of a now rapidly expanding range of remote sensing tools and techniques also facilitated much wider access by the international research community to the continuing data collection program at Narrabeen-Collaroy. In the past decade the video-based data streams have formed the basis of deeper understanding into storm to multi-year response of the shoreline to changing wave conditions and also contributed to progress in the understanding of estuary entrance dynamics. More recently, &lsquo;opportunistic&rsquo; remote sensing platforms such as surf cameras and smartphones have also been used for image-based shoreline data collection. Commencing in 2011, a significant new focus for the Narrabeen-Collaroy monitoring program shifted to include airborne lidar (and later Unmanned Aerial Vehicles (UAVs)), in an enhanced effort to quantify the morphological impacts of individual storm events, understand key drivers of erosion, and the placing of these observations within their broader regional context. A fixed continuous scanning lidar installed in 2014 again improved the spatial and temporal resolution of the remote-sensed data collection, providing new insight into swash dynamics and the often-overlooked processes of post-storm beach recovery. The use of satellite data that is now readily available to all coastal researchers via Google Earth Engine continues to expand the routine data collection program and provide key insight into multi-decadal shoreline variability. As new and expanding remote sensing technologies continue to emerge, a key lesson from the long-term monitoring at Narrabeen-Collaroy is the importance of a regular re-evaluation of what data is most needed to progress the science.},
DOI = {10.3390/rs10111744}
}



@Article{electronics7110301,
AUTHOR = {Dominguez-Sanchez, Alex and Cazorla, Miguel and Orts-Escolano, Sergio},
TITLE = {A New Dataset and Performance Evaluation of a Region-Based CNN for Urban Object Detection},
JOURNAL = {Electronics},
VOLUME = {7},
YEAR = {2018},
NUMBER = {11},
ARTICLE-NUMBER = {301},
URL = {https://www.mdpi.com/2079-9292/7/11/301},
ISSN = {2079-9292},
ABSTRACT = {In recent years, we have seen a large growth in the number of applications which use deep learning-based object detectors. Autonomous driving assistance systems (ADAS) are one of the areas where they have the most impact. This work presents a novel study evaluating a state-of-the-art technique for urban object detection and localization. In particular, we investigated the performance of the Faster R-CNN method to detect and localize urban objects in a variety of outdoor urban videos involving pedestrians, cars, bicycles and other objects moving in the scene (urban driving). We propose a new dataset that is used for benchmarking the accuracy of a real-time object detector (Faster R-CNN). Part of the data was collected using an HD camera mounted on a vehicle. Furthermore, some of the data is weakly annotated so it can be used for testing weakly supervised learning techniques. There already exist urban object datasets, but none of them include all the essential urban objects. We carried out extensive experiments demonstrating the effectiveness of the baseline approach. Additionally, we propose an R-CNN plus tracking technique to accelerate the process of real-time urban object detection.},
DOI = {10.3390/electronics7110301}
}



@Article{app8112169,
AUTHOR = {Cui, Jun-hui and Wei, Rui-xuan and Liu, Zong-cheng and Zhou, Kai},
TITLE = {UAV Motion Strategies in Uncertain Dynamic Environments: A Path Planning Method Based on Q-Learning Strategy},
JOURNAL = {Applied Sciences},
VOLUME = {8},
YEAR = {2018},
NUMBER = {11},
ARTICLE-NUMBER = {2169},
URL = {https://www.mdpi.com/2076-3417/8/11/2169},
ISSN = {2076-3417},
ABSTRACT = {A solution framework for UAV motion strategies in uncertain dynamic environments is constructed in this paper. Considering that the motion states of UAV might be influenced by some dynamic uncertainties, such as control strategies, flight environments, and any other bursting-out threats, we model the uncertain factors that might cause such influences to the path planning of the UAV, unified as an unobservable part of the system and take the acceleration together with the bank angle of the UAV as a control variable. Meanwhile, the cost function is chosen based on the tracking error, then the control instructions and flight path for UAV can be achieved. Then, the cost function can be optimized through Q-learning, and the best UAV action sequence for conflict avoidance under the moving threat environment can be obtained. According to Bellman&rsquo;s optimization principle, the optimal action strategies can be obtained from the current confidence level. The method in this paper is more in line with the actual UAV path planning, since the generation of the path planning strategy at each moment takes into account the influence of the UAV control strategy on its motion at the next moment. The simulation results show that all the planning paths that are created according to the solution framework proposed in this paper have a very high tracking accuracy, and this method has a much shorter processing time as well as a shorter path it can create.},
DOI = {10.3390/app8112169}
}



@Article{s18113814,
AUTHOR = {Erdelj, Milan and Uk, Borey and Konam, David and Natalizio, Enrico},
TITLE = {From the Eye of the Storm: An IoT Ecosystem Made of Sensors, Smartphones and UAVs},
JOURNAL = {Sensors},
VOLUME = {18},
YEAR = {2018},
NUMBER = {11},
ARTICLE-NUMBER = {3814},
URL = {https://www.mdpi.com/1424-8220/18/11/3814},
ISSN = {1424-8220},
ABSTRACT = {The development of Unmanned Aerial Vehicles (UAV) along with the ubiquity of Internet of Things (IoT) enables the creation of systems that, leveraging 5G enhancements, can provide real-time multimedia communications and data streaming. However, the usage of the UAVs introduces new constraints, such as unstable network communications and security pitfalls. In this work, the experience of implementing a system architecture for data and multimedia transmission using a multi-UAV system is presented. The system aims at creating an IoT ecosystem to bridge UAVs and other types of devices, such as smartphones and sensors, while coping with the fallback in an unstable communication environment. Furthermore, this work proposes a detailed description of a system architecture designed for remote drone fleet control. The proposed system provides an efficient, reliable and secure system for multi-UAV remote control that will offer the on-demand usage of available sensors, smartphones and unmanned vehicle infrastructure.},
DOI = {10.3390/s18113814}
}



@Article{rs10111760,
AUTHOR = {Ghaffarian, Saman and Kerle, Norman and Filatova, Tatiana},
TITLE = {Remote Sensing-Based Proxies for Urban Disaster Risk Management and Resilience: A Review},
JOURNAL = {Remote Sensing},
VOLUME = {10},
YEAR = {2018},
NUMBER = {11},
ARTICLE-NUMBER = {1760},
URL = {https://www.mdpi.com/2072-4292/10/11/1760},
ISSN = {2072-4292},
ABSTRACT = {Rapid increase in population and growing concentration of capital in urban areas has escalated both the severity and longer-term impact of natural disasters. As a result, Disaster Risk Management (DRM) and reduction have been gaining increasing importance for urban areas. Remote sensing plays a key role in providing information for urban DRM analysis due to its agile data acquisition, synoptic perspective, growing range of data types, and instrument sophistication, as well as low cost. As a consequence numerous methods have been developed to extract information for various phases of DRM analysis. However, given the diverse information needs, only few of the parameters of interest are extracted directly, while the majority have to be elicited indirectly using proxies. This paper provides a comprehensive review of the proxies developed for two risk elements typically associated with pre-disaster situations (vulnerability and resilience), and two post-disaster elements (damage and recovery), while focusing on urban DRM. The proxies were reviewed in the context of four main environments and their corresponding sub-categories: built-up (buildings, transport, and others), economic (macro, regional and urban economics, and logistics), social (services and infrastructures, and socio-economic status), and natural. All environments and the corresponding proxies are discussed and analyzed in terms of their reliability and sufficiency in comprehensively addressing the selected DRM assessments. We highlight strength and identify gaps and limitations in current proxies, including inconsistencies in terminology for indirect measurements. We present a systematic overview for each group of the reviewed proxies that could simplify cross-fertilization across different DRM domains and may assist the further development of methods. While systemizing examples from the wider remote sensing domain and insights from social and economic sciences, we suggest a direction for developing new proxies, also potentially suitable for capturing functional recovery.},
DOI = {10.3390/rs10111760}
}



@Article{rs10111759,
AUTHOR = {Zhao, Yingyi and Hu, Qingwu and Li, Haidong and Wang, Shaohua and Ai, Mingyao},
TITLE = {Evaluating Carbon Sequestration and PM2.5 Removal of Urban Street Trees Using Mobile Laser Scanning Data},
JOURNAL = {Remote Sensing},
VOLUME = {10},
YEAR = {2018},
NUMBER = {11},
ARTICLE-NUMBER = {1759},
URL = {https://www.mdpi.com/2072-4292/10/11/1759},
ISSN = {2072-4292},
ABSTRACT = {Street trees are an important part of urban facilities, and they can provide both aesthetic benefits and ecological benefits for urban environments. Ecological benefits of street trees now are attracting more attention because of environmental deterioration in cities. Conventional methods of evaluating ecological benefits require a lot of labor and time, and establishing an efficient and effective evaluating method is challenging. In this study, we investigated the feasibility to use mobile laser scanning (MLS) data to evaluate carbon sequestration and fine particulate matter (PM2.5) removal of street trees. We explored the approach to extract individual street trees from MLS data, and street trees of three streets in Nantong City were extracted. The correctness rates and completeness rates of extraction results were both over 92%. Morphological parameters, including tree height, crown width, and diameter at breast height (DBH), were measured for extracted street trees, and parameters derived from MLS data were in a good agreement with field-measured parameters. Necessary information about street trees, including tree height, DBH, and tree species, meteorological data and PM2.5 deposition velocities were imported into i-Tree Eco model to estimate carbon sequestration and PM2.5 removal. The estimation results indicated that ecological benefits generated by different tree species were considerably varied and the differences for trees of the same species were mainly caused by the differences in morphological parameters (tree height and DBH). This study succeeds in estimating the amount of carbon sequestration and PM2.5 removal of individual street trees with MLS data, and provides researchers with a novel and efficient way to investigate ecological benefits of urban street trees or urban forests.},
DOI = {10.3390/rs10111759}
}



@Article{s18113837,
AUTHOR = {Siddiqui, Zahid Ali and Park, Unsang and Lee, Sang-Woong and Jung, Nam-Joon and Choi, Minhee and Lim, Chanuk and Seo, Jang-Hun},
TITLE = {Robust Powerline Equipment Inspection System Based on a Convolutional Neural Network},
JOURNAL = {Sensors},
VOLUME = {18},
YEAR = {2018},
NUMBER = {11},
ARTICLE-NUMBER = {3837},
URL = {https://www.mdpi.com/1424-8220/18/11/3837},
ISSN = {1424-8220},
ABSTRACT = {Electric power line equipment such as insulators, cut-out-switches, and lightning-arresters play important roles in ensuring a safe and uninterrupted power supply. Unfortunately, their continuous exposure to rugged environmental conditions may cause physical or electrical defects in them which may lead to the failure to the electrical system. In this paper, we present an automatic real-time electrical equipment detection and defect analysis system. Unlike previous handcrafted feature-based approaches, the proposed system utilizes a Convolutional Neural Network (CNN)-based equipment detection framework, making it possible to detect 17 different types of powerline insulators in a highly cluttered environment. We also propose a novel rotation normalization and ellipse detection method that play vital roles in the defect analysis process. Finally, we present a novel defect analyzer that is capable of detecting gunshot defects occurring in electrical equipment. The proposed system uses two cameras; a low-resolution camera that detects insulators from long-shot images, and a high-resolution camera which captures close-shot images of the equipment at high-resolution that helps for effective defect analysis. We demonstrate the performances of the proposed real-time equipment detection with up to 93% recall with 92% precision, and defect analysis system with up to 98% accuracy, on a large evaluation dataset. Experimental results show that the proposed system achieves state-of-the-art performance in automatic powerline equipment inspection.},
DOI = {10.3390/s18113837}
}



@Article{s18113843,
AUTHOR = {Hashemi-Beni, Leila and Jones, Jeffery and Thompson, Gary and Johnson, Curt and Gebrehiwot, Asmamaw},
TITLE = {Challenges and Opportunities for UAV-Based Digital Elevation Model Generation for Flood-Risk Management: A Case of Princeville, North Carolina},
JOURNAL = {Sensors},
VOLUME = {18},
YEAR = {2018},
NUMBER = {11},
ARTICLE-NUMBER = {3843},
URL = {https://www.mdpi.com/1424-8220/18/11/3843},
ISSN = {1424-8220},
ABSTRACT = {Among the different types of natural disasters, floods are the most devastating, widespread, and frequent. Floods account for approximately 30% of the total loss caused by natural disasters. Accurate flood-risk mapping is critical in reducing such damages by correctly predicting the extent of a flood when coupled with rain and stage gage data, supporting emergency-response planning, developing land use plans and regulations with regard to the construction of structures and infrastructures, and providing damage assessment in both spatial and temporal measurements. The reliability and accuracy of such flood assessment maps is dependent on the quality of the digital elevation model (DEM) in flood conditions. This study investigates the quality of an Unmanned Aerial Vehicle (UAV)-based DEM for spatial flood assessment mapping and evaluating the extent of a flood event in Princeville, North Carolina during Hurricane Matthew. The challenges and problems of on-demand DEM production during a flooding event were discussed. An accuracy analysis was performed by comparing the water surface extracted from the UAV-derived DEM with the water surface/stage obtained using the nearby US Geologic Survey (USGS) stream gauge station and LiDAR data.},
DOI = {10.3390/s18113843}
}



@Article{jimaging4110132,
AUTHOR = {Zisi, Theodota and Alexandridis, Thomas K. and Kaplanis, Spyridon and Navrozidis, Ioannis and Tamouridou, Afroditi-Alexandra and Lagopodi, Anastasia and Moshou, Dimitrios and Polychronos, Vasilios},
TITLE = {Incorporating Surface Elevation Information in UAV Multispectral Images for Mapping Weed Patches},
JOURNAL = {Journal of Imaging},
VOLUME = {4},
YEAR = {2018},
NUMBER = {11},
ARTICLE-NUMBER = {132},
URL = {https://www.mdpi.com/2313-433X/4/11/132},
ISSN = {2313-433X},
ABSTRACT = {Accurate mapping of weed distribution within a field is a first step towards effective weed management. The aim of this work was to improve the mapping of milk thistle (Silybum marianum) weed patches through unmanned aerial vehicle (UAV) images using auxiliary layers of information, such as spatial texture and estimated vegetation height from the UAV digital surface model. UAV multispectral images acquired in the visible and near-infrared parts of the spectrum were used as the main source of data, together with texture that was estimated for the image bands using a local variance filter. The digital surface model was created from structure from motion algorithms using the UAV image stereopairs. From this layer, the terrain elevation was estimated using a focal minimum filter followed by a low-pass filter. The plant height was computed by subtracting the terrain elevation from the digital surface model. Three classification algorithms (maximum likelihood, minimum distance and an object-based image classifier) were used to identify S. marianum from other vegetation using various combinations of inputs: image bands, texture and plant height. The resulting weed distribution maps were evaluated for their accuracy using field-surveyed data. Both texture and plant height have helped improve the accuracy of classification of S. marianum weed, increasing the overall accuracy of classification from 70% to 87% in 2015, and from 82% to 95% in 2016. Thus, as texture is easier to compute than plant height from a digital surface model, it may be preferable to be used in future weed mapping applications.},
DOI = {10.3390/jimaging4110132}
}



@Article{ijgi7110441,
AUTHOR = {Zhou, Zhenjin and Ma, Lei and Fu, Tengyu and Zhang, Ge and Yao, Mengru and Li, Manchun},
TITLE = {Change Detection in Coral Reef Environment Using High-Resolution Images: Comparison of Object-Based and Pixel-Based Paradigms},
JOURNAL = {ISPRS International Journal of Geo-Information},
VOLUME = {7},
YEAR = {2018},
NUMBER = {11},
ARTICLE-NUMBER = {441},
URL = {https://www.mdpi.com/2220-9964/7/11/441},
ISSN = {2220-9964},
ABSTRACT = {Despite increases in the spatial resolution of satellite imagery prompting interest in object-based image analysis, few studies have used object-based methods for monitoring changes in coral reefs. This study proposes a high accuracy object-based change detection (OBCD) method intended for coral reef environment, which uses QuickBird and WorldView-2 images. The proposed methodological framework includes image fusion, multi-temporal image segmentation, image differencing, random forests models, and object-area-based accuracy assessment. For validation, we applied the method to images of four coral reef study sites in the South China Sea. We compared the proposed OBCD method with a conventional pixel-based change detection (PBCD) method by implementing both methods under the same conditions. The average overall accuracy of OBCD exceeded 90%, which was approximately 20% higher than PBCD. The OBCD method was free from salt-and-pepper effects and was less prone to images misregistration in terms of change detection accuracy and mapping results. The object-area-based accuracy assessment reached a higher overall accuracy and per-class accuracy than the object-number-based and pixel-number-based accuracy assessment.},
DOI = {10.3390/ijgi7110441}
}



@Article{polym10111262,
AUTHOR = {Galatas, Athanasios and Hassanin, Hany and Zweiri, Yahya and Seneviratne, Lakmal},
TITLE = {Additive Manufactured Sandwich Composite/ABS Parts for Unmanned Aerial Vehicle Applications},
JOURNAL = {Polymers},
VOLUME = {10},
YEAR = {2018},
NUMBER = {11},
ARTICLE-NUMBER = {1262},
URL = {https://www.mdpi.com/2073-4360/10/11/1262},
ISSN = {2073-4360},
ABSTRACT = {Fused deposition modelling (FDM) is one of most popular 3D printing techniques of thermoplastic polymers. Nonetheless, the poor mechanical strength of FDM parts restricts the use of this technology in functional parts of many applications such as unmanned aerial vehicles (UAVs) where lightweight, high strength, and stiffness are required. In the present paper, the fabrication process of low-density acrylonitrile butadiene styrenecarbon (ABS) with carbon fibre reinforced polymer (CFRP) sandwich layers for UAV structure is proposed to improve the poor mechanical strength and elastic modulus of printed ABS. The composite sandwich structures retains FDM advantages for rapid making of complex geometries, while only requires simple post-processing steps to improve the mechanical properties. Artificial neural network (ANN) was used to investigate the influence of the core density and number of CFRP layers on the mechanical properties. The results showed an improvement of specific strength and elastic modulus with increasing the number of CFRP. The specific strength of the samples improved from 20 to 145 KN&middot;m/kg while the Young&rsquo;s modulus increased from 0.63 to 10.1 GPa when laminating the samples with CFRP layers. On the other hand, the core density had no significant effect on both specific strength and elastic modulus. A case study was undertaken by applying the CFRP/ABS/CFRP sandwich structure using the proposed method to manufacture improved dual-tilting clamps of a quadcopter UAV.},
DOI = {10.3390/polym10111262}
}



@Article{rs10111798,
AUTHOR = {Michez, Adrien and Bauwens, Sébastien and Brostaux, Yves and Hiel, Marie-Pierre and Garré, Sarah and Lejeune, Philippe and Dumont, Benjamin},
TITLE = {How Far Can Consumer-Grade UAV RGB Imagery Describe Crop Production? A 3D and Multitemporal Modeling Approach Applied to Zea mays},
JOURNAL = {Remote Sensing},
VOLUME = {10},
YEAR = {2018},
NUMBER = {11},
ARTICLE-NUMBER = {1798},
URL = {https://www.mdpi.com/2072-4292/10/11/1798},
ISSN = {2072-4292},
ABSTRACT = {In recent decades, remote sensing has increasingly been used to estimate the spatio-temporal evolution of crop biophysical parameters such as the above-ground biomass (AGB). On a local scale, the advent of unmanned aerial vehicles (UAVs) seems to be a promising trade-off between satellite/airborne and terrestrial remote sensing. This study aims to evaluate the potential of a low-cost UAV RGB solution to predict the final AGB of Zea mays. Besides evaluating the interest of 3D data and multitemporality, our study aims to answer operational questions such as when one should plan a combination of two UAV flights for AGB modeling. In this case, study, final AGB prediction model performance reached 0.55 (R-square) using only UAV information and 0.8 (R-square) when combining UAV information from a single flight with a single-field AGB measurement. The adding of UAV height information to the model improves the quality of the AGB prediction. Performing two flights provides almost systematically an improvement in AGB prediction ability in comparison to most single flights. Our study provides clear insight about how we can counter the low spectral resolution of consumer-grade RGB cameras using height information and multitemporality. Our results highlight the importance of the height information which can be derived from UAV data on one hand, and on the other hand, the lower relative importance of RGB spectral information.},
DOI = {10.3390/rs10111798}
}



@Article{s18113908,
AUTHOR = {Liu, Yanli and Zhang, Heng and Guo, Hanlei and Xiong, Neal N.},
TITLE = {A FAST-BRISK Feature Detector with Depth Information},
JOURNAL = {Sensors},
VOLUME = {18},
YEAR = {2018},
NUMBER = {11},
ARTICLE-NUMBER = {3908},
URL = {https://www.mdpi.com/1424-8220/18/11/3908},
ISSN = {1424-8220},
ABSTRACT = {RGB-D cameras offer both color and depth images of the surrounding environment, making them an attractive option for robotic and vision applications. This work introduces the BRISK_D algorithm, which efficiently combines Features from Accelerated Segment Test (FAST) and Binary Robust Invariant Scalable Keypoints (BRISK) methods. In the BRISK_D algorithm, the keypoints are detected by the FAST algorithm and the location of the keypoint is refined in the scale and the space. The scale factor of the keypoint is directly computed with the depth information of the image. In the experiment, we have made a detailed comparative analysis of the three algorithms SURF, BRISK and BRISK_D from the aspects of scaling, rotation, perspective and blur. The BRISK_D algorithm combines depth information and has good algorithm performance.},
DOI = {10.3390/s18113908}
}



@Article{su10114178,
AUTHOR = {Zhu, Yadi and Chen, Feng and Li, Ming and Wang, Zijia},
TITLE = {Inferring the Economic Attributes of Urban Rail Transit Passengers Based on Individual Mobility Using Multisource Data},
JOURNAL = {Sustainability},
VOLUME = {10},
YEAR = {2018},
NUMBER = {11},
ARTICLE-NUMBER = {4178},
URL = {https://www.mdpi.com/2071-1050/10/11/4178},
ISSN = {2071-1050},
ABSTRACT = {Socioeconomic attributes are essential characteristics of people, and many studies on economic attribute inference focus on data that contain user profile information. For data without user profiles, like smart card data, there is no validated method for inferring individual economic attributes. This study aims to bridge this gap by formulating a mobility to attribute framework to infer passengers&rsquo; economic attributes based on the relationship between individual mobility and personal attributes. This framework integrates shop consumer prices, house prices, and smart card data using three steps: individual mobility extraction, location feature identification, and economic attribute inference. Each passenger&rsquo;s individual mobility is extracted by smart card data. Economic features of stations are described using house price and shop consumer price data. Then, each passenger&rsquo;s comprehensive consumption indicator set is formulated by integrating these data. Finally, individual economic levels are classified. From the case study of Beijing, commuting distance and trip frequency using the metro have a negative correlation with passengers&rsquo; income and the results confirm that metro passengers are mainly in the low- and middle-income groups. This study improves on passenger information extracted from data without user profile information and provides a method to integrate multisource big data mining for more information.},
DOI = {10.3390/su10114178}
}



@Article{s18113921,
AUTHOR = {Boonpook, Wuttichai and Tan, Yumin and Ye, Yinghua and Torteeka, Peerapong and Torsri, Kritanai and Dong, Shengxian},
TITLE = {A Deep Learning Approach on Building Detection from Unmanned Aerial Vehicle-Based Images in Riverbank Monitoring},
JOURNAL = {Sensors},
VOLUME = {18},
YEAR = {2018},
NUMBER = {11},
ARTICLE-NUMBER = {3921},
URL = {https://www.mdpi.com/1424-8220/18/11/3921},
ISSN = {1424-8220},
ABSTRACT = {Buildings along riverbanks are likely to be affected by rising water levels, therefore the acquisition of accurate building information has great importance not only for riverbank environmental protection but also for dealing with emergency cases like flooding. UAV-based photographs are flexible and cloud-free compared to satellite images and can provide very high-resolution images up to centimeter level, while there exist great challenges in quickly and accurately detecting and extracting building from UAV images because there are usually too many details and distortions on UAV images. In this paper, a deep learning (DL)-based approach is proposed for more accurately extracting building information, in which the network architecture, SegNet, is used in the semantic segmentation after the network training on a completely labeled UAV image dataset covering multi-dimension urban settlement appearances along a riverbank area in Chongqing. The experiment results show that an excellent performance has been obtained in the detection of buildings from untrained locations with an average overall accuracy more than 90%. To verify the generality and advantage of the proposed method, the procedure is further evaluated by training and testing with another two open standard datasets which have a variety of building patterns and styles, and the final overall accuracies of building extraction are more than 93% and 95%, respectively.},
DOI = {10.3390/s18113921}
}



@Article{ijgi7110445,
AUTHOR = {Mishra, Niti B. and Mainali, Kumar P. and Shrestha, Bharat B. and Radenz, Jackson and Karki, Debendra},
TITLE = {Species-Level Vegetation Mapping in a Himalayan Treeline Ecotone Using Unmanned Aerial System (UAS) Imagery},
JOURNAL = {ISPRS International Journal of Geo-Information},
VOLUME = {7},
YEAR = {2018},
NUMBER = {11},
ARTICLE-NUMBER = {445},
URL = {https://www.mdpi.com/2220-9964/7/11/445},
ISSN = {2220-9964},
ABSTRACT = {Understanding ecological patterns and response to climate change requires unbiased data on species distribution. This can be challenging, especially in biodiverse but extreme environments like the Himalaya. This study presents the results of the first ever application of Unmanned Aerial Systems (UAS) imagery for species-level mapping of vegetation in the Himalaya following a hierarchical Geographic Object Based Image Analysis (GEOBIA) method. The first level of classification separated green vegetated objects from the rest with overall accuracy of 95%. At the second level, seven cover types were identified (including four woody vegetation species). For this, the suitability of various spectral, shape and textural features were tested for classifying them using an ensemble decision tree algorithm. Spectral features alone yielded ~70% accuracy (kappa 0.66) whereas adding textural and shape features marginally improved the accuracy (73%) but at the cost of a substantial increase in processing time. Contrast in plant morphological traits was the key to distinguishing nearby stands as different species. Hence, broad-leaved versus fine needle leaved vegetation were mapped more accurately than structurally similar classes such as Rhododendron anthopogon versus non-photosynthetic vegetation. Results highlight the potential and limitations of the suggested UAS-GEOBIA approach for detailed mapping of plant communities and suggests future research directions.},
DOI = {10.3390/ijgi7110445}
}



@Article{s18113937,
AUTHOR = {Zhang, Yihong and Yang, Yijin and Zhou, Wuneng and Shi, Lifeng and Li, Demin},
TITLE = {Motion-Aware Correlation Filters for Online Visual Tracking},
JOURNAL = {Sensors},
VOLUME = {18},
YEAR = {2018},
NUMBER = {11},
ARTICLE-NUMBER = {3937},
URL = {https://www.mdpi.com/1424-8220/18/11/3937},
ISSN = {1424-8220},
ABSTRACT = {The discriminative correlation filters-based methods struggle deal with the problem of fast motion and heavy occlusion, the problem can severely degrade the performance of trackers, ultimately leading to tracking failures. In this paper, a novel Motion-Aware Correlation Filters (MACF) framework is proposed for online visual object tracking, where a motion-aware strategy based on joint instantaneous motion estimation Kalman filters is integrated into the Discriminative Correlation Filters (DCFs). The proposed motion-aware strategy is used to predict the possible region and scale of the target in the current frame by utilizing the previous estimated 3D motion information. Obviously, this strategy can prevent model drift caused by fast motion. On the base of the predicted region and scale, the MACF detects the position and scale of the target by using the DCFs-based method in the current frame. Furthermore, an adaptive model updating strategy is proposed to address the problem of corrupted models caused by occlusions, where the learning rate is determined by the confidence of the response map. The extensive experiments on popular Object Tracking Benchmark OTB-100, OTB-50 and unmanned aerial vehicles (UAV) video have demonstrated that the proposed MACF tracker performs better than most of the state-of-the-art trackers and achieves a high real-time performance. In addition, the proposed approach can be integrated easily and flexibly into other visual tracking algorithms.},
DOI = {10.3390/s18113937}
}



@Article{sym10110646,
AUTHOR = {Sun, Jian and Huang, Guanhua and Sun, Gang and Yu, Hongfang and Sangaiah, Arun Kumar and Chang, Victor},
TITLE = {A Q-Learning-Based Approach for Deploying Dynamic Service Function Chains},
JOURNAL = {Symmetry},
VOLUME = {10},
YEAR = {2018},
NUMBER = {11},
ARTICLE-NUMBER = {646},
URL = {https://www.mdpi.com/2073-8994/10/11/646},
ISSN = {2073-8994},
ABSTRACT = {As the size and service requirements of today&rsquo;s networks gradually increase, large numbers of proprietary devices are deployed, which leads to network complexity, information security crises and makes network service and service provider management increasingly difficult. Network function virtualization (NFV) technology is one solution to this problem. NFV separates network functions from hardware and deploys them as software on a common server. NFV can be used to improve service flexibility and isolate the services provided for each user, thus guaranteeing the security of user data. Therefore, the use of NFV technology includes many problems worth studying. For example, when there is a free choice of network path, one problem is how to choose a service function chain (SFC) that both meets the requirements and offers the service provider maximum profit. Most existing solutions are heuristic algorithms with high time efficiency, or integer linear programming (ILP) algorithms with high accuracy. It&rsquo;s necessary to design an algorithm that symmetrically considers both time efficiency and accuracy. In this paper, we propose the Q-learning Framework Hybrid Module algorithm (QLFHM), which includes reinforcement learning to solve this SFC deployment problem in dynamic networks. The reinforcement learning module in QLFHM is responsible for the output of alternative paths, while the load balancing module in QLFHM is responsible for picking the optimal solution from them. The results of a comparison simulation experiment on a dynamic network topology show that the proposed algorithm can output the approximate optimal solution in a relatively short time while also considering the network load balance. Thus, it achieves the goal of maximizing the benefit to the service provider.},
DOI = {10.3390/sym10110646}
}



@Article{s18114015,
AUTHOR = {Lagkas, Thomas and Argyriou, Vasileios and Bibi, Stamatia and Sarigiannidis, Panagiotis},
TITLE = {UAV IoT Framework Views and Challenges: Towards Protecting Drones as “Things”},
JOURNAL = {Sensors},
VOLUME = {18},
YEAR = {2018},
NUMBER = {11},
ARTICLE-NUMBER = {4015},
URL = {https://www.mdpi.com/1424-8220/18/11/4015},
ISSN = {1424-8220},
ABSTRACT = {Unmanned aerial vehicles (UAVs) have enormous potential in enabling new applications in various areas, ranging from military, security, medicine, and surveillance to traffic-monitoring applications. Lately, there has been heavy investment in the development of UAVs and multi-UAVs systems that can collaborate and complete missions more efficiently and economically. Emerging technologies such as 4G/5G networks have significant potential on UAVs equipped with cameras, sensors, and GPS receivers in delivering Internet of Things (IoT) services from great heights, creating an airborne domain of the IoT. However, there are many issues to be resolved before the effective use of UAVs can be made, including security, privacy, and management. As such, in this paper we review new UAV application areas enabled by the IoT and 5G technologies, analyze the sensor requirements, and overview solutions for fleet management over aerial-networking, privacy, and security challenges. Finally, we propose a framework that supports and enables these technologies on UAVs. The introduced framework provisions a holistic IoT architecture that enables the protection of UAVs as “flying” things in a collaborative networked environment.},
DOI = {10.3390/s18114015}
}



@Article{rs10111827,
AUTHOR = {Song, Ahram and Choi, Jaewan and Han, Youkyung and Kim, Yongil},
TITLE = {Change Detection in Hyperspectral Images Using Recurrent 3D Fully Convolutional Networks},
JOURNAL = {Remote Sensing},
VOLUME = {10},
YEAR = {2018},
NUMBER = {11},
ARTICLE-NUMBER = {1827},
URL = {https://www.mdpi.com/2072-4292/10/11/1827},
ISSN = {2072-4292},
ABSTRACT = {Hyperspectral change detection (CD) can be effectively performed using deep-learning networks. Although these approaches require qualified training samples, it is difficult to obtain ground-truth data in the real world. Preserving spatial information during training is difficult due to structural limitations. To solve such problems, our study proposed a novel CD method for hyperspectral images (HSIs), including sample generation and a deep-learning network, called the recurrent three-dimensional (3D) fully convolutional network (Re3FCN), which merged the advantages of a 3D fully convolutional network (FCN) and a convolutional long short-term memory (ConvLSTM). Principal component analysis (PCA) and the spectral correlation angle (SCA) were used to generate training samples with high probabilities of being changed or unchanged. The strategy assisted in training fewer samples of representative feature expression. The Re3FCN was mainly comprised of spectral&ndash;spatial and temporal modules. Particularly, a spectral&ndash;spatial module with a 3D convolutional layer extracts the spectral&ndash;spatial features from the HSIs simultaneously, whilst a temporal module with ConvLSTM records and analyzes the multi-temporal HSI change information. The study first proposed a simple and effective method to generate samples for network training. This method can be applied effectively to cases with no training samples. Re3FCN can perform end-to-end detection for binary and multiple changes. Moreover, Re3FCN can receive multi-temporal HSIs directly as input without learning the characteristics of multiple changes. Finally, the network could extract joint spectral&ndash;spatial&ndash;temporal features and it preserved the spatial structure during the learning process through the fully convolutional structure. This study was the first to use a 3D FCN and a ConvLSTM for the remote-sensing CD. To demonstrate the effectiveness of the proposed CD method, we performed binary and multi-class CD experiments. Results revealed that the Re3FCN outperformed the other conventional methods, such as change vector analysis, iteratively reweighted multivariate alteration detection, PCA-SCA, FCN, and the combination of 2D convolutional layers-fully connected LSTM.},
DOI = {10.3390/rs10111827}
}



@Article{s18114019,
AUTHOR = {Kim, Yunbin and Sa, Jaewon and Chung, Yongwha and Park, Daihee and Lee, Sungju},
TITLE = {Resource-Efficient Pet Dog Sound Events Classification Using LSTM-FCN Based on Time-Series Data},
JOURNAL = {Sensors},
VOLUME = {18},
YEAR = {2018},
NUMBER = {11},
ARTICLE-NUMBER = {4019},
URL = {https://www.mdpi.com/1424-8220/18/11/4019},
ISSN = {1424-8220},
ABSTRACT = {The use of IoT (Internet of Things) technology for the management of pet dogs left alone at home is increasing. This includes tasks such as automatic feeding, operation of play equipment, and location detection. Classification of the vocalizations of pet dogs using information from a sound sensor is an important method to analyze the behavior or emotions of dogs that are left alone. These sounds should be acquired by attaching the IoT sound sensor to the dog, and then classifying the sound events (e.g., barking, growling, howling, and whining). However, sound sensors tend to transmit large amounts of data and consume considerable amounts of power, which presents issues in the case of resource-constrained IoT sensor devices. In this paper, we propose a way to classify pet dog sound events and improve resource efficiency without significant degradation of accuracy. To achieve this, we only acquire the intensity data of sounds by using a relatively resource-efficient noise sensor. This presents issues as well, since it is difficult to achieve sufficient classification accuracy using only intensity data due to the loss of information from the sound events. To address this problem and avoid significant degradation of classification accuracy, we apply long short-term memory-fully convolutional network (LSTM-FCN), which is a deep learning method, to analyze time-series data, and exploit bicubic interpolation. Based on experimental results, the proposed method based on noise sensors (i.e., Shapelet and LSTM-FCN for time-series) was found to improve energy efficiency by 10 times without significant degradation of accuracy compared to typical methods based on sound sensors (i.e., mel-frequency cepstrum coefficient (MFCC), spectrogram, and mel-spectrum for feature extraction, and support vector machine (SVM) and k-nearest neighbor (K-NN) for classification).},
DOI = {10.3390/s18114019}
}



@Article{drones2040039,
AUTHOR = {Csillik, Ovidiu and Cherbini, John and Johnson, Robert and Lyons, Andy and Kelly, Maggi},
TITLE = {Identification of Citrus Trees from Unmanned Aerial Vehicle Imagery Using Convolutional Neural Networks},
JOURNAL = {Drones},
VOLUME = {2},
YEAR = {2018},
NUMBER = {4},
ARTICLE-NUMBER = {39},
URL = {https://www.mdpi.com/2504-446X/2/4/39},
ISSN = {2504-446X},
ABSTRACT = {Remote sensing is important to precision agriculture and the spatial resolution provided by Unmanned Aerial Vehicles (UAVs) is revolutionizing precision agriculture workflows for measurement crop condition and yields over the growing season, for identifying and monitoring weeds and other applications. Monitoring of individual trees for growth, fruit production and pest and disease occurrence remains a high research priority and the delineation of each tree using automated means as an alternative to manual delineation would be useful for long-term farm management. In this paper, we detected citrus and other crop trees from UAV images using a simple convolutional neural network (CNN) algorithm, followed by a classification refinement using superpixels derived from a Simple Linear Iterative Clustering (SLIC) algorithm. The workflow performed well in a relatively complex agricultural environment (multiple targets, multiple size trees and ages, etc.) achieving high accuracy (overall accuracy = 96.24%, Precision (positive predictive value) = 94.59%, Recall (sensitivity) = 97.94%). To our knowledge, this is the first time a CNN has been used with UAV multi-spectral imagery to focus on citrus trees. More of these individual cases are needed to develop standard automated workflows to help agricultural managers better incorporate large volumes of high resolution UAV imagery into agricultural management operations.},
DOI = {10.3390/drones2040039}
}



@Article{s18114073,
AUTHOR = {N. de Sousa, Marcelo and S. Thomä, Reiner},
TITLE = {Enhancement of Localization Systems in NLOS Urban Scenario with Multipath Ray Tracing Fingerprints and Machine Learning},
JOURNAL = {Sensors},
VOLUME = {18},
YEAR = {2018},
NUMBER = {11},
ARTICLE-NUMBER = {4073},
URL = {https://www.mdpi.com/1424-8220/18/11/4073},
ISSN = {1424-8220},
ABSTRACT = {A hybrid technique is proposed to enhance the localization performance of a time difference of arrival (TDOA) deployed in non-line-of-sight (NLOS) suburban scenario. The idea was to use Machine Learning framework on the dataset, produced by the ray tracing simulation, and the Channel Impulse Response estimation from the real signal received by each sensor. Conventional localization techniques mitigate errors trying to avoid NLOS measurements in processing emitter position, while the proposed method uses the multipath fingerprint information produced by ray tracing (RT) simulation together with calibration emitters to refine a Machine Learning engine, which gives an extra layer of information to improve the emitter position estimation. The ray-tracing fingerprints perform the target localization embedding all the reflection and diffraction in the propagation scenario. A validation campaign was performed and showed the feasibility of the proposed method, provided that the buildings can be appropriately included in the scenario description.},
DOI = {10.3390/s18114073}
}



@Article{drones2040040,
AUTHOR = {White, Raechel A. and Bomber, Michael and Hupy, Joseph P. and Shortridge, Ashton},
TITLE = {UAS-GEOBIA Approach to Sapling Identification in Jack Pine Barrens after Fire},
JOURNAL = {Drones},
VOLUME = {2},
YEAR = {2018},
NUMBER = {4},
ARTICLE-NUMBER = {40},
URL = {https://www.mdpi.com/2504-446X/2/4/40},
ISSN = {2504-446X},
ABSTRACT = {Jack pine (pinus banksiana) forests are unique ecosystems controlled by wildfire. Understanding the traits of revegetation after wildfire is important for sustainable forest management, as these forests not only provide economic resources, but also are home to specialized species, like the Kirtland Warbler (Setophaga kirtlandii). Individual tree detection of jack pine saplings after fire events can provide information about an environment&rsquo;s recovery. Traditional satellite and manned aerial sensors lack the flexibility and spatial resolution required for identifying saplings in early post-fire analysis. Here we evaluated the use of unmanned aerial systems and geographic object-based image analysis for jack pine sapling identification in a region burned during the 2012 Duck Lake Fire in the Upper Peninsula of Michigan. Results of this study indicate that sapling identification accuracies can top 90%, and that accuracy improves with the inclusion of red and near infrared spectral bands. Results also indicated that late season imagery performed best when discriminating between young (&lt;5 years) jack pines and herbaceous ground cover in these environments.},
DOI = {10.3390/drones2040040}
}



@Article{rs10121865,
AUTHOR = {Garcia Millan, Virginia and Sanchez-Azofeifa, Arturo},
TITLE = {Quantifying Changes on Forest Succession in a Dry Tropical Forest Using Angular-Hyperspectral Remote Sensing},
JOURNAL = {Remote Sensing},
VOLUME = {10},
YEAR = {2018},
NUMBER = {12},
ARTICLE-NUMBER = {1865},
URL = {https://www.mdpi.com/2072-4292/10/12/1865},
ISSN = {2072-4292},
ABSTRACT = {The tropical dry forest (TDF) is one the most threatened ecosystems in South America, existing on a landscape with different levels of ecological succession. Among satellites dedicated to Earth observation and monitoring ecosystem succession, CHRIS/PROBA is the only satellite that presents quasi-simultaneous multi-angular pointing and hyperspectral imaging. These two characteristics permit the study of structural and compositional differences of TDFs with different levels of succession. In this paper, we use 2008 and 2014 CHRIS/PROBA images from a TDF in Minas Gerais, Brazil to study ecosystem succession after abandonment. Using a &minus;55&deg; angle of observation; several classifiers including spectral angle mapper (SAM), support vector machine (SVM), and decision trees (DT) were used to test how well they discriminate between different successional stages. Our findings suggest that the SAM is the most appropriate method to classify TDFs as a function of succession (accuracies ~80 for % for late stage, ~85% for the intermediate stage, ~70% for early stage, and ~50% for other classes). Although CHRIS/PROBA cannot be used for large-scale/long-term monitoring of tropical forests because of its experimental nature; our results support the potential of using multi-angle hyperspectral data to characterize the structure and composition of TDFs in the near future.},
DOI = {10.3390/rs10121865}
}



@Article{rs10121866,
AUTHOR = {Rahman, Muhammad Moshiur and Robson, Andrew and Bristow, Mila},
TITLE = {Exploring the Potential of High Resolution WorldView-3 Imagery for Estimating Yield of Mango},
JOURNAL = {Remote Sensing},
VOLUME = {10},
YEAR = {2018},
NUMBER = {12},
ARTICLE-NUMBER = {1866},
URL = {https://www.mdpi.com/2072-4292/10/12/1866},
ISSN = {2072-4292},
ABSTRACT = {Pre-harvest yield estimation of mango fruit is important for the optimization of inputs and other resources on the farm. Current industry practice of visual counting the fruit on a small number of trees for yield forecasting can be highly inaccurate due to the spatial variability, especially if the trees selected do not represent the entire crop. Therefore, this study evaluated the potential of high resolution WorldView-3 (WV3) satellite imagery to estimate yield of mango by integrating both geometric (tree crown area) and optical (spectral vegetation indices) data using artificial neural network (ANN) model. WV3 images were acquired in 2016&ndash;2017 and 2017&ndash;2018 growing seasons at the early fruit stage from three orchards in Acacia Hills region, Northern Territory, Australia. Stratified sampling technique (SST) was applied to select 18 trees from each orchard and subsequently ground truthed for yield (kg&middot;tree&minus;1) and fruit number per tree. For each sampled tree, spectral reflectance data and tree crown area (TCA) was extracted from WV3 imagery. The TCA was identified as the most important predictor of both fruit yield (kg&middot;tree&minus;1) and fruit number, followed by NDVI red-edge band when all trees from three orchards in two growing seasons were combined. The results of all sampled trees from three orchards in two growing seasons using ANN model produced a strong correlation (R2 = 0.70 and 0.68 for total fruit yield (kg&middot;tree&minus;1) and fruit number respectively), which suggest that the model can be obtained to predict yield on a regional level. On orchard level also the ANN model produced a high correlation when both growing seasons were combined. However, the model developed in one season could not be applied in another season due to the influence of seasonal variation and canopy condition. Using the relationship derived from the measured yield parameters against combined VIs and TCA data, the total fruit yield (t&middot;ha&minus;1) and fruit number were estimated for each orchard, produced 7% under estimation to less than 1% over estimation. The accuracy of the findings showed the potential of WV3 imagery to better predict the yield parameters than the current practice across the mango industry as well as to quantify lost yield as a result of delayed harvest.},
DOI = {10.3390/rs10121866}
}



@Article{s18124092,
AUTHOR = {Han, Xiongzhe and Thomasson, J. Alex and Bagnall, G. Cody and Pugh, N. Ace and Horne, David W. and Rooney, William L. and Jung, Jinha and Chang, Anjin and Malambo, Lonesome and Popescu, Sorin C. and Gates, Ian T. and Cope, Dale A.},
TITLE = {Measurement and Calibration of Plant-Height from Fixed-Wing UAV Images},
JOURNAL = {Sensors},
VOLUME = {18},
YEAR = {2018},
NUMBER = {12},
ARTICLE-NUMBER = {4092},
URL = {https://www.mdpi.com/1424-8220/18/12/4092},
ISSN = {1424-8220},
ABSTRACT = {Continuing population growth will result in increasing global demand for food and fiber for the foreseeable future. During the growing season, variability in the height of crops provides important information on plant health, growth, and response to environmental effects. This paper indicates the feasibility of using structure from motion (SfM) on images collected from 120 m above ground level (AGL) with a fixed-wing unmanned aerial vehicle (UAV) to estimate sorghum plant height with reasonable accuracy on a relatively large farm field. Correlations between UAV-based estimates and ground truth were strong on all dates (R2 &gt; 0.80) but are clearly better on some dates than others. Furthermore, a new method for improving UAV-based plant height estimates with multi-level ground control points (GCPs) was found to lower the root mean square error (RMSE) by about 20%. These results indicate that GCP-based height calibration has a potential for future application where accuracy is particularly important. Lastly, the image blur appeared to have a significant impact on the accuracy of plant height estimation. A strong correlation (R2 = 0.85) was observed between image quality and plant height RMSE and the influence of wind was a challenge in obtaining high-quality plant height data. A strong relationship (R2 = 0.99) existed between wind speed and image blurriness.},
DOI = {10.3390/s18124092}
}



@Article{rs10121867,
AUTHOR = {Aragon, Bruno and Houborg, Rasmus and Tu, Kevin and Fisher, Joshua B. and McCabe, Matthew},
TITLE = {CubeSats Enable High Spatiotemporal Retrievals of Crop-Water Use for Precision Agriculture},
JOURNAL = {Remote Sensing},
VOLUME = {10},
YEAR = {2018},
NUMBER = {12},
ARTICLE-NUMBER = {1867},
URL = {https://www.mdpi.com/2072-4292/10/12/1867},
ISSN = {2072-4292},
ABSTRACT = {Remote sensing based estimation of evapotranspiration (ET) provides a direct accounting of the crop water use. However, the use of satellite data has generally required that a compromise between spatial and temporal resolution is made, i.e., one could obtain low spatial resolution data regularly, or high spatial resolution occasionally. As a consequence, this spatiotemporal trade-off has tended to limit the impact of remote sensing for precision agricultural applications. With the recent emergence of constellations of small CubeSat-based satellite systems, these constraints are rapidly being removed, such that daily 3 m resolution optical data are now a reality for earth observation. Such advances provide an opportunity to develop new earth system monitoring and assessment tools. In this manuscript we evaluate the capacity of CubeSats to advance the estimation of ET via application of the Priestley-Taylor Jet Propulsion Laboratory (PT-JPL) retrieval model. To take advantage of the high-spatiotemporal resolution afforded by these systems, we have integrated a CubeSat derived leaf area index as a forcing variable into PT-JPL, as well as modified key biophysical model parameters. We evaluate model performance over an irrigated farmland in Saudi Arabia using observations from an eddy covariance tower. Crop water use retrievals were also compared against measured irrigation from an in-line flow meter installed within a center-pivot system. To leverage the high spatial resolution of the CubeSat imagery, PT-JPL retrievals were integrated over the source area of the eddy covariance footprint, to allow an equivalent intercomparison. Apart from offering new precision agricultural insights into farm operations and management, the 3 m resolution ET retrievals were shown to explain 86% of the observed variability and provide a relative RMSE of 32.9% for irrigated maize, comparable to previously reported satellite-based retrievals. An observed underestimation was diagnosed as a possible misrepresentation of the local surface moisture status, highlighting the challenge of high-resolution modeling applications for precision agriculture and informing future research directions.},
DOI = {10.3390/rs10121867}
}



@Article{f9120736,
AUTHOR = {Morales, Giorgio and Kemper, Guillermo and Sevillano, Grace and Arteaga, Daniel and Ortega, Ivan and Telles, Joel},
TITLE = {Automatic Segmentation of Mauritia flexuosa in Unmanned Aerial Vehicle (UAV) Imagery Using Deep Learning},
JOURNAL = {Forests},
VOLUME = {9},
YEAR = {2018},
NUMBER = {12},
ARTICLE-NUMBER = {736},
URL = {https://www.mdpi.com/1999-4907/9/12/736},
ISSN = {1999-4907},
ABSTRACT = {One of the most important ecosystems in the Amazon rainforest is the Mauritia flexuosa swamp or “aguajal”. However, deforestation of its dominant species, the Mauritia flexuosa palm, also known as “aguaje”, is a common issue, and conservation is poorly monitored because of the difficult access to these swamps. The contribution of this paper is twofold: the presentation of a dataset called MauFlex, and the proposal of a segmentation and measurement method for areas covered in Mauritia flexuosa palms using high-resolution aerial images acquired by UAVs. The method performs a semantic segmentation of Mauritia flexuosa using an end-to-end trainable Convolutional Neural Network (CNN) based on the Deeplab v3+ architecture. Images were acquired under different environment and light conditions using three different RGB cameras. The MauFlex dataset was created from these images and it consists of 25,248 image patches of     512 × 512     pixels and their respective ground truth masks. The results over the test set achieved an accuracy of 98.143%, specificity of 96.599%, and sensitivity of 95.556%. It is shown that our method is able not only to detect full-grown isolated Mauritia flexuosa palms, but also young palms or palms partially covered by other types of vegetation.},
DOI = {10.3390/f9120736}
}



@Article{rs10121890,
AUTHOR = {Al Rahhal, Mohamad M. and Bazi, Yakoub and Abdullah, Taghreed and Mekhalfi, Mohamed L. and AlHichri, Haikel and Zuair, Mansour},
TITLE = {Learning a Multi-Branch Neural Network from Multiple Sources for Knowledge Adaptation in Remote Sensing Imagery},
JOURNAL = {Remote Sensing},
VOLUME = {10},
YEAR = {2018},
NUMBER = {12},
ARTICLE-NUMBER = {1890},
URL = {https://www.mdpi.com/2072-4292/10/12/1890},
ISSN = {2072-4292},
ABSTRACT = {In this paper we propose a multi-branch neural network, called MB-Net, for solving the problem of knowledge adaptation from multiple remote sensing scene datasets acquired with different sensors over diverse locations and manually labeled with different experts. Our aim is to learn invariant feature representations from multiple source domains with labeled images and one target domain with unlabeled images. To this end, we define for MB-Net an objective function that mitigates the multiple domain shifts at both feature representation and decision levels, while retaining the ability to discriminate between different land-cover classes. The complete architecture is trainable end-to-end via the backpropagation algorithm. In the experiments, we demonstrate the effectiveness of the proposed method on a new multiple domain dataset created from four heterogonous scene datasets well known to the remote sensing community, namely, the University of California (UC-Merced) dataset, the Aerial Image dataset (AID), the PatternNet dataset, and the Northwestern Polytechnical University (NWPU) dataset. In particular, this method boosts the average accuracy over all transfer scenarios up to 89.05% compared to standard architecture based only on cross-entropy loss, which yields an average accuracy of 78.53%.},
DOI = {10.3390/rs10121890}
}



@Article{rs10121900,
AUTHOR = {Sarron, Julien and Malézieux, Éric and Sané, Cheikh Amet Bassirou and Faye, Émile},
TITLE = {Mango Yield Mapping at the Orchard Scale Based on Tree Structure and Land Cover Assessed by UAV},
JOURNAL = {Remote Sensing},
VOLUME = {10},
YEAR = {2018},
NUMBER = {12},
ARTICLE-NUMBER = {1900},
URL = {https://www.mdpi.com/2072-4292/10/12/1900},
ISSN = {2072-4292},
ABSTRACT = {In the value chain, yields are key information for both growers and other stakeholders in market supply and exports. However, orchard yields are often still based on an extrapolation of tree production which is visually assessed on a limited number of trees; a tedious and inaccurate task that gives no yield information at a finer scale than the orchard plot. In this work, we propose a method to accurately map individual tree production at the orchard scale by developing a trade-off methodology between mechanistic yield modelling and extensive fruit counting using machine vision systems. A methodological toolbox was developed and tested to estimate and map tree species, structure, and yields in mango orchards of various cropping systems (from monocultivar to plurispecific orchards) in the Niayes region, West Senegal. Tree structure parameters (height, crown area and volume), species, and mango cultivars were measured using unmanned aerial vehicle (UAV) photogrammetry and geographic, object-based image analysis. This procedure reached an average overall accuracy of 0.89 for classifying tree species and mango cultivars. Tree structure parameters combined with a fruit load index, which takes into account year and management effects, were implemented in predictive production models of three mango cultivars. Models reached satisfying accuracies with R2 greater than 0.77 and RMSE% ranging from 20% to 29% when evaluated with the measured production of 60 validation trees. In 2017, this methodology was applied to 15 orchards overflown by UAV, and estimated yields were compared to those measured by the growers for six of them, showing the proper efficiency of our technology. The proposed method achieved the breakthrough of rapidly and precisely mapping mango yields without detecting fruits from ground imagery, but rather, by linking yields with tree structural parameters. Such a tool will provide growers with accurate yield estimations at the orchard scale, and will permit them to study the parameters that drive yield heterogeneity within and between orchards.},
DOI = {10.3390/rs10121900}
}



@Article{rs10121907,
AUTHOR = {Pádua, Luís and Marques, Pedro and Hruška, Jonáš and Adão, Telmo and Peres, Emanuel and Morais, Raul and Sousa, Joaquim J.},
TITLE = {Multi-Temporal Vineyard Monitoring through UAV-Based RGB Imagery},
JOURNAL = {Remote Sensing},
VOLUME = {10},
YEAR = {2018},
NUMBER = {12},
ARTICLE-NUMBER = {1907},
URL = {https://www.mdpi.com/2072-4292/10/12/1907},
ISSN = {2072-4292},
ABSTRACT = {This study aimed to characterize vineyard vegetation thorough multi-temporal monitoring using a commercial low-cost rotary-wing unmanned aerial vehicle (UAV) equipped with a consumer-grade red/green/blue (RGB) sensor. Ground-truth data and UAV-based imagery were acquired on nine distinct dates, covering the most significant vegetative growing cycle until harvesting season, over two selected vineyard plots. The acquired UAV-based imagery underwent photogrammetric processing resulting, per flight, in an orthophoto mosaic, used for vegetation estimation. Digital elevation models were used to compute crop surface models. By filtering vegetation within a given height-range, it was possible to separate grapevine vegetation from other vegetation present in a specific vineyard plot, enabling the estimation of grapevine area and volume. The results showed high accuracy in grapevine detection (94.40%) and low error in grapevine volume estimation (root mean square error of 0.13 m and correlation coefficient of 0.78 for height estimation). The accuracy assessment showed that the proposed method based on UAV-based RGB imagery is effective and has potential to become an operational technique. The proposed method also allows the estimation of grapevine areas that can potentially benefit from canopy management operations.},
DOI = {10.3390/rs10121907}
}



@Article{ijgi7120462,
AUTHOR = {Griffith, David C. and Hay, Geoffrey J.},
TITLE = {Integrating GEOBIA, Machine Learning, and Volunteered Geographic Information to Map Vegetation over Rooftops},
JOURNAL = {ISPRS International Journal of Geo-Information},
VOLUME = {7},
YEAR = {2018},
NUMBER = {12},
ARTICLE-NUMBER = {462},
URL = {https://www.mdpi.com/2220-9964/7/12/462},
ISSN = {2220-9964},
ABSTRACT = {The objective of this study is to evaluate operational methods for creating a particular type of urban vegetation map—one focused on vegetation over rooftops (VOR), specifically trees that extend over urban residential buildings. A key constraint was the use of passive remote sensing data only. To achieve this, we (1) conduct a review of the urban remote sensing vegetation classification literature, and we then (2) discuss methods to derive a detailed map of VOR for a study area in Calgary, Alberta, Canada from a late season, high-resolution airborne orthomosaic based on an integration of Geographic Object-Based Image Analysis (GEOBIA), pre-classification filtering of image-objects using Volunteered Geographic Information (VGI), and a machine learning classifier. Pre-classification filtering lowered the computational burden of classification by reducing the number of input objects by 14%. Accuracy assessment results show that, despite the presence of senescing vegetation with low vegetation index values and deep shadows, classification using a small number of image-object spectral attributes as classification features (n = 9) had similar overall accuracy (88.5%) to a much more complex classification (91.8%) comprising a comprehensive set of spectral, texture, and spatial attributes as classification features (n = 86). This research provides an example of the very specific questions answerable about precise urban locations using a combination of high-resolution passive imagery and freely available VGI data. It highlights the benefits of pre-classification filtering and the judicious selection of features from image-object attributes to reduce processing load without sacrificing classification accuracy.},
DOI = {10.3390/ijgi7120462}
}



@Article{rs10121922,
AUTHOR = {Fu, Kun and Li, Yang and Sun, Hao and Yang, Xue and Xu, Guangluan and Li, Yuting and Sun, Xian},
TITLE = {A Ship Rotation Detection Model in Remote Sensing Images Based on Feature Fusion Pyramid Network and Deep Reinforcement Learning},
JOURNAL = {Remote Sensing},
VOLUME = {10},
YEAR = {2018},
NUMBER = {12},
ARTICLE-NUMBER = {1922},
URL = {https://www.mdpi.com/2072-4292/10/12/1922},
ISSN = {2072-4292},
ABSTRACT = {Ship detection plays an important role in automatic remote sensing image interpretation. The scale difference, large aspect ratio of ship, complex remote sensing image background and ship dense parking scene make the detection task difficult. To handle the challenging problems above, we propose a ship rotation detection model based on a Feature Fusion Pyramid Network and deep reinforcement learning (FFPN-RL) in this paper. The detection network can efficiently generate the inclined rectangular box for ship. First, we propose the Feature Fusion Pyramid Network (FFPN) that strengthens the reuse of different scales features, and FFPN can extract the low level location and high level semantic information that has an important impact on multi-scale ship detection and precise location of dense parking ships. Second, in order to get accurate ship angle information, we apply deep reinforcement learning to the inclined ship detection task for the first time. In addition, we put forward prior policy guidance and a long-term training method to train an angle prediction agent constructed through a dueling structure Q network, which is able to iteratively and accurately obtain the ship angle. In addition, we design soft rotation non-maximum suppression to reduce the missed ship detection while suppressing the redundant detection boxes. We carry out detailed experiments on the remote sensing ship image dataset, and the experiments validate that our FFPN-RL ship detection model has efficient detection performance.},
DOI = {10.3390/rs10121922}
}



@Article{rs10121927,
AUTHOR = {Wang, Bing and Jia, Kun and Liang, Shunlin and Xie, Xianhong and Wei, Xiangqin and Zhao, Xiang and Yao, Yunjun and Zhang, Xiaotong},
TITLE = {Assessment of Sentinel-2 MSI Spectral Band Reflectances for Estimating Fractional Vegetation Cover},
JOURNAL = {Remote Sensing},
VOLUME = {10},
YEAR = {2018},
NUMBER = {12},
ARTICLE-NUMBER = {1927},
URL = {https://www.mdpi.com/2072-4292/10/12/1927},
ISSN = {2072-4292},
ABSTRACT = {Fractional vegetation cover (FVC) is an essential parameter for characterizing the land surface vegetation conditions and plays an important role in earth surface process simulations and global change studies. The Sentinel-2 missions carrying multi-spectral instrument (MSI) sensors with 13 multispectral bands are potentially useful for estimating FVC. However, the performance of these bands for FVC estimation is unclear. Therefore, the objective of this study was to assess the performance of Sentinel-2 MSI spectral band reflectances on FVC estimation. The samples, including the Sentinel-2 MSI canopy reflectances and corresponding FVC values, were simulated using the PROSPECT + SAIL radiative transfer model under different conditions, and random forest regression (RFR) method was then used to develop FVC estimation models and assess the performance of various band reflectances for FVC estimation. These models were finally evaluated using field survey data. The results indicate that the three most important bands of Sentinel-2 MSI data for FVC estimation are band 4 (Red), band 12 (SWIR2) and band 8a (NIR2). FVC estimation using these bands has a comparable accuracy (root mean square error (RMSE) = 0.085) with that using all bands (RMSE = 0.090). The results also demonstrate that band 12 had a better performance for FVC estimation than the green band (RMSE = 0.097). However, the newly added red-edge bands, with low scores in the RFR model, have little significance for improving FVC estimation accuracy compared with the Red, NIR2 and SWIR2 bands.},
DOI = {10.3390/rs10121927}
}



@Article{electronics7120364,
AUTHOR = {Wu, Hao and Pang, Bo and Dai, Dahai and Wu, Jiani and Wang, Xuesong},
TITLE = {Unmanned Aerial Vehicle Recognition Based on Clustering by Fast Search and Find of Density Peaks (CFSFDP) with Polarimetric Decomposition},
JOURNAL = {Electronics},
VOLUME = {7},
YEAR = {2018},
NUMBER = {12},
ARTICLE-NUMBER = {364},
URL = {https://www.mdpi.com/2079-9292/7/12/364},
ISSN = {2079-9292},
ABSTRACT = {Unmanned aerial vehicles (UAV) have become vital targets in civilian and military fields. However, the polarization characteristics are rarely studied. This paper studies the polarization property of UAVs via the fusion of three polarimetric decomposition methods. A novel algorithm is presented to classify and recognize UAVs automatically which includes a clustering method proposed in &ldquo;Science&rdquo;, one of the top journals in academia. Firstly, the selection of the imaging algorithm ensures the quality of the radar images. Secondly, local geometrical structures of UAVs can be extracted based on Pauli, Krogager, and Cameron polarimetric decomposition. Finally, the proposed algorithm with clustering by fast search and find of density peaks (CFSFDP) has been demonstrated to be better than the original methods under the various noise conditions with the fusion of three polarimetric decomposition methods.},
DOI = {10.3390/electronics7120364}
}



@Article{rs10121933,
AUTHOR = {Liu, Mingyue and Mao, Dehua and Wang, Zongming and Li, Lin and Man, Weidong and Jia, Mingming and Ren, Chunying and Zhang, Yuanzhi},
TITLE = {Rapid Invasion of Spartina alterniflora in the Coastal Zone of Mainland China: New Observations from Landsat OLI Images},
JOURNAL = {Remote Sensing},
VOLUME = {10},
YEAR = {2018},
NUMBER = {12},
ARTICLE-NUMBER = {1933},
URL = {https://www.mdpi.com/2072-4292/10/12/1933},
ISSN = {2072-4292},
ABSTRACT = {Plant invasion imposes significant threats to biodiversity and ecosystem function. Thus, monitoring the spatial pattern of invasive plants is vital for effective ecosystem management. Spartina alterniflora (S. alterniflora) has been one of the most prevalent invasive plants along the China coast, and its spread has had severe ecological consequences. Here, we provide new observation from Landsat operational land imager (OLI) images. Specifically, 43 Landsat-8 OLI images from 2014 to 2016, a combination of object-based image analysis (OBIA) and support vector machine (SVM) methods, and field surveys covering the whole coast were used to construct an up-to-date dataset for 2015 and investigate the spatial variability of S. alterniflora in the coastal zone of mainland China. The classification results achieved good estimation, with a kappa coefficient of 0.86 and 96% overall accuracy. Our results revealed that there was approximately 545.80 km2 of S. alterniflora distributed in the coastal zone of mainland China in 2015, from Hebei to Guangxi provinces. Nearly 92% of the total area of S. alterniflora was distributed within four provinces: Jiangsu, Shanghai, Zhejiang, and Fujian. Seven national nature reserves invaded by S. alterniflora encompassed approximately one-third (174.35 km2) of the total area of S. alterniflora over mainland China. The Yancheng National Nature Reserve exhibited the largest area of S. alterniflora (115.62 km2) among the reserves. Given the rapid and extensive expansion of S. alterniflora in the 40 years since its introduction and its various ecological effects, geospatially varied responding decisions are needed to promote sustainable coastal ecosystems.},
DOI = {10.3390/rs10121933}
}



@Article{agronomy8120288,
AUTHOR = {Castillejo-González, Isabel Luisa},
TITLE = {Mapping of Olive Trees Using Pansharpened QuickBird Images: An Evaluation of Pixel- and Object-Based Analyses},
JOURNAL = {Agronomy},
VOLUME = {8},
YEAR = {2018},
NUMBER = {12},
ARTICLE-NUMBER = {288},
URL = {https://www.mdpi.com/2073-4395/8/12/288},
ISSN = {2073-4395},
ABSTRACT = {This study sought to verify whether remote sensing offers the ability to efficiently delineate olive tree canopies using QuickBird (QB) satellite imagery. This paper compares four classification algorithms performed in pixel- and object-based analyses. To increase the spectral and spatial resolution of the standard QB image, three different pansharpened images were obtained based on variations in the weight of the red and near infrared bands. The results showed slight differences between classifiers. Maximum Likelihood algorithm yielded the highest results in pixel-based classifications with an average overall accuracy (OA) of 94.2%. In object-based analyses, Maximum Likelihood and Decision Tree classifiers offered the highest precisions with average OA of 95.3% and 96.6%, respectively. Between pixel- and object-based analyses no clear difference was observed, showing an increase of average OA values of approximately 1% for all classifiers except Decision Tree, which improved up to 4.5%. The alteration of the weight of different bands in the pansharpen process exhibited satisfactory results with a general performance improvement of up to 9% and 11% in pixel- and object-based analyses, respectively. Thus, object-based analyses with the DT algorithm and the pansharpened imagery with the near-infrared band altered would be highly recommended to obtain accurate maps for site-specific management.},
DOI = {10.3390/agronomy8120288}
}



@Article{s18124245,
AUTHOR = {Xu, Yanlei and Gao, Zongmei and Khot, Lav and Meng, Xiaotian and Zhang, Qin},
TITLE = {A Real-Time Weed Mapping and Precision Herbicide Spraying System for Row Crops},
JOURNAL = {Sensors},
VOLUME = {18},
YEAR = {2018},
NUMBER = {12},
ARTICLE-NUMBER = {4245},
URL = {https://www.mdpi.com/1424-8220/18/12/4245},
ISSN = {1424-8220},
ABSTRACT = {This study developed and field tested an automated weed mapping and variable-rate herbicide spraying (VRHS) system for row crops. Weed detection was performed through a machine vision sub-system that used a custom threshold segmentation method, an improved particle swarm optimum (IPSO) algorithm, capable of segmenting the field images. The VRHS system also used a lateral histogram-based algorithm for fast extraction of weed maps. This was the basis for determining real-time herbicide application rates. The central processor of the VRHS system had high logic operation capacity, compared to the conventional controller-based systems. Custom developed monitoring system allowed real-time visualization of the spraying system functionalities. Integrated system performance was then evaluated through field experiments. The IPSO successfully segmented weeds within corn crop at seedling growth stage and reduced segmentation error rates to 0.1% from 7.1% of traditional particle swarm optimization algorithm. IPSO processing speed was 0.026 s/frame. The weed detection to chemical actuation response time of integrated system was 1.562 s. Overall, VRHS system met the real-time data processing and actuation requirements for its use in practical weed management applications.},
DOI = {10.3390/s18124245}
}



@Article{jimaging4120143,
AUTHOR = {Behmann, Jan and Bohnenkamp, David and Paulus, Stefan and Mahlein, Anne-Katrin},
TITLE = {Spatial Referencing of Hyperspectral Images for Tracing of Plant Disease Symptoms},
JOURNAL = {Journal of Imaging},
VOLUME = {4},
YEAR = {2018},
NUMBER = {12},
ARTICLE-NUMBER = {143},
URL = {https://www.mdpi.com/2313-433X/4/12/143},
ISSN = {2313-433X},
ABSTRACT = {The characterization of plant disease symptoms by hyperspectral imaging is often limited by the missing ability to investigate early, still invisible states. Automatically tracing the symptom position on the leaf back in time could be a promising approach to overcome this limitation. Therefore we present a method to spatially reference time series of close range hyperspectral images. Based on reference points, a robust method is presented to derive a suitable transformation model for each observation within a time series experiment. A non-linear 2D polynomial transformation model has been selected to cope with the specific structure and growth processes of wheat leaves. The potential of the method is outlined by an improved labeling procedure for very early symptoms and by extracting spectral characteristics of single symptoms represented by Vegetation Indices over time. The characteristics are extracted for brown rust and septoria tritici blotch on wheat, based on time series observations using a VISNIR (400&ndash;1000 nm) hyperspectral camera.},
DOI = {10.3390/jimaging4120143}
}



@Article{app8122493,
AUTHOR = {Zhang, Ye and Wang, Gang and Li, Mingchao and Han, Shuai},
TITLE = {Automated Classification Analysis of Geological Structures Based on Images Data and Deep Learning Model},
JOURNAL = {Applied Sciences},
VOLUME = {8},
YEAR = {2018},
NUMBER = {12},
ARTICLE-NUMBER = {2493},
URL = {https://www.mdpi.com/2076-3417/8/12/2493},
ISSN = {2076-3417},
ABSTRACT = {It is meaningful to study the geological structures exposed on the Earth&rsquo;s surface, which is paramount to engineering design and construction. In this research, we used 2206 images with 12 labels to identify geological structures based on the Inception-v3 model. Grayscale and color images were adopted in the model. A convolutional neural network (CNN) model was also built in this research. Meanwhile, K nearest neighbors (KNN), artificial neural network (ANN) and extreme gradient boosting (XGBoost) were applied in geological structures classification based on features extracted by the Open Source Computer Vision Library (OpenCV). Finally, the performances of the five methods were compared and the results indicated that KNN, ANN, and XGBoost had a poor performance, with the accuracy of less than 40.0%. CNN was overfitting. The model trained using transfer learning had a significant effect on a small dataset of geological structure images; and the top-1 and top-3 accuracy of the model reached 83.3% and 90.0%, respectively. This shows that texture is the key feature in this research. Transfer learning based on a deep learning model can extract features of small geological structure data effectively, and it is robust in geological structure image classification.},
DOI = {10.3390/app8122493}
}




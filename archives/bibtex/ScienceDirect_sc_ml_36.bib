@article{BARBIERI2017242,
title = {Very short-term photovoltaic power forecasting with cloud modeling: A review},
journal = {Renewable and Sustainable Energy Reviews},
volume = {75},
pages = {242-263},
year = {2017},
issn = {1364-0321},
doi = {https://doi.org/10.1016/j.rser.2016.10.068},
url = {https://www.sciencedirect.com/science/article/pii/S136403211630733X},
author = {Florian Barbieri and Sumedha Rajakaruna and Arindam Ghosh},
keywords = {Photovoltaic, Solar power, Forecasting, Very short term, Nowcasting},
abstract = {This paper endeavors to provide the reader with an overview of the various tools needed to forecast photovoltaic (PV) power within a very short-term horizon. The study focuses on the specific application of a large scale grid-connected PV farm. Solar resource is largely underexploited worldwide whereas it exceeds by far humans’ energy needs. In the current context of global warming, PV energy could potentially play a major role to substitute fossil fuels within the main grid in the future. Indeed, the number of utility-scale PV farms is currently fast increasing globally, with planned capacities in excess of several hundred megawatts. This makes the cost of PV-generated electricity quickly plummet and reach parity with non-renewable resources. However, like many other renewable energy sources, PV power depends highly on weather conditions. This particularity makes PV energy difficult to dispatch unless a properly sized and controlled energy storage system (ESU) is used. An accurate power forecasting method is then required to ensure power continuity but also to manage the ramp rates of the overall power system. In order to perform these actions, the forecasting timeframe also called horizon must be first defined according to the grid operation that is considered. This leads to define both spatial and temporal resolutions. As a second step, an adequate source of input data must be selected. As a third step, the input data must be processed with statistical methods. Finally, the processed data are fed to a precise PV model. It is found that forecasting the irradiance and the cell temperature are the best approaches to forecast precisely swift PV power fluctuations due to the cloud cover. A combination of several sources of input data like satellite and land-based sky imaging also lead to the best results for very-short term forecasting.}
}
@article{SEPULCRE201813,
title = {Context-aware heterogeneous V2X communications for connected vehicles},
journal = {Computer Networks},
volume = {136},
pages = {13-21},
year = {2018},
issn = {1389-1286},
doi = {https://doi.org/10.1016/j.comnet.2018.02.024},
url = {https://www.sciencedirect.com/science/article/pii/S1389128618300975},
author = {Miguel Sepulcre and Javier Gozalvez},
keywords = {Vehicular networks, Cooperative ITS, Connected vehicles, Heterogeneous networks, Hybrid networks, Context-aware, Architecture, Vehicle to infrastructure, V2I, V2X},
abstract = {Connected vehicles will require heterogeneous or hybrid communication technologies to implement the full range of cooperative ITS services in diverse scenarios. This paper presents an architecture for context-aware heterogeneous vehicular networks. The architecture is compatible with the current ETSI and ISO standardized ITS station reference architectures, and allows for the dynamic selection and configuration of communication profiles based on the context conditions and the application requirements. The potential of the proposed architecture is demonstrated with the implementation and evaluation of a heterogeneous V2I communications algorithm that improves the quality of service and the capacity to satisfy the vehicular application requirements, and reduces the economic cost of connected vehicle services.}
}
@article{OCHE201788,
title = {Multivariate statistical approach for estimating QoE of real-time multimedia applications in vehicular ITS network},
journal = {Computer Communications},
volume = {104},
pages = {88-107},
year = {2017},
issn = {0140-3664},
doi = {https://doi.org/10.1016/j.comcom.2016.12.022},
url = {https://www.sciencedirect.com/science/article/pii/S0140366416307411},
author = {Michael Oche and Rafidah Md Noor and Christopher Chembe},
keywords = {IPTV, ITS, Multimedia services, Ordinal logistic regression, Proportional odds model, QoE, QoS, VANETs},
abstract = {Though absolute QoE assessment, requires a subjective approach, performing a subjective test to assess real-time multimedia quality is expensive in terms of time and resources. The process involved in subjective approach is not suited for assessing real-time multimedia services such as IPTV over a dynamic network such as VANETs. Thus, the only practical solution during service operation is to apply an objective quality assessment model, which produces an estimate of the perceived quality. Hence, in this paper, we propose a novel objective QoE prediction model that estimates the QoE of real-time multimedia services over VANETs. Our proposed model is based on a multivariate statistical approach, in conjunction with ordinal regression analysis, that estimates perceived multimedia service quality as a function of aggregated QoE influencing parameters. We assume that each parameter has a different weight depending on the application used. Therefore, to create a standardized QoE model, we develop a correlation model where we estimate the QoE as a weighted sum of the QoE influencing parameters. To validate the effectiveness of our proposed model, Monte Carlo simulation was carried out to investigate the model predicting capabilities. The results attest to be very promising as the proposed model exhibits good predictive ability coherent with the observed data.}
}
@article{FIGUEIRAS2019476,
title = {Novel Big Data-supported dynamic toll charging system: Impact assessment on Portugal’s shadow-toll highways},
journal = {Computers & Industrial Engineering},
volume = {135},
pages = {476-491},
year = {2019},
issn = {0360-8352},
doi = {https://doi.org/10.1016/j.cie.2019.06.043},
url = {https://www.sciencedirect.com/science/article/pii/S0360835219303742},
author = {Paulo Figueiras and Diogo Gonçalves and Ruben Costa and Guilherme Guerreiro and Panos Georgakis and Ricardo Jardim-Gonçalves},
keywords = {Intelligent transportation systems, Big Data, Dynamic toll charging},
abstract = {Traffic congestion is a huge problem in many countries. It affects not only the inner workings of cities but also the quality of life of the people that endure it. In Portugal, traffic congestion happens mainly on national/urban roads, and this phenomenon has increased since the introduction of the so called shadow-toll systems in highways that were free to use. This work proposes a toll charging system that relies on a novel dynamic congestion charging scheme, supported by state of the art Big Data technologies, in order to shift traffic from national/urban roads to tolled highways, taking into account not only the Quality of Service of the highways and national roads, but also the competitiveness of toll prices for users. This Intelligent Transportation System was tested and validated in a real-world scenario with one of the biggest freight logistics companies in Portugal and with the Portuguese public road infrastructure operator.}
}
@article{GUELL20201,
title = {Integrating a cognitive assistant within a critique-based recommender system},
journal = {Cognitive Systems Research},
volume = {64},
pages = {1-14},
year = {2020},
issn = {1389-0417},
doi = {https://doi.org/10.1016/j.cogsys.2020.07.003},
url = {https://www.sciencedirect.com/science/article/pii/S1389041720300449},
author = {Marc Güell and Maria Salamó and David Contreras and Ludovico Boratto},
keywords = {Recommender system, Cognitive assxºistant, Cognitive systems},
abstract = {Recommender systems are cognitive computing systems designed to support humans in their decision-making processes through convincing, timely product suggestions. In the field of recommender systems, critique-based recommenders have been widely applied as an effective approach for guiding users through a product space in pursuit of suitable products. To date, no critique-based approach has included an assistant that support users in their search in a pleasant way. In this paper, we describe how we integrate an assistant within a critique-based recommender. We consider the proposed assistant to be cognitive because its reasoning process when recommending products is based on a cognitively-inspired clustering algorithm. The proposal is evaluated by users and compared with a non-assistant approach. The results of this research demonstrate that the integration of a cognitive assistant within the recommender improves the user experience and increases the performance of the recommendation process, i.e., users need fewer cycles to achieve the desired product or service.}
}
@article{SHAFEEQ2019420,
title = {Privacy aware decentralized access control system},
journal = {Future Generation Computer Systems},
volume = {101},
pages = {420-433},
year = {2019},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2019.06.025},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X18332308},
author = {Sehrish Shafeeq and Masoom Alam and Abid Khan},
keywords = {Blockchain, ABAC, Access control, Tangle, Internet of things, IOTA},
abstract = {IoT security and privacy have proven to be a significant challenge. The traditional access control protocols are not suitable for IoT mainly due to a massive scale, ubiquitous connectivity and distributed nature. Blockchain based access control approaches provide decentralized security but they involve scalability problem, high transaction fees, a significant delay, and computational overhead that is not acceptable for resource-constrained IoT devices. Moreover, data published on the blockchain are public which is not ideal for many scenarios. In this paper, we proposed a new decentralized access control system based on the Tangle which empowers the users to dictate the access to their resource. In our proposed decentralized access control model the policies and access rights are published on the Tangle which guarantees distributed auditability and prevents the user from fraudulently denying the granted access rights. The main contribution of the paper is to provide privacy of the policy by leveraging Masked Authenticated Messaging (MAM) data communication protocol. The proposed work is validated by implementation and is tested with AVISPA tool which confirms security in the presence of the intruder.}
}
@article{FABRA2019413,
title = {Automatic system supporting multicopter swarms with manual guidance},
journal = {Computers & Electrical Engineering},
volume = {74},
pages = {413-428},
year = {2019},
issn = {0045-7906},
doi = {https://doi.org/10.1016/j.compeleceng.2019.01.026},
url = {https://www.sciencedirect.com/science/article/pii/S0045790618323577},
author = {Francisco Fabra and Willian Zamora and Joan Masanet and Carlos T. Calafate and Juan-Carlos Cano and Pietro Manzoni},
keywords = {UAV, Swarm, Multicopter, Flight coordination, ArduSim},
abstract = {Currently, there are some scenarios, such as search and rescue operations,where the deployment of manually guided swarms of UAVs can be necessary. In such cases, the pilot’s commands are unknown a priori (unpredictable), meaning that the UAVs must respond in near real time to the movements of the leader UAV in order to maintain swarm consistency. In this paper we develop a protocol for the coordination of UAVs in a swarm where the swarm leader is controlled by a real pilot, and the other UAVs must follow it in real time to maintain swarm cohesion. We validate our solution using a realistic simulation software that we developed (ArduSim), testing flights with multiple numbers of UAVs and different swarm configurations. Simulation results show the validity of the proposed swarm coordination protocol, detailing the responsiveness limits of our solution, and finding the minimum distances between UAVs to avoid collisions.}
}
@article{VAQUERO201920,
title = {Research challenges in nextgen service orchestration},
journal = {Future Generation Computer Systems},
volume = {90},
pages = {20-38},
year = {2019},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2018.07.039},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X18303157},
author = {Luis M. Vaquero and Felix Cuadrado and Yehia Elkhatib and Jorge Bernal-Bernabe and Satish N. Srirama and Mohamed Faten Zhani},
keywords = {NVM, SDN, NFV, Orchestration, Large scale, Serverless, FaaS, Churn, Edge, Fog},
abstract = {Fog/edge computing, function as a service, and programmable infrastructures, like software-defined networking or network function virtualisation, are becoming ubiquitously used in modern Information Technology infrastructures. These technologies change the characteristics and capabilities of the underlying computational substrate where services run (e.g. higher volatility, scarcer computational power, or programmability). As a consequence, the nature of the services that can be run on them changes too (smaller codebases, more fragmented state, etc.). These changes bring new requirements for service orchestrators, which need to evolve so as to support new scenarios where a close interaction between service and infrastructure becomes essential to deliver a seamless user experience. Here, we present the challenges brought forward by this new breed of technologies and where current orchestration techniques stand with regards to the new challenges. We also present a set of promising technologies that can help tame this brave new world.}
}
@article{BALADO2017103,
title = {Automatic building accessibility diagnosis from point clouds},
journal = {Automation in Construction},
volume = {82},
pages = {103-111},
year = {2017},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2017.06.026},
url = {https://www.sciencedirect.com/science/article/pii/S0926580517302029},
author = {J. Balado and L. Díaz-Vilariño and P. Arias and M. Soilán},
keywords = {Building accessibility, Building information modelling, Indoor-outdoor seamless, 3D data processing, Obstacle detection, Point clouds, Mobile Laser Scanning, 3D urban as-built},
abstract = {Building accessibility diagnosis is of high interest especially in case of people with reduced mobility. This paper proposes a methodology for automated detection of inaccessible steps in building façade entrances from MLS (mobile laser scanner) data. Our approach uses the MLS trajectory to automatically subdivide urban point clouds into regular stretches. From each stretch, the lower zone of façade is isolated and selected as region of interest. Points belonging to vertical elements are projected onto a 2D image and steps are detected and classified as inaccessible areas according to the comparison of geometrical features such as height jump, proximity to ground and width, with regulation. The methodology has been tested in four real datasets, which constitute >400m of different urban scenarios. Results exhibit a robust performance under urban scenes with a high variability of façade geometry due to the presence of different entrance types to shops and dwellings. Results have been quantitatively evaluated and they show global F1 value around 93%. Moreover, the methodology is very fast since 100m are processed in <2min.}
}
@article{TRAORE2021886,
title = {Unifying Digital Twin Framework: Simulation-Based Proof-of-Concept},
journal = {IFAC-PapersOnLine},
volume = {54},
number = {1},
pages = {886-893},
year = {2021},
note = {17th IFAC Symposium on Information Control Problems in Manufacturing INCOM 2021},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2021.08.105},
url = {https://www.sciencedirect.com/science/article/pii/S2405896321008545},
author = {Mamadou K. Traoré},
keywords = {Digital Twin, Simulation, Framework, Anylogic},
abstract = {In recent years, the Digital Twin (DT) concept has surfaced in many areas and landed the approach in top strategic technology trends. However, there seems to be no unique understanding of the concept, and debates about what is a DT are leading to ambiguity on the concrete solution to be developed in a given situation. This paper introduces a unifying reference framework, to both serve as a conceptual basis that disambiguates the concept and a guide to derive custom solutions. It is a technology-agnostic three-layered model, which reconciles existing understandings of DT under a common umbrella. We also derive an operational architecture as a possible implementation of the framework, which we demonstrate on two use cases. The large adoption of such a framework will draw a clear line between what is a DT and what is not, while establishing a high-level standard model for DT engineering.}
}
@article{LANGONE2015268,
title = {LS-SVM based spectral clustering and regression for predicting maintenance of industrial machines},
journal = {Engineering Applications of Artificial Intelligence},
volume = {37},
pages = {268-278},
year = {2015},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2014.09.008},
url = {https://www.sciencedirect.com/science/article/pii/S095219761400222X},
author = {Rocco Langone and Carlos Alzate and Bart {De Ketelaere} and Jonas Vlasselaer and Wannes Meert and Johan A.K. Suykens},
keywords = {Kernel spectral clustering, LS-SVMs, Time-series prediction, Fault detection, Machine degradation, Artificial intelligence},
abstract = {Accurate prediction of forthcoming faults in modern industrial machines plays a key role in reducing production arrest, increasing the safety of plant operations, and optimizing manufacturing costs. The most effective condition monitoring techniques are based on the analysis of historical process data. In this paper we show how Least Squares Support Vector Machines (LS-SVMs) can be used effectively for early fault detection in an online fashion. Although LS-SVMs are existing artificial intelligence methods, in this paper the novelty is represented by their successful application to a complex industrial use case, where other approaches are commonly used in practice. In particular, in the first part we present an unsupervised approach that uses Kernel Spectral Clustering (KSC) on the sensor data coming from a vertical form seal and fill (VFFS) machine, in order to distinguish between normal operating condition and abnormal situations. Basically, we describe how KSC is able to detect in advance the need of maintenance actions in the analysed machine, due the degradation of the sealing jaws. In the second part we illustrate a nonlinear auto-regressive (NAR) model, thus a supervised learning technique, in the LS-SVM framework. We show that we succeed in modelling appropriately the degradation process affecting the machine, and we are capable to accurately predict the evolution of dirt accumulation in the sealing jaws.}
}
@article{WANG2019435,
title = {Modular exponential multivariate sequence and its application to lightweight security design},
journal = {Future Generation Computer Systems},
volume = {98},
pages = {435-443},
year = {2019},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2019.03.040},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X18315401},
author = {Jia Wang and Houbing Song and Jianqiang Li and Qiuzhen Lin and Lee-Ming Cheng},
keywords = {Economic lightweight security, Multivariate cryptography, Public key cryptography, Superfluous keys},
abstract = {How to design an economic lightweight security scheme is emerging as a challenging issue since a larger number of private and confidential datum are generated every day in this big data era. As presented in this paper, dynamic systems generated using multivariate sequences constructed from residual rings of matrices have been proven to admit good randomness and non-singularity which can be used to solve the equivalent keys and factorization problems found in Multivariate Quadratic asymmetric systems. These properties are useful for constructing a practical economic cryptographic system for constraint devices and provide a potential balanced solution between cost and security.}
}
@article{TORKAYESH2021103243,
title = {A mulTi-noRmalization mUlti-distance aSsessmenT (TRUST) approach for locating a battery swapping station for electric scooters},
journal = {Sustainable Cities and Society},
volume = {74},
pages = {103243},
year = {2021},
issn = {2210-6707},
doi = {https://doi.org/10.1016/j.scs.2021.103243},
url = {https://www.sciencedirect.com/science/article/pii/S2210670721005205},
author = {Ali Ebadi Torkayesh and Muhammet Deveci},
keywords = {Multi-criteria decision-making, Multi-normalization, Distance measures, Constrained attributes, Electric scooters},
abstract = {Due to high popularity of electric scooters, cities with high population have faced challenges regarding establishment of battery swapping stations (BSS) along populated areas of the urban districts. However, locating a BSS in a big city is a multi-dimensional problem which require reliable tools to efficiently address. This paper proposes a novel robust decision-making tool, named mulTi-noRmalization mUlti-distance aSsessmenT (TRUST), to tackle location selection problem for BSS considering sustainability criteria. The proposed approach applies a multi-normalization procedure using three linear normalization techniques, logarithmic-normalization, and constraint-based normalization which are integrated through an aggregation operator. Then, Euclidean, Manhattan, Lorentzian, and Pearson distance measures are used to determine distance of alternatives from the negative ideal solution in order to calculate the final score. Advantages of the proposed approach are consideration of a multi-normalization algorithm to minimize subjectivity in normalized data, consideration of constraint-based normalization technique to ensure specific standards, and utilization of four distance measures through a two-stage process to determine a relative distance score. To show the feasibility and applicability of the new approach, a real-life case study is investigated to locate a BSS in Istanbul. Results show that the best alternative is Beyoğlu for locating a BSS for electric scooters.}
}
@article{BUTTURI2019113825,
title = {Renewable energy in eco-industrial parks and urban-industrial symbiosis: A literature review and a conceptual synthesis},
journal = {Applied Energy},
volume = {255},
pages = {113825},
year = {2019},
issn = {0306-2619},
doi = {https://doi.org/10.1016/j.apenergy.2019.113825},
url = {https://www.sciencedirect.com/science/article/pii/S0306261919315120},
author = {M.A. Butturi and F. Lolli and M.A. Sellitto and E. Balugani and R. Gamberini and B. Rimini},
keywords = {Carbon emissions reduction, Renewable energy sources, Industrial symbiosis, Eco-industrial parks, Industrial energy symbiosis, Urban-industrial energy symbiosis},
abstract = {Replacing fossil fuels with renewable energy sources is considered as an effective means to reduce carbon emissions at the industrial level and it is often supported by local authorities. However, individual firms still encounter technical and financial barriers that hinder the installation of renewables. The eco-industrial park approach aims to create synergies among firms thereby enabling them to share and efficiently use natural and economic resources. It also provides a suitable model to encourage the use of renewable energy sources in the industry sector. Synergies among eco-industrial parks and the adjacent urban areas can lead to the development of optimized energy production plants, so that the excess energy is available to cover some of the energy demands of nearby towns. This study thus provides an overview of the scientific literature on energy synergies within eco-industrial parks, which facilitate the uptake of renewable energy sources at the industrial level, potentially creating urban-industrial energy symbiosis. The literature analysis was conducted by arranging the energy-related content into thematic categories, aimed at exploring energy symbiosis options within eco-industrial parks. It focuses on the urban-industrial energy symbiosis solutions, in terms of design and optimization models, technologies used and organizational strategies. The study highlights four main pathways to implement energy synergies, and demonstrates viable solutions to improve renewable energy sources uptake at the industrial level. A number of research gaps are also identified, revealing that the energy symbiosis networks between industrial and urban areas integrating renewable energy systems, are under-investigated.}
}
@article{CAO201752,
title = {Approximate Cardinality Estimation (ACE) in large-scale Internet of Things deployments},
journal = {Ad Hoc Networks},
volume = {66},
pages = {52-63},
year = {2017},
issn = {1570-8705},
doi = {https://doi.org/10.1016/j.adhoc.2017.08.009},
url = {https://www.sciencedirect.com/science/article/pii/S1570870517301592},
author = {Qing Cao and Yunhe Feng and Zheng Lu and Hairong Qi and Leon M. Tolbert and Lipeng Wan and Zhibo Wang and Wenjun Zhou},
keywords = {Cardinality, Estimation, Query},
abstract = {IoT (Internet of Things) deployments have been used in many diverse applications in increasingly large numbers, usually composed of embedded sensors, computational units, and actuators. One central problem with IoT applications is that we frequently need to query the number of nodes according to certain requirements, or filters. For example, a user may want to query the number of nodes that are currently actively sensing data, or having data above a threshold. Conventional methods typically require each active node to report their status, leading to a total communication overhead that is at least proportional to the network size. In this paper, we study the problem of deployment size estimation by investigating probabilistic methods for processing queries, where we only try to obtain approximate estimates within desired confidence intervals. Our methods are different with other probabilistic methods, such as sampling, in that our approach is based on the well-known birthday paradox in statistics. Hence, our methods provide a different solution that can be combined or used to enhance existing methods. We demonstrate through extensive simulations that their overhead is considerably lower than conventional methods, usually by an order of magnitude.}
}
@article{ALBADI2018271,
title = {Exploring Big Data Governance Frameworks},
journal = {Procedia Computer Science},
volume = {141},
pages = {271-277},
year = {2018},
note = {The 9th International Conference on Emerging Ubiquitous Systems and Pervasive Networks (EUSPN-2018) / The 8th International Conference on Current and Future Trends of Information and Communication Technologies in Healthcare (ICTH-2018) / Affiliated Workshops},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2018.10.181},
url = {https://www.sciencedirect.com/science/article/pii/S1877050918318313},
author = {Ali Al-Badi and Ali Tarhini and Asharul Islam Khan},
keywords = {Big Data, Big Data model, Big Data governance, Data management, Big Data governance framework, Big Data analytic},
abstract = {The recent explosion in ICT and digital data has led organizations, both private and public, to efficient decision-making. Nowadays organizations can store huge amounts of data, which can be accessible at any time. Big Data governance refers to the management of huge volumes of an organization’s data, exploiting it in the organization’s decision-making using different analytical tools. Big Data emergence provides great convenience, but it also brings challenges. Nevertheless, for Big Data governance, data has to be prepared in a timely manner, keeping in view the consistency and reliability of the data, and being able to trust its source and the meaningfulness of the result. Hence, a framework for Big Data governance would have many advantages. There are Big Data governance frameworks, which guide the management of Big Data. However, there are also limitations associated with these frameworks. Therefore, this study aims to explore the existing Big Data governance frameworks and their shortcomings, and propose a new framework. The proposed framework consists of eight components. As a framework validation, the proposed framework has been compared with the ISO 8000 data governance framework.}
}
@article{QYYUM2022115055,
title = {Assessment of working fluids, thermal resources and cooling utilities for Organic Rankine Cycles: State-of-the-art comparison, challenges, commercial status, and future prospects},
journal = {Energy Conversion and Management},
volume = {252},
pages = {115055},
year = {2022},
issn = {0196-8904},
doi = {https://doi.org/10.1016/j.enconman.2021.115055},
url = {https://www.sciencedirect.com/science/article/pii/S0196890421012310},
author = {Muhammad Abdul Qyyum and Amjad Khan and Sajid Ali and Muhammad Shahzad Khurram and Ning Mao and Ahmad Naquash and Adnan Aslam Noon and Tianbiao He and Moonyong Lee},
keywords = {Organic Rankine cycle, Working fluid selection, Power generation, Renewable energy, Sustainable development, ORC commercialization},
abstract = {This paper presents state-of-the-art review on organic Rankine cycle (ORC) by assessing the working fluids, thermal resources, cooling utilities, and commercial status with future aspects. It is found that the mixture working fluids achieve higher thermodynamic efficiency. However, the difficulty in obtaining the optimum composition and components limits their applications. The thermal resources with different temperature ranges and cooling utilities are then assessed to investigate their effects on the thermodynamic performance of ORC. The low-temperature ORC utilizing waste heat and geothermal heat is dominant, while biomass and solar energy are still rarely adopted as ORC’s heat resources. From the commercial perspective, the USA and Europe are the leaders in conversion of low-grade waste heat into useful power using ORC. Furthermore, the main challenges of ORC are: (a) selection of appropriate working fluid with suitable expander, and (b) reducing the specific cost of the small-scale ORC system to compete with the renewable energy. Finally, several future research directions are identified such as: (1) overall performance of the ORC system including its thermodynamic efficiency, stability and safety needs to be investigated with experimental studies; (2) a general methodology should be developed for the selection of working fluids; (3) studies for reducing the net present cost and levelized cost of electricity with techno-economic optimization are needed to be carried out. This study benchmarks the recent progress on ORC technology and presents an insight into the scientific problems that need to be explored to nexus low-grade heat to power in the future.}
}
@article{BAGOZI201951,
title = {A Relevance-based approach for Big Data Exploration},
journal = {Future Generation Computer Systems},
volume = {101},
pages = {51-69},
year = {2019},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2019.05.056},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X18320867},
author = {Ada Bagozi and Devis Bianchini and Valeria {De Antonellis} and Massimiliano Garda and Alessandro Marini},
keywords = {Data exploration, Big data, Multi-dimensional data modelling, Human-In-the-Loop Data Analysis, Industry 4.0, Cyber Physical Systems},
abstract = {The collection, organisation and analysis of large amount of data (Big Data) in different application domains still require the involvement of experts for the identification of relevant data only, without being overwhelmed by volume, velocity and variety of collected data. According to the “Human-In-the-Loop Data Analysis” vision, experts explore data to take decisions in unexpected situations, based on their long-term experience. In this paper, the IDEAaS (Interactive Data Exploration As-a-Service) approach is presented, apt to enable Big Data Exploration (BDE) according to data relevance. In the approach, novel techniques have been developed: (i) an incremental clustering algorithm, to provide summarised representation of collected data streams; (ii) multi-dimensional organisation of summarised data, for data exploration according to different analysis dimensions; (iii) data relevance evaluation techniques, to attract the experts’ attention on relevant data only during exploration. The approach has been experimented to apply BDE for state detection in the Industry 4.0 domain, given the strategic importance of Big Data management as enabling technology in this field. In particular, a stream of numeric features is collected from a Cyber Physical System and is explored to monitor the system health status, supporting the identification of unknown anomalous conditions. Results of an extensive experimentation in the Industry 4.0 domain are presented in the paper and demonstrated the effectiveness of developed techniques to attract the attention of experts on relevant data, also beyond the considered domain, in presence of disruptive characteristics of Big Data, namely volume (millions of collected records), velocity (measured in milliseconds) and variety (number and heterogeneity of analysis dimensions).}
}
@article{TRUJILLOTOLEDO2021111506,
title = {Real-time RGB image encryption for IoT applications using enhanced sequences from chaotic maps},
journal = {Chaos, Solitons & Fractals},
volume = {153},
pages = {111506},
year = {2021},
issn = {0960-0779},
doi = {https://doi.org/10.1016/j.chaos.2021.111506},
url = {https://www.sciencedirect.com/science/article/pii/S0960077921008602},
author = {D.A. Trujillo-Toledo and O.R. López-Bonilla and E.E. García-Guerrero and E. Tlelo-Cuautle and D. López-Mancilla and O. Guillén-Fernández and E. Inzunza-González},
keywords = {Chaotic map, Image encryption, PRNG, IoT, MQTT, M2M},
abstract = {Four chaotic maps are used herein as case study to design an embedded cryptosystem based on a pseudo-random number generator (PRNG). The randomness of the sequences is enhanced by applying the mod 1023 function and verified by analyzing bifurcation diagrams, the maximum Lyapunov exponent, and performing NIST SP 800-22 and TestU01 statistical tests. The PRNG is applied in a simple algorithm for real-time RGB images encryption on a machine-to-machine (M2M) scheme, using message queuing telemetry transport (MQTT) protocol over WiFi network and through Internet. The cryptanalysis confirms that the proposed image encryption scheme is robust to resist most of the existing attacks, such as statistical histograms, entropy, key-space, correlation of adjacent pixels, and differential attacks. The implementation of the proposed cryptosystem is done using enhanced sequences from the Logistic 1D map, and it reaches a throughput of up to 47.44 Mbit/s using a personal computer with a 2.9 GHz clock, and 10.53 Mbit/s using a Raspberry Pi 4. As a result, our proposed embedded cryptosystem is suitable to increase the security in the transmission of RGB images in real-time through WiFi networks and Internet.}
}
@article{LUO202042,
title = {Delivery Route Optimization with automated vehicle in smart urban environment},
journal = {Theoretical Computer Science},
volume = {836},
pages = {42-52},
year = {2020},
issn = {0304-3975},
doi = {https://doi.org/10.1016/j.tcs.2020.05.050},
url = {https://www.sciencedirect.com/science/article/pii/S0304397520303376},
author = {Chuanwen Luo and Deying Li and Xingjian Ding and Weili Wu},
keywords = {Smart urban, Automated vehicle, Path planning, Approximation algorithm, Delivery Route Optimization},
abstract = {As a part of the smart urban construction, automated driving is introduced to improve the utilization efficiency of cars and roads, which not only reduces the incidence of traffic accidents, but also improves the environment quality. With the development of the smart urban, it is predictable that, in the city of the future, the service of package pickup and delivery or takeout will be supported mainly by automated vehicles. However, the existing works mainly focus on the variants of the Vehicle Routing Problem (VRP), in which they either take no account of service time of automated vehicle for customers when the automated vehicle arrives at the locations of customers or ignore the impact of rewards gained from customers on path planning of the automated vehicles. In this paper, we also extend a variant of VRP where an automated vehicle is used to package delivery or distribution of food in the smart urban environment, which is called the Delivery Reward Maximization (DRM) problem. The problem aims at designing a route of the automated vehicle while considering the service time for customers before their deadlines and the impact of rewards of the automated vehicle on path planning. We first prove that the DRM problem is NP-hard. Then we study two special cases of the DRM problem, which are called Linear DRM (LDRM) problem and Two-dimensional DRM (TDRM) problem, respectively. In the LDRM and TDRM problems, all customers have the same visiting deadlines and are deployed on the one-dimensional line and two-dimensional plane, respectively. Then we prove that the LDRM and TDRM problems are also NP-hard and propose a constant approximation algorithm for each of them. Afterward, we propose a greedy algorithm to solve the DRM problem, and give the analysis by counterexample.}
}
@article{XIAO2018115,
title = {Conceptual space based model fitting for multi-structure data},
journal = {Neurocomputing},
volume = {315},
pages = {115-127},
year = {2018},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2018.07.001},
url = {https://www.sciencedirect.com/science/article/pii/S0925231218308270},
author = {Guobao Xiao and Xing Wang and Hailing Luo and Jin Zheng and Bo Li and Yan Yan and Hanzi Wang},
keywords = {Model fitting, Conceptual space, Outlier removal, Model selection},
abstract = {In this paper, we propose a novel fitting method, called the Conceptual Space based Model Fitting (CSMF), to fit and segment multi-structure data contaminated with a large number of outliers. CSMF includes two main parts: an outlier removal algorithm and a model selection algorithm. Specifically, we firstly construct a novel conceptual space to measure data points by only considering the good model hypotheses. Then we analyze the conceptual space to effectively remove the gross outliers. Based on the results of outlier removal, we propose to search center points (representing the estimated model instances) in the conceptual space for model selection. CSMF is able to efficiently and effectively remove gross outliers in data, and simultaneously estimate the number and the parameters of model instances without using prior information. Experimental results on both synthetic data and real images demonstrate the advantages of the proposed method over several state-of-the-art fitting methods.}
}
@article{YAPA20216530,
title = {Survey on blockchain for future smart grids: Technical aspects, applications, integration challenges and future research},
journal = {Energy Reports},
volume = {7},
pages = {6530-6564},
year = {2021},
issn = {2352-4847},
doi = {https://doi.org/10.1016/j.egyr.2021.09.112},
url = {https://www.sciencedirect.com/science/article/pii/S2352484721009185},
author = {Charithri Yapa and Chamitha {de Alwis} and Madhusanka Liyanage and Janaka Ekanayake},
keywords = {Smart Grid 2.0, Distribute Energy Resources, Blockchains, Integration challenges, Security, Scalability, De-centralization},
abstract = {Smart Grid 2.0 is envisaged to automate the operations of the intelligent electricity grid. Blockchain and smart contracts are integrated to facilitate the transformation from DSO-centric operations to consumer-oriented, distributed electricity grid management. The envisaged smart grids, integrated with blockchain would provoke challenges, which would hinder the maximum utilization of Distribute Energy Resources (DERs). This comprehensive review aims at analyzing the applicability of blockchain technology in Smart Grid 2.0, which would facilitate a seamless decentralization process. Further, the paper elaborates the blockchain-based applications of future smart grid operations and the role of blockchain in each scenario. The paper further provides a concise analysis on the blockchain integration challenges, thereby ensure secure and scalable, decentralized operations of future, autonomous electricity networks.}
}
@article{ZHOU20201141,
title = {Topic-based crossing-workflow fragment discovery},
journal = {Future Generation Computer Systems},
volume = {112},
pages = {1141-1155},
year = {2020},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2020.05.029},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X20301084},
author = {Zhangbing Zhou and Jinfeng Wen and Yasha Wang and Xiao Xue and Patrick C.K. Hung and Long D. Nguyen},
keywords = {Crossing-workflow fragments, Activity knowledge graph, Topic discovery, Scientific workflows},
abstract = {Along with the large and increasing number of scientific workflows publicly accessible on Web repositories, the discovery of workflow fragments is significant to promote the reuse or repurposing of best-practices evidenced in legacy workflows, when novel scientific experiments are to be conducted. This paper proposes a novel crossing-workflow fragment discovery mechanism, where an activity knowledge graph is constructed to capture flat invocation relations between activities, and hierarchical parent–child relations specified upon sub-workflows and their corresponding activities. Semantic relevance of activities and sub-workflows is calculated based on their representative topics, where these topics are generated by applying the biterm topic model. Given a requirement specified in terms of a workflow fragment template, individual candidate activities or sub-workflows are discovered when considering their semantic relevance and short-document descriptions. Candidate fragments are constructed through discovering the relations in activity knowledge graph specified upon candidate activities or sub-workflows. These fragments are evaluated by balancing their structural and semantic similarities. Evaluation results show that our approach is accurate in discovering appropriate crossing-workflow fragments in comparison with the state of art’s techniques.}
}
@article{ZHANG2021109849,
title = {Battery internal temperature estimation via a semilinear thermal PDE model},
journal = {Automatica},
volume = {133},
pages = {109849},
year = {2021},
issn = {0005-1098},
doi = {https://doi.org/10.1016/j.automatica.2021.109849},
url = {https://www.sciencedirect.com/science/article/pii/S0005109821003691},
author = {Dong Zhang and Satadru Dey and Shu-Xia Tang and Ross Drummond and Scott J. Moura},
keywords = {Lithium-ion batteries, Battery temperature estimation, Infinite dimensional systems, PDE backstepping, Robust observer},
abstract = {Accurate Lithium-ion (Li-ion) battery internal temperature information enables high-fidelity monitoring and safe operation in battery management systems, thus prevents thermal faults that could cause catastrophic failures. This paper proposes an online temperature estimation scheme for cylindrical Li-ion batteries based on a one-dimensional semilinear parabolic partial differential equation (PDE) model subject to in-domain and output uncertainties, using temperature measurements at the battery surface only. The thermal state observer design exploits PDE backstepping method, with a mild assumption on the Lipschitz continuity of the nonlinear heat generation rate. A sufficient condition on the Lipschitz constant to achieve exponential convergence is derived. Furthermore, when the thermal system uncertainties are present, an analytic bound on the temperature estimation error is formulated in the sense of spatial L2 norm, in terms of Lipschitz constant, design parameters, and bounds on system uncertainties. Simulation studies on various practical current profiles are demonstrated to illustrate the effectiveness of the proposed thermal estimation framework on a commercial cylindrical Li-ion battery cell.}
}
@article{JIANG2021,
title = {Green UAV communications for 6G: A survey},
journal = {Chinese Journal of Aeronautics},
year = {2021},
issn = {1000-9361},
doi = {https://doi.org/10.1016/j.cja.2021.04.025},
url = {https://www.sciencedirect.com/science/article/pii/S1000936121001801},
author = {Xu Jiang and Min Sheng and Nan Zhao and Chengwen Xing and Weidang Lu and Xianbin Wang},
keywords = {Energy efficiency, Green communications, Sixth Generation (6G) networks, Unmanned Aerial Vehicle (UAV), Wireless networks},
abstract = {Unmanned Aerial Vehicles (UAVs) have received a wide range of attention for military and commercial applications. Enhanced with communication capability, UAVs are considered to play important roles in the Sixth Generation (6G) networks due to their low cost and flexible deployment. 6G is supposed to be an all-coverage network to provide ubiquitous connections for space, air, ground and underwater. UAVs are able to provide air-borne wireless coverage flexibly, serving as aerial base stations for ground users, as relays to connect isolated nodes, or as mobile users in cellular networks. However, the onboard energy of small UAVs is extremely limited. Thus, UAVs can be only deployed to establish wireless links temporarily. Prolonging the lifetime and developing green UAV communication with low power consumption becomes a critical challenge. In this article, a comprehensive survey on green UAV communications for 6G is carried out. Specifically, the typical UAVs and their energy consumption models are introduced. Then, the typical trends of green UAV communications are provided. In addition, the typical applications of UAVs and their green designs are discussed. Finally, several promising techniques and open research issues are also pointed out.}
}
@article{TORRES201717,
title = {TBDClust: Time-based density clustering to enable free browsing of sites in pay-per-use mobile Internet providers},
journal = {Journal of Network and Computer Applications},
volume = {99},
pages = {17-27},
year = {2017},
issn = {1084-8045},
doi = {https://doi.org/10.1016/j.jnca.2017.10.007},
url = {https://www.sciencedirect.com/science/article/pii/S1084804517303193},
author = {Luis Miguel Torres and Eduardo Magaña and Daniel Morató and Santiago Garcia-Jimenez and Mikel Izal},
keywords = {Clustering TCP connections, Time-based density clustering, DBSCAN, Mobile web browsing, Online monitoring, Real traffic dataset},
abstract = {The World Wide Web has evolved rapidly, incorporating new content types and becoming more dynamic. The contents from a website can be distributed between several servers, and as a consequence, web traffic has become increasingly complex. From a network traffic perspective, it can be difficult to ascertain which websites are being visited by a user, let alone which part of the user's traffic each website is responsible for. In this paper we present a method for identifying the TCP connections involved in the same full webpage download without the need of deep packet inspection. This identification is needed for example to enable free browsing of specific websites in a pay per use mobile Internet access. It could be not only for third party promoted websites but also portals to gubernamental or medical emergency websites. The proposal is based on a modification of the DBSCAN clustering algorithm to work online and over one-dimensional sorted data. In order to validate our results we use both real traffic and packet captures from a controlled environment. The proposal achieves excellent results in consistency (99%) and completeness (92%), meaning that its error margin identifying the webpage downloads is minimal.}
}
@article{THOMSON202150,
title = {Towards an energy balancing solution for wireless sensor network with mobile sink node},
journal = {Computer Communications},
volume = {170},
pages = {50-64},
year = {2021},
issn = {0140-3664},
doi = {https://doi.org/10.1016/j.comcom.2021.01.011},
url = {https://www.sciencedirect.com/science/article/pii/S0140366421000323},
author = {Craig Thomson and Isam Wadhaj and Zhiyuan Tan and Ahmed Al-Dubai},
keywords = {Wireless sensor networks, Sink mobility, Energy holes, Balanced energy, Duty cycle},
abstract = {The issue of energy holes, or hotspots, in wireless sensor networks is well referenced. As is the proposed mobilisation of the sink node in order to combat this. However, as the mobile sink node may communicate with some nodes more than others, issues remain, such as energy spikes. In this study we propose a lightweight MAC layer solution — Dynamic Mobility and Energy Aware Algorithm (DMEAAL). Building on existing solutions utilising a communication threshold between static nodes and a sink node using a predictable mobility pattern, DMEAAL takes knowledge of optimum energy consumption levels and implements a cross-layer approach, utilising current energy consumption and dynamically adjusting communication threshold size based on target energy consumption. This approach is shown to balance energy consumption across individual nodes without increasing overall energy consumption compared to previous solutions. This without detrimentally affecting frame delivery to the sink. As such, network lifetime is improved. In addition we propose Mobile Edge Computing (MEC) applications for this solution, removing certain functionality from static nodes and instead deploying this within the mobile sink at the network edge.}
}
@article{KAKLAUSKAS2019346,
title = {Affective analytics of demonstration sites},
journal = {Engineering Applications of Artificial Intelligence},
volume = {81},
pages = {346-372},
year = {2019},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2019.03.001},
url = {https://www.sciencedirect.com/science/article/pii/S0952197619300442},
author = {A. Kaklauskas and D. Jokubauskas and J. Cerkauskas and G. Dzemyda and I. Ubarte and D. Skirmantas and A. Podviezko and I. Simkute},
keywords = {Intelligent decision support system, Crowd, Biometrics, Neuro decision matrix, Public spaces, Demonstration sites},
abstract = {Multiple-criteria decision-making (MCDM) typically assumes that crowds make completely rational decisions. In MCDM, a crowd as a whole, or its individual members, generally make decisions free from any influence of valence, arousal, emotional state or environment. In contrast, various theories dealing with crowd psychology (Gustave Le Bon, Freudian, Deindividuation, Convergence, Emergent norm, Social identity) analyze, in one form or another, the emotions of the crowd. According to above theories, crowd is influenced by a range of behavioral factors, such as physical, social, psychological, culture, norms, and emotions. It can be argued that the emotional state, valence and arousal of crowds affect their decision making to a considerable degree and multiple criteria crowd behavior modeling must, therefore, consider this impact as well. In this light, the integration of crowd simulation and biometric methods, behavioral operations research and emotions in decision making has taken a prominent place as it leads to a better understanding of crowd emotions and crowd decision making. In this context, the authors developed the Affective Analytics of Demonstration Sites (ANDES) that added to this body of research in four ways. The crowd analysis and simulations conducted with ANDES used a neuro decision matrix. The matrix contains a detailed description of demonstration sites (public spaces) in question and the emotions, valence, arousal and physiological parameters of people present there. With ANDES’s Remote Sensor Network, emotional (emotions, valence, arousal) and physiological (average crowd facial temperature, crowd composition by gender and age group, etc.) parameters of people present at demonstration sites can be mapped. ANDES can assist experts in more effective implementations of public spaces planning and a participation process by attendees by collecting and examining various layers of data on the emotional and physiological parameters of visitors based on a visitors-centric public spaces planning approach. ANDES can determine the public space and real estate values.}
}
@article{DHOU20211,
title = {A highly efficient chain code for compression using an agent-based modeling simulation of territories in biological beavers},
journal = {Future Generation Computer Systems},
volume = {118},
pages = {1-13},
year = {2021},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2020.12.016},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X20330788},
author = {Khaldoon Dhou and Christopher Cruzen},
keywords = {Beavers, Compression, Beaver territories, Bi-level image, Chain code, Agent-based model},
abstract = {The accelerated developments in technology led to a tremendous increase in the volumes of data to be transferred and exchanged between various network channels. These advancements create a huge demand for researchers to investigate new data compression techniques. Recent evidence from the literature shows that agent-based modeling is a promising direction to reduce the size of the data and change its original representation. In this article, the objective is to build an agent-based modeling simulation for chain coding and take advantage of it in data compression. Our agent-based model is inspired by the concept of defended territories of biological beavers. To this end, we use the pixel distribution in a bi-level image to construct a virtual environment of agents, add the beavers, and build territories around them. The main idea of defended beaver territories is to allow each beaver to maintain its area and protects it from intruders. To put it another way, defended territories allow beavers to work on different parts of an image while the algorithm tracks and records their movements, as well as manages disputes between them. Our research findings represent a further step towards employing the generated codes of movements in image processing operations other than coding and compression. Additionally, the experimental results showed that the current model was prosperous, and it could outperform many existing image compression techniques, including JBIG family methods. What’s more, paired-samples t-tests reveal that the mean differences between the outcomes of the current approach and each of the other standardized benchmarks we employed in comparison are statistically significant.}
}
@article{WANG2017452,
title = {Particle swarm optimization based clustering algorithm with mobile sink for WSNs},
journal = {Future Generation Computer Systems},
volume = {76},
pages = {452-457},
year = {2017},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2016.08.004},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X16302540},
author = {Jin Wang and Yiquan Cao and Bin Li and Hye-jin Kim and Sungyoung Lee},
keywords = {Sink mobility, Particle swarm optimization, Energy consumption, Wireless sensor network},
abstract = {Wireless sensor networks with fixed sink node often suffer from hot spots problem since sensor nodes close to the sink usually have more traffic burden to forward during transmission process. Utilizing mobile sink has been shown as an effective technique to enhance the network performance such as energy efficiency, network lifetime, and latency, etc. In this paper, we propose a particle swarm optimization based clustering algorithm with mobile sink for wireless sensor network. In this algorithm, the virtual clustering technique is performed during routing process which makes use of the particle swarm optimization algorithm. The residual energy and position of the nodes are the primary parameters to select cluster head. The control strategy for mobile sink to collect data from cluster head is well designed. Extensive simulation results show that the energy consumption is much reduced, the network lifetime is prolonged, and the transmission delay is reduced in our proposed routing algorithm than some other popular routing algorithms.}
}
@article{KOTIAN201794,
title = {Impact of Transmission Power Control in multi-hop networks},
journal = {Future Generation Computer Systems},
volume = {75},
pages = {94-107},
year = {2017},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2016.10.010},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X16303910},
author = {R. Kotian and G. Exarchakos and S. Stavros and A. Liotta},
keywords = {Internet-of-Things, Transmission Power Control, Routing protocol, MAC protocol, Energy efficiency},
abstract = {Many Transmission Power Control (TPC) algorithms have been proposed in the past, yet the conditions under which they are evaluated do not always reflect typical Internet-of-Things (IoT) scenarios. IoT networks consist of several source nodes transmitting data simultaneously, possibly along multiple hops. Link failures are highly frequent, causing the TPC algorithm to kick-in quite often. To this end, in this paper we study the impact that frequent TPC actions have across different layers. Our study shows how one node’s decision to scale its transmission power can affect the performance of both routing and MAC layers of multiple other nodes in the network, generating cascading packet retransmissions and forcing far too many nodes to consume more energy. We find that crucial objectives of TPC such as conserving energy and increasing network capacity are severely undermined in multi-hop networks.}
}
@article{WANG2021101638,
title = {Will researching digital technology really empower green development?},
journal = {Technology in Society},
volume = {66},
pages = {101638},
year = {2021},
issn = {0160-791X},
doi = {https://doi.org/10.1016/j.techsoc.2021.101638},
url = {https://www.sciencedirect.com/science/article/pii/S0160791X21001135},
author = {Lei Wang and Yangyang Chen and Thomas Stephen Ramsey and Geoffrey J.D. Hewings},
keywords = {Digital technology, Technology spillover, Carbon emission intensity},
abstract = {The information industry has become a “new engine” driving the growth of the world economy. However, there are many controversies about whether digital technology can reduce the intensity of carbon emissions. Based on OECD data, KPWW method and multiple panel regression, this paper explores the impact and mechanism of digital technology innovation and technology spillover to the domestic carbon emission intensity. Through impulse response analysis and variance decomposition, the comprehensive impact of digital technology on carbon intensity is clarified. This paper concludes that technology innovation in the information industry will increase the intensity of carbon emissions, while cross-industry technology spillovers are persistent for reducing the intensity of domestic carbon emissions. Since the emission reduction effect of technology spillover is greater than the emission increase effect of technology innovation, the digital technology would empower domestic green development. Increasing the proportion of non-fossil energy use and optimizing the industrial structure are effective mechanisms for digital technology innovation to reduce carbon emission intensity.}
}
@article{TEIXEIRA2022103567,
title = {Demystifying the digital transition of remanufacturing: A systematic review of literature},
journal = {Computers in Industry},
volume = {134},
pages = {103567},
year = {2022},
issn = {0166-3615},
doi = {https://doi.org/10.1016/j.compind.2021.103567},
url = {https://www.sciencedirect.com/science/article/pii/S0166361521001743},
author = {Evandro Leonardo Silva Teixeira and Benny Tjahjono and Macarena Beltran and Jorge Julião},
keywords = {Remanufacturing, Industry 4.0, Internet of Things, Systematic literature review},
abstract = {The remanufacturing sector has already instigated the shift towards the adoption of digital technology, especially enabled by the progressive development of the Industry 4.0 (I4.0) technologies. However, remanufacturing systems are faced with many challenges that are not typically found in traditional manufacturing systems. Inspired by the need to better understand their idiosyncrasies, particular needs and implications, this paper aims to scrutinise current issues and concerns about digital transformation in the remanufacturing systems. In particular, the paper reviews the extant literature to observe: (1) how the I4.0 technologies have so far been used in remanufacturing and (2) the benefits and risks that need to be considered by remanufacturers when adopting the I4.0 technologies. We have elucidated the significance of our findings and subsequently synthesised our thoughts into eight propositions that demystify the mechanisms of how the I4.0 technologies can bring potential benefits when used by remanufacturers to accomplish a portfolio of remanufacturing tasks, and the risks they need to be aware of. This articulation represents contributions to knowledge as it will set out the underpinning of the future human-technology collaboration, which is key in the I4.0 realm.}
}
@article{YANG2015191,
title = {Global Coupled Learning and Local Consistencies Ensuring for sparse-based tracking},
journal = {Neurocomputing},
volume = {160},
pages = {191-205},
year = {2015},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2014.12.060},
url = {https://www.sciencedirect.com/science/article/pii/S092523121401724X},
author = {Yehui Yang and Yuan Xie and Wensheng Zhang and Wenrui Hu and Yuanhua Tan},
keywords = {Visual tracking, Sparse representation, Dictionary learning, Coupled learning, Consistency ensuring},
abstract = {This paper presents a robust tracking algorithm by sparsely representing the object at both global and local levels. Accordingly, the algorithm is constructed by two complementary parts: Global Coupled Learning (GCL) part and Local Consistencies Ensuring (LCE) part. The global part is a discriminative model which aims to utilize the holistic features of the object via an over-complete global dictionary and classifier, and the dictionary and classifier are coupled learning to construct an adaptive GCL part. While in LCE part, we explore the object׳s local features by sparsely coding the object patches via a local dictionary, then both temporal and spatial consistencies of the local patches are ensured to refine the tracking results. Moreover, the GCL and LCE parts are integrated into a Bayesian framework for constructing the final tracker. Experiments on fifteen benchmark challenging sequences demonstrate that the proposed algorithm has more effectiveness and robustness than the alternative ten state-of-the-art trackers.}
}
@article{LIN2021141618,
title = {Assessment and management of lake eutrophication: A case study in Lake Erhai, China},
journal = {Science of The Total Environment},
volume = {751},
pages = {141618},
year = {2021},
issn = {0048-9697},
doi = {https://doi.org/10.1016/j.scitotenv.2020.141618},
url = {https://www.sciencedirect.com/science/article/pii/S0048969720351470},
author = {Song-Shun Lin and Shui-Long Shen and Annan Zhou and Hai-Min Lyu},
keywords = {Eutrophication, Lake Erhai, Nutrient transformation, Sustainable development, Comprehensive management},
abstract = {Some wastewater sources, such as agricultural waste and runoff, and industrial sewage, can degrade water quality. This study summarises the sources and corresponding mechanisms that trigger eutrophication in lakes. Additionally, the trophic status index and water quality index (WQI) which are effective tools for evaluating the degree of eutrophication of lakes, have been discussed. This study also explores the main nutrients (nitrogen and phosphorus) driving transformations in the water body and sediment. Lake Erhai was used as a case study, and it was found to be in a mesotrophic state, with N and P co-limitation before 2006, and only P limitation since 2006. Finally, effective measures to maintain sustainable development in the watershed are proposed, along with a framework for an early warning system adopting the latest technologies (geographic information systems (GIS), remote sensing (RS)) for preventing eutrophication.}
}
@article{SHEIKHPOUR2021114202,
title = {A low cost fault-attack resilient AES for IoT applications},
journal = {Microelectronics Reliability},
volume = {123},
pages = {114202},
year = {2021},
issn = {0026-2714},
doi = {https://doi.org/10.1016/j.microrel.2021.114202},
url = {https://www.sciencedirect.com/science/article/pii/S0026271421001682},
author = {Saeideh Sheikhpour and Seok-Bum Ko and Ali Mahani},
keywords = {Advanced encryption standard (AES), Error detection, Internet-of-things (IoTs), Compact implementation, Fault-attack resiliency},
abstract = {The Internet of Things (IoT) as an emerging infrastructure has an essential rule in daily lives in many domains, ranging from healthcare wearable devices to complex industrial systems. Nevertheless, its security is a challenging issue that has to be addressed. The security can be settled by utilizing cryptographic techniques such as Advanced Encryption Standard (AES) for encryption and authentication. In this paper, we propose 32-bit architecture AES encryption/decryption for utilizing in IoT infrastructure and similar resource-constrained applications. On the other hand, providing robustness against existing malicious attacks is a significant factor in ensuring communication reliably and so securely. Therefore, we propose a low-cost fault-resilient integrated architecture, named LC-FRAES, for data-path and also on-the-fly key expansion unit by exploiting of resource sharing between encryption and decryption processes. The results of both ASIC and FPGA implementations of the proposed architecture are reported and also compared with those of similar recent designs. The comparisons illustrate that the LC-FRAES outperforms its counterparts in many architectural features which make it suitable for IoT applications. Moreover, we provide a comparison between our proposal and lightweight cryptographic designs from literature. The comparisons verify the consistency and appropriateness of proposed architecture for IoT applications. Finally, through the extensive experimental results, we show that LC-FRAES can detect almost all injected faults.}
}
@article{TU201845,
title = {Spatial variations in urban public ridership derived from GPS trajectories and smart card data},
journal = {Journal of Transport Geography},
volume = {69},
pages = {45-57},
year = {2018},
issn = {0966-6923},
doi = {https://doi.org/10.1016/j.jtrangeo.2018.04.013},
url = {https://www.sciencedirect.com/science/article/pii/S0966692317304155},
author = {Wei Tu and Rui Cao and Yang Yue and Baoding Zhou and Qiuping Li and Qingquan Li},
keywords = {Ridership, Big data, Trajectory, Smart card data, Geographically weighted regression, Transit, Taxi},
abstract = {Understanding urban public ridership is essential for promoting public transportation. However, limited efforts have been made to reveal the spatial variations of multi-modal public ridership (such as buses, metro systems, and taxis) and the underlying controlling factors. This study explores multi-modal public ridership and compares the similarities and differences of the associated factors. Daily bus, metro, and taxi ridership patterns are first extracted from multiple sources of big transportation data, including vehicle (bus and taxi) GPS trajectories and smart card data. Multivariate regression analysis and geographically weighted regression analysis are used to reveal the associations between these data and demographic, land use, and transportation factors. An empirical study in Shenzhen, China, suggests that employment, mixed land use, and road density have significant effects on the ridership of each mode; however, some effects vary from negative to positive across the city. The results also indicate that road density, income, and metro accessibility do not have significant effects on metro, transit or bus ridership. These findings suggest that the effects of the associated factors vary depending on the mode of travel being considered and that the city should carefully consider which factors to emphasize in formulating future transport policy.}
}
@article{OPREA2018125,
title = {Flattening the electricity consumption peak and reducing the electricity payment for residential consumers in the context of smart grid by means of shifting optimization algorithm},
journal = {Computers & Industrial Engineering},
volume = {122},
pages = {125-139},
year = {2018},
issn = {0360-8352},
doi = {https://doi.org/10.1016/j.cie.2018.05.053},
url = {https://www.sciencedirect.com/science/article/pii/S0360835218302614},
author = {Simona Vasilica Oprea and Adela Bâra and George Ifrim},
keywords = {Consumption peak, Shifting optimization algorithm, Programmable appliance, ToU tariff, Flattening index},
abstract = {Nowadays, by means of smart meters and sensors, more and more electricity consumers can shift the operation of some of their appliances thus, reducing the electricity expenses calculated on advanced tariff schemes such as time-of-use (ToU) tariff. In this paper, we propose an optimization algorithm that can be automatically implemented by the electricity suppliers without knowing the specific characteristics of residential consumers’ appliances (preserving privacy) to flatten the daily consumption curve and identify the ToU tariff that would reduce the consumers’ electricity payment. This way the consumers will receive incentives to provide the daily operation schedule of the appliances indicating their type, considering that the electricity appliances are divided into programmable and non-programmable appliances. The dependency between operations of some appliances brings certain constraints to the optimization model that shift programmable appliances from peak to off-peak hours. Therefore, the flattening of the consumption peak relies on programmable appliances, while the operation of the non-programmable appliances forms the base of the daily consumption curve. By transparently implementing the optimization algorithm in relation to several ToU tariffs, the suppliers show the benefits in terms of consumption peak and electricity payment reduction. Also, this would stimulate the consumer to shift the operation of appliances and choose the tariff that minimizes the electricity payment that is a function of the consumption flexibility. Although the proposed algorithm is mainly designed to flatten the consumption peak, it can further restrict the operation of the programmable appliances at high-rate time intervals that rewards the flexible consumers with more savings.}
}
@article{CHEN2020102500,
title = {Channel-reserved medium access control for edge computing based IoT},
journal = {Journal of Network and Computer Applications},
volume = {150},
pages = {102500},
year = {2020},
issn = {1084-8045},
doi = {https://doi.org/10.1016/j.jnca.2019.102500},
url = {https://www.sciencedirect.com/science/article/pii/S1084804519303601},
author = {Yan Chen and Yanjing Sun and Nannan Lu and Bin Wang},
keywords = {Edge computing IoT, Service performance, Response collision, Channel reservation, MAC, Cross-layer design},
abstract = {Edge computing brings powerful computing service to the proximity of IoT nodes to support sophisticated applications in future Internet of Things (IoT). Considering the channel is generally shared or multiplexed by multiple nodes in wireless networks, short response packets in edge computing service processes may easily congest or conflict with other simultaneous transmissions. Then, the service latency increases and may exceed the latency constraint of computing tasks, which naturally decrease the service performance of applications. Therefore, for edge computing based IoT (EdgeIoT), it is of great necessary yet has not been studied to schedule the transmission of responses. This paper studies the transmission of responses from the perspective of the MAC layer, a channel-reserved MAC (ChRMAC) protocol is proposed to reduce the collision and latency of responses in edge computing service procedures. A latency constraint aware scheme is devised in the ChRMAC to improve the effectiveness of reservations. Besides, a backoff recovery mechanism is designed to avoid the increase of latency and collision of computing tasks after reservations. Moreover, a cross-layer framework for the implementation of ChRMAC is proposed. Simulations are conducted in ns-3 to evaluate the proposed ChRMAC. Simulation results indicate that ChRMAC can reduce the average latency of response and increase the service performance of EdgeIoT.}
}
@article{FLICK2018202,
title = {Ascertainment of Energy Consumption Information in the Age of Industrial Big Data},
journal = {Procedia CIRP},
volume = {72},
pages = {202-208},
year = {2018},
note = {51st CIRP Conference on Manufacturing Systems},
issn = {2212-8271},
doi = {https://doi.org/10.1016/j.procir.2018.03.122},
url = {https://www.sciencedirect.com/science/article/pii/S2212827118302798},
author = {Dominik Flick and Felix Kuschicke and Marcelo Schweikert and Thomas Thiele and Niklas Panten and Sebastian Thiede and Christoph Herrmann},
keywords = {energy transparency, shop floor data, energy monitoring, fields of application},
abstract = {Industrial Big Data and Energy Management have become major strategic topics in manufacturing as they offer possibilities to realize untapped cost and emission saving potentials. The paper discusses the utilization of equipment internal energy-relevant data as part of the Industrial Big Data developments taking place in manufacturing to create energy transparency according to ISO 50001. A classification framework to estimate the required effort of ascertaining information on energy consumption of production equipment is described and the synergy effects with Industrial Big Data related to data acquisition, extraction and infrastructure are discussed. Furthermore, a case study provides insights about the achievable energy transparency in an automotive body shop.}
}
@article{CICIRELLI2017274,
title = {Metamodeling of Smart Environments: from design to implementation},
journal = {Advanced Engineering Informatics},
volume = {33},
pages = {274-284},
year = {2017},
issn = {1474-0346},
doi = {https://doi.org/10.1016/j.aei.2016.11.005},
url = {https://www.sciencedirect.com/science/article/pii/S1474034616302063},
author = {Franco Cicirelli and Giancarlo Fortino and Antonio Guerrieri and Giandomenico Spezzano and Andrea Vinci},
keywords = {Smart Environments, Cyber-Physical Systems, Internet of Things, Metamodeling, Modeling, Development methodology, Smart office},
abstract = {A smart environment is a physical environment enriched with sensing, actuation, communication and computation capabilities aiming at acquiring and exploiting knowledge about the environment so as to adapt itself to its inhabitants’ preferences and requirements. In this domain, there is the need of tools supporting the design and analysis of applications. In this paper, the Smart Environment Metamodel (SEM) framework is proposed. The framework allows to model applications by exploiting concepts specific to the smart environment domain. SEM approaches the modeling from two different points of view, namely the functional and data perspectives. The application of the framework is supported by a set of general guidelines to drive the analysis, the design and the implementation of smart environments. The effectiveness of the framework is shown by applying it to the modeling of a real smart office scenario that has been developed, deployed and analyzed.}
}
@article{HUSSAIN202186,
title = {CODE-V: Multi-hop computation offloading in Vehicular Fog Computing},
journal = {Future Generation Computer Systems},
volume = {116},
pages = {86-102},
year = {2021},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2020.09.039},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X20303526},
author = {Md. Muzakkir Hussain and M.M. Sufyan Beg},
keywords = {Intelligent Transportation Systems, Vehicular Fog Computing, Multi-objective optimization, Differential evolution},
abstract = {Vehicular Fog Computing (VFC) is an extension of fog computing in Intelligent Transportation Systems (ITS). It is an emerging computing model that leverages latency-aware and energy-aware application deployment in ITS. In this paper, we consider the problem of multi-hop computation offloading in a VFC network, where the client vehicles are connected to fog computing nodes by multi-hop LTE access points. Our scheme addresses three key aspects in a VFC architecture namely: (i) Optimal decision on local or remote task execution, (ii) Optimal fog node assignment, and (iii) Optimal path (multi-hop) selection for computation offloading. Considering the constraints on service latency, hop-limit, and computing capacity, the process of workload allocation across host vehicles, stationary and mobile fog nodes, and the cloud servers is formulated into a multi-objective, non-convex, and NP-hard Quadratic Integer Problem (QIP). Accordingly, an algorithm named Computation Offloading with Differential Evolution in VFC (CODE-V) is proposed. For each client task, CODE-V takes into account inter-fog cooperation, fog node acceptance probability, and the topological variations in the transportation fleets, towards optimal selection of a target fog node. We conduct extensive simulations on the real-world mobility traces of Shenzhen, China, to show that CODE-V reduces the average service latency and energy consumption by approximately 28% and 61%, respectively, compared to the state-of-the-art. Moreover, the CODE-V also gives better solution quality compared to standard DE∕rand∕1∕bin algorithm and the solutions generated by a CPLEX solver.}
}
@article{WEI2021104939,
title = {Soil salinity prediction based on scale-dependent relationships with environmental variables by discrete wavelet transform in the Tarim Basin},
journal = {CATENA},
volume = {196},
pages = {104939},
year = {2021},
issn = {0341-8162},
doi = {https://doi.org/10.1016/j.catena.2020.104939},
url = {https://www.sciencedirect.com/science/article/pii/S0341816220304896},
author = {Yang Wei and Jianli Ding and Shengtian Yang and Fei Wang and Chen Wang},
keywords = {Scale-dependent relationships, Soil salinity, Discrete wavelet transform, Tarim basin},
abstract = {The variation in soil salinity is affected by environmental factors that occur at different scales with varying intensities. It is critical to adequately consider environmental variables under scale effects for digital soil mapping which has been minimally discussed in previous studies. The objectives of this research are to analyze the scale-dependent variability in soil salinity distribution under environmental controlling factors using discrete wavelet transform (DWT) techniques and to compare the differences between the accuracy of soil salinity predictions with and without multiple scale-specific relationships. Thirteen environmental factors related to soil salinity that included influencing environmental factors and indicative environmental factors involving climate, soil, terrain, and vegetation were extracted at 500 m intervals along four transects through farmland and salt-affected land situated at the oasis and oasis-desert ecotones of Xinjiang, China. Each spatial series of soil salinity and environmental variables along the four transects was separated into seven scale components (six details components, namely D1 through D6, and one approximation component, namely A6). A Hilbert transform was used to identify the specific spatial scales of each scale component in the DWT procedure. The results indicate that 21.77 km and >32 km were the dominant scales, which explained approximately 60–80% of the spatial variation of soil salinity throughout the oases. The prediction accuracy with wavelet reconstruction that depended on all the scale components of environmental variables is significantly improved compared with the accuracy of those with the stepwise multiple linear regression method at a single sampling scale. The generalized difference vegetation index (GDVI) was the major predictor of soil salinity on salt-affected land, while evapotranspiration and the terrain ruggedness index (TRI) were the major contributing factors in farmland inside the oases. This study demonstrated that specific scale-dependent relationships can reveal the scale control of soil salinity variation and had the potential to improve the prediction accuracy of soil properties.}
}
@article{SRINIDHI20191,
title = {Network optimizations in the Internet of Things: A review},
journal = {Engineering Science and Technology, an International Journal},
volume = {22},
number = {1},
pages = {1-21},
year = {2019},
issn = {2215-0986},
doi = {https://doi.org/10.1016/j.jestch.2018.09.003},
url = {https://www.sciencedirect.com/science/article/pii/S2215098618303379},
author = {N.N. Srinidhi and S.M. {Dilip Kumar} and K.R. Venugopal},
keywords = {Congestion, Energy conservation, Network optimization, QoS, Reliability},
abstract = {The Internet was initially used to transfer data packets between users and data sources with a specific IP address. Due to advancements, the Internet is being used to share data among different small, resource constrained devices connected in billions to constitute the Internet of Things (IoT). A large amount of data from these devices imposes overhead on the IoT network. Hence, it is required to provide solutions for various network related problems in IoT including routing, energy conservation, congestion, heterogeneity, scalability, reliability, quality of service (QoS) and security to optimally make use of the available network. In this paper, a comprehensive survey on the network optimization in IoT is presented. The paper draws an attention towards the background of IoT and its distinction with other technologies, discussion on network optimization in IoT and algorithms classification. Finally, state-of-the-art-techniques for IoT in particular to network optimization are discussed based on the recent works and the review is concluded with open issues and challenges for network optimization in IoT. This paper not only reviews, compares and consolidates the recent related works, but also admires the author’s findings, solutions and discusses its usefulness towards network optimization in IoT. The uniqueness of this paper lies in the review of network optimization issues and challenges in IoT.}
}
@article{MARIANO2019920,
title = {Fast Access to Remote Objects 2.0 a renewed gateway to ENEAGRID distributed computing resources},
journal = {Future Generation Computer Systems},
volume = {94},
pages = {920-928},
year = {2019},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2017.11.032},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X17308907},
author = {Angelo Mariano and Giulio D’Amato and Fiorenzo Ambrosino and Giuseppe Aprea and Francesco Buonocore and Massimo Celino and Antonio Colavincenzo and Marco Fina and Agostino Funel and Simone Giusepponi and Guido Guarnieri and Filippo Palombi and Samuele Pierattini and Giovanni Ponti and Giuseppe Santomauro and Giovanni Bracco and Silvio Migliori},
keywords = {Graphical user interface, Remote desktop, Distributed computing, Virtual labs},
abstract = {This paper introduces a renewed gateway to ENEAGRID distributed computing resources named Fast Access to Remote Objects 2.0 (FARO 2.0). FARO 2.0 is a tool for application and desktop virtualization with a focus towards user experience (UX), providing trained as well as untrained users with a collection of centralized services that can be seamlessly used on their client through a remote desktop protocol. FARO 2.0 is a JavaFX application whose graphical user interface (GUI) and whose main logics have been implemented through the well-known Web technologies (HTML5, CSS3, Javascript) for easier maintainability and customizability, taking full advantage of the WebView component. The FARO 2.0 framework has been deployed both as a general purpose GUI for remote user access to ENEAGRID resources and as a specialized application or workflow-oriented GUI. They are applied in a set of applicative domains, ranging from materials science to technologies for energy and industry, environmental modeling, and nuclear fusion. Some examples and results are also presented.}
}
@article{CAI201931,
title = {Sensing multiple semantics of urban space from crowdsourcing positioning data},
journal = {Cities},
volume = {93},
pages = {31-42},
year = {2019},
issn = {0264-2751},
doi = {https://doi.org/10.1016/j.cities.2019.04.011},
url = {https://www.sciencedirect.com/science/article/pii/S0264275118318080},
author = {Ling Cai and Jun Xu and Ju Liu and Ting Ma and Tao Pei and Chenghu Zhou},
keywords = {Spatial function, Urban dynamics, Spatial-temporal pattern, Tencent location big data, Tensor factorization},
abstract = {Urban spaces have multiple functions, and the main functions of these space change with human activities during a day; thus, there are dynamic semantics of spaces in a city. Knowing the dynamic semantics of urban spaces, which are implied in spatiotemporal patterns of human activities, can help urban planners and managers understand how a city performs over time and space. The very large amount of multidimensional user-generated data makes it possible to disclose the spatiotemporal patterns of human activities from multiple perspectives. In this paper, using Beijing as a case study, we extract the dynamic semantics of urban spaces through the spatiotemporal patterns of human activities discovered from crowdsourced positioning data. A high-order decomposition method, tensor factorization, is used to explore the crowdsourced positioning data. The decomposition results reveal five hourly patterns, four daily patterns and six spatial patterns of urban dynamics in Beijing, showing that urban dynamics in Beijing vary noticeably over different hours, days and space. The human activities implicated by hourly and daily patterns are inferred through empirical knowledge, and the activity semantics of spatial patterns are further disclosed by using the interaction relations among three dimensions stored in the core tensor. The k-means clustering method is executed to aggregate similar spatial units into one group. Five clusters of regions with similar activity semantics are discovered, the function semantics of clusters are clarified with point of interest (POI) data.}
}
@article{SUN2019194,
title = {State and runtime-aware scheduling in elastic stream computing systems},
journal = {Future Generation Computer Systems},
volume = {97},
pages = {194-209},
year = {2019},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2019.02.053},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X18321897},
author = {Dawei Sun and Shang Gao and Xunyun Liu and Fengyun Li and Xinqi Zheng and Rajkumar Buyya},
keywords = {State awareness, Runtime awareness, Application scheduling, Elastic stream computing, Big data system},
abstract = {State and runtime-aware scheduling is one of the problems that is hard to resolve in elastic big data stream computing systems, as the state of each vertex is different, and the arrival rate of data streams fluctuates over time. A state and runtime-aware scheduling framework should be able to dynamically adapt to the fluctuation of the arrival rate of data streams and be aware of vertex states and resource availability. Currently, there is an increasing number of research work focusing on application scheduling in stream computing systems, however, this problem is still far from being completely solved. In this paper, we focus on the state of vertex in applications and the runtime feature of resources in a data center, and propose a state and runtime-aware scheduling framework (Sra-Stream) for elastic streaming computing systems, which incorporates the following features: (1) Profiling mathematical relationships between the system response time and the arrival rate of data streams, and identifying relevant resource constraints to meet the low response time and high throughput objectives. (2) Classifying vertex into stateless vertex or stateful vertex from a quantitative perspective, and achieving vertex parallelization by considering the state of the vertex. (3) Demonstrating a proposed stream application scheduling scheme consisting of a modified first-fit based runtime-aware data tuple scheduling strategy at the initial stage, and a maximum latency-sensitive based runtime-aware data stream scheduling strategy at the online stage, by considering the current scheduling status of the application. (4) Evaluating the achievement levels of low response time and high throughput objectives in a real-world elastic stream computing system. Experimental results conclusively demonstrate that the proposed Sra-Stream provides significant performance improvements on achieving the low system response time and high system throughput.}
}
@article{SHOWKATBAKHSH2020108920,
title = {Securing state reconstruction under sensor and actuator attacks: Theory and design},
journal = {Automatica},
volume = {116},
pages = {108920},
year = {2020},
issn = {0005-1098},
doi = {https://doi.org/10.1016/j.automatica.2020.108920},
url = {https://www.sciencedirect.com/science/article/pii/S0005109820301187},
author = {Mehrdad Showkatbakhsh and Yasser Shoukry and Suhas N. Diggavi and Paulo Tabuada},
keywords = {Cyber–physical security, State reconstruction, Security monitoring},
abstract = {This paper discusses the problem of reconstructing the state of a linear time invariant system when some of its actuators and sensors are compromised by an adversarial agent. In the model considered in this paper, the adversarial agent attacks an input (output) by manipulating its value arbitrarily, i.e., we impose no constraints (statistical or otherwise) on how control commands (sensor measurements) are changed by the adversary other than a bound on the number of attacked actuators and sensors In the first part of this paper, we introduce the notion of sparse strong observability and we show that is a necessary and sufficient condition for correctly reconstructing the state despite the considered attacks. In the second half of this work, we propose an observer to harness the complexity of this intrinsically combinatorial problem, by leveraging satisfiability modulo theory solving. Numerical simulations illustrate the effectiveness and scalability of our observer.}
}
@article{KEELER2021102830,
title = {The future of aging in smart environments: Four scenarios of the United States in 2050},
journal = {Futures},
volume = {133},
pages = {102830},
year = {2021},
issn = {0016-3287},
doi = {https://doi.org/10.1016/j.futures.2021.102830},
url = {https://www.sciencedirect.com/science/article/pii/S0016328721001312},
author = {Lauren Withycombe Keeler and Michael J. Bernstein},
keywords = {Scenarios, Aging, Smart environments, Futures, Innovation},
abstract = {The population of the United States is getting older. Unlike other countries with aging populations, however, the state of aging in the United States is in crisis. Healthcare and social reforms will likely be necessary in the coming decades to address structural issues with retirement, socio-economic inequality, and the high cost of healthcare. In the meantime, AI-enabled smart technologies and environments are being rapidly developed to assist overwhelmed caretakers, enable access to healthcare providers, address isolation and depression among older adults, and provide mobility to and from essential services in sprawling suburbs and rural areas. This study utilizes a participatory, intuitive logics approach to construct scenarios of aging in smart environments in 2050 that illuminate the uncertainties, challenges, and opportunities presented by the coming confluence of two mega trends: an aging population and increasingly sensed people and environments. The results include four scenarios including descriptions and key features, and with narratives available in the appendix. In the discussion, we reflect on five provocations distilled from expert interviews to illustrate what aging might look like in 2050 from a variety of socio-economic vantage points and mediated by technological capabilities and arrangements born of differing policy, economic, and societal conditions.}
}
@article{LI2020284,
title = {Inlier extraction for point cloud registration via supervoxel guidance and game theory optimization},
journal = {ISPRS Journal of Photogrammetry and Remote Sensing},
volume = {163},
pages = {284-299},
year = {2020},
issn = {0924-2716},
doi = {https://doi.org/10.1016/j.isprsjprs.2020.01.021},
url = {https://www.sciencedirect.com/science/article/pii/S0924271620300277},
author = {Wei Li and Cheng Wang and Congren Lin and Guobao Xiao and Chenglu Wen and Jonathan Li},
keywords = {Supervoxel segmentation, Non-cooperative game, Keypoint correspondences, Point cloud registration},
abstract = {As a key step in Six-Degree-of-Freedom (6DoF) point cloud registration, 3D keypoint technique aims to extract matches or inliers from random correspondences between the two keypoint sets. The major challenge in 3D keypoint techniques is the high ratio of mismatched or outliers in random correspondences in real-world point cloud registration. In this paper, we present a novel inlier extraction method, which is based on Supervoxel Guidance and Game Theory optimization (SGGT), to extract reliable inliers and apply for point cloud registration. Specifically, to reduce the scale of keypoint correspondences, we first construct powerful groups of keypoint correspondences by introducing supervoxels, which involves 3D spatial homogeneity. Second, to select promising combined groups, we present a novel ‘fit-and-remove’ strategy by incorporating 3D local transformation constraints. Third, to extract purer inliers for point cloud registration, we propose a grouping non-cooperative game algorithm, which considers the relationship between the combined groups. The proposed SGGT, by eliminating the mismatched combined groups globally, avoids the false combined groups that lead to the failed estimation of rigid transformations. Experimental results show that when processing on large keypoint sets, the proposed SGGT is over 100 times more efficient compared to the stat-of-the-art, while keeping the similar accuracy.}
}
@article{GARCIAMAGARINO201784,
title = {TABSAOND: A technique for developing agent-based simulation apps and online tools with nondeterministic decisions},
journal = {Simulation Modelling Practice and Theory},
volume = {77},
pages = {84-107},
year = {2017},
issn = {1569-190X},
doi = {https://doi.org/10.1016/j.simpat.2017.05.006},
url = {https://www.sciencedirect.com/science/article/pii/S1569190X17300886},
author = {Iván García-Magariño and Guillermo Palacios-Navarro and Raquel Lacuesta},
keywords = {Agent-based simulation, Mobile application, Multi-agent system, Nondeterministic decisions, Online tools},
abstract = {Agent-based simulators (ABSs) have successfully allowed practitioners to estimate the outcomes of certain input circumstances in several domains. Although some techniques and processes provide hints about the construction of these systems, some aspects have not been discussed yet in the literature. In this context, the current approach presents a technique for developing ABSs. Its focus is to guide practitioners in designing and implementing the decision-making processes of agents in nondeterministic scenarios. As an additional technological innovation, the ABSs are deployed as both mobile apps and online tools. This work illustrates the current approach with two case studies in the fields of (a) health and welfare and (b) tourism. These case studies have also been developed with the most similar technique from the literature for comparing both techniques. The presented technique improved the simulated outcomes in terms of their similarity with the real ones. The obtained ABSs were more efficient and reliable for large amounts of agents (e.g. 10,000 – 400,000 agents). The development time was lower. Both the framework and the implementation of a case study are freely distributed as open-source to facilitate the reproducibility of the experiments and to assist practitioners in applying the current approach.}
}
@article{FAN2017205,
title = {Statistical analysis of drivers of residential peak electricity demand},
journal = {Energy and Buildings},
volume = {141},
pages = {205-217},
year = {2017},
issn = {0378-7788},
doi = {https://doi.org/10.1016/j.enbuild.2017.02.030},
url = {https://www.sciencedirect.com/science/article/pii/S0378778817304929},
author = {H. Fan and I.F. MacGill and A.B. Sproul},
keywords = {Peak demand, Residential, Electricity demand, Energy demand, Smart grid, Peak load, Influence, Factors},
abstract = {Growth in peak electricity demand poses considerable challenges for utilities seeking to ensure secure, reliable yet affordable energy provision. A better understanding of the key drivers of residential peak electricity demand could assist in better managing peak demand growth through options including demand-side participation and energy efficiency programs. However, such analysis has often been constrained by the limited data available from standard household metering, as well as typically low direct engagement by utilities with households regarding their energy use. This paper presents a study analysing and modeling residential peak demand in the greater Sydney region using data from Australia’s largest Smart Grid study to date. The dataset includes household level half hour consumption matched to surveyed information including housing type, demographics and appliance ownership. A range of statistical and modeling techniques are applied to determine key drivers for household demand at times of network peaks. The analysis and model quantify how different factors drive residential peak demand on hot summer days. Key drivers identified include air-conditioning ownership, the number of household occupants, swimming pool ownership, and clothes dryer usage. Finally, the model is used to investigate the potential aggregate network peak implications of changes in household demographics and appliance ownership.}
}
@article{CHEN202073,
title = {Taxi hailing choice behavior and economic benefit analysis of emission reduction based on multi-mode travel big data},
journal = {Transport Policy},
volume = {97},
pages = {73-84},
year = {2020},
issn = {0967-070X},
doi = {https://doi.org/10.1016/j.tranpol.2020.04.001},
url = {https://www.sciencedirect.com/science/article/pii/S0967070X19305542},
author = {Fangxi Chen and Zhiwei Yin and Yingwei Ye and Daniel(Jian) Sun},
keywords = {Urban travel big data, Travel mode selection, Logit regression model, Exhaust emission model, Cost-benefit analysis, Removing the non-motor vehicle restrictions (on road)},
abstract = {During the passing decade, taxi floating car data (FCD) has become an important tool to investigate urban trip choice behaviors and activities. The corresponding taxi exhaust reduction issue is also with rather significance for traffic emission mitigation in urban areas. By taking Shanghai as an empirical case, this paper analyzed the spatiotemporal characteristics of multimode travelers by combining the taxi FCD (from Qiangsheng Inc.), the metro smartcard data and the GPS trajectories of Mobike, one of the most popular shared bicycles in China, 2018). Binomial logit models (BNL) were proposed to estimate mode choices for both peak and off-peak periods by incorporating socio-economic, demographic, urban morphology, land use properties, and various trip-related variables. The choices between metro and taxi, Mobike and taxi were analyzed, respectively, with the corresponding influential factors identified. The results indicated that the percentage of residential and commercial land uses, the number of educational facilities have significant impacts on travel mode choice during peak hours, while the percentage of commercial land, the number of hospitals and bus lines are more prominent during off-peak periods. To quantify the emission reduction benefits, localized calculation of automobile exhaust was established according to the Vehicle Specific Power (VSP) based measurements obtained from the Portable Emission Measurement System (PEMS) experiments. Then, five corresponding emission mitigation schemes were proposed based on the model findings, and the cost-benefit of each countermeasure was further analyzed. Comparing with releasing the peak-hour crowdedness of metro stations, increasing Mobike supply, updating taxis into electric vehicles, and equipping taxis with catalytic converters, the scheme of removing non-motor vehicle restrictions was found with the shortest payback period and was consequently recommended as accordance with the proposal of urban eco and non-motorized transportation. Findings of this study is useful for transportation management in improving the mode share of metro and bicycles, thus to alleviate the congestion and auto emissions in urban areas.}
}
@article{DING2021127166,
title = {RTVEMVS: Real-time modeling and visualization system for vehicle emissions on an urban road network},
journal = {Journal of Cleaner Production},
volume = {309},
pages = {127166},
year = {2021},
issn = {0959-6526},
doi = {https://doi.org/10.1016/j.jclepro.2021.127166},
url = {https://www.sciencedirect.com/science/article/pii/S0959652621013858},
author = {Hui Ding and Ming Cai and Xiaofang Lin and Tong Chen and Li Li and Yonghong Liu},
keywords = {Precise control, Real-time modeling, Real-time visualization, Vehicle emission, Urban traffic},
abstract = {To improve the real-time and precision of vehicle emission monitoring and estimation for supporting variable and speedy response on vehicle emission control work, a real-time modeling and visualization system for vehicle emissions on an urban road network (RTVEMVS) was designed and built with Web platform by the development of three modules: real-time data collection, real-time modeling and real-time visualization. The real-time mapping of vehicle emission by vehicle types and road links and real-time“precise vehicles emissions impact estimation” technology which can trace key roads and vehicles induced high air pollution were innovated on system to provide the sensitive perception for government decision makers on speedy vehicles emission control. The detailed vehicle information, traffic flow, speed on each road link and weather data were accessed and fused in real-time from multiple urban sensor systems together with road network information. Integrating an emission calculation model with a high spatiotemporal resolution and the AREMOD dispersion model was running on real-time in RTVEMVS. Based on the Web interface and WebGIS technology (ArcGIS API for JavaScript), real-time vehicle emissions and estimation results can be visualized on a map. The RTEMVS was demonstrated by application on Chongqing of China, hourly based-links vehicle emission by vehicle types on road network and the top 10 of key road links and vehicles induced high air pollution per hour were clearly reveal and visually viewed, and indicate that the real-time system with real-time mapping and precise estimation can provide direct support to the variable vehicle emission control. The RTVEMVS is a useful platform for supporting decision-making in the precise control of urban vehicle emissions pollution.}
}
@article{GARG201828,
title = {Identifying influential segments from word co-occurrence networks using AHP},
journal = {Cognitive Systems Research},
volume = {47},
pages = {28-41},
year = {2018},
issn = {1389-0417},
doi = {https://doi.org/10.1016/j.cogsys.2017.07.003},
url = {https://www.sciencedirect.com/science/article/pii/S138904171630198X},
author = {Muskan Garg and Mukesh Kumar},
keywords = {Word co-occurrence networks, Analytic hierarchy process, Word adjacency model, Topic detection and tracking},
abstract = {Identifying important segments in textual data seems to be an important area of research for various applications including topic modelling, trend detection, summarization and event detection. In existing research work, different metrics have been studied to analyse the word co-occurrence network. This research work contributes towards non-semantic and an unsupervised topic identification using the word co-occurrence networks. In this research work, keyphrase have been identified by preserving the lexical sequence using a directed and weighted word co-occurrence network. Further AHP (Analytic Hierarchy Process) model based upon four significant attributes of the word co-occurrence networks have been proposed to rank the keyphrases. Most frequently occurring segment is identified as an influential segment. Experimental results proved high effectiveness of the proposed approach. Results for the First Story Detection, 72 Twitter TDT, synthesized Rio Olympics dataset have been discussed to demonstrate its potential in precisely discovering influential segments.}
}
@article{HARTMANN2019101,
title = {GreyCat: Efficient what-if analytics for data in motion at scale},
journal = {Information Systems},
volume = {83},
pages = {101-117},
year = {2019},
issn = {0306-4379},
doi = {https://doi.org/10.1016/j.is.2019.03.004},
url = {https://www.sciencedirect.com/science/article/pii/S0306437917303988},
author = {Thomas Hartmann and Francois Fouquet and Assaad Moawad and Romain Rouvoy and Yves {Le Traon}},
keywords = {What-if analysis, Time-evolving graphs, Predictive analytics, Graph processing},
abstract = {Over the last few years, data analytics shifted from adescriptive era, confined to the explanation of past events, to the emergence of predictive techniques. Nonetheless, existing predictive techniques still fail to effectively explore alternative futures, which continuously diverge from current situations when exploring the effects of what-if decisions. Enabling prescriptive analytics therefore calls for the design of scalable systems that can cope with the complexity and the diversity of underlying data models. In this article, we address this challenge by combining graphs and time series within a scalable storage system that can organize a massive amount of unstructured and continuously changing data into multi-dimensional data models, called Many-Worlds Graphs. We demonstrate that our open source implementation, GreyCat, can efficiently fork and update thousands of parallel worlds composed of millions of timestamped nodes, such as what-if exploration.}
}
@article{YAN201640,
title = {Quadratic projection based feature extraction with its application to biometric recognition},
journal = {Pattern Recognition},
volume = {56},
pages = {40-49},
year = {2016},
issn = {0031-3203},
doi = {https://doi.org/10.1016/j.patcog.2016.02.010},
url = {https://www.sciencedirect.com/science/article/pii/S0031320316000819},
author = {Yan Yan and Hanzi Wang and Si Chen and Xiaochun Cao and David Zhang},
keywords = {Biometric recognition, Feature extraction, Quadratic projection, Semidefinite programming, Lagrange duality},
abstract = {This paper presents a novel quadratic projection based feature extraction framework, where a set of quadratic matrices is learned to distinguish each class from all other classes. We formulate quadratic matrix learning (QML) as a standard semidefinite programming (SDP) problem. However, the conventional interior-point SDP solvers do not scale well to the problem of QML for high-dimensional data. To solve the scalability of QML, we develop an efficient algorithm, termed DualQML, based on the Lagrange duality theory, to extract nonlinear features. To evaluate the feasibility and effectiveness of the proposed framework, we conduct extensive experiments on biometric recognition. Experimental results on three representative biometric recognition tasks, including face, palmprint, and ear recognition, demonstrate the superiority of the DualQML-based feature extraction algorithm compared to the current state-of-the-art algorithms.}
}
@article{NAKAGAWA2021107241,
title = {Industry 4.0 reference architectures: State of the art and future trends},
journal = {Computers & Industrial Engineering},
volume = {156},
pages = {107241},
year = {2021},
issn = {0360-8352},
doi = {https://doi.org/10.1016/j.cie.2021.107241},
url = {https://www.sciencedirect.com/science/article/pii/S0360835221001455},
author = {Elisa Yumi Nakagawa and Pablo Oliveira Antonino and Frank Schnicke and Rafael Capilla and Thomas Kuhn and Peter Liggesmeyer},
keywords = {Industry 4.0, Reference architecture, Software architecture, Interoperability},
abstract = {Industry 4.0 has led to a dramatic shift in manufacturing processes, which must be accomplished by interacting end-to-end industrial systems. While Industry 4.0 is still a big challenge for many manufacturing companies, reference architectures have been increasingly adopted in different domains to guide engineers on how their systems should interoperate and be structured. Companies have made different experiences with reference architectures for Industry 4.0. However, depending on the use cases addressed, a reference architecture may be more or less suited to support the transformation of a particular company. Besides, a complete understanding of existing representative architectures does not exist. The main goal of this work is to review existing reference architectures for Industry 4.0 and analyze them concerning their suitability for supporting Industry 4.0 processes and solutions. For this, we systematically researched these architectures and thoroughly analyzed and characterized them. We also address their use and technologies/tools that could support their implementation. As a result, we found that existing architectures still have a long way to go; hence, we present the most urgent steps for the near future. We conclude that the Industry 4.0 community is right in investing in reference architectures considering the future of Industry 4.0.}
}
@article{LI2020117180,
title = {Optimal scheduling of multiple multi-energy supply microgrids considering future prediction impacts based on model predictive control},
journal = {Energy},
volume = {197},
pages = {117180},
year = {2020},
issn = {0360-5442},
doi = {https://doi.org/10.1016/j.energy.2020.117180},
url = {https://www.sciencedirect.com/science/article/pii/S0360544220302875},
author = {Bei Li and Robin Roche},
keywords = {Real-time scheduling, Gas/electric/heat, Markov chain prediction, Model predictive control, Uncertainty, Microgrid},
abstract = {Renewable energy based multi-energy supply microgrids not only can cover different types of demands (such as, electricity/heat/gas), but also can interconnect with different utility grid networks (electricity/heat/gas). When there are large numbers of grid-connected microgrids, how to operate these multiple microgrids in real-time is a problem. In this paper, day-ahead stochastic optimization scheduling and real-time sliding window model predictive control are used to control the operation of microgrids. In order to consider the influence of future prediction on the current optimal decision results, different prediction methods are adopted to predict the load demands and renewable energy output. For example, online learning Markov chain prediction, and support vector machine are used to predict the future values. As for comparison, robust prediction and bilevel optimization are adopted to describe the future prediction uncertainty. The real-time operation of microgrids aims to follow the day-ahead exchanged energy with utility grids, which can minimize the impact of the microgrid on the utility grids. The supply network is an IEEE30 + gas20+heat14 network. The results show that: 1) when the sliding window number is smaller, the total operation cost is larger, but the calculation time is smaller, the trade-off between sliding window numbers and calculation time should be considered; 2) the accuracy of the prediction impacts the 2-norm error of the operation cost, when we decrease by “1” unit of 2-norm prediction error of the whole system, the 2-norm operation cost will decrease by “0.15” unit; 3) from the view of the post-event analysis (total operation cost), for the Markov chain prediction method, the relative error is about 0.32%, is better than the support vector machine method; 4) in the robust cases, the larger the conservative value, the higher the stored hydrogen energy. At last, the results of real-time sliding window model predictive control problem are influenced by the future prediction methods and the window numbers.}
}
@article{AHMED2021107744,
title = {Using differential evolution and Moth–Flame optimization for scientific workflow scheduling in fog computing},
journal = {Applied Soft Computing},
volume = {112},
pages = {107744},
year = {2021},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2021.107744},
url = {https://www.sciencedirect.com/science/article/pii/S1568494621006657},
author = {Omed Hassan Ahmed and Joan Lu and Qiang Xu and Aram Mahmood Ahmed and Amir Masoud Rahmani and Mehdi Hosseinzadeh},
keywords = {Fog computing, Task, Workflow, Optimization, Makespan, Energy, DVFS},
abstract = {Fog computing is an interesting technology aimed at providing various processing and storage resources at the IoT networks’ edge. Energy consumption is one of the essential factors that can directly impact the maintenance cost and CO2 emissions of fog environments. Energy consumption can be mitigated by effective scheduling approaches, in which tasks are going to be mapped on the best possible resources regarding some conflicting objectives. To deal with these issues, we introduce an opposition-based hybrid discrete optimization algorithm, called DMFO-DE. For this purpose, first, a discrete and Opposition-Based Learning (OBL) version of the Moth–Flame Optimization (MFO) algorithm is provided, and it then is combined with the Differential Evolution (DE) algorithm to improve the convergence speed and prevent local optima problem. The DMFO-DE is then employed for scientific workflow scheduling in fog computing environments using the Dynamic Voltage and Frequency Scaling (DVFS) method. The Heterogeneous Earliest Finish Time (HEFT) algorithm is used to find the tasks execution order in the scientific workflows. Our workflow scheduling approach mainly tries to decrease the scheduling process’s energy consumption by minimizing the applied Virtual Machines (VMs), makespan, and communication between dependent tasks. For evaluating the performance of the proposed scheduling scheme, extensive simulations are conducted on the scientific workflows with four different sizes. The experimental results indicate that scheduling using the DMFO-DE algorithm can outperform other metrics such as the number of applied VMs, and energy consumption.}
}
@article{TCHAO2021e00796,
title = {On cloud-based systems and distributed platforms for smart grid integration: Challenges and prospects for Ghana's Grid Network},
journal = {Scientific African},
volume = {12},
pages = {e00796},
year = {2021},
issn = {2468-2276},
doi = {https://doi.org/10.1016/j.sciaf.2021.e00796},
url = {https://www.sciencedirect.com/science/article/pii/S2468227621001009},
author = {Eric Tutu Tchao and David Ato Quansah and Griffith Selorm Klogo and Francis Boafo-Effah and Seth Kotei and Clement Nartey and Willie K. Ofosu},
keywords = {Cloud Computing, Distributed Energy Sources, Smart Grid, Security, Blockchain},
abstract = {Advances in cloud computing and distributed systems are enhancing the advantages that computing delivers to systems that can be integrated with computers due to their multitasking ability. This is already the case when discussing Smart Grid (SG). This enhancement can be applied to drive efficiency in energy management systems in electricity generation, transmission and distribution. As electricity has become the de facto main source of energy worldwide, it is to be expected that all nations, including developing nations such as Ghana, seeks to constantly improve their electrical energy capabilities through the integration of computing and network infrastructure. The integration of SG with cloud computing however presents some complexities which need to be addressed to ensure secure implementation of the SG in the cloud. This paper presents important issues which need to be addressed to ensure security in distributed cloud-based energy systems. The paper also discusses how cloud computing and blockchain could be leveraged to improve on Ghana's current inefficient distribution and transmission networks. An architecture for achieving decentralization in Ghana's grid network is subsequently proposed.}
}
@article{KAMGUEU201810,
title = {Survey on RPL enhancements: A focus on topology, security and mobility},
journal = {Computer Communications},
volume = {120},
pages = {10-21},
year = {2018},
issn = {0140-3664},
doi = {https://doi.org/10.1016/j.comcom.2018.02.011},
url = {https://www.sciencedirect.com/science/article/pii/S0140366417308241},
author = {Patrick Olivier Kamgueu and Emmanuel Nataf and Thomas Djotio Ndie},
keywords = {RPL, Low-power and Lossy Networks, Topology optimization, Mobility, Security, Routing protocol, Internet of Things},
abstract = {A few years ago, the IPv6 Routing Protocol for Low-power and Lossy Networks (RPL) was proposed by IETF as the routing standard designed for classes of networks in which both nodes and their interconnects are constrained. Since then, great attention has been paid by the scientific and industrial communities for the protocol evaluation and improvement. Indeed, depending on applications scenarios, constraints related to the target environments or other requirements, many adaptations and improvements can be made. So, since the initial release of the standard, several implementations were proposed, some targeting specific optimization goals whereas others would optimize several criteria while building the routing topology. They include, but are not limited to, extending the network lifetime, maximizing throughput at the sink node, avoiding the less secured nodes, considering nodes or sink mobility. Sometimes, to consider the Quality of Service (QoS), it is necessary to consider several of those criteria at the same time. This paper reviews recent works on RPL and highlights major contributions to its improvement, especially those related to topology optimization, security and mobility. We aim to provide an insight into relevant efforts around the protocol, draw some lessons and give useful guidelines for future developments.}
}
@article{QIU2019212,
title = {An efficient key distribution system for data fusion in V2X heterogeneous networks},
journal = {Information Fusion},
volume = {50},
pages = {212-220},
year = {2019},
issn = {1566-2535},
doi = {https://doi.org/10.1016/j.inffus.2019.02.002},
url = {https://www.sciencedirect.com/science/article/pii/S1566253518306948},
author = {Han QIU and Meikang QIU and Zhihui LU and Gerard MEMMI},
keywords = {Data fusion, Data trust, Data processing, Security, Heterogeneous network, V2X communication},
abstract = {Data fusion in Vehicle-to-Everything (V2X) networks for different data types coming from different sources is the foundation for decision making in the smart vehicle driving systems. Different communication technologies have been combined to form a heterogeneous V2X network to support the data exchange. However, data fusion trust models are still designed for single use cases which cannot meet the general needs of Cooperative Intelligent Transport Systems (C-ITS). In this paper, we first define a data fusion trust architecture with different trust levels. Then, we propose an efficient and practical data fusion trust system for the multi-source and multi-formats of data exchange in the V2X heterogeneous networks. In particular, a location-based PKI system with acceleration brought by General Purpose Graphic Processing Unit (GPGPU) is presented for efficient key distribution with a high level of trust achieved. A performance evaluation is given to verify our data fusion trust system can meet the strict latency requirements in V2X networks.}
}
@article{GHAEBIPANAH2020101413,
title = {Urban microgrid ancillary service provision using plugin electric vehicle and waste-to-energy CHP},
journal = {Journal of Energy Storage},
volume = {29},
pages = {101413},
year = {2020},
issn = {2352-152X},
doi = {https://doi.org/10.1016/j.est.2020.101413},
url = {https://www.sciencedirect.com/science/article/pii/S2352152X20302334},
author = {Payam {Ghaebi Panah} and Rahmat-Allah Hooshmand and Mehdi Gholipour and Mosayeb Bornapour},
keywords = {Clustering, Crow search algorithm, District heating, Municipal solid waste, Regulating power markets, Waste-to-energy CHP},
abstract = {Today in developed megacities, municipal waste incinerators are a practical solution although they require a relatively high initial investment. On the other hand, E-Transport is growing in metropolitans along with the Renewable Energy Sources (RES). This study proposes an Urban Micro Grid (UMG) consisting of a Waste-to-Energy Combined Heat and Power generation unit (WtE-CHP) and series of Plugin Electric Vehicles (PEV). The main purpose is to provide ancillary services through the incorporation of PEVs as fast-responsive storages. The parking lots may aggregate to form PEV clusters and make bilateral contracts with WtE-CHP to be able to participate in the regulating power markets. A Crow Search Algorithm (CSA) is developed for the UMG operation. In addition, a data analysis section is provided focusing on the behavior of urban drives to extract the realistic probabilities for PEVs available during the daytime. Moreover, the power market of Denmark east (DK2) is considered for the case study of Copenhagen. The results confirm that in case the UMG succeeds in selling the products in the regulating up market, the economic value per MW is remarkably enhanced and the total profit is escalated.}
}
@article{SHAH2022101801,
title = {Can big data analytics help organisations achieve sustainable competitive advantage? A developmental enquiry},
journal = {Technology in Society},
volume = {68},
pages = {101801},
year = {2022},
issn = {0160-791X},
doi = {https://doi.org/10.1016/j.techsoc.2021.101801},
url = {https://www.sciencedirect.com/science/article/pii/S0160791X21002761},
author = {Tushar R. Shah},
keywords = {Big data analytics, Knowledge-based view, Maturity model, Resource-based view, Sustainable competitive advantage, Digital age},
abstract = {Society is changing radically and fast, triggered by the digital revolution. Firms are thus looking for newer ways to attract, satisfy and retain those customers as their needs and aspirations change. Such newer ways constitute the firms’ quest to achieve competitive advantage. However, in this current digital era almost all the traditional “Porterian” competitive advantage barriers are difficult to sustain. Further, COVID has led to a rapid acceleration in the pace of digitalisation. Can the huge data generated in every digitally enabled entity of today be judiciously combined with other firm resources? Can this big data be transformed into meaningful knowledge which organisations can leverage to sustain and grow? Can big data provide a sustainable competitive advantage? In this conceptual paper, I use a knowledge-based approach analysed through resource-based view from the strategic management domain to search for answers to these questions. I introduce a holistic framework that integrates the following: (i) firm knowledge, (ii) managerial capabilities and decision-making, (iii) sustainable competitive advantage, (iv) big data analytics. I call this framework the “The Perpetual Model of BDA as a Sustainable Competitive Advantage”. I also propose a unique Analytic Maturity Model, which I call the SAMDDC-DAMPPC Model, which can help identify and classify firms based on their analytic maturity.}
}
@article{KHAN2017923,
title = {A survey on scholarly data: From big data perspective},
journal = {Information Processing & Management},
volume = {53},
number = {4},
pages = {923-944},
year = {2017},
issn = {0306-4573},
doi = {https://doi.org/10.1016/j.ipm.2017.03.006},
url = {https://www.sciencedirect.com/science/article/pii/S0306457316305994},
author = {Samiya Khan and Xiufeng Liu and Kashish A. Shakil and Mansaf Alam},
keywords = {Scholarly data, Big data, Cloud-based big data analytics, Big scholarly data, Big data platform, Scholarly applications},
abstract = {Recently, there has been a shifting focus of organizations and governments towards digitization of academic and technical documents, adding a new facet to the concept of digital libraries. The volume, variety and velocity of this generated data, satisfies the big data definition, as a result of which, this scholarly reserve is popularly referred to as big scholarly data. In order to facilitate data analytics for big scholarly data, architectures and services for the same need to be developed. The evolving nature of research problems has made them essentially interdisciplinary. As a result, there is a growing demand for scholarly applications like collaborator discovery, expert finding and research recommendation systems, in addition to several others. This research paper investigates the current trends and identifies the existing challenges in development of a big scholarly data platform, with specific focus on directions for future research and maps them to the different phases of the big data lifecycle.}
}
@article{KASWAN2018123,
title = {An efficient scheduling scheme for mobile charger in on-demand wireless rechargeable sensor networks},
journal = {Journal of Network and Computer Applications},
volume = {114},
pages = {123-134},
year = {2018},
issn = {1084-8045},
doi = {https://doi.org/10.1016/j.jnca.2018.02.017},
url = {https://www.sciencedirect.com/science/article/pii/S1084804518300687},
author = {Amar Kaswan and Abhinav Tomar and Prasanta K. Jana},
keywords = {Wireless rechargeable sensor networks, On-demand, Wireless energy transfer, Gravitational search algorithm, Charging schedule, Charging latency},
abstract = {Existing studies on wireless sensor networks (WSNs) have revealed that the limited battery capacity of sensor nodes (SNs) hinders their perpetual operation. Recent findings in the domain of wireless energy transfer (WET) have attracted a lot of attention of academia and industry to cater the lack of energy in the WSNs. The main idea of WET is to restore the energy of SNs using one or more wireless mobile chargers (MCs), which leads to a new paradigm of wireless rechargeable sensor networks (WRSNs). The determination of an optimal order of charging the SNs (i.e., charging schedule) in an on-demand WRSN is a well-known NP-hard problem. Moreover, care must be taken while designing the charging schedule of an MC as requesting SNs introduce both spatial and temporal constraints. In this paper, we first present a Linear Programming (LP) formulation for the problem of scheduling an MC and then propose an efficient solution based on gravitational search algorithm (GSA). Our method is presented with a novel agent representation scheme and an efficient fitness function. We perform extensive simulations on the proposed scheme to demonstrate its effectiveness over two state-of-the-art algorithms, namely first come first serve (FCFS) and nearest job next with preemption (NJNP). The simulation results reveal that the proposed scheme outperforms both the existing algorithms in terms of charging latency. The virtue of our scheme is also proved by the well-known statistical test, analysis of variance (ANOVA), followed by post hoc analysis.}
}
@article{AKILAL2019123,
title = {A robust trust inference algorithm in weighted signed social networks based on collaborative filtering and agreement as a similarity metric},
journal = {Journal of Network and Computer Applications},
volume = {126},
pages = {123-132},
year = {2019},
issn = {1084-8045},
doi = {https://doi.org/10.1016/j.jnca.2018.11.008},
url = {https://www.sciencedirect.com/science/article/pii/S1084804518303679},
author = {Karim Akilal and Hachem Slimani and Mawloud Omar},
keywords = {Online social network, Trust inference, Distrust, Weighted signed network, Collaborative filtering, Agreement},
abstract = {Trust is a very significant notion in social life, and even more in online social networks where people from different cultures and backgrounds interact. Weighted Signed Networks (WSNs) are an elegant representation of social networks, since they are able to encode both positive and negative relations, thus allow to express trust and distrust as we know them in the real world. While many trust inference algorithms exist for traditional unsigned networks, distrust makes it hard to adapt them to WSNs. In this paper, we propose a new unsupervised trust inference algorithm based on collaborative filtering (CF), where we consider the trustors as users, the trustees as items, and agreement as a local similarity metric to predict trust values in signed, and unsigned, networks. In addition to its prediction performances, experiments on four real-world datasets show that our algorithm is very robust to network sparsity.}
}
@article{XUE2021126272,
title = {A two-stage system analysis of real and pseudo urban human settlements in China},
journal = {Journal of Cleaner Production},
volume = {293},
pages = {126272},
year = {2021},
issn = {0959-6526},
doi = {https://doi.org/10.1016/j.jclepro.2021.126272},
url = {https://www.sciencedirect.com/science/article/pii/S0959652621004923},
author = {Qirui Xue and Xiaohua Yang and Feifei Wu},
keywords = {Real and pseudo human settlements, Two-stage model, Empirical orthogonal function (EOF) analysis, K-means clustering, Spatial-temporal distribution, China},
abstract = {Urban human settlements have an important impact on human health, livability and economy. To facilitate objective regionalization and identify impact factors, we established a two-stage model with spatiotemporal analysis and factor analysis. The suitability of urban human settlements and temporal and spatial changes in their characteristics were analyzed using the urban real human settlements (RHS) index and pseudo human settlements (PHS) index. Annual RHS and PHS values were calculated using panel data for 31 Chinese provinces and cities and Baidu search query data covering 2557 days. The findings were as follows: (1) The urban RHS and PHS indexes decrease from the southeastern coastal area to the northwestern inland area (excluding Beijing City). (2) The urban RHS index is larger than the PHS index, and the two indexes have a positive correlation, with an average correlation coefficient of 0.7 over 7 years. (3) Population size, social development and environmental governance are the main factors affecting the urban RHS and PHS indexes. (4) The urban RHS and PHS indexes fluctuate, and the values vary unevenly across space. Our research results can help policymakers identify the key factors affecting urban human settlements so that they can make better decisions.}
}
@article{MA2020107937,
title = {Optimization on the intellectual monitoring system for structures based on acoustic emission and data mining},
journal = {Measurement},
volume = {163},
pages = {107937},
year = {2020},
issn = {0263-2241},
doi = {https://doi.org/10.1016/j.measurement.2020.107937},
url = {https://www.sciencedirect.com/science/article/pii/S0263224120304759},
author = {Guofeng Ma and Qingjuan Du},
keywords = {Acoustic emission, Structural health monitoring, Sensors, Data mining, Fog node, Building information model},
abstract = {Structures show their health information through various forms during their service. Acoustic emission (AE) sensors can capture the relevant information, but fail to realize their value fully. AE, data mining (DM) and cloud computing have promoted the development of centralized management of structures health management (SHM) but accompanied by the slow response, high requirement for computing capacity. This paper puts forward an innovative concept combining AE, DM on fog computing and centralized management to improve these problems. Firstly, raw data are collected by the AE sensors system and transformed into fog node for DM, including removing useless data, consolidating, organizing, and visualizing the result. Then the concise results will be integrated into a data center for centralized management and visualization. This idea is verified by a case study. It includes both a systematic experiment and a real-world application. The test conducts two groups of beams according to actual bridges and gives two parameters analysis of the experiment data to find the characteristics between signals and performance. Then the results are applied into two real bridges for practical application and detect a critical point. It not only explains how this new concept works but also has practical significance for engineering managers.}
}
@article{ZHANG2021107555,
title = {Enhanced Jaya algorithm: A simple but efficient optimization method for constrained engineering design problems},
journal = {Knowledge-Based Systems},
volume = {233},
pages = {107555},
year = {2021},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2021.107555},
url = {https://www.sciencedirect.com/science/article/pii/S0950705121008170},
author = {Yiying Zhang and Aining Chi and Seyedali Mirjalili},
keywords = {Jaya algorithm, Swarm intelligence, Evolutionary computing, Global optimization, Metaheuristics},
abstract = {Jaya algorithm (JAYA) is a new metaheuristic algorithm, which has a very simple structure and only requires population size and terminal condition for optimization. Given the two features, JAYA has been widely used to solve various types of optimization problems. However, JAYA may easily get trapped in local optima for solving complex optimization problems due to its single learning strategy with little population information. To improve the global search ability of JAYA, this work proposes an enhanced Jaya algorithm (EJAYA) for global optimization. In EJAYA, the local exploitation is based on defined upper and lower local attractors and global exploration is guided by historical population. Like JAYA, EJAYA does notneed any effort for fine tuning initial parameters. To check the performance of the proposed EJAYA, EJAYA is first used to solve 45 test functions extracted from the well-known CEC 2014 and CEC 2015 test suites. Then EJAYA is employed to solve seven challenging real-world engineering design optimization problems. Experimental results support the strong ability of EJAYA to escape from the local optimum for solving complex optimization problems and the effectively of the introduced improved strategies to JAYA. Note that, the source codes of the proposed EJAYA are publicly available at https://ww2.mathworks.cn/matlabcentral/fileexchange/88877-enhanced-jaya-algorithm-for-global-optimization.}
}
@article{LI2020101701,
title = {Privacy-preserving self-serviced medical diagnosis scheme based on secure multi-party computation},
journal = {Computers & Security},
volume = {90},
pages = {101701},
year = {2020},
issn = {0167-4048},
doi = {https://doi.org/10.1016/j.cose.2019.101701},
url = {https://www.sciencedirect.com/science/article/pii/S016740481930238X},
author = {Dong Li and Xiaofeng Liao and Tao Xiang and Jiahui Wu and Junqing Le},
keywords = {Self-serviced medical diagnosis, Internet + intelligent medical diagnosis, Privacy-preserving, Privacy-preserving access control, Homomorphic encryption, Secure multi-party computation},
abstract = {With the development of the “Internet + Intelligent Medical”, patients can online diagnose some common diseases via the Internet. However, during the diagnostic process, there exist many severe problems on privacy for medical sensitive data of patients. To solve these problems, in this paper, we present a new privacy-preserving self-serviced medical diagnosis scheme based on secure multi-party computation (SMC). In our scheme, a registered patient first encrypts his/her medical health data and sends it to the hospital server, then the hospital server calculates the similarity value between the patient’s medical health data and the trait vector of hospital disease. Finally, the hospital server searches for the disease that matches the patient according to the calculated similarity value, and sends the treatment method of this disease to the patient. Specifically, based on homomorphic encryption (HE) and privacy-preserving access control, our self-serviced medical diagnosis scheme can achieve privacy preservation of patient’s medical health data and confidentiality of hospital diagnosis mode. Through detailed security analysis, we show that our scheme can resist various known security threats. In addition, our scheme not only reduces the cost of treatment for the patients and relieves the hospitals’ heavy pressure in the course of diagnosis, but can also predict other diseases of the patients, which can make the patients a more clear understanding of their current physical condition, and the patients can obtain the most appropriate treatment.}
}
@article{CONTI20151,
title = {From MANET to people-centric networking: Milestones and open research challenges},
journal = {Computer Communications},
volume = {71},
pages = {1-21},
year = {2015},
issn = {0140-3664},
doi = {https://doi.org/10.1016/j.comcom.2015.09.007},
url = {https://www.sciencedirect.com/science/article/pii/S0140366415003412},
author = {Marco Conti and Chiara Boldrini and Salil S. Kanhere and Enzo Mingozzi and Elena Pagani and Pedro M. Ruiz and Mohamed Younis},
keywords = {MANET, Mesh networks, Opportunistic networks, Vehicular networks, Sensor networks},
abstract = {In this paper, we discuss the state of the art of (mobile) multi-hop ad hoc networking with the aim to present the current status of the research activities and identify the consolidated research areas, with limited research opportunities, and the hot and emerging research areas for which further research is required. We start by briefly discussing the MANET paradigm, and why the research on MANET protocols is now a cold research topic. Then we analyze the active research areas. Specifically, after discussing the wireless-network technologies, we analyze four successful ad hoc networking paradigms, mesh networks, opportunistic networks, vehicular networks, and sensor networks that emerged from the MANET world. We also present an emerging research direction in the multi-hop ad hoc networking field: people centric networking, triggered by the increasing penetration of the smartphones in everyday life, which is generating a people-centric revolution in computing and communications.}
}
@article{LIU2020457,
title = {Privacy-preserving matrix product based static mutual exclusive roles constraints violation detection in interoperable role-based access control},
journal = {Future Generation Computer Systems},
volume = {109},
pages = {457-468},
year = {2020},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2018.10.017},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X17320551},
author = {Meng Liu and Yun Luo and Chi Yang and Shaoning Pang and Deepak Puthal and Kaijun Ren and Xuyun Zhang},
keywords = {Privacy-preserving, Secure multi-party computation, Matrix product, Homomorphic cryptosystem, Statically mutually exclusive roles},
abstract = {Secure interoperation is an important technology to protect shared data in multi-domain environments. IRBAC (Interoperable Role-based Access Control) 2000 model has been proposed to achieve security interoperation between two or more RBAC administrative domains. Static Separation of Duties (SSoD) is an important security policy in RBAC, but it has not been enforced in the IRBAC 2000 model. As a result, some previous works have studied the problem of SMER (Statically Mutually Exclusive Roles) constraints violation between two RBAC domains in the IRBAC 2000 model. However all of them do not enforce how to preserve privacy of RBAC policies, such as roles, roles hierarchies and user-role assignment while detecting SMER constraints violation, if the two interoperable domains do not want to disclose them each other and to others. In order to enforce privacy-preserving detection of SMER constraints violation, we first introduce a solution without privacy-preserving mechanism using matrix product. Then a privacy-preserving solution is proposed to securely detect SMER constraints violation without disclosing any RBAC policy based on a secure three-party protocol to matrix product computation. By efficiency analysis and experimental results comparison, the secure three-party computation protocol to matrix product based on the Paillier cryptosystem is more efficient and practical.}
}
@article{BERTOK2020118520,
title = {Renewable energy storage and distribution scheduling for microgrids by exploiting recent developments in process network synthesis},
journal = {Journal of Cleaner Production},
volume = {244},
pages = {118520},
year = {2020},
issn = {0959-6526},
doi = {https://doi.org/10.1016/j.jclepro.2019.118520},
url = {https://www.sciencedirect.com/science/article/pii/S0959652619333906},
author = {Botond Bertok and Aniko Bartos},
keywords = {P-Graph, Optimization, Microgrid, Renewable energy, Power generation, Scheduling},
abstract = {In developing countries such as in Africa, rural areas are not always connected to the national or regional electric grid. As there is a huge potential for solar energy production, photovoltaics are established to supply electricity for operating critical infrastructures with battery systems and diesel generators installed for redundancy. These systems have the potential for further utilization. As a first step, overproduction of solar energy is offered to households due to simple control rules observing battery levels. This paper proposes an optimization method for energy allocation by process graphs or P-graphs. The method provides preliminary estimations on optimal periodical energy balances between energy producers, storage, and consumers of different priorities. These preliminary estimations serve as reconciliation parameters for advanced real-time control of energy distribution. Each step of transforming the practical problem of multiperiod energy distribution to the language of process network synthesis and then optionally to mathematical programming is detailed. To represent the problem adequately, the original formulation of process network synthesis is extended to take into account potential targets and intermediate entities that cannot be accumulated. The work aims to provide better utilization of renewable energy sources and storage. The microgrid profit and return of investment can also be improved by the proposed methodology.}
}
@article{PETRAKIS2018156,
title = {Internet of Things as a Service (iTaaS): Challenges and solutions for management of sensor data on the cloud and the fog},
journal = {Internet of Things},
volume = {3-4},
pages = {156-174},
year = {2018},
issn = {2542-6605},
doi = {https://doi.org/10.1016/j.iot.2018.09.009},
url = {https://www.sciencedirect.com/science/article/pii/S2542660518300350},
author = {Euripides G.M. Petrakis and Stelios Sotiriadis and Theodoros Soultanopoulos and Pelagia Tsiachri Renta and Rajkumar Buyya and Nik Bessis},
keywords = {Cloud computing, Internet of Things, Fog computing, Remote patient monitoring, Health sensors},
abstract = {Building upon cloud, IoT and smart sensors technologies we design and develop an IoT as a Service (iTaaS) framework, that transforms a user’s mobile device (e.g. a smart phone) to an IoT gateway which allows for fast and efficient data streams transmission to the cloud. We develop a two-fold solution, based on micro-services for the IoT (users’ smart devices) and the cloud side (back-end services). iTaaS includes configurations for (a) the IoT side to support data collection from IoT devices to a gateway on a real time basis and, (b) the cloud back-end side to support data sharing, storage and processing. iTaaS provides the technology foreground to enable immediate application deployments in the domain of interest. An obvious and promising implementation of this technology is e-Health and remote health monitoring. As a proof of concept we implement a real time remote patient monitoring system that integrates the proposed framework and uses Bluetooth Low Energy (BLE) pulse oximeter and heart rate monitoring sensing devices. The experimental analysis shows fast data collection, as (for our experimental setup) data is transmitted from the IoT side (i.e. the gateway) to the cloud in less than 130 ms. We also stress the back-end system with high user concurrency (e.g. with 40 users per second) and high data streams (e.g. 240 data records per second) and we show that the requests are executed at around 1 s, a number that signifies a satisfactory performance by considering the number of requests, the network latency and the relatively small size of the Virtual Machines implementing services on the cloud (2 GB RAM, 1 CPU and 20 GB hard disk size).}
}
@article{OLMEDILLA2019133,
title = {Identification of the unique attributes and topics within Smart Things Open Innovation Communities},
journal = {Technological Forecasting and Social Change},
volume = {146},
pages = {133-147},
year = {2019},
issn = {0040-1625},
doi = {https://doi.org/10.1016/j.techfore.2019.05.004},
url = {https://www.sciencedirect.com/science/article/pii/S0040162518308114},
author = {M. Olmedilla and H. Send and S.L. Toral},
keywords = {Text mining, Unique innovations, Open communities, Unique attributes, Co-occurrence analysis, Open innovation},
abstract = {One of the main challenges of open innovation communities is how to create value from shared content either by selecting those ideas that are worthy of pursuit and implementation or by identifying the users' preferences and needs. These tasks can be done manually when there is an overseeable amount of content or by using computational tools when there are massive amounts of data. However, previous studies on text mining have not dealt with the identification of unique attributes, which can be defined as those contributions that are inextricably linked with a specific tag or category within open innovation websites. The uniqueness of these ideas means that they can only be obtained through a selection of one choice among several alternatives. To obtain such unique ideas and thus to also obtain innovations, this paper proposes a novel methodology called co-occurrence differential analysis. The proposed methodology combines traditional co-occurrence analysis with additional statistical processing to obtain the unique attributes and topics associated with different alternatives. The identification of unique content provides valuable information that can reveal the strengths and weaknesses of several options in a comparative fashion.}
}
@article{DURAO201925,
title = {Current and future state of Portuguese organizations towards digital transformation},
journal = {Procedia Computer Science},
volume = {164},
pages = {25-32},
year = {2019},
note = {CENTERIS 2019 - International Conference on ENTERprise Information Systems / ProjMAN 2019 - International Conference on Project MANagement / HCist 2019 - International Conference on Health and Social Care Information Systems and Technologies, CENTERIS/ProjMAN/HCist 2019},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2019.12.150},
url = {https://www.sciencedirect.com/science/article/pii/S1877050919321891},
author = {Natércia Durão and Maria João Ferreira and Carla Santos Pereira and Fernando Moreira},
keywords = {Digital transformation, Agility, Four pillars, Innovation accelerators, Technology, Business processes},
abstract = {In recent years, digital transformation has emerged as a phenomenon that contributes to the transition from the industrial era to an era of connected and intelligent products, causing great impact on organizations and society. This transformation is revolutionizing, not only on the way people work, but also stresses the need to find new ways of combining physical and digital innovations and interorganizational collaborations in order to foster organizations’ success. The research work presented allows increasing the understanding of specific aspects of the phenomenon of digital transformation (DT). From this research it is possible to understand that the technology itself is just part of a complex puzzle, that must be solved in order for organizations to remain competitive in a digital world. It is fundamental to see if organizations in Portugal are already living the mentioned DT or if they are aware of the need to adapt to this new reality. In this context, the objective of this research is to evaluate and compare, in Portuguese organizations, the current state of digital adoption in light of their preparation in relation to the prevailing technological categories (pillars and innovation accelerators), with the future priorities of the organizations in the DT implementation.}
}
@article{KARRI2018395,
title = {Modeling airborne indoor and outdoor particulate matter using genetic programming},
journal = {Sustainable Cities and Society},
volume = {43},
pages = {395-405},
year = {2018},
issn = {2210-6707},
doi = {https://doi.org/10.1016/j.scs.2018.08.015},
url = {https://www.sciencedirect.com/science/article/pii/S2210670718301331},
author = {Rama Rao Karri and Behzad Heibati and Yusri Yusup and Mohd Rafatullah and Mahmoud Mohammadyan and J.N. Sahu},
keywords = {Air quality, Airborne particles, Particulate matter, Modeling, Genetic programming},
abstract = {Airborne particulate matter (PM) is considered to be an essential indicator of outdoor and indoor air quality. In this study, indoor and outdoor PM1, PM2.5, PM10 concentrations were monitored at different locations within the Tehran University campus. It is found that 10% of PM1, PM2.5 and PM10 concentrations were higher than 36.11, 52.48 and 92.13 μg/m3 for indoors respectively. Genetic programming (GP) based methodology is implemented to identify the influence of outdoor PM on the indoor PM and established significant empirical models. The best GP model is identified based on fitness measure and root mean square error. It was observed that the GP based models are perfectly able to mimic the behavioural trends of outdoor particulate matter for PM1, PM2.5 and PM10 concentrations. The model predictions are very similar to the measured values and their variation was less than ± 8%. This analysis confirms the performance of GP based data driven modeling approach to predict the relationship between the outdoor particulate matter and its influence on the indoor particulate matter concentration.}
}
@article{HAKAK201922,
title = {Cloud-assisted gamification for education and learning – Recent advances and challenges},
journal = {Computers & Electrical Engineering},
volume = {74},
pages = {22-34},
year = {2019},
issn = {0045-7906},
doi = {https://doi.org/10.1016/j.compeleceng.2019.01.002},
url = {https://www.sciencedirect.com/science/article/pii/S0045790618304968},
author = {Saqib Hakak and Nurul Fazmidar Mohd Noor and Mohamad Nizam Ayub and Hannyzurra Affal and Nornazlita Hussin and Ejaz ahmed and Muhammad Imran},
keywords = {Gamification, Cloud computing, Education, Game-based learning, Mobile learning},
abstract = {Gamification has gained considerable interest in education circles due to its capability of enhancing the learning process among students. In the future, it is expected that gamification will overtake the traditional way of learning resulting in issues such as scalability, upgradation of learning modules. To address these issues, merging gamification with cloud computing seems a viable solution. However, the employability of gamification through cloud computing is still in its infant stage. Hence, this article investigates the applicability of gamification through cloud computing and presents a comprehensive survey of state-of-the-art gamification in education and learning. We also identify the subject areas that can be gamified and taught using the cloud service. The critical elements and minimum requirements necessary to gamify education are also identified. Moreover, a specific cloud-assisted gamification architecture is proposed and discussed together with its possible applications. The article is concluded with the research challenges and suggestions for future work.}
}
@article{IBRAHIM2020106791,
title = {A fog based recommendation system for promoting the performance of E-Learning environments},
journal = {Computers & Electrical Engineering},
volume = {87},
pages = {106791},
year = {2020},
issn = {0045-7906},
doi = {https://doi.org/10.1016/j.compeleceng.2020.106791},
url = {https://www.sciencedirect.com/science/article/pii/S0045790620306455},
author = {Taghreed S. Ibrahim and Ahmed I. Saleh and Nehad Elgaml and Mohamed M. Abdelsalam},
keywords = {Fog computing, Recommendation system, Association rules mining, Information gain, Weighting method, Ontology and fuzzy logic},
abstract = {Recently, Recommendation Systems (RSs) have gained a great interest. E-Learning is one of the most important working fields of RS in which many challenges that hinder users in discovering the most appropriate materials can be overcome. The fog computing technique can enrich E-Learning based RS as it bridges the gap between; the cloud and end devices. In this paper, we propose Fog based Recommendation System (FBRS), which can be successfully utilized for promoting the performance of the E-Learning environment. We discuss a framework to consolidate and improve EL environment through defining three modules of FBRS: (i) Class Identification Module (CIM), (ii) Subclass Identification Module (SIM), and (iii) Matchmaking Module (MM). Moreover, the FBRS approach achieves a high response time and security to overcome both personalization and synonymy. Experimental results show that FBRS outperforms are recent techniques in terms of recommendation accuracy.}
}
@article{CAPOZZOLI2018336,
title = {Automated load pattern learning and anomaly detection for enhancing energy management in smart buildings},
journal = {Energy},
volume = {157},
pages = {336-352},
year = {2018},
issn = {0360-5442},
doi = {https://doi.org/10.1016/j.energy.2018.05.127},
url = {https://www.sciencedirect.com/science/article/pii/S0360544218309617},
author = {Alfonso Capozzoli and Marco Savino Piscitelli and Silvio Brandi and Daniele Grassi and Gianfranco Chicco},
keywords = {Energy consumption, Building energy management, Adaptive symbolic aggregate approximation, Anomaly detection, Data mining, Smart buildings},
abstract = {The energy management of buildings currently offers a powerful opportunity to enhance energy efficiency and reduce the mismatch between the actual and expected energy demand, which is often due to an anomalous operation of the equipment and control systems. In this context, the characterisation of energy consumption patterns over time is of fundamental importance. This paper proposes a novel methodology for the characterisation of energy time series in buildings and the identification of infrequent and unexpected energy patterns. The process is based on an enhanced Symbolic Aggregate approXimation (SAX) process, and it includes an optimised tuning of the time window width and of the symbol intervals according to the building energy behaviour. The methodology has been tested on the whole electrical load of buildings for two case studies, and its flexibility and robustness have been confirmed. In order to demonstrate the implications for a preliminary diagnosis, some unexpected trends of the total electrical load have also been discussed in a post-mining phase, using additional datasets related to heating and cooling electrical energy needs. The process can be used to support stakeholders in characterising building behaviour, to define appropriate energy management strategies, and to send timely alerts based on anomaly detection outcomes.}
}
@article{KUANG2020101945,
title = {DO-RA: Data-oriented runtime attestation for IoT devices},
journal = {Computers & Security},
volume = {97},
pages = {101945},
year = {2020},
issn = {0167-4048},
doi = {https://doi.org/10.1016/j.cose.2020.101945},
url = {https://www.sciencedirect.com/science/article/pii/S0167404820302212},
author = {Boyu Kuang and Anmin Fu and Lu Zhou and Willy Susilo and Yuqing Zhang},
keywords = {Internet of things, Remote attestation, Software integrity, Control flow graph, Unique code target},
abstract = {Remote attestation is an excellent approach to confirm the security states of Internet of Things (IoT) devices. It allows an entity (verifier) to validate the integrity of a potentially compromised platform (prover). Most of the current attestation schemes are static, which verify only the software integrity of devices. Recently, some runtime attestation schemes based on the Control Flow Graph (CFG) of the program have been proposed to collect the runtime information. However, the algorithm for constructing CFG only focuses on the rationality of the programs’ control flow, and ignores the possibility that attackers could compromise the control flow of the device by modifying key data. Some mitigation of runtime exploitation technologies take into account the Unique Code Target (UCT) property of control flow, but there are limitations to their algorithms abilities to find out the constraining data. In this paper, we present a Data-Oriented Control Flow Graph (DO-CFG) that can match a single legitimate target for each control-flow transfer, which guarantees both the rationality and the full uniqueness of programs’ control flow. Furthermore, we propose a Data-Oriented Runtime Attestation (DO-RA) scheme based on DO-CFG. It collects some critical non-control data to enhance the detection ability of the attestation scheme, which further ensures the uniqueness of the control flow. We also present a detailed proof-of-concept implementation and analyze our protocol based on Raspberry Pi. We simulate several real applications to evaluate the security and performance of DO-RA, which demonstrates that our scheme provides a more comprehensive detection capability within an acceptable overhead.}
}
@article{YUMLU2015198,
title = {Bayesian changepoint and time-varying parameter learning in regime switching volatility models},
journal = {Digital Signal Processing},
volume = {40},
pages = {198-212},
year = {2015},
issn = {1051-2004},
doi = {https://doi.org/10.1016/j.dsp.2015.02.001},
url = {https://www.sciencedirect.com/science/article/pii/S1051200415000433},
author = {M. Serdar Yümlü and Fikret S. Gürgen and A. Taylan Cemgil and Nesrin Okay},
keywords = {Multiple Changepoint Detection (MCD), Sequential Monte Carlo (SMC) methods, Particle Filtering (PF), Auxiliary Particle Filtering (APF), Exponential Generalized Autoregressive Conditional Heteroskedasticity (EGARCH), Volatility modeling},
abstract = {This paper proposes a combined state and piecewise time-varying parameter learning technique in regime switching volatility models using multiple changepoint detection. This approach is a Sequential Monte Carlo method for estimating GARCH & EGARCH based volatility models with an unknown number of changepoints. Modern auxiliary particle filtering techniques are used to calculate the posterior densities and online forecasts. This approach also automatically deals with the common ancestral path dependence problem faced in these type volatility models. The model is tested on Borsa Istanbul (BIST) formerly known as Istanbul Stock Exchange (ISE) market data using daily log returns. A full structural changepoint specification is defined in which all parameters of the conditional variance of the volatility models are dynamic. Finally, it is shown with simulation experiments that the proposed approach partitions the series into several regimes and learns the parameters of each regime's volatility model in parallel with the multiple changepoint detection process.}
}
@article{PETRONI2017202,
title = {Exploiting user feedback for online filtering in event-based systems},
journal = {Future Generation Computer Systems},
volume = {71},
pages = {202-211},
year = {2017},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2016.10.017},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X16304125},
author = {Fabio Petroni and Leonardo Querzoni and Roberto Beraldi and Mario Paolucci},
keywords = {Event-based systems, Recommendation systems, Content filtering, Distributed systems},
abstract = {Modern large-scale internet applications represent today a fundamental source of information for millions of users. The larger is the user base, the more difficult it is to control the quality of data that is spread from producers to consumers. This can easily hamper the usability of such systems as the amount of low quality data received by consumers grows uncontrolled. In this paper we propose a novel solution to automatically filter new data injected in event-based systems with the aim of delivering only content consumers are actually interested in. Filtering is executed by profiling producers and consumers, and matching their profiles as new data is produced. Profiles are built by aggregating feedback submitted by consumers on previously received data.}
}
@article{ARRIBASBEL2013248,
title = {Benchmarking of world cities through Self-Organizing Maps},
journal = {Cities},
volume = {31},
pages = {248-257},
year = {2013},
issn = {0264-2751},
doi = {https://doi.org/10.1016/j.cities.2012.06.019},
url = {https://www.sciencedirect.com/science/article/pii/S0264275112001151},
author = {Daniel Arribas-Bel and Karima Kourtit and Peter Nijkamp},
keywords = {Urbanisation, World cities, Self-Organizing Maps, Benchmarking},
abstract = {This paper argues that there is a global trend towards the highest possible performance among functionally specialized and heterogeneous world cities in different parts of our world. It aims to map out the relative disparities in competitive performance among a preselected set of major global cities by offering a hierarchical benchmark analysis of these cities on the basis of a recently completed comparative study on their socio-economic ‘power’, as exerted and/or perceived by various groups of relevant urban stakeholders. The analytical tool employed to highlight and better understand the relative (hierarchical) position of these cities from a topological perspective is based on Self-Organizing Maps (SOMs), which depict in a multidimensional space the similarities among the cities under consideration. The empirical results are presented and interpreted from the perspective of a benchmark ranking of the various cities involved, while finally also an actor-oriented analysis of the distinct performance components of these cities is provided.}
}
@article{FAN2020119181,
title = {Optimisation and process design tools for cleaner production},
journal = {Journal of Cleaner Production},
volume = {247},
pages = {119181},
year = {2020},
issn = {0959-6526},
doi = {https://doi.org/10.1016/j.jclepro.2019.119181},
url = {https://www.sciencedirect.com/science/article/pii/S095965261934051X},
author = {Yee Van Fan and Hon Huin Chin and Jiří Jaromír Klemeš and Petar Sabev Varbanov and Xia Liu},
abstract = {Assessments of hotspot analysis and process optimisation followed by improved design are essential to achieve cleaner production. Cleaner production also involves complex interactions with economic and social performance. It plays a substantial role in sustainable development. This contribution presents an overview of cleaner production achievements and selection of relevant recent work dealing with optimisation tools and process design as published in the Special Issue on Process Integration and Intensification for Sustainable Evolution via Resource and Emission Reduction. The cleaner production tools including Pinch Analysis, Process Graph, Artificial Intelligence and computer-aided modelling, are reviewed. The roles of waste streams as secondary resources process design in cleaner production and circular economy is also discussed. The highlights of the recent development contribute to the field of study by drawing out the attention for potential future research.}
}
@article{MOTLAGH2015165,
title = {Analysis of household electricity consumption behaviours: Impact of domestic electricity generation},
journal = {Applied Mathematics and Computation},
volume = {270},
pages = {165-178},
year = {2015},
issn = {0096-3003},
doi = {https://doi.org/10.1016/j.amc.2015.08.029},
url = {https://www.sciencedirect.com/science/article/pii/S009630031501084X},
author = {Omid Motlagh and Phillip Paevere and Tang Sai Hong and George Grozev},
keywords = {Demand side management, Renewables, Rooftop solar electricity, Domestic electricity Generation, Rebound effect, Self-Consumption},
abstract = {Adoption of renewable electricity generation technologies such as photovoltaic (PV) systems is at the early majority stage in most developed countries. Depending on solar capacity, applied feed-in tariff, and other factors, households exhibit different electricity consumption behaviours which can potentially assist in Demand Side Management (DSM) of electricity usage. This article presents three univariate analysis methods to infer deliberative behavioural patterns at households with solar electricity generation capacity. Analysis methods include qualitative Principal Component Analysis (PCA), unsupervised Hebbian-based clustering, and clustering using a semi-supervised Self-Organising Map (SOM). The techniques are individually applied to 300 sample households with rooftop PV panels operating under a Gross Metering (GM) scheme. According to the PCA, the dominant behaviours are often general among most households, and therefore reveal themselves on first and second principal components. However, on the third and fourth components some specific household behaviours related to load-shifting and self-consumption, are observed. The Hebbian model differentiates between at least eight behaviour types, some of which indicate deliberative behaviours by the households. Most effectively, SOM clustering clearly detects a self-consumption behaviour attributed to domestic electricity generation. A control group of 400 households is analysed to ensure uniqueness of the self-consumption behaviour to customers with solar PV installed. The techniques developed herein may be able to be used by electricity utilities to assess the influence that future tariff and technology offerings will have on behavioural aspects of customer electricity consumption.}
}
@article{GU2019105,
title = {Compressive sampling optimization for user signal parameter estimation in massive MIMO systems},
journal = {Digital Signal Processing},
volume = {94},
pages = {105-113},
year = {2019},
note = {Special Issue on Source Localization in Massive MIMO},
issn = {1051-2004},
doi = {https://doi.org/10.1016/j.dsp.2019.06.010},
url = {https://www.sciencedirect.com/science/article/pii/S1051200419300806},
author = {Yujie Gu and Yimin D. Zhang},
keywords = {Adaptive beamforming, Compressive sampling optimization, Massive MIMO, Mutual information, Parameter estimation},
abstract = {As the most promising technology in wireless communications, massive multiple-input multiple-output (MIMO) faces a significant challenge in practical implementation because of the high complexity and cost involved in deploying a separate front-end circuit for each antenna. In this paper, we apply the compressive sampling technique to reduce the number of required front-end circuits in the analog domain and the computational complexity in the digital domain. Unlike the commonly adopted random projections, we exploit the a priori probability distribution of the user positions to optimize the compressive sampling strategy, so as to maximize the mutual information between the compressed measurements and the direction-of-arrival (DOA) of user signals. With the optimized compressive sampling strategy, we further propose a compressive sampling Capon spatial spectrum estimator for DOA estimation. In addition, the user signal power is estimated by solving a compressed measurement covariance matrix fitting problem. Furthermore, the user signal waveforms are estimated from a robust adaptive beamformer through the reconstruction of an interference-plus-noise compressed covariance matrix. Simulation results clearly demonstrate the performance advantages of the proposed techniques for user signal parameter estimation as compared to existing techniques.}
}
@article{BHARDWAJ20178,
title = {Security challenges for cloud-based email infrastructure},
journal = {Network Security},
volume = {2017},
number = {11},
pages = {8-15},
year = {2017},
issn = {1353-4858},
doi = {https://doi.org/10.1016/S1353-4858(17)30094-6},
url = {https://www.sciencedirect.com/science/article/pii/S1353485817300946},
author = {Akashdeep Bhardwaj and Sam Goundar},
abstract = {Over the past few years, the recognition and acceptance of cloud-based applications has gained a lot of momentum. Commercial applications that were initially installed inside corporate on-premises server rooms are now hosted on cloud infrastructures. Software applications are provided in the form of commercial services that are accessible anytime, anywhere. Cloud-based solutions also eliminate the need for regular maintenance-related activities, unnecessary downtimes or outages, attention to back-ups or regular infrastructure upgrades. Commercial applications that were initially installed inside corporate server rooms are now hosted on cloud infrastructures, accessible anytime, anywhere. However, mitigating cloud-based security risks requires that service providers and corporate users adopt a universal approach for ensuring that the right solution is in place, especially when application services used over insecure Internet connections raise new risks. Akashdeep Bhardwaj and Sam Goundar examine the kinds of threats facing cloud-based email systems and the mitigations available.}
}
@article{ALMAADEED2016238,
title = {Low-quality facial biometric verification via dictionary-based random pooling},
journal = {Pattern Recognition},
volume = {52},
pages = {238-248},
year = {2016},
issn = {0031-3203},
doi = {https://doi.org/10.1016/j.patcog.2015.09.031},
url = {https://www.sciencedirect.com/science/article/pii/S0031320315003623},
author = {Somaya Al-Maadeed and Mehdi Bourif and Ahmed Bouridane and Richard Jiang},
keywords = {Facial biometrics, Low resolution, Sparse coding, Random pooling, Kernel LDA, Visual surveillance},
abstract = {In the past decade, visual surveillance has emerged as an effective tool in public security applications. Due to the technical limitations of both surveillance cameras and transmission speed, videos collected from surveillance sites are usually of low resolution. Especially, facial images at a distance in surveillance videos are usually at very low quality, making it difficult to carry out automated facial biometric verification. To handle with this challenge, in this work, we introduce dictionary based techniques to cope with low quality facial images, and propose a random pooling scheme to enhance the accuracy of facial biometric verification. In the proposed scheme, a dictionary is first learned from paired low-resolution and high-resolution facial images, and the input low-resolution query face can then be modelled by a set of high-resolution visual words via a dictionary lookup. A random pooling strategy is then applied to select subsets of visual words, and kernel Fisher׳s linear discriminant analysis (k-LDA) is introduced to find the discriminant metrics. The final decision is based on the average over different pooling results. The experiment on three publically available face datasets validated that our proposed scheme can robustly cope with the challenges from low quality facial images, and attained an improved accuracy over all datasets, making our method a promising candidate for facial biometric based security applications.}
}
@article{XU2019522,
title = {A computation offloading method over big data for IoT-enabled cloud-edge computing},
journal = {Future Generation Computer Systems},
volume = {95},
pages = {522-533},
year = {2019},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2018.12.055},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X18319770},
author = {Xiaolong Xu and Qingxiang Liu and Yun Luo and Kai Peng and Xuyun Zhang and Shunmei Meng and Lianyong Qi},
keywords = {IoT, Big data, Cloud-edge computing, Computation offloading, Energy consumption},
abstract = {The Internet of mobile things is a burgeoning technique that generates, stores and processes big real-time data to render rich services for mobile users. In order to mitigate conflicts between the resource limitation of mobile devices and users’ demands of decreasing processing latency as well as prolonging battery life, it spurs a popular wave of offloading mobile applications for execution to centralized and decentralized data centers, such as cloud and edge servers. Due to the complexity and difference of mobile big data, arbitrarily offloading the mobile applications poses a remarkable challenge to optimizing the execution time and the energy consumption for mobile devices, despite the improved performance of Internet of Things (IoT) in cloud-edge computing. To address this challenge, we propose a computation offloading method, named COM, for IoT-enabled cloud-edge computing. Specifically, a system model is investigated, including the execution time and energy consumption for mobile devices. Then dynamic schedules of data/control-constrained computing tasks are confirmed. In addition, NSGA-III (non-dominated sorting genetic algorithm III) is employed to address the multi-objective optimization problem of task offloading in cloud-edge computing. Finally, systematic experiments and comprehensive simulations are conducted to corroborate the efficiency of our proposed method.}
}
@article{PHAM20181,
title = {AD3-GLaM: A cooperative distributed QoE-based approach for SVC video streaming over wireless mesh networks},
journal = {Ad Hoc Networks},
volume = {80},
pages = {1-15},
year = {2018},
issn = {1570-8705},
doi = {https://doi.org/10.1016/j.adhoc.2018.07.005},
url = {https://www.sciencedirect.com/science/article/pii/S157087051830461X},
author = {Tran Anh Quang Pham and Kamal Deep Singh and Juan Antonio Rodríguez-Aguilar and Gauthier Picard and Kandaraj Piamrat and Jesús Cerquides and César Viho},
keywords = {QoE, SVC video streaming, Distributed, Wireless mesh networks},
abstract = {We study the routing problem of scalable video coding video streaming over wireless mesh networks. In contrast to most of the conventional routing algorithms, our proposal focuses on optimizing users’ satisfaction. The mean opinion score –an indicator of quality of experience (QoE) in video streaming– is utilized to assess the quality of routes in wireless mesh networks. The objective is to optimize the overall user experience in the network. Conventional routing approaches do not consider QoE and are not optimal with respect to user experience. Moreover, some centralized approaches are not scalable and require significant computational resources. The latter disadvantage can be overcome using distributed approaches. This paper presents a QoE-based cooperative distributed routing approach. Among distributed cooperative optimization schemes, AD3 is highlighted as one of the most efficient because of its fast convergence. The contributions of this paper are as follows: we encode the original problem into a factor graph and optimize the number of exchanged messages; we propose a partially distributed routing scheme based on OLSR and AD3; and we propose a distributed decoding algorithm in order to find a feasible solution. Our thorough simulation results confirm the advantages of the proposed scheme.}
}
@article{WU2021126684,
title = {A comprehensive obstacle analysis framework on dispersed wind power: A case of China},
journal = {Journal of Cleaner Production},
volume = {297},
pages = {126684},
year = {2021},
issn = {0959-6526},
doi = {https://doi.org/10.1016/j.jclepro.2021.126684},
url = {https://www.sciencedirect.com/science/article/pii/S0959652621009045},
author = {Yunna Wu and Fangtong Liu and Zhongqing Deng and Jiaming He and Chuanbo Xu and Yao Tao and Yiming Ke},
keywords = {Dispersed wind power, Obstacles analysis, Pythagorean fuzzy numbers, DANP, K-means clustering algorithm},
abstract = {Dispersed wind power is undoubtedly assisting sustainable development of society but hindered by various factors. To promote the development of dispersed wind power, this paper is devoted to obstacles identification and analysis to provide effective development proposals. Firstly, a three-stage process (namely collection, screening and improvement) is developed to extract common obstacles from literature and explore unique obstacles according to the characteristics and development status of dispersed wind power. Then, DANP method is improved to analyze interaction, interrelation and relative importance among filtered obstacles, where Pythagorean fuzzy numbers and K-Means clustering algorithm are introduced to modify incomplete information collection and arbitrary threshold determination, respectively. Three reasonable thresholds are determined according to clustering results, which divide the influence degree among obstacles into four categories (namely, high, moderate, low and no influence). The analysis results indicate that lagged unified planning ranks the first of obstacles, followed by financial difficulty and restricted grid access. On that basis, some practical proposals on regional coordinated development are suggested, including building unified coordination platforms and forming dispersed wind power project group. This paper does not only enrich material database for scholars, but also provide reference and guidance for government and related enterprises.}
}
@article{QURESHI2021107647,
title = {Anomaly detection and trust authority in artificial intelligence and cloud computing},
journal = {Computer Networks},
volume = {184},
pages = {107647},
year = {2021},
issn = {1389-1286},
doi = {https://doi.org/10.1016/j.comnet.2020.107647},
url = {https://www.sciencedirect.com/science/article/pii/S1389128620312664},
author = {Kashif Naseer Qureshi and Gwanggil Jeon and Francesco Piccialli},
keywords = {SDN, Edge, Cloud, Networks, Trust, Security, Data plane, IoT, Multimedia, Malicious, Attacks},
abstract = {The rapid development of smart Internet of Things (IoT) and its multimedia applications with conventional cloud and edge computing platforms are driving a new trend that shifts the functions of centralized networks. These centralized cloud and edge computing networks are encountering various new routing and security challenges. These networks are vulnerable due to different malicious activities and security attacks. The malicious activities lead to link failure and wrong forwarding decisions and or divert the paths. To detect the malicious activities in these networks, we need an efficient detection system for malicious switches in Software Defined Networks (SDN) data plan and leads to data traffic diversion and degrades the network performance. Another aspect is the trust of edge devices and always need to trustworthy devices to forward the IoT devices data to SDN networks. In this paper, we proposed a Software-Defined Network-based Anomaly Detection System (SDN-ADS) for edge computing-based system architecture for IoT networks. Afterwards, we proposed an anomaly detection system to detect the device's behaviour for SDN and edge computing networks. Also, we proposed a Trusted Authority for Edge Computing (TA-Edge) to ensure the trust of edge devices for data forwarding. The edge device is acting as a certificate authority for the specified trusted domain. To overcome the edge devices overhead, in this proposed TA-Edge model, the edge node, only one time, verifies the certificate and when the trust is established, all communication can be done through local certificates. The simulation results show the better performance of proposed systems in terms of different performance parameters.}
}
@article{ZAVALA2019161,
title = {Adaptive monitoring: A systematic mapping},
journal = {Information and Software Technology},
volume = {105},
pages = {161-189},
year = {2019},
issn = {0950-5849},
doi = {https://doi.org/10.1016/j.infsof.2018.08.013},
url = {https://www.sciencedirect.com/science/article/pii/S0950584918301861},
author = {Edith Zavala and Xavier Franch and Jordi Marco},
keywords = {Adaptive monitoring, Monitoring reconfiguration, Monitor customization, State of the art, Systematic mapping study, Literature review},
abstract = {Context
Adaptive monitoring is a method used in a variety of domains for responding to changing conditions. It has been applied in different ways, from monitoring systems’ customization to re-composition, in different application domains. However, to the best of our knowledge, there are no studies analyzing how adaptive monitoring differs or resembles among the existing approaches.
Objective
To characterize the current state of the art on adaptive monitoring, specifically to: (a) identify the main concepts in the adaptive monitoring topic; (b) determine the demographic characteristics of the studies published in this topic; (c) identify how adaptive monitoring is conducted and evaluated by the different approaches; (d) identify patterns in the approaches supporting adaptive monitoring.
Method
We have conducted a systematic mapping study of adaptive monitoring approaches following recommended practices. We have applied automatic search and snowballing sampling on different sources and used rigorous selection criteria to retrieve the final set of papers. Moreover, we have used an existing qualitative analysis method for extracting relevant data from studies. Finally, we have applied data mining techniques for identifying patterns in the solutions.
Results
We have evaluated 110 studies organized in 81 approaches that support adaptive monitoring. By analyzing them, we have: (1) surveyed related terms and definitions of adaptive monitoring and proposed a generic one; (2) visualized studies’ demographic data and arranged the studies into approaches; (3) characterized the main approaches’ contributions; (4) determined how approaches conduct the adaptation process and evaluate their solutions.
Conclusions
This cross-domain overview of the current state of the art on adaptive monitoring may be a solid and comprehensive baseline for researchers and practitioners in the field. Especially, it may help in identifying opportunities of research; for instance, the need of proposing generic and flexible software engineering solutions for supporting adaptive monitoring in a variety of systems.}
}
@article{KHANSARI2020102503,
title = {Incorporating an agent-based decision tool to better understand occupant pathways to GHG reductions in NYC buildings},
journal = {Cities},
volume = {97},
pages = {102503},
year = {2020},
issn = {0264-2751},
doi = {https://doi.org/10.1016/j.cities.2019.102503},
url = {https://www.sciencedirect.com/science/article/pii/S0264275119303981},
author = {Nasrin Khansari and Elizabeth Hewitt},
keywords = {Agent-based model, Greenhouse gas emissions, Energy efficiency, Occupant behavior, New York City, Buildings},
abstract = {A number of cities globally have developed ambitious goals to reduce greenhouse gas emissions (GHGs), and New York City has publicly committed to reducing emissions 80% by 2050 (80 × 50). While physical infrastructure is important, cities can gain important insights through information about human behavior, as people are the end users of buildings, transportation, and other physical assets. In this paper, we present a simplistic, pilot agent-based model (ABM) for New York City with projections about the city's potential for reaching the 80 × 50 goal in the building sector. Importantly, the ABM models occupant choices about technology adoption to predict the prevalence of green buildings in coming years. We find that even though traditional building types are slow to transition, CO2 production still decreases substantially over the forecast interval. Traditional buildings begin to slow their dominance in the model pathways by approximately 10 years into the forecast. Although the ABM presented here relies on simplistic assumptions about human agents and brings a high level of uncertainty, it presents a useful pilot tool to begin to understand system-level impacts from micro-level actions of households and individuals, and provides vast potential for future use of ABMs for this task.}
}
@article{LI2021100201,
title = {Wartime industrial logistics information integration: Framework and application in optimizing deployment and formation of military logistics platforms},
journal = {Journal of Industrial Information Integration},
volume = {22},
pages = {100201},
year = {2021},
issn = {2452-414X},
doi = {https://doi.org/10.1016/j.jii.2021.100201},
url = {https://www.sciencedirect.com/science/article/pii/S2452414X21000029},
author = {Xiong Li and Wei Zhang and Xiaodong Zhao and Wei Pu and Ping Chen and Fang Liu},
keywords = {Industrial information integration engineering, Industrial logistics system, Optimal decisions, Data analytics, Agent-based simulation},
abstract = {Industrial logistics system is one of the key objects of industrial informatization, and analysis on this system is an important task of industrial information integration. According to the concept and principle of industrial information integration engineering, we present a five-layered framework of wartime industrial logistics information integration, and form an analysis of wartime industrial logistics system from the perspective of industrial information integration. To provide resolutions to the problems of optimizing deployment and formation of resources in wartime industrial logistics system (e.g., military logistics platforms [MLPs]), we conduct a typical application of this framework. As the research objects of the fourth layer, war statistics, mathematical calculations and simulation experiment are designed as the means by which descriptive analysis, predictive analysis and prescriptive analysis at the fifth layer can be implemented, respectively. Accordingly, the battle damage repair efficiency-oriented optimal decisions model of using MLPs are built. Results show that our study forms a systematic procedure for wartime industrial logistics information integration, thus obtaining more decision support and greater reference value for wartime industrial logistics.}
}
@article{ULLAH201981,
title = {Architectural Tactics for Big Data Cybersecurity Analytics Systems: A Review},
journal = {Journal of Systems and Software},
volume = {151},
pages = {81-118},
year = {2019},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2019.01.051},
url = {https://www.sciencedirect.com/science/article/pii/S0164121219300172},
author = {Faheem Ullah and Muhammad {Ali Babar}},
keywords = {Big data, Cybersecurity, Quality attribute, Architectural tactic},
abstract = {Context
Big Data Cybersecurity Analytics (BDCA) systems leverage big data technologies for analyzing security events data to protect organizational networks, computers, and data from cyber attacks.
Objective
We aimed at identifying the most frequently reported quality attributes and architectural tactics for BDCA systems.
Method
We used Systematic Literature Review (SLR) method for reviewing 74 papers.
Result
Our findings are twofold: (i) identification of 12 most frequently reported quality attributes for BDCA systems; and (ii) identification and codification of 17 architectural tactics for addressing the identified quality attributes. The identified tactics include six performance tactics, four accuracy tactics, two scalability tactics, three reliability tactics, and one security and usability tactic each.
Conclusion
Our study reveals that in the context of BDCA (a) performance, accuracy and scalability are the most important quality concerns (b) data analytics is the most critical architectural component (c) despite the significance of interoperability, modifiability, adaptability, generality, stealthiness, and privacy assurance, these quality attributes lack explicit architectural support (d) empirical investigation is required to evaluate the impact of the codified tactics and explore the quality trade-offs and dependencies among the tactics and (e) the reported tactics need to be modelled using a standardized modelling language such as UML.}
}
@article{PALIPANA201780,
title = {Recent advances in RF-based passive device-free localisation for indoor applications},
journal = {Ad Hoc Networks},
volume = {64},
pages = {80-98},
year = {2017},
issn = {1570-8705},
doi = {https://doi.org/10.1016/j.adhoc.2017.06.007},
url = {https://www.sciencedirect.com/science/article/pii/S1570870517301257},
author = {Sameera Palipana and Bastien Pietropaoli and Dirk Pesch},
keywords = {Indoor, Device-free, Localisation, Wireless networks, Radar},
abstract = {Radio frequency (RF) based indoor localisation techniques have gained much attention over the past nearly three decades. Such techniques can be classified as active and passive while passive systems can have either device-assisted or device-free characteristics. Device-free localisation can be a prominent research field as it transcends other device-based approaches in certain application scenarios. Accordingly, we have witnessed an influx of IDFL research focusing on multiple disciplines including occupancy, positioning, activity and identity. However, despite the recent emergence of several exciting technologies and corresponding techniques, IDFL faces some important challenges and because of this, we haven’t come across many mainstream commercial products using RF-based IDFL techniques. In this article, we survey the recent progress of IDFL prioritising on indoor positioning. We decompose the localisation dimensions into occupants, space and time, provide a detailed taxonomy and a comprehensive review of these techniques. We divide the state of the art mainly into Wireless Network-based and Radar-based, evaluate the respective technologies and the techniques qualitatively, discuss trends, limitations and also indicate future research directions relevant to this field.}
}
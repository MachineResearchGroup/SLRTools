@article{LING2019440,
title = {On hybrid network coding for visual traffic surveillance},
journal = {Future Generation Computer Systems},
volume = {100},
pages = {440-455},
year = {2019},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2019.05.044},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X18328450},
author = {Chih Wei Ling and Anwitaman Datta and Jun Xu},
keywords = {Internet of things, Fog/edge computing, Network coding, Software-defined network, Traffic visual surveillance},
abstract = {A large volume of data is generated by traffic surveillance devices such as cameras and sensors integrated into an intelligent transportation system (ITS), a subfield of the Internet of Things (IoT). We argue that network coding can be applied to leverage on an emerging fog architecture that relies on edge resources, to achieve higher throughput, saving up network bandwidth, and provide resilience to link failures, while also achieving simple obfuscation against wire-tapping attacks by linearly combining the source packets. There are two broad linear network coding paradigms in the literature — deterministic and random network coding, each with their own strengths and limitations. With the aid of software-defined network (SDN), we rethink about the possibility of applying a hybrid approach to deal with networks at different scales. Under network conditions that reflect expected network properties of an ITS, our simulation results show that the proposed hybrid approach performs better than other alternates.}
}
@article{AFSHINNEKOO201572,
title = {Geospatial Resolution of Human and Bacterial Diversity with City-Scale Metagenomics},
journal = {Cell Systems},
volume = {1},
number = {1},
pages = {72-87},
year = {2015},
issn = {2405-4712},
doi = {https://doi.org/10.1016/j.cels.2015.01.001},
url = {https://www.sciencedirect.com/science/article/pii/S2405471215000022},
author = {Ebrahim Afshinnekoo and Cem Meydan and Shanin Chowdhury and Dyala Jaroudi and Collin Boyer and Nick Bernstein and Julia M. Maritz and Darryl Reeves and Jorge Gandara and Sagar Chhangawala and Sofia Ahsanuddin and Amber Simmons and Timothy Nessel and Bharathi Sundaresh and Elizabeth Pereira and Ellen Jorgensen and Sergios-Orestis Kolokotronis and Nell Kirchberger and Isaac Garcia and David Gandara and Sean Dhanraj and Tanzina Nawrin and Yogesh Saletore and Noah Alexander and Priyanka Vijay and Elizabeth M. Hénaff and Paul Zumbo and Michael Walsh and Gregory D. O’Mullan and Scott Tighe and Joel T. Dudley and Anya Dunaif and Sean Ennis and Eoghan O’Halloran and Tiago R. Magalhaes and Braden Boone and Angela L. Jones and Theodore R. Muth and Katie Schneider Paolantonio and Elizabeth Alter and Eric E. Schadt and Jeanne Garbarino and Robert J. Prill and Jane M. Carlton and Shawn Levy and Christopher E. Mason},
abstract = {Summary
The panoply of microorganisms and other species present in our environment influence human health and disease, especially in cities, but have not been profiled with metagenomics at a city-wide scale. We sequenced DNA from surfaces across the entire New York City (NYC) subway system, the Gowanus Canal, and public parks. Nearly half of the DNA (48%) does not match any known organism; identified organisms spanned 1,688 bacterial, viral, archaeal, and eukaryotic taxa, which were enriched for genera associated with skin (e.g., Acinetobacter). Predicted ancestry of human DNA left on subway surfaces can recapitulate U.S. Census demographic data, and bacterial signatures can match a station’s history, such as marine-associated bacteria in a hurricane-flooded station. This baseline metagenomic map of NYC could help long-term disease surveillance, bioterrorism threat mitigation, and health management in the built environment of cities.}
}
@article{RMAYTI201753,
title = {A stochastic approach for packet dropping attacks detection in mobile Ad hoc networks},
journal = {Computer Networks},
volume = {121},
pages = {53-64},
year = {2017},
issn = {1389-1286},
doi = {https://doi.org/10.1016/j.comnet.2017.04.027},
url = {https://www.sciencedirect.com/science/article/pii/S1389128617301615},
author = {Mohammad Rmayti and Rida Khatoun and Youcef Begriche and Lyes Khoukhi and Dominique Gaiti},
keywords = {Packet dropping attacks, Intrusion detection, Bayesian classification, Fuzzy logic, Markov chain},
abstract = {A Mobile Ad hoc Network (MANET) is a dynamic network composed of mobile nodes that can communicate without relying on an existing infrastructure. In such decentralized environment, packet forwarding and other routing services are provided by network nodes cooperatively without any central administration. Most of existing Ad hoc routing protocols are based on the assumption that all network nodes are trustworthy. However, this assumption may be inconsistent when a malicious node decides to drop packets that are supposed to be forwarded in the aim of disrupting the routing services. Furthermore, the malicious node can change its behavior over time in order to appear as a legitimate node and still disrupting the network without being detected. To address this problem, we propose in this paper a fully decentralized mechanism that allows a node to monitor and detect neighbors that are malicious even if they have a changing behavior. Our mechanism is based on a Bernoulli Bayesian model for nodes’ behavior classification and a Markov chain model for behavior evolution tracking. Performance analysis of numerical results obtained using NS2 simulations show an accurate detection of malicious nodes, which can be used to guarantee a reliable and secure packet forwarding among network nodes.}
}
@article{NAIR2021102885,
title = {Sharing the road with autonomous vehicles: Perceived safety and regulatory preferences},
journal = {Transportation Research Part C: Emerging Technologies},
volume = {122},
pages = {102885},
year = {2021},
issn = {0968-090X},
doi = {https://doi.org/10.1016/j.trc.2020.102885},
url = {https://www.sciencedirect.com/science/article/pii/S0968090X20307853},
author = {Gopindra S. Nair and Chandra R. Bhat},
keywords = {Autonomous vehicles, Driverless cars, Safety, Regulation, Generalized heterogenous data model, Digital assistants},
abstract = {Technology providers, car manufacturers, and public agencies all need to work together to undertake extensive testing of fully autonomous vehicles (AVs) on public roads before such AVs are allowed to freely travel in ways similar to human-driven vehicles. This raises the importance of understanding public perceptions regarding safety considerations when traveling alongside AVs. This study makes use of a national survey conducted by the Pew Research Center to identify the affective, socio-demographic and technology-use attributes that affect an individual’s perception of the safety of sharing the road with AVs (PSSRAV) and identifies measures and interventions that can be undertaken to improve PSSRAV. Additionally, we evaluate individual preferences for AV regulations. Our results underscore the importance of the need for service providers and public agencies to be cognizant of the demographic and lifestyle/affective emotion considerations shaping AV safety perceptions and opinions about AV regulations. In particular, there is a need not only to focus on technological and other infrastructure components of AV development, but also to recognize the socio-technical considerations and human-related factors of the end-users. Our findings should be of substantial interest in the planning, design, deployment, and introduction of AVs within a safe and minimally regulated public operating arena.}
}
@article{RUAN201878,
title = {Device-free human localization and tracking with UHF passive RFID tags: A data-driven approach},
journal = {Journal of Network and Computer Applications},
volume = {104},
pages = {78-96},
year = {2018},
issn = {1084-8045},
doi = {https://doi.org/10.1016/j.jnca.2017.12.010},
url = {https://www.sciencedirect.com/science/article/pii/S1084804517304228},
author = {Wenjie Ruan and Quan Z. Sheng and Lina Yao and Xue Li and Nickolas J.G. Falkner and Lei Yang},
keywords = {RFID, Hidden Markov model, Gaussian mixture model, Device-free, Indoor localization, Tracking},
abstract = {Localizing and tracking human movement in a device-free and passive manner is promising in two aspects: i) it neither requires users to wear any sensors or devices, ii) nor it needs them to consciously cooperate during the localization. Such indoor localization technique underpins many real-world applications such as shopping navigation, intruder detection, surveillance care of seniors etc. However, current passive localization techniques either need expensive/sophisticated hardware such as ultra-wideband radar or infrared sensors, or have an issue of invasion of privacy such as camera-based techniques, or need regular maintenance such as the replacement of batteries. In this paper, we build a novel data-driven localization and tracking system upon a set of commercial ultra-high frequency passive radio-frequency identification tags in an indoor environment. Specifically, we formulate human localization problem as finding a location with the maximum posterior probability given the observed received signal strength indicator from passive radio-frequency identification tags. In this regard, we design a series of localization schemes to capture the posterior probability by taking the advance of supervised-learning models including Gaussian Mixture Model, k Nearest Neighbor and Kernel-based Learning. For tracking a moving target, we mathematically model the task as searching a location sequence with the most likelihood, in which we first augment the probabilistic estimation learned in localization to construct the Emission Matrix and propose two human mobility models to approximate the Transmission Matrix in the Hidden Markov Model. The proposed tracking model is able to transfer the pattern learned in localization into tracking but also reduce the location-state candidates at each transmission iteration, which increases both the computation efficiency and tracking accuracy. The extensive experiments in two real-world scenarios reveal that our approach can achieve up to 94% localization accuracy and an average 0.64 m tracking error, outperforming other state-of-the-art radio-frequency identification based indoor localization systems.}
}
@article{WANG20181693,
title = {The effects of urbanization on CO2 emissions in the Pearl River Delta: A comprehensive assessment and panel data analysis},
journal = {Applied Energy},
volume = {228},
pages = {1693-1706},
year = {2018},
issn = {0306-2619},
doi = {https://doi.org/10.1016/j.apenergy.2018.06.155},
url = {https://www.sciencedirect.com/science/article/pii/S0306261918310249},
author = {Shaojian Wang and Jingyuan Zeng and Yongyuan Huang and Chenyi Shi and Peiyu Zhan},
keywords = {Urbanization, CO emissions, Pearl River Delta, Stepwise regression, Remote sensing},
abstract = {Urbanization has been viewed as an important factor in soaring energy consumption and rapidly increasing CO2 emissions, globally. While much existing literature has explored the effects of urbanization on CO2 emissions, little work has been undertaken to examine how differences in the urbanization process itself affect the impact that urbanization has on such emissions. In order to supplement the shortness of existing literature, this paper empirically investigates the multiple effects of urbanization on CO2 emissions, by addressing four different aspects of the urbanization process—namely, economic urbanization, population urbanization, land urbanization, and social urbanization, and expects that these four aspects of urbanization will conduct multiple effects on CO2 emissions. A balanced city panel remote sensing and socioeconomic data and stepwise panel data model were used in the study, which examined the period of 1990–2013 in the Pearl River Delta, an economically developed region in China that has experienced rapid urbanization since the country’s economic reforms. Our empirical results show that urbanization exerts two opposing effects on CO2 emissions: land urbanization and economic urbanization positively affects emissions due to transformation from non-built to built-up area and wealth accumulation respectively, while population urbanization exerts a negative impact on CO2 emissions as a result of improvement in energy consumption mode and efficiency. Social urbanization decreased emissions mainly through cultivating the awareness of energy-saving. Surprisingly, the industrial structure and social consumption had positive but not significant impacts on CO2 emissions in the Pearl River Delta. This finding suggests that urbanization, if measured by different indicators, does have different effects on CO2 emissions. In addition, we note the remarkable positive influence of energy intensity, indicating that lower energy efficiency tends to increase emissions. Furthermore, the impact of FDI was found to be positive, and R&D was not found to have performed any significant negative effect on CO2 emissions. These findings provide a useful insight into the relationship between urbanization and CO2 emissions that can support policy makers and urban planners.}
}
@article{HAIDER20201,
title = {P-DACCA: A Probabilistic Direction-Aware Cooperative Collision Avoidance Scheme for VANETs},
journal = {Future Generation Computer Systems},
volume = {103},
pages = {1-17},
year = {2020},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2019.09.054},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X1831714X},
author = {Shahab Haider and Ghulam Abbas and Ziaul Haq Abbas and Saadi Boudjit and Zahid Halim},
keywords = {Cooperative Collision Avoidance, Inter-vehicular communication, Vehicular Ad hoc Networks, Intelligent Transportation Systems},
abstract = {One of the major challenges in Vehicular Ad hoc Networks (VANETs) is to find a stable and robust Cooperative Collision Avoidance (CCA) scheme to address the rising death toll caused by road accidents every year. This work presents a Probabilistic-Direction-Aware Cooperative Collision Avoidance (P-DACCA) scheme that takes into account realistic bi-directional traffic, which makes this work unique in the VANETs’ collision avoidance domain. The scheme starts with formation of dynamic clusters, which becomes challenging due to bi-directional heterogeneous traffic and intra-cluster and inter-cluster collision avoidance. For clustering, we modify the k-medoids algorithm by incorporating Hamming distance as an additional metric for direction-awareness. After clustering, relative distances and speeds of nodes with respect to their expected states are computed. The scheme then estimates a collision probability on the basis of a node’s expected state and provides an early warning when the probability exceeds a predefined threshold. For implementing a preventive measure, we introduce an adaptive Benign factor that computes the safe speed for a target node. The safe speed is encapsulated along with the collision probability into an early warning message for dissemination to the target node to avoid an upcoming threat. Simulation results demonstrate significant improvement of the proposed scheme in terms of cluster stability, reduced number of collisions, low latency and low communication overhead.}
}
@article{TAUFICK2021101752,
title = {The underdeterrence, underperformance response to privacy, data protection laws},
journal = {Technology in Society},
volume = {67},
pages = {101752},
year = {2021},
issn = {0160-791X},
doi = {https://doi.org/10.1016/j.techsoc.2021.101752},
url = {https://www.sciencedirect.com/science/article/pii/S0160791X2100227X},
author = {Roberto D. Taufick},
keywords = {Privacy, Data protection, Cost, Underperformance, Underdeterrence, Insourcing, Outsourcing},
abstract = {The digital economy has been defined in the economic literature as one with near zero marginal cost, unmonetized services but also an escalating data flow. After a careful review of the most recent economic papers, we offer an alternative theory on the cost of privacy and data protection regulations. We have observed that the characteristics of the regulation lead not only to the amplification of costs that have been traditionally assigned as variable costs by the literature, but also of costs that used to be fixed but have been outsourced in the digital economy, meaning that significant new variable costs might trigger diseconomies of scale. At the same time, privacy and data protection regulations have created incentives that are making the dominant firms insource, in what seems to be a way back to increased sunk fixed costs for these firms. Having all that in mind, we claim that the perception of deterrence and compliance costs has affected how firms might decide to incur higher risks to avoid costs. Although compliance costs are high, we claim that an efficient implementation of the regulation avoids much of these costs. Our claim is supported by evidence that a relevant share of the regulatory costs are now variable costs, leaving room for at least two efficient strategies that medium-sized firms might implement in order to avoid them. First, firms can lower the volumes of data that they use without significantly impairing the predictive functions of their algorithms. Second, firms can invest in security at a comparatively lower degree than dominant firms considering their lower exposure to strong regulatory action.}
}
@article{NAG20202343,
title = {Assessment of relationships between user satisfaction, physical environment, and user behaviour in pedestrian infrastructure},
journal = {Transportation Research Procedia},
volume = {48},
pages = {2343-2363},
year = {2020},
note = {Recent Advances and Emerging Issues in Transport Research – An Editorial Note for the Selected Proceedings of WCTR 2019 Mumbai},
issn = {2352-1465},
doi = {https://doi.org/10.1016/j.trpro.2020.08.284},
url = {https://www.sciencedirect.com/science/article/pii/S2352146520307043},
author = {Dipanjan Nag and Eeshan Bhaduri and Gujjar Pankaj Kumar and Arkopal K Goswami},
keywords = {Walking, Pedestrian Behaviour, User Satisfaction, Built Environment, Ordinal Logistic, Negative Binomial},
abstract = {Does infrastructure shape human behavior, or does human behavior shape infrastructure? Users’ perception about infrastructure, both current condition and future needs, is essential in devising policy decisions. In the transport sector, one of the reasons for several large infrastructure projects not performing at par with the expectations, once they are built, is because the users are not taken into confidence sufficiently. At the same time, it is uncertain to what extent user perception leads to actual behavior change – how many people that say today will walk more if walking environment is improved, will actual do so when the facility is built? The current research measures the users’ satisfaction of present walking environment using a revealed preference survey on factors that include quality of infrastructure, comfort, safety, design, and others, in two different urban settings of a large metropolis – one a newly planned suburb and the other and older and well established area. Results of an ordinal logistic regression model shows that the factors which are likely to significantly influence the overall user satisfaction of pedestrian facilities are buffer, ease of walking, zebra crossings, footpath continuity, night time safety and location. Subsequently, stated preference data was collected and the results of a negative binomial regression model shows that improving footpath continuity has the greatest impact in the likelihood of bringing about a change in user behavior when compared to not only other individual improvements, but also the combined improvement in buffer and ease of walking.}
}
@article{DORRI2019180,
title = {LSB: A Lightweight Scalable Blockchain for IoT security and anonymity},
journal = {Journal of Parallel and Distributed Computing},
volume = {134},
pages = {180-197},
year = {2019},
issn = {0743-7315},
doi = {https://doi.org/10.1016/j.jpdc.2019.08.005},
url = {https://www.sciencedirect.com/science/article/pii/S0743731518307688},
author = {Ali Dorri and Salil S. Kanhere and Raja Jurdak and Praveen Gauravaram},
keywords = {Internet of Things, Blockchain, Security, Smart home},
abstract = {In recent years, Blockchain has attracted tremendous attention due to its salient features including auditability, immutability, security, and anonymity. Resulting from these salient features, blockchain has been applied in multiple non-monetary applications including the Internet of Things (IoT). However, blockchain is computationally expensive, has limited scalability and incurs significant bandwidth overheads and delays which are not suited for most IoT applications. In this paper, we propose a Lightweight Scalable blockchain (LSB) that is optimized for IoT requirements while also providing end-to-end security. Our blockchain instantiation achieves decentralization by forming an overlay network where high resource devices jointly manage the blockchain. The overlay is organized as distinct clusters to reduce overheads and the cluster heads are responsible for managing the public blockchain. We propose a Distributed Time-based Consensus algorithm (DTC) which reduces the mining processing overhead and delay. Distributed trust approach is employed by the cluster heads to progressively reduce the processing overhead for verifying new blocks. LSB incorporates a Distributed Throughput Management (DTM) algorithm which ensures that the blockchain throughput does not significantly deviate from the cumulative transaction load in the network. We explore our approach in a smart home setting as a representative example for broader IoT applications. Qualitative arguments demonstrate that our approach is resilient to several security attacks. Extensive simulations show that packet overhead and delay are decreased and blockchain scalability is increased compared to relevant baselines.}
}
@article{FENG201820,
title = {Accelerating simulation of Population Continuous Time Markov Chains via automatic model reduction},
journal = {Performance Evaluation},
volume = {120},
pages = {20-35},
year = {2018},
issn = {0166-5316},
doi = {https://doi.org/10.1016/j.peva.2017.11.004},
url = {https://www.sciencedirect.com/science/article/pii/S016653161730130X},
author = {Cheng Feng and Jane Hillston},
keywords = {Population Continuous Time Markov Chain, Stochastic simulation, Model reduction},
abstract = {We present a novel model reduction method which can significantly boost the speed of stochastic simulation of a population continuous-time Markov chain (PCTMC) model. Specifically, given a set of predefined target populations of the modellers’ interest, our method exploits the coupling coefficients between population variables and transitions with respect to those target populations which are calculated based on a directed coupling graph constructed for the PCTMC. Population variables and transitions which have high coupling coefficients on the target populations are exactly simulated. However, the remaining population variables and transitions which have low coupling coefficients can either be removed or approximately simulated in the reduced model. The reduced model generated by our approach has significantly lower cost for stochastic simulation, but still retains high accuracy on the statistical properties of the target populations. The applicability and effectiveness of our method are demonstrated on two illustrative models.}
}
@article{KRAMER201569,
title = {A modular software architecture for processing of big geospatial data in the cloud},
journal = {Computers & Graphics},
volume = {49},
pages = {69-81},
year = {2015},
issn = {0097-8493},
doi = {https://doi.org/10.1016/j.cag.2015.02.005},
url = {https://www.sciencedirect.com/science/article/pii/S0097849315000138},
author = {Michel Krämer and Ivo Senner},
keywords = {Cloud computing, Big Data, Geoprocessing, Distributed systems, Software architectures, Domain-specific languages},
abstract = {In this paper we propose a software architecture that allows for processing of large geospatial data sets in the cloud. Our system is modular and flexible and supports multiple algorithm design paradigms such as MapReduce, in-memory computing or agent-based programming. It contains a web-based user interface where domain experts (e.g. GIS analysts or urban planners) can define high-level processing workflows using a domain-specific language (DSL). The workflows are passed through a number of components including a parser, interpreter, and a service called job manager. These components use declarative and procedural knowledge encoded in rules to generate a processing chain specifying the execution of the workflows on a given cloud infrastructure according to the constraints defined by the user. The job manager evaluates this chain, spawns processing services in the cloud and monitors them. The services communicate with each other through a distributed file system that is scalable and fault-tolerant. Compared to previous work describing cloud infrastructures and architectures we focus on the processing of big heterogeneous geospatial data. In addition to that, we do not rely on only one specific programming model or a certain cloud infrastructure but support several ones. Combined with the possibility to control the processing through DSL-based workflows, this makes our architecture very flexible and configurable. We do not only see the cloud as a means to store and distribute large data sets but also as a way to harness the processing power of distributed computing environments for large-volume geospatial data sets. The proposed architecture design has been developed for the IQmulus research project funded by the European Commission. The paper concludes with the evaluation results from applying our solution to two example workflows from this project.}
}
@article{BRINGS20201010,
title = {A systematic map on verification and validation of emergent behavior in software engineering research},
journal = {Future Generation Computer Systems},
volume = {112},
pages = {1010-1037},
year = {2020},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2020.06.049},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X19333606},
author = {Jennifer Brings and Marian Daun and Kevin Keller and Patricia {Aluko Obe} and Thorsten Weyer},
keywords = {Emergent behavior, Verification and validation, Systematic mapping study},
abstract = {Context:
Emergent behavior cannot be attributed to one individual system alone but arises in the interplay of various systems, components etc. Ensuring the correctness of emergent behavior is a well-known challenge that has been addressed by research in various subfields of software engineering.
Objective:
This paper aims at providing a unified view on the research activities conducted and research contributions made on verification and validation of emergent behavior.
Methods:
We have conducted a systematic mapping study on the topic of verification and validation of emergent behavior. We applied a combined search strategy using manual, database, and snowball search. In total we investigated 7211 papers, from these 168 relevant papers have been included and classified.
Results:
Results show an increasing interest in the topic of verification and validation of emergent behavior. As only little validation and evaluation research has been conducted, the field can be considered still immature. There exist different verification and validation techniques used in the various solution approaches such as model checking, simulation, or runtime monitoring. It stands out that even though research is published in different software engineering fields and subfields no verification or validation technique can be attributed solely to a single field.}
}
@article{SARAIVADESOUSA201969,
title = {Network Service Orchestration: A survey},
journal = {Computer Communications},
volume = {142-143},
pages = {69-94},
year = {2019},
issn = {0140-3664},
doi = {https://doi.org/10.1016/j.comcom.2019.04.008},
url = {https://www.sciencedirect.com/science/article/pii/S0140366418309502},
author = {Nathan F. {Saraiva de Sousa} and Danny A. {Lachos Perez} and Raphael V. Rosa and Mateus A.S. Santos and Christian {Esteve Rothenberg}},
keywords = {Network Service Orchestration (NSO), SDN, NFV, Multi-domain, Orchestration, Virtualization, Lifecycle management},
abstract = {Business models of network service providers are undergoing an evolving transformation fueled by vertical customer demands and technological advances such as 5G, Software Defined Networking (SDN), and Network Function Virtualization (NFV). Emerging scenarios call for agile network services consuming network, storage, and compute resources across heterogeneous infrastructures and administrative domains. Coordinating resource control and service creation across interconnected domains and diverse technologies becomes a grand challenge. Research and development efforts are being devoted to enabling orchestration processes to automate, coordinate, and manage the deployment and operation of network services. In this survey, we delve into the topic of Network Service Orchestration (NSO) by reviewing the historical background, relevant research projects, enabling technologies, and standardization activities. We define key concepts and propose a taxonomy of NSO approaches and solutions to pave the way towards a common understanding of the various ongoing efforts around the realization of diverse NSO application scenarios. Based on the analysis of the state of affairs, we present a series of open challenges and research opportunities, altogether contributing to a timely and comprehensive survey on the vibrant and strategic topic of network service orchestration.}
}
@article{OH2019217,
title = {Tactical supply planning in smart manufacturing supply chain},
journal = {Robotics and Computer-Integrated Manufacturing},
volume = {55},
pages = {217-233},
year = {2019},
note = {Extended Papers Selected from FAIM2016},
issn = {0736-5845},
doi = {https://doi.org/10.1016/j.rcim.2018.04.003},
url = {https://www.sciencedirect.com/science/article/pii/S0736584517301266},
author = {Jisoo Oh and Bongju Jeong},
keywords = {Smart supply chain, Smart manufacturing, Planning model, Supply chain performance, Flexibility},
abstract = {With the fast change of information and communication technologies and global economics, manufacturing industry faces the challenges in both market and supply sides. The challenges in the market include short product life cycle, demand uncertainty, and product customization. Accordingly, supply challenges are the dramatic increase of flexibility in productions and complexity in the supply chain, which result from the changes in the industry and rapid development of ICPT (Information, Communication, and Production Technologies). In this study, we consider a supply chain converged with ICPT, called Smart Manufacturing Supply Chain (SMSC). By investigating the attributes of SMSC, we identify the functional and structural characteristics of SMSC. Tactical supply planning in SMSC recognizes the ability of a pseudo real-time decision-making constrained by the planning horizon. In order to take advantages of SMSC, this study develops a profit-effective and response-efficient tactical supply planning model to find an optimal trade-off between profit and lead time. The model determines the optimal supply throughput during a planning horizon, called Smart Supply Chain Performance (SSCP) as a performance measure for SMSC. The proposed model is investigated and validated using comprehensive numerical experiments and managerial insights are addressed.}
}
@article{HORCAS201620,
title = {An approach for deploying and monitoring dynamic security policies},
journal = {Computers & Security},
volume = {58},
pages = {20-38},
year = {2016},
issn = {0167-4048},
doi = {https://doi.org/10.1016/j.cose.2015.11.007},
url = {https://www.sciencedirect.com/science/article/pii/S0167404815001832},
author = {Jose-Miguel Horcas and Mónica Pinto and Lidia Fuentes and Wissam Mallouli and Edgardo {Montes de Oca}},
keywords = {Aspect-oriented programming, Dynamic deployment, Monitoring, Security framework, Security policies},
abstract = {Security policies are enforced through the deployment of certain security functionalities within the applications. When the security policies dynamically change, the associated security functionalities currently deployed within the applications must be adapted at runtime in order to enforce the new security policies. INTER-TRUST is a framework for the specification, negotiation, deployment and dynamic adaptation of interoperable security policies, in the context of pervasive systems where devices are constantly exchanging critical information through the network. The dynamic adaptation of the security policies at runtime is addressed using Aspect-Oriented Programming (AOP) that allows enforcing security requirements by dynamically weaving security aspects into the applications. However, a mechanism to guarantee the correct adaptation of the functionality that enforces the changing security policies is needed. In this paper, we present an approach based on the combination of monitoring and detection techniques in order to maintain the correlation between the security policies and the associated functionality deployed using AOP, allowing the INTER-TRUST framework to automatically react when needed.}
}
@article{GOYAL2021125011,
title = {Circular economy research: A bibliometric analysis (2000–2019) and future research insights},
journal = {Journal of Cleaner Production},
volume = {287},
pages = {125011},
year = {2021},
issn = {0959-6526},
doi = {https://doi.org/10.1016/j.jclepro.2020.125011},
url = {https://www.sciencedirect.com/science/article/pii/S0959652620350551},
author = {Sandeep Goyal and Sumedha Chauhan and Pavitra Mishra},
keywords = {Circular economy, Literature review, Bibliometric metric, Conceptual framework, Sustainability},
abstract = {This study undertakes an empirical analysis of the circular economy (CE) literature published between 2000 and 2019 and articulates the key research themes on the basis of content analysis and citation mapping of the top-cited CE-related articles. HistCite software was used to perform bibliometric citation meta-analysis on a sample of 2279 articles, obtained from the ISI Web of Science database, having 89,995 global cited references. Influential journals, articles, yearly trends, institutions, and authors in CE research were identified and presented in this study. Content analysis and citation mapping of the top-cited 33 articles revealed the following key research themes: 1) CE assessment methods and frameworks, 2) CE concept and sustainability, 3) Inter-disciplinary research in circular context, 4) CE adoption – country, region or firm level, 5) CE recycling, recovery, and reuse, 6) CE and environmental economics, 7) CE and eco-industrial parks, 8) CE and resource life extension, 9) CE and design of circular products and 10) CE rebound. Subsequently, a knowledge synthesis approach was applied to develop an integrated, multi-dimensional conceptual framework depicting the linkage between CE drivers, stakeholders, CE practice indicators, and performance measures. Finally, future research directions from recent articles were analyzed, and suggestions are made for future CE research themes.}
}
@article{ROBINSON2019276,
title = {Developing cyber peacekeeping: Observation, monitoring and reporting},
journal = {Government Information Quarterly},
volume = {36},
number = {2},
pages = {276-293},
year = {2019},
issn = {0740-624X},
doi = {https://doi.org/10.1016/j.giq.2018.12.001},
url = {https://www.sciencedirect.com/science/article/pii/S0740624X18302831},
author = {Michael Robinson and Kevin Jones and Helge Janicke and Leandros Maglaras},
keywords = {Cyber peacekeeping, Cyber warfare, Cyber OMR, Cyber peace operations},
abstract = {Cyberphysical societies are becoming reliant upon the cyber domain for everyday life. With cyber warfare increasingly becoming part of future conflicts, new and novel solutions are needed to assist governments in securing their national infrastructure. Cyber peacekeeping is one such solution: an emerging and multi-disciplinary field of research, touching upon technical, political, governmental and societal domains of thought. In this article we build upon previous works by developing the cyber peacekeeping activity of observation, monitoring and reporting. We take a practical approach: describing a scenario in which two cyberphysical societies experience the negative effects of cyber warfare and require cyber expertise to restore services their citizens depend upon. We explore how a cyber peacekeeping operation could start up and discuss the challenges it will face. The article makes a number of proposals, including the use of a virtual collaborative environment to bring multiple benefits. We conclude by summarising our findings, and describing where further work lies.}
}
@article{HASAN2019178,
title = {A comprehensive review of wireless body area network},
journal = {Journal of Network and Computer Applications},
volume = {143},
pages = {178-198},
year = {2019},
issn = {1084-8045},
doi = {https://doi.org/10.1016/j.jnca.2019.06.016},
url = {https://www.sciencedirect.com/science/article/pii/S1084804519302218},
author = {Khalid Hasan and Kamanashis Biswas and Khandakar Ahmed and Nazmus S. Nafi and Md Saiful Islam},
keywords = {WBAN, IEEE 802.15.6, M2M, SDN, Blockchain},
abstract = {Recent development and advancement of information and communication technologies facilitate people in different dimensions of life. Most importantly, in the healthcare industry, this has become more and more involved with the information and communication technology-based services. One of the most important services is monitoring of remote patients, that enables the healthcare providers to observe, diagnose and prescribe the patients without being physically present. The advantage of miniaturization of sensor technologies gives the flexibility of installing in, on or off the body of patients, which is capable of forwarding physiological data wirelessly to remote servers. Such technology is named as Wireless Body Area Network (WBAN). In this paper, WBAN architecture, communication technologies for WBAN, challenges and different aspects of WBAN are illustrated. This paper also describes the architectural limitations of existing WBAN communication frameworks. blueFurthermore, implementation requirements are presented based on IEEE 802.15.6 standard. Finally, as a source of motivation towards future development of research incorporating Software Defined Networking (SDN), Energy Harvesting (EH) and Blockchain technology into WBAN are also provided.}
}
@article{BALTACIAKHUSEYINOGLU2020101802,
title = {A constraint and risk-aware approach to attribute-based access control for cyber-physical systems},
journal = {Computers & Security},
volume = {96},
pages = {101802},
year = {2020},
issn = {0167-4048},
doi = {https://doi.org/10.1016/j.cose.2020.101802},
url = {https://www.sciencedirect.com/science/article/pii/S0167404820300869},
author = {Nuray {Baltaci Akhuseyinoglu} and James Joshi},
keywords = {Attribute-based access control, Cyber-physical systems, Action generation, Risk, Separation of duties},
abstract = {Cyber-physical systems (CPSs) integrate cyber components and physical processes. This integration enhances the capabilities of physical systems by incorporating intelligence into objects and services. On the other hand, the integration of cyber and physical components and the interaction between them introduce new security threats. Since CPSs are mostly safety-critical systems, data stored and communicated in them are highly critical. Hence, there is a crucial need for protecting the data and resources in CPSs against unauthorized accesses. In this paper, we propose an access control (AC) framework to address CPS related security issues. The proposed framework consists of two parts: a Cyber-Physical Access Control model (CPAC) and a Generalized Action Generation Model (GAGM). CPAC utilizes an attribute-based approach and extends it with cyber-physical components and cyber-physical interactions. In addition, we incorporate Separation of Duty (SoD) constraints into the CPAC model. GAGM is used to augment the enforcement of access policies. We present formal representations of CPAC and GAGM and demonstrate their use in a sample scenario for a medical CPS. We propose an algorithm for enforcing authorization policies. We implement the CPAC model and compare its performance against the core attribute-based access control model. We present an authorization enforcement approach and show through our experimental results its feasibility.}
}
@article{ROY2020107573,
title = {AI-enabled mobile multimedia service instance placement scheme in mobile edge computing},
journal = {Computer Networks},
volume = {182},
pages = {107573},
year = {2020},
issn = {1389-1286},
doi = {https://doi.org/10.1016/j.comnet.2020.107573},
url = {https://www.sciencedirect.com/science/article/pii/S1389128620312160},
author = {Palash Roy and Sujan Sarker and Md. Abdur Razzaque and Mohammad Mehedi Hassan and Salman A. AlQahtani and Gianluca Aloi and Giancarlo Fortino},
keywords = {Mobile multimedia service, Mobile edge computing, Quality-of-Experience, Service instance deployment, Binary particle swarm optimization, User satisfaction, 5G network},
abstract = {Leveraging cloud infrastructure to the mobile edge computing helps the mobile users to get real time multimedia services in Fifth Generation (5G) network system. To ensure higher Quality-of-Experience (QoE), faster migration of mobile multimedia service instances is required to cope up with user mobility. By deploying the mobile multimedia service instances proactively in multiple edge nodes (ENs) helps the users to get higher QoE. However, excessive deployment of service replicas might increase the cost of the overall network. To establish trade-off between these two conflicting objectives, we have formulated the problem as a Multi-objective Integer Linear Programming (MILP) by integrating the users’ path prediction model. This problem is proven to be an NP-hard one for large networks, thus we develop an artificial intelligence (AI) based meta-heuristic Binary Particle Swarm Optimization (BPSO) algorithm to achieve near-optimal solution within polynomial time. The performance analysis results show the significant performance improvement in terms of QoE and user satisfaction as compared to other state-of-the-art works.}
}
@article{WAIBEL20191661,
title = {Co-simulation and optimization of building geometry and multi-energy systems: Interdependencies in energy supply, energy demand and solar potentials},
journal = {Applied Energy},
volume = {242},
pages = {1661-1682},
year = {2019},
issn = {0306-2619},
doi = {https://doi.org/10.1016/j.apenergy.2019.03.177},
url = {https://www.sciencedirect.com/science/article/pii/S0306261919305938},
author = {Christoph Waibel and Ralph Evins and Jan Carmeliet},
keywords = {Co-simulation, Multi-objective optimization, Energy hub, Multi-energy system, Building energy demand, Solar potentials, Geometry optimization},
abstract = {This paper presents a co-simulation framework for the simultaneous optimization of building geometries and multi-energy systems using the energy hub approach. The rationale for such coupling is that building geometry has an impact on energy demands and solar potentials on roofs and façades, thus also altering the corresponding optimal energy system. As a demonstration of this approach, we formulate bi-objective optimization problems for minimizing operational cost and carbon emissions, with decision variables for building geometry and for selection and sizing of energy system technologies. The methodology is applied to a case study in the city of Zurich, Switzerland, involving four office buildings. Different carbon emissions targets are studied to show the impact on cost, densities, sizing of the multi-energy system, and architectural design implications. Results for this case study show a clear relation between emissions targets and densities due to available solar potentials for renewable energy generation, with an optimal density in the strictest emissions target reaching only 10% of the optimal density without emissions target. This indicates that differentiated environmental targets should be defined depending on the location of a building, where rural sites could have stricter targets than dense urban sites to reflect the respective marginal costs for achieving the targets. Our study shows that coupling multiple simulators into a common optimization and design workflow brings together architectural aspects, such as geometry, with engineering aspects, such as the energy system design, and microclimate conditions, such as local solar potentials. Thus, essential interdependencies between the energy supply and demand side can be captured in the design of energy efficient cities.}
}
@article{FENG2021103053,
title = {Unknown hostile environment-oriented autonomous WSN deployment using a mobile robot},
journal = {Journal of Network and Computer Applications},
volume = {182},
pages = {103053},
year = {2021},
issn = {1084-8045},
doi = {https://doi.org/10.1016/j.jnca.2021.103053},
url = {https://www.sciencedirect.com/science/article/pii/S1084804521000783},
author = {Sheng Feng and Haiyan Shi and Longjun Huang and Shigen Shen and Shui Yu and Hua Peng and Chengdong Wu},
keywords = {Unknown hostile environment, Optimal localizable k-coverage network, Path planning, Autonomous deployment, Wireless sensor networks},
abstract = {In this study, we consider the Internet of Things (IoT) with an autonomous deployment framework and seek optimal localizable k-coverage (OLKC) strategies to preserve the connectivity and robustness in IoT networks to assist robots during disaster recovery activities. Therefore, we define localizable k-coverage as the covered region within which a mobile robot can localize itself aided by k neighboring beacon nodes (BNs) in a wireless sensor network (WSN). To this end, we first propose the optimal localizable k-coverage WSN deployment problem (OLKWDP) and present a novel framework that preserves WSN connectivity and robustness for mobile robots. To localize a mobile robot with at least k BNs and overcome the network hole problem that can occur in unknown hostile environments, we propose a hole recovery method for the OLKC achieved by a mobile robot that knows the concurrent mapping, deployment and localization of the WSN. We then present a mapping-to-image transformation method to reveal the interactions between the WSN deployment and the network holes for the OLKC while constructing the online mapping. To solve the OLKWDP, we also develop two optimality conditions to achieve maximum coverage by the proposed OLKC in the unknown hostile environment using the minimum number of sensors. Moreover, we analyze the factors that influence the probability of success of the OLKC and the factors that influence the performance of a mobile robot when determining the WSN deployment. The simulation results illustrate that our framework outperforms the trilateration and spanning tree (TST) method in unknown hostile environment exploration and can achieve the OLKC in a WSN. In 27 simulated situations, our framework achieved average rates of nearly 100% 1-coverage, 91.34% 2-coverage and 89.00% 3-coverage.}
}
@article{LI2020316,
title = {SLAM integrated mobile mapping system in complex urban environments},
journal = {ISPRS Journal of Photogrammetry and Remote Sensing},
volume = {166},
pages = {316-332},
year = {2020},
issn = {0924-2716},
doi = {https://doi.org/10.1016/j.isprsjprs.2020.05.012},
url = {https://www.sciencedirect.com/science/article/pii/S0924271620301386},
author = {Shuaixin Li and Guangyun Li and Li Wang and Yuchu Qin},
keywords = {Mobile mapping, SLAM, Factor graph optimization, Seamless positioning, Data fusion},
abstract = {In this paper, a SLAM-integrated MMS with the capability of efficient, consistent and robust mapping in complex environments where GNSS signal is intermittently lost is presented. The system is developed to take the feedback from mapping module to the localization module into account, which significantly improves the smoothness of the 6 DOF trajectory estimation. In particular, the complex mapping problem is modeled as a hierarchical factor graph to improve the computation efficiency of the optimization back-end. Moreover, GNSS signal is modeled as a plug-and-play constrained factor to facilitate the mapping process in complex urban environments. We evaluate the performance of the proposed method on KITTI benchmark, and compare the result with both the GNNS/INS system and SuMa, which represents the traditional MMS and the typical laser SLAM system respectively. The results confirm that the proposed method enables normal and accurate mapping even when the inavailability of GNSS is up to 60%. It outperforms the traditional MMS in terms of map consistency with an increase of 24.7% on average MME, and outperforms laser SLAM in terms of the absolute accuracy with 5.9 times increase on average RMSE.}
}
@article{CHEN20143,
title = {Machine-to-machine communications: Technologies and challenges},
journal = {Ad Hoc Networks},
volume = {18},
pages = {3-23},
year = {2014},
issn = {1570-8705},
doi = {https://doi.org/10.1016/j.adhoc.2013.03.007},
url = {https://www.sciencedirect.com/science/article/pii/S1570870513000395},
author = {Kwang-Cheng Chen and Shao-Yu Lien},
keywords = {Machine-to-machine communications, Internet of Things, Cyber–physical systems, Multi-hop networks, Cognitive radio, Spectrum sharing, Swarm communications},
abstract = {Machine-to-machine (M2M) communications emerge to autonomously operate to link interactions between Internet cyber world and physical systems. We present the technological scenario of M2M communications consisting of wireless infrastructure to cloud, and machine swarm of tremendous devices. Related technologies toward practical realization are explored to complete fundamental understanding and engineering knowledge of this new communication and networking technology front.}
}
@article{COSTA2016121,
title = {Smart Cargo for Multimodal Freight Transport: When “Cloud” becomes “Fog”},
journal = {IFAC-PapersOnLine},
volume = {49},
number = {12},
pages = {121-126},
year = {2016},
note = {8th IFAC Conference on Manufacturing Modelling, Management and Control MIM 2016},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2016.07.561},
url = {https://www.sciencedirect.com/science/article/pii/S2405896316308187},
author = {R. Costa and R. Jardim-Goncalves and P. Figueiras and Margherita Forcolin and Mitja Jermol and Richard Stevens},
keywords = {Intelligent Transport Systems, Logistics, Smart Cargo, Fog Computing, Interoperability},
abstract = {Freight transport is recognized as a complex system that is affected by globalization effects, integration of different transport modes, geographically distributed operations and extended business models. Such complexity is also amplified by the need for the real-time response on the unexpected situations detected during the transportation phase (e.g. weather conditions, strikes, accidents). In a very demanding market, request for on-time cargo delivery, transport efficiency is a critical issue, and the ability for real-time detection and resolving of all possible obstacles and exceptions becomes a core competency for logistics operators. The work presented here introduces the concept of Smart Cargo, able to autonomously react to its context, find and understand alternatives, compute adaptive behavior, optimizing its own decisions. The Smart Cargo concept, implements a paradigm shift requiring taking the control of computing applications, data, and services away from some central nodes (the “cloud”) to the other logical extreme (the “fog”) of the Internet. Fog provides an intelligent connection of people, processes, data, and things, enabling Smart Cargo to go beyond the existing Intelligent Cargo concept. Fog computing is described here, as a necessary paradigm shift on distributed freight intelligence, allowing multimodal freight transport to achieve real-time situation awareness and reaction, planning with predictions and learning from the environment.}
}
@article{KAMARAESTEBAN2017279,
title = {MASSHA: An agent-based approach for human activity simulation in intelligent environments},
journal = {Pervasive and Mobile Computing},
volume = {40},
pages = {279-300},
year = {2017},
issn = {1574-1192},
doi = {https://doi.org/10.1016/j.pmcj.2017.07.007},
url = {https://www.sciencedirect.com/science/article/pii/S1574119216304072},
author = {Oihane Kamara-Esteban and Gorka Azkune and Ander Pijoan and Cruz E. Borges and Ainhoa Alonso-Vicario and Diego López-de-Ipiña},
keywords = {Intelligent environments, Activity recognition, Agent based modelling, Agent environment},
abstract = {Human activity recognition has the potential to become a real enabler for ambient assisted living technologies. Research on this area demands the execution of complex experiments involving humans interacting with intelligent environments in order to generate meaningful datasets, both for development and validation. Running such experiments is generally expensive and troublesome, slowing down the research process. This paper presents an agent-based simulator for emulating human activities within intelligent environments: MASSHA. Specifically, MASSHA models the behaviour of the occupants of a sensorised environment from a single-user and multiple-user point of view. The accuracy of MASSHA is tested through a sound validation methodology, providing examples of application with three real human activity datasets and comparing these to the activity datasets produced by the simulator. Results show that MASSHA can reproduce behaviour patterns that are similar to those registered in the real datasets, achieving an overall accuracy of 93.52% and 88.10% in frequency and 98.27% and 99.09% in duration for the single-user scenario datasets; and a 99.3% and 88.25% in terms of frequency and duration for the multiple-user scenario.}
}
@article{ZHOU2017164,
title = {A survey on trends of cross-media topic evolution map},
journal = {Knowledge-Based Systems},
volume = {124},
pages = {164-175},
year = {2017},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2017.03.009},
url = {https://www.sciencedirect.com/science/article/pii/S0950705117301272},
author = {Houkui Zhou and Huimin Yu and Roland Hu and Junguo Hu},
keywords = {Cross-media, Topic evolution, Topic map, Probabilistic generative model},
abstract = {Rapid advancements in internet and social media technologies have made “information overload” a rampant and widespread problem. Complex subjects, histories, or issues break down into branches, side stories, and intertwining narratives; a “topic evolution map” can assist in joining together and clarifying these disparate parts of an unfamiliar territory. This paper reviews the extant research on topic evolution map based on text and cross-media corpora over the past decade. We first define a series of necessary terms, then go on to describe the traditional topic evolution map per 1) topic evolution over time, based on the probabilistic generative model, and 2) topic evolution from a non-probabilistic perspective. Next, we discuss the current state of research on topic evolution map based on the cross-media corpus, including some open questions and possible future research directions. The main contribution of this review is in its construction of an evolution map that can be used to visualize and integrate the extant studies on topic modeling – specifically in regards to cross-media research.}
}
@article{SIMIC2022103669,
title = {Adapting Urban Transport Planning to the COVID-19 Pandemic: An Integrated Fermatean Fuzzy Model},
journal = {Sustainable Cities and Society},
volume = {79},
pages = {103669},
year = {2022},
issn = {2210-6707},
doi = {https://doi.org/10.1016/j.scs.2022.103669},
url = {https://www.sciencedirect.com/science/article/pii/S2210670722000038},
author = {Vladimir Simić and Ivan Ivanović and Vladimir Đorić and Ali Ebadi Torkayesh},
keywords = {Sustainability, COVID-19, Transport Planning, Multi-Criteria Decision-Making, Fermatean Fuzzy Set, CoCoSo},
abstract = {The critical worldwide problem of adapting urban transport planning to COVID-19 is for the first time comprehensively addressed and solved in this study. It primarily aims to help transport planners increase the resilience of transport systems. Firstly, a multi-level decision-making hierarchy structure based on four main criteria and 17 sub-criteria is introduced for relevant stakeholders to provide a practical framework for assessing existing transport plans. Then, a three-stage integrated Fermatean fuzzy model for adapting urban transport planning to the pandemic is presented. The model hybridizes the method based on the removal effects of criteria (MEREC) and combined compromise solution (CoCoSo) method into a unique methodological framework under the Fermatean fuzzy environment. A case study provides decision-making guidelines on how to adapt transport plans to COVID-19 in the real-world context of Belgrade, Serbia. The research findings show that the pandemic significantly changed the priorities of transport planning strategies and measures. “Non-motorized travel” is now the best alternative since its numerous short-term measures lead to better transport service. The major advantages of the introduced model are higher flexibility and a more precise fusion of experts’ preference information. The integrated Fermatean fuzzy model could be used for adapting other emerging problems to COVID-19.}
}
@article{WU201878,
title = {EDAWS: A distributed framework with efficient data analytics workspace towards discriminative services for critical infrastructures},
journal = {Future Generation Computer Systems},
volume = {81},
pages = {78-93},
year = {2018},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2017.11.009},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X17311184},
author = {Renke Wu and Linpeng Huang and Peng Yu and Haojie Zhou},
keywords = {Critical infrastructure systems, Parallel processing, Distributed environment, Lucene, Discriminative services,  framework},
abstract = {Critical infrastructure systems which are interrelated with people’s daily life perform functions in multiple domains. However, with the explosion of specialized textual information in such systems, providing discriminative services for users through potential knowledge discovery becomes an essential and technical concern. Once massive data analytics is conducted in standalone server, the performance will degenerate tremendously. Alternatively, people cannot conveniently get such discriminative (self-caring) services. To address these concerns, we propose the general solution of EDAWS: a Novel Distributed Framework with Efficient Data Analytics Workspace towards Discriminative Service for Critical Infrastructures, through leveraging the state-of-the-art software technologies and computing paradigms. We argue it from the following aspects: Firstly, the server-side platform facilitates native data capture, storage, index and data mining with a systematic organization. Secondly, a text-mining approach with index building in parallel is conducted for various functional business, by exploiting the potential of Lucene-based distributed cluster. Thirdly, with the widespread usage of tiny but powerful mobile devices, the server-side platform could be accessed by mobile-side clients remotely in a more convenient way. To demonstrate our solution, a case study of smart residence prototype towards discriminative services in terms of information retrieval, personalized information push, and hot topic discovery is thoroughly discussed. The extensively experimental studies are conducted for the prototype over various real-world datasets. Experimental results indicate that, data processing which runs on computing nodes has good scalability with data sizes and computing nodes, and the prototype passes from data to discriminative services successfully.}
}
@article{DEMIL201437,
title = {snapMac: A generic MAC/PHY architecture enabling flexible MAC design},
journal = {Ad Hoc Networks},
volume = {17},
pages = {37-59},
year = {2014},
issn = {1570-8705},
doi = {https://doi.org/10.1016/j.adhoc.2014.01.004},
url = {https://www.sciencedirect.com/science/article/pii/S1570870514000158},
author = {Pieter {De Mil} and Bart Jooris and Lieven Tytgat and Jeroen Hoebeke and Ingrid Moerman and Piet Demeester},
keywords = {Radio hardware abstraction, MAC/PHY architecture, Reconfigurable, MAC, Flexible, Time accurate radio driver},
abstract = {Timing is a key issue in many wireless, lower-layer (e.g., physical and data link layer) communication protocols. Maintaining time-critical behavior while increasing MAC protocol complexity is the challenge for many MAC implementations. To comply with stringent time constraints, current MAC implementations typically require such a tight integration to the radio driver that they become one monolithic block of code with MAC-specific logic hard coded at the lowest firmware level. Execution of time-critical functions in the firmware is a good strategy, but results in limited flexibility for MAC designers because the radio driver is dedicated for specific MAC protocol logic. We propose “snapMac”: a generic MAC/PHY architecture with a clean separation between the MAC protocol logic at the user level and the execution at the radio firmware level (Patent Pending). Our generic programming interface enables more flexibility, an easy way to compose new MAC designs, and getting feedback from the radio capabilities We demonstrate the feasibility and performance of this architecture by implementing it on a resource-constrained wireless sensor node. The experimental evaluation shows, for example, that we can simultaneously keep the flexibility of a software ACK and meet the ACK timing constraints as specified in the 802.15.4 standard. We also achieve 97% (i.e., 218kbit/s) of the theoretical 802.15.4 throughput. This new implementation approach for MAC/PHY interactions has potential to be applied in other domains (e.g., WiFi, software defined radio, cognitive radio, etc.). Demonstrating the portability of snapMac is future work. “snapMac” enables the design and execution of new MAC protocols in a snap.}
}
@article{RAUT2019100117,
title = {Improvement in the food losses in fruits and vegetable supply chain - a perspective of cold third-party logistics approach},
journal = {Operations Research Perspectives},
volume = {6},
pages = {100117},
year = {2019},
issn = {2214-7160},
doi = {https://doi.org/10.1016/j.orp.2019.100117},
url = {https://www.sciencedirect.com/science/article/pii/S2214716019300028},
author = {Rakesh D. Raut and Bhaskar B. Gardas and Vaibhav S. Narwane and Balkrishna E. Narkhede},
keywords = {Food losses, Waste, Fruits and vegetable supply chain, Cold third-party logistic (CTPLs), Fuzzy-DEMATEL, Fuzzy-AHP},
abstract = {The maximum amount of food losses in the fruits and vegetable supply chain due to quality and mismatch between supply and demand. As per the Global Agenda Council on Logistics and Supply Chains indicated that fruits and vegetables food losses due to improper handling and lack of proper cold transportation such as cold-logistics facilities/providers or inadequate infrastructure. In this article, a unique fuzzy Multi-Criteria Decision Making approach is proposed for improving the food losses through cold-third party logistics providers (CTPLs) evaluation and selection process. Through a literature survey and expert opinion, five criteria and thirty sub-criteria were identified for reducing the food losses in fruits and vegetable supply chain. The proposed tool use of fuzzy-Decision making trial and evaluation laboratory tool for selection and evaluation the priority weights of the factors and fuzzy-analytical hierarchy process tool assessing the best CTPLs according to factors. The result shows that ‘Refrigerator and loading capacity’ and ‘Knowledge and Information technology management’ were most significant in the selection of CTPLs. The findings of this paper are anticipated to guide managers of the food industry, CTPLs, and government agencies in formulating of strategies for the practical food supply chain. Future scope includes extending the study for other developing countries, validating the proposed methodology, and improving the reliability of the model.}
}
@article{FADDA2021102174,
title = {Comparative analysis of models and performance indicators for optimal service facility location},
journal = {Transportation Research Part E: Logistics and Transportation Review},
volume = {145},
pages = {102174},
year = {2021},
issn = {1366-5545},
doi = {https://doi.org/10.1016/j.tre.2020.102174},
url = {https://www.sciencedirect.com/science/article/pii/S1366554520308176},
author = {Edoardo Fadda and Daniele Manerba and Gianpiero Cabodi and Paolo Enrico Camurati and Roberto Tadei},
keywords = {Facility location, Key performance indicators, Back-up coverage, Progressive interventions},
abstract = {This study investigates the optimal process for locating generic service facilities by applying and comparing several well-known basic models from the literature. At a strategic level, we emphasize that selecting the right location model to use could result in a problematic and possibly misleading task if not supported by appropriate quantitative analysis. For this reason, we propose a general methodological framework to analyze and compare the solutions provided by several models to obtain a comprehensive evaluation of the location decisions from several different perspectives. Therefore, a battery of key performance indicators (KPIs) has been developed and calculated for the different models’ solutions. Additional insights into the decision process have been obtained through a comparative analysis. The indicators involve topological, coverage, equity, robustness, dispersion, and accessibility aspects. Moreover, a specific part of the analysis is devoted to progressive location interventions over time and identifying core location decisions. Results on randomly generated instances, which simulate areas characterized by realistic geographical or demographic features, are reported to analyze the models’ behavior in different settings and demonstrate the methodology’s general applicability. Our experimental campaign shows that the p-median model behaves very well against the proposed KPIs. In contrast, the maximal covering problem and some proposed back-up coverage models return very robust solutions when the location plan is implemented through several progressive interventions over time.}
}
@article{BOUTIGNY2020101662,
title = {Solving security constraints for 5G slice embedding: A proof-of-concept},
journal = {Computers & Security},
volume = {89},
pages = {101662},
year = {2020},
issn = {0167-4048},
doi = {https://doi.org/10.1016/j.cose.2019.101662},
url = {https://www.sciencedirect.com/science/article/pii/S0167404819302044},
author = {François Boutigny and Stéphane Betgé-Brezetz and Gregory Blanc and Antoine Lavignotte and Hervé Debar and Houda Jmila},
keywords = {Virtual network embedding, Network slicing, 5G Security, Satisfiability modulo theories, Network virtualization},
abstract = {Network slicing is a prominent feature of 5G, which allow tenants to rent network and computing virtual resources from one or more Infrastructure Providers (InPs). Those resources are allocated according to tenants requirements, not only in terms of QoS but also in terms of security. In this paper, we build on our previous work to propose and evaluate a security-aware slice embedding implementation which enables tenants to declare security-oriented requirements, while limiting InP network information disclosure. To do so we improve our requirement model so that it becomes compatible with an Satisfiability Modulo Theories (SMT) formulation. Our implementation distinguishes two sub-problems, one for the intra-domain level (inside each InP) and one for the inter-domain level (in between the InPs). We leverage those sub-problems in a multi-level resolution algorithm to generate all multi-domain slice embeddings.}
}
@article{LIU201713,
title = {Modeling cyber-physical attacks based on probabilistic colored Petri nets and mixed-strategy game theory},
journal = {International Journal of Critical Infrastructure Protection},
volume = {16},
pages = {13-25},
year = {2017},
issn = {1874-5482},
doi = {https://doi.org/10.1016/j.ijcip.2016.11.002},
url = {https://www.sciencedirect.com/science/article/pii/S1874548216300798},
author = {Xiaoxue Liu and Jiexin Zhang and Peidong Zhu},
keywords = {Cyber-Physical Systems, Cyber-Physical Attacks, Systematic Quantitative Modeling Approach, Dependency Model, Attack Model, Probabilistic Colored Petri Nets, Mixed-Strategy Attack-Defense Game Model},
abstract = {Cyber-physical attacks are posing great threats to the safety and security of cyber-physical systems. Modeling cyber-physical attacks reasonably and efficiently is the basis for defending cyber-physical systems effectively, which requires the development of quantitative analysis and modeling approaches for expressing threat propagation in cyber-physical systems. This paper extends the colored Petri net model by defining a probabilistic colored Petri net model that comprises basic models, rules, logical operators and transitions that describe threat propagation between nodes. Basic cyber-physical attack models based on probabilistic colored Petri nets are presented. Furthermore, a systematic modeling approach is presented for constructing a quantitative cyber-physical attack model for a cyber-physical system. The weights of the cyber-physical attack model connections are computed using a mixed-strategy attack-defense game model for each node and solving the Nash equilibrium. Additionally, a hierarchical method of division and integration is proposed to efficiently model complex, large-scale cyber-physical systems. Finally, the systematic cyber-physical attack modeling approach is applied to a case study involving a thermal power plant.}
}
@article{KARKOUCH201657,
title = {Data quality in internet of things: A state-of-the-art survey},
journal = {Journal of Network and Computer Applications},
volume = {73},
pages = {57-81},
year = {2016},
issn = {1084-8045},
doi = {https://doi.org/10.1016/j.jnca.2016.08.002},
url = {https://www.sciencedirect.com/science/article/pii/S1084804516301564},
author = {Aimad Karkouch and Hajar Mousannif and Hassan {Al Moatassime} and Thomas Noel},
keywords = {Internet of things, Data quality, Data cleaning, Outlier detection},
abstract = {In the Internet of Things (IoT), data gathered from a global-scale deployment of smart-things, are the base for making intelligent decisions and providing services. If data are of poor quality, decisions are likely to be unsound. Data quality (DQ) is crucial to gain user engagement and acceptance of the IoT paradigm and services. This paper aims at enhancing DQ in IoT by providing an overview of its state-of-the-art. Data properties and their new lifecycle in IoT are surveyed. The concept of DQ is defined and a set of generic and domain-specific DQ dimensions, fit for use in assessing IoT's DQ, are selected. IoT-related factors endangering the DQ and their impact on various DQ dimensions and on the overall DQ are exhaustively analyzed. DQ problems manifestations are discussed and their symptoms identified. Data outliers, as a major DQ problem manifestation, their underlying knowledge and their impact in the context of IoT and its applications are studied. Techniques for enhancing DQ are presented with a special focus on data cleaning techniques which are reviewed and compared using an extended taxonomy to outline their characteristics and their fitness for use for IoT. Finally, open challenges and possible future research directions are discussed.}
}
@article{SOARES2017845,
title = {A review on current advances in the energy and environmental performance of buildings towards a more sustainable built environment},
journal = {Renewable and Sustainable Energy Reviews},
volume = {77},
pages = {845-860},
year = {2017},
issn = {1364-0321},
doi = {https://doi.org/10.1016/j.rser.2017.04.027},
url = {https://www.sciencedirect.com/science/article/pii/S1364032117305270},
author = {N. Soares and J. Bastos and L. Dias Pereira and A. Soares and A.R. Amaral and E. Asadi and E. Rodrigues and F.B. Lamas and H. Monteiro and M.A.R. Lopes and A.R. Gaspar},
keywords = {Buildings, Environmental performance, Energy efficiency, Thermal performance, Design and retrofitting, End-users behaviors},
abstract = {Nowadays, debates addressing climate change, fossil fuels depletion and energy security highlight the need for a more sustainable built environment in order to reduce energy consumption and emission trends in the buildings sector. Meeting these targets is a challenge that calls for innovative research to improve the use of renewable energy sources, new technologies, and holistic tools and methodologies. Such research should integrate the dynamics and main drivers of energy supply and demand in buildings to support new policies, plans and actions towards lowering the built environment burdens. This paper brings together ten research topics concerning the energy and environmental performance of buildings, which can support a shift towards a more sustainable built environment. Background information and state of the art literature on the covered research topics is briefly summarized, gaps are identified and guidelines for future research are provided. The selected topics cover different stages along the lifetime of buildings (from design and operation, to retrofitting and end-of-life), different scale approaches (from building elements/components, to the building, district and urban scales), and different methods to assess the energy and environmental performance of buildings (life-cycle assessment, generative design methods and retrofitting tools). Other topics are discussed such as: nearly zero-energy buildings, the control of domestic energy resources in smart grid scenarios, the need to include end-users' behaviors in the dynamics of energy demand, the advantages of improving thermal storage by using phase change materials, the importance of reducing heating and cooling energy demand (maintaining indoor thermal comfort), and the optimization of heating and cooling fluids, and their system control.}
}
@article{SOTELOMONGE2021869,
title = {Conceptualization and cases of study on cyber operations against the sustainability of the tactical edge},
journal = {Future Generation Computer Systems},
volume = {125},
pages = {869-890},
year = {2021},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2021.07.016},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X21002788},
author = {Marco Antonio {Sotelo Monge} and Jorge {Maestre Vidal}},
keywords = {Cyber defense, Economical Denial of Sustainability, Military operations, Situational Awareness, Tactical Denial of Sustainability},
abstract = {The last decade consolidated the cyberspace as fifth domain of military operations, which extends its preliminarily intelligence and information exchange purposes towards enabling complex offensive and defensive operations supported/supportively of parallel kinetic domain actuations. Although there is a plethora of well documented cases on strategic and operational interventions of cyber commands, the cyber tactical military edge is still a challenge, where cyber fires barely integrate to the traditional joint targeting cycle due to, among others, long planning/development times, asymmetric effects, strict target reachability requirements, or the fast propagation of collateral damage; the latter rapidly deriving on hybrid impacts (political, economic, social, etc.) and evidencing significant socio-technical gaps. In this context, it is expected that Tactical Clouds disruptively facilitate cyber operations at the edge while exposing the rest of the digital assets of the operation to them. On these grounds, the main purpose of the conducted research is to review and in depth analyze the risks and opportunities of jeopardizing the sustainability of the military Tactical Clouds at their cyber edge. Along with a 1) comprehensively formulation of the researched problematic, the study 2) formalizes the Tactical Denial of Sustainability (TDoS) concept; 3) introduces the phasing, potential attack surfaces, terrains and impact of TDoS attacks; 4) emphasizes the related human and socio-technical aspects; 5) analyzes the threats/opportunities inherent to their impact on the cloud energy efficiency; 6) reviews their implications at the military cyber thinking for tactical operations; 7) illustrates five extensive CONOPS that facilitate the understanding of the TDoS concept; and given the high novelty of the discussed topics, this paper 8) paves the way for further research and development actions.}
}
@article{RAJABION2019271,
title = {Healthcare big data processing mechanisms: The role of cloud computing},
journal = {International Journal of Information Management},
volume = {49},
pages = {271-289},
year = {2019},
issn = {0268-4012},
doi = {https://doi.org/10.1016/j.ijinfomgt.2019.05.017},
url = {https://www.sciencedirect.com/science/article/pii/S0268401217304917},
author = {Lila Rajabion and Abdusalam Abdulla Shaltooki and Masoud Taghikhah and Amirhossein Ghasemi and Arshad Badfar},
keywords = {Cloud computing, Processing, Healthcare, Big data, Review},
abstract = {Recently, patient safety and healthcare have gained high attention in professional and health policy-makers. This rapid growth causes generating a high amount of data, which is known as big data. Therefore, handling and processing of this data are attracted great attention. Cloud computing is one of the main choices for handling and processing of this type of data. But, as far as we know, the detailed review and deep discussion in this filed are very rare. Therefore, this paper reviews and discusses the recently introduced mechanisms in this field as well as providing a deep analysis of their applied mechanisms. Moreover, the drawbacks and benefits of the reviewed mechanisms have been discussed and the main challenges of these mechanisms are highlighted for developing more efficient healthcare big data processing techniques over cloud computing in the future.}
}
@article{WANG2022235,
title = {LIAA: A listen interval adaptive adjustment scheme for green communication in event-sparse IoT systems},
journal = {Information Sciences},
volume = {584},
pages = {235-268},
year = {2022},
issn = {0020-0255},
doi = {https://doi.org/10.1016/j.ins.2021.10.045},
url = {https://www.sciencedirect.com/science/article/pii/S0020025521010616},
author = {Han Wang and Wei Liu and Neal N. Xiong and Shaobo Zhang and Tian Wang},
keywords = {Sensor based system, Duty cycle, Delay, Energy saving, Lifetime, Listen interval adaptive adjustment},
abstract = {Due to the development of microprocessor technology, there are more than 20 billion sensor-based devices connected to the Internet of Things (IoT) to monitor physical phenomena and events. To reduce the energy used by idle listening, a low-duty cycle is often used in an event-sparse wireless sensor network. However, low-duty cycles bring large end-to-end delays. In this paper, a listen interval adaptive adjustment (LIAA) scheme is proposed to adjust the listen interval (LI) of a node to reduce end-to-end delays while maintaining the long lifetime of a network. The key idea is to make full use of the energy consumption imbalance in a network, to allow nodes away from the sink to use the residual energy to add listen intervals. The LIAA scheme has 3 sub-strategies. One is the basic add listen interval (BALI) strategy, in which the parent node adds listen intervals in the fixed active slots of its child nodes. Another strategy is the consecutive listen (CL) scheme, which is based on BALI, and listen intervals are added consecutively. The third strategy is the random add listen interval (RALI) scheme, which uses the idea of randomness to add listen intervals. The extensive theoretical analysis and experimental results show that the LIAA scheme proposed in this paper has better performance. Compared with the traditional scheme, the delays in the BALI scheme, CL scheme and RALI scheme were reduced by 24.03%, 23.45% and 39.41%, respectively, while the lifetime of the network was maintained.}
}
@article{TOSELLO2019153,
title = {Using robotics to train students for Industry 4.0},
journal = {IFAC-PapersOnLine},
volume = {52},
number = {9},
pages = {153-158},
year = {2019},
note = {12th IFAC Symposium on Advances in Control Education ACE 2019},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2019.08.185},
url = {https://www.sciencedirect.com/science/article/pii/S2405896319305221},
author = {Elisa Tosello and Nicola Castaman and Emanuele Menegatti},
keywords = {Education, Robotics, ROS, Industry 4.0, Robotic manipulation, Robot navigation},
abstract = {This paper presents the master course on Autonomous Robotics that we offer at the School of Engineering of the University of Padova (Italy). Its novelty is the assignment of a lab project carefully designed to train students on autonomous and industrial robotics in the framework of Industry 4.0: the “Industry 4.0 Robotics Challenge”. Students have to program both a manipulator and a mobile robot, together with a 3D vision system, in order to collaborate in the fulfillment of a pick-place-transport industrial task. We adopt a constructionist approach: project-based learning and team-based learning are applied to robotics and Industry 4.0. The project is organized as a challenge to motivate students to propose innovative ideas. A survey on students’ satisfaction is reported at the end of the paper. We made the description of both the hardware and software setup, together with tutorials and wikis, publicly available to let other robotics instructors replicate our proposal and make it a point of reference for teaching robotics in the frame of Industry 4.0.}
}
@article{HAILE2021107692,
title = {End-to-end congestion control approaches for high throughput and low delay in 4G/5G cellular networks},
journal = {Computer Networks},
volume = {186},
pages = {107692},
year = {2021},
issn = {1389-1286},
doi = {https://doi.org/10.1016/j.comnet.2020.107692},
url = {https://www.sciencedirect.com/science/article/pii/S1389128620312974},
author = {Habtegebreil Haile and Karl-Johan Grinnemo and Simone Ferlin and Per Hurtig and Anna Brunstrom},
keywords = {TCP, QUIC, Wireless, Mobile, 4G, 5G, Congestion control, Survey},
abstract = {Cellular networks have evolved to support high peak bitrates with low loss rates as observed by the higher layers. However, applications and services running over cellular networks are now facing other difficult congestion-related challenges, most notably a highly variable link capacity and bufferbloat. To overcome these issues and improve performance of network traffic in 4G/5G cellular networks, a number of in-network and end-to-end solutions have been proposed. Fairness between interacting congestion control algorithms (CCAs) has played an important role in the type of CCAs considered for research and deployment. The placement of content closer to the user and the allocation of per-user queues in cellular networks has increased the likelihood of a cellular access bottleneck and reduced the extent of flow interaction between multiple users. This has resulted in renewed interest in end-to-end CCAs for cellular networks by opening up room for research and exploration. In this work, we present end-to-end CCAs that target a high throughput and a low latency over highly variable network links, and classify them according to the way they address the congestion control. The work also discusses the deployability of the algorithms. In addition, we provide insights into possible future research directions, such as coping with a higher degree of variability, interaction of CCAs in a shared bottleneck, and avenues for synergized research, such as CCAs assisted by software defined networking and network function virtualization. We hope that this work will serve as a starting point for systematically navigating through the expanding number of cellular CCAs.}
}
@article{GHIASSI2017372,
title = {Reductive bottom-up urban energy computing supported by multivariate cluster analysis},
journal = {Energy and Buildings},
volume = {144},
pages = {372-386},
year = {2017},
issn = {0378-7788},
doi = {https://doi.org/10.1016/j.enbuild.2017.03.004},
url = {https://www.sciencedirect.com/science/article/pii/S0378778817307508},
author = {Neda Ghiassi and Ardeshir Mahdavi},
keywords = {Urban energy computing, Urban energy modeling, GIS, Multivariate cluster analysis, Building stock, Sampling},
abstract = {The present research effort investigates the requirements of an urban energy computing environment, aimed to support strategic decision making with regard to physical and technological interventions as well as behavioral, and contextual changes. Providing an analytical overview of some previous efforts, the present contribution introduces a novel two-step approach toward bottom-up urban energy computing, involving a reductive phase and a re-diversification process. The reductive phase is performed through an automated process within a GIS platform. The developed process utilizes available large-scale data to generated an energy-relevant representation of the urban building stock. A matrix of energy-influential building characteristics, depicted as aggregate descriptive indicators, is computed based on the generated representation and subjected to multivariate cluster analysis methods for stock classification. The resulting classes are represented through typical buildings, which undergo detailed performance simulation computations. The re-diversification process addresses the loss of diversity due to the reductive method, through employment of stochastic occupancy models and model parametrization. This paper reports on the development of the reductive step, illustrating the encountered challenges and the adopted responses.}
}
@article{BERNABE2020409,
title = {ARIES: Evaluation of a reliable and privacy-preserving European identity management framework},
journal = {Future Generation Computer Systems},
volume = {102},
pages = {409-425},
year = {2020},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2019.08.017},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X1930843X},
author = {Jorge Bernal Bernabe and Martin David and Rafael Torres Moreno and Javier Presa Cordero and Sébastien Bahloul and Antonio Skarmeta},
keywords = {Privacy, Security, Risk reduction, Identity management systems, Identification, Biometrics, Virtual identities, Identity derivation, Secure wallet},
abstract = {Despite several efforts in the last years to make Identity Management Systems (IdMs) reliable, secured and privacy-respectful, identity-related cybercrimes are still continuously expanding. Current IdMs lack of proper security and privacy mechanisms that can holistically manage user’s privacy, strong authentication and ID-proofing mechanisms based on biometrics, usage of breeder documents, while maintaining usability for mobile, online or face-to-face scenarios. To fill this gap, the ARIES EU project aims to set up a reliable identity ecosystem, combining mature technologies for meet highest level of assurance, such as biometrics or use of secure elements, with innovative credential derivation mechanisms. ARIES has devised and implemented a privacy-preserving and user-centric Identity Management framework as well as associated management practices that ensure usability and flexibility for identity management processes. This paper presents ARIES results obtained after the successful development and validation of the ARIES IdM System in the associated use cases.}
}
@article{AMMAR20188,
title = {Internet of Things: A survey on the security of IoT frameworks},
journal = {Journal of Information Security and Applications},
volume = {38},
pages = {8-27},
year = {2018},
issn = {2214-2126},
doi = {https://doi.org/10.1016/j.jisa.2017.11.002},
url = {https://www.sciencedirect.com/science/article/pii/S2214212617302934},
author = {Mahmoud Ammar and Giovanni Russello and Bruno Crispo},
keywords = {Internet of Things, IoT, Framework, Platform, Security},
abstract = {The Internet of Things (IoT) is heavily affecting our daily lives in many domains, ranging from tiny wearable devices to large industrial systems. Consequently, a wide variety of IoT applications have been developed and deployed using different IoT frameworks. An IoT framework is a set of guiding rules, protocols, and standards which simplify the implementation of IoT applications. The success of these applications mainly depends on the ecosystem characteristics of the IoT framework, with the emphasis on the security mechanisms employed in it, where issues related to security and privacy are pivotal. In this paper, we survey the security of the main IoT frameworks, a total of 8 frameworks are considered. For each framework, we clarify the proposed architecture, the essentials of developing third-party smart apps, the compatible hardware, and the security features. Comparing security architectures shows that the same standards used for securing communications, whereas different methodologies followed for providing other security properties.}
}
@article{AFZAL2019718,
title = {Enabling IoT platforms for social IoT applications: Vision, feature mapping, and challenges},
journal = {Future Generation Computer Systems},
volume = {92},
pages = {718-731},
year = {2019},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2017.12.002},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X17312724},
author = {Bilal Afzal and Muhammad Umair and Ghalib {Asadullah Shah} and Ejaz Ahmed},
keywords = {Social IoT, Operating systems, Microcontroller architecture, Embedded systems, Resource-constrained devices},
abstract = {Social IoT (SIoT) is an emerging paradigm of IoT in which different IoT devices interact and establish relationships with each other to achieve a common goal. In essence, SIoT adapts a service-oriented architecture where heterogeneous IoT devices can offer or request autonomous services and collaborate on behalf of their owners. Operating Systems (OSs) are employed in IoT devices as they offer portability, threading support and access to development libraries; thus allowing easiness in IoT application development. Several OSs are available for IoT devices, but selecting an OS and hardware befitting for a particular IoT application is a critical task. In case of SIoT, the specific OS selection for hardware devices in various applications is even more challenging because of their collaborative nature. Existing surveys on OSs are mostly domain oriented and lack the discussion on hardware architectural features. As a consequence, it is infeasible for developers to choose best-suited OS for various hardware platforms which results in their underperformance in many application scenarios. This paper considers standard features of OS as well as hardware IoT platforms and provides an OS-to-hardware architectures features-mapping while exploring the unique requirements of SIoT applications. In doing so, resource-constrained IoT devices are particularly emphasized due to their memory constraints and power limitations. Further, a model OS architecture is proposed for devices in SIoT applications and associated open research challenges are identified. This research will benefit developers to best utilize IoT platform resources and to envisage an efficient OS for futuristic SIoT applications.}
}
@article{NIZAMI2020114322,
title = {A residential energy management system with bi-level optimization-based bidding strategy for day-ahead bi-directional electricity trading},
journal = {Applied Energy},
volume = {261},
pages = {114322},
year = {2020},
issn = {0306-2619},
doi = {https://doi.org/10.1016/j.apenergy.2019.114322},
url = {https://www.sciencedirect.com/science/article/pii/S0306261919320094},
author = {M.S.H. Nizami and M.J. Hossain and B.M. Ruhul Amin and Edstan Fernandez},
keywords = {Demand response, Building energy management system, Distributed energy resources, Mixed-integer programming, Bi-level optimization},
abstract = {Bi-directional electricity trading of demand response (DR) and transactive energy (TE) frameworks allows the traditionally passive end-users of electricity to play an active role in the local power balance of the grid. Appropriate building energy management systems (BEMSs), coupled with an optimized bidding strategy, can provide significant cost savings for prosumers (consumers with on-site power generation and/or storage facility) when they participate in such bi-directional trading. This paper presents a BEMS with an optimization-based scheduling and bidding strategy for small-scale residential prosumers to determine optimal day-ahead energy-quantity bids considering the expected cost of real-time imbalance trading under uncertainty. The proposed scheduling and bidding strategy is formulated as a stochastic bi-level minimization problem that determines the day-ahead energy-quantity bids by minimizing the energy cost in the upper level considering expected cost of uncertainty, whereas a number of lower-level sub-problems ensure optimal operation of building loads and distributed energy resources (DERs) for comfort reservation, minimization of consumers’ inconveniences and degradation of residential storage units. A modified decomposition method is used to reformulate the nonlinear bi-level problem as a mixed-integer linear programming (MILP) problem and solved using ‘of the shelf’ commercial software. The effectiveness of the proposed BEMS model is verified via case studies for a residential prosumer in Sydney, Australia with real measurement data for building energy demand. The efficacy of the proposed method for overall financial savings is also validated by comparing its performance with state-of-the-art day-ahead scheduling strategies. Case studies indicate that the proposed method can provide up to 51% and 22% cost savings compared to inflexible non-optimal scheduling strategies and deterministic optimization-based methods respectively. Results also indicate that the proposed method offers better economic performance than standard cost minimization models and multi-objective methods for simultaneous minimization of energy cost and user inconveniences.}
}
@article{REHAN2020102552,
title = {QCM2R: A QoS-aware cross-layered multichannel multisink routing protocol for stream based wireless sensor networks},
journal = {Journal of Network and Computer Applications},
volume = {156},
pages = {102552},
year = {2020},
issn = {1084-8045},
doi = {https://doi.org/10.1016/j.jnca.2020.102552},
url = {https://www.sciencedirect.com/science/article/pii/S1084804520300266},
author = {Waqas Rehan and Stefan Fischer and Maaz Rehan and Yasser Mawad and Shahzad Saleem},
abstract = {Unlike the scalar data (such as temperature, pressure and humidity), the vector data (such as image, audio and video) necessitates more stringent Quality of Service (QoS) requirements in terms of bandwidth, delay, reliability and information security. These QoS requirements can be hardly achieved in a proper fashion by using a single channel for wireless communication. However, multichannel methodology may assist in accomplishing these QoS requirements by making possible parallel communication, enhancing throughput/delivery ratio, reducing transmission delay and countering jamming attacks. Furthermore, enabling data gathering at multiple points (i.e. multisink approach) may improve QoS by handling congestion, avoiding single point of failure issue and making possible load balancing between the available routes towards the corresponding destinations. To achieve reliable communication in stream based multichannel Wireless Sensor Networks (WSNs), this work proposes a novel QoS-aware Cross-layered Multichannel Multisink Routing protocol (QCM2R) for WSNs. For substantiating the performance of QCM2R protocol, the simulations are performed in NS-2 demonstrating the performance superiority of the proposed QCM2R protocol against the counterpart in terms of network lifetime, reliability, delay and throughput.}
}
@article{VELIK2014384,
title = {Grid-price-dependent energy management in microgrids using a modified simulated annealing triple-optimizer},
journal = {Applied Energy},
volume = {130},
pages = {384-395},
year = {2014},
issn = {0306-2619},
doi = {https://doi.org/10.1016/j.apenergy.2014.05.060},
url = {https://www.sciencedirect.com/science/article/pii/S0306261914005650},
author = {Rosemarie Velik and Pascal Nicolay},
keywords = {Renewable energy, Battery storage, Energy management, Variable grid prices, Microgrids, Optimization},
abstract = {This article introduces a modified simulated annealing triple-optimizer for finding the optimal energy management strategy in terms of financial gain maximization in grid-connected, storage-augmented, photovoltaics-supplied prosumer building microgrids in a variable grid price scenario. For evaluating the performance of the optimizer, a number of test cases are specified offering different trading options to the prosumers. Obtained results are compared to a total state space search reference method and demonstrate that the simulated annealing approach was for all test cases able to find a globally optimal or close to optimal solution in significantly less computation time than the total space search reference method.}
}
@article{GORISSEN2018171,
title = {Moving towards systemic change? Investigating acceleration dynamics of urban sustainability transitions in the Belgian City of Genk},
journal = {Journal of Cleaner Production},
volume = {173},
pages = {171-185},
year = {2018},
note = {Sustainable urban transformations towards smarter, healthier cities: theories, agendas and pathways},
issn = {0959-6526},
doi = {https://doi.org/10.1016/j.jclepro.2016.12.052},
url = {https://www.sciencedirect.com/science/article/pii/S0959652616321072},
author = {Leen Gorissen and Felix Spira and Erika Meynaerts and Pieter Valkering and Niki Frantzeskaki},
keywords = {Acceleration, Urban transitions, Transition initiatives, Sustainability, Transition governance},
abstract = {In recent years, multiple transformative initiatives have been set up in cities across the world to kick-start transitions of urban systems towards sustainability. Yet to what extent do these initiatives influence systemic change or accelerate sustainability transitions? We apply an analytical framework, conceptualizing five mechanisms representing acceleration dynamics of sustainability transitions – replicating, partnering, upscaling, instrumentalising and embedding – to examine transition dynamics in the Belgian City of Genk. The focal unit of analysis are the innovative activities and related actor-networks from the city region, defined as ‘transition initiatives’, situated within the local governance context. We selected 10 local transition initiatives with a clear focus on environmental sustainability and set out to understand their origins and identify conditions and mechanisms for accelerating sustainable low-carbon transitions. Our findings show that all five mechanisms of acceleration are occurring in Genk at the moment and that the local governance context is favourable for accelerating transition dynamics to sustainability, mostly because it promotes diffusion, partnering and embedding processes. For instance, one initiative that proved to be a hotspot for partnering is the Heempark, a Public-Civic Partnership in which volunteers and the government collaborate in a mutually beneficial way. Our findings provide early indications of mounting changes, increasing reflexivity and coordination from governance actors and diffusion, embedding and routinisation of more sustainable ways of thinking, doing and organising in the wider public. These acceleration dynamics are most apparent in the food, nature, resource and education domain in Genk and are mostly fuelled via multi-actor collaborations. On an aggregate level, these observations suggest that socio-cultural, economic, ecological and institutional changes are accumulating. We therefore conclude that early but fragile acceleration dynamics are unfolding in Genk. Our findings are relevant to deepen the understanding of transition scholars on the acceleration dynamics of urban sustainability transitions and may be of particular interest for practitioners on the field.}
}
@article{VANRIJMENAM2019101841,
title = {Avoid being the Turkey: How big data analytics changes the game of strategy in times of ambiguity and uncertainty},
journal = {Long Range Planning},
volume = {52},
number = {5},
pages = {101841},
year = {2019},
issn = {0024-6301},
doi = {https://doi.org/10.1016/j.lrp.2018.05.007},
url = {https://www.sciencedirect.com/science/article/pii/S0024630117303606},
author = {Mark {van Rijmenam} and Tatiana Erekhinskaya and Jochen Schweitzer and Mary-Anne Williams},
keywords = {Big data, Dynamic capabilities, Strategy, Data analytics},
abstract = {In order for organisations to remain competitive in times of ambiguity and uncertainty, there is a need to detect and anticipate unknown unknowns, also called ‘black swans’. When these are ignored they may lead to competitive struggles. In this paper, we build on this view and suggest that big data analytics can provide necessary insights to help change strategy making. Research suggests that ambidextrous organisations should focus on developing and maintaining their dynamic capabilities. Following on from this, we take a dynamic capabilities perspective and propose a theoretical framework to explain the intricacies of big data analytics. This framework explains the ability of organisations to detect, anticipate and respond strategically in ambiguous and uncertain business environments. For a meta-synthesis of 101 cases of big data analytics, we employ a multi-method approach that incorporates Natural Language Processing, semantic analysis and case analysis, allowing extraction and analysis of structured information from unstructured data. Overall, we find evidence of big data analytics helping to detect, anticipate and respond to industry disruption. We offer six propositions about the relationships between the levels of data analytics capabilities and strategic dynamic capabilities. We find that descriptive data analytics improves the capability of an organisation to understand the business context (sensing) and that predictive data analytics aids in the realisation of business opportunities (seizing). This study contributes to an understanding of big data analytics as a dynamic organisational capability that supports strategic decision-making in times of ambiguity and uncertainty. We conclude by suggesting areas for further investigation, particularly in regard to the strategic application of prescriptive data analytics.}
}
@article{BUSHNAQ2020102659,
title = {Sensor placement and resource allocation for energy harvesting IoT networks},
journal = {Digital Signal Processing},
volume = {105},
pages = {102659},
year = {2020},
note = {Special Issue on Optimum Sparse Arrays and Sensor Placement for Environmental Sensing},
issn = {1051-2004},
doi = {https://doi.org/10.1016/j.dsp.2020.102659},
url = {https://www.sciencedirect.com/science/article/pii/S105120042030004X},
author = {Osama M. Bushnaq and Anas Chaaban and Sundeep Prabhakar Chepuri and Geert Leus and Tareq Y. Al-Naffouri},
keywords = {Convex optimization, Source estimation, Sensor selection, Wireless sensor networks},
abstract = {Optimal sensor selection for source parameter estimation in energy harvesting Internet of Things (IoT) networks is studied in this paper. Specifically, the focus is on the selection of the sensor locations which minimizes the estimation error at a fusion center, and to optimally allocate power and bandwidth for each selected sensor subject to a prescribed spectral and energy budget. To do so, measurement accuracy, communication link quality, and the amount of energy harvested are all taken into account. The sensor selection is studied under both analog and digital transmission schemes from the selected sensors to the fusion center. In the digital transmission case, an information theoretic approach is used to model the transmission rate, observation quantization, and encoding. We numerically prove that with a sufficient system bandwidth, the digital system outperforms the analog system with a possibly different sensor selection. The design problem of interest is a Boolean non convex optimization problem, which is solved by relaxing the Boolean constraints. To efficiently round the obtained relaxed solution, we propose a randomized rounding algorithm which generalizes the existing algorithm.}
}
@article{CORTEREAL2020103141,
title = {Leveraging internet of things and big data analytics initiatives in European and American firms: Is data quality a way to extract business value?},
journal = {Information & Management},
volume = {57},
number = {1},
pages = {103141},
year = {2020},
note = {Big data and business analytics: A research agenda for realizing business value},
issn = {0378-7206},
doi = {https://doi.org/10.1016/j.im.2019.01.003},
url = {https://www.sciencedirect.com/science/article/pii/S0378720617308662},
author = {Nadine Côrte-Real and Pedro Ruivo and Tiago Oliveira},
keywords = {Big data analytics, Internet of things, Strategic management, Knowledge-based theory, Dynamics capability theory},
abstract = {Big data analytics (BDA) and the Internet of Things (IoT) tools are considered crucial investments for firms to distinguish themselves among competitors. Drawing on a strategic management perspective, this study proposes that BDA and IoT capabilities can create significant value in business processes if supported by a good level of data quality, which will lead to a better competitive advantage. Responses are collected from 618 European and American firms that use IoT and BDA applications. Partial least squares results reveal that better data quality is needed to unlock the value of IoT and BDA capabilities.}
}
@article{ROYUELA2020101702,
title = {Enabling Ada and OpenMP runtimes interoperability through template-based execution},
journal = {Journal of Systems Architecture},
volume = {105},
pages = {101702},
year = {2020},
issn = {1383-7621},
doi = {https://doi.org/10.1016/j.sysarc.2019.101702},
url = {https://www.sciencedirect.com/science/article/pii/S1383762119305090},
author = {Sara Royuela and Luís Miguel Pinho and Eduardo Quiñones},
keywords = {Concurrency, Parallelism, Ada, OpenMP, Safety, Runtimes},
abstract = {The growing trend to support parallel computation to enable the performance gains of the recent hardware architectures is increasingly present in more conservative domains, such as safety-critical systems. Applications such as autonomous driving require levels of performance only achievable by fully leveraging the potential parallelism in these architectures. To address this requirement, the Ada language, designed for safety and robustness, is considering to support parallel features in the next revision of the standard (Ada 202X). Recent works have motivated the use of OpenMP, a de facto standard in high-performance computing, to enable parallelism in Ada, showing the compatibility of the two models, and proposing static analysis to enhance reliability. This paper summarizes these previous efforts towards the integration of OpenMP into Ada to exploit its benefits in terms of portability, programmability and performance, while providing the safety benefits of Ada in terms of correctness. The paper extends those works proposing and evaluating an application transformation that enables the OpenMP and the Ada runtimes to operate (under certain restrictions) as they were integrated. The objective is to allow Ada programmers to (naturally) experiment and evaluate the benefits of parallelizing concurrent Ada tasks with OpenMP while ensuring the compliance with both specifications.}
}
@article{AIREHROUR2016198,
title = {Secure routing for internet of things: A survey},
journal = {Journal of Network and Computer Applications},
volume = {66},
pages = {198-213},
year = {2016},
issn = {1084-8045},
doi = {https://doi.org/10.1016/j.jnca.2016.03.006},
url = {https://www.sciencedirect.com/science/article/pii/S1084804516300133},
author = {David Airehrour and Jairo Gutierrez and Sayan Kumar Ray},
keywords = {IETF, 6LoWPAN, RPL, IEEE 802.15.4, IoT, Routing, Security, Sensors},
abstract = {The Internet of Things (IoT) could be described as the pervasive and global network which aids and provides a system for the monitoring and control of the physical world through the collection, processing and analysis of generated data by IoT sensor devices. It is projected that by 2020 the number of connected devices is estimated to grow exponentially to 50 billion. The main drivers for this growth are our everyday devices such as cars, refrigerators, fans, lights, mobile phones and other operational technologies including the manufacturing infrastructures which are now becoming connected systems across the world. It is apparent that security will pose a fundamental enabling factor for the successful deployment and use of most IoT applications and in particular secure routing among IoT sensor nodes thus, mechanisms need to be designed to provide secure routing communications for devices enabled by the IoT technology. This survey analyzes existing routing protocols and mechanisms to secure routing communications in IoT, as well as the open research issues. We further analyze how existing approaches ensure secure routing in IoT, their weaknesses, threats to secure routing in IoT and the open challenges and strategies for future research work for a better secure IoT routing.}
}
@article{FRANCO2020244,
title = {Demand responsive transport: Generation of activity patterns from mobile phone network data to support the operation of new mobility services},
journal = {Transportation Research Part A: Policy and Practice},
volume = {131},
pages = {244-266},
year = {2020},
note = {Developments in Mobility as a Service (MaaS) and Intelligent Mobility},
issn = {0965-8564},
doi = {https://doi.org/10.1016/j.tra.2019.09.038},
url = {https://www.sciencedirect.com/science/article/pii/S0965856418310000},
author = {Patrizia Franco and Ryan Johnston and Ecaterina McCormick},
keywords = {Demand responsive transport, Shared mobility, MaaS, Agent based modelling, Mobile phone network data, MatSim},
abstract = {Demand Responsive Transport (DRT), covering the first/last mile of a journey, plays a pivotal role in the delivery of a seamless integrated door-to-door service, which is a fundamental requirement for the implementation of Mobility as a Service (MaaS). Business models currently in use do not deliver sustainable and durable DRT in urban areas. This can be minimised using transport modelling tools ahead of the operation phase. However, transport models are not fit for purpose when it comes to model on-demand shared mobility services and the integration of these services in a complex public transport ecosystem. This paper focuses on how to model demand for ride-shared mobility services and how to plan for these services when running in integration with mass transit. An Agent Based Model (ABM), built in the open-source Multi-Agent Transport Simulation (MatSim) platform for Bristol (UK), has used an activity-based approach to model demand for two New Mobility Services (NMS). This was then generated using anonymised and aggregated Mobile phone Network Dataset (MND), both as a trip-based and trip chains dataset to assess the capabilities of MND. Results show that the simulations built using the trip chains MND datasets (722,752 agents generated) lead to better insights in users’ travel patterns. An advanced method using additional data sources covering land-use (location of business, services and transport facilities) was used to infer purpose and mode of transport during the multimodal journeys. The output of the ABM predicts demand for two flexible on-demand services, identifying best routes to maximise the number of users served and quantifying the benefits in the integration with public transport services and in modal shift from private cars. This is expected to be useful either for Local Authorities for transport planning purposes, and for operators looking at financially sustainable DRT.}
}
@article{NGUYENGIA2019198,
title = {Energy efficient fog-assisted IoT system for monitoring diabetic patients with cardiovascular disease},
journal = {Future Generation Computer Systems},
volume = {93},
pages = {198-211},
year = {2019},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2018.10.029},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X18314365},
author = {Tuan Nguyen Gia and Imed Ben Dhaou and Mai Ali and Amir M. Rahmani and Tomi Westerlund and Pasi Liljeberg and Hannu Tenhunen},
keywords = {Glucose, Diabetes, ECG, Hypoglycemia, Fall detection, Health monitoring, IoT, Fog/edge computing, Energy efficiency},
abstract = {Blood glucose plays an important role in maintaining body’s activities. For example, brain only uses glucose as its energy source. However, when blood glucose level is abnormal, it causes some serious consequences. For instance, low-blood glucose phenomenon referred to as hypoglycemia can cause heart repolarization and induce cardiac arrhythmia causing sudden cardiac deaths. Diabetes, which can be viewed as a high-blood glucose level for a long period of time, is a dangerous disease as it can directly or indirectly cause heart attack, stroke, heart failure, and other vicious diseases. A solution for reducing the serious consequences caused by diabetes and hypoglycemia is to continuously monitor blood glucose level for real-time responses such as adjusting insulin levels from the insulin pump. Nonetheless, it is a misstep when merely monitoring blood glucose without considering other signals or data such as Electrocardiography (ECG) and activity status since they have close relationships. When hypoglycemia occurs, a fall can easily occur especially in case of people over 65 years old. Fall’s consequences are more hazardous when a fall is not detected. Therefore, we present a Fog-based system for remote health monitoring and fall detection. Through the system, both e-health signals such as glucose, ECG, body temperature and contextual data such as room temperature, humidity, and air quality can be monitored remotely in real-time. By leveraging Fog computing at the edge of the network, the system offers many advanced services such as ECG feature extraction, security, and local distributed storage. Results show that the system works accurately and the wearable sensor node is energy efficient. Even though the node is equipped with many types of sensors, it can operate in a secure way for up to 157 h per a single charge when applying a 1000 mAh Lithium battery.}
}
@article{ROUKH201744,
title = {Eco-Physic: Eco-Physical design initiative for very large databases},
journal = {Information Systems},
volume = {68},
pages = {44-63},
year = {2017},
note = {Special issue on DOLAP 2015: Evolving data warehousing and OLAP cubes to big data analytics},
issn = {0306-4379},
doi = {https://doi.org/10.1016/j.is.2017.01.003},
url = {https://www.sciencedirect.com/science/article/pii/S0306437916305129},
author = {Amine Roukh and Ladjel Bellatreche and Selma Bouarar and Ahcene Boukorca},
keywords = {Physical design, Energy efficiency, Power management},
abstract = {In the Big Data Era, the management of energy consumption by servers and data centers has become a challenging issue for companies, institutions, and countries. In data-centric applications, Database Management Systems are one of the major energy consumers when executing complex queries involving very large databases. Several initiatives have been proposed to deal with this issue, covering both the hardware and software dimensions. They can be classified in two main approaches assuming that either (a) the database is already deployed on a given platform, or (b) it is not yet deployed. In this study, we focus on the first set of initiatives with a particular interest in physical design, where optimization structures (e.g., indexes, materialized views) are selected to satisfy a given set of non-functional requirements such as query performance for a given workload. In this paper, we first propose an initiative, called Eco-Physic, which integrates the energy dimension into the physical design when selecting materialized views, one of the redundant optimization structures. Secondly, we provide a multi-objective formalization of the materialized view selection problem, considering two non-functional requirements: query performance and energy consumption while executing a given workload. Thirdly, an evolutionary algorithm is developed to solve the problem. This algorithm differs from the existing ones by being interactive, so that database administrators can adjust some energy sensitive parameters at the final stage of the algorithm execution according to their specifications. Finally, intensive experiments are conducted using our mathematical cost model and a real device for energy measurements. Results underscore the value of our approach as an effective way to save energy while optimizing queries through materialized views structures.}
}
@article{NGUYENGIA201834,
title = {Energy efficient wearable sensor node for IoT-based fall detection systems},
journal = {Microprocessors and Microsystems},
volume = {56},
pages = {34-46},
year = {2018},
issn = {0141-9331},
doi = {https://doi.org/10.1016/j.micpro.2017.10.014},
url = {https://www.sciencedirect.com/science/article/pii/S0141933117301461},
author = {Tuan {Nguyen Gia} and Victor Kathan Sarker and Igor Tcarenko and Amir M. Rahmani and Tomi Westerlund and Pasi Liljeberg and Hannu Tenhunen},
keywords = {Internet-of-Things, IoT, Fall detection, Energy efficiency, Wearable devices, Accelerometer, Gyroscope, Magnetometer, nRF},
abstract = {Falls can cause serious traumas such as brain injuries and bone fractures, especially among elderly people. Fear of falling might reduce physical activities resulting in declining social interactions and eventually causing depression. To lessen the effects of a fall, timely delivery of medical treatment can play a vital role. In a similar scenario, an IoT-based wearable system can pave the most promising way to mitigate serious consequences of a fall while providing the convenience of usage. However, to deliver sufficient degree of monitoring and reliability, wearable devices working at the core of fall detection systems are required to work for a prolonged period of time. In this work, we focus on energy efficiency of a wearable sensor node in an Internet-of-Things (IoT) based fall detection system. We propose the design of a tiny, lightweight, flexible and energy efficient wearable device. We investigate different parameters (e.g. sampling rate, communication bus interface, transmission protocol, and transmission rate) impacting on energy consumption of the wearable device. In addition, we provide a comprehensive analysis of energy consumption of the wearable in different configurations and operating conditions. Furthermore, we provide hints (hardware and software) for system designers implementing the optimal wearable device for IoT-based fall detection systems in terms of energy efficiency and high quality of service. The results clearly indicate that the proposed sensor node is novel and energy efficient. In a critical condition, the wearable device can be used continuously for 76 h with a 1000 mAh li-ion battery.}
}
@article{KOLOMVATSOS2019155,
title = {Time-optimized management of mobile IoT nodes for pervasive applications},
journal = {Journal of Network and Computer Applications},
volume = {125},
pages = {155-167},
year = {2019},
issn = {1084-8045},
doi = {https://doi.org/10.1016/j.jnca.2018.10.016},
url = {https://www.sciencedirect.com/science/article/pii/S1084804518303382},
author = {Kostas Kolomvatsos},
keywords = {Pervasive computing, Internet of Things, Updates management, Optimal stopping},
abstract = {The Internet of Things (IoT) incorporates numerous nodes adopted to support novel pervasive computing applications. Nodes are capable of interacting each other and/or collect/process huge volumes of ambient data. Any service or application executed on top of the collected data is hosted by the operating software/firmware of nodes, thus, such software should be up-to-date. Legacy techniques dealing with the update task cannot efficiently support it due to the adopted centralized approach that suffers from a number of disadvantages. In this paper, we go a step forward and propose a time-optimized and network performance-aware model for initiating and concluding the update process. Our aim is to have the nodes independently deciding the initiation of the update process by finding the appropriate time to execute it. Every node acts autonomously and monitors the network's performance to find a slot where performance parameters advocate for an efficient and uninterrupted conclusion of the update task. Hence, the proposed model can be adapted to the environment and the status of each node. The final decision is made taking into consideration multiple parameters and it is based on the solution of the widely known Secretary Problem (SP) originated in the Optimal Stopping Theory (OST). We provide the description of the problem, specific formulations and the analysis of our solution while extensive experiments reveal the advantages of the proposed scheme.}
}
@article{DOMINICINI2020106975,
title = {KeySFC: Traffic steering using strict source routing for dynamic and efficient network orchestration},
journal = {Computer Networks},
volume = {167},
pages = {106975},
year = {2020},
issn = {1389-1286},
doi = {https://doi.org/10.1016/j.comnet.2019.106975},
url = {https://www.sciencedirect.com/science/article/pii/S138912861930194X},
author = {Cristina K. Dominicini and Gilmar L. Vassoler and Rodolfo Valentim and Rodolfo S. Villaca and Moisés R.N. Ribeiro and Magnos Martinello and Eduardo Zambon},
keywords = {SFC, NFV, SDN, Traffic steering, Source routing, Orchestration,},
abstract = {Current service function chaining (SFC) solutions are cumbersome adaptations of classic routing mechanisms, which lack flexibility and agility to cope with new dynamic services required by network functions virtualization (NFV). These SFC solutions require modification of forwarding tables in both physical and virtual elements in the path when updating a chain. In addition, current SFC implementations restrict traffic engineering to sub-optimal resource allocation solutions, because limited switch table sizes prevent the consideration of all possible traffic paths. Moreover, overlay chaining decisions are usually decoupled from the actual underlay routing of packets across service functions. To tackle these issues, we propose KeySFC, a traffic steering scheme that uses software-defined networking (SDN) and strict source routing. KeySFC exploits the fabric network concept in data center networks (DCNs) in two ways: (i) edge software switches classify, encapsulate, forward, and decapsulate flows with SFC labels; and (ii) core tableless switches forward packets based on simple modulo operations over these labels. Thus, the modification of a small number of flow entries in edge elements allows changing of SFC labels and effectively stitching paths via SDN. An OpenStack-based prototype demonstrates that the traffic steering scheme provided by KeySFC has the potential to enable efficient traffic engineering and to provide agile path migration per SFC segment.}
}
@article{PERERA2016122,
title = {A knowledge-based resource discovery for Internet of Things},
journal = {Knowledge-Based Systems},
volume = {109},
pages = {122-136},
year = {2016},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2016.06.030},
url = {https://www.sciencedirect.com/science/article/pii/S0950705116302015},
author = {Charith Perera and Athanasios V. Vasilakos},
keywords = {Internet of Things, Middleware, Semantic knowledge, IoT resource composition},
abstract = {In the sensing as a service paradigm, Internet of Things (IoT) Middleware platforms allow data consumers to retrieve the data they want without knowing the underlying technical details of IoT resources (i.e. sensors and data processing components). However, configuring an IoT middleware platform and retrieving data is a significant challenge for data consumers as it requires both technical knowledge and domain expertise. In this paper, we propose a knowledge driven approach called Context Aware Sensor Configuration Model (CASCOM) to simplify the process of configuring IoT middleware platforms, so the data consumers, specifically non-technical personnel, can easily retrieve the data they required. In this paper, we demonstrate how IoT resources can be described using semantics in such away that they can later be used to compose service work-flows. Such automated semantic-knowledge-based IoT resource composition approach advances the current research. We demonstrate the feasibility and the usability of our approach through a prototype implementation based on an IoT middleware called Global Sensor Networks (GSN), though our model can be generalized to any other middleware platform.}
}
@article{SEDAGHATI2019830,
title = {A novel control strategy and power management of hybrid PV/FC/SC/battery renewable power system-based grid-connected microgrid},
journal = {Sustainable Cities and Society},
volume = {44},
pages = {830-843},
year = {2019},
issn = {2210-6707},
doi = {https://doi.org/10.1016/j.scs.2018.11.014},
url = {https://www.sciencedirect.com/science/article/pii/S221067071830355X},
author = {Reza Sedaghati and Mahmoud Reza Shakarami},
keywords = {HRES system, Dynamic modeling, Power management, Sliding mode control (SMC), Distributed energy generation},
abstract = {This paper proposes a new control and power management strategy for a grid-connected microgrid, which includes a hybrid renewable energy sources (HRES) system and a three-phase load. The HRES system consists of a photovoltaic (PV), a battery storage system (BSS), a super-capacitor (SC) and a solid oxide fuel cell (SOFC). The dynamic model of each of these units is described. The PV is the main energy source, while the SC and the BSS due to their various power densities are considered to provide a steady and transient load demand, respectively. For increasing the reliability of the system, SOFC source is selected to keep the BSS completely charged. All these units with different DC-DC converters are connected in parallel to a common DC bus. Then, a three-phase voltage source inverter (VSI) is employed to convert the DC voltage to AC. To maintain the power balance and appropriate load-sharing, an adaptive fractional fuzzy sliding mode control (AFFSMC) strategy for VSI-based HRES system is presented. The controller is able to track the pre-defined instruction precisely and quickly in the microgrid. For stable performance of the control strategy under load variation, a fractional order-based sliding surface is considered. Moreover, fractional adaptive rules-based fuzzy sets are employed to accurately estimate the uncertain parameters in the microgrid. The simulation results demonstrate the effectiveness and capability of an AFFSMC strategy under various faults and different loading conditions. Moreover, the proposed control strategy is compared with the conventional PI controller.}
}
@article{SHARMA2021102316,
title = {Fifty years of information management research: A conceptual structure analysis using structural topic modeling},
journal = {International Journal of Information Management},
volume = {58},
pages = {102316},
year = {2021},
issn = {0268-4012},
doi = {https://doi.org/10.1016/j.ijinfomgt.2021.102316},
url = {https://www.sciencedirect.com/science/article/pii/S0268401221000098},
author = {Anuj Sharma and Nripendra P. Rana and Robin Nunkoo},
keywords = {Information management, Structural topic models, Topic modeling, Generative models, Text analytics},
abstract = {Information management is the management of organizational processes, technologies, and people which collectively create, acquire, integrate, organize, process, store, disseminate, access, and dispose of the information. Information management is a vast, multi-disciplinary domain that syndicates various subdomains and perfectly intermingles with other domains. This study aims to provide a comprehensive overview of the information management domain from 1970 to 2019. Drawing upon the methodology from statistical text analysis research, this study summarizes the evolution of knowledge in this domain by examining the publication trends as per authors, institutions, countries, etc. Further, this study proposes a probabilistic generative model based on structural topic modeling to understand and extract the latent themes from the research articles related to information management. Furthermore, this study graphically visualizes the variations in the topic prevalences over the period of 1970 to 2019. The results highlight that the most common themes are data management, knowledge management, environmental management, project management, service management, and mobile and web management. The findings also identify themes such as knowledge management, environmental management, project management, and social communication as academic hotspots for future research.}
}
@article{VERDOUW2019104939,
title = {Architecture framework of IoT-based food and farm systems: A multiple case study},
journal = {Computers and Electronics in Agriculture},
volume = {165},
pages = {104939},
year = {2019},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2019.104939},
url = {https://www.sciencedirect.com/science/article/pii/S0168169919306192},
author = {Cor Verdouw and Harald Sundmaeker and Bedir Tekinerdogan and Davide Conzon and Teodoro Montanaro},
keywords = {Internet of Things, Architecture, Architectural framework, System of systems, Smart farming, Food supply chains},
abstract = {The Internet of Things (IoT) is expected to be a real game changer in food and farming. However, an important challenge for large-scale uptake of IoT is to deal with the huge heterogeneity of this domain. This paper develops and applies an architecture framework for modelling IoT-based systems in the agriculture and food domain. The framework comprises a coherent set of architectural viewpoints and a guideline to use these viewpoints to model architectures of individual IoT-based systems. The framework is validated in a multiple case study of the European IoF2020 project, including different agricultural sub sectors, conventional and organic farming, early adopters and early majority farmers, and different supply chain roles. The framework provides a valuable help to model, in a timely, punctual and coherent way, the architecture of IoT-based systems of this diverse set of use cases. Moreover, it serves as a common language for aligning system architectures and enabling reuse of architectural knowledge among multiple autonomous IoT-based systems in agriculture and food.}
}
@article{ROMERO2019522,
title = {A framework for event classification in tweets based on hybrid semantic enrichment},
journal = {Expert Systems with Applications},
volume = {118},
pages = {522-538},
year = {2019},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2018.10.028},
url = {https://www.sciencedirect.com/science/article/pii/S095741741830678X},
author = {Simone Romero and Karin Becker},
keywords = {Event classification, Semantic web, DBPedia, Twitter, Discriminative features},
abstract = {Twitter has become instrumental as a means of spreading information, opinions or awareness about real-world events. The classification of event-related tweets is a challenging problem since tweets are noisy and sparse pieces of text that lack contextual information. Related work proposes contextual enrichment techniques using external sources (e.g. semantic web, external documents), often considering underlying assumptions about the target events. However, they lack guidelines for determining the textual features to enrich, the external sources to use, the properties to explore, and how to prevent the inclusion of unrelated information. In this paper, we propose a hybrid semantic enrichment framework for the classification of event-related tweets. We contribute to this field by leveraging different contextual enrichment strategies into a unifying framework targeted at a broad range of event types, where each enrichment technique has a role in the improvement of event classification. The framework also encompasses a solution to deal with the huge number of features that result from semantic enrichment, which combines a pruning method to select domain relevant semantic features and general-purpose feature selection techniques. We assessed the contribution of each framework component to event classification improvement using a broad experimental setting. Using seven events of distinct natures, we outperformed a word embeddings baseline in 93.6% of cases, and a textual baseline in 60.3% of cases. In most cases, we improved the recall, with no significant impact on the precision.}
}
@article{BERNUS201687,
title = {Enterprise engineering and management at the crossroads},
journal = {Computers in Industry},
volume = {79},
pages = {87-102},
year = {2016},
note = {Special Issue on Future Perspectives On Next Generation Enterprise Information Systems},
issn = {0166-3615},
doi = {https://doi.org/10.1016/j.compind.2015.07.010},
url = {https://www.sciencedirect.com/science/article/pii/S0166361515300282},
author = {Peter Bernus and Ted Goranson and John Gøtze and Anders Jensen-Waud and Hadi Kandjani and Arturo Molina and Ovidiu Noran and Ricardo J. Rabelo and David Romero and Pallab Saha and Pat Turner},
keywords = {Enterprise Information Systems, Enterprise Architecture, Complexity management, Sustainability, Viability, Situation theory},
abstract = {The article provides an overview of the challenges and the state of the art of the discipline of Enterprise Architecture (EA), with emphasis on the challenges and future development opportunities of the underlying Information System (IS), and its IT implementation, the Enterprise Information System (EIS). The first challenge is to overcome the narrowness of scope of present practice in IS and EA, and re-gain the coverage of the entire business on all levels of management, and a holistic and systemic coverage of the enterprise as an economic entity in its social and ecological environment. The second challenge is how to face the problems caused by complexity that limit the controllability and manageability of the enterprise as a system. The third challenge is connected with the complexity problem, and describes fundamental issues of sustainability and viability. Following from the third, the fourth challenge is to identify modes of survival for systems, and dynamic system architectures that evolve and are resilient to changes of the environment in which they live. The state of the art section provides pointers to possible radical changes to models, methodologies, theories and tools in EIS design and implementation, with the potential to solve these grand challenges.}
}
@article{KANTOR2019106844,
title = {A survey on multi-layer IP and optical Software-Defined Networks},
journal = {Computer Networks},
volume = {162},
pages = {106844},
year = {2019},
issn = {1389-1286},
doi = {https://doi.org/10.1016/j.comnet.2019.06.022},
url = {https://www.sciencedirect.com/science/article/pii/S1389128618314312},
author = {Mirosław Kantor and Edyta Biernacka and Piotr Boryło and Jerzy Domżał and Piotr Jurkiewicz and Miłosz Stypiński and Robert Wójcik},
keywords = {SDN, Software-Defined Networking, Multi-layer, Optical networks},
abstract = {As Software-Defined Networks become more and more popular, they start to appear in various architectures. The most common utilization of SDN is to control the network in the electric layers, including OSI/ISO layers 2 and above. However, SDN can be used much further. Professionals and scientists noticed that combining management and control of many layers at the same time can provide benefits. At one point, SDN started to be envisioned for multi-layer networks. In this survey we present, compare and contrast solutions that utilize SDN in multi-layer network architectures. The main objective is to analyze evolving multi-layer network architectures and show how these solutions coupled with SDN contribute to make future networks simple, flexible and cost-effective.}
}
@article{NOY201868,
title = {Automated driving: Safety blind spots},
journal = {Safety Science},
volume = {102},
pages = {68-78},
year = {2018},
issn = {0925-7535},
doi = {https://doi.org/10.1016/j.ssci.2017.07.018},
url = {https://www.sciencedirect.com/science/article/pii/S0925753517304198},
author = {Ian Y. Noy and David Shinar and William J. Horrey},
keywords = {Automated driving, Safety, Driver-vehicle interaction, Psychology, Autonomous vehicles},
abstract = {Driver assist technologies have reached the tipping point and are poised to take control of most, if not all, aspects of the driving task. Proponents of automated driving (AD) are enthusiastic about its promise to transform mobility and realize impressive societal benefits. This paper is an attempt to carefully examine the potential of AD to realize safety benefits, to challenge widely-held assumptions and to delve more deeply into the barriers that are hitherto largely overlooked. As automated vehicle (AV) technologies advance and emerge within a ubiquitous cyber-physical world they raise additional issues that have not yet been adequately defined, let alone researched. Issues around automation, sociotechnical complexity and systems resilience are well known in the context of aviation and space. There are important lessons that could be drawn from these applications to help inform the development of automated driving. This paper argues that for the foreseeable future, regardless of the level of automation, a driver will continue to have a role. It seems clear that the benefits of automated driving, safety and otherwise, will accrue only if these technologies are designed in accordance with sound cybernetics principles, promote effective human-systems integration and gain the trust by operators and the public.}
}
@article{BANERJEE202199,
title = {Private blockchain-envisioned multi-authority CP-ABE-based user access control scheme in IIoT},
journal = {Computer Communications},
volume = {169},
pages = {99-113},
year = {2021},
issn = {0140-3664},
doi = {https://doi.org/10.1016/j.comcom.2021.01.023},
url = {https://www.sciencedirect.com/science/article/pii/S014036642100044X},
author = {Soumya Banerjee and Basudeb Bera and Ashok Kumar Das and Samiran Chattopadhyay and Muhammad Khurram Khan and Joel J.P.C. Rodrigues},
keywords = {Industrial Internet of Things (IIoT), Access control, Attribute-based encryption, Blockchain, Security},
abstract = {Recent advances in Low Power Wide Area Network (LPWAN) are expected to augment the already prodigious proliferation of Industrial Internet of Things (IIoT). However, this unrepresented growth is tinged by the uncertainty of possible challenges in security and privacy. In this work, we propose a novel blockchain-envisioned fine grained user access control scheme for data security and scalability in IIoT environment. The proposed scheme supports multiple attribute authorities and also a constant size key and ciphertext. The data gathered by the IoT smart devices are encrypted using the cipher-policy attribute based encryption (CP-ABE) and sent to their nearby gateway nodes. Later, the gateway nodes form the transactions from the encrypted data from the smart devices which are used to form partial blocks. The partial blocks are then forwarded to the cloud server(s) in the peer-to-peer (P2P) network to convert them into full blocks, which are verified, mined and added into the blockchain using the voting-based practical Byzantine fault tolerance (PBFT) consensus algorithm. The proposed scheme also allows a user to access the secure data stored in the blocks into the blockchain using the CP-ABE mechanism. The security analysis demonstrates the robustness of the proposed scheme against various attacks, and the comparative study with related relevant schemes also highlights the advantage of the proposed scheme over existing approaches. Finally, a blockchain implementation of the presented scheme summarizes the computational costs for a varied number of transactions per block, and also for a varied number of blocks mined in the blockchain.}
}
@article{LOHACHAB2020100174,
title = {A comprehensive survey of prominent cryptographic aspects for securing communication in post-quantum IoT networks},
journal = {Internet of Things},
volume = {9},
pages = {100174},
year = {2020},
issn = {2542-6605},
doi = {https://doi.org/10.1016/j.iot.2020.100174},
url = {https://www.sciencedirect.com/science/article/pii/S2542660520300159},
author = {Ankur Lohachab and Anu Lohachab and Ajay Jangra},
keywords = {Internet of things, Security, Cryptography, Quantum key distribution, Post-quantum cryptography},
abstract = {Internet of Things (IoT) ideates smart and inter-connected things capable of sharing their perceptions through the Internet. These devices are different from conventional Internet-connected devices in the sense that these are able to perform skill-full things on their own with minimal or no human interaction. Unfortunately, with the advent of amalgamate technologies, security has become a major concern for IoT networks. Recent efforts include re-inventing cryptographic solutions through the use of light-weight operations. However, after witnessing the growth of quantum computers, it can be inferred that the cryptographic techniques based on mathematical problems are not reliable enough. Therefore, there is need to develop solutions that can easily resist the adversarial effects and are suitable for the post-quantum world. In this paper, we perform in-depth analysis over the role of post-quantum cryptographic techniques for securing IoT networks and also explore ongoing research efforts in the field. In addition, we discuss the open research challenges and future research directions in the field.}
}
@article{LI201968,
title = {Exploring urban taxi ridership and local associated factors using GPS data and geographically weighted regression},
journal = {Cities},
volume = {87},
pages = {68-86},
year = {2019},
issn = {0264-2751},
doi = {https://doi.org/10.1016/j.cities.2018.12.033},
url = {https://www.sciencedirect.com/science/article/pii/S0264275118312721},
author = {Bozhao Li and Zhongliang Cai and Lili Jiang and Shiliang Su and Xinran Huang},
keywords = {Taxi ridership, Taxi trajectory data, Urban mobility, GWR, Traffic source and sink places},
abstract = {Taxi is a core component of urban transit systems. Since they can provide more time-saving and convenient service than many other transit options, taxis have a certain passenger base. The analysis of taxi ridership can be used to better understand the travel mobility of passengers and the traffic structure of urban areas. In previous studies, taxi trajectory data have been widely used, especially in exploring taxi ridership, and point-of-interest (POI) data are usually used to evaluate the land-use type of a certain sub-district. On the basis of preceding research, this paper uses taxi trajectory data within the long time scale of one week. Five traffic factors are taken into consideration: pick-ups, drop-offs, and the ratio of pick-ups to drop-offs, pick-up probability and drop-off probability. The research model is divided into weekdays and weekends. For the calculation of probabilities, an index termed the Area Crossing Index is proposed to reflect the taxi cardinality and accessibility of a region. At the same time, POI and demographic data are used as explanatory variables. In this study, we also take the business hours of POIs into consideration. In order to explore the ridership in each hour, hierarchical clustering is used to determine the similarity characteristics of hourly dependent variables. Then, stepwise linear regression is used to screen and evaluate coefficients without collinearity. Finally, geographically weighted regression is adopted to evaluate spatial variability, and the coefficients of common explanatory variables on weekdays and weekends are examined. At the end of this paper, the causes of common explanatory factors on weekdays and weekends for each traffic factor are discussed. This paper also analyzes ridership by combining all the results of dependent variables and proposes some suggestions for taxi scheduling.}
}
@article{KILANIOTI201942,
title = {A survey on cost-effective context-aware distribution of social data streams over energy-efficient data centres},
journal = {Simulation Modelling Practice and Theory},
volume = {93},
pages = {42-64},
year = {2019},
note = {Modeling and Simulation of Cloud Computing and Big Data},
issn = {1569-190X},
doi = {https://doi.org/10.1016/j.simpat.2018.11.004},
url = {https://www.sciencedirect.com/science/article/pii/S1569190X18301709},
author = {Irene Kilanioti and Alejandro Fernández-Montes and Damián Fernández-Cerero and Christos Mettouris and Valentina Nejkovic and Rabih Bashroush and George A. Papadopoulos},
keywords = {Social Data Streams, Social Media, Social Networks, Contextaware, Content Distribution, Multimedia Content, Energy-efficient, Data Centers, 5G, Infrastructure, Cost-effective},
abstract = {Social media have emerged in the last decade as a viable and ubiquitous means of communication. The ease of user content generation within these platforms, e.g. check-in information, multimedia data, etc., along with the proliferation of Global Positioning System (GPS)-enabled, always-connected capture devices lead to data streams of unprecedented amount and a radical change in information sharing. Social data streams raise a variety of practical challenges, including derivation of real-time meaningful insights from effectively gathered social information, as well as a paradigm shift for content distribution with the leverage of contextual data associated with user preferences, geographical characteristics and devices in general. In this article we present a comprehensive survey that outlines the state-of-the-art situation and organizes challenges concerning social media streams and the infrastructure of the data centres supporting the efficient access to data streams in terms of content distribution, data diffusion, data replication, energy efficiency and network infrastructure. We systematize the existing literature and proceed to identify and analyse the main research points and industrial efforts in the area as far as modelling, simulation and performance evaluation are concerned.}
}
@article{ENRIQUEZ201714,
title = {Entity reconciliation in big data sources: A systematic mapping study},
journal = {Expert Systems with Applications},
volume = {80},
pages = {14-27},
year = {2017},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2017.03.010},
url = {https://www.sciencedirect.com/science/article/pii/S0957417417301550},
author = {J.G. Enríquez and F.J. Domínguez-Mayo and M.J. Escalona and M. Ross and G. Staples},
keywords = {Systematic mapping study, Entity reconciliation, Heterogeneous databases, Big data},
abstract = {The entity reconciliation (ER) problem aroused much interest as a research topic in today's Big Data era, full of big and open heterogeneous data sources. This problem poses when relevant information on a topic needs to be obtained using methods based on: (i) identifying records that represent the same real world entity, and (ii) identifying those records that are similar but do not correspond to the same real-world entity. ER is an operational intelligence process, whereby organizations can unify different and heterogeneous data sources in order to relate possible matches of non-obvious entities. Besides, the complexity that the heterogeneity of data sources involves, the large number of records and differences among languages, for instance, must be added. This paper describes a Systematic Mapping Study (SMS) of journal articles, conferences and workshops published from 2010 to 2017 to solve the problem described before, first trying to understand the state-of-the-art, and then identifying any gaps in current research. Eleven digital libraries were analyzed following a systematic, semiautomatic and rigorous process that has resulted in 61 primary studies. They represent a great variety of intelligent proposals that aim to solve ER. The conclusion obtained is that most of the research is based on the operational phase as opposed to the design phase, and most studies have been tested on real-world data sources, where a lot of them are heterogeneous, but just a few apply to industry. There is a clear trend in research techniques based on clustering/blocking and graphs, although the level of automation of the proposals is hardly ever mentioned in the research work.}
}
@article{ALKHAFAJIY20201,
title = {COMITMENT: A Fog Computing Trust Management Approach},
journal = {Journal of Parallel and Distributed Computing},
volume = {137},
pages = {1-16},
year = {2020},
issn = {0743-7315},
doi = {https://doi.org/10.1016/j.jpdc.2019.10.006},
url = {https://www.sciencedirect.com/science/article/pii/S0743731519302965},
author = {Mohammed Al-khafajiy and Thar Baker and Muhammad Asim and Zehua Guo and Rajiv Ranjan and Antonella Longo and Deepak Puthal and Mark Taylor},
keywords = {Fog computing, Trust, Quality of protection},
abstract = {As an extension of cloud computing, fog computing is considered to be relatively more secure than cloud computing due to data being transiently maintained and analyzed on local fog nodes closer to data sources. However, there exist several security and privacy concerns when fog nodes collaborate and share data to execute certain tasks. For example, offloading data to a malicious fog node can result into an unauthorized collection or manipulation of users’ private data. Cryptographic-based techniques can prevent external attacks, but are not useful when fog nodes are already authenticated and part of a networks using legitimate identities. We therefore resort to trust to identify and isolate malicious fog nodes and mitigate security, respectively. In this paper, we present a fog COMputIng Trust manageMENT (COMITMENT) approach that uses quality of service and quality of protection history measures from previous direct and indirect fog node interactions for assessing and managing the trust level of the nodes within the fog computing environment. Using COMITMENT approach, we were able to reduce/identify the malicious attacks/interactions among fog nodes by approximately 66%, while reducing the service response time by approximately 15 s.}
}
@article{GUPTA2020100263,
title = {Application aware networks' resource selection decision making technique using group mobility in vehicular cognitive radio networks},
journal = {Vehicular Communications},
volume = {26},
pages = {100263},
year = {2020},
issn = {2214-2096},
doi = {https://doi.org/10.1016/j.vehcom.2020.100263},
url = {https://www.sciencedirect.com/science/article/pii/S2214209620300346},
author = {Mani Shekhar Gupta and Krishan Kumar},
keywords = {Resource allocation, CR networks, Vehicular communication, Multiple attributes decision making (MADM), Group mobility},
abstract = {Nowadays detonation of holding vehicle has wrought overcrowded traffic. The US Federal Communication Commission officially allocated nearly 75 MHz spectrum in 5.8 GHz band to support vehicular communication and many studies found this band incapable to handle the demand for future data traffic. The application of Cognitive Radio (CR) technology will be utilized to make the Internet of Vehicles (IoV) environment in order to increase the spectrum resource opportunities available for vehicular communication. In the CR networks environment, each network supporting multiple attributes likes mobility, Quality of Service, data rates and bandwidth. Therefore, new challenges including link failures, network volatility, group mobility and decision making for the fair selection of optimal networks' resource in vehicular CR networks have become the focus of the global concern. Contrarily, future applications require the vehicular CR networks to support safety and non-safety applications and services. The contribution of this article is two folds. First, the group mobility feature of vehicular communication is considered in this work and two techniques (GRA based Vehicular CR node Assisted Networks' resource Selection (VANS) and Network Assisted Networks' resource Selection (NANS)) for vehicular CR networks are proposed. Second, a testbed using coded scripting programme and LabVIEW communications system design suite software to universal software radio peripheral (USRP-2954) is considered to analyze the practical realization issues in vehicular CR networks. Furthermore, the performance of the proposed techniques is analyzed and validated through experimental testbed and compared with the conventional decision-making techniques. Results show that the proposed techniques have outperformed traditional techniques.}
}
@article{CHAMIKARA20181,
title = {Efficient data perturbation for privacy preserving and accurate data stream mining},
journal = {Pervasive and Mobile Computing},
volume = {48},
pages = {1-19},
year = {2018},
issn = {1574-1192},
doi = {https://doi.org/10.1016/j.pmcj.2018.05.003},
url = {https://www.sciencedirect.com/science/article/pii/S1574119217305229},
author = {M.A.P. Chamikara and P. Bertok and D. Liu and S. Camtepe and I. Khalil},
keywords = {Privacy, Privacy preserving data mining, Data streams, Internet of Things (IoT), Web of Things (WoT), Sensor data streams, Big data},
abstract = {The widespread use of the Internet of Things (IoT) has raised many concerns, including the protection of private information. Existing privacy preservation methods cannot provide a good balance between data utility and privacy, and also have problems with efficiency and scalability. This paper proposes an efficient data stream perturbation method (named as P2RoCAl). P2RoCAl offers better data utility than similar methods and the classification accuracies of P2RoCAl perturbed data streams are very close to those of the original data streams. P2RoCAl also provides higher resilience against data reconstruction attacks.}
}
@article{LEVEQUE2021102656,
title = {Impact of climate change on the vulnerability of drinking water intakes in a northern region},
journal = {Sustainable Cities and Society},
volume = {66},
pages = {102656},
year = {2021},
issn = {2210-6707},
doi = {https://doi.org/10.1016/j.scs.2020.102656},
url = {https://www.sciencedirect.com/science/article/pii/S2210670720308726},
author = {B. Leveque and J.-B. Burnet and S. Dorner and F. Bichai},
keywords = {Climate change, Drinking water supply, Source water vulnerability assessment, Water quality, Contaminant fate and transport, Extreme events},
abstract = {Climate change impacts the vulnerability of drinking water sources to contamination and water shortages. This review highlights key risk factors along the impact chain of climate change on water supply security, from precipitation and runoff to surface water quality and availability at drinking water intakes. How climate impacts water quantity (hydrology) and quality (fate, transport and loads of contaminants, via soils, forests, and urban water infrastructure) is examined across the scientific literature. An emphasis is placed on high-latitude regions, where the kinetics and intensity of projected changes are high. The province of Quebec, Canada, is used as a study area that covers diverse land and climate conditions, with extended relevance at a broader scale globally. This review aims at guiding researchers and water managers in considering the climate-related evolution of a range of threats when assessing the vulnerability of drinking water systems. It highlights how climate change increases the seasonal risks of water supply insecurity in a northern region, thereby increasing socioeconomic and public health risks. Accounting for multiple feedback effects is a major cause of uncertainty in assessing future risks in drinking water supplies. Under deep uncertainty, a paradigm change in assessing climate impacts on water supplies is needed.}
}
@article{ZHANG20156866,
title = {Towards a smart energy network: The roles of fuel/electrolysis cells and technological perspectives},
journal = {International Journal of Hydrogen Energy},
volume = {40},
number = {21},
pages = {6866-6919},
year = {2015},
issn = {0360-3199},
doi = {https://doi.org/10.1016/j.ijhydene.2015.03.133},
url = {https://www.sciencedirect.com/science/article/pii/S036031991500779X},
author = {Xiongwen Zhang and Siew Hwa Chan and Hiang Kwee Ho and Siew-Chong Tan and Mengyu Li and Guojun Li and Jun Li and Zhenping Feng},
keywords = {Fuel/electrolysis cell, Smart energy network, Smart grid, Hydrogen economy, Renewable energy resource},
abstract = {The current carbon-based energy system is undergoing a profound change driven by the increased concerns over the longevity and security of energy supply, as well as energy-related emissions of carbon dioxide and air pollutions. The evolutionary trend of this transition is toward a smart energy network of the future that is characterized by widespread deployment of clean energy technologies and intelligent energy management technologies. In this transition, hydrogen and fuel/electrolysis cell technologies have crucial roles to play in developing the smart energy network, which is particularly captured in this work. The features of the future energy system, i.e., the smart energy network, are illustrated. In particular, the visions from technical aspects for the deployment of battery-based electric vehicles and fuel-cell-based electric vehicles are discussed. The key technologies and its current status for the smart energy network are reviewed.}
}
@article{RAHMAN201872,
title = {Hybrid bio-Inspired computational intelligence techniques for solving power system optimization problems: A comprehensive survey},
journal = {Applied Soft Computing},
volume = {69},
pages = {72-130},
year = {2018},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2018.04.051},
url = {https://www.sciencedirect.com/science/article/pii/S1568494618302424},
author = {Imran Rahman and Junita Mohamad-Saleh},
keywords = {Computational intelligence, Hybrid optimization, Optimization, Bio-inspired computation, Power system},
abstract = {Optimization problems of modern day power system are very challenging to resolve because of its design complexity, wide geographical dispersion and influence from many unpredictable factors. For that reason, it is essential to apply most effective optimization techniques by taking full benefits of simplified formulation and execution of a particular problem. This study presents a summary of significant hybrid bio-inspired computational intelligence (CI) techniques utilized for power system optimization. Authors have reviewed an extensive range of hybrid CI techniques and examined the motivations behind their improvements. Various applications of hybrid bio-inspired CI algorithms have been highlighted in this paper. In addition, few drawbacks regarding the hybrid CI algorithms are explained. Current trends in CI techniques from the past researches have also been discussed in the domain of power system optimization. Lastly, some future research directions are suggested for further advancement of hybrid techniques.}
}
@article{ASMUS202027,
title = {General interval-valued overlap functions and interval-valued overlap indices},
journal = {Information Sciences},
volume = {527},
pages = {27-50},
year = {2020},
issn = {0020-0255},
doi = {https://doi.org/10.1016/j.ins.2020.03.091},
url = {https://www.sciencedirect.com/science/article/pii/S0020025520302711},
author = {Tiago da Cruz Asmus and Graçaliz Pereira Dimuro and Benjamín Bedregal and José Antonio Sanz and Sidnei Pereira and Humberto Bustince},
keywords = {N-dimensional overlap functions, General overlap functions, Overlap index, Interval-valued overlap function},
abstract = {Overlap functions are aggregation functions that express the overlapping degree between two values. They have been used both as a conjunction in several practical problems (e.g., image processing and decision making), and to generate overlap indices between two fuzzy sets, which can be used to construct fuzzy confidence values to be applied in fuzzy rule based classification systems. Some generalizations of overlap functions were recently proposed, such as n-dimensional and general overlap functions, which allowed their application in n-dimensional problems. More recently, the concept of interval-valued overlap functions was presented, mainly to deal with uncertainty in providing membership functions. In this paper, we introduce: (i) the concept of n-dimensional interval-valued overlap functions, studying their representability, (ii) the definition of general interval-valued overlap functions, providing their characterization and some construction methods. Moreover, we also define the concept of interval-valued overlap index, as well as some constructing methods. In addition, we show an illustrative example where those new concepts are applied.}
}
@article{NAFI2020102003,
title = {Matrix-based key management scheme for IoT networks},
journal = {Ad Hoc Networks},
volume = {97},
pages = {102003},
year = {2020},
issn = {1570-8705},
doi = {https://doi.org/10.1016/j.adhoc.2019.102003},
url = {https://www.sciencedirect.com/science/article/pii/S1570870519303786},
author = {Mohammed Nafi and Samia Bouzefrane and Mawloud Omar},
keywords = {Key management, Security, Internet of things, Dynamic networks},
abstract = {The key management is the central element of network security. In fact, key distribution is necessary for securing applications in the context of Internet of Things (IoT). However, existing key management protocols are not directly applicable on IoT due, among other things, to severe and high resource constraints of some devices that make up the IoT network. Therefore, it is necessary that the proposed key management protocols takes in charge these features and constraints. Most existing solutions didn’t focus on optimizing, at the same time, all performance criteria, like communication, computation and storage. Some of them put special emphasis on minimizing one criteria but ignore the others. In this paper, we propose a new lightweight matrix based key management protocol for Iot network, which is not only flexible, scalable and resilient to many types of attacks, but also can reduce the communication, computation and storage overheads at constrained nodes side. The security properties like authentication, integrity and secrecy have been checked by using the formal verification tool AVISPA. Moreover, security and performance analysis show that our scheme protects user’s sensitive data from several types of attacks by achieving secure end-to-end communications, and optimizes the energy consumption, which is suitable for resource-limited networks.}
}
@article{CHEN2019102050,
title = {Sustainability based perspective on the utilization efficiency of urban infrastructure --- A China study},
journal = {Habitat International},
volume = {93},
pages = {102050},
year = {2019},
issn = {0197-3975},
doi = {https://doi.org/10.1016/j.habitatint.2019.102050},
url = {https://www.sciencedirect.com/science/article/pii/S0197397518309536},
author = {Yang Chen and Liyin Shen and Yu Zhang and Heng Li and Yitian Ren},
keywords = {Urban infrastructure, Utilization efficiency, Sustainability perspective, China, Super-SBM model, Malmquist productivity index},
abstract = {The development of urban infrastructures has been playing a key role in the urbanization process in China over last several decades. Great scale of urban infrastructures has been built and it is anticipated that great number of more will be built in the near future in the country. This paper examines whether these built infrastructures have been effectively utilized from a sustainability perspective that integrates economic, social, and environmental concerns. The Super-slack-based measure (Super-SBM) model is adopted to analyze the utilization efficiency of urban infrastructure. Data used are from 281 sample cities in China for the period of 2003–2017. Malmquist Productivity Index (MPI) is further used to examine the dynamic change of the utilization efficiency between these sample cities. The study reveals that the overall infrastructure utilization efficiency is at low level across China. The empirical analysis results show that 86% Chinese cities have low infrastructure utilization efficiency and only 11% cities present continuous satisfactory performance. There are considerable efficiency disparities both between regions and cities. It is interesting to note that some economically less developed cities present better infrastructure utilization efficiency than some better developed cities, and vice versa. Nevertheless, it is encouraging to note that 78% of the sample cities have experienced positive shift in improving infrastructure utilization efficiency in the surveyed period. The research findings provide valuable references for assisting government departments and practitioners to take measures for improving the efficiency in utilizing urban infrastructure in China.}
}
@article{PETRYK2021104376,
title = {Sensitivity of HfO2-based RRAM Cells to Laser Irradiation},
journal = {Microprocessors and Microsystems},
volume = {87},
pages = {104376},
year = {2021},
issn = {0141-9331},
doi = {https://doi.org/10.1016/j.micpro.2021.104376},
url = {https://www.sciencedirect.com/science/article/pii/S0141933121005275},
author = {Dmytro Petryk and Zoya Dyka and Eduardo Perez and Ievgen Kabin and Jens Katzer and Jan Schäffner and Peter Langendörfer},
keywords = {Optical Fault Injection attack, Laser, Reliability, Security, RRAM, Memristive devices, Resistive switching, 1T-1R},
abstract = {Today, the technology of resistive random access memory is used as a non-volatile memory. In this paper we investigate in details the sensitivity of the TiN/Ti/Al:HfO2/TiN-based 1T-1R resistive random access memory cells implemented in a 250 nm CMOS IHP technology to the laser irradiation. Experimental results show that the laser irradiation can influence the resistive state of RRAM cells significantly, i.e. precisely localized optical faults can be successfully injected. We focus on the selection of the configurable parameters of the laser station and their influence on the success of optical Fault Injections. Additionally, we localize sensitive areas of attacked chips. Based on the determined sensitive areas we show that metal fillers atop memory cells influence on success of optical fault injection attacks.}
}
@article{DOMINGUEZRIOS2019217,
title = {Efficient anytime algorithms to solve the bi-objective Next Release Problem},
journal = {Journal of Systems and Software},
volume = {156},
pages = {217-231},
year = {2019},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2019.06.097},
url = {https://www.sciencedirect.com/science/article/pii/S0164121219301414},
author = {Miguel Ángel Domínguez-Ríos and Francisco Chicano and Enrique Alba and Isabel {del Águila} and José {del Sagrado}},
keywords = {Next release problem, Multi-objective optimization, Search-based software engineering, Anytime algorithm, Pareto front},
abstract = {The Next Release Problem consists in selecting a subset of requirements to develop in the next release of a software product. The selection should be done in a way that maximizes the satisfaction of the stakeholders while the development cost is minimized and the constraints of the requirements are fulfilled. Recent works have solved the problem using exact methods based on Integer Linear Programming. In practice, there is no need to compute all the efficient solutions of the problem; a well-spread set in the objective space is more convenient for the decision maker. The exact methods used in the past to find the complete Pareto front explore the objective space in a lexicographic order or use a weighted sum of the objectives to solve a single-objective problem, finding only supported solutions. In this work, we propose five new methods that maintain a well-spread set of solutions at any time during the search, so that the decision maker can stop the algorithm when a large enough set of solutions is found. The methods are called anytime due to this feature. They find both supported and non-supported solutions, and can complete the whole Pareto front if the time provided is long enough.}
}
@article{LUOMALA2019100,
title = {Analysis and evaluation of adaptive RSSI-based ranging in outdoor wireless sensor networks},
journal = {Ad Hoc Networks},
volume = {87},
pages = {100-112},
year = {2019},
issn = {1570-8705},
doi = {https://doi.org/10.1016/j.adhoc.2018.10.004},
url = {https://www.sciencedirect.com/science/article/pii/S1570870518307297},
author = {Jari Luomala and Ismo Hakala},
keywords = {RSSI-based ranging, Adaptive, Localization, Wireless sensor network, Path loss exponent, Temperature},
abstract = {Estimating inter-node distances based on received radio signal strength (RSSI) is the foundation of RSSI-based outdoor localization in wireless sensor networks (WSNs). However, the accuracy of RSSI-based ranging depends on environmental and weather conditions. Therefore, it is important that RSSI-based ranging adapts to prevailing conditions to improve its range and location accuracy. This paper analyzes and evaluates RSSI-based ranging and adaptive techniques in outdoor WSNs to improve the range quality. The findings highlight the effects of path loss exponent (PLE) estimation error and temperature change on RSSI-based ranging. Consequently, we analyze techniques for mitigating these detrimental effects and propose an adaptive RSSI-based ranging algorithm in order to improve the ranging quality in changing outdoor conditions. The algorithm comprises link RSSI estimation, temperature compensation, PLE estimation, and inter-node distance estimation. Furthermore, we evaluate the performance of the proposed algorithm and compare different WSN-specific PLE estimation techniques by employing real measurement data of 2.4 GHz IEEE 802.15.4-compliant WSN nodes. The results indicate that although ranging error can be mitigated using the proposed adaptive techniques, the accuracy when a single PLE estimate is used is, in general, limited due to high inter-link PLE variation.}
}
@article{ALIOUA2020107273,
title = {UAVs for traffic monitoring: A sequential game-based computation offloading/sharing approach},
journal = {Computer Networks},
volume = {177},
pages = {107273},
year = {2020},
issn = {1389-1286},
doi = {https://doi.org/10.1016/j.comnet.2020.107273},
url = {https://www.sciencedirect.com/science/article/pii/S1389128619315798},
author = {Ahmed Alioua and Houssem-eddine Djeghri and Mohammed Elyazid Tayeb Cherif and Sidi-Mohammed Senouci and Hichem Sedjelmaci},
keywords = {Unnamed arial vehicles, Vehicular networks, Computation offloading/sharing, Game theory},
abstract = {Recently, UAVs or Unnamed Aerial Vehicles have been proposed as flexible aerial support to assist ground vehicles for different applications such as rescue and traffic surveillance missions. UAVs can collect different data information about the road/traffic state usually as aerial photography and videos. The processing of this kind of data consists usually on pattern recognition and video processing which are complex tasks that necessitate powerful computing and energy resources. Unfortunately, the moderate UAV's computational and energy capabilities restrict local data processing. Fortunately, UAVs can leverage the computation resources of the surrounding edge network entities to enhance their computational capabilities. In this paper, we aim to achieve efficient data processing for the data collected by UAVs in the context of UAVs-aided vehicular networks for traffic monitoring missions. For this purpose, we propose a new system model where UAVs can offload and/or share intensive computation tasks with other nearby network nodes. Then, we use the computation response time, the energy consumed for the computation, the cost of cellular communication and the computation cost as the main system metrics to make any computation offloading/sharing decisions that optimize the system performance. We then modele the offloading/sharing decision-making problem as a sequential game, where we provide complete proof of the existence of the Nash equilibrium and propose an algorithm to reach such an equilibrium. The simulation results showed that the proposed game-based model outperforms other approaches by delivering better performance in terms of overall system utility with a data processing efficiency that varies between 43% and 97% depending on the computation approach, and provides a more efficient computation time and energy average.}
}
@article{SANCHEZ2021102609,
title = {On the effects of aggregation strategies for different groups of users in venue recommendation},
journal = {Information Processing & Management},
volume = {58},
number = {5},
pages = {102609},
year = {2021},
issn = {0306-4573},
doi = {https://doi.org/10.1016/j.ipm.2021.102609},
url = {https://www.sciencedirect.com/science/article/pii/S0306457321001059},
author = {Pablo Sánchez and Alejandro Bellogín},
keywords = {Venue recommendation, Data augmentation, Temporal evaluation, Tourism, User types, Fairness},
abstract = {Suggesting new venues to be visited by a user in a specific city remains an interesting but challenging problem, partly because of the inherent high sparsity of the data available in location-based social networks (LSBNs). At the same time, in traditional recommender systems, in order to improve their performance in these sparse situations, different techniques have been proposed mainly by augmenting and aggregating the data available in different domains. In this paper, we address the problem of venue recommendation from a novel perspective: we propose two strategies to select a set of candidate cities in order to use their information when performing recommendations for the users in a specific (target) city. In this context, we categorize users into two different groups (tourists and locals) according to their movement patterns and analyze the potential biases in the recommendations received by each of these groups. We provide an experimental comparison of several recommendation algorithms in a temporal split, where we analyze two strategies to select cities and augment the available data: based on the number of interactions and based on the distance with respect to the target city. Our results show that, in general, extending the available data by proximity increases the performance of the majority of the tested recommenders in terms of relevance and coverage, with almost no change in novelty and diversity. We have found that those users belonging to the tourist group tend to obtain better results in terms of relevance. Furthermore, in general, tourists consistently exhibit different performance by some families of recommenders for other evaluation dimensions, evidencing a popularity bias in user behavior and raising potential fairness issues regarding the quality of the received recommendations. We investigate these aspects and provide methods to better understand the problem. We expect these results could provide readers with an overall picture of what can be achieved in a real-world environment.}
}
@article{DANAF201935,
title = {Context-aware stated preferences with smartphone-based travel surveys},
journal = {Journal of Choice Modelling},
volume = {31},
pages = {35-50},
year = {2019},
issn = {1755-5345},
doi = {https://doi.org/10.1016/j.jocm.2019.03.001},
url = {https://www.sciencedirect.com/science/article/pii/S1755534518300381},
author = {Mazen Danaf and Bilge Atasoy and Carlos Lima {de Azevedo} and Jing Ding-Mastera and Maya Abou-Zeid and Nathaniel Cox and Fang Zhao and Moshe Ben-Akiva},
keywords = {Stated preferences, Smartphone, Mode choice, Context-aware, Random design, Travel behavior},
abstract = {Stated preferences surveys are most commonly used to provide behavioral insights on hypothetical travel scenarios such as new transportation services or attribute ranges beyond those observed in existing conditions. When designing SP surveys, considerable care is needed to balance the statistical objectives with the realism of the experiment. This paper presents an innovative method for smartphone-based stated preferences (SP) surveys leveraging state-of-the-art smartphone-based survey platforms and their revealed preferences sensing capabilities. A random experimental design generates context-aware SP profiles using user specific socioeconomic characteristics and past travel data along with relevant web data for scenario generation. The generated choice tasks are automatically validated to reduce the number of dominant or inferior alternatives in real-time, then validated using Monte-Carlo simulations offline. In this paper we focus our attention on mode choice and design an experiment that considers a wide range of possible existing mode alternatives along with a new alternative on-demand mobility service that does not exist in real life. This experiment is then used to collect SP data or a sample of 224 respondents in the Greater Boston Area. A discrete mode choice model is estimated to illustrate the benefit of the proposed method in capturing current context-specific preferences in response to the new scenario.}
}
@article{BARNARDWILLS2017142,
title = {The technology foresight activities of European Union data protection authorities},
journal = {Technological Forecasting and Social Change},
volume = {116},
pages = {142-150},
year = {2017},
issn = {0040-1625},
doi = {https://doi.org/10.1016/j.techfore.2016.08.032},
url = {https://www.sciencedirect.com/science/article/pii/S0040162516305571},
author = {David Barnard-Wills},
keywords = {Data protection, Participatory foresight, Expert bodies, Privacy, Regulation},
abstract = {Data Protection Authorities play multiple roles, including education, consultancy, provision of policy advice, international coordination, as well as enforcement of regulation. In exercising these roles DPA's engage in a range of activities centred around understanding new technology developments, and anticipating their potential effects and impacts upon data protection and privacy. As responsible parties in relation to enforcement of national and EU data protection law DPAs are in a clear position to assess or provide guidance upon the requirements of the existing legal framework in relation to new technologies. This paper maps the technology foresight activities of European DPAs, the importance of this activity to their work, the particular challenges they face, and the extent to which such activities are performed in isolation or collaboration. It also assesses the potential for a collaborative EU DPA technology foresight task force.}
}
@article{MUNSTER20172391,
title = {How to involve inhabitants in urban design planning by using digital tools? An overview on a state of the art, key challenges and promising approaches},
journal = {Procedia Computer Science},
volume = {112},
pages = {2391-2405},
year = {2017},
note = {Knowledge-Based and Intelligent Information & Engineering Systems: Proceedings of the 21st International Conference, KES-20176-8 September 2017, Marseille, France},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2017.08.102},
url = {https://www.sciencedirect.com/science/article/pii/S1877050917314461},
author = {Sander Münster and Christopher Georgi and Katrina Heijne and Kevin Klamert and Jörg {Rainer Noennig} and Matthias Pump and Benjamin Stelzle and Han {van der Meer}},
keywords = {urban planning, survey, public participation, state of the art},
abstract = {Different cases of public disagreement in different European countries have shown recently that perusing a thorough planning process is by no means a guarantee for a broad public acceptance of an envisioned urban project. Consequently, the employment of digital media and tools to enable participation of inhabitants in urban planning processes on a massive scale is a promising, but currently not comprehensively analyzed approach. Our research activities are intended to gain an overview on a state of the art of research on communication channels, methods and best practices as well as to identify key challenges and promising strategies and tools to overcome these challenges with specific regards to large numbers of users and digital supported approaches. The latter aspects comprise the investigation of phenomena like participant selection, framing effects and gamified approaches for digital-mediated participatory processes as well as native language processing techniques to examine opinions as well as ideas of relevance from massive public feedback. To examine, we performed literature reviews of several hundred research articles, investigated cases in Germany, France and the Netherlands by interviews and workshops with stakeholders and employed methods of prototyping to conceptualize, develop and assess some promising approaches such as sentiment analysis in detail.}
}
@article{BALIS2018128,
title = {Holistic approach to management of IT infrastructure for environmental monitoring and decision support systems with urgent computing capabilities},
journal = {Future Generation Computer Systems},
volume = {79},
pages = {128-143},
year = {2018},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2016.08.007},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X16302576},
author = {Bartosz Balis and Robert Brzoza-Woch and Marian Bubak and Marek Kasztelnik and Bartosz Kwolek and Piotr Nawrocki and Piotr Nowakowski and Tomasz Szydlo and Krzysztof Zielinski},
keywords = {IT infrastructure management, Urgent computing, Environmental computing, Smart levee monitoring, Internet of Things, Cloud computing},
abstract = {Modern environmental monitoring and decision support systems are based on complex IT infrastructures comprising multiple hardware and software subsystems that need to provide a variety of Quality of Service (QoS) guarantees required for urgent computing services, essential in emergency situations. Such IT infrastructures need to be managed in order to maintain the quality of service, which–especially when operating in the urgent mode–involves optimization of multiple, often conflicting, objectives and making trade-offs between them. Existing approaches do not solve this issue optimally because they focus on delivering quality of service within individual subsystems in isolation. We propose a holistic approach to system management which takes into account knowledge about the system as a whole—in particular the interplay of conflicting objectives and configuration options across all subsystems. We argue that such an approach produces a better configuration of the involved subsystems, improving the resolution of trade-offs between cost, energy and performance objectives, leading to their better overall fulfillment in comparison with the non-holistic approach in which individual subsystems are managed in isolation. We validate our approach using a prototype implementation of the holistic optimization algorithm—the Holistic Computing Controller, and applying it to a smart levee monitoring and flood decision support system.}
}
@article{ZHANG201765,
title = {Secure hitch in location based social networks},
journal = {Computer Communications},
volume = {100},
pages = {65-77},
year = {2017},
issn = {0140-3664},
doi = {https://doi.org/10.1016/j.comcom.2017.01.011},
url = {https://www.sciencedirect.com/science/article/pii/S0140366417300853},
author = {Shiwen Zhang and Yaping Lin and Qin Liu and Junqiang Jiang and Bo Yin and Kim-Kwang {Raymond Choo}},
keywords = {Location based social networks, Location privacy, Private proximity detection, Multi-keyword dimensional search},
abstract = {Location based services are increasingly popular, partly due to the trend of smartphone and online social network service adoption. However, it is important for location-based service provider (LBSP) to ensure user location privacy in the provision of such services. In this paper, we present a secure hitch service in location based social networks (LBSNs). To provide such a service, we propose a privacy-preserving proximity based location query (PPLQ) protocol, which is based on the hierarchical predicate encryption technique and the prefix membership verification technique. There are two types of users in this system, namely: the querier and the publisher. Our protocol allows a querier to query the location of publishers using multi-dimensional search, and it enforces distance based access control in the location queries. In order to improve the efficiency of our protocol, we use the multi-scale technique to represent user’s location information in the query condition and searchable index. The proposed protocol is designed to achieve multi-dimensional keyword search and bilateral private proximity testing simultaneously. Our protocol enables each user to independently define his/her own location policy for private proximity testing. In particular, we propose some solutions to reduce the search time cost of the CSP so that the time cost is acceptable for queriers. Finally, we demonstrate the utility of the protocol using simulated data on the map of the city area of Changsha and a U.S. census dataset.}
}
@article{PIAO2019158,
title = {Privacy-preserving governmental data publishing: A fog-computing-based differential privacy approach},
journal = {Future Generation Computer Systems},
volume = {90},
pages = {158-174},
year = {2019},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2018.07.038},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X18300773},
author = {Chunhui Piao and Yajuan Shi and Jiaqi Yan and Changyou Zhang and Liping Liu},
keywords = {Governmental statistical data publishing, Privacy-preserving, Fog computing, Differential privacy, MaxDiff histogram},
abstract = {With the growing availability of public open data, the protection of citizens’ privacy has become a vital issue for governmental data publishing. However, there are a large number of operational risks in the current government cloud platforms. When the cloud platform is attacked, most existing privacy protection models for data publishing cannot resist the attacks if the attacker has prior background knowledge. Potential attackers may gain access to the published statistical data, and identify specific individual’s background information, which may cause the disclosure of citizens’ private information. To address this problem, we propose a fog-computing-based differential privacy approach for privacy-preserving data publishing in this paper. We discuss the risk of citizens’ privacy disclosure related to governmental data publishing, and present a differential privacy framework for publishing governmental statistical data based on fog computing. Based on the framework, a data publishing algorithm using a MaxDiff histogram is developed, which can be used to realize the function of preserving user privacy based on fog computing. Applying the differential method, Laplace noises are added to the original data set, which prevents citizens’ privacy from disclosure even if attackers get strong background knowledge. According to the maximum frequency difference, the adjacent data bins are grouped, then the differential privacy histogram with minimum average error can be constructed. We evaluate the proposed approach by computational experiments based on the real data set of Philippine families’ income and expenditures provided by Kaggle. It shows that the proposed data publishing approach can not only effectively protect citizens’ privacy, but also reduce the query sensitivity and improve the utility of the data published.}
}
@article{XIE2020380,
title = {Digital Twin Enabled Asset Anomaly Detection for Building Facility Management},
journal = {IFAC-PapersOnLine},
volume = {53},
number = {3},
pages = {380-385},
year = {2020},
note = {4th IFAC Workshop on Advanced Maintenance Engineering, Services and Technologies - AMEST 2020},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2020.11.061},
url = {https://www.sciencedirect.com/science/article/pii/S2405896320302111},
author = {Xiang Xie and Qiuchen Lu and Ajith Kumar Parlikad and Jennifer Mary Schooling},
keywords = {Building Information Modeling, Digital Twin, Facility Management, Asset Management, Condition Monitoring, Anomaly Detection},
abstract = {Assets play a significant role in building utilities by undertaking the majority of their service functionalities. However, a comprehensive facility management solution that can help to monitor, detect, record and communicate asset anomalous issues is till nowhere to be found. The digital twin concept is gaining increasing popularity in architecture, engineering and construction/facility management (AEC/FM) sector, and a digital twin enabled asset condition monitoring and anomaly detection framework is proposed in this paper. A Bayesian change point detection methodology is tentatively embedded to reveal the suspicious asset anomalies in a real time manner. A demonstrator on cooling pumps is developed and implemented based on Centre for Digital Built Britain (CDBB) West Cambridge Digital Twin Pilot. The results demonstrate that supported by the data management capability provided by digital twin, the proposed framework realizes a continuous condition monitoring and anomaly detection for single asset, which contributes to efficient and automated asset monitoring in O&M management.}
}
@article{BASAK2017114,
title = {Cross layer optimization for outage minimizing routing in cognitive radio ad hoc networks with primary users’ outage protection},
journal = {Journal of Network and Computer Applications},
volume = {98},
pages = {114-124},
year = {2017},
issn = {1084-8045},
doi = {https://doi.org/10.1016/j.jnca.2017.09.004},
url = {https://www.sciencedirect.com/science/article/pii/S1084804517302977},
author = {Surajit Basak and Tamaghna Acharya},
keywords = {Cognitive radio ad hoc networks, Cross-layer approach, Distributed routing, End-to-end outage probability},
abstract = {Path selection to minimize end-to-end (e2e) outage experience of cognitive users (CUs) in a given communication session is one of the key challenges in multi-hop cognitive radio ad hoc networks, where each CU node experiences a unique spatio-temporal variation of spectrum access opportunity. We study the problem under the constraint of probabilistic interference to primary receivers, in contrast to the popular trend of considering detection probability of primary user (PU) transmissions. This is formulated as a joint transmit power control, spectrum assignment and routing problem and a constrained optimization framework are presented for it. Further, using a standard technique for solving the convex optimization problem, a closed form expression for the transmission power of source as well as relay nodes is derived. Based on this, a centralized solution is proposed for optimal spectrum assignment and route selection. In addition, due to the prohibitive complexity of the optimal solution, a low complexity spectrum aware-outage minimizing opportunistic routing (SA-OMOR) solution is presented, along with its possible distributed implementation. Simulation results are used to validate our analytical results as well as the performance comparison between the proposed SA-OMOR scheme and the optimal one.}
}
@article{ZHAO2020132,
title = {Privacy-preserving clustering for big data in cyber-physical-social systems: Survey and perspectives},
journal = {Information Sciences},
volume = {515},
pages = {132-155},
year = {2020},
issn = {0020-0255},
doi = {https://doi.org/10.1016/j.ins.2019.10.019},
url = {https://www.sciencedirect.com/science/article/pii/S0020025519309764},
author = {Yaliang Zhao and Samwel K. Tarus and Laurence T. Yang and Jiayu Sun and Yunfei Ge and Jinke Wang},
keywords = {CPSS, Big data, Cloud computing, Privacy preserving, Clustering},
abstract = {Clustering technique plays a critical role in data mining, and has received great success to solve application problems like community analysis, image retrieval, personalized recommendation, activity prediction, etc. This paper first reviews the traditional clustering and the emerging multiple clustering methods, respectively. Although the existing methods have superior performance on some small or certain datasets, they fall short when clustering is performed on CPSS big data because of the high cost of computation and storage. With the powerful cloud computing, this challenge can be effectively addressed, but it brings enormous threat to individual or company’s privacy. Currently, privacy preserving data mining has attracted widespread attention in academia. Compared to other reviews, this paper focuses on privacy preserving clustering technique, guiding a detailed overview and discussion. Specifically, we introduce a novel privacy-preserving tensor-based multiple clustering, propose a privacy-preserving tensor-based multiple clustering analytic and service framework, and give an illustrated case study on the public transportation dataset. Furthermore, we indicate the remaining challenges of privacy preserving clustering and discuss the future significant research in this area.}
}
@article{QIN201641,
title = {3D change detection – Approaches and applications},
journal = {ISPRS Journal of Photogrammetry and Remote Sensing},
volume = {122},
pages = {41-56},
year = {2016},
issn = {0924-2716},
doi = {https://doi.org/10.1016/j.isprsjprs.2016.09.013},
url = {https://www.sciencedirect.com/science/article/pii/S0924271616304026},
author = {Rongjun Qin and Jiaojiao Tian and Peter Reinartz},
keywords = {3D change detection, Digital surface models, Oblique images, LiDAR, Land-cover classification, Very high resolution},
abstract = {Due to the unprecedented technology development of sensors, platforms and algorithms for 3D data acquisition and generation, 3D spaceborne, airborne and close-range data, in the form of image based, Light Detection and Ranging (LiDAR) based point clouds, Digital Elevation Models (DEM) and 3D city models, become more accessible than ever before. Change detection (CD) or time-series data analysis in 3D has gained great attention due to its capability of providing volumetric dynamics to facilitate more applications and provide more accurate results. The state-of-the-art CD reviews aim to provide a comprehensive synthesis and to simplify the taxonomy of the traditional remote sensing CD techniques, which mainly sit within the boundary of 2D image/spectrum analysis, largely ignoring the particularities of 3D aspects of the data. The inclusion of 3D data for change detection (termed 3D CD), not only provides a source with different modality for analysis, but also transcends the border of traditional top-view 2D pixel/object-based analysis to highly detailed, oblique view or voxel-based geometric analysis. This paper reviews the recent developments and applications of 3D CD using remote sensing and close-range data, in support of both academia and industry researchers who seek for solutions in detecting and analyzing 3D dynamics of various objects of interest. We first describe the general considerations of 3D CD problems in different processing stages and identify CD types based on the information used, being the geometric comparison and geometric-spectral analysis. We then summarize relevant works and practices in urban, environment, ecology and civil applications, etc. Given the broad spectrum of applications and different types of 3D data, we discuss important issues in 3D CD methods. Finally, we present concluding remarks in algorithmic aspects of 3D CD.}
}
@article{MENCAGLI201874,
title = {Harnessing sliding-window execution semantics for parallel stream processing},
journal = {Journal of Parallel and Distributed Computing},
volume = {116},
pages = {74-88},
year = {2018},
note = {Towards the Internet of Data: Applications, Opportunities and Future Challenges},
issn = {0743-7315},
doi = {https://doi.org/10.1016/j.jpdc.2017.10.021},
url = {https://www.sciencedirect.com/science/article/pii/S0743731517302976},
author = {Gabriele Mencagli and Massimo Torquati and Fabio Lucattini and Salvatore Cuomo and Marco Aldinucci},
keywords = {Data stream processing, Internet of Things, Continuous queries, Sliding windows, Parallel computing},
abstract = {According to the recent trend in data acquisition and processing technology, big data are increasingly available in the form of unbounded streams of elementary data items to be processed in real-time. In this paper we study in detail the paradigm of sliding windows, a well-known technique for approximated queries that update their results continuously as new fresh data arrive from the stream. In this work we focus on the relationship between the various existing sliding window semantics and the way the query processing is performed from the parallelism perspective. From this study two alternative parallel models are identified, each covering semantics with very precise properties. Each model is described in terms of its pros and cons, and parallel implementations in the FastFlow framework are analyzed by discussing the layout of the concurrent data structures used for the efficient windows representation in each model.}
}
@article{SANCHEZARIAS2017444,
title = {Midgar: Study of communications security among Smart Objects using a platform of heterogeneous devices for the Internet of Things},
journal = {Future Generation Computer Systems},
volume = {74},
pages = {444-466},
year = {2017},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2017.01.033},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X17301632},
author = {Gonzalo Sánchez-Arias and Cristian {González García} and B. Cristina {Pelayo G-Bustelo}},
keywords = {Internet of Things, Privacy, Security, Cryptography, Ubiquitous computing, Smart Objects, Communications},
abstract = {In last years, the Internet of Things has been a revolution in terms of applications and research. Currently, there are a great variety of nodes connected to each other to create different applications in areas, ranging from sport to business, inter alia. These applications compromise our private information about our bank accounts, health, and location. This makes us take safety measures to achieve a secure communication, where the interception of a message by a malicious user cannot compromise our privacy. This security encompasses a very broad concept that can be addressed in multiple ways. This work focuses on the techniques and cryptographic algorithms that can be used in the messages exchanged among the nodes to create secure Internet of Things networks in a way to protect our communications. In this article, we have used the Midgar platform to evaluate the different possibilities of traditional security techniques related to cryptography with the purpose of testing the different combinations to find a solution for the Internet of Things when it uses insecure protocols. Analysing the results to determine the best solution, in terms of costs and security, we concluded that the use the RSA, AES and SHA-3 algorithms are a real possibility to protect message privacy among smart objects. This combination offers the lowest consumption–security relation among all the combinations that we have tested in our evaluation.}
}
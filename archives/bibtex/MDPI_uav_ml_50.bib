
@Article{rs4051146,
AUTHOR = {Antonio, Pedro and Grimaccia, Francesco and Mussetta, Marco},
TITLE = {Architecture and Methods for Innovative Heterogeneous Wireless Sensor Network Applications},
JOURNAL = {Remote Sensing},
VOLUME = {4},
YEAR = {2012},
NUMBER = {5},
PAGES = {1146--1161},
URL = {https://www.mdpi.com/2072-4292/4/5/1146},
ISSN = {2072-4292},
ABSTRACT = {Nowadays wireless sensor netwoks (WSN) technology, wireless communications and digital electronics have made it realistic to produce a large scale miniaturized devices integrating sensing, processing and communication capabilities. The focus of this paper is to present an innovative mobile platform for heterogeneous sensor networks, combined with adaptive methods to optimize the communication architecture for novel potential applications in multimedia and entertainment. In fact, in the near future, some of the applications foreseen for WSNs will employ multi-platform systems with a high number of different devices, which may be completely different in nature, size, computational and energy capabilities, etc. Nowadays, in addition, data collection could be performed by UAV platforms which can be a sink for ground sensors layer, acting essentially as a mobile gateway. In order to maximize the system performances and the network lifespan, the authors propose a recently developed hybrid technique based on evolutionary algorithms. The goal of this procedure is to optimize the communication energy consumption in WSN by selecting the optimal multi-hop routing schemes, with a suitable hybridization of different routing criteria. The proposed approach can be potentially extended and applied to ongoing research projects focused on UAV-based sensing with WSN augmentation and real-time processing for immersive media experiences.},
DOI = {10.3390/rs4051146}
}



@Article{rs4051310,
AUTHOR = {Hölbling, Daniel and Füreder, Petra and Antolini, Francesco and Cigna, Francesca and Casagli, Nicola and Lang, Stefan},
TITLE = {A Semi-Automated Object-Based Approach for Landslide Detection Validated by Persistent Scatterer Interferometry Measures and Landslide Inventories},
JOURNAL = {Remote Sensing},
VOLUME = {4},
YEAR = {2012},
NUMBER = {5},
PAGES = {1310--1336},
URL = {https://www.mdpi.com/2072-4292/4/5/1310},
ISSN = {2072-4292},
ABSTRACT = {Geoinformation derived from Earth observation (EO) plays a key role for detecting, analyzing and monitoring landslides to assist hazard and risk analysis. Within the framework of the EC-GMES-FP7 project SAFER (Services and Applications For Emergency Response) a semi-automated object-based approach for landslide detection and classification has been developed. The method was applied to a case study in North-Western Italy using SPOT-5 imagery and a digital elevation model (DEM), including its derivatives slope, aspect, curvature and plan curvature. For the classification in the object-based environment spectral, spatial and morphological properties as well as context information were used. In a first step, landslides were classified on a coarse segmentation level to separate them from other features with similar spectral characteristics. Thereafter, the classification was refined on a finer segmentation level, where two categories of mass movements were differentiated: flow-like landslides and other landslide types. In total, an area of 3.77 km² was detected as landslide-affected area, 1.68 km² were classified as flow-like landslides and 2.09 km² as other landslide types. The outcomes were compared to and validated by pre-existing landslide inventory data (IFFI and PAI) and an interpretation of PSI (Persistent Scatterer Interferometry) measures derived from ERS1/2, ENVISAT ASAR and RADARSAT-1 data. The spatial overlap of the detected landslides and existing landslide inventories revealed 44.8% (IFFI) and 50.4% (PAI), respectively. About 32% of the polygons identified through OBIA are covered by persistent scatterers data.},
DOI = {10.3390/rs4051310}
}



@Article{s121216802,
AUTHOR = {Martí, Enrique David and Martín, David and García, Jesús and De la Escalera, Arturo and Molina, José Manuel and Armingol, José María},
TITLE = {Context-Aided Sensor Fusion for Enhanced Urban Navigation},
JOURNAL = {Sensors},
VOLUME = {12},
YEAR = {2012},
NUMBER = {12},
PAGES = {16802--16837},
URL = {https://www.mdpi.com/1424-8220/12/12/16802},
PubMedID = {23223080},
ISSN = {1424-8220},
ABSTRACT = {The deployment of Intelligent Vehicles in urban environments requires reliable estimation of positioning for urban navigation. The inherent complexity of this kind of environments fosters the development of novel systems which should provide reliable and precise solutions to the vehicle. This article details an advanced GNSS/IMU fusion system based on a context-aided Unscented Kalman filter for navigation in urban conditions. The constrained non-linear filter is here conditioned by a contextual knowledge module which reasons about sensor quality and driving context in order to adapt it to the situation, while at the same time it carries out a continuous estimation and correction of INS drift errors. An exhaustive analysis has been carried out with available data in order to characterize the behavior of available sensors and take it into account in the developed solution. The performance is then analyzed with an extensive dataset containing representative situations. The proposed solution suits the use of fusion algorithms for deploying Intelligent Transport Systems in urban environments.},
DOI = {10.3390/s121216802}
}



@Article{rs5052037,
AUTHOR = {Sima, Aleksandra A. and Buckley, Simon J.},
TITLE = {Optimizing SIFT for Matching of Short Wave Infrared and Visible Wavelength Images},
JOURNAL = {Remote Sensing},
VOLUME = {5},
YEAR = {2013},
NUMBER = {5},
PAGES = {2037--2056},
URL = {https://www.mdpi.com/2072-4292/5/5/2037},
ISSN = {2072-4292},
ABSTRACT = {The scale invariant feature transform (SIFT) is a widely used interest operator for supporting tasks such as 3D matching, 3D scene reconstruction, panorama stitching, image registration and motion tracking. Although SIFT is reported to be robust to disparate radiometric and geometric conditions in visible light imagery, using the default input parameters does not yield satisfactory results when matching imagery acquired at  non-overlapping wavelengths. In this paper, optimization of the SIFT parameters for matching multi-wavelength image sets is documented. In order to integrate hyperspectral panoramic images with reference imagery and 3D data, corresponding points were required between visible light and short wave infrared images, each acquired from a slightly different position and with different resolutions and geometric projections. The default SIFT parameters resulted in too few points being found, requiring the influence of five key parameters on the number of matched points to be explored using statistical techniques. Results are discussed for two geological datasets. Using the SIFT operator with optimized parameters and an additional outlier elimination method, allowed between four and 22 times more homologous points to be found with improved image point distributions, than using the default parameter values recommended in the literature.},
DOI = {10.3390/rs5052037}
}



@Article{s131013464,
AUTHOR = {Zhong, Xungao and Zhong, Xunyu and Peng, Xiafu},
TITLE = {Robust Kalman Filtering Cooperated Elman Neural Network Learning for Vision-Sensing-Based Robotic Manipulation with Global Stability},
JOURNAL = {Sensors},
VOLUME = {13},
YEAR = {2013},
NUMBER = {10},
PAGES = {13464--13486},
URL = {https://www.mdpi.com/1424-8220/13/10/13464},
PubMedID = {24108426},
ISSN = {1424-8220},
ABSTRACT = {In this paper, a global-state-space visual servoing scheme is proposed for uncalibrated model-independent robotic manipulation. The scheme is based on robust Kalman filtering (KF), in conjunction with Elman neural network (ENN) learning techniques. The global map relationship between the vision space and the robotic workspace is learned using an ENN. This learned mapping is shown to be an approximate estimate of the Jacobian in global space. In the testing phase, the desired Jacobian is arrived at using a robust KF to improve the ENN learning result so as to achieve robotic precise convergence of the desired pose. Meanwhile, the ENN weights are updated  (re-trained) using a new input-output data pair vector (obtained from the KF cycle)  to ensure robot global stability manipulation. Thus, our method, without requiring  either camera or model parameters, avoids the corrupted performances caused by  camera calibration and modeling errors. To demonstrate the proposed scheme’s  performance, various simulation and experimental results have been presented using a  six-degree-of-freedom robotic manipulator with eye-in-hand configurations.},
DOI = {10.3390/s131013464}
}



@Article{rs5105006,
AUTHOR = {Honkavaara, Eija and Saari, Heikki and Kaivosoja, Jere and Pölönen, Ilkka and Hakala, Teemu and Litkey, Paula and Mäkynen, Jussi and Pesonen, Liisa},
TITLE = {Processing and Assessment of Spectrometric, Stereoscopic Imagery Collected Using a Lightweight UAV Spectral Camera for Precision Agriculture},
JOURNAL = {Remote Sensing},
VOLUME = {5},
YEAR = {2013},
NUMBER = {10},
PAGES = {5006--5039},
URL = {https://www.mdpi.com/2072-4292/5/10/5006},
ISSN = {2072-4292},
ABSTRACT = {Imaging using lightweight, unmanned airborne vehicles (UAVs) is one of the most rapidly developing fields in remote sensing technology. The new, tunable,  Fabry-Perot interferometer-based (FPI) spectral camera, which weighs less than 700 g, makes it possible to collect spectrometric image blocks with stereoscopic overlaps using light-weight UAV platforms. This new technology is highly relevant, because it opens up new possibilities for measuring and monitoring the environment, which is becoming increasingly important for many environmental challenges. Our objectives were to investigate the processing and use of this new type of image data in precision agriculture. We developed the entire processing chain from raw images up to georeferenced reflectance images, digital surface models and biomass estimates. The processing integrates photogrammetric and quantitative remote sensing approaches. We carried out an empirical assessment using FPI spectral imagery collected at an agricultural wheat test site in the summer of 2012. Poor weather conditions during the campaign complicated the data processing, but this is one of the challenges that are faced in operational applications. The results indicated that the camera performed consistently and that the data processing was consistent, as well. During the agricultural experiments, promising results were obtained for biomass estimation when the spectral data was used and when an appropriate radiometric correction was applied to the data. Our results showed that the new FPI technology has a great potential in precision agriculture and indicated many possible future research topics.},
DOI = {10.3390/rs5105006}
}



@Article{f4040922,
AUTHOR = {Lisein, Jonathan and Pierrot-Deseilligny, Marc and Bonnet, Stéphanie and Lejeune, Philippe},
TITLE = {A Photogrammetric Workflow for the Creation of a Forest Canopy Height Model from Small Unmanned Aerial System Imagery},
JOURNAL = {Forests},
VOLUME = {4},
YEAR = {2013},
NUMBER = {4},
PAGES = {922--944},
URL = {https://www.mdpi.com/1999-4907/4/4/922},
ISSN = {1999-4907},
ABSTRACT = {The recent development of operational small unmanned aerial systems (UASs) opens the door for their extensive use in forest mapping, as both the spatial and temporal resolution of UAS imagery better suit local-scale investigation than traditional remote sensing tools. This article focuses on the use of combined photogrammetry and “Structure from Motion” approaches in order to model the forest canopy surface from low-altitude aerial images. An original workflow, using the open source and free photogrammetric toolbox, MICMAC (acronym for Multi Image Matches for Auto Correlation Methods), was set up to create a digital canopy surface model of deciduous stands. In combination with a co-registered light detection and ranging (LiDAR) digital terrain model, the elevation of vegetation was determined, and the resulting hybrid photo/LiDAR canopy height model was compared to data from a LiDAR canopy height model and from forest inventory data. Linear regressions predicting dominant height and individual height from plot metrics and crown metrics showed that the photogrammetric canopy height model was of good quality for deciduous stands. Although photogrammetric reconstruction significantly smooths the canopy surface, the use of this workflow has the potential to take full advantage of the flexible revisit period of drones in order to refresh the LiDAR canopy height model and to collect dense multitemporal canopy height series.},
DOI = {10.3390/f4040922}
}



@Article{rs6042765,
AUTHOR = {Mei, Alessandro and Salvatori, Rosamaria and Fiore, Nicola and Allegrini, Alessia and D&#039;Andrea, Antonio},
TITLE = {Integration of Field and Laboratory Spectral Data with  Multi-Resolution Remote Sensed Imagery for  Asphalt Surface Differentiation},
JOURNAL = {Remote Sensing},
VOLUME = {6},
YEAR = {2014},
NUMBER = {4},
PAGES = {2765--2781},
URL = {https://www.mdpi.com/2072-4292/6/4/2765},
ISSN = {2072-4292},
ABSTRACT = {The ability to classify asphalt surfaces is an important goal for the selection of suitable non-variant targets as pseudo-invariant targets during the calibration/validation of remotely-sensed images. In addition, the possibility to recognize different types of asphalt surfaces on the images can help optimize road network management. This paper presents a multi-resolution study to improve asphalt surface differentiation using field spectroradiometric data, laboratory analysis and remote sensing imagery. Multispectral Infrared and Visible Imaging Spectrometer (MIVIS) airborne data and multispectral images, such as Quickbird and Ikonos, were used. From scatter plots obtained by field data using λ = 460 and 740 nm, referring to MIVIS Bands 2 and 16 and Quickbird and Ikonos Bands 1 and 4, pixels corresponding to asphalt covering were identified, and the slope of their interpolation lines, assumed as asphalt lines, was calculated. These slopes, used as threshold values in the Spectral Angle Mapper (SAM) classifier, obtained an overall accuracy of 95% for Ikonos, 98% for Quickbird and 93% for MIVIS. Laboratory investigations confirm the existence of the asphalt line also for new asphalts, too.},
DOI = {10.3390/rs6042765}
}



@Article{agronomy4030349,
AUTHOR = {Deery, David and Jimenez-Berni, Jose and Jones, Hamlyn and Sirault, Xavier and Furbank, Robert},
TITLE = {Proximal Remote Sensing Buggies and Potential Applications for Field-Based Phenotyping},
JOURNAL = {Agronomy},
VOLUME = {4},
YEAR = {2014},
NUMBER = {3},
PAGES = {349--379},
URL = {https://www.mdpi.com/2073-4395/4/3/349},
ISSN = {2073-4395},
ABSTRACT = {The achievements made in genomic technology in recent decades are yet to be matched by fast and accurate crop phenotyping methods. Such crop phenotyping methods are required for crop improvement efforts to meet expected demand for food and fibre in the future. This review evaluates the role of proximal remote sensing buggies for field-based phenotyping with a particular focus on the application of currently available sensor technology for large-scale field phenotyping. To illustrate the potential for the development of high throughput phenotyping techniques, a case study is presented with sample data sets obtained from a ground-based proximal remote sensing buggy mounted with the following sensors: LiDAR, RGB camera, thermal infra-red camera and imaging spectroradiometer. The development of such techniques for routine deployment in commercial-scale breeding and pre-breeding operations will require a multidisciplinary approach to leverage the recent technological advances realised in computer science, image analysis, proximal remote sensing and robotics.},
DOI = {10.3390/agronomy4030349}
}



@Article{s140813778,
AUTHOR = {Christiansen, Peter and Steen, Kim Arild and Jørgensen, Rasmus Nyholm and Karstoft, Henrik},
TITLE = {Automated Detection and Recognition of Wildlife Using Thermal Cameras},
JOURNAL = {Sensors},
VOLUME = {14},
YEAR = {2014},
NUMBER = {8},
PAGES = {13778--13793},
URL = {https://www.mdpi.com/1424-8220/14/8/13778},
PubMedID = {25196105},
ISSN = {1424-8220},
ABSTRACT = {In agricultural mowing operations, thousands of animals are injured or killed each year, due to the increased working widths and speeds of agricultural machinery. Detection and recognition of wildlife within the agricultural fields is important to reduce wildlife mortality and, thereby, promote wildlife-friendly farming. The work presented in this paper contributes to the automated detection and classification of animals in thermal imaging. The methods and results are based on top-view images taken manually from a lift to motivate work towards unmanned aerial vehicle-based detection and recognition. Hot objects are detected based on a threshold dynamically adjusted to each frame. For the classification of animals, we propose a novel thermal feature extraction algorithm. For each detected object, a thermal signature is calculated using morphological operations. The thermal signature describes heat characteristics of objects and is partly invariant to translation, rotation, scale and posture. The discrete cosine transform (DCT) is used to parameterize the thermal signature and, thereby, calculate a feature vector, which is used for subsequent classification. Using a k-nearest-neighbor (kNN) classifier, animals are discriminated from non-animals with a balanced classification accuracy of 84.7% in an altitude range of 3–10 m and an accuracy of 75.2% for an altitude range of 10–20 m. To incorporate temporal information in the classification, a tracking algorithm is proposed. Using temporal information improves the balanced classification accuracy to 93.3% in an altitude range 3–10 of meters and 77.7% in an altitude range of 10–20 m},
DOI = {10.3390/s140813778}
}



@Article{rs6087660,
AUTHOR = {Mizuochi, Hiroki and Hiyama, Tetsuya and Ohta, Takeshi and Nasahara, Kenlo N.},
TITLE = {Evaluation of the Surface Water Distribution in North-Central Namibia Based on MODIS and AMSR Series},
JOURNAL = {Remote Sensing},
VOLUME = {6},
YEAR = {2014},
NUMBER = {8},
PAGES = {7660--7682},
URL = {https://www.mdpi.com/2072-4292/6/8/7660},
ISSN = {2072-4292},
ABSTRACT = {Semi-arid North-central Namibia has high potential for rice cultivation because large seasonal wetlands (oshana) form during the rainy season. Evaluating the distribution of surface water would reveal the area potentially suitable for rice cultivation. In this study, we detected the distribution of surface water with high spatial and temporal resolution by using two types of complementary satellite data: MODIS (MODerate-resolution Imaging Spectroradiometer) and AMSR-E (Advanced Microwave Scanning Radiometer–Earth Observing System), using AMSR2 after AMSR-E became unavailable. We combined the modified normalized-difference water index (MNDWI) from the MODIS data with the normalized-difference polarization index (NDPI) from the AMSR-E and AMSR2 data to determine the area of surface water. We developed a simple gap-filling method (“database unmixing”) with the two indices, thereby providing daily 500-m-resolution MNDWI maps of north-central Namibia regardless of whether the sky was clear. Moreover, through receiver-operator characteristics (ROC) analysis, we determined the threshold MNDWI  (−0.316) for wetlands. Using ROC analysis, MNDWI had moderate performance (the area under the ROC curve was 0.747), and the recognition error for seasonal wetlands and dry land was 21.2%. The threshold MNDWI let us calculate probability of water presence (PWP) maps for the rainy season and the whole year. The PWP maps revealed the total area potentially suitable for rice cultivation: 1255 km2 (1.6% of the study area).},
DOI = {10.3390/rs6087660}
}



@Article{s140815525,
AUTHOR = {Akbarzadeh, Vahab and Lévesque, Julien-Charles and Gagné, Christian and Parizeau, Marc},
TITLE = {Efficient Sensor Placement Optimization Using Gradient Descent and Probabilistic Coverage},
JOURNAL = {Sensors},
VOLUME = {14},
YEAR = {2014},
NUMBER = {8},
PAGES = {15525--15552},
URL = {https://www.mdpi.com/1424-8220/14/8/15525},
PubMedID = {25196164},
ISSN = {1424-8220},
ABSTRACT = {We are proposing an adaptation of the gradient descent method to optimize the position and orientation of sensors for the sensor placement problem. The novelty of the proposed method lies in the combination of gradient descent optimization with a realistic model, which considers both the topography of the environment and a set of sensors with directional probabilistic sensing. The performance of this approach is compared with two other black box optimization methods over area coverage and processing time. Results show that our proposed method produces competitive results on smaller maps and superior results on larger maps, while requiring much less computation than the other optimization methods to which it has been compared.},
DOI = {10.3390/s140815525}
}



@Article{f5092377,
AUTHOR = {Michelakis, Dimitrios and Stuart, Neil and Lopez, German and Linares, Vinicio and Woodhouse, Iain H.},
TITLE = {Local-Scale Mapping of Biomass in Tropical Lowland Pine Savannas Using ALOS PALSAR},
JOURNAL = {Forests},
VOLUME = {5},
YEAR = {2014},
NUMBER = {9},
PAGES = {2377--2399},
URL = {https://www.mdpi.com/1999-4907/5/9/2377},
ISSN = {1999-4907},
ABSTRACT = {Fine-scale biomass maps offer forest managers the prospect of more  detailed and locally accurate information for measuring, reporting and  verification activities in contexts, such as sustainable forest  management, carbon stock assessments and ecological studies of forest  growth and change. In this study, we apply a locally validated method  for estimating aboveground woody biomass (AGWB) from Advanced Land  Observing Satellite (ALOS) Phased Array-type L-band Synthetic Aperture  Radar (PALSAR) data to produce an AGWB map for the lowland pine savannas  of Belize at a spatial resolution of 100 m. Over 90% of these woodlands  are predicted to have an AGWB below 60 tha−1, with the average woody biomass of these savannas estimated at 23.5 tha−1.  By overlaying these spatial estimates upon previous thematic mapping of  national land cover, we derive representative average biomass values of  ~32 tha−1 and ~18 tha−1 for the previously  qualitative classes of “denser” and “less dense” tree savannas. The  predicted average biomass, from the mapping for savannas woodlands  occurring within two of Belize’s larger protected areas, agree closely  with previous biomass estimates for these areas based on ground surveys  and forest inventories (error ≤20%). However, biomass estimates derived  for these protected areas from two biomass maps produced at coarser  resolutions (500 m and 1000 m) from global datasets overestimated  biomass (errors ≥275% in each dataset). The finer scale biomass mapping  of both protected and unprotected areas provides evidence to suggest  that protection has a positive effect upon woody biomass, with the mean  AGWB higher in areas protected and managed for biodiversity (protected  and passively managed (PRPM), 29.5 tha−1) compared to unprotected areas  (UPR, 23.29 tha−1). These findings suggest that where sufficient ground  data exists to build a reliable local relationship to radar backscatter,  the more detailed biomass mapping that can be produced from ALOS and  similar satellite data at resolutions of ~100 m provides more accurate  and spatially detailed information that is more appropriate for  supporting the management of forested areas of ~10,000 ha than biomass  maps that can be produced from lower resolution, but freely available  global data sets.},
DOI = {10.3390/f5092377}
}



@Article{rs61212037,
AUTHOR = {Hung, Calvin and Xu, Zhe and Sukkarieh, Salah},
TITLE = {Feature Learning Based Approach for Weed Classification Using High Resolution Aerial Images from a Digital Camera Mounted on a UAV},
JOURNAL = {Remote Sensing},
VOLUME = {6},
YEAR = {2014},
NUMBER = {12},
PAGES = {12037--12054},
URL = {https://www.mdpi.com/2072-4292/6/12/12037},
ISSN = {2072-4292},
ABSTRACT = {The development of low-cost unmanned aerial vehicles (UAVs) and light weight imaging sensors has resulted in significant interest in their use for remote sensing applications. While significant attention has been paid to the collection, calibration, registration and mosaicking of data collected from small UAVs, the interpretation of these data into semantically meaningful information can still be a laborious task. A standard data collection and classification work-flow requires significant manual effort for segment size tuning, feature selection and rule-based classifier design. In this paper, we propose an alternative learning-based approach using feature learning to minimise the manual effort required. We apply this system to the classification of invasive weed species. Small UAVs are suited to this application, as they can collect data at high spatial resolutions, which is essential for the classification of small or localised weed outbreaks. In this paper, we apply feature learning to generate a bank of image filters that allows for the extraction of features that discriminate between the weeds of interest and background objects. These features are pooled to summarise the image statistics and form the input to a texton-based linear classifier that classifies an image patch as weed or background. We evaluated our approach to weed classification on three weeds of significance in Australia: water hyacinth, tropical soda apple and serrated tussock. Our results showed that collecting images at 5–10 m resulted in the highest classifier accuracy, indicated by F1 scores of up to 94%.},
DOI = {10.3390/rs61212037}
}



@Article{rs70100342,
AUTHOR = {Sankey, Joel B. and Munson, Seth M. and Webb, Robert H. and Wallace, Cynthia S. A. and Duran, Cesar M.},
TITLE = {Remote Sensing of Sonoran Desert Vegetation Structure and Phenology with Ground-Based LiDAR},
JOURNAL = {Remote Sensing},
VOLUME = {7},
YEAR = {2015},
NUMBER = {1},
PAGES = {342--359},
URL = {https://www.mdpi.com/2072-4292/7/1/342},
ISSN = {2072-4292},
ABSTRACT = {Long-term vegetation monitoring efforts have become increasingly important for understanding ecosystem response to global change. Many traditional methods for monitoring can be infrequent and limited in scope. Ground-based LiDAR is one remote sensing method that offers a clear advancement to monitor vegetation dynamics at high spatial and temporal resolution. We determined the effectiveness of LiDAR to detect  intra-annual variability in vegetation structure at a long-term Sonoran Desert monitoring plot dominated by cacti, deciduous and evergreen shrubs. Monthly repeat LiDAR scans  of perennial plant canopies over the course of one year had high precision. LiDAR measurements of canopy height and area were accurate with respect to total station survey measurements of individual plants. We found an increase in the number of LiDAR vegetation returns following the wet North American Monsoon season. This intra-annual variability in vegetation structure detected by LiDAR was attributable to a drought deciduous shrub Ambrosia deltoidea, whereas the evergreen shrub Larrea tridentata and cactus Opuntia engelmannii had low variability. Benefits of using LiDAR over traditional methods to census desert plants are more rapid, consistent, and cost-effective data acquisition in a high-resolution, 3-dimensional context. We conclude that repeat LiDAR measurements can be an effective method for documenting ecosystem response to desert climatology and drought over short time intervals and at detailed-local spatial scale.},
DOI = {10.3390/rs70100342}
}



@Article{rs70101074,
AUTHOR = {Feng, Quanlong and Liu, Jiantao and Gong, Jianhua},
TITLE = {UAV Remote Sensing for Urban Vegetation Mapping Using Random Forest and Texture Analysis},
JOURNAL = {Remote Sensing},
VOLUME = {7},
YEAR = {2015},
NUMBER = {1},
PAGES = {1074--1094},
URL = {https://www.mdpi.com/2072-4292/7/1/1074},
ISSN = {2072-4292},
ABSTRACT = {Unmanned aerial vehicle (UAV) remote sensing has great potential for vegetation mapping in complex urban landscapes due to the ultra-high resolution imagery acquired at low altitudes. Because of payload capacity restrictions, off-the-shelf digital cameras are widely used on medium and small sized UAVs. The limitation of low spectral resolution in digital cameras for vegetation mapping can be reduced by incorporating texture features and robust classifiers. Random Forest has been widely used in satellite remote sensing applications, but its usage in UAV image classification has not been well documented. The objectives of this paper were to propose a hybrid method using Random Forest and texture analysis to accurately differentiate land covers of urban vegetated areas, and analyze how classification accuracy changes with texture window size. Six least correlated second-order texture measures were calculated at nine different window sizes and added to original Red-Green-Blue (RGB) images as ancillary data. A Random Forest classifier consisting of 200 decision trees was used for classification in the spectral-textural feature space. Results indicated the following: (1) Random Forest outperformed traditional Maximum Likelihood classifier and showed similar performance to object-based image analysis in urban vegetation classification; (2) the inclusion of texture features improved classification accuracy significantly; (3) classification accuracy followed an inverted U relationship with texture window size. The results demonstrate that UAV provides an efficient and ideal platform for urban vegetation mapping. The hybrid method proposed in this paper shows good performance in differentiating urban vegetation mapping. The drawbacks of off-the-shelf digital cameras can be reduced by adopting Random Forest and texture analysis at the same time.},
DOI = {10.3390/rs70101074}
}



@Article{rs70201206,
AUTHOR = {Li, Li and Dong, Jinwei and Njeudeng Tenku, Simon and Xiao, Xiangming},
TITLE = {Mapping Oil Palm Plantations in Cameroon Using PALSAR  50-m Orthorectified Mosaic Images},
JOURNAL = {Remote Sensing},
VOLUME = {7},
YEAR = {2015},
NUMBER = {2},
PAGES = {1206--1224},
URL = {https://www.mdpi.com/2072-4292/7/2/1206},
ISSN = {2072-4292},
ABSTRACT = {Oil palm plantations have expanded rapidly. Estimating either positive effects on the economy, or negative effects on the environment, requires accurate maps. In this paper, three classification algorithms (Support Vector Machine (SVM), Decision Tree and  K-Means) were explored to map oil palm plantations in Cameroon, using PALSAR 50 m Orthorectified Mosaic images and differently sized training samples. SVM had the ideal performance with overall accuracy ranging from 86% to 92% and a Kappa coefficient from 0.76 to 0.85, depending upon the training sample size (ranging from 20 to 500 pixels per class). The advantage of SVM was more obvious when the training sample size was smaller. K-Means required the user’s intervention, and thus, the accuracy depended on the level of his/her expertise and experience. For large-scale mapping of oil palm plantations, the Decision Tree algorithm outperformed both SVM and K-Means in terms of speed and performance. In addition, the decision threshold values of Decision Tree for a large training sample size agrees with the results from previous studies, which implies the possible universality of the decision threshold. If it can be verified, the Decision Tree algorithm will be an easy and robust methodology for mapping oil palm plantations.},
DOI = {10.3390/rs70201206}
}



@Article{rs70302302,
AUTHOR = {Ai, Mingyao and Hu, Qingwu and Li, Jiayuan and Wang, Ming and Yuan, Hui and Wang, Shaohua},
TITLE = {A Robust Photogrammetric Processing Method of Low-Altitude UAV Images},
JOURNAL = {Remote Sensing},
VOLUME = {7},
YEAR = {2015},
NUMBER = {3},
PAGES = {2302--2333},
URL = {https://www.mdpi.com/2072-4292/7/3/2302},
ISSN = {2072-4292},
ABSTRACT = {Low-altitude Unmanned Aerial Vehicles (UAV) images which include distortion, illumination variance, and large rotation angles are facing multiple challenges of image orientation and image processing. In this paper, a robust and convenient photogrammetric approach is proposed for processing low-altitude UAV images, involving a strip management method to automatically build a standardized regional aerial triangle (AT) network, a parallel inner orientation algorithm, a ground control points (GCPs) predicting method, and an improved Scale Invariant Feature Transform (SIFT) method to produce large number of evenly distributed reliable tie points for bundle adjustment (BA). A multi-view matching approach is improved to produce Digital Surface Models (DSM) and Digital Orthophoto Maps (DOM) for 3D visualization. Experimental results show that the proposed approach is robust and feasible for photogrammetric processing of  low-altitude UAV images and 3D visualization of products.},
DOI = {10.3390/rs70302302}
}



@Article{rs70302627,
AUTHOR = {Hassan-Esfahani, Leila and Torres-Rua, Alfonso and Jensen, Austin and McKee, Mac},
TITLE = {Assessment of Surface Soil Moisture Using High-Resolution Multi-Spectral Imagery and Artificial Neural Networks},
JOURNAL = {Remote Sensing},
VOLUME = {7},
YEAR = {2015},
NUMBER = {3},
PAGES = {2627--2646},
URL = {https://www.mdpi.com/2072-4292/7/3/2627},
ISSN = {2072-4292},
ABSTRACT = {Many crop production management decisions can be informed using data from high-resolution aerial images that provide information about crop health as influenced by soil fertility and moisture. Surface soil moisture is a key component of soil water balance, which addresses water and energy exchanges at the surface/atmosphere interface; however, high-resolution remotely sensed data is rarely used to acquire soil moisture values. In this study, an artificial neural network (ANN) model was developed to quantify the effectiveness of using spectral images to estimate surface soil moisture. The model produces acceptable estimations of surface soil moisture (root mean square error (RMSE) = 2.0, mean absolute error (MAE) = 1.8, coefficient of correlation (r) = 0.88, coefficient of performance (e) = 0.75 and coefficient of determination (R2) = 0.77) by combining field measurements with inexpensive and readily available remotely sensed inputs. The spatial data (visual spectrum, near infrared, infrared/thermal) are produced by the AggieAir™ platform, which includes an unmanned aerial vehicle (UAV) that enables users to gather aerial imagery at a low price and high spatial and temporal resolutions. This study reports the development of an ANN model that translates AggieAir™ imagery into estimates of surface soil moisture for a large field irrigated by a center pivot sprinkler system.},
DOI = {10.3390/rs70302627}
}



@Article{w7041437,
AUTHOR = {Feng, Quanlong and Liu, Jiantao and Gong, Jianhua},
TITLE = {Urban Flood Mapping Based on Unmanned Aerial Vehicle Remote Sensing and Random Forest Classifier—A Case of Yuyao, China},
JOURNAL = {Water},
VOLUME = {7},
YEAR = {2015},
NUMBER = {4},
PAGES = {1437--1455},
URL = {https://www.mdpi.com/2073-4441/7/4/1437},
ISSN = {2073-4441},
ABSTRACT = {Flooding is a severe natural hazard, which poses a great threat to human life and property, especially in densely-populated urban areas. As one of the fastest developing fields in remote sensing applications, an unmanned aerial vehicle (UAV) can provide  high-resolution data with a great potential for fast and accurate detection of inundated areas under complex urban landscapes. In this research, optical imagery was acquired by a mini-UAV to monitor the serious urban waterlogging in Yuyao, China. Texture features derived from gray-level co-occurrence matrix were included to increase the separability of different ground objects. A Random Forest classifier, consisting of 200 decision trees, was used to extract flooded areas in the spectral-textural feature space. Confusion matrix was used to assess the accuracy of the proposed method. Results indicated the following:  (1) Random Forest showed good performance in urban flood mapping with an overall accuracy of 87.3% and a Kappa coefficient of 0.746; (2) the inclusion of texture features improved classification accuracy significantly; (3) Random Forest outperformed maximum likelihood and artificial neural network, and showed a similar performance to support vector machine. The results demonstrate that UAV can provide an ideal platform for urban flood monitoring and the proposed method shows great capability for the accurate extraction of inundated areas.},
DOI = {10.3390/w7041437}
}



@Article{mi6040487,
AUTHOR = {Li, Dachuan and Li, Qing and Tang, Liangwen and Yang, Sheng and Cheng, Nong and Song, Jingyan},
TITLE = {Invariant Observer-Based State Estimation for Micro-Aerial Vehicles in GPS-Denied Indoor Environments Using an RGB-D Camera and MEMS Inertial Sensors},
JOURNAL = {Micromachines},
VOLUME = {6},
YEAR = {2015},
NUMBER = {4},
PAGES = {487--522},
URL = {https://www.mdpi.com/2072-666X/6/4/487},
ISSN = {2072-666X},
ABSTRACT = {This paper presents a non-linear state observer-based integrated navigation scheme for estimating the attitude, position and velocity of micro aerial vehicles (MAV) operating in GPS-denied indoor environments, using the measurements from low-cost MEMS (micro electro-mechanical systems) inertial sensors and an RGB-D camera.  A robust RGB-D visual odometry (VO) approach was developed to estimate the MAV’s relative motion by extracting and matching features captured by the RGB-D camera from the environment. The state observer of the RGB-D visual-aided inertial navigation was then designed based on the invariant observer theory for systems possessing symmetries. The motion estimates from the RGB-D VO were fused with inertial and magnetic measurements from the onboard MEMS sensors via the state observer, providing the MAV with accurate estimates of its full six degree-of-freedom states. Implementations on a quadrotor MAV and indoor flight test results demonstrate that the resulting state observer is effective in estimating the MAV’s states without relying on external navigation aids such as GPS. The properties of computational efficiency and simplicity in gain tuning make the proposed invariant observer-based navigation scheme appealing for actual MAV applications in indoor environments.},
DOI = {10.3390/mi6040487}
}



@Article{rs70505584,
AUTHOR = {Calderón, Rocío and Navas-Cortés, Juan A. and Zarco-Tejada, Pablo J.},
TITLE = {Early Detection and Quantification of Verticillium Wilt in Olive Using Hyperspectral and Thermal Imagery over Large Areas},
JOURNAL = {Remote Sensing},
VOLUME = {7},
YEAR = {2015},
NUMBER = {5},
PAGES = {5584--5610},
URL = {https://www.mdpi.com/2072-4292/7/5/5584},
ISSN = {2072-4292},
ABSTRACT = {Automatic methods for an early detection of plant diseases (i.e., visible symptoms at early stages of disease development) using remote sensing are critical for precision crop protection. Verticillium wilt (VW) of olive caused by Verticillium dahliae can be controlled only if detected at early stages of development. Linear discriminant analysis (LDA) and support vector machine (SVM) classification methods were applied to classify V. dahliae severity using remote sensing at large scale. High-resolution thermal and hyperspectral imagery were acquired with a manned platform which flew a 3000-ha commercial olive area. LDA reached an overall accuracy of 59.0% and a κ of 0.487 while SVM obtained a higher overall accuracy, 79.2% with a similar κ, 0.495. However, LDA better classified trees at initial and low severity levels, reaching accuracies of 71.4 and 75.0%, respectively, in comparison with the 14.3% and 40.6% obtained by SVM. Normalized canopy temperature, chlorophyll fluorescence, structural, xanthophyll, chlorophyll, carotenoid and disease indices were found to be the best indicators for early and advanced stage infection by VW. These results demonstrate that the methods developed in other studies at orchard scale are valid for flights in large areas comprising several olive orchards differing in soil and crop management characteristics.},
DOI = {10.3390/rs70505584}
}



@Article{rs70506380,
AUTHOR = {Dronova, Iryna},
TITLE = {Object-Based Image Analysis in Wetland Research: A Review},
JOURNAL = {Remote Sensing},
VOLUME = {7},
YEAR = {2015},
NUMBER = {5},
PAGES = {6380--6413},
URL = {https://www.mdpi.com/2072-4292/7/5/6380},
ISSN = {2072-4292},
ABSTRACT = {The applications of object-based image analysis (OBIA) in remote sensing studies of wetlands have been growing over recent decades, addressing tasks from detection and delineation of wetland bodies to comprehensive analyses of within-wetland cover types and their change. Compared to pixel-based approaches, OBIA offers several important benefits to wetland analyses related to smoothing of the local noise, incorporating meaningful  non-spectral features for class separation and accounting for landscape hierarchy of wetland ecosystem organization and structure. However, there has been little discussion on whether unique challenges of wetland environments can be uniformly addressed by OBIA across different types of data, spatial scales and research objectives, and to what extent technical and conceptual aspects of this framework may themselves present challenges in a complex wetland setting. This review presents a synthesis of 73 studies that applied OBIA to different types of remote sensing data, spatial scale and research objectives. It summarizes the progress and scope of OBIA uses in wetlands, key benefits of this approach, factors related to accuracy and uncertainty in its applications and the main research needs and directions to expand the OBIA capacity in the future wetland studies. Growing demands for higher-accuracy wetland characterization at both regional and local scales together with advances in very high resolution remote sensing and novel tasks in wetland restoration monitoring will likely continue active exploration of the OBIA potential in these diverse and complex environments.},
DOI = {10.3390/rs70506380}
}



@Article{s150716848,
AUTHOR = {Huang, Kuo-Lung and Chiu, Chung-Cheng and Chiu, Sheng-Yi and Teng, Yao-Jen and Hao, Shu-Sheng},
TITLE = {Monocular Vision System for Fixed Altitude Flight of Unmanned Aerial Vehicles},
JOURNAL = {Sensors},
VOLUME = {15},
YEAR = {2015},
NUMBER = {7},
PAGES = {16848--16865},
URL = {https://www.mdpi.com/1424-8220/15/7/16848},
PubMedID = {26184213},
ISSN = {1424-8220},
ABSTRACT = {The fastest and most economical method of acquiring terrain images is aerial photography. The use of unmanned aerial vehicles (UAVs) has been investigated for this task. However, UAVs present a range of challenges such as flight altitude maintenance. This paper reports a method that combines skyline detection with a stereo vision algorithm to enable the flight altitude of UAVs to be maintained. A monocular camera is mounted on the downside of the aircraft’s nose to collect continuous ground images, and the relative altitude is obtained via a stereo vision algorithm from the velocity of the UAV. Image detection is used to obtain terrain images, and to measure the relative altitude from the ground to the UAV. The UAV flight system can be set to fly at a fixed and relatively low altitude to obtain the same resolution of ground images. A forward-looking camera is mounted on the upside of the aircraft’s nose. In combination with the skyline detection algorithm, this helps the aircraft to maintain a stable flight pattern. Experimental results show that the proposed system enables UAVs to obtain terrain images at constant resolution, and to detect the relative altitude along the flight path.},
DOI = {10.3390/s150716848}
}



@Article{s150923805,
AUTHOR = {Gökçe, Fatih and Üçoluk, Göktürk and Şahin, Erol and Kalkan, Sinan},
TITLE = {Vision-Based Detection and Distance Estimation of Micro Unmanned Aerial Vehicles},
JOURNAL = {Sensors},
VOLUME = {15},
YEAR = {2015},
NUMBER = {9},
PAGES = {23805--23846},
URL = {https://www.mdpi.com/1424-8220/15/9/23805},
PubMedID = {26393599},
ISSN = {1424-8220},
ABSTRACT = {Detection and distance estimation of micro unmanned aerial vehicles (mUAVs) is crucial for (i) the detection of intruder mUAVs in protected environments; (ii) sense and avoid purposes on mUAVs or on other aerial vehicles and (iii) multi-mUAV control scenarios, such as environmental monitoring, surveillance and exploration. In this article, we evaluate vision algorithms as alternatives for detection and distance estimation of mUAVs, since other sensing modalities entail certain limitations on the environment or on the distance. For this purpose, we test Haar-like features, histogram of gradients (HOG) and local binary patterns (LBP) using cascades of boosted classifiers. Cascaded boosted classifiers allow fast processing by performing detection tests at multiple stages, where only candidates passing earlier simple stages are processed at the preceding more complex stages. We also integrate a distance estimation method with our system utilizing geometric cues with support vector regressors. We evaluated each method on indoor and outdoor videos that are collected in a systematic way and also on videos having motion blur. Our experiments show that, using boosted cascaded classifiers with LBP, near real-time detection and distance estimation of mUAVs are possible in about 60 ms indoors (1032 × 778 resolution) and 150 ms outdoors (1280 × 720 resolution) per frame, with a detection rate of 0.96 F-score. However, the cascaded classifiers using Haar-like features lead to better distance estimation since they can position the bounding boxes on mUAVs more accurately. On the other hand, our time analysis yields that the cascaded classifiers using HOG train and run faster than the other algorithms.},
DOI = {10.3390/s150923805}
}



@Article{rs70912539,
AUTHOR = {Feng, Quanlong and Gong, Jianhua and Liu, Jiantao and Li, Yi},
TITLE = {Flood Mapping Based on Multiple Endmember Spectral Mixture Analysis and Random Forest Classifier—The Case of Yuyao, China},
JOURNAL = {Remote Sensing},
VOLUME = {7},
YEAR = {2015},
NUMBER = {9},
PAGES = {12539--12562},
URL = {https://www.mdpi.com/2072-4292/7/9/12539},
ISSN = {2072-4292},
ABSTRACT = {Remote sensing is recognized as a valuable tool for flood mapping due to its synoptic view and continuous coverage of the flooding event. This paper proposed a hybrid approach based on multiple endmember spectral analysis (MESMA) and Random Forest classifier to extract inundated areas in Yuyao City in China using medium resolution optical imagery. MESMA was adopted to tackle the mixing pixel problem induced by medium resolution data. Specifically, 35 optimal endmembers were selected to construct a total of 3111 models in the MESMA procedure to derive accurate fraction information. A multi-dimensional feature space was constructed including the normalized difference water index (NDWI), topographical parameters of height, slope, and aspect together with the fraction maps. A Random Forest classifier consisting of 200 decision trees was adopted to classify the post-flood image based on the above multi-features. Experimental results indicated that the proposed method can extract the inundated areas precisely with a classification accuracy of 94% and a Kappa index of 0.88. The inclusion of fraction information can help improve the mapping accuracy with an increase of 2.5%. Moreover, the proposed method also outperformed the maximum likelihood classifier and the NDWI thresholding method. This research provided a useful reference for flood mapping using medium resolution optical remote sensing imagery.},
DOI = {10.3390/rs70912539}
}



@Article{ijgi4042131,
AUTHOR = {Akcay, Ozgun},
TITLE = {Landslide Fissure Inference Assessment by ANFIS and Logistic Regression Using UAS-Based Photogrammetry},
JOURNAL = {ISPRS International Journal of Geo-Information},
VOLUME = {4},
YEAR = {2015},
NUMBER = {4},
PAGES = {2131--2158},
URL = {https://www.mdpi.com/2220-9964/4/4/2131},
ISSN = {2220-9964},
ABSTRACT = {Unmanned Aerial Systems (UAS) are now capable of gathering high-resolution data, therefore, landslides can be explored in detail at larger scales. In this research, 132 aerial photographs were captured, and 85,456 features were detected and matched automatically using UAS photogrammetry. The root mean square (RMS) values of the image coordinates of the Ground Control Points (GPCs) varied from 0.521 to 2.293 pixels, whereas maximum RMS values of automatically matched features was calculated as 2.921 pixels. Using the 3D point cloud, which was acquired by aerial photogrammetry, the raster datasets of the aspect, slope, and maximally stable extremal regions (MSER) detecting visual uniformity, were defined as three variables, in order to reason fissure structures on the landslide surface. In this research, an Adaptive Neuro Fuzzy Inference System (ANFIS) and a Logistic Regression (LR) were implemented using training datasets to infer fissure data appropriately. The accuracy of the predictive models was evaluated by drawing receiver operating characteristic (ROC) curves and by calculating the area under the ROC curve (AUC). The experiments exposed that high-resolution imagery is an indispensable data source to model and validate landslide fissures appropriately.},
DOI = {10.3390/ijgi4042131}
}



@Article{s151127969,
AUTHOR = {Casado, Monica Rivas and Gonzalez, Rocio Ballesteros and Kriechbaumer, Thomas and Veal, Amanda},
TITLE = {Automated Identification of River Hydromorphological Features Using UAV High Resolution Aerial Imagery},
JOURNAL = {Sensors},
VOLUME = {15},
YEAR = {2015},
NUMBER = {11},
PAGES = {27969--27989},
URL = {https://www.mdpi.com/1424-8220/15/11/27969},
PubMedID = {26556355},
ISSN = {1424-8220},
ABSTRACT = {European legislation is driving the development of methods for river ecosystem protection in light of concerns over water quality and ecology. Key to their success is the accurate and rapid characterisation of physical features (i.e., hydromorphology) along the river. Image pattern recognition techniques have been successfully used for this purpose. The reliability of the methodology depends on both the quality of the aerial imagery  and the pattern recognition technique used. Recent studies have proved the potential of Unmanned Aerial Vehicles (UAVs) to increase the quality of the imagery by capturing high resolution photography. Similarly, Artificial Neural Networks (ANN) have been shown to be a high precision tool for automated recognition of environmental patterns. This paper presents a UAV based framework for the identification of hydromorphological features from high resolution RGB aerial imagery using a novel classification technique based on ANNs. The framework is developed for a 1.4 km river reach along the river Dee in Wales, United Kingdom. For this purpose, a Falcon 8 octocopter was used to gather  2.5 cm resolution imagery. The results show that the accuracy of the framework is above 81%, performing particularly well at recognising vegetation. These results leverage the use of UAVs for environmental policy implementation and demonstrate the potential of ANNs and RGB imagery for high precision river monitoring and river management.},
DOI = {10.3390/s151127969}
}



@Article{su71114834,
AUTHOR = {Feng, Quanlong and Gong, Jianhua and Liu, Jiantao and Li, Yi},
TITLE = {Monitoring Cropland Dynamics of the Yellow River Delta based on Multi-Temporal Landsat Imagery over 1986 to 2015},
JOURNAL = {Sustainability},
VOLUME = {7},
YEAR = {2015},
NUMBER = {11},
PAGES = {14834--14858},
URL = {https://www.mdpi.com/2071-1050/7/11/14834},
ISSN = {2071-1050},
ABSTRACT = {Natural deltas can provide human beings with flat and fertile land to be cultivated. It is important to monitor cropland dynamics to provide policy-relevant information for regional sustainable development. This paper utilized Landsat imagery to study the cropland dynamics of the Yellow River Delta during the last three decades. Multi-temporal Landsat data were used to account for the phenological variations of different plants. Several spectral and textural features were adopted to increase the between-class separability. The robust random forest classifier was used to generate the land cover maps of the Yellow River Delta for 1986, 1995, 2005 and 2015. Experimental results indicated that the proposed methodology showed good performance with an average classification accuracy of 89.44%. The spatial-temporal analysis indicated that the cropland area increased from 467.6 km2 in 1986 to 718.5 km2 in 2015 with an average growth rate of 8.65 km2/year. The newly created croplands were mainly due to the reclamation of grassland and bare soil while the losses of croplands were due to abandoned cultivation and urban sprawl. The results demonstrate that a sustainable perspective should be adopted by the decision makers in order to simultaneously maintain food security, industrial development and ecosystem safety.},
DOI = {10.3390/su71114834}
}



@Article{rs71115467,
AUTHOR = {Näsi, Roope and Honkavaara, Eija and Lyytikäinen-Saarenmaa, Päivi and Blomqvist, Minna and Litkey, Paula and Hakala, Teemu and Viljanen, Niko and Kantola, Tuula and Tanhuanpää, Topi and Holopainen, Markus},
TITLE = {Using UAV-Based Photogrammetry and Hyperspectral Imaging for Mapping Bark Beetle Damage at Tree-Level},
JOURNAL = {Remote Sensing},
VOLUME = {7},
YEAR = {2015},
NUMBER = {11},
PAGES = {15467--15493},
URL = {https://www.mdpi.com/2072-4292/7/11/15467},
ISSN = {2072-4292},
ABSTRACT = {Low-cost, miniaturized hyperspectral imaging technology is becoming available for small unmanned aerial vehicle (UAV) platforms. This technology can be efficient in carrying out small-area inspections of anomalous reflectance characteristics of trees at a very high level of detail. Increased frequency and intensity of insect induced forest disturbance has established a new demand for effective methods suitable in mapping and monitoring tasks. In this investigation, a novel miniaturized hyperspectral frame imaging sensor operating in the wavelength range of 500–900 nm was used to identify mature Norway spruce (Picea abies L. Karst.) trees suffering from infestation, representing a different outbreak phase, by the European spruce bark beetle (Ips typographus L.). We developed a new processing method for analyzing spectral characteristic for high spatial resolution photogrammetric and hyperspectral images in forested environments, as well as for identifying individual anomalous trees. The dense point clouds, measured using image matching, enabled detection of single trees with an accuracy of 74.7%. We classified the trees into classes of healthy, infested and dead, and the results were promising. The best results for the overall accuracy were 76% (Cohen’s kappa 0.60), when using three color classes (healthy, infested, dead). For two color classes (healthy, dead), the best overall accuracy was 90% (kappa 0.80). The survey methodology based on high-resolution hyperspectral imaging will be of a high practical value for forest health management, indicating a status of bark beetle outbreak in time.},
DOI = {10.3390/rs71115467}
}



@Article{s151229777,
AUTHOR = {Li, Geng and Zhang, Pengfei and Wei, Guo and Xie, Yuanping and Yu, Xudong and Long, Xingwu},
TITLE = {Multiple-Point Temperature Gradient Algorithm for Ring Laser Gyroscope Bias Compensation},
JOURNAL = {Sensors},
VOLUME = {15},
YEAR = {2015},
NUMBER = {12},
PAGES = {29910--29922},
URL = {https://www.mdpi.com/1424-8220/15/12/29777},
PubMedID = {26633401},
ISSN = {1424-8220},
ABSTRACT = {To further improve ring laser gyroscope (RLG) bias stability, a multiple-point temperature gradient algorithm is proposed for RLG bias compensation in this paper. Based on the multiple-point temperature measurement system, a complete thermo-image of the RLG block is developed. Combined with the multiple-point temperature gradients between different points of the RLG block, the particle swarm optimization algorithm is used to tune the support vector machine (SVM) parameters, and an optimized design for selecting the thermometer locations is also discussed. The experimental results validate the superiority of the introduced method and enhance the precision and generalizability in the RLG bias compensation model.},
DOI = {10.3390/s151229777}
}



@Article{s151229861,
AUTHOR = {Olivares-Mendez, Miguel A. and Fu, Changhong and Ludivig, Philippe and Bissyandé, Tegawendé F. and Kannan, Somasundar and Zurad, Maciej and Annaiyan, Arun and Voos, Holger and Campoy, Pascual},
TITLE = {Towards an Autonomous Vision-Based Unmanned Aerial System against Wildlife Poachers},
JOURNAL = {Sensors},
VOLUME = {15},
YEAR = {2015},
NUMBER = {12},
PAGES = {31362--31391},
URL = {https://www.mdpi.com/1424-8220/15/12/29861},
PubMedID = {26703597},
ISSN = {1424-8220},
ABSTRACT = {Poaching is an illegal activity that remains out of control in many countries. Based on the 2014 report of the United Nations and Interpol, the illegal trade of global wildlife and natural resources amounts to nearly                                        $               213                                  billion every year, which is even helping to fund armed conflicts. Poaching activities around the world are further pushing many animal species on the brink of extinction. Unfortunately, the traditional methods to fight against poachers are not enough, hence the new demands for more efficient approaches. In this context, the use of new technologies on sensors and algorithms, as well as aerial platforms is crucial to face the high increase of poaching activities in the last few years. Our work is focused on the use of vision sensors on UAVs for the detection and tracking of animals and poachers, as well as the use of such sensors to control quadrotors during autonomous vehicle following and autonomous landing.},
DOI = {10.3390/s151229861}
}



@Article{rs8020095,
AUTHOR = {Al-Rawabdeh, Abdulla and He, Fangning and Moussa, Adel and El-Sheimy, Naser and Habib, Ayman},
TITLE = {Using an Unmanned Aerial Vehicle-Based Digital Imaging System to Derive a 3D Point Cloud for Landslide Scarp Recognition},
JOURNAL = {Remote Sensing},
VOLUME = {8},
YEAR = {2016},
NUMBER = {2},
ARTICLE-NUMBER = {95},
URL = {https://www.mdpi.com/2072-4292/8/2/95},
ISSN = {2072-4292},
ABSTRACT = {Landslides often cause economic losses, property damage, and loss of lives. Monitoring landslides using high spatial and temporal resolution imagery and the ability to quickly identify landslide regions are the basis for emergency disaster management. This study presents a comprehensive system that uses unmanned aerial vehicles (UAVs) and Semi-Global dense Matching (SGM) techniques to identify and extract landslide scarp data. The selected study area is located along a major highway in a mountainous region in Jordan, and contains creeping landslides induced by heavy rainfall. Field observations across the slope body and a deformation analysis along the highway and existing gabions indicate that the slope is active and that scarp features across the slope will continue to open and develop new tension crack features, leading to the downward movement of rocks. The identification of landslide scarps in this study was performed via a dense 3D point cloud of topographic information generated from high-resolution images captured using a low-cost UAV and a target-based camera calibration procedure for a low-cost large-field-of-view camera. An automated approach was used to accurately detect and extract the landslide head scarps based on geomorphological factors: the ratio of normalized Eigenvalues (i.e., λ1/λ2 ≥ λ3) derived using principal component analysis, topographic surface roughness index values, and local-neighborhood slope measurements from the 3D image-based point cloud. Validation of the results was performed using root mean square error analysis and a confusion (error) matrix between manually digitized landslide scarps and the automated approaches. The experimental results using the fully automated 3D point-based analysis algorithms show that these approaches can effectively distinguish landslide scarps. The proposed algorithms can accurately identify and extract landslide scarps with centimeter-scale accuracy. In addition, the combination of UAV-based imagery, 3D scene reconstruction, and landslide scarp recognition/extraction algorithms can provide flexible and effective tool for monitoring landslide scarps and is acceptable for landslide mapping purposes.},
DOI = {10.3390/rs8020095}
}



@Article{rs8030257,
AUTHOR = {Zhang, Jian and Yang, Chenghai and Song, Huaibo and Hoffmann, Wesley Clint and Zhang, Dongyan and Zhang, Guozhong},
TITLE = {Evaluation of an Airborne Remote Sensing Platform Consisting of Two Consumer-Grade Cameras for Crop Identification},
JOURNAL = {Remote Sensing},
VOLUME = {8},
YEAR = {2016},
NUMBER = {3},
ARTICLE-NUMBER = {257},
URL = {https://www.mdpi.com/2072-4292/8/3/257},
ISSN = {2072-4292},
ABSTRACT = {Remote sensing systems based on consumer-grade cameras have been increasingly used in scientific research and remote sensing applications because of their low cost and ease of use. However, the performance of consumer-grade cameras for practical applications has not been well documented in related studies. The objective of this research was to apply three commonly-used classification methods (unsupervised, supervised, and object-based) to three-band imagery with RGB (red, green, and blue bands) and four-band imagery with RGB and near-infrared (NIR) bands to evaluate the performance of a dual-camera imaging system for crop identification. Airborne images were acquired from a cropping area in Texas and mosaicked and georeferenced. The mosaicked imagery was classified using the three classification methods to assess the usefulness of NIR imagery for crop identification and to evaluate performance differences between the object-based and pixel-based methods. Image classification and accuracy assessment showed that the additional NIR band imagery improved crop classification accuracy over the RGB imagery and that the object-based method achieved better results with additional non-spectral image features. The results from this study indicate that the airborne imaging system based on two consumer-grade cameras used in this study can be useful for crop identification and other agricultural applications.},
DOI = {10.3390/rs8030257}
}



@Article{s16040446,
AUTHOR = {Ma, Yalong and Wu, Xinkai and Yu, Guizhen and Xu, Yongzheng and Wang, Yunpeng},
TITLE = {Pedestrian Detection and Tracking from Low-Resolution Unmanned Aerial Vehicle Thermal Imagery},
JOURNAL = {Sensors},
VOLUME = {16},
YEAR = {2016},
NUMBER = {4},
ARTICLE-NUMBER = {446},
URL = {https://www.mdpi.com/1424-8220/16/4/446},
ISSN = {1424-8220},
ABSTRACT = {Driven by the prominent thermal signature of humans and following the growing availability of unmanned aerial vehicles (UAVs), more and more research efforts have been focusing on the detection and tracking of pedestrians using thermal infrared images recorded from UAVs. However, pedestrian detection and tracking from the thermal images obtained from UAVs pose many challenges due to the low-resolution of imagery, platform motion, image instability and the relatively small size of the objects. This research tackles these challenges by proposing a pedestrian detection and tracking system. A two-stage blob-based approach is first developed for pedestrian detection. This approach first extracts pedestrian blobs using the regional gradient feature and geometric constraints filtering and then classifies the detected blobs by using a linear Support Vector Machine (SVM) with a hybrid descriptor, which sophisticatedly combines Histogram of Oriented Gradient (HOG) and Discrete Cosine Transform (DCT) features in order to achieve accurate detection. This research further proposes an approach for pedestrian tracking. This approach employs the feature tracker with the update of detected pedestrian location to track pedestrian objects from the registered videos and extracts the motion trajectory data. The proposed detection and tracking approaches have been evaluated by multiple different datasets, and the results illustrate the effectiveness of the proposed methods. This research is expected to significantly benefit many transportation applications, such as the multimodal traffic performance measure, pedestrian behavior study and pedestrian-vehicle crash analysis. Future work will focus on using fused thermal and visual images to further improve the detection efficiency and effectiveness.},
DOI = {10.3390/s16040446}
}



@Article{rs8040333,
AUTHOR = {Zhen, Zhen and Quackenbush, Lindi J. and Zhang, Lianjun},
TITLE = {Trends in Automatic Individual Tree Crown Detection and Delineation—Evolution of LiDAR Data},
JOURNAL = {Remote Sensing},
VOLUME = {8},
YEAR = {2016},
NUMBER = {4},
ARTICLE-NUMBER = {333},
URL = {https://www.mdpi.com/2072-4292/8/4/333},
ISSN = {2072-4292},
ABSTRACT = {Automated individual tree crown detection and delineation (ITCD) using remotely sensed data plays an increasingly significant role in efficiently, accurately, and completely monitoring forests. This paper reviews trends in ITCD research from 1990–2015 from several perspectives—data/forest type, method applied, accuracy assessment and research objective—with a focus on studies using LiDAR data. This review shows that active sources are becoming more prominent in ITCD studies. Studies using active data—LiDAR in particular—accounted for 80% of the total increase over the entire time period, those using passive data or fusion of passive and active data comprised relatively small proportions of the total increase (8% and 12%, respectively). Additionally, ITCD research has moved from incremental adaptations of algorithms developed for passive data sources to innovative approaches that take advantage of the novel characteristics of active datasets like LiDAR. These improvements make it possible to explore more complex forest conditions (e.g., closed hardwood forests, suburban/urban forests) rather than a single forest type although most published ITCD studies still focused on closed softwood (41%) or mixed forest (22%). Approximately one-third of studies applied individual tree level (30%) assessment, with only a quarter reporting more comprehensive multi-level assessment (23%). Almost one-third of studies (32%) that concentrated on forest parameter estimation based on ITCD results had no ITCD-specific evaluation. Comparison of methods continues to be complicated by both choice of reference data and assessment metric; it is imperative to establish a standardized two-level assessment framework to evaluate and compare ITCD algorithms in order to provide specific recommendations about suitable applications of particular algorithms. However, the evolution of active remotely sensed data and novel platforms implies that automated ITCD will continue to be a promising technology and an attractive research topic for both the forestry and remote sensing communities.},
DOI = {10.3390/rs8040333}
}



@Article{w8040167,
AUTHOR = {Torres-Rua, Alfonso F. and Ticlavilca, Andres M. and Bachour, Roula and McKee, Mac},
TITLE = {Estimation of Surface Soil Moisture in Irrigated Lands by Assimilation of Landsat Vegetation Indices, Surface Energy Balance Products, and Relevance Vector Machines},
JOURNAL = {Water},
VOLUME = {8},
YEAR = {2016},
NUMBER = {4},
ARTICLE-NUMBER = {167},
URL = {https://www.mdpi.com/2073-4441/8/4/167},
ISSN = {2073-4441},
ABSTRACT = {Spatial surface soil moisture can be an important indicator of crop conditions on farmland, but its continuous estimation remains challenging due to coarse spatial and temporal resolution of existing remotely-sensed products. Furthermore, while preceding research on soil moisture using remote sensing (surface energy balance, weather parameters, and vegetation indices) has demonstrated a relationship between these factors and soil moisture, practical continuous spatial quantification of the latter is still unavailable for use in water and agricultural management. In this study, a methodology is presented to estimate volumetric surface soil moisture by statistical selection from potential predictors that include vegetation indices and energy balance products derived from satellite (Landsat) imagery and weather data as identified in scientific literature. This methodology employs a statistical learning machine called a Relevance Vector Machine (RVM) to identify and relate the potential predictors to soil moisture by means of stratified cross-validation and forward variable selection. Surface soil moisture measurements from irrigated agricultural fields in Central Utah in the 2012 irrigation season were used, along with weather data, Landsat vegetation indices, and energy balance products. The methodology, data collection, processing, and estimation accuracy are presented and discussed.},
DOI = {10.3390/w8040167}
}



@Article{s16050594,
AUTHOR = {Chuang, Yung-Chung Matt and Shiu, Yi-Shiang},
TITLE = {A Comparative Analysis of Machine Learning with WorldView-2 Pan-Sharpened Imagery for Tea Crop Mapping},
JOURNAL = {Sensors},
VOLUME = {16},
YEAR = {2016},
NUMBER = {5},
ARTICLE-NUMBER = {594},
URL = {https://www.mdpi.com/1424-8220/16/5/594},
ISSN = {1424-8220},
ABSTRACT = {Tea is an important but vulnerable economic crop in East Asia, highly impacted by climate change. This study attempts to interpret tea land use/land cover (LULC) using very high resolution WorldView-2 imagery of central Taiwan with both pixel and object-based approaches. A total of 80 variables derived from each WorldView-2 band with pan-sharpening, standardization, principal components and gray level co-occurrence matrix (GLCM) texture indices transformation, were set as the input variables. For pixel-based image analysis (PBIA), 34 variables were selected, including seven principal components, 21 GLCM texture indices and six original WorldView-2 bands. Results showed that support vector machine (SVM) had the highest tea crop classification accuracy (OA = 84.70% and KIA = 0.690), followed by random forest (RF), maximum likelihood algorithm (ML), and logistic regression analysis (LR). However, the ML classifier achieved the highest classification accuracy (OA = 96.04% and KIA = 0.887) in object-based image analysis (OBIA) using only six variables. The contribution of this study is to create a new framework for accurately identifying tea crops in a subtropical region with real-time high-resolution WorldView-2 imagery without field survey, which could further aid agriculture land management and a sustainable agricultural product supply.},
DOI = {10.3390/s16050594}
}



@Article{s16050605,
AUTHOR = {Alavi, Shamir and Arsenault, Dennis and Whitehead, Anthony},
TITLE = {Quaternion-Based Gesture Recognition Using Wireless Wearable Motion Capture Sensors},
JOURNAL = {Sensors},
VOLUME = {16},
YEAR = {2016},
NUMBER = {5},
ARTICLE-NUMBER = {605},
URL = {https://www.mdpi.com/1424-8220/16/5/605},
ISSN = {1424-8220},
ABSTRACT = {This work presents the development and implementation of a unified multi-sensor human motion capture and gesture recognition system that can distinguish between and classify six different gestures. Data was collected from eleven participants using a subset of five wireless motion sensors (inertial measurement units) attached to their arms and upper body from a complete motion capture system. We compare Support Vector Machines and Artificial Neural Networks on the same dataset under two different scenarios and evaluate the results. Our study indicates that near perfect classification accuracies are achievable for small gestures and that the speed of classification is sufficient to allow interactivity. However, such accuracies are more difficult to obtain when a participant does not participate in training, indicating that more work needs to be done in this area to create a system that can be used by the general population.},
DOI = {10.3390/s16050605}
}



@Article{ijgi5050057,
AUTHOR = {Minaei, Masoud and Kainz, Wolfgang},
TITLE = {Watershed Land Cover/Land Use Mapping Using Remote Sensing and Data Mining in Gorganrood, Iran},
JOURNAL = {ISPRS International Journal of Geo-Information},
VOLUME = {5},
YEAR = {2016},
NUMBER = {5},
ARTICLE-NUMBER = {57},
URL = {https://www.mdpi.com/2220-9964/5/5/57},
ISSN = {2220-9964},
ABSTRACT = {The Gorganrood watershed (GW) is experiencing considerable environmental change in the form of natural hazards and erosion, as well as deforestation, cultivation and development activities. As a result of this, different types of Land Cover/Land Use (LCLU) change are taking place on an intensive level in the area. This research study investigates the LCLU conditions upstream of this watershed for the years 1972, 1986, 2000 and 2014, using Landsat MSS, TM, ETM+ and OLI/TIRS images. LCLU maps for 1972, 1986, and 2000 were produced using pixel-based classification methods. For the 2014 LCLU map, Geographic Object-Based Image Analysis (GEOBIA) in combination with the data-mining capabilities of Gini and J48 machine-learning algorithms were used. The accuracy of the maps was assessed using overall accuracy, quantity disagreement and allocation disagreement indexes. The overall accuracy ranged from 89% to 95%, quantity disagreement from 2.1% to 6.6%, and allocation disagreement from 2.1% for 2014 to 2.7% for 2000. The results of this study indicate that a significant amount of change has occurred in the region, and that this has as a consequence affected ecosystem services and human activity. This knowledge of the LCLU status in the area will help managers and decision makers to develop plans and programs aimed at effectively managing the watershed into the future.},
DOI = {10.3390/ijgi5050057}
}



@Article{s16050618,
AUTHOR = {Vázquez-Arellano, Manuel and Griepentrog, Hans W. and Reiser, David and Paraforos, Dimitris S.},
TITLE = {3-D Imaging Systems for Agricultural Applications—A Review},
JOURNAL = {Sensors},
VOLUME = {16},
YEAR = {2016},
NUMBER = {5},
ARTICLE-NUMBER = {618},
URL = {https://www.mdpi.com/1424-8220/16/5/618},
ISSN = {1424-8220},
ABSTRACT = {Efficiency increase of resources through automation of agriculture requires more information about the production process, as well as process and machinery status. Sensors are necessary for monitoring the status and condition of production by recognizing the surrounding structures such as objects, field structures, natural or artificial markers, and obstacles. Currently, three dimensional (3-D) sensors are economically affordable and technologically advanced to a great extent, so a breakthrough is already possible if enough research projects are commercialized. The aim of this review paper is to investigate the state-of-the-art of 3-D vision systems in agriculture, and the role and value that only 3-D data can have to provide information about environmental structures based on the recent progress in optical 3-D sensors. The structure of this research consists of an overview of the different optical 3-D vision techniques, based on the basic principles. Afterwards, their application in agriculture are reviewed. The main focus lays on vehicle navigation, and crop and animal husbandry. The depth dimension brought by 3-D sensors provides key information that greatly facilitates the implementation of automation and robotics in agriculture.},
DOI = {10.3390/s16050618}
}



@Article{rs8050416,
AUTHOR = {Fang, Shenghui and Tang, Wenchao and Peng, Yi and Gong, Yan and Dai, Can and Chai, Ruhui and Liu, Kan},
TITLE = {Remote Estimation of Vegetation Fraction and Flower Fraction in Oilseed Rape with Unmanned Aerial Vehicle Data},
JOURNAL = {Remote Sensing},
VOLUME = {8},
YEAR = {2016},
NUMBER = {5},
ARTICLE-NUMBER = {416},
URL = {https://www.mdpi.com/2072-4292/8/5/416},
ISSN = {2072-4292},
ABSTRACT = {This study developed an approach for remote estimation of Vegetation Fraction (VF) and Flower Fraction (FF) in oilseed rape, which is a crop species with conspicuous flowers during reproduction. Canopy reflectance in green, red, red edge and NIR bands was obtained by a camera system mounted on an unmanned aerial vehicle (UAV) when oilseed rape was in the vegetative growth and flowering stage. The relationship of several widely-used Vegetation Indices (VI) vs. VF was tested and found to be different in different phenology stages. At the same VF when oilseed rape was flowering, canopy reflectance increased in all bands, and the tested VI decreased. Therefore, two algorithms to estimate VF were calibrated respectively, one for samples during vegetative growth and the other for samples during flowering stage. The results showed that the Visible Atmospherically Resistant Index (VARIgreen) worked most accurately for estimating VF in flower-free samples with an Root Mean Square Error (RMSE) of 3.56%, while the Enhanced Vegetation Index (EVI2) was the best in flower-containing samples with an RMSE of 5.65%. Based on reflectance in green and NIR bands, a technique was developed to identify whether a sample contained flowers and then to choose automatically the appropriate algorithm for its VF estimation. During the flowering season, we also explored the potential of using canopy reflectance or VIs to estimate FF in oilseed rape. No significant correlation was observed between VI and FF when soil was visible in the sensor’s field of view. Reflectance at 550 nm worked well for FF estimation with coefficient of determination (R2) above 0.6. Our model was validated in oilseed rape planted under different nitrogen fertilization applications and in different phenology stages. The results showed that it was able to predict VF and FF accurately in oilseed rape with RMSE below 6%.},
DOI = {10.3390/rs8050416}
}



@Article{rs8070474,
AUTHOR = {Coy, André and Rankine, Dale and Taylor, Michael and Nielsen, David C. and Cohen, Jane},
TITLE = {Increasing the Accuracy and Automation of Fractional Vegetation Cover Estimation from Digital Photographs},
JOURNAL = {Remote Sensing},
VOLUME = {8},
YEAR = {2016},
NUMBER = {7},
ARTICLE-NUMBER = {474},
URL = {https://www.mdpi.com/2072-4292/8/7/474},
ISSN = {2072-4292},
ABSTRACT = {The use of automated methods to estimate fractional vegetation cover (FVC) from digital photographs has increased in recent years given its potential to produce accurate, fast and inexpensive FVC measurements. Wide acceptance has been delayed because of the limitations in accuracy, speed, automation and generalization of these methods. This work introduces a novel technique, the Automated Canopy Estimator (ACE) that overcomes many of these challenges to produce accurate estimates of fractional vegetation cover using an unsupervised segmentation process. ACE is shown to outperform nine other segmentation algorithms, consisting of both threshold-based and machine learning approaches, in the segmentation of photographs of four different crops (oat, corn, rapeseed and flax) with an overall accuracy of 89.6%. ACE is similarly accurate (88.7%) when applied to remotely sensed corn, producing FVC estimates that are strongly correlated with ground truth values.},
DOI = {10.3390/rs8070474}
}



@Article{s16071117,
AUTHOR = {Kim, Sungho and Song, Woo-Jin and Kim, So-Hyun},
TITLE = {Robust Ground Target Detection by SAR and IR Sensor Fusion Using Adaboost-Based Feature Selection},
JOURNAL = {Sensors},
VOLUME = {16},
YEAR = {2016},
NUMBER = {7},
ARTICLE-NUMBER = {1117},
URL = {https://www.mdpi.com/1424-8220/16/7/1117},
ISSN = {1424-8220},
ABSTRACT = {Long-range ground targets are difficult to detect in a noisy cluttered environment using either synthetic aperture radar (SAR) images or infrared (IR) images. SAR-based detectors can provide a high detection rate with a high false alarm rate to background scatter noise. IR-based approaches can detect hot targets but are affected strongly by the weather conditions. This paper proposes a novel target detection method by decision-level SAR and IR fusion using an Adaboost-based machine learning scheme to achieve a high detection rate and low false alarm rate. The proposed method consists of individual detection, registration, and fusion architecture. This paper presents a single framework of a SAR and IR target detection method using modified Boolean map visual theory (modBMVT) and feature-selection based fusion. Previous methods applied different algorithms to detect SAR and IR targets because of the different physical image characteristics. One method that is optimized for IR target detection produces unsuccessful results in SAR target detection. This study examined the image characteristics and proposed a unified SAR and IR target detection method by inserting a median local average filter (MLAF, pre-filter) and an asymmetric morphological closing filter (AMCF, post-filter) into the BMVT. The original BMVT was optimized to detect small infrared targets. The proposed modBMVT can remove the thermal and scatter noise by the MLAF and detect extended targets by attaching the AMCF after the BMVT. Heterogeneous SAR and IR images were registered automatically using the proposed RANdom SAmple Region Consensus (RANSARC)-based homography optimization after a brute-force correspondence search using the detected target centers and regions. The final targets were detected by feature-selection based sensor fusion using Adaboost. The proposed method showed good SAR and IR target detection performance through feature selection-based decision fusion on a synthetic database generated by OKTAL-SE.},
DOI = {10.3390/s16071117}
}



@Article{s16081325,
AUTHOR = {Xu, Yongzheng and Yu, Guizhen and Wang, Yunpeng and Wu, Xinkai and Ma, Yalong},
TITLE = {A Hybrid Vehicle Detection Method Based on Viola-Jones and HOG + SVM from UAV Images},
JOURNAL = {Sensors},
VOLUME = {16},
YEAR = {2016},
NUMBER = {8},
ARTICLE-NUMBER = {1325},
URL = {https://www.mdpi.com/1424-8220/16/8/1325},
ISSN = {1424-8220},
ABSTRACT = {A new hybrid vehicle detection scheme which integrates the Viola-Jones (V-J) and linear SVM classifier with HOG feature (HOG + SVM) methods is proposed for vehicle detection from low-altitude unmanned aerial vehicle (UAV) images. As both V-J and HOG + SVM are sensitive to on-road vehicles’ in-plane rotation, the proposed scheme first adopts a roadway orientation adjustment method, which rotates each UAV image to align the roads with the horizontal direction so the original V-J or HOG + SVM method can be directly applied to achieve fast detection and high accuracy. To address the issue of descending detection speed for V-J and HOG + SVM, the proposed scheme further develops an adaptive switching strategy which sophistically integrates V-J and HOG + SVM methods based on their different descending trends of detection speed to improve detection efficiency. A comprehensive evaluation shows that the switching strategy, combined with the road orientation adjustment method, can significantly improve the efficiency and effectiveness of the vehicle detection from UAV images. The results also show that the proposed vehicle detection method is competitive compared with other existing vehicle detection methods. Furthermore, since the proposed vehicle detection method can be performed on videos captured from moving UAV platforms without the need of image registration or additional road database, it has great potentials of field applications. Future research will be focusing on expanding the current method for detecting other transportation modes such as buses, trucks, motors, bicycles, and pedestrians.},
DOI = {10.3390/s16081325}
}



@Article{rs8080689,
AUTHOR = {Crommelinck, Sophie and Bennett, Rohan and Gerke, Markus and Nex, Francesco and Yang, Michael Ying and Vosselman, George},
TITLE = {Review of Automatic Feature Extraction from High-Resolution Optical Sensor Data for UAV-Based Cadastral Mapping},
JOURNAL = {Remote Sensing},
VOLUME = {8},
YEAR = {2016},
NUMBER = {8},
ARTICLE-NUMBER = {689},
URL = {https://www.mdpi.com/2072-4292/8/8/689},
ISSN = {2072-4292},
ABSTRACT = {Unmanned Aerial Vehicles (UAVs) have emerged as a rapid, low-cost and flexible acquisition system that appears feasible for application in cadastral mapping: high-resolution imagery, acquired using UAVs, enables a new approach for defining property boundaries. However, UAV-derived data are arguably not exploited to its full potential: based on UAV data, cadastral boundaries are visually detected and manually digitized. A workflow that automatically extracts boundary features from UAV data could increase the pace of current mapping procedures. This review introduces a workflow considered applicable for automated boundary delineation from UAV data. This is done by reviewing approaches for feature extraction from various application fields and synthesizing these into a hypothetical generalized cadastral workflow. The workflow consists of preprocessing, image segmentation, line extraction, contour generation and postprocessing. The review lists example methods per workflow step—including a description, trialed implementation, and a list of case studies applying individual methods. Furthermore, accuracy assessment methods are outlined. Advantages and drawbacks of each approach are discussed in terms of their applicability on UAV data. This review can serve as a basis for future work on the implementation of most suitable methods in a UAV-based cadastral mapping workflow.},
DOI = {10.3390/rs8080689}
}



@Article{s16091406,
AUTHOR = {Fu, Changhong and Duan, Ran and Kircali, Dogan and Kayacan, Erdal},
TITLE = {Onboard Robust Visual Tracking for UAVs Using a Reliable Global-Local Object Model},
JOURNAL = {Sensors},
VOLUME = {16},
YEAR = {2016},
NUMBER = {9},
ARTICLE-NUMBER = {1406},
URL = {https://www.mdpi.com/1424-8220/16/9/1406},
ISSN = {1424-8220},
ABSTRACT = {In this paper, we present a novel onboard robust visual algorithm for long-term arbitrary 2D and 3D object tracking using a reliable global-local object model for unmanned aerial vehicle (UAV) applications, e.g., autonomous tracking and chasing a moving target. The first main approach in this novel algorithm is the use of a global matching and local tracking approach. In other words, the algorithm initially finds feature correspondences in a way that an improved binary descriptor is developed for global feature matching and an iterative Lucas–Kanade optical flow algorithm is employed for local feature tracking. The second main module is the use of an efficient local geometric filter (LGF), which handles outlier feature correspondences based on a new forward-backward pairwise dissimilarity measure, thereby maintaining pairwise geometric consistency. In the proposed LGF module, a hierarchical agglomerative clustering, i.e., bottom-up aggregation, is applied using an effective single-link method. The third proposed module is a heuristic local outlier factor (to the best of our knowledge, it is utilized for the first time to deal with outlier features in a visual tracking application), which further maximizes the representation of the target object in which we formulate outlier feature detection as a binary classification problem with the output features of the LGF module. Extensive UAV flight experiments show that the proposed visual tracker achieves real-time frame rates of more than thirty-five frames per second on an i7 processor with 640 × 512 image resolution and outperforms the most popular state-of-the-art trackers favorably in terms of robustness, efficiency and accuracy.},
DOI = {10.3390/s16091406}
}



@Article{rs8090768,
AUTHOR = {Houborg, Rasmus and McCabe, Matthew F.},
TITLE = {High-Resolution NDVI from Planet’s Constellation of Earth Observing Nano-Satellites: A New Data Source for Precision Agriculture},
JOURNAL = {Remote Sensing},
VOLUME = {8},
YEAR = {2016},
NUMBER = {9},
ARTICLE-NUMBER = {768},
URL = {https://www.mdpi.com/2072-4292/8/9/768},
ISSN = {2072-4292},
ABSTRACT = {Planet Labs (“Planet”) operate the largest fleet of active nano-satellites in orbit, offering an unprecedented monitoring capacity of daily and global RGB image capture at 3–5 m resolution. However, limitations in spectral resolution and lack of accurate radiometric sensor calibration impact the utility of this rich information source. In this study, Planet’s RGB imagery was translated into a Normalized Difference Vegetation Index (NDVI): a common metric for vegetation growth and condition. Our framework employs a data mining approach to build a set of rule-based regression models that relate RGB data to atmospherically corrected Landsat-8 NDVI. The approach was evaluated over a desert agricultural landscape in Saudi Arabia where the use of near-coincident (within five days) Planet and Landsat-8 acquisitions in the training of the regression models resulted in NDVI predictabilities with an r2 of approximately 0.97 and a Mean Absolute Deviation (MAD) on the order of 0.014 (~9%). The MAD increased to 0.021 (~14%) when the Landsat NDVI training image was further away (i.e., 11–16 days) from the corrected Planet image. In these cases, the use of MODIS observations to inform on the change in NDVI occurring between overpasses was shown to significantly improve prediction accuracies. MAD levels ranged from 0.002 to 0.011 (3.9% to 9.1%) for the best performing 80% of the data. The technique is generic and extendable to any region of interest, increasing the utility of Planet’s dense time-series of RGB imagery.},
DOI = {10.3390/rs8090768}
}



@Article{s16101645,
AUTHOR = {Kim, Jaeho and Choi, Sung-Chan and Ahn, Il-Yeup and Sung, Nak-Myoung and Yun, Jaeseok},
TITLE = {From WSN towards WoT: Open API Scheme Based on oneM2M Platforms},
JOURNAL = {Sensors},
VOLUME = {16},
YEAR = {2016},
NUMBER = {10},
ARTICLE-NUMBER = {1645},
URL = {https://www.mdpi.com/1424-8220/16/10/1645},
ISSN = {1424-8220},
ABSTRACT = {Conventional computing systems have been able to be integrated into daily objects and connected to each other due to advances in computing and network technologies, such as wireless sensor networks (WSNs), forming a global network infrastructure, called the Internet of Things (IoT). To support the interconnection and interoperability between heterogeneous IoT systems, the availability of standardized, open application programming interfaces (APIs) is one of the key features of common software platforms for IoT devices, gateways, and servers. In this paper, we present a standardized way of extending previously-existing WSNs towards IoT systems, building the world of the Web of Things (WoT). Based on the oneM2M software platforms developed in the previous project, we introduce a well-designed open API scheme and device-speciﬁc thing adaptation software (TAS) enabling WSN elements, such as a wireless sensor node, to be accessed in a standardized way on a global scale. Three pilot services are implemented (i.e., a WiFi-enabled smart ﬂowerpot, voice-based control for ZigBee-connected home appliances, and WiFi-connected AR.Drone control) to demonstrate the practical usability of the open API scheme and TAS modules. Full details on the method of integrating WSN elements into three example systems are described at the programming code level, which is expected to help future researchers in integrating their WSN systems in IoT platforms, such as oneM2M. We hope that the ﬂexibly-deployable, easily-reusable common open API scheme and TAS-based integration method working with the oneM2M platforms will help the conventional WSNs in diverse industries evolve into the emerging WoT solutions.},
DOI = {10.3390/s16101645}
}



@Article{agriculture6040056,
AUTHOR = {Abdulridha, Jaafar and Ehsani, Reza and De Castro, Ana},
TITLE = {Detection and Differentiation between Laurel Wilt Disease, Phytophthora Disease, and Salinity Damage Using a Hyperspectral Sensing Technique},
JOURNAL = {Agriculture},
VOLUME = {6},
YEAR = {2016},
NUMBER = {4},
ARTICLE-NUMBER = {56},
URL = {https://www.mdpi.com/2077-0472/6/4/56},
ISSN = {2077-0472},
ABSTRACT = {Laurel wilt (Lw) is a fatal disease. It is a vascular pathogen and is considered a major threat to the avocado industry in Florida. Many of the symptoms of Lw resemble those that are caused by other diseases or stress factors. In this study, the best wavelengths with which to discriminate plants affected by Lw from stress factors were determined and classified. Visible-near infrared (400–950 nm) spectral data from healthy trees and those with Lw, Phytophthora, or salinity damage were collected using a handheld spectroradiometer. The total number of wavelengths was averaged in two ranges: 10 nm and 40 nm. Three classification methods, stepwise discriminant (STEPDISC) analysis, multilayer perceptron (MLP), and radial basis function (RBF), were applied in the early stage of Lw infestation. The classification results obtained for MLP, with percent accuracy of classification as high as 98% were better than STEPDISC and RBF. The MLP neural network selected certain wavelengths that were crucial for correctly classifying healthy trees from those with stress trees. The results showed that there were sufficient spectral differences between laurel wilt, healthy trees, and trees that have other diseases; therefore, a remote sensing technique could diagnose Lw in the early stage of infestation.},
DOI = {10.3390/agriculture6040056}
}



@Article{w8120584,
AUTHOR = {Perea-Moreno, Alberto-Jesús and Aguilera-Ureña, María-Jesús and Meroño-De Larriva, José-Emilio and Manzano-Agugliaro, Francisco},
TITLE = {Assessment of the Potential of UAV Video Image Analysis for Planning Irrigation Needs of Golf Courses},
JOURNAL = {Water},
VOLUME = {8},
YEAR = {2016},
NUMBER = {12},
ARTICLE-NUMBER = {584},
URL = {https://www.mdpi.com/2073-4441/8/12/584},
ISSN = {2073-4441},
ABSTRACT = {Golf courses can be considered as precision agriculture, as being a playing surface, their appearance is of vital importance. Areas with good weather tend to have low rainfall. Therefore, the water management of golf courses in these climates is a crucial issue due to the high water demand of turfgrass. Golf courses are rapidly transitioning to reuse water, e.g., the municipalities in the USA are providing price incentives or mandate the use of reuse water for irrigation purposes; in Europe this is mandatory. So, knowing the turfgrass surfaces of a large area can help plan the treated sewage effluent needs. Recycled water is usually of poor quality, thus it is crucial to check the real turfgrass surface in order to be able to plan the global irrigation needs using this type of water. In this way, the irrigation of golf courses does not detract from the natural water resources of the area. The aim of this paper is to propose a new methodology for analysing geometric patterns of video data acquired from UAVs (Unmanned Aerial Vehicle) using a new Hierarchical Temporal Memory (HTM) algorithm. A case study concerning maintained turfgrass, especially for golf courses, has been developed. It shows very good results, better than 98% in the confusion matrix. The results obtained in this study represent a first step toward video imagery classification. In summary, technical progress in computing power and software has shown that video imagery is one of the most promising environmental data acquisition techniques available today. This rapid classification of turfgrass can play an important role for planning water management.},
DOI = {10.3390/w8120584}
}



@Article{s16122118,
AUTHOR = {Ortiz, Alberto and Bonnin-Pascual, Francisco and Garcia-Fidalgo, Emilio and Company-Corcoles, Joan P.},
TITLE = {Vision-Based Corrosion Detection Assisted by a Micro-Aerial Vehicle in a Vessel Inspection Application},
JOURNAL = {Sensors},
VOLUME = {16},
YEAR = {2016},
NUMBER = {12},
ARTICLE-NUMBER = {2118},
URL = {https://www.mdpi.com/1424-8220/16/12/2118},
ISSN = {1424-8220},
ABSTRACT = {Vessel maintenance requires periodic visual inspection of the hull in order to detect typical defective situations of steel structures such as, among others, coating breakdown and corrosion. These inspections are typically performed by well-trained surveyors at great cost because of the need for providing access means (e.g., scaffolding and/or cherry pickers) that allow the inspector to be at arm’s reach from the structure under inspection. This paper describes a defect detection approach comprising a micro-aerial vehicle which is used to collect images from the surfaces under inspection, particularly focusing on remote areas where the surveyor has no visual access, and a coating breakdown/corrosion detector based on a three-layer feed-forward artificial neural network. As it is discussed in the paper, the success of the inspection process depends not only on the defect detection software but also on a number of assistance functions provided by the control architecture of the aerial platform, whose aim is to improve picture quality. Both aspects of the work are described along the different sections of the paper, as well as the classification performance attained.},
DOI = {10.3390/s16122118}
}



@Article{ijgi5120238,
AUTHOR = {Liu, Kai and Ding, Hu and Tang, Guoan and Na, Jiaming and Huang, Xiaoli and Xue, Zhengguang and Yang, Xin and Li, Fayuan},
TITLE = {Detection of Catchment-Scale Gully-Affected Areas Using Unmanned Aerial Vehicle (UAV) on the Chinese Loess Plateau},
JOURNAL = {ISPRS International Journal of Geo-Information},
VOLUME = {5},
YEAR = {2016},
NUMBER = {12},
ARTICLE-NUMBER = {238},
URL = {https://www.mdpi.com/2220-9964/5/12/238},
ISSN = {2220-9964},
ABSTRACT = {The Chinese Loess Plateau suffers from serious gully erosion induced by natural and human causes. Gully-affected areas detection is the basic work in this region for gully erosion assessment and monitoring. For the first time, an unmanned aerial vehicle (UAV) was applied to extract gully features in this region. Two typical catchments in Changwu and Ansai were selected to represent loess tableland and loess hilly regions, respectively. A high-powered quadrocopter (md4-1000) equipped with a non-metric camera was used for image acquisition. InPho and MapMatrix were applied for semi-automatic workflow including aerial triangulation and model generation. Based on the stereo-imaging and the ground control points, the highly detailed digital elevation models (DEMs) and ortho-mosaics were generated. Subsequently, an object-based approach combined with the random forest classifier was designed to detect gully-affected areas. Two experiments were conducted to investigate the influences of segmentation strategy and feature selection. Results showed that vertical and horizontal root-mean-square errors were below 0.5 and 0.2 m, respectively, which were ideal for the Loess Plateau region. The overall extraction accuracy in Changwu and Ansai achieved was 84.62% and 86.46%, respectively, which indicated the potential of the proposed workflow for extracting gully features. This study demonstrated that UAV can bridge the gap between field measurement and satellite-based remote sensing, obtaining a balance in resolution and efficiency for catchment-scale gully erosion research.},
DOI = {10.3390/ijgi5120238}
}



@Article{rs8121025,
AUTHOR = {Gevaert, Caroline M. and Persello, Claudio and Vosselman, George},
TITLE = {Optimizing Multiple Kernel Learning for the Classification of UAV Data},
JOURNAL = {Remote Sensing},
VOLUME = {8},
YEAR = {2016},
NUMBER = {12},
ARTICLE-NUMBER = {1025},
URL = {https://www.mdpi.com/2072-4292/8/12/1025},
ISSN = {2072-4292},
ABSTRACT = {Unmanned Aerial Vehicles (UAVs) are capable of providing high-quality orthoimagery and 3D information in the form of point clouds at a relatively low cost. Their increasing popularity stresses the necessity of understanding which algorithms are especially suited for processing the data obtained from UAVs. The features that are extracted from the point cloud and imagery have different statistical characteristics and can be considered as heterogeneous, which motivates the use of Multiple Kernel Learning (MKL) for classification problems. In this paper, we illustrate the utility of applying MKL for the classification of heterogeneous features obtained from UAV data through a case study of an informal settlement in Kigali, Rwanda. Results indicate that MKL can achieve a classification accuracy of 90.6%, a 5.2% increase over a standard single-kernel Support Vector Machine (SVM). A comparison of seven MKL methods indicates that linearly-weighted kernel combinations based on simple heuristics are competitive with respect to computationally-complex, non-linear kernel combination methods. We further underline the importance of utilizing appropriate feature grouping strategies for MKL, which has not been directly addressed in the literature, and we propose a novel, automated feature grouping method that achieves a high classification accuracy for various MKL methods.},
DOI = {10.3390/rs8121025}
}



@Article{rs8121029,
AUTHOR = {Lausch, Angela and Erasmi, Stefan and King, Douglas J. and Magdon, Paul and Heurich, Marco},
TITLE = {Understanding Forest Health with Remote Sensing -Part I—A Review of Spectral Traits, Processes and Remote-Sensing Characteristics},
JOURNAL = {Remote Sensing},
VOLUME = {8},
YEAR = {2016},
NUMBER = {12},
ARTICLE-NUMBER = {1029},
URL = {https://www.mdpi.com/2072-4292/8/12/1029},
ISSN = {2072-4292},
ABSTRACT = {Anthropogenic stress and disturbance of forest ecosystems (FES) has been increasing at all scales from local to global. In rapidly changing environments, in-situ terrestrial FES monitoring approaches have made tremendous progress but they are intensive and often integrate subjective indicators for forest health (FH). Remote sensing (RS) bridges the gaps of these limitations, by monitoring indicators of FH on different spatio-temporal scales, and in a cost-effective, rapid, repetitive and objective manner. In this paper, we provide an overview of the definitions of FH, discussing the drivers, processes, stress and adaptation mechanisms of forest plants, and how we can observe FH with RS. We introduce the concept of spectral traits (ST) and spectral trait variations (STV) in the context of FH monitoring and discuss the prospects, limitations and constraints. Stress, disturbances and resource limitations can cause changes in FES taxonomic, structural and functional diversity; we provide examples how the ST/STV approach can be used for monitoring these FES characteristics. We show that RS based assessments of FH indicators using the ST/STV approach is a competent, affordable, repetitive and objective technique for monitoring. Even though the possibilities for observing the taxonomic diversity of animal species is limited with RS, the taxonomy of forest tree species can be recorded with RS, even though its accuracy is subject to certain constraints. RS has proved successful for monitoring the impacts from stress on structural and functional diversity. In particular, it has proven to be very suitable for recording the short-term dynamics of stress on FH, which cannot be cost-effectively recorded using in-situ methods. This paper gives an overview of the ST/STV approach, whereas the second paper of this series concentrates on discussing in-situ terrestrial monitoring, in-situ RS approaches and RS sensors and techniques for measuring ST/STV for FH.},
DOI = {10.3390/rs8121029}
}



@Article{rs9010022,
AUTHOR = {Li, Weijia and Fu, Haohuan and Yu, Le and Cracknell, Arthur},
TITLE = {Deep Learning Based Oil Palm Tree Detection and Counting for High-Resolution Remote Sensing Images},
JOURNAL = {Remote Sensing},
VOLUME = {9},
YEAR = {2017},
NUMBER = {1},
ARTICLE-NUMBER = {22},
URL = {https://www.mdpi.com/2072-4292/9/1/22},
ISSN = {2072-4292},
ABSTRACT = {Oil palm trees are important economic crops in Malaysia and other tropical areas. The number of oil palm trees in a plantation area is important information for predicting the yield of palm oil, monitoring the growing situation of palm trees and maximizing their productivity, etc. In this paper, we propose a deep learning based framework for oil palm tree detection and counting using high-resolution remote sensing images for Malaysia. Unlike previous palm tree detection studies, the trees in our study area are more crowded and their crowns often overlap. We use a number of manually interpreted samples to train and optimize the convolutional neural network (CNN), and predict labels for all the samples in an image dataset collected through the sliding window technique. Then, we merge the predicted palm coordinates corresponding to the same palm tree into one palm coordinate and obtain the final palm tree detection results. Based on our proposed method, more than 96% of the oil palm trees in our study area can be detected correctly when compared with the manually interpreted ground truth, and this is higher than the accuracies of the other three tree detection methods used in this study.},
DOI = {10.3390/rs9010022}
}



@Article{d9010006,
AUTHOR = {Monteiro, Antonio T. and Gonçalves, João and Fernandes, Rui F. and Alves, Susana and Marcos, Bruno and Lucas, Richard and Teodoro, Ana Claúdia and Honrado, João P.},
TITLE = {Estimating Invasion Success by Non-Native Trees in a National Park Combining WorldView-2 Very High Resolution Satellite Data and Species Distribution Models},
JOURNAL = {Diversity},
VOLUME = {9},
YEAR = {2017},
NUMBER = {1},
ARTICLE-NUMBER = {6},
URL = {https://www.mdpi.com/1424-2818/9/1/6},
ISSN = {1424-2818},
ABSTRACT = {Invasion by non-native tree species is an environmental and societal challenge requiring predictive tools to assess invasion dynamics. The frequent scale mismatch between such tools and on-ground conservation is currently limiting invasion management. This study aimed to reduce these scale mismatches, assess the success of non-native tree invasion and determine the environmental factors associated to it. A hierarchical scaling approach combining species distribution models (SDMs) and satellite mapping at very high resolution (VHR) was developed to assess invasion by Acacia dealbata in Peneda-Gerês National Park, the only national park in Portugal. SDMs were first used to predict the climatically suitable areas for A. dealdata and satellite mapping with the random-forests classifier was then applied to WorldView-2 very-high resolution imagery to determine whether A. dealdata had actually colonized the predicted areas (invasion success). Environmental attributes (topographic, disturbance and canopy-related) differing between invaded and non-invaded vegetated areas were then analyzed. The SDM results indicated that most (67%) of the study area was climatically suitable for A. dealbata invasion. The onset of invasion was documented to 1905 and satellite mapping highlighted that 12.6% of study area was colonized. However, this species had only colonized 62.5% of the maximum potential range, although was registered within 55.6% of grid cells that were considerable unsuitable. Across these areas, the specific success rate of invasion was mostly below 40%, indicating that A. dealbata invasion was not dominant and effective management may still be possible. Environmental attributes related to topography (slope), canopy (normalized difference vegetation index (ndvi), land surface albedo) and disturbance (historical burnt area) differed between invaded and non-invaded vegetated area, suggesting that landscape attributes may alter at specific locations with Acacia invasion. Fine-scale spatial-explicit estimation of invasion success combining SDM predictions with VHR invasion mapping allowed the scale mismatch between predictions of invasion dynamics and on-ground conservation decision making for invasion management to be reduced. Locations with greater potential to suppress invasions could also be defined. Uncertainty in the invasion mapping needs to be accounted for in the interpretation of the results.},
DOI = {10.3390/d9010006}
}



@Article{rs9020100,
AUTHOR = {Bejiga, Mesay Belete and Zeggada, Abdallah and Nouffidj, Abdelhamid and Melgani, Farid},
TITLE = {A Convolutional Neural Network Approach for Assisting Avalanche Search and Rescue Operations with UAV Imagery},
JOURNAL = {Remote Sensing},
VOLUME = {9},
YEAR = {2017},
NUMBER = {2},
ARTICLE-NUMBER = {100},
URL = {https://www.mdpi.com/2072-4292/9/2/100},
ISSN = {2072-4292},
ABSTRACT = {Following an avalanche, one of the factors that affect victims’ chance of survival is the speed with which they are located and dug out. Rescue teams use techniques like trained rescue dogs and electronic transceivers to locate victims. However, the resources and time required to deploy rescue teams are major bottlenecks that decrease a victim’s chance of survival. Advances in the field of Unmanned Aerial Vehicles (UAVs) have enabled the use of flying robots equipped with sensors like optical cameras to assess the damage caused by natural or manmade disasters and locate victims in the debris. In this paper, we propose assisting avalanche search and rescue (SAR) operations with UAVs fitted with vision cameras. The sequence of images of the avalanche debris captured by the UAV is processed with a pre-trained Convolutional Neural Network (CNN) to extract discriminative features. A trained linear Support Vector Machine (SVM) is integrated at the top of the CNN to detect objects of interest. Moreover, we introduce a pre-processing method to increase the detection rate and a post-processing method based on a Hidden Markov Model to improve the prediction performance of the classifier. Experimental results conducted on two different datasets at different levels of resolution show that the detection performance increases with an increase in resolution, while the computation time increases. Additionally, they also suggest that a significant decrease in processing time can be achieved thanks to the pre-processing step.},
DOI = {10.3390/rs9020100}
}



@Article{s17020235,
AUTHOR = {Sharma, Ram C. and Tateishi, Ryutaro and Hara, Keitarou and Nguyen, Hoan Thanh and Gharechelou, Saeid and Nguyen, Luong Viet},
TITLE = {Earthquake Damage Visualization (EDV) Technique for the Rapid Detection of Earthquake-Induced Damages Using SAR Data},
JOURNAL = {Sensors},
VOLUME = {17},
YEAR = {2017},
NUMBER = {2},
ARTICLE-NUMBER = {235},
URL = {https://www.mdpi.com/1424-8220/17/2/235},
ISSN = {1424-8220},
ABSTRACT = {The damage of buildings and manmade structures, where most of human activities occur, is the major cause of casualties of from earthquakes. In this paper, an improved technique, Earthquake Damage Visualization (EDV) is presented for the rapid detection of earthquake damage using the Synthetic Aperture Radar (SAR) data. The EDV is based on the pre-seismic and co-seismic coherence change method. The normalized difference between the pre-seismic and co-seismic coherences, and vice versa, are used to calculate the forward (from pre-seismic to co-seismic) and backward (from co-seismic to pre-seismic) change parameters, respectively. The backward change parameter is added to visualize the retrospective changes caused by factors other than the earthquake. The third change-free parameter uses the average values of the pre-seismic and co-seismic coherence maps. These three change parameters were ultimately merged into the EDV as an RGB (Red, Green, and Blue) composite imagery. The EDV could visualize the earthquake damage efficiently using Horizontal transmit and Horizontal receive (HH), and Horizontal transmit and Vertical receive (HV) polarizations data from the Advanced Land Observing Satellite-2 (ALOS-2). Its performance was evaluated in the Kathmandu Valley, which was hit severely by the 2015 Nepal Earthquake. The cross-validation results showed that the EDV is more sensitive to the damaged buildings than the existing method. The EDV could be used for building damage detection in other earthquakes as well.},
DOI = {10.3390/s17020235}
}



@Article{rs9020129,
AUTHOR = {Lausch, Angela and Erasmi, Stefan and King, Douglas J. and Magdon, Paul and Heurich, Marco},
TITLE = {Understanding Forest Health with Remote Sensing-Part II—A Review of Approaches and Data Models},
JOURNAL = {Remote Sensing},
VOLUME = {9},
YEAR = {2017},
NUMBER = {2},
ARTICLE-NUMBER = {129},
URL = {https://www.mdpi.com/2072-4292/9/2/129},
ISSN = {2072-4292},
ABSTRACT = {Stress in forest ecosystems (FES) occurs as a result of land-use intensification, disturbances, resource limitations or unsustainable management, causing changes in forest health (FH) at various scales from the local to the global scale. Reactions to such stress depend on the phylogeny of forest species or communities and the characteristics of their impacting drivers and processes. There are many approaches to monitor indicators of FH using in-situ forest inventory and experimental studies, but they are generally limited to sample points or small areas, as well as being time- and labour-intensive. Long-term monitoring based on forest inventories provides valuable information about changes and trends of FH. However, abrupt short-term changes cannot sufficiently be assessed through in-situ forest inventories as they usually have repetition periods of multiple years. Furthermore, numerous FH indicators monitored in in-situ surveys are based on expert judgement. Remote sensing (RS) technologies offer means to monitor FH indicators in an effective, repetitive and comparative way. This paper reviews techniques that are currently used for monitoring, including close-range RS, airborne and satellite approaches. The implementation of optical, RADAR and LiDAR RS-techniques to assess spectral traits/spectral trait variations (ST/STV) is described in detail. We found that ST/STV can be used to record indicators of FH based on RS. Therefore, the ST/STV approach provides a framework to develop a standardized monitoring concept for FH indicators using RS techniques that is applicable to future monitoring programs. It is only through linking in-situ and RS approaches that we will be able to improve our understanding of the relationship between stressors, and the associated spectral responses in order to develop robust FH indicators.},
DOI = {10.3390/rs9020129}
}



@Article{rs9020159,
AUTHOR = {Su, Lihong and Gibeaut, James},
TITLE = {Using UAS Hyperspatial RGB Imagery for Identifying Beach Zones along the South Texas Coast},
JOURNAL = {Remote Sensing},
VOLUME = {9},
YEAR = {2017},
NUMBER = {2},
ARTICLE-NUMBER = {159},
URL = {https://www.mdpi.com/2072-4292/9/2/159},
ISSN = {2072-4292},
ABSTRACT = {Shoreline information is fundamental for understanding coastal dynamics and for implementing environmental policy. The analysis of shoreline variability usually uses a group of shoreline indicators visibly discernible in coastal imagery, such as the seaward vegetation line, wet beach/dry beach line, and instantaneous water line. These indicators partition a beach into four zones: vegetated land, dry sand or debris, wet sand, and water. Unmanned aircraft system (UAS) remote sensing that can acquire imagery with sub-decimeter pixel size provides opportunities to map these four beach zones. This paper attempts to delineate four beach zones based on UAS hyperspatial RGB (Red, Green, and Blue) imagery, namely imagery of sub-decimeter pixel size, and feature textures. Besides the RGB images, this paper also uses USGS (the United States Geological Survey) Munsell HSV (Hue, Saturation, and Value) and CIELUV (the CIE 1976 (L*, u*, v*) color space) images transformed from an RGB image. The four beach zones are identified based on the Gray Level Co-Occurrence Matrix (GLCM) and Local Binary Pattern (LBP) textures. Experiments were conducted with South Padre Island photos acquired by a Nikon D80 camera mounted on the US-16 UAS during March 2014. The results show that USGS Munsell hue can separate land and water reliably. GLCM and LBP textures can slightly improve classification accuracies by both unsupervised and supervised classification techniques. The experiments also indicate that we could reach acceptable results on different photos while using training data from another photo for site-specific UAS remote sensing. The findings imply that parallel processing of classification is feasible.},
DOI = {10.3390/rs9020159}
}



@Article{ijgi6020051,
AUTHOR = {Ma, Lei and Fu, Tengyu and Blaschke, Thomas and Li, Manchun and Tiede, Dirk and Zhou, Zhenjin and Ma, Xiaoxue and Chen, Deliang},
TITLE = {Evaluation of Feature Selection Methods for Object-Based Land Cover Mapping of Unmanned Aerial Vehicle Imagery Using Random Forest and Support Vector Machine Classifiers},
JOURNAL = {ISPRS International Journal of Geo-Information},
VOLUME = {6},
YEAR = {2017},
NUMBER = {2},
ARTICLE-NUMBER = {51},
URL = {https://www.mdpi.com/2220-9964/6/2/51},
ISSN = {2220-9964},
ABSTRACT = {The increased feature space available in object-based classification environments (e.g., extended spectral feature sets per object, shape properties, or textural features) has a high potential of improving classifications. However, the availability of a large number of derived features per segmented object can also lead to a time-consuming and subjective process of optimizing the feature subset. The objectives of this study are to evaluate the effect of the advanced feature selection methods of popular supervised classifiers (Support Vector Machines (SVM) and Random Forest (RF)) for the example of object-based mapping of an agricultural area using Unmanned Aerial Vehicle (UAV) imagery, in order to optimize their usage for object-based agriculture pattern recognition tasks. In this study, several advanced feature selection methods were divided into both types of classifiers (SVM and RF) to conduct further evaluations using five feature-importance-evaluation methods and three feature-subset-evaluation methods. A visualization method was used to measure the change pattern of mean classification accuracy with the increase of features used, and a two-tailed t-test was used to determine the difference between two population means for both repeated ten classification accuracies. This study mainly contribute to the uncertainty analysis of feature selection for object-based classification instead of the per-pixel method. The results highlight that the RF classifier is relatively insensitive to the number of input features, even for a small training set size, whereby a negative impact of feature set size on the classification accuracy of the SVM classifier was observed. Overall, the SVM Recursive Feature Elimination (SVM-RFE) seems to be an appropriate method for both groups of classifiers, while the Correlation-based Feature Selection (CFS) is the best feature-subset-evaluation method. Most importantly, this study verified that feature selection for both classifiers is crucial for the evolving field of Object-based Image Analysis (OBIA): It is highly advisable for feature selection to be performed before object-based classification, even though an adverse impact could sometimes be observed from the wrapper methods.},
DOI = {10.3390/ijgi6020051}
}



@Article{rs9020171,
AUTHOR = {Crommelinck, Sophie and Bennett, Rohan and Gerke, Markus and Yang, Michael Ying and Vosselman, George},
TITLE = {Contour Detection for UAV-Based Cadastral Mapping},
JOURNAL = {Remote Sensing},
VOLUME = {9},
YEAR = {2017},
NUMBER = {2},
ARTICLE-NUMBER = {171},
URL = {https://www.mdpi.com/2072-4292/9/2/171},
ISSN = {2072-4292},
ABSTRACT = {Unmanned aerial vehicles (UAVs) provide a flexible and low-cost solution for the acquisition of high-resolution data. The potential of high-resolution UAV imagery to create and update cadastral maps is being increasingly investigated. Existing procedures generally involve substantial fieldwork and many manual processes. Arguably, multiple parts of UAV-based cadastral mapping workflows could be automated. Specifically, as many cadastral boundaries coincide with visible boundaries, they could be extracted automatically using image analysis methods. This study investigates the transferability of gPb contour detection, a state-of-the-art computer vision method, to remotely sensed UAV images and UAV-based cadastral mapping. Results show that the approach is transferable to UAV data and automated cadastral mapping: object contours are comprehensively detected at completeness and correctness rates of up to 80%. The detection quality is optimal when the entire scene is covered with one orthoimage, due to the global optimization of gPb contour detection. However, a balance between high completeness and correctness is hard to achieve, so a combination with area-based segmentation and further object knowledge is proposed. The localization quality exhibits the usual dependency on ground resolution. The approach has the potential to accelerate the process of general boundary delineation during the creation and updating of cadastral maps.},
DOI = {10.3390/rs9020171}
}



@Article{rs9030185,
AUTHOR = {Nevalainen, Olli and Honkavaara, Eija and Tuominen, Sakari and Viljanen, Niko and Hakala, Teemu and Yu, Xiaowei and Hyyppä, Juha and Saari, Heikki and Pölönen, Ilkka and Imai, Nilton N. and Tommaselli, Antonio M. G.},
TITLE = {Individual Tree Detection and Classification with UAV-Based Photogrammetric Point Clouds and Hyperspectral Imaging},
JOURNAL = {Remote Sensing},
VOLUME = {9},
YEAR = {2017},
NUMBER = {3},
ARTICLE-NUMBER = {185},
URL = {https://www.mdpi.com/2072-4292/9/3/185},
ISSN = {2072-4292},
ABSTRACT = {Small unmanned aerial vehicle (UAV) based remote sensing is a rapidly evolving technology. Novel sensors and methods are entering the market, offering completely new possibilities to carry out remote sensing tasks. Three-dimensional (3D) hyperspectral remote sensing is a novel and powerful technology that has recently become available to small UAVs. This study investigated the performance of UAV-based photogrammetry and hyperspectral imaging in individual tree detection and tree species classification in boreal forests. Eleven test sites with 4151 reference trees representing various tree species and developmental stages were collected in June 2014 using a UAV remote sensing system equipped with a frame format hyperspectral camera and an RGB camera in highly variable weather conditions. Dense point clouds were measured photogrammetrically by automatic image matching using high resolution RGB images with a 5 cm point interval. Spectral features were obtained from the hyperspectral image blocks, the large radiometric variation of which was compensated for by using a novel approach based on radiometric block adjustment with the support of in-flight irradiance observations. Spectral and 3D point cloud features were used in the classification experiment with various classifiers. The best results were obtained with Random Forest and Multilayer Perceptron (MLP) which both gave 95% overall accuracies and an F-score of 0.93. Accuracy of individual tree identification from the photogrammetric point clouds varied between 40% and 95%, depending on the characteristics of the area. Challenges in reference measurements might also have reduced these numbers. Results were promising, indicating that hyperspectral 3D remote sensing was operational from a UAV platform even in very difficult conditions. These novel methods are expected to provide a powerful tool for automating various environmental close-range remote sensing tasks in the very near future.},
DOI = {10.3390/rs9030185}
}



@Article{su9030353,
AUTHOR = {Adeyemi, Olutobi and Grove, Ivan and Peets, Sven and Norton, Tomas},
TITLE = {Advanced Monitoring and Management Systems for Improving Sustainability in Precision Irrigation},
JOURNAL = {Sustainability},
VOLUME = {9},
YEAR = {2017},
NUMBER = {3},
ARTICLE-NUMBER = {353},
URL = {https://www.mdpi.com/2071-1050/9/3/353},
ISSN = {2071-1050},
ABSTRACT = {Globally, the irrigation of crops is the largest consumptive user of fresh water. Water scarcity is increasing worldwide, resulting in tighter regulation of its use for agriculture. This necessitates the development of irrigation practices that are more efficient in the use of water but do not compromise crop quality and yield. Precision irrigation already achieves this goal, in part. The goal of precision irrigation is to accurately supply the crop water need in a timely manner and as spatially uniformly as possible. However, to maximize the benefits of precision irrigation, additional technologies need to be enabled and incorporated into agriculture. This paper discusses how incorporating adaptive decision support systems into precision irrigation management will enable significant advances in increasing the efficiency of current irrigation approaches. From the literature review, it is found that precision irrigation can be applied in achieving the environmental goals related to sustainability. The demonstrated economic benefits of precision irrigation in field-scale crop production is however minimal. It is argued that a proper combination of soil, plant and weather sensors providing real-time data to an adaptive decision support system provides an innovative platform for improving sustainability in irrigated agriculture. The review also shows that adaptive decision support systems based on model predictive control are able to adequately account for the time-varying nature of the soil–plant–atmosphere system while considering operational limitations and agronomic objectives in arriving at optimal irrigation decisions. It is concluded that significant improvements in crop yield and water savings can be achieved by incorporating model predictive control into precision irrigation decision support tools. Further improvements in water savings can also be realized by including deficit irrigation as part of the overall irrigation management strategy. Nevertheless, future research is needed for identifying crop response to regulated water deficits, developing improved soil moisture and plant sensors, and developing self-learning crop simulation frameworks that can be applied to evaluate adaptive decision support strategies related to irrigation.},
DOI = {10.3390/su9030353}
}



@Article{rs9030248,
AUTHOR = {Campos-Taberner, Manuel and García-Haro, Francisco Javier and Camps-Valls, Gustau and Grau-Muedra, Gonçal and Nutini, Francesco and Busetto, Lorenzo and Katsantonis, Dimitrios and Stavrakoudis, Dimitris and Minakou, Chara and Gatti, Luca and Barbieri, Massimo and Holecz, Francesco and Stroppiana, Daniela and Boschetti, Mirco},
TITLE = {Exploitation of SAR and Optical Sentinel Data to Detect Rice Crop and Estimate Seasonal Dynamics of Leaf Area Index},
JOURNAL = {Remote Sensing},
VOLUME = {9},
YEAR = {2017},
NUMBER = {3},
ARTICLE-NUMBER = {248},
URL = {https://www.mdpi.com/2072-4292/9/3/248},
ISSN = {2072-4292},
ABSTRACT = {This paper presents and evaluates multitemporal LAI estimates derived from Sentinel-2A data on rice cultivated area identified using time series of Sentinel-1A images over the main European rice districts for the 2016 crop season. This study combines the information conveyed by Sentinel-1A and Sentinel-2A into a high-resolution LAI retrieval chain. Rice crop was detected using an operational multi-temporal rule-based algorithm, and LAI estimates were obtained by inverting the PROSAIL radiative transfer model with Gaussian process regression. Direct validation was performed with in situ LAI measurements acquired in coordinated field campaigns in three countries (Italy, Spain and Greece). Results showed high consistency between estimates and ground measurements, revealing high correlations (R2 &gt; 0.93) and good accuracies (RMSE &lt; 0.83, rRMSEm &lt; 23.6% and rRMSEr &lt; 16.6%) in all cases. Sentinel-2A estimates were compared with Landsat-8 showing high spatial consistency between estimates over the three areas. The possibility to exploit seasonally-updated crop mask exploiting Sentinel-1A data and the temporal consistency between Sentinel-2A and Landsat-7/8 LAI time series demonstrates the feasibility of deriving operationally high spatial-temporal decametric multi-sensor LAI time series useful for crop monitoring.},
DOI = {10.3390/rs9030248}
}



@Article{rs9030268,
AUTHOR = {Poblete-Echeverría, Carlos and Olmedo, Guillermo Federico and Ingram, Ben and Bardeen, Matthew},
TITLE = {Detection and Segmentation of Vine Canopy in Ultra-High Spatial Resolution RGB Imagery Obtained from Unmanned Aerial Vehicle (UAV): A Case Study in a Commercial Vineyard},
JOURNAL = {Remote Sensing},
VOLUME = {9},
YEAR = {2017},
NUMBER = {3},
ARTICLE-NUMBER = {268},
URL = {https://www.mdpi.com/2072-4292/9/3/268},
ISSN = {2072-4292},
ABSTRACT = {The use of Unmanned Aerial Vehicles (UAVs) in viticulture permits the capture of aerial Red-Green-Blue (RGB) images with an ultra-high spatial resolution. Recent studies have demonstrated that RGB images can be used to monitor spatial variability of vine biophysical parameters. However, for estimating these parameters, accurate and automated segmentation methods are required to extract relevant information from RGB images. Manual segmentation of aerial images is a laborious and time-consuming process. Traditional classification methods have shown satisfactory results in the segmentation of RGB images for diverse applications and surfaces, however, in the case of commercial vineyards, it is necessary to consider some particularities inherent to canopy size in the vertical trellis systems (VSP) such as shadow effect and different soil conditions in inter-rows (mixed information of soil and weeds). Therefore, the objective of this study was to compare the performance of four classification methods (K-means, Artificial Neural Networks (ANN), Random Forest (RForest) and Spectral Indices (SI)) to detect canopy in a vineyard trained on VSP. Six flights were carried out from post-flowering to harvest in a commercial vineyard cv. Carménère using a low-cost UAV equipped with a conventional RGB camera. The results show that the ANN and the simple SI method complemented with the Otsu method for thresholding presented the best performance for the detection of the vine canopy with high overall accuracy values for all study days. Spectral indices presented the best performance in the detection of Plant class (Vine canopy) with an overall accuracy of around 0.99. However, considering the performance pixel by pixel, the Spectral indices are not able to discriminate between Soil and Shadow class. The best performance in the classification of three classes (Plant, Soil, and Shadow) of vineyard RGB images, was obtained when the SI values were used as input data in trained methods (ANN and RForest), reaching overall accuracy values around 0.98 with high sensitivity values for the three classes.},
DOI = {10.3390/rs9030268}
}



@Article{rs9040306,
AUTHOR = {Duan, Fuzhou and Wan, Yangchun and Deng, Lei},
TITLE = {A Novel Approach for Coarse-to-Fine Windthrown Tree Extraction Based on Unmanned Aerial Vehicle Images},
JOURNAL = {Remote Sensing},
VOLUME = {9},
YEAR = {2017},
NUMBER = {4},
ARTICLE-NUMBER = {306},
URL = {https://www.mdpi.com/2072-4292/9/4/306},
ISSN = {2072-4292},
ABSTRACT = {Surveys of windthrown trees, resulting from hurricanes and other types of natural disasters, are an important component of agricultural insurance, forestry statistics, and ecological monitoring. Aerial images are commonly used to determine the total area or number of downed trees, but conventional methods suffer from two primary issues: misclassification of windthrown trees due to the interference from other objects or artifacts, and poor extraction resolution when trunk diameters are small. The objective of this study is to develop a coarse-to-fine extraction technique for individual windthrown trees that reduces the effects of these common flaws. The developed method was tested using UAV imagery collected over rubber plantations on Hainan Island after the Nesat typhoon in China on 19 October 2011. First, a coarse extraction of the affected area was performed by analyzing the image spectrum and textural characteristics. A thinning algorithm was then used to simplify downed trees into skeletal structures. Finally, fine extraction of individual trees was achieved using a line detection algorithm. The completeness of windthrown trees in the study area was 75.7% and the correctness was 92.5%. While similar values have been reported in other studies, they often include constraints, such as tree height. This technique is proposed to be a more feasible extraction algorithm as it is capable of achieving low commission errors across a broad range of tree heights and sizes. As such, it is a viable option for extraction of windthrown trees with a small trunk diameter.},
DOI = {10.3390/rs9040306}
}



@Article{rs9040309,
AUTHOR = {Yuan, Huanhuan and Yang, Guijun and Li, Changchun and Wang, Yanjie and Liu, Jiangang and Yu, Haiyang and Feng, Haikuan and Xu, Bo and Zhao, Xiaoqing and Yang, Xiaodong},
TITLE = {Retrieving Soybean Leaf Area Index from Unmanned Aerial Vehicle Hyperspectral Remote Sensing: Analysis of RF, ANN, and SVM Regression Models},
JOURNAL = {Remote Sensing},
VOLUME = {9},
YEAR = {2017},
NUMBER = {4},
ARTICLE-NUMBER = {309},
URL = {https://www.mdpi.com/2072-4292/9/4/309},
ISSN = {2072-4292},
ABSTRACT = {Leaf area index (LAI) is an important indicator of plant growth and yield that can be monitored by remote sensing. Several models were constructed using datasets derived from SRS and STR sampling methods to determine the optimal model for soybean (multiple strains) LAI inversion for the whole crop growth period and a single growth period. Random forest (RF), artificial neural network (ANN), and support vector machine (SVM) regression models were compared with a partial least-squares regression (PLS) model. The RF model yielded the highest precision, accuracy, and stability with V-R2, SDR2, V-RMSE, and SDRMSE values of 0.741, 0.031, 0.106, and 0.005, respectively, over the whole growth period based on STR sampling. The ANN model had the highest precision, accuracy, and stability (0.452, 0.132, 0.086, and 0.009, respectively) over a single growth phase based on STR sampling. The precision, accuracy, and stability of the RF, ANN, and SVM models were improved by inclusion of STR sampling. The RF model is suitable for estimating LAI when sample plots and variation are relatively large (i.e., the whole growth period or more than one growth period). The ANN model is more appropriate for estimating LAI when sample plots and variation are relatively low (i.e., a single growth period).},
DOI = {10.3390/rs9040309}
}



@Article{rs9040312,
AUTHOR = {Ammour, Nassim and Alhichri, Haikel and Bazi, Yakoub and Benjdira, Bilel and Alajlan, Naif and Zuair, Mansour},
TITLE = {Deep Learning Approach for Car Detection in UAV Imagery},
JOURNAL = {Remote Sensing},
VOLUME = {9},
YEAR = {2017},
NUMBER = {4},
ARTICLE-NUMBER = {312},
URL = {https://www.mdpi.com/2072-4292/9/4/312},
ISSN = {2072-4292},
ABSTRACT = {This paper presents an automatic solution to the problem of detecting and counting cars in unmanned aerial vehicle (UAV) images. This is a challenging task given the very high spatial resolution of UAV images (on the order of a few centimetres) and the extremely high level of detail, which require suitable automatic analysis methods. Our proposed method begins by segmenting the input image into small homogeneous regions, which can be used as candidate locations for car detection. Next, a window is extracted around each region, and deep learning is used to mine highly descriptive features from these windows. We use a deep convolutional neural network (CNN) system that is already pre-trained on huge auxiliary data as a feature extraction tool, combined with a linear support vector machine (SVM) classifier to classify regions into “car” and “no-car” classes. The final step is devoted to a fine-tuning procedure which performs morphological dilation to smooth the detected regions and fill any holes. In addition, small isolated regions are analysed further using a few sliding rectangular windows to locate cars more accurately and remove false positives. To evaluate our method, experiments were conducted on a challenging set of real UAV images acquired over an urban area. The experimental results have proven that the proposed method outperforms the state-of-the-art methods, both in terms of accuracy and computational time.},
DOI = {10.3390/rs9040312}
}



@Article{rs9040333,
AUTHOR = {Chen, Tao and Trinder, John C. and Niu, Ruiqing},
TITLE = {Object-Oriented Landslide Mapping Using ZY-3 Satellite Imagery, Random Forest and Mathematical Morphology, for the Three-Gorges Reservoir, China},
JOURNAL = {Remote Sensing},
VOLUME = {9},
YEAR = {2017},
NUMBER = {4},
ARTICLE-NUMBER = {333},
URL = {https://www.mdpi.com/2072-4292/9/4/333},
ISSN = {2072-4292},
ABSTRACT = {Landslide mapping (LM) has recently become an important research topic in remote sensing and geohazards. The area near the Three Gorges Reservoir (TGR) along the Yangtze River in China is one of the most landslide-prone regions in the world, and the area has suffered widespread and significant landslide events in recent years. In our study, an object-oriented landslide mapping (OOLM) framework was proposed for reliable and accurate LM from ‘ZY-3’ high spatial resolution (HSR) satellite images. The framework was based on random forests (RF) and mathematical morphology (MM). RF was first applied as an object feature information reduction tool to identify the significant features for describing landslides, and it was then combined with MM to map the landslides. Three object-feature domains were extracted from the ‘ZY-3’ HSR data: layer information, texture, and geometric features. A total group of 124 features and 24 landslides were used as inputs to determine the landslide boundaries and evaluate the landslide classification accuracy. The results showed that: (1) the feature selection (FS) method had a positive influence on effective landslide mapping; (2) by dividing the data into two sets, training sets which consisted of 20% of the landslide objects (OLS) and non-landslide objects (ONLS), and test sets which consisted of the remaining 80% of the OLS and ONLS, the selected feature subsets were combined for training to obtain an overall classification accuracy of 93.3% ± 0.12% of the test sets; (3) four MM operations based on closing and opening were used to improve the performance of the RF classification. Seven accuracy evaluation indices were used to compare the accuracies of these landslide mapping methods. Finally, the landslide inventory maps were obtained. Based on its efficiency and accuracy, the proposed approach can be employed for rapid response to natural hazards in the Three Gorges area.},
DOI = {10.3390/rs9040333}
}



@Article{electronics6020031,
AUTHOR = {Manrique, Pedro D. and Johnson, D. Dylan and Johnson, Neil F.},
TITLE = {Using Competition to Control Congestion in Autonomous Drone Systems},
JOURNAL = {Electronics},
VOLUME = {6},
YEAR = {2017},
NUMBER = {2},
ARTICLE-NUMBER = {31},
URL = {https://www.mdpi.com/2079-9292/6/2/31},
ISSN = {2079-9292},
ABSTRACT = {With the number and variety of commercial drones and UAVs (Unmanned Aerial Vehicles) set to escalate, there will be high future demands on popular regions of airspace and communication bandwidths. This raises safety concerns and hence heightens the need for a generic quantitative understanding of the real-time dynamics of multi-drone populations. Here, we explain how a simple system design built around system-level competition, as opposed to cooperation, can be used to control and ultimately reduce the fluctuations that ordinarily arise in such congestion situations, while simultaneously keeping the on-board processing requirements minimal. These benefits naturally arise from the collective competition to choose the less crowded option, using only previous outcomes and built-in algorithms. We provide explicit closed-form formulae that are applicable to any number of airborne drones N, and which show that the necessary on-board processing increases slower than N as N increases. This design therefore offers operational advantages over traditional cooperative schemes that require drone-to-drone communications that scale like     N 2    , and also over optimization and control schemes that do not easily scale up to general N. In addition to populations of drones, the same mathematical analysis can be used to describe more complex individual drones that feature N adaptive sensor/actuator units.},
DOI = {10.3390/electronics6020031}
}



@Article{rs9040376,
AUTHOR = {Zhuo, Xiangyu and Koch, Tobias and Kurz, Franz and Fraundorfer, Friedrich and Reinartz, Peter},
TITLE = {Automatic UAV Image Geo-Registration by Matching UAV Images to Georeferenced Image Data},
JOURNAL = {Remote Sensing},
VOLUME = {9},
YEAR = {2017},
NUMBER = {4},
ARTICLE-NUMBER = {376},
URL = {https://www.mdpi.com/2072-4292/9/4/376},
ISSN = {2072-4292},
ABSTRACT = {Recent years have witnessed the fast development of UAVs (unmanned aerial vehicles). As an alternative to traditional image acquisition methods, UAVs bridge the gap between terrestrial and airborne photogrammetry and enable flexible acquisition of high resolution images. However, the georeferencing accuracy of UAVs is still limited by the low-performance on-board GNSS and INS. This paper investigates automatic geo-registration of an individual UAV image or UAV image blocks by matching the UAV image(s) with a previously taken georeferenced image, such as an individual aerial or satellite image with a height map attached or an aerial orthophoto with a DSM (digital surface model) attached. As the biggest challenge for matching UAV and aerial images is in the large differences in scale and rotation, we propose a novel feature matching method for nadir or slightly tilted images. The method is comprised of a dense feature detection scheme, a one-to-many matching strategy and a global geometric verification scheme. The proposed method is able to find thousands of valid matches in cases where SIFT and ASIFT fail. Those matches can be used to geo-register the whole UAV image block towards the reference image data. When the reference images offer high georeferencing accuracy, the UAV images can also be geolocalized in a global coordinate system. A series of experiments involving different scenarios was conducted to validate the proposed method. The results demonstrate that our approach achieves not only decimeter-level registration accuracy, but also comparable global accuracy as the reference images.},
DOI = {10.3390/rs9040376}
}



@Article{aerospace4020027,
AUTHOR = {Salamat, Babak and Tonello, Andrea M.},
TITLE = {Stochastic Trajectory Generation Using Particle Swarm Optimization for Quadrotor Unmanned Aerial Vehicles (UAVs)},
JOURNAL = {Aerospace},
VOLUME = {4},
YEAR = {2017},
NUMBER = {2},
ARTICLE-NUMBER = {27},
URL = {https://www.mdpi.com/2226-4310/4/2/27},
ISSN = {2226-4310},
ABSTRACT = {The aim of this paper is to provide a realistic stochastic trajectory generation method for unmanned aerial vehicles that offers a tool for the emulation of trajectories in typical flight scenarios. Three scenarios are defined in this paper. The trajectories for these scenarios are implemented with quintic B-splines that grant smoothness in the second-order derivatives of Euler angles and accelerations. In order to tune the parameters of the quintic B-spline in the search space, a multi-objective optimization method called particle swarm optimization (PSO) is used. The proposed technique satisfies the constraints imposed by the configuration of the unmanned aerial vehicle (UAV). Further particular constraints can be introduced such as: obstacle avoidance, speed limitation, and actuator torque limitations due to the practical feasibility of the trajectories. Finally, the standard rapidly-exploring random tree (RRT*) algorithm, the standard (A*) algorithm and the genetic algorithm (GA) are simulated to make a comparison with the proposed algorithm in terms of execution time and effectiveness in finding the minimum length trajectory.},
DOI = {10.3390/aerospace4020027}
}



@Article{rs9050488,
AUTHOR = {Wei, Chuanwen and Huang, Jingfeng and Mansaray, Lamin R. and Li, Zhenhai and Liu, Weiwei and Han, Jiahui},
TITLE = {Estimation and Mapping of Winter Oilseed Rape LAI from High Spatial Resolution Satellite Data Based on a Hybrid Method},
JOURNAL = {Remote Sensing},
VOLUME = {9},
YEAR = {2017},
NUMBER = {5},
ARTICLE-NUMBER = {488},
URL = {https://www.mdpi.com/2072-4292/9/5/488},
ISSN = {2072-4292},
ABSTRACT = {Leaf area index (LAI) is a key input in models describing biosphere processes and has widely been used in monitoring crop growth and in yield estimation. In this study, a hybrid inversion method is developed to estimate LAI values of winter oilseed rape during growth using high spatial resolution optical satellite data covering a test site located in southeast China. Based on PROSAIL (coupling of PROSPECT and SAIL) simulation datasets, nine vegetation indices (VIs) were analyzed to identify the optimal independent variables for estimating LAI values. The optimal VIs were selected using curve fitting methods and the random forest algorithm. Hybrid inversion models were then built to determine the relationships between optimal simulated VIs and LAI values (generated by the PROSAIL model) using modeling methods, including curve fitting, k-nearest neighbor (kNN), and random forest regression (RFR). Finally, the mapping and estimation of winter oilseed rape LAI using reflectance obtained from Pleiades-1A, WorldView-3, SPOT-6, and WorldView-2 were implemented using the inversion method and the LAI estimation accuracy was validated using ground-measured datasets acquired during the 2014–2015 growing season. Our study indicates that based on the estimation results derived from different datasets, RFR is the optimal modeling algorithm amidst curve fitting and kNN with R2 &gt; 0.954 and RMSE &lt;0.218. Using the optimal VIs, the remote sensing-based mapping of winter oilseed rape LAI yielded an accuracy of R2 = 0.520 and RMSE = 0.923 (RRMSE = 93.7%). These results have demonstrated the potential operational applicability of the hybrid method proposed in this study for the mapping and retrieval of winter oilseed rape LAI values at field scales using multi-source and high spatial resolution optical remote sensing datasets. Details provided by this high resolution mapping cannot be easily discerned at coarser mapping scales and over larger spatial extents that usually employ lower resolution satellite images. Our study therefore has significant implications for field crop monitoring at local scales, providing relevant data for agronomic practices and precision agriculture.},
DOI = {10.3390/rs9050488}
}



@Article{rs9050492,
AUTHOR = {Ciriza, Raquel and Sola, Ion and Albizua, Lourdes and Álvarez-Mozos, Jesús and González-Audícana, María},
TITLE = {Automatic Detection of Uprooted Orchards Based on Orthophoto Texture Analysis},
JOURNAL = {Remote Sensing},
VOLUME = {9},
YEAR = {2017},
NUMBER = {5},
ARTICLE-NUMBER = {492},
URL = {https://www.mdpi.com/2072-4292/9/5/492},
ISSN = {2072-4292},
ABSTRACT = {Permanent crops, such as olive groves, vineyards and fruit trees, are important in European agriculture because of their spatial and economic relevance. Agricultural geographical databases (AGDBs) are commonly used by public bodies to gain knowledge of the extension covered by these crops and to manage related agricultural subsidies and inspections. However, the updating of these databases is mostly based on photointerpretation, and thus keeping this information up-to-date is very costly in terms of time and money. This paper describes a methodology for automatic detection of uprooted orchards (parcels where fruit trees have been eliminated) based on the textural classification of orthophotos with a spatial resolution of 0.25 m. The textural features used for this classification were derived from the grey level co-occurrence matrix (GLCM) and wavelet transform, and were selected through principal components (PCA) and separability analyses. Next, a Discriminant Analysis classification algorithm was used to detect uprooted orchards. Entropy, contrast and correlation were found to be the most informative textural features obtained from the co-occurrence matrix. The minimum and standard deviation in plane 3 were the selected features based on wavelet transform. The classification based on these features achieved a true positive rate (TPR) of over 80% and an accuracy (A) of over 88%. As a result, this methodology enabled reducing the number of fields to photointerpret by 60–85%, depending on the membership threshold value selected. The proposed approach could be easily adopted by different stakeholders and could increase significantly the efficiency of agricultural database updating tasks.},
DOI = {10.3390/rs9050492}
}



@Article{ijgi6060157,
AUTHOR = {Zhao, Hanqing and Fang, Xuan and Ding, Hu and Josef, Strobl and Xiong, Liyang and Na, Jiaming and Tang, Guoan},
TITLE = {Extraction of Terraces on the Loess Plateau from High-Resolution DEMs and Imagery Utilizing Object-Based Image Analysis},
JOURNAL = {ISPRS International Journal of Geo-Information},
VOLUME = {6},
YEAR = {2017},
NUMBER = {6},
ARTICLE-NUMBER = {157},
URL = {https://www.mdpi.com/2220-9964/6/6/157},
ISSN = {2220-9964},
ABSTRACT = {Abstract: Terraces are typical artificial landforms on the Loess Plateau, with ecological functions in water and soil conservation, agricultural production, and biodiversity. Recording the spatial distribution of terraces is the basis of monitoring their extent and understanding their ecological effects. The current terrace extraction method mainly relies on high-resolution imagery, but its accuracy is limited due to vegetation coverage distorting the features of terraces in imagery. High-resolution topographic data reflecting the morphology of true terrace surfaces are needed. Terraces extraction on the Loess Plateau is challenging because of the complex terrain and diverse vegetation after the implementation of “vegetation recovery”. This study presents an automatic method of extracting terraces based on 1 m resolution digital elevation models (DEMs) and 0.3 m resolution Worldview-3 imagery as auxiliary information used for object-based image analysis (OBIA). A multi-resolution segmentation method was used where slope, positive and negative terrain index (PN), accumulative curvature slope (AC), and slope of slope (SOS) were determined as input layers for image segmentation by correlation analysis and Sheffield entropy method. The main classification features based on DEMs were chosen from the terrain features derived from terrain factors and texture features by gray-level co-occurrence matrix (GLCM) analysis; subsequently, these features were determined by the importance analysis on classification and regression tree (CART) analysis. Extraction rules based on DEMs were generated from the classification features with a total classification accuracy of 89.96%. The red band and near-infrared band of images were used to exclude construction land, which is easily confused with small-size terraces. As a result, the total classification accuracy was increased to 94%. The proposed method ensures comprehensive consideration of terrain, texture, shape, and spectrum characteristics, demonstrating huge potential in hilly-gully loess region with similarly complex terrain and diverse vegetation covers.},
DOI = {10.3390/ijgi6060157}
}



@Article{rs9060539,
AUTHOR = {Liu, Mingyue and Li, Huiying and Li, Lin and Man, Weidong and Jia, Mingming and Wang, Zongming and Lu, Chunyan},
TITLE = {Monitoring the Invasion of Spartina alterniflora Using Multi-source High-resolution Imagery in the Zhangjiang Estuary, China},
JOURNAL = {Remote Sensing},
VOLUME = {9},
YEAR = {2017},
NUMBER = {6},
ARTICLE-NUMBER = {539},
URL = {https://www.mdpi.com/2072-4292/9/6/539},
ISSN = {2072-4292},
ABSTRACT = {Spartina alterniflora (S. alterniflora) is one of the most harmful invasive plants in China. Google Earth (GE), as a free software, hosts high-resolution imagery for many areas of the world. To explore the use of GE imagery for monitoring S. alterniflora invasion and developing an understanding of the invasion process of S. alterniflora in the Zhangjiang Estuary, the object-oriented method and visual interpretation were applied to GE, SPOT-5, and Gaofen-1 (GF-1) images. In addition, landscape metrics of S. alterniflora patches adjacent to mangrove forests were calculated and mangrove gaps were recorded by checking whether S. alterniflora exists. The results showed that from 2003–2015, the areal extent of S. alterniflora in the Zhangjiang Estuary increased from 57.94 ha to 116.11 ha, which was mainly converted from mudflats and moved seaward significantly. Analyses of the S. alterniflora expansion patterns in the six subzones indicated that the expansion trends varied with different environmental circumstances and human activities. Land reclamation, mangrove replantation, and mudflat aquaculture caused significant losses of S. alterniflora. The number of invaded gaps increased and S. alterniflora patches adjacent to mangrove forests became much larger and more aggregated during 2003–2015 (the class area increased from 12.13 ha to 49.76 ha and the aggregation index increased from 91.15 to 94.65). We thus concluded that S. alterniflora invasion in the Zhangjiang Estuary had seriously increased and that measures should be taken considering the characteristics shown in different subzones. This study provides an example of applying GE imagery to monitor invasive plants and illustrates that this approach can aid in the development of governmental policies employed to control S. alterniflora invasion.},
DOI = {10.3390/rs9060539}
}



@Article{rs9060583,
AUTHOR = {Yang, Ming-Der and Huang, Kai-Siang and Kuo, Yi-Hsuan and Tsai, Hui Ping and Lin, Liang-Mao},
TITLE = {Spatial and Spectral Hybrid Image Classification for Rice Lodging Assessment through UAV Imagery},
JOURNAL = {Remote Sensing},
VOLUME = {9},
YEAR = {2017},
NUMBER = {6},
ARTICLE-NUMBER = {583},
URL = {https://www.mdpi.com/2072-4292/9/6/583},
ISSN = {2072-4292},
ABSTRACT = {Rice lodging identification relies on manual in situ assessment and often leads to a compensation dispute in agricultural disaster assessment. Therefore, this study proposes a comprehensive and efficient classification technique for agricultural lands that entails using unmanned aerial vehicle (UAV) imagery. In addition to spectral information, digital surface model (DSM) and texture information of the images was obtained through image-based modeling and texture analysis. Moreover, single feature probability (SFP) values were computed to evaluate the contribution of spectral and spatial hybrid image information to classification accuracy. The SFP results revealed that texture information was beneficial for the classification of rice and water, DSM information was valuable for lodging and tree classification, and the combination of texture and DSM information was helpful in distinguishing between artificial surface and bare land. Furthermore, a decision tree classification model incorporating SFP values yielded optimal results, with an accuracy of 96.17% and a Kappa value of 0.941, compared with that of a maximum likelihood classification model (90.76%). The rice lodging ratio in paddies at the study site was successfully identified, with three paddies being eligible for disaster relief. The study demonstrated that the proposed spatial and spectral hybrid image classification technology is a promising tool for rice lodging assessment.},
DOI = {10.3390/rs9060583}
}



@Article{su9061010,
AUTHOR = {Ampatzidis, Yiannis and De Bellis, Luigi and Luvisi, Andrea},
TITLE = {iPathology: Robotic Applications and Management of Plants and Plant Diseases},
JOURNAL = {Sustainability},
VOLUME = {9},
YEAR = {2017},
NUMBER = {6},
ARTICLE-NUMBER = {1010},
URL = {https://www.mdpi.com/2071-1050/9/6/1010},
ISSN = {2071-1050},
ABSTRACT = {The rapid development of new technologies and the changing landscape of the online world (e.g., Internet of Things (IoT), Internet of All, cloud-based solutions) provide a unique opportunity for developing automated and robotic systems for urban farming, agriculture, and forestry. Technological advances in machine vision, global positioning systems, laser technologies, actuators, and mechatronics have enabled the development and implementation of robotic systems and intelligent technologies for precision agriculture. Herein, we present and review robotic applications on plant pathology and management, and emerging agricultural technologies for intra-urban agriculture. Greenhouse advanced management systems and technologies have been greatly developed in the last years, integrating IoT and WSN (Wireless Sensor Network). Machine learning, machine vision, and AI (Artificial Intelligence) have been utilized and applied in agriculture for automated and robotic farming. Intelligence technologies, using machine vision/learning, have been developed not only for planting, irrigation, weeding (to some extent), pruning, and harvesting, but also for plant disease detection and identification. However, plant disease detection still represents an intriguing challenge, for both abiotic and biotic stress. Many recognition methods and technologies for identifying plant disease symptoms have been successfully developed; still, the majority of them require a controlled environment for data acquisition to avoid false positives. Machine learning methods (e.g., deep and transfer learning) present promising results for improving image processing and plant symptom identification. Nevertheless, diagnostic specificity is a challenge for microorganism control and should drive the development of mechatronics and robotic solutions for disease management.},
DOI = {10.3390/su9061010}
}



@Article{s17061428,
AUTHOR = {Domingues Franceschini, Marston Héracles and Bartholomeus, Harm and Van Apeldoorn, Dirk and Suomalainen, Juha and Kooistra, Lammert},
TITLE = {Intercomparison of Unmanned Aerial Vehicle and Ground-Based Narrow Band Spectrometers Applied to Crop Trait Monitoring in Organic Potato Production},
JOURNAL = {Sensors},
VOLUME = {17},
YEAR = {2017},
NUMBER = {6},
ARTICLE-NUMBER = {1428},
URL = {https://www.mdpi.com/1424-8220/17/6/1428},
ISSN = {1424-8220},
ABSTRACT = {Vegetation properties can be estimated using optical sensors, acquiring data on board of different platforms. For instance, ground-based and Unmanned Aerial Vehicle (UAV)-borne spectrometers can measure reflectance in narrow spectral bands, while different modelling approaches, like regressions fitted to vegetation indices, can relate spectra with crop traits. Although monitoring frameworks using multiple sensors can be more flexible, they may result in higher inaccuracy due to differences related to the sensors characteristics, which can affect information sampling. Also organic production systems can benefit from continuous monitoring focusing on crop management and stress detection, but few studies have evaluated applications with this objective. In this study, ground-based and UAV spectrometers were compared in the context of organic potato cultivation. Relatively accurate estimates were obtained for leaf chlorophyll (RMSE = 6.07 µg·cm−2), leaf area index (RMSE = 0.67 m2·m−2), canopy chlorophyll (RMSE = 0.24 g·m−2) and ground cover (RMSE = 5.5%) using five UAV-based data acquisitions, from 43 to 99 days after planting. These retrievals are slightly better than those derived from ground-based measurements (RMSE = 7.25 µg·cm−2, 0.85 m2·m−2, 0.28 g·m−2 and 6.8%, respectively), for the same period. Excluding observations corresponding to the first acquisition increased retrieval accuracy and made outputs more comparable between sensors, due to relatively low vegetation cover on this date. Intercomparison of vegetation indices indicated that indices based on the contrast between spectral bands in the visible and near-infrared, like OSAVI, MCARI2 and CIg provided, at certain extent, robust outputs that could be transferred between sensors. Information sampling at plot level by both sensing solutions resulted in comparable discriminative potential concerning advanced stages of late blight incidence. These results indicate that optical sensors, and their integration, have great potential for monitoring this specific organic cropping system.},
DOI = {10.3390/s17061428}
}



@Article{aerospace4020032,
AUTHOR = {Yang, Yurong and Gong, Huajun and Wang, Xinhua and Sun, Peng},
TITLE = {Aerial Target Tracking Algorithm Based on Faster R-CNN Combined with Frame Differencing},
JOURNAL = {Aerospace},
VOLUME = {4},
YEAR = {2017},
NUMBER = {2},
ARTICLE-NUMBER = {32},
URL = {https://www.mdpi.com/2226-4310/4/2/32},
ISSN = {2226-4310},
ABSTRACT = {We propose a robust approach to detecting and tracking moving objects for a naval unmanned aircraft system (UAS) landing on an aircraft carrier. The frame difference algorithm follows a simple principle to achieve real-time tracking, whereas Faster Region-Convolutional Neural Network (R-CNN) performs highly precise detection and tracking characteristics. We thus combine Faster R-CNN with the frame difference method, which is demonstrated to exhibit robust and real-time detection and tracking performance. In our UAS landing experiments, two cameras placed on both sides of the runway are used to capture the moving UAS. When the UAS is captured, the joint algorithm uses frame difference to detect the moving target (UAS). As soon as the Faster R-CNN algorithm accurately detects the UAS, the detection priority is given to Faster R-CNN. In this manner, we also perform motion segmentation and object detection in the presence of changes in the environment, such as illumination variation or “walking persons”. By combining the 2 algorithms we can accurately detect and track objects with a tracking accuracy rate of up to 99% and a frame per second of up to 40 Hz. Thus, a solid foundation is laid for subsequent landing guidance.},
DOI = {10.3390/aerospace4020032}
}



@Article{rs9060631,
AUTHOR = {López-Fernández, Luis and Lagüela, Susana and Fernández, Jesús and González-Aguilera, Diego},
TITLE = {Automatic Evaluation of Photovoltaic Power Stations from High-Density RGB-T 3D Point Clouds},
JOURNAL = {Remote Sensing},
VOLUME = {9},
YEAR = {2017},
NUMBER = {6},
ARTICLE-NUMBER = {631},
URL = {https://www.mdpi.com/2072-4292/9/6/631},
ISSN = {2072-4292},
ABSTRACT = {A low-cost unmanned aerial platform (UAV) equipped with RGB (Red, Green, Blue) and thermographic sensors is used for the acquisition of all the data needed for the automatic detection and evaluation of thermal pathologies on photovoltaic (PV) surfaces and geometric defects in the mounting on photovoltaic power stations. RGB imagery is used for the generation of a georeferenced 3D point cloud through digital image preprocessing, photogrammetric and computer vision algorithms. The point cloud is complemented with temperature values measured by the thermographic sensor and with intensity values derived from the RGB data in order to obtain a multidimensional product (5D: 3D geometry plus temperature and intensity on the visible spectrum). A segmentation workflow based on the proper integration of several state-of-the-art geomatic and mathematic techniques is applied to the 5D product for the detection and sizing of thermal pathologies and geometric defects in the mounting in the PV panels. It consists of a three-step segmentation procedure, involving first the geometric information, then the radiometric (RGB) information, and last the thermal data. No configuration of parameters is required. Thus, the methodology presented contributes to the automation of the inspection of PV farms, through the maximization of the exploitation of the data acquired in the different spectra (visible and thermal infrared bands). Results of the proposed workflow were compared with a ground truth generated according to currently established protocols and complemented with a topographic survey. The proposed methodology was able to detect all pathologies established by the ground truth without adding any false positives. Discrepancies in the measurement of damaged surfaces regarding established ground truth, which can reach the 5% of total panel surface for the visual inspection by an expert operator, decrease with the proposed methodology under the 2%. The geometric evaluation of the facilities presents discrepancies regarding the ground truth lower than one degree for angular parameters (azimuth and tilt) and lower than 0.05 m2 for the area of each solar panel.},
DOI = {10.3390/rs9060631}
}



@Article{rs9070646,
AUTHOR = {Radoux, Julien and Bogaert, Patrick},
TITLE = {Good Practices for Object-Based Accuracy Assessment},
JOURNAL = {Remote Sensing},
VOLUME = {9},
YEAR = {2017},
NUMBER = {7},
ARTICLE-NUMBER = {646},
URL = {https://www.mdpi.com/2072-4292/9/7/646},
ISSN = {2072-4292},
ABSTRACT = {Thematic accuracy assessment of a map is a necessary condition for the comparison of research results and the appropriate use of geographic data analysis. Good practices of accuracy assessment already exist, but Geographic Object-Based Image Analysis (GEOBIA) is based on a partition of the spatial area of interest into polygons, which leads to specific issues. In this study, additional guidelines for the validation of object-based maps are provided. These guidelines include recommendations about sampling design, response design and analysis, as well as the evaluation of structural and positional quality. Different types of GEOBIA applications are considered with their specific issues. In particular, accuracy assessment could either focus on the count of spatial entities or on the area of the map that is correctly classified. Two practical examples are given at the end of the manuscript.},
DOI = {10.3390/rs9070646}
}



@Article{rs9070696,
AUTHOR = {Zeng, Chuiqing and King, Douglas J. and Richardson, Murray and Shan, Bo},
TITLE = {Fusion of Multispectral Imagery and Spectrometer Data in UAV Remote Sensing},
JOURNAL = {Remote Sensing},
VOLUME = {9},
YEAR = {2017},
NUMBER = {7},
ARTICLE-NUMBER = {696},
URL = {https://www.mdpi.com/2072-4292/9/7/696},
ISSN = {2072-4292},
ABSTRACT = {Abstract: High spatial resolution hyperspectral data often used in precision farming applications are not available from current satellite sensors, and difficult or expensive to acquire from standard aircraft. Alternatively, in precision farming, unmanned aerial vehicles (UAVs) are emerging as lower cost and more flexible means to acquire very high resolution imagery. Miniaturized hyperspectral sensors have been developed for UAVs, but the sensors, associated hardware, and data processing software are still cost prohibitive for use by individual farmers or small remote sensing firms. This study simulated hyperspectral image data by fusing multispectral camera imagery and spectrometer data. We mounted a multispectral camera and spectrometer, both being low cost and low weight, on a standard UAV and developed procedures for their precise data alignment, followed by fusion of the spectrometer data with the image data to produce estimated spectra for all the multispectral camera image pixels. To align the data collected from the two sensors in both the time and space domains, a post-acquisition correlation-based global optimization method was used. Data fusion, to estimate hyperspectral reflectance, was implemented using several methods for comparison. Flight data from two crop sites, one being tomatoes, and the other corn and soybeans, were used to evaluate the alignment procedure and the data fusion results. The data alignment procedure resulted in a peak R2 between the spectrometer and camera data of 0.95 and 0.72, respectively, for the two test sites. The corresponding multispectral camera data for these space and time offsets were taken as the best match to a given spectrometer reading, and used in modelling to estimate hyperspectral imagery from the multispectral camera pixel data. Of the fusion approaches evaluated, principal component analysis (PCA) based models and Bayesian imputation reached a similar accuracy, and outperformed simple spline interpolation. Mean absolute error (MAE) between predicted and observed spectra was 17% relative to the mean of the observed spectra, and root mean squared error (RMSE) was 0.028. This approach to deriving estimated hyperspectral image data can be applied in a simple fashion at very low cost for crop assessment and monitoring within individual fields.},
DOI = {10.3390/rs9070696}
}



@Article{rs9070726,
AUTHOR = {Danner, Martin and Berger, Katja and Wocher, Matthias and Mauser, Wolfram and Hank, Tobias},
TITLE = {Retrieval of Biophysical Crop Variables from Multi-Angular Canopy Spectroscopy},
JOURNAL = {Remote Sensing},
VOLUME = {9},
YEAR = {2017},
NUMBER = {7},
ARTICLE-NUMBER = {726},
URL = {https://www.mdpi.com/2072-4292/9/7/726},
ISSN = {2072-4292},
ABSTRACT = {The future German Environmental Mapping and Analysis Program (EnMAP) mission, due to launch in late 2019, will deliver high resolution hyperspectral data from space and will thus contribute to a better monitoring of the dynamic surface of the earth. Exploiting the satellite’s ±30° across-track pointing capabilities will allow for the collection of hyperspectral time-series of homogeneous quality. Various studies have shown the possibility to retrieve geo-biophysical plant variables, like leaf area index (LAI) or leaf chlorophyll content (LCC), from narrowband observations with fixed viewing geometry by inversion of radiative transfer models (RTM). In this study we assess the capability of the well-known PROSPECT 5B + 4SAIL (Scattering by Arbitrarily Inclined Leaves) RTM to estimate these variables from off-nadir observations obtained during a field campaign with respect to EnMAP-like sun–target–sensor-geometries. A novel approach for multiple inquiries of a large look-up-table (LUT) in hierarchical steps is introduced that accounts for the varying instances of all variables of interest. Results show that anisotropic effects are strongest for early growth stages of the winter wheat canopy which influences also the retrieval of the variables. RTM inversions from off-nadir spectra lead to a decreased accuracy for the retrieval of LAI with a relative root mean squared error (rRMSE) of 18% at nadir vs. 25% (backscatter) and 24% (forward scatter) at off-nadir. For LCC estimations, however, off-nadir observations yield improvements, i.e., rRMSE (nadir) = 24% vs. rRMSE (forward scatter) = 20%. It follows that for a variable retrieval through RTM inversion, the final user will benefit from EnMAP time-series for biophysical studies regardless of the acquisition angle and will thus be able to exploit the maximum revisit capability of the mission.},
DOI = {10.3390/rs9070726}
}



@Article{s17071625,
AUTHOR = {Kicherer, Anna and Herzog, Katja and Bendel, Nele and Klück, Hans-Christian and Backhaus, Andreas and Wieland, Markus and Rose, Johann Christian and Klingbeil, Lasse and Läbe, Thomas and Hohl, Christian and Petry, Willi and Kuhlmann, Heiner and Seiffert, Udo and Töpfer, Reinhard},
TITLE = {Phenoliner: A New Field Phenotyping Platform for Grapevine Research},
JOURNAL = {Sensors},
VOLUME = {17},
YEAR = {2017},
NUMBER = {7},
ARTICLE-NUMBER = {1625},
URL = {https://www.mdpi.com/1424-8220/17/7/1625},
ISSN = {1424-8220},
ABSTRACT = {In grapevine research the acquisition of phenotypic data is largely restricted to the field due to its perennial nature and size. The methodologies used to assess morphological traits and phenology are mainly limited to visual scoring. Some measurements for biotic and abiotic stress, as well as for quality assessments, are done by invasive measures. The new evolving sensor technologies provide the opportunity to perform non-destructive evaluations of phenotypic traits using different field phenotyping platforms. One of the biggest technical challenges for field phenotyping of grapevines are the varying light conditions and the background. In the present study the Phenoliner is presented, which represents a novel type of a robust field phenotyping platform. The vehicle is based on a grape harvester following the concept of a moveable tunnel. The tunnel it is equipped with different sensor systems (RGB and NIR camera system, hyperspectral camera, RTK-GPS, orientation sensor) and an artificial broadband light source. It is independent from external light conditions and in combination with artificial background, the Phenoliner enables standardised acquisition of high-quality, geo-referenced sensor data.},
DOI = {10.3390/s17071625}
}



@Article{s17081720,
AUTHOR = {Roldán, Juan Jesús and Peña-Tapia, Elena and Martín-Barrio, Andrés and Olivares-Méndez, Miguel A. and Del Cerro, Jaime and Barrientos, Antonio},
TITLE = {Multi-Robot Interfaces and Operator Situational Awareness: Study of the Impact of Immersion and Prediction},
JOURNAL = {Sensors},
VOLUME = {17},
YEAR = {2017},
NUMBER = {8},
ARTICLE-NUMBER = {1720},
URL = {https://www.mdpi.com/1424-8220/17/8/1720},
ISSN = {1424-8220},
ABSTRACT = {Multi-robot missions are a challenge for operators in terms of workload and situational awareness. These operators have to receive data from the robots, extract information, understand the situation properly, make decisions, generate the adequate commands, and send them to the robots. The consequences of excessive workload and lack of awareness can vary from inefficiencies to accidents. This work focuses on the study of future operator interfaces of multi-robot systems, taking into account relevant issues such as multimodal interactions, immersive devices, predictive capabilities and adaptive displays. Specifically, four interfaces have been designed and developed: a conventional, a predictive conventional, a virtual reality and a predictive virtual reality interface. The four interfaces have been validated by the performance of twenty-four operators that supervised eight multi-robot missions of fire surveillance and extinguishing. The results of the workload and situational awareness tests show that virtual reality improves the situational awareness without increasing the workload of operators, whereas the effects of predictive components are not significant and depend on their implementation.},
DOI = {10.3390/s17081720}
}



@Article{rs9080813,
AUTHOR = {Jiang, San and Jiang, Wanshou},
TITLE = {On-Board GNSS/IMU Assisted Feature Extraction and Matching for Oblique UAV Images},
JOURNAL = {Remote Sensing},
VOLUME = {9},
YEAR = {2017},
NUMBER = {8},
ARTICLE-NUMBER = {813},
URL = {https://www.mdpi.com/2072-4292/9/8/813},
ISSN = {2072-4292},
ABSTRACT = {Feature extraction and matching is a crucial task in the fields of computer vision and photogrammetry. Even though wide researches have been reported, some issues are still existing for oblique images. This paper exploits the use of on-board GNSS/IMU (Global Navigation Satellite System/Inertial Measurement Unit) data to achieve efficient and reliable feature extraction and matching for oblique unmanned aerial vehicle (UAV) images. Firstly, rough POS (Positioning and Orientation System) is calculated for each image with cooperation of on-board GNSS/IMU data and camera installation angles, which enables image rectification and footprint calculation. Secondly, two robust strategies, including the geometric rectification and tile strategy, are considered to address the issues caused by perspective deformations and to relieve the side-effects of image down-sampling. According to the results of individual performance evaluation, four combinations of these two strategies are designed and comprehensively compared in BA (Bundle Adjustment) experiments by using a real oblique UAV dataset. The results reported in this paper demonstrate that the solution with the tiling strategy is superior to the other solutions in terms of efficiency, completeness and accuracy. For feature extraction and matching of oblique UAV images, it is proposed to combine the tiling strategy with existing workflows to achieve an efficient and reliable solution.},
DOI = {10.3390/rs9080813}
}



@Article{rs9080815,
AUTHOR = {Laso Bayas, Juan Carlos and See, Linda and Perger, Christoph and Justice, Christina and Nakalembe, Catherine and Dempewolf, Jan and Fritz, Steffen},
TITLE = {Validation of Automatically Generated Global and Regional Cropland Data Sets: The Case of Tanzania},
JOURNAL = {Remote Sensing},
VOLUME = {9},
YEAR = {2017},
NUMBER = {8},
ARTICLE-NUMBER = {815},
URL = {https://www.mdpi.com/2072-4292/9/8/815},
ISSN = {2072-4292},
ABSTRACT = {There is a need to validate existing global cropland maps since they are used for different purposes including agricultural monitoring and assessment. In this paper we validate three recent global products (ESA-CCI, GlobeLand30, FROM-GC) and one regional product (Tanzania Land Cover 2010 Scheme II) using a validation data set that was collected by students through the Geo-Wiki tool. The ultimate aim was to understand the usefulness of these products for agricultural monitoring. Data were collected wall-to-wall for Kilosa district and for a sample across Tanzania. The results show that the amount of and spatial extent of cropland in the different products differs considerably from 8% to 42% for Tanzania, with similar values for Kilosa district. The agreement of the validation data with the four different products varied between 36% and 54% and highlighted that cropland is overestimated by the ESA-CCI and underestimated by FROM-GC. The validation data were also analyzed for consistency between the student interpreters and also compared with a sample interpreted by five experts for quality assurance. Regarding consistency between the students, there was more than 80% agreement if one difference in cropland category was considered (e.g., between low and medium cropland) while most of the confusion with the experts was also within one category difference. In addition to the validation of current cropland products, the data set collected by the students also has potential value as a training set for improving future cropland products.},
DOI = {10.3390/rs9080815}
}



@Article{rs9080838,
AUTHOR = {Sothe, Camile and Almeida, Cláudia Maria de and Liesenberg, Veraldo and Schimalski, Marcos Benedito},
TITLE = {Evaluating Sentinel-2 and Landsat-8 Data to Map Sucessional Forest Stages in a Subtropical Forest in Southern Brazil},
JOURNAL = {Remote Sensing},
VOLUME = {9},
YEAR = {2017},
NUMBER = {8},
ARTICLE-NUMBER = {838},
URL = {https://www.mdpi.com/2072-4292/9/8/838},
ISSN = {2072-4292},
ABSTRACT = {Studies designed to discriminate different successional forest stages play a strategic role in forest management, forest policy and environmental conservation in tropical environments. The discrimination of different successional forest stages is still a challenge due to the spectral similarity among the concerned classes. Considering this, the objective of this paper was to investigate the performance of Sentinel-2 and Landsat-8 data for discriminating different successional forest stages of a patch located in a subtropical portion of the Atlantic Rain Forest in Southern Brazil with the aid of two machine learning algorithms and relying on the use of spectral reflectance data selected over two seasons and attributes thereof derived. Random Forest (RF) and Support Vector Machine (SVM) were used as classifiers with different subsets of predictor variables (multitemporal spectral reflectance, textural metrics and vegetation indices). All the experiments reached satisfactory results, with Kappa indices varying between 0.9, with Landsat-8 spectral reflectance alone and the SVM algorithm, and 0.98, with Sentinel-2 spectral reflectance alone also associated with the SVM algorithm. The Landsat-8 data had a significant increase in accuracy with the inclusion of other predictor variables in the classification process besides the pure spectral reflectance bands. The classification methods SVM and RF had similar performances in general. As to the RF method, the texture mean of the red-edge and SWIR bands were considered the most important ranked attributes for the classification of Sentinel-2 data, while attributes resulting from multitemporal bands, textural metrics of SWIR bands and vegetation indices were the most important ones in the Landsat-8 data classification.},
DOI = {10.3390/rs9080838}
}



@Article{s17091987,
AUTHOR = {Nguyen, Phong Ha and Kim, Ki Wan and Lee, Young Won and Park, Kang Ryoung},
TITLE = {Remote Marker-Based Tracking for UAV Landing Using Visible-Light Camera Sensor},
JOURNAL = {Sensors},
VOLUME = {17},
YEAR = {2017},
NUMBER = {9},
ARTICLE-NUMBER = {1987},
URL = {https://www.mdpi.com/1424-8220/17/9/1987},
ISSN = {1424-8220},
ABSTRACT = {Unmanned aerial vehicles (UAVs), which are commonly known as drones, have proved to be useful not only on the battlefields where manned flight is considered too risky or difficult, but also in everyday life purposes such as surveillance, monitoring, rescue, unmanned cargo, aerial video, and photography. More advanced drones make use of global positioning system (GPS) receivers during the navigation and control loop which allows for smart GPS features of drone navigation. However, there are problems if the drones operate in heterogeneous areas with no GPS signal, so it is important to perform research into the development of UAVs with autonomous navigation and landing guidance using computer vision. In this research, we determined how to safely land a drone in the absence of GPS signals using our remote maker-based tracking algorithm based on the visible light camera sensor. The proposed method uses a unique marker designed as a tracking target during landing procedures. Experimental results show that our method significantly outperforms state-of-the-art object trackers in terms of both accuracy and processing time, and we perform test on an embedded system in various environments.},
DOI = {10.3390/s17091987}
}



@Article{s17092007,
AUTHOR = {Alexandridis, Thomas K. and Tamouridou, Afroditi Alexandra and Pantazi, Xanthoula Eirini and Lagopodi, Anastasia L. and Kashefi, Javid and Ovakoglou, Georgios and Polychronos, Vassilios and Moshou, Dimitrios},
TITLE = {Novelty Detection Classifiers in Weed Mapping: Silybum marianum Detection on UAV Multispectral Images},
JOURNAL = {Sensors},
VOLUME = {17},
YEAR = {2017},
NUMBER = {9},
ARTICLE-NUMBER = {2007},
URL = {https://www.mdpi.com/1424-8220/17/9/2007},
ISSN = {1424-8220},
ABSTRACT = {In the present study, the detection and mapping of Silybum marianum (L.) Gaertn. weed using novelty detection classifiers is reported. A multispectral camera (green-red-NIR) on board a fixed wing unmanned aerial vehicle (UAV) was employed for obtaining high-resolution images. Four novelty detection classifiers were used to identify S. marianum between other vegetation in a field. The classifiers were One Class Support Vector Machine (OC-SVM), One Class Self-Organizing Maps (OC-SOM), Autoencoders and One Class Principal Component Analysis (OC-PCA). As input features to the novelty detection classifiers, the three spectral bands and texture were used. The S. marianum identification accuracy using OC-SVM reached an overall accuracy of 96%. The results show the feasibility of effective S. marianum mapping by means of novelty detection classifiers acting on multispectral UAV imagery.},
DOI = {10.3390/s17092007}
}



@Article{rs9090910,
AUTHOR = {Zhong, Yanfei and Jia, Tianyi and Zhao, Ji and Wang, Xinyu and Jin, Shuying},
TITLE = {Spatial-Spectral-Emissivity Land-Cover Classification Fusing Visible and Thermal Infrared Hyperspectral Imagery},
JOURNAL = {Remote Sensing},
VOLUME = {9},
YEAR = {2017},
NUMBER = {9},
ARTICLE-NUMBER = {910},
URL = {https://www.mdpi.com/2072-4292/9/9/910},
ISSN = {2072-4292},
ABSTRACT = {High-resolution visible remote sensing imagery and thermal infrared hyperspectral imagery are potential data sources for land-cover classification. In this paper, in order to make full use of these two types of imagery, a spatial-spectral-emissivity land-cover classification method based on the fusion of visible and thermal infrared hyperspectral imagery is proposed, namely, SSECRF (spatial-spectral-emissivity land-cover classification based on conditional random fields). A spectral-spatial feature set is constructed considering the spectral variability and spatial-contextual information, to extract features from the high-resolution visible image. The emissivity is retrieved from the thermal infrared hyperspectral image by the FLAASH-IR algorithm and firstly introduced in the fusion of the visible and thermal infrared hyperspectral imagery; also, the emissivity is utilized in SSECRF, which contributes to improving the identification of man-made objects, such as roads and roofs. To complete the land-cover classification, the spatial-spectral feature set and emissivity are integrated by constructing the SSECRF energy function, which relates labels to the spatial-spectral-emissivity features, to obtain an improved classification result. The classification map performs a good result in distinguishing some certain classes, such as roads and bare soil. Also, the experimental results show that the proposed SSECRF algorithm efficiently integrates the spatial, spectral, and emissivity information and performs better than the traditional methods using raw radiance from thermal infrared hyperspectral imagery data, with a kappa value of 0.9137.},
DOI = {10.3390/rs9090910}
}



@Article{rs9090940,
AUTHOR = {Zhang, Zhengnan and Cao, Lin and She, Guanghui},
TITLE = {Estimating Forest Structural Parameters Using Canopy Metrics Derived from Airborne LiDAR Data in Subtropical Forests},
JOURNAL = {Remote Sensing},
VOLUME = {9},
YEAR = {2017},
NUMBER = {9},
ARTICLE-NUMBER = {940},
URL = {https://www.mdpi.com/2072-4292/9/9/940},
ISSN = {2072-4292},
ABSTRACT = {Accurate and timely estimation of forest structural parameters plays a key role in the management of forest resources, as well as studies on the carbon cycle and biodiversity. Light Detection and Ranging (LiDAR) is a promising active remote sensing technology capable of providing highly accurate three dimensional and wall-to-wall forest structural characteristics. In this study, we evaluated the utility of standard metrics and canopy metrics derived from airborne LiDAR data for estimating plot-level forest structural parameters individually and in combination, over a subtropical forest in Yushan forest farm, southeastern China. Standard metrics, i.e., height-based and density-based metrics, and canopy metrics extracted from canopy vertical profiles, i.e., canopy volume profile (CVP), canopy height distribution (CHD), and foliage profile (FP), were extracted from LiDAR point clouds. Then the standard metrics and canopy metrics were used for estimating forest structural parameters individually and in combination by multiple regression models, including forest type-specific (coniferous forest, broad-leaved forest, mixed forest) models and general models. Additionally, the synergy of standard metrics and canopy metrics for estimating structural parameters was evaluated using field measured data. Finally, the sensitivity of vertical and horizontal resolution of voxel size for estimating forest structural parameters was assessed. The results showed that, in general, the accuracies of forest type-specific models (Adj-R2 = 0.44–0.88) were relatively higher than general models (Adj-R2 = 0.39–0.77). For forest structural parameters, the estimation accuracies of Lorey’s mean height (Adj-R2 = 0.61–0.88) and aboveground biomass (Adj-R2 = 0.54–0.81) models were the highest, followed by volume (Adj-R2 = 0.42–0.78), DBH (Adj-R2 = 0.48–0.74), basal area (Adj-R2 = 0.41–0.69), whereas stem density (Adj-R2 = 0.39–0.64) models were relatively lower. The combination models (Adj-R2 = 0.45–0.88) had higher performance compared with models developed using standard metrics (only) (Adj-R2 = 0.42–0.84) and canopy metrics (only) (Adj-R2 = 0.39–0.83). The results also demonstrated that the optimal voxel size was 5 × 5 × 0.5 m3 for estimating most of the parameters. This study demonstrated that canopy metrics based on canopy vertical profiles can be effectively used to enhance the estimation accuracies of forest structural parameters in subtropical forests.},
DOI = {10.3390/rs9090940}
}



@Article{rs9090939,
AUTHOR = {Huang, Yaohuan and Zhao, Chuanpeng and Yang, Haijun and Song, Xiaoyang and Chen, Jie and Li, Zhonghua},
TITLE = {Feature Selection Solution with High Dimensionality and Low-Sample Size for Land Cover Classification in Object-Based Image Analysis},
JOURNAL = {Remote Sensing},
VOLUME = {9},
YEAR = {2017},
NUMBER = {9},
ARTICLE-NUMBER = {939},
URL = {https://www.mdpi.com/2072-4292/9/9/939},
ISSN = {2072-4292},
ABSTRACT = {Land cover information extraction through object-based image analysis (OBIA) has become an important trend in remote sensing, thanks to the increasing availability of high-resolution imagery. Segmented objects have a large number of features that cause high-dimension and low-sample size problems in the classification process. In this study, on the basis of a partial least squares generalized linear regression (PLSGLR), we propose a group corrected PLSGLR, known as G-PLSGLR, that aims to reduce the redundancy of object features for land cover identifications. Using Gaofen-2 images, the area of interest was segmented and sampled to generate small sample-size training datasets with 51 object features. The features selected by G-PLSGLR were compared against a guided regularized random forest (GRRF) in metrics of reduction rate, feature redundancy, and accuracy assessment of classification. Three indicators of overall accuracy (OA), user’s accuracy (UA), and producer’s accuracy (PA) were applied for accuracy assessment in this paper. The result shows that the G-PLSGLR achieved a reduction rate of 9.27 with a feature redundancy of 0.29, and a value of OA 90.63%. The GRRF achieved a reduction rate of 1.61 with a feature redundancy of 0.42, and a value of OA 85.56%. The PA of each land cover category was more than 95% using features selected by G-PLSGLR, while the PA ranged from 77 to 96% using features selected by GRRF. The UA of G-PLSGLR-selected features ranged from 70 to 80% except for grass land and bare land, which achieved 10% higher UA than GRRF-selected features. The G-PLSGLR method we proposed has the advantages of a large reduction rate, low feature redundancy, and high classification performance, which can be applied in OBIA-based land cover classification.},
DOI = {10.3390/rs9090939}
}



@Article{s17102173,
AUTHOR = {Ribeiro-Gomes, Krishna and Hernández-López, David and Ortega, José F. and Ballesteros, Rocío and Poblete, Tomás and Moreno, Miguel A.},
TITLE = {Uncooled Thermal Camera Calibration and Optimization of the Photogrammetry Process for UAV Applications in Agriculture},
JOURNAL = {Sensors},
VOLUME = {17},
YEAR = {2017},
NUMBER = {10},
ARTICLE-NUMBER = {2173},
URL = {https://www.mdpi.com/1424-8220/17/10/2173},
ISSN = {1424-8220},
ABSTRACT = {The acquisition, processing, and interpretation of thermal images from unmanned aerial vehicles (UAVs) is becoming a useful source of information for agronomic applications because of the higher temporal and spatial resolution of these products compared with those obtained from satellites. However, due to the low load capacity of the UAV they need to mount light, uncooled thermal cameras, where the microbolometer is not stabilized to a constant temperature. This makes the camera precision low for many applications. Additionally, the low contrast of the thermal images makes the photogrammetry process inaccurate, which result in large errors in the generation of orthoimages. In this research, we propose the use of new calibration algorithms, based on neural networks, which consider the sensor temperature and the digital response of the microbolometer as input data. In addition, we evaluate the use of the Wallis filter for improving the quality of the photogrammetry process using structure from motion software. With the proposed calibration algorithm, the measurement accuracy increased from 3.55 °C with the original camera configuration to 1.37 °C. The implementation of the Wallis filter increases the number of tie-point from 58,000 to 110,000 and decreases the total positing error from 7.1 m to 1.3 m.},
DOI = {10.3390/s17102173}
}



@Article{rs9100992,
AUTHOR = {Zheng, Zhong and Zhou, Weiqi and Wang, Jia and Hu, Xiaofang and Qian, Yuguo},
TITLE = {Sixty-Year Changes in Residential Landscapes in Beijing: A Perspective from Both the Horizontal (2D) and Vertical (3D) Dimensions},
JOURNAL = {Remote Sensing},
VOLUME = {9},
YEAR = {2017},
NUMBER = {10},
ARTICLE-NUMBER = {992},
URL = {https://www.mdpi.com/2072-4292/9/10/992},
ISSN = {2072-4292},
ABSTRACT = {Landscape changes associated with urbanization can lead to many serious ecological and environmental problems. Quantifying the vertical structure of the urban landscape and its change is important to understand its social and ecological impacts, but previous studies mainly focus on urban horizontal expansion and its impacts on land cover/land use change. This papers focuses on the residential landscape to investigate how the vertical dimension of the urban landscape (i.e., building height) change through time, and how such change is related to changes in the horizontal dimension of the landscape, using Beijing, the capital of China, as a case study. We quantified the expansion of the residential neighborhoods from 1949 to 2009, and changes in vegetation coverage, building density, and building height within these neighborhoods, using 1 m spatial resolution imagery. One-way ANOVA and correlation analysis were used to examine the relationships of building height to vegetation coverage and building density. We found: (1) The residential areas expanded rapidly and were dominated by outward growth, with much less within-city infilling. The growth rate varied greatly through time, first increasing from 1949–2004 and then decreasing from 2005–2009. The expansion direction of newly built residential neighborhoods shifted from west to north in a clockwise direction. (2) The vertical structure of residential neighborhoods changed with time and varied in space, forming a “low-high” pattern from urban central areas to the urban edges within the 5th ring road of Beijing. (3) The residential neighborhoods built in different time periods had significant differences in vegetation coverage, building density, and building height. The residential neighborhoods built in more recent years tended to have taller buildings, lower building density and lower vegetation coverage.},
DOI = {10.3390/rs9100992}
}



@Article{s17102210,
AUTHOR = {Rivas Casado, Mónica and González, Rocío Ballesteros and Ortega, José Fernando and Leinster, Paul and Wright, Ros},
TITLE = {Towards a Transferable UAV-Based Framework for River Hydromorphological Characterization},
JOURNAL = {Sensors},
VOLUME = {17},
YEAR = {2017},
NUMBER = {10},
ARTICLE-NUMBER = {2210},
URL = {https://www.mdpi.com/1424-8220/17/10/2210},
ISSN = {1424-8220},
ABSTRACT = {The multiple protocols that have been developed to characterize river hydromorphology, partly in response to legislative drivers such as the European Union Water Framework Directive (EU WFD), make the comparison of results obtained in different countries challenging. Recent studies have analyzed the comparability of existing methods, with remote sensing based approaches being proposed as a potential means of harmonizing hydromorphological characterization protocols. However, the resolution achieved by remote sensing products may not be sufficient to assess some of the key hydromorphological features that are required to allow an accurate characterization. Methodologies based on high resolution aerial photography taken from Unmanned Aerial Vehicles (UAVs) have been proposed by several authors as potential approaches to overcome these limitations. Here, we explore the applicability of an existing UAV based framework for hydromorphological characterization to three different fluvial settings representing some of the distinct ecoregions defined by the WFD geographical intercalibration groups (GIGs). The framework is based on the automated recognition of hydromorphological features via tested and validated Artificial Neural Networks (ANNs). Results show that the framework is transferable to the Central-Baltic and Mediterranean GIGs with accuracies in feature identification above 70%. Accuracies of 50% are achieved when the framework is implemented in the Very Large Rivers GIG. The framework successfully identified vegetation, deep water, shallow water, riffles, side bars and shadows for the majority of the reaches. However, further algorithm development is required to ensure a wider range of features (e.g., chutes, structures and erosion) are accurately identified. This study also highlights the need to develop an objective and fit for purpose hydromorphological characterization framework to be adopted within all EU member states to facilitate comparison of results.},
DOI = {10.3390/s17102210}
}



@Article{geosciences7040096,
AUTHOR = {Poux, Florent and Neuville, Romain and Van Wersch, Line and Nys, Gilles-Antoine and Billen, Roland},
TITLE = {3D Point Clouds in Archaeology: Advances in Acquisition, Processing and Knowledge Integration Applied to Quasi-Planar Objects},
JOURNAL = {Geosciences},
VOLUME = {7},
YEAR = {2017},
NUMBER = {4},
ARTICLE-NUMBER = {96},
URL = {https://www.mdpi.com/2076-3263/7/4/96},
ISSN = {2076-3263},
ABSTRACT = {Digital investigations of the real world through point clouds and derivatives are changing how curators, cultural heritage researchers and archaeologists work and collaborate. To progressively aggregate expertise and enhance the working proficiency of all professionals, virtual reconstructions demand adapted tools to facilitate knowledge dissemination. However, to achieve this perceptive level, a point cloud must be semantically rich, retaining relevant information for the end user. In this paper, we review the state of the art of point cloud integration within archaeological applications, giving an overview of 3D technologies for heritage, digital exploitation and case studies showing the assimilation status within 3D GIS. Identified issues and new perspectives are addressed through a knowledge-based point cloud processing framework for multi-sensory data, and illustrated on mosaics and quasi-planar objects. A new acquisition, pre-processing, segmentation and ontology-based classification method on hybrid point clouds from both terrestrial laser scanning and dense image matching is proposed to enable reasoning for information extraction. Experiments in detection and semantic enrichment show promising results of 94% correct semantization. Then, we integrate the metadata in an archaeological smart point cloud data structure allowing spatio-semantic queries related to CIDOC-CRM. Finally, a WebGL prototype is presented that leads to efficient communication between actors by proposing optimal 3D data visualizations as a basis on which interaction can grow.},
DOI = {10.3390/geosciences7040096}
}



@Article{sym9100221,
AUTHOR = {Xu, Jiachen and Liu, Xiao and Ma, Ming and Liu, Anfeng and Wang, Tian and Huang, Changqin},
TITLE = {Intelligent Aggregation Based on Content Routing Scheme for Cloud Computing},
JOURNAL = {Symmetry},
VOLUME = {9},
YEAR = {2017},
NUMBER = {10},
ARTICLE-NUMBER = {221},
URL = {https://www.mdpi.com/2073-8994/9/10/221},
ISSN = {2073-8994},
ABSTRACT = {Cloud computing has emerged as today’s most exciting computing paradigm for providing services using a shared framework, which opens a new door for solving the problems of the explosive growth of digital resource demands and their corresponding convenience. With the exponential growth of the number of data types and data size in so-called big data work, the backbone network is under great pressure due to its transmission capacity, which is lower than the growth of the data size and would seriously hinder the development of the network without an effective approach to solve this problem. In this paper, an Intelligent Aggregation based on a Content Routing (IACR) scheme for cloud computing, which could reduce the amount of data in the network effectively and play a basic supporting role in the development of cloud computing, is first put forward. All in all, the main innovations in this paper are: (1) A framework for intelligent aggregation based on content routing is proposed, which can support aggregation based content routing; (2) The proposed IACR scheme could effectively route the high aggregation ratio data to the data center through the same routing path so as to effectively reduce the amount of data that the network transmits. The theoretical analyses experiments and results show that, compared with the previous original routing scheme, the IACR scheme can balance the load of the whole network, reduce the amount of data transmitted in the network by 41.8%, and reduce the transmission time by 31.6% in the same network with a more balanced network load.},
DOI = {10.3390/sym9100221}
}



@Article{s17112472,
AUTHOR = {Bakr, Muhammad Abu and Lee, Sukhan},
TITLE = {Distributed Multisensor Data Fusion under Unknown Correlation and Data Inconsistency},
JOURNAL = {Sensors},
VOLUME = {17},
YEAR = {2017},
NUMBER = {11},
ARTICLE-NUMBER = {2472},
URL = {https://www.mdpi.com/1424-8220/17/11/2472},
ISSN = {1424-8220},
ABSTRACT = {The paradigm of multisensor data fusion has been evolved from a centralized architecture to a decentralized or distributed architecture along with the advancement in sensor and communication technologies. These days, distributed state estimation and data fusion has been widely explored in diverse fields of engineering and control due to its superior performance over the centralized one in terms of flexibility, robustness to failure and cost effectiveness in infrastructure and communication. However, distributed multisensor data fusion is not without technical challenges to overcome: namely, dealing with cross-correlation and inconsistency among state estimates and sensor data. In this paper, we review the key theories and methodologies of distributed multisensor data fusion available to date with a specific focus on handling unknown correlation and data inconsistency. We aim at providing readers with a unifying view out of individual theories and methodologies by presenting a formal analysis of their implications. Finally, several directions of future research are highlighted.},
DOI = {10.3390/s17112472}
}



@Article{s17112488,
AUTHOR = {Poblete, Tomas and Ortega-Farías, Samuel and Moreno, Miguel Angel and Bardeen, Matthew},
TITLE = {Artificial Neural Network to Predict Vine Water Status Spatial Variability Using Multispectral Information Obtained from an Unmanned Aerial Vehicle (UAV)},
JOURNAL = {Sensors},
VOLUME = {17},
YEAR = {2017},
NUMBER = {11},
ARTICLE-NUMBER = {2488},
URL = {https://www.mdpi.com/1424-8220/17/11/2488},
ISSN = {1424-8220},
ABSTRACT = {Water stress, which affects yield and wine quality, is often evaluated using the midday stem water potential (Ψstem). However, this measurement is acquired on a per plant basis and does not account for the assessment of vine water status spatial variability. The use of multispectral cameras mounted on unmanned aerial vehicle (UAV) is capable to capture the variability of vine water stress in a whole field scenario. It has been reported that conventional multispectral indices (CMI) that use information between 500–800 nm, do not accurately predict plant water status since they are not sensitive to water content. The objective of this study was to develop artificial neural network (ANN) models derived from multispectral images to predict the Ψstem spatial variability of a drip-irrigated Carménère vineyard in Talca, Maule Region, Chile. The coefficient of determination (R2) obtained between ANN outputs and ground-truth measurements of Ψstem were between 0.56–0.87, with the best performance observed for the model that included the bands 550, 570, 670, 700 and 800 nm. Validation analysis indicated that the ANN model could estimate Ψstem with a mean absolute error (MAE) of 0.1 MPa, root mean square error (RMSE) of 0.12 MPa, and relative error (RE) of −9.1%. For the validation of the CMI, the MAE, RMSE and RE values were between 0.26–0.27 MPa, 0.32–0.34 MPa and −24.2–25.6%, respectively.},
DOI = {10.3390/s17112488}
}



@Article{rs9111120,
AUTHOR = {Liu, Xiang and Liu, Huiyu and Gong, Haibo and Lin, Zhenshan and Lv, Shicheng},
TITLE = {Appling the One-Class Classification Method of Maxent to Detect an Invasive Plant Spartina alterniflora with Time-Series Analysis},
JOURNAL = {Remote Sensing},
VOLUME = {9},
YEAR = {2017},
NUMBER = {11},
ARTICLE-NUMBER = {1120},
URL = {https://www.mdpi.com/2072-4292/9/11/1120},
ISSN = {2072-4292},
ABSTRACT = {Spartina alterniflora has become the main invasive plant along the Chinese coast and now threatens the local ecological environment. Accurately monitoring the distribution of S. alterniflora is urgent and essential for developing cost-effective control strategies. In this study, we applied the One-Class Classification (OCC) methods of Maximum entropy (Maxent) and Biased Support Vector Machine (BSVM) based on Landsat time-series imagery to detect the species on the middle coast of Jiangsu in east China. We conducted four experimental setups (i.e., single-scene analysis, time-series analysis, Normalized Difference Vegetation Index (NDVI) time-series analysis and a compressed time-series analysis), using OCC methods to recognize the species. Then, we tested the performance of a compressed time-series model for S. alterniflora detection and evaluated the expansibility of this approach when it was applied to a larger region. Our principal findings are as follows: (1) Maxent and BSVM performed equally well, and Maxent appeared to have a more balanced performance over the summer months; (2) the Maxent model with the Default Parameter Set (Maxent-DPS) showed a slightly higher accuracy and more overfitting than Maxent with the Akaike Information Criterion corrected for small samples sizes (AICc)-selected parameter set model, but a t-test found no significant difference between these two settings; (3) April and December were deemed to be important periods for the detection of S. alterniflora; (4) a compressed time-series analysis model—including only three variables (December NDVI, March green and the third Principal Component in January, PC3)—yielded higher accuracy than single-scene analyses, which indicated that time-series analysis can better detect S. alterniflora than single-scene analyses; and (5) the Maxent model using the reconstructed optimal variables and 70 training samples over a larger region produced encouraging results with an overall accuracy of 90.88% and a Kappa of 0.78. The one-class classification method combined with a phenology-based detection strategy is therefore promising for the application of the long-term detection of S. alterniflora over extended areas.},
DOI = {10.3390/rs9111120}
}



@Article{s17112557,
AUTHOR = {Yamamoto, Kyosuke and Togami, Takashi and Yamaguchi, Norio},
TITLE = {Super-Resolution of Plant Disease Images for the Acceleration of Image-based Phenotyping and Vigor Diagnosis in Agriculture},
JOURNAL = {Sensors},
VOLUME = {17},
YEAR = {2017},
NUMBER = {11},
ARTICLE-NUMBER = {2557},
URL = {https://www.mdpi.com/1424-8220/17/11/2557},
ISSN = {1424-8220},
ABSTRACT = {Unmanned aerial vehicles (UAVs or drones) are a very promising branch of technology, and they have been utilized in agriculture—in cooperation with image processing technologies—for phenotyping and vigor diagnosis. One of the problems in the utilization of UAVs for agricultural purposes is the limitation in flight time. It is necessary to fly at a high altitude to capture the maximum number of plants in the limited time available, but this reduces the spatial resolution of the captured images. In this study, we applied a super-resolution method to the low-resolution images of tomato diseases to recover detailed appearances, such as lesions on plant organs. We also conducted disease classification using high-resolution, low-resolution, and super-resolution images to evaluate the effectiveness of super-resolution methods in disease classification. Our results indicated that the super-resolution method outperformed conventional image scaling methods in spatial resolution enhancement of tomato disease images. The results of disease classification showed that the accuracy attained was also better by a large margin with super-resolution images than with low-resolution images. These results indicated that our approach not only recovered the information lost in low-resolution images, but also exerted a beneficial influence on further image analysis. The proposed approach will accelerate image-based phenotyping and vigor diagnosis in the field, because it not only saves time to capture images of a crop in a cultivation field but also secures the accuracy of these images for further analysis.},
DOI = {10.3390/s17112557}
}



@Article{rs9111130,
AUTHOR = {Weil, Gilad and Lensky, Itamar M. and Resheff, Yehezkel S. and Levin, Noam},
TITLE = {Optimizing the Timing of Unmanned Aerial Vehicle Image Acquisition for Applied Mapping of Woody Vegetation Species Using Feature Selection},
JOURNAL = {Remote Sensing},
VOLUME = {9},
YEAR = {2017},
NUMBER = {11},
ARTICLE-NUMBER = {1130},
URL = {https://www.mdpi.com/2072-4292/9/11/1130},
ISSN = {2072-4292},
ABSTRACT = {Most recent studies relating to the classification of vegetation species on the individual level use cutting-edge sensors and follow a data-driven approach, aimed at maximizing classification accuracy within a relatively small allocated area of optimal conditions. However, this approach does not incorporate cost-benefit considerations or the ability of applying the chosen methodology for applied mapping over larger areas with higher natural heterogeneity. In this study, we present a phenology-based cost-effective approach for optimizing the number and timing of unmanned aerial vehicle (UAV) imagery acquisition, based on a priori near-surface observations. A ground-placed camera was used in order to generate annual time series of nine spectral indices and three color conversions (red, green and blue to hue, saturation and value) in four different East Mediterranean sites that represent different environmental conditions. After outliers’ removal, the time series dataset represented 1852 individuals of 12 common vegetation species and annual herbaceous patches. A feature selection process was used for identifying the optimal dates for species classification in every site. The feature selection can be designed for various objectives, e.g., optimization of overall classification, discrimination between two species, or discrimination of one species from all others. In order to evaluate the a priori findings, a UAV was flown for acquiring five overhead multiband orthomosaics (five bands in the visible-near infrared range based on the five optimal dates identified in the feature selection of the near-surface time series of the previous year. An object-based classification methodology was used for the discrimination of 976 individuals of nine species and annual herbaceous patches in the UAV imagery, and resulted in an average overall accuracy of 85% and an average Kappa coefficient of 0.82. This cost-effective approach has high potential for detailed vegetation mapping, regarding the accessibility of UAV-produced time series, compared to hyper-spectral imagery with high spatial resolution which is more expensive and involves great difficulties in implementation over large areas.},
DOI = {10.3390/rs9111130}
}



@Article{ijgi6110346,
AUTHOR = {Chu, Hone-Jay and Huang, Min-Lang and Tain, Yu-Ching and Yang, Mon-Shieh and Höfle, Bernhard},
TITLE = {Historic Low Wall Detection via Topographic Parameter Images Derived from Fine-Resolution DEM},
JOURNAL = {ISPRS International Journal of Geo-Information},
VOLUME = {6},
YEAR = {2017},
NUMBER = {11},
ARTICLE-NUMBER = {346},
URL = {https://www.mdpi.com/2220-9964/6/11/346},
ISSN = {2220-9964},
ABSTRACT = {Coral walls protect vegetation gardens from strong winds that sweep across Xiji Island, Taiwan Strait for half the year. Topographic parameters based on light detection and ranging (LiDAR)-based high-resolution digital elevation model (DEM) provide obvious correspondence with the expected form of landscape features. The information on slope, curvature, and openness can help identify the location of landscape features. This study applied the automatic landscape line detection to extract historic vegetable garden wall lines from a LiDAR-derived DEM. The three rapid processes used in this study included the derivation of topographic parameters, line extraction, and aggregation. The rules were extracted from a decision tree to check the line detection from multiple topographic parameters. Results show that wall line detection with multiple topographic parameter images is an alternative means of obtaining essential historic wall feature information. Multiple topographic parameters are highly related to low wall feature identification. Furthermore, the accuracy of wall feature detection is 74% compared with manual interpretation. Thus, this study provides rapid wall detection systems with multiple topographic parameters for further historic landscape management.},
DOI = {10.3390/ijgi6110346}
}



@Article{s17112583,
AUTHOR = {Malek, Sami A. and Avanzi, Francesco and Brun-Laguna, Keoma and Maurer, Tessa and Oroza, Carlos A. and Hartsough, Peter C. and Watteyne, Thomas and Glaser, Steven D.},
TITLE = {Real-Time Alpine Measurement System Using Wireless Sensor Networks},
JOURNAL = {Sensors},
VOLUME = {17},
YEAR = {2017},
NUMBER = {11},
ARTICLE-NUMBER = {2583},
URL = {https://www.mdpi.com/1424-8220/17/11/2583},
ISSN = {1424-8220},
ABSTRACT = {Monitoring the snow pack is crucial for many stakeholders, whether for hydro-power optimization, water management or flood control. Traditional forecasting relies on regression methods, which often results in snow melt runoff predictions of low accuracy in non-average years. Existing ground-based real-time measurement systems do not cover enough physiographic variability and are mostly installed at low elevations. We present the hardware and software design of a state-of-the-art distributed Wireless Sensor Network (WSN)-based autonomous measurement system with real-time remote data transmission that gathers data of snow depth, air temperature, air relative humidity, soil moisture, soil temperature, and solar radiation in physiographically representative locations. Elevation, aspect, slope and vegetation are used to select network locations, and distribute sensors throughout a given network location, since they govern snow pack variability at various scales. Three WSNs were installed in the Sierra Nevada of Northern California throughout the North Fork of the Feather River, upstream of the Oroville dam and multiple powerhouses along the river. The WSNs gathered hydrologic variables and network health statistics throughout the 2017 water year, one of northern Sierra’s wettest years on record. These networks leverage an ultra-low-power wireless technology to interconnect their components and offer recovery features, resilience to data loss due to weather and wildlife disturbances and real-time topological visualizations of the network health. Data show considerable spatial variability of snow depth, even within a 1 km     2     network location. Combined with existing systems, these WSNs can better detect precipitation timing and phase in, monitor sub-daily dynamics of infiltration and surface runoff during precipitation or snow melt, and inform hydro power managers about actual ablation and end-of-season date across the landscape.},
DOI = {10.3390/s17112583}
}



@Article{rs9111170,
AUTHOR = {Tang, Tianyu and Zhou, Shilin and Deng, Zhipeng and Lei, Lin and Zou, Huanxin},
TITLE = {Arbitrary-Oriented Vehicle Detection in Aerial Imagery with Single Convolutional Neural Networks},
JOURNAL = {Remote Sensing},
VOLUME = {9},
YEAR = {2017},
NUMBER = {11},
ARTICLE-NUMBER = {1170},
URL = {https://www.mdpi.com/2072-4292/9/11/1170},
ISSN = {2072-4292},
ABSTRACT = {Vehicle detection with orientation estimation in aerial images has received widespread interest as it is important for intelligent traffic management. This is a challenging task, not only because of the complex background and relatively small size of the target, but also the various orientations of vehicles in aerial images captured from the top view. The existing methods for oriented vehicle detection need several post-processing steps to generate final detection results with orientation, which are not efficient enough. Moreover, they can only get discrete orientation information for each target. In this paper, we present an end-to-end single convolutional neural network to generate arbitrarily-oriented detection results directly. Our approach, named Oriented_SSD (Single Shot MultiBox Detector, SSD), uses a set of default boxes with various scales on each feature map location to produce detection bounding boxes. Meanwhile, offsets are predicted for each default box to better match the object shape, which contain the angle parameter for oriented bounding boxes’ generation. Evaluation results on the public DLR Vehicle Aerial dataset and Vehicle Detection in Aerial Imagery (VEDAI) dataset demonstrate that our method can detect both the location and orientation of the vehicle with high accuracy and fast speed. For test images in the DLR Vehicle Aerial dataset with a size of     5616 × 3744    , our method achieves 76.1% average precision (AP) and 78.7% correct direction classification at 5.17 s on an NVIDIA GTX-1060.},
DOI = {10.3390/rs9111170}
}



@Article{rs9111187,
AUTHOR = {Meng, Xuelian and Shang, Nan and Zhang, Xukai and Li, Chunyan and Zhao, Kaiguang and Qiu, Xiaomin and Weeks, Eddie},
TITLE = {Photogrammetric UAV Mapping of Terrain under Dense Coastal Vegetation: An Object-Oriented Classification Ensemble Algorithm for Classification and Terrain Correction},
JOURNAL = {Remote Sensing},
VOLUME = {9},
YEAR = {2017},
NUMBER = {11},
ARTICLE-NUMBER = {1187},
URL = {https://www.mdpi.com/2072-4292/9/11/1187},
ISSN = {2072-4292},
ABSTRACT = {Photogrammetric UAV sees a surge in use for high-resolution mapping, but its use to map terrain under dense vegetation cover remains challenging due to a lack of exposed ground surfaces. This paper presents a novel object-oriented classification ensemble algorithm to leverage height, texture and contextual information of UAV data to improve landscape classification and terrain estimation. Its implementation incorporates multiple heuristics, such as multi-input machine learning-based classification, object-oriented ensemble, and integration of UAV and GPS surveys for terrain correction. Experiments based on a densely vegetated wetland restoration site showed classification improvement from 83.98% to 96.12% in overall accuracy and from 0.7806 to 0.947 in kappa value. Use of standard and existing UAV terrain mapping algorithms and software produced reliable digital terrain model only over exposed bare grounds (mean error = −0.019 m and RMSE = 0.035 m) but severely overestimated the terrain by ~80% of mean vegetation height in vegetated areas. The terrain correction method successfully reduced the mean error from 0.302 m to −0.002 m (RMSE from 0.342 m to 0.177 m) in low vegetation and from 1.305 m to 0.057 m (RMSE from 1.399 m to 0.550 m) in tall vegetation. Overall, this research validated a feasible solution to integrate UAV and RTK GPS for terrain mapping in densely vegetated environments. },
DOI = {10.3390/rs9111187}
}



@Article{s17122720,
AUTHOR = {Zhong, Jiandan and Lei, Tao and Yao, Guangle},
TITLE = {Robust Vehicle Detection in Aerial Images Based on Cascaded Convolutional Neural Networks},
JOURNAL = {Sensors},
VOLUME = {17},
YEAR = {2017},
NUMBER = {12},
ARTICLE-NUMBER = {2720},
URL = {https://www.mdpi.com/1424-8220/17/12/2720},
ISSN = {1424-8220},
ABSTRACT = {Vehicle detection in aerial images is an important and challenging task. Traditionally, many target detection models based on sliding-window fashion were developed and achieved acceptable performance, but these models are time-consuming in the detection phase. Recently, with the great success of convolutional neural networks (CNNs) in computer vision, many state-of-the-art detectors have been designed based on deep CNNs. However, these CNN-based detectors are inefficient when applied in aerial image data due to the fact that the existing CNN-based models struggle with small-size object detection and precise localization. To improve the detection accuracy without decreasing speed, we propose a CNN-based detection model combining two independent convolutional neural networks, where the first network is applied to generate a set of vehicle-like regions from multi-feature maps of different hierarchies and scales. Because the multi-feature maps combine the advantage of the deep and shallow convolutional layer, the first network performs well on locating the small targets in aerial image data. Then, the generated candidate regions are fed into the second network for feature extraction and decision making. Comprehensive experiments are conducted on the Vehicle Detection in Aerial Imagery (VEDAI) dataset and Munich vehicle dataset. The proposed cascaded detection model yields high performance, not only in detection accuracy but also in detection speed.},
DOI = {10.3390/s17122720}
}



@Article{s17122726,
AUTHOR = {Su, Jinya and Yi, Dewei and Liu, Cunjia and Guo, Lei and Chen, Wen-Hua},
TITLE = {Dimension Reduction Aided Hyperspectral Image Classification with a Small-sized Training Dataset: Experimental Comparisons},
JOURNAL = {Sensors},
VOLUME = {17},
YEAR = {2017},
NUMBER = {12},
ARTICLE-NUMBER = {2726},
URL = {https://www.mdpi.com/1424-8220/17/12/2726},
ISSN = {1424-8220},
ABSTRACT = {Hyperspectral images (HSI) provide rich information which may not be captured by other sensing technologies and therefore gradually find a wide range of applications. However, they also generate a large amount of irrelevant or redundant data for a specific task. This causes a number of issues including significantly increased computation time, complexity and scale of prediction models mapping the data to semantics (e.g., classification), and the need of a large amount of labelled data for training. Particularly, it is generally difficult and expensive for experts to acquire sufficient training samples in many applications. This paper addresses these issues by exploring a number of classical dimension reduction algorithms in machine learning communities for HSI classification. To reduce the size of training dataset, feature selection (e.g., mutual information, minimal redundancy maximal relevance) and feature extraction (e.g., Principal Component Analysis (PCA), Kernel PCA) are adopted to augment a baseline classification method, Support Vector Machine (SVM). The proposed algorithms are evaluated using a real HSI dataset. It is shown that PCA yields the most promising performance in reducing the number of features or spectral bands. It is observed that while significantly reducing the computational complexity, the proposed method can achieve better classification results over the classic SVM on a small training dataset, which makes it suitable for real-time applications or when only limited training data are available. Furthermore, it can also achieve performances similar to the classic SVM on large datasets but with much less computing time.},
DOI = {10.3390/s17122726}
}



@Article{ijerph14121463,
AUTHOR = {Suh, Jangwon and Kim, Sung-Min and Yi, Huiuk and Choi, Yosoon},
TITLE = {An Overview of GIS-Based Modeling and Assessment of Mining-Induced Hazards: Soil, Water, and Forest},
JOURNAL = {International Journal of Environmental Research and Public Health},
VOLUME = {14},
YEAR = {2017},
NUMBER = {12},
ARTICLE-NUMBER = {1463},
URL = {https://www.mdpi.com/1660-4601/14/12/1463},
PubMedID = {29186922},
ISSN = {1660-4601},
ABSTRACT = {In this study, current geographic information system (GIS)-based methods and their application for the modeling and assessment of mining-induced hazards were reviewed. Various types of mining-induced hazard, including soil contamination, soil erosion, water pollution, and deforestation were considered in the discussion of the strength and role of GIS as a viable problem-solving tool in relation to mining-induced hazards. The various types of mining-induced hazard were classified into two or three subtopics according to the steps involved in the reclamation procedure, or elements of the hazard of interest. Because GIS is appropriated for the handling of geospatial data in relation to mining-induced hazards, the application and feasibility of exploiting GIS-based modeling and assessment of mining-induced hazards within the mining industry could be expanded further.},
DOI = {10.3390/ijerph14121463}
}



@Article{geosciences7040123,
AUTHOR = {Armenakis, Costas and Du, Erin Xinheng and Natesan, Sowmya and Persad, Ravi Ancil and Zhang, Ying},
TITLE = {Flood Risk Assessment in Urban Areas Based on Spatial Analytics and Social Factors},
JOURNAL = {Geosciences},
VOLUME = {7},
YEAR = {2017},
NUMBER = {4},
ARTICLE-NUMBER = {123},
URL = {https://www.mdpi.com/2076-3263/7/4/123},
ISSN = {2076-3263},
ABSTRACT = {Flood maps alone are not sufficient to determine and assess the risks to people, property, infrastructure, and services due to a flood event. Simply put, the risk is almost zero to minimum if the flooded region is “empty” (i.e., unpopulated, has not properties, no industry, no infrastructure, and no socio-economic activity). High spatial resolution Earth Observation (EO) data can contribute to the generation and updating of flood risk maps based on several aspects including population, economic development, and critical infrastructure, which can enhance a city’s flood mitigation and preparedness planning. In this case study for the Don River watershed, Toronto, the flood risk is determined and flood risk index maps are generated by implementing a methodology for estimating risk based on the geographic coverage of the flood hazard, vulnerability of people, and the exposure of large building structures to flood water. Specifically, the spatial flood risk index maps have been generated through analytical spatial modeling which takes into account the areas in which a flood hazard is expected to occur, the terrain’s morphological characteristics, socio-economic parameters based on demographic data, and the density of large building complexes. Generated flood risk maps are verified through visual inspection with 3D city flood maps. Findings illustrate that areas of higher flood risk coincide with areas of high flood hazard and social and building exposure vulnerability.},
DOI = {10.3390/geosciences7040123}
}



@Article{rs9121244,
AUTHOR = {Chen, Suting and Li, Xin and Zhang, Yanyan and Feng, Rui and Zhang, Chuang},
TITLE = {Local Deep Hashing Matching of Aerial Images Based on Relative Distance and Absolute Distance Constraints},
JOURNAL = {Remote Sensing},
VOLUME = {9},
YEAR = {2017},
NUMBER = {12},
ARTICLE-NUMBER = {1244},
URL = {https://www.mdpi.com/2072-4292/9/12/1244},
ISSN = {2072-4292},
ABSTRACT = {Aerial images have features of high resolution, complex background, and usually require large amounts of calculation, however, most algorithms used in matching of aerial images adopt the shallow hand-crafted features expressed as floating-point descriptors (e.g., SIFT (Scale-invariant Feature Transform), SURF (Speeded Up Robust Features)), which may suffer from poor matching speed and are not well represented in the literature. Here, we propose a novel Local Deep Hashing Matching (LDHM) method for matching of aerial images with large size and with lower complexity or fast matching speed. The basic idea of the proposed algorithm is to utilize the deep network model in the local area of the aerial images, and study the local features, as well as the hash function of the images. Firstly, according to the course overlap rate of aerial images, the algorithm extracts the local areas for matching to avoid the processing of redundant information. Secondly, a triplet network structure is proposed to mine the deep features of the patches of the local image, and the learned features are imported to the hash layer, thus obtaining the representation of a binary hash code. Thirdly, the constraints of the positive samples to the absolute distance are added on the basis of the triplet loss, a new objective function is constructed to optimize the parameters of the network and enhance the discriminating capabilities of image patch features. Finally, the obtained deep hash code of each image patch is used for the similarity comparison of the image patches in the Hamming space to complete the matching of aerial images. The proposed LDHM algorithm evaluates the UltraCam-D dataset and a set of actual aerial images, simulation result demonstrates that it may significantly outperform the state-of-the-art algorithm in terms of the efficiency and performance.},
DOI = {10.3390/rs9121244}
}



@Article{s17122852,
AUTHOR = {Klosterman, Stephen and Richardson, Andrew D.},
TITLE = {Observing Spring and Fall Phenology in a Deciduous Forest with Aerial Drone Imagery},
JOURNAL = {Sensors},
VOLUME = {17},
YEAR = {2017},
NUMBER = {12},
ARTICLE-NUMBER = {2852},
URL = {https://www.mdpi.com/1424-8220/17/12/2852},
ISSN = {1424-8220},
ABSTRACT = {Plant phenology is a sensitive indicator of the effects of global change on terrestrial ecosystems and controls the timing of key ecosystem functions including photosynthesis and transpiration. Aerial drone imagery and photogrammetric techniques promise to advance the study of phenology by enabling the creation of distortion-free orthomosaics of plant canopies at the landscape scale, but with branch-level image resolution. The main goal of this study is to determine the leaf life cycle events corresponding to phenological metrics derived from automated analyses based on color indices calculated from drone imagery. For an oak-dominated, temperate deciduous forest in the northeastern USA, we find that plant area index (PAI) correlates with a canopy greenness index during spring green-up, and a canopy redness index during autumn senescence. Additionally, greenness and redness metrics are significantly correlated with the timing of budburst and leaf expansion on individual trees in spring. However, we note that the specific color index for individual trees must be carefully chosen if new foliage in spring appears red, rather than green—which we observed for some oak trees. In autumn, both decreasing greenness and increasing redness correlate with leaf senescence. Maximum redness indicates the beginning of leaf fall, and the progression of leaf fall correlates with decreasing redness. We also find that cooler air temperature microclimates near a forest edge bordering a wetland advance the onset of senescence. These results demonstrate the use of drones for characterizing the organismic-level variability of phenology in a forested landscape and advance our understanding of which phenophase transitions correspond to color-based metrics derived from digital image analysis.},
DOI = {10.3390/s17122852}
}



@Article{rs9121279,
AUTHOR = {Nevalainen, Paavo and Salmivaara, Aura and Ala-Ilomäki, Jari and Launiainen, Samuli and Hiedanpää, Juuso and Finér, Leena and Pahikkala, Tapio and Heikkonen, Jukka},
TITLE = {Estimating the Rut Depth by UAV Photogrammetry},
JOURNAL = {Remote Sensing},
VOLUME = {9},
YEAR = {2017},
NUMBER = {12},
ARTICLE-NUMBER = {1279},
URL = {https://www.mdpi.com/2072-4292/9/12/1279},
ISSN = {2072-4292},
ABSTRACT = {The rut formation during forest operations is an undesirable phenomenon. A methodology is being proposed to measure the rut depth distribution of a logging site by photogrammetric point clouds produced by unmanned aerial vehicles (UAV). The methodology includes five processing steps that aim at reducing the noise from the surrounding trees and undergrowth for identifying the trails. A canopy height model is produced to focus the point cloud on the open pathway around the forest machine trail. A triangularized ground model is formed by a point cloud filtering method. The ground model is vectorized using the histogram of directed curvatures (HOC) method to produce an overall ground visualization. Finally, a manual selection of the trails leads to an automated rut depth profile analysis. The bivariate correlation (Pearson’s r) between rut depths measured manually and by UAV photogrammetry is     r = 0.67    . The two-class accuracy a of detecting the rut depth exceeding 20 cm is     a = 0.65    . There is potential for enabling automated large-scale evaluation of the forestry areas by using autonomous drones and the process described.},
DOI = {10.3390/rs9121279}
}



@Article{fi9040094,
AUTHOR = {Qadir, Junaid and Sathiaseelan, Arjuna and Farooq, Umar Bin and Usama, Muhammad and Imran, Muhammad Ali and Shafique, Muhammad},
TITLE = {Approximate Networking for Universal Internet Access},
JOURNAL = {Future Internet},
VOLUME = {9},
YEAR = {2017},
NUMBER = {4},
ARTICLE-NUMBER = {94},
URL = {https://www.mdpi.com/1999-5903/9/4/94},
ISSN = {1999-5903},
ABSTRACT = {Despite the best efforts of networking researchers and practitioners, an ideal Internet experience is inaccessible to an overwhelming majority of people the world over, mainly due to the lack of cost-efficient ways of provisioning high-performance, global Internet. In this paper, we argue that instead of an exclusive focus on a utopian goal of universally accessible “ideal networking” (in which we have a high throughput and quality of service as well as low latency and congestion), we should consider providing “approximate networking” through the adoption of context-appropriate trade-offs. In this regard, we propose to leverage the advances in the emerging trend of “approximate computing” that rely on relaxing the bounds of precise/exact computing to provide new opportunities for improving the area, power, and performance efficiency of systems by orders of magnitude by embracing output errors in resilient applications. Furthermore, we propose to extend the dimensions of approximate computing towards various knobs available at network layers. Approximate networking can be used to provision “Global Access to the Internet for All” (GAIA) in a pragmatically tiered fashion, in which different users around the world are provided a different context-appropriate (but still contextually functional) Internet experience.},
DOI = {10.3390/fi9040094}
}



@Article{app7121294,
AUTHOR = {Valiente, David and Gil, Arturo and Payá, Luis and Sebastián, Jose M. and Reinoso, Óscar},
TITLE = {Robust Visual Localization with Dynamic Uncertainty Management in Omnidirectional SLAM},
JOURNAL = {Applied Sciences},
VOLUME = {7},
YEAR = {2017},
NUMBER = {12},
ARTICLE-NUMBER = {1294},
URL = {https://www.mdpi.com/2076-3417/7/12/1294},
ISSN = {2076-3417},
ABSTRACT = {This work presents a robust visual localization technique based on an omnidirectional monocular sensor for mobile robotics applications. We intend to overcome the non-linearities and instabilities that the camera projection systems typically introduce, which are especially relevant in catadioptric sensors. In this paper, we come up with several contributions. First, a novel strategy for the uncertainty management is developed, which accounts for a realistic visual localization technique, since it dynamically encodes the instantaneous variations and drifts on the uncertainty, by defining an information metric of the system. Secondly, an epipolar constraint adaption to the omnidirectional geometry reference is devised. Thirdly, Bayesian considerations are also implemented, in order to produce a final global metric for a consistent feature matching between images. The resulting outcomes are supported by real data experiments performed with publicly-available datasets, in order to assess the suitability of the approach and to confirm the reliability of the main contributions. Besides localization results, real visual SLAM (Simultaneous Localization and Mapping) comparison experiments with acknowledged methods are also presented, by using a public dataset and benchmark framework.},
DOI = {10.3390/app7121294}
}



@Article{rs9121332,
AUTHOR = {Liang, Hui and Huang, Xiaodong and Sun, Yanhua and Wang, Yunlong and Liang, Tiangang},
TITLE = {Fractional Snow-Cover Mapping Based on MODIS and UAV Data over the Tibetan Plateau},
JOURNAL = {Remote Sensing},
VOLUME = {9},
YEAR = {2017},
NUMBER = {12},
ARTICLE-NUMBER = {1332},
URL = {https://www.mdpi.com/2072-4292/9/12/1332},
ISSN = {2072-4292},
ABSTRACT = {Moderate-resolution imaging spectroradiometer (MODIS) snow-cover products have relatively low accuracy over the Tibetan Plateau because of its complex terrain and shallow, fragmented snow cover. In this study, fractional snow-cover (FSC) mapping algorithms were developed using a linear regression model (LR), a linear spectral mixture analysis model (LSMA) and a back-propagation artificial neural network model (BP-ANN) based on MODIS data (version 006) and unmanned aerial vehicle (UAV) data. The accuracies of the three models were validated against Landsat 8 Operational Land Imager (OLI) snow-cover maps (Landsat 8 FSC) and compared with the MODIS global FSC product (MOD10A1 FSC, version 005) for the purpose of finding the optimal algorithm for FSC extraction for the Tibetan Plateau. The results showed that (1) the overall retrieval results of the LR and BP-ANN models based on MODIS and UAV data were relatively similar to the OLI snow-cover maps; the accuracy and stability were greatly improved, with even some reduction in errors; compared to the Landsat 8 FSC, the correlation coefficients (r) were 0.8222 and 0.8445 respectively and the root-mean-square errors (RMSEs) were 0.2304 and 0.2201, respectively. (2) The accuracy and stability of the fully constrained LSMA model using the pixel purity index (PPI) endmember extraction method based only on MODIS data suffered the worst performance of the three models; r was only 0.7921 and the RMSE was as large as 0.3485. There were some serious omission phenomena in the study area, specifically for the largest mean absolute error (MAE = 0.2755) and positive mean error (PME = 0.3411). (3) The accuracy of the MOD10A1 FSC product was much lower than that of the LR and BP-ANN models, although its accuracy slightly better that of the LSMA based on comprehensive evaluation of six accuracy indices. (4) The optimal model was the BP-ANN model with combined inputs of surface reflectivity data (R1–R7), elevation (DEM) and temperature (LST), which can easily incorporate auxiliary information (DEM and LST) on the basis of (R1–R7) during the relationship training period and can effectively improve the accuracy of snow area monitoring—it is the ideal algorithm for retrieving FSC for the Tibetan Plateau.},
DOI = {10.3390/rs9121332}
}



@Article{rs10010015,
AUTHOR = {Chen, Weitao and Li, Xianju and He, Haixia and Wang, Lizhe},
TITLE = {A Review of Fine-Scale Land Use and Land Cover Classification in Open-Pit Mining Areas by Remote Sensing Techniques},
JOURNAL = {Remote Sensing},
VOLUME = {10},
YEAR = {2018},
NUMBER = {1},
ARTICLE-NUMBER = {15},
URL = {https://www.mdpi.com/2072-4292/10/1/15},
ISSN = {2072-4292},
ABSTRACT = {Over recent decades, fine-scale land use and land cover classification in open-pit mine areas (LCCMA) has become very important for understanding the influence of mining activities on the regional geo-environment, and for environmental impact assessment procedure. This research reviews advances in fine-scale LCCMA from the following aspects. Firstly, it analyzes and proposes classification thematic resolution for LCCMA. Secondly, remote sensing data sources, features, feature selection methods, and classification algorithms for LCCMA are summarized. Thirdly, three major factors that affect LCCMA are discussed: significant three-dimensional terrain features, strong LCCMA feature variability, and homogeneity of spectral-spatial features. Correspondingly, three key scientific issues that limit the accuracy of LCCMA are presented. Finally, several future research directions are discussed: (1) unitization of new sensors, particularly those with stereo survey ability; (2) procurement of sensitive features by new sensors and combinations of sensitive features using novel feature selection methods; (3) development of robust and self-adjusted classification algorithms, such as ensemble learning and deep learning for LCCMA; and (4) application of fine-scale mining information for regularity and management of mines.},
DOI = {10.3390/rs10010015}
}



@Article{rs10010066,
AUTHOR = {Yue, Jibo and Feng, Haikuan and Yang, Guijun and Li, Zhenhai},
TITLE = {A Comparison of Regression Techniques for Estimation of Above-Ground Winter Wheat Biomass Using Near-Surface Spectroscopy},
JOURNAL = {Remote Sensing},
VOLUME = {10},
YEAR = {2018},
NUMBER = {1},
ARTICLE-NUMBER = {66},
URL = {https://www.mdpi.com/2072-4292/10/1/66},
ISSN = {2072-4292},
ABSTRACT = {Above-ground biomass (AGB) provides a vital link between solar energy consumption and yield, so its correct estimation is crucial to accurately monitor crop growth and predict yield. In this work, we estimate AGB by using 54 vegetation indexes (e.g., Normalized Difference Vegetation Index, Soil-Adjusted Vegetation Index) and eight statistical regression techniques: artificial neural network (ANN), multivariable linear regression (MLR), decision-tree regression (DT), boosted binary regression tree (BBRT), partial least squares regression (PLSR), random forest regression (RF), support vector machine regression (SVM), and principal component regression (PCR), which are used to analyze hyperspectral data acquired by using a field spectrophotometer. The vegetation indexes (VIs) determined from the spectra were first used to train regression techniques for modeling and validation to select the best VI input, and then summed with white Gaussian noise to study how remote sensing errors affect the regression techniques. Next, the VIs were divided into groups of different sizes by using various sampling methods for modeling and validation to test the stability of the techniques. Finally, the AGB was estimated by using a leave-one-out cross validation with these powerful techniques. The results of the study demonstrate that, of the eight techniques investigated, PLSR and MLR perform best in terms of stability and are most suitable when high-accuracy and stable estimates are required from relatively few samples. In addition, RF is extremely robust against noise and is best suited to deal with repeated observations involving remote-sensing data (i.e., data affected by atmosphere, clouds, observation times, and/or sensor noise). Finally, the leave-one-out cross-validation method indicates that PLSR provides the highest accuracy (R2 = 0.89, RMSE = 1.20 t/ha, MAE = 0.90 t/ha, NRMSE = 0.07, CV (RMSE) = 0.18); thus, PLSR is best suited for works requiring high-accuracy estimation models. The results indicate that all these techniques provide impressive accuracy. The comparison and analysis provided herein thus reveals the advantages and disadvantages of the ANN, MLR, DT, BBRT, PLSR, RF, SVM, and PCR techniques and can help researchers to build efficient AGB-estimation models.},
DOI = {10.3390/rs10010066}
}



@Article{s18010156,
AUTHOR = {Li, Hongguang and Shi, Yang and Zhang, Baochang and Wang, Yufeng},
TITLE = {Superpixel-Based Feature for Aerial Image Scene Recognition},
JOURNAL = {Sensors},
VOLUME = {18},
YEAR = {2018},
NUMBER = {1},
ARTICLE-NUMBER = {156},
URL = {https://www.mdpi.com/1424-8220/18/1/156},
ISSN = {1424-8220},
ABSTRACT = {Image scene recognition is a core technology for many aerial remote sensing applications. Different landforms are inputted as different scenes in aerial imaging, and all landform information is regarded as valuable for aerial image scene recognition. However, the conventional features of the Bag-of-Words model are designed using local points or other related information and thus are unable to fully describe landform areas. This limitation cannot be ignored when the aim is to ensure accurate aerial scene recognition. A novel superpixel-based feature is proposed in this study to characterize aerial image scenes. Then, based on the proposed feature, a scene recognition method of the Bag-of-Words model for aerial imaging is designed. The proposed superpixel-based feature that utilizes landform information establishes top-task superpixel extraction of landforms to bottom-task expression of feature vectors. This characterization technique comprises the following steps: simple linear iterative clustering based superpixel segmentation, adaptive filter bank construction, Lie group-based feature quantification, and visual saliency model-based feature weighting. Experiments of image scene recognition are carried out using real image data captured by an unmanned aerial vehicle (UAV). The recognition accuracy of the proposed superpixel-based feature is 95.1%, which is higher than those of scene recognition algorithms based on other local features.},
DOI = {10.3390/s18010156}
}



@Article{rs10010085,
AUTHOR = {Berger, Katja and Atzberger, Clement and Danner, Martin and D’Urso, Guido and Mauser, Wolfram and Vuolo, Francesco and Hank, Tobias},
TITLE = {Evaluation of the PROSAIL Model Capabilities for Future Hyperspectral Model Environments: A Review Study},
JOURNAL = {Remote Sensing},
VOLUME = {10},
YEAR = {2018},
NUMBER = {1},
ARTICLE-NUMBER = {85},
URL = {https://www.mdpi.com/2072-4292/10/1/85},
ISSN = {2072-4292},
ABSTRACT = {Upcoming satellite hyperspectral sensors require powerful and robust methodologies for making optimum use of the rich spectral data. This paper reviews the widely applied coupled PROSPECT and SAIL radiative transfer models (PROSAIL), regarding their suitability for the retrieval of biophysical and biochemical variables in the context of agricultural crop monitoring. Evaluation was carried out using a systematic literature review of 281 scientific publications with regard to their (i) spectral exploitation, (ii) vegetation type analyzed, (iii) variables retrieved, and (iv) choice of retrieval methods. From the analysis, current trends were derived, and problems identified and discussed. Our analysis clearly shows that the PROSAIL model is well suited for the analysis of imaging spectrometer data from future satellite missions and that the model should be integrated in appropriate software tools that are being developed in this context for agricultural applications. The review supports the decision of potential users to employ PROSAIL for their specific data analysis and provides guidelines for choosing between the diverse retrieval techniques.},
DOI = {10.3390/rs10010085}
}



@Article{rs10010072,
AUTHOR = {Kim, Sungho and Song, Woo-Jin and Kim, So-Hyun},
TITLE = {Double Weight-Based SAR and Infrared Sensor Fusion for Automatic Ground Target Recognition with Deep Learning},
JOURNAL = {Remote Sensing},
VOLUME = {10},
YEAR = {2018},
NUMBER = {1},
ARTICLE-NUMBER = {72},
URL = {https://www.mdpi.com/2072-4292/10/1/72},
ISSN = {2072-4292},
ABSTRACT = {This paper presents a novel double weight-based synthetic aperture radar (SAR) and infrared (IR) sensor fusion method (DW-SIF) for automatic ground target recognition (ATR). IR-based ATR can provide accurate recognition because of its high image resolution but it is affected by the weather conditions. On the other hand, SAR-based ATR shows a low recognition rate due to the noisy low resolution but can provide consistent performance regardless of the weather conditions. The fusion of an active sensor (SAR) and a passive sensor (IR) can lead to upgraded performance. This paper proposes a doubly weighted neural network fusion scheme at the decision level. The first weight (   α   ) can measure the offline sensor confidence per target category based on the classification rate for an evaluation set. The second weight (   β   ) can measure the online sensor reliability based on the score distribution for a test target image. The LeNet architecture-based deep convolution network (14 layers) is used as an individual classifier. Doubly weighted sensor scores are fused by two types of fusion schemes, such as the sum-based linear fusion scheme (    α β    -sum) and neural network-based nonlinear fusion scheme (    α β    -NN). The experimental results confirmed the proposed linear fusion method (    α β    -sum) to have the best performance among the linear fusion schemes available (SAR-CNN, IR-CNN,    α   -sum,    β   -sum,     α β    -sum, and Bayesian fusion). In addition, the proposed nonlinear fusion method (    α β    -NN) showed superior target recognition performance to linear fusion on the OKTAL-SE-based synthetic database.},
DOI = {10.3390/rs10010072}
}



@Article{rs10010089,
AUTHOR = {Cao, Jingjing and Leng, Wanchun and Liu, Kai and Liu, Lin and He, Zhi and Zhu, Yuanhui},
TITLE = {Object-Based Mangrove Species Classification Using Unmanned Aerial Vehicle Hyperspectral Images and Digital Surface Models},
JOURNAL = {Remote Sensing},
VOLUME = {10},
YEAR = {2018},
NUMBER = {1},
ARTICLE-NUMBER = {89},
URL = {https://www.mdpi.com/2072-4292/10/1/89},
ISSN = {2072-4292},
ABSTRACT = {Mangroves are one of the most important coastal wetland ecosystems, and the compositions and distributions of mangrove species are essential for conservation and restoration efforts. Many studies have explored this topic using remote sensing images that were obtained by satellite-borne and airborne sensors, which are known to be efficient for monitoring the mangrove ecosystem. With improvements in carrier platforms and sensor technology, unmanned aerial vehicles (UAVs) with high-resolution hyperspectral images in both spectral and spatial domains have been used to monitor crops, forests, and other landscapes of interest. This study aims to classify mangrove species on Qi’ao Island using object-based image analysis techniques based on UAV hyperspectral images obtained from a commercial hyperspectral imaging sensor (UHD 185) onboard a UAV platform. First, the image objects were obtained by segmenting the UAV hyperspectral image and the UAV-derived digital surface model (DSM) data. Second, spectral features, textural features, and vegetation indices (VIs) were extracted from the UAV hyperspectral image, and the UAV-derived DSM data were used to extract height information. Third, the classification and regression tree (CART) method was used to selection bands, and the correlation-based feature selection (CFS) algorithm was employed for feature reduction. Finally, the objects were classified into different mangrove species and other land covers based on their spectral and spatial characteristic differences. The classification results showed that when considering the three features (spectral features, textural features, and hyperspectral VIs), the overall classification accuracies of the two classifiers used in this paper, i.e., k-nearest neighbor (KNN) and support vector machine (SVM), were 76.12% (Kappa = 0.73) and 82.39% (Kappa = 0.801), respectively. After incorporating tree height into the classification features, the accuracy of species classification increased, and the overall classification accuracies of KNN and SVM reached 82.09% (Kappa = 0.797) and 88.66% (Kappa = 0.871), respectively. It is clear that SVM outperformed KNN for mangrove species classification. These results also suggest that height information is effective for discriminating mangrove species with similar spectral signatures, but different heights. In addition, the classification accuracy and performance of SVM can be further improved by feature reduction. The overall results provided evidence for the effectiveness and potential of UAV hyperspectral data for mangrove species identification.},
DOI = {10.3390/rs10010089}
}



@Article{s18010225,
AUTHOR = {Qu, Yufu and Huang, Jianyu and Zhang, Xuan},
TITLE = {Rapid 3D Reconstruction for Image Sequence Acquired from UAV Camera},
JOURNAL = {Sensors},
VOLUME = {18},
YEAR = {2018},
NUMBER = {1},
ARTICLE-NUMBER = {225},
URL = {https://www.mdpi.com/1424-8220/18/1/225},
ISSN = {1424-8220},
ABSTRACT = {In order to reconstruct three-dimensional (3D) structures from an image sequence captured by unmanned aerial vehicles’ camera (UAVs) and improve the processing speed, we propose a rapid 3D reconstruction method that is based on an image queue, considering the continuity and relevance of UAV camera images. The proposed approach first compresses the feature points of each image into three principal component points by using the principal component analysis method. In order to select the key images suitable for 3D reconstruction, the principal component points are used to estimate the interrelationships between images. Second, these key images are inserted into a fixed-length image queue. The positions and orientations of the images are calculated, and the 3D coordinates of the feature points are estimated using weighted bundle adjustment. With this structural information, the depth maps of these images can be calculated. Next, we update the image queue by deleting some of the old images and inserting some new images into the queue, and a structural calculation of all the images can be performed by repeating the previous steps. Finally, a dense 3D point cloud can be obtained using the depth–map fusion method. The experimental results indicate that when the texture of the images is complex and the number of images exceeds 100, the proposed method can improve the calculation speed by more than a factor of four with almost no loss of precision. Furthermore, as the number of images increases, the improvement in the calculation speed will become more noticeable.},
DOI = {10.3390/s18010225}
}



@Article{urbansci2010008,
AUTHOR = {Mahabir, Ron and Croitoru, Arie and Crooks, Andrew T. and Agouris, Peggy and Stefanidis, Anthony},
TITLE = {A Critical Review of High and Very High-Resolution Remote Sensing Approaches for Detecting and Mapping Slums: Trends, Challenges and Emerging Opportunities},
JOURNAL = {Urban Science},
VOLUME = {2},
YEAR = {2018},
NUMBER = {1},
ARTICLE-NUMBER = {8},
URL = {https://www.mdpi.com/2413-8851/2/1/8},
ISSN = {2413-8851},
ABSTRACT = {Slums are a global urban challenge, with less developed countries being particularly impacted. To adequately detect and map them, data is needed on their location, spatial extent and evolution. High- and very high-resolution remote sensing imagery has emerged as an important source of data in this regard. The purpose of this paper is to critically review studies that have used such data to detect and map slums. Our analysis shows that while such studies have been increasing over time, they tend to be concentrated to a few geographical areas and often focus on the use of a single approach (e.g., image texture and object-based image analysis), thus limiting generalizability to understand slums, their population, and evolution within the global context. We argue that to develop a more comprehensive framework that can be used to detect and map slums, other emerging sourcing of geospatial data should be considered (e.g., volunteer geographic information) in conjunction with growing trends and advancements in technology (e.g., geosensor networks). Through such data integration and analysis we can then create a benchmark for determining the most suitable methods for mapping slums in a given locality, thus fostering the creation of new approaches to address this challenge.},
DOI = {10.3390/urbansci2010008}
}



@Article{rs10020202,
AUTHOR = {Loggenberg, Kyle and Strever, Albert and Greyling, Berno and Poona, Nitesh},
TITLE = {Modelling Water Stress in a Shiraz Vineyard Using Hyperspectral Imaging and Machine Learning},
JOURNAL = {Remote Sensing},
VOLUME = {10},
YEAR = {2018},
NUMBER = {2},
ARTICLE-NUMBER = {202},
URL = {https://www.mdpi.com/2072-4292/10/2/202},
ISSN = {2072-4292},
ABSTRACT = {The detection of water stress in vineyards plays an integral role in the sustainability of high-quality grapes and prevention of devastating crop loses. Hyperspectral remote sensing technologies combined with machine learning provides a practical means for modelling vineyard water stress. In this study, we applied two ensemble learners, i.e., random forest (RF) and extreme gradient boosting (XGBoost), for discriminating stressed and non-stressed Shiraz vines using terrestrial hyperspectral imaging. Additionally, we evaluated the utility of a spectral subset of wavebands, derived using RF mean decrease accuracy (MDA) and XGBoost gain. Our results show that both ensemble learners can effectively analyse the hyperspectral data. When using all wavebands (p = 176), RF produced a test accuracy of 83.3% (KHAT (kappa analysis) = 0.67), and XGBoost a test accuracy of 80.0% (KHAT = 0.6). Using the subset of wavebands (p = 18) produced slight increases in accuracy ranging from 1.7% to 5.5% for both RF and XGBoost. We further investigated the effect of smoothing the spectral data using the Savitzky-Golay filter. The results indicated that the Savitzky-Golay filter reduced model accuracies (ranging from 0.7% to 3.3%). The results demonstrate the feasibility of terrestrial hyperspectral imagery and machine learning to create a semi-automated framework for vineyard water stress modelling.},
DOI = {10.3390/rs10020202}
}



@Article{rs10020206,
AUTHOR = {Zhang, Wangfei and Chen, Erxue and Li, Zengyuan and Zhao, Lei and Ji, Yongjie and Zhang, Yahong and Liu, Zhiqin},
TITLE = {Rape (Brassica napus L.) Growth Monitoring and Mapping Based on Radarsat-2 Time-Series Data},
JOURNAL = {Remote Sensing},
VOLUME = {10},
YEAR = {2018},
NUMBER = {2},
ARTICLE-NUMBER = {206},
URL = {https://www.mdpi.com/2072-4292/10/2/206},
ISSN = {2072-4292},
ABSTRACT = {In this study, 27 polarimetric parameters were extracted from Radarsat-2 polarimetric synthetic aperture radar (SAR) at each growth stage of the rape crop. The sensitivity to growth parameters such as stem height, leaf area index (LAI), and biomass were investigated as a function of days after sowing. Based on the sensitivity analysis, five empirical regression models were compared to determine the best model for stem height, LAI, and biomass inversion. Of these five models, quadratic models had higher R2 values than other models in most cases of growth parameter inversions, but when these results were related to physical scattering mechanisms, the inversion results produced overestimation in the performance of some parameters. By contrast, linear and logarithmic models, which had lower R2 values than the quadratic models, had stable performance for growth parameter inversions, particularly in terms of their performance at each growth stage. The best biomass inversion performance was acquired by the volume component of a quadratic model, with an R2 value of 0.854 and root mean square error (RMSE) of 109.93 g m−2. The best LAI inversion was also acquired by a quadratic model, but used the radar vegetation index (Cloude), with an R2 value of 0.8706 and RMSE of 0.56 m2 m−2. Stem height was acquired by scattering angle alpha (   α   ) using a logarithmic model, with an R2 of 0.926 value and RMSE of 11.09 cm. The performances of these models were also analysed for biomass estimation at the second growth stage (P2), third growth stage (P3), and fourth growth stage (P4). The results showed that the models built at the P3 stage had better substitutability with the models built during all of the growth stages. From the mapping results, we conclude that a model built at the P3 stage can be used for rape biomass inversion, with 90% of estimation errors being less than 100 g m−2.},
DOI = {10.3390/rs10020206}
}



@Article{s18020441,
AUTHOR = {Behmann, Jan and Acebron, Kelvin and Emin, Dzhaner and Bennertz, Simon and Matsubara, Shizue and Thomas, Stefan and Bohnenkamp, David and Kuska, Matheus T. and Jussila, Jouni and Salo, Harri and Mahlein, Anne-Katrin and Rascher, Uwe},
TITLE = {Specim IQ: Evaluation of a New, Miniaturized Handheld Hyperspectral Camera and Its Application for Plant Phenotyping and Disease Detection},
JOURNAL = {Sensors},
VOLUME = {18},
YEAR = {2018},
NUMBER = {2},
ARTICLE-NUMBER = {441},
URL = {https://www.mdpi.com/1424-8220/18/2/441},
ISSN = {1424-8220},
ABSTRACT = {Hyperspectral imaging sensors are promising tools for monitoring crop plants or vegetation in different environments. Information on physiology, architecture or biochemistry of plants can be assessed non-invasively and on different scales. For instance, hyperspectral sensors are implemented for stress detection in plant phenotyping processes or in precision agriculture. Up to date, a variety of non-imaging and imaging hyperspectral sensors is available. The measuring process and the handling of most of these sensors is rather complex. Thus, during the last years the demand for sensors with easy user operability arose. The present study introduces the novel hyperspectral camera Specim IQ from Specim (Oulu, Finland). The Specim IQ is a handheld push broom system with integrated operating system and controls. Basic data handling and data analysis processes, such as pre-processing and classification routines are implemented within the camera software. This study provides an introduction into the measurement pipeline of the Specim IQ as well as a radiometric performance comparison with a well-established hyperspectral imager. Case studies for the detection of powdery mildew on barley at the canopy scale and the spectral characterization of Arabidopsis thaliana mutants grown under stressed and non-stressed conditions are presented.},
DOI = {10.3390/s18020441}
}



@Article{rs10020285,
AUTHOR = {De Castro, Ana I. and Torres-Sánchez, Jorge and Peña, Jose M. and Jiménez-Brenes, Francisco M. and Csillik, Ovidiu and López-Granados, Francisca},
TITLE = {An Automatic Random Forest-OBIA Algorithm for Early Weed Mapping between and within Crop Rows Using UAV Imagery},
JOURNAL = {Remote Sensing},
VOLUME = {10},
YEAR = {2018},
NUMBER = {2},
ARTICLE-NUMBER = {285},
URL = {https://www.mdpi.com/2072-4292/10/2/285},
ISSN = {2072-4292},
ABSTRACT = {Accurate and timely detection of weeds between and within crop rows in the early growth stage is considered one of the main challenges in site-specific weed management (SSWM). In this context, a robust and innovative automatic object-based image analysis (OBIA) algorithm was developed on Unmanned Aerial Vehicle (UAV) images to design early post-emergence prescription maps. This novel algorithm makes the major contribution. The OBIA algorithm combined Digital Surface Models (DSMs), orthomosaics and machine learning techniques (Random Forest, RF). OBIA-based plant heights were accurately estimated and used as a feature in the automatic sample selection by the RF classifier; this was the second research contribution. RF randomly selected a class balanced training set, obtained the optimum features values and classified the image, requiring no manual training, making this procedure time-efficient and more accurate, since it removes errors due to a subjective manual task. The ability to discriminate weeds was significantly affected by the imagery spatial resolution and weed density, making the use of higher spatial resolution images more suitable. Finally, prescription maps for in-season post-emergence SSWM were created based on the weed maps—the third research contribution—which could help farmers in decision-making to optimize crop management by rationalization of the herbicide application. The short time involved in the process (image capture and analysis) would allow timely weed control during critical periods, crucial for preventing yield loss.},
DOI = {10.3390/rs10020285}
}



@Article{drones2010007,
AUTHOR = {Mueller, Markus S. and Jutzi, Boris},
TITLE = {UAS Navigation with SqueezePoseNet—Accuracy Boosting for Pose Regression by Data Augmentation},
JOURNAL = {Drones},
VOLUME = {2},
YEAR = {2018},
NUMBER = {1},
ARTICLE-NUMBER = {7},
URL = {https://www.mdpi.com/2504-446X/2/1/7},
ISSN = {2504-446X},
ABSTRACT = {The navigation of Unmanned Aerial Vehicles (UAVs) nowadays is mostly based on Global Navigation Satellite Systems (GNSSs). Drawbacks of satellite-based navigation are failures caused by occlusions or multi-path interferences. Therefore, alternative methods have been developed in recent years. Visual navigation methods such as Visual Odometry (VO) or visual Simultaneous Localization and Mapping (SLAM) aid global navigation solutions by closing trajectory gaps or performing loop closures. However, if the trajectory estimation is interrupted or not available, a re-localization is mandatory. Furthermore, the latest research has shown promising results on pose regression in 6 Degrees of Freedom (DoF) based on Convolutional Neural Networks (CNNs). Additionally, existing navigation methods can benefit from these networks. In this article, a method for GNSS-free and fast image-based pose regression by utilizing a small Convolutional Neural Network is presented. Therefore, a small CNN (SqueezePoseNet) is utilized, transfer learning is applied and the network is tuned for pose regression. Furthermore, recent drawbacks are overcome by applying data augmentation on a training dataset utilizing simulated images. Experiments with small CNNs show promising results for GNSS-free and fast localization compared to larger networks. By training a CNN with an extended data set including simulated images, the accuracy on pose regression is improved up to 61.7% for position and up to 76.0% for rotation compared to training on a standard not-augmented data set.},
DOI = {10.3390/drones2010007}
}



@Article{rs10020320,
AUTHOR = {Meng, Baoping and Gao, Jinlong and Liang, Tiangang and Cui, Xia and Ge, Jing and Yin, Jianpeng and Feng, Qisheng and Xie, Hongjie},
TITLE = {Modeling of Alpine Grassland Cover Based on Unmanned Aerial Vehicle Technology and Multi-Factor Methods: A Case Study in the East of Tibetan Plateau, China},
JOURNAL = {Remote Sensing},
VOLUME = {10},
YEAR = {2018},
NUMBER = {2},
ARTICLE-NUMBER = {320},
URL = {https://www.mdpi.com/2072-4292/10/2/320},
ISSN = {2072-4292},
ABSTRACT = {Grassland cover and its temporal changes are key parameters in the estimation and monitoring of ecosystems and their functions, especially via remote sensing. However, the most suitable model for estimating grassland cover and the differences between models has rarely been studied in alpine meadow grasslands. In this study, field measurements of grassland cover in Gannan Prefecture, from 2014 to 2016, were acquired using unmanned aerial vehicle (UAV) technology. Single-factor parametric and multi-factor parametric/non-parametric cover inversion models were then constructed based on 14 factors related to grassland cover, and the dynamic variation of the annual maximum cover was analyzed. The results show that (1) nine out of 14 factors (longitude, latitude, elevation, the concentrations of clay and sand in the surface and bottom soils, temperature, precipitation, enhanced vegetation index (EVI) and normalized difference vegetation index (NDVI)) exert a significant effect on grassland cover in the study area. The logarithmic model based on EVI presents the best performance, with an R2 and RMSE of 0.52 and 16.96%, respectively. Single-factor grassland cover inversion models account for only 1–49% of the variation in cover during the growth season. (2) The optimum grassland cover inversion model is the artificial neural network (BP-ANN), with an R2 and RMSE of 0.72 and 13.38%, and SDs of 0.062% and 1.615%, respectively. Both the accuracy and the stability of the BP-ANN model are higher than those of the single-factor parametric models and multi-factor parametric/non-parametric models. (3) The annual maximum cover in Gannan Prefecture presents an increasing trend over 60.60% of the entire study area, while 36.54% is presently stable and 2.86% exhibits a decreasing trend.},
DOI = {10.3390/rs10020320}
}



@Article{rs10020343,
AUTHOR = {Varela, Sebastian and Dhodda, Pruthvidhar Reddy and Hsu, William H. and Prasad, P. V. Vara and Assefa, Yared and Peralta, Nahuel R. and Griffin, Terry and Sharda, Ajay and Ferguson, Allison and Ciampitti, Ignacio A.},
TITLE = {Early-Season Stand Count Determination in Corn via Integration of Imagery from Unmanned Aerial Systems (UAS) and Supervised Learning Techniques},
JOURNAL = {Remote Sensing},
VOLUME = {10},
YEAR = {2018},
NUMBER = {2},
ARTICLE-NUMBER = {343},
URL = {https://www.mdpi.com/2072-4292/10/2/343},
ISSN = {2072-4292},
ABSTRACT = {Corn (Zea mays L.) is one of the most sensitive crops to planting pattern and early-season uniformity. The most common method to determine number of plants is by visual inspection on the ground but this field activity becomes time-consuming, labor-intensive, biased, and may lead to less profitable decisions by farmers. The objective of this study was to develop a reliable, timely, and unbiased method for counting corn plants based on ultra-high-resolution imagery acquired from unmanned aerial systems (UAS) to automatically scout fields and applied to real field conditions. A ground sampling distance of 2.4 mm was targeted to extract information at a plant-level basis. First, an excess greenness (ExG) index was used to individualized green pixels from the background, then rows and inter-row contours were identified and extracted. A scalable training procedure was implemented using geometric descriptors as inputs of the classifier. Second, a decision tree was implemented and tested using two training modes in each site to expose the workflow to different ground conditions at the time of the aerial data acquisition. Differences in performance were due to training modes and spatial resolutions in the two sites. For an object classification task, an overall accuracy of 0.96, based on the proportion of corrected assessment of corn and non-corn objects, was obtained for local (per-site) classification, and an accuracy of 0.93 was obtained for the combined training modes. For successful model implementation, plants should have between two to three leaves when images are collected (avoiding overlapping between plants). Best workflow performance was reached at 2.4 mm resolution corresponding to 10 m of altitude (lower altitude); higher altitudes were gradually penalized. The latter was coincident with the larger number of detected green objects in the images and the effectiveness of geometry as descriptor for corn plant detection.},
DOI = {10.3390/rs10020343}
}



@Article{rs10030356,
AUTHOR = {Chen, Hao and Zhang, Wanchang and Gao, Huiran and Nie, Ning},
TITLE = {Climate Change and Anthropogenic Impacts on Wetland and Agriculture in the Songnen and Sanjiang Plain, Northeast China},
JOURNAL = {Remote Sensing},
VOLUME = {10},
YEAR = {2018},
NUMBER = {3},
ARTICLE-NUMBER = {356},
URL = {https://www.mdpi.com/2072-4292/10/3/356},
ISSN = {2072-4292},
ABSTRACT = {Influences of the increasing pressure of climate change and anthropogenic activities on wetlands ecosystems and agriculture are significant around the world. This paper assessed the spatiotemporal land use and land cover changes (LULCC), especially for conversion from marshland to other LULC types (e.g., croplands) over the Songnen and Sanjiang Plain (SNP and SJP), northeast China, during the past 35 years (1980–2015). The relative role of human activities and climatic changes in terms of their impacts on wetlands and agriculture dynamics were quantitatively distinguished and evaluated in different periods based on a seven-stage LULC dataset. Our results indicated that human activities, such as population expansion and socioeconomic development, and institutional policies related to wetlands and agriculture were the main driving forces for LULCC of the SJP and SNP during the past decades, while increasing contributions of climatic changes were also found. Furthermore, as few studies have identified which geographic regions are most at risk, how the future climate changes will spatially and temporally impact wetlands and agriculture, i.e., the suitability of wetlands and agriculture distributions under different future climate change scenarios, were predicted and analyzed using a habitat distribution model (Maxent) at the pixel-scale. The present findings can provide valuable references for policy makers on regional sustainability for food security, water resource rational management, agricultural planning and wetland protection as well as restoration of the region.},
DOI = {10.3390/rs10030356}
}



@Article{f9030102,
AUTHOR = {Puliti, Stefano and Talbot, Bruce and Astrup, Rasmus},
TITLE = {Tree-Stump Detection, Segmentation, Classification, and Measurement Using Unmanned Aerial Vehicle (UAV) Imagery},
JOURNAL = {Forests},
VOLUME = {9},
YEAR = {2018},
NUMBER = {3},
ARTICLE-NUMBER = {102},
URL = {https://www.mdpi.com/1999-4907/9/3/102},
ISSN = {1999-4907},
ABSTRACT = {Unmanned aerial vehicles (UAVs) are increasingly used as tools to perform a detailed assessment of post-harvest sites. One of the potential use of UAV photogrammetric data is to obtain tree-stump information that can then be used to support more precise decisions. This study developed and tested a methodology to automatically detect, segment, classify, and measure tree-stumps. Among the potential applications for single stump data, this study assessed the possibility (1) to detect and map root- and butt-rot on the stumps using a machine learning approach, and (2) directly measure or model tree stump diameter from the UAV data. The results revealed that the tree-stumps were detected with an overall accuracy of 68–80%, and once the stump was detected, the presence of root- and butt-rot was detected with an accuracy of 82.1%. Furthermore, the root mean square error of the UAV-derived measurements or model predictions for the stump diameter was 7.5 cm and 6.4 cm, respectively, and with the former systematically under predicting the diameter by 3.3 cm. The results of this study are promising and can lead to the development of more cost-effective and comprehensive UAV post-harvest surveys.},
DOI = {10.3390/f9030102}
}



@Article{s18030712,
AUTHOR = {Zhao, Yi and Ma, Jiale and Li, Xiaohui and Zhang, Jie},
TITLE = {Saliency Detection and Deep Learning-Based Wildfire Identification in UAV Imagery},
JOURNAL = {Sensors},
VOLUME = {18},
YEAR = {2018},
NUMBER = {3},
ARTICLE-NUMBER = {712},
URL = {https://www.mdpi.com/1424-8220/18/3/712},
ISSN = {1424-8220},
ABSTRACT = {An unmanned aerial vehicle (UAV) equipped with global positioning systems (GPS) can provide direct georeferenced imagery, mapping an area with high resolution. So far, the major difficulty in wildfire image classification is the lack of unified identification marks, the fire features of color, shape, texture (smoke, flame, or both) and background can vary significantly from one scene to another. Deep learning (e.g., DCNN for Deep Convolutional Neural Network) is very effective in high-level feature learning, however, a substantial amount of training images dataset is obligatory in optimizing its weights value and coefficients. In this work, we proposed a new saliency detection algorithm for fast location and segmentation of core fire area in aerial images. As the proposed method can effectively avoid feature loss caused by direct resizing; it is used in data augmentation and formation of a standard fire image dataset ‘UAV_Fire’. A 15-layered self-learning DCNN architecture named ‘Fire_Net’ is then presented as a self-learning fire feature exactor and classifier. We evaluated different architectures and several key parameters (drop out ratio, batch size, etc.) of the DCNN model regarding its validation accuracy. The proposed architecture outperformed previous methods by achieving an overall accuracy of 98%. Furthermore, ‘Fire_Net’ guarantied an average processing speed of 41.5 ms per image for real-time wildfire inspection. To demonstrate its practical utility, Fire_Net is tested on 40 sampled images in wildfire news reports and all of them have been accurately identified.},
DOI = {10.3390/s18030712}
}



@Article{rs10030409,
AUTHOR = {Darvishi, Mehdi and Schlögel, Romy and Bruzzone, Lorenzo and Cuozzo, Giovanni},
TITLE = {Integration of PSI, MAI, and Intensity-Based Sub-Pixel Offset Tracking Results for Landslide Monitoring with X-Band Corner Reflectors—Italian Alps (Corvara)},
JOURNAL = {Remote Sensing},
VOLUME = {10},
YEAR = {2018},
NUMBER = {3},
ARTICLE-NUMBER = {409},
URL = {https://www.mdpi.com/2072-4292/10/3/409},
ISSN = {2072-4292},
ABSTRACT = {This paper presents an analysis of the integration between interferometric and intensity-offset tracking-based SAR remote sensing for landslide hazard mitigation in the Italian Alps. Despite the advantages of Synthetic Aperture Radar Interferometry (InSAR) methods for quantifying landslide deformation, some limitations remain. The temporal decorrelation, the 1-D Line Of Sight (LOS) observation restriction, the high velocity rate and the multi-directional movement properties make it difficult to monitor accurately complex landslides in areas covered by vegetation. Therefore, complementary and integrated approaches, such as offset tracking-based techniques, are needed to overcome these InSAR limitations for monitoring ground surface deformations. As sub-pixel offset tracking is highly sensitive to data spatial resolution, the latest generations of SAR sensors, such as TerraSAR-X and COSMO-SkyMed, open interesting perspective for a more accurate hazard assessment. In this paper, we consider high-resolution X-band data acquired by the COSMO-SkyMed (CSK) constellation for Permanent Scatterers Interferometry (PSI), Multi-Aperture Interferometry (MAI) and offset tracking processing. We analyze the offset tracking techniques considering area and feature-based matching algorithms to evaluate their applicability to CSK data by improving sub-pixel offset estimations. To this end, PSI and MAI are used for extracting LOS and azimuthal displacement components. Then, four well-known area-based and five feature-based matching algorithms (taken from computer vision) are applied to 16 X-band corner reflectors. Results show that offset estimation accuracy can be considerably improved up to less than 3% of the pixel size using the combination of the different feature-based detectors and descriptors. A sensitivity analysis of these techniques applied to CSK data to monitor complex landslides in the Italian Alps provides indications on advantages and disadvantages of each of them.},
DOI = {10.3390/rs10030409}
}



@Article{s18030892,
AUTHOR = {Du, Jianping and Wang, Ding and Yu, Wanting and Yu, Hongyi},
TITLE = {Direct Position Determination of Unknown Signals in the Presence of Multipath Propagation},
JOURNAL = {Sensors},
VOLUME = {18},
YEAR = {2018},
NUMBER = {3},
ARTICLE-NUMBER = {892},
URL = {https://www.mdpi.com/1424-8220/18/3/892},
ISSN = {1424-8220},
ABSTRACT = {A novel geolocation architecture, termed “Multiple Transponders and Multiple Receivers for Multiple Emitters Positioning System (MTRE)” is proposed in this paper. Existing Direct Position Determination (DPD) methods take advantage of a rather simple channel assumption (line of sight channels with complex path attenuations) and a simplified MUltiple SIgnal Classification (MUSIC) algorithm cost function to avoid the high dimension searching. We point out that the simplified assumption and cost function reduce the positioning accuracy because of the singularity of the array manifold in a multi-path environment. We present a DPD model for unknown signals in the presence of Multi-path Propagation (MP-DPD) in this paper. MP-DPD adds non-negative real path attenuation constraints to avoid the mistake caused by the singularity of the array manifold. The Multi-path Propagation MUSIC (MP-MUSIC) method and the Active Set Algorithm (ASA) are designed to reduce the dimension of searching. A Multi-path Propagation Maximum Likelihood (MP-ML) method is proposed in addition to overcome the limitation of MP-MUSIC in the sense of a time-sensitive application. An iterative algorithm and an approach of initial value setting are given to make the MP-ML time consumption acceptable. Numerical results validate the performances improvement of MP-MUSIC and MP-ML. A closed form of the Cramér–Rao Lower Bound (CRLB) is derived as a benchmark to evaluate the performances of MP-MUSIC and MP-ML.},
DOI = {10.3390/s18030892}
}



@Article{s18030924,
AUTHOR = {Zhang, Duona and Ding, Wenrui and Zhang, Baochang and Xie, Chunyu and Li, Hongguang and Liu, Chunhui and Han, Jungong},
TITLE = {Automatic Modulation Classification Based on Deep Learning for Unmanned Aerial Vehicles},
JOURNAL = {Sensors},
VOLUME = {18},
YEAR = {2018},
NUMBER = {3},
ARTICLE-NUMBER = {924},
URL = {https://www.mdpi.com/1424-8220/18/3/924},
ISSN = {1424-8220},
ABSTRACT = {Deep learning has recently attracted much attention due to its excellent performance in processing audio, image, and video data. However, few studies are devoted to the field of automatic modulation classification (AMC). It is one of the most well-known research topics in communication signal recognition and remains challenging for traditional methods due to complex disturbance from other sources. This paper proposes a heterogeneous deep model fusion (HDMF) method to solve the problem in a unified framework. The contributions include the following: (1) a convolutional neural network (CNN) and long short-term memory (LSTM) are combined by two different ways without prior knowledge involved; (2) a large database, including eleven types of single-carrier modulation signals with various noises as well as a fading channel, is collected with various signal-to-noise ratios (SNRs) based on a real geographical environment; and (3) experimental results demonstrate that HDMF is very capable of coping with the AMC problem, and achieves much better performance when compared with the independent network.},
DOI = {10.3390/s18030924}
}



@Article{s18040944,
AUTHOR = {Sandino, Juan and Pegg, Geoff and Gonzalez, Felipe and Smith, Grant},
TITLE = {Aerial Mapping of Forests Affected by Pathogens Using UAVs, Hyperspectral Sensors, and Artificial Intelligence},
JOURNAL = {Sensors},
VOLUME = {18},
YEAR = {2018},
NUMBER = {4},
ARTICLE-NUMBER = {944},
URL = {https://www.mdpi.com/1424-8220/18/4/944},
ISSN = {1424-8220},
ABSTRACT = {The environmental and economic impacts of exotic fungal species on natural and plantation forests have been historically catastrophic. Recorded surveillance and control actions are challenging because they are costly, time-consuming, and hazardous in remote areas. Prolonged periods of testing and observation of site-based tests have limitations in verifying the rapid proliferation of exotic pathogens and deterioration rates in hosts. Recent remote sensing approaches have offered fast, broad-scale, and affordable surveys as well as additional indicators that can complement on-ground tests. This paper proposes a framework that consolidates site-based insights and remote sensing capabilities to detect and segment deteriorations by fungal pathogens in natural and plantation forests. This approach is illustrated with an experimentation case of myrtle rust (Austropuccinia psidii) on paperbark tea trees (Melaleuca quinquenervia) in New South Wales (NSW), Australia. The method integrates unmanned aerial vehicles (UAVs), hyperspectral image sensors, and data processing algorithms using machine learning. Imagery is acquired using a Headwall Nano-Hyperspec     ®     camera, orthorectified in Headwall SpectralView     ®    , and processed in Python programming language using eXtreme Gradient Boosting (XGBoost), Geospatial Data Abstraction Library (GDAL), and Scikit-learn third-party libraries. In total, 11,385 samples were extracted and labelled into five classes: two classes for deterioration status and three classes for background objects. Insights reveal individual detection rates of 95% for healthy trees, 97% for deteriorated trees, and a global multiclass detection rate of 97%. The methodology is versatile to be applied to additional datasets taken with different image sensors, and the processing of large datasets with freeware tools.},
DOI = {10.3390/s18040944}
}



@Article{s18040967,
AUTHOR = {Pang, Jingyue and Liu, Datong and Peng, Yu and Peng, Xiyuan},
TITLE = {Optimize the Coverage Probability of Prediction Interval for Anomaly Detection of Sensor-Based Monitoring Series},
JOURNAL = {Sensors},
VOLUME = {18},
YEAR = {2018},
NUMBER = {4},
ARTICLE-NUMBER = {967},
URL = {https://www.mdpi.com/1424-8220/18/4/967},
ISSN = {1424-8220},
ABSTRACT = {Effective anomaly detection of sensing data is essential for identifying potential system failures. Because they require no prior knowledge or accumulated labels, and provide uncertainty presentation, the probability prediction methods (e.g., Gaussian process regression (GPR) and relevance vector machine (RVM)) are especially adaptable to perform anomaly detection for sensing series. Generally, one key parameter of prediction models is coverage probability (CP), which controls the judging threshold of the testing sample and is generally set to a default value (e.g., 90% or 95%). There are few criteria to determine the optimal CP for anomaly detection. Therefore, this paper designs a graphic indicator of the receiver operating characteristic curve of prediction interval (ROC-PI) based on the definition of the ROC curve which can depict the trade-off between the PI width and PI coverage probability across a series of cut-off points. Furthermore, the Youden index is modified to assess the performance of different CPs, by the minimization of which the optimal CP is derived by the simulated annealing (SA) algorithm. Experiments conducted on two simulation datasets demonstrate the validity of the proposed method. Especially, an actual case study on sensing series from an on-orbit satellite illustrates its significant performance in practical application.},
DOI = {10.3390/s18040967}
}



@Article{s18041000,
AUTHOR = {Kong, Xiangxiong and Li, Jian},
TITLE = {Image Registration-Based Bolt Loosening Detection of Steel Joints},
JOURNAL = {Sensors},
VOLUME = {18},
YEAR = {2018},
NUMBER = {4},
ARTICLE-NUMBER = {1000},
URL = {https://www.mdpi.com/1424-8220/18/4/1000},
ISSN = {1424-8220},
ABSTRACT = {Self-loosening of bolts caused by repetitive loads and vibrations is one of the common defects that can weaken the structural integrity of bolted steel joints in civil structures. Many existing approaches for detecting loosening bolts are based on physical sensors and, hence, require extensive sensor deployment, which limit their abilities to cost-effectively detect loosened bolts in a large number of steel joints. Recently, computer vision-based structural health monitoring (SHM) technologies have demonstrated great potential for damage detection due to the benefits of being low cost, easy to deploy, and contactless. In this study, we propose a vision-based non-contact bolt loosening detection method that uses a consumer-grade digital camera. Two images of the monitored steel joint are first collected during different inspection periods and then aligned through two image registration processes. If the bolt experiences rotation between inspections, it will introduce differential features in the registration errors, serving as a good indicator for bolt loosening detection. The performance and robustness of this approach have been validated through a series of experimental investigations using three laboratory setups including a gusset plate on a cross frame, a column flange, and a girder web. The bolt loosening detection results are presented for easy interpretation such that informed decisions can be made about the detected loosened bolts.},
DOI = {10.3390/s18041000}
}



@Article{su10041072,
AUTHOR = {Kim, KeumJi and Yoon, SeongHwan},
TITLE = {Assessment of Building Damage Risk by Natural Disasters in South Korea Using Decision Tree Analysis},
JOURNAL = {Sustainability},
VOLUME = {10},
YEAR = {2018},
NUMBER = {4},
ARTICLE-NUMBER = {1072},
URL = {https://www.mdpi.com/2071-1050/10/4/1072},
ISSN = {2071-1050},
ABSTRACT = {The purpose of this study is to identify the relationship between weather variables and buildings damaged in natural disasters. We used four datasets on building damage history and 33 weather datasets from 230 regions in South Korea in a decision tree analysis to evaluate the risk of building damage. We generated the decision tree model to determine the risk of rain, gale, and typhoon (excluding gale with less damage). Using the weight and limit values of the weather variables derived using the decision tree model, the risk of building damage was assessed for 230 regions in South Korea until 2100. The number of regions at risk of rain damage increased by more than 30% on average. Conversely, regions at risk of damage from snowfall decreased by more than 90%. The regions at risk of typhoons decreased by 57.5% on average, while those at high risk of the same increased by up to 62.5% under RCP 8.5. The results of this study are highly fluid since they are based on the uncertainty of future climate change. However, the study is meaningful because it suggests a new method for assessing disaster risk using weather indices.},
DOI = {10.3390/su10041072}
}



@Article{s18041120,
AUTHOR = {Li, He and Liu, Gaohuan and Liu, Qingsheng and Chen, Zhongxin and Huang, Chong},
TITLE = {Retrieval of Winter Wheat Leaf Area Index from Chinese GF-1 Satellite Data Using the PROSAIL Model},
JOURNAL = {Sensors},
VOLUME = {18},
YEAR = {2018},
NUMBER = {4},
ARTICLE-NUMBER = {1120},
URL = {https://www.mdpi.com/1424-8220/18/4/1120},
ISSN = {1424-8220},
ABSTRACT = {Leaf area index (LAI) is one of the key biophysical parameters in crop structure. The accurate quantitative estimation of crop LAI is essential to verify crop growth and health. The PROSAIL radiative transfer model (RTM) is one of the most established methods for estimating crop LAI. In this study, a look-up table (LUT) based on the PROSAIL RTM was first used to estimate winter wheat LAI from GF-1 data, which accounted for some available prior knowledge relating to the distribution of winter wheat characteristics. Next, the effects of 15 LAI-LUT strategies with reflectance bands and 10 LAI-LUT strategies with vegetation indexes on the accuracy of the winter wheat LAI retrieval with different phenological stages were evaluated against in situ LAI measurements. The results showed that the LUT strategies of LAI-GNDVI were optimal and had the highest accuracy with a root mean squared error (RMSE) value of 0.34, and a coefficient of determination (R2) of 0.61 during the elongation stages, and the LUT strategies of LAI-Green were optimal with a RMSE of 0.74, and R2 of 0.20 during the grain-filling stages. The results demonstrated that the PROSAIL RTM had great potential in winter wheat LAI inversion with GF-1 satellite data and the performance could be improved by selecting the appropriate LUT inversion strategies in different growth periods.},
DOI = {10.3390/s18041120}
}



@Article{rs10040584,
AUTHOR = {De Castro, Ana I. and Jiménez-Brenes, Francisco M. and Torres-Sánchez, Jorge and Peña, José M. and Borra-Serrano, Irene and López-Granados, Francisca},
TITLE = {3-D Characterization of Vineyards Using a Novel UAV Imagery-Based OBIA Procedure for Precision Viticulture Applications},
JOURNAL = {Remote Sensing},
VOLUME = {10},
YEAR = {2018},
NUMBER = {4},
ARTICLE-NUMBER = {584},
URL = {https://www.mdpi.com/2072-4292/10/4/584},
ISSN = {2072-4292},
ABSTRACT = {Precision viticulture has arisen in recent years as a new approach in grape production. It is based on assessing field spatial variability and implementing site-specific management strategies, which can require georeferenced information of the three dimensional (3D) grapevine canopy structure as one of the input data. The 3D structure of vineyard fields can be generated applying photogrammetric techniques to aerial images collected with Unmanned Aerial Vehicles (UAVs), although processing the large amount of crop data embedded in 3D models is currently a bottleneck of this technology. To solve this limitation, a novel and robust object-based image analysis (OBIA) procedure based on Digital Surface Model (DSM) was developed for 3D grapevine characterization. The significance of this work relies on the developed OBIA algorithm which is fully automatic and self-adaptive to different crop-field conditions, classifying grapevines, and row gap (missing vine plants), and computing vine dimensions without any user intervention. The results obtained in three testing fields on two different dates showed high accuracy in the classification of grapevine area and row gaps, as well as minor errors in the estimates of grapevine height. In addition, this algorithm computed the position, projected area, and volume of every grapevine in the field, which increases the potential of this UAV- and OBIA-based technology as a tool for site-specific crop management applications.},
DOI = {10.3390/rs10040584}
}



@Article{s18041170,
AUTHOR = {Besada, Juan A. and Bergesio, Luca and Campaña, Iván and Vaquero-Melchor, Diego and López-Araquistain, Jaime and Bernardos, Ana M. and Casar, José R.},
TITLE = {Drone Mission Definition and Implementation for Automated Infrastructure Inspection Using Airborne Sensors},
JOURNAL = {Sensors},
VOLUME = {18},
YEAR = {2018},
NUMBER = {4},
ARTICLE-NUMBER = {1170},
URL = {https://www.mdpi.com/1424-8220/18/4/1170},
ISSN = {1424-8220},
ABSTRACT = {This paper describes a Mission Definition System and the automated flight process it enables to implement measurement plans for discrete infrastructure inspections using aerial platforms, and specifically multi-rotor drones. The mission definition aims at improving planning efficiency with respect to state-of-the-art waypoint-based techniques, using high-level mission definition primitives and linking them with realistic flight models to simulate the inspection in advance. It also provides flight scripts and measurement plans which can be executed by commercial drones. Its user interfaces facilitate mission definition, pre-flight 3D synthetic mission visualisation and flight evaluation. Results are delivered for a set of representative infrastructure inspection flights, showing the accuracy of the flight prediction tools in actual operations using automated flight control.},
DOI = {10.3390/s18041170}
}



@Article{rs10040613,
AUTHOR = {Chen, Chi and Yang, Bisheng and Song, Shuang and Peng, Xiangyang and Huang, Ronggang},
TITLE = {Automatic Clearance Anomaly Detection for Transmission Line Corridors Utilizing UAV-Borne LIDAR Data},
JOURNAL = {Remote Sensing},
VOLUME = {10},
YEAR = {2018},
NUMBER = {4},
ARTICLE-NUMBER = {613},
URL = {https://www.mdpi.com/2072-4292/10/4/613},
ISSN = {2072-4292},
ABSTRACT = {Transmission line corridor (i.e., Right-of-Ways (ROW)) clearance management plays a critically important role in power line risk management and is an important task of the routine power line inspection of the grid company. The clearance anomaly detection measures the distance between the power lines and the surrounding non-power-facility objects in the corridor such as trees, and buildings, to judge whether the clearance is within the safe range. To find the clearance hazards efficiently and flexibly, this study thus proposed an automatic clearance anomaly detection method utilizing LiDAR point clouds collected by unmanned aerial vehicle (UAV). Firstly, the terrain points were filtered out using two-step adaptive terrain filter and the pylons were detected in the non-terrain points following a feature map method. After dividing the ROW point clouds into spans based on the pylon detection results, the power line point clouds were extracted according to their geometric distribution in local span point clouds slices, and were further segmented into clusters by applying conditional Euclidean clustering with linear feature constraints. Secondly, the power line point clouds segments were iteratively fitted with 3D catenary curve model that is represented by a horizontal line and a vertical catenary curve defined by a hyperbolic cosine function, resulting in a continuous mathematical model of the discretely sampled points of the power line. Finally, a piecewise clearance calculation method which converts the point-to-catenary curve distance measurements to minimal distance calculation based on differential geometry was used to calculate the distance between the power line and the non-power-facility objects in the ROW. The clearance measurements were compared with the standard safe threshold to find the clearance anomalies in the ROWs. Multiple LiDAR point clouds datasets collected by a large-scale UAV power line inspection system were used to validate the effectiveness and accuracy of the proposed method. The detected results were validated through qualitatively visual inspection, quantitatively manual measurements in raw point clouds and on-site field survey. The experiments show that the automatic clearance anomaly detection method proposed in this paper effectively detects the clearance hazards such as tree encroachment, and the clearance measurement accuracy is decimeter level for the LiDAR point clouds collected by our UAV inspection system.},
DOI = {10.3390/rs10040613}
}



@Article{rs10040618,
AUTHOR = {Al-Saddik, Hania and Laybros, Anthony and Billiot, Bastien and Cointault, Frederic},
TITLE = {Using Image Texture and Spectral Reflectance Analysis to Detect Yellowness and Esca in Grapevines at Leaf-Level},
JOURNAL = {Remote Sensing},
VOLUME = {10},
YEAR = {2018},
NUMBER = {4},
ARTICLE-NUMBER = {618},
URL = {https://www.mdpi.com/2072-4292/10/4/618},
ISSN = {2072-4292},
ABSTRACT = {Plant diseases are one of the main reasons behind major economic and production losses in the agricultural field. Current research activities enable large fields monitoring and plant disease detection using innovative and robust technologies. French grapevines have a reputation for producing premium quality wines, however, these major fruit crops are susceptible to many diseases, including Esca, Downy mildew, Powdery mildew, Yellowing, and many others. In this study, we focused on two main infections (Esca and Yellowing), and data were gathered from fields that were located in Aquitaine and Burgundy regions, France. Since plant diseases can be diagnosed from the properties of the leaf, we acquired both Red-Green-Blue (RGB) digital image and hyperspectral reflectance data from infected and healthy leaves. Biophysical parameters that were produced by the PROSPECT model inversion together with texture parameters compiled from the literature were deduced. Then we investigated their relationship to damage caused by Yellowing and Esca. This study examined whether spectral and textural data can identify the two diseases through the use of Neural Networks. We obtained an overall accuracy of 99% for both of the diseases when textural and spectral data are combined. These results suggest that, first, biophysical parameters present a valid dimension reduction tool that could replace the use of complete hyperspectral data. Second, remote sensing using spectral reflectance and digital images can make an overall nondestructive, rapid, cost-effective, and reproducible technique to determine diseases in grapevines with a good level of accuracy.},
DOI = {10.3390/rs10040618}
}



@Article{rs10040624,
AUTHOR = {Zhuo, Xiangyu and Fraundorfer, Friedrich and Kurz, Franz and Reinartz, Peter},
TITLE = {Optimization of OpenStreetMap Building Footprints Based on Semantic Information of Oblique UAV Images},
JOURNAL = {Remote Sensing},
VOLUME = {10},
YEAR = {2018},
NUMBER = {4},
ARTICLE-NUMBER = {624},
URL = {https://www.mdpi.com/2072-4292/10/4/624},
ISSN = {2072-4292},
ABSTRACT = {Building footprint information is vital for 3D building modeling. Traditionally, in remote sensing, building footprints are extracted and delineated from aerial imagery and/or LiDAR point cloud. Taking a different approach, this paper is dedicated to the optimization of OpenStreetMap (OSM) building footprints exploiting the contour information, which is derived from deep learning-based semantic segmentation of oblique images acquired by the Unmanned Aerial Vehicle (UAV). First, a simplified 3D building model of Level of Detail 1 (LoD 1) is initialized using the footprint information from OSM and the elevation information from Digital Surface Model (DSM). In parallel, a deep neural network for pixel-wise semantic image segmentation is trained in order to extract the building boundaries as contour evidence. Subsequently, an optimization integrating the contour evidence from multi-view images as a constraint results in a refined 3D building model with optimized footprints and height. Our method is leveraged to optimize OSM building footprints for four datasets with different building types, demonstrating robust performance for both individual buildings and multiple buildings regardless of image resolution. Finally, we compare our result with reference data from German Authority Topographic-Cartographic Information System (ATKIS). Quantitative and qualitative evaluations reveal that the original OSM building footprints have large offset, but can be significantly improved from meter level to decimeter level after optimization.},
DOI = {10.3390/rs10040624}
}




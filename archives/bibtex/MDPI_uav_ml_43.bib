
@Article{rs13214445,
AUTHOR = {Nazeri, Behrokh and Crawford, Melba},
TITLE = {Detection of Outliers in LiDAR Data Acquired by Multiple Platforms over Sorghum and Maize},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {21},
ARTICLE-NUMBER = {4445},
URL = {https://www.mdpi.com/2072-4292/13/21/4445},
ISSN = {2072-4292},
ABSTRACT = {High-resolution point cloud data acquired with a laser scanner from any platform contain random noise and outliers. Therefore, outlier detection in LiDAR data is often necessary prior to analysis. Applications in agriculture are particularly challenging, as there is typically no prior knowledge of the statistical distribution of points, plant complexity, and local point densities, which are crop-dependent. The goals of this study were first to investigate approaches to minimize the impact of outliers on LiDAR acquired over agricultural row crops, and specifically for sorghum and maize breeding experiments, by an unmanned aerial vehicle (UAV) and a wheel-based ground platform; second, to evaluate the impact of existing outliers in the datasets on leaf area index (LAI) prediction using LiDAR data. Two methods were investigated to detect and remove the outliers from the plant datasets. The first was based on surface fitting to noisy point cloud data via normal and curvature estimation in a local neighborhood. The second utilized the PointCleanNet deep learning framework. Both methods were applied to individual plants and field-based datasets. To evaluate the method, an F-score was calculated for synthetic data in the controlled conditions, and LAI, the variable being predicted, was computed both before and after outlier removal for both scenarios. Results indicate that the deep learning method for outlier detection is more robust than the geometric approach to changes in point densities, level of noise, and shapes. The prediction of LAI was also improved for the wheel-based vehicle data based on the coefficient of determination (R2) and the root mean squared error (RMSE) of the residuals before and after the removal of outliers.},
DOI = {10.3390/rs13214445}
}



@Article{agriculture11111104,
AUTHOR = {Rokhafrouz, Mohammad and Latifi, Hooman and Abkar, Ali A. and Wojciechowski, Tomasz and Czechlowski, Mirosław and Naieni, Ali Sadeghi and Maghsoudi, Yasser and Niedbała, Gniewko},
TITLE = {Simplified and Hybrid Remote Sensing-Based Delineation of Management Zones for Nitrogen Variable Rate Application in Wheat},
JOURNAL = {Agriculture},
VOLUME = {11},
YEAR = {2021},
NUMBER = {11},
ARTICLE-NUMBER = {1104},
URL = {https://www.mdpi.com/2077-0472/11/11/1104},
ISSN = {2077-0472},
ABSTRACT = {Enhancing digital and precision agriculture is currently inevitable to overcome the economic and environmental challenges of the agriculture in the 21st century. The purpose of this study was to generate and compare management zones (MZ) based on the Sentinel-2 satellite data for variable rate application of mineral nitrogen in wheat production, calculated using different remote sensing (RS)-based models under varied soil, yield and crop data availability. Three models were applied, including (1) a modified “RS- and threshold-based clustering”, (2) a “hybrid-based, unsupervised clustering”, in which data from different sources were combined for MZ delineation, and (3) a “RS-based, unsupervised clustering”. Various data processing methods including machine learning were used in the model development. Statistical tests such as the Paired Sample T-test, Kruskal–Wallis H-test and Wilcoxon signed-rank test were applied to evaluate the final delineated MZ maps. Additionally, a procedure for improving models based on information about phenological phases and the occurrence of agricultural drought was implemented. The results showed that information on agronomy and climate enables improving and optimizing MZ delineation. The integration of prior knowledge on new climate conditions (drought) in image selection was tested for effective use of the models. Lack of this information led to the infeasibility of obtaining optimal results. Models that solely rely on remote sensing information are comparatively less expensive than hybrid models. Additionally, remote sensing-based models enable delineating MZ for fertilizer recommendations that are temporally closer to fertilization times.},
DOI = {10.3390/agriculture11111104}
}



@Article{agronomy11112244,
AUTHOR = {Yang, Mingxin and Gao, Peng and Zhou, Ping and Xie, Jiaxing and Sun, Daozong and Han, Xiongzhe and Wang, Weixing},
TITLE = {Simulating Canopy Temperature Using a Random Forest Model to Calculate the Crop Water Stress Index of Chinese Brassica},
JOURNAL = {Agronomy},
VOLUME = {11},
YEAR = {2021},
NUMBER = {11},
ARTICLE-NUMBER = {2244},
URL = {https://www.mdpi.com/2073-4395/11/11/2244},
ISSN = {2073-4395},
ABSTRACT = {The determination of crop water status has positive effects on the Chinese Brassica industry and irrigation decisions. Drought can decrease the production of Chinese Brassica, whereas over-irrigation can waste water. It is desirable to schedule irrigation when the crop suffers from water stress. In this study, a random forest model was developed using sample data derived from meteorological measurements including air temperature (Ta), relative humidity (RH), wind speed (WS), and photosynthetic active radiation (Par) to predict the lower baseline (Twet) and upper baseline (Tdry) canopy temperatures for Chinese Brassica from 27 November to 31 December 2020 (E1) and from 25 May to 20 June 2021 (E2). Crop water stress index (CWSI) values were determined based on the predicted canopy temperature and used to assess the crop water status. The study demonstrated the viability of using a random forest model to forecast Twet and Tdry. The coefficients of determination (R2) in E1 were 0.90 and 0.88 for development and 0.80 and 0.77 for validation, respectively. The R2 values in E2 were 0.91 and 0.89 for development and 0.83 and 0.80 for validation, respectively. Our results reveal that the measured and predicted CWSI values had similar R2 values related to stomatal conductance (~0.5 in E1, ~0.6 in E2), whereas the CWSI showed a poor correlation with transpiration rate (~0.25 in E1, ~0.2 in E2). Finally, the methodology used to calculate the daily CWSI for Chinese Brassica in this study showed that both Twet and Tdry, which require frequent measuring and design experiment due to the trial site and condition changes, have the potential to simulate environmental parameters and can therefore be applied to conveniently calculate the CWSI.},
DOI = {10.3390/agronomy11112244}
}



@Article{rs13214452,
AUTHOR = {Nababan, Bisman and Mastu, La Ode Khairum and Idris, Nurul Hazrina and Panjaitan, James P.},
TITLE = {Shallow-Water Benthic Habitat Mapping Using Drone with Object Based Image Analyses},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {21},
ARTICLE-NUMBER = {4452},
URL = {https://www.mdpi.com/2072-4292/13/21/4452},
ISSN = {2072-4292},
ABSTRACT = {Spatial information on benthic habitats in Wangiwangi island waters, Wakatobi District, Indonesia was very limited in recent years. However, this area is one of the marine tourism destinations and one of the Indonesia’s triangle coral reef regions with a very complex coral reef ecosystem. The drone technology that has rapidly developed in this decade, can be used to map benthic habitats in this area. This study aimed to map shallow-water benthic habitats using drone technology in the region of Wangiwangi island waters, Wakatobi District, Indonesia. The field data were collected using a 50 × 50 cm squared transect of 434 observation points in March–April 2017. The DJI Phantom 3 Pro drone with a spatial resolution of 5.2 × 5.2 cm was used to acquire aerial photographs. Image classifications were processed using object-based image analysis (OBIA) method with contextual editing classification at level 1 (reef level) with 200 segmentation scale and several segmentation scales at level 2 (benthic habitat). For level 2 classification, we found that the best algorithm to map benthic habitat was the support vector machine (SVM) algorithm with a segmentation scale of 50. Based on field observations, we produced 12 and 9 benthic habitat classes. Using the OBIA method with a segmentation value of 50 and the SVM algorithm, we obtained the overall accuracy of 77.4% and 81.1% for 12 and 9 object classes, respectively. This result improved overall accuracy up to 17% in mapping benthic habitats using Sentinel-2 satellite data within the similar region, similar classes, and similar method of classification analyses.},
DOI = {10.3390/rs13214452}
}



@Article{rs13214466,
AUTHOR = {Eischeid, Isabell and Soininen, Eeva M. and Assmann, Jakob J. and Ims, Rolf A. and Madsen, Jesper and Pedersen, Åshild Ø. and Pirotti, Francesco and Yoccoz, Nigel G. and Ravolainen, Virve T.},
TITLE = {Disturbance Mapping in Arctic Tundra Improved by a Planning Workflow for Drone Studies: Advancing Tools for Future Ecosystem Monitoring},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {21},
ARTICLE-NUMBER = {4466},
URL = {https://www.mdpi.com/2072-4292/13/21/4466},
ISSN = {2072-4292},
ABSTRACT = {The Arctic is under great pressure due to climate change. Drones are increasingly used as a tool in ecology and may be especially valuable in rapidly changing and remote landscapes, as can be found in the Arctic. For effective applications of drones, decisions of both ecological and technical character are needed. Here, we provide our method planning workflow for generating ground-cover maps with drones for ecological monitoring purposes. The workflow includes the selection of variables, layer resolutions, ground-cover classes and the development and validation of models. We implemented this workflow in a case study of the Arctic tundra to develop vegetation maps, including disturbed vegetation, at three study sites in Svalbard. For each site, we generated a high-resolution map of tundra vegetation using supervised random forest (RF) classifiers based on four spectral bands, the normalized difference vegetation index (NDVI) and three types of terrain variables—all derived from drone imagery. Our classifiers distinguished up to 15 different ground-cover classes, including two classes that identify vegetation state changes due to disturbance caused by herbivory (i.e., goose grubbing) and winter damage (i.e., ‘rain-on-snow’ and thaw-freeze). Areas classified as goose grubbing or winter damage had lower NDVI values than their undisturbed counterparts. The predictive ability of site-specific RF models was good (macro-F1 scores between 83% and 85%), but the area of the grubbing class was overestimated in parts of the moss tundra. A direct transfer of the models between study sites was not possible (macro-F1 scores under 50%). We show that drone image analysis can be an asset for studying future vegetation state changes on local scales in Arctic tundra ecosystems and encourage ecologists to use our tailored workflow to integrate drone mapping into long-term monitoring programs.},
DOI = {10.3390/rs13214466}
}



@Article{s21217397,
AUTHOR = {Wang, Yanjun and Li, Shaochun and Lin, Yunhao and Wang, Mengjie},
TITLE = {Lightweight Deep Neural Network Method for Water Body Extraction from High-Resolution Remote Sensing Images with Multisensors},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {21},
ARTICLE-NUMBER = {7397},
URL = {https://www.mdpi.com/1424-8220/21/21/7397},
PubMedID = {34770701},
ISSN = {1424-8220},
ABSTRACT = {Rapid and accurate extraction of water bodies from high-spatial-resolution remote sensing images is of great value for water resource management, water quality monitoring and natural disaster emergency response. For traditional water body extraction methods, it is difficult to select image texture and features, the shadows of buildings and other ground objects are in the same spectrum as water bodies, the existing deep convolutional neural network is difficult to train, the consumption of computing resources is large, and the methods cannot meet real-time requirements. In this paper, a water body extraction method based on lightweight MobileNetV2 is proposed and applied to multisensor high-resolution remote sensing images, such as GF-2, WorldView-2 and UAV orthoimages. This method was validated in two typical complex geographical scenes: water bodies for farmland irrigation, which have a broken shape and long and narrow area and are surrounded by many buildings in towns and villages; and water bodies in mountainous areas, which have undulating topography, vegetation coverage and mountain shadows all over. The results were compared with those of the support vector machine, random forest and U-Net models and also verified by generalization tests and the influence of spatial resolution changes. First, the results show that the F1-score and Kappa coefficients of the MobileNetV2 model extracting water bodies from three different high-resolution images were 0.75 and 0.72 for GF-2, 0.86 and 0.85 for Worldview-2 and 0.98 and 0.98 for UAV, respectively, which are higher than those of traditional machine learning models and U-Net. Second, the training time, number of parameters and calculation amount of the MobileNetV2 model were much lower than those of the U-Net model, which greatly improves the water body extraction efficiency. Third, in other more complex surface areas, the MobileNetV2 model still maintained relatively high accuracy of water body extraction. Finally, we tested the effects of multisensor models and found that training with lower and higher spatial resolution images combined can be beneficial, but that using just lower resolution imagery is ineffective. This study provides a reference for the efficient automation of water body classification and extraction under complex geographical environment conditions and can be extended to water resource investigation, management and planning.},
DOI = {10.3390/s21217397}
}



@Article{s21217396,
AUTHOR = {Kim, Bubryur and Choi, Se-Woon and Hu, Gang and Lee, Dong-Eun and Serfa Juan, Ronnie O.},
TITLE = {Multivariate Analysis of Concrete Image Using Thermography and Edge Detection},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {21},
ARTICLE-NUMBER = {7396},
URL = {https://www.mdpi.com/1424-8220/21/21/7396},
PubMedID = {34770702},
ISSN = {1424-8220},
ABSTRACT = {With the growing demand for structural health monitoring system applications, data imaging is an ideal method for performing regular routine maintenance inspections. Image analysis can provide invaluable information about the health conditions of a structure’s existing infrastructure by recording and analyzing exterior damages. Therefore, it is desirable to have an automated approach that reports defects on images reliably and robustly. This paper presents a multivariate analysis approach for images, specifically for assessing substantial damage (such as cracks). The image analysis provides graph representations that are related to the image, such as the histogram. In addition, image-processing techniques such as grayscale are also implemented, which enhance the object’s information present in the image. In addition, this study uses image segmentation and a neural network, for transforming an image to analyze it more easily and as a classifier, respectively. Initially, each concrete structure image is preprocessed to highlight the crack. A neural network is used to calculate and categorize the visual characteristics of each region, and it shows an accuracy for classification of 98%. Experimental results show that thermal image extraction yields better histogram and cumulative distribution function features. The system can promote the development of various thermal image applications, such as nonphysical visual recognition and fault detection analysis.},
DOI = {10.3390/s21217396}
}



@Article{su132112291,
AUTHOR = {Wu, Li-Ya and Weng, Sung-Shun},
TITLE = {Ensemble Learning Models for Food Safety Risk Prediction},
JOURNAL = {Sustainability},
VOLUME = {13},
YEAR = {2021},
NUMBER = {21},
ARTICLE-NUMBER = {12291},
URL = {https://www.mdpi.com/2071-1050/13/21/12291},
ISSN = {2071-1050},
ABSTRACT = {Ensemble learning was adopted to design risk prediction models with the aim of improving border inspection methods for food imported into Taiwan. Specifically, we constructed a set of prediction models to enhance the hit rate of non-conforming products, thus strengthening the border control of food products to safeguard public health. Using five algorithms, we developed models to provide recommendations for the risk assessment of each imported food batch. The models were evaluated by constructing a confusion matrix to calculate predictive performance indicators, including the positive prediction value (PPV), recall, harmonic mean of PPV and recall (F1 score), and area under the curve. Our results showed that ensemble learning achieved better and more stable prediction results than any single algorithm. When the results of comparable data periods were examined, the non-conformity hit rate was found to increase significantly after online implementation of the ensemble learning models, indicating that ensemble learning was effective at risk prediction. In addition to enhancing the inspection hit rate of non-conforming food, the results of this study can serve as a reference for the improvement of existing random inspection methods, thus strengthening capabilities in food risk management.},
DOI = {10.3390/su132112291}
}



@Article{s21217403,
AUTHOR = {Fil, Pavel P and Yurova, Alla Yu and Dobrokhotov, Alexey and Kozlov, Daniil},
TITLE = {Estimation of Infiltration Volumes and Rates in Seasonally Water-Filled Topographic Depressions Based on Remote-Sensing Time Series},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {21},
ARTICLE-NUMBER = {7403},
URL = {https://www.mdpi.com/1424-8220/21/21/7403},
PubMedID = {34770708},
ISSN = {1424-8220},
ABSTRACT = {In semi-arid ecoregions of temperate zones, focused snowmelt water infiltration in topographic depressions is a key, but imperfectly understood, groundwater recharge mechanism. Routine monitoring is precluded by the abundance of depressions. We have used remote-sensing data to construct mass balances and estimate volumes of temporary ponds in the Tambov area of Russia. First, small water bodies were automatically recognized in each of a time series of high-resolution Planet Labs images taken in April and May 2021 by object-oriented supervised classification. A training set of water pixels defined in one of the latest images using a small unmanned aerial vehicle enabled high-confidence predictions of water pixels in the earlier images (Cohen’s Κ = 0.99). A digital elevation model was used to estimate the ponds’ water volumes, which decreased with time following a negative exponential equation. The power of the exponent did not systematically depend on the pond size. With adjustment for estimates of daily Penman evaporation, function-based interpolation of the water bodies’ areas and volumes allowed calculation of daily infiltration into the depression beds. The infiltration was maximal (5–40 mm/day) at onset of spring and decreased with time during the study period. Use of the spatially variable infiltration rates improved steady-state shallow groundwater simulations.},
DOI = {10.3390/s21217403}
}



@Article{rs13214476,
AUTHOR = {Traore, Adama and Ata-Ul-Karim, Syed Tahir and Duan, Aiwang and Soothar, Mukesh Kumar and Traore, Seydou and Zhao, Ben},
TITLE = {Predicting Equivalent Water Thickness in Wheat Using UAV Mounted Multispectral Sensor through Deep Learning Techniques},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {21},
ARTICLE-NUMBER = {4476},
URL = {https://www.mdpi.com/2072-4292/13/21/4476},
ISSN = {2072-4292},
ABSTRACT = {The equivalent water thickness (EWT) is an important biophysical indicator of water status in crops. The effective monitoring of EWT in wheat under different nitrogen and water treatments is important for irrigation management in precision agriculture. This study aimed to investigate the performances of machine learning (ML) algorithms in retrieving wheat EWT. For this purpose, a rain shelter experiment (Exp. 1) with four irrigation quantities (0, 120, 240, 360 mm) and two nitrogen levels (75 and 255 kg N/ha), and field experiments (Exps. 2–3) with the same irrigation and rainfall water levels (360 mm) but different nitrogen levels (varying from 75 to 255 kg N/ha) were conducted in the North China Plain. The canopy reflectance was measured for all plots at 30 m using an unmanned aerial vehicle (UAV)-mounted multispectral camera. Destructive sampling was conducted immediately after the UAV flights to measure total fresh and dry weight. Deep Neural Network (DNN) is a special type of neural network, which has shown performance in regression analysis is compared with other machine learning (ML) models. A feature selection (FS) algorithm named the decision tree (DT) was used as the automatic relevance determination method to obtain the relative relevance of 5 out of 67 vegetation indices (Vis), which were used for estimating EWT. The selected VIs were used to estimate EWT using multiple linear regression (MLR), deep neural network multilayer perceptron (DNN-MLP), artificial neural networks multilayer perceptron (ANN-MLP), boosted tree regression (BRT), and support vector machines (SVMs). The results show that the DNN-MLP with R2 = 0.934, NSE = 0.933, RMSE = 0.028 g/cm2, and MAE of 0.017 g/cm2 outperformed other ML algorithms (ANN-MPL, BRT, and SVM- Polynomial) owing to its high capacity for estimating EWT as compared to other ML methods. Our findings support the conclusion that ML can potentially be applied in combination with VIs for retrieving EWT. Despite the complexity of the ML models, the EWT map should help farmers by improving the real-time irrigation efficiency of wheat by quantifying field water content and addressing variability.},
DOI = {10.3390/rs13214476}
}



@Article{rs13214486,
AUTHOR = {Rakhmatuiln, Ildar and Kamilaris, Andreas and Andreasen, Christian},
TITLE = {Deep Neural Networks to Detect Weeds from Crops in Agricultural Environments in Real-Time: A Review},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {21},
ARTICLE-NUMBER = {4486},
URL = {https://www.mdpi.com/2072-4292/13/21/4486},
ISSN = {2072-4292},
ABSTRACT = {Automation, including machine learning technologies, are becoming increasingly crucial in agriculture to increase productivity. Machine vision is one of the most popular parts of machine learning and has been widely used where advanced automation and control have been required. The trend has shifted from classical image processing and machine learning techniques to modern artificial intelligence (AI) and deep learning (DL) methods. Based on large training datasets and pre-trained models, DL-based methods have proven to be more accurate than previous traditional techniques. Machine vision has wide applications in agriculture, including the detection of weeds and pests in crops. Variation in lighting conditions, failures to transfer learning, and object occlusion constitute key challenges in this domain. Recently, DL has gained much attention due to its advantages in object detection, classification, and feature extraction. DL algorithms can automatically extract information from large amounts of data used to model complex problems and is, therefore, suitable for detecting and classifying weeds and crops. We present a systematic review of AI-based systems to detect weeds, emphasizing recent trends in DL. Various DL methods are discussed to clarify their overall potential, usefulness, and performance. This study indicates that several limitations obstruct the widespread adoption of AI/DL in commercial applications. Recommendations for overcoming these challenges are summarized.},
DOI = {10.3390/rs13214486}
}



@Article{rs13214489,
AUTHOR = {Chancia, Robert and Bates, Terry and Vanden Heuvel, Justine and van Aardt, Jan},
TITLE = {Assessing Grapevine Nutrient Status from Unmanned Aerial System (UAS) Hyperspectral Imagery},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {21},
ARTICLE-NUMBER = {4489},
URL = {https://www.mdpi.com/2072-4292/13/21/4489},
ISSN = {2072-4292},
ABSTRACT = {This study aimed to identify the optimal sets of spectral bands for monitoring multiple grapevine nutrients in vineyards. We used spectral data spanning 400–2500 nm and leaf samples from 100 Concord grapevine canopies, lab-analyzed for six key nutrient values, to select the optimal bands for the nutrient regression models. The canopy spectral data were obtained with unmanned aerial systems (UAS), using push-broom imaging spectrometers (hyperspectral sensors). The novel use of UAS-based hyperspectral imagery to assess the grapevine nutrient status fills the gap between in situ spectral sampling and UAS-based multispectral imaging, avoiding their inherent trade-offs between spatial and spectral resolution. We found that an ensemble feature ranking method, utilizing six different machine learning feature selection methods, produced similar regression results as the standard PLSR feature selection and regression while generally selecting fewer wavelengths. We identified a set of biochemically consistent bands (606, 641, and 1494 nm) to predict the nitrogen content with an RMSE of 0.17% (using leave-one-out cross-validation) in samples with nitrogen contents ranging between 2.4 and 3.6%. Further studying is needed to confirm the relevance and consistency of the wavelengths selected for each nutrient model, but ensemble feature selection showed promise in identifying stable sets of wavelengths for assessing grapevine nutrient contents from canopy spectra.},
DOI = {10.3390/rs13214489}
}



@Article{su132112327,
AUTHOR = {Georgiou, Nikos and Dimas, Xenophon and Papatheodorou, George},
TITLE = {Integrated Methodological Approach for the Documentation of Marine Priority Habitats and Submerged Antiquities: Examples from the Saronic Gulf, Greece},
JOURNAL = {Sustainability},
VOLUME = {13},
YEAR = {2021},
NUMBER = {21},
ARTICLE-NUMBER = {12327},
URL = {https://www.mdpi.com/2071-1050/13/21/12327},
ISSN = {2071-1050},
ABSTRACT = {The rising human activities and resource exploitation have increased pressure in the coastal zone and the marine environment, risking the very existence of Marine Priority Habitats (MPH) and Underwater Cultural Heritage (UCH). The delimitation of these two priority areas in a time- and cost-effective way is essential for the sustainable management and exploitation of sea resources and natural-cultural heritage preservation. We propose an Integrated Methodological Approach for the Detection and Mapping of MPH and UCH. To achieve this, we used a downscale methodological approach of increasing spatial resolution based on three main methodological axes: (i) desk-based research, (ii) marine geophysics/seafloor classification, and (iii) in-depth visual inspection/3D mapping. This methodological scheme was implemented at the Saronic Gulf and focused on Aegina island. The methodology proposed, which combines existing and new techniques, proved successful in detecting and mapping the MPH and UCH in detail, while it compiled the information necessary for the establishment of Marine Spatial Planning (MSP) maps. Finally, the MSP map constructed for the Saronic Gulf demonstrated the lack of holistic coastal zone management plans due to impacts on UCH linked to anthropogenic intervention and the sparsity of marine habitats owing to marine pollution.},
DOI = {10.3390/su132112327}
}



@Article{rs13224500,
AUTHOR = {He, Yixin and Wang, Dawei and Huang, Fanghui and Zhang, Yufei and Zhang, Ruonan and Yan, Xiaohong},
TITLE = {A RFID-Integrated Framework for Tag Anti-Collision in UAV-Aided VANETs},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {22},
ARTICLE-NUMBER = {4500},
URL = {https://www.mdpi.com/2072-4292/13/22/4500},
ISSN = {2072-4292},
ABSTRACT = {In this paper, we investigate tags in anti-collision applications of radio frequency identification (RFID) technology in unmanned aerial vehicle (UAV)-aided vehicular ad hoc networks (VANETs). The integration of RFID technology in UAV-aided VANETs can provide reliable traffic-related services for vehicles. However, multiple tags’ simultaneous responses to a reader mounted on a UAV, denoted as tag collision, gravely affect the correct tag detection on each vehicle. Therefore, in order to decrease the collision probability and improve the throughput, we propose a multi-frequency tag identification method. In the proposed scheme, we devise a tag grouping method based on adaptive power control to make the reader dynamically match the optimal frame length. Based on the above matching results, we introduce a tag estimation method using the optimal weight to improve the accuracy of tag estimation. We theoretically analyze the closed-form expression of the security outage probability expression. Finally, our simulation results demonstrate that the proposed tag anti-collision scheme achieved significant performance superiority in terms of the throughput and identification time slots.},
DOI = {10.3390/rs13224500}
}



@Article{app112210595,
AUTHOR = {Zhao, Wenlong and Meng, Zhijun and Wang, Kaipeng and Zhang, Jiahui and Lu, Shaoze},
TITLE = {Hierarchical Active Tracking Control for UAVs via Deep Reinforcement Learning},
JOURNAL = {Applied Sciences},
VOLUME = {11},
YEAR = {2021},
NUMBER = {22},
ARTICLE-NUMBER = {10595},
URL = {https://www.mdpi.com/2076-3417/11/22/10595},
ISSN = {2076-3417},
ABSTRACT = {Active tracking control is essential for UAVs to perform autonomous operations in GPS-denied environments. In the active tracking task, UAVs take high-dimensional raw images as input and execute motor actions to actively follow the dynamic target. Most research focuses on three-stage methods, which entail perception first, followed by high-level decision-making based on extracted spatial information of the dynamic target, and then UAV movement control, using a low-level dynamic controller. Perception methods based on deep neural networks are powerful but require considerable effort for manual ground truth labeling. Instead, we unify the perception and decision-making stages using a high-level controller and then leverage deep reinforcement learning to learn the mapping from raw images to the high-level action commands in the V-REP-based environment, where simulation data are infinite and inexpensive. This end-to-end method also has the advantages of a small parameter size and reduced effort requirements for parameter turning in the decision-making stage. The high-level controller, which has a novel architecture, explicitly encodes the spatial and temporal features of the dynamic target. Auxiliary segmentation and motion-in-depth losses are introduced to generate denser training signals for the high-level controller’s fast and stable training. The high-level controller and a conventional low-level PID controller constitute our hierarchical active tracking control framework for the UAVs’ active tracking task. Simulation experiments show that our controller trained with several augmentation techniques sufficiently generalizes dynamic targets with random appearances and velocities, and achieves significantly better performance, compared with three-stage methods.},
DOI = {10.3390/app112210595}
}



@Article{s21227484,
AUTHOR = {Hu, Aihua and Deng, Zhongliang and Yang, Hui and Zhang, Yao and Gao, Yuhui and Zhao, Di},
TITLE = {An Optimal Geometry Configuration Algorithm of Hybrid Semi-Passive Location System Based on Mayfly Optimization Algorithm},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {22},
ARTICLE-NUMBER = {7484},
URL = {https://www.mdpi.com/1424-8220/21/22/7484},
PubMedID = {34833560},
ISSN = {1424-8220},
ABSTRACT = {In view of the demand of location awareness in a special complex environment, for an unmanned aerial vehicle (UAV) airborne multi base-station semi-passive positioning system, the hybrid positioning solutions and optimized site layout in the positioning system can effectively improve the positioning accuracy for a specific region. In this paper, the geometric dilution of precision (GDOP) formula of a time difference of arrival (TDOA) and angles of arrival (AOA) hybrid location algorithm is deduced. Mayfly optimization algorithm (MOA) which is a new swarm intelligence optimization algorithm is introduced, and a method to find the optimal station of the UAV airborne multiple base station’s semi-passive positioning system using MOA is proposed. The simulation and analysis of the optimization of the different number of base stations, compared with other station layout methods, such as particle swarm optimization (PSO), genetic algorithm (GA), and artificial bee colony (ABC) algorithm. MOA is less likely to fall into local optimum, and the error of regional target positioning is reduced. By simulating the deployment of four base stations and five base stations in various situations, MOA can achieve a better deployment effect. The dynamic station configuration capability of the multi-station semi-passive positioning system has been improved with the UAV.},
DOI = {10.3390/s21227484}
}



@Article{ijgi10110762,
AUTHOR = {Jaalama, Kaisa and Kauhanen, Heikki and Keitaanniemi, Aino and Rantanen, Toni and Virtanen, Juho-Pekka and Julin, Arttu and Vaaja, Matti and Ingman, Matias and Ahlavuo, Marika and Hyyppä, Hannu},
TITLE = {3D Point Cloud Data in Conveying Information for Local Green Factor Assessment},
JOURNAL = {ISPRS International Journal of Geo-Information},
VOLUME = {10},
YEAR = {2021},
NUMBER = {11},
ARTICLE-NUMBER = {762},
URL = {https://www.mdpi.com/2220-9964/10/11/762},
ISSN = {2220-9964},
ABSTRACT = {The importance of ensuring the adequacy of urban ecosystem services and green infrastructure has been widely highlighted in multidisciplinary research. Meanwhile, the consolidation of cities has been a dominant trend in urban development and has led to the development and implementation of the green factor tool in cities such as Berlin, Melbourne, and Helsinki. In this study, elements of the green factor tool were monitored with laser-scanned and photogrammetrically derived point cloud datasets encompassing a yard in Espoo, Finland. The results show that with the support of 3D point clouds, it is possible to support the monitoring of the local green infrastructure, including elements of smaller size in green areas and yards. However, point clouds generated by distinct means have differing abilities in conveying information on green elements, and canopy covers, for example, might hinder these abilities. Additionally, some green factor elements are more promising for 3D measurement-based monitoring than others, such as those with clear geometrical form. The results encourage the involvement of 3D measuring technologies for monitoring local urban green infrastructure (UGI), also of small scale.},
DOI = {10.3390/ijgi10110762}
}



@Article{agronomy11112277,
AUTHOR = {Jensen, Signe M. and Akhter, Muhammad Javaid and Azim, Saiful and Rasmussen, Jesper},
TITLE = {The Predictive Power of Regression Models to Determine Grass Weed Infestations in Cereals Based on Drone Imagery—Statistical and Practical Aspects},
JOURNAL = {Agronomy},
VOLUME = {11},
YEAR = {2021},
NUMBER = {11},
ARTICLE-NUMBER = {2277},
URL = {https://www.mdpi.com/2073-4395/11/11/2277},
ISSN = {2073-4395},
ABSTRACT = {Site-specific weed management (SSWM) may reduce herbicide use by identifying weed patches and weed-free areas. However, one major constraint is robust weed detection algorithms that are able to predict weed infestations outside of the training data. This study investigates the predictive power of regression models trained on drone imagery that are used within fields to predict infestations of annual grass weeds in the late growth stages of cereals. The main objective was to identify the optimum sampling strategy for training regression models based on aerial RGB images. The study showed that training based on sampling from the whole range of weed infestations or the extreme values in the field provided better prediction accuracy than random sampling. Prediction models based on vegetation indices (VIs) offered a useful alternative to a more complex random forest machine-learning algorithm. For binary decision-making, linear regression utilizing weed density information resulted in higher accuracy than a logistic regression approach that only relied on information regarding the presence/absence of weeds. Across six fields, the average balanced accuracy based on linear regression was in the range of 75–83%, with the highest accuracy found when the sampling was from the extreme values in the field, and with the lowest accuracy found for random sampling. For future work on training weed prediction models, choosing training sets covering the entire sample space is recommended in favor of random sampling.},
DOI = {10.3390/agronomy11112277}
}



@Article{agronomy11112290,
AUTHOR = {Sadgrove, Edmund J. and Falzon, Greg and Miron, David and Lamb, David W.},
TITLE = {The Segmented Colour Feature Extreme Learning Machine: Applications in Agricultural Robotics},
JOURNAL = {Agronomy},
VOLUME = {11},
YEAR = {2021},
NUMBER = {11},
ARTICLE-NUMBER = {2290},
URL = {https://www.mdpi.com/2073-4395/11/11/2290},
ISSN = {2073-4395},
ABSTRACT = {This study presents the Segmented Colour Feature Extreme Learning Machine (SCF-ELM). The SCF-ELM is inspired by the Extreme Learning Machine (ELM) which is known for its rapid training and inference times. The ELM is therefore an ideal candidate for an ensemble learning algorithm. The Colour Feature Extreme Learning Machine (CF-ELM) is used in this study due to its additional ability to extract colour image features. The SCF-ELM is an ensemble learner that utilizes feature mapping via k-means clustering, a decision matrix and majority voting. It has been evaluated on a range of challenging agricultural object classification scenarios including weed, livestock and machinery detection. SCF-ELM model performance results were excellent both in terms of detection, 90 to 99% accuracy, and also inference times, around 0.01(s) per image. The SCF-ELM was able to compete or improve upon established algorithms in its class, indicating its potential for remote computing applications in agriculture.},
DOI = {10.3390/agronomy11112290}
}



@Article{electronics10222764,
AUTHOR = {Hassan, Syed-Ali and Rahim, Tariq and Shin, Soo-Young},
TITLE = {An Improved Deep Convolutional Neural Network-Based Autonomous Road Inspection Scheme Using Unmanned Aerial Vehicles},
JOURNAL = {Electronics},
VOLUME = {10},
YEAR = {2021},
NUMBER = {22},
ARTICLE-NUMBER = {2764},
URL = {https://www.mdpi.com/2079-9292/10/22/2764},
ISSN = {2079-9292},
ABSTRACT = {Recent advancements in the field of machine learning (ML) provide opportunity to conduct research on autonomous devices for a variety of applications. Intelligent decision-making is a critical task for self-driving systems. An attempt is made in this study to use a deep learning (DL) approach for the early detection of road cracks, potholes, and the yellow lane. The accuracy is not sufficient after training with the default model. To enhance accuracy, a convolutional neural network (CNN) model with 13 convolutional layers, a softmax layer as an output layer, and two fully connected layers (FCN) are constructed. In order to achieve the deeper propagation and to prevent saturation in the training phase, mish activation is employed in the first 12 layers with a rectified linear unit (ReLU) activation function. The upgraded CNN model performs better than the default CNN model in terms of accuracy. For the varied situation, a revised and enriched dataset for road cracks, potholes, and the yellow lane is created. The yellow lane is detected and tracked in order to move the unmanned aerial vehicle (UAV) autonomously by following yellow lane. After identifying a yellow lane, the UAV performs autonomous navigation while concurrently detecting road cracks and potholes using the robot operating system within the UAV. The performance model is benchmarked using performance measures, such as accuracy, sensitivity, F1-score, F2-score, and dice-coefficient, which demonstrate that the suggested technique produces better outcomes.},
DOI = {10.3390/electronics10222764}
}



@Article{app112210701,
AUTHOR = {Rosle, Rhushalshafira and Che’Ya, Nik Norasma and Ang, Yuhao and Rahmat, Fariq and Wayayok, Aimrun and Berahim, Zulkarami and Fazlil Ilahi, Wan Fazilah and Ismail, Mohd Razi and Omar, Mohamad Husni},
TITLE = {Weed Detection in Rice Fields Using Remote Sensing Technique: A Review},
JOURNAL = {Applied Sciences},
VOLUME = {11},
YEAR = {2021},
NUMBER = {22},
ARTICLE-NUMBER = {10701},
URL = {https://www.mdpi.com/2076-3417/11/22/10701},
ISSN = {2076-3417},
ABSTRACT = {This paper reviewed the weed problems in agriculture and how remote sensing techniques can detect weeds in rice fields. The comparison of weed detection between traditional practices and automated detection using remote sensing platforms is discussed. The ideal stage for controlling weeds in rice fields was highlighted, and the types of weeds usually found in paddy fields were listed. This paper will discuss weed detection using remote sensing techniques, and algorithms commonly used to differentiate them from crops are deliberated. However, weed detection in rice fields using remote sensing platforms is still in its early stages; weed detection in other crops is also discussed. Results show that machine learning (ML) and deep learning (DL) remote sensing techniques have successfully produced a high accuracy map for detecting weeds in crops using RS platforms. Therefore, this technology positively impacts weed management in many aspects, especially in terms of the economic perspective. The implementation of this technology into agricultural development could be extended further.},
DOI = {10.3390/app112210701}
}



@Article{app112210702,
AUTHOR = {Gonzalez-Aguirre, Juan Angel and Osorio-Oliveros, Ricardo and Rodríguez-Hernández, Karen L. and Lizárraga-Iturralde, Javier and Morales Menendez, Rubén and Ramírez-Mendoza, Ricardo A. and Ramírez-Moreno, Mauricio Adolfo and Lozoya-Santos, Jorge de Jesús},
TITLE = {Service Robots: Trends and Technology},
JOURNAL = {Applied Sciences},
VOLUME = {11},
YEAR = {2021},
NUMBER = {22},
ARTICLE-NUMBER = {10702},
URL = {https://www.mdpi.com/2076-3417/11/22/10702},
ISSN = {2076-3417},
ABSTRACT = {The 2021 sales volume in the market of service robots is attractive. Expert reports from the International Federation of Robotics confirm 27 billion USD in total market share. Moreover, the number of new startups with the denomination of service robots nowadays constitutes 29% of the total amount of robotic companies recorded in the United States. Those data, among other similar figures, remark the need for formal development in the service robots area, including knowledge transfer and literature reviews. Furthermore, the COVID-19 spread accelerated business units and some research groups to invest time and effort into the field of service robotics. Therefore, this research work intends to contribute to the formalization of service robots as an area of robotics, presenting a systematic review of scientific literature. First, a definition of service robots according to fundamental ontology is provided, followed by a detailed review covering technological applications; state-of-the-art, commercial technology; and application cases indexed on the consulted databases.},
DOI = {10.3390/app112210702}
}



@Article{rs13224560,
AUTHOR = {Luo, Lili and Chang, Qingrui and Wang, Qi and Huang, Yong},
TITLE = {Identification and Severity Monitoring of Maize Dwarf Mosaic Virus Infection Based on Hyperspectral Measurements},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {22},
ARTICLE-NUMBER = {4560},
URL = {https://www.mdpi.com/2072-4292/13/22/4560},
ISSN = {2072-4292},
ABSTRACT = {Prompt monitoring of maize dwarf mosaic virus (MDMV) is critical for the prevention and control of disease and to ensure high crop yield and quality. Here, we first analyzed the spectral differences between MDMV-infected red leaves and healthy leaves and constructed a sensitive index (SI) for measurements. Next, based on the characteristic bands (Rλ) associated with leaf anthocyanins (Anth), we determined vegetation indices (VIs) commonly used in plant physiological and biochemical parameter inversion and established a vegetation index (VIc) by utilizing the combination of two arbitrary bands following the construction principles of NDVI, DVI, RVI, and SAVI. Furthermore, we developed classification models based on linear discriminant analysis (LDA) and support vector machine (SVM) in order to distinguish the red leaves from healthy leaves. Finally, we performed UR, MLR, PLSR, PCR, and SVM simulations on Anth based on Rλ, VIs, VIc, and Rλ + VIs + VIc and indirectly estimated the severity of MDMV infection based on the relationship between the reflection spectra and Anth. Distinct from those of the normal leaves, the spectra of red leaves showed strong reflectance characteristics at 640 nm, and SI increased with increasing Anth. Moreover, the accuracy of the two VIc-based classification models was 100%, which is significantly higher than that of the VIs and Rλ-based models. Among the Anth regression models, the accuracy of the MLR model based on Rλ + VIs + VIc was the highest (R2c = 0.85; R2v = 0.74). The developed models could accurately identify MDMV and estimate the severity of its infection, laying the theoretical foundation for large-scale remote sensing-based monitoring of this virus in the future.},
DOI = {10.3390/rs13224560}
}



@Article{rs13224562,
AUTHOR = {Lei, Shuhan and Luo, Jianbiao and Tao, Xiaojun and Qiu, Zixuan},
TITLE = {Remote Sensing Detecting of Yellow Leaf Disease of Arecanut Based on UAV Multisource Sensors},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {22},
ARTICLE-NUMBER = {4562},
URL = {https://www.mdpi.com/2072-4292/13/22/4562},
ISSN = {2072-4292},
ABSTRACT = {Unmanned aerial vehicle (UAV) remote sensing technology can be used for fast and efficient monitoring of plant diseases and pests, but these techniques are qualitative expressions of plant diseases. However, the yellow leaf disease of arecanut in Hainan Province is similar to a plague, with an incidence rate of up to 90% in severely affected areas, and a qualitative expression is not conducive to the assessment of its severity and yield. Additionally, there exists a clear correlation between the damage caused by plant diseases and pests and the change in the living vegetation volume (LVV). However, the correlation between the severity of the yellow leaf disease of arecanut and LVV must be demonstrated through research. Therefore, this study aims to apply the multispectral data obtained by the UAV along with the high-resolution UAV remote sensing images to obtain five vegetation indexes such as the normalized difference vegetation index (NDVI), optimized soil adjusted vegetation index (OSAVI), leaf chlorophyll index (LCI), green normalized difference vegetation index (GNDVI), and normalized difference red edge (NDRE) index, and establish five algorithm models such as the back-propagation neural network (BPNN), decision tree, naïve Bayes, support vector machine (SVM), and k-nearest-neighbor classification to determine the severity of the yellow leaf disease of arecanut, which is expressed by the proportion of the yellowing area of a single areca crown (in percentage). The traditional qualitative expression of this disease is transformed into the quantitative expression of the yellow leaf disease of arecanut per plant. The results demonstrate that the classification accuracy of the test set of the BPNN algorithm and SVM algorithm is the highest, at 86.57% and 86.30%, respectively. Additionally, the UAV structure from motion technology is used to measure the LVV of a single areca tree and establish a model of the correlation between the LVV and the severity of the yellow leaf disease of arecanut. The results show that the relative root mean square error is between 34.763% and 39.324%. This study presents the novel quantitative expression of the severity of the yellow leaf disease of arecanut, along with the correlation between the LVV of areca and the severity of the yellow leaf disease of arecanut. Significant development is expected in the degree of integration of multispectral software and hardware, observation accuracy, and ease of use of UAVs owing to the rapid progress of spectral sensing technology and the image processing and analysis algorithms.},
DOI = {10.3390/rs13224562}
}



@Article{agriculture11111142,
AUTHOR = {Song, Huan and Hu, Yongguang and Lu, Yongzong and Wang, Jizhang and Pan, Qingmin and Li, Pingping},
TITLE = {A Review of Methods and Techniques for Detecting Frost on Plant Surfaces},
JOURNAL = {Agriculture},
VOLUME = {11},
YEAR = {2021},
NUMBER = {11},
ARTICLE-NUMBER = {1142},
URL = {https://www.mdpi.com/2077-0472/11/11/1142},
ISSN = {2077-0472},
ABSTRACT = {Severe frost usually has adverse impacts on agricultural production, resulting in crop freeze injury, poor crop yield, and crop quality reduction. Timely and accurate detection of frost plays an important role in cold damage warnings, prevention, and control. Current frost detection methods mostly use physical properties such as light, electricity, and heat, or the judge and quantify using environmental factors such as temperature and wind speed. However, it is difficult to detect and accurately identify the frosting phenomenon in real time during field trials because of the complex environment, different plant types, and interference by many factors during observation. To provide an overview of the analytical tools for scientists, researchers, and product developers, a review and comparative analysis of the available literature on frost mechanisms, correlations, and characteristics are presented in this study. First, the mechanisms of the frost formation process, frost level, and the significance of detection, are introduced. Then, the methods and techniques used to measure frost on plant surfaces are synthetically classified and further compared. Moreover, the key points and difficulties are summarized and discussed. Finally, some constructive methods of frost detection are proposed to improve the frost detection process.},
DOI = {10.3390/agriculture11111142}
}



@Article{rs13224591,
AUTHOR = {Zhou, Xiaoteng and Liu, Chun and Akbar, Akram and Xue, Yun and Zhou, Yuan},
TITLE = {Spectral and Spatial Feature Integrated Ensemble Learning Method for Grading Urban River Network Water Quality},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {22},
ARTICLE-NUMBER = {4591},
URL = {https://www.mdpi.com/2072-4292/13/22/4591},
ISSN = {2072-4292},
ABSTRACT = {Urban river networks have the characteristics of medium and micro scales, complex water quality, rapid change, and time–space incoherence. Aiming to monitor the water quality accurately, it is necessary to extract suitable features and establish a universal inversion model for key water quality parameters. In this paper, we describe a spectral- and spatial-feature-integrated ensemble learning method for urban river network water quality grading. We proposed an in situ sampling method for urban river networks. Factor and correlation analyses were applied to extract the spectral features. Moreover, we analyzed the maximum allowed bandwidth for feature bands. We demonstrated that spatial features can improve the accuracy of water quality grading using kernel canonical correlation analysis (KCCA). Based on the spectral and spatial features, an ensemble learning model was established for total phosphorus (TP) and ammonia nitrogen (NH3-N). Both models were evaluated by means of fivefold validation. Furthermore, we proposed an unmanned aerial vehicle (UAV)-borne water quality multispectral remote sensing application process for urban river networks. Based on the process, we tested the model in practice. The experiment confirmed that our model can improve the grading accuracy by 30% compared to other machine learning models that use only spectral features. Our research can extend the application field of water quality remote sensing to complex urban river networks.},
DOI = {10.3390/rs13224591}
}



@Article{rs13224606,
AUTHOR = {Eide, Austin and Koparan, Cengiz and Zhang, Yu and Ostlie, Michael and Howatt, Kirk and Sun, Xin},
TITLE = {UAV-Assisted Thermal Infrared and Multispectral Imaging of Weed Canopies for Glyphosate Resistance Detection},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {22},
ARTICLE-NUMBER = {4606},
URL = {https://www.mdpi.com/2072-4292/13/22/4606},
ISSN = {2072-4292},
ABSTRACT = {The foundation of contemporary weed management practices in many parts of the world is glyphosate. However, dependency on the effectiveness of herbicide practices has led to overuse through continuous growth of crops resistant to a single mode of action. In order to provide a cost-effective weed management strategy that does not promote glyphosate-resistant weed biotypes, differences between resistant and susceptible biotypes have to be identified accurately in the field conditions. Unmanned Aerial Vehicle (UAV)-assisted thermal and multispectral remote sensing has potential for detecting biophysical characteristics of weed biotypes during the growing season, which includes distinguishing glyphosate-susceptible and glyphosate-resistant weed populations based on canopy temperature and deep learning driven weed identification algorithms. The objective of this study was to identify herbicide resistance after glyphosate application in true field conditions by analyzing the UAV-acquired thermal and multispectral response of kochia, waterhemp, redroot pigweed, and common ragweed. The data were processed in ArcGIS for raster classification as well as spectral comparison of glyphosate-resistant and glyphosate-susceptible weeds. The classification accuracy between the sensors and classification methods of maximum likelihood, random trees, and Support Vector Machine (SVM) were compared. The random trees classifier performed the best at 4 days after application (DAA) for kochia with 62.9% accuracy. The maximum likelihood classifier provided the highest performing result out of all classification methods with an accuracy of 75.2%. A commendable classification was made at 8 DAA where the random trees classifier attained an accuracy of 87.2%. However, thermal reflectance measurements as a predictor for glyphosate resistance within weed populations in field condition was unreliable due to its susceptibility to environmental conditions. Normalized Difference Vegetation Index (NDVI) and a composite reflectance of 842 nm, 705 nm, and 740 nm wavelength managed to provide better classification results than thermal in most cases.},
DOI = {10.3390/rs13224606}
}



@Article{rs13224609,
AUTHOR = {Pan, Baihong and Zheng, Yi and Shen, Ruoque and Ye, Tao and Zhao, Wenzhi and Dong, Jie and Ma, Hanqing and Yuan, Wenping},
TITLE = {High Resolution Distribution Dataset of Double-Season Paddy Rice in China},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {22},
ARTICLE-NUMBER = {4609},
URL = {https://www.mdpi.com/2072-4292/13/22/4609},
ISSN = {2072-4292},
ABSTRACT = {Although China is the largest producer of rice, accounting for about 25% of global production, there are no high-resolution maps of paddy rice covering the entire country. Using time-weighted dynamic time warping (TWDTW), this study developed a pixel- and phenology-based method to identify planting areas of double-season paddy rice in China, by comparing temporal variations of synthetic aperture radar (SAR) signals of unknown pixels to those of known double-season paddy rice fields. We conducted a comprehensive evaluation of the method’s performance at pixel and regional scales. Based on 145,210 field surveyed samples from 2018 to 2020, the producer’s and user’s accuracy are 88.49% and 87.02%, respectively. Compared to county-level statistical data from 2016 to 2019, the relative mean absolute errors are 34.11%. This study produced distribution maps of double-season rice at 10 m spatial resolution from 2016 to 2020 over nine provinces in South China, which account for more than 99% of the planting areas of double-season paddy rice of China. The maps are expected to contribute to timely monitoring and evaluating rice growth and yield.},
DOI = {10.3390/rs13224609}
}



@Article{jimaging7110241,
AUTHOR = {Moussaid, Abdellatif and Fkihi, Sanaa El and Zennayi, Yahya},
TITLE = {Tree Crowns Segmentation and Classification in Overlapping Orchards Based on Satellite Images and Unsupervised Learning Algorithms},
JOURNAL = {Journal of Imaging},
VOLUME = {7},
YEAR = {2021},
NUMBER = {11},
ARTICLE-NUMBER = {241},
URL = {https://www.mdpi.com/2313-433X/7/11/241},
PubMedID = {34821872},
ISSN = {2313-433X},
ABSTRACT = {Smart agriculture is a new concept that combines agriculture and new technologies to improve the yield’s quality and quantity as well as facilitate many tasks for farmers in managing orchards. An essential factor in smart agriculture is tree crown segmentation, which helps farmers automatically monitor their orchards and get information about each tree. However, one of the main problems, in this case, is when the trees are close to each other, which means that it would be difficult for the algorithm to delineate the crowns correctly. This paper used satellite images and machine learning algorithms to segment and classify trees in overlapping orchards. The data used are images from the Moroccan Mohammed VI satellite, and the study region is the OUARGHA citrus orchard located in Morocco. Our approach starts by segmenting the rows inside the parcel and finding all the trees there, getting their canopies, and classifying them by size. In general, the model inputs the parcel’s image and other field measurements to classify the trees into three classes: missing/weak, normal, or big. Finally, the results are visualized in a map containing all the trees with their classes. For the results, we obtained a score of 0.93 F-measure in rows segmentation. Additionally, several field comparisons were performed to validate the classification, dozens of trees were compared and the results were very good. This paper aims to help farmers to quickly and automatically classify trees by crown size, even if there are overlapping orchards, in order to easily monitor each tree’s health and understand the tree’s distribution in the field.},
DOI = {10.3390/jimaging7110241}
}



@Article{sym13112190,
AUTHOR = {Hashim, Wahidah and Eng, Lim Soon and Alkawsi, Gamal and Ismail, Rozita and Alkahtani, Ammar Ahmed and Dzulkifly, Sumayyah and Baashar, Yahia and Hussain, Azham},
TITLE = {A Hybrid Vegetation Detection Framework: Integrating Vegetation Indices and Convolutional Neural Network},
JOURNAL = {Symmetry},
VOLUME = {13},
YEAR = {2021},
NUMBER = {11},
ARTICLE-NUMBER = {2190},
URL = {https://www.mdpi.com/2073-8994/13/11/2190},
ISSN = {2073-8994},
ABSTRACT = {Vegetation inspection and monitoring is a time-consuming task. In the era of industrial revolution 4.0 (IR 4.0), unmanned aerial vehicles (UAV), commercially known as drones, are in demand, being adopted for vegetation inspection and monitoring activities. However, most off-the-shelf drones are least favoured by vegetation maintenance departments for on-site inspection due to limited spectral bands camera restricting advanced vegetation analysis. Most of these drones are normally equipped with a normal red, green, and blue (RGB) camera. Additional spectral bands are found to produce more accurate analysis during vegetation inspection, but at the cost of advanced camera functionalities, such as multispectral camera. Vegetation indices (VI) is a technique to maximize detection sensitivity related to vegetation characteristics while minimizing other factors which are not categorised otherwise. The emergence of machine learning has slowly influenced the existing vegetation analysis technique in order to improve detection accuracy. This study focuses on exploring VI techniques in identifying vegetation objects. The selected VIs investigated are Visible Atmospheric Resistant Index (VARI), Green Leaf Index (GLI), and Vegetation Index Green (VIgreen). The chosen machine learning technique is You Only Look Once (YOLO), which is a clever convolutional neural network (CNN) offering object detection in real time. The CNN model has a symmetrical structure along the direction of the tensor flow. Several series of data collection have been conducted at identified locations to obtain aerial images. The proposed hybrid methods were tested on captured aerial images to observe vegetation detection performance. Segmentation in image analysis is a process to divide the targeted pixels for further detection testing. Based on our findings, more than 70% of the vegetation objects in the images were accurately detected, which reduces the misdetection issue faced by previous VI techniques. On the other hand, hybrid segmentation methods perform best with the combination of VARI and YOLO at 84% detection accuracy.},
DOI = {10.3390/sym13112190}
}




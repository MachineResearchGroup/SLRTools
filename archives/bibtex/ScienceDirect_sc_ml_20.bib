@article{WANG2021100031,
title = {An investigation of barriers to Hong Kong K-12 schools incorporating Artificial Intelligence in education},
journal = {Computers and Education: Artificial Intelligence},
volume = {2},
pages = {100031},
year = {2021},
issn = {2666-920X},
doi = {https://doi.org/10.1016/j.caeai.2021.100031},
url = {https://www.sciencedirect.com/science/article/pii/S2666920X21000254},
author = {Tianchong Wang and Eric Chi Keung Cheng},
keywords = {AI in Education, Barrier to change, K-12 education},
abstract = {Artificial Intelligence in Education (AIED) has been the focus of significant attention in recent years because of its growing social importance and pedagogical value. In Hong Kong, an increasing number of K-12 schools are planning or piloting their grassroots AIED incorporation practices. However, progress is reportedly slow due to a number of barriers. Unfortunately, because of their limited scope, disputed interpretations and contextual irrelevance, current research literature seems to be of limited referencing value in aiding schools to address the issues and overcome the barriers. This paper highlights the necessity of embracing AIED as wide-ranging given the current understanding of it as a collective notion. Three major directions of AIED are identified: Learning from AI, Learning about AI, and Learning with AI. A collective case study, which examined the perceived barriers to AIED incorporation in Hong Kong K-12 schools with different AIED directions, was conducted. Qualitative data were gathered via ten semi-structured interviews with key stakeholders from two schools. Ertmer’s (1999) typology was applied to segregate the barriers. The findings showed that both first-order and second-order barriers existed, although they varied between the cases. It was also found that the barriers did not hinder in isolation but appeared to be interconnected. The findings suggest that schools use differentiated strategies to tackle barriers according to their approach to incorporating AIED. Moreover, there is a need to trace the links between barriers and prioritise school efforts to remove or reduce them with high linkage. Several recommendations for practice are given.}
}
@article{PAN2021103435,
title = {Digital interoperability in logistics and supply chain management: state-of-the-art and research avenues towards Physical Internet},
journal = {Computers in Industry},
volume = {128},
pages = {103435},
year = {2021},
issn = {0166-3615},
doi = {https://doi.org/10.1016/j.compind.2021.103435},
url = {https://www.sciencedirect.com/science/article/pii/S0166361521000427},
author = {Shenle Pan and Damien Trentesaux and Duncan McFarlane and Benoit Montreuil and Eric Ballot and George Q. Huang},
keywords = {Interoperability, Interconnection, Physical internet, Digitalization, Logistics, Supply Chain management, Bibliometric review, State-of-the-art, Research avenues},
abstract = {Interoperability is playing an increasing role for today’s logistics and supply chain management (LSCM) because of the trends of cooperation or coopetition. Especially, digital interoperability concerning data or information exchange becomes a key enabler for the next evolutions that will massively rely upon digitalization, artificial intelligence, and autonomous systems. The notion of Physical Internet (PI) is one such evolution, an innovative worldwide logistic paradigm aimed at interconnecting and coordinating logistics networks for efficiency and sustainability. This paper investigates how digital interoperability can help interconnect logistics and supply networks as well as the operational solutions for sustainable development, and examines the new challenges and research opportunities for digital interoperability under the PI paradigm. To this end, we study the most relevant technologies for digital interoperability in LSCM, via a bibliometric analysis based on 208 papers published during 2010−2020. The results reveal that the present state-of-the-art solutions of digital interoperability are not fully aligned with PI requirements and show new challenges, research gaps and opportunities that need further discussion. Accordingly, several research avenues are suggested to advance research and applications in this area, and to achieve interconnection in logistics and supply networks for sustainability.}
}
@article{WONGTHONGTHAM2021107299,
title = {Blockchain-enabled Peer-to-Peer energy trading},
journal = {Computers & Electrical Engineering},
volume = {94},
pages = {107299},
year = {2021},
issn = {0045-7906},
doi = {https://doi.org/10.1016/j.compeleceng.2021.107299},
url = {https://www.sciencedirect.com/science/article/pii/S0045790621002780},
author = {Pornpit Wongthongtham and Daniel Marrable and Bilal Abu-Salih and Xin Liu and Greg Morrison},
keywords = {Blockchain, Peer-to-Peer, Energy trading, Electricity markets},
abstract = {The increasing amount of distributed power generation from rooftop solar panels allows new electricity markets to emerge in which prosumers and consumers can trade locally produced energy. The use of blockchain technology has increasingly emerged in energy markets and shows great potential to facilitate Peer-to-Peer energy trading. However, blockchain technology is still in its infancy meaning it is not yet being used to its’ full potential. In this paper, blockchain technology for Peer-to-Peer energy trading and its implications are explored, especially in view of the ‘trilemma’: scalability, security, and decentralisation. Peer-to-Peer energy trading is the focus of this paper, which ultimately proposes a blockchain scalability solution. This solution is empirically modelled using data collected in a trial case study. The proposed solution increases scalability without compromising security and decentralisation when compared to base layer models.}
}
@article{SALIMITARI2020100212,
title = {A survey on consensus methods in blockchain for resource-constrained IoT networks},
journal = {Internet of Things},
volume = {11},
pages = {100212},
year = {2020},
issn = {2542-6605},
doi = {https://doi.org/10.1016/j.iot.2020.100212},
url = {https://www.sciencedirect.com/science/article/pii/S2542660520300482},
author = {Mehrdad Salimitari and Mainak Chatterjee and Yaser P. Fallah},
keywords = {Blockchain, Consensus method, Internet of things (IoT), Hyperledger, AI-enabled blockchain},
abstract = {The success of blockchain as the underlying technology for cryptocurrencies has opened up possibilities for its use in other application domains as well. The main advantages of blockchain for its potential use in other areas are its inherent security mechanisms and immunity to data manipulation attacks. A blockchain relies on a consensus method for agreeing on any new data. Most of the consensus methods which are currently used for the blockchain of different cryptocurrencies require high computational power and thus are not suitable for resource-constrained systems. In this article, we survey the various blockchain-based consensus methods that are applicable to resource-constrained IoT devices and networks. In a typical IoT network, there exist several devices with limited computational and communication capabilities. Most often, these devices cannot perform intensive computations and are starved for bandwidth. Therefore, we discuss the possible measures that can be taken to reduce the computational power and convergence time for the underlying consensus methods. We also talk about some of the alternatives to the public blockchain, such as private blockchain and tangle, along with their potential adoption for IoT networks. Furthermore, we review the existing consensus methods that have been implemented and explore the possibility of utilizing them to realize a blockchain-based IoT network. Some of the open research challenges including AI-enabled blockchains are also put forward.}
}
@article{CHEN2020204,
title = {A security integration model for private data of intelligent mobile communication based on edge computing},
journal = {Computer Communications},
volume = {162},
pages = {204-211},
year = {2020},
issn = {0140-3664},
doi = {https://doi.org/10.1016/j.comcom.2020.08.026},
url = {https://www.sciencedirect.com/science/article/pii/S0140366420319137},
author = {Xiang Chen},
keywords = {Intelligent mobile communication, Edge computing, Security integration model, Private data},
abstract = {This paper proposes a security integration model of mobile intelligent private data for edge computing. According to the characteristics of the heterogeneous network of edge computing networks, the network is layered according to the mobile intelligent private data structure. The homomorphism encryption algorithm is adopted to enable private data to be transmitted and stored in the form of ciphertext on the edge network and the mobile terminal. The encryption model ensures that the device data is not peeped by malicious attackers. Besides, the application layer system model is designed to enable service providers to integrate their hardware resources and provide a unified edge computing solution for different data owners. The experiment evaluated its encryption performance and system availability. An edge network security defense model based on a mean-field game is established, and an edge network security defense algorithm is proposed. Based on the study of the relationship between the individual edge network equipment’s optimal defense strategy and the overall edge network’s optimal defense strategy, the individual cost of the edge network equipment is analyzed by proving the existence of the edge network equipment balance. The optimal conditions between the overall cost of the edge network are given under this condition. The simulation results showed that for large-scale edge network devices, the model realized the unity of the optimal defense strategies of the individual edge network devices and the entire edge network, and effectively reduces the consumption of computing resources of the edge network devices Because all migration strategies allow all devices to migrate their computing tasks to MBS, leading to severe uplink and downlink congestion, wireless transmission energy consumption has increased dramatically. The energy consumption of migration calculation is higher than that of local calculation.}
}
@article{TSENG2021101606,
title = {Developmental trajectories of blockchain research and its major subfields},
journal = {Technology in Society},
volume = {66},
pages = {101606},
year = {2021},
issn = {0160-791X},
doi = {https://doi.org/10.1016/j.techsoc.2021.101606},
url = {https://www.sciencedirect.com/science/article/pii/S0160791X21000816},
author = {Fang-Mei Tseng and Eunice Ina N. {Palma Gil} and Louis Y.Y. Lu},
keywords = {Blockchain, Girvan-Newman clustering, Key-route analysis, Main path analysis, Smart contract, Technology trajectory},
abstract = {Unlike previous reviews, most of which focus on a field and use qualitative methods to analyze blockchain technology, herein main path analysis was used to determine the key route of citations and identify the developmental trajectories of blockchain technology and its major themes. A total of 3159 blockchain-related articles published through August 5, 2019, were gathered from the Web of Science. In all, 2478 articles formed the citation network, 27 of which were on the key route. These 27 key papers on blockchain represented the four developmental stages. Stage 1 focused on challenges to bitcoin. Stage 2 focused on smart contract issues. Stage 3 focused on opportunities, challenges, and development in blockchain. Finally, Stage 4 focused on smart contract applications, especially in e-healthcare, where blockchain technology is paving the way to a quicker, more secure, and more efficient means of storing and accessing medical data. The Girvan-Newman clustering technique was used to classify articles, and keyword analysis was used to analyze the top six major themes. These were bitcoin security, bitcoin financial applications, e-healthcare, Ethereum smart contracts, security and privacy in IoT, and energy. Main path analysis was also used to analyze their developmental trends. The results have significant value for both academics and practitioners.}
}
@article{SHA2020195,
title = {A survey of edge computing-based designs for IoT security},
journal = {Digital Communications and Networks},
volume = {6},
number = {2},
pages = {195-202},
year = {2020},
issn = {2352-8648},
doi = {https://doi.org/10.1016/j.dcan.2019.08.006},
url = {https://www.sciencedirect.com/science/article/pii/S2352864818303018},
author = {Kewei Sha and T. Andrew Yang and Wei Wei and Sadegh Davari},
keywords = {Edge computing, Internet of Things (IoT), Security, Architecture, Secure protocols, Firewall, Intrusion detection, Authentication, Authorization, Privacy},
abstract = {Pervasive IoT applications enable us to perceive, analyze, control, and optimize the traditional physical systems. Recently, security breaches in many IoT applications have indicated that IoT applications may put the physical systems at risk. Severe resource constraints and insufficient security design are two major causes of many security problems in IoT applications. As an extension of the cloud, the emerging edge computing with rich resources provides us a new venue to design and deploy novel security solutions for IoT applications. Although there are some research efforts in this area, edge-based security designs for IoT applications are still in its infancy. This paper aims to present a comprehensive survey of existing IoT security solutions at the edge layer as well as to inspire more edge-based IoT security designs. We first present an edge-centric IoT architecture. Then, we extensively review the edge-based IoT security research efforts in the context of security architecture designs, firewalls, intrusion detection systems, authentication and authorization protocols, and privacy-preserving mechanisms. Finally, we propose our insight into future research directions and open research issues.}
}
@article{JARDIM2022199,
title = {Customer reviews sentiment-based analysis and clustering for market-oriented tourism services and products development or positioning},
journal = {Procedia Computer Science},
volume = {196},
pages = {199-206},
year = {2022},
note = {International Conference on ENTERprise Information Systems / ProjMAN - International Conference on Project MANagement / HCist - International Conference on Health and Social Care Information Systems and Technologies 2021},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2021.12.006},
url = {https://www.sciencedirect.com/science/article/pii/S1877050921022298},
author = {Sandra Jardim and Carlos Mora},
keywords = {sentiment analysis, automatic sentiment classification, lexicon-based approach, customer reviews, customer segmentation},
abstract = {This paper proposes a method that allows the clustering and identification of similarities between users of a digital tourism platform, through the extraction of the sentiments expressed by them in the reviews or comments registered and the subsequent automatic clustering of the users, according to the polarity of sentiments subjectively expressed in their posts. This research fills a gap in the text mining literature for the development, improvement and/or reorientation of services and products in the field of tourism, providing a method to explore the needs and desires of the client based on their digital footprint drawn from posts and reviews about the service or product in question. The sentiment analysis is detailed, comprehending language detection and some specific language syntax treatment, with a subsequent explanation of the clustering algorithm used. The developed algorithm was tested in the user’s segmentation and sentiment analysis of their publications on a digital tourism platform. The results obtained demonstrate the efficiency of the solution, which presents a high accuracy in the classification of publications in four different languages and in the user’s segmentation process.}
}
@article{SUBBU201733,
title = {Big Data for Context Aware Computing – Perspectives and Challenges},
journal = {Big Data Research},
volume = {10},
pages = {33-43},
year = {2017},
issn = {2214-5796},
doi = {https://doi.org/10.1016/j.bdr.2017.10.002},
url = {https://www.sciencedirect.com/science/article/pii/S2214579616300077},
author = {Kalyan P. Subbu and Athanasios V. Vasilakos},
keywords = {Big data, Context Awareness, Smartphones, Sensors, Internet of Things, Wireless Sensor Networks},
abstract = {Big data has arrived. Myriad applications, systems generate data of humongous volumes, variety and velocity which traditional computing systems and databases are unable to manage. The proliferation of sensors in every possible device is also becoming one of the major generators of Big data. Of particular interest in this article is how context aware computing systems which derive context from data and act accordingly, deal with such huge amounts of data. Big industry players namely Google, Yahoo, and Amazon are already developing context aware applications using user data from emails, chat messages, browsing and shopping histories etc. For instance, Gmail reminds us of our flight schedule by understanding flight booking related content in our emails. Similarly, Amazon understands user preference and recommends items of interest to shop and so on. In this paper, we survey context aware computing systems from a Big data perspective. We first propose a taxonomy of existing work on the basis of sensing platforms and then discuss the latest developments in this field of Big data context aware systems focusing on how such systems deal with various Big data challenges. We conclude the paper with an insight on open research issues involving designing and developing context aware Big data generating systems.}
}
@article{PHUNG201588,
title = {Schedule-based multi-channel communication in wireless sensor networks: A complete design and performance evaluation},
journal = {Ad Hoc Networks},
volume = {26},
pages = {88-102},
year = {2015},
issn = {1570-8705},
doi = {https://doi.org/10.1016/j.adhoc.2014.11.008},
url = {https://www.sciencedirect.com/science/article/pii/S157087051400242X},
author = {Kieu-Ha Phung and Bart Lemmens and Marnix Goossens and Ann Nowe and Lan Tran and Kris Steenhaut},
keywords = {Multi-channel communication, Schedule-based, MAC protocol, Reinforcement Learning, Test-bed, Wireless sensor networks},
abstract = {Recently, wireless sensor networks (WSNs), enabling the connection between the physical world and the digital world, have become an important component of the Internet of Things (IoT). Several applications in the IoT require the efficient and timely collection of larger amounts of data. Due to the interference and contention over the wireless medium, the limited bandwidth of the radios, the limited resources of the battery-operated sensor nodes, this requirement becomes a challenging task. In this research, we exploit the multi-channel operation capability of the radios to provide the higher network throughput and propose an efficient scheduling algorithm to eliminate collision, idle-listening or over-hearing, which are consequences of non-coordinated transmissions. Our work focuses on scheduling the regular traffic that is periodically transmitted and on adapting the schedule to the additional traffic that can be requested at some point in time. To deploy the schedule-based multi-channel protocol on real applications, we design the complete communication procedure that is necessary for sensor nodes to communicate among them to form a network and to propagate the sensed data to the collection point. We also propose a low-overhead time synchronization scheme that is critical for a schedule-based protocol. The results of extensive simulation experiments show that the proposed scheduling algorithm can achieve collision-free parallel transmissions over different channels to provide high throughput and high delivery ratio while meeting the crucial energy efficiency requirements. Finally, we demonstrate the feasibility of the protocol and the time synchronization scheme on a laboratory-scaled test-bed of real motes.}
}
@article{CHEN2016200,
title = {Mapping the fine-scale spatial pattern of housing rent in the metropolitan area by using online rental listings and ensemble learning},
journal = {Applied Geography},
volume = {75},
pages = {200-212},
year = {2016},
issn = {0143-6228},
doi = {https://doi.org/10.1016/j.apgeog.2016.08.011},
url = {https://www.sciencedirect.com/science/article/pii/S0143622816303204},
author = {Yimin Chen and Xiaoping Liu and Xia Li and Yilun Liu and Xiaocong Xu},
keywords = {Housing rent mapping, Online rental listings, Anjuke, Ensemble learning},
abstract = {Abstracts
The accurate mapping of housing rent is crucial to the understanding of residential dynamics. In this study, we proposed the use of online rental listings as a new reliable data source for mapping housing rent. With the collected individual rental information from an online platform, we attempted to produce the fine-scale spatial pattern of housing rent in the metropolitan area of Guangzhou, China, at the neighborhood committee (NC) level. This involves the task of estimating the housing rent for areas with no observation data of housing rent. To this end, we evaluated six numeric prediction methods of machine learning. We further enhanced their performance through ensemble learning, an approach which can form new classifiers with even better performance than any of the individual constituent classifiers. We implemented ensemble learning through ways of bagging and stacking, and selected the most accurate ensemble classifier to produce the spatial pattern of housing rent at the NC-level. In the resulting housing rent pattern, we identified a distance decay relationship between the housing rent and the distance from the city center. The data sources and the ensemble learning platform in this application of housing rent mapping are generally open access. Therefore, the proposed approach in this study can provide useful hints for housing rent mapping in other geographical areas. Our mapping results can also be integrated with additional information to support the studies of urban residential problems in China.}
}
@article{WANG2022107394,
title = {Data-driven prediction method for characteristics of voltage sag based on fuzzy time series},
journal = {International Journal of Electrical Power & Energy Systems},
volume = {134},
pages = {107394},
year = {2022},
issn = {0142-0615},
doi = {https://doi.org/10.1016/j.ijepes.2021.107394},
url = {https://www.sciencedirect.com/science/article/pii/S0142061521006335},
author = {Ying Wang and Min-hui Yang and Hua-ying Zhang and Xian Wu and Wen-xi Hu},
keywords = {Voltage sag, Fuzzy time series, Homologous aggregation, Fuzzy c-means algorithm, Hidden Markov model},
abstract = {To inform the power utility and users, and help them reduce the huge financial losses due to voltage sag, it is important to obtain information on voltage sag events in advance. This paper proposes a method for predicting voltage sag characteristics based on fuzzy time series. First, we propose a homologous aggregation method to eliminate redundant data representing the same disturbance event and obtain the time series of voltage sag (TSOVS), which can describe the trend of the voltage sag data. Second, this paper introduces a fuzzification method for the time series of voltage sag based on the fuzzy c-means algorithm (FCMA), which transforms the time series of voltage sag into a fuzzy time series composed of interval symbols, to characterize the mapping relationship between the disturbance and voltage sag event. Furthermore, a hidden Markov model (HMM) of voltage sag is constructed to reveal the transformation relationship among elements in the fuzzy time series, considering the causal relationship between the disturbance and voltage sag event. Finally, the occurrence time and residual voltage of the voltage sag in the future were predicted based on this transformation relation. The measured voltage sags in a province in central China were used to verify the accuracy of the proposed method, prediction results with an accuracy of up to 90%.}
}
@article{SOUZA2022108403,
title = {City Information Modelling as a support decision tool for planning and management of cities: A systematic literature review and bibliometric analysis},
journal = {Building and Environment},
volume = {207},
pages = {108403},
year = {2022},
issn = {0360-1323},
doi = {https://doi.org/10.1016/j.buildenv.2021.108403},
url = {https://www.sciencedirect.com/science/article/pii/S0360132321008003},
author = {Letícia Souza and Cristiane Bueno},
keywords = {City information modelling, Support decision tool, Urban management tool, Future urban planning},
abstract = {The growing demand of the population has caused serious problems for cities and has become one of the main challenges for city managers. This demand has occurred much faster than the tooling of public management. In this context, the urgent need for implementations that meet current requirements highlighting the advantages of City Information Modelling (CIM). The CIM helps in the search for information on future demands, providing a holistic view of the city. However, the absence of a full application and an established concept has been observed in the literature. Considering this, a systematic literature review and bibliometric analysis was conducted, resulting in 80 articles that composed the final analysis. We identified five recurring topics in the articles, the most important of the CIM, and discussed them in depth. We found a direction towards the CIM concept: the integration of Building Information Modelling (BIM), geographic information system (GIS), and a complete and up-to-date urban database, which enables analysis and simulation. The research concluded that a major effort will still be needed to establish the CIM, and its full implementation also depends on the dissemination of knowledge and demonstration of the tool's potential.}
}
@article{LIM2020371,
title = {Toward Semantic IoT Load Inference Attention Management for Facilitating Healthcare and Public Health Collaboration: A Survey},
journal = {Procedia Computer Science},
volume = {177},
pages = {371-378},
year = {2020},
note = {The 11th International Conference on Emerging Ubiquitous Systems and Pervasive Networks (EUSPN 2020) / The 10th International Conference on Current and Future Trends of Information and Communication Technologies in Healthcare (ICTH 2020) / Affiliated Workshops},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2020.10.050},
url = {https://www.sciencedirect.com/science/article/pii/S1877050920323188},
author = {Sachiko Lim and Rahim Rahmani},
keywords = {Semantic IoT, Federated edge-cloud computing, semantic interoperability, Healthcare, Public Health, Crisis management},
abstract = {The health of individuals and populations requires concerted and collaborative efforts by healthcare, public health, social care, and personal health management. The inter-sectoral collaborations are more crucial than ever, especially when facing public health crises, including the ongoing pandemic of coronavirus disease-2019 (COVID-19). Although the capabilities of healthcare and public health systems have increased with a dramatic boost in the use of the Internet of Things (IoT), such IoT-enabled systems are often operating in silos. A pressing need, thus, is the seamless integration of those currently incompatible systems. A promising solution is to leverage semantic technologies to increase interoperability among such systems. Therefore, this article aims to: conduct a systematic review on the current state-of-the-art semantic IoT solutions used in health domain; identify the associated challenges; propose a federated edge-cloud semantic IoT architecture to facilitate the healthcare and public health (HC-PH) collaborations for the health and well-being of the individuals and populations.}
}
@article{LI2019237,
title = {One-pass person re-identification by sketch online discriminant analysis},
journal = {Pattern Recognition},
volume = {93},
pages = {237-250},
year = {2019},
issn = {0031-3203},
doi = {https://doi.org/10.1016/j.patcog.2019.03.015},
url = {https://www.sciencedirect.com/science/article/pii/S0031320319301220},
author = {Wei-Hong Li and Zhuowei Zhong and Wei-Shi Zheng},
keywords = {Online learning, Person re-identification, Discriminant feature extraction},
abstract = {Person re-identification (re-id) is to match people across disjoint camera views in a multi-camera system, and re-id has been an important technology applied in smart city in recent years. However, the majority of existing person re-id methods assumes all data samples are available in advance for training. However, in a real-world scenario person images detected from multi-camera system are coming sequentially, and thus these methods are not designed for processing sequential data in an online way. While there is a few work on discussing online re-id, most of them require considerable storage of all passed labelled data samples that have been ever observed. In this work, we present an one-pass person re-id model that adapts the re-id model based on each newly observed data and no passed data are required for each update. More specifically, we develop a Sketch online Discriminant Analysis (SoDA) by embedding sketch processing into Fisher discriminant analysis (FDA). SoDA can efficiently keep the main data variations of all passed samples in a low rank matrix when processing sequential data samples, and estimate the approximate within-class variance (i.e. within-class covariance matrix) from the sketch data information. We provide theoretical analysis on the effect of the estimated approximate within-class covariance matrix. In particular, we derive upper and lower bounds on the Fisher discriminant score (i.e. the quotient between between-class variation and within-class variation after feature transformation) in order to investigate how the optimal feature transformation learned by SoDA sequentially approximates the offline FDA that is learned on all observed data. Extensive experimental results have shown the effectiveness of our SoDA and empirically support our theoretical analysis.}
}
@article{CHEN2021103184,
title = {Learning to locate for fine-grained image recognition},
journal = {Computer Vision and Image Understanding},
volume = {206},
pages = {103184},
year = {2021},
issn = {1077-3142},
doi = {https://doi.org/10.1016/j.cviu.2021.103184},
url = {https://www.sciencedirect.com/science/article/pii/S107731422100028X},
author = {Jiamin Chen and Jianguo Hu and Shiren Li},
keywords = {Background suppression, CNN, Feature extraction, Fine-grained image recognition, Salient point detection, Weakly supervised},
abstract = {In this paper, we propose an end-to-end weakly supervised method for fine-grained image recognition called bounding box-part location method(BBPL), which can locate the object and part precisely without part annotations. The proposed method includes three modules: object detection, ObjectMask, and classification. Firstly, the object detection module predicts the bounding boxes, and the predicted bounding boxes are employed to generate a mask through ObjectMask module. The generated mask can suppress the background interference during recognition. Secondly, the classification module can be further divided into two branches, which are global feature classification and local feature classification. In global feature classification branch, global feature is extracted to get global classification result. While in local feature classification branch, salient point is first detected through our novel salient point detection module, which can greatly reduce the consuming-time compared with the most existing local feature extraction methods. Further, the local feature is extracted in these detected salient points, and local classification result is obtained by local feature classification branch. Finally, we get the final result by fusing the results of two classification branches together. With experiments on three widely used fine-grained image recognition datasets (CUB-200-2011, Stanford Cars, Stanford Dogs), our method can achieve the state-of-the-art performance.}
}
@article{PESANTEZ2022103520,
title = {Using a digital twin to explore water infrastructure impacts during the COVID-19 pandemic},
journal = {Sustainable Cities and Society},
volume = {77},
pages = {103520},
year = {2022},
issn = {2210-6707},
doi = {https://doi.org/10.1016/j.scs.2021.103520},
url = {https://www.sciencedirect.com/science/article/pii/S2210670721007861},
author = {Jorge E. Pesantez and Faisal Alghamdi and Shreya Sabu and G. Mahinthakumar and Emily Zechman Berglund},
keywords = {COVID-19, Water demand, Water distribution systems, Multi-modal failure, Resilience, Digital twin,},
abstract = {During the coronavirus disease 2019 (COVID-19) pandemic, the daily pattern of activities changed dramatically for people across the globe, as they socially distanced and worked remotely. Changes in daily routines created changes in water consumption patterns. Significant changes in water demands can affect the operation of water distribution systems, resulting in new patterns of flow, with implications for water age, pressure, and energy consumption. This research develops a digital twin to couple Advanced Metering Infrastructure (AMI) data with a hydraulic model to assess impacts on infrastructure due to changes in water demands associated with the COVID-19 pandemic for a case study. Using 2019 and COVID-19 modeling scenarios, the hydraulic model was executed to evaluate changes to water quality based on water age, pressure across nodes in the network, and the energy required by the system to distribute potable water. A water supply interruption event was modeled as a water main break to assess network resiliency for 2019 and COVID-19 demands. A digital twin provides the capabilities to explore and visualize emerging consumption patterns and their effects on the functioning of water systems, providing valuable analyses for water utility managers and insight for optimizing infrastructure operations and planning for long-term impacts.}
}
@article{FERNANDEZ2020103624,
title = {Associated Reality: A cognitive Human–Machine Layer for autonomous driving},
journal = {Robotics and Autonomous Systems},
volume = {133},
pages = {103624},
year = {2020},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2020.103624},
url = {https://www.sciencedirect.com/science/article/pii/S0921889020304644},
author = {Felipe Fernandez and Angel Sanchez and Jose F. Velez and Belen Moreno},
keywords = {ADAS and autonomous vehicle, Cooperative-ITS, Human–Machine​ system, Augmented Local Dynamic Map, Cognitive system, Cognitive landmark},
abstract = {Advanced Driver Assistance Systems (ADAS) and Automated and Autonomous Vehicles (AV) are cooperative systems and processes that use: artificial intelligence, cognitive methods, cloud technologies, cooperative vehicle-to-everything-communications (V2X), software–hardwareplatforms, sensor platforms and incipient intelligent transport infrastructures, to get self-driving systems and smart connected mobility services. This paper, to support automated driving systems (assisted, semi-autonomous and fully autonomous vehicles), introduces a cognitive layer called Associated Reality to enhance the involved information, knowledge and communication processes. The architecture defined includes an augmented Local Dynamic Map, with complementary layers, and an augmented Graph Database, with complementary semantic–cognitive relations, for the considered purpose, in cooperative human–machine and machine–machine systems. Virtual augmented landmarks are defined to improve the connectivity and intelligence of the involved spatial-information systems. Different structure landmarks and sequence landmarks (which includes regular, repetitive and periodic landmarks) are defined, categorized and used in diverse visual localization and mapping scenarios, for autonomous driving. In this paper, it is also shown, as a proof-of-concept for vehicle localization and mapping in road tunnels, the visual detection of different sequences of periodic luminaires, using YOLO v3 for the corresponding LED lights detection, or a specific alternative procedure developed with very low computational cost.}
}
@article{GAI2018262,
title = {A survey on FinTech},
journal = {Journal of Network and Computer Applications},
volume = {103},
pages = {262-273},
year = {2018},
issn = {1084-8045},
doi = {https://doi.org/10.1016/j.jnca.2017.10.011},
url = {https://www.sciencedirect.com/science/article/pii/S1084804517303247},
author = {Keke Gai and Meikang Qiu and Xiaotong Sun},
keywords = {FinTech, Cloud computing, Cyber security, Big data, Financial computing, Data-driven framework},
abstract = {As a new term in the financial industry, FinTech has become a popular term that describes novel technologies adopted by the financial service institutions. This term covers a large scope of techniques, from data security to financial service deliveries. An accurate and up-to-date awareness of FinTech has an urgent demand for both academics and professionals. This work aims to produce a survey of FinTech by collecting and reviewing contemporary achievements, by which a theoretical data-driven FinTech framework is proposed. Five technical aspects are summarized and involved, which include security and privacy, data techniques, hardware and infrastructure, applications and management, and service models. The main findings of this work are fundamentals of forming active FinTech solutions.}
}
@article{LAUPHEIMER202155,
title = {Juggling with representations: On the information transfer between imagery, point clouds, and meshes for multi-modal semantics},
journal = {ISPRS Journal of Photogrammetry and Remote Sensing},
volume = {176},
pages = {55-68},
year = {2021},
issn = {0924-2716},
doi = {https://doi.org/10.1016/j.isprsjprs.2021.03.007},
url = {https://www.sciencedirect.com/science/article/pii/S0924271621000769},
author = {Dominik Laupheimer and Norbert Haala},
keywords = {Multi-modality, Data fusion, 3D textured mesh, 3D point cloud, Imagery, Ground truth, Semantic segmentation},
abstract = {The automatic semantic segmentation of the huge amount of acquired remote sensing data has become an important task in the last decade. Images and Point Clouds (PCs) are fundamental data representations, particularly in urban mapping applications. Textured 3D meshes integrate both data representations geometrically by wiring the PC and texturing the surface elements with available imagery. We present a mesh-centered holistic geometry-driven methodology that explicitly integrates entities of imagery, PC and mesh. Due to its integrative character, we choose the mesh as the core representation that also helps to solve the visibility problem for points in imagery. Utilizing the proposed multi-modal fusion as the backbone and considering the established entity relationships, we enable the sharing of information across the modalities imagery, PC and mesh in a twofold manner: (i) feature transfer and (ii) label transfer. By these means, we achieve to enrich feature vectors to multi-modal feature vectors for each representation. Concurrently, we achieve to label all representations consistently while reducing the manual label effort to a single representation. Consequently, we facilitate to train machine learning algorithms and to semantically segment any of these data representations – both in a multi-modal and single-modal sense. The paper presents the association mechanism and the subsequent information transfer, which we believe are cornerstones for multi-modal scene analysis. Furthermore, we discuss the preconditions and limitations of the presented approach in detail. We demonstrate the effectiveness of our methodology on the ISPRS 3D semantic labeling contest (Vaihingen 3D) and a proprietary data set (Hessigheim 3D).}
}
@article{ALSINAPAGES2019183,
title = {Anomalous events removal for automated traffic noise maps generation},
journal = {Applied Acoustics},
volume = {151},
pages = {183-192},
year = {2019},
issn = {0003-682X},
doi = {https://doi.org/10.1016/j.apacoust.2019.03.007},
url = {https://www.sciencedirect.com/science/article/pii/S0003682X18310764},
author = {Rosa Ma Alsina-Pagès and Francesc Alías and Joan Claudi Socoró and Ferran Orga and Roberto Benocci and Giovanni Zambon},
keywords = {Noise monitoring, Smart city, Manual labelling, Noise maps, Automated labelling, Anomalous noise event, },
abstract = {Road Traffic Noise (RTN) is one of the biggest pollutants in modern cities, which is known to affect public health to be the direct cause of many illnesses for their inhabitants. Until recently, RTN maps have been generated using representative static measurements collected by experts, after manually discarding all non-traffic related noise events, or Anomalous Noise Events (ANEs). However, the automation of noise measurements using Wireless Acoustic Sensor Networks (WASNs) is allowing the development of dynamic maps, which require the detection of non-traffic noise sources in real-time in order to provide accurate noise level measurements. In this work, the manual an automatic removal of ANEs are compared. The latter is based on two versions of the Anomalous Noise Event Detector (ANED) designed to detect ANEs within a WASN in real-time as a two-class classifier. The experiments on 4 h and 44 min of real-life audio data show similar error rates among all the considered annotation methods. However, the detailed analysis of the experiments reveal, on the one hand, inconsistent manual annotations in certain non-ANE labelling situations, where non-coincident expert-based decisions are observed; and, on the other hand, the decrease of the overall accuracy of the ANED-based approaches due to the large number of false alarms in the case of RTN class. Thus, although the results demonstrate the viability of the automated removal of ANEs, further research should be conducted to keep improving the automation of ANEs annotation.}
}
@article{LIU2021102481,
title = {A novel Landsat-based automated mapping of marsh wetland in the headwaters of the Brahmaputra, Ganges and Indus Rivers, southwestern Tibetan Plateau},
journal = {International Journal of Applied Earth Observation and Geoinformation},
volume = {103},
pages = {102481},
year = {2021},
issn = {0303-2434},
doi = {https://doi.org/10.1016/j.jag.2021.102481},
url = {https://www.sciencedirect.com/science/article/pii/S0303243421001884},
author = {Qionghuan Liu and Yili Zhang and Linshan Liu and Zhaofeng Wang and Yong Nie and Mohan Rai},
keywords = {Wetland mapping, Random forest, Feature optimization, Google Earth Engine, Tibetan Plateau},
abstract = {Wetlands not only affect the local hydrology and ecosystems, but also regulate the conditions of human-environment. However, the availability of accurate wetland data remains a key challenge in wetland research. This study attempts to address this problem through a novel mapping framework that is based on the Google Earth Engine (GEE), feature optimization, and the random forest (RF) model (GFORF). This framework was built to map high-accuracy wetland data on the headwaters of the Brahmaputra, Ganges, and Indus rivers (HBGIR) in the western Tibetan Plateau (TP). Four time periods were examined: 1990, 2000, 2010, and 2017. Our results showed that the overall accuracy for the acquired wetland data was 82.73%, 83.16%, 82.47%, and 88.14% in 1990, 2000, 2010, and 2017, respectively. Furthermore, the feature optimization results showed that the spectral indices feature was the main contributor to the accuracy of wetland mapping, with the highest value being 26.9%. The seasonal factors, surface reflectance, auxiliary data, and texture contributed 21.8%, 21.6%, 21.5%, and 8.1%, respectively. Combining the seasonal features and auxiliary data of distances to rivers significantly improved the mapping accuracy of the wetlands by approximately 14%, 24%, 11%, and 10% in 1990, 2000, 2010, and 2017, respectively. In addition, our analysis showed that the wetland areas in the HBGIR amounted to 5177.39 km2, accounting for 5.82% of the total area. Over the 30-year observation period, the overall consolidation of the wetlands was characterized by a slight expansionary phase, with an average increase of 0.16% per year from 1990 to 2017. As a result of the improvement in the accuracy of wetland mapping in alpine areas, the change dynamics of wetlands was revealed, which provides justification for implementing ongoing wetland ecological services and protection measures.}
}
@article{SMALEC20215156,
title = {Big Data as a tool helpful in communication management},
journal = {Procedia Computer Science},
volume = {192},
pages = {5156-5165},
year = {2021},
note = {Knowledge-Based and Intelligent Information & Engineering Systems: Proceedings of the 25th International Conference KES2021},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2021.09.293},
url = {https://www.sciencedirect.com/science/article/pii/S1877050921020329},
author = {Agnieszka Smalec},
keywords = {Big Data, marketing communication, management, data processing, collection, communication management},
abstract = {The boundaries between the online and offline worlds have become irretrievably blurred, especially as mobile devices have proliferated. As a result, more and more activities are transferred to the Internet. Every activity in the network leaves a trace, which is why the volume of available data is growing rapidly. The amount of increasing information affects all market participants, and the necessity to constantly collect and process large amounts of data becomes an everyday reality. The aim of the article is to present the concept of big data and to indicate examples of the use of big data to manage marketing communication with the environment. It should be emphasized that not only data transfer devices, but also human interaction contribute to the creation of very large data sets. Acquiring and correctly interpreting them plays an important role in market entities in terms of management, including communication management. Contemporary multi-directional communication, including communication in a hypermedia environment, creates new challenges and threats. The article was prepared based on a literature review, research reports and an analysis of secondary sources. It also outlines the practical implications. The considerations provided are the basis for further activities and empirical research.}
}
@article{XIE2021353,
title = {ALGeNet: Adaptive Log-Euclidean Gaussian embedding network for time series forecasting},
journal = {Neurocomputing},
volume = {423},
pages = {353-361},
year = {2021},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2020.11.001},
url = {https://www.sciencedirect.com/science/article/pii/S0925231220317252},
author = {Zongxia Xie and Hui Hu and Qilong Wang and Renhui Li},
keywords = {Uncertainty modeling, Time series forecasting, LSTM, Lie group, Log-Euclidean, Adaptive learning},
abstract = {Time series prediction has attracted much attention as various issues can be formulated as such a task. It is one of the critical challenges to extract the intrinsic information for estimating future trends from historical data. Long Short-Term Memory Network (LSTM) shows excellent performance in this assignment. Probabilistic information extraction, which is demonstrated effective in object recognition in recent years, has not been introduced in time series prediction. To our knowledge, there has not been any work on plugging trainable probability distributions into LSTM as feature representation in an end-to-end manner. In this work we put forward an Adaptive Log-Euclidean Gaussian embedding Network (ALGeNet) to take one step further on solving this problem. The core of the network is capturing statistical information through the Gaussian Distribution with LSTM for end-to-end learning. As the space of Gaussian Distribution is a manifold, we try to embed Gaussian layer into LSTM through mapping Gaussian space into a linear space based on the Lie group and logarithm operation. We introduce four descriptors of Gaussian, two descriptors performing direct logarithm and the others performing indirect logarithm. All of them can extract first-order and second-order statistical features while utilizing the structures of geometry and smooth group of Gaussians. Furthermore, our adaptive mechanism merges the advantages of each descriptor and works well. Experimental results on a real-world wind speed dataset and a system-level electricity load dataset show that the proposed adaptive network outperforms some state-of-the-art algorithms.}
}
@article{PEZESHKI20191,
title = {Application of BEM and using BIM database for BEM: A review},
journal = {Journal of Building Engineering},
volume = {23},
pages = {1-17},
year = {2019},
issn = {2352-7102},
doi = {https://doi.org/10.1016/j.jobe.2019.01.021},
url = {https://www.sciencedirect.com/science/article/pii/S2352710218309501},
author = {Z. Pezeshki and A. Soleimani and A. Darabi},
keywords = {BEM, Building energy, BIM, Optimization, New methods},
abstract = {This paper reviews Building Energy Modeling (BEM) development using classification and review of articles for the recent years (2015–2018) to explore how much BEM methodologies have been used Building Information Modeling (BIM) database during this period. Nowadays, BEM and supervision are the most important challenges of smart cities, and BIM has a good and useful source of information for buildings. Recent innovations have provided the opportunity for construction industry to invest in state-of-the-art technologies and adopt new processes. Among these new methodologies is BIM, which has developed for the construction industry over the last two decades. Integrating graphical and non-graphical information, it enables construction industry stakeholders to work collaboratively for efficient project delivery throughout the life cycle of construction projects. The use of BEM in construction industry has come about to respond to the global call for energy conservation and sustainability. BEM tools and processes can be used to simulate energy performance, evaluate energy needs and optimize architectural design. This article reviews and classifies BEM applications into eight different categories such as prediction, estimation, consumption, optimal design, evaluation, efficiency, management, and optimization. In addition to examination of BEM in different categories and according to BIM that is a coordination model and includes all information in construction industry as well as electrical, mechanical, and architectural information, this review paper wants to know how many articles have used BIM such as a database in this industry.}
}
@article{DAI2021103859,
title = {Towards a systematic computational framework for modeling multi-agent decision-making at micro level for smart vehicles in a smart world},
journal = {Robotics and Autonomous Systems},
volume = {144},
pages = {103859},
year = {2021},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2021.103859},
url = {https://www.sciencedirect.com/science/article/pii/S0921889021001445},
author = {Qi Dai and Xunnong Xu and Wen Guo and Suzhou Huang and Dimitar Filev},
keywords = {Multi-agent decision-making, Coordinated path planning, Human driving behavior modeling},
abstract = {We propose a multi-agent based computational framework for modeling decision-making and strategic interaction at micro level for smart vehicles in a smart world. The concepts of Markov game and best response dynamics are heavily leveraged. Our aim is to make the framework conceptually sound and computationally practical for a range of realistic applications, including micro path planning for autonomous vehicles. To this end, we first convert the would-be stochastic game problem into a closely related deterministic one by introducing risk premium in the utility function for each individual agent. We show how the sub-game perfect Nash equilibrium of the simplified deterministic game can be solved by an algorithm based on best response dynamics. In order to better model human driving behaviors with bounded rationality, we seek to further simplify the solution concept by replacing the Nash equilibrium condition with a heuristic and adaptive optimization with finite look-ahead anticipation. In addition, the algorithm corresponding to the new solution concept drastically improves the computational efficiency. To demonstrate how our approach can be applied to realistic traffic settings, we conduct a simulation experiment: to derive merging and yielding behaviors on a double-lane highway with an unexpected barrier. Despite assumption differences involved in the two solution concepts, the derived numerical solutions show that the endogenized driving behaviors are very similar. We also briefly comment on how the proposed framework can be further extended in a number of directions in our forthcoming work, such as behavioral calibration using real traffic video data, and computational mechanism design for traffic policy optimization.}
}
@article{GOYAL2021719,
title = {Internet of things: Architecture and enabling technologies},
journal = {Materials Today: Proceedings},
volume = {34},
pages = {719-735},
year = {2021},
note = {3rd International Conference on Science and Engineering in Materials},
issn = {2214-7853},
doi = {https://doi.org/10.1016/j.matpr.2020.04.678},
url = {https://www.sciencedirect.com/science/article/pii/S2214785320333253},
author = {Parul Goyal and Ashok Kumar Sahoo and Tarun Kumar Sharma},
keywords = {Enabling technologies, IoT, RFID, Sensors, ZigBee},
abstract = {Internet of Things is transforming real devices to smart intelligent virtual devices. In IoT day today devices of daily use are manufactured along with sensors which are capable for identification and sensing. They can be networked, are capable to process, can interact with other devices through Internet. IoT objective is to connect almost everything under a common infrastructure. This helps to control devices and will keep us informed about the status of devices. The paper aims to give Internet of Things overview, architectures, enabling technologies and their applications. It presents latest trends, current state, recent developments, challenges, security, privacy, applications of IoT and future research directions.}
}
@article{QAISAR2021115,
title = {Adaptive-Rate Method for the Power Quality Disturbances Identification in the 5G Framework},
journal = {Procedia Computer Science},
volume = {182},
pages = {115-120},
year = {2021},
note = {Learning and Technology Conference 2020; Beyond 5G: Paving the way for 6G},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2021.02.016},
url = {https://www.sciencedirect.com/science/article/pii/S1877050921004804},
author = {Saeed Mian Qaisar and Raheef Aljefri},
keywords = {5 G, Cloud, Adaptive-Rate Processing, Time-Domain Features Extraction, Power Quality (PQ) disturbances, Compression Gain, Classification},
abstract = {The digitization and IoT advancement is evolving the energy sector. 5G is playing an important role in connecting various smart grid modules and stockholders. In this framework, this paper suggests a new adaptive-rate method for time-domain power quality (PQ) signals features extraction and identification. The incoming PQ signal is digitized with an event-driven A/D converter (EDADC). A novel selection mechanism is employed to efficiently segment the non-uniformly sampled signal. In next step, features of these segments are explored by performing only the time-domain analysis. The identification is performed with the k-nearest neighbor (KNN) classifier. Results demonstrate a 12.3 times reduction in collected samples count as compared to the traditional counterparts. It confirms a significant processing and power consumption effectiveness of the designed solution compared to the conventional equals. The proposed system secures an average recognition accuracy of 93.5%. Thanks to the 5G network, findings are effectively logged on the cloud for further analysis and decision making.}
}
@article{GAO2021107725,
title = {Transfer learning for thermal comfort prediction in multiple cities},
journal = {Building and Environment},
volume = {195},
pages = {107725},
year = {2021},
issn = {0360-1323},
doi = {https://doi.org/10.1016/j.buildenv.2021.107725},
url = {https://www.sciencedirect.com/science/article/pii/S0360132321001359},
author = {Nan Gao and Wei Shao and Mohammad Saiedur Rahaman and Jun Zhai and Klaus David and Flora D. Salim},
keywords = {Human–building interaction, Thermal comfort, Transfer learning, HVAC automation, Smart building},
abstract = {The HVAC (Heating, Ventilation and Air Conditioning) system is an important part of a building, which constitutes up to 40% of building energy usage. The main purpose of HVAC, maintaining appropriate thermal comfort, is crucial for the best energy usage. Additionally, thermal comfort is also important for well-being, health, and work productivity. Recently, data-driven thermal comfort models have achieved better performance than traditional knowledge-based methods (e.g. the predicted mean vote model). An accurate thermal comfort model requires a large amount of self-reported thermal comfort data from indoor occupants which undoubtedly remains a challenge for researchers. In this research, we aim to address this data-shortage problem and boost the performance of thermal comfort prediction. We utilize sensor data from multiple cities in the same climate zone to learn thermal comfort patterns. We present a transfer learning-based multilayer perceptron model from the same climate zone (TL-MLP-C*) for accurate thermal comfort prediction. Extensive experimental results on the ASHRAE RP-884, Scales Project and Medium US Office datasets show that the performance of the proposed TL-MLP-C* exceeds the performance of state-of-the-art methods in accuracy and F1-score.}
}
@article{BISOGNI2021102814,
title = {ECB2: A novel encryption scheme using face biometrics for signing blockchain transactions},
journal = {Journal of Information Security and Applications},
volume = {59},
pages = {102814},
year = {2021},
issn = {2214-2126},
doi = {https://doi.org/10.1016/j.jisa.2021.102814},
url = {https://www.sciencedirect.com/science/article/pii/S2214212621000545},
author = {Carmen Bisogni and Gerardo Iovane and Riccardo Emanuele Landi and Michele Nappi},
keywords = {Biometrics, Smart contracts, Blockchain, Face biometrics, Biometricsignature, Encryption scheme, RSA, Information Fusion, Authentication scheme},
abstract = {Blockchain is the technology on the basis of the recent smart and digital contracts. It ensures at this system the required characteristics to be effectively applied. In this work, we propose a novel encryption scheme specifically built to authorize and sign transactions in digital or smart contracts. The face is used as a biometric key, encoded through the Convolutional Neural Network (CNN), FaceNet. Then, this encoding is fused with an RSA key by using the Hybrid Information Fusion algorithm (BNIF). The results show a combined key that ensures the identity of the user that is executing the transaction by preserving privacy. Experiments reveal that, even in strong heterogeneous acquisition conditions for the biometric trait, the identity of the user is ensured and the contract is properly signed in less than 1.86 s. The proposed ECB2 encryption scheme is also very fast in the user template creation (0.05s) and requires at most four attempts to recognize the user with an accuracy of 94%.}
}
@article{SPEZZANO20151016,
title = {Pattern Detection in Cyber-Physical Systems},
journal = {Procedia Computer Science},
volume = {52},
pages = {1016-1021},
year = {2015},
note = {The 6th International Conference on Ambient Systems, Networks and Technologies (ANT-2015), the 5th International Conference on Sustainable Energy Information Technology (SEIT-2015)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2015.05.096},
url = {https://www.sciencedirect.com/science/article/pii/S1877050915008960},
author = {Giandomenico Spezzano and Andrea Vinci},
keywords = {Cyber-physical systems, data streams mining, stream clustering, monitoring applications ;},
abstract = {A Cyber-Physical System (CPS) integrates physical devices (i.e., sensors) with cyber (i.e., informational) components to form a context sensitive system that responds intelligently to dynamic changes in real-world situations. A core element of CPS is the collection and assessment of information from noisy, dynamic, and uncertain physical environments that must be transformed into usable knowledge in real-time. Machine learning algorithms such as cluster analysis can be used to extract useful information and patterns from data generated from physical devices based on which novel applications of CPS can make informed decisions. In this paper we propose to use a density-based data stream clustering algorithm, built on the Multiple Species Flocking model, for the monitoring of big data, generated from numerous applications such as machine monitoring, health monitoring, sensor networks. In the proposed approach, approximate results are available on demand at anytime, so it is particularly apt for real life monitoring applications.}
}
@article{CUQUET201874,
title = {The societal impact of big data: A research roadmap for Europe},
journal = {Technology in Society},
volume = {54},
pages = {74-86},
year = {2018},
issn = {0160-791X},
doi = {https://doi.org/10.1016/j.techsoc.2018.03.005},
url = {https://www.sciencedirect.com/science/article/pii/S0160791X17300131},
author = {Martí Cuquet and Anna Fensel},
keywords = {Big data, Research roadmap, Societal externalities, Skills development, Standardisation},
abstract = {With its rapid growth and increasing adoption, big data is producing a substantial impact in society. Its usage is opening both opportunities such as new business models and economic gains and risks such as privacy violations and discrimination. Europe is in need of a comprehensive strategy to optimise the use of data for a societal benefit and increase the innovation and competitiveness of its productive activities. In this paper, we contribute to the definition of this strategy with a research roadmap to capture the economic, social and ethical, legal and political benefits associated with the use of big data in Europe. The present roadmap considers the positive and negative externalities associated with big data, maps research and innovation topics in the areas of data management, processing, analytics, protection, visualisation, as well as non-technical topics, to the externalities they can tackle, and provides a time frame to address these topics in order to deliver social impact, skills development and standardisation. Finally, it also identifies what sectors will be most benefited by each of the research efforts. The goal of the roadmap is to guide European research efforts to develop a socially responsible big data economy, and to allow stakeholders to identify and meet big data challenges and proceed with a shared understanding of the societal impact, positive and negative externalities and concrete problems worth investigating in future programmes.}
}
@article{ALONSO2020102047,
title = {An intelligent Edge-IoT platform for monitoring livestock and crops in a dairy farming scenario},
journal = {Ad Hoc Networks},
volume = {98},
pages = {102047},
year = {2020},
issn = {1570-8705},
doi = {https://doi.org/10.1016/j.adhoc.2019.102047},
url = {https://www.sciencedirect.com/science/article/pii/S1570870519306043},
author = {Ricardo S. Alonso and Inés Sittón-Candanedo and Óscar García and Javier Prieto and Sara Rodríguez-González},
keywords = {Internet of things, Edge computing, Distributed ledger technologies, Smart farming, Precision agriculture, Livestock monitoring},
abstract = {Today’s globalized and highly competitive world market has broadened the spectrum of requirements in all the sectors of the agri-food industry. This paper focuses on the dairy industry, on its need to adapt to the current market by becoming more resource efficient, environment-friendly, transparent and secure. The Internet of Things (IoT), Edge Computing (EC) and Distributed Ledger Technologies (DLT) are all crucial to the achievement of those improvements because they allow to digitize all parts of the value chain, providing detailed information to the consumer on the final product and ensuring its safety and quality. In Smart Farming environments, IoT and DLT enable resource monitoring and traceability in the value chain, allowing producers to optimize processes, provide the origin of the produce and guarantee its quality to consumers. In comparison to a centralized cloud, EC manages the Big Data generated by IoT devices by processing them at the network edge, allowing for the implementation of services with shorter response times, and a higher Quality of Service (QoS) and security. This work presents a platform oriented to the application of IoT, Edge Computing, Artificial Intelligence and Blockchain techniques in Smart Farming environments, by means of the novel Global Edge Computing Architecture, and designed to monitor the state of dairy cattle and feed grain in real time, as well as ensure the traceability and sustainability of the different processes involved in production. The platform is deployed and tested in a real scenario on a dairy farm, demonstrating that the implementation of EC contributes to a reduction in data traffic and an improvement in the reliability in communications between the IoT-Edge layers and the Cloud.}
}
@article{RAY2021,
title = {A review on 6G for space-air-ground integrated network: Key enablers, open challenges, and future direction},
journal = {Journal of King Saud University - Computer and Information Sciences},
year = {2021},
issn = {1319-1578},
doi = {https://doi.org/10.1016/j.jksuci.2021.08.014},
url = {https://www.sciencedirect.com/science/article/pii/S1319157821002172},
author = {Partha Pratim Ray},
keywords = {6G, Space-air-ground integrated network, Next-generation network augmentation, New network design},
abstract = {Space-air-ground integrated network (SAGIN) is still in nascent stage of design. Despite of several key insights onto the augmentation of terrestrial, aerial and satellite systems, SAGIN ecosystem is yet not mature enough to survive into the realty. More agility, robustness, flexibility, and scalability are required to conform to optimum standard of abstraction. As 5G is at the verge of technology domain, this is high time when we should keep our focus on the next-generation advanced 6G technology to cater the issues of existing SAGIN ecosystem. In this article, we envisage a clear vision on how 6G can improve the current scenario of the SAGIN infrastructure will some value-added services. We firstly, present basics behind the SAGIN and discuss key concepts of the 6G. Secondly, we review key technologies related to the unmanned aerial vehicle (UAV) and satellite-based communications. Thirdly, we describe key enablers of the 6G-enbled SAGIN i.e., 6G-SAGIN. Fourthly, we present the UAV-as-a-service to augment the comprehension of 6G-SAGIN. Fifthly, we extend the orientation of 6G-SAGIN toward elemental design aspects. Finally, we depict key open research challenges and prescribe some future direction.}
}
@article{JALLAL2020114977,
title = {A hybrid neuro-fuzzy inference system-based algorithm for time series forecasting applied to energy consumption prediction},
journal = {Applied Energy},
volume = {268},
pages = {114977},
year = {2020},
issn = {0306-2619},
doi = {https://doi.org/10.1016/j.apenergy.2020.114977},
url = {https://www.sciencedirect.com/science/article/pii/S030626192030489X},
author = {Mohammed Ali Jallal and Aurora González-Vidal and Antonio F. Skarmeta and Samira Chabaa and Abdelouhab Zeroual},
keywords = {ANFIS, Autoregressive process, Gender-difference firefly algorithm, Building energy consumption, Time series forecasting},
abstract = {The accuracy of the prediction of buildings’ energy consumption is being tackled using existing artificial intelligence techniques. However, there is a lack of effort on the development of new techniques for solving that problem and, therefore, achieving higher performance, which is important for the efficient management of energy in many levels. This study addresses this gap by proposing a new hybrid machine learning algorithm that incorporates the adaptive neuro-fuzzy inference system model with a new version of the firefly algorithm denominated as the gender-difference firefly algorithm. We expanded the search space diversification to increase the accuracy on the prediction and adopted the autoregressive process in order to approximate the chaotic behavior of the consumption time series. A new layer, denominated as non-working time adaptation was also integrated so as to decrease the fast variability of the predictions during non-working periods of time. We have applied our algorithm for the consumption prediction on 1 h, 2 h and 3 h ahead horizons. We have obtained improvements on the MAPE and R coefficient when compared with state-of-the-art publications in both a private dataset from the Faculty of Chemistry, located in the city of Murcia, Spain and a public dataset of the consumption of a Retail building located in California, United States. We also show our method’s performance in five more buildings. Our results demonstrate the robustness and the accuracy of our proposal when compared to the traditional adaptive neuro-fuzzy inference system models and also to the different predictive techniques implemented in several pieces of literature.}
}
@article{NGUYEN2021113857,
title = {Structural representation learning for network alignment with self-supervised anchor links},
journal = {Expert Systems with Applications},
volume = {165},
pages = {113857},
year = {2021},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2020.113857},
url = {https://www.sciencedirect.com/science/article/pii/S0957417420306680},
author = {Thanh Toan Nguyen and Minh Tam Pham and Thanh Tam Nguyen and Thanh Trung Huynh and Van Vinh Tong and Quoc Viet Hung Nguyen and Thanh Tho Quan},
keywords = {Graph mining, Graph matching, Network alignment, Network representation learning, Network embedding},
abstract = {Network alignment, the problem of identifying similar nodes across networks, is an emerging research topic due to its ubiquitous applications in many data domains such as social-network reconciliation and protein-network analysis. While traditional alignment methods struggle to scale to large graphs, the state-of-the-art representation-based methods often rely on pre-defined anchor links, which are unavailable or expensive to compute in many applications. In this paper, we propose NAWAL, a novel, end-to-end unsupervised embedding-based network alignment framework emphasizing on structural information. The model first embeds network nodes into a low-dimension space where the structural neighborhoodship on original network is captured by the distance on the space. As the space for the input networks are learnt independently, we further leverage a generative adversarial deep neural network to reconcile the spaces without relying on hand-crafted features or domain-specific supervision. The empirical results on three real-world datasets show that NAWAL significantly outperforms state-of-the-art baselines, by over 13% of accuracy against unsupervised methods and on par or better than supervised methods. Our technique also demonstrate the robustness against adversarial conditions, such as structural noises and graph size imbalance.}
}
@article{CHAUDHRY2021103322,
title = {An anonymous device to device access control based on secure certificate for internet of medical things systems},
journal = {Sustainable Cities and Society},
volume = {75},
pages = {103322},
year = {2021},
issn = {2210-6707},
doi = {https://doi.org/10.1016/j.scs.2021.103322},
url = {https://www.sciencedirect.com/science/article/pii/S2210670721005989},
author = {Shehzad Ashraf Chaudhry and Azeem Irshad and Jamel Nebhen and Ali Kashif Bashir and Nour Moustafa and Yasser D. Al-Otaibi and Yousaf Bin Zikria},
keywords = {IoMT, Key establishment, Device access control, Certificate, Stolen IoMT device},
abstract = {The Internet of Medical Things (IoMT) is structured upon both the sensing and communication infrastructure and computation facilities. The IoMT provides the convenient and cheapest ways for healthcare by aiding the remote access to the patients’ physiological data and using machine learning techniques for help in diagnosis. The communication delays in IoMT can be very harmful to healthcare. Device to device (D2D) secure communication is a vital area that can reduce communication delays; otherwise, caused due to the mediation of a third party. To substantiate a secure D2D communication framework, some schemes were recently proposed to secure D2D based communication infrastructure suitable for IoMT-based environments. However, the insecurities of some schemes against device physical capture attack and non-provision of anonymity along with related attacks are evident from the literature. This calls for a D2D secure access control system for realizing sustainable smart healthcare. In this article, using elliptic curve cryptography, a certificate based D2D access control scheme for IoMT systems (D2DAC-IoMT) is proposed. The security of the proposed D2DAC-IoMT is substantiated through formal and informal methods. Moreover, the performance analysis affirms that the proposed scheme provides a good trade-off between security and efficiency compared with some recent schemes.}
}
@article{RASTOGI2020107209,
title = {Narrowband Internet of Things: A Comprehensive Study},
journal = {Computer Networks},
volume = {173},
pages = {107209},
year = {2020},
issn = {1389-1286},
doi = {https://doi.org/10.1016/j.comnet.2020.107209},
url = {https://www.sciencedirect.com/science/article/pii/S1389128619313593},
author = {Eshita Rastogi and Navrati Saxena and Abhishek Roy and Dong Ryeol Shin},
keywords = {NB-IoT, LPWA, LTE, 5G-NR, 3GPP},
abstract = {Over the last decade, the number of Low-Power Wireless Access (LPWA) devices has increased remarkably. It has become crucial to introduce several LPWA technologies to share the burden of catering to the demands of these devices. Narrowband Internet of Things (NB-IoT) is one such new cellular LPWA technology which has been standardized by 3rd Generation Partnership Project (3GPP) in June, 2016. It was developed with the aim to support low-complexity and low-power devices serving areas of poor radio coverage. In this survey, we review NB-IoT technology in detail. NB-IoT’s architecture is derived from that of Long Term Evolution (LTE) cellular technology, which is another 3GPP technology. We first discuss the architectural changes made to the design of LTE to derive the design of NB-IoT, including changes in physical layer and layer-2 architecture. Next, we describe the various features introduced for NB-IoT in 3GPP Rel-13 and follow it up to describe the enhancements made in subsequent 3GPP releases until 3GPP Rel-16. Then, we review, in depth, the research work done on various aspects of NB-IoT. We follow it up with a discussion on the combination of NB-IoT with other interesting cellular technologies like Device-to-Device communication (D2D), Non-Orthogonal Multiple Access (NOMA), social IoT, and 5th Generation New Radio (5G NR). We also look into a wide variety of real-world applications of NB-IoT. Finally, we point out a few open issues of NB-IoT and identify possible future research directions.}
}
@article{CAI2021e06322,
title = {Natural language processing for urban research: A systematic review},
journal = {Heliyon},
volume = {7},
number = {3},
pages = {e06322},
year = {2021},
issn = {2405-8440},
doi = {https://doi.org/10.1016/j.heliyon.2021.e06322},
url = {https://www.sciencedirect.com/science/article/pii/S2405844021004278},
author = {Meng Cai},
keywords = {Natural language processing, Urban research, Urban big data, Text mining},
abstract = {Natural language processing (NLP) has shown potential as a promising tool to exploit under-utilized urban data sources. This paper presents a systematic review of urban studies published in peer-reviewed journals and conference proceedings that adopted NLP. The review suggests that the application of NLP in studying cities is still in its infancy. Current applications fell into five areas: urban governance and management, public health, land use and functional zones, mobility, and urban design. NLP demonstrates the advantages of improving the usability of urban big data sources, expanding study scales, and reducing research costs. On the other hand, to take advantage of NLP, urban researchers face challenges of raising good research questions, overcoming data incompleteness, inaccessibility, and non-representativeness, immature NLP techniques, and computational skill requirements. This review is among the first efforts intended to provide an overview of existing applications and challenges for advancing urban research through the adoption of NLP.}
}
@article{YEH2022,
title = {Perspectives on 6G wireless communications},
journal = {ICT Express},
year = {2022},
issn = {2405-9595},
doi = {https://doi.org/10.1016/j.icte.2021.12.017},
url = {https://www.sciencedirect.com/science/article/pii/S240595952100182X},
author = {Choongil Yeh and Gweon Do Jo and Young-Jo Ko and Hyun Kyu Chung},
keywords = {6G, Usage scenario, Tactile internet, Key performance indicator, Enabling technology},
abstract = {Since its first commercialization in early 2019, 5G has been making progress around the world and penetrating daily lives. Now, research interest in wireless communication is quickly shifting to the next generation mobile system, 6G. This paper envisions the 6G as a union of physical space, cyberspace, and connectivity with intelligence. Also, interactivity is a critical component to provide users with a truly immersive experience. In this paper, 6G usage scenarios and use cases which cannot be properly supported under the 5G regime are proposed. Major key performance indicators (KPIs) to support these use cases are considered. The 6G-related state-of-the-art technologies and standardization activities are discussed in terms of interactivity, intelligence and connectivity. Also, future works to be accomplished for the completion of 6G are shortly stated.}
}
@article{IQBAL2020766,
title = {Big Data analytics and Computational Intelligence for Cyber–Physical Systems: Recent trends and state of the art applications},
journal = {Future Generation Computer Systems},
volume = {105},
pages = {766-778},
year = {2020},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2017.10.021},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X17323282},
author = {Rahat Iqbal and Faiyaz Doctor and Brian More and Shahid Mahmud and Usman Yousuf},
keywords = {Big Data, Big Data analytics, Cyber–Physical Systems, Computational Intelligence, CI and CPS applications, HSTSM},
abstract = {Big data is fuelling the digital revolution in an increasingly knowledge driven and connected society by offering big data analytics and computational intelligence based solutions to reduce the complexity and cognitive burden on accessing and processing large volumes of data. In this paper, we discuss the importance of big data analytics and computational intelligence techniques applied to data produced from the myriad of pervasively connected machines and personalized devices offering embedded and distributed information processing capabilities. We provide a comprehensive survey of computational intelligence techniques appropriate for the effective processing and analysis of big data. We discuss a number of exemplar application areas that generate big data and can hence benefit from its effective processing. State of the art research and novel applications in health-care, intelligent transportation and social network sentiment analysis, are presented and discussed in the context of Big data, Cyber–Physical Systems (CPS), and Computational Intelligence (CI). We present a data modelling methodology, which introduces a novel biologically inspired universal generative modelling approach called Hierarchical Spatial–Temporal State Machine (HSTSM). The HSTSM modelling approach incorporates a number of soft computing techniques such as: deep belief networks, auto-encoders, agglomerative hierarchical clustering and temporal sequence processing, in order to address the computational challenges arising from analysing and processing large volumes of diverse data to provide an effective big data analytics tool for diverse application areas. A conceptual cyber–physical architecture, which can accommodate and benefit from the proposed methodology, is further presented.}
}
@article{MOUSA2021114592,
title = {Multi-dimensional trust for context-aware services computing},
journal = {Expert Systems with Applications},
volume = {172},
pages = {114592},
year = {2021},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2021.114592},
url = {https://www.sciencedirect.com/science/article/pii/S0957417421000336},
author = {Afaf Mousa and Jamal Bentahar and Omar Alam},
keywords = {Context-aware services, QoS trust management, Dynamic cyclic dependency, Collusion attacks, White-washing attack},
abstract = {The paper addresses the problem of trust management of cloud, fog and IoT services in dynamically changing environments. The continuous dynamic environment is one of the challenges that trustworthy services management in the cloud, fog and IoT settings faces. Services in such an environmental context have difficulty securing an acceptable quality of service (QoS). This article proposes a trust management framework that establishes service trust by considering the direct trust from the truster (subjective trust), aggregating referrals about the service in a collusion-resistant manner (objective trust), and bootstrapping new services. We introduce a subjective trust model based on the formalism of dependency networks to dynamically predict the provided QoS in response to context environment changes. The proposed approach leverages the dependency relations that exist among the QoS metrics and environmental context variables. The novelty at the subjective trust level lies in considering the dynamic cyclic dependency relations that enhances the prediction accuracy. However, subjective trust based on direct interactions could be insufficient to make the trust estimate credible. Hence, on top of the subjective layer, we propose an objective trust management model resilient to collusion attacks by leveraging the power of mass collaboration among referees. Finally, we propose a bootstrapping mechanism that is resilient to the white-washing attacks by observing the behaviours of newcomer services with no trust resources using the concept of social adoption to estimate their initial trust values. Experiments conducted on real-life and synthetic datasets demonstrate the effectiveness of our approach compared with state-of-the-art approaches. We used the statistical log score to assess the model’s prediction accuracy and employed the estimation error of the objective trust as indicated by referees relative to the one calculated by the multi-round simulation. The ROC (Receiver Operating Characteristic) curves are finally used to measure the accuracy of the classifier used in the proposed trust bootstrapping mechanism in providing accurate initial trust values. The main findings of the paper are around the new trust model of cloud, fog and IoT services considering their dynamically changing environments. The first finding is that the prediction of the provided QoS shows better results when it is dynamic and responds to context environment changes by leveraging the dynamic dependency network linking the QoS metrics and context variables of the environment. The second finding is that the objective trust performs better when it is resilient to collusion attacks by leveraging the power of mass collaboration among referees. The third finding is that the bootstrapping mechanism that observes the behaviours of new comer services with no trust resources using the concept of social adoption to estimate their initial trust values excels by being resilient to white watching attacks.}
}
@article{BOSMAN201514,
title = {Ensembles of incremental learners to detect anomalies in ad hoc sensor networks},
journal = {Ad Hoc Networks},
volume = {35},
pages = {14-36},
year = {2015},
note = {Special Issue on Big Data Inspired Data Sensing, Processing and Networking Technologies},
issn = {1570-8705},
doi = {https://doi.org/10.1016/j.adhoc.2015.07.013},
url = {https://www.sciencedirect.com/science/article/pii/S1570870515001481},
author = {Hedde H.W.J. Bosman and Giovanni Iacca and Arturo Tejada and Heinrich J. Wörtche and Antonio Liotta},
keywords = {Anomaly detection, Wireless sensor networks, Online learning, Incremental learning, Ensemble methods},
abstract = {In the past decade, rapid technological advances in the fields of electronics and telecommunications have given rise to versatile, ubiquitous decentralized embedded sensor systems with ad hoc wireless networking capabilities. Typically these systems are used to gather large amounts of data, while the detection of anomalies (such as system failures, intrusion, or unanticipated behavior of the environment) in the data (or other types or processing) is performed in centralized computer systems. In spite of the great interest that it attracts, the systematic porting and analysis of centralized anomaly detection algorithms to a decentralized paradigm (compatible with the aforementioned sensor systems) has not been thoroughly addressed in the literature. We approach this task from a new angle, assessing the viability of localized (in-node) anomaly detection based on machine learning. The main challenges we address are: (1) deploying decentralized, automated, online learning, anomaly detection algorithms within the stringent constraints of typical embedded systems; and (2) evaluating the performance of such algorithms and comparing them with that of centralized ones. To this end, we first analyze (and port) single and multi-dimensional input classifiers that are trained incrementally online and whose computational requirements are compatible with the limitations of embedded platforms. Next, we combine multiple classifiers in a single online ensemble. Then, using both synthetic and real-world datasets from different application domains, we extensively evaluate the anomaly detection performance of our algorithms and ensemble, in terms of precision and recall, and compare it to that of well-known offline, centralized machine learning algorithms. Our results show that the ensemble performs better than each individual decentralized classifier and that it can match the performance of the offline alternatives, thus showing that our approach is a viable solution to detect anomalies, even in environments with little a priori knowledge.}
}
@article{RAUSCH2021259,
title = {Optimized container scheduling for data-intensive serverless edge computing},
journal = {Future Generation Computer Systems},
volume = {114},
pages = {259-271},
year = {2021},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2020.07.017},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X2030399X},
author = {Thomas Rausch and Alexander Rashed and Schahram Dustdar},
keywords = {Edge computing, Serverless, Container scheduling, Machine learning},
abstract = {Operating data-intensive applications on edge systems is challenging, due to the extreme workload and device heterogeneity, as well as the geographic dispersion of compute and storage infrastructure. Serverless computing has emerged as a compelling model to manage the complexity of such systems, by decoupling the underlying infrastructure and scaling mechanisms from applications. Although serverless platforms have reached a high level of maturity, we have found several limiting factors that inhibit their use in an edge setting. This paper presents a container scheduling system that enables such platforms to make efficient use of edge infrastructures. Our scheduler makes heuristic trade-offs between data and computation movement, and considers workload-specific compute requirements such as GPU acceleration. Furthermore, we present a method to automatically fine-tune the weights of scheduling constraints to optimize high-level operational objectives such as minimizing task execution time, uplink usage, or cloud execution cost. We implement a prototype that targets the container orchestration system Kubernetes, and deploy it on an edge testbed we have built. We evaluate our system with trace-driven simulations in different infrastructure scenarios, using traces generated from running representative workloads on our testbed. Our results show that (a) our scheduler significantly improves the quality of task placement compared to the state-of-the-art scheduler of Kubernetes, and (b) our method for fine-tuning scheduling parameters helps significantly in meeting operational goals.}
}
@article{YANG2022121188,
title = {Quantitative mapping of the evolution of AI policy distribution, targets and focuses over three decades in China},
journal = {Technological Forecasting and Social Change},
volume = {174},
pages = {121188},
year = {2022},
issn = {0040-1625},
doi = {https://doi.org/10.1016/j.techfore.2021.121188},
url = {https://www.sciencedirect.com/science/article/pii/S0040162521006211},
author = {Chao Yang and Cui Huang},
keywords = {Artificial intelligence (AI), China's policy, Bibliometrics, Policy evolution, Policy documents},
abstract = {Artificial intelligence (AI) technology policy plays a critical role to steer its applications to broadly relevant endpoints, and contributes to critical governance of innovations by governments, industry and society at large. In this paper, we adopt a bibliometrics-based research framework to characterize the development and evolution of China's AI policy. The framework integrates bibliometric methods, semantic analysis, and network analysis for identifying core policy elements and their evolution in the AI policy process. Specifically, we first collect China's central-level AI-related policies and identify four stages of its evolution based on policy-issuing frequency, policy trends, and core policy issuing time nodes. We then identify the core policies, core institutions, and core policy targets in each stage. Then we explore the policy issuing trends, policy distribution changes, and evolution of policy targets. Finally, patterns and characteristics of the policy process are identified, and trends are predicted. We used the PKULaw database to collect the policy-relevant data on AI in China, and the time frame is from 1990 to 2019. Our findings and the reported quantitative map might usefully inform AI policy in China and elsewhere around the world. It could also help broader stakeholder engagement in policy discussions on AI technology, industry and society.}
}
@article{SILVA2019329,
title = {Computational sustainability and the PHESS platform: Using affective computing as social indicators},
journal = {Future Generation Computer Systems},
volume = {92},
pages = {329-341},
year = {2019},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2018.10.006},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X17328856},
author = {Fábio Silva and Cesar Analide},
keywords = {Intelligent environments, Affective computing, Internet of things, Computational sustainability},
abstract = {The use of ubiquitous devices on intelligent environment enables opportunities to solve complex problems and react to changes quicker. Namely the use of computational resources to assist the management of environment through predicament of parameters based on sustainable indicators applied to social indicators and intelligent environments. This paper considers a computational sustainability platform which manages contexts supported by principles of computational sustainability and the assurance of sustainable scenarios. An application case study based on the definition of social indicators based on mood analysis demonstrates the application of the platform and some of its innovative functionalities. It uses different types of indicators from classical sustainability dimensions in order to demonstrate the platform. Context gathering and predicative services are used based on these indicators obtained from the environment over public services, sensors networks and ubiquitous devices which are used to create indicators based on the fusion of data.}
}
@article{CIECHANOWSKI2020322,
title = {TUTORIAL: AI research without coding: The art of fighting without fighting: Data science for qualitative researchers},
journal = {Journal of Business Research},
volume = {117},
pages = {322-330},
year = {2020},
issn = {0148-2963},
doi = {https://doi.org/10.1016/j.jbusres.2020.06.012},
url = {https://www.sciencedirect.com/science/article/pii/S0148296320303854},
author = {Leon Ciechanowski and Dariusz Jemielniak and Peter A. Gloor},
keywords = {Twitter, Data scraping, Sentiment analysis, Tribe finding, Wikidata},
abstract = {In this tutorial, we show how to scrape and collect online data, perform sentiment analysis, social network analysis, tribe finding, and Wikidata cross-checks, all without using a single line of programming code. In a step-by-step example, we use self-collected data to perform several analyses of the glass ceiling. Our tutorial can serve as a standalone introduction to data science for qualitative researchers and business researchers, who have avoided learning to program. It should also be useful for experienced data scientists who want to learn about the tools that will allow them to collect and analyze data more easily and effectively.}
}
@article{DHINGRA2021100175,
title = {Internet of things-based fog and cloud computing technology for smart traffic monitoring},
journal = {Internet of Things},
volume = {14},
pages = {100175},
year = {2021},
issn = {2542-6605},
doi = {https://doi.org/10.1016/j.iot.2020.100175},
url = {https://www.sciencedirect.com/science/article/pii/S2542660519302100},
author = {Swati Dhingra and Rajasekhara Babu Madda and Rizwan Patan and Pengcheng Jiao and Kaveh Barri and Amir H. Alavi},
keywords = {Smart traffic monitoring, Fog computing, Cloud computing, Internet-of-things, Thingspeak, Twitter},
abstract = {Internet of Things (IoT) is changing the world by connecting billions of physical and virtual objects with distinctive identities to the Internet. This fusion results in generating huge volumes of data that might not be manageable using today's storage and data analytics technologies. Although cloud computing offers services to tackle this issue at infrastructural level, its efficiency for time sensitive applications (e.g. oil, gas, and traffic monitoring) is still questionable. Arguably, transferring massive amount of data to the cloud for storage and processing may lead to cloud overloading and saturation of network bandwidth. In this study, an integrated fog and cloud computing framework is introduced to overcome the limitations of real-time analytics, latency and network congestion of basic cloud services for traffic monitoring. The proposed approach is implemented to prototype a smart traffic monitoring system (STMS). The proposed monitoring system is designed for congestion monitoring and traffic light management. It can also be tuned to detect traffic incidents that requires immediate assistance during congestion. In this framework, a tiny computer-on-module serves as a fog node to collect real-time data from geographically distributed sensors and to transfer it to the cloud for storage and processing. The results show the efficiency of the fog network in improving the performance of the cloud platform in terms of reducing the response time and increasing the bandwidth. Furthermore, the proposed integrated fog and cloud framework is interfaced with Tweeter to send alerts about traffic congestion to be subscribed users in the form of Tweet messages .}
}
@article{ZAIDI202153,
title = {Internet of Flying Things (IoFT): A Survey},
journal = {Computer Communications},
volume = {165},
pages = {53-74},
year = {2021},
issn = {0140-3664},
doi = {https://doi.org/10.1016/j.comcom.2020.10.023},
url = {https://www.sciencedirect.com/science/article/pii/S014036642031971X},
author = {Sofiane Zaidi and Mohammed Atiquzzaman and Carlos T. Calafate},
keywords = {Internet of Flying Things, Unmanned Aerial Vehicle, Unmanned Artifact System, Internet of Things, Flying Ad-hoc NETwork},
abstract = {Unmanned Aerial Vehicles (UAVs) have recently received significant attention by the civilian and military community, mostly due to the fast growth of UAV technologies supported by wireless communications and networking. UAVs can be used to improve the efficiency and performance of the Internet of Things (IoT) in terms of connectivity, coverage, reliability, stability, etc. In particular, to support IoT applications in an efficient manner, UAVs should be organized as a Flying Ad-hoc NETwork (FANET). FANET is a subclass of Mobile Ad-hoc Network (MANET) where nodes are Unmanned Artifact Systems (UAS). However, the deployment of UAVs in IoT is limited by several constraints, such as limited resource capacity of UAVs and ground devices, signal collision and interference, intermittent availability of the IoT infrastructure, etc. In the Internet of Flying Things (IoFT) literature, there are no survey or study that exhaustively covers and discusses all key concepts and recent works on IoFT. In this paper a comprehensive survey on the IoFT is presented, covering the state of the art in flying things with a focus on IoFT. A taxonomy of related literature on IoFT is proposed, including a classification, description and comparative study of different work on IoFT. Furthermore, the paper presents IoFT applications, IoFT challenges and future perspectives. This survey aims to provide the basic concepts and a complete overview of the recent studies on IoFT for the scientific researchers.}
}
@article{GUL2021103524,
title = {Blockchain for public health care in smart society},
journal = {Microprocessors and Microsystems},
volume = {80},
pages = {103524},
year = {2021},
issn = {0141-9331},
doi = {https://doi.org/10.1016/j.micpro.2020.103524},
url = {https://www.sciencedirect.com/science/article/pii/S0141933120306748},
author = {M. Junaid Gul and Barathi Subramanian and Anand Paul and Jeonghong Kim},
keywords = {IoT, IoMT,usiness Models, Blockchain, Healthcare, Smart Society},
abstract = {Blockchain is a new technology that demands more efficient and scalable techniques to incorporate it with business models. Therefore, in this paper, we propose a blockchain-based smart healthcare business model, which keeps customers at the center of business. Our proposed smart healthcare business model can predict customer's status and is able to give rewards according to the business rules set by participating organizations. However, businesses also demand something in return, and in our scenario, we are concerned about data in the wild. Our model fetches “data in the wild” from the Internet of Medical Things. Nevertheless, this model can be applied to any business scenario where a customer reward system exists. Our proposed model focuses more on customers and business while utilizing technology to ease the customer and other parties involved in the business. This fusion makes business more effective as the organization can determine the path of business and make decisions accordingly. Incorporating technologies with existing business models such as the “consumer centric model” makes it easy for businesses to modernize.}
}
@article{GUO2017519,
title = {Object detection among multimedia big data in the compressive measurement domain under mobile distributed architecture},
journal = {Future Generation Computer Systems},
volume = {76},
pages = {519-527},
year = {2017},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2017.03.004},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X17303333},
author = {Jie Guo and Bin Song and Fei {Richard Yu} and Zheng Yan and Laurence T. Yang},
keywords = {Exploration method, Multimedia big data, Compressed sensing, Distributed computing architecture},
abstract = {Multimedia big data is difficult to handle because of its enormous amount and the elusive property of underlying information. To study how to explore valuable information among multimedia big data with low complexity, this paper proposes an object detection method of big data, which is in compressive measurement domain under a mobile distributed computing architecture. It includes the sparse representation and object detection processes. Considering the unbalanced computation capacity between a mobile center cloud and mobile edge sites, we shift large storage burden into the cloud, while performing the dictionary learning by using compressive measurements in the mobile edge sites. Specifically, after getting the measurements at the edge sites, we perform dictionary learning to obtain the sparse representation in pixel domain, then select significant images and their feature vectors to be stored in the center cloud. In addition, we also analyze the trained dictionary in the measurement domain employing measurements. In order to reveal the two kinds of dictionaries’ relationship, we conduct a formulation process into each of them and find that the relationship depends on the uniqueness relation between the original signal and the sparse coefficient in the measurement domain. At the same time, we keep coefficients for a certain time period at the mobile edge sites in order to realize real time object detection, taking the advantage of low latency of the mobile edge computing ends. Since the sparse coefficients and the original signal have a one-to-one correspondence relationship, we can just search for the matched coefficients of the image block for detecting object. Experimental results show that Hadamard measurement matrix can better preserve the characteristics of the original signal than Gaussian matrix and that the proposed method can achieve a favorable detection performance. Meanwhile, the computation cost and storage cost of the proposed detection process can be significantly reduced compared with traditional methods, which is suitable for the multimedia big data. This can also be used in smart cities for looking for lost children and other specific events.}
}
@article{SEMERARO2021103469,
title = {Digital twin paradigm: A systematic literature review},
journal = {Computers in Industry},
volume = {130},
pages = {103469},
year = {2021},
issn = {0166-3615},
doi = {https://doi.org/10.1016/j.compind.2021.103469},
url = {https://www.sciencedirect.com/science/article/pii/S0166361521000762},
author = {Concetta Semeraro and Mario Lezoche and Hervé Panetto and Michele Dassisti},
keywords = {Digital twin, Industry 4.0, Cyber-physical systems, Predictive manufacturing},
abstract = {Manufacturing enterprises are facing the need to align themselves to the new information technologies (IT) and respond to the new challenges of variable market demand. One of the key enablers of this IT revolution toward Smart Manufacturing is the digital twin (DT). It embeds a “virtual” image of the reality constantly synchronized with the real operating scenario to provide sound information (knowledge model) to reality interpretation model to draw sound decisions. The paper aims at providing an up-to date picture of the main DT components, their features and interaction problems. The paper aims at clearly tracing the ongoing research and technical challenges in conceiving and building DTs as well, according to different application domains and related technologies. To this purpose, the main questions answered here are: ‘What is a Digital Twin?’; ‘Where is appropriate to use a Digital Twin?’; ‘When has a Digital Twin to be developed?’; ‘Why should a Digital Twin be used?’; ‘How to design and implement a Digital Twin?’; ‘What are the main challenges of implementing a Digital Twin?’. This study tries to answer to the previous questions funding on a wide systematic literature review of scientific research, tools, and technicalities in different application domains.}
}
@article{LO2021101297,
title = {A review of digital twin in product design and development},
journal = {Advanced Engineering Informatics},
volume = {48},
pages = {101297},
year = {2021},
issn = {1474-0346},
doi = {https://doi.org/10.1016/j.aei.2021.101297},
url = {https://www.sciencedirect.com/science/article/pii/S1474034621000513},
author = {C.K. Lo and C.H. Chen and Ray Y. Zhong},
keywords = {Digital twin, Product design, New product development, Product lifecycle, Review},
abstract = {In the era of digitalization, there are many emerging technologies, such as the Internet of Things (IoT), Digital Twin (DT), Cloud Computing and Artificial Intelligence (AI), which are quickly developped and used in product design and development. Among those technologies, DT is one promising technology which has been widely used in different industries, especially manufacturing, to monitor the performance, optimize the progresses, simulate the results and predict the potential errors. DT also plays various roles within the whole product lifecycle from design, manufacturing, delivery, use and end-of-life. With the growing demands of individualized products and implementation of Industry 4.0, DT can provide an effective solution for future product design, development and innovation. This paper aims to figure out the current states of DT research focusing on product design and development through summarizing typical industrial cases. Challenges and potential applications of DT in product design and development are also discussed to inspire future studies.}
}
@article{VILENSKI2019412,
title = {Multivariate anomaly detection for ensuring data quality of dendrometer sensor networks},
journal = {Computers and Electronics in Agriculture},
volume = {162},
pages = {412-421},
year = {2019},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2019.04.018},
url = {https://www.sciencedirect.com/science/article/pii/S0168169918317666},
author = {Efrat Vilenski and Peter Bak and Jonathan D. Rosenblatt},
keywords = {Dendrometer, Irrigation scheduling, Precision agriculture, Data quality, Multivariate data, Anomaly detection, Internet of things},
abstract = {Ensuring the integrity of data from large sensor networks is a challenging task that is relevant in many domains. Precision agriculture is one instance of this challenge, where dendrometer sensors provide data used for plot-specific irrigation decisions, with critical implications for yields and water savings. To aid the identification of malfunctioning dendrometer sensors, we introduce a pipeline for detecting various types of anomalies and investigating their root causes using visual analytics. Our pipeline is unique not only in that it borrows from web technologies to provide interactivity, but also because it incorporates detection algorithms from several fields, such as robust multivariate statistics, unsupervised machine learning, and social-network analysis.}
}
@article{TROTTA2020107425,
title = {BEE-DRONES: Ultra low-power monitoring systems based on unmanned aerial vehicles and wake-up radio ground sensors},
journal = {Computer Networks},
volume = {180},
pages = {107425},
year = {2020},
issn = {1389-1286},
doi = {https://doi.org/10.1016/j.comnet.2020.107425},
url = {https://www.sciencedirect.com/science/article/pii/S1389128620311142},
author = {Angelo Trotta and Marco Di Felice and Luca Perilli and Eleonora Franchi Scarselli and Tullio Salmon Cinotti},
keywords = {Wireless sensor networks, Unmanned aerial vehicle, Wake-Up radio},
abstract = {Nowadays, Unmanned Aerial Vehicles (UAVs) represent a significant aid on scenarios where fixed, ground infrastructures are temporarily or permanently not available; this is the case of large-scale applications of the Internet of Things (IoTs), e.g. smart city and agriculture 3.0, where the UAVs can be employed as mobile data mules and gather the data from Wireless Ground Sensors (WGSs). UAV-aided wireless sensor networks (WSNs) introduce considerable advantages both in terms of performance and costs since they avoid the need of error-prone multi-hop communications, and also the installation of static gateways; at the same time, they pose formidable research challenges for their implementation, like the synchronization issue between the UAV and the WGS and the path planning, which should take into account the extremely limited flight autonomy of the UAVs. In this paper, we address both the issues above by proposing BEE-DRONES, a novel framework for large-scale, ultra low-power UAV-aided WSNs. In order to mitigate the synchronization problem, we investigate the utilization of passive Wake-up Radio (WR) technology on the WGSs, and of wireless power transfer from the UAVs: by harvesting the energy from the UAV hovering over it, the WGS is activated only for the short time required to transfer the data toward the mobile sink, while it experiences zero-consumption in sleep mode. We investigate the performance of passive WR-based WGS through real measurements, under different WGS-UAV distances and antenna orientations. Then, based on such results, we formulate the joint WGS scheduling and UAV path planning problem, where the goal is to determine the optimal trajectory of the UAVs activating the WR-based WGSs while taking into account the Value of the Sensing (VoS) as well as the total lifetime of the WSN. The original problem is transformed into a multi-commodity flow problem, and both centralized and distributed heuristics over the multi-graph are proposed. Finally, we evaluate the proposed algorithms through extensive OMNeT++ simulations; the results demonstrate the gain of BEE-DRONES in terms of extended lifetime compared to traditional, non WR-based solutions (e.g. duty-cycle), and in terms of reduced data-correlation compared to non VoS-aware path planning solutions.}
}
@article{GOMEZ2019100,
title = {Exploratory study on Class Imbalance and solutions for Network Traffic Classification},
journal = {Neurocomputing},
volume = {343},
pages = {100-119},
year = {2019},
note = {Learning in the Presence of Class Imbalance and Concept Drift},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2018.07.091},
url = {https://www.sciencedirect.com/science/article/pii/S092523121930164X},
author = {Santiago Egea Gómez and Luis Hernández-Callejo and Belén Carro Martínez and Antonio J. Sánchez-Esguevillas},
keywords = {Machine Learning, Network management, Class Imbalance, Network Traffic Classification},
abstract = {Network Traffic Classification is a fundamental component in network management, and the fast-paced advances in Machine Learning have motivated the application of learning techniques to identify network traffic. The intrinsic features of Internet networks lead to imbalanced class distributions when datasets are conformed, phenomena called Class Imbalance and that is attaching an increasing attention in many research fields. In spite of performance losses due to Class Imbalance, this issue has not been thoroughly studied in Network Traffic Classification and some previous works are limited to few solutions and/or assumed misleading methodological approaches. In this article, we deal with Class Imbalance in Network Traffic Classification, studying the presence of this phenomenon and analyzing a wide number of solutions in two different Internet environments: a lab network and a high-speed backbone. Namely, we experimented with 21 data-level algorithms, six ensemble methods and one cost-level approach. Throughout the experiments performed, we have applied the most recent methodological aspects for imbalanced problems, such as: DOB-SCV validation approach or the performance metrics assumed. And last but not least, the strategies to tune parameters and our algorithm implementations to adapt binary methods to multiclass problems are presented and shared with the research community, including two ensemble techniques used for the first time in Machine Learning to the best of our knowledge. Our experimental results reveal that some techniques mitigated Class Imbalance with interesting benefit for traffic classification models. More specifically, some algorithms reached increases greater than 8% in overall accuracy and greater than 4% in AUC-ROC for the most challenging network scenario.}
}
@article{YAN2021111165,
title = {Strategical district cooling system operation with accurate spatiotemporal consumption modeling},
journal = {Energy and Buildings},
volume = {247},
pages = {111165},
year = {2021},
issn = {0378-7788},
doi = {https://doi.org/10.1016/j.enbuild.2021.111165},
url = {https://www.sciencedirect.com/science/article/pii/S0378778821004497},
author = {Biao Yan and Ge Chen and Hongcai Zhang and Man Chung Wong},
keywords = {District cooling system, Energy efficiency, Operation optimization, Spatiotemporal modeling, Thermal comfort},
abstract = {As a large integrated energy system, district cooling system (DCS) is widely proposed for its favorable comprehensive performance. However, due to the high complexity of DCS structure and comprehensive influential variables on cooling demand, to propose an effective operational strategy that not only enhances energy efficiency but also ensures indoor thermal comfort is quite challenging. This research proposes a novel and online multi-objective optimization strategy for DCS operations, which minimizes both energy consumption and thermal discomfort, to tackle the aforementioned challenge. The proposed strategy incorporates accurate spatiotemporal cooling demand modeling: (1) On the one hand, cooling load models of both cooling dissipations during transport networks and cooling end consumers considering comprehensive influence of outdoor meteorological parameters are described; (2) On the other hand, all power consumption components in the DCS including chiller, pump, fan coil, fan of cooling tower, are built and connected with system cooling demand. Numerical experiments based on a real-world DCS are conducted to validate the proposed strategy. The results show that by adopting the proposed strategy, energy consumption cost and thermal comfort can be effectively optimized and can save an extra 5% of energy consumption comparing with published strategies.}
}
@article{REYNOLDS2018397,
title = {Holistic modelling techniques for the operational optimisation of multi-vector energy systems},
journal = {Energy and Buildings},
volume = {169},
pages = {397-416},
year = {2018},
issn = {0378-7788},
doi = {https://doi.org/10.1016/j.enbuild.2018.03.065},
url = {https://www.sciencedirect.com/science/article/pii/S0378778817340240},
author = {Jonathan Reynolds and Muhammad Waseem Ahmad and Yacine Rezgui},
keywords = {Energy modelling, Multi-vector energy systems, Power-to-Gas, Building energy modelling, Urban energy systems, Energy management, Optimisation},
abstract = {Modern district energy systems are highly complex with several controllable and uncontrollable variables. To effectively manage a multi-vector district requires a holistic perspective in terms of both modelling and optimisation. Current district optimisation strategies found in the literature often consider very simple models for energy generation and conversion technologies. To improve upon the state of the art, more realistic and accurate models must be produced whilst remaining computationally and mathematically simple enough to calculate within short periods. Therefore, this paper provides a comprehensive review of modelling techniques for common district energy conversion technologies including Power-to-Gas. In addition, dynamic building modelling techniques are reviewed, as buildings must be considered active and flexible participants in a district energy system. In both cases, a specific focus is placed on artificial intelligence-based models suitable for implementation in the real-time operational optimisation of multi-vector systems. Future research directions identified from this review include the need to integrate simplified models of energy conversion units, energy distribution networks, dynamic building models and energy storage into a holistic district optimisation framework. Finally, a future district energy management solution is proposed. It leverages semantic modelling to allow interoperability of heterogeneous data sources to provide added value inferencing from contextually enriched information.}
}
@article{BOURGAIS2021507,
title = {Detecting Situations with Stream Reasoning on Health Data Obtained with IoT},
journal = {Procedia Computer Science},
volume = {192},
pages = {507-516},
year = {2021},
note = {Knowledge-Based and Intelligent Information & Engineering Systems: Proceedings of the 25th International Conference KES2021},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2021.08.052},
url = {https://www.sciencedirect.com/science/article/pii/S1877050921015398},
author = {Mathieu Bourgais and Franco Giustozzi and Laurent Vercouter},
keywords = {IoT, Stream Reasoning, Health Data},
abstract = {The development of Internet of Things (IoT) creates large amount of data usable by decision making systems in various domains. In particular, in the field of health monitoring, it enables to follow the medical state of a patient at home in real-time. A challenge is to interpret these data with a high-level representation model in order to have a better understanding of the medical state of a patient. We propose in this article to use Stream Reasoning associated to an ontological representation of the medical context of a patient to understand her situation. This permits to combine in real time static knowledge stored in an ontology and dynamic information provided by smart sensors. To facilitate this process, we introduce constraints and situations concepts to ease the translation of expert knowledge into logical queries. We provide in this paper an experimental analysis of real body temperature data to illustrate how situations may be detected.}
}
@article{MUPPAVARAPU2021101923,
title = {Knowledge extraction using semantic similarity of concepts from Web of Things knowledge bases},
journal = {Data & Knowledge Engineering},
volume = {135},
pages = {101923},
year = {2021},
issn = {0169-023X},
doi = {https://doi.org/10.1016/j.datak.2021.101923},
url = {https://www.sciencedirect.com/science/article/pii/S0169023X21000501},
author = {Vamsee Muppavarapu and Gowtham Ramesh and Amelie Gyrard and Mahda Noura},
keywords = {Interoperability, Internet of Things, Semantic Web of Things, Popular concepts, Smart building, Smart home},
abstract = {The Internet of Things (IoT) is one of the rapidly growing technologies with the aim of establishing communication among objects, people, and processes. This rapidly growing technology faces a lot of challenges that hinder its wider adoption, specifically in developing applications that involve heterogeneous domains. Currently, developing such interoperable applications require substantial efforts by the developers to hard code the requirements to ensure the correctness of transferring knowledge. The efforts can be significantly reduced by developing an interoperable platform that ensures seamless communication between heterogeneous IoT devices. W3C Web of Things (WoT) is a significant step towards enabling interoperability between IoT devices by integrating the existing Web ecosystem with “Things”. WoT provides a unified interface over a suitable network protocol facilitating interactions between different IoT protocols. WoT Thing Descriptions (TD) enrich interoperability providing both human and machine readable metadata about a Thing. However, the WoT still falls short in providing semantic interoperability due to insufficient standard vocabularies which can describe different IoT application domains. In this paper, we propose a semantic similarity-based approach to automatically identify and extract the most common concepts from sixteen popular ontologies belonging to smart home and smart building domains. The proposed method helps the developers and researchers to develop a domain ontology with reduced effort. The extracted concepts are evaluated by the domain experts and are found to be sufficient in describing the smart home and smart building domains.}
}
@article{MISAK2015272,
title = {A heuristic approach to Active Demand Side Management in Off-Grid systems operated in a Smart-Grid environment},
journal = {Energy and Buildings},
volume = {96},
pages = {272-284},
year = {2015},
issn = {0378-7788},
doi = {https://doi.org/10.1016/j.enbuild.2015.03.033},
url = {https://www.sciencedirect.com/science/article/pii/S037877881500242X},
author = {Stanislav Mišák and Jindřich Stuchlý and Jan Platoš and Pavel Krömer},
keywords = {Smart-Grid system, Smart house, Off-Grid system, Renewable energy sources (RESs), Active Demand Side Management (ADSM), Active energy unit, Artificial intelligence},
abstract = {This paper presents a heuristic approach to Active Demand Side Management in the Off-Grid systems with a set of specific requirements. The tests were performed on the smart house platform developed at VSB – Technical University of Ostrava campus, Czech Republic in order to accomplish the effective design, testing, operation and analysis of the proposed system. These results consequently consist of a prerequisite for the development of new leading-edge power distribution systems in the Off-Grid environment and for improvement of the efficiency, security and reliability of the existing systems.}
}
@article{LI2020718,
title = {Information processing in Internet of Things using big data analytics},
journal = {Computer Communications},
volume = {160},
pages = {718-729},
year = {2020},
issn = {0140-3664},
doi = {https://doi.org/10.1016/j.comcom.2020.06.020},
url = {https://www.sciencedirect.com/science/article/pii/S0140366420311579},
author = {Chaomin Li},
keywords = {Internet of Things (IoT), Fog computing, Cloud computing, Naïve Bayes classifier, Smart and real-time healthcare information processing (SRHIP)},
abstract = {With innovation in persistent technologies, such as wearable sensor gadgets, sensor devices, and wireless ad-hoc communication networks connect everyday life things to the Internet, normally referred to as Internet of Things (IoT). IoT is observed as an active entity for design and development of smart and context awareness services and applications in the area of business, science and engineering discipline. These applications and services could vigorously respond to the surroundings transformation and users’ preference. Developing a scalable system for data analysis, processing and mining of enormous real world based datasets has turned into one of the demanding problems that faces both system research scholars and data management research scholars. Employing big data analytics with IoT technologies is one of the ways for handling the timely analyzing information (i.e., data, events) streams. In this paper, we propose an integrated approach that coalesce IoT systems with big data tools into a holistic platform for real-time and continuous data monitoring and processing. We propose Fog assisted IoT based Smart and real time healthcare information processing (SRHIP) system in which large amounts of data generated by IoT sensor devices are offloaded at Fog cloud form data analytics and processing with minimum delay. The processed data is then transferred to a centralized cloud system for further analysis and storage. In this work, we introduce a Fog-assisted model with big data environment for data analytic of real time data with remote monitoring and discuss our plan for evaluating its efficacy in terms of several performance metrics such as transmission cost, storage cost, accuracy, specificity, sensitivity and F-measure. The proposed SRHIP system needs less transmission cost of 40.10% in comparison to SPPDA, 100% fewer bytes are compromised in comparison to GCEDA. Our proposed system data size reduction of 60% reduction due to proposed compression scheme in comparison to other benchmark strategies that offer 40% of reduction.}
}
@article{SHUKLA2020103625,
title = {A bibliometric analysis and cutting-edge overview on fuzzy techniques in Big Data},
journal = {Engineering Applications of Artificial Intelligence},
volume = {92},
pages = {103625},
year = {2020},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2020.103625},
url = {https://www.sciencedirect.com/science/article/pii/S0952197620300877},
author = {Amit K. Shukla and Pranab K. Muhuri and Ajith Abraham},
keywords = {Big data, Fuzzy sets, Type-2 fuzzy sets, Bibliometric study, Web of science, Scopus},
abstract = {Over the last few years, Big Data has gained a tremendous attention from the research community. The data being generated in huge quantity from almost every field is unstructured and unprocessed. Extracting knowledge base and useful information from the big raw data is one of the major challenges, present today. Various computational intelligence and soft computing techniques have been proposed for efficient big data analytics. Fuzzy techniques are one of the soft computing approaches which can play a very crucial role in current big data challenges by pre-processing and reconstructing data. There is a wide spread application domains where traditional fuzzy sets (type-1 fuzzy sets) and higher order fuzzy sets (type-2 fuzzy sets) have shown remarkable outcomes. Although, this research domain of “fuzzy techniques in Big Data” is gaining some attention, there is a strong need for a motivation to encourage researchers to explore more in this area. In this paper, we have conducted bibliometric study on recent development in the field of “fuzzy techniques in big data”. In bibliometric study, various performance metrics including total papers, total citations, and citation per paper are calculated. Further, top 10 of most productive and highly cited authors, discipline, source journals, countries, institutions, and highly influential papers are also evaluated. Later, a comparative analysis is performed on the fuzzy techniques in big data after analysing the most influential works in this field.}
}
@article{ISLAM2018216,
title = {A robust and efficient password-based conditional privacy preserving authentication and group-key agreement protocol for VANETs},
journal = {Future Generation Computer Systems},
volume = {84},
pages = {216-227},
year = {2018},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2017.07.002},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X17308439},
author = {SK Hafizul Islam and Mohammad S. Obaidat and Pandi Vijayakumar and Enas Abdulhay and Fagen Li and M Krishna Chaitanya Reddy},
keywords = {VANET, Group-key, Conditional privacy, Road-side-unit, On-board-unit, Hash function},
abstract = {With the rapid growth of information and communication technology (ICT) and Internet of things (IoT), the concept of smart-city is recently introduced by the government of many countries to improve the living environment of urban people. In city areas, the numbers of vehicles are increased exponentially day-by-day. Therefore, it is very difficult to control and manage the city traffic caused by tens of thousands vehicles. The Vehicular Ad-hoc Network (VANET) is used to communicate with the vehicles to give alert for weather conditions, road defects, traffic conditions, etc. and the conditions of the vehicle including location, speed, traffic status, etc. Therefore, the traffic efficiency and safety of the vehicles can be improved with the help of VANET. To serve this purpose, in the literature, many conditional privacy preserving authentication (CPPA) protocols based on CA-PKC (certificate authority-based public key cryptography), and ID-PKC (identity-based public key cryptography) have been put forwarded. In addition, some of these CPPA protocols use elliptic curve or bilinear-pairing for their implementation. The computation cost for bilinear-pairing and elliptic curve is very high compared to the cryptographic general hash function. Therefore, all the earlier protocols suffer from the heavy computational burden and some security weaknesses as well. Therefore, bilinear-pairing-free, robust and efficient CPPA with group-key agreement protocol for VANETs is essential. This paper presents a password-based conditional privacy preserving authentication and group-key generation (PW-CPPA-GKA) protocol for VANETs. Our protocol offers group-key generation, user leaving, user join, and password change facilities. Our protocol is lightweight in terms computation and communication since it can be designed without bilinear-pairing and elliptic curve.}
}
@article{FARROKHI2020257,
title = {Using artificial intelligence to detect crisis related to events: Decision making in B2B by artificial intelligence},
journal = {Industrial Marketing Management},
volume = {91},
pages = {257-273},
year = {2020},
issn = {0019-8501},
doi = {https://doi.org/10.1016/j.indmarman.2020.09.015},
url = {https://www.sciencedirect.com/science/article/pii/S0019850120308464},
author = {Aydin Farrokhi and Farid Shirazi and Nick Hajli and Mina Tajvidi},
keywords = {Big data, Artificial intelligence, Machine learning, Data mining, Sentiment analytics},
abstract = {Artificial Intelligence (AI) could be an important foundation of competitive advantage in the market for firms. As such, firms use AI to achieve deep market engagement when the firm's data are employed to make informed decisions. This study examines the role of computer-mediated AI agents in detecting crises related to events in a firm. A crisis threatens organizational performance; therefore, a data-driven strategy will result in an efficient and timely reflection, which increases the success of crisis management. The study extends the situational crisis communication theory (SCCT) and Attribution theory frameworks built on big data and machine learning capabilities for early detection of crises in the market. This research proposes a structural model composed of a statistical and sentimental big data analytics approach. The findings of our empirical research suggest that knowledge extracted from day-to-day data communications such as email communications of a firm can lead to the sensing of critical events related to business activities. To test our model, we use a publicly available dataset containing 517,401 items belonging to 150 users, mostly senior managers of Enron during 1999 through the 2001 crisis. The findings suggest that the model is plausible in the early detection of Enron's critical events, which can support decision making in the market.}
}
@article{TANG2021117297,
title = {Interpolating high granularity solar generation and load consumption data using super resolution generative adversarial network},
journal = {Applied Energy},
volume = {299},
pages = {117297},
year = {2021},
issn = {0306-2619},
doi = {https://doi.org/10.1016/j.apenergy.2021.117297},
url = {https://www.sciencedirect.com/science/article/pii/S0306261921007108},
author = {Rui Tang and Jonathon Dore and Jin Ma and Philip H.W. Leong},
keywords = {Data interpolation, Smart meter, Load energy, Solar energy},
abstract = {The vast majority of commonly accessible photovoltaics (PV) generation and load consumption datasets have low temporal resolutions, leading to inaccuracies in the modeling and optimisation of PV-integrated battery systems. This study addresses this problem by proposing an interpolation model based on a super resolution generative adversarial network (SRGAN) that generates 5-minute PV and load power data from 30-minute/hourly temporal resolutions. The proposed approach is validated by two different datasets including large amounts of residential data and compared to an alternative predictive model. The results indicate that the model can adequately capture the targeted data distributions and temporal characteristics with negligible statistical differences from the measured high resolution data. Moreover, it performs consistently across different types of PV/load profiles and on average it results in 0.32% and 0.28% normalised root mean squared errors (NRMSEs) in daily totals of 5-minute PV and load power values when using hourly data as inputs. Under a time-of-use (ToU) tariff, the interpolated 5-minute data leads to 44.7% and 41.7% error reductions compared to using hourly data for estimating electricity costs and battery saving potentials of a PV battery system. Hence, the proposed model can be potentially applied in a battery sizing tool to obtain more accurate sizing results when only low resolution data is available.}
}
@article{YU2021107120,
title = {Emotion-aware mobile edge computing system: A case study},
journal = {Computers & Electrical Engineering},
volume = {92},
pages = {107120},
year = {2021},
issn = {0045-7906},
doi = {https://doi.org/10.1016/j.compeleceng.2021.107120},
url = {https://www.sciencedirect.com/science/article/pii/S0045790621001245},
author = {Qiao Yu and Wenjing Xiao and Sheng Jiang and Mohammed F. Alhamid and Ghulam Muhammad and M. Shamim Hossain},
keywords = {Emotion-aware, Mobile computing, Edge computing, Emotion detection, Health care},
abstract = {Recently, great progress has been witnessed in the application of mobile cloud computing in the field of health care such as online medical inquiries. However, due to the limitation of cognitive intelligence, QoE (Quality of Experience) is hampered by two problems, the first of which is that the traffic pressure of the core network cannot well meet the requirements of delay-sensitive emotional services, especially for users with different emergencies, while the second is that current applications cannot provide personalized service for different users. Based on the two problems, we propose an emotion-aware mobile edge computing architecture based on emotional task priority to guide the allocation of edge resources and to provide intelligent and personalized emotional services with higher QoE. Specifically, we first introduce the entities involved in the proposed architecture of emotion-aware mobile edge computing system. Next, we describe our optimal computing resource allocation strategy, including important concepts and a detailed algorithm. Finally, we build a test platform and conduct experiments, which show that the proposed architecture obtains better performance in terms of system utility compared with baseline methods.}
}
@article{FINOTTIAMARAL2020149,
title = {An extension of the type-1 and singleton fuzzy logic system trained by scaled conjugate gradient methods for multiclass classification problems},
journal = {Neurocomputing},
volume = {411},
pages = {149-163},
year = {2020},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2020.05.052},
url = {https://www.sciencedirect.com/science/article/pii/S0925231220308870},
author = {Renan P. {Finotti Amaral} and Ivan F.M. Menezes and Moisés V. Ribeiro},
keywords = {Fuzzy logic system, Multiclass classification, Scaled conjugate gradient, Hessian-free},
abstract = {This paper proposes an extension of the type-1 and singleton fuzzy logic system for dealing with multiclass classification problems. The proposed extension enables a fuzzy classifier to generate more than one output, thereby avoiding the use of binary decomposition strategies when multiclass classification problems are considered. Additionally, with the goal of improving classifier performance, the scaled conjugate gradient training method was applied, as well as its modified version using the differential operator R·. The effectiveness of the proposed extension was evaluated using data from the UCI Machine Learning Repository based on well-established classification metrics. The numerical results reveal a significant reduction in computational complexity when using the proposed extension compared to the traditional decomposition strategy, as well as improved convergence speed when using the scaled conjugate gradient training method.}
}
@article{RIBEIRO2017675,
title = {An Advanced Software Tool to Simulate Service Restoration Problems: a case study on Power Distribution Systems},
journal = {Procedia Computer Science},
volume = {108},
pages = {675-684},
year = {2017},
note = {International Conference on Computational Science, ICCS 2017, 12-14 June 2017, Zurich, Switzerland},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2017.05.248},
url = {https://www.sciencedirect.com/science/article/pii/S1877050917308761},
author = {Richardson Ribeiro and Fabrício Enembreck and Douglas M. Guisi and Dalcimar Casanova and Marcelo Teixeira and Fausto A. {de Souza} and André P. Borges},
keywords = {Software Tool, Restoration Problem, Self-Healing Smart Grid, Reinforcement Learning},
abstract = {This paper presents a software tool to simulate a practical problem in smart grid systems. A feature of the smart grid is a system self-recovery capability in the occurrence of anomalies, such as a recovery of a power distribution network after an occurrence of a fault. When this system has a capacity for self-recovery, it is called self-healing. The intersection among areas as computer science, telecommunication, automation and electrical engineering, has allowed power systems to gain new technologies. However, because it is a multi-area domain, self-recovery simulation tools in smart grids are often highly complex as well as presenting low fidelity by using approximation algorithms. The main contribution of this paper is a simulator with high fidelity and low complexity in terms of programming, usability and semantics. In this simulator, a computational intelligence technique and a derivative method for calculating the power flow were encapsulated. The result is a software tool with high abstraction and easy customization, aimed at a self-healing system for a reconfiguration of an electric power distribution network.}
}
@article{LI2021100900,
title = {Digital technology, tele-medicine and artificial intelligence in ophthalmology: A global perspective},
journal = {Progress in Retinal and Eye Research},
volume = {82},
pages = {100900},
year = {2021},
issn = {1350-9462},
doi = {https://doi.org/10.1016/j.preteyeres.2020.100900},
url = {https://www.sciencedirect.com/science/article/pii/S1350946220300720},
author = {Ji-Peng Olivia Li and Hanruo Liu and Darren S.J. Ting and Sohee Jeon and R.V. Paul Chan and Judy E. Kim and Dawn A. Sim and Peter B.M. Thomas and Haotian Lin and Youxin Chen and Taiji Sakomoto and Anat Loewenstein and Dennis S.C. Lam and Louis R. Pasquale and Tien Y. Wong and Linda A. Lam and Daniel S.W. Ting},
keywords = {Telemedicine, Tele-ophthalmology, Tele-screening, Diabetic retinopathy screening, Artificial intelligence, Deep learning, Digital transformation, Digital innovations, COVID-19, Digital technology},
abstract = {The simultaneous maturation of multiple digital and telecommunications technologies in 2020 has created an unprecedented opportunity for ophthalmology to adapt to new models of care using tele-health supported by digital innovations. These digital innovations include artificial intelligence (AI), 5th generation (5G) telecommunication networks and the Internet of Things (IoT), creating an inter-dependent ecosystem offering opportunities to develop new models of eye care addressing the challenges of COVID-19 and beyond. Ophthalmology has thrived in some of these areas partly due to its many image-based investigations. Tele-health and AI provide synchronous solutions to challenges facing ophthalmologists and healthcare providers worldwide. This article reviews how countries across the world have utilised these digital innovations to tackle diabetic retinopathy, retinopathy of prematurity, age-related macular degeneration, glaucoma, refractive error correction, cataract and other anterior segment disorders. The review summarises the digital strategies that countries are developing and discusses technologies that may increasingly enter the clinical workflow and processes of ophthalmologists. Furthermore as countries around the world have initiated a series of escalating containment and mitigation measures during the COVID-19 pandemic, the delivery of eye care services globally has been significantly impacted. As ophthalmic services adapt and form a “new normal”, the rapid adoption of some of telehealth and digital innovation during the pandemic is also discussed. Finally, challenges for validation and clinical implementation are considered, as well as recommendations on future directions.}
}
@article{AGRAWAL2021104,
title = {Developing bug severity prediction models using word2vec},
journal = {International Journal of Cognitive Computing in Engineering},
volume = {2},
pages = {104-115},
year = {2021},
issn = {2666-3074},
doi = {https://doi.org/10.1016/j.ijcce.2021.08.001},
url = {https://www.sciencedirect.com/science/article/pii/S2666307421000127},
author = {Rashmi Agrawal and Rinkaj Goyal},
keywords = {Word embedding, Bug severity prediction, Natural language processing, Hyperparameters, Text analytics},
abstract = {Bug tracking systems use repositories to keep track of the bugs to improve software quality. A manual analysis of each bug and classifying it according to its severity is an unmanageable job. Therefore, it is imperative to correctly classify the severity of a bug, which otherwise might be misclassified by a laymen user. Text mining techniques have the potential to analyze such massive databases of the textual description of bug reports to classify bug severity levels adequately. Word embedding is a state-of-art text mining technique that captures the semantics of the text and group the words according to their relevance in a document. Words are embedded into real-valued vectors through word-embedding models. Word2vec is a word embedding model, proven to be effective in representing word meanings. However, the configuration of hyperparameters and feature selection affects the performance of word2vec. Tuning hyperparameter is a time-consuming process, and it is crucial to identify the correct set of parameters. The paper outlines the effectiveness of word2vec technique on the efficiency of classifiers to predict a bug severity from a bug report and examines the impact of different averaging methods, including the configuration of word embedding parameters on the classifiers’ efficiency. Results show that the bigger window size enhances the performance of classifiers; however, the influence of the minimum word count parameter was found to be mixed and depends on the selected data sets. Further, out of the classifiers used, Random Forest and Xgboost could classify the severity level for classes with few records or a rare occurrence of words specific to each class. Otherwise, Support Vector Machine and Naive Bayes classifiers performed better and worst, respectively.}
}
@article{GUTOWSKI2021378,
title = {Gorthaur-EXP3: Bandit-based selection from a portfolio of recommendation algorithms balancing the accuracy-diversity dilemma},
journal = {Information Sciences},
volume = {546},
pages = {378-396},
year = {2021},
issn = {0020-0255},
doi = {https://doi.org/10.1016/j.ins.2020.08.106},
url = {https://www.sciencedirect.com/science/article/pii/S0020025520308744},
author = {Nicolas Gutowski and Tassadit Amghar and Olivier Camp and Fabien Chhel},
keywords = {Application of reinforcement learning, Recommendation systems, Multi-Armed Bandit, Contextual Multi-Armed Bandit, Portfolio approach},
abstract = {Nowadays, real-world pervasive computing applications increasingly face multi-objective problems. This is the case for recommendation systems where, from a user’s view point, recommended items must be both accurate and diverse. In recent years, model-based recommendation systems like those relying on Multi-Armed Bandit algorithms have been extensively studied. They are known to ensure theoretical guarantees of global accuracy. Nevertheless, despite these guarantees, the existing algorithms obtain different results depending on the application or on the dataset they operate on. Hence, when one needs to integrate such solutions, they should first be thoroughly evaluated to ensure the chosen method is efficient for the dynamic and potentially non-stationary nature of the target environments. However, human-based evaluations cost in time and money. Here, we propose a novel algorithm portfolio approach, Gorthaur-EXP3 aiming at automatically selecting the optimal algorithms which best maximise global accuracy and diversity of recommendations according to a predefined trade-off. Our method uses the EXP3 bandit algorithm which ensures a continuous exploration and a systematic exploitation of the best algorithm to apply in each situation it encounters. Gorthaur-EXP3 is an extension of the original Gorthaur method, which uses a roulette wheel selection, and obtains better results in most experimental cases.}
}
@article{CASADOVARA2020965,
title = {IoT network slicing on virtual layers of homogeneous data for improved algorithm operation in smart buildings},
journal = {Future Generation Computer Systems},
volume = {102},
pages = {965-977},
year = {2020},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2019.09.042},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X19304819},
author = {Roberto Casado-Vara and Angel {Martin-del Rey} and Soffiene Affes and Javier Prieto and Juan M. Corchado},
keywords = {IoT, Complex networks, Clustering, Layer slicing, Algorithm design, Data quality},
abstract = {With its strong coverage, low energy consumption, low cost and great connectivity, the Internet of Things technology has become the key technology in smart cities. However, faced with a large number of terminals, the rational allocation of limited resources, the topology and non-uniformity of smart buildings, the fusion of heterogeneous data become important trends in Internet of Things research. As a result, this paper proposes a novel technique for processing heterogeneous temperature data collected by an IoT network in a smart building and transforms them into homogeneous data that can be used as an input for monitoring and control algorithms in smart buildings, optimizing their performance. The proposed technique, called IoT slicing, combines complex networks and clusters in order to reduce algorithm input errors and improve the monitoring and control of a smart building. For validating the efficiency of the algorithm, it is proposed as a case study using the IoT slicing technique to improve the operation of an algorithm to self-correct outliers in data collected by IoT networks. The results of the case study confirm, irrefutably, the effectiveness of the proposed method.}
}
@article{YANG2018177,
title = {Mini-batch algorithms with Barzilai–Borwein update step},
journal = {Neurocomputing},
volume = {314},
pages = {177-185},
year = {2018},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2018.06.002},
url = {https://www.sciencedirect.com/science/article/pii/S0925231218307380},
author = {Zhuang Yang and Cheng Wang and Yu Zang and Jonathan Li},
keywords = {Stochastic optimization, Mini batches, Barzilai–Borwein method, Variance reduction, Convex optimization},
abstract = {As a way to accelerate stochastic schemes, mini-batch optimization has been a popular choice for large scale learning due to its good general performance and ease of parallel computing. However, the performance of mini-batch algorithms can vary significantly based on the choice of the step size sequence, and, in general, there is a paucity of guidance for making good choices. In this paper, we propose to use the Barzilai–Borwein (BB) update step to automatically compute step sizes for the state of the art mini-batch method (mini-batch semi-stochastic gradient descent (mS2GD) method), thereby obtaining a new optimization method: mS2GD-BB. We prove that mS2GD-BB converges linearly in expectation for nonsmooth strongly convex objective functions. We analyze the complexity of mS2GD-BB and show that it achieves as fast a rate as modern stochastic gradient methods. Numerical experiments on standard data sets indicate that the performance of mS2GD-BB is superior to some state of the art methods.}
}
@article{BIREK2018226,
title = {A novel Big Data analytics and intelligent technique to predict driver's intent},
journal = {Computers in Industry},
volume = {99},
pages = {226-240},
year = {2018},
issn = {0166-3615},
doi = {https://doi.org/10.1016/j.compind.2018.03.025},
url = {https://www.sciencedirect.com/science/article/pii/S0166361517303640},
author = {Lech Birek and Adam Grzywaczewski and Rahat Iqbal and Faiyaz Doctor and Victor Chang},
keywords = {Driver's intent prediction, Big Data, Big Data analytics, Computational intelligence, E-calendar, Geo referencing},
abstract = {Modern age offers a great potential for automatically predicting the driver's intent through the increasing miniaturization of computing technologies, rapid advancements in communication technologies and continuous connectivity of heterogeneous smart objects. Inside the cabin and engine of modern cars, dedicated computer systems need to possess the ability to exploit the wealth of information generated by heterogeneous data sources with different contextual and conceptual representations. Processing and utilizing this diverse and voluminous data, involves many challenges concerning the design of the computational technique used to perform this task. In this paper, we investigate the various data sources available in the car and the surrounding environment, which can be utilized as inputs in order to predict driver's intent and behavior. As part of investigating these potential data sources, we conducted experiments on e-calendars for a large number of employees, and have reviewed a number of available geo referencing systems. Through the results of a statistical analysis and by computing location recognition accuracy results, we explored in detail the potential utilization of calendar location data to detect the driver's intentions. In order to exploit the numerous diverse data inputs available in modern vehicles, we investigate the suitability of different Computational Intelligence (CI) techniques, and propose a novel fuzzy computational modelling methodology. Finally, we outline the impact of applying advanced CI and Big Data analytics techniques in modern vehicles on the driver and society in general, and discuss ethical and legal issues arising from the deployment of intelligent self-learning cars.}
}
@article{OULEFKI2021107747,
title = {Automatic COVID-19 lung infected region segmentation and measurement using CT-scans images},
journal = {Pattern Recognition},
volume = {114},
pages = {107747},
year = {2021},
issn = {0031-3203},
doi = {https://doi.org/10.1016/j.patcog.2020.107747},
url = {https://www.sciencedirect.com/science/article/pii/S0031320320305501},
author = {Adel Oulefki and Sos Agaian and Thaweesak Trongtirakul and Azzeddine {Kassah Laouar}},
keywords = {Corona-virus Ddisease (COVID-19), Computer-Aaided Ddetection (CAD), COVID-19 lesion, Segmentation, Color-mapping, 3D Visualization},
abstract = {History shows that the infectious disease (COVID-19) can stun the world quickly, causing massive losses to health, resulting in a profound impact on the lives of billions of people, from both a safety and an economic perspective, for controlling the COVID-19 pandemic. The best strategy is to provide early intervention to stop the spread of the disease. In general, Computer Tomography (CT) is used to detect tumors in pneumonia, lungs, tuberculosis, emphysema, or other pleura (the membrane covering the lungs) diseases. Disadvantages of CT imaging system are: inferior soft tissue contrast compared to MRI as it is X-ray-based Radiation exposure. Lung CT image segmentation is a necessary initial step for lung image analysis. The main challenges of segmentation algorithms exaggerated due to intensity in-homogeneity, presence of artifacts, and closeness in the gray level of different soft tissue. The goal of this paper is to design and evaluate an automatic tool for automatic COVID-19 Lung Infection segmentation and measurement using chest CT images. The extensive computer simulations show better efficiency and flexibility of this end-to-end learning approach on CT image segmentation with image enhancement comparing to the state of the art segmentation approaches, namely GraphCut, Medical Image Segmentation (MIS), and Watershed. Experiments performed on COVID-CT-Dataset containing (275) CT scans that are positive for COVID-19 and new data acquired from the EL-BAYANE center for Radiology and Medical Imaging. The means of statistical measures obtained using the accuracy, sensitivity, F-measure, precision, MCC, Dice, Jacquard, and specificity are 0.98, 0.73, 0.71, 0.73, 0.71, 0.71, 0.57, 0.99 respectively; which is better than methods mentioned above. The achieved results prove that the proposed approach is more robust, accurate, and straightforward.}
}
@article{GRZYBOWSKA2020113110,
title = {A simulation-optimisation genetic algorithm approach to product allocation in vending machine systems},
journal = {Expert Systems with Applications},
volume = {145},
pages = {113110},
year = {2020},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2019.113110},
url = {https://www.sciencedirect.com/science/article/pii/S0957417419308279},
author = {Hanna Grzybowska and Briscoe Kerferd and Charles Gretton and S. {Travis Waller}},
keywords = {Vending machine systems, Portfolio optimisation, Genetic algorithm, Simulation},
abstract = {In recent years, vending machines have seen increasing levels of popularity. In a fast-paced world where convenience and accessibility of products is highly sought after the vending industry has provided a suitable solution. Although the economic impact of the vending industry is indisputable, it is not without challenges, especially when it comes to the efficiency of the vending logistics operations. The optimisation of logistic vending machine systems is decidedly complex. Product allocation to columns in a vending machine, replenishment points of products, product thresholds at vending machines, and vehicle routes for inventory replenishments are all essential challenges in vending machine system management and operation. If all facets of the problem were to be addressed, it would require techniques such as forecasting, machine learning, data mining, combinatorial optimization and vehicle routing, among others. In the past, these approaches have been explored individually despite their intrinsic interdependence within the problem. This paper aims to help to fill in this gap and proposes a model for the optimisation of product allocation within a vending machine under the constraint of fixed restocking instances. The optimal product allocation is based on the definition of product profitability which accounts for the net revenue earned after the cost of restock, as opposed to the revenue earned until first stock-out to prevent arbitrary extension of the stock-out period. The whole approach is encompassed in the simulation-optimisation framework that utilises a Genetic Algorithm, with fitness evaluated as simulated revenue, to determine the optimal product allocation. The acceptable threshold of missed sales for a machine is also determined as a means to make intelligent restocking decisions. Overall, the proposed approach allows the strengths of mathematically robust optimization algorithms and the implementation of analytic solutions to be combined and applied to realistic scenarios where uncertainty may rule out some high quality analytic solutions. It respects problem intricacies proper to vending and addresses the interdependence between routing and portfolio optimisation. The proposal is application-driven and stems from a collaboration with an industry partner. The model is validated against an authentic data set supplied by the partner. The case study results revealed a network-wide improvement in net revenue of approximately 3.4%, with varied efficacy based on machine popularity. The method of optimisation was found to be significantly more effective for higher performing machines, with median improvements as high as 6%. Our framework based on the optimization-simulation model yields clear benefits to vending logistics operations management. The simulation component provides the decision maker with a more comprehensive view on the actual implementation of the solution. Effectively, the joint use of simulation and optimization methods provides managers with enhanced information to help decide on both: (i) the most beneficial product portfolio, and (ii) the quality of the proposed restocking schedules. Simulation-optimisation based approach is a powerful technique used to address stochastic problems. However, it was yet to be applied specifically to logistic vending machine systems.}
}
@article{TANG2020158,
title = {A n-Gated Recurrent Unit with review for answer selection},
journal = {Neurocomputing},
volume = {371},
pages = {158-165},
year = {2020},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2019.09.007},
url = {https://www.sciencedirect.com/science/article/pii/S0925231219312676},
author = {Dongge Tang and Wenge Rong and Shuang Qin and Jianxin Yang and Zhang Xiong},
keywords = {Answer selection, Review mechanism, Ebbinghaus forgetting curve, Sentence representation},
abstract = {Answer selection is one of the most important techniques in question answering applications since it can improve the user experience to a large extend. To achieve a better answer selection performance, a fundamental approach is to better understand the answers and questions. In this research, motivated by the Ebbinghaus Forgetting Curve which indicated that people should review the knowledge timely to prevent from forgetting, we proposed a new n-Gated Recurrent Unit with Review (nGRUR) model which applies the review mechanism on the gated recurrent unit (GRU). The nGRUR model recurrently reviews the past information after a fixed time distance n, and the process of review is controlled by the new gated units. Experimental results have proven the potential of the proposed model and the quantitative analysis has demonstrated that our model is able to acquire a better sentence level representation.}
}
@article{MARK20191,
title = {Ethics of Public Use of AI and Big Data: The Case of Amsterdam’s Crowdedness Project},
journal = {The ORBIT Journal},
volume = {2},
number = {2},
pages = {1-33},
year = {2019},
issn = {2515-8562},
doi = {https://doi.org/10.29297/orbit.v2i1.101},
url = {https://www.sciencedirect.com/science/article/pii/S2515856220300067},
author = {Ryan Mark},
abstract = {Smart information systems (Big Data and artificial intelligence) are used by governments to improve mobility, reduce over-crowdedness in hotspots, and provide more effective management of crowds. I looked at how Amsterdam municipality is using smart information systems (SIS) in their DrukteRadar Project to identify, report, and tackle issues surrounding crowdedness levels in the city. SIS are becoming popular amongst governmental officials to automate activities more effectively. SIS provide the opportunity to improve mobility, increase economic growth, reduce energy outputs, improve management decisions, respond to disasters quicker, and improve citizens’ quality of life. They offer governments the possibility of improving services, while reducing costs. The use and implementation of SIS is becoming widespread and governments are observing the benefits posed by SIS, particularly in relation to urban management. 80% of Europe’s population will live in cities by 2020 and governments face a huge strain on resources and infrastructure. The use of SIS is being pioneered to help governments meet these needs and to provide a sustainable future for urban citizens. Ethical issues in this context can include that data may not be accurate, faithful or representative of a city and its citizens, which may cause bias, prejudice and harm to a population, by leading to unfair service provision. ICT companies’ involvement in governmental SIS projects may also lead technological lock-in and dependency on corporations. Instantaneous and ubiquitous retrieval and analysis of data may infringe upon citizens’ privacy and may lead vulnerabilities of malicious hacking, stolen data and a city’s security. To uncover if these issues correlate with the experience of those working in the field, I interviewed the Project Owner of Amsterdam’s DrukteRadar project (translated as crowdedness project). This project implements SIS to anticipate and prevent overcrowding in Amsterdam, and was created in response to growing pressures on the city’s amenities. The DrukteRadar Project collates a wide array of datasets to predict crowd levels and potential problem hotspots, visualised through a digital dashboard. The project aims to improve municipality management, provide help to tourists planning their trips, and assisting citizens’ navigation through the city. Through my discussions with the Project Owner of the DrukteRadar, I uncovered two additional issues not found in the literature: access to SIS and data ownership. The DrukteRadar team is concerned about access to SIS to promote fairness, equality, and provision of services amongst citizens. It aims to make its dashboard user-friendly and available to as many people as possible to promote inclusion. Data ownership is a concern for the project – who owns the data and what can be done with it. The DrukteRadar Project ensures they have data sovereignty, so that they do not become technologically locked-in to relationships with private organisations. The Project Owner was aware that inaccurate of data may lead to discriminatory recommendations and harmful consequences. The DrukteRadar Project tries to minimise their algorithmic inaccuracy through extensive monitoring; secure technical infrastructure; and stakeholder review sessions. Another interesting finding was identifying how projects ensure privacy protection of its citizens. The DrukteRadar ensures that data is not traceable to individuals and the use of datasets follow privacy-by-design principles. The project also has strong security protocols, cyber-security measures, anonymization techniques, and repeated vulnerability tests. Overall, my report was able to evaluate how ethical issues found within the SIS literature correlate to those identified, and tackled, in practice. as well as highlighting the two additional concerns not explicitly mentioned in the literature.}
}
@article{ALMUHTADI2021102610,
title = {A lightweight cyber security framework with context-awareness for pervasive computing environments},
journal = {Sustainable Cities and Society},
volume = {66},
pages = {102610},
year = {2021},
issn = {2210-6707},
doi = {https://doi.org/10.1016/j.scs.2020.102610},
url = {https://www.sciencedirect.com/science/article/pii/S2210670720308271},
author = {Jalal Al-Muhtadi and Kashif Saleem and Sumayah Al-Rabiaah and Muhammad Imran and Amjad Gawanmeh and Joel J.P.C. Rodrigues},
keywords = {Context-aware, Cyber security, Data privacy, Internet of things, Pervasive computing, Smart environment, Sustainability},
abstract = {Internet of things (IoT) plays a key role in enabling smart sustainable cities. Pervasive computing over the IoT platform makes life more convenient by embedding sensors based on context-aware computing devices in the physical environment for the ubiquitous availability of computing resources. The sensors gather contextual information from the physical world and transmit it to receivers as per requirements or in case of environmental changes, such as temperature and humidity. However, the combination of dynamic operation and the need to handle sensitive and private data make the pervasive computing environment and IoT devices vulnerable to numerous attacks. Smart environments require a maximum level of safety assurance, such as trusted context producers and customers, which should protect sensitive information from exposure or monitoring. This paper discusses the major cyber threats in smart environments and proposes a novel lightweight security framework that authenticates and maintains the context providers and receivers. The cloud environment is adopted for user authentication at the user layer to implement access control and role assignment. Finally, the proposed security framework is implemented in the IBM cloud platform with six devices to evaluate its efficiency, sustainability, and secure communication.}
}
@article{IRANMANESH2021107265,
title = {A protocol for cluster confirmations of SDN controllers against DDoS attacks},
journal = {Computers & Electrical Engineering},
volume = {93},
pages = {107265},
year = {2021},
issn = {0045-7906},
doi = {https://doi.org/10.1016/j.compeleceng.2021.107265},
url = {https://www.sciencedirect.com/science/article/pii/S0045790621002482},
author = {Amir Iranmanesh and Hamid {Reza Naji}},
keywords = {Cluster Confirmations, DDoS, Genetic Algorithm, SDN},
abstract = {Software-Defined Networking (SDN) makes it easier to manage the network by separating the Data plane and Control plane, but these networks are susceptible to DDoS attacks. Most well-known algorithms for reducing the effects of DDoS attacks are based on SDN traffic analysis and prediction. Their main problems are false positive/negative results. Therefore, we propose PATGEN, a Protocol to reduce the effects of DDoS ATtacks using an advanced GENetic algorithm with optimized and new operators, thereby significantly reducing the effects of attacks and increasing the efficiency of the multi-controller SDN. Using the robust initial population procedure increases the convergence speed of the algorithm. Unlike other methods, PATGEN is possible without using external resources. Experimental results show that PATGEN increases the throughput and reduces the average delay compared to states of the art methods.}
}
@article{LI2018194,
title = {A quantitative relationship between Application Performance Metrics and Quality of Experience for Over-The-Top video},
journal = {Computer Networks},
volume = {142},
pages = {194-207},
year = {2018},
issn = {1389-1286},
doi = {https://doi.org/10.1016/j.comnet.2018.05.020},
url = {https://www.sciencedirect.com/science/article/pii/S1389128618302664},
author = {Weiwei Li and Petros Spachos and Mark Chignell and Alberto Leon-Garcia and Leon Zucherman and Jie Jiang},
keywords = {QoE, QoS, OTT video streaming, Machine learning},
abstract = {Quality of Experience (QoE) is a measure of the overall level of customer satisfaction with a vendor. In telecommunications, consumer satisfaction is of great interest in the adoption of novel multimedia products and services. A number of factors can greatly influence the customer experience during a video session. Factors such as user perception, experience, and expectations are expressed by QoE while factors such as application and network performance are expressed by Quality of Service (QoS) parameters. This paper studies the relationship between QoS and QoE in a session-based mobile video streaming. Specific QoS Application Performance Metrics (APMs) are examined based on a QoE assessment database which is built for experimentation and contains 108 subjects. It is shown that these APMs are highly related to two QoE factors, Technical Quality (TQ) and Acceptability. Furthermore, Viewing Ration (VR) parameter and the corresponding Kendall correlation between VR and QoE factors proves that VR is a valuable metric for mapping QoS to QoE. We further generated the compacted decision tree to predict QoE factors through Rebuffering Ratio (RR), Non-interruption Content Viewing Ratio (VRc), and Non-interruption Viewing Ratio (VRs). Through extensive experimentation, a general relationship between APMs and QoE factors has been examined and a primary QoE model is proposed based on this relationship.}
}
@article{KASNESIS2017412,
title = {Cognitive friendship and goal management for the social IoT},
journal = {Computers & Electrical Engineering},
volume = {58},
pages = {412-428},
year = {2017},
issn = {0045-7906},
doi = {https://doi.org/10.1016/j.compeleceng.2016.09.024},
url = {https://www.sciencedirect.com/science/article/pii/S0045790616303445},
author = {Panagiotis Kasnesis and Charalampos Z. Patrikakis and Dimitris Κogias and Lazaros Toumanidis and Iakovos S. Venieris},
keywords = {CIoT, Decision making, SIoT, Semantic web, Multi-agent systems},
abstract = {The concept of an Internet of Things is already mature, enough to start evolving towards an Internet of Everything, over which humans, objects and virtual items can be interconnected. For this to be feasible though, there is the need for a framework which not only supports the interconnection between the entities of this Internet, but also allows the meaningful interaction between them. In this paper, we present an idea on how this can be materialized, based on the use of semantic web technologies and smart software agents. These middleware technologies, combined with machine learning techniques, can lead to cognitive friendship and goal management. The paper includes a presentation of the theoretical framework, a use case scenario, and results over the use of a simulation tool.}
}
@article{YE2017246,
title = {Urban sound event classification based on local and global features aggregation},
journal = {Applied Acoustics},
volume = {117},
pages = {246-256},
year = {2017},
note = {Acoustics in Smart Cities},
issn = {0003-682X},
doi = {https://doi.org/10.1016/j.apacoust.2016.08.002},
url = {https://www.sciencedirect.com/science/article/pii/S0003682X16302274},
author = {Jiaxing Ye and Takumi Kobayashi and Masahiro Murakawa},
keywords = {Urban sound classification, Crowd-sourcing, Signal processing, Machine learning, Dictionary learning, Feature aggregation},
abstract = {The automatic content-based classification of complex and dynamic urban sound is an important aspect of various emerging applications, such as surveillance, urban soundscape understanding and noise source identification, therefore the research topic has gained a lot of attention in recent years. The aim of this paper is to develop efficient machine learning-based scheme for urban sound classification in real-life noise conditions. Unlike conventional sound event classification methods that mainly address local temporal-spectral patterns, we propose an aggregation scheme to combine both local and global acoustic features. For characterizing local patterns, we employ feature learning method to extract class-dependent temporal-spectral structures; on the other hand, long-term descriptive statistics are employed to exploit global features of sound events, e.g. variability and recurrence, which also carry rich discriminant information. In order to aggregate the heterogeneous acoustic information for classification, we introduce mixture of experts model (MoE) which effectively formulates relationship between local and global information. At validation stage, we conduct experiments on UrbanSound8K database which consists of 10 categories of urban sound events with 8732 real-world clips. It is noteworthy that the 10 classes of crowdsourced recordings, including air conditioner, car horn, children playing, dog bark, drilling, engine idling, gunshot, jackhammer, siren and street music, are most common urban sounds closely related to urban life. According to experimental results, the proposed scheme achieved superior performance compared with 3 other latest approaches and it can be a fundamental building block of various urban multimedia information processing systems that help to improve quality of life.}
}
@article{GUTIERREZTORRE2020103793,
title = {Improving maritime traffic emission estimations on missing data with CRBMs},
journal = {Engineering Applications of Artificial Intelligence},
volume = {94},
pages = {103793},
year = {2020},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2020.103793},
url = {https://www.sciencedirect.com/science/article/pii/S0952197620301822},
author = {Alberto Gutierrez-Torre and Josep Ll. Berral and David Buchaca and Marc Guevara and Albert Soret and David Carrera},
keywords = {Data cleaning, AIS, Emission modeling, CRBM, Ship time series, GPS},
abstract = {Maritime traffic emissions are a major concern to governments as they heavily impact the Air Quality in coastal cities. Ships use the Automatic Identification System (AIS) to continuously report position and speed among other features, and therefore this data is suitable to be used to estimate emissions, if it is combined with engine data. However, important ship features are often inaccurate or missing. State-of-the-art complex systems, like CALIOPE at the Barcelona Supercomputing Center, are used to model Air Quality. These systems can benefit from AIS based emission models as they are very precise in positioning the pollution. Unfortunately, these models are sensitive to missing or corrupted data, and therefore they need data curation techniques to significantly improve the estimation accuracy. In this work, we propose a methodology for treating ship data using Conditional Restricted Boltzmann Machines (CRBMs) plus machine learning methods to improve the quality of data passed to emission models that can also be applied to other GPS and time-series problems. Results show that we can improve the default methods proposed to cover missing data. In our results, we observed that using our method the models boosted their accuracy to detect otherwise undetectable emissions. In particular, we used a real data-set of AIS data, provided by the Spanish Port Authority, to estimate that thanks to our method, the model was able to detect 45% of additional emissions, representing 152 tonnes of pollutants per week in Barcelona and propose new features that may enhance emission modeling.}
}
@article{SOHAIBAJMAL2021101210,
title = {Cost-based Energy Efficient Scheduling Technique for Dynamic Voltage and Frequency Scaling System in cloud computing},
journal = {Sustainable Energy Technologies and Assessments},
volume = {45},
pages = {101210},
year = {2021},
issn = {2213-1388},
doi = {https://doi.org/10.1016/j.seta.2021.101210},
url = {https://www.sciencedirect.com/science/article/pii/S2213138821002204},
author = {Muhammad {Sohaib Ajmal} and Zeshan Iqbal and Farrukh {Zeeshan Khan} and Muhammad Bilal and Raja {Majid Mehmood}},
keywords = {Cloud computing, Energy efficiency, Resource allocation, Scheduling algorithm, SLA violations, Virtual server scaling},
abstract = {Cloud computing is used as a backbone infrastructure to meet exponentially increasing computational and storage demands. This increase in service demands in smart cities will result in escalating energy consumption in cloud datacenters. Such a rise in energy consumption will result in upsurge of operational costs and emission of greenhouse gases. In this work, a green cloud computing algorithm named “Cost-based Energy Efficient Scheduling Technique for Dynamic Volage Frequency Scaling (DVFS) Systems (CEEST)” is proposed. The proposed algorithm reduces energy consumption without compromising the quality of service (QoS). The goal of this algorithm is optimization and management of servers in the datacenters by utilizing maximum resources of the servers and powering off the underutilized servers. CEEST utilizes the scaling of virtual machines to finish jobs in the deadlines to reduce violations of service level agreement (SLA). Simulation results prove that the proposed algorithm outperforms the existing algorithms in terms of execution time, energy consumption, resource utilization, and SLA violations. The proposed algorithm saves energy up to 30% in comparison to existing algorithms. The utilization of resources is also significantly increased by to 30%. In terms of SLA violations, the proposed algorithm reduced SLA violations up to 50%.}
}
@article{PATEL2020105779,
title = {A state-of-the-art survey on recommendation system and prospective extensions},
journal = {Computers and Electronics in Agriculture},
volume = {178},
pages = {105779},
year = {2020},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2020.105779},
url = {https://www.sciencedirect.com/science/article/pii/S016816992031629X},
author = {Krupa Patel and Hiren B. Patel},
keywords = {Content-base, Collaborative filtering, Crop recommendation system, Recommendation algorithms, Agriculture},
abstract = {With the new era of the Internet, we have a large amount of data available in the form of ratings, reviews, graphs, images, etc. However, still, people face difficulty in finding useful information or knowledge from those data. To address these challenges, recommendation systems come into the picture by providing useful content to the user based on users’ history and similarity among users. Content-based and collaborative filtering are two major building blocks of recommendation systems. Recommendation systems have been applied into numbers of a domain such as recommending movies, music, course, literature, items, people, links, location, healthcare, agriculture. In the agriculture domain, appropriate crops to cultivate and selecting applicable pesticides based on land quality and types of crops are interesting factors to consider for a country like India. Initially, we review different types of recommendation systems along with its application area. Subsequently, we explore various parameters to evaluate recommendation systems followed by open issues and research challenges. We further study the work carried out by existing researchers in the said domain. As part of our contribution through this research, we have selected the Agriculture domain and proposed our algorithm for recommending crops based on various parameters. As an outcome of our contribution, a crop is recommended to farmers based on his land. Also, the system recommends a list of lands for a given crop. Using statistical analysis, we achieve accuracy from 93% to 97%.}
}
@article{YEVU2021129093,
title = {Digitalization of construction supply chain and procurement in the built environment: Emerging technologies and opportunities for sustainable processes},
journal = {Journal of Cleaner Production},
volume = {322},
pages = {129093},
year = {2021},
issn = {0959-6526},
doi = {https://doi.org/10.1016/j.jclepro.2021.129093},
url = {https://www.sciencedirect.com/science/article/pii/S0959652621032820},
author = {Sitsofe Kwame Yevu and Ann T.W. Yu and Amos Darko},
keywords = {Digitalization, Industry 4.0, Blockchain, Construction supply chain, Sustainability, Built environment},
abstract = {With rapid advances in digitalization, the application of digital technologies for supply chain and procurement processes have been advocated to facilitate revolutionary innovations in the built environment. Therefore, over the past decades, substantial research has been conducted on digital supply chain and procurement technologies (DCSP-technologies) in the built environment, resulting in a vast, fragmented and diverse body of knowledge. In this study, a comprehensive state-of-the-art research on DSCP-technologies in the built environment is presented through mixed review methods, to reveal knowledge areas that are needed to advance digitalization in construction supply chains. The science mapping analysis and qualitative discussions were used to provide insights into the research activities, challenges and opportunities regarding the digitalization of construction supply chains. Six themes including digital construction, digital integration concepts and security were identified, with blockchain-smart contracts being the most recent trend in construction supply chains. Further, future research opportunities including building information modeling (BIM) system integration, Industry 4.0 and emerging DSCP-technologies, cybersecurity and sustainability relationships with DCSP-technologies were provided. This study adds value to construction digitalization literature by providing the comprehensive picture of research explorations, and revealing the research needs essential for researchers and practitioners to develop and advance DSCP-technologies in a digitalized and sustainable built environment.}
}
@article{XING2021103332,
title = {Agricultural labor market equilibrium based on FPGA platform and IoT communication},
journal = {Microprocessors and Microsystems},
volume = {80},
pages = {103332},
year = {2021},
issn = {0141-9331},
doi = {https://doi.org/10.1016/j.micpro.2020.103332},
url = {https://www.sciencedirect.com/science/article/pii/S0141933120304919},
author = {Huang Xing and Li Xiaofeng},
keywords = {FPGA, Internet of Things (IoT), Agriculture market equilibrium, Economic analysis, Market agencies},
abstract = {Increasing food demand in terms of quality and quantity is the need for industrialization and strengthening the agricultural sector. IoT is an upcoming technology that offers many innovative solutions to modernize the agricultural sector. Scientific research institutes and scientific groups continue to work hard to provide solutions and products that use the Internet of Things to solve different issues of agriculture. FPGA-based IoT (Internet of thing) systems are preferred as a source of communication in agricultural labor market equilibrium systems, for balancing marketability and flexibility in the economic sector. In the agriculture labor market, labor can be taken and given as a commodity. Agriculture performs these labor market equilibrium in a different application of non-farm labor markets, often relying on intermediaries such as contractors to market groups of workers and relocating them to the farm, using piece-rate wage systems to encourage workers and employers cooperating with the labor market. The economic market analysis is guided, and monetary boundaries influence the low and high performance of enrollment. Market Equilibrium conditions have been created to clarify the roundabout impacts of changes in money owed to the utilization of provisions. Labor market equilibrium models show the immediate and roundabout impacts of yield power, yield value, input use, and benefit of the rural segment on yield and salary approaches.}
}
@article{TRIPATHI2021135,
title = {Resilience: Some Conceptual Considerations in the Case of AI},
journal = {Procedia Computer Science},
volume = {185},
pages = {135-143},
year = {2021},
note = {Big Data, IoT, and AI for a Smarter Future},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2021.05.015},
url = {https://www.sciencedirect.com/science/article/pii/S1877050921010954},
author = {Abhishek Tripathi and Shwetha Suresh and Parmeet Kaur},
keywords = {Resilience, pandemic management},
abstract = {The devastating impacts of coronavirus have recently shaken up the world. This pandemic has changed every individual’s life, forcing them to adapt to a new normal to survive the deadly disease. With these adjustments, technology has never been more needed than today to stay connected, stay productive, and receive important news. Though people are getting used to the new normal, it is essential to understand technology’s role. Resiliency is an important concept to look at during the pandemic. It is crucial to understand how technology has helped individuals, communities, and infrastructures become more resilient. The purpose of this paper is to gain a deeper understanding of resiliency through previous literature. Though resiliency has become a study over the years, it is relatively new in artificial intelligence (AI). By reviewing different resilient models and systems from preceding literature and their impact on various kinds of situations, there will be an understanding of the term resilience and how various frameworks and scales will help create a pandemic management model. Discussing how the various kinds of resilience have helped people and Infrastructure during the pandemic will allow researchers and other professionals to understand resiliency and prepare for future disturbances.}
}
@article{SANTOS2021103833,
title = {A systematic mapping study of robotics in human care},
journal = {Robotics and Autonomous Systems},
volume = {144},
pages = {103833},
year = {2021},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2021.103833},
url = {https://www.sciencedirect.com/science/article/pii/S0921889021001184},
author = {Nícolas B. Santos and Rodrigo S. Bavaresco and João E.R. Tavares and Gabriel de O. Ramos and Jorge L.V. Barbosa},
keywords = {Caregiver robot, Human caregiver, Assistive robot, Service robot, Cognitive impairment, Systematic mapping study},
abstract = {The World Health Organization (WHO) reported that more than 1 billion people live with some form of disability. Moreover, the number of elderly is increasing in recent years. According to the United Nations (UN), in 2050, there will be 2.1 billion people above 60 years of age worldwide. Many of these people live alone in their homes or clinics and rely on some kind of help to fulfill their specific needs. In this context, emerging opportunities for the application of robotics to support ubiquitous healthcare may reflect in reducing medical costs and increasing the convenience of patients and people in general. This paper presents a systematic mapping study to identify the application of service robots in the assistance of human care, focusing on the employment of computational technologies and unexplored research gaps in the literature. The study conducted searches in eight scientific repositories in the area of service robots through a systematic filtering process to remove bias. Afterward, the filtering process allowed to reduce from an initial sample of 9372 to 69 studies. As a result, these studies were reviewed entirely, analyzed, and categorized to answer six research questions. In addition, the study proposed four taxonomies illustrating the state-of-the-art of robotics in human care. The results highlight therapy and entertainment as the most common categories of the usage of robotics in human care. The most widely-used technologies to integrate with smart environments are smartphone sensors, smart device integration, wearables, and cloud services. The most frequently used mean of human–robot interaction is verbal communication, which is useful to help the elderly, children, and people with a mental health disorder. The most commonly cited diseases were cognition impairment, autism spectrum disorder, and motor impairment. Finally, we observed a trend in the growth of the use of service robots to improve the intelligence of the environment supporting human care. The scientific contribution of this article are four taxonomies that classify and group caregiver robots according to the application, integration with a smart environment, human–robot interaction, and target audience. This study also allowed the learning of 11 lessons on methodological and technological aspects based on the profound research performed.}
}
@article{TRASBERG2021101601,
title = {Using Wi-Fi probe requests from mobile phones to quantify the impact of pedestrian flows on retail turnover},
journal = {Computers, Environment and Urban Systems},
volume = {87},
pages = {101601},
year = {2021},
issn = {0198-9715},
doi = {https://doi.org/10.1016/j.compenvurbsys.2021.101601},
url = {https://www.sciencedirect.com/science/article/pii/S0198971521000089},
author = {Terje Trasberg and Balamurugan Soundararaj and James Cheshire},
keywords = {Human activity patterns, Wi-fi probe requests, Retail location analysis, Regression model},
abstract = {This paper discusses the opportunities afforded by novel population sensing technologies in the field of ‘smart’ urban management. In particular, it focuses on the application of these new sources of data in retail analysis. Our goal is to integrate data derived through novel pedestrian counting and point-of-sale systems to build a statistical model that captures the relationship between retail turnover and footfall in the UK. The point-of-sales data are provided by two UK-based food & beverage retailers. To accurately measure the pedestrian activity around retail units, we make use of the data generated by the SmartStreetSensor project: a deployment of a large network of sensors installed across 105 towns and cities in the UK that collect Wi-Fi probe requests generated by mobile devices. We propose and implement novel methods for processing these raw signals into accurate estimates of pedestrian activity without compromising participants' privacy. The resulting data is then integrated into seasonal ARIMA and dynamic regression models that can be used to predict future sales. Our results indicate that the dynamic regression model that accounts for fluctuations in footfall data outperforms seasonal ARIMA model that uses only past values and behaviours of transaction data to predict future sales. Thus, we conclude that footfall does have a strong impact on retail sales and therefore integrating footfall measures into sales forecasting can significantly improve the forecasting results. We also examine differences between the two retailers and observe a stronger correlation at the Fast Food Retailer locations compared to the correlation at Family Restaurant locations.}
}
@article{MAKKAR2019381,
title = {Cognitive spammer: A Framework for PageRank analysis with Split by Over-sampling and Train by Under-fitting},
journal = {Future Generation Computer Systems},
volume = {90},
pages = {381-404},
year = {2019},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2018.07.046},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X18305703},
author = {Aaisha Makkar and Neeraj Kumar},
keywords = {Internet of Things(IoT), Cognitive IoT, Web spam, PageRank},
abstract = {From the past few years, there is an exponential increase in one of the most popular technologies of the modern era called as Internet of Things (IoT). In IoT, various objects perform the tasks of sensing, communication, and computation for providing uninterrupted services (e.g., e-health, e-transportation, security access, etc.) to the end users. In this era, Cognitive Internet of Things (CIoT) is an another paradigm of IoT developed to enhance the capabilities of intelligence in IoT objects where these objects can take independent decisions in any environment. IoT follows the service oriented architecture (SOA), in which the application layer is the topmost layer. It enables the IoT objects to interact with the other objects located across the globe. The power of learning, thinking, and understanding by these objects, can make the information access more accurate and reliable but Web spam is one of the challenges while accessing information from the web. It has been observed from the literature review that search engines are preferred mostly by the people for accessing information. The efficient ranking by the search engines can reduce the computational cost of information exchange by IoT objects. Search engines should be able to prevent the spam from being injected into the web. But, the existing techniques for this problem target in finding the spam after its occurrence in search engine result pages. So, in this proposal, we present an intelligent cognitive spammer framework, Cognitive spammer, which eliminates the spam pages during the web page rank score calculation by search engines. The framework update the Google’s ranking algorithm, PageRank in such a way that it automatically prevents link spam by considering the link structure of web for rank score computation. The updated PageRank algorithm provided the better ranking of web pages. The proposed framework is validated with the WEBSPAM-UK2007 dataset. Before processing, the dataset is preprocessed with a new technique, called as ‘Split by Over-sampling and Train by Under-fitting’ to remove the trade off between imbalanced instances of target class. After data cleaning, we applied machine learning techniques (Bagged model, Boosted linear model, etc) with the web page features to make accurate predictions. The detection classifiers only consider the link features of the web page irrespective of the page content. Out of the fifteen classifiers, best three are ensemble, which results in better performance with overall accuracy improvement. Ten-fold cross validation has also been applied with the resulted ensemble model, which results in getting the accuracy of 99.6% in the proposed scheme.}
}
@article{HAN2020696,
title = {An effective approach to unmanned aerial vehicle navigation using visual topological map in outdoor and indoor environments},
journal = {Computer Communications},
volume = {150},
pages = {696-702},
year = {2020},
issn = {0140-3664},
doi = {https://doi.org/10.1016/j.comcom.2019.12.026},
url = {https://www.sciencedirect.com/science/article/pii/S0140366419307868},
author = {Tao Han and Jefferson S. Almeida and Suane Pires P. {da Silva} and Paulo Honório Filho and Antonio W. {de Oliveira Rodrigues} and Victor Hugo C. {de Albuquerque} and Pedro P. {Rebouças Filho}},
keywords = {Unmanned aerial vehicles, UAV navigation, Computer vision, Topological maps},
abstract = {Unmanned Aerial Vehicles are constantly being using in professional activities that require higher precision in navigating and positioning the aircraft during operation. Advanced location technologies such as Global Navigation Satellite System and Real-Time Kinematic are widely used, however, they depend on an area with transmission coverage. In this approach, this article presents a visual navigation methodology based on topological maps. We compared the performance of consolidated classifiers such as Bayesian classifier, k-nearest neighbor, Multilayer Perceptron, Optimal Path Forest and Support Vector Machines (SVM). They are evaluated with attributes returned by last generation resource extractors such as Fourier, Gray Level Co-Occurrence and Local Binary Patterns (LBP). After analyzing the results we found that the combination of LBP and SVM obtained the best values in the evaluation metrics considered, among them, 99.99% Specificity and 99.98% Precision in the navigation process. SVM reached 5.49787 s in combination with LBP completes the training in 5.49787 s. Concerning the testing time, SVM achieving 80.91 ms in association with LBP.}
}
@article{VARADHARAJAN2022105024,
title = {BASIN-3D: A brokering framework to integrate diverse environmental data},
journal = {Computers & Geosciences},
volume = {159},
pages = {105024},
year = {2022},
issn = {0098-3004},
doi = {https://doi.org/10.1016/j.cageo.2021.105024},
url = {https://www.sciencedirect.com/science/article/pii/S0098300421003058},
author = {Charuleka Varadharajan and Valerie C. Hendrix and Danielle S. Christianson and Madison Burrus and Catherine Wong and Susan S. Hubbard and Deborah A. Agarwal},
keywords = {Data integration, Multiscale diverse data, Synthesis, Environmental data},
abstract = {Diverse observational and simulation datasets are needed to understand and predict complex ecosystem behavior over seasonal to decadal and century time-scales. Integration of these datasets poses a major barrier towards advancing environmental science, particularly due to differences in the structure and formats of data provided by various sources. Here, we describe BASIN-3D (Broker for Assimilation, Synthesis and Integration of eNvironmental Diverse, Distributed Datasets), a data integration framework designed to dynamically retrieve and transform heterogeneous data from different sources into a common format to provide an integrated view. BASIN-3D enables users to adopt a standardized approach for data retrieval and avoid customizations for the data type or source. We demonstrate the value of BASIN-3D with two use cases that require integration of data from regional to watershed spatial scales. The first application uses the BASIN-3D Python library to integrate time-series hydrological and meteorological data to provide standardized inputs to analytical and machine learning codes in order to predict the impacts of hydrological disturbances on large river corridors of the United States. The second application uses the BASIN-3D Django framework to integrate diverse time-series data in a mountainous watershed in East River, Colorado, United States to enable scientific researchers to explore and download data through an interactive web portal. Thus, BASIN-3D can be used to support data integration for both web-based tools, as well as data analytics using Python scripting and extensions like Jupyter notebooks. The framework is expected to be transferable to and useful for many other field and modeling studies.}
}
@article{YANG2018124,
title = {Random Barzilai–Borwein step size for mini-batch algorithms},
journal = {Engineering Applications of Artificial Intelligence},
volume = {72},
pages = {124-135},
year = {2018},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2018.03.017},
url = {https://www.sciencedirect.com/science/article/pii/S0952197618300666},
author = {Zhuang Yang and Cheng Wang and Zhemin Zhang and Jonathan Li},
keywords = {Stochastic gradient descent, Mini batches, Barzilai–Borwein method, Variance reduction, Convex optimization},
abstract = {Mini-batch algorithms, a well-studied, highly popular approach in stochastic optimization methods, are used by practitioners because of their ability to accelerate training through better use of parallel processing power and reduction of stochastic variance. However, mini-batch algorithms often employ either a diminishing step size or a tuning step size by hand, which, in practice, can be time consuming. In this paper, we propose using the improved Barzilai–Borwein (BB) method to automatically compute step sizes for the state of the art mini-batch algorithm (mini-batch semi-stochastic gradient descent (mS2GD) method), which leads to a new algorithm: mS2GD-RBB. We theoretically prove that mS2GD-RBB converges with a linear convergence rate for strongly convex objective functions. To further validate the efficacy and scalability of the improved BB method, we introduce it into another modern mini-batch algorithm, Accelerated Mini-Batch Prox SVRG (Acc-Prox-SVRG) method. In a machine learning context, numerical experiments on three benchmark data sets indicate that the proposed methods outperform some advanced stochastic optimization methods.}
}
@article{PURSWANI2021,
title = {Examining and predicting land use change dynamics in Gandhinagar district, Gujarat, India},
journal = {Journal of Urban Management},
year = {2021},
issn = {2226-5856},
doi = {https://doi.org/10.1016/j.jum.2021.09.003},
url = {https://www.sciencedirect.com/science/article/pii/S2226585621001060},
author = {Ekta Purswani and Satyam Verma and S. Jayakumar and M.L. Khan and Bhawana Pathak},
keywords = {Urbanization, Land use change, Land change modeling, Remote sensing, Markov chain analysis},
abstract = {Urbanization is gaining pace worldwide and is the most elemental cause of global land transformation. This necessitates land use land cover change to be analyzed on various spatial and temporal scales to understand its potential impacts on the environment. This work focuses on the urbanization in the area of Gandhinagar district, Gujarat, India which encloses Gandhinagar, the capital city of Gujarat. Though a capital, the city has seen limited growth and development since its formation in 1961. Land use change was analyzed from 1995 to 2016 and land change modeling was attempted to generate future prediction scenarios in 2025 using the IDRISI TERRSET Land change modeler. The change analysis revealed vast growth in rural and urban built-up, majorly, at the expense of agriculture, slightly contributed by the decline in scrubland. There is much scope for urban densification as urban built-up occupies only about 5% of the total land cover as observed by the land use land cover map of 2016. The growth of the city has been very slow as compared to the other cities of its time due to a state-centric approach. But the projected scenario discovered a faster sprawl-like built-up growth towards the urban areas in the west and the south instead of an isodiametric aggregation around the capital city due to an arbitrary planning system. We recommend bringing all the talukas in Gandhinagar under one roof and considering the development of the whole district in scope for better policy and management.}
}
@article{HBAIEB2022108558,
title = {A survey of trust management in the Internet of Vehicles},
journal = {Computer Networks},
volume = {203},
pages = {108558},
year = {2022},
issn = {1389-1286},
doi = {https://doi.org/10.1016/j.comnet.2021.108558},
url = {https://www.sciencedirect.com/science/article/pii/S1389128621004758},
author = {Amal Hbaieb and Samiha Ayed and Lamia Chaari},
keywords = {Vehicular networks, VANET, IoV, V2X, Trust management, Security, Blockchain},
abstract = {In recent years, the emergence of the Internet of Vehicles (IoV) aims to enhance the users’ quality of experience through proposing more sophisticated services ranging from guaranteeing the user safety to improving his comfort. The IoV ecosystem is complex, heterogeneous, and evolving. Many entities participate to compose its architecture (such as vehicles, humans, roadside units, ITS). Moreover, different communication types co-exist to ensure the IoV connectivity and continuity. This diversity leads to new security requirements that seem more complex to take into account and enlarge the attack surface of such ecosystem. Many security mechanisms should be considered to enforce the security of IoV environment at many levels: data, entities, communications, storage, etc.. Trust management is one of the potential security mechanisms that aims to increase the reliability within the IoV environment. The topic has been widely explored within the vehicular ad hoc networks (VANETs). However, the VANET represents only one component of the IoV ecosystem. Thus, the approaches proposed for the VANET should be adapted to be applied for the IoV. Moreover, the advent of the emerging technologies like blockchain, cloud, SDN as well as artificial intelligence bring new opportunities to propose more relevant approaches within the trust management mechanisms within the IoV context. Accordingly, this survey deals with the literature about the trust management topic in vehicular environments. The scope considers the IoV environment as well as the relevant approaches proposed for the VANET context since it is one of the important component of the IoV ecosystem. We start by quickly reviewing the existing surveys about security of the vehicular environments. Then, we give a general overview about trust concepts. Afterwards, we present the security and trust challenges and attacks in the vehicular context. Later, we classify and compare the most relevant approaches related to the trust management for the IoV proposing a new taxonomy. We complete this survey by highlighting the open future directions and perspectives for research.}
}
@article{MAITRA20181171,
title = {Mining authentic student feedback for faculty using Naïve Bayes classifier},
journal = {Procedia Computer Science},
volume = {132},
pages = {1171-1183},
year = {2018},
note = {International Conference on Computational Intelligence and Data Science},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2018.05.032},
url = {https://www.sciencedirect.com/science/article/pii/S1877050918307646},
author = {Sandhya Maitra and Sushila Madan and Rekha Kandwal and Prerna Mahajan},
keywords = {Educational data mining, Machine learning, Naïve Bayes classifier, Higher education institution},
abstract = {The output of traditional analysis of student feedback for class room delivery of faculty suffers from inaccuracy due to non consideration of the influence of various direct and indirect quality features related to student such as regularity in class attendance, effort, academic background, course outcomes achieved and positive attitude on the feedback measure. Consequently, the output of traditional faculty feedback analysis is not a true indicator of faculty effectiveness in the teaching learning process. The paper presents a proactive and outcome based faculty feedback analysis model which uses Naïve Bayes Classifier to cull out and classify the feedback provided by each student into valid or invalid categories on the basis of the relative effect of aforementioned quality features on the feedback measure. The above quality features are used to refine the feedback measure. The method attempts to address the imprecision to overcome the limitations of the traditional model. Consequently, the output of faculty feedback analysis results in a more refined and accurate Faculty Effectiveness Index. The Faculty Effectiveness Index is calculated as weighted average of only the valid feedback measures with the validity of feedback taken as the associated weight. The classifier takes into consideration the independent contribution of each of the features as well as the multiple evidences of their occurrences in the feedback provided by each student. The method also suggests a comprehensive feedback form comprising of two parts namely subjective feedback part for eliciting feedback in traditional manner and an outcome based feedback part to collect information on the aforesaid quality features related to student which influence the feedback measure.}
}
@article{SCHMIDT2018742,
title = {Smart buildings as Cyber-Physical Systems: Data-driven predictive control strategies for energy efficiency},
journal = {Renewable and Sustainable Energy Reviews},
volume = {90},
pages = {742-756},
year = {2018},
issn = {1364-0321},
doi = {https://doi.org/10.1016/j.rser.2018.04.013},
url = {https://www.sciencedirect.com/science/article/pii/S1364032118302211},
author = {Mischa Schmidt and Christer Åhlund},
keywords = {Energy efficiency, Predictive control, Cyber-Physical System, Existing buildings},
abstract = {Due to its significant contribution to global energy usage and the associated greenhouse gas emissions, existing building stock's energy efficiency must improve. Predictive building control promises to contribute to that by increasing the efficiency of building operations. Predictive control complements other means to increase performance such as refurbishments as well as modernizations of systems. This survey reviews recent works and contextualizes these with the current state of the art of interrelated topics in data handling, building automation, distributed control, and semantics. The comprehensive overview leads to seven research questions guiding future research directions.}
}
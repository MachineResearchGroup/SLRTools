@article{SABERIOON2020106236,
title = {Chlorophyll-a and total suspended solids retrieval and mapping using Sentinel-2A and machine learning for inland waters},
journal = {Ecological Indicators},
volume = {113},
pages = {106236},
year = {2020},
issn = {1470-160X},
doi = {https://doi.org/10.1016/j.ecolind.2020.106236},
url = {https://www.sciencedirect.com/science/article/pii/S1470160X20301734},
author = {Mohammadmehdi Saberioon and Jakub Brom and Václav Nedbal and Pavel Souc̆ek and Petr Císar̆},
keywords = {Water quality, Small inland waters, Cubist modelling, Remote sensing, Monitoring, Fish ponds},
abstract = {Chlorophyll-a (Chl-a) and Total Suspended Solids (TSS) are both key indicators of the biophysical status of inland waters, and their continued monitoring is essential. Existing conventional methods (e.g., in situ monitoring) have shown that they are impractical due to their time and space limitations. The recently operated Sentinel-2A satellite offers the potential to have higher temporal, spatial, and spectral resolution images with no cost for monitoring water quality parameters of inland waters. The main aim of this study was to develop a semi-empirical model for predicting water quality parameters by combining Sentinel-2A data and machine learning methods using samples collected from several water reservoirs within the southern part of the Czech Republic, Central Europe. A combination of 10 spectral bands of the Sentinel-2A and 19 spectral indices, as independent variables, were used to train prediction models (i.e., Cubist) and then produce spatial distribution maps for both Chl-a and TSS. The results showed that the prediction accuracy based on Sentinel-2A was adequate for both Chl-a (R2=0.85,RMSEp=48.57) and TSS (R2=0.80,RMSEp=19.55). The spatial distribution maps derived from Sentinel-2A performed well where Chl-a and TSS were relatively high. The temporal changes in both Chl-a and TSS could be seen in the distribution maps. The temporal changes are showing that The values of TSS dramatically changed in fishponds compared to sand lakes over time which might be due to indifferent management practices. Overall, it can be concluded that Sentinel-2A, when coupled with machine learning algorithms, could be employed as a reliable, inexpensive, and accurate instrument for monitoring the biophysical status of small inland waters like fishponds and sandpit lakes.}
}
@article{LI2020105174,
title = {Crop pest recognition in natural scenes using convolutional neural networks},
journal = {Computers and Electronics in Agriculture},
volume = {169},
pages = {105174},
year = {2020},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2019.105174},
url = {https://www.sciencedirect.com/science/article/pii/S0168169919313638},
author = {Yanfen Li and Hanxiang Wang and L. Minh Dang and Abolghasem Sadeghi-Niaraki and Hyeonjoon Moon},
keywords = {Pest classification, CNN, Deep learning, GoogLeNet, Crop, Natural scenes},
abstract = {Crop diseases and insect pests are major agricultural problems worldwide, because the severity and extent of their occurrence causes significant crop losses. In addition, traditional crop pests recognition methods are limited, ineffective, and time-consuming due to the manual selection of the useful feature sets. This paper introduces a crop pest recognition method that accurately recognizes ten common species of crop pests by applying several deep convolutional neural networks (CNNs). The main contributions of this paper are (1) a manually collected and validated crop pest dataset is described and shared; (2) a fine-tuned GoogLeNet model is proposed to deal with the complicated backgrounds presented by farmland scenes, with pest classification results better than the original model; and (3) the fine-tuned GoogLeNet model obtains an improvement of 6.22% compared to the state-of-the-art method. As a result, the proposed model has the potential to be applied in real-world applications and further motivate research on crop disease identification.}
}
@article{ZHANG2021107590,
title = {Learning modulation filter networks for weak signal detection in noise},
journal = {Pattern Recognition},
volume = {109},
pages = {107590},
year = {2021},
issn = {0031-3203},
doi = {https://doi.org/10.1016/j.patcog.2020.107590},
url = {https://www.sciencedirect.com/science/article/pii/S0031320320303939},
author = {Duona Zhang and Wenrui Ding and Baochang Zhang and Chunhui Liu and Jungong Han and David Doermann},
keywords = {Weak signal detection, Filter learning, Attention, Modulation classification, Wireless communication},
abstract = {Weak signal detection is a challenging yet significant problem in the field of radio communication. Although hand-crafted filters are widely used in signal processing, they are challenged by the weak signal detection task with unknown background noise especially in the range of 0-5dB. In this paper, we propose the learning modulation filter networks (LMFNs) to improve the detection performance. The approach is based on a two-stage optimization scheme which addresses filter learning, attention mechanism and classification in a unified framework. Modulation filters are built to enhance the capacity of the learned filters, and the attention mechanism further characterizes the saliency properties of the input signal. LMFNs reduce the storage size of the network while achieving the state-of-the-art performance by a significant margin compared to traditional cognitive radio approaches. We establish a weak signal dataset that contains unmanned aerial vehicle (UAV) communication signals in a real-terrain environment. The source code and dataset will be made publicly available soon.}
}
@article{MESSOUS2017393,
title = {Implementing an emerging mobility model for a fleet of UAVs based on a fuzzy logic inference system},
journal = {Pervasive and Mobile Computing},
volume = {42},
pages = {393-410},
year = {2017},
issn = {1574-1192},
doi = {https://doi.org/10.1016/j.pmcj.2017.06.007},
url = {https://www.sciencedirect.com/science/article/pii/S1574119216302565},
author = {Mohamed-Ayoub Messous and Hichem Sedjelmaci and Sidi-Mohammed Senouci},
keywords = {Mobile and distributed computing, Emerging mobility model, Unmanned Aerial Vehicles, Fuzzy Inference System},
abstract = {In this paper, we design and implement a novel generic mobility model, named Alpha-based, for a fleet of small interconnected UAVs (Unmanned Aerial Vehicles) that collaborate to explore a geographic area (battle field, research and rescue missions, surveillance applications, etc.). In fact, due to the significant impact of mobility models on the networking performance, the mobility models must realistically capture the UAV’s attributes. Hence, we propose to use a combination of energy level, coverage-area and network connectivity for mobility decision-making, in contrast to the literature where only network connectivity and area coverage are investigated. On the one hand, these two metrics are very important, especially for applications where achieving the best area-coverage and maintaining network connectivity represent an essential requirement. On the other hand, energy is another equally noteworthy constraint that should be taken into account. In fact, being a crucial resource for all mobile devices and especially for UAVs, the energy becomes vital to ensure the network lifetime and mission success. As far as we know, Alpha-based mobility model is the first to ever consider a combination of these three metrics within the same decision-making criterion. A distributed scheme is adopted, where each UAV determines locally its future movement based on the information it receives from its neighbors. Moreover, a novel fuzzy inference system is implemented in order to compute the values of a followship weighting parameter, named Alpha. This latter is used to choose the most suitable neighboring UAV to follow. To validate the proposed mobility model, rigorous testing has been accomplished, through simulation work. Compared to Random-based and Forces-based mobility models, the Alpha-based mobility model achieves good coverage rate while maintaining connectivity.}
}
@article{ZHAO2019224,
title = {Comparison of machine learning algorithms for forest parameter estimations and application for forest quality assessments},
journal = {Forest Ecology and Management},
volume = {434},
pages = {224-234},
year = {2019},
issn = {0378-1127},
doi = {https://doi.org/10.1016/j.foreco.2018.12.019},
url = {https://www.sciencedirect.com/science/article/pii/S0378112718316414},
author = {Qingxia Zhao and Shichuan Yu and Fei Zhao and Linghong Tian and Zhong Zhao},
keywords = {Machine learning algorithms (MLAs), Forest parameter estimations, Forest quality (FQ), Black locust ()},
abstract = {Forest parameters have been estimated using various regression methods based on satellite data. However, there are a few concerns regarding further application of these predicted parameters. Current forest quality (FQ) assessments are mainly based on forest parameters collected in the field. To evaluate FQ quickly and comprehensively, forest parameters estimated from satellite images can be used. Black locust (Robinia pseudoacacia) plantations have experienced increases in tree mortality and reductions in tree growth caused by human destruction and poor natural conditions on the Loess Plateau. Assessing the FQ of the black locust plantations in these areas is critical. In this study, four machine learning algorithms (MLAs) – classification and regression tree (CART), support vector machine (SVM), artificial neural network (ANN) and random forest (RF) – were first implemented and compared regarding their ability to estimate forest parameters of black locust plantations on the Loess Plateau. The results indicated that among the four MLAs, the CART method achieved the lowest accuracy, the SVM and ANN methods had moderate performances, and the RF obtained the highest accuracy and lowest error for all forest parameter estimates. As a result, the RF algorithm was chosen to predict the forest parameters. The highest R2 values among the forest parameters were predicted for the diameter at breast height (DBH, R2 = 0.85 and relative root mean square error (rRMSE) = 0.18), and the lowest R2 values were predicted for the forest aboveground biomass (AGB, R2 = 0.66 and rRMSE = 0.25). These predicted forest parameters as well as the topographic factors derived from a digital elevation model (DEM) were used to assess the FQ of the study area. Among the four stand age classes, the middle-aged forest had the lowest proportion of poor quality forests (7%) and the highest proportion of good quality forests (52%), whereas overmature forests presented a moderate proportion of poor quality forests (23%) and good quality forests (21%). These results provide the necessary foundation for forest management and guidance for regional reforestation on the Loess Plateau.}
}
@article{GU2019105066,
title = {Early detection of tomato spotted wilt virus infection in tobacco using the hyperspectral imaging technique and machine learning algorithms},
journal = {Computers and Electronics in Agriculture},
volume = {167},
pages = {105066},
year = {2019},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2019.105066},
url = {https://www.sciencedirect.com/science/article/pii/S0168169919304089},
author = {Qing Gu and Li Sheng and Tianhao Zhang and Yuwen Lu and Zhijun Zhang and Kefeng Zheng and Hao Hu and Hongkui Zhou},
keywords = {Tobacco plants, Tomato spotted wilt virus, Presymptomatic detection, Hyperspectral imaging, Machine learning},
abstract = {The hyperspectral imaging technique was used for the non-destructive detection of tomato spotted wilt virus (TSWV) infection in tobacco at an early stage. Spectra ranging from 400 to 1000 nm with 128 bands from inoculated and healthy tobacco plants were analyzed by using three wavelength selection methods (successive projections algorithm (SPA), boosted regression tree (BRT), and genetic algorithm (GA)), and four machine learning (ML) techniques (boosted regression tree (BRT), support vector machine (SVM), random forest (RF), and classification and regression tress (CART)). The results indicated that the models built by the BRT algorithm using the wavelengths selected by SPA as the input variables obtained the best outcome for the 10-fold cross-validation with the mean overall accuracy of 85.2% and area under receiver operating curve (AUC) of 0.932. The band selection results and variable contribution analysis in BRT modeling jointly showed that the near-infrared (NIR) spectral region is informative and important for the differentiation of infected and healthy tobacco leaves. Different stages of post-inoculation were split according to the molecular identification and visual observation. The classification results at different stages indicated that the hyperspectral imaging data combined with ML methods and wavelength selection algorithms can be used for the early detection of TSWV in tobacco, both at the presymptomatic stage and during the period before the systematic infection can be detected by the molecular identification approach.}
}
@article{MU20196946,
title = {Q-learning solution for optimal consensus control of discrete-time multiagent systems using reinforcement learning},
journal = {Journal of the Franklin Institute},
volume = {356},
number = {13},
pages = {6946-6967},
year = {2019},
issn = {0016-0032},
doi = {https://doi.org/10.1016/j.jfranklin.2019.06.007},
url = {https://www.sciencedirect.com/science/article/pii/S0016003219304375},
author = {Chaoxu Mu and Qian Zhao and Zhongke Gao and Changyin Sun},
abstract = {This paper investigates a Q-learning scheme for the optimal consensus control of discrete-time multiagent systems. The Q-learning algorithm is conducted by reinforcement learning (RL) using system data instead of system dynamics information. In the multiagent systems, the agents are interacted with each other and at least one agent can communicate with the leader directly, which is described by an algebraic graph structure. The objective is to make all the agents achieve synchronization with leader and make the performance indices reach Nash equilibrium. On one hand, the solutions of the optimal consensus control for multiagent systems are acquired by solving the coupled Hamilton–Jacobi–Bellman (HJB) equation. However, it is difficult to get analytical solutions directly of the discrete-time HJB equation. On the other hand, accurate mathematical models of most systems in real world are hard to be obtained. To overcome these difficulties, Q-learning algorithm is developed using system data rather than the accurate system model. We formulate performance index and corresponding Bellman equation of each agent i. Then, the Q-function Bellman equation is acquired on the basis of Q-function. Policy iteration is adopted to calculate the optimal control iteratively, and least square (LS) method is employed to motivate the implementation process. Stability analysis of proposed Q-learning algorithm for multiagent systems by policy iteration is given. Two simulation examples are experimented to verify the effectiveness of the proposed scheme.}
}
@article{CHOI201410,
title = {UAV guidance using a monocular-vision sensor for aerial target tracking},
journal = {Control Engineering Practice},
volume = {22},
pages = {10-19},
year = {2014},
issn = {0967-0661},
doi = {https://doi.org/10.1016/j.conengprac.2013.09.006},
url = {https://www.sciencedirect.com/science/article/pii/S0967066113001743},
author = {Hyunjin Choi and Youdan Kim},
keywords = {Unmanned aerial vehicle, Target tracking, Monocular-vision sensor, Nonlinear adaptive observer},
abstract = {Target tracking is difficult for a Unmanned Aerial Vehicle (UAV) equipped with a monocular-vision sensor because the sensor cannot measure the range between aerial target and UAV. Since the range between UAV and target is unobservable, the target position is also unknown. A measurement model of the vision sensor is proposed based on a specific image processing technique. A nonlinear adaptive observer is designed to estimate states and parameters, and the position of the target is estimated. A guidance law for target tracking and UAV maneuvers for persistent excitation condition are also proposed. To demonstrate the effectiveness of the proposed algorithms, numerical simulations are performed.}
}
@article{KOCER2018455,
title = {Centralized predictive ceiling interaction control of quadrotor VTOL UAV},
journal = {Aerospace Science and Technology},
volume = {76},
pages = {455-465},
year = {2018},
issn = {1270-9638},
doi = {https://doi.org/10.1016/j.ast.2018.02.020},
url = {https://www.sciencedirect.com/science/article/pii/S1270963817315572},
author = {Basaran Bahadir Kocer and Tegoeh Tjahjowidodo and Gerald Gim Lee Seet},
keywords = {Unmanned aerial vehicles, Identification, Unscented Kalman filter, Model predictive control, Quadrotor, Interaction control},
abstract = {Unmanned aerial vehicle (UAV) applications have become increasingly vital, especially when human operators have limited access to the mission such as an inspection of a deep sewerage tunnel system. The problem arises when the UAV is deployed to perform a pre-defined operation, particularly in close proximity to the environment. When the UAV flies within a few centimeters away from its surrounding environment, the ceiling effect problem might occur, which will affect the flight performance. This paper presents the utilization of a centralized predictive interaction control by leveraging an identified nonlinear model of a quadrotor UAV to mitigate the problem. In the first step, real-time data is collected for translational states of the system to identify its aerodynamic parameters. Secondly, a centralized predictive controller is applied to the system in real–time to compensate for the ceiling effect. Finally, the proposed approach is validated numerically and experimentally in free-flight and ceiling interaction phases. The results show that the optimization-based controller with a centralized algorithm is able to converge within 5 ms.}
}
@article{MADEC2019225,
title = {Ear density estimation from high resolution RGB imagery using deep learning technique},
journal = {Agricultural and Forest Meteorology},
volume = {264},
pages = {225-234},
year = {2019},
issn = {0168-1923},
doi = {https://doi.org/10.1016/j.agrformet.2018.10.013},
url = {https://www.sciencedirect.com/science/article/pii/S016819231830337X},
author = {Simon Madec and Xiuliang Jin and Hao Lu and Benoit {De Solan} and Shouyang Liu and Florent Duyme and Emmanuelle Heritier and Frédéric Baret},
keywords = {Wheat ear density, Object detection, Object counting, Convolutional neural networks, Phenotyping, Broad-sense heritability},
abstract = {Wheat ear density estimation is an appealing trait for plant breeders. Current manual counting is tedious and inefficient. In this study we investigated the potential of convolutional neural networks (CNNs) to provide accurate ear density using nadir high spatial resolution RGB images. Two different approaches were investigated, either using the Faster-RCNN state-of-the-art object detector or with the TasselNet local count regression network. Both approaches performed very well (rRMSE≈6%) when applied over the same conditions as those prevailing for the calibration of the models. However, Faster-RCNN was more robust when applied to a dataset acquired at a later stage with ears and background showing a different aspect because of the higher maturity of the plants. Optimal spatial resolution for Faster-RCNN was around 0.3 mm allowing to acquire RGB images from a UAV platform for high-throughput phenotyping of large experiments. Comparison of the estimated ear density with in-situ manual counting shows reasonable agreement considering the relatively small sampling area used for both methods. Faster-RCNN and in-situ counting had high and similar heritability (H²≈85%), demonstrating that ear density derived from high resolution RGB imagery could replace the traditional counting method.}
}
@article{YANG2021,
title = {Concrete crack segmentation based on UAV-enabled edge computing},
journal = {Neurocomputing},
year = {2021},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2021.03.139},
url = {https://www.sciencedirect.com/science/article/pii/S0925231221016362},
author = {Jianxi Yang and Hao Li and Junzhi Zou and Shixin Jiang and Ren Li and Xinlong Liu},
keywords = {Edge computing, UAV, Concrete crack, Semantic segmentation, Multiscale convolution features},
abstract = {In recent years, the rapid development of UAV technology has greatly improved the efficiency of the detection of concrete bridge cracks. With the increase in the number of bridge inspection UAVs, the number of tasks handled by cloud services has increased linearly, resulting in increased computational pressure on cloud services. In order to reduce the computational load of cloud servers, we proposed a crack segmentation network based on UAV-enabled edge computing. However, due to the limitation of computational capability of edge computing and the strength inhomogeneity and background complexity of cracks, crack detection is still a challenging task. Thus, we proposed an effective concrete crack segmentation network based on UAV-enabled edge computing, the network used feature map fusion to fuse different levels of feature map information into lower-level features for crack detection. The atrous spatial pyramid pooling network was used to increase the low-resolution feature map receptive field information for cracks and to enhance the detection accuracy for cracks of different scales. In addition, loss functions for crack datasets were proposed to solve the problem of imbalance due to positive and negative samples in the concrete crack images. Experiments demonstrated that the proposed methods are better than the state-of-the-art edge detection and semantic segmentation methods in terms of accuracy and generality.}
}
@article{SARKAR2021103848,
title = {A novel search and survey technique for unmanned aerial systems in detecting and estimating the area for wildfires},
journal = {Robotics and Autonomous Systems},
volume = {145},
pages = {103848},
year = {2021},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2021.103848},
url = {https://www.sciencedirect.com/science/article/pii/S0921889021001330},
author = {Mrinmoy Sarkar and Xuyang Yan and Berat A. Erol and Ioannis Raptis and Abdollah Homaifar},
keywords = {UAV, Multi-agent autonomous system, AMASE, Search & survey, Collaborative operation, Robotics},
abstract = {In recent years Unmanned Aerial Vehicles (UAVs) have progressively been utilized for wildfire management, and are especially in prevalent in forest fire monitoring missions. To ensure the fast detection and accurate area estimation of forest fires, a two-step search and survey algorithm for multi-UAV system is proposed to address these fire scenarios. Initially, a grid-based partition method is applied to divide the area-of-interest into several search areas. Then, an archetype search pattern is used to provide timely UAV exploration within those sub-areas. Once the fire zones are detected, a novel survey strategy is employed for UAVs to discover the boundary points of the fire zones, so that the area of the fire zones can be estimated using the sampled boundary points. In addition, the effect of wind is accounted for improving fire zone boundary estimates. The proposed search-and-survey procedure is validated on multiple simulated scenarios using the U.S. Air Force’s mission-realistic Aerospace Multi-Agent Simulation Environment (AMASE) software. Simulation results showcase that the proposed search pattern can effectively discover the seeded fire zones within 40 min of the mission. This is relatively faster than the other two well-known search patterns. Moreover, the proposed survey technique provides a coverage estimate with at least 85% accuracy for the area of interest within 90 min of the mission.}
}
@article{SANTOS2020105247,
title = {Grape detection, segmentation, and tracking using deep neural networks and three-dimensional association},
journal = {Computers and Electronics in Agriculture},
volume = {170},
pages = {105247},
year = {2020},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2020.105247},
url = {https://www.sciencedirect.com/science/article/pii/S0168169919315765},
author = {Thiago T. Santos and Leonardo L. {de Souza} and Andreza A. {dos Santos} and Sandra Avila},
keywords = {Fruit detection, Yield prediction, Computer vision, Deep learning},
abstract = {Agricultural applications such as yield prediction, precision agriculture and automated harvesting need systems able to infer the crop state from low-cost sensing devices. Proximal sensing using affordable cameras combined with computer vision has seen a promising alternative, strengthened after the advent of convolutional neural networks (CNNs) as an alternative for challenging pattern recognition problems in natural images. Considering fruit growing monitoring and automation, a fundamental problem is the detection, segmentation and counting of individual fruits in orchards. Here we show that for wine grapes, a crop presenting large variability in shape, color, size and compactness, grape clusters can be successfully detected, segmented and tracked using state-of-the-art CNNs. In a test set containing 408 grape clusters from images taken on a trellis-system based vineyard, we have reached an F1-score up to 0.91 for instance segmentation, a fine separation of each cluster from other structures in the image that allows a more accurate assessment of fruit size and shape. We have also shown as clusters can be identified and tracked along video sequences recording orchard rows. We also present a public dataset containing grape clusters properly annotated in 300 images and a novel annotation methodology for segmentation of complex objects in natural images. The presented pipeline for annotation, training, evaluation and tracking of agricultural patterns in images can be replicated for different crops and production systems. It can be employed in the development of sensing components for several agricultural and environmental applications.}
}
@article{CHEN20217170,
title = {Distributed consensus control of periodically time-varying multi-agent systems using neural networks and fourier series expansion},
journal = {Journal of the Franklin Institute},
volume = {358},
number = {14},
pages = {7170-7186},
year = {2021},
issn = {0016-0032},
doi = {https://doi.org/10.1016/j.jfranklin.2021.07.002},
url = {https://www.sciencedirect.com/science/article/pii/S0016003221003938},
author = {Jiaxi Chen and Junmin Li},
abstract = {This paper studies the consensus of nonlinear multi-agent systems with periodic disturbances and uncertain dynamics based on matrix theory, adaptive control, neural networks and fourier series expansion. Firstly, fourier series expansion and neural networks are used to describe the unknown periodic time-varying parameter and uncertain nonlinear dynamic, respectively. Secondly, based on adaptive control technology and reparameterization method, two new fully distributed control protocols are designed based on symbolic function and smooth hyperbolic tangent function, respectively, so that all agents can reach asymptotic consensus. Thirdly, a new positive integral bounded function is introduced to compensate for the approximation error caused by the smooth hyperbolic tangent function instead of the symbolic function, so that all network nodes achieve the same consensus effect. Finally, a simulation example is given to verify the effectiveness of the two algorithms and to illustrate their advantages and disadvantages.}
}
@article{LABBADI2019105306,
title = {Robust adaptive backstepping fast terminal sliding mode controller for uncertain quadrotor UAV},
journal = {Aerospace Science and Technology},
volume = {93},
pages = {105306},
year = {2019},
issn = {1270-9638},
doi = {https://doi.org/10.1016/j.ast.2019.105306},
url = {https://www.sciencedirect.com/science/article/pii/S1270963819300318},
author = {Moussa Labbadi and Mohamed Cherkaoui},
keywords = {Quadrotor unmanned aerial vehicle (UAV), Fast terminal sliding mode controller, Robust control, Backstepping, Adaptive laws, Uncertainties and Disturbances},
abstract = {The problem of controlling the quadrotor orientation and position is considered in the presence of parametric uncertainties and external disturbances. Previous works generally assume that the flight controller parameters are constants. In reality, these parameters depend on the desired trajectory. In this article, a complete mathematical model of a quadrotor UAV is presented based on the Euler-Newton formulation. A robust nonlinear fast control structured for the quadrotor position and attitude trajectory tracking is designed. The position loop generates the actual thrust to control the altitude of the quadrotor and provides the desired pitch and roll angles to the attitude loop, which allow the control of the quadrotor center of gravity in the horizontal plane. The attitude loop generates the rolling, pitching and yawing torques that easily allow the insurance of the quadrotors stability. The outer loop (position loop) uses the robust adaptive backstepping (AB) control to get the desired Euler-angles and the control laws. The inner loop (attitude loop) employs a new controller based on a combination of backstepping technique and fast terminal sliding mode control (AB-ABFTSMC) to command the yaw angle and the tilting angles. In order to estimate the proposed controller parameters of the position and the upper bounds of the uncertainties and disturbances of the attitude, online adaptive rules are proposed. Furthermore, the Lyapunov analysis is used to warranty the stability of the quadrotor UAV system and to ensure the robustness of the controllers against variation. Finally, different simulations were performed in the MATLAB environment to show the efficiency of the suggested controller. The sovereignty of the proposed controller is highlighted by comparing its performance with various approaches such as classical sliding mode control, integral backstepping and second order sliding mode controls.}
}
@article{CONGRESS202134,
title = {Identifying hazardous obstructions within an intersection using unmanned aerial data analysis},
journal = {International Journal of Transportation Science and Technology},
volume = {10},
number = {1},
pages = {34-48},
year = {2021},
issn = {2046-0430},
doi = {https://doi.org/10.1016/j.ijtst.2020.05.004},
url = {https://www.sciencedirect.com/science/article/pii/S2046043020300411},
author = {Surya Sarat Chandra Congress and Anand J. Puppala and Aritra Banerjee and Ujwalkumar D. Patil},
keywords = {Unmanned aerial vehicle, Traffic safety, Obstructions, Intersections, Railroad safety},
abstract = {Intersections are places where two or more roadways intersect with one another. Federal Highway Administration (FHWA) quoted that more than fifty percent of crashes occur at or near intersections. An at-grade intersection is more accident prone compared to grade separated intersections. Intersection-related crashes are almost 335-times more likely to occur as compared to non-intersection-related crashes caused by vehicles turned with obstructed views. Approach and departure sight triangles are two types of sight triangles that are considered to provide clear visibility for drivers entering and exiting an intersection. Presently, there is no common practice followed by transportation or public work agencies other than considering accident history and public complaints as indicators for the need to improve intersection conditions. This approach warrants a safe and rapid methodology that can effectively identify obstructions within the intersection sight triangles. Unmanned aerial vehicles coupled with close range photogrammetry (UAV-CRP) technology offers a safe, quick, and efficient alternative for obstruction identification compared to traditional methods. In this study, a UAV based methodology is developed to identify obstructions in intersections from the 3-dimensional models developed using the imagery collected from unmanned aerial surveys. Two case studies including a T-intersection and a railroad crossing were considered to demonstrate the developed methodology. This research successfully validated the developed UAV methodology by analyzing departure sight triangles at T-intersection and approach sight triangles at railroad crossing. It is expected to be applied in many other civil engineering applications that are deemed critical due to the presence of obstructions and can potentially save human lives.}
}
@article{YANG202148,
title = {AEVRNet: Adaptive exploration network with variance reduced optimization for visual tracking},
journal = {Neurocomputing},
volume = {449},
pages = {48-60},
year = {2021},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2021.03.118},
url = {https://www.sciencedirect.com/science/article/pii/S0925231221005105},
author = {Yuxiang Yang and Weiwei Xing and Dongdong Wang and Shunli Zhang and Qi Yu and Liqiang Wang},
keywords = {Object tracking, Convolutional neural network, Reinforcement learning, Policy gradient, Adaptive exploration},
abstract = {For visual tracking methods based on reinforcement learning, action space determines the ability of exploration, which is crucial to model robustness. However, most trackers adopted simple strategies with action space, which will suffer local optima problem. To address this issue, a novel reinforcement learning based tracker called AEVRNet is proposed with non-convex optimization and effective action space exploration. Firstly, inspired by combinatorial upper confidence bound, we design an adaptive exploration strategy leveraging temporal and spatial knowledge to enhance effective action exploration and jump out of local optima. Secondly, we define the tracking problem as a non-convex problem and incorporate non-convex optimization in stochastic variance reduced gradient as backward propagation of our model, which can converge faster with lower loss. Thirdly, different from existing reinforcement learning based trackers using classification method to train model, we define a regression based action-reward loss function, which is more sensitive to aspects of the target states, e.g., the width and height of the target to further improve robustness. Extensive experiments on six benchmark datasets demonstrate that our proposed AEVRNet achieves favorable performance against the state-of-the-art reinforcement learning based methods.}
}
@article{ZHANG2015401,
title = {MLP technique based reinforcement learning control of discrete pure-feedback systems},
journal = {Neurocomputing},
volume = {168},
pages = {401-407},
year = {2015},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2015.05.087},
url = {https://www.sciencedirect.com/science/article/pii/S0925231215007857},
author = {Yu Zhang and Shixing Wang},
keywords = {Approximate dynamic programming, Discrete-time, Pure-feedback system, Minimal-learning-parameter},
abstract = {The reinforcement learning control with neural networks (NNs) is investigated for a class of pure-feedback systems in discrete time using minimal-learning-parameter (MLP) technique. To make the dynamics feasible for controller design, the nth order system is transformed into the prediction model. By selecting the “strategic” utility function including the future performance, the critic NN is designed. The action NN is employed to minimize both the strategic utility function and the tracking error. A radial basis function (RBF) NN is employed to approximate the unknown control with the MLP technique which greatly reduces the number of the online adaptive parameters. The uniformly ultimate boundedness (UUB) of the closed-loop tracking error is guaranteed. The feasibility of the proposed controller is verified by a simulation example.}
}
@article{FU2021102553,
title = {Comparison of optimized object-based RF-DT algorithm and SegNet algorithm for classifying Karst wetland vegetation communities using ultra-high spatial resolution UAV data},
journal = {International Journal of Applied Earth Observation and Geoinformation},
volume = {104},
pages = {102553},
year = {2021},
issn = {0303-2434},
doi = {https://doi.org/10.1016/j.jag.2021.102553},
url = {https://www.sciencedirect.com/science/article/pii/S0303243421002609},
author = {Bolin Fu and Man Liu and Hongchang He and Feiwu Lan and Xu He and Lilong Liu and Liangke Huang and Donglin Fan and Min Zhao and Zhenglei Jia},
keywords = {Karst wetland, UAV image, RF-DT algorithm, SegNet algorithm, Object-based method, Vegetation communities’ classification},
abstract = {Karst wetlands have the characteristics of small scale and poor stability. At present, the wetland is being severely damaged and its area is seriously degraded, and the accurate identification of vegetation communities is very important for the rapid assessment and management of karst wetland. In this paper, Huixian Karst National Wetland Park, located in Guilin city, China, was taken as the study area, the digital orthophoto map (DOM) and digital surface model (DSM) of UAV images were selected as the data sources, and the vegetation communities of karst wetland were classified by using the object-based Random Forest (RF)-Decision Tree (DT) algorithm and SegNet algorithm. When the object-based RF algorithm and SegNet algorithm were used for coarse classification of karst vegetation, the parameters (mtry, ntree) of the object-based RF algorithm were optimized, and the data dimensionality reduction and RFE variable selection algorithm were used for selecting feature, and the single-class SegNet model was integrated based on the soft voting method to improve the applicability of vegetation classification in karst wetlands. In the classification of vegetation communities in karst wetlands, the optimized object-based RF-DT algorithm were used to extract the vegetation communities in the Areas A, B, and C. The statistical analysis of the importance of the feature variables (spectral features, texture features, geometric features, and position features) of various types of land cover in the three areas was carried out to explore the optimal classification variables of various types of vegetation. The results showed that: (1) the optimized object-based RF algorithm performed better than the SegNet algorithm in classifying karst vegetation at 95% confidence level during the coarse classification. The average accuracy of wetland vegetation was improved by 1.06–13.58%; (2) the object-based RF-DT algorithm had high classification ability for the karst wetland vegetation community, with overall accuracy and kappa coefficient above 0.85; and that (3) although geometric features accounted for the largest proportion (52.2%) in the classification of bermudagrass, water hyacinth, lotus, linden and other vegetation, texture features accounted for the highest proportion of 56.3% in the classification of vegetation whose importance was more than 90.}
}
@article{LUO2018282,
title = {Convolutional neural networks: Computer vision-based workforce activity assessment in construction},
journal = {Automation in Construction},
volume = {94},
pages = {282-289},
year = {2018},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2018.06.007},
url = {https://www.sciencedirect.com/science/article/pii/S0926580518305855},
author = {Hanbin Luo and Chaohua Xiong and Weili Fang and Peter E.D. Love and Bowen Zhang and Xi Ouyang},
keywords = {Activity analysis, Convolutional neural networks, Computer vision, Construction, Video interpretation},
abstract = {Computer vision approaches have been widely used to automatically recognize the activities of workers from videos. While considerable advancements have been made to capture complementary information from still frames, it remains a challenge to obtain motion between them. As a result, this has hindered the ability to conduct real-time monitoring. Considering this challenge, an improved convolutional neural network (CNN) that integrates Red-Green-Blue (RGB), optical flow, and gray stream CNNs, is proposed to accurately monitor and automatically assess workers' activities associated with installing reinforcement during construction. A database containing photographs of workers installing reinforcement is created from activities undertaken on several construction projects in Wuhan, China. The database is then used to train and test the developed CNN network. Results demonstrate that the developed method can accurately detect the activities of workers. The developed computer vision-based approach can be used by construction managers as a mechanism to assist them to ensure that projects meet pre-determined deliverables.}
}
@article{MYLONAS2022100028,
title = {Eden Library: A long-term database for storing agricultural multi-sensor datasets from UAV and proximal platforms},
journal = {Smart Agricultural Technology},
volume = {2},
pages = {100028},
year = {2022},
issn = {2772-3755},
doi = {https://doi.org/10.1016/j.atech.2021.100028},
url = {https://www.sciencedirect.com/science/article/pii/S2772375521000289},
author = {Nikos Mylonas and Ioannis Malounas and Sofia Mouseti and Eleanna Vali and Borja Espejo-Garcia and Spyros Fountas},
keywords = {Open-data, Dataset, Precision agriculture, Deep learning, Computer vision, Robotics, Artificial intelligence},
abstract = {In modern agriculture, visual recognition systems based on deep learning are arising to allow autonomous machines to execute field operations in crops. However, for obtaining high performances, these methods need high amounts of data, which are usually scarce in agriculture. The main reason is that building an agricultural dataset covering exhaustively a specific problem is challenging, as visual characteristics of the symptoms may change, and there is a high dependency on environmental factors, such as temperature, humidity and light conditions. Therefore, an efficient methodology is necessary to consistently cover the entire workflow for creating an agricultural dataset, from the image acquisition to its online publication. This paper presents the Eden Library, a platform for contributing to this existing gap in open access crop/plant databases covering proximal and aerial images. The complete workflow on the design and deployment of the platform is also explained and discussed. This workflow is relevant because the provided datasets are thought to be maintained and enriched along the time, and they do not just remain as a static research output covering only specific species, growth stages, and conditions. The image annotations of plants and symptoms are provided, saving users from manually annotating images. Currently, the Eden Library covers 15 different crops, 9 weeds and 30 disorders (pests, diseases and nutrient deficiencies). Eden Library aspires to close this gap by providing a large and diversified image collection of plants, organized in a consistent manner, in order to boost further vision-based and AI-enabled field applications.}
}
@article{TEPANOSYAN2021107390,
title = {Studying spatial-temporal changes and relationship of land cover and surface Urban Heat Island derived through remote sensing in Yerevan, Armenia},
journal = {Building and Environment},
volume = {187},
pages = {107390},
year = {2021},
issn = {0360-1323},
doi = {https://doi.org/10.1016/j.buildenv.2020.107390},
url = {https://www.sciencedirect.com/science/article/pii/S0360132320307599},
author = {Garegin Tepanosyan and Vahagn Muradyan and Azatuhi Hovsepyan and Gleb Pinigin and Andrey Medvedev and Shushanik Asmaryan},
keywords = {Land cover, Surface urban heat island, Remote sensing, Machine learning, Thermal UAV survey, Yerevan},
abstract = {The city of Yerevan, Armenia has undergone major environmental and economic changes after the collapse of the Soviet Union. The objectives of this study were to: (i) investigate the changes of the Land Cover (LC) and Surface Urban Heat Island (SUHI) in Yerevan and analyze relations between them, (ii) study the relationships between land surface temperature (LST) and environmental factors/parameters, (iii) explore the accuracy of satellite derived LST. LC and SUHI were derived from Landsat TM/ETM+/OLI-TIRS images (years 1989, 2000, 2010 and 2018) by means of three Machine Learning algorithms and the Urban Thermal Field Variance Index (UTFVI) ecological evaluation index, respectively. The comparison between Unmanned Aerial Vehicle (UAV) and satellite LSTs showed that the overall spatial pattern of Landsat and UAV LSTs matched. It was found that the green and built-up areas were the main factors affecting LST variation in Yerevan. The results of the LC change analysis revealed an expansion of built-up areas and the reduction of green spaces. Yerevan shares almost an equal percentage of land for the excellent and the worst categories of the UTFVI. The transformations from excellent to the worst category of UTFVI were mainly related to the loss of green spaces, while the opposite transformations were associated with the gain of vegetation cover, the construction of new districts and the reduction/cessation of anthropogenic heat emission. It appeared that the urban construction had possibly led to the improvement of UTFVI index in the case of no/low anthropogenic heat emission.}
}
@article{MOROCHOCAYAMCELA2021,
title = {An optimal location strategy for multiple drone base stations in massive MIMO},
journal = {ICT Express},
year = {2021},
issn = {2405-9595},
doi = {https://doi.org/10.1016/j.icte.2021.08.010},
url = {https://www.sciencedirect.com/science/article/pii/S2405959521000990},
author = {Manuel Eugenio Morocho-Cayamcela and Wansu Lim and Martin Maier},
keywords = {Disaster scenario, Massive MIMO, Path planning, Unmanned aerial vehicle, User association},
abstract = {The concept of drone base stations (DBSs) has been applied to reduce the distance of the wireless link between a macro base station and its active users under diverse scenarios in military communications, smart industries, and high-density networks, and to provide service in topologies with damaged infrastructure. In this paper, we address the optimal positioning of multiple DBSs in a multiple-input multiple-output wireless network setting. We present a low-complexity machine learning-based algorithm to optimize the location of the DBSs by minimizing the collective wireless received signal strength experienced by the active terminals. The proposed algorithm reduces the propagation loss in the system and provides a lower bit error rate when compared with the Euclidean cost benchmark.}
}
@article{WU2018127,
title = {Modeling and simulation of dynamic ant colony’s labor division for task allocation of UAV swarm},
journal = {Physica A: Statistical Mechanics and its Applications},
volume = {491},
pages = {127-141},
year = {2018},
issn = {0378-4371},
doi = {https://doi.org/10.1016/j.physa.2017.08.094},
url = {https://www.sciencedirect.com/science/article/pii/S0378437117308166},
author = {Husheng Wu and Hao Li and Renbin Xiao and Jie Liu},
keywords = {Ant colony’s labor division, Dynamic task allocation, Response threshold model, UAV swarm},
abstract = {The problem of unmanned aerial vehicle (UAV) task allocation not only has the intrinsic attribute of complexity, such as highly nonlinear, dynamic, highly adversarial and multi-modal, but also has a better practicability in various multi-agent systems, which makes it more and more attractive recently. In this paper, based on the classic fixed response threshold model (FRTM), under the idea of “problem centered + evolutionary solution” and by a bottom-up way, the new dynamic environmental stimulus, response threshold and transition probability are designed, and a dynamic ant colony’s labor division (DACLD) model is proposed. DACLD allows a swarm of agents with a relatively low-level of intelligence to perform complex tasks, and has the characteristic of distributed framework, multi-tasks with execution order, multi-state, adaptive response threshold and multi-individual response. With the proposed model, numerical simulations are performed to illustrate the effectiveness of the distributed task allocation scheme in two situations of UAV swarm combat (dynamic task allocation with a certain number of enemy targets and task re-allocation due to unexpected threats). Results show that our model can get both the heterogeneous UAVs’ real-time positions and states at the same time, and has high degree of self-organization, flexibility and real-time response to dynamic environments.}
}
@article{HASSANIJALILIAN2020105433,
title = {Chlorophyll estimation in soybean leaves infield with smartphone digital imaging and machine learning},
journal = {Computers and Electronics in Agriculture},
volume = {174},
pages = {105433},
year = {2020},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2020.105433},
url = {https://www.sciencedirect.com/science/article/pii/S0168169919315236},
author = {Oveis Hassanijalilian and C. Igathinathane and Curt Doetkott and Sreekala Bajwa and John Nowatzki and Seyed Ali {Haji Esmaeili}},
keywords = {Soybean, Chlorophyll content, Image processing, Machine learning, Random coefficients model, Smartphone},
abstract = {Soybean (Glycine max (L.) Merrill) leaf chlorophyll content is indicative of the plant growth and health issues. However, chlorophyll measurement using the standard chemical procedure is laborious, while the sensor-based electronic options, such as soil plant analysis development (SPAD) meter tend to be highly expensive and made only spot measurements. Therefore, a simpler and less expensive infield method of chlorophyll measurement in soybeans using smartphone camera with image processing and machine learning models was developed. Soybean leaf images (720 images) and SPAD readings were collected from different cultivars (4), with replications (3) and sampling dates (2) from experimental plots. Of the several color vegetation indices (CVIs) tested, the dark green color index (DGCI) had the best correlation with SPAD meter readings (r=0.90), which was further improved by color calibration (r=0.93). The results of the random coefficients model showed that both cultivars and sampling dates had no significant effect (0.06≤P≤0.96), hence data were combined for the analysis. The simpler statistical linear regression (SLR) and polynomial regression (PR), multiple linear regression as well as the advanced machine learning models (support vector machine (SVM), random forest (RF)) tested with color scheme inputs (RGB, DGCI, range pixel count (RPC) of DGCI, and ‘Both’ (RPC + RGB)) produced the best chlorophyll prediction with DGCI, RPC, and ‘Both’ inputs (0.87<R2<0.89; 2.90≤RMSE≤3.41 SPAD units). Overall, these models were not significantly different, but the SVM model found to be the best (R2=0.89 and RMSE=2.90 SPAD units). The simpler SLR and PR models with DGCI input (R2≥0.87 and RMSE≤3.1 SPAD units) performed as good as the advanced SVM and RF models. The SVM model had the potential of predicting the chlorophyll directly with the raw RGB input (R2=0.86 and RMSE=3.20 SPAD units) without the need of using the standard calibration board. The developed methodology of image processing with machine learning modeling and conversion relationship of measuring infield soybean leaf chlorophyll is efficient, inexpensive, not requiring the standard calibration board, and can be easily extended to other large-scale aerial imaging platforms and field crops.}
}
@article{PEREZCARABAZA2019357,
title = {UAV trajectory optimization for Minimum Time Search with communication constraints and collision avoidance},
journal = {Engineering Applications of Artificial Intelligence},
volume = {85},
pages = {357-371},
year = {2019},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2019.06.002},
url = {https://www.sciencedirect.com/science/article/pii/S0952197619301411},
author = {Sara Pérez-Carabaza and Jürgen Scherer and Bernhard Rinner and José A. López-Orozco and Eva Besada-Portas},
keywords = {Ant Colony Optimization, Probabilistic path planning, UAVs, Minimum time search, Communication constraints},
abstract = {Minimum Time Search (MTS) algorithms help in search missions proposing search trajectories that minimize the target detection time considering the available information about the search scenario. This work proposes a MTS planner based on ant colony optimization that includes communication and collision avoidance constraints. This ensures that the Unmanned Aerial Vehicles (UAVs) are able to complete the optimized search trajectories without risk of collision or loss of communication with the ground control station. This approach is a great advantage nowadays, where UAVs flight regulation is quite strict, often requiring to monitor the state of the UAVs during the whole mission, impeding UAV deployments without continuous communication to the ground control station. The proposed algorithm is tested with several search scenarios and compared against two state of the art techniques based on Cross Entropy Optimization and Genetic Algorithms, which have been adapted to make them consider collision and communication constraints as well.}
}
@article{RODRIGUEZFERNANDEZ2017103,
title = {Analysing temporal performance profiles of UAV operators using time series clustering},
journal = {Expert Systems with Applications},
volume = {70},
pages = {103-118},
year = {2017},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2016.10.044},
url = {https://www.sciencedirect.com/science/article/pii/S0957417416305851},
author = {Víctor Rodríguez-Fernández and Héctor D. Menéndez and David Camacho},
keywords = {UAVs, UAV operators, Time Series Clustering, Performance measures, Simulation-Based Training},
abstract = {The continuing growth in the use of Unmanned Aerial Vehicles (UAVs) is causing an important social step forward in the performance of many sensitive tasks, reducing both human and economical risks. The work of UAV operators is a key aspect to guarantee the success of this kind of tasks, and thus UAV operations are studied in many research fields, ranging from human factors to data analysis and machine learning. The present work aims to describe the behaviour of operators over time using a profile-based model where the evolution of the operator performance during a mission is the main unit of measure. In order to compare how different operators act throughout a mission, we describe a methodology based of multivariate-time series clustering to define and analyse a set of representative temporal performance profiles. The proposed methodology is applied in a multi-UAV simulation environment with inexperienced operators, obtaining a fair description of the temporal behavioural patterns followed during the course of the simulation.}
}
@article{CLAESSON2020196,
title = {The use of drones and a machine-learning model for recognition of simulated drowning victims—A feasibility study},
journal = {Resuscitation},
volume = {156},
pages = {196-201},
year = {2020},
issn = {0300-9572},
doi = {https://doi.org/10.1016/j.resuscitation.2020.09.022},
url = {https://www.sciencedirect.com/science/article/pii/S0300957220304706},
author = {A. Claesson and S. Schierbeck and J. Hollenberg and S. Forsberg and P. Nordberg and M. Ringh and M. Olausson and A. Jansson and A. Nord},
keywords = {Drowning, Drone, OHCA, Machine-learning},
abstract = {Background
Submersion time is a strong predictor for death in drowning, already 10 min after submersion, survival is poor. Traditional search efforts are time-consuming and demand a large number of rescuers and resources. We aim to investigate the feasibility and effectiveness of using drones combined with an online machine learning (ML) model for automated recognition of simulated drowning victims.
Methods
This feasibility study used photos taken by a drone hovering at 40 m altitude over an estimated 3000 m2 surf area with individuals simulating drowning. Photos from 2 ocean beaches in the south of Sweden were used to (a) train an online ML model (b) test the model for recognition of a drowning victim.
Results
The model was tested for recognition on n = 100 photos with one victim and n = 100 photos with no victims. In drone photos containing one victim (n = 100) the ML model sensitivity for drowning victim recognition was 91% (95%CI 84.9%–96.2%) with a median probability score that the finding was human of 66% (IQR 52−71). In photos with no victim (n = 100) the ML model specificity was 90% (95%CI: 83.9%–95.6%). False positives were present in 17.5% of all n = 200 photos but could all be ruled out manually as false objects.
Conclusions
The use of a drone and a ML model was feasible and showed satisfying effectiveness in identifying a submerged static human simulating drowning in open water and favorable environmental conditions. The ML algorithm and methodology should be further optimized, again tested and validated in a real-life clinical study.}
}
@article{XU2020105762,
title = {Establishing a model to predict the single boll weight of cotton in northern Xinjiang by using high resolution UAV remote sensing data},
journal = {Computers and Electronics in Agriculture},
volume = {179},
pages = {105762},
year = {2020},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2020.105762},
url = {https://www.sciencedirect.com/science/article/pii/S0168169920304671},
author = {Weicheng Xu and Weiguang Yang and Shengde Chen and Changsheng Wu and Pengchao Chen and Yubin Lan},
keywords = {UAV remote sensing, Neural networks, Multiple linear regression, Single boll weight prediction of cotton, Cotton boll recognition},
abstract = {Single boll weight is the main factor of cotton yield and a key index used to evaluate the quality of cotton. Predicting the single boll weight in a large area is important for variety selection and yield improvement. A model was established to predict the single boll weight by using the multitemporal high-resolution visible light remote sensing data obtained from UAV. Specifically, remote sensing data were collected for 29 fields in the Changji, Shihezi and Shawan areas in northern Xinjiang during the blooming period and boll opening stage. Five circular areas with a radius of 1 m were selected from each field as the ground investigation area for collection of the cotton boll samples. Fully convolutional networks (FCN) was used to recognize and extract bolls at the boll opening stage in the remote sensing images as a dependent variable of the model. Correlation analysis was carried out by combining VDVI (Visible-band difference vegetation index) at the flowering and boll setting stages, VDVI at boll opening stages, VDVI at boll opening areas (Extracted by FCN) and RGB mean values, then use the least squares linear regression and BP neural networks to model the upper, middle, lower cotton layers and average single boll weight in investigation area. Subsequently, K-fold cross-validation was performed to evaluate the results. The results showed that the results of the least squares linear regression (R2 = 0.8162) and BP neural networks (R2 = 0.8170) were nearly equivalent. The percentage of boll opening in the area and VDVI at the flowering and boll setting stages were highly correlated with upper single boll weight. This study proposes a method to realize the large scale prediction of single boll weight, which provided a new idea for cotton yield prediction and breeding screening.}
}
@article{SHEN2020102128,
title = {Synergistic path planning of multi-UAVs for air pollution detection of ships in ports},
journal = {Transportation Research Part E: Logistics and Transportation Review},
volume = {144},
pages = {102128},
year = {2020},
issn = {1366-5545},
doi = {https://doi.org/10.1016/j.tre.2020.102128},
url = {https://www.sciencedirect.com/science/article/pii/S1366554520307766},
author = {Lixin Shen and Yaodong Wang and Kunpeng Liu and Zaili Yang and Xiaowen Shi and Xu Yang and Ke Jing},
keywords = {UAVs, Ship emissions, Air pollution, Path planning, Dynamic multiobjective, PSO},
abstract = {The phenomena of the COVID-19 outbreak and the Arctic Iceberg melting over the past two years make us reconsider the impact our way of life has on the environment and the responsibility of business toward minimizing and potentially eliminating emissions. Increasing ship traffic in ports leads to the growing emission of air pollutants, which influences the air quality and public health in the surrounding areas. The International Maritime Organization (IMO) has adopted relevant regulations (e.g., Annex VI of IMO's pollution prevention treaty (MARPOL) and mandatory energy-efficiency measures) to address ship emissions. To ensure the effective implementation of such regulations and measures, air emission detection and monitoring has become crucial. In this paper, a dynamic multitarget path planning model is developed to realize multi-UAVs (Unmanned Aerial Vehicles) performing synergistic detection of ship emissions in ports. A path planning algorithm under a dynamic environment is developed to establish the model. This algorithm incorporates a Tabu table into particle swarm optimization (PSO) to improve its optimization ability, and it obtains the initial detection route of each UAV based on a “minimum ring” method. This paper describes a multi-UAVs synergistic algorithm to formulate the path reprogramming time in a dynamic environment by judging and cutting the “minimum ring”. This finding proves the improved efficiency of air pollution detection by UAVs. It provides useful insights for maritime and port authorities to detect ship emissions in practice and to ensure ship emission reduction for better air quality in the postpandemic era.}
}
@article{MERGHADI2020103225,
title = {Machine learning methods for landslide susceptibility studies: A comparative overview of algorithm performance},
journal = {Earth-Science Reviews},
volume = {207},
pages = {103225},
year = {2020},
issn = {0012-8252},
doi = {https://doi.org/10.1016/j.earscirev.2020.103225},
url = {https://www.sciencedirect.com/science/article/pii/S0012825220302713},
author = {Abdelaziz Merghadi and Ali P. Yunus and Jie Dou and Jim Whiteley and Binh ThaiPham and Dieu Tien Bui and Ram Avtar and Boumezbeur Abderrahmane},
keywords = {Landslide, Natural hazard, Machine learning, Random forest, Susceptibility},
abstract = {Landslides are one of the catastrophic natural hazards that occur in mountainous areas, leading to loss of life, damage to properties, and economic disruption. Landslide susceptibility models prepared in a Geographic Information System (GIS) integrated environment can be key for formulating disaster prevention measures and mitigating future risk. The accuracy and precision of susceptibility models is evolving rapidly from opinion-driven models and statistical learning toward increased use of machine learning techniques. Critical reviews on opinion-driven models and statistical learning in landslide susceptibility mapping have been published, but an overview of current machine learning models for landslide susceptibility studies, including background information on their operation, implementation, and performance is currently lacking. Here, we present an overview of the most popular machine learning techniques available for landslide susceptibility studies. We find that only a handful of researchers use machine learning techniques in landslide susceptibility mapping studies. Therefore, we present the architecture of various Machine Learning (ML) algorithms in plain language, so as to be understandable to a broad range of geoscientists. Furthermore, a comprehensive study comparing the performance of various ML algorithms is absent from the current literature, making an assessment of comparative performance and predictive capabilities difficult. We therefore undertake an extensive analysis and comparison between different ML techniques using a case study from Algeria. We summarize and discuss the algorithm's accuracies, advantages and limitations using a range of evaluation criteria. We note that tree-based ensemble algorithms achieve excellent results compared to other machine learning algorithms and that the Random Forest algorithm offers robust performance for accurate landslide susceptibility mapping with only a small number of adjustments required before training the model.}
}
@article{KAMARI2021103430,
title = {Vision-based volumetric measurements via deep learning-based point cloud segmentation for material management in jobsites},
journal = {Automation in Construction},
volume = {121},
pages = {103430},
year = {2021},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2020.103430},
url = {https://www.sciencedirect.com/science/article/pii/S0926580520310104},
author = {Mirsalar Kamari and Youngjib Ham},
keywords = {Visual sensing and analytics, Volumetric measurements, Point cloud segmentation},
abstract = {Emerging vision-based frameworks have demonstrated the great potential to robustly perform volumetric measurements on point cloud models, which has several applications for site material management (e.g., during earthworks). However, prevalent vision-based frameworks to date involve human interventions to manually trim objects of interest from point cloud models, which would be time-consuming and labor-intensive. In addition, point cloud models for volumetric measurements are often incomplete and noisy. To address such challenges, we automatically detect and segment target objects in point cloud models via a deep learning-based approach and then map the semantic values onto point cloud models for 3D semantic segmentation. Once target objects are segmented, the associated volumes are quantified through the proposed vision-based computational process. For evaluation, case studies were performed on material piles in the real-world. The proposed method has the potential to enhance vision-based volumetric measurements, which supports systematic decision-making for material management in jobsites.}
}
@article{LI2020109,
title = {Machine learning based code dissemination by selection of reliability mobile vehicles in 5G networks},
journal = {Computer Communications},
volume = {152},
pages = {109-118},
year = {2020},
issn = {0140-3664},
doi = {https://doi.org/10.1016/j.comcom.2020.01.034},
url = {https://www.sciencedirect.com/science/article/pii/S0140366419315609},
author = {Ting Li and Ming Zhao and Kelvin Kian Loong Wong},
keywords = {Machine learning, Code disseminations, Safety degree, Coverage ratio, Reliability, 5G networks},
abstract = {Recently, the evolving of 5G networks is foreseen as a major driver of future mobile vehicular social networks (VSNs), which can provide a novel method of code disseminations. Based on this concept, vehicles can be used as code disseminators. That is, infrastructures of a smart city can be upgraded by receiving updated program codes that are disseminated by vehicles in the VSNs. Specifically, vehicles in the 5G network are hard to be managed. Under this domain, safety of program codes is a key challenge. Meanwhile, improving coverage of program codes is also challenging. However, arranging plenty of vehicles as code disseminators will incur large costs of the ground control station (GCS). Therefore, by utilizing machine learning methods, this paper proposes a “Machine Learning based Code Dissemination by Selecting Reliability Mobile Vehicles in 5G Networks” (MLCD) scheme to choose vehicles with higher reliable degree and coverage ratio as code disseminators to deliver code with lower costs. Firstly, reliable degrees of vehicles are calculated and selected to improve safety degree of code disseminations. Secondly, vehicles with higher coverage ratio are preferred to promise code coverage. Thirdly, machine learning methods are utilized to select vehicles with both higher coverage ratios and reliable degrees as code disseminators with limited costs. Compared to random-selection and coverage-only scheme respectively, the MLCD scheme can improve safety degree of code dissemination process by 83.6% and 18.86% in 5G networks, and can improve coverage ratio of updated information by 23.16%. Comprehensive performances of the proposed scheme can be improved by 80.56% and 17.25% respectively. Future works focus on improving code security in 5G networks by more advanced and suitable machine learning methods.}
}
@article{AHMED2022103290,
title = {Deep residual learning-based cognitive model for detection and classification of transmitted signal patterns in 5G smart city networks},
journal = {Digital Signal Processing},
volume = {120},
pages = {103290},
year = {2022},
issn = {1051-2004},
doi = {https://doi.org/10.1016/j.dsp.2021.103290},
url = {https://www.sciencedirect.com/science/article/pii/S1051200421003298},
author = {Ramsha Ahmed and Yueyun Chen and Bilal Hassan},
keywords = {Cognitive radio, Deep learning, Spectrum sensing, Signal detection, Transmission pattern classification},
abstract = {Primary user (PU) signal detection or classification is a critical component of cognitive radio (CR) related wireless communication applications. In CR, the PU detection methods are mostly based on statistical models, and their detection performance heavily relies on the accuracy of assumed models. In this paper, we design a novel detector, dubbed as PU-Net, that dynamically learns the PU activity patterns in a cognitive 5G smart city, where a network of unmanned aerial vehicles (UAVs) is deployed as flying base stations to serve the Internet-of-Things (IoT) users. Unlike the traditional schemes, the PU-Net is free from signal-noise model assumptions and is leveraged through deep residual learning integrated with atrous spatial pyramid pooling (ASPP) to sense the PU's transmitted signal patterns in the network. The PU-Net detects and classifies the active and idle PU states by exploiting the multilevel spatial-temporal features in the signal and noise frames. The proposed model is trained using locally synthesized Rayleigh channel-impaired data with large variability of modulated signals and different noise floor regimes. Additionally, the PU-Net model is blind-tested and evaluated on real-world over-the-air signals and with variable-length frames and varying channel effects at secondary users (SUs). With extensive experiments, it is shown that PU-Net outperforms other benchmark detectors, obtaining an accuracy of 0.9974, with 0.9978 recall and 0.9970 precision in detecting and classifying the PU transmitted signal patterns. Correspondingly, the proposed PU-Net can be adopted for IoT/UAV-assisted communication systems in optimizing spectrum efficiency and resolving the coexistence issues in 5G and beyond networks.}
}
@article{MABBAS2019243,
title = {Autonomous Canal Following by a Micro-Aerial Vehicle Using Deep CNN⁎⁎We acknowledgement the finanical support of National Center for Robotics and Automation (NCRA), Pakistan; the German Academic Exchange Service (DAAD); Center for Water Informatics & Technology at LUMS, in carrying out this research.},
journal = {IFAC-PapersOnLine},
volume = {52},
number = {30},
pages = {243-250},
year = {2019},
note = {6th IFAC Conference on Sensing, Control and Automation Technologies for Agriculture AGRICONTROL 2019},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2019.12.529},
url = {https://www.sciencedirect.com/science/article/pii/S2405896319324486},
author = {Syed {M. Abbas} and Hashim Ali and Abubakr Muhammad},
keywords = {Agricultural robotics, water management, precision agriculture, trajectory tracking, CNN, autonomous navigation, Unmanned Aerial Vehicles},
abstract = {Globally, large-scale irrigation canal networks serve as the backbone of agriculture in many important river basins. However, these water channels are in a constant threat of erosion, silt accumulation and structural damages over time which significantly reduces the water carrying capacity. Therefore, periodic inspections of the canals are required for critical operations and maintenance tasks. Due to the vast lengths of the channels and time-critical operations, automation has become a necessity. In this paper, we have proposed an aerial autonomous canal traversal system using ResNet50 inspired deep convolutional neural network. Given the uniqueness of our problem, we have generated our dataset for supervised learning and validation and later evaluated the proposed approach on a real canal. We have implemented our approach on a COTS micro-aerial vehicle. We have designed our system in such a way that it takes 200ms from perception to action thereby making the system real-time. We compare the superior performance of our Res Net 50 inspired network with other state-of-the-art CNNs trained on canal datasets.}
}
@article{MARKOLF202015608,
title = {Trajectory Planning for Autonomous Vehicles combining Nonlinear Optimal Control and Supervised Learning⁎⁎Financial support by the German Research Foundation (DFG) within priority program (SPP) 1835 is gratefully acknowledged.},
journal = {IFAC-PapersOnLine},
volume = {53},
number = {2},
pages = {15608-15614},
year = {2020},
note = {21st IFAC World Congress},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2020.12.2495},
url = {https://www.sciencedirect.com/science/article/pii/S2405896320332183},
author = {Lukas Markolf and Jan Eilbrecht and Olaf Stursberg},
keywords = {Nonlinear, optimal automotive control, automated driving, machine learning, intelligent control, neural networks},
abstract = {This paper considers computationally efficient planning of reference trajectories for autonomous on-road vehicles in a cooperative setting. The basic element of the approach is the notion of so-called maneuvers, which allow to cast the nonlinear and non-convex planning task into a highly structured optimal control problem. This can be solved quite efficiently, but not fast enough for online operation when considering nonlinear vehicle models. Therefore, the approach proposed in this paper aims at approximating solutions using a supervised learning approach: First, training data are generated by solving optimal control problems and are then used to train a neural network. As is demonstrated for a cooperative overtaking maneuver, this approach shows good performance, while (contrasting approaches like reinforcement learning) requiring only low training effort.}
}
@article{SCHINDLER2021101215,
title = {Identification of animals and recognition of their actions in wildlife videos using deep learning techniques},
journal = {Ecological Informatics},
volume = {61},
pages = {101215},
year = {2021},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2021.101215},
url = {https://www.sciencedirect.com/science/article/pii/S1574954121000066},
author = {Frank Schindler and Volker Steinhage},
abstract = {Biodiversity crisis has continued to accelerate. Studying animal distribution, movement and behaviour is of critical importance to address environmental challenges such as spreading of diseases, invasive species, climate and land-use change. Camera traps are an appropriate technique for continuous animal monitoring in an automated 24/7/52 documentation. This study shows a proof-of-concept for an end-to-end pipeline to detect and classify animals and their behaviour in video clips. Video clips are captured with 8 frames per second by camera traps using infrared cameras and infrared flash-lights. The clips show deer, boars, foxes and hares - mostly at night time. Our approach shows an average precision of 63.8% for animal detection and identification. For action recognition the achieved accuracies range between 88.4% and 94.1%.}
}
@article{ALTAN2020106548,
title = {Model predictive control of three-axis gimbal system mounted on UAV for real-time target tracking under external disturbances},
journal = {Mechanical Systems and Signal Processing},
volume = {138},
pages = {106548},
year = {2020},
issn = {0888-3270},
doi = {https://doi.org/10.1016/j.ymssp.2019.106548},
url = {https://www.sciencedirect.com/science/article/pii/S0888327019307691},
author = {Aytaç Altan and Rıfat Hacıoğlu},
keywords = {UAV, Gimbal system, Hammerstein, Model predictive control, Target tracking},
abstract = {The fact that Unmanned Aerial Vehicles (UAVs) move in a specific path and that the camera in the gimbal system mounted on the UAV adhere to the right target attracts the attention of many researchers. The effective control of the gimbal system directly affects the performance of the UAV which is tracking a predetermined moving target, following a specified path. The contribution of this study is not only modelling three-axis gimbal system mounted on mobile platform based on nonlinear Hammerstein block structure to control effectively using model predictive controller (MPC) but also improving real time target tracking performance under external disturbances. A novel Hammerstein model based MPC controller is successfully proposed for real time target tracking of three-axis gimbal system applying flight scenarios of UAV to be robust under external disturbances. In this study, firstly, the mathematical model of three-axis gimbal system mounted on UAV is developed based on traditional Newton–Euler method. Secondly, linear and nonlinear modeling based on the input and output data of the three-axis gimbal system mounted on UAV moving autonomously for target tracking is emphasized. The linear output error (OE) and nonlinear block structure Hammerstein models of the three-axis gimbal system are identified under the external disturbance effect, respectively. Then, the identified Hammerstein model is embedded in the flight control card, which included the three-axis gimbal system control to realize real time target tracking of the UAV. Afterwards, the MPC of three-axis gimbal system is realized under the external disturbance with linear and nonlinear models. Also, the performance of proposed MPC controller with Hammerstein model is evaluated comparing with conventional PID controller in terms of robustness and quantitative study of error analysis. Finally, the stability and robustness of the three-axis gimbal system controlled with the MPC algorithm has been investigated by the test results carried out in different scenarios. The simulation and experimental results show that the proposed MPC algorithm with Hammerstein model in this paper can ensure that the UAV exactly tracking the target while maintaining stability, even with external disturbances.}
}
@article{ORENGO2019105013,
title = {A brave new world for archaeological survey: Automated machine learning-based potsherd detection using high-resolution drone imagery},
journal = {Journal of Archaeological Science},
volume = {112},
pages = {105013},
year = {2019},
issn = {0305-4403},
doi = {https://doi.org/10.1016/j.jas.2019.105013},
url = {https://www.sciencedirect.com/science/article/pii/S0305440319301001},
author = {H.A. Orengo and A. Garcia-Molsosa},
keywords = {Landscape archaeology, Archaeological survey, Drone survey, Photogrammetry, Machine learning, Cloud distributed computing, Automated site detection},
abstract = {Archaeological pedestrian survey is one of the most popular techniques available for primary detection of archaeological sites and description of past landscape use. As such it is an essential tool not just for the understanding of past human distribution, economy, demography and so on but also for cultural heritage management and protection. The most common type of pedestrian surface survey consists of fieldwalking relatively large tracts of land, recording the dispersion of items of material culture, predominantly pottery fragments, by teams of archaeologists and students. This paper presents the first proof of concept for the automated recording of material culture dispersion across large areas using high resolution drone imagery, photogrammetry and a combination of machine learning and geospatial analysis that can be run using the Google Earth Engine geospatial cloud computing platform. The results show the potential of this technique, under appropriate field circumstances, to produce accurate distribution maps of individual potsherds opening a new horizon for the application of archaeological survey. The paper also discusses current limitations and future developments of this method.}
}
@article{PENG2021108158,
title = {Random forest regression results in accurate assessment of potato nitrogen status based on multispectral data from different platforms and the critical concentration approach},
journal = {Field Crops Research},
volume = {268},
pages = {108158},
year = {2021},
issn = {0378-4290},
doi = {https://doi.org/10.1016/j.fcr.2021.108158},
url = {https://www.sciencedirect.com/science/article/pii/S0378429021001040},
author = {Junxiang Peng and Kiril Manevski and Kirsten Kørup and René Larsen and Mathias Neumann Andersen},
keywords = {Nitrogen requirement, Nutrient index, Hand-held Rapidscan, Sentinel-2, Unmanned aerial vehicle},
abstract = {Remote sensing can be used for precision nutrient management to assess plant nitrogen (N) status in a spatially detailed and real-time manner. Despite recent advances in satellite- and drone technology and machine learning, neither differences between platforms nor methodological aspects for estimating plant N status have been sufficiently investigated. In this study, multispectral data obtained by ground (handheld Rapidscan), air- (unmanned aerial vehicle, UAV) and spaceborne (Sentinel-2) platforms were exploited to estimate plant N uptake (PNU), concentration (PNC) and N nutrition index (NNI). The test plant was potato grown for three years on a sandy soil in Denmark and the analysis was based on the critical N dilution curve. Parametric (PR) and non-parametric (random forest, RFR) regressions were conducted and compared in predicting mid-season PNU, PNC and NNI from band reflectances or vegetation indices (VIs) derived from each platform data. The results obtained by the UAV data had the highest accuracy, largely due to the fine spatial resolution. For both regression types, PNU and NNI correlated better than PNC to reflectance data. For the UAV data, validation Nash-Sutcliffe model efficiency (NSE) of PNU and NNI ranged between 0.64–0.95 and 0.41–0.92 respectively, with corresponding values for relative root mean square error (RRMSE) of 7.1–22% and 5.86–22%. The lower end of NSE and higher end RRMSE intervals systematically being from the PR, which demonstrates the robustness and the high accuracy of RFR in predicting plant N status. The other platforms resulted in acceptable results, with validation NSE and RRMSE for PNU and NNI of, respectively, 0.60–0.79 and 14–20%, 0.25–0.79 and 10–17% for Rapidscan, and 0.48–0.83 and 17–28%, 0.42–0.82 and 12–19% for Sentinel-2. The band reflectance and the VIs were equally suited as input predictors for the RFR algorithm. The N requirement calculated from all three datasets reflected the field observations well. The study reveals the potential of different regression methods for detailed spatial estimation of plant N status to guide in-season fertilization by matching the plant growth demands, emphasizing the strengths of the RFR. The procedure is helpful for the digital agriculture and the smart farming industry aiming to avoid excess application of N.}
}
@article{WANG2021107966,
title = {Deep neural network-aided coherent integration method for maneuvering target detection},
journal = {Signal Processing},
volume = {182},
pages = {107966},
year = {2021},
issn = {0165-1684},
doi = {https://doi.org/10.1016/j.sigpro.2021.107966},
url = {https://www.sciencedirect.com/science/article/pii/S0165168421000050},
author = {Chunlei Wang and Jibin Zheng and Bo Jiu and Hongwei Liu and Yuchun Shi},
keywords = {Long-time coherent integration, Maneuvering target detection, Motion parameter estimation, Deep neural network},
abstract = {Generalized Radon-Fourier transform (GRFT) is a classical long-time coherent integration method for radar maneuvering target detection. GRFT, whose core is to achieve motion parameter estimation via searching, can almost reach the optimal detection performance but heavily suffers from the high computational cost. Motivated by the fact that motion parameter estimation is essentially a non-linear mapping from the radar echo to the target’s motion parameters, one can use a deep neural network (DNN), a kind of modeling tool that can learn complex mappings from training data, to directly realize this mapping, thus alleviating the heavy computational burden brought by the searching efforts. Based on this idea, a DNN-aided long-time coherent integration algorithm, which can be viewed as a fast implementation of GRFT, is proposed in this paper. More specifically, we first use a pre-trained DNN to roughly estimate the motion parameters of the target to be detected from the radar echo, and then accomplish the coherent integration of the target for detection via a fine grid search in the neighborhood of the obtained rough estimation results. Finally, simulation results demonstrate that the proposed algorithm can achieve the detection performance close to that of GRFT but with a much lower computational cost.}
}
@article{HAMADI2020103602,
title = {Comparative study of self tuning, adaptive and multiplexing FTC strategies for successive failures in an Octorotor UAV},
journal = {Robotics and Autonomous Systems},
volume = {133},
pages = {103602},
year = {2020},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2020.103602},
url = {https://www.sciencedirect.com/science/article/pii/S0921889020304425},
author = {Hussein Hamadi and Benjamin Lussier and Isabelle Fantoni and Clovis Francis and Hassan Shraim},
keywords = {Fault-tolerant control, Sliding mode control, Robust control, Multiplexing, Control allocation, Actuator redundancy, Adaptive control, UAV},
abstract = {This paper presents three fault-tolerant control (FTC) strategies for a coaxial octorotor unmanned aerial vehicle (UAV) regarding motor failures. The first FTC is based on a control mixing strategy which consists of a set of control laws designed offline, each one dedicated to a specific fault situation. The second FTC, a robust adaptive sliding mode control allocation is presented, where the control gains of the controller are adjusted online in order to redistribute the control signals among the healthy motors in order to stabilize the overall system. The third FTC strategy is a new strategy proposed in this article, which is based on a self-tuning sliding mode control (STSMC) where the control gains are readjusted based on the detected error to maintain the stability of the system. Multiple indoor experiments on an octorotor UAV are conducted to show and compare the effectiveness and the behavior of each FTC scheme after successive faults are injected. More specifically, we inject complete actuator’s failures into the top four motors of our octorotor. Every strategies show good fault tolerance results, although the control mixing method performs slightly better overall while the adaptive method performs slightly worse. However, the control mixing method requires a huge design effort to take into account as much situations as possible, while the adaptive method and the STSMC only require to determine a few gains. The adaptive method do not need fault detection to operate, but it thus does not provide information on the system’s health without an additional fault identification and diagnosis mechanism, while both the control mixing method and the STSMC provide such information.}
}
@article{DING2021102949,
title = {Detection and tracking of infrared small target by jointly using SSD and pipeline filter},
journal = {Digital Signal Processing},
volume = {110},
pages = {102949},
year = {2021},
issn = {1051-2004},
doi = {https://doi.org/10.1016/j.dsp.2020.102949},
url = {https://www.sciencedirect.com/science/article/pii/S1051200420302943},
author = {Lianghui Ding and Xin Xu and Yuan Cao and Guangtao Zhai and Feng Yang and Liang Qian},
keywords = {Infrared small target, Object detection, Target tracking, Deep learning, Anti-UAV},
abstract = {Infrared imaging has been an efficient anti-drone approach due to its low-cost, anti-interference and all-weather working characteristics. However, the detection of Unmanned Aerial Vehicle (UAV) through infrared camera is still a challenging issue because infrared targets in the field-of-view are usually small and lack of shape and texture features. In this paper, we propose an infrared small target detection and tracking method based on deep learning. We improve the network architecture of Single Shot MultiBox Detector (SSD) for infrared small target detection, called Single Shot MultiBox Detector for Small Target (SSD-ST), by dropping low-resolution layers and enhance high-resolution layer. In addition, in order to further reduce the false alarm rate and improve the precision, we also design an Adaptive Pipeline Filter (APF) based on the temporal correlation and motion information to correct the detection results. We have evaluated our method over a dataset with 16177 infrared images and 30 trajectories. The results show our method is more robust than traditional methods in complex scenes, and achieve a recall rate higher than 90% and a precision higher than 95%, which prove that our method can well complete the detection and tracking task of infrared small targets.}
}
@article{JIN202087,
title = {Deep neural network algorithm for estimating maize biomass based on simulated Sentinel 2A vegetation indices and leaf area index},
journal = {The Crop Journal},
volume = {8},
number = {1},
pages = {87-97},
year = {2020},
issn = {2214-5141},
doi = {https://doi.org/10.1016/j.cj.2019.06.005},
url = {https://www.sciencedirect.com/science/article/pii/S2214514119300881},
author = {Xiuliang Jin and Zhenhai Li and Haikuan Feng and Zhibin Ren and Shaokun Li},
keywords = {Biomass estimation, Maize, Vegetation indices, Deep neural network algorithm, LAI},
abstract = {Accurate estimation of biomass is necessary for evaluating crop growth and predicting crop yield. Biomass is also a key trait in increasing grain yield by crop breeding. The aims of this study were (i) to identify the best vegetation indices for estimating maize biomass, (ii) to investigate the relationship between biomass and leaf area index (LAI) at several growth stages, and (iii) to evaluate a biomass model using measured vegetation indices or simulated vegetation indices of Sentinel 2A and LAI using a deep neural network (DNN) algorithm. The results showed that biomass was associated with all vegetation indices. The three-band water index (TBWI) was the best vegetation index for estimating biomass and the corresponding R2, RMSE, and RRMSE were 0.76, 2.84 t ha−1, and 38.22% respectively. LAI was highly correlated with biomass (R2 = 0.89, RMSE = 2.27 t ha−1, and RRMSE = 30.55%). Estimated biomass based on 15 hyperspectral vegetation indices was in a high agreement with measured biomass using the DNN algorithm (R2 = 0.83, RMSE = 1.96 t ha−1, and RRMSE = 26.43%). Biomass estimation accuracy was further increased when LAI was combined with the 15 vegetation indices (R2 = 0.91, RMSE = 1.49 t ha−1, and RRMSE = 20.05%). Relationships between the hyperspectral vegetation indices and biomass differed from relationships between simulated Sentinel 2A vegetation indices and biomass. Biomass estimation from the hyperspectral vegetation indices was more accurate than that from the simulated Sentinel 2A vegetation indices (R2 = 0.87, RMSE = 1.84 t ha−1, and RRMSE = 24.76%). The DNN algorithm was effective in improving the estimation accuracy of biomass. It provides a guideline for estimating biomass of maize using remote sensing technology and the DNN algorithm in this region.}
}
@article{WANG2020152,
title = {A UAV-assisted CH election framework for secure data collection in wireless sensor networks},
journal = {Future Generation Computer Systems},
volume = {102},
pages = {152-162},
year = {2020},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2019.07.076},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X18325056},
author = {G. Wang and B. Lee and J. Ahn and G. Cho},
keywords = {Unmanned aerial system, Wireless sensor network, Cluster head election, Unmanned aerial vehicle, Security},
abstract = {With the advance of UAV-related technologies, UAV-assisted wireless communications such as UAV-assisted coverage extension, UAV-assisted relaying and UAV-assisted data distribution and collection are gathering a lot of interests from government and industry fields. More specifically, the UAV-assisted data distribution and collection is implemented as a UAV-based WSN (Wireless Sensor Network). In the UAV-based WSN, a CH (Cluster Head) plays a crucial role such as data collection from members, data transfer toward a UAV and data distribution from the UAV to its members. Due to the role of a CH, many attackers try to make their compromised nodes CHs. In the general CH election framework, since each node determines a CH role by itself, compromised nodes declare themselves as a CH regardless of their disqualification. Generally, a compromised CH consumes much more energy than a normal CH because it keeps fulfilling the CH role to deliver corrupted messages to the sink greedily. Inspired by this phenomenon, we propose a UAV-assisted CH election framework which collects residual energy of nodes, and employs them for electing new CHs and excluding the lowest energy nodes from CH candidates. Simulation results show that our framework outperforms the general CH election framework even when the number of compromised nodes is large. Concerning the CH election period, our framework provides better security and performance than the general CH election framework with a short CH election period. Besides, the variation of node compromise time had no impact on our framework’s superiority to the general CH election framework. Another simulation results show that the increase of UAV tour frequency enhances both security and performance of our framework. Our CH election framework is easily applied to a network of IoT devices because the IoT network also demands clustering for energy and data management efficiency. Our future work item is applying as many other CH election schemes as possible to our framework and comparing their security and performance.}
}
@article{AWAIS2021101465,
title = {Remotely sensed identification of canopy characteristics using UAV-based imagery under unstable environmental conditions},
journal = {Environmental Technology & Innovation},
volume = {22},
pages = {101465},
year = {2021},
issn = {2352-1864},
doi = {https://doi.org/10.1016/j.eti.2021.101465},
url = {https://www.sciencedirect.com/science/article/pii/S2352186421001139},
author = {Muhammad Awais and Wei Li and Muhammad Jehanzeb Masud Cheema and Shahid Hussain and Tahani Saad AlGarni and Chenchen Liu and Asad Ali},
keywords = {remote sensing, Precision agriculture, Thermal imagery, Image processing, unstable condition, Thermography, UAV},
abstract = {Water is a crucial element for plant growth, metabolic processes, and general health. Water-deficit, typically simplified by drought stress, is the most critical photosynthetic source of stress that restricts plant growth, crop yield, and food product quality. This research highlights state of the art, possibilities for detecting the canopy temperature by integrating very-high-resolution RGB and thermal imagery from UAV. A multi-rotor drone has assembled by DJI (S900) attached with RGB thermal and cameras was used for experiments. The thermal cameras have a spectral range of 7.5–13μm, a resolution of 640 × 512 pixels, thermal sensitivity of <0.05 °C at ＋30 °C, and a focal length of 25 mm, respectively. UAV flights were operated with DJI ground stations pro software (SZ DJI Technology Co. Ltd., China), using the DJI A3 flight controller. This work aimed to compare the accuracy of canopy temperature and to evaluate the performance of thermography. The extracted CT results were closely related to ground truth CT with the value of (R2) 0.9297 and correlation (r) 0.97702, respectively. The calculated results of CWSI showed a strong relation with gs under different irrigation levels 90%–100%, 75%, 60%, and 50% of the field capacity. The relationship of each time of day was substantial with (R2) 0.90, 0.75, and 0.86, respectively. The Correlation coefficients (R2) of CT, stomatal conductance, and SD were compared and found to be 0.755, 0.67, and 0.695, respectively. Results stated that this approach estimates the most reliable temperature around 35 °C to 40 °C. This study demonstrates the different temperature based spectral indices and provides accurate, rapid, and reliable canopy temperature quantification.}
}
@article{EUGENIO2020100397,
title = {Estimation of soybean yield from machine learning techniques and multispectral RPAS imagery},
journal = {Remote Sensing Applications: Society and Environment},
volume = {20},
pages = {100397},
year = {2020},
issn = {2352-9385},
doi = {https://doi.org/10.1016/j.rsase.2020.100397},
url = {https://www.sciencedirect.com/science/article/pii/S2352938520301646},
author = {Fernando Coelho Eugenio and Mara Grohs and Luan Peroni Venancio and Mateus Schuh and Eduardo Leonel Bottega and Régis Ruoso and Cristine Schons and Caroline Lorenci Mallmann and Tiago Luis Badin and Pablo Fernandes},
keywords = {Precision agriculture, UAV, Artificial intelligence, Predictive modeling, Crop yield},
abstract = {Throughout the plant development, the physiological processes of growth, as well as the handling of water and fertilizers represent sources of variation in the spectral response of the crops. Thus, in the context of precision agriculture, information on the phenological stage of cultivation can be decisive in accurately estimating agronomic variables through the use of aerial images obtained by RPAS (Remotely Piloted Aircraft System) platforms. Therefore, the aim of this study was: i) to investigate the potential of using RPAS embedded with multispectral sensors in order to obtain data on a soybean irrigated field with a central pivot system ii) to identify the best stage of development of irrigated soybean in order to obtain multispectral images aiming to the yield prediction; iii) to test different vegetation indices (VIs) for estimating the yield of soybean crop using artificial neural networks. The treatments were established using different metric water potentials in the soil and the analysis was comprised by 30 sample units. Multispectral images were acquired through a Sequoia® camera aboard the Phantom 4® Pro platform, during seven phenological crop stages. In addition to the spectral bands, nine VIs were taken as predictors based on the response variables derived from the site survey. The selection of the best growth stage was based on the highest level of association, represented by the Spearman correlation coefficient between predictors and each response variable. The Multi-Layer Perceptron (MLP) algorithm was used to adjust the predictive model, whose performance was assessed in terms of training and testing. To have independent measurements of the performance of the proposed algorithm was used by k-fold cross-validation. The results obtained from the correlation between the image-derived data and the soybean yield indicate that the ideal monitoring window for irrigated soybean can be found at the end of the vegetative stage (V6). The selection of the phenological crop stage had a positive impact on the predictions. The MLP models showed a good adjustment and good generalization capability. In turn, grain yield was the most complex agronomic parameter for modeling, with correlations of 0.70 and 0.92 for training/testing, and excellent results in other statistical tests, reinforce the great combining capacity between remote sensing via RPAS and machine learning (ML) in applications aimed at precision agriculture. This approach offers a useful tool for evaluating grain yield in center-pivot-irrigated soybean crops and emphasizes the need of observation regarding the phenological crop stage as a factor of analysis in the prediction of grain yield via remote sensing.}
}
@article{PATACCHIOLA2017132,
title = {Head pose estimation in the wild using Convolutional Neural Networks and adaptive gradient methods},
journal = {Pattern Recognition},
volume = {71},
pages = {132-143},
year = {2017},
issn = {0031-3203},
doi = {https://doi.org/10.1016/j.patcog.2017.06.009},
url = {https://www.sciencedirect.com/science/article/pii/S0031320317302327},
author = {Massimiliano Patacchiola and Angelo Cangelosi},
keywords = {Convolutional Neural Networks, Head pose estimation, Adaptive gradient, Deep learning},
abstract = {Head pose estimation is an old problem that is recently receiving new attention because of possible applications in human-robot interaction, augmented reality and driving assistance. However, most of the existing work has been tested in controlled environments and is not robust enough for real-world applications. In order to handle these limitations we propose an approach based on Convolutional Neural Networks (CNNs) supplemented with the most recent techniques adopted from the deep learning community. We evaluate the performance of four architectures on recently released in-the-wild datasets. Moreover, we investigate the use of dropout and adaptive gradient methods giving a contribution to their ongoing validation. The results show that joining CNNs and adaptive gradient methods leads to the state-of-the-art in unconstrained head pose estimation.}
}
@article{CHIRAYATH2019111475,
title = {Fluid lensing and machine learning for centimeter-resolution airborne assessment of coral reefs in American Samoa},
journal = {Remote Sensing of Environment},
volume = {235},
pages = {111475},
year = {2019},
issn = {0034-4257},
doi = {https://doi.org/10.1016/j.rse.2019.111475},
url = {https://www.sciencedirect.com/science/article/pii/S0034425719304948},
author = {Ved Chirayath and Ron Instrella},
keywords = {Coral reefs, Fluid lensing, Supervised machine learning, Airborne remote sensing, Habitat mapping, American Samoa},
abstract = {A novel NASA remote sensing technique, airborne fluid lensing, has enabled cm-resolution multispectral 3D remote sensing of aquatic systems, without adverse refractive distortions from ocean waves. In 2013, a drone-based airborne fluid lensing campaign conducted over the coral reef of Ofu Island, American Samoa, revealed complex 3D morphological, ecological, and bathymetric diversity at the cm-scale over a regional area. In this paper, we develop and validate supervised machine learning algorithm products tailored for accurate automated segmentation of coral reefs using airborne fluid lensing multispectral 3D imagery. Results show that airborne fluid lensing can significantly improve the accuracy of coral habitat mapping using remote sensing. The machine learning algorithm is based on multidimensional naïve-Bayes maximum a posteriori (MAP) estimation. Provided a user-selected training subset of 3D multispectral images, comprising ~1% of the total dataset, the algorithm separates living structure from nonliving structure and segments the coral reef into four distinct morphological classes – branching coral, mounding coral, basalt rock, and sand. The user-selected training data and algorithm classification results are created and verified, respectively, with sub-cm-resolution ground-truth maps, manually generated from extensive in-situ mapping, underwater gigapixel photogrammetry, and visual inspection of the 3D dataset with subject matter experts. The algorithm generates 3D cm-resolution data products such as living structure and morphology distribution for the Ofu Island coral reef ecosystem with 95% and 92% accuracy, respectively. By comparison, classification of m-resolution remote sensing imagery, representative of the effective spatial resolution of commonly-used airborne and spaceborne aquatic remote sensing instruments subject to ocean wave distortion, typically produces data products with 68% accuracy. These results suggest existing methodologies may not resolve coral reef ecosystems in sufficient detail for accurate determination of percent cover of living structure and morphology breakdown. The methods presented here offer a new remote sensing approach enabling repeatable quantitative ecosystem assessment of aquatic systems, independent of ocean wave distortion and sea state. Aquatic remote sensing imagery, free from refractive distortion, appears necessary for accurate and quantitative health assessment capabilities for coral reef ecosystems at the cm-scale, over regional areas. The accurate and automated determination of percent cover and morphology distribution at cm-resolution may lead to a significantly improved understanding of reef ecosystem dynamics and responses in a rapidly-changing global climate.}
}
@article{SANTANA2022101551,
title = {Computer vision system for superpixel classification and segmentation of sheep},
journal = {Ecological Informatics},
pages = {101551},
year = {2022},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2021.101551},
url = {https://www.sciencedirect.com/science/article/pii/S1574954121003423},
author = {Diego André Sant'Ana and Marcio Carneiro Brito Pache and José Martins and Gilberto Astolfi and Wellington Pereira Soares and Sebastião Lucas Neves {de Melo} and Natália {da Silva Heimbach} and Vanessa Aparecida {de Moraes Weber} and Rodrigo Gonçalves Mateus and Hemerson Pistori},
keywords = {Machine learning, Image processing, Smart farms, Livestock, Convolutional neural network},
abstract = {This paper presents an experiment with four different convolutional neural networks architectures that aim to classify segments of a sheep using a dataset of superpixels. The proposal used an image dataset with 512 images of 32 sheep. In this dataset of images, we applied the Simple Linear Iterative Clustering technique with a K number parameter of 600 to generate the dataset of superpixels that was later processed in the deep neural networks. We selected four architectures for training the models: VGG16, ResNet152V2, InceptionV3, and DenseNet201. The experiment was conducted using cross-validation with five-folds separating the dataset into training (60%), validation (20%), and testing (20%). The best result presented was from the approach with the DenseNet201 technique with an F-score of 0.928. When applying ANOVA, the P-value was 0.0000000000329 (3.29e-11***) between the tested architectures, which shows that the results are statistically significant. Therefore, DenseNet201 presented itself as a relevant architecture for this problem that aims to classify the superpixels referring to a sheep and the image's background, and the average IoU with post-processing for image segmentation with DenseNet201 obtained 0.8332. Thus, we can highlight the contributions of this research as a methodology to segment images of mixed-breed sheep of the Texel and Santa Inês breeds using convolutional neural networks and provide a non-invasive method that can support other implementations such as animal tracking and weight prediction.}
}
@article{YE2020107577,
title = {Offspeeding: Optimal energy-efficient flight speed scheduling for UAV-assisted edge computing},
journal = {Computer Networks},
volume = {183},
pages = {107577},
year = {2020},
issn = {1389-1286},
doi = {https://doi.org/10.1016/j.comnet.2020.107577},
url = {https://www.sciencedirect.com/science/article/pii/S1389128620312196},
author = {Weidu Ye and Junzhou Luo and Feng Shan and Wenjia Wu and Ming Yang},
keywords = {UAV, Edge computing, Data collection, Energy consumption, Flight speed scheduling, Optimal algorithm},
abstract = {Millions of Internet of Thing (IoT) devices have been widely deployed to support applications such as smart city, industrial Internet, and smart transportation. These IoT devices periodically upload their collected data and reconfigure themselves to adapt to the dynamic environment. Both operations are resource consuming for low-end IoT devices. An edge computing enabled unmanned aerial vehicle (UAV) is proposed to fly over to collect data and complete reconfiguration computing tasks from IoT devices. Distinct from most existing work, this paper focuses on flight speed scheduling that allocates proper flight speed to minimize the energy consumption of the UAV with a practical energy model, under the constraints of individual task execution deadlines and communication ranges. We formulate the Energy-Efficient flight Speed Scheduling (EESS) problem, and devise a novel diagram to visualize and analyze this problem. An optimal energy-efficient flight speed scheduling (Offspeeding) algorithm is then proposed to solve the offline version of the EESS problem. Utilizing Offspeeding and the optimal properties obtained from the theoretical analysis, an online heuristic speed scheduling algorithm is developed for more realistic scenarios, where information from IoT devices keeps unknown until the UAV flies close. Finally, simulation results demonstrate our online heuristic is near optimal. This research sheds light on a new research direction, e.g., deadline driven UAV speed scheduling for edge computing with a practical propulsion energy model.}
}
@article{ZHANG2020124,
title = {Classification method of CO2 hyperspectral remote sensing data based on neural network},
journal = {Computer Communications},
volume = {156},
pages = {124-130},
year = {2020},
issn = {0140-3664},
doi = {https://doi.org/10.1016/j.comcom.2020.03.045},
url = {https://www.sciencedirect.com/science/article/pii/S0140366420301766},
author = {Le Zhang and Jinsong Wang and Zhiyong An},
keywords = {Hyperspectral, Remote sensing image, Neural network, Carbon dioxide, Support vector machine},
abstract = {Based on the dimension reduction of hyperspectral remote sensing image, a new neural network method is used to classify the hyperspectral remote sensing image of carbon dioxide in detail. Firstly, the Kernel Principal Component Analysis (KPCA) and Genetic Algorithms (GA) are used to reduce the dimension of hyperspectral remote sensing images; secondly, the traditional remote sensing image classification methods (ISODATA, SVM), traditional neural networks (BP), and new neural networks are used to classify the hyperspectral remote sensing images. Finally, noise assessment method based on local mean and local standard deviation (LMLSD) of spectral image is used to evaluate the classification accuracy. In addition, hyperspectral remote sensing images are dimensionality reduction. Secondly, the comparison between the traditional remote sensing image classification method and the new neural network method is analyzed. Finally, a new neural network method is applied to classify hyperspectral remote sensing images.}
}
@article{WANG2021,
title = {Distributed multi-UAV cooperation for dynamic target tracking optimized by an SAQPSO algorithm},
journal = {ISA Transactions},
year = {2021},
issn = {0019-0578},
doi = {https://doi.org/10.1016/j.isatra.2021.12.014},
url = {https://www.sciencedirect.com/science/article/pii/S0019057821006315},
author = {Yi’an Wang and Kun Li and Ying Han and Xinxin Yan},
keywords = {Multi-UAV, Dynamic target tracking, Trajectory prediction, Quantum Particle Swarm Optimization algorithm, Simulated Annealing algorithm},
abstract = {Real-time tracking of the dynamic intrusion targets consists of two crucial factors: the path forecast of the target and real-time path optimization of multi-UAV target tracking. For the first one, the uncertainty of the target trajectory is an obstacle to realizing real-time tracking. Thus a trajectory prediction method is proposed in this paper to ensure the sampling period of the target. Owing to the poor prediction accuracy of the single-step trajectory, a multi-step Unscented Kalman Filter (MUKF) is proposed to forecast its multi-step trajectory further in different regions. For the second one, there are two problems: poor optimization accuracy of the tracking trajectory and larger local optimization deviation, which will cause failure of the regional tracking. Under this circumstance, a hybrid algorithm called SAQPSO is proposed, combining the specific mechanism of two intelligence algorithms. The annealing mechanism in the Simulated Annealing (SA) algorithm is used to modify the Quantum Particle Swarm Optimization (QPSO) algorithm. Then the characteristic of quantum particles is used to update the population and enhance global searchability. Furthermore, to testify the effectiveness of the trajectory optimization algorithm and related target prediction method, a specific simulation environment is given as an example, in which the tracking trajectories of eight different algorithms are compared. Simulation results show the effectiveness of the proposed algorithm.}
}
@article{YUNGAICELANAULA202264,
title = {Towards security automation in Software Defined Networks},
journal = {Computer Communications},
volume = {183},
pages = {64-82},
year = {2022},
issn = {0140-3664},
doi = {https://doi.org/10.1016/j.comcom.2021.11.014},
url = {https://www.sciencedirect.com/science/article/pii/S0140366421004436},
author = {Noe M. Yungaicela-Naula and Cesar Vargas-Rosales and Jesús Arturo Pérez-Díaz and Mahdi Zareei},
keywords = {Software defined networks, Security automation, Network function virtualization, Machine learning, Deep learning, Reinforcement learning},
abstract = {Software-Defined Networking (SDN) is a modern paradigm that provides a platform for implementing reliable, centrally managed, and automated security solutions for conventional and new generation networks, such as IoT, cloud computing, 5G/6G mobile communication networks, and vehicular communications. In these complex systems, manual security operations can delay or obstruct the identification, mitigation, and prevention of ever-increasing sophisticated threats. Thus, the idea of security automation for networks using the SDN paradigm has become fundamental, given that SDN was created to facilitate the operation and management of complex networks with minimal human intervention, which is considered error-prone. This survey studies the state-of-the-art research efforts concerned with security automation in SDN environments. We identified and ranked various classes of security solutions with different levels of automation and complexity. The level of automation is measured using four well-defined qualitative parameters: self-healing, self-adaptation, self-configuration, and self-optimization. The complexity is characterized by the amount of processing and storage resources and implementation requirements. This work represents the first endeavor to analyze the level of automation and complexity of security solutions in SDN environments. Our findings reveal important advances in the area of security automation in SDN. However, there are still several open problems and challenges, which we detail in this work.}
}
@article{WEINSTEIN2020101061,
title = {Cross-site learning in deep learning RGB tree crown detection},
journal = {Ecological Informatics},
volume = {56},
pages = {101061},
year = {2020},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2020.101061},
url = {https://www.sciencedirect.com/science/article/pii/S157495412030011X},
author = {Ben G. Weinstein and Sergio Marconi and Stephanie A. Bohlman and Alina Zare and Ethan P. White},
keywords = {Tree crown detection, RGB deep learning, Object detection, Airborne LiDAR},
abstract = {Tree crown detection is a fundamental task in remote sensing for forestry and ecosystem ecology. While many individual tree segmentation algorithms have been proposed, the development and testing of these algorithms is typically site specific, with few methods evaluated against data from multiple forest types simultaneously. This makes it difficult to determine the generalization of proposed approaches, and limits tree detection at broad scales. Using data from the National Ecological Observatory Network, we extend a recently developed deep learning approach to include data from a range of forest types to determine whether information from one forest can be used for tree detection in other forests, and explore the potential for building a universal tree detection algorithm. We find that the deep learning approach works well for overstory tree detection across forest conditions. Performance was best in open oak woodlands and worst in alpine forests. When models were fit to one forest type and used to predict another, performance generally decreased, with better performance when forests were more similar in structure. However, when models were pretrained on data from other sites and then fine-tuned using a relatively small amount of hand-labeled data from the evaluation site, they performed similarly to local site models. Most importantly, a model fit to data from all sites performed as well or better than individual models trained for each local site.}
}
@article{MAC2018187,
title = {The development of an autonomous navigation system with optimal control of an UAV in partly unknown indoor environment},
journal = {Mechatronics},
volume = {49},
pages = {187-196},
year = {2018},
issn = {0957-4158},
doi = {https://doi.org/10.1016/j.mechatronics.2017.11.014},
url = {https://www.sciencedirect.com/science/article/pii/S0957415817301770},
author = {Thi Thoa Mac and Cosmin Copot and Robin De Keyser and Clara M. Ionescu},
keywords = {Unmanned aerial vehicles (UAVs), Sensor fusion, Autonomous navigation, Optimal control, Multi-objective particle swarm optimization},
abstract = {This paper presents an autonomous methodology for a low-cost commercial AR.Drone 2.0 in partly unknown indoor flight using only on-board visual and internal sensing. Novelty lies in: (i) the development of a position-estimation method using sensor fusion in a structured environment. This localization method presents how to get the UAV localization states (position and orientation), through a sensor fusion scheme, dealing with data provided by an optical sensor and an inertial measurement unit (IMU). Such a data fusion scheme takes also in to account the time delay present in the camera signal due to the communication protocols; (ii) improved potential field method which is capable of performing obstacle avoiding in an unknown environment and solving the non-reachable goal problem; and (iii) the design and implementation of an optimal proportional - integral - derivative (PID) controller based on a novel multi-objective particle swarm optimization with an accelerated update methodology tracking such reference trajectories, thus characterizing a cascade controller. Experimental results validate the effectiveness of the proposed approach.}
}
@article{SAHRAOUI2022102699,
title = {A cooperative crowdsensing system based on flying and ground vehicles to control respiratory viral disease outbreaks},
journal = {Ad Hoc Networks},
volume = {124},
pages = {102699},
year = {2022},
issn = {1570-8705},
doi = {https://doi.org/10.1016/j.adhoc.2021.102699},
url = {https://www.sciencedirect.com/science/article/pii/S1570870521002006},
author = {Yesin Sahraoui and Chaker Abdelaziz Kerrache and Marica Amadeo and Anna Maria Vegni and Ahmed Korichi and Jamel Nebhen and Muhammad Imran},
keywords = {UAVs, Covid-19, Crowdsensing, Sensors, Internet of Things, Internet of vehicles},
abstract = {The massive increase in population density in cities has led to several urban problems, such as an increment of air pollution, traffic congestion, and a faster spread of infectious diseases. With the rapid innovation in the intelligent sensors technology, and its integration into smart vehicles and Unmanned Aerial Vehicles (UAVs), a novel sensing paradigm has been promoted, namely vehicular crowdsensing, which leverages on-board sensors to capture information from the surrounding environment. Collected data are then analyzed to take proper countermeasures. In this paper, we present a smart coordination mechanism between UAVs and ground vehicles (GVs), which sense information like body temperature and breathing rate of people, in order to support a variety of monitoring applications, including discovering the presence of infectious diseases. In our framework, namely GUAVA, aerial and ground vehicles are equipped with GPS devices and thermal cameras to monitor specific geographic areas, detect humans’ vital parameters and, at the same time, discover duplicate data by identifying matching faces in thermal video sequences with the GaussianFace algorithm. The sensing tasks in hard-to-reach places are assigned to UAVs, with the ability to power up wirelessly from the nearest GV and offload the collected monitoring images to it. Simulation results have assessed our proposed framework, showing good performance in terms of distinct Quality of Service (QoS) metrics.}
}
@article{LIU2019104,
title = {Throughput maximization for UAV-enabled full-duplex relay system in 5G communications},
journal = {Physical Communication},
volume = {32},
pages = {104-111},
year = {2019},
issn = {1874-4907},
doi = {https://doi.org/10.1016/j.phycom.2018.11.014},
url = {https://www.sciencedirect.com/science/article/pii/S1874490718305111},
author = {Xin Liu and Dongyue He and Hua Ding},
keywords = {UAV, Full-duplex relay, Throughput maximization, 5G communications},
abstract = {In areas without infrastructure coverage, unmanned aerial vehicles (UAVs) have made great progress in wireless communication because of its low cost and flexible connectivity. This paper studies a novel mobile relay system, which can obtain the properties of high-mobility and high-performance by adopting an UAV as a relay node. By assuming that the UAV employs full-duplex (FD) and spectrum-efficient trajectory-based decode-and-forward (DF) relay, we study the throughput maximization problem by jointly optimizing UAV trajectory and source/relay transmission power, subject to the constraints on initial/final location, maximum speed and maximum power of the UAV and information-causality of each node in practical situations. It is revealed that there exists a jointly optimal allocation of trajectory and power for the UAV achieved by alternative and iterative algorithm. Numerical results show that by jointly optimizing the trajectory and power, the proposed two UAV-enabled full-duplex relay models are able to obtain significant throughput gains over the conventional static relay.}
}
@article{MAO2021150,
title = {IRS-assisted low altitude passive aerial relaying},
journal = {Computer Communications},
volume = {175},
pages = {150-155},
year = {2021},
issn = {0140-3664},
doi = {https://doi.org/10.1016/j.comcom.2021.05.001},
url = {https://www.sciencedirect.com/science/article/pii/S0140366421001845},
author = {Minghe Mao and Ning Cao and Rui Li and Rui Shi},
keywords = {Equivalent line-of-sight, Intelligent reflecting surface, Outage probability, Passive aerial relaying},
abstract = {This paper studies an unmanned aerial vehicle (UAV) based intelligent reflecting surface (IRS) assisted low altitude passive aerial relaying system. This ensures that more users can be served with better wireless channels. The flexibility of the UAV-based relay carrying the IRS can passively provide better signal-to-noise ratio (SNR) to compensate the performance degradation at the edge of cells or in the period of heavy traffic. In particular, the UAV-based IRS can generate an equivalent line-of-sight (ELoS) channel to transform the conventional Rayleigh fading channel into a Rician fading channel, which will significantly improve the performance of urban mobile communications. Closed-form expression for the outage is derived, and numerical results are presented to demonstrate the performance of the proposed UAV-IRS passive relaying scheme.}
}
@article{WAN2022296,
title = {Adaptive tracking control for an unmanned autonomous helicopter using neural network and disturbance observer},
journal = {Neurocomputing},
volume = {468},
pages = {296-305},
year = {2022},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2021.09.060},
url = {https://www.sciencedirect.com/science/article/pii/S0925231221014387},
author = {Min Wan and Mou Chen and Kenan Yong},
keywords = {Unmanned autonomous helicopter, Neural network, Flight control, Disturbance observer},
abstract = {In this paper, an adaptive tracking control scheme is investigated for a medium scale unmanned autonomous helicopter (UAH) with unknown external disturbances and system uncertainties to achieve improvement on the flight performance. The neural networks (NNs) are employed to compensate the system uncertainties. The second-order disturbance observers are introduced to restrain the compound disturbances which are combined with the NN approximation errors and the external disturbances. Accordingly, the tracking control law is designed for the UAH. The closed-loop stability of the whole UAH system is proved by using Lyapunov function method. Simulation results show that the developed control scheme can effectively solve the tracking control problems of UAH and certainly accomplish strong robustness with respect to the external disturbances and system uncertainties.}
}
@article{SHAO2021100077,
title = {PaFiR: Particle Filter Routing – A predictive relaying scheme for UAV-assisted IoT communications in future innovated networks},
journal = {Internet of Things},
volume = {14},
pages = {100077},
year = {2021},
issn = {2542-6605},
doi = {https://doi.org/10.1016/j.iot.2019.100077},
url = {https://www.sciencedirect.com/science/article/pii/S2542660519301362},
author = {Baohua Shao and Mark S. Leeson},
keywords = {IoT (Internet of Things), Particle Filter, Flying network platform, ONE (Opportunistic Network Environment) simulator},
abstract = {Increasing urbanization, smart cities and other cutting-edge technologies offer the prospect of providing more functions to benefit citizens by relying on the substantial data processing and exchange capabilities now possible. This can generate significant unpredictable and unbalanced data loads for the bearing IoT network to support its application and service demands. We thus propose a wireless routing scheme designed to use the Particle Filter algorithm to empower portable smart devices with intelligent capacities for the radio communication system. This facilitates the offloading of traffic from traditional wireless networks and enables the IoT system to adopt unmanned aerial vehicles, thus also offering further innovation to flying network platforms. The proposed PaFiR routing protocol offers the network more scalability, tolerance and resilience, to achieve the goal of smart relaying. Simulation results that demonstrate the routing algorithm designed offers excellent performance when compared with existing wireless relaying schemes. It provides delivery ratios that are improved by up to 40% without unmanageable increases in latency or overheads.}
}
@article{KWAK2013251,
title = {Optimization of Decentralized Task Assignment for Heterogeneous UAVs},
journal = {IFAC Proceedings Volumes},
volume = {46},
number = {11},
pages = {251-256},
year = {2013},
note = {11th IFAC Workshop on Adaptation and Learning in Control and Signal Processing},
issn = {1474-6670},
doi = {https://doi.org/10.3182/20130703-3-FR-4038.00072},
url = {https://www.sciencedirect.com/science/article/pii/S1474667016329548},
author = {Dong Jun Kwak and Sungwon Moon and Suseong Kim and H. Jin Kim},
keywords = {Multi-agent system, Heterogeneous UAVs, Decentralized task assignment, CBBA},
abstract = {In this paper, the optimization of a decentralized task assignment strategy for heterogeneous UAVs in a probabilistic engagement scenario is investigated. In the engagement scenario, each UAV selects its targets by employing the consensus-based bundle algorithm (CBBA). This paper uses a scoring matrix to reflect heterogeneity among the UAVs and targets with different capabilities. Therefore, a performance improvement of CBBA is closely connected with the scoring matrix and it should be optimally selected. The values of scoring matrix can be obtained by employing an episodic parameter optimization (EPO). The EPO algorithm is performed during the numerous repeated simulation runs of the engagement and the reward of each episode is updated using reinforcement learning. The candidate scoring matrices are selected by using particle swarm optimization. The optimization results show that the team survivability of the UAVs is increased after performing the EPO algorithm and the values of the optimized score matrix are also optimally selected.}
}
@article{YANG2020103199,
title = {Deep convolution neural network-based transfer learning method for civil infrastructure crack detection},
journal = {Automation in Construction},
volume = {116},
pages = {103199},
year = {2020},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2020.103199},
url = {https://www.sciencedirect.com/science/article/pii/S0926580519316000},
author = {Qiaoning Yang and Weimin Shi and Juan Chen and Weiguo Lin},
keywords = {Crack detection, Transfer learning, Deep convolution neural network},
abstract = {Crack detection is critical to guaranteeing safety of bridges, highway and other infrastructures. The deep convolution neural network (DCNN) makes it possible to efficiently and accurately implement image classification, and the accumulated knowledge of DCNN in other domains can be reused for crack detection. In this paper, we propose a transfer learning method based on DCNN to detect cracks. The proposed method models the knowledge learned by DCNN and transfers three kinds of knowledge from other research achievements: sample knowledge, model knowledge and parameter knowledge. New fully connected layers have emerged in the Visual Geometry Group (VGG) network as a new learning framework for crack detection. The performance and validity of the proposed method are verified. Compared with other detection methods, the proposed method can detect many kinds of cracks with a high detection accuracy. The detection accuracy for CCIC [24] is 99.83%, that for BCD [25] is 99.72%, and that for SDNET [45] is 97.07%. The accumulated knowledge in this method can also be transferred to other research work.}
}
@article{NIU2020103068,
title = {UAV track planning based on evolution algorithm in embedded system},
journal = {Microprocessors and Microsystems},
volume = {75},
pages = {103068},
year = {2020},
issn = {0141-9331},
doi = {https://doi.org/10.1016/j.micpro.2020.103068},
url = {https://www.sciencedirect.com/science/article/pii/S0141933120300582},
author = {Xi Niu and Xiaodong Yuan and Yongwei Zhou and Hehua Fan},
keywords = {Embedded system, UAV, Track planning, Evolution algorithm},
abstract = {The embedded controller is small in size and powerful in computing power, and can quickly complete the related processing and calculation of flight attitude and track planning data. Wireless data transmission can realize a long-distance data transmission between the aircraft command center and the airborne control platform. Based on the data fusion algorithm of the Kalmánz filter, the data collected by multiple sensors can be integrated, which can effectively reduce the measurement noise amplitude. At the same time, the cumulative error of a single sensor is reduced. In order to solve the problems of ant colony algorithm in case it is easy to fall into the local extremum and the convergence speed is slow, an improved ant colony algorithm for 3D navigation of unmanned aerial vehicles is proposed for trace planning. This study divides the three-dimensional track planning into two parts based on the improved ant colony algorithm for two-dimensional plane planning and height planning. Geometric optimization methods to enhance the guidance of ant search are used. According to the distance and height constraints between the track point and the threat source, the altitude of the track points to plan the 3D track of the drone is calculated and adjusted. At the same time, the adaptive parameter adjustment method is used to improve the ant colony search ability and the interaction ability between individuals, and effectively get rid of the situation to avoid to falling into a local optimum. In addition, the index function is established and the path is smoothed. Simulation results show that the proposed improved algorithm cannot only safely avoid threats in the three-dimensional environment, but also has the ability to find the optimal solution and the convergence speed is better than the original algorithm.}
}
@article{NOBAHARI2020103629,
title = {Multiple model extended continuous ant colony filter applied to real-time wind estimation in a fixed-wing UAV},
journal = {Engineering Applications of Artificial Intelligence},
volume = {92},
pages = {103629},
year = {2020},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2020.103629},
url = {https://www.sciencedirect.com/science/article/pii/S0952197620300890},
author = {Hadi Nobahari and Alireza Sharifi},
keywords = {Multiple model filter, Heuristic filter, Extended Continuous Ant Colony Filter, Multiple model wind estimation, Hardware in the loop},
abstract = {In this study, a new heuristic multiple model filter, called Multiple Model Extended Continuous Ant Colony Filter, is proposed to solve a nonlinear multiple model state estimation problem. In this filter, a bank of extended continuous ant colony filters are run in parallel to solve the multiple model estimation problem. The probability of each model is continually updated and consequently both the true model and the states of the nonlinear system are updated based on the weighted sum of the filters. The new multiple model filter is tested on an engineering problem. The problem is to estimate simultaneously the states of a fixed-wing unmanned aerial vehicle as well as the wind model, applied to the system. Four different wind models are considered and the proposed filter is unaware of the wind type. Then, observability of the states and the wind components are analyzed. Four new propositions are introduced and proved for unknown input observability, state and unknown input observability, the effect of time-varying unknown input matrix on the unknown input observability, and the effect of linearization errors on the state observability. Moreover, observability of the wind parameters is analyzed based on the nonlinear systems observability theory. Performance of the proposed filter is also evaluated in maneuvering flight and compared to a single extended continuous ant colony filter and a multiple model extended Kalman filter. A hardware-in-the-loop experiment is also performed to verify the real-time implementation capability of the suggested architecture.}
}
@article{TRAN2021100156,
title = {Hybrid adaptive negative imaginary- neural-fuzzy control with model identification for a quadrotor},
journal = {IFAC Journal of Systems and Control},
volume = {16},
pages = {100156},
year = {2021},
issn = {2468-6018},
doi = {https://doi.org/10.1016/j.ifacsc.2021.100156},
url = {https://www.sciencedirect.com/science/article/pii/S2468601821000110},
author = {Vu Phi Tran and Mohamed A. Mabrok and Matthew A. Garratt and Ian R. Petersen},
keywords = {Strictly Negative Imaginary controller, Neural-Fuzzy controller, Hybrid control, Online identification, Quadcopter unmanned aerial vehicle, Uncertainties},
abstract = {Quadrotor system is subject to multiple disturbances, including both internal and external effects (e.g. wind gusts, coupling effects, and unmodeled dynamics). For example, severe wind disturbances may significantly degrade trajectory tracking during the flight of autonomous aerial vehicles, or even cause loss of control or failure of a tracking mission. This paper introduces a robust hybrid control system, including a linear Strictly Negative Imaginary (SNI) controller and an adaptive nonlinear Neural-Fuzzy control law, to enable high-precision trajectory tracking tasks for a quadcopter drone. Based on a parallel form, both proposed controllers are able to enhance the transient performance, the system response, and the robustness of the quadcopter controllers. Also, a linear time-invariant SNI UAV dynamic model, in combination with an online adaptive residual nonlinear model using the neural network identification, is proposed to model the natural behavior of a quadcopter system. Through a series of numerical simulations, this paper highlights the effectiveness of our hybrid controller in the face of some parameter variations, such as nonlinear aerodynamic models and exogenous disturbances (e.g., wind gusts). Moreover, it compares its tracking performance with that of a fixed-gain SNI controller and the adaptive Neural-Fuzzy controller separately. Finally, the stability of the closed-loop control system is also discussed using the SNI theorem.}
}
@article{QUINTIN20178037,
title = {Use of Co-operative UAVs to Support/Augment UGV Situational Awareness and/or Inter-Vehicle Communications},
journal = {IFAC-PapersOnLine},
volume = {50},
number = {1},
pages = {8037-8044},
year = {2017},
note = {20th IFAC World Congress},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2017.08.1229},
url = {https://www.sciencedirect.com/science/article/pii/S2405896317317354},
author = {F. Quintin and S. Iovino and A. Savvaris and A. Tsourdos},
keywords = {Co-operative UAVs, Multiple-depots vehicle routing problem, path planning, vehicle routing problem with moving depots, TABU search meta-heuristic},
abstract = {This paper presents the development of a path-planning algorithm for Unmanned Aerial Vehicles (UAVs) in order to increase the situational awareness for platooning vehicles. The scenario considers a team of cooperative UAVs, initially docked on moving Unmanned Ground Vehicles (UGVs). In particular, the goal consists in finding the best routing plan for the UAVs in order to visit some designated targets in a wide search area to augment the UGVs’ situational awareness. Taking into account the maximal endurance constraint of the UAVs, this problem becomes equivalent to a time-constrained multiple depot vehicle routing problem with moving depots. To tackle this variant of the well-known vehicle routing problem, a methodology based on a TABU search meta-heuristic is implemented. While respecting the endurance constraint, this methodology tempts to optimize multiple objectives: the number of UAVs required, the total length of the routing and the balance of the lengths of the different routes within the routing plan. The proposed approach based on a meta-heuristic gives relevant results in a relatively short period of time.}
}
@article{IP2018376,
title = {Big data and machine learning for crop protection},
journal = {Computers and Electronics in Agriculture},
volume = {151},
pages = {376-383},
year = {2018},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2018.06.008},
url = {https://www.sciencedirect.com/science/article/pii/S0168169917314588},
author = {Ryan H.L. Ip and Li-Minn Ang and Kah Phooi Seng and J.C. Broster and J.E. Pratley},
keywords = {Big data, Machine learning, Crop protection, Weed control, Herbicide resistance, Markov random field model},
abstract = {Crop protection is the science and practice of managing plant diseases, weeds and other pests. Weed management and control are important given that crop yield losses caused by pests and weeds are high. However, farmers face increased complexity of weed control due to evolved resistance to herbicides. This paper first presents a brief review of some significant research efforts in crop protection using Big data with the focus on weed control and management followed by some potential applications. Some machine learning techniques for Big data analytics are also reviewed. The outlook for Big data and machine learning in crop protection is very promising. The potential of using Markov random fields (MRF) which takes into account the spatial component among neighboring sites for herbicide resistance modeling of ryegrass is then explored. To the best of our knowledge, no similar work of modeling herbicide resistance using the MRF has been reported. Experiments and data analytics have been performed on data collected from farms in Australia. Results have revealed the good performance of our approach.}
}
@article{ZHANG2021117618,
title = {Retrieval of water quality parameters from hyperspectral images using a hybrid feedback deep factorization machine model},
journal = {Water Research},
volume = {204},
pages = {117618},
year = {2021},
issn = {0043-1354},
doi = {https://doi.org/10.1016/j.watres.2021.117618},
url = {https://www.sciencedirect.com/science/article/pii/S0043135421008137},
author = {Yishan Zhang and Lun Wu and Licui Deng and Bin Ouyang},
keywords = {Hyperspectral images, Water quality monitoring, Deep learning, Spectral unmixing, Spatial distribution analysis},
abstract = {Environmental protection of water resources is of critical importance to daily life of human beings. In recent years, monitoring the variation of water quality using remote sensing techniques has become prevalent. Unmanned aerial vehicle (UAV) based remote sensing techniques have been applied to quantitative retrieval of concentrations of water quality parameters including phosphorus, nitrogen, chemical oxygen demand (COD), biochemical oxygen demand (BOD), and chlorophyll a (Chl-a), successfully and efficiently. In this study, a novel method with deep factorization machine, spatial distribution pattern analysis, and probabilistic analysis engaged, named hybrid feedback deep factorization machine (HF-DFM), has been developed to quantitatively estimate concentrations of water quality parameters based on hyperspectral reflectance data on large scale effectively. Our proposed method is a unified model for quantifying concentrations of water quality parameters with an end to end structure, which integrates UAV based optical remote sensing techniques and deep learning to estimate concentrations of water quality parameters. Furthermore, our proposed model was applied to real-time quantitative monitoring the variation of water quality of Mazhou River, Shenzhen, Guangdong, China. Finally, we evaluate the performance of proposed model on a real-world dataset in terms of root of mean squared error (RMSE), mean absolute percent error (MAPE), and coefficient of determination (R2). The experimental results show that our proposed model outperforms other state-of-the-art models with respect to RMSE, MAPE, and R2, where resulting MAPEs for quantifying all water quality parameters range from 8.78% to 12.36%, and resulting R2s range from 0.81 to 0.93. It can serve as a useful tool for decision makers in effectively monitoring water quality of urban rivers.}
}
@article{SHI2021102427,
title = {Throughput-aware path planning for UAVs in D2D 5G networks},
journal = {Ad Hoc Networks},
volume = {116},
pages = {102427},
year = {2021},
issn = {1570-8705},
doi = {https://doi.org/10.1016/j.adhoc.2021.102427},
url = {https://www.sciencedirect.com/science/article/pii/S157087052100010X},
author = {Lin Shi and Zhongyi Jiang and Shoukun Xu},
keywords = {UAV, 5G network, QoS, Path planning, Device-to-Device},
abstract = {Unmanned Ariel Vehicles (UAVs) face increasing challenges in obtaining sensory data and transferring them to the user even before the completion of their flight for time-critical processing. Traditionally bounded by only area coverage and battery capacity, UAVs now need to meet network QoS requirement when streaming data. The emergence of 5G Device-to-Device (D2D) Networks enables high speed network communication for UAVs to transfer data via D2D links during a flight. The planning of UAV flight paths is now subject to both battery capacity and network quality of service (QoS) constraints. In this paper, we focus on the path planning for UAVs, which stream data to a data receiver machine, under the constraints of full area coverage and network throughput. We present a mathematical model to formulate the issue as a combinatorial optimization problem that attempts to minimize the flight cost of multiple UAVs covering the entire area. We show that the problem is NP-hard, therefore propose a heuristic method to derive the number of UAVs and determine their flight paths. The solution is proved to be bound by K⋅OPT. We conduct simulations to evaluate how the size of the area and the maximal flight distance of a UAV affect the number of UAVs needed, and how the D2D channel parameters affect the link throughputs.}
}
@article{PUSTOKHIN2021107376,
title = {Optimal deep learning approaches and healthcare big data analytics for mobile networks toward 5G},
journal = {Computers & Electrical Engineering},
volume = {95},
pages = {107376},
year = {2021},
issn = {0045-7906},
doi = {https://doi.org/10.1016/j.compeleceng.2021.107376},
url = {https://www.sciencedirect.com/science/article/pii/S0045790621003451},
author = {Denis A. Pustokhin and Irina V. Pustokhina and Poonam Rani and Vineet Kansal and Mohamed Elhoseny and Gyanendra Prasad Joshi and K. Shankar},
keywords = {5G networking, Big data analytics, Map reduce, Disease diagnosis, Feature selection},
abstract = {Recent developments in wireless networking, big data technologies like 5G networks, healthcare big data analytics, Internet of Things (IoT) and other advanced technologies in wearables and Artificial Intelligence (AI) have enabled the development of intelligent disease diagnosis models. The current study devises a new big data analytic-based feature selection and Deep Belief Network (DBN)-based disease diagnostic model. To reduce the number of features and curse of dimensionality, a Link-based Quasi Oppositional Binary Particle Swarm Optimization Algorithm is used in feature selection to narrow down an optimal set of features. The application of quasi-oppositional mechanism in BPSO algorithm helps in increasing the convergence rate. Followed by, the DBN model is applied as a classifier to diagnose the existence of disease from feature-reduced data. A series of experiments was conducted to emphasize the performance of the presented model. The obtained experimental outcomes showcased that the presented model yielded better results in several aspects.}
}
@article{C2021104313,
title = {Onboard target detection in hyperspectral image based on deep learning with FPGA implementation},
journal = {Microprocessors and Microsystems},
volume = {85},
pages = {104313},
year = {2021},
issn = {0141-9331},
doi = {https://doi.org/10.1016/j.micpro.2021.104313},
url = {https://www.sciencedirect.com/science/article/pii/S0141933121004749},
author = {Sherin Shibi C and Gayathri R},
keywords = {Hyperspectral image, Image classification, Computational complexity, Locality preserving discriminative broad learning, FPGA implementation},
abstract = {Onboard target detection of Hyperspectral Imagery (HSI) is widely adopted in the field of remote sensing. It requires high detection accuracy and low computational complexity for processing a large volume of HSI data. In this study, a Locally Preserving Discriminative Broad Learning (LPDBL) was introduced for target detection due to its simple, excellent generalization ability, and its competitive performance. The detection was done through spatial-spectral information, band selection, and estimation of the covariance matrix. The fisher discriminant method was used to reduce the dimension of HSI data. Weights was adjusted through manifold regularization in order to enhance the detection ability of the proposed method. To study the performance of the proposed LPDBL, experiment was conducted on two different datasets of HSI. The results revealed that the proposed method performed better and suitable for target detection. The LPDBL was implemented on Virtex-7 Field Programmable Gate Array (FPGA) board. Furthermore, the LPDBL technique was practically validated by two different techniques such as a broad learning system (BLS) and Automatic Target Detection in HSI (ATD-HSI). The result obtained from the FPGA was very close to the actual target position.}
}
@article{POSEWSKY2018151,
title = {Throughput optimizations for FPGA-based deep neural network inference},
journal = {Microprocessors and Microsystems},
volume = {60},
pages = {151-161},
year = {2018},
issn = {0141-9331},
doi = {https://doi.org/10.1016/j.micpro.2018.04.004},
url = {https://www.sciencedirect.com/science/article/pii/S014193311730296X},
author = {Thorbjörn Posewsky and Daniel Ziener},
keywords = {Deep neural networks, Batch processing, Pruning, Compression, FPGA, Inference, Throughput optimizations, Fully-connected},
abstract = {Deep neural networks are an extremely successful and widely used technique for various pattern recognition and machine learning tasks. Due to power and resource constraints, these computationally intensive networks are difficult to implement in embedded systems. Yet, the number of applications that can benefit from the mentioned possibilities is rapidly rising. In this paper, we propose novel architectures for the inference of previously learned and arbitrary deep neural networks on FPGA-based SoCs that are able to overcome these limitations. Our key contributions include the reuse of previously transferred weight matrices across multiple input samples, which we refer to as batch processing, and the usage of compressed weight matrices, also known as pruning. An extensive evaluation of these optimizations is presented. Both techniques allow a significant mitigation of data transfers and speed-up the network inference by one order of magnitude. At the same time, we surpass the data throughput of fully-featured x86-based systems while only using a fraction of their energy consumption.}
}
@article{LOPEZGUEDE2015116,
title = {A L-MCRS dynamics approximation by ELM for Reinforcement Learning},
journal = {Neurocomputing},
volume = {150},
pages = {116-123},
year = {2015},
note = {Bioinspired and knowledge based techniques and applications The Vitality of Pattern Recognition and Image Analysis Data Stream Classification and Big Data Analytics},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2014.01.076},
url = {https://www.sciencedirect.com/science/article/pii/S0925231214012442},
author = {Jose Manuel Lopez-Guede and Borja Fernandez-Gauna and Jose Antonio Ramos-Hernanz},
keywords = {Extreme learning machines, Linked multicomponent robotic systems, Hose control, Reinforcement learning},
abstract = {Autonomous task learning for Linked Multicomponent Robotic Systems (L-MCRS) is an open research issue. Pilot studies applying Reinforcement Learning (RL) on Single Robot Hose Transport (SRHT) task need extensive simulations of the L-MCRS involved in the task. The Geometrically Exact Dynamic Spline (GEDS) simulator used for the accurate simulation of the dynamics of the overall system is a time expensive process, so that it is infeasible to carry out extensive learning experiments based on it. In this paper we address the problem of learning the dynamics of the L-MCRS encapsulated on the GEDS simulator using an Extreme Learning Machine (ELM) approach. Profiting from the adaptability and flexibility of the ELMs, we have formalized the problem of learning the hose geometry as a multi-variate regression problem. Empirical evaluation of this strategy achieves remarkable accurate approximation results.}
}
@article{DONATEO2015119,
title = {Sizing and Simulation of a Piston-prop UAV},
journal = {Energy Procedia},
volume = {82},
pages = {119-124},
year = {2015},
note = {70th Conference of the Italian Thermal Machines Engineering Association, ATI2015},
issn = {1876-6102},
doi = {https://doi.org/10.1016/j.egypro.2015.12.003},
url = {https://www.sciencedirect.com/science/article/pii/S1876610215026521},
author = {Teresa Donateo and Luigi Spedicato and Gianluca Trullo and A. Paolo Carlucci and Antonio Ficarella},
keywords = {diesel engine, aircraft, 1D modeling, performance maps},
abstract = {A sizing and simulation platform has been developed for the optimization of advanced configurations for aircrafts including, but not limited to, more electric, hybrid-electric, turbo-compound piston engines and fuel cell systems. In the present investigation the software has been applied to the simulation of a medium-altitude, medium-endurance unmanned aerial vehicle (UAV) equipped with a two-stroke diesel engine with a single stage turbo-compressor. The engine was simulated with a 1D code (AVL-Boost) taking into account several values of speed, air-fuel ratio and flight altitude. The behavior of the waste-gate valve at the different flight levels was also accounted for. The Willans line method is used to obtain the seal level and in flight performance map of scaled engines with the same configuration. The power requests of a reference 128kW engine and two scaled engines along the mission have been compared with the available power to discuss the potentiality of hybrid electric and turbo-compound configurations.}
}
@article{SUN2022149805,
title = {Monitoring water quality using proximal remote sensing technology},
journal = {Science of The Total Environment},
volume = {803},
pages = {149805},
year = {2022},
issn = {0048-9697},
doi = {https://doi.org/10.1016/j.scitotenv.2021.149805},
url = {https://www.sciencedirect.com/science/article/pii/S0048969721048804},
author = {Xiao Sun and Yunlin Zhang and Kun Shi and Yibo Zhang and Na Li and Weijia Wang and Xin Huang and Boqiang Qin},
keywords = {Proximal remote sensing, Water quality, Machine learning algorithms, BP neural networks, Empirical algorithms},
abstract = {Accurate, high spatial and temporal resolution water quality monitoring in inland waters is vital for environmental management. However, water quality monitoring in inland waters by satellite remote sensing remains challenging due to low signal-to-noise ratios (SNRs) and instrumental resolution limitations. We propose the concept of proximal remote sensing for monitoring water quality. The proximal hyperspectral imager, developed by Nanjing Institute of Geography and Limnology, Chinese Academy of Sciences (CAS) and Hikvision Digital Technology, Ltd., is a high spatial, temporal and spectral resolution (1 nm) sensor for continuous observation, allowing for effective and practical long-term monitoring of inland water quality. In this study, machine learning and empirical algorithms were developed and validated using in situ total nitrogen (TN), total phosphorus (TP), chemical oxygen demand (COD) concentrations and spectral reflectance from Lake Taihu (N = 171), the Liangxi River (N = 94) and the Fuchunjiang Reservoir (N = 109) covering different water quality. Our dataset includes a large range for three key water quality parameters of TN from 0.93 to 6.46 mg/L, TP from 0.04 to 0.62 mg/L, and COD from 1.32 to 15.41 mg/L. Overall, the back-propagation (BP) neural network model had an accuracy of over 80% for TN (R2 = 0.84, RMSE = 0.33 mg/L, and MRE = 11.4%) and over 90% for TP (R2 = 0.93, RMSE = 0.02 mg/L, and MRE = 12.4%) and COD (R2 = 0.91, RMSE = 0.66 mg/L, and MRE = 9.3%). Our results show that proximal remote sensing combined with machine learning algorithms has great potential for monitoring water quality in inland waters.}
}
@article{MADOKORO2018462,
title = {Non-Rectangular RoI Extraction and Machine Learning Based Multiple Object Recognition Used for Time-Series Areal Images Obtained Using MAV},
journal = {Procedia Computer Science},
volume = {126},
pages = {462-471},
year = {2018},
note = {Knowledge-Based and Intelligent Information & Engineering Systems: Proceedings of the 22nd International Conference, KES-2018, Belgrade, Serbia},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2018.07.280},
url = {https://www.sciencedirect.com/science/article/pii/S1877050918312560},
author = {Hirokazu Madokoro and Asahi Kainuma and Kazuhito Sato},
keywords = {object recognition, micro air vehicle (MAV), region of interest (RoI), self-organizing map (SOMs), counter propagation networks (CPNs)},
abstract = {This paper presents a novel method to recognize multiple objects from aerial scene images obtained using a micro air vehicle (MAV). As a robot vision extended platform, MAVs measure objects in time-series images obtained from various angles and altitudes with advanced outstanding active vision characteristics. The proposed method consists of four major steps: region of interest (RoI) extraction using binarized normed gradients (BING), feature point detection and description using accelerated-KAZE (AKAZE), generation of codebook as histogram features quantized using self-organizing map (SOMs), and semantic recognition of multiple objects using category maps created using counter propagation networks (CPNs). We obtained five datasets of time-series aerial images at an atrium while flying a MAV manually. The original video images were downsampled from 30 fps to 1 fps in consideration of calculation cost and appearance changes between frames. We annotated ground truth (GT) labels to all images used for teaching signals for learning and validation signals for testing. Experimentally obtained results with leave-one-out cross-validation (LOOCV) revealed the mean recognition accuracy for all datasets as 71.96%. For each dataset, the maximum and minimum recognition accuracies were, respectively, 77.26% in Dataset 3 and 65.25% in Dataset 2.}
}
@article{SPENCER2019199,
title = {Advances in Computer Vision-Based Civil Infrastructure Inspection and Monitoring},
journal = {Engineering},
volume = {5},
number = {2},
pages = {199-222},
year = {2019},
issn = {2095-8099},
doi = {https://doi.org/10.1016/j.eng.2018.11.030},
url = {https://www.sciencedirect.com/science/article/pii/S2095809918308130},
author = {Billie F. Spencer and Vedhus Hoskere and Yasutaka Narazaki},
keywords = {Structural inspection and monitoring, Artificial intelligence, Computer vision, Machine learning, Optical flow},
abstract = {Computer vision techniques, in conjunction with acquisition through remote cameras and unmanned aerial vehicles (UAVs), offer promising non-contact solutions to civil infrastructure condition assessment. The ultimate goal of such a system is to automatically and robustly convert the image or video data into actionable information. This paper provides an overview of recent advances in computer vision techniques as they apply to the problem of civil infrastructure condition assessment. In particular, relevant research in the fields of computer vision, machine learning, and structural engineering is presented. The work reviewed is classified into two types: inspection applications and monitoring applications. The inspection applications reviewed include identifying context such as structural components, characterizing local and global visible damage, and detecting changes from a reference image. The monitoring applications discussed include static measurement of strain and displacement, as well as dynamic measurement of displacement for modal analysis. Subsequently, some of the key challenges that persist toward the goal of automated vision-based civil infrastructure and monitoring are presented. The paper concludes with ongoing work aimed at addressing some of these stated challenges.}
}
@article{NYAMEKYE2021e07080,
title = {Evaluating the spatial and temporal variations of aquatic weeds (Biomass) on Lower Volta River using multi-sensor Landsat Images and machine learning},
journal = {Heliyon},
volume = {7},
number = {5},
pages = {e07080},
year = {2021},
issn = {2405-8440},
doi = {https://doi.org/10.1016/j.heliyon.2021.e07080},
url = {https://www.sciencedirect.com/science/article/pii/S240584402101183X},
author = {Clement Nyamekye and Samuel Anim Ofosu and Richard Arthur and Gabriel Osei and Linda Boamah Appiah and Samuel Kwofie and Benjamin Ghansah and Dieter Bryniok},
keywords = {Water hyacinth, Bioenergy, Multi-sensor, Random forest},
abstract = {Aquatic invasive weeds affect hydrological, ecological, and socio-economic activities on freshwater ecosystems. On the Lower Volta River (LVR) of Ghana, invasive aquatic weeds have been known to be nuisance to fishing, navigation, aquaculture, hydropower production and other agricultural practices in the area. While information on the spatial and temporal distribution of aquatic weeds would be beneficial in improving weed management and control measures on the river, such information is very scanty. Also, these aquatic weeds are also biomass resources, that can be transformed to bioenergy. Thus, this study evaluated the spatial and temporal variations of aquatic weeds on the Lower Volta River, and assessed their potential biomass for bioenergy production. Random Forest (RF) algorithm and Landsat images were used to map the distribution of the weeds in 1975, 2003, and 2020, respectively. Accuracy assessment results showed mean Overall Accuracy (OA) of 83.44% and mean User Accuracy (UA) of 79.24%. The results indicated that as of 1975, aquatic weeds covered only 1495 ha and appeared in some specific locations such as Kpong and Ada. However, by 2003, the weeds had spread to most parts of the river covering 5600 ha, which was an increase of approximately 4-fold within a period of 28 years. The area covered by the weeds, however declined by 1505 ha between 2003 and 2020. Thus, in 2020, water hyacinth covered about 36% of the aquatic weeds relative to 28% in 2003. The results showed that, the quantity of the water hyacinth biomass per unit area was 21.5 kg/m2. This result can also be used as the basis for resource assessment as well as determination of its viability for bioenergy production and strategies for its modern utilisation. The conversion of water hyacinth into bioenergy remains one of the best aquatic weed management strategies that must be adopted in LVR.}
}
@article{ZHANG2021105909,
title = {State and parameter estimation of the AquaCrop model for winter wheat using sensitivity informed particle filter},
journal = {Computers and Electronics in Agriculture},
volume = {180},
pages = {105909},
year = {2021},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2020.105909},
url = {https://www.sciencedirect.com/science/article/pii/S0168169920331148},
author = {Tianxiang Zhang and Jinya Su and Cunjia Liu and Wen-Hua Chen},
keywords = {Particle filter, Sensitivity analysis, Machine learning, Multispectral image, Unmanned Aerial Vehicle},
abstract = {Crop models play a paramount role in providing quantitative information on crop growth and field management. However, its prediction performance degrades significantly in the presence of unknown, uncertain parameters and noisy measurements. Consequently, simultaneous state and parameter estimation (SSPE) for crop model is required to maximize its potentials. This work aims to develop an integrated dynamic SSPE framework for the AquaCrop model by leveraging constrained particle filter, crop sensitivity analysis and UAV remote sensing. Both Monte Carlo simulation and one winter wheat experimental case study are performed to validate the proposed framework. It is shown that: (i) the proposed framework with state/parameter bound and parameter sensitivity information outperforms conventional particle filter and constrained particle filter in both state and parameter estimation in Monte Carlo simulations; (ii) in real-world experiment, the proposed approach achieves the smallest root mean squared error for canopy cover estimation among the three algorithms by using day forward-chaining validation method.}
}
@article{LIU20202430,
title = {High precision detection algorithm based on improved RetinaNet for defect recognition of transmission lines},
journal = {Energy Reports},
volume = {6},
pages = {2430-2440},
year = {2020},
issn = {2352-4847},
doi = {https://doi.org/10.1016/j.egyr.2020.09.002},
url = {https://www.sciencedirect.com/science/article/pii/S2352484720312907},
author = {Jun Liu and Rong Jia and Wei Li and Fuqi Ma and Heba M. Abdullah and Hengrui Ma and Mohamed A. Mohamed},
keywords = {Transmission line defects, Convolutional neural network, RetinaNet, DenseNet, Intelligent identification},
abstract = {The Unmanned Aerial Vehicle (UAV) inspection mode has been gradually implemented in the power system. The UAV inspection image is checked by the target detection technology, but there is no high-precision target detection algorithm as the technical support. In this regard, this paper proposes a target detection algorithm based on the improved RetinaNet which is suitable for transmission lines defect detection. In this algorithm, the shortcomings of the RetinaNet anchor frame extraction mechanism based on Apriori are corrected. At the same time, the number and size of anchor frames are redesigned by using the improved K-means + + algorithm, so that the anchor frame of the improved algorithm gets the highest average IoU (Intersection over Union) value, which matches the actual size of the transmission line defects. Then, in RetinaNet, the feature pyramid network based on DenseNet is built as the backbone network to improve the model accuracy and make the model lighter. The improved model is trained and tested by using the data set of transmission line defects for validation. The results show that the proposed method has advantages and effectiveness in the detection of transmission line defects, and meets the requirements of intelligent inspection in terms of accuracy.}
}
@article{LIN2021112299,
title = {Quality control and crop characterization framework for multi-temporal UAV LiDAR data over mechanized agricultural fields},
journal = {Remote Sensing of Environment},
volume = {256},
pages = {112299},
year = {2021},
issn = {0034-4257},
doi = {https://doi.org/10.1016/j.rse.2021.112299},
url = {https://www.sciencedirect.com/science/article/pii/S0034425721000171},
author = {Yi-Chun Lin and Ayman Habib},
keywords = {Unmanned aerial vehicles, Multi-temporal LiDAR point clouds, Quality control, Field-based phenotyping, Relative accuracy, Row/alley detection, Plot extraction},
abstract = {Recent developments in remote sensing are enabling automatic, high resolution, and non-destructive survey of agriculture fields, providing the key basis for advancing plant breeding. Among the used remote sensing modalities, LiDAR has attracted wide attention for its ability to directly provide accurate 3D information. Despite the increasing utilization of LiDAR technology in phenotyping, there is still a lack of effective quality control strategies, in particular, quality control of LiDAR data collected on a multi-temporal basis. This study proposes a targetless framework for multi-temporal LiDAR data quality control and crop characterization in mechanized agricultural fields. Features extracted from the fields – terrain patches and row/alley locations – are utilized for evaluating the vertical and planimetric relative accuracy of the point clouds. Row/alley locations in the field are automatically identified from the point clouds based on the assumption that higher point density and/or higher elevation correspond to plant locations. The performance of the proposed quality control strategies is evaluated using multi-temporal datasets collected in agricultural fields of different sizes, orientation, crops, and growth stages. The result shows that the net vertical and planimetric discrepancies between multi-temporal point clouds are ±3 cm and ±8 cm, respectively. While the former reflects the actual accuracy of the point clouds, the latter is a combined effect of the LiDAR point cloud accuracy, rasterization artifacts, crop type, growth pattern, and wind condition during data acquisition. In terms of row and alley detection, the result shows that the proposed strategy achieves high performance and can deal with different planting orientation, crop types, growth stages, canopy cover, and planting density. In conclusion, this study presents a quality control framework for multi-temporal LiDAR data. Moreover, the row and alley detection leads to automated extraction of plots, and hence facilitates the use of remotely sensed data for automated phenotyping.}
}
@article{RUI2021107007,
title = {Research on fast natural aerial image mosaic},
journal = {Computers & Electrical Engineering},
volume = {90},
pages = {107007},
year = {2021},
issn = {0045-7906},
doi = {https://doi.org/10.1016/j.compeleceng.2021.107007},
url = {https://www.sciencedirect.com/science/article/pii/S004579062100032X},
author = {Ting Rui and Yucheng Hu and Chengsong Yang and Dong Wang and Xun Liu},
keywords = {UAV images, Image mosaic, RSIFT, Ghosting elimination, Scale invariance},
abstract = {Research on unmanned aerial vehicles (UAV) image mosaic aims to generate a high-quality panoramic image without distortions or ghosting at a high operation speed. To this end, this study first constructed a Rapid Scale-Invariant Feature Transform (RSIFT) operator to reduce computer time. Subsequently, we employ the As-Natural-As-Possible (AANAP) algorithm for image registration. An image segmentation algorithm is applied to eliminate the motion ghosting. Lastly, A special aerial images dataset for image mosaic is constructed, based on which the comparable experiments with state-of-art image mosaic methods are conducted. Experimental results demonstrate that the feature extraction speed with the proposed algorithm is improved by at least 78% compared to SIFT, and the motion ghosting is effectively eliminated, thus achieving a fast and high-quality mosaic.}
}
@article{MASOOD2021827,
title = {Machine learning-based surrogate model for accelerating simulation-driven optimisation of hydropower Kaplan turbine},
journal = {Renewable Energy},
volume = {173},
pages = {827-848},
year = {2021},
issn = {0960-1481},
doi = {https://doi.org/10.1016/j.renene.2021.04.005},
url = {https://www.sciencedirect.com/science/article/pii/S0960148121005176},
author = {Zahid Masood and Shahroz Khan and Li Qian},
keywords = {Renewable energy, Hydropower plants, Kaplan turbine, Shape optimisation, Surrogate model},
abstract = {In this work, a data-driven technique is proposed for efficient design exploration and optimisation of the Kaplan turbine. To avoid the curse of dimensionality, the proposed approach commences with the extraction of latent features of a parametric design space, which form a lower-dimensional subspace accumulating maximum geometric variability of designs. Afterwards, this subspace is exploited for the construction of a Gaussian Process-based surrogate model using an adaptive training strategy to infer the relative-tangential velocities at the leading and trailing edges of the turbine. The training strategy is structured on a high-fidelity sampling approach to ensure a notable prediction accuracy with a few training samples. After training, the surrogate model is integrated with an optimiser to explore the subspace for an optimal design and to determine the sensitivity of design parameters. The results showed that the optimal design generated with the proposed method increases the efficiency of the initial design from 56.98% to 90.73% at a significantly low computational cost. Finally, the convergence performance is verified with different experimentation and its accuracy to extract latent features and to predict the relative-tangential velocity is demonstrated via a comparative study in which different state-of-the-art approaches are compared with the proposed approach.}
}
@article{ZHAO2020106273,
title = {SpiderNet: A spiderweb graph neural network for multi-view gait recognition},
journal = {Knowledge-Based Systems},
volume = {206},
pages = {106273},
year = {2020},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2020.106273},
url = {https://www.sciencedirect.com/science/article/pii/S0950705120304597},
author = {Aite Zhao and Jianbo Li and Manzoor Ahmed},
keywords = {Multi-view, Gait knowledge, Spiderweb graph convolutional network, Feature fusion, Capsule network, Long-short term memory, Spatio-temporal information},
abstract = {Human gait is a proven biometric trait with applications in security for authentication and disease diagnosis. However, it is one-sided to express and interpret gait data from a single point of view, which cannot reflect multi-dimensional characteristics of gait changes. Moreover, if the gait pattern observed from other views has pathological or abnormal behavior, or has micro movement, it is not easy to be detected and thus affects the recognition rate of gait. In addition, the multi-view fusion of gait knowledge can be challenging due to the close correlation between various visual angles. Owing to the above facts, we propose a spiderweb graph neural network (SpiderNet) to solve the multi-view gait recognition problem, which connects the gait data of single view with that of other views concurrently and constructs an active graph convolutional neural network. The gait trajectory of each view is analyzed by the combination of a memory module and a capsule module, which accomplishes the multi-view feature fusion, as well as the spatio-temporal feature extraction of single view. The experimental results show that the SpiderNet is superior to fifteen state-of-the-art methods, such as random forest, long-short term memory and convolutional neural network, and achieves 98.54%, 98.77%, and 96.91% of the results on three challenging gait datasets: SDUgait, CASIA-B, and OU-MVLP.}
}
@article{VELUMANI2020107793,
title = {An automatic method based on daily in situ images and deep learning to date wheat heading stage},
journal = {Field Crops Research},
volume = {252},
pages = {107793},
year = {2020},
issn = {0378-4290},
doi = {https://doi.org/10.1016/j.fcr.2020.107793},
url = {https://www.sciencedirect.com/science/article/pii/S0378429019321604},
author = {Kaaviya Velumani and Simon Madec and Benoit {de Solan} and Raul Lopez-Lozano and Jocelyn Gillet and Jeremy Labrosse and Stephane Jezequel and Alexis Comar and Frédéric Baret},
keywords = {Phenology, Internet of Things for Agriculture, Convolutional neural networks, Field sensors, Phenology modelling},
abstract = {Accurate and timely observations of wheat phenology and, particularly, of heading date are instrumental for many scientific and technical domains such as wheat ecophysiology, crop breeding, crop management or precision agriculture. Visual annotation of the heading date in situ is a labour-intensive task that may become prohibitive in scientific and technical activities where high-throughput is needed. This study presents an automatic method to estimate wheat heading date from a series of daily images acquired by a fixed RGB camera in the field. A convolutional neural network (CNN) is trained to identify the presence of spikes in small patches. The heading date is then estimated from the dynamics of the spike presence in the patches over time. The method is applied and validated over a large set of 47 experimental sites located in different regions in France, covering three years with nine wheat cultivars. Results show that our method provides good estimates of the heading dates with a root mean square error close to 2 days when compared to the visual scoring from experts. It outperforms the predictions of a phenological model based on the ARCWHEAT crop model calibrated for our local conditions. The potentials and limits of the proposed methodology towards a possible operational implementation in agronomic applications and decision support systems are finally further discussed.}
}
@article{SHARMA201794,
title = {Intelligent deployment of UAVs in 5G heterogeneous communication environment for improved coverage},
journal = {Journal of Network and Computer Applications},
volume = {85},
pages = {94-105},
year = {2017},
note = {Intelligent Systems for Heterogeneous Networks},
issn = {1084-8045},
doi = {https://doi.org/10.1016/j.jnca.2016.12.012},
url = {https://www.sciencedirect.com/science/article/pii/S1084804516303034},
author = {Vishal Sharma and Kathiravan Srinivasan and Han-Chieh Chao and Kai-Lung Hua and Wen-Huang Cheng},
keywords = {UAVs, 5G, Heterogeneous Networks, Interference, Capacity},
abstract = {With hard requirements of high performance for the next generation mobile communication systems, especially 5G networks, coverage has been the crucial problem which requires the deployment of more stations by the service providers. However, this deployment of new stations is not cost effective and requires network replanning. This issue can easily be overcome by the use of Unmanned Aerial Vehicles (UAVs) in the existing communication system. Thus, considering this as a problem, an intelligent solution is presented for the accurate and efficient placement of the UAVs with respect to the demand areas resulting in the increase in the capacity and coverage of the wireless networks. The proposed approach utilizes the priority-wise dominance and the entropy approaches for providing solutions to the two problems considered in this paper, namely, Macro Base Station (MBS) decision problem and the cooperative UAV allocation problem. Finally, network bargaining is defined over these solutions to accurately map the UAVs to the desired areas resulting in the significant improvement of the network parameters, namely, throughput, per User Equipment (UE) capacity, 5th percentile spectral efficiency, network delays and guaranteed signal to interference plus noise ratio by 6.3%, 16.6%, 55.9%, 48.2%, and 36.99%, respectively in comparison with the existing approaches.}
}
@article{MELLIT2021110889,
title = {Artificial intelligence and internet of things to improve efficacy of diagnosis and remote sensing of solar photovoltaic systems: Challenges, recommendations and future directions},
journal = {Renewable and Sustainable Energy Reviews},
volume = {143},
pages = {110889},
year = {2021},
issn = {1364-0321},
doi = {https://doi.org/10.1016/j.rser.2021.110889},
url = {https://www.sciencedirect.com/science/article/pii/S1364032121001830},
author = {Adel Mellit and Soteris Kalogirou},
keywords = {Deep learning, Fault detection and diagnosis, Internet of things, Machine learning, Photovoltaic systems, Remote sensing, Smart monitoring},
abstract = {Currently, a huge number of photovoltaic plants have been installed worldwide and these plants should be carefully protected and supervised continually in order to be safe and reliable during their working lifetime. Photovoltaic plants are subject to different types of faults and failures, while available fault detection equipment are mainly used to protect and isolate the photovoltaic plants from some faults (such as arc fault, line-to-line, line-to-ground and ground faults). Although a good number of international standards (IEC, NEC, and UL) exists, undetectable faults continue to create serious problems in photovoltaic plants. Thus, designing smart equipment, including artificial intelligence and internet of things for remote sensing and fault detection and diagnosis of photovoltaic plants, will considerably solve the shortcomings of existing methods and commercialized equipment. This paper presents an overview of artificial intelligence and internet of things applications in photovoltaic plants. This research presents also the most advanced algorithms such as machine and deep learning, in terms of cost implementation, complexity, accuracy, software suitability, and feasibility of real-time applications. The embedding of artificial intelligence and internet of things techniques for fault detection and diagnosis into simple hardware, such as low-cost chips, may be economical and technically feasible for photovoltaic plants located in remote areas, with costly and challenging accessibility for maintenance. Challenging issues, recommendations, and trends of these techniques will also be presented in this paper.}
}
@article{BERA202191,
title = {Private blockchain-based access control mechanism for unauthorized UAV detection and mitigation in Internet of Drones environment},
journal = {Computer Communications},
volume = {166},
pages = {91-109},
year = {2021},
issn = {0140-3664},
doi = {https://doi.org/10.1016/j.comcom.2020.12.005},
url = {https://www.sciencedirect.com/science/article/pii/S0140366420320119},
author = {Basudeb Bera and Ashok Kumar Das and Anil Kumar Sutrala},
keywords = {Internet of drones (IoD), UAV detection and mitigation, Access control, Blockchain, Security, AVISPA},
abstract = {Drones, which are also known as Unmanned Aerial Vehicles (UAVs), are very useful in delivering the packages, and real-time object detection and tracking with minimal human interference. However, there may be several security threats in such an environment, for instance, a malicious user can spy unauthorized drones, transfer malicious packages, or even damage the network reliability that can have direct impact on drones control. This may lead to a potential threat for people, governments, and business sectors. To deal with these issues, in this paper, we propose a novel access control scheme for unauthorized UAV detection and mitigation in an Internet of Drones (IoD) environment, called ACSUD-IoD. With the help of the blockchain-based solution incorporated in ACSUD-IoD, the transactional data having both the normal secure data from a drone (UAV) to the Ground Station Server (GSS) and the abnormal (suspected) data for detection of unauthorized UAVs by the GSS are stored in private blockchain, that are authentic and genuine. As a result, the Big data analytics can be performed on the authenticated transactional data stored in the blockchain. Through the detailed security analysis including formal security under the broadly-accepted Real-Or-Random (ROR) model, formal security verification using the widely-applied Automated Validation of Internet Security Protocols and Applications (AVISPA) tool and non-mathematical security analysis show the robustness of the proposed scheme against a number of potential attacks needed in an IoD environment. The testbed experiments for various cryptographic primitives using the broadly-accepted Multiprecision Integer and Rational Arithmetic Cryptographic Library (MIRACL) have been performed under both server and Raspberry PI 3 configurations. Furthermore, a detailed comparative analysis among the proposed scheme and other existing competing schemes shows the efficacy and more robustness as compared to the existing schemes. Finally, the blockchain-based practical demonstration shows the effectiveness of the proposed scheme.}
}
@article{VETRIVEL201845,
title = {Disaster damage detection through synergistic use of deep learning and 3D point cloud features derived from very high resolution oblique aerial images, and multiple-kernel-learning},
journal = {ISPRS Journal of Photogrammetry and Remote Sensing},
volume = {140},
pages = {45-59},
year = {2018},
note = {Geospatial Computer Vision},
issn = {0924-2716},
doi = {https://doi.org/10.1016/j.isprsjprs.2017.03.001},
url = {https://www.sciencedirect.com/science/article/pii/S0924271616305913},
author = {Anand Vetrivel and Markus Gerke and Norman Kerle and Francesco Nex and George Vosselman},
keywords = {Oblique images, UAV, 3D point cloud features, CNN features, Multiple-kernel-learning, Transfer learning, Model transferability, Structural damage detections},
abstract = {Oblique aerial images offer views of both building roofs and façades, and thus have been recognized as a potential source to detect severe building damages caused by destructive disaster events such as earthquakes. Therefore, they represent an important source of information for first responders or other stakeholders involved in the post-disaster response process. Several automated methods based on supervised learning have already been demonstrated for damage detection using oblique airborne images. However, they often do not generalize well when data from new unseen sites need to be processed, hampering their practical use. Reasons for this limitation include image and scene characteristics, though the most prominent one relates to the image features being used for training the classifier. Recently features based on deep learning approaches, such as convolutional neural networks (CNNs), have been shown to be more effective than conventional hand-crafted features, and have become the state-of-the-art in many domains, including remote sensing. Moreover, often oblique images are captured with high block overlap, facilitating the generation of dense 3D point clouds – an ideal source to derive geometric characteristics. We hypothesized that the use of CNN features, either independently or in combination with 3D point cloud features, would yield improved performance in damage detection. To this end we used CNN and 3D features, both independently and in combination, using images from manned and unmanned aerial platforms over several geographic locations that vary significantly in terms of image and scene characteristics. A multiple-kernel-learning framework, an effective way for integrating features from different modalities, was used for combining the two sets of features for classification. The results are encouraging: while CNN features produced an average classification accuracy of about 91%, the integration of 3D point cloud features led to an additional improvement of about 3% (i.e. an average classification accuracy of 94%). The significance of 3D point cloud features becomes more evident in the model transferability scenario (i.e., training and testing samples from different sites that vary slightly in the aforementioned characteristics), where the integration of CNN and 3D point cloud features significantly improved the model transferability accuracy up to a maximum of 7% compared with the accuracy achieved by CNN features alone. Overall, an average accuracy of 85% was achieved for the model transferability scenario across all experiments. Our main conclusion is that such an approach qualifies for practical use.}
}
@article{ALOQAILY2022103617,
title = {An adaptive UAV positioning model for sustainable smart transportation},
journal = {Sustainable Cities and Society},
volume = {78},
pages = {103617},
year = {2022},
issn = {2210-6707},
doi = {https://doi.org/10.1016/j.scs.2021.103617},
url = {https://www.sciencedirect.com/science/article/pii/S2210670721008817},
author = {Moayad Aloqaily and Ouns Bouachir and Ismaeel {Al Ridhawi} and Anthony Tzes},
keywords = {UAVs, AI, Adaptive positioning, Sustainable smart transportation},
abstract = {Several research works are being considered to adopt the use of UAVs to support smart transportation systems due to their movement flexibility. In this article, a UAV-supported vehicular network solution is developed which considers both power and coverage limitations of UAVs to attain the vision of sustainable smart cities. Nodes communicate with each other through the 5G connection and ad-hoc links. The solution is solved for as a predictive optimization problem that determines the height of the UAV to dynamically change it to ensure the optimal communication coverage of vehicular nodes. Moreover, the solution considers UAV energy consumption constraints when setting the optimal height of the UAV. Additionally, the optimal distance between every two adjacent UAVs is also considered to avoid any coverage overlapping while protecting their connectivity. Extensive evaluations were considered in terms of both implementation and simulation to test the proposed model. Evaluation results show that the proposed solution can predict vehicle traffic patterns accurately to ensure proper adjustments of the UAV height. Moreover, network coverage is ensured for areas with and without fixed BS availability with the support of the self-positioning UAVs while adhering to QoS requirements.}
}
@article{PASSOS2022101754,
title = {Automatic detection of Aedes aegypti breeding grounds based on deep networks with spatio-temporal consistency},
journal = {Computers, Environment and Urban Systems},
volume = {93},
pages = {101754},
year = {2022},
issn = {0198-9715},
doi = {https://doi.org/10.1016/j.compenvurbsys.2021.101754},
url = {https://www.sciencedirect.com/science/article/pii/S0198971521001617},
author = {Wesley L. Passos and Gabriel M. Araujo and Amaro A. {de Lima} and Sergio L. Netto and Eduardo A.B. {da Silva}},
keywords = {Vector control, , Aerial images, Convolutional neural networks, Image and video processing, Computer vision, Object detection},
abstract = {Every year, the Aedes aegypti mosquito infects millions of people with diseases such as dengue, zika, chikungunya, and urban yellow fever. The main form to combat these diseases is to avoid mosquito reproduction by searching for and eliminating the potential mosquito breeding grounds. In this work, we introduce a comprehensive dataset of aerial videos, acquired with an unmanned aerial vehicle, containing possible mosquito breeding sites. All frames of the video dataset were manually annotated with bounding boxes identifying all objects of interest. This dataset was employed to develop an automatic detection system of such objects based on deep convolutional networks. We propose the exploitation of the temporal information contained in the videos by the incorporation, in the object detection pipeline, of a spatio-temporal consistency module that can register the detected objects, minimizing most false-positive and false-negative occurrences. Also, we experimentally show that using videos is more beneficial than only composing a mosaic using the frames. Using the ResNet-50-FPN as a backbone, we achieve F1-scores of 0.65 and 0.77 on the object-level detection of ‘tires’ and ‘water tanks’, respectively, illustrating the system capabilities to properly locate potential mosquito breeding objects.}
}
@article{ZHOU202051,
title = {A two-step approach for the correction of rolling shutter distortion in UAV photogrammetry},
journal = {ISPRS Journal of Photogrammetry and Remote Sensing},
volume = {160},
pages = {51-66},
year = {2020},
issn = {0924-2716},
doi = {https://doi.org/10.1016/j.isprsjprs.2019.11.020},
url = {https://www.sciencedirect.com/science/article/pii/S0924271619302849},
author = {Yilin Zhou and Mehdi Daakir and Ewelina Rupnik and Marc Pierrot-Deseilligny},
keywords = {Rolling shutter, Readout time calibration, Distortion correction, UAV, Aerial photogrammetry},
abstract = {The use of consumer grade unmanned aerial vehicles (UAV) is becoming more and more ubiquitous in photogrammetric applications. A large proportion of consumer grade UAVs are equipped with CMOS image sensor and rolling shutter. When imaging with a rolling shutter camera, the image sensor is exposed line by line, which can introduce additional distortions in image space since the UAV navigates at a relatively high speed during aerial acquisitions. In this paper, we propose (1) an approach to calibrate the readout time of rolling shutter camera, (2) a two-step method to correct the image distortion introduced by this effect. The two-step method makes assumption that during exposure, the change of camera orientation is negligible with respect to the change of camera position, which is often the case when camera is fixed on a stabilized mount. Firstly, the camera velocity is estimated from the results of an initial bundle block adjustment; then, one camera pose per scan-line of the image sensor is recovered and image observations are corrected. To evaluate the performance of the proposed method, four datasets of block and corridor configurations are acquired with the DJI Mavic 2 Pro and its original Hasselbald L1D-20c camera. The proposed method is implemented in MicMac, a free, open-source photogrammetric software; comparisons are carried out with other two mainstream software, AgiSoft MetaShape and Pix4D, which also have the functionality of rolling shutter effect correction. For block configuration datasets, the three software give comparable results. AgiSoft Metashape and Pix4D are sensitive to the flight configuration and encounter difficulties when processing datasets in corridor configurations. The proposed method shows good robustness both in block and corridor configurations, and is the only method that works in corridor configuration. After the application of the rolling shutter effect correction, the 3D accuracy is improved by 30–60% in block configuration and 15–25% in corridor configuration. A further improvement can be expected if a precise dating of image is available or if the camera positions can be directly extracted from GNSS data.}
}
@article{REHMAN2019585,
title = {Current and future applications of statistical machine learning algorithms for agricultural machine vision systems},
journal = {Computers and Electronics in Agriculture},
volume = {156},
pages = {585-605},
year = {2019},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2018.12.006},
url = {https://www.sciencedirect.com/science/article/pii/S0168169918304289},
author = {Tanzeel U. Rehman and Md. Sultan Mahmud and Young K. Chang and Jian Jin and Jaemyung Shin},
keywords = {Machine vision, Statistical machine learning, Naïve Bayes, Discriminant analysis, k-Nearest Neighbour, Support vector machines, K-means clustering, Fuzzy clustering, Gaussian mixture model},
abstract = {With being rapid increasing population in worldwide, the need for satisfactory level of crop production with decreased amount of agricultural lands. Machine vision would ensure the increase of crop production by using an automated, non-destructive and cost-effective technique. In last few years, remarkable results have been achieved in different sectors of agriculture. These achievements are integrated with machine learning techniques on machine vision approach that cope with colour, shape, texture and spectral analysis from the image of objects. Despite having many applications of different machine learning techniques, this review only described the statistical machine learning technologies with machine vision systems in agriculture due to broad area of machine learning applications. Two types of statistical machine learning techniques such as supervised and unsupervised learning have been utilized for agriculture. This paper comprehensively surveyed current application of statistical machine learning techniques in machine vision systems, analyses each technique potential for specific application and represents an overview of instructive examples in different agricultural areas. Suggestions of specific statistical machine learning technique for specific purpose and limitations of each technique are also given. Future trends of statistical machine learning technology applications are discussed.}
}
@article{TOSIC20102217,
title = {A unified framework for reinforcement learning, co-learning and meta-learning how to coordinate in collaborative multi-agent systems},
journal = {Procedia Computer Science},
volume = {1},
number = {1},
pages = {2217-2226},
year = {2010},
note = {ICCS 2010},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2010.04.248},
url = {https://www.sciencedirect.com/science/article/pii/S1877050910002498},
author = {Predrag T. Tošić and Ricardo Vilalta},
keywords = {Autonomous agents, Multi-agent systems, Distributed problem solving, Agent coordination, Coalition formation, Distributed task allocation, Reinforcement learning, Co-learning, Meta-learning, Multi-level learning},
abstract = {Coordination among multiple autonomous, distributed cognitive agents is one of the most challenging and ubiquitous problems in Distributed AI and its applications in general, and in collaborative multi-agent systems in particular. A particularly prominent problem in multi-agent coordination is that of group, team or coalition formation. A considerable majority of the approaches to this problem found in the literature assume fixed interactions among autonomous agents involved in the coalition formation process. Moreover, most of the prior research where agents are actually able to learn and adapt based on their past interactions mainly focuses on reinforcement learning techniques at the individual agent level. We argue that, in many important applications and contexts, complex large-scale collaborative multi-agent systems need to be able to learn and adapt at multiple organization, hierarchical and logical levels. In particular, the agents need to be able to learn both at the level of individual agents and at the system or agent ensemble levels, and then to integrate these different sources of learned knowledge and behavior, in order to be effective at solving complex tasks in typical dynamic, partially observable and noisy multi-agent environments. In this paper, we describe a conceptual framework for addressing the problem of learning how to coordinate effectively at three qualitatively distinct levels — those of (i) individual agents, (ii) small groups of agents, and (iii) very large agent ensembles (or alternatively, depending on the nature of a multi-agent system, at the system or central control level). We briefly illustrate the applicability and usefulness of the proposed conceptual framework with an example of how it would apply to an important practical coordination problem, namely that of distributed coordination of a large ensemble of unmanned vehicles on a complex multi-task mission.}
}
@article{WANG201890,
title = {Collaborative model based UAV tracking via local kernel feature},
journal = {Applied Soft Computing},
volume = {72},
pages = {90-107},
year = {2018},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2018.07.049},
url = {https://www.sciencedirect.com/science/article/pii/S156849461830437X},
author = {Yong Wang and Xinbin Luo and Lu Ding and Shan Fu and Shiqiang Hu},
keywords = {UAV tracking, Structure support vector machine, Local kernel feature, Collaborative model},
abstract = {Partial occlusion is one of a challenging problem in unmanned aerial vehicle (UAV) tracking. In this paper, we propose a novel collaborative model based tracking method which attempts to exploit a holistic model and a part model that tracks an object consistently through the entire video sequence. Specifically, we first develop a robust local kernel feature which learns the data around to encode the geometric information of the object. Next, the target is divided into four parts. And structure support vector machine (SSVM) is employed to integrate with the local feature to a robust visual tracking framework. Furthermore, we adopt a reliable metric to measure the reliability of a patch. Kalman filter is used to fuse the holistic model and part model tracking results smoothly according to the metric. Extensive experimental results demonstrate our tracker achieves comparable performance to state-of-the-art methods.}
}
@article{SANKARALINGAM2020749,
title = {A comprehensive survey on the methods of angle of attack measurement and estimation in UAVs},
journal = {Chinese Journal of Aeronautics},
volume = {33},
number = {3},
pages = {749-770},
year = {2020},
issn = {1000-9361},
doi = {https://doi.org/10.1016/j.cja.2019.11.003},
url = {https://www.sciencedirect.com/science/article/pii/S1000936119304078},
author = {L. SANKARALINGAM and C. RAMPRASADH},
keywords = {Angle of attack estimation, Angle of attack measurement, Angle of attack vane, Five-hole probe, Multi-hole probe, Multi-hole probe calibration, Nine-hole probe, Seven-hole probe, Virtual angle of attack sensor},
abstract = {Angle of Attack (AOA) is a crucial parameter which directly affects the aerodynamic forces of an aircraft. The measurement of AOA is required to ensure a safe flight within its designed flight envelop. This paper intends to summarise a comprehensive survey on the measurement techniques and estimation methods for AOA, specifically in Unmanned Aerial Vehicle (UAV) applications. In the case of UAVs, weight constraint plays a major role as far as sensor suites are concerned. This results in selecting a suitable estimation method to extract AOA using the available data from the autopilot. The most feasible and widely employed AOA measurement technique is by using the Multi-Hole Probes (MHPs). The MHP measures the AOA regarding the pressure variations between the ports. Due to the importance of MHP in AOA measurement, the calibration methods for the MHP are also included in this paper. This paper discusses the AOA measurement using virtual AOA sensors, their importance and the operation.}
}
@article{HUANG2016182,
title = {A novel coordinated path planning method using k-degree smoothing for multi-UAVs},
journal = {Applied Soft Computing},
volume = {48},
pages = {182-192},
year = {2016},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2016.06.046},
url = {https://www.sciencedirect.com/science/article/pii/S1568494616303362},
author = {Liwei Huang and Hong Qu and Peng Ji and Xintong Liu and Zhen Fan},
keywords = {Multi-UAVs, Voronoi diagram, -Degree smoothing, Coordinated path planning},
abstract = {Coordinated path planning for multiple unmanned aerial vehicles (multi-UAVs) is a highly significant problem encountered in their coordinated control. In the interests of completing mission securely and efficiently, the advanced multi-UAVs control technology requires a universal smoothing method as well as a precise coordination strategy. In this paper, we propose a novel multi-UAVs coordinated path planning method based on the k-degree smoothing, a more complex environment consists of multiple threat sources of which is constructed. By employing the Improved Ant Colony Optimization algorithm, a k-degree smoothing method is also presented aiming at obtaining a more flyable path. Additionally, the multi-UAVs coordination algorithm is induced by k-degree smoothing, allowing the UAVs to arrive at the destination simultaneously or in an acceptable time interval. Finally, simulations of the comparison between the Improved Ant Colony Optimization and classic algorithm, the detailed smoothing method, and the coordination are respectively conducted to validate that the proposed approach is feasible and effective in multi-UAVs coordinated path planning problems.}
}
@article{BANG2020103198,
title = {Image augmentation to improve construction resource detection using generative adversarial networks, cut-and-paste, and image transformation techniques},
journal = {Automation in Construction},
volume = {115},
pages = {103198},
year = {2020},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2020.103198},
url = {https://www.sciencedirect.com/science/article/pii/S0926580519311653},
author = {Seongdeok Bang and Francis Baek and Somin Park and Wontae Kim and Hyoungkwan Kim},
keywords = {Data augmentation, Construction resource detection, On-site management, GAN, UAV},
abstract = {The paper proposes an image augmentation method to construct a large-size dataset for improving construction resource detection. The method consists of three techniques: removing-and-inpainting, cut-and-paste, and image-variation. The removing-and-inpainting technique arbitrarily removes objects from images and reconstructs the removed regions via generative adversarial networks (GAN). The cut-and-paste technique extracts objects from the original dataset and places them into the reconstructed images via the previous technique. The image-variation technique applies three image transformation techniques, intensity-, blur- and scale-variation, to the images. To evaluate the method, 656 unmanned aerial vehicle (UAV)-acquired construction site images were used as the original dataset. A faster region-based convolutional neural network (Faster R-CNN) trained with the augmented training dataset achieves better performance, which is higher than that of a network trained with the original dataset. These results prove that the method is optimal for improving construction resource detection in UAV-acquired images.}
}
@article{LIU202181,
title = {An active disturbance rejection control for hysteresis compensation based on Neural Networks adaptive control},
journal = {ISA Transactions},
volume = {109},
pages = {81-88},
year = {2021},
issn = {0019-0578},
doi = {https://doi.org/10.1016/j.isatra.2020.10.019},
url = {https://www.sciencedirect.com/science/article/pii/S0019057820304146},
author = {Wentao Liu and Tong Zhao},
keywords = {RBF neural network, Active disturbance rejection control, RBF-ADRC composite controller, Lyapunov stability theory},
abstract = {In the present paper, an active disturbance rejection control(ADRC) scheme via radial basis function(RBF) neural networks is designed for adaptive control of non-affine nonlinear systems facing hysteresis disturbance in which RBF neural network approximation is utilized to tackle the system uncertainties and ADRC is designed to real-time estimate and compensate disturbance with unknown backlash-like hysteresis. Combining the adaptive neural networks design with ADRC design techniques, a new dual-channel composite controller scheme is developed herein whereby adaptive neural networks are used as feed-forward inverse control and ADRC as closed-loop feedback control. Furthermore, as compared to adaptive neural networks control algorithm, the proposed RBF-ADRC dual-channel composite controller can guarantee that the desired signal can be tracked with a small domain of the origin and it is confirmed to be effective under Lyapunov stability theory and MATLAB simulations.}
}
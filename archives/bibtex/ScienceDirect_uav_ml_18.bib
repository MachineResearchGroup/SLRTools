@article{KARADAL2021115659,
title = {Automated classification of remote sensing images using multileveled MobileNetV2 and DWT techniques},
journal = {Expert Systems with Applications},
volume = {185},
pages = {115659},
year = {2021},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2021.115659},
url = {https://www.sciencedirect.com/science/article/pii/S0957417421010502},
author = {Can Haktan Karadal and M. Cagri Kaya and Turker Tuncer and Sengul Dogan and U. Rajendra Acharya},
keywords = {MobilNetV2, Multilevel feature generation, INCA, Remote sensing image classification},
abstract = {Automated classification of remote sensing images is one of the complex issues in robotics and machine learning fields. Many models have been proposed for remote sensing image classification (RSIC) to obtain high classification performance. The objective of this study are twofold. First, to create a new space object image collection as such a dataset is not currently available. Second, propose a novel RSIC model to yield highest classification performance using our newly created dataset. Our presented automated classification model consists of multilevel deep feature generation, iterative feature selection, and classification steps. The features are extracted from the images using pre-trained MobileNetV2 and discrete wavelet transform (DWT) methods. The combination of DWT and MobileNetV2 generates large number of features. Then, iterative neighborhood component analysis (INCA) is used to select the best features. Finally, selected features are fed to support vector machine (SVM) for automated classification. The presented model is validated using two RSIC datasets: UC-Merced, and newly created space object images (publicly available at: http://web.firat.edu.tr/turkertuncer/space_object.rar). The developed model has obtained an accuracy of 98.10% and 95.95% using UC-Merced, and newly generated space object image datasets, respectively with 10-fold cross-validation strategy. It can be concluded from the results that, the presented RSIC model is accurate and ready for real-world applications.}
}
@article{LIU2017377,
title = {Analysis of the Relation between Artificial Intelligence and the Internet from the Perspective of Brain Science},
journal = {Procedia Computer Science},
volume = {122},
pages = {377-383},
year = {2017},
note = {5th International Conference on Information Technology and Quantitative Management, ITQM 2017},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2017.11.383},
url = {https://www.sciencedirect.com/science/article/pii/S1877050917326261},
author = {Feng Liu and Yong Shi and Peijia Li},
keywords = {Internet’s virtual brain, Big SNS, AI model of the Internet-like brain},
abstract = {Artificial intelligence (AI) like deep learning, cloud AI computation has been advancing at a rapid pace since 2014. There is no doubt that the prosperity of AI is inseparable with the development of the Internet. However, there has been little attention to the link between AI and the internet. This paper explores them with brain insights mainly from four views:1) How is the general relation between artificial intelligence and Internet of Things, cloud computing, big data and Industrial Internet from the perspective of brain science. 2) Construction of a new AI system model with the Internet and brain science.}
}
@article{CAVIERES2022117964,
title = {Automatic soiling and partial shading assessment on PV modules through RGB images analysis},
journal = {Applied Energy},
volume = {306},
pages = {117964},
year = {2022},
issn = {0306-2619},
doi = {https://doi.org/10.1016/j.apenergy.2021.117964},
url = {https://www.sciencedirect.com/science/article/pii/S030626192101271X},
author = {Robinson Cavieres and Rodrigo Barraza and Danilo Estay and José Bilbao and Patricio Valdivia-Lefort},
keywords = {Photovoltaic monitoring, Image analysis, Segmentation, Computer vision},
abstract = {This article presents an artificial neural network tool able to quantify the power loss due to soiling and partial shading effects of solar photovoltaic modules in the field, which may play a key factor on an optimal operation and maintenance of PV systems. The proposed approach uses visible spectrum RGB images of multiple solar panels and environmental data to predict each module’s performance individually. The algorithm consists of three main stages. The first step is segmentation, which takes the image input and identifies every module present in the scene using Region Based Convolutional Neural Networks (RCNN) and supervised learning. In the second step, each of these regions is resized and reshaped to achieve a homogeneous format. The final step uses the processed regions and environmental data to predict the performance of each module, categorizing power loss according to a percentile classification. This step uses a convolutional neural network (CNN) designed specifically for this task. When compared to state-of-the-art computer vision architectures, the proposed approach achieved similar results with a significant reduction in computational cost. Preliminary experiments show that the classifier has an accuracy of over 73% when power loss predictions are divided into 8 percentiles ranging from 0 to 100%, where most of the errors originate from minimal differences between the actual and predicted percentiles.}
}
@article{REINA201861,
title = {Evolutionary deployment and local search-based movements of 0th responders in disaster scenarios},
journal = {Future Generation Computer Systems},
volume = {88},
pages = {61-78},
year = {2018},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2018.05.024},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X17325372},
author = {D.G. Reina and T. Camp and A. Munjal and S.L. Toral},
keywords = {Disaster scenarios, Communications, Evolutionary algorithm, Local search algorithm, 0th responders},
abstract = {The establishment of communications in disaster scenarios is of paramount importance, especially because preexisting communication infrastructure is likely to be destroyed or malfunctioning. Consequently, there is a need for an alternative and self-organizing communication infrastructure that can be rapidly deployed in disaster situations. In this paper, we propose to use drones or unmanned aerial vehicles as 0th responders to form a network that provides communication services to victims. Finding the best positions of the 0th responders is a non-trivial problem and is, therefore, divided into two phases. The first phase is the initial deployment, where the 0th responders are placed using partial information on the disaster scenario. In the second phase, which we call the adaptation to real conditions, the drones move according to a local search algorithm to find positions that provide better coverage to the victims. We conduct extensive simulations to validate our proposed approach for rural disaster scenarios under different conditions. We show that our proposed initial deployment based on genetic algorithm provides coverage for up to 94% (maximum) and 86% (mean) of victims if complete knowledge of the disaster scenario is known and 10 drones are used. When the adaptation to the real condition phase is used, this percentage is increased to 95% (maximum). If no knowledge of the scenario and 10 UAVs are used 80% (maximum) and 59% (mean) of victims are found and successfully covered. The proposed approach outperforms in 6.4% the random deployment method, and in 2.4% the best grid deployment approach. Finally, we show that by using different numbers of drones for the two phases of the proposed approach, the percentage of victims is increased up to 51% for low values of knowledge of the scenario.}
}
@article{RAJ2019106118,
title = {Analyzing critical success factors for implementation of drones in the logistics sector using grey-DEMATEL based approach},
journal = {Computers & Industrial Engineering},
volume = {138},
pages = {106118},
year = {2019},
issn = {0360-8352},
doi = {https://doi.org/10.1016/j.cie.2019.106118},
url = {https://www.sciencedirect.com/science/article/pii/S036083521930587X},
author = {Alok Raj and Bhawesh Sah},
keywords = {Critical success factors, Grey-DEMATEL analysis, Unmanned aerial vehicle, Drone},
abstract = {Drone has become an important buzzword in the logistics sector in recent times. Drone deliveries have a two-pronged advantage as they have the potential to lessen delivery time by avoiding traffic congestions, and the inherent structure that reduces its carbon footprint compared to traditional modes of transportation under some restrictions. To leverage this potential, many companies across the world have developed and tested drones for real-world applications. However, many factors may play a significant role in the adoption of drone-delivery in the logistics sector. This paper attempts to unearth such critical success factors and establish the interrelationships between these factors. Twelve critical success factors were identified by systematically reviewing the literature and taking inputs from experts. An integrated multi-criteria decision-making technique, decision making trial and evaluation laboratory (DEMATEL)’, combined with the Grey-based approach, was used to envisage causal relationships between the identified critical success factors. The results reveal that ‘Technological advancements’ and ‘Government regulations’ are the most influential factors that impact the adoption of drones in the logistics sector. The research implications of these findings will help practitioners and policymakers effectively implement drones in the logistics sector.}
}
@article{ZHANG20201,
title = {Construction of a plant spectral library based on an optimised feature selection method},
journal = {Biosystems Engineering},
volume = {195},
pages = {1-16},
year = {2020},
issn = {1537-5110},
doi = {https://doi.org/10.1016/j.biosystemseng.2020.04.008},
url = {https://www.sciencedirect.com/science/article/pii/S1537511020300994},
author = {Jingcheng Zhang and Chendong Wang and Lin Yuan and Peng Liu and Yao Zhang and Kaihua Wu},
keywords = {Plant spectral library, Hyperspectral remote sensing, Spectral feature, Sensitivity analysis, Robustness analysis},
abstract = {Hyperspectral remote sensing data have great potential for plant classification, monitoring, and mapping due to their considerable spectral information. A spectral library can be used for the automatic interpretation of remote sensing data, which is an efficient tool for the classification of plant species. Given that similar spectral signatures are usually found among different plant species, it is critical to identify plant-sensitive spectral features when constructing a robust plant spectral library. This study proposed an approach to the establishment and application of a plant spectral library based on spectral data from ground objects. It included a spectral feature screening method for plant spectral response and a feature robustness analysis method suitable for monitoring, while unmanned aerial vehicle (UAV) hyperspectral imaging data was used to validate mapping results. This study was divided into an urban scenario and an agricultural scenario based on plant composition, and a set of spectral feature sensitivity methods based on Iterative Self-Organizing Data Analysis (ISODATA) and Jeffries–Matusita (JM) distance was proposed. At the same time, a robust spectral analysis method was developed based on illumination and noise disturbance. The performance of K-nearest neighbour algorithm (KNN), Random Forest (RF), and Support Vector Machine coupled with a Genetic Algorithm (GA-SVM) for plant classification modelling were compared. Results showed that the spectral indices obtained by sensitivity and robustness screening were effective for plant classification, and the GA-SVM model had the highest accuracy with overall accuracy (OAA) = 0.98, Kappa = 0.98 in the urban scenario, and OAA = 0.97, Kappa = 0.97 in the agricultural scenario. In addition, pixel-based crop classification validation based on UAV hyperspectral imaging also had high accuracy, and the plot level classification results were in good agreement with field survey results. Therefore, it is feasible to use a plant spectral library to assist in monitoring and mapping of plant species using hyperspectral remote sensing images at large scales. The effects of plant growth status, growth stage, and other changes on classification should be further studied.}
}
@article{HUSSEIN2021104348,
title = {Key technologies for safe and autonomous drones},
journal = {Microprocessors and Microsystems},
volume = {87},
pages = {104348},
year = {2021},
issn = {0141-9331},
doi = {https://doi.org/10.1016/j.micpro.2021.104348},
url = {https://www.sciencedirect.com/science/article/pii/S0141933121005056},
author = {Mahmoud Hussein and Réda Nouacer and Federico Corradi and Yassine Ouhammou and Eugenio Villar and Carlo Tieri and Rodrigo Castiñeira},
keywords = {Drones/UAVs, U-space, System functions, Tools, Architecture, Trusted communications, Safe-decision},
abstract = {Drones/UAVs are able to perform air operations that are very difficult to be performed by manned aircrafts. In addition, drones’ usage brings significant economic savings and environmental benefits, while reducing risks to human life. In this paper, we present key technologies that enable development of drone systems. The technologies are identified based on the usages of drones (driven by COMP4DRONES project use cases). These technologies are grouped into four categories: U-space capabilities, system functions, payloads, and tools. Also, we present the contributions of the COMP4DRONES project to improve existing technologies. These contributions aim to ease drones’ customization, and enable their safe operation.}
}
@article{SUN2021104112,
title = {Multi-agent hierarchical policy gradient for Air Combat Tactics emergence via self-play},
journal = {Engineering Applications of Artificial Intelligence},
volume = {98},
pages = {104112},
year = {2021},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2020.104112},
url = {https://www.sciencedirect.com/science/article/pii/S0952197620303547},
author = {Zhixiao Sun and Haiyin Piao and Zhen Yang and Yiyang Zhao and Guang Zhan and Deyun Zhou and Guanglei Meng and Hechang Chen and Xing Chen and Bohao Qu and Yuanjie Lu},
keywords = {Air combat, Artificial intelligence, Multi-agent reinforcement learning},
abstract = {Air-to-air confrontation has attracted wide attention from artificial intelligence scholars. However, in the complex air combat process, operational strategy selection depends heavily on aviation expert knowledge, which is usually expensive and difficult to obtain. Moreover, it is challenging to select optimal action sequences efficiently and accurately with existing methods, due to the high complexity of action selection when involving hybrid actions, e.g., discrete/continuous actions. In view of this, we propose a novel Multi-Agent Hierarchical Policy Gradient algorithm (MAHPG), which is capable of learning various strategies and transcending expert cognition by adversarial self-play learning. Besides, a hierarchical decision network is adopted to deal with the complicated and hybrid actions. It has a hierarchical decision-making ability similar to humankind, and thus, reduces the action ambiguity efficiently. Extensive experimental results demonstrate that the MAHPG outperforms the state-of-the-art air combat methods in terms of both defense and offense ability. Notably, it is discovered that the MAHPG has the ability of Air Combat Tactics Interplay Adaptation, and new operational strategies emerged that surpass the level of experts.}
}
@article{BECK2018251,
title = {Collaborative online planning for automated victim search in disaster response},
journal = {Robotics and Autonomous Systems},
volume = {100},
pages = {251-266},
year = {2018},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2017.09.014},
url = {https://www.sciencedirect.com/science/article/pii/S0921889016307515},
author = {Zoltán Beck and W.T. Luke Teacy and Alex Rogers and Nicholas R. Jennings},
keywords = {Search and rescue, Task allocation, Hindsight optimisation, Path planning, Multi-robot teams, Particle filter},
abstract = {Collaboration is essential for effective performance by groups of robots in disaster response settings. Here we are particularly interested in heterogeneous robots that collaborate in complex scenarios with incomplete, dynamically changing information. In detail, we consider an automated victim search setting, where unmanned aerial vehicles (UAVs) with different capabilities work together to scan for mobile phones and find and provide information about possible victims near these phone locations. The state of the art for such collaboration is robot control based on independent planning for robots with different tasks and typically incorporates uncertainty with only a limited scope. In contrast, in this paper, we take into account complex relations between robots with different tasks. As a result, we create a joint, full-horizon plan for the whole robot team by optimising over the uncertainty of future information gain using an online planner with hindsight optimisation. This joint plan is also used for further optimisation of individual UAV paths based on the long-term plans of all robots. We evaluate our planner’s performance in a realistic simulation environment based on a real disaster and find that our approach finds victims 25% faster compared to current state-of-the-art approaches.}
}
@article{GAN201879,
title = {Robust design and analysis of a conformal expansion nozzle with inverse-design idea},
journal = {Chinese Journal of Aeronautics},
volume = {31},
number = {1},
pages = {79-88},
year = {2018},
issn = {1000-9361},
doi = {https://doi.org/10.1016/j.cja.2017.11.009},
url = {https://www.sciencedirect.com/science/article/pii/S1000936117302443},
author = {Wenbiao GAN and Xiaocui ZHANG and Tielin MA and Qinling ZHANG and Wu YUAN},
keywords = {Aerodynamic analysis, Inverse-design, Nozzle, Off-design, Robust optimization},
abstract = {This paper examines robust optimization design and analysis of a conformal expansion nozzle of flying wing Unmanned Aerial Vehicle (UAV) with the inverse-design idea. In view of flow features and stealth constraints, the inverse-design idea is described and the uncertainty-based robust design model is presented. A robust design system employs this model to combine deterministic optimization and robust optimization and is applied into design of a conformal expansion nozzle. The results indicate that design optimization can conform to the anticipation of the inverse-design idea and significantly improve the aerodynamic performance that meet the requirement of 6σ. The present method is a feasible nozzle design strategy that integrates robust optimization and inverse-design.}
}
@article{DU2021109900,
title = {Application of image technology on pavement distress detection: A review},
journal = {Measurement},
volume = {184},
pages = {109900},
year = {2021},
issn = {0263-2241},
doi = {https://doi.org/10.1016/j.measurement.2021.109900},
url = {https://www.sciencedirect.com/science/article/pii/S0263224121008393},
author = {Zhenyu Du and Jie Yuan and Feipeng Xiao and Chamod Hettiarachchi},
keywords = {Digital image technology, Pavement detection, Image acquisition equipment, Pavement distress},
abstract = {Digital image processing technology has been widely applied in various fields, and it is also increasingly used in pavement distress detection in recent years. The objective of this review article is to help researchers to select the most appropriate digital image processing technology (image acquisition equipment, processing, recognition technology and etc.) to study the pavement distress detection. Firstly, a proper application of the current image acquisition equipment is presented, and the advantages and disadvantages are compared. Secondly, the problems encountered in the practical application of image processing technology in pavement detection are presented. Further, the problems need to be solved in the future research are suggested, including cracks detection, pavement texture detection, temperature segregation detection, rutting detection, pothole detection, and joint faulting detection. In conclusion, the state of the art in pavement detection by digital image processing technology is summarized and proves that the digital image processing technology has become a promising method for pavement detection and materials analysis.}
}
@article{WANG2017111,
title = {Augmented Cubature Kalman filter for nonlinear RTK/MIMU integrated navigation with non-additive noise},
journal = {Measurement},
volume = {97},
pages = {111-125},
year = {2017},
issn = {0263-2241},
doi = {https://doi.org/10.1016/j.measurement.2016.10.056},
url = {https://www.sciencedirect.com/science/article/pii/S0263224116306170},
author = {Dingjie Wang and Hanfeng Lv and Jie Wu},
keywords = {Low-cost MIMU, Bayesian estimation, Non-additive noise, Cubature Kalman filter, UAV},
abstract = {In order to enhance the capability of autonomous operation for small unmanned aerial vehicles (UAV), a MEMS-based inertial navigation system (INS)/global navigation satellite system (GNSS) integrated navigation method is proposed. An augmented Cubature Kalman filter is derived to fulfil the data fusion of precise GNSS real-time kinematic (RTK) solution and noisy inertial measurements. In the filter, Cubature Kalman filtering is adopted to handle the strong INS model nonlinearity caused by sudden and large UAV maneuvers, and the technique of state-augmentation is used to capture meaningful odd-order moment information and reduce the adverse impacts of non-additive noise in inertial measurements. It is analyzed that the basic difference between the augmented and non-augmented CKFs generally favors the augmented CKF, which is supported by a representative example and flight test. The results of flight test have also shown that the proposed augmented Cubature Kalman filtering method can complete more accurate navigation compared with the conventional EKF/UKF-based approaches.}
}
@article{MUHAMMAD2020100141,
title = {Polly: A Tool for Rapid Data Integration and Analysis in Support of Agricultural Research and Education},
journal = {Internet of Things},
volume = {9},
pages = {100141},
year = {2020},
issn = {2542-6605},
doi = {https://doi.org/10.1016/j.iot.2019.100141},
url = {https://www.sciencedirect.com/science/article/pii/S254266051930246X},
author = {Waqar Muhammad and Flavio Esposito and Maitiniyazi Maimaitijiang and Vasit Sagan and Enrico Bonaiuti},
keywords = {smart farming, serverless computing, network virtualization, machine learning, UAV},
abstract = {Data analysis and modeling is a complex and demanding task. While a variety of software and tools exist to cope with this problem and tame big data operations, most of these tools are either not free, and when they are, they require large amount of configuration and steep learning curve. Moreover, they provide limited functionalities. In this paper we propose Polly, an online data analysis and modeling open-source tool that is intuitive to use and can be used with minimal or no configuration. Users can use Polly to rapidly integrate, analyze their data, prototype and test their novel methodologies. Polly can be used also as an educational tool. Users can use Polly to upload or connect to their structured data sources, load the required data into our system and perform various data processing tasks. Examples of such operations include data cleaning, data pre-processing, attribute encoding, regression and classification analysis. Aside from modeling, users can then download their results in the form of graphs in several standard visualization formats. While in this paper we focus on analyzing dataset for smart farming, our tool usage fits to a more general audience. To justify our backend design and implementation choices, we also present a performance analysis between backend virtualization technologies (containers or serverless computing), showing both expected and surprising results.}
}
@article{TURNBULL20161,
title = {A cloned linguistic decision tree controller for real-time path planning in hostile environments},
journal = {Fuzzy Sets and Systems},
volume = {293},
pages = {1-29},
year = {2016},
note = {Theme: Applications of Fuzzy Sets},
issn = {0165-0114},
doi = {https://doi.org/10.1016/j.fss.2015.08.017},
url = {https://www.sciencedirect.com/science/article/pii/S0165011415003759},
author = {Oliver Turnbull and Jonathan Lawry and Mark Lowenberg and Arthur Richards},
keywords = {Learning, Fuzzy control, Linguistic modelling, Optimization, Behavioural cloning, Interpretability, UAV},
abstract = {The idea of a Cloned Controller to approximate optimised control algorithms in a real-time environment is introduced. A Cloned Controller is demonstrated using Linguistic Decision Trees (LDTs) to clone a Model Predictive Controller (MPC) based on Mixed Integer Linear Programming (MILP) for Unmanned Aerial Vehicle (UAV) path planning through a hostile environment. Modifications to the LDT algorithm are proposed to account for attributes with circular domains, such as bearings, and discontinuous output functions. The cloned controller is shown to produce near optimal paths whilst significantly reducing the decision period. Further investigation shows that the cloned controller generalises to the multi-obstacle case although this can lead to situations far outside of the training dataset and consequently result in decisions with a high level of uncertainty. A modification to the algorithm to improve the performance in regions of high uncertainty is proposed and shown to further enhance generalisation. The resulting controller combines the high performance of MPC–MILP with the rapid response of an LDT while providing a degree of transparency/interpretability of the decision making.}
}
@article{RANASINGHE2022100758,
title = {Advances in Integrated System Health Management for mission-essential and safety-critical aerospace applications},
journal = {Progress in Aerospace Sciences},
volume = {128},
pages = {100758},
year = {2022},
issn = {0376-0421},
doi = {https://doi.org/10.1016/j.paerosci.2021.100758},
url = {https://www.sciencedirect.com/science/article/pii/S0376042121000622},
author = {Kavindu Ranasinghe and Roberto Sabatini and Alessandro Gardi and Suraj Bijjahalli and Rohan Kapoor and Thomas Fahey and Kathiravan Thangavel},
keywords = {Avionics, Integrated system health management, Prognostics, Diagnostics, Health and usage monitoring systems, Artificial intelligence, Machine learning, Intelligent health and mission management, Unmanned aircraft system, UAS, Satellite systems, UAS Traffic management, UTM, Distributed satellite systems},
abstract = {Integrated System Health Management (ISHM) is a promising technology that fuses sensor data and historical state-of-health information of components and subsystems to provide actionable information and enable intelligent decision-making regarding the operation and maintenance of aerospace systems. ISHM fundamentally relies on assessments and predictions of system health, including the early detection of failures and estimation of Remaining Useful Life (RUL). Model-based, data-driven or hybrid reasoning techniques can be utilized to maximise the timeliness and reliability of diagnosis and prognosis information. The benefits of ISHM include enhancing the maintainability, reliability, safety and performance of systems. The next evolution of the ISHM concept, Intelligent Health and Mission Management (IHMM), delves deeper into the utilization of on-line system health predictions to modify mission profiles to ensure safety and reliability, as well as efficiency through predictive integrity. This concept is particularly important for Trusted Autonomous System (TAS) applications, where an accurate assessment of the current and future system state-of-health to make operational decisions (with or without human intervention) is integral to both flight safety and mission success. IHMM systems introduce the capability of predicting degradation in the functional performance of subsystems, with sufficient time to dynamically identify which appropriate restorative or reconfiguration actions to take in order to ensure that the system can perform at an acceptable level of operational capability before the onset of a failure event. This paper reviews some of the key advancements and contributions to knowledge in the field of ISHM for the aerospace industry, with a particular focus on various architectures and reasoning strategies involving the use of artificial intelligence. The paper also discusses the key challenges faced in the development and deployment of ISHM systems in the aerospace industry and highlights the safety-critical role that IHMM will play in future cyber-physical and autonomous system applications (both vehicle and ground support systems), such as Unmanned Aircraft Systems (UAS) Traffic Management (UTM), Urban Air Mobility (UAM) and Distributed Satellite Systems (DSS).}
}
@article{GUO2020104477,
title = {Mapping field-scale soil organic carbon with unmanned aircraft system-acquired time series multispectral images},
journal = {Soil and Tillage Research},
volume = {196},
pages = {104477},
year = {2020},
issn = {0167-1987},
doi = {https://doi.org/10.1016/j.still.2019.104477},
url = {https://www.sciencedirect.com/science/article/pii/S0167198718314612},
author = {Long Guo and Peng Fu and Tiezhu Shi and Yiyun Chen and Haitao Zhang and Ran Meng and Shanqin Wang},
keywords = {Digital soil mapping, Vegetation indices, Machine learning algorithms, Spatial variation},
abstract = {Rapidly and accurately obtaining soil organic carbon (SOC) maps can help understand farmland soil fertility and serves managing mineral fertilizers. The pedogenesis theory provides a fundamental basis for digital soil mapping by environmental factors. However, these soil forming factors may be insensitive to soil properties in low relief areas, such as plains or small-scale farmlands. To overcome this problem, an ingenious method for soil mapping was proposed based on the relationships between vegetative growth and soil fertility. Six multispectral images of a winter oilseed rape (Brassica napus L.) field were captured from October 2017 to March 2018 every month by using an unmanned aircraft system. The spectral bands and three vegetation indices were used as predictors to reflect the growth of rape and to predict SOC. Two regression models, i.e., stepwise regression (STR) and partial least square regression (PLSR), and three machine learning algorithms, namely, backpropagation neural networks (BPNN), extreme learning machine (ELM), and support vector machine (SVM), were applied for digital SOC mapping. The results show that (1) SOC has strong relationships with the spectral bands and vegetation indices in different months; (2) the ratios of performance to interquartile range (RPIQ) of STR, PLSR, SVM, BPNN, and ELM were 2.218, 2.074, 2.168, 2.546, and 2.380 in predicting SOC; (3) the spatial characteristics of SOC were existed between and within fields, but only BPNN and ELM can highlight the spatial heterogeneity of SOC within fields. Therefore, time series multispectral images can provide covariates and overcome the influence of surface vegetation in predicting SOC at the field scale, whereas machine learning algorithms can further extract valuable information from complex variables and improve soil mapping accuracy.}
}
@article{FONG2015278,
title = {A review of metaheuristics in robotics},
journal = {Computers & Electrical Engineering},
volume = {43},
pages = {278-291},
year = {2015},
issn = {0045-7906},
doi = {https://doi.org/10.1016/j.compeleceng.2015.01.009},
url = {https://www.sciencedirect.com/science/article/pii/S0045790615000154},
author = {Simon Fong and Suash Deb and Ankit Chaudhary},
keywords = {Collaborative robotics, Metaheuristics, Robotics, Swarm intelligence, Survey},
abstract = {Metaheuristics have a substantial history in fine-tuning machine learning algorithms. They gained tremendous popularity in many application domains. Robotics on the other hand is a wide research discipline that embraces artificial intelligence in a complex individually-thinking robot and distributed robots. Recently, metaheuristics made a significant impact on the application areas of collaborating robotics. This new trend of collaborating robotics, offers the possibility of enhanced task performance, high reliability, low unit complexity and decreased cost over traditional robotic systems. Collaborating robots however are more than just networks of independent agents; they are potentially reconfigurable networks of communicating agents capable of coordinated sensing and interaction with the environment. On the conceptual level, these bots can be empowered by the logics of metaheuristic algorithms which share the same functionalities and capabilities. This paper reviews the recent advances of metaheuristic algorithms on robotics applications. A taxonomy is provided as a reference for robotics designers.}
}
@article{JAMES201749,
title = {A historical survey of algorithms and hardware architectures for neural-inspired and neuromorphic computing applications},
journal = {Biologically Inspired Cognitive Architectures},
volume = {19},
pages = {49-64},
year = {2017},
issn = {2212-683X},
doi = {https://doi.org/10.1016/j.bica.2016.11.002},
url = {https://www.sciencedirect.com/science/article/pii/S2212683X16300561},
author = {Conrad D. James and James B. Aimone and Nadine E. Miner and Craig M. Vineyard and Fredrick H. Rothganger and Kristofor D. Carlson and Samuel A. Mulder and Timothy J. Draelos and Aleksandra Faust and Matthew J. Marinella and John H. Naegle and Steven J. Plimpton},
keywords = {Neuromorphic computing, Algorithms, Artificial neural networks, Data-driven computing, Machine learning, Pattern recognition},
abstract = {Biological neural networks continue to inspire new developments in algorithms and microelectronic hardware to solve challenging data processing and classification problems. Here, we survey the history of neural-inspired and neuromorphic computing in order to examine the complex and intertwined trajectories of the mathematical theory and hardware developed in this field. Early research focused on adapting existing hardware to emulate the pattern recognition capabilities of living organisms. Contributions from psychologists, mathematicians, engineers, neuroscientists, and other professions were crucial to maturing the field from narrowly-tailored demonstrations to more generalizable systems capable of addressing difficult problem classes such as object detection and speech recognition. Algorithms that leverage fundamental principles found in neuroscience such as hierarchical structure, temporal integration, and robustness to error have been developed, and some of these approaches are achieving world-leading performance on particular data classification tasks. In addition, novel microelectronic hardware is being developed to perform logic and to serve as memory in neuromorphic computing systems with optimized system integration and improved energy efficiency. Key to such advancements was the incorporation of new discoveries in neuroscience research, the transition away from strict structural replication and towards the functional replication of neural systems, and the use of mathematical theory frameworks to guide algorithm and hardware developments.}
}
@article{FANG2020103013,
title = {Computer vision applications in construction safety assurance},
journal = {Automation in Construction},
volume = {110},
pages = {103013},
year = {2020},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2019.103013},
url = {https://www.sciencedirect.com/science/article/pii/S0926580519301487},
author = {Weili Fang and Lieyun Ding and Peter E.D. Love and Hanbin Luo and Heng Li and Feniosky Peña-Mora and Botao Zhong and Cheng Zhou},
keywords = {Computer vision, Deep learning, Digital technology, Safety},
abstract = {Advancements in the development of deep learning and computer vision-based approaches have the potential to provide managers and engineers with the ability to improve the safety performance of their construction operations on-site. In practice, however, the application of deep learning and computer vision has been limited due to an array of technical (e.g., accuracy and reliability) and managerial challenges. These challenges are a product of the dynamic and complex nature of construction and the difficulties associated with acquiring video surveillance data. In this paper, we design and develop a deep learning and computer vision-based framework for safety in construction by integrating an array of digital technologies with multiple aspects of data fusion. Then, we review existing studies that have focused on identifying unsafe behavior and work conditions and develop a computer-vision enabled framework that: (1) considers current progress on computer vision and deep learning for safety; (2) identifies the research challenges that can materialize with using deep learning to identify unsafe behavior and work conditions; and (3) can provide a signpost for future research in the emergent and fertile area of deep-learning within the context of safety.}
}
@article{MISHRA20201,
title = {Drone-surveillance for search and rescue in natural disaster},
journal = {Computer Communications},
volume = {156},
pages = {1-10},
year = {2020},
issn = {0140-3664},
doi = {https://doi.org/10.1016/j.comcom.2020.03.012},
url = {https://www.sciencedirect.com/science/article/pii/S0140366419318602},
author = {Balmukund Mishra and Deepak Garg and Pratik Narang and Vipul Mishra},
keywords = {Drone surveillance, Convolution neural network (CNN), Object detection (OD), Action recognition, Aerial action dataset},
abstract = {Due to the increasing capability of drones and requirements to monitor remote areas, drone surveillance is becoming popular. In case of natural disaster, it can scan the wide affected-area quickly and make the search and rescue (SAR) faster to save more human lives. However, using autonomous drone for search and rescue is least explored and require attention of researchers to develop efficient algorithms in autonomous drone surveillance. To develop an automated application using recent advancement of deep-learning, dataset is the key. For this, a substantial amount of human detection and action detection dataset is required to train the deep-learning models. As dataset of drone surveillance in SAR is not available in literature, this paper proposes an image dataset for human action detection for SAR. Proposed dataset contains 2000 unique images filtered from 75,000 images. It contains 30000 human instances of different actions. Also, in this paper various experiments are conducted with proposed dataset, publicly available dataset, and stat-of-the art detection method. Our experiments shows that existing models are not adequate for critical applications such as SAR, and that motivates us to propose a model which is inspired by the pyramidal feature extraction of SSD for human detection and action recognition Proposed model achieves 0.98mAP when applied on proposed dataset which is a significant contribution. In addition, proposed model achieve 7% higher mAP value when applied to standard Okutama dataset in comparison with the state-of-the-art detection models in literature.}
}
@article{DU202067,
title = {Object-adaptive LSTM network for real-time visual tracking with adversarial data augmentation},
journal = {Neurocomputing},
volume = {384},
pages = {67-83},
year = {2020},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2019.12.022},
url = {https://www.sciencedirect.com/science/article/pii/S0925231219317242},
author = {Yihan Du and Yan Yan and Si Chen and Yang Hua},
keywords = {Visual tracking, LSTM network, Generative adversarial network, Data augmentation},
abstract = {In recent years, deep learning based visual tracking methods have obtained great success owing to the powerful feature representation ability of Convolutional Neural Networks (CNNs). Among these methods, classification-based tracking methods exhibit excellent performance while their speeds are heavily limited by the expensive computation for massive proposal feature extraction. In contrast, matching-based tracking methods (such as Siamese networks) possess remarkable speed superiority. However, the absence of online updating renders these methods unadaptable to significant object appearance variations. In this paper, we propose a novel real-time visual tracking method, which adopts an object-adaptive LSTM network to effectively capture the video sequential dependencies and adaptively learn the object appearance variations. For high computational efficiency, we also present a fast proposal selection strategy, which utilizes the matching-based tracking method to pre-estimate dense proposals and selects high-quality ones to feed to the LSTM network for classification. This strategy efficiently filters out some irrelevant proposals and avoids the redundant computation for feature extraction, which enables our method to operate faster than conventional classification-based tracking methods. In addition, to handle the problems of sample inadequacy and class imbalance during online tracking, we adopt a data augmentation technique based on the Generative Adversarial Network (GAN) to facilitate the training of the LSTM network. Extensive experiments on four visual tracking benchmarks demonstrate the state-of-the-art performance of our method in terms of both tracking accuracy and speed, which exhibits great potentials of recurrent structures for visual tracking.}
}
@article{BOUZID20181568,
title = {Energy based 3D trajectory tracking control of quadrotors with model-free based on-line disturbance compensation},
journal = {Chinese Journal of Aeronautics},
volume = {31},
number = {7},
pages = {1568-1578},
year = {2018},
issn = {1000-9361},
doi = {https://doi.org/10.1016/j.cja.2018.05.007},
url = {https://www.sciencedirect.com/science/article/pii/S1000936118301675},
author = {Yasser BOUZID and Houria SIGUERDIDJANE and Yasmina BESTAOUI},
keywords = {IDA-PBC, Model-free control, Nonlinear flight control, Robust control, Trajectory tracking},
abstract = {In this work, a Revisited form of the so-called Model-Free Control (R-MFC) is derived. Herein, the MFC principle is employed to deal with the unknown part of a plant only (i.e., unmodeled dynamics, disturbances, etc.) and occurs beside an Interconnection and Damping Assignment-Passivity Based Control (IDA-PBC) strategy. Using the proposed formulation, it is shown that we can significantly improve the performance of the control through the reshaping properties of the IDA-PBC technique. Moreover, the control robustness level is increased via a compensation of the time-varying disturbances and the unmodeled system dynamics. This on-line compensation capability is provided by the MFC principle. The problem is studied in the case of Multi-Input Multi-Output (MIMO) mechanical systems with an explicit application to a small Vertical Take-Off and Landing (VTOL) Unmanned Aerial Vehicle (UAV) where a stability analysis is also provided. Numerical simulations have shown satisfactory results, in comparison with some other control strategies, where an in-depth discussion with respect to the control performance is highlighted by considering several scenarios and using several metrics.}
}
@article{BENDALIBRAHAM2021100023,
title = {Recent trends in crowd analysis: A review},
journal = {Machine Learning with Applications},
volume = {4},
pages = {100023},
year = {2021},
issn = {2666-8270},
doi = {https://doi.org/10.1016/j.mlwa.2021.100023},
url = {https://www.sciencedirect.com/science/article/pii/S2666827021000049},
author = {Mounir Bendali-Braham and Jonathan Weber and Germain Forestier and Lhassane Idoumghar and Pierre-Alain Muller},
keywords = {Crowd analysis, Crowd behavior analysis, Group behavior analysis, Abnormal behavior detection, Deep Learning, Video-surveillance},
abstract = {When overpopulated cities face frequent crowded events like strikes, demonstrations, parades or other sorts of people gatherings, they are confronted to multiple security issues. To mitigate these issues, security forces are often involved to monitor the gatherings and to ensure the security of their participants. However, when access to technology is limited, the security forces can quickly become overwhelmed. Fortunately, more and more important smart cities are adopting the concept of intelligent surveillance systems. In these situations, intelligent surveillance systems require the most advanced techniques of crowd analysis to monitor crowd events properly. In this review, we explore various studies related to crowd analysis. Crowd analysis is commonly broken down into two major branches: crowd statistics and crowd behavior analysis. When crowd statistics determines the Level Of Service (LoS) of a crowded scene, crowd behavior analysis describes the motion patterns and the activities that are observed in a scene. One of the hottest topics of crowd analysis is anomaly detection. Although a unanimous definition of anomaly has not yet been met, each of crowd analysis subtopics can be subjected to abnormality. The purpose of our review is to find subareas, in crowd analysis, that are still unexplored or that seem to be rarely addressed through the prism of Deep Learning.}
}
@article{EDMONDS2021711,
title = {Learning-Based Near-Surface Modeling for Predictive Multirotor Landing Control⁎⁎This work was supported in part by the Siemens Corporate Technology FutureMaker project.},
journal = {IFAC-PapersOnLine},
volume = {54},
number = {20},
pages = {711-716},
year = {2021},
note = {Modeling, Estimation and Control Conference MECC 2021},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2021.11.255},
url = {https://www.sciencedirect.com/science/article/pii/S2405896321022990},
author = {Merrill Edmonds and Jingang Yi},
keywords = {Modeling, Identification, control methods, Flying robots},
abstract = {Multirotor aerial vehicles landing on moving platforms are subject to large near-surface forces which depend on the state of the multirotor and the geometry of the platform. These near-surface dynamics must be modeled accurately to minimize prediction errors in multirotor landing controllers. In this paper, we propose a novel learning-based method for modeling near-surface effects for arbitrary landing pad geometries. The model learns latent space representations of the landing pad geometries by auto-encoding robot-centered occupancy grids. Thrust and torque profiles for the multirotor under different control inputs and robot states are predicted using three neural networks that first predict single-rotor static thrusts and then correct these predictions for multi-rotor vortex interactions. The proposed method is tested using single- and multi-rotor thrust models to validate the learning approach and to ensure the thrust profiles are learnable given only on-board data. The latent space representations of the landing pads are investigated by comparing ground truth occupancy grids to reconstructions obtained from the auto-encoder sub-network. Time complexity for the method is analyzed to ensure the network can be used for real-time control applications.}
}
@article{GUO2019307,
title = {Underwater sea cucumber identification via deep residual networks},
journal = {Information Processing in Agriculture},
volume = {6},
number = {3},
pages = {307-315},
year = {2019},
issn = {2214-3173},
doi = {https://doi.org/10.1016/j.inpa.2019.06.004},
url = {https://www.sciencedirect.com/science/article/pii/S2214317319301581},
author = {Xiangyun Guo and Xuehua Zhao and Yahui Liu and Daoliang Li},
keywords = {Sea cucumber, Identification, Convolutional neural networks, Deep residual networks},
abstract = {Sea cucumber culture and fishing are primarily dependent on manual work. For fast and accurate automatic identification of sea cucumbers, deep residual networks with different configures were conducted in this experiment to identify underwater sea cucumber. Sea cucumber images were captured by a C-Watch remotely operated underwater vehicle (ROV) in a sea cucumber fishery at Haiyang Qiandao Lake in Shandong Province, China and sliced to positive samples and negative samples. Two training algorithms, namely, the stochastic gradient descent algorithm (SGD) and Adam, activation functions ReLU and leaky ReLU, as well as learning rates of 0.001, 0.005, 0.01, 0.05, and 0.1 were combined to form different models, which were trained with epochs 200 times and mini-batch of 100. The results showed that the accuracy of each model was higher than 82%, and the highest accuracy reached 89.53% under the SGD algorithm with ReLU and a learning rate of 0.05 or 0.1, which showed better generalization ability than that of other models. The performance of the proposed method indicates a great potential for automatic sea cucumber identification.}
}
@article{CLEDAT202024,
title = {Mapping quality prediction for RTK/PPK-equipped micro-drones operating in complex natural environment},
journal = {ISPRS Journal of Photogrammetry and Remote Sensing},
volume = {167},
pages = {24-38},
year = {2020},
issn = {0924-2716},
doi = {https://doi.org/10.1016/j.isprsjprs.2020.05.015},
url = {https://www.sciencedirect.com/science/article/pii/S0924271620301428},
author = {E. Cledat and L.V. Jospin and D.A. Cucci and J. Skaloud},
keywords = {Photogrammetry, Mapping, Aerial, Bundle adjustment, Unmanned aerial vehicle, GPS},
abstract = {Drone mapping with GNSS-assisted photogrammetry is a highly efficient method for surveying small- or medium-sized areas. However, the mapping quality is not intuitively predictable, particularly in complex environments (with steep and cluttered terrain), in which the quality of the real-time kinematic (RTK) or post-processed kinematic (PPK) positioning varies. We present a method to predict the mapping quality from the information that is available prior to the flight, such as the flight plan, expected flight time, approximate digital terrain model, prevailing surface texture, and embedded sensor characteristics. After detailing the important considerations, we also present the concept of global precision within the context of minimal and efficient ground control point placement in a complex terrain. Finally, we validate the proposed methodology by means of rigorous statistical testing against numerous experiments conducted under different mapping conditions.}
}
@article{VORAJEE2020697,
title = {Analyzing capacity of a consumer-grade infrared camera in South Africa for cost-effective aerial inspection of building envelopes},
journal = {Frontiers of Architectural Research},
volume = {9},
number = {3},
pages = {697-710},
year = {2020},
issn = {2095-2635},
doi = {https://doi.org/10.1016/j.foar.2020.05.004},
url = {https://www.sciencedirect.com/science/article/pii/S2095263520300418},
author = {Naadir Vorajee and Asit Kumar Mishra and Amit Kumar Mishra},
keywords = {IR thermography, Building envelopes, Cost-effective, Thermal images, Image processing, Segmentation algorithms},
abstract = {Prohibitive equipment cost and certain export regulations are the major obstacles to the widespread adoption of infrared (IR) thermography when evaluating building envelopes. In this work, we propose the use of an affordable and easily available camera as a first step of making the technology accessible. Combined with image post-processing, we hypothesize that a low-cost, low-resolution, and consumer-grade device can provide an economic alternative for the periodic evaluation of building envelopes. Following a market survey, the Seek Thermal Compact (STC) was chosen for evaluation. The STC was able to accurately measure the temperature of surfaces and distinguish small thermal anomalies (3 mm in diameter), and the IR images can be post-processed to reasonably estimate the anomaly areas. The STC was particularly effective when images were taken within 1.75 m from the surface. The 1.75 m distance did not pose a challenge in this study, as the goal was to mount the selected IR camera on an unmanned aerial vehicle for the surveys. The small size and weight of the STC were also useful. The results from the analysis of the capability of the STC and the image post-processing techniques may help form the basis of future investigations aiming at lowering the cost of building thermographic surveys.}
}
@article{WANG2019365,
title = {A crash prediction method based on bivariate extreme value theory and video-based vehicle trajectory data},
journal = {Accident Analysis & Prevention},
volume = {123},
pages = {365-373},
year = {2019},
issn = {0001-4575},
doi = {https://doi.org/10.1016/j.aap.2018.12.013},
url = {https://www.sciencedirect.com/science/article/pii/S0001457518304275},
author = {Chen Wang and Chengcheng Xu and Yulu Dai},
keywords = {Bivariate extreme value theory, Video-based vehicle trajectory, Traffic conflict, Crash prediction},
abstract = {Traditional statistical crash prediction models oftentimes suffer from poor data quality and require large amount of historical data. In this paper, we propose a crash prediction method based on a bivariate extreme value theory (EVT) framework, considering both drivers’ perception-reaction failure and failure to proper evasive actions. An unmanned aerial vehicle (UAV) was utilized to collect videos of ten intersections in Fengxian, China, at representative time periods. High-resolution vehicle trajectory data were extracted by a Kanade-Lucas-Tomasi (KLT) technique, based on four detailed metrics were derived including Time-to-accident (TA), Post-encroachment Time (PET), minimum Time-to-collision (mTTC), and Maximum Deceleration Rate (MaxD). TA was expected to capture the chance of perception-reaction failure, while other three metrics were used to measure the probability of failure to proper evasive actions. Univariate EVT models were applied to obtain marginal crash probability based on each metric. Bivariate EVT models were developed to obtain joint crash probability based on three pairs: TA and mTTC, TA and PET, and TA and MaxD. Thus, union crash probability within observation periods can be derived and the annual crash frequency of each intersection was predicted. The predictions were compared to actual annual crash frequencies, using multiple tests. The findings are three-folds: 1. The best conflict metrics for angle and rear-end crash predictions were different; 2. Bivariate EVT models were found to be superior to univariate models, regarding both angle and rear-end crash predictions; 3. TA appeared to be an important conflict metric that should be considered in a bivariate EVT model framework. In general, the proposed method can be considered as a promising tool for safety evaluation, when crash data are limited.}
}
@article{KHAN2020101642,
title = {Multi-hazard disaster studies: Monitoring, detection, recovery, and management, based on emerging technologies and optimal techniques},
journal = {International Journal of Disaster Risk Reduction},
volume = {47},
pages = {101642},
year = {2020},
issn = {2212-4209},
doi = {https://doi.org/10.1016/j.ijdrr.2020.101642},
url = {https://www.sciencedirect.com/science/article/pii/S2212420919310398},
author = {Amina Khan and Sumeet Gupta and Sachin Kumar Gupta},
keywords = {Landslide, Forest fire, Earthquake, Monitoring, Detection, Management, WSN, MANET, IoT, Artificial intelligence, Fuzzy logic, Remote sensing technique, Satellite imagery, UAV, Big data analytics},
abstract = {Every year man-made and natural disasters impact the lives of millions of people. The frequency of occurrence of such disasters is steadily increasing since the last 50 years, and this has resulted in considerable loss of life, destruction of infrastructure, and social and economic disruption. A focussed and comprehensive solution is needed encompassing all aspects, including early detection of disaster scenarios, prevention, recovery, and management to minimize the losses. This survey paper presents a critical analysis of the existing methods and technologies that are relevant to a disaster scenario, such as WSN, remote sensing technique, artificial intelligence, IoT, UAV, and satellite imagery, to encounter the issues associated with disaster monitoring, detection, and management. In case of emergency conditions arising out of a typical disaster scenario, there is a strong likelihood that the communication networks will be partially disrupted; thus the alternate networks can play a vital role in disaster detection and management. It focuses on the role of the alternate networks and the associated technologies in maintaining connectivity in various disaster scenarios. It presents a comprehensive study on multiple disasters such as landslide, forest fire, and an earthquake based on the latest technologies to monitor, detect, and manage the various disasters. It focuses on several parameters that are necessary for disaster detection and monitoring and offers appropriate solutions. It also touches upon big data analytics for disaster management. Several techniques are explored, along with their merits and demerits. Open challenges are highlighted, and possible future directions are given.}
}
@article{LIANG201697,
title = {Big data-enabled multiscale serviceability analysis for aging bridges☆},
journal = {Digital Communications and Networks},
volume = {2},
number = {3},
pages = {97-107},
year = {2016},
note = {Advances in Big Data},
issn = {2352-8648},
doi = {https://doi.org/10.1016/j.dcan.2016.05.002},
url = {https://www.sciencedirect.com/science/article/pii/S2352864816300268},
author = {Yu Liang and Dalei Wu and Guirong Liu and Yaohang Li and Cuilan Gao and Zhongguo John Ma and Weidong Wu},
keywords = {Hadoop Ecosystem, Bridge, Serviceability, Multi-scale, Reliability analysis, Deep learning},
abstract = {This work is dedicated to constructing a multi-scale structural health monitoring system to monitor and evaluate the serviceability of bridges based on the Hadoop Ecosystem (MS-SHM-Hadoop). By taking the advantages of the fault-tolerant distributed file system called the Hadoop Distributed File System (HDFS) and high-performance parallel data processing engine called MapReduce programming paradigm, MS-SHM-Hadoop features include high scalability and robustness in data ingestion, fusion, processing, retrieval, and analytics. MS-SHM-Hadoop is a multi-scale reliability analysis framework, which ranges from nationwide bridge-surveys, global structural integrity analysis, and structural component reliability analysis. This Nationwide bridge survey uses deep-learning techniques to evaluate the bridge serviceability according to real-time sensory data or archived bridge-related data such as traffic status, weather conditions and bridge structural configuration. The global structural integrity analysis of a targeted bridge is made by processing and analyzing the measured vibration signals incurred by external loads such as wind and traffic flow. Component-wise reliability analysis is also enabled by the deep learning technique, where the input data is derived from the measured structural load effects, hyper-spectral images, and moisture measurement of the structural components. As one of its major contributions, this work employs a Bayesian network to formulate the integral serviceability of a bridge according to its components serviceability and inter-component correlations. Here the inter-component correlations are jointly specified using a statistics-oriented machine learning method (e.g., association rule learning) or structural mechanics modeling and simulation.}
}
@article{SUR2021101386,
title = {Intelligent reflecting surface assisted MIMO communication system: A review},
journal = {Physical Communication},
volume = {47},
pages = {101386},
year = {2021},
issn = {1874-4907},
doi = {https://doi.org/10.1016/j.phycom.2021.101386},
url = {https://www.sciencedirect.com/science/article/pii/S1874490721001233},
author = {Samarendra Nath Sur and Rabindranath Bera},
keywords = {IRS, MIMO, Precoder, Beamforming, Radio environment, Channel estimation, Deployment},
abstract = {This paper presents a comprehensive literature review on the intelligent reflecting surface (IRS) assisted multiple input multiple output(MIMO) system. IRS is a new and key enabling technology that significantly improves the system performance and in combination with MIMO, it is considered to be the front runner for realizing the 6G networks. In this survey, we first discussed the basic concepts of the IRS and the following which we have discussed its advantages and possible applications. We have also provided an overview of the different applications of IRS assisted wireless networks and related issues in a very comprehensive way. The channel estimation protocols and the deployment strategies are reviewed and discussed thoroughly. It also highlights different applications, developed algorithms, and design considerations related to IRS assisted MIMO (IRS–MIMO) systems. And in the final section, we have discussed the research challenges and future research direction related to the IRS-MIMO system for realizing beyond 5G/6G networks.}
}
@article{DENG2019105006,
title = {Field detection and classification of citrus Huanglongbing based on hyperspectral reflectance},
journal = {Computers and Electronics in Agriculture},
volume = {167},
pages = {105006},
year = {2019},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2019.105006},
url = {https://www.sciencedirect.com/science/article/pii/S0168169919307574},
author = {Xiaoling Deng and Zixiao Huang and Zheng Zheng and Yubin Lan and Fen Dai},
keywords = {Citrus Huanglongbing, Hyperspectral, Band selection, Classification, Machine learning},
abstract = {Citrus Huanglongbing (HLB), also called citrus greening, is the most destructive disease in the citrus industry. Detecting the disease as early as possible and then eradicating infected roots can effectively control its spread. For the Shatangju mandarin cultivar, a non-destructive citrus HLB field detection method based on hyperspectral reflectance is proposed in this study. A characteristic band extraction method based on entropy distance and sequential backward selection is explored. Several machine learning algorithms (logistic regression, decision tree, support vector machine, k-nearest neighbor, linear discriminant analysis, and ensemble learning) were used to discriminate between disease groups: healthy, symptomatic HLB-infected, and asymptomatic HLB-infected, based on leaf reflectance. The results showed that the use of primary hyperspectral reflectance is very feasible for such classification. The band selection method proposed in this study provides an option for dimensionality reduction while still providing high classification accuracy. In three-group classification, the SVM learner achieved 90.8% accuracy, while in two-group classification (healthy vs symptomatic HLB leaves), the accuracy reached to 96%. The results also show that using only a few bands is insufficient for classification. In this study, 13 characteristic bands extracted by the proposed method provided the best performance.}
}
@article{GUPTA2021,
title = {People detection and counting using YOLOv3 and SSD models},
journal = {Materials Today: Proceedings},
year = {2021},
issn = {2214-7853},
doi = {https://doi.org/10.1016/j.matpr.2020.11.562},
url = {https://www.sciencedirect.com/science/article/pii/S2214785320392312},
author = {Pooja Gupta and Varsha Sharma and Sunita Varma},
keywords = {You only look once, Single shot multibox detector, Object detection, Object counting},
abstract = {Object detection has become a crucial task for the various applications used in the real world such as surveillance, security, and automated vehicle system. The counting of the numbers of peoples at any junction also having various applications to provide integrity to any task. To count the number of peoples at any junction, we have various methods. Among the present methods, we analyzed the two algorithms that are You Only Look Once (YOLOv3) and Single Shot multi-box Detector (SSD). Two tasks were performed independently; one is for object detection by using the image dataset, and the other one is the counting of objects by using the video dataset. In this research, these two methods are analyzed for counting as well as detection efficiency, and comparison is presented. The results have shown that the precision, recall, and F1 measure achieved for SSD is higher than YOLOV3 v3.}
}
@article{HUNG2012170,
title = {Multi-class predictive template for tree crown detection},
journal = {ISPRS Journal of Photogrammetry and Remote Sensing},
volume = {68},
pages = {170-183},
year = {2012},
issn = {0924-2716},
doi = {https://doi.org/10.1016/j.isprsjprs.2012.01.009},
url = {https://www.sciencedirect.com/science/article/pii/S0924271612000366},
author = {Calvin Hung and Mitch Bryson and Salah Sukkarieh},
keywords = {Agriculture, Forestry, Vision, Mapping, Engineering, Robotics},
abstract = {This paper presents a novel approach for automatic segmentation and object detection of tree crowns in airborne images captured from a low-flying Unmanned Aerial Vehicle (UAV) in ecology monitoring applications. Cost effective monitoring in these applications necessitates the use of vision-band-only imaging on the UAV platform; the reduction in spectral resolution (compared to multi- or hyper-spectral imaging) is balanced by the high spatial resolution available (∼20cm/pixel) from the low-flying UAV, when compared to existing satellite or manned-aerial survey data. Our approach to object detection thus uses both geometry and appearance information (through the use of tree shape and shadow information) in addition to spectral information to help accurately distinguish tree crowns within our application. A predictive geometric template for tree detection is constructed using on-board UAV navigation data, sun lighting information and information about the geometry of the target crown. A two-stage detection algorithm is then used to segment tree crowns based on spectral (colour) information convolved with information from the predictive template. Results of our approach are presented using airborne image data collected from a fixed-wing UAV during a weed monitoring and mapping mission over farmland in West Queensland, Australia.}
}
@article{XUEHUI2021103482,
title = {Dataset and benchmark for detecting moving objects in construction sites},
journal = {Automation in Construction},
volume = {122},
pages = {103482},
year = {2021},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2020.103482},
url = {https://www.sciencedirect.com/science/article/pii/S0926580520310621},
author = {An Xuehui and Zhou Li and Liu Zuguang and Wang Chengzhi and Li Pengfei and Li Zhiwei},
keywords = {Dataset, Deep neural networks, Construction site, Benchmark, Object detection},
abstract = {Detecting workers and equipment through images/videos can assist in safety monitoring, quality control, and productivity management at construction sites. Currently, the dominant method for detecting is Deep Neural Networks (DNNs). To apply this method, the DNNs always need to be trained on image datasets that contain objects at the construction site. However, a large-scale and publicly available image dataset for detecting objects at construction sites is still absent, and this hinders research in this field. In this study, the Moving Objects in Construction Sites (MOCS) image dataset is presented. The dataset contains 41,668 images collected from 174 different construction sites. Thirteen categories of moving objects found in construction sites were annotated. Furthermore, the objects were precisely annotated using per-pixel segmentations to assist in precise object localization. A detailed statistical analysis was performed in this study. Finally, a benchmark containing 15 different DNN-based detectors was made using the MOCS dataset. The results show that all detectors trained on the dataset could detect objects at construction sites precisely and robustly.}
}
@article{MAZIED2019104,
title = {The wireless control plane: An overview and directions for future research},
journal = {Journal of Network and Computer Applications},
volume = {126},
pages = {104-122},
year = {2019},
issn = {1084-8045},
doi = {https://doi.org/10.1016/j.jnca.2018.09.017},
url = {https://www.sciencedirect.com/science/article/pii/S1084804518303047},
author = {EmadelDin A. Mazied and Mustafa Y. ElNainay and Mohammad J. Abdel-Rahman and Scott F. Midkiff and Mohamed R.M. Rizk and Hesham A. Rakha and Allen B. MacKenzie},
keywords = {Software-defined networks, Wireless control plane, Wireless SDN controller, Deep reinforcement learning},
abstract = {Software-defined networking (SDN), which has been successfully deployed in the management of complex data centers, has recently been incorporated into a myriad of 5G networks to intelligently manage a wide range of heterogeneous wireless devices, software systems, and wireless access technologies. Thus, the SDN control plane needs to communicate wirelessly with the wireless data plane either directly or indirectly. The uncertainties in the wireless SDN control plane (WCP) make its design challenging. Both WCP schemes (direct WCP, D-WCP, and indirect WCP, I-WCP) have been incorporated into recent 5G networks; however, a discussion of their design principles and their design limitations is missing. This paper introduces an overview of the WCP design (I-WCP and D-WCP) and discusses its intricacies by reviewing its deployment in recent 5G networks. Furthermore, to facilitate synthesizing a robust WCP, this paper proposes a generic WCP framework using deep reinforcement learning (DRL) principles and presents a roadmap for future research.}
}
@article{STOGIANNOS2020106135,
title = {An enhanced decentralized artificial immune-based strategy formulation algorithm for swarms of autonomous vehicles},
journal = {Applied Soft Computing},
volume = {89},
pages = {106135},
year = {2020},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2020.106135},
url = {https://www.sciencedirect.com/science/article/pii/S1568494620300752},
author = {Marios Stogiannos and Alex Alexandridis and Haralambos Sarimveis},
keywords = {Artificial immune system, Autonomous vehicle swarm, Decentralized path planning, Optimal task allocation, Swarm intelligence},
abstract = {This work presents an algorithmic approach to the problem of strategy assignment to the members of a swarm of autonomous vehicles. The proposed methodology draws inspiration from the artificial immune system (AIS), where a large number of antibodies cooperate in order to protect an organism from foreign threats by local exchange of information. The decentralized nature of the methodology does not suffer from problems like the need of a central control unit, the high maintenance costs and the risks associated with having a single point of system failure, which are common to centralized control techniques. Decentralized and distributed optimization schemes employ simple algorithms, which are fast, robust and can run locally on an autonomous unit due to their low processing power requirements. In contrast to standard AIS-based decentralized schemes, the proposed methodology makes use of a dynamic formulation of the available strategies and avoids the possibility of choosing an invalid strategy, which may lead to inferior swarm performance. The methodology is further enhanced by a dual strategy activation decay technique and a blind threat-follow rule. Statistical testing on different case studies based on “enemy search and engage” type scenarios in a simulated environment demonstrates the superior performance of the proposed algorithm against the standard AIS, an enhanced AIS version and a centralized particle swarm optimization (PSO) based methodology.}
}
@article{CHEN2021112233,
title = {“Looking beneath the surface”: A visual-physical feature hybrid approach for unattended gauging of construction waste composition},
journal = {Journal of Environmental Management},
volume = {286},
pages = {112233},
year = {2021},
issn = {0301-4797},
doi = {https://doi.org/10.1016/j.jenvman.2021.112233},
url = {https://www.sciencedirect.com/science/article/pii/S0301479721002954},
author = {Junjie Chen and Weisheng Lu and Fan Xue},
keywords = {Construction and demolition waste, Construction waste management, Waste composition, Computer vision, Deep convolutional neural network, Support vector machine},
abstract = {There are various scenarios challenging human experts to judge the interior of something based on limited surface information. Likewise, at waste disposal facilities around the world, human inspectors are often challenged to gauge the composition of waste bulks to determine admissibility and chargeable levy. Manual approaches are laborious, hazardous, and prone to carelessness and fatigue, making unattended gauging of construction waste composition using simple surface information highly desired. This research attempts to contribute to automated waste composition gauging by harnessing a valuable dataset from Hong Kong. Firstly, visual features, called visual inert probability (VIP), characterizing inert and non-inert materials are extracted from 1127 photos of waste bulks using a fine-tuned convolutional neural network (CNN). Then, these visual features together with easy-to-obtain physical features (e.g., weight and depth) are fed to a tailor-made support vector machine (SVM) model to determine waste composition as measured by the proportions of inert and non-inert materials. The visual-physical feature hybrid model achieved a waste composition gauging accuracy of 94% in the experiments. This high performance implies that the model, with proper adaption and integration, could replace human inspectors to smooth the operation of the waste disposal facilities.}
}
@article{HAMLEDARI201778,
title = {Automated computer vision-based detection of components of under-construction indoor partitions},
journal = {Automation in Construction},
volume = {74},
pages = {78-94},
year = {2017},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2016.11.009},
url = {https://www.sciencedirect.com/science/article/pii/S0926580516304046},
author = {Hesam Hamledari and Brenda McCabe and Shakiba Davari},
keywords = {Computer vision, Interior construction, Machine learning, Image processing, Digital images, Indoors},
abstract = {This paper presents a computer vision-based algorithm that automatically detects the components of an interior partition and infers its current state using 2D digital images. The algorithm relies on four integrated shape and color-based modules, which detect studs, insulation, electrical outlets, and three states for drywall sheets (installed, plastered, and painted). Based on the results of the four modules, images are classified into five states. The proposed method was validated using three image databases of indoor construction sites captured by a quadcopter (a type of unmanned aerial vehicle), a smartphone, and collected from publically available sources on the internet. The method's high accuracy rates, its fast performance, and applicability to different contexts such as automated robotic inspection are indicative of its promising performance. The visual detection results can potentially provide situational awareness for construction trades, provide future progress tracking systems with information on actual state, and help leverage the use of image processing at indoor sites.}
}
@article{KUMAR2020113711,
title = {Recent trends in multicue based visual tracking: A review},
journal = {Expert Systems with Applications},
volume = {162},
pages = {113711},
year = {2020},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2020.113711},
url = {https://www.sciencedirect.com/science/article/pii/S0957417420305352},
author = {Ashish Kumar and Gurjit Singh Walia and Kapil Sharma},
keywords = {Visual tracking, Multicue, Deep learning, Tracking evaluation, Computer vision},
abstract = {In the recent years, multicue visual tracking frameworks have been preferred over single cue visual tracking approaches to address critical environmental challenges. In literature, it has been well accepted that combining multiple complementary cues extracted from single sensor or multiple sensors, deep features and features extracted from different layers of deep learning architecture enhance tracking performance and accuracy. In this paper, we have categorized the multi-cue object tracking work based on the exploited appearance model into traditional architecture and deep learning based trackers. The categorized work have been tabulated to provide detailed overview of the representative work and to list out the new trends in the domain. Also, we have briefly analyzed the various tracking benchmark and tabulated their substantial parameters. Our review work analyze the recent trends in the field of object tracking alongwith the latest tracking benchmark to indicate the future directions to the researchers. In addition, we have experimentally evaluated the state-of-the-arts on OTB-15, UAV123, VOT2017 and LaSOT datasets under various tracking challenges.}
}
@article{HOU2020103382,
title = {Inspection of surface defects on stay cables using a robot and transfer learning},
journal = {Automation in Construction},
volume = {119},
pages = {103382},
year = {2020},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2020.103382},
url = {https://www.sciencedirect.com/science/article/pii/S0926580520309626},
author = {Shitong Hou and Bin Dong and Haochen Wang and Gang Wu},
keywords = {Robotic defect inspection, Transfer learning, Cascade Mask RCNN, Stay cables, Defect image segmentation},
abstract = {In-service stay cables suffer from surface scratch and crack defects, which may cause corrosion inside cables, and fracture damage is likely to occur when those defects are exposed to long-term rain and sunshine environments. Current methods such as manual inspection and bridge inspection vehicles are inefficient, costly and risky. However, traditional image processing technologies (e.g., Canny) and convolutional neural networks may not be able to obtain accurate surface defect information. This paper proposes a novel and cost-effective method for identifying stay cable surface defects combining a cable inspection robot and transfer learning on a cascade mask region conventional neural network (Cascade Mask RCNN). This automatic procedure not only precisely identifies the defects but also locates and measures the defects that can be used for further maintenance strategies. Comparison work and on-site testing were conducted to evaluate the proposed model performance, and the validity of cable defects identification and measurement. An automatic and cost-effective inspection method is proposed for cable surface defect detection. Transfer learning with Cascade Mask RCNN model is presented for defect identification and location. The IoU index can reach up to 0.743, comparison work with other networks and on-site test was implemented to validate the validity and accuracy of cable surface defect detection and measurement.}
}
@article{HAMEED201824,
title = {A comprehensive review of fruit and vegetable classification techniques},
journal = {Image and Vision Computing},
volume = {80},
pages = {24-44},
year = {2018},
issn = {0262-8856},
doi = {https://doi.org/10.1016/j.imavis.2018.09.016},
url = {https://www.sciencedirect.com/science/article/pii/S0262885618301616},
author = {Khurram Hameed and Douglas Chai and Alexander Rassau},
keywords = {Recognition, Classification, Fruit, Vegetable, Produce classification, Machine learning, Computer vision},
abstract = {Recent advancements in computer vision have enabled wide-ranging applications in every field of life. One such application area is fresh produce classification, but the classification of fruit and vegetable has proven to be a complex problem and needs to be further developed. Fruit and vegetable classification presents significant challenges due to interclass similarities and irregular intraclass characteristics. Selection of appropriate data acquisition sensors and feature representation approach is also crucial due to the huge diversity of the field. Fruit and vegetable classification methods have been developed for quality assessment and robotic harvesting but the current state-of-the-art has been developed for limited classes and small datasets. The problem is of a multi-dimensional nature and offers significantly hyperdimensional features, which is one of the major challenges with current machine learning approaches. Substantial research has been conducted for the design and analysis of classifiers for hyperdimensional features which require significant computational power to optimise with such features. In recent years numerous machine learning techniques for example, Support Vector Machine (SVM), K-Nearest Neighbour (KNN), Decision Trees, Artificial Neural Networks (ANN) and Convolutional Neural Networks (CNN) have been exploited with many different feature description methods for fruit and vegetable classification in many real-life applications. This paper presents a critical comparison of different state-of-the-art computer vision methods proposed by researchers for classifying fruit and vegetable.}
}
@article{ZEGHLACHE2019330,
title = {Fault tolerant control for modified quadrotor via adaptive type-2 fuzzy backstepping subject to actuator faults},
journal = {ISA Transactions},
volume = {95},
pages = {330-345},
year = {2019},
issn = {0019-0578},
doi = {https://doi.org/10.1016/j.isatra.2019.04.034},
url = {https://www.sciencedirect.com/science/article/pii/S0019057819302083},
author = {Samir Zeghlache and Ali Djerioui and Loutfi Benyettou and Tarak Benslimane and Hemza Mekki and Abderrahmen Bouguerra},
keywords = {Backstepping control, Type-2 fuzzy logic systems, Adaptive control, Robust control, Modified quadrotor},
abstract = {In this paper, a robust attitude and position control of a novel modified quadrotor unmanned aerial vehicles (UAV) which has higher drive capability as well as greater robustness against actuator faults than conventional quad-rotor UAV has been developed. A robust backstepping controller with adaptive interval type-2 fuzzy logic is proposed to control the attitude and position of the modified quadrotor under actuator faults. Besides globally stabilizing the system amid other disturbances, the insensitivity to the model errors and parametric uncertainties are the asset of the backstepping approach. The adaptive interval type-2 fuzzy logic as fault observer can effectively estimate the lumped faults without the knowledge of their bounds for the modified quadrotor UAV. Additionally, the type-2 fuzzy systems are utilized to approximate the local nonlinearities of each subsystem under actuator faults, next and in order to achieve the expected tracking performance, we used Lyapunov theory stability and convergence analysis to online adjust adaptive laws. As a result, the uniformly ultimate stability of the modified quadrotor system is proved. Finally, the performances of the proposed control method are evaluated by simulation and the results demonstrate the effectiveness of the proposed control strategy for the modified quadrotor in vertical flights in presence of actuator faults.}
}
@article{WANG2019226,
title = {A review on weed detection using ground-based machine vision and image processing techniques},
journal = {Computers and Electronics in Agriculture},
volume = {158},
pages = {226-240},
year = {2019},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2019.02.005},
url = {https://www.sciencedirect.com/science/article/pii/S0168169918317150},
author = {Aichen Wang and Wen Zhang and Xinhua Wei},
keywords = {Weed detection, Machine vision, Image processing, Site-specific weed management, Precision agriculture},
abstract = {Weeds are among the major factors that could harm crop yield. With the advances in electronic and information technologies, machine vision combined with image processing techniques has become a promising tool for precise real-time weed and crop detection in the field, providing valuable sensing information for site-specific weed management. This review summarized the advances of weed detection using ground-based machine vision and image processing techniques. Concretely, the four procedures, i.e., pre-processing, segmentation, feature extraction and classification, for weed detection were presented in detail. To separate vegetation from background, different color indices and classification approaches like color index-based, threshold-based and learning-based ones, were developed. The difficulty of weed detection lies in discriminating between crops and weeds that often have similar properties. Generally, four categories of features, i.e., biological morphology, spectral features, visual textures and spatial contexts, were used for the task, which were discussed in this review. Application of conventional machine learning-based and recently developed deep learning-based approaches for weed detection were also presented. Finally, challenges and solutions provided by researchers for weed detection in the field, including occlusion and overlap of leaves, varying lighting conditions and different growth stages, were discussed.}
}
@article{MISHRA2022103954,
title = {Structural health monitoring of civil engineering structures by using the internet of things: A review},
journal = {Journal of Building Engineering},
volume = {48},
pages = {103954},
year = {2022},
issn = {2352-7102},
doi = {https://doi.org/10.1016/j.jobe.2021.103954},
url = {https://www.sciencedirect.com/science/article/pii/S235271022101812X},
author = {Mayank Mishra and Paulo B. Lourenço and G.V. Ramana},
keywords = {Internet of things, Structural health monitoring, Real-time monitoring, Concrete structures, Sensors, Masonry},
abstract = {Structural health monitoring (SHM) and damage assessment of civil engineering infrastructure are complex tasks. Structural health and strength of structures are influenced by various factors, such as the material production stage, transportation, placement, workmanship, formwork removal, and concrete curing. Technological advancements and the widespread availability of Wi-Fi networks has resulted in SHM shifting from traditional wire-based methods to Internet of Things (IoT)-based real-time wireless sensors. Comprehensive structural health assessment can be performed through the efficient use of real-time test data on structures obtained from various types of IoT sensors, which monitor several health parameters of structures, available on cloud-based data storage systems. The sensor data may be subsequently used for various applications, such as forecasting masonry construction deterioration, predicting the early-stage compressive strength of concrete, forecasting the optimum time for the removal of formwork, vibration and curing quality control, crack detection in buildings, pothole detection on roads, determination of the construction quality, corrosion diagnosis, identification of various damage typologies and seismic vulnerability assessment. This review paper summarizes the applications of the wireless IoT technology in the monitoring of civil engineering infrastructure. In addition, several case studies on real structures and laboratory investigations for monitoring the structural health of civil engineering constructions are discussed.}
}
@article{CHATTERJEE2020100279,
title = {Soil moisture quantity prediction using optimized neural supported model for sustainable agricultural applications},
journal = {Sustainable Computing: Informatics and Systems},
volume = {28},
pages = {100279},
year = {2020},
issn = {2210-5379},
doi = {https://doi.org/10.1016/j.suscom.2018.09.002},
url = {https://www.sciencedirect.com/science/article/pii/S2210537918302464},
author = {Sankhadeep Chatterjee and Nilanjan Dey and Soumya Sen},
keywords = {Soil moisture, Sustainable agriculture, Artificial neural network, Flower pollination algorithm, Stability analysis},
abstract = {Predicting soil moisture quantity could directly help the people engaged in sustainable agriculture and associated socio-economic structures. Recently researchers have engaged traditional and machine learning based models to predict soil moisture quantity. In the current study a modified Flower Pollination Algorithm (MFPA) has been employed to train Artificial Neural Network (ANN) to predict soil moisture quantity. The proposed method is compared with well known PSO (Particle Swarm optimization) supported ANN and Cuckoo Search (CS) supported ANN along with MLP-FFN classifier. The stability of the proposed model in presence of varying weather conditions has been established by performing a stability analysis using data level perturbation. Experimental results have indicated that NN-MFPA achieved an average RMSE of 0.0019 and outperformed other models. The ingenuity of the proposed model is further established by performing Wilcoxon rank test with 5% level of significance.}
}
@article{MORGAN2020135757,
title = {Drone-based imaging to assess the microbial water quality in an irrigation pond: A pilot study},
journal = {Science of The Total Environment},
volume = {716},
pages = {135757},
year = {2020},
issn = {0048-9697},
doi = {https://doi.org/10.1016/j.scitotenv.2019.135757},
url = {https://www.sciencedirect.com/science/article/pii/S0048969719357523},
author = {B.J. Morgan and M.D. Stocker and J. Valdes-Abellan and M.S. Kim and Y. Pachepsky},
keywords = {UAV, Water quality, , Irrigation pond, Pond habitats, Remote sensing},
abstract = {Microbial water quality datasets are essential in irrigated agricultural practices to detect and inform measures to prevent the contamination of produce. Escherichia coli (E. coli) concentrations are commonly used to evaluate microbial water quality. Remote sensing imagery has been successfully used to retrieve several water quality parameters that can be determinants of E. coli habitats in waterbodies. This pilot study was conducted to test the possibility of using imagery from a small unmanned aerial vehicle (sUAV or drone) to improve the estimation of microbial water quality in small irrigation ponds. In situ measurements of pH, turbidity, specific conductance, and concentrations of dissolved oxygen, chlorophyll-a, phycocyanin, and fluorescent dissolved organic matter were taken at depths of 0–15 cm in 23 locations across a pond in Central Maryland, USA. The pond surface was concurrently imaged using a drone with three modified GoPro cameras, and a multispectral MicaSense RedEdge camera with five spectral bands. The GoPro imagery was decomposed into red, blue, and green components. Mean digital numbers for 1-m radius areas in the images were combined with the water quality data to provide input for a regression tree-based analysis. The accuracy of the regression-tree data description with “only imagery” inputs was the same or better than that of trees constructed with “only water-quality parameters” as inputs. From multiple cross-validation runs with “only imagery” inputs for the regression trees, the average (±SD) determination coefficient and root-mean-squared error of the decimal logarithm of E. coli concentrations were 0.793 ± 0.035 and 0.131 ± 0.011, respectively. The results of this study demonstrate the opportunities for using sUAV imagery for obtaining a more accurate delineation of the spatial variation of E. coli concentrations in irrigation ponds.}
}
@article{SINGH202153,
title = {Challenges and Opportunities in Machine-Augmented Plant Stress Phenotyping},
journal = {Trends in Plant Science},
volume = {26},
number = {1},
pages = {53-69},
year = {2021},
issn = {1360-1385},
doi = {https://doi.org/10.1016/j.tplants.2020.07.010},
url = {https://www.sciencedirect.com/science/article/pii/S1360138520302405},
author = {Arti Singh and Sarah Jones and Baskar Ganapathysubramanian and Soumik Sarkar and Daren Mueller and Kulbir Sandhu and Koushik Nagasubramanian},
keywords = {image-based phenotyping, machine learning, deep learning, biotic stress, abiotic stress, standard area diagram},
abstract = {Plant stress phenotyping is essential to select stress-resistant varieties and develop better stress-management strategies. Standardization of visual assessments and deployment of imaging techniques have improved the accuracy and reliability of stress assessment in comparison with unaided visual measurement. The growing capabilities of machine learning (ML) methods in conjunction with image-based phenotyping can extract new insights from curated, annotated, and high-dimensional datasets across varied crops and stresses. We propose an overarching strategy for utilizing ML techniques that methodically enables the application of plant stress phenotyping at multiple scales across different types of stresses, program goals, and environments.}
}
@article{MONTEIRO20213020,
title = {Artificial Intelligence in Extended Agri-Food Supply Chain: A Short Review Based on Bibliometric Analysis},
journal = {Procedia Computer Science},
volume = {192},
pages = {3020-3029},
year = {2021},
note = {Knowledge-Based and Intelligent Information & Engineering Systems: Proceedings of the 25th International Conference KES2021},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2021.09.074},
url = {https://www.sciencedirect.com/science/article/pii/S1877050921018111},
author = {José Monteiro and João Barata},
keywords = {Artificial Intelligence, Extended Agri-Food Supply Chain, Agriculture 4.0, State of the Art},
abstract = {Climate change and population growth are triggering a digital transformation in agriculture. Consequently, agri-food supply chains are becoming more intelligent, producing vast amounts of data and pushing the boundaries of the traditional food lifecycle. However, artificial intelligence (AI) for the extended agri-food supply chain is only beginning to emerge. This paper presents a short literature review of eighteen papers on the intelligent agri-food supply chain. The bibliometric analysis reveals key research clusters and current trends in the AI-enabled stages of food production, distribution, and sustainable consumption. The important advances of AI in traditional stages of production need to be expanded with intelligent planning for demand uncertainty and personalized needs of end-customers, storage optimization, waste reduction in the post-production phase (e.g., distribution and recycling), and boundary-spanning analytics. For theory, this work highlights mature areas for AI adoption in agri-food and identifies opportunities for future research in the extended agri-food supply chain. For practice, the review findings can inspire startups interested in extended agri-food ecosystems and incumbents in their pilot projects for the intelligent and sustainable digital transformation of agri-food. AI techniques can contribute to close the loop of sustainable agri-food supply chains.}
}
@article{MUEHLEBACH201752,
title = {The Flying Platform – A testbed for ducted fan actuation and control design},
journal = {Mechatronics},
volume = {42},
pages = {52-68},
year = {2017},
issn = {0957-4158},
doi = {https://doi.org/10.1016/j.mechatronics.2017.01.001},
url = {https://www.sciencedirect.com/science/article/pii/S0957415817300016},
author = {Michael Muehlebach and Raffaello D’Andrea},
keywords = {Unmanned aerial vehicle, Ducted fans, Thrust vectoring, System identification of an unmanned aerial vehicle, Control design of an unmanned aerial vehicle},
abstract = {This article discusses the design of an unmanned aerial vehicle whose purpose is to study the use of electric ducted fans as control and propulsion system. Thrust vectoring is essential for stabilizing the vehicle. We present measurement results characterizing the thrust vectoring capabilities of the propulsion system (both statically and dynamically), discuss a first-principle model describing the behavior of the flying machine, and analyze and quantify the controllability about hover. The first-principle model is subsequently used for a cascaded control design, which is shown to work reliably in practice. Furthermore, system identification results are discussed and used to extended the model. The resulting augmented model is shown to match the measured frequency response function.}
}
@article{WANG20151667,
title = {Real-time drogue recognition and 3D locating for UAV autonomous aerial refueling based on monocular machine vision},
journal = {Chinese Journal of Aeronautics},
volume = {28},
number = {6},
pages = {1667-1675},
year = {2015},
issn = {1000-9361},
doi = {https://doi.org/10.1016/j.cja.2015.10.006},
url = {https://www.sciencedirect.com/science/article/pii/S1000936115001922},
author = {Xufeng Wang and Xingwei Kong and Jianhui Zhi and Yong Chen and Xinmin Dong},
keywords = {Autonomous aerial refueling, Drogue 3D locating, Drogue attitude measurement, Drogue detection, Drogue recognition, Monocular machine vision},
abstract = {Drogue recognition and 3D locating is a key problem during the docking phase of the autonomous aerial refueling (AAR). To solve this problem, a novel and effective method based on monocular vision is presented in this paper. Firstly, by employing computer vision with red-ring-shape feature, a drogue detection and recognition algorithm is proposed to guarantee safety and ensure the robustness to the drogue diversity and the changes in environmental conditions, without using a set of infrared light emitting diodes (LEDs) on the parachute part of the drogue. Secondly, considering camera lens distortion, a monocular vision measurement algorithm for drogue 3D locating is designed to ensure the accuracy and real-time performance of the system, with the drogue attitude provided. Finally, experiments are conducted to demonstrate the effectiveness of the proposed method. Experimental results show the performances of the entire system in contrast with other methods, which validates that the proposed method can recognize and locate the drogue three dimensionally, rapidly and precisely.}
}
@article{BA202177,
title = {Multi-hazard disaster scenario method and emergency management for urban resilience by integrating experiment–simulation–field data},
journal = {Journal of Safety Science and Resilience},
volume = {2},
number = {2},
pages = {77-89},
year = {2021},
issn = {2666-4496},
doi = {https://doi.org/10.1016/j.jnlssr.2021.05.002},
url = {https://www.sciencedirect.com/science/article/pii/S2666449621000141},
author = {Rui Ba and Qing Deng and Yi Liu and Rui Yang and Hui Zhang},
keywords = {Multi-hazard, Disaster, Scenario, Resilience, Emergency management},
abstract = {Due to the frequent occurrence of multi-hazard disasters worldwide in recent years, effective multi-hazard scenario analysis is imperative for disaster rescue and emergency management. The response procedure for different single hazards were investigated and formulated before. However, the investigations of disaster scenario rarely systematically address the entire development and response process of multi-hazards, including the coupling mechanisms, evolution dynamics, scenario assessment and emergency response. To this end, this paper presents our methodology of multi-hazard disaster scenario that integrates experiment–simulation–field data, focusing on three dimensions consisting of multi-hazard coupling, structures and systems, and emergency management. The newly proposed scenario method mainly comprises three aspects: experiments and simulations, multi-hazard field investigation, scenario analysis and response. Specifically, in order to study the large-scale, high-intensity and multi-hazard coupling effects, we carried out reduced-scale experiments and field measurement experiments to develop experimental similarity theory and prototype simulations of multi-hazards. In addition, a variety of field rescue and survey equipment, such as robots, Unmanned Aerial Vehicle (UAV), and Virtual Reality/Augmented Reality (VR/AR) technologies were utilized to acquire real-time data of multi-hazard field. Furthermore, we also examine the mechanism and framework of multi-hazard scenarios to formulate the detailed procedures of management and response. They are incorporated with the experiments, simulations, field data and models to construct a new scenario platform. The proposed scenario method was applied in a case study of the coupled wind and snow multi-hazard to verify its effectiveness. The new method contributes to the disaster relief, decision-making and emergency management for multi-hazard disaster to improve the urban resilience.}
}
@article{HAM2019102831,
title = {Automated content-based filtering for enhanced vision-based documentation in construction toward exploiting big visual data from drones},
journal = {Automation in Construction},
volume = {105},
pages = {102831},
year = {2019},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2019.102831},
url = {https://www.sciencedirect.com/science/article/pii/S0926580518303698},
author = {Youngjib Ham and Mirsalar Kamari},
keywords = {Visual sensing, Visual data filtering, UAV, Construction monitoring},
abstract = {In recent years, emerging mobile devices and camera-equipped platforms have offered a great convenience to visually capture and constantly document the as-is status of construction sites. In this regard, visual data are regularly collected in the form of numerous photos or lengthy videos. However, massive amounts of visual data that are being collected from jobsites (e.g., data collection on daily or weekly bases by Unmanned Aerial Vehicles, UAVs) has provoked visual data overload as an inevitable problem to face. To address such data overload issue in the construction domain, this paper aims at proposing a new method to automatically retrieve photo-worthy frames containing construction-related contents that are scattered in collected video footages or consecutive images. In the proposed method, the presence of objects of interest (i.e., construction-related contents) in given image frames are recognized by the semantic segmentation, and then scores of the image frames are computed based on the spatial composition of the identified objects. To improve the filtering performance, high-score image frames are further analyzed to estimate their likelihood to be intentionally taken. Case studies in two construction sites have revealed that the accuracy of the proposed method is close-to-human judgment in filtering visual data to retrieve photo-worthy image frames containing construction-related contents. The performance metrics demonstrate around 91% of accuracy in the semantic segmentation, and we observed enhanced human-like judgment in filtering construction visual data comparing to prior works. It is expected that the proposed automated method enables practitioners to assess the as-is status of construction sites efficiently through selective visual data, thereby facilitating data-driven decision making at the right time.}
}
@article{G2021101323,
title = {An hierarchical approach for automatic segmentation of leaf images with similar background using kernel smoothing based Gaussian process regression},
journal = {Ecological Informatics},
volume = {63},
pages = {101323},
year = {2021},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2021.101323},
url = {https://www.sciencedirect.com/science/article/pii/S157495412100114X},
author = {Jaya Brindha G. and Gopi E.S.},
keywords = {Automatic segmentation, Kernel linear discriminant analysis, Kernel smoothing based Gaussian process, Regression techniques},
abstract = {Real-time automation of leaf image segmentation is a difficult task when there are similar leaves in the background, particularly in leaf images captured in the cultivation fields. These leaf images play a key role in monitoring the growth and health of the plants. An hierarchical approach based on Kernel Linear Discriminant Analysis (KLDA) and Gaussian process regression is proposed in this paper for automating the segmentation process. In the first level, KLDA is used to discriminate the target leaf from its similar leaf background in two steps - (i) detecting the surfaces of the target leaf and (ii) detecting the edges of the target leaf. The resulting coarsely segmented image is further subjected to the second level consisting of the edge detection and morphological operations necessary for obtaining the fine segmented image. To fully automate the segmentation process, it is proposed to use the Gaussian process based regression technique for estimating the tuning parameters required for morphological processing. The proposed method is tested on a Sunflower leaf dataset and the ImageCLEF (Pl@ntleaves) dataset. The experimental results reveal the potential of the proposed method in automating the leaf segmentation process.}
}
@article{GAO2021199,
title = {EWNet: An early warning classification framework for smart grid based on local-to-global perception},
journal = {Neurocomputing},
volume = {443},
pages = {199-212},
year = {2021},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2021.03.007},
url = {https://www.sciencedirect.com/science/article/pii/S092523122100357X},
author = {Feng Gao and Qun Li and Yuzhu Ji and Shengchang Ji and Jie Guo and Haofei Sun and Yang Liu and Simeng Feng and Haokun Wei and Nan Wang and Biao Yang and Haijun Zhang},
keywords = {Power grid surveillance, Early warning classification, Deep learning, Image recognition},
abstract = {Early warning mechanism is crucial for maintaining the security and reliability of the power grid system. It remains to be a difficult task in a smart grid system due to complex environments in practice. In this paper, by considering the lack of vision-based datasets and models for early warning classification, we constructed a large-scale image dataset, namely EWSPG1.0, which contains 12,113 images annotated with five levels of early warnings. Moreover, 104,448 object instances with respect to ten categories of high-risk objects and power gird infrastructure were annotated with labels, bounding boxes and polygon masks. On the other hand, we proposed a local-to-global perception framework for arly warning classification, namely EWNet. Specifically, a local patch responsor is trained by using image patches extracted from the training set according to the labeled bounding box information of objects. The capability of recognizing high-risk objects and power grid infrastructure is transferred by loading the trained local patch responsor with frozen weights. Features are then fed into a feature integration module and a global classification module for early warning classification of an entire image. In order to evaluate the proposed framework, we benchmarked the proposed framework on our constructed dataset with 11 state-of-the-art deep convolutional neural networks (CNNs)-based classification models. Experimental results exhibit the effectiveness of our proposed method in terms of Top-1 classification accuracy. They also indicate that vision-based early warning classification remains challengeable under power grid surveillance and needs further study in future work.}
}
@article{PALAZZO2021107806,
title = {Exploiting structured high-level knowledge for domain-specific visual classification},
journal = {Pattern Recognition},
volume = {112},
pages = {107806},
year = {2021},
issn = {0031-3203},
doi = {https://doi.org/10.1016/j.patcog.2020.107806},
url = {https://www.sciencedirect.com/science/article/pii/S0031320320306099},
author = {S. Palazzo and F. Murabito and C. Pino and F. Rundo and D. Giordano and M. Shah and C. Spampinato},
keywords = {Fine-grained visual classification, Computational ontologies, Belief networks},
abstract = {In the last decade, deep learning models have yielded impressive performance on visual object recognition and image classification. However these methods still rely on learning visual data distributions and show difficulties in dealing with complex scenarios where visual appearance only is not enough to effectively tackle them. This is the case, for instance, of fine-grained image classification in domain-specific applications for which it is very complex to employ data-driven models because of the lack of large amounts of samples and that, instead, can be solved by resorting to specialized human knowledge. However, encoding this specialized knowledge and injecting it into deep models is not trivial. In this paper, we address this problem by: a) employing computational ontologies to model specialized knowledge in a structured representation and, b) building a hybrid visual-semantic classification framework. The classification method performs inference over a Bayesian Network graph, whose structure depends on the knowledge encoded in an ontology and evidences are built using the outputs of deep networks. We test our approach on a fine-grained classification task, employing an extremely complex dataset containing images from several fruit varieties as well as visual and semantic annotations. Since the classification is done at the variety level (e.g., discriminating between different cherry varieties), appearance changes slightly and expert domain knowledge — making using of contextual information — is required to perform classification accurately. Experimental results show that our approach significantly outperforms standard deep learning–based classification methods over the considered scenario as well as existing methods leveraging semantic information for classification. These results demonstrate, on one hand, the difficulty of purely-visual deep methods in tackling small and highly-specialized datasets and, on the other hard, the capabilities of our approach to effectively encode and use semantic knowledge for enhanced accuracy.}
}
@article{XIA2022,
title = {GAN-based anomaly detection: A review},
journal = {Neurocomputing},
year = {2022},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2021.12.093},
url = {https://www.sciencedirect.com/science/article/pii/S0925231221019482},
author = {Xuan Xia and Xizhou Pan and Nan Li and Xing He and Lin Ma and Xiaoguang Zhang and Ning Ding},
keywords = {Deep learning, Generative adversarial nets, Anomaly detection, Adversarial learning and inference, Representation learning},
abstract = {Supervised learning algorithms have shown limited use in the field of anomaly detection due to the unpredictability and difficulty in acquiring abnormal samples. In recent years, unsupervised or semi-supervised anomaly-detection algorithms have become more widely used in anomaly-detection tasks. As a form of unsupervised learning algorithm, generative adversarial networks (GAN/GANs) have been widely used in anomaly detection because GAN can make abnormal inferences using adversarial learning of the representation of samples. To provide inspiration for the research of GAN-based anomaly detection, this review reconsiders the concept of anomaly, provides three criteria for discussing the anomaly detection task, and discusses the current challenges of anomaly detection. For the existing works, this review focuses on the theoretical and technological evolution, theoretical basis, applicable tasks, and practical application of GAN-based anomaly detection. This review also addresses the current internal and external outstanding issues encountered by GAN-based anomaly detection and predicts and analyzes several future research directions in detail. This review summarizes more than 330 references related to GAN-based anomaly detection and provides detailed technical information for researchers who are interested in GANs and want to apply them to anomaly-detection tasks.}
}
@article{KUMAR20211,
title = {A drone-based networked system and methods for combating coronavirus disease (COVID-19) pandemic},
journal = {Future Generation Computer Systems},
volume = {115},
pages = {1-19},
year = {2021},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2020.08.046},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X20317064},
author = {Adarsh Kumar and Kriti Sharma and Harvinder Singh and Sagar Gupta Naugriya and Sukhpal Singh Gill and Rajkumar Buyya},
keywords = {Artificial intelligence, Collision avoidance, COVID-19, Drones, Internet of Things, Pandemic},
abstract = {Coronavirus disease (COVID-19) is an infectious disease caused by a newly discovered coronavirus. It is similar to influenza viruses and raises concerns through alarming levels of spread and severity resulting in an ongoing pandemic worldwide. Within eight months (by August 2020), it infected 24.0 million persons worldwide and over 824 thousand have died. Drones or Unmanned Aerial Vehicles (UAVs) are very helpful in handling the COVID-19 pandemic. This work investigates the drone-based systems, COVID-19 pandemic situations, and proposes an architecture for handling pandemic situations in different scenarios using real-time and simulation-based scenarios. The proposed architecture uses wearable sensors to record the observations in Body Area Networks (BANs) in a push–pull data fetching mechanism. The proposed architecture is found to be useful in remote and highly congested pandemic areas where either the wireless or Internet connectivity is a major issue or chances of COVID-19 spreading are high. It collects and stores the substantial amount of data in a stipulated period and helps to take appropriate action as and when required. In real-time drone-based healthcare system implementation for COVID-19 operations, it is observed that a large area can be covered for sanitization, thermal image collection, and patient identification within a short period (2 KMs within 10 min approx.) through aerial route. In the simulation, the same statistics are observed with an addition of collision-resistant strategies working successfully for indoor and outdoor healthcare operations. Further, open challenges are identified and promising research directions are highlighted.}
}
@article{ATYABI2018196,
title = {Current advancements on autonomous mission planning and management systems: An AUV and UAV perspective},
journal = {Annual Reviews in Control},
volume = {46},
pages = {196-215},
year = {2018},
issn = {1367-5788},
doi = {https://doi.org/10.1016/j.arcontrol.2018.07.002},
url = {https://www.sciencedirect.com/science/article/pii/S1367578818300257},
author = {Adham Atyabi and Somaiyeh MahmoudZadeh and Samia Nefti-Meziani},
keywords = {Cognition, Mission management, Autonomy, Contingency management, Situational awareness},
abstract = {Advances in hardware technology have enabled more integration of sophisticated software, triggering progresses in development and employment of Unmanned Vehicles (UVs), and mitigating restraints for onboard intelligence. As a result, UVs can now take part in more complex mission where continuous transformation in environmental condition calls for higher level of situational responsiveness. This paper serves as an introduction to UVs mission planning and management systems aiming to highlight some of the recent developments in the field of autonomous underwater and aerial vehicles in addition to stressing some possible future directions and discussing the learned lessons. A comprehensive survey over autonomy assessment of UVs, and different aspects of autonomy such as situation awareness, cognition, and decision-making has been provided in this study. The paper separately explains the humanoid and autonomous system's performance and highlights the role and impact of a human in UVs operations.}
}
@article{TAN201318,
title = {Research Advance in Swarm Robotics},
journal = {Defence Technology},
volume = {9},
number = {1},
pages = {18-39},
year = {2013},
issn = {2214-9147},
doi = {https://doi.org/10.1016/j.dt.2013.03.001},
url = {https://www.sciencedirect.com/science/article/pii/S221491471300024X},
author = {Ying Tan and Zhong-yang Zheng},
keywords = {Swarm robotics, Cooperative control, Modeling, Simulation, Swarm intelligence},
abstract = {The research progress of swarm robotics is reviewed in details. The swarm robotics inspired from nature is a combination of swarm intelligence and robotics, which shows a great potential in several aspects. First of all, the cooperation of nature swarm and swarm intelligence are briefly introduced, and the special features of the swarm robotics are summarized compared to a single robot and other multi-individual systems. Then the modeling methods for swarm robotics are described, followed by a list of several widely used swarm robotics entity projects and simulation platforms. Finally, as a main part of this paper, the current research on the swarm robotic algorithms are presented in detail, including cooperative control mechanisms in swarm robotics for flocking, navigating and searching applications.}
}
@article{XIONG2022104066,
title = {A blockchain-based edge collaborative detection scheme for construction internet of things},
journal = {Automation in Construction},
volume = {134},
pages = {104066},
year = {2022},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2021.104066},
url = {https://www.sciencedirect.com/science/article/pii/S0926580521005173},
author = {Feng Xiong and Cheng Xu and Wei Ren and Rongyue Zheng and Peisong Gong and Yi Ren},
keywords = {Smart construction, Internet of things, Edge computing, Coordinated recognition, Smart contract},
abstract = {For smart construction, it is increasingly necessary to develop innovative methods to automatically detect whether construction workers are wearing safety helmets or not. With the development of Internet of Things and object detection in deep learning, it is possible to enable object detection in end devices. In this paper, we propose a coordinated recognition scheme based on YOLOv3 to automatically detect safety helmets at construction sites. Our scheme provides coordinated recognition from multiple devices to obtain comprehensive detection results with multiple viewpoints, which improves the detection accuracy. Besides, to strengthen the security and reliability of detection devices, we propose a peer-to-peer cooperation scheme which is based on smart contract over blockchain. Our scheme ensures that only trusted devices can initiate or participate coordinated recognition tasks. All access and detection records are stored in the blockchain, which is auditable and traceable. Moreover, we propose a fair video sharing mechanism which encourages trusted devices to actively participate in the coordinated recognition tasks. Only participated nodes can access the shared detection videos from others, which forms an alliance of fair sharing with long term interest. The experimental results and analysis justify that our scheme performs well in terms of security and detection accuracy at few expense of a certain startup delay. Our framework can be employed for detecting other objects related to risks in smart construction.}
}
@article{SUN2022105034,
title = {A review of Earth Artificial Intelligence},
journal = {Computers & Geosciences},
volume = {159},
pages = {105034},
year = {2022},
issn = {0098-3004},
doi = {https://doi.org/10.1016/j.cageo.2022.105034},
url = {https://www.sciencedirect.com/science/article/pii/S0098300422000036},
author = {Ziheng Sun and Laura Sandoval and Robert Crystal-Ornelas and S. Mostafa Mousavi and Jinbo Wang and Cindy Lin and Nicoleta Cristea and Daniel Tong and Wendy Hawley Carande and Xiaogang Ma and Yuhan Rao and James A. Bednar and Amanda Tan and Jianwu Wang and Sanjay Purushotham and Thomas E. Gill and Julien Chastang and Daniel Howard and Benjamin Holt and Chandana Gangodagamage and Peisheng Zhao and Pablo Rivas and Zachary Chester and Javier Orduz and Aji John},
keywords = {Geosphere, Hydrology, Atmosphere, Artificial intelligence/machine learning, Big data, Cyberinfrastructure},
abstract = {In recent years, Earth system sciences are urgently calling for innovation on improving accuracy, enhancing model intelligence level, scaling up operation, and reducing costs in many subdomains amid the exponentially accumulated datasets and the promising artificial intelligence (AI) revolution in computer science. This paper presents work led by the NASA Earth Science Data Systems Working Groups and ESIP machine learning cluster to give a comprehensive overview of AI in Earth sciences. It holistically introduces the current status, technology, use cases, challenges, and opportunities, and provides all the levels of AI practitioners in geosciences with an overall big picture and to “blow away the fog to get a clearer vision” about the future development of Earth AI. The paper covers all the majorspheres in the Earth system and investigates representative AI research in each domain. Widely used AI algorithms and computing cyberinfrastructure are briefly introduced. The mandatory steps in a typical workflow of specializing AI to solve Earth scientific problems are decomposed and analyzed. Eventually, it concludes with the grand challenges and reveals the opportunities to give some guidance and pre-warnings on allocating resources wisely to achieve the ambitious Earth AI goals in the future.}
}
@article{NG2021107178,
title = {Maximizing minority accuracy for imbalanced pattern classification problems using cost-sensitive Localized Generalization Error Model},
journal = {Applied Soft Computing},
volume = {104},
pages = {107178},
year = {2021},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2021.107178},
url = {https://www.sciencedirect.com/science/article/pii/S1568494621001010},
author = {Wing W.Y. Ng and Zhengxi Liu and Jianjun Zhang and Witold Pedrycz},
keywords = {Localized generalization error model (L-GEM), Cost-sensitive, Multilayer perceptron neural network (MLPNN)},
abstract = {Traditional machine learning methods may not yield satisfactory generalization capability when samples in different classes are imbalanced. These methods tend to sacrifice the accuracy of the minority class to improve the overall accuracy without regarding the fact that misclassifications of minority samples usually costs more in many real world applications. Therefore, we propose a neural network training method via a minimization of the cost-sensitive localized generalization error-based objective function (c-LGEM) to achieve a better balance of error yielded by the minority and the majority classes. The c-LGEM emphasizes the minimization of the generalization error of the minority class in a cost-sensitive manner. Experimental results obtained on 16 UCI datasets show that neural networks trained by the c-LGEM yield better performance in comparison to the performance yielded by some existing methods.}
}
@article{LAROSA202135,
title = {Multi-task fully convolutional network for tree species mapping in dense forests using small training hyperspectral data},
journal = {ISPRS Journal of Photogrammetry and Remote Sensing},
volume = {179},
pages = {35-49},
year = {2021},
issn = {0924-2716},
doi = {https://doi.org/10.1016/j.isprsjprs.2021.07.001},
url = {https://www.sciencedirect.com/science/article/pii/S0924271621001787},
author = {Laura Elena Cué {La Rosa} and Camile Sothe and Raul Queiroz Feitosa and Cláudia Maria {de Almeida} and Marcos Benedito Schimalski and Dário Augusto Borges Oliveira},
keywords = {Semantic segmentation, Tree species identification, Multi-task learning, Fully convolutional network, Sparse annotations},
abstract = {This work proposes a multi-task fully convolutional architecture for tree species mapping in dense forests from sparse and scarce polygon-level annotations using hyperspectral UAV-borne data. Our model implements a partial loss function that enables dense tree semantic labeling outcomes from non-dense training samples, and a distance regression complementary task that enforces tree crown boundary constraints and substantially improves the model performance. Our multi-task architecture uses a shared backbone network that learns common representations for both tasks and two task-specific decoders, one for the semantic segmentation output and one for the distance map regression. We report that introducing the complementary task boosts the semantic segmentation performance compared to the single-task counterpart in up to 11% reaching an average user’s accuracy of 88.63% and an average producer’s accuracy of 88.59%, achieving state-of-art performance for tree species classification in tropical forests.}
}
@article{DAS201646,
title = {MRoCS: A new multi-robot communication system based on passive action recognition},
journal = {Robotics and Autonomous Systems},
volume = {82},
pages = {46-60},
year = {2016},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2016.04.002},
url = {https://www.sciencedirect.com/science/article/pii/S0921889015301482},
author = {Barnali Das and Micael S. Couceiro and Patricia A. Vargas},
keywords = {Swarm robotics, Multi-robot communication, Passive action recognition, Bio-inspired computation, Honey bee waggle dance, Unmanned aerial vehicle},
abstract = {Multi-robot search-and-rescue missions often face major challenges in adverse environments due to the limitations of traditional implicit and explicit communication. This paper proposes a novel multi-robot communication system (MRoCS), which uses a passive action recognition technique that overcomes the shortcomings of traditional models. The proposed MRoCS relies on individual motion, by mimicking the waggle dance of honey bees and thus forming and recognising different patterns accordingly. The system was successfully designed and implemented in simulation and with real robots. Experimental results show that, the pattern recognition process successfully reported high sensitivity with good precision in all cases for three different patterns thus corroborating our hypothesis.}
}
@article{GAO2021107683,
title = {Monitoring terrain elevation of intertidal wetlands by utilising the spatial-temporal fusion of multi-source satellite data: A case study in the Yangtze (Changjiang) Estuary},
journal = {Geomorphology},
volume = {383},
pages = {107683},
year = {2021},
issn = {0169-555X},
doi = {https://doi.org/10.1016/j.geomorph.2021.107683},
url = {https://www.sciencedirect.com/science/article/pii/S0169555X2100091X},
author = {Wenli Gao and Fang Shen and Kai Tan and Weiguo Zhang and Quanxing Liu and Nina S.N. Lam and Jianzhong Ge},
keywords = {Terrain elevation, Intertidal wetland, Remote sensing, Spatial-temporal data fusion, Yangtze (Changjiang) Estuary},
abstract = {Intertidal wetlands are dynamic geomorphological areas located at the land-sea interface and perform multiple ecosystem functions. Owing to increased human activities, intertidal wetlands have been subjected to dramatic changes in recent decades; therefore, high-resolution monitoring of wetland topography is critical to its management. However, satellite imagery with high spatial resolution usually demonstrates a low revisit frequency (e.g. several days to greater than ten days) and is frequently obstructed by clouds, limiting its capability to display the high-resolution time-series information of intertidal wetland terrain elevation variations. Conversely, satellite imagery with a high revisit frequency generally demonstrates a lower spatial resolution. In this study, a spatial-temporal data fusion method was utilised to generate hourly time-series images with a spatial resolution of 16 m by combining the satellite GF-1/WFV data (spatial resolution: 16 m; revisit frequency: 4 days) with geostationary satellite GOCI data (spatial resolution: 500 m; revisit frequency: 1 h). In combination with the tidal level information, digital terrain elevation (DTM) data of the intertidal wetland can be derived from fusion images. The DTM was synchronously validated by the terrain elevation data acquired on the same day utilising unmanned aerial vehicle (UAV)-borne LiDAR in the North Branch intertidal wetland of Chongming Island, Yangtze Estuary, with a root mean square error of 0.16 m. The application in Chongming-Dongtan indicates that this method is effective for monitoring high dynamic changes in intertidal wetland terrain elevations.}
}
@article{KARTAL2021101467,
title = {Comparison of semantic segmentation algorithms for the estimation of botanical composition of clover-grass pastures from RGB images},
journal = {Ecological Informatics},
volume = {66},
pages = {101467},
year = {2021},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2021.101467},
url = {https://www.sciencedirect.com/science/article/pii/S1574954121002582},
author = {Serkan Kartal},
keywords = {Semantic segmentation, Clover-grass, Precision agriculture, Deep learning},
abstract = {In dairy industry, estimation of the in-field clover-grass ratio is an important factor in composing feed ratios for cows. Accurate estimation of the grass and clover ratios enables smart decisions to optimize seeding density and fertilization, resulting in increased yield and reduced amount of chemicals used. In practice, this process is still primarily performed by human-eye, which is labor-intensive, subjective, and error-prone. Therefore, plant species ratio estimation using traditional methods is hardly possible and misleading. Modern semantic segmentation models on digital images offer a promising alternative to overcome these drawbacks. In this paper, an extensive comparison of Deep Learning (DL) models for estimating the ratio of clover, grass, and weeds in red, green, and blue (RGB) images is presented. Three DL architectures (Unet, Linknet, FPN) are combined with ten randomly initialized encoders (variations of VGG, DenseNet, ResNet, Inception and EfficientNet) to construct thirty different segmentation models. Evaluation of models was performed on a publicly available dataset provided by the Biomass Prediction Challenge. The best segmentation accuracy was reached by the FPN-Inceptionresnetv2 model by 76.7%. This result indicates the great potential in deep convolutional neural networks for the segmentation of plant species in RGB images. Furthermore, this study lays the foundation for our next set of experiments with DL to improve the benchmarks and will further the quest to identify phenotype characteristics from agricultural imagery collected from the field.}
}
@article{WEI2020105119,
title = {Intelligent monitoring and control technologies of open sea cage culture: A review},
journal = {Computers and Electronics in Agriculture},
volume = {169},
pages = {105119},
year = {2020},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2019.105119},
url = {https://www.sciencedirect.com/science/article/pii/S0168169919314115},
author = {Yaoguang Wei and Qiong Wei and Dong An},
keywords = {Aquaculture, Water environment monitoring, Fish behaviour monitoring, Intelligent feeding, Intelligent control, Open sea cage},
abstract = {Since open sea cage culture sites are far from shore, the sea situation is complex and changeable, and the monitoring of cage culture water quality, fish behaviour, cage operation and other states is the basis of intelligent control of cage casting, feeding, capture, and cage washing to achieve high yield, high efficiency, and safety of cage farming. First, a cage farming model is introduced for analysis of the needs of intelligent monitoring and control technology. The applications of underwater robots, unmanned aerial vehicles, online monitoring networks and other technologies involved in aquaculture water environment information monitoring are summarized. Secondly, the intelligent management of cages is summarized. This paper demonstrates that cage farming is the trend of aquaculture. In the future, applications will combine information monitoring technology, intelligent control technology, and intelligent equipment technology to realize intelligent, digital, automatic and unmanned operation of cage aquaculture.}
}
@article{BERGER2020111758,
title = {Crop nitrogen monitoring: Recent progress and principal developments in the context of imaging spectroscopy missions},
journal = {Remote Sensing of Environment},
volume = {242},
pages = {111758},
year = {2020},
issn = {0034-4257},
doi = {https://doi.org/10.1016/j.rse.2020.111758},
url = {https://www.sciencedirect.com/science/article/pii/S0034425720301280},
author = {Katja Berger and Jochem Verrelst and Jean-Baptiste Féret and Zhihui Wang and Matthias Wocher and Markus Strathmann and Martin Danner and Wolfram Mauser and Tobias Hank},
keywords = {Hyperspectral, Biochemical traits, Radiative transfer modelling, Hybrid techniques, machine learning},
abstract = {Nitrogen (N) is considered as one of the most important plant macronutrients and proper management of N therefore is a pre-requisite for modern agriculture. Continuous satellite-based monitoring of this key plant trait would help to understand individual crop N use efficiency and thus would enable site-specific N management. Since hyperspectral imaging sensors could provide detailed measurements of spectral signatures corresponding to the optical activity of chemical constituents, they have a theoretical advantage over multi-spectral sensing for the detection of crop N. The current study aims to provide a state-of-the-art overview of crop N retrieval methods from hyperspectral data in the agricultural sector and in the context of future satellite imaging spectroscopy missions. Over 400 studies were reviewed for this purpose, identifying those estimating mass-based N (N concentration, N%) and area-based N (N content, Narea) using hyperspectral remote sensing data. Retrieval methods of the 125 studies selected in this review can be grouped into: (1) parametric regression methods, (2) linear nonparametric regression methods or chemometrics, (3) nonlinear nonparametric regression methods or machine learning regression algorithms, (4) physically-based or radiative transfer models (RTM), (5) use of alternative data sources (sun-induced fluorescence, SIF) and (6) hybrid or combined techniques. Whereas in the last decades methods for estimation of Narea and N% from hyperspectral data have been mainly based on simple parametric regression algorithms, such as narrowband vegetation indices, there is an increasing trend of using machine learning, RTM and hybrid techniques. Within plants, N is invested in proteins and chlorophylls stored in the leaf cells, with the proteins being the major nitrogen-containing biochemical constituent. However, in most studies, the relationship between N and chlorophyll content was used to estimate crop N, focusing on the visible-near infrared (VNIR) spectral domains, and thus neglecting protein-related N and reallocation of nitrogen to non-photosynthetic compartments. Therefore, we recommend exploiting the estimation of nitrogen via the proxy of proteins using hyperspectral data and in particular the short-wave infrared (SWIR) spectral domain. We further strongly encourage a standardization of nitrogen terminology, distinguishing between N% and Narea. Moreover, the exploitation of physically-based approaches is highly recommended combined with machine learning regression algorithms, which represents an interesting perspective for future research in view of new spaceborne imaging spectroscopy sensors.}
}
@article{PARK2020105882,
title = {Stereo vision based obstacle collision avoidance for a quadrotor using ellipsoidal bounding box and hierarchical clustering},
journal = {Aerospace Science and Technology},
volume = {103},
pages = {105882},
year = {2020},
issn = {1270-9638},
doi = {https://doi.org/10.1016/j.ast.2020.105882},
url = {https://www.sciencedirect.com/science/article/pii/S1270963820305642},
author = {Jongho Park and Hoki Baek},
keywords = {Collision avoidance, Multiple obstacles, Ellipsoidal bounding box, Hierarchical clustering, Unmanned aerial vehicle, Quadrotor},
abstract = {A collision avoidance algorithm for multiple unknown static obstacles is proposed for a quadrotor system. A stereo vision system with a limited field of view and sensing range is assumed to be mounted on the quadrotor to obtain obstacle information. An ellipsoid is chosen as a circumscribed bounding box containing the obtained obstacle data points, which can be determined by solving a convex optimization problem. An affine transformation is used to form a collision cone consisting of straight lines tangent to the ellipsoid. A collision condition is examined using the collision cone and velocity vector of the quadrotor. The hierarchical clustering method is proposed to address multiple obstacles, and the bounding boxes are updated using the clusters. Numerical simulations are performed to demonstrate the performance of the proposed collision avoidance algorithm.}
}
@article{BRINKHOFF2021102627,
title = {Rice nitrogen status detection using commercial-scale imagery},
journal = {International Journal of Applied Earth Observation and Geoinformation},
volume = {105},
pages = {102627},
year = {2021},
issn = {0303-2434},
doi = {https://doi.org/10.1016/j.jag.2021.102627},
url = {https://www.sciencedirect.com/science/article/pii/S0303243421003342},
author = {James Brinkhoff and Brian W. Dunn and Andrew J. Robson},
keywords = {Remote sensing, Precision Agriculture, Statistical Modeling, Machine Learning, Rice, Nitrogen},
abstract = {Determining the mid-season nitrogen status of rice is important for precision application of fertilizer to optimize productivity. While there has been much research aimed at developing remote-sensing-based models to predict the nitrogen status of rice, this has been predominantly limited to scientific small plot trials, relying on experts performing radiometric calibrations, encompassing limited cultivars, seasons and locations, and uniform management practices. As such, there has been little testing of models at commercial scale, against the range of conditions encountered across entire growing regions. To fill this gap, this work brings together four years of data, from both experimental replicated plot trials (38 datasets with 1734 observations) and commercial farms (12 datasets with 106 observations). Using commercial scale imagery acquired from airplanes, a number of nitrogen uptake modeling methodologies were evaluated. Universal single vegetation index based linear regression models had prediction root mean squared error (RMSE) of more than 45 kg/ha when tested at the 12 commercial sites. Machine learning models using multiple remote sensing features were able to improve predictions somewhat (RMSE > 30 kg/ha). Practically useful accuracies were achieved after using three local field samples to calibrate models to each field image. The prediction RMSE using this methodology was 22.9 kg/ha, or 19.4%. This approach enables provision of optimal variable-rate mid-season rice fertilizer prescriptions to growers, while motivating continued research towards development of methods that reduce requirement of local sampling.}
}
@article{LEI2011821,
title = {A small unmanned polar research aerial vehicle based on the composite control method},
journal = {Mechatronics},
volume = {21},
number = {5},
pages = {821-830},
year = {2011},
note = {Special Issue on Development of Autonomous Unmanned Aerial Vehicles},
issn = {0957-4158},
doi = {https://doi.org/10.1016/j.mechatronics.2010.12.002},
url = {https://www.sciencedirect.com/science/article/pii/S0957415810002138},
author = {Xusheng Lei and Lang Bai and Yuhu Du and Cunxiao Miao and Yang Chen and Tianmiao Wang},
keywords = {Unmanned aerial vehicle, Trajectory following control, Vector filed, LQR},
abstract = {Focusing on the polar extreme environment, a composite control method is proposed to finish the polar scientific research task in this paper. Based on the vector field and the linear quadratic regulator (LQR) control method, the small unmanned aerial vehicle can realize precise trajectory following control under wind disturbance. Through vector filed method, system constructs the corresponding vector fields for the planed research trajectory, generates the desired course inputs for the small aerial vehicle. Furthermore, the LQR control method is proposed and utilized as the inner control loop to realize the precise attitude control. Lyapunov stability arguments are used to demonstrate the asymptotic decay of trajectory following errors in the presence of wind disturbances. Experimental flight results are given to show that the small unmanned aerial vehicle can get the high trajectory following performance in the polar environment.}
}
@article{WANG2021178,
title = {Adaptive sliding window LSTM NN based RUL prediction for lithium-ion batteries integrating LTSA feature reconstruction},
journal = {Neurocomputing},
volume = {466},
pages = {178-189},
year = {2021},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2021.09.025},
url = {https://www.sciencedirect.com/science/article/pii/S0925231221013837},
author = {Zhuqing Wang and Ning Liu and Yangming Guo},
keywords = {Prediction, Deep learning, Long short-term memory (LSTM), Adaptive sliding window, Local tangent space alignment (LTSA)},
abstract = {Abstractp
The extraction and prediction of health indicators (HIs) are two vital aspects in remaining useful life (RUL) prediction of lithium-ion batteries (LIBs). Aiming to estimate the RUL precisely, a novel integrated prediction method is proposed for LIBs on the basis of local tangent space alignment (LTSA) feature extraction and adaptive sliding window long short-term memory neural networks (ASW LSTM NN). In the proposed method, the indirect HI is first extracted by LTSA automatically to replace the unmeasurable capacity, and a strong correlation between them is verified by the Spearman correlation coefficient. Following that, with the extracted HI, an adaptive sliding window LSTM is constructed to conduct the RUL estimation of LIBs in routine environment. For the structured neural network, corresponding inputs are dynamically selected by the sliding window, while a varying length window mechanism is devised to update the window data along with the predicting cycle. Hence, the designed predicting method can learn the long-term dependencies by means of the inherent nature of LSTM and simultaneously capture the local fluctuations via the adaptive sliding window. Eventually, extensive experiments are conducted and corresponding results are compared with those obtained by existed approaches. The effectiveness of the integrated prediction method is validated, and our proposed model is proved to be more accurate in predicting the RUL compared with existed approaches.}
}
@article{SHIT2020351,
title = {Precise localization for achieving next-generation autonomous navigation: State-of-the-art, taxonomy and future prospects},
journal = {Computer Communications},
volume = {160},
pages = {351-374},
year = {2020},
issn = {0140-3664},
doi = {https://doi.org/10.1016/j.comcom.2020.06.007},
url = {https://www.sciencedirect.com/science/article/pii/S0140366420303935},
author = {Rathin Chandra Shit},
keywords = {Autonomous system, Navigation, AUV, UAV, Autonomous mobile robots, Localization, Mapping, Perception, Sensing, Network localization, Sensor fusion, Micro air vehicle},
abstract = {Achieving full autonomy in navigation is a complicated problem. The most widely used solution takes up the modular framework for sensing and information processing such as perception, mapping, control, planning and decision making. However, this approach misses the capability of environmental understanding. Hence, to achieve full autonomy in navigation a computing model with self-learning capability inspired by biological intelligence such as memorizing, inferring and experience update is essential for dynamic and noisy environments. Recent advanced sensing, communication and hardware miniaturization technologies achieved few autonomous operations in commercial systems but the full autonomy has not been attained yet. In this paper, the effect of precise and accurate localization for autonomous navigation technologies is extensively studied and the problems and limitations of the related algorithms are analyzed. The major limitations for precise localization are computational complexity, sensor noise and communication delays. These limitations further reduce perception and planning capabilities of autonomous navigation systems. From this study, the future prospects are outlined to achieve a higher level of autonomy by precise localization.}
}
@article{QI2020337,
title = {MLRSNet: A multi-label high spatial resolution remote sensing dataset for semantic scene understanding},
journal = {ISPRS Journal of Photogrammetry and Remote Sensing},
volume = {169},
pages = {337-350},
year = {2020},
issn = {0924-2716},
doi = {https://doi.org/10.1016/j.isprsjprs.2020.09.020},
url = {https://www.sciencedirect.com/science/article/pii/S0924271620302677},
author = {Xiaoman Qi and Panpan Zhu and Yuebin Wang and Liqiang Zhang and Junhuan Peng and Mengfan Wu and Jialong Chen and Xudong Zhao and Ning Zang and P. Takis Mathiopoulos},
keywords = {Multi-label image dataset, Semantic scene understanding, Convolutional Neural Network (CNN), Image classification, Image retrieval},
abstract = {To better understand scene images in the field of remote sensing, multi-label annotation of scene images is necessary. Moreover, to enhance the performance of deep learning models for dealing with semantic scene understanding tasks, it is vital to train them on large-scale annotated data. However, most existing datasets are annotated by a single label, which cannot describe the complex remote sensing images well because scene images might have multiple land cover classes. Few multi-label high spatial resolution remote sensing datasets have been developed to train deep learning models for multi-label based tasks, such as scene classification and image retrieval. To address this issue, in this paper, we construct a multi-label high spatial resolution remote sensing dataset named MLRSNet for semantic scene understanding with deep learning from the overhead perspective. It is composed of high-resolution optical satellite or aerial images. MLRSNet contains a total of 109,161 samples within 46 scene categories, and each image has at least one of 60 predefined labels. We have designed visual recognition tasks, including multi-label based image classification and image retrieval, in which a wide variety of deep learning approaches are evaluated with MLRSNet. The experimental results demonstrate that MLRSNet is a significant benchmark for future research, and it complements the current widely used datasets such as ImageNet, which fills gaps in multi-label image research. Furthermore, we will continue to expand the MLRSNet. MLRSNet and all related materials have been made publicly available at https://data.mendeley.com/datasets/7j9bv9vwsx/1 and https://github.com/cugbrs/MLRSNet.git.}
}
@article{FOURATI2021108435,
title = {Comprehensive survey on self-organizing cellular network approaches applied to 5G networks},
journal = {Computer Networks},
volume = {199},
pages = {108435},
year = {2021},
issn = {1389-1286},
doi = {https://doi.org/10.1016/j.comnet.2021.108435},
url = {https://www.sciencedirect.com/science/article/pii/S1389128621003960},
author = {Hasna Fourati and Rihab Maaloul and Lamia Chaari and Mohamed Jmaiel},
keywords = {SON, Machine learning, 5G, Self-configuration, Self-optimization, Self-healing, Coverage and capacity optimization, Mobility management, Resource optimization, Backhaul optimization, Caching optimization, SON architectures},
abstract = {Self-Organizing Network (SON) stands for a key concept characterizing the behavior of the future mobile networks. The evolution of telecom infrastructures towards 5G transforms the network management from the traditional and static processes to automatic and dynamic ones. SON was proposed to offer agile on-demand services to the users through providing self-adaptation capabilities to mobile networks on different categories. This paper presents a detailed and exhaustive survey on SON evolution from 4G towards 5G networks. The central focus of this survey is upon providing a deep understanding of SON mechanisms along with the architectural changes associated with 5G networks. Within this framework, the approaches and trends in self-organizing cellular networks are discussed. Additionally, the main functionalities of SON, namely self-configuration, self-optimization and self-healing are displayed. Our work serves as an enlightening guideline for future research works on SON as far as cellular networks domain is concerned.}
}
@article{DBOUK2021107934,
title = {Modular approach for optimal pipeline layout},
journal = {Journal of Petroleum Science and Engineering},
volume = {197},
pages = {107934},
year = {2021},
issn = {0920-4105},
doi = {https://doi.org/10.1016/j.petrol.2020.107934},
url = {https://www.sciencedirect.com/science/article/pii/S092041052030989X},
author = {Haytham M. Dbouk and Hussein Hayek and Kassem Ghorayeb},
keywords = {Oil and gas pipeline layout, Pipeline network optimization, A* algorithm, Dijkstra's algorithm, Shortest path, Topological complexity},
abstract = {Oil and gas production systems are getting deeper, more complex, and far away offshore where energy companies are targeting further resources. These complexities are transforming the problem of field layout design optimization into a much more pressing need. Considering the various pipeline design and layout constraints and associated investment costs, planning and development of production gathering and transmission pipeline networks for oil and gas fields is gaining further importance in field development planning. The optimization of transmission and gathering pipeline networks is conducted to accommodate the encountered topological complexities and significantly reduce total investment cost for the corresponding fields. Although many optimization schemes are developed and widely available in literature, these methods are either prohibitively slow with exhaustive search required, or they don't account for the various topological complexities typically encountered in real scenarios. Thus, the deficiency associated to these optimization schemes becomes drastically more limiting in the case of a concept-select phase of field development planning where many scenarios need to be assessed in a relatively short timeframe. In this study, the optimal shortest path A* algorithm is introduced to the field of pipeline placement optimization. A* is successfully used in other applications such as unmanned aerial vehicle (UAV) and robots motion planning. A benchmark comparison is presented with the Dijkstra algorithm; another algorithm that assures optimal shortest path solution that was recently introduced into this field. This comparison is performed on a varied set of pipeline layout scenarios accounting for different topological complexities and dynamic conditions. The conducted tests show the superiority of the A* algorithm in terms of accounting for the application heuristics and assuring an optimal and efficient solution.}
}
@article{SHARMA2022107936,
title = {Enabling Smart Agriculture by Implementing Artificial Intelligence and Embedded Sensing},
journal = {Computers & Industrial Engineering},
pages = {107936},
year = {2022},
issn = {0360-8352},
doi = {https://doi.org/10.1016/j.cie.2022.107936},
url = {https://www.sciencedirect.com/science/article/pii/S0360835222000067},
author = {Ashutosh Sharma and Mikhail Georgi and Maxim Tregubenko and Alexey Tselykh and Alexander Tselykh},
keywords = {Computational intelligence technique, genetic algorithm, artificial neural network, varying lighting illuminations, color normalization},
abstract = {The increasing demand of smart agriculture has led to the significant growth and development in the field of crop estimation and prediction improving its productivity. The analysis of crop age status is very important to prevent the excessive fertilization, understand the proper time to harvest and reduce the production cost. Image based analysis using computational intelligence have proved beneficial in estimation of categorical age in the crops. This work focuses on the utilization of predictive computational intelligence technique for the evaluation of nitrogen status in wheat crop. The evaluation depends on the analysis of crop images captured in field at varying lighting illuminations. The wheat crop is initially subjected to HSI color normalization, followed by the optimization process using genetic algorithm (GA) and artificial neural network (ANN) based prediction and crop precision status classification. This ANN based optimized approach can significantly differentiate between the wheat crops from the other unwanted plants and weeds while identifying the crop yield age into categorical classes. The outcomes obtained for the experimentation yields the highest validation accuracy of 97.75% with the minimized error rate of 0.22 and a decrease of 0.28 in the loss value. Comparative to the other contemporary counterparts, the proposed ANN+GA mechanism provides improved performance outcomes while minimizing the error rate.}
}
@article{KONIG2021102907,
title = {Optimized deep encoder-decoder methods for crack segmentation},
journal = {Digital Signal Processing},
volume = {108},
pages = {102907},
year = {2021},
issn = {1051-2004},
doi = {https://doi.org/10.1016/j.dsp.2020.102907},
url = {https://www.sciencedirect.com/science/article/pii/S1051200420302529},
author = {Jacob König and Mark David Jenkins and Mike Mannion and Peter Barrie and Gordon Morison},
keywords = {Crack segmentation, Convolutional neural network, Deep learning, Semantic segmentation},
abstract = {Surface crack segmentation poses a challenging computer vision task as background, shape, color and size of cracks vary. In this work we propose optimized deep encoder-decoder methods consisting of a combination of techniques which yield an increase in crack segmentation performance. Specifically we propose a decoder-part for an encoder-decoder based deep learning architecture for semantic segmentation and study its components to achieve increased performance. We also examine the use of different encoder strategies and introduce a data augmentation policy to increase the amount of available training data. The performance evaluation of our method is carried out on four publicly available crack segmentation datasets. Additionally, we introduce two techniques into the field of surface crack segmentation, previously not used there: Generating results using test-time-augmentation and performing a statistical result analysis over multiple training runs. The former approach generally yields increased performance results, whereas the latter allows for more reproducible and better representability of a methods results. Using those aforementioned strategies with our proposed encoder-decoder architecture we are able to achieve new state of the art results in all datasets.}
}
@article{RAMAKRISHNA2020101760,
title = {Dynamic-weighted simplex strategy for learning enabled cyber physical systems},
journal = {Journal of Systems Architecture},
volume = {111},
pages = {101760},
year = {2020},
issn = {1383-7621},
doi = {https://doi.org/10.1016/j.sysarc.2020.101760},
url = {https://www.sciencedirect.com/science/article/pii/S1383762120300540},
author = {Shreyas Ramakrishna and Charles Harstell and Matthew P. Burruss and Gabor Karsai and Abhishek Dubey},
keywords = {Convolutional Neural Networks, Learning Enabled Components, Reinforcement Learning, Simplex Architecture},
abstract = {Cyber Physical Systems (CPS) have increasingly started using Learning Enabled Components (LECs) for performing perception-based control tasks. The simple design approach, and their capability to continuously learn has led to their widespread use in different autonomous applications. Despite their simplicity and impressive capabilities, these components are difficult to assure, which makes their use challenging. The problem of assuring CPS with untrusted controllers has been achieved using the Simplex Architecture. This architecture integrates the system to be assured with a safe controller and provides a decision logic to switch between the decisions of these controllers. However, the key challenges in using the Simplex Architecture are: (1) designing an effective decision logic, and (2) sudden transitions between controller decisions lead to inconsistent system performance. To address these research challenges, we make three key contributions: (1) dynamic-weighted simplex strategy – we introduce “weighted simplex strategy” as the weighted ensemble extension of the classical Simplex Architecture. We then provide a reinforcement learning based mechanism to find dynamic ensemble weights, (2) middleware framework – we design a framework that allows the use of the dynamic-weighted simplex strategy, and provides a resource manager to monitor the computational resources, and (3) hardware testbed – we design a remote-controlled car testbed called DeepNNCar to test and demonstrate the aforementioned key concepts. Using the hardware, we show that the dynamic-weighted simplex strategy has 60% fewer out-of-track occurrences (soft constraint violations), while demonstrating higher optimized speed (performance) of 0.4 m/s during indoor driving than the original LEC driven system.}
}
@article{TONDEWAD20202390,
title = {Remote Sensing Image Registration Methodology: Review and Discussion},
journal = {Procedia Computer Science},
volume = {171},
pages = {2390-2399},
year = {2020},
note = {Third International Conference on Computing and Network Communications (CoCoNet'19)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2020.04.259},
url = {https://www.sciencedirect.com/science/article/pii/S1877050920312515},
author = {Ms. Priyanka S. Tondewad and Ms. Manisha P. Dale},
keywords = {Convolutional Neural Network (CNN), Remote Sensing (RS), Automatic Image Registration(AIR)},
abstract = {Image registration is the process of overlaying two or more multi sensor or multi temporal or multi resolution images of the same scene. Image registration is very crucial preprocessing step in any remote sensing image processing application. This paper presents a brief review of evolution of different image registration methodologies with challenges involved in it. Image registration basically aligns the two images (reference and sensed image) geometrically. In the first part of this paper, classical methods will be discussed which are mainly based on area based (Intensity based) approach and feature based approach. Ample amount of work has already been done in both methods in manual and automatic manner. In the second part all recent approaches will be discussed and compared with results, on the basis of registration accuracy, number of correct correspondence. In recent studies Convolutional Neural Network with deep learning algorithms are used in combination with traditional methods to boost the overall performance.}
}
@article{IVANOV2019518,
title = {Distribution of Roles in Groups of Robots with Limited Communications Based on the Swarm Interaction},
journal = {Procedia Computer Science},
volume = {150},
pages = {518-523},
year = {2019},
note = {Proceedings of the 13th International Symposium “Intelligent Systems 2018” (INTELS’18), 22-24 October, 2018, St. Petersburg, Russia},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2019.02.087},
url = {https://www.sciencedirect.com/science/article/pii/S187705091930434X},
author = {D.Ya. Ivanov},
keywords = {swarm intelligence, distribution of tasks, distribution of roles, group of robots},
abstract = {The paper is aimed at the problem of the distribution of roles in groups of robots with limited communications and based on the principles of the swarm intelligence. The iteration approach to the distribution of roles in a group of robots is proposed. There are results of the study and computer simulation of the proposed approach.}
}
@article{LIU20191,
title = {A method for restraining gyroscope drift using horizon detection in infrared video},
journal = {Infrared Physics & Technology},
volume = {101},
pages = {1-12},
year = {2019},
issn = {1350-4495},
doi = {https://doi.org/10.1016/j.infrared.2019.05.018},
url = {https://www.sciencedirect.com/science/article/pii/S1350449519302658},
author = {Zewei Liu and Dongming Lu and Weixian Qian and Kan Ren and Guohua Gu and Qian Chen and Jun Zhang},
keywords = {Gyroscope, Sea-sky line, Unscented Kalman Filter (UKF), Drift, Infrared camera},
abstract = {Gyroscope plays an important role in UAV (Unmanned Aerial Vehicle), navigation and other fields. However, the zero drift problem is always the key point affecting the gyroscope precision. We propose a method to suppress the zero drift using horizon in infrared video sequence and predict the attitude. In the first step, we introduce a horizon detection method without Hough transform which mainly uses template matching to determine the most likely points on the horizon and determines the direction of the horizon in the image. And then using an Unscented Kalman Filter (UKF), we can take the direction of the horizon in the image as the observation equation to estimate the camera attitude. Experimental results show that the attitude estimated by our method is more reliable than those by gyroscope data and images alone.}
}
@article{BHATTACHARJYA2021102304,
title = {IoUT: Modelling and simulation of Edge-Drone-based Software-Defined smart Internet of Underwater Things},
journal = {Simulation Modelling Practice and Theory},
volume = {109},
pages = {102304},
year = {2021},
issn = {1569-190X},
doi = {https://doi.org/10.1016/j.simpat.2021.102304},
url = {https://www.sciencedirect.com/science/article/pii/S1569190X21000289},
author = {Kamalika Bhattacharjya and Debashis De},
keywords = {Internet of Underwater Things (IoUT), Software Defined Networking (SDN), Drones, Edge-Drone based Software-Defined smart Internet of Underwater Things, Energy consumption, Packet delivery ratio},
abstract = {Internet of Underwater Things (IoUT) is growing an attractive zone of the research to explore the underwater scenario for surveillance. The autonomous manner of Unmanned Aerial Vehicles (UAV) or Drone makes search and surveillance of the target underwater region effectively. Drone gather, analyse, and transmit data at the time of flight by consuming battery energy. Underwater search and monitoring are carried out by IoUT. But battery energy is limited in drones, and elongation of the lifetime is an important requirement in IoUT. Energy consumption by being reduced by selecting an efficient cluster head in the Underwater Wireless Sensor Networks (UWSNs). Efficient data transmission makes a network efficient in terms of energy consumption, and delay. Software-Defined Networking (SDN) make UWSN more scalable. An Edge-Drone-based four-layer Software-Defined smart Internet of Underwater Things (EdgeIoUT) for efficient data transmission is proposed in this article. The architecture of the proposed EdgeIoUT model is based on edge computing and the drones act as an edge device in the proposed work. The proposed EdgeIoUT model works in four layers, (i) Underwater sensor and cluster head layer, (ii) Drone layer (iii) SDN switch, and (iv) SDN controller & data storage layer. The comparison of the proposed model with the existing traditional Software-Defined IoUT is performed using QualNet 7.1 simulator. The outcome of simulation shows that the proposed EdgeIoUT superior with regard to mean jitter by 63%, mean total energy consumption by 3%, and packet delivery ratio by 17% than traditional SD-IoUT in maximum data size.}
}
@article{RAKAI2022116300,
title = {Data association in multiple object tracking: A survey of recent techniques},
journal = {Expert Systems with Applications},
volume = {192},
pages = {116300},
year = {2022},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2021.116300},
url = {https://www.sciencedirect.com/science/article/pii/S0957417421016031},
author = {Lionel Rakai and Huansheng Song and ShiJie Sun and Wentao Zhang and Yanni Yang},
keywords = {Data association, Probabilistic association techniques, Hierarchical association techniques, Interactive multiple model, Kalman filter, Multiple object tracking},
abstract = {The advances of Visual object tracking tasks in computer vision have enabled a growing value in its application to video surveillance, particularly in a traffic scenario. In recent years, significant attention has been made for the improvement of multiple object tracking frameworks to be effective in real-time while maintaining accuracy and generality. By breaking down the tasks involved in a Multiple Object Tracking framework based on the Tracking-By-Detection approach — an extension of simply detecting and identifying objects, further involved solving a filtering problem by defining a similarity function to associate objects. Hence, this paper focuses on the task of data association via uniquely defined similarity functions and filters only where we review current literature about these techniques which have been used to advance the performance in MOT for vehicle and pedestrian scenarios. While there is difficulty in classifying the quantitative results for the association task only within a proposed MOT framework, our study tries to outline the fundamental ideas put forward by researchers and compare results in a theoretically qualitative approach. Tracking methods are reviewed by categories based on legacy techniques like Probabilistic and Hierarchical methods, followed by an analysis of new approaches and hybrid models. The models identified in each category are further analysed based on performance in stability, accuracy, robustness, speed and computational complexity to derive an understanding of which direction the research within the data association level is strong and which is lacking. Our review further aims to identify the successful models applied to recognize the weaknesses for future improvement.}
}
@article{YANG2021794,
title = {Development of flight simulation system based on leap motion controller},
journal = {Procedia Computer Science},
volume = {183},
pages = {794-800},
year = {2021},
note = {Proceedings of the 10th International Conference of Information and Communication Technology},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2021.02.131},
url = {https://www.sciencedirect.com/science/article/pii/S1877050921006074},
author = {Binbin Yang and Xiaojun Xia and Shuai Wang and Lanqing Ye},
keywords = {Natural interaction, machine learning, Leap Motion Controller, flight simulation},
abstract = {Aiming at the problems of low precision and discontinuous interaction in traditional human-computer interaction, A natural interactive system that can be used for flight simulation is proposed, which is based on Leap Motion combined with machine learning. Firstly, a gesture Motion suitable for flight simulation is introduced, and the Leap Motion is used to collect custom interactive gesture data. Then, linear regression and local weighted regression algorithm are respectively used to fit the collected original data, so as to obtain the interactive control curve that most conforms to the experimenter. The experimental results show that the control curve obtained by linear regression and local weighted regression algorithm have increased accuracy by 21.40% and 65.27% respectively compared with the data curve obtained by the original data, which is very helpful to improve the human-computer interaction experience in flight simulation.}
}
@article{DELIMA2021102025,
title = {Free and open-source software for Geographic Information System on coastal management: A study case of sea-level rise in southern Brazil},
journal = {Regional Studies in Marine Science},
volume = {48},
pages = {102025},
year = {2021},
issn = {2352-4855},
doi = {https://doi.org/10.1016/j.rsma.2021.102025},
url = {https://www.sciencedirect.com/science/article/pii/S2352485521004175},
author = {Lucas T. {de Lima} and Sandra Fernández-Fernández and Carlos V.C. Weiss and Volney Bitencourt and Cristina Bernardes},
keywords = {GIS, Sea-level rise, Climate change, Modeling, Coastal hazards, End point rate, Uncertainty bathtub, Bruun rule},
abstract = {This work assesses sea-level rise impact using three different models created on Free and Open-Source Software for Geographic Information System to help coastal managers in the initial stages. The End Point Rate for QGIS (EPR4Q) computes a coastline projection using the End Point Rate method. The Uncertainty Bathtub Model (uBTM) analyses the effects of sea-level rise through the uncertainty of sea-level projections and the vertical error of the Digital Elevation/Terrain Model. The Bruun Rule for Google Earth Engine Model (BRGM) predicts the position of the shoreline with sea-level rise, using topographic and bathymetric data from Unmanned Aerial Vehicles and Coastal Modeling System, respectively. Based on the regional projections of the Special Report on Climate Change and Oceans and Cryosphere of the Intergovernmental Panel on Climate Change, the models were applied to a study case on the coast of Rio Grande do Sul—Brazilunder different scenarios of sea-level rise expected by the end of this century. The results showed a maximum coastal retreat for the year 2100 of -502 m and -1727 m using EPR4Q and BRGM, respectively. The uBTM with Mapbiomas land use showed a maximum of 44.57 km 2 of urban area affected by sea-level flooding. This study highlights the feasibility of conducting coastal management analysis in GIS environment using non-commercial software.}
}
@article{AMBATI2017218,
title = {Robust auto-landing of fixed-wing UAVs using neuro-adaptive design},
journal = {Control Engineering Practice},
volume = {60},
pages = {218-232},
year = {2017},
issn = {0967-0661},
doi = {https://doi.org/10.1016/j.conengprac.2016.03.017},
url = {https://www.sciencedirect.com/science/article/pii/S0967066116300582},
author = {Pradeep R. Ambati and Radhakant Padhi},
keywords = {Dynamic inversion, Neuro-adaptive control, Automatic landing, UAV, Wind shear, Ground effect, Wind gust},
abstract = {An innovative neuro-adaptive design philosophy is presented in this paper embedding a Sobolev norm based Lyapunov function for directional learning of the unknown function, which is capable of learning both the unknown function in the system model and its Jacobian. This facilitates fast learning (model adaptation) without much of transient effects. The updated model is then used in the framework of dynamic inversion to design the guidance (outer) loop as well as the control (inner) loop. Using this philosophy a robust adaptive nonlinear guidance and control design is presented for robust automatic landing. The performance of the proposed approach is successfully verified through numerous simulation studies using the six degrees-of-freedom (six-DOF) nonlinear model of a prototype UAV. All possible disturbance effects that arise in practice, namely modeling inaccuracies, wind disturbances and ground effect, have been considered in the simulation studies.}
}
@article{HU2020737,
title = {An infrared target intrusion detection method based on feature fusion and enhancement},
journal = {Defence Technology},
volume = {16},
number = {3},
pages = {737-746},
year = {2020},
issn = {2214-9147},
doi = {https://doi.org/10.1016/j.dt.2019.10.005},
url = {https://www.sciencedirect.com/science/article/pii/S2214914719308682},
author = {Xiaodong Hu and Xinqing Wang and Xin Yang and Dong Wang and Peng Zhang and Yi Xiao},
keywords = {Target intrusion detection, Convolutional neural network, Feature fusion, Infrared target},
abstract = {Infrared target intrusion detection has significant applications in the fields of military defence and intelligent warning. In view of the characteristics of intrusion targets as well as inspection difficulties, an infrared target intrusion detection algorithm based on feature fusion and enhancement was proposed. This algorithm combines static target mode analysis and dynamic multi-frame correlation detection to extract infrared target features at different levels. Among them, LBP texture analysis can be used to effectively identify the posterior feature patterns which have been contained in the target library, while motion frame difference method can detect the moving regions of the image, improve the integrity of target regions such as camouflage, sheltering and deformation. In order to integrate the advantages of the two methods, the enhanced convolutional neural network was designed and the feature images obtained by the two methods were fused and enhanced. The enhancement module of the network strengthened and screened the targets, and realized the background suppression of infrared images. Based on the experiments, the effect of the proposed method and the comparison method on the background suppression and detection performance was evaluated, and the results showed that the SCRG and BSF values of the method in this paper had a better performance in multiple data sets, and it’s detection performance was far better than the comparison algorithm. The experiment results indicated that, compared with traditional infrared target detection methods, the proposed method could detect the infrared invasion target more accurately, and suppress the background noise more effectively.}
}
@article{WANG201939,
title = {A feature selection approach for hyperspectral image based on modified ant lion optimizer},
journal = {Knowledge-Based Systems},
volume = {168},
pages = {39-48},
year = {2019},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2018.12.031},
url = {https://www.sciencedirect.com/science/article/pii/S0950705118306348},
author = {Mingwei Wang and Chunming Wu and Lizhe Wang and Daxiang Xiang and Xiaohui Huang},
keywords = {Hyperspectral image, Feature selection, Wavelet support vector machine, Ant lion optimizer, Lévy flight},
abstract = {Feature selection is one of the most important issues in hyperspectral image (HSI) classification to achieve high correlation between the adjacent bands. The main concern is selecting fewer bands with the highest accuracy as possible. Generally, it is a combinatorial optimization problem and cannot be fully solved by swarm intelligence algorithms. Ant lion optimizer (ALO) is a newly proposed swarm intelligence algorithm that mimics the swarming behaviour of antlions. In addition, wavelet support vector machine (WSVM) is able to enhance the stability of the classification result, and Lévy flight helps swarm intelligence algorithms jump out of the local optimum. Therefore, in this paper, a novel feature selection method based on a modified ALO (MALO) and WSVM is proposed to reduce the dimensionality of HSIs. The proposed method is compared with some state-of-the-art algorithms on some HSI datasets. Moreover, a new evaluating criteria is formulated to estimate the performance of feature selection, and the classification accuracy and selected number of bands are balanced as much as possible. Experimental results demonstrate that the proposed method outperforms other approaches, finds the optimal solution with a reasonable convergence orientation, and its classification accuracy is satisfied with fewer bands, it is robust, adaptive and might be applied for practical work of feature selection.}
}
@article{CAO201850,
title = {Learning spatio-temporal context via hierarchical features for visual tracking},
journal = {Signal Processing: Image Communication},
volume = {66},
pages = {50-65},
year = {2018},
issn = {0923-5965},
doi = {https://doi.org/10.1016/j.image.2018.04.010},
url = {https://www.sciencedirect.com/science/article/pii/S092359651830359X},
author = {Yi Cao and Hongbing Ji and Wenbo Zhang and Fei Xue},
keywords = {Visual tracking, Convolutional neural network, Transfer learning, Spatio-temporal context, Dynamic training confidence map, Training confidence index},
abstract = {Spatio-temporal context (STC) based visual tracking algorithms have demonstrated remarkable tracking capabilities in recent years. In this paper, we propose an improved STC method, which seamlessly integrates capabilities of the powerful feature representations and mappings from the convolutional neural networks (CNNs) based on the theory of transfer learning. Firstly, the dynamic training confidence map, obtained from a mapping neural network using transferred CNN features, rather than the fixed training confidence map is utilized in our tracker to adapt the practical tracking scenes better. Secondly, we exploit hierarchical features from both the original image intensity and the transferred CNN features to construct context prior models. In order to enhance the accuracy and robustness of our tracker, we simultaneously transfer the fine-grained and semantic features from deep networks. Thirdly, we adopt the training confidence index (TCI), reflected from the dynamic training confidence map, to guide the updating process. It can determine whether back propagations should be conducted in the mapping neural network, and whether the STC model should be updated. The introduction of the dynamic training confidence map could effectively deal with the problem of location ambiguity further in our tracker. Overall, the comprehensive experimental results illustrate that the tracking capability of our tracker is competitive against several state-of-the-art trackers, especially the baseline STC tracker, on the existing OTB-2015 and UAV123 visual tracking benchmarks.}
}
@article{WEI2021103876,
title = {Damage inspection for road markings based on images with hierarchical semantic segmentation strategy and dynamic homography estimation},
journal = {Automation in Construction},
volume = {131},
pages = {103876},
year = {2021},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2021.103876},
url = {https://www.sciencedirect.com/science/article/pii/S0926580521003277},
author = {Chong Wei and Shurong Li and Kai Wu and Zijian Zhang and Ying Wang},
keywords = {Damage inspection, Road marking, Deep learning, Semantic segmentation, Homography estimation},
abstract = {This study proposes a computer vision-based damage inspection system for road markings. In order to evaluate the degree of damage of a marking objectively, the proposed system estimates its damage ratio according to the marking's damaged part and the marking's region. A hierarchical semantic segmentation strategy is proposed which employs a series of convolutional neural networks to recognize the 2D bounding box, damaged part and region of a marking. Specifically, this strategy can effectively identify the original region of a marking through an improved U-Net even if the marking is significantly damaged. The damage ratio estimation is enhanced by integrating information from multiple images based on object tracking and dynamic homography estimation. The experimental results confirm that the proposed system is effective in automating the inspection of road markings and producing objective damage assessments that should significantly assist road managers in prioritizing maintenance operations.}
}
@article{NATH2022101450,
title = {Drone mapping of damage information in GPS-Denied disaster sites},
journal = {Advanced Engineering Informatics},
volume = {51},
pages = {101450},
year = {2022},
issn = {1474-0346},
doi = {https://doi.org/10.1016/j.aei.2021.101450},
url = {https://www.sciencedirect.com/science/article/pii/S1474034621002020},
author = {Nipun D. Nath and Chih-Shen Cheng and Amir H. Behzadan},
keywords = {Disaster management, Unmanned aerial vehicle (UAV), Damage assessment, Homography, Photogrammetry, Spatial mapping},
abstract = {The increasing number and severity of natural hazard events in recent years, and their devastating impact on human life, local economies, and the built environment has called governments around the world into action and created a new mandate for a paradigm shift in disaster management and mitigation policies. To this end, new affordable technologies with mobile connectivity (e.g., smartphones, unmanned systems, reality capture devices) have scaled up tasks such as data collection and curation, leading to a significant increase in the volume of data gathered and shared in the aftermath of disasters. In the meantime, advancements in high-power and distributed computing have created new opportunities in fast and reliable data analytics. In particular to the application of drones in disaster response, past research has primarily focused on aerial data collection and more recently, ground object detection. Geolocalization of drone data (i.e., the process of determining the geographical position of objects in drone’s field of view), however, is a complex task that relies on prior knowledge of the drone’s geolocation (e.g., flight path coordinates, inertial sensors, camera gaze). Such metadata may not be always available or shared across platforms especially with the increased use of crowdsourcing in disaster response, damage assessment, and recovery. This paper presents a methodology for spatial mapping of disaster impact information in drone videos without reliance on GPS data of the aerial camera. We perform progressive mapping using scale-invariant visual features in red–greenblue (RGB) videos of disaster-affected sites in two major hurricanes in North America, namely Harvey (2017) and Dorian (2019). Results indicate that the proposed methodology can project objects from the perspective view of a drone camera onto an orthogonal map with 32.7–36.9 ft of average root mean square (RMS) error in a land area of 18–45 acres.}
}
@article{ARSLAN2021109262,
title = {A comparative study for obtaining effective Leaf Area Index from single Terrestrial Laser Scans by removal of wood material},
journal = {Measurement},
volume = {178},
pages = {109262},
year = {2021},
issn = {0263-2241},
doi = {https://doi.org/10.1016/j.measurement.2021.109262},
url = {https://www.sciencedirect.com/science/article/pii/S0263224121002700},
author = {Adil Enis Arslan and Esra Erten and Muhittin Inan},
keywords = {LeaF Area Index, TerreStrial Laser Scanning, Biomass, Neural networks},
abstract = {Leaf Area Index (LAI) is a dimensionless parameter that has a significant impact on forestry applications. With conventional methods, LAI can be calculated with destructive sample collection or with a relatively new non-destructive method called hemispherical photography. With the engagement of surveying instruments in forestry, obtaining LAI value for large areas in a short time has recently become more prominent and possible with the use of Terrestrial Laser Scanners (TLS). Although promising, TLS data evaluation techniques for LAI calculation are still subject to development. This paper aims to make a comparative evaluation of existing novel techniques with newly proposed methods and incorporates the use of neural networks and connected component analysis for segmentation purposes. The in-situ measurements, as a case study, were conducted in Istanbul- University-Cerrahpasa research forest – a part of Belgrad forest – Istanbul, Turkey. The Results obtained from the study show that segmentation and removal of wood materials from forest point cloud data, by using neural network algorithms and connected component analysis methods, albeit time and resource consuming, have a promising future on the calculation of effective LAI values of large areas.}
}
@article{SRIVASTAVA2021100359,
title = {Future FANET with application and enabling techniques: Anatomization and sustainability issues},
journal = {Computer Science Review},
volume = {39},
pages = {100359},
year = {2021},
issn = {1574-0137},
doi = {https://doi.org/10.1016/j.cosrev.2020.100359},
url = {https://www.sciencedirect.com/science/article/pii/S1574013720304597},
author = {Ashish Srivastava and Jay Prakash},
keywords = {FANET, UAV, Drones, Mobility model, Routing, Routing protocol},
abstract = {Rapid expansion and technological advancement of Wireless communication lead by researchers in different fields of engineering have achieved various milestones. Its efficient use has proven that days are not too far when even we think of anything flying sensors, actuators of multiple types surrounded by us process it, and try to bring down or show the best possible result. One of the most talked-about innovations in drones the day it was invented. Group of Drones working in a collectively and Ad hoc manner form a Flying Ad hoc network (FANET). The Mobility of UAVs makes it more accessible, which helps in the mobile revolution that the present world is going through. The use of such a network in different applications across the globe is highly demanding. Most of the traditional study compares it with other Ad hoc networks and coupling, relating to them. However, FANET has its considerations relating to the same class of system. This paper presents a comprehensive survey relating FANET and critical points regarding it, ranging from the categorization of FANET, the architecture of FANET, types of possible communication in FANET, numerous Mobility Models, constraints in FANET, characteristics, and design of FANET, routing protocol, and routing topology. We further present open issues and challenges in FANET relating to essential parameters and research. It endeavored to store all the recommendations to encourage the researchers to function in this particular area and the same class of network. Deterministic jointly with probabilistic points of studies compiled and listed with the belief that deterministic methods should be in association with stochastic approaches for better results in FANET.}
}
@article{ZHAI2020333,
title = {Learning-based prediction of wildfire spread with real-time rate of spread measurement},
journal = {Combustion and Flame},
volume = {215},
pages = {333-341},
year = {2020},
issn = {0010-2180},
doi = {https://doi.org/10.1016/j.combustflame.2020.02.007},
url = {https://www.sciencedirect.com/science/article/pii/S001021802030064X},
author = {Chunjie Zhai and Siyu Zhang and Zhaolou Cao and Xinmeng Wang},
keywords = {Wildfire spread, Real-time RoS measurement, Level-set method, Machine learning},
abstract = {A learning-based wildfire spread model was developed in this study to predict short-term wildfire spread. Real-time rate of spread (RoS) measurement was first conducted by calculating normal movements of fire fronts. Subsequently, machine learning was employed to correlate the local RoS and environmental parameters and predict the RoS in the unburnt area. After that, a narrow-band level-set method was utilized to simulate the evolution of fire front. RoS measurement, machine learning, and level-set method were individually verified with numerically generated fire fronts, and applied in a real scale shrubland fire scenario. Results show that the proposed learning-based method is capable of predicting short-term fire spread without employing an empirical RoS model, which is beneficial for modeling spreading of a real wildfire.}
}
@article{GE2020103232,
title = {Towards automatic visual inspection: A weakly supervised learning method for industrial applicable object detection},
journal = {Computers in Industry},
volume = {121},
pages = {103232},
year = {2020},
issn = {0166-3615},
doi = {https://doi.org/10.1016/j.compind.2020.103232},
url = {https://www.sciencedirect.com/science/article/pii/S0166361519307559},
author = {Ce Ge and Jing Wang and Jingyu Wang and Qi Qi and Haifeng Sun and Jianxin Liao},
keywords = {Industrial automation, Insulator detection, Object detection, Weakly supervised learning, Deep learning},
abstract = {Industrial visual detection is an essential part in modern industry for equipment maintenance and inspection. With the recent progress of deep learning, advanced industrial object detectors are built for smart industrial applications. However, deep learning methods are known data-hungry: the processes of data collection and annotation are labor-intensive and time-consuming. It is especially impractical in industrial scenarios to collect publicly available datasets due to the inherent diversity and privacy. In this paper, we explore automation of industrial visual inspection and propose a segmentation-aggregation framework to learn object detectors from weakly annotated visual data. The used minimum annotation is only image-level category labels without bounding boxes. The method is implemented and evaluated on collected insulator images and public PASCAL VOC benchmarks to verify its effectiveness. The experiments show that our models achieve high detection accuracy and can be applied in industry to achieve automatic visual inspection with minimum annotation cost.}
}
@article{GALLELLI2019175,
title = {Effects of calibration process on the simulation of rear-end conflicts at roundabouts},
journal = {Journal of Traffic and Transportation Engineering (English Edition)},
volume = {6},
number = {2},
pages = {175-184},
year = {2019},
issn = {2095-7564},
doi = {https://doi.org/10.1016/j.jtte.2018.03.006},
url = {https://www.sciencedirect.com/science/article/pii/S2095756417304385},
author = {Vincenzo Gallelli and Giuseppe Guido and Alessandro Vitale and Rosolino Vaiana},
keywords = {Simulation, Safety performance, Unmanned aerial vehicle, Roundabouts, Traffic conflicts},
abstract = {A methodology for calibrating and validating VISSIM simulation model is presented that allows to replicate the observed vehicles conflicts. A roundabout case study has been selected to test the usefulness of a combined approach of VISSIM simulation package and the surrogate safety assessment model (SSAM) for providing reliable estimates of traffic conflicts. Safety performance has been assessed from the field by video-recording vehicle interactions at the roundabout, and then expressed in terms of time to collision (TTC) values. The proposed calibration procedure has been performed by a multistage methodology involving microscopic drivers' car following behavior parameters to enhance the correlation between observed and simulated queue lengths at the roundabout's entries. The calibration procedure is based on a statistical screening of inputs leading to a linear expression relating significant parameters to the queue length. The best estimates of the model's parameters have been determined using a genetic algorithm technique. The spatial distribution of the rear-end conflicts and the TTC values determined by SSAM have been finally compared with the observed ones to analyze the capability of the model of replicating rear-end conflicts. The results suggest to this calibration procedure impacts positively on the estimate of the safety performance measures obtained through the simulation processes. Notwithstanding the good results in the evaluation of the model's accuracy, the simulation seems to fail in reproducing the traffic phenomena linked to unusual driving behavior, and therefore it is not able to replicate forced drivers' maneuvers that can lead to a conflict situation.}
}
@article{NGUYEN2020102693,
title = {Blockchain for 5G and beyond networks: A state of the art survey},
journal = {Journal of Network and Computer Applications},
volume = {166},
pages = {102693},
year = {2020},
issn = {1084-8045},
doi = {https://doi.org/10.1016/j.jnca.2020.102693},
url = {https://www.sciencedirect.com/science/article/pii/S1084804520301673},
author = {Dinh C. Nguyen and Pubudu N. Pathirana and Ming Ding and Aruna Seneviratne},
keywords = {5G networks, Blockchain, 5G Internet of Things, 5G services, Machine learning, Security and privacy},
abstract = {The fifth generation (5G) wireless networks are on the way to be deployed around the world. The 5G technologies target to support diverse vertical applications by connecting heterogeneous devices and machines with drastic improvements in terms of high quality of service, increased network capacity and enhanced system throughput. However, 5G systems still remain a number of security challenges that have been mentioned by researchers and organizations, including decentralization, transparency, risks of data interoperability, and network privacy vulnerabilities. Furthermore, the conventional techniques may not be sufficient to deal with the security requirements of 5G. As 5G is generally deployed in heterogeneous networks with massive ubiquitous devices, it is quite necessary to provide secure and decentralized solutions. Motivated from these facts, in this paper we provide a state-of-the-art survey on the integration of blockchain with 5G networks and beyond. In this detailed survey, our primary focus is on the extensive discussions on the potential of blockchain for enabling key 5G technologies, including cloud computing, edge computing, Network Function Virtualization, Network Slicing, and D2D communications. We then explore and analyse the opportunities that blockchain potentially empowers important 5G services, ranging from spectrum management, data sharing, network virtualization, resource management to interference management, federated learning, privacy and security provision. The recent advances in the applications of blockchain in 5G Internet of Things are also surveyed in a wide range of popular use-case domains, such as smart healthcare, smart city, smart transportation, smart grid and UAVs. The main findings derived from the comprehensive survey on the cooperated blockchain-5G networks and services are then summarized, and possible research challenges with open issues are also identified. Lastly, we complete this survey by shedding new light on future directions of research on this newly emerging area.}
}
@article{ZHU2021103252,
title = {Review on flashover risk prediction method of iced insulator based on icing monitoring technology},
journal = {Cold Regions Science and Technology},
volume = {185},
pages = {103252},
year = {2021},
issn = {0165-232X},
doi = {https://doi.org/10.1016/j.coldregions.2021.103252},
url = {https://www.sciencedirect.com/science/article/pii/S0165232X21000331},
author = {Yongcan Zhu and Ruiwen Zhou and Ye Zhang and Xinsheng Dong and Xinbo Huang},
keywords = {Power insulator, Icing flashover, Image processing, Icing monitoring technology, Icing flashover risk prediction},
abstract = {Insulator flashover caused by atmospheric icing is a serious accident with high frequency, which seriously influences the security of the power system in icing areas. Therefore, it is of great theoretical significance and engineering value to carry out research on risk prediction technology of icing flashover. Firstly, in this paper, the main influencing factors of icing flashover of insulators are analyzed, and the morphological characteristics of iced insulators are deeply studied, such as icing type, icing amount, icicle length and bridging state, insulator pollution, etc. Secondly, the monitoring methods of iced insulator are analyzed and compared, and the results show that the image monitoring technology has obvious advantages in icing flashover prediction. More importantly, the current research progress and technical difficulties of image recognition technology for icing flashover parameters are discussed. Finally, the research prospect of flashover risk prediction model for iced insulator is introduced based on deduction method and machine learning algorithm.}
}
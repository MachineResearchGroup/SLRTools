@article{GOPE202119,
title = {A provably secure authentication scheme for RFID-enabled UAV applications},
journal = {Computer Communications},
volume = {166},
pages = {19-25},
year = {2021},
issn = {0140-3664},
doi = {https://doi.org/10.1016/j.comcom.2020.11.009},
url = {https://www.sciencedirect.com/science/article/pii/S0140366420319897},
author = {Prosanta Gope and Owen Millwood and Neetesh Saxena},
keywords = {Unmanned aerial vehicle, PHysically Uncloneable Functions, Fuzzy extractor, Realistic anonymous authentication},
abstract = {Advantages of Physically Uncloneable Functions (PUFs) have led to appearing a substantial number of novel identification and authentication based systems such as Radio frequency identification (RFID), which is expected to replace the conventional bar-code identification system due to its advantages such as real-time recognition of a considerable number of objects. For example, RFID can be used to identify an unmanned aerial vehicle (UAV) when it is attached with a tag. In this article, we propose a novel anonymous authentication scheme for RFID-enabled UAV applications using Physically Unclonable Functions. Security and the performance analyses demonstrate that our proposed scheme is secure and efficient. Hence, it can be useful for several RFID-based secure application systems.}
}
@article{ZHANG2020102861,
title = {Multi-vehicle routing problems with soft time windows: A multi-agent reinforcement learning approach},
journal = {Transportation Research Part C: Emerging Technologies},
volume = {121},
pages = {102861},
year = {2020},
issn = {0968-090X},
doi = {https://doi.org/10.1016/j.trc.2020.102861},
url = {https://www.sciencedirect.com/science/article/pii/S0968090X20307610},
author = {Ke Zhang and Fang He and Zhengchao Zhang and Xi Lin and Meng Li},
keywords = {Reinforcement learning, Vehicle routing problem, Attention mechanism, Computational efficiency, Multi-agent},
abstract = {Multi-vehicle routing problem with soft time windows (MVRPSTW) is an indispensable constituent in urban logistics distribution systems. Over the past decade, numerous methods for MVRPSTW have been proposed, but most are based on heuristic rules that require a large amount of computation time. With the current rapid increase of logistics demands, traditional methods incur the dilemma between computational efficiency and solution quality. To efficiently solve the problem, we propose a novel reinforcement learning algorithm called the Multi-Agent Attention Model that can solve routing problem instantly benefit from lengthy offline training. Specifically, the vehicle routing problem is regarded as a vehicle tour generation process, and an encoder-decoder framework with attention layers is proposed to generate tours of multiple vehicles iteratively. Furthermore, a multi-agent reinforcement learning method with an unsupervised auxiliary network is developed for the model training. By evaluated on four synthetic networks with different scales, the results demonstrate that the proposed method consistently outperforms Google OR-Tools and traditional methods with little computation time. In addition, we validate the robustness of the well-trained model by varying the number of customers and the capacities of vehicles.}
}
@article{HUA2021107071,
title = {Light-weight UAV object tracking network based on strategy gradient and attention mechanism},
journal = {Knowledge-Based Systems},
volume = {224},
pages = {107071},
year = {2021},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2021.107071},
url = {https://www.sciencedirect.com/science/article/pii/S0950705121003348},
author = {Xia Hua and Xinqing Wang and Ting Rui and Faming Shao and Dong Wang},
keywords = {Computer vision, Object tracking, Attention mechanism, Strategy gradient, Unmanned aerial vehicle},
abstract = {Most existing object tracking methods have poor adaptability to complex scenes, and cannot achieve a good balance between tracking accuracy and real-time performance. To solve the above problems, this paper proposes a lightweight UAV object real-time tracking algorithm based on strategy gradient and attention. Firstly, a lightweight E-Mobile Net is designed as the backbone network of feature extraction; secondly, a feature enhanced attention assistant module is designed to enhance the adaptability and discrimination ability of the model; with multi-layer feature fusion regional suggestion network, foreground background classification and boundary box regression response map are obtained by cross-correlation, and the tracking results are calculated. The strategy network based on strategy gradient is used to optimize the template update and re detection strategy, which improves the overall tracking accuracy and efficiency of the model. Simulation experiments on an embedded device and multiple standard data sets show that compared with the current mainstream algorithms, the tracking accuracy is significantly improved 20%∼30%, the algorithm robustness also has obvious advantages, and the tracking speed on an embedded device is 56 fps can meet the real-time requirements.}
}
@article{LOPEZMARTIN2021114924,
title = {Model-free short-term fluid dynamics estimator with a deep 3D-convolutional neural network},
journal = {Expert Systems with Applications},
volume = {177},
pages = {114924},
year = {2021},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2021.114924},
url = {https://www.sciencedirect.com/science/article/pii/S0957417421003651},
author = {Manuel Lopez-Martin and Soledad {Le Clainche} and Belen Carro},
keywords = {Computational fluid dynamics, Prediction, Deep learning, Convolutional neural network},
abstract = {Deep learning models are not yet fully applied to fluid dynamics predictions, while they are the state-of-the-art solution in many other areas i.e. video and language processing, finance, robotics . Prediction problems on high-dimensional, complex dynamical systems require deep learning models devised to avoid overfitting while maintaining the required model complexity. In this work we present a deep learning prediction model based on a combination of 3D convolutional layers and a low-dimensional intermediate representation that is specifically designed to forecast the future states of this type of dynamical systems. The model predicts p future velocity-field time-slices (samples) based on k past samples from a training dataset consisting of a synthetic jet in transitional regime. The complexity of this flow is characterized by two topology patterns that are periodically changing, making this flow as a suitable example to test the performance of deep learning models to predict time states in complex flows. Moreover, the wide number of applications of synthetic jets (i.e.: fluid mixing, heat transfer enhancement, flow control), points out this example as a reference for future applications, where modeling synthetic jet flows with a reduced computational effort is needed. This work additionally opens up research opportunities for other areas that also operate with complex and high-dimensional time-series data: future frame video prediction, network traffic forecasting, network intrusion detection . The proposed model is presented in detail. A comprehensive analysis of the results is provided. The results are based on a strict validation strategy to ensure its generalization. The model offers an average symmetric mean absolute error (sMAPE) and a relative root mean square error (RRMSE) of 1.068 and 0.026 respectively (one order of magnitude improvement over low-rank approximation tools), using 10 past samples and predicting 6 future samples of a two-dimensional velocity field on a 70x50 point matrix associated to a synthetic jet dataset.}
}
@article{PAN2022509,
title = {Golden eagle optimizer with double learning strategies for 3D path planning of UAV in power inspection},
journal = {Mathematics and Computers in Simulation},
volume = {193},
pages = {509-532},
year = {2022},
issn = {0378-4754},
doi = {https://doi.org/10.1016/j.matcom.2021.10.032},
url = {https://www.sciencedirect.com/science/article/pii/S0378475421003967},
author = {Jeng-Shyang Pan and Ji-Xiang Lv and Li-Jun Yan and Shao-Wei Weng and Shu-Chuan Chu and Jian-Kai Xue},
keywords = {Unmanned aerial vehicle, Path planning, Personal example learning, Mirror reflection learning, Exploration–exploitation},
abstract = {Unmanned aerial vehicle (UAV) inspection is an indispensable part of power inspection. In the process of power inspection, the UAV needs to obtain an efficient and feasible path in the complex environment. To solve this problem, a Golden eagle optimizer with double learning strategies (GEO-DLS) is proposed. The double learning strategies consist of personal example learning and mirror reflection learning. The personal example learning can enhance the search ability of the Golden eagle optimizer (GEO) and reduce the possibility of the GEO falling into the local optimum. The mirror reflection learning can improve the optimization accuracy of the GEO and accelerate the convergence speed of the GEO. To verify the optimization performance of the algorithm, the proposed GEO-DLS and several other algorithms were tested under the CEC2013 test suite. At the same time, the proposed GEO-DLS and the GEO were analyzed for population diversity and exploration–exploitation​ ratio. Finally, the proposed GEO-DLS is applied to the UAV path planning to generate the initial path, and the cubic B-spline curve is used to smooth the path. These experimental results show that the GEO-DLS has a good performance. The code can be publicly available at: https://www.mathworks.com/matlabcentral/fileexchange/98799-golden-eagle-optimizer-with-double-learning-strategies}
}
@article{DENG2021108440,
title = {A secure data collection strategy using mobile vehicles joint UAVs in smart city},
journal = {Computer Networks},
volume = {199},
pages = {108440},
year = {2021},
issn = {1389-1286},
doi = {https://doi.org/10.1016/j.comnet.2021.108440},
url = {https://www.sciencedirect.com/science/article/pii/S1389128621003996},
author = {Qingyong Deng and Shaobo Huang and Zhetao Li and Bin Guo and Liyao Xiang and Rong Ran},
keywords = {Security data collection, Mobile vehicles, Unmanned aerial vehicles, Trust, Set covering problem},
abstract = {Recruiting mobile vehicles (MVs) has been proved as an effective and low-cost strategy to collect data from sensing devices (SDs) in the smart city. However, few works consider data security when using MVs as data mules. In our previous work, we have proposed a Consistent Trust Verification for MVs (CTV-MV), which builts trust through recommendation relationships, but this method was vulnerable to collusion attack, that is, multiple MVs provided consistent fake data to deceive the system. Therefore, a Cross Trust Verification for MVs joint UAVs (CTV-MVU) data collection strategy is proposed in this paper, where the Unmanned Aerial Vehicles (UAVs) are deployed to collect data from specific SDs which are used as baseline data to realize trust reasoning mechanism. Besides, the UAVs can also sense the SDs that are difficult to be collected by MVs due to their limitations of coverage, and thus improve the data collection ratio. Furthermore, a Trust Priority Recruitment (TPR) strategy for CTV-MVU is also proposed to prioritize the recruitment of high-trust MVs. Experiment results show that the proposed CTV-MVU strategy outperforms the CTV-MV one in terms of the excellent ratio, trust, data collection ratio, and robustness.}
}
@article{CHEN2021108186,
title = {Edge intelligence computing for mobile augmented reality with deep reinforcement learning approach},
journal = {Computer Networks},
volume = {195},
pages = {108186},
year = {2021},
issn = {1389-1286},
doi = {https://doi.org/10.1016/j.comnet.2021.108186},
url = {https://www.sciencedirect.com/science/article/pii/S1389128621002425},
author = {Miaojiang Chen and Wei Liu and Tian Wang and Anfeng Liu and Zhiwen Zeng},
keywords = {Beyond fifth-generation, Mobile augmented reality, Markov decision process, Deep reinforcement learning, Artificial intelligence},
abstract = {Convergence of Augmented Reality (AR) and Next Generation Internet-of-Things (NG-IoT) can create new opportunities in many emerging areas, where the real-time data can be visualized on the devices. Integrated NG-IoT network, AR can improve efficiency in many fields such as mobile computing, smart city, intelligent transportation and telemedicine. However, limited by capability of mobile device, the reliability and latency requirements of AR applications is difficult to meet by local processing. To solve this problem, we study a binary offloading scheme for AR edge computing. Based on the proposed model, the parts of AR computing can offload to edge network servers, which is extend the computing capability of mobile AR devices. Moreover, a deep reinforcement learning offloading model is considered to acquire B5G network resource allocation and optimally AR offloading decisions. First, this offloading model does not need to solve combinatorial optimization, which is greatly reduced the computational complexity. Then the wireless channel gains and binary offloading states is modeled as a Markov decision process, and solved by deep reinforcement learning. Numerical results show that our scheme can achieve better performance compared with existing optimization methods.}
}
@article{BEHJAT2020106665,
title = {A physics-aware learning architecture with input transfer networks for predictive modeling},
journal = {Applied Soft Computing},
volume = {96},
pages = {106665},
year = {2020},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2020.106665},
url = {https://www.sciencedirect.com/science/article/pii/S1568494620306037},
author = {Amir Behjat and Chen Zeng and Rahul Rai and Ion Matei and David Doermann and Souma Chowdhury},
keywords = {Hybrid modeling, Neural networks, Particle Swarm Optimization, Physics-aware machine learning, Unmanned aerial vehicle},
abstract = {Hybrid modeling architectures seek to combine a machine learning model with a computationally efficient (simplified or partial) physics model to predict the behavior of physical systems. Existing sequential or parallel approaches to hybrid modeling do not typically exploit the potential relationship between the input or latent features of the partial and full physics. In addition, very few existing architectures take advantage of the provision to generously or on-demand sample the partial physics model. To address these gaps, we have developed a novel neural network-based hybrid architecture called “Opportunistic Physics-mining Transfer Mapping Architecture” or OPTMA. The goal of the OPTMA architecture is to facilitate greater exploitation of input space correlations between partial and full physics where they exist. To this end, a transfer neural network is used to transform the original inputs into modified inputs or latent features, where the partial physics operates on these artificially transformed features to produce the final prediction. An extended back-propagation approach and a Particle Swarm Optimization (to deal with multimodal loss functions) are used to train the network weights. The new architecture is first tested on a simple regression problem for analysis. It is then used to predict the behavior of more complex dynamic systems — an Inverted pendulum and the motion of an unmanned aerial vehicle, both under wind effects. Subsequent tests on unseen samples demonstrate OPTMA’s competitive performance compared to pure ANN and sequential hybrid models and provide empirical validation of the transfer concepts underlying OPTMA.}
}
@article{LIANG2021108573,
title = {Charging UAV deployment for improving charging performance of wireless rechargeable sensor networks via joint optimization approach},
journal = {Computer Networks},
volume = {201},
pages = {108573},
year = {2021},
issn = {1389-1286},
doi = {https://doi.org/10.1016/j.comnet.2021.108573},
url = {https://www.sciencedirect.com/science/article/pii/S1389128621004849},
author = {Shuang Liang and Zhiyi Fang and Geng Sun and Chi Lin and Jiahui Li and Songyang Li and Aimin Wang},
keywords = {Wireless rechargeable sensor networks, Charging unmanned aerial vehicles, Charging efficiency, Joint optimization problem, Firefly algorithm},
abstract = {Wireless power transfer based on charging unmanned aerial vehicles (CUAVs) is a promising method for enhancing the lifetime of wireless rechargeable sensor networks (WRSNs). However, how to deploy the CUAVs so that enhancing the charging efficiency is still a challenge. In this work, we formulate a CUAV deployment optimization problem (CUAVDOP) to jointly increase the number of the sensor nodes that within the charging scopes of CUAVs, improve the minimum charging efficiency in the network and reduce the motion energy consumptions of CUAVs. Moreover, the formulated CUAVDOP is analyzed and proven as NP-hard. Then, we propose an improved firefly algorithm (IFA) to solve the formulated CUAVDOP. IFA introduces three improved items that are the opposition-based learning model, attraction model and adaptive step size factor to enhance the performance of conventional firefly algorithm, so that making it more suitable for solving the formulated CUAVDOP. Simulation results demonstrate that the proposed algorithm is effective for dealing with the formulated joint optimization problem. Moreover, the superiority of IFA is verified by tests.}
}
@article{FU2021104116,
title = {Learning dynamic regression with automatic distractor repression for real-time UAV tracking},
journal = {Engineering Applications of Artificial Intelligence},
volume = {98},
pages = {104116},
year = {2021},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2020.104116},
url = {https://www.sciencedirect.com/science/article/pii/S0952197620303560},
author = {Changhong Fu and Fangqiang Ding and Yiming Li and Jin Jin and Chen Feng},
keywords = {Unmanned aerial vehicle, Visual object tracking, Discriminative correlation filter, Learning dynamic regression, Local maximums repression},
abstract = {With high efficiency and efficacy, the trackers based on the discriminative correlation filter have experienced rapid development in the field of unmanned aerial vehicle (UAV) over the past decade. In literature, these trackers aim at solving a regression problem in which the circulated samples are mapped into a Gaussian label for online filter training. However, the fixed target label for regression makes trackers lose adaptivity in uncertain tracking scenarios. One of the typical failure cases is that the distractors, e.g., background clutter, camouflage, and similar object, are prone to confuse these trackers. In this work, an efficient approach to instantly monitor the local maximums of the response map for discovering distractors automatically is proposed. In addition, the regression target is accordingly learned, i.e., the location possessing local maximum indicates latent distractor and thus should be repressed by reducing its target response value in filter training. Qualitative and quantitative experiments performed on three challenging well-known benchmarks demonstrate that the presented method not only outperforms the state-of-the-art handcrafted feature-based trackers but also exhibits comparable performance compared to deep learning-based approaches. Specifically, the presented tracker has phenomenal practicability in real-time UAV applications with an average speed of ∼50 frames per second on an affordable CPU.}
}
@article{WANG20201,
title = {Artificial noise aided scheme to secure UAV-assisted Internet of Things with wireless power transfer},
journal = {Computer Communications},
volume = {164},
pages = {1-12},
year = {2020},
issn = {0140-3664},
doi = {https://doi.org/10.1016/j.comcom.2020.09.017},
url = {https://www.sciencedirect.com/science/article/pii/S014036642031937X},
author = {Qubeijian Wang and Hong-Ning Dai and Xuran Li and Mahendra K. Shukla and Muhammad Imran},
keywords = {Unmanned aerial vehicles, Internet of Things, Artificial noise, Security, Wireless energy transfer},
abstract = {The proliferation of massive Internet of Things (IoT) devices poses research challenges especially in unmanned aerial vehicles(UAV)-assisted IoT. In particular, the limited battery capacity not only restricts the life time of UAV-assisted IoT but also brings security vulnerabilities since computation-complex cryptographic algorithms cannot be adopted in UAV-assisted IoT systems. In this paper, artificial noise and wireless power transfer technologies are integrated to secure communications in UAV-assisted IoT (particularly in secret key distribution). We present the artificial noise aided scheme to secure UAV-assisted IoT communications by letting UAV gateway transfer energy to a number of helpers who will generate artificial noise to interfere with the eavesdroppers while the legitimate nodes can decode the information by canceling additive artificial noise. We introduce the eavesdropping probability and the security rate to validate the effectiveness of our proposed scheme. We further formulate an eavesdropping probability constrained security rate maximization problem to investigate the optimal power allocation. Moreover, analytical and numerical results are provided to obtain some useful insights, and to demonstrate the effect of crucial parameters (e.g., the transmit power, the main channel gain) on the eavesdropping probability, the security rate, and the optimal power allocation.}
}
@article{ZHANG201714896,
title = {Pattern Classification of Instantaneous Mental Workload Using Ensemble of Convolutional Neural Networks},
journal = {IFAC-PapersOnLine},
volume = {50},
number = {1},
pages = {14896-14901},
year = {2017},
note = {20th IFAC World Congress},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2017.08.2534},
url = {https://www.sciencedirect.com/science/article/pii/S2405896317334560},
author = {Jianhua Zhang and Sunan Li and Zhong Yin},
keywords = {Mental Workload, Pattern Classification, Convolutional Neural Network, Ensemble Learning, Deep Learning, Machine Learning},
abstract = {In this paper, we consider the Mental Workload (MWL) classification problem based on the measured physiological data. Firstly we discussed the optimal classifier structure from two perspectives of Convolutional Neural Network (CNN) depth (i.e., the number of hidden layers) and parameter optimization algorithm. The base CNNs designed were tested according to Accuracy and the model training time required. Then we developed an Ensemble Convolutional Neural Network (ECNN) to enhance the robustness and accuracy of a single CNN model. For the ECNN design, three model aggregation approaches (weighted averaging, majority voting and stacking) were examined and a resampling strategy was used to enhance the diversity of individual CNN models. The results of a series of MWL classification performance comparison indicated that the proposed ECNN framework can effectively improve the MWL classification performance and is characterized by entirely automatic feature extraction and MWL classification, when compared with traditional machine learning methods.}
}
@article{SHAO2021106906,
title = {Mapping maize crop coefficient Kc using random forest algorithm based on leaf area index and UAV-based multispectral vegetation indices},
journal = {Agricultural Water Management},
volume = {252},
pages = {106906},
year = {2021},
issn = {0378-3774},
doi = {https://doi.org/10.1016/j.agwat.2021.106906},
url = {https://www.sciencedirect.com/science/article/pii/S0378377421001712},
author = {Guomin Shao and Wenting Han and Huihui Zhang and Shouyang Liu and Yi Wang and Liyuan Zhang and Xin Cui},
keywords = {Crop water requirements, FAO56 approach, LAI, Evapotranspiration, Random forest regression, Remote sensing},
abstract = {Rapid and accurate acquisition of crop coefficient (Kc) values is essential for estimating field crop evapotranspiration (ET). The lack of rapid access to the high-resolution spatial and temporal distribution of Kc values hinders obtaining a crop Kc value for application in precision irrigation agriculture. This study aimed to explore the potential of leaf area index (LAI) and multispectral vegetation indices (VIs) obtained by an unmanned aerial vehicle (UAV) for estimating the Kc value for a maize crop on a field scale and to obtain a high-resolution spatial-temporal map of Kc values. Hence, the performance of the estimation model for daily maize Kc derived by two machine learning algorithms (random forest regression-RFR and multiple linear regression-MLR) based on the ground-based LAI and six types of UAV-based multispectral VIs (normalized difference vegetation index, NDVI; soil adjusted vegetation index, SAVI; enhanced vegetation index, EVI; transformed chlorophyll absorption in reflectance index, TCARI; green normalized vegetation index, GNDVI; and visual atmospheric resistance index, VARI), was evaluated under multiple irrigation conditions during the entire cropping cycle. Maize RFR with VIs-LAI-based ET was compared to soil water balance (SWB) and FAO-56-based ET. The results showed that the RFR algorithm effectively (R2 = 0.65) estimated maize Kc values based on ground-based LAI and UAV-based VIs. The UAV-based VIs based on Red-edge-Red and Green-Red spectral bands and ground-based LAI were suitable predictors in the Kc prediction model under different irrigation conditions. Further, we successfully obtained a high resolution (pixel size of centimeter) spatial distribution of maize Kc values based on EVI-based LAI and UAV-based VIs. Furthermore, the results indicated that the combination of UAV multispectral remote sensing technology and the RFR algorithm provides a potential solution for the distribution of water use and precision irrigation on a field scale.}
}
@article{QU2021247,
title = {DroneCOCoNet: Learning-based edge computation offloading and control networking for drone video analytics},
journal = {Future Generation Computer Systems},
volume = {125},
pages = {247-262},
year = {2021},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2021.06.040},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X21002351},
author = {Chengyi Qu and Prasad Calyam and Jeromy Yu and Aditya Vandanapu and Osunkoya Opeoluwa and Ke Gao and Songjie Wang and Raymond Chastain and Kannappan Palaniappan},
keywords = {Edge/fog computation offloading, Drone video analytics, Mobile edge computing, Learning-based scheme, Data processing in fog computing},
abstract = {Multi-Unmanned Aerial Vehicle (UAV) systems with high-resolution cameras have been found useful for operations such as smart city and disaster management. These systems feature Flying Ad-Hoc Networks (FANETs) that connect the computation edge with UAVs and a Ground Control Station (GCS) through air-to-ground wireless network links. Leveraging the edge/fog computation resources effectively with energy-latency-awareness, and handling intermittent failures of FANETs are the major challenges in supporting video processing applications. In this paper, we propose a novel “DroneCOCoNet” framework for drone video analytics that coordinates intelligent processing of large video datasets using edge computation offloading and performs network protocol selection based on resource-awareness. We present two edge computation offloading approaches, i.e., heuristic-based and reinforcement learning-based approaches. These approaches provide intelligent task sharing and co-ordination for dynamic offloading decision-making among UAVs. Our scheme handles the problem of computation offloading tasks in two separate ways: (i) heuristic decision-making process, and (ii) Markov decision process; wherein we aim to minimize the total computation costs as well as latency in the edge/fog resources while minimizing video processing times to meet application requirements. Our experimental results show that our heuristic-based offloading decision-making scheme enables lower scheduling time and energy consumption for low drone-to-ground server ratios. In comparison, our dynamic reinforcement learning-based decision-making approach increases the accuracy and saves overall time periodically. Notably, these results also hold in various other multi-UAV scenarios involving largely different numbers of detected objects in e.g., smart farming, transportation traffic flow monitoring and disaster response.}
}
@article{JENKINS2021101121,
title = {Predicting success in United States Air Force pilot training using machine learning techniques},
journal = {Socio-Economic Planning Sciences},
pages = {101121},
year = {2021},
issn = {0038-0121},
doi = {https://doi.org/10.1016/j.seps.2021.101121},
url = {https://www.sciencedirect.com/science/article/pii/S0038012121001130},
author = {Phillip R. Jenkins and William N. Caballero and Raymond R. Hill},
keywords = {Human resource management, Machine learning, Pilot training, Educational data mining},
abstract = {The chronic pilot shortage that has plagued the United States Air Force over the past three years poses a national-level problem that senior military members are working to overcome. Unfortunately, not all pilot candidates successfully complete the necessary training requirements to become fully qualified Air Force pilots, which wastes critical time and resources and only further exacerbates the pilot shortage problem. Therefore, it is important for the Air Force to carefully consider whom they select to attend pilot training. This research examines historical specialized undergraduate pilot training (SUPT) candidate data leveraging a variety of machine learning techniques to obtain insights on candidate success. Computational experimentation is performed to determine how selected machine learning techniques and their respective hyperparameters affect solution quality. Results reveal that the extremely randomized tree machine learning technique can achieve nearly 94% accuracy in predicting candidate success. Additional analysis indicates degree type and commissioning source are the most important features in determining candidate success. Ultimately, this research can inform the modification of future SUPT candidate selection criteria and other related Air Force personnel policies.}
}
@article{SEYYEDABBASI2021107044,
title = {Hybrid algorithms based on combining reinforcement learning and metaheuristic methods to solve global optimization problems},
journal = {Knowledge-Based Systems},
volume = {223},
pages = {107044},
year = {2021},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2021.107044},
url = {https://www.sciencedirect.com/science/article/pii/S0950705121003075},
author = {Amir Seyyedabbasi and Royal Aliyev and Farzad Kiani and Murat Ugur Gulle and Hasan Basyildiz and Mohammed Ahmed Shah},
keywords = {Metaheuristic algorithm, Reinforcement learning algorithm, Grey wolf optimization algorithm, Whale optimization algorithm, Q-learning},
abstract = {This paper introduces three hybrid algorithms that help in solving global optimization problems using reinforcement learning along with metaheuristic methods. Using the algorithms presented, the search agents try to find a global optimum avoiding the local optima trap. Compared to the classical metaheuristic approaches, the proposed algorithms display higher success in finding new areas as well as exhibiting a more balanced performance while in the exploration and exploitation phases. The algorithms employ reinforcement agents to select an environment based on predefined actions and tasks. A reward and penalty system is used by the agents to discover the environment, done dynamically without following a predetermined model or method. The study makes use of Q-Learning method in all three metaheuristic algorithms, so-called RLI−GWO, RLEx−GWO, and RLWOA algorithms, so as to check and control exploration and exploitation with Q-Table. The Q-Table values guide the search agents of the metaheuristic algorithms to select between the exploration and exploitation phases. A control mechanism is used to get the reward and penalty values for each action. The algorithms presented in this paper are simulated over 30 benchmark functions from CEC 2014, 2015 and the results obtained are compared with well-known metaheuristic and hybrid algorithms (GWO, RLGWO, I-GWO, Ex-GWO, and WOA). The proposed methods have also been applied to the inverse kinematics of the robot arms problem. The results of the used algorithms demonstrate that RLWOA provides better solutions for relevant problems.}
}
@article{KHALIL2021269,
title = {Neural network for grain yield predicting based multispectral satellite imagery: comparative study},
journal = {Procedia Computer Science},
volume = {186},
pages = {269-278},
year = {2021},
note = {14th International Symposium "Intelligent Systems},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2021.04.146},
url = {https://www.sciencedirect.com/science/article/pii/S1877050921009625},
author = {Z.H. Khalil and S.M. Abdullaev},
keywords = {Neural network, vegetation index, machine learning, multispectral satellite imagery, crop yield prediction},
abstract = {Estimations of crop yield predictions are vital in the management of agronomical matters. Such Agronomical issues affecting agriculture include agricultural management, national food policies, as well as the international crop trade-which is under the mandate of Food agriculture organization (FAO). Also, an increase in food demand due to the ever-growing population has contributed to the cultivation of large tracts of land. Thus has led to the evolution of diverse methods as well as systems deployed for prediction of crop yield including the application of satellite images. Satellite techniques are utilized due to their capacity to continuously cover large areas while providing accurate estimations of crop yields. In this context of crop yield estimations, the vegetation indices provided by the satellite sensors, as well as land surface variables such as weather elements, soil moisture, hydrological conditions, soil fertility, and fertilizer application is used. Where the convenience of data acquisition and high prediction accuracy is mandatory, many empirical models based on machine learning techniques were employed and the most successful methodology applied was the neural network. The neural network data input varied in the form of normalized histograms of a multi-spectral image bands, normalized vegetation index, absorbed active photosynthetic radiation, canopy surface, and environmental factors. Our findings indicate that the rapid advances in satellite technologies and ML techniques will provide affordable and comprehensive solutions for accurate grain prediction. Many remote sensing researches for yield estimation is needed to adjust and develop the existing methods for more accurate grain crop prediction.}
}
@article{LAM20205757,
title = {Fast Hildreth-based Model Predictive Control of Roll Angle for a Fixed-Wing UAV},
journal = {IFAC-PapersOnLine},
volume = {53},
number = {2},
pages = {5757-5763},
year = {2020},
note = {21st IFAC World Congress},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2020.12.1608},
url = {https://www.sciencedirect.com/science/article/pii/S2405896320322047},
author = {V.T.T. Lam and A. Sattar and L. Wang and M. Lazar},
keywords = {Model Predictive Control, Quadratic Programming, Fixed-Wing Unmanned Aerial Vehicle, Active Set Methods},
abstract = {In this paper we consider model predictive control (MPC) design for roll angle control for a fixed-wing unmanned aerial vehicle (UAV) with multiple segmented control surfaces. The challenge of roll angle control for a fixed-wing UAV consists of switching between inner and outer aileron pairs with hard constraints due to safety, energy saving and switching actuators. The novelty consists of formulating a hybrid control problem as a switched linear constrained MPC-QP problem and switched state observer design for fixed-wing UAV. A fast novel QP-solver based on the active-set QP-solver Hildreth is developed to meet the real-time implementation sampling time of Ts = 10 ms. The designed MPC controllers are simulated using Matlab. Simulations and the CPU-time from the improved QP-solvers show MPC to be a very good solution for real-time roll angle control of fixed-wing UAVs.}
}
@article{CHEN2021,
title = {Three dimensional stabilization controller based on improved quaternion transformation for fixed-wing UAVs},
journal = {ISA Transactions},
year = {2021},
issn = {0019-0578},
doi = {https://doi.org/10.1016/j.isatra.2021.10.035},
url = {https://www.sciencedirect.com/science/article/pii/S0019057821005565},
author = {Pengyun Chen and Tong Guan and Guobing Zhang and Shangyao Shi and Jian Shen and Meini Yuan},
keywords = {UAV, Quaternion, Homogeneous method},
abstract = {To realize the three-dimensional stabilization control of fixed-wing unmanned aerial vehicles (UAVs), we analyze the nonholonomic characteristics, constraint non-integrability, and controllability of UAVs. To simplify the trigonometric function term in the dynamics of the UAV and avoid the singularity problem of the Euler angle in describing attitude, we use the quaternion theory to transform the dynamics of the UAV to avoid the complex trigonometric function derivation, which makes the dynamic matrix more concise. Based on this, a continuous periodic time-varying controller (CPTVC) is designed, and the effectiveness of the controller is proved using the homogeneous method. Finally, the results of the hardware in a loop simulation indicated that the exponential stability provided by the feedback controller can realize the three-dimensional stabilization of any initial position.}
}
@article{SADASHIVAN2021192,
title = {Fully automated region of interest segmentation pipeline for UAV based RGB images},
journal = {Biosystems Engineering},
volume = {211},
pages = {192-204},
year = {2021},
issn = {1537-5110},
doi = {https://doi.org/10.1016/j.biosystemseng.2021.08.032},
url = {https://www.sciencedirect.com/science/article/pii/S1537511021002166},
author = {Shreeshan Sadashivan and Subhra S. Bhattacherjee and Gattu Priyanka and Rajalakshmi Pachamuthu and Jana Kholova},
keywords = {High throughput phenotyping, UAV, Sub-Path detection, Parallel processing, Sub-Plot, LAI},
abstract = {Unmanned Aerial Vehicles (UAVs) have exhibited its potential for efficient and non-invasive crop data acquisition in high throughput crop phenotyping. In general, for analysis of phenotypic traits, there is a need for extracting the region of interest (RoI) from images captured by UAVs. It involves the generation of orthomosaic, which is a complicated and time-intensive process. In this study, a fully automated AI-based pipeline has been proposed for the RoI segmentation from raw RGB images acquired via UAV. The proposed pipeline achieves a near real-time processing speed compared to the other baseline methods. The key feature of the pipeline is the introduction of Sub-Paths, in which the original UAV flight path is divided into several small paths which facilitates parallel processing. The image quality of the extracted RoI has been examined using blind/referenceless image spatial quality evaluator (BRISQUE) and natural image quality evaluator (NIQE). The performance of the proposed pipeline is exemplified with the Leaf Area Index (LAI) estimation on five datasets containing three different crop types and growth stages. Regression analysis has also been performed on the estimated LAI values. Average R2, RMSE, and correlation scores of the estimates are observed to be 0.68, 0.033, and 0.83, respectively.}
}
@article{HU2022147,
title = {S3ANet: Spectral-spatial-scale attention network for end-to-end precise crop classification based on UAV-borne H2 imagery},
journal = {ISPRS Journal of Photogrammetry and Remote Sensing},
volume = {183},
pages = {147-163},
year = {2022},
issn = {0924-2716},
doi = {https://doi.org/10.1016/j.isprsjprs.2021.10.014},
url = {https://www.sciencedirect.com/science/article/pii/S0924271621002823},
author = {Xin Hu and Xinyu Wang and Yanfei Zhong and Liangpei Zhang},
keywords = {Precise crop classification, Spectral attention, Spatial attention, Scale attention, UAV-borne hyperspectral imagery, WHU-Hi dataset},
abstract = {High spatial and spectral resolution (H2) imagery collected by unmanned aerial vehicle (UAV) systems is an important data source for precise crop classification. Although this data source can provide us with abundant information about the crops of interest, it also introduces new challenges for the image processing. Specifically, the spectral similarities of green crops lead to small inter-class distances, and the severe intra-class spectral variability and high spatial heterogeneity in H2 imagery increases the difficulty of precise classification. In addition, the scales of the different crop plots can show great differences, which makes it difficult to determine the optimal patch size for deep learning based classification models. In this paper, a spectral-spatial-scale attention network (S3ANet) is proposed for H2 imagery based precise crop classification. In the proposed method, each channel, each pixel, and each scale perception of the feature map is adaptively weighted to relieve the intra-class spectral variability, the spatial heterogeneity, and the scale difference of the crop plots, respectively. Furthermore, the proposed S3ANet method introduces the additive angular margin loss function to further increase the inter-class distances between the different crops, and reduce the misclassification effect. S3ANet was verified using the public WHU-Hi UAV-borne hyperspectral dataset and the new WHU-Hi-JiaYu dataset, which is a dataset for precise rice classification that was built by the authors. In these experiments, the overall accuracy of the proposed S3ANet method all exceeds 96% under 50 training pixels per class, and it achieved significant improvement compared with some state-of-the-art hyperspectral images classifiers (such as SSRN, CNNCRF and FPGA, etc.). The code of S3ANet is available at http://rsidea.whu.edu.cn/resource_sharing.htm.}
}
@article{POURRAHIMIAN2020103012,
title = {On-demand monitoring of construction projects through a game-like hybrid application of BIM and machine learning},
journal = {Automation in Construction},
volume = {110},
pages = {103012},
year = {2020},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2019.103012},
url = {https://www.sciencedirect.com/science/article/pii/S0926580519310222},
author = {Farzad {Pour Rahimian} and Saleh Seyedzadeh and Stephen Oliver and Sergio Rodriguez and Nashwan Dawood},
keywords = {Construction management, Progress monitoring, Building information modelling, Image processing, Virtual reality, Machine learning},
abstract = {While unavoidable, inspections, progress monitoring, and comparing as-planned with as-built conditions in construction projects do not readily add tangible intrinsic value to the end-users. In large-scale construction projects, the process of monitoring the implementation of every single part of buildings and reflecting them on the BIM models can become highly labour intensive and error-prone, due to the vast amount of data produced in the form of schedules, reports and photo logs. In order to address the mentioned methodological and technical gap, this paper presents a framework and a proof of concept prototype for on-demand automated simulation of construction projects, integrating some cutting edge IT solutions, namely image processing, machine learning, BIM and Virtual Reality. This study utilised the Unity game engine to integrate data from the original BIM models and the as-built images, which were processed via various computer vision techniques. These methods include object recognition and semantic segmentation for identifying different structural elements through supervised training in order to superimpose the real world images on the as-planned model. The proposed framework leads to an automated update of the 3D virtual environment with states of the construction site. This framework empowers project managers and stockholders with an advanced decision-making tool, highlighting the inconsistencies in an effective manner. This paper contributes to body knowledge by providing a technical exemplar for the integration of ML and image processing approaches with immersive and interactive BIM interfaces, the algorithms and program codes of which can help replicability of these approaches by other scholars.}
}
@article{SMITH20213667,
title = {Propulsionless planar phasing of multiple satellites using deep reinforcement learning},
journal = {Advances in Space Research},
volume = {67},
number = {11},
pages = {3667-3682},
year = {2021},
note = {Satellite Constellations and Formation Flying},
issn = {0273-1177},
doi = {https://doi.org/10.1016/j.asr.2020.09.025},
url = {https://www.sciencedirect.com/science/article/pii/S0273117720306724},
author = {Brenton Smith and Rasit Abay and Joshua Abbey and Sudantha Balage and Melrose Brown and Russell Boyce},
keywords = {Reinforcement learning, Formation control},
abstract = {This work creates a framework for solving highly non-linear satellite formation control problems by using model-free policy optimisation deep reinforcement learning (DRL) methods. This work considers, believed to be for the first time, DRL methods, such as advantage actor-critic method (A2C) and proximal policy optimisation (PPO), to solve the example satellite formation problem of propellantless planar phasing of multiple satellites. Three degree-of-freedom simulations, including a novel surrogate propagation model, are used to train the deep reinforcement learning agents. During training, the agents actuated their motion through cross-sectional area changes which altered the environmental accelerations acting on them. The DRL framework designed in this work successfully coordinated three spacecraft to achieve a propellantless planar phasing manoeuvre. This work has created a DRL framework that can be used to solve complex satellite formation flying problems, such as planar phasing of multiple satellites and in doing so provides key insights into achieving optimal and robust formation control using reinforcement learning.}
}
@article{FENG2020679,
title = {Optimal trajectory tracking control based on reinforcement learning for the deployment process of space tether system},
journal = {IFAC-PapersOnLine},
volume = {53},
number = {1},
pages = {679-684},
year = {2020},
note = {6th Conference on Advances in Control and Optimization of Dynamical Systems ACODS 2020},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2020.06.113},
url = {https://www.sciencedirect.com/science/article/pii/S2405896320301324},
author = {Yiting Feng and Changqing Wang and Aijun Li},
keywords = {space tether system, deployment, trajectory tracking, neural network, adaptive dynamic programming, reinforcement learning},
abstract = {Space tether system has a wide application prospect in space mission. Due to the characteristics of strong non-linearity and under-actuation, as well as the interference of complex space environment, it is difficult to model the tethered system accurately. Hence, the controller based on the parameters of the system model will cause large errors in the process of control. In this paper, an adaptive dynamic programming algorithm based on reinforcement learning theory is adopted. By training two Back Propagation (BP) neural networks, namely critic neural network (NN) and actor NN, the performance index function and control law of the system approach approximate optimal values respectively. The controller design is independent of the system model, so model-free control of the system is realized by implementing this control method. First, assuming that the out-of-plane motion of the system is stable, the optimal deployment trajectory of the tethered system is obtained by parameter optimization based on Nelder-Mead method. The optimal trajectory is taken as the nominal trajectory and the trajectory tracking is carried out by reinforcement learning controller. The simulation results show that the reinforcement learning algorithm has a good control effect on the in-plane trajectory tracking of the tethered system, which proves the feasibility and robustness of the control method.}
}
@article{JIANG2021,
title = {Green UAV communications for 6G: A survey},
journal = {Chinese Journal of Aeronautics},
year = {2021},
issn = {1000-9361},
doi = {https://doi.org/10.1016/j.cja.2021.04.025},
url = {https://www.sciencedirect.com/science/article/pii/S1000936121001801},
author = {Xu Jiang and Min Sheng and Nan Zhao and Chengwen Xing and Weidang Lu and Xianbin Wang},
keywords = {Energy efficiency, Green communications, Sixth Generation (6G) networks, Unmanned Aerial Vehicle (UAV), Wireless networks},
abstract = {Unmanned Aerial Vehicles (UAVs) have received a wide range of attention for military and commercial applications. Enhanced with communication capability, UAVs are considered to play important roles in the Sixth Generation (6G) networks due to their low cost and flexible deployment. 6G is supposed to be an all-coverage network to provide ubiquitous connections for space, air, ground and underwater. UAVs are able to provide air-borne wireless coverage flexibly, serving as aerial base stations for ground users, as relays to connect isolated nodes, or as mobile users in cellular networks. However, the onboard energy of small UAVs is extremely limited. Thus, UAVs can be only deployed to establish wireless links temporarily. Prolonging the lifetime and developing green UAV communication with low power consumption becomes a critical challenge. In this article, a comprehensive survey on green UAV communications for 6G is carried out. Specifically, the typical UAVs and their energy consumption models are introduced. Then, the typical trends of green UAV communications are provided. In addition, the typical applications of UAVs and their green designs are discussed. Finally, several promising techniques and open research issues are also pointed out.}
}
@article{FENG2022110,
title = {Resilience optimization for multi-UAV formation reconfiguration via enhanced pigeon-inspired optimization},
journal = {Chinese Journal of Aeronautics},
volume = {35},
number = {1},
pages = {110-123},
year = {2022},
issn = {1000-9361},
doi = {https://doi.org/10.1016/j.cja.2020.10.029},
url = {https://www.sciencedirect.com/science/article/pii/S1000936120305616},
author = {Qiang FENG and Xingshuo HAI and Bo SUN and Yi REN and Zili WANG and Dezhen YANG and Yaolong HU and Ronggen FENG},
keywords = {Formation reconfiguration, Parameter optimization, Pigeon-inspired optimization, Resilience, Unmanned aerial vehicles},
abstract = {This paper develops a novel optimization method oriented to the resilience of multiple Unmanned Aerial Vehicle (multi-UAV) formations to achieve rapid and accurate reconfiguration under random attacks. First, a resilience metric is applied to reflect the effect and rapidity of multi-UAV formation resisting random attacks. Second, an optimization model based on a parameter optimization problem to maximize the system resilience is established. Third, an Adaptive Learning-based Pigeon-Inspired Optimization (ALPIO) algorithm is designed to optimize the resilience value. Finally, typical formation topologies with six UAVs are investigated as a case study to verify the proposed approach. The experimental results indicate that the proposed scheme can achieve resilience optimization for a multi-UAV formation reconfiguration by increasing the system resilience values to 97.53% and 81.4% after random attacks.}
}
@article{TOGEIRODEALCKMIN2022106574,
title = {Perennial ryegrass biomass retrieval through multispectral UAV data},
journal = {Computers and Electronics in Agriculture},
volume = {193},
pages = {106574},
year = {2022},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2021.106574},
url = {https://www.sciencedirect.com/science/article/pii/S0168169921005913},
author = {Gustavo {Togeirode Alckmin} and Arko Lucieer and Richard Rawnsley and Lammert Kooistra},
keywords = {Perennial ryegrass, Machine learning, Vegetation indices, Biomass, UAV, Radiometric calibration},
abstract = {Frequent biomass measurement is a key activity for optimal perennial ryegrass (Lolium perenne) management in intensive forage-based dairy operations. Due to the necessary high-frequency (i.e., weekly or monthly) pasture monitoring and continuous trend of larger dairy farms, such activity is perceived as an operational bottleneck. Consequently, substantial effort is directed to the development of accurate and automated technological solutions for biomass assessment. The popularization of unmanned aerial vehicles (UAVs) combined with multispectral cameras should allow for an optimal observational system able to deploy machine learning algorithms for near real-time biomass dry-matter (DM) mapping. For successful operation, these systems should deliver radiometrically accurate orthomosaics and robust models able to generalize across different periods. Nevertheless, the accuracy of radiometric calibration and generalization ability of these models is seldom evaluated. Also, such pipelines should require minimum processing power and allow for fast deployment. This study has established a two-year experiment comparing reflectance measurements between a handheld spectrometer and a commercial multispectral UAV camera. Different algorithms based on regression-tree architecture were contrasted regarding accuracy, speed, and model size. Model performances were validated, providing error-metrics for baseline accuracy and temporal validation. The results have shown that the standard procedure for multispectral imagery radiometric calibration is sub-optimal, requiring further post-processing and presenting low correlation with handheld measurements across spectral bands and dates. Nevertheless, after post-calibration, the use of spectral imagery has presented better baseline error than the point-based sensors, respectively displaying an average of 397.3 and 464.2 kg DM/ha when employed alongside the best performing algorithm (i.e., Cubist). When trained and validated across different years, model performance was largely reduced and deemed unfit for operational purposes. The Cubist/M5 family of algorithms have exhibited advantageous characteristics such as compact model structure, allowing for a higher level of model interpretability, while displaying a smaller size and faster deployment than the Random Forest, Boosted, and Bagged Regression Trees algorithms.}
}
@article{KNOLL2019105097,
title = {Real-time classification of weeds in organic carrot production using deep learning algorithms},
journal = {Computers and Electronics in Agriculture},
volume = {167},
pages = {105097},
year = {2019},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2019.105097},
url = {https://www.sciencedirect.com/science/article/pii/S016816991931631X},
author = {Florian J. Knoll and Vitali Czymmek and Leif O. Harders and Stephan Hussmann},
keywords = {Convolution Neural Network (CNN), Deep learning, Visual sensors, Colour room processing, Random forest classifier, Real-time performance, Organic farming},
abstract = {This paper proposes a real-time machine learning approach for carrot plants classification in organic farming using Convolutional Neural Network. Artificial neural networks become increasingly popular for image processing tasks, e.g. the classification of complex structures in images. The problem is not very often the accuracy of the classification, but the speed of calculation. The core of this paper presents a real-time calculation flow for the neural networks, in which all the individual steps are summarized. It also briefly discusses the used sensors, which are suitable for the Convolutional Neural Network and the pre-processing which extracts the plants from the background in order to keep the load on the neural network as low as possible.}
}
@article{SANKARALINGAM2021108379,
title = {Angle of attack measurement using low-cost 3D printed five hole probe for UAV applications},
journal = {Measurement},
volume = {168},
pages = {108379},
year = {2021},
issn = {0263-2241},
doi = {https://doi.org/10.1016/j.measurement.2020.108379},
url = {https://www.sciencedirect.com/science/article/pii/S0263224120309155},
author = {L. Sankaralingam and C. Ramprasadh},
keywords = {Angle of attack measurement, Multihole probe, Unmanned aerial vehicles, Air data probes},
abstract = {This paper presents a low-cost 3D printed Five Hole Probe (FHP) for Angle of Attack (AOA) measurement and a solution to predict the missing pressure data due to hole blockage using machine learning. The five Hole Probe is designed and fabricated taking reference to the open-source probe called “the oxford probe”. It is intended to use this probe in Mini Unmanned Aerial Vehicles for AOA measurement because the UAVs are primarily designed to carry out unconventional missions like flying at low speed and low altitude, which makes the AOA measurement as one of the absolute requirement. The main challenges involved in mini flyers are their size and weight constraints. Due to these constraints, the probe should have lightweight but highly accurate. Keeping this in mind, suitable design modifications and material selection are made on the Oxford probe and it is manufactured by 3D printing. Then the 3D printed probe is tested in the wind tunnel. In parallel, a CFD analysis of the FHP is carried out in the ANSYS WORKBENCH environment and the results are presented. The CFD results are compared with windtunnel measurements of AOA, and the results are analyzed. Calibration of FHP is carried out, and a lookup table is generated using the pressure coefficients CPα and CPβ corresponding to respective AOA and AOS. For validation, the probe is kept at known AOA and AOS, and the pressure coefficients were calculated. It has been found that the accuracy of measurement is increased by using the mean of ten pressure samples for calculating the pressure coefficients, instead of every pressure sample. And due to the small diameter, the ports may get blocked from dust particles. The machine learning algorithm (SVR – Support Vector Regression) has been trained and tested to tackle the problem of hole blockage. Various regression models were tested to predict the missing Pressure. The Quadratic SVR regression model is selected based on RMSE value. The selected regression model is validated by blocking one of the ports of FHP.}
}
@article{LIU2021109301,
title = {Tree species classification of LiDAR data based on 3D deep learning},
journal = {Measurement},
volume = {177},
pages = {109301},
year = {2021},
issn = {0263-2241},
doi = {https://doi.org/10.1016/j.measurement.2021.109301},
url = {https://www.sciencedirect.com/science/article/pii/S0263224121003043},
author = {Maohua Liu and Ziwei Han and Yiming Chen and Zhengjun Liu and Yanshun Han},
keywords = {LiDAR, Point cloud, 3D deep learning, Tree species classification},
abstract = {Accurate tree species identification is essential for ecological evaluation and other forest applications. In this paper, we proposed a point-based deep neural network called LayerNet. For light detection and ranging (LiDAR) data in forest regions, the network can divide multiple overlapping layers in Euclidean space to obtain the local three-dimensional (3D) structural features of the tree. The features of all layers are aggregated, and the global feature is obtained by convolution to classify the tree species. To validate the proposed framework, multiple experiments, including airborne and ground-based LiDAR datasets, are conducted and compared with several existing tree species classification algorithms. The test results show that LayerNet can directly use 3D data to accurately classify tree species, with the highest classification accuracy of 92.5%. Also, the results of comparative experiments demonstrate that the proposed framework has obvious advantages in classification accuracy and provides an effective solution for tree species classification tasks.}
}
@article{WEN2019105004,
title = {Single-rotor UAV flow field simulation using generative adversarial networks},
journal = {Computers and Electronics in Agriculture},
volume = {167},
pages = {105004},
year = {2019},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2019.105004},
url = {https://www.sciencedirect.com/science/article/pii/S0168169919306878},
author = {Sheng Wen and Ningwen Shen and Jiantao Zhang and Yubin Lan and Jie Han and Xuanchun Yin and Quanyong Zhang and Yufeng Ge},
keywords = {Flow-field, CFD, GAN, Flow field prediction, Feature extraction},
abstract = {In recent years, with the large-scale application of unmanned aerial vehicles (UAV) in agricultural plant protection, various shortcomings of have been identified; for example, the rotor flow field of the UAV will cause drift of the droplets, resulting in waste and secondary disaster. Therefore, digital simulation has become a necessity. However, due to the complexity of the rotor flow field of the rotor UAV and the operating environment of the UAV, digital simulation is associated with a large workload and great computational costs. It is urgent to explore new models using deep learning to identify the law of the rotor flow field. To address this problem, deep learning, in combination with flow field methods, is used to explore new models in this paper. A generative adversarial network (GAN) prediction model is proposed in this paper. The GAN includes a generation network and a discrimination network. In this paper, the features of the flow field are learned by the generative network to identify deep features of the flow field. The discrimination network distinguishes between true and false pictures by extracting features during training to realize adversarial training. This model can predict the flow field by identifying features of the flow-field distribution in training samples to build a predictive model. The compression effects of the computational fluid dynamics (CFD) model and the GAN model are compared in this paper. The GAN model outperforms the CFD model in predicting the flow field and compressing the data.}
}
@article{PI2021101278,
title = {3D-CNN based UAV hyperspectral imagery for grassland degradation indicator ground object classification research},
journal = {Ecological Informatics},
volume = {62},
pages = {101278},
year = {2021},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2021.101278},
url = {https://www.sciencedirect.com/science/article/pii/S1574954121000698},
author = {Weiqiang Pi and Jianmin Du and Yuge Bi and Xinchao Gao and Xiangbing Zhu},
keywords = {3D convolutional neural networks, Degraded grasslands, Plant population classification, UAV hyperspectral remote sensing},
abstract = {The identification and counting of grassland degradation indicator ground objects is an important component of grassland ecological monitoring. These steps are also an important basis for developing ecological restoration and management programs for degraded grasslands. Compared with a traditional human survey, the use of remote sensing images can not only achieve dynamic monitoring of a large area, but also improve the efficiency. Recently, most studies regarding ground object classification based on remote sensing images address the development and optimization of classification models for features in several widely used datasets. For the remote sensing of desertified grasslands, remote sensing images with high spatial resolutions are used for studies on small and sparse features in degraded grasslands. The spatial resolution of the above mentioned datasets yields difficulties when attempting to classify small and sparse indicator features for desertified grasslands because generalization becomes limited. Therefore, establishing a lightweight classification model suitable for degraded grassland features with high spatial resolution is important. In this study, a low altitude unmanned aerial vehicle (UAV) hyperspectral remote sensing platform was constructed to collect high spatial resolution remote sensing images of degraded grasslands. The GDIF-3D-CNN classification model was used to classify the pure pixels and all pixels datasets, whose accuracy and efficiency were further improved by optimizing the eight parameters of the model. This study explores the remote sensing ground object classification of thin small plants and a large number of mixed pixels, realizing high precision classification among desertification degradation indicating plant populations of a species, and provides key quantitative data for grassland degradation research.}
}
@article{KIM2021103941,
title = {Investigation of steel frame damage based on computer vision and deep learning},
journal = {Automation in Construction},
volume = {132},
pages = {103941},
year = {2021},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2021.103941},
url = {https://www.sciencedirect.com/science/article/pii/S0926580521003927},
author = {Bubryur Kim and N. Yuvaraj and Hee Won Park and K.R. Sri Preethaa and R. Arun Pandian and Dong-Eun Lee},
keywords = {Steel frame damage, Deep learning, Computer vision, Deep convolutional neural network, Steel structure monitoring},
abstract = {Visual damage inspection of steel frames by eyes alone is time-consuming and cumbersome; therefore, it produces inconsistent results. Existing computer vision-based methods for inspecting civil structures using deep learning algorithms have not reached full maturity in exactly locating the damage. This paper presents a deep convolutional neural network-based damage locating (DCNN-DL) method that classifies the steel frame images provided as inputs as damaged and undamaged. DenseNet, a DCNN architecture, was trained to classify the damage. The DenseNet output was upscaled and superimposed on the original image to locate the damaged part of the steel frame. The DCNN-DL method was validated using 144 training and 114 validation sets of steel frame images. DenseNet, with an accuracy of 99.3%, outperformed MobileNet and ResNet with accuracies of 96.2% and 95.4%, respectively. This case study confirms that the DCNN-DL method effectively facilitates the real-time inspection and location of steel frame damage.}
}
@article{ZHANG2022106616,
title = {Improving wheat yield estimates using data augmentation models and remotely sensed biophysical indices within deep neural networks in the Guanzhong Plain, PR China},
journal = {Computers and Electronics in Agriculture},
volume = {192},
pages = {106616},
year = {2022},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2021.106616},
url = {https://www.sciencedirect.com/science/article/pii/S0168169921006335},
author = {Jingqi Zhang and Huiren Tian and Pengxin Wang and Kevin Tansey and Shuyu Zhang and Hongmei Li},
keywords = {Convolutional neural network, Leaf area index, Vegetation temperature condition index, Yield estimation, Generative adversarial network},
abstract = {Crop yield estimation and prediction constitutes a key issue in agricultural management, particularly under the context of demographic pressure and climate change. Currently, the main challenge in estimating crop yields based on remotely sensed data and data-driven methods is how to cope with small datasets and the limited amount of annotated samples. In order to cope with small datasets and the limited amount of annotated samples and improve the accuracy of winter wheat yield estimation in the Guanzhong Plain, PR China, this study proposed a method of combining generative adversarial networks (GANs) and convolutional neural network (CNN) for comprehensive growth monitoring of winter wheat, in which the remotely sensed leaf area index (LAI), vegetation temperature condition index (VTCI) and meteorological data at four growth stages of winter wheat during 2012–2017 were generated as the inputs of multi-layer convolutional neural networks (CNNs), and GAN was employed to artificially increase the number of training samples. Then, a linear regression model between the simulated comprehensive growth monitoring (I) and the measured yields was established to estimate yields of winter wheat in the Guanzhong Plain pixel by pixel. The final results showed when GAN was used to double the size of the training samples, and the simulation values obtained by CNN based on augmented samples using GAN provided a better training (R2 = 0.95, RMSE = 0.05), validation (R2 = 0.54, RMSE = 0.16) and testing (R2 = 0.50, RMSE = 0.14) performance than that just using the original samples. The achieved best pixel-scale yield estimation accuracy of winter wheat (R2 = 0.50, RMSE = 591.46 kg/ha) in the Guanzhong Plain. These results showed that small samples can be enlarged by GAN, thus, more important features for reflecting the growth conditions and yields of winter wheat from the remotely sensed indices and meteorological indices can be extracted, and indicated that CNN accompanied with GAN could contribute a lot to the comprehensive growth monitoring and yield estimation of winter wheat and data augmentation methods are extremely useful for the application of small samples in deep learning.}
}
@article{CHENG2020102341,
title = {Automatic delamination segmentation for bridge deck based on encoder-decoder deep learning through UAV-based thermography},
journal = {NDT & E International},
volume = {116},
pages = {102341},
year = {2020},
issn = {0963-8695},
doi = {https://doi.org/10.1016/j.ndteint.2020.102341},
url = {https://www.sciencedirect.com/science/article/pii/S0963869520303224},
author = {Chongsheng Cheng and Zhexiong Shang and Zhigang Shen},
keywords = {Concrete delamination, Thermography, Nondestructive evaluation, Deep learning, Encoder-decoder architecture, Semantic segmentation, UAV},
abstract = {Concrete deck delamination often demonstrates strong variations in size, shape, and temperature distribution under the influences of outdoor weather conditions. The strong variations create challenges for pure analytical solutions in infrared image segmentation of delaminated areas. The recently developed supervised deep learning approach demonstrated the potentials in achieving automatic segmentation of RGB images. However, its effectiveness in segmenting thermal images remains under-explored. The main challenge lies in the development of specific models and the generation of a large range of labeled infrared images for training. To address this challenge, a customized deep learning model based on encoder-decoder architecture is proposed to segment the delaminated areas in thermal images at the pixel level. Data augmentation strategies were implemented in creating the training data set to improve the performance of the proposed model. The deep learning generated model was deployed in a real-world project to further evaluate the model's applicability and robustness. The results of these experimental studies supported the effectiveness of the deep learning model in segmenting concrete delamination areas from infrared images. It also suggested that data augmentation is a helpful technique to address the small size issue of training samples. The field test with validation further demonstrated the generalizability of the proposed framework. Limitations of the proposed approach were also briefed at the end of the paper.}
}
@article{CASTELLANOS2021100390,
title = {Evaluation of flying caching servers in UAV-BS based realistic environment},
journal = {Vehicular Communications},
volume = {32},
pages = {100390},
year = {2021},
issn = {2214-2096},
doi = {https://doi.org/10.1016/j.vehcom.2021.100390},
url = {https://www.sciencedirect.com/science/article/pii/S2214209621000590},
author = {German Castellanos and Greta Vallero and Margot Deruyck and Luc Martens and Michela Meo and Wout Joseph},
keywords = {UAV-BS, Flying caching servers, Unmanned aerial vehicle networks, Multi-access edge caching, Backhaul, Radio access network},
abstract = {The dramatic growth of data traffic during the past decade has challenged wireless networks to provide new mechanisms to support such demand. Fast deployable wireless networks supported by Unmanned Aerial Vehicles (UAV) are a promising solution, especially to support in crowded scenarios with high peaks of traffic. Nevertheless, mounting a Base Station (BS) on UAVs (UAV-BSs) raises several challenges like the saturation of the backhaul (BH) link, needed for the communication between them and the Core Network (CN). In this work, this issue is addressed with the usage of the Multi-Access Edge Computing (MEC) technology, consisting on the placement of servers, providing computing platforms and storage, directly at the edge of these networks, e.g. on the UAV-BSs. In particular, we consider a portion of a Radio Access Network (RAN) composed by UAV-BSs, equipped with servers that provide the caching capability. The performance is evaluated, using realistic traffic demand, for different traffic characteristics, capacity of the cache server and users' density. Simulation results reveal that the usage of the MEC caching prevents the BH network saturation, since in case a requested content is locally cached, the BH network is not used. As consequences, the user coverage and the access capacity increase up to 33% and 70%, respectively and the experienced delay drops by 30%.}
}
@article{OSCO20211,
title = {A CNN approach to simultaneously count plants and detect plantation-rows from UAV imagery},
journal = {ISPRS Journal of Photogrammetry and Remote Sensing},
volume = {174},
pages = {1-17},
year = {2021},
issn = {0924-2716},
doi = {https://doi.org/10.1016/j.isprsjprs.2021.01.024},
url = {https://www.sciencedirect.com/science/article/pii/S0924271621000307},
author = {Lucas Prado Osco and Mauro {dos Santos de Arruda} and Diogo Nunes Gonçalves and Alexandre Dias and Juliana Batistoti and Mauricio {de Souza} and Felipe David Georges Gomes and Ana Paula Marques Ramos and Lúcio André {de Castro Jorge} and Veraldo Liesenberg and Jonathan Li and Lingfei Ma and José Marcato and Wesley Nunes Gonçalves},
keywords = {Deep learning, UAV imagery, Object detection, Remote sensing, Precision agriculture},
abstract = {Accurately mapping croplands is an important prerequisite for precision farming since it assists in field management, yield-prediction, and environmental management. Crops are sensitive to planting patterns and some have a limited capacity to compensate for gaps within a row. Optical imaging with sensors mounted on Unmanned Aerial Vehicles (UAV) is a cost-effective option for capturing images covering croplands nowadays. However, visual inspection of such images can be a challenging and biased task, specifically for detecting plants and rows on a one-step basis. Thus, developing an architecture capable of simultaneously extracting plant individually and plantation-rows from UAV-images is yet an important demand to support the management of agricultural systems. In this paper, we propose a novel deep learning method based on a Convolutional Neural Network (CNN) that simultaneously detects and geolocates plantation-rows while counting its plants considering highly-dense plantation configurations. The experimental setup was evaluated in (a) a cornfield (Zea mays L.) with different growth stages (i.e. recently planted and mature plants) and in a (b) Citrus orchard (Citrus Sinensis Pera). Both datasets characterize different plant density scenarios, in different locations, with different types of crops, and from different sensors and dates. This scheme was used to prove the robustness of the proposed approach, allowing a broader discussion of the method. A two-branch architecture was implemented in our CNN method, where the information obtained within the plantation-row is updated into the plant detection branch and retro-feed to the row branch; which are then refined by a Multi-Stage Refinement method. In the corn plantation datasets (with both growth phases – young and mature), our approach returned a mean absolute error (MAE) of 6.224 plants per image patch, a mean relative error (MRE) of 0.1038, precision and recall values of 0.856, and 0.905, respectively, and an F-measure equal to 0.876. These results were superior to the results from other deep networks (HRNet, Faster R-CNN, and RetinaNet) evaluated with the same task and dataset. For the plantation-row detection, our approach returned precision, recall, and F-measure scores of 0.913, 0.941, and 0.925, respectively. To test the robustness of our model with a different type of agriculture, we performed the same task in the citrus orchard dataset. It returned an MAE equal to 1.409 citrus-trees per patch, MRE of 0.0615, precision of 0.922, recall of 0.911, and F-measure of 0.965. For the citrus plantation-row detection, our approach resulted in precision, recall, and F-measure scores equal to 0.965, 0.970, and 0.964, respectively. The proposed method achieved state-of-the-art performance for counting and geolocating plants and plant-rows in UAV images from different types of crops. The method proposed here may be applied to future decision-making models and could contribute to the sustainable management of agricultural systems.}
}
@article{MAYRA2021112322,
title = {Tree species classification from airborne hyperspectral and LiDAR data using 3D convolutional neural networks},
journal = {Remote Sensing of Environment},
volume = {256},
pages = {112322},
year = {2021},
issn = {0034-4257},
doi = {https://doi.org/10.1016/j.rse.2021.112322},
url = {https://www.sciencedirect.com/science/article/pii/S0034425721000407},
author = {Janne Mäyrä and Sarita Keski-Saari and Sonja Kivinen and Topi Tanhuanpää and Pekka Hurskainen and Peter Kullberg and Laura Poikolainen and Arto Viinikka and Sakari Tuominen and Timo Kumpula and Petteri Vihervaara},
keywords = {Hyperspectral imaging, Deep learning, Convolutional neural network, Tree species classification},
abstract = {During the last two decades, forest monitoring and inventory systems have moved from field surveys to remote sensing-based methods. These methods tend to focus on economically significant components of forests, thus leaving out many factors vital for forest biodiversity, such as the occurrence of species with low economical but high ecological values. Airborne hyperspectral imagery has shown significant potential for tree species classification, but the most common analysis methods, such as random forest and support vector machines, require manual feature engineering in order to utilize both spatial and spectral features, whereas deep learning methods are able to extract these features from the raw data. Our research focused on the classification of the major tree species Scots pine, Norway spruce and birch, together with an ecologically valuable keystone species, European aspen, which has a sparse and scattered occurrence in boreal forests. We compared the performance of three-dimensional convolutional neural networks (3D-CNNs) with the support vector machine, random forest, gradient boosting machine and artificial neural network in individual tree species classification from hyperspectral data with high spatial and spectral resolution. We collected hyperspectral and LiDAR data along with extensive ground reference data measurements of tree species from the 83 km2 study area located in the southern boreal zone in Finland. A LiDAR-derived canopy height model was used to match ground reference data to aerial imagery. The best performing 3D-CNN, utilizing 4 m image patches, was able to achieve an F1-score of 0.91 for aspen, an overall F1-score of 0.86 and an overall accuracy of 87%, while the lowest performing 3D-CNN utilizing 10 m image patches achieved an F1-score of 0.83 and an accuracy of 85%. In comparison, the support-vector machine achieved an F1-score of 0.82 and an accuracy of 82.4% and the artificial neural network achieved an F1-score of 0.82 and an accuracy of 81.7%. Compared to the reference models, 3D-CNNs were more efficient in distinguishing coniferous species from each other, with a concurrent high accuracy for aspen classification. Deep neural networks, being black box models, hide the information about how they reach their decision. We used both occlusion and saliency maps to interpret our models. Finally, we used the best performing 3D-CNN to produce a wall-to-wall tree species map for the full study area that can later be used as a reference prediction in, for instance, tree species mapping from multispectral satellite images. The improved tree species classification demonstrated by our study can benefit both sustainable forestry and biodiversity conservation.}
}
@article{HENDRIA2021,
title = {Combining transformer and CNN for object detection in UAV imagery},
journal = {ICT Express},
year = {2021},
issn = {2405-9595},
doi = {https://doi.org/10.1016/j.icte.2021.12.006},
url = {https://www.sciencedirect.com/science/article/pii/S2405959521001715},
author = {Willy Fitra Hendria and Quang Thinh Phan and Fikriansyah Adzaka and Cheol Jeong},
keywords = {Convolutional neural network, Object detection, Transformer, UAV imagery},
abstract = {Combining multiple models is a well-known technique to improve predictive performance in challenging tasks such as object detection in UAV imagery. In this paper, we propose fusion of transformer-based and convolutional neural network-based (CNN) models with two approaches. First, we ensemble Swin Transformer and DetectoRS with ResNet backbone, and conduct performance comparison on four typical methods for combining predictions of multiple object detection models. Second, we design a hybrid architecture by combining Swin Transformer backbone with a neck of DetectoRS. We show that the fusion of the transformer and the CNN-based models performs better compared to the respective baseline model.}
}
@article{MARUTHI2020102651,
title = {Robust mixed source localization in WSN using swarm intelligence algorithms},
journal = {Digital Signal Processing},
volume = {98},
pages = {102651},
year = {2020},
issn = {1051-2004},
doi = {https://doi.org/10.1016/j.dsp.2019.102651},
url = {https://www.sciencedirect.com/science/article/pii/S1051200419302052},
author = {Shree Prasad Maruthi and Trilochan Panigrahi},
keywords = {Mixed source localization, Impulse noise, Swarm intelligence algorithm, LSTM-RNN, Bounded non-linear covariance function},
abstract = {Passive localization and classification algorithms for mixed near-field and far-field sources have mainly been investigated for antenna arrays with regular or symmetrical geometry. However, these algorithms may not be applicable to wireless sensor networks, where spatially distributed sensor nodes form an array of random geometry. This paper proposes squared error norm of residual fitting error matrix (SRFEM) cost function for mixed source localization, which does not place any constraint on the geometry of antenna array. The proposed cost function is optimized using computationally simple swarm intelligence (SI) algorithms. Convergence performance of three SI algorithms, i.e., particle swarm optimization, Whale optimization, and Grey Wolf optimization is investigated to obtain estimates of the source location parameters with a minimal number of iterations or computational complexity. In order to provide robustness for the SRFEM cost function, this paper proposes an impulse denoising technique based on the long-short term memory recurrent neural network (LSTM-RNN). Simulation results confirm that, in the presence of AWGN, the proposed SRFEM cost function outperforms existing techniques based on the uniform linear array and approaches the theoretical Cramer-Rao lower bound even for a fewer number of snapshots. Further, simulation analysis also reveals that LSTM-RNN provides better mixed localization performance under impulse noise as compared to the bounded noise covariance approach at high signal-to-noise values.}
}
@article{SONG2020105812,
title = {Identifying sunflower lodging based on image fusion and deep semantic segmentation with UAV remote sensing imaging},
journal = {Computers and Electronics in Agriculture},
volume = {179},
pages = {105812},
year = {2020},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2020.105812},
url = {https://www.sciencedirect.com/science/article/pii/S0168169920316938},
author = {Zhishuang Song and Zhitao Zhang and Shuqin Yang and Dianyuan Ding and Jifeng Ning},
keywords = {Sunflower lodging identification, Image fusion, Deep learning, Unmanned aerial vehicle remote sensing image},
abstract = {Sunflower lodging is a common agricultural disorder taking place in the middle and late sunflower growth periods. This disorder reduces the sunflower seed yield, damages the seed quality, and hence usually causes great losses in both crop quantity and quality. Sunflower lodging is mainly caused by extreme and destructive weather events, which have been recently occurring more frequently. This is why it is highly crucial to develop methods for fast and accurate identification of sunflower lodging. In this work, an efficient method for sunflower lodging identification is proposed based on image fusion and deep semantic segmentation of remote sensing images obtained from an unmanned aerial vehicle (UAV). First, the resolution of low-resolution multispectral images was enhanced through matching their features with those of high-resolution visible-range images. Then, for effective lodging assessment, high-quality multispectral images with rich spectral information and high spatial resolution were obtained through fusing the visible-range images and the enhanced multispectral ones. Subsequently, in order to refine the identification outcomes, a variant of the segmentation network (SegNet) deep architecture was developed for semantic segmentation. This variant has skip connections, separable convolution, and a conditional random field. Experimental evaluation shows that the fusion-based approaches clearly outperform the no-fusion ones in terms of the lodging identification accuracy for all compared architectures including support vector machine (SVM), fully convolutional network (FCN), SegNet, and the proposed SegNet variant. Meanwhile, the deep semantic segmentation methods consistently outperform the classical SVM one with hand-crafted features. As well, the improved SegNet method outperformed all of the compared methods and achieved the best accuracies of 84.4% and 89.8% without and with image fusion, respectively, on one test. The corresponding accuracies on another test set were 76.6% and 83.3%, respectively. Moreover, the proposed method can also identify the sunflower lodging and non-lodging patterns and separate them from the background. These capabilities are highly beneficial for lodging hazard assessment and sunflower harvest survey. Overall, the proposed method effectively exploited UAV remote sensing image data with fusion and deep semantic segmentation modules in order to provide a useful reference for sunflower lodging assessment and mapping.}
}
@article{ALMEIDA2021102525,
title = {Joint traffic-aware UAV placement and predictive routing for aerial networks},
journal = {Ad Hoc Networks},
volume = {118},
pages = {102525},
year = {2021},
issn = {1570-8705},
doi = {https://doi.org/10.1016/j.adhoc.2021.102525},
url = {https://www.sciencedirect.com/science/article/pii/S1570870521000779},
author = {Eduardo Nuno Almeida and André Coelho and José Ruela and Rui Campos and Manuel Ricardo},
keywords = {Aerial wireless networks, UAV placement, Predictive routing, Quality of Service (QoS)},
abstract = {Aerial networks, composed of Unmanned Aerial Vehicles (UAVs) acting as Wi-Fi access points or cellular base stations, are emerging as an interesting solution to provide on-demand wireless connectivity to users, when there is no network infrastructure available, or to enhance the network capacity. This article proposes a traffic-aware topology control solution for aerial networks that holistically combines the placement of UAVs with a predictive and centralized routing protocol. The synergy created by the combination of the UAV placement and routing solutions allows the aerial network to seamlessly update its topology according to the users’ traffic demand, whilst minimizing the disruption caused by the movement of the UAVs. As a result, the Quality of Service (QoS) provided to the users is improved. The components of the proposed solution are described and evaluated in this article by means of simulation and an experimental testbed. The results show that the QoS provided to the users is significantly improved when compared to the corresponding baseline solutions.}
}
@article{LEE2022104138,
title = {Bounding-box object augmentation with random transformations for automated defect detection in residential building façades},
journal = {Automation in Construction},
volume = {135},
pages = {104138},
year = {2022},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2022.104138},
url = {https://www.sciencedirect.com/science/article/pii/S0926580522000115},
author = {Kisu Lee and Sanghyo Lee and Ha Young Kim},
keywords = {Data augmentation, Multi-class defect detection, Bounding box, Efficient maintenance strategy, Residential building façade, Unmanned aerial vehicles},
abstract = {This study proposes a novel bounding-box object augmentation (BoxAug) method to improve the performance of deep learning models in detecting defects in residential building façades. The most significant characteristic of the method is that it augments objects in images, rather than augmenting images, to solve the data imbalance problem. Moreover, it employs the bounding-box form for object detection, instead of the segmentation mask form. To evaluate the method, 7635 images obtained using unmanned aerial vehicles were utilized as the original training dataset. The faster region-based convolutional neural network model trained with the augmented training dataset using the method exhibited better performance than the model trained with the original dataset. Particularly, the class with the least objects in the original dataset displayed a markedly improved performance. Thus, the method can serve as an auxiliary method for effectively augmenting real-world image datasets with an unbalanced number of objects.}
}
@article{DIJKSTRA2021490,
title = {CentroidNetV2: A hybrid deep neural network for small-object segmentation and counting},
journal = {Neurocomputing},
volume = {423},
pages = {490-505},
year = {2021},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2020.10.075},
url = {https://www.sciencedirect.com/science/article/pii/S0925231220316647},
author = {Klaas Dijkstra and Jaap {van de Loosdrecht} and Waatze A. Atsma and Lambert R.B. Schomaker and Marco A. Wiering},
keywords = {Deep Learning, Computer Vision, Convolutional Neural Networks, Object Detection, Instance Segmentation},
abstract = {This paper presents CentroidNetV2, a novel hybrid Convolutional Neural Network (CNN) that has been specifically designed to segment and count many small and connected object instances. This complete redesign of the original CentroidNet uses a CNN backbone to regress a field of centroid-voting vectors and border-voting vectors. The segmentation masks of the individual object instances are produced by decoding centroid votes and border votes. A loss function that combines cross-entropy loss and Euclidean-distance loss achieves high quality centroids and borders of object instances. Several backbones and loss functions are tested on three different datasets ranging from precision agriculture to microbiology and pathology. CentroidNetV2 is compared to the state-of-the art networks You Only Look Once Version 3 (YOLOv3) and Mask Recurrent Convolutional Neural Network (MRCNN). On two out of three datasets CentroidNetV2 achieves the highest F1 score and on all three datasets CentroidNetV2 achieves the highest recall. CentroidNetV2 demonstrates the best ability to detect small objects although the best segmentation masks for larger objects are produced by MRCNN.}
}
@article{GISMONDI2021,
title = {A solution to the path planning problem via algebraic geometry and reinforcement learning},
journal = {Journal of the Franklin Institute},
year = {2021},
issn = {0016-0032},
doi = {https://doi.org/10.1016/j.jfranklin.2021.12.003},
url = {https://www.sciencedirect.com/science/article/pii/S0016003221007092},
author = {Francesco Gismondi and Corrado Possieri and Antonio Tornambe},
abstract = {In this paper, the path planning problem for an unicycle-like mobile robot is considered. By using some results borrowed from algebraic geometry, a technique is given to determine a dynamical system that is affine in the input and whose trajectories tend to a chosen algebraic set independently of the control input. Since this does not guarantee that the corresponding paths of motion are collision free, an optimal control problem is formulated to enforce this behavior, and its approximate solution is determined via integral reinforcement learning. Finally, it is shown how such results can be used to derive a feedback control law for unicycle-like mobile robots.}
}
@article{JIANG2020105824,
title = {Image recognition of four rice leaf diseases based on deep learning and support vector machine},
journal = {Computers and Electronics in Agriculture},
volume = {179},
pages = {105824},
year = {2020},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2020.105824},
url = {https://www.sciencedirect.com/science/article/pii/S016816992030795X},
author = {Feng Jiang and Yang Lu and Yu Chen and Di Cai and Gongfa Li},
keywords = {Identification of rice leaf diseases, Deep learning, Convolutional neural network, Support vector machine},
abstract = {In the field of agricultural information, identification and prediction of rice leaf diseases has always been a research focus. Deep learning and support vector machine (SVM) technology are hot research topics in the field of pattern recognition at present. Their combination can not only solve the problem effectively, but also improve the recognition accuracy. In this study, firstly, we use convolution neural networks (CNNs) to extract the rice leaf disease images features. Then the SVM method is applied to classify and predict the specific disease. The optimal parameters of SVM model are obtained through the 10-fold cross validation method. The experimental results show that when the penalty parameter C=1 and the kernel parameter g = 50, the average correct recognition rate of the rice disease recognition model based on deep learning and SVM is 96.8%. This accuracy is higher than that of the traditional back propagation neural networks models. This study provides a new method for the further research of crop diseases diagnosis by using deep learning.}
}
@article{GU2021107212,
title = {An enhanced UAV safety control scheme against attacks on desired trajectory},
journal = {Aerospace Science and Technology},
volume = {119},
pages = {107212},
year = {2021},
issn = {1270-9638},
doi = {https://doi.org/10.1016/j.ast.2021.107212},
url = {https://www.sciencedirect.com/science/article/pii/S1270963821007227},
author = {Yapei Gu and Kexin Guo and Lei Guo and Jianzhong Qiao and Jindou Jia and Xiang Yu and Lihua Xie},
keywords = {Unmanned aerial vehicles, Safety control, Desired trajectory attacks, Attack detection, Attack compensation},
abstract = {The detection and compensation of attacks are crucial for UAV safety. This paper focuses on the case where the desired trajectory sent by ground control station (GCS) is attacked. Based on the analysis of the attack transmission mechanism, an integrated scheme of attack detection and compensation is presented. The attack detection mechanism is established based on the trajectory tracking error and state estimation error. In addition, the proposed scheme can not only detect attacks but also distinguish attacks from unknown abrupt disturbances. In the proposed scheme, attack observer (AO) and learning observer (LO) are developed to address the coupling problem of additive and multiplicative attacks. Finally, the effectiveness of the proposed scheme is validated by both simulation and experimental tests.}
}
@article{ABDULRIDHA2020135,
title = {Detecting powdery mildew disease in squash at different stages using UAV-based hyperspectral imaging and artificial intelligence},
journal = {Biosystems Engineering},
volume = {197},
pages = {135-148},
year = {2020},
issn = {1537-5110},
doi = {https://doi.org/10.1016/j.biosystemseng.2020.07.001},
url = {https://www.sciencedirect.com/science/article/pii/S1537511020301926},
author = {Jaafar Abdulridha and Yiannis Ampatzidis and Pamela Roberts and Sri Charan Kakarla},
keywords = {Disease detection, Vegetation indices, Remote sensing, Machine learning},
abstract = {In this study hyperspectral imaging (380–1020 nm) and machine learning were utilised to develop a technique for detecting different disease development stages (asymptomatic, early, intermediate, and late disease stage) of powdery mildew (PM) in squash. Data were collected in the laboratory as well as in the field using an unmanned aerial vehicle (UAV). Radial basis function (RBF) was used to discriminate between healthy and diseased plants, and to classify the severity level (disease stage) of a plant; the most significant bands to differentiate between healthy and different stages of disease development were selected (388 nm, 591 nm, 646 nm, 975 nm, and 1012 nm). Furthermore, 29 spectral vegetation indices (VIs) were tested and evaluated for their ability to detect and classify healthy and PM-infected plants; the M value was used to evaluate the VIs. The water index (WI) and the photochemical reflectance index (PRI) were able to accurately detect and classify PM in asymptomatic, early, and late development stages under laboratory conditions. Under field conditions (UAV-based), the spectral ratio of 761 (SR761) accurately detected PM in early stages, and the chlorophyll index green (CI green), the normalised difference of 750/705 (ND 750/705), the green normalised difference vegetation index (GNDVI), and the spectral ratio of 850 (SR850) in late stages. The classification results, by using RBF, in laboratory conditions for the asymptomatic and late stage was 82% and 99% respectively, while in field conditions it was 89% and 96% in early and late disease development stages, respectively.}
}
@article{ZHOU2021,
title = {Robust trajectory planning for UAV communication systems in the presence of jammers},
journal = {Chinese Journal of Aeronautics},
year = {2021},
issn = {1000-9361},
doi = {https://doi.org/10.1016/j.cja.2021.10.038},
url = {https://www.sciencedirect.com/science/article/pii/S1000936121004258},
author = {Lingyun ZHOU and Xiaotong ZHAO and Xin GUAN and Enbin SONG and Xin ZENG and Qingjiang SHI},
keywords = {6G, UAV communications, Jamming resistance, Trajectory optimization, Robust design, Non-convex optimization},
abstract = {Unmanned Aerial Vehicle (UAV) has emerged as a promising novel application for the Sixth-generation (6G) wireless communication by leveraging more favorable Line-of-sight (LoS) propagation. However, the jamming resistance by exploiting UAV’s mobility is a new challenge in the UAV-ground communication. This paper investigates the trajectory planning problem in an UAV communication system, where the UAV is operated by a Ground Control Unit (GCU) to perform certain tasks in the presence of multiple jammers with imperfect power and location information. To ensure the reliability of the GCU-to-UAV link, we formulate the problem as a non-convex semi-infinite optimization, aiming to maximize the average worst-case Signal-to-Interference-plus-Noise Ratio (SINR) over a given flight duration by designing the robust trajectory of the UAV under stringent energy availability constraints. To handle this problem efficiently, we develop an iterative algorithm for the solution with the aid of S-procedure and Successive Convex Approximation (SCA) method. Numerous results demonstrate the efficacy of our proposed algorithm and offer some useful designinsights to practical system.}
}
@article{PENG2021123896,
title = {A UAV-based machine vision method for bridge crack recognition and width quantification through hybrid feature learning},
journal = {Construction and Building Materials},
volume = {299},
pages = {123896},
year = {2021},
issn = {0950-0618},
doi = {https://doi.org/10.1016/j.conbuildmat.2021.123896},
url = {https://www.sciencedirect.com/science/article/pii/S0950061821016561},
author = {Xiong Peng and Xingu Zhong and Chao Zhao and Anhua Chen and Tianyu Zhang},
keywords = {Bridge crack, Unmanned Aerial Vehicle, Machine vision, Crack width recognition, Hybrid feature learning},
abstract = {Bridge crack width is an important indicator to assess and evaluate the health condition of the bridge. In this paper, we have proposed a UAV-based machine vision method for bridge crack recognition and width quantification through hybrid feature learning. Firstly, we have configured a UAV system that can obtain bridge crack image (effective pixel 7952x5304) and GPS position, calculate image resolution, and correct measured plane simultaneously. Then, the crack recognition method combining the R-FCN network and Haar-AdaBoost suited for UAV imagery recognition is proposed, which can make full use of advanced features, shape features and gray features of bridge cracks. The time cost of our method is about 0.2 s for crack detection per one 7952 × 5304 pixels images and 4.5 s in pixel-level segmentation per one 1000 × 1000 pixels bounding box. Additionally, the real bridge crack widths are calculated and quantified by the ranging method using corresponding object distance data. Finally, a case study of the Xiangjiang-River bridge inspection is carried out to demonstrate the effectiveness of the proposed method, achieving above 90% precision in the real bridge crack width quantification.}
}
@article{AMPATZIDIS2020105457,
title = {Agroview: Cloud-based application to process, analyze and visualize UAV-collected data for precision agriculture applications utilizing artificial intelligence},
journal = {Computers and Electronics in Agriculture},
volume = {174},
pages = {105457},
year = {2020},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2020.105457},
url = {https://www.sciencedirect.com/science/article/pii/S0168169920304695},
author = {Yiannis Ampatzidis and Victor Partel and Lucas Costa},
keywords = {UAVs, Artificial intelligence, Machine learning, Smart agriculture, Precision agriculture, Neural networks, Cloud computing},
abstract = {Traditional sensing technologies in specialty crops production, for pest and disease detection and field phenotyping, rely on manual sampling and are time consuming and labor intensive. Since availability of personnel trained for field scouting is a major problem, small Unmanned Aerial Vehicles (UAVs) equipped with various sensors can simplify the surveying procedure, decrease data collection time, and reduce cost. To accurate and rapidly process, analyze and visualize data collected from UAVs and other platforms (e.g. small airplanes, satellites, ground platforms), a cloud and artificial intelligence (AI) based application (named Agroview) was developed. This interactive and user-friendly application can: (i) detect, count and geo-locate plants and plant gaps (locations with dead or no plants); (ii) measure plant height and canopy size (plant inventory); (iii) develop plant health (or stress) maps. In this study, the use of this Agroview application to evaluate phenotypic characteristics of citrus trees (as a case study) is presented. It was found, that this emerging technology detected citrus trees with mean absolute percentage error (MAPE) of 2.3% in a commercial citrus orchard with 175,977 trees (1,871 acres; 39 normal and high-density spacing blocks). Furthermore, it accurately estimated tree height with 4.5% and 12.93% MAPE for normal and high-density spacing respectively, and canopy size with MAPE of 12.9% and 34.6% for normal and high-density spacing respectively. It provides a consistent, more direct, cost-effective and rapid method for field survey and plant phenotyping.}
}
@article{WOO2020107001,
title = {Collision avoidance for an unmanned surface vehicle using deep reinforcement learning},
journal = {Ocean Engineering},
volume = {199},
pages = {107001},
year = {2020},
issn = {0029-8018},
doi = {https://doi.org/10.1016/j.oceaneng.2020.107001},
url = {https://www.sciencedirect.com/science/article/pii/S0029801820300792},
author = {Joohyun Woo and Nakwan Kim},
keywords = {Deep reinforcement learning, Collision avoidance, Unmanned surface vehicle, COLREGs, Artificial intelligence},
abstract = {In this paper, a deep reinforcement learning (DRL)-based collision avoidance method is proposed for an unmanned surface vehicle (USV). This approach is applicable to the decision-making stage of collision avoidance, which determines whether the avoidance is necessary, and if so, determines the direction of the avoidance maneuver. To utilize the visual recognition capability of deep neural networks as a tool for analyzing the complex and ambiguous situations that are typically encountered, a grid map representation of the ship encounter situation was suggested. For the composition of the DRL network, we proposed a neural network architecture and semi-Markov decision process model that was specially designed for the USV collision avoidance problem. The proposed DRL network was trained through repeated simulations of collision avoidance. After the training process, the DRL network was implemented in collision avoidance experiments and simulations to evaluate its situation recognition and collision avoidance capability.}
}
@article{ADHYA2022100582,
title = {Performance assessment of selective machine learning techniques for improved PV array fault diagnosis},
journal = {Sustainable Energy, Grids and Networks},
volume = {29},
pages = {100582},
year = {2022},
issn = {2352-4677},
doi = {https://doi.org/10.1016/j.segan.2021.100582},
url = {https://www.sciencedirect.com/science/article/pii/S2352467721001454},
author = {Dhritiman Adhya and Soumesh Chatterjee and Ajoy Kumar Chakraborty},
keywords = {PV arrays, Machine learning, Fault diagnosis and classification, XGBoost, CatBoost, Light gradient boosting machine},
abstract = {Solar photovoltaics (SPV) are susceptible to various kinds of faults which can diminish overall performance of the system. Proper fault diagnosis strategy needs to be developed to accurately identify the faults for smooth operation of the photovoltaic (PV) systems. Machine learning (ML) can be used to diagnose the faults in PV arrays. In this paper, three powerful machine learning algorithms i.e., categorical boosting (CatBoost), light gradient boosting method (LGBM), and extreme gradient boosting (XGBoost) have been selected for investigating their efficacy to diagnose different PV array faults. A PV system has been designed in MATLAB/Simulink environment using real time irradiance and temperature data acquired from grid connected PV System of National Institute of Technology Agartala. The constructed dataset is used to extract features including one new index to train these algorithms in Python 3.7. Promising results have been achieved using these algorithms as average detection and classification accuracy of 99.996% and 99.745% has been noted by implementing LGBM, followed by CatBoost, and XGBoost respectively. Moreover, these algorithms reduce the computational time significantly with LGBM leading the chart with training time of 0.053 and 0.375 s for fault detection and classification. These algorithms have been compared with random forest (RF) technique to exhibit their proficiency in fault diagnosis of PV arrays.}
}
@article{WANG2021119739,
title = {Hyperspectral monitor of soil chromium contaminant based on deep learning network model in the Eastern Junggar coalfield},
journal = {Spectrochimica Acta Part A: Molecular and Biomolecular Spectroscopy},
volume = {257},
pages = {119739},
year = {2021},
issn = {1386-1425},
doi = {https://doi.org/10.1016/j.saa.2021.119739},
url = {https://www.sciencedirect.com/science/article/pii/S1386142521003152},
author = {Yuan Wang and Hongbing Ma and Jingzhe Wang and Li Liu and Matti Pietikäinen and Zipeng Zhang and Xiangyue Chen},
keywords = {Soil hyperspectrum, Soil heavy metal pollution, Data enhancement (DA), Support vector machine (SVM), k-nearest neighbour (KNN), Deep neural network (DNN)},
abstract = {In China, over 10% of cultivated land is polluted by heavy metals, which can affect crop growth, food safety and human health. Therefore, how to effectively and quickly detect soil heavy metal pollution has become a critical issue. This study provides a novel data preprocessing method that can extract vital information from soil hyperspectra and uses different classification algorithms to detect levels of heavy metal contamination in soil. In this experiment, 160 soil samples from the Eastern Junggar Coalfield in Xinjiang were employed for verification, including 143 noncontaminated samples and 17 contaminated soil samples. Because the concentration of chromium in the soil exists in trace amounts, combined with the fact that spectral characteristics are easily influenced by other types of impurity in the soil, the evaluation of chromium concentrations in the soil through hyperspectral analysis is not satisfactory. To avoid this phenomenon, the pretreatment method of this experiment includes a combination of second derivative and data enhancement (DA) approaches. Then, support vector machine (SVM), k-nearest neighbour (KNN) and deep neural network (DNN) algorithms are used to create the discriminant models. The accuracies of the DA-SVM, DA-KNN and DA-DNN models were 95.61%, 95.62% and 96.25%, respectively. The results of this experiment demonstrate that soil hyperspectral technology combined with deep learning can be used to instantly monitor soil chromium pollution levels on a large scale. This research can be used for the management of polluted areas and agricultural insurance applications.}
}
@article{ZHANG2022275,
title = {Multi-agent reinforcement learning by the actor-critic model with an attention interface},
journal = {Neurocomputing},
volume = {471},
pages = {275-284},
year = {2022},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2021.06.049},
url = {https://www.sciencedirect.com/science/article/pii/S0925231221009735},
author = {Lixiang Zhang and Jingchen Li and Yi'an Zhu and Haobin Shi and Kao-Shing Hwang},
keywords = {Multi-agent reinforcement learning, Multi-agent system, Actor-critic, Attention mechanism, Mean-field theory},
abstract = {Multi-agent reinforcement learning algorithms have achieved satisfactory performances in various scenarios, but many of them encounter difficulties in partially observable environments. In partially observable environments, the inability to perceive environment states results in unsteadiness and misconvergence, especially in large-scale multi-agent environments. To improve interactions among homogeneous agents in a partially observable environment, we propose a novel multi-agent actor-critic model with a visual attention interface to solve this problem. First, a recurrent visual attention interface is used to extract a latent state from each agent’s partial observation. These latent states allow agents to focus on several local environments, in which each agent has a complete perception of a local environment and the intricate multi-agent environment is teased out by the interaction among several agents in the same local environment. The proposed method trains multi-agent systems with a centralized training and decentralized execution mechanism. The joint action of agents is approximated by the mean-field theory because the number of agents in a local environment is uncertain. Experimental results on the simulation platform suggest that our model performs better when training large-scale multi-agent systems in partially observable environments than baselines.}
}
@article{EMILIEN2021100019,
title = {UAV & satellite synergies for optical remote sensing applications: A literature review},
journal = {Science of Remote Sensing},
volume = {3},
pages = {100019},
year = {2021},
issn = {2666-0172},
doi = {https://doi.org/10.1016/j.srs.2021.100019},
url = {https://www.sciencedirect.com/science/article/pii/S2666017221000067},
author = {Alvarez-Vanhard Emilien and Corpetti Thomas and Houet Thomas},
keywords = {Drone, Spaceborne, Sensor synergy, Multiscale, Calibration, Fusion},
abstract = {Unmanned aerial vehicles (UAVs) and satellite constellations are both essential Earth Observation (EO) systems for monitoring land surface dynamics. The former is frequently used for its acquisition flexibility and its ability to supply imagery with very high spatial resolution (VHSR); the latter is interesting for supplying time-series data over large areas. However, each of these data sources is generally used separately even though they are complementary and have strong and promising potential synergies. Data fusion is a well-known technique to exploit this multi-source synergy, but in practice, UAV and satellite synergies are more specific, less well known and need to be formalized. In this article, we review remote sensing studies that addressed both data sources. Current approaches were categorized to distinguish four strategies: “data comparison”, “multiscale explanation”, “model calibration” and “data fusion”. Analysis of the literature revealed emerging trends, the supply of these distinct strategies for several applications and allowed to identify key contributions of UAV data. Finally, the high potential of this synergy seems currently under-exploited; therefore a discussion is proposed about the related implications for data interoperability, machine learning and data sharing to reinforce synergies between UAVs and satellites.}
}
@article{FANG2021125734,
title = {Predicting flood susceptibility using LSTM neural networks},
journal = {Journal of Hydrology},
volume = {594},
pages = {125734},
year = {2021},
issn = {0022-1694},
doi = {https://doi.org/10.1016/j.jhydrol.2020.125734},
url = {https://www.sciencedirect.com/science/article/pii/S0022169420311951},
author = {Zhice Fang and Yi Wang and Ling Peng and Haoyuan Hong},
keywords = {Flood susceptibility prediction, Long short-term memory neural network, Deep learning, Feature engineering},
abstract = {Identifying floods and producing flood susceptibility maps are crucial steps for decision-makers to prevent and manage disasters. Plenty of studies have used machine learning models to produce reliable susceptibility maps. Nevertheless, most research ignores the importance of developing appropriate feature engineering methods. In this study, we propose a local spatial sequential long short-term memory neural network (LSS-LSTM) for flood susceptibility prediction in Shangyou County, China. The three main contributions of this study are summarized below. First of all, it is a new perspective to use the deep learning technique of LSTM for flood susceptibility prediction. Second, we integrate an appropriate feature engineering method with LSTM to predict flood susceptibility. Third, we implement two optimization techniques of data augmentation and batch normalization to further improve the performance of the proposed method. The LSS-LSTM method can not only capture the attribution information of flood conditioning factors and the local spatial information of flood data, but also has powerful sequential modelling capabilities to deal with the spatial relationship of floods. The experimental results demonstrate that the LSS-LSTM method achieves satisfactory prediction performance (93.75% and 0.965) in terms of accuracy and area under the receiver operating characteristic (ROC) curve.}
}
@article{ZHANG2022106586,
title = {Real-time strawberry detection using deep neural networks on embedded system (rtsd-net): An edge AI application},
journal = {Computers and Electronics in Agriculture},
volume = {192},
pages = {106586},
year = {2022},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2021.106586},
url = {https://www.sciencedirect.com/science/article/pii/S0168169921006037},
author = {Yanchao Zhang and Jiya Yu and Yang Chen and Wen Yang and Wenbo Zhang and Yong He},
keywords = {YOLO, Object detection, Deep learning, Edge computing},
abstract = {Computer vision is a key technique to make agricultural machinery smart. Deep neural network has achieved great success in computer vision. How to use it at a small size, low cost, low power consumption device with high accuracy and speed on strawberry harvesting machinery has drawn much research attention. Since the infield situation has reduced number of objects and that they are easier to be distinguished from the background compared to other computer vision datasets, the huge neural network structure can be simplified in order to speed up the detection inference without penalizing the detection accuracy. In this research, a new deep neural network called RTSD-Net is proposed based on stat-of-art light-weighted YOLOv4-tiny with reduced layers and modified structure for real-time strawberry detection under infield condition. The original CSPNet was replaced by 2 types of CSPNet designed with reduced parameters and a simplified structure and 4 new network structures are designed by combining these 2 types. The performances of the 4 networks were evaluated. It was observed that the number of parameters of these 4 networks and the detection speed of the model is negatively correlated. Simplified structure and reduced parameters can contribute to faster operational speed. The last one was selected and named as RTSD-Net. Comparing with YOLOv4 tiny, the accuracy of RTSD-Net is only reduced by 0.62% but the speed is increased by 25FPS, which is 25.93% higher than that of YOLOv4-tiny. Embedded system Jetson Nano was selected as the evaluation platform to evaluate the RTSD-Net’s performance for edge computing. The original Open Neural Network Exchange (ONNX) model was loaded on Jetson Nano and the speed of RTSD-Net was 13.1FPS, which is 19.0% higher than that of YOLOv4-tiny. After speeded up by TensorRT method, the transformed model reached 25.20fps, which is twice as fast as the ONNX model, and 15% faster than the YOLOv4-tiny model. After speeding up, the efficiency of RTSD-Net is enough for computer vision based strawberry detection and harvesting. In summary, the proposed RTSD-Net has good potential in smart strawberry harvesting machinery and the idea of redesigning neural structure and reducing parameters to speed up the detection rate of deep neural network is expected to have good application in edge computing.}
}
@article{KALKE2018225,
title = {Support vector machine learning applied to digital images of river ice conditions},
journal = {Cold Regions Science and Technology},
volume = {155},
pages = {225-236},
year = {2018},
issn = {0165-232X},
doi = {https://doi.org/10.1016/j.coldregions.2018.08.014},
url = {https://www.sciencedirect.com/science/article/pii/S0165232X17304251},
author = {H. Kalke and M. Loewen},
abstract = {In this study the use of support vector machines (SVM), a popular type of machine learning algorithm, for monitoring river ice properties during freeze-up was investigated. The goal was to develop an automated image processing method that could be used to accurately compute the total surface ice concentration and also discriminate between frazil and released floating anchor ice pans. Total surface ice concentration has previously been computed from digital images of surface ice conditions using the most common image segmentation method, thresholding. However, thresholding techniques often produce inaccurate results or if performed manually can be highly subjective and labour intensive. Three site specific SVM models were trained in this study to accurately distinguish between surface ice and water, and produce binary images from which the total surface ice concentration could be computed. The digital images of river ice conditions were acquired using bridge-mounted game cameras and an unmanned aerial vehicle on two Alberta rivers. The total surface ice concentrations computed from the SVM generated binary images were significantly more accurate than concentrations computed using four thresholding methods. The trained SVM models were then used to compute spatial distributions of surface ice concentration across the two rivers from the UAV images. In addition, time-series of surface ice concentrations during freeze-up were also computed from the bridge-mounted game camera images. Site specific SVM models for estimating surface ice concentration were shown to be a feasible and accurate tool for river ice monitoring that could potentially aid in the validation of numerical models and improve understanding of river freeze-up processes. An SVM to separate total surface ice into frazil and anchor ice components was also trained and validated. This model produced mixed results when tested on images from two anchor ice release events and additional research is needed to more fully assess its potential.}
}
@article{CHEN2021106552,
title = {Mapping agricultural plastic greenhouses using Google Earth images and deep learning},
journal = {Computers and Electronics in Agriculture},
volume = {191},
pages = {106552},
year = {2021},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2021.106552},
url = {https://www.sciencedirect.com/science/article/pii/S016816992100569X},
author = {Wei Chen and Yameng Xu and Zhe Zhang and Lan Yang and Xubin Pan and Zhe Jia},
keywords = {Facility agriculture, Remote sensing, Deep learning, High-resolution images},
abstract = {The worldwide use of agricultural plastic greenhouses (APGs) is crucial to provide sufficient food, including vegetables and fruits, for residents. However, the pollution problem created by plastic materials has also aroused widespread concern. Therefore, it is important to obtain the spatial distribution of APGs via different approaches, especially using remote sensing images. In this study, a deep learning method is adopted to map the distribution of APGs in Shouguang, Shandong Province, China, with high-resolution Google Earth images. The results suggest that the distribution of greenhouses can be accurately extracted with a mean intersection over union (mIOU) of 97.20%. The total area covered by APGs is 185.37 km2, and the total number of APGs is approximately 170,807. Both densely and sparsely distributed APGs can be extracted effectively. This research shows that the deep learning method can extract greenhouse information quickly and effectively from high-resolution images and can be used in agricultural pollution monitoring and agricultural development planning.}
}
@article{SHIHAVUDDIN20214566,
title = {Image based surface damage detection of renewable energy installations using a unified deep learning approach},
journal = {Energy Reports},
volume = {7},
pages = {4566-4576},
year = {2021},
issn = {2352-4847},
doi = {https://doi.org/10.1016/j.egyr.2021.07.045},
url = {https://www.sciencedirect.com/science/article/pii/S2352484721005102},
author = {ASM Shihavuddin and Mohammad Rifat Ahmmad Rashid and Md Hasan Maruf and Muhammad Abul Hasan and Mohammad Asif ul Haq and Ratil H. Ashique and Ahmed Al Mansur},
keywords = {PV panel, Wind turbine, Structural health monitoring, Deep learning, Damage detection, Drone inspection},
abstract = {Smart Grid technology as a platform can encompass several advanced technological features across the spectrum of the power system. Smart Grid may introduce an early warning system for structural damage on the surface of large-scale power utility facilities providing crucial information to maintain the safety of the plant. To achieve such a cost-effective structural health monitoring system, a holistic smart inspection implementation framework is required. Using recently available sophisticated inspection technologies, high-resolution images covering the structural condition of large infrastructure can be routinely acquired as a remote monitoring process. Automated analysis of these inspection images can significantly reduce the inspection cost, provide an effective detection mechanism, and shorten reporting time, as a result, reducing overall maintenance costs, and improving safety measures. In this work, we have applied state of art deep learning based inspection image analysis methods for surface damage detection of various renewable energy power plants with a single unified model. We have achieved the state-of-the-art accuracy of 0.79 mean average precision on average even where input images are of varied modalities: from thermal images to visual images, from high- to low-resolution images, and from PV panels to wind turbines. All variations have been tackled with one single deep learning model to detect surface damages. Our results demonstrate the promise of effectively deploying a single trained model to inspect a wide range of energy installations while reducing the monitoring cost significantly. In addition, this work also published the reported dataset comprising four specific image sets for the research community.}
}
@article{DOU2020137320,
title = {Different sampling strategies for predicting landslide susceptibilities are deemed less consequential with deep learning},
journal = {Science of The Total Environment},
volume = {720},
pages = {137320},
year = {2020},
issn = {0048-9697},
doi = {https://doi.org/10.1016/j.scitotenv.2020.137320},
url = {https://www.sciencedirect.com/science/article/pii/S0048969720308305},
author = {Jie Dou and Ali P. Yunus and Abdelaziz Merghadi and Ataollah Shirzadi and Hoang Nguyen and Yawar Hussain and Ram Avtar and Yulong Chen and Binh Thai Pham and Hiromitsu Yamagishi},
keywords = {Susceptibility, Landslide sampling strategies, Deep learning, Lidar DEM, M6.6 Hokkaido earthquake},
abstract = {Predictive capability of landslide susceptibilities is assumed to be varied with different sampling techniques, such as (a) the landslide scarp centroid, (b) centroid of landslide body, (c) samples of the scrap region representing the scarp polygon, and (d) samples of the landslide body representing the entire landslide body. However, new advancements in statistical and machine learning algorithms continuously being updated the landslide susceptibility paradigm. This paper explores the predictive performance power of different sampling techniques in landslide susceptibility mapping in the wake of increased usage of artificial intelligence. We used logistic regression (LR), neural network (NNET), and deep learning neural network (DNN) model for testing and validation of the models. The tests were applied to the 2018 Hokkaido Earthquake affected areas using a set of 11 predictor variables (seismic, topographic, and hydrological). We found that the prediction rates are inconsequential with the DNN model irrespective of the sampling technique (AUC: 0.904 – 0.919). Whereas, testing with LR (AUC: 0.825 – 0.785) and NNET (AUC: 0.882 – 0.858) produces larger differences in the accuracies between the four datasets. Nonetheless, the highest success rates were obtained for samples within the landslide scarp area. The analogy was then validated with a published landslide inventory from the 2015 Gorkha earthquake. We, therefore, suggest that DNN models as an appropriate technique to increase the predictive performance of landslide susceptibilities if the landslide scarp and body are not characterized properly in an inventory.}
}
@article{AMPATZIDIS2019104900,
title = {Citrus rootstock evaluation utilizing UAV-based remote sensing and artificial intelligence},
journal = {Computers and Electronics in Agriculture},
volume = {164},
pages = {104900},
year = {2019},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2019.104900},
url = {https://www.sciencedirect.com/science/article/pii/S0168169919311123},
author = {Yiannis Ampatzidis and Victor Partel and Bo Meyering and Ute Albrecht},
keywords = {UAV, Machine learning, Smart agriculture, Precision agriculture, Neural networks, Deep learning, Rootstock, Citrus},
abstract = {The implementation of breeding methods requires the creation of a large and genetically diverse training population. Large-scale experiments are needed for the rapid acquisition of phenotypic data to explore the correlation between genomic and phenotypic information. Traditional sensing technologies for field surveys and field phenotyping rely on manual sampling and are time consuming and labor intensive. Since availability of personnel trained for phenotyping is a major problem, small UAVs (unmanned aerial vehicles) equipped with various sensors can simplify the surveying procedure, decrease data collection time, and reduce cost. In this study, we evaluated the phenotypic characteristics of sweet orange trees grafted on 25 rootstock cultivars with different influences on plant growth and productivity utilizing a UAV-based high throughput phenotyping system. Data collected by UAV were compared with data collected manually according to standard horticultural procedures. The UAV-based technique was able to detect and count citrus trees with high precision (99.9%) in an orchard of 4931 trees and estimate tree canopy size with a high correlation (R = 0.84) with the manual collected data. No correlation of UAV-based data and manually collected data was observed for yield. The reason for the observed deviation is the influence of different rootstock cultivars on yield efficiency. Despite the low vigor-inducing effect of some rootstocks, they are highly productive, whilst others are high in vigor but produce less fruit. Our study demonstrates the high accuracy of the UAV technique to assess tree size. When using these techniques, it is essential to recognize the limitations imposed by the biological system.}
}
@article{TESKE2019226,
title = {Optimised dispensing of predatory mites by multirotor UAVs in wind: A distribution pattern modelling approach for precision pest management},
journal = {Biosystems Engineering},
volume = {187},
pages = {226-238},
year = {2019},
issn = {1537-5110},
doi = {https://doi.org/10.1016/j.biosystemseng.2019.09.009},
url = {https://www.sciencedirect.com/science/article/pii/S1537511019308311},
author = {April L. Teske and Gang Chen and Christian Nansen and Zhaodan Kong},
keywords = {Unmanned aerial vehicle, Precision pest management, Machine learning, Natural enemies, Precision agriculture, Predatory mites},
abstract = {Multirotor unmanned aerial vehicles (UAVs), or drones, are increasingly being used to spray liquid pesticides to control emerging pest infestations in field crops. In recent years, UAVs have been used to release predatory mites and other natural enemies to optimise and promote sustainable pest management practices by relying less on conventional insecticides. Drone dispensed samples of predatory mites are typically mixed with a granular material, vermiculite, which serves as a filler. The low density of the vermiculite and weather conditions (mainly wind), influences the distribution pattern of predatory mites when delivered by a UAV-based system. The purpose of this paper is to present a data-driven methodology to develop a mathematical model that can be used to optimise UAV-based autonomous dispensing of predatory mites. The model characterises the distribution of vermiculite as a function of wind speed and direction, and the UAVs altitude and forward speed. The model is constructed by first conducting outdoor experiments and then using machine-learning techniques on the collected data. The constructed model produced an average generalisation error of 12.8%, RMSE. Due to its parametric and predictive nature, the model is amenable for the future design of UAV flight controllers that can compensate for the targeting error caused by wind. The proposed modelling methodology could be useful not only for the dispensing of predatory mites, but also for other UAV dispensing applications, such as liquid or granular pesticide deliveries.}
}
@article{LIU2021,
title = {Bringing AI to edge: From deep learning’s perspective},
journal = {Neurocomputing},
year = {2021},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2021.04.141},
url = {https://www.sciencedirect.com/science/article/pii/S0925231221016428},
author = {Di Liu and Hao Kong and Xiangzhong Luo and Weichen Liu and Ravi Subramaniam},
keywords = {Deep learning, Model optimization, Edge computing, Neural architecture search},
abstract = {Edge computing and artificial intelligence (AI), especially deep learning algorithms, are gradually intersecting to build the novel system, namely edge intelligence. However, the development of edge intelligence systems encounters several challenges, and one of these challenges is the computational gap between computation-intensive deep learning algorithms and less-capable edge systems. Due to the computational gap, many edge intelligence systems cannot meet the expected performance requirements. To bridge the gap, a plethora of new techniques and optimization methods were proposed in the past years: lightweight deep learning models, network compression, and efficient neural architecture search. Although some reviews or surveys have partially covered this large body of literature, we lack a systematic and comprehensive review to discuss all aspects of these deep learning techniques which are critical for edge intelligence implementation. As various and diverse methods, applicable to edge systems, are proposed, a holistic review would enable edge computing engineers and the community to understand the state-of-the-art deep learning techniques that are instrumental for edge intelligence and to facilitate the development of edge intelligence systems. This paper surveys the representative and latest deep learning techniques that are useful for edge intelligence systems, including hand-crafted models, model compression, hardware-aware neural architecture search, and adaptive deep learning models. Finally, based on observations and simple experiments we conducted, we discuss some future directions.}
}
@article{SUN2022107263,
title = {Stability control of a fixed full-wing layout UAV under manipulation constraints},
journal = {Aerospace Science and Technology},
volume = {120},
pages = {107263},
year = {2022},
issn = {1270-9638},
doi = {https://doi.org/10.1016/j.ast.2021.107263},
url = {https://www.sciencedirect.com/science/article/pii/S1270963821007732},
author = {Ruijie Sun and Zhou Zhou and Xiaoping Zhu},
keywords = {Fixed full-wing layout UAV, Stability control, Radial basis function neural network, Dynamic surface control, Sliding mode control, Vector field-based lateral-directional path following control},
abstract = {The fixed full-wing layout unmanned aerial vehicle (UAV) has simple structure and high aerodynamic efficiency, but the special configuration and manipulation characteristics bring challenges to the controller design, which has little related research work. Aiming at the aileronless and rudderless manipulation mode, considering the disturbance and uncertainty, this paper proposes a comprehensive stability controller for the fixed full-wing layout UAV under manipulation constraints. First, adaptive neural network dynamic surface control schemes based on the asymmetric barrier Lyapunov function and auxiliary system are designed for pitch and yaw attitude control. Then, this paper combines the adaptive super-twisting observer, terminal sliding mode control, and double power reaching law to design the airspeed controller and the altitude controller, and further introduces the pitch angle command constraint in the altitude controller. In addition, an improved vector field-based lateral-directional path following control method is designed to realize straight-line and circular orbit path following control. In this paper, the approximation and compensation effects of the radial basis function neural network and robust compensator are fully verified. The design of the pitch angle command constraint specifically considers the characteristics of weak pitch manipulation ability, small available trim airspeed range, and low longitudinal moment of inertia. The developed path following control approach effectively prevents the nonlinear tracking differentiator from generating unreasonable yaw angle commands. Simulation results also show that the proposed controller can enable the fixed full-wing layout UAV to achieve the typical three-dimensional mission flight with high robustness and high precision, and make the fixed full-wing layout UAV remain stable even after suffering stall and manipulation saturation under the action of the gust wind field.}
}
@article{LI20202989,
title = {An aggregate flow based scheduler in multi-task cooperated UAVs network},
journal = {Chinese Journal of Aeronautics},
volume = {33},
number = {11},
pages = {2989-2998},
year = {2020},
note = {SI: Emerging Technologies of Unmanned Aerial Vehicles},
issn = {1000-9361},
doi = {https://doi.org/10.1016/j.cja.2020.03.029},
url = {https://www.sciencedirect.com/science/article/pii/S1000936120302156},
author = {Xiaohuan LI and Ziqi XIE and Jin YE and Xin TANG and Chunhai LI and Fengzhu TANG and Rong YU},
keywords = {Mixed-flow scheduling, Multi-task, Task completion rate, Unmanned Aerial Vehicles (UAVs), Urgency-level},
abstract = {Unmanned Aerial Vehicles (UAVs) cooperative multi-task system has become the research focus in recent years. However, the existing network frameworks of UAVs are not flexible and efficient enough to deal with the complex multi-task scheduling, because they are not able to perceive the different features. In this paper, a novel cooperated UAVs network framework for multi-task scheduling is proposed. It is a three-layer network including a core layer, an aggregation layer and an execution layer, which enhances the efficiency of multi-task distribution, aggregation and transmission. Furthermore, an AggreGate Flow (AGFlow) based scheduler is dedicatedly designed to maximize the task completion rate, whose key point is to aggregate flows belonging to one task during the multi-task transmission of UAVs network and to allocate priority by calculating the urgency-level of each AGFlow. Simulation results demonstrate that, compared with that of state-of-the-art scheduler, the average task completion rate of AGFlow based scheduler is raised by 0.278.}
}
@article{TAN2021,
title = {Machine learning in vehicular networking: An overview},
journal = {Digital Communications and Networks},
year = {2021},
issn = {2352-8648},
doi = {https://doi.org/10.1016/j.dcan.2021.10.007},
url = {https://www.sciencedirect.com/science/article/pii/S2352864821000870},
author = {Kang Tan and Duncan Bremner and Julien {Le Kernec} and Lei Zhang and Muhammad Imran},
keywords = {Vehicular networks, Machine learning, Vehicle-to-everything (V2X), Networking, Handover management, Resource allocation, Energy efficiency},
abstract = {As vehicle complexity and road congestion increase, combined with the emergence of electric vehicles, the need for intelligent transportation systems to improve on-road safety and transportation efficiency using vehicular networks has become essential. The evolution of high mobility wireless networks will provide improved support for connected vehicles through highly dynamic heterogeneous networks. Particularly, 5G deployment introduces new features and technologies that enable operators to capitalize on emerging infrastructure capabilities. Machine Learning (ML), a powerful methodology for adaptive and predictive system development, has emerged in both vehicular and conventional wireless networks. Adopting data-centric methods enables ML to address highly dynamic vehicular network issues faced by conventional solutions, such as traditional control loop design and optimization techniques. This article provides a short survey of ML applications in vehicular networks from the networking aspect. Research topics covered in this article include network control containing handover management and routing decision making, resource management, and energy efficiency in vehicular networks. The findings of this paper suggest more attention should be paid to network forming/deforming decision making. ML applications in vehicular networks should focus on researching multi-agent cooperated oriented methods and overall complexity reduction while utilizing enabling technologies, such as mobile edge computing for real-world deployment. Research datasets, simulation environment standardization, and method interpretability also require more research attention.}
}
@article{YANG2021108187,
title = {Fast and robust super-resolution DOA estimation for UAV swarms},
journal = {Signal Processing},
volume = {188},
pages = {108187},
year = {2021},
issn = {0165-1684},
doi = {https://doi.org/10.1016/j.sigpro.2021.108187},
url = {https://www.sciencedirect.com/science/article/pii/S0165168421002255},
author = {Tianyuan Yang and Jibin Zheng and Tao Su and Hongwei Liu},
keywords = {Unmanned aerial vehicle swarms, radar detection, direction of arrival estimation, gridless sparse technique, super-resolution},
abstract = {Unmanned aerial vehicle (UAV) swarms have shown great potentials in civilian and military applications. Consequently, there is a high demand for accurate UAV swarms detection. In response to resolve the closely spaced UAVs, we propose three super-resolution direction of arrival (DOA) estimation algorithms, i.e., frequency-selective reweighted atomic-norm minimization (FSRAM), fast Fourier transform (FFT)-reweighted atomic-norm minimization (FFT-RAM) and FFT-FSRAM. These proposed three algorithms take full account of advantages of prior knowledge, effective information extraction and gridless sparse technique, i.e., i) the use of prior knowledge can improve the accuracy of DOA estimation; ii) the effective information extraction can improve the signal-to-noise ratio to enhance the robustness and reduce the computational complexity; iii) the gridless sparse technique is insensitive to signal correlations. Complexity analysis and numerical simulations are performed to demonstrate that, compared with the Beamforming method, multiple signal classification (MUSIC) and reweighted atomic-norm minimization (RAM), the proposed three algorithms are insensitive to signal correlations and the FFT-RAM and FFT-FSRAM are more robust and faster for super-resolution DOA estimation of UAV swarms under the noisy environment. Additionally, the real experiment with C-band radar is also conducted to verify the effectiveness of the proposed super-resolution DOA estimation algorithms.}
}
@article{LIU2020253,
title = {Data analysis in visual power line inspection: An in-depth review of deep learning for component detection and fault diagnosis},
journal = {Annual Reviews in Control},
volume = {50},
pages = {253-277},
year = {2020},
issn = {1367-5788},
doi = {https://doi.org/10.1016/j.arcontrol.2020.09.002},
url = {https://www.sciencedirect.com/science/article/pii/S1367578820300596},
author = {Xinyu Liu and Xiren Miao and Hao Jiang and Jing Chen},
keywords = {Power lines, Aerial inspection, Computer vision, Image analysis, Component detection, Fault diagnosis, Deep learning},
abstract = {The widespread popularity of unmanned aerial vehicles enables an immense amount of power line inspection data to be collected. It is an urgent issue to employ massive data especially the visible images to maintain the reliability, safety, and sustainability of power transmission. To date, substantial works have been conducted on the data analysis for power line inspection. With the aim of providing a comprehensive overview for researchers interested in developing a deep-learning-based analysis system for power line inspection data, this paper conducts a thorough review of the current literature and identifies the challenges for future study. Following the typical procedure of data analysis in power line inspection, current works in this area are categorized into component detection and fault diagnosis. For each aspect, the techniques and methodologies adopted in the literature are summarized. Valuable information is also included such as data description and method performance. In particular, an in-depth discussion of existing deep-learning-based analysis methods of power line inspection data is proposed. To conclude the paper, several study trends for the future in this area are presented including data quality problems, small object detection, embedded application, and evaluation baseline.}
}
@article{LI2021119481,
title = {Study on the environmental adaptability of lithium-ion battery powered UAV under extreme temperature conditions},
journal = {Energy},
volume = {219},
pages = {119481},
year = {2021},
issn = {0360-5442},
doi = {https://doi.org/10.1016/j.energy.2020.119481},
url = {https://www.sciencedirect.com/science/article/pii/S0360544220325883},
author = {Niansi Li and Xiaoyong Liu and Bendong Yu and Liang Li and Jianqiang Xu and Qiong Tan},
keywords = {UAV (Unmanned aerial vehicle), Lithium-ion battery, Extreme temperature, Environmental adaptability, Battery discharge characteristic, Emergency rescue},
abstract = {Unmanned aerial vehicles (UAVs) have more and more potential in the emergency rescue tasks under disastrous conditions. Thus, the environmental adaptability of UVAs under extreme high and low temperature levels is very important. Firstly, we built an extreme environmental testing chamber that could simulate multiple disaster conditions. Secondly, the performance of the whole machine of UVAs especially the flying performance under extreme temperature (−30–60 °C) was investigated. Thirdly, the electrical performance of lithium-ion battery used in UVAs was investigated at the same time. Main conclusions were: (1) The high temperature condition even 60 °C had little effect on the flying performance, while significantly degraded the lifetime and discharging capacity, and even damaged the lithium-ion battery. (2) The low temperature condition significantly decreased the flying performance and the battery performance. UAV could not work normally when the environmental temperature was below −25 °C. (3) The low-temperature condition played greater effect on the battery performance than that of high-temperature condition and the testing results of battery discharge experiments well explained this phenomenon. (4) The irreversible and the reversible heat took the dominant role for lower and high temperatures, respectively.}
}
@article{MOYSIADIS2021100345,
title = {Smart Farming in Europe},
journal = {Computer Science Review},
volume = {39},
pages = {100345},
year = {2021},
issn = {1574-0137},
doi = {https://doi.org/10.1016/j.cosrev.2020.100345},
url = {https://www.sciencedirect.com/science/article/pii/S1574013720304457},
author = {Vasileios Moysiadis and Panagiotis Sarigiannidis and Vasileios Vitsas and Adel Khelifi},
keywords = {Smart Farming, Unmanned Aerial Vehicles (UAVs), Unmanned Ground Vehicles (UGVs), Image Processing, Machine Learning, Big Data, Cloud Computing, Wireless Sensor Networks (WSNs)},
abstract = {Smart Farming is the new term in the agriculture sector, aiming to transform the traditional techniques to innovative solutions based on Information Communication Technologies (ICT). Concretely, technologies like Unmanned Aerial Vehicles (UAVs), Unmanned Ground Vehicles (UGVs), Image Processing, Machine Learning, Big Data, Cloud Computing, and Wireless Sensor Networks (WSNs), are expected to bring significant changes in this area. Expected benefits are the increase in production, the decrease in cost by reducing the inputs needed such as fuel, fertilizer and pesticides, the reduction in labor efforts, and finally improvement in the quality of the final products. Such innovative methods are crucial in recent days, due to the exponential increase of the global population, the importance of producing healthier products grown with as much fewer pesticides, where public opinion of European citizens is sensitized. Moreover, due to the globalization of the world economy, European countries face the low cost of production of other low-income countries. In this vein, Europe tries to evolve its agriculture domain using technology, aiming at the sustainability of its agricultural sector. Although many surveys exist, most of them tackle in a specific scientific area of Smart Farming. An overview of Smart Farming covering all the involved technologies and providing an extensive reference of good practices around Europe is essential. Our expectation from our work is to become a good reference for researchers and help them with their future work. This paper aims to provide a comprehensive reference for European research efforts in Smart Farming and is two-fold. First, we present the research efforts from researchers in Smart Farming, who apply innovative technology trends in various crops around Europe. Second, we provide and analyze the most significant projects in Europe in the area of Smart Farming.}
}
@article{KOUPPAS2021103891,
title = {Hybrid autonomous controller for bipedal robot balance with deep reinforcement learning and pattern generators},
journal = {Robotics and Autonomous Systems},
volume = {146},
pages = {103891},
year = {2021},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2021.103891},
url = {https://www.sciencedirect.com/science/article/pii/S0921889021001767},
author = {Christos Kouppas and Mohamad Saada and Qinggang Meng and Mark King and Dennis Majoe},
keywords = {Bipedal robot, Pattern generator, Reinforcement learning, Hybrid controller},
abstract = {Recovering after an abrupt push is essential for bipedal robots in real-world applications within environments where humans must collaborate closely with robots. There are several balancing algorithms for bipedal robots in the literature, however most of them either rely on hard coding or power-hungry algorithms. We propose a hybrid autonomous controller that hierarchically combines two separate, efficient systems, to address this problem. The lower-level system is a reliable, high-speed, full state controller that was hardcoded on a microcontroller to be power efficient. The higher-level system is a low-speed reinforcement learning controller implemented on a low-power onboard computer. While one controller offers speed, the other provides trainability and adaptability. An efficient control is then formed without sacrificing adaptability to new dynamic environments. Additionally, as the higher-level system is trained via deep reinforcement learning, the robot could learn after deployment, which is ideal for real-world applications. The system’s performance is validated with a real robot recovering after a random push in less than 5 s, with minimal steps from its initial positions. The training was conducted using simulated data.}
}
@article{WANG2021104394,
title = {Ground object information extraction from hyperspectral remote sensing images using deep learning algorithm},
journal = {Microprocessors and Microsystems},
volume = {87},
pages = {104394},
year = {2021},
issn = {0141-9331},
doi = {https://doi.org/10.1016/j.micpro.2021.104394},
url = {https://www.sciencedirect.com/science/article/pii/S014193312100541X},
author = {Zhengyang Wang and Shufang Tian},
keywords = {Deep learning, Hyperspectral remote sensing image, Ground object information extraction, Convolutional neural network},
abstract = {Mining and utilizing coal resources play an influential role in economic development. In this regard, the feature information extraction in the area is researched to accurately and efficiently assist the production arrangement and deployment in the mining area. First, the detection ability of Hyperspectral Remote Sensing Image (HRSI) technology is analyzed. It has high spectral resolution and many bands. Specific bands can be extracted as needed to highlight target features. According to the characteristics of HRSIs, the data spectrum information and spatial information are comprehensively utilized, and the Convolutional Neural Network (CNN) based on deep learning is employed for feature extraction. CNN allows the machine to automatically obtain data features by learning and guide the classification of features. Taking the Liuyuan research area in Gansu as an example, three CNN models are used to extract and classify the ground features in the area. The VGG-19 model can provide the highest classification accuracy rate, reaching 87.3%; the VGG-16 model has the highest classification accuracy rate of the ground in the mining area, reaching 95.2%. ResNet model has the best effect on road classification. Then, the lithology classification is applied based on Thermal Airborne Hyperspectral Imager (TASI) data. The noise level of the first 20 bands is comparatively stable; afterward, it increases exponentially, showing a higher noise level, and the spectrum curve of the data after denoising becomes smoother. The end-member extraction method is employed to extract 25 end-member spectra of almost all lithology in the research area from the image. The similarity coefficient clustering analysis is employed to group the curves, which are divided into six categories in total. The separability of similar categories can be constrained by the objective function using the dictionary learning method, and the accuracy of the sparse representation of the category spectrum can be improved. The spectral matching method is used to subdivide each group of mapping results, suggesting that in the research area, granite is the most widely distributed, followed by diorite, andesite, and quartzite. Deep learning algorithms are applied to extract ground feature information, which is of great significance to the safety production in the mining area. The hyperspectral remote sensing rock and mineral thematic information extraction module is developed, which preliminarily realizes the quantitative acquisition and high-precision identification of typical mineral information, and provides technical support for the research of remote sensing geological evaluation technology of resource exploration in the new era.}
}
@article{BHUSAL201918,
title = {Improving Pest Bird Detection in a Vineyard Environment using Super-Resolution and Deep Learning},
journal = {IFAC-PapersOnLine},
volume = {52},
number = {30},
pages = {18-23},
year = {2019},
note = {6th IFAC Conference on Sensing, Control and Automation Technologies for Agriculture AGRICONTROL 2019},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2019.12.483},
url = {https://www.sciencedirect.com/science/article/pii/S2405896319323924},
author = {Santosh Bhusal and Uddhav Bhattarai and Manoj Karkee},
keywords = {Bird detection, Vineyard, Unmanned Aerial Vehicles (UASs), Deep Learning, Super-resolution},
abstract = {Pest bird detection, classification, and recognition in vineyard environment are challenging because of their varying shapes, small size, movement, and outdoor environment. Motion is often used to detect flying birds in outdoor environment from video sequences. However, motion detection is sensitive to noise as well as background movement of leaves and give rise to false detection. The high-quality image resolution is desired for performance improvement in pattern recognition and analysis. This work presents the integration of super-resolution technology to enhance quality of small moving objects which were later on classified as birds or false positives using deep learning. Implementation of the super-resolution enhanced the image resolution which offers high pixel density and more details about the scene. With the implementation of super-resolution, the CNN-based classifier received enhanced feature information to perform more informed decision in classifying birds. The classification accuracy shows a significant rise from 70% to more than 90% after resolution enhancement. Results also show that the model trained with combined varying spatial resolution for the same set of images performs almost equally over any spatial resolution.}
}
@article{SALEEM2021526,
title = {Deep learning for the internet of things: Potential benefits and use-cases},
journal = {Digital Communications and Networks},
volume = {7},
number = {4},
pages = {526-542},
year = {2021},
issn = {2352-8648},
doi = {https://doi.org/10.1016/j.dcan.2020.12.002},
url = {https://www.sciencedirect.com/science/article/pii/S2352864820302893},
author = {Tausifa Jan Saleem and Mohammad Ahsan Chishti},
keywords = {Internet of things (IoT), Deep learning, Convolutional neural network, Recurrent neural network, Long short term memory},
abstract = {The massive number of sensors deployed in the Internet of Things (IoT) produce gigantic amounts of data for facilitating a wide range of applications. Deep Learning (DL) would undoubtedly play a role in generating valuable inferences from this massive volume of data and hence will assist in creating smarter IoT. In this regard, exploring the potential of DL for IoT data analytics becomes highly crucial. This paper begins with a concise discussion on the Deep Neural Network (DNN) and its different architectures. The potential benefits that DL will bring to the IoT are also discussed. Then, a detailed review of DL-driven IoT use-cases is presented. Moreover, this paper formulates a DL-based model for Human Activity Recognition (HAR). It carries out a performance comparison of the proposed model with other machine learning techniques to delineate the superiority of the DL model over other techniques. Apart from enlightening the potential of DL in IoT applications, this paper will serve as an impetus to encourage advanced research in the realm of DL-driven IoT applications.}
}
@article{ESPEJOGARCIA2020105593,
title = {Improving weeds identification with a repository of agricultural pre-trained deep neural networks},
journal = {Computers and Electronics in Agriculture},
volume = {175},
pages = {105593},
year = {2020},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2020.105593},
url = {https://www.sciencedirect.com/science/article/pii/S016816992030692X},
author = {Borja Espejo-Garcia and Nikolaos Mylonas and Loukas Athanasakos and Spyros Fountas},
keywords = {Weed identification, Deep learning, Transfer learning, Open-access repository, Precision agriculture},
abstract = {Nowadays, several studies in the field of deep learning in agriculture obtain high performances in weeds identification by fine-tuning neural networks, previously trained on general-purpose datasets containing images unrelated to agriculture. This work examines whether these achievements could be further improved by fine-tuning neural networks pre-trained on agricultural datasets instead of ImageNet. The experimental results showed that with the suggested method the overall performance can increase. Some architectures such as Xception and Inception-Resnet presented an improvement of 0.51% and 1.89% respectively, while reducing the number of epochs by 13.67%. It is then argued that an agricultural repository should be developed to engage research into making their pre-trained neural networks publicly available, for the benefit of research progress and efficiency.}
}
@article{KUMARI2020304,
title = {A taxonomy of blockchain-enabled softwarization for secure UAV network},
journal = {Computer Communications},
volume = {161},
pages = {304-323},
year = {2020},
issn = {0140-3664},
doi = {https://doi.org/10.1016/j.comcom.2020.07.042},
url = {https://www.sciencedirect.com/science/article/pii/S0140366420318545},
author = {Aparna Kumari and Rajesh Gupta and Sudeep Tanwar and Neeraj Kumar},
keywords = {Unmanned aerial vehicle, Softwarization, 5G, Software defined networking, Network function virtualization, Blockchain, Smart contract, Security},
abstract = {The recent advancements in unmanned aerial vehicles (UAVs) upsurges its usages in commercial and civilian applications such as surveillance, rescue, and crowdsensing. UAVs are vulnerable to being destroyed, lost, or stolen in case of security breaches of its network. The network management of UAVs is a crucial task due to its high mobility, which necessitates UAV network softwarization. Then, it becomes indispensable that allows the separation of control functions (i.e., control plane data) from hardware for smooth execution of complex operations. Further, UAV uses the Internet (an open channel) for communication in its complex system that raises a network security concern. The well-known softwarization techniques, i.e., software-defined networking (SDN) and network function virtualization (NFV) can be used to accomplish the secure network services on less expense. Conversely, these softwarization techniques may suffer from various threats like access control, user authentication, controller hijacking, and many more attack. The existing solutions are using a centralized system, which is having a single point of failure issue and vulnerable to security threats. Motivated from these facts, we present a comprehensive and systematic survey on the blockchain-based softwarization for a secure UAV network. Then, we propose a blockchain-enabled UAV softwarization architecture for secure communication and network management. It provides dynamic, flexible, and on-the-fly decision capabilities for communication services over the UAV network. Eventually, we analyzed the open research issues and challenges for future research directions in this emerging area.}
}
@article{SIERRAGARCIA2021450,
title = {Switched learning adaptive neuro-control strategy},
journal = {Neurocomputing},
volume = {452},
pages = {450-464},
year = {2021},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2019.12.139},
url = {https://www.sciencedirect.com/science/article/pii/S0925231220316507},
author = {J. Enrique Sierra-García and Matilde Santos},
keywords = {Neuro-control, Adaptive control, Disturbance rejection, Online learning, Neural networks, Unmanned aerial vehicle (UAV)},
abstract = {The generalized learning algorithm can be efficiently used as control strategy, but it has some drawbacks such as: sensitivity to the training dataset, poor robustness against changes in the system, difficulty to generate the control signals without destabilising the plant, tuning of the controller, etc. To overcome some of these issues, in this work a new switched neural adaptive control strategy is proposed. It is based on the combination of an adaptive artificial neural network, a PID regulator, an estimated inverse model of the plant and two switches to route the signals properly in the control scheme. The technique is described using the hybrid automata formalism. In order to test the validity of this proposal, it is applied to the control of a quadrotor unmanned aerial vehicle (UAV), subjected to changes in its mass and wind disturbances. Simulation results show how the on-line learning increases the robustness of the controller, reducing the effects of the mass change and of the wind on the UAV stabilization, thus improving the UAV trajectory tracking.}
}
@article{YANG2021102618,
title = {Winter wheat SPAD estimation from UAV hyperspectral data using cluster-regression methods},
journal = {International Journal of Applied Earth Observation and Geoinformation},
volume = {105},
pages = {102618},
year = {2021},
issn = {0303-2434},
doi = {https://doi.org/10.1016/j.jag.2021.102618},
url = {https://www.sciencedirect.com/science/article/pii/S0303243421003251},
author = {Xin Yang and Rui Yang and Yin Ye and Ziran Yuan and Daozhong Wang and Keke Hua},
keywords = {SPAD estimation, Winter wheat, Extreme Gradient Boosting (XGBoost), Cluster-RF, Cluster-XGBoost, UAV hyperspectral data},
abstract = {Soil plant analysis development (SPAD) values indicate the relative chlorophyll content in leaves. Chlorophyll plays a vital role in wheat growth and fertilization management as a photosynthetic agent. Unmanned aerial vehicle (UAV) hyperspectral data, combined with measured SPAD values in fields, are widely used to study wheat chlorophyll concentrations over time. In this study, considering the spectral differences in fields with different soil fertility, we propose a new modeling method named as cluster-regression to estimate the winter wheat SPAD at a national soil observation and experimental station in northern Anhui, China. The wheat spectrum was divided into several clusters according to the spectral angular distance, and regression models were built between wheat spectrum and the measured SPAD for each cluster. We used K-means as the clustering method and two types of ensemble learning algorithms, namely, random forests and Extreme Gradient Boosting (XGBoost) as the regression methods. The root-mean-square error (RMSE), median absolute percentage error (MAPE), and R2 were used as model accuracy indicators. The results showed that the XGBoost model slightly outperformed the random forest in wheat SPAD estimation. Coupled with the first step of K-means clustering, the overall performance of the regression models can be easily improved, and cluster-XGBoost showed the best performance, with an RMSE of 1.444, MAPE of 2.36%, and R2 of 0.925. Moreover, addition of soil organic matter and soil total nitrogen positively impacted the accuracy of SPAD estimation models. This study provides an effective UAV hyperspectral technique for wheat SPAD concentration estimation and demonstrates the impact of soil organic matter and total nitrogen on wheat SPAD estimation.}
}
@article{LI2021106480,
title = {Estimation of leaf area index for winter wheat at early stages based on convolutional neural networks},
journal = {Computers and Electronics in Agriculture},
volume = {190},
pages = {106480},
year = {2021},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2021.106480},
url = {https://www.sciencedirect.com/science/article/pii/S016816992100497X},
author = {Yunxia Li and Hongjie Liu and Juncheng Ma and Lingxian Zhang},
keywords = {Leaf area index, Winter wheat, RGB images, Convolutional neural network, Early stages},
abstract = {Leaf area index (LAI) is a key growth trait to characterize the winter wheat growth at early stages. However, there needs more study on the low cost and fine-scale estimation of LAI of winter wheat. In this study, a LAI estimation method of winter wheat at the early stages was proposed based on low-cost RGB images and deep learning. The time-series canopy images of winter wheat at early stages were collected for two consecutive growth seasons (growth season 2018 and 2019), based on which the proposed model, as well as the compared models, were built. In the following step, the performances of these models were compared and analyzed. The influences of the input image with different pixel resolutions and the network depth on the model performance were discussed. Moreover, transfer learning was used to test the generalization ability of the proposed model. The results showed that the proposed estimation model could reflect the time-series variation of LAI of winter wheat at early stages. The proposed model with the input image of 128 × 128 pixel resolution achieved the best performance (R2 = 0.82, NRMSE = 24.89%), outperforming the compared models. The generalization test showed that the proposed model had a good generalization ability, achieving accurate LAI estimations for growing season 2019. However, deepen the network by adding extra SAME convolutional layers could not improve the model performance. In conclusion, based on the convolutional neural network (CNN) and low-cost RGB images, the proposed model is fast and accurate in estimating the LAI of winter wheat at early stages. This method can meet the need for LAI estimation of winter wheat at early stages and provide support for growth monitoring and agronomic management of winter wheat at early stages.}
}
@article{ZHANG2021106174,
title = {Evaluating the sensitivity of water stressed maize chlorophyll and structure based on UAV derived vegetation indices},
journal = {Computers and Electronics in Agriculture},
volume = {185},
pages = {106174},
year = {2021},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2021.106174},
url = {https://www.sciencedirect.com/science/article/pii/S0168169921001915},
author = {Liyuan Zhang and Wenting Han and Yaxiao Niu and José L. Chávez and Guomin Shao and Huihui Zhang},
keywords = {Stomatal conductance, Chlorophyll content, Leaf area index, Random forest, Artificial neural networks},
abstract = {To further assess the sensitivity of crop chlorophyll and structure based on UAV vegetation indices (VIs) to maize water stress, a study was carried out in a maize field located in Inner Mongolia, China, with various levels of deficit irrigation over the entire 2018 and 2019 growing seasons. Ground measurements of stomatal conductance (Gs), leaf area index and leaf chlorophyll were used as references for maize water status, canopy structure and chlorophyll content, respectively. Four structure VIs and two chlorophyll VIs, and three regression algorithms (multiple linear, random forest and artificial neural networks regression) were adopted. The results showed that canopy structure derived from VIs had a significant correlation (p < 0.001) with Gs with the highest r value of 0.64 (n = 270) in 2018 and 2019. The transformed chlorophyll absorption in reflectance index, chlorophyll VI, could only estimate severe maize water stress with an r value of −0.47 (p < 0.001, n = 270) for the drier 2019. The water stress sensitivity of chlorophyll and structure VIs maybe significantly influenced by different responses of canopy structure and chlorophyll concentration to water stress, and the different spectral resolution of UAV multispectral cameras. Compared to non-linear machine learning regression algorithms, the multiple linear regression was robust enough to relate UAV-based multispectral VIs to Gs with coefficients of determination of 0.48 and 0.45 (n = 270) for 2018 and 2019, respectively. Although stable significant correlations were found between UAV multispectral VIs and Gs, annual changes in these specific expressions were also observed. Overall, our results demonstrated the potential of using structure VIs derived from UAV multispectral images and multiple linear regression approach to estimate maize water status in field scale.}
}
@article{ZAKERI2016211,
title = {Rahbin: A quadcopter unmanned aerial vehicle based on a systematic image processing approach toward an automated asphalt pavement inspection},
journal = {Automation in Construction},
volume = {72},
pages = {211-235},
year = {2016},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2016.09.002},
url = {https://www.sciencedirect.com/science/article/pii/S0926580516302114},
author = {H. Zakeri and Fereidoon Moghadas Nejad and Ahmad Fahimifar},
keywords = {QUAV, Pavement Inspection, PSVM, 3DPRT, MSS},
abstract = {Automatic inspection of pavement cracking is a critical issue in pavement management systems. In this study, a quadcopter-based digital imaging system is introduced for collecting pavement surface data over a distressed area for visual conditions interpretation. An aerial evaluation was carried out using a quadcopter unmanned aerial vehicle (QUAV), which is a device equipped with a set of automatic systems. Since QUAV flies autonomously and has high maneuverability, it is potentially useful in a variety of conditions particularly the positions dangerous for surveillance and reconnaissance. The main purpose of this work is to design a multi-stage system for QUAV image analysis consisting of image processing, threshold selection, and classification stages. The images are transformed into a new domain; then, an adaptive thresholding is applied to build the pattern of transformed cracks; and finally, the polar support vector machine (the PSVM) is applied for interpretation of crack distress. The PSVM is an automation procedure based on the support vector machine (SVM) classifier defined in the polar coordinate frame. A Mixture of Wavelet modulus and three-dimensional polar Radon transform (3DPRT) are used for feature generation. We show that the PSVM method can be successfully applied to classify the crack and is capable of providing new features about cracking distress, threshold selection and classification. In order to show the applicability and efficiency of the proposed system and method, a test was conducted applying a variety of pavement distresses. The experimental results demonstrate that the applied system provides reliable output. In addition, the comparison of the derived information with the on-site manual quantifications revealed the potentiality of the QUAV and multi-stage system for future practice.}
}
@article{TANG2020453,
title = {Deep learning based automatic defect identification of photovoltaic module using electroluminescence images},
journal = {Solar Energy},
volume = {201},
pages = {453-460},
year = {2020},
issn = {0038-092X},
doi = {https://doi.org/10.1016/j.solener.2020.03.049},
url = {https://www.sciencedirect.com/science/article/pii/S0038092X20302875},
author = {Wuqin Tang and Qiang Yang and Kuixiang Xiong and Wenjun Yan},
keywords = {Electroluminescence Images, Convolution neural network, Automatic defect classification, Generative adversarial network},
abstract = {The maintenance of large-scale photovoltaic (PV) power plants is considered as an outstanding challenge for years. This paper presented a deep learning-based defect detection of PV modules using electroluminescence images through addressing two technical challenges: (1) providing a large number of high-quality Electroluminescence (EL) image generation method for the limit of EL image samples; and (2) an efficient model for automatic defect classification with the generated EL image. The EL image generation approach combines traditional image processing technology and GAN characteristics. It can produce a large number of EL image samples with high resolution using a limited number of samples. Then, a convolution neural network (CNN) based model for the automatic classification of defects in an EL image is presented. CNN is used to extract the deep feature of the EL image. It can greatly increase the accuracy and efficiency of PV modules inspection and health management in comparison with the other solutions. The proposed solution is assessed through extensive experiments by using the existing machine learning models, VGG16, ResNet50, Inception V3 and MobileNet, as the comparison benchmarks. The numerical results confirm that the proposed deep learning-based solution can carry out efficient and accurate defect detection automatically using the electroluminescence images.}
}
@article{MICHAILIDIS2021101475,
title = {Outage probability analysis in multi-user FSO/RF and UAV-enabled MIMO communication networks},
journal = {Physical Communication},
volume = {49},
pages = {101475},
year = {2021},
issn = {1874-4907},
doi = {https://doi.org/10.1016/j.phycom.2021.101475},
url = {https://www.sciencedirect.com/science/article/pii/S1874490721002123},
author = {Emmanouel T. Michailidis and Petros S. Bithas and Nikolaos Nomikos and Demosthenes Vouyioukas and Athanasios G. Kanatas},
keywords = {Free-space optical (FSO) communications, Geometric and misalignment loss (GML), Multiple-input multiple-output (MIMO) channels, Multi-user (MU) scheduling, Nakagami/inverse Gamma (IG) channels, Unmanned aerial vehicle (UAV)},
abstract = {This paper considers a mixed free-space optical/radio frequency (FSO/RF) system, which facilitates the communication between a ground central unit (CU) and multiple ground users (GUs) via a hovering unmanned aerial vehicle (UAV) acting as a decode-and-forward (DF) aerial relay. It is considered that the CU employs multiple transmit apertures and is interconnected with the aerial relay via an FSO link with transmit aperture selection (TAS), whereas the relay communicates with the GUs over multiple-input multiple-output (MIMO) RF links with orthogonal space–time block coding (OSTBC) transmission. It is assumed that the optical channels are mainly affected by atmospheric attenuation as well as geometric and misalignment loss (GML). Besides, the atmospheric turbulence is assumed weak for short-range links. Also, fully correlated shadowed conditions are considered in the RF links and the MIMO channels are modeled using the Nakagami/Inverse Gamma (IG) composite fading distribution. Opportunistic GU scheduling is applied in the downlink and novel closed-form mathematical formulas for the outage probability (OP) are derived. The results demonstrate the theoretical derivations and the performance benefits of the proposed approach.}
}
@article{LYU2020108,
title = {UAVid: A semantic segmentation dataset for UAV imagery},
journal = {ISPRS Journal of Photogrammetry and Remote Sensing},
volume = {165},
pages = {108-119},
year = {2020},
issn = {0924-2716},
doi = {https://doi.org/10.1016/j.isprsjprs.2020.05.009},
url = {https://www.sciencedirect.com/science/article/pii/S0924271620301295},
author = {Ye Lyu and George Vosselman and Gui-Song Xia and Alper Yilmaz and Michael Ying Yang},
keywords = {UAV, Semantic segmentation, Deep learning, Dataset},
abstract = {Semantic segmentation has been one of the leading research interests in computer vision recently. It serves as a perception foundation for many fields, such as robotics and autonomous driving. The fast development of semantic segmentation attributes enormously to the large scale datasets, especially for the deep learning related methods. There already exist several semantic segmentation datasets for comparison among semantic segmentation methods in complex urban scenes, such as the Cityscapes and CamVid datasets, where the side views of the objects are captured with a camera mounted on the driving car. There also exist semantic labeling datasets for the airborne images and the satellite images, where the nadir views of the objects are captured. However, only a few datasets capture urban scenes from an oblique Unmanned Aerial Vehicle (UAV) perspective, where both of the top view and the side view of the objects can be observed, providing more information for object recognition. In this paper, we introduce our UAVid dataset, a new high-resolution UAV semantic segmentation dataset as a complement, which brings new challenges, including large scale variation, moving object recognition and temporal consistency preservation. Our UAV dataset consists of 30 video sequences capturing high-resolution images in oblique views. In total, 300 images have been densely labeled with 8 classes for the semantic labeling task. We have provided several deep learning baseline methods with pre-training, among which the proposed Multi-Scale-Dilation net performs the best via multi-scale feature extraction, reaching a mean intersection-over-union (IoU) score around 50%. We have also explored the influence of spatial-temporal regularization for sequence data by leveraging on feature space optimization (FSO) and 3D conditional random field (CRF). Our UAVid website and the labeling tool have been published online (https://uavid.nl/).}
}
@article{ZHAO2021102358,
title = {UAV-based individual shrub aboveground biomass estimation calibrated against terrestrial LiDAR in a shrub-encroached grassland},
journal = {International Journal of Applied Earth Observation and Geoinformation},
volume = {101},
pages = {102358},
year = {2021},
issn = {0303-2434},
doi = {https://doi.org/10.1016/j.jag.2021.102358},
url = {https://www.sciencedirect.com/science/article/pii/S0303243421000659},
author = {Yujin Zhao and Xiaoliang Liu and Yang Wang and Zhaoju Zheng and Shuxia Zheng and Dan Zhao and Yongfei Bai},
keywords = {Shrub encroachment, Biomass, Unmanned aerial vehicle (UAV), Terrestrial laser scanning, Volume, Individual shrub identification},
abstract = {Shrub encroachment is an important ecological issue that is increasingly receiving global attention in arid and semiarid grasslands. Monitoring the spatial distribution of encroached shrub aboveground biomass (AGB) is critical for ecological conservation and adaptive ecosystem management. However, the low stature and fine spatial heterogeneity of encroached shrub communities increase difficulties for coarse spatial-resolution satellite images to adequately capture detailed characteristics of individual shrubs. Unmanned aerial vehicle (UAV) can acquire centimeter-level optical images or high-density LiDAR point cloud data, providing an effective means to map encroached shrub AGB spatially explicitly, even at the individual scale. In this study, we first extracted the individual shrubs based on thresholds in normalized difference vegetation index (NDVI) and canopy height model (CHM) using UAV-based multispectral and LiDAR data. For each shrub, we then derived and determined the dominant geometric, spectral, and textural features from the high-resolution multispectral image and the volumetric features from the LiDAR data as predictors of shrub AGB. Finally, we compared the capability of different data sources (UAV-based multispectral image, LiDAR, and their combination) and regression methods (multiple linear, random forest, and support vector regression) to estimate and map the individual shrub AGB in the study area. The volume-based approaches to individual shrub AGB, including global convex hull method, voxel method, and surface differencing method, were also employed using terrestrial laser scanning (TLS) to further calibrate the UAV-based estimation. Our results show that individual shrubs can be accurately extracted based on the threshold method with an overall classification accuracy of 91.8%. The UAV-based AGB estimation suggests that the textural feature, the sum of contrast metric within the individual shrub canopy, is the most important predictor of individual shrub AGB, followed by volumetric, geometric and spectral features. Moreover, the high-resolution multispectral image shows greater potential (R2 = 0.83, RMSE = 106.46 g) than LiDAR (R2 = 0.77, RMSE = 123.33 g) in the estimation of individual shrub AGB, and their combination can only slightly improve the estimation accuracy (R2 = 0.86, RMSE = 101.97 g). Our results also show that TLS-derived volume based on the surface differencing method obtained the best prediction accuracy of individual shrub AGB (R2 = 0.91, RMSE = 79.98 g), and can be used as an alternative of destructive harvesting. This study provides a new insight for quantifying and mapping individual shrub AGB using UAV-based optical sensors and TLS without destructive harvesting in arid and semiarid grasslands.}
}
@article{MENDONCA201837,
title = {Reinforcement learning with optimized reward function for stealth applications},
journal = {Entertainment Computing},
volume = {25},
pages = {37-47},
year = {2018},
issn = {1875-9521},
doi = {https://doi.org/10.1016/j.entcom.2017.12.003},
url = {https://www.sciencedirect.com/science/article/pii/S1875952117300587},
author = {Matheus R.F. Mendonça and Heder S. Bernardino and Raul Fonseca Neto},
keywords = {Machine learning, Reinforcement learning, Evolved reward function, Genetic algorithms, Stealth applications},
abstract = {Stealth applications are focused in accomplishing a certain objective without being spotted by enemy patrols. Although very diffused in modern applications (security, robotic, military, games), stealthy behaviors has not been extensively studied. Here, we focus on how to obtain good stealthy behaviors by tackling two different problems: (i) how to use a machine learning approach in order to allow the stealthy agent to learn good behaviors for any environment, and (ii) how to use evolutionary computing in order to define specific parameters for our machine learning approach without any prior knowledge of the problem. We use Reinforcement Learning in order to learn good covert behaviors capable of achieving a high success rate in random trials of a purpose built stealth simulator. We also propose an evolutionary approach that is capable of automatically defining a good reward function for our reinforcement learning model. The experiments performed shows that using reinforcement learning with evolved reward function through evolutionary computing achieves a higher performance than using reinforcement learning with the hand-crafted reward function.}
}
@article{WANG2021102590,
title = {Adaptive and extendable control of unmanned surface vehicle formations using distributed deep reinforcement learning},
journal = {Applied Ocean Research},
volume = {110},
pages = {102590},
year = {2021},
issn = {0141-1187},
doi = {https://doi.org/10.1016/j.apor.2021.102590},
url = {https://www.sciencedirect.com/science/article/pii/S0141118721000675},
author = {Shuwu Wang and Feng Ma and Xinping Yan and Peng Wu and Yuanchang Liu},
keywords = {Unmanned surface vehicles (USVs), USV formation control, Deep reinforcement learning, Deep deterministic policy gradient (DDPG), Extendable reinforcement learning},
abstract = {Future ocean exploration will be dominated by a large-scale deployment of marine robots such as unmanned surface vehicles (USVs). Without the involvement of human operators, USVs exploit oceans, especially the complex marine environments, in an unprecedented way with an increased mission efficiency. However, current autonomy level of USVs is still limited, and the majority of vessels are being remotely controlled. To address such an issue, artificial intelligence (AI) such as reinforcement learning can effectively equip USVs with high-level intelligence and consequently achieve full autonomous operation. Also, by adopting the concept of multi-agent intelligence, future trend of USV operations is to use them as a formation fleet. Current researches in USV formation control are largely based upon classical control theories such as PID, backstepping and model predictive control methods with the impact by using advanced AI technologies unclear. This paper, therefore, paves the way in this area by proposing a distributed deep reinforcement learning algorithm for USV formations. More importantly, using the proposed algorithm USV formations can learn two critical abilities, i.e. adaptability and extendibility that enable formations to arbitrarily increase the number of USVs or change formation shapes. The effectiveness of algorithms has been verified and validated through a number of computer-based simulations.}
}
@article{YOUSSEFI2021114907,
title = {Swarm intelligence based robotic search in unknown maze-like environments},
journal = {Expert Systems with Applications},
volume = {178},
pages = {114907},
year = {2021},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2021.114907},
url = {https://www.sciencedirect.com/science/article/pii/S0957417421003481},
author = {Khalil Al-Rahman Youssefi and Modjtaba Rouhani},
keywords = {Swarm robotic search, Complex unknown environments, Autonomous mobile robots, Particle swarm optimization},
abstract = {This paper proposes a novel decentralize and asynchronous robotic search algorithm based on particle swarm optimization (PSO), which has focused on solving mazes and finding targets in unknown environments with minimal inter-swarm communication and without any synchronization or communication center. In the proposed method, robots are advanced particles of the PSO algorithm, enriched with a toolkit, including an angle of rotation to change the course when confronted with obstacles to avoid them (AoR tool), and a memory to remember and reuse their best personal experiences to turn back from dead-ends (Mem tool). This toolkit enables the swarm to avoid obstacles and solve mazes while moving toward the target. The performance of the proposed algorithm is tested in a specially designed framework. As a validation, the proposed algorithm is compared with some recently published methods, including Adaptive Robotic PSO (A-RPSO), Robotic Bat Algorithm (RBA), and Adaptive Robotic Bat Algorithm (ARBA), in simple search environments that they can solve. The results of this comparison show that the introduced search method has the highest success rate (100%) in environments of different sizes and reflects the nature of swarm intelligence better. The proposed method is also tested in various maze-like search environments. The results depict the algorithm’s high efficiency to solve mazes in varying complexity levels and locate the target in a reliable time. It is also shown that the performance of the proposed algorithm does not decrease and remains constant as the complexity of search environments increases.}
}
@article{WANG2022107277,
title = {Integrated path planning and trajectory tracking control for quadrotor UAVs with obstacle avoidance in the presence of environmental and systematic uncertainties: Theory and experiment},
journal = {Aerospace Science and Technology},
volume = {120},
pages = {107277},
year = {2022},
issn = {1270-9638},
doi = {https://doi.org/10.1016/j.ast.2021.107277},
url = {https://www.sciencedirect.com/science/article/pii/S1270963821007872},
author = {Ban Wang and Youmin Zhang and Wei Zhang},
keywords = {Trajectory tracking control, Path planning, Adaptive sliding mode control, Model uncertainty, Unmanned aerial vehicle, Flight experiment},
abstract = {This paper proposes an innovative integrated path planning and trajectory tracking control framework for a quadrotor unmanned aerial vehicle (UAV) in the presence of environmental and systematic uncertainties to achieve integrated guidance and control. Firstly, in order to perform real-time path planning, a computationally cost-effective planning algorithm is designed to find an optimal and smooth path while avoiding both static and dynamic obstacles. Then, by employing the pure-pursuit path following approach, the generated geometric path is converted to a trajectory profile related to time, which serves as the reference commands for the low-level trajectory tracking controller. Finally, a novel adaptive sliding mode trajectory tracking controller is proposed to compensate model uncertainties and maintain the desired tracking performance for the studied quadrotor UAV. With the proposed adaptive schemes, overestimation of uncertain parameters can be avoided, which further contributes to avoiding control chattering of the system. The performance of the proposed framework is validated through comparative simulation and experimental tests based on a quadrotor UAV subject to model uncertainties and environmental obstacles, which confirms the effectiveness and superiority of the proposed approach for practical applications.}
}
@article{YANG2022460,
title = {A rapid, low-cost deep learning system to classify strawberry disease based on cloud service},
journal = {Journal of Integrative Agriculture},
volume = {21},
number = {2},
pages = {460-473},
year = {2022},
issn = {2095-3119},
doi = {https://doi.org/10.1016/S2095-3119(21)63604-3},
url = {https://www.sciencedirect.com/science/article/pii/S2095311921636043},
author = {Guo-feng YANG and Yong YANG and Zi-kang HE and Xin-yu ZHANG and Yong HE},
keywords = {deep learning, strawberry disease, image classification, mini program, cloud service},
abstract = {Accurate and timely classification of diseases during strawberry planting can help growers deal with them in timely manner, thereby reducing losses. However, the classification of strawberry diseases in real planting environments is facing severe challenges, including complex planting environments, multiple disease categories with small differences, and so on. Although recent mobile vision technology based deep learning has achieved some success in overcoming the above problems, a key problem is how to construct a non-destructive, fast and convenient method to improve the efficiency of strawberry disease identification for the multi-region, multi-space and multi-time classification requirements. We develop and evaluate a rapid, low-cost system for classifying diseases in strawberry cultivation. This involves designing an easy-to-use cloud-based strawberry disease identification system, combined with our novel self-supervised multi-network fusion classification model, which consists of a Location network, a Feedback network and a Classification network to identify the categories of common strawberry diseases. With the help of a novel self-supervision mechanism, the model can effectively identify diseased regions of strawberry disease images without the need for annotations such as bounding boxes. Using accuracy, precision, recall and F1 to evaluate the classification effect, the results of the test set are 92.48, 90.68, 86.32 and 88.45%, respectively. Compared with popular Convolutional Neural Networks (CNN) and five other methods, our network achieves better disease classification effect. Currently, the client (mini program) has been released on the WeChat platform. The mini program has perfect classification effect in the actual test, which verifies the feasibility and effectiveness of the system, and can provide a reference for the intelligent research and application of strawberry disease identification.}
}
@article{SHUJA2021103005,
title = {Applying machine learning techniques for caching in next-generation edge networks: A comprehensive survey},
journal = {Journal of Network and Computer Applications},
volume = {181},
pages = {103005},
year = {2021},
issn = {1084-8045},
doi = {https://doi.org/10.1016/j.jnca.2021.103005},
url = {https://www.sciencedirect.com/science/article/pii/S1084804521000321},
author = {Junaid Shuja and Kashif Bilal and Waleed Alasmary and Hassan Sinky and Eisa Alanazi},
keywords = {Caching, Edge networks, Machine learning, Popularity prediction, 5G},
abstract = {Edge networking is a complex and dynamic computing paradigm that aims to push cloud re-sources closer to the end user improving responsiveness and reducing backhaul traffic. User mobility, preferences, and content popularity are the dominant dynamic features of edge networks. Temporal and social features of content, such as the number of views and likes are leveraged to estimate the popularity of content from a global perspective. However, such estimates should not be mapped to an edge network with particular social and geographic characteristics. In next generation edge networks, i.e., 5G and beyond 5G, machine learning techniques can be applied to predict content popularity based on user preferences, cluster users based on similar content interests, and optimize cache placement and replacement strategies provided a set of constraints and predictions about the state of the network. These applications of machine learning can help identify relevant content for an edge network. This article investigates the application of machine learning techniques for in-network caching in edge networks. We survey recent state-of-the-art literature and formulate a comprehensive taxonomy based on (a) machine learning technique (method, objective, and features), (b) caching strategy (policy, location, and replacement), and (c) edge network (type and delivery strategy). A comparative analysis of the state-of-the-art literature is presented with respect to the parameters identified in the taxonomy. Moreover, we debate research challenges and future directions for optimal caching decisions and the application of machine learning in edge networks.}
}
@article{WANG2022108732,
title = {Computation offloading and resource allocation based on distributed deep learning and software defined mobile edge computing},
journal = {Computer Networks},
volume = {205},
pages = {108732},
year = {2022},
issn = {1389-1286},
doi = {https://doi.org/10.1016/j.comnet.2021.108732},
url = {https://www.sciencedirect.com/science/article/pii/S1389128621005843},
author = {Zhongyu Wang and Tiejun Lv and Zheng Chang},
keywords = {Software defined mobile edge computing, Internet of Things, Computation offloading, Power allocation, System utility, Distributed deep learning},
abstract = {In this paper, a software defined mobile edge computing (SD-MEC) in Internet of Things (IoT) is investigated, in which multiple IoT devices choose to offload their computation tasks to an appropriate edge server to support the emerging IoT applications with strict computation-intensive and latency-critical requirements. In considered SD-MEC networks, a joint computation offloading and power allocation problem is proposed to minimize the utility of weighted delay and power consumption in the distributed dense IoT. The optimization problem is a mixed-integer non-linear programming problem and difficult to solve by general optimization tools due to the nonconvexity and complexity. We propose a distributed deep learning based computation offloading and resource allocation (DDL-CORA) algorithm for SD-MEC IoT in which multiple parallel deep neural networks (DNNs) are invoked to generate the optimal offloading decision and resource scheduling. Additionally, we design a shared replay memory mechanism to effectively store newly generated offloading decisions which are further used to train and improve DNNs. The simulation results show that the proposed DDL-CORA algorithm can reduce the system utility on average 7.72% than reference Deep Q-network (DQN) algorithm and 31.9% than reference Branch-and-Bound (BNB) algorithm, and keep a good tradeoff between the complexity and utility performance.}
}
@article{LIU2019105403,
title = {Novel docking controller for autonomous aerial refueling with probe direct control and learning-based preview method},
journal = {Aerospace Science and Technology},
volume = {94},
pages = {105403},
year = {2019},
issn = {1270-9638},
doi = {https://doi.org/10.1016/j.ast.2019.105403},
url = {https://www.sciencedirect.com/science/article/pii/S1270963819311496},
author = {Yiheng Liu and Honglun Wang and Jiaxuan Fan},
keywords = {Unmanned aerial vehicle (UAV), Autonomous aerial refueling (AAR), Probe control, Deep learning, Reinforcement learning, Preview control},
abstract = {Autonomous aerial refueling (AAR) has always been a hot research area due to its significant application and complicated control problem. In order to improve the docking precision of AAR, a novel docking controller with probe direct control and learning-based preview method is proposed. Firstly, the controlled object is transformed from receiver barycenter to probe tactfully. Then, a suitable probe direct controller designed via the combination of reference-observer-based tracking control method and the high order sliding mode control method is proposed for the probe direct control. Furthermore, a learning-based preview method is introduced to solve the tracking lag problem. The prediction of drogue motion is considered in the reference signal. Then, a novel learning algorithm, named deep learning and reinforcement learning (DLRL), which combines deep learning (DL) and reinforcement learning (RL) spatially rather than structurally like deep reinforcement learning (DRL) is proposed to generate the preview time adaptively. And a novel preview index is proposed to adapt for it. Through the combination of probe direct controller and learning-based preview method, the proposed docking controller could improve the tracking precision largely. Effectiveness of the proposed method is demonstrated by the simulations.}
}
@article{BRAGAGNOLO2021105189,
title = {Convolutional neural networks applied to semantic segmentation of landslide scars},
journal = {CATENA},
volume = {201},
pages = {105189},
year = {2021},
issn = {0341-8162},
doi = {https://doi.org/10.1016/j.catena.2021.105189},
url = {https://www.sciencedirect.com/science/article/pii/S0341816221000485},
author = {L. Bragagnolo and L.R. Rezende and R.V. {da Silva} and J.M.V. Grzybowski},
keywords = {Satellite imagery, Deep learning, Landslide database, U-Nets},
abstract = {Landslides are considered to be among the most alarming natural hazards. Therefore, there is a growing demand for databases and inventories of these events worldwide, since they are a vital resource for landslide risk assessment applications. Given the recent advances in the field of image processing, the objective of this study is to evaluate the performance of a deep convolutional neural network architecture called U-Net for the mapping of landslide scars from satellite imagery. The question that drives the study is: can fully convolutional neural networks be successfully applied as the backbone of automatic frameworks for building landslide inventories, keeping or improving the identification accuracy and agility when compared to other methods? To seek for an answer to it, scenes from the Landsat-8 satellite of a region of Nepal were obtained and processed in order to compose a landslide image database that served as the basis for the training, validation and test of deep convolutional neural networks. The U-Net architecture was applied and the results indicate that it has the potential to identify landslide scars, improving over previously published research on the topic for the same study region. The validation process resulted in recall, precision and F1-score values of 0.74, 0.61 and 0.67, respectively, thus higher than those from previous studies using different methodologies. The results indicate the potential of the method to be applied in dynamic mapping systems for landslide scar identification, which paves the way to the composition and updating of landslide scar databases. These, in turn, can support a great deal of quantitative landslide susceptibility mapping methods that heavily rely on data to provide accurate results.}
}
@article{SUN2021102373,
title = {Retrieval of rapeseed leaf area index using the PROSAIL model with canopy coverage derived from UAV images as a correction parameter},
journal = {International Journal of Applied Earth Observation and Geoinformation},
volume = {102},
pages = {102373},
year = {2021},
issn = {0303-2434},
doi = {https://doi.org/10.1016/j.jag.2021.102373},
url = {https://www.sciencedirect.com/science/article/pii/S0303243421000805},
author = {Bo Sun and Chufeng Wang and Chenghai Yang and Baodong Xu and Guangsheng Zhou and Xiaoyong Li and Jing Xie and Shijie Xu and Bin Liu and Tianjin Xie and Jie Kuai and Jian Zhang},
keywords = {Leaf area index, Rapeseed, PROSAIL model, Empirical statistical model, Canopy coverage},
abstract = {Leaf area index (LAI), which is an important structural parameter, plays a vital role in evaluating crop growth and yield. In this study, we used the canopy coverage (CC) derived from unmanned aerial vehicle (UAV) images as a correction parameter in the PROSAIL model coupled with a neural network (NN) to improve the accuracy of LAI inversion of rapeseed plots. CC had a significantly positive impact on the accuracy of LAI inversion especially in sparse canopy structure with the 22.24% decrease in the entire dataset and 35.76% decrease in the sparse canopy dataset. We then compared the inversion performances of an empirical statistical model (ESM) based on a vegetation index and the PROSAIL model incorporating CC correction for 2016 and 2018 datasets. The ESM performed better in modeling the 2016 dataset, but its accuracy was much lower for the 2018 dataset (2016: NRMSE = 0.131; 2018: NRSME = 0.348). Overall, the PROSAIL model was more robust over these two datasets (2016: NRMSE = 0.152; 2018: NRMSE = 0.168). In addition, the original-resolution images were resampled to six coarse resolutions to evaluate the influence of image resolution on the LAI inversion performance of the PROSAIL model. When pixel size increased to more than 10 cm, the inversion accuracy began to decrease dramatically. In conclusion, introducing a canopy coverage correction parameter in the PROSAIL model improved its performance in retrieving rapeseed LAI.}
}
@article{JATAIN2021,
title = {A contemplative perspective on federated machine learning: Taxonomy, threats & vulnerability assessment and challenges},
journal = {Journal of King Saud University - Computer and Information Sciences},
year = {2021},
issn = {1319-1578},
doi = {https://doi.org/10.1016/j.jksuci.2021.05.016},
url = {https://www.sciencedirect.com/science/article/pii/S1319157821001312},
author = {Divya Jatain and Vikram Singh and Naveen Dahiya},
keywords = {Federated Learning, Security Concerns, Language Modelling, Fog Computing, Healthcare Informatics, Vulnerability Assessment},
abstract = {Today, the rapid growth of the internet and advancements in mobile technology and increased internet connectivity have brought us to a data-driven economy where an enormous amount of data is being used to train machine learning models to make strategic decisions. However, in the aftermath of a data breach by Facebook in 2018, there are some serious concerns over user data privacy and security being used to train the Machine Learning models. In this context, a new approach, Federated Machine Learning is now one of the most talked-about and recent approaches. Current research primarily focuses on Federated Learning's advantages over the traditional methods and/or its classification. However, being in a nascent stage of development as a method, certain challenges need to be addressed. This paper intends to address the totality of federated learning with a complete vulnerability assessment. During the study of the literature, it is found that security being promised as one of the key advantages of federated learning can still not be guaranteed because of some issues inherently present, and this can lead to poisoning, inference attacks and insertion of backdoors, etc. This paper intends to provide a complete picture by giving an in-depth and comprehensive analysis of Federated Learning and its taxonomy. It also provides a detailed vulnerability assessment and highlights the challenges faced in the current setting and future research directions to make federated learning a more functional, robust and secure method to train machine learning models.}
}
@article{QIN2021108251,
title = {Multi-agent reinforcement learning-based dynamic task assignment for vehicles in urban transportation system},
journal = {International Journal of Production Economics},
volume = {240},
pages = {108251},
year = {2021},
issn = {0925-5273},
doi = {https://doi.org/10.1016/j.ijpe.2021.108251},
url = {https://www.sciencedirect.com/science/article/pii/S0925527321002279},
author = {Wei Qin and Yan-Ning Sun and Zi-Long Zhuang and Zhi-Yao Lu and Yao-Ming Zhou},
keywords = {Urban transportation system, Transportation task assignment, Multi-agent reinforcement learning, Actor-critic algorithm},
abstract = {The task assignment for vehicles plays an important role in urban transportation system, which is the key to cost reduction and efficiency improvement. The development of information technology and the emergence of “sharing economy” create a more convenient transportation mode, but also bring a greater challenge to efficient operation of urban transportation system. On the one hand, considering the complex and dynamic environment of urban transportation, an efficient method for assigning transportation tasks to idle vehicles is desired. On the other hand, to meet the users' expectations on immediate response of vehicle, the task assignment problem with dynamic arrival remains to be resolved. In this study, we propose a dynamic task assignment method for vehicles in urban transportation system based on the multi-agent reinforcement learning (RL). The transportation task assignment problem is transformed into a stochastic game process from vehicles’ perspective, and then an extended actor-critic (AC) algorithm is employed to obtain the optimal strategy. Based on the proposed method, vehicles can independently make decisions in real time, thus eliminating a lot of communication cost. Compared with the methods based on first-come-first-service (FCFS) rule and classic contract net algorithm (CNA), the results show that the proposed method can obtain higher acceptance rate and profit rate in the service cycle.}
}
@article{JEONG2022149726,
title = {Predicting rice yield at pixel scale through synthetic use of crop and deep learning models with satellite data in South and North Korea},
journal = {Science of The Total Environment},
volume = {802},
pages = {149726},
year = {2022},
issn = {0048-9697},
doi = {https://doi.org/10.1016/j.scitotenv.2021.149726},
url = {https://www.sciencedirect.com/science/article/pii/S0048969721048014},
author = {Seungtaek Jeong and Jonghan Ko and Jong-Min Yeom},
keywords = {Crop yield prediction, Data driven model, Crop model, Remote sensing, Korean peninsula},
abstract = {Prediction of rice yields at pixel scale rather than county scale can benefit crop management and scientific understanding because it is useful for monitoring how crop yields respond to various agricultural systems and environmental factors. In this study, we propose a methodology for the early prediction of rice yield at pixel scale combining a crop model and a deep learning model for different agricultural systems throughout South and North Korea. Initially, satellite-integrated crop models were applied to obtain a pixel-scale reference rice yield. Then, the pixel-scale reference rice yields were used as target labels in the deep learning model to leverage the advantages of crop models. Models of five different deep learning network architectures were employed to help determine the hybrid structure of long-short term memory (LSTM) and one-dimensional convolutional neural network (1D-CNN) layers by predicting the optimal model about two months ahead of harvest time. The suggested model showed good performance [R2 = 0.859, Nash-Sutcliffe model efficiency = 0.858, root mean squared error = 0.605 Mg ha−1], with specific spatial patterns of rice yields for South and North Korea. Analysis of the relative importance of the input variables showed the water-related index and maximum temperature in North Korea and the vegetation indices and geographic variables in South Korea to be crucial for predicting rice yields. The proposed approach successfully predicted and diagnosed rice yield at the pixel scale for inaccessible locations where reliable ground measurements are not available, especially North Korea.}
}
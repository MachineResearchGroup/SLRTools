@ARTICLE{8712550,
author={Liu, Yan and Guo, Bin and Li, Nuo and Zhang, Jing and Chen, Jingmin and Zhang, Daqing and Liu, Yinxiao and Yu, Zhiwen and Zhang, Sizhe and Yao, Lina},
journal={IEEE Internet of Things Journal}, title={DeepStore: An Interaction-Aware Wide amp;Deep Model for Store Site Recommendation With Attentional Spatial Embeddings},
year={2019},
volume={6},
number={4},
pages={7319-7333},
abstract={Store site recommendation is one of the essential business services in smart cities for brick-and-mortar enterprises. In recent years, the proliferation of multisource data in cities has fostered unprecedented opportunities to the data-driven store site recommendation, which aims at leveraging large-scale user-generated data to analyze and mine users' preferences for identifying the optimal location for a new store. However, most works in store site recommendation pay more attention to a single data source which lacks some significant data (e.g., consumption data and user profile data). In this paper, we aim to study the store site recommendation in a fine-grained manner. Specifically, we predict the consumption level of different users at the store based on multisource data, which can not only help the store placement but also benefit analyzing customer behavior in the store at different time periods. To solve this problem, we design a novel model based on the deep neural network, named DeepStore, which learns low- and high-order feature interactions explicitly and implicitly from dense and sparse features simultaneously. In particular, DeepStore incorporates three modules: 1) the cross network; 2) the deep network; and 3) the linear component. In addition, to learn the latent feature representation from multisource data, we propose two embedding methods for different types of data: 1) the filed embedding and 2) attention-based spatial embedding. Extensive experiments are conducted on a real-world dataset including store data, user data, and point-of-interest data, the results demonstrate that DeepStore outperforms the state-of-the-art models.},
keywords={Data models;Internet of Things;Business;Neural networks;Feature extraction;Urban areas;Data mining;Attention mechanism;data analytics;deep learning;spatial embedding;store site recommendation},
doi={10.1109/JIOT.2019.2916143},
ISSN={2327-4662},
month={Aug},}
@INPROCEEDINGS{8090851,
author={Gao, Qiang and Han, Lei and Shen, Jie and Wang, Huibin and Xu, Lizhong and Han, Lei},
booktitle={2017 International Smart Cities Conference (ISC2)}, title={Focused-Region segmentation for light field images based on PCNN},
year={2017},
volume={},
number={},
pages={1-6},
abstract={Light field can generate a set of refocused images by integrating rays into any image plane. It is useful to segment focus region from the refocused image because the focus region contains depth clues. However, to the best of our knowledge, focus-region segmentation for light field images has not been reported. We firstly transform the refocused image into the space of neuron ignition sequence with pulse coupled neural networks (PCNN). Then the model of neuron ignition sequence and the classification criteria are established to divide pixels into different regions. Finally, the clearest region is selected as the segmentation result by the sliding window technology. In this paper, we analyze the features of focus/defocus information in the space of neuron ignition sequence, and propose some simple criteria for pixel classification. The proposed algorithm and other two typical segmentation algorithms for low depth-of-field images are tested on the data set of light field images. The experimental results show that the three algorithms have similar error rates of focused-region segmentation, but the computational time of ours is one order of magnitude shorter than that of the other two.},
keywords={Ignition;Image segmentation;Neurons;Lenses;Classification algorithms;Cameras;Microoptics;light field;digital refocusing;image segmentation;PCNN},
doi={10.1109/ISC2.2017.8090851},
ISSN={},
month={Sep.},}
@INPROCEEDINGS{9562904,
author={Amjad, Arslan and Qaiser, Shahzad and Anwar, Aamir and Ijaz-ul-Haq and Ali, Ramsha},
booktitle={2021 IEEE International Smart Cities Conference (ISC2)}, title={Analysing Public Sentiments Regarding COVID-19 Vaccines: A Sentiment Analysis Approach},
year={2021},
volume={},
number={},
pages={1-7},
abstract={The COVID-19 pandemic has signified the interconnected nature of our world demonstrating that no one is safe until everyone is safe. The social and economic turmoil caused by the pandemic is devastating and revealing a dramatic loss of human life worldwide and presents a prodigious challenge to food systems, public health, and work worldwide. The vaccination programs are of utmost priority for every institution but there is a clear divide among people on efficacies and application of the offered vaccines. Today, the world has access to high-performance wireless internet due to 5G technologies which can enable systems to fetch billions of records from social media within a blink of an eye. The internet revolution has opened a new door of opportunities. This study aims to come up with a system that can utilize 5G technologies to access the data from social media to create awareness, prevent and control the impact of the pandemic by assessing the people's sentiments towards the COVID vaccines. People's sentiments are classified from not afraid to afraid divulging a total of three classes. The dataset is extracted from Twitter. The study has three main objectives 1) data collection and preprocessing 2) analyzing public sentiments, 3) evaluating the performance of Machine Learning (ML) classifiers. The results show that majority of people belong to the neutral class which indicates that they are still doubtful if they should be vaccinated or not. There is an urgent need for vaccine awareness programs to prevent COVID.},
keywords={COVID-19;Wireless communication;Support vector machines;Sentiment analysis;Social networking (online);Pandemics;5G mobile communication;Covid;Vaccine;Sentiment;Opinion;ML;NLP},
doi={10.1109/ISC253183.2021.9562904},
ISSN={2687-8860},
month={Sep.},}
@INPROCEEDINGS{9616999,
author={Bahaweres, Rizal Broer and Jana, Ellrica Dewi Herawati and Hermadi, Irman and Suroso, Arif Imam and Arkeman, Yandra},
booktitle={2021 2nd International Conference On Smart Cities, Automation Intelligent Computing Systems (ICON-SONICS)}, title={Handling High-Dimensionality on Software Defect Prediction with FLDA},
year={2021},
volume={},
number={},
pages={76-81},
abstract={For years, Software Defect Prediction (SDP) has been used as a way to improve software reliability. It is used as a tool to detect the defects on software module before the testing phase. The steps consist of building machine learning model by training dataset with classifier and predict on defective modules. Many datasets suffer from high dimensionality because of the high number of features and those features are mostly irrelevant to predict defect. This results the data to be unnecessarily bulky and the classification process to be time-consuming. We propose a feature extraction technique called FLDA for handling dimensionality problem of dataset and improving the classification performance. We use a total of four dataset from NASA MDP. For classifiers, we use Support Vector Machine (SVM), Random Forest (RF), Naive Bayes (NF), and Multi Layer Perceptron (MLP). Based on the study results, FLDA can significantly reduced the dimension of datasets by creating new feature that contains the most relevant information. FLDA can also shorten the processing time of the classifiers. When compared to another feature extraction technique such as PCA, FLDA can easily outperform it in terms of Recall and AUC.},
keywords={Support vector machines;Training;Radio frequency;Tools;Feature extraction;Software;Software reliability;Feature Extraction;FLDA;PCA;Software Defect Prediction},
doi={10.1109/ICON-SONICS53103.2021.9616999},
ISSN={},
month={Oct},}
@INPROCEEDINGS{8906529,
author={Nguyen, Khoi and Stewart, Rodney A and Sahin, Oz and Bertone, Edoardo and Beal, Cara D. and Cominola, Andrea and Zhang, Hong and Silva Vieira, Abel},
booktitle={2019 3rd International Conference on Smart Grid and Smart Cities (ICSGSC)}, title={Digital Multi-Utility Data for Contemporaneous Water-Electricity-Gas End Use Categorization},
year={2019},
volume={},
number={},
pages={45-50},
abstract={The advent of advanced metering technologies combined with machine learning creates an opportunity to form digital multi-utility service providers. These service providers can concurrently collect a customers' water, electricity and gas demand data and provide phone and web applications to disseminate this information back to utility professionals and customers. Service companies that can provide inexpensive integrated systems will derive benefits such as operational synergies and access to mass markets not bounded by historical city, state or country limits. This article provides a vision of an integrated multi-utility service provider covering the system architecture, barriers and strategies, and opportunities and benefits. The focus of paper is to demonstrate the data modelling processes and informatics opportunities for contemporaneously collected water, electricity and gas demand data. Moreover, a transformative R&D framework is provided to realize this digital multi-utility future.},
keywords={digital metering;smart metering;multi-utility;big data;water-energy nexus},
doi={10.1109/ICSGSC.2019.00-20},
ISSN={},
month={June},}
@INPROCEEDINGS{9373264,
author={Thwal, Chu Myaet and Thar, Kyi and Tun, Ye Lin and Hong, Choong Seon},
booktitle={2021 IEEE International Conference on Big Data and Smart Computing (BigComp)}, title={Attention on Personalized Clinical Decision Support System: Federated Learning Approach},
year={2021},
volume={},
number={},
pages={141-147},
abstract={Health management has become a primary problem as new kinds of diseases and complex symptoms are introduced to a rapidly growing modern society. Building a better and smarter healthcare infrastructure is one of the ultimate goals of a smart city. To the best of our knowledge, neural network models are already employed to assist healthcare professionals in achieving this goal. Typically, training a neural network requires a rich amount of data but heterogeneous and vulnerable properties of clinical data introduce a challenge for the traditional centralized network. Moreover, adding new inputs to a medical database requires re-training an existing model from scratch. To tackle these challenges, we proposed a deep learning-based clinical decision support system trained and managed under a federated learning paradigm. We focused on a novel strategy to guarantee the safety of patient privacy and overcome the risk of cyberattacks while enabling large-scale clinical data mining. As a result, we can leverage rich clinical data for training each local neural network without the need for exchanging the confidential data of patients. Moreover, we implemented the proposed scheme as a sequence-to-sequence model architecture integrating the attention mechanism. Thus, our objective is to provide a personalized clinical decision support system with evolvable characteristics that can deliver accurate solutions and assist healthcare professionals in medical diagnosing.},
keywords={Decision support systems;Training;Neural networks;Collaborative work;Data models;Medical diagnostic imaging;Diseases;clinical decision support system;healthcare;artificial intelligence;sequence-to-sequence network;attention mechanism;federated learning},
doi={10.1109/BigComp51126.2021.00035},
ISSN={2375-9356},
month={Jan},}
@INPROCEEDINGS{8656949,
author={Acosta, Sergio F. and Camargo, Jorge E.},
booktitle={2018 IEEE International Smart Cities Conference (ISC2)}, title={City safety perception model based on visual content of street images},
year={2018},
volume={},
number={},
pages={1-8},
abstract={Safety perception measurement has been a subject of interest in many cities of the world. This is due to its social relevance, and to its effect on some local economic activities. Even though people safety perception is a subjective topic, sometimes it is possible to find out common beliefs given a restricted sociocultural context. This paper presents an approach that makes use of image processing and machine learning techniques to model citizen's safety perception using visual information of city images. The proposed method predicts how safe a given street of Bogotá City can be. This is done based on people judgment of the visual appearance of a street image. Results suggest that the obtained model is able to detect city streets, where a visual feature is linked to an activity or street condition that has a significant influence on their associated safety perception. This feature makes the proposed model an alternative tool for decision makers with regard to urban planning, safety and health public policies, as well as a collective memory associated to a particular urban environment.},
keywords={Urban areas;Visualization;Safety;Feature extraction;Support vector machines;Predictive models;Histograms},
doi={10.1109/ISC2.2018.8656949},
ISSN={},
month={Sep.},}
@ARTICLE{9169777,
author={Jin, Yong and Qian, Zhenjiang and Gong, Shengrong and Yang, Weiyong},
journal={IEEE/ACM Transactions on Computational Biology and Bioinformatics}, title={Learning Transferable Driven and Drone Assisted Sustainable and Robust Regional Disease Surveillance for Smart Healthcare},
year={2021},
volume={18},
number={1},
pages={114-125},
abstract={Smart healthcare has been applied in many fields such as disease surveillance and telemedicine, etc. However, there are some challenges for device deployment, data collection and guarantee of stainability in regional disease surveillance. First, it is difficult to deploy sensors and adjust the sensor network in unknown region for dynamic disease surveillance. Second, the limited life-cycle of sensor network may cause the loss of surveillance data. Thus, it is important to provide a sustainable and robust regional disease surveillance system. Given a set of Disease surveillance Area (DsA)s and Point of disease Surveillance (PoS)s, some sensors are deployed to monitor these PoSs, and a drone collect data from the sensors as well as charge the sensors to extend their life-cycles. The drone replenish its energy by relying on the bus network. We first formulate the drone assisted regional disease surveillance problem under the constraints of life-cycle of sensors and energy of drone, and propose an approximation algorithm to find a feasible cycle of drone to minimize the traveling time cost of drone. To satisfy the diversity requirements and dynamic scalability of regional disease surveillance, we deploy one robot in each DsA instead of sensors. We further formulate the learning transferable driven regional disease surveillance problem, and propose a joint schedule algorithm of drone and robots. The results of both theoretical analysis and extensive simulations show that the proposed algorithms can reduce the total time cost by 39.71 and 48.74 percent, average waiting time by 42.00 and 50.14 percent, and increase the average accessing ratio of PoSs by 15.53 and 22.30 percent, through the assistance of bus network and learning transferable features.},
keywords={Drones;Surveillance;Diseases;Sensors;Wireless sensor networks;Wireless communication;Smart healthcare;regional disease surveillance;bus network;transfer learning;deadline Traveling Salesman Problem;multiple Traveling Salesman Problem},
doi={10.1109/TCBB.2020.3017041},
ISSN={1557-9964},
month={Jan},}
@INPROCEEDINGS{9217007,
author={Shu, Pengfeng and Sun, Ying and Zhao, Yifan and Xu, Gangyan},
booktitle={2020 IEEE 16th International Conference on Automation Science and Engineering (CASE)}, title={Spatial-Temporal Taxi Demand Prediction Using LSTM-CNN},
year={2020},
volume={},
number={},
pages={1226-1230},
abstract={Spatial-temporal taxi demand prediction is vital for efficient planning and scheduling of taxis, which could improve overall service level of public transportation in megacities. However, previous research mainly focuses on predicting the taxi demand within certain areas, and seldom considers the inter-area demands, which is essential for the macro-level taxi scheduling. Therefore, this paper proposes an effective model for spatial-temporal inter-area taxi demand prediction through integrating Convolutional Neural Networks (CNN) and Long Short-Term Memory (LSTM). CNN is adopted to extract the correlation between features and temporal closeness dependence while LSTM for fusing them in time series. The model is verified using the historical data in Haikou (China) and results show it is more accurate and stable than traditional LSTM in inter-area taxi demand prediction.},
keywords={Public transportation;Predictive models;Logic gates;Feature extraction;Correlation;Computational modeling;Training;CNN;LSTM;Taxi Demand Prediction;Smart Mobility;Smart City},
doi={10.1109/CASE48305.2020.9217007},
ISSN={2161-8089},
month={Aug},}
@INPROCEEDINGS{9221230,
author={Junaid Farooq, Muhammad and Zhu, Quanyan},
booktitle={2020 IEEE 6th World Forum on Internet of Things (WF-IoT)}, title={PhD Forum: Enabling Autonomic IoT for Smart Urban Services},
year={2020},
volume={},
number={},
pages={1-2},
abstract={The development of autonomous cyber-physical systems (CPS) and advances towards the fifth generation (5G) of wireless technology is promising to revolutionize many industry verticals such as healthcare, transportation, energy, retail services, building automation, education, etc., leading to the realization of the smart city paradigm. The Internet of things (IoT), enables powerful and unprecedented capabilities for intelligent and autonomous operation. We leverage ideas from network science, optimization & decision theory, incentive mechanism design, and data science/machine learning to achieve key design goals such as efficiency, security & resilience, and economics in IoT-enabled urban systems.},
keywords={Internet of things;cyber-physical systems;mission-critical;network science},
doi={10.1109/WF-IoT48130.2020.9221230},
ISSN={},
month={June},}
@INPROCEEDINGS{9156121,
author={Sieck, Noah and Calpin, Cameron and Almalag, Mohammad},
booktitle={2020 IEEE International Conference on Pervasive Computing and Communications Workshops (PerCom Workshops)}, title={Machine Vision Smart Parking Using Internet of Things (IoTs) In A Smart University},
year={2020},
volume={},
number={},
pages={1-6},
abstract={The concept of smart cities is becoming more widespread as the critical need for smart parking systems becomes evident in these cities. This paper suggests a method of smart parking in a heretofore relatively untouched area: midsize college campuses. With a high concentration of people and expansion with a relatively low increase in parking spots, parking problems are commonplace on college campuses. There is no designated terminology for universities utilizing smart systems, with suggestions ranging from “smart campuses” to “smart universities.” This paper discusses a proof of concept structure utilized by the researchers to implement a smart parking system in a midsize university parking lot. The system looks promising as evidenced by the results gathered using the proposed system. The results are discussed later in the paper and the implications for the smart parking system.},
keywords={Cameras;Real-time systems;Mobile applications;Sensors;Databases;Navigation;Servers;smart parking;machine learning;smart university;smart campus;parking system;parking tracker},
doi={10.1109/PerComWorkshops48775.2020.9156121},
ISSN={},
month={March},}
@ARTICLE{8721206,
author={Zhou, Zhenyu and Wang, Bingchen and Guo, Yufei and Zhang, Yan},
journal={IEEE Transactions on Emerging Topics in Computational Intelligence}, title={Blockchain and Computational Intelligence Inspired Incentive-Compatible Demand Response in Internet of Electric Vehicles},
year={2019},
volume={3},
number={3},
pages={205-216},
abstract={By leveraging the charging and discharging capabilities of Internet of electric vehicles (IoEV), demand response (DR) can be implemented in smart cities to enable intelligent energy scheduling and trading. However, IoEV-based DR confronts many challenges, such as a lack of incentive mechanism, privacy leakage, and security threats. This motivates us to develop a distributed, privacy-preserved, and incentive-compatible DR mechanism for IoEV. Specifically, we propose a consortium blockchain-enabled secure energy trading framework for electric vehicles (EVs) with moderate cost. To incentivize more EVs to participate in DR, a contract theory-based incentive mechanism is proposed, in which various contract items are tailored for the unique characteristics of EV types. The contract optimization problem falls into the category of difference of convex programing, and is solved by using the iterative convex-concave procedure algorithm. Furthermore, we consider the scenario where the statistical knowledge of the EV type is unknown. In such a case, we demonstrate how to derive the probability distribution of the EV type by exploring computational intelligence-based state of charge estimation techniques, e.g., Gaussian process regression. Finally, the security and efficiency performance of the proposed scheme is analyzed and validated.},
keywords={Contracts;Blockchain;Computational intelligence;Privacy;Security;Estimation;Batteries;Demand response;consortium blockchain;machine learning;contract theory;Internet of electric vehicles;computational intelligence},
doi={10.1109/TETCI.2018.2880693},
ISSN={2471-285X},
month={June},}
@ARTICLE{8467301,
author={Wang, Shen and Wu, Jun and Zhang, Shanghua and Wang, Kuan},
journal={IEEE Access}, title={SSDS: A Smart Software-Defined Security Mechanism for Vehicle-to-Grid Using Transfer Learning},
year={2018},
volume={6},
number={},
pages={63967-63975},
abstract={Nowadays, vehicle-to-grid (V2G) is a very important component for smart cities, which provide a novel energy storage and scheduling approach. However, security threats currently disturb the normal operations of V2G. There are two challenges for the security of V2G. On one hand, existing security schemes for V2G just consider the static security strategy, which cannot deal well with the problem of high dynamics and advanced persistent threat in V2G. On the other hand, existing V2G lacks a unified information modeling approach, which results in the difficulties of security and communications. To address above challenges, this paper proposes a smart software-defined security mechanism, SSDS, for V2G using transfer learning and IEC 61850 standards. First, as next generation networking technology, software-defined networking (SDN) is adopted to establish a dynamic security protection architecture for V2G, which can provide dynamic security strategy configuration capability. Second, IEC 61850 is introduced to model SSDS, including SDN controller and OpenFlow switch. Third, transfer learning-based security strategy constructing scheme is proposed for the security strategy updating dynamically. Simulation results in terms of network performance and security strategy constructing verify the efficiency as well as feasibility of the proposed security mechanism.},
keywords={Vehicle-to-grid;Security;IEC Standards;Substations;Protocols;Computer architecture;Vehicles;security;software architecture;machine learning},
doi={10.1109/ACCESS.2018.2870955},
ISSN={2169-3536},
month={},}
@ARTICLE{9016241,
author={Lawal, Muhammad Aminu and Shaikh, Riaz Ahmed and Hassan, Syed Raheel},
journal={IEEE Access}, title={Security Analysis of Network Anomalies Mitigation Schemes in IoT Networks},
year={2020},
volume={8},
number={},
pages={43355-43374},
abstract={The Internet of Things (IoT) is on the rise and it is giving a new shape to several fields such as smart cities, smart homes, smart health, etc. as it facilitates the connection of physical objects to the internet. However, this advancement comes along with new challenges in terms of security of the devices in the IoT networks. Some of these challenges come as network anomalies. Hence, this has prompted the use of network anomaly mitigation schemes as an integral part of the defense mechanisms of IoT networks in order to protect the devices from malicious users. Thus, several schemes have been proposed to mitigate network anomalies. This paper covers a review of different network anomaly mitigation schemes in IoT networks. The schemes' objectives, operational procedures, and strengths are discussed. A comparison table of the reviewed schemes, as well as a taxonomy based on the detection methodology, is provided. In contrast to other surveys that presented qualitative evaluations, our survey provides both qualitative and quantitative evaluations. The UNSW-NB15 dataset was used to conduct a performance evaluation of some classification algorithms used for network anomaly mitigation schemes in IoT. Finally, challenges and open issues in the development of network anomaly mitigation schemes in IoT are discussed.},
keywords={Internet of Things;Intrusion detection;Performance evaluation;Telecommunication traffic;Standards;Protocols;Classification algorithms;Intrusion Detection System (IDS);Internet of Things (IoT);machine learning;network anomalies;security},
doi={10.1109/ACCESS.2020.2976624},
ISSN={2169-3536},
month={},}
@INPROCEEDINGS{9045678,
author={Weiss, Maria Barros and Gavras, Anastasius and Salva-Garcia, Pablo and Alcaraz-Calero, Jose M. and Wang, Qi},
booktitle={2020 IEEE 17th Annual Consumer Communications Networking Conference (CCNC)}, title={Network Management - Edge and Cloud Computing The SliceNet Case},
year={2020},
volume={},
number={},
pages={1-6},
abstract={The new Fifth-Generation (5G) mobile networks entail next-generation network management solutions to manage both physical and virtual network infrastructures and services. The challenge is to effectively manage the increased complexity due to virtualization and softwarization, whilst attempting to reduce the operational costs for 5G operators. This paper focuses on the approach of the EU Horizon 2020 5G-PPP project SliceNet to meet this challenge. SliceNet is implementing an intelligence-based autonomic end-to-end slicing-friendly infrastructure for 5G networks. The paper describes SliceNet's virtualized Mobile/Multi-access Edge Computing (MEC) infrastructure segment as a solution to manage the combination of edge and cloud computing for the new services emerging on the vertical industries as part of the new 5G mobile networks. It presents the vision and recent development of the project on the MEC part of the architecture, and the artificial intelligence approach being investigated in the project. Moreover, the paper introduces three representative use cases to describe how the framework organizes between cloud and edge. These use cases show how the MEC and cloud computing can be combined for services in e-health, smart-grids, and smart-cities verticals.},
keywords={Cloud computing;5G mobile communication;Network slicing;Scalability;Load management;Smart grids;Security;5G network;network management;cloud;mobile edge;artificial intelligence;machine learning},
doi={10.1109/CCNC46108.2020.9045678},
ISSN={2331-9860},
month={Jan},}
@INPROCEEDINGS{9002261,
author={Ramesh, R and Divya, G and Dorairangaswamy, M A and Unnikrishnan, K N and Joseph, Aleena and Vijayakumar, Asha and Mani, Arun},
booktitle={2019 International Conference on Communication and Electronics Systems (ICCES)}, title={Real-Time Vehicular Traffic Analysis using Big Data Processing and IoT based Devices for Future Policy Predictions in Smart Transportation},
year={2019},
volume={},
number={},
pages={1482-1488},
abstract={The primary objectives of his research work are “Node Congestion Management” and “Policy Settings”. The secondary objective is to assess the congestion nodes and construct a graph based output so as to analyze the trends in traffic flow of kerala state's Ernakulam district during 2 peak hours by considering first peak hour from 7.00 am to 8.30 am and second from 4.00 pm to 6.30 pm. The traffic management and public works department under state government of Kerala can obtain various insights related to congestion nodes. One important intelligence that this project provides is the change in congestion rate of various congestion points with respect to a single road infrastructure project. Even a road-hump or a speed breaker would affect the congestion rate at various congestion points far away. This automated analysis based on machine learning would save public funds by preventing unnecessary allocation of funds. Also this system justifies allocation of funds for various useful projects. The traffic monitoring helps in long term decision making especially while formulating transport policies and budgets. It also guides the law enforcement agencies to properly understand the variations of such traffic and properly take precautionary measures like installation of security cameras and other control measures.},
keywords={Roads;Urban areas;Big Data;Smart transportation;Electron tubes;Magnetic sensors;Smart city;smart transportation;IoT sensors;Big Data processing;Traffic congestion},
doi={10.1109/ICCES45898.2019.9002261},
ISSN={},
month={July},}
@ARTICLE{9076121,
author={Yang, Jun and Guizani, Nadra and Hu, Long and Ghoneim, Ahmed and Alrashoud, Mubarak and Hossain, M. Shamim},
journal={IEEE Network}, title={Smart Autonomous Moving Platforms},
year={2020},
volume={34},
number={3},
pages={116-123},
abstract={In recent years, several advances in artificial intelligence such as deep learning, computer vision, automatic driving, cognitive computing, and robotics, have laid the technological foundation for the large-scale application of Smart-AMPs in complex environments. Potential solutions have appeared for smart transportation, aerospace exploration, smart logistics and smart cities. This article summarizes all kinds of autonomous moving platforms, proposes a definition of Smart- AMPs, and investigates taxonomy, technologies, applications, open issues and key challenges for Smart-AMPs. This article is suitable as a pedagogical overview of Smart-AMPs.},
keywords={Task analysis;Service robots;Navigation;Planning;Decision making;Space exploration},
doi={10.1109/MNET.011.1900263},
ISSN={1558-156X},
month={May},}
@INPROCEEDINGS{7328142,
author={Ju, Qianao and Chen, Shang-Tse and Zhang, Ying},
booktitle={2015 12th Annual IEEE International Conference on Sensing, Communication, and Networking - Workshops (SECON Workshops)}, title={Benchmarking renderscript: potential for energy efficient multi-core mobile devices},
year={2015},
volume={},
number={},
pages={1-6},
abstract={Multi-core System On Chips (SoCs) are playing a predominating role in smart phones and tablets. Unlike traditional multi-core desktops, mobile devices are restricted by the limited energy the batteries can buffer. It remains unclear whether it is energy efficient to adopt heterogeneous computing in multi-core mobile devices. In this paper, we evaluate mobile heterogeneous computing by benchmarking RenderScript, a high performance computing framework in Android system, using 6 selected benchmarks in the area of linear algebra, machine learning and image processing. For each benchmark, both the original version and the RenderScript heterogeneous version are implemented for the performance comparison. We make a thorough study of the performance in terms of computation speedup and power consumption on two smart phone platforms. Our results demonstrate that, compared with original implementation, the increase of computation speed ranges from 2 to 18 by using RenderScript while the power consumption overhead is capped by 75%. By adopting heterogeneous computing, the total energy required for executing the applications can be significantly reduced. Based on the benchmarking results, the potential for improving energy efficiency of multi-core mobile devices is discussed.},
keywords={Benchmark testing;Mobile communication;Power demand;Smart phones;Image edge detection;smart city;mobile heterogeneous computing;RenderScript;energy efficiency},
doi={10.1109/SECONW.2015.7328142},
ISSN={},
month={June},}
@INPROCEEDINGS{9307603,
author={Ignatius Dimas, Priambodo and Suhono H, Supangkat},
booktitle={2020 International Conference on ICT for Smart Society (ICISS)}, title={Assessment on Road Anomalies using Smartphone Sensor: A Review},
year={2020},
volume={CFP2013V-ART},
number={},
pages={1-7},
abstract={Road quality degradation could lead to various impacts on road users, such as reduced safety during the trip, increased risk of accidents, increased potential for congestion, or increased maintenance costs. Road maintenance and monitoring by manual inspection are costly, time-consuming, complex, and prone to bias. A system capable of identifying road anomalies, such as cracks, potholes, and speedbumps, is needed. Smartphones nowadays were equipped with a variety of powerful yet low-cost sensors. It enables collecting road anomalies data in a cheap, more productive, and efficient way. This paper aims to review the development of a vibration-based system to identify road anomalies. It also tries to explain the factors that can influence the vibration-based data collection using a smartphone. This review will include features used to improve road anomalies identification results, various machine learning algorithms, and their performance in road anomalies identification.},
keywords={Roads;Sensors;Vibrations;Vehicles;Transportation;Maintenance engineering;Band-pass filters;road anomalies;pothole;smart city;accelerometer;smartphone sensor},
doi={10.1109/ICISS50791.2020.9307603},
ISSN={2640-0545},
month={Nov},}
@INPROCEEDINGS{9170732,
author={Sharma, Priyamwada},
booktitle={2nd International Conference on Data, Engineering and Applications (IDEA)}, title={Critical Review of Various Intrusion Detection Techniques for Internet of Things},
year={2020},
volume={},
number={},
pages={1-6},
abstract={Technology is rapidly moving towards the systems enabling maximum comfort to human being. IoT scenario has evolved into a technology for developing such comfortable eco system and became popular day by day, and at the point of attraction for the researchers world-wide who are involved in developing technology for creating comfortable and sustainable eco system for human being. Now a days IoT has shown a strong technological presence globally which embraced humanity in many ways, spread from home automation, smart city, industry and healthcare. These applications is endless and imaginable. A number of challenges and issues perceived by the system in which security and privacy are key issues. This security and vulnerability in IoT based system implies security threats which affects the overall performance of the system. In majority system related attacks could be addressed by an effective Intrusion detection system (IDS). Due to limited resources like computing, energy, storage and specially designed protocols for operations, common Intrusion detection system those are well suited for conventional network are not enough for the intrusion detection in IoT. A well designed mechanism is needed for addressing the specific challenges and issues IoT faces. This paper surveys some suitable mechanism designed for detection of intrusions in an IoT system. As a result of the survey, this paper highlights the various issues and challenges associated with IDS of IOT.},
keywords={Internet of things;Intrusion Detection System;Cyber-attack;Machine Learning;Anomaly Detection},
doi={10.1109/IDEA49133.2020.9170732},
ISSN={},
month={Feb},}
@INPROCEEDINGS{9482237,
author={Niu, Jiaming and Yang, Yu and Yue, Tong},
booktitle={2021 IEEE 4th Advanced Information Management, Communicates, Electronic and Automation Control Conference (IMCEC)}, title={Current Status and Development Trend of Crowd Counting},
year={2021},
volume={4},
number={},
pages={904-909},
abstract={As a challenging task, crowd counting has attracted the attention of researchers due to its wide application in the fields of smart video surveillance, smart city construction, and public safety. But at the same time, the impact of many factors, including occlusion, scale changes, and perspective distortion, on task accuracy is still a problem that needs to be solved urgently. On the basis of combing and summarizing the relevant literature, the mainstream population counting methods are reviewed to lay the foundation for more in-depth research in the future. Firstly, it analyzes the research background, current situation and development trend of crowd counting method as a whole. Secondly, the traditional counting method is summarized with the three angles of detection, regression and density estimation as the starting point. Then, it focuses on the crowd counting method based on CNN. Once again, a brief introduction to commonly used counting data sets is given, and Ground Truth generation methods and mainstream evaluation indicators are explained. Finally, based on a series of analyses, the main characteristics and development prospects of population counting are summarized.},
keywords={Analytical models;Visualization;Correlation;Sociology;Estimation;Market research;Video surveillance;crowd counting;convolutional neural network;deep learning;image processing},
doi={10.1109/IMCEC51613.2021.9482237},
ISSN={2693-2776},
month={June},}
@INPROCEEDINGS{8796519,
author={Chen, Weiling and Yang, Chenyan and Cheng, Gibson and Zhang, Yan and Yeo, Chai Kiat and Lau, Chiew Tong and Lee, Bu Sung},
booktitle={2018 9th IEEE Annual Ubiquitous Computing, Electronics Mobile Communication Conference (UEMCON)}, title={Exploiting Behavioral Differences to Detect Fake Ne},
year={2018},
volume={},
number={},
pages={879-884},
abstract={Online social platforms have become the most influential media and their impact will be far greater in the highly connected and super-efficient smart cities. The speed, reach and sheer volume of digital media pose a global challenge to combat fake news. There is an urgent need to build resilience in a post-truth era. Misinformation gnaws social cohesion and erodes the trust of the citizens. This study seeks to identify the key differences in the traits between fake news and normal information in tweets and present two case studies to showcase two such features, namely, user sentiments and spread pattern. We then we propose an AI-based system using Autoencoder and Recurrent Neural Networks to detect fake news in Sina Weibo. This Proof-of-Concept (POC) can achieve a reasonable accuracy and F1 score and also proves its applicability to other online social platforms. The proposed POC is especially useful for governments, companies and other organizations to identify such misinformation as early as possible so that immediate actions can be taken to minimize the potential negative effect. It can also be deployed for use by social media platform users.},
keywords={Fake news detection;Feature selection;Autoencoder;Recurrent neural network},
doi={10.1109/UEMCON.2018.8796519},
ISSN={},
month={Nov},}
@ARTICLE{9261957,
author={El-Tanab, Manal and Hamouda, Walaa},
journal={IEEE Network}, title={An Overview of Uplink Access Techniques in Machine-Type Communications},
year={2021},
volume={35},
number={3},
pages={246-251},
abstract={The bright future of smart cities relies on an effective deployment of IoT technologies. Machine-type communications (MTC) is a major backbone technology that supports connectivity for the Internet of things (IoT). Cellular networks are known to be cost-effective, with ubiquitous coverage that ease the deployment of MTC. However, cellular networks were originally designed for human-centric services with high-cost devices and ever-increasing rate requirements. In contrast, MTC services need to support low-cost, low-energy, massive number of devices. This poses a number of challenges toward the adaptation of current cellular networks to accommodate MTC. This article gives an overview of the conventional random access (RA) scheme of cellular networks and its variants in the literature. However, without discounting the efforts of optimizing the RA scheme, we show that due to the increased collisions and prohibitive overhead, it falls short to support MTC with reduced latency and guaranteed reliability. Alternatively, we discuss different uplink access techniques that are found promising in tackling massive connectivity while avoiding the shortcomings of the conventional RA. Moreover, we discuss how to utilize different future 5G and beyond technologies to efficiently handle massive MTC while pointing out the promising role of machine learning techniques.},
keywords={Uplink;Quality of service;Proposals;Data communication;Cellular networks;Delays;3GPP},
doi={10.1109/MNET.011.2000513},
ISSN={1558-156X},
month={May},}
@INPROCEEDINGS{8821090,
author={Al-Din, Munaf Salim Najim},
booktitle={2018 International Conference on Circuits and Systems in Digital Enterprise Technology (ICCSDET)}, title={Highway Driving Events Identification and Classification using Smartphone},
year={2018},
volume={},
number={},
pages={1-6},
abstract={Research and developments in the newly emerging vehicular applications such as driving monitoring systems, driving behavior and style analysis, driving intension modeling and vehicle telematics, have greatly contributed in the fields of road safety analysis, intelligent transportation systems and microscopic traffic simulation for smart cities. Identification and classification of driving events represents a fundamental necessity for all these systems and in fact they represent the backbone module for any successful application. In recent years, the use of smartphones has grown significantly due to the increase in their computational capabilities and the integration of advanced sensor technologies. This prevalence of smartphones and advances in machine learning techniques have rapidly transformed the field of vehicular applications to be easily accessible, widely available, and implemented at low cost. This paper presents a simple but an effective approach for the identification and classification of driving events. The approach is based on separating events identification process from the classification process. The Dynamic Time Warping (DTW) technique is used for the identification, while statistical and time metrics features are used for the classification. Results obtained show a high accuracy rate of the proposed system.},
keywords={Magnetometers;Feature extraction;Acceleration;Magnetic separation;Accelerometers;Gyroscopes;Low-pass filters;Driving Events;Smartphone;Detection and Classification},
doi={10.1109/ICCSDET.2018.8821090},
ISSN={},
month={Dec},}
@INPROCEEDINGS{8812180,
author={Nedelkoski, Sasho and Thamsen, Lauritz and Verbitskiy, Ilya and Kao, Odej},
booktitle={2019 IEEE International Conference on Edge Computing (EDGE)}, title={Multilayer Active Learning for Efficient Learning and Resource Usage in Distributed IoT Architectures},
year={2019},
volume={},
number={},
pages={8-12},
abstract={The use of machine learning modeling techniques enables smart IoT applications in geo-distributed infrastructures such as in the areas of Industry 4.0, smart cities, autonomous driving, and telemedicine. The data for these models is continuously emitted by sensor-equipped devices. It is usually unlabeled and commonly has dynamically-changing data distribution, which impedes the learning process. However, many critical applications such as telemedicine require highly accurate models and human supervision. Therefore, online supervised learning is often utilized, but its application remains challenging as it requires continuous labeling by experts, which is expensive. To reduce the cost, active learning (AL) strategies are used for efficient data selection and labeling. In this paper we propose a novel AL framework for IoT applications, which employs data selection strategies throughout the multiple layers of distributed IoT architectures. This enables an improved utilization of the available resources and reduces costs. The results from the evaluation using classification and regression tasks and synthetic as well as real-world datasets in multiple settings show that the use of multilayer AL can significantly reduce communication, expert costs, and energy, without a loss in model performance. We believe that this study motivates the development of new techniques that employ selective sampling strategies on data streams to optimize the resource usage in IoT architectures.},
keywords={Internet of Things;Data models;Computer architecture;Nonhomogeneous media;Labeling;Task analysis;Computational modeling;active learning, edge computing, internet of things, communication efficiency, resource utilization},
doi={10.1109/EDGE.2019.00015},
ISSN={},
month={July},}
@INPROCEEDINGS{8987294,
author={Nadaf, Raju A. and M, Rubina and P, Sujata and Bonal, Vasudha M.},
booktitle={2019 1st International Conference on Advances in Information Technology (ICAIT)}, title={Smart Mirror Using Raspberry Pi for Human Monitoring and Intrusion Detection},
year={2019},
volume={},
number={},
pages={116-121},
abstract={The demand for latest technology is rising and there by changing the way the world lives. The impact of technology is so heavy on our lives that, we are surrounded by technology filled equipments. Ranging from smart home to smart cities, everything is turning to smart. The ease of life and comfort zone also increasing with the advancement of technology. Hence, the proposed model, The Smart Mirror is a system in which the normal mirror will behave like a smart device. The Smart mirror is designed using Raspberry Pi-3 model and a touch enabled screen. The designed system is having two modes of operation namely regular mode and the triggered mode. In regular mode, it will act like a normal mirror and in triggered mode, the mirror will act like a smart mirror, which will capable of accepting commands and displays the results on the screen. There are three ways in which commands can be issued to the Smart mirror namely Voice, Touch and Mobile controlled commands. The system displays weather, temperature and latest news on the mirror. The system is primarily designed for the purpose of Human Monitoring and also Intrusion Detection. The proposed design is an interactive system and is made as a package bundled with maximum possible features, which not only just displays information over screen, but also can be used for providing security. The system is built using hardware units like Raspberry Pi-3 model, microphone, touch screen, mobile device, camera and PIR (Passive Infrared Sensor) sensors and programming coded in Python language. The Human Intrusion detection and Human Monitoring is implemented using Yolo Machine learning technique with OpenCV.},
keywords={Mirrors;Monitoring;Cameras;Sensors;Intrusion detection;Meteorology;Raspberry Pi;Human Monitoring;Yolo using Raspberry;Intrusion Detection},
doi={10.1109/ICAIT47043.2019.8987294},
ISSN={},
month={July},}
@INPROCEEDINGS{8252147,
author={Sultan, Mohamed and Ahmed, Khaled Nabil},
booktitle={2017 Computing Conference}, title={SLASH: Self-learning and adaptive smart home framework by integrating IoT with big data analytics},
year={2017},
volume={},
number={},
pages={530-538},
abstract={Over the last decades, smart home systems have failed to spread widely in every home and be a coherent part of our life like what smartphones did in half this period of time. However, the latest evolution of Internet of Things (IoT) and Big Data analysis gave new insights of smart platforms that can potentially lead to the new dream of `smart cities'. The paper presented a survey such latest technologies that can lead to a new paradigm of a smart home, based on classifying the basic components of such systems and present the previous work in each component. Moreover, SLASH framework is proposed for designing and implementing smart home systems that are both adaptive and self-learning. Our framework suggests integrating IoT across every home with a large network connected to Big Data analyser. Such an engine that supports analysing inhabitants' behaviours on a large-scale can enable a new type of home automation that depends on machine learning and develops on-going automation decision over time. Essentially, this approach holds some challenges that are considered throughout the framework or state for future enhancements.},
keywords={Smart homes;Wireless fidelity;Wireless sensor networks;Intelligent sensors;ZigBee;Big Data;Smart Homes;Human-Building Interaction;Embedded Systems;Ubiquitous Computing;Context-awareness;Big Data;Internet of Things},
doi={10.1109/SAI.2017.8252147},
ISSN={},
month={July},}
@INPROCEEDINGS{8834189,
author={Rahman, Md Juber and Morshed, Bashir I.},
booktitle={2019 IEEE International Conference on Electro Information Technology (EIT)}, title={SCC Health: A Framework for Online Estimation of Disease Severity for the Smart and Connected Community},
year={2019},
volume={},
number={},
pages={373-378},
abstract={Development of a smart and connected community (SCC) health framework is an indispensable part in the development of smart cities. Smartphones with increased processing capability, integrated sensors, storage capacity, and cloud connectivity have a key role to play in developing this SCC Health framework. In this paper, we report a novel smartphone-based framework for continuous monitoring of arrhythmia, obstructive sleep apnea (OSA), chronic obstructive pulmonary disease (COPD), and flu. In addition to personalized monitoring, community-wide temporal and spatial monitoring are also possible in this approach. A custom smartphone app is developed that has the ability for collection of body sensor data via Bluetooth, loading machine learning algorithms dynamically from the webserver, computing disease severity in real-time, sharing of anonymous data, and visualization of community health status via the webserver. The framework has been tested for online monitoring of OSA, COPD, and flu severity. An accuracy of ± 1°F has been achieved for flu measurement and a mean absolute error (MAE) of 8.27 AHI has been achieved for OSA severity estimation using heart rate variability and SpO2. The app has a power consumption of 218 mW when active, uses a memory of 7 MB, and requires a total storage space of 9.36 MB. This framework aims to improve community health, reduce waste in healthcare spending, and facilitate early treatment in case of disease exacerbation.},
keywords={Heuristic algorithms;Wireless sensor networks;Wireless communication;Intelligent sensors;Estimation;Data privacy;Connected health;Mobile Health;Smartphone app.;Smart and connected community;Wireless body sensors},
doi={10.1109/EIT.2019.8834189},
ISSN={2154-0373},
month={May},}
@ARTICLE{8777171,
author={Islam, Shama Naz and Baig, Zubair and Zeadally, Sherali},
journal={IEEE Transactions on Industrial Informatics}, title={Physical Layer Security for the Smart Grid: Vulnerabilities, Threats, and Countermeasures},
year={2019},
volume={15},
number={12},
pages={6522-6530},
abstract={Smart energy systems are becoming an important component of smart cities. The wide adoption of existing computing technologies and communication standards by a smart energy system exposes it to the plethora of threats that exist in cyberspace. In this article, we investigate the vulnerabilities and threats associated with smart energy system components, including Internet of Things enabled devices, as well as relevant communication standards, and we discuss countermeasures against adversarial attacks. We found that the existing literature has reported various attacks, including modification, denial-of-service, malware, and message replay, which can cause malfunctioning of different components of a smart energy system. In addition, we propose a framework for securing the physical layer of the smart energy system. The framework is based on advanced key generation, machine learning, and physical layer security techniques, which enhance the security of smart energy systems across different applications.},
keywords={Security;Smart grids;Phasor measurement units;Smart meters;Physical layer security;Information security;physical layer;smart grids},
doi={10.1109/TII.2019.2931436},
ISSN={1941-0050},
month={Dec},}
@INPROCEEDINGS{8472999,
author={Desai, Palak V.},
booktitle={2018 Second International Conference on Inventive Communication and Computational Technologies (ICICCT)}, title={A survey on big data applications and challenges},
year={2018},
volume={},
number={},
pages={737-740},
abstract={Big data defines huge, diverse and fast growing data which requires new technologies to handle. With the rapid growth of data, big data has brought attention of researchers to use it in most prominent way for decision making in various emerging applications. These huge data is extremely useful and valuable for scientific exploration, increase productivity in business and improvement in mankind. It helps from public sector to business activities, healthcare to better navigation, smart cities to national security. Though, with large opportunities to work, the challenges are to handle these data is also increased. In this paper basic of big data with its application and challenges have been discussed. These challenges are also inherent from verity, volume and velocity of data. However if we can manage this issues related to big data then there will be potential improvement in quality of our lives.},
keywords={Big Data;Data visualization;Social network services;Medical services;Decision making;Machine learning algorithms;Big data;Challenges;Big data applications},
doi={10.1109/ICICCT.2018.8472999},
ISSN={},
month={April},}
@ARTICLE{8047951,
author={Ploennigs, Joern and Ba, Amadou and Barry, Michael},
journal={IEEE Internet of Things Journal}, title={Materializing the Promises of Cognitive IoT: How Cognitive Buildings Are Shaping the Way},
year={2018},
volume={5},
number={4},
pages={2367-2374},
abstract={Relatively tiny examples have demonstrated the potential of cognitive IoT (CIoT) in its full-stack, namely, semantic modeling, learning and reasoning over sensors data, and machine learning, to uncover and expose actionable insights via advanced user interfaces. In this paper, we make the case for the feasibility of CIoT in all of its dimensions. We devise a CIoT architecture that integrates thousands of sensors present in our buildings in order to learn the buildings' behavior and intuitively assist users in diagnosing and mitigating undesired events. With our architecture, we place emphasis on the scalability and flexibility that reduce the configuration effort. The solution shows the potential of CIoT to create highly scalable, adaptable and interactive IoT systems functioning for buildings and capable of addressing the challenges encountered in the realm of homes, Smart Cities and Industry 4.0.},
keywords={Buildings;Computer architecture;Architecture;Cognition;Semantics;Cognitive systems;Internet of Things;Auagmented reality;automated analytics;cognitive Internet of Things (CIoT);fog and cloud computing;learning and reasoning;semantic modeling},
doi={10.1109/JIOT.2017.2755376},
ISSN={2327-4662},
month={Aug},}
@INPROCEEDINGS{9473900,
author={Vishwakarma, Shelly and Tang, Chong and Li, Wenda and Woodbridge, Karl and Adve, Raviraj and Chetty, Kevin},
booktitle={2021 IEEE International Conference on Communications Workshops (ICC Workshops)}, title={GAN Based Noise Generation to Aid Activity Recognition when Augmenting Measured WiFi Radar Data with Simulations},
year={2021},
volume={},
number={},
pages={1-6},
abstract={This work considers the use of a passive WiFi radar (PWR) to monitor human activities. Real-time uncooperative monitoring of people has numerous applications ranging from smart cities and transport to IoT and security. In e-healthcare, PWR technology could be used for ambient assisted living and early detection of chronic health conditions. Large training datasets could drive forward machine-learning-focused research in the above applications. However, generating and labeling large volumes of high-quality, diverse radar datasets is an onerous task. Therefore, we present an open-source motion capture data-driven simulation tool, SimHumalator, that can generate large volumes of human micro-Doppler radar data at multiple IEEE WiFi standards(IEEE 802.11g, n, and ad). We qualitatively compare the micro-Doppler signatures generated through SimHumalator with the measured signatures. To create a more realistic training dataset, we artificially add noise to our clean simulated spectrograms. A noise distribution is directly learned from real radar measurements using a Generative Adversarial Network (GAN). We observe improvements in the classification performances between 3 to 8%. Our results suggest that simulation data can be used to make adequate training data when the available measurement training support is low.},
keywords={Training;Radar measurements;Conferences;Generative adversarial networks;Data models;Noise measurement;Task analysis;Passive WiFi Sensing;micro-Doppler;activity recognition;generative adversarial networks},
doi={10.1109/ICCWorkshops50388.2021.9473900},
ISSN={2694-2941},
month={June},}
@INPROCEEDINGS{9185880,
author={Ekárt, Anikó and Patelli, Alina and Lush, Victoria and Ilie-Zudor, Elisabeth},
booktitle={2020 IEEE Congress on Evolutionary Computation (CEC)}, title={Genetic Programming with Transfer Learning for Urban Traffic Modelling and Prediction},
year={2020},
volume={},
number={},
pages={1-8},
abstract={Intelligent transportation is a cornerstone of smart cities' infrastructure. Its practical realisation has been attempted by various technological means (ranging from machine learning to evolutionary approaches), all aimed at informing urban decision making (e.g., road layout design), in environmentally and financially sustainable ways. In this paper, we focus on traffic modelling and prediction, both central to intelligent transportation. We formulate this challenge as a symbolic regression problem and solve it using Genetic Programming, which we enhance with a lag operator and transfer learning. The resulting algorithm utilises knowledge collected from other road segments in order to predict vehicle flow through a junction where traffic data are not available. The experimental results obtained on the Darmstadt case study show that our approach is successful at producing accurate models without increasing training time.},
keywords={Junctions;Predictive models;Data models;Roads;Training;Genetic programming;Computational modeling;Genetic Programming;Transfer Learning;Symbolic Regression;Intelligent Transportation;Traffic Prediction},
doi={10.1109/CEC48606.2020.9185880},
ISSN={},
month={July},}
@INPROCEEDINGS{9014234,
author={Amour, Lamine and Tong, Van and Souihi, Sami and Tran, Hai Anh and Mellouk, Abdelhamid},
booktitle={2019 IEEE Global Communications Conference (GLOBECOM)}, title={Quality Estimation Framework for Encrypted Traffic (Q2ET)},
year={2019},
volume={},
number={},
pages={1-6},
abstract={In the coming years, the development of the Internet of Things (IoT) will have relevance for transport, environment, health care, smart cities and also multimedia services (Multimedia Internet of Things (MIoT)). Nowadays, many ISP (Internet Service Provider) encrypt the data to make it secure during the transmission. However, it imposes some obstacles for the NSP (Network Service Provider) because of the lack of visibility for operators into network traffic. To resolve these issues, we proposed the Quality Estimation Framework for Encrypted Traffic (Q2ET) containing a classification module and a QoE assessment module. The first module inherited from our previous research works to classify the encrypted network traffic using CNN (Convolutional Neural Network). The second one applies the objective and subjective methods based on the statistical analysis and machine learning methods that combine application and network parameters to calculate user's QoE (Quality of Experience) in terms of MOS (Mean Opinion Score). The Q2ET allows the NSP to monitor the user's QoE to take the appropriate decisions when the QoE degradation happens in the network systems.},
keywords={Quality of experience;Cryptography;Streaming media;Estimation;Internet of Things;Quality assessment;Feature extraction},
doi={10.1109/GLOBECOM38437.2019.9014234},
ISSN={2576-6813},
month={Dec},}
@ARTICLE{9296560,
author={Zeng, Liekang and Chen, Xu and Zhou, Zhi and Yang, Lei and Zhang, Junshan},
journal={IEEE/ACM Transactions on Networking}, title={CoEdge: Cooperative DNN Inference With Adaptive Workload Partitioning Over Heterogeneous Edge Devices},
year={2021},
volume={29},
number={2},
pages={595-608},
abstract={Recent advances in artificial intelligence have driven increasing intelligent applications at the network edge, such as smart home, smart factory, and smart city. To deploy computationally intensive Deep Neural Networks (DNNs) on resource-constrained edge devices, traditional approaches have relied on either offloading workload to the remote cloud or optimizing computation at the end device locally. However, the cloud-assisted approaches suffer from the unreliable and delay-significant wide-area network, and the local computing approaches are limited by the constrained computing capability. Towards high-performance edge intelligence, the cooperative execution mechanism offers a new paradigm, which has attracted growing research interest recently. In this paper, we propose CoEdge, a distributed DNN computing system that orchestrates cooperative DNN inference over heterogeneous edge devices. CoEdge utilizes available computation and communication resources at the edge and dynamically partitions the DNN inference workload adaptive to devices' computing capabilities and network conditions. Experimental evaluations based on a realistic prototype show that CoEdge outperforms status-quo approaches in saving energy with close inference latency, achieving up to 25.5% ~ 66.9% energy reduction for four widely-adopted CNN models.},
keywords={Image edge detection;Computational modeling;Smart homes;Performance evaluation;Task analysis;Feature extraction;Runtime;Edge intelligence;cooperative DNN inference;distributed computing;energy efficiency},
doi={10.1109/TNET.2020.3042320},
ISSN={1558-2566},
month={April},}
@ARTICLE{9043538,
author={Sanam, Tahsina Farah and Godrich, Hana},
journal={IEEE Access}, title={A Multi-View Discriminant Learning Approach for Indoor Localization Using Amplitude and Phase Features of CSI},
year={2020},
volume={8},
number={},
pages={59947-59959},
abstract={Location Based Service (LBS) is one of the important aspects of a smart city. Accurate indoor localization plays a vital role in LBS. The ability to localize various subjects in the area of interest facilitates further ubiquitous environments. Specifically, device free localization using wireless signals is getting increased attention as human location is estimated using its impact on the surrounding wireless signals without any active device tagged with subject. In this paper, we propose MuDLoc, the first multi-view discriminant learning approach for device free indoor localization using both amplitude and phase features of Channel State Information (CSI) from multiple Access Points (APs). The same location oriented CSI data can be observed by different APs, thus generating multiple distinct even heterogeneous samples. Multi-view learning is an emerging technique in machine learning which improve performance by utilizing diversity from different view data. In MuDLoc, the localization is modeled as a pattern matching problem, where the target location is predicted based on similarity measure of CSI features of an unknown location with those of the training locations. MuDLoc implements Generalized Inter-view and Intra-view Discriminant Correlation Analysis (GI2DCA), a discriminative feature extraction approach that incorporates inter-view and intra-view class associations while maximizing pairwise correlations across multi-view data sets. Experimental results from two cluttered environments show that MuDLoc can estimate location with high accuracy which outperforms other benchmark approaches.},
keywords={Wireless communication;Correlation;Performance evaluation;Feature extraction;OFDM;Communication system security;Pattern matching;Indoor localization;device free;multi-view discriminant learning;amplitude and phase features;CSI},
doi={10.1109/ACCESS.2020.2982277},
ISSN={2169-3536},
month={},}
@INPROCEEDINGS{9298043,
author={Hammoudi, Sarra and Bentaleb, Abdelhak and Harous, Saad and Aliouat, Zibouda},
booktitle={2020 11th IEEE Annual Ubiquitous Computing, Electronics Mobile Communication Conference (UEMCON)}, title={Scheduling in IEEE 802.15.4e Time Slotted Channel Hopping: A Survey},
year={2020},
volume={},
number={},
pages={0331-0336},
abstract={Time Slotted Channel Hopping (TSCH, termed also Time Synchronized Channel Hopping) is one of the medium access control modes that is defined in IEEE 802.15.4e standard. TSCH plays a vital role in the development of the Internet of Things (IoT) applications such as smart city, smart home, and smart factory. For reliable communications, it leverages time slotted channel together with time slotted access capabilities. Moreover, it serves deterministic low-power mesh network deployed for critical applications with high reliability and low latency. However, it suffers from problems that may seriously deteriorate the system performance. As an attempt to identify the scheduling technique problems, in this paper, we first presents an overview on existing scheduling techniques, rules, and their challenges in TSCH-enabled IoT applications, and second, we study some recent emerging scheduling-based proposals that benefit from intelligent and machine learning techniques to avoid such scheduling problems. Therefore, increase the efficiency of the IoT applications. This survey inspires researchers to create a reliable TECH communications for critical IoT applications.},
keywords={Internet of Things;Reliability;Job shop scheduling;Topology;Synchronization;Standards;IEEE 802.15 Standard;IEEE 802.15.4e;TSCH;Internet of Things;Wireless Sensor Networks;Scheduling},
doi={10.1109/UEMCON51285.2020.9298043},
ISSN={},
month={Oct},}
@INPROCEEDINGS{7501718,
author={Cabrera, Wellington and Benhaddou, Driss and Ordonez, Carlos},
booktitle={2016 IEEE International Conference on Smart Computing (SMARTCOMP)}, title={Solar Power Prediction for Smart Community Microgrid},
year={2016},
volume={},
number={},
pages={1-6},
abstract={Urban areas host more than 50% of the world's populations, are responsible for 75% of energy consumption in the world, and they emit almost 80% of global carbon dioxide. There is an urgent need to develop "low carbon" cities that are smart and efficient and use renewable energy to foster the growth of the green economy. Smart grids are being developed to tackle these challenges through integration of renewable and green energy as well as energy efficiency. They are moving toward a concept of networked microgrids. Microgrids will enable the integration of distributed renewable energy such as roof top solar panels within smart city communities. For these microgrids to operate reliably and efficiently, prediction algorithms are a significant because of the fluctuation of solar energy and its dependence on weather. Prediction of energy is a component of microgrids energy management systems to optimize their operation. This paper presents a machine learning based algorithm, which learns a regression tree model with time of the day and humidity as main parameters. The regression tree model presents a promising accuracy. This work shows that solar panel prediction in Houston is heavily dependent on humidity of the region.},
keywords={Microgrids;Meteorology;Regression tree analysis;Prediction algorithms;Autoregressive processes;Algorithm design and analysis;Solar energy},
doi={10.1109/SMARTCOMP.2016.7501718},
ISSN={},
month={May},}
@INPROCEEDINGS{9271376,
author={Lyasheva, S. and Shleymovich, M.},
booktitle={2020 International Multi-Conference on Industrial Engineering and Modern Technologies (FarEastCon)}, title={Boundary Detection in Images in Intelligent Systems of Autonomous Vehicles Using Wavelet Transform},
year={2020},
volume={},
number={},
pages={1-5},
abstract={“Smart city” is one of the concepts within which modern scientific and technical areas are actively developing. This concept defines the tasks associated with the organization of various infrastructure objects' continuous monitoring to optimally divide resources and ensure security. One of these tasks is to ensure road safety involving autonomous vehicles. The solution to this problem involves various technologies, including computer vision technologies. One of the approaches in this area is based on machine learning methods. These methods consider objects models in images represented as attribute vectors. Boundary attributes are often used here. The formation of these attribute comes down to two steps the boundaries detection and their description in the form of descriptors. This paper describes an approach to the objects' boundaries detection in images in intelligent systems of autonomous vehicles, which is based on the use of wavelet transform. The method is based on determining the significance of the brightness change magnitude at some point at a certain level of the wavelet decomposition. For that, it is necessary to evaluate the contribution to the total image energy of the detailed coefficients corresponding to this point. The method determines the sequential refinement of boundaries, which is as follows: as the brightnesses of the original image's copies at different levels are interconnected, we assume that the boundary points at different levels correspond to each other. The proposed method is simple to implement, has a relatively high speed and the ability to flexibly configure for real operating conditions.},
keywords={Wavelet transforms;Transforms;Brightness;Intelligent systems;Autonomous vehicles;Image processing;Task analysis;autonomous vehicles intelligent systems;computer vision;detection and recognition of objects in images;boundaries detection on images;wavelet transform},
doi={10.1109/FarEastCon50210.2020.9271376},
ISSN={},
month={Oct},}
@INPROCEEDINGS{8284322,
author={Saini, Abhinav and Suregaonkar, Sameer and Gupta, Neena and Karar, Vinod and Poddar, Shashi},
booktitle={2017 Tenth International Conference on Contemporary Computing (IC3)}, title={Region and feature matching based vehicle tracking for accident detection},
year={2017},
volume={},
number={},
pages={1-6},
abstract={Intelligent traffic monitoring using video surveillance is one of the most important aspects in administering a modern smart city. A recent growth towards machine learning and computer vision techniques has provided an added impetus towards this growth. In this paper, an image processing based vehicle tracking technique is developed that does not require background subtraction process to be applied for extracting the region of interest. Instead, a hybrid of feature detection and region matching approach is suggested in this article, which helps in estimating vehicle trajectory over consequent frames. Later, the tracked path is monitored for the occurrence of any specific event while the vehicle passes through an intersection. The proposed scheme is found to work promisingly on the real world dataset and is able to detect the occurrence of an accident between two vehicles.},
keywords={Feature extraction;Detectors;Accidents;Monitoring;Tracking;Microsoft Windows;Correlation;feature detection;block matching;normalised cross-correlation;vehicle tracking;moving average},
doi={10.1109/IC3.2017.8284322},
ISSN={2572-6129},
month={Aug},}
@ARTICLE{9416288,
author={Arzo, Sisay Tadesse and Naiga, Claire and Granelli, Fabrizio and Bassoli, Riccardo and Devetsikiotis, Michael and Fitzek, Frank H. P.},
journal={IEEE Internet of Things Journal}, title={A Theoretical Discussion and Survey of Network Automation for IoT: Challenges and Opportunity},
year={2021},
volume={8},
number={15},
pages={12021-12045},
abstract={The introduction of the Internet of Things (IoT) and massive machine-type communications has implied an increase in network size and complexity. In particular, there is already a huge number of IoT devices in the market in various sectors, such as smart agriculture, smart city, smart home, smart transportation, etc. The IoT interconnectivity technologies are also increasing. Therefore, these are increasingly overwhelming the efforts of network administrators as they try to design, reconfigure and manage such networks. Relying on humans to manage such complex and dynamic networks is becoming unsustainable. Network automation promises to reduce the cost of administration and maintenance of network infrastructure, by offering networks the capability to manage themselves. Network automation is the ability of the network to manage itself. Various standardization organizations are taking the initiative in introducing network automation, such as European Telecommunication Standardization Institute (ETSI). ETSI is leading the standardization activities for network automation. It has provided different versions of reference architecture called generic autonomic network architecture (GANA), which describes a four-level abstraction for network-management decision elements (DEs), protocol level, function level, node level, and network level. In this article, we review and survey the existing works before and after the introduction of software-defined networking (SDN) and network-function-virtualization (NFV). We relate the main trending paradigms being followed, such as SDN, NFV, machine learning (ML), microservices, multiagent system (MAS), containerization, and cloudification, as a pivotal enabler of full network automation. We also discuss the autonomic architectures proposed in the literature. Finally, we presented possible future research directions and challenges that need to be tackled to progress in achieving full network automation.},
keywords={Automation;Internet of Things;Computer architecture;Market research;Software;Monitoring;Cloud computing;Autonomic networking;machine learning;multiagent system (MAS);network function virtualization;network management system (NMS);network softwarization;software-defined networking (SDN)},
doi={10.1109/JIOT.2021.3075901},
ISSN={2327-4662},
month={Aug},}
@ARTICLE{9090830,
author={Zhang, Dan and Woo, Simon S.},
journal={IEEE Access}, title={Real Time Localized Air Quality Monitoring and Prediction Through Mobile and Fixed IoT Sensing Network},
year={2020},
volume={8},
number={},
pages={89584-89594},
abstract={Air pollution and its harm to human health has become a serious problem in many cities around the world. In recent years, research interests in measuring and predicting the quality of air around people has spiked. Since the Internet of Things (IoT) has been widely used in different domains to improve the quality life for people by connecting multiple sensors in different places, it also makes the air pollution monitoring more easier than before. Traditional way of using fixed sensors cannot effectively provide a comprehensive view of air pollution in people's immediate surroundings, since the closest sensors can be possibly miles away. Our research focuses on modeling the air quality pattern in a given region by adopting both fixed and moving IoT sensors, which are placed on vehicles patrolling around the region. With our approach, a full spectrum of how air quality varies in nearby regions can be analyzed. We demonstrate the feasibility of our approach in effectively measuring and predicting air quality using different machine learning algorithms with real world data. Our evaluation shows a promising result for effective air quality monitoring and prediction for a smart city application.},
keywords={Sensors;Monitoring;Air pollution;Atmospheric modeling;Pollution measurement;Atmospheric measurements;Time-series prediction;air quality measurement;machine learning},
doi={10.1109/ACCESS.2020.2993547},
ISSN={2169-3536},
month={},}
@INPROCEEDINGS{8555810,
author={Urošević, Vladimir and Andrić, Marina and Vukićević, Milan and Tatsiopoulos, Christos},
booktitle={2018 26th International Conference on Software, Telecommunications and Computer Networks (SoftCOM)}, title={A Highly Configurable Flexible Analytic Model for MCI/Frailty Risk Detection in Age-friendly Cities},
year={2018},
volume={},
number={},
pages={1-6},
abstract={The global human population is aging rapidly, however, living longer does not necessarily mean living healthy, active and independent life. The emerging disruptive technologies like the Internet of Things (IoT) are proving instrumental in addressing this prominent societal challenge. Urban IoT infrastructures, designed to support the Smart City vision, enable capturing of personal data for analyzing behaviour of elderly people. Activities within the Horizon 2020 City 4Age project are aimed at showing that behavioral analysis can help detect and mitigate risks of Mild Cognitive Impairment (MCI) and frailty problems of elderly. This paper presents the latest developments in extending the configurability and flexibility of the comprehensive City4Age computational model for risk detection. The proposed model extensions have demonstrated seamless adaptation to specific characteristics of various urban contexts, as well as seamless “pluggable” integration of various combined evolving and extendable parameterized algorithm implementations and methods for behaviour variation and risk recognition, based on relevant statistical and machine learning techniques.},
keywords={Analytical models;Adaptation models;Computational modeling;Senior citizens;Software algorithms;Sociology;Software;geriatric model;data-driven development;flexible modelling;configurability;temporal analysis},
doi={10.23919/SOFTCOM.2018.8555810},
ISSN={1847-358X},
month={Sep.},}
@INPROCEEDINGS{8746459,
author={Seymer, Paul and Wijesekera, Duminda and Kan, Cing-Dao},
booktitle={2019 IEEE 89th Vehicular Technology Conference (VTC2019-Spring)}, title={Secure Outdoor Smart Parking Using Dual Mode Bluetooth Mesh Networks},
year={2019},
volume={},
number={},
pages={1-7},
abstract={Efficient parking lot automation continues to be a focal point of smart city initiatives. Most existing unattended parking lots suffer from a lack of seamless automation, instead deploying ticketing and payment at ingress and egress points or other systems with heavy user involvement that often form bottlenecks. Similarly, many lots use per-space sensing with expensive networking and power requirements simply to determine space occupancy. Parking solutions that are free from the delay caused by this user burden and infrastructure could experience faster occupancy turnover with lower cost. An ongoing challenge in developing seamless parking experiences is the detection and identification of vehicles in parking spaces without the need for complex and expensive per-space occupancy detection technology. We develop a smart parking solution that uses a single low-power wireless radio technology to seamlessly perform parked vehicle localization and transport of sensor data for use by a central management system. Our solution uses a sparse, self-forming network of dual-mode Bluetooth sensors within a parking area to observe the presence of customized authenticated Bluetooth Low-Energy (BLE) beacons placed in vehicles parked in the lot. Our localization technique is based on radio fingerprinting using Received Signal Strength Indication (RSSI) values from the beacon, and a random forest machine learning classifier that predicts where the vehicle is parked based on its fingerprint. We implemented our solution in Python on commodity Internet of Things (IoT) hardware and deployed it to a 105 space outdoor parking lot. There, we conducted fingerprinting and prediction experiments. Our results show that our exact-space prediction model evaluates with a high accuracy using radio training data (90.7% correctly identified), and our in-vehicle tests show a promising result (69.17% accurate up to and including 3 spaces away), even without employing tuning and data filtering techniques. This encouraging result shows that localization using Bluetooth is a viable means of managing parked vehicles, with great promise for a variety of future parking management applications.},
keywords={Bluetooth;Feature extraction;Space vehicles;Cryptography;Authentication;Mesh networks;Advertising},
doi={10.1109/VTCSpring.2019.8746459},
ISSN={2577-2465},
month={April},}
@INPROCEEDINGS{7943147,
author={Vashishth, Vidushi and Chhabra, Anshuman and Sood, Apoorvi},
booktitle={2017 7th International Conference on Cloud Computing, Data Science Engineering - Confluence}, title={A predictive approach to task scheduling for Big Data in cloud environments using classification algorithms},
year={2017},
volume={},
number={},
pages={188-192},
abstract={There have been many recent developments in integrating the Cloud with the Internet of T hings (IoT) which comprise of up and coming technologies such as Smart Cities and Smart devices. This federation has resulted in research being directed towards further integration of Big Data with the Cloud, as IoT devices consisting of such technologies generate a continuous stream of sensor data. Thus, in this paper, we seek to present a predictive approach to task scheduling with the aim of reducing the overhead incurred when Big Data is processed on the Cloud. Subsequently, we wish to increase both the efficiency and reliability of the Cloud network while handling Big Data. We present a method of using classification in Machine Learning as a tool for scheduling tasks and assigning them to Virtual Machines (VMs) in the Cloud environment. A comparative study is undertaken to observe which brand of classifiers perform optimally in the given scenario. Particle Swarm Optimization (PSO) is used to generate the dataset which is used to train the classifiers. A number of classification algorithms such as Naive Bayes, Random Forest and K Nearest Neighbor are then used to predict the VM best suited to a task in the test dataset.},
keywords={Cloud computing;Classification algorithms;Processor scheduling;Algorithm design and analysis;Big Data;Resource management;Prediction algorithms;Cloud computing;Big Data;Machine Learning;Classification;Internet of Things;Task Scheduling},
doi={10.1109/CONFLUENCE.2017.7943147},
ISSN={},
month={Jan},}
@INPROCEEDINGS{8637446,
author={Ghosh, Arindam and Pramanik, Prithviraj and Banerjee, Kartick Das and Roy, Ashutosh and Nandi, Subrata and Saha, Sujoy},
booktitle={2018 IEEE International Conference on Data Mining Workshops (ICDMW)}, title={Analyzing Correlation Between Air and Noise Pollution with Influence on Air Quality Prediction},
year={2018},
volume={},
number={},
pages={913-918},
abstract={Air and noise pollution are two major factors that determine the quality of life of the people living in cities. The prime reasons for the rise of air and noise pollution are due to imbalanced urbanization, unregulated increase in traffic and inorganic industrialization. These have resulted in compromising the well-being of the citizens. In this context, the concept of smart cities has been developed. They inherently have the ability to sense and respond to the challenges which characterizes regular cities with the help of embedded intelligence. It has become important to monitor the environmental parameters for policy-making, planning and for making smart cities livable and sustainable. In a bid to make a smart city, in this work, we have studied the spatio-temporal relationship between air and noise pollution in four different locations and have also evaluated the effect of noise in predicting Air Quality(AQ). Data acquisition has been done using customized, self-developed CO_2; NO_2; PM2:5, humidity, temperature and intensity of noise. To determine the relationship between air and noise pollution, we have used Pearson correlation. Results show a strong association between the two types of pollution. For predicting the air quality, the impact of noise pollution as a feature has been investigated using three different machine learning models which are Decision Tree, Random Forest and K-Nearest Neighbors. When applicable, the results show that if noise pollution is used as a feature, we get a prediction accuracy of upto 95% which is an improvement of 5% on an average},
keywords={Pollution;Correlation;Monitoring;Air quality;Temperature sensors;Atmospheric modeling;Air Pollution, Noise Pollution, Air Quality, Sensors, Correlation, Prediction},
doi={10.1109/ICDMW.2018.00133},
ISSN={2375-9259},
month={Nov},}
@INPROCEEDINGS{8855451,
author={Wu, Jiang and Di, Bang and Sun, Jianhua and Chen, Hao and Zhong, Xionghu and Hu, DaoKun and Huang, Chenlin},
booktitle={2019 IEEE 21st International Conference on High Performance Computing and Communications; IEEE 17th International Conference on Smart City; IEEE 5th International Conference on Data Science and Systems (HPCC/SmartCity/DSS)}, title={A Fast and Secure GPU Memory Allocator},
year={2019},
volume={},
number={},
pages={146-153},
abstract={Graphics Processing Units (GPUs) is widely used to perform general purpose computing in many areas such as scientific computing and deep learning. In order to offer more flexibility in GPU programming, dynamic memory allocation has been introduced in GPU programming frameworks such as CUDA. However, the dynamic memory allocator in CUDA is inefficient in highly concurrent environments. Thus, several dynamic memory allocators are recently proposed to enhance the performance of dynamic memory management. However, these allocators only focus on achieving higher performance but ignore the security issues. In this paper, we propose a fast and secure GPU memory allocator based on ScatterAlloc. In order to efficiently protect against memory attacks such as buffer overflows, our allocator consists of several key techniques including canary-based memory protection (two options such as detection-on-free and always-on-detection are provided), address compression, and over-provisioning. Experimental results show that the allocator can effectively detect buffer overflow errors while it is still approximately 100 times faster than the CUDA toolkit allocator.},
keywords={Graphics processing units;Resource management;Instruction sets;Dynamic scheduling;Security;Memory management;Real-time systems;Dynamic Memory Allocation, CUDA, Buffer Overflow, GPGPU},
doi={10.1109/HPCC/SmartCity/DSS.2019.00035},
ISSN={},
month={Aug},}
@INPROCEEDINGS{8560202,
author={Zheng, Wei and Cao, ShiChao and Gao, ZhiQian and Wu, XiaoXue and Ding, Qian},
booktitle={2018 IEEE SmartWorld, Ubiquitous Intelligence Computing, Advanced Trusted Computing, Scalable Computing Communications, Cloud Big Data Computing, Internet of People and Smart City Innovation (SmartWorld/SCALCOM/UIC/ATC/CBDCom/IOP/SCI)}, title={The Performance Evaluation Model of Intel SGX-Based Data Protection},
year={2018},
volume={},
number={},
pages={1289-1292},
abstract={The hardware-level security protection method represented by SGX is the main trend of security guarantee for data processing of cloud tenants. However, different protection strategies have a great impact on the application performance of the tenants. How to make effective balance between the protection cost and the security enhancement has become the key problem in the decision of the data processing hardware security protection. Aiming at this problem, we will study an effective method to balance SGX application performance overhead and security enhancements, which is based on multi-objective optimization. Because there are many factors that cause performance losses in SGX applications, the performance of CPU intensive programs and concurrent programs is difficult to accurately estimate. We analyze the invisible relationship between performance factors and performance losses with deep learning theory, then we build a high precision SGX application performance loss estimation model which can adapt to different application scenarios.},
keywords={Cloud Security, performance model, Intel SGX},
doi={10.1109/SmartWorld.2018.00224},
ISSN={},
month={Oct},}
@INPROCEEDINGS{8560178,
author={Shi, Rongrong and Wang, Yiming and Chen, Yifeng and Wu, Cheng},
booktitle={2018 IEEE SmartWorld, Ubiquitous Intelligence Computing, Advanced Trusted Computing, Scalable Computing Communications, Cloud Big Data Computing, Internet of People and Smart City Innovation (SmartWorld/SCALCOM/UIC/ATC/CBDCom/IOP/SCI)}, title={An Efficient Recognition Method for Incomplete Iris Image Based on CNN Model},
year={2018},
volume={},
number={},
pages={1154-1159},
abstract={The iris of the eye is a research hot spot in the field of biometric identification because of its uniqueness, non-contact and bioactivity. The incompleteness of the iris caused by the acquisition process has brought great uncertainty to the subsequent iris region segmentation and iris code matching, thereby reducing the efficiency of iris recognition. This paper describes a deep convolution neural network model with adaptive incomplete iris preprocessing mechanism. Based on the normalization of the iris image, the incomplete iris preprocessing mechanism adopts the method of making the inner circle or the outer circle. The iris region can be segmented by the line fitting and the circle fitting method for extracting as many iris features as possible. The deep convolution neural network then uses pixel coding of Irregular iris regions to complete the iris pattern classification. The model fully utilizes the characteristics of deep learning, local feature characterization and weight sharing, and realizes the problem of using large sample to compensate the incomplete feature of local feature. The experimental results show that this method has significant accuracy improvement compared with the traditional algorithms.},
keywords={iris recognition;iris image normalization;convolution neural network;algorithm},
doi={10.1109/SmartWorld.2018.00200},
ISSN={},
month={Oct},}
@INPROCEEDINGS{9604520,
author={Raza, Syed Arshad and Siddiqui, Atiq W.},
booktitle={2021 IEEE SmartWorld, Ubiquitous Intelligence Computing, Advanced Trusted Computing, Scalable Computing Communications, Internet of People and Smart City Innovation (SmartWorld/SCALCOM/UIC/ATC/IOP/SCI)}, title={Discovering COVID-19 Induced Shifts in Refined Petroleum Products Demand: A Sequence-based Time Series Mining Approach},
year={2021},
volume={},
number={},
pages={642-646},
abstract={COVID-19 has directly affected the refined petroleum products industry due to significant changes in energy usage patterns induced by local and global responses to the pandemic. With its onset and persistence, these products faced systematic shifts in their demand patterns, which need to be discovered and monitored by oil producers to respond appropriately to market needs. We perform a mid-term (annual scale) time series mining using a machine-learning-based approach of matrix profile to primarily unveil the post-COVID-19 behavior of the demand generation processes of four petroleum products, including gasoline, distillate fuel oils, kerosene-type jet fuel, and propane. The results indicate that some refined products have responded robustly to the pandemic, while major changes in the demand patterns for other products are evident. This study's outcome will help refineries lay out short to medium-term plans and make prediction-based adjustments to their production and refining processes.},
keywords={COVID-19;Technological innovation;Pandemics;Oils;Time series analysis;Refining;Data mining;Refining Petroleum Products;Time Series Mining;Discords;Semantic Segmentation;Gasoline;Kerosene;Fuel Oils},
doi={10.1109/SWC50871.2021.00095},
ISSN={},
month={Oct},}
@INPROCEEDINGS{8560120,
author={Li, Ke and Wen, Hui and Li, Hong and Zhu, Hongsong and Sun, Limin},
booktitle={2018 IEEE SmartWorld, Ubiquitous Intelligence Computing, Advanced Trusted Computing, Scalable Computing Communications, Cloud Big Data Computing, Internet of People and Smart City Innovation (SmartWorld/SCALCOM/UIC/ATC/CBDCom/IOP/SCI)}, title={Security OSIF: Toward Automatic Discovery and Analysis of Event Based Cyber Threat Intelligence},
year={2018},
volume={},
number={},
pages={741-747},
abstract={To adapt to the rapidly evolving landscape of cyber threats, efficient collection and analysis of cyber threat intelligence (CTI) is crucial for safety staff to implement a proactive cyber defense, such as security hardening or incident responding. However, with the exponential increase in open source information, cyber threat intelligence becomes increasing hard to gather from wild open source by human efforts. Furthermore, autonomous determining cyber intelligent information with respect to relevant threats reported or newsletter remains a challenge, largely due to the lack of corresponding principles or rules to analyze semantics and contextual information that present in textual representations. To overcome these limitation, this paper propose a security open source intelligence framework (OSIF) to automatically analyze unstructured text for generating event based cyber threat intelligent. It uses several technologies such as natural language process, machine learning and data mining to extract cybersecurity event related information (device, organization, location, etc.) and Common Vulnerabilities and Exposure (CVE) for threat actor profiling. Finally, we perform a comprehensive structural and conceptual evaluation of critical threats on dataset that collected from dozens of websites. And the experiments that conducted on the dataset demonstrate that our approach have a considerable performance.},
keywords={cyber threat intelligent;text analytics;nature language process;information extraction},
doi={10.1109/SmartWorld.2018.00142},
ISSN={},
month={Oct},}
@INPROCEEDINGS{8560263,
author={Ma, Liqiu and Bao, Yuanyuan and Chen, Wai},
booktitle={2018 IEEE SmartWorld, Ubiquitous Intelligence Computing, Advanced Trusted Computing, Scalable Computing Communications, Cloud Big Data Computing, Internet of People and Smart City Innovation (SmartWorld/SCALCOM/UIC/ATC/CBDCom/IOP/SCI)}, title={An Autonomous Model Construction Mechanism in Dynamic Sensor Networks},
year={2018},
volume={},
number={},
pages={1676-1683},
abstract={Internet-of-Things (IoT) plays a critical role in many intelligent scenarios, such as home automation, health care, connected vehicles and so on. Taking into account of several practical concerns like privacy, latency and battery issues, embedding machine learning algorithms in IoT devices is a potentially effective solution. Due to the fact that IoT devices are deployed in highly dynamic environment, reconstruction capability for model which can make the devices adapt to changes of the environment is imperative. In this paper, we design a novel autonomous model training mechanism based on curriculum learning which can deduce a set of labels to rebuild a new model adapting to dynamic environment. In particular, the label learning adopts a three-step strategy, including (1) curriculum generation, (2) curriculum refinement, and (3) curriculum teaching. In the first step, we design a reliability evaluation mechanism to pick out a high-quality set with higher reliability over the original curriculum. In the second step, based on confusion matrix and label propagation, we adjust the labels of the curriculum to accomplish the curriculum refinement. In the third step, the labels of the low-quality set will be adjusted based on the refined curriculum. Then an accurate training set can be obtained, based on which a new model can be built. Extensive experiments on three datasets demonstrate the efficiency of our approach compared to the state-of-the-art methods.},
keywords={curriculum learning;autonomous training;label propagation;dynamic sensor networks},
doi={10.1109/SmartWorld.2018.00285},
ISSN={},
month={Oct},}
@INPROCEEDINGS{9060228,
author={Zhang, Xuejun and Chen, Qian and Peng, Xiaohui and Jiang, Xinlong},
booktitle={2019 IEEE SmartWorld, Ubiquitous Intelligence Computing, Advanced Trusted Computing, Scalable Computing Communications, Cloud Big Data Computing, Internet of People and Smart City Innovation (SmartWorld/SCALCOM/UIC/ATC/CBDCom/IOP/SCI)}, title={Differential Privacy-Based Indoor Localization Privacy Protection in Edge Computing},
year={2019},
volume={},
number={},
pages={491-496},
abstract={With the popularity of smart devices and the widespread use of the Wi-Fi-based indoor localization, edge computing is becoming the mainstream paradigm of processing massive sensing data to acquire indoor localization service. However, these data which were conveyed to train the localization model unintentionally contain some sensitive information of users/devices, and were released without any protection may cause serious privacy leakage. To solve this issue, we propose a lightweight differential privacy-preserving mechanism for the edge computing environment. We extend ε-differential privacy theory to a mature machine learning localization technology to achieve privacy protection while training the localization model. Experimental results on multiple real-world datasets show that, compared with the original localization technology without privacy-preserving, our proposed scheme can achieve high accuracy of indoor localization while providing differential privacy guarantee. Through regulating the value of ε, the data quality loss of our method can be controlled up to 8.9% and the time consumption can be almost negligible. Therefore, our scheme can be efficiently applied in the edge networks and provides some guidance on indoor localization privacy protection in the edge computing.},
keywords={Privacy;Training;Fingerprint recognition;Edge computing;Cloud computing;Indoor localization, Differential privacy, Privacy preserving, Edge computing.},
doi={10.1109/SmartWorld-UIC-ATC-SCALCOM-IOP-SCI.2019.00125},
ISSN={},
month={Aug},}
@INPROCEEDINGS{8855445,
author={Li, Zhenhao and Hu, Wei and Chen, Shuang},
booktitle={2019 IEEE 21st International Conference on High Performance Computing and Communications; IEEE 17th International Conference on Smart City; IEEE 5th International Conference on Data Science and Systems (HPCC/SmartCity/DSS)}, title={Design and Implementation of CNN Custom Processor Based on RISC-V Architecture},
year={2019},
volume={},
number={},
pages={1945-1950},
abstract={With the rapid development of CNN(convolutional neural networks), the traditional CPU platform can not make full use of the parallelism of CNN. We decide to adopt a new and popular processor architecture: the risc-v architecture for experimental design. In this paper, a new convolutional neural network processor is designed based on risc-v architecture. The processor can take advantage of the parallelism of CNN and is more flexible. This paper completely designed a CNN processor based on the risc-v architecture. The processor uses a classic five-stage pipeline structure, and implements instruction buffer memory and data buffer memory, and adds peripherals such as FLASH, SRAM, and SDRAM. And, this paper designed custom instructions. Given the convolution operation frequently occurring in CNN, vector store instruction, vector load instruction, vector addition instruction, and convolution operation instruction are designed to accelerate the execution of the convolution process. The design has passed the simulation experiment. It can not only complete the general instructions but also run the custom instructions. The final simulation test verified the correctness of the design.},
keywords={Convolution;Computer architecture;Instruction sets;Decoding;Acceleration;Hardware;Parallel processing;RISC-V processor;CNN;custom instruction;SoC technology},
doi={10.1109/HPCC/SmartCity/DSS.2019.00268},
ISSN={},
month={Aug},}
@INPROCEEDINGS{8560283,
author={Shi, Depeng and Zhou, Jiehan and Xu, Jirui and Yang, Jun and Li, Xuekun and Zhao, Zeming and Chen, Junchuang and Rong, Yiming},
booktitle={2018 IEEE SmartWorld, Ubiquitous Intelligence Computing, Advanced Trusted Computing, Scalable Computing Communications, Cloud Big Data Computing, Internet of People and Smart City Innovation (SmartWorld/SCALCOM/UIC/ATC/CBDCom/IOP/SCI)}, title={Machine Vision-Based Segmentation and Classification Method for Intelligent Roller Surface Monitoring},
year={2018},
volume={},
number={},
pages={1811-1817},
abstract={The surface quality of steel rollers is a key factor determining the quality of final products such as metal sheets and foils in the rolling industry. It is important to examine the surface quality of rollers since rollers with optical defects will always duplicate the defects onto the metal sheet or foil during rolling. The typical optical defects of rollers after finish grinding include speckles, chatter marks, swirl marks and combination of all of the above. They can hardly be modeled or shaped by the approach of micro topography or SEM (scanning electrical microscope). In this paper, an on-site machine vision system is firstly applied for stable inspection for the optical defects on roller surfaces. Then, an improved optical defect segmentation algorithm is developed based on the active contour model and the images including chatter marks and swirl marks. The normal surface state is classified by the combination of methods of Gabor filters, KPCA method and ELM neural networks. Finally, experiment are carried out to verify the efficiency of the improved segmentation method and the recognition rate of the combined classification algorithm.},
keywords={optical defect detection, machine vision, big data, roller surface monitoring},
doi={10.1109/SmartWorld.2018.00305},
ISSN={},
month={Oct},}
@INPROCEEDINGS{8397419,
author={Felmlee, Diane and Lupu, Emil and McMillan, Cassie and Karafili, Erisa and Bertino, Elisa},
booktitle={2017 IEEE SmartWorld, Ubiquitous Intelligence Computing, Advanced Trusted Computed, Scalable Computing Communications, Cloud Big Data Computing, Internet of People and Smart City Innovation (SmartWorld/SCALCOM/UIC/ATC/CBDCom/IOP/SCI)}, title={Decision-making in policy governed human-autonomous systems teams},
year={2017},
volume={},
number={},
pages={1-6},
abstract={Policies govern choices in the behavior of systems. They are applied to human behavior as well as to the behavior of autonomous systems but are defined differently in each case. Generally humans have the ability to interpret the intent behind the policies, to bring about their desired effects, even occasionally violating them when the need arises. In contrast, policies for automated systems fully define the prescribed behavior without ambiguity, conflicts or omissions. The increasing use of AI techniques and machine learning in autonomous systems such as drones promises to blur these boundaries and allows us to conceive in a similar way more flexible policies for the spectrum of human-autonomous systems collaborations. In coalition environments this spectrum extends across the boundaries of authority in pursuit of a common coalition goal and covers collaborations between human and autonomous systems alike. In social sciences, social exchange theory has been applied successfully to explain human behavior in a variety of contexts. It provides a framework linking the expected rewards, costs, satisfaction and commitment to explain and anticipate the choices that individuals make when confronted with various options. We discuss here how it can be used within coalition environments to explain joint decision making and to help formulate policies re-framing the concepts where appropriate. Social exchange theory is particularly attractive within this context as it provides a theory with “measurable” components that can be readily integrated in machine reasoning processes.},
keywords={Autonomous systems;Decision making;Military computing;Collaboration;Biological system modeling;Mathematical model;Protocols;Decision making;autonomous systems;social-exchange theory},
doi={10.1109/UIC-ATC.2017.8397419},
ISSN={},
month={Aug},}
@INPROCEEDINGS{9604425,
author={Sudharsan, Bharath and Yadav, Piyush and Breslin, John G. and Intizar Ali, Muhammad},
booktitle={2021 IEEE SmartWorld, Ubiquitous Intelligence Computing, Advanced Trusted Computing, Scalable Computing Communications, Internet of People and Smart City Innovation (SmartWorld/SCALCOM/UIC/ATC/IOP/SCI)}, title={Train++: An Incremental ML Model Training Algorithm to Create Self-Learning IoT Devices},
year={2021},
volume={},
number={},
pages={97-106},
abstract={The majority of Internet of Things (IoT) devices are tiny embedded systems with a micro-controller unit (MCU) as its brain. The memory footprint (SRAM, Flash, and EEPROM) of such MCU-based devices is often very limited, restricting onboard Machine Learning (ML) model training for large trainsets with high feature dimensions. To cope with memory issues, the current edge analytics approaches train high-quality ML models on the cloud GPUs (uses large volume historical data), then deploy the deep optimized version of the resultant models on edge devices for inference. Such approaches are inefficient in concept drift situations where the data generated at the device level vary frequently, and trained models are clueless on how to behave if previously unseen data arrives. In this paper, we present Train++, an incremental training algorithm that trains ML models locally at the device level (e.g., on MCUs and small CPUs) using the full n-samples of high-dimensional data. Train++ transforms even the most resource-constrained MCU-based IoT edge devices into intelligent devices that can locally build their own knowledge base on-the-fly using the live data, thus creating smart self-learning and autonomous problem-solving devices. Train++ algorithm is extensively evaluated on 5 popular MCU-boards, using 7 datasets of varying sizes and feature dimensions. A few exciting findings when analyzing the evaluation results are: (i) The proposed method reduces the onboard binary classifier training time by ≈ 10 - 226 sec across various commodity MCUs; (ii) Train++ can infer on MCUs for the entire test set in real-time of 1 ms; (iii) The accuracy improved by 5.15 - 7.3% since the incremental characteristic of Train++ enabled the loading of full n-samples of the high-dimensional datasets even on MCUs with only a few hundred kBs of memory.},
keywords={Training;Performance evaluation;Solid modeling;Embedded systems;Data models;Real-time systems;Inference algorithms;Intelligent Microcontrollers;Online Learning;Optimization;Incremental Learning;Edge Computing},
doi={10.1109/SWC50871.2021.00023},
ISSN={},
month={Oct},}
@INPROCEEDINGS{8622854,
author={Chen, Shizhao and Fang, Jianbin and Chen, Donglin and Xu, Chuanfu and Wang, Zheng},
booktitle={2018 IEEE 20th International Conference on High Performance Computing and Communications; IEEE 16th International Conference on Smart City; IEEE 4th International Conference on Data Science and Systems (HPCC/SmartCity/DSS)}, title={Adaptive Optimization of Sparse Matrix-Vector Multiplication on Emerging Many-Core Architectures},
year={2018},
volume={},
number={},
pages={649-658},
abstract={Sparse matrix vector multiplication (SpMV) is one of the most common operations in scientific and high-performance applications, and is often responsible for the application performance bottleneck. While the sparse matrix representation has a significant impact on the resulting application performance, choosing the right representation typically relies on expert knowledge and trial and error. This paper provides the first comprehensive study on the impact of sparse matrix representations on two emerging many-core architectures: the Intel's Knights Landing (KNL) XeonPhi and the ARM-based FT-2000Plus (FTP). Our large-scale experiments involved over 9,500 distinct profiling runs performed on 956 sparse datasets and five mainstream SpMV representations. We show that the best sparse matrix representation depends on the underlying architecture and the program input. To help developers to choose the optimal matrix representation, we employ machine learning to develop a predictive model. Our model is first trained offline using a set of training examples. The learned model can be used to predict the best matrix representation for any unseen input for a given architecture. We show that our model delivers on average 95% and 91% of the best available performance on KNL and FTP respectively, and it achieves this with no runtime profiling overhead.},
keywords={Sparse matrices;Random access memory;Two dimensional displays;Predictive models;Arrays;Sparse matrix vector multiplication, Performance optimization, Many-Cores, Performance analysis},
doi={10.1109/HPCC/SmartCity/DSS.2018.00116},
ISSN={},
month={June},}
@INPROCEEDINGS{8560029,
author={Wang, Hongyu and Zhu, Ping and Zou, Xueqiang and Qin, Sujuan},
booktitle={2018 IEEE SmartWorld, Ubiquitous Intelligence Computing, Advanced Trusted Computing, Scalable Computing Communications, Cloud Big Data Computing, Internet of People and Smart City Innovation (SmartWorld/SCALCOM/UIC/ATC/CBDCom/IOP/SCI)}, title={An Ensemble Learning Framework for Credit Card Fraud Detection Based on Training Set Partitioning and Clustering},
year={2018},
volume={},
number={},
pages={94-98},
abstract={The popularity of credit card has greatly facilitated the transactions between merchants and cardholders. However, credit card fraud has been derived, which results in losses of billions of euros every year. In recent years, machine learning and data mining technology have been widely used in fraud detection and achieved favorable performances. Most of these studies use the technology of under-sampling to deal with the high imbalance of credit card data. However, it will potentially discard some relevant training samples which will weaken the ability of the classifier. In this paper, we propose an ensemble learning framework based on training set partitioning and clustering. It turns out that the proposed framework not only ensures the integrity of the sample features, but also solves the high imbalance of the dataset. A main feature of our framework is that every base estimator can be trained in parallel. This improves the efficiency of the framework. We show the effectiveness of our proposed ensemble framework by experimental results on a real credit card transaction dataset.},
keywords={credit card fraud detection, highly unbalanced, division, clustering, ensemble},
doi={10.1109/SmartWorld.2018.00051},
ISSN={},
month={Oct},}
@INPROCEEDINGS{8622795,
author={Wang, Chenxu and Cai, Tingting and Suo, Guang and Lu, Yutong and Zhou, Enqiang},
booktitle={2018 IEEE 20th International Conference on High Performance Computing and Communications; IEEE 16th International Conference on Smart City; IEEE 4th International Conference on Data Science and Systems (HPCC/SmartCity/DSS)}, title={DistForest: A Parallel Random Forest Training Framework Based on Supercomputer},
year={2018},
volume={},
number={},
pages={196-204},
abstract={The random forest algorithm is an ensemble classifier algorithm based on the decision tree model. It has a wide range of applications in machine learning, data mining and other fields. With the emergence of big data age, the training process of random forest becomes very lengthy. Most studies speed up the training of random forests through small clusters or high performance device, however, few pay attention to high performance supercomputers. In this paper, we propose a parallel random forest training framework on supercomputers called DistForest which can utilize multiple nodes to train random forest with large data sets concurrently. Firstly, DistForest applies master-slave architecture in which system will select some nodes as the primary node to distribute the large tasks to other slave nodes. Secondly, DistForest exploits a multilevel parallel strategy which pushes small tasks to a task queue rather than continues to distribute them among other slaves. Thirdly, DistForest can use the heterogeneous architecture of supercomputers to accelerated training process. Finally, DistForest can also balance computing tasks between devices with different computing ability. Our performance results on Tianhe-2 show our implementation can acquire very high performance improvement.},
keywords={Training;Supercomputers;Task analysis;Decision trees;Vegetation;Radio frequency;Forestry;Parallel Random Forest;Supercomputers;Speed up;Framework},
doi={10.1109/HPCC/SmartCity/DSS.2018.00057},
ISSN={},
month={June},}
@INPROCEEDINGS{8560318,
author={Yang, Yizhuo and Yu, Hongtao and Huang, Ruiyang and Ming, Tuosiyu},
booktitle={2018 IEEE SmartWorld, Ubiquitous Intelligence Computing, Advanced Trusted Computing, Scalable Computing Communications, Cloud Big Data Computing, Internet of People and Smart City Innovation (SmartWorld/SCALCOM/UIC/ATC/CBDCom/IOP/SCI)}, title={A Fusion Information Embedding Method for User Identity Matching Across Social Networks},
year={2018},
volume={},
number={},
pages={2030-2035},
abstract={Aiming at the deficiencies of low accuracy and difficulty in obtaining data for existing cross social network user identity matching algorithms, an algorithm of user identity matching across social networks based on information fusion representation was proposed. Firstly, the seed nodes were used to transform the cross-network problem into a single network problem by using the network merging algorithms. Then the username information was turned to vectors and merged with the topology vector. Finally, with the network representation learning method, account nodes' vectors with information of usernames and topology were acquired for the mission of user identity matching. Experimental results showed that the average F1 measure reached 79.7%, which is improved by 7.3%-28.8% compared with traditional machine learning algorithms and the existing other two algorithms. It can be seen that our algorithm can effectively improve the performance of user identity matching.},
keywords={user identity matching;fusion information;social network;network embedding},
doi={10.1109/SmartWorld.2018.00340},
ISSN={},
month={Oct},}
@INPROCEEDINGS{9637750,
author={Wang, Xinyu and Zheng, Xiaolong and Du, Peilun and Liu, Liang and Ma, Huadong},
booktitle={2021 IEEE 18th International Conference on Mobile Ad Hoc and Smart Systems (MASS)}, title={Occlusion Resilient Adversarial Attack for Person Re-identification},
year={2021},
volume={},
number={},
pages={527-535},
abstract={Deep learning-based person re-identification (Re-ID) methods have achieved the significant performance of matching person images across camera views, which plays an important role in the construction of the smart city. Recent works of adversarial attacks have explored the serious vulnerability of deep Re-ID systems. However, existing attacks are performed with idealized conditions and ignore the real-world environments, such as occlusion caused by walking habits. In this paper, we propose a two-stage method to perform an occlusion resilient adversarial attack for better evaluation of deep Re-ID systems. Specifically, we construct the occlusion template from the observation and statics of pedestrian walking habits. Then, we design a partition training strategy for a better combination of occluded and exposed adversarial patches. During the training, we introduce contextual loss to penalize the semantic distance of attacked images with the same identity. The extensive experiments on Market1501 demonstrate the performance of our method.},
keywords={Training;Legged locomotion;Smart cities;Conferences;Semantics;Cameras;Robustness;n/a},
doi={10.1109/MASS52906.2021.00071},
ISSN={2155-6814},
month={Oct},}
@INPROCEEDINGS{9676241,
author={Snehi, Manish and Bhandari, Abhinav},
booktitle={2021 10th International Conference on System Modeling Advancement in Research Trends (SMART)}, title={An SDN/NFV based Intelligent Fog Architecture for DDoS Defense in Cyber Physical Systems},
year={2021},
volume={},
number={},
pages={229-234},
abstract={The Internet of Things (IoT) has garnered considerable interest in recent years as its technical capabilities have facilitated the creation of a diverse variety of commercial revenue models and services (e.g., medical cyber-physical systems, smart agriculture, Industry 4.0, smart cities, etc.). However, the security gaps in intelligent systems continue to be a significant source of concern. Malevolent attackers employ attacks like distributed denial of service (DDoS) to weaken system availability. To mitigate attack traffic, adopting a modern Software-defined Networked backbone and Network Function Virtualization (NFV) paradigm has proven to be a potential approach. This paper offers a comprehensive examination of the cutting-edge defense solutions driven by contemporary SDN/NFV technologies, highlighting the key limitations and future scope. The paper also presents the multi-dimensional view of the defense architecture by examining the Internet of Things (IoT) scenarios, defense strategies, the role of Fog to overcome research gaps, and leveraging SDN/NFV architecture for an intelligent defense solution. Furthermore, the paper examines the profound network backbone and offers the intelligent Machine and Deep learning-based distributed DDoS defense solution deployed in the Fog layer. The article concludes with an evaluation of open issues and research prospects for vulnerability apprehension in Smart systems. Keywords—SDN, Software Defined Network, NFV, Network Functions Virtualization, Cloud, IoT, Fog Computing, Distributed Denial of Service, DDoS},
keywords={Cloud computing;Smart cities;Biological system modeling;Computer architecture;Cyber-physical systems;Turning;Network function virtualization},
doi={10.1109/SMART52563.2021.9676241},
ISSN={2767-7362},
month={Dec},}
@INPROCEEDINGS{9670975,
author={Bajaj, Karan and Sharma, Bhisham and Singh, Raman},
booktitle={2021 International Conference on Artificial Intelligence and Machine Vision (AIMV)}, title={Edge, Fog and Cloud-based Smart Communications for IoT Network based Services amp; Applications},
year={2021},
volume={},
number={},
pages={1-5},
abstract={The Internet of Things is increasing its span in our daily life, intelligent homes, agriculture, industries and smart cities are few popular fields among application areas. Use of smart devices connected over the network can be seen in the mentioned fields. Vast data is collected through the connected devices using wireless sensors and then transmitted over the network to the edge and cloud for the computation. The increase in sensory devices lead to more data generation thereby there is also raise in wireless terminals as now more data is generated. This brings some challenges that need to be resolved, like processing delay leading to more time consumption, data bandwidth issues affecting data transfer rate and computation capability. It has been identified that massive work needs to be researched on communication medium to provide IoT services among the applications. Various frameworks like TelcoFog, Edge framework, CoSMOS, ROUTER, FogFlow, Deep Learning and IoTecture were studied and their results were analysed. This paper aims to understand the role of different communication channels for edge/fog and cloud-based computing, and understand their role in different computation methodologies.},
keywords={Wireless sensor networks;Cloud computing;Protocols;Smart cities;Scalability;Network architecture;Throughput;Internet of Things;cloud/edge computing;5G;communication channels},
doi={10.1109/AIMV53313.2021.9670975},
ISSN={},
month={Sep.},}
@ARTICLE{9245538,
author={Dallaqua, Fernanda Beatriz Jordan Rojas and Faria, Fabio Augusto and Fazenda, Álvaro Luiz},
journal={IEEE Geoscience and Remote Sensing Letters}, title={Building Data Sets for Rainforest Deforestation Detection Through a Citizen Science Project},
year={2022},
volume={19},
number={},
pages={1-5},
abstract={Originally, the ForestEyes project aims to detect deforestation in tropical forests based on citizen science (CS) and machine learning (ML) approaches, in which the volunteers analyze and label segments of remote sensing images to build new training sets for creating different classification models. In previous work, only three modules related to CS have been proposed. In this letter, two new modules are created: 1) organization and selection and 2) ML. Therefore, these modules turn the ForestEyes project a more robust system in the deforestation detection task, building high-confidence labeled collections, increasing the monitoring coverage, and decreasing volunteer dependence. Performed experiments show that volunteers create better data sets than those based on automatic PRODES-based approaches, selecting the most relevant samples and discarding noisy segments that might disrupt ML techniques. Finally, the results showed the feasibility of allying CS with ML for rainforest deforestation detection task.},
keywords={Forestry;Image segmentation;Remote sensing;Training;Earth;Artificial satellites;Task analysis;Active learning (AL);image classification;machine learning (ML);supervised learning},
doi={10.1109/LGRS.2020.3032098},
ISSN={1558-0571},
month={},}
@INPROCEEDINGS{9110366,
author={Sawabe, Anan and Iwai, Takanori and Satoda, Kozo and Nakao, Akihiro},
booktitle={NOMS 2020 - 2020 IEEE/IFIP Network Operations and Management Symposium}, title={Edge Concierge: Democratizing Cost-Effective and Flexible Network Operations using Network Layer AI at Private Network Edges},
year={2020},
volume={},
number={},
pages={1-7},
abstract={We observe two major revolutionary trends in net-work operations: democratization of cost-effective and flexible communication means for vertical players, such as public safety, by private mobile networking combined with edge computing, and automatic and autonomic network operations empowered by Artificial Intelligence (AI). Further innovations are required for making private networking readily available for vertical players that are reluctant to acquire expertise in complex network operations. We propose Edge Concierge, of which concept is to democratize cost-effective and flexible network operations using network layer AI at private network edges. Edge Concierge assists smart network operations for private mobile network operators and energy saving by changing working state of AI-empowered anomaly detection applications by network layer AI. We also employ unsupervised machine learning using Hidden Markov Model (HMM) for estimating contexts by solely observing net-work traffic at mobile edge computing (MEC) middle boxes. In detail, we design a system of real-time and self-learning context estimation by a multi-level probabilistic state transition model trained by unsupervised learning, which is implemented in a commodity PC. In order to evaluate our proposed system, we take public safety context of smart cities as an example use case and show the benefits.},
keywords={Technological innovation;Multi-access edge computing;Smart cities;Image edge detection;Hidden Markov models;Probabilistic logic;Market research},
doi={10.1109/NOMS47738.2020.9110366},
ISSN={2374-9709},
month={April},}
@INPROCEEDINGS{9615332,
author={Kampars, Janis and Tropins, Dainis and Matisons, Ralfs},
booktitle={2021 62nd International Scientific Conference on Information Technology and Management Science of Riga Technical University (ITMS)}, title={A Review of Application Layer Communication Protocols for the IoT Edge Cloud Continuum},
year={2021},
volume={},
number={},
pages={1-6},
abstract={The IoT technological paradigm has become widespread and has found its place within industries such as smart cities, smart grids, smart homes, physical security, e-health, asset management, and logistics. Around 50 billion various devices will soon be connected to the Internet. A hot topic within the IoT field is edge computing, which adds extra computing capacity to the edge allowing to perform computationally intensive operations like execution of Deep Neural Networks possibly requiring specialized devices equipped with Graphical Processing Units. Optimal construction of solutions that span the IoT, edge, and cloud computing layers is still an open research area, and it is believed that edge computing is in its infancy. This article reviews application layer protocols that can be used to interconnect entities belonging to the three previously mentioned layers.},
keywords={Performance evaluation;Cloud computing;Protocols;Smart cities;Smart homes;Smart grids;Security;AMQP;CoAP;DDS;edge computing;gRPC;IoT;MQTT;XMPP},
doi={10.1109/ITMS52826.2021.9615332},
ISSN={},
month={Oct},}
@INPROCEEDINGS{9454644,
author={Cerbulescu, Catalin Constantin and Marian, Marius and Ganea, Eugen},
booktitle={2021 22nd International Carpathian Control Conference (ICCC)}, title={IoT Big Data Management for Improved Response Time},
year={2021},
volume={},
number={},
pages={1-6},
abstract={Internet of Things (IoT) impact in our daily life quickly evolves from recording basic data to process and take decisions based on complex data. Data provided by various sources (Health Care IoT, life quality, smart cities etc) came in many formats and will be used for statistical analysis and decision making, often based on data evolution and machine learning. Decisions involving data analysis over a huge database can be very time consuming. In critical time situations, system response time needs to be highly improved. This paper discusses a proposed architecture, suitable to improve the response time on systems using data analysis and decision based on data evolution. Simulation results for a system using sensors, gateways and persistence layers are presented and discussed. Considering all sensor data is sent to a non-relational database (NoSQL) suitable to store various data formats, this paper discusses the particularities of using IoT programmable gateways to send data used in critical time analysis to a fast relational database (SQL) database. In such databases, queries are very fast and, as a result, the decisions based on data evolution have an improved time response. Analysis to detect critical data patterns is triggered when data is inserted in SQL database or based on a time interval. Both strategies are discussed and analysed.},
keywords={Data analysis;Databases;Smart cities;Logic gates;Sensor systems;Data models;Time factors;IoT;data centralization;data analysis;critical response time},
doi={10.1109/ICCC51557.2021.9454644},
ISSN={},
month={May},}
@ARTICLE{7917244,
author={Lee, Keonsoo and Choi, Hyung Oh and Min, Se Dong and Lee, Jinseok and Gupta, Brij B. and Nam, Yunyoung},
journal={IEEE Access}, title={A Comparative Evaluation of Atrial Fibrillation Detection Methods in Koreans Based on Optical Recordings Using a Smartphone},
year={2017},
volume={5},
number={},
pages={11437-11443},
abstract={This paper evaluated three methods of atrial fibrillation (AF) detection in Korean patients using 149 records of photoplethysmography signals from 148 participants: the k-nearest neighbor (kNN), neural network (NN), and support vector machine (SVM) methods. The 149 records are preprocessed to calculate the root-mean square of the successive differences in the R-R intervals and Shannon entropy which are validated from x-means and Massachusetts Institute of Technology and Beth Israel Hospital database for the features for AF detection. A smartphone camera was used to obtain photoplethysmography signals. Clinicians labeled 29 records by referring to the electrocardiogram signals. These labeled records were used as a ground truth set to evaluate the accuracy of each method. In the experiments, the kNN, NN, and SVM methods achieved 98.65%, 99.32%, and 97.98% accuracies, respectively.},
keywords={Heart beat;Electrocardiography;Artificial neural networks;Support vector machines;Cameras;Atrial fibrillation;Arrhythmia;atrial fibrillation;machine learning;photoplethysmography;smartphone},
doi={10.1109/ACCESS.2017.2700488},
ISSN={2169-3536},
month={},}
@INPROCEEDINGS{7838195,
author={Bordogna, Gloria and Frigerio, Luca and Cuzzocrea, Alfredo and Psaila, Giuseppe},
booktitle={2016 15th IEEE International Conference on Machine Learning and Applications (ICMLA)}, title={An Effective and Efficient Similarity-Matrix-Based Algorithm for Clustering Big Mobile Social Data},
year={2016},
volume={},
number={},
pages={514-521},
abstract={Nowadays a great deal of attention is devoted to the issue of supporting big data analytics over big mobile social data. These data are generated by modern emerging social systems like Twitter, Facebook, Instagram, and so forth. Mining big mobile social data has been of great interest, as analyzing such data is critical for a wide spectrum of big data applications (e.g., smart cities). Among several proposals, clustering is a well-known solution for extracting interesting and actionable knowledge from massive amounts of big mobile (geo-located) social data. Inspired by this main thesis, this paper proposes an effective and efficient similarity-matrix-based algorithm for clustering big mobile social data, called TourMiner, which is specifically targeted to clustering trips extracted from tweets, in order to mine most popular tours. The main characteristic of TourMiner consists in applying clustering over a well-suited similarity matrix computed on top of trips. A comprehensive experimental assessment and analysis over Twitter data finally comfirms the benefits coming from our proposal.},
keywords={Trajectory;Clustering algorithms;Mobile communication;Semantics;Algorithm design and analysis;Data mining;Proposals;Big Data Analytics; Big Mobile Social Data; Big Data Clustering},
doi={10.1109/ICMLA.2016.0091},
ISSN={},
month={Dec},}
@INPROCEEDINGS{8862443,
author={Tripathi, Dipty and Maurya, Ashish Kumar and Chaturvedi, Amrita and Tripathi, Anil Kumar},
booktitle={2019 International Conference on Machine Learning, Big Data, Cloud and Parallel Computing (COMITCon)}, title={A Study of Security Modeling Techniques for Smart Systems},
year={2019},
volume={},
number={},
pages={87-92},
abstract={The term “smart” has been used in many ways for describing systems and infrastructure such as smart city, smart home, smart grid, smart meter, etc. These systems may lie in the domain of critical security systems where security can be estimated in terms of confidentiality, integrity and some cases may involve availability for protection against the theft or damage of system resources as well as disruption of the system services. Although, in spite of, being a hot topic to enhance the quality of life, there is no concrete definition of what smart system is and what should be the characteristics of it. Thus, there is a need to identify what these systems actually are and how they can be designed securely. This work firstly attempts to describe attributes related to the smartness to define smart systems. Furthermore, we propose a secure smart system development life cycle, where the security is weaved at all the development phase of smart systems according to principles, guidelines, attack patterns, risk, vulnerability, exploits, and defined rules. Finally, the comparative study is performed for evaluation of traditional security modeling techniques for early assessment of threats and risks in smart systems.},
keywords={Security;Unified modeling language;Analytical models;Fault trees;Risk management;Software;Stochastic processes;Smart Systems;Smartness;Security Modeling;Threat Modeling},
doi={10.1109/COMITCon.2019.8862443},
ISSN={},
month={Feb},}
@INPROCEEDINGS{9350396,
author={Bin Ahammed, Tareq and Patgiri, Ripon},
booktitle={2020 Advanced Communication Technologies and Signal Processing (ACTS)}, title={6G and AI: The Emergence of Future Forefront Technology},
year={2020},
volume={},
number={},
pages={1-6},
abstract={The next generation 6G communication network would be a six sense communication network that would add a value of ambient intelligence. With the advancement in every sector of Artificial Intelligence, 6G will fabricate a new utility as "Augmentation of Human Intelligence" and this utility creation is driving the new generation network. Artificial Intelligence and 6G communication technology will be revolutionized from connecting the things to connecting intelligence. In this paper, we present the bigger picture of artificial intelligence subdivision that makes a revolt with the help of the 6G Communication Technology. We keep our focus straight to the deploying of right application that solves human needs and problems as well as create values for new technologies. Machine learning, Deep learning, Federated learning, Big Data and many more aspects are brought out together to prepare the network for the era of human and machine augmentation. 6G will fully deplorable in an AI ecosystem and will use on-premises Cloud that will likely be the outcome for future industrial automation.},
keywords={6G mobile communication;Smart cities;Quality of service;Communications technology;Communication networks;Quality of experience;Artificial intelligence;Artificial intelligence;Edge AI;Quality of Life;Quality of Experience;Cognitive intelligence;Federated AI;Black-box;Data Science;Big Data.Unnamed Aerial Vehicles},
doi={10.1109/ACTS49415.2020.9350396},
ISSN={},
month={Dec},}
@INPROCEEDINGS{7868439,
author={Saha, Himadri Nath and Mandal, Abhilasha and Sinha, Abhirup},
booktitle={2017 IEEE 7th Annual Computing and Communication Workshop and Conference (CCWC)}, title={Recent trends in the Internet of Things},
year={2017},
volume={},
number={},
pages={1-4},
abstract={The Internet of Things (IoT) has become a hot topic in the present tech-driven world. A strong framework of cloud computing, backed up by a seamless blending of sensors and actuators with the environment around us, is making this “network of networks of autonomous objects” a reality. From smart wearables to smart cities, from domestic life to industries, the IoT is expanding itself to different areas. According to Gartner Inc., the IoT will include 26 billion units installed by 2020. Smart security solutions, smart home automation, smart health care, smart wearables etc. are in-trend applications of IoT, and by the near future we expect to see its application to a city's transportation system or smart power grids. This paper presents a brief overview on different trends of the IoT and also discusses about the effects of the IoT on our day-to-day life. It also discusses the importance of cloud computing, autonomous control, artificial intelligence in the context of the IoT. Lastly, it's concluded with the need of synchronization of the Internet, wireless sensors and actuators and distributed computing for successfully enabling technologies for the IoT.},
keywords={The Internet of Things;Smart devices;Cloud Computing;Wireless Networks;Machine Learning;Embedded Systems;Automation},
doi={10.1109/CCWC.2017.7868439},
ISSN={},
month={Jan},}
@INPROCEEDINGS{8806189,
author={Nguyen, Huy and Le, Nam Tuan and Lam, Pham Tung and Hoan, Nguyen Cong and Vu, Thanh Luan and Thieu, Minh Duc and Jang, Yeong Min},
booktitle={2019 Eleventh International Conference on Ubiquitous and Future Networks (ICUFN)}, title={The Next Generation Architecture of Low Power Wide Area Network for Energy Platform},
year={2019},
volume={},
number={},
pages={144-147},
abstract={The low power wide area has a lot of attraction to research from many researchers in the world due to their ability to offer connectivity to low-power devices over a large area. With the Internet of Things (IoT) systems, the low-power wide area technologies contributed a critical position. It can be complemented and replaced the conventional wireless technologies for smart city, wireless sensor network, smart grid.... In this paper, we survey several LPWA technologies like Sigfox, LoRa, Narrow Bandwidth IoT... Besides that, we proposed the next generation architecture of LPWA network for energy platform using AI/Deep learning to reduce power consumption.},
keywords={Engines;Wireless communication;Logic gates;Cloud computing;Next generation networking;Computer architecture;Internet of Things;LPWA;Low-power;Low-power Wide Area;Internet of Energy;IoE},
doi={10.1109/ICUFN.2019.8806189},
ISSN={2165-8536},
month={July},}
@ARTICLE{9239305,
author={Ye, Famao and Luo, Wei and Dong, Meng and Li, Dajun and Min, Weidong},
journal={IEEE Geoscience and Remote Sensing Letters}, title={Content-Based Remote Sensing Image Retrieval Based on Fuzzy Rules and a Fuzzy Distance},
year={2022},
volume={19},
number={},
pages={1-5},
abstract={The methods in remote sensing image retrieval (RSIR) usually search the whole retrieval data set in the retrieval process, which takes much time and is unnecessary. To reduce the overall search time, this letter proposes a new retrieval scheme based on fuzzy rules. The proposed method calculates the fuzzy class membership of images using two ways. The first way predicts the fuzzy class membership by convolutional neural network (CNN). The other uses the image-to-class distance that is a distance between an image and each class on the training data set. The two fuzzy class memberships are used to measure the classification confidence, and a query image is classified into three fuzzy sets, namely, “low classification confidence,” “medium classification confidence,” and “high classification confidence,” based on the classification confidence. The fuzzy rules are built according to fuzzy classification to choose the search space for each fuzzy set. The final search space is determined by the two search spaces obtained by fuzzy rules. Moreover, the fuzzy distance between a query image and a retrieved image is used to improve the retrieval performance, which is calculated according to their fuzzy class memberships and the Euclidean distance between the two images. The experimental results on University of California, Merced data set (UCMD) and PatternNet databases show that our proposed method can not only enhance the retrieval performance but also reduce the search time in comparison to other state-of-the-art techniques.},
keywords={Remote sensing;Fuzzy sets;Image retrieval;Feature extraction;Convolutional neural networks;Probability distribution;Euclidean distance;Convolutional neural network (CNN);fuzzy rule;fuzzy weight;remote sensing image retrieval (RSIR)},
doi={10.1109/LGRS.2020.3030858},
ISSN={1558-0571},
month={},}
@ARTICLE{8826330,
author={Jung, Younghwa and Seo, Seung-Woo and Kim, Seong-Woo},
journal={IEEE Transactions on Intelligent Transportation Systems}, title={Curb Detection and Tracking in Low-Resolution 3D Point Clouds Based on Optimization Framework},
year={2020},
volume={21},
number={9},
pages={3893-3908},
abstract={Curb detection and tracking is an essential component of autonomous vehicle operation in urban environments. Detecting curbs is a particularly challenging task in urban environments that contain countless dynamic objects. Previous studies have approached curb detection using different types of sensor such as cameras, radar, and LIDAR. Among these, LIDAR sensors have superior advantages in regard to detecting curbs because of their robustness in different weather conditions and they can provide accurate distance measurements. Previous methods based on LIDAR have exploited high-resolution 3D point clouds using high-cost LIDARs. However, the processing of large volumes of information is inefficient for autonomous driving technologies because of real time constraints. This paper presents a novel real-time curb detection and tracking algorithm that makes use of a low-resolution LIDAR. The proposed method consists of three steps. First is the extraction of curb candidates based on Principal Component Analysis (PCA) and Density-Based Spatial Clustering of Applications with Noise (DBSCAN). Second is the selection of the optimal candidate using an optimization framework. Lastly is the tracking of the detected curbs. In the tracking module, we use a combination of spatial consistency and validation gate to track the curb in the occlusion region with dynamic objects. Experiments on a public dataset show that the proposed method achieved 91.54% and 89.76% F1 score on the straight and curved road while running at about 18 ms per frame, thereby outperforming the state-of-the-art by a large margin. In addition, we integrated the proposed method with the localization module of our autonomous driving platform. The localization module integrated with the proposed method reduces the positional and lateral root mean square (RMS) error of the vehicle localization by 3.58% and 6.68% respectively. In addition, we compare this method with a deep neural network based method from the perspective of a safety-critical system such as self-driving cars.},
keywords={Laser radar;Three-dimensional displays;Radar tracking;Roads;Feature extraction;Autonomous vehicles;Vehicle dynamics;Curb detection and tracking;deep neural networks;black box problem;optimization},
doi={10.1109/TITS.2019.2938498},
ISSN={1558-0016},
month={Sep.},}
@ARTICLE{9109639,
author={Rocca, Paolo and Anselmi, Nicola and Benoni, Arianna and Massa, Andrea},
journal={IEEE Transactions on Antennas and Propagation}, title={Probabilistic Interval Analysis for the Analytic Prediction of the Pattern Tolerance Distribution in Linear Phased Arrays With Random Excitation Errors},
year={2020},
volume={68},
number={12},
pages={7866-7878},
abstract={A statistical approach based on the interval analysis (IA) is proposed for the analysis of the effects, on the radiation patterns radiated by phased arrays, of random errors and tolerances in the amplitudes and phases of the array-elements excitations. Starting from the efficient, reliable, and inclusive computation of the bounds of the complex-valued interval array pattern function by means of IA, an analytic method is presented to yield closed-form expressions for the probability of occurrence of a user-chosen value of the power pattern or of its features within the corresponding IA-derived bounds. A set of numerical examples is reported and discussed to assess the reliability of the proposed probabilistic interval analysis (PIA) method with the results from Monte Carlo simulations as well as to point out its effectiveness and potentialities/advantages/efficiency in real applications of great industrial interest.},
keywords={Phased arrays;Linear antenna arrays;Artificial neural networks;Antenna radiation patterns;Probabilistic logic;Amplitude and phase excitation errors;linear arrays;phased array (PA) antenna;probabilistic interval analysis (PIA);tolerance analysis},
doi={10.1109/TAP.2020.2998924},
ISSN={1558-2221},
month={Dec},}
@ARTICLE{9179752,
author={Kim, Mintae and Lee, Sangheon and Oh, Yeongtaek and Choi, Hyunseung and Kim, Wooju},
journal={IEEE Access}, title={A Near-Real-Time Answer Discovery for Open-Domain With Unanswerable Questions From the Web},
year={2020},
volume={8},
number={},
pages={158346-158355},
abstract={With the proliferation of question and answering (Q&A) services, studies on building a knowledge base (KB) using various information extraction (IE) methodologies from unstructured data on the Web have received significant attention. Existing IE approaches, including machine reading comprehension (MRC), can find the correct answer to a question if the correct answer exists in the document. However, most are prone to extracting incorrect answers rather than producing no answers when the correct answer does not exist in the given documents. This problem is likely to cause serious real-world problems when we apply such technologies to practical services such as AI speakers. We propose a novel open-domain IE system to alleviate the weaknesses of previous approaches. The proposed system integrates an elaborated document selection, sentence selection, and knowledge extraction ensemble method to obtain high specificity while maintaining a realistically achievable level of precision. Based on this framework, we extract answers on Korean open-domain user queries from unstructured documents collected from multiple Web sources. For evaluating our system, we build a benchmark dataset with the SKTelecom AI Speaker log. The baseline models KYLIN infobox generator and BiDAF were used to evaluate the performance of the proposed approach. The experimental results demonstrate that the proposed method outperforms the baseline models and is practically applicable to real-world services.},
keywords={Data mining;Encyclopedias;Poles and towers;Electronic publishing;Internet;Data models;Information extraction system;knowledge base;natural language processing;neural networks;real time systems},
doi={10.1109/ACCESS.2020.3020245},
ISSN={2169-3536},
month={},}
@ARTICLE{9269970,
author={Kim, Dasol and Kim, Mintae and Kim, Wooju},
journal={IEEE Access}, title={Wafer Edge Yield Prediction Using a Combined Long Short-Term Memory and Feed- Forward Neural Network Model for Semiconductor Manufacturing},
year={2020},
volume={8},
number={},
pages={215125-215132},
abstract={In semiconductor manufacturing, maintaining a high yield and ensuring accurate yield prediction are considerably important for improving productivity, customer satisfaction, and enhancing profitability. Despite its importance and merits, achieving wafer yield prediction with high quality and accuracy is challenging. In this paper, we propose a method for wafer edge yield prediction using a combined long short-term memory (LSTM) and feed-forward neural network (FFNN) model. Unlike previous research, we focus on the edge yield because of the higher yield loss at the wafer edge. The combined LSTM-FFNN model uses a dataset divided into two types according to data characteristics. Time-series data are used in the case of LSTM, and non-time-series data are fed into the FFNN. When preparing the time-series data, comprising data related to the equipment and chambers, data of different chambers do not overlap, thereby rendering them as independent entities. The proposed model outperforms other models in terms of all evaluation metrics. The coefficient of determination of the proposed combined LSTM-FFNN model is 34.14%, which is almost 13% higher than that of the other compared models on average.},
keywords={Metrology;Semiconductor device modeling;Predictive models;Fabrication;Semiconductor device measurement;Sensors;Scanning electron microscopy;Feed-forward neural networks;long short-term memory;semiconductor manufacturing;wafer yield prediction},
doi={10.1109/ACCESS.2020.3040426},
ISSN={2169-3536},
month={},}
@ARTICLE{9171870,
author={Porcu, Simone and Floris, Alessandro and Voigt-Antons, Jan-Niklas and Atzori, Luigi and Möller, Sebastian},
journal={IEEE Transactions on Network and Service Management}, title={Estimation of the Quality of Experience During Video Streaming From Facial Expression and Gaze Direction},
year={2020},
volume={17},
number={4},
pages={2702-2716},
abstract={This article investigates the possibility to estimate the perceived Quality of Experience (QoE) automatically and unobtrusively by analyzing the face of the consumer of video streaming services, from which facial expression and gaze direction are extracted. If effective, this would be a valuable tool for the monitoring of personal QoE during video streaming services without asking the user to provide feedback, with great advantages for service management. Additionally, this would eliminate the bias of subjective tests and would avoid bothering the viewers with questions to collect opinions and feedback. The performed analysis relies on two different experiments: i) a crowdsourcing test, where the videos are subject to impairments caused by long initial delays and re-buffering events; ii) a laboratory test, where the videos are affected by blurring effects. The facial Action Units (AU) that represent the contractions of specific facial muscles together with the position of the eyes' pupils are extracted to identify the correlation between perceived quality and facial expressions. An SVM with a quadratic kernel and a k-NN classifier have been tested to predict the QoE from these features. These have also been combined with measured application-level parameters to improve the quality prediction. From the performed experiments, it results that the best performance is obtained with the k-NN classifier by combining all the described features and after training it with both the datasets, with a prediction accuracy as high as 93.9% outperforming the state of the art achievements.},
keywords={Streaming media;Quality of experience;Feature extraction;Electroencephalography;Two dimensional displays;Face;Brain modeling;Video streaming;quality of experience;facial expressions;gaze direction;machine learning;video key quality indicators;QoE estimation},
doi={10.1109/TNSM.2020.3018303},
ISSN={1932-4537},
month={Dec},}
@INPROCEEDINGS{8920530,
author={Nuseibeh, Bashar},
booktitle={2019 IEEE 27th International Requirements Engineering Conference (RE)}, title={Requirements We Live By},
year={2019},
volume={},
number={},
pages={1-1},
abstract={Enlightened requirements engineering (RE) researchers and practitioners generally accept that RE is as much about understanding the world as it is about understanding the software and systems that will be built to inhabit that world. As a result, the RE field has fostered a multi-disciplinary following of researchers and practitioners who are prepared to engage deeply in application domains, to apply a range of technical and socio-technical skills to understand those domains, and to accept that the outcome of an effective RE process may not deliver a software system at all. The RE community has also developed, deployed, and evaluated a wide range of contributions that reflect such enlightenment: conceptual models that reflect the relationships between the world and the machine, domain models and scenarios that reflect understandings of problem domains, and enterprise models that reflect the organisations and processes that build and deploy systems. All these in addition to the models that capture the all-important behaviour of systems and software. It seems to me however that the RE discipline is at a crossroads. The mechanics of the discipline appear to be established - much of the published research is now empirical - or technical, but only in so far as it responds to technological advances elsewhere, such as mobile and ubiquitous technologies represented by the Internet of Things, richer application domains such as Industrie 4.0 and Smart Cities, or more advanced computational techniques that are maturing, such AI, machine learning, and blockchains. As a community, we reassure ourselves that our discipline is safe and thriving, after all RE is a “forever problem”: all systems we wish to build will have requirements, now and forever. But this is to be complacent. RE has no protected status to study and deploy requirements. The formal models we elicit, design, and build are increasingly deployable by other disciplines, as are the values that we seek our modern, AI-driven systems to embody. A new and potentially radical re-framing of our discipline may be needed, and I will speculate what this may look like. It may require letting go of what we have considered to be the boundaries of our discipline, while embracing new but fluid boundaries. I have advocated and explored “software without boundaries” as one such framing that challenges the separation of `world and the machine', not because I don't accept the separation of the `what' and the `how', the `indicative' and the `optative', or the `problem' and the `solution', but because the world we live in no longer accepts these separations. Society, more often than not, does not think of systems, of technology, or indeed of software; it thinks of ways of working, ways of interacting, ways of living. Requirements, such as they are, are `requirements we live by' not requirements of systems in the world. At an extreme, if one believes the AI hype, `the world and the machine' will increasingly be replaced by the `world in the machine'. Where does the RE community stand on this, and what can this community do to contribute to the framing and solving of this new reality? My own work in recent years has evolved to reflect the above. I still revisit, with some pride, the `RE Roadmap' that Steve Easterbrook and I published in 2000 - many of the fundamental RE principles we presented still hold today. But I cringe at how we missed the changing nature of the world in which we operate: a world populated by autonomous and adaptive systems, populated by big data and associated analytics, and populated by stakeholders whose multiple perspectives reflect a multitude of ethical and social values, not all of which are wholesome, and many of which are actively subversive or malicious. My own research on security and privacy requirements only scratches the surface of this evolving reality. I invite the RE community to reflect on how it frames its own research in this context.},
keywords={Requirements engineering;Conferences;requirements-engineering;software-engineering,;security-and-privacy},
doi={10.1109/RE.2019.00009},
ISSN={2332-6441},
month={Sep.},}
@INPROCEEDINGS{8489260,
author={Pesaranghader, Ali and Viktor, Herna L. and Paquet, Eric},
booktitle={2018 International Joint Conference on Neural Networks (IJCNN)}, title={McDiarmid Drift Detection Methods for Evolving Data Streams},
year={2018},
volume={},
number={},
pages={1-9},
abstract={Increasingly, Internet of Things (IoT) domains, such as sensor networks, smart cities, and social networks, generate vast amounts of data. Such data are not only unbounded and rapidly evolving. Rather, the content thereof dynamically evolves over time, often in unforeseen ways. These variations are due to so-called concept drifts, caused by changes in the underlying data generation mechanisms. In a classification setting, concept drift causes the previously learned models to become inaccurate, unsafe and even unusable. Accordingly, concept drifts need to be detected, and handled, as soon as possible. In medical applications and emergency response settings, for example, change in behaviours should be detected in near real-time, to avoid potential loss of life. To this end, we introduce the McDiarmid Drift Detection Method (MDDM), which utilizes McDiarmid's inequality [1] in order to detect concept drift. The MDDM approach proceeds by sliding a window over prediction results, and associate window entries with weights. Higher weights are assigned to the most recent entries, in order to emphasize their importance. As instances are processed, the detection algorithm compares a weighted mean of elements inside the sliding window with the maximum weighted mean observed so far. A significant difference between the two weighted means, upper-bounded by the McDiarmid inequality, implies a concept drift. Our extensive experimentation against synthetic and real-world data streams show that our novel method outperforms the state-of-the-art. Specifically, MDDM yields shorter detection delays as well as lower false negative rates, while maintaining high classification accuracies.},
keywords={Microsoft Windows;Adaptive learning;Probability distribution;Real-time systems;Delays;Adaptation models;Memory management},
doi={10.1109/IJCNN.2018.8489260},
ISSN={2161-4407},
month={July},}
@ARTICLE{9146161,
author={Cygert, Sebastian and Czyżewski, Andrzej},
journal={IEEE Access}, title={Toward Robust Pedestrian Detection With Data Augmentation},
year={2020},
volume={8},
number={},
pages={136674-136683},
abstract={In this article, the problem of creating a safe pedestrian detection model that can operate in the real world is tackled. While recent advances have led to significantly improved detection accuracy on various benchmarks, existing deep learning models are vulnerable to invisible to the human eye changes in the input image which raises concerns about its safety. A popular and simple technique for improving robustness is using data augmentation. In this work, the robustness of existing data augmentation techniques is evaluated to propose a new simple augmentation scheme where during training, an image is combined with a patch of a stylized version of that image. Evaluation of pedestrian detection models robustness and uncertainty calibration under naturally occurring corruption and in realistic cross-dataset evaluation setting is conducted to show that our proposed solution improves upon previous work. In this paper, the importance of testing the robustness of recognition models is emphasized and it shows a simple way to improve it, which is a step towards creating robust pedestrian and object detection models.},
keywords={Robustness;Training;Data models;Uncertainty;Calibration;Computational modeling;Gaussian noise;Convolutional neural network;pedestrian detection;robustness;style-transfer;data augmentation;uncertainty estimation},
doi={10.1109/ACCESS.2020.3011356},
ISSN={2169-3536},
month={},}
@ARTICLE{9497092,
author={Kim, Seokyeon and Jang, Yun and Kim, Seung-Eock},
journal={IEEE Access}, title={Image-Based TF Colorization With CNN for Direct Volume Rendering},
year={2021},
volume={9},
number={},
pages={124281-124294},
abstract={In the direct volume rendering (DVR), it often takes a long time for a novice to manipulate the transfer function (TF) and analyze the volume data. To lessen the difficulty in volume rendering, several researchers have developed deep learning techniques. However, the existing techniques are not easy to apply directly to existing DVR pipelines. In this study, we propose an image-based TF colorization with CNN to automatically generate a direct volume rendering image (DVRI) similar to a target image. Our system includes CNN model training, TF labeling, image-based TF generation, and volume rendering by matching the target image. We introduce a technique for training CNN and labeling the TF with images similar to the input volume dataset. Moreover, we extract the primary colors from the target image according to the labels classified with the CNN model. We render the volume data with the TF to produce the DVRI reproducing the prominent colors in the target image.},
keywords={Rendering (computer graphics);Solid modeling;Training;Image color analysis;Transfer functions;Labeling;Data visualization;Volume rendering;CNN;TF colorization},
doi={10.1109/ACCESS.2021.3100429},
ISSN={2169-3536},
month={},}
@ARTICLE{9406879,
author={Firouzi, Farshad and Farahani, Bahar and Daneshmand, Mahmoud and Grise, Kathy and Song, Jaeseung and Saracco, Roberto and Wang, Lucy Lu and Lo, Kyle and Angelov, Plamen and Soares, Eduardo and Loh, Po-Shen and Talebpour, Zeynab and Moradi, Reza and Goodarzi, Mohsen and Ashraf, Haleh and Talebpour, Mohammad and Talebpour, Alireza and Romeo, Luca and Das, Rupam and Heidari, Hadi and Pasquale, Dana and Moody, James and Woods, Chris and Huang, Erich S. and Barnaghi, Payam and Sarrafzadeh, Majid and Li, Ron and Beck, Kristen L. and Isayev, Olexandr and Sung, Nakmyoung and Luo, Alan},
journal={IEEE Internet of Things Journal}, title={Harnessing the Power of Smart and Connected Health to Tackle COVID-19: IoT, AI, Robotics, and Blockchain for a Better World},
year={2021},
volume={8},
number={16},
pages={12826-12846},
abstract={As COVID-19 hounds the world, the common cause of finding a swift solution to manage the pandemic has brought together researchers, institutions, governments, and society at large. The Internet of Things (IoT), artificial intelligence (AI)-including machine learning (ML) and Big Data analytics-as well as Robotics and Blockchain, are the four decisive areas of technological innovation that have been ingenuity harnessed to fight this pandemic and future ones. While these highly interrelated smart and connected health technologies cannot resolve the pandemic overnight and may not be the only answer to the crisis, they can provide greater insight into the disease and support frontline efforts to prevent and control the pandemic. This article provides a blend of discussions on the contribution of these digital technologies, propose several complementary and multidisciplinary techniques to combat COVID-19, offer opportunities for more holistic studies, and accelerate knowledge acquisition and scientific discoveries in pandemic research. First, four areas, where IoT can contribute are discussed, namely: 1) tracking and tracing; 2) remote patient monitoring (RPM) by wearable IoT (WIoT); 3) personal digital twins (PDTs); and 4) real-life use case: ICT/IoT solution in South Korea. Second, the role and novel applications of AI are explained, namely: 1) diagnosis and prognosis; 2) risk prediction; 3) vaccine and drug development; 4) research data set; 5) early warnings and alerts; 6) social control and fake news detection; and 7) communication and chatbot. Third, the main uses of robotics and drone technology are analyzed, including: 1) crowd surveillance; 2) public announcements; 3) screening and diagnosis; and 4) essential supply delivery. Finally, we discuss how distributed ledger technologies (DLTs), of which blockchain is a common example, can be combined with other technologies for tackling COVID-19.},
keywords={COVID-19;Pandemics;Artificial intelligence;Medical services;Internet of Things;Vaccines;Robots;Artificial intelligence (AI);big data;blockchain;COVID-19;digital twin;eHealth;healthcare;Internet of Things (IoT);pandemic;robotics;wearable},
doi={10.1109/JIOT.2021.3073904},
ISSN={2327-4662},
month={Aug},}
@ARTICLE{9274475,
author={He, Wenji and Liu, Yifeng and Yao, Haipeng and Mai, Tianle and Zhang, Ni and Yu, F. Richard},
journal={IEEE Internet of Things Journal}, title={Distributed Variational Bayes-Based In-Network Security for the Internet of Things},
year={2021},
volume={8},
number={8},
pages={6293-6304},
abstract={The past few years have witnessed the compelling applications of the Internet of Things (IoT) in our daily life. The explosive growth of the number of IoT devices also presents a great challenge in network security, especially the DDoS attack. Current DDoS defense mechanisms adopted out-of-band architecture, which is accomplished by a process that receives monitoring data from routers and switches, then analyzes that flow data to detect attacks. However, facing IoT devices growing rapidly, this out-of-band architecture confronted with limited processing capacity, bandwidth resources, and service assurance problems. Recently, with the development of the programming switch, it opens up new possibilities for in-network DDoS detection, where the detection algorithms could be directly implemented inside the routers and switches. Benefit from switch processing performance, the in-network mechanism could achieve high scalability and line speed performance. Therefore, in this article, we design a machine learning-based in-network DDoS detection framework. We implement the lightweight variational Bayes algorithm in each switch to detect the anomaly traffic. Besides, considering the shortage of training data in each switch, a centralized platform is introduced to synchronize parameters among distributed switches to realize collaborative learning. Extensive simulations are conducted to evaluate our proposed algorithm in comparison to some state-of-the-art schemes.},
keywords={Computer crime;Security;Internet of Things;Denial-of-service attack;Monitoring;Performance evaluation;Optimization;DDoS;distributed variational Bayes;in-network security;Internet of Things (IoT)},
doi={10.1109/JIOT.2020.3041656},
ISSN={2327-4662},
month={April},}
@INPROCEEDINGS{9185774,
author={Le, Hoang Lam and Landa-Silva, Dario and Galar, Mikel and Garcia, Salvador and Triguero, I.},
booktitle={2020 IEEE Congress on Evolutionary Computation (CEC)}, title={A Hybrid Surrogate Model for Evolutionary Undersampling in Imbalanced Classification},
year={2020},
volume={},
number={},
pages={1-8},
abstract={Data preprocessing is a key stage in data mining that allows machine learning algorithms to obtain meaningful insights. Many preprocessing problems such as feature selection or instance selection can be modelled as optimisation/search problems. Evolutionary algorithms have traditionally excelled in this task when dealing with data of a moderate size. However, their application to large datasets typically involves very high computational costs. In this work, we propose a hybrid surrogate model for evolutionary undersampling in imbalanced classification problems. These are characterised by having a highly skewed distribution of classes in which evolutionary algorithms aim to balance the training data by selecting only the most relevant data. The proposed technique combines a two-stage clustering-based surrogate method with a windowing approach to quickly approximate fitness values of the chromosomes and accelerate the search. The experiments carried out in 44 standard imbalanced datasets show that the proposed hybrid surrogate model highly reduces the computational cost of the evolutionary algorithm without a considerable loss of performance.},
keywords={Biological cells;Computational modeling;Computational efficiency;Training data;Evolutionary computation;Training;Data models;Data Preprocessing;Evolutionary undersampling;Surrogate models;Imbalanced classification;Fitness approximation;Windowing},
doi={10.1109/CEC48606.2020.9185774},
ISSN={},
month={July},}
@INPROCEEDINGS{8961574,
author={Li, Yuxiao and Wang, Can and Su, Zhilong and duan, Shengcai and Wu, Xinyu},
booktitle={2019 IEEE International Conference on Robotics and Biomimetics (ROBIO)}, title={Dynamic Obstacle Tracking Based On High-Definition Map In Urban Scene},
year={2019},
volume={},
number={},
pages={461-466},
abstract={The application of High-Definition map can realize centimeter-level position in urban scenes, the development of deep learning has made great breakthrough in the point cloud dynamic obstacle recognition. All these technologies make obstacle detection and tracking based on High-Definition map effectively realize in the modern smart city scene. It is different from the previous obstacle detection and tracking methods based purely on vision the using of High-Definition map can provide high-precision positioning and reduce the difficulty of point cloud classification. The using of lidar also solves the problem of up-to-scale in dynamic detection. In this paper, we put forward a new Multi-camera Lidar Point Cloud Map, we complete the map at normal speed on the highway and get a satisfactory result. At the same time, we also find a robust combination of traditional kalman filter, Hungary algorithm and current deep learning to solve dynamic obstacle tracking and detection. The experimental results show that our system can effectively complete the special problem of generating map and target tracking on urban scene.},
keywords={High-Definition Map;Lidar;Obstacle Tracking},
doi={10.1109/ROBIO49542.2019.8961574},
ISSN={},
month={Dec},}
@ARTICLE{9210552,
author={Bucchiarone, Antonio and Battisti, Sandro and Marconi, Annapaola and Maldacea, Roberto and Ponce, Diego Cardona},
journal={IEEE Transactions on Intelligent Transportation Systems}, title={Autonomous Shuttle-as-a-Service (ASaaS): Challenges, Opportunities, and Social Implications},
year={2021},
volume={22},
number={6},
pages={3790-3799},
abstract={Providing mobility services effectively to residents and visitors is a complex socio-technical system task to city public managers. Smart mobility systems aim to support the efficient exploitation of city transport facilities and sustainable mobility within the urban environment. People need to travel quickly and conveniently between locations at different scales, ranging from a few blocks within a city to a journey across cities. At the same time, goods need to be timely delivered, considering both the users and the businesses' needs. Several cities indicated an interest in using Autonomous Vehicles (AV) for the “last-mile” mobility services in the last few years. With them, it seems to be easier to get people and goods around using fewer vehicles. In this context, Autonomous Shuttles (AS) are beginning to be thought of as a new mobility/delivery service into the city center where narrow streets are not easily served by traditional buses. They allow them to perform critical areas with minimal new infrastructure and reduce noise and pollution. The article analyses the state-of-art on autonomous shuttles by proposing four application scenarios targeting the last-mile delivery of goods, the tourist experiences, and the shared and integrated mobility. Furthermore, we contribute with the proposition of the Autonomous Shuttles-as-a service (ASaaS) concept as the key pillar for the realization of innovative and sustainable proximity mobility. Our research proposed new research challenges for ASaaS, and we discuss social implications and governance challenges that consider user engagement and sustainability. It also recommended extending new research to focus on simulation and machine learning techniques for last-mile mobility planning and explore the journeys tracking certification via artificial intelligence and blockchain-based techniques.},
keywords={Autonomous vehicles;Biological system modeling;Automobiles;Safety;Smart cities;Smart mobility;autonomous shuttles;proximity mobility;last mile delivery;mobility services},
doi={10.1109/TITS.2020.3025670},
ISSN={1558-0016},
month={June},}
@ARTICLE{8736758,
author={Jeong, Jinyong and Cho, Younghun and Kim, Ayoung},
journal={IEEE Robotics and Automation Letters}, title={The Road is Enough! Extrinsic Calibration of Non-overlapping Stereo Camera and LiDAR using Road Information},
year={2019},
volume={4},
number={3},
pages={2831-2838},
abstract={This letter presents a framework for the target-less extrinsic calibration of stereo cameras and light detection and ranging (LiDAR) sensors with a non-overlapping field of view (FOV). In order to solve extrinsic calibration problems under such challenging configurations, the proposed solution exploits road markings as static and robust features among the various objects that are present in urban environments. First, this study utilizes road markings that are commonly captured by the two sensor modalities to select informative images for estimating the extrinsic parameters. In order to accomplish stable optimization, multiple cost functions are defined, including normalized information distance (NID), edge alignment, and plane fitting cost. Therefore, a smooth cost curve is formed for global optimization to prevent convergence to the local optimal point. We further evaluate each cost function by examining parameter sensitivity near the optimal point. Another key characteristic of extrinsic calibration, repeatability, is analyzed by conducting the proposed method multiple times with varying randomly perturbed initial points.},
keywords={Calibration;Laser radar;Roads;Cameras;Optimization;Sensor systems;Calibration and identification;sensor fusion;range sensing;SLAM;field robots},
doi={10.1109/LRA.2019.2921648},
ISSN={2377-3766},
month={July},}
@ARTICLE{9344812,
author={Karim, Hassan and Rawat, Danda B.},
journal={IEEE Internet of Things Journal}, title={TollsOnly Please – Homomorphic Encryption for Toll Transponder Privacy in Internet of Vehicles},
year={2021},
volume={},
number={},
pages={1-1},
abstract={Cities have circumvented privacy norms and deployed sensors to track vehicles via toll transponders (like E-Zpass tags). The ethical problems regarding these practices have been highlighted by various privacy advocacy groups. The industry however, has yet to implement a standard privacy protection regime to protect users’ data. Further, existing risk management models do not adequately address user-controlled data sharing requirements. In this paper, we consider the challenges of protecting private data in the Internet of Vehicles (IoV) and mobile edge networks. Specifically, we present a privacy risk reduction model for electronic toll transponder data. We seek to preserve driver privacy while contributing to intelligent transportation infrastructure congestion automation schemes. We thus propose TollsOnly, a fully homomorphic encryption protocol. TollsOnly is expected to be a post-quantum privacy preservation scheme. It enables users to share specific data with smart cities via blockchain technology. TollsOnly protects driver privacy in compliance with the European General Data Protection Regulation (GDPR) and the California Consumer Privacy Act.},
keywords={Transponders;Data privacy;Privacy;Encryption;Vehicles;Cryptography;Security;IoV Privacy;Mobile Cyber Physical System;Homomorphic Encryption;Vehicle Data Privacy;Toll Data Privacy.},
doi={10.1109/JIOT.2021.3056240},
ISSN={2327-4662},
month={},}
@INPROCEEDINGS{9671703,
author={Shalaginov, Andrii and Grønli, Tor-Morten},
booktitle={2021 IEEE International Conference on Big Data (Big Data)}, title={Securing Smart Future: Cyber Threats and Intelligent Means to Respond},
year={2021},
volume={},
number={},
pages={2560-2564},
abstract={Smart Environments contribute towards better, user-friendly and automated environments; however, often lacking means of implementation of necessary cybersecurity measures capable of handling adversarial actions. In this paper we will introduce the anticipated cyber threats and corresponding ambition of the ENViSEC project that is aimed at enhancing the Smart Environments cybersecurity by introducing intelligent multi-agent data handling and cyber threats sharing. The potential of the project is to introduce situational awareness and data streams from Internet of Things ecosystem to offer a resilient response to cyber-attacks. This will ensure human-oriented awareness and early detection of cybercrimes in the era of Big Data. The new approach will include multi-level data aggregation and off-chip Machine Learning model training to reduce the overhead and latency of the IoT components yet guarantee the necessary level of hardening cybersecurity in a cross-sector context.},
keywords={Training;Renewable energy sources;Protocols;Microcontrollers;Urban areas;Big Data;Internet of Things;cybersecurity;artificial intelligence;smart cities},
doi={10.1109/BigData52589.2021.9671703},
ISSN={},
month={Dec},}
@INPROCEEDINGS{9566384,
author={Jelen, Goran and Babic, Jurica and Podobnik, Vedran},
booktitle={2021 6th International Conference on Smart and Sustainable Technologies (SpliTech)}, title={Contextual Prediction of On-Street and Off-Street Parking Lot Utilisation: An Opening Gate Towards Sustainable Parking},
year={2021},
volume={},
number={},
pages={1-6},
abstract={There is a growing requirement for sustainable management of urban assets with the help of insights and trends into parking utilisation. Also, there is a need for faster discovery of available parking spaces through parking utilisation prediction, thereby reducing the environmental impact in cities. This paper presents models for on-street and off-street contextual parking utilisation prediction, using weather data and point-of-interest data as contextual data. CatBoost and Random Forest as machine learning (ML) methods are used for contextual parking utilisation prediction, and data analysis showed that models with contextual data achieved better results for both types of parking lots. In both cases, on-street and off-street parking, the best model is based on CatBoost and point-of-interest data, achieving R2 92.84% in the case of on-street parking and 97.04% for off-street parking. Models with weather data performed lower than models with point-of-interests, where the difference between the models is 4.01% for on-street parking and 0.69% for off-street parking. The paper's overall conclusion is that ML models with contextual data are performing better than models without contextual data, and point-of-interest context provides better performance than weather data for both on-street and off-street parking.},
keywords={Training;Analytical models;Urban areas;Predictive models;Logic gates;Market research;Data models;Sustainable Parking;On-Street Parking;Off-Street Parking;Smart City;Data Science;Contextually Enriched Data},
doi={10.23919/SpliTech52315.2021.9566384},
ISSN={},
month={Sep.},}
@ARTICLE{9541001,
author={Liu, Ning and He, Tao and He, Suining and Niu, Qun},
journal={IEEE Transactions on Vehicular Technology}, title={Indoor Localization With Adaptive Signal Sequence Representations},
year={2021},
volume={70},
number={11},
pages={11678-11694},
abstract={Indoor location-based services (LBS) have exhibited large commercial and social values in smart cities, and urgent demands of which have spurred many localization techniques. Existing indoor localization approaches mostly rely on fingerprint techniques, leveraging either spatially discrete fingerprints or temporally consecutive ones for localization. However, these approaches often suffer from large errors or high time overhead in practice due to signal ambiguities or long input sequences. To overcome these drawbacks, this paper proposes a framework utilizing multiple adaptive representations of signal sequences for localization, where each representation indicates a corresponding signal structure with underlying location clues. As an example, the proposed approach takes geomagnetic signal sequences as input and infers location features from two intuitive representations, e.g., spatial and temporal ones. With adaptive signal representations, the proposed approach takes specifically optimized neural networks to extract corresponding location clues respectively and fuses them to generate more distinguishing features for more accurate localization. Furthermore, the ensemble learning mechanism is adopted in the approach and a weighted k-NN based location estimation algorithm is devised to enhance the robustness. Extensive experiments in three different trial sites demonstrate that the proposed approach outperforms state-of-the-art competing schemes by a wide margin, reducing mean localization error by more than 46%.},
keywords={Location awareness;Feature extraction;Correlation;Matrix converters;Estimation;Wireless fidelity;Robustness;indoor localization;geomagnetism;signal representations;neural networks;ensemble learning},
doi={10.1109/TVT.2021.3113333},
ISSN={1939-9359},
month={Nov},}
@INPROCEEDINGS{9668503,
author={Pati, Preeti Samhita and Sahoo, Shubham Somnath and Singhal, Chetna and Datta, Raja},
booktitle={2022 14th International Conference on COMmunication Systems NETworkS (COMSNETS)}, title={Efficient Last-Mile Link Adaptation in Next-Gen Wireless Heterogeneous Networks},
year={2022},
volume={},
number={},
pages={31-36},
abstract={The forthcoming generations of wireless networks have a high demand for reliable and enhanced data rate transmissions which are crucial for emerging smart cities. Thus, there is a need to develop efficient Link Adaptation (LA) for the last hop between end-users and the base stations in order to mitigate the severe interference resulting from the dense heterogeneous networks. We develop a Machine Learning (ML) based last-mile link adaptation method for a 5G wireless communication network. Dynamic selection of MCS for Resource Block (RB) allocation is efficient in terms of better network throughput and reduced BER which is verified through simulations for 5G New Radio (NR). We assume perfect channel estimation in our analysis. We have used a Deep Neural Network (DNN) model that dynamically selects the appropriate Modulation and Coding Scheme (MCS) ensuring 10 percent Bit Error Rate (BER) and maximizes the system spectral efficiency. Further, we evaluate the Signal to Interference and Noise Ratio (SINR) corresponding to varied channel states for different frequencies of operation and the DNN model selects the Channel Quality Indicator (CQI) corresponding to the optimal MCS available at the corresponding base stations for the end -users. This results in seamless connectivity for mobile users adapting to the last-mile link efficiently and achieving a higher downlink network throughput.},
keywords={Base stations;Adaptation models;Spectral efficiency;Wireless networks;Bit error rate;Neural networks;Interference;Link Adaptation (LA);Deep Neural Network (DNN);Modulation and Coding Scheme(MCS);Bit Error Rate(BER);Signal to Interference and Noise Ratio (SINR);Channel Quality Indicator (CQI);Network Throughput},
doi={10.1109/COMSNETS53615.2022.9668503},
ISSN={2155-2509},
month={Jan},}
@INPROCEEDINGS{9114681,
author={Ranjith, J. and Mahantesh, K.},
booktitle={2019 4th International Conference on Electrical, Electronics, Communication, Computer Technologies and Optimization Techniques (ICEECCOT)}, title={Privacy and Security issues in Smart Health Care},
year={2019},
volume={},
number={},
pages={378-383},
abstract={Smart healthcare is a practical way in health care industry to manage patient flow system intelligently. With recent advancements in cloud computing, Blockchain, Big data, Machine learning I can see a growth in smart healthcare. Adoption of smart healthcare decreases cost, very good disease management. However maintaining Privacy and security is challenging with increase in scalability of Wearable medical devices. Many of the design issues need a solution. In this paper I have made a systematic survey on different methodologies and approaches used by researchers to implement secure smart health care. I have also listed various privacy and security challenges need to be resolved during implementation of smart health care in smart cities.},
keywords={Privacy;Smart healthcare;Blockchain;Authentication;Cryptography;Smart Health Care;Blockchain;Cloud;Security;IoT},
doi={10.1109/ICEECCOT46775.2019.9114681},
ISSN={},
month={Dec},}
@ARTICLE{8344767,
author={Javed, Muhammad Awais and Hamida, Elyes Ben and Al-Fuqaha, Ala and Bhargava, Bharat},
journal={IEEE Intelligent Transportation Systems Magazine}, title={Adaptive Security for Intelligent Transport System Applications},
year={2018},
volume={10},
number={2},
pages={110-120},
abstract={The transportation system is gradually migrating toward autonomous, electric and intelligent vehicles. Wireless-enabled vehicles along with infrastructure units on the road are connected with traffic management centers that use intelligent data analysis tools to efficiently manage city's traffic. However, such wireless connectivity can make the ITS networks vulnerable to security threats; thus, impacting the application's reliability. On the other hand, the use of robust security techniques could hamper applications' quality of service (QoS). To understand the interplay between these two conflicting requirements, this article reviews the security and QoS design challenges in the ITS aspect of smart cities. Using an experimental test-bed, we evaluate the standard compliant security processing delays, develop an on-line tool that presents detailed security benchmark results, and study the impact of security on QoS using simulation results. We also discuss how machine learning based adaptive signature verification techniques can enhance QoS in ITS. We further present future opportunities to optimize the security-QoS balance for ITS applications.},
keywords={Quality of service;Time series analysis;Vehicle safety;Road traffic;Data integrity;Data privacy;Logistics;Vehicle routing;Traffic control},
doi={10.1109/MITS.2018.2806636},
ISSN={1941-1197},
month={Summer},}
@ARTICLE{9197677,
author={Razian, Mohammadreza and Fathian, Mohammad and Wu, Huaming and Akbari, Ahmad and Buyya, Rajkumar},
journal={IEEE Internet of Things Journal}, title={SAIoT: Scalable Anomaly-Aware Services Composition in CloudIoT Environments},
year={2021},
volume={8},
number={5},
pages={3665-3677},
abstract={Among the novel IT paradigms, cloud computing and the Internet of Things (CloudIoT) are two complementary areas designed to support the creation of smart cities and application services. The CloudIoT not only presents ubiquitous services through IoT nodes but it also provides virtually unlimited resources through services composition. The services composition problem aims to find a set of services among functionally equivalent services with different Quality of Service (QoS) concerning users' constraints. To this aim, previous studies calculate QoS values through service logs without considering the presence of anomalies in the existing QoS values; however, the dynamicity of distributed service environments and communication networks in CloudIoT environments causes anomalies in the QoS values. Therefore, existing approaches fail to model QoS values accurately that leads to service-level agreement (SLA) violation and penalties for service broker. To address this challenge, we propose a scalable anomaly-aware approach (SAIoT) including two main components: the first component models QoS values based on a machine learning anomaly detection technique, to remove the existing abnormal QoS records, and the second component finds a near-optimal composition by using an effective and efficient metaheuristic algorithm. The experimental results based on real-world data sets show that our approach achieves 30.64% of the average improvement in the QoS value of a composite plan with equal or even less price compared to the previous works, such as information theory-based and advertised QoS-based methods.},
keywords={Quality of service;Cloud computing;Internet of Things;Anomaly detection;Computer architecture;Optimization;Heuristic algorithms;Anomaly detection;cloud computing;Internet of Things (IoT);optimization;scalability;services composition},
doi={10.1109/JIOT.2020.3023938},
ISSN={2327-4662},
month={March},}
@INPROCEEDINGS{8317664,
author={Toader, Bogdan and Moawad, Assaad and Fouquet, Francois and Hartmann, Thomas and Popescu, Mioara and Viti, Francesco},
booktitle={2017 IEEE 20th International Conference on Intelligent Transportation Systems (ITSC)}, title={A new modelling framework over temporal graphs for collaborative mobility recommendation systems},
year={2017},
volume={},
number={},
pages={1-6},
abstract={Over the years, collaborative mobility proved to be an important but challenging component of the smart cities paradigm. One of the biggest challenges in the smart mobility domain is the use of data science as an enabler for the implementation of large scale transportation sharing solutions. In particular, the next generation of Intelligent Transportation Systems (ITS) requires the combination of artificial intelligence and discrete simulations when exploring the effects of what-if decisions in complex scenarios with millions of users. In this paper, we address this challenge by presenting an innovative data modelling framework that can be used for ITS related problems. We demonstrate that the use of graphs and time series in multi-dimensional data models can satisfy the requirements of descriptive and predictive analytics in real-world case studies with massive amounts of continuously changing data. The features of the framework are explained in a case study of a complex collaborative mobility system that combines carpooling, carsharing and shared parking. The performance of the framework is tested with a large-scale dataset, performing machine learning tasks and interactive realtime data visualization. The outcome is a fast, efficient and complete architecture that can be easily deployed, tested and used for research as well in an industrial environment.},
keywords={Data models;Automobiles;Collaboration;Mobile handsets;Global Positioning System},
doi={10.1109/ITSC.2017.8317664},
ISSN={2153-0017},
month={Oct},}
@INPROCEEDINGS{8768740,
author={Bhat, Anmol and Rao, Aneesh C. and Bhaskar, Anirudh and Adithya, V. and Pratiba, D.},
booktitle={2018 3rd International Conference on Computational Systems and Information Technology for Sustainable Solutions (CSITSS)}, title={A Cost-Effective Audio-Visual Summarizer for Summarization of Presentations and Seminars},
year={2018},
volume={},
number={},
pages={271-276},
abstract={Nowadays, more than half the world's population live hand-in-hand with technology. From smart watches to smart phones to smart cities, the embodiment of technology in all of our day-to-day activities no longer looks like a distant dream. Lectures in classrooms have also advanced to the extent of using smart-boards and smart-classrooms; the developments in jotting down notes in such scenarios has, however, not advanced at the same pace. In the problem statement being tackled, based on similar lines, the target audience includes the attendees of any seminar, presentation or lecture, be it students, or the public in general, attending important conferences and talks. More often than not, complete undivided attention proves to be difficult at these seminars as the attendee may be preoccupied with the objective of jotting down pointers and making notes for future reference. It is during this process that several essentials in the speaker's delivery are missed out. Keeping this forethought in mind, this paper delves into the implementation of an audio-visual summarizer that achieves the aforementioned motive. With audio evidence on the speaker's delivery, paired with visual images of PowerPoint slides or handwritten material that is presented in the seminars, this device provides a smart solution of summarizing the entire presentation and logging the summary to a remote database server from where it is accessed through a user-end software application. The prototype comprises a Raspberry Pi coupled with a camera and a microphone. The prototype uses a fast RCNN model for text detection, Open Source Computer Vision (OpenCV) for text extraction, Google Speech Recognition and Natural Language Processing concepts for generating the summarized data. The proposed solution is very effective, in terms of feasibility and cost cutting factors. The novelty aspect of the proposed solution lies in the consolidation of ideas of Internet of Things (IOT) and machine learning, to deliver a product capable of providing a smooth and potent solution to the problem statement.},
keywords={Training;Object detection;Seminars;Servers;Microphones;Cameras;Google;Raspberry Pi;Object detection;Text extraction;Speech-to-text;Natural Language Processing},
doi={10.1109/CSITSS.2018.8768740},
ISSN={},
month={Dec},}

@article{YANG20191111,
title = {AI-based design of urban stormwater detention facilities accounting for carryover storage},
journal = {Journal of Hydrology},
volume = {575},
pages = {1111-1122},
year = {2019},
issn = {0022-1694},
doi = {https://doi.org/10.1016/j.jhydrol.2019.06.009},
url = {https://www.sciencedirect.com/science/article/pii/S0022169419305578},
author = {Shun-Nien Yang and Li-Chiu Chang and Fi-John Chang},
keywords = {Real-time urban flood control, Flood risk mitigation, Pump operation rules, Multi-objective optimization, Non-dominated sorting genetic algorithm-II (NSGA-II)},
abstract = {Rapid urbanization in metropolitan areas easily triggers flashy floods. Urban drainage systems conveying stormwater out of cities are key infrastructure elements for flood mitigation. This study develops an intelligent urban flood drainage system accounting for carryover storage through optimizing the multi-objective operation rules of pumping stations for effectual flood management in Taipei City. The Yu-Cheng pumping station constitutes the study case, and a large number of datasets collected from 17 typhoon/storm events are adopted for model construction and validation. Three objective functions are designed to minimize: (1) the sum of water level fluctuations in the flood storage pond (FSP); (2) the sum of peak FSP water levels; and (3) the mean absolute difference of pump switches between two consecutive times along operation sequence. The non-dominated sorting genetic algorithm II (NSGA-II) is applied to searching the Pareto-optimal solutions that optimize the trade-off between the objectives. We next formulate the optimal operation rules through a two-tier sorting process based on a compromised Pareto-optimal solution. The comparison of the simulated results obtained from both the optimal operation rules and current operation rules indicate that the optimal operation rules outperform current operation rules for all three objectives, with improvement rates reaching 43% (OBJ1), 3% (OBJ2) and 71% (OBJ3), respectively. We demonstrate that the derived intelligent urban flood drainage system can serve as reliable and efficient operational strategies for urban flood management and flood risk mitigation.}
}
@article{ULHASSAN202050,
title = {Differential privacy in blockchain technology: A futuristic approach},
journal = {Journal of Parallel and Distributed Computing},
volume = {145},
pages = {50-74},
year = {2020},
issn = {0743-7315},
doi = {https://doi.org/10.1016/j.jpdc.2020.06.003},
url = {https://www.sciencedirect.com/science/article/pii/S0743731520303105},
author = {Muneeb {Ul Hassan} and Mubashir Husain Rehmani and Jinjun Chen},
keywords = {Differential privacy, Blockchain, Privacy preservation},
abstract = {Blockchain has received a widespread attention because of its decentralized, tamper-proof, and transparent nature. Blockchain works over the principle of distributed, secured, and shared ledger, which is used to record, and track data within a decentralized network. This technology has successfully replaced certain systems of economic transactions in organizations and has the potential to overtake various industrial business models in future. Blockchain works over peer-to-peer (P2P) phenomenon for its operation and does not require any trusted-third party authorization for data tracking and storage. The information stored in blockchain is distributed throughout the decentralized network and is usually protected using cryptographic hash functions. Since the beginning of blockchain technology, its use in different applications is increasing exponentially, but this increased use has also raised some questions regarding privacy and security of data being stored in it. Protecting privacy of blockchain data using data perturbation strategy such as differential privacy could be a novel approach to overcome privacy issues in blockchain. In this article, we cover the topic of integration of differential privacy in each layer of blockchain and in certain blockchain based scenarios. Moreover, we highlight some future challenges and application scenarios in which integration of differential privacy in blockchain can produce fruitful results.}
}
@article{LAMGHARIELIDRISSI2020100878,
title = {Knapsack problem-based control approach for traffic signal management at urban intersections: Increasing smooth traffic flows and reducing environmental impact},
journal = {Ecological Complexity},
volume = {44},
pages = {100878},
year = {2020},
issn = {1476-945X},
doi = {https://doi.org/10.1016/j.ecocom.2020.100878},
url = {https://www.sciencedirect.com/science/article/pii/S1476945X20301586},
author = {Hajar {Lamghari Elidrissi} and Ahmed Nait-Sidi-Moh and Abdelouahed Tajer},
keywords = {Complex System, Environmental impact, Traffic regulation, Urban mobility, Petri nets, SUMO based simulation},
abstract = {Urbanism development makes cities more congested and then more polluted. Hence, the primary factor that influences the urban environment directly is traffic flow. Therefore, this complex system requires efficient control methods to reduce its impact at urban zones, in particular for traffic light within intersections. In this paper, a dynamic control strategy of traffic signal at urban intersections is proposed. This strategy is based on Knapsack-problem and enables to manage the green light duration autonomously following the queue length for each road lane. The dynamic behavior of this system is considered as a discrete event system. Consequently, a modular Timed Synchronized Petri Net (TSPN) model is developed. Depending on real-time communication, the TSPN modules represent the ”slaves”, and the responsive controller represents the ”master” that manage optimally the vehicles evacuation at the intersection. Moreover, for the system dependability, some interesting properties of the system are checked through the developed Petri net model. SUMO based simulations are performed and analyzed to validate the proposed approach. Through the performed simulations and the analysis of the proposed dynamic control approach and findings show the efficiency of our control policy about smooth traffic increasing and environmental impact reducing.}
}
@article{WILLING201775,
title = {Moving in time and space – Location intelligence for carsharing decision support},
journal = {Decision Support Systems},
volume = {99},
pages = {75-85},
year = {2017},
note = {Location Analytics and Decision Support},
issn = {0167-9236},
doi = {https://doi.org/10.1016/j.dss.2017.05.005},
url = {https://www.sciencedirect.com/science/article/pii/S0167923617300830},
author = {Christoph Willing and Konstantin Klemmer and Tobias Brandt and Dirk Neumann},
keywords = {Carsharing, Spatial analytics, Location-based services, Spatial decision support system},
abstract = {In this paper we develop a spatial decision support system that assists free-floating carsharing providers in countering imbalances between vehicle supply and customer demand in existing business areas and reduces the risk of imbalance when expanding the carsharing business to a new city. For this purpose, we analyze rental data of a major carsharing provider in the city of Amsterdam in combination with points of interest (POIs). The spatio-temporal demand variations are used to develop pricing zones for existing business areas. We then apply the influence of POIs derived from carsharing usage in Amsterdam in order to predict carsharing demand in the city of Berlin. The results indicate that predicted and actual usage patterns are very similar. Hence, our approach can be used to define new business areas when expanding to new cities to include high demand areas and exclude low demand areas, thereby reducing the risk of supply-demand imbalance.}
}
@article{SPIRKOVA2019520,
title = {Mixture functions and their monotonicity},
journal = {Information Sciences},
volume = {481},
pages = {520-549},
year = {2019},
issn = {0020-0255},
doi = {https://doi.org/10.1016/j.ins.2018.12.090},
url = {https://www.sciencedirect.com/science/article/pii/S002002551831048X},
author = {Jana Špirková and Gleb Beliakov and Humberto Bustince and Javier Fernandez},
keywords = {Aggregation function, Mixture function, Monotonicity, Weak monotonicity, Directional monotonicity},
abstract = {We consider mixture functions, which are a type of weighted averages for which the corresponding weights are calculated by means of appropriate continuous functions of their inputs. In general, these mixture function need not be monotone increasing. For this reason we study sufficient conditions to ensure standard, weak and directional monotonicity for specific types of weighting functions. We also analyze directional monotonicity when differentiability is assumed.}
}
@article{ALHAMWI2019113360,
title = {Development of a GIS-based platform for the allocation and optimisation of distributed storage in urban energy systems},
journal = {Applied Energy},
volume = {251},
pages = {113360},
year = {2019},
issn = {0306-2619},
doi = {https://doi.org/10.1016/j.apenergy.2019.113360},
url = {https://www.sciencedirect.com/science/article/pii/S0306261919310347},
author = {Alaa Alhamwi and Wided Medjroubi and Thomas Vogt and Carsten Agert},
keywords = {Urban Energy Systems (UES), Geographic Information Systems (GIS), OpenStreetMap (OSM), Open source data, Flexibility options, FlexiGIS platform},
abstract = {As the world is already highly urbanised, energy systems in cities are already responsible for significant amount of the global Greenhouse Gas (GHG) emissions. Therefore, climate change mitigation demands a fundamental transformation in the Urban Energy Systems (UES), energy markets and energy policies. In this context, the large shift to micro-generation from renewable energy sources and their integration in the current energy system are a technical challenge for future energy systems design and operation. This will be further exacerbated if flexibilisation technologies such as storage are not efficiently integrated. For this purpose, an accurate modelling and representation of UES requires the characterisation of different urban energy requirements. These requirements, along with the urban fabric of cities, should be adequately incorporated in a spatial-temporal framework including both static and dynamic datasets. In this context, urban energy models provide policymakers with qualitative and quantitative insights for the planning of future UES. Within this framework, urban energy models integrated in Geographic Information Systems (GIS) will play an important role due to their multi-layer approach. This study introduces an open source GIS-based platform called FlexiGIS for the optimisation of energy systems in cities. FlexiGIS is used in this contribution to optimally allocate distributed battery storage in urban areas. The FlexiGIS platform provides the urban energy infrastructure (spatial dimension), simulates electricity consumption and generation (spatial and temporal dimension) and performs a linear optimisation for the economic deployment of micro-generation and decentralised storage under different energy scenarios. The first case study considers the city as a single system or ‘energy cell’, while the second one assumes that the city is divided into connected subsystems or districts. The total UES costs and required storage capacities for the investigated scenarios are obtained using optimisation. A key finding is that, for the investigated scenarios, investing in local electricity storage and renewable power generation can significantly reduce the total system costs and increase urban self-sufficiency. This study also highlights that the off-grid scenario (isolated city) is not an optimal choice.}
}
@article{RAJASEGARAR20142867,
title = {Ellipsoidal neighbourhood outlier factor for distributed anomaly detection in resource constrained networks},
journal = {Pattern Recognition},
volume = {47},
number = {9},
pages = {2867-2879},
year = {2014},
issn = {0031-3203},
doi = {https://doi.org/10.1016/j.patcog.2014.04.006},
url = {https://www.sciencedirect.com/science/article/pii/S003132031400137X},
author = {Sutharshan Rajasegarar and Alexander Gluhak and Muhammad {Ali Imran} and Michele Nati and Masud Moshtaghi and Christopher Leckie and Marimuthu Palaniswami},
keywords = {Anomaly detection, Outlier factor, Hyperellipsoidal model, Distributed detection, Sensor networks},
abstract = {Anomaly detection in resource constrained wireless networks is an important challenge for tasks such as intrusion detection, quality assurance and event monitoring applications. The challenge is to detect these interesting events or anomalies in a timely manner, while minimising energy consumption in the network. We propose a distributed anomaly detection architecture, which uses multiple hyperellipsoidal clusters to model the data at each sensor node, and identify global and local anomalies in the network. In particular, a novel anomaly scoring method is proposed to provide a score for each hyperellipsoidal model, based on how remote the ellipsoid is relative to their neighbours. We demonstrate using several synthetic and real datasets that our proposed scheme achieves a higher detection performance with a significant reduction in communication overhead in the network compared to centralised and existing schemes.}
}
@article{DOMINKOVIC2022111749,
title = {Reviewing two decades of energy system analysis with bibliometrics},
journal = {Renewable and Sustainable Energy Reviews},
volume = {153},
pages = {111749},
year = {2022},
issn = {1364-0321},
doi = {https://doi.org/10.1016/j.rser.2021.111749},
url = {https://www.sciencedirect.com/science/article/pii/S1364032121010200},
author = {D.F. Dominković and J.M. Weinand and F. Scheller and M. D'Andrea and R. McKenna},
keywords = {Energy system analysis, Bibliometrics, Collaboration networks, Renewable energy, Sustainable energy, Research impact},
abstract = {The field of Energy System Analysis (ESA) has experienced exponential growth in the number of publications in the last two decades. This paper presents a comprehensive bibliometric analysis on ESA by employing different statistical techniques to investigate the underlying science's structure, characteristics, and patterns. The focus of results is on quantitative indicators relating to the number and type of publication outputs, collaboration links between institutions, authors and countries, and dynamic trends within the field. The five and twelve most productive countries have 50% and 80% of ESA publications, respectively. The dominant institutions are even more concentrated within a small number of countries. A significant concentration of published papers within countries and institutions was also confirmed by analysing collaboration networks. These show dominant collaboration within the same university or at least the same country. There is also a strong link among the most successful journals, authors and institutions. Within the field, the Energy journal has had the most publications, its editor-in-chief is the author with both the highest overall number of publications and the most highly cited publications. In terms of the dynamics within the field in the past decade, recent years have seen a higher impact of topics related to flexibility and hybrid/integrated energy systems alongside a decline in individual technologies. This paper provides a holistic overview of two decades' research output and enables interested readers to obtain a comprehensive overview of the key trends in this active field.}
}
@article{VAZ201652,
title = {Urban habitats and the injury landscape},
journal = {Habitat International},
volume = {56},
pages = {52-62},
year = {2016},
issn = {0197-3975},
doi = {https://doi.org/10.1016/j.habitatint.2016.04.006},
url = {https://www.sciencedirect.com/science/article/pii/S0197397516300522},
author = {Eric Vaz and Yishi Zhao and Michael Cusimano},
abstract = {Multi-dimensional data analysis has rarely been performed on injury data. However, the implementation of sound policies can only be considered over geographical space when typologies of health vectors are considered at a global scale, and may be integrated at local level for decision making. In this study, frequency data of six injury types in Extended Golden Horseshoe area are collected and self-organizing maps (SOM) are used to construct an injury cluster system for the region. The results indicate that the variables are positively correlated and several outliers are found in the study area. The implementation of SOM brings an efficient tool for planning and assessment of spatially-explicit clusters for decision making at local and regional level. Furthermore, the visualization of multi-dimensional data allows for an integrative system of understanding the connectivity of injuries to existing land use types. The results also suggest that the injury prevention strategies should be reinforced in smaller CMAs like St. Catherine's – Niagara and Oshawa. But also, that land use typologies exist within metropolitan areas that create more probable injury outcomes. Overall our paper suggests the existence of clear clusters over geographical space that transcend traditional analysis techniques that may be adapted to ubiquitous concerns in epidemiology linked to land use planning and safer environments. Self-organizing maps may have a profound and significant role in merging decision-makers with adequate spatial information for health determinants and assessments suggesting a new integrative method of multi-dimension analysis of land use and injury data.}
}
@article{TAKAC2021,
title = {Discrete IV dG-Choquet integrals with respect to admissible orders},
journal = {Fuzzy Sets and Systems},
year = {2021},
issn = {0165-0114},
doi = {https://doi.org/10.1016/j.fss.2021.09.013},
url = {https://www.sciencedirect.com/science/article/pii/S0165011421003432},
author = {Zdenko Takáč and Mikel Uriz and Mikel Galar and Daniel Paternain and Humberto Bustince},
keywords = {Choquet integral, Interval-valued dissimilarity function, Interval-valued fuzzy measure, -Choquet integral},
abstract = {In this work, we introduce the notion of dG-Choquet integral, which generalizes the discrete Choquet integral replacing, in the first place, the difference between inputs represented by closed subintervals of the unit interval [0,1] by a dissimilarity function; and we also replace the sum by more general appropriate functions. We show that particular cases of dG-Choquet integral are both the discrete Choquet integral and the d-Choquet integral. We define interval-valued fuzzy measures and we show how they can be used with dG-Choquet integrals to define an interval-valued discrete Choquet integral which is monotone with respect to admissible orders. We finally study the validity of this interval-valued Choquet integral by means of an illustrative example in a classification problem.}
}
@article{MANI2020850,
title = {An IoT Guided Healthcare Monitoring System for Managing Real-Time Notifications by Fog Computing Services},
journal = {Procedia Computer Science},
volume = {167},
pages = {850-859},
year = {2020},
note = {International Conference on Computational Intelligence and Data Science},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2020.03.424},
url = {https://www.sciencedirect.com/science/article/pii/S1877050920308905},
author = {Neel Mani and Akhil Singh and Shastri L Nimmagadda},
keywords = {IOT, Healthcare, Fog computing, Smart devices, Noticification services},
abstract = {Fog Computing is a new computing paradigm which is grown ever since it is being used. It is aimed at bringing the computations close to data sources from healthcare centers. IoT driven Fog Computing is developed in the healthcare industry that can expedite facilities and services among the mass population and help in saving billions of lives. The new computing platform, founded as fog computing paradigm may help to ease latency while transmitting and communicating signals with remote servers, which can accelerate medical services in spatial-temporal dimensions. The latency reduction is one of the necessary features of computing platforms which can enable completing the healthcare operations, especially in large-size medical projects and in relation to providing sensitive and intensive services. Reducing the cost of delivering data to the cloud is one of the research objectives.}
}
@article{LI2021101325,
title = {A human-centred approach based on functional near-infrared spectroscopy for adaptive decision-making in the air traffic control environment: A case study},
journal = {Advanced Engineering Informatics},
volume = {49},
pages = {101325},
year = {2021},
issn = {1474-0346},
doi = {https://doi.org/10.1016/j.aei.2021.101325},
url = {https://www.sciencedirect.com/science/article/pii/S1474034621000781},
author = {Qinbiao Li and Kam K.H. Ng and Zhijun Fan and Xin Yuan and Heshan Liu and Lingguo Bu},
keywords = {Air traffic control, Adaptive decision-making, Functional Near-Infrared spectroscopy, Human factors, Intelligent automation},
abstract = {Safety-critical systems like air traffic control (ATC) are usually less automated than might be expected by the public, so human intelligence will remain at the core in the decision-making (DM) process. Meanwhile, human factors (HFs) need to be fully considered in the DM process, which can design the ATC system to be more intelligent and more adaptive to the behaviour of the user. However, the existing DM research lacks the systematic methods that fully consider human performance in a smart manner. This study proposed a human-centred adaptive DM methodology that combines subjective and objective measurements made by functional near-infrared spectroscopy (fNIRS) via intelligent automation (IA). Moreover, this paper also described a case study of radar display map operation, including descriptive and optimised maps, to illustrate the proposed approach and verify its feasibility and effectiveness. The results were determined by jointly considering the user-generated and system-generated data and suggested that the proposed approach could capture subjective and objective data, take into consideration the HFs information to provide real-time online feedback and adjust the decision support system to HFs. It is hoped that this study can promote the methodology of human-centred subjective and objective data-driven applications in the future ATC environment adaptive decision research.}
}
@article{GARCIA201961,
title = {BIM-oriented data mining for thermal performance of prefabricated buildings},
journal = {Ecological Informatics},
volume = {51},
pages = {61-72},
year = {2019},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2019.02.012},
url = {https://www.sciencedirect.com/science/article/pii/S1574954118302929},
author = {Lucianne Casasanta Garcia and Bernard Kamsu-Foguem},
keywords = {Data mining, Association rules, Clustering, Building information, Green buildings},
abstract = {The use of energy efficiency procedures is a typical practice in building construction process that creates a huge amount of data regarding the building. This is particularly valid in structures which include complex collaborations, for example, ventilation, sunlight-based increases, inner additions, and warm mass. This paper proposes a new approach for automating building construction when improving their energy efficiency, aiming to foresee comfort levels based on Heating, Ventilating, Air Conditioning (HVAC), constructive systems performance, environmental conditions, and occupant behavior. More specifically, it presents a research work about thermal performance of prefabricated construction systems developed by an Argentine enterprise called Astori, using two Knowledge Discovery in Databases (KDD) processes to extract knowledge. In this context, Building Information Modeling (BIM) will give data to support the calculation to outline goal levels of a sustainable building performance concerning classification systems. The data were collected from a project in Uruguay referring to the construction systems and the energy efficiency of the building. The data mining tool SPMF was used to test the performance of classification and its use in prediction. Particularly, FP-Growth Algorithm and Clustering methodologies were used to analyze a combination of ambient conditions, in order to compare them using Revit© software. The results generated by these methods can be generalized for a set of buildings, according to the objective to be achieved concerning the thermal building performance.}
}
@article{PANNU2021102606,
title = {Dwell time estimation at intersections for improved vehicular micro cloud operations},
journal = {Ad Hoc Networks},
volume = {122},
pages = {102606},
year = {2021},
issn = {1570-8705},
doi = {https://doi.org/10.1016/j.adhoc.2021.102606},
url = {https://www.sciencedirect.com/science/article/pii/S1570870521001360},
author = {Gurjashan Singh Pannu and Seyhan Ucar and Takamasa Higuchi and Onur Altintas and Falko Dressler},
keywords = {Mobile Edge Computing, Vehicular cloud, Vehicular micro cloud, Data management},
abstract = {Edge computing is becoming a major building block of next generation 5G/6G networks. However, infrastructure might not always be available because of slow deployment. At the same time, vehicular networks are becoming a reality now and cars are being equipped with a variety of short-range communication devices. The idea of vehicular micro clouds is to turn cars into (virtual) edge computing infrastructure. One of the challenging questions in this domain is to maintain data within and among such micro clouds. In this paper, we focus on this task and present a novel solution for such data exchange between vehicular micro clouds. For efficient operation, the dwell times of cars in such a micro cloud need to be known or accurately predicted. In an extensive study based on trace data, we investigate the distribution of dwell times of cars at intersections. We make use of this distribution as an input for designing an improved data exchange algorithm. As not all intersections are the same, adding additional variance further benefits the solution. We evaluated our algorithm in different vehicular densities, and we observed that we could maintain data 22–208% longer within the micro clouds using our new algorithm. Overall, our results show that our algorithm clearly outperforms previous solutions.}
}
@article{NAMANYA2020824,
title = {Similarity hash based scoring of portable executable files for efficient malware detection in IoT},
journal = {Future Generation Computer Systems},
volume = {110},
pages = {824-832},
year = {2020},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2019.04.044},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X18325913},
author = {Anitta Patience Namanya and Irfan U. Awan and Jules Pagna Disso and Muhammad Younas},
keywords = {Malware, Static analysis, Detection, Hashes, Internet of things},
abstract = {The current rise in malicious attacks shows that existing security systems are bypassed by malicious files. Similarity hashing has been adopted for sample triaging in malware analysis and detection. File similarity is used to cluster malware into families such that their common signature can be designed. This paper explores four hash types currently used in malware analysis for portable executable (PE) files. Although each hashing technique produces interesting results, when applied independently, they have high false detection rates. This paper investigates into a central issue of how different hashing techniques can be combined to provide a quantitative malware score and to achieve better detection rates. We design and develop a novel approach for malware scoring based on the hashes results. The proposed approach is evaluated through a number of experiments. Evaluation clearly demonstrates a significant improvement (> 90%) in true detection rates of malware.}
}
@article{GARG2020105,
title = {A multi-stage anomaly detection scheme for augmenting the security in IoT-enabled applications},
journal = {Future Generation Computer Systems},
volume = {104},
pages = {105-118},
year = {2020},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2019.09.038},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X19319703},
author = {Sahil Garg and Kuljeet Kaur and Shalini Batra and Georges Kaddoum and Neeraj Kumar and Azzedine Boukerche},
keywords = {Anomaly detection, Internet of Things, Boruta algorithm, K-medoid clustering, Firefly algorithm, Density-based clustering, Locality sensitive hashing},
abstract = {The synergy between data security and high intensive computing has envisioned the way to robust anomaly detection schemes which in turn necessitates the need for efficient data analysis. Data clustering is one of the most important components of data analytics, and plays an important role in various Internet of Things (IoT)-enabled applications such as-Industrial IoT, Smart Grids, Connected Vehicles, etc. Density-Based Spatial Clustering of Applications with Noise (DBSCAN) is one such clustering technique which is widely used to detect anomalies in large-scale data. However, the traditional DBSCAN algorithm suffers from the nearest neighbor search and parameter selection problems, which may cause the performance of any implemented solution in this environment to deteriorate. To remove these gaps, in this paper, a multi-stage model for anomaly detection has been proposed by rectifying the problems incurred in traditional DBSCAN. In the first stage of the proposed solution, Boruta algorithm is used to capture the relevant set of features from the dataset. In the second stage, firefly algorithm, with a Davies–Bouldin Index based K-medoid approach, is used to perform the partitioning. In the third stage, a kernel-based locality sensitive hashing is used along with the traditional DBSCAN to solve the problem of the nearest neighbor search. Finally, the resulting set of the nearest neighbors are used in k-distance graph to determine the desired set of parameters, i.e., Eps (maximum radius of the neighborhood) and MinPts (minimum number of points in Eps neighborhood) for DBSCAN. Several sets of experiments have been performed on different datasets to demonstrate the effectiveness of the proposed scheme.}
}
@article{ARRIBASBEL201445,
title = {Accidental, open and everywhere: Emerging data sources for the understanding of cities},
journal = {Applied Geography},
volume = {49},
pages = {45-53},
year = {2014},
note = {The New Urban World},
issn = {0143-6228},
doi = {https://doi.org/10.1016/j.apgeog.2013.09.012},
url = {https://www.sciencedirect.com/science/article/pii/S0143622813002178},
author = {Daniel Arribas-Bel},
keywords = {Data sources, Open data, Cities},
abstract = {In this paper, I review the recent emergence of three groups of data sources and assess some of the opportunities and challenges they pose for the understanding of cities, particularly in the context of the Regional Science and urban research agenda. These are data collected from mobile sensors carried by individuals, data derived from businesses moving their activity online and government data released in an open format. Although very different from each other, they are all becoming available as a side-effect since they were created with different purposes but their degree of popularity, pervasiveness and ease of access is turning them into interesting alternatives for researchers. Existing projects and initiatives that conform to each class are featured as illustrative examples of these new potential sources of knowledge.}
}
@article{MAIA2021101302,
title = {Transposition of Location-based Games: Using Procedural Content Generation to deploy balanced game maps to multiple locations},
journal = {Pervasive and Mobile Computing},
volume = {70},
pages = {101302},
year = {2021},
issn = {1574-1192},
doi = {https://doi.org/10.1016/j.pmcj.2020.101302},
url = {https://www.sciencedirect.com/science/article/pii/S157411922030136X},
author = {Luís Fernando Maia and Windson Viana and Fernando Trinta},
keywords = {Location-based Games, Procedural Content Generation, Graph isomorphism},
abstract = {Location-Based Games (LBGs) rely on the player’s location to change its game state. Developing worldwide LBGs is a challenging task due to the need to deploy game instances in multiple locations, while maintaining the same game balancing, features, and even correlations between locations of the game and the real world. Hence, it is virtually impossible to manually design interactions, challenges, and game scenarios for every place a player is at. As a result, even modern LBGs still present huge balancing differences between regions and avoid exploring the competition between players like other game genres. This work uses Procedural Content Generation to transpose maps of LBGs while focusing on maintaining their game balancing. We convert LBGs into a game model based on a directed weighted graph using information about Points-of-Interest (POIs) around the players’ location. This game model is simplistic and lightweight, which makes it suitable to wearable and IoT devices that are becoming popular among LBGs. Moreover, we use a Genetic Algorithm to generate a corresponding LBG instance with similar game balancing. To validate the proposed approach, we designed four LBGs with distinct features, gameplay, and mechanics, and conducted an experiment that required samples to compare maps generated by the algorithm in different locations. Results indicate that games with similar game balancing score higher and that the number of POIs has a significant impact on the performance of the approach. Finally, we can conclude that this work contributes to improving the development of LBGs by helping to mitigate the challenge of transposing LBGs while maintaining game balancing.}
}
@article{MORE20201711,
title = {An Experimental Assessment of Random Forest Classification Performance Improvisation with Sampling and Stage Wise Success Rate Calculation},
journal = {Procedia Computer Science},
volume = {167},
pages = {1711-1721},
year = {2020},
note = {International Conference on Computational Intelligence and Data Science},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2020.03.381},
url = {https://www.sciencedirect.com/science/article/pii/S1877050920308474},
author = {Anjali S. More and Dipti P. Rana},
keywords = {Random forest classification, imbalanced data, classification, SMOTE, oversampling, KEEL},
abstract = {Imbalanced data classification with Random Forest Classification (RFC) technique has gained huge prominence in today’s application era. Data imbalance between practical applications relates to either binary class imbalance or multiclass imbalance. Binary class imbalance constitutes one of the classes with majority data samples and other contains minor number of data samples. In case of multiclass there are two categories of multiclass imbalanced dataset as Multiclass Minority Imbalanced Class (MMinIC) and Multiclass Majority Imbalanced Class (MMajIC). Classification performance leans towards degradation for MMajIC than MMinIC due to major imbalance rate severity. In this paper, the study investigates the influence of RFC classification analysis method on binary and multiclass sample imbalanced datasets. The analytical study of RFC incorporates with measurement of classification accuracy with performance metrics as True Positive (TP) Rate, False Positive (FP) Rate, Precision (Pre), Recall (Rec) F-Measure, Operating Characteristics of Receiver (ROC) Area, Matthews Correlation Coefficient (MCC), Probabilistic Relevance Classification (PRC) area with respect to numerous classes in refereed dataset. This paper focuses the reduction of the negative influence of imbalanced data with the use of Synthetic Minority Oversampling Technique (SMOTE). Experimental analysis carried out with the use of Knowledge Extraction Evolutionary Learning (KEEL) imbalanced data learning repository incorporating RFC classification with SMOTE technique. It also deals with RFC model construction with stage wise success rate calculation in training and testing partition and its impact on accuracy. The incorporates with error analysis report of incorrectly classified instances. Experimental results of the study indicate that imbalanced data have significant impact on classification accuracy and RFC outperforms with SMOTE.}
}
@article{SAMARAH2018122,
title = {Transferring activity recognition models in FOG computing architecture},
journal = {Journal of Parallel and Distributed Computing},
volume = {122},
pages = {122-130},
year = {2018},
issn = {0743-7315},
doi = {https://doi.org/10.1016/j.jpdc.2018.07.020},
url = {https://www.sciencedirect.com/science/article/pii/S0743731518305410},
author = {Samer Samarah and Mohammed GH. AL Zamil and Majdi Rawashdeh and M. Shamim Hossain and Ghulam Muhammad and Atif Alamri},
keywords = {Fog computing, Cloud architecture, Edge computing, Transfer learning, Activity recognition, Internet of things, Wireless networks, Data mining},
abstract = {A major focus of research in the field of in-home activity recognition (AR) and home automation (HA) is the ability to transfer data models to other homes for the purpose of applying new services, annotating classified data, and generating datasets due to lack of training ones. The wide spread of fog computing as an architecture for organizing edge devices in Internet-of-Things (IoT) systems lends support to the sharing of different environmental characteristics between different fogs (smart homes). In this paper, we propose a framework that serves the transfer of data models between different smart homes in a bid to overcome the lack of training data, which prevents the development of high-performance models that utilize fog computing characteristics. Our technique incorporates the sharing of environmental characteristics (by Fogs) in order to analyze the data features at the source and target smart homes. The features, then, are mapped onto each other using a fusion method that guarantees to keep the variations between different homes by reducing the divergence between them. The hidden Markov model has also been applied in order to model activities at target homes. Three experiments have been conducted to measure the performance of the proposed framework: first, against the accuracy of feature-mapping techniques; second, measuring the performance of classifying data at target homes; and, third, the ability of the proposed framework to function well due to noise data. The results show promising indicators and highlight the limitations of the proposed methodology.}
}
@article{MARTINEZDIAZ2018275,
title = {Autonomous vehicles: theoretical and practical challenges},
journal = {Transportation Research Procedia},
volume = {33},
pages = {275-282},
year = {2018},
note = {XIII Conference on Transport Engineering, CIT2018},
issn = {2352-1465},
doi = {https://doi.org/10.1016/j.trpro.2018.10.103},
url = {https://www.sciencedirect.com/science/article/pii/S2352146518302606},
author = {Margarita Martínez-Díaz and Francesc Soriguera},
keywords = {autonomous vehicles, vehicle technology, cooperative driving, traffic efficiency, vehicle automation impacts},
abstract = {Autonomous driving is expected to revolutionize road traffic attenuating current externalities, especially accidents and congestion. Carmakers, researchers and administrations have been working on autonomous driving for years and significant progress has been made. However, the doubts and challenges to overcome are still huge, as the implementation of an autonomous driving environment encompasses not only complex automotive technology, but also human behavior, ethics, traffic management strategies, policies, liability, etc. As a result, carmakers do not expect to commercially launch fully driverless vehicles in the short-term. From the technical perspective, the unequivocal detection of obstacles at high speeds and long distances is one of the greatest difficulties to face. Regarding traffic management strategies, all approaches share the vision that vehicles should behave cooperatively. General V2V cooperation and platooning are options being discussed, both with multiple variants. Various strategies, built from different standpoints, are being designed and validated using simulation. Besides, legal issues have already been arisen in the context of highly-automated driving. They range from the need for special driving licenses to much more intricate topics like liability in the event of an accident or privacy issues. All these legal and ethical concerns could hinder the spread of autonomous vehicles once technologically feasible. This paper provides an overview of the current state of the art in the key aspects of autonomous driving. Based on the information received in situ from top research centers in the field and on a literature review, authors highlight the most important advances and findings reached so far, discuss different approaches regarding autonomous traffic and propose a framework for future research.}
}
@article{NAMBUI20181012,
title = {Cooperative game-theoretic approach to traffic flow optimization for multiple intersections},
journal = {Computers & Electrical Engineering},
volume = {71},
pages = {1012-1024},
year = {2018},
issn = {0045-7906},
doi = {https://doi.org/10.1016/j.compeleceng.2017.10.016},
url = {https://www.sciencedirect.com/science/article/pii/S0045790617318050},
author = {Khac-Hoai {Nam Bui} and Jason J. Jung},
keywords = {Internet of Things, Cooperative game theory approach, Coalition formation, Traffic simulation, Multiple intersections},
abstract = {In this study, we focus on optimizing traffic flow at multiple intersections. Particularly, with the development of Internet of Things, intersection controllers are regarded as smart agents which can communicate and coordinate with each other. In this regard, a cooperative game theoretic approach among agents is proposed to improve traffic flow with large network. Thereby, a distributed merge and split algorithm for coalition formation is presented. This algorithm is applied to find out how to incorporate with the cooperation among agents for dynamically controlling traffic light at intersections. Furthermore, we construct a traffic simulation framework to evaluate our approach. With various parameters for traffic density, our proposed system can effectively improve traffic flow in both uniform and non-uniform. In particular, by coordinating among controllers, the waiting time of vehicles at intersections can be reduced from 15% to 25% comparing with previous methods (e.g., Green Wave Coordination).}
}
@article{OLSTHOORN2017113,
title = {Abilities and limitations of thermal mass activation for thermal comfort, peak shifting and shaving: A review},
journal = {Building and Environment},
volume = {118},
pages = {113-127},
year = {2017},
issn = {0360-1323},
doi = {https://doi.org/10.1016/j.buildenv.2017.03.029},
url = {https://www.sciencedirect.com/science/article/pii/S0360132317301282},
author = {Dave Olsthoorn and Fariborz Haghighat and Alain Moreau and Gino Lacroix},
keywords = {Thermal mass, Peak shifting, Peak shaving, Energy, Indoor environment, Predictive control},
abstract = {The building and infrastructure sector is accountable for 40% of the total worldwide energy consumption and one third of the worldwide GHG emissions. In developed countries, the total energy consumption has increased, despite energy efficiency measures. A sustainable solution is to reduce the peak consumption by shifting the profile to off peak periods. This option can be economically advantageous for consumers in regions with off peak tariffs. It can also generate an energy consumption reduction if off peak charging of the thermal mass makes the mechanical equipment run at a higher efficiency. Thermal energy systems (TES) are believed to be the most cost effective method for demand side management at the moment. Note however, that thermal mass in buildings for load management is an obstacle with classical controls because it reduces the instantaneous influence of the conditioning system. Four activation methods are discussed: surface activation, forced-air activation, hydronic activation and electrical activation. The performance and control for such systems with peak shaving and shifting as an objective is discussed and barriers to its application and development is also addressed.}
}
@article{COOK201222,
title = {Pervasive computing at scale: Transforming the state of the art},
journal = {Pervasive and Mobile Computing},
volume = {8},
number = {1},
pages = {22-35},
year = {2012},
issn = {1574-1192},
doi = {https://doi.org/10.1016/j.pmcj.2011.10.004},
url = {https://www.sciencedirect.com/science/article/pii/S1574119211001416},
author = {Diane J. Cook and Sajal K. Das},
keywords = {Smart environments, Energy harvesting, Cloud computing, Smart phones, Behavior modeling, Internet of things},
abstract = {The remarkable recent progress in computing power, sensors and embedded devices, smart phones, wireless communications and networking technologies, combined with emerging data mining techniques, cloud computing and social networking paradigms has enabled us to create pervasive computing systems and services with diverse applications and global accessibility. In this paper, we assess the current state of the art of pervasive computing at scale (PeCS) and look ahead to future directions the field can pursue together with challenges it will need to overcome.}
}
@article{CHRYSOPOULOS2014299,
title = {Bottom-up modeling of small-scale energy consumers for effective Demand Response Applications},
journal = {Engineering Applications of Artificial Intelligence},
volume = {35},
pages = {299-315},
year = {2014},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2014.06.015},
url = {https://www.sciencedirect.com/science/article/pii/S0952197614001377},
author = {A. Chrysopoulos and C. Diou and A.L. Symeonidis and P.A. Mitkas},
keywords = {Smart grid, Small-scale consumer models, Demand simulation, Demand Response Applications},
abstract = {In contemporary power systems, small-scale consumers account for up to 50% of a country׳s total electrical energy consumption. Nevertheless, not much has been achieved towards eliminating the problems caused by their inelastic consumption habits, namely the peaks in their daily power demand and the inability of energy suppliers to perform short-term forecasting and/or long-term portfolio management. Typical approaches applied in large-scale consumers, like providing targeted incentives for behavioral change, cannot be employed in this case due to the lack of models for everyday habits, activities and consumption patterns, as well as the inability to model consumer response based on personal comfort. Current work aspires to tackle these issues; it introduces a set of small-scale consumer models that provide statistical descriptions of electrical consumption patterns, parameterized from the analysis of real-life consumption measurements. These models allow (i) bottom-up aggregation of appliance use up to the overall installation load, (ii) simulation of various energy efficiency scenarios that involve changes at appliance and/or activity level and (iii) the assessment of change in consumer habits, and therefore the power consumption, as a result of applying different pricing policies. Furthermore, an autonomous agent architecture is introduced that adopts the proposed consumer models to perform simulation and result analysis. The conducted experiments indicate that (i) the proposed approach leads to accurate prediction of small-scale consumption (in terms of energy consumption and consumption activities) and (ii) small shifts in appliance usage times are sufficient to achieve significant peak power reduction.}
}
@article{BAKKER2018201,
title = {Smart Earth: A meta-review and implications for environmental governance},
journal = {Global Environmental Change},
volume = {52},
pages = {201-211},
year = {2018},
issn = {0959-3780},
doi = {https://doi.org/10.1016/j.gloenvcha.2018.07.011},
url = {https://www.sciencedirect.com/science/article/pii/S0959378017313730},
author = {Karen Bakker and Max Ritts},
keywords = {Eco-informatics, Environmental governance, Smart earth, Ecology, ICT, IoT, Information and communications technology, Internet of things, Sensors, Digital},
abstract = {Environmental governance has the potential to be significantly transformed by Smart Earth technologies, which deploy enhanced environmental monitoring via combinations of information and communication technologies (ICT), conventional monitoring technologies (e.g. remote sensing), and Internet of Things (IoT) applications (e.g. Environmental Sensor Networks (ESNs)). This paper presents a systematic meta-review of Smart Earth scholarship, focusing our analysis on the potential implications and pitfalls of Smart Earth technologies for environmental governance. We present a meta-review of academic research on Smart Earth, covering 3187 across the full range of academic disciplines from 1997 to 2017, ranging from ecological informatics to the digital humanities. We then offer a critical perspective on potential pathways for evolution in environmental governance frameworks, exploring five key Smart Earth issues relevant to environmental governance: data; real-time regulation; predictive management; open source; and citizen sensing. We conclude by offering suggestions for future research directions and trans-disciplinary conversations about environmental governance in a Smart Earth world.}
}
@article{HUANG2020102719,
title = {Quantifying the bias in place emotion extracted from photos on social networking sites: A case study on a university campus},
journal = {Cities},
volume = {102},
pages = {102719},
year = {2020},
issn = {0264-2751},
doi = {https://doi.org/10.1016/j.cities.2020.102719},
url = {https://www.sciencedirect.com/science/article/pii/S0264275119312818},
author = {Yingjing Huang and Jun Li and Guofeng Wu and Teng Fei},
keywords = {Place emotion, Affective computing, User-generated content, Weibo},
abstract = {Various fields have widely used place emotion extracted from social networking sites (SNS) information in recent years. However, the emotional information may contain biases as users are a particular subset of the whole population. This research studies whether there are significant differences between place emotion extracted from SNS and the place in-situ (a campus of Wuhan University). Two datasets from different sources, Weibo (a platform similar to twitter) and in-situ cameras, are collected over the same time periods in the same geographical range. By utilizing online cognitive services on the photos collected, the diversity of people with a recognizable face in terms of age, gender, and emotions are determined. The results suggest that there are significant differences in place emotion extracted from Weibo and in-situ. Furthermore, the pattern of differences varies among diverse demographic groups. This paper quantitatively contrasts place emotion extracted from SNS and the place in-situ, which can help researchers achieve a more profound understanding of human behavior differences between online and offline place emotion. This research also provides a theoretical basis to calibrate the emotion metrics obtained from SNS facial expressions on future place emotion studies.}
}
@article{SOLTANISARVESTANI2021101251,
title = {Modeling unaccounted-for gas among residential natural gas consumers using a comprehensive fuzzy cognitive map},
journal = {Utilities Policy},
volume = {72},
pages = {101251},
year = {2021},
issn = {0957-1787},
doi = {https://doi.org/10.1016/j.jup.2021.101251},
url = {https://www.sciencedirect.com/science/article/pii/S0957178721000850},
author = {A. Soltanisarvestani and A.A. Safavi},
keywords = {Residential natural gas consumption, Fuzzy cognitive map, Modeling, Unaccounted for gas},
abstract = {Residential natural gas consumption depends on several factors. Available tools and methods to identify, categorize, and validate effective factors have some limitations, making consumption modeling more complex. Once a comprehensive model of effective consumption factors is developed for residential gas consumers, it can predict consumption. In addition, such a model could be used to verify the accuracy of measuring devices in order to reduce unaccounted for gas (UFG). The key factors affecting residential gas consumption were identified based on previous studies and their mutual effects were analyzed using a fuzzy cognitive mapping (FCM) method. The most significant factors and their effects on natural gas consumption in the residential sector were determined. In this study, for the first time, the expected consumption for each consumer was estimated using a consumption index. Generally, if the estimated consumption is significantly different from the amount recorded by the meter, it could suggest a potential source of UFG. The proposed method was applied to the data collected from the residential gas consumers of a small region in Iran (Dasht-e Arjan region, Fars province), and the results demonstrate the effectiveness of the proposed method.}
}
@article{FARMAN2018364,
title = {Multi-criteria based zone head selection in Internet of Things based wireless sensor networks},
journal = {Future Generation Computer Systems},
volume = {87},
pages = {364-371},
year = {2018},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2018.04.091},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X17320174},
author = {Haleem Farman and Bilal Jan and Huma Javed and Naveed Ahmad and Javed Iqbal and Muhammad Arshad and Shaukat Ali},
keywords = {Wireless sensor network, Energy efficiency, Network stability, Zone/cluster head selection, Internet of Things},
abstract = {The past few years have seen dramatic development and a great interest in efficient service delivery and better resource utilization in the Internet of Things (IoT) based constrained Wireless Sensor Network (WSN). The IoT is mainly dependent on optimal deployment of energy aware WSN and efficient communication architecture for data transfer among heterogeneous devices. In addition, energy efficient clustering techniques for WSN node deployment and routing have achieved great involvement for prolonging network lifetime. In clustering technique, where the network is partitioned into different segments (clusters or zones) and proper attention must be given to the cluster head (CH) selection procedure for maximizing node reachability inside the cluster and efficient communication to the base station. In this paper, we have proposed multi-criteria based cluster head/zone head selection scheme in Internet of Things based WSN by considering distinct parameters affecting node energy and network lifetime. These parameters; energy level, distance from neighboring nodes, distance from center of the zone, number of times a node has been zone head and whether a node is merged or not, have direct impact on overall performance of WSN. The relative impact of each parameter in CH/ZH selection is computed using the Analytical Network Process (ANP) which is widely used multi-criteria decision tool. Simulation results of the proposed scheme show relatively better performance than existing energy efficient clustering techniques. The obtained results have been analyzed by varying the number of parameters in ZH selection and their impact on network stability and lifetime.}
}
@article{MAHASETH2018559,
title = {An efficient signal conditioning circuit to piecewise linearizing the response characteristic of highly nonlinear sensors},
journal = {Sensors and Actuators A: Physical},
volume = {280},
pages = {559-572},
year = {2018},
issn = {0924-4247},
doi = {https://doi.org/10.1016/j.sna.2018.08.001},
url = {https://www.sciencedirect.com/science/article/pii/S0924424718309932},
author = {Durga Nand Mahaseth and Lokesh Kumar and Tarikul Islam},
keywords = {Humidity sensor, Thermistor, Nonlinearity compensation, Parallel ADC, Multiplexer, Signal conditioning circuit},
abstract = {To obtain the solutions to the problem of linearization of the sensor characteristics is a matter of investigations for a long time. This paper presents a new and simple piecewise linearizing circuit to compensate the nonlinearity of highly nonlinear sensor. It is having a mixed signal conditioning circuit, employing a 2-bit flash ADC, a (4×1) multiplexer and the Op amp-based signal conditioning units. The circuit was initially simulated using SPICE software and then hardware implemented for linearizing the nonlinear response characteristic of two sensors. One of the sensors is a graphene oxide capacitive humidity sensor with nearly 46% nonlinearity and the other is a thermistor-based temperature sensor with 16.4% nonlinearity. The humidity sensor is fabricated and characterized to measure humidity in the range of 2–85% RH. The maximum nonlinearity of the humidity and temperature sensors of the hardware implemented circuit after compensation was 1% and 1.5% respectively. The circuit is simple and requires few hardware components for implementation and applicable for any nonlinear sensor. The circuit is CMOS compatible for ASIC implementation.}
}
@article{OTGONBAYAR2018238,
title = {K-VARP: K-anonymity for varied data streams via partitioning},
journal = {Information Sciences},
volume = {467},
pages = {238-255},
year = {2018},
issn = {0020-0255},
doi = {https://doi.org/10.1016/j.ins.2018.07.057},
url = {https://www.sciencedirect.com/science/article/pii/S0020025518305772},
author = {Ankhbayar Otgonbayar and Zeeshan Pervez and Keshav Dahal and Steve Eager},
keywords = {Internet of things, Data privacy, Data streams, Anonymization, Missing values},
abstract = {The Internet-of-Things (IoT) produces and transmits enormous amounts of data. Extracting valuable information from this enormous volume of data has become an important consideration for businesses and research. However, extracting information from this data without providing privacy protection puts individuals at risk. Data has to be sanitized before use, and anonymization provides solution to this problem. Since, IoT is a collection of numerous different devices, data streams from these devices tend to vary over time thus creating varied data streams. However, implementing traditional data stream anonymization approaches only provide privacy protection for data streams that have predefined and fixed attributes. Therefore, conventional methods cannot directly work on varied data streams. In this work, we propose K-VARP (K-anonymity for VARied data stream via Partitioning) to publish varied data streams. K-VARP reads the tuple and assigns them to partitions based on description, and all tuples must be anonymized before expiring. It tries to anonymize expiring tuple within a partition if its partition is eligible to produce a K-anonymous cluster. Otherwise, partition merging is applied. In K-VARP we propose a new merging criterion called R-likeness to measure similarity distance between tuple and partitions. Moreover, flexible re-using and imputation free-publication is implied in K-VARP to achieve better anonymization quality and performance. Our experiments on a real datasets show that K-VARP is efficient and effective compared to existing algorithms. K-VARP demonstrated approximately three to nine and ten to twenty percent less information loss on two real datasets, while forming a similar number of clusters within a comparable computation time.}
}
@article{GIANNETTI2019866,
title = {Ten years working together for a sustainable world, dedicated to the 6th IWACP: Introductory article},
journal = {Journal of Cleaner Production},
volume = {226},
pages = {866-873},
year = {2019},
issn = {0959-6526},
doi = {https://doi.org/10.1016/j.jclepro.2019.03.292},
url = {https://www.sciencedirect.com/science/article/pii/S0959652619310029},
author = {B.F. Giannetti and F. Agostinho and C.M.V.B. Almeida and Zhifeng Yang and Gengyuan Liu and Yutao Wang and D. Huisingh},
keywords = {Local, Regional, Global coverage, CP concepts and practices},
abstract = {This special volume of the JCLP is mainly built upon articles presented at the 6th International Workshop Advances in Cleaner Production held in São Paulo, Brazil, in 2017. The event had provided a progressive interdisciplinary meeting for knowledge advance and information trade. Papers in this issue cover a broad range of perspectives of cleaner production strategies and practices, and a special focus was placed upon the type of contribution – practical, conceptual/practical, conceptual - and the scale of their coverage – local, regional and global. The papers provide understanding on the research intended to systematically include cleaner production in the path sustainability, and identifies the extent to which cleaner production practitioners directly and indirectly provide local, regional and global solutions. Key results of this introductory article include research on: efficient and responsive use of energy and resources; the search for reduced emissions, the role of managerial support and environmental assessments, and the implementation/analysis of closed-loop systems of materials.}
}
@article{ODAT2020102276,
title = {A memory-oriented MAC-layer design for future IoT systems},
journal = {Ad Hoc Networks},
volume = {108},
pages = {102276},
year = {2020},
issn = {1570-8705},
doi = {https://doi.org/10.1016/j.adhoc.2020.102276},
url = {https://www.sciencedirect.com/science/article/pii/S1570870520306375},
author = {Enas Odat and Doha Hamza and Basem Shihada and Jeff S. Shamma},
keywords = {IoT, Random access games, Perfect information, Gradient play, Imperfect information},
abstract = {The Internet of Things (IoT) paradigm envisions billions of interconnected things. This high density of things generates a huge amount of data, which results in communication delays and increases the amount of contention. Thus, it is necessary to have efficient Medium Access Control (MAC) protocols to coordinate channel access. In this paper, we consider a network throughput maximization problem in which a set of selfish nodes compete for transmission opportunities in the IoT scenario. To enhance cooperation among the nodes and to reduce the collision rate, we formulate a memory-one channel access game in which the nodes maximize their payoffs by optimizing their channel access probabilities, conditioned on their previous transmission state. A distributed learning algorithm is used by the nodes to solve the problem efficiently in order to overcome any coordination overhead. We investigate the impact of the network topology on the solution to the problem. Our simulation results show that the throughput achieved by the memory-one game outperforms the throughput achieved by other methods including IEEE 802.11 DCF protocol.}
}
@article{FOTI2021100008,
title = {What blockchain can do for power grids?},
journal = {Blockchain: Research and Applications},
volume = {2},
number = {1},
pages = {100008},
year = {2021},
issn = {2096-7209},
doi = {https://doi.org/10.1016/j.bcra.2021.100008},
url = {https://www.sciencedirect.com/science/article/pii/S2096720921000038},
author = {Magda Foti and Manolis Vavalis},
keywords = {Energy, Power grid, Blockchain, Distributed ledger technology, Review},
abstract = {The aim of this work is to provide an up-to-date comprehensive review of the peer-reviewed articles, the research projects and the entrepreneurial efforts that consider the utilization of blockchain technology in the energy sector in general and the power grid in particular. Through our review study we systematically classify existing applications of blockchain technology in the energy sector according to their field of activity. The comprehensive and holistic picture provided aims to contribute to the body of knowledge of the applicability of blockchain technology within the energy sector and pave the way for further research in this field.}
}
@article{YE2021381,
title = {Big data analytics for sustainable cities: An information triangulation study of hazardous materials transportation},
journal = {Journal of Business Research},
volume = {128},
pages = {381-390},
year = {2021},
issn = {0148-2963},
doi = {https://doi.org/10.1016/j.jbusres.2021.01.057},
url = {https://www.sciencedirect.com/science/article/pii/S0148296321000606},
author = {Lisha Ye and Shan L Pan and Jingyuan Wang and Junjie Wu and Xiaoying Dong},
keywords = {Big data analytics, Grand challenges, Information triangulation, Case study},
abstract = {Big data analytics (BDA) is regarded as an advanced tool for achieving sustainable development as part of the grand challenges (GCs). However, it is not clear how BDA can be used by data scientists to solve the GCs with multisource data in a cross-disciplinary approach. Based on a case study of city-based dangerous goods transportation (DGT), this paper explores how data scientists use BDA to triangulate data, methods, knowledge and solutions for solving GCs. The contribution of this study is threefold: (1) it contributes to research on GCs and discusses how BDA can be used in problem solving for multidomain GCs from a management perspective; (2) it enriches the theory of information triangulation and proposes several steps for information triangulation in BDA to solve GCs; and (3) it contributes some practical implications for the management of organizations when solving social problems and pursuing sustainable development.}
}
@article{SINGH2020104987,
title = {Probabilistic data structures for big data analytics: A comprehensive review},
journal = {Knowledge-Based Systems},
volume = {188},
pages = {104987},
year = {2020},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2019.104987},
url = {https://www.sciencedirect.com/science/article/pii/S0950705119304071},
author = {Amritpal Singh and Sahil Garg and Ravneet Kaur and Shalini Batra and Neeraj Kumar and Albert Y. Zomaya},
keywords = {Big data, Internet of things (IoT), Probabilistic data structures, Bloom filter, Quotient filter, Count min sketch, HyperLogLog counter, Min-hash, Locality sensitive hashing},
abstract = {An exponential increase in the data generation resources is widely observed in last decade, because of evolution in technologies such as-cloud computing, IoT, social networking, etc. This enormous and unlimited growth of data has led to a paradigm shift in storage and retrieval patterns from traditional data structures to Probabilistic Data Structures (PDS). PDS are a group of data structures that are extremely useful for Big data and streaming applications in order to avoid high-latency analytical processes. These data structures use hash functions to compactly represent a set of items in stream-based computing while providing approximations with error bounds so that well-formed approximations get built into data collections directly. Compared to traditional data structures, PDS use much less memory and constant time in processing complex queries. This paper provides a detailed discussion of various issues which are normally encountered in massive data sets such as-storage, retrieval, query,etc. Further, role of PDS in solving these issues is also discussed where these data structures are used as temporary accumulators in query processing. Several variants of existing PDS along with their application areas have also been explored which give a holistic view of domains where these data structures can be applied for efficient storage and retrieval of massive data sets. Mathematical proofs of various parameters considered in the PDS have also been discussed in the paper. Moreover, the relative comparison of various PDS with respect to various parameters is also explored.}
}
@article{QI2018636,
title = {A two-stage locality-sensitive hashing based approach for privacy-preserving mobile service recommendation in cross-platform edge environment},
journal = {Future Generation Computer Systems},
volume = {88},
pages = {636-643},
year = {2018},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2018.02.050},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X18301420},
author = {Lianyong Qi and Xuyun Zhang and Wanchun Dou and Chunhua Hu and Chi Yang and Jinjun Chen},
keywords = {Mobile service recommendation, Distributed edge platform, Collaborative filtering, Privacy-preservation, Locality-sensitive hashing, MinHash},
abstract = {With the increasing popularity of service computing paradigm, tremendous resources or services are emerging rapidly on the Web, imposing heavy burdens on the service selection decisions of users. In this situation, recommendation (e.g., collaborative filtering) has been considered as one of the most effective ways to alleviate such burdens. However, in the mobile and edge environment, the service recommendation bases, i.e., historical service usage data are often generated from various mobile devices (e.g., Smartphone and PDA) and stored in different edge platforms. Therefore, effective collaboration between these distributed edge platforms plays an important role in the successful mobile service recommendation. Such a cross-platform collaboration process often faces the following two challenges. First, a platform is often reluctant to release its data to other platforms due to privacy concerns. Second, the collaboration efficiency is often low when the data in each platform update frequently. In view of these two challenges, we introduce MinHash, an instance of Locality-Sensitive Hashing (LSH), into service recommendation, and further put forward a novel privacy-preserving and scalable mobile service recommendation approach based on two-stage LSH, named SerRectwo-LSH. Finally, extensive experiments are conducted on WS-DREAM, a real distributed service quality dataset, and the evaluation results demonstrate that both the service recommendation accuracy and the scalability have been significantly improved while privacy preservation is guaranteed.}
}
@article{WUBBEN2021108119,
title = {A novel resilient and reconfigurable swarm management scheme},
journal = {Computer Networks},
volume = {194},
pages = {108119},
year = {2021},
issn = {1389-1286},
doi = {https://doi.org/10.1016/j.comnet.2021.108119},
url = {https://www.sciencedirect.com/science/article/pii/S138912862100195X},
author = {Jamie Wubben and Francisco Fabra and Carlos T. Calafate and Juan-Carlos Cano and Pietro Manzoni},
keywords = {UAV swarm, Resilience, Flight coordination},
abstract = {As we witness the fast growth of the Unmanned Aerial Vehicles (UAVs) field, new applications and services emerge at a rapid pace. Above all, the interest in groups of UAVs working together (swarms) is gaining momentum. This interest emerges since swarms are able to undertake more sophisticated tasks. Furthermore, they can also increase task performance and/or robustness. However, organizing a multi-UAV flight is not easy, involving challenges in terms of (i) swarm formation definition, (ii) takeoff procedure, (iii) in-flight coordination, (iv) communication between the swarm elements, (v) swarm layout reconfiguration, (vi) handling the loss of swarms elements, and (vii) controlled landing. These and other issues still hold back the mainstream adoption of swarms in sectors such as agriculture, border surveillance, and parcel delivery. In this work we provide solutions for two of the main critical challenges: (a) swarm layout reconfiguration, and (b) handling the loss of swarm elements. A wide set of experiments were made using our own realistic UAV emulation tool (ArduSim) in order to validate our proposals. The experiments show that the chances of facing collisions during the reconfiguration are greatly reduced even in error-prone scenarios, and that, in many cases, the loss of a UAV is handled seamlessly; otherwise (in the worst-case scenarios) a delay of just a few seconds is introduced. Additionally, this work addresses cases where, due to the lack of proper communication between the swarm elements, a swarm splits up. Experiments show that with our swarm resilience mechanisms those cases are inherently solved by creating autonomous sub-swarms which will then complete their part of the mission independently.}
}
@article{TALAT2020382,
title = {A decentralised approach to privacy preserving trajectory mining},
journal = {Future Generation Computer Systems},
volume = {102},
pages = {382-392},
year = {2020},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2019.07.068},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X19313901},
author = {Romana Talat and Mohammad S. Obaidat and Muhammad Muzammal and Ali Hassan Sodhro and Zongwei Luo and Sandeep Pirbhulal},
keywords = {Trajectory data, Blockchain technology, Privacy preservation, Decentralised trajectory mining},
abstract = {Large volumes of mobility data is collected in various application domains. Enterprise applications are designed on the notion of centralised data control where the proprietary of the data rests with the enterprise and not with the user. This has consequences as evident by the occasional privacy breaches. Trajectory mining is an important data mining problem, however, trajectory data can disclose sensitive location information about users. In this work, we propose a decentralised blockchain-enabled privacy-preserving trajectory data mining framework where the proprietary of the data rests with the user and not with the enterprise. We formalise the privacy preservation in trajectory data mining settings, present a proposal for privacy preservation, and implement the solution as a proof-of-concept. A comprehensive experimental evaluation is conducted to assess the applicability of the system. The results show that the proposed system yields promising results for blockchain-enabled privacy preservation in user trajectory data.}
}
@article{LEYVAMAYORGA2019252,
title = {Adaptive access class barring for efficient mMTC},
journal = {Computer Networks},
volume = {149},
pages = {252-264},
year = {2019},
issn = {1389-1286},
doi = {https://doi.org/10.1016/j.comnet.2018.12.003},
url = {https://www.sciencedirect.com/science/article/pii/S1389128618308211},
author = {Israel Leyva-Mayorga and Miguel A. Rodriguez-Hernandez and Vicent Pla and Jorge Martinez-Bauset and Luis Tello-Oquendo},
keywords = {Access class barring (ACB), Adaptive filters, Internet of Things (IoT), LTE-A, Massive machine-type communications (mMTC)},
abstract = {In massive machine-type communications (mMTC), an immense number of wireless devices communicate autonomously to provide users with ubiquitous access to information and services. The current 4G LTE-A cellular system and its Internet of Things (IoT) implementation, the narrowband IoT (NB-IoT), present appealing options for the interconnection of these wireless devices. However, severe congestion may arise whenever a massive number of highly-synchronized access requests occur. Consequently, access control schemes, such as the access class barring (ACB), have become a major research topic. In the latter, the precise selection of the barring parameters in a real-time fashion is needed to maximize performance, but is hindered by numerous characteristics and limitations of the current cellular systems. In this paper, we present a novel ACB configuration (ACBC) scheme that can be directly implemented at the cellular base stations. In our ACBC scheme, we calculate the ratio of idle to total available resources, which then serves as the input to an adaptive filtering algorithm. The main objective of the latter is to enhance the selection of the barring parameters by reducing the effect of the inherent randomness of the system. Results show that our ACBC scheme greatly enhances the performance of the system during periods of high congestion. In addition, the increase in the access delay during periods of light traffic load is minimal.}
}
@article{THEODOROPOULOS2017540,
title = {The AXIOM platform for next-generation cyber physical systems},
journal = {Microprocessors and Microsystems},
volume = {52},
pages = {540-555},
year = {2017},
issn = {0141-9331},
doi = {https://doi.org/10.1016/j.micpro.2017.05.018},
url = {https://www.sciencedirect.com/science/article/pii/S0141933116304434},
author = {Dimitris Theodoropoulos and Somnath Mazumdar and Eduard Ayguade and Nicola Bettin and Javier Bueno and Sara Ermini and Antonio Filgueras and Daniel Jiménez-González and Carlos {Álvarez Martínez} and Xavier Martorell and Francesco Montefoschi and David Oro and Dionisis Pnevmatikatos and Antonio Rizzo and Paolo Gai and Stefano Garzarella and Bruno Morelli and Alberto Pomella and Roberto Giorgi},
keywords = {Cyber-physical systems, Distributed shared memory, Programming model, Performance evaluation, Reconfigurable, Smart video surveillance, Smart home living},
abstract = {Cyber-Physical Systems (CPSs) are widely used in many applications that require interactions between humans and their physical environment. These systems usually integrate a set of hardware-software components for optimal application execution in terms of performance and energy consumption. The AXIOM project (Agile, eXtensible, fast I/O Module), presented in this paper, proposes a hardware-software platform for CPS coupled with an easy parallel programming model and sufficient connectivity so that the performance can scale-up by adding multiple boards. AXIOM supports a task-based programming model based on OmpSs and leverages a high-speed, inexpensive communication interface called AXIOM-Link. The board also tightly couples the CPU with reconfigurable resources to accelerate portions of the applications. As case studies, AXIOM uses smart video surveillance, and smart home living applications.}
}
@article{FIOT2014718,
title = {Longitudinal deformation models, spatial regularizations and learning strategies to quantify Alzheimer's disease progression},
journal = {NeuroImage: Clinical},
volume = {4},
pages = {718-729},
year = {2014},
issn = {2213-1582},
doi = {https://doi.org/10.1016/j.nicl.2014.02.002},
url = {https://www.sciencedirect.com/science/article/pii/S2213158214000205},
author = {Jean-Baptiste Fiot and Hugo Raguet and Laurent Risser and Laurent D. Cohen and Jurgen Fripp and François-Xavier Vialard},
keywords = {Alzheimer's disease, Brain imaging, Deformation model, LDDMM, Disease progression, Karcher mean, Transport, Logistic regression, Spatial regularization, Coefficient map},
abstract = {In the context of Alzheimer's disease, two challenging issues are (1) the characterization of local hippocampal shape changes specific to disease progression and (2) the identification of mild-cognitive impairment patients likely to convert. In the literature, (1) is usually solved first to detect areas potentially related to the disease. These areas are then considered as an input to solve (2). As an alternative to this sequential strategy, we investigate the use of a classification model using logistic regression to address both issues (1) and (2) simultaneously. The classification of the patients therefore does not require any a priori definition of the most representative hippocampal areas potentially related to the disease, as they are automatically detected. We first quantify deformations of patients' hippocampi between two time points using the large deformations by diffeomorphisms framework and transport these deformations to a common template. Since the deformations are expected to be spatially structured, we perform classification combining logistic loss and spatial regularization techniques, which have not been explored so far in this context, as far as we know. The main contribution of this paper is the comparison of regularization techniques enforcing the coefficient maps to be spatially smooth (Sobolev), piecewise constant (total variation) or sparse (fused LASSO) with standard regularization techniques which do not take into account the spatial structure (LASSO, ridge and ElasticNet). On a dataset of 103 patients out of ADNI, the techniques using spatial regularizations lead to the best classification rates. They also find coherent areas related to the disease progression.}
}
@article{MISHRA2020100370,
title = {Assessment of solar power potential in a hill state of India using remote sensing and Geographic Information System},
journal = {Remote Sensing Applications: Society and Environment},
volume = {19},
pages = {100370},
year = {2020},
issn = {2352-9385},
doi = {https://doi.org/10.1016/j.rsase.2020.100370},
url = {https://www.sciencedirect.com/science/article/pii/S2352938520300835},
author = {Tripti Mishra and Amit Rabha and Ujjwal Kumar and Kusum Arunachalam and Vijay Sridhar},
keywords = {Mean solar radiation, Solar energy potential of hills, Rooftop solar photovoltaic (PV) potential, Geographic information system (GIS)},
abstract = {Estimation of the solar energy potential of the area is a pre-requisite for the large-scale deployment of photovoltaic (PV) panels. This study summarizes the solar PV potential at the rooftop areas of Uttarakhand through satellite imageries. The available rooftop area for solar PV system installation was estimated by a three-step hierarchical process including physical, geographic, and technical aspects. Our results showed that 58% area of the state receives solar radiation greater than 4 kWh/m2/day throughout the year. Using median efficiency (15%) of PV panels, the rooftop solar energy generation potential in hill region of Uttarakhand was estimated at 9.1 GWh from January to March, 12.7 GWh from April to June, 12.4 GWh from July to September and 7.7 GWh from October to December. If all available high irradiance roof-space (technical potential) is utilized for solar power generation it contributes about 57% of the state electricity consumption. The PV potential of field survey reports 27.47 GWh electricity output from the 234.4 MW ground-mounted solar PV systems and 5.9 MW rooftop solar PV systems in the plain district of Uttarakhand. Despite having high solar insolation, hills are ignored as potential solar energy sites due to their topography. Utilizing the flat rooftop surface to harvesting solar energy via solar PV panels can be a solution to issues arising due to undulating terrains of the mountains.}
}
@article{BHARATH2018201,
title = {Modelling urban dynamics in rapidly urbanising Indian cities},
journal = {The Egyptian Journal of Remote Sensing and Space Science},
volume = {21},
number = {3},
pages = {201-210},
year = {2018},
issn = {1110-9823},
doi = {https://doi.org/10.1016/j.ejrs.2017.08.002},
url = {https://www.sciencedirect.com/science/article/pii/S1110982316300722},
author = {H.A. Bharath and M.C. Chandan and S. Vinay and T.V. Ramachandra},
keywords = {Urban pattern, Modelling, AHP, Cellular Automata, Agent based modelling},
abstract = {Metropolitan cities in India are emerging as major economic hubs with an unprecedented land use changes and decline of environmental resources. Globalisation and consequent relaxations of Indian markets to global players has given impetus to rapid urbanisation process. Urbanisation being irreversible and rapid coupled with fast growth of population during the last century, contributed to serious ecological and environmental consequences. This necessitates monitoring and advance visualisation of spatial patterns of landscape dynamics for evolving appropriate management strategies towards sustainable development approaches. This study visualises the growth of Indian mega cities Delhi, Mumbai, Pune, Chennai and Coimbatore, through Cellular Automata Markov model considering the influence of agent(s) of urban growth through soft computing techniques. CA Markov model is considered to be one of most effective algorithm to visualise the growth of urban spatial structures. Prediction of growth using agent based modelling considering the spatial patterns of urbanisation during the past four decades has provided insights to the urban dynamics. The industrial, infrastructural, socio-economic factors significantly influence the urban growth compared to the biophysical factors. Visualisation of urban growth suggest agents driven growth in the cities and its surroundings with large land use transformations in urban corridors and upcoming Industrial and ear marked developmental zones. Integrating local agents of urban growth help in identifying specific regions of intense growth, likely challenges and provide opportunities for evolving appropriate management strategies towards sustainable cities during the 21st century.}
}
@article{DUTTA2020102067,
title = {Blockchain technology in supply chain operations: Applications, challenges and research opportunities},
journal = {Transportation Research Part E: Logistics and Transportation Review},
volume = {142},
pages = {102067},
year = {2020},
issn = {1366-5545},
doi = {https://doi.org/10.1016/j.tre.2020.102067},
url = {https://www.sciencedirect.com/science/article/pii/S1366554520307183},
author = {Pankaj Dutta and Tsan-Ming Choi and Surabhi Somani and Richa Butala},
keywords = {Blockchain, Supply chain, Logistics, Integration, Applications, Literature review},
abstract = {Blockchain is a technology with unique combination of features such as decentralized structure, distributed notes and storage mechanism, consensus algorithm, smart contracting, and asymmetric encryption to ensure network security, transparency and visibility. Blockchain has immense potential to transform supply chain (SC) functions, from SC provenance, business process reengineering to security enhancement. More and more studies exploring the use of blockchain in SCs have appeared in recent years. In this paper, we consider a total of 178 articles and examine all the relevant research done in the field associated with the use of blockchain integration in SC operations. We highlight the corresponding opportunities, possible societal impacts, current state-of-the-art technologies along with major trends and challenges. We examine several industrial sectors such as shipping, manufacturing, automotive, aviation, finance, technology, energy, healthcare, agriculture and food, e-commerce, and education among others that can be successfully revamped with blockchain based technologies through enhanced visibility and business process management. A future research agenda is established which lays the solid foundation for further studies on this important emerging research area.}
}
@article{DANIELS2021102754,
title = {Using foresight to explore the impacts of flooding in Houston on health, poverty, and equity out to 2050},
journal = {Futures},
volume = {131},
pages = {102754},
year = {2021},
issn = {0016-3287},
doi = {https://doi.org/10.1016/j.futures.2021.102754},
url = {https://www.sciencedirect.com/science/article/pii/S001632872100063X},
author = {Kimberly ''Kay'' Daniels and Terry Grim and Timothy Morgan},
keywords = {Foresight, Flooding, Houston, Resilience, Delphi, Qualitative text analysis, Cross impact analysis (CIA), Cross impact balances (CIB), Scenarios, Scenario archetypes},
abstract = {This paper presents a research study that is a valuable first project in setting the stage for bringing a foresight perspective to the impacts of severe flooding on health, poverty, and equity in Houston, out to the year 2050. Drawing on qualitative and quantitative research gathered from methodologies such as the Delphi and Cross-Impact Analysis combined with insights gained from interviews with subject-matter experts, it explores four alternative, plausible scenarios for Houston’s long-term future. Exploring scenarios that feature the continuation of present-day trends, a system collapse, a system balanced by a new equilibrium, and a system transformation provides an opportunity for stakeholders and policymakers to work together to create a more inclusive future for all city residents.}
}
@article{RICHTER2020119970,
title = {Towards an integrated urban development considering novel intelligent transportation systems: Urban Development Considering Novel Transport},
journal = {Technological Forecasting and Social Change},
volume = {155},
pages = {119970},
year = {2020},
issn = {0040-1625},
doi = {https://doi.org/10.1016/j.techfore.2020.119970},
url = {https://www.sciencedirect.com/science/article/pii/S0040162518319498},
author = {Andreas Richter and Marc-O. Löwner and Rüdiger Ebendt and Michael Scholz},
keywords = {Intelligent Transportation Systems, Urban development, Geo-databases, Toolchains, Data formats},
abstract = {Urban areas are currently facing new and enormous challenges: urbanization, connected and automated land and air transport with new demand for transport and logistic services, maintenance of more complex traffic and supply infrastructure as well as mandatory digitalization of cadastral information under the constraints of limited space and resources. Different stakeholders are interested in using detailed, precise and up-to-date data about the urban environment. These stakeholders are not only governmental bodies, road operators and (public) fleet managers but also companies that are interested in testing and operating new intelligent transportation systems and connected and automated vehicles in realistic and complex urban simulation environments. This article proposes a concept of how to tackle this complex task based on approaches already conducted in the domain of the development and test of automated driving and city modeling. Core elements of this thesis are an all-embracing geo-database, a toolchain to import, validate, process and fuse the necessary data as well as interfaces and data formats for automated data exchange. The feasibility and challenges as well as the potential and synergies of implementing of this concept are discussed by analyzing similar solutions in the key domains. The article concludes with a proposal to realize such a concept.}
}
@article{XIAO201880,
title = {Performance evaluation of IEEE 802.15.4 with real time queueing analysis},
journal = {Ad Hoc Networks},
volume = {73},
pages = {80-94},
year = {2018},
issn = {1570-8705},
doi = {https://doi.org/10.1016/j.adhoc.2018.01.006},
url = {https://www.sciencedirect.com/science/article/pii/S1570870518300167},
author = {Zhuoling Xiao and Jie Zhou and Junjie Yan and Chen He and Lingge Jiang and Niki Trigoni},
keywords = {IEEE 802.15.4, Queueing analysis, CSMA/CA, Energy consumption, Throughput},
abstract = {To provide a tool for performance evaluation of IEEE 802.15.4 with sleep mode enabled, a novel model based on real time queueing analysis is proposed in this paper. A low-rate wireless personal area network (LR-WPAN), composed of multiple nodes which send packets to the coordinator, is considered. The queueing behaviour of IEEE 802.15.4 node with sleep mode enabled differs from others because the packet arrivals in sleep period accumulate at the beginning of the active period, which makes a heavier load in the beginning than at any other time. This model analyses this behaviour by dividing the active portion of the superframe into backoff slots and then using an embedded discrete-time Markov chain model. The concept of virtual service time is introduced into this model which makes the proposed queueing model novel and different from typical ones. The accuracy of the proposed model is validated by Monte Carlo simulations in existing typical application scenarios, which indicates that the proposed queueing model can accurately evaluate the performance of IEEE 802.15.4 in the context of the application scenarios described in the simulations.}
}
@article{HUAN2020102088,
title = {Design of water quality monitoring system for aquaculture ponds based on NB-IoT},
journal = {Aquacultural Engineering},
volume = {90},
pages = {102088},
year = {2020},
issn = {0144-8609},
doi = {https://doi.org/10.1016/j.aquaeng.2020.102088},
url = {https://www.sciencedirect.com/science/article/pii/S0144860919301189},
author = {Juan Huan and Hui Li and Fan Wu and Weijian Cao},
keywords = {Aquaculture, The water quality, Monitoring, The internet of things, Narrow band internet of things},
abstract = {In order to promote the development of aquaculture informatization and monitor aquaculture ponds more accurately and conveniently, this article has developed a water quality monitoring system for aquaculture ponds based on the narrow band internet of things (NB-IoT) technology. This system realizes remote collection and data storage of multi-sensor processor information (temperature, pH, dissolved oxygen (DO) and other environmental parameters), as well as intelligent control and centralized management of breeding ponds. The system uses STM32L151C8 microcontroller and sensor terminal real-time acquisition, such as temperature, pH value, dissolved oxygen. It realizes data aggregation and transmission over a long distance to the Internet of things (IoT) telecom cloud platform through the technology of NB-IoT. The software called Keil implement the data format design of wireless communication module and data transmission. Java is used to develop background monitoring applications for accessing cloud platform, controlling underlying devices and local data processing. It can not only send hypertext transfer protocol (HTTP) requests to monitor cloud platform data, but also issue commands to the underlying control module to control the startup and shutdown of equipment such as aerator. The system was implemented and tested in ChangZhou, JiangSu Province, China. The experimental results showed that the system can obtain water quality parameters in time. The temperature control accuracy is maintained at ±0.12℃, the average relative error is 0.15 %, the dissolved oxygen control accuracy is maintained within ±0.55mg/L, the average relative error is 2.48 %, the pH control accuracy is maintained at ±0.09, and the average relative error is 0.21 %. The system has stable overall operation, real-time and accurate data transmission, which can meet the actual production needs and provide strong data and technical support for further water quality regulation and aquaculture production management.}
}
@article{LIN2022117791,
title = {Design and experiments of a thermoelectric-powered wireless sensor network platform for smart building envelope},
journal = {Applied Energy},
volume = {305},
pages = {117791},
year = {2022},
issn = {0306-2619},
doi = {https://doi.org/10.1016/j.apenergy.2021.117791},
url = {https://www.sciencedirect.com/science/article/pii/S0306261921011272},
author = {Qiliang Lin and Yi-Chung Chen and Fangliang Chen and Tejav DeGanyar and Huiming Yin},
keywords = {Smart building envelope, Energy harvesting, Wireless sensor platform, Energy equilibrium design},
abstract = {A new thermoelectric-powered wireless sensor network platform is presented for the low-cost environmental sensing in building envelopes through thermoelectric energy harvesting and ultra-low power management. It is designed and prototyped entirely inside a window frame without compromising architectural aesthetics. This self-powered sensing platform is achieved by maximizing the harvested energy from building envelopes and optimizing the wireless sensing unit’s energy consumption. It harvests milli-watt level thermoelectric power from the temperature gradient across building envelopes through thermoelectric generators with an optimized thermal connector. The harvested energy is voltage-boosted and regulated through two integrated circuits that are tailored for ultra-low-power input. A low power system-on-chip is used to supervise the environmental sensing and wireless data communication. The energy consumption is tailored by adjusting the system sleep time to match the harvested energy. The proposed platform is prototyped in a window frame and thoroughly tested, where 1.5 mW of power is harvested from thermoelectric generators under 6 °C of temperature difference, and a 33.4% efficiency to the battery. In the meantime, 0.42 mW power is consumed by the wireless sensing unit under a sampling period of 2 h, which reaches the energy equilibrium state. The energy equilibrium algorithm can project the battery energy based on historical weather conditions, so as to achieve the self-powered condition given a geographic location. This smart building envelope systems include the unique innovations in self-powered system architecture, thermally optimized internal structure, and milli-watt level power management.}
}
@article{KRUPITZER2015184,
title = {A survey on engineering approaches for self-adaptive systems},
journal = {Pervasive and Mobile Computing},
volume = {17},
pages = {184-206},
year = {2015},
note = {10 years of Pervasive Computing' In Honor of Chatschik Bisdikian},
issn = {1574-1192},
doi = {https://doi.org/10.1016/j.pmcj.2014.09.009},
url = {https://www.sciencedirect.com/science/article/pii/S157411921400162X},
author = {Christian Krupitzer and Felix Maximilian Roth and Sebastian VanSyckel and Gregor Schiele and Christian Becker},
keywords = {Taxonomy, Self-adaptation, Survey, Self-adaptive systems, Context adaptation},
abstract = {The complexity of information systems is increasing in recent years, leading to increased effort for maintenance and configuration. Self-adaptive systems (SASs) address this issue. Due to new computing trends, such as pervasive computing, miniaturization of IT leads to mobile devices with the emerging need for context adaptation. Therefore, it is beneficial that devices are able to adapt context. Hence, we propose to extend the definition of SASs and include context adaptation. This paper presents a taxonomy of self-adaptation and a survey on engineering SASs. Based on the taxonomy and the survey, we motivate a new perspective on SAS including context adaptation.}
}
@article{MCNAMARA2021103452,
title = {Intelligent contract adoption in the construction industry: Concept development},
journal = {Automation in Construction},
volume = {122},
pages = {103452},
year = {2021},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2020.103452},
url = {https://www.sciencedirect.com/science/article/pii/S0926580520310323},
author = {Alan J. McNamara and Samad M.E. Sepasgozar},
keywords = {Construction industry, iContract, Smart contract, Digitalisation, Big data, Blockchain, Automation},
abstract = {The digitalisation of the construction industry through revolutionary innovations, such as blockchain and intelligent contracts (iContracts), is becoming increasingly researched. However, a gap in current literature exists on the identification of contributing factors that will influence successful iContract development and adoption. This study aims to identify key considerations for iContracts in order to develop a novel theoretical adoption model and offer an agenda of six research directions for future iContract development. Through systematic analysis, forty-six key papers were identified with further thematic analysis highlighting the iContract technology's taxonomy. Content analysis then identified nine key themes of relevant considerations, barriers and contributing factors informing the development of the Tri-Dimensional iContract model. This study contributes to the iContract body of knowledge by identifying key considerations for the development and successful adoption of the iContract concept while offering a practical lens to direct future industry adoption and inform the development of iContract technologies.}
}
@article{SUN20151528,
title = {Prediction of stock index futures prices based on fuzzy sets and multivariate fuzzy time series},
journal = {Neurocomputing},
volume = {151},
pages = {1528-1536},
year = {2015},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2014.09.018},
url = {https://www.sciencedirect.com/science/article/pii/S092523121401176X},
author = {BaiQing Sun and Haifeng Guo and Hamid {Reza Karimi} and Yuanjing Ge and Shan Xiong},
keywords = {Fuzzy set theory, Multivariate fuzzy time series, Stock index futures},
abstract = {This paper makes a prediction of Chinese stock index (CSI) future prices using fuzzy sets and multivariate fuzzy time series method. We select Chinese CSI 300 index futures as the research object. The fuzzy time series model combines the fuzzy theory and the time series theory, thus this model can solve the fuzzy data in stock index futures prices. This paper establishes a multivariate model and improves the accuracy of computation. By combing traditional fuzzy time series models and rough set method, we use fuzzy c-mean algorithm to make the data into discrete. Further more, we deal with the rules in mature modules of the rough set and then refine the rules using data mining algorithms. Finally, we use the CSI 300 index futures to test our model and make a prediction of the prices.}
}
@article{YU2016106,
title = {Bag-of-visual-phrases and hierarchical deep models for traffic sign detection and recognition in mobile laser scanning data},
journal = {ISPRS Journal of Photogrammetry and Remote Sensing},
volume = {113},
pages = {106-123},
year = {2016},
issn = {0924-2716},
doi = {https://doi.org/10.1016/j.isprsjprs.2016.01.005},
url = {https://www.sciencedirect.com/science/article/pii/S0924271616000198},
author = {Yongtao Yu and Jonathan Li and Chenglu Wen and Haiyan Guan and Huan Luo and Cheng Wang},
keywords = {Bag-of-visual-phrases, Deep Boltzmann machine (DBM), Mobile laser scanning (MLS), Point cloud, Traffic sign detection, Traffic sign recognition (TSR)},
abstract = {This paper presents a novel algorithm for detection and recognition of traffic signs in mobile laser scanning (MLS) data for intelligent transportation-related applications. The traffic sign detection task is accomplished based on 3-D point clouds by using bag-of-visual-phrases representations; whereas the recognition task is achieved based on 2-D images by using a Gaussian-Bernoulli deep Boltzmann machine-based hierarchical classifier. To exploit high-order feature encodings of feature regions, a deep Boltzmann machine-based feature encoder is constructed. For detecting traffic signs in 3-D point clouds, the proposed algorithm achieves an average recall, precision, quality, and F-score of 0.956, 0.946, 0.907, and 0.951, respectively, on the four selected MLS datasets. For on-image traffic sign recognition, a recognition accuracy of 97.54% is achieved by using the proposed hierarchical classifier. Comparative studies with the existing traffic sign detection and recognition methods demonstrate that our algorithm obtains promising, reliable, and high performance in both detecting traffic signs in 3-D point clouds and recognizing traffic signs on 2-D images.}
}
@article{AHMAD2021101430,
title = {Maximum power point tracking and photovoltaic energy harvesting for Internet of Things: A comprehensive review},
journal = {Sustainable Energy Technologies and Assessments},
volume = {47},
pages = {101430},
year = {2021},
issn = {2213-1388},
doi = {https://doi.org/10.1016/j.seta.2021.101430},
url = {https://www.sciencedirect.com/science/article/pii/S2213138821004409},
author = {Fahad Faraz Ahmad and Chaouki Ghenai and Maamar Bettayeb},
keywords = {Renewable energy, Solar PV, MPPT, IoT, Energy harvesting},
abstract = {Internet of Things (IoT) is a powerful platform for connecting the physical world to the digital one. The recent development in IoT-based technologies has increased human-technology interaction and consequently improves the quality of life. Low-cost deployment, remote access, and the auto-mechanized operation of IoT nodes/sensors are attractive attributes that compel the wide adaption and mushrooming growth of IoT in environmental, health, and industrial applications. To confront the issue of energy scarcity, environmental energy harvesters (EHs) are imperative for self-powered and self-sustained IoT nodes. Indoor or outdoor light energy scavenging by PV panels is widely adopted for EH-IoT, as it is a source of higher energy density. Significant research efforts are required to deeply investigate the pros and cons of solar PV energy harvesters (PV-EH) towards self-sustainability goals. This study presents a comprehensive review of recent developments, comparative analysis of solar PV-EH, and algorithms for self-powered, self-sustained IoT nodes. The maximum power point tracking (MPPT) techniques for PV-EH-IoT are briefly elaborated and a concise summary of employed MPPT algorithm, converter type, input/output parameters, storage devices, as well as fabrication technology and power efficiency are presented in tabular form. Furthermore, the commercially available devices and integrated circuits (ICs) for ultra-low power solar PV-EH-IoT are introduced. Finally, the research issues and challenges in the development of PV-EH-IoT are presented. The outcome of this article includes a better understanding of current trends and progress in PV-EH-IoT focusing on MPPT techniques, challenges, and issues in the development.}
}
@article{HEJJA2021100419,
title = {Network slicing with load-balancing for task offloading in vehicular edge computing},
journal = {Vehicular Communications},
pages = {100419},
year = {2021},
issn = {2214-2096},
doi = {https://doi.org/10.1016/j.vehcom.2021.100419},
url = {https://www.sciencedirect.com/science/article/pii/S2214209621000887},
author = {Khaled Hejja and Sara Berri and Houda Labiod},
keywords = {Edge computing, Network slicing, Vehicular offloading, Load-balancing, Network function virtualization},
abstract = {The support of edge computing for vehicular technologies gained increasing momentum with 5G to fulfill efficient offloading tasks from vehicles towards the edge nodes. Accordingly, vehicles demanding powerful computation and large storage resources will be directed to communicate with the nearest edge computing nodes hosted at a wireless 5G new generation nodes (gNBs) or a road side units (RSUs). To efficiently utilize the edge nodes' resources, network slicing and load-balancing features can greatly help in that, therefore, this paper proposes an algorithm for Vehicular Edge Computing (VEC) with network slicing and load-balancing based on resources utilization, denoted as VECSlic-LB, specifically dedicated for offloading tasks from vehicles to edge nodes at gNBs or RSUs. The algorithm can holistically view and manage the whole network, and use network function virtualization framework to manage the data plane. VECSlic-LB can handle a mix of slicing configurations, capable of balancing the loads between various slices per node, and can support multiple edge computing nodes. Several simulations were conducted comparing the performance of the proposed algorithm to the optimal solution, resulting on very close acceptance ratios as the optimal solution, and also was evaluated against a recent reference algorithm, providing more efficient resource utilizations ratios, saving up to 48% of the resources better than the state-of-art algorithm.}
}
@article{HE2020160,
title = {Dynamic MRI reconstruction exploiting blind compressed sensing combined transform learning regularization},
journal = {Neurocomputing},
volume = {392},
pages = {160-167},
year = {2020},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2018.12.087},
url = {https://www.sciencedirect.com/science/article/pii/S0925231219304813},
author = {Ning He and Ruolin Wang and Yixue Wang},
keywords = {Dynamic MRI, BCS, Image reconstruction, Transform learning regularization, Sparsity priors},
abstract = {The goal of dynamic magnetic resonance imaging (dynamic MRI) is to visualize tissue properties and their local changes over time that are traceable in the MR signal. Compressed sensing enables the accurate recovery of images from highly under-sampled measurements by exploiting the sparsity of the images or image patches in a transform domain or dictionary. In this work, we focus on blind compressed sensing (BCS), where the underlying sparse signal model is a priori unknown, and propose a framework to simultaneously reconstruct the underlying image as well as the unknown model from highly under-sampled measurements. Specifically, in our model, the patches of the under-sampled images are approximately sparse in a transform domain. Transform learning that combines wavelet and gradient sparsity is considered as regularization in our model for dynamic MR images. The original complex problem is decomposed into several simpler subproblems, then each of the subproblems is efficiently solved with a variable splitting iterative scheme. The results of numerous experiments show that the proposed algorithm outperforms the state-of-the-art compressed sensing MRI algorithms and yields better reconstructions results.}
}
@article{TEECE20181367,
title = {Profiting from innovation in the digital economy: Enabling technologies, standards, and licensing models in the wireless world},
journal = {Research Policy},
volume = {47},
number = {8},
pages = {1367-1387},
year = {2018},
issn = {0048-7333},
doi = {https://doi.org/10.1016/j.respol.2017.01.015},
url = {https://www.sciencedirect.com/science/article/pii/S0048733318300763},
author = {David J. Teece},
keywords = {Appropriability, Complementarity, General-purpose technology, Licensing, Platform, Standards, Technology policy},
abstract = {The value-capture problem for innovators in the digital economy involves some different challenges from those in the industrial economy. It inevitably requires understanding the dynamics of platforms and ecosystems. These challenges are amplified for enabling technologies, which are the central focus of this article. The innovator of an enabling technology has a special business model challenge because the applicability to many downstream verticals forecloses, as a practical matter, ownership of all the relevant complements. Complementary assets (vertical and lateral) in the digital context are no longer just potential value-capture mechanisms (through asset price appreciation or through preventing exposure to monopolistic bottleneck pricing by others); they may well be needed simply for the technology to function. Technological and innovational complementors present both coordination and market design challenges to the innovator that generally lead to market failure in the form of an excess of social over private returns. The low private return leads to socially sub-optimal underinvestment in future R&D that can be addressed to some extent by better strategic decision-making by the innovator and/or by far-sighted policies from government and the judiciary. The default value-capture mechanism for many enabling technologies is the licensing of trade secrets and/or patents. Licensing is shown to be a difficult business model to implement from a value-capture perspective. When injunctions for intellectual property infringement are hard to win, or even to be considered, the incentives for free riding by potential licensees are considerable. Licensing is further complicated if it involves standard essential patents, as both courts and policy makers may fail to understand that development of a standard involves components of both interoperability and technology development. If a technology standard is not treated as the embodiment of significant R&D efforts enabling substantial new downstream economic activity, then rewards are likely to be calibrated too low to support appropriate levels of future innovation.}
}
@article{AMAH201651,
title = {Towards next-generation routing protocols for pocket switched networks},
journal = {Journal of Network and Computer Applications},
volume = {70},
pages = {51-88},
year = {2016},
issn = {1084-8045},
doi = {https://doi.org/10.1016/j.jnca.2016.05.011},
url = {https://www.sciencedirect.com/science/article/pii/S1084804516301072},
author = {Tekenate E. Amah and Maznah Kamat and Waldir Moreira and Kamalrulnizam {Abu Bakar} and Satria Mandala and Marcos A. Batista},
keywords = {Pocket, Networks, Opportunistic, Delay tolerant, Routing, Protocols},
abstract = {A pocket switched network (PSN) is dynamically formed by people who carry portable handheld devices. Interest in PSNs is driven by the increasing number of handheld devices, the several wireless interfaces they possess, as well as their ability to store, carry and forward data. The lack of fixed network topology distinguishes PSNs from traditional networks, and unlike other types of mobile networks, nodes in PSNs closely follow human movement patterns. As a result, PSNs are faced with new challenges especially in the aspect of routing. Although various routing protocols have been proposed, most of them focus on optimizing the performance of networking primitives for traditional networks such as unicast, broadcast and multicast. However, these primitives themselves appear to be insufficient due to new application opportunities presented by PSNs. This paper adopts a user scenario based approach to determine the current state of PSN routing protocols. Specifically, four modes of data transfer are established from six generalized PSN user scenarios. Due to the wide range of existing routing proposals, a new taxonomy is proposed to facilitate analysis of their compatibility with the established modes of data transfer. The analysis provides new insights into application based routing approaches for realizing next-generation PSN routing protocols.}
}
@article{COBBEN2022138,
title = {Ecosystem types: A systematic review on boundaries and goals},
journal = {Journal of Business Research},
volume = {142},
pages = {138-164},
year = {2022},
issn = {0148-2963},
doi = {https://doi.org/10.1016/j.jbusres.2021.12.046},
url = {https://www.sciencedirect.com/science/article/pii/S0148296321009607},
author = {Dieudonnee Cobben and Ward Ooms and Nadine Roijakkers and Agnieszka Radziwon},
keywords = {Business ecosystem, Entrepreneurial ecosystem, Innovation ecosystem, Knowledge ecosystem, Systematic literature review},
abstract = {In the past few years, we have witnessed a reinvigorated interest by academics, practitioners and policymakers in the ecosystem concept. Recent reviews have set out to clarify the conceptual boundaries between ecosystem concepts. Yet there is still a lack of clarity when it comes to which ecosystem types can best help organisations achieve various goals. This systematic literature review advances our understanding of the conceptual boundaries between different ecosystems and, more importantly, identifies which types of ecosystems are suitable for achieving the goals. We focus on four commonly studied ecosystem types: business, innovation, entrepreneurship and knowledge ecosystems. The key findings centre on systematically demarcating the ecosystem types by accounting for (and distinguishing between) their conceptual boundaries and goals. The results show how multifaceted ecosystem goals are and reveal several shifts in the literature on ecosystem types over time. Our review establishes a thematic agenda for future research with practical outlook.}
}
@article{ELKANO201875,
title = {CHI-BD: A fuzzy rule-based classification system for Big Data classification problems},
journal = {Fuzzy Sets and Systems},
volume = {348},
pages = {75-101},
year = {2018},
note = {SI: Fuzzy Approaches to Big Data},
issn = {0165-0114},
doi = {https://doi.org/10.1016/j.fss.2017.07.003},
url = {https://www.sciencedirect.com/science/article/pii/S0165011417302774},
author = {Mikel Elkano and Mikel Galar and Jose Sanz and Humberto Bustince},
keywords = {Fuzzy Rule-Based Classification Systems, Big Data, Hadoop, MapReduce, Imbalanced datasets},
abstract = {The previous Fuzzy Rule-Based Classification Systems (FRBCSs) for Big Data problems consist in concurrently learning multiple Chi et al. FRBCSs whose rule bases are then aggregated. The problem of this approach is that different models are obtained when varying the configuration of the cluster, becoming less accurate as more computing nodes are added. Our aim with this work is to design a new FRBCS for Big Data classification problems (CHI-BD) which is able to provide exactly the same model as the one that would be obtained by the original Chi et al. algorithm if it could be executed with this quantity of data. In order to do so, we take advantage of the suitability of the Chi et al. algorithm for the MapReduce paradigm, solving the problems of the previous approach, which lead us to obtain the same model (i.e., classification accuracy) regardless of the number of computing nodes considered.}
}
@article{SAMAILA2021108496,
title = {Performance evaluation of the SRE and SBPG components of the IoT hardware platform security advisor framework},
journal = {Computer Networks},
volume = {199},
pages = {108496},
year = {2021},
issn = {1389-1286},
doi = {https://doi.org/10.1016/j.comnet.2021.108496},
url = {https://www.sciencedirect.com/science/article/pii/S1389128621004370},
author = {Musa G. Samaila and Carolina Lopes and Édi Aires and João B.F. Sequeiros and Tiago Simões and Mário M. Freire and Pedro R.M. Inácio},
keywords = {Internet of Things, IoT security, Privacy in IoT, Security framework, IoT-HarPSecA, IoT security requirements, IoT standards, IoT security best practices},
abstract = {The applications of Internet of Things (IoT) and associated technologies have been spreading rapidly across a wide range of domains, including environmental monitoring, home automation, and supply chain, having a significant bearing on the social and economic well-being of humans as well as enhancing environmental sustainability. In recent years, however, there have been several data breaches and other security and privacy incidents involving IoT devices, which have attracted significant attention from the research community in both academia and industry. This has resulted in a surge of proposals put forward by many researchers, including IoT blockchain-based security solutions, IoT intrusion detection systems, IoT authentication systems, and IoT security analytics. While these proposals are aimed at addressing various IoT security and privacy-related issues, many of these solutions arguably seem not to focus on helping designers and developers with little or no security expertise in start-up companies to produce secure IoT systems. To this end, the IoT Hardware Platform Security Advisor (IoT-HarPSecA) framework was proposed to foster the design and implementation of secure IoT systems. In this paper, we present the performance and usability evaluation of the Security Requirements Elicitation (SRE) and Security Best Practice Guidelines (SBPG) component tools of IoT-HarPSecA, which are two of the three component tools of the security framework. Results show that the two components of the IoT-HarPSecA framework can facilitate the development of secure IoT systems and that the SRE and SBPG tools are easy to use.}
}
@article{SAMULEVICIUS2014494,
title = {Lattice-based Spatio-temporal Ensemble Prediction},
journal = {Procedia Computer Science},
volume = {35},
pages = {494-503},
year = {2014},
note = {Knowledge-Based and Intelligent Information & Engineering Systems 18th Annual Conference, KES-2014 Gdynia, Poland, September 2014 Proceedings},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2014.08.130},
url = {https://www.sciencedirect.com/science/article/pii/S1877050914010953},
author = {Saulius Samulevičius and Yoann Pitarch and Torben Bach Pedersen},
keywords = {Time series, prediction, spatio-temporal, ensemble, context, lattice, hierarchy, latent attributes},
abstract = {With the rapidly increasing deployment of sensor networks, large amounts of time series data are generated. One of the main challenges when dealing with such data is performing accurate predictions in order to address a broad class of application problems, ranging from mobile broadband network (MBN) optimization to preventive maintenance. To this end, time series prediction has been widely addressed by the statistics community. Nevertheless, such approaches fail in performing well when the data are more context-dependent than history-dependent. In this paper, we investigate how latent attributes can be built upon the time series in order to define a spatio-temporal context for predictions. Moreover, such attributes are often hierarchical, leading to multiple potential contexts at different levels of granularity for performing a given prediction. In support of this scenario, we propose the Lattice-Based Spatio-Temporal Ensemble Prediction (LBSTEP) approach, which allows modeling the problem as a multidimensional spatio-temporal prediction. Given an ensemble prediction model, we propose a solution for determining the most appropriate spatio-temporal context that maximizes the global prediction metrics of a set of the time series. LBSTEP is evaluated with a real-world MBN dataset, which exemplifies the intended general application domain of time series data with a strong spatio-temporal component. The experimental results shows that the proposed contextual and multi-granular view of the prediction problem is effective, in terms of both several optimization metrics and the model calculation.}
}
@article{CHEN2022127901,
title = {Joint compressed sensing and JPEG coding based secure compression scheme in OFDM-PON},
journal = {Optics Communications},
volume = {510},
pages = {127901},
year = {2022},
issn = {0030-4018},
doi = {https://doi.org/10.1016/j.optcom.2022.127901},
url = {https://www.sciencedirect.com/science/article/pii/S0030401822000025},
author = {Yuhang Chen and Chongfu Zhang and Mengwei Cui and Yufeng Luo and Tingwei Wu and Xinshuai Liang},
keywords = {Secure compression, Compressed sensing, JPEG, Random DNA encryption, OFDM-PON},
abstract = {This paper proposes a secure compressed communication scheme in orthogonal frequency division multiplexing passive optical network (OFDM-PON) based on joint compressed sensing and JPEG coding (JCS-JPEG) and multilevel encryption, with a focus to its application in secure storage and transmission. Specifically, working with the under-sampling data of compressed sensing (CS), we combine the JPEG coding standard to deepen compression into the storage and transmission link while inserting random factors into Deoxyribonucleic Acid (DNA) encryption to improve the security of the physical layer. The rationale behind the joint compression is that the data after CS is suitable for block quantization and entropy encoding methods to compress further, similar to the JPEG encoding. For the compression of multimedia data, we demonstrate that it can achieve a satisfactory reconstruction effect and provide an additional 5 to 8 times compression ratio on images. Moreover, we show that the DCT coefficient encryption and random DNA encryption can be seamlessly incorporated into the encryption in CS through the two dimensions of a 2D-chaotic map, thus realizing secure compression and transmission when under-sampling. The proposed scheme is expected to reduce the computational complexity and storage pressure of light resource-constrained sensors, simultaneously improve bandwidth utilization and sensitive information protection in OFDM-PON.}
}
@article{CEBRIAN2020401,
title = {High-throughput fuzzy clustering on heterogeneous architectures},
journal = {Future Generation Computer Systems},
volume = {106},
pages = {401-411},
year = {2020},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2020.01.022},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X19313883},
author = {Juan M. Cebrian and Baldomero Imbernón and Jesus Soto and José M. García and José M. Cecilia},
keywords = {Parallel fuzzy clustering, Fuzzy clustering, Fuzzy minimals},
abstract = {The Internet of Things (IoT) is pushing the next economic revolution in which the main players are data and immediacy. IoT is increasingly producing large amounts of data that are now classified as “dark data” because most are created but never analyzed. The efficient analysis of this data deluge is becoming mandatory in order to transform it into meaningful information. Among the techniques available for this purpose, clustering techniques, which classify different patterns into groups, have proven to be very useful for obtaining knowledge from the data. However, clustering algorithms are computationally hard, especially when it comes to large data sets and, therefore, they require the most powerful computing platforms on the market. In this paper, we investigate coarse and fine grain parallelization strategies in Intel and Nvidia architectures of fuzzy minimals (FM) algorithm; a fuzzy clustering technique that has shown very good results in the literature. We provide an in-depth performance analysis of the FM’s main bottlenecks, reporting a speed-up factor of up to 40× compared to the sequential counterpart version.}
}
@article{SHARMA201663,
title = {Expanded cloud plumes hiding Big Data ecosystem},
journal = {Future Generation Computer Systems},
volume = {59},
pages = {63-92},
year = {2016},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2016.01.003},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X16000054},
author = {Sugam Sharma},
keywords = {Cloud, Big Data, Smart Data and Lakes, IoT, XCLOUDX, as-a-Service},
abstract = {Today, a paradigm shift is being observed in science, where the focus is gradually shifting away from operation to data, which is greatly influencing the decision making also. The data is being inundated proactively from several sources in various forms; especially social media and in modern data science vocabulary is being recognized as Big Data. Today, Big Data is permeating through the bigger aspect of human life for scientific and commercial dependencies, especially for massive scale data analytics of beyond the exabyte magnitude. As the footprint of Big Data applications is continuously expanding, the reliability on cloud environments is also increasing to obtain appropriate, robust and affordable services to deal with Big Data challenges. Cloud computing avoids any need to locally maintain the overly scaled computing infrastructure that include not only dedicated space, but the expensive hardware and software also. Several data models to process Big Data are already developed and a number of such models are still emerging, potentially relying on heterogeneous underlying storage technologies, including cloud computing. In this paper, we investigate the growing role of cloud computing in Big Data ecosystem. Also, we propose a novel XCLOUDX {XCloudX, X…X}classification to zoom in to gauge the intuitiveness of the scientific name of the cloud-assisted NoSQL Big Data models and analyze whether XCloudX always uses cloud computing underneath or vice versa. XCloudX symbolizes those NoSQL Big Data models that embody the term “cloud” in their name, where X is any alphanumeric variable. The discussion is strengthen by a set of important case studies. Furthermore, we study the emergence of as-a-Service era, motivated by cloud computing drive and explore the new members beyond traditional cloud computing stack, developed in the past couple of years.}
}
@article{AMIRJAVID20192366,
title = {A Fuzzy Data-Driven Paradigmatic Predictor},
journal = {IFAC-PapersOnLine},
volume = {52},
number = {13},
pages = {2366-2371},
year = {2019},
note = {9th IFAC Conference on Manufacturing Modelling, Management and Control MIM 2019},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2019.11.560},
url = {https://www.sciencedirect.com/science/article/pii/S2405896319315472},
author = {Farzad Amirjavid and Hamidreza Nemati and Sasan Barak},
keywords = {Fuzzy logic, temporal data analytics, adaptive learning, systems theory},
abstract = {Data-driven prediction of future events is to provide decision-makers Predictive Information (PI) to decrease human-error. They usually desire possession of a predictor which works independently from the humanized configurations and works efficiently and accurately. The accurate data-driven prediction of the systems’ behavior is the primary focus of this paper. We define the future state of a system is a set of uncertain values, which can be modeled by fuzzy numbers. The future machine state is not very dissimilar to the current status, and the next event is a sort of behavior repetition. The PI also justifies the system being in a trend to achieve a goal, and it counts the unplanned contextual reactions of the system. In this paper, we come up with a fuzzy data-driven predictor application to foretell the system behavior.}
}
@article{RADOGLOUGRAMMATIKIS201941,
title = {Securing the Internet of Things: Challenges, threats and solutions},
journal = {Internet of Things},
volume = {5},
pages = {41-70},
year = {2019},
issn = {2542-6605},
doi = {https://doi.org/10.1016/j.iot.2018.11.003},
url = {https://www.sciencedirect.com/science/article/pii/S2542660518301161},
author = {Panagiotis I. {Radoglou Grammatikis} and Panagiotis G. Sarigiannidis and Ioannis D. Moscholios},
keywords = {Countermeasures, Cyberattacks, Internet of Things, Privacy, Protocols, Risk assessment, Security},
abstract = {The Internet of Things (IoT) is the next technological leap that will introduce significant improvements to various aspects of the human environment, such as health, commerce, and transport. However, despite the fact that it may bring beneficial economic and social changes, the security and the privacy protection of objects and users remain a crucial challenge that has to be addressed. Specifically, now the security measures have to monitor and control the actions both of users and objects. However, the interconnected and independent nature of objects, as well as their constrained capabilities regarding the computing resources make impossible the applicability of the conventional security mechanisms. Moreover, the heterogeneity of various technologies which the IoT combines increases the complexity of the security processes, since each technology is characterized by different vulnerabilities. Furthermore, the tremendous amounts of data which is generated by the multiple interactions between the users and objects or among the objects make harder their management and the functionality of the access control systems. In this context, this paper intends to provide a comprehensive security analysis of the IoT, by examining and assessing the potential threats and countermeasures. More detailed, after studying and determining the security requirements in the context of the IoT, we implement a qualitative and quantitative risk analysis, investigating the security threats per layer. Subsequently, based on this process we identify the suitable countermeasures and their limitations, paying special attention to the IoT protocols. Finally, we provide research directions for future work.}
}
@article{DELVILLAR2017174,
title = {Optical sensors based on lossy-mode resonances},
journal = {Sensors and Actuators B: Chemical},
volume = {240},
pages = {174-185},
year = {2017},
issn = {0925-4005},
doi = {https://doi.org/10.1016/j.snb.2016.08.126},
url = {https://www.sciencedirect.com/science/article/pii/S0925400516313594},
author = {Ignacio {Del Villar} and Francisco J. Arregui and Carlos R. Zamarreño and Jesus M. Corres and Candido Bariain and Javier Goicoechea and Cesar Elosua and Miguel Hernaez and Pedro J. Rivero and Abian B. Socorro and Aitor Urrutia and Pedro Sanchez and Pablo Zubiate and Diego Lopez and Nerea {De Acha} and Joaquin Ascorbe and Ignacio R. Matias},
keywords = {Optical sensor, Resonance, Thin-film, Waveguide, Hydrogel, Biosensor},
abstract = {Lossy-mode resonance (LMR)–based optical sensing technology has emerged in the last two decades as a nanotechnological platform with very interesting and promising properties. LMR complements the metallic materials typically used in surface plasmon resonance (SPR)–based sensors, with metallic oxides and polymers. In addition, it enables one to tune the position of the resonance in the optical spectrum, to excite the resonance with both transverse electric (TE) and transverse magnetic (TM) polarized light, and to generate multiple resonances. The domains of application are numerous: as sensors for detection of refractive indices voltage, pH, humidity, chemical species, and antigens, as well as biosensors. This review will discuss the bases of this relatively new technology and will show the main contributions that have permitted the optimization of its performance to the point that the question arises as to whether LMR–based optical sensors could become the sensing platform of the near future.}
}
@article{TULI2020595,
title = {Shared data-aware dynamic resource provisioning and task scheduling for data intensive applications on hybrid clouds using Aneka},
journal = {Future Generation Computer Systems},
volume = {106},
pages = {595-606},
year = {2020},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2020.01.038},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X19319508},
author = {Shreshth Tuli and Rajinder Sandhu and Rajkumar Buyya},
keywords = {Shared file aware, Dynamic provisioning, Task scheduling, Hybrid cloud, Aneka platform as a service, Data-intensive applications},
abstract = {In the recent years, data-intensive applications have been growing at an increasing rate and there is a critical need to solve the high-performance and scalability issues. Hybrid Cloud Computing paradigm provides a promising solution to harness local infrastructure and remote resources and provide high Quality of Service (QoS) for time sensitive and data-intensive applications. Generally, hybrid cloud deployments have a heterogeneous pool of resources and it becomes a challenging task to efficiently utilize resources to provide optimum results. In modern data hungry applications, it is crucial to optimize bandwidth consumption, latency and networking overheads. Moreover, most of them have large extent of file sharing capability. The existing algorithms do not explicitly consider file sharing scenarios that leads large data transmission times and has severe effects on latency. In this direction, this paper focuses on building upon existing dynamic resource provisioning and task scheduling algorithms to provide better QoS in hybrid cloud environments for data intensive applications in a shared file task environment. The efficiency of proposed algorithms is demonstrated by deploying them on Microsoft Azure using Aneka, a platform for developing scalable applications on the Cloud. Experiments using real-world applications and datasets show that proposed algorithms are able to allocate tasks and extend to public cloud resources more efficiently, reducing deadline violations and improving response times to give response time reduction of upto 40.12% for a sample local alignment search application on genome sequences.}
}
@article{LERAY2020111258,
title = {The ethical smart grid: Enabling a fruitful and long-lasting relationship between utilities and customers},
journal = {Energy Policy},
volume = {140},
pages = {111258},
year = {2020},
issn = {0301-4215},
doi = {https://doi.org/10.1016/j.enpol.2020.111258},
url = {https://www.sciencedirect.com/science/article/pii/S0301421520300185},
author = {G. {Le Ray} and P. Pinson},
keywords = {Big data, Privacy, Smart meter, Smart grid, Ethics},
abstract = {The European Union is implementing ambitious programs to tackle energy efficiency, energy independence, and climate change challenges. To reach the 20/20/20 targets, the EU aims at modernizing power grids to make them ‘smart’ by collecting close to real-time data and subsequently operate grids more optimally. One of the smart grid purposes is to integrate a growing share of renewable generation while efficiently accommodating their variability and limited predictability through the actuation of consumer flexibility. Hence, the success of energy programs relies on customer involvement in altering their energy consumption through the use of analytics and incentive-based demand-side management. The rollout of smart meters throughout Europe should provide the necessary information to implement them. This is without accounting for a possible backlash of customers in response to bad practices of utilities when it comes to digitization and smart meter rollout, also associated with the potential distrust of digital products. Beyond legal binds and technical obstacles, the possible ways of handling the rollout of smart meters and metering, which defines the relationship between customers and utilities, are multiple. However, only the practices that exhibit ethical behavior of the utilities towards customers, and consider them as stakeholders in smart grids will lead to a fruitful and long-lasting relationship between customers and utilities.}
}
@article{ZANFERRARIMORAIS2020102655,
title = {When SDN meets C-RAN: A survey exploring multi-point coordination, interference, and performance},
journal = {Journal of Network and Computer Applications},
volume = {162},
pages = {102655},
year = {2020},
issn = {1084-8045},
doi = {https://doi.org/10.1016/j.jnca.2020.102655},
url = {https://www.sciencedirect.com/science/article/pii/S1084804520301296},
author = {Fernando {Zanferrari Morais} and Cristiano {André da Costa} and Antonio Marcos Alberti and Cristiano {Bonato Both} and Rodrigo {da Rosa Righi}},
keywords = {SDN, Cloud RAN, CoMP, ICIC, Fronthaul, 5G},
abstract = {The transformation of mobile networks towards fifth generation (5G) is considered an unprecedented revolution when compared to the previous generations, mainly because of the support required for three scenarios: ultra reliable and low latency; high throughput broadband; and massive machine type communication. In this context, the evolution from RAN to C-RAN is a significant contribution to advance the deployment of this new generation. C-RAN concepts bring opportunities like centralized processing, improved interference control, flexible fronthaul networks, and support for ultra-dense heterogeneous radio access networks. SDN emerges as a candidate technology for the development of programmable 5G networks, with centralized orchestration and control/data planes decoupling. In this article, we propose a systematic literature review to cover SDN application in the context of 5G communication and C-RAN. In combination with the concepts as mentioned earlier, the article evaluates coordination and interference management features provided by Coordinated Multi-point and Inter-cell Interference Coordination techniques, besides reviewing fronthaul transport tier capabilities offered by SDN for 5G networks. A careful literature analysis shows that there are no revisions with the same focus as that developed in this survey. As contributions, this article presents a novel taxonomy of SDN technology, enabling C-RAN, as well as trending directions and development opportunities for SDN and C-RAN-based 5G networks.}
}
@article{GALLINELLI2017391,
title = {CityFeel - micro climate monitoring for climate mitigation and urban design},
journal = {Energy Procedia},
volume = {122},
pages = {391-396},
year = {2017},
note = {CISBAT 2017 International ConferenceFuture Buildings & Districts – Energy Efficiency from Nano to Urban Scale},
issn = {1876-6102},
doi = {https://doi.org/10.1016/j.egypro.2017.07.427},
url = {https://www.sciencedirect.com/science/article/pii/S1876610217332605},
author = {Peter Gallinelli and Reto Camponovo and Victor Guillot},
keywords = {climate mitigation, micro climate monitoring, urban design, open data},
abstract = {While a significant part of the population is concentrated in urban areas, the influence of cityscape parameters on human heat stress remain poorly understood. Yet we agree to develop urban spaces (street, square, district ...) in a way to provide best possible quality of life. In order to do so, quantitative and qualitative references are required. To fill this gap the HES-SO††University of Applied Sciences and Arts of Western Switzerland - hepia/leea‡‡Haute école du paysage, d’ingénierie et d’architecture de Genève / Laboratory for energy, environment and architecture has developed an innovative portable monitoring system that can be easily deployed in various outdoor and indoor environments. The monitoring equipment is embedded into a backpack that is carried during ‘climatic urban walks’ that can be reproduced at different times of the day or seasons so to yield a detailed and dynamic description of the climatic context of a portion of the city from the pedestrian point of view.}
}
@article{MUNSHI2017369,
title = {Big data framework for analytics in smart grids},
journal = {Electric Power Systems Research},
volume = {151},
pages = {369-380},
year = {2017},
issn = {0378-7796},
doi = {https://doi.org/10.1016/j.epsr.2017.06.006},
url = {https://www.sciencedirect.com/science/article/pii/S0378779617302559},
author = {Amr A. Munshi and Yasser A.-R. I. Mohamed},
keywords = {Smart grid, Smart meters, Big data, Data management, Dynamic demand response},
abstract = {Smart meters are being deployed replacing conventional meters worldwide and to enable automated collection of energy consumption data. However, the massive amounts of data evolving from smart grid meters used for monitoring and control purposes need to be sufficiently managed to increase the efficiency, reliability and sustainability of the smart grid. Interestingly, the nature of smart grids can be considered as a big data challenge that requires advanced informatics techniques and cyber-infrastructure to deal with huge amounts of data and their analytics. For that, this unprecedented smart grid data require an effective platform that takes the smart grid a step forward in the big data era. This paper presents a framework that can be a start for innovative research and take smart grids a step forward. An implementation of the framework on a secure cloud-based platform is presented. Furthermore, the framework has been applied on two scenarios to visualize the energy, for a single-house and a smart grid that contains over 6000 smart meters. The application of the two scenarios to visualize the grid status and enable dynamic demand response, suggests that the framework is feasible in performing further smart grid data analytics.}
}
@article{RAN2021116823,
title = {Demand response to improve the shared electric vehicle planning: Managerial insights, sustainable benefits},
journal = {Applied Energy},
volume = {292},
pages = {116823},
year = {2021},
issn = {0306-2619},
doi = {https://doi.org/10.1016/j.apenergy.2021.116823},
url = {https://www.sciencedirect.com/science/article/pii/S0306261921003238},
author = {Cuiling Ran and Yanzi Zhang and Ying Yin},
keywords = {Energy management, Sustainable operations, Electric vehicle sharing operations, Demand response, Shared mobility},
abstract = {Massive adoption of shared electric mobility benefits people’s daily commute and environment but creates overload issues into the power grid, then further cause challenges to charging service operations and power management. Previous research always focuses on single optimization process on shared vehicle planning, rather than the combination of demand management into day-ahead planning operations. To this end, we attempt to propose a mixed integer programming model integrating demand response operations to further explore the impacts of demand response on shared electric vehicle planning operations. We first model a two-stages model integrating charging facility location in the first stage and vehicle relocation in the second stage. Moreover, both supply-side and demand-side uncertainties are considered and approximated into tractable form by applying sample average approximation and distributional robust set featuring the entropy knowledge and electric vehicle’s multi-level charging duration. The demand response policy is also proposed to reshape the original charging demand into an economical and reliable way to improve operational efficiency and mitigate the power overload issues caused by massive electric vehicle adoption. Further, we conduct a real-world case study in Amsterdam, the Netherlands, to explore the social-operational impacts of vehicle planning optimization model integrating the demand response, robust charging facility planning in three areas: (1) The demand response integration promote electric vehicle planning operations on cost-saving for about 3%. (2) Data richness of serviceability towards charging piles influence all decisions through the shared electric vehicle charging station planning. (3) A trade-off exists between technical progress on charging rate and charging technology stability.}
}
@article{DACRUZ201853,
title = {Performance evaluation of IoT middleware},
journal = {Journal of Network and Computer Applications},
volume = {109},
pages = {53-65},
year = {2018},
issn = {1084-8045},
doi = {https://doi.org/10.1016/j.jnca.2018.02.013},
url = {https://www.sciencedirect.com/science/article/pii/S108480451830064X},
author = {Mauro A.A. {da Cruz} and Joel J.P.C. Rodrigues and Arun Kumar Sangaiah and Jalal Al-Muhtadi and Valery Korotaev},
keywords = {Internet of things, IoT, Middleware, Platform, Performance metrics, Qualitative, Quantitative, Performance assessment},
abstract = {Connected objects in a billion scale are expected in the Internet of Things (IoT). These objects (“things”) are interacting autonomously, with minimal human intervention and connected to the Internet. Most of these objects are constrained in terms of resources, meaning that their intelligence is delegated to a smarter player, a software, identified as middleware. It is present in most IoT scenarios because it solves interoperability problems, allowing previously incompatible devices to communicate, while also integrates and makes decisions based on collected data. This paper presents a performance evaluation study of open-source middleware solutions, including a proprietary solution developed at Inatel for the Inatel Smart Campus. Performance metrics, both qualitative and quantitative to evaluate middleware solutions objectively are also proposed. The results are analyzed and it is concluded that the proposed metrics are well adjusted for this type of platforms and can play a key role when choosing the best middleware solution to deploy in a given IoT solution. Sitewhere is the middleware platform that obtained better performance in the study.}
}
@article{MONOSTORI2016621,
title = {Cyber-physical systems in manufacturing},
journal = {CIRP Annals},
volume = {65},
number = {2},
pages = {621-641},
year = {2016},
issn = {0007-8506},
doi = {https://doi.org/10.1016/j.cirp.2016.06.005},
url = {https://www.sciencedirect.com/science/article/pii/S0007850616301974},
author = {L. Monostori and B. Kádár and T. Bauernhansl and S. Kondoh and S. Kumara and G. Reinhart and O. Sauer and G. Schuh and W. Sihn and K. Ueda},
keywords = {Manufacturing systems, Cyber-physical systems, Distributed systems},
abstract = {One of the most significant advances in the development of computer science, information and communication technologies is represented by the cyber-physical systems (CPS). They are systems of collaborating computational entities which are in intensive connection with the surrounding physical world and its on-going processes, providing and using, at the same time, data-accessing and data-processing services available on the Internet. Cyber-physical production systems (CPPS), relying on the latest, and the foreseeable further developments of computer science, information and communication technologies on one hand, and of manufacturing science and technology, on the other, may lead to the 4th industrial revolution, frequently noted as Industrie 4.0. The paper underlines that there are significant roots in general – and in particular to the CIRP community – which point towards CPPS. Expectations towards research in and implementation of CPS and CPPS are outlined and some case studies are introduced. Related new R&D challenges are highlighted.}
}
@article{YOUSEFI2020106733,
title = {An energy-efficient artificial bee colony-based clustering in the internet of things},
journal = {Computers & Electrical Engineering},
volume = {86},
pages = {106733},
year = {2020},
issn = {0045-7906},
doi = {https://doi.org/10.1016/j.compeleceng.2020.106733},
url = {https://www.sciencedirect.com/science/article/pii/S0045790620305887},
author = {Shamim Yousefi and Farnaz Derakhshan and Hadi S. Aghdasi and Hadis Karimipour},
keywords = {Artificial bee colony (ABC) algorithm, Clustering, Data transmission delay, Energy efficiency, Internet of things (IoT), Wireless communication},
abstract = {Wireless communication on the Internet of Things (IoT) requires context-aware data transmission protocols. Developing an energy-efficient clustering mechanism is the primary challenge in data transmission over IoT. The existing approaches struggle with the short lifetime of IoT, imbalance load distribution, and high transmission delay. This paper proposes a novel cluster-head selection and clustering mechanism on IoT. It is composed of two main phases. The first phase selects the near-optimal cluster-heads using Artificial Bee Colony (ABC) algorithm. Performance criteria include the residual energy of the devices, the number of neighbors, Euclidean distance between devices and the sink, and Euclidean distance between each device and its neighbors. The principal objective of the second phase is to group devices into some clusters based on Euclidean distance between each cluster-head and its members, and the data volume generated by clusters. Simulation results verify that our mechanism improves energy consumption, lifetime, and transmission delay.}
}
@article{PARKER2017211,
title = {A methodology for creating building energy model occupancy schedules using personal location metadata},
journal = {Energy and Buildings},
volume = {150},
pages = {211-223},
year = {2017},
issn = {0378-7788},
doi = {https://doi.org/10.1016/j.enbuild.2017.06.014},
url = {https://www.sciencedirect.com/science/article/pii/S0378778817302384},
author = {James Parker and Adam Hardy and David Glew and Christopher Gorse},
keywords = {Occupancy schedules, Dynamic simulation modelling, Metadata, Non-domestic buildings, Commercial buildings},
abstract = {Occupants affect energy consumption in buildings by contributing internal heat gains, increasing internal carbon dioxide levels and adapting their behaviour. Estimated occupancy schedules are used in building energy models for regulatory compliance purposes and when empirical data are not available. Metadata, such as personal location data, is now collected and visualised on a global scale and can be used to create more realistic occupancy schedules for non-domestic facilities, such as large retail outlets. This paper describes a protocol for extracting and using freely available metadata to create occupancy schedules that are used as inputs for dynamic simulation models. A sample set of twenty supermarket building models are used to demonstrate the impact metadata schedules have when compared with models using the estimated schedules from regulatory compliance. Metadata can be used to create bespoke occupancy profiles for specific buildings, groups of buildings and building archetypes. This method could also help reduce the gap between predicted and actual performance. In the example models, those using the regulatory compliance schedules underestimated heating demand by approximately 10% and overestimated cooling demand by over 50% when compared to models using the metadata schedules. Although this work focuses on UK facilities, this methodology has scope for global application.}
}
@article{MARINOVA2020107298,
title = {End-to-end network slicing for future wireless in multi-region cloud platforms},
journal = {Computer Networks},
volume = {177},
pages = {107298},
year = {2020},
issn = {1389-1286},
doi = {https://doi.org/10.1016/j.comnet.2020.107298},
url = {https://www.sciencedirect.com/science/article/pii/S1389128619316081},
author = {Simona Marinova and Thomas Lin and Hadi Bannazadeh and Alberto Leon-Garcia},
keywords = {End-to-end (E2E) network slicing, Software defined networking, Network function virtualization, Management and orchestration, 5G},
abstract = {End-to-end network slicing is an auspicious paradigm, which promises to lead the way towards efficiently addressing the problems of legacy networks. Based on softwarization and virtualization, it is capable of enabling network as a service (NaaS) and allowing the coexistence of multiple networks on the same physical infrastructure. These features make network slicing suitable for 5G by fostering the defined service performance and key performance indicators (KPIs). In this paper, we propose and implement an end-to-end slicing solution for multi-region cloud platforms. This solution leverages enablers like SDN and NFV and works in conjunction with our wireless testbed featuring fully virtualized and programmable systems that can be suitably installed and packaged for agile deployment. We conducted experiments to evaluate the performance regarding important KPIs such as: deployment time, management and reconfiguration, latency, and QoS characteristics. We present evaluations to validate the proposed slicing model and demonstrate its applicability for future wireless systems.}
}
@article{NKENYEREYE202161,
title = {Secure crowd-sensing protocol for fog-based vehicular cloud},
journal = {Future Generation Computer Systems},
volume = {120},
pages = {61-75},
year = {2021},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2021.02.008},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X21000601},
author = {Lewis Nkenyereye and S.M. Riazul Islam and Muhammad Bilal and M. Abdullah-Al-Wadud and Atif Alamri and Anand Nayyar},
keywords = {Privacy preservation, Crowd-sensing, Fog enabled vehicular computing, Access control, ID-based signature, Attribute-based encryption, Information-centric network},
abstract = {The new paradigm of fog computing was extended from conventional cloud computing to provide computing and storage capabilities at the edge of the network. Applied to vehicular networks, fog-enabled vehicular computing is expected to become a core feature that can accelerate a multitude of services including crowd-sensing. Accordingly, the security and privacy of vehicles joining the crowd-sensing system have become important issues for cyber defense and smart policing. In addition, to satisfy the demand of crowd-sensing data users, fine-grained access control is required. In this paper, we propose a secure and privacy-preserving crowd-sensing scheme for fog-enabled vehicular computing. The proposed architecture is made by a double layer of fog nodes that is used to generate crowd-sensing tasks for vehicles, then collect, aggregate and analyze the data based on user specifications. To ensure data confidentiality and fined-grained access control, we make use of ciphertext-policy attribute-based encryption with access update policy (CP-ABE-UP), which is a well-known one-to-many encryption technique. The policy update algorithm allows the fog nodes to outsource the crowd-sensing data to other fog nodes or to data users directly. We also adopted the ID-based signature tied to pseudonymous techniques to guarantee the authentication and privacy-preservation of the entities in the system. From the upper fog layer to the data user, we show that an information-centric networking (ICN) approach can be applied to maximize the network resources and enhance the security by avoiding unauthorized and unauthenticated data owners. The security analysis confirms that our approach is secure against known attacks, whereas the simulation results show its efficiency in terms of communication with little computational overhead.}
}
@article{SHI2021170,
title = {Advanced model predictive control framework for autonomous intelligent mechatronic systems: A tutorial overview and perspectives},
journal = {Annual Reviews in Control},
volume = {52},
pages = {170-196},
year = {2021},
issn = {1367-5788},
doi = {https://doi.org/10.1016/j.arcontrol.2021.10.008},
url = {https://www.sciencedirect.com/science/article/pii/S1367578821000821},
author = {Yang Shi and Kunwu Zhang},
keywords = {Model predictive control, Autonomous intelligent mechatronic systems, Unmanned Aerial Vehicles, Autonomous marine vehicles, Autonomous ground robots},
abstract = {This paper presents a review on the development and application of model predictive control (MPC) for autonomous intelligent mechatronic systems (AIMS). Starting from the conceptual analysis of “mechatronics”, we analyze the characteristics and control system design requirements of AIMS. In order to fulfill the design requirements, we propose to develop a unified MPC framework for AIMS. The main MPC schemes, covering MPC basics, robust MPC, distributed MPC, Lyapunov-based MPC, event-based MPC, network-based MPC, switched MPC, fast MPC, are reviewed with an attempt to document some of the key achievements in the past decades. Furthermore, we provide the review and analysis of MPC applications to three types of mechatronic systems, including unmanned aerial vehicles (UAVs), autonomous marine vehicles (AMVs), and autonomous ground robots (AGRs). Some promising research directions and concluding remarks are presented.}
}
@article{CHEN201932,
title = {A nonparametric model for online topic discovery with word embeddings},
journal = {Information Sciences},
volume = {504},
pages = {32-47},
year = {2019},
issn = {0020-0255},
doi = {https://doi.org/10.1016/j.ins.2019.07.048},
url = {https://www.sciencedirect.com/science/article/pii/S0020025519306541},
author = {Junyang Chen and Zhiguo Gong and Weiwen Liu},
keywords = {Data mining, Clustering, Topic model, Online topic discovery, Nonparametric model, Word embeddings},
abstract = {With the explosive growth of short documents generated from streaming textual sources (e.g., Twitter), latent topic discovery has become a critical task for short text stream clustering. However, most online clustering models determine the probability of producing a new topic by manually setting some hyper-parameter/threshold, which becomes barrier to achieve better topic discovery results. Moreover, topics generated by using existing models often involve a wide coverage of the vocabulary which is not suitable for online social media analysis. Therefore, we propose a nonparametric model (NPMM) which exploits auxiliary word embeddings to infer the topic number and employs a “spike and slab” function to alleviate the sparsity problem of topic-word distributions in online short text analyses. NPMM can automatically decide whether a given document belongs to existing topics, measured by the squared Mahalanobis distance. Hence, the proposed model is free from tuning the hyper-parameter to obtain the probability of generating new topics. Additionally, we propose a nonparametric sampling strategy to discover representative terms for each topic. To perform inference, we introduce a one-pass Gibbs sampling algorithm based on Cholesky decomposition of covariance matrices, which can further be sped up using a Metropolis-Hastings step. Our experiments demonstrate that NPMM significantly outperforms the state-of-the-art algorithms.}
}
@article{IBRAHIM2021,
title = {Characterization of task response time in a fog-enabled IoT network using queueing models with general service times},
journal = {Journal of King Saud University - Computer and Information Sciences},
year = {2021},
issn = {1319-1578},
doi = {https://doi.org/10.1016/j.jksuci.2021.09.008},
url = {https://www.sciencedirect.com/science/article/pii/S1319157821002597},
author = {Amira S. Ibrahim and Hassan Al-Mahdi and Hamed Nassar},
keywords = {IoT, Fog computing, Task offloading, Queueing model, Truncated exponential},
abstract = {Fog computing can improve the IoT quality of service/experience by bringing cloud resources closer to the terminal devices (TD.) With this paradigm, some tasks are offloaded to nearby fogs for fast processing, with the remaining tasks retained for processing locally. The challenge, however, is which tasks to offload and which to retain. We propose a novel scheme that bases the offloading decision on the task computational needs. Specifically, the TD offloads only time consuming tasks, which saves TD energy and guarantees fast responses. We develop a queueing theoretic model for the scheme, where tasks are generated at the TD as a Poisson process, with each task requiring an exponential processing time. If this time exceeds a user defined threshold, the task is offloaded; otherwise, it is retained. This leads to two queueing systems with general service times: M/G/1 at the TD and M/G/c at the fog. The model incorporates six operational parameters, two of them making it unique: the offloading threshold and a fog virtual machine (VM) speedup factor. The model culminates in three equations for the task response times, revealing insights that can be used to enhance the offloading performance. The equations have been validated by extensive simulations.}
}
@article{RAJASEGARAR20141833,
title = {Hyperspherical cluster based distributed anomaly detection in wireless sensor networks},
journal = {Journal of Parallel and Distributed Computing},
volume = {74},
number = {1},
pages = {1833-1847},
year = {2014},
issn = {0743-7315},
doi = {https://doi.org/10.1016/j.jpdc.2013.09.005},
url = {https://www.sciencedirect.com/science/article/pii/S0743731513002013},
author = {Sutharshan Rajasegarar and Christopher Leckie and Marimuthu Palaniswami},
keywords = {Distributed processing, Wireless sensor networks, Anomaly detection},
abstract = {This article describes a distributed hyperspherical cluster based algorithm for identifying anomalies in measurements from a wireless sensor network, and an implementation on a real wireless sensor network testbed. The communication overhead incurred in the network is minimised by clustering sensor measurements and merging clusters before sending a compact description of the clusters to other nodes. An evaluation on several real and synthetic datasets demonstrates that the distributed hyperspherical cluster-based scheme achieves comparable detection accuracy with a significant reduction in communication overhead compared to a centralised scheme, where all the sensor node measurements are communicated to a central node for processing.}
}
@article{TERROSOSAENZ20191066,
title = {An open IoT platform for the management and analysis of energy data},
journal = {Future Generation Computer Systems},
volume = {92},
pages = {1066-1079},
year = {2019},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2017.08.046},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X17304181},
author = {Fernando Terroso-Saenz and Aurora González-Vidal and Alfonso P. Ramallo-González and Antonio F. Skarmeta},
keywords = {IoT platform, Energy consumption, FIWARE, Data mining},
abstract = {Buildings are key players when looking at end-use energy demand. It is for this reason that during the last few years, the Internet of Things (IoT) has been considered as a tool that could bring great opportunities for energy reduction via the accurate monitoring and control of a large variety of energy-related agents in buildings. However, there is a lack of IoT platforms specifically oriented towards the proper processing, management and analysis of such large and diverse data. In this context, we put forward in this paper the IoT Energy Platform (IoTEP) which attempts to provide the first holistic solution for the management of IoT energy data. The platform we show here (that has been based on FIWARE) is suitable to include several functionalities and features that are key when dealing with energy quality insurance and support for data analytics. As part of this work, we have tested the platform IoTEP with a real use case that includes data and information from three buildings totalizing hundreds of sensors. The platform has exceed expectations proving robust, plastic and versatile for the application at hand.}
}
@article{SIFAKIS2021114684,
title = {Integrating a novel smart control system for outdoor lighting infrastructures in ports},
journal = {Energy Conversion and Management},
volume = {246},
pages = {114684},
year = {2021},
issn = {0196-8904},
doi = {https://doi.org/10.1016/j.enconman.2021.114684},
url = {https://www.sciencedirect.com/science/article/pii/S0196890421008608},
author = {Nikolaos Sifakis and Konstantinos Kalaitzakis and Theocharis Tsoutsos},
keywords = {Lighting energy efficiency, Smart ports' outdoor lighting control system, Daylight harvesting, Climate change mitigation, Nearly zero energy ports},
abstract = {Lighting is amongst the most energy-demanding ports’ operations due to the strict legislative illuminance limits ensuring the safety and the visual comfort of ports' end-users. Lighting exceeds 70% of a port's energy demand in most cases. In parallel, they should be harmonised during the energy transition. This research proposes a novel replicable typology of smart-controlling the outdoor lighting infrastructures in three stages: the reallocation and replacement of the obsolete luminaires, the integration of the daylight harvesting techniques, and the implementation of the occupational-based dimming strategy based on the actual data. A typical Mediterranean port was used as a testbed, the port of Rethymno. The innovative aspect of the proposed typology is that it improves two existing smart lighting control techniques and combines them to a complete typology that responds fast and accurately to any possible lighting conditions' alteration in each space distinctively. The system incorporates high replicability and applicability to a great variety of needs, technologies, and spaces. The energy wastes are diminished while the end-used visual comfort is significantly enhanced. The system's energy savings potential and impacts on the port's infrastructures are quantified, discussed and evaluated. The suggested tool leads to a 56.8% decrease in the port's lighting operations' annual energy demand, which may reach up to 90% in some months. The port’s environmental footprint is also reduced to half than the baseline levels. In conclusion, the investment is viable and feasible, leading to an investment paid back in less than ten years in some instances.}
}
@article{ZENG2021451,
title = {Sharing economy platform firms and their resource orchestration approaches},
journal = {Journal of Business Research},
volume = {136},
pages = {451-465},
year = {2021},
issn = {0148-2963},
doi = {https://doi.org/10.1016/j.jbusres.2021.07.054},
url = {https://www.sciencedirect.com/science/article/pii/S0148296321005385},
author = {Jing Zeng and M. {Mahdi Tavalaei} and Zaheer Khan},
keywords = {Sharing economy platforms, Value creation, Resource-based view, Resource orchestration, Emerging markets, China},
abstract = {Drawing upon key insights from the resource orchestration framework as a dynamic perspective on the resource-based view (RBV), we investigated the value creation dynamics found in sharing economy platform firms. By performing multiple-case analyses on platform firms operating in the sharing economy in China, we identified three main mechanisms by which sharing economy platform firms orchestrate their external resources (i.e., crowds of suppliers and consumers) to create value and gain a competitive advantage—constructing on-demand resource adaptation, building big-data-driven network effects, and enabling ecosystem resource coordination. We contribute to the emerging literature on the sharing economy while extending the RBV to the digital platform context, in which the value creation process is significantly shifted to beyond the boundaries of the firm.}
}
@article{CHEN2020101817,
title = {Where do people tweet? The relationship of the built environment to tweeting in Chicago},
journal = {Sustainable Cities and Society},
volume = {52},
pages = {101817},
year = {2020},
issn = {2210-6707},
doi = {https://doi.org/10.1016/j.scs.2019.101817},
url = {https://www.sciencedirect.com/science/article/pii/S2210670719300204},
author = {Yan Chen and Yan Song and Chaosu Li},
keywords = {Built environment, Social media, Tweet, Twitter, Spatial association},
abstract = {Understanding the relationships between human activities and the built environment are central to urban planning. The increase in readily available, location-based social media data offers scholars important new data for understanding this relationship. This study examines the relationship between the spatial distribution of geotagged tweets and key characteristics of the built environment at the census block group level in Chicago. First, we performed a hotspot analysis to ascertain the distribution of tweets in the study area. Then, we employed a count regression model with Twitter message counts by census block group as the dependent variable to test the significance and magnitude of the associations between the built environment and tweeting. After that, we standardized the coefficients to compare the variables’ effects on tweeting. The analysis found that the built environment significantly influenced tweeting and provides empirical statistical evidence to guide urban planners’ placemaking decisions.}
}
@article{SITHOLE2020100268,
title = {Systematic methods for organising patterns for the internet of things: A preliminary exploration},
journal = {Internet of Things},
volume = {11},
pages = {100268},
year = {2020},
issn = {2542-6605},
doi = {https://doi.org/10.1016/j.iot.2020.100268},
url = {https://www.sciencedirect.com/science/article/pii/S2542660520301025},
author = {Vusi Sithole and Linda Marshall},
keywords = {Internet of things, IoT patterns, IoT Solutions, IoT architectures, Classification schemes, IoT interoperability, IoT pattern language},
abstract = {Most popular industry verticals such as smart health, smart mining, smart agriculture, etc. fail to map clearly the solution patterns used in the Internet of Things (IoT). This causes a disconnection in our understanding of the implementation approaches and solutions used in the IoT paradigm. Nonetheless, there is another way of subdividing this space – decoding the building blocks of the IoT architectures, with a focus on common components and patterns for interoperability. The IoT presents us with several design challenges at all architectural levels. This ranges from the overall architecture at the highest level to device connectivity at the lowest level. In this complex design, it is easy to get lost in the forest of the latest IoT offerings without understanding the underlying solution patterns. In this study, we have mapped several IoT architectural patterns, spanning several industry verticals, by analysing the literature that report on real-world IoT implementations to identify common, recurring solution patterns. In the spirit of the Gang-of-Four11The classic book Design Patterns: Elements of Reusable Object-Oriented Software (Addison-Wesley, 1994) is commonly viewed as the reference point and starting point for exploring solutions to common software design problems. The authors of the book: Erich Gamma, Richard Helm, Ralph Johnson, and John Vlissides, are often referred to as the ‘Gang of Four’. and Christopher Alexander’s pattern language, as well as some recent advances in the IoT space, we have identified some systematic methods which are used to organise the IoT patterns.}
}
@article{RZEPKA2022,
title = {SDN-based fog and cloud interplay for stream processing},
journal = {Future Generation Computer Systems},
year = {2022},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2022.01.006},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X22000140},
author = {Michał Rzepka and Piotr Boryło and Marcos D. Assunção and Artur Lasoń and Laurent Lefèvre},
keywords = {Stream processing, Fog computing, Edge computing, SDN},
abstract = {This paper focuses on SDN-based approaches for deploying stream processing workloads on heterogeneous environments comprising wide-area networks, cloud and fog resources. Stream processing applications impose strict latency requirements to operate appropriately. Deploying workloads in the fog reduces unnecessary delays, but its computational resources may not handle all the tasks. On the other hand, offloading the tasks to the cloud is constrained by limited network resources and involves additional transmission delays that exceed latency thresholds. Adaptive workload deployment may solve these issues by ensuring that resource and latency requirements are satisfied for all the data streams processed by an application. This paper’s main contribution consists of dynamic workload placement algorithms operating on stream processing requests with latency constraints. Provisioning of computing infrastructure exploits the interplay between fog and cloud under limited network capacity. The algorithms aim to maximize the ratio of successfully handled requests by effectively utilizing available resources while meeting application latency constraints. Experiments demonstrate that the goal can be achieved by detailed analysis of requests and ensuring balanced computing and network resources utilization. As a result, up to 30% improvement over the reference algorithms in success rate is observed.}
}
@article{MAJEED2021102026,
title = {A big data-driven framework for sustainable and smart additive manufacturing},
journal = {Robotics and Computer-Integrated Manufacturing},
volume = {67},
pages = {102026},
year = {2021},
issn = {0736-5845},
doi = {https://doi.org/10.1016/j.rcim.2020.102026},
url = {https://www.sciencedirect.com/science/article/pii/S0736584520302374},
author = {Arfan Majeed and Yingfeng Zhang and Shan Ren and Jingxiang Lv and Tao Peng and Saad Waqar and Enhuai Yin},
keywords = {Big data, Additive manufacturing, Sustainable manufacturing, Smart manufacturing, Optimization},
abstract = {From the last decade, additive manufacturing (AM) has been evolving speedily and has revealed the great potential for energy-saving and cleaner environmental production due to a reduction in material and resource consumption and other tooling requirements. In this modern era, with the advancements in manufacturing technologies, academia and industry have been given more interest in smart manufacturing for taking benefits for making their production more sustainable and effective. In the present study, the significant techniques of smart manufacturing, sustainable manufacturing, and additive manufacturing are combined to make a unified term of sustainable and smart additive manufacturing (SSAM). The paper aims to develop framework by combining big data analytics, additive manufacturing, and sustainable smart manufacturing technologies which is beneficial to the additive manufacturing enterprises. So, a framework of big data-driven sustainable and smart additive manufacturing (BD-SSAM) is proposed which helped AM industry leaders to make better decisions for the beginning of life (BOL) stage of product life cycle. Finally, an application scenario of the additive manufacturing industry was presented to demonstrate the proposed framework. The proposed framework is implemented on the BOL stage of product lifecycle due to limitation of available resources and for fabrication of AlSi10Mg alloy components by using selective laser melting (SLM) technique of AM. The results indicate that energy consumption and quality of the product are adequately controlled which is helpful for smart sustainable manufacturing, emission reduction, and cleaner production.}
}
@article{TORQUATO2020101742,
title = {Moving target defense in cloud computing: A systematic mapping study},
journal = {Computers & Security},
volume = {92},
pages = {101742},
year = {2020},
issn = {0167-4048},
doi = {https://doi.org/10.1016/j.cose.2020.101742},
url = {https://www.sciencedirect.com/science/article/pii/S0167404820300286},
author = {Matheus Torquato and Marco Vieira},
keywords = {Moving target defense, Cloud computing, Systematic mapping, Cyber security, Network security},
abstract = {Moving Target Defense (MTD) consists of applying system reconfiguration (e.g., VM migration, IP shuffling) to dynamically change the available attack surface. MTD makes use of reconfiguration to confuse attackers and nullify their knowledge about the system state. It also can be used as an attack reaction (e.g., using Virtual Machine (VM) migration to move VMs away from a compromised host). Thus, MTD seems to be a promising technique to tackle some of the cloud computing security challenges. In this systematic mapping study, we aim to investigate the current research state of Moving Target Defense in the cloud computing context, and to identify potential research gaps in the literature. Considering five major scientific databases in the computer science domain, we collected 224 papers related to the area. After disambiguation and filtering, we selected 95 papers for analysis. The outcome of such analysis offers a comprehensive overview of the current research. We can highlight some relevant research opportunities. First, only a few works present advances in the theoretical field of Moving Target Defense in cloud computing. Second, the proposal and evaluation of multi-layer Moving Target Defense mechanisms is still an open problem. Thirdly, there is a need for frameworks to support MTD evaluation, which may include a benchmark for comparing alternative MTD strategies. Finally, the study of potential impacts of Moving Target Defense in context-oriented clouds is a barely explored topic.}
}
@article{GRAMHANSSEN201894,
title = {“Home is where the smart is”? Evaluating smart home research and approaches against the concept of home},
journal = {Energy Research & Social Science},
volume = {37},
pages = {94-101},
year = {2018},
issn = {2214-6296},
doi = {https://doi.org/10.1016/j.erss.2017.09.037},
url = {https://www.sciencedirect.com/science/article/pii/S2214629617303213},
author = {Kirsten Gram-Hanssen and Sarah J. Darby},
keywords = {Smart energy, DIY, Meaning of home, Energy management},
abstract = {This article develops concepts of what the home is and reflects on smart home technology and the research literature on smart homes in relation to these concepts. The focus is on the aspects of smart home technologies related to energy management within the home (end-uses) and at network or grid level (system). Four aspects of a home are distinguished: a place for security and control, for activity, for relationships and continuity, and for identity and values. These aspects of home are used to discuss approaches to, and ideas of, the smart home, as reflected in the research literature. It is shown that technical and ‘prospective’ research literature focuses on aspects of security and control in the home as well as on activities, whereas research papers that are more conceptual and evaluative are more likely to include questions of relations, values and identities. The paper concludes that a broader understanding of the home in all aspects is needed when conducting research into smart homes. This can be valuable when evaluating how smart home technologies work in real homes, as well as in the more technical and prospective approaches to developing new socio-technical configurations.}
}
@article{DEARQUERFERNANDEZ2021106540,
title = {An IoT open source platform for photovoltaic plants supervision},
journal = {International Journal of Electrical Power & Energy Systems},
volume = {125},
pages = {106540},
year = {2021},
issn = {0142-0615},
doi = {https://doi.org/10.1016/j.ijepes.2020.106540},
url = {https://www.sciencedirect.com/science/article/pii/S0142061520310279},
author = {Pedro {de Arquer Fernández} and Miguel Ángel {Fernández Fernández} and Juan Luis {Carús Candás} and Pablo {Arboleya Arboleya}},
keywords = {Internet of Things, Photovoltaic, SmartGrid, Industry 4.0, Eclipse Kapua, Eclipse Kura, Real-time monitoring},
abstract = {In the present work, the authors propose an IoT solution for photovoltaic plants monitoring based entirely on Open Source software. The described solution is implemented and deployed in a real plant of approximately 3 MW with a total number of 24 inverters and 156 string boxes. All details about software and hardware architecture are provided, proving that it is possible to develop a flexible, versatile and competitive monitoring system just using available Open Source tools. In addition, the authors make a detailed comparison between the proposed IoT solution and conventional SCADA-based monitoring systems, describing all benefits and drawbacks of conventional SCADAs and modern IoT systems and proposing solutions in order to overcome the identified weak points of the newest IoT-based monitoring systems.}
}
@article{LOZOYASANTOS2019175,
title = {Survey on biometry for cognitive automotive systems},
journal = {Cognitive Systems Research},
volume = {55},
pages = {175-191},
year = {2019},
issn = {1389-0417},
doi = {https://doi.org/10.1016/j.cogsys.2019.01.007},
url = {https://www.sciencedirect.com/science/article/pii/S1389041717301948},
author = {Jorge de J. Lozoya-Santos and Victorino Sepúlveda-Arróniz and Juan C. Tudon-Martinez and Ricardo A. Ramirez-Mendoza},
keywords = {Biometry, Biometrics, Cognitive, Autonomous, Intelligent vehicles, Automotive systems},
abstract = {A survey on biometry for cognitive automotive systems is presented in this paper, specially those biometric systems used for high tech security access, law enforcement and/or commercial transactions. In general, biometric systems can be expensive due to the amount of sensors and processing resources involved. Efforts have been made to integrate these systems to vehicles mostly for security purposes and user authentication. Until now, most of the systems do not go beyond using facial and fingerprint data to start the engine or access the car; however, new generations demand more personalization plus the vehicle making decisions based on their physiological characteristics. Although this kind of technology is considered a luxury feature in general, actually it could help users and save their lives. Indeed, biometry is the way to make the human-vehicle relationship happen, whether the biometric devices are embedded inside the vehicle, used as an accessory or wearables. By using as input not only the sensors inside the vehicle but also data from outside, the vehicle could adapt and/or learn new information to make the best possible decision.}
}
@article{ZHOU2021131,
title = {Crowdsourcing-based indoor mapping using smartphones: A survey},
journal = {ISPRS Journal of Photogrammetry and Remote Sensing},
volume = {177},
pages = {131-146},
year = {2021},
issn = {0924-2716},
doi = {https://doi.org/10.1016/j.isprsjprs.2021.05.006},
url = {https://www.sciencedirect.com/science/article/pii/S0924271621001313},
author = {Baoding Zhou and Wei Ma and Qingquan Li and Naser El-Sheimy and Qingzhou Mao and You Li and Fuqiang Gu and Lian Huang and Jiasong Zhu},
keywords = {Indoor mapping, Crowdsourcing, Smartphone, Survey},
abstract = {Indoor map is a fundamental element of indoor location-based services (ILBS). However, traditional indoor mapping techniques are labor-intensive and time-consuming. The advancement of smartphones offers great opportunities for crowdsourcing-based indoor mapping, which is one of the most promising applications due to its low cost and flexibility. Over the last decade, many crowdsourcing-based indoor mapping solutions using smartphones have been proposed. This article provides a systematic review of these works. Different from former surveys, we classify the indoor mapping process by the stage of map construction. In particular, we highlight the two key steps, geospatial-element acquisition, and indoor-map construction, and provide state-of-the-art techniques on these topics. Then, we systematically review the crowdsourcing-based indoor mapping solutions under grid-based, landmark-based, and semantic maps. In addition to covering the principles, benefits, and challenges, these systems are compared in terms of sensors, participation, output, experimental environment, and reported accuracy. Besides these existing performance criteria, we extract quantitative performance criteria that are suitable to evaluate crowdsourcing-based indoor mapping solutions. Finally, we present open issues and future research directions.}
}
@article{FENG201812,
title = {A novel spatial pooling method for 3D mesh quality assessment based on percentile weighting strategy},
journal = {Computers & Graphics},
volume = {74},
pages = {12-22},
year = {2018},
issn = {0097-8493},
doi = {https://doi.org/10.1016/j.cag.2018.04.005},
url = {https://www.sciencedirect.com/science/article/pii/S0097849318300530},
author = {Xiang Feng and Wanggen Wan and Richard {Yi Da Xu} and Stuart Perry and Pengfei Li and Song Zhu},
keywords = {Spatial pooling, Percentile weighting strategy, Mesh quality assessment, Quality map, Surface area},
abstract = {Most of existing mesh quality assessment metrics consist of a similar two-stage computation process: first constructing a quality map by comparing the local regions between reference mesh and distorted mesh, then adopting a spatial pooling method to generate the overall quality score. In this paper, we propose a novel spatial pooling method for 3D mesh quality assessment based on percentile weighting strategy. We assign more weight to the severely distorted regions of the mesh at the pooling stage and extend the percentile weighting method by incorporating surface area at the pooling stage. Our analysis indicates that the percentile weighting method has a strong capability to emphasize the local regions with severe distortion of the mesh. We develop a mesh quality metric by pooling the local distances generated by the Tensor-based Perceptual Distance Measure metric with our spatial pooling method. We investigate the influence of the parameters of percentile weighting on the performance, and determine the optimal parameters and unified parameters through empirical tests on three publicly available databases. Experimental results demonstrate the effectiveness of our spatial pooling method and the superiority of our metric over state-of-the-art metrics.}
}
@article{WACHTER2018436,
title = {Normative challenges of identification in the Internet of Things: Privacy, profiling, discrimination, and the GDPR},
journal = {Computer Law & Security Review},
volume = {34},
number = {3},
pages = {436-449},
year = {2018},
issn = {0267-3649},
doi = {https://doi.org/10.1016/j.clsr.2018.02.002},
url = {https://www.sciencedirect.com/science/article/pii/S0267364917303904},
author = {Sandra Wachter},
keywords = {Data protection, Digital Ethics, Identity, Identification, Internet of Things, Privacy, Profiling, Discrimination, GDPR, Review},
abstract = {In the Internet of Things (IoT), identification and access control technologies provide essential infrastructure to link data between a user's devices with unique identities, and provide seamless and linked up services. At the same time, profiling methods based on linked records can reveal unexpected details about users' identity and private life, which can conflict with privacy rights and lead to economic, social, and other forms of discriminatory treatment. A balance must be struck between identification and access control required for the IoT to function and user rights to privacy and identity. Striking this balance is not an easy task because of weaknesses in cybersecurity and anonymisation techniques. The EU General Data Protection Regulation (GDPR), set to come into force in May 2018, may provide essential guidance to achieve a fair balance between the interests of IoT providers and users. Through a review of academic and policy literature, this paper maps the inherent tension between privacy and identifiability in the IoT. It focuses on four challenges: (1) profiling, inference, and discrimination; (2) control and context-sensitive sharing of identity; (3) consent and uncertainty; and (4) honesty, trust, and transparency. The paper will then examine the extent to which several standards defined in the GDPR will provide meaningful protection for privacy and control over identity for users of IoT. The paper concludes that in order to minimise the privacy impact of the conflicts between data protection principles and identification in the IoT, GDPR standards urgently require further specification and implementation into the design and deployment of IoT technologies.}
}
@article{ANTHI2018477,
title = {EclipseIoT: A secure and adaptive hub for the Internet of Things},
journal = {Computers & Security},
volume = {78},
pages = {477-490},
year = {2018},
issn = {0167-4048},
doi = {https://doi.org/10.1016/j.cose.2018.07.016},
url = {https://www.sciencedirect.com/science/article/pii/S0167404818309052},
author = {Eirini Anthi and Shazaib Ahmad and Omer Rana and George Theodorakopoulos and Pete Burnap},
keywords = {Internet of Things (IoT), Networking, Security, Framework, Hub},
abstract = {With the proliferation in the quantity and types of devices that may be included in an Internet of Things (IoT) ecosystem, particularly in the context of a smart home, it is essential to provide mechanisms to deal with the heterogeneity which such devices encompass. Variations can occur in data formats, frequency of operation, or type of communication protocols supported. The ability to support integration between sensors using a “hub” has become central to address many of these issues. The implementation of such a hub can provide both the ability to act as an aggregator for various sensors, and also limit an attacker’s visibility into locally provisioned sensing capability. This paper introduces EclipseIoT, an adaptive hub which uses dynamically loadable add-on modules to communicate with diverse IoT devices, provides policy-based access control, limits exposure of local IoT devices through cloaking, and offers a canary-function based capability to monitor attack behaviours. Its architecture and implementation are discussed, along with its use within a smart home testbed consisting of commercially available devices such as Phillips Hue Bridge, Samsung Smart Things Hub, TP-Link Smart Plug, and TP-Link Smart Camera. The effectiveness of EclipseIoT is further evaluated by simulating various attacks such as Address Resolution Protocol (ARP) spoofing, Media Access Control (MAC) address spoofing, Man-In-The-Middle (MITM), port scanning, capturing handshakes, sniffing, and Denial of Service (DoS). It is demonstrated that direct attacks upon EclipseIoT components are mitigated due to the security techniques being used.}
}
@article{ZONTA2020106889,
title = {Predictive maintenance in the Industry 4.0: A systematic literature review},
journal = {Computers & Industrial Engineering},
volume = {150},
pages = {106889},
year = {2020},
issn = {0360-8352},
doi = {https://doi.org/10.1016/j.cie.2020.106889},
url = {https://www.sciencedirect.com/science/article/pii/S0360835220305787},
author = {Tiago Zonta and Cristiano André {da Costa} and Rodrigo {da Rosa Righi} and Miromar José {de Lima} and Eduardo Silveira {da Trindade} and Guann Pyng Li},
keywords = {Industry 4.0, Predictive Maintenance, Remaining Useful Life, Conditional-based maintenance, Artificial intelligence},
abstract = {Industry 4.0 is collaborating directly for the technological revolution. Both machines and managers are daily confronted with decision making involving a massive input of data and customization in the manufacturing process. The ability to predict the need for maintenance of assets at a specific future moment is one of the main challenges in this scope. The possibility of performing predictive maintenance contributes to enhancing machine downtime, costs, control, and quality of production. We observed that surveys and tutorials about Industry 4.0 focus mainly on addressing data analytics and machine learning methods to change production procedures, so not comprising predictive maintenance methods and their organization. In this context, this article presents a systematic literature review of initiatives of predictive maintenance in Industry 4.0, identifying and cataloging methods, standards, and applications. As the main contributions, this survey discusses the current challenges and limitations in predictive maintenance, in addition to proposing a novel taxonomy to classify this research area considering the needs of the Industry 4.0. We concluded that computer science, including artificial intelligence and distributed computing fields, is more and more present in an area where engineering was the dominant expertise, so detaching the importance of a multidisciplinary approach to address Industry 4.0 effectively.}
}
@article{PRAKASH2021103252,
title = {Deep transfer learning for COVID-19 detection and infection localization with superpixel based segmentation},
journal = {Sustainable Cities and Society},
volume = {75},
pages = {103252},
year = {2021},
issn = {2210-6707},
doi = {https://doi.org/10.1016/j.scs.2021.103252},
url = {https://www.sciencedirect.com/science/article/pii/S221067072100528X},
author = {N.B. Prakash and M. Murugappan and G.R. Hemalakshmi and M. Jayalakshmi and Mufti Mahmud},
keywords = {COVID-19, Chest X-Ray, Super pixel, GMM, SqueezeNet},
abstract = {The evolution the novel corona virus disease (COVID-19) as a pandemic has inflicted several thousand deaths per day endangering the lives of millions of people across the globe. In addition to thermal scanning mechanisms, chest imaging examinations provide valuable insights to the detection of this virus, diagnosis and prognosis of the infections. Though Chest CT and Chest X-ray imaging are common in the clinical protocols of COVID-19 management, the latter is highly preferred, attributed to its simple image acquisition procedure and mobility of the imaging mechanism. However, Chest X-ray images are found to be less sensitive compared to Chest CT images in detecting infections in the early stages. In this paper, we propose a deep learning based framework to enhance the diagnostic values of these images for improved clinical outcomes. It is realized as a variant of the conventional SqueezeNet classifier with segmentation capabilities, which is trained with deep features extracted from the Chest X-ray images of a standard dataset for binary and multi class classification. The binary classifier achieves an accuracy of 99.53% in the discrimination of COVID-19 and Non COVID-19 images. Similarly, the multi class classifier performs classification of COVID-19, Viral Pneumonia and Normal cases with an accuracy of 99.79%. This model called the COVID-19 Super pixel SqueezNet (COVID-SSNet) performs super pixel segmentation of the activation maps to extract the regions of interest which carry perceptual image features and constructs an overlay of the Chest X-ray images with these regions. The proposed classifier model adds significant value to the Chest X-rays for an integral examination of the image features and the image regions influencing the classifier decisions to expedite the COVID-19 treatment regimen.}
}
@article{YU2018187,
title = {Delay aware transient stability assessment with synchrophasor recovery and prediction framework},
journal = {Neurocomputing},
volume = {322},
pages = {187-194},
year = {2018},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2018.09.059},
url = {https://www.sciencedirect.com/science/article/pii/S0925231218311329},
author = {James J.Q. Yu and David J. Hill and Albert Y.S. Lam},
keywords = {Communication latency, Deep learning, Synchrophasor, Transient stability assessment.},
abstract = {Transient stability assessment is critical for power system operation and control. Existing related research makes a strong assumption that the data transmission time for system variable measurements to arrive at the control center is negligible, which is unrealistic. In this paper, we focus on investigating the impact of data transmission latency on synchrophasor-based transient stability assessment. In particular, we employ a recently proposed methodology named synchrophasor recovery and prediction framework to handle the latency issue and make up missing synchrophasors. Advanced deep learning techniques are adopted to utilize the processed data for assessment. Compared with existing work, our proposed mechanism can make accurate assessments with a significantly faster response speed.}
}
@article{CHENG2021,
title = {6G service-oriented space-air-ground integrated network: A survey},
journal = {Chinese Journal of Aeronautics},
year = {2021},
issn = {1000-9361},
doi = {https://doi.org/10.1016/j.cja.2021.12.013},
url = {https://www.sciencedirect.com/science/article/pii/S1000936121004738},
author = {Nan CHENG and Jingchao HE and Zhisheng YIN and Conghao ZHOU and Huaqing WU and Feng LYU and Haibo ZHOU and Xuemin SHEN},
keywords = {Mobile Edge Computing (MEC), Network Function Virtualization (NFV), Network slicing, Service-oriented network, Software Defined Networking (SDN), Space-Air-Ground Integrated Networks (SAGINs)},
abstract = {As an indispensable component of the emerging 6G networks, Space-Air-Ground Integrated Networks (SAGINs) are envisioned to provide ubiquitous network connectivity and services by integrating satellite networks, aerial networks, and terrestrial networks. In 6G SAGINs, a wide variety of network services with the features of diverse requirements, complex mobility, and multi-dimensional resources will pose great challenges to service provisioning, which urges the development of service-oriented SAGINs. In this paper, we conduct a comprehensive review of 6G SAGINs from a new perspective of service-oriented network. First, we present the requirements of service-oriented networks, and then propose a service-oriented SAGINs management architecture. Two categories of critical technologies are presented and discussed, i.e., heterogeneous resource orchestration technologies and the cloud-edge synergy technologies, which facilitate the interoperability of different network segments and cooperatively orchestrate heterogeneous resources across different domains, according to the service features and requirements. In addition, the potential future research directions are also presented and discussed.}
}
@article{PHAM2021103141,
title = {Swarm intelligence for next-generation networks: Recent advances and applications},
journal = {Journal of Network and Computer Applications},
volume = {191},
pages = {103141},
year = {2021},
issn = {1084-8045},
doi = {https://doi.org/10.1016/j.jnca.2021.103141},
url = {https://www.sciencedirect.com/science/article/pii/S1084804521001582},
author = {Quoc-Viet Pham and Dinh C. Nguyen and Seyedali Mirjalili and Dinh Thai Hoang and Diep N. Nguyen and Pubudu N. Pathirana and Won-Joo Hwang},
keywords = {5G and beyond, 6G, Artificial intelligence (AI), Computational intelligence, Swarm intelligence (SI), Next-generation wireless networks},
abstract = {In next-generation networks (NGN), a very large number of devices and applications are emerged, along with the heterogeneity of technologies, architectures, mobile data, etc., and optimizing such a network is of utmost importance. Besides convex optimization and game theory, swarm intelligence (SI) has recently appeared as a promising optimization tool for wireless networks. As a new subdivision of artificial intelligence, SI is inspired by the collective behaviors of societies of biological species. In SI, simple agents with limited capabilities can achieve intelligent strategies for high-dimensional and challenging problems, and thus SI has recently found many applications in NGN. However, SI techniques have still not fully investigated in the literature, especially in the contexts of wireless networks. In this work, our primary focus will be the integration of these two domains, i.e., NGN and SI. Firstly, we provide an overview of SI techniques from fundamental concepts to well-known optimizers. Secondly, we review the applications of SI to settle emerging issues in NGN, including spectrum management and resource allocation, wireless caching and edge computing, network security, and several other miscellaneous issues. Finally, we highlight challenges and issues in the literature, and introduce some interesting directions for future research.}
}
@article{KOFINAS201848,
title = {A methodology for synthetic household water consumption data generation},
journal = {Environmental Modelling & Software},
volume = {100},
pages = {48-66},
year = {2018},
issn = {1364-8152},
doi = {https://doi.org/10.1016/j.envsoft.2017.11.021},
url = {https://www.sciencedirect.com/science/article/pii/S1364815216310520},
author = {Dimitris T. Kofinas and Alexandra Spyropoulou and Chrysi S. Laspidou},
keywords = {Synthetic water consumption data generation, Pulse models, Missing data, Water consumption patterns},
abstract = {In the smart cities context, real-time knowledge of residential water consumption has become increasingly important, especially given the fast evolution of sensors, ICT and the production of big, high-resolution data coming from the urban environment. A variety of reasons often leads to the creation of continuity gaps in these data series, thus making the need for a methodology that produces reliable and realistic synthetic data urgent. In this article, we present a methodology that generates synthetic household water consumption data; we showcase it in two case studies, Skiathos, Greece and Sosnowiec, Poland, which exhibit significant differences in water consumption patterns. The methodology captures the stochasticity of daily residential water use. Algorithm validation is implemented through the comparison of various metrics for actual and generated data; this way, we show that the suggested approach is capable of adequately simulating water consumption in both micro- and macro-time scale.}
}
@article{FORCEN202045,
title = {Learning ordered pooling weights in image classification},
journal = {Neurocomputing},
volume = {411},
pages = {45-53},
year = {2020},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2020.06.028},
url = {https://www.sciencedirect.com/science/article/pii/S0925231220309991},
author = {J.I. Forcén and Miguel Pagola and Edurne Barrenechea and Humberto Bustince},
keywords = {Pooling, Ordered weighted aggregation, Image classification, Bag-of-words, Mid-level features, Convolutional neural networks, Global pooling},
abstract = {Spatial pooling is an important step in computer vision systems like Convolutional Neural Networks or the Bag-of-Words method. The spatial pooling purpose is to combine neighbouring descriptors to obtain a single descriptor for a given region (local or global). The resultant combined vector must be as discriminant as possible, in other words, must contain relevant information, while removing irrelevant and confusing details. Maximum and average are the most common aggregation functions used in the pooling step. To improve the aggregation of relevant information without degrading their discriminative power for image classification, we introduce a simple but effective scheme based on Ordered Weighted Average (OWA) aggregation operators. We present a method to learn the weights of the OWA aggregation operator in a Bag-of-Words framework and in Convolutional Neural Networks, and provide an extensive evaluation showing that OWA based pooling outperforms classical aggregation operators.}
}
@article{IMANI2019113505,
title = {Residential load forecasting using wavelet and collaborative representation transforms},
journal = {Applied Energy},
volume = {253},
pages = {113505},
year = {2019},
issn = {0306-2619},
doi = {https://doi.org/10.1016/j.apenergy.2019.113505},
url = {https://www.sciencedirect.com/science/article/pii/S0306261919311791},
author = {Maryam Imani and Hassan Ghassemian},
keywords = {Load forecasting, Long short-term memory, Collaborative representation, Wavelet transform},
abstract = {Short-term household-level load forecasting requires to acquire knowledge about lifestyle and consumption patterns of residents. A new forecasting framework is proposed in this work which uses the extra appliance measurements in meter-level for short-term electrical load forecasting. The long short-term memory network as a deep learning method is used as a predictor where useful features are fed to it for forecast learning. A lagged load variable vector is assigned to each point of the load curve. To remove redundant details and to use the approximate component of the feature vector, the wavelet decomposition is applied to it. In addition, a new version of collaborative representation is introduced and used to achieve information of the neighboring points (previous and future time instances) of the considered load point. Collaborative representation of the feature vector associated with each load point contains valuable local information about adjacent load points. The load features extracted from the lagged load variable vector provide superior forecasting performance especially with extra appliances load data.}
}
@article{RATHORE2018600,
title = {Exploiting IoT and big data analytics: Defining Smart Digital City using real-time urban data},
journal = {Sustainable Cities and Society},
volume = {40},
pages = {600-610},
year = {2018},
issn = {2210-6707},
doi = {https://doi.org/10.1016/j.scs.2017.12.022},
url = {https://www.sciencedirect.com/science/article/pii/S2210670717309782},
author = {M. Mazhar Rathore and Anand Paul and Won-Hwa Hong and HyunCheol Seo and Imtiaz Awan and Sharjil Saeed},
keywords = {Smart Digital City, Smart Transportation System, Big data, Hadoop},
abstract = {Integration of all smart systems (such as smart home, smart parking, etc.) and the IoT devices (such as sensors, actuators, and smartphones) in the city can play a vital role to develop the urban services by building their city digital and smarter. However, interconnection of lots of IoT objects to collect urban data over the Internet to launch a smart digital city, effects vast volume of data generation, termed as Big Data. Thus, it is a challenging task to integrate IoT devices and smart systems in order to harvest and process such big amount of real-time city data in an effective manner aimed at creating a Smart Digital City. Therefore, in this paper, we have established an IoT-based Smart City by using Big Data analytics while harvesting real-time data from the city. We used sensors’ deployment including sensors at smart home, smart parking, vehicular networking, surveillance, weather and water monitoring system, etc., for real time data collection. The complete system is described by its proposed architecture and implementation prototype using Hadoop ecosystem in a real environment. In addition, the Smart Digital City services are extended by developing the intelligent Smart Transportation System by means of big graph processing to facilitate citizens while providing real-time traffic information and alerts. The proposed system consists of number of stages including data generation and collection, aggregation, filtration, classification, preprocessing, computing, and decision making. The efficiency of the system is extended by applying Big Data processing using Apache Spark over Hadoop. Whereas, the big city graph processing is achieved by using Giraph over Hadoop. The system is practically implemented by taken existing smart systems and IoT devices as city data sources to develop the Smart Digital City. The proposed system is evaluated with respect to efficiency in terms of scalability and real-time data processing.}
}
@article{KADIAN2021100419,
title = {Quantum walk and its application domains: A systematic review},
journal = {Computer Science Review},
volume = {41},
pages = {100419},
year = {2021},
issn = {1574-0137},
doi = {https://doi.org/10.1016/j.cosrev.2021.100419},
url = {https://www.sciencedirect.com/science/article/pii/S1574013721000599},
author = {Karuna Kadian and Sunita Garhwal and Ajay Kumar},
keywords = {Quantum walk, Quantum models, Quantum algorithms, Graph isomorphism, Security, Steganography, Quantum neural networks, Blockchain security, Teleportation, Machine learning, Quantum transport, Network security},
abstract = {Quantum random walk is the quantum counterpart of a classical random walk. The classical random walk concept has long been used as a computational framework for designing classical algorithms for complex problems. Quantum analogues of random walk provide speed-up in computational power for various algorithms such as element distinctness, spatial search, graph connectivity, etc. Quantum walks have emerged to be a universal computational model over the last decade. Quantum walk formulations applied in graph theory have shown quadratic and polynomial time in graph traversal as opposed to the exponential time taken by classical algorithms. Quantum walk models have also found use in designing quantum computers. Inspired by these facts, this article presents a substantial systematic literature review and analysis of various quantum walk formulations and their strengths and limitations w.r.t. application domains used in literature up-to-date by researchers in various fields. The analysis provided in this article may help upcoming researchers to gain new insights towards the application of quantum walk formulation in varied domains. Various performance metrics, physical implementation set-ups, coin operators, and simulators used to analyze classical and quantum walk dynamics on graphs have been described. Finally, the article discusses existing open problems and notable future directions related to quantum walk application for potential researchers.}
}
@article{ISLAM2021102225,
title = {A Survey on Task Offloading in Multi-access Edge Computing},
journal = {Journal of Systems Architecture},
volume = {118},
pages = {102225},
year = {2021},
issn = {1383-7621},
doi = {https://doi.org/10.1016/j.sysarc.2021.102225},
url = {https://www.sciencedirect.com/science/article/pii/S1383762121001570},
author = {Akhirul Islam and Arindam Debnath and Manojit Ghose and Suchetana Chakraborty},
keywords = {Multi-access edge computing, Task offloading, Mobile edge computing, Survey},
abstract = {With the advent of new technologies in both hardware and software, we are in the need of a new type of application that requires huge computation power and minimal delay. Applications such as face recognition, augmented reality, virtual reality, automated vehicles, industrial IoT, etc. belong to this category. Cloud computing technology is one of the candidates to satisfy the computation requirement of resource-intensive applications running in UEs (User Equipment) as it has ample computational capacity, but the latency requirement for these applications cannot be satisfied by the cloud due to the propagation delay between UEs and the cloud. To solve the latency issues for the delay-sensitive applications a new network paradigm has emerged recently known as Multi-Access Edge Computing (MEC) (also known as mobile edge computing) in which computation can be done at the network edge of UE devices. To execute the resource-intensive tasks of UEs in the MEC servers hosted in the network edge, a UE device has to offload some of the tasks to MEC servers. Few survey papers talk about task offloading in MEC, but most of them do not have in-depth analysis and classification exclusive to MEC task offloading. In this paper, we are providing a comprehensive survey on the task offloading scheme for MEC proposed by many researchers. We will also discuss issues, challenges, and future research direction in the area of task offloading to MEC servers.}
}
@article{KUMAR2021482,
title = {Artificial intelligence-based solution for sorting COVID related medical waste streams and supporting data-driven decisions for smart circular economy practice},
journal = {Process Safety and Environmental Protection},
volume = {152},
pages = {482-494},
year = {2021},
issn = {0957-5820},
doi = {https://doi.org/10.1016/j.psep.2021.06.026},
url = {https://www.sciencedirect.com/science/article/pii/S0957582021003177},
author = {Nallapaneni Manoj Kumar and Mazin Abed Mohammed and Karrar Hameed Abdulkareem and Robertas Damasevicius and Salama A. Mostafa and Mashael S. Maashi and Shauhrat S. Chopra},
keywords = {Medical waste streams, Smart circular economy, COVID waste management, Waste sorting, Feature fusion, Machine learning},
abstract = {Waste generation is a continuous process that needs to be managed effectively to ensure environmental safety and public health. The recent circular economy (CE) practices have brought a new shape for the waste management industry, creating value from the generated waste. The shift to a CE represents one of the most significant challenges, particularly in sorting and classifying generated waste. Addressing these challenges would facilitate the recycling industry and helps in promoting remanufacturing. But in the COVID times, most of the generated waste is getting mixed with conventional waste types, especially in the global south. The pandemic has resulted in colossal infectious waste generation. Its handling became the most significant challenge raising fears and concerns over sorting and classifying. Hence, this study proposes an Artificial Intelligence (AI) based automated solution for sorting COVID related medical waste streams from other waste types and, at the same time, ensures data-driven decisions for recycling in the context of CE. Metal, paper, glass waste categories, including the polyethylene terephthalate (PET) waste from the pandemic, are considered. The waste type classification is done based on the image-texture-dependent features, which provided an accurate sorting and classification before the recycling process starts. The features are fused using the proposed decision-level feature fusion scheme. The classification model based on the support vector machine (SVM) classifier performs best (with 96.5 % accuracy, 95.3 % sensitivity, and 95.9 % specificity) in classifying waste types in the context of circular manufacturing and exhibiting the abilities to manage the COVID related medical waste mixed.}
}
@article{ZHOU2020106286,
title = {Deep Flexible Structured Spatial–Temporal Model for Taxi Capacity Prediction},
journal = {Knowledge-Based Systems},
volume = {205},
pages = {106286},
year = {2020},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2020.106286},
url = {https://www.sciencedirect.com/science/article/pii/S0950705120304652},
author = {Wei Zhou and Yan Yang and Yiling Zhang and Dongjie Wang and Xiaobo Zhang},
keywords = {Deep learning, Traffic prediction, Spatial–temporal dependencies},
abstract = {The prevalence of taxi-hailing applications has brought great convenience to urban travel. People can not only get a taxi anytime and anywhere, but also make an appointment for taxi in advance. Therefore, people are concerned about the current taxi capacity (i.e. the number of vacant taxis) around them. Meanwhile, they also want to know the future capacity to help them choose the appointment time to avoid congestion and plan their itinerary. However, most of the exiting studies only aim to help taxi companies to schedule traffic resources, and cannot consider future travel plans for users. In this paper, we propose the Deep Flexible Structured Spatial–Temporal Model (DFSSTM) to tackle the task. In order to explore more sufficient temporal relationship of data, DFSSTM models the temporal dynamics as three views: period, trend and closeness. Then the Siamese Spatial–Temporal Network (SSTN) is designed for each view, which introduces the Siamese architecture to capture the spatial–temporal dependencies of inflows and outflows simultaneously. Finally, DFSSTM automatically weights each view and fuses the outputs of the three views to get the final prediction. Experimental results on real-world datasets show that the proposed approach outperforms state-of-the-art methods.}
}
@article{ELHAMDANI2020102856,
title = {Pedestrian Support in Intelligent Transportation Systems: Challenges, Solutions and Open issues},
journal = {Transportation Research Part C: Emerging Technologies},
volume = {121},
pages = {102856},
year = {2020},
issn = {0968-090X},
doi = {https://doi.org/10.1016/j.trc.2020.102856},
url = {https://www.sciencedirect.com/science/article/pii/S0968090X20307567},
author = {Sara {El Hamdani} and Nabil Benamar and Mohamed Younis},
keywords = {Intelligent transportation systems, VRUs protection, V2P communication, Autonomous vehicle Interaction, Pedestrian collision avoidance},
abstract = {The increased urbanization and the drive for realizing smart cities have motivated extensive research and development in the realm of Intelligent Transportation Systems (ITS) in order to deal with the increased traffic intensity. Yet, the scope of ITS is not limited to vehicles, as pedestrians are special road users that play an important role in affecting traffic, road infrastructure, and vehicle design. Pedestrians are deemed to be the most vulnerable road users and are the major sufferers of road-incident fatalities and injuries each year. Therefore, quite a few studies have focused on pedestrian’s support and safety. On the other hand, due to imperceptible behavior, a pedestrian may also negatively impact traffic efficiency and can thus be viewed as an obstacle for fully realizing the advantages of ITS. In addition, more issues related to pedestrians have been raised with the emergence of Autonomous Vehicles (AVs). In this paper, we discuss different issues related to pedestrians as road users. Furthermore, we provide a comprehensive survey and classification of the different solutions of pedestrian protection. Finally, we highlight technical gaps and point out possible future research directions.}
}
@article{MAITY2022101546,
title = {CoAN: A system framework correlating the air and noise pollution sensor data},
journal = {Pervasive and Mobile Computing},
pages = {101546},
year = {2022},
issn = {1574-1192},
doi = {https://doi.org/10.1016/j.pmcj.2022.101546},
url = {https://www.sciencedirect.com/science/article/pii/S1574119222000050},
author = {Biswajit Maity and Yashwant Polapragada and Sanghita Bhattacharjee and Subrata Nandi},
keywords = {Air pollution, Noise pollution, Context, Correlation, LIME analysis, Route recommendation},
abstract = {Although existing works in the literature highlight the monitoring, characterization, and analysis of both air and noise pollution, they mainly focus on the two environmental pollutants independently. In this paper, we develop a system framework that includes sensing and allows the processing of the combined impact of air and noise samples together to design micro-services. Few of the existing works that studied the combined effect of the two environmental stressors merely calculated the correlation values without further inferring contextual information from it. In contrast, our work aims to draw further inferences about the demographic/traffic/spatio-temporal aspect of a location and thus identifies the context in which the samples are collected. To achieve the goal, a system framework CoAN is developed under which we performed in-house data collection with approx. 820 km trail, covering approx. 10 km road segment in Durgapur, a sub-urban city in India. We used a commercially available ‘Flow’ device, and developed an android-based application, ‘AudREC’ for air and noise sampling, respectively. An unsupervised K-means algorithm has been used to segregate the combined samples into disjoint clusters for analysis. In addition, feature selection, model training, and cluster interpretation using the LIME model are performed to draw some inferences about the sample data space. Several supervised models, like Decision Tree, Random Forest, Logistic Regression, SVM, and Kernel-SVM is used for training the system. Results show that Logistic Regression performs best over others achieving 99% accuracy. Furthermore, as a micro-service, a healthier route recommendation system is designed to avoid pollution exposure by taking into account both air and noise pollution exposure volumes. A sample result shows that our recommended route gives almost 12% lesser pollution exposures as compared to all other available routes suggested by Google map with the same source and destination.}
}
@article{LINDER2017589,
title = {Big Building Data - a Big Data Platform for Smart Buildings},
journal = {Energy Procedia},
volume = {122},
pages = {589-594},
year = {2017},
note = {CISBAT 2017 International ConferenceFuture Buildings & Districts – Energy Efficiency from Nano to Urban Scale},
issn = {1876-6102},
doi = {https://doi.org/10.1016/j.egypro.2017.07.354},
url = {https://www.sciencedirect.com/science/article/pii/S1876610217329582},
author = {Lucy Linder and Damien Vionnet and Jean-Philippe Bacher and Jean Hennebert},
keywords = {Big Data, Building Management Systems, Smart Buildings, Web of Buildings},
abstract = {Future buildings will more and more rely on advanced Building Management Systems (BMS) connected to a variety of sensors, actuators and dedicated networks. Their objectives are to observe the state of rooms and apply automated rules to preserve or increase comfort while economizing energy. In this work, we advocate for the inclusion of a dedicated system for sensors data storage and processing, based on Big Data technologies. This choice enables new potentials in terms of data analytics and applications development, the most obvious one being the ability to scale up seamlessly from one smart building to several, in the direction of smart areas and smart cities. We report in this paper on our system architecture and on several challenges we met in its elaboration, attempting to meet requirements of scalability, data processing, flexibility, interoperability and privacy. We also describe current and future end-user services that our platform will support, including historical data retrieval, visualisation, processing and alarms. The platform, called BBData - Big Building Data, is currently in production at the Smart Living Lab of Fribourg and is offered to several research teams to ease their work, to foster the sharing of historical data and to avoid that each project develops its own data gathering and processing pipeline.}
}
@article{MAZUNGA2021e00720,
title = {Ultra-low power techniques in energy harvesting wireless sensor networks: Recent advances and issues},
journal = {Scientific African},
volume = {11},
pages = {e00720},
year = {2021},
issn = {2468-2276},
doi = {https://doi.org/10.1016/j.sciaf.2021.e00720},
url = {https://www.sciencedirect.com/science/article/pii/S2468227621000247},
author = {Felix Mazunga and Action Nechibvute},
keywords = {Ultra-low power, Dynamic Power Management, Routing protocol, Wireless sensor network, Energy harvesting, Network lifetime},
abstract = {Wireless sensor network (WSN) technology has gained increasing importance in industrial automation, agriculture, smart cities, environmental monitoring, target tracking, structural health monitoring, healthcare, military applications, and so on. WSNs powered by batteries have a problem of limited lifetime due to energy constraints. Energy harvesting technology aims to eliminate the burden of replacing or replenishing depleted batteries for the sensor nodes by harnessing energy from the environment. Ultra-low power techniques are aimed at prolonging the overall sensor network lifetime by yielding significant energy savings in the WSN. The performance and lifetime of energy harvesting wireless sensor networks (EHWSNs) can be enhanced by the development of Dynamic Power Management techniques. Energy management and conservation are critical issues in EHWSNs, hence the need to develop energy harvesting-aware protocols and algorithms that facilitate perpetual network operation. It is anticipated that advancements in miniaturization and ultra-low power techniques will drive the widespread adoption of the energy harvesting paradigm. This article provides a comprehensive review of recent advances towards ultra-low power techniques in EHWSNs. We explore some of the existing types of power management techniques in WSNs including their disadvantages. The operating principles of recently proposed applications of ultra-low power techniques in EHWSNs are reviewed along with their associated fundamental mathematical expressions and assumptions. An analysis of these recent ultra-low power schemes is also presented. For each of the techniques, a summary of strengths, weaknesses and proposed solutions is presented. We provide the research community with open research issues and future research directions as well.}
}
@article{JIANG202157,
title = {A new nonlocal means based framework for mixed noise removal},
journal = {Neurocomputing},
volume = {431},
pages = {57-68},
year = {2021},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2020.12.039},
url = {https://www.sciencedirect.com/science/article/pii/S0925231220319391},
author = {Jielin Jiang and Kang Yang and Jian Yang and Zhi-Xin Yang and Yadang Chen and Lei Luo},
keywords = {Mixed noise removal, Nonlocal self-similarity, Low rank approximation, Gradient regularization, Convolutional neural network},
abstract = {Many image-denoising approaches seek to remove either additive white Gaussian noise (AWGN) or impulse noise (IN), because both types are easier to process when considered separately. However, images can be corrupted by a mixture of AWGN and IN during image acquisition and transmission. The major difficulty of mixed noise removal arises through the complex distribution of noise, which cannot be fitted by a simple parametric model. In this paper, a new nonlocal means based framework (NMF) is proposed. A median-type filter is used to detect the locations of outlier pixels; these pixels are then replaced by their nonlocal means, which makes the mixed noise distribution approximately Gaussian. To prove the effectiveness of our NMF, a low rank approximation combined with NMF (LRNM) model is presented for mixed noise removal. In the LRNM, we group similar nonlocal patches in a matrix and apply a low rank approximation to reconstruct the clean image. Gradient regularization is added to better preserve the image texture details. A convolutional neural network (CNN) combined with the NMF (NMF-CNN) is also presented, to prove the generality of the NMF. Experimental results show that LRNM and NMF-CNN achieve a strong mixed noise removal performance and also produce visually pleasing denoising results.}
}
@article{SAIDMOHAMED2021971,
title = {Smart farming for improving agricultural management},
journal = {The Egyptian Journal of Remote Sensing and Space Science},
volume = {24},
number = {3, Part 2},
pages = {971-981},
year = {2021},
issn = {1110-9823},
doi = {https://doi.org/10.1016/j.ejrs.2021.08.007},
url = {https://www.sciencedirect.com/science/article/pii/S1110982321000582},
author = {Elsayed {Said Mohamed} and AA. Belal and Sameh {Kotb Abd-Elmabod} and Mohammed A El-Shirbeny and A. Gad and Mohamed B Zahran},
keywords = {IoT, Smart Agriculture, 5G, Decision support systems, Smart sensing},
abstract = {The food shortage and the population growth are the most challenges facing sustainable development worldwide. Advanced technologies such as artificial intelligence (AI), the Internet of Things (IoT), and the mobile internet can provide realistic solutions to the challenges that are facing the world. Therefore, this work focuses on the new approaches regarding smart farming (SF) from 2019 to 2021, where the work illustrates the data gathering, transmission, storage, analysis, and also, suitable solutions. IoT is one of the essential pillars in smart systems, as it connects sensor devices to perform various basic tasks. The smart irrigation system included those sensors for monitoring water level, irrigation efficiency, climate, etc. Smart irrigation is based on smart controllers and sensors as well as some mathematical relations. In addition, this work illustrated the application of unmanned aerial vehicles (UAV) and robots, where they can be achieved several functions such as harvesting, seedling, weed detection, irrigation, spraying of agricultural pests, livestock applications, etc. real-time using IoT, artificial intelligence (AI), deep learning (DL), machine learning (ML) and wireless communications. Moreover, this work demonstrates the importance of using a 5G mobile network in developing smart systems, as it leads to high-speed data transfer, up to 20 Gbps, and can link a large number of devices per square kilometer. Although the applications of smart farming in developing countries are facing several challenges, this work highlighted some approaches the smart farming. In addition, the implementation of Smart Decision Support Systems (SDSS) in developing countries supports the real-time analysis, mapping of soil characteristics and also helps to make proper decision management. Finally, smart agriculture in developing countries needs more support from governments at the small farms and the private sector.}
}
@article{LI202072,
title = {Short-term traffic state prediction from latent structures: Accuracy vs. efficiency},
journal = {Transportation Research Part C: Emerging Technologies},
volume = {111},
pages = {72-90},
year = {2020},
issn = {0968-090X},
doi = {https://doi.org/10.1016/j.trc.2019.12.007},
url = {https://www.sciencedirect.com/science/article/pii/S0968090X19308009},
author = {Wan Li and Jingxing Wang and Rong Fan and Yiran Zhang and Qiangqiang Guo and Choudhury Siddique and Xuegang (Jeff) Ban},
keywords = {Short-term traffic state prediction, Spatiotemporal dependencies, Partial least square regression, Latent structures, Real-time applications},
abstract = {Recently, deep learning models have shown promising performances in many research areas, including traffic states prediction, due to their ability to model complex nonlinear relationships. However, deep learning models also have drawbacks that make them less preferable for certain short-term traffic prediction applications. For example, they require a large amount of data for model training, which is also computationally expensive. Moreover, deep learning models lack interpretability of the results. This paper develops a short-term traffic states forecasting algorithm based on partial least square (PLS) to help enhance real-time decision-making and build better insights into traffic data. The proposed model is capable of predicting short-term traffic states accurately and efficiently by capturing dominant spatiotemporal features and day-to-day variations from collinear and correlated traffic data. Three case studies are developed to demonstrate the proposed model in short-term traffic prediction applications.}
}
@article{CHEN2020101520,
title = {Impact of extreme weather events on urban human flow: A perspective from location-based service data},
journal = {Computers, Environment and Urban Systems},
volume = {83},
pages = {101520},
year = {2020},
issn = {0198-9715},
doi = {https://doi.org/10.1016/j.compenvurbsys.2020.101520},
url = {https://www.sciencedirect.com/science/article/pii/S0198971520302532},
author = {Zhenhua Chen and Zhaoya Gong and Shan Yang and Qiwei Ma and Changcheng Kan},
keywords = {Disaster analysis, Urban human flow, Location-based service data, AMOEBA, Baidu map},
abstract = {This study investigates the impact of extreme weather events on urban human flow disruptions using location-based service data obtained from Baidu Map. Utilizing the 2018 Typhoon Mangkhut as an example, the spatial and temporal variations of urban human flow patterns in Shenzhen are examined using GIS and spatial flow analysis. In addition, the variation of human flow by different urban functions (e.g. transport, recreational, institutional, commercial and residential related facilities) is also examined through an integration of flow data and point-of-interest (POI) data. The study reveals that urban flow patterns varied substantially before, during, and after the typhoon. Specifically, urban flows were found to have reduced by 39% during the disruption. Conversely, 56% of flows increased immediately after the disruption. In terms of functional variation, the assessment reveals that fundamental urban functions, such as industrial (work) and institutional - (education) related trips experienced less disruption, whereas the typhoon event appears to have a relatively larger negative influence on recreational related trips. Overall, the study provides implications for planners and policy makers to enhance urban resilience to disasters through a better understanding of the urban vulnerability to disruptive events.}
}
@article{GREGOR20191327,
title = {Transfer Learning for Classification of Parking Spots using Residual Networks},
journal = {Transportation Research Procedia},
volume = {40},
pages = {1327-1334},
year = {2019},
note = {TRANSCOM 2019 13th International Scientific Conference on Sustainable, Modern and Safe Transport},
issn = {2352-1465},
doi = {https://doi.org/10.1016/j.trpro.2019.07.184},
url = {https://www.sciencedirect.com/science/article/pii/S2352146519303527},
author = {Michal Gregor and Rastislav Pirník and Dušan Nemec},
keywords = {deep learning, convolutional networks, parking lots, occupancy detection, residual architecture},
abstract = {The paper proposes a classifier with a residual convolutional architecture for visual parking spot classification into classes “empty” and “occupied”. The classifier is trained on the well-known PKLot dataset. Transfer of the resulting model to data with new challenging modalities (such as snow, partially obscured vision, reflections, mist, …) is tested - to this end a new dataset has been collected by the authors. It is shown that the original classifier fails in some of these unfamiliar settings, but that the failure modes can successfully be corrected using transfer learning.}
}
@article{RAJPUT2020101246,
title = {Opportunistic sensing based detection of crowdedness in public transport buses},
journal = {Pervasive and Mobile Computing},
volume = {68},
pages = {101246},
year = {2020},
issn = {1574-1192},
doi = {https://doi.org/10.1016/j.pmcj.2020.101246},
url = {https://www.sciencedirect.com/science/article/pii/S1574119220300961},
author = {Pruthvish Rajput and Manish Chaturvedi and Vivek Patel},
keywords = {Smart city, Intelligent Transportation System (ITS), Opportunistic sensing (crowdsourcing), Public transportation, Machine learning},
abstract = {This paper presents an opportunistic sensing based solution to detect crowdedness in public transportation buses. The solution uses data of accelerometer and Global Positioning System (GPS) sensors available in smartphones carried by the commuters. These data are used to accurately identify bus boarding event and whether a commuter got a seat during his/her trip. The solution is energy efficient as it uses power hungry GPS very conservatively and keeps it off majority of the times. The solution is evaluated using data collected over the arterial roads of Ahmedabad and Gandhinagar city. The length of routes varies from 25 to 45 kilometers. The effect of application penetration on crowdedness detection in buses is also evaluated. It is found that the penetration of 8 to 12% in commuter population can detect the crowdedness for more than 80% of route segments on the test routes. Further, the solution results in the energy-saving of about 50% compared to a solution that requires GPS data continuously. We also present the bus scheduling scheme that uses the historical data of bus-crowdedness to schedule the feeder buses on the crowded segments of the route.}
}
@article{QU2021262,
title = {Visual content-enhanced sequential recommendation with feature-level attention},
journal = {Neurocomputing},
volume = {443},
pages = {262-271},
year = {2021},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2021.02.037},
url = {https://www.sciencedirect.com/science/article/pii/S0925231221002915},
author = {Tong Qu and Wanggen Wan and Shoujin Wang},
keywords = {Visual understanding, Attention mechanism, Recurrent neural networks},
abstract = {A sequential recommender system (SRS) takes historical user-item interactions as a sequence to predict the next item that may be of interest to a user. Most of existing SRSs make predictions by only considering item IDs, while ignoring other important factors that may also significantly influence users’ choices, such as the visual content of items. This may not always be true in reality since an item’s appearance usually has great visual impact on users and thus plays an important role in users’ choices. In practice, each item’s appearance has often been specifically designed to represent a particular style or look. In addition, users’ preferences with regard to visual aspects, such as styling, color, etc., may be relatively consistent compared with their dynamic preferences on items for a certain period under sequential transaction scenarios. This motivates us to take the items’ visual content into account to build more reliable SRSs. Accordingly, we propose a novel visual content-enhanced sequential recommender system (VCSRS) for improving the performance of sequential recommendations. Particularly, in VCSRS, a feature-level attention module (FAM) is designed to learn the attentive visual representations of an item’s appearance. Moreover, a vision-concentrated recurrent network (VCRN) is devised to model the sequential dependencies between items while incorporating items’ visual representations. Extensive experiments on real-world datasets demonstrated the effectiveness of visual information and showed the superiority of our approach over other representative and state-of-the-art methods.}
}
@article{ARDAGNA2018548,
title = {Context-aware data quality assessment for big data},
journal = {Future Generation Computer Systems},
volume = {89},
pages = {548-562},
year = {2018},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2018.07.014},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X17329151},
author = {Danilo Ardagna and Cinzia Cappiello and Walter Samá and Monica Vitali},
keywords = {Data quality, Big data, Context-awareness, Data profiling, DQ assessment},
abstract = {Big data changed the way in which we collect and analyze data. In particular, the amount of available information is constantly growing and organizations rely more and more on data analysis in order to achieve their competitive advantage. However, such amount of data can create a real value only if combined with quality: good decisions and actions are the results of correct, reliable and complete data. In such a scenario, methods and techniques for the Data Quality assessment can support the identification of suitable data to process. If for traditional database numerous assessment methods are proposed, in the Big Data scenario new algorithms have to be designed in order to deal with novel requirements related to variety, volume and velocity issues. In particular, in this paper we highlight that dealing with heterogeneous sources requires an adaptive approach able to trigger the suitable quality assessment methods on the basis of the data type and context in which data have to be used. Furthermore, we show that in some situations it is not possible to evaluate the quality of the entire dataset due to performance and time constraints. For this reason, we suggest to focus the Data Quality assessment only on a portion of the dataset and to take into account the consequent loss of accuracy by introducing a confidence factor as a measure of the reliability of the quality assessment procedure. We propose a methodology to build a Data Quality adapter module, which selects the best configuration for the Data Quality assessment based on the user main requirements: time minimization, confidence maximization, and budget minimization. Experiments are performed by considering real data gathered from a smart city case study.}
}
@article{BUDDHAN2019965,
title = {Even Driven Multimodal Augmented Reality based Command and Control Systems for Mining Industry},
journal = {Procedia Computer Science},
volume = {151},
pages = {965-970},
year = {2019},
note = {The 10th International Conference on Ambient Systems, Networks and Technologies (ANT 2019) / The 2nd International Conference on Emerging Data and Industry 4.0 (EDI40 2019) / Affiliated Workshops},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2019.04.135},
url = {https://www.sciencedirect.com/science/article/pii/S187705091930599X},
author = {Andhan Rahul Buddhan and Subha P. Eswaran and D. M Ezhil Buddhan and Sridhar Sripurushottama},
keywords = {Multimodal Learning, Augmented Reality (AR), CEP, Command, Control, Mining},
abstract = {The mining industry is confronted with obligations to improve worker safety and provide more effective maintenance of the new-age mining machineries. It is also essential to develop reconnaissance mission to support emergency rescue operations. An approach to ensure the mine workers safety using AR (Augmented Reality) with remote monitoring CCS (Command Control System) is proposed in this paper. This method provides an interactive and augmented real time instantaneous personal safety solution. The benefit of augmented reality is blended with real time mining environmental sensor data using multimodal learning approach to predict the emergency situation instantaneously. Environmental mining sensory information is processed with Complex Event Processing (CEP) engine to derive high level events that trigger the alarm for the emergency situation. The proposed event driven multimodal AR based CCS, outperforms the existing emergency prediction solutions that use sensor fusion or deep learning AR.}
}
@article{STAINO2016713,
title = {Cooperative optimization of building energy systems in an economic model predictive control framework},
journal = {Energy and Buildings},
volume = {128},
pages = {713-722},
year = {2016},
issn = {0378-7788},
doi = {https://doi.org/10.1016/j.enbuild.2016.07.009},
url = {https://www.sciencedirect.com/science/article/pii/S0378778816306053},
author = {Andrea Staino and Himanshu Nagpal and Biswajit Basu},
keywords = {Cooperative optimization, Control systems, Building energy management systems, Heat-pumps, Economic model predictive control},
abstract = {A concept of ‘cooperative’ optimization of building energy systems is proposed in this paper. A cooperative optimization framework for a group of buildings connected to heat pumps in the context of economic model predictive control is formulated. Two optimization scenarios have been considered for analysis – a ‘selfish’ optimization of an individual building and a cooperative optimization of a group of buildings. The impact of cooperative optimization on the energy usage patterns and cost of electricity for operating the heat pumps have been investigated. The proposed cooperative optimization approach is able to achieve up to 15% reduction in energy demand cost in comparison with selfish optimization. The benefits arising out of the cooperative optimization concept may be a major drive for the future smart cities and will play a significant role in advancing the concept of smart energy systems.}
}
@article{SAFAEIPOUR2020101707,
title = {On data-driven curation, learning, and analysis for inferring evolving internet-of-Things (IoT) botnets in the wild},
journal = {Computers & Security},
volume = {91},
pages = {101707},
year = {2020},
issn = {0167-4048},
doi = {https://doi.org/10.1016/j.cose.2019.101707},
url = {https://www.sciencedirect.com/science/article/pii/S0167404819302445},
author = {Morteza {Safaei Pour} and Antonio Mangino and Kurt Friday and Matthias Rathbun and Elias Bou-Harb and Farkhund Iqbal and Sagar Samtani and Jorge Crichigno and Nasir Ghani},
keywords = {Data science, Cyber forensics, Internet-of-things, IoT Security, Internet measurements},
abstract = {The insecurity of the Internet-of-Things (IoT) paradigm continues to wreak havoc in consumer and critical infrastructures. The highly heterogeneous nature of IoT devices and their widespread deployments has led to the rise of several key security and measurement-based challenges, significantly crippling the process of collecting, analyzing and correlating IoT-centric data. To this end, this paper explores macroscopic, passive empirical data to shed light on this evolving threat phenomena. The proposed work aims to classify and infer Internet-scale compromised IoT devices by solely observing one-way network traffic, while also uncovering, reporting and thoroughly analyzing “in the wild” IoT botnets. To prepare a relevant dataset, a novel probabilistic model is developed to cleanse unrelated traffic by removing noise samples (i.e., misconfigured network traffic). Subsequently, several shallow and deep learning models are evaluated in an effort to train an effective multi-window convolutional neural network. By leveraging active and passing measurements when generating the training dataset, the neural network aims to accurately identify compromised IoT devices. Consequently, to infer orchestrated and unsolicited activities that have been generated by well-coordinated IoT botnets, hierarchical agglomerative clustering is employed by scrutinizing a set of innovative and efficient network feature sets. Analyzing 3.6 TB of recently captured darknet traffic revealed a momentous 440,000 compromised IoT devices and generated evidence-based artifacts related to 350 IoT botnets. Moreover, by conducting thorough analysis of such inferred campaigns, we reveal their scanning behaviors, packet inter-arrival times, employed rates and geo-distributions. Although several campaigns exhibit significant differences in these aspects, some are more distinguishable; by being limited to specific geo-locations or by executing scans on random ports besides their core targets. While many of the inferred botnets belong to previously documented campaigns such as Hide and Seek, Hajime and Fbot, newly discovered events portray the evolving nature of such IoT threat phenomena by demonstrating growing cryptojacking capabilities or by targeting industrial control services. To motivate empirical (and operational) IoT cyber security initiatives as well as aid in reproducibility of the obtained results, we make the source codes of all the developed methods and techniques available to the research community at large.}
}
@article{TESLYUK2019394,
title = {Neural controller for smart house security subsystem},
journal = {Procedia Computer Science},
volume = {160},
pages = {394-401},
year = {2019},
note = {The 10th International Conference on Emerging Ubiquitous Systems and Pervasive Networks (EUSPN-2019) / The 9th International Conference on Current and Future Trends of Information and Communication Technologies in Healthcare (ICTH-2019) / Affiliated Workshops},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2019.11.075},
url = {https://www.sciencedirect.com/science/article/pii/S1877050919317752},
author = {Vasyl Teslyuk and Pavlo Denysyuk and Natalia Kryvinska and Khrystyna Beregovska and Taras Teslyuk},
keywords = {neural controller, Smart House, security subsystem, model, artificical neural network, Petri net},
abstract = {The Smart House security subsystem is presented in the paper. The subsystem is based on neural controller that uses an artificial neural network of a multilayer perceptron type, a model based on the Petri nets theory and physical model based on an Arduino microcontroller. The model of artificial neural network is developed using C++ and loaded into microcontroller memory. The presented security subsystem Smart House supports processing fuzzy and semistructured data received from sensor subsystems.}
}
@article{NISHIMWE2021111535,
title = {Estimation, analysis and mapping of electricity consumption of a regional building stock in a temperate climate in Europe},
journal = {Energy and Buildings},
volume = {253},
pages = {111535},
year = {2021},
issn = {0378-7788},
doi = {https://doi.org/10.1016/j.enbuild.2021.111535},
url = {https://www.sciencedirect.com/science/article/pii/S0378778821008197},
author = {Antoinette Marie Reine Nishimwe and Sigrid Reiter},
keywords = {Electricity consumption modelling, Energy management, Smart city, Building stock characterization, Urban region},
abstract = {This study financed by ERDF and the Wallonia Region estimates the annual electricity consumption (EC) of building stock, including the 3 building sectors namely residential, tertiary and industrial building. The estimation takes into account appliances, electrical heating, cooling, lighting, cooking and EC by m2 on a building level. The results are spatialized on different territorial scales. Using cadastral data of more than 1,700,000 Walloon buildings and annual EC data from a sample collected in 2012 from the energy reports, the paper assesses the EC of the whole building stock and tests to what extent different types of variables (building factors and socio-demographics) explain annual EC. It then shows which individual variables have the highest explanatory power. In contrast to many other studies, the research recognizes the problem of multicollinearity between predictors in regression analysis and uses Lasso regression to address this issue. Three separate regression models were used to study the predictors of annual EC of residential, tertiary and industrial buildings. EC building factors (appliances, auxiliary and main heating, domestic hot water and cooking) explained the largest share which is 66.46% of the variability in EC for residential buildings whereas the EC usages share for tertiary buildings (lighting, heating and domestic hot water, air conditioning, cooling, etc.) is about 50.53% and 38.55% for industrial buildings. Socio-demographic variables on their own explained about 61.59%, 26.34% and 3.41% of the annual EC, respectively for residential, tertiary and industrial buildings. Hence, the building variables present the highest explanatory power for EC, presumably because heating and cooling EC are included in this study. The study highlights that when attempting to explain EC related to Walloon households, including heating and cooling EC, appliances usage has the strongest predictive power in residential buildings. On the other hand, the projected decrease in EC use for heating in existing residential buildings is −8.82% and −10% for existing tertiary buildings while the projected increase in EC use for cooling in existing tertiary buildings is + 11.94% from 2012 to 2050 on a regional scale. These trends follow the predicted regional heating degree-days (HDD) of −11.76% and cooling degree-days (CDD) of 14.04% for the same period based on the gated recurrent unit (GRU) an implemented deep learning (DL) model. In addition, the produced EC maps on different territorial scales show that the highest EC is seen in large and main cities in general.}
}
@article{WANG2021261,
title = {Digital twin improved via visual question answering for vision-language interactive mode in human–machine collaboration},
journal = {Journal of Manufacturing Systems},
volume = {58},
pages = {261-269},
year = {2021},
note = {Digital Twin towards Smart Manufacturing and Industry 4.0},
issn = {0278-6125},
doi = {https://doi.org/10.1016/j.jmsy.2020.07.011},
url = {https://www.sciencedirect.com/science/article/pii/S0278612520301217},
author = {Tian Wang and Jiakun Li and Zhaoning Kong and Xin Liu and Hichem Snoussi and Hongqiang Lv},
keywords = {Digital twin, Human–machine collaboration, Visual question answer, Deep learning},
abstract = {The human–machine collaboration system is a key means of manufacturing. Its surveillance, prognostic, and health management are related to safety and manufacturing persistence. This paper begins with the mission requirements of intelligent manufacturing. The study is based on the visual question answering (VQA) technology with a digital twin to increase efficiency. The research contents are as follows: (1) A method of modeling human–machine collaboration based on digital twins is proposed. (2) A VQA is adopted in the digital twin. The video and neural language are considered. (3) VQA technology is introduced into the modeling of the human–machine collaboration system for consistent integration. With VQA technology, humans and machines can collaborate. Human–machine interaction and product counting are implemented in a case study to provide a comprehensive perception.}
}
@article{BALALI2020106492,
title = {Joint event extraction along shortest dependency paths using graph convolutional networks},
journal = {Knowledge-Based Systems},
volume = {210},
pages = {106492},
year = {2020},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2020.106492},
url = {https://www.sciencedirect.com/science/article/pii/S0950705120306213},
author = {Ali Balali and Masoud Asadpour and Ricardo Campos and Adam Jatowt},
keywords = {Information extraction, Event extraction, Deep learning, Shortest dependency path, Graph convolution network},
abstract = {Event extraction (EE) is one of the core information extraction tasks, whose purpose is to automatically identify and extract information about incidents and their actors from texts. This may be beneficial to several domains such as knowledge base construction, question answering and summarization tasks, to name a few. The problem of extracting event information from texts is longstanding and usually relies on elaborately designed lexical and syntactic features, which, however, take a large amount of human effort and lack generalization. More recently, deep neural network approaches have been adopted as a means to learn underlying features automatically. However, existing networks do not make full use of syntactic features, which play a fundamental role in capturing very long-range dependencies. Also, most approaches extract each argument of an event separately without considering associations between arguments which ultimately leads to low efficiency, especially in sentences with multiple events. To address the above-referred problems, we propose a novel joint event extraction framework that aims to extract multiple event triggers and arguments simultaneously by introducing shortest dependency path in the dependency graph. We do this by eliminating irrelevant words in the sentence, thus capturing long-range dependencies. Also, an attention-based graph convolutional network is proposed, to carry syntactically related information along the shortest paths between argument candidates that captures and aggregates the latent associations between arguments; a problem that has been overlooked by most of the literature. Our results show a substantial improvement over state-of-the-art methods on two datasets, namely ACE 2005 and TAC KBP 2015.}
}
@article{RECALEGARI201615,
title = {Filtering and windowing mobile traffic time series for territorial land use classification},
journal = {Computer Communications},
volume = {95},
pages = {15-28},
year = {2016},
note = {Mobile Traffic Analytics},
issn = {0140-3664},
doi = {https://doi.org/10.1016/j.comcom.2016.04.016},
url = {https://www.sciencedirect.com/science/article/pii/S0140366416301529},
author = {Gloria {Re Calegari} and Emanuela Carlino and Diego Peroni and Irene Celino},
keywords = {Mobile traffic time series, Time series smoothing, Time series decomposition, Time series filtering, Time series windowing, Land use classification, Urban planning, Smart cities},
abstract = {Analytics of mobile traffic information may take into account the time-series nature of the data itself. When employing mobile traffic data in a predictive setting to derive useful knowledge to characterize the city environment, the most suitable time series processing methods must be identified. In this paper, we propose an approach to process mobile traffic data using specific time series techniques – smoothing, decomposition, filtering, time-windowing – and to establish the best approach to exploit information extracted from those time series to classify land use, according to sensitivity/specificity metrics. We apply our methodology to a large-scale mobile traffic dataset, we assess its feasibility and we discuss the suitability of different methods for land use classification.}
}
@article{SINGH202156,
title = {Fog computing: A taxonomy, systematic review, current trends and research challenges},
journal = {Journal of Parallel and Distributed Computing},
volume = {157},
pages = {56-85},
year = {2021},
issn = {0743-7315},
doi = {https://doi.org/10.1016/j.jpdc.2021.06.005},
url = {https://www.sciencedirect.com/science/article/pii/S0743731521001349},
author = {Jagdeep Singh and Parminder Singh and Sukhpal Singh Gill},
keywords = {Fog computing, Frameworks, Edge computing, Applications, Internet of things (IoT)},
abstract = {There has been rapid development in the number of Internet of Things (IoT) connected nodes and devices in our daily life in recent times. With this increase in the number of devices, fog computing has become a well-established paradigm to optimize various key Quality of Service (QoS) requirements such as latency, bandwidth limitation, response time, scalability, privacy and security. In this paper, we present a systematic literature review of fog computing. This review article aims to classify recently published studies and investigate the current status in the area of fog computing. In this work, we have discussed the important characteristics of fog computing frameworks and identified various issues related to its architectural design, QoS metrics, implementation details, applications and communication modes. We have proposed taxonomy for fog computing frameworks based on the existing literature and compared the different research work based on taxonomy. Finally, various open research challenges and promising future directions are highlighted for further research in the area of fog computing.}
}
@article{EPPERLEIN2019116,
title = {Recovering Markov models from closed-loop data},
journal = {Automatica},
volume = {103},
pages = {116-125},
year = {2019},
issn = {0005-1098},
doi = {https://doi.org/10.1016/j.automatica.2019.01.022},
url = {https://www.sciencedirect.com/science/article/pii/S0005109819300299},
author = {Jonathan P. Epperlein and Sergiy Zhuk and Robert Shorten},
abstract = {Situations in which recommender systems are used to augment decision making are becoming prevalent in many application domains. Almost always, these prediction tools (recommenders) are created with a view to affecting behavioural change. Clearly, successful applications actuating behavioural change, affect the original model underpinning the predictor, leading to an inconsistency. This feedback loop is often not considered in standard machine learning techniques which rely upon machine learning/statistical learning machinery. The objective of this paper is to develop tools that recover unbiased user models in the presence of recommenders. More specifically, we assume that we observe a time series which is a trajectory of a Markov chain R modulated by another Markov chain S, i.e. the transition matrix of R is unknown and depends on the current state of S. The transition matrix of the latter is also unknown. In other words, at each time instant, S selects a transition matrix for R within a given set which consists of known and unknown matrices. The state of S, in turn, depends on the current state of R thus introducing a feedback loop. We propose an Expectation–Maximisation (EM) type algorithm, which estimates the transition matrices of S and R. Experimental results are given to demonstrate the efficacy of the approach.}
}
@article{SINGH2020952,
title = {An Improved Vehicle Parking Mechanism to reduce Parking Space Searching Time using Firefly Algorithm and Feed Forward Back Propagation Method},
journal = {Procedia Computer Science},
volume = {167},
pages = {952-961},
year = {2020},
note = {International Conference on Computational Intelligence and Data Science},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2020.03.394},
url = {https://www.sciencedirect.com/science/article/pii/S1877050920308607},
author = {Ruby Singh and Chiranjit Dutta and Niraj Singhal and Tanupriya Choudhury},
keywords = {Firefly Algorithm, Neural Network, Parking Efficiency, Parking space searching time},
abstract = {An issue of finding parking space is a serious concern in some locations, especially shopping complexes, hospitals, buildings, malls and other premises requires large parking space for vehicles. The parking scenario becomes worst on special occasions like festivals, fiesta and weekends. The conventional developed techniques using installation of sensors in parking zone for parking vehicles becomes costly. Therefore, a reliable method is required that works for long time to manage traffic congestion that occurs while searching for parking space. In this paper, a novel method is proposed for parking vehicles using metaheuristic approaches. The developed approach provides consistent results considering two parameters, parking efficiency and parking space search time. The parking efficiency is improved and parking space search time is reduced using the Firefly Algorithm (FA) and Feed Forward Back Propagation Neural Network (NN) approach.}
}
@article{HAMEED2020106643,
title = {Towards Energy and Performance-aware Geographic Routing for IoT-enabled Sensor Networks},
journal = {Computers & Electrical Engineering},
volume = {85},
pages = {106643},
year = {2020},
issn = {0045-7906},
doi = {https://doi.org/10.1016/j.compeleceng.2020.106643},
url = {https://www.sciencedirect.com/science/article/pii/S0045790620304985},
author = {Ahmad Raza Hameed and Saif ul Islam and Mohsin Raza and Hasan Ali Khattak},
keywords = {Internet of Things, Wireless sensor networks, Location error, Energy holes, Energy void regions},
abstract = {Internet of Things has been a pivotal technology enabler for realizing smart cities vision through the provision of connectivity for everyday objects by means of wireless sensor networks (WSNs). Scalability, flexibility, route efficiency, mobility support and reduced overhead in routing protocols are desired functions in large-scale WSNs. Given the several geographic routing schemes proposed, mainly focusing on positioning, location error, and energy consumption, still exhibit higher delays and overhead which significantly affect the performance of the network. In this paper, an energy-efficient geographic (EEG) routing protocol has been proposed that focuses on network throughput and energy consumption of sensor nodes. Moreover, this strategy also helps in avoiding void region’s creation in the network. The proposed protocol reduces the energy hole problem by efficiently balancing the energy consumption among sensor nodes. The extensive simulations illustrate that the proposed scheme manages energy consumption and packet delivery ratio more efficiently in comparison to a state-of-the-art geographic routing protocol.}
}
@article{GRANELL202012,
title = {Study of the influence of lexicon and language restrictions on computer assisted transcription of historical manuscripts},
journal = {Neurocomputing},
volume = {390},
pages = {12-27},
year = {2020},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2020.01.081},
url = {https://www.sciencedirect.com/science/article/pii/S0925231220301338},
author = {Emilio Granell and Verónica Romero and Carlos-D. Martínez-Hinarejos},
keywords = {Handwritten text recognition, Deep learning, Interactive transcription},
abstract = {State-of-the-art Handwritten Text Recognition (HTR) systems allow transcribers to speed-up the transcription of handwritten text images. These systems provide transcribers an initial draft transcription that can be corrected with less effort than transcribing the handwritten text images from scratch. Currently, even the draft transcriptions offered by the most advanced HTR systems contain errors. Therefore, the supervision of this draft by a human transcriber is still necessary to obtain the correct transcription of the handwritten text images. This supervision can be eased by using interactive and assistive transcription systems, where the transcriber and the automatic system cooperate in the amending process. In this paper, the draft transcription is provided by an HTR system based on Convolutional and Recurrent Neural Networks with Bidirectional Long-Short Term Memory units, and the assistive system is fed by lattices generated by using Weighted Finite State Transducers. The influence of the lexicon and language restrictions on the performance of our computer assisted transcription system is evaluated on three historical manuscripts. The transcriptions offered by the proposed HTR system present very low error rates for the studied historical manuscripts. However, our assistive transcription system without lexicon or language restrictions is able to provide an additional reduction on the human effort required to correct the transcriptions in more than 50% over the transcriptions offered by the HTR system.}
}
@article{NASSER2021103048,
title = {n-Gram based language processing using Twitter dataset to identify COVID-19 patients},
journal = {Sustainable Cities and Society},
volume = {72},
pages = {103048},
year = {2021},
issn = {2210-6707},
doi = {https://doi.org/10.1016/j.scs.2021.103048},
url = {https://www.sciencedirect.com/science/article/pii/S2210670721003322},
author = {Nidal Nasser and Lutful Karim and Ahmed {El Ouadrhiri} and Asmaa Ali and Nargis Khan},
keywords = {Language categorization, Character -gram, Word -gram, TFIDF, LSVM, Natural language processing},
abstract = {Due to the rapid growth of electronic documents, e.g., tweets, blogs, Facebook posts, snaps in different languages that use the same writing script, language categorization, and processing have great importance. For instance, to identify COVID-19 positive patients or people’s emotions on COVID-19 pandemic from tweets written in 35 different languages faster and accurate, language categorization and processing of tweets is significantly essential. Among many language categorization and processing techniques, character and word n-gram based techniques are very popular and simple but very efficient for categorizing and processing both short and large documents. One of the fundamental problems of language processing is the efficient use of memory space in implementing a technique so that a vast collection of documents can be easily categorized and processed. In this paper, we introduce a framework that categorizes the language of tweets using n-gram based language categorization technique and further processes the tweets using the machine-learning approach, Linear Support Vector Machine (LSVM), that may be able to identify COVID-19 positive patients. We evaluate and compare the performance of the proposed framework in terms of language categorization accuracy, precession, recall, and F-measure over n-gram length. The proposed framework is scalable as many other applications that involve extracting features and classifying languages collected from social media, and different types of networks may use this framework. This proposed framework, also being a part of health monitoring and improvement, tends to achieve the goal of having a sustainable society.}
}
@article{DWIVEDI2021101994,
title = {Artificial Intelligence (AI): Multidisciplinary perspectives on emerging challenges, opportunities, and agenda for research, practice and policy},
journal = {International Journal of Information Management},
volume = {57},
pages = {101994},
year = {2021},
issn = {0268-4012},
doi = {https://doi.org/10.1016/j.ijinfomgt.2019.08.002},
url = {https://www.sciencedirect.com/science/article/pii/S026840121930917X},
author = {Yogesh K. Dwivedi and Laurie Hughes and Elvira Ismagilova and Gert Aarts and Crispin Coombs and Tom Crick and Yanqing Duan and Rohita Dwivedi and John Edwards and Aled Eirug and Vassilis Galanos and P. Vigneswara Ilavarasan and Marijn Janssen and Paul Jones and Arpan Kumar Kar and Hatice Kizgin and Bianca Kronemann and Banita Lal and Biagio Lucini and Rony Medaglia and Kenneth {Le Meunier-FitzHugh} and Leslie Caroline {Le Meunier-FitzHugh} and Santosh Misra and Emmanuel Mogaji and Sujeet Kumar Sharma and Jang Bahadur Singh and Vishnupriya Raghavan and Ramakrishnan Raman and Nripendra P. Rana and Spyridon Samothrakis and Jak Spencer and Kuttimani Tamilmani and Annie Tubadji and Paul Walton and Michael D. Williams},
keywords = {Artificial intelligence, AI, Cognitive computing, Expert systems, Machine learning, Research agenda},
abstract = {As far back as the industrial revolution, significant development in technical innovation has succeeded in transforming numerous manual tasks and processes that had been in existence for decades where humans had reached the limits of physical capacity. Artificial Intelligence (AI) offers this same transformative potential for the augmentation and potential replacement of human tasks and activities within a wide range of industrial, intellectual and social applications. The pace of change for this new AI technological age is staggering, with new breakthroughs in algorithmic machine learning and autonomous decision-making, engendering new opportunities for continued innovation. The impact of AI could be significant, with industries ranging from: finance, healthcare, manufacturing, retail, supply chain, logistics and utilities, all potentially disrupted by the onset of AI technologies. The study brings together the collective insight from a number of leading expert contributors to highlight the significant opportunities, realistic assessment of impact, challenges and potential research agenda posed by the rapid emergence of AI within a number of domains: business and management, government, public sector, and science and technology. This research offers significant and timely insight to AI technology and its impact on the future of industry and society in general, whilst recognising the societal and industrial influence on pace and direction of AI development.}
}
@article{HAUSKEN2020100204,
title = {Cyber resilience in firms, organizations and societies},
journal = {Internet of Things},
volume = {11},
pages = {100204},
year = {2020},
issn = {2542-6605},
doi = {https://doi.org/10.1016/j.iot.2020.100204},
url = {https://www.sciencedirect.com/science/article/pii/S2542660520300408},
author = {Kjell Hausken},
keywords = {Cyber resilience, Recovery, Non-threat actors, Threat actors, Levels of organization, Insurance, Internet of things},
abstract = {Cyber resilience involves most societal actors, i.e. organizations, individuals, threat actors, governments, insurers, etc., at most levels of organization. Actors are embedded within each other and choose strategies based on beliefs and preferences which impact and is impacted by cyber resilience. The article reviews the literature, attempting to capture the core ingredients of cyber resilience. Non-threat actors seeking to obtain cyber resilience are distinguished from threat actors. Actors have resources, competence, technology, and tools. They make choices that impact the cyber resilience for all actors, including themselves. Cyber resilience relates to cyber insurance through entry requirements or preconditions for cyber contracts, need for various services such as incident response, data gathering, and cover limitations. Cyber resilience is linked to the internet of things which in the future can be expected to simplify life through artificial intelligence and machine learning, while being vulnerable through a large attack surface, insufficient technology, challenging handling of data, possible high trust in computers and software, and ethics.}
}
@article{SILVA2019101880,
title = {A congestion control framework for delay- and disruption tolerant networks},
journal = {Ad Hoc Networks},
volume = {91},
pages = {101880},
year = {2019},
issn = {1570-8705},
doi = {https://doi.org/10.1016/j.adhoc.2019.101880},
url = {https://www.sciencedirect.com/science/article/pii/S1570870518301288},
author = {Aloizio P. Silva and Katia Obraczka and Scott Burleigh and José M.S. Nogueira and Celso M. Hirata},
keywords = {Delay and disruption tolerant networks, Interplanetary networks, Congestion control, Intermittent connectivity},
abstract = {Delay and Disruption Tolerant Networks (DTNs) are networks that experience frequent and long-lived connectivity disruptions. Unlike traditional networks, such as TCP/IP Internet, DTNs are often subject to high latency caused by very long propagation delays (e.g., interplanetary communication) and/or intermittent connectivity. In DTNs there is no guarantee of end-to-end connectivity between source and destination. Such distinct features pose a number of technical challenges in designing core network functions such as routing and congestion control mechanisms. Detecting and dealing with congestion in DTNs is an important problem since congestion can significantly deteriorate DTN performance. Most existing DTN congestion control mechanisms have been designed for a specific DTN application domain and have been shown to exhibit inadequate performance when used in different DTN scenarios and conditions. In this paper, we introduce Smart-DTN-CC, a novel DTN congestion control framework that adjusts its operation automatically based on the dynamics of the underlying network and its nodes. Smart-DTN-CC is an adaptive and distributed congestion aware framework that mitigates congestion using reinforcement learning, a machine learning technique known to be well suited to problems where: (1) the environment, in this case the network, plays a crucial role; and (2) yet, no prior knowledge about the target environment can be assumed, i.e., the only way to acquire information about the environment is to interact with it through continuous online learning. Smart-DTN-CC nodes receive input from the environment (e.g., buffer occupancy, neighborhood membership, etc), and, based on that information, choose an action to take from a set of possible actions. Depending on the selected action’s effectiveness in controlling congestion, a reward will be given. Smart-DTN-CC’s goal is to maximize the overall reward which translates to minimizing congestion. To our knowledge, Smart-DTN-CC is the first DTN congestion control framework that has the ability to automatically and continuously adapt to the dynamics of the target environment. As demonstrated by our experimental evaluation, Smart-DTN-CC is able to consistently outperform existing DTN congestion control mechanisms under a wide range of network conditions and characteristics.}
}
@article{JIN2020106730,
title = {Urban Fire Situation Forecasting: Deep sequence learning with spatio-temporal dynamics},
journal = {Applied Soft Computing},
volume = {97},
pages = {106730},
year = {2020},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2020.106730},
url = {https://www.sciencedirect.com/science/article/pii/S1568494620306682},
author = {Guangyin Jin and Qi Wang and Cunchao Zhu and Yanghe Feng and Jincai Huang and Xingchen Hu},
keywords = {Fire Situation Forecasting, Information fusion, Variational Auto-Encoder, Sequence generation, Spatio-temporal analysis},
abstract = {Understanding the evolving discipline of urban fire situations is a basic but challenging task for urban security and fire-fighting decisions. Traditional methods forecast the urban fire situation through mathematical modeling and statistical learning, which could be interpretable but generally lack of efficiency and practicality. Recently, some deep neural network methodologies, especially convolutional neural network (CNN) and recurrent neural network (RNN), are presented as paradigms to capture dynamics in spatial–temporal complex phenomenon, which tally with the characteristics of fire situation forecasting. In this paper, we propose a novel deep sequence learning model as the fire situation forecasting network (FSFN) to better process the information and spatio-temporal correlations in regional urban fire alarm dataset. FSFN model integrates structures of Variational auto-encoders and context-based sequence generative model Seq2seq to obtain the latent representation of the fire situation and learn the spatio-temporal dynamics. Furthermore, we augment the network structure of FSFN from a simple deep sequence generative model to adversarial fire situation forecasting network with auxiliary information(Adversarial FSFN-A). The experimental studies demonstrate the effectiveness of Adversarial FSFN-A has superior spatio-temporal distribution prediction of multi-type urban fire situation.}
}
@article{CLUNNEKIELY20172249,
title = {Modelling and Implementation of Humanoid Robot Behaviour},
journal = {Procedia Computer Science},
volume = {112},
pages = {2249-2258},
year = {2017},
note = {Knowledge-Based and Intelligent Information & Engineering Systems: Proceedings of the 21st International Conference, KES-20176-8 September 2017, Marseille, France},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2017.08.137},
url = {https://www.sciencedirect.com/science/article/pii/S1877050917314941},
author = {Leroy Clunne-Kiely and Bijin Idicula and Luke Payne and Enrico Ronggowarsito and Maria Spichkova and Milan Simic and Heinrich Schmidt},
keywords = {Intelligent Mobile Robots, Modelling, Smart City, REEM},
abstract = {This paper presents an approach for modelling and implementation of autonomous humanoid system’s behaviour. The main objective of our project was to analyse possible interaction scenarios between humans and autonomous robots, and to elaborate a framework for providing flexible guided tour options, utilising the features of humanoid PAL REEM robot. The framework can be used to support guided tours through exhibitions, museums, art centres, innovative labs, etc. We introduce the core results of the project and briefly discuss our future work. There are many scenarios where humans interactively conduct some joint activities. Using our approach, presented here, one of the parties could be replaced by humanoid robots. State of the art technology in voice recognition and generation, as well as path planning were used to achieve requested research objectives.}
}
@article{PAN2016171,
title = {Urban Big Data and the Development of City Intelligence},
journal = {Engineering},
volume = {2},
number = {2},
pages = {171-178},
year = {2016},
issn = {2095-8099},
doi = {https://doi.org/10.1016/J.ENG.2016.02.003},
url = {https://www.sciencedirect.com/science/article/pii/S2095809916309456},
author = {Yunhe Pan and Yun Tian and Xiaolong Liu and Dedao Gu and Gang Hua},
keywords = {Urban big data, City intelligence, Ternary space, Construction emphases},
abstract = {ABSTRACT
This study provides a definition for urban big data while exploring its features and applications of China's city intelligence. The differences between city intelligence in China and the “smart city” concept in other countries are compared to highlight and contrast the unique definition and model for China's city intelligence in this paper. Furthermore, this paper examines the role of urban big data in city intelligence by showing that it not only serves as the cornerstone of this trend as it also plays a core role in the diffusion of city intelligence technology and serves as an inexhaustible resource for the sustained development of city intelligence. This study also points out the challenges of shaping and developing of China's urban big data. Considering the supporting and core role that urban big data plays in city intelligence, the study then expounds on the key points of urban big data, including infrastructure support, urban governance, public services, and economic and industrial development. Finally, this study points out that the utility of city intelligence as an ideal policy tool for advancing the goals of China's urban development. In conclusion, it is imperative that China make full use of its unique advantages—including using the nation's current state of development and resources, geographical advantages, and good human relations—in subjective and objective conditions to promote the development of city intelligence through the proper application of urban big data.}
}
@article{ZHANG2021189,
title = {V-LPDR: Towards a unified framework for license plate detection, tracking, and recognition in real-world traffic videos},
journal = {Neurocomputing},
volume = {449},
pages = {189-206},
year = {2021},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2021.03.103},
url = {https://www.sciencedirect.com/science/article/pii/S0925231221004951},
author = {Cong Zhang and Qi Wang and Xuelong Li},
keywords = {License plate detection, License plate recognition, Deep learning},
abstract = {License plate detection and recognition (LPDR) has attracted considerable attention in recent years, and many algorithms have presented the competitive performance on several datasets. However, there are still three significant issues to be addressed in this field. Firstly, most methods have poor detection performance in unconstrained scenarios with moving vehicles and highly distracting background objects. Secondly, existing systems generally focus on single image-based algorithms, yet traffic video sequences provide more effective information than individual frames for LPDR tasks. Thirdly, images and videos captured in complex environments may be adversely affected by distortions and low resolution, causing sensitive recognition performance and reduced robustness. To remedy these issues, we propose to automatically perform license plate detection, tracking, and recognition in real-world traffic videos and integrate them into a unified end-to-end framework via deep learning. The contributions of this paper are threefold: 1) A deep flow-guided spatiotemporal license plate detector is proposed to model the video contextual information by introducing optical flow and a novel spatiotemporal attention mechanism; 2) An online license plate tracker is developed to bridge video-based detection and recognition which utilizes both motion and deep appearance information, and innovatively, it can be end-to-end trained with the detector via multi-task learning; 3) The efficient quality-guided license plate recommender and recognizer are proposed to jointly perform stream recognition. The former recommends high-quality frames from video streams while the latter generates recognition results. We evaluate the proposed method on three traffic video-based license plate datasets, and ablation studies have been presented to verify the effectiveness of each component mentioned above. Moreover, extensive experiments are conducted for comparison with other approaches in different scenarios, and the results have demonstrated that our method achieves state-of-the-art performance on all datasets.}
}
@article{CAMPOS2022108661,
title = {Evaluating Federated Learning for intrusion detection in Internet of Things: Review and challenges},
journal = {Computer Networks},
volume = {203},
pages = {108661},
year = {2022},
issn = {1389-1286},
doi = {https://doi.org/10.1016/j.comnet.2021.108661},
url = {https://www.sciencedirect.com/science/article/pii/S1389128621005405},
author = {Enrique Mármol Campos and Pablo Fernández Saura and Aurora González-Vidal and José L. Hernández-Ramos and Jorge Bernal Bernabé and Gianmarco Baldini and Antonio Skarmeta},
keywords = {Internet of Things, Federated Learning, Intrusion detection systems},
abstract = {The application of Machine Learning (ML) techniques to the well-known intrusion detection systems (IDS) is key to cope with increasingly sophisticated cybersecurity attacks through an effective and efficient detection process. In the context of the Internet of Things (IoT), most ML-enabled IDS approaches use centralized approaches where IoT devices share their data with data centers for further analysis. To mitigate privacy concerns associated with centralized approaches, in recent years the use of Federated Learning (FL) has attracted a significant interest in different sectors, including healthcare and transport systems. However, the development of FL-enabled IDS for IoT is in its infancy, and still requires research efforts from various areas, in order to identify the main challenges for the deployment in real-world scenarios. In this direction, our work evaluates a FL-enabled IDS approach based on a multiclass classifier considering different data distributions for the detection of different attacks in an IoT scenario. In particular, we use three different settings that are obtained by partitioning the recent ToN_IoT dataset according to IoT devices’ IP address and types of attack. Furthermore, we evaluate the impact of different aggregation functions according to such setting by using the recent IBMFL framework as FL implementation. Additionally, we identify a set of challenges and future directions based on the existing literature and the analysis of our evaluation results.}
}
@article{PAN2021103517,
title = {Roles of artificial intelligence in construction engineering and management: A critical review and future trends},
journal = {Automation in Construction},
volume = {122},
pages = {103517},
year = {2021},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2020.103517},
url = {https://www.sciencedirect.com/science/article/pii/S0926580520310979},
author = {Yue Pan and Limao Zhang},
keywords = {Artificial intelligence, Construction engineering and management, Critical review},
abstract = {With the extensive adoption of artificial intelligence (AI), construction engineering and management (CEM) is experiencing a rapid digital transformation. Since AI-based solutions in CEM has become the current research focus, it needs to be comprehensively understood. In this regard, this paper presents a systematic review under both scientometric and qualitative analysis to present the current state of AI adoption in the context of CEM and discuss its future research trends. To begin with, a scientometric review is performed to explore the characteristics of keywords, journals, and clusters based on 4,473 journal articles published in 1997–2020. It is found that there has been an explosion of relevant papers especially in the past 10 years along with the change in keyword popularity from expert systems to building information modeling (BIM), digital twins, and others. Then, a brief understanding of CEM is provided, which can be benefited from the emerging trend of AI in terms of automation, risk mitigation, high efficiency, digitalization, and computer vision. Special concerns have been put on six hot research topics that amply the advantage of AI in CEM, including (1) knowledge representation and reasoning, (2) information fusion, (3) computer vision, (4) natural language processing, (5) intelligence optimization, and (6) process mining. The goal of these topics is to model, predict, and optimize issues in a data-driven manner throughout the whole lifecycle of the actual complex project. To further narrow the gap between AI and CEM, six key directions of future researches, such as smart robotics, cloud virtual and augmented reality (cloud VR/AR), Artificial Intelligence of Things (AIoT), digital twins, 4D printing, and blockchains, are highlighted to constantly facilitate the automation and intelligence in CEM.}
}
@article{KALFA2021103134,
title = {Towards goal-oriented semantic signal processing: Applications and future challenges},
journal = {Digital Signal Processing},
volume = {119},
pages = {103134},
year = {2021},
issn = {1051-2004},
doi = {https://doi.org/10.1016/j.dsp.2021.103134},
url = {https://www.sciencedirect.com/science/article/pii/S1051200421001731},
author = {Mert Kalfa and Mehmetcan Gok and Arda Atalik and Busra Tegin and Tolga M. Duman and Orhan Arikan},
keywords = {Semantic signal processing, Graph-based languages, Semantic communications, Goal-oriented communications},
abstract = {Advances in machine learning technology have enabled real-time extraction of semantic information in signals which can revolutionize signal processing techniques and improve their performance significantly for the next generation of applications. With the objective of a concrete representation and efficient processing of the semantic information, we propose and demonstrate a formal graph-based semantic language and a goal filtering method that enables goal-oriented signal processing. The proposed semantic signal processing framework can easily be tailored for specific applications and goals in a diverse range of signal processing applications. To illustrate its wide range of applicability, we investigate several use cases and provide details on how the proposed goal-oriented semantic signal processing framework can be customized. We also investigate and propose techniques for communications where sensor data is semantically processed and semantic information is exchanged across a sensor network.}
}
@article{KENYON2020102022,
title = {Are public intrusion datasets fit for purpose characterising the state of the art in intrusion event datasets},
journal = {Computers & Security},
volume = {99},
pages = {102022},
year = {2020},
issn = {0167-4048},
doi = {https://doi.org/10.1016/j.cose.2020.102022},
url = {https://www.sciencedirect.com/science/article/pii/S0167404820302959},
author = {A. Kenyon and L. Deka and D. Elizondo},
keywords = {Intrusion dataset, Intrusion detection, Anomaly detection, Intrusion prevention, Ddos, Malware, Netfow, Masquerade, nids},
abstract = {In recent years cybersecurity attacks have caused major disruption and information loss for online organisations, with high profile incidents in the news. One of the key challenges in advancing the state of the art in intrusion detection is the lack of representative datasets. These datasets typically contain millions of time-ordered events (e.g. network packet traces, flow summaries, log entries); subsequently analysed to identify abnormal behavior and specific attacks (Duffield et al., April). Generating realistic datasets has historically required expensive networked assets, specialised traffic generators, and considerable design preparation. Even with advances in virtualisation it remains challenging to create and maintain a representative environment. Major improvements are needed in the design, quality and availability of datasets, to assist researchers in developing advanced detection techniques. With the emergence of new technology paradigms, such as intelligent transport and autonomous vehicles, it is also likely that new classes of threat will emerge (Kenyon, 2018). Given the rate of change in threat behavior (Ugarte-Pedrero et al., 2019) datasets become quickly obsolete, and some of the most widely cited datasets date back over two decades. Older datasets have limited value: often heavily filtered and anonymised, with unrealistic event distributions, and opaque design methodology. The relative scarcity of (Intrusion Detection System) IDS datasets is compounded by the lack of a central registry, and inconsistent information on provenance. Researchers may also find it hard to locate datasets or understand their relative merits. In addition, many datasets rely on simulation, originating from academic or government institutions. The publication process itself often creates conflicts, with the need to de-identify sensitive information in order to meet regulations such as General Data Protection Act (GDPR) (Regulation, 2016). Another final issue for researchers is the lack of standardised metrics with which to compare dataset quality. In this paper we attempt to classify the most widely used public intrusion datasets, providing references to archives and associated literature. We illustrate their relative utility and scope, highlighting the threat composition, formats, special features, and associated limitations. We identify best practice in dataset design, and describe potential pitfalls of designing anomaly detection techniques based on data that may be either inappropriate, or compromised due to unrealistic threat coverage. Such contributions as made in this paper is expected to facilitate continuous research and development for effectively combating the constantly evolving cyber threat landscape. CCS CONCEPTS Intrusion Detection;Intrusion Prevention; Anomaly Detection; Network Flow; Smart Cities}
}
@article{SUNHARE2020,
title = {Internet of things and data mining: An application oriented survey},
journal = {Journal of King Saud University - Computer and Information Sciences},
year = {2020},
issn = {1319-1578},
doi = {https://doi.org/10.1016/j.jksuci.2020.07.002},
url = {https://www.sciencedirect.com/science/article/pii/S131915782030416X},
author = {Priyank Sunhare and Rameez R. Chowdhary and Manju K. Chattopadhyay},
keywords = {Internet of things, Data mining, Big data, Smart home, Ambient assistant living, Smart healthcare, Smart grid, Industrial IoT, Smart manufacturing, Smart agriculture, Smart transportation},
abstract = {Advancement in the fields of electronic communication, data processing, and internet technologies enable easy access to and interaction with a variety of physical devices throughout the globe. Our whole world is enveloped by a blanket of innumerable smart devices equipped with the sensors and actuators. Extensive research on the Internet of things (IoT) with cloud technologies, make it possible to accumulate tremendous data created from this heterogeneous environment and transform it into precious knowledge by utilizing data mining technologies. Furthermore, this generated knowledge will play a key role in intelligent decision making, system performance boosting, and optimum management of resources and services. With this background, this paper presents a systematic and detailed review of various data mining techniques employed in the large and small scale IoT applications to formulate an intelligent environment. It also presents an overview of cloud-assisted IoT Big data mining system to better understand the importance of data mining for an IoT environment.}
}
@article{BEZAI202165,
title = {Future cities and autonomous vehicles: analysis of the barriers to full adoption},
journal = {Energy and Built Environment},
volume = {2},
number = {1},
pages = {65-81},
year = {2021},
issn = {2666-1233},
doi = {https://doi.org/10.1016/j.enbenv.2020.05.002},
url = {https://www.sciencedirect.com/science/article/pii/S2666123320300398},
author = {Nacer Eddine Bezai and Benachir Medjdoub and Amin Al-Habaibeh and Moulay Larbi Chalal and Fodil Fadli},
keywords = {autonomous vehicles, smart city, barriers, safety, technology, users' behaviour},
abstract = {The inevitable upcoming technology of autonomous vehicles (AVs) will affect our cities and several aspects of our lives. The widespread adoption of AVs repose at crossing distinct barriers that prevent their full adoption. This paper presents a critical review of recent debates about AVs and analyse the key barriers to their full adoption. This study has employed a mixed research methodology on a selected database of recently published research works. Thus, the outcomes of this review integrate the barriers into two main categories; (1) User/Government perspectives that include (i) Users' acceptance and behaviour, (ii) Safety, and (iii) Legislation. (2) Information and Communication Technologies (ICT) which include (i) Computer software and hardware, (ii) Communication systems V2X, and (iii) accurate positioning and mapping. Furthermore, a framework of barriers and their relations to AVs system architecture has been suggested to support future research and technology development.}
}
@article{ABID2021108583,
title = {A survey on recent contention-free MAC protocols for static and mobile wireless decentralized networks in IoT},
journal = {Computer Networks},
volume = {201},
pages = {108583},
year = {2021},
issn = {1389-1286},
doi = {https://doi.org/10.1016/j.comnet.2021.108583},
url = {https://www.sciencedirect.com/science/article/pii/S1389128621004886},
author = {Khaled Abid and Hicham Lakhlef and Abdelmadjid Bouabdallah},
keywords = {IoT, Wireless networks, Decentralized network, Communicating things, MANET, VANET, FANET, UAV, Slot-access, Contention-free, Medium Access Control, TDMA, FDMA, Network mobility, Distributed learning, Game theory, Self-organizing network, Delay tolerant network},
abstract = {Medium Access Control (MAC) protocols for wireless decentralized networks in IoT have attracted a lot of attention in both academic and industrial fields. They aim to coordinate access among IoT devices to the shared wireless medium. More specifically, contention-free MAC protocols are known to be more efficient than contention-based ones in the case of high traffic load and dense networks. To face the main communication challenges between IoT devices such as collisions and conflicts as well as mobility, it is crucial to design an efficient MAC protocol. To do so, several solutions have been proposed in the literature. Among recent proposed solutions, Machine Learning (ML) algorithms and game theory models were used to revolutionize the communication in IoT networks, especially for devices with high mobility degree. In our survey, we first start by studying the challenges and requirements of communication in wireless networks. Then, we provide a comprehensive survey on recent contention-free MAC protocols existing in the literature. Next, we compare these solutions based on important metrics such as QoS, robustness, fairness etc., and discuss the relationship between MAC protocols, network type and network mobility. Finally, we investigate a future research direction to solve a major problem, which is the network disruption and delay tolerance in IoT wireless mobile networks.}
}
@article{IZONIN201911,
title = {An Approach towards Missing Data Recovery within IoT Smart System},
journal = {Procedia Computer Science},
volume = {155},
pages = {11-18},
year = {2019},
note = {The 16th International Conference on Mobile Systems and Pervasive Computing (MobiSPC 2019),The 14th International Conference on Future Networks and Communications (FNC-2019),The 9th International Conference on Sustainable Energy Information Technology},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2019.08.006},
url = {https://www.sciencedirect.com/science/article/pii/S1877050919309184},
author = {Ivan Izonin and Natalia Kryvinska and Roman Tkachenko and Khrystyna Zub},
keywords = {missing data, recovery gaps, IoT systems, machine learning, service science, AbaBoost, Ito decomposition},
abstract = {Today, the fast development of the hardware for the Internet of things systems creates conditions for the development of IoT based Services of various purposes. The imperfect systems of collecting, aggregation and the transmission of large volumes of various types of data, fixed by sensors of IoT devices, as well as possible failures of the latter, cause the occurrence of missing data problems. The paper proposes a regression approach to solving the task of missed data recovery. The authors have developed a composition of the method of the missing data recovery for IoT systems based on the use of the Ito decomposition and the AdaBoost algorithm. We transform each data vectors by using Ito decomposition, and searching the coefficients of this decomposition scheme using AdaBoost algorithm. Increasing the dimensionality of the input space due to the use of the second-degree Ito decomposition scheme, as well as its high approximation properties, allowed to increase the accuracy of filling the missed values by the AdaBoost regressor at more than 6% (MAPE). It has been established that the developed method provides the highest accuracy of filling missed data based on all other indicators (MAE, RMSE, SMAPE) among the considered regression methods.}
}
@article{ULLAH2021321,
title = {Conflux LSTMs Network: A Novel Approach for Multi-View Action Recognition},
journal = {Neurocomputing},
volume = {435},
pages = {321-329},
year = {2021},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2019.12.151},
url = {https://www.sciencedirect.com/science/article/pii/S0925231220317860},
author = {Amin Ullah and Khan Muhammad and Tanveer Hussain and Sung Wook Baik},
keywords = {Artificial intelligence, Deep learning, Action recognition, Multi-view video analytics, Sequence learning, LSTM, CNN, Multi-view action recognition},
abstract = {Multi-view action recognition (MVAR) is an optimal technique to acquire numerous clues from different views data for effective action recognition, however, it is not well explored yet. There exist several challenges to MVAR domain such as divergence in viewpoints, invisible regions, and different scales of appearance in each view require better solutions for real world applications. In this paper, we present a conflux long short-term memory (LSTMs) network to recognize actions from multi-view cameras. The proposed framework has four major steps; 1) frame level feature extraction, 2) its propagation through conflux LSTMs network for view self-reliant patterns learning, 3) view inter-reliant patterns learning and correlation computation, and 4) action classification. First, we extract deep features from a sequence of frames using a pre-trained VGG19 CNN model for each view. Second, we forward the extracted features to conflux LSTMs network to learn the view self-reliant patterns. In the next step, we compute the inter-view correlations using the pairwise dot product from output of the LSTMs network corresponding to different views to learn the view inter-reliant patterns. In the final step, we use flatten layers followed by SoftMax classifier for action recognition. Experimental results over benchmark datasets compared to state-of-the-art report an increase of 3% and 2% on northwestern-UCLA and MCAD datasets, respectively.}
}
@article{NEX2022215,
title = {UAV in the advent of the twenties: Where we stand and what is next},
journal = {ISPRS Journal of Photogrammetry and Remote Sensing},
volume = {184},
pages = {215-242},
year = {2022},
issn = {0924-2716},
doi = {https://doi.org/10.1016/j.isprsjprs.2021.12.006},
url = {https://www.sciencedirect.com/science/article/pii/S0924271621003282},
author = {F. Nex and C. Armenakis and M. Cramer and D.A. Cucci and M. Gerke and E. Honkavaara and A. Kukko and C. Persello and J. Skaloud},
keywords = {UAV, Photogrammetry, LiDAR, Deep learning, Hyperspectral, Remote sensing, Sensors, Data processing, Navigation},
abstract = {The use of Unmanned Aerial Vehicles (UAVs) has surged in the last two decades, making them popular instruments for a wide range of applications, and leading to a remarkable number of scientific contributions in geoscience, remote sensing and engineering. However, the development of best practices for high quality of UAV mapping are often overlooked representing a drawback for their wider adoption. UAV solutions then require an inter-disciplinary research, integrating different expertise and combining several hardware and software components on the same platform. Despite the high number of peer-reviewed papers on UAVs, little attention has been given to the interaction between research topics from different domains (such as robotics and computer vision) that impact the use of UAV in remote sensing. The aim of this paper is to (i) review best practices for the use of UAVs for remote sensing and mapping applications and (ii) report on current trends - including adjacent domains - for UAV use and discuss their future impact in photogrammetry and remote sensing. Hardware developments, navigation and acquisition strategies, and emerging solutions for data processing in innovative applications are considered in this analysis. As the number and the heterogeneity of debated topics are large, the paper is organized according to very specific questions considered most relevant by the authors.}
}
@article{XIE2016119,
title = {A new variance-based approach for discriminative feature extraction in machine hearing classification using spectrogram features},
journal = {Digital Signal Processing},
volume = {54},
pages = {119-128},
year = {2016},
issn = {1051-2004},
doi = {https://doi.org/10.1016/j.dsp.2016.04.005},
url = {https://www.sciencedirect.com/science/article/pii/S1051200416300203},
author = {Zhipeng Xie and Ian McLoughlin and Haomin Zhang and Yan Song and Wei Xiao},
keywords = {Machine hearing, Auditory event detection, Robust auditory classification, Sound classification, Discriminative sound features},
abstract = {Machine hearing is an emerging research field that is analogous to machine vision in that it aims to equip computers with the ability to hear and recognise a variety of sounds. It is a key enabler of natural human–computer speech interfacing, as well as in areas such as automated security surveillance, environmental monitoring, smart homes/buildings/cities. Recent advances in machine learning allow current systems to accurately recognise a diverse range of sounds under controlled conditions. However doing so in real-world noisy conditions remains a challenging task. Several front–end feature extraction methods have been used for machine hearing, employing speech recognition features like MFCC and PLP, as well as image-like features such as AIM and SIF. The best choice of feature is found to be dependent upon the noise environment and machine learning techniques used. Machine learning methods such as deep neural networks have been shown capable of inferring discriminative classification rules from less structured front–end features in related domains. In the machine hearing field, spectrogram image features have recently shown good performance for noise-corrupted classification using deep neural networks. However there are many methods of extracting features from spectrograms. This paper explores a novel data-driven feature extraction method that uses variance-based criteria to define spectral pooling of features from spectrograms. The proposed method, based on maximising the pooled spectral variance of foreground and background sound models, is shown to achieve very good performance for robust classification.}
}
@article{CHEN201859,
title = {Deep mobile traffic forecast and complementary base station clustering for C-RAN optimization},
journal = {Journal of Network and Computer Applications},
volume = {121},
pages = {59-69},
year = {2018},
issn = {1084-8045},
doi = {https://doi.org/10.1016/j.jnca.2018.07.015},
url = {https://www.sciencedirect.com/science/article/pii/S1084804518302455},
author = {Longbiao Chen and Dingqi Yang and Daqing Zhang and Cheng Wang and Jonathan Li and Thi-Mai-Trang Nguyen},
keywords = {Deep learning, Mobile network, Big data analytics, C-RAN},
abstract = {The increasingly growing data traffic has posed great challenges for mobile operators to increase their data processing capacity, which incurs a significant energy consumption and deployment cost. With the emergence of the Cloud Radio Access Network (C-RAN) architecture, the data processing units can now be centralized in data centers and shared among base stations. By mapping a cluster of base stations with complementary traffic patterns to a data processing unit, the processing unit can be fully utilized in different periods of time, and the required capacity to be deployed is expected to be smaller than the sum of capacities of single base stations. However, since the traffic patterns of base stations are highly dynamic in different time and locations, it is challenging to foresee and characterize the traffic patterns in advance to make optimal clustering schemes. In this paper, we address these issues by proposing a deep-learning-based C-RAN optimization framework. First, we exploit a Multivariate Long Short-Term Memory (MuLSTM) model to learn the temporal dependency and spatial correlation among base station traffic patterns, and make accurate traffic forecast for a future period of time. Afterwards, we build a weighted graph to model the complementarity of base stations according to their traffic patterns, and propose a Distance-Constrained Complementarity-Aware (DCCA) algorithm to find optimal base station clustering schemes with the objectives of optimizing capacity utility and deployment cost. We evaluate the performance of our framework using data in two months from real-world mobile networks in Milan and Trentino, Italy. Results show that our method effectively increases the average capacity utility to 83.4% and 76.7%, and reduces the overall deployment cost to 48.4% and 51.7% of the traditional RAN architecture in the two datasets, respectively, which consistently outperforms the state-of-the-art baseline methods.}
}
@article{DHARMADHIKARI2021103954,
title = {A smart grid incorporated with ML and IoT for a secure management system},
journal = {Microprocessors and Microsystems},
volume = {83},
pages = {103954},
year = {2021},
issn = {0141-9331},
doi = {https://doi.org/10.1016/j.micpro.2021.103954},
url = {https://www.sciencedirect.com/science/article/pii/S0141933121001332},
author = {S.C. Dharmadhikari and Veerraju Gampala and Ch. Mallikarjuna Rao and Syed Khasim and Shafali Jain and R. Bhaskaran},
keywords = {Demand side management (DSM), Machine learning (ML), Smart grid (SG), Internet of Things (IoT), Home area network (HAN)},
abstract = {The economy, national safety, and health care are tremendously dependent on the faithful supply of power. The communication technology integration and sensors in power systems have been authorized as a smart grid (SG) that is revolutionizing the model of power generation, distribution, monitoring, and control. To know the Smart Grid compatibility, many problems are required to be directed. The safety of the smart grid is the most challenging function and very crucial difficulties. This paper proposed, a safe demand-side management machine deploying machine learning for the Internet of Things authorized phase is recommended. The propounded demand-side management (DSM) machine protects the effective energy use based on their preferences. A particular flexibility sample was proposed to manage incursion into the smart grid. Anelastic agent prognosticates swindling companies, the ML classifiers are utilized. Promoted power management and intermediate control companies are recommended for processing power data to improve energy usage. The proposed project's effective simulation is implemented to examine the efficiency. The outcome of the analysis discloses that the planned demand-side management (DSM) machine is less susceptible to the incursion and it is sufficient to decrease the smart grid's energy consumption.}
}
@article{GHOSH2021100242,
title = {Developing sensor signal-based digital twins for intelligent machine tools},
journal = {Journal of Industrial Information Integration},
volume = {24},
pages = {100242},
year = {2021},
issn = {2452-414X},
doi = {https://doi.org/10.1016/j.jii.2021.100242},
url = {https://www.sciencedirect.com/science/article/pii/S2452414X21000418},
author = {Angkush Kumar Ghosh and AMM Sharif Ullah and Roberto Teti and Akihiko Kubo},
keywords = {Digital twin, Sensor signal, Cyber-physical systems, Machine tool, Monitoring},
abstract = {Digital twins can assist machine tools in performing their monitoring and troubleshooting tasks autonomously from the context of smart manufacturing. For this, a special type of twin denoted as sensor signal-based twin must be constructed and adapted into the cyber-physical systems. The twin must (1) machine-learn the required knowledge from the historical sensor signal datasets, (2) seamlessly interact with the real-time sensor signals, (3) handle the semantically annotated datasets stored in clouds, and (4) accommodate the data transmission delay. The development of such twins has not yet been studied in detail. This study fills this gap by addressing sensor signal-based digital twin development for intelligent machine tools. Two computerized systems denoted as Digital Twin Construction System (DTCS) and Digital Twin Adaptation System (DTAS) are proposed to construct and adapt the twin, respectively. The modular architectures of the proposed DTCS and DTAS are presented in detail. The real-time responses and delay-related computational arrangements are also elucidated for both systems. The systems are also developed using a Java™-based platform. Milling torque signals are used as an example to demonstrate the efficacy of DTCS and DTAS. This study thus contributes toward the advancement of intelligent machine tools from the context of smart manufacturing.}
}
@article{LIU2021102532,
title = {Detecting home countries of social media users with machine-learned ranking approach: A case study in Hong Kong},
journal = {Applied Geography},
volume = {134},
pages = {102532},
year = {2021},
issn = {0143-6228},
doi = {https://doi.org/10.1016/j.apgeog.2021.102532},
url = {https://www.sciencedirect.com/science/article/pii/S014362282100148X},
author = {Zhewei Liu and Wenzhong Shi and Anshu Zhang},
keywords = {Home country detection, Human mobility, Spatial data mining},
abstract = {Inferring individual's home country from geotagged footprints is widely applied in human mobility research. Previous studies mainly used simple empirical methods that are based on intuitive hypothetical assumptions. Because the exact relationships between users' home countries and geotagged footprints haven't be quantitatively revealed, empirical methods based on human intuitions and past experiences are used for rough approximation. In this study, we propose a machine-learning approach for the task of home country detection, by formulating the task as a query-ranking problem and using a machine-learned ranking model for problem solving. The used model is a Multiple Additive Regression Trees framework that aims to rank regions in specific orders and the region ranked first is designated as the home country. Our approach is data-driven and can adaptively learn the unknown function from input (geotagged footprints) to output (user's home country), thus alleviating the bias introduced by previous empirical methods. We conduct experiments with real-world datasets, and results demonstrate that our approach achieves better performance than previous empirical methods. The model's parameter sensitivity is also investigated, and results show that user's origin may be a factor affecting the approach's performance and that our approach achieves robust good performance with various parameter settings.}
}
@article{LIONO2019196,
title = {QDaS: Quality driven data summarisation for effective storage management in Internet of Things},
journal = {Journal of Parallel and Distributed Computing},
volume = {127},
pages = {196-208},
year = {2019},
issn = {0743-7315},
doi = {https://doi.org/10.1016/j.jpdc.2018.03.013},
url = {https://www.sciencedirect.com/science/article/pii/S074373151830220X},
author = {Jonathan Liono and Prem Prakash Jayaraman and A.K. Qin and Thuong Nguyen and Flora D. Salim},
keywords = {Quality of data, Storage management, Internet of Things (IoT), Cloud computing, Quality of service, Data summarisation},
abstract = {The proliferation of Internet of Things (IoT) has led to the emergence of enabling many interesting applications within the realm of several domains including smart cities. However, the accumulation of data from smart IoT devices poses significant challenges for data storage while there are needs to deliver relevant and high quality services to consumers. In this paper, we propose QDaS, a novel domain agnostic framework as a solution for effective data storage and management of IoT applications. The framework incorporates a novel data summarisation mechanism that uses an innovative data quality estimation technique. This proposed data quality estimation technique computes the quality of data (based on their utility) without requiring any feedback from users of this IoT data or domain awareness of the data. We evaluate the effectiveness of the proposed QDaS framework using real world datasets.}
}
@article{GONZALEZRAMIREZ2021107745,
title = {IoT-networks group-based model that uses AI for workgroup allocation},
journal = {Computer Networks},
volume = {186},
pages = {107745},
year = {2021},
issn = {1389-1286},
doi = {https://doi.org/10.1016/j.comnet.2020.107745},
url = {https://www.sciencedirect.com/science/article/pii/S1389128620313293},
author = {Pedro Luis {González Ramírez} and Jaime Lloret and Jesús Tomás and Mikel Hurtado},
keywords = {IoT, IoT-smart architecture, IoT-gateway, M2M protocols, ML classifiers, Collaborative workgroups, Network model, Graph theory, Smart IoT-networks},
abstract = {This paper presents a centralized management architecture model for designing workgroup-based Internet of Things (IoT) and Internet of Everything (IoE) networks. The architecture establishes the organization of an object according to its functions and capacities in layers. From its model, it is derived the design of the algorithms that give the network operation. These algorithms include the multi-protocol communication and interconnectivity algorithm, the routing algorithm, the resource sharing algorithm, and the grouping algorithm, all controlled by Artificial Intelligence (AI). The grouping algorithm consists of creating collaborative workgroups based on Machine Learning (ML) techniques that use the objects’ features to allocating these within a workgroup that attends a type of service and within an architecture layer according to its capabilities. The model was tested with a simulation that shows the Machine-to-Machine (M2M) interaction between the devices involved in providing a service to a user within a Smart Home. This simulation uses an AI hosted within an IoT-Gateway to collect data on the features that define a connected object's functions and services. The extraction of the features is done using the Discovery of Functions and Services Protocol (DFSP) transported through an IoT-Protocol. With this information, the AI assigns a layer and a workgroup to a new object when it enters the network. The result of these tests can be used to know which ML technique has better accuracy.}
}
@article{BIBRI2017183,
title = {Smart sustainable cities of the future: An extensive interdisciplinary literature review},
journal = {Sustainable Cities and Society},
volume = {31},
pages = {183-212},
year = {2017},
issn = {2210-6707},
doi = {https://doi.org/10.1016/j.scs.2017.02.016},
url = {https://www.sciencedirect.com/science/article/pii/S2210670716304073},
author = {Simon Elias Bibri and John Krogstie},
keywords = {Smart cities, Sustainable cities, Smart sustainable cities, Sustainable urban forms, Urban sustainability, Sustainable development goals, ICT, Computing, Planning, Big data analytics},
abstract = {In recent years, the concept of smart sustainable cities has come to the fore. And it is rapidly gaining momentum and worldwide attention as a promising response to the challenge of urban sustainability. This pertains particularly to ecologically and technologically advanced nations. This paper provides a comprehensive overview of the field of smart (and) sustainable cities in terms of its underlying foundations and assumptions, state–of–the art research and development, research opportunities and horizons, emerging scientific and technological trends, and future planning practices. As to the design strategy, the paper reviews existing sustainable city models and smart city approaches. Their strengths and weaknesses are discussed with particular emphasis being placed on the extent to which the former contributes to the goals of sustainable development and whether the latter incorporates these goals. To identify the related challenges, those models and approaches are evaluated and compared against each other in line with the notion of sustainability. The gaps in the research within the field of smart sustainable cities are identified in accordance with and beyond the research being proposed. As a result, an integrated approach is proposed based on an applied theoretical perspective to align the existing problems and solutions identification for future practices in the area of smart sustainable urban planning and development. As to the findings, the paper shows that critical issues remain unsettled, less explored, largely ignored, and theoretically underdeveloped for applied purposes concerning existing models of sustainable urban form as to their contribution to sustainability, among other things. It also reveals that numerous research opportunities are available and can be realized in the realm of smart sustainable cities. Our perspective on the topic in this regard is to develop a theoretically and practically convincing model of smart sustainable city or a framework for strategic smart sustainable urban development. This model or framework aims to address the key limitations, uncertainties, paradoxes, and fallacies pertaining to existing models of sustainable urban form—with support of ICT of the new wave of computing and the underlying big data and context–aware computing technologies and their advanced applications. We conclude that the applied theoretical inquiry into smart sustainable cities of the future is deemed of high pertinence and importance—given that the research in the field is still in its early stages, and that the subject matter draws upon contemporary and influential theories with practical applications. The comprehensive overview of and critique on existing work on smart (and) sustainable cities provide a valuable and seminal reference for researchers and practitioners in related research communities and the necessary material to inform these communities of the latest developments in the area of smart sustainable urban planning and development. In addition, the proposed holistic approach is believed to be the first of its kind. That is, it has not been, to the best of one’s knowledge, investigated or produced elsewhere.}
}
@article{YU2021107361,
title = {A deep residual computation model for heterogeneous data learning in smart Internet of Things},
journal = {Applied Soft Computing},
volume = {107},
pages = {107361},
year = {2021},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2021.107361},
url = {https://www.sciencedirect.com/science/article/pii/S1568494621002842},
author = {Hang Yu and Laurence T. Yang and Xiangchao Fan and Qingchen Zhang},
keywords = {Deep residual computation, High-order computation, Tensor back-propagation algorithm, Classification},
abstract = {Smart Internet of Things (smart IoT) have emerged as a transformative computing paradigm recently. This new approach has made great contributions in the area of cyber–physical–social systems by employing various computational intelligence techniques like deep learning, for analyzing data, especially heterogeneous data from sensing and wireless communication. As a representative example of deep learning, deep residual networks have achieved excellent performance for big data feature learning since they can avoid gradient vanishing issues in deep learning models effectively. Unfortunately, they could not learn features for heterogeneous data, especially multi-modal data, in smart IoT. This paper proposes a deep residual computation model by generalizing the deep residual network in the tensor space. Especially, each multi-modal data object is represented as a tensor, while all hidden layers are also represented as tensors. Furthermore, we propose a tensor back-propagation algorithm to train the parameters of the deep residual computation model. Finally, we conduct extensive experiments to evaluate the presented deep residual model by comparing with the existing models such as multi-modal deep learning models, 3D deep residual models, deep computation models, and deep convolutional computation models. Results show that the proposed model produces more accurate classification results than other models for heterogeneous data feature learning in cyber–physical–social systems.}
}
@article{REY2022108693,
title = {Federated learning for malware detection in IoT devices},
journal = {Computer Networks},
volume = {204},
pages = {108693},
year = {2022},
issn = {1389-1286},
doi = {https://doi.org/10.1016/j.comnet.2021.108693},
url = {https://www.sciencedirect.com/science/article/pii/S1389128621005582},
author = {Valerian Rey and Pedro Miguel {Sánchez Sánchez} and Alberto {Huertas Celdrán} and Gérôme Bovet},
keywords = {IoT security, Federated learning, IoT device, Botnet detection, Adversarial attack},
abstract = {Billions of IoT devices lacking proper security mechanisms have been manufactured and deployed for the last years, and more will come with the development of Beyond 5G technologies. Their vulnerability to malware has motivated the need for efficient techniques to detect infected IoT devices inside networks. With data privacy and integrity becoming a major concern in recent years, increasing with the arrival of 5G and Beyond networks, new technologies such as federated learning and blockchain emerged. They allow training machine learning models with decentralized data while preserving its privacy by design. This work investigates the possibilities enabled by federated learning concerning IoT malware detection and studies security issues inherent to this new learning paradigm. In this context, a framework that uses federated learning to detect malware affecting IoT devices is presented. N-BaIoT, a dataset modeling network traffic of several real IoT devices while affected by malware, has been used to evaluate the proposed framework. Both supervised and unsupervised federated models (multi-layer perceptron and autoencoder) able to detect malware affecting seen and unseen IoT devices of N-BaIoT have been trained and evaluated. Furthermore, their performance has been compared to two traditional approaches. The first one lets each participant locally train a model using only its own data, while the second consists of making the participants share their data with a central entity in charge of training a global model. This comparison has shown that the use of more diverse and large data, as done in the federated and centralized methods, has a considerable positive impact on the model performance. Besides, the federated models, while preserving the participant’s privacy, show similar results as the centralized ones. As an additional contribution and to measure the robustness of the federated approach, an adversarial setup with several malicious participants poisoning the federated model has been considered. The baseline model aggregation averaging step used in most federated learning algorithms appears highly vulnerable to different attacks, even with a single adversary. The performance of other model aggregation functions acting as countermeasures is thus evaluated under the same attack scenarios. These functions provide a significant improvement against malicious participants, but more efforts are still needed to make federated approaches robust.}
}
@article{RAY2021102180,
title = {A perspective on 6G: Requirement, technology, enablers, challenges and future road map},
journal = {Journal of Systems Architecture},
volume = {118},
pages = {102180},
year = {2021},
issn = {1383-7621},
doi = {https://doi.org/10.1016/j.sysarc.2021.102180},
url = {https://www.sciencedirect.com/science/article/pii/S1383762121001302},
author = {Partha Pratim Ray},
keywords = {6G, Next generation communication, New radio, Wireless communications},
abstract = {Mobile network operators are at the verge of distribution and allotment of existing mobile communications with 5G. It is a high time that we should be focused on the forthcoming sixth generation (6G) networking. Though, it is mandated that 6G would leverage best of the existing network functions and cover an extended geographical range, we need to first understand the importance of 6G. In this article, we discuss about the vision of 6G and elaborate how it should look like with relevant elaborations. Key objective of this paper is to present analysis of the crucial requirements to develop 6G network infrastructure. We present a list of important networking and communication technologies that shall indeed play the vital role to design 6G. We also present how key enablers of 6G shall highlight their significance to emerge 6G. The article also presents important use case scenarios which may be overserved in the 6G era. Lastly, we find open research challenges and discuss way outs. Discussion about future road map designing concludes this literature.}
}
@article{ZHANG2022103598,
title = {Using street view images to identify road noise barriers with ensemble classification model and geospatial analysis},
journal = {Sustainable Cities and Society},
volume = {78},
pages = {103598},
year = {2022},
issn = {2210-6707},
doi = {https://doi.org/10.1016/j.scs.2021.103598},
url = {https://www.sciencedirect.com/science/article/pii/S2210670721008635},
author = {Kai Zhang and Zhen Qian and Yue Yang and Min Chen and Teng Zhong and Rui Zhu and Guonian Lv and Jinyue Yan},
keywords = {Ensemble learning, Street view image, Image classification model, Road noise barrier, Sustainable Transport Infrastructure},
abstract = {Road noise barriers (RNBs) are important urban infrastructures to relieve the harm of traffic noise pollution for citizens. Therefore, obtaining the spatial distribution characteristics of RNBs, such as precise positions and mileage, can be of great help for obtaining more accurate urban noise maps and assessing the quality of the urban living environment for sustainable urban development. However, an effective and efficient method for identifying RNBs and acquiring their attributes in large areas is scarce. This study constructs an ensemble classification model (ECM) to automatically identify RNBs at the city level based on Baidu Street View (BSV). Firstly, the bootstrap sampling method is proposed to build a street view image-based train set, where the effect of imbalanced categories of samples was reduced by adding confusing negative samples. Secondly, two state-of-the-art deep learning models, ResNet and DenseNet, are ensembled to construct an ECM based on the bagging framework. Finally, a post-processing method has been proposed based on geospatial analysis to eliminate street view images (SVIs) that are misclassified as RNBs. This study takes Suzhou, China as the study area to validate the proposed method. The model achieved an accuracy and F1-score of 0.98 and 0.90, respectively. The total mileage of the RNBs in Suzhou was 178,919 m. The results demonstrated the performance of the proposed RNBs identification framework. The significance of obtaining RNBs attributes for accelerating sustainable urban development has been demonstrated through the case of photovoltaic noise barriers (PVNBs).}
}
@article{SINHA2017591,
title = {Transportation infrastructure asset management in the new millennium: continuing issues, and emerging challenges and opportunities},
journal = {Transportmetrica A Transport Science},
volume = {13},
number = {7},
pages = {591-606},
year = {2017},
issn = {2324-9935},
doi = {https://doi.org/10.1080/23249935.2017.1308977},
url = {https://www.sciencedirect.com/science/article/pii/S2324993522000987},
author = {Kumares C. Sinha and Samuel Labi and Bismark R. D.K. Agbelie},
keywords = {Transportation asset management, infrastructure management, asset management system, project selection, trade-off analysis, system of systems},
abstract = {ABSTRACT
The time has come for renewed emphasis on the life cycle management of the physical aspects of transportation infrastructure. The urgency for this new direction is underscored by the fact that the physical transportation network at most countries constitutes the most valuable publicly owned infrastructure and efforts must be made to keep it resilient to possible threats of man-made or natural disasters over its service life so that the movement of people and goods can continue uninterrupted to serve the economy and maintain the quality of life. The concept of transportation asset management (TAM) is a systematic process based on multiple disciplines (engineering, finance, operations research and economics), to make cost-effective repair and replacement decisions geared towards a sustained state of good repair over the infrastructure life cycle. This paper first argues for the continued application of asset management principles for transportation infrastructure in the new millennium. The paper then discusses the development cycle of transportation infrastructure as a prelude to a discussion of the key functions of an asset management system. The paper proceeds to identify the components (asset types) and elements of asset management (that is, the tasks that are carried out by an asset manager in an agency). The challenges and opportunities of asset management in the new millennium are then discussed. These include, among others, the specter of climate change, infrastructure resilience, sustainable development of transportations assets, the emerging era of autonomous vehicles and smart cities, and the consideration of transportation assets as a holistic system-of-systems. These issues are addressed in the context of the availability of big data and advances in analytical techniques and computing power.}
}
@article{VILLEGAS2022103500,
title = {Lessons from Harvey: Improving traditional damage estimates with social media sourced damage estimates},
journal = {Cities},
volume = {121},
pages = {103500},
year = {2022},
issn = {0264-2751},
doi = {https://doi.org/10.1016/j.cities.2021.103500},
url = {https://www.sciencedirect.com/science/article/pii/S0264275121003991},
author = {Carlos A. Villegas and Matthew J. Martinez},
keywords = {Big data, Smart City, Social media, Disaster maps, Text analysis, Flood, Damage assessments},
abstract = {Social media systems and crowdsourced data sites were incredibly active during disasters. Residents, first responders, and officials all turn to these systems to impart information and make calls for assistance. These systems will likely continue to hold a central informational and communication role in future disasters. Analyzing the trends and information that come from these sources in real-time aids the recovery process and help public agencies, first responders and researchers more quickly assess damages during and immediately after a disaster. Traditional sources, such as the initial FEMA damage estimates can miss areas of heavy impact and are often time delayed by several weeks. Using Harris County, Texas in the Houston region and the 2017 Hurricane Harvey flooding, the study provides a novel use-case in crisis informatics. The study leverages calls for help during the flooding event to mine address-level information to proxy damage estimates at the parcel-level. The study finds 36- to 53% of Twitter-sourced damage estimates are not captured in the FEMA estimates, significantly augmenting initial estimates with new data – feasibly within hours after the information is first tweeted. Empirically, the study evaluates how parcel-level FEMA damage estimates and Twitter-sourced damage estimates complement each other to proxy damaged structures.}
}
@article{TAHAEI2020102538,
title = {The rise of traffic classification in IoT networks: A survey},
journal = {Journal of Network and Computer Applications},
volume = {154},
pages = {102538},
year = {2020},
issn = {1084-8045},
doi = {https://doi.org/10.1016/j.jnca.2020.102538},
url = {https://www.sciencedirect.com/science/article/pii/S1084804520300126},
author = {Hamid Tahaei and Firdaus Afifi and Adeleh Asemi and Faiz Zaki and Nor Badrul Anuar},
keywords = {Internet of things, IoT traffic classification, Traffic analysis, IoT security, M2M traffic classification},
abstract = {With the proliferation of the Internet of Things (IoT), the integration and communication of various objects have become a prevalent practice. The huge growth of IoT devices and different characteristics in the IoT traffic patterns have brought attention to traffic classification methods to address various raised issues in IoT applications. While network traffic classification has been well discussed in a number of surveys and review papers, it is still immature in IoT due to the differences in traffic characteristics in IoT and Non-IoT devices. This survey looks at the emerging trends of network traffic classification in IoT and the utilization of traffic classification in its applications. It also compares the legacy of traffic classification methods and presents an overview of traditional models. This paper extends the discussion with a taxonomy of the current network traffic classification within the IoT context. We then expose commercial and real-world use cases of the IoT traffic classification and finally outline open research issues and challenges in this domain.}
}
@article{CENGGORO2019175,
title = {Feature Pyramid Networks for Crowd Counting},
journal = {Procedia Computer Science},
volume = {157},
pages = {175-182},
year = {2019},
note = {The 4th International Conference on Computer Science and Computational Intelligence (ICCSCI 2019) : Enabling Collaboration to Escalate Impact of Research Results for Society},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2019.08.155},
url = {https://www.sciencedirect.com/science/article/pii/S1877050919310737},
author = {Tjeng Wawan Cenggoro and Ayu Hidayah Aslamiah and Ardian Yunanto},
keywords = {Crowd Counting, Scale-Aware, Deep Learning, Feature Pyramid Networks},
abstract = {In this paper, we propose the use of Feature Pyramid Networks (FPN) for Crowd Counting problem. FPN previously has been used for retinanet, the state-of-the-art model for object detection. By using FPN, our proposed crowd counting model achieved a state-of-the-art performance for UCF CC 50 dataset with MAE 136.4 and MSE 223.6. The proposed model is also achieved a state-of-the-art MSE value of 7.6 for ShanghaiTech Part B dataset. The code can be accessed at https: //github.com/wawancenggoro/fpncc.}
}
@article{BALADO2018226,
title = {Automatic classification of urban ground elements from mobile laser scanning data},
journal = {Automation in Construction},
volume = {86},
pages = {226-239},
year = {2018},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2017.09.004},
url = {https://www.sciencedirect.com/science/article/pii/S092658051730153X},
author = {J. Balado and L. Díaz-Vilariño and P. Arias and H. González-Jorge},
keywords = {Urban environment, As-built 3D, Graph library, Accessibility, Smart cities, Point cloud, Topology, Adjacency},
abstract = {Accessibility diagnosis of as-built urban environments is essential for path planning, especially in case of people with reduced mobility and it requires an in-depth knowledge of ground elements. In this paper, we present a new approach for automatically detect and classify urban ground elements from 3D point clouds. The methodology enables a high level of detail classification from the combination of geometric and topological information. The method starts by a planar segmentation followed by a refinement based on split and merge operations. Next, a feature analysis and a geometric decision tree are followed to classify regions in preliminary classes. Finally, adjacency is studied to verify and correct the preliminary classification based on a comparison with a topological graph library. The methodology is tested in four real complex case studies acquired with a Mobile Laser Scanner Device. In total, five classes are considered (roads, sidewalks, treads, risers and curbs). Results show a success rate of 97% in point classification, enough to analyse extensive urban areas from an accessibility point of view. The combination of topology and geometry improves a 10% to 20% the success rate obtained with only the use of geometry.}
}
@article{NESI2016202,
title = {Geographical localization of web domains and organization addresses recognition by employing natural language processing, Pattern Matching and clustering},
journal = {Engineering Applications of Artificial Intelligence},
volume = {51},
pages = {202-211},
year = {2016},
note = {Mining the Humanities: Technologies and Applications},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2016.01.011},
url = {https://www.sciencedirect.com/science/article/pii/S0952197616000154},
author = {Paolo Nesi and Gianni Pantaleo and Marco Tenti},
keywords = {Geographic Information Retrieval, Geoparsing, Geocoding, Data mining, Natural language processing, Hierarchical Clustering},
abstract = {Nowadays, the World Wide Web is growing at increasing rate and speed, and consequently the online available resources populating Internet represent a large source of knowledge for various business and research interests. For instance, over the past years, increasing attention has been focused on retrieving information related to geographical location of places and entities, which is largely contained in web pages and documents. However, such resources are represented in a wide variety of generally unstructured formats, and this actually does not help final users to find desired information items. The automatic annotation and comprehension of toponyms, location names and addresses (at different resolution and granularity levels) can deliver significant benefits for the whole web community by improving search engines filtering capabilities and intelligent data mining systems. The present paper addresses the problem of gathering geographical information from unstructured text in web pages and documents. In the specific, the proposed method aims at extracting geographical location (at street number resolution) of commercial companies and services, by annotating geo-related information from their web domains. The annotation process is based on Natural Language Processing (NLP) techniques for text comprehension, and relies on Pattern Matching and Hierarchical Cluster Analysis for recognizing and disambiguating geographical entities. Geotagging performances have been assessed by evaluating Precision, Recall and F-Measure of the proposed system output (represented in form of semantic RDF triples) against both a geo-annotated reference database and a semantic Smart City repository.}
}
@article{JAVAID2021,
title = {Integration of context awareness in Internet of Agricultural Things},
journal = {ICT Express},
year = {2021},
issn = {2405-9595},
doi = {https://doi.org/10.1016/j.icte.2021.09.004},
url = {https://www.sciencedirect.com/science/article/pii/S2405959521001247},
author = {Nadeem Javaid},
keywords = {Artificial intelligence, Machine learning, Data analytics, TOWS matrix, Internet of Agricultural Things},
abstract = {This work explores an efficient integration of IoT devices based on context awareness in the agricultural sector. A four-layered framework is proposed in which automation techniques are embedded to get real-time context aware insights from the ecosystem of IoT. The framework is evaluated using a strategic tool called threats, opportunities, weaknesses and strengths (TOWS) matrix to measure the performance of automation techniques. This analysis points out various opportunities to innovate the livelihood of agrarian society around the globe.}
}
@article{YANG2021103228,
title = {Real-time spatiotemporal prediction and imputation of traffic status based on LSTM and Graph Laplacian regularized matrix factorization},
journal = {Transportation Research Part C: Emerging Technologies},
volume = {129},
pages = {103228},
year = {2021},
issn = {0968-090X},
doi = {https://doi.org/10.1016/j.trc.2021.103228},
url = {https://www.sciencedirect.com/science/article/pii/S0968090X21002412},
author = {Jin-Ming Yang and Zhong-Ren Peng and Lei Lin},
keywords = {Spatiotemporal data, Traffic data prediction, Missing data imputation, Temporal matrix factorization, Deep learning, Intelligent transportation system},
abstract = {Accurate prediction of traffic status in real time is critical for advanced traffic management and travel navigation guidance. There are many attempts to predict short-term traffic flows using various deep learning algorithms. Most existing prediction models are only tested on spatiotemporal data assuming no missing data entries. However, this ideal situation rarely exists in real world due to sensor or network transmission failure. Missing data is a nonnegligible problem. Previous studies either remove time series with missing entries or impute missing data before building prediction models. The former may cause insufficient data for model training, while the latter adds extra computational burden and the imputation accuracy has direct impacts on the prediction performance. In this study, we propose an online framework that can make spatiotemporal predictions based on raw incomplete data and impute possible missing values at the same time. We design a novel spatial and temporal regularized matrix factorization model, namely LSTM-GL-ReMF, as the key component of the framework. The Long Short-term Memory (LSTM) model is chosen as the temporal regularizer to capture temporal dependency in time series data and the Graph Laplacian (GL) serves as the spatial regularizer to utilize spatial correlations among network sensors to enhance prediction and imputation performance. The proposed framework integrating with the LSTM-GL-ReMF model are tested and compared with other state-of-the-art matrix factorization models and deep learning models on three uni-variate and multi-variate spatiotemporal traffic datasets. The experimental results show our approach has a robust and accurate performance in terms of prediction and imputation accuracy under various data missing scenarios.}
}
@article{SESTITO2021103413,
title = {A general optimization-based approach to the detection of real-time Ethernet traffic events},
journal = {Computers in Industry},
volume = {128},
pages = {103413},
year = {2021},
issn = {0166-3615},
doi = {https://doi.org/10.1016/j.compind.2021.103413},
url = {https://www.sciencedirect.com/science/article/pii/S0166361521000208},
author = {Guilherme Serpa Sestito and Afonso Celso Turcato and Andre Luis Dias and Paolo Ferrari and Danilo Hernane Spatti and Maíra Martins {da Silva}},
keywords = {Anomaly detection, PROFINET, SERCOS III, Ethernet/IP, Differential evolution},
abstract = {One of the most used technologies in industrial automation is industrial Ethernet. RTE protocols can cope with the requirements of the Industry 4.0 frameworks. However, the broader use of industrial Ethernet also generates discussion about its vulnerabilities. In this sense, this work proposes anomaly detection methods. These methods are usually time-consuming and limited in scope since they are derived for addressing a single protocol. Thus, this work proposes a general and accurate anomaly detection technique suitable for any protocol based on RTE. ANN-based and SVM-based classifiers are used for classifying data traffic events based on the most relevant features extracted from data sets. An optimal sliding window approach is used for extracting these data sets, which improves the accuracy of the proposal. Seven different classifiers are investigated. Firstly, a Perceptron Neural Network is applied for verifying if the data sets are linearly separable. If this first classifier is unable to reach the required accuracy, three ANN-based classifiers with different activation functions and three SVM-based classifiers with different kernels are employed. The use of several classifiers not only improves the accuracy but also eliminates the need for advanced knowledge about communication dynamics. The generality and accuracy of the proposal are evaluated for detecting traffic events using real traffic data of a real automotive plant. PROFINET, Ethernet/IP, and SERCOS III networks have been analyzed, showing that some traffic events can be classified using the Perceptron while others require the use of more complex classifiers achieving accuracy greater than 98%.}
}
@article{AFYOUNI2022279,
title = {Multi-feature, multi-modal, and multi-source social event detection: A comprehensive survey},
journal = {Information Fusion},
volume = {79},
pages = {279-308},
year = {2022},
issn = {1566-2535},
doi = {https://doi.org/10.1016/j.inffus.2021.10.013},
url = {https://www.sciencedirect.com/science/article/pii/S1566253521002220},
author = {Imad Afyouni and Zaher Al Aghbari and Reshma Abdul Razack},
keywords = {Social data mining, Event detection, Big data, Multi-modal, Multi-source, Multi-lingual, Visualization},
abstract = {The tremendous growth of event dissemination over social networks makes it very challenging to accurately discover and track exciting events, as well as their evolution and scope over space and time. People have migrated to social platforms and messaging apps, which represent an opportunity to create a more accurate prediction of social developments by translating event related streams to meaningful insights. However, the huge spread of ‘noise’ from unverified social media sources makes it difficult to accurately detect and track events. Over the last decade, multiple surveys on event detection from social media have been presented, with the aim of highlighting the different NLP, data management and machine learning techniques used to discover specific types of events, such as social gatherings, natural disasters, and emergencies, among others. However, these surveys focus only on a few dimensions of event detection, such as emphasizing on knowledge discovery form single modality or single social media platform or applied only to one specific language. In this survey paper, we introduce multiple perspectives for event detection in the big social data era. This survey paper thoroughly investigates and summarizes the significant progress in social event detection and visualization techniques, by emphasizing crucial challenges ranging from the management, fusion, and mining of big social data, to the applicability of these methods to different platforms, multiple languages and dialects rather than a single language, and with multiple modalities. The survey also focuses on advanced features required for event extraction, such as spatial and temporal scopes, location inference from multi-modal data (i.e., text or image), and semantic analysis. Application-oriented challenges and opportunities are also discussed. Finally, quantitative and qualitative experimental procedures and results to illustrate the effectiveness and gaps in existing works are presented.}
}
@article{WEN2021192,
title = {Cooperative indoor 3D mapping and modeling using LiDAR data},
journal = {Information Sciences},
volume = {574},
pages = {192-209},
year = {2021},
issn = {0020-0255},
doi = {https://doi.org/10.1016/j.ins.2021.06.006},
url = {https://www.sciencedirect.com/science/article/pii/S0020025521005934},
author = {Chenglu Wen and Jinbin Tan and Fashuai Li and Chongrong Wu and Yitai Lin and Zhiyong Wang and Cheng Wang},
keywords = {Frame-level semantic labeling, Line model, Point-cloud-based mapping},
abstract = {Point clouds and models with semantic information facilitate various indoor automation, ranging from indoor robotics to emergency responses. Studies are currently being conducted on semantic labeling and modeling based on offline mapped point clouds, in which, the performance is strongly limited by the mapping process. To address this issue, we propose a framework to cooperatively perform the three tasks of semantic labeling, mapping, and 3D modeling of point clouds. First, our framework uses a deep-learning-assisted method to perform frame-level point cloud semantic labeling. Subsequently, point cloud frames with semantic labels are used to extract the structural planes of buildings, followed by the generation of line structures from the planes. Then, these frames are used to estimate the initial poses of a 3D sensor for data collection. In the subsequent pose optimization process, the initial poses are optimized under the constraints of the structural planes. Finally, the optimized poses are used to integrate semantic frames and line structures to generate a point cloud map and 3D line model of buildings. The experimental results show that the proposed method achieves better results than the state-of-the-art methods that separately perform one of the two tasks.}
}
@article{GURDURBROO2021100192,
title = {Cyber-physical systems research and education in 2030: Scenarios and strategies},
journal = {Journal of Industrial Information Integration},
volume = {21},
pages = {100192},
year = {2021},
issn = {2452-414X},
doi = {https://doi.org/10.1016/j.jii.2020.100192},
url = {https://www.sciencedirect.com/science/article/pii/S2452414X20300674},
author = {Didem {Gürdür Broo} and Ulf Boman and Martin Törngren},
keywords = {Cyber-physical systems, Research and education, 2030, Future studies, Scenario planning TAIDA framework, Future of engineering research, Future of research},
abstract = {Future cyber-physical systems (CPS), such as smart cities, collaborative robots, autonomous vehicles or intelligent transport systems, are expected to be highly intelligent, electrified, and connected. This study explores a focal question about how these new characteristics may affect the education and research related to CPS in 2030, the date identified by the United Nations to achieve the Agenda for Sustainable Development. To this end, first, we have conducted a trend spotting activity, seeking to identify possible influencing factors that may have a great impact on the future of CPS education and research. These factors were clustered in a total of 12 trends – four certainties; namely connectivity, electrification, data and automation – and eight uncertainties; namely intelligence, data ethics, labour market, lifelong learning, higher education, trust in technology, technological development speed, and sustainable development goals. After that, two of the eight uncertainties are identified and used to construct a scenario matrix, which includes four scenarios. These two uncertainties – the so-called strategic uncertainties – are: fulfilment of sustainable development goals and the nature of the technological development, respectively. These two important uncertainties are considered to build the scenarios due to their potential impact on the research and education of CPS. For instance, sustainable development goals are significant targets for many initiatives, organisations and countries. While 2030 is the deadline to achieve these goals, the relationship between the sustainable development goals related to CPS research and education is not studied well. Similarly, the speed of technological development is seen as a driving force behind future CPS. However, the effect of this speed to CPS research and education environment is not known. Different outcomes of the chosen two uncertainties are, then, combined with the remaining trends and uncertainties. Consequently, four scenarios are derived. The Terminator scenario illustrates a dystopian future where profit is the driving force behind technological progress and sustainable development goals are not accomplished. In contrast, The Iron Giant scenario represents the successful implementation of the sustainable development goals where technological development is the force behind the accomplishment of these goals. The scenario called Slow Progress represents a future where gradual technological improvements are present, but sustainability is still not seen as concerning the issue. The Humanist scenario illustrates a future where slow technological development is happening yet sustainable development goals are successfully implemented. Finally, the scenarios are used to initiate discussions by illustrating what the future of research and education could look like and a list of strategies for future CPS research and education environments is proposed. To this end, we invite educators, researchers, institutions and governments to develop the necessary strategies to enable data-orientated, continuous, interdisciplinary, collaborative, ethical, and sustainable research and education by improving digital fluency, advancing digital equality, contributing to new ways of teaching complex thinking, expanding access to learning platforms and preparing next generations to adapt for a rapidly changing future of work conditions.}
}
@article{GORODOKIN2021241,
title = {Optimization of adaptive traffic light control modes based on machine vision},
journal = {Transportation Research Procedia},
volume = {57},
pages = {241-249},
year = {2021},
note = {International conference of Arctic transport accessibility: networks and systems},
issn = {2352-1465},
doi = {https://doi.org/10.1016/j.trpro.2021.09.047},
url = {https://www.sciencedirect.com/science/article/pii/S235214652100675X},
author = {Vladimir Gorodokin and Sultan Zhankaziev and Elena Shepeleva and Kirill Magdin and Sergey Evtyukov},
keywords = {adaptive traffic lights control, lane capacity, traffic lights cycle, vehicle queue, neural network, intersection},
abstract = {Urbanization leads to a significant increase in traffic density in large cities. The growing transport concentration is accompanied by an increase in traffic congestion and emissions of harmful substances. The policies and decisions developed by the authorities, such as the expansion of existing roads and construction of new roads, as well as increase in transport taxes, no longer make it possible to maintain the adequate mobility of the population. One of the solutions is to increase the efficiency of road infrastructure utilization by forecasting the traffic situation and using the adaptive adjustment of traffic lights operation. With dynamic collection and interpretation of traffic flow data from traffic monitoring cameras, it will be possible to use the dynamic parameters of vehicles as indicators for the adaptive adjustment of traffic light regulation. The first part of the paper describes the use of machine vision and a neural network (YOLOv4) in tracking the parameters of traffic flows on road sections in front of intersections. The second part of the paper presents a methodology based on the dynamic regulation of traffic lights cycles and their duration, taking into account the current and forecast parameters of the traffic flow. The algorithm for the adaptive adjustment of traffic lights regulation considers the following parameters: the number and dynamic dimensions of vehicles moving towards the intersection; the number of vehicles in the queue in front of the stop line and their acceleration at the start of the movement. We determined the relationship of the intersection capacity when driving straight ahead with the dynamic dimensions of vehicles and the formation of a queue in front of the stop line, waiting for the green light. The study resulted in the development of an algorithm for setting the duration of both a particular phase and the entire traffic lights cycle in the tasks of eliminating or minimizing the possibility of congestion.}
}
@article{SHARMA2019101966,
title = {Maximization of wireless sensor network lifetime using solar energy harvesting for smart agriculture monitoring},
journal = {Ad Hoc Networks},
volume = {94},
pages = {101966},
year = {2019},
issn = {1570-8705},
doi = {https://doi.org/10.1016/j.adhoc.2019.101966},
url = {https://www.sciencedirect.com/science/article/pii/S1570870519300952},
author = {Himanshu Sharma and Ahteshamul Haque and Zainul Abdin Jaffery},
keywords = {Wireless sensor networks, Sensor network lifetime, Network throughput, Solar energy harvesting, Smart agriculture},
abstract = {The wireless sensor networks (WSNs) are used for the real-life implementation of the Internet of Things (IoT) in smart agriculture, smart buildings, smart cities, and online industrial monitoring applications. Generally, traditional WSN nodes are powered by limited energy capacity, non-rechargeable batteries. The WSN lifetime (days) depends upon, duty cycle, type of application deployment, and battery state of charge (SoC) level. We propose an innovative solution to the limited energy availability design problem by utilizing the ambient solar energy harvesting for battery charging of WSN nodes. However, there are many challenges in solar energy harvesting like intermittency of available power, solar energy prediction, thermal issues, solar panel conversion efficiency, and other environmental issues. The objective of this research work is to maximize the WSN network lifetime using solar energy harvesting technique. From our simulation results, it is proved that the sensor network lifetime is increased from 5.75 days to 115.75 days @ 25% duty cycle and higher, ideally up to infinite network lifetime. Furthermore, the network throughput is also increased from 100 K bits/s to 160 K bits/s. in SEH-WSNs.}
}
@article{HACHEM2020110484,
title = {Modeling, analyzing and predicting security cascading attacks in smart buildings systems-of-systems},
journal = {Journal of Systems and Software},
volume = {162},
pages = {110484},
year = {2020},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2019.110484},
url = {https://www.sciencedirect.com/science/article/pii/S0164121219302584},
author = {Jamal EL Hachem and Vanea Chiprianov and Muhammad Ali Babar and Tarek AL Khalil and Philippe Aniorte},
keywords = {Systems-of-systems, Security modeling and analysis, Model driven engineering, Software architecture, Multi-agent systems simulation, Smart buildings},
abstract = {Software systems intelligence and complexity have been continuously increasing to deliver more and more features to support business critical and mission critical processes in numerous domains such as defense, health-care, and smart cities. Contemporary software-based solutions are composed of several software systems, that form System-of-Systems (SoS). SoS differentiating characteristics, such as emergent behavior, introduce specific issues that render their security modeling, simulation and analysis a critical challenge. The aim of this work is to investigate how Software Engineering (SE) approaches can be leveraged to model and analyze secure SoS solutions for predicting high impact (cascading) attacks at the architecture stage. In order to achieve this objective, we propose a Model Driven Engineering method, Systems-of-Systems Security (SoSSec), that comprises: (1) a modeling language (SoSSecML) for secure SoS modeling and (2) Multi-Agent Systems (MAS) for security analysis of SoS architectures. To illustrate our proposed approach in terms of modeling, simulating, and discovering attacks, we have conducted a case study on a real-life smart building SoS, the Adelaide University Health and Medical School (AHMS). The results from this case study demonstrate that our proposed method discovers cascading attacks comprising of a number of individual attacks, such as a Denial of Service, that arise from a succession of exploited vulnerabilities through interactions among the constituent systems of SoS. In future work, we intend to extend SoSSec to address diverse unknown emergent behaviors and non-functional properties such as safety and trust.}
}
@article{SUBASI201954,
title = {Smartphone-Based Human Activity Recognition Using Bagging and Boosting},
journal = {Procedia Computer Science},
volume = {163},
pages = {54-61},
year = {2019},
note = {16th Learning and Technology Conference 2019Artificial Intelligence and Machine Learning: Embedding the Intelligence},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2019.12.086},
url = {https://www.sciencedirect.com/science/article/pii/S1877050919321258},
author = {Abdulhamit Subasi and Asalah Fllatah and Kholoud Alzobidi and Tayeb Brahimi and Akila Sarirete},
keywords = {Smartphone, Human Activity Recognition (HAR), BAgging, Adaboost, Ensemble Classifier},
abstract = {In today’s healthcare applications, the use of mobile technologies brings together physicians and patients for intelligent and automatic monitoring of daily clinical activities, remote life assistants, and preventive care, especially for the elderly and those under medical control. As smartphones become an important part of our everyday life, they are ever more employed in human activities recognition (HAR) including the monitoring of personal health care and wellbeing. However, HAR is complex and it is important to use the best technology and learn about human activity using machine learning. The purpose of this paper is to develop a HAR system based on the smartphone sensors’ data using Bagging and Adaboost ensemble classifiers. The experimental results for the HAR data have been evaluated after performing different data mining techniques. For each subject, the total classification accuracy, the F-measure, and the ROC area were calculated. Adaboost ensemble classifiers algorithm improved significantly the performance of smartphone-based HAR, combined with SVM, it reached 97.44% accuracy compared to the rest of the classifiers. The proposed algorithm of Adaboost SVM can lead to an accurate HAR for elderly and disabled patients who need continuous care as well as it is a tool that supports the decisions of all medical practitioners.}
}
@article{RUUTU2017119,
title = {Development and competition of digital service platforms: A system dynamics approach},
journal = {Technological Forecasting and Social Change},
volume = {117},
pages = {119-130},
year = {2017},
issn = {0040-1625},
doi = {https://doi.org/10.1016/j.techfore.2016.12.011},
url = {https://www.sciencedirect.com/science/article/pii/S0040162516308605},
author = {Sampsa Ruutu and Thomas Casey and Ville Kotovirta},
keywords = {Digital platform, System dynamics, Simulation, Interoperability, Smart city},
abstract = {Digital service platforms are becoming widespread in all areas of society. One risk scenario in platform development is related to the fragmentation of development efforts and the failure to achieve a critical mass of platform users, while a second risk scenario is related to a winner-take-all situation in which one platform firm achieves a monopoly position in the market. We develop a system dynamics model of platform development that includes two competing platforms, and use the model to simulate various development paths by varying different factors that affect how resources accumulate to the platforms. Our simulation results show that delays in users' decision making can increase the likelihood of achieving critical mass. In addition, open interfaces and data transferability between platforms can accelerate platform adoption and decrease the likelihood of a winner-take-all situation. The simulation results also reveal more nuanced development paths than simple S-shaped growth because of delays in platform development and different cross-side network effects to end users and service providers.}
}
@article{SHAMS2021104606,
title = {HANA: A Healthy Artificial Nutrition Analysis model during COVID-19 pandemic},
journal = {Computers in Biology and Medicine},
volume = {135},
pages = {104606},
year = {2021},
issn = {0010-4825},
doi = {https://doi.org/10.1016/j.compbiomed.2021.104606},
url = {https://www.sciencedirect.com/science/article/pii/S0010482521004005},
author = {Mahmoud Y. Shams and Omar M. Elzeki and Lobna M. Abouelmagd and Aboul Ella Hassanien and Mohamed Abd Elfattah and Hanaa Salem},
keywords = {COVID-19, Healthy food, Regression, Artificial intelligence, Machine learning, Nutrition analysis},
abstract = {Background and objective
The impact of diet on COVID-19 patients has been a global concern since the pandemic began. Choosing different types of food affects peoples’ mental and physical health and, with persistent consumption of certain types of food and frequent eating, there may be an increased likelihood of death. In this paper, a regression system is employed to evaluate the prediction of death status based on food categories.
Methods
A Healthy Artificial Nutrition Analysis (HANA) model is proposed. The proposed model is used to generate a food recommendation system and track individual habits during the COVID-19 pandemic to ensure healthy foods are recommended. To collect information about the different types of foods that most of the world's population eat, the COVID-19 Healthy Diet Dataset was used. This dataset includes different types of foods from 170 countries around the world as well as obesity, undernutrition, death, and COVID-19 data as percentages of the total population. The dataset was used to predict the status of death using different machine learning regression models, i.e., linear regression (ridge regression, simple linear regularization, and elastic net regression), and AdaBoost models.
Results
The death status was predicted with high accuracy, and the food categories related to death were identified with promising accuracy. The Mean Square Error (MSE), Root Mean Square Error (RMSE), Mean Absolute Error (MAE), and R2 metrics and 20-fold cross-validation were used to evaluate the accuracy of the prediction models for the COVID-19 Healthy Diet Dataset. The evaluations demonstrated that elastic net regression was the most efficient prediction model. Based on an in-depth analysis of recent nutrition recommendations by WHO, we confirm the same advice already introduced in the WHO report1. Overall, the outcomes also indicate that the remedying effects of COVID-19 patients are most important to people which eat more vegetal products, oilcrops grains, beverages, and cereals - excluding beer. Moreover, people consuming more animal products, animal fats, meat, milk, sugar and sweetened foods, sugar crops, were associated with a higher number of deaths and fewer patient recoveries. The outcome of sugar consumption was important and the rates of death and recovery were influenced by obesity.
Conclusions
Based on evaluation metrics, the proposed HANA model may outperform other algorithms used to predict death status. The results of this study may direct patients to eat particular types of food to reduce the possibility of becoming infected with the COVID-19 virus.}
}
@article{YANG2022100301,
title = {Improved strategies of relation extraction based on graph convolutional model on tree structure for web information processing},
journal = {Journal of Industrial Information Integration},
volume = {25},
pages = {100301},
year = {2022},
issn = {2452-414X},
doi = {https://doi.org/10.1016/j.jii.2021.100301},
url = {https://www.sciencedirect.com/science/article/pii/S2452414X21000959},
author = {Shuo Yang and Jingzhi Guo},
keywords = {Information extraction, Relation extraction, Graph convolutional model, Dependency tree, Joint model},
abstract = {In the Industry 4.0/5.0 era, information integration is employed to fuse information from different companies to facilitate interoperation. However, information extraction is an important preprocessing phase that must be performed prior to integrating data from different contexts. Relation extraction, which is an element of information extraction, is typically the basis of many upper-level applications, e.g., information visualization and inference. Some current models may not fully consider the complementary effect of information at different levels of granularity featured by different neural networks. In this paper, two improvement relation extraction strategies based on the graph convolutional model on tree structure (GCNTree) are proposed. The first strategy integrates a hierarchical attention mechanism and correlation analysis between subjects and objects to generate sentence and entity vectors, respectively. The second strategy merges a named-entity recognition subnetwork with GCNTree to realize joint learning of relation and entity extraction. Experimental results demonstrate that the proposed strategies are comparable to state-of-the-art methods.11Our code will be available at https://github.com/yangshuodelove/.}
}
@article{XU20183,
title = {Mobile crowd sensing of human-like intelligence using social sensors: A survey},
journal = {Neurocomputing},
volume = {279},
pages = {3-10},
year = {2018},
note = {Advances in Human-like Intelligence towards Next-Generation Web},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2017.01.127},
url = {https://www.sciencedirect.com/science/article/pii/S0925231217317769},
author = {Zheng Xu and Lin Mei and Kim-Kwang Raymond Choo and Zhihan Lv and Chuanping Hu and Xiangfeng Luo and Yunhuai Liu},
keywords = {Mobile crowd sensing, Social sensors, Social sensing},
abstract = {Recently, with the fast proliferation of smart phones, mobile phone has the powerful ability of not only communication but also computation. Human beings are not only data consumers, but data producer with their objective or subjective sensing needs. Mobile crowd sensing is an emerging computing paradigm that tasks everyday mobile devices to form participatory sensor networks. It allows the increasing number of mobile phone users to share local knowledge acquired by their sensor-enhanced devices. Social sensors, social sensor receiver platform, and mobile crowd sensing paradigm compose a process by which physical sensors present in mobile devices such as GPS are used to infer social relationships and human activities. In this survey, we review the mobile crowd sensing applications on social sensors based on social sensor receiver platform (e.g., Weibo and Twitter) from three categories: public security, smart city, and location based services. Most applications adopted in current works fit in one of these categories. Existing works on applications of mobile crowd sensing on social sensors are collected and studied. Some possible future directions of potential new application category are proposed and analyzed.}
}
@article{YOUNAN2020107198,
title = {Challenges and recommended technologies for the industrial internet of things: A comprehensive review},
journal = {Measurement},
volume = {151},
pages = {107198},
year = {2020},
issn = {0263-2241},
doi = {https://doi.org/10.1016/j.measurement.2019.107198},
url = {https://www.sciencedirect.com/science/article/pii/S0263224119310644},
author = {Mina Younan and Essam H. Houssein and Mohamed Elhoseny and Abdelmgeid A. Ali},
keywords = {Industrial IoT (IIoT), Searching and indexing, Blockchain, Big data, Data fusion, Machine learning, Cloud and fog computing},
abstract = {Physical world integration with cyber world opens the opportunity of creating smart environments; this new paradigm is called the Internet of Things (IoT). Communication between humans and objects has been extended into those between objects and objects. Industrial IoT (IIoT) takes benefits of IoT communications in business applications focusing in interoperability between machines (i.e., IIoT is a subset from the IoT). Number of daily life things and objects connected to the Internet has been in increasing fashion, which makes the IoT be the dynamic network of networks. Challenges such as heterogeneity, dynamicity, velocity, and volume of data, make IoT services produce inconsistent, inaccurate, incomplete, and incorrect results, which are critical for many applications especially in IIoT (e.g., health-care, smart transportation, wearable, finance, industry, etc.). Discovering, searching, and sharing data and resources reveal 40% of IoT benefits to cover almost industrial applications. Enabling real-time data analysis, knowledge extraction, and search techniques based on Information Communication Technologies (ICT), such as data fusion, machine learning, big data, cloud computing, blockchain, etc., can reduce and control IoT and leverage its value. This research presents a comprehensive review to study state-of-the-art challenges and recommended technologies for enabling data analysis and search in the future IoT presenting a framework for ICT integration in IoT layers. This paper surveys current IoT search engines (IoTSEs) and presents two case studies to reflect promising enhancements on intelligence and smartness of IoT applications due to ICT integration.}
}
@article{KUSHWAHA2020286,
title = {Visualization of Agriculture Data of Rajasthan: An Application of R},
journal = {Materials Today: Proceedings},
volume = {29},
pages = {286-294},
year = {2020},
note = {National Conference on Smart Materials: Energy and Environment for Smart Cities, NSES-2018, 28th February 2018, Gwalior, India},
issn = {2214-7853},
doi = {https://doi.org/10.1016/j.matpr.2020.07.276},
url = {https://www.sciencedirect.com/science/article/pii/S2214785320353694},
author = {Meena Kushwaha and Ankita Bissa and V.R. Raghuveer},
keywords = {Artificial intelligence, Data science, advanced analytic tools, machine learning, R Language, Data visualization},
abstract = {Applications of artificial intelligence, machine learning, data science, and advanced analytics are abundantly used in various areas; however, these are yet to be effectively utilized in agriculture sector in Rajasthan. There are some commonly used open source platforms to perform data processing and representation of patterns as graphs. Data visualization is a key aspect of both the analysis and understanding of these data, and users now have many visualization methods and tools to choose from. The challenge is to create clear, meaningful and integrated visualizations. This representation of data using R Language provides a quick insight into both Information-assisted and knowledge-assisted visualization for interactive exploration and can be used for analytic purpose}
}
@article{ABDELBASSET202084,
title = {The fusion of Internet of Intelligent Things (IoIT) in remote diagnosis of obstructive Sleep Apnea: A survey and a new model},
journal = {Information Fusion},
volume = {61},
pages = {84-100},
year = {2020},
issn = {1566-2535},
doi = {https://doi.org/10.1016/j.inffus.2020.03.010},
url = {https://www.sciencedirect.com/science/article/pii/S1566253519307043},
author = {Mohamed Abdel-Basset and Weiping Ding and Laila Abdel-Fatah},
keywords = {Obstructive Sleep Apnea, Remote diagnosis, Internet of Things, Internet of Intelligent Things, Artificial Intelligence, Optimization},
abstract = {Obstructive Sleep Apnea (OSA) syndrome is one of the most widespread diseases that difficult to be detected and remedied. In particular, the examination of OSA by using the traditional Polysomnography (PSG) is one of formidable complexity as it requires full observation in a laboratory overnight. Meanwhile, the number of available laboratories and beds is minimal comparing to the number of OSA patients. What's more, the unusual environment and restricted mobility of patients may result in deficient diagnosis results. The Internet of Things (IoT) is the most appropriate solution for the previous diagnosis obstacles by allowing doctors to synchronize patient status. Besides, several studies have been introduced to consolidate the performance of IoT interoperability via the fusion with Artificial Intelligence (AI) resulting in the Internet of Intelligent Things (IoIT). This paper presents a literature survey about the intensification of IoT technologies for smart monitoring of sleep quality and OSA diagnosis. Mainly, the most recent enabling IoT and support technologies such as (smart devices, fog computing, cloud, big data, and machine learning) are covered via the discussion of more recent works of literature published from 2016 to 2019. Also, the roles of AI in optimizing the efficiency of OSA smart diagnosis are presented. Besides, a new comprehensive IoIT optimization framework is presented which employing AI for optimizing the performance of intelligent diagnosis of OSA. Finally, the open issues and challenges in this field are argued. This paper is, therefore, a major contributor to the compilation of all IoT innovative and efficient AI methods that improving the quality of OSA diagnosis.}
}
@article{LOUKAS201783,
title = {Computation offloading of a vehicle’s continuous intrusion detection workload for energy efficiency and performance},
journal = {Simulation Modelling Practice and Theory},
volume = {73},
pages = {83-94},
year = {2017},
note = {Smart Cities and Internet of Things},
issn = {1569-190X},
doi = {https://doi.org/10.1016/j.simpat.2016.08.005},
url = {https://www.sciencedirect.com/science/article/pii/S1569190X16302234},
author = {George Loukas and Yongpil Yoon and Georgia Sakellari and Tuan Vuong and Ryan Heartfield},
keywords = {Computation offloading, Intrusion detection, Energy efficiency, Detection latency, Cyber-physical systems, Vehicular security},
abstract = {Computation offloading has been used and studied extensively in relation to mobile devices. That is because their relatively limited processing power and reliance on a battery render the concept of offloading any processing/energy-hungry tasks to a remote server, cloudlet or cloud infrastructure particularly attractive. However, the mobile device’s tasks that are typically offloaded are not time-critical and tend to be one-off. We argue that the concept can be practical also for continuous tasks run on more powerful cyber-physical systems where timeliness is a priority. As case study, we use the process of real-time intrusion detection on a robotic vehicle. Typically, such detection would employ lightweight statistical learning techniques that can run onboard the vehicle without severely affecting its energy consumption. We show that by offloading this task to a remote server, we can utilse approaches of much greater complexity and detection strength based on deep learning. We show both mathematically and experimentally that this allows not only greater detection accuracy, but also significant energy savings, which improve the operational autonomy of the vehicle. In addition, the overall detection latency is reduced in most of our experiments. This can be very important for vehicles and other cyber-physical systems where cyber attacks can directly affect physical safety. In fact, in some cases, the reduction in detection latency thanks to offloading is not only beneficial but necessary. An example is when detection latency onboard the vehicle would be higher than the detection period, and as a result a detection run cannot complete before the next one is scheduled, increasingly delaying consecutive detection decisions. Offloading to a remote server is an effective and energy-efficient solution to this problem too.}
}
@article{KAISER2013708,
title = {Enabling real-time city sensing with kernel stream oracles and MapReduce},
journal = {Pervasive and Mobile Computing},
volume = {9},
number = {5},
pages = {708-721},
year = {2013},
note = {Special issue on Pervasive Urban Applications},
issn = {1574-1192},
doi = {https://doi.org/10.1016/j.pmcj.2012.11.003},
url = {https://www.sciencedirect.com/science/article/pii/S1574119212001381},
author = {Christian Kaiser and Alexei Pozdnoukhov},
keywords = {Sensor networks, Machine learning, Kernel methods, Spatial statistics, Smart cities},
abstract = {An algorithmic architecture for kernel-based modelling of data streams from city sensing infrastructures is introduced. It is both applicable for pre-installed, moving and extemporaneous sensors, including the “citizen-as-a-sensor” view on user-generated data. The approach is centred around a kernel dictionary implementing a general hypothesis space which is updated incrementally, accounting for memory and processing capacity limitations. It is general for both kernel-based classification and regression. An extension to area-to-point modelling is introduced to account for the data aggregated over a spatial region. A distributed implementation realised under the Map-Reduce framework is presented to train an ensemble of sequential kernel learners.}
}
@article{IYER2021100083,
title = {AI enabled applications towards intelligent transportation},
journal = {Transportation Engineering},
volume = {5},
pages = {100083},
year = {2021},
issn = {2666-691X},
doi = {https://doi.org/10.1016/j.treng.2021.100083},
url = {https://www.sciencedirect.com/science/article/pii/S2666691X21000397},
author = {Lakshmi Shankar Iyer},
keywords = {Public transport, Safety management, Logistics, Intelligent transportation systems, Traffic management, Transport management systems},
abstract = {Artificial intelligence (AI) is the ability of a machine to perform cognitive functions like perceiving, reasoning, learning and problem-solving which humans are capable of performing at ease. AI has gained traction since the past two decades across the globe due to availability of huge volume of data generated through Internet. There has been a huge benefit to governments and businesses by processing this data using advanced algorithms in the recent past. The robust growth of machine learning algorithms supported by various technologies like Internet of Things, Robotic Process Automation, Computer Vision, Natural Language Processing have enabled the growth of AI. This article is a compilation of various issues plaguing Transport Industry classified under Intelligent Transportation Systems. Some of the sub-systems considered are related to Traffic Management, Public Transport, Safety Management, Manufacturing & Logistics from Intelligent Transportation Systems where AI benefits are put into use. The study takes up specific areas of concern in transport industry and its related issues that have possible solutions using AI. The approach involves a secondary study based on the country-wise data available from various sources. Further, discussions on AI solutions to resolve issues in transport industry across various countries in the globe and in Indian states is taken up.}
}
@article{YANG2021126442,
title = {Current advances and future challenges of AIoT applications in particulate matters (PM) monitoring and control},
journal = {Journal of Hazardous Materials},
volume = {419},
pages = {126442},
year = {2021},
issn = {0304-3894},
doi = {https://doi.org/10.1016/j.jhazmat.2021.126442},
url = {https://www.sciencedirect.com/science/article/pii/S0304389421014072},
author = {Chao-Tung Yang and Ho-Wen Chen and En-Jui Chang and Endah Kristiani and Kieu Lan Phuong Nguyen and Jo-Shu Chang},
abstract = {Air pollution is at the center of pollution-control discussion due to the significant adverse health effects on individuals and the environment. Research has shown the association between unsafe environments and different sizes of particulate matter (PM), highlighting the importance of pollutant monitoring to mitigate its detrimental effect. By monitoring air quality with low-cost monitoring devices that collect massive observations, such as Air Box, a comprehensive collection of ground-level PM concentration is plausible due to the simplicity and low-cost, propelling applications in agriculture, aquaculture, and air quality, water resources, and disaster prevention. This paper aims to view IoT-based systems with low-cost microsensors at the sensor, network, and application levels, along with machine learning algorithms that improve sensor networks’ precision, providing better resolution. From the analysis at the three levels, we analyze current PM monitoring methods, including the use of sensors when collecting PM concentrations, demonstrate the use of IoT-based systems in PM monitoring and its challenges, and finally present the integration of AI and IoT (AIoT) in PM monitoring, indoor air quality control, and future directions. In addition, the inclusion of Taiwan as a site analysis was illustrated to show an example of AIoT in PM-control policy-making potential directions.}
}
@article{ZHANG20211478,
title = {Analysis of ground surface settlement in anisotropic clays using extreme gradient boosting and random forest regression models},
journal = {Journal of Rock Mechanics and Geotechnical Engineering},
volume = {13},
number = {6},
pages = {1478-1484},
year = {2021},
issn = {1674-7755},
doi = {https://doi.org/10.1016/j.jrmge.2021.08.001},
url = {https://www.sciencedirect.com/science/article/pii/S1674775521001098},
author = {Runhong Zhang and Yongqin Li and Anthony T.C. Goh and Wengang Zhang and Zhixiong Chen},
keywords = {Anisotropic clay, Numerical analysis, Ground surface settlement, Ensemble learning},
abstract = {Excessive ground surface settlement induced by pit excavation (i.e. braced excavation) can potentially result in damage to the nearby buildings and facilities. In this paper, extensive finite element analyses have been carried out to evaluate the effects of various structural, soil and geometric properties on the maximum ground surface settlement induced by braced excavation in anisotropic clays. The anisotropic soil properties considered include the plane strain shear strength ratio (i.e. the ratio of the passive undrained shear strength to the active one) and the unloading shear modulus ratio. Other parameters considered include the support system stiffness, the excavation width to excavation depth ratio, and the wall penetration depth to excavation depth ratio. Subsequently, the maximum ground surface settlement of a total of 1479 hypothetical cases were analyzed by various machine learning algorithms including the ensemble learning methods (extreme gradient boosting (XGBoost) and random forest regression (RFR) algorithms). The prediction models developed by the XGBoost and RFR are compared with that of two conventional regression methods, and the predictive accuracy of these models are assessed. This study aims to highlight the technical feasibility and applicability of advanced ensemble learning methods in geotechnical engineering practice.}
}
@article{LOPEZ2017102,
title = {Training my car to see using virtual worlds},
journal = {Image and Vision Computing},
volume = {68},
pages = {102-118},
year = {2017},
note = {Automotive Vision: Challenges, Trends, Technologies and Systems for Vision-Based Intelligent Vehicles},
issn = {0262-8856},
doi = {https://doi.org/10.1016/j.imavis.2017.07.007},
url = {https://www.sciencedirect.com/science/article/pii/S0262885617301154},
author = {Antonio M. López and Gabriel Villalonga and Laura Sellart and Germán Ros and David Vázquez and Jiaolong Xu and Javier Marín and Azadeh Mozafari},
keywords = {ADAS, Autonomous driving, Computer vision, Object detection, Semantic segmentation, Machine learning, Data annotation, Virtual worlds, Domain adaptation},
abstract = {Computer vision technologies are at the core of different advanced driver assistance systems (ADAS) and will play a key role in oncoming autonomous vehicles too. One of the main challenges for such technologies is to perceive the driving environment, i.e. to detect and track relevant driving information in a reliable manner (e.g. pedestrians in the vehicle route, free space to drive through). Nowadays it is clear that machine learning techniques are essential for developing such a visual perception for driving. In particular, the standard working pipeline consists of collecting data (i.e. on-board images), manually annotating the data (e.g. drawing bounding boxes around pedestrians), learning a discriminative data representation taking advantage of such annotations (e.g. a deformable part-based model, a deep convolutional neural network), and then assessing the reliability of such representation with the acquired data. In the last two decades most of the research efforts focused on representation learning (first, designing descriptors and learning classifiers; later doing it end-to-end). Hence, collecting data and, especially, annotating it, is essential for learning good representations. While this has been the case from the very beginning, only after the disruptive appearance of deep convolutional neural networks that it became a serious issue due to their data hungry nature. In this context, the problem is that manual data annotation is a tiresome work prone to errors. Accordingly, in the late 00’s we initiated a research line consisting of training visual models using photo-realistic computer graphics, especially focusing on assisted and autonomous driving. In this paper, we summarize such a work and show how it has become a new tendency with increasing acceptance.}
}
@article{ALI2022111594,
title = {Towards scalable deployment of Hidden Markov models in occupancy estimation: A novel methodology applied to the study case of occupancy detection},
journal = {Energy and Buildings},
volume = {254},
pages = {111594},
year = {2022},
issn = {0378-7788},
doi = {https://doi.org/10.1016/j.enbuild.2021.111594},
url = {https://www.sciencedirect.com/science/article/pii/S0378778821008781},
author = {Samr Ali and Nizar Bouguila},
keywords = {Hidden Markov models, Machine learning, Occupancy detection, Smart buildings},
abstract = {Occupancy detection and estimation are two of the main areas of research in smart buildings. This is due to its significant effect in the deployment of energy saving buildings and various other futuristic user-centered applications. Occupancy detection refers to the determination of presence of occupants in a space or smart building, whereas occupancy estimation represents the exact determination of the number of occupants. Recently, machine learning approaches have made momentous advancements in the smart buildings field. Hidden Markov models (HMMs) have played an important role in such amelioration. Consequently, in this paper, we propose and comprehensively study a novel approach for the employment of HMMs in occupancy applications of smart buildings. In particular, the benchmark approach in the literature relies on a state-based model deployment. Hence, an implicit assumption is made that the states would automatically represent the physical phenomena of the data. This is not always the case. Our proposed framework promises a scalable stable deployment of HMMs, particularly in relation to the status quo, with model selection criteria for the determination of the number of states. Our extensive experiments show considerable improvement across the various evaluation metrics. Finally, this work also establishes multiple promising venues of future investigation for practitioners and researchers in the field, of which we discuss some of, especially at the intersection of machine learning and smart buildings.}
}
@article{JIN2021107057,
title = {Learning HDR illumination from LDR panorama images},
journal = {Computers & Electrical Engineering},
volume = {91},
pages = {107057},
year = {2021},
issn = {0045-7906},
doi = {https://doi.org/10.1016/j.compeleceng.2021.107057},
url = {https://www.sciencedirect.com/science/article/pii/S0045790621000720},
author = {Xin Jin and Xingfan Zhu and Xinxin Li and Kejun Zhang and Xiaodong Li and Xiaokun Zhang and Quan Zhou and Shujiang Xie and Xi Fang},
keywords = {Spherical harmonic lighting, All convolutional neural network, Augmented reality},
abstract = {For indoor scenes, the fourth-order spherical harmonic function is used to model the illumination, resulting in that 48 spherical harmonic coefficients are used to represent the whole scene. The illumination contained in the low dynamic range image is insufficient, so high dynamic range environment maps are adopted in this part, and the aim is to predict spherical harmonic coefficients of the corresponding high dynamic range image from the low dynamic range image. For this problem, the MSE loss function is used in this paper. Experiments verify the effectiveness of our method. The final visual results show that our method can predict accurate spherical harmonic coefficients, and the recovered luminance is realistic.}
}
@article{CARVALHO2019276,
title = {At the Edge of Industry 4.0},
journal = {Procedia Computer Science},
volume = {155},
pages = {276-281},
year = {2019},
note = {The 16th International Conference on Mobile Systems and Pervasive Computing (MobiSPC 2019),The 14th International Conference on Future Networks and Communications (FNC-2019),The 9th International Conference on Sustainable Energy Information Technology},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2019.08.039},
url = {https://www.sciencedirect.com/science/article/pii/S1877050919309536},
author = {Anderson Carvalho and Niall O’ Mahony and Lenka Krpalkova and Sean Campbell and Joseph Walsh and Pat Doody},
keywords = {Industry 4.0, edge computing, machine learning, smart agriculture},
abstract = {This research investigates the impact of edge agents on industrial plants in the era of the Internet of Things (IoT) and the increasing availability of internet connection. This paper proposes ‘Edge Agent’ a holistic solution to managing many devices on the edge and will give a brief introduction to the communication between agents and existing machinery as well as present results which were extracted from experiments performed with our solution under low load in terms of data and with a small number of devices in terms of distribution. As result of extensive architecture investigation for an optimal edge solution and its possible correlation to industrial applications, this paper will introduce edge agents, communication between agents and machinery and industrial applications. The paper will present some important findings on edge computing, compare main architectural aspects and will provide a broad view of how edge solutions might be built for this particular scenario. Having discussed how the ideal architecture works and having provided an overview about how it may be applied to industrial plants, the final section of this paper addresses how artificial intelligence will fit into edge solutions, introducing important trends like the one-shot-learning technique, forming a new source of “smart capabilities” to existing environments.}
}
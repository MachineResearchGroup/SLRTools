@inproceedings{10.1145/3318216.3363381,
author = {Babu, Naveen T. R. and Stewart, Christopher},
title = {Energy, Latency and Staleness Tradeoffs in AI-Driven IoT},
year = {2019},
isbn = {9781450367332},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3318216.3363381},
doi = {10.1145/3318216.3363381},
abstract = {AI-driven Internet of Things (IoT) use AI inference to characterize data harvested from IoT sensors. Together, AI inference and IoT support smart buildings, smart cities and autonomous vehicles. However, AI inference consumes precious energy, drains batteries and shortens IoT lifetimes. Deep sleep modes on IoT processors can save energy during long, uninterrupted idle periods. When AI software is updated frequently, scheduling policies must choose between interrupting deep sleep and degrading AI inference by delaying updates. Scheduling is challenging because of the stochastic nature of update arrivals, processing needs and updates cannot be delayed indefinitely. This paper studies scheduling policies when (1) updates (tasks) arrive frequently, (2) updates must be processed within staleness limits and (3) energy footprint is the metric of merit. We define a scheduling policy as a sequence of choices that decide when updates are applied. We use random walks to explore the space of scheduling policies and 2K r design of experiments to quantify primary effects and interactions between factors. We conducted 6 2K r tests with 5X replication each. Each test executes 1,000,000 random walks and computes their energy footprint. We simulated multiple IoT, e.g., varying the number of AI inference components from 5--500. The best random-walk policy uses much less energy than 99th and 95th percentiles. First-come-first-serve and shortest-job-first policies use 7X more energy than the best policy.},
booktitle = {Proceedings of the 4th ACM/IEEE Symposium on Edge Computing},
pages = {425–430},
numpages = {6},
location = {Arlington, Virginia},
series = {SEC '19}
}

@inproceedings{10.1145/2442992.2442998,
author = {Jahr, Ralf and Gerdes, Mike and Ungerer, Theo},
title = {A Pattern-Supported Parallelization Approach},
year = {2013},
isbn = {9781450319089},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/2442992.2442998},
doi = {10.1145/2442992.2442998},
abstract = {In the embedded systems domain a trend towards multi-and many-core processors is evident. For the exploitation of these additional processing elements parallel software is inevitable. The pattern-supported parallelization approach, which is introduced here, eases the transition from sequential to parallel software. It is a novel model-based approach with clear methodology and the use of parallel design patterns as known building blocks.First the Activity and Pattern Diagram is created revealing the maximum degree of parallelism expressed by parallel design patterns. Second the degree of parallelism is reduced to the optimal level providing best performance by agglomeration of activities and patterns. By this, trade-offs are respected that are caused by the target platform, e.g. the computation-communication-ratio.As implementation for the parallel design patterns a library with algorithmic skeletons can be used. This leverages development effort and simplifies the transition from sequential to parallel code effectively.},
booktitle = {Proceedings of the 2013 International Workshop on Programming Models and Applications for Multicores and Manycores},
pages = {53–62},
numpages = {10},
keywords = {parallelization, algorithmic skeletons, design patterns, embedded systems, extended UML2 model, model-based parallelization, parallel design patterns, parallel programming},
location = {Shenzhen, Guangdong, China},
series = {PMAM '13}
}

@inproceedings{10.1145/3325693.3325700,
author = {Sun, Fang and Sun, Xiangyi and Guan, Banglei and Li, Tao and Sun, Cong and Liu, Yingchao},
title = {Planar Homography Based Monocular SLAM Initialization Method},
year = {2019},
isbn = {9781450362467},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3325693.3325700},
doi = {10.1145/3325693.3325700},
abstract = {Simultaneous Localization and Mapping (SLAM) is a popular topic in autonomous robots navigation. It has been studied for decades in both computer vision and robotics communities. Monocular systems is more cost effective compared to RGBD or Stereo systems; however, it is relatively complicated to initialize due to scale uncertainty. Under certain conditions, it is assumed that the camera only moves in a planar scene, which provides us with homography constraints. In this paper, the efficiency of monocular initialization was improved based on the open source platform ORB-SLAM2, employing the algorithm based on planar homography constraints. We compared the improved algorithm with the source code of ORB-SLAM2 on the public datasets. It showed that our algorithm has better stability and robustness in the planar scene dataset and more initializing map points.},
booktitle = {Proceedings of the 2019 2nd International Conference on Service Robotics Technologies},
pages = {48–52},
numpages = {5},
keywords = {Homography Matrix, SLAM, Initialization algorithm},
location = {Beijing, China},
series = {ICSRT 2019}
}

@inproceedings{10.1145/3388218.3388225,
author = {Maddi, Dheeraj Reddy and Sheta, Alaa and Mahdy, Ahmed and Turabieh, Hamza},
title = {Multiple Waypoint Mobile Robot Path Planning Using Neighborhood Search Genetic Algorithms},
year = {2019},
isbn = {9781450376716},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3388218.3388225},
doi = {10.1145/3388218.3388225},
abstract = {In this paper, we present a Neighborhood Search Genetic Algorithms (NSGAs) for mobile robot path planning. GAs have been used successfully in a variety of path planning problem because they can search the space of all possible paths and provide the optimal one. The convergence process of GAs might be lengthy compared to traditional search techniques that depend on local search methods. We propose a hybrid approach that allows GAs to combine both the advantages of GAs and local search algorithms. GAs will create a multiple waypoint path allowing a mobile robot to navigate through static obstacles and finding the optimal path in order to approach the target location without collision. The proposed NSGAs has been examined over four different path planning case studies with varying complexity. The performance of the enhanced GA has been compared with A-star algorithm (A*) standard GA, particle swarm optimization (PSO) algorithm. The obtained results show that the proposed approach is able to get good results compared to other algorithms.},
booktitle = {Proceedings of the 2019 International Conference on Artificial Intelligence, Robotics and Control},
pages = {14–22},
numpages = {9},
keywords = {Neighborhood Search, Genetic Algorithm, Path Planning},
location = {Cairo, Egypt},
series = {AIRC '19}
}

@inproceedings{10.1145/3240876.3240887,
author = {Zhou, Wei and Li, Yiying and Chen, Shuhui and Zhao, Baokang},
title = {Layer-Weakening Feature Fusion Network for Remote Sensing Detection},
year = {2018},
isbn = {9781450365208},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3240876.3240887},
doi = {10.1145/3240876.3240887},
abstract = {The remote sensing detection is a challenging issue for scale diversity, diversity of views, small objects, and sophisticated light and shadow backgrounds. In this paper, inspired by the state-of-the-art detection framework FPN [6], we propose a novel approach for constructing a feature fusion mode that optimizes feature context utilization in detection, calling our resulting system LFFN for Layer-weakening Feature Fusion Network. We explore the inherent relevance of different layers to the final decision, as well as the incentives of higher-level features to lower-level features. Based on the experiments on the remote sensing dataset from Google Earth, our approach has proved effective and practical for remote sensing detection, achieving 89% mAP which is 4.1% higher than that of FPN, running at 4 to 6 FPS.},
booktitle = {Proceedings of the 10th International Conference on Internet Multimedia Computing and Service},
articleno = {14},
numpages = {6},
keywords = {layer-weakening, feature pyramid, remote sensing detection},
location = {Nanjing, China},
series = {ICIMCS '18}
}

@inproceedings{10.1145/3174910.3174914,
author = {Hashizume, Satoshi and Suzuki, Ippei and Takazawa, Kazuki and Sasaki, Ryuichiro and Ochiai, Yoichi},
title = {Telewheelchair: The Remote Controllable Electric Wheelchair System Combined Human and Machine Intelligence},
year = {2018},
isbn = {9781450354158},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3174910.3174914},
doi = {10.1145/3174910.3174914},
abstract = {Wheelchairs are essential means of transport for the elderly people and the physically challenged. However, wheelchairs need to be accompanied by caregivers. As society ages and the number of care recipients increases, the burden on caregivers is expected to increase. In order to reduce the burden on caregivers, we present Telewheelchair, an electric wheelchair equipped with a remote control function and computational operation assistance function. The caregiver can remotely control the Telewheelchair by means of a head mounted display (HMD). In addition, the proposed system is equipped with a human detection system to stop the wheelchair automatically and avoid collisions. We conducted a user study on the wheelchair in four types of systems and investigated the time taken to achieve tasks. Telewheelchair will enhance geriatric mobility and improve society by combining human intelligence and machine intelligence.},
booktitle = {Proceedings of the 9th Augmented Human International Conference},
articleno = {7},
numpages = {9},
keywords = {virtual reality, nursing, telepresence, Wheelchair},
location = {Seoul, Republic of Korea},
series = {AH '18}
}

@inproceedings{10.1109/DS-RT52167.2021.9576125,
author = {Wubben, Jamie and Cecilia, Jos\'{e} M. and Calafate, Carlos T. and Cano, Juan-Carlos and Manzoni, Pietro},
title = {Evaluating the Effectiveness of Takeoff Assignment Strategies under Irregular Configurations},
year = {2021},
isbn = {9781665433266},
publisher = {IEEE Press},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1109/DS-RT52167.2021.9576125},
doi = {10.1109/DS-RT52167.2021.9576125},
abstract = {The use of UAVs has been growing steadily over the last years. Now that even the industry is adopting them for a wide range of activities, it can be said with certainty that UAVs will become an important asset for many enterprises. We foresee that, due to affordable prices, applications with groups of UAVs, also called swarms, will become mainstream. Swarms of UAVs can perform tasks faster and/or with more redundancy, and other tasks are only possible by collaborative work of UAVs. However, there are still many challenges to be solved before swarms of UAVs can be used safely. One of the challenges is the takeoff; i.e., takeoff should be safe (no collisions) and fast at the same time. An important part of the takeoff is the assignment task; i.e., determining which UAV goes where. In this work we will compare the effectiveness of three assignment algorithms, in terms of total distance travelled, number of flight paths crossing, and calculation time. We specially focus on irregular patterns. Our results show that the Kuhn-Munkres Algorithm (KMA) is preferable in almost all cases. It ensures that the total distance travelled by all UAVs is minimal, and most importantly it reduces the number of flight paths crossing each other (i.e. potential collisions). This is a very important metric because it allows for fast (semi) simultaneous takeoff procedures, which are not possible if the chances of collision are high.},
booktitle = {Proceedings of the 2021 IEEE/ACM 25th International Symposium on Distributed Simulation and Real Time Applications},
articleno = {27},
numpages = {7},
keywords = {takeoff, UAVs, swarms, Kuhn-Munkres algorithm},
location = {Valencia, Spain},
series = {DS-RT '21}
}

@inproceedings{10.1145/3459066.3459079,
author = {Wang, Jing and Liu, Tile and Yuan, Zejian and Shang, Yuanyuan},
title = {A Robust Saliency Integrated Method for Monocular Motion Estimation},
year = {2021},
isbn = {9781450389556},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3459066.3459079},
doi = {10.1145/3459066.3459079},
abstract = {The moving objects in the background bring the challenges for motion estimation in the visual odometer applications for autonomous driving. This paper proposed a robust motion estimation method with saliency based outlier removal with a single camera in visual odometer's applications. First, an efficient saliency calculation method is proposed to detect the moving objects from the noisy monocular image sequences. Then the robust motion estimation is conducted with weighted saliency map while considering of textures area and smooth area. Experiments on KITTI dataset are conducted and the experimental results show that our proposed method with a single camera is comparable with the start-of-art stereo motion estimation method and outperform other compared stereo motion estimation methods.},
booktitle = {2021 International Conference on Machine Vision and Applications},
pages = {49–54},
numpages = {6},
keywords = {Outlier removal, Saliency, Visual odometer, Motion estimation},
location = {Singapore, Singapore},
series = {ICMVA 2021}
}

@inproceedings{10.5555/3400397.3400605,
author = {Fitwi, Alem H. and Nagothu, Deeraj and Chen, Yu and Blasch, Erik},
title = {A Distributed Agent-Based Framework for a Constellation of Drones in a Military Operation},
year = {2019},
isbn = {9781728132839},
publisher = {IEEE Press},
abstract = {A seamless communication capability is important in military operations. Likewise, enhanced security, increased capacity, and robust communication mechanisms are vital for humanitarian and disaster-response operations. Often, a system of wide-band satellites is employed for real-time exchange of information and over-the-horizon control, but the communications are prone to denial of service (DoS) attacks, and delayed redeployment. Hence, a swarm of drones could be deployed in mission-critical operations in times of urgency for a secured and robust distributed-intercommunication which is essential for survivability and successful completion of missions. In this paper, a distributed-agent-based framework for secure and reliable information exchange between drones in a constellation is proposed. The framework comprises a mechanism for path planning simulation and estimation, a flexible network architecture for improved client-server(C/S) and peer-to-peer (P2P) connectivity, as well as agents for identity authentications and secure communications. The framework has been simulated and verified with results showing promise.},
booktitle = {Proceedings of the Winter Simulation Conference},
pages = {2548–2559},
numpages = {12},
location = {National Harbor, Maryland},
series = {WSC '19}
}

@article{10.5555/3144645.3144674,
author = {Sedaghat-Pisheh, Hani and Rivera, Amaury Rodr\'{\i}guez and Biaz, Saad and Chapman, Richard},
title = {Collision Avoidance Algorithms for Unmanned Aerial Vehicles Using Computer Vision},
year = {2017},
issue_date = {December 2017},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {33},
number = {2},
issn = {1937-4771},
abstract = {We present a computer-vision-based approach to enable unmanned aerial vehicles (UAVs) to avoid collisions. To detect a moving obstacle, a machine learning algorithm, cascade classification, is used. Next, to track the obstacle, the camshift algorithm is implemented. These algorithms determine the coordinates of center of an object moving towards the UAV. Finally, to determine the distance of the object to the UAV, a stereo camera is used. Once an object is successfully tracked, the UAV will execute avoidance maneuvers if the path of the moving object conflicts with the UAV's path.},
journal = {J. Comput. Sci. Coll.},
month = {dec},
pages = {191–197},
numpages = {7}
}

@inproceedings{10.1145/3150919.3150925,
author = {Ramirez, Andres and Rahnemoonfar, Maryam},
title = {Improved Locally Linear Embedding for Big-Data Classification},
year = {2017},
isbn = {9781450354943},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3150919.3150925},
doi = {10.1145/3150919.3150925},
abstract = {A hyperspectral image provides a multidimensional data consisting of hundreds of spectral dimensions. Even though having an abundance of spectral might seem favorable, classification of hyperspectral data tends to collide with the curse of dimensionality. Therefore, reducing the number of dimensions before classification is always favorable. For this research, the feature extraction method will consist of a nonlinear manifold learning technique named locally linear embedding (LLE). Additionally, another problem that we attempt to overcome is the high computational time required to run manifold learning methods. In order to help overcome this problem, this research compares one implementation of LLE against an improved version that runs much quicker than the original version.},
booktitle = {Proceedings of the 6th ACM SIGSPATIAL Workshop on Analytics for Big Geospatial Data},
pages = {37–41},
numpages = {5},
keywords = {Hyperspectral, Locally Linear Embedding, Big-data},
location = {Redondo Beach, CA, USA},
series = {BigSpatial'17}
}

@inproceedings{10.1145/3324921.3328791,
author = {Sciancalepore, Savio and Ibrahim, Omar Adel and Oligeri, Gabriele and Di Pietro, Roberto},
title = {Detecting Drones Status via Encrypted Traffic Analysis},
year = {2019},
isbn = {9781450367691},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3324921.3328791},
doi = {10.1145/3324921.3328791},
abstract = {We propose a methodology to detect the current status of a powered-on drone (flying or at rest), leveraging just the communication traffic exchanged between the drone and its Remote Controller (RC). Our solution, other than being the first of its kind, does not require either any special hardware or to transmit any signal; it is built applying standard classification algorithms to the eavesdropped traffic, analyzing features such as packets inter-arrival time and size. Moreover, it is fully passive and it resorts to cheap and general purpose hardware. To evaluate the effectiveness of our solution, we collected real communication measurements from a drone running the widespread ArduCopter open-source firmware, mounted onboard on a wide range of commercial amateur drones. The results prove that our methodology can efficiently and effectively identify the current state of a powered-on drone, i.e., if it is flying or lying on the ground. In addition, we estimate a lower bound on the time required to identify the status of a drone with the requested level of assurance. The quality and viability of our solution do prove that network traffic analysis can be successfully adopted for drone status identification, and pave the way for future research in the area.},
booktitle = {Proceedings of the ACM Workshop on Wireless Security and Machine Learning},
pages = {67–72},
numpages = {6},
location = {Miami, FL, USA},
series = {WiseML 2019}
}

@inproceedings{10.5555/2853908.2853912,
author = {Huang, Haibin and Kalogerakis, Evangelos and Marlin, Benjamin},
title = {Analysis and Synthesis of 3D Shape Families via Deep-Learned Generative Models of Surfaces},
year = {2015},
publisher = {Eurographics Association},
address = {Goslar, DEU},
abstract = {We present a method for joint analysis and synthesis of geometrically diverse 3D shape families. Our method first learns part-based templates such that an optimal set of fuzzy point and part correspondences is computed between the shapes of an input collection based on a probabilistic deformation model. In contrast to previous template-based approaches, the geometry and deformation parameters of our part-based templates are learned from scratch. Based on the estimated shape correspondence, our method also learns a probabilistic generative model that hierarchically captures statistical relationships of corresponding surface point positions and parts as well as their existence in the input shapes. A deep learning procedure is used to capture these hierarchical relationships. The resulting generative model is used to produce control point arrangements that drive shape synthesis by combining and deforming parts from the input collection. The generative model also yields compact shape descriptors that are used to perform fine-grained classification. Finally, it can be also coupled with the probabilistic deformation model to further improve shape correspondence. We provide qualitative and quantitative evaluations of our method for shape correspondence, segmentation, fine-grained classification and synthesis. Our experiments demonstrate superior correspondence and segmentation results than previous state-of-the-art approaches.},
booktitle = {Proceedings of the Eurographics Symposium on Geometry Processing},
pages = {25–38},
numpages = {14},
location = {Graz, Austria},
series = {SGP '15}
}

@inproceedings{10.1145/3207677.3278074,
author = {Min, Yue and Wei, Zhenzhong},
title = {An Anti-Occlusion Tracking Algorithm},
year = {2018},
isbn = {9781450365123},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3207677.3278074},
doi = {10.1145/3207677.3278074},
abstract = {When1 the calculated maximum filter response score is low, traditional correlation filter-based trackers can't determine whether it's drastic target appearance change or occlusion. They will take it as drastic target appearance change and introduce plenty of wrong training samples when target being occluded. In traditional correlation filter-based tracking algorithms, the original filter and the newly trained filter are fused together to approximate their weighted combination. So, these wrong training samples will pollute the original filter and this process is irreversible. In the proposed algorithm, when trackers can't determine whether it's drastic target appearance change or occlusion, target's bounding boxes' feature maps in that period will be assigned to a candidate set as candidate training samples. An independent filter is trained by training samples in the candidate set. This filter and the original filter work together to locate the target in subsequent frames but they are not fused. Their maximum filter response scores are recorded and analysed to determine whether the target has been occluded or not. Finally, these candidate training samples are fused into the original training samples set or be abandoned according to the confirmed situation.},
booktitle = {Proceedings of the 2nd International Conference on Computer Science and Application Engineering},
articleno = {20},
numpages = {6},
keywords = {correlation filter, a candidate set, anti-occlusion, tracking},
location = {Hohhot, China},
series = {CSAE '18}
}

@inproceedings{10.1145/3397166.3413465,
author = {Bazzi, Alessandro and Campolo, Claudia and Masini, Barbara M. and Molinaro, Antonella},
title = {How to Deal with Data Hungry V2X Applications?},
year = {2020},
isbn = {9781450380157},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3397166.3413465},
doi = {10.1145/3397166.3413465},
abstract = {Current vehicular communication technologies were designed for a so-called phase 1, where cars needed to advise of their presence. Several projects, research activities and field tests have proved their effectiveness to this scope. But entering the phase 2, where awareness needs to be improved with non-connected objects and vulnerable road users, and even more with phases 3 and 4, where also coordination is foreseen, the spectrum scarcity becomes a critical issue. In this work, we provide an overview of various 5G and beyond solutions currently under investigation that will be needed to tackle the challenge. We first recall the undergoing activities at the access layer aimed to satisfy capacity and bandwidth demands. We then discuss the role that emerging networking paradigms can play to improve vehicular data dissemination, while preventing congestion and better exploiting resources. Finally, we give a look into edge computing and machine learning techniques that will be determinant to efficiently process and mine the massive amounts of sensor data.},
booktitle = {Proceedings of the Twenty-First International Symposium on Theory, Algorithmic Foundations, and Protocol Design for Mobile Networks and Mobile Computing},
pages = {333–338},
numpages = {6},
keywords = {connected and automated vehicles, cooperative sensing, vehicle-to-everything, 5G},
location = {Virtual Event, USA},
series = {Mobihoc '20}
}

@inproceedings{10.1145/3411408.3411417,
author = {Sfikas, Giorgos and Ioannidis, Dimosthenis and Tzovaras, Dimitrios},
title = {Quaternionic Keypoint Description for Multispectral Imaging},
year = {2020},
isbn = {9781450388788},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3411408.3411417},
doi = {10.1145/3411408.3411417},
abstract = { In this work, we propose a new keypoint descriptor that is suitable for multispectral inputs comprising up to 4 channels. Color images with or without an additional infrared or depth channel are some of the use-cases that can be handled by the proposed descriptor. Standard keypoint descriptors employ single-channel input gradients, thereby discarding potentially useful content. The proposed descriptor is based on a quaternionic representation of the input image thereby treating each pixel multispectral value holistically. Coupled with a suitable multispectral quaternionic detector, we show that the proposed detector leads to superior experimental results on a keypoint matching scenario.},
booktitle = {11th Hellenic Conference on Artificial Intelligence},
pages = {78–84},
numpages = {7},
keywords = {Harris corners, quaternions, polar representation, SIFT},
location = {Athens, Greece},
series = {SETN 2020}
}

@inproceedings{10.5555/2876341.2876349,
author = {Madan, Bharat B. and Bein, Doina},
title = {MOE Quantification of Missions Using Sensor Data Driven Graph Similarity Metrics},
year = {2015},
isbn = {9781510800991},
publisher = {Society for Computer Simulation International},
address = {San Diego, CA, USA},
abstract = {A mission plan consists of a set of actions to be performed in a given situation such that the specified actions mitigate the assessed situation effectively. Military missions use sensors of diverse sensing modalities for Intelligence, Reconnaissance and Surveillance (ISR). These sensors produce massive volume data, which can be fused using some established data fusion model, e.g., Joint Directorate of Laboratories (JDL) model. The Level-2 of JDL model provides situational assessment, which is defined in terms of relationships between different objects relevant to the mission context. Using this definition, we model a situation as graph G(V,E), in which the set of vertices V model the set of objects and the set of edges E models the relationships between objects. Additionally, an action taken by one or more objects can change the situation. The Measure of Effectiveness (MOE), which measures the effectiveness of actions, is an important metric of the mission performance. In a given situation sk at time k, if some action ak is performed, it leads to a new situation sk+1. The actor performing this action is interested in (i) selecting a particular action ak ∈ Ak from the set of actions Ak possible in situation sk, and (ii) effectiveness of action. This paper is concerned with quantifying the effective of actions or the MOE. The available literature on MOE has the utilized different variations of the Lanchester model and Monte Carlo simulations to compute the MOE. The paper proposes the use a novel technique of first modeling a situation as graph G(V, E) and then quantifying MOE by measuring differences between situations sk and sk+1 caused by mission actions. Modeling a situation sk as a graph Gk represented by its adjacency matrix Mk itself enables us to apply the graph similarity algorithms to measure the differences between sk and sk+1 between thus quantifying MOE of mission actions. Since a situation is derived from sensor data, as compared to existing techniques, our approach offers three advantages over existing techniques - (i) Reduced computations as compared to Monte Carlo techniques, (ii) Ability to measure situation changes and consequently the MOE, in an online manner, and (iii) Ability to deal with battle space objects of different types. The online computation of the MOE from one time epoch to the next can also be utilized to dynamically adapt missions.},
booktitle = {Proceedings of the 48th Annual Simulation Symposium},
pages = {57–61},
numpages = {5},
keywords = {measure of effectiveness, graph similarity, sensor data fusion, situation assessment, impact assessment, combat modeling},
location = {Alexandria, Virginia},
series = {ANSS '15}
}

@inbook{10.1145/3461702.3462627,
author = {Raz, Daniella and Bintz, Corinne and Guetler, Vivian and Tam, Aaron and Katell, Michael and Dailey, Dharma and Herman, Bernease and Krafft, P. M. and Young, Meg},
title = {Face Mis-ID: An Interactive Pedagogical Tool Demonstrating Disparate Accuracy Rates in Facial Recognition},
year = {2021},
isbn = {9781450384735},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3461702.3462627},
abstract = {This paper reports on the making of an interactive demo to illustrate algorithmic bias in facial recognition. Facial recognition technology has been demonstrated to be more likely to misidentify women and minoritized people. This risk, among others, has elevated facial recognition into policy discussions across the country, where many jurisdictions have already passed bans on its use. Whereas scholarship on the disparate impacts of algorithmic systems is growing, general public awareness of this set of problems is limited in part by the illegibility of machine learning systems to non-specialists. Inspired by discussions with community organizers advocating for tech fairness issues, we created the Face Mis-ID Demo to reveal the algorithmic functions behind facial recognition technology and to demonstrate its risks to policymakers and members of the community. In this paper, we share the design process behind this interactive demo, its form and function, and the design decisions that honed its accessibility, toward its use for improving legibility of algorithmic systems and awareness of the sources of their disparate impacts.},
booktitle = {Proceedings of the 2021 AAAI/ACM Conference on AI, Ethics, and Society},
pages = {895–904},
numpages = {10}
}

@inproceedings{10.5555/3320516.3320605,
author = {Fujimoto, Richard and Barjis, Joseph and Blasch, Erik and Cai, Wentong and Jin, Dong and Lee, Seunghan and Son, Young-Jun},
title = {Dynamic Data Driven Application Systems: Research Challenges and Opportunities},
year = {2018},
isbn = {978153866570},
publisher = {IEEE Press},
abstract = {Dynamic Data Driven Applications Systems (DDDAS) is a paradigm where data is dynamically integrated into an executing application, and in reverse, the application dynamically steers the measurement process in a feedback control loop. Since its inception in 2000, the DDDAS concept has been successfully applied to a host of application areas. New technologies are emerging such as big data, the Internet of Things, and cloud/edge computing. With these trends DDDAS is poised to have large-scale impacts in areas such as smart cities, manufacturing, health care, and security, to name a few. Each author describes their views concerning the important research challenges facing the DDDAS paradigm and opportunities for impact in the years ahead.},
booktitle = {Proceedings of the 2018 Winter Simulation Conference},
pages = {664–678},
numpages = {15},
location = {Gothenburg, Sweden},
series = {WSC '18}
}

@inproceedings{10.1145/3477090.3481051,
author = {Chhikara, Prateek and Tekchandani, Rajkumar and Kumar, Neeraj and Tanwar, Sudeep},
title = {Federated Learning-Based Aerial Image Segmentation for Collision-Free Movement and Landing},
year = {2021},
isbn = {9781450387057},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3477090.3481051},
doi = {10.1145/3477090.3481051},
abstract = {The utilization of drones has recently revolutionized remote sensing with their high spatial resolution and flexibility in capturing images. In the proposed work, we employ a swarm of drones that communicate in a wireless network. Each drone captures the image frames, and each frame is further used to locate and differentiate different objects in an image frame. The semantic segmentation of the captured images is done using deep learning algorithms. To identify the most suitable, cost-efficient, and accurate segmentation method, various state-of-the-art models, are appraised and compared based on different evaluation metrics. Resnet50 model with U-net segmentation model performs the best out of all used models by providing 91.51% pixel accuracy. Also, to give real-time predictions, we have used federated learning with the drone network. Each drone trains a local model using its accumulated data and then transfers the locally trained model to the central server that aggregates the received models, generates a global federated learning model, and transmits it in the swarm network.},
booktitle = {Proceedings of the 4th ACM MobiCom Workshop on Drone Assisted Wireless Communications for 5G and Beyond},
pages = {13–18},
numpages = {6},
keywords = {computer vision, internet of things, image segmentation, federated learning, aerial imaging},
location = {Virtual Event},
series = {DroneCom '21}
}

@inbook{10.1145/3474085.3475365,
author = {Hu, Lei and Huang, Shaoli and Wang, Shilei and Liu, Wei and Ning, Jifeng},
title = {Do We Really Need Frame-by-Frame Annotation Datasets for Object Tracking?},
year = {2021},
isbn = {9781450386517},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3474085.3475365},
abstract = {There has been an increasing emphasis on building large-scale datasets as the driver of deep learning-based trackers' success. However, accurately annotating tracking data is highly labor-intensive and expensive, making it infeasible in real-world applications. In this study, we investigate the necessity of large-scale training data to ensure tracking algorithms' performance. To this end, we introduce a FAT (Few-Annotation Tracking) benchmark constructed by sampling one or a few frames per video from some existing tracking datasets. The proposed dataset can be used to evaluate the effectiveness of tracking algorithms considering data efficiency and new data augmentation approaches for object tracking. We further present AMMC (Augmentation by Mimicking Motion Change), a data augmentation strategy that enables learning high-performing trackers using small-scale datasets. AMMC first cuts out the tracked targets and performs a sequence of transformations to simulate the possible change by object motion. Then the transformed targets are pasted on the inpainted background images and further conjointly augmented to mimic variability caused by camera motion. Compared with standard augmentation methods, AMMC explicitly considers tracking data characteristics, which synthesizes more valid data for object tracking. We extensively evaluate our approach with two popular trackers on the FAT datasets. Experiments show that our method allows these trackers to even trained on a dataset requiring much less annotation to achieve comparable or even better performance to those on the full-annotation dataset. The results imply complete video annotation might not be necessary for object tracking if leveraging motion-driven data augmentations during training.},
booktitle = {Proceedings of the 29th ACM International Conference on Multimedia},
pages = {4949–4957},
numpages = {9}
}

@inproceedings{10.5555/3199700.3199725,
author = {Amir, Maral and Givargis, Tony},
title = {Hybrid State Machine Model for Fast Model Predictive Control: Application to Path Tracking},
year = {2017},
publisher = {IEEE Press},
abstract = {Cyber-Physical Systems (CPS) are composed of computing devices interacting with physical systems. Model-based design is a powerful methodology in CPS design in the implementation of control systems. For instance, Model Predictive Control (MPC) is typically implemented in CPS applications, e.g., in path tracking of autonomous vehicles. MPC deploys a model to estimate the behavior of the physical system at future time instants for a specific time horizon. Ordinary Differential Equations (ODE) are the most commonly used models to emulate the behavior of continuous-time (non-)linear dynamical systems. A complex physical model may comprise thousands of ODEs which pose scalability, performance and power consumption challenges. One approach to address these model complexity challenges are frameworks that automate the development of model-to-model transformation. In this paper, we introduce a model generation framework to transform ODE models of a physical system to Hybrid Harmonic Equivalent State (HES) Machine model equivalents. Moreover, tuning parameters are introduced to reconfigure the model and adjust its accuracy from coarse-grained time critical situations to fine-grained scenarios in which safety is paramount. Machine learning techniques are applied to adopt the model to run-time applications. We conduct experiments on a closed-loop MPC for path tracking using the vehicle dynamics model. We analyze the performance of the MPC when applying our Hybrid HES Machine model. The performance of our proposed model is compared with state-of-the-art ODE-based models, in terms of execution time and model accuracy. Our experimental results show a 32% reduction in MPC return time for 0.8% loss in model accuracy.},
booktitle = {Proceedings of the 36th International Conference on Computer-Aided Design},
pages = {185–192},
numpages = {8},
keywords = {simulation, modeling, state machine, FFT, CPS, model generation, model-based design},
location = {Irvine, California},
series = {ICCAD '17}
}

@inproceedings{10.1145/3415958.3433039,
author = {Peinl, Peter},
title = {A Retrospective on ASPires: An Advanced System for the Prevention and Early Detection of Forest Fires},
year = {2020},
isbn = {9781450381154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3415958.3433039},
doi = {10.1145/3415958.3433039},
abstract = {In this paper, we describe the design and a prototypical implementation of an open system (ASPires) for the early prevention and early detection of forest fires. Forest fires cause huge, constantly increasing material damage and immaterial costs to humans, the environment and property. Among others, the use of new sensor and mobile communication technologies, the use of drones, data storage and analysis in a cloud, and direct connection with authorities reduces reaction time and thereby damage. Also, biodiversity is sustained in remote areas with rare and endemic species of flora and fauna. This has been tested and proven in 3 national parks in South East Europe.},
booktitle = {Proceedings of the 12th International Conference on Management of Digital EcoSystems},
pages = {30–37},
numpages = {8},
keywords = {sensors, Internet of Things, Open system, forest fire prevention and detection, Biodiversity, wireless communication technologies, drones, cloud},
location = {Virtual Event, United Arab Emirates},
series = {MEDES '20}
}

@inproceedings{10.5555/3433701.3433716,
author = {Zhang, Jian and Xie, Tao and Jing, Yuzhuo and Song, Yanjie and Hu, Guanzhou and Chen, Si and Yin, Shu},
title = {BORA: A Bag Optimizer for Robotic Analysis},
year = {2020},
isbn = {9781728199986},
publisher = {IEEE Press},
abstract = {We present BORA (Bag Optimizer for Robotic Analysis), a file system middleware that optimizes the acquisition of bags, which are specially formatted files used to store timestamped ROS (robot operating system) messages. BORA sits between ROS and an existing file system to conduct semantic-aware data pre-processing. In particular, it categorizes ROS bag data into multiple groups with each having a distinct label. BORA predigests data index constructions and reduces file open time via a hash-based label management scheme. It is also capable of providing ROS analytic applications with only data needed without a sequence of data searching and locating operations. We implement a BORA prototype, which is then integrated into three computing platforms: a single-node server, a four-node PVFS storage cluster, and a Tianhe-1A Supercomputer storage subsystem. Next, we evaluate the BORA prototype on the three platforms using four real-world ROS applications. Our experimental results show that compared to a traditional bag management scheme BORA improves data acquisition performance by up to 11x. In addition, it offers up to 10x data acquisition performance improvement and 3,100x bags open improvement under a swarm robotics data analysis scenario where data is retrieved across multiple bags simultaneously.},
booktitle = {Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis},
articleno = {12},
numpages = {15},
location = {Atlanta, Georgia},
series = {SC '20}
}

@article{10.1145/3310012,
author = {M\"{u}nster, Sander},
title = {Digital Heritage as a Scholarly Field—Topics, Researchers, and Perspectives from a Bibliometric Point of View},
year = {2019},
issue_date = {October 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {12},
number = {3},
issn = {1556-4673},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3310012},
doi = {10.1145/3310012},
abstract = {Digital heritage comprises a broad variety of approaches and topics and involves researchers from multiple disciplines. Against this background, this article presents a four-stage investigation on standards, publications, disciplinary cultures, as well as scholars in the field of digital heritage and particularly tangible objects as monuments and sites, carried out in 2016 and 2017. It includes results of (1) the inquiry of nearly 4,000 publications from major conferences, (2) a workshop-based survey involving 44 researchers, (3) 15 qualitative interviews, as well as (4) two online surveys with 1,000 and 700 participants, respectively. As an overall finding, the community is driven by researchers from European countries, especially Italy, with a background in humanities. Cross-national co-authorships are promoted by cultural and spatial closeness and—probably due to funding policy—EU membership. A discourse is primarily driven by technologies, and the most common keywords refer to the technologies used. Most prominent research areas are data acquisition and management, visualization, and analysis. Recent topics are, for instance, unmanned airborne vehicle (UAV)-based 3D surveying technologies, augmented and virtual reality visualization, metadata and paradata standards for documentation, and virtual museums. Since a lack of money is named as the biggest obstacle nowadays, competency and human resources are most frequently named as demand. An epistemic culture in the scholarly field of digital heritage is closer to engineering than to humanities. Moreover, conference series are most relevant for a scientific discourse, and especially EU projects set pace as most important research endeavors.},
journal = {J. Comput. Cult. Herit.},
month = {jul},
articleno = {22},
numpages = {27},
keywords = {Digital Heritage, topics, survey, scholarly field}
}

@inproceedings{10.5555/2772879.2773298,
author = {Chen, Yingke and Doshi, Prashant and Zeng, Yifeng},
title = {Iterative Online Planning in Multiagent Settings with Limited Model Spaces and PAC Guarantees},
year = {2015},
isbn = {9781450334136},
publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
address = {Richland, SC},
abstract = {Methods for planning in multiagent settings often model other agents' possible behaviors. However, the space of these models - whether these are policy trees, finite-state controllers or intentional models - is very large and thus arbitrarily bounded. This may exclude the true model or the optimal model. In this paper, we present a novel iterative algorithm for online planning that considers a limited model space, updates it dynamically using data from interactions, and provides a provable and probabilistic bound on the approximation error. We ground this approach in the context of graphical models for planning in partially observable multiagent settings - interactive dynamic influence diagrams. We empirically demonstrate that the limited model space facilitates fast solutions and that the true model often enters the limited model space.},
booktitle = {Proceedings of the 2015 International Conference on Autonomous Agents and Multiagent Systems},
pages = {1161–1169},
numpages = {9},
keywords = {mental models, influence diagram, online planning, multiple agents},
location = {Istanbul, Turkey},
series = {AAMAS '15}
}

@inproceedings{10.5555/2343576.2343637,
author = {Colby, Mitchell and Tumer, Kagan},
title = {Shaping Fitness Functions for Coevolving Cooperative Multiagent Systems},
year = {2012},
isbn = {0981738117},
publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
address = {Richland, SC},
abstract = {Coevolution is a natural approach to evolve teams of agents which must cooperate to achieve some system objective. However, in many coevolutionary approaches, credit assignment is often subjective and context dependent, as the fitness of an individual agent strongly depends on the actions of the agents with which it collaborates. In order to alleviate this problem, we introduce a cooperative coevolutionary algorithm which biases the evolutionary search as well as shapes agent fitness functions to reward behavior that benefits the system. More specifically, we bias the search using a hall of fame approximation of optimal collaborators, and we shape the agent fitness using the difference evaluation function. Our results show that shaping agent fitness with the difference evaluation improves system performance by up to 50%, and adding an additional fitness bias can improve performance by up to 75%.},
booktitle = {Proceedings of the 11th International Conference on Autonomous Agents and Multiagent Systems - Volume 1},
pages = {425–432},
numpages = {8},
keywords = {multiagent learning, co-evolution},
location = {Valencia, Spain},
series = {AAMAS '12}
}

@inproceedings{10.1145/3351108.3351124,
author = {James, Katherine and Bradshaw, Karen},
title = {Segmenting Objects with Indistinct Edges, with Application to Aerial Imagery of Vegetation},
year = {2019},
isbn = {9781450372657},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3351108.3351124},
doi = {10.1145/3351108.3351124},
abstract = {Image segmentation mask creation relies on objects having distinct edges. While this may be true for the objects seen in many image segmentation challenges, it is less so when approaching tasks such as segmentation of vegetation in aerial imagery. Such datasets contain indistinct edges, or areas of mixed information at edges, which introduces a level of annotator subjectivity at edge pixels. Existing loss functions apply equal learning ability to both these pixels of low and high annotation confidence. In this paper, we propose a weight map based loss function that takes into account low confidence in the annotation at edges of objects by down-weighting the contribution of these pixels to the overall loss. We examine different weight map designs to find the most optimal one when applied to a dataset of aerial imagery of vegetation, with the task of segmenting a particular genus of shrub from other land cover types. When compared to inverse class frequency weighted binary cross-entropy loss, we found that using weight map based loss produced a better performing model than binary cross-entropy loss, improving F1 score by 4%.},
booktitle = {Proceedings of the South African Institute of Computer Scientists and Information Technologists 2019},
articleno = {15},
numpages = {7},
keywords = {image segmentation, indistinct edges, vegetation segmentation, aerial imagery},
location = {Skukuza, South Africa},
series = {SAICSIT '19}
}

@inproceedings{10.1145/3474944.3474960,
author = {Chen, Jie and Ji, Xuan and Wu, Junhui and Wu, Yusheng and Lin, Kaiyan and Si, Huiping},
title = {Review of Research on Irrigation Decision Control},
year = {2021},
isbn = {9781450389280},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3474944.3474960},
doi = {10.1145/3474944.3474960},
abstract = {With the development of intelligent control technology in the field of agriculture, the research of intelligent irrigation decision control has been widely concerned by scholars. Soil moisture, crop physiology and environment all have important influence on the precision of irrigation decision, and the influence is nonlinear and fuzzy. Therefore, it is difficult to build an accurate mathematical model to abtain an accurate irrigation scheme. How to combine the crop with other influencing factors, use sensor technology and intelligent control technology to build an intelligent irrigation decision-making system is an urgent problem need to be solved in irrigation decision-making. This article presents a comprehensive review of irrigation decision control from the aspects of expert system, fuzzy control and neural network. And pointing out the problems that need to be solved by various intelligent methods in irrigation decision making.},
booktitle = {2021 the 3rd International Conference on Big Data Engineering and Technology (BDET)},
pages = {94–98},
numpages = {5},
keywords = {Control systems, Irrigation control, Precision irrigation, Decision support system},
location = {Singapore, Singapore},
series = {BDET 2021}
}

@inproceedings{10.1145/2967938.2967963,
author = {Bodin, Bruno and Nardi, Luigi and Zia, M. Zeeshan and Wagstaff, Harry and Sreekar Shenoy, Govind and Emani, Murali and Mawer, John and Kotselidis, Christos and Nisbet, Andy and Lujan, Mikel and Franke, Bj\"{o}rn and Kelly, Paul H.J. and O'Boyle, Michael},
title = {Integrating Algorithmic Parameters into Benchmarking and Design Space Exploration in 3D Scene Understanding},
year = {2016},
isbn = {9781450341219},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/2967938.2967963},
doi = {10.1145/2967938.2967963},
abstract = {System designers typically use well-studied benchmarks to evaluate and improve new architectures and compilers. We design tomorrow's systems based on yesterday's applications. In this paper we investigate an emerging application, 3D scene understanding, likely to be significant in the mobile space in the near future. Until now, this application could only run in real-time on desktop GPUs. In this work, we examine how it can be mapped to power constrained embedded systems. Key to our approach is the idea of incremental co-design exploration, where optimization choices that concern the domain layer are incrementally explored together with low-level compiler and architecture choices. The goal of this exploration is to reduce execution time while minimizing power and meeting our quality of result objective. As the design space is too large to exhaustively evaluate, we use active learning based on a random forest predictor to find good designs. We show that our approach can, for the first time, achieve dense 3D mapping and tracking in the real-time range within a 1W power budget on a popular embedded device. This is a 4.8x execution time improvement and a 2.8x power reduction compared to the state-of-the-art.},
booktitle = {Proceedings of the 2016 International Conference on Parallel Architectures and Compilation},
pages = {57–69},
numpages = {13},
keywords = {design space exploration, dse, slam, computer vision, embedded systems},
location = {Haifa, Israel},
series = {PACT '16}
}

@inbook{10.1145/3341105.3373996,
author = {Rehman, Abdul and Paul, Anand and Yaqub, Muhammad Azfar and Rathore, Muhammad Mazhar Ullah},
title = {Trustworthy Intelligent Industrial Monitoring Architecture for Early Event Detection by Exploiting Social IoT},
year = {2020},
isbn = {9781450368667},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3341105.3373996},
abstract = {Catastrophes like conflagration, noxious gases, chemical leakages, toxic smoke, and mishaps due to unsafe distance from the jeopardous situations are very common in industrial environment. Such calamities can cause colossal fiscal and loss of human lives. Adroit surveillance and early detection of such perilous events can impede the fiscal and social fiasco. In this research, an Industrial Smart Social Agent (ISSA) and Industrial Social Internet of Things (ISIoT) paradigm are introduced which empowers the intelligent objects to interact independently. ISSA entrust every IIoT object to communicate and collaborate with one and all to augment the surveillance in every industrial environment. ISSA controls all intelligent surveillance devices (i.e. sensors, cameras, robots etc.,) for monitoring and uses Machine Learning based Algorithm for event detection. Therefore, the proposed adroit surveillance system accomplishes early event detection resulting in minimum monetary and personnel damage.},
booktitle = {Proceedings of the 35th Annual ACM Symposium on Applied Computing},
pages = {2163–2169},
numpages = {7}
}

@inbook{10.1145/3233795.3233812,
author = {Cohen, Philip R. and Tumuluri, Raj},
title = {Commercialization of Multimodal Systems},
year = {2019},
isbn = {9781970001754},
publisher = {Association for Computing Machinery and Morgan &amp; Claypool},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3233795.3233812},
booktitle = {The Handbook of Multimodal-Multisensor Interfaces: Language Processing, Software, Commercialization, and Emerging Directions},
pages = {621–658},
numpages = {38}
}

@inbook{10.1145/3447548.3467422,
author = {Yang, Menglin and Zhou, Min and Kalander, Marcus and Huang, Zengfeng and King, Irwin},
title = {Discrete-Time Temporal Network Embedding via Implicit Hierarchical Learning in Hyperbolic Space},
year = {2021},
isbn = {9781450383325},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3447548.3467422},
abstract = {Representation learning over temporal networks has drawn considerable attention in recent years. Efforts are mainly focused on modeling structural dependencies and temporal evolving regularities in Euclidean space which, however, underestimates the inherent complex and hierarchical properties in many real-world temporal networks, leading to sub-optimal embeddings. To explore these properties of a complex temporal network, we propose a hyperbolic temporal graph network (HTGN) that fully takes advantage of the exponential capacity and hierarchical awareness of hyperbolic geometry. More specially, HTGN maps the temporal graph into hyperbolic space, and incorporates hyperbolic graph neural network and hyperbolic gated recurrent neural network, to capture the evolving behaviors and implicitly preserve hierarchical information simultaneously. Furthermore, in the hyperbolic space, we propose two important modules that enable HTGN to successfully model temporal networks: (1) hyperbolic temporal contextual self-attention (HTA) module to attend to historical states and (2) hyperbolic temporal consistency (HTC) module to ensure stability and generalization. Experimental results on multiple real-world datasets demonstrate the superiority of HTGN for temporal graph embedding, as it consistently outperforms competing methods by significant margins in various temporal link prediction tasks. Specifically, HTGN achieves AUC improvement up to 9.98% for link prediction and 11.4% for new link prediction. Moreover, the ablation study further validates the representational ability of hyperbolic geometry and the effectiveness of the proposed HTA and HTC modules.},
booktitle = {Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery &amp; Data Mining},
pages = {1975–1985},
numpages = {11}
}

@inproceedings{10.1145/3427796.3428480,
author = {Alsoliman, Anas and Rigoni, Giulio and Levorato, Marco and Pinotti, Cristina and Tippenhauer, Nils Ole and Conti, Mauro},
title = {COTS Drone Detection Using Video Streaming Characteristics},
year = {2021},
isbn = {9781450389334},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3427796.3428480},
doi = {10.1145/3427796.3428480},
abstract = {Cheap commercial off-the-shelf (COTS) drones have become widely available for consumers in recent years. Unfortunately, they also provide low-cost capabilities for attackers. Therefore, effective methods to detect the presence of non-cooperating rogue drones within a restricted area are highly required. Approaches based on detection of control traffic have been proposed but were not yet shown to work against other benign traffic, such as that generated by wireless security cameras. In this work, we propose a novel drone detection framework based on a Random Forest classification model. In essence, the framework leverages specific patterns in video traffic transmitted by drones. The patterns consist of repetitive synchronization packets (denoted as pivots) which we use as features in the proposed machine learning classifier. We show that our framework can achieve up to 99% detection accuracy over an encrypted WiFi channel using only 20 packets originated from the drone. Our system is able to identify drone transmissions even among very similar WiFi transmission (such as a security camera video stream) and in a noisy scenario with background traffic.},
booktitle = {International Conference on Distributed Computing and Networking 2021},
pages = {166–175},
numpages = {10},
location = {Nara, Japan},
series = {ICDCN '21}
}

@article{10.1145/3377000.3377002,
author = {Hu, Yingjie and Gao, Song and Lunga, Dalton and Li, Wenwen and Newsam, Shawn and Bhaduri, Budhendra},
title = {GeoAI at ACM SIGSPATIAL: Progress, Challenges, and Future Directions},
year = {2019},
issue_date = {July 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {11},
number = {2},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3377000.3377002},
doi = {10.1145/3377000.3377002},
abstract = {Geospatial artificial intelligence (GeoAI) is an interdisciplinary field that has received tremendous attention from both academia and industry in recent years. This article reviews the series of GeoAI workshops held at the Association for Computing Machinery (ACM) International Conference on Advances in Geographic Information Systems (SIGSPATIAL) since 2017. These workshops have provided researchers a forum to present GeoAI advances covering a wide range of topics, such as geospatial image processing, transportation modeling, public health, and digital humanities. We provide a summary of these topics and the research articles presented at the 2017, 2018, and 2019 GeoAI workshops. We conclude with a list of open research directions for this rapidly advancing field.},
journal = {SIGSPATIAL Special},
month = {dec},
pages = {5–15},
numpages = {11}
}

@article{10.1145/3447748,
author = {Shihada, Basem and Elbatt, Tamer and Eltawil, Ahmed and Mansour, Mohammad and Sabir, Essaid and Rekhis, Slim and Sharafeddine, Sanaa},
title = {Networking Research for the Arab World: From Regional Initiatives to Potential Global Impact},
year = {2021},
issue_date = {April 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {64},
number = {4},
issn = {0001-0782},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3447748},
doi = {10.1145/3447748},
journal = {Commun. ACM},
month = {mar},
pages = {114–119},
numpages = {6}
}

@inproceedings{10.5555/3437539.3437640,
author = {Zhang, Runyu and Liu, Duo and Chen, Xianzhang and She, Xiongxiong and Yang, Chaoshu and Tan, Yujuan and Shen, Zhaoyan and Shao, Zili},
title = {LOFFS: A Low-Overhead File System for Large Flash Memory on Embedded Devices},
year = {2020},
isbn = {9781450367257},
publisher = {IEEE Press},
abstract = {Emerging applications like machine learning in embedded devices (e.g., satellite and vehicles) require huge storage space, which recently stimulates the widespread deployment of large-capacity flash memory in IoT devices. However, existing embedded file systems fall short in managing large-capacity storage efficiently for excessive memory consumption and poor booting performance. In this paper, we propose a novel embedded file system, LOFFS, to tackle the above issues and manage large-capacity NAND flash on resource-limited embedded devices. We redesign the space management mechanisms and construct hybrid file structures to achieve high performance with minimum resource occupation. We have implemented LOFFS in Linux, and the experimental results show that LOFFS outperforms YAFFS by 55.8% on average with orders of magnitude reductions on memory footprint.},
booktitle = {Proceedings of the 57th ACM/EDAC/IEEE Design Automation Conference},
articleno = {101},
numpages = {6},
keywords = {NAND flash, file system, embedded},
location = {Virtual Event, USA},
series = {DAC '20}
}

@inproceedings{10.1145/3213526.3213531,
author = {Misra, Prasant and Kandaswamy, Gopi and Mohapatra, Pragyan and Kumar, Kriti and Balamuralidhar, P.},
title = {Structural Health Monitoring of Multi-Rotor Micro Aerial Vehicles},
year = {2018},
isbn = {9781450358392},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3213526.3213531},
doi = {10.1145/3213526.3213531},
abstract = {Structural Health Monitoring (SHM) is a key troubleshooting methodology for assessing the working condition and health of (manned or unmanned) aerial vehicles; however, its understanding with respect to the multi-rotor class of Micro Aerial Vehicles (MAV) is limited. The portentous structural failure sources, in this case, are the two moving components: motors and propellers. In this paper, we undertake a detailed exercise of characterizing the common and frequent faults of these units using multi-modal sensing of vibration, acoustic noise, input power, and thrust profiles; and then use relevant features to perform a two-level diagnosis. Through our empirical fault studies on our custom designed test rig, we propose a set of befitting features in each sensory domain; which result in high fault detection and classification accuracy that exceeds 90%.},
booktitle = {Proceedings of the 4th ACM Workshop on Micro Aerial Vehicle Networks, Systems, and Applications},
pages = {21–26},
numpages = {6},
keywords = {Machine Analytics, Structural Health Monitoring, Multi-rotor MAV, Fault Detection and Classification, Sensor Informatics},
location = {Munich, Germany},
series = {DroNet'18}
}

@inproceedings{10.5555/3395101.3395134,
author = {Wubben, Jamie and Fabra, Francisco and Calafate, Carlos T. and Krzeszowski, Tomasz and Marquez-Barja, Johann M. and Cano, Juan-Carlos and Manzoni, Pietro},
title = {A Vision-Based System for Autonomous Vertical Landing of Unmanned Aerial Vehicles},
year = {2019},
isbn = {9781728129235},
publisher = {IEEE Press},
abstract = {Over the last few years, different researchers have been developing protocols and applications in order to land unmanned aerial vehicles (UAVs) autonomously. However, most of the proposed protocols rely on expensive equipment or do not satisfy the high precision needs of some UAV applications, such as package retrieval and delivery. Therefore, in this paper, we present a solution for high precision landing based on the use of ArUco markers. In our solution, a UAV equipped with a camera is able to detect ArUco markers from an altitude of 20 meters. Once the marker is detected, the UAV changes its flight behavior in order to land on the exact position where the marker is located. We evaluated our proposal using our own UAV simulation platform (ArduSim), and validated it using real UAVs. The results show an average offset of only 11 centimeters, which vastly improves the landing accuracy compared to the traditional GPS-based landing, that typically deviates from the intended target by 1 to 3 meters.},
booktitle = {Proceedings of the 23rd IEEE/ACM International Symposium on Distributed Simulation and Real Time Applications},
pages = {188–194},
numpages = {7},
location = {Cosenza, Italy},
series = {DS-RT '19}
}

@article{10.1145/3454008,
author = {Chandra, Ranveer and Collis, Stewart},
title = {Digital Agriculture for Small-Scale Producers: Challenges and Opportunities},
year = {2021},
issue_date = {December 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {64},
number = {12},
issn = {0001-0782},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3454008},
doi = {10.1145/3454008},
abstract = {Smart Farming with technologies such as IoT, computer vision, and AI can improve agricultural efficiency, transparency, profitability, and equity for farmers in low-and middle-income countries.},
journal = {Commun. ACM},
month = {nov},
pages = {75–84},
numpages = {10}
}

@inproceedings{10.1145/3330482.3330524,
author = {Cadiz, Luis G. and Hernandez, Alexander A.},
title = {Hybrid Detection for Vehicle Blind Spot Using Fisheye Camera: A Framework},
year = {2019},
isbn = {9781450361064},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3330482.3330524},
doi = {10.1145/3330482.3330524},
abstract = {Many vehicular accidents occur because of a blind spot. Previous studies of blind spot reveal that an algorithm becomes weak if the car is near, car detection is 5 to 10 meters only, and the detection rate is not high. A study on fisheye detection using hybrid algorithms for vehicle blind spots can address the issues about accidents in the national and city roads. The hybrid algorithms involved for vehicle detections are rapid AdaBoost Classifier, Background Subtraction, and Color Edge Detection. This study can be very efficient and can give more accurate vehicle detection. As a result, the study will give the driver's awareness and warning from the incoming threats for any untoward accidents.},
booktitle = {Proceedings of the 2019 5th International Conference on Computing and Artificial Intelligence},
pages = {250–253},
numpages = {4},
keywords = {blinds-spot, fisheye camera, hybrid, AdaBoost, color edge detection background subtraction},
location = {Bali, Indonesia},
series = {ICCAI '19}
}

@article{10.1145/3149180,
author = {Moreno, Gabriel A. and C\'{a}mara, Javier and Garlan, David and Schmerl, Bradley},
title = {Flexible and Efficient Decision-Making for Proactive Latency-Aware Self-Adaptation},
year = {2018},
issue_date = {March 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {13},
number = {1},
issn = {1556-4665},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3149180},
doi = {10.1145/3149180},
abstract = {Proactive latency-aware adaptation is an approach for self-adaptive systems that considers both the current and anticipated adaptation needs when making adaptation decisions, taking into account the latency of the available adaptation tactics. Since this is a problem of selecting adaptation actions in the context of the probabilistic behavior of the environment, Markov decision processes (MDPs) are a suitable approach. However, given all the possible interactions between the different and possibly concurrent adaptation tactics, the system, and the environment, constructing the MDP is a complex task. Probabilistic model checking has been used to deal with this problem, but it requires constructing the MDP every time an adaptation decision is made to incorporate the latest predictions of the environment behavior. In this article, we describe PLA-SDP, an approach that eliminates that runtime overhead by constructing most of the MDP offline. At runtime, the adaptation decision is made by solving the MDP through stochastic dynamic programming, weaving in the environment model as the solution is computed. We also present extensions that support different notions of utility, such as maximizing reward gain subject to the satisfaction of a probabilistic constraint, making PLA-SDP applicable to systems with different kinds of adaptation goals.},
journal = {ACM Trans. Auton. Adapt. Syst.},
month = {apr},
articleno = {3},
numpages = {36},
keywords = {proactive latency awareness, Self-adaptive systems, Markov decision process}
}

@article{10.1145/3490032,
author = {Gao, Fei and Li, Jiada and Ge, Yisu and Shao, Jianwen and Lu, Shufang and Weng, Libo},
title = {A Trajectory Evaluator by Sub-Tracks for Detecting VOT-Based Anomalous Trajectory},
year = {2022},
issue_date = {August 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {16},
number = {4},
issn = {1556-4681},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3490032},
doi = {10.1145/3490032},
abstract = {With the popularization of visual object tracking (VOT), more and more trajectory data are obtained and have begun to gain widespread attention in the fields of mobile robots, intelligent video surveillance, and the like. How to clean the anomalous trajectories hidden in the massive data has become one of the research hotspots. Anomalous trajectories should be detected and cleaned before the trajectory data can be effectively used. In this article, a Trajectory Evaluator by Sub-tracks (TES) for detecting VOT-based anomalous trajectory is proposed. Feature of Anomalousness is defined and described as the Eigenvector of classifier to filter Track Lets anomalous trajectory and IDentity Switch anomalous trajectory, which includes Feature of Anomalous Pose and Feature of Anomalous Sub-tracks (FAS). In the comparative experiments, TES achieves better results on different scenes than state-of-the-art methods. Moreover, FAS makes better performance than point flow, least square method fitting and Chebyshev Polynomial Fitting. It is verified that TES is more accurate and effective and is conducive to the sub-tracks trajectory data analysis.},
journal = {ACM Trans. Knowl. Discov. Data},
month = {jan},
articleno = {67},
numpages = {19},
keywords = {trajectory analysis, data mining, anomalous trajectory detection, Data cleaning}
}

@inproceedings{10.1145/2746285.2746318,
author = {Tarsa, Stephen J. and Comiter, Marcus and Crouse, Michael B. and McDanel, Bradley and Kung, H.T.},
title = {Taming Wireless Fluctuations by Predictive Queuing Using a Sparse-Coding Link-State Model},
year = {2015},
isbn = {9781450334891},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/2746285.2746318},
doi = {10.1145/2746285.2746318},
abstract = {We introduce State-Informed Link-Layer Queuing (SILQ), a system that models, predicts, and avoids packet delivery failures caused by temporary wireless outages in everyday scenarios. By stabilizing connections in adverse link conditions, SILQ boosts throughput and reduces performance variation for network applications, for example by preventing unnecessary TCP timeouts due to dead zones, elevators, and subway tunnels. SILQ makes predictions in real-time by actively probing links, matching measurements to an overcomplete dictionary of patterns learned offline, and classifying the resulting sparse feature vectors to identify those that precede outages. We use a clustering method called sparse coding to build our data-driven link model, and show that it produces more variation-tolerant predictions than traditional loss-rate, location-based, or Markov chain techniques.We present extensive data collection and field-validation of SILQ in airborne, indoor, and urban scenarios of practical interest. We show how offline unsupervised learning discovers link-state patterns that are stable across diverse networks and signal-propagation environments. Using these canonical primitives, we train outage predictors for 802.11 (Wi-Fi) and 3G cellular networks to demonstrate TCP throughput gains of 4x with off-the-shelf mobile devices. SILQ addresses delivery failures solely at the link layer, requires no new hardware, and upholds the end-to-end design principle, to enable easy integration across applications, devices, and networks.},
booktitle = {Proceedings of the 16th ACM International Symposium on Mobile Ad Hoc Networking and Computing},
pages = {287–296},
numpages = {10},
keywords = {tcp, cellular data networks, 802.11 (wi-fi), sparse coding, wireless networking, data-driven model learning},
location = {Hangzhou, China},
series = {MobiHoc '15}
}

@inproceedings{10.1145/3290607.3310433,
author = {Keyes, Os and Hutson, Jevan and Durbin, Meredith},
title = {A Mulching Proposal: Analysing and Improving an Algorithmic System for Turning the Elderly into High-Nutrient Slurry},
year = {2019},
isbn = {9781450359719},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3290607.3310433},
doi = {10.1145/3290607.3310433},
abstract = {The ethical implications of algorithmic systems have been much discussed in both HCI and the broader community of those interested in technology design, development and policy. In this paper, we explore the application of one prominent ethical framework-Fairness, Accountability, and Transparency-to a proposed algorithm that resolves various societal issues around food security and population ageing. Using various standardised forms of algorithmic audit and evaluation, we drastically increase the algorithm's adherence to the FAT framework, resulting in a more ethical and beneficent system. We discuss how this might serve as a guide to other researchers or practitioners looking to ensure better ethical outcomes from algorithmic systems in their line of work.},
booktitle = {Extended Abstracts of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11},
keywords = {algorithmic critique, transparency, accountability, dystopia, fairness, computer vision, algorithmic analysis, ethics},
location = {Glasgow, Scotland Uk},
series = {CHI EA '19}
}

@inproceedings{10.1145/3376067.3376098,
author = {Liu, Zihao and Xu, Haiqin and Zhang, Yihong and Xu, Zhouyi and Wu, Sen and Zhu, Di},
title = {A Real-Time Detection Drone Algorithm Based on Instance Semantic Segmentation},
year = {2019},
isbn = {9781450376822},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3376067.3376098},
doi = {10.1145/3376067.3376098},
abstract = {With the rapid development of drones, drones are widely used in various fields and bring convenience to people's production and life. However, they also bring security problems to society and the country. Especially in airports or military areas, the flight of drones can cause some problems. In order to effectively supervise the drone, this paper proposes a real-time detection drone algorithm HR-YOLACT which is based on instance semantic segmentation, and designed a new drone data set. The proposed algorithm combines the real-time instance semantic segmentation algorithm YOLACT with the deep high-resolution representation classification network HRNet. Firstly, feature maps are extracted by HRNet's backbone network. Secondly, the feature pyramid network is used to further extract image features, so that the network has better classification ability. Finally, the improved prediction head is utilized to detect the boxes of drones. In addition, this paper uses cross entropy instead of focal loss as the loss function to obtain better network training speed and quality. The experimental results show that HR-YOLACT has faster detection speed and higher detection precision than existing popular real-time object detection and real-time instance semantic segmentation algorithms.},
booktitle = {Proceedings of the 3rd International Conference on Video and Image Processing},
pages = {36–41},
numpages = {6},
keywords = {Drones detection, pattern recognition, instance semantic segmentation},
location = {Shanghai, China},
series = {ICVIP 2019}
}

@inbook{10.1145/3479239.3485700,
author = {Heimann, Karsten and Sliwa, Benjamin and Patchou, Manuel and Wietfeld, Christian},
title = {Modeling and Simulation of Reconfigurable Intelligent Surfaces for Hybrid Aerial and Ground-Based Vehicular Communications},
year = {2021},
isbn = {9781450390774},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3479239.3485700},
abstract = {The requirements of vehicular communications grow with increasing level of automated driving and future applications of intelligent transportation systems (ITS). Beside the ever-increasing need for high capacity radio links, reliability and latency constraints challenge the mobile network supply. While for example the millimeter-wave spectrum and THz-bands offer a vast amount of radio resources, their applicability is limited due to delicate radio channel conditions and signal propagation characteristics. Reconfigurable intelligent surfaces (RISs) as part of smart radio environments (SREs) of future ITS infrastructure promise improved radio link qualities by means of purposeful cultivation of passive reflections. With this, obstructed mmWave or THz beams can be guided around obstacles through RIS reflection paths to improve the otherwise limited coverage. In this article, application use cases of RIS-enhanced vehicular communications are proposed. Beside static deployments of RISs at exterior walls of buildings, unmanned aerial vehicles (UAV) could provide reflection capabilities on demand, while future vehicles could - in a visionary approach - consist of meta-material allowing for their opportunistic utilization within an enriched SRE. Results of a case study based on our multi-scale mobility and network simulation model clearly highlight the potential of RIS deployment for hybrid vehicular communication scenarios. Path loss and outage percentages can be reduced considerably.},
booktitle = {Proceedings of the 24th International ACM Conference on Modeling, Analysis and Simulation of Wireless and Mobile Systems},
pages = {67–74},
numpages = {8}
}

@inproceedings{10.1145/2683405.2683451,
author = {Shimazaki, Rikki and Green, Richard},
title = {Perimeter Detection of Burnt Rural Fire Regions},
year = {2014},
isbn = {9781450331845},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/2683405.2683451},
doi = {10.1145/2683405.2683451},
abstract = {Rural fires are dangerous, and even after a fire has been extinguished hidden hotspots can continue to burn under burnt foliage. To aid in the post fire investigation procedure this paper proposes a method to locate the perimeter of a burnt fire region on the ground from an aerial camera. This process involves a boundary detection application which applies texture boundary detection algorithms. The Variance Ridge Detector can detect texture-boundaries in real-time yet still results in a high quality output. The Variance Ridge Detector is able to run at 47 frames per second on 320 by 240 pixel images. This paper discusses the methods to optimise the boundary detector for the purpose of recognising and highlighting the perimeter of burnt fire regions. This implements a threshold filter to remove undesired texture boundaries and obtain a mask of the fire ground. The mask is merged with the target image to identify the perimeter of the burnt fire region. This method is performed in real time and reliably detects a burnt fire ground with an accuracy of 74%. These objective measurements show that the proposed method outperforms all investigated prior burnt fire ground detectors on either quality or speed. The development of this perimeter detector could lead to deployment onto embedded systems for more practical tasks. This could include autonomous robots via tracking of a perimeter.},
booktitle = {Proceedings of the 29th International Conference on Image and Vision Computing New Zealand},
pages = {184–189},
numpages = {6},
keywords = {burnt fire regions, threshold filter, Texture boundary, real-time boundary detectors},
location = {Hamilton, New Zealand},
series = {IVCNZ '14}
}

@inproceedings{10.1145/2642918.2647414,
author = {Afergan, Daniel and Shibata, Tomoki and Hincks, Samuel W. and Peck, Evan M. and Yuksel, Beste F. and Chang, Remco and Jacob, Robert J.K.},
title = {Brain-Based Target Expansion},
year = {2014},
isbn = {9781450330695},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/2642918.2647414},
doi = {10.1145/2642918.2647414},
abstract = {The bubble cursor is a promising cursor expansion technique, improving a user's movement time and accuracy in pointing tasks. We introduce a brain-based target expansion system, which improves the efficacy of bubble cursor by increasing the expansion of high importance targets at the optimal time based on brain measurements correlated to a particular type of multitasking. We demonstrate through controlled experiments that brain-based target expansion can deliver a graded and continuous level of assistance to a user according to their cognitive state, thereby improving task and speed-accuracy metrics, even without explicit visual changes to the system. Such an adaptation is ideal for use in complex systems to steer users toward higher priority goals during times of increased demand.},
booktitle = {Proceedings of the 27th Annual ACM Symposium on User Interface Software and Technology},
pages = {583–593},
numpages = {11},
keywords = {bubble cursor., BCI, fNIRS, adaptive interface, brain-computer interface},
location = {Honolulu, Hawaii, USA},
series = {UIST '14}
}

@inproceedings{10.5555/3330299.3330333,
author = {Bonache-Seco, J. A. and Lopez-Orozco, J. A. and Portas, Eva Besada and Mart\'{\i}n, Jos\'{e} L. Risco},
title = {Adaptive Event Driven Framework for Real Time Multi-Agent Missions},
year = {2018},
isbn = {9781538650486},
publisher = {IEEE Press},
abstract = {A Ground Control Station (GCS) is an essential element to supervise and control autonomous vehicles performing complex missions in real time. In the new era of Internet of Things, where systems are highly connected, these missions demand enormous amounts of computational power to correctly manage the coordination of all the vehicles involved. In this scope, the set of Unmanned Vehicles (UVs) included in the mission must achieve more difficult tasks everyday. As a consequence, the development of a robust, reusable and adaptable GCS framework to allow a single operator to monitor and control a team of heterogeneous agents raises a number of research and engineering challenges. In this paper we introduce an adaptive event-driven framework specially designed for GCSs involved in heterogeneous multi-agent missions that takes advantage of two features: 1) it allows the GCS to add or remove both actual or simulated agents in real time, changing the number or types of monitored agents, and 2) from a software design perspective, the graphical user interface dynamically changes its view in order to minimize operators fatigue and mental workload, facilitating the success of the mission in such complex environments. We also show one of the tests performed with the adaptive framework, where after observing how a real UV deployed in a water surface performs successfully a set of previously planned trajectories, we will see how a simulated UV joins the mission in order to fulfill a leader-follower maneuver.},
booktitle = {Proceedings of the 22nd International Symposium on Distributed Simulation and Real Time Applications},
pages = {255–262},
numpages = {8},
keywords = {adaptive graphics user interface, ground control station, event-driven architecture, mental workload},
location = {Madrid, Spain},
series = {DS-RT '18}
}


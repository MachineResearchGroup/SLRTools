@article{10.1145/3423133,
author = {Alzubaidi, Mohammad A. and Otoom, Mwaffaq and Ahmad, Nouran S.},
title = {Real-Time Assistive Reader Pen for Arabic Language},
year = {2021},
issue_date = {January 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {20},
number = {1},
issn = {2375-4699},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3423133},
doi = {10.1145/3423133},
abstract = {Disability is an impairment affecting an individual's livelihood and independence. Assistive technology enables the disabled cohort of the community to break the barriers to learning, access information, contribute to the community, and live independently. This article proposes an assistive device to enable people with visual disabilities and learning disabilities to access printed Arabic material in real-time, and to help them participate in the education system and the professional workforce.This proposed assistive device employs Optical Character Recognition (OCR) and Text To Speech (TTS) conversion, using concatenation synthesis. OCR is achieved using image processing, character extraction, and classification, while Arabic speech synthesis is achieved through concatenation synthesis, followed by Multi Band Re-synthesis Overlap-Add (MBROLA). Waveform generation in the second phase produces vocal output for the disabled user to hear. OCR character and word accuracy tests were conducted for nine Arabic fonts. The results show that six fonts were recognized with over 60% character accuracy and two fonts were recognized with over 88% accuracy. A Mean Opinion Score (MOS) test for speech quality was conducted. The results showed an overall MOS score of 3.53/5 and indicated that users were able to understand the speech. A real-time usability testing was conducted with 10 subjects. The results showed an overall average of agreements scores of 3.9/5 and indicated that the proposed Arabic reader pen meets the real-time constraints and is pleasant and satisfying to use and can contribute to make printed Arabic material accessible to visually impaired persons and people with learning disabilities.},
journal = {ACM Trans. Asian Low-Resour. Lang. Inf. Process.},
month = {mar},
articleno = {13},
numpages = {30},
keywords = {Arabic language, optical character recognition, assistive embedded systems, real-time systems, text-to-speech, reader pen}
}

@article{10.5555/3207692.3207704,
author = {Paetzold, Gustavo H. and Specia, Lucia},
title = {A Survey on Lexical Simplification},
year = {2017},
issue_date = {September 2017},
publisher = {AI Access Foundation},
address = {El Segundo, CA, USA},
volume = {60},
number = {1},
issn = {1076-9757},
abstract = {Lexical Simplification is the process of replacing complex words in a given sentence with simpler alternatives of equivalent meaning. This task has wide applicability both as an assistive technology for readers with cognitive impairments or disabilities, such as Dyslexia and Aphasia, and as a pre-processing tool for other Natural Language Processing tasks, such as machine translation and summarisation. The problem is commonly framed as a pipeline of four steps: the identification of complex words, the generation of substitution candidates, the selection of those candidates that fit the context, and the ranking of the selected substitutes according to their simplicity. In this survey we review the literature for each step in this typical Lexical Simplification pipeline and provide a benchmarking of existing approaches for these steps on publicly available datasets. We also provide pointers for datasets and resources available for the task.},
journal = {J. Artif. Int. Res.},
month = {sep},
pages = {549–593},
numpages = {45}
}

@article{10.1162/coli_a_00370,
author = {Alva-Manchego, Fernando and Scarton, Carolina and Specia, Lucia},
title = {Data-Driven Sentence Simplification: Survey and
                    Benchmark},
year = {2020},
issue_date = {March 2020},
publisher = {MIT Press},
address = {Cambridge, MA, USA},
volume = {46},
number = {1},
issn = {0891-2017},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1162/coli_a_00370},
doi = {10.1162/coli_a_00370},
abstract = {Sentence Simplification (SS) aims to modify a sentence in order to make it easier
                    to read and understand. In order to do so, several rewriting transformations can
                    be performed such as replacement, reordering, and splitting. Executing these
                    transformations while keeping sentences grammatical, preserving their main idea,
                    and generating simpler output, is a challenging and still far from solved
                    problem. In this article, we survey research on SS, focusing on approaches that
                    attempt to learn how to simplify using corpora of aligned original-simplified
                    sentence pairs in English, which is the dominant paradigm nowadays. We also
                    include a benchmark of different approaches on common data sets so as to compare
                    them and highlight their strengths and limitations. We expect that this survey
                    will serve as a starting point for researchers interested in the task and help
                    spark new ideas for future developments.},
journal = {Comput. Linguist.},
month = {mar},
pages = {135–187},
numpages = {53}
}

@article{10.1145/3442695,
author = {Al-Thanyyan, Suha S. and Azmi, Aqil M.},
title = {Automated Text Simplification: A Survey},
year = {2021},
issue_date = {March 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {54},
number = {2},
issn = {0360-0300},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3442695},
doi = {10.1145/3442695},
abstract = {Text simplification (TS) reduces the complexity of the text to improve its readability and understandability, while possibly retaining its original information content. Over time, TS has become an essential tool in helping those with low literacy levels, non-native learners, and those struggling with various types of reading comprehension problems. In addition, it is used in a preprocessing stage to enhance other NLP tasks. This survey presents an extensive study of current research studies in the field of TS, as well as covering resources, corpora, and evaluation methods that have been used in those studies.},
journal = {ACM Comput. Surv.},
month = {mar},
articleno = {43},
numpages = {36},
keywords = {lexical simplification, Text simplification, monolingual machine translation, survey, syntactic simplification}
}

@article{10.1145/3447651,
author = {Bhowmick, Rajat Subhra and Ganguli, Isha and Paul, Jayanta and Sil, Jaya},
title = {A Multimodal Deep Framework for Derogatory Social Media Post Identification of a Recognized Person},
year = {2021},
issue_date = {January 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {21},
number = {1},
issn = {2375-4699},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3447651},
doi = {10.1145/3447651},
abstract = {In today’s era of digitization, social media platforms play a significant role in networking and influencing the perception of the general population. Social network sites have recently been used to carry out harmful attacks against individuals, including political and theological figures, intellectuals, sports and movie stars, and other prominent dignitaries, which may or may not be intentional. However, the exchange of such information across the general population inevitably contributes to social-economic, socio-political turmoil, and even physical violence in society. By classifying the derogatory content of a social media post, this research work helps to eradicate and discourage the upsetting propagation of such hate campaigns. Social networking posts today often include the picture of Memes along with textual remarks and comments, which throw new challenges and opportunities to the research community while identifying the attacks. This article proposes a multimodal deep learning framework by utilizing ensembles of computer vision and natural language processing techniques to train an encapsulated transformer network for handling the classification problem. The proposed framework utilizes the fine-tuned state-of-the-art deep learning-based models (e.g., BERT, Electra) for multilingual text analysis along with face recognition and the optical character recognition model for Meme picture comprehension. For the study, a new Facebook meme-post dataset is created with recorded baseline results. The subject of the created dataset and context of the work is more geared toward multilingual Indian society. The findings demonstrate the efficacy of the proposed method in the identification of social media meme posts featuring derogatory content about a famous/recognized individual.},
journal = {ACM Trans. Asian Low-Resour. Lang. Inf. Process.},
month = {nov},
articleno = {2},
numpages = {19},
keywords = {deep learning, Social media analysis and security, Indic languages, transformer network, derogatory content, NLP}
}

@article{10.1145/3470651,
author = {Kafle, Sushant and Dingman, Becca and Huenerfauth, Matt},
title = {Deaf and Hard-of-Hearing Users Evaluating Designs for Highlighting Key Words in Educational Lecture Videos},
year = {2021},
issue_date = {December 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {14},
number = {4},
issn = {1936-7228},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3470651},
doi = {10.1145/3470651},
abstract = {There are style guidelines for authors who highlight important words in static text, e.g., bolded words in student textbooks, yet little research has investigated highlighting in dynamic texts, e.g., captions during educational videos for Deaf or Hard of Hearing (DHH) users. In our experimental study, DHH participants subjectively compared design parameters for caption highlighting, including: decoration (underlining vs. italicizing vs. boldfacing), granularity (sentence level vs. word level), and whether to highlight only the first occurrence of a repeating keyword. In partial contrast to recommendations in prior research, which had not been based on experimental studies with DHH users, we found that DHH participants preferred boldface, word-level highlighting in captions. Our empirical results provide guidance for the design of keyword highlighting during captioned videos for DHH users, especially in educational video genres.},
journal = {ACM Trans. Access. Comput.},
month = {oct},
articleno = {20},
numpages = {24},
keywords = {deaf and hard of hearing, user study, captioning system, text highlighting, Caption highlighting}
}

@article{10.1145/1998384.1998385,
author = {Potamianos, Alexandros and Giuliani, Diego and Narayanan, Shrikanth S. and Berkling, Kay},
title = {Introduction to the Special Issue on Speech and Language Processing of Children's Speech for Child-Machine Interaction Applications},
year = {2011},
issue_date = {August 2011},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {7},
number = {4},
issn = {1550-4875},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/1998384.1998385},
doi = {10.1145/1998384.1998385},
journal = {ACM Trans. Speech Lang. Process.},
month = {aug},
articleno = {11},
numpages = {3}
}

@article{10.1145/3241066,
author = {G\"{o}tzelmann, T.},
title = {Autonomous Selection and Printing of 3D Models for People Who Are Blind},
year = {2018},
issue_date = {September 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {11},
number = {3},
issn = {1936-7228},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3241066},
doi = {10.1145/3241066},
abstract = {3D models are an important means for understanding spatial contexts. Today these models can be materialized by 3D printing, which is increasingly used at schools for people with visual impairments. In contrast to sighted people, people with visual impairments have so far, however, neither been able to search nor to print 3D models without assistance. This article describes our work to develop an aid for people with visual impairments that would facilitate autonomous searching for and printing of 3D models. In our initial study, we determined the requirements to accomplish this task by means of a questionnaire and developed a first approach that allowed personal computer-based 3D printing. An extended approach allowed searching and printing using common smartphones. In our architecture, technical details of 3D printers are abstracted by a separate component that can be accessed via Wi-Fi independently of the actual 3D printer used. It comprises a search of the models in an annotated database and 3D model retrieval from the internet. The whole process can be controlled by voice interaction. The feasibility of autonomous 3D printing for people with visual impairments is shown with a first user study. Our second user study examines the usability of the user interface when searching for 3D models on the internet and preparing them for the materialization. The participants were able to define important printing settings, whereas other printing parameters could be determined algorithmically.},
journal = {ACM Trans. Access. Comput.},
month = {sep},
articleno = {14},
numpages = {25},
keywords = {retrieval, internet, autonomous, print server, hardware abstraction, 3D printing, accessibility, visually impaired, user study, 3D models, tactile, exploration, graphics, independent, blind, tangible, self-reliant}
}

@article{10.1145/1786774.1786775,
author = {Pino, Alexandros and Kouroupetroglou, Georgios},
title = {ITHACA: An Open Source Framework for Building Component-Based Augmentative and Alternative Communication Applications},
year = {2010},
issue_date = {June 2010},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {2},
number = {4},
issn = {1936-7228},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/1786774.1786775},
doi = {10.1145/1786774.1786775},
abstract = {As an answer to the disabled community’s odyssey to gain access to adaptable, modular, multilingual, cheap and sustainable Augmentative and Alternative Communication (AAC) products, we propose the use of the ITHACA framework. It is a software environment for building component-based AAC applications, grounded on the Design for All principles and a hybrid---community and commercial---Open Source development model. ITHACA addresses the developers, the vendors, as well as the people who use AAC. We introduce a new viewpoint on the AAC product design-develop-distribute lifecycle, and a novel way to search-select-modify-maintain the AAC aid. ITHACA provides programmers with a set of tools and reusable Open Source code for building AAC software components. It also facilitates AAC product vendors to put together sophisticated applications using the available on the Web, independently premanufactured, free or commercial software parts. Furthermore, it provides people who use AAC with a variety of compatible AAC software products which incorporate multimodal, user-tailored interfaces that can fulfill their changing needs. The ITHACA architecture and the proposed fusion of past and current approaches, trends and technologies are explained. ITHACA has been successfully applied by implementing a family of AAC products, based on interchangeable components. Several ready to use ITHACA-based components, including on-screen keyboards, Text-to-Speech, symbol selection sets, e-chatting, emailing, and scanning-based input, as well as four complete communication aids addressing different user cases have been developed. This demonstration showed good acceptance of the ITHACA applications and substantial improvement of the end users’ communication skills. Developers’ experience on working in ITHACA’s Open Source projects was also positively evaluated. More importantly, the potential contribution of the component-based framework and Open Source development model combination to the AAC community emerged.},
journal = {ACM Trans. Access. Comput.},
month = {jun},
articleno = {14},
numpages = {30},
keywords = {design for all, open source, framework, Augmentative and alternative communication, component}
}

@article{10.1145/3474706,
author = {Rankin, Yolanda A. and Tibi, Sana and Kennington, Casey and Han, Na-eun},
title = {In-Game Social Interactions to Facilitate ESL Students' Morphological Awareness, Language and Literacy Skills},
year = {2021},
issue_date = {September 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {5},
number = {CHI PLAY},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3474706},
doi = {10.1145/3474706},
abstract = {Video games that require players to utilize a target or second language to complete tasks have emerged as alternative pedagogical tools for Second Language Acquisition (SLA). With the exception of vocabulary acquisition, much of the prior research in game-based SLA fails to gauge students' literacy skills, specifically their morphological awareness or understanding of the smallest meaningful linguistic units (e.g., prefixes, suffixes, and roots). Given this shortcoming, we utilize a two-player online game to facilitate social interactions between Native English Speakers (NES) and English as a Second Language (ESL) students as a mechanism to generate ESL students' written output in the targeted language and draw attention to their morphological awareness. Analysis of chat logs demonstrates the game's potential to enhance ESL students' morphological awareness and other important L2 literacy skills such as word reading accuracy. Both NES and ESL students' reflections of their gameplay experiences suggest game design modifications that promote ESL students' willingness to communicate with NES while developing their morphological awareness and practicing their L2 communication and literacy skills.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = {oct},
articleno = {279},
numpages = {25},
keywords = {dialogue, social interactions, morphological awareness, l2 literacy, game-based learning, english second language}
}

@article{10.1145/3479545,
author = {Wong-Villacres, Marisol and Gautam, Aakash and Tatar, Deborah and DiSalvo, Betsy},
title = {Reflections on Assets-Based Design: A Journey Towards A Collective of Assets-Based Thinkers},
year = {2021},
issue_date = {October 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {5},
number = {CSCW2},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3479545},
doi = {10.1145/3479545},
abstract = {The field of Computer-Supported Cooperative Work (CSCW) has long recognized a socio-technical gap complicating the design of technologies that can sustainably meet social needs. In response, a growing body of research advocates for assets-based design, an approach that seeks to build upon what the individuals and community already have. The emphasis on positioning assets rather than needs at the center of the process can complicate designers' decisions on what activities to foster, how to conduct them, and what outcomes to expect. In this paper, we reflect on two different assets-based design endeavors with vulnerable populations. Our reflections present assets-based design as an ongoing process that prioritizes the formation and evolution of a collective of assets-based thinkers who continually learn about their assets and ways to use them to attain desirable change. From that reflection, we contribute three methodological commitments for assets-based design to the growing CSCW scholarship on supporting vulnerable communities to attain emancipatory transformations: (1) embedding trust-building elements throughout the journey; (2) facilitating the formation of an interdependent collective; and (3) making moves towards incremental transformations. Further, we contribute a discussion on the change of perspective that entails for researchers and designers interested in undertaking assets-based design. In particular, we underscore the need to recognize the value of work before the work, to see technology as an intermediary rather than an inevitable end, and embrace impact in the shape of slow incremental transformation.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = {oct},
articleno = {401},
numpages = {32},
keywords = {capacities, vulnerable population, participatory design, asset-based}
}


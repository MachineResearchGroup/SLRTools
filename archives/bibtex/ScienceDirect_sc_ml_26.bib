@article{POONIA2021100459,
title = {CONFRONT: Cloud-fog-dew based monitoring framework for COVID-19 management},
journal = {Internet of Things},
volume = {16},
pages = {100459},
year = {2021},
issn = {2542-6605},
doi = {https://doi.org/10.1016/j.iot.2021.100459},
url = {https://www.sciencedirect.com/science/article/pii/S2542660521001001},
author = {Anish Poonia and Shreya Ghosh and Akash Ghosh and Shubha Brata Nath and Soumya K. Ghosh and Rajkumar Buyya},
keywords = {Internet of Things (IoT), Cloud computing, Fog computing, Dew computing, Pandemic, COVID-19, Health monitoring},
abstract = {In the recent times, the IoT (Internet of Things) enabled devices and applications have seen a rapid growth in various sectors including healthcare. The ability of low-cost connected sensors to cover large areas makes it a potential tool in the fight against pandemics, like COVID-19. The COVID-19 has posed a formidable challenge for the developing countries, like India, which need to cater to large population base with limited health infrastructure. In this paper, we proposed a  Cloud-fog-dew based mOnitoriNg Framework foR cOvid-19 maNagemenT, called CONFRONT. This cloud-fog-dew based healthcare model may help in preliminary diagnosis and also in monitoring patients while they are in quarantine facilities or home based treatments. The fog architecture ensures that the model is suited for real-time scenarios while keeping the bandwidth requirements low. To analyse large scale COVID-19 statistics data for extracting aggregate information of the disease spread, the cloud servers are leveraged due to its scalable computational and storage capabilities. The dew architecture ensures that the application is available at a limited scale even when cloud connectivity is lost, leading to a faster uptime for the application. A low cost wearable device consisting of heterogeneous sensors has also been designed and fabricated to realize the proposed framework.}
}
@article{TWOMEY201793,
title = {Unsupervised learning of sensor topologies for improving activity recognition in smart environments},
journal = {Neurocomputing},
volume = {234},
pages = {93-106},
year = {2017},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2016.12.049},
url = {https://www.sciencedirect.com/science/article/pii/S0925231216315740},
author = {Niall Twomey and Tom Diethe and Ian Craddock and Peter Flach},
keywords = {Machine learning, Digital signal processing, Smart homes, Activity recognition, Activities of daily life, Unsupervised learning, Meta learning},
abstract = {There has been significant recent interest in sensing systems and ‘smart environments’, with a number of longitudinal studies in this area. Typically the goal of these studies is to develop methods to predict, at any one moment of time, the activity or activities that the resident(s) of the home are engaged in, which may in turn be used for determining normal or abnormal patterns of behaviour (e.g. in a health-care setting). Classification algorithms, such as Conditional Random Field (CRFs), typically consider sensor activations as features but these are often treated as if they were independent, which in general they are not. Our hypothesis is that learning patterns based on combinations of sensors will be more powerful than single sensors alone. The exhaustive approach – to take all possible combinations of sensors and learn classifier weights for each combination – is clearly computationally prohibitive. We show that through the application of signal processing and information-theoretic techniques we can learn about the sensor topology in the home (i.e. learn an adjacency matrix) which enables us to determine the combinations of sensors that will be useful for classification ahead of time. As a result we can achieve classification performance better than that of the exhaustive approach, whilst only incurring a small cost in terms of computational resources. We demonstrate our results on several datasets, showing that our method is robust in terms of variations in the layout and the number of residents in the house. Furthermore, we have incorporated the adjacency matrix into the CRF learning framework and have shown that it can improve performance over multiple baselines.}
}
@article{CHEN201890,
title = {Mixed kernel based extreme learning machine for electric load forecasting},
journal = {Neurocomputing},
volume = {312},
pages = {90-106},
year = {2018},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2018.05.068},
url = {https://www.sciencedirect.com/science/article/pii/S0925231218306532},
author = {Yanhua Chen and Marius Kloft and Yi Yang and Caihong Li and Lian Li},
keywords = {Electric load forecasting, Extreme learning machine, RBF kernel, UKF kernel, Empirical mode decomposition},
abstract = {Short term electric load forecasting, as an important tool in the electricity market, plays a critical role in the management of electric systems. Proposing an accuracy and optimization method is not only a challenging task but also an indispensable part of the energy system. More and more accurate forecasting methods are needed by different people in different areas. This paper proposes a novel short-term electric load forecasting method EMD-Mixed-ELM which based on empirical mode decomposition (EMD) and extreme learning machine (ELM). EMD-Mixed-ELM first uses the empirical mode decomposition to decompose the load series for capturing the complicated features of the electric load and de-noising the data. Considering that the performance of extreme learning machine (ELM) is greatly influenced by the choice of kernel, the mixed kernel method is proposed for ELM. The mixed kernel combines the RBF kernel and the UKF kernel. The forecasting results of the EMD-Mixed-ELM are proved to be better than all the other three methods (RBF-ELM, UKF-ELM and Mixed-ELM) and other existing methods (MFES, ESPLSSVM and Combined method). To verify the forecasting ability of the EMD-Mixed-ELM, half-hourly electric load data from the state of New South Wales, Victoria and Queensland in Australia are used in this paper as a case study. The experimental results clearly indicate that for this three datasets, the forecasting accuracy of the proposed method is superior to other methods.}
}
@article{FALCO20151008,
title = {City Resilience through Data Analytics: A Human-centric Approach},
journal = {Procedia Engineering},
volume = {118},
pages = {1008-1014},
year = {2015},
note = {Defining the future of sustainability and resilience in design, engineering and construction},
issn = {1877-7058},
doi = {https://doi.org/10.1016/j.proeng.2015.08.542},
url = {https://www.sciencedirect.com/science/article/pii/S1877705815021979},
author = {Gregory J. Falco},
keywords = {resilience, resiliency, planning, data analytics, risk management, cities, emergency management},
abstract = {Our cities are being redefined daily based on social, political and environmental factors. This creates substantial challenges for those that attempt to develop resilience strategies for cities. Resilience planning requires a set of assumptions often based on data; however, the dynamic nature of our growing urban environments has impeded our ability to rely on these suppositions. To account for the unpredictable ebb and flow of changes in our cities we have become heavily dependent on data modeling and analytics. The ability to collect and store data from a variety of systems in a cloud infrastructure has enabled the potential for resilience planning to be based on historical scenarios and societal context – prioritizing risks and issues based on multiple factors. As our infrastructure becomes “smarter” with the ability to capture more data and make decisions through machine learning algorithms, resilience plans may become less in touch with the citizens for whom the resilience strategies exist. Thusly, an emergent risk to the inhabitants of cities is the imbalance of qualitative versus quantitative feedback that is leveraged to develop and improve a city's resilience strategy. Cities are living organisms that cannot be purely defined through machine data. A modern way to establish policies and plans for major urban centers is to leverage machine data collected through various “smart” technology programs. Such data-aggregation mechanisms feed into analytics tools that often fail to account for historical context or citizens’ perspectives. Without leveraging this information, a resilience plan cannot be complete as it will not address the city as a system, but only a component thereof. This paper proposes a new model for developing a city's comprehensive resilience strategy that integrates machine data, historical context and societal effects. The risk of not pursuing a three-pronged model would be that future resilience strategies would lack a human-centric approach.}
}
@article{SRINIVASADITYA2021103245,
title = {A Survey on Blockchain in Robotics: Issues, Opportunities, Challenges and Future Directions},
journal = {Journal of Network and Computer Applications},
volume = {196},
pages = {103245},
year = {2021},
issn = {1084-8045},
doi = {https://doi.org/10.1016/j.jnca.2021.103245},
url = {https://www.sciencedirect.com/science/article/pii/S1084804521002435},
author = {U.S.P. {Srinivas Aditya} and Roshan Singh and Pranav Kumar Singh and Anshuman Kalla},
keywords = {Blockchain, Robotics, Smart contracts},
abstract = {Robotics is the multi-disciplinary domain that is booming in today’s world, and expanding its roots deep into various fields of research, manufacturing industries, healthcare, and even in our day-to-day lives. Nevertheless, as with any other evolving technology, robotics face numerous challenges. In this context, lately, blockchain technology has been identified as a promising technology to resolve many of these issues such as identification of malicious/rogue nodes, malfunctioning/faults in automated processes, non-compliance to the agreed norms and privacy rules, security attacks on robotic systems, and non-transparency in performance monitoring and audits. In particular, blockchain with its features like decentrality, immutability, provenance, low operational cost, tight access control, and trustworthy operations, can offer significant improvements to new applications and use cases driven by robotics. Thus, the paper begins with exploring the key requirements and technical challenges encountered by robots in general. Next, it provides detailed overview of blockchain technology in a tutorial style. Then, the role of blockchain for different uses cases of robotics are surveyed. Furthermore, various technical challenges that need to be mitigated to harness full potential of blockchain for robotics are highlighted. Finally, the future research directions are presented that can pave the way ahead for advancements and profitable integration of blockchain in the realm of robotics.}
}
@article{AZAZA20193208,
title = {An open-source visualization platform for energy flows mapping and enhanced decision making.},
journal = {Energy Procedia},
volume = {158},
pages = {3208-3214},
year = {2019},
note = {Innovative Solutions for Energy Transitions},
issn = {1876-6102},
doi = {https://doi.org/10.1016/j.egypro.2019.01.1006},
url = {https://www.sciencedirect.com/science/article/pii/S1876610219310586},
author = {Maher Azaza and Anton Eskilsson and Fredrik Wallin},
keywords = {Smart metering, Visualization, Energy mapping, Decision making},
abstract = {Visualization of energy consumption within the built environment, both in the private and public sectors, can be a potent tool for increasing conservation behavior. For instance, dynamics visualization could add new knowledge to the end-users to have a better understanding of the energy flows, dynamic mapping of the energy usage in order to avoid misplacing effort and resources, e.g. when it comes to selection of heating systems, investing in energy efficiency measures and renewables as well as when stakeholders are planning for new area to be populated with either commercial or residential buildings. This paper introduces an open-source visualization platform allowing various energy flows mapping in both time and space of a sports facilities. It further includes advanced functionalities such as key performance indicators and integrated prediction models to assist the benchmarking and decision making processes.}
}
@article{SIVARAJAH2017263,
title = {Critical analysis of Big Data challenges and analytical methods},
journal = {Journal of Business Research},
volume = {70},
pages = {263-286},
year = {2017},
issn = {0148-2963},
doi = {https://doi.org/10.1016/j.jbusres.2016.08.001},
url = {https://www.sciencedirect.com/science/article/pii/S014829631630488X},
author = {Uthayasankar Sivarajah and Muhammad Mustafa Kamal and Zahir Irani and Vishanth Weerakkody},
keywords = {Big Data, Big Data Analytics, Challenges, Methods, Systematic literature review},
abstract = {Big Data (BD), with their potential to ascertain valued insights for enhanced decision-making process, have recently attracted substantial interest from both academics and practitioners. Big Data Analytics (BDA) is increasingly becoming a trending practice that many organizations are adopting with the purpose of constructing valuable information from BD. The analytics process, including the deployment and use of BDA tools, is seen by organizations as a tool to improve operational efficiency though it has strategic potential, drive new revenue streams and gain competitive advantages over business rivals. However, there are different types of analytic applications to consider. Therefore, prior to hasty use and buying costly BD tools, there is a need for organizations to first understand the BDA landscape. Given the significant nature of the BD and BDA, this paper presents a state-of-the-art review that presents a holistic view of the BD challenges and BDA methods theorized/proposed/employed by organizations to help others understand this landscape with the objective of making robust investment decisions. In doing so, systematically analysing and synthesizing the extant research published on BD and BDA area. More specifically, the authors seek to answer the following two principal questions: Q1 – What are the different types of BD challenges theorized/proposed/confronted by organizations? and Q2 – What are the different types of BDA methods theorized/proposed/employed to overcome BD challenges?. This systematic literature review (SLR) is carried out through observing and understanding the past trends and extant patterns/themes in the BDA research area, evaluating contributions, summarizing knowledge, thereby identifying limitations, implications and potential further research avenues to support the academic community in exploring research themes/patterns. Thus, to trace the implementation of BD strategies, a profiling method is employed to analyze articles (published in English-speaking peer-reviewed journals between 1996 and 2015) extracted from the Scopus database. The analysis presented in this paper has identified relevant BD research studies that have contributed both conceptually and empirically to the expansion and accrual of intellectual wealth to the BDA in technology and organizational resource management discipline.}
}
@article{LIN2020105305,
title = {The improvement of spatial-temporal resolution of PM2.5 estimation based on micro-air quality sensors by using data fusion technique},
journal = {Environment International},
volume = {134},
pages = {105305},
year = {2020},
issn = {0160-4120},
doi = {https://doi.org/10.1016/j.envint.2019.105305},
url = {https://www.sciencedirect.com/science/article/pii/S0160412018326552},
author = {Yuan-Chien Lin and Wan-Ju Chi and Yong-Qing Lin},
keywords = {PM, Micro-air quality sensors, Data fusion, Spatial-temporal estimation},
abstract = {With the rapid development of the Internet of things (IoTs) and modern industrial society, forecasting air pollution concentration, e.g., the concentration of PM2.5, is of great significance to protect human health and the environment. Accurate prediction of PM2.5 concentrations is limited by the number and the data quality of air quality monitoring stations. In Taiwan, the spatial and temporal data of PM2.5 concentrations are measured by 77 national air quality monitoring stations (built by Taiwan EPA). However, the national stations are costly and scarce because of the highly precise instrument and their size. Therefore, many places are still out of coverage of the monitoring network. Recently, under the framework of IoTs, there are hundreds of portable air quality sensors called “AirBox” developed jointly by the Taiwan local government and a private company. By virtue of its low price and portability, the AirBox can provide a higher resolution of space-time PM2.5 measurement. However, the spatiotemporal distribution is different between AirBox and EPA stations, and data quality and accuracy of AirBox is poorer than national air quality monitoring stations. Thus, to integrate the heterogeneous PM2.5 data, the data fusion technique should be used before further analysis. In this study, we propose a new data fusion method called multi-sensor space-time data fusion framework. It is based on the Optimum Linear Data Fusion theory and integrating with a multi-time step Kriging method for spatial-temporal estimation. The method is used to do heterogeneous data fusion from different sources and data qualities. It is able to improve the estimation of PM2.5 concentration in space and time. Results have shown that by combining PM2.5 concentration data from 1176 low-cost AirBoxes as additional information in our model, the estimation of spatial-temporal PM2.5 concentration becomes better and more reasonable. The r2 of the validation regression model is 0.89. Under the approach proposed in this study, we made the information of the micro-sensors more reliable and improved the higher spatial-temporal resolution of air quality monitoring. It could provide very useful information for better spatial-temporal data analysis and further environmental management, such as air pollution source localization, health risk assessment, and micro-scale air pollution analysis.}
}
@article{KOCIAN2020105167,
title = {Dynamic Bayesian network for crop growth prediction in greenhouses},
journal = {Computers and Electronics in Agriculture},
volume = {169},
pages = {105167},
year = {2020},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2019.105167},
url = {https://www.sciencedirect.com/science/article/pii/S0168169919321131},
author = {A. Kocian and D. Massa and S. Cannazzaro and L. Incrocci and S. {Di Lonardo} and P. Milazzo and S. Chessa},
keywords = {Internet of Things, Evapotranspiration, Leaf-area, EM algorithm, Prediction},
abstract = {The paper presents an Internet-of-Things based agricultural decision support system for crop growth. A dynamic Bayesian network (DBN) relates indicative parameters of crop development to environmental control parameters via unobserved (hidden) Markov states. The expectation-maximization algorithm is used to track the states and to learn the parameters of the DBN. The steady state information is then used to derive a predictor for the measurement data a few days ahead. The proposed DBN avoids time-consuming training cultivation cycles, as only data of the current cultivation cycle are available to the algorithm. Three cultivation cycles of lettuce have been used to test the performance of the proposed DBN. The environmental parameters were temperature, solar irradiance and vapor-pressure deficit. The measurement data include evapotranspiration at granularity equal one day, and leaf-area index and dry weight, at granularity equal one week. It turned out that accurate measurement data prediction a few days ahead is possible even if the number of data samples is low.}
}
@article{JAVAID2021209,
title = {Internet of Things (IoT) enabled healthcare helps to take the challenges of COVID-19 Pandemic},
journal = {Journal of Oral Biology and Craniofacial Research},
volume = {11},
number = {2},
pages = {209-214},
year = {2021},
issn = {2212-4268},
doi = {https://doi.org/10.1016/j.jobcr.2021.01.015},
url = {https://www.sciencedirect.com/science/article/pii/S2212426821000154},
author = {Mohd Javaid and Ibrahim Haleem Khan},
keywords = {Internet of things (IoT), COVID-19, Information technology applications, Healthcare, Smart hospital},
abstract = {Background/objectives
The Internet of Things (IoT) can create disruptive innovation in healthcare. Thus, during COVID-19 Pandemic, there is a need to study different applications of IoT enabled healthcare. For this, a brief study is required for research directions.
Methods
Research papers on IoT in healthcare and COVID-19 Pandemic are studied to identify this technology’s capabilities. This literature-based study may guide professionals in envisaging solutions to related problems and fighting against the COVID-19 type pandemic.
Results
Briefly studied the significant achievements of IoT with the help of a process chart. Then identifies seven major technologies of IoT that seem helpful for healthcare during COVID-19 Pandemic. Finally, the study identifies sixteen basic IoT applications for the medical field during the COVID-19 Pandemic with a brief description of them.
Conclusions
In the current scenario, advanced information technologies have opened a new door to innovation in our daily lives. Out of these information technologies, the Internet of Things is an emerging technology that provides enhancement and better solutions in the medical field, like proper medical record-keeping, sampling, integration of devices, and causes of diseases. IoT’s sensor-based technology provides an excellent capability to reduce the risk of surgery during complicated cases and helpful for COVID-19 type pandemic. In the medical field, IoT’s focus is to help perform the treatment of different COVID-19 cases precisely. It makes the surgeon job easier by minimising risks and increasing the overall performance. By using this technology, doctors can easily detect changes in critical parameters of the COVID-19 patient. This information-based service opens up new healthcare opportunities as it moves towards the best way of an information system to adapt world-class results as it enables improvement of treatment systems in the hospital. Medical students can now be better trained for disease detection and well guided for the future course of action. IoT’s proper usage can help correctly resolve different medical challenges like speed, price, and complexity. It can easily be customised to monitor calorific intake and treatment like asthma, diabetes, and arthritis of the COVID-19 patient. This digitally controlled health management system can improve the overall performance of healthcare during COVID-19 pandemic days.}
}
@article{ZHANG2017884,
title = {From Numerical Model to Computational Intelligence: The Digital Transition of Urban Energy System},
journal = {Energy Procedia},
volume = {143},
pages = {884-890},
year = {2017},
note = {Leveraging Energy Technologies and Policy Options for Low Carbon Cities},
issn = {1876-6102},
doi = {https://doi.org/10.1016/j.egypro.2017.12.778},
url = {https://www.sciencedirect.com/science/article/pii/S1876610217365426},
author = {Chuan Zhang and Alessandro Romagnoli and Li Zhou and Markus Kraft},
keywords = {urban energy system, big data, digitalization, ontology, blockchain},
abstract = {With the development of digital technologies, especially big data analytics, digital innovations are taking root in various industries, including energy sector. Particularly, urban energy system is also experiencing digital transition; such digital transition not only offers new business models commercially, but also brings new research problems scientifically. The new capabilities enabled by these digital technologies are reshaping the generation, transmission, consumption and storage sections in the urban energy system, sequentially the traditional way of how urban energy system is designed and operated should be reexamined. Starting from here, there have been many studies regarding how various digital technologies can be applied all along the urban energy system value chain; these studies range from individuals’ energy consumption pattern characterization by using customer behavior data in smart home, to complex data-driven planning of regional scale energy system. More specifically, numerous computational models have been proposed by the scientific community to mimic the dynamics of various components at various levels in the urban energy system. However, the potential benefits of applying these numerical models are somehow underestimated; we believe there are still several gaps from numerical modeling to computational intelligence which need to be bridged. In such a context, in this paper we strive to present a systematic review on the status of urban energy system related digital innovations as well as prospective outlook on the future application of such digital technologies. Through the study of this paper, we hope to identify several key points where digitalization should be prioritized in urban energy system, picture a roadmap towards future digital technology enabled intelligent urban energy system, and finally points out the research gaps that need to be fulfilled over there.}
}
@article{CHEHRI20214542,
title = {MAC Protocols for Industrial Delay-Sensitive Applications in Industry 4.0: Exploring Challenges, Protocols, and Requirements},
journal = {Procedia Computer Science},
volume = {192},
pages = {4542-4551},
year = {2021},
note = {Knowledge-Based and Intelligent Information & Engineering Systems: Proceedings of the 25th International Conference KES2021},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2021.09.232},
url = {https://www.sciencedirect.com/science/article/pii/S1877050921019712},
author = {Abdellah Chehri},
keywords = {MAC protocol, IIoT, Industry 4.0, WirelessHart},
abstract = {The Industrial Internet of Things (IIoT) is expected to enable Industry 4.0 through the extensive deployment of low-power devices. However, industrial applications require, most of the time, high reliability close to 100% and low end-to-end delays. This corresponds to very challenging objectives in wireless (lossy) environments. This delay can be disastrous in time-sensitive industrial IoT deployments where immediate detection and actions impact security, safety, and machine failures. With an efficient MAC protocol, data will be provided quickly to enable the IoT to be fully effective for mission-critical applications. Efficient medium sharing is even more difficult in IIoT due to ultra-low latency, high reliability, and high quality of service (QoS) compared to best-effort for IoT. This article does not survey all existing MAC protocols for IoTs, which was already done in other works. The goal of this paper is to analyze existing MAC protocols that are more suitable for IIoT.}
}
@article{JOY201816,
title = {K Privacy: Towards improving privacy strength while preserving utility},
journal = {Ad Hoc Networks},
volume = {80},
pages = {16-30},
year = {2018},
issn = {1570-8705},
doi = {https://doi.org/10.1016/j.adhoc.2018.05.009},
url = {https://www.sciencedirect.com/science/article/pii/S1570870518302427},
author = {Josh Joy and Dylan Gray and Ciaran McGoldrick and Mario Gerla},
keywords = {Internet of Vehicles, Location privacy, Privacy-preserving data collection, Differential privacy},
abstract = {Future autonomous vehicles will generate, collect, aggregate and consume significant volumes of data as key gateway devices in emerging Internet of Things scenarios. While vehicles are widely accepted as one of the most challenging mobility contexts in which to achieve effective data communications, less attention has been paid to the privacy of data emerging from these vehicles. The quality and usability of such privatized data will lie at the heart of future safe and efficient transportation solutions. In this paper, we present the K Privacy mechanism. K Privacy is to our knowledge the first such mechanism that enables data creators to submit multiple contradictory responses to a query, whilst preserving utility measured as the absolute error from the actual original data. The functionalities are achieved in both a scalable and secure fashion. For instance, individual location data can be obfuscated while preserving utility, thereby enabling the scheme to transparently integrate with existing systems (e.g. Waze). A new cryptographic primitive Function Secret Sharing is used to achieve non-attributable writes and we show an order of magnitude improvement from the default implementation.}
}
@article{JOSHI2019281,
title = {Evaluation of design alternatives of End-Of-Life products using internet of things},
journal = {International Journal of Production Economics},
volume = {208},
pages = {281-293},
year = {2019},
issn = {0925-5273},
doi = {https://doi.org/10.1016/j.ijpe.2018.12.010},
url = {https://www.sciencedirect.com/science/article/pii/S0925527318304882},
author = {Aditi D. Joshi and Surendra M. Gupta},
keywords = {Product design, Linear physical programming, Internet of things, Disassembly, Remanufacturing},
abstract = {Internet of Things (IoT) can play a crucial role in End-of-Life (EOL) product recovery. It can help in determining conditions of returned EOL products with the help of sensors and RFID tags, which then can be used to decide a feasible recovery process for the EOL product amongst disassembly, remanufacturing, recycling or disposal. Product design is a key criterion which affects the choice of recovery process. Complex product designs will increase the cost of disassembly which will lead to higher recovery costs. Therefore, considering the recovery operations during a product's design phase can lead to effective recovery process after its EOL. In order to see the effect of product design on product recovery using IoT, this paper proposes an Advanced-Remanufacturing-To-Order-Disassembly-To-Order (ARTODTO) system which receives sensors and Radio Frequency Identification (RFID) tags embedded End-Of-Life (EOL) products to satisfy various products, components and materials demands. The received EOL products can be recovered via disassembly to meet the components demands, remanufactured to meet the products demands or recycled to meet the materials demands. The remaining EOL products can be disposed of. The model evaluates different designs of a product for the ease of disassembly and remanufacturing based on three criteria viz., total profit, quality level and the number of disposed items. To solve the proposed multi-criteria decision-making model, linear physical programming is used. An example of laptops is considered for illustration of the proposed methodology.}
}
@article{SIMO202113,
title = {Air quality assessment system based on self-driven drone and LoRaWAN network},
journal = {Computer Communications},
volume = {175},
pages = {13-24},
year = {2021},
issn = {0140-3664},
doi = {https://doi.org/10.1016/j.comcom.2021.04.032},
url = {https://www.sciencedirect.com/science/article/pii/S0140366421001766},
author = {Attila Simo and Simona Dzitac and Ioan Dzitac and Mihaela Frigura-Iliasa and Flaviu Mihai Frigura-Iliasa},
keywords = {Air quality monitoring, Self-driven drone, LoRaWAN},
abstract = {Poor air quality harms human health and the environment. In Europe, emissions of many air pollutants have decreased substantially over the past decades. A significant part of Europe’s population lives in areas, especially cities, where exceedances of air quality standards occur: ozone (O3), nitrogen dioxide (NO2) and particulate matter (PM) pollution pose serious health problems. Several countries have exceeded one or more of their 2010 emission limits for four important air pollutants. Reducing air pollution therefore remains important. This paper presents a low-cost air quality monitoring device that due to the communication technology (LoRaWAN) can be used on large geographical areas. The presented solution was tested and verified on real field service conditions. The obtained data is compared with existing public air quality stations official data.}
}
@article{ZHANG2021100007,
title = {Urban power load profiles under ageing transition integrated with future EVs charging},
journal = {Advances in Applied Energy},
volume = {1},
pages = {100007},
year = {2021},
issn = {2666-7924},
doi = {https://doi.org/10.1016/j.adapen.2020.100007},
url = {https://www.sciencedirect.com/science/article/pii/S266679242030007X},
author = {Haoran Zhang and Jinyu Chen and Jie Yan and Xuan Song and Ryosuke Shibasaki and Jinyue Yan},
keywords = {Power load profile, Energy consumption, Ageing society, EV charging},
abstract = {Understanding ageing transition caused fine-grained changes of electricity profile is the significant insight for coping with future threatens in grid flexibility management. The research gaps for the hourly-basis knowledge exist due to challenges in microanalysis on user-side behavior. Based on billions of users’ behavior data, we investigated the changes on the load profiles due to population aging. We found that owing to ageing transition, the participation population in high electricity-density activities decreases by about 8%. The corresponding shift in driving behavior rises the 14% difference between peak charging load and valley. We concluded that population aging will dramatically change both the magnitude and shape of future dynamic-load profiles. Therefore, we further suggested a new solution with comprehensive and quantitative management for PVs development and the smart charging market with smooth operation of the grid in coupling the potential challenges caused by the ageing issue.}
}
@article{DONG2017102,
title = {Novel feature selection and classification of Internet video traffic based on a hierarchical scheme},
journal = {Computer Networks},
volume = {119},
pages = {102-111},
year = {2017},
issn = {1389-1286},
doi = {https://doi.org/10.1016/j.comnet.2017.03.019},
url = {https://www.sciencedirect.com/science/article/pii/S1389128617301184},
author = {Yu-ning Dong and Jia-jie Zhao and Jiong Jin},
keywords = {Statistical features, QoS, Video traffic classification, -Nearest Neighbor classification},
abstract = {Accurate traffic classification is critical for efficient network management and resources utilization. Different video traffics have different QoS (Quality of Service) requirements. To provide Internet video services with better QoS support, a fine grained classification scheme for network video traffic is proposed in this paper. Through extensive statistical analysis of typical video traffic flows with a consistency-based method, several new flow statistical features are extracted. They are found to be more effective in discriminating different video traffics, especially from the QoS perspective, than commonly used features available in the literature. A hierarchical k-Nearest Neighbor (kNN) classification algorithm is then developed based on the combinations of these statistical features. Experiments are performed to evaluate the effectiveness of the proposed method on a large scale real network video traffic data. The experimental results show that the proposed method outperforms existing methods applying commonly used flow statistical features.}
}
@article{FENG2018128,
title = {Sparse latent model with dual graph regularization for collaborative filtering},
journal = {Neurocomputing},
volume = {284},
pages = {128-137},
year = {2018},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2018.01.011},
url = {https://www.sciencedirect.com/science/article/pii/S0925231218300262},
author = {Xiaodong Feng and Sen Wu and Zhiwei Tang and Zhichao Li},
keywords = {Collaborative flittering, Matrix factorization, Sparse representation, Graph Laplacian, Iterative optimization},
abstract = {Matrix factorization (MF) has been one of the powerful machine learning techniques for collaborative flittering, and it is also widely extended to improve the quality for various tasks. For recommendation tasks, it is noting that a single user or item is actually shown to be sparsely correlated with latent factors extracted by MF, which has not been developed in existing works. Thus, we are focusing on levering sparse representation, as a successful feature learning schema for high dimensional data, into latent factor model. We propose a Sparse LAtent Model (SLAM) based on the ideas of sparse representation and matrix factorization. In SLAM, the item and user representation vectors in the latent space are expected to be sparse, induced by the ℓ1-regularization on those vectors. Besides, we extend a dual graph Lapalacian regularization term to simultaneously integrate both user network and item network knowledge. Also, an iterative optimization method is presented to solve the new learning problem. The experiments on real datasets show that SLAM can predict the user–item ratings better than the state-of-the-art matrix factorization based methods.}
}
@article{WEN2022117916,
title = {A data-driven method of traffic emissions mapping with land use random forest models},
journal = {Applied Energy},
volume = {305},
pages = {117916},
year = {2022},
issn = {0306-2619},
doi = {https://doi.org/10.1016/j.apenergy.2021.117916},
url = {https://www.sciencedirect.com/science/article/pii/S0306261921012289},
author = {Yifan Wen and Ruoxi Wu and Zihang Zhou and Shaojun Zhang and Shengge Yang and Timothy J. Wallington and Wei Shen and Qinwen Tan and Ye Deng and Ye Wu},
keywords = {Data driven method, Land use random forest, Intelligent transportation systems, Vehicle emissions, Transportation sustainability},
abstract = {The development of intelligent approaches to quantify and mitigate on-road emissions is essential for urban and transportation sustainability for global megacities. Here, we utilize high-density traffic monitoring data and land use data to train random forest models capable of accurately predicting dynamic, link-level vehicle emissions. A total of 272 predicting indicators, including road features, population density, and land use information, were included in model training. Our model performed well, with a spatial generalization R2 > 0.8 for both volume and speed simulations. Dynamic link-based emissions of major air pollutants and carbon dioxide (CO2) were estimated for the whole road network of Chengdu, a populous city with the second greatest vehicle population in China. We adopted a generalized additive model to identify the drivers of spatial heterogeneity of on-road emissions and energy consumption, and nonlinear relationships between emissions, demographic and land use variables were found. Fine-grained assessments of emission reductions from potential Low Emission Zone policies are explored based on the high-resolution vehicle emission mapping tool. With high computational efficiency, the method is promising for handling traffic data streams in a real-time fashion, thus offering the potential for more precise vehicle emission management and carbon footprint tracking.}
}
@article{ILIE2020530,
title = {E-HoA: A Distributed Layered Architecture for Context-aware Autonomous Vehicles},
journal = {Procedia Computer Science},
volume = {170},
pages = {530-538},
year = {2020},
note = {The 11th International Conference on Ambient Systems, Networks and Technologies (ANT) / The 3rd International Conference on Emerging Data and Industry 4.0 (EDI40) / Affiliated Workshops},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2020.03.121},
url = {https://www.sciencedirect.com/science/article/pii/S1877050920305597},
author = {Jean-Michel Ilié and Ahmed-Chawki Chaouche and François Pêcheux},
keywords = {Ambient systems, Autonomous vehicle, Embedded architecture, Context-awareness, Contextual planning, Reactive behavioral strategies},
abstract = {The Embedded Higher-order Agent (E-HoA) architecture presented in this paper addresses the growing need for context-aware ambient systems, such as autonomous vehicles. This multi-process architecture, to be embedded into the control loop of these vehicles, includes a Belief-Desire-Intention agent that can consistently assist the symbolic execution of intentions. It also performs the appropriate conversion of these intentions into real physical vehicle maneuvers based on ROS. The proposed architecture offers gradually 4 levels of reactivity, from arch-reflex to the deep modification of the previously built symbolic execution plan. The presented use-case, the daily delivery of a network of pharmacy offices by an autonomous vehicle taking into account contextual (spatio-temporal) traffic features, shows the efficiency and the modularity of the architecture, as well as the scalability of the reaction levels.}
}
@article{CHEN2022130240,
title = {Revamping construction supply chain processes with circular economy strategies: A systematic literature review},
journal = {Journal of Cleaner Production},
volume = {335},
pages = {130240},
year = {2022},
issn = {0959-6526},
doi = {https://doi.org/10.1016/j.jclepro.2021.130240},
url = {https://www.sciencedirect.com/science/article/pii/S095965262104405X},
author = {Qian Chen and Haibo Feng and Borja {Garcia de Soto}},
keywords = {Circular economy, BIM, LCA, Construction supply chain, Recycle, Reuse, Deconstruction},
abstract = {The construction sector has suffered from low productivity and considerable wastes due to the fragmentation of its value chain, the large number of diverse stakeholders and the complex nature of the projects. A promising way to reduce construction wastes and encourage value chain integration is to implement circular economy (CE) strategies. Many recent studies in the fields of construction management and sustainability have advanced CE from multiple perspectives. There remains room to refine such knowledge by clearly identifying all the possible strategies and drivers to be carried out in practice that help stakeholders slow, narrow, and close resource loops. A systematic review was conducted in this study to examine the relevant literature on construction circularity to address the knowledge gap. A total of 61 relevant publications in the past ten years were rigorously selected and reviewed in-depth based on an iterative coding procedure. The phase-specific circular economy strategies were classified into five categories: 1) Design phase (including design with LCA, design with reused materials, design with recycled materials, and design for disassembly); 2) Manufacturing phase (including industrial symbiosis); 3) Construction phase (including lean construction methods); 4) Operation and maintenance phase (including service life planning); and 5) End-of-Life phase (including diversion of wastes). Internal drivers were identified to consist of BIM (Building Information Modelling)-based design and evaluation, IoT (Internet of Things)-based material tracking, predictive data analytics, and logistics network optimization. External drivers included material certifications and legislation, financial incentives, market maturity and material flow balance, and social engagement. The review revealed that the BIM-based and LCA-based methods have been widely used; however, logistics network optimization to allow industrial symbiosis was not adequately addressed in the existing literature. The strategies and drivers were also composed into a framework to guide the future implementation of circular construction projects. The framework could help construction researchers and project participants clearly understand circular resource flows across various construction supply chain stages and thus help them to keep up with the global action of “Net Zero Emission” by 2050.}
}
@article{LEDERMAN2021100552,
title = {The role of the Internet of Things in Healthcare in supporting clinicians and patients: A narrative review},
journal = {Health Policy and Technology},
volume = {10},
number = {3},
pages = {100552},
year = {2021},
issn = {2211-8837},
doi = {https://doi.org/10.1016/j.hlpt.2021.100552},
url = {https://www.sciencedirect.com/science/article/pii/S2211883721000757},
author = {Reeva Lederman and Ofir Ben-Assuli and Thanh Hong Vo},
keywords = {Decision support, Disruptive technology, Health information systems, E-health, M-commerce, Literature review},
abstract = {Purpose
This narrative review surveys the literature on the Internet of Things (IoT) in healthcare, organising it according to dominant trends to provide instructive examples of how the IoT is used. It extends previous categorisations, providing an extensive framework for understanding IoT implementation in healthcare. It reflects on the nature of the current work, IoT models, success factors and the challenges facing IoT implementation.
Design
This paper follows Wolfswinkel et al. (2013) in selecting relevant articles and categorising them into six categories as suggested by Balandina et al. (2015) and Laranjo (2013) and synthesising a list of success factors.
Findings
The paper illustrates a need for deeper theoretical and conceptual work in this area. It concludes that healthcare systems need to be ready, through establishing appropriate collaborations and identifying value propositions, to adopt the huge level of technological advancement and change that results from the IoT. When suitably implemented and considered, the IoT can provide immense benefits in personalised care - without increasing the burden on human resources. However, while inexpensive technologies such as smartphones and wearables can be a conduit for many benefits, they also increase threats to security and data privacy. Success factors involve recogniton of the need for new business models which address the shorter lifecycle of IoT product development.
Originality
Our work provides a summary of recent trends, analysis of success factors and insight into the type of work completed - not provided by previous literature, which will be valuable to both researchers and practitioners.}
}
@article{HOU2020102019,
title = {Industrial espionage – A systematic literature review (SLR)},
journal = {Computers & Security},
volume = {98},
pages = {102019},
year = {2020},
issn = {0167-4048},
doi = {https://doi.org/10.1016/j.cose.2020.102019},
url = {https://www.sciencedirect.com/science/article/pii/S0167404820302923},
author = {Tie Hou and Victoria Wang},
keywords = {Industrial espionage, Systematic literature review (SLR), Key features, Challenges, Trends},
abstract = {Industrial Espionage (IE) is an umbrella term covering a complicated range of activities performed to gain competitive advantages, resulting in a huge amount of financial loss annually. Currently, techniques generated by rapid developments of Internet of Things (IOTs) and Data Science are enabling a massive increase of both frequency and power of IE related activities in our increasingly challenging global commercial environment. Thus, an in-depth understanding of IE is necessary. In this paper, we report a comprehensive Systematic Literature Review (SLR) of current English literature on IE. Particularly, we systematically: i) identify key features of IE by analysing its current definitions, and coin our own working definition; ii) discuss the current state of research on IE from different academic disciplines; iii) highlight some key challenges in the current state of research on IE; and iv) identify some possible trends in its future development. Further, based on our findings, we call for more multi-disciplinary/multi-agency research on IE in order to construct a comprehensive framework to combat IE.}
}
@article{MOYSIADIS2021102388,
title = {Extending ADR mechanism for LoRa enabled mobile end-devices},
journal = {Simulation Modelling Practice and Theory},
volume = {113},
pages = {102388},
year = {2021},
issn = {1569-190X},
doi = {https://doi.org/10.1016/j.simpat.2021.102388},
url = {https://www.sciencedirect.com/science/article/pii/S1569190X21000952},
author = {Vasileios Moysiadis and Thomas Lagkas and Vasileios Argyriou and Antonios Sarigiannidis and Ioannis D. Moscholios and Panagiotis Sarigiannidis},
keywords = {LoRa, LoRaWAN, Adaptive data rate, Mobile devices, Energy consumption},
abstract = {A considerable percentage of Internet of Things end-devices are characterised by mobility, a feature that adds extra complexity to protocols used in Wireless Sensor Networks. LoRa is one of the newly introduced wireless sensor protocols, capable of delivering messages in long distances and consuming low energy, features that make it proper for low cost devices. Although LoRa was introduced as a technology for stationary devices, it can also be used for mobile devices of low speed. In this paper, we introduce an enhancement to Adaptive Data Rate (ADR) mechanism to enable mobile LoRa, by improving the connection reliability of mobile end-devices, while keeping energy consumption at low levels. Firstly, we propose the Linear Regression-ADR (LR-ADR) mechanism for the Network Server side to smooth the Signal to Noise Ratio (SNR) estimates per gateway and predict the SNR of the next transmission. Secondly, we propose the Linear Regression + ADR (LR+ADR) mechanism, an adaptive method for the end-device side to regain the connectivity faster with the Network Server. We conducted simulation modelling to evaluate the performance of our implementation while we compared our results with four alternative solutions ADR, ADR+, EMA-ADR, G-ADR. The results prove that our first approach (LR-ADR) performs better than the best competitor, and our second approach (LR+ADR) brings an additional improvement in terms of Packet Delivery Ratio (PDR), while they retain the Energy Consumption per Packet Delivered (ECPD) at low levels. In particular, in a scenario that mimics real world conditions, LR+ADR presents an increase of up to 520% for PDR compared to the original ADR and an improvement of up to 38% compared to the best competitor (G-ADR). Moreover, it reduces ECPD up to 74% compared to the original ADR, while keeping it at the same level with the best competitor (G-ADR).}
}
@article{BIBRI2017219,
title = {On the social shaping dimensions of smart sustainable cities: A study in science, technology, and society},
journal = {Sustainable Cities and Society},
volume = {29},
pages = {219-246},
year = {2017},
issn = {2210-6707},
doi = {https://doi.org/10.1016/j.scs.2016.11.004},
url = {https://www.sciencedirect.com/science/article/pii/S2210670716305881},
author = {Simon Elias Bibri and John Krogstie},
keywords = {Smart sustainable cities, ICT, Computing, S&T, Urban sustainability, Discourse, Social construction, Innovation, Socio-technical, Techno-urban, Ecologically and technologically advanced societies},
abstract = {Situated within science of science, this study analyzes the nature, practice, and impact of ICT of the new wave of computing for urban sustainability as a form of science and technology (S&T) within the defining context of smart sustainable cities. Specifically, it probes the ways in which this form has emerged from different perspectives, why it has become institutionalized and interwoven with politics and policy—urban dissemination, as well as the risks it poses to environmental sustainability in the context thereof. To achieve these aims, an analytical and philosophical framework of STS is adopted, which supports analyses and evaluations whose approaches are drawn from a variety of disciplinary and theoretical perspectives. The study shows that smart sustainable cities are discursively construed and materially produced by the socially constructed understandings and socially anchored and institutionalized practices pertaining to ICT of the new wave of computing for urban sustainability. Thereby, such cities are medicated by and situated within ecologically and technologically advanced societies. And as urban manifestations of scientific knowledge and technological innovation, they are shaped by, and also shape, socio–cultural and politico–institutional structures. In addition, the study demonstrates that the success and expansion of smart sustainable cities stem from the transformational power, knowledge/power relation, productive and constitutive force, and legitimation capacity underlying ICT of the new wave of computing for urban sustainability due to its association with the scientific discourse and its societal entailments. This form of S&T is, however, shown to pose risks to environmental sustainability. Therefore, it needs to be reoriented in a more environmentally sustainable direction, as it can not, as currently practiced, solve the complex environmental problems placed in the agenda of smart sustainable cities as a holistic approach to urban development.}
}
@article{KU2021121198,
title = {A new algorithm for eco-friendly path guidance focused on electric vehicles},
journal = {Energy},
volume = {233},
pages = {121198},
year = {2021},
issn = {0360-5442},
doi = {https://doi.org/10.1016/j.energy.2021.121198},
url = {https://www.sciencedirect.com/science/article/pii/S0360544221014468},
author = {Donggyun Ku and Minje Choi and Nakyoung Yoo and Seungheon Shin and Seungjae Lee},
keywords = {Transportation and energy, Electric vehicles, Traffic assignment, Volume delay function, Gradient, Digital elevation model},
abstract = {The automobile industry is showing increasing interest in eco-friendly electric vehicles (EVs) with the aim of replacing vehicles that rely on traditional fossil fuels for energy. This study investigates the routing of an EV with maximum efficiency relative to the terrain. As EVs have poor climbing ability due to limitations associated with battery efficiency, this study determines the optimal route using 3D spatial information data and the slope of each link in the route. In the transportation field, the Bureau of Public Roads function classifies the shortest paths and optimizes paths. By adding slope-related variables, a new functional expression that includes weighting as a result of slope-related speed reduction is constructed, and a new functional expression system and network are built. As a result of assigning a route to optimize battery efficiency, the energy efficiency was improved by 7.84 km/kWh at an average speed of 70 km/h. The effectiveness was verified by comparing the total travel time and energy efficiency differences between the two methods. The proposed approach enables efficient transport and ultimately achieves the goal of green transportation with maximum energy efficiency.}
}
@article{WU20201187,
title = {PM2.5 concentrations forecasting using a new multi-objective feature selection and ensemble framework},
journal = {Atmospheric Pollution Research},
volume = {11},
number = {7},
pages = {1187-1198},
year = {2020},
issn = {1309-1042},
doi = {https://doi.org/10.1016/j.apr.2020.04.013},
url = {https://www.sciencedirect.com/science/article/pii/S1309104220300982},
author = {Haiping Wu and Hui Liu and Zhu Duan},
keywords = {PM concentrations forecasting, Time series multi-step forecasting, Multi-objective optimization},
abstract = {Multi-step PM2.5 concentrations forecasting can help reduce the negative impact of PM2.5 on public health. In this study, a hybrid method is proposed for multi-step PM2.5 concentrations forecasting. The proposed hybrid computing framework consists of three modules: hybrid data pretreatment, multi-objective feature selection and ensemble predicting. The hybrid data pretreatment can smooth the original series, generate more predictable sublayers. The multi-objective feature selection can produce the optimal input structure by rough selection and fine selection. The ensemble predicting can generate the forecasting results with the selected input structure. Four hourly pollutant data from four different cities in China are utilized to verify the effectiveness of the proposed model. The studying results indicated that: (a) the computational framework of the proposed model is proved to be effective; (b) the selected algorithms are advanced when compared with the alternative algorithms; (c) the 1-step mean absolute errors of the proposed model and three existing models on data from Hohhot are 3.2804 μg/m3, 7.0232 μg/m3, 5.1644 μg/m3 and 3.4720 μg/m3, respectively. The proposed hybrid computing model can generate accurate forecasting results with relatively small computational time, when compared with several existing models.}
}
@article{MARCODETCHART2021111,
title = {Ordered directional monotonicity in the construction of edge detectors},
journal = {Fuzzy Sets and Systems},
volume = {421},
pages = {111-132},
year = {2021},
note = {Data Science and Fuzzy Systems},
issn = {0165-0114},
doi = {https://doi.org/10.1016/j.fss.2020.07.002},
url = {https://www.sciencedirect.com/science/article/pii/S0165011420302712},
author = {C. Marco-Detchart and H. Bustince and J. Fernandez and R. Mesiar and J. Lafuente and E. Barrenechea and J.M. Pintor},
keywords = {Ordered directionally monotone function, Directional monotonicity, Edge detection, Consensus image},
abstract = {In this paper we provide a specific construction method of ordered directionally monotone functions. We show that the functions obtained with this construction method can be used to build edge detectors for grayscale images. We compare the results of these detectors to those obtained with some other ones that are widely used in the literature. Finally, we show how a consensus edge detector can be built improving the results obtained both by our proposal and by those in the literature when applied individually.}
}
@article{KHAN201893,
title = {Understanding autonomic network management: A look into the past, a solution for the future},
journal = {Computer Communications},
volume = {122},
pages = {93-117},
year = {2018},
issn = {0140-3664},
doi = {https://doi.org/10.1016/j.comcom.2018.01.014},
url = {https://www.sciencedirect.com/science/article/pii/S0140366417305327},
author = {Manzoor Ahmed Khan and Sebastian Peters and Doruk Sahinel and Francisco Denis Pozo-Pardo and Xuan-Thuy Dang},
keywords = {Autonomic network management, Self-x network management, Meta learning},
abstract = {The evolution of mobile network technologies and their vertical integration, heterogeneity of applications, and the advent of sophisticated end-user devices have continuously been expanding the complexity of network management tasks. In addition, there is a significant urge for the dynamic reconfiguration of networks to meet operators’ costs and to achieve their performance objectives. These facts substantiate the idea of pushing the classical human dependent network management approaches out of the equation to a great extent. The vast scope of network management makes it difficult to have a common understanding and definition, which is often noticeable in different research articles. The situation is further worsened by the network evolution timeline that traverses several technological shifts, such as the time when computer networks and mobile networks were far apart, to the time of fully IP-based and converged networks. Hence, one of the main aims of this paper is to provide a study of the network management evolution in general and in particular the concepts of autonomic network management, so that researchers may be equipped to understand the involved concepts. To achieve the aforementioned objective, the authors carried out an elaborate analysis of the different network management approaches, mapped them to a timeline, and discussed their features. This analysis sets the stage for an extensive discussion of the enabling concepts of autonomic network management, followed by a survey of research projects targeting the advancement of the autonomic networking vision. Having identified incomplete realizations of autonomic network management due to simplifying assumptions, this paper focused on the relevant aspects of architectural construction with the presentation of the core challenges to be addressed so as to realize a fully autonomic network management framework. These challenges led us to reconstruct the design goals that the contributions of this work were built upon. The first proposal of this paper is to deploy intelligent software agents on different hierarchical layers of the proposed mobile network architecture. The agents implement different stages of cognitive control loops and contribute to learning algorithms for various management tasks. CoDIPAS-RL learning framework is used for layer specific learning decisions. To advance the autonomic network management, the authors also propose a novel idea of self-learning that enables the meta-learning vision. This paper concludes with a discussion on the implementation of our autonomic network management framework and with a use case that shows the performance of the proposed approach.}
}
@article{AHN2020120062,
title = {Three characteristics of technology competition by IoT-driven digitization},
journal = {Technological Forecasting and Social Change},
volume = {157},
pages = {120062},
year = {2020},
issn = {0040-1625},
doi = {https://doi.org/10.1016/j.techfore.2020.120062},
url = {https://www.sciencedirect.com/science/article/pii/S0040162519322395},
author = {Sang-Jin Ahn},
keywords = {Industrial revolution, Industrial internet, Digitization, IoT, Industry 4.0, Patent analysis  CR, concentration ratio, CR3, 3-firm concentration ratio, EPO, European Patent Office, HHI, Herfindal-Hirschman Index, IBM, International Business Machines Corporation, ICT, information and communication technology, IoT, Internet of Things, IPC, International Patent Classification, JPO, Japan Patent Office, PCT, Patent Cooperation Treaty, R&D, Research and Development, RQ, research question, TCT, technology cycle time, U.S., United States, USPTO, United States Patent and Trademark Office},
abstract = {The purpose of this paper is to understand changes in the technological competitiveness of countries induced by Internet of Things (IoT)-driven digitization. Patent analysis, as one of the best ways to measure technological competitiveness, exhibits three characteristics of IoT-driven digitization, namely, agile innovation, stagnation across Asian countries, and the resurgence of the U.S., in turn taking advantage of network effects. The agile innovation of IoT-driven digitization suggests that digitization relies less on existing technologies and enables the leveraging of opportunities that arise from new order emergence. Some Asian countries took advantage of agile innovation as a window of opportunity in the previous age of digitization. These countries now lag less behind the U.S. as a result. Nevertheless, as these countries experience difficulties in taking advantage of agile innovation in the current age of digitization, they lag further behind the U.S. in terms of IoT-driven digitization. The structure of joint patent applications reveals that the U.S. has become a hub between the two European communities, the Chinese community and individual pro-American countries, implying that the network effect of IoT-driven digitization could have a significant impact on the technological competitiveness of countries.}
}
@article{ASKI2022108687,
title = {Advances on networked ehealth information access and sharing: Status, challenges and prospects},
journal = {Computer Networks},
volume = {204},
pages = {108687},
year = {2022},
issn = {1389-1286},
doi = {https://doi.org/10.1016/j.comnet.2021.108687},
url = {https://www.sciencedirect.com/science/article/pii/S1389128621005545},
author = {Vidyadhar Jinnappa Aski and Vijaypal Singh Dhaka and Sunil Kumar and Sahil Verma and Danda B. Rawat},
keywords = {Internet of medical things, Access controlling techniques, Interoperability},
abstract = {Abstarct
Internet of Medical Things (IoMT) is no longer a futuristic technology and has become a day-to-day reality with the increasing ease of availing modern internet services. IoMT services interconnect numerous healthcare ecosystem stakeholders, such as doctors, patients, pharmacists, etc., seamlessly under the light of Advanced Internet Communication Tools (AICT). Wireless Body Area Network (WBAN) is a primary constituent of any IoMT device, offering a data acquisition environment through various bio-sensors deployed in edge devices. The data generated through such edge devices should be stored securely in Electronic Health Server (EHS) for further analysis and knowledge inference by medical professionals. Thus designing access control techniques that prevent unauthorised access at the cloud and device level is crucial. Interoperability concern in the IoMT development cycle is becoming a focus of interest for many researchers because most devices and underlying protocols are highly heterogeneous. Lack of worldwide acceptable protocol standards is another major issue in dealing with platform interoperability. In this study, the authors describe the various existing device and data access control strategies such as RBAC (Role Based Access Controlling), CaPBAC (Capability-Based Access Controlling), and ABAC (Attribute-Based Access Controlling), etc. This article majorly surveys the literature from 2000 to 2020 on various access controlling and Interoperability aspects as they are potential players of modern IoT applications. The study also comprehensively discusses the state-of-the-art strategies that provide platform interoperability followed by crucial implementation challenges. CCS CONCEPTS • General and reference→Surveys and overview;• Access Control→Access control strategies; • Interoperability→ patterns}
}
@article{HAMID2021100337,
title = {How smart is e-tourism? A systematic review of smart tourism recommendation system applying data management},
journal = {Computer Science Review},
volume = {39},
pages = {100337},
year = {2021},
issn = {1574-0137},
doi = {https://doi.org/10.1016/j.cosrev.2020.100337},
url = {https://www.sciencedirect.com/science/article/pii/S1574013720304378},
author = {Rula A. Hamid and A.S. Albahri and Jwan K. Alwan and Z.T. Al-qaysi and O.S. Albahri and A.A. Zaidan and Alhamzah Alnoor and A.H. Alamoodi and B.B. Zaidan},
keywords = {e-tourism, Smart tourism, Tourism recommender systems, TRS},
abstract = {Extensive research has been conducted on e-tourism spanning a wide range of concepts, challenges and concerns discussed in tourism recommender systems (TRS). Smart tourism can be considered a logical progression from e-tourism laid with the extensive adoption of information and communication technologies and connecting the physical and digital worlds by taking advantage of 12 ‘smart key concepts’ such as privacy protection, Internet of Things and augmented reality, among others. Consequently, several disparate types of research have existed in various classes of TRS that have accomplished smart key concepts where others have failed. However, such piecemeal development is insufficient for a pragmatic smart tourism solution. Accordingly, the current study complements the academic literature with a systematic review that covers all main aspects of the e-tourism management system applied to the smart tourism concepts over the last eight years of publication. This study also provides a state-of-the-art e-tourism data management classification taxonomy based on smart concepts and reviews works in different fields against that classification. To this end, we reviewed the ScienceDirect, IEEE Xplore and Web of Science databases. A total of 1240 papers were collected from 2013 to 2020. The retrieved articles were filtered according to the defined inclusion criteria. Finally, 65 articles were selected and classified into two categories. The first category includes smart-based TRS that accounts for 87.70% (n = 57/65) and classified into four approaches: collaborative filtering, content model, context model and hybrid model. The second category includes tourism marketing that accounts for 12.30% (n = 8/65). This multi-field systematic review has exposed new research opportunities, motivations, recommendations and challenges and limitations that need attention for the synergistic smart integration of interdisciplinary studies. The reliability and acceptability of smart-based TRS approach from the implemented 12 smart key concepts show a significant difference. Analysis shows that the content model-based approach has a highly important effect on smart e-tourism, i.e., applying numerous smart key concepts in higher mean (40.2%). Results of several past studies that used a content model-based approach were nearly perceived as smart e-tourism. The smartly achieved key concepts for hybrid and context-based approaches have approximate means of (37.9%) and 36.6%, respectively, thereby confirming results. The results of tourism marketing and collaborative filtering approaches are worse than the previously reported results, achieving means of (33.3%) and (30.3%), respectively. This study is a useful guide for researchers and practitioners in providing avenues and valuable information for future research. This study is also expected to address the ambiguity of e-tourism and smart tourism trends.}
}
@article{DEVITO2020127869,
title = {On the robustness of field calibration for smart air quality monitors},
journal = {Sensors and Actuators B: Chemical},
volume = {310},
pages = {127869},
year = {2020},
issn = {0925-4005},
doi = {https://doi.org/10.1016/j.snb.2020.127869},
url = {https://www.sciencedirect.com/science/article/pii/S0925400520302161},
author = {Saverio {De Vito} and Elena Esposito and Nuria Castell and Philipp Schneider and A. Bartonova},
keywords = {Field calibration robustness, Mobile air quality multi-sensor platforms, Sensors relocation, Concept drift, Learning in dynamic environments},
abstract = {The robustness of field calibrated Air Quality Multi-sensors (AQM) performances to long term and/or mobile operation is still debated. Though accuracy generally exceeds the one of laboratory calibrations models, experimental results show that field calibration models cannot sustain optimal field performances due to changes occurring in operative conditions. Among them, the relocation of calibrated multi-sensors platforms and sensor drift are considered as the most relevant. In this work, we want to provide an answer to the general issue of field calibration robustness assessement. Analysing theoretical foundations and providing tools for determining the calibration model validity domain. In particular, by leveraging the probability distribution of target and interferent gas as well as environmental variables, measures of dissimilarity between calibration and operative phase conditions are considered to quantitatively capture the occurring change. A 6 months multiple nodes dataset including node relocations events in several sites have been processed for deriving nonlinear multivariate field calibrations whose robustness to changing conditions have been analysed. Kullback-Leibler, Euclidean and Hellinger dissimilarity measurements have been correlated with recorded performance degradation. Results show that quantifying relevant factors probability distribution changes allows to explain and predict performances of in field data driven calibration models. They also highlight the role of concept drift in explaining field performances ameliorating our capability to select optimal conditions in which a field calibration should be derived. Finally, smart air quality monitors could now autonomously detect the need for re-calibration.}
}
@article{KE20183,
title = {Big data analytics enabled by feature extraction based on partial independence},
journal = {Neurocomputing},
volume = {288},
pages = {3-10},
year = {2018},
note = {Learning System in Real-time Machine Vision},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2017.07.072},
url = {https://www.sciencedirect.com/science/article/pii/S0925231217319215},
author = {Qiao Ke and Jiangshe Zhang and Houbing Song and Yan Wan},
keywords = {Independent Component(IC), Overcomplete features, Sparse representation, Big data},
abstract = {Complex cells in primary visual cortex (V1) selectively respond to bars and edges at a particular location and orientation. Namely, they are relatively invariant to the phase as well as selective to the frequency and orientation emerging from natural images that are analogous to the characteristics of complex cells in V1 with the energy function of receptive fields (RFs) from tuning curve test with sinusoidal function in our related jobs. In this paper, we propose a feature learning algorithm based on the overcomplete AISA to apply on big data in parallel computing. In order to demonstrate the effectiveness of the overcomplete AISA features in the classification task, two feature representation architectures are evolved into the partial independent signal bases and partial independent factorial representation, respectively. Experiments on four datasets (Coil20, Extended YaleB, USPS, PIE), acquired conjunction with two classification architectures based on the overcomplete AISA features, show that the classification accuracy is mostly higher than those obtained from the other ICA related features and two other sparse representation features with a small number of training samples via nearest neighbor (NN) classification method.}
}
@article{SANCHEZMARTINEZ2016236,
title = {Workshop 5 report: Harnessing big data},
journal = {Research in Transportation Economics},
volume = {59},
pages = {236-241},
year = {2016},
note = {Competition and Ownership in Land Passenger Transport (selected papers from the Thredbo 14 conference)},
issn = {0739-8859},
doi = {https://doi.org/10.1016/j.retrec.2016.10.008},
url = {https://www.sciencedirect.com/science/article/pii/S0739885916301494},
author = {Gabriel E. Sánchez-Martínez and Marcela Munizaga},
keywords = {Big data, Measurement, Implementation challenges, Analysis tools, Transit best practices},
abstract = {A group of researchers, consultants, software developers, and transit agencies convened in Santiago, Chile over 3 days as part of the Thredbo workshop titled “Harnessing Big Data”, to present their recent research and discuss the state of practice, state of the art, and future directions of big data in public transportation. This report documents their discussion. The key conclusion of the workshop is that, although much progress has been made in utilizing big data to improve transportation planning and operations, much remains to be done, both in terms of developing further analysis tools and use cases of big data, and of disseminating best practices so that they are adopted across the industry.}
}
@article{NTAKOU201945,
title = {Full AC analysis of value of DER to the grid and optimal DER scheduling},
journal = {The Electricity Journal},
volume = {32},
number = {4},
pages = {45-49},
year = {2019},
note = {Special Issue on Strategies for a sustainable, reliable and resilient grid},
issn = {1040-6190},
doi = {https://doi.org/10.1016/j.tej.2019.03.007},
url = {https://www.sciencedirect.com/science/article/pii/S1040619019300661},
author = {Elli Ntakou and Ralph Masiello and Farnaz Farzan and Shay Bahramirad and Aleksi Paaso and M.A. Nayeem and Maigha Maigha and Daniel Kushner},
keywords = {Value of DER, Cost of capacity, Locational marginal value, AC OPF},
abstract = {This paper presents part of the work ComEd and Quanta Technology have performed to quantify the locational and temporal value of DER to avoid distribution grid upgrade investments. It focuses on the formulation of a robust and efficient algorithm for DER optimal dispatch on a distribution feeder to mitigate the violation of current and voltage limits using the allocated cost of capacity and locational marginal value of real and reactive DER injection/withdrawal.}
}
@article{KANO20191347,
title = {A Method of Extracting and Classifying Local Community Problems from Citizen-Report Data using Text Mining},
journal = {Procedia Computer Science},
volume = {159},
pages = {1347-1356},
year = {2019},
note = {Knowledge-Based and Intelligent Information & Engineering Systems: Proceedings of the 23rd International Conference KES2019},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2019.09.305},
url = {https://www.sciencedirect.com/science/article/pii/S1877050919315054},
author = {Eiji Kano and Yoshikatsu Fujita and Kazuhiko Tsuda},
keywords = {Text mining, Citizen Report, Chiba-Repo, government},
abstract = {Local governments are required to appropriately prioritize and respond to regional issues that are becoming diversified and complicated under the constraints of manpower and budget. In addition, it is required to understand regional issues based on objective data analysis from the viewpoint of “evidence-based policymaking.” Under these circumstances, the “Citizen-Report” mechanism, which has recently been introduced in local governments, may contribute not only to prompt resolution of individual field problems but also to the clarification of the tendencies of problem occurrence. However, the classification of problems is not necessarily set for reflecting the actual occurrence tendencies. Therefore, this study proposes a method to extract and classify problems in an objective and reproducible manner that reflects the tendencies of actual problem occurrences by analyzing the content of the Citizen-Report using text mining. We verify this method using the data of Chiba City as an example, and the result shows that the tendencies of real problem occurrence, which were not able to be understood by classifying based on the category of the department in charge in local government such as “roads” or “parks,” became clear. This method is also applicable to other Citizen-Report data and can be expected to be used for understanding regional issues in various local governments.}
}
@article{KAUR2021520,
title = {A survey on energy efficient routing techniques in WSNs focusing IoT applications and enhancing fog computing paradigm},
journal = {Global Transitions Proceedings},
volume = {2},
number = {2},
pages = {520-529},
year = {2021},
note = {International Conference on Computing System and its Applications (ICCSA- 2021)},
issn = {2666-285X},
doi = {https://doi.org/10.1016/j.gltp.2021.08.001},
url = {https://www.sciencedirect.com/science/article/pii/S2666285X21000273},
author = {Loveleen Kaur and Rajbir Kaur},
keywords = {Energy efficiency, Internet of Things (IoT), Wireless Sensor Networks (WSNs), Fog computing, Sensor networks, Routing},
abstract = {Standardization and technological advancements have contributed in the development of the IoT. The accessibility of ease IoT gadgets has likewise assumed a key job in facilitating IoT research, improvement, and deployment. IoT is worldview network that permits the virtual existence of physical objects throughout our life. The Internet of Things (IoT) is based on the idea of installing embedded devices in everyday objects. In the mean time, because of the low cost and high accessibility of sensor devices, wireless sensor networks (WSNs) have an extraordinary job in overspreading of IoT. To be clear, the function of such systems is completely unpredictable in terms of node heterogeneity and node failure. Continuous advancements in IoT systems have resulted in several of the new protocols designed specifically for sensor networks where energy saving is such a top priority. The routing protocols, on the other hand, have earned the most attention because they might change based on the application and network design. This study examines the most recent routing protocols for sensor networks and developing action plans for the various approaches pursued. One of the potential drawbacks in the IoT is the energy requirement. Furthermore, several directions to extend the network's life expectancy have attracted in an expanding level of attention. Recently, a number of a achievements have emerged. Designing routing protocols is one of the most encouraging of these mechanisms, as demonstrated by the significant amount of energy required for information transmission. This paper begins with a detailed description of the foundation and its associated works. In addition, this study introduces a new routing protocol to increase the energy efficiency of sensor devices in the Internet of Things.}
}
@article{QIAN2021110519,
title = {Operation and performance of VRF systems: Mining a large-scale dataset},
journal = {Energy and Buildings},
volume = {230},
pages = {110519},
year = {2021},
issn = {0378-7788},
doi = {https://doi.org/10.1016/j.enbuild.2020.110519},
url = {https://www.sciencedirect.com/science/article/pii/S0378778820315425},
author = {Mingyang Qian and Da Yan and Tianzhen Hong and Hua Liu},
keywords = {VRF system, Data mining, Big data, System performance, China, Energy efficiency},
abstract = {The energy consumption of air-conditioning systems has gained increasing attention as it contributes significantly to the global building energy use. The variable refrigerant flow (VRF) system is a common air-conditioning system applied widely in residential and office buildings in China. Understanding the actual operation and performance of VRF systems is fundamental for the energy-efficient design and operation of VRF systems. Previous research on VRF system operation used either limited field data covering certain building types and climate zones or used a questionnaire to obtain a larger dataset. However, they did not capture the wide applications of VRF systems quantitatively across all building types, climate zones, and operating conditions. To fill this gap, statistical and clustering analysis was conducted on the newly proposed key performance indicators of approximately 287,000 VRF systems for residential and commercial buildings in all five climate zones in China. The main findings are: (1) VRF systems are mainly used for cooling in all climate zones in China; (2) among all building types, the duration of use is lowest in residential buildings and highest in hotels and medical buildings; (3) the distribution of the ideal VRF cooling coefficient of performance (COP) is similar across all climate zones and building types; whereas the COPs of ideal VRF heating in the Severe Cold region and Cold regions are lower than those in other climate zones; and (4) partial load operations for VRF systems are common in residential buildings and office buildings due to the part-time-part-space operation mode. These findings can inform the actual application of VRF systems in China, supporting the design, operation, industry standard development, and performance optimization of VRF systems.}
}
@article{MEI2020447,
title = {From pedestrian to group retrieval via siamese network and correlation},
journal = {Neurocomputing},
volume = {412},
pages = {447-460},
year = {2020},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2020.06.055},
url = {https://www.sciencedirect.com/science/article/pii/S0925231220310432},
author = {Ling Mei and Jianhuang Lai and Zhanxiang Feng and Xiaohua Xie},
keywords = {Siamese Network, Minimum Distance Matching, Group Retrieval Correlation, Benchmark},
abstract = {In many public security applications such as anomaly detection, it is important to re-identify a group of pedestrians by other surveillance cameras, which ascribes to the group retrieval problem. Most previous studies focus on single-person re-identification (re-id) and ignore the correlations among group members, and they lack a large and comprehensive group retrieval benchmark to associate these two tasks. To address this issue, this paper focuses on solving the group retrieval problem and uses it to improve re-id. First, the paper build a comprehensive benchmark for both group retrieval and the group-aided re-id task by proposing a novel pedestrian group retrieval dataset named “SYSU-Group” and a corresponding group-associated re-id dataset named “Group-reID”, which introduces realistic challenges such as variations of pose, viewpoint, illumination, and intra-group layout. The paper then proposes the Siamese Verification-Identification-based Group Retrieval (SVIGR) method, which combines verification and identification modules in a Siamese network to extract robust person features and follows the principle of minimum distance matching to realize group retrieval. Finally, a group-guided re-id method named group retrieval correlation (GRC) is proposed to improve re-id with additional group information. Experimental results on three various group retrieval benchmarks demonstrate the superiority and effectiveness of our method.}
}
@article{GOODE20185,
title = {Biometrics for banking: best practices and barriers to adoption},
journal = {Biometric Technology Today},
volume = {2018},
number = {10},
pages = {5-7},
year = {2018},
issn = {0969-4765},
doi = {https://doi.org/10.1016/S0969-4765(18)30156-5},
url = {https://www.sciencedirect.com/science/article/pii/S0969476518301565},
author = {Alan Goode},
abstract = {Banks are increasingly adopting biometric technology in their drive to better identify new customers, securely authenticate existing customers, protect high-value transactions and combat fraud. In fact, as banks deploy biometrics everywhere from traditional physical branches to the latest digital platforms, this technology is proving to be the sole reliable means to authenticate and secure banking customers across all channels.}
}
@article{ABIOYE2022103915,
title = {The performance and cognitive workload analysis of a multimodal speech and visual gesture (mSVG) UAV control interface},
journal = {Robotics and Autonomous Systems},
volume = {147},
pages = {103915},
year = {2022},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2021.103915},
url = {https://www.sciencedirect.com/science/article/pii/S0921889021002001},
author = {Ayodeji Opeyemi Abioye and Stephen D. Prior and Peter Saddington and Sarvapali D. Ramchurn},
keywords = {Aerobot, mSVG (multimodal speech and visual gesture), nCA (navigation control autonomy), RFDS (RealFlight Drone Simulator), Speech, Visual gesture},
abstract = {This paper conducts a comparison of the performance and cognitive workload between three UAV control interfaces on an nCA (navigation control autonomy) Tier 1-III flight navigation task. The first interface is the standard RC Joystick (RCJ) controller, the second interface is the multimodal speech and visual gesture (mSVG) interface, and the third interface is the modified version of the RCJ interface with altitude, attitude, and position (AAP) assist. The modified RCJ interface was achieved with the aid of the Keyboard (KBD). A model of the mSVG interface previously designed and tested was used in this comparison. An experiment study was designed to measure the completion time and navigation accuracy of participants using each of the three interfaces, on a developed path_v02 test flight path. Thirty-seven (37) participants volunteered. The NASA task load index (TLX) survey questionnaire was administered at the end of each interface experiment to access the participants experience and to estimate the interface cognitive workload. A commercial software, the RealFlight Drone Simulator (RFDS) was used to estimate the RCJ skill level of the participants. From the results of the experiment, it was shown that the flying hours, the number of months flying, and the RFDS Level 4 challenge performance was a good estimator for participants RCJ flying skill level. A two-way result was obtained in the comparison of the RCJ and mSVG interfaces. It was concluded that, although the mSVG was better than the standard RCJ interface, the AAP-assisted RCJ was found to be as effective as (in some cases better than) the mSVG interface. It was also shown, from the speech gesture ratio result, that the participants had a preference for gesture over speech when using the mSVG interface. Some further works such as an outdoor field test and a performance comparison at higher nCA levels were suggested.}
}
@article{REKA201890,
title = {Future effectual role of energy delivery: A comprehensive review of Internet of Things and smart grid},
journal = {Renewable and Sustainable Energy Reviews},
volume = {91},
pages = {90-108},
year = {2018},
issn = {1364-0321},
doi = {https://doi.org/10.1016/j.rser.2018.03.089},
url = {https://www.sciencedirect.com/science/article/pii/S1364032118301837},
author = {S. Sofana Reka and Tomislav Dragicevic},
keywords = {Internet of Things, Smart grid, Smart buildings, Smart meters},
abstract = {In today's ecosystem of energy management, the contribution of Internet of Things (IoT) to smart grids has acquired immense potential due to its multi-faceted advantages in various fields. IoT paves a way to associate and virtually control everything in almost every domain of society. Conversely, the smart grid framework attracted the attention of the universal research community and the idea of merging IoT with smart grid together demonstrates enormous growth potential. This review paper highlights the most significant research works that focus on applying IoT to smart grids. This work also addresses many innovative approaches used in IoT and smart grids along with their respective applications in various fields. The objective of this work is to benefit scientists and new entrants in the field of IoT and smart grids opens up awareness for new interdisciplinary research.}
}
@article{PARTHIBAN2021,
title = {Effective resource scheduling using hybrid gradient descent cuckoo search algorithm and security enhancement in cloud via blockchain for healthcare 4.0},
journal = {Materials Today: Proceedings},
year = {2021},
issn = {2214-7853},
doi = {https://doi.org/10.1016/j.matpr.2021.10.473},
url = {https://www.sciencedirect.com/science/article/pii/S2214785321069807},
author = {R. Parthiban and K. {Santhosh Kumar}},
keywords = {Modern healthcare system, Healthcare 4.0, Internet of Things (IoT), Cloud computing, Resource sharing, Blockchain, Hybrid gradient decent cuckoo search algorithm},
abstract = {The Modern Healthcare System (MHS) has become a revolutionized domain over the past decade and has extemporized from version 1.0 to 4.0 with an amalgamation of IoT and its allied technologies. The record sustaining in the MHS is the superlative task in Healthcare 4.0 and the need for maintaining the integrity and resource availability congregate challenges like cyber attacks, lack of resources, etc. However, these challenges can be subdued through augmented resource sharing and blockchain technology. Blockchain technology has proven to be more promising in preserving data security and maintaining the integrity of sensitive data. The conventional healthcare system is slowly cruising towards the modern healthcare domain for the ease of process by the users and for adopting rapid sharing and accessing of healthcare data by the authorized users. Cloud computing offers a major role in modernizing the conventional healthcare system as the patient’s sensitive data were shared and stored in the cloud resources so that to access across the world. Even with the preoccupation of technology like cloud computing, there exists certain challenge like resource availability and data security and to address the aforementioned challenges this paper introduces an integrated model of Hybrid Gradient Decent Cuckoo Search (HGDCS) algorithm for effective resource sharing and Blockchain technology for affording inherent security and high level of integrity for the sensitive data.}
}
@article{CIRIBINI20171484,
title = {Tracking Users’ Behaviors through Real-time Information in BIMs: Workflow for Interconnection in the Brescia Smart Campus Demonstrator},
journal = {Procedia Engineering},
volume = {180},
pages = {1484-1494},
year = {2017},
note = {International High-Performance Built Environment Conference – A Sustainable Built Environment Conference 2016 Series (SBE16), iHBE 2016},
issn = {1877-7058},
doi = {https://doi.org/10.1016/j.proeng.2017.04.311},
url = {https://www.sciencedirect.com/science/article/pii/S1877705817318180},
author = {Angelo L.C. Ciribini and Daniela Pasini and Lavinia C. Tagliabue and Massimiliano Manfren and Bruno Daniotti and Stefano Rinaldi and Enrico {De Angelis}},
keywords = {Building Information Modelling, Building Management Systems, Intelligent Building, Behavioural Modelling, Interoperability},
abstract = {An intelligent building supports the needs of its occupants by data analytics. Nowadays, buildings are evolving from being products to become effective service providers for end-users: thus, occupancy topics become crucial. The paper focuses on building operations, pointing out how advantages in supporting the needs of users could be derived through the implementation of Building Management Systems (BMS) into a Building Information Modeling (BIM) environment, connecting real-time information collected by sensors to a BIM database. The connection and the integration of information between BIM and BMS have been established based on the Industry Foundation Classes (IFC) neutral data format; moreover, web-interfaces and apps have been tested for enhancing information to be visualized by different end-users. The ongoing research has a twofold scope: 1) to point-out how buildings should evolve, managing knowledge coming from sensors in order to anticipate the needs of users, and 2) to analyze whether and how the centrality of users should change the building process. The proposed workflow has been tested on the Brescia Smart Campus Demonstrator, a building equipped with 94 off-the-shelf sensors.}
}
@article{VECCHIO2019119771,
title = {A system dynamic approach for the smart mobility of people: Implications in the age of big data},
journal = {Technological Forecasting and Social Change},
volume = {149},
pages = {119771},
year = {2019},
issn = {0040-1625},
doi = {https://doi.org/10.1016/j.techfore.2019.119771},
url = {https://www.sciencedirect.com/science/article/pii/S0040162519306419},
author = {Pasquale Del Vecchio and Giustina Secundo and Ylenia Maruccia and Giuseppina Passiante},
keywords = {Big data, Smart mobility, Data science, System dynamics, Simulation Model, Decision Making},
abstract = {Mobility of people can be configured as an information intensive process resulting from a complex set of factors. Its effective implementation requires the adoption of methods able to leverage on a set of complex and dynamic variables, and mainly on a huge amount of data available. Moving from this assumption, this paper aims to demonstrate that system dynamics could present a useful approach for optimising decision making for people's mobility. The conceptual model is built by using the principles of system dynamics methodology and is based on causal feedback relationships among the various factors related to the different needs of people's mobility. The causal feedback loops and interrelationship among various parameters illustrate the dynamicity and the influence of parameters on one another. The simulation analysis was conducted to dynamically evaluate six scenarios corresponding to the different solutions available for particular segments of demand. Findings highlight that the modelling approaches could guide the city planners to evolve responsive policy interventions for further developing smart mobility of people. Implications for policy makers regard the developing sustainable mobility scenarios based on the analysis of big data from the adoption of digital platforms grounded on the simulation model.}
}
@article{LITOUSSI2020503,
title = {IoT security: challenges and countermeasures},
journal = {Procedia Computer Science},
volume = {177},
pages = {503-508},
year = {2020},
note = {The 11th International Conference on Emerging Ubiquitous Systems and Pervasive Networks (EUSPN 2020) / The 10th International Conference on Current and Future Trends of Information and Communication Technologies in Healthcare (ICTH 2020) / Affiliated Workshops},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2020.10.069},
url = {https://www.sciencedirect.com/science/article/pii/S1877050920323395},
author = {Mohamed Litoussi and Nabil Kannouf and Khalid {El Makkaoui} and Abdellah Ezzati and Mohamed Fartitchou},
keywords = {Internet of things (IoT), Security, Cryptography},
abstract = {Internet of things (IoT) dramatically influences our daily lives in several domains, ranging from teeny wearable devices to large industrial systems. IoT technology aims to enhance humans life quality. Nevertheless, IoT is vulnerable to various cyberattacks and needs challenging techniques in order to achieve their security. The principal objective of IoT security is to protect the privacy of the customers, the data integrity and confidentiality, the security of infrastructures and IoT devices, likewise, ensure the availability of services provided by an IoT ecosystem. In this work, we present the IoT security challenges and countermeasures.}
}
@article{YANG2021107779,
title = {Design, analysis and implementation of a smart next generation secure shipping infrastructure using autonomous robot},
journal = {Computer Networks},
volume = {187},
pages = {107779},
year = {2021},
issn = {1389-1286},
doi = {https://doi.org/10.1016/j.comnet.2020.107779},
url = {https://www.sciencedirect.com/science/article/pii/S1389128620313554},
author = {Jiapie Yang and Prosanta Gope and Yongqiang Cheng and Li Sun},
keywords = {Cooperative user authentication system, Non-cooperative user authentication system, Person reidentification, QR code},
abstract = {In general, price is the key element in shipping, and half of the costs are tied up in last-mile deliveries. The biggest expense here is the human element, so companies, which can cut down on staff costs, will be able to out-price their competitors. Therefore, we expect sooner, or later robotic delivery systems will become the norm. However, ensuring security in such a system will be a challenge. In this article, we propose a secure shipping infrastructure using robot. In this regard, we first design a cooperative user authentication system for delivering parcel using crypto primitives such as one-way hash function, asymmetric encryption and QR code. Next, we design a non-cooperative user identification scheme using Siamese Network for Person Reidentification, where the client is not ready to cooperate during the authentication process. Therefore, the robot carrier needs to automatically recognize and go towards the client to deliver the parcel in a secure way. Finally, we implement the proof-of-concept system through a cooperative user authentication process using TurtleBot3 robot platform and analyse the security of the proposed scheme using ProVerif. Analysis and experiment results show that our proposed system can complete the delivery mission and resist a variety of security attacks.}
}
@article{TOOR20191112,
title = {Energy and performance aware fog computing: A case of DVFS and green renewable energy},
journal = {Future Generation Computer Systems},
volume = {101},
pages = {1112-1121},
year = {2019},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2019.07.010},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X19310234},
author = {Asfa Toor and Saif ul Islam and Nimra Sohail and Adnan Akhunzada and Jalil Boudjadar and Hasan Ali Khattak and Ikram Ud Din and Joel J.P.C. Rodrigues},
keywords = {Fog computing, Power consumption, Blockchain, QoS, Renewable energy, Green energy, DVFS},
abstract = {Fog Computing has appeared as a very favorable computing paradigm for location, time, and delay sensitive applications. The aforementioned features make fog computing an extremely suitable interface between the Internet of Things (IoT) and Cloud. Despite implementation, design, modeling, computing, communication, and several architectural challenges, performance and energy aware Fog–IoT computing has not attained significant attention by the researchers lately. To that end, this paper encompasses the concept of green renewable energy in the fog environment. In order to effectively add authentication as well as security layer to this sensitive data, blockchain presents a ideal solution for securing a centralized ledger of the utilization data. Blockchain technology being easy to deploy and having cross platform nature becomes an ideal candidate for leveraging the full potential of the system. This paper proposes an adaptive performance and energy-aware scheme for Fog–IoT computational environment. To evaluate the effectiveness of our proposed methodology, simulations are configured through iFogSim simulator and the results are compared with the state-of-the-art methodology. This proposed scheme is also formally verified for the safety properties. Experimental results demonstrate that the scheme performs significantly better than the compared approach in terms of energy consumption in the power saver mode. Moreover, the proposed scheme also establishes its efficacy in terms of the Quality of Service (QoS) parameters in both the power saver mode and the conservative mode.}
}
@article{GUO2022381,
title = {Constructing a prior-dependent graph for data clustering and dimension reduction in the edge of AIoT},
journal = {Future Generation Computer Systems},
volume = {128},
pages = {381-394},
year = {2022},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2021.09.044},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X21003903},
author = {Tan Guo and Keping Yu and Moayad Aloqaily and Shaohua Wan},
keywords = {IoT, AI, AIoT, Edge computing, Data analysis, Data clustering, Dimensionality reduction, Graph learning},
abstract = {The Artificial Intelligence Internet of Things (AIoT) is an emerging concept aiming to perceive, understand and connect the ‘intelligent things’ to make the intercommunication of various networks and systems more efficient. A key step in achieving this goal is to carry out high-precision data analysis at the edge and cloud level. Clustering and dimensionality reduction in AIoT can facilitate efficient data management, storage, computing, and transmission of various data-driven AIoT applications. For high-efficiency data clustering and dimensionality reduction, this paper develops a prior-dependent graph (PDG) construction method to model and discover the complex relations of data. With the proper utilization and incorporation of data priors, i.e., (a) element local sparsity; (b) pair-wise symmetry; (c) multi-instance manifold smoothness; and (d) matrix low-rankness, the obtained graph has the characteristics of local sparsity, symmetry, low-rank, and can well reveal the complex multi-instance proximity among data points. The developed PDG model is then applied for two typical data analysis tasks, i.e., unsupervised data clustering and dimensionality reduction. Experimental results on multiple benchmark databases verify that, compared with some existing graph learning models, the PDG model can achieve substantial performance, which can be deployed in edge computing modules to provide efficient solutions for massive data management and applications in AIoT.}
}
@article{YAO2021357,
title = {Efficiently mining maximal co-locations in a spatial continuous field under directed road networks},
journal = {Information Sciences},
volume = {542},
pages = {357-379},
year = {2021},
issn = {0020-0255},
doi = {https://doi.org/10.1016/j.ins.2020.06.057},
url = {https://www.sciencedirect.com/science/article/pii/S0020025520306459},
author = {Xiaojing Yao and Xufeng Jiang and Dacheng Wang and Lina Yang and Ling Peng and Tianhe Chi},
keywords = {Co-location pattern mining, Road network, Traffic direction, Distance decay effect, Spatial continuity},
abstract = {Extracting useful spatial co-location patterns from urban service facilities can help planners allocate limited resources effectively. These facilities are mostly distributed within man-made spatial fields with road-network constraints. To promote urban-space adaptivity, co-location algorithms for this network circumstance have been designed with distance decay effects and topological relationships of roads. However, these algorithms neglect the traffic direction, which affects the accuracy of the results. Moreover, the efficiency problem is more severe than with the traditional algorithm (i.e., no constraints). To address these problems, we propose an efficient maximal co-location mining algorithm with directed road-network constraints and spatial-continuity consideration (CMDS). To improve the accuracy, we design a network-based prevalence index, combined with both distance decay effects and road direction interference, to measure the significance of a pattern. To promote the execution speed, we use a key-node-separating approach and an improved shortest-path batch task for the co-location mining process. The experiments with both the synthetic and real datasets show that the CMDS algorithm is more efficient and accurate than the state-of-the-art network co-location when applied to problems in an urban space.}
}
@article{GASSAR2020110238,
title = {Energy prediction techniques for large-scale buildings towards a sustainable built environment: A review},
journal = {Energy and Buildings},
volume = {224},
pages = {110238},
year = {2020},
issn = {0378-7788},
doi = {https://doi.org/10.1016/j.enbuild.2020.110238},
url = {https://www.sciencedirect.com/science/article/pii/S0378778820301237},
author = {Abdo Abdullah Ahmed Gassar and Seung Hyun Cha},
keywords = {Energy use, Black-box based approach, Grey-box based approach, White-box based approach, Large-scale buildings},
abstract = {Building energy prediction techniques are the primary tool for moving towards sustainable built environments. Energy prediction models play irreplaceable roles in making energy policy and the development of the building sector. This paper presents a comprehensive review of the prevailing prediction techniques used in large-scale building energy applications under different scopes and different archetypes, including black-box, white-box, and grey-box based methods. Additionally, the advantages and disadvantages of the applications of those approaches are compared and discussed in the context of large-scale buildings. The review results show that prediction techniques have addressed a variety of large-scale building energy related-applications, such as energy consumption forecasting and prediction, energy consumption profiling, energy mapping and benchmarking of buildings. However, there are still some research gaps that require more attention such as the inclusion of occupant behavior in white-box based models and the explicit representation of end-uses in black-box based models. Significantly, this review concludes with a few key tasks for modification of the current prediction approach framework, which can help with forecasting future energy use changes of specific buildings during the retrofit process or inclusion of renewable energy technology. This would assist in developing an appropriate strategy for the sustainability of the built environment.}
}
@article{YASSINE2019563,
title = {IoT big data analytics for smart homes with fog and cloud computing},
journal = {Future Generation Computer Systems},
volume = {91},
pages = {563-573},
year = {2019},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2018.08.040},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X18311099},
author = {Abdulsalam Yassine and Shailendra Singh and M. Shamim Hossain and Ghulam Muhammad},
keywords = {Internet of Things (IoT), Cloud computing, Fog computing, Big data analytics, Energy management, Smart homes},
abstract = {Internet of Things (IoT) analytics is an essential mean to derive knowledge and support applications for smart homes. Connected appliances and devices inside the smart home produce a significant amount of data about consumers and how they go about their daily activities. IoT analytics can aid in personalizing applications that benefit both homeowners and the ever growing industries that need to tap into consumers profiles. This article presents a new platform that enables innovative analytics on IoT captured data from smart homes. We propose the use of fog nodes and cloud system to allow data-driven services and address the challenges of complexities and resource demands for online and offline data processing, storage, and classification analysis. We discuss in this paper the requirements and the design components of the system. To validate the platform and present meaningful results, we present a case study using a dataset acquired from real smart home in Vancouver, Canada. The results of the experiments show clearly the benefit and practicality of the proposed platform.}
}
@article{KHAN2021100390,
title = {Energy, performance and cost efficient cloud datacentres: A survey},
journal = {Computer Science Review},
volume = {40},
pages = {100390},
year = {2021},
issn = {1574-0137},
doi = {https://doi.org/10.1016/j.cosrev.2021.100390},
url = {https://www.sciencedirect.com/science/article/pii/S1574013721000307},
author = {Ayaz Ali Khan and Muhammad Zakarya},
keywords = {Clouds, Datacentres, Resource management, Energy efficiency, Performance},
abstract = {In major Information Technology (IT) companies such as Google, Rackspace and Amazon Web Services (AWS), virtualization and containerization technologies are usually used to execute customers’ workloads and applications — as part of their cloud computing services offering. The computational resources are provided through large-scale datacentres, which consume substantial amount of energy and, consequently, affect our environment with global warming. Cloud datacentres have become a backbone for today’s business and economy, which are the fastest-growing electricity consumers, globally. Numerous studies suggest that ∼30% of the US datacentres are comatose and the others are grossly less-utilized, which make it possible to save energy through technologies like virtualization and containerization. These technologies provide support for allocation and consolidation of workloads on appropriate resources. However, consolidation comprises migrations of virtual machines (VMs), containers and/or applications, depending on the underlying virtualization method; that are expensive in terms of energy consumption, performance degradation, and therefore, costs which is mostly not accounted for in many existing models, and, possibly, it could be more energy and performance efficient not to consolidate. This paper describes energy consumption and performance, therefore, cost issues of large-scale datacentres. Besides, we cover various methods for energy and performance efficient distributed systems, clouds and datacentres. We elaborate energy efficiency methods at three different levels: hardware; resource management; and applications. Besides these, different performance management techniques are mapped onto taxonomies and described in details. In last, energy, performance and cost management techniques, at geographically distributed and multi-access edge computing platforms, are described along with critical discussion.}
}
@article{KHAN20221,
title = {Computationally efficient topology optimization of scale-free IoT networks},
journal = {Computer Communications},
volume = {185},
pages = {1-12},
year = {2022},
issn = {0140-3664},
doi = {https://doi.org/10.1016/j.comcom.2021.12.013},
url = {https://www.sciencedirect.com/science/article/pii/S0140366421004795},
author = {Muhammad Awais Khan and Nadeem Javaid},
keywords = {Betweenness centrality, Closeness centrality, Heat map centrality, Malicious attacks, Scale-free IoT networks},
abstract = {The malicious attacks in the scale-free Internet of Things (IoT) networks create a serious threat for the functionality of nodes. During the malicious attacks, the removal of high degree nodes greatly affects the connectivity of the remaining nodes in the networks. Therefore, ensuring the maximum connectivity among the nodes is an important part of the topology optimization. A good scale-free network has the ability to maintain the functionality of the nodes even if some of them are removed from the network. Thus, designing a robust network to support the nodes’ functionality is the aim of topology optimization in the scale-free networks. Moreover, the computational complexity of an optimization process increases the cost of the network. Therefore, in this paper, the main objective is to reduce the computational cost of the network with the aim of constructing a robust network topology. Thus, four solutions are presented to reduce the computational cost of the network. First, a Smart Edge Swap Mechanism (SESM) is proposed to overcome the excessive randomness of the standard Random Edge Swap Mechanism (RESM). Second, a threshold based node removal method is introduced to reduce the operation of the edge swap mechanism when an objective function converges at a point. Third, multiple attacks are performed in the network to find the correlation between the measures, which are degree, betweenness and closeness centralities. Fourth, based on the third solution, a Heat Map Centrality (HMC) is used that finds the set of most important nodes from the network. The HMC damages the network by utilizing the information of two positively correlated measures. It helps to provide a good attack strategy for robust optimization. The simulation results demonstrate the efficacy of the proposed SESM mechanism. It outperforms the existing RESM mechanism by almost 4% better network robustness and 10% less number of swaps. Moreover, 64% removal of nodes helps to reduce the computational cost of the network.}
}
@article{GYRARD2020100083,
title = {IAMHAPPY: Towards an IoT knowledge-based cross-domain well-being recommendation system for everyday happiness},
journal = {Smart Health},
volume = {15},
pages = {100083},
year = {2020},
issn = {2352-6483},
doi = {https://doi.org/10.1016/j.smhl.2019.100083},
url = {https://www.sciencedirect.com/science/article/pii/S2352648319300479},
author = {Amelie Gyrard and Amit Sheth},
keywords = {Internet of things (IoT), Recommender systems (RS), Affective science, Emotion, Happiness, Well-being, Wellness, Rule-based reasoning, Inference engine, Knowledge directory service, Semantic ontology interoperability, Ontology validation, Reusability, Semantic web of things (SWoT), Semantic web technologies, Reusable knowledge},
abstract = {Nowadays, healthy lifestyle, fitness, and diet habits have become central applications in our daily life. Positive psychology such as well-being and happiness is the ultimate dream of everyday people's feelings (even without being aware of it). Wearable devices are being increasingly employed to support well-being and fitness. Those devices produce physiological signals that are analyzed by machines to understand emotions and physical state. The Internet of Things (IoT) technology connects (wearable) devices to the Internet to easily access and process data, even using Web technologies (aka Web of Things). We design IAMHAPPY, an innovative IoT-based well-being recommendation system to encourage every day people's happiness. The system helps people deal with day-to-day discomforts (e.g., minor symptoms such as headache, fever) by using home remedies and related alternative medicines (e.g., naturopathy, aromatherapy), activities to reduce stress, etc. To achieve this system, we build a web-based knowledge repository for emotion with a focus on happiness and well-being. The knowledge repository helps analyze data produced by IoT devices to understand users' emotions and health. The semantics-based knowledge repository is integrated with a rule-based engine to suggest recommendations to achieve everyday people's happiness. The naturopathy application scenario supports the recommendation system.}
}
@article{NIU2022173,
title = {Big data-driven scheduling optimization algorithm for Cyber–Physical Systems based on a cloud platform},
journal = {Computer Communications},
volume = {181},
pages = {173-181},
year = {2022},
issn = {0140-3664},
doi = {https://doi.org/10.1016/j.comcom.2021.10.020},
url = {https://www.sciencedirect.com/science/article/pii/S0140366421003984},
author = {Chao Niu and Lizhou Wang},
keywords = {Cloud platform, Big data-driven, Cyber–Physical Systems, Scheduling optimization algorithm},
abstract = {In this paper, we study big data-driven Cyber–Physical Systems (CPS) through cloud platforms and design scheduling optimization algorithms to improve the efficiency of the system. A task scheduling scheme for large-scale factory access under cloud–edge collaborative computing architecture is proposed. The method firstly merges the directed acyclic graphs on cloud-side servers and edge-side servers; secondly, divide the tasks using a critical path-based partitioning strategy to effectively improve the allocation accuracy; then achieves load balancing through reasonable processor allocation, and finally compares and analyses the proposed task scheduling algorithm through simulation experiments. The experimental system is thoroughly analysed, hierarchically designed, and modelled, simulated, and the experimental data analysed and compared with related methods. The experimental results prove the effectiveness and correctness of the worst-case execution time analysis method and the idea of big data-driven CPS proposed in this paper and show that big data knowledge can help improve the accuracy of worst-case execution time analysis. This paper implements a big data-driven scheduling optimization algorithm for Cyber–Physical Systems based on a cloud platform, which improves the accuracy and efficiency of the algorithm by about 15% compared to other related studies.}
}
@article{SHARMA2020102220,
title = {Blockchain and federated learning-based distributed computing defence framework for sustainable society},
journal = {Sustainable Cities and Society},
volume = {59},
pages = {102220},
year = {2020},
issn = {2210-6707},
doi = {https://doi.org/10.1016/j.scs.2020.102220},
url = {https://www.sciencedirect.com/science/article/pii/S2210670720302079},
author = {Pradip Kumar Sharma and Jong Hyuk Park and Kyungeun Cho},
keywords = {Distributed computing, Internet of battle things, Sustainable society, Blockchain, Federated learning},
abstract = {Ensuring social security through the defense organization determines the creation of links between the army and society. Realizing the benefits of the Internet of Battle Things in the defense system can perfectly monetize intelligence and strengthen the armed forces. It establishes a network for strong connectivity in the army with good coordination between complex processes to effectively edge out the enemies. However, this new technology poses organizational and national security challenges that present both opportunities and obstacles. The current framework of the defense IoT network for sustainable society is not adequate enough to make actionable situational awareness decisions in order to infer the state of the battlefield while preserving the privacy of sensitive data. In this paper, we propose a distributed computing defence framework for sustainable society using the features of blockchain technology and federated learning. The proposed model presents an algorithm to meet the challenges of limited training data in order to obtain high accuracy and avoid a reason specific model. To evaluate the effectiveness of the proposed model, we prepare the dataset and investigate the performance of our framework in various scenarios. The result outcomes are promising in terms of accuracy and loss compared to baseline approach.}
}
@article{ANGELOPOULOS2020107039,
title = {Keeping data at the edge of smart irrigation networks: A case study in strawberry greenhouses},
journal = {Computer Networks},
volume = {167},
pages = {107039},
year = {2020},
issn = {1389-1286},
doi = {https://doi.org/10.1016/j.comnet.2019.107039},
url = {https://www.sciencedirect.com/science/article/pii/S1389128619305195},
author = {Constantinos Marios Angelopoulos and Gabriel Filios and Sotiris Nikoletseas and Theofanis P. Raptis},
keywords = {Smart farming, Edge computing, Network architecture},
abstract = {Strawberries are widely appreciated for their characteristic aroma, bright red color, juicy texture, and sweetness. They are, however, among the most sensitive fruits when it comes to the quality of the end product. The recent commercial trends show a rising number of farmers who directly sell their products in the market and are more interested in using smart solutions for a continuous control of the factors that affect the quality of the final product. Cloud-based approaches for smart irrigation have been widely used in the recent years. However, the network traffic, security and regulatory challenges, which come hand in hand with sharing the crop data with third parties outside the edge of the network, lead strawberry farmers and data owners to rely on global clouds and potentially lose control over their data, which are usually transferred to third party data centers. In this paper, we follow a three-step methodological approach in order to design, implement and validate a solution for smart strawberry irrigation in greenhouses, while keeping the corresponding data at the edge of the network: (i) We develop a small-scale smart irrigation prototype solution with off-the-shelf hardware and software equipment, which we test and evaluate on different kinds of plants in order to gain useful insights for larger scale deployments, (ii) we introduce a reference network architecture, specifically targeting smart irrigation and edge data distribution for strawberry greenhouses, and (iii) adopting the proposed reference architecture, we implement a full-scale system in an actual strawberry greenhouse environment in Greece, and we compare its performance against that of conventional strawberries irrigation. We show that our design significantly outperforms the conventional approach, both in terms of soil moisture variation and in terms of water consumption, and conclude by critically appraising the costs and benefits of our approach in the agricultural industry.}
}
@article{BHARDWAJ201915,
title = {A framework for effective threat hunting},
journal = {Network Security},
volume = {2019},
number = {6},
pages = {15-19},
year = {2019},
issn = {1353-4858},
doi = {https://doi.org/10.1016/S1353-4858(19)30074-1},
url = {https://www.sciencedirect.com/science/article/pii/S1353485819300741},
author = {Akashdeep Bhardwaj and Sam Goundar},
abstract = {In today's dynamic cyber security environment, with its rapidly changing threat landscape, companies are becoming increasingly aware of the necessity of getting ahead of new cyber attack trends. It is for this reason that threat hunting has become so popular. A new wave of attacks has become exceptionally proficient in successful, undetected intrusions, breaching network defences, exploiting system vulnerabilities and obtaining access to organisations’ systems and data.}
}
@article{KUMAR2021107386,
title = {Impact of peak to average power ratio reduction techniques on Generalized Frequency Division Multiplexing for 5th generation systems},
journal = {Computers & Electrical Engineering},
volume = {95},
pages = {107386},
year = {2021},
issn = {0045-7906},
doi = {https://doi.org/10.1016/j.compeleceng.2021.107386},
url = {https://www.sciencedirect.com/science/article/pii/S0045790621003542},
author = {Pawan Kumar and Lavish Kansal and Gurjot Singh Gaba and Mohamed Mounir and Ashutosh Sharma and Pradeep Kumar Singh},
keywords = {5G (fifth generation), Generalized Frequency Division Multiplexing, Orthogonal Frequency Division Multiplexing, Peak to average power ratio},
abstract = {Generalized Frequency Division Multiplexing (GFDM) is the advanced multi-carrier methodology proposed for a reliable operation of the 5th generation (5G) systems. It has been observed that the performance of GFDM is hampered by the elevated peak to power ratio (PAPR). High PAPR leads to the saturation of the transmit power amplifier which degrades the bit error rate (BER) and causes the out of band emissions. The prime objective of this work is to evaluate the PAPR performances of GFDM under the various reduction schemes like precoding, clipping, companding, precoding ＋ clipping and precoding ＋ companding. The results show that the precoding techniques combined with clipping or companding results in less PAPR and BER as compared to the conventional GFDM. The discrete cosine transform (DCT) and discrete sine transform (DST) precoded GFDM provides a signal to noise (SNR) improvement of 2−4 dB and 5−8 dB respectively, in comparison to conventional GFDM systems for a BER of 10−3.}
}
@article{KAKKAR202089,
title = {A survey on secure communication techniques for 5G wireless heterogeneous networks},
journal = {Information Fusion},
volume = {62},
pages = {89-109},
year = {2020},
issn = {1566-2535},
doi = {https://doi.org/10.1016/j.inffus.2020.04.009},
url = {https://www.sciencedirect.com/science/article/pii/S1566253520302621},
author = {Ajay Kakkar},
keywords = {Encryption Algorithms, Internet of Things, 5G Heterogeneous Networks, Attacks and Chaotic Encryption},
abstract = {With the increasing number of emerging robust networks, the challenges to design new security protocols and techniques are never ending. With the enlargement of 5G paradigm, there is a remarkable makeshift in how the distributed devices perform to achieve a common goal. The 5G technology has been significantly revolutionized by the advent of the Internet of Things, and its quick and pervasive evolution. However, it remains imperative that all these devices work in a sequential manner to execute a collective and secure operation. Despite computing being focused around cloud infrastructures in the last two decades, the 5G networks and the huge amount of data it generates is presently inverting this trend, shifting computing power back to where data is generated from. To encompass different autonomous and collaborative systems with functions of data sensing and authentication between such systems in a predictive and adaptive manner is a challenging task. Wireless network design in 5G is expected to emphasize broadly on three facets: security, privacy and energy efficiency. Therefore, this paper investigates the role of various data security and privacy techniques for different generation networks, but emphasis is on 5G. It addresses encryption schemes with the focus on the challenges faced such as side channel and ciphertext attacks, inherent key generation, sharing and distribution, key escrow, analysis of various overheads, and potential techniques, and solutions to address such challenges by leveraging 5G network devices. With the proliferation of ubiquitous computing and wide adoption of hybrid encryption techniques, various attacks will be circumvent in an intelligent manner.}
}
@article{JAHID2022103311,
title = {A contemporary survey on free space optical communication: Potentials, technical challenges, recent advances and research direction},
journal = {Journal of Network and Computer Applications},
volume = {200},
pages = {103311},
year = {2022},
issn = {1084-8045},
doi = {https://doi.org/10.1016/j.jnca.2021.103311},
url = {https://www.sciencedirect.com/science/article/pii/S108480452100299X},
author = {Abu Jahid and Mohammed H. Alsharif and Trevor J. Hall},
keywords = {Optical wireless communication, 5G/B5G, IoT/IoE, Free space optical communication, MIMO FSO, Multi-user FSO},
abstract = {Due to the unprecedented growth of high speed multimedia services and diversified applications initiated from the massive connectivity of IoT devices, 5G and beyond 5G (B5G) cellular communications, the existing electromagnetic spectrum under RF ranges is incapable to tackle the enormous future data rate demands. Free space optical (FSO) communication systems covering an ultra-wide range of unlicensed spectrum have emerged as a promising solution to mitigate conventional RF spectrum scarcity ranging of communication distances from nm to several kilometers. The implication of hybrid FSO, radio over FSO (RoFSO), MIMO FSO systems support ultra high speed 5G/B5G demand by eliminating the limitations of individual technology. FSO offers a broad range of applications both in outdoor and indoor services, for instance, wireless video surveillance, data centers, terrestrial transmission, LAN connectivity, mobile cellular networks, last mile solution, space communications, radio astronomy, remote sensing, and so on. Despite the potential benefits of FSO technology, its link reliability deteriorates due to atmospheric turbulence, cloud induced fading, some other environmental factors such as fog, aerosol, temperature variations, storms, heavy rain, pointing error, and scintillation. This survey presents the overview of several key technologies, significance, demonstration, recent development, and implications of state-of-the-art criteria in terms of spectrum reuse, classification, architecture, physical layer security, and future applications for understanding FSO system among different appealing optical wireless technologies. In addition, the adaptive modulation, channel modeling schemes, relay-aided transmission, cooperative diversity, potential challenges, numerous mitigation techniques, and opportunities in the near future are also outlined to realize the successful deployment of FSO systems.}
}
@article{LI2016119,
title = {Geospatial big data handling theory and methods: A review and research challenges},
journal = {ISPRS Journal of Photogrammetry and Remote Sensing},
volume = {115},
pages = {119-133},
year = {2016},
note = {Theme issue 'State-of-the-art in photogrammetry, remote sensing and spatial information science'},
issn = {0924-2716},
doi = {https://doi.org/10.1016/j.isprsjprs.2015.10.012},
url = {https://www.sciencedirect.com/science/article/pii/S0924271615002439},
author = {Songnian Li and Suzana Dragicevic and Francesc Antón Castro and Monika Sester and Stephan Winter and Arzu Coltekin and Christopher Pettit and Bin Jiang and James Haworth and Alfred Stein and Tao Cheng},
keywords = {Big data, Geospatial, Data handling, Analytics, Spatial modeling, Review},
abstract = {Big data has now become a strong focus of global interest that is increasingly attracting the attention of academia, industry, government and other organizations. Big data can be situated in the disciplinary area of traditional geospatial data handling theory and methods. The increasing volume and varying format of collected geospatial big data presents challenges in storing, managing, processing, analyzing, visualizing and verifying the quality of data. This has implications for the quality of decisions made with big data. Consequently, this position paper of the International Society for Photogrammetry and Remote Sensing (ISPRS) Technical Commission II (TC II) revisits the existing geospatial data handling methods and theories to determine if they are still capable of handling emerging geospatial big data. Further, the paper synthesises problems, major issues and challenges with current developments as well as recommending what needs to be developed further in the near future.}
}
@article{MAZONOLIVO2018347,
title = {Rules engine and complex event processor in the context of internet of things for precision agriculture},
journal = {Computers and Electronics in Agriculture},
volume = {154},
pages = {347-360},
year = {2018},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2018.09.013},
url = {https://www.sciencedirect.com/science/article/pii/S0168169918302436},
author = {Bertha Mazon-Olivo and Dixys Hernández-Rojas and José Maza-Salinas and Alberto Pan},
keywords = {Complex event processing, Internet of Things (IoT), Precision Agriculture, Rules engine, Real-time event processing},
abstract = {The Internet of Things (IoT) applications monitor large data flows and events in real time, some raw data is captured from devices located in wireless sensor networks (WSN) and used to make control decisions about actuators. This can be a major problem when the devices grow in number as well as the data that is captured. In this paper, we propose an architecture called “RECEP” for the dynamic processing of events generated in the context of IoT and Precision Agriculture (PA); it is made up of two components: Rules Engine (RE) and Complex Event Processor (CEP). RE allows you to configure dynamic rules conditioning input data from different sources and planning control actions on actuators, alerts, and notifications for end users or applications. The CEP component fuses the input data at the rate at which they arrive, with the rules established in the RE and it performs a prescriptive analysis that consists not only in predicting or detecting patterns of events, but in making automatic decisions. RECEP was implemented in a virtual machine with a 1.9 GHz CPU and 6 GB RAM, then it was integrated into an intelligent irrigation system of an experimental banana plot located in Machala-Ecuador. A WSN simulator was also used to generate sensor data in large quantities, the CEP was evaluated with several test cases, and results show that it consumes computational resources with a growth trend, represented by a logarithmic regression model (r-squared > 0.9); that is, the more events are processed, there is a minimum consumption of resources. It was tested for fifteen days; around 25 thousand events/s were processed. Our RECEP can be implemented in low-cost infrastructure typical of small and large banana producers.}
}
@article{MAMDOUH2021102491,
title = {Authentication and Identity Management of IoHT Devices: Achievements, Challenges, and Future Directions},
journal = {Computers & Security},
volume = {111},
pages = {102491},
year = {2021},
issn = {0167-4048},
doi = {https://doi.org/10.1016/j.cose.2021.102491},
url = {https://www.sciencedirect.com/science/article/pii/S0167404821003151},
author = {Moustafa Mamdouh and Ali Ismail Awad and Ashraf A.M. Khalaf and Hesham F.A. Hamed},
keywords = {IoT, Healthcare, IoHT, Security, IoHT device identification, IoHT device authentication, Vulnerabilities, Attacks, Threats},
abstract = {The Internet of Things (IoT) paradigm serves as an enabler technology in several domains. Healthcare is one of the domains in which the IoT plays a vital role in increasing quality of life. On the one hand, the Internet of Healthcare Things (IoHT) creates smart environments and increases the efficiency and intelligence of the provided services. On the other hand, unfortunately, it suffers from security vulnerabilities inside and outside. There are various techniques used to identify, access, and securely manage IoT devices. Additionally, sensors, monitoring, key confidentiality management, integrity, and sensitive data accessibility are required. This study focuses on the IoT perception layer and offers a comprehensive review of the IoHT or the Internet of Medical Things (IoMT). The paper covers the current trends and open challenges in IoHT device authentication mechanisms, such as the physically unclonable function (PUF) and blockchain-based techniques. In addition, IoT simulators and verification tools are included. Finally, a future vision regarding the evolution of IoHT device authentication in terms of the utilization of different technologies, such as artificial intelligence, cloud computing, and 5G, is provided at end of this review.}
}
@article{YAN2019331,
title = {Geo CPS: Spatial challenges and opportunities for CPS in the geographic dimension},
journal = {Journal of Urban Management},
volume = {8},
number = {3},
pages = {331-341},
year = {2019},
issn = {2226-5856},
doi = {https://doi.org/10.1016/j.jum.2019.09.005},
url = {https://www.sciencedirect.com/science/article/pii/S2226585619301293},
author = {Wanglin Yan and Takeo Sakairi},
keywords = {Internet of things (IoT), Space integration, Cyber-physical systems (CPS), Sensing, Processing and Accutation (SPA)},
abstract = {Recent advances in the Internet of Things (IoT) have brought great opportunities for geographical information systems (GIS) to be integrated with cyber-physical systems (CPS) in urban management. However, the term IoT and CPS are new in the GIS realm. This article reviews the concepts of IoT and CPS from the perspective of geospatial spaces and proposes the concept of Geo CPS to develop the potential of new technology in the geographic dimension. Two forms of Geo CPS are discussed: pseudo-CPS (PCPS), which projects spatial data onto a display without interaction among data sources, and true-CPS (TCPS), which handles data sources deeply and semantically. While PCPS already has wide industrial applications, TCPS is still in its infancy. The spatial challenge for CPS in geo space involves operating conditions in an open environment, and here, the human-machine system interface will be key. A transformation of our mindset relating to GIS can lead to the creation of new value-added geographical information services. This will require new schemes and platforms for data sharing, processing, security, and privacy, etc.}
}
@article{SHIT2020351,
title = {Precise localization for achieving next-generation autonomous navigation: State-of-the-art, taxonomy and future prospects},
journal = {Computer Communications},
volume = {160},
pages = {351-374},
year = {2020},
issn = {0140-3664},
doi = {https://doi.org/10.1016/j.comcom.2020.06.007},
url = {https://www.sciencedirect.com/science/article/pii/S0140366420303935},
author = {Rathin Chandra Shit},
keywords = {Autonomous system, Navigation, AUV, UAV, Autonomous mobile robots, Localization, Mapping, Perception, Sensing, Network localization, Sensor fusion, Micro air vehicle},
abstract = {Achieving full autonomy in navigation is a complicated problem. The most widely used solution takes up the modular framework for sensing and information processing such as perception, mapping, control, planning and decision making. However, this approach misses the capability of environmental understanding. Hence, to achieve full autonomy in navigation a computing model with self-learning capability inspired by biological intelligence such as memorizing, inferring and experience update is essential for dynamic and noisy environments. Recent advanced sensing, communication and hardware miniaturization technologies achieved few autonomous operations in commercial systems but the full autonomy has not been attained yet. In this paper, the effect of precise and accurate localization for autonomous navigation technologies is extensively studied and the problems and limitations of the related algorithms are analyzed. The major limitations for precise localization are computational complexity, sensor noise and communication delays. These limitations further reduce perception and planning capabilities of autonomous navigation systems. From this study, the future prospects are outlined to achieve a higher level of autonomy by precise localization.}
}
@article{JAIN2021100044,
title = {How is Blockchain used in marketing: A review and research agenda},
journal = {International Journal of Information Management Data Insights},
volume = {1},
number = {2},
pages = {100044},
year = {2021},
issn = {2667-0968},
doi = {https://doi.org/10.1016/j.jjimei.2021.100044},
url = {https://www.sciencedirect.com/science/article/pii/S2667096821000379},
author = {Deepa Jain and Manoj Kumar Dash and Anil Kumar and Sunil Luthra},
keywords = {Blockchain, Bibliometric analysis, Data analytics, Citation analysis, Marketing integration},
abstract = {Blockchain technology is the need of the hour today, due to its strong pillars of distribution, decentralisation, encryption, immutability and tokenization. It has a growing scope in various sectors of the economy. With vast data availability, there are challenges of big data, privacy, ransomware attacks, resulting into marketing fraud and spam. The present study reviews the use of blockchain in marketing area and seeks to identify influential aspects, research streams and research questions to propose the future research agenda of emerging market perspectives for blockchain marketing integration. The study analysed 75 articles from the international database of Scopus using bibliometric and network-based analysis. Present study firstly, identified influential aspects of literature in terms of highly cited articles, keywords, authors and publications; Secondly, identified five future research streams: (i) Blockchain and Electronic Commerce, (ii) Blockchain and Marketing; (iii) Blockchain and Data; (iv) Blockchain and Data Analytics and (v) Blockchain-Privacy and Security, Finally, suggested 18 future research questions. The study paved way for future researchers by providing future research agenda in terms of the proposed framework, which needs to be explored further to identify the relationships between five identified streams using proposed research questions. The study is unique in terms of its contribution to the literature publishing literature with an exhaustive focus on ‘identifying the blockchain-marketing integration.’ The present study fills this literature gap and proposed a framework and research questions for future researchers.}
}
@article{KUMAR2020102242,
title = {Drone assisted Flying Ad-Hoc Networks: Mobility and Service oriented modeling using Neuro-fuzzy},
journal = {Ad Hoc Networks},
volume = {106},
pages = {102242},
year = {2020},
issn = {1570-8705},
doi = {https://doi.org/10.1016/j.adhoc.2020.102242},
url = {https://www.sciencedirect.com/science/article/pii/S1570870520301062},
author = {Kirshna Kumar and Sushil Kumar and Omprakash Kaiwartya and Pankaj Kumar Kashyap and Jaime Lloret and Houbing Song},
keywords = {Flying Ad-Hoc networks, Internet of Things, Quality of Service, Routing, Aerial drone},
abstract = {Flying ad-hoc networks enable vast of IoT services while maintaining communication among the ground systems and flying drones. The domain research is focusing on flying networks assisted data centric IoT applications while integrating the benefits and services of aerial objects such as unmanned aerial vehicle and drones. Considering the growing market significance of drone centric flying networks, quality of service provisioning is one of the most leading research themes in flying ad-hoc networks. The related literature majorly relies on centralized base station monitored communications. Towards this end, this paper proposes a drone assisted distributed routing framework focusing on quality of service provision in IoT environments (D-IoT). The aerial drone mobility and parameters are modeled probabilistically focusing on highly dynamic flying ad-hoc networks environments. These drone centric models are utilized to develop a complete distributed routing framework. Neuro-fuzzy interference system has been employed to assist in reliable and efficient route selection. A comparative performance evaluation attests the benefits of the proposed drone assisted routing framework. It is evident that D-IoT outperforms the state-of-the-art techniques in terms of number of network performance metrics in flying ad-hoc networks environments.}
}
@article{KNOX2022102333,
title = {The (in)justices of smart local energy systems: A systematic review, integrated framework, and future research agenda},
journal = {Energy Research & Social Science},
volume = {83},
pages = {102333},
year = {2022},
issn = {2214-6296},
doi = {https://doi.org/10.1016/j.erss.2021.102333},
url = {https://www.sciencedirect.com/science/article/pii/S2214629621004254},
author = {Stephen Knox and Matthew Hannon and Fraser Stewart and Rebecca Ford},
keywords = {Energy justice, Smart local energy systems, Local energy, Smart technology, Systematic review},
abstract = {Smart technology alongside local energy systems are regularly considered critical for a low-carbon transition. More recently, a growing body of literature has started to examine the (in)justices that exist within energy systems and the impact this has on all people having equal access to safe, affordable, and sustainable energy. To date, little research has sought to synthesise the evidence base around whether smart local energy systems are an effective means of promoting energy justice. This paper presents a systematic literature review of 105 peer-reviewed articles, with a focus on understanding the antecedents of energy justice in local energy systems and the role smart technology can play in mitigating these (in)justices. We propose an integrated framework outlining our findings and discuss the implications for a future research agenda.}
}
@article{BARDHAN2019102040,
title = {Sentiment analysis as tool for gender mainstreaming in slum rehabilitation housing management in Mumbai, India},
journal = {Habitat International},
volume = {92},
pages = {102040},
year = {2019},
issn = {0197-3975},
doi = {https://doi.org/10.1016/j.habitatint.2019.102040},
url = {https://www.sciencedirect.com/science/article/pii/S0197397519302619},
author = {Ronita Bardhan and Minna Sunikka-Blank and Anika Nasra Haque},
keywords = {Participatory approach, Gender mainstreaming, Slum rehabilitation, Stakeholders perception, Semantic maps, Sentiment analysis},
abstract = {Gender mainstreaming in slum rehabilitation is a critical determinant for the success or failure of it. Slum rehabilitation in Mumbai is a hallmark example of a participatory process which is supposed to improve the quality of life and well-being among the rehabilitated occupants, on paper. Yet our findings show that the key stakeholders’ (i.e. policymaker, architect, management co-operatives and female occupants) sentiments are worlds apart. This gap evokes a need for a more systematic framework for a participatory approach. Verbal communication has the power to implicitly decipher the common emotion or sentiment regarding infrastructure or its related policy. This study uses a quasi-qualitative approach to understand the underlying concerns of gender mainstreaming in slum rehabilitation housing (SRH) management in Mumbai, India. Verbal narratives from semi-structured interviews and focus group discussions are used to explore the concerns of the stakeholders. Sentiment analysis using the machine learning technique of Natural Language Processing (NLP) is used to decode the emotions across the stakeholders. The results indicate that gender inequality in SRH is propagated through lack of communication and the different vocabulary used by the female occupants and the apex policymakers. There are also remarkable differences between male- and female-led co-operatives who are in charge of SRH management. Female-led co-operatives were observed to go beyond basic maintenance duties, to reduce debt and monthly fees and to take up incremental improvements such as decorative elements or installation of solar panels. This participation required a full female body co-operative rather than partial female representation in order to be effective. This study suggests that gender mainstreaming is important not only in SRH design but also in maintenance and that exploring the sentiments of the key stakeholders, as proposed in our analysis, could mitigate undesirable effects of SRH and enable the participatory process.}
}
@article{AHMADI201814,
title = {An accurate prediction method for moving target localization and tracking in wireless sensor networks},
journal = {Ad Hoc Networks},
volume = {70},
pages = {14-22},
year = {2018},
issn = {1570-8705},
doi = {https://doi.org/10.1016/j.adhoc.2017.11.008},
url = {https://www.sciencedirect.com/science/article/pii/S157087051730207X},
author = {Hanen Ahmadi and Federico Viani and Ridha Bouallegue},
keywords = {Target tracking, Localization, Wireless sensor networks, Learning algorithm, Pervasive computing, Filtering},
abstract = {With the large use of wireless sensor devices, the interest in positioning and tracking by means of wireless sensor networks is expected to grow further. Particularly, accurate localization of a moving target is a fundamental requirement in several Machine to Machine monitoring applications. Tracking using Received Signal Strength Indicator (RSSI) has been frequently adopted thanks to the availability and the low cost of this parameter. In this paper, we propose an innovative target tracking algorithm which combines learning regression tree approach and filtering methods using RSSI metric. Regression Tree algorithm is investigated in order to estimate the position using the RSSI. This method is combined to filtering approaches yielding to more refined results. The suggested approach is evaluated through simulations and experiments. We also compare our method to existing algorithms available in the literature. The numerical and experimental results show the relevance and the efficiency of our method.}
}
@article{YAQOOB2021202,
title = {Novel congestion avoidance scheme for Internet of Drones},
journal = {Computer Communications},
volume = {169},
pages = {202-210},
year = {2021},
issn = {0140-3664},
doi = {https://doi.org/10.1016/j.comcom.2021.01.008},
url = {https://www.sciencedirect.com/science/article/pii/S0140366421000293},
author = {Shumayla Yaqoob and Ata Ullah and Muhammad Awais and Iyad Katib and Aiiad Albeshri and Rashid Mehmood and Mohsin Raza and Saif {ul Islam} and Joel J.P.C. Rodrigues},
keywords = {Internet of drones, Smooth message dissemination, Fog computing, Congestion avoidance, Emergency messages},
abstract = {Internet of Drones (IoDs) is getting growing interest of researchers due to its applicability in wide range of applications for transportation, weather monitoring, emergency monitoring for flood, earth quake, healthcare and road hazards. To update the data about emergency situation, a real-time data sharing is mandatory. However, regular message transmission by various drones may not only overwhelm a central server but it also causes congestion on the network. It is mandatory to reduce messaging cost and congestion. This paper presents a fog-assisted congestion avoidance approach for Smooth Message Dissemination (SMD). We present a message forwarding algorithm for congestion avoidance to select the appropriate next-hop node using layered model. This model is based on various layers having drones. In first phase, it looks for an appropriate drone in a layer near the fog server for message forwarding. In next step, the drone is identified in nearby layers to forward the emergency message to next-hop to further locate the group head as per priority. It is a drone that has less distance towards fog server and inform in its one-hop circle. It can stop forwarding message after delivering it to fog server. Finally, the fog server disseminates information timely towards upper layers for necessary actions for emergency situations. The performance of the proposed approach is validated through extensive simulations using NS 2.35. Results prove the dominance of SMD over counterparts in terms of messaging overhead, packet delivery ratio, throughput, energy consumption and average delay. Proposed SMD improves PDR by 85% and message overhead cost by 91% as compared to counterparts.}
}
@article{WU2022,
title = {Improved coyote algorithm and application to optimal load forecasting model},
journal = {Alexandria Engineering Journal},
year = {2022},
issn = {1110-0168},
doi = {https://doi.org/10.1016/j.aej.2022.01.032},
url = {https://www.sciencedirect.com/science/article/pii/S1110016822000345},
author = {Songmei Wu and Jiandong Jiang and Yuehao Yan and Wei Bao and Yangtao Shi},
keywords = {Improved Coyote Optimization Algorithm (ICOA), Sobol, Extreme Learning Machine (ELM), Short-term Load Forecasting(STLF)},
abstract = {Accurate load forecasting is critical to guarantee the security, steadiness and economic operation of the power system. Therefore, in order to improve the load forecasting accuracy, improved coyote optimization (ICOA) was proposed in this paper to optimizing the Extreme learning machine for load forecasting, which is a novel load forecasting model. The ICOA algorithm effectively improves the accuracy and speed of convergence by introducing the sobol sequence and improving the pack culture trend, which is approved beneath a set of benchmark capacities from the Organized of Electrical and Hardware Engineers (IEEE) Congress on Developmental Computation (CEC) 2017. The result comparisons have moreover shown the exceptional execution of ICOA, since it could rank to begin with within the optimization of 16 benchmark. In addition, the ELM was optimized using to address the problem that the randomly formed weights and thresholds of the ELM lead to an unstable model, as well as experiment with different models using real electricity load data. The results show that the ICOA-ELM model possesses excellent accuracy and stability in short-term load forecasting. Its R2 and RMSE are 0.9970 and 0.3840 MW respectively, which are much better than ELM and LSTM. Thus, the proposed ICOA-ELM is a viable strategy for short-term load forecasting.}
}
@article{SULTANA2022101857,
title = {Evaluating the Potential and Challenges of IoT in Education and Other Sectors during the COVID-19 Pandemic: The Case of Bangladesh},
journal = {Technology in Society},
volume = {68},
pages = {101857},
year = {2022},
issn = {0160-791X},
doi = {https://doi.org/10.1016/j.techsoc.2021.101857},
url = {https://www.sciencedirect.com/science/article/pii/S0160791X21003328},
author = {Nahida Sultana and Marzia Tamanna},
keywords = {IoT, Bangladesh, COVID-19, Internet of things},
abstract = {The Internet of Things (IoT) adoption affects different sectors immensely, especially during Covid-19. This study mainly examines the benefits and challenges experienced in Bangladesh's education, and corporate and service sectors while using IoT services during COVID-19. Data collection was performed using a convenient random sampling method and distributing questions online. Two hundred sixty completed responses were analyzed, where 40% of responses were from the education sector, and 60% were from the corporate and service sector. The research method was quantitative and empirical. The study reveals that people find saving time the most potential in education sector, whereas, in the corporate and service sector, the topmost benefit of using IoT services is that it helps strictly maintain physical distance. Conversely, the most significant challenges people face in both sectors are that the IoT increases social distance and reduces individual communication. Nevertheless, people in both sectors have a positive attitude towards using IoT in the future. The findings have practical implications for business professionals, academic scholars, and other associated parties keen to identify IoT impact during the pandemic.}
}
@article{BONACCORSI2020113645,
title = {Emerging technologies and industrial leadership. A Wikipedia-based strategic analysis of Industry 4.0},
journal = {Expert Systems with Applications},
volume = {160},
pages = {113645},
year = {2020},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2020.113645},
url = {https://www.sciencedirect.com/science/article/pii/S0957417420304693},
author = {Andrea Bonaccorsi and Filippo Chiarello and Gualtiero Fantoni and Hanna Kammering},
keywords = {Emerging technologies, Industry 4.0, Innovation, Technology foresight, Industrial leadership, Germany},
abstract = {Among emerging technologies large attention has been devoted to the so called Fourth Industrial Revolution, or Industry 4.0, which is also a case study of a major industrial policy initiative, led by Germany. In the field of methodologies to profile and monitor emerging technologies the role of Wikipedia has been recently explored. In this paper we extend the use of Wikipedia by comparing the German edition with the world largest edition (in English) in order to examine whether there are significant structural differences. We first validate the use of Wikipedia for emerging technologies and for cross-language comparisons as a tool for (almost) real time strategic analysis. We then extract all Wikipedia pages related to Industry 4.0, build up a knowledge network and study its topological properties in the two editions. We find striking differences, which can be explained with respect to the persistence of the industrial pattern of specialization of Germany with respect to all other countries. Emerging technologies introduce novelty but also preserve path-dependency in the pattern of specialization. The implications for companies and policy makers are discussed.}
}
@article{OGUNTALA201855,
title = {Indoor location identification technologies for real-time IoT-based applications: An inclusive survey},
journal = {Computer Science Review},
volume = {30},
pages = {55-79},
year = {2018},
issn = {1574-0137},
doi = {https://doi.org/10.1016/j.cosrev.2018.09.001},
url = {https://www.sciencedirect.com/science/article/pii/S1574013718301163},
author = {George Oguntala and Raed Abd-Alhameed and Stephen Jones and James Noras and Mohammad Patwary and Jonathan Rodriguez},
keywords = {Indoor localization, Internet of Things, Indoor technologies, Hybridization},
abstract = {The advent of the Internet of Things has witnessed tremendous success in the application of wireless sensor networks and ubiquitous computing for diverse smart-based applications. The developed systems operate under different technologies using different methods to achieve their targeted goals. In this treatise, we carried out an inclusive survey on key indoor technologies and techniques, with to view to explore their various benefits, limitations, and areas for improvement. The mathematical formulation for simple localization problems is also presented. In addition, an empirical evaluation of the performance of these indoor technologies is carried out using a common generic metric of scalability, accuracy, complexity, robustness, energy-efficiency, cost and reliability. An empirical evaluation of performance of different RF-based technologies establishes the viability of Wi-Fi, RFID, UWB, Wi-Fi, Bluetooth, ZigBee, and Light over other indoor technologies for reliable IoT-based applications. Furthermore, the survey advocates hybridization of technologies as an effective approach to achieve reliable IoT-based indoor systems. The findings of the survey could be useful in the selection of appropriate indoor technologies for the development of reliable real-time indoor applications. The study could also be used as a reliable source for literature referencing on the subject of indoor location identification.}
}
@article{AGALIANOS20201636,
title = {Discrete Event Simulation and Digital Twins: Review and Challenges for Logistics},
journal = {Procedia Manufacturing},
volume = {51},
pages = {1636-1641},
year = {2020},
note = {30th International Conference on Flexible Automation and Intelligent Manufacturing (FAIM2021)},
issn = {2351-9789},
doi = {https://doi.org/10.1016/j.promfg.2020.10.228},
url = {https://www.sciencedirect.com/science/article/pii/S2351978920320990},
author = {K. Agalianos and S.T. Ponis and E. Aretoulaki and G. Plakas and O. Efthymiou},
keywords = {Warehouse Logistics, Discrete Event Simulation, Internet of Things, Logistics 4.0, Warehouse Automations, Digital Twins},
abstract = {In the Logistics 4.0 era, the demand for anticipating asset behaviour and make decisions in an almost real time fashion has led to the evolution of DES into an integral part of what is currently known as the Digital Twins (DTs). A Discrete Event Simulation software is assuming the role of the cyber twin, executing simulation software queries on real time data produced by IoT devices embedded on the physical twin, i.e. the automation, which are then processed, updating the simulation to the next system state. In that way, DTs facilitate the convergence of the physical and virtual warehouse, thus supporting efficient and responsive warehouse planning, management and decision making. This paper explores the current literature on the integration of DES and DTs and identifies trends and challenges for contemporary Logistics.}
}
@article{RAHIMIGOLKHANDAN2021101166,
title = {Predictive resilience of interdependent water and transportation infrastructures: A sociotechnical approach},
journal = {Socio-Economic Planning Sciences},
pages = {101166},
year = {2021},
issn = {0038-0121},
doi = {https://doi.org/10.1016/j.seps.2021.101166},
url = {https://www.sciencedirect.com/science/article/pii/S0038012121001580},
author = {Armin Rahimi-Golkhandan and Babak Aslani and Shima Mohebbi},
keywords = {Infrastructure systems, Interdependency, Social vulnerability, Predictive analytics, Natural disasters, Cascading random failure, Community detection},
abstract = {Infrastructures are interdependent systems and their interdependency can influence their resilience to routine failures and extreme events. Even though infrastructure resilience has been widely explored, few studies have considered physical, spatial, and social dimensions simultaneously. In this paper, we propose a resilience assessment framework for interdependent water and transportation infrastructures. The framework incorporates the physical network of these infrastructures, social vulnerability indicators, and predictive analytics for a sociotechnical resilience assessment. It enables us to measure the impact of random failures due to aging infrastructures, natural disasters, and their cascading failures. We applied the proposed framework to the City of Tampa, FL. The results indicated that areas with higher social vulnerability are more prone to cascading failures caused by both random breakdowns and natural disasters. While natural disasters affect all land use classes similarly, random failures have a greater impact on residential and institutional land use. The findings of this study highlight that infrastructure interdependency and the consequences of cascading failures should be taken into account in a coordinated infrastructure resilience assessment and planning. Further, socioeconomic factors and land use features should be incorporated in interdependent resilience assessment for a more comprehensive and equitable resilience planning.}
}
@article{MODGIL2021120607,
title = {Big data-enabled large-scale group decision making for circular economy: An emerging market context},
journal = {Technological Forecasting and Social Change},
volume = {166},
pages = {120607},
year = {2021},
issn = {0040-1625},
doi = {https://doi.org/10.1016/j.techfore.2021.120607},
url = {https://www.sciencedirect.com/science/article/pii/S0040162521000391},
author = {Sachin Modgil and Shivam Gupta and Uthayasankar Sivarajah and Bharat Bhushan},
keywords = {Big data, Circular economy, Stakeholders as large decision makers, Case study, Emerging market},
abstract = {This study is focused on presenting a unique landscape for big data-enabled circular economy that involves stakeholders as important decision makers. This research is designed based on five case studies from emerging markets with a focus on circular models to propose a framework for large scale decision making. In these cases, different linear economy problems are addressed that further utilizes the integration of big data and large-scale group decision making by stakeholders to achieve circularity. The findings of our study indicate a four-step design (enabling technologies, business significance, deriving value, and circular goals) to implement the 10R's of the circular economy through emerging technologies such as big data and related mobile applications along with cloud-based platforms. The study highlights how cases from emerging markets can be useful for other firms and ecosystems, ranging from e-commerce to manufacturing, that employ large number of decision makers with the aim of creating a circular economy. At the end, the study presents theoretical and practical implications along with the scope for future research.}
}
@article{SHARMA2021723,
title = {Multi-view spectral clustering for uncertain objects},
journal = {Information Sciences},
volume = {547},
pages = {723-745},
year = {2021},
issn = {0020-0255},
doi = {https://doi.org/10.1016/j.ins.2020.08.080},
url = {https://www.sciencedirect.com/science/article/pii/S0020025520308410},
author = {Krishna Kumar Sharma and Ayan Seal},
keywords = {Spectral clustering, Co-regularization, Multi-view clustering, Uncertain, Similarity measure},
abstract = {In the machine learning and pattern recognition fraternity, uncertain data clustering is an essential job because uncertainty in data makes the clustering process more difficult. Recently, multi-view clustering is gaining more attention towards data miners for certain data because it produces good results compared to grouping based on a single viewpoint. In uncertain data clustering, similarity measure plays an imperative role. However, state-of-the-art similarity measures suffer from several limitations. For example, when two distributions of two uncertain data are heavily overlapped in locations, then Geometric similarity measure alone is not sufficient. On the other hand, similarity measure based on probability distribution is not enough when two uncertain data are not closed to each other or completely separated. In this study, induced kernel distance and Jeffrey-divergence are fused by the degree of overlap concerning each view of a dataset to construct a self-adaptive mixture similarity measure (SAM). The SAM is further used with pairwise co-regularization in multi-view spectral clustering for grouping uncertain data. The proof of convergence of the objective function of the proposed clustering algorithm is also presented in this study. All the experiments are carried out on nine real-world deterministic datasets, three real-life and one synthetic uncertain datasets. Nine real-world deterministic datasets are further converted into uncertain datasets before executing all the clustering algorithms. Experimental results illustrate that the proposed algorithm outperforms nine state-of-the-art methods. The comparison is made using five clustering evaluation metrics. The proposed method is also tested using null hypothesis significance tests.}
}
@article{BARBAGONZALEZ2020538,
title = {On the design of a framework integrating an optimization engine with streaming technologies},
journal = {Future Generation Computer Systems},
volume = {107},
pages = {538-550},
year = {2020},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2020.02.020},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X19315699},
author = {Cristóbal Barba-González and Antonio J. Nebro and Antonio Benítez-Hidalgo and José García-Nieto and José F. Aldana-Montes},
keywords = {Dynamic multi-objective optimization, Streaming data processing, Big data, Software framework},
abstract = {A number of streaming technologies have appeared in the last years as a result of the rising of Big Data applications. Nowadays, deciding which technology to adopt is not an easy task due not only to the number of available data streaming processing projects, but also because they are continuously evolving. In this paper, we focus on how these issues have affected jMetalSP, a framework for dynamic multi-objective optimization that incorporates streaming features. jMetalSP allows the development of three tier optimization workflows where the central component is an optimizer that is continuously solving a dynamic multi-objective optimization problem. This problem can change as a consequence of the analysis of data streams carried out by components that use the Apache Spark streaming engine. A third kind of components receive and process the Pareto front approximations being yielded by the optimization algorithm. However, all jMetalSP elements are tightly coupled and linked to Spark, making it difficult to use a different streaming system. To overcome this issue, we have redesigned the jMetalSP architecture to make it flexible enough to avoid the dependence of any particular streaming system. This way, popular Apache projects such as Spark Structured Streaming, Kafka Streams, or Flink can be used without requiring to change the rest of components of the application. Furthermore, Kafka can be used for inter-process communication, what enables the execution of components in different nodes of a cluster, independently of their implementation languages thanks to the serialization of data streams with Apache Avro. We show how the embraced solution provides a high degree of flexibility that enhances the usability of jMetalSP. To this end, a representative case study based on a transport problem is conducted that focuses on data representation and performance evaluation of the Spark, Flink, and Kafka systems.}
}
@article{RITTS2021144,
title = {Conservation acoustics: Animal sounds, audible natures, cheap nature},
journal = {Geoforum},
volume = {124},
pages = {144-155},
year = {2021},
issn = {0016-7185},
doi = {https://doi.org/10.1016/j.geoforum.2021.04.022},
url = {https://www.sciencedirect.com/science/article/pii/S0016718521001214},
author = {Max Ritts and Karen Bakker},
keywords = {Conservation, Sound, Digital capitalism, Nature, Science},
abstract = {This paper asks why growing numbers of government agencies, professional conservation authorities, university researchers, citizen scientists, and private companies are turning to bioacoustical approaches for conservation research and management needs. These varied activities describe a set of agendas we examine here under the rubric of “conservation acoustics.” More than a scientific response to urgent environmental problems, “conservation acoustics” is a contemporary formation of power-knowledge: digital technologies and associated techno-social innovations that are enhancing capitalism's capacity to appropriate new, previously uncommodified sources of “work/energy” (Moore 2015). By pairing Moore with recent work on the political economy of digital music, we can better grasp the structural forces that have given rise to “conservation acoustics” – including advances in digital sound compression, the economic interests of Big Tech and the territorial ambitions of the environmental state. Within this examination, Donna Haraway reminds us of the importance of listening to the stories scientists tell about themselves, which can reveal epistemological closures and political openings that may not be visible from the grand historical view. At the same time, capitalism’s organization of nature via the intermediation of digital sound suggests that Haraway’s own insights regarding vision and the “God Trick” require a reframing with respect to sound. We draw from literature reviews, a meta-review of over 2000 scholarly papers on bioacoustics and eco-acoustics, and 15 expert interviews to advance our claims.}
}
@article{ZHANG2019515,
title = {Secure weighted possibilistic c-means algorithm on cloud for clustering big data},
journal = {Information Sciences},
volume = {479},
pages = {515-525},
year = {2019},
issn = {0020-0255},
doi = {https://doi.org/10.1016/j.ins.2018.02.013},
url = {https://www.sciencedirect.com/science/article/pii/S0020025518300951},
author = {Qingchen Zhang and Laurence T. Yang and Arcangelo Castiglione and Zhikui Chen and Peng Li},
keywords = {Big data, Possibilistic c-means algorithm, Cloud computing, BGV},
abstract = {The weighted possibilistic c-means algorithm is an important soft clustering technique for big data analytics with cloud computing. However, the private data will be disclosed when the raw data is directly uploaded to cloud for efficient clustering. In this paper, a secure weighted possibilistic c-means algorithm based on the BGV encryption scheme is proposed for big data clustering on cloud. Specially, BGV is used to encrypt the raw data for the privacy preservation on cloud. Furthermore, the Taylor theorem is used to approximate the functions for calculating the weight value of each object and updating the membership matrix and the cluster centers as the polynomial functions which only include addition and multiplication operations such that the weighed possibilistic c-means algorithm can be securely and correctly performed on the encrypted data in cloud. Finally, the presented scheme is estimated on two big datasets, i.e., eGSAD and sWSN, by comparing with the traditional weighted possibilistic c-means method in terms of effectiveness, efficiency and scalability. The results show that the presented scheme performs more efficiently than the traditional weighted possiblistic c-means algorithm and it achieves a good scalability on cloud for big data clustering.}
}
@article{SALEEM2020102234,
title = {Intelligent learning automata-based objective function in RPL for IoT},
journal = {Sustainable Cities and Society},
volume = {59},
pages = {102234},
year = {2020},
issn = {2210-6707},
doi = {https://doi.org/10.1016/j.scs.2020.102234},
url = {https://www.sciencedirect.com/science/article/pii/S2210670720302213},
author = {Ahsan Saleem and Muhammad Khalil Afzal and Muhammad Ateeq and Sung Won Kim and Yousaf Bin Zikria},
keywords = {Internet of Things, RPL, Objective function (OF), Learning automata, Smart grid (SG), Link estimation, Intelligent routing},
abstract = {Sustainable cities are widely adopting the standards of the Internet of Things (IoT) in almost every domain, e.g., smart grids (SG) to provide services to a sustainable community. It enables two-way communication to manage the energy resources, where routing protocol has a significant role in communication. The diversification of IoT networks arises many challenges for the routing protocol for low power and lossy networks (RPL). The dynamic and lossy environment is one of the key challenges in various IoT networks, specifically SG. RPL does not able to adjust its link metric efficiently against the dynamic and lossy environment, which have a great impact on the performance metrics. To address this issue, we have introduced cognition in RPL by integrating learning automata with the objective function (LA-OF). Learning automata (LA) is applied to expected transmission count (ETX) to tune it according to the environment. LA learns through interacting with the environment and yields the best ETX values, afterwards the environment is monitored to trace down the instability in the environment. The proposed LA-OF is compared with standardized techniques MRHOF and OF0. The simulation results show a significant improvement with overall 7.04% in PRR, 17.52% in energy consumption, and 18.72% in overhead.}
}
@article{HU2021107994,
title = {A comprehensive review of acoustic based leak localization method in pressurized pipelines},
journal = {Mechanical Systems and Signal Processing},
volume = {161},
pages = {107994},
year = {2021},
issn = {0888-3270},
doi = {https://doi.org/10.1016/j.ymssp.2021.107994},
url = {https://www.sciencedirect.com/science/article/pii/S0888327021003897},
author = {Zhongyu Hu and Salman Tariq and Tarek Zayed},
keywords = {Literature review, Pipeline, Leak, Localization, Research trend},
abstract = {Pipelines are widely used in the transportation of water, oil, gas, etc. Leakage in pipelines leads to a great waste of natural resources and sometimes constitutes a public health risk. Due to its wave-like nature, acoustics is one of the most studied technology for leak detection and localization in pipelines. Over the past decades, numerous articles have been published to address leak localization problems with acoustic-based methods. However, a review of the research development on acoustic-based leak localization technology is lacking. Therefore, this paper utilizes bibliometric analysis to systematically examine the published research articles in this field. Analyses showe that investigations on acoustic-based leak localization technology became popular in the last decade. Most existing researches focus on or exploited the cross-correlation based methods. Furthermore, the most frequently investigated research objective is the development of a signal processing algorithm for denoising and extracting leak signals. Other efforts include altering the number of sensors, developing wireless detection systems, etc. Potential future directions are presented based on a summary of the limitations of the existing research. This paper provides an in-depth understanding of the state-of-the-art in this field to researchers and engineers. Additionally, it identifies prospective research areas based on the findings and limitations of the previous studies.}
}
@article{AGARWAL2021102942,
title = {Indoor air quality improvement in COVID-19 pandemic: Review},
journal = {Sustainable Cities and Society},
volume = {70},
pages = {102942},
year = {2021},
issn = {2210-6707},
doi = {https://doi.org/10.1016/j.scs.2021.102942},
url = {https://www.sciencedirect.com/science/article/pii/S2210670721002274},
author = {Nehul Agarwal and Chandan Swaroop Meena and Binju P Raj and Lohit Saini and Ashok Kumar and N. Gopalakrishnan and Anuj Kumar and Nagesh Babu Balam and Tabish Alam and Nishant Raj Kapoor and Vivek Aggarwal},
keywords = {Indoor air quality, Air purifiers, Social distancing, Facemasks, Lockdown, Ventilation, HVAC},
abstract = {Introduction
The advent of COVID-19 has impinged millions of people. The increased concern of the virus spread in confined spaces due to meteorological factors has sequentially fostered the need to improve indoor air quality.
Objective
This paper aims to review control measures and preventive sustainable solutions for the future that can deliberately help in bringing down the impact of declined air quality and prevent future biological attacks from affecting the occupant’s health.
Methodology
Anontology chart is constructed based on the set objectives and review of all the possible measures to improve the indoor air quality taking into account the affecting parameters has been done.
Observations
An integrated approach considering non-pharmaceutical and engineering control measures together for a healthy indoor environment should be contemplated rather than discretizing the available solutions. Maintaining social distance by reducing occupant density and implementing a modified ventilation system with advance filters for decontamination of viral load can help in sustaining healthy indoor air quality.
Conclusion
The review paper in the main, provides a brief overview of all the improvement techniques bearing in mind thermal comfort and safety of occupants and looks for a common ground for all the technologies based on literature survey and offers recommendation for a sustainable future.}
}
@article{WANG2021131,
title = {Lightweight blockchain assisted secure routing of swarm UAS networking},
journal = {Computer Communications},
volume = {165},
pages = {131-140},
year = {2021},
issn = {0140-3664},
doi = {https://doi.org/10.1016/j.comcom.2020.11.008},
url = {https://www.sciencedirect.com/science/article/pii/S0140366420319885},
author = {Jian Wang and Yongxin Liu and Shuteng Niu and Houbing Song},
keywords = {5G cellular networking, Swarm UAS, Lightweight blockchain, Secure routing, Passive synchronization},
abstract = {The prominent capacities of 5G New Radio (5G NR) cellular networking drive the rapid development of many fields. The ubiquitous implementations of 5G NR cellular networking also provide swarm Unmanned Aircraft System (UAS) networking the feasibility of scalable deployment and smart control. However, the conveniences derived from 5G NR also bring other vulnerabilities to swarm UAS networking. The advanced capacities of 5G NR enable attackers to commit disruptive attacks to swarm UAS networking more severely and quickly. The requirement for the security of swarm UAS networking is imminent. In this paper, we propose a lightweight Blockchain-based secure routing algorithm for swarm UAS networking. We leverage the lightweight Blockchain to enhance the security of routing of swarm UAS networking which is based on 5G NR cellular networking. Different from the conventional routing algorithms, the proposed algorithm with lightweight Blockchain can avoid the malicious connections from attackers, recognize the malicious UASs and mitigate the attacks from malicious UASs. Concurrently, the proposed algorithm are swarm UAS oriented which aims to extend the deployment of swarm UAS networking on a large scale. Compared with Proof-of-Work (PoW) and Proof-of-Stake(PoS), we adopt pheromone to estimate the traffic status of each UAS in swarm UAS networking, construct consensus for swarm UAS networking with Proof-of-Traffic (PoT) and synchronize the updated blocks for lightweight Blockchain passively under the constraints of energy consumption. The evaluation shows PoT can reduce the routing consumption in the processes of consensus construction and blocks synchronization. Compatible with the constrained resource of swarm UASs, the lightweight Blockchain-assisted approach, proposed in this paper, can maintain the efficiency of swarm UAS networking.}
}
@article{DEEPU2021100038,
title = {Supply chain digitalization: An integrated MCDM approach for inter-organizational information systems selection in an electronic supply chain},
journal = {International Journal of Information Management Data Insights},
volume = {1},
number = {2},
pages = {100038},
year = {2021},
issn = {2667-0968},
doi = {https://doi.org/10.1016/j.jjimei.2021.100038},
url = {https://www.sciencedirect.com/science/article/pii/S2667096821000318},
author = {T.S. Deepu and V. Ravi},
keywords = {Inter-organizational information systems, Digital technologies, AHP-TOPSIS, electronics industry, Supply chain digitalization},
abstract = {Efficient Inter-Organizational Information Systems (IOIS) have become the backbone of modern supply chains. IOIS can be used to plan, coordinate, collaborate and integrate supply chains for attaining competitive advantage. The speed of innovative technology evolvement, lack of clarity, and delay in taking appropriate managerial and strategic decisions for adopting IOIS demand further research in this area. The robust advancement in digital technologies stresses a proper decision model for the IOIS adoption process. This paper provides a novel model for selecting the best IOIS alternative by considering the contents, scope, and critical decision-making factors affecting supply chain integration. Twelve decision-making factors affecting IOIS selection were identified and categorized under four significant dimensions: technological, operational, application, and innovative for effective decision-making. Study results reveal that project completion time is the most relevant criterion, followed by digital technology enablers and the financial resources required to select IOIS alternatives.}
}
@article{SOE2018323,
title = {Agile local governments: Experimentation before implementation},
journal = {Government Information Quarterly},
volume = {35},
number = {2},
pages = {323-335},
year = {2018},
note = {Agile Government and Adaptive Governance in the Public Sector},
issn = {0740-624X},
doi = {https://doi.org/10.1016/j.giq.2017.11.010},
url = {https://www.sciencedirect.com/science/article/pii/S0740624X1630315X},
author = {Ralf-Martin Soe and Wolfgang Drechsler},
abstract = {This paper discusses how local governments can team up for joint service provision, be more adaptive towards new technological and organisational changes and introduce novel services following main industry trends (e.g. predictive analytics, autonomous vehicles and artificial intelligence). The conceptual approach is to use Public Value (PV) as the framework for the organisation and management of government performance, one of the most important successor ‘paradigmettes’ of the New Public Management (NPM). Based on the PV concept, the ‘adaptive model’ for local governments is introduced according to which each procured ICT solution is preceded by agile, open, bottom-up and experimental trial. This model is corroborated via recent empirical evidence from the case of Helsinki and Tallinn which was obtained by observing how city governments collaborate on joint innovation-lab-type structures and conduct agile trials in the field of smart mobility before traditional procurement.}
}
@article{ZORRILLA2022103595,
title = {A reference framework for the implementation of data governance systems for industry 4.0},
journal = {Computer Standards & Interfaces},
volume = {81},
pages = {103595},
year = {2022},
issn = {0920-5489},
doi = {https://doi.org/10.1016/j.csi.2021.103595},
url = {https://www.sciencedirect.com/science/article/pii/S0920548921000908},
author = {Marta Zorrilla and Juan Yebenes},
keywords = {Data governance, Data-Centric architecture, Industry 4.0, Big data, IoT},
abstract = {The fourth industrial revolution, or Industry 4.0, represents a new stage of evolution in the organization, management and control of the value chain throughout the product or service life cycle. This is mainly based on the digitalization of the industrial environment by means of the convergence of Information Technologies (IT) and operational Technologies (OT) through cyber-physical systems and the Industrial IoT (IIoT) and the use of data generated in real time for gaining insights and making decisions. Therefore data becomes a critical asset for Industry 4.0 and must be managed and governed like a strategic asset. We rely on Data Governance (DG) as a key instrument for carrying out this transformation. This paper presents the design of a specific governance framework for Industry 4.0. First, this contextualizes data governance for Industry 4.0 environments and identifies the requirements that this framework must address, which are conditioned by the specific features of Industry 4.0, among others, the intensive use of big data, the cloud and edge computing, the artificial intelligence and the current regulations. Next, we formally define a reference framework for the implementation of Data Governance Systems for Industry 4.0 using international standards and providing several examples of architecture building blocks.}
}
@article{WELCH2019795,
title = {Big data in public transportation: a review of sources and methods},
journal = {Transport Reviews},
volume = {39},
number = {6},
pages = {795-818},
year = {2019},
issn = {0144-1647},
doi = {https://doi.org/10.1080/01441647.2019.1616849},
url = {https://www.sciencedirect.com/science/article/pii/S0144164722001544},
author = {Timothy F. Welch and Alyas Widita},
keywords = {Big data, public transportation, transport analysis, transit planning, planning methods, statistics},
abstract = {ABSTRACT
The collection of big data, as an alternative to traditional resource-intensive manual data collection approaches, has become significantly more feasible over the past decade. The availability of such data, coupled with more sophisticated predictive statistical techniques, has contributed to an increase in attention towards the application of these data, particularly for transportation analysis. Within the transportation literature, there is a growing emphasis on developing sources of commonly collected public transportation data into more powerful analytical tools. A commonly held belief is that application of big data to transportation problems will yield new insights previously unattainable through traditional transportation data sets. However, there exist many ambiguities related to what constitutes big data, the ethical implications of big data collection and application, and how to best utilize the emerging data sets. The existing literature exploring big data provides no clear and consistent definition. While the collection of big data has grown and its application in both research and practice continues to expand, there is a significant disparity between methods of analysis applied to such data. This paper summarizes the recent literature on sources of big data and commonly applied methods used in its application to public transportation problems. We assess predominant big data sources, most frequently studied topics, and methodologies employed. The literature suggests smart card and automated data are the two big data sources most frequently used by researchers to conduct public transit analyses. The studies reviewed indicate that big data has largely been used to understand transit users’ travel behavior and to assess public transit service quality. The techniques reported in the literature largely mirror those used with smaller data sets. The application of more advanced statistical methods, commonly associated with big data, has been limited to a small number of studies. In order to fully capture the value of big data, new approaches to analysis will be necessary.}
}
@article{FIRTH201842,
title = {I'll make your car drive itself},
journal = {New Scientist},
volume = {237},
number = {3166},
pages = {42-43},
year = {2018},
issn = {0262-4079},
doi = {https://doi.org/10.1016/S0262-4079(18)30355-5},
url = {https://www.sciencedirect.com/science/article/pii/S0262407918303555},
author = {Niall Firth},
abstract = {Notorious hacker George Hotz is helping people turn standard vehicles into self-driving ones – but his eyes are on a bigger prize, he tells Niall Firth}
}
@article{REDDY2022101511,
title = {Spectrum cartography techniques, challenges, opportunities, and applications: A survey},
journal = {Pervasive and Mobile Computing},
volume = {79},
pages = {101511},
year = {2022},
issn = {1574-1192},
doi = {https://doi.org/10.1016/j.pmcj.2021.101511},
url = {https://www.sciencedirect.com/science/article/pii/S1574119221001346},
author = {Yeduri Sreenivasa Reddy and Abhinav Kumar and Om Jee Pandey and Linga Reddy Cenkeramaddi},
keywords = {Channel gain map, Channel state information, Interference map, Mean absolute error (MAE), Mean square error (MSE), Normalized MSE (NMSE), Power spectral density map, Power map, Radio frequency (RF) power, RF map, Root MSE (RMSE), Spectrum cartography, Spectrum map, Transmitter locations},
abstract = {The spectrum cartography finds applications in several areas such as cognitive radios, spectrum aware communications, machine-type communications, Internet of Things, connected vehicles, wireless sensor networks, and radio frequency management systems, etc. This paper presents a survey on state-of-the-art of spectrum cartography techniques for the construction of various radio environment maps (REMs). Following a brief overview on spectrum cartography, various techniques considered to construct the REMs such as channel gain map, power spectral density map, power map, spectrum map, power propagation map, radio frequency map, and interference map are reviewed. In this paper, we compare the performance of the different spectrum cartography methods in terms of mean absolute error, mean square error, normalized mean square error, and root mean square error. The information presented in this paper aims to serve as a practical reference guide for various spectrum cartography methods for constructing different REMs. Finally, some of the open issues and challenges for future research and development are discussed.}
}
@article{ENGIN2020140,
title = {Data-driven urban management: Mapping the landscape},
journal = {Journal of Urban Management},
volume = {9},
number = {2},
pages = {140-150},
year = {2020},
issn = {2226-5856},
doi = {https://doi.org/10.1016/j.jum.2019.12.001},
url = {https://www.sciencedirect.com/science/article/pii/S2226585619301153},
author = {Zeynep Engin and Justin {van Dijk} and Tian Lan and Paul A. Longley and Philip Treleaven and Michael Batty and Alan Penn},
keywords = {Data-driven society, Urban management and applications, Evidence-based decision making},
abstract = {Big data analytics and artificial intelligence, paired with blockchain technology, the Internet of Things, and other emerging technologies, are poised to revolutionise urban management. With massive amounts of data collected from citizens, devices, and traditional sources such as routine and well-established censuses, urban areas across the world have – for the first time in history – the opportunity to monitor and manage their urban infrastructure in real-time. This simultaneously provides previously unimaginable opportunities to shape the future of cities, but also gives rise to new ethical challenges. This paper provides a transdisciplinary synthesis of the developments, opportunities, and challenges for urban management and planning under this ongoing ‘digital revolution’ to provide a reference point for the largely fragmented research efforts and policy practice in this area. We consider both top-down systems engineering approaches and the bottom-up emergent approaches to coordination of different systems and functions, their implications for the existing physical and institutional constraints on the built environment and various planning practices, as well as the social and ethical considerations associated with this transformation from non-digital urban management to data-driven urban management.}
}
@article{DUAN20202404,
title = {Emerging RFID technology in structural engineering – A review},
journal = {Structures},
volume = {28},
pages = {2404-2414},
year = {2020},
issn = {2352-0124},
doi = {https://doi.org/10.1016/j.istruc.2020.10.036},
url = {https://www.sciencedirect.com/science/article/pii/S2352012420305968},
author = {Kang-Kang Duan and Shuang-Yin Cao},
keywords = {Radio frequency identification (RFID), Intelligent construction, Structural health monitoring (SHM), Intelligent management and operation, Internet of things},
abstract = {Radio frequency identification (RFID) has become a hot topic in structural engineering. It has an immense potential in promoting the intelligence of construction, changing the traditional way of detection, optimizing the usage of building. Especially during the last ten years, the number of publications focus on this technology has increased dramatically. In this paper, we presented a literature review of articles which focus on the applications of RFID in structural engineering. According to the different effects of RFID in different stages of the lifecycle of a building, we organized these applications into three main categories: intelligent construction, structural health monitoring (SHM) and intelligent management and operation. The basic theory of RFID technology, the tendency and status of current researches were discussed in this paper. Finally, the gap and latent improvement of existing applications in each category were proposed. It is hoped that our analysis of these researches will provide meaningful information on the comprehension of the applications of RFID in structural engineering.}
}
@article{PIANINI202144,
title = {Partitioned integration and coordination via the self-organising coordination regions pattern},
journal = {Future Generation Computer Systems},
volume = {114},
pages = {44-68},
year = {2021},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2020.07.032},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X20304775},
author = {Danilo Pianini and Roberto Casadei and Mirko Viroli and Antonio Natali},
keywords = {Coordination, Distributed systems, Design patterns, Self-organisation, Self-improving integration, Edge computing, Aggregate programming},
abstract = {In software engineering, knowledge about recurrent problems, along with blueprints of associated solutions for diverse design contexts, are often captured in so-called design patterns. Identifying design patterns is particularly valuable for novel and still largely unexplored application contexts such as the Internet of Things, Cyber–Physical Systems, and Edge Computing, as it would help keeping a balanced trade-off between generality and applicability, guiding the mainstream development of language mechanisms, algorithms, architectures, and supporting platforms. Based on recurrence of related solutions found in the literature, in this work we present a design pattern for self-adaptive systems, named Self-organising Coordination Regions (SCR): its goal is to organise a process of interconnecting devices into teams, to solve local tasks in cooperation. Specifically, it is a decentralised coordination pattern for partitioned integration and coordination of devices, which relies on continuous adaptivity to context change to provide resilient distributed decision-making in large-scale situated systems. It leverages the divide-and-conquer principle, partitioning (in a self-organising fashion) the network of devices into regions, where internal coordination activities are regulated via feedback/control flows among leaders and subordinate nodes. We present the pattern, provide a template implementation in the Aggregate Computing framework, and evaluate it through simulation of two case studies in edge computing and hierarchical, heterogeneous networks.}
}
@article{BIRAL20151,
title = {The challenges of M2M massive access in wireless cellular networks},
journal = {Digital Communications and Networks},
volume = {1},
number = {1},
pages = {1-19},
year = {2015},
issn = {2352-8648},
doi = {https://doi.org/10.1016/j.dcan.2015.02.001},
url = {https://www.sciencedirect.com/science/article/pii/S235286481500005X},
author = {Andrea Biral and Marco Centenaro and Andrea Zanella and Lorenzo Vangelista and Michele Zorzi},
keywords = {M2M, MTD, MTC, Massive access, 5G},
abstract = {The next generation of communication systems, which is commonly referred to as 5G, is expected to support, besides the traditional voice and data services, new communication paradigms, such as Internet of Things (IoT) and Machine-to-Machine (M2M) services, which involve communication between Machine-Type Devices (MTDs) in a fully automated fashion, thus, without or with minimal human intervention. Although the general requirements of 5G systems are progressively taking shape, the technological issues raised by such a vision are still partially unclear. Nonetheless, general consensus has been reached upon some specific challenges, such as the need for 5G wireless access networks to support massive access by MTDs, as a consequence of the proliferation of M2M services. In this paper, we describe the main challenges raised by the M2M vision, focusing in particular on the problems related to the support of massive MTD access in current cellular communication systems. Then we analyze the most common approaches proposed in the literature to enable the coexistence of conventional and M2M services in the current and next generation of cellular wireless systems. We finally conclude by pointing out the research challenges that require further investigation in order to provide full support to the M2M paradigm.}
}
@article{LOPEZROBLES2019729,
title = {The last five years of Big Data Research in Economics, Econometrics and Finance: Identification and conceptual analysis},
journal = {Procedia Computer Science},
volume = {162},
pages = {729-736},
year = {2019},
note = {7th International Conference on Information Technology and Quantitative Management (ITQM 2019): Information technology and quantitative management based on Artificial Intelligence},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2019.12.044},
url = {https://www.sciencedirect.com/science/article/pii/S1877050919320551},
author = {José Ricardo López-Robles and Marisela Rodríguez-Salvador and Nadia Karina Gamboa-Rosales and Selene Ramirez-Rosales and Manuel Jesús Cobo},
keywords = {Type your keywords here, separated by semicolons},
abstract = {Today, the Big Data term has a multidimensional approach where five main characteristics stand out: volume, velocity, veracity, value and variety. It has changed from being an emerging theme to a growing research area. In this respect, this study analyses the literature on Big Data in the Economics, Econometrics and Finance field. To do that, 1.034 publications from 2015 to 2019 were evaluated using SciMAT as a bibliometric and network analysis software. SciMAT offers a complete approach of the field and evaluates the most cited and productive authors, countries and subject areas related to Big Data. Lastly, a science map is performed to understand the intellectual structure and the main research lines (themes).}
}
@inbook{10.1109/ASONAM49781.2020.9381377,
author = {Aposporis, Panagiotis},
title = {Object Detection Methods for Improving UAV Autonomy and Remote Sensing Applications},
year = {2020},
isbn = {9781728110561},
publisher = {IEEE Press},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1109/ASONAM49781.2020.9381377},
abstract = {The last decades the Unmanned Aerial Systems (UASs) are being used in a variety of applications, such as civil protection, security, agriculture, armed forces, that need real time object detection of observed information by their sensors. Moreover, the development of fully autonomous UAS is heavily dependent on their capability to detect and track steady or moving objects in a robust, powerful and reliable manner. In this review, we present a comprehensive literature survey and discussion on object detection methodologies for improving UAV autonomy and remote sensing applications Emphasis is placed on Convolutional Neural Networks (CNN) implementing different object detectors and exploiting cloud processing. Based on these works, we provide a brief discussion and summary of related proposals for UAV-based object detection using different methodologies and approaches, share views for future research directions and draw conclusive remarks.},
booktitle = {Proceedings of the 12th IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining},
pages = {845–853},
numpages = {9}
}

@inproceedings{10.1145/3389189.3397997,
author = {Protopapadakis, Eftychios and Katsamenis, Iason and Doulamis, Anastasios},
title = {Multi-Label Deep Learning Models for Continuous Monitoring of Road Infrastructures},
year = {2020},
isbn = {9781450377737},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3389189.3397997},
doi = {10.1145/3389189.3397997},
abstract = {A multi-class, multi-label deep learning model for the monitoring of road infrastructures is presented in this paper. The employed detection methodology can identify animals, debris, road defects, fire, fog, flooded areas and humans. All these categories are strongly related to the efficient movement of vehicles through a transportation network. Possible detections indicate roadway disruptions of various types. Therefore, they should be detected as fast as possible. Experimental results indicate that the proposed scheme presents high detection results and, thus, can be used in any motorway monitoring process.},
booktitle = {Proceedings of the 13th ACM International Conference on PErvasive Technologies Related to Assistive Environments},
articleno = {66},
numpages = {7},
keywords = {deep learning, road safety, driver alert, multi-class classification, risk perception},
location = {Corfu, Greece},
series = {PETRA '20}
}

@inproceedings{10.1145/3330393.3330409,
author = {Cheng, Tao and Liu, Chunhui and Ding, Wenrui},
title = {Weak Signal Detection Based on Deep Learning},
year = {2019},
isbn = {9781450371711},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3330393.3330409},
doi = {10.1145/3330393.3330409},
abstract = {Weak signal detection of radio communication signals in complex background noise is an essential part of modern signal processing science. Despite wide application of classical process in various signal detection tasks, the exclusive filter in terms of background noise of radio channel impedes the deployment on modern complex electromagnetism environment. This study introduces a new method of radio signal detection via convolutional neural network (CNN) and bounding box regression. This approach has improved the recent performance of computer vision for object detection. Numerous experiments have shown that Faster R-CNN can accurately detect signal portion in noise, while achieving high-level contextual understanding with millisecond latency compared to traditional schemes.},
booktitle = {Proceedings of the 2019 4th International Conference on Multimedia Systems and Signal Processing},
pages = {114–118},
numpages = {5},
keywords = {convolutional neural network, bounding box regression, Signal detection},
location = {Guangzhou, China},
series = {ICMSSP 2019}
}

@inproceedings{10.1145/3460797.3460810,
author = {Sch\"{u}ler, Cedrik and Patchou, Manuel and Sliwa, Benjamin and Wietfeld, Christian},
title = {Robust Machine Learning-Enabled Routing for Highly Mobile Vehicular Networks with PARRoT in Ns-3},
year = {2021},
isbn = {9781450390347},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3460797.3460810},
doi = {10.1145/3460797.3460810},
abstract = {As implied by the high grade of relative mobility, the inherent network topology dynamics render aerial and ground-based vehicular mesh routing a highly challenging task. Since existing protocols are often not able to timely adopt their decision-making to the actual network conditions, they fail to provide reliable and efficient data delivery mechanisms. In this paper, we present the ns-3 integration of Predictive Ad-hoc Routing fueled by Reinforcement learning and Trajectory knowledge (PARRoT), a novel reinforcement learning-enabled routing protocol that integrates knowledge about the future motion of the mobile agents into the routing process.},
booktitle = {Proceedings of the Workshop on Ns-3},
pages = {88–94},
numpages = {7},
keywords = {reinforcement learning, routing protocol, mobile vehicular networks},
location = {Virtual Event, USA},
series = {WNS3 '21}
}

@inproceedings{10.1145/3453892.3461320,
author = {Temenos, Anastasios and Protopapadakis, Eftychios and Doulamis, Anastasios and Temenos, Nikos},
title = {Building Extraction from RGB Satellite Images Using Deep Learning: A U-Net Approach},
year = {2021},
isbn = {9781450387927},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3453892.3461320},
doi = {10.1145/3453892.3461320},
abstract = { Automatic building extraction from satellite RGB images, is a low-cost alternative to perform important urban planning tasks. Yet, it is a challenging one, especially when natural and non-city block objects interfere in the semantic segmentation of algorithms that extract their key features. In this work we approach the automatic building extraction using a Convolution Neural Network based on the U-Net architecture. In contrast to existing approaches, it successfully encodes important features and decodes the buildings’ localization by requiring both reduced computational time and dataset size. We evaluate the U-Net’s performance using RGB images selected from the SpaceNet 1 dataset and the experimental results show an accuracy in building localization of 92.3%. Finally, favorable comparison with existing CNN approaches to hyperspectral images targeting the SpaceNet 1 dataset, demonstrated its effectiveness.},
booktitle = {The 14th PErvasive Technologies Related to Assistive Environments Conference},
pages = {391–395},
numpages = {5},
keywords = {SpaceNet 1, U-Net, Remote Sensing, CNN Building Extraction, Automatic Building Extraction, Semantic Segmentation, Deep Learning},
location = {Corfu, Greece},
series = {PETRA 2021}
}

@article{10.1145/3383314,
author = {Kumar, Pakhee and Ofli, Ferda and Imran, Muhammad and Castillo, Carlos},
title = {Detection of Disaster-Affected Cultural Heritage Sites from Social Media Images Using Deep Learning Techniques},
year = {2020},
issue_date = {October 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {13},
number = {3},
issn = {1556-4673},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3383314},
doi = {10.1145/3383314},
abstract = {This article describes a method for early detection of disaster-related damage to cultural heritage. It is based on data from social media, a timely and large-scale data source that is nevertheless quite noisy. First, we collect images posted on social media that may refer to a cultural heritage site. Then, we automatically categorize these images according to two dimensions: whether they are indeed a photo in which a cultural heritage resource is the main subject, and whether they represent damage. Both categorizations are challenging image classification tasks, given the ambiguity of these visual categories; we tackle both tasks using a convolutional neural network. We test our methodology on a large collection of thousands of images from the web and social media, which exhibit the diversity and noise that is typical of these sources, and contain buildings and other architectural elements, heritage and not-heritage, damaged by disasters as well as intact. Our results show that while the automatic classification is not perfect, it can greatly reduce the manual effort required to find photos of damaged cultural heritage by accurately detecting relevant candidates to be examined by a cultural heritage professional.},
journal = {J. Comput. Cult. Herit.},
month = {aug},
articleno = {23},
numpages = {31},
keywords = {deep learning, Cultural heritage sites, social media, damage assessment}
}

@inproceedings{10.1109/DS-RT52167.2021.9576130,
author = {Campoverde, Luis Miguel Samaniego and Tropea, Mauro and De Rango, Floriano},
title = {An IoT Based Smart Irrigation Management System Using Reinforcement Learning Modeled through a Markov Decision Process},
year = {2021},
isbn = {9781665433266},
publisher = {IEEE Press},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1109/DS-RT52167.2021.9576130},
doi = {10.1109/DS-RT52167.2021.9576130},
abstract = {In this paper, the proposal of an irrigation system exploiting IoT is provided. The proposed system, based on IoT sensors and smart platforms such as Raspberry PI and Arduino, is able to manage farm operations in term of irrigation. The control of water pumps for irrigation is driven by two important parameters: soil moisture and evapotranspiration. The system uses a Reinforcement Learning approach based on Markov Decision Process in order to learn the right water amount needed by the plants. This approach allows to reduce both water and energy consumption. The proposal has been compared with a conventional irrigation system that normally is based on a soil humidity threshold and takes its decision considering the threshold setting. Conducted experiments show the water and energy saving by the use of the proposed Smart Irrigation system.},
booktitle = {Proceedings of the 2021 IEEE/ACM 25th International Symposium on Distributed Simulation and Real Time Applications},
articleno = {16},
numpages = {4},
keywords = {reinforcement learning, internet of things, smart irrigation, markovian decision process},
location = {Valencia, Spain},
series = {DS-RT '21}
}

@inproceedings{10.1145/3414045.3415951,
author = {Moustafa, Nour and Jolfaei, Alireza},
title = {Autonomous Detection of Malicious Events Using Machine Learning Models in Drone Networks},
year = {2020},
isbn = {9781450381055},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3414045.3415951},
doi = {10.1145/3414045.3415951},
abstract = {Drone systems, the so-called Unmanned Autonomous Vehicles (UAVs), have been widely employed in military and civilian sectors. Drone systems have been used for cyber warfare, warfighting and surveillance purposes of modern military and civilian applications. However, they have increasingly suffered from sophisticated malicious activities that exploit their vulnerabilities through network communications. As drones comprise a complex infrastructure as piloted aircraft but without operators, they still need a reliable security control to assert their safe operations. This paper proposes an autonomous intrusion detection scheme for discovering advanced and sophisticated cyberattacks that exploit drone networks. A testbed was configured to launch malicious events against a drone network for collecting legitimate and malicious observations and evaluate the performances of machine learning in real-time. Machine learning algorithms, including decision tree, k-nearest neighbors, naive Bayes, support vector machine and deep learning multi-layer perceptron, were trained and evaluated using the data collections, with promising results in terms of detection accuracy, false alarm rates, and processing times.},
booktitle = {Proceedings of the 2nd ACM MobiCom Workshop on Drone Assisted Wireless Communications for 5G and Beyond},
pages = {61–66},
numpages = {6},
keywords = {network systems, drones, machine and deep learning algorithms, intrusion detection},
location = {London, United Kingdom},
series = {DroneCom '20}
}

@inbook{10.1145/3324884.3416559,
author = {Mashhadi, Mohammad Jafar and Hemmati, Hadi},
title = {Hybrid Deep Neural Networks to Infer State Models of Black-Box Systems},
year = {2020},
isbn = {9781450367684},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3324884.3416559},
abstract = {Inferring behavior model of a running software system is quite useful for several automated software engineering tasks, such as program comprehension, anomaly detection, and testing. Most existing dynamic model inference techniques are white-box, i.e., they require source code to be instrumented to get run-time traces. However, in many systems, instrumenting the entire source code is not possible (e.g., when using black-box third-party libraries) or might be very costly. Unfortunately, most black-box techniques that detect states over time are either univariate, or make assumptions on the data distribution, or have limited power for learning over a long period of past behavior. To overcome the above issues, in this paper, we propose a hybrid deep neural network that accepts as input a set of time series, one per input/output signal of the system, and applies a set of convolutional and recurrent layers to learn the non-linear correlations between signals and the patterns, over time. We have applied our approach on a real UAV auto-pilot solution from our industry partner with half a million lines of C code. We ran 888 random recent system-level test cases and inferred states, over time. Our comparison with several traditional time series change point detection techniques showed that our approach improves their performance by up to 102%, in terms of finding state change points, measured by F1 score. We also showed that our state classification algorithm provides on average 90.45% F1 score, which improves traditional classification algorithms by up to 17%.},
booktitle = {Proceedings of the 35th IEEE/ACM International Conference on Automated Software Engineering},
pages = {299–311},
numpages = {13}
}

@inproceedings{10.1145/3478905.3478992,
author = {Hong, Xianbin and Guan, Sheng-Uei and Wong, Prudence W.H. and Xue, Nian and Man, Ka Lok and Liu, Dawei},
title = {Can AI Teach Humans? Humans AI Collaboration for Lifelong Machine Learning},
year = {2021},
isbn = {9781450390248},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3478905.3478992},
doi = {10.1145/3478905.3478992},
abstract = { Humans always play the role of a teacher to AI in the last decades. One day, AI will become wiser than humans in various fields. At that time, humans need to learn from AI to improve themselves. However, most of the current high-performance machine learning models are black boxes and challenging to understand. So a system with better explainability is needed to help humans to understand AI. Therefore, the authors proposed a double-track approach to use expert systems to supplement the current machine learning paradigm to solve this problem. Under lifelong machine learning, the double-track approach can be wiser and wiser and achieve high performance but keeps outstanding explainability.},
booktitle = {2021 4th International Conference on Data Science and Information Technology},
pages = {427–432},
numpages = {6},
keywords = {Lifelong Machine Learning, Knowledge Base, Expert System},
location = {Shanghai, China},
series = {DSIT 2021}
}

@article{10.1145/3451163,
author = {Abououf, Menatalla and Singh, Shakti and Otrok, Hadi and Mizouni, Rabeb and Damiani, Ernesto},
title = {Machine Learning in Mobile Crowd Sourcing: A Behavior-Based Recruitment Model},
year = {2021},
issue_date = {February 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {22},
number = {1},
issn = {1533-5399},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3451163},
doi = {10.1145/3451163},
abstract = {With the advent of mobile crowd sourcing (MCS) systems and its applications, the selection of the right crowd is gaining utmost importance. The increasing variability in the context of MCS tasks makes the selection of not only the capable but also the willing workers crucial for a high task completion rate. Most of the existing MCS selection frameworks rely primarily on reputation-based feedback mechanisms to assess the level of commitment of potential workers. Such frameworks select workers having high reputation scores but without any contextual awareness of the workers, at the time of selection, or the task. This may lead to an unfair selection of workers who will not perform the task. Hence, reputation on its own only gives an approximation of workers’ behaviors since it assumes that workers always behave consistently regardless of the situational context. However, following the concept of cross-situational consistency, where people tend to show similar behavior in similar situations and behave differently in disparate ones, this work proposes a novel recruitment system in MCS based on behavioral profiling. The proposed approach uses machine learning to predict the probability of the workers performing a given task, based on their learned behavioral models. Subsequently, a group-based selection mechanism, based on the genetic algorithm, uses these behavioral models in complementation with a reputation-based model to recruit a group of workers that maximizes the quality of recruitment of the tasks. Simulations based on a real-life dataset show that considering human behavior in varying situations improves the quality of recruitment achieved by the tasks and their completion confidence when compared with a benchmark that relies solely on reputation.},
journal = {ACM Trans. Internet Technol.},
month = {nov},
articleno = {16},
numpages = {28},
keywords = {Machine learning, mobile crowd sourcing, quality of recruitment, behavioral profiling, selection management}
}

@article{10.1145/3292027,
author = {Marais, Patrick and Dellepiane, Matteo and Cignoni, Paolo and Scopigno, Roberto},
title = {Semi-Automated Cleaning of Laser Scanning Campaigns with Machine Learning},
year = {2019},
issue_date = {October 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {12},
number = {3},
issn = {1556-4673},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3292027},
doi = {10.1145/3292027},
abstract = {Terrestrial laser scanning campaigns provide an important means to document the 3D structure of historical sites. Unfortunately, the process of converting the 3D point clouds acquired by the laser scanner into a coherent and accurate 3D model has many stages and is not generally automated. In particular, the initial cleaning stage of the pipeline—in which undesired scene points are deleted—remains largely manual and is usually labour intensive. In this article, we introduce a semi-automated cleaning approach that incrementally trains a random forest (RF) classifier on an initial keep/discard point labelling generated by the user when cleaning the first scan(s). The classifier is then used to predict the labelling of the next scan in the sequence. Before this classification is presented to the user, a denoising post-process, based on the 2D range map representation of the laser scan, is applied. This significantly reduces small isolated point clusters that the user would otherwise have to fix. The user then selects the remaining incorrectly labelled points and these are weighted, based on a confidence estimate, and fed back into the classifier to retrain it for the next scan. Our experiments, across 8 scanning campaigns, show that when the scan campaign is coherent, i.e., it does not contain widely disparate or contradictory data, the classifier yields a keep/discard labelling that typically ranges between 95% and 99%. This is somewhat surprising, given that the data in each class can represent many object types, such as a tree, person, wall, and so on, and that no further effort beyond the point labeling of keep/discard is required of the user. We conducted an informal timing experiment over a 15-scan campaign, which compared the processing time required by our software, without user interaction (point label correction) time, against the time taken by an expert user to completely clean all scans. The expert user required 95mins to complete all cleaning. The average time required by the expert to clean a single scan was 6.3mins. Even with current unoptimized code, our system was able to generate keep/discard labels for all scans, with 98% (average) accuracy, in 75mins. This leaves as much as 20mins for the user input required to relabel the 2% of mispredicted points across the set of scans before the full system time would match the expert’s cleaning time.},
journal = {J. Comput. Cult. Herit.},
month = {jun},
articleno = {16},
numpages = {29},
keywords = {point clouds, machine learning, laser scan, Heritage data, full dome scan, cleaning}
}

@article{10.1145/3448612,
author = {Wan, Liangtian and Zhang, Mingyue and Sun, Lu and Wang, Xianpeng},
title = {Machine Learning Empowered IoT for Intelligent Vehicle Location in Smart Cities},
year = {2021},
issue_date = {August 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {21},
number = {3},
issn = {1533-5399},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3448612},
doi = {10.1145/3448612},
abstract = {Intelligent Transportation System (ITS) can boost the development of smart cities, and artificial intelligence and edge computing are key technologies that support the implementation of ITS. Vehicle localization is critical for ITS since the safety driving and location-aware serves highly depend on the accurate location information. In this article, we construct a vehicle localization system architecture composed of multiple Internet of Things (IoT) with arbitrary array configuration and a large amount of vehicles in smart cities. In order to deal with the coexisting of circular and non-circular signals transmitted by vehicles, we proposed several vehicle number estimation methods for non-circular signals. Based on the machine learning technique, we extend the vehicle number estimation method into mixed signals in more complex scenario of smart cities. Then the DOA estimation method for non-circular signals based on IoT is proposed, and then the performance of this method is analyzed as well. Simulation outcomes verify the excellent performance of the proposed vehicle number estimation methods and the DOA estimation method in smart cities, and the vehicle positions can be achieved with high estimation accuracy.},
journal = {ACM Trans. Internet Technol.},
month = {aug},
articleno = {71},
numpages = {25},
keywords = {Smart cities, vehicle location, machine learning, IoT}
}

@inproceedings{10.1145/3449301.3449348,
author = {M. Alaboudi, Mariam and Abu Talib, Manar and Nasir, Qassim},
title = {Radio Frequency-Based Techniques of Drone Detection and Classification Using Machine Learning},
year = {2020},
isbn = {9781450388597},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3449301.3449348},
doi = {10.1145/3449301.3449348},
abstract = {This research paper provides a comprehensive survey review on drone detection using Radio Frequency (RF)-based techniques along with machine learning and localization algorithms. RF signals proved its effectiveness in detecting drones, however, due to the lack of a published survey, this research paper reviews the newly emerged RF-based techniques by addressing the implemented methods and discussing the results obtained in terms of the testing environment, range of detection and accuracy of the system. In this survey review, thirty conference and journal papers have been collected, however only selected papers have been discussed depending on the contribution and limited space of the paper. Finally, this survey also discusses the challenges encountered in drone detection using RF due to its great impact on the efficiency of the system.},
booktitle = {2020 6th International Conference on Robotics and Artificial Intelligence},
pages = {278–282},
numpages = {5},
keywords = {Drone Detection, Machine Learning, Radio Frequency, Localization},
location = {Singapore, Singapore},
series = {ICRAI 2020}
}

@inproceedings{10.1145/3390525.3390535,
author = {Bhargavi, Kovvuri N. and Suma, G. Jaya},
title = {Quasi Analysis of Rainfall Prediction during Floods Using Machine Learning},
year = {2020},
isbn = {9781450375047},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3390525.3390535},
doi = {10.1145/3390525.3390535},
abstract = {Floods are the most common natural disasters and researchers turned their spotlight on prediction of rainfall for rescuing lives of the people before or after its arrival. The intensity of flood majorly relies on heavy rainfall. If the rainfall is predicted well in advance it will be useful for taking precautionary measures. In this paper, predictive analysis is carried out using both classification and regression models. The prediction analysis is evaluated with the feature rain Tomorrow feature in the dataset. The computation analysis shows that prediction using Random Forest classifier and nth Polynomial regression gives exactness for assessment.},
booktitle = {Proceedings of the 2020 8th International Conference on Communications and Broadband Networking},
pages = {63–67},
numpages = {5},
keywords = {Logistic Regression, Gaussian Naive Bayes, Random Forest, Multinomial Naive Bayes, nth Polynomial degree regression},
location = {Auckland, New Zealand},
series = {ICCBN '20}
}

@inproceedings{10.1145/3501409.3501557,
author = {Wang, Yudong and Zhao, Yongmei and Wang, Qiong and Gu, Wenlong and Deng, Wengui},
title = {Remaining Useful Life Prediction for Aero-Engine Based on LSTM-HMM1},
year = {2021},
isbn = {9781450384322},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3501409.3501557},
doi = {10.1145/3501409.3501557},
abstract = {The remaining useful life (RUL) prediction for aero-engine is very complex. There are complex nonlinear characteristics among state variables. Moreover, it is also affected by external factors such as operating environment, which makes it difficult for a single model to predict its life in an accurate and stable manner. To solve this problem, an RUL prediction method that combines long short term memory network (LSTM) and hidden Markov model (HMM) is proposed. This method uses LSTM to predict the time sequence of some screened sensor parameters to obtain the preliminary predicted value, and then obtain the final predicted value by combining the preliminary predicted value with the HMM remaining useful life (RUL) change, in which the HMM RUL change is calculated through comparison of the hidden state predicted by HMM with the health state classified by the times of take-off and landing. Experimental results show that the proposed method improves the accuracy of prediction results.},
booktitle = {Proceedings of the 2021 5th International Conference on Electronic Information Technology and Computer Engineering},
pages = {825–830},
numpages = {6},
keywords = {aeroengine, Long short term memory network, remaining useful life prediction, hidden Markov model},
location = {Xiamen, China},
series = {EITCE 2021}
}

@inproceedings{10.5555/3378680.3378717,
author = {Tabrez, Aaquib and Agrawal, Shivendra and Hayes, Bradley},
title = {Explanation-Based Reward Coaching to Improve Human Performance via Reinforcement Learning},
year = {2019},
isbn = {9781538685556},
publisher = {IEEE Press},
abstract = {For robots to effectively collaborate with humans, it is critical to establish a shared mental model amongst teammates. In the case of incongruous models, catastrophic failures may occur unless mitigating steps are taken. To identify and remedy these potential issues, we propose a novel mechanism for enabling an autonomous system to detect model disparity between itself and a human collaborator, infer the source of the disagreement within the model, evaluate potential consequences of this error, and finally, provide human-interpretable feedback to encourage model correction. This process effectively enables a robot to provide a human with a policy update based on perceived model disparity, reducing the likelihood of costly or dangerous failures during joint task execution. This paper makes two contributions at the intersection of explainable AI (xAI) and human-robot collaboration: 1) The Reward Augmentation and Repair through Explanation (RARE) framework for estimating task understanding and 2) A human subjects study illustrating the effectiveness of reward augmentation-based policy repair in a complex collaborative task.},
booktitle = {Proceedings of the 14th ACM/IEEE International Conference on Human-Robot Interaction},
pages = {249–257},
numpages = {9},
keywords = {joint task execution, explainable AI, human-robot collaboration, policy explanation, reward estimation},
location = {Daegu, Republic of Korea},
series = {HRI '19}
}

@inbook{10.1145/3487923.3487927,
author = {Valdez, Daryl B. and Godmalin, Rey Anthony G.},
title = {A Deep Learning Approach of Recognizing Natural Disasters on Images Using Convolutional Neural Network and Transfer Learning},
year = {2021},
isbn = {9781450385756},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3487923.3487927},
abstract = {Natural disasters are uncontrollable phenomena occurring yearly which cause extensive damage to lives, property and cause permanent damage to the environment. However by, using Deep Learning, real-time recognition of these disasters can help the victims and emergency response agencies during the onset of these destructive events. At present, there are still gaps in the literature regarding real-time natural disaster recognition. In this paper, we present a dataset for the joint classification of natural disasters and intensity. We also proposed a lightweight convolutional neural network with two classification heads for the two tasks. This study leveraged on transfer learning in training the network to recognize natural disasters, as well as detecting normal, no-disaster images. At the same time, it is also capable of recognizing disaster intensity. Under controlled conditions, the model showed promising results on the two classification tasks. Thus, the study proved that accurate recognition of natural disasters is possible using a lightweight model and transfer learning. We hope that this study would lead to development of monitoring or surveillance systems that can perform accurate, on-the-ground, and real-time recognition of natural disasters allowing for rapid emergency responses mitigating the loss of lives and damages to properties.},
booktitle = {Proceedings of the International Conference on Artificial Intelligence and Its Applications},
articleno = {4},
numpages = {7}
}

@inbook{10.1145/3377812.3381398,
author = {Pyrgies, John},
title = {Towards DO-178C Certification of Adaptive Learning UAV Agents Designed with a Cognitive Architecture},
year = {2020},
isbn = {9781450371223},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3377812.3381398},
abstract = {Adaptive and Learning Agents (ALAs) bring computational intelligence to their Cyber Physical host systems to adapt to novel situations encountered in their complex operational environment. They do so by learning from their experience to improve their performance. RTCA DO-178C specifies a stringent certification process for airborne software which represents several challenges when applied to an ALA in regards of functional completeness, functional correctness, testability and adaptability. This research claims that it is possible to certify an Adaptive Learning Unmanned Aerial Vehicle (UAV) Agent designed as per a Cognitive Architecture with current DO-178C certification process when leveraging a qualified tool (DO-330), Model-Based Development and Verification (DO-331) and Formal Methods (DO-333). The research consists in developing, as a case study, an ALA embedded in a UAV aimed at neutralizing rogue UAVs in the vicinity of civil airports and test it in the field. This article is the plan to complete, by end 2022, a dissertation currently in its confirmation phase.},
booktitle = {Proceedings of the ACM/IEEE 42nd International Conference on Software Engineering: Companion Proceedings},
pages = {174–177},
numpages = {4}
}

@inproceedings{10.1145/3460620.3460749,
author = {Alzate, Javier Rozo and Tabares, Marta S. and Vallejo, Paola},
title = {Graffiti and Government in Smart Cities: A Deep Learning Approach Applied to Medell\'{\i}n City, Colombia},
year = {2021},
isbn = {9781450388382},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3460620.3460749},
doi = {10.1145/3460620.3460749},
abstract = { Graffiti is an element of graphic expression that manifests different states of the human being. However, for many governments worldwide, it has been an element of discord between them and the communities that express themselves through graffitis. This article proposes identifying graffiti and concentration zones through Computer Vision and object detection and localization to support public policy management in smart cities. ASUM-DM methodology is used to achieve the aim. Initially, the current problems faced by municipal governments in the management of public graffiti policy are identified. Then available datasets of images from Google Street View (GSV) and other acquired datasets are identified for the case study carried out in the city of Medell\'{\i}n (Colombia) and border municipalities. A training dataset of 1,395 images and a production dataset of 71,100 panoramas is placed on strictly using the experimental method of the division of training data, validation, and a production sample, to make a correct estimation of the generalization error. As a result of the training process, we obtained an Average Precision of 69,14%, which presented a high precision Tag of 89.23%, and low precision of 59.13% in Mural. Finally, it is possible to build heat maps of graffiti concentration areas that could guide rulers to create or improve public policies related to graffiti expression.},
booktitle = {International Conference on Data Science, E-Learning and Information Systems 2021},
pages = {160–165},
numpages = {6},
keywords = {Public policies, Deep Learning, Smart cities, Graffiti., Object Detection and Localization},
location = {Ma'an, Jordan},
series = {DATA'21}
}

@article{10.1145/3306346.3322940,
author = {Xu, Jie and Du, Tao and Foshey, Michael and Li, Beichen and Zhu, Bo and Schulz, Adriana and Matusik, Wojciech},
title = {Learning to Fly: Computational Controller Design for Hybrid UAVs with Reinforcement Learning},
year = {2019},
issue_date = {August 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {38},
number = {4},
issn = {0730-0301},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3306346.3322940},
doi = {10.1145/3306346.3322940},
abstract = {Hybrid unmanned aerial vehicles (UAV) combine advantages of multicopters and fixed-wing planes: vertical take-off, landing, and low energy use. However, hybrid UAVs are rarely used because controller design is challenging due to its complex, mixed dynamics. In this paper, we propose a method to automate this design process by training a mode-free, model-agnostic neural network controller for hybrid UAVs. We present a neural network controller design with a novel error convolution input trained by reinforcement learning. Our controller exhibits two key features: First, it does not distinguish among flying modes, and the same controller structure can be used for copters with various dynamics. Second, our controller works for real models without any additional parameter tuning process, closing the gap between virtual simulation and real fabrication. We demonstrate the efficacy of the proposed controller both in simulation and in our custom-built hybrid UAVs (Figure 1, 8). The experiments show that the controller is robust to exploit the complex dynamics when both rotors and wings are active in flight tests.},
journal = {ACM Trans. Graph.},
month = {jul},
articleno = {42},
numpages = {12},
keywords = {hybrid UAVs, neural network controllers}
}

@inproceedings{10.1145/3373419.3373450,
author = {Yang, Tianwei and Yang, Jungang and An, Wei},
title = {An Improved Method of Detecting Infrared Weak and Small Targets Based on Deep Learning},
year = {2019},
isbn = {9781450376754},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3373419.3373450},
doi = {10.1145/3373419.3373450},
abstract = {The convolution network is a very powerful visual model that can be used to detect objects in an image. Traditional target detection frameworks are generally divided into anchor-based object detector and anchor-free object detector. Among them, SSD is a single-stage anchor-based object detector that can detect objects quickly and efficiently. In order to detect the infrared weak and small objects, we improve the SSD network for our object detection tasks by using an improved backbone network. We use the open UAVs dataset and achieve highly training and testing accuracy in the open dataset.},
booktitle = {Proceedings of the 2019 3rd International Conference on Advances in Image Processing},
pages = {15–18},
numpages = {4},
keywords = {Backbone, SSD, Detnet, Infrared object detection},
location = {Chengdu, China},
series = {ICAIP 2019}
}

@inproceedings{10.1145/3086512.3086524,
author = {Karanasiou, Argyro and Pinotsis, Dimitris},
title = {Towards a Legal Definition of Machine Intelligence: The Argument for Artificial Personhood in the Age of Deep Learning},
year = {2017},
isbn = {9781450348911},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3086512.3086524},
doi = {10.1145/3086512.3086524},
abstract = {The paper dissects the intricacies of Automated Decision Making (ADM) and urges for refining the current legal definition of AI when pinpointing the role of algorithms in the advent of ubiquitous computing, data analytics and deep learning. ADM relies upon a plethora of algorithmic approaches and has already found a wide range of applications in marketing automation, social networks, computational neuroscience, robotics, and other fields. Our main aim here is to explain how a thorough understanding of the layers of ADM could be a first good step towards this direction: AI operates on a formula based on several degrees of automation employed in the interaction between the programmer, the user, and the algorithm; this can take various shapes and thus yield different answers to key issues regarding agency. The paper offers a fresh look at the concept of "Machine Intelligence", which exposes certain vulnerabilities in its current legal interpretation. Most importantly, it further helps us to explore whether the argument for "artificial personhood" holds any water. To highlight this argument, analysis proceeds in two parts: Part 1 strives to provide a taxonomy of the various levels of automation that reflects distinct degrees of Human - Machine interaction and can thus serve as a point of reference for outlining distinct rights and obligations of the programmer and the consumer: driverless cars are used as a case study to explore the several layers of human and machine interaction. These different degrees of automation reflect various levels of complexities in the underlying algorithms, and pose very interesting questions in terms of agency and dynamic tasks carried out by software agents. Part 2 further discusses the intricate nature of the underlying algorithms and artificial neural networks (ANN) that implement them and considers how one can interpret and utilize observed patterns in acquired data. Is "artificial personhood" a sufficient legal response to highly sophisticated machine learning techniques employed in decision making that successfully emulate or even enhance human cognitive abilities?},
booktitle = {Proceedings of the 16th Edition of the International Conference on Articial Intelligence and Law},
pages = {119–128},
numpages = {10},
keywords = {ANN, machine learning, algorithmic agency, personhood hybrids},
location = {London, United Kingdom},
series = {ICAIL '17}
}

@inproceedings{10.1145/3457682.3457739,
author = {Cai, Tianxiao and Zhang, Sheng and Tan, Boyu},
title = {AEE-Net: An Efficient End-to-End Dehazing Network in UAV Imaging System},
year = {2021},
isbn = {9781450389310},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3457682.3457739},
doi = {10.1145/3457682.3457739},
abstract = {Because it can provide real-time images for the first time, UAV plays a massive role in disaster relief, environmental observation, and information collection. However, the quality of images collected by UAV is always affected by fog. Therefore, the research on how to remove the fog in the image becomes more and more critical. In recent years, the role of convolutional neural networks (CNN), which can automatically extract features and efficiently process high-dimensional data, has received more and more attention in many disciplines. To improve the imaging quality of UAV in a foggy environment, this paper proposes an image dehazing model built with a convolutional neural network (CNN), called an effective end-to-end dehazing Network (AEE-Net). Our proposed method has a faster running speed than traditional models due to the simple structure of the model and the design based on the modified atmospheric scattering model. Our method combines the characteristics of dehazing processes and the advantages of deep learning. Experimental results on the training set and raw images show that the proposed method has better performance than traditional methods. This method can improve the quality of UAV-captured images under foggy conditions and can meet the input requirements of UAV vision tasks.},
booktitle = {2021 13th International Conference on Machine Learning and Computing},
pages = {397–403},
numpages = {7},
keywords = {Dehazing vessel, Atmosphere scattering model, UAV, Image restoration, CNN, Machine learning},
location = {Shenzhen, China},
series = {ICMLC 2021}
}

@inproceedings{10.1145/3360774.3368199,
author = {Zhang, Hongxing and Gao, Hui and Su, Xin},
title = {Channel Prediction Based on Adaptive Structure Extreme Learning Machine for UAV MmWave Communications},
year = {2019},
isbn = {9781450372831},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3360774.3368199},
doi = {10.1145/3360774.3368199},
abstract = {In unmanned aerial vehicle (UAV) millimeter wave (mmWave) communications, the inter-UAV wireless channel is fast varying because the high mobility of the UAV transmission platform. In such dynamic scenarios, it is very costly to obtain the inter-UAV channel state information (CSI) with the conventional pilot-aided channel estimation. Aiming to address this critical issue, in this paper, we propose a novel adaptive-structure extreme learning machine (ASELM) enabled fast channel predication to obtain the CSI in a proactive fashion, which can further support agile beam-based inter-UAV mmWave communication. In particular, ASELM copes with the channel variations by adaptively adjusting the number of neurons in the hidden-layer of ELM. Moreover, a sliding window prediction mechanism (SWPM) predicts subsequent-CSI by efficiently reuses the predicted concurrent-CSI to train the ASELM, which is able to save the pilot overhead for channel sampling (estimation) towards longer-range channel prediction and improve prediction accuracy at affordable costs. Simulation results show that the proposed ASELM enabled fast channel predication can achieve lower normalized mean square error than traditional prediction algorithm in the considered inter-UAV mmWave communication scenarios.},
booktitle = {Proceedings of the 16th EAI International Conference on Mobile and Ubiquitous Systems: Computing, Networking and Services},
pages = {492–497},
numpages = {6},
keywords = {adaptive structure extreme learning machine (ASELM), sliding window prediction mechanism (SWPM), unmanned aerial vehicle (UAV), channel prediction},
location = {Houston, Texas, USA},
series = {MobiQuitous '19}
}

@inproceedings{10.1145/3474717.3483970,
author = {Xie, Yiqun and Jia, Xiaowei and Bao, Han and Zhou, Xun and Yu, Jia and Ghosh, Rahul and Ravirathinam, Praveen},
title = {Spatial-Net: A Self-Adaptive and Model-Agnostic Deep Learning Framework for Spatially Heterogeneous Datasets},
year = {2021},
isbn = {9781450386647},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3474717.3483970},
doi = {10.1145/3474717.3483970},
abstract = {Knowledge discovery from spatial data is essential for many important societal applications including crop monitoring, solar energy estimation, traffic prediction and public health. This paper aims to tackle a key challenge posed by spatial data - the intrinsic spatial heterogeneity commonly embedded in their generation processes - in the context of deep learning. In related work, the early rise of convolutional neural networks showed the promising value of explicit spatial-awareness in deep architectures (i.e., preservation of spatial structure among input cells and the use of local connection). However, the issue of spatial heterogeneity has not been sufficiently explored. While recent developments have tried to incorporate awareness of spatial variability (e.g., SVANN), these methods either rely on manually-defined space partitioning or only support very limited partitions (e.g., two) due to reduction of training data. To address these limitations, we propose a Spatial-Net to simultaneously learn a space-partitioning scheme and a deep network architecture with a Significance-based Grow-and-Collapse (SIG-GAC) framework. SIG-GAC allows collaborative training between partitions and uses an exponential reduction tree to control the network size. Experiments using real-world datasets show that Spatial-Net can automatically learn the pattern underlying heterogeneous spatial process and greatly improve model performance.},
booktitle = {Proceedings of the 29th International Conference on Advances in Geographic Information Systems},
pages = {313–323},
numpages = {11},
keywords = {model-agnostic, deep learning, Spatial-Net, spatial heterogeneity},
location = {Beijing, China},
series = {SIGSPATIAL '21}
}

@inproceedings{10.1145/3351180.3351183,
author = {Zeng, Diqing and Zeng, Guigen and Kodom, Prince Owusu},
title = {Research on Recognition Technology of Vehicle Rolling Line Violation in Highway Based on Visual UAV},
year = {2019},
isbn = {9781450371834},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3351180.3351183},
doi = {10.1145/3351180.3351183},
abstract = {The recognition technology of vehicle illegal rolling line is an important part of intelligent transportation system. Aiming at the problems of traditional fixed monitoring and traditional rolling line detection algorithm, this paper designs a system model of vehicle illegal rolling line recognition based on visual UAV. Firstly, video data are collected by UAV patrol aerial photography, vehicle target detection is carried out by YOLOv3 algorithm based on deep learning, and then combined with lane line detection results based on closed angles average algorithm, according to whether the diagonal line of the bounding box of the vehicle intersects with the solid lane line to determine whether the vehicle is illegally compacted or not. The experimental results show that the accuracy and robustness of the proposed model are significantly improved compared with those of the traditional monitoring technology for illegal rolling. This provides an efficient and flexible monitoring mode for traffic monitoring and management.},
booktitle = {Proceedings of the 2019 4th International Conference on Robotics, Control and Automation},
pages = {198–204},
numpages = {7},
keywords = {Vehicle Illegal Rolling, Unmanned Aerial Vehicle, Lane Line Detection, Deep Learning Target Detection},
location = {Guangzhou, China},
series = {ICRCA 2019}
}

@article{10.1145/3447866,
author = {Boukerche, Azzedine and Ma, Xiren},
title = {Vision-Based Autonomous Vehicle Recognition: A New Challenge for Deep Learning-Based Systems},
year = {2021},
issue_date = {May 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {54},
number = {4},
issn = {0360-0300},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3447866},
doi = {10.1145/3447866},
abstract = {Vision-based Automated Vehicle Recognition (VAVR) has attracted considerable attention recently. Particularly given the reliance on emerging deep learning methods, which have powerful feature extraction and pattern learning abilities, vehicle recognition has made significant progress. VAVR is an essential part of Intelligent Transportation Systems. The VAVR system can fast and accurately locate a target vehicle, which significantly helps improve regional security. A comprehensive VAVR system contains three components: Vehicle Detection (VD), Vehicle Make and Model Recognition (VMMR), and Vehicle Re-identification (VRe-ID). These components perform coarse-to-fine recognition tasks in three steps. In this article, we conduct a thorough review and comparison of the state-of-the-art deep learning--based models proposed for VAVR. We present a detailed introduction to different vehicle recognition datasets used for a comprehensive evaluation of the proposed models. We also critically discuss the major challenges and future research trends involved in each task. Finally, we summarize the characteristics of the methods for each task. Our comprehensive model analysis will help researchers that are interested in VD, VMMR, and VRe-ID and provide them with possible directions to solve current challenges and further improve the performance and robustness of models.},
journal = {ACM Comput. Surv.},
month = {may},
articleno = {84},
numpages = {37},
keywords = {Deep learning, fine-grained recognition, vehicle detection, vehicle re-identification, video surveillance, convolutional neural network, intelligent transportation system, vehicle make and model recognition}
}

@inproceedings{10.1145/3206185.3206188,
author = {Zhang, Xiaonan and Luo, Pengcheng and Hu, Xinwu},
title = {Defense Success Rate Evaluation for UAV Swarm Defense System},
year = {2018},
isbn = {9781450364126},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3206185.3206188},
doi = {10.1145/3206185.3206188},
abstract = {Unmanned aerial vehicle (UAV) swarms will play important roles in future warfare. Given the worldwide advances in unmanned systems, UAV swarms pose an increasing threat to traditional defensive methods. This paper addresses the concept of a defensive UAV swarm launched from a sea-based platform. To simulate and analyze this this system, an agent-based model is developed, and the defense success rate (DSR) is proposed as a metric of effectiveness, which can avoid inaccuracies of evaluation in a single simulation result. Then single-factor experiments are conducted to analyze the impacts of different design factors, and some reasonable and comprehensive suggestions are provided to improve the DSR. This paper showcases the important meaning of artificial intelligence in the study of UAV swarm combat and deeply analyzes the impacts of various factors on UAV swarm defense system which can be used for future engineering designs.},
booktitle = {Proceedings of the 2nd International Conference on Intelligent Systems, Metaheuristics &amp; Swarm Intelligence},
pages = {127–132},
numpages = {6},
keywords = {simulation, evaluation, factorial experiments, UAV swarm, DSR},
location = {Phuket, Thailand},
series = {ISMSI '18}
}

@inproceedings{10.1145/3332186.3333049,
author = {Merck, Matthew L. and Wang, Bingyao and Liu, Lixing and Jia, Chunjun and Siqueira, Arthur and Huang, Qiusen and Saraha, Abhijeet and Lim, Dongsuk and Cao, Jiashen and Hadidi, Ramyad and Kim, Hyesoon},
title = {Characterizing the Execution of Deep Neural Networks on Collaborative Robots and Edge Devices},
year = {2019},
isbn = {9781450372275},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3332186.3333049},
doi = {10.1145/3332186.3333049},
abstract = {Edge devices and robots have access to an abundance of raw data that needs to be processed on the edge. Deep neural networks (DNNs) can help these devices understand and learn from this complex data; however, executing DNNs while achieving high performance is a challenge for edge devices. This is because of the high computational demands of DNN execution in real-time. This paper describes and implements a method to enable edge devices to execute DNNs collaboratively. This is possible and useful because in many environments, several on-edge devices are already integrated in their surroundings, but are usually idle and can provide additional computing power to a distributed system. We implement this method on two iRobots, each of which has been equipped with a Raspberry Pi 3. Then, we characterize the execution performance, communication latency, energy consumption, and thermal behavior of our system while it is executing AlexNet.},
booktitle = {Proceedings of the Practice and Experience in Advanced Research Computing on Rise of the Machines (Learning)},
articleno = {65},
numpages = {6},
location = {Chicago, IL, USA},
series = {PEARC '19}
}

@inproceedings{10.1145/3454127.3457637,
author = {Taberkit, Amine Mohammed and Kechida, Ahmed and Bouguettaya, Abdelmalek},
title = {Algerian Perspectives for UAV-Based Remote Sensing Technologies and Artificial Intelligence in Precision Agriculture},
year = {2021},
isbn = {9781450388719},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3454127.3457637},
doi = {10.1145/3454127.3457637},
abstract = { Unmanned Aerial Vehicles (UAVs) are considered emerging innovative technologies, equipped with different sensors they can offer various services and applications. It is possible to exploit unmanned aerial vehicles to capture high spatial resolution images and high temporal resolution images, which could be helpful in many smart farming applications. We expect that these innovations will revolutionize agriculture, enabling to take faster decisions, and promise major cost savings and production enhancements. Precision agriculture is based on the use of the right process, with the right quantities, at the proper place and time, according to the targeted application. In this paper, we address the prevalent applications of UAVs and artificial intelligence in precision agriculture and their benefits in Algeria.},
booktitle = {Proceedings of the 4th International Conference on Networking, Information Systems &amp; Security},
articleno = {61},
numpages = {9},
keywords = {Remote Sensing., Artificial Intelligence, Unmanned Aerial Vehicle, Precision Agriculture, Smart Farming},
location = {KENITRA, AA, Morocco},
series = {NISS2021}
}

@inproceedings{10.1145/3416014.3424600,
author = {Martinez-Alpiste, Ignacio and Golcarenarenji, Gelayol and Wang, Qi and Alcaraz-Calero, Jose Maria},
title = {Real-Time Low-Pixel Infrared Human Detection From Unmanned Aerial Vehicles},
year = {2020},
isbn = {9781450381215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3416014.3424600},
doi = {10.1145/3416014.3424600},
abstract = {To improve the speed and accuracy in human detection in Search and Rescue (SAR) operations, this paper presents a novel and highly efficient machine learning empowered system by extending the You Only Look Once (YOLO) algorithm, which is designed and deployed on an embedded system. The proposed approach has been evaluated under real-world conditions on a Jetson AGX Xavier platform and the results have shown a well-balanced system in terms of accuracy, speed and portability. Moreover, the system demonstrates its resilience to perform low-pixel human detection on infrared images received from an Unmanned Aerial Vehicle (UAV) at low-light conditions, different altitudes and postures such as sitting, walking and running. The proposed approach has achieved in a constrained environment a total of 89.26% of accuracy and 24.6 FPS, surpassing the barrier of real-time object recognition.},
booktitle = {Proceedings of the 10th ACM Symposium on Design and Analysis of Intelligent Vehicular Networks and Applications},
pages = {9–15},
numpages = {7},
keywords = {YOLO, machine learning, Jetson AGX Xavier, UAV, thermal imagery},
location = {Alicante, Spain},
series = {DIVANet '20}
}

@inproceedings{10.1145/3419111.3421302,
author = {Jeon, Beomyeol and Cai, Linda and Srivastava, Pallavi and Jiang, Jintao and Ke, Xiaolan and Meng, Yitao and Xie, Cong and Gupta, Indranil},
title = {Baechi: Fast Device Placement of Machine Learning Graphs},
year = {2020},
isbn = {9781450381376},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3419111.3421302},
doi = {10.1145/3419111.3421302},
abstract = {Machine Learning graphs (or models) can be challenging or impossible to train when either devices have limited memory, or the models are large. Splitting the model graph across multiple devices, today, largely relies on learning-based approaches to generate this placement. While it results in models that train fast on data (i.e., with low step times), learning-based model-parallelism is time-consuming, taking many hours or days to create a placement plan of operators on devices. We present the Baechi system, where we adopt an algorithmic approach to the placement problem for running machine learning training graphs on a small cluster of memory-constrained devices. We implemented Baechi so that it works modularly with TensorFlow. Our experimental results using GPUs show that Baechi generates placement plans in time 654X--206K X faster than today's learning-based approaches, and the placed model's step time is only up to 6.2% higher than expert-based placements.},
booktitle = {Proceedings of the 11th ACM Symposium on Cloud Computing},
pages = {416–430},
numpages = {15},
keywords = {placement algorithms, constrained memory, machine learning systems, TensorFlow, distributed systems},
location = {Virtual Event, USA},
series = {SoCC '20}
}

@inproceedings{10.5555/3374138.3374173,
author = {Kilic, Sezgin and Ozkan, Omer},
title = {A Self-Adaptive UAV Routing for Forest Fire Risk Mitigation: A Conceptual Model},
year = {2019},
publisher = {Society for Computer Simulation International},
address = {San Diego, CA, USA},
abstract = {Forests have crucial importance for the sustainability of Earth and humanity and one of the biggest threats to the existence of forests are the fires. This paper proposes a conceptual model for mitigating forest fire risk by use of self-adaptive and autonomous unmanned aerial vehicles (UAVs). Memoryless property of exponential distribution is also reflected and considered in the calculations of forest fire probabilities. Stochastic and dynamic properties of the situation and the mathematical complexity of the routing problem entailed and justified a simulation study. The effectiveness of the proposed dispatching approach for routing UAVs and the validity of the proposed model are tested on a small sized realistic scenario. Experimental results encourage the development of complex models. Integrating the proposed model with advanced information technologies may lead to the development of a digital twin system.},
booktitle = {Proceedings of the 2019 Summer Simulation Conference},
articleno = {35},
numpages = {12},
keywords = {unmanned aerial vehicle, forest fire detection, UAV routing},
location = {Berlin, Germany},
series = {SummerSim '19}
}

@inproceedings{10.1145/3446132.3446198,
author = {Shen, Xiangeng and Liu, Xiaoyang and Jiao, Pengfei},
title = {Research on the Application of Image Processing in Improving the Reconnaissance Efficiency of UAV},
year = {2020},
isbn = {9781450388115},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3446132.3446198},
doi = {10.1145/3446132.3446198},
abstract = {With the development of military intelligence, uav has become one of the important means of intelligence acquisition in modern warfare. As the main way of UAV reconnaissance, image reconnaissance is playing an increasingly important role in the mission. At present, in the process of uav image reconnaissance, there are still some problems, such as unclear fog image and inability to reflect the overall situation. Aiming at these two kinds of problems, this paper reviews several mainstream algorithms of image processing. Then the algorithm is compared and analyzed based on the characteristics of uav reconnaissance image. Finally, the application prospect of image processing algorithm in improving uav reconnaissance efficiency is prospected.},
booktitle = {2020 3rd International Conference on Algorithms, Computing and Artificial Intelligence},
articleno = {66},
numpages = {5},
keywords = {Image processing, Unmanned aerial vehicle, Reconnaissance},
location = {Sanya, China},
series = {ACAI 2020}
}

@inproceedings{10.1145/3414045.3415947,
author = {Al-Hilo, Ahmed and Samir, Moataz and Assi, Chadi and Sharafeddine, Sanaa and Ebrahimi, Dariush},
title = {Cooperative Content Delivery in UAV-RSU Assisted Vehicular Networks},
year = {2020},
isbn = {9781450381055},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3414045.3415947},
doi = {10.1145/3414045.3415947},
abstract = {Intelligent Transportation Systems (ITS) are gaining substantial attention owing to the great benefits offered to the vehicle users. In ITS paradigm, content data is normally obtained from road side units (RSUs). However, in some scenarios, terrestrial networks are partially/temporarily out-of-service. Unmanned Aerial Vehicle (UAV) or drone cells are expected to be one of the pillars of future networks to assist the vehicular networks in such scenarios. To this end, we propose a collaborative framework between UAVs and in-service RSUs to partial service vehicles. Our objective is to maximize the amount of downloaded contents to vehicles while considering the dynamic nature of the network. Motivated by the success of machine learning (ML) techniques particularly deep Reinforcement learning in solving complex problems, we formulate the scheduling and content management policy problem as a Markov Decision Process (MDP) where the system state space considers the vehicular network dynamics. Proximal Policy Optimization (PPO) is utilized to govern the content decisions in the vehicular network. The simulation-based results show that during the mission time, the proposed algorithm learns the vehicular environment and its dynamics to handle the complex action space.},
booktitle = {Proceedings of the 2nd ACM MobiCom Workshop on Drone Assisted Wireless Communications for 5G and Beyond},
pages = {73–78},
numpages = {6},
keywords = {content delivery, UAV, RSU, PPO},
location = {London, United Kingdom},
series = {DroneCom '20}
}

@inproceedings{10.1145/3321408.3321414,
author = {Grewe, Lynne and Stevenson, Garrett},
title = {Seeing Eye Drone: A Deep Learning, Vision-Based UAV for Assisting the Visually Impaired with Mobility},
year = {2019},
isbn = {9781450371582},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3321408.3321414},
doi = {10.1145/3321408.3321414},
abstract = {Seeing Eye Drone assists low-vision persons with environment awareness performing exploration and obstacle detection. The modalities of 3D (stereo) and 2D vision on a drone are compared for this task. Different deep-learning systems are developed including 2D only and 3D+2D networks. Comparisons of retrained networks versus training from scratch are also made and approximately 34,000 samples were collected for training and the resulting SSD CNN architecture is used to determine a user's location and direction of travel. A second network identifies locations of common objects in the scene. The object locations are then compared with the user location/heading and depth data to determine whether they represent obstacles. Obstacles determined to be in the user's region of interest are communicated to the visually-impaired user via Text-to-Speech. Real data from outdoor drone flights that communicate with an Android based application are shown.},
booktitle = {Proceedings of the ACM Turing Celebration Conference - China},
articleno = {110},
numpages = {5},
keywords = {blind/ low vision, machine learning, assistive technology, drone, computer vision},
location = {Chengdu, China},
series = {ACM TURC '19}
}

@inbook{10.1145/3458380.3458422,
author = {Zhao, Zhiwei and song, lili and han, jianfeng},
title = {An Improved Object Detection Model for Autonomous Pilot of Engineering Inspection},
year = {2021},
isbn = {9781450389365},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3458380.3458422},
abstract = {Previously, Engineering maintenance vehicle mainly through human operations, which has higher labor costs and lower efficiency. In order to obtain complete images needed in the field of engineering maintenance quickly and easily, auto pilot of engineering maintenance vehicle can play a huge role in engineering fields such as power maintenance and highway maintenance. Automatic ground key information detection is the most important part of auto pilot of engineering maintenance vehicle. In this study, we propose a new model that uses an improved form of the You Only Look Once (YOLO) model to enhance the real-time detection of key information problems. This model is mainly realized by optimizing the network structure of original YOLOv3 model. The experimental results show that in the highway center marking data set, the precision of the trained model is 95.76%, and an average accuracy of 90.43% for the test setup. By comparing with YOLOv3, the detection accuracy of the proposed improved method is mainly improved. At the same time, under GPU acceleration, the average detection speed is 29.20 frames/s, which can meet the real-time detection by the engineering maintenance vehicle platform.},
booktitle = {2021 5th International Conference on Digital Signal Processing},
pages = {243–248},
numpages = {6}
}

@inbook{10.1145/3394171.3413934,
author = {Mandal, Murari and Kumar, Lav Kush and Vipparthi, Santosh Kumar},
title = {MOR-UAV: A Benchmark Dataset and Baselines for Moving Object Recognition in UAV Videos},
year = {2020},
isbn = {9781450379885},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3394171.3413934},
abstract = {Visual data collected from Unmanned Aerial Vehicles (UAVs) has opened a new frontier of computer vision that requires automated analysis of aerial images/videos. However, the existing UAV datasets primarily focus on object detection. An object detector does not differentiate between the moving and non-moving objects. Given a real-time UAV video stream, how can we both localize and classify the moving objects, i.e. perform moving object recognition (MOR) The MOR is one of the essential tasks to support various UAV vision-based applications including aerial surveillance, search and rescue, event recognition, urban and rural scene understanding.To the best of our knowledge, no labeled dataset is available for MOR evaluation in UAV videos. Therefore, in this paper, we introduce MOR-UAV, a large-scale video dataset for MOR in aerial videos. We achieve this by labeling axis-aligned bounding boxes for moving objects which requires less computational resources than producing pixel-level estimates. We annotate 89,783 moving object instances collected from 30 UAV videos, consisting of 10,948 frames in various scenarios such as weather conditions, occlusion, changing flying altitude and multiple camera views. We assigned the labels for two categories of vehicles (car and heavy vehicle). Furthermore, we propose a deep unified framework MOR-UAVNet for MOR in UAV videos. Since, this is a first attempt for MOR in UAV videos, we present 16 baseline results based on the proposed framework over the MOR-UAV dataset through quantitative and qualitative experiments. We also analyze the motion-salient regions in the network through multiple layer visualizations. The MOR-UAVNet works online at inference as it requires only few past frames. Moreover, it doesn't require predefined target initialization from user. Experiments also demonstrate that the MOR-UAV dataset is quite challenging.},
booktitle = {Proceedings of the 28th ACM International Conference on Multimedia},
pages = {2626–2635},
numpages = {10}
}

@inproceedings{10.1145/3479645.3479661,
author = {Kusnandar, Toni and Surendro, Kridanto},
title = {Camera-Based Vegetation Index from Unmanned Aerial Vehicles},
year = {2021},
isbn = {9781450384070},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3479645.3479661},
doi = {10.1145/3479645.3479661},
abstract = {Agriculture assumes a vital role in human life because it provides food, feed for livestock, and bioenergy. The agricultural sector is expected to meet the needs of secure and nutritious food for the community at all times to boost productivity. Providing nutrition, water and light precisely and measuredly is an important effort in plant cultivation to produce quality. This effort can be materialized by implementing smart farming involving devices and information technology. Vast field surveillance or monitoring is made easy with the advent of unmanned aerial vehicle (UAV). Detection of plant condition can be achieved by obtaining Vegetation Index (VI) through camera imaging in UAVs which are more economic compared to multispectral or hyperspectral cameras. This study aims to obtain VI that is accurate but still economical, so that it can be utilized even by small-scale agriculture. The work that will be done is to conduct repair experiments at several stages of image processing to produce a new, more accurate VI. The research stages started from experiments on previous research, to finding new research opportunities in VI. Furthermore, the experiment was carried out with the addition of white balance value parameters and other UAV sensor parameters at the Pre-Processing stage to improve its quality. The hypothesis of adding white balance parameters should prove to be more accurate in correcting shooting in various light conditions. Next, try to modify the feature extraction algorithm using Color Extraction Edge Detection. Followed by modifying it using Back Propagation Neural Network to increase accuracy at the image processing stage. After synthesizing some of these experiments, a new formula or model VI using the camera on the UAV is expected to be produced. This research will contribute to the modification of methods or algorithms at the image processing stage to produce a corrected image in producing a new VI that is more accurate using a camera on a more economical UAV.},
booktitle = {6th International Conference on Sustainable Information Engineering and Technology 2021},
pages = {173–178},
numpages = {6},
keywords = {Precission Agriculture, Vegetation Index, Image Processing, Unmanned Aerial Vehicle},
location = {Malang, Indonesia},
series = {SIET '21}
}

@inproceedings{10.1145/3131885.3131906,
author = {Cavigelli, Lukas and Degen, Philippe and Benini, Luca},
title = {CBinfer: Change-Based Inference for Convolutional Neural Networks on Video Data},
year = {2017},
isbn = {9781450354875},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3131885.3131906},
doi = {10.1145/3131885.3131906},
abstract = {Extracting per-frame features using convolutional neural networks for real-time processing of video data is currently mainly performed on powerful GPU-accelerated workstations and compute clusters. However, there are many applications such as smart surveillance cameras that require or would benefit from on-site processing. To this end, we propose and evaluate a novel algorithm for change-based evaluation of CNNs for video data recorded with a static camera setting, exploiting the spatio-temporal sparsity of pixel changes. We achieve an average speed-up of 8.6x over a cuDNN baseline on a realistic benchmark with a negligible accuracy loss of less than 0.1% and no retraining of the network. The resulting energy efficiency is 10x higher than that of per-frame evaluation and reaches an equivalent of 328 GOp/s/W on the Tegra X1 platform.},
booktitle = {Proceedings of the 11th International Conference on Distributed Smart Cameras},
pages = {1–8},
numpages = {8},
location = {Stanford, CA, USA},
series = {ICDSC 2017}
}

@inproceedings{10.1145/3395260.3395263,
author = {Zhang, Sheng and Li, Jie and Yang, Chengwei and Yang, Yu and Hu, Xiaolin},
title = {Vision-Based UAV Positioning Method Assisted by Relative Attitude Classification},
year = {2020},
isbn = {9781450377072},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3395260.3395263},
doi = {10.1145/3395260.3395263},
abstract = {When the Unmanned Aerial Vehicle(UAV) is flying in formation, the common communication method is radio frequency(RF) communication. However, in practical applications, the way of RF communication is susceptible to interference from other factors such as electromagnetism. Therefore, in order to improve the anti-interference of the UAV cluster flight, it's necessary to use a positioning method which is based on visual information. Based on the above analysis, this paper proposes a vision-based UAV positioning method assisted by attitude classification. Firstly, the problem of solving the relative attitude of the UAV is transformed into a classification problem by the object recognition method, and a preliminary classification of the relative attitude of the friendly UAV is realized. Based on the principle of camera calibration, the pixel size and coordinates of the target UAV can be transform to the body coordinate system. Since the camera and the carrier UAV are fixedly connected, when the latitude and longitude coordinates of the carrier UAV are known, relative coordinate conversion can be performed to calculate the coordinates of the target UAV in the world coordinate system. Realize the positioning task of the target UAV. Simulation results are performed on the proposed method of the UAV relative attitude recognition accuracy exceeds 90%, and the average error in the distance simulation system of 2.56%. The final coordinate positioning accuracy exceeds 90% without losing the target.},
booktitle = {Proceedings of the 2020 5th International Conference on Mathematics and Artificial Intelligence},
pages = {154–160},
numpages = {7},
keywords = {fixed-wing UAV, relative attitude recognition, UAV formation, Computer-visual, deep-learning, target positioning},
location = {Chengdu, China},
series = {ICMAI 2020}
}

@inproceedings{10.1145/3427228.3427254,
author = {Xue, Nian and Niu, Liang and Hong, Xianbin and Li, Zhen and Hoffaeller, Larissa and P\"{o}pper, Christina},
title = {DeepSIM: GPS Spoofing Detection on UAVs Using Satellite Imagery Matching},
year = {2020},
isbn = {9781450388580},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3427228.3427254},
doi = {10.1145/3427228.3427254},
abstract = { Unmanned Aerial Vehicles (UAVs), better known as drones, have significantly advanced fields such as aerial surveillance, military reconnaissance, cadastral surveying, disaster monitoring, and delivery services. However, UAVs rely on civilian (unauthenticated) GPS for navigation which can be trivially spoofed. In this paper, we present DeepSIM, a satellite imagery matching approach to detect GPS spoofing attacks against UAVs based on deep learning. We make use of the camera(s) a typical UAV is equipped with, and present a system that compares historical satellite images of its GPS-based position (spaceborne photography) with real-time aerial images from its cameras (airborne imagery). Historical images are taken from, e.&nbsp;g., Google Earth or NASA WorldWind. To detect GPS spoofing attacks, we investigate different deep neural network models that compare the real-time camera images with the historical satellite images. To train and test the models, we have constructed the SatUAV dataset (consisting of 967 image pairs), partially by using real UAVs such as the DJI Phantom 4 Advanced. Real-world experimental results show that our best model has a success rate of about 95% in detecting GPS spoofing attacks within less than 100 milliseconds. Our approach does not require any modification of the existing GPS infrastructures and relies only on public satellite imagery, making it a practical solution for many everyday scenarios.},
booktitle = {Annual Computer Security Applications Conference},
pages = {304–319},
numpages = {16},
keywords = {neural networks, GPS spoofing detection, UAV, deep learning},
location = {Austin, USA},
series = {ACSAC '20}
}

@inproceedings{10.1145/3485190.3485232,
author = {Zhang, Lu and Yu, Xueying and Zhang, Shuyi},
title = {Research on Collaborative and Confrontation of UAV Swarms Based on SAC-OD Rules},
year = {2021},
isbn = {9781450384278},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3485190.3485232},
doi = {10.1145/3485190.3485232},
abstract = {With the introduction of the new generation of artificial intelligence technology into the military field, unmanned aerial vehicle (UAV) swarm operation, as an important form of intelligent operation, has attracted the attention of various countries. In this paper, we consider the problem of coordinated confrontation between UAV swarms in the plane area. An improved “SAC-OD” rules and combat strategy of UAV swarm are employed to establish the decision-making model for UAV swarm conflict where each UAV in the swarm is regarded as an independent individual. With the introduction of SAC-OD, each UAV keeps on interacting with its neighboring environment and the UAV swarm conflict is dynamic. Simulation experiments are conducted using MATLAB and the results demonstrate the effectiveness of the built decision-making model for UAV swarm conflict.},
booktitle = {2021 4th International Conference on Information Management and Management Science},
pages = {273–278},
numpages = {6},
keywords = {dynamic confrontation, UAV, SAC-OD, cooperative search},
location = {Chengdu, China},
series = {IMMS 2021}
}

@inproceedings{10.1145/3404663.3404668,
author = {Shanthakumar, Vaidyanath Areyur and Banerjee, Chaity and Mukherjee, Tathagata and Pasiliao, Eduardo},
title = {Uncooperative RF Direction Finding with I/Q Data},
year = {2020},
isbn = {9781450377652},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3404663.3404668},
doi = {10.1145/3404663.3404668},
abstract = {This paper studies the possibility of implicitly exploiting the characteristics of the In-phase and Quadrature components (I/Q components) of a transmitter using deep learning techniques for the problem of uncooperative direction finding using a single un-calibrated directional receiver. Radio "Direction Finding" (DF) is the problem of estimating the direction of a radio transmitter using features of the received signal. In this paper, we study this problem in the 2.4 GHz WiFi band and restrict ourselves to using I/Q information in a deep learning framework. For this work we used a custom designed data acquisition system built with commercial off-the-shelf (COTS) hardware and collected over the air raw I/Q signal data in both indoor and outdoor settings. The experimental results show that it is possible to reliably predict the bearing of the transmitter with an error bounded by 10 degrees in both indoor and outdoor environments. As our goal was to build an end-to-end system for direction finding with the raw I/Q data, we do not explicitly model the multi-path that inevitably arises in such situations and neither do we hand engineer features to mitigate the problems arising out of the same. Since the characteristics of a transmitter's I/Q data does not change in response to changes in the modulation schemes, the proposed approach has the ability to find the direction of specific emitters in-spite of changes to their modulation scheme.},
booktitle = {Proceedings of the 2020 the 4th International Conference on Information System and Data Mining},
pages = {6–13},
numpages = {8},
keywords = {Software Radio, Deep Learning, Direction Finding, Neural Networks},
location = {Hawaii, HI, USA},
series = {ICISDM 2020}
}

@inproceedings{10.1145/3474198.3478163,
author = {Huang, Xu and Liu, Jiarun and Long, Han and Gong, Qinghai and Zhong, Honghao},
title = {DDPG with Multiple Data Frames for Robust UAV Attitude Control},
year = {2021},
isbn = {9781450390149},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3474198.3478163},
doi = {10.1145/3474198.3478163},
abstract = {In this paper, a robust attitude control method for unmanned aerial vehicle (UAV) based on the Deep Deterministic Policy Gradient (DDPG) algorithm is studied. In the Markov Decision Process, multi-step angle of attack, pitch rate and differential angle of attack information are taken as the environment state, and a reward function with sparse reward is designed. As well as uncertain state transition increases the uncertainty of the environment during agent training which can make the agent adapt to the control task under different aerodynamic coefficients so as to improve the robustness of the agent. The results show that after a certain number of training episodes, the agent can not only effectively improve the dynamic process and steady-state performance of the system, but also owns strong robustness, that is, it has good control performance for the system with different aerodynamic coefficients.},
booktitle = {International Conference on Frontiers of Electronics, Information and Computation Technologies},
articleno = {7},
numpages = {5},
keywords = {UAV, uncertain state transition, DDPG, robust attitude control},
location = {Changsha, China},
series = {ICFEICT 2021}
}

@inproceedings{10.1145/3390557.3394306,
author = {Zhi, Wang and Zhang-song, Shi and Wen-bin, Gong and Zhong-hong, Wu},
title = {Research on a Miss Distance Measurement Method Based on UAV},
year = {2020},
isbn = {9781450376587},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3390557.3394306},
doi = {10.1145/3390557.3394306},
abstract = {In order to more intuitively and effectively evaluate the effects of shooting tests and overcome the shortcomings of traditional visualization methods under the background of intelligent construction, this paper proposes a method for miss distance measurement based on Unmanned Aerial Vehicle (UAV). Three aspects of target detection and tracking, water column detection and tracking and miss distance measurement are analyzed and studied, and the effectiveness of miss distance detection method is verified by measured video images.},
booktitle = {Proceedings of the 2020 the 4th International Conference on Innovation in Artificial Intelligence},
pages = {95–99},
numpages = {5},
keywords = {KCF, Detection and tracking, Image segmentation, UAV, Error analysis, Miss distance measurement},
location = {Xiamen, China},
series = {ICIAI 2020}
}

@inproceedings{10.1145/3414045.3415940,
author = {Wang, Xiaoding and Hu, Jia and Lin, Hui},
title = {An Intelligent UAV Based Data Aggregation Strategy for IoT after Disaster Scenarios},
year = {2020},
isbn = {9781450381055},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3414045.3415940},
doi = {10.1145/3414045.3415940},
abstract = {The study on data aggregation in Internet of Things (IoT) has drawn a great attention in recent years. Since a large-scale disaster could damage the entire communication network and cut off data aggregation completely, an Intelligent UAV based Data Aggregation Strategy, named (IDAS), is proposed for after disaster scenarios in IoT. Specifically, IDAS first employs an task distribution mechanism to achieve the trade-off between the aggregation ratio and the energy cost. Then, a deep reinforcement learning method is developed for UAV route design to perform corresponding task. Thus, all data are aggregated toward the rescue headquarter by UAV deployment. The simulation results indicate that IDAS has a higher aggregation ratio and a lower energy cost while compared with contemporary strategies.},
booktitle = {Proceedings of the 2nd ACM MobiCom Workshop on Drone Assisted Wireless Communications for 5G and Beyond},
pages = {97–101},
numpages = {5},
keywords = {deep reinforcement learning, IoT, data aggregation, UAV},
location = {London, United Kingdom},
series = {DroneCom '20}
}

@inbook{10.1145/3483207.3483221,
author = {Liu, Jue and Yang, Weiwei and Tao, Liwei and Liu, Jun and Zhang, Qianqian},
title = {Secure UAV Communication Under Cooperative Adaptive Eavesdroppers with Incomplete Information},
year = {2021},
isbn = {9781450390170},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3483207.3483221},
abstract = {The adaptive eavesdroppers (AEs) bring more serious attacks and exacerbate the uncertainty of wireless communication due to their adaptivity of acting as either passive eavesdroppers or active jammer by learning the communication environment. In this paper, we investigate secure unmanned aerial vehicle communication under multiple cooperative AEs with incomplete information. A hierarchical game framework based on observation accuracies and channel estimation coefficients is proposed, in which a cooperative attack game (CAG) is modeled to get the optimal joint attack action of multiple AEs by proving CAG is an exact potential game and a Stackelberg game is applied to derive the aerial base station's (ABS's) optimal position according to AEs’ strategies. Then, a hierarchical learning algorithm is proposed to search the ABS's optimal position for enhancing the secrecy rate under the cooperative AEs. Finally, the simulation results validate the effectiveness of the proposed hierarchical game framework.},
booktitle = {2021 4th International Conference on Signal Processing and Machine Learning},
pages = {82–88},
numpages = {7}
}

@inproceedings{10.1145/3297280.3297373,
author = {Lima, Rolif and Das, Kaushik and Ghose, Debasish},
title = {Support Vector Regression Based Sensor Localization Using UAV},
year = {2019},
isbn = {9781450359337},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi-org.ez294.periodicos.capes.gov.br/10.1145/3297280.3297373},
doi = {10.1145/3297280.3297373},
abstract = {In this work, we focus on localization of a beacon which is a source of radio frequency (RF) signal using a single unmanned aerial vehicle (UAV). We propose to use the Support Vector Regression (SVR) technique to directly localize the sensor by using the received signal strength (RSS) of the RF signal as the input. A systematic method to collect the samples of the RSS values followed by the filtering techniques to process the noise in the RSS measurements as well as the estimate of the sensor position are presented. Pure pursuit guidance law is used to guide the UAV to the estimated sensor location. The algorithm is tested by means of simulations, where it was shown to estimate the position within 2 m accuracy.},
booktitle = {Proceedings of the 34th ACM/SIGAPP Symposium on Applied Computing},
pages = {938–945},
numpages = {8},
keywords = {support vector regression, received signal strength, localization},
location = {Limassol, Cyprus},
series = {SAC '19}
}



@Article{agronomy12010183,
AUTHOR = {Denora, Michele and Fiorentini, Marco and Zenobi, Stefano and Deligios, Paola A. and Orsini, Roberto and Ledda, Luigi and Perniola, Michele},
TITLE = {Validation of Rapid and Low-Cost Approach for the Delineation of Zone Management Based on Machine Learning Algorithms},
JOURNAL = {Agronomy},
VOLUME = {12},
YEAR = {2022},
NUMBER = {1},
ARTICLE-NUMBER = {183},
URL = {https://www.mdpi.com/2073-4395/12/1/183},
ISSN = {2073-4395},
ABSTRACT = {Proximal soil sensors are receiving strong attention from several disciplinary fields, and this has led to a rise in their availability in the market in the last two decades. The aim of this work was to validate agronomically a zone management delineation procedure from electromagnetic induction (EMI) maps applied to two different rainfed durum wheat fields. The k-means algorithm was applied based on the gap statistic index for the identification of the optimal number of management zones and their positions. Traditional statistical analysis was performed to detect significant differences in soil characteristics and crop response of each management zones. The procedure showed the presence of two management zones at both two sites under analysis, and it was agronomically validated by the significant difference in soil texture (+24.17%), bulk density (+6.46%), organic matter (+39.29%), organic carbon (+39.4%), total carbonates (+25.34%), total nitrogen (+30.14%), protein (+1.50%) and yield data (+1.07 t ha&minus;1). Moreover, six unmanned aerial vehicle (UAV) flight missions were performed to investigate the relationship between five vegetation indexes and the EMI maps. The results suggest performing the multispectral images acquisition during the flowering phenological stages to attribute the crop spatial variability to different soil proprieties.},
DOI = {10.3390/agronomy12010183}
}



@Article{drones6010021,
AUTHOR = {Zhang, Ruohao and Condomines, Jean-Philippe and Lochin, Emmanuel},
TITLE = {A Multifractal Analysis and Machine Learning Based Intrusion Detection System with an Application in a UAS/RADAR System},
JOURNAL = {Drones},
VOLUME = {6},
YEAR = {2022},
NUMBER = {1},
ARTICLE-NUMBER = {21},
URL = {https://www.mdpi.com/2504-446X/6/1/21},
ISSN = {2504-446X},
ABSTRACT = {The rapid development of Internet of Things (IoT) technology, together with mobile network technology, has created a never-before-seen world of interconnection, evoking research on how to make it vaster, faster, and safer. To support the ongoing fight against the malicious misuse of networks, in this paper we propose a novel algorithm called AMDES (unmanned aerial system multifractal analysis intrusion detection system) for spoofing attack detection. This novel algorithm is based on both wavelet leader multifractal analysis (WLM) and machine learning (ML) principles. In earlier research on unmanned aerial systems (UAS), intrusion detection systems (IDS) based on multifractal (MF) spectral analysis have been used to provide accurate MF spectrum estimations of network traffic. Such an estimation is then used to detect and characterize flooding anomalies that can be observed in an unmanned aerial vehicle (UAV) network. However, the previous contributions have lacked the consideration of other types of network intrusions commonly observed in UAS networks, such as the man in the middle attack (MITM). In this work, this promising methodology has been accommodated to detect a spoofing attack within a UAS. This methodology highlights a robust approach in terms of false positive performance in detecting intrusions in a UAS location reporting system.},
DOI = {10.3390/drones6010021}
}



@Article{rs14020349,
AUTHOR = {Abdi, Omid and Uusitalo, Jori and Kivinen, Veli-Pekka},
TITLE = {Logging Trail Segmentation via a Novel U-Net Convolutional Neural Network and High-Density Laser Scanning Data},
JOURNAL = {Remote Sensing},
VOLUME = {14},
YEAR = {2022},
NUMBER = {2},
ARTICLE-NUMBER = {349},
URL = {https://www.mdpi.com/2072-4292/14/2/349},
ISSN = {2072-4292},
ABSTRACT = {Logging trails are one of the main components of modern forestry. However, spotting the accurate locations of old logging trails through common approaches is challenging and time consuming. This study was established to develop an approach, using cutting-edge deep-learning convolutional neural networks and high-density laser scanning data, to detect logging trails in different stages of commercial thinning, in Southern Finland. We constructed a U-Net architecture, consisting of encoder and decoder paths with several convolutional layers, pooling and non-linear operations. The canopy height model (CHM), digital surface model (DSM), and digital elevation models (DEMs) were derived from the laser scanning data and were used as image datasets for training the model. The labeled dataset for the logging trails was generated from different references as well. Three forest areas were selected to test the efficiency of the algorithm that was developed for detecting logging trails. We designed 21 routes, including 390 samples of the logging trails and non-logging trails, covering all logging trails inside the stands. The results indicated that the trained U-Net using DSM (k = 0.846 and IoU = 0.867) shows superior performance over the trained model using CHM (k = 0.734 and IoU = 0.782), DEMavg (k = 0.542 and IoU = 0.667), and DEMmin (k = 0.136 and IoU = 0.155) in distinguishing logging trails from non-logging trails. Although the efficiency of the developed approach in young and mature stands that had undergone the commercial thinning is approximately perfect, it needs to be improved in old stands that have not received the second or third commercial thinning.},
DOI = {10.3390/rs14020349}
}



@Article{rs14020353,
AUTHOR = {Ruan, Mengying and Hu, Zhenqi and Duan, Xinyi and Zhou, Tao and Nie, Xinran},
TITLE = {Using UAV and Field Measurement Technology to Monitor the Impact of Coal Gangue Pile Temperature on Vegetation Ecological Construction},
JOURNAL = {Remote Sensing},
VOLUME = {14},
YEAR = {2022},
NUMBER = {2},
ARTICLE-NUMBER = {353},
URL = {https://www.mdpi.com/2072-4292/14/2/353},
ISSN = {2072-4292},
ABSTRACT = {Coal gangue is an inevitable product in coal mining and processing and is the most important source of pollution in mines. Vegetation restoration of coal gangue piles must consider its special site conditions. Therefore, we conducted unmanned air vehicle (UAV) temperature monitoring, field investigation and experimental analysis on spontaneous combustion coal gangue piles in Lu&rsquo;an mining area. In the vegetation construction of coal gangue piles, high-temperature stress affects plant survival. The spontaneous combustion coal gangue piles have abnormal temperature, high surface temperature and few vegetation types. The plant community species diversity index (Shannon&ndash;Wiener index, Pielou&rsquo;s index and Species abundance index) is small, the plant community is single and the plant diversity is low. Spontaneous combustion of coal gangue leads to soil acidification, reducing soil water content, soil organic carbon (SOM), available nitrogen (AN), available potassium (AK) and available phosphorus (AP). These factors are single or interactive in plants and have an impact on plant survival and growth. The research results are of great significance to the vegetation restoration of spontaneous combustion coal gangue piles, ecological reconstruction and the improvement of the ecological environment of coal mine areas.},
DOI = {10.3390/rs14020353}
}



@Article{s22020601,
AUTHOR = {Sharma, Prakriti and Leigh, Larry and Chang, Jiyul and Maimaitijiang, Maitiniyazi and Caffé, Melanie},
TITLE = {Above-Ground Biomass Estimation in Oats Using UAV Remote Sensing and Machine Learning},
JOURNAL = {Sensors},
VOLUME = {22},
YEAR = {2022},
NUMBER = {2},
ARTICLE-NUMBER = {601},
URL = {https://www.mdpi.com/1424-8220/22/2/601},
ISSN = {1424-8220},
ABSTRACT = {Current strategies for phenotyping above-ground biomass in field breeding nurseries demand significant investment in both time and labor. Unmanned aerial vehicles (UAV) can be used to derive vegetation indices (VIs) with high throughput and could provide an efficient way to predict forage yield with high accuracy. The main objective of the study is to investigate the potential of UAV-based multispectral data and machine learning approaches in the estimation of oat biomass. UAV equipped with a multispectral sensor was flown over three experimental oat fields in Volga, South Shore, and Beresford, South Dakota, USA, throughout the pre- and post-heading growth phases of oats in 2019. A variety of vegetation indices (VIs) derived from UAV-based multispectral imagery were employed to build oat biomass estimation models using four machine-learning algorithms: partial least squares (PLS), support vector machine (SVM), Artificial neural network (ANN), and random forest (RF). The results showed that several VIs derived from the UAV collected images were significantly positively correlated with dry biomass for Volga and Beresford (r = 0.2&ndash;0.65), however, in South Shore, VIs were either not significantly or weakly correlated with biomass. For Beresford, approximately 70% of the variance was explained by PLS, RF, and SVM validation models using data collected during the post-heading phase. Likewise for Volga, validation models had lower coefficient of determination (R2 = 0.20&ndash;0.25) and higher error (RMSE = 700&ndash;800 kg/ha) than training models (R2 = 0.50&ndash;0.60; RMSE = 500&ndash;690 kg/ha). In South Shore, validation models were only able to explain approx. 15&ndash;20% of the variation in biomass, which is possibly due to the insignificant correlation values between VIs and biomass. Overall, this study indicates that airborne remote sensing with machine learning has potential for above-ground biomass estimation in oat breeding nurseries. The main limitation was inconsistent accuracy in model prediction across locations. Multiple-year spectral data, along with the inclusion of textural features like crop surface model (CSM) derived height and volumetric indicators, should be considered in future studies while estimating biophysical parameters like biomass.},
DOI = {10.3390/s22020601}
}



@Article{app12020826,
AUTHOR = {Yuan, Jing and Yu, Bo and Yan, Changxiang and Zhang, Junqiang and Ding, Ning and Dong, Youzhi},
TITLE = {Strategies for the Efficient Estimation of Soil Moisture through Spectroscopy: Sensitive Wavelength Algorithm, Spectral Resampling and Signal-to-Noise Ratio Selection},
JOURNAL = {Applied Sciences},
VOLUME = {12},
YEAR = {2022},
NUMBER = {2},
ARTICLE-NUMBER = {826},
URL = {https://www.mdpi.com/2076-3417/12/2/826},
ISSN = {2076-3417},
ABSTRACT = {It is found that the remote sensing parameters such as spectral range, spectral resolution and signal-to-noise ratio directly affect the estimation accuracy of soil moisture content. However, the lack of research on the relationship between the parameters and estimation accuracy restricts the prolongation of application. Therefore, this study took the demand for this application as the foothold for developing spectrometry. Firstly, a method based on sensitivity analysis of soil radiative transfer model-successive projection algorithm (SA-SPA) was proposed to select sensitive wavelengths. Then, the spectral resampling method was used to select the best spectral resolution in the corresponding sensitive wavelengths. Finally, the noise-free spectral data simulated by the soil radiative transfer model was added with Gaussian random noise to change the signal-to-noise ratio, so as to explore the influence of signal-to-noise ratio on the estimation accuracy. The research results show that the estimation accuracy obtained through the SA-SPA (RMSEP &lt; 12.1 g kg&minus;1) is generally superior to that from full-spectrum data (RMSEP &lt; 14 g kg&minus;1). At selected sensitive wavelengths, the best spectral resolution is 34 nm, and the applicable signal-to-noise ratio ranges from 150 to 350. This study provides technical support for the efficient estimation of soil moisture content and the development of spectrometry, which comprehensively considers the common influence of spectral range, spectral resolution and signal-to-noise ratio on the estimation accuracy of soil moisture content.},
DOI = {10.3390/app12020826}
}



@Article{rs14020380,
AUTHOR = {Putzenlechner, Birgitta and Marzahn, Philip and Koal, Philipp and Sánchez-Azofeifa, Arturo},
TITLE = {Fractional Vegetation Cover Derived from UAV and Sentinel-2 Imagery as a Proxy for In Situ FAPAR in a Dense Mixed-Coniferous Forest?},
JOURNAL = {Remote Sensing},
VOLUME = {14},
YEAR = {2022},
NUMBER = {2},
ARTICLE-NUMBER = {380},
URL = {https://www.mdpi.com/2072-4292/14/2/380},
ISSN = {2072-4292},
ABSTRACT = {The fraction of absorbed photosynthetic active radiation (FAPAR) is an essential climate variable for assessing the productivity of ecosystems. Satellite remote sensing provides spatially distributed FAPAR products, but their accurate and efficient validation is challenging in forest environments. As the FAPAR is linked to the canopy structure, it may be approximated by the fractional vegetation cover (FCOVER) under the assumption that incoming radiation is either absorbed or passed through gaps in the canopy. With FCOVER being easier to retrieve, FAPAR validation activities could benefit from a priori information on FCOVER. Spatially distributed FCOVER is available from satellite remote sensing or can be retrieved from imagery of Unmanned Aerial Vehicles (UAVs) at a centimetric resolution. We investigated remote sensing-derived FCOVER as a proxy for in situ FAPAR in a dense mixed-coniferous forest, considering both absolute values and spatiotemporal variability. Therefore, direct FAPAR measurements, acquired with a Wireless Sensor Network, were related to FCOVER derived from UAV and Sentinel-2 (S2) imagery at different seasons. The results indicated that spatially aggregated UAV-derived FCOVER was close (RMSE = 0.02) to in situ FAPAR during the peak vegetation period when the canopy was almost closed. The S2 FCOVER product underestimated both the in situ FAPAR and UAV-derived FCOVER (RMSE &gt; 0.3), which we attributed to the generic nature of the retrieval algorithm and the coarser resolution of the product. We concluded that UAV-derived FCOVER may be used as a proxy for direct FAPAR measurements in dense canopies. As another key finding, the spatial variability of the FCOVER consistently surpassed that of the in situ FAPAR, which was also well-reflected in the S2 FAPAR and FCOVER products. We recommend integrating this experimental finding as consistency criteria in the context of ECV quality assessments. To facilitate the FAPAR sampling activities, we further suggest assessing the spatial variability of UAV-derived FCOVER to benchmark sampling sizes for in situ FAPAR measurements. Finally, our study contributes to refining the FAPAR sampling protocols needed for the validation and improvement of FAPAR estimates in forest environments.},
DOI = {10.3390/rs14020380}
}



@Article{quat5010005,
AUTHOR = {Howland, Matthew D. and Tamberino, Anthony and Liritzis, Ioannis and Levy, Thomas E.},
TITLE = {Digital Deforestation: Comparing Automated Approaches to the Production of Digital Terrain Models (DTMs) in Agisoft Metashape},
JOURNAL = {Quaternary},
VOLUME = {5},
YEAR = {2022},
NUMBER = {1},
ARTICLE-NUMBER = {5},
URL = {https://www.mdpi.com/2571-550X/5/1/5},
ISSN = {2571-550X},
ABSTRACT = {This paper tests the suitability of automated point cloud classification tools provided by the popular image-based modeling (IBM) software package Agisoft Metashape for the generation of digital terrain models (DTMs) at moderately-vegetated archaeological sites. DTMs are often required for various forms of archaeological mapping and analysis. The suite of tools provided by Agisoft are relatively user-friendly as compared to many point cloud classification algorithms and do not require the use of additional software. Based on a case study from the Mycenaean site of Kastrouli, Greece, the mostly-automated, geometric classification tool &ldquo;Classify Ground Points&rdquo; provides the best results and produces a quality DTM that is sufficient for mapping and analysis. Each of the methods tested in this paper can likely be improved through manual editing of point cloud classification.},
DOI = {10.3390/quat5010005}
}



@Article{agronomy12010202,
AUTHOR = {Li, Zongpeng and Chen, Zhen and Cheng, Qian and Duan, Fuyi and Sui, Ruixiu and Huang, Xiuqiao and Xu, Honggang},
TITLE = {UAV-Based Hyperspectral and Ensemble Machine Learning for Predicting Yield in Winter Wheat},
JOURNAL = {Agronomy},
VOLUME = {12},
YEAR = {2022},
NUMBER = {1},
ARTICLE-NUMBER = {202},
URL = {https://www.mdpi.com/2073-4395/12/1/202},
ISSN = {2073-4395},
ABSTRACT = {Winter wheat is a widely-grown cereal crop worldwide. Using growth-stage information to estimate winter wheat yields in a timely manner is essential for accurate crop management and rapid decision-making in sustainable agriculture, and to increase productivity while reducing environmental impact. UAV remote sensing is widely used in precision agriculture due to its flexibility and increased spatial and spectral resolution. Hyperspectral data are used to model crop traits because of their ability to provide continuous rich spectral information and higher spectral fidelity. In this study, hyperspectral image data of the winter wheat crop canopy at the flowering and grain-filling stages was acquired by a low-altitude unmanned aerial vehicle (UAV), and machine learning was used to predict winter wheat yields. Specifically, a large number of spectral indices were extracted from the spectral data, and three feature selection methods, recursive feature elimination (RFE), Boruta feature selection, and the Pearson correlation coefficient (PCC), were used to filter high spectral indices in order to reduce the dimensionality of the data. Four major basic learner models, (1) support vector machine (SVM), (2) Gaussian process (GP), (3) linear ridge regression (LRR), and (4) random forest (RF), were also constructed, and an ensemble machine learning model was developed by combining the four base learner models. The results showed that the SVM yield prediction model, constructed on the basis of the preferred features, performed the best among the base learner models, with an R2 between 0.62 and 0.73. The accuracy of the proposed ensemble learner model was higher than that of each base learner model; moreover, the R2 (0.78) for the yield prediction model based on Boruta&rsquo;s preferred characteristics was the highest at the grain-filling stage.},
DOI = {10.3390/agronomy12010202}
}



@Article{s22020662,
AUTHOR = {Talaei Khoei, Tala and Ismail, Shereen and Kaabouch, Naima},
TITLE = {Dynamic Selection Techniques for Detecting GPS Spoofing Attacks on UAVs},
JOURNAL = {Sensors},
VOLUME = {22},
YEAR = {2022},
NUMBER = {2},
ARTICLE-NUMBER = {662},
URL = {https://www.mdpi.com/1424-8220/22/2/662},
ISSN = {1424-8220},
ABSTRACT = {Unmanned aerial vehicles are prone to several cyber-attacks, including Global Positioning System spoofing. Several techniques have been proposed for detecting such attacks. However, the recurrence and frequent Global Positioning System spoofing incidents show a need for effective security solutions to protect unmanned aerial vehicles. In this paper, we propose two dynamic selection techniques, Metric Optimized Dynamic selector and Weighted Metric Optimized Dynamic selector, which identify the most effective classifier for the detection of such attacks. We develop a one-stage ensemble feature selection method to identify and discard the correlated and low importance features from the dataset. We implement the proposed techniques using ten machine-learning models and compare their performance in terms of four evaluation metrics: accuracy, probability of detection, probability of false alarm, probability of misdetection, and processing time. The proposed techniques dynamically choose the classifier with the best results for detecting attacks. The results indicate that the proposed dynamic techniques outperform the existing ensemble models with an accuracy of 99.6%, a probability of detection of 98.9%, a probability of false alarm of 1.56%, a probability of misdetection of 1.09%, and a processing time of 1.24 s.},
DOI = {10.3390/s22020662}
}



@Article{rs14020396,
AUTHOR = {Shi, Yue and Han, Liangxiu and Kleerekoper, Anthony and Chang, Sheng and Hu, Tongle},
TITLE = {Novel CropdocNet Model for Automated Potato Late Blight Disease Detection from Unmanned Aerial Vehicle-Based Hyperspectral Imagery},
JOURNAL = {Remote Sensing},
VOLUME = {14},
YEAR = {2022},
NUMBER = {2},
ARTICLE-NUMBER = {396},
URL = {https://www.mdpi.com/2072-4292/14/2/396},
ISSN = {2072-4292},
ABSTRACT = {The accurate and automated diagnosis of potato late blight disease, one of the most destructive potato diseases, is critical for precision agricultural control and management. Recent advances in remote sensing and deep learning offer the opportunity to address this challenge. This study proposes a novel end-to-end deep learning model (CropdocNet) for accurate and automated late blight disease diagnosis from UAV-based hyperspectral imagery. The proposed method considers the potential disease-specific reflectance radiation variance caused by the canopy&rsquo;s structural diversity and introduces multiple capsule layers to model the part-to-whole relationship between spectral&ndash;spatial features and the target classes to represent the rotation invariance of the target classes in the feature space. We evaluate the proposed method with real UAV-based HSI data under controlled and natural field conditions. The effectiveness of the hierarchical features is quantitatively assessed and compared with the existing representative machine learning/deep learning methods on both testing and independent datasets. The experimental results show that the proposed model significantly improves accuracy when considering the hierarchical structure of spectral&ndash;spatial features, with average accuracies of 98.09% for the testing dataset and 95.75% for the independent dataset, respectively.},
DOI = {10.3390/rs14020396}
}



@Article{rs14020397,
AUTHOR = {Zhang, Fangfang and Wang, Changkun and Pan, Kai and Guo, Zhiying and Liu, Jie and Xu, Aiai and Ma, Haiyi and Pan, Xianzhang},
TITLE = {The Simultaneous Prediction of Soil Properties and Vegetation Coverage from Vis-NIR Hyperspectral Data with a One-Dimensional Convolutional Neural Network: A Laboratory Simulation Study},
JOURNAL = {Remote Sensing},
VOLUME = {14},
YEAR = {2022},
NUMBER = {2},
ARTICLE-NUMBER = {397},
URL = {https://www.mdpi.com/2072-4292/14/2/397},
ISSN = {2072-4292},
ABSTRACT = {Remote sensing of land surface mostly obtains a mixture of spectral information of soil and vegetation. It is thus of great value if soil and vegetation information can be acquired simultaneously from one model. In this study, we designed a laboratory experiment to simulate land surface compositions, including various soil types with varying soil moisture and vegetation coverage. A model of a one-dimensional convolutional neural network (1DCNN) was established to simultaneously estimate soil properties (organic matter, soil moisture, clay, and sand) and vegetation coverage based on the hyperspectral data measured in the experiment. The results showed that the model achieved excellent predictions for soil properties (R2 = 0.88&ndash;0.91, RPIQ = 4.01&ndash;5.78) and vegetation coverage (R2 = 0.95, RPIQ = 7.75). Compared with the partial least-squares regression (PLSR), the prediction accuracy of 1DCNN improved 42.20%, 45.82%, 43.32%, and 36.46% in terms of the root-mean-squared error (RMSE) for predicting soil organic matter, sand, clay, and soil moisture, respectively. The improvement might be caused by the fact that the spectral preprocessing and spectral features useful for predicting soil properties were successfully identified in the 1DCNN model. For the prediction of vegetation coverage, although the prediction accuracy by 1DCNN was excellent, its performance (R2 = 0.95, RPIQ = 7.75, RMSE = 3.92%) was lower than the PLSR model (R2 = 0.98, RPIQ = 12.57, RMSE = 2.41%). These results indicate that 1DCNN can simultaneously predict soil properties and vegetation coverage. However, the factors such as surface roughness and vegetation type that could affect the prediction accuracy should be investigated in the future.},
DOI = {10.3390/rs14020397}
}



@Article{en15020614,
AUTHOR = {Ding, Zhenhuan and Huang, Xiaoge and Liu, Zhao},
TITLE = {Active Exploration by Chance-Constrained Optimization for Voltage Regulation with Reinforcement Learning},
JOURNAL = {Energies},
VOLUME = {15},
YEAR = {2022},
NUMBER = {2},
ARTICLE-NUMBER = {614},
URL = {https://www.mdpi.com/1996-1073/15/2/614},
ISSN = {1996-1073},
ABSTRACT = {Voltage regulation in distribution networks encounters a challenge of handling uncertainties caused by the high penetration of photovoltaics (PV). This research proposes an active exploration (AE) method based on reinforcement learning (RL) to respond to the uncertainties by regulating the voltage of a distribution network with battery energy storage systems (BESS). The proposed method integrates engineering knowledge to accelerate the training process of RL. The engineering knowledge is the chance-constrained optimization. We formulate the problem in a chance-constrained optimization with a linear load flow approximation. The optimization results are used to guide the action selection of the exploration for improving training efficiency and reducing the conserveness characteristic. The comparison of methods focuses on how BESSs are used, training efficiency, and robustness under varying uncertainties and BESS sizes. We implement the proposed algorithm, a chance-constrained optimization, and a traditional Q-learning in the IEEE 13 Node Test Feeder. Our evaluation shows that the proposed AE method has a better response to the training efficiency compared to traditional Q-learning. Meanwhile, the proposed method has advantages in BESS usage in conserveness compared to the chance-constrained optimization.},
DOI = {10.3390/en15020614}
}



@Article{biology11010149,
AUTHOR = {Paux, Etienne and Lafarge, Stéphane and Balfourier, François and Derory, Jérémy and Charmet, Gilles and Alaux, Michael and Perchet, Geoffrey and Bondoux, Marion and Baret, Frédéric and Barillot, Romain and Ravel, Catherine and Sourdille, Pierre and Le Gouis, Jacques and on behalf of the BREEDWHEAT Consortium},
TITLE = {Breeding for Economically and Environmentally Sustainable Wheat Varieties: An Integrated Approach from Genomics to Selection},
JOURNAL = {Biology},
VOLUME = {11},
YEAR = {2022},
NUMBER = {1},
ARTICLE-NUMBER = {149},
URL = {https://www.mdpi.com/2079-7737/11/1/149},
ISSN = {2079-7737},
ABSTRACT = {There is currently a strong societal demand for sustainability, quality, and safety in bread wheat production. To address these challenges, new and innovative knowledge, resources, tools, and methods to facilitate breeding are needed. This starts with the development of high throughput genomic tools including single nucleotide polymorphism (SNP) arrays, high density molecular marker maps, and full genome sequences. Such powerful tools are essential to perform genome-wide association studies (GWAS), to implement genomic and phenomic selection, and to characterize the worldwide diversity. This is also useful to breeders to broaden the genetic basis of elite varieties through the introduction of novel sources of genetic diversity. Improvement in varieties particularly relies on the detection of genomic regions involved in agronomical traits including tolerance to biotic (diseases and pests) and abiotic (drought, nutrient deficiency, high temperature) stresses. When enough resolution is achieved, this can result in the identification of candidate genes that could further be characterized to identify relevant alleles. Breeding must also now be approached through in silico modeling to simulate plant development, investigate genotype &times; environment interactions, and introduce marker&ndash;trait linkage information in the models to better implement genomic selection. Breeders must be aware of new developments and the information must be made available to the world wheat community to develop new high-yielding varieties that can meet the challenge of higher wheat production in a sustainable and fluctuating agricultural context. In this review, we compiled all knowledge and tools produced during the BREEDWHEAT project to show how they may contribute to face this challenge in the coming years.},
DOI = {10.3390/biology11010149}
}



@Article{rs14020415,
AUTHOR = {Ilniyaz, Osman and Kurban, Alishir and Du, Qingyun},
TITLE = {Leaf Area Index Estimation of Pergola-Trained Vineyards in Arid Regions Based on UAV RGB and Multispectral Data Using Machine Learning Methods},
JOURNAL = {Remote Sensing},
VOLUME = {14},
YEAR = {2022},
NUMBER = {2},
ARTICLE-NUMBER = {415},
URL = {https://www.mdpi.com/2072-4292/14/2/415},
ISSN = {2072-4292},
ABSTRACT = {The leaf area index (LAI), a valuable variable for assessing vine vigor, reflects nutrient concentrations in vineyards and assists in precise management, including fertilization, improving yield, quality, and vineyard uniformity. Although some vegetation indices (VIs) have been successfully used to assess LAI variations, they are unsuitable for vineyards of different types and structures. By calibrating the light extinction coefficient of a digital photography algorithm for proximal LAI measurements, this study aimed to develop VI-LAI models for pergola-trained vineyards based on high-resolution RGB and multispectral images captured by an unmanned aerial vehicle (UAV). The models were developed by comparing five machine learning (ML) methods, and a robust ensemble model was proposed using the five models as base learners. The results showed that the ensemble model outperformed the base models. The highest R2 and lowest RMSE values that were obtained using the best combination of VIs with multispectral data were 0.899 and 0.434, respectively; those obtained using the RGB data were 0.825 and 0.547, respectively. By improving the results by feature selection, ML methods performed better with multispectral data than with RGB images, and better with higher spatial resolution data than with lower resolution data. LAI variations can be monitored efficiently and accurately for large areas of pergola-trained vineyards using this framework.},
DOI = {10.3390/rs14020415}
}



@Article{rs14020420,
AUTHOR = {Qi, Guanqiu and Zhang, Yuanchuan and Wang, Kunpeng and Mazur, Neal and Liu, Yang and Malaviya, Devanshi},
TITLE = {Small Object Detection Method Based on Adaptive Spatial Parallel Convolution and Fast Multi-Scale Fusion},
JOURNAL = {Remote Sensing},
VOLUME = {14},
YEAR = {2022},
NUMBER = {2},
ARTICLE-NUMBER = {420},
URL = {https://www.mdpi.com/2072-4292/14/2/420},
ISSN = {2072-4292},
ABSTRACT = {As one type of object detection, small object detection has been widely used in daily-life-related applications with many real-time requirements, such as autopilot and navigation. Although deep-learning-based object detection methods have achieved great success in recent years, they are not effective in small object detection and most of them cannot achieve real-time processing. Therefore, this paper proposes a single-stage small object detection network (SODNet) that integrates the specialized feature extraction and information fusion techniques. An adaptively spatial parallel convolution module (ASPConv) is proposed to alleviate the lack of spatial information for target objects and adaptively obtain the corresponding spatial information through multi-scale receptive fields, thereby improving the feature extraction ability. Additionally, a split-fusion sub-module (SF) is proposed to effectively reduce the time complexity of ASPConv. A fast multi-scale fusion module (FMF) is proposed to alleviate the insufficient fusion of both semantic and spatial information. FMF uses two fast upsampling operators to first unify the resolution of the multi-scale feature maps extracted by the network and then fuse them, thereby effectively improving the small object detection ability. Comparative experimental results prove that the proposed method considerably improves the accuracy of small object detection on multiple benchmark datasets and achieves a high real-time performance.},
DOI = {10.3390/rs14020420}
}



@Article{rs14020424,
AUTHOR = {He, Yibo and Hu, Zhenqi and Fu, Yaokun and Yang, Kun and Wang, Rui and Shi, Guomou and Feng, Zhanjie and Yang, Qirang and Yu, Liang},
TITLE = {Underground Morphological Detection of Ground Fissures in Collapsible Loess Area Based on Three-Dimensional Laser Scanning Technology},
JOURNAL = {Remote Sensing},
VOLUME = {14},
YEAR = {2022},
NUMBER = {2},
ARTICLE-NUMBER = {424},
URL = {https://www.mdpi.com/2072-4292/14/2/424},
ISSN = {2072-4292},
ABSTRACT = {Underground coal mining inevitably causes ground fissures, especially permanent cracks that cannot be closed at the boundary of the working face. Studying the underground three-dimensional morphology of the permanent cracks allows one to accurately constrain the formation and development of the ground fissures. This information will contribute to reducing mine disasters and is also a prerequisites to avoid environmental pollution. We selected the Zhangjiamao coal mine (China), which is situated in a collapsible loess area, as a case study for deciphering the formation of permanent cracks. After injecting gypsum slurry into the mine, a three-dimensional model of the ground fissures is obtained by three-dimensional (3D) laser scanner technology that records the 3D underground morphology. Integrating the geological context of a collapsible loess area, the characteristics and main processes of the ground fissure development are constrained: (1) The width of the ground fissure decreases to 0 with increasing depth and is strongly affected by the soil composition. (2) Along the vertical extension direction, the ground fissures are generally inclined to the inner-side of the working face, but the direction remains uncertain at different depths. (3) The transverse propagation direction of the ground fissure becomes more complex with increasing depth. (4) Under the influence of soil texture and water, loose soil fills the bottom of the ground fissure, thus affecting the underground 3D morphology.},
DOI = {10.3390/rs14020424}
}



@Article{agriculture12020124,
AUTHOR = {Song, Xiaoxin and Wu, Fei and Lu, Xiaotong and Yang, Tianle and Ju, Chengxin and Sun, Chengming and Liu, Tao},
TITLE = {The Classification of Farming Progress in Rice&ndash;Wheat Rotation Fields Based on UAV RGB Images and the Regional Mean Model},
JOURNAL = {Agriculture},
VOLUME = {12},
YEAR = {2022},
NUMBER = {2},
ARTICLE-NUMBER = {124},
URL = {https://www.mdpi.com/2077-0472/12/2/124},
ISSN = {2077-0472},
ABSTRACT = {Extraction of farming progress information in rice&ndash;wheat rotation regions is an important topic in smart field research. In this study, a new method for the classification of farming progress types using unmanned aerial vehicle (UAV) RGB images and the proposed regional mean (RM) model is presented. First, RGB information was extracted from the images to create and select the optimal color indices. After index classification, we compared the brightness reflection of the corresponding grayscale map, the classification interval, and the standard deviation of each farming progress type. These comparisons showed that the optimal classification color indices were the normalized red&ndash;blue difference index (NRBDI), the normalized green&ndash;blue difference index (NGBDI), and the modified red&ndash;blue difference index (MRBDI). Second, the RM model was built according to the whole-field farming progress classification requirements to achieve the final classification. We verified the model accuracy, and the Kappa coefficients obtained by combining the NRBDI, NGBDI, and MRBDI with the RM model were 0.86, 0.82, and 0.88, respectively. The proposed method was then applied to predict UAV RGB images of unharvested wheat, harvested wheat, and tilled and irrigated fields. The results were compared with those obtained with traditional machine learning methods, that is, the support vector machine, maximum likelihood classification, and random forest methods. The NRBDI, NGBDI, and MRBDI were combined with the RM model to monitor farming progress of ground truth ROIs, and the Kappa coefficients obtained were 0.9134, 0.8738, and 0.9179, respectively, while traditional machine learning methods all produced a Kappa coefficient less than 0.7. The results indicate a significantly higher accuracy of the proposed method than those of the traditional machine learning classification methods for the identification of farming progress type. The proposed work provides an important reference for the application of UAV to the field classification of progress types.},
DOI = {10.3390/agriculture12020124}
}



@Article{rs14030440,
AUTHOR = {Elkhrachy, Ismail},
TITLE = {Flash Flood Water Depth Estimation Using SAR Images, Digital Elevation Models, and Machine Learning Algorithms},
JOURNAL = {Remote Sensing},
VOLUME = {14},
YEAR = {2022},
NUMBER = {3},
ARTICLE-NUMBER = {440},
URL = {https://www.mdpi.com/2072-4292/14/3/440},
ISSN = {2072-4292},
ABSTRACT = {In this article, the local spatial correlation of multiple remote sensing datasets, such as those from Sentinel-1, Sentinel-2, and digital surface models (DSMs), are linked to machine learning (ML) regression algorithms for flash floodwater depth retrieval. Edge detection filters are applied to remote sensing images to extract features that are used as independent features by ML algorithms to estimate flood depths. Data of dependent variables were obtained from the Hydrologic Engineering Center&rsquo;s River Analysis System (HEC-RAS 2D) simulation model, as applied to the New Cairo, Egypt, post-flash flood event from 24&ndash;26 April 2018. Gradient boosting regression (GBR), random forest regression (RFR), linear regression (LR), extreme gradient boosting regression (XGBR), multilayer perceptron neural network regression (MLPR), k-nearest neighbors regression (KNR), and support vector regression (SVR) were used to estimate floodwater depths; their outputs were compared and evaluated for accuracy using the root-mean-square error (RMSE). The RMSE accuracy for all ML algorithms was 0.18&ndash;0.22 m for depths less than 1 m (96% of all test data), indicating that ML models are relatively portable and capable of computing floodwater depths using remote sensing data as an input.},
DOI = {10.3390/rs14030440}
}



@Article{buildings12020090,
AUTHOR = {Na, Seunguk and Heo, Seokjae and Han, Sehee and Shin, Yoonsoo and Roh, Youngsook},
TITLE = {Acceptance Model of Artificial Intelligence (AI)-Based Technologies in Construction Firms: Applying the Technology Acceptance Model (TAM) in Combination with the Technology&ndash;Organisation&ndash;Environment (TOE) Framework},
JOURNAL = {Buildings},
VOLUME = {12},
YEAR = {2022},
NUMBER = {2},
ARTICLE-NUMBER = {90},
URL = {https://www.mdpi.com/2075-5309/12/2/90},
ISSN = {2075-5309},
ABSTRACT = {In the era of the Fourth Industrial Revolution, artificial intelligence (AI) is a core technology, and AI-based applications are expanding in various fields. This research explored the influencing factors on end-user&rsquo;s intentions and acceptance of AI-based technology in construction companies using the technology acceptance model (TAM) and technology&ndash;organisation&ndash;environment (TOE) framework. The analysis of end-users&rsquo; intentions for accepting AI-based technology was verified by applying the structure equation model. According to the research results, the technological factors along with external variables and an individual&rsquo;s personality had a positive influence (+) on the perceived usefulness and the perceived ease of use of end-users of AI-based technology. Conversely, environmental factors such as suggestions from others appeared to be disruptive to users&rsquo; technology acceptance. In order to effectively utilise AI-based technology, organisational factors such as the support, culture, and participation of the company as a whole were indicated as important factors for AI-based technology implementation.},
DOI = {10.3390/buildings12020090}
}



@Article{su14031139,
AUTHOR = {Feng, Lanbo and Xiao, Huashun and Yang, Zhigao and Zhang, Gui},
TITLE = {A Multiscale Normalization Method of a Mixed-Effects Model for Monitoring Forest Fires Using Multi-Sensor Data},
JOURNAL = {Sustainability},
VOLUME = {14},
YEAR = {2022},
NUMBER = {3},
ARTICLE-NUMBER = {1139},
URL = {https://www.mdpi.com/2071-1050/14/3/1139},
ISSN = {2071-1050},
ABSTRACT = {This paper points out the shortcomings of existing normalization methods, and proposes a brightness temperature inversion normalization method for multi-source remote sensing monitoring of forest fires. This method can satisfy both radiation normalization and observation angle normalization, and reduce the discrepancies in forest fire monitoring between multi-source sensors. The study was based on Himawari-8 data; the longitude, latitude, solar zenith angle, solar azimuth angle, emissivity, slope, aspect, elevation, and brightness temperature values were collected as modeling parameters. The mixed-effects brightness temperature inversion normalization (MEMN) model based on FY-4A and Himawari-8 satellite sensors is fitted by multiple stepwise regression and mixed-effects modeling methods. The results show that, when the model is tested by Himawari-8 data, the coefficient of determination (R2) reaches 0.8418, and when it is tested by FY-4A data, R2 reaches 0.8045. At the same time, through comparison and analysis, the accuracy of the MEMN method is higher than that of the random forest normalization method (RF) (R2=0.7318), the pseudo-invariant feature method (PIF) (R2=0.7264), and the automatic control scatter regression method (ASCR) (R2=0.6841). The MEMN model can not only reduce the discrepancies in forest fire monitoring owing to different satellite sensors between FY-4A and Himawari-8, but also improve the accuracy and timeliness of forest fire monitoring.},
DOI = {10.3390/su14031139}
}



@Article{app12031047,
AUTHOR = {Aslan, Muhammet Fatih and Durdu, Akif and Sabanci, Kadir and Ropelewska, Ewa and Gültekin, Seyfettin Sinan},
TITLE = {A Comprehensive Survey of the Recent Studies with UAV for Precision Agriculture in Open Fields and Greenhouses},
JOURNAL = {Applied Sciences},
VOLUME = {12},
YEAR = {2022},
NUMBER = {3},
ARTICLE-NUMBER = {1047},
URL = {https://www.mdpi.com/2076-3417/12/3/1047},
ISSN = {2076-3417},
ABSTRACT = {The increasing world population makes it necessary to fight challenges such as climate change and to realize production efficiently and quickly. However, the minimum cost, maximum income, environmental pollution protection and the ability to save water and energy are all factors that should be taken into account in this process. The use of information and communication technologies (ICTs) in agriculture to meet all of these criteria serves the purpose of precision agriculture. As unmanned aerial vehicles (UAVs) can easily obtain real-time data, they have a great potential to address and optimize solutions to the problems faced by agriculture. Despite some limitations, such as the battery, load, weather conditions, etc., UAVs will be used frequently in agriculture in the future because of the valuable data that they obtain and their efficient applications. According to the known literature, UAVs have been carrying out tasks such as spraying, monitoring, yield estimation, weed detection, etc. In recent years, articles related to agricultural UAVs have been presented in journals with high impact factors. Most precision agriculture applications with UAVs occur in outdoor environments where GPS access is available, which provides more reliable control of the UAV in both manual and autonomous flights. On the other hand, there are almost no UAV-based applications in greenhouses where all-season crop production is available. This paper emphasizes this deficiency and provides a comprehensive review of the use of UAVs for agricultural tasks and highlights the importance of simultaneous localization and mapping (SLAM) for a UAV solution in the greenhouse.},
DOI = {10.3390/app12031047}
}



@Article{rs14030477,
AUTHOR = {Carpenter, Stephen and Byfield, Val and Felgate, Stacey L. and Price, David M. and Andrade, Valdemar and Cobb, Eliceo and Strong, James and Lichtschlag, Anna and Brittain, Hannah and Barry, Christopher and Fitch, Alice and Young, Arlene and Sanders, Richard and Evans, Claire},
TITLE = {Using Unoccupied Aerial Vehicles (UAVs) to Map Seagrass Cover from Sentinel-2 Imagery},
JOURNAL = {Remote Sensing},
VOLUME = {14},
YEAR = {2022},
NUMBER = {3},
ARTICLE-NUMBER = {477},
URL = {https://www.mdpi.com/2072-4292/14/3/477},
ISSN = {2072-4292},
ABSTRACT = {Seagrass habitats are ecologically valuable and play an important role in sequestering and storing carbon. There is, thus, a need to estimate seagrass percentage cover in diverse environments in support of climate change mitigation, marine spatial planning and coastal zone management. In situ approaches are accurate but time-consuming, expensive and may not represent the larger spatial units collected by satellite imaging. Hence, there is a need for a consistent methodology that uses accurate point-based field surveys to deliver high-quality mapping of percentage seagrass cover at large spatial scales. Here, we develop a three-step approach that combines in situ (quadrats), aerial (unoccupied aerial vehicle&mdash;UAV) and satellite data to map percentage seagrass cover at Turneffe Atoll, Belize, the largest atoll in the northern hemisphere. First, the optical bands of four UAV images were used to calculate seagrass cover, in combination with in situ data. The seagrass cover calculated from the UAV was then used to develop training and validation datasets to estimate seagrass cover in Sentinel-2 pixels. Next, non-seagrass areas were identified in the Sentinel-2 data and removed by object-based classification, followed by a pixel-based regression to calculate seagrass percentage cover. Using this approach, percentage seagrass cover was mapped using UAVs (R2 = 0.91 between observed and mapped distributions) and using Sentinel-2 data (R2 = 0.73). This work provides the first openly available and explorable map of seagrass percentage cover across Turneffe Atoll, where we estimate approximately 242 km2 of seagrass above 10% cover is located. We estimate that this approach offers 30 times more data for training satellite data than traditional methods, therefore presenting a substantial reduction in cost-per-point for data. Furthermore, the increase in data helps deliver a high-quality seagrass cover map, suitable for resolving trends of deteriorating, stable or recovering seagrass environments at 10 m2 resolution to underpin evidence-based management and conservation of seagrass.},
DOI = {10.3390/rs14030477}
}



@Article{f13020153,
AUTHOR = {Krisanski, Sean and Taskhiri, Mohammad Sadegh and Montgomery, James and Turner, Paul},
TITLE = {Design and Testing of a Novel Unoccupied Aircraft System for the Collection of Forest Canopy Samples},
JOURNAL = {Forests},
VOLUME = {13},
YEAR = {2022},
NUMBER = {2},
ARTICLE-NUMBER = {153},
URL = {https://www.mdpi.com/1999-4907/13/2/153},
ISSN = {1999-4907},
ABSTRACT = {Unoccupied Aircraft Systems (UAS) are beginning to replace conventional forest plot mensuration through their use as low-cost and powerful remote sensing tools for monitoring growth, estimating biomass, evaluating carbon stocks and detecting weeds; however, physical samples remain mostly collected through time-consuming, expensive and potentially dangerous conventional techniques. Such conventional techniques include the use of arborists to climb the trees to retrieve samples, shooting branches with firearms from the ground, canopy cranes or the use of pole-mounted saws to access lower branches. UAS hold much potential to improve the safety, efficiency, and reduce the cost of acquiring canopy samples. In this work, we describe and demonstrate four iterations of 3D printed canopy sampling UAS. This work includes detailed explanations of designs and how each iteration informed the design decisions in the subsequent iteration. The fourth iteration of the aircraft was tested for the collection of 30 canopy samples from three tree species: eucalyptus pulchella, eucalyptus globulus and acacia dealbata trees. The collection times ranged from 1 min and 23 s, up to 3 min and 41 s for more distant and challenging to capture samples. A vision for the next iteration of this design is also provided. Future work may explore the integration of advanced remote sensing techniques with UAS-based canopy sampling to progress towards a fully-automated and holistic forest information capture system.},
DOI = {10.3390/f13020153}
}



@Article{rs14030480,
AUTHOR = {Price, David M. and Felgate, Stacey L. and Huvenne, Veerle A. I. and Strong, James and Carpenter, Stephen and Barry, Chris and Lichtschlag, Anna and Sanders, Richard and Carrias, Abel and Young, Arlene and Andrade, Valdemar and Cobb, Eliceo and Le Bas, Tim and Brittain, Hannah and Evans, Claire},
TITLE = {Quantifying the Intra-Habitat Variation of Seagrass Beds with Unoccupied Aerial Vehicles (UAVs)},
JOURNAL = {Remote Sensing},
VOLUME = {14},
YEAR = {2022},
NUMBER = {3},
ARTICLE-NUMBER = {480},
URL = {https://www.mdpi.com/2072-4292/14/3/480},
ISSN = {2072-4292},
ABSTRACT = {Accurate knowledge of the spatial extent of seagrass habitats is essential for monitoring and management purposes given their ecological and economic significance. Extent data are typically presented in binary (presence/absence) or arbitrary, semi-quantitative density bands derived from low-resolution satellite imagery, which cannot resolve fine-scale features and intra-habitat variability. Recent advances in consumer-grade unoccupied aerial vehicles (UAVs) have advanced our ability to survey large areas at higher resolution and at lower cost. This has improved the accessibility of mapping technologies to developing coastal nations, where a large proportion of the world&rsquo;s seagrass habitats are found. Here, we present the application of UAV-gathered imagery to determine seagrass habitat extent and percent of canopy cover. Four contrasting sites were surveyed in the Turneffe Atoll Marine Reserve, Belize, and seagrass canopy cover was ground truthed from in situ quadrats. Orthomosaic images were created for each site from the UAV-gathered imagery. Three modelling techniques were tested to extrapolate the findings from quadrats to spatial information, producing binary (random forest) and canopy cover (random forest regression and beta regression) habitat maps. The most robust model (random forest regression) had an average absolute error of 6.8&ndash;11.9% (SE of 8.2&ndash;14), building upon previous attempts at mapping seagrass density from satellite imagery, which achieved errors between 15&ndash;20% approximately. The resulting maps exhibited great intra-habitat heterogeneity and different levels of patchiness, which were attributed to site energetics and, possibly, species composition. The extra information in the canopy cover maps provides greater detail and information for key management decisions and provides the basis for future spatial studies and monitoring programmes.},
DOI = {10.3390/rs14030480}
}



@Article{data7020012,
AUTHOR = {Kharel, Tulsi P. and Ashworth, Amanda J. and Owens, Phillip R.},
TITLE = {Linking and Sharing Technology: Partnerships for Data Innovations for Management of Agricultural Big Data},
JOURNAL = {Data},
VOLUME = {7},
YEAR = {2022},
NUMBER = {2},
ARTICLE-NUMBER = {12},
URL = {https://www.mdpi.com/2306-5729/7/2/12},
ISSN = {2306-5729},
ABSTRACT = {Combining data into a centralized, searchable, and linked platform will provide a data exploration platform to agricultural stakeholders and researchers for better agricultural decision making, thus fully utilizing existing data and preventing redundant research. Such a data repository requires readiness to share data, knowledge, and skillsets and working with Big Data infrastructures. With the adoption of new technologies and increased data collection, agricultural workforces need to update their knowledge, skills, and abilities. The partnerships for data innovation (PDI) effort integrates agricultural data by efficiently capturing them from field, lab, and greenhouse studies using a variety of sensors, tools, and apps and provides a quick visualization and summary of statistics for real-time decision making. This paper aims to evaluate and provide examples of case studies currently using PDI and use its long-term continental US database (18 locations and 24 years) to test the cover crop and grazing effects on soil organic carbon (SOC) storage. The results show that legume and rye (Secale cereale L.) cover crops increased SOC storage by 36% and 50%, respectively, compared with oat (Avena sativa L.) and rye mixtures and low and high grazing intensities improving the upper SOC by 69&ndash;72% compared with a medium grazing intensity. This was likely due to legumes providing a more favorable substrate for SOC formation and high grazing intensity systems having continuous manure deposition. Overall, PDI can be used to democratize data regionally and nationally and therefore can address large-scale research questions aimed at addressing agricultural grand challenges.},
DOI = {10.3390/data7020012}
}



@Article{rs14030492,
AUTHOR = {Yang, Qichi and Wang, Lihui and Huang, Jinliang and Lu, Lijie and Li, Yang and Du, Yun and Ling, Feng},
TITLE = {Mapping Plant Diversity Based on Combined SENTINEL-1/2 Data&mdash;Opportunities for Subtropical Mountainous Forests},
JOURNAL = {Remote Sensing},
VOLUME = {14},
YEAR = {2022},
NUMBER = {3},
ARTICLE-NUMBER = {492},
URL = {https://www.mdpi.com/2072-4292/14/3/492},
ISSN = {2072-4292},
ABSTRACT = {Plant diversity is an important parameter in maintaining forest ecosystem services, functions and stability. Timely and accurate monitoring and evaluation of large-area wall-to-wall maps on plant diversity and its spatial heterogeneity are crucial for the conservation and management of forest resources. However, traditional botanical field surveys designed to estimate plant diversity are usually limited in their spatiotemporal resolutions. Using Sentinel-1 (S-1) and Sentinel-2 (S-2) data at high spatiotemporal scales, combined with and referenced to botanical field surveys, may be the best choice to provide accurate plant diversity distribution information over a large area. In this paper, we predicted and mapped plant diversity in a subtropical forest using 24 months of freely and openly available S-1 and S-2 images (10 m &times; 10 m) data over a large study area (15,290 km2). A total of 448 quadrats (10 m &times; 10 m) of forestry field surveys were captured in a subtropical evergreen-deciduous broad-leaved mixed forest to validate a machine learning algorithm. The objective was to link the fine Sentinel spectral and radar data to several ground-truthing plant diversity indices in the forests. The results showed that: (1) The Simpson and Shannon-Wiener diversity indices were the best predicted indices using random forest regression, with &#531;2 of around 0.65; (2) The use of S-1 radar data can enhance the accuracy of the predicted heterogeneity indices in the forests by approximately 0.2; (3) As for the mapping of Simpson and Shannon-Wiener, the overall accuracy was 67.4% and 64.2% respectively, while the texture diversity&rsquo;s overall accuracy was merely 56.8%; (4) From the evaluation and prediction map information, the Simpson, Shannon-Wiener and texture diversity values (and its confidence interval values) indicate spatial heterogeneity in pixel level. The large-area forest plant diversity indices maps add spatially explicit information to the ground-truthing data. Based on the results, we conclude that using the time-series of S-1 and S-2 radar and spectral characteristics, when coupled with limited ground-truthing data, can provide reasonable assessments of plant spatial heterogeneity and diversity across wide areas. It could also help promote forest ecosystem and resource conservation activities in the forestry sector.},
DOI = {10.3390/rs14030492}
}



@Article{rs14030518,
AUTHOR = {Brewer, Kiara and Clulow, Alistair and Sibanda, Mbulisi and Gokool, Shaeden and Naiken, Vivek and Mabhaudhi, Tafadzwanashe},
TITLE = {Predicting the Chlorophyll Content of Maize over Phenotyping as a Proxy for Crop Health in Smallholder Farming Systems},
JOURNAL = {Remote Sensing},
VOLUME = {14},
YEAR = {2022},
NUMBER = {3},
ARTICLE-NUMBER = {518},
URL = {https://www.mdpi.com/2072-4292/14/3/518},
ISSN = {2072-4292},
ABSTRACT = {Smallholder farmers depend on healthy and productive crop yields to sustain their socio-economic status and ensure livelihood security. Advances in South African precision agriculture in the form of unmanned aerial vehicles (UAVs) provide spatially explicit near-real-time information that can be used to assess crop dynamics and inform smallholder farmers. The use of UAVs with remote-sensing techniques allows for the acquisition of high spatial resolution data at various spatio-temporal planes, which is particularly useful at the scale of fields and farms. Specifically, crop chlorophyll content is assessed as it is one of the best known and reliable indicators of crop health, due to its biophysical pigment and biochemical processes that indicate plant productivity. In this regard, the study evaluated the utility of multispectral UAV imagery using the random forest machine learning algorithm to estimate the chlorophyll content of maize through the various growth stages. The results showed that the near-infrared and red-edge wavelength bands and vegetation indices derived from these wavelengths were essential for estimating chlorophyll content during the phenotyping of maize. Furthermore, the random forest model optimally estimated the chlorophyll content of maize over the various phenological stages. Particularly, maize chlorophyll was best predicted during the early reproductive, late vegetative, and early vegetative growth stages to RMSE accuracies of 40.4 &micro;mol/m&minus;2, 39 &micro;mol/m&minus;2, and 61.6 &micro;mol/m&minus;2, respectively. The least accurate chlorophyll content results were predicted during the mid-reproductive and late reproductive growth stages to RMSE accuracies of 66.6 &micro;mol/m&minus;2 and 69.6 &micro;mol/m&minus;2, respectively, as a consequence of a hailstorm. A resultant chlorophyll variation map of the maize growth stages captured the spatial heterogeneity of chlorophyll within the maize field. Therefore, the study&rsquo;s findings demonstrate that the use of remotely sensed UAV imagery with a robust machine algorithm is a critical tool to support the decision-making and management in smallholder farms.},
DOI = {10.3390/rs14030518}
}



@Article{rs14030522,
AUTHOR = {Peng, Baochai and Ren, Dong and Zheng, Cheng and Lu, Anxiang},
TITLE = {TRDet: Two-Stage Rotated Detection of Rural Buildings in Remote Sensing Images},
JOURNAL = {Remote Sensing},
VOLUME = {14},
YEAR = {2022},
NUMBER = {3},
ARTICLE-NUMBER = {522},
URL = {https://www.mdpi.com/2072-4292/14/3/522},
ISSN = {2072-4292},
ABSTRACT = {Fast and accurate acquisition of the outline of rural buildings on remote sensing images is an efficient method to monitor illegal rural buildings. The traditional object detection method produces useless background information when detecting rural buildings; the semantic segmentation method cannot accurately segment the contours between buildings; the instance segmentation method cannot obtain regular building contours. The rotated object detection methods can effectively solve the problem that the traditional artificial intelligence method cannot accurately extract the outline of buildings. However, the rotated object detection methods are easy to lose location information of small objects in advanced feature maps and are sensitive to noise. To resolve these problems, this paper proposes a two-stage rotated object detection network for rural buildings (TRDet) by using a deep feature fusion network (DFF-Net) and a pixel attention module (PAM). Specifically, TRDet first fuses low-level location and high-level semantic information through the DFF-Net and then reduces the interference of noise information to the network through the PAM. The experimental results show that the mean average precession (mAP), precision, recall rate, and F1 score of the proposed TRDet are 83.57%, 91.11%, 86.5%, and 88.74%, respectively, which outperform the R2CNN model by 15%, 15.54%, 4.01%, and 9.87%. The results demonstrate that the TRDet can achieve better detection in small rural buildings and dense rural buildings.},
DOI = {10.3390/rs14030522}
}



@Article{aerospace9020056,
AUTHOR = {Perk, Baris Eren and Inalhan, Gokhan},
TITLE = {Safe Motion Planning and Learning for Unmanned Aerial Systems},
JOURNAL = {Aerospace},
VOLUME = {9},
YEAR = {2022},
NUMBER = {2},
ARTICLE-NUMBER = {56},
URL = {https://www.mdpi.com/2226-4310/9/2/56},
ISSN = {2226-4310},
ABSTRACT = {To control unmanned aerial systems, we rarely have a perfect system model. Safe and aggressive planning is also challenging for nonlinear and under-actuated systems. Expert pilots, however, demonstrate maneuvers that are deemed at the edge of plane envelope. Inspired by biological systems, in this paper, we introduce a framework that leverages methods in the field of control theory and reinforcement learning to generate feasible, possibly aggressive, trajectories. For the control policies, Dynamic Movement Primitives (DMPs) imitate pilot-induced primitives, and DMPs are combined in parallel to generate trajectories to reach original or different goal points. The stability properties of DMPs and their overall systems are analyzed using contraction theory. For reinforcement learning, Policy Improvement with Path Integrals (PI2) was used for the maneuvers. The results in this paper show that PI2 updated policies are a feasible and parallel combination of different updated primitives transfer the learning in the contraction regions. Our proposed methodology can be used to imitate, reshape, and improve feasible, possibly aggressive, maneuvers. In addition, we can exploit trajectories generated by optimization methods, such as Model Predictive Control (MPC), and a library of maneuvers can be instantly generated. For application, 3-DOF (degrees of freedom) Helicopter and 2D-UAV (unmanned aerial vehicle) models are utilized to demonstrate the main results.},
DOI = {10.3390/aerospace9020056}
}




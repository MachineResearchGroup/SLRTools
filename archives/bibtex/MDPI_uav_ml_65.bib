
@Article{rs11101153,
AUTHOR = {Bejiga, Mesay Belete and Melgani, Farid and Beraldini, Pietro},
TITLE = {Domain Adversarial Neural Networks for Large-Scale Land Cover Classification},
JOURNAL = {Remote Sensing},
VOLUME = {11},
YEAR = {2019},
NUMBER = {10},
ARTICLE-NUMBER = {1153},
URL = {https://www.mdpi.com/2072-4292/11/10/1153},
ISSN = {2072-4292},
ABSTRACT = {Learning classification models require sufficiently labeled training samples, however, collecting labeled samples for every new problem is time-consuming and costly. An alternative approach is to transfer knowledge from one problem to another, which is called transfer learning. Domain adaptation (DA) is a type of transfer learning that aims to find a new latent space where the domain discrepancy between the source and the target domain is negligible. In this work, we propose an unsupervised DA technique called domain adversarial neural networks (DANNs), composed of a feature extractor, a class predictor, and domain classifier blocks, for large-scale land cover classification. Contrary to the traditional methods that perform representation and classifier learning in separate stages, DANNs combine them into a single stage, thereby learning a new representation of the input data that is both domain-invariant and discriminative. Once trained, the classifier of a DANN can be used to predict both source and target domain labels. Additionally, we also modify the domain classifier of a DANN to evaluate its suitability for multi-target domain adaptation problems. Experimental results obtained for both single and multiple target DA problems show that the proposed method provides a performance gain of up to 40%.},
DOI = {10.3390/rs11101153}
}



@Article{rs11101157,
AUTHOR = {Fuentes-Pacheco, Jorge and Torres-Olivares, Juan and Roman-Rangel, Edgar and Cervantes, Salvador and Juarez-Lopez, Porfirio and Hermosillo-Valadez, Jorge and Rendón-Mancha, Juan Manuel},
TITLE = {Fig Plant Segmentation from Aerial Images Using a Deep Convolutional Encoder-Decoder Network},
JOURNAL = {Remote Sensing},
VOLUME = {11},
YEAR = {2019},
NUMBER = {10},
ARTICLE-NUMBER = {1157},
URL = {https://www.mdpi.com/2072-4292/11/10/1157},
ISSN = {2072-4292},
ABSTRACT = {Crop segmentation is an important task in Precision Agriculture, where the use of aerial robots with an on-board camera has contributed to the development of new solution alternatives. We address the problem of fig plant segmentation in top-view RGB (Red-Green-Blue) images of a crop grown under open-field difficult circumstances of complex lighting conditions and non-ideal crop maintenance practices defined by local farmers. We present a Convolutional Neural Network (CNN) with an encoder-decoder architecture that classifies each pixel as crop or non-crop using only raw colour images as input. Our approach achieves a mean accuracy of 93.85% despite the complexity of the background and a highly variable visual appearance of the leaves. We make available our CNN code to the research community, as well as the aerial image data set and a hand-made ground truth segmentation with pixel precision to facilitate the comparison among different algorithms.},
DOI = {10.3390/rs11101157}
}



@Article{app9102009,
AUTHOR = {Han, Jiaming and Yang, Zhong and Zhang, Qiuyan and Chen, Cong and Li, Hongchen and Lai, Shangxiang and Hu, Guoxiong and Xu, Changliang and Xu, Hao and Wang, Di and Chen, Rui},
TITLE = {A Method of Insulator Faults Detection in Aerial Images for High-Voltage Transmission Lines Inspection},
JOURNAL = {Applied Sciences},
VOLUME = {9},
YEAR = {2019},
NUMBER = {10},
ARTICLE-NUMBER = {2009},
URL = {https://www.mdpi.com/2076-3417/9/10/2009},
ISSN = {2076-3417},
ABSTRACT = {Insulator faults detection is an important task for high-voltage transmission line inspection. However, current methods often suffer from the lack of accuracy and robustness. Moreover, these methods can only detect one fault in the insulator string, but cannot detect a multi-fault. In this paper, a novel method is proposed for insulator one fault and multi-fault detection in UAV-based aerial images, the backgrounds of which usually contain much complex interference. The shapes of the insulators also vary obviously due to the changes in filming angle and distance. To reduce the impact of complex interference on insulator faults detection, we make full use of the deep neural network to distinguish between insulators and background interference. First of all, plenty of insulator aerial images with manually labelled ground-truth are collected to construct a standard insulator detection dataset &lsquo;InST_detection&rsquo;. Secondly, a new convolutional network is proposed to obtain accurate insulator string positions in the aerial image. Finally, a novel fault detection method is proposed that can detect both insulator one fault and multi-fault in aerial images. Experimental results on a large number of aerial images show that our proposed method is more effective and efficient than the state-of-the-art insulator fault detection methods.},
DOI = {10.3390/app9102009}
}



@Article{geosciences9050235,
AUTHOR = {Held, Philipp and Schneider von Deimling, Jens},
TITLE = {New Feature Classes for Acoustic Habitat Mapping—A Multibeam Echosounder Point Cloud Analysis for Mapping Submerged Aquatic Vegetation (SAV)},
JOURNAL = {Geosciences},
VOLUME = {9},
YEAR = {2019},
NUMBER = {5},
ARTICLE-NUMBER = {235},
URL = {https://www.mdpi.com/2076-3263/9/5/235},
ISSN = {2076-3263},
ABSTRACT = {A new method for multibeam echosounder (MBES) data analysis is presented with the aim of improving habitat mapping, especially when considering submerged aquatic vegetation (SAV). MBES data were acquired with 400 kHz in 1&ndash;8 m water depth with a spatial resolution in the decimeter scale. The survey area was known to be populated with the seagrass Zostera marina and the bathymetric soundings were highly influenced by this habitat. The depth values often coincide with the canopy of the seagrass. Instead of classifying the data with a digital terrain model and the given derivatives, we derive predictive features from the native point cloud of the MBES soundings in a similar way to terrestrial LiDAR data analysis. We calculated the eigenvalues to derive nine characteristic features, which include linearity, planarity, and sphericity. The features were calculated for each sounding within a cylindrical neighborhood of 0.5 m radius and holding 88 neighboring soundings, on average, during our survey. The occurrence of seagrass was ground-truthed by divers and aerial photography. A data model was constructed and we applied a random forest machine learning supervised classification to predict between the two cases of &ldquo;seafloor&rdquo; and &ldquo;vegetation&rdquo;. Prediction by linearity, planarity, and sphericity resulted in 88.5% prediction accuracy. After constructing the higher-order eigenvalue derivatives and having the nine features available, the model resulted in 96% prediction accuracy. This study outlines for the first time that valuable feature classes can be derived from MBES point clouds&mdash;an approach that could substantially improve bathymetric measurements and habitat mapping.},
DOI = {10.3390/geosciences9050235}
}



@Article{rs11101241,
AUTHOR = {Li, Jing and Chen, Shuo and Zhang, Fangbing and Li, Erkang and Yang, Tao and Lu, Zhaoyang},
TITLE = {An Adaptive Framework for Multi-Vehicle Ground Speed Estimation in Airborne Videos},
JOURNAL = {Remote Sensing},
VOLUME = {11},
YEAR = {2019},
NUMBER = {10},
ARTICLE-NUMBER = {1241},
URL = {https://www.mdpi.com/2072-4292/11/10/1241},
ISSN = {2072-4292},
ABSTRACT = {With the rapid development of unmanned aerial vehicles (UAVs), UAV-based intelligent airborne surveillance systems represented by real-time ground vehicle speed estimation have attracted wide attention from researchers. However, there are still many challenges in extracting speed information from UAV videos, including the dynamic moving background, small target size, complicated environment, and diverse scenes. In this paper, we propose a novel adaptive framework for multi-vehicle ground speed estimation in airborne videos. Firstly, we build a traffic dataset based on UAV. Then, we use the deep learning detection algorithm to detect the vehicle in the UAV field of view and obtain the trajectory in the image through the tracking-by-detection algorithm. Thereafter, we present a motion compensation method based on homography. This method obtains matching feature points by an optical flow method and eliminates the influence of the detected target to accurately calculate the homography matrix to determine the real motion trajectory in the current frame. Finally, vehicle speed is estimated based on the mapping relationship between the pixel distance and the actual distance. The method regards the actual size of the car as prior information and adaptively recovers the pixel scale by estimating the vehicle size in the image; it then calculates the vehicle speed. In order to evaluate the performance of the proposed system, we carry out a large number of experiments on the AirSim Simulation platform as well as real UAV aerial surveillance experiments. Through quantitative and qualitative analysis of the simulation results and real experiments, we verify that the proposed system has a unique ability to detect, track, and estimate the speed of ground vehicles simultaneously even with a single downward-looking camera. Additionally, the system can obtain effective and accurate speed estimation results, even in various complex scenes.},
DOI = {10.3390/rs11101241}
}



@Article{molecules24102025,
AUTHOR = {Tan, Jin Yeong and Ker, Pin Jern and Lau, K. Y. and Hannan, M. A. and Tang, Shirley Gee Hoon},
TITLE = {Applications of Photonics in Agriculture Sector: A Review},
JOURNAL = {Molecules},
VOLUME = {24},
YEAR = {2019},
NUMBER = {10},
ARTICLE-NUMBER = {2025},
URL = {https://www.mdpi.com/1420-3049/24/10/2025},
PubMedID = {31137897},
ISSN = {1420-3049},
ABSTRACT = {The agricultural industry has made a tremendous contribution to the foundations of civilization. Basic essentials such as food, beverages, clothes and domestic materials are enriched by the agricultural industry. However, the traditional method in agriculture cultivation is labor-intensive and inadequate to meet the accelerating nature of human demands. This scenario raises the need to explore state-of-the-art crop cultivation and harvesting technologies. In this regard, optics and photonics technologies have proven to be effective solutions. This paper aims to present a comprehensive review of three photonic techniques, namely imaging, spectroscopy and spectral imaging, in a comparative manner for agriculture applications. Essentially, the spectral imaging technique is a robust solution which combines the benefits of both imaging and spectroscopy but faces the risk of underutilization. This review also comprehends the practicality of all three techniques by presenting existing examples in agricultural applications. Furthermore, the potential of these techniques is reviewed and critiqued by looking into agricultural activities involving palm oil, rubber, and agro-food crops. All the possible issues and challenges in implementing the photonic techniques in agriculture are given prominence with a few selective recommendations. The highlighted insights in this review will hopefully lead to an increased effort in the development of photonics applications for the future agricultural industry.},
DOI = {10.3390/molecules24102025}
}



@Article{app9112173,
AUTHOR = {Wang, Mingwei and Gao, Lang and Huang, Xiaohui and Jiang, Ying and Gao, Xianjun},
TITLE = {A Texture Classification Approach Based on the Integrated Optimization for Parameters and Features of Gabor Filter via Hybrid Ant Lion Optimizer},
JOURNAL = {Applied Sciences},
VOLUME = {9},
YEAR = {2019},
NUMBER = {11},
ARTICLE-NUMBER = {2173},
URL = {https://www.mdpi.com/2076-3417/9/11/2173},
ISSN = {2076-3417},
ABSTRACT = {Texture classification is an important topic for many applications in machine vision and image analysis, and Gabor filter is considered one of the most efficient tools for analyzing texture features at multiple orientations and scales. However, the parameter settings of each filter are crucial for obtaining accurate results, and they may not be adaptable to different kinds of texture features. Moreover, there is redundant information included in the process of texture feature extraction that contributes little to the classification. In this paper, a new texture classification technique is detailed. The approach is based on the integrated optimization of the parameters and features of Gabor filter, and obtaining satisfactory parameters and the best feature subset is viewed as a combinatorial optimization problem that can be solved by maximizing the objective function using hybrid ant lion optimizer (HALO). Experimental results, particularly fitness values, demonstrate that HALO is more effective than the other algorithms discussed in this paper, and the optimal parameters and features of Gabor filter are balanced between efficiency and accuracy. The method is feasible, reasonable, and can be utilized for practical applications of texture classification.},
DOI = {10.3390/app9112173}
}



@Article{mi10060362,
AUTHOR = {Wang, Hailu and Liu, Ning and Su, Zhong and Li, Qing},
TITLE = {Research on Low-Cost Attitude Estimation for MINS/Dual-Antenna GNSS Integrated Navigation Method},
JOURNAL = {Micromachines},
VOLUME = {10},
YEAR = {2019},
NUMBER = {6},
ARTICLE-NUMBER = {362},
URL = {https://www.mdpi.com/2072-666X/10/6/362},
PubMedID = {31151269},
ISSN = {2072-666X},
ABSTRACT = {A high-precision navigation system is required for an unmanned vehicle, and the high-precision sensor is expensive. A low-cost, high-precision, dual-antenna Global Navigation Satellite System/Micro-electromechanical Systems-Inertial Navigation System (GNSS/MINS) combination method is proposed. The GNSS with dual antennas provides velocity, position, and attitude angle information as the measurement information is combined with the MINS. By increasing the heading angle, pitch angle, velocity, the accuracy of the integrated system is improved. The Extended Kalman Filtering (EKF) integrated algorithm simulation is designed to verify the feasibility and is realized based on the Field Programmable Gate Array and Advanced RISC Machine (ARM+FPGA) system. Static and dynamic tests were performed using the Synchronous Position, Attitude and Navigation (SPAN-CPT) as a reference system. The results show that the velocity, position, and attitude angle accuracy were improved. The yaw angle and pitch angle accuracy were 0.2&deg; Root Mean Square (RMS) and 0.3&deg; RMS, respectively. The method can be used as a navigation system for the unmanned vehicle.},
DOI = {10.3390/mi10060362}
}



@Article{app9112253,
AUTHOR = {Andoga, Rudolf and Főző, Ladislav and Schrötter, Martin and Češkovič, Marek and Szabo, Stanislav and Bréda, Róbert and Schreiner, Michal},
TITLE = {Intelligent Thermal Imaging-Based Diagnostics of Turbojet Engines},
JOURNAL = {Applied Sciences},
VOLUME = {9},
YEAR = {2019},
NUMBER = {11},
ARTICLE-NUMBER = {2253},
URL = {https://www.mdpi.com/2076-3417/9/11/2253},
ISSN = {2076-3417},
ABSTRACT = {There are only a few applications of infrared thermal imaging in aviation. In the area of turbojet engines, infrared imaging has been used to detect temperature field anomalies in order to identify structural defects in the materials of engine casings or other engine parts. In aviation applications, the evaluation of infrared images is usually performed manually by an expert. This paper deals with the design of an automatic intelligent system which evaluates the technical state and diagnoses a turbojet engine during its operation based on infrared thermal (IRT) images. A hybrid system interconnecting a self-organizing feature map and an expert system is designed for this purpose. A Kohonen neural network (the self-organizing feature map) is successfully applied to segment IRT images of a turbojet engine with high precision, and the expert system is then used to create diagnostic information from the segmented images. This paper represents a proof of concept of this hybrid system using data from a small iSTC-21v turbojet engine operating in laboratory conditions.},
DOI = {10.3390/app9112253}
}



@Article{electronics8060614,
AUTHOR = {Li, Xingyu and Tang, Bo and Ball, John and Doude, Matthew and Carruth, Daniel W.},
TITLE = {Rollover-Free Path Planning for Off-Road Autonomous Driving},
JOURNAL = {Electronics},
VOLUME = {8},
YEAR = {2019},
NUMBER = {6},
ARTICLE-NUMBER = {614},
URL = {https://www.mdpi.com/2079-9292/8/6/614},
ISSN = {2079-9292},
ABSTRACT = {Perception, planning, and control are three enabling technologies to achieve autonomy in autonomous driving. In particular, planning provides vehicles with a safe and collision-free path towards their destinations, accounting for vehicle dynamics, maneuvering capabilities in the presence of obstacles, traffic rules, and road boundaries. Existing path planning algorithms can be divided into two stages: global planning and local planning. In the global planning stage, global routes and the vehicle states are determined from a digital map and the localization system. In the local planning stage, a local path can be achieved based on a global route and surrounding information obtained from sensors such as cameras and LiDARs. In this paper, we present a new local path planning method, which incorporates a vehicle&rsquo;s time-to-rollover model for off-road autonomous driving on different road profiles for a given predefined global route. The proposed local path planning algorithm uses a 3D occupancy grid and generates a series of 3D path candidates in the s-p coordinate system. The optimal path is then selected considering the total cost of safety, including obstacle avoidance, vehicle rollover prevention, and comfortability in terms of path smoothness and continuity with road unevenness. The simulation results demonstrate the effectiveness of the proposed path planning method for various types of roads, indicating its wide practical applications to off-road autonomous driving.},
DOI = {10.3390/electronics8060614}
}



@Article{rs11111308,
AUTHOR = {Wang, Dongliang and Shao, Quanqin and Yue, Huanyin},
TITLE = {Surveying Wild Animals from Satellites, Manned Aircraft and Unmanned Aerial Systems (UASs): A Review},
JOURNAL = {Remote Sensing},
VOLUME = {11},
YEAR = {2019},
NUMBER = {11},
ARTICLE-NUMBER = {1308},
URL = {https://www.mdpi.com/2072-4292/11/11/1308},
ISSN = {2072-4292},
ABSTRACT = {This article reviews studies regarding wild animal surveys based on multiple platforms, including satellites, manned aircraft, and unmanned aircraft systems (UASs), and focuses on the data used, animal detection methods, and their accuracies. We also discuss the advantages and limitations of each type of remote sensing data and highlight some new research opportunities and challenges. Submeter very-high-resolution (VHR) spaceborne imagery has potential in modeling the population dynamics of large (&gt;0.6 m) wild animals at large spatial and temporal scales, but has difficulty discerning small (&lt;0.6 m) animals at the species level, although high-resolution commercial satellites, such as WorldView-3 and -4, have been able to collect images with a ground resolution of up to 0.31 m in panchromatic mode. This situation will not change unless the satellite image resolution is greatly improved in the future. Manned aerial surveys have long been employed to capture the centimeter-scale images required for animal censuses over large areas. However, such aerial surveys are costly to implement in small areas and can cause significant disturbances to wild animals because of their noise. In contrast, UAS surveys are seen as a safe, convenient and less expensive alternative to ground-based and conventional manned aerial surveys, but most UASs can cover only small areas. The proposed use of UAS imagery in combination with VHR satellite imagery would produce critical population data for large wild animal species and colonies over large areas. The development of software systems for automatically producing image mosaics and recognizing wild animals will further improve survey efficiency.},
DOI = {10.3390/rs11111308}
}



@Article{rs11111310,
AUTHOR = {Zhao, Rui and Shi, Zhenwei and Zou, Zhengxia and Zhang, Zhou},
TITLE = {Ensemble-Based Cascaded Constrained Energy Minimization for Hyperspectral Target Detection},
JOURNAL = {Remote Sensing},
VOLUME = {11},
YEAR = {2019},
NUMBER = {11},
ARTICLE-NUMBER = {1310},
URL = {https://www.mdpi.com/2072-4292/11/11/1310},
ISSN = {2072-4292},
ABSTRACT = {Ensemble learning is an important group of machine learning techniques that aim to enhance the nonlinearity and generalization ability of a learning system by aggregating multiple learners. We found that ensemble techniques show great potential for improving the performance of traditional hyperspectral target detection algorithms, while at present, there are few previous works have been done on this topic. To this end, we propose an Ensemble based Constrained Energy Minimization (E-CEM) detector for hyperspectral image target detection. Classical hyperspectral image target detection algorithms like Constrained Energy Minimization (CEM), matched filter (MF) and adaptive coherence/cosine estimator (ACE) are usually designed based on constrained least square regression methods or hypothesis testing methods with Gaussian distribution assumption. However, remote sensing hyperspectral data captured in a real-world environment usually shows strong nonlinearity and non-Gaussianity, which will lead to performance degradation of these classical detection algorithms. Although some hierarchical detection models are able to learn strong nonlinear discrimination of spectral data, due to the spectrum changes, these models usually suffer from the instability in detection tasks. The proposed E-CEM is designed based on the classical CEM detection algorithm. To improve both of the detection nonlinearity and generalization ability, the strategies of &ldquo;cascaded detection&rdquo;, &ldquo;random averaging&rdquo; and &ldquo;multi-scale scanning&rdquo; are specifically designed. Experiments on one synthetic hyperspectral image and two real hyperspectral images demonstrate the effectiveness of our method. E-CEM outperforms the traditional CEM detector and other state-of-the-art detection algorithms. Our code will be made publicly available.},
DOI = {10.3390/rs11111310}
}



@Article{s19112530,
AUTHOR = {Chen, Shichao and Liu, Ming and Lu, Fugang and Xing, Mengdao},
TITLE = {A Target Identification Method for the Millimeter Wave Seeker via Correlation Matching and Beam Pointing},
JOURNAL = {Sensors},
VOLUME = {19},
YEAR = {2019},
NUMBER = {11},
ARTICLE-NUMBER = {2530},
URL = {https://www.mdpi.com/1424-8220/19/11/2530},
ISSN = {1424-8220},
ABSTRACT = {Target identification is a challenging task under land backgrounds for the millimeter wave (MMW) seeker, especially under complex backgrounds. Focusing on the problem, an effective method combining correlation matching and beam pointing is proposed in this paper. In the beginning, seeker scanning for target detection is conducted in two rounds, and target information of the detected targets is stored for correlation matching. Point or body feature judgment is implemented by using high resolution range profile (HRRP). Then, the error distribution zone is constructed with the beam pointing as the origin. In the end, we identify the target by searching the one which lies in the closest error distribution from the beam pointing center. The effectiveness of the proposed method is verified by using mooring test-fly and real flight data.},
DOI = {10.3390/s19112530}
}



@Article{rs11111338,
AUTHOR = {Sothe, Camile and Dalponte, Michele and Almeida, Cláudia Maria de and Schimalski, Marcos Benedito and Lima, Carla Luciane and Liesenberg, Veraldo and Miyoshi, Gabriela Takahashi and Tommaselli, Antonio Maria Garcia},
TITLE = {Tree Species Classification in a Highly Diverse Subtropical Forest Integrating UAV-Based Photogrammetric Point Cloud and Hyperspectral Data},
JOURNAL = {Remote Sensing},
VOLUME = {11},
YEAR = {2019},
NUMBER = {11},
ARTICLE-NUMBER = {1338},
URL = {https://www.mdpi.com/2072-4292/11/11/1338},
ISSN = {2072-4292},
ABSTRACT = {The use of remote sensing data for tree species classification in tropical forests is still a challenging task, due to their high floristic and spectral diversity. In this sense, novel sensors on board of unmanned aerial vehicle (UAV) platforms are a rapidly evolving technology that provides new possibilities for tropical tree species mapping. Besides the acquisition of high spatial and spectral resolution images, UAV-hyperspectral cameras operating in frame format enable to produce 3D hyperspectral point clouds. This study investigated the use of UAV-acquired hyperspectral images and UAV-photogrammetric point cloud (PPC) for classification of 12 major tree species in a subtropical forest fragment in Southern Brazil. Different datasets containing hyperspectral visible/near-infrared (VNIR) bands, PPC features, canopy height model (CHM), and other features extracted from hyperspectral data (i.e., texture, vegetation indices-VIs, and minimum noise fraction-MNF) were tested using a support vector machine (SVM) classifier. The results showed that the use of VNIR hyperspectral bands alone reached an overall accuracy (OA) of 57% (Kappa index of 0.53). Adding PPC features to the VNIR hyperspectral bands increased the OA by 11%. The best result was achieved combining VNIR bands, PPC features, CHM, and VIs (OA of 72.4% and Kappa index of 0.70). When only the CHM was added to VNIR bands, the OA increased by 4.2%. Among the hyperspectral features, besides all the VNIR bands and the two VIs (NDVI and PSSR), the first four MNF features and the textural mean of 565 and 679 nm spectral bands were pointed out as more important to discriminate the tree species according to Jeffries&ndash;Matusita (JM) distance. The SVM method proved to be a good classifier for the tree species recognition task, even in the presence of a high number of classes and a small dataset.},
DOI = {10.3390/rs11111338}
}



@Article{rs11111354,
AUTHOR = {Yue, Rui and Xu, Hao and Wu, Jianqing and Sun, Renjuan and Yuan, Changwei},
TITLE = {Data Registration with Ground Points for Roadside LiDAR Sensors},
JOURNAL = {Remote Sensing},
VOLUME = {11},
YEAR = {2019},
NUMBER = {11},
ARTICLE-NUMBER = {1354},
URL = {https://www.mdpi.com/2072-4292/11/11/1354},
ISSN = {2072-4292},
ABSTRACT = {The Light Detection and Ranging (LiDAR) sensors are being considered as new traffic infrastructure sensors to detect road users&rsquo; trajectories for connected/autonomous vehicles and other traffic engineering applications. A LiDAR-enhanced traffic infrastructure system requires multiple LiDAR sensors around intersections, along with road segments, which can provide a seamless detection range at intersections or along arterials. Each LiDAR sensor generates cloud points of surrounding objects in a local coordinate system with the sensor at the origin, so it is necessary to integrate multiple roadside LiDAR sensors&rsquo; data into the same coordinate system. None of existing methods can integrate the data from roadside LiDAR sensors, because the extensive detection range of roadside sensors generates low-density cloud points and the alignment of roadside sensors is different from mapping scans or autonomous sensing systems. This paper presents a method to register datasets from multiple roadside LiDAR sensors. This approach innovatively integrates LiDAR datasets with 3D cloud points of road surface and 2D reference point features, so the method is abbreviated as RGP (Registration with Ground and Points). The RGP method applies optimization algorithms to identify the optimized linear coordinate transformation. This research considered the genetic algorithm (global optimization) and the hill climbing algorithm (local optimization). The performance of the RGP method and the different optimization algorithms was evaluated with field LiDAR sensors data. When the developed process can integrate data from roadside sensors, it can also register LiDAR sensors&rsquo; data on an autonomous vehicle or a robot.},
DOI = {10.3390/rs11111354}
}




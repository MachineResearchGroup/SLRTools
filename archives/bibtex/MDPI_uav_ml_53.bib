
@Article{drones5020052,
AUTHOR = {Lee, Thomas and Mckeever, Susan and Courtney, Jane},
TITLE = {Flying Free: A Research Overview of Deep Learning in Drone Navigation Autonomy},
JOURNAL = {Drones},
VOLUME = {5},
YEAR = {2021},
NUMBER = {2},
ARTICLE-NUMBER = {52},
URL = {https://www.mdpi.com/2504-446X/5/2/52},
ISSN = {2504-446X},
ABSTRACT = {With the rise of Deep Learning approaches in computer vision applications, significant strides have been made towards vehicular autonomy. Research activity in autonomous drone navigation has increased rapidly in the past five years, and drones are moving fast towards the ultimate goal of near-complete autonomy. However, while much work in the area focuses on specific tasks in drone navigation, the contribution to the overall goal of autonomy is often not assessed, and a comprehensive overview is needed. In this work, a taxonomy of drone navigation autonomy is established by mapping the definitions of vehicular autonomy levels, as defined by the Society of Automotive Engineers, to specific drone tasks in order to create a clear definition of autonomy when applied to drones. A top–down examination of research work in the area is conducted, focusing on drone navigation tasks, in order to understand the extent of research activity in each area. Autonomy levels are cross-checked against the drone navigation tasks addressed in each work to provide a framework for understanding the trajectory of current research. This work serves as a guide to research in drone autonomy with a particular focus on Deep Learning-based solutions, indicating key works and areas of opportunity for development of this area in the future.},
DOI = {10.3390/drones5020052}
}



@Article{app11125621,
AUTHOR = {An, Kang and Chen, Yixin and Wang, Suhong and Xiao, Zhifeng},
TITLE = {RCBi-CenterNet: An Absolute Pose Policy for 3D Object Detection in Autonomous Driving},
JOURNAL = {Applied Sciences},
VOLUME = {11},
YEAR = {2021},
NUMBER = {12},
ARTICLE-NUMBER = {5621},
URL = {https://www.mdpi.com/2076-3417/11/12/5621},
ISSN = {2076-3417},
ABSTRACT = {3D Object detection is a critical mission of the perception system of a self-driving vehicle. Existing bounding box-based methods are hard to train due to the need to remove duplicated detections in the post-processing stage. In this paper, we propose a center point-based deep neural network (DNN) architecture named RCBi-CenterNet that predicts the absolute pose for each detected object in the 3D world space. RCBi-CenterNet is composed of a recursive composite network with a dual-backbone feature extractor and a bi-directional feature pyramid network (BiFPN) for cross-scale feature fusion. In the detection head, we predict a confidence heatmap that is used to determine the position of detected objects. The other pose information, including depth and orientation, is regressed. We conducted extensive experiments on the Peking University/Baidu-Autonomous Driving dataset, which contains more than 60,000 labeled 3D vehicle instances from 5277 real-world images, and each vehicle object is annotated with the absolute pose described by the six degrees of freedom (6DOF). We validated the design choices of various data augmentation methods and the backbone options. Through an ablation study and an overall comparison with the state-of-the-art (SOTA), namely CenterNet, we showed that the proposed RCBi-CenterNet presents performance gains of 2.16%, 2.76%, and 5.24% in Top 1, Top 3, and Top 10 mean average precision (mAP). The model and the result could serve as a credible benchmark for future research in center point-based object detection.},
DOI = {10.3390/app11125621}
}



@Article{app11125644,
AUTHOR = {Marin, Ivana and Mladenović, Saša and Gotovac, Sven and Zaharija, Goran},
TITLE = {Deep-Feature-Based Approach to Marine Debris Classification},
JOURNAL = {Applied Sciences},
VOLUME = {11},
YEAR = {2021},
NUMBER = {12},
ARTICLE-NUMBER = {5644},
URL = {https://www.mdpi.com/2076-3417/11/12/5644},
ISSN = {2076-3417},
ABSTRACT = {The global community has recognized an increasing amount of pollutants entering oceans and other water bodies as a severe environmental, economic, and social issue. In addition to prevention, one of the key measures in addressing marine pollution is the cleanup of debris already present in marine environments. Deployment of machine learning (ML) and deep learning (DL) techniques can automate marine waste removal, making the cleanup process more efficient. This study examines the performance of six well-known deep convolutional neural networks (CNNs), namely VGG19, InceptionV3, ResNet50, Inception-ResNetV2, DenseNet121, and MobileNetV2, utilized as feature extractors according to three different extraction schemes for the identification and classification of underwater marine debris. We compare the performance of a neural network (NN) classifier trained on top of deep CNN feature extractors when the feature extractor is (1) fixed; (2) fine-tuned on the given task; (3) fixed during the first phase of training and fine-tuned afterward. In general, fine-tuning resulted in better-performing models but is much more computationally expensive. The overall best NN performance showed the fine-tuned Inception-ResNetV2 feature extractor with an accuracy of 91.40% and F1-score 92.08%, followed by fine-tuned InceptionV3 extractor. Furthermore, we analyze conventional ML classifiers’ performance when trained on features extracted with deep CNNs. Finally, we show that replacing NN with a conventional ML classifier, such as support vector machine (SVM) or logistic regression (LR), can further enhance the classification performance on new data.},
DOI = {10.3390/app11125644}
}



@Article{rs13122388,
AUTHOR = {Peprah, Clement Oppong and Yamashita, Megumi and Yamaguchi, Tomoaki and Sekino, Ryo and Takano, Kyohei and Katsura, Keisuke},
TITLE = {Spatio-Temporal Estimation of Biomass Growth in Rice Using Canopy Surface Model from Unmanned Aerial Vehicle Images},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {12},
ARTICLE-NUMBER = {2388},
URL = {https://www.mdpi.com/2072-4292/13/12/2388},
ISSN = {2072-4292},
ABSTRACT = {The awareness of spatial and temporal variations in site-specific crop parameters, such as aboveground biomass (total dry weight: (TDW), plant length (PL) and leaf area index (LAI), help in formulating appropriate management decisions. However, conventional monitoring methods rely on time-consuming manual field operations. In this study, the feasibility of using an unmanned aerial vehicle (UAV)-based remote sensing approach for monitoring growth in rice was evaluated using a digital surface model (DSM). Approximately 160 images of paddy fields were captured during each UAV survey campaign over two vegetation seasons. The canopy surface model (CSM) was developed based on the differences observed between each DSM and the first DSM after transplanting. Mean canopy height (CH) was used as a variable for the estimation models of LAI and TDW. The mean CSM of the mesh covering several hills was sufficient to explain the PL (R2 = 0.947). TDW and LAI prediction accuracy of the model were high (relative RMSE of 20.8% and 28.7%, and RMSE of 0.76 m2 m−2 and 141.4 g m−2, respectively) in the rice varieties studied (R2 = 0.937 (Basmati370), 0.837 (Nipponbare and IR64) for TDW, and 0.894 (Basmati370), 0.866 (Nipponbare and IR64) for LAI). The results of this study support the assertion of the benefits of DSM-derived CH for predicting biomass development. In addition, LAI and TDW could be estimated temporally and spatially using the UAV-based CSM, which is not easily affected by weather conditions.},
DOI = {10.3390/rs13122388}
}



@Article{rs13122401,
AUTHOR = {Albuquerque, Rafael Walter and Ferreira, Manuel Eduardo and Olsen, Søren Ingvor and Tymus, Julio Ricardo Caetano and Balieiro, Cintia Palheta and Mansur, Hendrik and Moura, Ciro José Ribeiro and Costa, João Vitor Silva and Branco, Maurício Ruiz Castello and Grohmann, Carlos Henrique},
TITLE = {Forest Restoration Monitoring Protocol with a Low-Cost Remotely Piloted Aircraft: Lessons Learned from a Case Study in the Brazilian Atlantic Forest},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {12},
ARTICLE-NUMBER = {2401},
URL = {https://www.mdpi.com/2072-4292/13/12/2401},
ISSN = {2072-4292},
ABSTRACT = {Traditional forest restoration (FR) monitoring methods employ spreadsheets and photos taken at the ground level. Since remotely piloted aircraft (RPA) generate a panoramic high resolution and georeferenced view of the entire area of interest, this technology has high potential to improve the traditional FR monitoring methods. This study evaluates how low-cost RPA data may contribute to FR monitoring of the Brazilian Atlantic Forest by the automatic remote measurement of Tree Density, Tree Height, Vegetation Cover (area covered by trees), and Grass Infestation. The point cloud data was processed to map the Tree Density, Tree Height, and Vegetation Cover parameters. The orthomosaic was used for a Random Forest classification that considered trees and grasses as a single land cover class. The Grass Infestation parameter was mapped by the difference between this land cover class (which considered trees and grasses) and the Vegetation Cover results (obtained by the point cloud data processing). Tree Density, Vegetation Cover, and Grass Infestation parameters presented F_scores of 0.92, 0.85, and 0.64, respectively. Tree Height accuracy was indicated by the Error Percentage considering the traditional fieldwork and the RPA results. The Error Percentage was equal to 0.13 and was considered accurate because it estimated a 13% shorter height for trees that averaged 1.93 m tall. Thus, this study showed that the FR structural parameters were accurately measured by the low-cost RPA, a technology that contributes to FR monitoring. Despite accurately measuring the structural parameters, this study reinforced the challenge of measuring the Biodiversity parameter via remote sensing because the classification of tree species was not possible. After all, the Brazilian Atlantic Forest is a biodiversity hotspot, and thus different species have similar spectral responses in the visible spectrum and similar geometric forms. Therefore, until improved automatic classification methods become available for tree species, traditional fieldwork remains necessary for a complete FR monitoring diagnostic.},
DOI = {10.3390/rs13122401}
}



@Article{rs13122404,
AUTHOR = {Perich, Gregor and Aasen, Helge and Verrelst, Jochem and Argento, Francesco and Walter, Achim and Liebisch, Frank},
TITLE = {Crop Nitrogen Retrieval Methods for Simulated Sentinel-2 Data Using In-Field Spectrometer Data},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {12},
ARTICLE-NUMBER = {2404},
URL = {https://www.mdpi.com/2072-4292/13/12/2404},
ISSN = {2072-4292},
ABSTRACT = {Nitrogen (N) is one of the key nutrients supplied in agricultural production worldwide. Over-fertilization can have negative influences on the field and the regional level (e.g., agro-ecosystems). Remote sensing of the plant N of field crops presents a valuable tool for the monitoring of N flows in agro-ecosystems. Available data for validation of satellite-based remote sensing of N is scarce. Therefore, in this study, field spectrometer measurements were used to simulate data of the Sentinel-2 (S2) satellites developed for vegetation monitoring by the ESA. The prediction performance of normalized ratio indices (NRIs), random forest regression (RFR) and Gaussian processes regression (GPR) for plant-N-related traits was assessed on a diverse real-world dataset including multiple crops, field sites and years. The plant N traits included the mass-based N measure, N concentration in the biomass (Nconc), and an area-based N measure approximating the plant N uptake (NUP). Spectral indices such as normalized ratio indices (NRIs) performed well, but the RFR and GPR methods outperformed the NRIs. Key spectral bands for each trait were identified using the RFR variable importance measure and the Gaussian processes regression band analysis tool (GPR-BAT), highlighting the importance of the short-wave infrared (SWIR) region for estimation of plant Nconc—and to a lesser extent the NUP. The red edge (RE) region was also important. The GPR-BAT showed that five bands were sufficient for plant N trait and leaf area index (LAI) estimation and that a surplus of bands effectively reduced prediction performance. A global sensitivity analysis (GSA) was performed on all traits simultaneously, showing the dominance of the LAI in the mixed remote sensing signal. To delineate the plant-N-related traits from this signal, regional and/or national data collection campaigns producing large crop spectral libraries (CSL) are needed. An improved database will likely enable the mapping of N at the agro-ecosystem level or for use in precision farming by farmers in the future.},
DOI = {10.3390/rs13122404}
}



@Article{agriculture11060563,
AUTHOR = {Li, Minhui and Shamshiri, Redmond R. and Schirrmann, Michael and Weltzien, Cornelia},
TITLE = {Impact of Camera Viewing Angle for Estimating Leaf Parameters of Wheat Plants from 3D Point Clouds},
JOURNAL = {Agriculture},
VOLUME = {11},
YEAR = {2021},
NUMBER = {6},
ARTICLE-NUMBER = {563},
URL = {https://www.mdpi.com/2077-0472/11/6/563},
ISSN = {2077-0472},
ABSTRACT = {Estimation of plant canopy using low-altitude imagery can help monitor the normal growth status of crops and is highly beneficial for various digital farming applications such as precision crop protection. However, extracting 3D canopy information from raw images requires studying the effect of sensor viewing angle by taking into accounts the limitations of the mobile platform routes inside the field. The main objective of this research was to estimate wheat (Triticum aestivum L.) leaf parameters, including leaf length and width, from the 3D model representation of the plants. For this purpose, experiments with different camera viewing angles were conducted to find the optimum setup of a mono-camera system that would result in the best 3D point clouds. The angle-control analytical study was conducted on a four-row wheat plot with a row spacing of 0.17 m and with two seeding densities and growth stages as factors. Nadir and six oblique view image datasets were acquired from the plot with 88% overlapping and were then reconstructed to point clouds using Structure from Motion (SfM) and Multi-View Stereo (MVS) methods. Point clouds were first categorized into three classes as wheat canopy, soil background, and experimental plot. The wheat canopy class was then used to extract leaf parameters, which were then compared with those values from manual measurements. The comparison between results showed that (i) multiple-view dataset provided the best estimation for leaf length and leaf width, (ii) among the single-view dataset, canopy, and leaf parameters were best modeled with angles vertically at −45° and horizontally at 0° (VA −45, HA 0), while (iii) in nadir view, fewer underlying 3D points were obtained with a missing leaf rate of 70%. It was concluded that oblique imagery is a promising approach to effectively estimate wheat canopy 3D representation with SfM-MVS using a single camera platform for crop monitoring. This study contributes to the improvement of the proximal sensing platform for crop health assessment.},
DOI = {10.3390/agriculture11060563}
}



@Article{rs13132429,
AUTHOR = {Chen, Fang},
TITLE = {Comparing Methods for Segmenting Supra-Glacial Lakes and Surface Features in the Mount Everest Region of the Himalayas Using Chinese GaoFen-3 SAR Images},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {13},
ARTICLE-NUMBER = {2429},
URL = {https://www.mdpi.com/2072-4292/13/13/2429},
ISSN = {2072-4292},
ABSTRACT = {Glaciers and numerous glacial lakes that are produced by glacier melting are key indicators of climate change. Often overlooked, supra-glacial lakes develop in the melting area in the low-lying part of a glacier and appear to be highly variable in their size, shape, and location. The lifespan of these lakes is thought to be quite transient, since the lakes may be completely filled by water and burst out within several weeks. Changes in supra-glacial lake outlines and other surface features such as supra-glacial rivers and crevasses on the glaciers are useful indicators for the direct monitoring of glacier changes. Synthetic aperture radar (SAR) is not affected by weather and climate, and is an effective tool for study of glaciated areas. The development of the Chinese GaoFen-3 (GF-3) SAR, which has high spatial and temporal resolution and high-precision observation performance, has made it possible to obtain dynamic information about glaciers in more detail. In this paper, the classical Canny operator, the variational B-spline level-set method, and U-Net-based deep-learning model were applied and compared to extract glacial lake outlines and other surface features using different modes and Chinese GF-3 SAR imagery in the Mount Everest Region of the Himalayas. Particularly, the U-Net-based deep-learning method, which was independent of auxiliary data and had a high degree of automation, was used for the first time in this context. The experimental results showed that the U-Net-based deep-learning model worked best in the segmentation of supra-glacial lakes in terms of accuracy (Precision = 98.45% and Recall = 95.82%) and segmentation efficiency, and was good at detecting small, elongated, and ice-covered supra-glacial lakes. We also found that it was useful for accurately identifying the location of supra-glacial streams and ice crevasses on glaciers, and quantifying their width. Finally, based on the time series of the mapping results, the spatial characteristics and temporal evolution of these features over the glaciers were comprehensively analyzed. Overall, this study presents a novel approach to improve the detection accuracy of glacier elements that could be leveraged for dynamic monitoring in future research.},
DOI = {10.3390/rs13132429}
}



@Article{rs13132436,
AUTHOR = {Calamita, Federico and Imran, Hafiz Ali and Vescovo, Loris and Mekhalfi, Mohamed Lamine and La Porta, Nicola},
TITLE = {Early Identification of Root Rot Disease by Using Hyperspectral Reflectance: The Case of Pathosystem Grapevine/Armillaria},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {13},
ARTICLE-NUMBER = {2436},
URL = {https://www.mdpi.com/2072-4292/13/13/2436},
ISSN = {2072-4292},
ABSTRACT = {Armillaria genus represents one of the most common causes of chronic root rot disease in woody plants. Prompt recognition of diseased plants is crucial to control the pathogen. However, the current disease detection methods are limited at a field scale. Therefore, an alternative approach is needed. In this study, we investigated the potential of hyperspectral techniques to identify fungi-infected vs. healthy plants of Vitis vinifera. We used the hyperspectral imaging sensor Specim-IQ to acquire leaves’ reflectance data of the Teroldego Rotaliano grapevine cultivar. We analyzed three different groups of plants: healthy, asymptomatic, and diseased. Highly significant differences were found in the near-infrared (NIR) spectral region with a decreasing pattern from healthy to diseased plants attributable to the leaf mesophyll changes. Asymptomatic plants emerged from the other groups due to a lower reflectance in the red edge spectrum (around 705 nm), ascribable to an accumulation of secondary metabolites involved in plant defense strategies. Further significant differences were observed in the wavelengths close to 550 nm in diseased vs. asymptomatic plants. We evaluated several machine learning paradigms to differentiate the plant groups. The Naïve Bayes (NB) algorithm, combined with the most discriminant variables among vegetation indices and spectral narrow bands, provided the best results with an overall accuracy of 90% and 75% in healthy vs. diseased and healthy vs. asymptomatic plants, respectively. To our knowledge, this study represents the first report on the possibility of using hyperspectral data for root rot disease diagnosis in woody plants. Although further validation studies are required, it appears that the spectral reflectance technique, possibly implemented on unmanned aerial vehicles (UAVs), could be a promising tool for a cost-effective, non-invasive method of Armillaria disease diagnosis and mapping in-field, contributing to a significant step forward in precision viticulture.},
DOI = {10.3390/rs13132436}
}



@Article{ijgi10070426,
AUTHOR = {Lan, Tingting and Qin, Danyang and Sun, Guanyu},
TITLE = {Joint Optimization on Trajectory, Cache Placement, and Transmission Power for Minimum Mission Time in UAV-Aided Wireless Networks},
JOURNAL = {ISPRS International Journal of Geo-Information},
VOLUME = {10},
YEAR = {2021},
NUMBER = {7},
ARTICLE-NUMBER = {426},
URL = {https://www.mdpi.com/2220-9964/10/7/426},
ISSN = {2220-9964},
ABSTRACT = {In recent years, due to the strong mobility, easy deployment, and low cost of unmanned aerial vehicles (UAV), great interest has arisen in utilizing UAVs to assist in wireless communication, especially for on-demand deployment in emergency situations and temporary events. However, UAVs can only provide users with data transmission services through wireless backhaul links established with a ground base station, and the limited capacity of the wireless backhaul link would limit the transmission speed of UAVs. Therefore, this paper designed a UAV-assisted wireless communication system that used cache technology and realized the transmission of multi-user data by using the mobility of UAVs and wireless cache technology. Considering the limited storage space and energy of UAVs, the joint optimization problem of the UAV’s trajectory, cache placement, and transmission power was established to minimize the mission time of the UAV. Since this problem was a non-convex problem, it was decomposed into three sub-problems: trajectory optimization, cache placement optimization, and power allocation optimization. An iterative algorithm based on the successive convex approximation and alternate optimization techniques was proposed to solve these three optimization problems. Finally, in the power allocation optimization, the proposed algorithm was improved by changing the optimization objective function. Numerical results showed that the algorithm had good performance and could effectively reduce the task completion time of the UAV.},
DOI = {10.3390/ijgi10070426}
}



@Article{app11135911,
AUTHOR = {Martos, Vanesa and Ahmad, Ali and Cartujo, Pedro and Ordoñez, Javier},
TITLE = {Ensuring Agricultural Sustainability through Remote Sensing in the Era of Agriculture 5.0},
JOURNAL = {Applied Sciences},
VOLUME = {11},
YEAR = {2021},
NUMBER = {13},
ARTICLE-NUMBER = {5911},
URL = {https://www.mdpi.com/2076-3417/11/13/5911},
ISSN = {2076-3417},
ABSTRACT = {Timely and reliable information about crop management, production, and yield is considered of great utility by stakeholders (e.g., national and international authorities, farmers, commercial units, etc.) to ensure food safety and security. By 2050, according to Food and Agriculture Organization (FAO) estimates, around 70% more production of agricultural products will be needed to fulfil the demands of the world population. Likewise, to meet the Sustainable Development Goals (SDGs), especially the second goal of “zero hunger”, potential technologies like remote sensing (RS) need to be efficiently integrated into agriculture. The application of RS is indispensable today for a highly productive and sustainable agriculture. Therefore, the present study draws a general overview of RS technology with a special focus on the principal platforms of this technology, i.e., satellites and remotely piloted aircrafts (RPAs), and the sensors used, in relation to the 5th industrial revolution. Nevertheless, since 1957, RS technology has found applications, through the use of satellite imagery, in agriculture, which was later enriched by the incorporation of remotely piloted aircrafts (RPAs), which is further pushing the boundaries of proficiency through the upgrading of sensors capable of higher spectral, spatial, and temporal resolutions. More prominently, wireless sensor technologies (WST) have streamlined real time information acquisition and programming for respective measures. Improved algorithms and sensors can, not only add significant value to crop data acquisition, but can also devise simulations on yield, harvesting and irrigation periods, metrological data, etc., by making use of cloud computing. The RS technology generates huge sets of data that necessitate the incorporation of artificial intelligence (AI) and big data to extract useful products, thereby augmenting the adeptness and efficiency of agriculture to ensure its sustainability. These technologies have made the orientation of current research towards the estimation of plant physiological traits rather than the structural parameters possible. Futuristic approaches for benefiting from these cutting-edge technologies are discussed in this study. This study can be helpful for researchers, academics, and young students aspiring to play a role in the achievement of sustainable agriculture.},
DOI = {10.3390/app11135911}
}



@Article{rs13132483,
AUTHOR = {Meng, Baoping and Yang, Zhigui and Yu, Hongyan and Qin, Yu and Sun, Yi and Zhang, Jianguo and Chen, Jianjun and Wang, Zhiwei and Zhang, Wei and Li, Meng and Lv, Yanyan and Yi, Shuhua},
TITLE = {Mapping of Kobresia pygmaea Community Based on Umanned Aerial Vehicle Technology and Gaofen Remote Sensing Data in Alpine Meadow Grassland: A Case Study in Eastern of Qinghai–Tibetan Plateau},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {13},
ARTICLE-NUMBER = {2483},
URL = {https://www.mdpi.com/2072-4292/13/13/2483},
ISSN = {2072-4292},
ABSTRACT = {The Kobresia pygmaea (KP) community is a key succession stage of alpine meadow degradation on the Qinghai–Tibet Plateau (QTP). However, most of the grassland classification and mapping studies have been performed at the grassland type level. The spatial distribution and impact factors of KP on the QTP are still unclear. In this study, field measurements of the grassland vegetation community in the eastern part of the QTP (Counties of Zeku, Henan and Maqu) from 2015 to 2019 were acquired using unmanned aerial vehicle (UAV) technology. The machine learning algorithms for grassland vegetation community classification were constructed by combining Gaofen satellite images and topographic indices. Then, the spatial distribution of KP community was mapped. The results showed that: (1) For all field observed sites, the alpine meadow vegetation communities demonstrated a considerable spatial heterogeneity. The traditional classification methods can hardly distinguish those communities due to the high similarity of their spectral characteristics. (2) The random forest method based on the combination of satellite vegetation indices, texture feature and topographic indices exhibited the best performance in three counties, with overall accuracy and Kappa coefficient ranged from 74.06% to 83.92% and 0.65 to 0.80, respectively. (3) As a whole, the area of KP community reached 1434.07 km2, and accounted for 7.20% of the study area. We concluded that the combination of satellite remote sensing, UAV surveying and machine learning can be used for KP classification and mapping at community level.},
DOI = {10.3390/rs13132483}
}



@Article{rs13132482,
AUTHOR = {Zamboni, Pedro and Junior, José Marcato and Silva, Jonathan de Andrade and Miyoshi, Gabriela Takahashi and Matsubara, Edson Takashi and Nogueira, Keiller and Gonçalves, Wesley Nunes},
TITLE = {Benchmarking Anchor-Based and Anchor-Free State-of-the-Art Deep Learning Methods for Individual Tree Detection in RGB High-Resolution Images},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {13},
ARTICLE-NUMBER = {2482},
URL = {https://www.mdpi.com/2072-4292/13/13/2482},
ISSN = {2072-4292},
ABSTRACT = {Urban forests contribute to maintaining livability and increase the resilience of cities in the face of population growth and climate change. Information about the geographical distribution of individual trees is essential for the proper management of these systems. RGB high-resolution aerial images have emerged as a cheap and efficient source of data, although detecting and mapping single trees in an urban environment is a challenging task. Thus, we propose the evaluation of novel methods for single tree crown detection, as most of these methods have not been investigated in remote sensing applications. A total of 21 methods were investigated, including anchor-based (one and two-stage) and anchor-free state-of-the-art deep-learning methods. We used two orthoimages divided into 220 non-overlapping patches of 512 × 512 pixels with a ground sample distance (GSD) of 10 cm. The orthoimages were manually annotated, and 3382 single tree crowns were identified as the ground-truth. Our findings show that the anchor-free detectors achieved the best average performance with an AP50 of 0.686. We observed that the two-stage anchor-based and anchor-free methods showed better performance for this task, emphasizing the FSAF, Double Heads, CARAFE, ATSS, and FoveaBox models. RetinaNet, which is currently commonly applied in remote sensing, did not show satisfactory performance, and Faster R-CNN had lower results than the best methods but with no statistically significant difference. Our findings contribute to a better understanding of the performance of novel deep-learning methods in remote sensing applications and could be used as an indicator of the most suitable methods in such applications.},
DOI = {10.3390/rs13132482}
}



@Article{rs13132486,
AUTHOR = {Ouhami, Maryam and Hafiane, Adel and Es-Saady, Youssef and El Hajji, Mohamed and Canals, Raphael},
TITLE = {Computer Vision, IoT and Data Fusion for Crop Disease Detection Using Machine Learning: A Survey and Ongoing Research},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {13},
ARTICLE-NUMBER = {2486},
URL = {https://www.mdpi.com/2072-4292/13/13/2486},
ISSN = {2072-4292},
ABSTRACT = {Crop diseases constitute a serious issue in agriculture, affecting both quality and quantity of agriculture production. Disease control has been a research object in many scientific and technologic domains. Technological advances in sensors, data storage, computing resources and artificial intelligence have shown enormous potential to control diseases effectively. A growing body of literature recognizes the importance of using data from different types of sensors and machine learning approaches to build models for detection, prediction, analysis, assessment, etc. However, the increasing number and diversity of research studies requires a literature review for further developments and contributions in this area. This paper reviews state-of-the-art machine learning methods that use different data sources, applied to plant disease detection. It lists traditional and deep learning methods associated with the main data acquisition modalities, namely IoT, ground imaging, unmanned aerial vehicle imaging and satellite imaging. In addition, this study examines the role of data fusion for ongoing research in the context of disease detection. It highlights the advantage of intelligent data fusion techniques, from heterogeneous data sources, to improve plant health status prediction and presents the main challenges facing this field. The study concludes with a discussion of several current issues and research trends.},
DOI = {10.3390/rs13132486}
}



@Article{e23070812,
AUTHOR = {Fu, Wei and Yu, Shuang and Wang, Xin},
TITLE = {A Novel Method to Determine Basic Probability Assignment Based on Adaboost and Its Application in Classification},
JOURNAL = {Entropy},
VOLUME = {23},
YEAR = {2021},
NUMBER = {7},
ARTICLE-NUMBER = {812},
URL = {https://www.mdpi.com/1099-4300/23/7/812},
PubMedID = {34202212},
ISSN = {1099-4300},
ABSTRACT = {In the framework of evidence theory, one of the open and crucial issues is how to determine the basic probability assignment (BPA), which is directly related to whether the decision result is correct. This paper proposes a novel method for obtaining BPA based on Adaboost. The method uses training data to generate multiple strong classifiers for each attribute model, which is used to determine the BPA of the singleton proposition since the weights of classification provide necessary information for fundamental hypotheses. The BPA of the composite proposition is quantified by calculating the area ratio of the singleton proposition’s intersection region. The recursive formula of the area ratio of the intersection region is proposed, which is very useful for computer calculation. Finally, BPAs are combined by Dempster’s rule of combination. Using the proposed method to classify the Iris dataset, the experiment concludes that the total recognition rate is 96.53% and the classification accuracy is 90% when the training percentage is 10%. For the other datasets, the experiment results also show that the proposed method is reasonable and effective, and the proposed method performs well in the case of insufficient samples.},
DOI = {10.3390/e23070812}
}



@Article{s21134363,
AUTHOR = {Nabwire, Shona and Suh, Hyun-Kwon and Kim, Moon S. and Baek, Insuck and Cho, Byoung-Kwan},
TITLE = {Review: Application of Artificial Intelligence in Phenomics},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {13},
ARTICLE-NUMBER = {4363},
URL = {https://www.mdpi.com/1424-8220/21/13/4363},
PubMedID = {34202291},
ISSN = {1424-8220},
ABSTRACT = {Plant phenomics has been rapidly advancing over the past few years. This advancement is attributed to the increased innovation and availability of new technologies which can enable the high-throughput phenotyping of complex plant traits. The application of artificial intelligence in various domains of science has also grown exponentially in recent years. Notably, the computer vision, machine learning, and deep learning aspects of artificial intelligence have been successfully integrated into non-invasive imaging techniques. This integration is gradually improving the efficiency of data collection and analysis through the application of machine and deep learning for robust image analysis. In addition, artificial intelligence has fostered the development of software and tools applied in field phenotyping for data collection and management. These include open-source devices and tools which are enabling community driven research and data-sharing, thereby availing the large amounts of data required for the accurate study of phenotypes. This paper reviews more than one hundred current state-of-the-art papers concerning AI-applied plant phenotyping published between 2010 and 2020. It provides an overview of current phenotyping technologies and the ongoing integration of artificial intelligence into plant phenotyping. Lastly, the limitations of the current approaches/methods and future directions are discussed.},
DOI = {10.3390/s21134363}
}



@Article{electronics10131549,
AUTHOR = {Shrestha, Rakesh and Omidkar, Atefeh and Roudi, Sajjad Ahmadi and Abbas, Robert and Kim, Shiho},
TITLE = {Machine-Learning-Enabled Intrusion Detection System for Cellular Connected UAV Networks},
JOURNAL = {Electronics},
VOLUME = {10},
YEAR = {2021},
NUMBER = {13},
ARTICLE-NUMBER = {1549},
URL = {https://www.mdpi.com/2079-9292/10/13/1549},
ISSN = {2079-9292},
ABSTRACT = {The recent development and adoption of unmanned aerial vehicles (UAVs) is due to its wide variety of applications in public and private sector from parcel delivery to wildlife conservation. The integration of UAVs, 5G, and satellite technologies has prompted telecommunication networks to evolve to provide higher-quality and more stable service to remote areas. However, security concerns with UAVs are growing as UAV nodes are becoming attractive targets for cyberattacks due to enormously growing volumes and poor and weak inbuilt security. In this paper, we propose a UAV- and satellite-based 5G-network security model that can harness machine learning to effectively detect of vulnerabilities and cyberattacks. The solution is divided into two main parts: the model creation for intrusion detection using various machine learning (ML) algorithms and the implementation of ML-based model into terrestrial or satellite gateways. The system identifies various attack types using realistic CSE-CIC IDS-2018 network datasets published by Canadian Establishment for Cybersecurity (CIC). It consists of seven different types of new and contemporary attack types. This paper demonstrates that ML algorithms can be used to classify benign or malicious packets in UAV networks to enhance security. Finally, the tested ML algorithms are compared for effectiveness in terms of accuracy rate, precision, recall, F1-score, and false-negative rate. The decision tree algorithm performed well by obtaining a maximum accuracy rate of 99.99% and a minimum false negative rate of 0% in detecting various attacks as compared to all other types of ML classifiers.},
DOI = {10.3390/electronics10131549}
}



@Article{rs13132496,
AUTHOR = {Khoroshevsky, Faina and Khoroshevsky, Stanislav and Bar-Hillel, Aharon},
TITLE = {Parts-per-Object Count in Agricultural Images: Solving Phenotyping Problems via a Single Deep Neural Network},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {13},
ARTICLE-NUMBER = {2496},
URL = {https://www.mdpi.com/2072-4292/13/13/2496},
ISSN = {2072-4292},
ABSTRACT = {Solving many phenotyping problems involves not only automatic detection of objects in an image, but also counting the number of parts per object. We propose a solution in the form of a single deep network, tested for three agricultural datasets pertaining to bananas-per-bunch, spikelets-per-wheat-spike, and berries-per-grape-cluster. The suggested network incorporates object detection, object resizing, and part counting as modules in a single deep network, with several variants tested. The detection module is based on a Retina-Net architecture, whereas for the counting modules, two different architectures are examined: the first based on direct regression of the predicted count, and the other on explicit parts detection and counting. The results are promising, with the mean relative deviation between estimated and visible part count in the range of 9.2% to 11.5%. Further inference of count-based yield related statistics is considered. For banana bunches, the actual banana count (including occluded bananas) is inferred from the count of visible bananas. For spikelets-per-wheat-spike, robust estimation methods are employed to get the average spikelet count across the field, which is an effective yield estimator.},
DOI = {10.3390/rs13132496}
}



@Article{s21134408,
AUTHOR = {Salehi Hikouei, Iman and Kim, S. Sonny and Mishra, Deepak R.},
TITLE = {Machine-Learning Classification of Soil Bulk Density in Salt Marsh Environments},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {13},
ARTICLE-NUMBER = {4408},
URL = {https://www.mdpi.com/1424-8220/21/13/4408},
PubMedID = {34199102},
ISSN = {1424-8220},
ABSTRACT = {Remotely sensed data from both in situ and satellite platforms in visible, near-infrared, and shortwave infrared (VNIR–SWIR, 400–2500 nm) regions have been widely used to characterize and model soil properties in a direct, cost-effective, and rapid manner at different scales. In this study, we assess the performance of machine-learning algorithms including random forest (RF), extreme gradient boosting machines (XGBoost), and support vector machines (SVM) to model salt marsh soil bulk density using multispectral remote-sensing data from the Landsat-7 Enhanced Thematic Mapper Plus (ETM+) platform. To our knowledge, use of remote-sensing data for estimating salt marsh soil bulk density at the vegetation rooting zone has not been investigated before. Our study reveals that blue (band 1; 450–520 nm) and NIR (band 4; 770–900 nm) bands of Landsat-7 ETM+ ranked as the most important spectral features for bulk density prediction by XGBoost and RF, respectively. According to XGBoost, band 1 and band 4 had relative importance of around 41% and 39%, respectively. We tested two soil bulk density classes in order to differentiate salt marshes in terms of their capability to support vegetation that grows in either low (0.032 to 0.752 g/cm3) or high (0.752 g/cm3 to 1.893 g/cm3) bulk density areas. XGBoost produced a higher classification accuracy (88%) compared to RF (87%) and SVM (86%), although discrepancies in accuracy between these models were small (&lt;2%). XGBoost correctly classified 178 out of 186 soil samples labeled as low bulk density and 37 out of 62 soil samples labeled as high bulk density. We conclude that remote-sensing-based machine-learning models can be a valuable tool for ecologists and engineers to map the soil bulk density in wetlands to select suitable sites for effective restoration and successful re-establishment practices.},
DOI = {10.3390/s21134408}
}



@Article{s21134417,
AUTHOR = {Ukaegbu, Uchechi F. and Tartibu, Lagouge K. and Okwu, Modestus O. and Olayode, Isaac O.},
TITLE = {Development of a Light-Weight Unmanned Aerial Vehicle for Precision Agriculture},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {13},
ARTICLE-NUMBER = {4417},
URL = {https://www.mdpi.com/1424-8220/21/13/4417},
PubMedID = {34203187},
ISSN = {1424-8220},
ABSTRACT = {This paper describes the development of a modular unmanned aerial vehicle for the detection and eradication of weeds on farmland. Precision agriculture entails solving the problem of poor agricultural yield due to competition for nutrients by weeds and provides a faster approach to eliminating the problematic weeds using emerging technologies. This research has addressed the aforementioned problem. A quadcopter was built, and components were assembled with light-weight materials. The system consists of the electric motor, electronic speed controller, propellers, frame, lithium polymer (li-po) battery, flight controller, a global positioning system (GPS), and receiver. A sprayer module which consists of a relay, Raspberry Pi 3, spray pump, 12 V DC source, water hose, and the tank was built. It operated in such a way that when a weed is detected based on the deep learning algorithms deployed on the Raspberry Pi, general purpose input/output (GPIO) 17 or GPIO 18 (of the Raspberry Pi) were activated to supply 3.3 V, which turned on a DC relay to spray herbicides accordingly. The sprayer module was mounted on the quadcopter and from the test-running operation conducted, broadleaf and grass weeds were accurately detected and the spraying of herbicides according to the weed type occurred in less than a second.},
DOI = {10.3390/s21134417}
}



@Article{rs13132523,
AUTHOR = {Gili, Piero and Civera, Marco and Roy, Rinto and Surace, Cecilia},
TITLE = {An Unmanned Lighter-Than-Air Platform for Large Scale Land Monitoring},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {13},
ARTICLE-NUMBER = {2523},
URL = {https://www.mdpi.com/2072-4292/13/13/2523},
ISSN = {2072-4292},
ABSTRACT = {The concept and preliminary design of an unmanned lighter-than-air (LTA) platform instrumented with different remote sensing technologies is presented. The aim is to assess the feasibility of using a remotely controlled airship for the land monitoring of medium sized (up to 107 m2) urban or rural areas at relatively low altitudes (below 1000 m) and its potential convenience with respect to other standard remote and in-situ sensing systems. The proposal includes equipment for high-definition visual, thermal, and hyperspectral imaging as well as LiDAR scanning. The data collected from these different sources can be then combined to obtain geo-referenced products such as land use land cover (LULC), soil water content (SWC), land surface temperature (LSC), and leaf area index (LAI) maps, among others. The potential uses for diffuse structural health monitoring over built-up areas are discussed as well. Several mission typologies are considered.},
DOI = {10.3390/rs13132523}
}



@Article{jsan10030042,
AUTHOR = {Al-Nuaimi, Mohammed and Wibowo, Sapto and Qu, Hongyang and Aitken, Jonathan and Veres, Sandor},
TITLE = {Hybrid Verification Technique for Decision-Making of Self-Driving Vehicles},
JOURNAL = {Journal of Sensor and Actuator Networks},
VOLUME = {10},
YEAR = {2021},
NUMBER = {3},
ARTICLE-NUMBER = {42},
URL = {https://www.mdpi.com/2224-2708/10/3/42},
ISSN = {2224-2708},
ABSTRACT = {The evolution of driving technology has recently progressed from active safety features and ADAS systems to fully sensor-guided autonomous driving. Bringing such a vehicle to market requires not only simulation and testing but formal verification to account for all possible traffic scenarios. A new verification approach, which combines the use of two well-known model checkers: model checker for multi-agent systems (MCMAS) and probabilistic model checker (PRISM), is presented for this purpose. The overall structure of our autonomous vehicle (AV) system consists of: (1) A perception system of sensors that feeds data into (2) a rational agent (RA) based on a belief–desire–intention (BDI) architecture, which uses a model of the environment and is connected to the RA for verification of decision-making, and (3) a feedback control systems for following a self-planned path. MCMAS is used to check the consistency and stability of the BDI agent logic during design-time. PRISM is used to provide the RA with the probability of success while it decides to take action during run-time operation. This allows the RA to select movements of the highest probability of success from several generated alternatives. This framework has been tested on a new AV software platform built using the robot operating system (ROS) and virtual reality (VR) Gazebo Simulator. It also includes a parking lot scenario to test the feasibility of this approach in a realistic environment. A practical implementation of the AV system was also carried out on the experimental testbed.},
DOI = {10.3390/jsan10030042}
}



@Article{s21134442,
AUTHOR = {Niu, Zijie and Deng, Juntao and Zhang, Xu and Zhang, Jun and Pan, Shijia and Mu, Haotian},
TITLE = {Identifying the Branch of Kiwifruit Based on Unmanned Aerial Vehicle (UAV) Images Using Deep Learning Method},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {13},
ARTICLE-NUMBER = {4442},
URL = {https://www.mdpi.com/1424-8220/21/13/4442},
PubMedID = {34209571},
ISSN = {1424-8220},
ABSTRACT = {It is important to obtain accurate information about kiwifruit vines to monitoring their physiological states and undertake precise orchard operations. However, because vines are small and cling to trellises, and have branches laying on the ground, numerous challenges exist in the acquisition of accurate data for kiwifruit vines. In this paper, a kiwifruit canopy distribution prediction model is proposed on the basis of low-altitude unmanned aerial vehicle (UAV) images and deep learning techniques. First, the location of the kiwifruit plants and vine distribution are extracted from high-precision images collected by UAV. The canopy gradient distribution maps with different noise reduction and distribution effects are generated by modifying the threshold and sampling size using the resampling normalization method. The results showed that the accuracies of the vine segmentation using PSPnet, support vector machine, and random forest classification were 71.2%, 85.8%, and 75.26%, respectively. However, the segmentation image obtained using depth semantic segmentation had a higher signal-to-noise ratio and was closer to the real situation. The average intersection over union of the deep semantic segmentation was more than or equal to 80% in distribution maps, whereas, in traditional machine learning, the average intersection was between 20% and 60%. This indicates the proposed model can quickly extract the vine distribution and plant position, and is thus able to perform dynamic monitoring of orchards to provide real-time operation guidance.},
DOI = {10.3390/s21134442}
}



@Article{s21134447,
AUTHOR = {Shin, Jisun and Jo, Young-Heon and Ryu, Joo-Hyung and Khim, Boo-Keun and Kim, Soo Mee},
TITLE = {High Spatial-Resolution Red Tide Detection in the Southern Coast of Korea Using U-Net from PlanetScope Imagery},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {13},
ARTICLE-NUMBER = {4447},
URL = {https://www.mdpi.com/1424-8220/21/13/4447},
PubMedID = {34209710},
ISSN = {1424-8220},
ABSTRACT = {Red tides caused by Margalefidinium polykrikoides occur continuously along the southern coast of Korea, where there are many aquaculture cages, and therefore, prompt monitoring of bloom water is required to prevent considerable damage. Satellite-based ocean-color sensors are widely used for detecting red tide blooms, but their low spatial resolution restricts coastal observations. Contrarily, terrestrial sensors with a high spatial resolution are good candidate sensors, despite the lack of spectral resolution and bands for red tide detection. In this study, we developed a U-Net deep learning model for detecting M. polykrikoides blooms along the southern coast of Korea from PlanetScope imagery with a high spatial resolution of 3 m. The U-Net model was trained with four different datasets that were constructed with randomly or non-randomly chosen patches consisting of different ratios of red tide and non-red tide pixels. The qualitative and quantitative assessments of the conventional red tide index (RTI) and four U-Net models suggest that the U-Net model, which was trained with a dataset of non-randomly chosen patches including non-red tide patches, outperformed RTI in terms of sensitivity, precision, and F-measure level, accounting for an increase of 19.84%, 44.84%, and 28.52%, respectively. The M. polykrikoides map derived from U-Net provides the most reasonable red tide patterns in all water areas. Combining high spatial resolution images and deep learning approaches represents a good solution for the monitoring of red tides over coastal regions.},
DOI = {10.3390/s21134447}
}



@Article{rs13132548,
AUTHOR = {Habibi, Luthfan Nur and Watanabe, Tomoya and Matsui, Tsutomu and Tanaka, Takashi S. T.},
TITLE = {Machine Learning Techniques to Predict Soybean Plant Density Using UAV and Satellite-Based Remote Sensing},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {13},
ARTICLE-NUMBER = {2548},
URL = {https://www.mdpi.com/2072-4292/13/13/2548},
ISSN = {2072-4292},
ABSTRACT = {The plant density of soybean is a critical factor affecting plant canopy structure and yield. Predicting the spatial variability of plant density would be valuable for improving agronomic practices. The objective of this study was to develop a model for plant density measurement using several data sets with different spatial resolutions, including unmanned aerial vehicle (UAV) imagery, PlanetScope satellite imagery, and climate data. The model establishment process includes (1) performing the high-throughput measurement of actual plant density from UAV imagery with the You Only Look Once version 3 (YOLOv3) object detection algorithm, which was further treated as a response variable of the estimation models in the next step, and (2) developing regression models to estimate plant density in the extended areas using various combinations of predictors derived from PlanetScope imagery and climate data. Our results showed that the YOLOv3 model can accurately measure actual soybean plant density from UAV imagery data with a root mean square error (RMSE) value of 0.96 plants m−2. Furthermore, the two regression models, partial least squares and random forest (RF), successfully expanded the plant density prediction areas with RMSE values ranging from 1.78 to 3.67 plant m−2. Model improvement was conducted using the variable importance feature in RF, which improved prediction accuracy with an RMSE value of 1.72 plant m−2. These results demonstrated that the established model had an acceptable prediction accuracy for estimating plant density. Although the model could not often evaluate the within-field spatial variability of soybean plant density, the predicted values were sufficient for informing the field-specific status.},
DOI = {10.3390/rs13132548}
}



@Article{rs13132555,
AUTHOR = {Yoosefzadeh-Najafabadi, Mohsen and Tulpan, Dan and Eskandari, Milad},
TITLE = {Using Hybrid Artificial Intelligence and Evolutionary Optimization Algorithms for Estimating Soybean Yield and Fresh Biomass Using Hyperspectral Vegetation Indices},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {13},
ARTICLE-NUMBER = {2555},
URL = {https://www.mdpi.com/2072-4292/13/13/2555},
ISSN = {2072-4292},
ABSTRACT = {Recent advanced high-throughput field phenotyping combined with sophisticated big data analysis methods have provided plant breeders with unprecedented tools for a better prediction of important agronomic traits, such as yield and fresh biomass (FBIO), at early growth stages. This study aimed to demonstrate the potential use of 35 selected hyperspectral vegetation indices (HVI), collected at the R5 growth stage, for predicting soybean seed yield and FBIO. Two artificial intelligence algorithms, ensemble-bagging (EB) and deep neural network (DNN), were used to predict soybean seed yield and FBIO using HVI. Considering HVI as input variables, the coefficients of determination (R2) of 0.76 and 0.77 for yield and 0.91 and 0.89 for FBIO were obtained using DNN and EB, respectively. In this study, we also used hybrid DNN-SPEA2 to estimate the optimum HVI values in soybeans with maximized yield and FBIO productions. In addition, to identify the most informative HVI in predicting yield and FBIO, the feature recursive elimination wrapper method was used and the top ranking HVI were determined to be associated with red, 670 nm and near-infrared, 800 nm, regions. Overall, this study introduced hybrid DNN-SPEA2 as a robust mathematical tool for optimizing and using informative HVI for estimating soybean seed yield and FBIO at early growth stages, which can be employed by soybean breeders for discriminating superior genotypes in large breeding populations.},
DOI = {10.3390/rs13132555}
}



@Article{app11136112,
AUTHOR = {Mbiydzenyuy, Gideon and Nowaczyk, Sławomir and Knutsson, Håkan and Vanhoudt, Dirk and Brage, Jens and Calikus, Ece},
TITLE = {Opportunities for Machine Learning in District Heating},
JOURNAL = {Applied Sciences},
VOLUME = {11},
YEAR = {2021},
NUMBER = {13},
ARTICLE-NUMBER = {6112},
URL = {https://www.mdpi.com/2076-3417/11/13/6112},
ISSN = {2076-3417},
ABSTRACT = {The district heating (DH) industry is facing an important transformation towards more efficient networks that utilise significantly lower water temperatures to distribute the heat. This change requires taking advantage of new technologies, and Machine Learning (ML) is a popular direction. In the last decade, we have witnessed an extreme growth in the number of published research papers that focus on applying ML techniques to the DH domain. However, based on our experience in the field, and an extensive review of the state-of-the-art, we perceive a mismatch between the most popular research directions, such as forecasting, and the challenges faced by the DH industry. In this work, we present our findings, explain and demonstrate the key gaps between the two communities and suggest a road-map ahead towards increasing the impact of ML research in the DH industry.},
DOI = {10.3390/app11136112}
}



@Article{info12070272,
AUTHOR = {Ackerson, Joseph M. and Dave, Rushit and Seliya, Naeem},
TITLE = {Applications of Recurrent Neural Network for Biometric Authentication &amp; Anomaly Detection},
JOURNAL = {Information},
VOLUME = {12},
YEAR = {2021},
NUMBER = {7},
ARTICLE-NUMBER = {272},
URL = {https://www.mdpi.com/2078-2489/12/7/272},
ISSN = {2078-2489},
ABSTRACT = {Recurrent Neural Networks are powerful machine learning frameworks that allow for data to be saved and referenced in a temporal sequence. This opens many new possibilities in fields such as handwriting analysis and speech recognition. This paper seeks to explore current research being conducted on RNNs in four very important areas, being biometric authentication, expression recognition, anomaly detection, and applications to aircraft. This paper reviews the methodologies, purpose, results, and the benefits and drawbacks of each proposed method below. These various methodologies all focus on how they can leverage distinct RNN architectures such as the popular Long Short-Term Memory (LSTM) RNN or a Deep-Residual RNN. This paper also examines which frameworks work best in certain situations, and the advantages and disadvantages of each proposed model.},
DOI = {10.3390/info12070272}
}



@Article{telecom2030017,
AUTHOR = {Pourroostaei Ardakani, Saeid and Cheshmehzangi, Ali},
TITLE = {Reinforcement Learning-Enabled UAV Itinerary Planning for Remote Sensing Applications in Smart Farming},
JOURNAL = {Telecom},
VOLUME = {2},
YEAR = {2021},
NUMBER = {3},
PAGES = {255--270},
URL = {https://www.mdpi.com/2673-4001/2/3/17},
ISSN = {2673-4001},
ABSTRACT = {UAV path planning for remote sensing aims to find the best-fitted routes to complete a data collection mission. UAVs plan the routes and move through them to remotely collect environmental data from particular target zones by using sensory devices such as cameras. Route planning may utilize machine learning techniques to autonomously find/select cost-effective and/or best-fitted routes and achieve optimized results including: minimized data collection delay, reduced UAV power consumption, decreased flight traversed distance and maximized number of collected data samples. This paper utilizes a reinforcement learning technique (location and energy-aware Q-learning) to plan UAV routes for remote sensing in smart farms. Through this, the UAV avoids heuristically or blindly moving throughout a farm, but this takes the benefits of environment exploration–exploitation to explore the farm and find the shortest and most cost-effective paths into target locations with interesting data samples to collect. According to the simulation results, utilizing the Q-learning technique increases data collection robustness and reduces UAV resource consumption (e.g., power), traversed paths, and remote sensing latency as compared to two well-known benchmarks, IEMF and TBID, especially if the target locations are dense and crowded in a farm.},
DOI = {10.3390/telecom2030017}
}



@Article{aerospace8070179,
AUTHOR = {Swinney, Carolyn J. and Woods, John C.},
TITLE = {The Effect of Real-World Interference on CNN Feature Extraction and Machine Learning Classification of Unmanned Aerial Systems},
JOURNAL = {Aerospace},
VOLUME = {8},
YEAR = {2021},
NUMBER = {7},
ARTICLE-NUMBER = {179},
URL = {https://www.mdpi.com/2226-4310/8/7/179},
ISSN = {2226-4310},
ABSTRACT = {Small unmanned aerial systems (UASs) present many potential solutions and enhancements to industry today but equally pose a significant security challenge. We only need to look at the levels of disruption caused by UASs at airports in recent years. The accuracy of UAS detection and classification systems based on radio frequency (RF) signals can be hindered by other interfering signals present in the same frequency band, such as Bluetooth and Wi-Fi devices. In this paper, we evaluate the effect of real-world interference from Bluetooth and Wi-Fi signals concurrently on convolutional neural network (CNN) feature extraction and machine learning classification of UASs. We assess multiple UASs that operate using different transmission systems: Wi-Fi, Lightbridge 2.0, OcuSync 1.0, OcuSync 2.0 and the recently released OcuSync 3.0. We consider 7 popular UASs, evaluating 2 class UAS detection, 8 class UAS type classification and 21 class UAS flight mode classification. Our results show that the process of CNN feature extraction using transfer learning and machine learning classification is fairly robust in the presence of real-world interference. We also show that UASs that are operating using the same transmission system can be distinguished. In the presence of interference from both Bluetooth and Wi-Fi signals, our results show 100% accuracy for UAV detection (2 classes), 98.1% (+/−0.4%) for UAV type classification (8 classes) and 95.4% (+/−0.3%) for UAV flight mode classification (21 classes).},
DOI = {10.3390/aerospace8070179}
}




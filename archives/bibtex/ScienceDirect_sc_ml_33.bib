@article{GUPTA201878,
title = {Big data with cognitive computing: A review for the future},
journal = {International Journal of Information Management},
volume = {42},
pages = {78-89},
year = {2018},
issn = {0268-4012},
doi = {https://doi.org/10.1016/j.ijinfomgt.2018.06.005},
url = {https://www.sciencedirect.com/science/article/pii/S0268401218304110},
author = {Shivam Gupta and Arpan Kumar Kar and Abdullah Baabdullah and Wassan A.A. Al-Khowaiter},
keywords = {Big data, Cognitive computing, Literature review, Resource based View, Institutional theory},
abstract = {Analysis of data by humans can be a time-consuming activity and thus use of sophisticated cognitive systems can be utilized to crunch this enormous amount of data. Cognitive computing can be utilized to reduce the shortcomings of the concerns faced during big data analytics. The aim of the study is to provide readers a complete understanding of past, present and future directions in the domain big data and cognitive computing. A systematic literature review has been adopted for this study by using the Scopus, DBLP and Web of Science databases. The work done in the field of big data and cognitive computing is currently at the nascent stage and this is evident from the publication record. The characteristics of cognitive computing, namely observation, interpretation, evaluation and decision were mapped to the five V’s of big data namely volume, variety, veracity, velocity and value. Perspectives which touch all these parameters are yet to be widely explored in existing literature.}
}
@article{BANERJEE201717,
title = {Whose online reviews to trust? Understanding reviewer trustworthiness and its impact on business},
journal = {Decision Support Systems},
volume = {96},
pages = {17-26},
year = {2017},
issn = {0167-9236},
doi = {https://doi.org/10.1016/j.dss.2017.01.006},
url = {https://www.sciencedirect.com/science/article/pii/S0167923617300155},
author = {Shankhadeep Banerjee and Samadrita Bhattacharyya and Indranil Bose},
keywords = {Online reviews, Predictive model, Regression analysis, Reviewer characteristics, Trustworthiness, Yelp, Electronic word-of-mouth, Online reviewers, Online trust},
abstract = {Why do top movie reviewers receive invitations to exclusive screenings? Even popular technology bloggers get free new gadgets for reviewing. How much do these reviewers really matter for businesses? While the impact of online reviews on sales of products and services has been well established, not much literature is available on impact of reviewers for businesses. Source credibility theory expounds how a communication's persuasiveness is affected by the perceived credibility of its source. So, perceived trustworthiness of reviewers should influence acceptance of reviews, and consequently should have an indirect impact on sales. Using local business review data from Yelp.com, this paper successfully tests the premise that reviewer trustworthiness positively moderates the impact of review-based online reputation on business patronages. Given the importance of reviewer trustworthiness, the next logical question is – how to estimate and predict it, if no direct proxy is available? We propose a theoretical model with several reviewer characteristics (positivity, involvement, experience, reputation, competence, sociability) affecting reviewer trustworthiness, and find all factors to be significant using the robust regression method. Further, using these factors, a predictive classification of reviewers into high and low level of potential trustworthiness is done using logistic regression with nearly 83% accuracy. Our findings have several implications - firstly, businesses should focus on building a good review-based online reputation; secondly, they should encourage top trustworthy reviewers to review their products and services; and thirdly, trustworthy reviewers could be identified and ranked using reviewer characteristics.}
}
@article{BHAVIN2021102673,
title = {Blockchain and quantum blind signature-based hybrid scheme for healthcare 5.0 applications},
journal = {Journal of Information Security and Applications},
volume = {56},
pages = {102673},
year = {2021},
issn = {2214-2126},
doi = {https://doi.org/10.1016/j.jisa.2020.102673},
url = {https://www.sciencedirect.com/science/article/pii/S2214212620308255},
author = {Makwana Bhavin and Sudeep Tanwar and Navneet Sharma and Sudhanshu Tyagi and Neeraj Kumar},
keywords = {Quantum computing, Blockchain, Quantum blind signature, Healthcare},
abstract = {Insurance agencies and digitally recorded healthcare databases can help society to decrease the high-level complexity and the cost of the entire healthcare ecosystem. The general data protection regulation provides the right to its data owner’s to know how data is stored, and for which purpose his/her data is being used. However, the healthcare data flow through an open channel, i.e., the Internet, which opens the doors for intruders to perform some malicious activities, such as breach of confidential data, modification in the stored data, etc. So it is a challenging task for the traditional healthcare systems to maintain the security and privacy of the stakeholders. Blockchain is emerged as a technology that improves the efficiency of today’s healthcare system and also helps to maintain the security and privacy of all the stakeholders. Motivated by these facts, in this paper, we analyse various security architectures used to secure electronic health records (EHRs) and apply Quantum Computing (QC) to the traditional encryption system. Then, we propose a blockchain-based architecture for Healthcare, which allows users to access the data from the database with their defined role. Further, to protect the traditional encryption system from the quantum attacks, the Quantum blind signature is used during the block creation using hyperledger Fabric blockchain. Results show the efficacy of the proposed scheme compared to the state-of-the-art schemes in terms of transaction throughput, resource consumption, and network traffic.}
}
@article{WILLIAMS2020178,
title = {Electricity demand forecasting for decentralised energy management},
journal = {Energy and Built Environment},
volume = {1},
number = {2},
pages = {178-186},
year = {2020},
issn = {2666-1233},
doi = {https://doi.org/10.1016/j.enbenv.2020.01.001},
url = {https://www.sciencedirect.com/science/article/pii/S2666123320300076},
author = {Sean Williams and Michael Short},
keywords = {Demand response, Decentralised, Grid edge, Time series forecasting},
abstract = {The world is experiencing a fourth industrial revolution. Rapid development of technologies is advancing smart infrastructure opportunities. Experts observe decarbonisation, digitalisation and decentralisation as the main drivers for change. In electrical power systems a downturn of centralised conventional fossil fuel fired power plants and increased proportion of distributed power generation adds to the already troublesome outlook for operators of low-inertia energy systems. In the absence of reliable real-time demand forecasting measures, effective decentralised demand-side energy planning is often problematic. In this work we formulate a simple yet highly effective lumped model for forecasting the rate at which electricity is consumed. The methodology presented focuses on the potential adoption by a regional electricity network operator with inadequate real-time energy data who requires knowledge of the wider aggregated future rate of energy consumption. Thus, contributing to a reduction in the demand of state-owned generation power plants. The forecasting session is constructed initially through analysis of a chronological sequence of discrete observations. Historical demand data shows behaviour that allows the use of dimensionality reduction techniques. Combined with piecewise interpolation an electricity demand forecasting methodology is formulated. Solutions of short-term forecasting problems provide credible predictions for energy demand. Calculations for medium-term forecasts that extend beyond 6-months are also very promising. The forecasting method provides a way to advance a novel decentralised informatics, optimisation and control framework for small island power systems or distributed grid-edge systems as part of an evolving demand response service.}
}
@article{KARLESSI20171316,
title = {The Concept of Smart and NZEB Buildings and the Integrated Design Approach},
journal = {Procedia Engineering},
volume = {180},
pages = {1316-1325},
year = {2017},
note = {International High-Performance Built Environment Conference – A Sustainable Built Environment Conference 2016 Series (SBE16), iHBE 2016},
issn = {1877-7058},
doi = {https://doi.org/10.1016/j.proeng.2017.04.294},
url = {https://www.sciencedirect.com/science/article/pii/S1877705817318015},
author = {Theoni Karlessi and Nikos Kampelis and Denia Kolokotsa and Mat Santamouris and Laura Standardi and D. Isidori and C. Cristalli},
keywords = {Smart building, smart grid, integrated energy design, zero energy concept},
abstract = {As we are nowadays experiencing a transition period for the energy demand, there is a clear movement of the European energy market towards a new field of efficiency including reliable and smart systems that will upgrade the improvement of Europe's economic and environmental health. To this end smart systems introduce innovative applications with multiple and interdisciplinary characteristics: safe integration of additional renewables, distribution to the network, efficient delivery systems and monitoring control through demand response in order to achieve zero energy targets. The integration of smart technologies requires a holistic approach that takes into account all aspects of sustainability. The implementation of highly efficient smart buildings is feasible through the integration of smart metering, renewable systems acting as generators/storage and energy management. The holistic system supports and fulfils demand load management and distribution network of future grids.. Moreover, the benefits of effective thermal and electrical storage are underlined as a crucial factor of smart systems and smart buildings. This paper highlights the principles of integrated design procedure and links the process with smart building technologies. Energy efficiency methodologies and innovative techniques applied at building level are presented. To this context current EU policy framework, trends and perspectives concerning integrated design as a supportive tool for zero energy concept are also provided.}
}
@article{HAMMOUD202121,
title = {Stable federated fog formation: An evolutionary game theoretical approach},
journal = {Future Generation Computer Systems},
volume = {124},
pages = {21-32},
year = {2021},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2021.05.021},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X21001710},
author = {Ahmad Hammoud and Hadi Otrok and Azzam Mourad and Zbigniew Dziong},
keywords = {Evolutionary game theory, Federated fog, Fog computing, Stability, IoT},
abstract = {Instability within fog federations is considered as a serious problem that degrades the performance of the provided services. The latter may affect the service availability due to fog providers withdrawing their resources. It may either lead to failures for some users invocations, or to an increase in the number of tasks inside the servers’ processing-queue. Such a critical problem strips the fog paradigm from its main characteristic, the low latency factor. As far as we are aware, no work in the literature has addressed the problem of encountering unstable fog federations. Their main concerns were increasing the providers’ payoff regardless of their behavior. To address the aforementioned limitation, this work studies the stability of the federations through modeling the problem as an evolutionary game-theoretical model. Moreover, it devises a decentralized algorithm that implants the Replicator Dynamics model within which expresses the evolutionary dynamics. Experiments are conducted using EUA Datasets to simulate our algorithm and to show that it leads to an evolutionarily stable strategy over time, which stabilizes the federations and improves the Quality-of-Service for the users.}
}
@article{MISHRA2019217,
title = {An adaptive model for resource selection and allocation in fog computing environment},
journal = {Computers & Electrical Engineering},
volume = {77},
pages = {217-229},
year = {2019},
issn = {0045-7906},
doi = {https://doi.org/10.1016/j.compeleceng.2019.05.010},
url = {https://www.sciencedirect.com/science/article/pii/S0045790618307262},
author = {Manoj Kumar Mishra and Niranjan Kumar Ray and Amulya Ratna Swain and Ganga Bishnu Mund and Bhabani Sankar Prasad Mishra},
keywords = {Fog computing, Distributed computing, Multi-criteria decision-making (MCDM), PROMETHEE-II, Recommender systems, Adaptive-MCDM},
abstract = {Fog computing is a computing infrastructure that supports data distribution between cloud and source in an efficient manner. Building an effective and generalized model for efficient resource selection and allocation mechanism seems to be complex in fog computing. Allocation and selection mechanisms in such environment fall into a class of multi-criteria decision-making (MCDM) problems. The existing MCDM methods may not be suitable for fog computing environment as these problems are distributed, scalable and dynamic. We propose an adaptive multi-criteria decision-making (A-MCDM) model to obtain an optimal ranking of alternatives in dynamic and scalable environments. The time complexity of the proposed A-MCDM is O(nm) in general, and it takes only O(m) time to assign a rank to an alternative where n is the number of criteria and m is the number of alternatives. The performance of the proposed model has been analyzed and found to be better than other MCDM methods.}
}
@article{LIU2021102672,
title = {‘Solving for X?’ Towards a problem-finding framework to ground long-term governance strategies for artificial intelligence},
journal = {Futures},
volume = {126},
pages = {102672},
year = {2021},
issn = {0016-3287},
doi = {https://doi.org/10.1016/j.futures.2020.102672},
url = {https://www.sciencedirect.com/science/article/pii/S0016328720301634},
author = {Hin-Yan Liu and Matthijs M. Maas},
keywords = {Problem-finding, Governance puzzles, Governance disruptors, Macrostrategic trajectories & destinations, Governance goldilocks zone, Artificial intelligence},
abstract = {Change is hardly a new feature in human affairs. Yet something has begun to change in change. In the face of a range of emerging, complex, and interconnected global challenges, society’s collective governance efforts may need to be put on a different footing. Many of these challenges derive from emerging technological developments – take Artificial Intelligence (AI), the focus of much contemporary governance scholarship and efforts. AI governance strategies have predominantly oriented themselves towards clear, discrete clusters of pre-defined problems. We argue that such ‘problem-solving’ approaches may be necessary, but are also insufficient in the face of many of the ‘wicked problems’ created or driven by AI. Accordingly, we propose in this paper a complementary framework for grounding long-term governance strategies for complex emerging issues such as AI into a ‘problem-finding’ orientation. We first provide a rationale by sketching the range of policy problems created by AI, and providing five reasons why problem-solving governance approaches to these challenges fail or fall short. We conversely argue that that creative, ‘problem-finding’ research into these governance challenges is not only warranted scientifically, but will also be critical in the formulation of governance strategies that are effective, meaningful, and resilient over the long-term. We accordingly illustrate the relation between and the complementarity of problem-solving and problem-finding research, by articulating a framework that distinguishes between four distinct ‘levels’ of governance: problem-solving research generally approaches AI (governance) issues from a perspective of (Level 0) ‘business-as-usual’ or as (Level 1) ‘governance puzzle-solving’. In contrast, problem-finding approaches emphasize (Level 2) ‘governance Disruptor-Finding’; or (Level 3) ‘Charting Macrostrategic Trajectories’. We apply this theoretical framework to contemporary governance debates around AI throughout our analysis to elaborate upon and to better illustrate our framework. We conclude with reflections on nuances, implications, and shortcomings of this long-term governance framework, offering a range of observations on intra-level failure modes, between-level complementarities, within-level path dependencies, and the categorical boundary conditions of governability (‘Governance Goldilocks Zone’). We suggest that this framework can help underpin more holistic approaches for long-term strategy-making across diverse policy domains and contexts, and help cross the bridge between concrete policies on local solutions, and longer-term considerations of path-dependent societal trajectories to avert, or joint visions towards which global communities can or should be rallied.}
}
@article{GUO2021103947,
title = {Planning and application of underground logistics systems in new cities and districts in China},
journal = {Tunnelling and Underground Space Technology},
volume = {113},
pages = {103947},
year = {2021},
issn = {0886-7798},
doi = {https://doi.org/10.1016/j.tust.2021.103947},
url = {https://www.sciencedirect.com/science/article/pii/S0886779821001383},
author = {Dongjun Guo and Yicun Chen and Jingsheng Yang and Yoong Heng Tan and Chenhao Zhang and Zhilong Chen},
keywords = {Underground logistics system, New cities and districts, Urban planning, Application},
abstract = {Underground logistics systems (ULSs) has been an important topic and research hotspot for urban underground space use in China, especially for implementation in new cities and districts, as it is a necessary element to be considered for city underground space planning. Since these newly planned areas will face many challenges, including increasing logistics volume, spatial constraints etc. if we use the existing freight transport modes similar to old cities. Furthermore, the rapid developments of Chinese new cities provides an opportunity to implement innovative ULS freight transport systems and technology that are efficient and sustainable. Recently, ULS has been included officially in the planning and study for Beijing’s Sub-Center, the Yangtze River Demonstration District and other new cities and districts. However, the real value of ULS will not materialize unless it is successfully implemented. This paper presents the exploration, observations and findings of a few proposed ULS planning and research works in the new districts mentioned. The suitability of goods and freight types in ULS, logistic flow demand forecasting and ULS network systems integrated with underground metro or infrastructure are discussed. Both dedicated and integrated ULS network systems are also compared and analyzed. Despite the many advantages, many challenges and difficulties remain in the planning integration, technology adaptation and implementation of ULSs in new districts and cities, thus, interdisciplinary collaborations is one of the key success factors to ensure ULS can be brought to fruition.}
}
@article{LING20222,
title = {A graph-matching approach for cross-view registration of over-view and street-view based point clouds},
journal = {ISPRS Journal of Photogrammetry and Remote Sensing},
volume = {185},
pages = {2-15},
year = {2022},
issn = {0924-2716},
doi = {https://doi.org/10.1016/j.isprsjprs.2021.12.013},
url = {https://www.sciencedirect.com/science/article/pii/S0924271622000065},
author = {Xiao Ling and Rongjun Qin},
keywords = {Cross-view registration, Global optimization, Multi-view satellite image},
abstract = {Wide-area 3D data generation for complex urban environments often needs to leverage a mixed use of data collected from both air and ground platforms, such as from aerial surveys, satellite, and mobile vehicles. On one hand, such kind of data with information from drastically different views (ca. 90° and more) forming cross-view data, which due to very limited overlapping region caused by the drastically different line of sight of the sensors, is difficult to be registered without significant manual efforts. On the other hand, the registration of such data often suffers from non-rigid distortion of the street-view data (e.g., non-rigid trajectory drift), which cannot be simply rectified by a similarity transformation. In this paper, based on the assumption that the object boundaries (e.g., buildings) from the over-view data should coincide with footprints of façade 3D points generated from street-view photogrammetric images, we aim to address this problem by proposing a fully automated geo-registration method for cross-view data, which utilizes semantically segmented object boundaries as view-invariant features under a global optimization framework through graph-matching: taking the over-view point clouds generated from stereo/multi-stereo satellite images and the street-view point clouds generated from monocular video images as the inputs, the proposed method models segments of buildings as nodes of graphs, both detected from the satellite-based and street-view based point clouds, thus to form the registration as a graph-matching problem to allow non-rigid matches; to enable a robust solution and fully utilize the topological relations between these segments, we propose to address the graph-matching problem on its conjugate graph solved through a belief-propagation algorithm. The matched nodes will be subject to a further optimization to allow precise-registration, followed by a constrained bundle adjustment on the street-view image to keep 2D-3D consistencies, which yields well-registered street-view images and point clouds to the satellite point clouds. Our proposed method assumes no or little prior pose information (e.g. very sparse locations from consumer-grade GPS (global positioning system)) for the street-view data and has been applied to a large cross-view dataset with significant scale difference containing 0.5 m GSD (Ground Sampling Distance) satellite data and 0.005 m GSD street-view data, 1.5 km in length involving 12 GB of data. The experiment shows that the proposed method has achieved promising results (1.27 m accuracy in 3D), evaluated using collected LiDAR point clouds. Furthermore, we included additional experiments to demonstrate that this method can be generalized to process different types of over-view and street-view data sources, e.g., the open street view maps and the semantic labeling maps.}
}
@article{CAPELLA2020e00095,
title = {IoT & environmental analytical chemistry: Towards a profitable symbiosis},
journal = {Trends in Environmental Analytical Chemistry},
volume = {27},
pages = {e00095},
year = {2020},
issn = {2214-1588},
doi = {https://doi.org/10.1016/j.teac.2020.e00095},
url = {https://www.sciencedirect.com/science/article/pii/S2214158820300234},
author = {Juan V. Capella and Alberto Bonastre and José C. Campelo and Rafael Ors and Miguel Peris},
keywords = {Environmental analytical chemistry, Internet of things, Cloud computing, Future trends, Ambient intelligence, Advanced sensing systems},
abstract = {In a constantly evolving world, where the rising population and increased social awareness have led to a higher concern for the environment, research in this field (most notably in Environmental Analytical Chemistry) should take advantage of the great opportunities offered by new technologies such as Internet of Things (IoT) and Cloud-based services. Both of them are especially suitable when chemical sensors and related devices are used in the continuous in-line monitoring of environmental parameters. In this sense, it is very important to obtain spatially distributed information of these parameters as well as their temporal evolution. In this work, a friendly approach to IoT world for environmental applications is carried out. To get a global vision of these concepts, the starting point is their historical evolution. New trends are also identified along with associated challenges and potential threats. Furthermore, not only there will be (in the near future) a need to rely on distributed analytical sensors but also on even more complex, lab-based techniques that are connected to the IoT through appropriate mechanisms. A revision of the recent literature relating IoT with environmental issues has also been performed, the most relevant contributions being discussed. Finally, the need of a mutual cooperation between IoT and Environmental Analytical Chemistry is outlined and commented in detail. Ignoring the new capabilities offered by Cloud computing and IoT environments is no further an option. In this sense, the main contribution of this paper consists of highlighting the fact that the wiser course is to embrace these opportunities consciously for mutual profit.}
}
@article{TSAI201839,
title = {A parallel metaheuristic data clustering framework for cloud},
journal = {Journal of Parallel and Distributed Computing},
volume = {116},
pages = {39-49},
year = {2018},
note = {Towards the Internet of Data: Applications, Opportunities and Future Challenges},
issn = {0743-7315},
doi = {https://doi.org/10.1016/j.jpdc.2017.10.020},
url = {https://www.sciencedirect.com/science/article/pii/S0743731517302964},
author = {Chun-Wei Tsai and Shi-Jui Liu and Yi-Chung Wang},
keywords = {Metaheuristic algorithm, Internet of things, Data clustering problem},
abstract = {A high performance data analytics for internet of things (IoT) has been a promising research subject in recent years because traditional data mining algorithms may not be applicable to big data of IoT. One of the main reasons is that the data that need to be analyzed may exceed the storage size of a single machine. The computation cost of data analysis tasks that is too high for a single computer system is another critical problem we have to confront when analyzing data from an IoT system. That is why an efficient data clustering framework for metaheuristic algorithm on a cloud computing environment is presented in this paper for data analytics, which explains how to divide mining tasks of a mining algorithm into different nodes (i.e., the Map process) and then aggregate the mining results from these nodes (i.e., Reduce process). We further attempted to use the proposed framework to implement data clustering algorithms (e.g., k-means, genetic k-means, and particle swarm optimization) on a standalone system and Spark. The experimental results show that the performance of the proposed framework makes it useful to develop data clustering algorithms on a cloud computing environment.}
}
@article{LIU2022105824,
title = {Spatiotemporal evolution differences of urban green space: A comparative case study of Shanghai and Xuchang in China},
journal = {Land Use Policy},
volume = {112},
pages = {105824},
year = {2022},
issn = {0264-8377},
doi = {https://doi.org/10.1016/j.landusepol.2021.105824},
url = {https://www.sciencedirect.com/science/article/pii/S0264837721005470},
author = {Jie Liu and Lang Zhang and Qingping Zhang and Chao Li and Guilian Zhang and Yuncai Wang},
keywords = {Urban green space, Spatiotemporal evolution, Morphological structure, Fractal dimension, Greening policy},
abstract = {Urban green spaces (UGS) are vital for developing and evolving natural elements in urban spaces. The UGS information of a megacity behemoth (Shanghai) from 1996, 2006, and 2016, and a small and medium-sized city (Xuchang) from 2010, 2015, and 2019 was used as the basic data. The UGS evolution spatiotemporal characteristics were analyzed using the area change index, spatial morphological dimension, and spatial aggregation dimension. The changes of greening policies for UGS evolution in the two cities were compared. The results indicated that: (1) the UGS in downtown Shanghai mainly developed southwards from 1996 to 2006, then northeastwards and northwestwards. The UGS in downtown Xuchang mainly developed northeastwards and northwards between 2010 and 2019; (2) the spatial morphological dimensions of UGS in downtown Shanghai gradually increased indicating the UGS had systematic coordination and stability. The spatial morphological dimensions of UGS in downtown Xuchang first increased then decreased, indicating that the UGS tended to be integrated and systematic; (3) the spatial aggregation dimensions of UGS in downtown Shanghai decreased first and then increased, and the focus of UGS construction shifted from the center to the suburbs. The spatial aggregation dimensions of UGS in downtown Xuchang gradually increased, and the spatial distribution of UGS tended to be multi-center clustered; and, (4) under the guidance of greening policies, UGS evolution in Shanghai was progressive with stronger self-organization ability, while that in Xuchang leaped forward with weaker self-organization ability. The research results can provide a reference for other similar sized cities in UGS planning and government decision-making.}
}
@article{TSAI2016529,
title = {Photo sundial: Estimating the time of capture in consumer photos},
journal = {Neurocomputing},
volume = {177},
pages = {529-542},
year = {2016},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2015.11.050},
url = {https://www.sciencedirect.com/science/article/pii/S0925231215018457},
author = {Tsung-Hung Tsai and Wei-Cih Jhou and Wen-Huang Cheng and Min-Chun Hu and I-Chao Shen and Tekoing Lim and Kai-Lung Hua and Ahmed Ghoneim and M. Anwar Hossain and Shintami C. Hidayati},
keywords = {Photo time estimation, Camera parameters, Sun modeling},
abstract = {The time of capture of consumer photos provides rich information in temporal context and has been widely employed for solving various multimedia problems, such as multimedia retrieval and social media analysis. However, we observed that the recorded time stamp in a consumer photo does not often correspond to the true local time at which the photo was taken. This would greatly damage the robustness of time-aware multimedia applications, such as travel route recommendation. Therefore, motivated by the use of traditional sundials, this work proposes a system, Photo Sundial, for estimating the time of capture by exploiting the astronomical theory. In particular, we infer the time by establishing its relations to the measurable astronomical factors from a given outdoor photo, i.e. the sun position in the sky and the camera viewing direction in the photo-taken location. In practice, since it is more often that people would take multiple photos in a single trip, we further develop an optimization framework to jointly estimate the time from multiple photos. Experimental results show that the average estimated time error is less than 0.9h by the proposed approach, with a significant 65% relative improvement compared to the state-of-the-art method (2.5h). To the best of our knowledge, this work is the first study in multimedia research to explicitly address the problem of time of capture estimation in consumer photos, and the achieved performances highly encourage our system for practical applications.}
}
@article{DUCHBROWN2020111612,
title = {Digital platforms across the European regional energy markets},
journal = {Energy Policy},
volume = {144},
pages = {111612},
year = {2020},
issn = {0301-4215},
doi = {https://doi.org/10.1016/j.enpol.2020.111612},
url = {https://www.sciencedirect.com/science/article/pii/S0301421520303499},
author = {Néstor Duch-Brown and Fiammetta Rossetti},
keywords = {Energy, Energy union, European policies, Digital single market, Digital transformation, Platforms},
abstract = {Digital platforms increasingly propose business models that improve economic organisation -by better coordinating supply and demand under imperfect information- and attain higher efficiency levels. At the same time, the energy generation gradually reshapes into decentralised network with lower capacity, but able to manage demand and supply in real-time. However, the penetration of online platforms within the energy sector poses policy questions that are specific to platforms' business models. This study investigates a sample of 217 digital platforms running energy-related activities across the EU regional markets. These energy platforms make about 20% of the world energy platforms. By observing their characteristics and those of their surrounding markets, it appears that the digital platforms in the European energy sector still tend to be relatively small and concentrated in specific regions, often in the neighbourhood of capital cities. Furthermore, the quantitative analysis suggests that market size, digital readiness and regulatory quality are the most important features relating to platforms' presence in the EU regional markets. This paper offers empirical evidence and reflections to provide energy policy with key information to best ripe the potential of new technologies while being aware of their inherited complexities.}
}
@article{PISCITELLI2019113727,
title = {Recognition and classification of typical load profiles in buildings with non-intrusive learning approach},
journal = {Applied Energy},
volume = {255},
pages = {113727},
year = {2019},
issn = {0306-2619},
doi = {https://doi.org/10.1016/j.apenergy.2019.113727},
url = {https://www.sciencedirect.com/science/article/pii/S030626191931414X},
author = {Marco Savino Piscitelli and Silvio Brandi and Alfonso Capozzoli},
keywords = {Building energy management, Customer classification, Load profiling, Data mining, Energy benchmarking},
abstract = {The recent increasing spread of Advanced Metering Infrastructure (AMI) has enabled the collection of a huge amount of building related-data which can be exploited by both energy suppliers and users to gain insight on energy consumption patterns. In this context, data analytics-based methodologies can play a key role for performing advanced characterization, benchmarking and classification of buildings according to their typical energy use in the time domain. Traditionally, energy customers are classified according to their building end-use category. However, buildings belonging to the same category can exhibit very different energy patterns making ineffective this kind of a-priori categorization. For this reason, load profiling frameworks have been developed in the last decade to identify homogenous groups of buildings with similar daily energy profiles. The present study proposes a non-intrusive customer classification process, which does not use as predictive attributes in-field load monitoring data for the classification of unknown customers, but rather monthly energy bills and additional information on customers’ habits collected by means of a phone survey. The proposed classification process is developed by analysing hourly energy consumption data of 114 electrical customers of an Italian Energy Provider. The representative daily load profiles are grouped using the “Follow the Leader” clustering algorithm and a globally optimal decision tree is employed to build a supervised classification model. The model, compared to a baseline recursive partitioning tree, leads to an increase of accuracy of about 6%. Eventually, the procedure exploits energy bill data also for estimating the magnitude of typical load profiles.}
}
@article{CORRADINI2022338,
title = {A two-tier Blockchain framework to increase protection and autonomy of smart objects in the IoT},
journal = {Computer Communications},
volume = {181},
pages = {338-356},
year = {2022},
issn = {0140-3664},
doi = {https://doi.org/10.1016/j.comcom.2021.10.028},
url = {https://www.sciencedirect.com/science/article/pii/S0140366421004084},
author = {Enrico Corradini and Serena Nicolazzo and Antonino Nocera and Domenico Ursino and Luca Virgili},
keywords = {Internet of Things, Blockchain, Protection, Autonomy, Reliability, Trust, Reputation},
abstract = {In recent years, the Internet of Things paradigm has become pervasive in everyday life attracting the interest of the research community. Two of the most important challenges to be addressed concern the protection of smart objects and the need to guarantee them a great autonomy. For this purpose, the definition of trust and reputation mechanisms appears crucial. At the same time, several researchers have started to adopt a common distributed ledger, such as a Blockchain, for building advanced solutions in the IoT. However, due to the high dimensionality of this problem, enabling a trust and reputation mechanism by leveraging a Blockchain-based technology could give rise to several performance issues in the IoT. In this paper, we propose a two-tier Blockchain framework to increase the security and autonomy of smart objects in the IoT by implementing a trust-based protection mechanism. In this framework, smart objects are suitably grouped into communities. To reduce the complexity of the solution, the first-tier Blockchain is local and is used only to record probing transactions performed to evaluate the trust of an object in another one of the same community or of a different community. Periodically, after a time window, these transactions are aggregated and the obtained values are stored in the second-tier Blockchain. Specifically, stored values are the reputation of each object inside its community and the trust of each community in the other ones of the framework. In this paper, we describe in detail our framework, its behavior, the security model associated with it and the tests carried out to evaluate its correctness and performance.}
}
@article{POOJARA202291,
title = {Serverless data pipeline approaches for IoT data in fog and cloud computing},
journal = {Future Generation Computer Systems},
volume = {130},
pages = {91-105},
year = {2022},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2021.12.012},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X21004933},
author = {Shivananda R. Poojara and Chinmaya Kumar Dehury and Pelle Jakovits and Satish Narayana Srirama},
keywords = {Serverless computing, Data pipelines, Cloud computing, Fog computing, Edge computing, Internet of things},
abstract = {With the increasing number of Internet of Things (IoT) devices, massive amounts of raw data is being generated. The latency, cost, and other challenges in cloud-based IoT data processing have driven the adoption of Edge and Fog computing models, where some data processing tasks are moved closer to data sources. Properly dealing with the flow of such data requires building data pipelines, to control the complete life cycle of data streams from data acquisition at the data source, edge and fog processing, to Cloud side storage and analytics. Data analytics tasks need to be executed dynamically at different distances from the data sources and often on very heterogeneous hardware devices. This can be streamlined by the use of a Serverless (or FaaS) cloud computing model, where tasks are defined as virtual functions, which can be migrated from edge to cloud (and vice versa) and executed in an event-driven manner on data streams. In this work, we investigate the benefits of building Serverless data pipelines (SDP) for IoT data analytics and evaluate three different approaches for designing SDPs: (1) Off-the-shelf data flow tool (DFT) based, (2) Object storage service (OSS) based and (3) MQTT based. Further, we applied these strategies on three fog applications (Aeneas, PocketSphinx, and custom Video processing application) and evaluated the performance by comparing their processing time (computation time, network communication and disk access time), and resource utilization. Results show that DFT is unsuitable for compute-intensive applications such as video or image processing, whereas OSS is best suitable for this task. However, DFT is nicely fit for bandwidth-intensive applications due to the minimum use of network resources. On the other hand, MQTT-based SDP is observed with increase in CPU and Memory usage as the number of users rose, and experienced a drop in data units in the pipeline for PocketSphinx and custom video processing applications, however it performed well for Aeneas which had low size data units.}
}
@article{CANITEZ2019319,
title = {Pathways to sustainable urban mobility in developing megacities: A socio-technical transition perspective},
journal = {Technological Forecasting and Social Change},
volume = {141},
pages = {319-329},
year = {2019},
issn = {0040-1625},
doi = {https://doi.org/10.1016/j.techfore.2019.01.008},
url = {https://www.sciencedirect.com/science/article/pii/S0040162518309880},
author = {Fatih Canitez},
keywords = {Sustainable urban mobility, Socio-technical systems, Multi-level perspective, Transition, Developing megacities, Istanbul},
abstract = {Sustainable urban mobility paradigm has recently gained prominence in both developed and developing cities, yet the transition process raises important concerns and issues. Socio-technical transition perspective provides a useful way to interpret the social and technical dynamics and complexities involved in sustainability transitions. However, the context of developing megacities presents significant differences with that of the developed cities in terms of institutional settings, governance structures, and urban mobility challenges. This paper proposes a socio-technical transition perspective to examine and analyze the urban mobility systems in developing megacities. In addition, a multi-level perspective is offered to understand the dynamics of sustainable urban mobility transitions. The case study of Istanbul, a developing megacity having a population of nearly 15 million people with many urban mobility problems such as chronic traffic congestion, overcrowded public buses, traffic accidents and injuries, air and noise pollution, helps substantiate the proposed socio-technical perspective. The theoretical insights and empirical findings strongly suggest the potential usefulness of this perspective for other megacities grappling with similar problems.}
}
@article{YU2020106306,
title = {A novel case adaptation method based on differential evolution algorithm for disaster emergency},
journal = {Applied Soft Computing},
volume = {92},
pages = {106306},
year = {2020},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2020.106306},
url = {https://www.sciencedirect.com/science/article/pii/S1568494620302465},
author = {Xiaobing Yu and Chenliang Li and Wen-Xuan Zhao and Hong Chen},
keywords = {Case-based reasoning, Differential evolution algorithm, Disaster emergency, Adaptation},
abstract = {When disasters happen, time is often very urgent. Case-based reasoning (CBR) is one of the most effective approaches to support disaster emergency management. CBR takes good use of historical case data, which is one of the typical data-driven decision-making methods. Among the steps of CBR, adaptation is the core. To improve the adaptation, a hybrid mutation operator is implemented, and a new differential evolution (DE) algorithm is developed. An adaptation method based on the proposed algorithm is put forward to achieve case adaptation in the CBR system. The comparison results have shown that the proposed algorithm is superior compared with the state-of-art algorithms. Then, experiments of CBR have revealed that the adaptation method can effectively generate appropriate solutions with the help of the proposed algorithm.}
}
@article{LI2020110742,
title = {Early validation of cyber–physical space systems via multi-concerns integration},
journal = {Journal of Systems and Software},
volume = {170},
pages = {110742},
year = {2020},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2020.110742},
url = {https://www.sciencedirect.com/science/article/pii/S0164121220301692},
author = {Nianyu Li and Christos Tsigkanos and Zhi Jin and Zhenjiang Hu and Carlo Ghezzi},
abstract = {Cyber–physical space systems are engineered systems operating within physical space with design requirements that depend on space, e.g., regarding location or movement behavior. They are built from and depend upon the seamless integration of computation and physical components. Typical examples include systems where software-driven agents such as mobile robots explore space and perform actions to complete particular missions. Design of such a system often depends on multiple concerns expressed by different stakeholders, capturing different aspects of the system. We propose a model-driven approach supporting (a) separation of concerns during design, (b) systematic and semi-automatic integration of separately modeled concerns, and finally (c) early validation via statistical model checking. We evaluate our approach over two different case studies of cyber–physical space systems.}
}
@article{ZHANG2018392,
title = {User-centric interdependent urban systems: Using time-of-day electricity usage data to predict morning roadway congestion},
journal = {Transportation Research Part C: Emerging Technologies},
volume = {92},
pages = {392-411},
year = {2018},
issn = {0968-090X},
doi = {https://doi.org/10.1016/j.trc.2018.05.008},
url = {https://www.sciencedirect.com/science/article/pii/S0968090X18300810},
author = {Pinchao Zhang and Zhen (Sean) Qian},
keywords = {Data mining, Electricity use, Travel time prediction, Urban system interdependency},
abstract = {Urban systems are interdependent as individuals’ daily activities engage using those urban systems at certain time of day and locations. There may exist clear spatial and temporal correlations among usage patterns across all urban systems. This paper explores such a correlation among energy usage and roadway congestion. We propose a general framework to predict congestion starting time and congestion duration in the morning using the time-of-day electricity use data from anonymous households with no personally identifiable information. We show that using time-of-day electricity data from midnight to early morning from 322 households in the City of Austin, can make reliable prediction of congestion starting time of several highway segments, at the time as early as 2 am. This predictor significantly outperforms a time-series predictor that uses only real-time travel time data up to 6 am. We found that 8 out of the 10 typical electricity use patterns have statistically significant affects on morning congestion on highways in Austin. Some patterns have negative effects, represented by an early spike of electricity use followed by a drastic drop that could imply early departure from home. Others have positive effects, represented by a late night spike of electricity use possible implying late night activities that can lead to late morning departure from home.}
}
@article{CASINO201955,
title = {A systematic literature review of blockchain-based applications: Current status, classification and open issues},
journal = {Telematics and Informatics},
volume = {36},
pages = {55-81},
year = {2019},
issn = {0736-5853},
doi = {https://doi.org/10.1016/j.tele.2018.11.006},
url = {https://www.sciencedirect.com/science/article/pii/S0736585318306324},
author = {Fran Casino and Thomas K. Dasaklis and Constantinos Patsakis},
keywords = {Blockchain, Classification, Applications},
abstract = {This work provides a systematic literature review of blockchain-based applications across multiple domains. The aim is to investigate the current state of blockchain technology and its applications and to highlight how specific characteristics of this disruptive technology can revolutionise “business-as-usual” practices. To this end, the theoretical underpinnings of numerous research papers published in high ranked scientific journals during the last decade, along with several reports from grey literature as a means of streamlining our assessment and capturing the continuously expanding blockchain domain, are included in this review. Based on a structured, systematic review and thematic content analysis of the discovered literature, we present a comprehensive classification of blockchain-enabled applications across diverse sectors such as supply chain, business, healthcare, IoT, privacy, and data management, and we establish key themes, trends and emerging areas for research. We also point to the shortcomings identified in the relevant literature, particularly limitations the blockchain technology presents and how these limitations spawn across different sectors and industries. Building on these findings, we identify various research gaps and future exploratory directions that are anticipated to be of significant value both for academics and practitioners.}
}
@article{SICARI2020107345,
title = {5G In the internet of things era: An overview on security and privacy challenges},
journal = {Computer Networks},
volume = {179},
pages = {107345},
year = {2020},
issn = {1389-1286},
doi = {https://doi.org/10.1016/j.comnet.2020.107345},
url = {https://www.sciencedirect.com/science/article/pii/S1389128620300827},
author = {Sabrina Sicari and Alessandra Rizzardi and Alberto Coen-Porisini},
keywords = {5G, Internet of things, Fog computing, Blockchain, Security, Privacy},
abstract = {Now reaching 2020, the world is witnessing the initial diffusion of 5G networks, which promise to revolutionize the mobile wireless communications, providing faster services, very low delays, and a very pervasive connectivity via mobile devices. It is worth to remark that the main paradigm which will take advantage from 5G is really the Internet of Things (IoT). However, the spreading of 5G technology also generates important concerns in terms of security and privacy, due to the continuous and wireless connection to the network, which hinders the reliability of the involved devices. This paper deeply analyzed the current state of the art about the existing security and privacy solutions tailored to 5G. More in detail, the following requirements are discussed: data integrity, confidentiality, authentication, access control, non-repudiation, trust, privacy, identity management, key management, policy enforcement, and intrusion detection. Furthermore, the paper aims to shed the light on future research directions towards the realization of secure and privacy aware 5G systems. To this end, the role of emerging paradigms, such as IoT, fog computing, and blockchain is investigated.}
}
@article{HOSSEINIHAGHIGHI2022103640,
title = {Discovering, processing and consolidating housing stock and smart thermostat data in support of energy end-use mapping and housing retrofit program planning},
journal = {Sustainable Cities and Society},
volume = {78},
pages = {103640},
year = {2022},
issn = {2210-6707},
doi = {https://doi.org/10.1016/j.scs.2021.103640},
url = {https://www.sciencedirect.com/science/article/pii/S2210670721009033},
author = {Seyedehrabeeh Hosseinihaghighi and Karthik Panchabikesan and Sanam Dabirian and Jessica Webster and Mohamed Ouf and Ursula Eicker},
keywords = {Building and heating permits, Smart thermostat data, Systematic workflow, Simulation inputs, Energy mapping, Municipal housing retrofit program planning},
abstract = {There is growing interest in energy mapping amongst municipal planners and policymakers to accelerate greenhouse gas (GHG) emissions reduction program implementation. Responding to this interest partly involves addressing challenges related to building stock data collection and processing. The present study, carried out in conjunction with Natural Resources Canada's Canadian Energy End-use Mapping (CEE Map) project, aims to develop the inputs for housing energy modeling and mapping using property assessment data, building, heating permit data, and smart thermostat data. In this context, a systematic workflow is presented to extract useful information from various data sources to support housing energy simulations and municipal retrofit program planning. Permit data analysis supported refinement of housing data in Kelowna's urban digital twin. Results from building permit data analysis serve to update housing attributes including construction year and dwelling type. Results from heating permit analysis suggest that 17.5% of Kelowna dwellings could be potential candidates for heating system upgrades. Regarding thermostat setpoint temperature and occupancy for energy simulations, results obtained from smart thermostat data analysis were compared with EnerGuide Rating System (ERS) assumptions to investigate the potential improvements that can be made in energy simulation inputs. Comparative results indicated variations of up to 2 °C between smart thermostat data and EnerGuide assumptions for thermostat setpoint temperatures. Also, smart thermostat data suggests that 87% of dwellings were occupied for more than 50% of the time, whereas in ERS, occupancy is assumed to be 50%. Together, the overall data workflow and the detailed investigation of different datasets contributes to the development of a best practice methodology for housing energy modeling and mapping for municipalities in support of GHG emission reductions. Further, recommendations for permit data collection and scope for future research works are provided.}
}
@article{BHOYAR201981,
title = {Communication technologies and security challenges for internet of things: A comprehensive review},
journal = {AEU - International Journal of Electronics and Communications},
volume = {99},
pages = {81-99},
year = {2019},
issn = {1434-8411},
doi = {https://doi.org/10.1016/j.aeue.2018.11.031},
url = {https://www.sciencedirect.com/science/article/pii/S143484111831656X},
author = {Prachin Bhoyar and Parul Sahare and S.B. Dhok and R.B. Deshmukh},
keywords = {IoT, WSN, 3GPP, 5G, Security, Low power},
abstract = {‘Internet of things’ (IoT) realize a network of millions of connected devices like sensors, actuators and transceivers. Being a composite system, IoT must deal with the associated problems while meeting throughput, latency, energy consumption, and security criteria. In this work, wireless technologies have been classified based on the mechanisms of physical layer, media access control layer, and network layer. The fundamentals of wireless communication and all the non-trivial interests associated with these three layers are summarized with respect to the criteria imposed by IoT. Various security threats at these layers and vulnerabilities of the standards against such attacks have also been listed out. To mitigate these problems, instead of relying on any one particular solution, more emphasis is given on the integrated approach where layer-wise solutions are provided. Thereafter, a brief analysis of the available wireless communication standards and their salient features are discussed. Research scope and challenges in IoT applications ranging from low power, low data rate, short range to extended coverage are identified, followed by possible directions to be taken. Additionally, the third generation partnership project for low-power wide area solutions to meet the IoT requirements are analyzed in detail.}
}
@article{XU2022101729,
title = {Automatic detection of urban vacant land: An open-source approach for sustainable cities},
journal = {Computers, Environment and Urban Systems},
volume = {91},
pages = {101729},
year = {2022},
issn = {0198-9715},
doi = {https://doi.org/10.1016/j.compenvurbsys.2021.101729},
url = {https://www.sciencedirect.com/science/article/pii/S0198971521001368},
author = {Shaojuan Xu and Manfred Ehlers},
keywords = {Brownfield, Data fusion, Open source, Sustainable cities, Vacant land},
abstract = {With urban vacant land including brownfield land attracting increasing attention; spatial information on vacant land is crucial for city planners and decision-makers. Yet vacant land mapping faces the challenges of confusing terminology, reliance on inefficient registration systems, and the cost of data collection. Automatic site detection has been attempted using classification of remote sensing images. However, because the morphology of vacant land can cover such diverse aspects as derelict structures, bare soil, and vegetation or a mix thereof, even when commercial high-resolution images are used, it remains difficult to achieve this goal. This study starts by defining an urban vacant land typology suitable for automatic site detection. It covers four categories: transportation-associated land; natural sites with unfavorable conditions such as wetlands, steep slopes, or riverbanks; unattended areas or reserve parcels as “leftover spaces” within the urban fabric; and brownfield sites previously used but now abandoned. The study goes on to describe the rule-based data fusion method applied for site detection. The fusion procedure combines remote sensing images, GIS layers and citizen science data. For each type of vacant land, a separate data processing flow was developed. The method was tested in 63 urban and rural districts in Germany, identifying a large number of vacant sites. The study used an open-source approach. Open-source spatial data was collected for analysis, aerial photos provided by open-data projects were used for quality checks, and free software was used for data processing. This means that, information on vacant land is retrievable by local administrations irrespective of their financial circumstances. Depending on local urban development strategies, the detected sites can be used to support different sustainability goals.}
}
@article{MASON2017188,
title = {Multi-objective dynamic economic emission dispatch using particle swarm optimisation variants},
journal = {Neurocomputing},
volume = {270},
pages = {188-197},
year = {2017},
note = {Distributed Control and Optimization with Resource-Constrained Networked Systems},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2017.03.086},
url = {https://www.sciencedirect.com/science/article/pii/S0925231217310767},
author = {Karl Mason and Jim Duggan and Enda Howley},
keywords = {Constrained optimisation, Multi-objective, Swarm intelligence, Particle swarm optimisation, Dynamic economic emission dispatch, Power generation},
abstract = {Particle swarm optimisation (PSO) is a bio-inspired swarm based approach to solving optimisation problems. The algorithm functions as a result of particles traversing and evaluating the problem space, eventually converging on the optimum solution. This paper applies a number of PSO variants to the dynamic economic emission dispatch (DEED) problem. The DEED problem is a multi-objective optimisation problem in which the goal is to optimise two conflicting objectives: cost and emissions. The PSO variants tested include: the standard PSO (SPSO), the PSO with avoidance of worst locations (PSO AWL), and also a selection of different topologies including the PSO with a gradually increasing directed neighbourhood (PSO GIDN). The aim of the paper is to test the performance of different variants of the PSO AWL against variants of the SPSO on the DEED problem. The results show that the PSO AWL outperforms the SPSO for every topology implemented. The results are also compared to state of the art genetic algorithm (NSGA-II) and multi-agent eeinforcement learning (MARL). This paper then examines the performance of each PSO algorithm when the power demand is modified to form a triangle wave. The purpose of this experiment was to analyse the performance of different PSO variants on an increasingly constrained problem.}
}
@article{CAIAZZA2021108140,
title = {Measurement-driven design and runtime optimization in edge computing: Methodology and tools},
journal = {Computer Networks},
volume = {194},
pages = {108140},
year = {2021},
issn = {1389-1286},
doi = {https://doi.org/10.1016/j.comnet.2021.108140},
url = {https://www.sciencedirect.com/science/article/pii/S1389128621002085},
author = {Chiara Caiazza and Claudio Cicconetti and Valerio Luconi and Alessio Vecchio},
keywords = {Edge computing, ETSI MEC, Network measurements, GSMA platform operator},
abstract = {Edge computing is projected to become the dominant form of cloud computing in the future because of the significant advantages it brings to both users (less latency, higher throughput) and telecom operators (less Internet traffic, more local management). However, to fully unlock its potential at scale, system designers and automated optimization systems alike will have to monitor closely the dynamics of both processing and communication facilities. Especially the latter is often neglected in current systems since network performance in cloud computing plays only a minor role. In this paper, we propose the architecture of MECPerf, which is a solution to collect network measurements in a live edge computing domain, to be collected for offline provisioning analysis and simulations, or to be provided in real-time for on-line system optimization. MECPerf has been validated in a realistic testbed funded by the European Commission (Fed4Fire+), and we describe here a summary of the results, which are fully available as open data and through a Python library to expedite their utilization. This is demonstrated via a use case involving the optimization of a system parameter for migrating clients in a federated edge computing system adopting the GSMA platform operator concept.}
}
@article{DEEBAK2020102,
title = {A smart lightweight privacy preservation scheme for IoT-based UAV communication systems},
journal = {Computer Communications},
volume = {162},
pages = {102-117},
year = {2020},
issn = {0140-3664},
doi = {https://doi.org/10.1016/j.comcom.2020.08.016},
url = {https://www.sciencedirect.com/science/article/pii/S0140366420319034},
author = {B.D. Deebak and Fadi Al-Turjman},
keywords = {Unmanned aerial vehicle, Internet of drone, Authentication, Session-key agreement, Privacy-preserving},
abstract = {Unmanned Aerial Vehicle (UAV) has extensively been practiced in the military and civilian surveillance systems that access sensitive data over the cellular networks. However, channel insecurity and battery limitation may not protect the aerial coverage area. Thus, sensitive information gathered through aerial vehicles causes security threats. To manage the security issues, Smart Internet of Drone (S-IoD) have been evolved to use Intelligent Personal Assistant (IPA) as a software agent while monitoring and observing areas of interest. The current state-of-the-art technologies provide ubiquitous communication to enable several Internet of Things (IoT) paradigms. It achieves a feature of a decision support system that allows the smart interaction and communication between real-time entities. IPA offers smart interaction with other smart real-time entities to gain the user’s knowledge and awareness. This paper presents an S-IoD framework for a UAV environment that independently collects sensible information. In order to reduce the computation cost of the authentication protocol, a lightweight privacy-preserving scheme (L-PPS) is introduced. The proposed L-PPS is constructive to provide the robustness between the IoT devices with a valid authentication period. To demonstrate the security and performance efficiencies, the formal verification was performed using a verification tool, Scyther, and a random oracle model. In addition, the proposed L-PPS introduces a secret token and dynamic user authentication to speed up the authentication process between the communication entities. Importantly, the authentication session of L-PPS does not use any complex cryptographic operations, whereby it has less computation and communication costs to meet the standard constraints of surveillance systems. Moreover, the obtained simulation analysis proves that the proposed L-PPS achieves better quality metrics than other authentication schemes in the literature.}
}
@article{KOTOULAS201411,
title = {SPUD—Semantic Processing of Urban Data},
journal = {Journal of Web Semantics},
volume = {24},
pages = {11-17},
year = {2014},
note = {The Semantic Web Challenge 2012},
issn = {1570-8268},
doi = {https://doi.org/10.1016/j.websem.2013.12.003},
url = {https://www.sciencedirect.com/science/article/pii/S1570826814000043},
author = {Spyros Kotoulas and Vanessa Lopez and Raymond Lloyd and Marco Luca Sbodio and Freddy Lecue and Martin Stephenson and Elizabeth Daly and Veli Bicer and Aris Gkoulalas-Divanis and Giusy {Di Lorenzo} and Anika Schumann and Pol {Mac Aonghusa}},
keywords = {City data, Semantic integration, Diagnosis, Reasoning, Linked data, Applications},
abstract = {We present SPUD, a semantic environment for cataloging, exploring, integrating, understanding, processing and transforming urban information. A series of challenges are identified: namely, the heterogeneity of the domain and the impracticality of a common model, the volume of information and the number of data sets, the requirement for a low entry threshold to the system, the diversity of the input data, in terms of format, syntax and update frequency (streams vs static data), the complex data dependencies and the sensitivity of the information. We propose an approach for the incremental and continuous integration of static and streaming data, based on Semantic Web technologies and apply our technology to a traffic diagnosis scenario. We demonstrate our approach through a system operating on real data in Dublin and we show that semantic technologies can be used to obtain business results in an environment with hundreds of heterogeneous datasets coming from distributed data sources and spanning multiple domains.}
}
@article{KALLURI2020110230,
title = {A longitudinal analysis of energy consumption data from a high-performance building in the tropics},
journal = {Energy and Buildings},
volume = {224},
pages = {110230},
year = {2020},
issn = {0378-7788},
doi = {https://doi.org/10.1016/j.enbuild.2020.110230},
url = {https://www.sciencedirect.com/science/article/pii/S0378778819334875},
author = {Balaji Kalluri and Bharath Seshadri and Markus Gwerder and Arno Schlueter},
keywords = {High-performance, Performance verification, Benchmarking, Long-term, Middleware},
abstract = {With the use of computer-aided tools, design of high-performance buildings is becoming the de facto industry practice. While reliability and ingenuity of computer simulation models is debated on one hand, continuous measurement and verification of building performance over a long-term is embraced as an alternative solution. The goal of this study is to assess the energy performance of a state-of-the-art high-performance building design in the tropics. Longitudinal and high-fidelity energy consumption data from the high-performance office building (3for2) is presented and analysed for this purpose. The approach to energy-performance assessment presented in this study has two parts. The first part is performance verification which entails using two-years of detailed energy-use data to validate building’s estimated annual energy-use, determined using short-term (i.e. first 100 days of building energy-use) data. Thus, recalibrating the building’s baseline energy performance. The second part is performance benchmarking which entails comparing target building’s energy performance against their peers. Thus, verifying the original classification of 3for2 building design as high-performance, by comparing normalized annual building energy-use against national benchmark statistics. The results and analysis based on long-term measurements help assess several key building performance measures of the 3for2 office design. Firstly, it verified the baseline energy-use is 81.1 kWh/sqm/yr as compared to 77 kWh/sqm/yr estimated based on short-term data. Secondly, several positive energy-saving interventions collectively lowered energy-use to 67.7 kWh/sqm/yr, and thus improve energy-performance by approximately 16% over the baseline. The relevant interventions implemented in 3for2 design are CO2-based demand control ventilation, occupant-centric controls and low-lift vapour-compression chiller. Finally, it demonstrated approximately 40% improved energy performance over other similar buildings in the tropics. Thus, the lessons learnt from longitudinal study help conclude that 3for2 is one of the most energy-efficient office building in the tropics. In addition, this study also exemplifies the role of middleware in making building designs not only high-performing, but also verifiable continuously in long-term throughout building’s life cycle. Overall, this concludes that truly realising high-performance buildings in future lies in not only integrating low-energy architecture and building systems, but also closing the feedback loop by integrating appropriate energy-saving interventions through high-fidelity data infrastructure.}
}
@article{SESTINO2020102173,
title = {Internet of Things and Big Data as enablers for business digitalization strategies},
journal = {Technovation},
volume = {98},
pages = {102173},
year = {2020},
issn = {0166-4972},
doi = {https://doi.org/10.1016/j.technovation.2020.102173},
url = {https://www.sciencedirect.com/science/article/pii/S0166497220300456},
author = {Andrea Sestino and Maria Irene Prete and Luigi Piper and Gianluigi Guido},
keywords = {Internet of Things, Big data, Business opportunities, Business management, Digitalization, Marketing strategies},
abstract = {Digitization blurs the lines between technology and management, facilitating new business models built upon the concepts, methods and tools of the digital environment. The purpose of this study is to investigate the role of the Internet of Things (IoT) and Big Data in terms of how businesses manage their digital transformation. The paper argues that the outbreak of IoT and Big Data has resulted in a mass of disorganized knowledge. In order to make sense of the noise, a literature review was carried out to examine the studies, published in the last decade (2008–2019), that analyzed both the Internet of Things and Big Data. The results show that IoT and Big Data are predominantly reengineering factors for business processes, products and services; however, a lack of widespread knowledge and adoption has led research to evolve into multiple, yet inconsistent paths. The study offers interesting implications for managers and marketers, highlighting how the digital transformation enabled by IoT and Big Data can positively impact many facets of business. By treating IoT and Big Data as faces of the same coin, this study also sheds light on current challenges and opportunities, with the hope of informing future research and practice.}
}
@article{ZHANG2020102210,
title = {Charging infrastructure demands of shared-use autonomous electric vehicles in urban areas},
journal = {Transportation Research Part D: Transport and Environment},
volume = {78},
pages = {102210},
year = {2020},
issn = {1361-9209},
doi = {https://doi.org/10.1016/j.trd.2019.102210},
url = {https://www.sciencedirect.com/science/article/pii/S1361920919303840},
author = {Hongcai Zhang and Colin J.R. Sheppard and Timothy E. Lipman and Teng Zeng and Scott J. Moura},
keywords = {Autonomous vehicle, Electric vehicle, Shared-use vehicle, Ride-hailing service, Charging system planning, Agent-based simulation},
abstract = {Ride-hailing is a clear initial market for autonomous electric vehicles (AEVs) because it features high vehicle utilization levels and strong incentive to cut down labor costs. An extensive and reliable network of recharging infrastructure is the prerequisite to launch a lucrative AEV ride-hailing fleet. Hence, it is necessary to estimate the charging infrastructure demands for an AEV fleet in advance. This study proposes a charging system planning framework for a shared-use AEV fleet providing ride-hailing services in urban area. We first adopt an agent-based simulation model, called BEAM, to describe the complex behaviors of both passengers and transportation systems in urban cities. BEAM simulates the driving, parking and charging behaviors of the AEV fleet with range constraints and identifies times and locations of their charging demands. Then, based on BEAM simulation outputs, we adopt a hybrid algorithm to site and size charging stations to satisfy the charging demands subject to quality of service requirements. Based on the proposed framework, we estimate the charging infrastructure demands and calculate the corresponding economics and carbon emission impacts of electrifying a ride-hailing AEV fleet in the San Francisco Bay Area. We also investigate the impacts of various AEV and charging system parameters, e.g., fleet size, vehicle battery capacity and rated power of chargers, on the ride-hailing system’s overall costs.}
}
@article{CHEN20191122,
title = {Design of personnel big data management system based on blockchain},
journal = {Future Generation Computer Systems},
volume = {101},
pages = {1122-1129},
year = {2019},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2019.07.037},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X19313354},
author = {Jian Chen and Zhihan Lv and Houbing Song},
keywords = {Big data, Blockchain, Information management, Data separation},
abstract = {With the continuous development of information technology, enterprises, universities and governments are constantly stepping up the construction of electronic personnel information management system. The information of hundreds of thousands or even millions of people’s information are collected and stored into the system. So much information provides the cornerstone for the development of big data, if such data is tampered with or leaked, it will cause irreparable serious damage. However, in recent years, electronic archives have exposed a series of problems such as information leakage, information tampering, and information loss, which has made the reform of personnel information management more and more urgent. The unique characteristics of the blockchain, such as non-tampering and traceability make it have great application potential in personnel information management, and can effectively solve many problems of traditional file management. However, the blockchain is limited by its own shortcomings such as small storage space and slow synchronization time, and cannot be directly applied to the big data field. This paper proposes a personnel management system based on blockchain, we analyzed the defects of the blockchain and proposed an improved method, constructs a novel data storage model of on-chain and out-of-chain that can effectively solve the problem of data redundancy and insufficient storage space. Based on this, we developed a prototype system with query, add, modify, and track personnel information, verified the feasibility of applying blockchain to personnel information management, explore the possibility of combining blockchain with big data.}
}
@article{KAYABAY2022121264,
title = {Data science roadmapping: An architectural framework for facilitating transformation towards a data-driven organization},
journal = {Technological Forecasting and Social Change},
volume = {174},
pages = {121264},
year = {2022},
issn = {0040-1625},
doi = {https://doi.org/10.1016/j.techfore.2021.121264},
url = {https://www.sciencedirect.com/science/article/pii/S0040162521006983},
author = {Kerem Kayabay and Mert Onuralp Gökalp and Ebru Gökalp and P. {Erhan Eren} and Altan Koçyiğit},
keywords = {Technology roadmapping, Technology management, Data science, Digital transformation, Data-driven organization, Big data},
abstract = {Leveraging data science can enable businesses to exploit data for competitive advantage by generating valuable insights. However, many industries cannot effectively incorporate data science into their business processes, as there is no comprehensive approach that allows strategic planning for organization-wide data science efforts and data assets. Accordingly, this study explores the Data Science Roadmapping (DSR) to guide organizations in aligning their business strategies with data-related, technological, and organizational resources. The proposed approach is built on the widely adopted technology roadmapping framework and customizes its context, architecture, and process by synthesizing data science, big data, and data-driven organization literature. Based on industry collaborations, the framework provides a hybrid and agile methodology comprising the recommended steps. We applied DSR with a research group with sector experience to create a comprehensive data science roadmap to validate and refine the framework. The results indicate that the framework facilitates DSR initiatives by creating a comprehensive roadmap capturing strategy, data, technology, and organizational perspectives. The contemporary literature illustrates prebuilt roadmaps to help businesses become data-driven. However, becoming data-driven also necessitates significant social change toward openness and trust. The DSR initiative can facilitate this social change by opening communication channels, aligning perspectives, and generating consensus among stakeholders.}
}
@article{JEONG2021100349,
title = {A comprehensive survey on vehicular networking for safe and efficient driving in smart transportation: A focus on systems, protocols, and applications},
journal = {Vehicular Communications},
volume = {31},
pages = {100349},
year = {2021},
issn = {2214-2096},
doi = {https://doi.org/10.1016/j.vehcom.2021.100349},
url = {https://www.sciencedirect.com/science/article/pii/S2214209621000188},
author = {Hwanseok (Harrison) Jeong and Yiwen (Chris) Shen and Jaehoon (Paul) Jeong and Tae (Tom) Oh},
keywords = {Smart transportation, Vehicular networks, Driving safety, Driving efficiency, Protocol, Security},
abstract = {Dramatic increase in road traffic volume has made driving safety and traffic efficiency more challenging, but smart transportation has been spotlighted as a promising technology for improving driving safety and efficiency. This paper surveys safe and efficient driving in the smart transportation with a focus on the aspects of systems, protocols, applications, and security, especially for autonomous vehicles. This smart transportation requires to monitor road surfaces precisely and identify hazards, and vehicles also need to share sensing information to avoid dangerous situations or environments through wireless communication in vehicular networks. For this purpose, dedicated short-range communications (DSRC) have achieved the international standards of the IEEE Wireless Access in Vehicular Environments (WAVE), and applications are now common that use the global positioning systems (GPS) for a dedicated navigation system navigator or smartphone application. This combination of vehicular networking and navigation enables systems and applications not only to enhance driving safety, but also to increase traffic efficiency. To support the vehicular systems and applications efficiently, the protocols need to be designed carefully and implemented effectively. This paper summarizes and analyzes the state-of-the-art research based on standardization activities for smart transportation systems, protocols, applications, and security. This paper also provides the comparison between the different technologies composing vehicular systems, protocols, applications, and security in terms of advantages, disadvantages, analysis, simulation, implementation, and complexity to provide a trend of overall technologies. Lastly, this paper suggests research directions for the smart transportation.}
}
@article{ORTIS2017207,
title = {Organizing egocentric videos of daily living activities},
journal = {Pattern Recognition},
volume = {72},
pages = {207-218},
year = {2017},
issn = {0031-3203},
doi = {https://doi.org/10.1016/j.patcog.2017.07.010},
url = {https://www.sciencedirect.com/science/article/pii/S0031320317302819},
author = {Alessandro Ortis and Giovanni M. Farinella and Valeria D’Amico and Luca Addesso and Giovanni Torrisi and Sebastiano Battiato},
keywords = {First person vision, Video summarization, Video indexing},
abstract = {Egocentric videos are becoming popular since the possibility to observe the scene flow from the user’s point of view (First Person Vision). Among the different applications of egocentric vision is the daily living monitoring of a user wearing the camera. We propose a system able to automatically organize egocentric videos acquired by the user over different days. Through an unsupervised temporal segmentation, each egocentric video is divided in chapters by considering the visual content. The obtained video segments related to the different days are hence connected according to the scene context in which the user acts. Experiments on a challenging egocentric video dataset demonstrate the effectiveness of the proposed approach that outperforms with a good margin the state of the art in accuracy and computational time.}
}
@article{SOMRAK2019302,
title = {Estimating VR Sickness and user experience using different HMD technologies: An evaluation study},
journal = {Future Generation Computer Systems},
volume = {94},
pages = {302-316},
year = {2019},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2018.11.041},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X18325044},
author = {Andrej Somrak and Iztok Humar and M. Shamim Hossain and Mohammed F. Alhamid and M. Anwar Hossain and Jože Guna},
keywords = {Virtual reality, VR sickness, Cybersickness, User experience, User study},
abstract = {This paper presents results of a user study of the effects of virtual reality technology on VR Sickness and User Experience. In our study the participants watched two different panoramic (360) videos, one with relaxing content (beach clip) and second one with action content (roller coaster video clip). Videos were watched on four different head mounted displays (HMDs) and on the 2D television as a reference display. To assess VR Sickness discomfort levels, we have used the Simulator Sickness Questionnaire (SSQ), and for user experience the User Experience Questionnaire (UEQ) was used. For quick assessments of VR Sickness discomfort levels, we have also used Subjective Units of Distress Scale (SUDS). We have found a strong correlation between SUDS and total SSQ score and between total SSQ score and SSQ-D score. Shown negative correlation between VR Sickness discomfort levels (assessed by SSQ and UEQ Questionnaire), and user experience (assessed by UEQ Questionnaire), indicates that presence of VR Sickness symptoms affects the user experience.}
}
@article{ASCIONE2022103498,
title = {Building rating systems: A novel review about capabilities, current limits and open issues},
journal = {Sustainable Cities and Society},
volume = {76},
pages = {103498},
year = {2022},
issn = {2210-6707},
doi = {https://doi.org/10.1016/j.scs.2021.103498},
url = {https://www.sciencedirect.com/science/article/pii/S2210670721007642},
author = {Fabrizio Ascione and Rosa Francesca {De Masi} and Margherita Mastellone and Giuseppe Peter Vanoli},
keywords = {Rating Systems, Sustainability, Sustainability Assessment Method, COVID-19, New Buildings, Building Retrofit},
abstract = {An up-to-date review of more than 100 research papers about green building rating tools is proposed, with a view to what is changed or must be changed, also following the new requirements due to the recent pandemic. The review organizes current literature in the matter of rating systems in four different groups: rating systems’ comparison papers, case studies, the proposition of new rating systems, possible integration of rating systems into other design tools for buildings. The research papers have been analyzed to underline the main investigated aspects in rating systems, how to improve the rating systems for enlarging the sustainability assessment, and how much the level of certification reflects the green, sustainable, healthiness, and indoor environmental quality features of buildings. Moreover, possible improvements of the weighting systems are here showed, in the rating systems’ method, and some new aspects for the sustainability assessment are suggested. As regards the pillars of sustainability, the main neglected points are structural safety, vulnerability to calamitous events, compatibility with local culture and history. Moreover, the indoor environmental quality and the flexibility/adaptability of livable environments are underestimated in the current rating systems. These issues have emerged strongly during the COVID-19 pandemic and have become a priority.}
}
@article{TAWALBEH2021810,
title = {Reconsidering big data security and privacy in cloud and mobile cloud systems},
journal = {Journal of King Saud University - Computer and Information Sciences},
volume = {33},
number = {7},
pages = {810-819},
year = {2021},
issn = {1319-1578},
doi = {https://doi.org/10.1016/j.jksuci.2019.05.007},
url = {https://www.sciencedirect.com/science/article/pii/S1319157819303337},
author = {Lo'ai A. Tawalbeh and Gokay Saldamli},
keywords = {Cloud computing, Networked mobile cloud system, Big data security and privacy},
abstract = {Large scale distributed systems in particular cloud and mobile cloud deployments provide great services improving people's quality of life and organizational efficiency. In order to match the performance needs, cloud computing engages with the perils of peer-to-peer (P2P) computing and brings up the P2P cloud systems as an extension for federated cloud. Having a decentralized architecture built on independent nodes and resources without any specific central control and monitoring, these cloud deployments are able to handle resource provisioning at a very low cost. Hence, we see a vast amount of mobile applications and services that are ready to scale to billions of mobile devices painlessly. Among these, data driven applications are the most successful ones in terms of popularity or monetization. However, data rich applications expose other problems to consider including storage, big data processing and also the crucial task of protecting private or sensitive information. In this work, first, we go through the existing layered cloud architectures and present a solution addressing the big data storage. Secondly, we explore the use of P2P Cloud System (P2PCS) for big data processing and analytics. Thirdly, we propose an efficient hybrid mobile cloud computing model based on cloudlets concept and we apply this model to health care systems as a case study. Then, the model is simulated using Mobile Cloud Computing Simulator (MCCSIM). According to the experimental power and delay results, the hybrid cloud model performs up to 75% better when compared to the traditional cloud models. Lastly, we enhance our proposals by presenting and analyzing security and privacy countermeasures against possible attacks.}
}
@article{ZIEBAKULAWIK2021127195,
title = {Improving methods to calculate the loss of ecosystem services provided by urban trees using LiDAR and aerial orthophotos},
journal = {Urban Forestry & Urban Greening},
volume = {63},
pages = {127195},
year = {2021},
issn = {1618-8667},
doi = {https://doi.org/10.1016/j.ufug.2021.127195},
url = {https://www.sciencedirect.com/science/article/pii/S161886672100220X},
author = {Karolina Zięba-Kulawik and Paweł Hawryło and Piotr Wężyk and Piotr Matczak and Patrycja Przewoźna and Adam Inglot and Krzysztof Mączka},
keywords = {Ecosystem services, GEOBIA, i-Tree Eco, LiDAR, Predictive models, Urban forests},
abstract = {In this paper we propose a methodology for combining remotely sensed data with field measurements to assess selected tree parameters (diameter at breast height (DBH) and tree species) required by the i-Tree Eco model to estimate ecosystem services (ES) provided by urban trees. We determined values of ES provided by trees in 2017 in Racibórz (a city in South Poland) and estimated the loss of ES from January 1, 2017 to March 5, 2017, a period of changing legislation that temporarily allowed removal of trees on private property without any permission from city authorities. We applied Canopy Height Models (CHM; GSD 1.0 m) generated from two sets of ALS LiDAR point clouds (acquisitions on June 11, 2011 and March 5, 2017) and performed tree crown segmentations using the GEOBIA approach. Physical attributes were estimated for each tree using predictive models, developed based on field tree inventory . The reference areas for parameterizing the segmentation algorithm and assessing tree species composition were established in Racibórz, while reference data required for assessment of DBH were obtained from the MONIT-AIR project (from Municipality of Kraków). We found that in 2017, 988.79 ha of Racibórz (13.2 % of city area) was covered by the crowns of 264 471 trees, providing ES structural values worth over 384 mil €. The structural value of ES lost in the first months of 2017 (during which 5 075 trees were removed) was about 3.5 mil €. We concluded that in the face of information on tree crown cover that is often missing from city databases, tree inventories require application of a combination of multi-source and multi-resolution spatial analyses, including: administrative decisions for tree removal with exact location, predictive modelling of selected biometrical tree information, automatic crown segmentation on CHM and interpretation of regularly updated color infrared (CIR) aerial orthophotos.}
}
@article{GARBASEVSCHI2021101637,
title = {Spatial factors influencing building age prediction and implications for urban residential energy modelling},
journal = {Computers, Environment and Urban Systems},
volume = {88},
pages = {101637},
year = {2021},
issn = {0198-9715},
doi = {https://doi.org/10.1016/j.compenvurbsys.2021.101637},
url = {https://www.sciencedirect.com/science/article/pii/S0198971521000442},
author = {Oana M. Garbasevschi and Jacob {Estevam Schmiedt} and Trivik Verma and Iulia Lefter and Willem K. {Korthals Altes} and Ariane Droin and Björn Schiricke and Michael Wurm},
keywords = {Open data, Urban morphology, Spatial autocorrelation, Residential building age, Residential heat demand, Random forest},
abstract = {Urban energy consumption is expected to continuously increase alongside rapid urbanization. The building sector represents a key area for curbing the consumption trend and reducing energy-related emissions by adopting energy efficiency strategies. Building age acts as a proxy for building insulation properties and is an important parameter for energy models that facilitate decision making. The present study explores the potential of predicting residential building age at a large geographical scale from open spatial data sources in eight municipalities in the German federal state of North-Rhine Westphalia. The proposed framework combines building attributes with street and block metrics as classification features in a Random Forest model. Results show that the addition of urban fabric metrics improves the accuracy of building age prediction in specific training scenarios. Furthermore, the findings highlight the way in which the spatial disposition of training and test samples influences classification accuracy. Additionally, the paper investigates the impact of age misclassification on residential building heat demand estimation. The age classification model leads to reasonable errors in energy estimates, in various scenarios of training, which suggests that the proposed method is a promising addition to the urban energy modelling toolkit.}
}
@article{THAPLIYAL2022103253,
title = {NOMA-based UAV system under finite blocklength regime with analysis in Rician fading channel},
journal = {Digital Signal Processing},
volume = {120},
pages = {103253},
year = {2022},
issn = {1051-2004},
doi = {https://doi.org/10.1016/j.dsp.2021.103253},
url = {https://www.sciencedirect.com/science/article/pii/S105120042100292X},
author = {Shardul Thapliyal and Rajoo Pandey and Chhagan Charan},
keywords = {UAV, Finite block-length, NOMA, Power allocation, Rician fading channel, Optimization},
abstract = {The finite blocklength (FBL) communication has been studied for quite some time for the fifth generation of cellular networks (5G). Though, the research in FBL is still in early stage due to the fact that 5G requires high reliability of almost 99.9999% with latency of less than 1 ms, simultaneously. The FBL has been worked upon to reduce latency such that Shannon's capacity expression is no longer applicable. The 5G claims to provide connectivity everywhere, hence to increase the coverage to remote places Unmanned Ariel Vehicle (UAV) has gained attention due to its low cost, mobility, and air time. In this paper, a scenario where a UAV relays data from a base station (BS) to remote users (RU), which are otherwise not in direct contact, is analyzed. All the communications among BS, UAV, and RU's are considered to be non-orthogonal multiple access (NOMA) based with Finite blocklength (FBL). An exact closed form expression for end-to-end average block error rate (BLER) is derived for above mentioned scenario and verified by extensive simulations. In addition, an asymptotic BLER for remote users at high transmission Signal to noise ratio is also derived. Further, the BLER is minimized to jointly optimize the power allocation coefficients, position of UAV and Blocklength for the communication system. The effects of different parameters on average BLER, position, and power are studied and the coverage provided by UAV for given probability of error is presented.}
}
@article{ESMAEILIAN2020105064,
title = {Blockchain for the future of sustainable supply chain management in Industry 4.0},
journal = {Resources, Conservation and Recycling},
volume = {163},
pages = {105064},
year = {2020},
issn = {0921-3449},
doi = {https://doi.org/10.1016/j.resconrec.2020.105064},
url = {https://www.sciencedirect.com/science/article/pii/S0921344920303815},
author = {Behzad Esmaeilian and Joe Sarkis and Kemper Lewis and Sara Behdad},
keywords = {Blockchain, Supply chain, Sustainability, Industry 4.0, IoT, Circular economy},
abstract = {The objective of this study is to provide an overview of Blockchain technology and Industry 4.0 for advancing supply chains towards sustainability. First, extracted from the existing literature, we evaluate the capabilities of Industry 4.0 for sustainability under three main topics of (1) Internet of things (IoT)-enabled energy management in smart factories; (2) smart logistics and transportation; and (3) smart business models. We expand beyond Industry 4.0 with unfolding the capabilities that Blockchain offers for increasing sustainability, under four main areas: (1) design of incentive mechanisms and tokenization to promote consumer green behavior; (2) enhance visibility across the entire product lifecycle; (3) increase systems efficiency while decreasing development and operational costs; and (4) foster sustainability monitoring and reporting performance across supply chain networks. Furthermore, Blockchain technology capabilities for contributing to social and environmental sustainability, research gaps, adversary effects of Blockchain, and future research directions are discussed.}
}
@article{ALAM2020,
title = {A Blockchain-based Land Title Management System for Bangladesh},
journal = {Journal of King Saud University - Computer and Information Sciences},
year = {2020},
issn = {1319-1578},
doi = {https://doi.org/10.1016/j.jksuci.2020.10.011},
url = {https://www.sciencedirect.com/science/article/pii/S1319157820304912},
author = {Kazi Masudul Alam and J.M. {Ashfiqur Rahman} and Anisha Tasnim and Aysha Akther},
keywords = {Bangladesh, Land title management, Transparent governance, Hybrid Blockchain, Smart contract, Ethereum},
abstract = {Bangladesh is a small country with a large population. Its increasingly developing economy further makes land a lucrative source of fixed capital. On the other hand, land titling is a cumbersome and lengthy process, where different government bodies process different sets of documents, and bureaucratic loopholes encourage fraudulent activities by organized people. As a result, the current model suffers from good governance. In this paper, we propose a Blockchain-based solution that offers data synchronization and transparency, ease of access, immutable records management, a faster and cheaper solution. Considering the technological knowledge and capacity of the people and the government, we introduced a phase by phase Blockchain adoption model that starts with a public Blockchain ledger and later gradually incorporates two levels of Hybrid Blockchain. We provide detailed smart contracts design of the public Blockchain and implement a prototype system using Ethereum. Our experimental setup uses local and live Ethereum test networks to demonstrate the efficacy of the proposed system. Our analysis shows that the proposed model reduces the number of required travels, the overall cost of information processing as well as provide easy access to vital information. As a result, Blockchain adoption can improve the land title digitization effort of Bangladesh.}
}
@article{HRAOUI2019399,
title = {A New Cryptosystem of Color Image Using a Dynamic-Chaos Hill Cipher Algorithm},
journal = {Procedia Computer Science},
volume = {148},
pages = {399-408},
year = {2019},
note = {THE SECOND INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTING IN DATA SCIENCES, ICDS2018},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2019.01.048},
url = {https://www.sciencedirect.com/science/article/pii/S1877050919300481},
author = {Said Hraoui and Faiq Gmira and M.Fouad Abbou and A.Jarrar Oulidi and Abdellatif Jarjar},
keywords = {Hill cipher, cryptosystem, PWCLM, chaos, image encryption, dynamic-chaos Hill cipher, G=Z/256Z},
abstract = {The conventional symmetric Hill cipher encryption algorithm, applied for data encryption, presents several disadvantages. However, a drawback of the conventional algorithm is known to be vulnerable to plain-text attack. Another setback, it does not hide all features of the image with homogeneous background and finally, the difficulty of finding the inverse of the key matrix. To overcome these problems, in this paper, we propose an improvement of the Hill cipher algorithm. The principle consists in using an affine transformation provided by a three-order invertible matrix and a dynamic translation vector. This vector is dynamically transformed at each iteration by an affine transformation composed of a chaotic matrix T, not necessarily invertible, and a pseudo random translation vector Y. This improvement overcomes the linearity problem of Hill’s classic method. In addition, computational complexity can be reduced by simplifying the inverse matrix search process at the time of decryption. This inverse lies only in the search for the modular inverse of a single element of the matrix in the ring Z/256Z. The proposed scheme overcomes the disadvantages of the conventional Hill cipher, especially, the images with strong homogenous zones. The proposed algorithm guarantees a better quality of security and encryption.}
}
@article{VARGASMARTINEZ2021210,
title = {A Host Intrusion Detection System architecture for embedded industrial devices},
journal = {Journal of the Franklin Institute},
volume = {358},
number = {1},
pages = {210-236},
year = {2021},
issn = {0016-0032},
doi = {https://doi.org/10.1016/j.jfranklin.2019.03.037},
url = {https://www.sciencedirect.com/science/article/pii/S0016003219305307},
author = {Cyntia {Vargas Martinez} and Birgit Vogel-Heuser},
abstract = {The integration of Cyber-Physical Systems in the industrial domain has become indispensable for Industry 4.0. Unfortunately, as the interconnectivity among them increases, so do the opportunities for malicious users to target them. Hence, it is necessary to increase the security of these systems and their components. A wide range of security solutions (e.g., industrial Firewalls) are already an integral part of Industrial Automation Systems, however, these are deployed at strategical system locations and might not be capable of identifying intrusions that target specific elements of embedded industrial devices. Host Intrusion Detection Systems (Host IDS) are one security solution that allow to detect such type of intrusions, as they analyze information related to specific host devices. This contribution presents a feasible Host IDS architecture for embedded industrial devices. This architecture takes into consideration features and capabilities of Host IDS from the IT domain. It also considers system-, environmental- and device-specific properties from the industrial domain. These properties are presented in the form of abstracted requirements and considerations that are contemplated for the conceptualization of the presented architecture. Furthermore, the feasibility of this architecture is validated through the implementation and evaluation of a prototypical Host IDS deployed in a Programmable Logic Controller (PLC) hosting a Real-Time Operating System (RTOS). This evaluation is achieved through the demonstration of a set of hypotheses derived from the abstracted requirements and supported by the evaluation of test scenarios. To the best of our knowledge, this is the first fully operational Host IDS to be deployed and evaluated on a PLC.}
}
@article{ALNASSER201952,
title = {Cyber security challenges and solutions for V2X communications: A survey},
journal = {Computer Networks},
volume = {151},
pages = {52-67},
year = {2019},
issn = {1389-1286},
doi = {https://doi.org/10.1016/j.comnet.2018.12.018},
url = {https://www.sciencedirect.com/science/article/pii/S1389128618306157},
author = {Aljawharah Alnasser and Hongjian Sun and Jing Jiang},
keywords = {V2X communications, LTE, Cyber security, Vehicular network},
abstract = {In recent years, vehicles became able to establish connections with other vehicles and infrastructure units that are located in the roadside. In the near future, the vehicular network will be expanded to include the communication between vehicles and any smart devices in the roadside which is called Vehicle-to-Everything (V2X) communication. The vehicular network causes many challenges due to heterogeneous nodes, various speeds and intermittent connection, where traditional security methods are not always efficacious. As a result, an extensive variety of research works has been done on optimizing security solutions whilst considering network requirements. In this paper, we present a comprehensive survey and taxonomy of the existing security solutions for V2X communication technology. Then, we provide discussions and comparisons with regard to some pertinent criteria. Also, we present a threat analysis for V2X enabling technologies. Finally, we point out the research challenges and some future directions.}
}
@article{ZHANG2015387,
title = {Towards semantically linked multilingual corpus},
journal = {International Journal of Information Management},
volume = {35},
number = {3},
pages = {387-395},
year = {2015},
issn = {0268-4012},
doi = {https://doi.org/10.1016/j.ijinfomgt.2015.01.004},
url = {https://www.sciencedirect.com/science/article/pii/S0268401215000055},
author = {Junsheng Zhang and Yunchuan Sun and Antonio J. Jara},
keywords = {Information management, Multilingual corpus, Semantic association, Semantic link network, In-network},
abstract = {Multilingual information processing gains more and more attention in recent years with the development of information globalization. Multilingual corpus is a key challenge for multilingual information extraction, analysis, management and service in a wide range of systems. This work addresses on the study and analysis of semantic associations among elements in a multilingual corpus. A solution is proposed in this paper to optimize the semantic organization of multilingual corpus by linking the corpus elements into a semantic link network. This enhances the text-basd applications of multilingual corpus such as corpus linguistics study, dictionary search, machine translation and cross-lingual information retrieval.}
}
@article{JAIN2019100351,
title = {Social network sustainability for transport planning with complex interconnections},
journal = {Sustainable Computing: Informatics and Systems},
volume = {24},
pages = {100351},
year = {2019},
issn = {2210-5379},
doi = {https://doi.org/10.1016/j.suscom.2019.100351},
url = {https://www.sciencedirect.com/science/article/pii/S2210537919300538},
author = {Somya Jain and Adwitiya Sinha},
keywords = {Sustainable computing, Social network, Transport planning, Network bottleneck, Checkpoints, Large-scale graph analytics},
abstract = {Social network analysis serves as sustainable mechanism to examine large-scale complex social connections, with heterogeneity and interdependencies posing as major challenges. In our research, a novel approach is developed to efficaciously discover critical nodes, designated as network bottlenecks. The bottleneck is considered crucial in propagating the flow of information in the network. This is further extended to extraction of relative checkpoint(s) that acts as probable sources of major inflows towards the respective bottleneck. These set of checkpoints can be considered for prior surveillance resulting the control of information outbursts towards bottleneck node. Viable domains for applicability of our proposed methodology include, road traffic monitoring, extremist content tracking, fake news inspection, uncloaking online terrorist movements, etc. For our experimentation, we have focussed on transport planning application to identify traffic hotspot regions and relative set of nodes acting as checkpoints. These checkpoints can serve as monitoring stations for controlling the traffic hence improving sustainable mobility over roads. Moreover, air purifying machines can also be deployed, hence facilitating improved air quality.}
}
@article{MUTLAG201962,
title = {Enabling technologies for fog computing in healthcare IoT systems},
journal = {Future Generation Computer Systems},
volume = {90},
pages = {62-78},
year = {2019},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2018.07.049},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X18314006},
author = {Ammar Awad Mutlag and Mohd Khanapi {Abd Ghani} and N. Arunkumar and Mazin Abed Mohammed and Othman Mohd},
keywords = {Cloud computing, Fog computing, Edge computing, Healthcare applications, Shared nodes, Shared resources, Smart gateways, Systematic literature review},
abstract = {Context: A fog computing architecture that is geographically distributed and to which a variety of heterogeneous devices are ubiquitously connected at the end of a network in order to provide collaboratively variable and flexible communication, computation, and storage services. Fog computing has many advantages and it is suited for the applications whereby real-time, high response time, and low latency are of the utmost importance, especially healthcare applications. Objectives: The aim of this study was to present a systematic literature review of the technologies for fog computing in the healthcare IoT systems field and analyze the previous. Providing motivation, limitations faced by researchers, and suggestions proposed to analysts for improving this essential research field. Methods: The investigations were systematically performed on fog computing in the healthcare field by all studies; furthermore, the four databases Web of Science (WoS), ScienceDirect, IEEE Xplore Digital Library, and Scopus from 2007 to 2017 were used to analyze their architecture, applications, and performance evaluation. Results: A total of 99 articles were selected on fog computing in healthcare applications with deferent methods and techniques depending on our inclusion and exclusion criteria. The taxonomy results were divided into three major classes; frameworks and models, systems (implemented or architecture), review and survey. Discussion: Fog computing is considered suitable for the applications that require real-time, low latency, and high response time, especially in healthcare applications. All these studies demonstrate that resource sharing provides low latency, better scalability, distributed processing, better security, fault tolerance, and privacy in order to present better fog infrastructure. Learned lessons: numerous lessons related to fog computing. Fog computing without a doubt decreased latency in contrast to cloud computing. Researchers show that simulation and experimental proportions ensure substantial reductions of latency is provided. Which it is very important for healthcare IoT systems due to real-time requirements. Conclusion: Research domains on fog computing in healthcare applications differ, yet they are equally important for the most parts. We conclude that this review will help accentuating research capabilities and consequently expanding and making extra research domains.}
}
@article{CARBONE20161,
title = {Challenges in data science: a complex systems perspective},
journal = {Chaos, Solitons & Fractals},
volume = {90},
pages = {1-7},
year = {2016},
note = {Challenges in Data Science},
issn = {0960-0779},
doi = {https://doi.org/10.1016/j.chaos.2016.04.020},
url = {https://www.sciencedirect.com/science/article/pii/S0960077916301515},
author = {Anna Carbone and Meiko Jensen and Aki-Hiro Sato},
keywords = {Big data, Disordered systems, Complex systems, Nonlinear systems},
abstract = {The ability to process and manage large data volumes has been proven to be not enough to tackle the current challenges presented by “Big Data”. Deep insight is required for understanding interactions among connected systems, space- and time- dependent heterogeneous data structures. Emergence of global properties from locally interacting data entities and clustering phenomena demand suitable approaches and methodologies recently developed in the foundational area of Data Science by taking a Complex Systems standpoint. Here, we deal with challenges that can be summarized by the question: “What can Complex Systems Science contribute to Big Data? ”. Such question can be reversed and brought to a superior level of abstraction by asking “What Knowledge can be drawn from Big Data?” These aspects constitute the main motivation behind this article to introduce a volume containing a collection of papers presenting interdisciplinary advances in the Big Data area by methodologies and approaches typical of the Complex Systems Science, Nonlinear Systems Science and Statistical Physics.}
}
@article{KHAN2021921,
title = {ETERS: A comprehensive energy aware trust-based efficient routing scheme for adversarial WSNs},
journal = {Future Generation Computer Systems},
volume = {125},
pages = {921-943},
year = {2021},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2021.06.049},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X21002442},
author = {Tayyab Khan and Karan Singh and Mohd Hilmi Hasan and Khaleel Ahmad and G. Thippa Reddy and Senthilkumar Mohan and Ali Ahmadian},
keywords = {Trust estimation, Routing, Security, Data trust, Selfish nodes, Energy, Delay, Accuracy, Throughput},
abstract = {Trust-based secure routing schemes are more effective than cryptographic routing protocols to convey energy-efficient data in WSNs since cryptographic protocols require high computation, more convergence time as well as storage space. The paper presents a well-organized trust estimation-based routing scheme (ETERS) that consists multi-trust (communication trust, energy trust, data trust) approach to alleviate several internal attacks like badmouthing, Sybil, selective forwarding, on–off,​ black hole, and gray-hole attacks for clustered WSN. The proposed multi-trust approach is used to analyze the credibility of sensitive monitored data. A novel and efficient cluster head selection algorithm (ECHSA) is employed to improve the performance of the cluster head (CH) selection process in clustered WSN. ECHSA allows the facility to elect a robust CH after a certain period to perform an equal load balance on all CHs. ETERS utilizes the Beta distribution-based trust function because recovery of trust values under attacks is faster in Beta distribution than Gaussian and Dirichlet distribution. ETERS also incorporates an irregular attenuation factor during the evaluation of communication trust to reflect the effect of various external factors such as natural calamity (earthquake), network congestion, etc., based on the trust values. However, a trust-based attack detection algorithm (TADA) assesses the reliability of SNs to detect internal attacks. TADA employs IDs, locations, and triple trust to detect internal attacks. Additionally, the proposed trust system employs an adjustable dynamic sliding length logical timing window to eradicate the limitations of existing trust models. Furthermore, a trust-based secure routing algorithm is incorporated to dynamically detect misbehavior in terms of packet forwarding for energy-efficient communication among sensor nodes. ETERS is compared with QEBSR, ATRP, ELPC, and SQEER to examine its performance. Experimental results on the MATLAB simulation platform exhibit excellent performance in terms of severity analysis, attack detection, and prevention to protect WSN, energy consumption under (i) normal (ii) attack scenario, latency (in sec.), packet delivery ratio (PDR), and throughput (in %) in the existence of spiteful nodes.}
}
@article{JIAN2021103110,
title = {Energy-efficient user association with load-balancing for cooperative IIoT network within B5G era},
journal = {Journal of Network and Computer Applications},
volume = {189},
pages = {103110},
year = {2021},
issn = {1084-8045},
doi = {https://doi.org/10.1016/j.jnca.2021.103110},
url = {https://www.sciencedirect.com/science/article/pii/S1084804521001302},
author = {Xin Jian and Langyun Wu and Keping Yu and Moayad Aloqaily and Jalel Ben-Othman},
keywords = {5G wireless technology, Industrial Internet of Things, Multi-access edge computing, Cooperative networks, Multi-association, Load balancing},
abstract = {As one of the key technologies of 5G wireless communication technology, cooperative multi-access edge computing allows one device to associate multiple edge nodes simultaneously, namely multi-association, which can provide scalable communication services with characteristics of high reliability, massive connectivity and low latency for promising Industrial Internet of Things (IIoT). Effective association between edge nodes and devices is the prerequisite for providing high quality communication services in dense deployed IIoT networks. Most of state of art researches focus on the user association problem in single-association scenario. There are rarely no solutions presented for the considered user association problem with multi-association. In this paper, user association, power allocation and edge node deployment are jointly considered for load balance and energy efficiency under the multi-association mechanism. The problem is formulated as a nested knapsack optimization problem (NKOP) with energy efficiency and load balancing as objective functions and power and signal quality as constraints. Differential evolution with Monte Carlo and sequential quadratic programming (DMS) algorithm is proposed to solve this problem, which decouples the problem into three parts, user association, power allocation and optimizing the location of edge nodes. Numerical results show that: (1) Compared with the single-association, multi-association with power allocation can provide better signal quality and improve energy efficiency; (2) Proposed DMS algorithm is feasible and stable for optimal deployment of edge nodes. These works together provide good reference for edge node deployment of high-density IIoT application scenarios.}
}
@article{DAMICO2022105819,
title = {Digitalisation driven urban metabolism circularity: A review and analysis of circular city initiatives},
journal = {Land Use Policy},
volume = {112},
pages = {105819},
year = {2022},
issn = {0264-8377},
doi = {https://doi.org/10.1016/j.landusepol.2021.105819},
url = {https://www.sciencedirect.com/science/article/pii/S0264837721005421},
author = {Gaspare D’Amico and Roberta Arbolino and Lei Shi and Tan Yigitcanlar and Giuseppe Ioppolo},
keywords = {Urban metabolism, Digitalisation, Circular city, Sustainability, Circular economy, Urban development},
abstract = {Digitalisation of urban metabolism circularity provides policymakers, urban managers, planners and administrators with a useful tool for identifying, controlling and evaluating a wide range of data concerning the flows of social, environmental and economic resources. This approach is based on the crucial role of fixed and mobile digital infrastructures such as real-time monitoring stations, GPS tracking sensors, augmented reality, virtual sharing platforms, social media dashboards, smart grids, and the like in the development and strengthening of the quality and efficiency of the circularity of resources. For these reasons, the integration of digital technologies in mobility, waste, water and wastewater management, energy efficiency, safety, and so on, represents a crucial aspect for cities involved in the circularity of their urban metabolism. Through a systematic literature review and case study approaches, the analysis disclose a wide-range of initiatives adopted by several European circular cities that optimise the circularity of urban metabolic flows, and contributes to the efforts in increasing understanding and awareness of the digitalisation driven by the urban metabolism circularity.}
}
@article{MOUSAVI2021102945,
title = {Data cryptography in the Internet of Things using the artificial bee colony algorithm in a smart irrigation system},
journal = {Journal of Information Security and Applications},
volume = {61},
pages = {102945},
year = {2021},
issn = {2214-2126},
doi = {https://doi.org/10.1016/j.jisa.2021.102945},
url = {https://www.sciencedirect.com/science/article/pii/S2214212621001605},
author = {Seyyed Keyvan Mousavi and Ali Ghaffari},
keywords = {IoT, Security, Cryptography, Artificial bee colony},
abstract = {The Internet of Things (IoT) includes various technologies, including sensing devices, Radio-Frequency Identification (RFID), and Microelectromechanical Systems (MEMS). Despite numerous advantages of IoT, security and privacy are important challenges. IoT infrastructures are frequently attacked by different invaders, including white hat hackers whose mission is to test the system's penetrability. Other attacks are orchestrated by adversaries that misuse system vulnerabilities to seize information for personal benefits. Hence, security is a key factor and fundamental requirement of IoT design. Thus, increased cyberattacks call for an appropriate strategic plan to ensure IoT security. Enhancing data security in IoT has proved to be a major concern, and one solution to mitigate this is to apply suitable encryption techniques when storing data in the IoT. An intruder will be able to control IoT devices without physical access if the network is not secure enough. To overcome this challenge, this paper proposes a security design based on Elliptic-Curve Cryptography (ECC), the SHA-256 (Secure Hash Algorithm 256) algorithm, and the Artificial Bee Colony (ABC) algorithm to boost the security of IoT-based smart irrigation systems. The proposed model applies the ABC algorithm to generate the private key for ECC. The results show that the optimal encoding and decoding times were 100 and 150 iterations, respectively. Moreover, compared to 3DES&ECC&SHA-256 and RC4&ECC&SHA-256, the total throughput of the proposed model was about 50.04% and 55.29% higher in encryption and 51.36% and 58.41% higher in decryption. The evaluation indicates a significant improvement (>50%) in the throughput rate. The performance results obtained indicate the efficiency and effectiveness of the proposed scheme in terms of performance and security.}
}
@article{DARWISH2021196,
title = {Towards sustainable industry 4.0: A green real-time IIoT multitask scheduling architecture for distributed 3D printing services},
journal = {Journal of Manufacturing Systems},
volume = {61},
pages = {196-209},
year = {2021},
issn = {0278-6125},
doi = {https://doi.org/10.1016/j.jmsy.2021.09.004},
url = {https://www.sciencedirect.com/science/article/pii/S0278612521001904},
author = {Lamis R. Darwish and Mohamed T. El-Wakad and Mahmoud M. Farag},
keywords = {3D printing, Industrial internet of things, Industry 4.0, Multitask scheduling, Online graph coloring, Real-time},
abstract = {As the keystones of the personalized manufacturing, the Industrial Internet of Things (IIoT) consolidated with 3D printing pave the path for the era of Industry 4.0 and smart manufacturing. By resembling the age of craft manufacturing, Industry 4.0 expedites the alteration from mass production to mass customization. When distributed 3D printers (3DPs) are shared and collaborated in the IIoT, a promising dynamic, globalized, economical, and time-effective manufacturing environment for customized products will appear. However, the optimum allocation and scheduling of the personalized 3D printing tasks (3DPTs) in the IIoT in a manner that respects the customized attributes submitted for each model while satisfying not only the real-time requirements but also the workload balancing between the distributed 3DPs is an inevitable research challenge that needs further in-depth investigations. Therefore, to address this issue, this paper proposes a real-time green-aware multi-task scheduling architecture for personalized 3DPTs in the IIoT. The proposed architecture is divided into two interconnected folds, namely, allocation and scheduling. A robust online allocation algorithm is proposed to generate the optimal allocation for the 3DPTs. This allocation algorithm takes into consideration meeting precisely the customized user-defined attributes for each submitted 3DPT in the IIoT as well as balancing the workload between the distributed 3DPs simultaneously with improving their energy efficiency. Moreover, meeting the predefined deadline for each submitted 3DPT is among the main objectives of the proposed architecture. Consequently, an adaptive real-time multi-task priority-based scheduling (ARMPS) algorithm has been developed. The built ARMPS algorithm respects both the dynamicity and the real-time requirements of the submitted 3DPTs. A set of performance evaluation tests has been performed to thoroughly investigate the robustness of the proposed algorithm. Simulation results proved the robustness and scalability of the proposed architecture that surpasses its counterpart state-of-the-art architectures, especially in high-load environments.}
}
@article{OUTAY2021104412,
title = {Simulation of connected driving in hazardous weather conditions: General and extensible multiagent architecture and models},
journal = {Engineering Applications of Artificial Intelligence},
volume = {104},
pages = {104412},
year = {2021},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2021.104412},
url = {https://www.sciencedirect.com/science/article/pii/S0952197621002608},
author = {Fatma Outay and Stéphane Galland and Nicolas Gaud and Abdeljalil Abbas-Turki},
keywords = {Agent-based simulation, Microscopic simulation, Traffic simulation, Foggy weather condition},
abstract = {Based on historical records, driving in hazardous weather conditions is one of the most serious causes that lead to fatal accidents on roads in general and in United Arab Emirates (UAE) highways in particular. One solution for improving road safety is to equip the vehicles and infrastructure with connected and smart devices. Before deploying a concrete solution to the field, it must be validated by simulation, and more specifically agent-based simulation. Several key features are expected for the simulation framework, such as the reproduction of different and detailed behaviors for the components of the road infrastructure and for the drivers, simulate specific weather conditions and forecast their impacts on the global system behavior. Additionally, several technological features are related to recent advancements in agent software engineering and simulation. This paper proposes an agent-based model for the modeling and simulation of traffic in foggy weather conditions that covers the above features and technological requirements. The architecture is used and validated on two scenarios of traffic on UAE highways in foggy weather conditions. The first scenario does not include an intelligent transport system, and the second considers smart speed limit panels. From the experiments, the proposed model supports the expected key features, i.e., microscopic simulation of intelligent transport systems, including infrastructure and connected cars, and of different driving behaviors (human or autonomous car). Even if the included weather condition model is basic, a proof of concept is provided regarding the connection of an agent model and a weather condition model.}
}
@article{SALMAN2018221,
title = {IoT survey: An SDN and fog computing perspective},
journal = {Computer Networks},
volume = {143},
pages = {221-246},
year = {2018},
issn = {1389-1286},
doi = {https://doi.org/10.1016/j.comnet.2018.07.020},
url = {https://www.sciencedirect.com/science/article/pii/S1389128618305395},
author = {Ola Salman and Imad Elhajj and Ali Chehab and Ayman Kayssi},
keywords = {IoT, Survey, SDN, Fog, Cloud, 5G},
abstract = {Recently, there has been an increasing interest in the Internet of Things (IoT). While some analysts disvalue the IoT hype, several technology leaders, governments, and researchers are putting serious efforts to develop solutions enabling wide IoT deployment. Thus, the huge amount of generated data, the high network scale, the security and privacy concerns, the new requirements in terms of QoS, and the heterogeneity in this ubiquitous network of networks make its implementation a very challenging task. SDN, a new networking paradigm, has revealed its usefulness in reducing the management complexities in today's networks. Additionally, SDN, having a global view of the network, has presented effective security solutions. On the other hand, fog computing, a new data service platform, consists of pushing the data to the network edge reducing the cost (in terms of bandwidth consumption and high latency) of “big data” transportation through the core network. In this paper, we critically review the SDN and fog computing-based solutions to overcome the IoT main challenges, highlighting their advantages, and exposing their weaknesses. Thus, we make recommendations at the end of this paper for the upcoming research work.}
}
@article{WANG2018141,
title = {Applying mobile phone data to travel behaviour research: A literature review},
journal = {Travel Behaviour and Society},
volume = {11},
pages = {141-155},
year = {2018},
issn = {2214-367X},
doi = {https://doi.org/10.1016/j.tbs.2017.02.005},
url = {https://www.sciencedirect.com/science/article/pii/S2214367X17300224},
author = {Zhenzhen Wang and Sylvia Y. He and Yee Leung},
keywords = {Big data, Mobile phone data, Mobility, Travel behaviour},
abstract = {Travel behaviour has been studied for decades to guide transportation development and management, with the support of traditional data collected by travel surveys. Recently, with the development of information and communication technologies (ICT), we have entered an era of big data, and many sources of novel data, including mobile phone data, have emerged and been applied to travel behaviour research. Compared with traditional travel data, mobile phone data have many unique features and advantages, which attract scholars in various fields to apply them to travel behaviour research, and a certain amount of progress has been made to date. However, this is only the beginning, and mobile phone data still have great potential that needs to be exploited to further advance human mobility studies. This paper provides a review of existing travel behaviour studies that have applied mobile phone data, and presents the progress that has been achieved to date, and then discusses the potential of mobile phone data in advancing travel behaviour research and raises some challenges that need to be dealt with in this process.}
}
@article{SHAO2019433,
title = {IoT Avatars: Mixed Reality Hybrid Objects for CoRe Ambient Intelligent Environments},
journal = {Procedia Computer Science},
volume = {155},
pages = {433-440},
year = {2019},
note = {The 16th International Conference on Mobile Systems and Pervasive Computing (MobiSPC 2019),The 14th International Conference on Future Networks and Communications (FNC-2019),The 9th International Conference on Sustainable Energy Information Technology},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2019.08.060},
url = {https://www.sciencedirect.com/science/article/pii/S1877050919309743},
author = {Yiyi Shao and Nadine Lessio and Alexis Morris},
keywords = {Internet-of-things, Avatars, Mixed Reality, Agents, Context-awareness, Human-Computer Interaction, Ambient Intelligence},
abstract = {The Internet of Things (IoT) continues its growth, adoption, toward ubiquitous usage but is not without the inevitable communication bandwidth challenge. Human-computer-interaction in this space must account for the multiple facets of human-in-the-loop considerations in IoT, yet current mechanisms are at present limited by display dimensions and unclear indicators. Mixed Reality (MR) may be a solution to this human communication bandwidth problem, as smart glasses and other head mounted displays could provide an ideal interface platform for IoT human-computer interaction, while handheld mobile MR can be used as a testbed. To bring MR interfaces to the IoT, this work contributes; i) a new IoT-Avatar architectural framework; ii) a bi-directional communication approach between an IoT system and a virtual avatar character representation; and iii) an early descriptive exploration of how such systems could be explored in future applications toward MR interfaces in ambient intelligent environments.}
}
@article{SERNA2018291,
title = {TRANSPORT ANALYSIS APPROACH BASED ON BIG DATA AND TEXT MINING ANALYSIS FROM SOCIAL MEDIA},
journal = {Transportation Research Procedia},
volume = {33},
pages = {291-298},
year = {2018},
note = {XIII Conference on Transport Engineering, CIT2018},
issn = {2352-1465},
doi = {https://doi.org/10.1016/j.trpro.2018.10.105},
url = {https://www.sciencedirect.com/science/article/pii/S235214651830262X},
author = {Ainhoa Serna and Slaven Gasparovic},
keywords = {transport, social media, text mining, natural language processing, user generated content},
abstract = {The goal of the study of the paper is to propose a dashboard with dynamic graphics using a qualitatively and quantitatively approach to investigate the tourists’ satisfaction according by transport mode used. The methodology implemented in the research includes data collection from TripAdvisor.com with geographic locations and their integration with statistical territorial data. Text mining techniques are applied in order to assess tourists’ perceptions on success factors, which may be used as planning support tools. The case study concerns Croatia country and shows the value and complementarity of Social Media-related data with official statistics for transport and tourism planning.}
}
@article{ABDELBASSET2021120431,
title = {An intelligent framework using disruptive technologies for COVID-19 analysis},
journal = {Technological Forecasting and Social Change},
volume = {163},
pages = {120431},
year = {2021},
issn = {0040-1625},
doi = {https://doi.org/10.1016/j.techfore.2020.120431},
url = {https://www.sciencedirect.com/science/article/pii/S0040162520312579},
author = {Mohamed Abdel-Basset and Victor Chang and Nada A. Nabeeh},
keywords = {Covid-19, Blockchain, Internet of medical things (iomt), Industry 4.0, Healthcare, 5 G},
abstract = {This paper describes a framework using disruptive technologies for COVID-19 analysis. Disruptive technologies include high-tech and emerging technologies such as AI, industry 4.0, IoT, Internet of Medical Things (IoMT), big data, virtual reality (VR), Drone technology, and Autonomous Robots, 5 G, and blockchain to offer digital transformation, research and development and service delivery. Disruptive technologies are essential for Industry 4.0 development, which can be applied to many disciplines. In this paper, we present a framework that uses disruptive technologies for COVID-19 analysis. The proposed framework restricts the spread of COVID-19 outbreaks, ensures the safety of the healthcare teams and maintains patients' physical and psychological healthcare conditions. The framework is designed to deal with the severe shortage of PPE for the medical team, reduce the massive pressure on hospitals, and track recovered patients to treat COVID-19 patients with plasma. The study provides oversight for governments on how to adopt technologies to reduce the impact of unprecedented outbreaks for COVID-19. Our work illustrates an empirical case study on the analysis of real COVID-19 patients and shows the importance of the proposed intelligent framework to limit the current outbreaks for COVID-19. The aim is to help the healthcare team make rapid decisions to treat COVID-19 patients in hospitals, home quarantine, or identifying and treating patients with typical cold or flu.}
}
@article{ZERROUKI2021215,
title = {Towards a Foundation of a Mutual Authentication Protocol for a Robust and Resilient PUF-Based Communication Network},
journal = {Procedia Computer Science},
volume = {191},
pages = {215-222},
year = {2021},
note = {The 18th International Conference on Mobile Systems and Pervasive Computing (MobiSPC), The 16th International Conference on Future Networks and Communications (FNC), The 11th International Conference on Sustainable Energy Information Technology},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2021.07.027},
url = {https://www.sciencedirect.com/science/article/pii/S1877050921014228},
author = {Fahem Zerrouki and Samir Ouchani and Hafida Bouarfa},
keywords = {Physically Uncloneable Functions, Hash Functions, Resiliency, Robustness, Performance, Authentication Protocol},
abstract = {Nowadays the resiliency is the main property in any system especially communication infrastructures. Unfortunately, many developers are working on making programs more resilient and reliable, facing people who want to use leaks in an unethical way, and breaking (or trying to break) largely used one-way functions such as MD5, SHA-1, or RSA based algorithms. As an alternative, exploiting Physically Unclonable Functions (PUF) can be a good solution to improve the level of robustness and security for encryption by adding a pinch of randomness when manufacturing it, while enabling the use of true randomness. A PUF is characterized by a ‘digital fingerprint’, as an identifier, derived from a complex physical object or device, such as IoT. It is like a black box, which takes an input, called Challenge, and producing an output, called Response. Actually, they are different types of PUF, Weak and Strong, depending on the amount and the heterogeneity of challenge-responses pairs. This paper provides the fundamental concepts and techniques needed to develop a robust and resilient PUF-based communication system. This objective is achieved by mathematically defining FUFs, from foundations to the attacks, by relying on more concepts around PUF, such as cryptanalysis, or asymptotic notations. Also, we develop a mutual communication protocol that ensures security between different parties peer-to-peer devices, and devices-server. We concertize the provided fundamentals in a concrete framework that is experimentally validated.}
}
@article{BOSCH202062,
title = {Orchestration of heterogeneous wireless networks: State of the art and remaining challenges},
journal = {Computer Communications},
volume = {149},
pages = {62-77},
year = {2020},
issn = {0140-3664},
doi = {https://doi.org/10.1016/j.comcom.2019.10.008},
url = {https://www.sciencedirect.com/science/article/pii/S0140366419308497},
author = {Patrick Bosch and Tom {De Schepper} and Ensar Zeljković and Jeroen Famaey and Steven Latré},
keywords = {Heterogeneous networks, Wireless networks, Programmable networks, Network management, SDN},
abstract = {Wireless devices have a plethora of technologies at their disposal to connect to the Internet and other services. Management and control of each technology are traditionally isolated, and coordination between technologies is nearly non-existent. This isolation leads to poor resource usage, which in turn reduces performance and service guarantees. To satisfy growing user demands, we need to leverage the different service guarantees offered by each technology. Additionally, we need to improve orchestration between technologies to increase performance and flexibility while offering a more extensive range of service guarantees and maximizing resource utilization across networks and users. In this work, we present the general challenges one encounters when managing heterogeneous wireless networks. We argue that the primary challenge is the heterogeneity itself, the number of different devices and technologies, the different service requirements, and the increasing complexity as a consequence. However, technology abstraction can overcome these challenges. We provide an overview of state of the art commercial and scientific solutions and show their strengths and weaknesses. Based on this, we discuss the current status and what future challenges still await to provide full seamless heterogeneous wireless network management.}
}
@article{GOTTWALT2019234,
title = {CorrCorr: A feature selection method for multivariate correlation network anomaly detection techniques},
journal = {Computers & Security},
volume = {83},
pages = {234-245},
year = {2019},
issn = {0167-4048},
doi = {https://doi.org/10.1016/j.cose.2019.02.008},
url = {https://www.sciencedirect.com/science/article/pii/S0167404818306485},
author = {Florian Gottwalt and Elizabeth Chang and Tharam Dillon},
keywords = {Feature selection, Multivariate correlation, Correlation anomaly detection, Intrusion detection, Network anomaly detection},
abstract = {Recent research on network intrusion detection has focused on correlation-based techniques, which allow one to adapt to continuously changing environments such as the Internet of Things. Despite it being common practice for network intrusion detection to utilise feature selection techniques to enhance performance, correlation-based techniques have rarely been applied to them. This is mainly due the fact that traditional feature selection methods are not tailored to multivariate correlation techniques and new methods are required. To address this gap, we are introducing CorrCorr, a feature selection method for multivariate correlation-based network anomaly detection systems. Evaluated on the UNSW-NB15 and NSL-KDD intrusion detection dataset, CorrCorr consistently outperformed the original features as well as features selected with a Principal Component Analysis (PCA) and a Pearson class label correlation. We also analysed the UNSW-NB15 dataset on feature correlations and have identified several weaknesses.}
}
@article{HOSSEINI2018123,
title = {Supporting sustainable system adoption: Socio-semantic analysis of transit rider debates on social media},
journal = {Sustainable Cities and Society},
volume = {38},
pages = {123-136},
year = {2018},
issn = {2210-6707},
doi = {https://doi.org/10.1016/j.scs.2017.12.025},
url = {https://www.sciencedirect.com/science/article/pii/S2210670717310168},
author = {Moein Hosseini and Tamer El-Diraby and Amer Shalaby},
keywords = {Customer satisfaction, Energy saving, Ridership behavior, Social media, Social network analysis, Semantic analysis},
abstract = {Online social media platforms provide a bi-directional communication channel between transit agencies and their customers. It can also be an effective venue for profiling users and their needs as a step towards customizing service and communication policies. This study analyzed online Twitter discussions for three major transit agencies in Canada. In our work, we integrate the analysis of the participants’ social networks with the contents of their discussion. We also conduct the semantic analysis in a manner that parallels the structure and contents of customer satisfaction surveys—allowing for insightful comparisons between the results of both methods Analysis of the structure of the social networks of the Twitter accounts under study, including investigation of the formation of sub-communities and their interrelationship to the overall network. It was found that networks of the three cases portray a scale free and small world behaviors. This means that they are maturing networks; and that they represent viable communities—not just a randomly connected graph. This is important for future studies in relation to information diffusion and opinion dynamics: how people share information and how does this help shape their views. On the semantic front, a lexicon was developed based on existing thesauri for customer satisfaction analysis. Keywords form each tweet were extracted and the topic(s) of each tweet was defined based on the lexicon. It was found that, based on the sample investigated, the behavior of 100-follower networks (networks with nodes having at least 100 followers) closely mimics the behavior of the overall network. Studying these networks (of influential users) can make analysis faster and may not impact accuracy. We also clustered each network into sub-networks: small, medium, and large. Topics discussed in medium-size networks tended to be unique. This seems to be the level where active discussions of specific topics take place. Focusing on detecting these and analyzing their contents can provide better chance for capturing the evolution of community opinions.}
}
@article{ZHANG2020799,
title = {Vehicle communication network in intelligent transportation system based on Internet of Things},
journal = {Computer Communications},
volume = {160},
pages = {799-806},
year = {2020},
issn = {0140-3664},
doi = {https://doi.org/10.1016/j.comcom.2020.03.041},
url = {https://www.sciencedirect.com/science/article/pii/S0140366420301754},
author = {Hong Zhang and Xinxin Lu},
keywords = {Internet of Things, Intelligent transportation, Vehicle communication network, OPNET modeler, V2V network},
abstract = {With the rapid development of modern cities, relatively backward traffic management methods, inadequate road planning and construction, and the surge in car ownership, the problem of “urban traffic congestion” has become a problem faced by modern urban management. Intelligent Transportation System (ITS) is gradually becoming the research direction for solving the problem of traffic congestion in various countries around the world. Based on the above background, the purpose of this article is to study the vehicle communication network in the intelligent transportation system based on the Internet of Things. This paper uses OPNET Modeler software to build a vehicle movement model. OPNET Modeler uses a layered network simulation method. From the perspective of the protocol, the node module complies with the OSI standard of the open system interconnection model. From bottom to top, it is the physical layer, MAC layer, ARP layer, IP encapsulation layer, IP layer, TCP layer, and service layer. In a multi-hop scenario of vehicle self-organizing network in an intelligent transportation system based on the Internet of Things, simulation experiments show that when the vehicle is running at low speed, the wireless network coverage problem of the vehicle self-organizing network on the ground, especially In terms of the design and configuration of the roadside unit, the distance of the roadside unit should be maintained between 500 m and 600 m. At this time, the overall performance of the vehicle self-organizing network is stable. AODV protocol is superior to DSR protocol in terms of throughput, average network delay, routing load, packet loss rate, and average routing hops, and is more suitable for network communication needs.}
}
@article{KANTAKUMAR2020102269,
title = {What drives urban growth in Pune? A logistic regression and relative importance analysis perspective},
journal = {Sustainable Cities and Society},
volume = {60},
pages = {102269},
year = {2020},
issn = {2210-6707},
doi = {https://doi.org/10.1016/j.scs.2020.102269},
url = {https://www.sciencedirect.com/science/article/pii/S221067072030490X},
author = {Lakshmi N. Kantakumar and Shamita Kumar and Karl Schneider},
keywords = {Driving factors, Modelling, Performance, Predictive power, Sustainable cities, Urban planning},
abstract = {ABSTRACT
Proactive planning and management of rapidly urbanizing cities using up-to-date spatially explicit datasets is an urgent need. This requires a good understanding of the driving factors responsible for urban growth. Using Pune metropolis as test site, this paper presents an approach to assess the relative importance of urban growth driving factors from inexpensive geospatial datasets with respect to (i) urbanization process, (ii) urban planning (iii) urban growth modelling by utilizing relative importance analysis (RIA) as a supplement to logistic regression. Furthermore, this research proposes a new approach to reduce the parameterization and data requirement of urban growth models. Our research shows, that proximity to essential infrastructure has the highest predictive power in explaining urban growth of Pune. The importance of policy factors increase with time. Our results reveal that RIA is a suitable method, which can assist planners in deeper understanding of the urbanization process and to devise sustainable urban development strategies, utilizing a limited amount of data, which can be easily updated from geospatial datasets. The proposed break point method based on RIA to reduce parameterization of urban models performed at par with the model results achieved with the traditional AIC approach using less than half of the total number of driving factors.}
}
@article{SANMARTIN2018870,
title = {Methodology for sizing stand-alone hybrid systems: A case study of a traffic control system},
journal = {Energy},
volume = {153},
pages = {870-881},
year = {2018},
issn = {0360-5442},
doi = {https://doi.org/10.1016/j.energy.2018.04.099},
url = {https://www.sciencedirect.com/science/article/pii/S0360544218307126},
author = {Idoia {San Martín} and Alberto Berrueta and Pablo Sanchis and Alfredo Ursúa},
keywords = {Stand-alone hybrid systems, Renewable energy, Sizing, Lithium-ion battery, Modelling},
abstract = {This paper proposes a methodology for sizing stand-alone hybrid photovoltaic-wind power generation systems. This methodology makes it possible to optimise the overall performance of the stand-alone system components, based on the premise of guaranteeing the power supply throughout the useful life of the installation at a minimum cost. The sizing is performed in two stages. Firstly, the components of the wind and photovoltaic power generation subsystem are obtained and, secondly, the size of the storage subsystem is determined. For the storage subsystem sizing, account is taken of the variation in efficiency according to the operating point and also the deterioration of the subsystem due to aging and, therefore, the loss of available energy during the useful life of the installation. This methodology is applied to a stand-alone traffic control system located on a secondary road in the Autonomous Community of Valencia (Spain). This system comprises wind and photovoltaic power generation components, a lithium battery bank and various traffic management components. Finally, an analysis of the proposed sizing is made. Satisfactory results are obtained, showing how the proposed methodology makes it possible to optimise the sizing of stand-alone systems with regard to the size of its components, cost and operation.}
}
@article{ZHENG2016141,
title = {CMPTF: Contextual Modeling Probabilistic Tensor Factorization for recommender systems},
journal = {Neurocomputing},
volume = {205},
pages = {141-151},
year = {2016},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2016.04.016},
url = {https://www.sciencedirect.com/science/article/pii/S0925231216302594},
author = {Cong Zheng and Haihong E and Meina Song and Junde Song},
keywords = {Recommender systems, Context aware, Tensor factorization},
abstract = {Contextual information has been proven to be valuable factor for building personalized Recommender Systems. However, most existing solutions based on probabilistic matrix factorization in recommender systems do not provide a straightforward way of integrating information such as ratings, social relationships, item contents and contexts into one model simultaneously. In this paper, we deem the given data as an User-Item-Context-Rating tensor and introduce a high dimensional method of Collaborative Filtering named probabilistic tensor factorization (PTF) which is a generalization of probabilistic matrix factorization. Then, we further extend PTF to a new model named Contextual Modeling Probabilistic Tensor Factorization (CMPTF) which systematically integrates topic modeling, social relationships and contexts in contextual modeling manner to further improve the quality of recommendation. Comprehensive comparative experiments conducted using real-world datasets demonstrate the superiority of our approach.}
}
@article{WANG2019117499,
title = {Big data: New tend to sustainable consumption research},
journal = {Journal of Cleaner Production},
volume = {236},
pages = {117499},
year = {2019},
issn = {0959-6526},
doi = {https://doi.org/10.1016/j.jclepro.2019.06.330},
url = {https://www.sciencedirect.com/science/article/pii/S0959652619323078},
author = {Zhaohua Wang and Mengtian Xue and Yutao Wang and Malin Song and Shanjun Li and Ricardo A. Daziano and Bo Wang and Guanhua Ma and Ke Chen and Xiangtao Li and Bin Zhang},
keywords = {Big data, Sustainable consumption, Low carbon, Climate change},
abstract = {Growing consumption has brought a series of environmental problems. Sustainable consumption patterns which could meet human needs, improve the quality of lives, and reduce pollutants in the product life cycle emerge and develop. With the development and application of information and network technology, the scale and variety of data are increasing rapidly; advances in data analytics have made the economy, and consumption, quantifiable and visible. At present, many scholars rely on a big-data background and carry out research on sustainable consumption. Therefore, we called for sustainable and consumption papers for special volume of Journal of Cleaner Production (JCLPRO). We received submissions from all over the world and eventually accepted 45. This Special Issue forming a study on sustainable energy consumption, low-carbon transportation, waste recovery and recycling, climate change cost assessment, application and policy modelling for big data and sustainable consumption to promote sustainable development in the fields of energy consumption, low-carbon transportation, waste recovery, and so on. The authors have analysed the problems of pollution and carbon emission in different regions and product production cycles, according to the background of specific regions and enterprises, through data mining, measurement models, and an evaluation index system. Some suggestions are provided for urban construction and enterprise development according to the results.}
}
@article{SHAHBAZ2021101473,
title = {Environmental air pollution management system: Predicting user adoption behavior of big data analytics},
journal = {Technology in Society},
volume = {64},
pages = {101473},
year = {2021},
issn = {0160-791X},
doi = {https://doi.org/10.1016/j.techsoc.2020.101473},
url = {https://www.sciencedirect.com/science/article/pii/S0160791X20312768},
author = {Muhammad Shahbaz and Changyuan Gao and LiLi Zhai and Fakhar Shahzad and Imran Khan},
keywords = {Big data analytics, Environmental air pollution, BDA-EAP management system, UTAUT, Task-technology fit},
abstract = {This study has a dual purpose: to explore the novel phenomenon of a big data analytics-environmental air pollution (BDA-EAP) management system, and to propose a research model of factors influencing adoption of such a system. The research model is based on task-technology fit (TTF) and unified theory of acceptance and use of technology (UTAUT) concepts. A comprehensive BDA-EAP management system is proposed and the potential adoption speed of such a system evaluated by sending structured questionnaires to the employees of relevant environmental agencies, yielding 412 valid responses, using the structural equation modeling approach. The results of the study predict that factors of TTF including task characteristics and technology characteristics are strong influencers of TTF, and TTF is a strong predictor of the behavioral intention of users to adopt a BDA-EAP management system. The results demonstrated that the combination of TTF and UTAUT is a stronger predictor of behavioral intention than either TTF or UTAUT alone. Furthermore, resistance to change negatively moderates and extrinsic motivation positively moderates the significant positive relationship between behavioral intention and adoption of a BDA-EAP management system. Meanwhile, behavioral intention, resistance to change, and extrinsic motivation have a significant three-way interaction impact on adoption of a BDA-EAP management system such that an increase in users’ extrinsic motivation will decrease the negative impact of resistance to change during the process of adoption. The study findings contribute to the literature regarding the use of BDA to manage EAP, and provide a basis for future research in this area.}
}
@article{SAWUT201814,
title = {Possibility of optimized indices for the assessment of heavy metal contents in soil around an open pit coal mine area},
journal = {International Journal of Applied Earth Observation and Geoinformation},
volume = {73},
pages = {14-25},
year = {2018},
issn = {0303-2434},
doi = {https://doi.org/10.1016/j.jag.2018.05.018},
url = {https://www.sciencedirect.com/science/article/pii/S0303243418301533},
author = {Rukeya Sawut and Nijat Kasim and Abdugheni Abliz and Li Hu and Ahunaji Yalkun and Balati Maihemuti and Shi Qingdong},
keywords = {Heavy metal, Optimized spectral indices, GWR model, Coal mine field, Hyperspectral},
abstract = {Spectroscopy is regarded as a quick and nondestructive method to classify and quantitatively analyze many elements of the soil. Visible and Near-infrared reﬂectance spectroscopy offers a conductive tool for investigating soil heavy metal pollution. The main goal of this work is to obtain spectral optimized indices (RSI, NPDI and NDSI) related to soil heavy metal Arsenic (As), to estimate the As contents in soil based on geographically weighted regression model (GWR), and to investigate the plausibility of using these spectral optimized indices to map the distribution of heavy metal Arsenic in the soil of coal mining areas. The spectral optimized indices (RSI, NPDI and NDSI) derived from the original and transformed reflectance (the reciprocal (1/R), logarithm (lgR), logarithm-reciprocal (1/lgR) and root mean square method (R ) were used to construct the GWR models. Then, the variables (RSIs, NPDIs and NDIs) were applied in estimating the Arsenic (As) concentration and in the mapping of the As distribution in this study region. The NPDIs calculated by the original and transformed reflectance (R, 1/R, lgR, 1/lgR, and R ) indicated higher correlation coefficient values than NDSI and RSI. The highest correlation coefficient and lowest p-values (r≥0.73 and p=0.001) were found in thenear-infrared (NIR, 780–1100 nm) and shortwave infrared (SWIR, 1100–1935 nm). From the 4 prediction models (GWR) performances, it can be seen that Model-a (R) showed superior performance to the other three models (Model-b (1/R), Model-c (R ) and Model-d (lgR)), and it has the highest validation coefficients (R2 = 0.831, RMSE =4.912 μg/g, RPD=2.321) and lowest AIC (Akaike Information Criterion) value (AIC=179.96). NPDI1417 nm, 1246 nm is more sensitive and potential hyperspectral index for As in the study area. Thus, the two band optimized index (NPDI1417 nm, 1246 nm) might be recommended as an indicator for estimating soil As content. The hyperspectral optimized indices may help to quickly and accurately evaluate Arsenic contents in soil, and furthermore, the results provide theoretical and data support to access the distribution of heavy metal pollution in surface soil, promoting fast and efficient investigation of mining environment pollution and sustainable development of ecology.}
}
@article{ZHU202026,
title = {Leveraging photogrammetric mesh models for aerial-ground feature point matching toward integrated 3D reconstruction},
journal = {ISPRS Journal of Photogrammetry and Remote Sensing},
volume = {166},
pages = {26-40},
year = {2020},
issn = {0924-2716},
doi = {https://doi.org/10.1016/j.isprsjprs.2020.05.024},
url = {https://www.sciencedirect.com/science/article/pii/S0924271620301507},
author = {Qing Zhu and Zhendong Wang and Han Hu and Linfu Xie and Xuming Ge and Yeting Zhang},
keywords = {Aerial-ground integration, Feature matching, 3D reconstruction, Multi-view stereo, Structure-from-motion},
abstract = {Integration of aerial and ground images has been proved as an efficient approach to enhance the surface reconstruction in urban environments. However, as the first step, the feature point matching between aerial and ground images is remarkably difficult, due to the large differences in viewpoint and illumination conditions. Previous studies based on geometry-aware image rectification have alleviated this problem, but the performance and convenience of this strategy are still limited by several flaws, e.g. quadratic image pairs, segregated extraction of descriptors and occlusions. To address these problems, we propose a novel approach: leveraging photogrammetric mesh models for aerial-ground image matching. The methods have linear time complexity with regard to the number of images. It explicitly handles low overlap using multi-view images. The proposed methods can be directly injected into off-the-shelf structure-from-motion (SFM) and multi-view stereo (MVS) solutions. First, aerial and ground images are reconstructed separately and initially co-registered through weak georeferencing data. Second, aerial models are rendered to the initial ground views, in which color, depth and normal images are obtained. Then, feature matching between synthesized and ground images are conducted through descriptor searching and geometry-constrained outlier removal. Finally, oriented 3D patches are formulated using the synthesized depth and normal images and the correspondences are propagated to the aerial views through patch-based matching. Experimental evaluations using five datasets reveal satisfactory performance of the proposed methods in aerial-ground image matching, which succeeds in all of the ten challenging pairs compared to only three for the second best. In addition, incorporation of existing SFM and MVS solutions enables more complete reconstruction results, with better internal stability.}
}
@article{LEE2019100072,
title = {PDS: Deduce elder privacy from smart homes},
journal = {Internet of Things},
volume = {7},
pages = {100072},
year = {2019},
issn = {2542-6605},
doi = {https://doi.org/10.1016/j.iot.2019.100072},
url = {https://www.sciencedirect.com/science/article/pii/S2542660519300800},
author = {Ming-Chang Lee and Jia-Chun Lin and Olaf Owe},
keywords = {Internet of things, IoT, Smart home, Privacy, Deduction, Association rule learning},
abstract = {With the development of IoT technologies in the past few years, a wide range of smart devices are deployed in a variety of environments aiming to improve the quality of human life in a cost efficient way. Due to the increasingly serious aging problem around the world, smart homes for elder healthcare have become an important IoT-based application, which not only enables elders’ health to be properly monitored and taken care of, but also allows them to live more comfortably and independently in their houses. However, elders’ privacy might be disclosed from smart homes due to non-fully protected network communication. To show that elders’ privacy could be substantially exposed, in this paper we develop a Privacy Deduction Scheme (PDS for short) by eavesdropping sensor traffic from a smart home to identify elders’ movement activities and speculating sensor locations in the smart home based on a series of deductions from the viewpoint of an attacker. The experimental results based on sensor datasets from real smart homes demonstrate the effectiveness of PDS in deducing and disclosing elders’ privacy, which might be maliciously exploited by attackers to endanger elders and their properties.}
}
@article{XU2021129285,
title = {New understanding of miniaturized VOCs monitoring device: PID-type sensors performance evaluations in ambient air},
journal = {Sensors and Actuators B: Chemical},
volume = {330},
pages = {129285},
year = {2021},
issn = {0925-4005},
doi = {https://doi.org/10.1016/j.snb.2020.129285},
url = {https://www.sciencedirect.com/science/article/pii/S0925400520316257},
author = {Wei Xu and Yunfei Cai and Song Gao and Shuang Hou and Yong Yang and Yusen Duan and Qingyan Fu and Fei Chen and Jie Wu},
keywords = {VOCs, Low-cost sensors, Sensor evaluation, Performance, PID},
abstract = {With low-cost sensors getting more attention in network monitoring, whether volatile organic compounds (VOCs) sensors are easily serviceable in ambient air monitoring is debatable. Evaluations of performance are necessary to provide a comprehensive understanding of commercially available sensor devices at present. In this paper, 17 photo-ionization detectors (PID) based VOC sensor devices have been evaluated through both laboratory and field tests, sensor were primarily from Alphasense and Baseline. The results exhibited the average level of all participating devices and the influence of the humidity on the results has been discussed in detail. Good linearity (R2>0.93), repeatability (<10 %), and quick response time (T80<1 min) over the target gases in the laboratory have been revealed. The average of intra-best two devices correlation (R) is 0.68 and correlations (R2) with reference data are 0.5∼0.8 for one third of devices in the field tests. However, the accuracy is not as robust as flame ionization detector (FID). In summary, PID-type VOC sensor devices are capable of providing useful information in some application scenarios. The features of quick response and good accuracy at high concentrations are recognized as pollution indicators. Devices with good consistency, correlation and stability are appropriate for investigating the regional VOCs pollution distribution using network monitoring.}
}
@article{DJAMA202037,
title = {Information-Centric Networking solutions for the Internet of Things: A systematic mapping review},
journal = {Computer Communications},
volume = {159},
pages = {37-59},
year = {2020},
issn = {0140-3664},
doi = {https://doi.org/10.1016/j.comcom.2020.05.003},
url = {https://www.sciencedirect.com/science/article/pii/S0140366419316901},
author = {Adel Djama and Badis Djamaa and Mustapha Reda Senouci},
keywords = {Internet of Things, TCP/IP, Information-Centric Networks, Named Data Networking, Content-Centric Networking, Host-Centric communication, Data-Centric communication},
abstract = {Due to the similarity between the data-driven nature of sensor and actuator networks enabling the Internet of Things (IoT) and the data-oriented model of Information-Centric Networks (ICN), recent research began investigating ICN-based IoT systems. This paper provides a thorough systematic mapping review of such research with the aim to identify their strengths, weaknesses, and open-research issues. Thus, after introducing the IoT ecosystem, its main requirements, existing IP-based solutions, and their limitations, the survey investigates the ICN-IoT associations that have been proposed in the recent literature. To do so, a new taxonomy that captures the fundamental aspects of ICN-based IoT solutions is introduced along with a multidimensional framework that provides a comprehensive multi-criteria analysis of the reviewed research. This paper also summarizes the main observations learned from the analysis and draws recommendations about open research issues that require the attention of the community. Such issues include limited standardization efforts, hybrid ICN/IP deployments, push-based communications, efficient caching schemes, and QoS solutions.}
}
@article{PEINL2021100456,
title = {A retrospective on ASPires—An advanced system for the prevention and early detection of forest fires},
journal = {Internet of Things},
pages = {100456},
year = {2021},
issn = {2542-6605},
doi = {https://doi.org/10.1016/j.iot.2021.100456},
url = {https://www.sciencedirect.com/science/article/pii/S2542660521000974},
author = {Peter Peinl},
keywords = {Biodiversity, Forest fire prevention and detection, Open system, Internet of Things, Cloud, Wireless communication technologies, Sensors, Drones},
abstract = {Forest fires cause huge, constantly increasing material damage and immaterial costs to humans, the environment and property. The paper describes the design and a prototypical implementation of an open system (ASPires) for the prevention and early detection of forest fires (public information (ASPires Consortium, 2019), overview (Peinl et al., 2020 [2])). Collected data are sent to and stored within a Cloud based system and may be rapidly made available to or forwarded to Crisis Management Centers (CMC)s or other institutions or human users. Among others, the use of new sensor and mobile communication technologies, the use of drones, data storage and analysis in a cloud, and direct connection with authorities reduces reaction time and thereby damage. This also sustains biodiversity in remote areas with rare and endemic species of flora and fauna. The concept has been tested and proven in 3 national parks in South East Europe.}
}
@article{ZHOU2021103328,
title = {Semantic-based discovery method for high-performance computing resources in cyber-physical systems},
journal = {Microprocessors and Microsystems},
volume = {80},
pages = {103328},
year = {2021},
issn = {0141-9331},
doi = {https://doi.org/10.1016/j.micpro.2020.103328},
url = {https://www.sciencedirect.com/science/article/pii/S0141933120304877},
author = {Aolong Zhou and Kaijun Ren and Xiaoyong Li and Wen Zhang and Xiaoli Ren and Kefeng Deng},
keywords = {Cyber-physical system, High-performance computing, Ontology, Resource discovery},
abstract = {High-performance computing (HPC) systems with powerful computing capabilities are becoming increasingly significant in the large-scale cyber-physical systems (CPS), helping CPS process a huge number of real-time data. Nowadays, the efficiency of HPC resource management and discovery becomes a challenging problem in CPS, due to the complex characteristics of HPC resources and the growing demands of the users. Although lots of recent efforts have been conducted to the resource discovery in distributed systems, they cannot be well adapted for the cross-regional HPC environments, due to the lack of unified model for the resources description and consideration for the usability demands of non-expert users. In this paper, we propose novel techniques to try to solve the problem. Specifically, we first propose a unified semantic model named HPCRO for specifying cross-regional HPC resources, and apply ontology reasoning to obtain more semantic information for queries. Moreover, we propose a WordNet-based quick resource index list data structure called WQRIL to improve the query. Finally, according to the proposed model and data structure, we propose an efficient discovery method called ROLD for cross-regional HPC resources. Extensive experimental results demonstrate that, our proposals not only maintain efficient resource discovery performance, but also achieve the highest precision rate (94.76%), recall rate (92.34%) and F1-score (93.53%).}
}
@article{CICIRELLI2019189,
title = {ITEMa: A methodological approach for cognitive edge computing IoT ecosystems},
journal = {Future Generation Computer Systems},
volume = {92},
pages = {189-197},
year = {2019},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2018.10.003},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X17330224},
author = {Franco Cicirelli and Antonio Guerrieri and Alessandro Mercuri and Giandomenico Spezzano and Andrea Vinci},
keywords = {IoT-based ecosystems, Cognitive systems, Edge and cloud computing, Smart office, Activity recognition},
abstract = {The ever-increasing spread of Internet of Things (IoT)-based technologies paired with the diffusion of the edge-based computing boosts the development of pervasive cyber ecosystems having the goal of improving the life quality of people and assisting them in daily activities. In this context, cognitive behaviors are purposely required to make such ecosystems able to adapt to people needs and to envisage their behaviors. Despite the growing interest in cognitive ecosystems, still there is a lack of methodological approaches devoted to supporting the design and implementation of such complex systems. This paper proposes ITEMa, an Iot-based smarT Ecosystem Modeling Approach based on a three-layered architecture offering some well-suited abstractions tailored to the development of IoT-based ecosystems which exhibit cognitive behaviors and are able to exploit computational resources located either at the edge of the network or in the Cloud. The effectiveness of the approach is demonstrated through a case study concerning the development of a Smart Office devoted to forecast some usual office activities and to properly adapt the office environmental conditions to them.}
}
@article{HADI2018180,
title = {Big data analytics for wireless and wired network design: A survey},
journal = {Computer Networks},
volume = {132},
pages = {180-199},
year = {2018},
issn = {1389-1286},
doi = {https://doi.org/10.1016/j.comnet.2018.01.016},
url = {https://www.sciencedirect.com/science/article/pii/S1389128618300239},
author = {Mohammed S. Hadi and Ahmed Q. Lawey and Taisir E.H. El-Gorashi and Jaafar M.H. Elmirghani},
keywords = {Big data analytics, Network design, Self-optimization, Self-configuration, Self-healing network},
abstract = {Currently, the world is witnessing a mounting avalanche of data due to the increasing number of mobile network subscribers, Internet websites, and online services. This trend is continuing to develop in a quick and diverse manner in the form of big data. Big data analytics can process large amounts of raw data and extract useful, smaller-sized information, which can be used by different parties to make reliable decisions. In this paper, we conduct a survey on the role that big data analytics can play in the design of data communication networks. Integrating the latest advances that employ big data analytics with the networks’ control/traffic layers might be the best way to build robust data communication networks with refined performance and intelligent features. First, the survey starts with the introduction of the big data basic concepts, framework, and characteristics. Second, we illustrate the main network design cycle employing big data analytics. This cycle represents the umbrella concept that unifies the surveyed topics. Third, there is a detailed review of the current academic and industrial efforts toward network design using big data analytics. Forth, we identify the challenges confronting the utilization of big data analytics in network design. Finally, we highlight several future research directions. To the best of our knowledge, this is the first survey that addresses the use of big data analytics techniques for the design of a broad range of networks.}
}
@article{VERDERAME2020919,
title = {A secure cloud-edges computing architecture for metagenomics analysis},
journal = {Future Generation Computer Systems},
volume = {111},
pages = {919-930},
year = {2020},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2019.09.013},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X19301207},
author = {Luca Verderame and Ivan Merelli and Lucia Morganti and Elena Corni and Daniele Cesini and Daniele D’Agostino and Alessio Merlo},
keywords = {Edge computing, Cloud computing, Trusted cloud-edges computations, Metagenomics, Internet of Things},
abstract = {Portable sequencing machines, such as the Oxford Nanopore MinION, are making the genome sequencing ubiquitous. Consequently, metagenomic studies are becoming increasingly popular, yielding important insights into microbial communities covering diverse environments from terrestrial to aquatic ecosystems. Furthermore, the adoption of low-power IoT computing devices represents a feasible way of distributing and managing those machines on the field. However, a key issue is represented by the huge amount of data produced during operations, whose management is actually challenging considering the resources required for an efficient data transfer and processing. In order to deal with such a challenge, this paper put forward a novel architecture based on the coupling of Edge and Cloud computing paradigms. The focus of the paper is the Edge layer, responsible for the dynamic management of the full analysis pipeline of IoT devices producing large datasets like the MinION ones while adopting proper security mechanisms that handle the authentication of on-field devices and the confidentiality of the transmitted data.}
}
@article{BENELIA2015352,
title = {Response to Travel Information: A Behavioural Review},
journal = {Transport Reviews},
volume = {35},
number = {3},
pages = {352-377},
year = {2015},
issn = {0144-1647},
doi = {https://doi.org/10.1080/01441647.2015.1015471},
url = {https://www.sciencedirect.com/science/article/pii/S0144164722002227},
author = {Eran Ben-Elia and Erel Avineri},
keywords = {travel behaviour, choice modelling, bounded rationality, information, persuasion, cooperation},
abstract = {Innovation in information and communication technologies (ICTs) is providing us with a myriad of travel information sources. Knowledge on the influence of information on human travel behaviour (mainly route and mode choice) and their implications on network levels of service remains fragmented. We distinguish between experiential, descriptive, and prescriptive information sources. We draw on recently developed theoretical concepts in behavioural and cognitive sciences to examine the state of the knowledge on information and travel behaviour. Key theoretical concepts used to explore the relationship between information and travel behaviour include: reinforced learning; framing; risk and loss aversion; probability weighting; affect; anchoring and ambiguity aversion; and regret aversion. We review studies focusing on individual travel behaviour as well as network studies involving collective behaviours. While information seems to assist individual travellers in coping with uncertainty, the impacts relating to collective behaviour on networks remain unclear. Many open questions remain, yet research provides important insights and suggests that ICTs will enable the design of persuasive information systems that motivate cooperative and efficient use of the transportation network beyond what is possible today.}
}
@article{HARDY201730,
title = {Opening up government data for Big Data analysis and public benefit},
journal = {Computer Law & Security Review},
volume = {33},
number = {1},
pages = {30-37},
year = {2017},
issn = {0267-3649},
doi = {https://doi.org/10.1016/j.clsr.2016.11.003},
url = {https://www.sciencedirect.com/science/article/pii/S026736491630214X},
author = {Keiran Hardy and Alana Maurushat},
keywords = {Open data, Big Data, Privacy law, Open Government Partnership, Open Government Declaration, Open Data Charter, Freedom of information},
abstract = {Governments around the world are posting many thousands of their datasets on online portals. A major purpose of releasing this data is to drive innovation through Big Data analysis, as well as to promote government transparency and accountability. This article considers the benefits and risks of releasing government data as open data, and identifies the challenges the Australian government faces in releasing its data into the public domain. The Australian government has ambitious aims to release greater amounts of its data to the public. However, it is likely this task will prove difficult due to uncertainties surrounding the reliability of de-identification and the requirements of privacy law, as well as a public service culture which is yet to fully embrace the open data movement.}
}
@article{BERRUETA20181,
title = {Combined dynamic programming and region-elimination technique algorithm for optimal sizing and management of lithium-ion batteries for photovoltaic plants},
journal = {Applied Energy},
volume = {228},
pages = {1-11},
year = {2018},
issn = {0306-2619},
doi = {https://doi.org/10.1016/j.apenergy.2018.06.060},
url = {https://www.sciencedirect.com/science/article/pii/S0306261918309279},
author = {Alberto Berrueta and Michael Heck and Martin Jantsch and Alfredo Ursúa and Pablo Sanchis},
keywords = {Energy storage system, Lithium-ion battery, Optimal energy dispatch scheduling, Dynamic programming method, Energy arbitrage, Renewable energy},
abstract = {The unpredictable nature of renewable energies is drawing attention to lithium-ion batteries. In order to make full utilization of these batteries, some research works are focused on the management of existing systems, while others propose sizing techniques based on business models. However, in order to optimise the global system, a comprehensive methodology that considers both battery sizing and management at the same time is needed. This paper proposes a new optimisation algorithm based on a combination of dynamic programming and a region-elimination technique that makes it possible to address both problems at the same time. This is of great interest, since the optimal size of the storage system depends on the management strategy and, in turn, the design of this strategy needs to take account of the battery size. The method is applied to a real installation consisting of a 100 kWp rooftop photovoltaic plant and a Li-ion battery system connected to a grid with variable electricity price. Results show that, unlike conventional optimisation methods, the proposed algorithm reaches an optimised energy dispatch plan that leads to a higher net present value. Finally, the tool is used to provide a sensitivity analysis that identifies key informative variables for decision makers.}
}
@article{ALBUQUERQUE2020100922,
title = {Privacy in smart toys: Risks and proposed solutions},
journal = {Electronic Commerce Research and Applications},
volume = {39},
pages = {100922},
year = {2020},
issn = {1567-4223},
doi = {https://doi.org/10.1016/j.elerap.2019.100922},
url = {https://www.sciencedirect.com/science/article/pii/S1567422319300997},
author = {Otávio de Paula Albuquerque and Marcelo Fantinato and Judith Kelner and Anna Priscilla {de Albuquerque}},
keywords = {Internet of Toys, Connected toys, Data privacy, Children, Literature review, Scoping review},
abstract = {Smart toys have become popular as technological solutions offer a better experience for children. However, the technology employed greatly increases the risks to children’s privacy, which does not seem to have become a real concern for toy makers. We investigated this issue through a study driven by two major research questions: which are the major smart toys-related children’s privacy risks and which are the major mitigation so to such risks. To answer these questions, we conducted a scoping review. As a result, we selected 26 primary studies and elaborated two classifications of risks and proposed solutions – technical and domain-specific. The most mentioned technical risk is data disclosure, while from a domain-specific perspective there is much concern on the children’s physical and psychological safety. From a mitigation standpoint, many recommendations and solutions have been proposed, but without a more common type of contribution. As a main conclusion, we observed that toy makers and privacy regulations are not yet ready regarding children’s privacy for a more active smart toys market.}
}
@article{ZHU2020101113,
title = {Consensus-oriented cloud manufacturing based on blockchain technology: An exploratory study},
journal = {Pervasive and Mobile Computing},
volume = {62},
pages = {101113},
year = {2020},
issn = {1574-1192},
doi = {https://doi.org/10.1016/j.pmcj.2020.101113},
url = {https://www.sciencedirect.com/science/article/pii/S1574119220300018},
author = {Xiaobao Zhu and Jing Shi and Samuel Huang and Bin Zhang},
keywords = {Cloud manufacturing, Blockchain technology, KNN, Ethereum, POA, Consensus-oriented},
abstract = {In the era of cloud computing and Industry 4.0, significant research efforts on cloud manufacturing have been witnessed in recent years. Nevertheless, challenges, such as issues of trust, safety, payment, remain in this emerging area, which cause less confidence for industry to adopt cloud manufacturing. In this regard, the recent development of blockchain technology provides a potential viable solution thanks to its unique advantages in decentralization and security. As such, we propose a new framework of cloud manufacturing by integrating the blockchain technology. In essence, consensus-oriented mechanisms are employed to generate the operating standards for the blockchain cloud manufacturing model. Moreover, based on the open source Ethereum code, we construct a simulation case study for 3D printing services using the proposed framework. A consortium or federated blockchain is simulated which uses Proof-of-Authority (PoA) as the consensus algorithm of block generation. The simulation involves 939 job requests from 100 users, as well as 10 service providers. The k-nearest neighbors (KNN) algorithm is employed to recommend the service provider for each request. The results show that the provider’s score of service evaluation tends to be stabilize, and 934 requests for service are successfully fulfilled by the appropriate providers while the remaining 5 requests fail to be serviced.}
}
@article{CHEN202166,
title = {Long-term optimization for MEC-enabled HetNets with device–edge–cloud collaboration},
journal = {Computer Communications},
volume = {166},
pages = {66-80},
year = {2021},
issn = {0140-3664},
doi = {https://doi.org/10.1016/j.comcom.2020.11.011},
url = {https://www.sciencedirect.com/science/article/pii/S0140366420319915},
author = {Long Chen and Jigang Wu and Jun Zhang},
keywords = {Long-term, Offloading, Edge computing, HetNet, Lyapunov, Collaboration},
abstract = {For effective computation offloading with multi-access edge computing (MEC), both communication and computation resources should be properly managed, considering the dynamics of mobile users such as the time-varying demands and user mobility. Most existing works regard the remote cloud server as a special edge server. However, service quality cannot be met when some of the edge servers cannot be connected. Besides, the computation capability of the cloud has not been fully exploited especially when edge servers are congested. We develop an on-line offloading decision and computational resource management algorithm with joint consideration of collaborations between device–cloud, edge–edge and edge–cloud. The objective is to minimize the total energy consumption of the system, subject to computational capability and task buffer stability constraints. Lyapunov optimization technique is used to jointly deal with the delay-energy trade-off optimization and load balancing. The optimal CPU-cycle frequencies, best transmission powers and offloading scheduling policies are jointly handled in the three-layer system. Extensive simulation results demonstrate that, with V varies in [0.1,5]×109, the proposed algorithm can save more than 50% energy and over 120% task processing time than three existing benchmark algorithms averagely.}
}
@article{YAN2017181,
title = {A novel robust model fitting approach towards multiple-structure data segmentation},
journal = {Neurocomputing},
volume = {239},
pages = {181-193},
year = {2017},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2017.02.015},
url = {https://www.sciencedirect.com/science/article/pii/S0925231217302850},
author = {Yan Yan and Min Liu and Si Chen and Fan Xiao},
keywords = {Robust statistics, Model fitting, Kernel density estimation, Multiple-structure data segmentation},
abstract = {We propose a novel and effective robust model fitting approach based on the Structure Decision Graph (SDG) to segment multiple-structure data in the presence of outliers. The proposed approach is motivated by the observations that each structure can be characterized by one representative hypothesis, called as the Structure Prototype (SP), and the SPs have relatively large distances among them. In this paper, instead of analyzing each hypothesis individually, the residuals over all the hypotheses are used to explicitly construct an SDG, where a sorted weight score set and a minimum arrived distance set are respectively computed. Based on the SDG, the SPs corresponding to different structures can be easily determined. Compared with conventional robust model fitting approaches, one distinguishing characteristic of our approach is that the clustering procedure is not required. Therefore, the proposed approach is less disturbed by noises and outliers, and is relatively easy to implement. Experimental results on synthetic data and real-world image datasets demonstrate the superiority of the proposed approach over the state-of-the-art robust model fitting approaches for multiple-structure data segmentation.}
}
@article{PETRONI2016583,
title = {LCBM: a fast and lightweight collaborative filtering algorithm for binary ratings},
journal = {Journal of Systems and Software},
volume = {117},
pages = {583-594},
year = {2016},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2016.04.062},
url = {https://www.sciencedirect.com/science/article/pii/S0164121216300371},
author = {F. Petroni and L. Querzoni and R. Beraldi and M. Paolucci},
keywords = {Collaborative filtering, Big data, Personalization, Recommendation systems},
abstract = {In the last ten years, recommendation systems evolved from novelties to powerful business tools, deeply changing the internet industry. Collaborative Filtering (CF) represents a widely adopted strategy today to build recommendation engines. The most advanced CF techniques (i.e. those based on matrix factorization) provide high quality results, but may incur prohibitive computational costs when applied to very large data sets. In this paper we present Linear Classifier of Beta distributions Means (LCBM), a novel collaborative filtering algorithm for binary ratings that is (i) inherently parallelizable (ii) provides results whose quality is on-par with state-of-the-art solutions (iii) at a fraction of the computational cost. These characteristics allow LCBM to efficiently handle large instances of the collaborative filtering problem on a single machine in short timeframes.}
}
@article{LIU201915,
title = {Network security situation: From awareness to awareness-control},
journal = {Journal of Network and Computer Applications},
volume = {139},
pages = {15-30},
year = {2019},
issn = {1084-8045},
doi = {https://doi.org/10.1016/j.jnca.2019.04.022},
url = {https://www.sciencedirect.com/science/article/pii/S1084804519301468},
author = {Xiaowu Liu and Jiguo Yu and Weifeng Lv and Dongxiao Yu and Yinglong Wang and Yu Wu},
keywords = {Network security situation awareness, Cognitive computing, Multi-source fusion, Threat gene, Reinforced learning, Cognitive control},
abstract = {Network Security Situation Awareness (NSSA) is a security theory which can perceive the network threat from a global perspective. In this paper, we present a Cognitive Awareness-Control Model (CACM) for NSSA. CACM adopts the cross-layer architecture and cognitive circle which can break through the interactive barrier between different network layers. Firstly, we propose a decision-level fusion method in which different weights are assigned for different data sources so that the fusion accuracy can be improved. Secondly, a hierarchical quantification approach is discussed which can avoid inferring the complex memberships among network components. Finally, a cognitive regulation mechanism is analysed in order to solve the issue of automatic control. The simulation experiments show that our model can perceive and regulate the threat situation effectively. To the best of our knowledge, this is the first discussion which utilizes cognitive awareness-control to solve the regulation problem of NSSA.}
}
@article{VANDERLEI2021246,
title = {Patent analysis by automated mind maps: Contribution to sustainability in a water and sewage sanitation company},
journal = {Sustainable Operations and Computers},
volume = {2},
pages = {246-253},
year = {2021},
issn = {2666-4127},
doi = {https://doi.org/10.1016/j.susoc.2021.07.005},
url = {https://www.sciencedirect.com/science/article/pii/S2666412721000271},
author = {Celso Arruda Vanderlei and Luc Quoniam and Cláudia Terezinha Kniess and Renato Ribeiro Nogueira Ferraz},
keywords = {Patents, Organizational Knowledge, Mental Maps, Data Science, Sustainability, Sanitation, Circular Economy},
abstract = {Patent databases represent an essential source of easily accessible information and technological knowledge. Inherent difficulties in the search for useful knowledge, in particular situations from large volumes of companies’ data, have resulted in little exploration in patent databases. The focus in this work was to evaluate the use of automated mind maps as an auxiliary tool in the discovery of knowledge in patent databases. In this context, the objective was to analyze the patent information in a contributory perspective for the sustainability of water and sewage companies. We performed the study using the participant observation technique in a basic sanitation company and resulted in discovering alternatives to improve crucial processes and producing discussions about new technologies aimed at the sector's sustainability. The company selected for the research is within a context of activities in constant challenge for innovations, since the collection and treatment of sewage is currently a problem of global proportions and of great impact in matters of environmental sustainability. In the Sanitation Sector, certain approaches are not necessarily new and much of what is preached in the Circular Economy has already taken place. For example, making beneficial use of sludge in the soil, production and use of reuse water, use of biogas for generating electricity, and heat and energy or bio-methane. The results pointed to the adding of the use of mind maps as another possibility for the discovery of knowledge in the analysis of patents.}
}
@article{CHATTERJEE2021101621,
title = {Harnessing the Potential of Artificial Intelligence to Foster Citizens’ Satisfaction: An empirical study on India},
journal = {Government Information Quarterly},
pages = {101621},
year = {2021},
issn = {0740-624X},
doi = {https://doi.org/10.1016/j.giq.2021.101621},
url = {https://www.sciencedirect.com/science/article/pii/S0740624X21000575},
author = {Sheshadri Chatterjee and Sangeeta Khorana and Hatice Kizgin},
keywords = {Artificial intelligence, AI-enabled services, Public services, Citizen satisfaction, Risk, India},
abstract = {Governments are increasingly employing artificial intelligence (AI) enabled services though this is still a relatively new concept that is in nascent stages of implementation. Despite growing emphasis by governments on employing AI-enabled services, many citizens are skeptical of their benefits; this makes an analysis of AI-enabled services an important area of research, especially from the perspective of citizens. This paper employs IT assimilation theory and public value theory to develop a theoretical model that examines whether the introduction of AI-enabled services would generate public value for citizens in India. The model employs the Partial Least Square-Structural Equation Modeling (PLS-SEM) technique to examine how risk factors impact the uptake of AI-enabled services in India. Based on 315 interviews conducted in India, the study highlights that the breadth and depth assimilation of AI-enabled services positively impacts and enhances the satisfaction of citizens, which in turn generates public value.}
}
@article{DEEBAK2020368,
title = {IoT-BSFCAN: A smart context-aware system in IoT-Cloud using mobile-fogging},
journal = {Future Generation Computer Systems},
volume = {109},
pages = {368-381},
year = {2020},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2020.03.050},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X19320874},
author = {B.D. Deebak and Fadi Al-Turjman and Moayad Aloqaily and Omar Alfandi},
keywords = {Internet of things, Smart communication, Cloud-enabled networks, Computation cost, Fog},
abstract = {Internet of Things (IoT) leverages the sensor inter-connectivity that offers a wide range of real-time monitoring opportunities for smart environmental systems. As a consequence, it is witnessed that IoT plays an important role in the next generation of smart communication networks. In the future, the evolution of smart environment becomes a pillar of 2020 society for the various innovative services. In order to deal with the challenges, such as supporting urban development and improving the quality of people’s life, an interdisciplinary approach is preferred. It is evident that the infrastructure of smart information and communication technology (ICT) claims to be a de facto standard to realize the smart vision of emerging technologies. Thus, an IoT-Based Smart CAN (IoT-BSFCAN) framework is proposed to monitor the smart environment continuously through smart computing devices over cloud-enabled networks. The objective of this framework is to minimize computation cost along with communication fairness, while it uses different kinds of user applications. Moreover, the illustrative result proves that the proposed IoT-BSFCAN framework yields better successful execution results than the other alternative solutions.}
}
@article{ZHANG2021107597,
title = {A survey on stateful data plane in software defined networks},
journal = {Computer Networks},
volume = {184},
pages = {107597},
year = {2021},
issn = {1389-1286},
doi = {https://doi.org/10.1016/j.comnet.2020.107597},
url = {https://www.sciencedirect.com/science/article/pii/S1389128620312305},
author = {Xiaoquan Zhang and Lin Cui and Kaimin Wei and Fung Po Tso and Yangyang Ji and Weijia Jia},
keywords = {SDN, Stateful data plane, Data plane programmability, P4, OpenState},
abstract = {Software Defined Networking (SDN), which decouples control plane and data plane, normally stores states on controllers to provide flexible programmability and convenient management. However, recent studies have shown that such configuration may cause frequent and unnecessary interactions between data plane and controllers in some cases. For example, a DDoS detection installed on a controller needs to fetch information from data plane periodically, introducing additional network delay and controller overhead. Thus, stateful data plane is proposed to offload states and operation logics from controller to data plane. Stateful data plane allows switches to perform some operations independently, accelerating packets processing while reducing overhead on both controllers and networks. However, stateful data plane increases the complexity of network devices and imposes many new challenges to the management and schedule of SDN enabled networks. This paper conducts a comprehensive survey on the latest research works and provides insights into stateful data plane. Both stateful data plane platforms and compilers are extensively summarized and analyzed, as well as explicit design of applications based on them. Afterwards, we dwell on the fundamental technologies and research challenges, including implementation considerations of stateful data plane. Finally, we conclude this survey paper with some future works and discuss open research issues.}
}
@article{RAY2020111,
title = {Sensors for internet of medical things: State-of-the-art, security and privacy issues, challenges and future directions},
journal = {Computer Communications},
volume = {160},
pages = {111-131},
year = {2020},
issn = {0140-3664},
doi = {https://doi.org/10.1016/j.comcom.2020.05.029},
url = {https://www.sciencedirect.com/science/article/pii/S0140366420300086},
author = {Partha Pratim Ray and Dinesh Dash and Neeraj Kumar},
keywords = {IoT, Sensors, Connected sensors, e-healthcare, Pervasive sensors, Security, Privacy},
abstract = {Health is wealth. Thus, it is very important to keep it healthy all the time for sustenance of human livelihood. Last decade has witnessed a number of digital developments, including sensors, microcontrollers, communication paradigm, and smarter societal need. Internet of Things (IoT) has pushed the human race toward harnessing of truly digitized e-healthcare services mainly by relying over the biosensors. Biosensors play most crucial role in IoT when question of e-healthcare comes into the scene. A range of sensors are available in market that help people to monitor daily fitness, blood glucose level and many smart home-based diagnostics. However, lack of proper categorization of such sensors has led to create problems like delay in government approval, gap in patient–doctor​ relationship, increased social inertia toward using the sensors in accordance to regular life style. To mitigate these issues, this work presents a systematic review on existing IoT-based sensors and IoT-market cap originated sensor-systems for taxonomically representation. We present comparative analysis among the reviewed sensors. We further present security and privacy issues associated with the sensor data and ways to mitigate them. We also discuss about futuristic plans to enhance current scenario. We further elaborate on how such intervention could be beneficial or problematic for society. We can conclude that IoT-based sensors upon certain fixation in terms of categorization and proper orientation can be very useful to make a smarter human society.}
}
@article{WANG2021107441,
title = {Learning large-scale fuzzy cognitive maps using an evolutionary many-task algorithm},
journal = {Applied Soft Computing},
volume = {108},
pages = {107441},
year = {2021},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2021.107441},
url = {https://www.sciencedirect.com/science/article/pii/S1568494621003641},
author = {Chao Wang and Jing Liu and Kai Wu and Chaolong Ying},
keywords = {Fuzzy cognitive maps (FCMs), Many-task optimization, Multi-task optimization, Evolutionary algorithm, Random inactivation, Batch learning},
abstract = {Fuzzy cognitive maps (FCMs) are a powerful tool for simulating and analyzing complex systems. Many efficient methods based on evolutionary algorithms have been proposed to learn small-scale FCMs. However, large number of function evaluations of those methods make them difficult to cope with large-scale FCM learning problems. To overcome this issue, we propose a random inactivation-based batch many-task evolutionary algorithm, termed as IBMTEA-FCM. Inspired by the probability of knowledge sharing in different tasks, the problem of FCM learning is first modeled as a many-task optimization problem, in which each task represents learning local connections of a node in a single FCM. To ensure the effectiveness of knowledge transfer, all tasks are randomly divided into multiple batches to optimize separately. In this method, an evolutionary many-task framework is employed to overcome the proposed many-task FCM learning problem and we randomly deactivate weighted edges to ensure the sparsity of FCM in the evolutionary process. The performance of IBMTEA-FCM is validated on both synthetic datasets and a practical study of gene regulatory network reconstruction. Compared with existing classical methods, the experimental results show that IBMTEA-FCM can learn large-scale FCMs with higher accuracy and less computational cost.}
}
@article{BALAMURUGAN2022103564,
title = {DOA tracking for seamless connectivity in beamformed IoT-based drones},
journal = {Computer Standards & Interfaces},
volume = {79},
pages = {103564},
year = {2022},
issn = {0920-5489},
doi = {https://doi.org/10.1016/j.csi.2021.103564},
url = {https://www.sciencedirect.com/science/article/pii/S0920548921000593},
author = {N.M. Balamurugan and Senthilkumar Mohan and M. Adimoolam and A John and Thippa {reddy G} and Weizheng Wang},
keywords = {Adaptive antenna arrays, DOA tracking, Seamless communication, IoT, Drone},
abstract = {In recent times, there has been a surge of interest around the usage of adaptive antenna arrays of Internet of Things (IoT) based Drones in the communication systems. Adaptive antenna arrays have the ability to form customized radiation patterns based on the changes in the environment by employing methods for estimating Direction of Arrival (DOA) and adaptive beamforming. Nevertheless, upon deploying adaptive antenna arrays in complex IoT platforms, the radiation patterns that result from the use of such adaptive algorithms may be adjusted to the preceding location of the node and not attuned to the current location. These issues that arise due to mobility can be resolved by continuously tracking the DOA of the intended target. As DOA is time varying in an IoT Drone environment, existing algorithms for estimating the DOA like MUltiple SIgnal Classification (MUSIC) and Estimation of Signal Parameter via Rotational Invariance Techniques (ESPRIT) cannot be used to track the signal subspace recursively, as they are based on batch eigenvalue decomposition which is highly time consuming with a time complexity of O(n3). Furthermore, DOA estimation algorithms do not result in robust subspace estimates when the Signal to Noise Ratio (SNR) is low.The main novelty of the proposed work is a low computational complexity subspace tracking algorithm for tracking DOA in order to provide seamless connectivity. Simulation results show that the proposed DOA tracking takes lesser time for tracking the current location of the drone target as opposed to conventional DOA estimation methods. Furthermore,it is observed that the tracking process remains unaffected by SNR.}
}
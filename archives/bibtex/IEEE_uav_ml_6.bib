@INPROCEEDINGS{8780127,
author={Sacharny, David and Henderson, Thomas C.},
booktitle={2019 IEEE International Conference on Industrial Cyber Physical Systems (ICPS)}, title={Optimal Policies in Complex Large-scale UAS Traffic Management},
year={2019},
volume={},
number={},
pages={352-357},
abstract={There is currently a worldwide effort to develop UAS Traffic Management (UTM) systems that help ensure safe and reliable operation of Unmanned Autonomous Systems (UAS) in urban environments. A large number of factors must be considered in planning such flights, including GIS (roads, topography, etc.), weather (temperature, wind, precipitation), localization and navigation (GPS, V2X communication), infrastructure obstacles (buildings, towers, etc.), excluded zones of operation, etc. We have developed a cloud-based geospatial intelligence system, BRECCIA, which brokers such information among a set of intelligent agents. In this work, an extended version of BRECCIA is proposed as a universal-UTM (U-UTM) which allows the specification of urban airways constrained to be above roadways. In addition, we develop a reinforcement learning approach for the determination of optimal flight policies through such airways, where these policies can take into account a variety of factors (wind, precipitation, communication, etc.) which impact UAV path following capabilities. A novel context-based probabilistic state transition function is introduced. Simulation experiments are performed to demonstrate the performance of the approach.},
keywords={Indexes;Reinforcement learning;Urban areas;Probabilistic logic;Convergence;Global Positioning System;Aerospace electronics;UAS Traffic Management;Reinforcement Learning},
doi={10.1109/ICPHYS.2019.8780127},
ISSN={},
month={May},}
@ARTICLE{8742658,
author={Shakeri, Reza and Al-Garadi, Mohammed Ali and Badawy, Ahmed and Mohamed, Amr and Khattab, Tamer and Al-Ali, Abdulla Khalid and Harras, Khaled A. and Guizani, Mohsen},
journal={IEEE Communications Surveys Tutorials}, title={Design Challenges of Multi-UAV Systems in Cyber-Physical Applications: A Comprehensive Survey and Future Directions},
year={2019},
volume={21},
number={4},
pages={3340-3385},
abstract={Unmanned aerial vehicles (UAVs) have recently rapidly grown to facilitate a wide range of innovative applications that can fundamentally change the way cyber-physical systems (CPSs) are designed. CPSs are a modern generation of systems with synergic cooperation between computational and physical potentials that can interact with humans through several new mechanisms. The main advantages of using UAVs in CPS application is their exceptional features, including their mobility, dynamism, effortless deployment, adaptive altitude, agility, adjustability, and effective appraisal of real-world functions anytime and anywhere. Furthermore, from the technology perspective, UAVs are predicted to be a vital element of the development of advanced CPSs. Therefore, in this survey, we aim to pinpoint the most fundamental and important design challenges of multi-UAV systems for CPS applications. We highlight key and versatile aspects that span the coverage and tracking of targets and infrastructure objects, energy-efficient navigation, and image analysis using machine learning for fine-grained CPS applications. Key prototypes and testbeds are also investigated to show how these practical technologies can facilitate CPS applications. We present and propose state-of-the-art algorithms to address design challenges with both quantitative and qualitative methods and map these challenges with important CPS applications to draw insightful conclusions on the challenges of each application. Finally, we summarize potential new directions and ideas that could shape future research in these areas.},
keywords={Surveillance;Drones;Wireless sensor networks;Tutorials;Cyber-physical systems;Unmanned aerial vehicles;drones;multi-UAV;cyber-physical applications;design challenges},
doi={10.1109/COMST.2019.2924143},
ISSN={1553-877X},
month={Fourthquarter},}
@INPROCEEDINGS{8968555,
author={Andrew, William and Greatwood, Colin and Burghardt, Tilo},
booktitle={2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)}, title={Aerial Animal Biometrics: Individual Friesian Cattle Recovery and Visual Identification via an Autonomous UAV with Onboard Deep Inference},
year={2019},
volume={},
number={},
pages={237-243},
abstract={This paper describes a computationally-enhanced M100 UAV platform with an onboard deep learning inference system for integrated computer vision and navigation. The system is able to autonomously find and visually identify by coat pattern individual Holstein Friesian cattle in freely moving herds. We propose an approach that utilises three deep convolutional neural network architectures running live onboard the aircraft: (1) a YOLOv2-based species detector, (2) a dual-stream deep network delivering exploratory agency, and (3) an InceptionV3-based biometric long-term recurrent convolutional network for individual animal identification. We evaluate the performance of each of the components offline, and also online via real-world field tests comprising 147 minutes of autonomous low altitude flight in a farm environment over a dispersed herd of 17 heifer dairy cows. We report error-free identification performance on this online experiment. The presented proof-of-concept system is the first of its kind. It represents a practical step towards autonomous biometric identification of individual animals from the air in open pasture environments for tag-less AI support in farming and ecology.},
keywords={},
doi={10.1109/IROS40897.2019.8968555},
ISSN={2153-0866},
month={Nov},}
@INPROCEEDINGS{9605390,
author={Araújo, Matheus S. and Andrade, João P. B. and Da Silva Junior, Thayanne F. and Da Costa, Leonardo F. and Junior, Raimundo J. C. F. and Melo, Gabriel F. L. and Da Silva, Douglas A. and De Campos, Gustavo A. L.},
booktitle={2021 Latin American Robotics Symposium (LARS), 2021 Brazilian Symposium on Robotics (SBR), and 2021 Workshop on Robotics in Education (WRE)}, title={Cooperative Observation of Malicious Targets in a 3D Urban Traffic Environment Using UAVs},
year={2021},
volume={},
number={},
pages={60-65},
abstract={The Cooperative Multi-Robot Observation of Multiple Moving Targets (CMOMMT) considers two types of robots, observers and targets, in a partially observable 2D environment. The observers’ task is to monitor the target robots under a limited radial range of the sensor, minimizing the total time the targets escape observation. The Cooperative Target Observation (CTO), a variant of the CMOMMT problem, considers the environment to be fully observable, where target agents cooperate with observers by reporting their locations. These problems are at the center of many issues that occur in surveillance situations. This work proposes an approach to the extended CTO problem. We call the CTO-URBAN3D problem: a simplified urban traffic scenario in three dimensions for the CTO, considering that suspect transport like cars or buses are targets and Unmanned Aerial Vehicles (UAVs) are observers agents. The approach employs genetic algorithms and recurrent deep neural networks to improve the performance of transport-targets robots and an observer organizational behavior hierarchical consolidated in the CTO literature for UAV-observers robots. The first results were promising, as the average number of transport-targets evasion increased, considering the other approaches to the problem. It raises the need to research new organizations for UAV robots.},
keywords={Solid modeling;Three-dimensional displays;Robot kinematics;Surveillance;Neural networks;Urban areas;Organizations;Cooperative Target Observation;Urban Traffic Monitoring;Genetic Algorithm;Deep Neural Networks},
doi={10.1109/LARS/SBR/WRE54079.2021.9605390},
ISSN={2643-685X},
month={Oct},}
@INPROCEEDINGS{9455181,
author={Dale, Holly and Baker, Chris and Antoniou, Michail and Jahangir, Mohammed and Atkinson, George},
booktitle={2021 IEEE Radar Conference (RadarConf21)}, title={A Comparison of Convolutional Neural Networks for Low SNR Radar Classification of Drones},
year={2021},
volume={},
number={},
pages={1-5},
abstract={Reliable detection and tracking is required to ensure that drones are safely integrated into low altitude airspace. Radar provides a 24-hour, all-weather solution to this problem. However, the radar signatures of birds have a similar RCS to those of drones, thus a robust method of classification is needed to filter out non-drone targets and eliminate, or at least minimize to an acceptable level, false alarms. Convolutional neural networks (CNNs) have been shown to achieve high classification performance but results are only reported for high signal to noise ratio data -a luxury that is not always available to operational radar systems. In this paper, Gaussian noise is added to the test data to vary the signal to noise ratio (SNR) in order to investigate classifier robustness as a function of SNR in the context of drone classification. The performance of six CNN architectures previously established for computer vision applications are exploited and compared with each other to assess classification performance and robustness with network depth.},
keywords={Training;Radar cross-sections;Target tracking;Surveillance;Radar tracking;Birds;Robustness;classification;deep learning;staring radar;UAVs;birds},
doi={10.1109/RadarConf2147009.2021.9455181},
ISSN={2375-5318},
month={May},}
@INPROCEEDINGS{9217347,
author={Ni, Wanli and Tian, Hui and Fan, Shaoshuai and Nie, Gaofeng},
booktitle={2020 IEEE 31st Annual International Symposium on Personal, Indoor and Mobile Radio Communications}, title={Optimal Transmission Control and Learning-Based Trajectory Design for UAV-Assisted Detection and Communication},
year={2020},
volume={},
number={},
pages={1-6},
abstract={Due to their high mobility, flexible deployment and stable maneuverability, unmanned aerial vehicles (UAVs) have been deemed as a promising and indispensable role for various emerging applications (e.g., dangerous area detection, dynamic target tracking, and map remote sensing). Compared to the static monitoring equipments, UAV-mounted high-definition camera and signal transceiver can be used cost-effectively as an on-demand aerial platform to detect the unknown region and send the real-time data back at the same time. However, these highlighted limitations of battery capacity and communication resource extremely affect the UAV's performance such as flight endurance and data transmission. Motivated by the above conflicts, this paper aims to minimize the total energy consumed by the UAV during the region detection mission through jointly optimizing the collected data size, transmission time, and flying trajectory. Toward this end, we derive the optimal data collection and transmission time in closed forms via convex optimization, and propose a model-free reinforcement learning-based algorithm for training the UAV to plan its trajectory without knowing the environment information in advance. Simulation results validate the performance of our designs in terms of convergence, energy consumption, and energy efficiency.},
keywords={Trajectory;Energy consumption;Unmanned aerial vehicles;Real-time systems;Data collection;Propulsion;Land mobile radio},
doi={10.1109/PIMRC48278.2020.9217347},
ISSN={2166-9589},
month={Aug},}
@ARTICLE{9521193,
author={Xi, Mao and Zhou, Yun and Chen, Zheng and Zhou, Wengang and Li, Houqiang},
journal={IEEE Transactions on Circuits and Systems for Video Technology}, title={Anti-distractor Active Object Tracking in 3D Environments},
year={2021},
volume={},
number={},
pages={1-1},
abstract={In active object tracking, given a visual observation as input, the goal is to lockup the target by autonomously adjusting camera’s position and posture. Previous works on active tracking assume that there is only one object (person) in the environment without distractors. In this work, towards realistic setting, we move forward to a more challenging scenario, where the tracker moves freely in 3D space like unmanned aerial vehicles (UAV) to track a person in various complex scenes with multiple distractors. To this end, we propose a novel end-to-end anti-distractor active object tracking framework by introducing multiple attention modules. On one hand, we take the target template to learn an embedding as channel-wise attention for current observation to distinguish the target from the distractors. On the other hand, temporal attention is introduced to fuse the observation history to extract a feature representation, which is then fed into a reinforcement learning network to output the action of the tracker. To evaluate our method, we build several multi-object 3D environments in Unreal Engine and extensive experiments demonstrate the effectiveness of our approach.},
keywords={Target tracking;Object tracking;Training;Three-dimensional displays;Reinforcement learning;Cameras;Visualization;Active object tracking;reinforcement learning;attention mechanism},
doi={10.1109/TCSVT.2021.3107153},
ISSN={1558-2205},
month={},}
@INPROCEEDINGS{7525107,
author={Huanyu Ding and Cristofalo, Eric and Wang, Joseph and Castañón, David and Montijano, Eduardo and Saligrama, Venkatesh and Schwager, Mac},
booktitle={2016 American Control Conference (ACC)}, title={A multi-resolution approach for discovery and 3-D modeling of archaeological sites using satellite imagery and a UAV-borne camera},
year={2016},
volume={},
number={},
pages={1359-1365},
abstract={This paper proposes a method for discovering new archaeological sites from existing satellite imagery, then building a 3-D computer model of those sites using a controlled UAV with an onboard camera. We use an unmanned vehicle and other remote surveillance sensors, coupled with onboard pattern recognition algorithms, to perform a coarse search, and subsequently a fine search to identify structures of interest. We assume the availability of two sensors. The first sensor is a low resolution camera that sweeps an area of interest, such as an imaging satellite. We process the low-resolution image data to identify tentative locations of interest and to provide confidence estimates with this identification. This information is provided to a control algorithm for an unmanned air vehicle, which plans a trajectory to inspect closely promising objects subject to fuel constraints. These close inspections provide sequences of images that are combined to give 3-D reconstructions of the area of interest, leading to accurate classification of the structure. In this paper, we describe the design of the three principal algorithms in this system: machine learning processing of coarse resolution data, the near-optimal path planning subject to fuel constraints, and the high-resolution 3-D modeling from multiple 2-D views of a site. We illustrate the performance of our system on sample LANDSAT satellite data, and using a quadrotor with an on-board camera in a laboratory environment.},
keywords={Unmanned aerial vehicles;Three-dimensional displays;Satellites;Sensors;Fuels;Path planning;Cameras},
doi={10.1109/ACC.2016.7525107},
ISSN={2378-5861},
month={July},}
@INPROCEEDINGS{9620862,
author={Aouto, Ali and Lee, Jae-Min and Kim, Dong-Seong},
booktitle={2021 International Conference on Information and Communication Technology Convergence (ICTC)}, title={UAV Detection Using Split-Parallel CNN For Surveillance Systems},
year={2021},
volume={},
number={},
pages={1178-1181},
abstract={Commercial drones have become available to everyone with different sizes and shapes. Many are equipped with cameras and some with signal sabotage devices, the scariest scenario is that there are websites that offers weapons which can be attached to the drone. All those security threats either for privacy matters or people's safety, encouraged the researchers to find an intelligent system that can be implemented into the surveillance systems to classify unauthorized UAVs that are flying in a restricted area. This paper proposes a system that detects UAVs by acquiring RGB images via sensor then apply them to a convolutional neural network (CNN) that behave as an object classifier. Proposing Split-Parallel Cross Stage Partial DenseNet (PCSPDensenet) that is built from a modified CSPDenseNet. By splitting the feature map in two parts. Then, make each part flow in different side of the parallel network. The proposed network shows simulation results of an increment in the precision and showed higher $AP_{50}$ and $AP_{75}$ at higher frame rate on the UAV dataset With lower computational complexity.},
keywords={Privacy;Shape;Surveillance;Weapons;Simulation;Safety;Convolutional neural networks;Detection;Data Augmentation;Intelligent Surveillance System;UAV},
doi={10.1109/ICTC52510.2021.9620862},
ISSN={2162-1233},
month={Oct},}
@INPROCEEDINGS{9624393,
author={Ni, Zhou},
booktitle={2021 14th International Congress on Image and Signal Processing, BioMedical Engineering and Informatics (CISP-BMEI)}, title={Error Compensation Algorithm for UAV Telemetry Temperature Data},
year={2021},
volume={},
number={},
pages={1-5},
abstract={In recent years, the UAV industry has developed rapidly, and UAVs have been applied to many fields such as surveying, agriculture, military and even home entertainment. At present, my country has carried out drone remote sensing temperature measurement experiments in many experimental fields. In the experiment, drones equipped with infrared thermal imaging cameras were used to scan and measure the jointing stage corn of different traits. At the same time, portable handheld thermometers were used to measure Simultaneously measure the corn canopy temperature on the ground, and conduct a consistency analysis with the extracted canopy temperature to verify and evaluate the effect of extracting the corn canopy temperature based on thermal infrared images. Based on the corn canopy test data in this field, this paper mainly studies and solves the problems encountered in the temperature measurement accuracy in the post-processing of the test data, and proposes a temperature compensation method for UAV remote sensing temperature data based on wavelet neural network. It is a good solution to the problem that the accuracy cannot meet the requirements during the measurement process. It can be used in the data post-processing of remote sensing temperature measurement test of drones, so that the obtained data results are more accurate, and the measurement accuracy can also be greatly improved.},
keywords={Temperature measurement;Temperature sensors;Temperature distribution;Neural networks;Error compensation;Biomedical measurement;Autonomous aerial vehicles;UAV;temperature;telemetry;wavelet neural network;error compensation},
doi={10.1109/CISP-BMEI53629.2021.9624393},
ISSN={},
month={Oct},}
@INPROCEEDINGS{8741718,
author={Levasseur, Baptiste and Bertrand, Sylvain and Raballand, Nicolas and Viguier, Flavien and Goussu, Grégoire},
booktitle={2019 IEEE Aerospace Conference}, title={Accurate Ground Impact Footprints and Probabilistic Maps for Risk Analysis of UAV Missions},
year={2019},
volume={},
number={},
pages={1-10},
abstract={This paper addresses the generation of accurate ground impact footprints and probabilistic maps for fixed-wing UAVs. Monte Carlo simulations are performed using a 6DOF dynamic model of aircraft accounting for wind conditions and different types of uncertainties. Use of generated probabilistic maps for risk analysis is shown along an example of real flight trajectory. To also address possible online use of ground impact footprints, surrogate models (kriging and neural networks) are developed to reduce computation time. Real flight data are used for model and application purposes.},
keywords={Computational modeling;Trajectory;Aerodynamics;Uncertainty;Probabilistic logic;Engines;Atmospheric modeling},
doi={10.1109/AERO.2019.8741718},
ISSN={1095-323X},
month={March},}
@INPROCEEDINGS{8975715,
author={Rashid, Md Tahmid and Zhang, Daniel Yue and Shang, Lanyu and Wang, Dong},
booktitle={2019 IEEE 25th International Conference on Parallel and Distributed Systems (ICPADS)}, title={SEAD: Towards A Social-Media-Driven Energy-Aware Drone Sensing Framework},
year={2019},
volume={},
number={},
pages={647-654},
abstract={Autonomous unmanned aerial vehicles (UAVs) have become an important tool for efficient disaster response. Despite the virtues of UAVs in disaster response applications, various limitations (e.g., requiring manual input, finite battery life) hinder their mass adoption. In contrast, social sensing is emerging as a new sensing paradigm that utilizes signals provided by "human sensors" to gather awareness of the events occurring in the physical world. Despite being inherently broader in scope, a shortcoming of social sensing is the reliability of the sensing data that are contributed by humans. In this paper, we introduce the concept of jointly exploiting the reliability of drones and the scope of social sensing to efficiently uncover the truthful events during disasters. However, such a tight integration of social and physical sensing introduces several technical challenges. The first challenge is satisfying the conflicting objectives of event coverage of the application and energy conservation of drones. The second challenge is adapting to the dynamics of the physical world and social media. In this paper, we present a Social-media-driven Energy-Aware Drone (SEAD) sensing framework to address the above challenges. In particular, we develop a reinforcement learning-based drone dispatching scheme that adapts to the physical and social environments and launches an appropriate proportion of drones for event exploration. We further utilize a bottom-up game-theoretic task allocation approach to guide drones effectively to the event locations. The evaluation with a real-world disaster case study show that SEAD noticeably outperforms state-of-the-art baselines in terms of detection effectiveness and energy efficiency.},
keywords={SEAD;UAV;energy aware;social sensing;reinforcement learning;disaster response},
doi={10.1109/ICPADS47876.2019.00097},
ISSN={1521-9097},
month={Dec},}
@ARTICLE{9580752,
author={Chen, Guangdeng and Yao, Deyin and Li, Hongyi and Zhou, Qi and Lu, Renquan},
journal={IEEE Transactions on Circuits and Systems I: Regular Papers}, title={Saturated Threshold Event-Triggered Control for Multiagent Systems Under Sensor Attacks and Its Application to UAVs},
year={2021},
volume={},
number={},
pages={1-12},
abstract={This paper investigates the secure consensus tracking problem for continuous-time nonlinear multiagent systems with sensor attacks. By designing a secure data selector, the unattacked output data is extracted from a group of output measurements under sparse sensor attacks. Then, by virtue of the obtained data and neural networks, a state observer is constructed to estimate the unavailable system states, where the convex combination theory is introduced to reduce the difficulty of solving observation gains. To utilize the limited communication resources reasonably, a novel saturated threshold event-triggered control strategy is proposed to reduce control updates, and then each update is encoded into a binary signal (0 or 1) to further reduce the occupation of communication bandwidth. The designed control scheme ensures that all closed-loop signals are semi-globally uniformly ultimately bounded, and its effectiveness is verified via a simulation of attitude control of unmanned aerial vehicles.},
keywords={Observers;Artificial neural networks;Bandwidth;Stability analysis;Linear matrix inequalities;Physical layer;Nonlinear systems;Event-triggered control;multiagent systems;sensor attacks;state observer.},
doi={10.1109/TCSI.2021.3116670},
ISSN={1558-0806},
month={},}
@INPROCEEDINGS{9553826,
author={Trujillano, Fedra and Gonzalez, Jessenia and Saito, Carlos and Flores, Andres and Racoceanu, Daniel},
booktitle={2021 IEEE International Geoscience and Remote Sensing Symposium IGARSS}, title={Corn Crops Identification Using Multispectral Images from Unmanned Aircraft Systems},
year={2021},
volume={},
number={},
pages={4712-4715},
abstract={Corn is cultivated by smallholder farmers in Ancash - Peru and it is one of the most important crops of the region. Climate change and migration from rural to urban areas are affecting agricultural production and therefore, food security. Information about the cultivated extension is needed for the authorities in order to evaluate the impact in the region. The present study proposes corn areas segmentation in multi-spectral images acquired from Unmanned Aerial Vehicles (UAV), using convolutional neural networks. U-net and U-net using VGG11 encoder were compared using dice and IoU coefficient as metrics. Results show that with the second model, 81.5% dice coefficient can be obtained in this challenging task, allowing envisaging an effective and efficient use of this technology, in this hard context.},
keywords={Measurement;Image segmentation;Urban areas;Crops;Geoscience and remote sensing;Production;Unmanned aerial vehicles;UAV;climate change;corn identification;semantic segmentation},
doi={10.1109/IGARSS47720.2021.9553826},
ISSN={2153-7003},
month={July},}
@INPROCEEDINGS{9182686,
author={Junfei, Chen and Kunyi, Lu and Jiaxin, Wang},
booktitle={2020 IEEE International Conference on Artificial Intelligence and Computer Applications (ICAICA)}, title={Research on UAV Image Recognition Based on Convolutional Neural Network},
year={2020},
volume={},
number={},
pages={819-823},
abstract={As an important visual function of drones, image recognition has helped drones accomplish a variety of tasks in complex environments. At present, most of drone image detection uses the traditional method of artificial feature extraction. It is difficult to meet the increasing accuracy requirements. Based on this, this paper applies convolutional neural networks to UAV image recognition to meet high-precision requirements. This article first introduced the development process of convolutional neural networks to facilitate their overall integration. And then summarized the “visual function” of the drone, then analyzed the future development trend of the drone image recognition technology, expounded the key technology of the drone image recognition, and finally explained the image recognition technology based on convolutional neural network, discussed its recognition process and recognition method, and it has a certain significance for deepening the research of UAV image recognition.},
keywords={Drones;Feature extraction;Image recognition;Sensors;Target recognition;Convolutional neural networks;Task analysis;convolutional neural network;drone;image recognition;SSD algorithm},
doi={10.1109/ICAICA50127.2020.9182686},
ISSN={},
month={June},}
@ARTICLE{9493880,
author={Hossain, Md. Sakir and Becvar, Zdenek},
journal={IEEE Access}, title={Soft Frequency Reuse With Allocation of Resource Plans Based on Machine Learning in the Networks With Flying Base Stations},
year={2021},
volume={9},
number={},
pages={104887-104903},
abstract={Flying base stations (FlyBSs) enable ubiquitous communications in the next generation mobile networks with a flexible topology. However, a deployment of the FlyBSs intensifies interference, which can result in a degradation in the throughput of cell-edge users. In this paper, we introduce a flexible soft frequency reuse (F-SFR) that enables a self-organization of a common SFR in the networks with an unpredictable and dynamic topology with the FlyBSs. We propose a graph theory-based algorithm for an allocation of resource plans, which is understood as a bandwidth allocation and a transmission power setting in the context of SFR. Furthermore, we introduce a low-complexity implementation of the proposed resource allocation using deep neural network (DNN) to significantly reduce the computation complexity. We show that the proposed F-SFR increases the throughput of cell-edge users by 16% to 26% and, at the same time, improves the satisfaction of the cell-edge users by up to 25% compared to the state-of-the-art solutions. We also demonstrate that the proposed scheme ensures a higher fairness in the throughput among the users with respect to the state-of-the-art solutions. The implementation via DNN also outperforms all state-of-the-art solutions despite its very low complexity.},
keywords={Interference;Throughput;Resource management;Base stations;Complexity theory;Antenna arrays;Topology;Flying base station;interference;soft frequency reuse;deep neural networks;throughput;UAV;user satisfaction;fairness},
doi={10.1109/ACCESS.2021.3099535},
ISSN={2169-3536},
month={},}
@INPROCEEDINGS{8123131,
author={Zhou, Hailing and Wei, Lei and Fielding, Michael and Creighton, Doug and Deshpande, Sameer and Nahavandi, Saeid},
booktitle={2017 IEEE International Conference on Systems, Man, and Cybernetics (SMC)}, title={Car park occupancy analysis using UAV images},
year={2017},
volume={},
number={},
pages={3261-3265},
abstract={With the development of unmanned aerial vehicles (UAVs) and the relevant techniques, UAVs become common and popular for civilian applications such as remote sensing tasks. The reason is because they are cheap, flexible, and easy to set up. Car park occupancy analysis is important for authorities to make decisions on the design, plan and management of car parks. To have a quick knowledge of current parking situations, we proposed to use UAV images to count how many cars are parked during different periods. In this paper, our major contribution is a novel car counting approach for UAV images. Different from traditional detection- or segmentation-based counting techniques, the proposed counting method is density estimation based that does not need intense collection and learning procedures. We transform the car counting problem into the estimation of density values over pixels of an image. Experimental results have been conducted on real car park scenarios and all the results show that our method can provide a promising estimation of car numbers.},
keywords={Automobiles;Estimation;Unmanned aerial vehicles;Cameras;Sensors;Machine learning algorithms;Training;Object detection;car counting;car park occupancy;density estimation},
doi={10.1109/SMC.2017.8123131},
ISSN={},
month={Oct},}
@ARTICLE{8657348,
author={Zhaoxiang, Zhang and Iwasaki, Akira and Xu, Guodong},
journal={IEEE Geoscience and Remote Sensing Letters}, title={Attitude Jitter Compensation for Remote Sensing Images Using Convolutional Neural Network},
year={2019},
volume={16},
number={9},
pages={1358-1362},
abstract={Attitude jitter of satellites and unmanned aerial vehicle (UAV) platforms is a problem that degenerates the imaging quality in high-resolution remote sensing. This letter proposes a deep learning architecture that automatically learns essential scene features from a single image to estimate the attitude jitter, which is used to compensate deformed images. The proposed methodology consists of a convolutional neural network and a jitter compensation model. The neural network analyzes the deformed images and generates the attitude jitter vectors in two directions, which are utilized to correct the images through interpolation and resampling. The PatternNet and the small UAV data sets are introduced to train the neural network and to validate its effectiveness and accuracy. The compensation results on distorted remote sensing images obtained by satellites and UAVs reveal that the image distortion due to attitude jitter is clearly reduced and that the geometric quality is effectively improved. Compared to the existing methods that primarily rely on sensor data or parallax observation, no auxiliary information is required in our framework.},
keywords={Jitter;Remote sensing;Cameras;Training;Satellites;Image restoration;Convolutional neural network (CNN);high-resolution (HR) remote sensing;jitter compensation},
doi={10.1109/LGRS.2019.2897710},
ISSN={1558-0571},
month={Sep.},}
@ARTICLE{8337814,
author={Zhang, Jiajie and Weng, Jian and Luo, Weiqi and Liu, Jia-Nan and Yang, Anjia and Lin, Jiancheng and Zhang, Zhijun and Li, Hailiang},
journal={IEEE Network}, title={REMT: A Real-Time End-to-End Media Data Transmission Mechanism in UAV-Aided Networks},
year={2018},
volume={32},
number={5},
pages={118-123},
abstract={In recent years, UAVs have received much attention in both the military and civilian fields for monitoring, emergency relief and searching tasks. UAVs are considered a new technology to obtain data at high altitudes when equipped with sensors. This technology is vital to the success of next-generation monitoring systems, which are expected to be reliable, real-time, efficient and secure. However, due to the bandwidth limitations in UAV-aided networks, the size of the transmitted data is a crucial factor for real-time media data transmission requirements, especially for national defense. To address this issue, in this article, we propose a realtime end-to-end media data transmission mechanism with an unsupervised deep neural network. The proposed mechanism transmutes the media data captured by UAVs into latent codes with a predefined constant size and transmits the codes to the ground console station (GCS) for further reconstruction. We use a real-word dataset containing millions of samples to evaluate the proposed mechanism which achieves a high transmission ratio, low resource usage and good visual quality.},
keywords={Unmanned aerial vehicles;Real-time systems;Machine learning;Feature extraction;Data communication;Image reconstruction;Image sequences},
doi={10.1109/MNET.2018.1700382},
ISSN={1558-156X},
month={Sep.},}
@INPROCEEDINGS{7502621,
author={Cekmez, Ugur and Ozsiginan, Mustafa and Sahingoz, Ozgur Koray},
booktitle={2016 International Conference on Unmanned Aircraft Systems (ICUAS)}, title={Multi colony ant optimization for UAV path planning with obstacle avoidance},
year={2016},
volume={},
number={},
pages={47-52},
abstract={In recent years, the availability of low-cost and autonomous unmanned aerial vehicles (UAVs) results in the use of them for different types of military and commercial applications. The crucial part of the autonomous UAVs is their online or offline path planning algorithms. In the literature, there are many types of solutions, which use evolutionary and/or swarm intelligence approaches. Ant colony optimization is one of the mostly used algorithms, which has been applied to solve different type of path planning problems. Mainly, most of these studies have focused on a single colony ant colony optimization (ACO), which can find better solutions in fewer computation times. However, it is able to converge to a sub-optimal solution in the planning process. One approach to avoid the premature convergence is the use of Multi-Colony ACO, in which a number of ant colonies try to find an optimal solution cooperatively by exchanging their valuable information with each other. In this paper, it is aimed to implement an obstacle avoidance UAV path planning by using Multi-Colony ACO algorithm. We experimentally investigate the use of Multi-Colony ACO approach results from an effective path planning for UAVs with a comparison to a single colony ACO approach.},
keywords={Path planning;Particle swarm optimization;Optimization;Urban areas;Ant colony optimization;Search problems;Heuristic algorithms},
doi={10.1109/ICUAS.2016.7502621},
ISSN={},
month={June},}
@ARTICLE{9606685,
author={Niculescu, Vlad and Lamberti, Lorenzo and Conti, Francesco and Benini, Luca and Palossi, Daniele},
journal={IEEE Journal on Emerging and Selected Topics in Circuits and Systems}, title={Improving Autonomous Nano-Drones Performance via Automated End-to-End Optimization and Deployment of DNNs},
year={2021},
volume={11},
number={4},
pages={548-562},
abstract={The evolution of energy-efficient ultra-low-power (ULP) parallel processors and the diffusion of convolutional neural networks (CNNs) are fueling the advent of autonomous driving nano-sized unmanned aerial vehicles (UAVs). These sub-10cm robotic platforms are envisioned as next-generation ubiquitous smart-sensors and unobtrusive robotic-helpers. However, the limited computational/memory resources available aboard nano-UAVs introduce the challenge of minimizing and optimizing vision-based CNNs – which to date require error-prone, labor-intensive iterative development flows. This work explores methodologies and software tools to streamline and automate all the deployment of vision-based CNN navigation on a ULP multicore system-on-chip acting as a mission computer on a Crazyflie 2.1 nano-UAV. We focus on the deployment of PULP-Dronet (Palossi et al., 2019), a state-of-the-art CNN for autonomous navigation of nano-UAVs, from the initial training to the final closed-loop evaluation. Compared to the original hand-crafted CNN, our results show a $2\times $ reduction of memory footprint and a speedup of $1.6\times $ in inference time while guaranteeing the same prediction accuracy and significantly improving the behavior in the field, achieving: i) obstacle avoidance with a peak braking-speed of 1.65m/s and improving the speed/braking-space ratio of the baseline, ii) free flight in a familiar environment up to 1.96m/s (0.5m/s for the baseline), and iii) lane following on a path featuring a 90deg turn – all while using for computation less than 1.6% of the drone’s power budget. To foster new applications and future research, we open-source all the software design in a ready-to-run project compatible with the Crazyflie 2.1.},
keywords={Drones;Navigation;Autonomous robots;Task analysis;Collision avoidance;Sensors;Performance evaluation;Unmanned aerial vehicle (UAV);convolutional neural network (CNN);autonomous navigation;nano-drone;ultra-low-power (ULP)},
doi={10.1109/JETCAS.2021.3126259},
ISSN={2156-3365},
month={Dec},}
@INPROCEEDINGS{8768831,
author={Neacsu, Ana Antonia and Cioroiu, George and Radoi, Anamaria and Burileanu, Corneliu},
booktitle={2019 42nd International Conference on Telecommunications and Signal Processing (TSP)}, title={Automatic EMG-based Hand Gesture Recognition System using Time-Domain Descriptors and Fully-Connected Neural Networks},
year={2019},
volume={},
number={},
pages={232-235},
abstract={Hand gesture recognition has numerous applications in medical (e.g., prosthetics), engineering (e.g., robot manipulation) and, even, military research areas (e.g., UAV control applications). This paper proposes a fast and accurate method to identify hand gesture categories based on electromyo-graphic (EMG) signals registered by a commercial sensor (e.g., Myo Armband developed by Ontario-based Thalmic Labs), which is placed on the user's forearm. The proposed method is based on the extraction of time-domain features and a neural network architecture to perform the classification of the EMG signals. In order to evaluate the performance of the proposed algorithm, we use a publicly available dataset with 7 hand gesture categories. The proposed hand gesture recognition system achieves a 99.78 % overall performance accuracy, which is comparable to that reported by applying other state-of-the-art methods, but is able to work in real-time conditions.},
keywords={Feature extraction;Electromyography;Gesture recognition;Computer architecture;Neural networks;Real-time systems;Wrist;hand gesture recognition;neural networks;EMG signals},
doi={10.1109/TSP.2019.8768831},
ISSN={},
month={July},}
@INPROCEEDINGS{9574137,
author={Lian, Xi'nan and Dong, Chen and Kai, Chen},
booktitle={2021 IEEE International Conference on Advances in Electrical Engineering and Computer Applications (AEECA)}, title={Design and Key Technology of Coordinate Detection System for Burst Point of Artillery Shells Based on Rotor UAV},
year={2021},
volume={},
number={},
pages={238-244},
abstract={The coordinate detection of the burst point of artillery shells is the main basis for shooting deviation correction and the core link to the damage effected evaluation. The accuracy and real-time performance of the burst point of artillery shells has always been a major and difficult issue in the military field at home and abroad. At present, most of the coordinate detection of the burst point of artillery shells is based on ground observations, which has limitations on visibility. The observing field is small, and it is prone to occlusion. At the same time, due to the different requirements and understanding of the detection of the coordinate detection of the burst point of artillery shells, the detection output is different, such as the output of the burst point of artillery shells contour and detection frame, image coordinates of the burst point of artillery shells, and the three-dimensional coordinate of the burst point of artillery shells based on a fixed reference point. Based on this, our paper designs an intelligent coordinate detection system for burst point of artillery shells based on rotor UAV. Through the image segmentation technology, the contour of the burst point of artillery shells is segmented, and then the image coordinates are calculated. Combined with the photogrammetry model and the digital elevation model, the geodetic coordinates are calculated.},
keywords={Electrical engineering;Deep learning;Image segmentation;Computer vision;Conferences;Rotors;Organizations;rotor UAV;burst point of artillery shells;intelligent detection;image segmentation;coordinate location},
doi={10.1109/AEECA52519.2021.9574137},
ISSN={},
month={Aug},}
@INPROCEEDINGS{7515608,
author={De Oliveira, Diulhio Candido and Wehrmeister, Marco Aurelio},
booktitle={2016 IEEE 19th International Symposium on Real-Time Distributed Computing (ISORC)}, title={Towards Real-Time People Recognition on Aerial Imagery Using Convolutional Neural Networks},
year={2016},
volume={},
number={},
pages={27-34},
abstract={People recognition in aerial imagery is a complex problem since it involves cameras angles, which are subject to six degrees of freedom. Traditional classifiers used in pattern matching algorithms are not robust enough to deal with such issues. Thus it is necessary to use other techniques such as deep learning methods, e.g. Convolutional Neural Networks (CNN), in order to cope with such a complex problem. However, in spite of providing potentially better recognition results, deep learning methods demand greater processing time, hindering its use on on-board embedded systems of small Unmanned Aerial Vehicles (UAV). This work is a step towards real-time (and possibly on-board) people recognition on aerial imagery. We propose a new approach based on CNN for real-time people recognition on aerial images obtained from cameras attached to small UAVs. This approach combines images from a low-cost thermal camera to detect candidate objects and CNN for the classification task. We have compared our approach with two traditional pattern matching approaches: saliency map detection and cascade classifiers. The obtained results show that, by using CNN, higher rates of correct classification within 95% of precision are obtained. These results have been obtained within real-time processing of 1.08 fps in the worst case on a hardware without any GPU processing.},
keywords={Image recognition;Feature extraction;Real-time systems;Cameras;Object recognition;Graphics processing units;Shape;People recognition;aerial imagery;convolutional neural networks;object recognition},
doi={10.1109/ISORC.2016.14},
ISSN={2375-5261},
month={May},}
@INPROCEEDINGS{9567008,
author={Liu, Wenquan and Wang, Qiang and Zhang, Hanlong and Li, Zhenyuan and Liu, Qiuhan and She, Rongbin and Zhang, Rui},
booktitle={2021 46th International Conference on Infrared, Millimeter and Terahertz Waves (IRMMW-THz)}, title={Automatic terahertz recognition of hidden defects in layered polymer composites based on a deep residual network with transfer learning},
year={2021},
volume={},
number={},
pages={1-1},
abstract={We demonstrate a deep residual network with transfer learning strategy for automatic terahertz (THz) recognition of the hidden defects in fiber reinforced polymer (FRP) composites with small-scale training data. The recognition performance with high accuracy, precision, sensitivity and specificity indicate the effectiveness of the proposed method for automatically identifying different defects in THz nondestructive applications.},
keywords={Transfer learning;Training data;Sensitivity and specificity;Optical fiber networks;Polymers;Residual neural networks},
doi={10.1109/IRMMW-THz50926.2021.9567008},
ISSN={2162-2035},
month={Aug},}
@INPROCEEDINGS{9465325,
author={Mirzaei, Mehrdad and Kosari, Amirreza and Maghsoudi, Hossein},
booktitle={2021 IEEE International Conference on Automation/XXIV Congress of the Chilean Association of Automatic Control (ICA-ACCA)}, title={Optimal Path Planning For Two UAVs in a Pursuit-Evasion Game},
year={2021},
volume={},
number={},
pages={1-7},
abstract={In this paper a path planning technique will be introduced for the unmanned aerial vehicles (UAV) fly at low altitude using a synthetic approach based on game theory and artificial neural networks. The low altitude pursuit-evasion maneuver of two UAVs - is defined based on an optimal control approach. Moreover, it has been sought to utilize optimal control rules and Differential Games theory to calculate the most favorable trajectories for both UAVs - one as the pursuer and the other as an evader. Since producing the optimal trajectories through solving the related equations may be a time-consuming trend, an artificial neural network is utilized to predict the flyable trajectories. The multilayer perceptron networks are trained using a set of trajectories obtained based on the differential game theory approach and could locate the position where the evader is captured. Hence, choices could made in real times. Consequently, the comparison of neural network results with accurate data obtained previously in the optimal control section confirms the accuracy and performance of the proposed method.},
keywords={Optimal control;Games;Differential games;Artificial neural networks;Multilayer perceptrons;Market research;Unmanned aerial vehicles;Path Planning;Neural Network;Differential Game Theory;Optimal Control;Multilayer Perceptron},
doi={10.1109/ICAACCA51523.2021.9465325},
ISSN={},
month={March},}
@INPROCEEDINGS{9616570,
author={Chen, Yulu and Yang, Xuecheng and Liu, Huibin and Gui, Yumiao and Li, Wenbo and Qiu, Qi},
booktitle={2021 International Conference on Wireless Communications and Smart Grid (ICWCSG)}, title={Insulator Fault Recognizing via Modified Faster R-CNN Using UAV Data},
year={2021},
volume={},
number={},
pages={79-84},
abstract={Insulator fault recognition is a common hidden danger that affects the normal operation of the power system. In recent years, UAV aerial images have been widely used to identify defects in insulators. In order to solve the problem of low efficiency caused by manual inspection and traditional image defect detection methods, this paper proposed a modified Faster R-CNN model to improve the accuracy of model detection and reduce the amount of model parameters. Based on the traditional Faster R-CNN detection framework, the proposed method selected ResNet- 50 to replace VGGNet-16 as the feature extraction networks. The database used 781 labeled UAV aerial insulator images, and they are divided into training set, validation set and test set according to the ratio of 6:2:2. The mAP of the modified feature network model reached 62.41%, and the network model parameter size was 25.26M. Compared with the original framework with VGGNet-16 as the feature network, the mAP increased by 3.43% and the parameter amount was compressed by 4.41 times. The results show that the improved algorithm reduces the missed detection rate and false detection rate, and on the basis of improving the recognition accuracy, it can greatly reduce the amount of network parameters. And it can better meet the needs of lightweight network structure in actual scenarios.},
keywords={Wireless communication;Training;Manuals;Insulators;Feature extraction;Smart grids;Sensors;Modification Faster R-CNN;Insulator Fault Recognition;Deep Learning;ResNet-50;UAV data;Compressive sensing},
doi={10.1109/ICWCSG53609.2021.00023},
ISSN={},
month={Aug},}
@INPROCEEDINGS{9657806,
author={Li, Junhao and Mou, Shuhan and Zhang, Dehua},
booktitle={2021 6th International Conference on Robotics and Automation Engineering (ICRAE)}, title={A Novel Adaptive Robust Control Algorithm for Quadrotor UAV},
year={2021},
volume={},
number={},
pages={50-54},
abstract={This paper studies the robust fault tolerant control for quadrotor UAV and proposes a novel hybrid fault tolerant control algorithm without fault diagnosis module. Firstly, the multiplicative fault dynamic model of quadrotor UAV is established base on Newton-Euler laws. Secondly, the adaptive RBF neutral network is constructed based on the sliding mode control to approximate the unknown function of the system fault model online. The adaptive mechanism is designed in the controller to estimate the weight of the neural network and the fault information online. Then, the stability of fault tolerant system is verified based on Lyapunov theorem. Finally, simulation experiment is conducted to validate that the proposed fault tolerant control algorithm has excellent fault tolerant control effect than ordinary sliding mode fault tolerant control algorithm.},
keywords={Robust control;Adaptation models;Adaptive systems;Neural networks;Fault tolerant systems;Fault tolerant control;Approximation algorithms;Quadrotor UAV;Fault tolerant control;Radial Basis Function;Sliding mode control},
doi={10.1109/ICRAE53653.2021.9657806},
ISSN={},
month={Nov},}
@INPROCEEDINGS{8904837,
author={Cifola, L. and Harmanny, R. I. A.},
booktitle={2019 16th European Radar Conference (EuRAD)}, title={Target/clutter disentanglement using deep adversarial training on micro-Doppler signatures},
year={2019},
volume={},
number={},
pages={201-204},
abstract={In this manuscript we argue that, under certain conditions, machine learning techniques can help to increase the signal to background level of a target signal to aid the detection and classification process in the radar signal processing chain. Specifically, the deep adversarial training concept, through the use of Denoising Adversarial Autoencoders (DAEs), has been applied for the problem of separation the micro-Doppler signatures of wind-turbine and drones, in order to be able to extract the latter for further detection and classification purposes.},
keywords={micro-Doppler;Deep Learning;Adversarial training;wind-turbines;mini-UAVs;classification},
doi={},
ISSN={},
month={Oct},}
@INPROCEEDINGS{8902734,
author={Oliveira, Alexandre J. and Assis, Gleice A. and Faria, Elaine R. and Souza, Jefferson R. and Vivaldini, Kelen C. T. and Guizilini, Vitor and Ramos, Fabio and Mendes, C. T. Caio and Wolf, Denis F.},
booktitle={2019 27th European Signal Processing Conference (EUSIPCO)}, title={Analysis of nematodes in coffee crops at different altitudes using aerial images},
year={2019},
volume={},
number={},
pages={1-5},
abstract={Precision agriculture presents several challenges, amongst them the detection of diseases and pests in agricultural environments. This paper describes a methodology capable of detecting the presence of the nematode pest in coffee crops and also analyzing the behavior of this pest in several altitudes using aerial images. An Unmanned Aerial Vehicle (UAV) is used to obtain high-resolution RGB images of a Brazilian coffee farm. The proposed methodology uses Convolutional Neural Networks (CNN) with U-Net and PSPNet architectures to classify areas into two classes: pests and non-pests. Results demonstrate the viability of the proposed methodology, with an average F-measure of 0.69 for the U-Net architecture with the image resolution 640 × 480.},
keywords={Agriculture;Convolution;Training;Diseases;Soil;Image resolution;Unmanned aerial vehicles;CNN;Nematodes;Coffee Crops;UAV;Altitudes.},
doi={10.23919/EUSIPCO.2019.8902734},
ISSN={2076-1465},
month={Sep.},}
@INPROCEEDINGS{8301662,
author={Saha, Arnab Kumar and Saha, Jayeeta and Ray, Radhika and Sircar, Sachet and Dutta, Subhojit and Chattopadhyay, Soummyo Priyo and Saha, Himadri Nath},
booktitle={2018 IEEE 8th Annual Computing and Communication Workshop and Conference (CCWC)}, title={IOT-based drone for improvement of crop quality in agricultural field},
year={2018},
volume={},
number={},
pages={612-615},
abstract={Unmanned Aerial Vehicles are becoming more and more popular to meet the demands of increased population and agriculture. Drones equipped with appropriate cameras, sensors and integrating modules will help in achieving easy, efficient, precision agriculture. The proposed solutions related to these drones, if integrated with various Machine Learning and Internet of Things concepts, can help in increasing the scope of further improvement. In this paper, the related work in this field has been highlighted along with proposed solutions that can be integrated into the drone using Raspberry Pi 3 B module.},
keywords={Agriculture;Drones;Support vector machines;Monitoring;Cameras;Temperature sensors;Internet of Things;Support Vector Machine;Unmanned Aerial Vehicle(UAV);RGB-D sensor;Agriculture},
doi={10.1109/CCWC.2018.8301662},
ISSN={},
month={Jan},}
@INPROCEEDINGS{6858744,
author={Tang, Yimeng and Patton, Ron J},
booktitle={2014 American Control Conference}, title={Reconfigurable Fault Tolerant Control for nonlinear aircraft based on concurrent SMC-NN adaptor},
year={2014},
volume={},
number={},
pages={1267-1272},
abstract={This work focuses on an improved reconfigurable Fault Tolerant Flight Control (FTFC) strategy based on a traditional model reference Neural Network (NN) adaptive flight control architecture. An expanded control scheme is developed by using a concurrent learning NN strategy combined with the Sliding Mode Control (SMC) theory. The improved NN using concurrent update information to compensate for model inversion error is described for the full dynamic characteristics of the aircraft system. The SMC is implemented to treat the NN as a controlled system and allows a stable, dynamic calculation of the learning rates. The proposed reconfigurable FTFC system based on concurrent SMC-NN adaptor is tested on a nonlinear Unmanned Aerial Vehicle (UAV), the Machan UAV, in the presence of fault and disturbance scenarios. The results show that the designed controller achieves better adaptive performance by using the SMC in on-line concurrent NN learning law.},
keywords={Artificial neural networks;Aerodynamics;Training;Adaptation models;Aircraft;Adaptive systems;Aerospace control;Fault-tolerant systems;Flight control;Feedback linearization},
doi={10.1109/ACC.2014.6858744},
ISSN={2378-5861},
month={June},}
@INPROCEEDINGS{7502632,
author={Bannwarth, J. X. J. and Chen, Z. J. and Stol, K. A. and MacDonald, B. A.},
booktitle={2016 International Conference on Unmanned Aircraft Systems (ICUAS)}, title={Disturbance accomodation control for wind rejection of a quadcopter},
year={2016},
volume={},
number={},
pages={695-701},
abstract={This paper investigates the rejection of wind disturbances of an Unmanned Aerial Vehicle (UAV). UAVs are used for increasingly complex operations that require a great deal of accuracy and minimal position changes. This calls for better disturbance rejection. The drag-inclusive dynamics of a quadcopter are derived and used to create two uniaxial wind disturbance rejection controllers: a disturbance accommodating controller (DAC) and a nonlinear feedforward controller. Both controllers are integrated into an open-source flight controller. The performance of the controllers is assessed in simulation against the unmodified baseline. Over a 60 second loiter test, the DAC and nonlinear controllers result in a 45 % and 66 % decrease in error compared to the baseline respectively. Both controllers are shown to react to wind more rapidly. However, the DAC is found to be affected by changes in wind speed due to its linear nature. The baseline controller is used to show the feasibility of rejecting the effects of a 5 meters per second wind in a physical experiment.},
keywords={Wind speed;Drag;Feedforward neural networks;Attitude control;Mathematical model;Rotors;Force},
doi={10.1109/ICUAS.2016.7502632},
ISSN={},
month={June},}
@ARTICLE{8886369,
author={Chen, Haipeng and He, Zhentao and Shi, Bowen and Zhong, Tie},
journal={IEEE Access}, title={Research on Recognition Method of Electrical Components Based on YOLO V3},
year={2019},
volume={7},
number={},
pages={157818-157829},
abstract={The reliability of electrical components affects the stable operation of the power system. Electrical components inspection has long been important issues in the intelligent power system. The main problems of traditional recognition methods of electrical components are low detection accuracy and poor real-time performance, which are challenging to extract necessary features from the inspection images. This paper proposes a way to detect the electrical components in the Unmanned Aerial Vehicle (UAV) inspection image based on You Only Look Once (YOLO) V3 algorithm. Due to some of the inspection images are not clear, which result in the reduction of the available dataset. On this basis, we adopt Super-Resolution Convolutional Neural Network (SRCNN) to realize super-resolution reconstruction on the blurred image, which achieves the expansion of the dataset. We compare the performance of the proposed method with other popular recognition methods. The results of experiment verify the effectiveness of the proposed method, and the technique reaches high recognition accuracy, good robustness, and strong real-time performance for UAV power inspection system.},
keywords={Inspection;Feature extraction;Unmanned aerial vehicles;Image reconstruction;Image recognition;Image resolution;Insulators;Deep Learning;SRCNN;YOLO V3;electrical components;object detection},
doi={10.1109/ACCESS.2019.2950053},
ISSN={2169-3536},
month={},}
@INPROCEEDINGS{9158842,
author={Lee, Denzel and Liu, Jingmin and Lee, Shawndy Michael and Foong, Shaohui},
booktitle={2020 IEEE/ASME International Conference on Advanced Intelligent Mechatronics (AIM)}, title={Automated Dimensional Extraction Of Different Regions Using Single Monocular Camera In Pseudo-Stereo Configuration},
year={2020},
volume={},
number={},
pages={314-321},
abstract={This paper describes the development of an automated dimensional extraction algorithm of specific regions, implemented on BINO: Bearing Inspector for Narrow-space Observation. BINO is a tethered Unmanned Aerial Vehicle (UAV) system designed to eliminate the labor-intensive process and to improve the efficiency of inspecting infrastructures in confined remote locations. The UAV platform provides an effective method to access these hard to reach areas, and the algorithm proposed provides a dimensional analysis of the targeted infrastructure. The algorithm takes in several stereo pair images captured from only a single monocular camera. The availability of the multiple stereo images is possible due to a customized linear actuator where the camera sits on a rack-and-pinion configuration. The algorithm adopts a convolution network for image segmentation to extract crucial areas and, at the same time, generate disparity maps to obtain depth information. A pinhole camera model using the depth information and a single reference object of the bearing enables the derivation of the measurements of the segmented areas. Through experiments, the algorithm has an accuracy of an average RMSE of 1.23mm and a max error of 2.23mm. The ease of conducting inspection using BINO and more accurate measurements from the algorithm ultimately leads to an increase in inspection quality, safety and efficiency.},
keywords={Cameras;Actuators;Inspection;Calibration;Image segmentation;Unmanned aerial vehicles;Cavity resonators;Deep learning: Image segmentation neural network;Aerial systems: Robotics in enclosed environment;Photogrammetry: Triangulation;pinhole camera model.},
doi={10.1109/AIM43001.2020.9158842},
ISSN={2159-6255},
month={July},}
@INPROCEEDINGS{7408345,
author={Chung, Timothy H.},
booktitle={2015 Winter Simulation Conference (WSC)}, title={Advancing autonomous swarm capabilities: From simulation to experimentation},
year={2015},
volume={},
number={},
pages={2341-2341},
abstract={Summary form only given. With increasing availability and proliferation of unmanned system technologies, such as unmanned aerial vehicles (UAVs) in civilian and military applications, both opportunities and challenges arise in addressing large numbers of robots capable of collective interactions. In this presentation, we present active research efforts in the Advanced Robotic Systems Engineering Laboratory (ARSENL) at the Naval Post- graduate School exploring future concepts, mathematical, algorithmic, and simulation models, and live-fly field experimentation of UAV swarms. We highlight and address a number of the specific considerations for modeling engagements between adversarial swarms of autonomous systems, in which the two swarms have opposing mission objectives. Such efforts require further development of autonomous swarm tactics, leveraging existing and future enabling technologies in a holistic, system-of-systems context. This presentation also provides results and lessons learned from both extensive simulation-based studies and also recent field experiments, as part of a live-fly testbed development effort to support rapid innovation and exploration of such future concepts for advanced research and education.},
keywords={Mathematical model;Education;Robot sensing systems;Analytical models},
doi={10.1109/WSC.2015.7408345},
ISSN={1558-4305},
month={Dec},}
@INPROCEEDINGS{9297196,
author={Danesh, Shadi and Araghi, Ali and Khalily, Mohsen and Xiao, Pei and Tafazolli, Rahim},
booktitle={2020 International Symposium on Networks, Computers and Communications (ISNCC)}, title={Millimeter Wave Phased Array Antenna Synthesis Using a Machine Learning Technique for Different 5G Applications},
year={2020},
volume={},
number={},
pages={1-5},
abstract={A machine learning (ML) technique has been used to synthesis a linear millimetre wave (mmWave) phased array antenna by considering the phase-only synthesis approach. For the first time, gradient boosting tree (GBT) is applied to estimate the phase values of a 16-element array antenna to generate different far-field radiation patterns. GBT predicts phases while the amplitude values have been equally set to generate different beam patterns for various 5G mmWave transmission scenarios such as multicast, unicast, broadcast and unmanned aerial vehicle (UAV) applications.},
keywords={Phased arrays;Antenna radiation patterns;Linear antenna arrays;5G mobile communication;Unicast;Unmanned aerial vehicles;Training;5G;phased array antenna;gradient boosting tree (GBT);machine learning (ML);millimetre wave (mmWave);array factor;phase-only synthesis},
doi={10.1109/ISNCC49221.2020.9297196},
ISSN={},
month={Oct},}
@INPROCEEDINGS{9025665,
author={Ringwald, Tobias and Sommer, Lars and Schumann, Arne and Beyerer, Jürgen and Stiefelhagen, Rainer},
booktitle={2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)}, title={UAV-Net: A Fast Aerial Vehicle Detector for Mobile Platforms},
year={2019},
volume={},
number={},
pages={544-552},
abstract={Vehicle detection in aerial imagery is a challenging task due to small object sizes, high object density and partial occlusions. While past research mostly focused on improving detection accuracy, inference speed is another important factor when using CNN object detectors in a real life scenario - especially when targeting mobile platforms like unmanned aerial vehicles (UAVs). In this work, we compare several established detection frameworks in terms of their accuracy-speed trade-off and show that the Single Shot MultiBox Detector (SSD) offers the best compromise. We subsequently undertake a thorough evaluation of several design choices to further increase detection speed while sacrificing little to no accuracy. This includes the choice of base network architecture, improved prediction layers and an automatic model pruning approach. Given our evaluation results, we finally construct UAV-Net - a novel aerial vehicle detector that has a model size of less than 0.4 MiB and is more than 16 times faster than current top performing approaches. UAV-Net is well suited for on-board processing and operates in real time on a Jetson TX2 platform. Nevertheless, its accuracy is on par with state-of-the-art approaches on the DLR 3K, VEDAI and UAVDT datasets. Code and models are available on the project website.},
keywords={Convolution;Detectors;Feature extraction;Vehicle detection;Task analysis;Machine learning;Kernel},
doi={10.1109/CVPRW.2019.00080},
ISSN={2160-7516},
month={June},}
@INPROCEEDINGS{9136237,
author={Zhang, Weidong and Gu, Chaoyue and Li, Zhe and Sheng, Gehao},
booktitle={2020 5th Asia Conference on Power and Electrical Engineering (ACPEE)}, title={Image Detection Technology on Pin Defect to Overhead Power Lines},
year={2020},
volume={},
number={},
pages={229-233},
abstract={To improve efficiency of UAV in routing inspection of overhead power lines as well as detection rate of pin defect to overhead power lines, the thesis proposes a method for detection of pin defect for UAV routing inspection of overhead power lines based on Faster-RCNN algorithm. In view of the fact that UAV routing inspection is characterized by large image background and tiny size of pin, the deep residual network ResNet101 is selected as pre-feature extraction network on the basis of Faster-RCNN and training image scale is increased. Experiments show that the method has a good performance in pin defect detection in UAV patrol image on test set. Compared with other prevailing object detection methods, the detection effect is better and the generalization ability is stronger.},
keywords={Training;Electrical engineering;Neural networks;Asia;Object detection;Inspection;Routing;UAV Patrol Image;Overhead Power Lines;Pin Defect Detection;Convolutional Neural Network},
doi={10.1109/ACPEE48638.2020.9136237},
ISSN={},
month={June},}
@INPROCEEDINGS{8123592,
author={Hsu, Chihwei and Chen, Feng and Wang, Guijin},
booktitle={2017 International Conference on Vision, Image and Signal Processing (ICVISP)}, title={High-Resolution Image Inpainting through Multiple Deep Networks},
year={2017},
volume={},
number={},
pages={76-81},
abstract={For the operation and aerial photography of the UAV, it is important to identify the blindspots and observe the details on the ground. But limited by the camera resolution, small or fuzzy objects can not be effectively observed. Therefore, repairment of high-definition images has become one of the important problems to be solved. In recent years, the development of the deep learning method has effectively solved the loss and blurring of images, but because of the difficulties in training and the speed of calculation it can only be used with low-pixel images. Therefore, we propose a method for superimposing images first with the content and textual recovery for the defaced area. We use unsupervised learning GANs and trained VGG network to restore holes and missing areas of the image, and then enlarge it through CNN method. Our preliminary results show that high resolution image restoration speed has been greatly improved, and details become sharper than using traditional method.},
keywords={Signal processing;Image Inpainting;Deep Learning;Super Resolution},
doi={10.1109/ICVISP.2017.27},
ISSN={},
month={Sep.},}
@ARTICLE{9430527,
author={Kaputa, Daniel S. and Landy, Brian P.},
journal={IEEE Access}, title={YOLBO: You Only Look Back Once–A Low Latency Object Tracker Based on YOLO and Optical Flow},
year={2021},
volume={9},
number={},
pages={82497-82507},
abstract={One common computer vision task is to track an object as it moves from frame to frame within a video sequence. There are a myriad of applications for such capability and the underlying technologies to achieve this tracking are very well understood. More recently, deep convolutional neural networks have been employed to not only track, but also to classify objects as they are tracked from frame to frame. These models can be used in a tracking paradigm known as tracking by detection and can achieve very high tracking accuracy. The major drawback to these deep neural networks is the large amount of mathematical operations that must be performed for each inference which negatively impacts the number of tracked frames per second. For edge applications residing on size, weight, and power limited platforms, such as unmanned aerial vehicles, high frame rate and low latency real time tracking can be an elusive target. To overcome the limited power and computational resources of an edge compute device, various optimizations have been performed to trade off tracking speed, accuracy, power, and latency. Previous works on motion based interpolation with neural networks either do not take into account the latency accrued from camera image capture to tracking result or they compensate for this latency but are bottlenecked by the motion interpolation operation instead. The algorithm presented in this work gains the performance speedup used in previous motion based neural network inference papers and also performs a novel look back operation that is less cumbersome than other competing motion interpolation methods.},
keywords={Tracking;Target tracking;Image edge detection;Interpolation;Trajectory;Object tracking;Object detection;CNN;classifier;detector;neural network;low latency;tracker;UAV;YOLO;look back;drone;image processing},
doi={10.1109/ACCESS.2021.3080136},
ISSN={2169-3536},
month={},}
@ARTICLE{8961911,
author={Garcia-Magarino, Ivan and Gray, Geraldine and Lacuesta, Raquel and Lloret, Jaime},
journal={IEEE Network}, title={Smart Green Communication Protocols Based on Several-Fold Messages Extracted from Common Sequential Patterns in UAVs},
year={2020},
volume={34},
number={3},
pages={249-255},
abstract={Green communications can be crucial for saving energy in UAVs and enhancing their autonomy. The current work proposes to extract common sequential patterns of communications to gather each common pattern into a single several- fold message with a high-level compression. Since the messages of a pattern are elapsed from each other in time, the current approach performs a machine learning approach for estimating the elapsed times using off-line training. The learned predictive model is applied by each UAV during flight when receiving a several-fold compressed message. We have explored neural networks, linear regression and correlation analyses among others. The current approach has been tested in the domain of surveillance. In specific-purpose fleets of UAVs, the number of transmissions was reduced by 13.9 percent.},
keywords={Energy consumption;Encoding;Data mining;Relays;Training;Estimation;Big Data},
doi={10.1109/MNET.001.1900417},
ISSN={1558-156X},
month={May},}
@INPROCEEDINGS{9213538,
author={Lin, Fuyan and Zheng, Xin and Wu, Qiang},
booktitle={2020 IEEE International Conference on Advances in Electrical Engineering and Computer Applications( AEECA)}, title={Small object detection in aerial view based on improved YoloV3 neural network},
year={2020},
volume={},
number={},
pages={522-525},
abstract={In application scenarios such as UAV inspection, deep learning-based object detection methods are increasingly used to improve the automation of line inspection. In the aerial view scene, the drone is usually fly at a high altitude from the ground, so the proportion of the object in the image is relatively small. When the YoloV3 network identifies small objects, the detection result would not be good because there is less information in the 8x downsampling feature map. In this paper, base on the LaSOT data set, the YoloV3 network has been modified by adjusting the values of anchors and establishing the 4x downsampling prediction layer to enhance the detection effect of small objects. Compared with the original YoloV3 network, the improved YoloV3 network has a certain improvement in convergence ability and detection accuracy compared to the original YoloV3 network.},
keywords={Feature extraction;Object detection;Training;Inspection;Object recognition;Convergence;Neural networks;object detection;YoloV3;small object identify;Kmeans clustering;Multi-scale feature fusion},
doi={10.1109/AEECA49918.2020.9213538},
ISSN={},
month={Aug},}
@ARTICLE{8897093,
author={St-Onge, David and Kaufmann, Marcel and Panerati, Jacopo and Ramtoula, Benjamin and Cao, Yanjun and Coffey, Emily B.J. and Beltrame, Giovanni},
journal={IEEE Robotics Automation Magazine}, title={Planetary Exploration With Robot Teams: Implementing Higher Autonomy With Swarm Intelligence},
year={2020},
volume={27},
number={2},
pages={159-168},
abstract={Since the beginning of space exploration, Mars and the moon have been examined via orbiters, landers, and rovers. More than 40 missions have targeted Mars, and over 100 have been sent to the moon. Space agencies continue to focus on developing novel strategies and technologies for probing celestial bodies. Multirobot systems are particularly promising for planetary exploration, as they are more robust to individual failure and have the potential to examine larger areas; however, there are limits to how many robots an operator can control individually. We recently took part in the European Space Agency's (ESA's) interdisciplinary equipment test campaign (PANGAEA-X) at a lunar/Mars analog site in Lanzarote, Spain. We used a heterogeneous fleet of unmanned aerial vehicles (UAVs)-a swarm-to study the interplay of systems operations and human factors. Human operators directed the swarm via ad hoc networks and data-sharing protocols to explore unknown areas under two control modes: in one, the operator instructed each robot separately; in the other, the operator provided general guidance to the swarm, which self-organized via a combination of distributed decision making and consensus building. We assessed cognitive load via pupillometry for each condition and perceived task demand and intuitiveness via selfreport. Our results show that implementing higher autonomy with swarm intelligence can reduce workload, freeing the operator for other tasks such as overseeing strategy and communication. Future work will further leverage advances in swarm intelligence for exploration missions.},
keywords={Robot kinematics;Task analysis;Robot sensing systems;Safety;Global Positioning System;Moon;Mobile robots},
doi={10.1109/MRA.2019.2940413},
ISSN={1558-223X},
month={June},}
@INPROCEEDINGS{9316058,
author={V, Soundari. D. and S, Karthick. and V, Srikanth. and G, Sanjay Kumar V. and S, Srijith Raj.},
booktitle={2020 3rd International Conference on Intelligent Sustainable Systems (ICISS)}, title={Artificial Intelligence based Efficient Phenotyping for Agronomics},
year={2020},
volume={},
number={},
pages={484-488},
abstract={The evaluation of soil and plants has been a costly, labor-intensive, and time-consuming process traditionally. With the advancements in technology, the phenotypic variations in plants and their corresponding information can be extracted efficiently using IoT, WSN, and computer vision and processed with machine learning, artificial intelligence, and such cutting-edge techniques. This can help in accelerating the developments in vegetation, improving the genomic selection, and enable high-throughput plant phenotyping. In this work, the phenotypic characteristics of the crop and the soil conditions are assessed using deep learning convolutional neural networks based on the data obtained by the IoT sensors and multispectral imaging from small Unmanned Aerial Vehicles (UAVs) across the agricultural area. The plant quality and leaf diseases are identified. 99.9% precision and recall are obtained with an overall accuracy of 95%. This technique is quick, cost-effective, and reliable.},
keywords={Agriculture;Diseases;Sensors;Artificial intelligence;Stress;Unmanned aerial vehicles;Soil;Agronomics;Phenotyping;Artificial Intelligence;Computer Vision;IoT},
doi={10.1109/ICISS49785.2020.9316058},
ISSN={},
month={Dec},}
@ARTICLE{9420724,
author={Vachmanus, Sirawich and Ravankar, Ankit A. and Emaru, Takanori and Kobayashi, Yukinori},
journal={IEEE Sensors Journal}, title={Multi-Modal Sensor Fusion-Based Semantic Segmentation for Snow Driving Scenarios},
year={2021},
volume={21},
number={15},
pages={16839-16851},
abstract={In recent years, autonomous vehicle driving technology and advanced driver assistance systems have played a key role in improving road safety. However, weather conditions such as snow pose severe challenges for autonomous driving and are an active research area. Thanks to their superior reliability, the resilience of detection, and improved accuracy, advances in computation and sensor technology have paved the way for deep learning and neural network–based techniques that can replace the classical approaches. In this research, we investigate the semantic segmentation of roads in snowy environments. We propose a multi-modal fused RGB-T semantic segmentation utilizing a color (RGB) image and thermal map (T) as inputs for the network. This paper introduces a novel fusion module that combines the feature map from both inputs. We evaluate the proposed model on a new snow dataset that we collected and on other publicly available datasets. The segmentation results show that the proposed fused RGB-T input can segregate human subjects in snowy environments better than an RGB-only input. The fusion module plays a vital role in improving the efficiency of multiple input neural networks for person detection. Our results show that the proposed network can generate a higher success rate than other state-of-the-art networks. The combination of our fused module and pyramid supervision path generated the best results in both mean accuracy and mean intersection over union in every dataset.},
keywords={Roads;Snow;Image segmentation;Sensors;Semantics;Feature extraction;Training;Machine learning;semantic segmentation;thermal camera;data fusion},
doi={10.1109/JSEN.2021.3077029},
ISSN={1558-1748},
month={Aug},}
@INPROCEEDINGS{9216035,
author={Zak, Yuval and Parmet, Yisrael and Oron-Gilad, Tal},
booktitle={2020 IEEE Conference on Cognitive and Computational Aspects of Situation Management (CogSIMA)}, title={An Artificial Intelligence Algorithm to Automate Situation Management for Operators of Unmanned Aerial Vehicles},
year={2020},
volume={},
number={},
pages={1-9},
abstract={Unmanned Aerial Vehicle (UAV) operators must maintain high levels of situation awareness on their area of operation. To achieve this, they use the a Command and Control (C2) map, which is shared among forces, and regularly overloaded with data that is irrelevant to their operational mission. Operators require distilled information at the right timing. Yet, the existing filtering mechanisms for C2 maps are layer-based and insufficient. We propose a new approach to automatically and dynamically filter information items on the map based on environmental and mission context. To achieve this, we introduce a three-tiers artificial intelligence (AI) based algorithm (GiCo-MAF), where we delineate the use of machine learning (ML) models to support UAV missions. For the GiCoMAF development, tagged data was collected in simulated experimental runs with professional UAS operators. Different types of ML models were evaluated and fitted into the algorithm. The models achieved a relatively high accuracy at modeling human preference and area of interest. The approach presented in this study can be further implemented to support time-critical spatial-temporal operational problems.},
keywords={Heuristic algorithms;Unmanned aerial vehicles;Command and control systems;Artificial intelligence;Payloads;Computational modeling;Prediction algorithms;artificial intelligence;human systems integration;uninhabited aerial vehicles;mental workload;situation awareness;human-automation interaction;intelligent systems;decision making;information processing},
doi={10.1109/CogSIMA49017.2020.9216035},
ISSN={2379-1675},
month={Aug},}
@INPROCEEDINGS{9149258,
author={Qiu, Jin and Lyu, Jiangbin and Fu, Liqun},
booktitle={ICC 2020 - 2020 IEEE International Conference on Communications (ICC)}, title={Placement Optimization of Aerial Base Stations with Deep Reinforcement Learning},
year={2020},
volume={},
number={},
pages={1-6},
abstract={Unmanned aerial vehicles (UAVs) can be utilized as aerial base stations (ABSs) to assist terrestrial infrastructure for keeping wireless connectivity in various emergency scenarios. To maximize the coverage rate of N ground users (GUs) by jointly placing multiple ABSs with limited coverage range is known to be a NP-hard problem with exponential complexity in N. The problem is further complicated when the coverage range becomes irregular due to site-specific blockage (e.g., buildings) on the air-ground channel in the 3-dimensional (3D) space. To tackle this challenging problem, this paper applies the Deep Reinforcement Learning (DRL) method by 1) representing the state by a coverage bitmap to capture the spatial correlation of GUs/ABSs, whose dimension and associated neural network complexity is invariant with arbitrarily large N; and 2) designing the action and reward for the DRL agent to effectively learn from the dynamic interactions with the complicated propagation environment represented by a 3D Terrain Map. Specifically, a novel two-level design approach is proposed, consisting of a preliminary design based on the dominant line-of-sight (LoS) channel model, and an advanced design to further refine the ABS positions based on site-specific LoS/non-LoS channel states. The double deep Q-network (DQN) with Prioritized Experience Replay (Prioritized Replay DDQN) algorithm is applied to train the policy of multi-ABS placement decision. Numerical results show that the proposed approach significantly improves the coverage rate in complex environment, compared to the benchmark DQN and K-means algorithms.},
keywords={Channel models;Complexity theory;Three-dimensional displays;Optimization;Signal to noise ratio;Base stations;Machine learning},
doi={10.1109/ICC40277.2020.9149258},
ISSN={1938-1883},
month={June},}
@INPROCEEDINGS{9436958,
author={Huang, Shihong and Zhang, Zhaoyun and Yanxin, Li and Hui, Li and Wang, Qitong and Zhang, Zhi and Zhao, Yang},
booktitle={2021 6th Asia Conference on Power and Electrical Engineering (ACPEE)}, title={Transmission equipment image recognition based on Ensemble Learning},
year={2021},
volume={},
number={},
pages={295-299},
abstract={Unmanned aerial vehicle (UAV) inspection is the most popular inspection method in power transmission line inspection. UAV inspection mainly obtains the inspection image of power transmission equipment through machine vision and detects it. Image classification technology is mainly used for the identification of power transmission equipment, which can be used for fault diagnosis after sorting out the equipment. In order to accurately classify transmission equipment images, a classification method based on ensemble learning is proposed. This paper classifies and identifies four kinds of equipment in transmission line, including insulator, damper, interval rods, and corona ring. The experimental results show that the efficiency of the proposed ensemble learning method is better than that of single machine learning classifier.},
keywords={Fault diagnosis;Performance evaluation;Power transmission lines;Machine vision;Power transmission;Inspection;Feature extraction;ensemble learning;transmission line detection;image classification;power equipment identification;ensemble by voting},
doi={10.1109/ACPEE51499.2021.9436958},
ISSN={},
month={April},}
@INPROCEEDINGS{7925654,
author={Acuna, V. and Kumbhar, A. and Vattapparamban, E. and Rajabli, F. and Guvenc, I.},
booktitle={2017 IEEE Wireless Communications and Networking Conference (WCNC)}, title={Localization of WiFi Devices Using Probe Requests Captured at Unmanned Aerial Vehicles},
year={2017},
volume={},
number={},
pages={1-6},
abstract={Localization of mobile wireless devices carries critical importance for applications such as search and rescue, public safety, surveillance, and occupancy monitoring. In this paper, we study the problem of localizing WiFi-enabled mobile devices such as smartphones and tablets using the measurements captured by an unmanned aerial vehicle (UAV). We make use of the continuously broadcasted WiFi probe requests from mobile devices, capture them at different locations at a WiFi sniffer carried by a UAV, and subsequently estimate the user's location using random-forest based machine learning technique. More specifically, the geographical area of interest is partitioned into multiple zones, and based on the measured probe requests, we are interested to identify the zone where the WiFi device is located. Our experimental results show that the WiFi device can be detected in correct occupancy zone with a 81.8% accuracy.},
keywords={Wireless fidelity;Probes;Telemetry;Virtual private networks;Unmanned aerial vehicles;Global Positioning System;Safety},
doi={10.1109/WCNC.2017.7925654},
ISSN={1558-2612},
month={March},}
@INPROCEEDINGS{9024644,
author={Krijestorac, Enes and Hanna, Samer and Cabric, Danijela},
booktitle={2019 IEEE Globecom Workshops (GC Wkshps)}, title={UAV Access Point Placement for Connectivity to a User with Unknown Location Using Deep RL},
year={2019},
volume={},
number={},
pages={1-6},
abstract={In recent years, unmanned aerial vehicles (UAVs) have been considered for telecommunications purposes as relays, caches, or IoT data collectors. In addition to being easy to deploy, their maneuverability allows them to adjust their location to optimize the capacity of the link to the user equipment on the ground or of the link to the basestation. The majority of the previous work that analyzes the optimal placement of such a UAV makes at least one of two assumptions: the channel can be predicted using a simple model or the locations of the users on the ground are known. In this paper, we use deep reinforcement learning (deep RL) to optimally place a UAV serving a ground user in an urban environment, without the previous knowledge of the channel or user location. Our algorithm relies on signal-to-interference-plus- noise ratio (SINR) measurements and a 3D map of the topology to account for blockage and scatterers. Furthermore, it is designed to operate in any urban environment. Results in conditions simulated by a ray tracing software show that with the constraint on the maximum number of iterations our algorithm has a 90% success rate in converging to a target SINR.},
keywords={Learning (artificial intelligence);Signal to noise ratio;Interference;Topology;Unmanned aerial vehicles;Urban areas;Three-dimensional displays},
doi={10.1109/GCWkshps45667.2019.9024644},
ISSN={},
month={Dec},}
@INPROCEEDINGS{9580225,
author={Wang, Huanchi and Fang, He and Wang, Xianbin},
booktitle={2021 IEEE/CIC International Conference on Communications in China (ICCC)}, title={Edge Intelligence Enabled Soft Decentralized Authentication in UAV Swarm},
year={2021},
volume={},
number={},
pages={86-91},
abstract={With the increased deployment of the Unmanned Aerial Vehicles (UAVs) in both military and civilian fields, the authentication of the UAV surveillance and controlling data becomes critical due to the severe consequences of any forged data. With the highly dynamic operation environment, a flying UAV network may not be supported by the infrastructure network on the ground for security provision. Hence, it is vital to improving network security by utilizing on-site resources within a flying UAV swarm. In this paper, we utilize the physical-layer fingerprints to increase the difficulty for the attackers to impersonate the legitimate UAVs. A decentralized authentication scheme is proposed to avoid the single-point failure at the cluster head (CH) caused by the imperfect estimations. To mitigate the high computational cost of the decentralized authentication and to further improving the authentication accuracy, a situational-aware authentication customization algorithm is proposed at each UAV to compute the reliability of different attributes. Only the UAV with reliable attributes observations will contribute to the decentralized authentication process. Moreover, a soft authentication decision algorithm, which is compatible with customized regression models at each UAV, is proposed to further improve the system robustness. Hence, the proposed authentication algorithm can be customized at the system level and node level to maximize the overall authentication accuracy under a minimal extra computational cost based on the decentralized process. The simulation results demonstrate that our proposed scheme significantly increased the accuracy by comparing to the other state-of-the-art machine learning-aided physical-layer authentication schemes.},
keywords={Uncertainty;Surveillance;Simulation;Authentication;Estimation;Fingerprint recognition;Unmanned aerial vehicles;Decentralized Authentication;Physical-layer Fingerprints;Situation Awareness;Unmanned Aerial Vehicles (UAVs)},
doi={10.1109/ICCC52777.2021.9580225},
ISSN={2377-8644},
month={July},}
@INPROCEEDINGS{9308537,
author={Hepworth, Adam J. and Yaxley, Kate J. and Baxter, Daniel P. and Joiner, Keith F. and Abbass, Hussein},
booktitle={2020 IEEE Symposium Series on Computational Intelligence (SSCI)}, title={Tracking Footprints in a Swarm: Information-Theoretic and Spatial Centre of Influence Measures},
year={2020},
volume={},
number={},
pages={2217-2224},
abstract={Boids (bird-oids) is a widely used model to mimic the behaviour of birds. Shoids (sheep-oids) rely on the same boids rules with the addition of a repulsive force away from a sheepdog (a herding agent). Previous work assumed homogeneous shoids. Real-world observations of sheep show non-homogeneous responses to the presence of a herding agent. We present a portfolio of information-theoretic and spatial indicators to track the footprints of shoids with different parameters within the shoid flock. The portfolio is named the Centre of Influence to indicate that the aim is to identify the influential shoids with the highest impact on flock dynamics. We use both synthetic simulation-driven data and measurements collected from live sheep herding trials by an unmanned aerial vehicle (UAV) to validate the proposed measures. The resultant measures will allow us in our future research to design more efficient control strategies for the UAV, by polarising the attention of the machine learning algorithm on those shoids with influence footprints, to drive the flock to improve the herding of sheep.},
keywords={Entropy;Predator prey systems;Force;Data models;Unmanned aerial vehicles;Computational modeling;Area measurement;Centre of Influence;Predation Risk;Situation Awareness;Swarm Shepherding;Transfer Entropy;Unmanned Aerial Vehicles},
doi={10.1109/SSCI47803.2020.9308537},
ISSN={},
month={Dec},}
@ARTICLE{8474384,
author={Li, Lixin and Xu, Yang and Zhang, Zihe and Yin, Jiaying and Chen, Wei and Han, Zhu},
journal={IEEE Journal on Selected Areas in Communications}, title={A Prediction-Based Charging Policy and Interference Mitigation Approach in the Wireless Powered Internet of Things},
year={2019},
volume={37},
number={2},
pages={439-451},
abstract={The Internet of Things (IoT) technology has recently drawn more attention due to its ability to achieve the interconnections of massive physic devices. However, how to provide a reliable power supply to energy-constrained devices and improve the energy efficiency in the wireless powered IoT (WP-IoT) is a twofold challenge. In this paper, we develop a novel wireless power transmission (WPT) system, where an unmanned aerial vehicle (UAV) equipped with radio frequency energy transmitter charges the IoT devices. A machine learning framework of echo state networks together with an improved k -means clustering algorithm is used to predict the energy consumption and cluster all the sensor nodes at the next period, thus automatically determining the charging strategy. The energy obtained from the UAV by WPT supports the IoT devices to communicate with each other. In order to improve the energy efficiency of the WP-IoT system, the interference mitigation problem is modeled as a mean field game, where an optimal power control policy is presented to adapt and analyze the large number of sensor nodes randomly deployed in WP-IoT. The numerical results verify that our proposed dynamic charging policy effectively reduces the data packet loss rate, and that the optimal power control policy greatly mitigates the interference, and improve the energy efficiency of the whole network.},
keywords={Interference;Power control;Wireless sensor networks;Mathematical model;Games;Robot sensing systems;Wireless communication;Wireless power transmission (WPT);charging policy;energy prediction;Internet of Things (IoT);mean-field game (MFG)},
doi={10.1109/JSAC.2018.2872429},
ISSN={1558-0008},
month={Feb},}
@ARTICLE{8323415,
author={Shoufan, Abdulhadi and Al-Angari, Haitham M. and Sheikh, Muhammad Faraz Afzal and Damiani, Ernesto},
journal={IEEE Transactions on Information Forensics and Security}, title={Drone Pilot Identification by Classifying Radio-Control Signals},
year={2018},
volume={13},
number={10},
pages={2439-2447},
abstract={Analysis of interactions with remotely controlled devices has been used to detect the onset of hijacking attacks, as well as for forensics analysis, e.g., to identify the human controller. Its effectiveness is known to depend on the remote device type as well as on the properties of the remote control signal. This paper shows that the radio control signal sent to an unmanned aerial vehicle (UAV) using a typical transmitter can be captured and analyzed to identify the controlling pilot using machine learning techniques. Twenty trained pilots have been asked to fly a high-end research drone through three different trajectories. Control data have been collected and used to train multiple classifiers. Best performance has been achieved by a random forest classifier that achieved accuracy around 90% using simple time-domain features. Extensive tests have shown that the classification accuracy depends on the flight trajectory and that the pitch, roll, yaw, and thrust control signals show different levels of significance for pilot identification. This result paves the way to a number of security and forensics applications, including continuous identification of UAV pilots to mitigate the risk of hijacking.},
keywords={Drones;Global Positioning System;Security;Radio transmitters;Trajectory;Pilot identification;behavioral biometrics;unmanned aerial vehicles;random forest},
doi={10.1109/TIFS.2018.2819126},
ISSN={1556-6021},
month={Oct},}
@INPROCEEDINGS{9352891,
author={Basak, Sanjoy and Rajendran, Sreeraj and Pollin, Sofie and Scheers, Bart},
booktitle={2021 International Conference on COMmunication Systems NETworkS (COMSNETS)}, title={Drone classification from RF fingerprints using deep residual nets},
year={2021},
volume={},
number={},
pages={548-555},
abstract={Detecting UAVs is becoming more crucial for various industries such as airports and nuclear power plants for improving surveillance and security measures. Exploiting radio frequency (RF) based drone control and communication enables a passive way of drone detection for a wide range of environments and even without favourable line of sight (LOS) conditions. In this paper, we evaluate RF based drone classification performance of various state-of-the-art (SoA) models on a new realistic drone RF dataset. With the help of a newly proposed residual Convolutional Neural Network (CNN) model, we show that the drone RF frequency signatures can be used for effective classification. The robustness of the classifier is evaluated in a multipath environment considering varying Doppler frequencies that may be introduced from a flying drone. We also show that the model achieves better generalization capabilities under different wireless channel and drone speed scenarios. Furthermore, the newly proposed model's classification performance is evaluated on a simultaneous multi-drone scenario. The classifier achieves close to 99% classification accuracy for signal-to-noise ratio (SNR) 0dB and at-10 dB SNR it obtains 5% better classification accuracy compared to the existing framework.},
keywords={Radio frequency;Wireless communication;Visualization;Convolutional neural networks;Wireless fidelity;Drones;Signal to noise ratio;Convolutional neural network;deep neural networks;sensor systems and applications},
doi={10.1109/COMSNETS51098.2021.9352891},
ISSN={2155-2509},
month={Jan},}
@ARTICLE{9340340,
author={Viseras, Alberto and Meissner, Michael and Marchal, Juan},
journal={IEEE Access}, title={Wildfire Front Monitoring with Multiple UAVs using Deep Q-Learning},
year={2021},
volume={},
number={},
pages={1-1},
abstract={Wildfires destroy thousands of hectares every summer all over the globe. To provide an effective response and to mitigate wildfires impact, firefighters require a real-time monitoring of the fire front. This paper proposes a cooperative reinforcement learning (RL) framework that allows a team of autonomous unmanned aerial vehicles (UAVs) to learn how to monitor a fire front. In the literature, independent Q-learners were proposed to solve a wildfire monitoring task with two UAVs. Here we propose a framework that can be easily extended to a larger number of UAVs. Our framework builds on two methods: multiple single trained Q-learning agents (MSTA) and value decomposition networks (VDN). MSTA trains a single UAV controller, which is then "copied" to each of the UAVs in the team. In contrast, VDN trains agents to learn how to cooperate. We benchmarked in simulations our two considered methods – MSTA and VDN – against two state-of-the-art approaches: independent Q-learners and a joint Q-learner. Simulation results show that our considered methods outperform state-of-the-art approaches in a wildfire front monitoring task with up to 9 fixed-wing and multi-copter UAVs.},
keywords={Monitoring;Task analysis;Fuels;Stochastic processes;Satellites;Drones;Scalability;Robot learning;Multi-robot systems;Unmanned aerial vehicles;Intelligent robots;Mobile robots;Robot control},
doi={10.1109/ACCESS.2021.3055651},
ISSN={2169-3536},
month={},}
@INPROCEEDINGS{7727801,
author={Zhong, Dexing and Zhang, Xuefei and Sun, Haotian and Ren, Zhigang and Han, Jiuqiang},
booktitle={2016 International Joint Conference on Neural Networks (IJCNN)}, title={A vision-based auxiliary system of multirotor unmanned aerial vehicles for autonomous rendezvous and docking},
year={2016},
volume={},
number={},
pages={4586-4592},
abstract={Unmanned aerial vehicles (UAVs) are versatile in maneuverability for both civilian and military applications. To facilitate the long-term tasks of UAVs, autonomous rendezvous and docking (ARaD) will be a need in the emerging field of UAV research. In this paper, we proposed a vision-based auxiliary system (VAS) for multirotor UAVs to implement autonomous rendezvous and docking. The VAS consists of image acquisition and processing unit, wireless communication unit, and tracking and docking control unit. Continuously adaptive mean shift (CamShift) algorithm was applied for tracking the target and obtaining its 3D coordinates. A specific Zigbee protocol was designed to ensure the steady and rapid transmission of status data between UAVs and the ground station. A straight-forward tracking and docking control algorithm was proposed to assist the rendezvous and docking between the two UAVs. Physical simulation experiments were performed by two six-rotor rotorcrafts, which demonstrate the feasibility and practicability of our proposed vision-based auxiliary system for the future application.},
keywords={Wireless communication;Target tracking;Radar tracking;Heuristic algorithms;Algorithm design and analysis;Target recognition;ZigBee;UAVs;automatic refueling;tracking;wireless communication;Camshift},
doi={10.1109/IJCNN.2016.7727801},
ISSN={2161-4407},
month={July},}
@INPROCEEDINGS{6406777,
author={Hunt, S. and Meng, Q. and Hinde, C.J.},
booktitle={2012 11th International Conference on Machine Learning and Applications}, title={An Extension of the Consensus-Based Bundle Algorithm for Multi-agent Tasks with Task Based Requirements},
year={2012},
volume={2},
number={},
pages={451-456},
abstract={This paper addresses the problem of multi-agent, multi-task assignment with multiple agent requirements on tasks for unmanned aerial vehicles by presenting the Consensus Based Grouping Algorithm. The algorithm is an extension of the Consensus Based Bundle Algorithm that converges to a conflict free, feasible solution of which previous algorithms are unable to account for. Furthermore the algorithm creates a framework to take into account task based requirements, deadlocking and a method to store assignments for a dynamical environment.},
keywords={Vectors;Algorithm design and analysis;Resource management;Receivers;Educational institutions;Computer science;Unmanned aerial vehicles;CBAA;CBBA;CBGA;UAV;Consensus;Task Allocation;Cooperation},
doi={10.1109/ICMLA.2012.163},
ISSN={},
month={Dec},}
@INPROCEEDINGS{9230250,
author={Li, Boxuan and Wu, Jiezhang and Tan, Xiaojun and Wang, Benfei},
booktitle={2020 5th International Conference on Automation, Control and Robotics Engineering (CACRE)}, title={ArUco Marker Detection under Occlusion Using Convolutional Neural Network},
year={2020},
volume={},
number={},
pages={706-711},
abstract={Camera pose estimation is a significant warranty during Unmanned Aerial Vehicle (UAV) autonomous landing process. Fiducial marker system is a popular method to offer relatively precise pose information. However, square-based markers are unreliable under occlusion condition, especially when their corners are covered by unexpected disturbances. This study proposes a novel method to detect fiducial markers using neural network. The method is developed based on Convolutional Neural Network (CNN) and achieves outstanding results under various occlusion conditions, including different cover shapes and ratios. YOLOv3, along with its improved version YOLOv3-spp and its lightweight version YOLOv3-tiny, are applied as the marker detector. Compared to the traditional ArUco fiducial marker system, CNN architectures are more robust and stable in extreme environment. Performance of three different CNN models is quantified as marker detection rate. This work validates the feasibility of square-based fiducial marker localization employing CNN architecture, and reveals the potential of deep learning method in the field of fiducial marker detection and recognition.},
keywords={Warranties;Shape;Pose estimation;Fiducial markers;Unmanned aerial vehicles;Convolutional neural networks;Robots;Fiducial Marker;Convolutional Neural Network;Objection Detection;Occlusion},
doi={10.1109/CACRE50138.2020.9230250},
ISSN={},
month={Sep.},}
@INPROCEEDINGS{9653238,
author={Lorincz, Josip and Tahirović, Adnan and Stojkoska, Biljana Risteska},
booktitle={2021 29th Telecommunications Forum (TELFOR)}, title={A Novel Real-Time Unmanned Aerial Vehicles-based Disaster Management Framework},
year={2021},
volume={},
number={},
pages={1-4},
abstract={The paper proposes a novel computing and net-working framework that can be implemented for the realization of different disaster management applications or real-time surveillance. The framework is based on networks of unmanned aerial vehicles (UAVs) equipped with different sensors including cameras. The framework represents a holistic approach that exploits the distributed architecture of clusters of UAVs and cloud computing resources located on the ground. The proposed framework is characterized by the hierarchical organization among framework elements. In such a framework, each UAV is assumed to be fully autonomous and locally implements a state-of-the-art deep learning algorithms for real-time route planning, obstacle avoidance and object detection on aerial images. The main operating modules of the proposed framework have been presented, with the emphasis on the improvements which the proposed framework can bring in terms of event detection time and accuracy, energy consumption and reliability of application in disaster management systems. The proposed framework can serve as the foundation for the development of more reliable, faster in terms of disaster event detection and energy-efficient disaster management systems based on UAV networks.},
keywords={Deep learning;Cloud computing;Event detection;Disaster management;Object detection;Autonomous aerial vehicles;Real-time systems;holistic framework;disaster sensing;UAV;deep learning;architecture;image processing;CNN;cloud;wireless},
doi={10.1109/TELFOR52709.2021.9653238},
ISSN={},
month={Nov},}
@INPROCEEDINGS{9414421,
author={White, Teresa and Wheeler, Jesse and Lindstrom, Colton and Christensen, Randall and Moon, Kevin R.},
booktitle={ICASSP 2021 - 2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, title={Gps-Denied Navigation Using Sar Images And Neural Networks},
year={2021},
volume={},
number={},
pages={2395-2399},
abstract={Unmanned aerial vehicles (UAV) often rely on GPS for navigation. GPS signals, however, are very low in power and easily jammed or otherwise disrupted. This paper presents a method for determining the navigation errors present at the beginning of a GPS-denied period utilizing data from a synthetic aperture radar (SAR) system. This is accomplished by comparing an online-generated SAR image with a reference image obtained a priori. The distortions relative to the reference image are learned and exploited with a convolutional neural network to recover the initial navigational errors, which can be used to recover the true flight trajectory throughout the synthetic aperture. The proposed neural network approach is able to learn to predict the initial errors on both simulated and real SAR image data.},
keywords={Acoustic distortion;Sensitivity;Navigation;Neural networks;Training data;Apertures;Radar polarimetry;SAR images;CNNs;GPS-denied navigation},
doi={10.1109/ICASSP39728.2021.9414421},
ISSN={2379-190X},
month={June},}
@INPROCEEDINGS{7963344,
author={Stebler, S. and Campobasso, M. and Kidambi, K. and MacKunis, W. and Reyhanoglu, M.},
booktitle={2017 American Control Conference (ACC)}, title={Dynamic neural network-based sliding mode estimation of quadrotor systems},
year={2017},
volume={},
number={},
pages={2600-2605},
abstract={A dynamic neural network (DNN)-based observer design is presented, which amalgamates an adaptive neural network-based technique with a sliding mode estimation method. The proposed observer design is motivated by practical quadrotor tracking control applications, where direct sensor measurements of translational and rotational rates are not available for feedback. While sliding mode estimation strategies are well established as an effective means to compensate for bounded disturbances and dynamic model uncertainty, the proposed observer design employs a feedforward adaptive DNN-based estimation term in addition to a robust, high-gain feedback sliding mode element. The use of the DNN-based term in the estimator design is motivated by the desire to improve transient performance and reduce steady state error. The DNN-based feedforward term could also offer the advantage of reducing the control effort that would be required when the proposed observer design is operating as part of a closed-loop control system. A Lyapuov-based stability analysis is utilized to prove that the proposed DNN-based observer achieves asymptotic estimation of the quadrotor altitude and attitude rates in the presence of model uncertainty and bounded disturbances (e.g., sensor noise). Numerical simulation results are also provided to demonstrate the improved performance that is achieved by incorporating the adaptive DNN in the observer.},
keywords={Observers;Uncertainty;Aerodynamics;Artificial neural networks;Trajectory tracking;Biological neural networks},
doi={10.23919/ACC.2017.7963344},
ISSN={2378-5861},
month={May},}
@INPROCEEDINGS{8540706,
author={Rezende, H. B. and Silva, M. F. and Santos, M. F. and Honório, L. M. and Silva, L. A. Z. and Vidal, V. F. and Ribeiro, J. M. S. and Cerqueira, A. S. and Pancoti, A. A. N. and Regina, B. A.},
booktitle={2018 22nd International Conference on System Theory, Control and Computing (ICSTCC)}, title={Signal Estimation for UAV Control Loop Identification Using Artificial Immune Systems},
year={2018},
volume={},
number={},
pages={579-584},
abstract={The paper aims to estimate a signal that best provides the identification of a quadrotor type Unmanned Aerial Vehicle angular control loop using a bioinspired metaheuristic Artificial Immune System algorithm. The angular control loop was approximated by a second-order system using the Recursive Least Square method. The results were satisfactory, presenting, in general, a rich enough signal to provide a correct estimation of the system.},
keywords={Artificial intelligence;Mathematical model;Immune system;Estimation;Machine learning algorithms;Heuristic algorithms;Unmanned aerial vehicles;Artificial Immune System;optimization;quadrotors;recursive Least Square Method},
doi={10.1109/ICSTCC.2018.8540706},
ISSN={2372-1618},
month={Oct},}
@INPROCEEDINGS{9456213,
author={Kadam, Sujay and Seshapalli, Geeta and Nayak, Abhilash and Shaikh, Bushra A.},
booktitle={2021 2nd International Conference for Emerging Technology (INCET)}, title={Autonomous Drone for Social Distancing Surveillance.},
year={2021},
volume={},
number={},
pages={1-5},
abstract={Drones being capable of doing things that are not even remotely possible for a human have a major role to play in our society. These unmanned aerial vehicles have endless applications in various fields such as photography, surveillance, farming and communication systems. These drones due to such extraordinary capabilities pose a serious threat to privacy of the general population. However in desperate situations privacy is overtaken by safety and security in terms of priority. In this project the application of unmanned aerial vehicles in the surveillance field are explored while walking the thin line between invasion of privacy and safety concerns. An autonomous drone with a camera module with an intelligent scene analysis model is used to automate the surveillance of vast areas in a single go while keeping maintenance cheap and operability easy. The primary focus would be to surveil the overall population for honouring the “social distancing protocols” and then based on the results, a tool with a wider application in human behaviour analysis is to be developed.},
keywords={Privacy;Analytical models;Surveillance;Sociology;Human factors;Social factors;Safety;autonomous drone;deep learning;scene recognition;ground station;unmanned aerial vehicle;regularized deep learning architecture;object detection;social distancing},
doi={10.1109/INCET51464.2021.9456213},
ISSN={},
month={May},}
@INPROCEEDINGS{8689249,
author={Liu, Xuanlin and Chen, Mingzhe and Yin, Changchuan},
booktitle={2018 IEEE International Conference on Communication Systems (ICCS)}, title={Optimized Trajectory Design in UAV Based Cellular Networks: A Double Q-Learning Approach},
year={2018},
volume={},
number={},
pages={13-18},
abstract={In this paper, the problem of trajectory design of unmanned aerial vehicles (UAVs) for maximizing the number of satisfied users is studied in a UAV based cellular network. In this network, the UAV works as a flying base station that serves users, and the user indicates its satisfaction in terms of completion of its data request within an allowable maximum waiting time. The trajectory design is formulated as an optimization problem whose goal is to maximize the number of satisfied users. To solve this problem, a machine learning framework based on double Q-learning algorithm is proposed. The algorithm enables the UAV to find the optimal trajectory that maximizes the number of satisfied users. Compared to the traditional learning algorithms, such as Q-learning that selects and evaluates the action using the same Q-table, the proposed algorithm can decouple the selection from the evaluation, therefore avoid overestimation which leads to sub-optimal policies. Simulation results show that the proposed algorithm can achieve up to 19.4% and 6.7% gains in terms of the number of satisfied users compared to random algorithm and Q-learning algorithm.},
keywords={},
doi={10.1109/ICCS.2018.8689249},
ISSN={},
month={Dec},}
@INPROCEEDINGS{8266232,
author={Zeghlache, Samir and Bouguerra, Abderrahmen},
booktitle={2017 10th International Conference on Electrical and Electronics Engineering (ELECO)}, title={Sliding mode control based on interval type-2 fuzzy-neural network controller for an UAV},
year={2017},
volume={},
number={},
pages={780-783},
abstract={In this paper, a robust controller for a Six Degrees of Freedom (6 DOF) quadrotor helicopter control is proposed. Neural Networks (NN), Interval Type-2 Fuzzy Logic Control approach (IT2FLC) and Sliding Mode Control (SMC) technique are used to design a controller, named Neural Network Interval Type-2 Fuzzy Sliding Mode Controller (NNIT2FSMC), for each subsystem of the quadrotor helicopter. The proposed control scheme allows avoiding difficult modeling, attenuating the chattering effect of the SMC, reducing the rules number of the fuzzy controller, guaranteeing the stability and the robustness of the system. The simulation results show that the NNIT2FSMC can greatly alle-viate the chattering effect and is sufficiently robust with respect to the external disturbances.},
keywords={Sliding mode control;Simulation},
doi={},
ISSN={},
month={Nov},}
@INPROCEEDINGS{9025436,
author={Kyrkou, Christos and Theocharides, Theocharis},
booktitle={2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)}, title={Deep-Learning-Based Aerial Image Classification for Emergency Response Applications Using Unmanned Aerial Vehicles},
year={2019},
volume={},
number={},
pages={517-525},
abstract={Unmanned Aerial Vehicles (UAVs), equipped with camera sensors can facilitate enhanced situational awareness for many emergency response and disaster management applications since they are capable of operating in remote and difficult to access areas. In addition, by utilizing an embedded platform and deep learning UAVs can autonomously monitor a disaster stricken area, analyze the image in real-time and alert in the presence of various calamities such as collapsed buildings, flood, or fire in order to faster mitigate their effects on the environment and on human population. To this end, this paper focuses on the automated aerial scene classification of disaster events from on-board a UAV. Specifically, a dedicated Aerial Image Database for Emergency Response (AIDER) applications is introduced and a comparative analysis of existing approaches is performed. Through this analysis a lightweight convolutional neural network (CNN) architecture is developed, capable of running efficiently on an embedded platform achieving ~3x higher performance compared to existing models with minimal memory requirements with less than 2% accuracy drop compared to the state-of-the-art. These preliminary results provide a solid basis for further experimentation towards real-time aerial image classification for emergency response applications using UAVs.},
keywords={},
doi={10.1109/CVPRW.2019.00077},
ISSN={2160-7516},
month={June},}
@INPROCEEDINGS{9295894,
author={Zeng, Xiaoli and Liu, Yichuan},
booktitle={2020 IEEE 20th International Conference on Communication Technology (ICCT)}, title={A Multiple Representation Network with Adversarial Regularization for Automatic Modulation Recognition},
year={2020},
volume={},
number={},
pages={213-217},
abstract={In this paper, we proposed a multiple representation network with adversarial regularization (MRN_AR) for automatic modulation recognition. For multiple representation module, the MRN_AR can extract features with different scales to improve recognition accuracy by utilizing convolutional neural networks. Moreover, the adversarial regularization was employed for improving generalization of the network. The adversarial regularization was conducted by virtual adversarial training, which can promote the robustness of the model for conditional label distribution by local disturbance. Experiments on unmanned aerial vehicle communication signal datasets demonstrates the effectiveness of the proposed method.},
keywords={Modulation;Feature extraction;Convolution;Training;Kernel;Neural networks;Convolutional neural networks;automatic modulation recognition;convolutional neural networks;multiple representation;adversarial regularization},
doi={10.1109/ICCT50939.2020.9295894},
ISSN={2576-7828},
month={Oct},}
@ARTICLE{9057581,
author={Li, Peng and Han, Lirong and Tao, Xuanwen and Zhang, Xiaoyu and Grecos, Christos and Plaza, Antonio and Ren, Peng},
journal={IEEE Transactions on Geoscience and Remote Sensing}, title={Hashing Nets for Hashing: A Quantized Deep Learning to Hash Framework for Remote Sensing Image Retrieval},
year={2020},
volume={58},
number={10},
pages={7331-7345},
abstract={Fast and accurate remote sensing image retrieval from large data archives has been an important research topic in the remote sensing research literature. Recently, hashing-based remote sensing image retrieval has attracted extreme attention because of its efficient search capabilities. Especially, deep remote sensing image hashing algorithms have been developed based on convolutional neural networks (CNNs) and have shown effective retrieval performance. However, implementing a deep hashing network tends to be highly expensive in terms of storage space and computing resources to be suitable for on-orbit remote sensing image retrieval, which usually operates on resource-limited devices such as satellites and unmanned aerial vehicles (UAVs). To address this limitation, we propose to hash a deep network that in turn hashes remote sensing images. Specifically, we develop a quantized deep learning to hash (QDLH) framework for large-scale remote sensing image retrieval. The weights and activation functions in the QDLH framework are binarized to low-bit representations, which require comparatively much less storage space and computing resources. The QDLH results in a lightweight deep neural network for effective remote sensing image hashing. We conduct extensive experiments on two public remote sensing image data sets by incorporating several state-of-the-art network architectures into our QDLH methodology for remote sensing image hashing. The experimental results demonstrate that the proposed QDLH is effective in saving hardware resources in terms of both storage and computation. Moreover, superior remote sensing image retrieval performance is also achieved by our QDLH, compared with state-of-the-art deep remote sensing image hashing methods.},
keywords={Remote sensing;Image retrieval;Task analysis;Neurons;Satellites;Machine learning;Computational modeling;Class intensive;deep hashing;quantized deep network;remote sensing images retrieval},
doi={10.1109/TGRS.2020.2981997},
ISSN={1558-0644},
month={Oct},}
@INPROCEEDINGS{8593539,
author={Haksar, Ravi N. and Schwager, Mac},
booktitle={2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)}, title={Distributed Deep Reinforcement Learning for Fighting Forest Fires with a Network of Aerial Robots},
year={2018},
volume={},
number={},
pages={1067-1074},
abstract={This paper proposes a distributed deep reinforcement learning (RL) based strategy for a team of Unmanned Aerial Vehicles (UAVs) to autonomously fight forest fires. We first model the forest fire as a Markov decision process (MDP) with a factored structure. We consider optimally controlling the forest fire without agents using dynamic programming, and show any exact solution and many approximate solutions are computationally intractable. Given the problem complexity, we consider a deep RL approach in which each agent learns a policy requiring only local information. We show with Monte Carlo simulations that the deep RL policy outperforms a hand-tuned heuristic, and scales well for various forest sizes and different numbers of UAVs as well as variations in model parameters. Experimental demonstrations with mobile robots fighting a simulated forest fire in the Robotarium at the Georgia Institute of Technology are also presented.},
keywords={Vegetation;Forestry;Sensors;Retardants;Monitoring;Lattices;Unmanned aerial vehicles},
doi={10.1109/IROS.2018.8593539},
ISSN={2153-0866},
month={Oct},}
@INPROCEEDINGS{5452054,
author={Li Xiaoli and Liu Chao and Ding Wenrui and Wang Lei},
booktitle={2010 The 2nd International Conference on Computer and Automation Engineering (ICCAE)}, title={Software dependability evaluation based on quality characteristics},
year={2010},
volume={3},
number={},
pages={113-117},
abstract={In the reference of ISO/IEC 9126 software quality model, this article establishes a comprehensive evaluation system of the software dependability. At the same time, it uses the concept of entropy to combine subjective weights and the entropy of objective weights to determine the weight values of measurements in the evaluation system. On this basis, take advantage of the trapezoidal-semi-trapezoidal which is used to depict the degree of membership in the fuzzy mathematics to divide software dependability and put forward a detailed dependability evaluation process and method based on fuzzy mathematics evaluation. Preliminary experimental results show that software dependability evaluation system based on fuzzy mathematics theory is convenient and practical. The factor weights determined by an objective entropy values and the expert's subjective weights combine the subjective and objective factors. The results of evaluation is objective, rational and more effective to reflect the current level of dependability. It lays the groundwork to the study of software dependability evaluation.},
keywords={Software quality;Entropy;Mathematics;National security;Software reliability;Information security;Neural networks;Support vector machines;Software systems;Chaos;dependability;fuzzy mathematics theory;a comprehensive evaluation;entropy value method},
doi={10.1109/ICCAE.2010.5452054},
ISSN={},
month={Feb},}
@INPROCEEDINGS{8430428,
author={Yousefi, Parsa and Fekriazgomi, Hamid and Demir, Mevlut A. and Prevost, John J. and Jamshidi, Mo},
booktitle={2018 World Automation Congress (WAC)}, title={Data-Driven Fault Detection of Un-Manned Aerial Vehicles Using Supervised Learning Over Cloud Networks},
year={2018},
volume={},
number={},
pages={1-6},
abstract={Modern applications of Unmanned Aerial Vehicles are increasingly attracting the attention of traditional safety and reliability fields. There exist many standard approaches for determining UAV fault detection. However, there doesn't exist a method that is not only model independent but also has the ability to detect faults which have not been predefined for the UAV system. In this research we present two supervised machine learning algorithms implementing Logistic Regression and Linear Discriminant Analysis of Algorithms, respectively, to predict UAV faults. The data which has been used for these approaches comes from discrete-sampled, de-noised analog signals based on the voltage and current inputs belonging to four actuators of the UAV drones. In addition, we demonstrate that by using a five-fold cross validation process to generate different types of training and test datasets, the optimized model can be selected. We verify our results through an analysis describing the accuracies of our proposed model.},
keywords={Fault detection;Training;Mathematical model;Data models;Logistics;Drones;Un-manned Aerial Vehicles;Signal-based Fault Detection;Machine Learning;Supervised Learning;Data Prediction;Linear Discriminant Analysis;Logistic Regression},
doi={10.23919/WAC.2018.8430428},
ISSN={},
month={June},}
@INPROCEEDINGS{9638741,
author={Jabeur, Chiraz Ben and Seddik, Hassene},
booktitle={2021 International Conference on Control, Automation and Diagnosis (ICCAD)}, title={Design and Implementation of PD-NN Controller optimized Neural Networks for a quad-rotor},
year={2021},
volume={},
number={},
pages={1-7},
abstract={In this paper a full approach of modeling and control of a four rotor unmanned air vehicle (UAV) known as quad-rotor aircraft is presented. In fact, a PD and a PD optimized Neural Networks Approaches (PD-NN) are developed to be applied to control a quad-rotor. The goal of this work is to concept a smart Self-Tuning PD controller based on neural networks able to supervise the quad-rotor for an optimized behavior while tracking a desired trajectory. Many challenges could arise if the quad-rotor is navigating in hostile environments presenting irregular disturbances in the form of wind added to the model on each axis. Thus, the quad-rotor is subject to three dimensional unknown static/varying wind disturbances. The quad-rotor has to quickly perform tasks while ensuring stability and accuracy and must behave rapidly with regards to decision making facing disturbances. This technique offers some advantages over conventional control methods such as PD controller. Simulation results are obtained with the use of Matlab/Simulink environment and are founded on a comparative study between PD and PD-NN controllers based on wind disturbances. These later are applied with several degrees of strength to test the quad-rotor behavior. These simulation results are satisfactory and have demonstrated the effectiveness of the proposed PD-NN approach. In fact, this controller has relatively smaller errors than the PD controller and has a better capability to reject disturbances. In addition, it has proven to be highly robust and efficient facing turbulences in the form of wind disturbances.},
keywords={Trajectory tracking;Navigation;Simulation;Neural networks;Rotors;Stability analysis;Trajectory;PD and PID controllers;neural networks;hostile environment;quad-rotor control;dynamic model;trajectory tracking control;robustness against disturbance},
doi={10.1109/ICCAD52417.2021.9638741},
ISSN={2767-9896},
month={Nov},}
@INPROCEEDINGS{8798096,
author={James, Jasmin and Ford, Jason J. and Molloy, Timothy L.},
booktitle={2019 International Conference on Unmanned Aircraft Systems (ICUAS)}, title={Below Horizon Aircraft Detection Using Deep Learning for Vision-Based Sense and Avoid},
year={2019},
volume={},
number={},
pages={965-970},
abstract={The commercial operation of unmanned aerial vehicles (UAVs) would benefit from an onboard capability to sense and avoid (SAA) potential mid-air collision threats in the same manner expected from a human pilot. In this paper we present a new approach for detection of aircraft below the horizon. We address some of the challenges faced by existing vision-based SAA methods such as detecting stationary aircraft (that have no relative motion to the background), rejecting moving ground vehicles, and simultaneous detection of multiple aircraft. We propose a multi-stage vision-based aircraft detection system which utilises deep learning to produce candidate aircraft that we track over time. We evaluate the performance of our proposed system on real flight data where we demonstrate detection ranges comparable to the state of the art with the additional capability of detecting stationary aircraft, rejecting moving ground vehicles, and tracking multiple aircraft.},
keywords={Aircraft;Land vehicles;Image sequences;Training;Cameras;Deep learning;Visualization},
doi={10.1109/ICUAS.2019.8798096},
ISSN={2575-7296},
month={June},}
@INPROCEEDINGS{9435549,
author={Fichtel, Lars and Frühwald, Alexander M. and Hösch, Leonhard and Schreibmann, Vitaliy and Bachmeir, Christian and Bohlander, Frank},
booktitle={2021 29th Conference of Open Innovations Association (FRUCT)}, title={Tree Localization and Monitoring on Autonomous Drones employing Deep Learning},
year={2021},
volume={},
number={},
pages={132-140},
abstract={Forest management relies on the analysis of satellite imagery and time intensive physical on-site inspections. Both methods are costly and time consuming. Satellite based images are often not updated in a sufficient frequency to react to infestations or other occurring problems. Forest management benefits greatly from accurate and recent information about the local forest areas. In order to react appropriately and in time to incidents such as areas damaged by storms, areas infested by bark beetles and decaying ground water level, this information can be extracted from high resolution imagery. In this work, we propose UAVs to meet this demand and demonstrate that they are fully capable of gathering this information in a cost efficient way. Our work focuses on the cartography of trees to optimize forest-operation. We apply deep learning for image processing as a method to identify and isolate individual trees for GPS tagging and add some additional information such as height and diameter.},
keywords={Deep learning;Technological innovation;Satellites;Three-dimensional displays;Vegetation;Forestry;Tagging},
doi={10.23919/FRUCT52173.2021.9435549},
ISSN={2305-7254},
month={May},}
@INPROCEEDINGS{8460392,
author={Kharchenko, Volodymyr and Chyrka, Iurii},
booktitle={2018 IEEE 17th International Conference on Mathematical Methods in Electromagnetic Theory (MMET)}, title={Detection of Airplanes on the Ground Using YOLO Neural Network},
year={2018},
volume={},
number={},
pages={294-297},
abstract={The presented paper benchmarks the performance of state-of-the-art methods of objects detection in the particular case of airplanes on the ground identification detection in aerial images taken from unmanned aerial vehicles or satellites. There were tested two popular single-stage neural networks YOLO v.3 and Tiny YOLO v.3 based on the “You Only Look Once” approach. The considered artificial neural network architectures for objects detection has been trained and applied over the specifically created image database. Experimental verification proves their high detection ability, location precision and realtime processing speed using modern graphics processing unit. That approach can be easily applied for detection of many different classes of ground objects.},
keywords={Airplanes;Training;Neural networks;Unmanned aerial vehicles;Feature extraction;Graphics processing units;Detectors;Convolutional neural network;object detection;real-time processing;unmanned aerial vehicle},
doi={10.1109/MMET.2018.8460392},
ISSN={2161-1750},
month={July},}
@INPROCEEDINGS{8747253,
author={Pölönen, Ilkka and Annala, Leevi and Rahkonen, Samuli and Nevalainen, Olli and Honkavaara, Eija and Tuominen, Sakari and Viljanen, Niko and Hakala, Teemu},
booktitle={2018 9th Workshop on Hyperspectral Image and Signal Processing: Evolution in Remote Sensing (WHISPERS)}, title={Tree Species Identification Using 3D Spectral Data and 3D Convolutional Neural Network},
year={2018},
volume={},
number={},
pages={1-5},
abstract={In this study we apply 3D convolutional neural network (CNN) for tree species identification. Study includes the three most common Finnish tree species. Study uses a relatively large high-resolution spectral data set, which contains also a digital surface model for the trees. Data has been gathered using an unmanned aerial vehicle, a framing hyperspectral imager and a regular RGB camera. Achieved classification results are promising by with overall accuracy of 96.2 % for the classification of the validation data set.},
keywords={Vegetation;Three-dimensional displays;Training;Hyperspectral imaging;Convolutional neural networks;Forestry;Tree species;spectral imaging;3D;convolutional neural network;UAV},
doi={10.1109/WHISPERS.2018.8747253},
ISSN={2158-6276},
month={Sep.},}
@INPROCEEDINGS{9602743,
author={Guan, Tong and Zhang, Guobing and Chen, Pengyun},
booktitle={2021 33rd Chinese Control and Decision Conference (CCDC)}, title={A terrain matching navigation algorithm for UAV},
year={2021},
volume={},
number={},
pages={5203-5207},
abstract={Terrain matching positioning navigation uses the traditional algorithm to linearize the terrain and compares with the datum terrain. It can provide more accurate positioning, but due to the strong nonlinear characteristics of terrain, in the process of terrain linearization, most of the terrain features are ignored. So the matching result error is relatively large. Because the pulse coupled neural network has the characteristics of neuron's characteristic of linear addition and nonlinear multiplication adjustment coupling, it does not need to establish an accurate mathematical model, and it can better deal with nonlinear problems. Therefore, this paper will explore the application of pulse coupled neural network in terrain matching positioning. Firstly, the distance difference matrix between the prior terrain data and the measured matching terrain is normalized, then the nodes on each matching surface of the topographic map will be searched and summed one by one through the coupling relationship between the similar nodes, and the magnitude of ignition times represents the similarity degree. By selecting different regions and different parameters in the topographic map for simulation, the high-precision performance of the algorithm is verified.},
keywords={Couplings;Navigation;Ignition;Mathematical models;Surface topography;Biological neural networks;PCNN;Nonlinear;Terrain matching;Coupling},
doi={10.1109/CCDC52312.2021.9602743},
ISSN={1948-9447},
month={May},}
@INPROCEEDINGS{8012010,
author={Jiewan Zheng and Xianbin Cao},
booktitle={2017 Integrated Communications, Navigation and Surveillance Conference (ICNS)}, title={Bi-heterogeneous convolutional neural network for UAV-based dynamic scene classification},
year={2017},
volume={},
number={},
pages={1-28},
abstract={This article consists only of a collection of slides from the author's conference presentation.},
keywords={Vehicle dynamics;Aerodynamics;Surveillance;Unmanned aerial vehicles;Neural networks;Navigation;Videos},
doi={10.1109/ICNSURV.2017.8012010},
ISSN={},
month={April},}
@INPROCEEDINGS{8096070,
author={Chen, Jin and Wang, Yi and Chen, Zehan and Zou, Yuexian},
booktitle={2017 22nd International Conference on Digital Signal Processing (DSP)}, title={Sequence-guided siamese neural network for video summarization of unmanned aerial vehicles},
year={2017},
volume={},
number={},
pages={1-5},
abstract={Video summarization (VS) is one of key video signal processing techniques for unmanned aerial vehicles (UAVs). Essentially VS aims at eliminating redundant frames in aerial videos (AVs) with high similarity, which is helpful for quick browsing, retrieving and efficient storage without losing important information. For VS technique, how to measure the similarity between video frames is not a trivial work since VS for different video applications asks for different criteria. Besides, it is noted that aerial video frames of UAVs nearly only have gradual changes other than sudden changes between frames. In this paper, to capture the subtle variations between UAV frames, a sequence-guided Siamese neural network (SGSNN) approach is developed to extract the semantic features. Specifically, the sequential correlations have been incorporated into the learning objective of the proposed SGSNN, which is implemented by a logarithmic based semantic distance metric designed to automatically label the similarity between frames. For gradual transition shot segmentation in AVs, a co-voting method is presented to decide the membership of the input frame belongs to. Extensive experiments on the self-made UAV video datasets validate the effectiveness of our method.},
keywords={Feature extraction;Semantics;Neural networks;Training;Unmanned aerial vehicles;Correlation;Image segmentation;video summarization;unmanned aerial vehicles;aerial videos;Siamese neural networks;sequence-guided;co-voting},
doi={10.1109/ICDSP.2017.8096070},
ISSN={2165-3577},
month={Aug},}
@ARTICLE{8732335,
author={Bi, Fukun and Lei, Mingyang and Wang, Yanping and Huang, Dan},
journal={IEEE Access}, title={Remote Sensing Target Tracking in UAV Aerial Video Based on Saliency Enhanced MDnet},
year={2019},
volume={7},
number={},
pages={76731-76740},
abstract={Remote sensing target tracking in the aerial video from unmanned aerial vehicles (UAV) plays a key role in public security. As the UAV aerial video has rapid changes in scale and perspective, few pixels in the target region, and multiple similar disruptors, and the main tracking methods in this research field generally have relatively low tracking performance and timeliness, we propose a remote sensing target tracking method for the UAV aerial video based on a saliency enhanced multi-domain convolutional neural network (SEMD). First, in the pre-training stage, we combine the least squares generative adversarial networks (LSGANs) with a multi-orientation Gaussian Pyramid to augment typical easily confused negative samples for enhancing the capacity to distinguish between targets and the background. Then, a saliency module was integrated into our tracking network architecture to boost the saliency of the feature map, which can improve the representation power of a rapid dynamic change target. Finally, in the stage for generating tracking samples, we implemented a local weight allocation model to screen for hard negative samples. This approach can not only improve the stability in tracking but also boost efficiency. The comprehensive evaluations of public and homemade hard datasets demonstrate that the proposed method can achieve high accuracy and efficiency results compared with state-of-the-art methods.},
keywords={Target tracking;Remote sensing;Unmanned aerial vehicles;Resource management;Visualization;Convolution;Convolutional neural networks;Visual tracking;multi-domain learning;saliency enhanced;sample augmentation},
doi={10.1109/ACCESS.2019.2921315},
ISSN={2169-3536},
month={},}
@INPROCEEDINGS{9444035,
author={Liu, Yanjuan and Kong, Yingying and Zhang, Bowen and Peng, Xiangyang and Leung, Henry},
booktitle={2020 4th International Conference on Imaging, Signal Processing and Communications (ICISPC)}, title={A Novel Deep Transfer Learning Method for Airborne Remote Sensing Semantic Segmentation Based on Fully Convolutional Network},
year={2020},
volume={},
number={},
pages={13-19},
abstract={Semantic segmentation for airborne remote sensing images is a critical process in the workflow of object-based image analysis. The success of deep neural networks for semantic segmentation heavily rely on large-scale and well-labeled datasets, which are hard to collect in practice. In this paper, we consider transfer learning for semantic segmentation that can address the cross-domain learning problem by extracting useful information from data of related domain and transferring them to target domain. Considering the high similarity between Unmanned Aerial Vehicles (UAV) images and airborne remote sensing images, we propose a deep novel transfer learning method, which transfers a semantically segment model used UAV images to airborne remote sensing images. The experimental results show that the method proposed achieves higher Global Accuracy (GA) with less running time compared other transfer algorithm.},
keywords={Image segmentation;Convolution;Atmospheric modeling;Transfer learning;Semantics;Neural networks;Signal processing algorithms;semantic segmentation;airborne remote sensing images;transfer learning;UAV images},
doi={10.1109/ICISPC51671.2020.00010},
ISSN={},
month={Oct},}
@INPROCEEDINGS{9653589,
author={Zhang, Zhihong and Gong, Huajun and Wang, Xinhua and Feng, Yadong and Xu, Minjie},
booktitle={2021 International Conference on Intelligent Computing, Automation and Applications (ICAA)}, title={An Improved Yolov3 Object Detection Algorithm for UAV Aerial Images},
year={2021},
volume={},
number={},
pages={542-550},
abstract={Aiming at the problem that YOLOV3 is not ideal for aerial target detection, an improved target detection algorithm based on YOLOV3 is proposed. Firstly, improve the feature extraction network Darknet53,ResNext residuals module was used to replace the ResNet residuals module to optimize the convolutional network structure. The detection scale was expanded from 3 to 4, SSP structure and DIOU loss function were introduced to improve the positioning accuracy. Without affecting the detection speed, the improved YOLOV3 algorithm can effectively improve the detection accuracy of small target objects in the aerial perspective and reduce the rate of missed detection. Verifying on the Visdrone data set, the improved YOLOV3 algorithm is superior to YOLOV3 in detection accuracy and better robustness. Experimental results show that the average accuracy of the improved algorithm proposed in this paper reaches 93.45% on the data set, and the mean average precision (mAP) is 2.81% higher than that of the original YOLOV3 algorithm.},
keywords={Photography;Automation;Object detection;Autonomous aerial vehicles;Feature extraction;Robustness;Residual neural networks;n/a},
doi={10.1109/ICAA53760.2021.00100},
ISSN={},
month={June},}
@INPROCEEDINGS{9626844,
author={Marcos, Juliana T.C. and Utete, Simukai W.},
booktitle={2021 IEEE 24th International Conference on Information Fusion (FUSION)}, title={Animal Tracking within a Formation of Drones},
year={2021},
volume={},
number={},
pages={1-8},
abstract={In this study, we develop a distributed system that can be used by unmanned aerial vehicles (UAVs) or drones for single-animal tracking in terrestrial settings. The system involves a video object tracking (VOT) solution and a drone formation. The proposed VOT solution is based on the particle filter (PF) with two measurement providers: a colour image segmentation (CIS) approach and a machine learning (ML) technique. They are switched based on the structural similarity (SSIM) index between the initial and the current target appearances to mitigate the limitation of computational resources of civilian drones, and to ensure good tracking performance. At first, the deep learning object detector You Only Look Once version three (YOLOv3) is used as the second measurement provider. The proposed VOT solution has been tested on wildlife footage recorded by drones (and obtained from an animal behaviour group). The tests demonstrate amongst other results that the proposed VOT solution is more efficient when YOLOv3 is replaced by other methods such as boosting and channel and spatial reliability tracking (CSRT). The results suggest the utility of the proposed VOT solution in single-animal tracking with cooperative drones for wildlife preservation.},
keywords={Target tracking;Current measurement;Wildlife;Switches;Particle measurements;Information filters;Particle filters;Animal tracking;Boosting;channel and spatial reliability tracking (CSRT);drone;multiple instance learning (MIL);particle filter;structural similarity (SSIM) index;unmanned aerial vehicle (UAV);You Only Look Once version 3 (YOLOv3)},
doi={},
ISSN={},
month={Nov},}
@INPROCEEDINGS{9571027,
author={Patrona, Fotini and Mademlis, Ioannis and Pitas, Ioannis},
booktitle={2021 Aerial Robotic Systems Physically Interacting with the Environment (AIRPHARO)}, title={An Overview of Hand Gesture Languages for Autonomous UAV Handling},
year={2021},
volume={},
number={},
pages={1-7},
abstract={Camera-equipped Unmanned Aerial Vehicles (UAVs, or drones) have revolutionized several application domains, with a steadily increasing degree of cognitive autonomy in commercial drones paving the way for unprecedented robotization of daily life. Dynamic cooperation of UAV s with human collaborators is typically necessary during a mission; a fact that has led to various solutions for high-level UAV-operator interaction. Hand gestures are an effective way of facilitating this remote drone handling, giving rise to new gesture languages for visual communication between operators and autonomous UAV s. This paper reviews all the available languages which could be used or have been created for this purpose, as well as relevant gesture recognition datasets for training machine learning models. Moreover, a novel, generic, base gesture language for handling camera-equipped UAV s is proposed, along with a corresponding, large-scale, publicly available video dataset. The presented language can easily and consistently be extended in the future to more specific scenarios/profiles, tailored for particular application domains and/or additional UAV equipment (e.g., aerial manipulators/arms). Finally, we evaluate: a) the performance of state-of-the-art gesture recognition algorithms on the proposed dataset, in a quantitative and objective manner, and b) the intuitiveness, effectiveness and completeness of the proposed gesture language, in a qualitative and subjective manner.},
keywords={Training;Visual communication;Gesture recognition;Machine learning;Task analysis;Vehicle dynamics;Robots;Human Robot Interaction;Autonomous Drones;Unmanned Aerial Vehicles;Hand Gesture Recognition;Gesture Datasets},
doi={10.1109/AIRPHARO52252.2021.9571027},
ISSN={},
month={Oct},}
@ARTICLE{9425543,
author={Chen, Weiyang and Wang, Haifeng and Li, Hao and Li, Quanjing and Yang, Yang and Yang, Kun},
journal={IEEE Geoscience and Remote Sensing Letters}, title={Real-Time Garbage Object Detection With Data Augmentation and Feature Fusion Using SUAV Low-Altitude Remote Sensing Images},
year={2022},
volume={19},
number={},
pages={1-5},
abstract={Recently, a number of nature reserves have been shut down because of serious pollution from tourist garbage. Garbage monitoring in high-altitude natural reserves using small unmanned aerial vehicle (SUAV) remote sensing is an important and urgent need for environmental protection. In order to help cleaners to eliminate garbage more conveniently and quickly, a novel approach is proposed to detect scattered garbage regions in real time using low-altitude remote sensing videos captured by SUAVs. First, the high-resolution, low-altitude, multitemporal remote sensing images and videos containing scattered garbage were collected through SUAV and then proposed a data augmentation method to expand the training samples. Second, the Yolov4 detection network was used to classify the scattered garbage regions. Finally, the location of the object was roughly calculated according to the altitude, flight direction, global positioning system, and digital elevation model (DEM). Then, the garbage object was marked on the video, while the object location was marked on the map. Experimental results show that the proposed method achieves a mean accuracy of 91.34% and provides better performances on the real data set compared with state-of-the-art methods.},
keywords={Remote sensing;Videos;Object detection;Training;Real-time systems;Feature extraction;Deep learning;Low-altitude remote sensing of small unmanned aerial vehicle (SUAV);real-time object detection},
doi={10.1109/LGRS.2021.3074415},
ISSN={1558-0571},
month={},}
@ARTICLE{9099485,
author={Long, Nathan K. and Sammut, Karl and Sgarioto, Daniel and Garratt, Matthew and Abbass, Hussein A.},
journal={IEEE Transactions on Emerging Topics in Computational Intelligence}, title={A Comprehensive Review of Shepherding as a Bio-Inspired Swarm-Robotics Guidance Approach},
year={2020},
volume={4},
number={4},
pages={523-537},
abstract={The simultaneous control of multiple coordinated robotic agents represents an elaborate problem. If solved, however, the interaction between the agents can lead to solutions to sophisticated problems. The concept of swarming, inspired by nature, can be described as the emergence of complex system-level behaviors from the interactions of relatively elementary agents. Due to the effectiveness of solutions found in nature, bio-inspired swarming-based control techniques are receiving a lot of attention in robotics. One method, known as swarm shepherding, is founded on the sheep herding behavior exhibited by sheepdogs, where a swarm of relatively simple agents are governed by a shepherd (or shepherds) which is responsible for high-level guidance and planning. Many studies have been conducted on shepherding as a control technique, ranging from the replication of sheep herding via simulation, to the control of uninhabited vehicles and robots for a variety of applications. A comprehensive review of the literature on swarm shepherding is presented in order to reveal the advantages and potential of the approach to be applied to a plethora of robotic systems in the future.},
keywords={Dogs;Robot kinematics;Australia;Logic gates;Vehicle dynamics;Autonomous vehicles;herding;shepherding;swarm guidance;swarm intelligence;swarm robotics;uninhabited aerial vehicle (UAV)},
doi={10.1109/TETCI.2020.2992778},
ISSN={2471-285X},
month={Aug},}
@INPROCEEDINGS{9641171,
author={Han, Shuo and Ke, Liangjun and Wang, Zhigang},
booktitle={2021 IEEE International Conference on Unmanned Systems (ICUS)}, title={Multi-Agent Confrontation Game Based on Multi-Agent Reinforcement Learning},
year={2021},
volume={},
number={},
pages={157-162},
abstract={This paper studies the multi-agent confrontation game problem, and takes unmanned aerial vehicle (UAV) offense-defense confrontation as the research object. Deep Deterministic Policy Gradient (DDPG) and Multi-Agent Deep Deterministic Policy Gradient (MADDPG) algorithm are used for policy optimization. The experimental results show that MADDPG can acquire good policy in multi-agent confrontation game environment. In order to make MADDPG suitable for large-scale multi-agent game problems and obtain robust policy, this paper improves MADDPG by introducing Mean Field Theory (MFT) and ‘Minimax’ idea. The experimental results show that the improved algorithms can deal with large-scale multi-agent game problem and obtain robust policy.},
keywords={Training;Degradation;Conferences;Games;Reinforcement learning;Autonomous aerial vehicles;Robustness;multi-agent confrontation game;policy gradient;mean field theory;minimax},
doi={10.1109/ICUS52573.2021.9641171},
ISSN={},
month={Oct},}
@INPROCEEDINGS{7744141,
author={Pedro, Jimoh O. and Dangor, Muhammed and Kala, Praneet J.},
booktitle={2016 IEEE Congress on Evolutionary Computation (CEC)}, title={Differential evolution-based PID control of a quadrotor system for hovering application},
year={2016},
volume={},
number={},
pages={2791-2798},
abstract={This paper proposes the design of a PID controller for the position and attitude stabilization of a quadrotor unmanned aerial vehicle (UAV) using the differential-evolution (DE) optimization algorithm. The complexities of this underactuated system require tedious manual tuning for various flight configurations and DE offers a quick alternative to this time consuming and rigorous approach. A performance index is defined around stabilizing the attitude whilst reaching the desired altitude in the quickest possible time with minimal power consumption from the actuator. The proposed tuning method improved the performance index by 40% over a range of 100 iterations. The optimized system stabilized its attitude considerably quicker than its counterparts, whilst altitude response achieved a faster rise time with a marginally better settling time. The power consumption was minimized for the DE case as well. The performance of the DE-based PID controller is superior on a holistic level. This highlights the fact that the DE optimization algorithm is an effective tool for tuning the PID controllers' gains.},
keywords={Tuning;PD control;PI control;Manuals;Rotors;Robustness;Neural networks},
doi={10.1109/CEC.2016.7744141},
ISSN={},
month={July},}
@INPROCEEDINGS{8168502,
author={Suprapto, Bhakti Yudho and Mustaqim, Amsa and Wahab, Wahidin and Kusumoputro, Benyamin},
booktitle={2017 15th International Conference on Quality in Research (QiR) : International Symposium on Electrical and Computer Engineering}, title={Modified elman recurrent neural network for attitude and altitude control of heavy-lift hexacopter},
year={2017},
volume={},
number={},
pages={309-314},
abstract={Hexacopter is a member of rotor-wing Unmanned Aerial Vehicle (UAV) which has 6 six rotors with fixed pitch blades and nonlinear characteristics that cause controlling the attitude of hexacopter is difficult. In this paper, Modified Elman Recurrent Neural Network (MERNN) is used to control attitude and altitude of Heavy-lift Hexacopter to get better performance than Elman Recurrent Neural Network (ERNN). This Modified Elman Recurrent Neural Network has a self-feedback which provides a dynamic trace of the gradients in the parameter space. In the self-feedback, the gain coefficients are trained as connection weight. This connection weight could enhance the adaptability of Elman Recurrent Neural Network to the time-varying system. The flight data are taken from a real flight experiment. Results show that the Modified Elman Recurrent Neural Network can increase performance with small error and generate a better response than Elman Recurrent Neural Network.},
keywords={Recurrent neural networks;Training;Ink;Rotors;Neurons;Mathematical model;System identification;Direct Inverse Control;Elman Recurrent Neural Network;Heavy-lift Hexacopter;Modified Elman Recurrent Neural Network},
doi={10.1109/QIR.2017.8168502},
ISSN={},
month={July},}
@INPROCEEDINGS{9554481,
author={Talreja, Pratyush and Durbha, Surya S and Shinde, Rajat C. and Potnis, Abhishek V.},
booktitle={2021 IEEE International Geoscience and Remote Sensing Symposium IGARSS}, title={Real-Time Embedded HPC Based Earthquake Damage Mapping Using 3D LiDAR Point Clouds},
year={2021},
volume={},
number={},
pages={8241-8244},
abstract={In the early hours following the earthquake, supporting humanitarian actions like rescue operations and relief distribution is the primary objective of the rescue managers. The damage mapping can be performed using reliable data that can be obtained from high-resolution satellite imagery but obtaining satellite imagery can be challenging for some days post disaster due to revisit time. Considering the disaster response timing, Unmanned Aerial Vehicles (UAV) are used because ground transportation systems are ineffective due to road blockage. In this work, we make use of Light Detection and Ranging (LiDAR) 3D point cloud data obtained for Haiti Earthquake. The focus of our work is to develop and implement an approach for LiDAR data classification to enable Earthquake damage mapping and detection. This is obtained by running our deep learning network on NVIDIA Jetson Nano embedded supercomputing platform. This approach takes the advantage of embedded High-Performance computing and low power consumption capabilities of Jetson Nano which enhances the classification and promotes rapid response which is the key to manage post-disaster activities. Jetson Nano is a feasible option which provides a GPU architecture that is optimized for running energy-aware deep learning models and which generates the results in real or near-real time. We envisage that our work could be extended to perform near real-time classification of LiDAR point clouds in a post earthquake scenario.},
keywords={Deep learning;Performance evaluation;Laser radar;Three-dimensional displays;Satellites;Power demand;Earthquakes;LiDAR;High Performance Computing;Deep Learning;Damage Mapping;Earthquake},
doi={10.1109/IGARSS47720.2021.9554481},
ISSN={2153-7003},
month={July},}
@ARTICLE{8715489,
author={Palossi, Daniele and Loquercio, Antonio and Conti, Francesco and Flamand, Eric and Scaramuzza, Davide and Benini, Luca},
journal={IEEE Internet of Things Journal}, title={A 64-mW DNN-Based Visual Navigation Engine for Autonomous Nano-Drones},
year={2019},
volume={6},
number={5},
pages={8357-8371},
abstract={Fully miniaturized robots (e.g., drones), with artificial intelligence (AI)-based visual navigation capabilities, are extremely challenging drivers of Internet-of-Things edge intelligence capabilities. Visual navigation based on AI approaches, such as deep neural networks (DNNs) are becoming pervasive for standard-size drones, but are considered out of reach for nano-drones with a size of a few cm2. In this paper, we present the first (to the best of our knowledge) demonstration of a navigation engine for autonomous nano-drones capable of closed-loop end-to-end DNN-based visual navigation. To achieve this goal we developed a complete methodology for parallel execution of complex DNNs directly on board resource-constrained milliwatt-scale nodes. Our system is based on GAP8, a novel parallel ultralow-power computing platform, and a 27-g commercial, open-source Crazyflie 2.0 nano-quadrotor. As part of our general methodology, we discuss the software mapping techniques that enable the DroNet state-of-the-art deep convolutional neural network to be fully executed aboard within a strict 6 frame-per-second real-time constraint with no compromise in terms of flight results, while all processing is done with only 64 mW on average. Our navigation engine is flexible and can be used to span a wide performance range: at its peak performance corner, it achieves 18 frames/s while still consuming on average just 3.5% of the power envelope of the deployed nano-aircraft. To share our key findings with the embedded and robotics communities and foster further developments in autonomous nano-unmanned aerial vehicles (UAVs), we publicly release all our code, datasets, and trained networks.},
keywords={Navigation;Internet of Things;Visualization;Engines;Drones;Robot sensing systems;Autonomous UAV;CNNs;end-to-end learning;nano-UAV;ultralow-power},
doi={10.1109/JIOT.2019.2917066},
ISSN={2327-4662},
month={Oct},}
@INPROCEEDINGS{9061508,
author={Saleh, Matasem and Jhanjhi, NZ and Abdullah, Azween and Fatima-tuz-Zahra},
booktitle={2020 22nd International Conference on Advanced Communication Technology (ICACT)}, title={Proposing a Privacy Protection Model in Case of Civilian Drone},
year={2020},
volume={},
number={},
pages={596-602},
abstract={Technology-based products are meant for improving the people's quality of life. Since drones or more precisely Unmanned Aerial Vehicle's UAVs were permitted to be used for civilian purposes and applications, many lucrative reasons such as low price, mobility and ease of deployment have captured the attention of commercial organizations. These reasons have motivated the commercial organizations to involve and adopt UAVs in their company's operational body structure which will be positively reflected on the services provided to their clients. UAVs have influential features that can be used to infringe on the privacy of individuals if they are deliberately misused, therefor the commercial organizations willingness and the precious services going to be offered to clients should not be at the cost of privacy. This research will present a privacy detection model to guarantee the success of UAV commercial adoption as well as securing the individual privacy. Proposed model will be implemented in near future to escort the privacy protection of civilian in case of commercial drone.},
keywords={Drones;Privacy;Receivers;Cameras;Radar tracking;Transmitters;UAV's;Privacy;Security;Machine Learning;Detection System},
doi={10.23919/ICACT48636.2020.9061508},
ISSN={1738-9445},
month={Feb},}
@INPROCEEDINGS{9524972,
author={Wang, Qi and Liu, Jianmin and Liu, Cunzhuang and Huang, Jianhui and He, Chentao and Xu, Yongjun},
booktitle={2021 IEEE 46th Conference on Local Computer Networks (LCN)}, title={MPRdeep: Multi-Objective Joint Optimal Node Positioning and Resource Allocation for FANETs with Deep Reinforcement learning},
year={2021},
volume={},
number={},
pages={315-318},
abstract={This paper addresses the problem of UAV positioning and resource allocation under dynamic network conditions and under instantaneous communication demands in FANETs. We propose MPRdeep, an adaptive, deep reinforcement learning (DRL) approach considering several QoS requirements concurrently. MPRdeep learns to optimize relay UAVs’ positions and forwarding probabilities to minimize reliability-achieving delay and reliability-achieving energy consumption. The key advantage is that MPRdeep is able to learn and dynamically adjust the node positioning and resource allocation according to ongoing network conditions. The results show that MPRdeep converges fast and has generalization ability that adapts well under dynamic network conditions and dynamic locations of users. Compared with baseline methods, MPRdeep shows superior performance in terms of lower reliability-achieving delay and lower reliability-achieving energy consumption via simulations and experiments.},
keywords={Energy consumption;Adaptation models;Computer network reliability;Simulation;Reinforcement learning;Quality of service;Delays;Relay positioning;Resource allocation;Deep Q-Learning Network (DQN);Multi-Objective Optimal;FANETs},
doi={10.1109/LCN52139.2021.9524972},
ISSN={0742-1303},
month={Oct},}
@INPROCEEDINGS{8436950,
author={Han, Hyunjun and Kang, Jusung and Raza, Muhammad Asif and Lee, Heung-No},
booktitle={2018 Tenth International Conference on Ubiquitous and Future Networks (ICUFN)}, title={Learning Through Adverse Event for Collision Avoidance: A Self-Learning Approach},
year={2018},
volume={},
number={},
pages={874-877},
abstract={We introduce a deep learning based collision avoidance based on learning events accompanied by an online, semi-supervised learning algorithm that allows the learning agent to gain experiences and learn by itself without any preacquired training dataset through online trial-and-error approach. Using distance sequences as inputs, two procedures are performed in the proposed algorithm; data gathering procedure and learning procedure. Simulation results show that our system can achieve minimum of 99.86% up to 99.99% accuracy in classifying collision event from all possible events, allowing autonomous agent to navigate within simulated environments without collision.},
keywords={Training;Machine learning;Navigation;Semisupervised learning;Autonomous agents;Data models;Data processing;collision avoidance;deep learning;autonomous navigation;semi-supervised learning;autonomous agent;UAV},
doi={10.1109/ICUFN.2018.8436950},
ISSN={2165-8536},
month={July},}
@INPROCEEDINGS{5716956,
author={Samy, Ihab and Postlethwaite, Ian and Gu, Da-Wei},
booktitle={49th IEEE Conference on Decision and Control (CDC)}, title={Detection and accommodation of sensor faults in UAVs- a comparison of NN and EKF based approaches},
year={2010},
volume={},
number={},
pages={4365-4372},
abstract={In this paper we propose two schemes for sensor fault detection and accommodation (SFDA); one based on a neural network (NN) and the other an extended Kalman filter (EKF). The objective is to compare both approaches in terms of execution time, robustness to poorly modelled dynamics and sensitivity to different fault types. The schemes are tested on an unmanned air vehicle (UAV) application where traditional sensor redundancy methods can be too heavy and/or costly. In an attempt to reduce the false alarm rates and the number of undetected faults, a modified residual generator, originally proposed in [11], is implemented. Simulation work is presented for use on a UAV demonstrator under construction with support from BAE Systems and EPSRC. Results have shown that the NN-SFDA scheme outperforms the EKF-SFDA scheme with only 1 missed fault, zero false alarms and an average estimation error of 0.31deg/s for 112 different test conditions.},
keywords={Artificial neural networks;Mathematical model;Equations;Jacobian matrices;Unmanned aerial vehicles;Measurement uncertainty;Training},
doi={10.1109/CDC.2010.5716956},
ISSN={0191-2216},
month={Dec},}
@INPROCEEDINGS{8326145,
author={Kyrkou, Christos and Timotheou, Stelios and Kolios, Panayiotis and Theocharides, Theocharis and Panayiotou, Christos G.},
booktitle={2018 IEEE International Conference on Consumer Electronics (ICCE)}, title={Optimized vision-directed deployment of UAVs for rapid traffic monitoring},
year={2018},
volume={},
number={},
pages={1-6},
abstract={The flexibility and cost efficiency of traffic monitoring using Unmanned Aerial Vehicles (UAVs) has made such a proposition an attractive topic of research. To date, the main focus was placed on the types of sensors used to capture the data, and the alternative data processing options to achieve good monitoring performance. In this work we move a step further, and explore the deployment strategies that can be realized for rapid traffic monitoring over particular regions of the transportation network by considering a monitoring scheme that captures data from a visual sensor on-board the UAV, and subsequently analyzes it through a specific vision processing pipeline to extract network state information. These innovative deployment strategies can be used in real-time to assess traffic conditions, while for longer periods, to validate the underlying mobility models that characterise traffic patterns.},
keywords={Roads;Monitoring;Pipelines;Buildings;Image segmentation;Convolutional neural networks},
doi={10.1109/ICCE.2018.8326145},
ISSN={2158-4001},
month={Jan},}
@INPROCEEDINGS{7778103,
author={Maleki, K. Niki and Ashenayi, Kaveh and Hook, Loyd R and Fuller, Justin G and Hutchins, Nathan},
booktitle={2016 IEEE/AIAA 35th Digital Avionics Systems Conference (DASC)}, title={A reliable system design for nondeterministic adaptive controllers in small UAV autopilots},
year={2016},
volume={},
number={},
pages={1-5},
abstract={Despite the tremendous attention Unmanned Aerial Vehicles (UAVs) have received in recent years for applications in transportation, surveillance, agriculture, and search and rescue, as well as their possible enormous economic impact, UAVs are still banned from fully autonomous commercial flights. One of the main reasons for this is the safety of the flight. Traditionally, pilots control the aircraft when complex situations emerge that even advanced autopilots are not able to manage. Artificial Intelligence based methods and Adaptive Controllers have proven themselves to be efficient in scenarios with uncertainties; however, they also introduce another concern: nondeterminism. This research endeavors to find a solution on how such algorithms can be utilized with higher reliability. Our method is based on using an adaptive model to verify the performance of a control parameter - proposed by a nondeterministic adaptive controller or AI-based optimizer - before it is deployed on the physical platform. Furthermore, a backup mechanism is engaged to recover the drone in case of failure. A Neural Network is employed to model the aircraft, and a Genetic Algorithm is utilized to optimize the PID controller of a quadcopter. The initial experimental results from test flights indicate the feasibility of this method.},
keywords={Adaptation models;Genetic algorithms;Drones;Artificial intelligence;Atmospheric modeling;Adaptive systems;Neural networks;Adaptive Controller;Artificial Intelligence;Genetic Algorithm;Neural Network;Quadcopter},
doi={10.1109/DASC.2016.7778103},
ISSN={2155-7209},
month={Sep.},}
@INPROCEEDINGS{9476742,
author={Savva, Antonis and Zacharia, Angelos and Makrigiorgis, Rafael and Anastasiou, Antreas and Kyrkou, Christos and Kolios, Panayiotis and Panayiotou, Christos and Theocharides, Theocharis},
booktitle={2021 International Conference on Unmanned Aircraft Systems (ICUAS)}, title={ICARUS: Automatic Autonomous Power Infrastructure Inspection with UAVs},
year={2021},
volume={},
number={},
pages={918-926},
abstract={Power transmission and distribution networks mostly span across harsh environments and thus, frequent faults and failures are observed, increasing the maintenance costs, pressing the authorities to provide electricity continuously and uninterruptedly. To this end, thorough field inspections with skilled personnel are regularly conducted, which are labor-intensive, costly and slow, whereby efficiency and staff safety cannot be always ensured. UAVs stem as a promising solution for power infrastructure inspection; however, their use is mostly limited by the fact that a remote pilot is in control of flight and mission processes, rendering reliable data acquisition in short time interval a tedious task. Despite research efforts for automating inspection procedures, these have not been widely adopted. In this study, we address this challenge by developing a Power Distribution Network Inspection Platform Using UAVs (ICARUS), based on a vision-based artificial intelligence toolkit, that integrates multiple sensors and automates many tasks, such as detection, tracking and identification of infrastructure components, gathering reliable spatial/time data associated to these components autonomously, safely and fast.},
keywords={Process control;Power transmission;Pressing;Inspection;Rendering (computer graphics);Aircraft navigation;Safety;power line inspection;vision-based inspection;autonomous navigation;unmanned aerial vehicles;deep learning},
doi={10.1109/ICUAS51884.2021.9476742},
ISSN={2575-7296},
month={June},}
@INPROCEEDINGS{5611206,
author={Bou-Ammar, Haitham and Voos, Holger and Ertel, Wolfgang},
booktitle={2010 IEEE International Conference on Control Applications}, title={Controller design for quadrotor UAVs using reinforcement learning},
year={2010},
volume={},
number={},
pages={2130-2135},
abstract={Quadrotor UAVs are one of the most preferred type of small unmanned aerial vehicles because of the very simple mechanical construction and propulsion principle. However, the nonlinear dynamic behavior requires a rather advanced stabilizing control of these vehicles. One possible approach that relaxes the difficult task of nonlinear control design is the application of a learning algorithm that allows the training of suitable control actions. Here we apply reinforcement learning as one form of unsupervised learning. In this paper, we first propose a nonlinear autopilot for quadrotor UAVs based on feedback linearization. This controller is then compared to an autopilot which has been learned by reinforcement learning using fitted value iteration with regard to design effort and performance. First simulation and experimental results underline the outcome of this comparison.},
keywords={Learning;Input variables;Control systems;Unmanned aerial vehicles;Rotors;Mathematical model},
doi={10.1109/CCA.2010.5611206},
ISSN={1085-1992},
month={Sep.},}
@INPROCEEDINGS{9653036,
author={Galvan, Julio and Raja, Ashok and Li, Yanyan and Yuan, Jiawei},
booktitle={MILCOM 2021 - 2021 IEEE Military Communications Conference (MILCOM)}, title={Sensor Data-Driven UAV Anomaly Detection using Deep Learning Approach},
year={2021},
volume={},
number={},
pages={589-594},
abstract={Thanks to the high mobility and rich sensing capabilities of unmanned aerial vehicles (UAVs), or drones, they are increasingly leveraged to perform a series of military and civilian tasks today. Meanwhile, UAVs are also facing various security and safety concerns raised by both external attacks and internal hardware/software failures. Therefore, detecting the abnormal status of a UAV is a critical task to protect it against malicious adversaries and prevent potential crashes. In this paper, we propose an anomaly detection system for UAVs by monitoring and analyzing their sensor data in real-time using deep learning approaches. The proposed system leverages the convolutional neural network (CNN) to extract and learn features automatically from raw sensor data and then process them to support anomaly detection. We construct a data set of UAV IMU sensor data using our UAV cybersecurity simulation platform to support the training of our CNN model. Different deep learning models are also evaluated and compared in this paper. We validate the performance of the proposed detection system using extensive experimental evaluation, which demonstrates that our system achieves high detection accuracy under different conditions.},
keywords={Deep learning;Training;Autonomous aerial vehicles;Feature extraction;Data models;Sensors;Safety},
doi={10.1109/MILCOM52596.2021.9653036},
ISSN={2155-7586},
month={Nov},}
@INPROCEEDINGS{9205793,
author={Lee, Min-Fan Ricky and Nugroho, Asep and Le, Tuan-Tang and Bahrudin and Bastida, Saul Nieto},
booktitle={2020 International Conference on Advanced Robotics and Intelligent Systems (ARIS)}, title={Landing Area Recognition using Deep Learning for Unammaned Aerial Vehicles},
year={2020},
volume={},
number={},
pages={1-6},
abstract={The lack of an automated Unmanned Aerial Vehicles (UAV) landing site detection system has been identified as one of the main impediments to allow UAV flight over populated areas in civilian airspace to develop tasks in the logistical transport scenario. This research proposes landing area localization and obstruction detection for UAVs that are based on deep learning faster R-CNN and feature matching algorithm. Which output decides if the landing area is safe or not. The final result has been deployed on the Aerial Mobile Robot Platform and was successfully performed effectively.},
keywords={Training;Feature extraction;Drones;Testing;Object detection;Histograms;Machine learning;Convolutional Neural Network;Environment Classification;UAV;Object Detection;Feature Matching},
doi={10.1109/ARIS50834.2020.9205793},
ISSN={2572-6919},
month={Aug},}
@ARTICLE{8435993,
author={Ma, Carlos and Lam, James and Lewis, Frank L.},
journal={IEEE Transactions on Control Systems Technology}, title={Trajectory Regulating Model Reference Adaptive Controller for Robotic Systems},
year={2019},
volume={27},
number={6},
pages={2749-2756},
abstract={The new trajectory regulating model reference adaptive controller (TRMRAC) has been proposed in this brief. The intermediate reference model in the TRMRAC is self-regulated to enhance the stability and robustness of adaptation, with the trajectories of the controlled system proven to be ultimately uniformly bounded. The developed controller is implemented and simulated in a multivariable robotic arm system with its system dynamics approximated by a neural network, showing superior stability characteristics even under unmodeled actuator dynamics and input saturation. To demonstrate its practicality, a nested version of the controller was tested on a quadcopter for quaternion attitude tracking, showing enhanced robustness over the conventional model reference adaptive control strategy.},
keywords={Unmanned aerial vehicles;Actuators;Robustness;Neural networks;Artificial neural networks;Adaptive control;Robots;Boundedness;model reference adaptive control (MRAC);neural networks (NNs);quadcopter;quaternion;tracking;unmanned aerial vehicle (UAV)},
doi={10.1109/TCST.2018.2858203},
ISSN={1558-0865},
month={Nov},}
@INPROCEEDINGS{9533896,
author={Mokhtari, Ichrak and Bechkit, Walid and Rivano, Hervé},
booktitle={2021 International Joint Conference on Neural Networks (IJCNN)}, title={A generic framework for monitoring pollution plumes in emergencies using UAVs},
year={2021},
volume={},
number={},
pages={1-9},
abstract={Monitoring air pollution plumes in emergency situations (industrial accidents, natural disasters, deliberate terrorist releases, etc.) becomes an issue of utmost importance in our society given the dramatic effects that the released pollutants can cause. Considering these situations, the pollution plume is strongly dynamic leading to a fast dispersion of pollutants in the atmosphere. Thus, the need for real-time response is very strong and a solution to get precise mapping of pollution dispersion is required to mitigate risks. However, monitoring and forecasting air quality in real time in such situations remains a highly challenging endeavour. In this paper, we suggest a systemic approach for monitoring dynamic air pollution based on aerial sensing (sensors mounted on UAVs). The proposed framework consists of a cycle with feedback loop which will constantly combine a spatio-temporal forecasting model based on a convolutional long short term memory (ConvLSTM) network with a data assimilation technique to get accurate pollution maps, while adjusting at each time the trajectories of drones following uncertainty forecasts. Our solution was evaluated and validated using a highly dynamic real world data set namely Fusion Field Trial 2007 (FFT07). The proposed strategy, together with the obtained evaluation results, are presented, and carefully analyzed.},
keywords={Uncertainty;Terrorism;Air pollution;Real-time systems;Sensor systems;Sensors;Trajectory;Dynamic air pollution;Deep Learning;Data Assimilation;Uncertainty;UAVs},
doi={10.1109/IJCNN52387.2021.9533896},
ISSN={2161-4407},
month={July},}
@INPROCEEDINGS{9659413,
author={Theile, Mirco and Bayerlein, Harald and Nai, Richard and Gesbert, David and Caccamo, Marco},
booktitle={2021 20th International Conference on Advanced Robotics (ICAR)}, title={UAV Path Planning using Global and Local Map Information with Deep Reinforcement Learning},
year={2021},
volume={},
number={},
pages={539-546},
abstract={Path planning methods for autonomous unmanned aerial vehicles (UAVs) are typically designed for one specific type of mission. This work presents a method for autonomous UAV path planning based on deep reinforcement learning (DRL) that can be applied to a wide range of mission scenarios. Specifically, we compare coverage path planning (CPP), where the UAV's goal is to survey an area of interest to data harvesting (DH), where the UAV collects data from distributed Internet of Things (IoT) sensor devices. By exploiting structured map information of the environment, we train double deep Q-networks (DDQNs) with identical architectures on both distinctly different mission scenarios to make movement decisions that balance the respective mission goal with navigation constraints. By introducing a novel approach exploiting a compressed global map of the environment combined with a cropped but uncompressed local map showing the vicinity of the UAV agent, we demonstrate that the proposed method can efficiently scale to large environments. We also extend previous results for generalizing control policies that require no retraining when scenario parameters change and offer a detailed analysis of crucial map processing parameters' effects on path planning performance.},
keywords={Navigation;Distributed databases;Process control;Reinforcement learning;Autonomous aerial vehicles;Path planning;Internet of Things},
doi={10.1109/ICAR53236.2021.9659413},
ISSN={},
month={Dec},}
@INPROCEEDINGS{9562230,
author={Yun, Won Joon and Lim, Byungju and Jung, Soyi and Ko, Young-Chai and Park, Jihong and Kim, Joongheon and Bennis, Mehdi},
booktitle={2021 17th International Symposium on Wireless Communication Systems (ISWCS)}, title={Attention-based Reinforcement Learning for Real-Time UAV Semantic Communication},
year={2021},
volume={},
number={},
pages={1-6},
abstract={In this article, we study the problem of air-to-ground ultra-reliable and low-latency communication (URLLC) for a moving ground user. This is done by controlling multiple unmanned aerial vehicles (UAVs) in real time while avoiding inter-UAV collisions. To this end, we propose a novel multiagent deep reinforcement learning (MADRL) framework, coined a graph attention exchange network (GAXNet). In GAXNet, each UAV constructs an attention graph locally measuring the level of attention to its neighboring UAVs, while exchanging the attention weights with other UAVs so as to reduce the attention mismatch between them. Simulation results corroborates that GAXNet achieves up to 4.5x higher rewards during training. At execution, without incurring inter-UAV collisions, G2ANet improves reliability of air-to-ground network in terms of latency and error rate.},
keywords={Wireless communication;Weight measurement;Training;Simulation;Semantics;Reinforcement learning;Ultra reliable low latency communication},
doi={10.1109/ISWCS49558.2021.9562230},
ISSN={2154-0225},
month={Sep.},}
@INPROCEEDINGS{9361278,
author={Mao, Sheng and Guo, Jiansheng and Gu, Taoyong and Ma, Zhong},
booktitle={2020 International Conference on Artificial Intelligence and Computer Engineering (ICAICE)}, title={..Dis-AE-LSTM: Generative Adversarial Networks for Anomaly Detection of Time Series Data},
year={2020},
volume={},
number={},
pages={330-336},
abstract={Anomalies in time series data contain valuable information for engineers, scientists and entrepreneurs. However, the anomaly detection in time series is facing with the complexity caused by the large volume and high dimensions of data. To mitigate the problem, we propose an unsupervised anomaly detection method for time series data based on generative adversarial networks (GANs) with the long-short term memory recurrent neural networks (LSTM-RNN) as base modules. The nature of generative models is used to capture the distributions of high dimensional data, where the LSTM module is used to learn the temporal relationships. The proposed framework is designed with the capability to reconstruct input data after training, and the reconstruction errors based anomaly scores are assigned to each time step in the time series, which determines the anomalies. Experimental results show the superiorities and efficiency of the proposed method.},
keywords={Training;Recurrent neural networks;Time series analysis;Memory management;Generative adversarial networks;Anomaly detection;Testing;anomaly detection;time series;generative adversarial networks;autoencoder;long short term memory nerworks},
doi={10.1109/ICAICE51518.2020.00070},
ISSN={},
month={Oct},}
@INPROCEEDINGS{8278390,
author={Cui, Qiannan and Liu, Peizhi and Wang, Jinhua and Yu, Jing},
booktitle={2017 IEEE International Conference on Unmanned Systems (ICUS)}, title={Brief analysis of drone swarms communication},
year={2017},
volume={},
number={},
pages={463-466},
abstract={Swarm intelligence has received much research attention in recent years. As a typical application of swarm intelligence, swarm of drones systems generally exhibit decentralized control achieved through simple agent behaviors and interactions developing a self-organization that is considered an emergence of order from the system. Together the system is greater than the sum of its parts, capable of solving complex problems that no agent could accomplish singularly. Effective communication mechanisms are a key requirement for drone swarms and their meaningful deployment. Swarm with a large size requires a fully distributed communication system which scales well and optimizes the “many-to-many” communication. At a basic level a drone swarm is a floating dynamic wireless network, commonly known as a wireless mesh network. This thesis focuses on the comparison and analysis of two representative drone swarms communication techniques to solve the challenges of drone swarms communication design.},
keywords={Wireless mesh networks;Routing;Floods;Energy consumption;wireless mesh networks;drone swarms;UAV;communication techniques},
doi={10.1109/ICUS.2017.8278390},
ISSN={},
month={Oct},}
@INPROCEEDINGS{9602967,
author={Chen, Wei-Ting and Huang, Cheng-Sen and Wang, Li-Chun},
booktitle={2021 30th Wireless and Optical Communications Conference (WOCC)}, title={Cooperative Deep Learning-Based Uplink Distributed Fair Resource Allocation for Aerial Reconfigurable Intelligent Surfaces Wireless Networks},
year={2021},
volume={},
number={},
pages={11-15},
abstract={In this paper, we present a cooperative distributed learning based resource allocation scheme for an unmanned aerial vehicle (UAV)-assisted wireless communication framework equipped with reconfigurable intelligent surfaces (RIS), aiming to dynamically allocate the amount of the resource block(RB) to ensure the fairness and efficiency from the end-to-end communications system perspective. We suggest a novel, but simple fairness-efficiency metrics (FE metrics) to measure the performance of resource allocating, and to compare various resource allocation policies, including our proposed cooperative deep learning approaches, other rule-based and centralized methods. The proposed cooperative distributed learning framework has the advantages of making decisions by considering information about the entire environment, so that cooperation provides better overall performance and reliability. Moreover, it enables double parallel computing and reduces execution time dramatically. The simulation result shows that our cooperative deep learning algorithm ensures excellent convergence and low time complexity during the execution in the complex Aerial RIS system to reduce communication delays, improve communication quality, and ensure fairness.},
keywords={Deep learning;Measurement;Computer aided instruction;Distance learning;Wireless networks;Reconfigurable intelligent surfaces;Unmanned aerial vehicles;UAV-assisted Wireless Communication;Reconfigurable Intelligent Surfaces;Deep Learning;Uplink resource allocation},
doi={10.1109/WOCC53213.2021.9602967},
ISSN={2379-1276},
month={Oct},}
@ARTICLE{8664596,
author={Liu, Chi Harold and Chen, Zheyu and Zhan, Yufeng},
journal={IEEE Journal on Selected Areas in Communications}, title={Energy-Efficient Distributed Mobile Crowd Sensing: A Deep Learning Approach},
year={2019},
volume={37},
number={6},
pages={1262-1276},
abstract={High-quality data collection is crucial for mobile crowd sensing (MCS) with various applications like smart cities and emergency rescues, where various unmanned mobile terminals (MTs), e.g., driverless cars and unmanned aerial vehicles (UAVs), are equipped with different sensors that aid to collect data. However, they are limited with fixed carrying capacity, and thus, MT's energy resource and sensing range are constrained. It is quite challenging to navigate a group of MTs to move around a target area to maximize their total amount of collected data with the limited energy reserve, while geographical fairness among those point-of-interests (PoIs) should also be maximized. It is even more challenging if fully distributed execution is enforced, where no central control is allowed at the backend. To this end, we propose to leverage emerging deep reinforcement learning (DRL) techniques for directing MT's sensing and movement and to present a novel and highly efficient control algorithm, called energy-efficient distributed MCS (Edics). The proposed neural network integrates convolutional neural network (CNN) for feature extraction and then makes decision under the guidance of multi-agent deep deterministic policy gradient (DDPG) method in a fully distributed manner. We also propose two enhancements into Edics with N-step return and prioritized experienced replay buffer. Finally, we evaluate Edics through extensive simulations and found the appropriate set of hyperparameters in terms of number of CNN hidden layers and neural units for all the fully connected layers. Compared with three commonly used baselines, results have shown its benefits.},
keywords={Sensors;Task analysis;Data collection;Autonomous automobiles;Navigation;Reinforcement learning;Smart phones;Mobile crowd sensing;deep reinforcement learning;energy-efficiency;distributed data collection},
doi={10.1109/JSAC.2019.2904353},
ISSN={1558-0008},
month={June},}
@ARTICLE{9130680,
author={Rodriguez-Ramos, Alejandro and Rodriguez-Vazquez, Javier and Sampedro, Carlos and Campoy, Pascual},
journal={IEEE Access}, title={Adaptive Inattentional Framework for Video Object Detection With Reward-Conditional Training},
year={2020},
volume={8},
number={},
pages={124451-124466},
abstract={Recent object detection studies have been focused on video sequences, mostly due to the increasing demand of industrial applications. Although single-image architectures achieve remarkable results in terms of accuracy, they do not take advantage of particular properties of the video sequences and usually require high parallel computational resources, such as desktop GPUs. In this work, an inattentional framework is proposed, where the object context in video frames is dynamically reused in order to reduce the computation overhead. The context features corresponding to keyframes are fused into a synthetic feature map, which is further refined using temporal aggregation with ConvLSTMs. Furthermore, an inattentional policy has been learned to adaptively balance the accuracy and the amount of context reused. The inattentional policy has been learned under the reinforcement learning paradigm, and using our novel reward-conditional training scheme, which allows for policy training over a whole distribution of reward functions and enables the selection of a unique reward function at inference time. Our framework shows outstanding results on platforms with reduced parallelization capabilities, such as CPUs, achieving an average latency reduction up to 2.09×, and obtaining FPS rates similar to their equivalent GPU platform, at the cost of a 1.11× mAP reduction.},
keywords={Object detection;Feature extraction;Training;Reinforcement learning;Neural networks;Computer architecture;Measurement;Inattention;YOTO;reward-conditional training;deep learning;video object detection;reinforcement learning;CNN;LSTM;loss-conditional training},
doi={10.1109/ACCESS.2020.3006191},
ISSN={2169-3536},
month={},}
@INPROCEEDINGS{9512618,
author={Ou, Jiajun and Guo, Xiao and Lou, Wenjie and Zhu, Ming},
booktitle={2021 IEEE International Conference on Mechatronics and Automation (ICMA)}, title={Learning the Spatial Perception and Obstacle Avoidance with the Monocular Vision on a Quadrotor},
year={2021},
volume={},
number={},
pages={582-587},
abstract={We present a learning-based framework to simultaneously realize spatial perception and obstacle avoidance in this paper. It learns to extract the visual representations of obstacles from raw monocular images using unsupervised contrastive learning. Moreover, the framework utilizes the dueling double deep recurrent Q network to learn the optimal obstacle avoidance policy using the extracted representation features. The learned policy in the framework can reduce the side effects of the onboard fixed camera's limited observation capacity by adding recurrency to stack a history of observations. Compared with other typical obstacle avoidance methods, the proposed framework is more light weighted and data-efficient. The framework is trained and evaluated in several simulation scenarios, which are built in the ROS Gazebo environment. The trained framework is capable to control the quadrotor to pass through the crowded environments in evaluation.},
keywords={Training;Learning systems;Visualization;Mechatronics;Training data;Reinforcement learning;Feature extraction;Unmanned aerial vehicle;Obstacle avoidance;Contrastive learning;Deep reinforcement learning},
doi={10.1109/ICMA52036.2021.9512618},
ISSN={2152-744X},
month={Aug},}
@INPROCEEDINGS{8127595,
author={Chen, Bowei and Li, Zengyuan and Pang, Yong and Liu, Qingwang and Gao, Xianlian and Gao, Jinping and Fu, Anmin},
booktitle={2017 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)}, title={Forest height estimation based on uav lidar simulated waveform},
year={2017},
volume={},
number={},
pages={2859-2862},
abstract={The accurate estimation of forest height is very important for understanding forest biomass and forest vertical structures. To investigate the potentials of forest height mapping for future Chinese satellite mission concepts with a waveform Lidar system onboard, a field campaign was designed and implemented in Weihe forest farm, Northeastern China in August of 2016. The method we proposed in this paper is that firstly we generate simulated waveforms from Unmanned Aerial Vehicles (UAV) Lidar data, then we use random forest (RF) to get the most relevant variables from 18 waveform parameters driven from our simulated results and 11 terrain parameters from ASTER-DEM. Finally, we used Cubist machine learning algorithm to establish the relationships between 4 different forest heights and the selected variables. Initial results demonstrated that the simulated waveforms could estimate forest height very well.},
keywords={Laser radar;Satellites;Estimation;Remote sensing;Vegetation;Unmanned aerial vehicles;Biomass;Forest height;UAV Lidar;waveform;simulation;Cubist},
doi={10.1109/IGARSS.2017.8127595},
ISSN={2153-7003},
month={July},}
@INPROCEEDINGS{8206192,
author={Basha, Elizabeth and Watts-Willis, Tristan and Detweiler, Carrick},
booktitle={2017 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)}, title={Autonomous meta-classifier for surface hardness classification from UAV landings},
year={2017},
volume={},
number={},
pages={3503-3509},
abstract={Developing surface classification models manually requires significant time and detracts from the goal of automating systems. We create a system that automatically collects the data using an Unmanned Aerial Vehicle (UAV), extracts features, trains a large number of classifiers, selects the best classifier, and programs the UAV with that classifier. Motivating our work is a prior project [1] that manually developed a surface classifier using an accelerometer; to verify our system functionality, we replicate those results with our new automated system and improve on those results, providing a four-surface classifier with a 75% classification rate and a hard/soft classifier with a 100% classification rate. We further verify our system through a field experiment that collects and classifies new data, proving its end-to-end functionality. Overall, our system reduces the time and machine learning expertise needed by the user to develop new time-series classifiers usable by the UAV. The general form of our system provides a valuable tool for automation of classifier creation and is released as an open-source tool [2].},
keywords={Unmanned aerial vehicles;Feature extraction;Robot sensing systems;Hidden Markov models;Tools;Data models},
doi={10.1109/IROS.2017.8206192},
ISSN={2153-0866},
month={Sep.},}
@INPROCEEDINGS{7997333,
author={Chen, Junting and Yatnalli, Uday and Gesbert, David},
booktitle={2017 IEEE International Conference on Communications (ICC)}, title={Learning radio maps for UAV-aided wireless networks: A segmented regression approach},
year={2017},
volume={},
number={},
pages={1-6},
abstract={This paper targets the promising area of unmanned aerial vehicle (UAV)-assisted wireless networking, by which communication-enabled robots operate as flying wireless relays to help fill coverage or capacity gaps in the networks. In order to feed the UAV's autonomous path planning and positioning algorithm, a radio map is exploited, which must be, in practice, reconstructed from UAV-based measurements from a limited subset of locations. Unlike existing methods that ignore the segmented propagation structure of the radio map, this paper proposes a machine learning approach to reconstruct a finely structured map by exploiting both segmentation and signal strength models. A data clustering and parameter estimation problem is formulated using a maximum likelihood approach, and solved by an iterative clustering and regression algorithm. Numerical results demonstrate significant performance advantage in radio map reconstruction as compared to the baseline.},
keywords={Wireless communication;Buildings;Gain;Maximum likelihood estimation;Signal processing algorithms;Urban areas;Shadow mapping},
doi={10.1109/ICC.2017.7997333},
ISSN={1938-1883},
month={May},}
@ARTICLE{9437345,
author={Feng, Luwei and Zhang, Zhou and Ma, Yuchi and Sun, Yazhou and Du, Qingyun and Williams, Parker and Drewry, Jessica and Luck, Brian},
journal={IEEE Geoscience and Remote Sensing Letters}, title={Multitask Learning of Alfalfa Nutritive Value From UAV-Based Hyperspectral Images},
year={2022},
volume={19},
number={},
pages={1-5},
abstract={Alfalfa is a valuable and widely adapted forage crop, and its nutritive value directly affects animal performance and ultimately affects the profitability of livestock production. Traditional nutritive value measurement method is labor-intensive and time-consuming and thus hinders the determination of alfalfa nutritive values over large fields. The adoption of unmanned aerial vehicles (UAVs) facilitates the generation of images with high spatial and temporal resolutions for field-level agricultural research. Additionally, compared with other imaging modalities, hyperspectral data usually consist of hundreds of narrow spectral bands and allow the accurate detection, identification, and quantification of crop quality. Although various machine-learning methods have been developed for alfalfa quality prediction, they were all single-task models that learned independently for each quality trait and failed to utilize the underlying relatedness between each task. Inspired by the idea of multitask learning (MTL), this study aims to develop an approach that simultaneously predicts multiple quality traits. The algorithm first extracts shared information through a long short-term memory (LSTM)-based common hidden layer. To enhance the model flexibility, it is then divided into multiple branches, each containing the same or different number of task-specific fully connected hidden layers. Through comparison with multiple mainstream single-task machine-learning models, the effectiveness of the model is illustrated based on the measured alfalfa quality data and multitemporal UAV-based hyperspectral imagery.},
keywords={Task analysis;Hyperspectral imaging;Mathematical model;Agriculture;Predictive models;Computer architecture;Logic gates;Alfalfa;hyperspectral imagery;multitask learning;nutritive value;unmanned aerial vehicle (UAV)},
doi={10.1109/LGRS.2021.3079317},
ISSN={1558-0571},
month={},}
@INPROCEEDINGS{6842273,
author={Cekmez, Ugur and Ozsiginan, Mustafa and Sahingoz, Ozgur Koray},
booktitle={2014 International Conference on Unmanned Aircraft Systems (ICUAS)}, title={A UAV path planning with parallel ACO algorithm on CUDA platform},
year={2014},
volume={},
number={},
pages={347-354},
abstract={Solving the path planning problem of a UAV is a challenging issue especially if there are too many checkpoints to visit. Mainly, the brute force approach is used to find the shortest path in the mission area, which requires too many times to find a solution. Therefore, evolutionary algorithms and swarm intelligence techniques are used to find a feasible solution in an acceptable time. In this study, path planning problem of a UAV is solved by using a highly parallelized Ant Colony Optimization (ACO) algorithm on CUDA platform. The UAV path is constructed for disseminating keys and collecting data from a Wireless Sensor Network, which is previously defined. Due to its simplicity and effectiveness, ACO is selected as a path planning algorithm. However, ACO is not satisfactory if the mission area becomes large and there are an excessive number of checkpoints and/or additional constraints. In order to increase the performance, some parallelization techniques must be used in high performance computing platforms. GPU architecture has emerged as a powerful and low cost architecture for enabling impressive speedups for scientific calculations. Therefore, the parallel structure is constructed on CUDA architecture. The experimental results are compared with the CPU performance of the serial algorithm, and they clearly show that the proposed approach have a great potential for acceleration of ACO and allow to solve many complex tasks such as UAV path planning problem. We also present the execution results with different parameter values to expose the results for the researchers.},
keywords={Cities and towns;Graphics processing units;Instruction sets;Path planning;Computer architecture;Planning;Central Processing Unit},
doi={10.1109/ICUAS.2014.6842273},
ISSN={},
month={May},}
@INPROCEEDINGS{8741970,
author={Ezuma, Martins and Erden, Fatih and Anjinappa, Chethan Kumar and Ozdemir, Ozgur and Guvenc, Ismail},
booktitle={2019 IEEE Aerospace Conference}, title={Micro-UAV Detection and Classification from RF Fingerprints Using Machine Learning Techniques},
year={2019},
volume={},
number={},
pages={1-13},
abstract={This paper focuses on the detection and classification of micro-unmanned aerial vehicles (UAVs)using radio frequency (RF)fingerprints of the signals transmitted from the controller to the micro-UAV. In the detection phase, raw signals are split into frames and transformed into the wavelet domain to remove the bias in the signals and reduce the size of data to be processed. A naive Bayes approach, which is based on Markov models generated separately for UAV and non-UAV classes, is used to check for the presence of a UAV in each frame. In the classification phase, unlike the traditional approaches that rely solely on time-domain signals and corresponding features, the proposed technique uses the energy transient signal. This approach is more robust to noise and can cope with different modulation techniques. First, the normalized energy trajectory is generated from the energy-time-frequency distribution of the raw control signal. Next, the start and end points of the energy transient are detected by searching for the most abrupt changes in the mean of the energy trajectory. Then, a set of statistical features is extracted from the energy transient. Significant features are selected by performing neighborhood component analysis (NCA)to keep the computational cost of the algorithm low. Finally, selected features are fed to several machine learning algorithms for classification. The algorithms are evaluated experimentally using a database containing 100 RF signals from each of 14 different UAV controllers. The signals are recorded wirelessly using a high-frequency oscilloscope. The data set is randomly partitioned into training and test sets for validation with the ratio 4:1. Ten Monte Carlo simulations are run and results are averaged to assess the performance of the methods. All the micro-UAVs are detected correctly and an average accuracy of 96.3% is achieved using the k-nearest neighbor (kNN)classification. Proposed methods are also tested for different signal-to-noise ratio (SNR)levels and results are reported.},
keywords={Feature extraction;Time-domain analysis;Transient analysis;Radar cross-sections;Frequency modulation;Radio frequency},
doi={10.1109/AERO.2019.8741970},
ISSN={1095-323X},
month={March},}
@INPROCEEDINGS{9025597,
author={Masjedi, Ali and Carpenter, Neal R. and Crawford, Melba M. and Tuinstra, Mitch R.},
booktitle={2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)}, title={Prediction of Sorghum Biomass Using Uav Time Series Data and Recurrent Neural Networks},
year={2019},
volume={},
number={},
pages={2695-2702},
abstract={Phenotyping via Unmanned Aerial Vehicles (UAVs) is of increasing interest for many applications because of their capability to carry advanced sensors and achieve accurate positioning required to collect both high temporal and high spatial resolution data required over relatively limited areas. This paper focuses development of a data analytics based predictive modeling strategy that incorporates multi-sensor data acquisition systems and accommodates environmental inputs. Unsupervised feature learning based on fully connected and convolutional neural networks is investigated. Predictive models based on Recurrent Neural Networks (RNNs) are designed and implemented to accommodate high dimensional, multi-modal, multi-temporal data. Remote sensing data, including Light Detection and Ranging (LiDAR) and hyperspectral inputs, as well as weather data, are incorporated in RNN models. Results from multiple experiments focused on high throughput phenotyping of sorghum for biomass predictions are provided and evaluated for agricultural test fields at the Agronomy Center for Research and Education (ACRE) at Purdue University.},
keywords={Biomass;Predictive models;Feature extraction;Hyperspectral imaging;Biological system modeling;Laser radar;Data models},
doi={10.1109/CVPRW.2019.00327},
ISSN={2160-7516},
month={June},}
@INPROCEEDINGS{9194188,
author={Ozturk, Metin and Nadas, João P. B. and Klaine, Paulo H. V. and Hussain, Sajjad and Imran, Muhammad A.},
booktitle={2019 International Conference on Advances in the Emerging Computing Technologies (AECT)}, title={Clustering Based UAV Base Station Positioning for Enhanced Network Capacity},
year={2020},
volume={},
number={},
pages={1-6},
abstract={Unmanned aerial vehicles (UAVs) are expected to be deployed in a variety of applications in future mobile networks due to several advantages they bring over the deployment of ground base stations. However, despite the recent interest in UAVs in mobile networks, some issues still remain, such as determining the placement of multiple UAVs in different scenarios. In this paper we propose a solution to determine the optimal 3D position of multiple UAVs in a capacity enhancement use-case, or in other words, when the ground network cannot cope with the user traffic demand. For this scenario, real data from the city of Milan, provided by Telecom Italia is utilized to simulate an event. Based on that, a solution based on k-means, a machine learning technique, to position multiple UAVs is proposed and it is compared with two other baseline methods. Results demonstrate that the proposed solution is able to significantly outperform other methods in terms of users covered and quality of service.},
keywords={Interference;Quality of service;Signal to noise ratio;Throughput;Unmanned aerial vehicles;Base stations;Three-dimensional displays;UAV;Clustering;Enhanced Mobile Broad-band;Self Organizing Networks},
doi={10.1109/AECT47998.2020.9194188},
ISSN={},
month={Feb},}
@INPROCEEDINGS{8996643,
author={Wanguo, Wang and Zhenli, Wang and Bin, Liu and Yuechen, Yang and Xiaobin, Sun},
booktitle={2019 Chinese Automation Congress (CAC)}, title={Typical Defect Detection Technology of Transmission Line Based on Deep Learning},
year={2019},
volume={},
number={},
pages={1185-1189},
abstract={Detection of line component defects in UAV transmission line inspection is always a difficult problem. In order to solve the problem of identifying the defects of insulators and anti-vibration hammers in transmission lines, a target detection technique based on deep learning is proposed to diagnose the typical defects of transmission lines. SSD algorithm based on candidate regions is selected to locate and identify the defects. Firstly, the influence of different feature extraction networks and network parameters on the accuracy and speed of target detection is studied. The network is improved by adjusting network parameters and model optimization method, and the network parameters that are most conducive to transmission line defect detection are selected.Then, the influence of different data enhancement methods on the accuracy of defect detection is studied. The training samples are expanded by multi-scale training and horizontal mirror method to further improve the accuracy of target detection.Finally, the recognition and classification experiments are carried out using the actual images collected by UAV. The experimental results show that the target detection method based on deep learning can accurately locate the location of defects from the transmission line image, and can be applied to the fault diagnosis task in the transmission line scene.},
keywords={Power transmission lines;Feature extraction;Training;Convolution;Mathematical model;Machine learning;Insulators;transmission line;object detection;deep learning},
doi={10.1109/CAC48633.2019.8996643},
ISSN={2688-0938},
month={Nov},}
@INPROCEEDINGS{9417563,
author={Chu, Nam H. and Hoang, Dinh Thai and Nguyen, Diep N. and Huynh, Nguyen Van and Dutkiewicz, Eryk},
booktitle={2021 IEEE Wireless Communications and Networking Conference (WCNC)}, title={Fast or Slow: An Autonomous Speed Control Approach for UAV-assisted IoT Data Collection Networks},
year={2021},
volume={},
number={},
pages={1-6},
abstract={Unmanned Aerial Vehicles (UAVs) have been emerging as an effective solution for IoT data collection networks thanks to their outstanding flexibility, mobility, and low operation costs. However, due to the limited energy and uncertainty from the data collection process, speed control is one of the most important factors while optimizing the energy usage efficiency and performance for UAV collectors. This work aims to develop a novel autonomous speed control approach to address this issue. To that end, we first formulate the dynamic speed control task of a UAV as a Markov decision process taking into account its energy status and location. In this way, the Q-learning algorithm can be adopted to obtain the optimal speed control policy for the UAV. To further improve the system performance, we develop a highly-effective deep dueling double Q-learning algorithm utilizing outstanding features of the deep neural networks as well as advanced dueling architecture to quickly stabilize the learning process and obtain the optimal policy. Through simulations, we show that our proposed solution can achieve up to 40% greater performance, i.e., an average throughput of the system, compared with other conventional methods. Importantly, the simulation results also reveal significant impacts of UAV's energy and charging time on the system performance.},
keywords={Uncertainty;System performance;Simulation;Velocity control;Process control;Data collection;Throughput;IoT;UAV;data collection;speed control;deep Q-learning;MDP;and deep dueling},
doi={10.1109/WCNC49053.2021.9417563},
ISSN={1558-2612},
month={March},}
@INPROCEEDINGS{8206296,
author={Albani, Dario and Nardi, Daniele and Trianni, Vito},
booktitle={2017 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)}, title={Field coverage and weed mapping by UAV swarms},
year={2017},
volume={},
number={},
pages={4319-4325},
abstract={The demands from precision agriculture (PA) for high-quality information at the individual plant level require to re-think the approaches exploited to date for remote sensing as performed by unmanned aerial vehicles (UAVs). A swarm of collaborating UAVs may prove more efficient and economically viable compared to other solutions. To identify the merits and limitations of a swarm intelligence approach to remote sensing, we propose here a decentralised multi-agent system for a field coverage and weed mapping problem, which is efficient, intrinsically robust and scalable to different group sizes. The proposed solution is based on a reinforced random walk with inhibition of return, where the information available from other agents (UAVs) is exploited to bias the individual motion pattern. Experiments are performed to demonstrate the efficiency and scalability of the proposed approach under a variety of experimental conditions, accounting also for limited communication range and different routing protocols.},
keywords={Robots;Remote sensing;Agriculture;Robustness;Unmanned aerial vehicles;Multi-agent systems;Optimization},
doi={10.1109/IROS.2017.8206296},
ISSN={2153-0866},
month={Sep.},}
@INPROCEEDINGS{9473735,
author={Huang, Zhihan and Xu, Xiaodong},
booktitle={2021 IEEE International Conference on Communications Workshops (ICC Workshops)}, title={DQN-Based Relay Deployment and Trajectory Planning in Consensus-Based Multi-UAVs Tracking Network},
year={2021},
volume={},
number={},
pages={1-7},
abstract={Currently, that multiple unmanned aerial vehicles (UAVs) complete the tracking tasks cooperatively has became an important development trend. However, in multi-UAVs tracking network, the mobility of tracking UAVs will seriously affect the performance of the network, resulting in frequent network interruption, prolonging convergence delay of consensus algorithm, and even unable to meet the tracking requirements. In this paper, we proposed an approach by deploying a relay UAV to improve the connectivity and consensus performance of the multi-UAVs tracking network. We divide the process of deploying relay UAV into two steps. Firstly, DQN-based deployment algorithm is proposed to obtain the initial position of relay UAV, whose energy consumption and consensus convergence delay of the tracking network are optimized. Secondly, during the movement of tracking UAVs, DQN-based trajectory planning algorithm is proposed, which effectively improves the consensus success probability and reduces the outage probability of the multi-UAVs tracking network. Simulations verify that the DQN-based algorithms have superior performances compared with existing works.},
keywords={Energy consumption;Tracking;Trajectory planning;Conferences;Probability;Unmanned aerial vehicles;Delays;multi-UAVs network;tracking;consensus;DQN;trajectory planning;relay},
doi={10.1109/ICCWorkshops50388.2021.9473735},
ISSN={2694-2941},
month={June},}
@INPROCEEDINGS{9149115,
author={Fragkos, Georgios and Kemp, Nicholas and Tsiropoulou, Eirini Eleni and Papavassiliou, Symeon},
booktitle={ICC 2020 - 2020 IEEE International Conference on Communications (ICC)}, title={Artificial Intelligence Empowered UAVs Data Offloading in Mobile Edge Computing},
year={2020},
volume={},
number={},
pages={1-7},
abstract={The advances introduced by Unmanned Aerial Vehicles (UAVs) are manifold and have paved the path for the full integration of UAVs, as intelligent objects, into the Internet of Things (IoT). This paper brings artificial intelligence into the UAVs data offloading process in a multi-server Mobile Edge Computing (MEC) environment, by adopting principles and concepts from game theory and reinforcement learning. Initially, the autonomous MEC server selection for partial data offloading is performed by the UAVs, based on the theory of the stochastic learning automata. A non-cooperative game among the UAVs is then formulated to determine the UAVs' data to be offloaded to the selected MEC servers, while the existence of at least one Nash Equilibrium (NE) is proven by exploiting the power of submodular games. A best response dynamics framework and two alternative reinforcement learning algorithms are introduced that converge to an NE, and their tradeoffs are discussed. The overall framework performance evaluation is achieved via modeling and simulation, in terms of its efficiency and effectiveness, under different operation approaches and scenarios.},
keywords={Servers;Games;Task analysis;Learning (artificial intelligence);Heuristic algorithms;Game theory;UAV Data Offloading;Mobile Edge Computing;Reinforcement Learning;Game Theory},
doi={10.1109/ICC40277.2020.9149115},
ISSN={1938-1883},
month={June},}
@ARTICLE{8924612,
author={Deng, Jianing and Shi, Zhiguo and Zhuo, Cheng},
journal={IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems}, title={Energy-Efficient Real-Time UAV Object Detection on Embedded Platforms},
year={2020},
volume={39},
number={10},
pages={3123-3127},
abstract={The recent technology advancement on unmanned aerial vehicle (UAV) has enabled diverse applications in vision-related outdoor tasks. Visual object detection is a crucial task among them. However, it is difficult to actually deploy detectors on embedded devices due to the challenges among energy consumption, accuracy, and speed. In this article, we address a few key challenges from the platform, application to the system, and propose an energy-efficient system for real-time UAV object detection on an embedded platform. The proposed system can achieve speed of 28.5 FPS and 2.7-FPS/W energy efficiency on the data set from 2018 low-power object detection challenges (LPODCs).},
keywords={Feature extraction;Object detection;Detectors;Real-time systems;Training;Task analysis;Unmanned aerial vehicles;Artificial neural networks;object detection;real-time systems;unmanned aerial vehicles},
doi={10.1109/TCAD.2019.2957724},
ISSN={1937-4151},
month={Oct},}
@INPROCEEDINGS{9369472,
author={Hoseini, Sayed Amir and Bokani, Ayub and Hassan, Jahan and Salehi, Shavbo and Kanhere, Salil S.},
booktitle={2021 IEEE 18th Annual Consumer Communications Networking Conference (CCNC)}, title={Energy and Service-Priority aware Trajectory Design for UAV-BSs using Double Q-Learning},
year={2021},
volume={},
number={},
pages={1-4},
abstract={Next generation mobile networks have proposed the integration of Unmanned Aerial Vehicles (UAVs) as aerial base stations (UAV-BS) to serve ground nodes. Despite the advantages of UAV-BSs, their dependence on the on-board, limited-capacity battery hinders their service continuity. Shorter trajectories can save flying energy, however UAV-BSs must also serve nodes based on their service priority since nodes' service requirements are not always the same. In this paper, we present an energy-efficient trajectory optimization for a UAV assisted IoT system in which the UAV-BS considers the IoT nodes' service priorities in making its movement decisions. We solve the trajectory optimization problem using Double Q- Learning algorithm. Simulation results reveal that the Q-Learning based optimized trajectory outperforms a benchmark algorithm, namely Greedily served algorithm, in terms of reducing the average energy consumption of the UAV-BS as well as the service delay for high priority nodes.},
keywords={Energy consumption;Simulation;Reinforcement learning;Benchmark testing;Unmanned aerial vehicles;Delays;Trajectory optimization},
doi={10.1109/CCNC49032.2021.9369472},
ISSN={2331-9860},
month={Jan},}
@INPROCEEDINGS{9581973,
author={Roychowdhury, Saurabh and Ghosh, Debalina},
booktitle={2021 2nd International Conference on Range Technology (ICORT)}, title={Machine Learning Based Classification of Radar Signatures of Drones},
year={2021},
volume={},
number={},
pages={1-5},
abstract={With the current popularity of drones and UAVs, there is an urgent need to be able to classify the aerial objects with sufficient accuracy. Hence, several methods have been proposed for classification of drones and UAVs. Such methods are often based on visual sources and thus classification becomes dependent on extraneous parameters. In contrast, the use of Radar Cross Section (RCS) for drone classification shows less dependency of extraneous parameters. Radar Cross Section (RCS) is a significant radar signature that is popularly used for identification of targets. In this paper, the primary objective is to demonstrate a viable solution to classify drones based on their RCS values. During the process, various classification algorithms such as Support Vector Machines, Decision Tree, Naive Bayes Classifier, Neural Networks have been investigated for performance and accuracy.},
keywords={Visualization;Radar cross-sections;Gaussian noise;Neural networks;Support vector machine classification;Machine learning;Robustness;RCS- Radar Cross Section;Machine Learning;Decision Tree;K Nearest Neighbour;Linear Discriminant Analysis;Naive Bayes;Additive White Gaussian Noise (AWGN);Long short-term memory(LSTM);Recurrent Neural Network (RNN);Support Vector Machine;Ensemble Classifier},
doi={10.1109/ICORT52730.2021.9581973},
ISSN={},
month={Aug},}
@INPROCEEDINGS{8906323,
author={Ghazzai, Hakim and Khattab, Ahmed and Massoud, Yehia},
booktitle={2019 IEEE International Conference on Vehicular Electronics and Safety (ICVES)}, title={Mobility and Energy Aware Data Routing for UAV-Assisted VANETs},
year={2019},
volume={},
number={},
pages={1-6},
abstract={In this paper, we develop a mobility and energy aware data routing protocol for unmanned aerial vehicle-assisted vehicular ad-hoc networks (UAV-assisted VANETs). One of the UAV act as a flying roadside Uunit (RSU) collecting data from ground vehicles, while the other UAVs play the role of relays to deliver the data to mobility service center (MSC). The UAVs can adjust their three-dimensional (3D) locations within a predefined range, if needed, in order to ensure reliable communication links. The proposed approach aims to minimize the energy consumed by the UAVs in both data transfer and movement. which ensures fair distribution of the routing effort across the different UAVs in the network. This is achieved by taking the residual UAV energy into account in the routing decision. We formulate such a routing problem as a mixed integer non-linear program (MINLP) to determine both the selected route and the locations of the UAVs participating in the data transfer process. Since such a problem is non-convex, we proceed with a joint optimization solution where the route is optimized using an ILP and the UAVs’ 3D locations are determined using the meta-heuristic particle swarm optimization (PSO) algorithm. We present a selected set of numerical results to illustrate the performance of the proposed solution for different scenarios and compare it to a meta-heuristic approach based on swarm intelligence.},
keywords={Data routing;flying RSU;vehicular ad-hoc networks;unmanned aerial vehicle},
doi={10.1109/ICVES.2019.8906323},
ISSN={2643-9751},
month={Sep.},}
@ARTICLE{9199789,
author={Zhu, Xuetian and Qi, Fei and Feng, Yi},
journal={IEEE Network}, title={Deep-Learning-Based Multiple Beamforming for 5G UAV IoT Networks},
year={2020},
volume={34},
number={5},
pages={32-38},
abstract={This article develops a novel hierarchical 5G Internet of Things network with unmanned aerial vehicles (UAVs) in the sky. In the proposed system, the leader UAV plays a vital role in the communication with ground base stations and other UAVs. The leader UAV relies on multiple beamforming to establish and maintain reliable broadband connections, which requires the location and altitude information of the UAV. Therefore, we propose a novel deep learning algorithm based on gated recurrent units and autoencoder for trajectory prediction and pose estimation. Simulation results show that this algorithm greatly improves the performance of the entire system, and has obvious advantages compared to traditional methods.},
keywords={Internet of Things;5G mobile communication;Unmanned aerial vehicles;Sensors;Task analysis;Logic gates;Trajectory},
doi={10.1109/MNET.011.2000035},
ISSN={1558-156X},
month={Sep.},}
@ARTICLE{9343827,
author={Chen, Ching-Ju and Huang, Ya-Yu and Li, Yuan-Shuo and Chen, Ying-Cheng and Chang, Chuan-Yu and Huang, Yueh-Min},
journal={IEEE Access}, title={Identification of Fruit Tree Pests With Deep Learning on Embedded Drone to Achieve Accurate Pesticide Spraying},
year={2021},
volume={9},
number={},
pages={21986-21997},
abstract={Tessaratoma papillosa (Drury) first invaded Taiwan in 2009. Every year, T. papillosa causes severe damage to the longan crops. Novel applications for edge intelligence are applied in this study to establish an intelligent pest recognition system to manage this pest problem. We used a detecting drone to photograph the pest and employed a Tiny-YOLOv3 neural network model built on an embedded system NVIDIA Jetson TX2 to recognize T. papillosa in the orchard to determine the position of the pests in real-time. The pests' positions are then used to plan the optimal pesticide spraying route for the agricultural drone. Apart from planning the optimized spraying of pesticide for the spraying drone, the TX2 embedded platform also transmits the position and generation of pests to the cloud to record and analyze the growth of longan with a computer or mobile device. This study enables farmers to understand the pest distribution and take appropriate precautions in real-time. The agricultural drone sprays pesticides only where needed, which reduces pesticide use, decreases damage to the environment, and increases crop yield.},
keywords={Drones;Agriculture;Image edge detection;Real-time systems;Deep learning;Computational modeling;Object detection;Edge intelligence;unmanned aerial vehicles (UAV);real-time embedded systems;slope land orchard;object detection;agricultural pests damage;precision agriculture;intelligent pest recognition},
doi={10.1109/ACCESS.2021.3056082},
ISSN={2169-3536},
month={},}
@INPROCEEDINGS{8610500,
author={Ali, Muntadher A. and Zeng, Yong and Jamalipour, Abbas},
booktitle={2018 IEEE International Symposium on Dynamic Spectrum Access Networks (DySPAN)}, title={Delay-Oriented Spectrum Sharing and Traffic Offloading in Coexisting UAV-Enabled Cellular and WiFi Networks},
year={2018},
volume={},
number={},
pages={1-7},
abstract={This paper studies an unmanned aerial vehicle (UAV)-enabled cellular system coexisting with WiFi network. By spectrum sharing and traffic offloading with the WiFi access point, our objective is to minimize the average delay of the users served by the UAV base station, while ensuring that the delay of the WiFi users is not greater than certain threshold, via jointly optimizing the spectrum allocation, the set of offloaded users and their offloaded traffic rates. The optimization problem is non-convex and difficult to be directly solved. We propose efficient sub-optimal solution via block coordinate descent method. Numerical results are provided to validate the proposed design.},
keywords={Wireless fidelity;Delays;Unmanned aerial vehicles;Artificial neural networks;Copper;Long Term Evolution;Dynamic spectrum access},
doi={10.1109/DySPAN.2018.8610500},
ISSN={2334-3125},
month={Oct},}
@INPROCEEDINGS{8824903,
author={Careem, Maqsood Ahamed Abdul and Gomez, Jorge and Saha, Dola and Dutta, Aveek},
booktitle={2019 16th Annual IEEE International Conference on Sensing, Communication, and Networking (SECON)}, title={HiPER-V: A High Precision Radio Frequency Vehicle for Aerial Measurements},
year={2019},
volume={},
number={},
pages={1-6},
abstract={There is a growing interest towards enabling practical, dynamic and agile wireless applications by systems of independent or cooperative mobile agents such as Unmanned Aerial Vehicles (UAVs). Such mobile UAVs are often constrained on resources like storage, power and radio capabilities and require accurate position information to facilitate many of these wireless applications. In this paper, we introduce HiPER-V, which is a generalized UAV prototype platform to enable a broad range of applications in wireless communications using a single UAV or can be extended to a swarm of UAVs. We implement HiPER-V by using an UAV, equipped with resource constrained radio devices, and high precision position information available via RTK-GPS modules, achieving a median position accuracy of 3.8 cm. The details of implementation of HiPER-V and its applicability to a wide variety of applications in wireless communications are presented in this paper. With minimal payload and simple software modification, our solution can be ported to any UAV platform and extended to multiple UAV testbeds that enable an array of research in wireless applications using UAVs.},
keywords={Inspection;Feature extraction;Task analysis;Training;Convolutional neural networks;Automation;Lighting;UAV testbed;UAV positioning;aerial wireless communications},
doi={10.1109/SAHCN.2019.8824903},
ISSN={2155-5494},
month={June},}
@INPROCEEDINGS{9553286,
author={K, Anjana N. J. and Murugan, Deepak and Singh, Dharmendra},
booktitle={2021 IEEE International Geoscience and Remote Sensing Symposium IGARSS}, title={An Information Fusion Approach of UAV and Satellite Data for Intra Field Classification},
year={2021},
volume={},
number={},
pages={347-350},
abstract={Intra field classification of agriculture fields is challenging using dual pol sentinel 1 data due to its limited spatial information. With the use of sensors mountable on unmanned aerial vehicles (UAV) that has a fine spatial resolution, it is easy to obtain intra-field information. However, the use of drones is expensive and their coverage is limited. Therefore, an information fusion approach is used to make intelligent use of high-resolution drone and freely available Sentine1-1 data to provide intra-field classification at large scale for precision agriculture monitoring. Supervised random forest, support vector machine and k-nearest neighborhood classifiers were trained using the polarimetric parameters obtained from dual pol Sentine1-1 data for the classification of sparse and dense vegetation in a large sugarcane field. The overall accuracy of the proposed method is above 84% in segregating sparse and dense sugarcane fields.},
keywords={Support vector machines;Radio frequency;Training;Satellites;Vegetation mapping;Agriculture;Spatial resolution;UAV;Sentinel 1;sparse vegetation;dense vegetation;machine learning classification},
doi={10.1109/IGARSS47720.2021.9553286},
ISSN={2153-7003},
month={July},}
@INPROCEEDINGS{9213856,
author={Bhagat, Sarthak and Sujit, P.B.},
booktitle={2020 International Conference on Unmanned Aircraft Systems (ICUAS)}, title={UAV Target Tracking in Urban Environments Using Deep Reinforcement Learning},
year={2020},
volume={},
number={},
pages={694-701},
abstract={Persistent target tracking in urban environments using UAV is a difficult task due to the limited field of view, visibility obstruction from obstacles and uncertain target motion. The vehicle needs to plan intelligently in 3D such that the target visibility is maximized. In this paper, we introduce Target Following DQN (TF-DQN), a deep reinforcement learning technique based on Deep Q-Networks with a curriculum training framework for the UAV to persistently track the target in the presence of obstacles and target motion uncertainty. The algorithm is evaluated through simulations. The results show that the UAV tracks the target persistently in diverse environments while avoiding obstacles on the trained environments as well as on unseen environments.},
keywords={Target tracking;Urban areas;Unmanned aerial vehicles;Training;Uncertainty;Cameras},
doi={10.1109/ICUAS48674.2020.9213856},
ISSN={2575-7296},
month={Sep.},}
@INPROCEEDINGS{8693023,
author={Islam, Shafkat and Razi, Abolfazl},
booktitle={2019 53rd Annual Conference on Information Sciences and Systems (CISS)}, title={A Path Planning Algorithm for Collective Monitoring Using Autonomous Drones},
year={2019},
volume={},
number={},
pages={1-6},
abstract={This paper presents a novel mission-oriented path planning algorithm for a team of Unmanned Aerial Vehicles (UAVs). In the proposed algorithm, each UAV takes autonomous decisions to find its flight path towards a designated mission area while avoiding collisions to stationary and mobile obstacles. The main distinction with similar algorithms is that the target destination for each UAV is not apriori fixed and the UAVs locate themselves such that they collectively cover a potentially time-varying mission area. One potential application for this algorithm is deploying a team of autonomous drones to collectively cover an evolving forest wildfire and provide virtual reality for fire fighters. We formulated the algorithm based on Reinforcement Learning (RL) with a new method to accommodate continuous state space for adjacent locations. To consider more realistic scenario, we assess the impact of localization errors on the performance of the proposed algorithm. Simulation results show that success probability for this algorithm is about 80% when the observation error variance is as high as 100 (SNR:-6dB).},
keywords={Drones;Path planning;Monitoring;Reinforcement learning;Mathematical model;Simulation;UAV networks;Reinforcement Learning;Virtual Reality;Wildfire Monitoring},
doi={10.1109/CISS.2019.8693023},
ISSN={},
month={March},}
@INPROCEEDINGS{8292474,
author={Ghazzai, Hakim and Feidi, Awatef and Menouar, Hamid and Ammari, Mohamed Lassaad},
booktitle={2017 IEEE 28th Annual International Symposium on Personal, Indoor, and Mobile Radio Communications (PIMRC)}, title={An exploratory search strategy for data routing in flying ad hoc networks},
year={2017},
volume={},
number={},
pages={1-7},
abstract={This paper investigates the problem of data routing in flying ad hoc networks (FANETs) composed of multiple flying nodes, i.e., unmanned aerial vehicles (UAVs), supported by communication platforms. The objective is to exploit the mobility of UAVs in order to establish routing paths and transfer a message between two ground nodes at minimum transmission time. Assuming that the UAVs are already deployed to execute a given primary task, the cooperation of the UAVs in the data transfer process, considered as a secondary task, becomes subject to three conditions. First, the energy consumed by each UAV has to respect the allocated budget for the data routing process. Second, the UAVs cannot move out of the boundaries of a tolerated and well-defined region in order to maintain the operation of the primary task. Finally, the UAVs need to reduce their traveled distances in order to reduce the delay of the transfer. A mixed non-linear integer programming problem determining the routing path and the new locations of the UAVs participating in the data transfer process is formulated. Due to its nonconvexity, we proceed with a deterministic exploratory strategy inspired from the Hooke-Jeeves algorithm to meet the problem goals. Selected numerical results investigate the performance of the proposed solution for different scenarios and compare some of them to those of a metaheuristic approach based on swarm intelligence.},
keywords={Routing;Data transfer;Task analysis;Ad hoc networks;Unmanned aerial vehicles;Search problems;Particle swarm optimization;Data routing;exploratory search strategy;flying ad hoc network;unmanned aerial vehicle},
doi={10.1109/PIMRC.2017.8292474},
ISSN={2166-9589},
month={Oct},}
@INPROCEEDINGS{8844074,
author={Bayu, Azady and Wibisono, Ari and Wisesa, Hanif Arief and Intizhami, Naili Suri and Jatmiko, Wisnu and Gamal, Ahmad},
booktitle={2019 IEEE International Conference on Communication, Networks and Satellite (Comnetsat)}, title={Semantic Segmentation of Lidar Point Cloud in Rural Area},
year={2019},
volume={},
number={},
pages={73-78},
abstract={A 3D surface modeling format that is commonly used today is point cloud. 3D surface model segmentation could provide data for analysis in various fields. In the context of Geographic Information Systems, point cloud data obtained from the Light Detection and Ranging (LiDAR) sensor are used by machines to automatically identify objects such as houses, buildings, land, and rivers. There has been many Deep Learning approach through Convolutional Neural Network (CNN) that has been proven to be very capable for 2-dimensional imagery classification and segmentation. PointNet is a Deep Learning architecture that is designed so that the point cloud format that is still tabular form, can be directly convoluted by the CNN model. In this study, an improvement of PointNet is proposed for Point Cloud data of Kupang City. The Point Cloud data were acquired using an Unmanned Aerial Vehicle with a LiDAR sensor installed. The data were pre-processed and divided into training and testing data. The data were processed with the PointNet architecture and the model was tested using several metrics. The experiment shows that the PointNet architecture is capable on segmenting Geographical Point Cloud Data. In addition, incorporating voxel's color features could increase the performance of the segmentation.},
keywords={Three-dimensional displays;Laser radar;Data models;Deep learning;Solid modeling;Image segmentation;Training;Point Cloud;Deep Learning;PointNet;LiDAR;Convolutional Neural Network},
doi={10.1109/COMNETSAT.2019.8844074},
ISSN={},
month={Aug},}
@INPROCEEDINGS{8977051,
author={Daviran, Richard and Quispe, Grimaldo and Chavez-Arias, Heyul and Raymundo-Ibañez, Carlos and Dominguez, Francisco},
booktitle={2019 IEEE 39th Central America and Panama Convention (CONCAPAN XXXIX)}, title={Design of an unmanned aerial system for the detection of dangerous areas during fires},
year={2019},
volume={},
number={},
pages={1-6},
abstract={This article presents the design of an unmanned aerial vehicle manufactured in aramid, through the use of sensors and actuators for flight stabilization, capturing the images through a thermal imager and its wireless transmission for ground processing for application in the social security area used in fire accidents. The work shows that it is feasible to use the aramid material for the construction of the prototype, since it is a high temperature resistant material, also the integration of neural networks for semi-automatic flight control. The results of this research will serve to develop more advanced control devices, with simple components and controls so that people with technological limitations can use it, so that they can save lives in danger, that of their colleagues or themselves.},
keywords={Aramid;Unmanned Aerial Vehicle;neural network;Save lives},
doi={10.1109/CONCAPANXXXIX47272.2019.8977051},
ISSN={},
month={Nov},}
@INPROCEEDINGS{9315423,
author={Pethő, Máté and Nagy, Ádám and Zsedrovits, Tamás},
booktitle={2020 3rd International Seminar on Research of Information Technology and Intelligent Systems (ISRITI)}, title={A bio-motivated vision system and artificial neural network for autonomous UAV obstacle avoidance},
year={2020},
volume={},
number={},
pages={632-637},
abstract={Unmanned aerial vehicles (UAVs) becoming more and more common. They show excellent potential for multiple types of autonomous work, although they must achieve these tasks safely. For flight-safety, it must be assured that the UAV will avoid collision with any objects in its flight path during autonomous operations. Computer vision and artificial neural networks have shown to be effective in many applications. However, biological vision systems and the brain areas responsible for visual processing may hold solutions capable of acquiring information effectively. We are proposing a novel system, which performs visual cue extraction with algorithms based on the structure and functionality of the retina and the visual cortex of the mammalian visual system, and a convolutional neural network processing data to detect a predefined obstacle using the onboard camera of the UAV. We also examined the effect of preprocessing on calculation time and recognition effectiveness.},
keywords={Visualization;Training;Retina;Task analysis;Image edge detection;Image color analysis;Feature extraction;UAV;bio-motivated;convolutional neural networks;computer vision;obstacle avoidance},
doi={10.1109/ISRITI51436.2020.9315423},
ISSN={},
month={Dec},}
@INPROCEEDINGS{9476879,
author={Arnegaard, Ola Tranum and Leira, Frederik S. and Helgesen, Håkon H. and Kemna, Stephanie and Johansen, Tor A.},
booktitle={2021 International Conference on Unmanned Aircraft Systems (ICUAS)}, title={Detection of objects on the ocean surface from a UAV with visual and thermal cameras: A machine learning approach},
year={2021},
volume={},
number={},
pages={81-90},
abstract={Unmanned aerial vehicles (UAVs) can provide great value in off-shore operations that require aerial surveillance, for example by detecting objects on the water surface. For efficient operations by autonomous aerial surveillance, a reliable automatic detection system must be in place: one that will limit the amount of false negatives, but not at the expense of too many false positives. In this paper, we assess multiple aspects of the detection system that may provide significant impact in off-shore aerial surveillance: First by assessing detection architectures based on convolutional neural networks, then by adding tracking algorithms to utilize temporal information, and finally by investigating the use of different imaging modalities. Through a comparison of several detection models, the experiments prove that misclassification of objects is a particular issue, where input resolution and size of objects influence the overall model performance. The use of a tracking algorithm allows for decreasing the confidence threshold, which results in fewer false negatives, without a significant increase in false positives. In addition, comparing information obtained from visual and thermal imaging systems shows that these modalities provide complementary information in the presence of sunlight reflection.},
keywords={Visualization;Sea surface;Surveillance;Video sequences;Unmanned aerial vehicles;Reflection;Synchronization},
doi={10.1109/ICUAS51884.2021.9476879},
ISSN={2575-7296},
month={June},}
@INPROCEEDINGS{9024648,
author={Hou, Meng-Chun and Deng, Der-Jiunn and Wu, Chia-Ling},
booktitle={2019 IEEE Globecom Workshops (GC Wkshps)}, title={Optimum Aerial Base Station Deployment for UAV Networks: A Reinforcement Learning Approach},
year={2019},
volume={},
number={},
pages={1-6},
abstract={The boom of unmanned aerial vehicles (UAVs) is projected to fundamentally shift paradigms of transportations, logistics, agricultures, and public safety as a dominating unmanned application in following decades. To optimally process assigned tasks, each UAV requires prompt and ubiquitous information provisioning regarding the varying operation conditions, which renders exploiting base stations (BSs) of existing wireless infrastructures a tractable solution. To receive services from a BS, a UAV should stay within the coverage area of a BS, which however limits the operation range of a UAV. This obstacle thus drives the deployment of a special sort of UAV, known as an aerial base station (ABS), to relay signals between a BS and a UAV. Based on different flight paths of UAVs, an ABS should autonomously decide its own flight trajectory so as to maximize the number of UAVs which can receive wireless services. However, the inherently non-stationary environment renders the optimum autonomous deployment of an ABS a challenging issue. Inspired by the merit of interacting with the environment, we consequently propose a reinforcement learning scheme to optimize the flight trajectory of an ABS. To eliminate the engineering concern in the conventional Q-learning scheme that most state-action pairs may not be fully visited in the deployment of an ABS, in this paper, a state-amount-reduction (SAR) k-step Q-learning scheme is proposed to avoid the issue in the conventional Q-learning, so as to maximize the number of UAVs receiving services from an ABS. Through providing analytical foundations and simulation studies, outstanding performance of the proposed schemes is demonstrated as compared with that of the conventional reinforcement learning based ABS deployment.},
keywords={Learning (artificial intelligence);Trajectory;Wireless communication;Unmanned aerial vehicles;Optimization;Base stations;Task analysis},
doi={10.1109/GCWkshps45667.2019.9024648},
ISSN={},
month={Dec},}
@INPROCEEDINGS{9636183,
author={Yan, Chao and Xiang, Xiaojia and Wang, Chang and Lan, Zhen},
booktitle={2021 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)}, title={Flocking and Collision Avoidance for a Dynamic Squad of Fixed-Wing UAVs Using Deep Reinforcement Learning},
year={2021},
volume={},
number={},
pages={4738-4744},
abstract={Developing the flocking behavior for a dynamic squad of fixed-wing UAVs is still a challenge due to kinematic complexity and environmental uncertainty. In this paper, we deal with the decentralized flocking and collision avoidance problem through deep reinforcement learning (DRL). Specifically, we formulate a decentralized DRL-based decision making framework from the perspective of every follower, where a collision avoidance mechanism is integrated into the flocking controller. Then, we propose a novel reinforcement learning algorithm PS-CACER for training a shared control policy for all the followers. Besides, we design a plug-n-play embedding module based on convolutional neural networks and the attention mechanism. As a result, the variable-length system state can be encoded into a fixed-length embedding vector, which makes the learned DRL policy independent with the number and the order of followers. Finally, numerical simulation results demonstrate the effectiveness of the proposed method, and the learned policies can be directly transferred to semi-physical simulation without any parameter finetuning.},
keywords={Training;Uncertainty;Heuristic algorithms;Reinforcement learning;Kinematics;Numerical simulation;Numerical models},
doi={10.1109/IROS51168.2021.9636183},
ISSN={2153-0866},
month={Sep.},}
@INPROCEEDINGS{9389305,
author={Langenkämper, Daniel and Möller, Torben and Brün, Daniel and Wilhelm Nattkemper, Tim},
booktitle={Global Oceans 2020: Singapore – U.S. Gulf Coast}, title={Efficient visual monitoring of offshore windmill installations with online image annotation and deep learning computer vision},
year={2020},
volume={},
number={},
pages={1-6},
abstract={The number of offshore windmills keeps growing around the world since they are an essential part of any strategy to produce energy without using nuclear power plants or burning fossil resources. Due to the growing number of installations new monitoring and inspection strategies and routines need to be developed that are not only effective but efficient. In this work we will present first results from a joint project of industry partners and academia that aims at the development of new approaches making use of modern imaging technologies and new methods from artificial intelligence and computer vision research. We investigate three different strategies for collecting digital photos or video and posterior computational analysis using Convolutional Neural Networks (CNN). Our results indicate, that patterns of interest like rust or coating damage can be detected and classified with F1 scores between 0.80 and 0.94 in photos collected by inspectors. In videos collected with unmanned aerial vehicles (UAV) rust patterns, oils spills and coating damage were detected with F1= 0.91. To support users in the time-consuming task of visual data exploration, we present a new visualization method referred to as “virtual twin”. Using hand - recorded image collections, a data-driven 3D model of a windmill is generated, that can be used to investigate damage patterns in the full context of the windmill and in full detail. Altogether our results indicate, that although each single approach has its limitations, a combination of different imaging methods, deep learning computer vision algorithms and sophisticated visual data exploration by experienced users appears to have potential to overcome the bottleneck in data analysis, interpretation and decision making in the context of the future inspections of offshore windmills, platforms or other constructions.},
keywords={Visualization;Computer vision;Data visualization;Training data;Inspection;Unmanned aerial vehicles;Monitoring;Inspection;Offshore windmill;Offshore wind turbine;Unmanned Aerial Vehicles;Computer vision;Deep Learning;Artificial Intelligence},
doi={10.1109/IEEECONF38699.2020.9389305},
ISSN={0197-7385},
month={Oct},}
@INPROCEEDINGS{8407558,
author={Cheng, Haiyan and Chen, Rui and Wang, Jinna and Liu, Xinyue and Zhang, Muliu and Zhai, Yongjie},
booktitle={2018 Chinese Control And Decision Conference (CCDC)}, title={Study on insulator recognition method based on simulated samples expansion},
year={2018},
volume={},
number={},
pages={2569-2573},
abstract={In the application of the deep learning to the unmanned aerial vehicle (UAV) autonomous inspection, a problem about the insufficiency of both quantity and quality for insulator images emerges. In the light of this situation, a sample expansion method based on a combination of statute and 3D modelling technology is proposed. Its feasibility is verified in a deep convolutional neural network by using five kinds of insulator simulated samples. The classification accuracy acquired by the proposed method is higher verified by the comparison of the experimental results, which proves its superiority to the traditional method containing no simulated samples. It is concluded that the simulated intensive samples of pure background have a significant effect on the accuracy of network classification. And when the ratio of real samples to simulated intensive samples goes to an appropriate value, the classification has the best accuracy.},
keywords={Insulators;Training;Databases;Machine learning;Inspection;Power transmission lines;Ceramics;3D modelling;Simulated intensive samples;Deep learning;Insulators},
doi={10.1109/CCDC.2018.8407558},
ISSN={1948-9447},
month={June},}
@INPROCEEDINGS{9093759,
author={Yang, Bo and Wu, Hsiang-Huang and Cao, Xuelin and Li, Xiangfang and Kroecker, Timothy and Han, Zhu and Qian, Lijun},
booktitle={IEEE INFOCOM 2019 - IEEE Conference on Computer Communications Workshops (INFOCOM WKSHPS)}, title={Intelli-Eye: An UAV Tracking System with Optimized Machine Learning Tasks Offloading},
year={2019},
volume={},
number={},
pages={1-6},
abstract={The unmanned aerial vehicles (UAVs) have been extensively used in providing intelligence such as target tracking. In our field experiments, a pre-trained deep neural network (DNN) is deployed on the UAV to identify a target from the captured video frames and enable UAV to keep tracking. However, tracking in real time by the DNN requires a lot of computational resources. This motivates us to consider offloading this type of machine learning (ML) tasks to a mobile edge computing (MEC) server. Specifically, we propose a novel hierarchical ML tasks distribution framework for the UAV tracking system, where the UAV is embedded with lower layers of the pre-trained convolutional neural network (CNN) model due to its limited computing capability, while the MEC server with rich computing resources will handle the higher layers of the CNN model. An optimization problem is formulated to minimize the CNN inference delay while taking into account the communications delay, computing time, and ML error. Insights are provided to understand the tradeoff between communications and ML computing in offloading decisions. Numerical results demonstrate the effectiveness of the proposed ML tasks distribution framework with the optimized offloading strategy.},
keywords={Task analysis;Delays;Computational modeling;Unmanned aerial vehicles;Target tracking;Streaming media;Wireless communication},
doi={10.1109/INFOCOMWKSHPS47286.2019.9093759},
ISSN={},
month={April},}
@INPROCEEDINGS{7857214,
author={Kim, Seonghyun and Lee, Wonjae and Park, Young-su and Lee, Hyun-Woo and Lee, Yong-Tae},
booktitle={2016 3rd International Conference on Information and Communication Technologies for Disaster Management (ICT-DM)}, title={Forest fire monitoring system based on aerial image},
year={2016},
volume={},
number={},
pages={1-6},
abstract={Since natural disaster annually leads to casualties and property damages, developments for ICT-based disaster management techniques are fostering to minimize economic and social losses. For this reason, it is essential to develop a customized response technology for a natural disaster. In this paper, we introduce a smart-eye platform which is developed for disaster recognition and response. In addition, we propose a deep-learning based forest fire monitoring technique, which utilizes images acquired from an unmanned aerial vehicle with an optical sensor. Via training for image set of past forest fires, the proposed deep-learning based forest fire monitoring technique is designed to be able to make human-like judgement for a new input image automatically whether forest fire exists or not. Through simulation results, the algorithm architecture and detection accuracy of the proposed scheme is verified. By applying the proposed automatic disaster recognition technique to decision support system for disaster management, we expect to reduce losses caused by disasters and costs required for disaster monitoring and response.},
keywords={Decision support systems;Forest fire monitoring;deep-learning;decision support technology;disaster management},
doi={10.1109/ICT-DM.2016.7857214},
ISSN={},
month={Dec},}
@INPROCEEDINGS{9409002,
author={Zhang, Yu and Zhang, Yan and Shi, Zhiguang and Shi, Xiaoran and Liu, Di and Suo, Yuchang},
booktitle={2021 6th International Conference on Intelligent Computing and Signal Processing (ICSP)}, title={Research on Evaluation Method of Image Blending Based Image Simulation},
year={2021},
volume={},
number={},
pages={759-764},
abstract={Object detection and tracking algorithms for specific targets are important technologies in the fields of autonomous driving and video surveillance. The verification of related algorithms and the training of data-driven machine learning methods often rely on high-quality and large-scale data support. Therefore, data simulation methods are usually used to supplement the quantity and richness of data. This paper proposes an image simulation performance evaluation method based on the Probably Approximately Correct (PAC) learnable theory: experience consistency loss, which is used to quantitatively evaluate simulated images. Compared with the traditional performance evaluation method based on expert score and Turing test, this evaluation method can objectively and quantitatively reflect the characteristic consistency between the simulated image and the real image. The experimental results show that the evaluation results of this method are consistent with the qualitative analysis results, which can directly reflect the performance improvement of the simulation image for the machine learning model.},
keywords={Performance evaluation;Training;Analytical models;Machine learning algorithms;Target tracking;Computational modeling;Machine learning;evaluation index;image blending;Unmanned Aerial Vehicle (UAV) detection;data enhancement;image simulation},
doi={10.1109/ICSP51882.2021.9409002},
ISSN={},
month={April},}
@INPROCEEDINGS{9253816,
author={Opitz, Felix and Mohrdieck, Camilla and Dästner, Kaeye and Corcuera, Juan Jose Navarro and Schmid, Elke and Roseneckh-Köhler, Bastian von Hassler zu},
booktitle={2020 21st International Radar Symposium (IRS)}, title={Data Analytics, Machine Learning and Risk Assessment for Surveillance and Situation Awareness},
year={2020},
volume={},
number={},
pages={173-178},
abstract={Modern surveillance networks are able to provide trajectories of all kinds for aircrafts and vessels worldwide or at least in extended areas of the airspace or earth surface. Best known are Automatic Dependent Surveillance - Broadcast (ADS-B) and (Satellite-) Automatic Identification System (AIS) used in air and maritime surveillance. Both of them are cooperative systems. Besides these sources, sensors based on ground installations or mounted on airborne and space-based platforms deliver object trajectories independently of any transponders. This is done by advanced tracking and fusion algorithms generating trajectories out of sensor measurements. Examples include GMTI radar-based systems operating on UAV platforms or imaging systems based on high altitude pseudo satellites (HAPS) and satellites. These surveillance systems enable a continuous extraction of mid- and long-term trajectories of objects. Besides the trajectory generation, the challenge will be to place them into the right context and to provide situational awareness. This includes the estimation of the intents of the tracked objects, activity-based intelligence, and the determination of patterns of life. Otherwise, even modern surveillance systems are not able to take a real advantage of the gathered data. Therefore, trajectories are further processed by data analytics and machine learning. Unsupervised machine learning offers techniques to cluster and to partition trajectories, extract highly frequented routes and points of interest, predict object movement and identify anomalous behaviour. On the other hand, transponder and broadcast systems provide additional attributes of the tracked trajectories. These labels pave the way for numerous supervised machine learning methods. The derived predictors realise the determination of object types and activities. Finally, these new data analytic techniques have to be integrated in existing near real time surveillance systems. This requires specific system architectures as well as a completely new software and hardware landscape. In summary, trajectory-based data analytics, machine learning and risk assessment are embedded on local or global clouds and use dedicated mechanisms for distributed and parallel processing.},
keywords={Data analysis;Surveillance;Machine learning;Radar tracking;Trajectory;Sensors;Transponders;Radar;ADS-B;AIS;Data Analytics;Machine Learning;Activity based Intelligence;Data Fusion},
doi={10.23919/IRS48640.2020.9253816},
ISSN={2155-5753},
month={Oct},}
@ARTICLE{8675170,
author={Chen, Wuhui and Liu, Baichuan and Huang, Huawei and Guo, Song and Zheng, Zibin},
journal={IEEE Network}, title={When UAV Swarm Meets Edge-Cloud Computing: The QoS Perspective},
year={2019},
volume={33},
number={2},
pages={36-43},
abstract={In this article, we propose a hybrid computing model, UAV-Edge-Cloud, bringing edge/cloud computing and UAV swarm together to achieve high quality of service (QoS) guarantees. First, we design this novel hybrid computing framework to provide powerful resources to support resource-intensive applications and real-time tasks at edge networks. Next, we discuss some potential applications for smart cities and raise open research issues of the proposed hybrid framework. We then study a joint task placement and routing problem for latency-critical applications as a case study. Finally, the simulation results show that our approach can improve the QoS of UAV swarms effectively.},
keywords={Cloud computing;Task analysis;Computational modeling;Unmanned aerial vehicles;Quality of service;Real-time systems;Big Data;Smart cities;Internet of Things},
doi={10.1109/MNET.2019.1800222},
ISSN={1558-156X},
month={March},}
@INPROCEEDINGS{8453468,
author={Vankadari, Madhu Babu and Das, Kaushik and Shinde, Chinmay and Kumar, Swagat},
booktitle={2018 International Conference on Unmanned Aircraft Systems (ICUAS)}, title={A Reinforcement Learning Approach for Autonomous Control and Landing of a Quadrotor},
year={2018},
volume={},
number={},
pages={676-683},
abstract={This paper looks into the problem of precise autonomous landing of an Unmanned Aerial Vehicle (UAV) which is considered to be a difficult problem as one has to generate appropriate landing trajectories in presence of dynamic constraints, such as, sudden changes in wind velocities and directions, downwash effects, change in payload etc. The problem is further compounded due to uncertainties arising from inaccurate model information and noisy sensor readings. The problem is partially solved by proposing a Reinforcement Learning (RL) based controller that uses Least Square Policy Iteration (LSPI) to learn the optimal control policies required for generating these trajectories. The efficacy of the approach is demonstrated through both simulation and real-world experiments with actual Parrot AR drone 2.0. According to our study, this is the first time such experimental results have been presented using RL based controller for drone landing, making it a novel contribution in this field.},
keywords={Drones;Learning (artificial intelligence);Computational modeling;Trajectory;Uncertainty;Training;Mathematical model},
doi={10.1109/ICUAS.2018.8453468},
ISSN={2575-7296},
month={June},}
@INPROCEEDINGS{7967526,
author={Chen, Yuepeng and Hu, Xia and Zhang, Qingyong and Zhang, Cong},
booktitle={2017 32nd Youth Academic Annual Conference of Chinese Association of Automation (YAC)}, title={Research on multi-classification method of UAV sensor fault based on wavelet entropy and AFWA-BP neural network},
year={2017},
volume={},
number={},
pages={837-842},
abstract={According to the characteristics of high flexibility, high frequency of fault and difficult to detect real-time of the UAV, fault classification model by the Back Propagation neural network based on wavelet entropy and adaptive fireworks algorithm has been proposed. The fault signal can be analyzed locally with wavelet packet entropy, then extract the feature vector, which is used to express the feature state of the UAV in different sensor faults. For the sack of the defects of the BP neural network algorithm, such as low convergence speed and easy to fall into the local minimum value, we update and optimize the weights and thresholds of the BP neural network by adaptive fireworks algorithm, which is based on the best fireworks individual analyzed by the immune concentration idea. The experiment results show that the convergence speed of the network is faster, the error of function approximation is smaller and fault classification accuracy is higher compared with PSO-BP and GA-BP algorithm.},
keywords={Entropy;Feature extraction;Explosions;Biological neural networks;Convergence;wavelet entropy;adaptive fireworks algorithm;UAV;sensor faults;BP neural networks},
doi={10.1109/YAC.2017.7967526},
ISSN={},
month={May},}
@ARTICLE{9557763,
author={Fan, Bo and Jiang, Li and Chen, Yanyan and Zhang, Ye and Wu, Yuan},
journal={IEEE Transactions on Intelligent Transportation Systems}, title={UAV Assisted Traffic Offloading in Air Ground Integrated Networks With Mixed User Traffic},
year={2021},
volume={},
number={},
pages={1-11},
abstract={The air ground integrated networks can leverage unmanned aerial vehicle (UAV) communications to tackle the ever-increasing and unbalanced traffic load in future communication systems. This paper investigates the UAV enabled traffic offloading problem in air ground integrated networks with mixed user traffic. The problem jointly maximizes the system load balance and the total UAV reward, which can be formulated under a two-layer network graph model. In the cellular network graph, the association between the delay-sensitive users and the access points (APs) as well as the association between the UAVs and the APs are formulated. In the UAV network graph, the association between the delay-insensitive users and the UAVs is formulated. By observing the coupling relationship of the decision variables, we decouple the problem into three sub-problems and solve the first two sub-problems with reduced complexity. Then, we devise a Deep Neural Network (DNN) empowered genetic algorithm to solve the last sub-problem. The DNN can be leveraged to filter out the non-optimal solutions in the initialization operator of the genetic algorithm for improving the efficiency. Performance comparisons are provided between the proposed traffic offloading scheme and the existing ones, which validate the advantages of the DNN empowered genetic algorithm regarding its convergence, accuracy, and robustness.},
keywords={Unmanned aerial vehicles;Trajectory;Genetic algorithms;Delays;Load modeling;Cellular networks;Transportation;Air ground integrated networks;traffic offloading;deep learning;intelligent algorithms.},
doi={10.1109/TITS.2021.3115462},
ISSN={1558-0016},
month={},}
@INPROCEEDINGS{9665191,
author={Wastupranata, Leonard Matheus and Munir, Rinaldi},
booktitle={2021 IEEE International Conference on Aerospace Electronics and Remote Sensing Technology (ICARES)}, title={UAV Detection using Web Application Approach based on SSD Pre-Trained Model},
year={2021},
volume={},
number={},
pages={1-6},
abstract={UAV development is being intensively developed by various groups to help overcome various types of problems. Object Detection is important in helping UAVs to do drone chasing and other competition that need visual approach based on image processing and deep learning. Unfortunately, the computational capabilities of the onboard processing unit that attached to the UAV are less than optimal for object detection due to storage and memory size constraints. This paper aims to create the new approach to improve the precision and recall during UAV detection by using web application to do real time detection. To decide a pre-trained model, it is necessary to compare which SSD pre-trained model is suitable to be deployed in this web application. The results obtained are that using the web application approach is better than the onboard processing approach with a high level of precision and recall with an average precision value of 0.85 and an average recall value of 0.837.},
keywords={Deep learning;Visualization;Runtime;Computational modeling;Image processing;Memory management;Object detection;UAV;object detection;SSD;web application;deep learning},
doi={10.1109/ICARES53960.2021.9665191},
ISSN={},
month={Nov},}
@INPROCEEDINGS{9594300,
author={Gopalakrishnan, Shreevanth Krishnaa and Al-Rubaye, Saba and Inalhan, Gokhan},
booktitle={2021 IEEE/AIAA 40th Digital Avionics Systems Conference (DASC)}, title={Adaptive UAV Swarm Mission Planning by Temporal Difference Learning},
year={2021},
volume={},
number={},
pages={1-10},
abstract={The prevalence of Unmanned Aerial Vehicles (UAVs) in precision agriculture has been growing rapidly. This paper tackles the UAV global mission planning problem by incorporating a greater capacity for human-machine teaming in the architecture of a flexibly autonomous, near-fully-distributed Mission Management System for UAV swarms. Subsequently, the two problems of global mission planning are solved simultaneously using an integrated solution. This consists of a geometric clustering algorithm which prioritizes the minimization of overall mission time, and an off-policy, model-free Temporal Difference Learning global agent capable of learning about an initially unknown mission environment through simulations. The latter component makes the solution adaptive to missions with different requirements.},
keywords={Adaptation models;Adaptive systems;Clustering algorithms;Reinforcement learning;Minimization;Unmanned aerial vehicles;Agriculture;Reinforcement Learning;Temporal Difference Learning;UAV;Global Mission Planning;Precision Agriculture},
doi={10.1109/DASC52595.2021.9594300},
ISSN={2155-7209},
month={Oct},}
@INPROCEEDINGS{9322548,
author={Bryan Lim, Wei Yang and Huang, Jianqiang and Xiong, Zehui and Kang, Jiawen and Niyato, Dusit and Hua, Xian-Sheng and Leung, Cyril and Miao, Chunyan},
booktitle={GLOBECOM 2020 - 2020 IEEE Global Communications Conference}, title={Multi-Dimensional Contract-Matching for Federated Learning in UAV-Enabled Internet of Vehicles},
year={2020},
volume={},
number={},
pages={1-6},
abstract={Beyond ground data sources, Unmanned Aerial Vehicles (UAVs) based service providers for data collection and AI model training, i.e., Drones-as-a-Service (DaaS), is increasingly popular in the Internet of Vehicles (IoV) applications in recent years. However, the stringent regulations governing data privacy potentially impedes data sharing across independently owned UAVs. To this end, we propose the adoption of a Federated Learning (FL) based approach to enable privacy-preserving collaborative Machine Learning for the development of IoV applications, e.g., for traffic prediction and car park occupancy management. Given the information asymmetry and incentive mismatches between the UAVs and model owner, we leverage on the self-revealing properties of a multi-dimensional contract to ensure truthful reporting of the UAV types, while accounting for the multiple sources of heterogeneity, e.g., in sensing and transmission costs. Then, we adopt the Gale-Shapley algorithm to match the lowest cost UAV to each subregion. The simulation results validate the incentive compatibility of our contract design and shows the efficiency of our matching.},
keywords={Data models;Contracts;Sensors;Computational modeling;Unmanned aerial vehicles;Training;Task analysis;Federated Learning;Incentive Mechanism;Unmanned Aerial Vehicles;Contract theory;Matching},
doi={10.1109/GLOBECOM42002.2020.9322548},
ISSN={2576-6813},
month={Dec},}
@INPROCEEDINGS{8761112,
author={Ren, Huan and Li, Lixin and Xu, Wenjun and Chen, Wei and Han, Zhu},
booktitle={ICC 2019 - 2019 IEEE International Conference on Communications (ICC)}, title={Machine Learning-Based Hybrid Precoding with Robust Error for UAV mmWave Massive MIMO},
year={2019},
volume={},
number={},
pages={1-6},
abstract={Unmanned aerial vehicles (UAVs) can now be considered as aerial base stations (BSs) to support ultra-reliable and low-latency communications by establishing line-of-sight (LoS) connections to ground users. Moreover, combining UAVs with millimeter wave (mmWave) massive multiple-input multiple-output (MIMO) will be a promissing solution. It can provide potentially high capacity wireless services due to their aerial positions and their ability to deploy on demand at specific locations. In this paper, we propose a low-cost and energy-efficient hybrid precoding architecture for UAVs, where the antenna part is realized by lens array. We investigate an efficient and energy-saving hybrid precoding scheme with robustness, which is inspired by the cross-entropy (CE) optimization in machine learning and the relative error estimation optimization. As for each selection of the hybrid precoders for obtaining the optimized precoder, we regarded it as a training process in machine learning, in which the training target is the CE-loss function between the predicted precoders and the target precoders. It aims to minimize the relative error between the predicted and actual values for optimizing the probability distributions of the elements in the analog hybrid precoder. Simulation results show that our proposed scheme can achieve higher sum rate and energy efficiency.},
keywords={Precoding;Radio frequency;Antenna arrays;Lenses;MIMO communication;Computer architecture;Optimization},
doi={10.1109/ICC.2019.8761112},
ISSN={1938-1883},
month={May},}
@INPROCEEDINGS{9124741,
author={Wang, Yue-Jiao and Ma, Zhong and Tang, Xue-Han and Wang, Zhu-Ping},
booktitle={2019 IEEE International Conference on Unmanned Systems and Artificial Intelligence (ICUSAI)}, title={Autonomous Obstacle Avoidance Algorithm of UAVs for Automatic Terrain Following Application},
year={2019},
volume={},
number={},
pages={309-314},
abstract={Autonomous obstacle avoidance flight is a key capability for unmanned aerial vehicles (UAVs) in the automatic terrain following application, which ensures that the UAVs can perform complex, versatile and difficult movements in the flight. Existing obstacle avoidance methods such as the visual SLAM, generally require artificially specifying the feature values that need to be extracted and are susceptible to illumination and obstacle positions. While artificial intelligence technology has made breakthroughs in many fields, the advantages of the neural networks overcome these shortcomings. Therefore, we propose an autonomous obstacle avoidance algorithm using deep reinforcement learning method. Concretely, a virtual three-dimensional visual simulation environment is established firstly, which simulates the flight states of the UAV and output the state image in real time according to the control decision. A deep convolutional neural network is then built as the brain of the intelligent agent, which takes the state image of the UAV as input, and outputs the discretized control decision to control the UAV. Moreover, The Deep Q Network method is employed to train the convolutional neural network in an autonomous way, that is the intelligent agent can try to control the UAV to avoidance the obstacle by itself. After training, the UAV is controlled by the trained convolutional neural network to complete the autonomous obstacle avoidance task during the flight. This algorithm is realized through continuous self-learning and self-evolution, which enables the UAVs to utilize visual information in complex scenes, adjust flight height in real time according to terrain height and obstacle height. The research results will have a strong application prospects in both military and civilian areas.},
keywords={Autonomous obstacle avoidance;Automatic terrain following application;Deep reinforcement learning;Convolutional neural network;Deep Q Network},
doi={10.1109/ICUSAI47366.2019.9124741},
ISSN={},
month={Nov},}
@INPROCEEDINGS{9264486,
author={Luo, Siyu and Liu, Junkai and Chen, Siyu and Chen, Jienan and Guo, Jifeng},
booktitle={2020 IEEE 16th International Conference on Control Automation (ICCA)}, title={Intelligent joint trajectory design and resource allocation in UAV-based data harvesting system},
year={2020},
volume={},
number={},
pages={1378-1383},
abstract={With the development of Internet of Things (IoT) technology, wireless sensor networks (WSNs) composed of multiple sensor nodes (SNs) have been able to provide a large number of high-quality services, such as continuous environmental monitoring, automatic control, and transmission of data for intelligent decision-making. SNs in WSNs are typically energy limited and often exist in large numbers, which are widely distributed in hard-to-reach areas. Hence, it is difficult to collect data from SNs without infrastructure support such as base stations (BSs). The low cost and high maneuverability of unmanned aerial vehicles (UAVs) provide an efficient solution for data acquisition in WSNs but with the challenge of control system of the UAV. In this paper, we proposed a deep reinforcement learning based UAV control system to intelligently solve the data harvesting problem in WSNs. Our optimization target is to jointly optimize the trajectory of the UAV and the bandwidth resources of the airborne base station to maximize the data acquisition success rate when the UAV is limited in energy. The objective function and constraints of this problem are highly non-convex. To solve this problem, we first modeled the movement of the UAV and the bandwidth allocation of the airborne base station in each time slot as a Markov decision process (MDP). Then we designed a deep reinforcement learning architecture to solve the above MDP. Compared with the existing data harvesting algorithms, the proposed method has a great improvement in data acquisition success rate.},
keywords={Unmanned aerial vehicles;Trajectory;Wireless sensor networks;Bandwidth;Schedules;Data acquisition;Fading channels},
doi={10.1109/ICCA51439.2020.9264486},
ISSN={1948-3457},
month={Oct},}
@ARTICLE{9369882,
author={Yu, Ziquan and Zhang, Youmin and Jiang, Bin and Su, Chun-Yi and Fu, Jun and Jin, Ying and Chai, Tianyou},
journal={IEEE Transactions on Neural Networks and Learning Systems}, title={Fractional-Order Adaptive Fault-Tolerant Synchronization Tracking Control of Networked Fixed-Wing UAVs Against Actuator-Sensor Faults via Intelligent Learning Mechanism},
year={2021},
volume={32},
number={12},
pages={5539-5553},
abstract={This article presents an enhanced fault-tolerant synchronization tracking control scheme using fractional-order (FO) calculus and intelligent learning architecture for networked fixed-wing unmanned aerial vehicles (UAVs) against actuator and sensor faults. To increase the flight safety of networked UAVs, a recurrent wavelet fuzzy neural network (RWFNN) learning system with feedback loops is first designed to compensate for the unknown terms induced by the inherent nonlinearities, unexpected actuator, and sensor faults. Then, FO sliding-mode control (FOSMC), involving the adjustable FO operators and the robustness of SMC, are dexterously proposed to further enhance flight safety and reduce synchronization tracking errors. Moreover, the dynamic parameters of the RWFNN learning system embedded in the networked fixed-wing UAVs are updated based on adaptive laws. Furthermore, the Lyapunov analysis ensures that all fixed-wing UAVs can synchronously track their references with bounded tracking errors. Finally, comparative simulations and hardware-in-the-loop experiments are conducted to demonstrate the validity of the proposed control scheme.},
keywords={Actuators;Fuzzy neural networks;Learning systems;Synchronization;Fault tolerant systems;Fault tolerance;Aerodynamics;Actuator-sensor faults;fault-tolerant control (FTC);fractional-order sliding-mode control (FOSMC);intelligent learning mechanism;networked unmanned aerial vehicles (UAVs)},
doi={10.1109/TNNLS.2021.3059933},
ISSN={2162-2388},
month={Dec},}
@INPROCEEDINGS{9019021,
author={Liu, Mengqian and Dong, Xiwang and Li, Qingdong and Ren, Zhang},
booktitle={2018 IEEE CSAA Guidance, Navigation and Control Conference (CGNCC)}, title={Model Reference Adaptive Control of a Quadrotor UAV based on RBF Neural Networks},
year={2018},
volume={},
number={},
pages={1-6},
abstract={In this paper, a model reference control method based on RBF neural networks is applied to attitude control of quadrotor. The model of a quadrotor is constructed and simplified to obtain the reference model in the same order as the plant. The RBF is trained by using the gradient descent method. Through simulation experiments, MRAC based on RBF has presented good tracking performance on the nonlinear quadrotor system with unknown and changing parameters.},
keywords={Mathematical model;Adaptation models;Neural networks;Adaptive control;Attitude control;Nonlinear dynamical systems;Uncertainty},
doi={10.1109/GNCC42960.2018.9019021},
ISSN={},
month={Aug},}
@INPROCEEDINGS{8897854,
author={Delgado, Cristhian and Benitez, Hernan and Cruz, Maribel and Selvaraj, Michael},
booktitle={IGARSS 2019 - 2019 IEEE International Geoscience and Remote Sensing Symposium}, title={Digital Disease Phenotyping},
year={2019},
volume={},
number={},
pages={5702-5705},
abstract={Precise and rapid methods of plant disease detection and evaluation are key factors to accelerate resistant variety development in the rice breeding program. Conventional methods for the disease detection and evaluation is mainly carried out using standard visual estimation by trained experts which is slow and prone to high level of subjectivity. Rigorous research has recently recognized innovative, sensor-based methods for the detection and evaluation of plant diseases. Among different type of sensors, aerial multispectral imaging provides a fast and nondestructive way of scanning plants in diseased regions and has been used by various researchers to classify symptom levels on the spectral profile of a plant. In this paper, we developed machine learning models to classify rice breeding lines infected by rice Hoja Blanca virus (RHBV) using multispectral images collected from UAV (unmanned aerial vehicle). Our results revealed that, the Support Vector Machine (SVM) and Random Forest (RF) methods were not significantly different in their ability to separate susceptible from non-susceptible classes, but SVM best classifiers showed a better sensitivity rates 0.74 (SVM) versus 0.71 (RF). The tool developed from this study will allow rice breeders to characterize Hoja Blanca virus resistant varieties considerably earlier, and subsequent in reduced costs.},
keywords={Calibration;Diseases;Cameras;Feature extraction;Unmanned aerial vehicles;Immune system;Viruses (medical);Machine Learning (ML);Unmaned Aerial Vehicle (UAV);Rice Hoja Blanca Virus (RHBV);Hight Troughtput Phenotyping (HTP)},
doi={10.1109/IGARSS.2019.8897854},
ISSN={2153-7003},
month={July},}
@ARTICLE{9403402,
author={Pandey, Shashi Raj and Kim, Kitae and Alsenwi, Madyan and Tun, Yan Kyaw and Han, Zhu and Hong, Choong Seon},
journal={IEEE Wireless Communications Letters}, title={Latency-Sensitive Service Delivery With UAV-Assisted 5G Networks},
year={2021},
volume={10},
number={7},
pages={1518-1522},
abstract={In this letter, a novel framework to deliver critical spread out URLLC services deploying unmanned aerial vehicles (UAVs) in an out-of-coverage area is developed. To this end, the resource optimization problem, i.e., resource blocks (RBs) and power allocation, and optimal UAV deployment strategy are studied for UAV-assisted 5G networks to jointly maximize the average sum-rate and minimize the transmit power of UAV while satisfying the URLLC requirements. To cope with the sporadic URLLC traffic problem, an efficient online URLLC traffic prediction model based on Gaussian Process Regression (GPR) is proposed which derives optimal URLLC scheduling and transmit power strategy. The formulated problem is revealed as a mixed-integer nonlinear programming (MINLP), which is solved following the introduced successive minimization algorithm. Finally, simulation results are provided to show our proposed solution approach's efficiency.},
keywords={Ultra reliable low latency communication;Resource management;Optimization;5G mobile communication;Reliability;Unmanned aerial vehicles;Dynamic scheduling;Unmanned aerial vehicles (UAVs);5G NR;URLLC;Gaussian process regression (GPR)},
doi={10.1109/LWC.2021.3073014},
ISSN={2162-2345},
month={July},}
@ARTICLE{8424456,
author={Nikonorov, Artem V. and Petrov, Maksim V. and Bibikov, Sergei A. and Yakimov, Pavel Y. and Kutikova, Viktoriya V. and Yuzifovich, Yuriy V. and Morozov, Andrey A. and Skidanov, Roman V. and Kazanskiy, Nikolay L.},
journal={IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing}, title={Toward Ultralightweight Remote Sensing With Harmonic Lenses and Convolutional Neural Networks},
year={2018},
volume={11},
number={9},
pages={3338-3348},
abstract={In this paper, we describe our advances in manufacturing a 256-layer 7-μm thick harmonic lens with 150 and 300 mm focal distances combined with color correction, deconvolution, and a feedforwarding deep learning neural network capable of producing images approaching photographic visual quality. While reconstruction of images taken with diffractive optics was presented in previous works, this paper is the first to use deep neural networks during the restoration step. The level of imaging quality we achieved with our imaging system can facilitate the emergence of ultralightweight remote sensing cameras for nano- and pico-satellites, and for aerial remote sensing systems onboard small UAVs and solar-powered airplanes.},
keywords={Lenses;Harmonic analysis;Optical diffraction;Optical imaging;Remote sensing;Image color analysis;Color correction;deconvolution;deep learning;harmonic lens;point spread function (PSF) estimation;remote sensing},
doi={10.1109/JSTARS.2018.2856538},
ISSN={2151-1535},
month={Sep.},}
@INPROCEEDINGS{9369805,
author={Choi, Yeon Ji and Rahim, Tariq and Ramatryana, I Nyoman Apraz and Shin, Soo Young},
booktitle={2021 International Conference on Electronics, Information, and Communication (ICEIC)}, title={Improved CNN-Based Path Planning for Stairs Climbing in Autonomous UAV with LiDAR Sensor},
year={2021},
volume={},
number={},
pages={1-7},
abstract={Unmanned aerial vehicles (UAV) technology has been an innovative advancement in the scientific environment over recent years. In this paper, we propose an approach that facilitates UAVs with a monocular camera combined with light detection and range (LiDAR) sensor to navigate autonomously for stairs climbing in completely unknown, GPS-denied indoor environments. The suggested approach utilizes a state-of-the-art CNN model for the task. We suggest a novel approach utilizing the video feed derived from the UAV front camera to determine the next maneuver in the deep neural network model. The process is viewed as a classification activity, where the deep neural network model classifies the image as a stair or no-stair and LiDAR sensor data are used for distance calculation. The training is performed from a dataset of images obtained from multiple stairs. We show the effectiveness of the proposed device in indoor stairs scenarios in real-time.},
keywords={Training;Laser radar;Navigation;Neural networks;Stairs;Cameras;Unmanned aerial vehicles;UAV;CNN;path planning;stairs climbing;LiDAR sensor},
doi={10.1109/ICEIC51217.2021.9369805},
ISSN={},
month={Jan},}
@INPROCEEDINGS{9569429,
author={Wu, Mengjie and Chi, Huijia and Gan, Shuying and Wang, Xijun and Xu, Chao},
booktitle={2021 IEEE 32nd Annual International Symposium on Personal, Indoor and Mobile Radio Communications (PIMRC)}, title={AoI optimal UAV trajectory planning: A Deep Recurrent Reinforcement Learning Approach},
year={2021},
volume={},
number={},
pages={1-6},
abstract={In this paper, we consider an unmanned aerial vehicles (UAV)-assisted IoT network and study the trajectory planning problem to optimize the information freshness, in terms of age of information (AoI), where the update arrivals at IoT devices are stochastic and are not known to the UAV. To this end, we first formulate the dynamic UAV trajectory planning problem as a Partially Observable Markov Decision Process (POMDP) with non-uniform time steps, where the set of valid actions is coupled with the agent's observations. Then, a deep recurrent reinforcement learning (DRRL) algorithm is devised to find the policy minimizing the expectation of the weighted average AoI, in which a modified discount mechanism is utilized to deal with the challenge from non-uniform time steps and an action elimination mechanism is introduced to address the coupling between the valid actions and observations. Finally, simulations are conducted to validate the effectiveness of our proposed algorithm by comparing it with baseline strategies.},
keywords={Couplings;Trajectory planning;Heuristic algorithms;Simulation;Reinforcement learning;Markov processes;Information age},
doi={10.1109/PIMRC50174.2021.9569429},
ISSN={2166-9589},
month={Sep.},}
@INPROCEEDINGS{8644345,
author={Liu, Xiao and Liu, Yuanwei and Chen, Yue},
booktitle={2018 IEEE Globecom Workshops (GC Wkshps)}, title={Deployment and Movement for Multiple Aerial Base Stations by Reinforcement Learning},
year={2018},
volume={},
number={},
pages={1-6},
abstract={A novel framework for Quality of experience (QoE)-driven deployment and movement of multiple unmanned aerial vehicles (UAVs) is proposed. The problem of joint non-concave 3D deployment and dynamic movement for maximizing the sum mean opinion score (MOS) of users is formulated, which is proved to be NP-hard. In an effort to solve this problem, we proposed a three-step approach to obtain 3D deployment and dynamic movement of multiple UAVs. More specifically, in the first step, GAK-means algorithm is invoked to obtain the cell partitioning of ground users. Secondly, Q-learning based deployment algorithm is proposed, in which each UAV is considered as an agent, making its own decision to obtain 3D position. In contrast to conventional genetic algorithm based learning algorithms, the proposed algorithm is capable of training the policy of making decision offline. Thirdly, Q-learning algorithm is invoked when the ground users roam. Unlike the other trajectory obtaining algorithms, the proposed approach enables each UAV learn its movement gradually through trials and errors, and updates the direction selection strategy until it reaches convergence. Numerical results reveal that the proposed 3D deployment scheme outperforms K-means algorithm and IGK algorithm with low complexity. Additionally, with the aid of proposed approach, 3D real-time dynamic movement of UAVs is obtained.},
keywords={Three-dimensional displays;Partitioning algorithms;Clustering algorithms;Heuristic algorithms;Quality of experience;Unmanned aerial vehicles;Artificial neural networks},
doi={10.1109/GLOCOMW.2018.8644345},
ISSN={},
month={Dec},}
@INPROCEEDINGS{9602868,
author={Wu, Meng-Shou and Li, Chi-Yu},
booktitle={2021 30th Wireless and Optical Communications Conference (WOCC)}, title={Edge-based Realtime Image Object Detection for UAV Missions},
year={2021},
volume={},
number={},
pages={293-294},
abstract={Unmanned Aerial Vehicle (UAV) has limited computing power, but requires high accuracy and low latency in the visual object detection for critical UAV missions, such as infrastructure inspection. It may need highly complex machine learning algorithms with the demand of extensive computing power. With the rising edge computing technology, the heavily-loaded object detection tasks can be offloaded to edge computing systems. To enable such edge-based object detection with low overhead, we discover that it is critical to minimize the response time of the detection while maximizing the frequency of detected image frames. In this paper, we identify three key research challenges, conduct an experimental case study to show that current edge-based naive solutions cannot achieve the above goal, and finally point out major ideas for potential solutions.},
keywords={Wireless communication;Visualization;Time-frequency analysis;Image edge detection;Object detection;Unmanned aerial vehicles;Optical fiber communication;UAV;edge computing;visual object detection},
doi={10.1109/WOCC53213.2021.9602868},
ISSN={2379-1276},
month={Oct},}
@INPROCEEDINGS{8600838,
author={Anwar, Malik Aqeel and Raychowdhury, Arijit},
booktitle={2018 25th International Conference on Mechatronics and Machine Vision in Practice (M2VIP)}, title={NavREn-Rl: Learning to fly in real environment via end-to-end deep reinforcement learning using monocular images},
year={2018},
volume={},
number={},
pages={1-6},
abstract={We present NavREn-RL, an approach to NAVigate an unmanned aerial vehicle in an indoor Real ENvironment via end-to-end reinforcement learning (RL). A suitable reward function is designed keeping in mind the cost and weight constraints for micro drone with minimum number of sensing modalities. Collection of small number of expert data and knowledge based data aggregation is integrated into the RL process to aid convergence. Experimentation is carried out on a Parrot AR drone in different indoor arenas and the results are compared with other baseline technologies. We demonstrate how the drone successfully avoids obstacles and navigates across different arenas. Video of the drone navigating using the proposed approach can be seen at https://youtu.be/yOTkTHUPNVY.},
keywords={Drones;Navigation;Computer crashes;Cameras;Sensors;Collision avoidance;Neural networks},
doi={10.1109/M2VIP.2018.8600838},
ISSN={},
month={Nov},}
@INPROCEEDINGS{9643359,
author={Tang, Zhicheng and Zhang, Yang and Wang, Yizhen and Shang, Yi and Viegut, Reid and Webb, Elisabeth and Raedeke, Andrew and Sartwell, Joel},
booktitle={2021 IEEE 33rd International Conference on Tools with Artificial Intelligence (ICTAI)}, title={sUAS and Machine Learning Integration in Waterfowl Population Surveys},
year={2021},
volume={},
number={},
pages={517-521},
abstract={The rapid technological development of small Unmanned Aircraft Systems (sUAS) has led to an increase in capabilities of aerial image collection and analysis for monitoring a variety of wildlife species including waterfowl. Biologists mainly rely on conducting ocular surveys from fixed-wing aircraft or helicopters to estimate waterfowl abundance. sUAS provide an alternative that is safer, less expensive, and more flexible. Researchers have attempted to estimate waterfowl abundance from aerial imagery, but this method has proven to be too time consuming. Machine learning provides the opportunity to more efficiently estimate waterfowl abundance from aerial imagery. In this paper, we present a new integrated system of sUAS and machine learning for waterfowl population surveys. This system provides a user-friendly process for sUAS survey design, deployment, and data post-processing using deep learning methods to automatically detect and count waterfowl. To develop this system, we conducted many sUAS flights to capture a diversity of imagery and assembled six datasets of imagery taken from both fix-winged aircraft and sUAS flights. We used these datasets to develop and evaluate state-of-the-art deep learning models for waterfowl detection. Our system of using a combination of sUAS and machine learning has proved to be an efficient and accurate approach for collecting, analyzing, and estimating waterfowl abundance.},
keywords={Deep learning;Conferences;Atmospheric modeling;Sociology;Wildlife;Helicopters;Biology;Drone;UAV;aerial image;deep learning;computer vision;waterfowl population survey},
doi={10.1109/ICTAI52525.2021.00084},
ISSN={2375-0197},
month={Nov},}
@INPROCEEDINGS{8343133,
author={El-Sayed, Hesham and Chaqfeh, Moumena},
booktitle={2018 International Conference on Information Networking (ICOIN)}, title={The deployment of mobile edges in vehicular environments},
year={2018},
volume={},
number={},
pages={322-324},
abstract={The provision of online traffic information and applications in vehicular environment can be offered via fixed ground Roadside Units (RSUs). Nevertheless, employing flying RSUs that are carried by Unmanned Aerial Vehicles (UAVs) would bring the capabilities of Mobile Edge Computing (MEC) to the vehicular environment, where they can be deployed dynamically in accordance to traffic safety events and congestion conditions. In this paper, we propose a novel method for the deployment of flying RSUs based on swarm intelligence. Our proposed method relies on two fundamental properties of the dynamic deployment of edges in vehicular environments, which are self-organization and the division of workload among RSUs. These two properties are necessary and sufficient to obtain a swarm intelligent behavior. The term “swarm” can refer to any restrained collection of interacting agents or individuals, which are - in this case - the travelling vehicles and RSUs.},
keywords={Heuristic algorithms;Roads;Vehicle dynamics;Optimization;Cloud computing;Particle swarm optimization;Intelligent Transportation Systems (ITS);Vehicular Environment;Flying RSUs;Deployment;Optimization},
doi={10.1109/ICOIN.2018.8343133},
ISSN={},
month={Jan},}
@ARTICLE{7268858,
author={Sharma, Vishal and Kumar, Rajesh and Rana, Prashant Singh},
journal={IEEE Communications Letters}, title={Self-Healing Neural Model for Stabilization Against Failures Over Networked UAVs},
year={2015},
volume={19},
number={11},
pages={2013-2016},
abstract={Unmanned aerial vehicles (UAVs) allow formation of wide range ad hoc networks. These ad hoc formations with unmanned vehicles provide coverage of vast areas of applications involving mission dependent activities. Such networks can solve various issues related to civilian and military activities. One of the main applications of these networks is continuous surveillance. Surveillance by multiple nodes in ad hoc mode is directly dependent upon the continuous data sharing, cooperative decision making and stabilized network formation. Failures in network can hinder the performance and can decrease its operability. It is difficult to aloof network from discrete failures. Therefore, stabilized model is required which can provide stability to the whole network. For this, a self-healing neural model is developed which is capable of handling uncertain failures. It also provides provision for recovery of nodes from failure to stabilized state.},
keywords={Neurons;Neural networks;Training;Stability analysis;Vehicles;Linear programming;Analytical models;Self-Healing;UAVs;Stabilization;Network Failures;Neural;Self-healing;UAVs;stabilization;network failures;neural model},
doi={10.1109/LCOMM.2015.2478818},
ISSN={1558-2558},
month={Nov},}
@ARTICLE{9620034,
author={Rangappa, Nehul and Prasad, Y. Raja Vara and Dubey, Shiv Ram},
journal={IEEE Sensors Journal}, title={LEDNet: Deep Learning-Based Ground Sensor Data Monitoring System},
year={2022},
volume={22},
number={1},
pages={842-850},
abstract={Wireless Sensor Networks (WSN) are generally used for precision agriculture. However, reliability and cost are the key limitations of such approaches. In recent times, the application of Unmanned Aerial Vehicles (UAVs) in the agricultural field has become popular due to scalability, cost efficient and user friendly adaptations with the help of improved navigation algorithms. A Novel and cost effective Light Emitting Diode (LED) based wireless communication of field sensor data to server has been recently explored. This paper proposes a LEDNet framework that utilizes the LED pattern based sensor data encoding in an image with computer vision and deep learning based data extraction/communication of data. The LED pattern image can be captured using any decent resolution cameras that can be mounted on UAVs. The proposed framework generates LED sequences with the help of embedded boards and utilizes image processing and deep learning for the decoding of the sensor data from the LED pattern image. The experiments are carried out with the images taken under various lighting conditions from different heights in the field. Promising performance in terms of accuracy and power consumption is observed for the collection of sensor data using the proposed LEDNet framework for the LED bit sequence extraction from the dataset of images collected under various environmental conditions.},
keywords={Sensors;Light emitting diodes;Agriculture;Deep learning;Image sensors;Wireless sensor networks;Crops;Precision agriculture;WSN;UAV;sensors;LED communication;LED bit sequence;image processing;CNN;deep learning},
doi={10.1109/JSEN.2021.3129173},
ISSN={1558-1748},
month={Jan},}
@ARTICLE{8836448,
author={Ghazal, Mohammed Asaad and Mahmoud, Ali and Aslantas, Ali and Soliman, Ahmed and Shalaby, Ahmed and Benediktsson, Jón Atli and El-Baz, Ayman},
journal={IEEE Access}, title={Vegetation Cover Estimation Using Convolutional Neural Networks},
year={2019},
volume={7},
number={},
pages={132563-132576},
abstract={Vegetation is an important parameter in all bio- and ecosystems, and it should be monitored to conserve and restore the environment. This paper presents a design and implementation of a compact system for vegetation cover monitoring, which consists of a small unmanned aerial vehicle (UAV) equipped with four different cameras (RGB, NIR, NDVI, and red). These cameras simultaneously record videos and wirelessly send them to a ground station that applies on them a set of algorithms to construct a mosaic representing the covered area and segment vegetative regions. Mosaicing is performed using a fast multi-threaded approach based on binary descriptors. For segmenting vegetation, two scenarios are tested by using convolutional neural networks (CNNs). The first scenario trained a CNN using the images obtained from the four cameras, and then used it with the constructed mosaics. In the second scenario, we trained individual CNNs using images from each of the four cameras individually. The performance of the former scenario exceeded the others from the perspective of accuracy. Moreover, it proved to be highly comparable to previous approaches utilizing level sets, while the processing time is reduced. The proposed approach obtained high accuracy in terms of the Dice similarity coefficient (97 %), which demonstrates its favorable performance.},
keywords={Vegetation mapping;Cameras;Remote sensing;Videos;Estimation;Monitoring;Image segmentation;CNN;segmentation;UAV;vegetation cover estimation},
doi={10.1109/ACCESS.2019.2941441},
ISSN={2169-3536},
month={},}
@INPROCEEDINGS{8085049,
author={Cisek, Daniel and Mahajan, M. and Dale, Jedidiah and Pepper, Susan and Lin, Yuewei and Yoo, Shinjae},
booktitle={2017 New York Scientific Data Summit (NYSDS)}, title={A transfer learning approach to parking lot classification in aerial imagery},
year={2017},
volume={},
number={},
pages={1-5},
abstract={The importance of satellite imagery analysis has increased dramatically over the last several years, keeping pace with the rapid improvements seen in both remote sensing platforms and sensors. As this field expands, so too does the interest in using machine learning methods to automate parts of the imagery analyst's workflow. In this paper we address one aspect of this challenge: the development of a method for the automatic extraction of parking lots from aerial imagery. To the best of our knowledge, there has been no prior work conducted on the development of an end-to-end pipeline for this particular task. Due to the limited size of our dataset and to accommodate the potentially limited size of future datasets, we propose a deep learning approach using transfer learning. This process hinges upon the use of state of the art Convolutional Neural Networks (CNNs), trained on general image classification datasets. These networks were then fine-tuned on our custom dataset, to establish a comprehensive benchmark for this task. Our method exhibits promising results for automatic parking lot extraction, and is generalizable enough to work with different input types, including high resolution aerial orthoimagery, satellite imagery, full motion video (FMV), and UAV imagery.},
keywords={Training;Neural networks;Machine learning;Satellites;Object recognition;Visualization;Deep Learning;Neural Network;Geospatial;Automation;Satellite Imagery},
doi={10.1109/NYSDS.2017.8085049},
ISSN={},
month={Aug},}
@INPROCEEDINGS{9554041,
author={Booysen, René and Lorenz, Sandra and Jackisch, Robert and Gloaguen, Richard and Madriz, Yuleika},
booktitle={2021 IEEE International Geoscience and Remote Sensing Symposium IGARSS}, title={How Can Drones Contribute to Mineral Exploration?},
year={2021},
volume={},
number={},
pages={1867-1870},
abstract={Drones are getting more and more used to replace piloted platforms to reduce the costs and increase safety of activities such as monitoring, delivery or warfare. So far though, drones have barely been used as more than single-sensor platforms. In order to be used in mineral exploration we need to ensure that the data acquired by drones are versatile, accurate and adapted to the tasks but also that the platforms are robust and low-maintenance to ensure an operational use in remote locations. During the last years we developed and tested a series of workflows to rapidly provide relevant information to exploration teams. It starts with multi-source data acquisition, data integration and preprocessing. We then use machine learning to process the data and generate relevant geological information.},
keywords={Ores;Geoscience and remote sensing;Machine learning;Tools;Safety;Data mining;Magnetics;Drones;UAS;UAV;hyperspectral;magnetics;machine learning;exploration},
doi={10.1109/IGARSS47720.2021.9554041},
ISSN={2153-7003},
month={July},}
@INPROCEEDINGS{9079042,
author={Björklund, Svante and Wadströmer, Niclas},
booktitle={2019 International Radar Conference (RADAR)}, title={Target Detection and Classification of Small Drones by Deep Learning on Radar Micro-Doppler},
year={2019},
volume={},
number={},
pages={1-6},
abstract={Small drones, also called mini-UAVs (Unmanned Aerial Vehicles), have become very wide-spread. In security applications it is often desirable to detect and classify them. In this paper we employ radar micro-Doppler for detection and classification of small drones. Micro-Doppler are Doppler shifts generated by the movements of parts of the target. We have used radar measurements of small drones and birds, generated TVDs (Time Velocity Diagrams), and used a deep learning classifier to distinguish between drones and birds (target detection) and types of drones (target classification) with very good results. Our deep learning classifier is an improvement in classification performance compared to our earlier boosting and SVM (Support Vector Machine) classifiers on the same data.},
keywords={radar;micro-Doppler;UAV;drone;detection;classification;deep learning},
doi={10.1109/RADAR41533.2019.171294},
ISSN={2640-7736},
month={Sep.},}
@INPROCEEDINGS{8128413,
author={Zhang, Zhou and Masjedi, Ali and Zhao, Jieqiong and Crawford, Melba M.},
booktitle={2017 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)}, title={Prediction of sorghum biomass based on image based features derived from time series of UAV images},
year={2017},
volume={},
number={},
pages={6154-6157},
abstract={High throughput plant phenotyping has gained significant interest in the plant science community due to its potential impact in advancing the use of advanced plant genetics for problems ranging from global food security to biomass-based energy crops. While traditional collection of field-based phenotypes is manual, automated remote sensing-based methods can reduce the manual requirements, expand the number of sampled points, and accelerate associations with genotypes. In this preliminary work, we use multiple types of features derived from multi-temporal UAV-based hyperspectral and RGB image data for prediction of sorghum biomass. Considering the nonlinear properties of the spectral input features, multiple layer perception (MLP) neural networks and support vector regression (SVR) are explored for predicting dry biomass. The analysis is conducted on datasets acquired during June-August 2016 over an agricultural test field at the Agronomy Center for Research and Education (ACRE) at Purdue University.},
keywords={Biomass;Hyperspectral imaging;Biological system modeling;Predictive models;Data models;Automated phenotyping;regression;hyperspectral data;RGB images},
doi={10.1109/IGARSS.2017.8128413},
ISSN={2153-7003},
month={July},}
@INPROCEEDINGS{8615877,
author={Ruvalcaba-Cardenas, Ana Daysi and Scoleri, Tony and Day, Geoffrey},
booktitle={2018 Digital Image Computing: Techniques and Applications (DICTA)}, title={Object Classification using Deep Learning on Extremely Low-Resolution Time-of-Flight Data},
year={2018},
volume={},
number={},
pages={1-7},
abstract={This paper proposes two novel deep learning models for 2D and 3D classification of objects in extremely low-resolution time-of-flight imagery. The models have been developed to suit contemporary range imaging hardware based on a recently fabricated Single Photon Avalanche Diode (SPAD) camera with 64 χ 64 pixel resolution. Being the first prototype of its kind, only a small data set has been collected so far which makes it challenging for training models. To bypass this hurdle, transfer learning is applied to the widely used VGG-16 convolutional neural network (CNN), with supplementary layers added specifically to handle SPAD data. This classifier and the renowned Faster-RCNN detector offer benchmark models for comparison to a newly created 3D CNN operating on time-of-flight data acquired by the SPAD sensor. Another contribution of this work is the proposed shot noise removal algorithm which is particularly useful to mitigate the camera sensitivity in situations of excessive lighting. Models have been tested in both low-light indoor settings and outdoor daytime conditions, on eight objects exhibiting small physical dimensions, low reflectivity, featureless structures and located at ranges from 25m to 700m. Despite antagonist factors, the proposed 2D model has achieved 95% average precision and recall, with higher accuracy for the 3D model.},
keywords={Three-dimensional displays;Two dimensional displays;Solid modeling;Deep learning;Photonics;Data models;3D object classification;detection;time-of-flight;deep learning;convolutional neural network;low resolution;low sensing;single photon;SPAD;LADAR;denoising;shot noise;UAV},
doi={10.1109/DICTA.2018.8615877},
ISSN={},
month={Dec},}
@INPROCEEDINGS{7991052,
author={Chen, Chien-Hung and Liu, Keng-Hao},
booktitle={2017 IEEE International Conference on Consumer Electronics - Taiwan (ICCE-TW)}, title={Stingray detection of aerial images with region-based convolution neural network},
year={2017},
volume={},
number={},
pages={175-176},
abstract={The image processing technologies have become a popular tool for biological related researches. In order to detect the specific animal from aerial videos, this paper attempts to use the region-based convolution neural network to implement stingray detection on aerial images obtained by UAV. The experimental shows that using Faster R-CNN algorithm as the target detector can achieve good detection accuracy with short computing time. It suggests that deep learning-based methods have considerable potential to aid real-time applications.},
keywords={Videos;Convolution;Neural networks;Training;Machine learning;Object detection;Proposals},
doi={10.1109/ICCE-China.2017.7991052},
ISSN={},
month={June},}
@INPROCEEDINGS{8666569,
author={Dinh, Marc and Morris, Brendan and Kim, Yoohwan},
booktitle={2019 IEEE 9th Annual Computing and Communication Workshop and Conference (CCWC)}, title={UAS-based object tracking via Deep Learning},
year={2019},
volume={},
number={},
pages={0217-0275},
abstract={Unmanned Aerial System-based object tracking is a challenging new task in the computer vision community. In addition, existing benchmark and research focus on short sequences that are less than a minute long. In this work, we show the limitations of state-of-the art trackers in front of long-term aerial tracking. We propose a novel long-term, real-time, intelligent system for unmanned aerial system -based vehicle tracking utilizing deep learning techniques. We integrate a fast and accurate correlation filter with the expressiveness of a convolutional neural network embedding. A re-initialization policy based on a real-time anomaly detection on correlation map combined with a one-shot detector ensure that our system is impervious to drift and occlusion.},
keywords={Correlation;Detectors;Object tracking;Robustness;Deep learning;Feature extraction;UAV;UAS;tracking;object detection;long-term;deep learning},
doi={10.1109/CCWC.2019.8666569},
ISSN={},
month={Jan},}
@ARTICLE{9507275,
author={González-Trejo, Javier and Mercado-Ravell, Diego and Becerra, Israel and Murrieta-Cid, Rafael},
journal={IEEE Robotics and Automation Letters}, title={On the Visual-Based Safe Landing of UAVs in Populated Areas: A Crucial Aspect for Urban Deployment},
year={2021},
volume={6},
number={4},
pages={7901-7908},
abstract={Autonomous landing of Unmanned Aerial Vehicles (UAVs) in crowded scenarios is crucial for successful deployment of UAVs in populated areas, particularly in emergency landing situations where the highest priority is to avoid hurting people. In this work, a new visual-based algorithm for identifying Safe Landing Zones (SLZ) in crowded scenarios is proposed, considering a camera mounted on a UAV, where the people in the scene move with unknown dynamics. To do so, a density map is generated for each image frame using a Deep Neural Network, from where a binary occupancy map is obtained aiming to overestimate the people's location for security reasons. Then, the occupancy map is projected to the head's plane, and the SLZ candidates are obtained as circular regions with a minimum security radius, within the head's plane. Finally, to keep track of the SLZ candidates, a multiple instance tracking algorithm is implemented using Kalman Filters along with the Hungarian algorithm for data association. Several scenarios were studied to prove the validity of the proposed strategy, including public datasets and real uncontrolled scenarios with people moving in public squares, taken from a UAV in flight. The study showed promising results in the search of preventing the UAV from hurting people during emergency landing.},
keywords={Head;Generators;Task analysis;Security;Heuristic algorithms;Cameras;Drones;UAVs;autonomous landing;crowds detection;visual-based landing;density maps},
doi={10.1109/LRA.2021.3101861},
ISSN={2377-3766},
month={Oct},}
@INPROCEEDINGS{8101666,
author={Ma, Yuntao and Liu, Yuxuan and Jin, Ruiyang and Yuan, Xingyang and Sekha, Raza and Wilson, Samuel and Vaidyanathan, Ravi},
booktitle={2017 Workshop on Research, Education and Development of Unmanned Aerial Systems (RED-UAS)}, title={Hand gesture recognition with convolutional neural networks for the multimodal UAV control},
year={2017},
volume={},
number={},
pages={198-203},
abstract={We introduce a robust wearable sensor suite fusing arm motion and hand gesture recognition for operator control of UAVs. The sensor suite fuses mechanomyography (MMG) and an inertial measurement unit (IMU) to capture multi-modal (arm movement and hand gesture) command signals simultaneously. The IMU produces world referenced orientation and acceleration data while concomitant MMG tracks muscle activation through surface vibration. The use of surface muscle vibration for gesture recognition removes the need for electrical contact with the skin, which has impeded other forms of muscle measurement for gesture recognition in the field. This investigation presents hardware design, inertial recognition of arm movement, and the detailed structure of a convolutional neural network (CNN) system used for real-time hand gesture recognition based on MMG signals. The system achieved 94% accuracy for five gestures with simple calibration for each user, thereby providing an intuitive gesture based UAV control system. To our knowledge this is the first wearable system enabling multimodal control of UAVs through intuitive gestures that does not require electrical skin contact. Future work involves testing the system with larger UAV swarms.},
keywords={Convolution;Training;Gesture recognition;Unmanned aerial vehicles;Muscles;Calibration;Neural networks},
doi={10.1109/RED-UAS.2017.8101666},
ISSN={},
month={Oct},}
@INPROCEEDINGS{8625204,
author={Antonio-Toledo, M. Elena and Sanchez, Edgar N. and Alanis, Alma Y.},
booktitle={2018 IEEE Latin American Conference on Computational Intelligence (LA-CCI)}, title={Neural Inverse Optimal Control Applied to Quadrotor UAV},
year={2018},
volume={},
number={},
pages={1-8},
abstract={This paper presents a neural nonlinear control scheme of a quadrotor unmanned aerial vehicle (UAV) for altitude and position trajectory tracking. The neural controller is based on a recurrent high order neural network identifier (RHONN) trained using an Extended Kalman Filter (EFK). The proposed nonlinear control strategy is based on inverse optimal control (IOC) technique for altitude and translation motion. In addition, the control law stabilize the orientation of the vehicle. The dynamical model is obtained by the Euler-Lagrange methodology. The effectiveness of this proposed control scheme is verified by simulation results.},
keywords={Neural networks;Optimal control;Training;Covariance matrices;Unmanned aerial vehicles;Trajectory tracking;Kalman filters},
doi={10.1109/LA-CCI.2018.8625204},
ISSN={},
month={Nov},}
@INPROCEEDINGS{8518521,
author={Zhuo, Xiangyu and Fraundorfer, Friedrich and Kurz, Franz and Reinartz, Peter},
booktitle={IGARSS 2018 - 2018 IEEE International Geoscience and Remote Sensing Symposium}, title={Building Detection and Segmentation Using a CNN with Automatically Generated Training Data},
year={2018},
volume={},
number={},
pages={3461-3464},
abstract={Significantly outperforming traditional machine learning methods, deep convolutional neural networks have gained increasing popularity in the application of image classification and segmentation. Nevertheless, deep learning-based methods usually require a large amount of training data, which is quite labor-intensive and time-demanding. To deal with the problem in generating training data, we propose in this paper a novel approach to generate image annotations by transferring labels from aerial images to UAV images and refine the annotations using a densely connected CRF model with an embedded naive Bayes classifier. The generated annotations not only present correct semantic labels, but also preserve accurate class boundaries. To validate the utility of these automatic annotations, we deploy them as training data for pixel-wise image segmentation and compare the results with the segmentation using manual annotations. Experiment results demonstrate that the automatic annotations can achieve comparable segmentation accuracy as the manual annotations.},
keywords={Three-dimensional displays;Image segmentation;Manuals;Semantics;Training data;Computer vision;Image annotation;Image segmentation;Automatic image annotation;Label propagation;Deep learning},
doi={10.1109/IGARSS.2018.8518521},
ISSN={2153-7003},
month={July},}
@INPROCEEDINGS{9392478,
author={Aswin, S. and Sajithvariyar, V.V. and Sivanpillai, Ramesh and Sowmya, V. and Brown, Gregory K and Shashank, A. and Soman, K. P.},
booktitle={2021 International Conference on Advances in Electrical, Computing, Communication and Sustainable Technologies (ICAECT)}, title={Effect of Annotation and Loss Function on Epiphyte Identification using Conditional Generative Adversarial Network},
year={2021},
volume={},
number={},
pages={1-6},
abstract={The deep neural networks are capable of processing large amounts of data for image processing applications like classification, segmentation and identification etc. Conditional- Generative Adversarial Network (C-GAN) is an example of Deep Learning (DL)-based image processing algorithm that is used widely for identifying targets in images. In a Deep Learning based image processing application the quality of the input image plays an important role. The quality and variations within the dataset helps the neural network filters to derive the best features for the classification and identification of the target in the image. Many deep learning approaches will have a preprocessing pipeline which improves the quality of the input training data. The objective of this study was to evaluate the effect of preprocessing methods to improve C-GAN's ability to detect epiphytes in images acquired by Unmanned Aerial Vehicles (UAVs). These methods include 1) trimming the training images to include mostly the target plant, 2) generating annotation images with a thresholding technique, and 3) incorporating binary cross entropy loss function. Results obtained from this study shows that the percent occupancy of input images and annotation method plays an important role in identifying the target plant.},
keywords={Deep learning;Annotations;Pipelines;Neural networks;Training data;Generative adversarial networks;Unmanned aerial vehicles;C-GAN;Threshold annotation;Loss Function;IoU;SSIM},
doi={10.1109/ICAECT49130.2021.9392478},
ISSN={},
month={Feb},}
@INPROCEEDINGS{8868510,
author={Cao, Su and Shen, Lincheng and Zhang, Renshan and Yu, Huangchao and Wang, Xiangke},
booktitle={2019 IEEE/ASME International Conference on Advanced Intelligent Mechatronics (AIM)}, title={Adaptive Incremental Nonlinear Dynamic Inversion Control Based on Neural Network for UAV Maneuver},
year={2019},
volume={},
number={},
pages={642-647},
abstract={In this paper, a flight control strategy based on incremental nonlinear dynamic inversion (INDI) using properties of general flight control systems and nonlinear dynamic inversion by feeding back angular accelerations is presented. The INDI control law is based on a linearized approximation of incremental plant dynamics and reduces dependence on modeling accuracy. However, there is still an un-negligible nonlinear character of unmanned aerial vehicle (UAV) during high angle maneuvers. The main contributions of this article are 1) proposing an adaptive neural network compensation method : INDI with neural network(INDI_NN) to correctly consider the model uncertainties; 2) a quaternion based reference model which is suitable for vehicles to experience a high angle maneuver. The simulation results support the proposed control scheme in getting better tracking performance during large range of attitudes. Hence, the proposed control method makes INDI controller more practical and more suitable for high angle maneuver like Immelman Turn.},
keywords={Adaptation models;Quaternions;Nonlinear dynamical systems;Neural networks;Adaptive systems;Mathematical model;Unmanned aerial vehicles},
doi={10.1109/AIM.2019.8868510},
ISSN={2159-6255},
month={July},}
@INPROCEEDINGS{8678972,
author={Grumazescu, Constantin and Vladuta, Valentin-Alexandru and Timofte, Andrei},
booktitle={2018 10th International Conference on Electronics, Computers and Artificial Intelligence (ECAI)}, title={Hybrid identity based cryptographic scheme optimization using machine learning in WSN},
year={2018},
volume={},
number={},
pages={1-6},
abstract={Wireless sensor networks (WSN) security has become a very important issue considering the wide range of applications and implementation challenges. In this article we are proposing a machine learning based technique in order to optimize all aspects of wireless sensor network based applications that are being secured using a previously proposed Hybrid Distributed-Hierarchical Identity Based Cryptographic Scheme (HYDISH).},
keywords={Cryptography;Wireless sensor networks;Unmanned aerial vehicles;Generators;Optimization;Routing;identity;hierarchic;distributed;wireless sensor network;machine learning;unmanned aerial vehicle;sink;optimization},
doi={10.1109/ECAI.2018.8678972},
ISSN={},
month={June},}
@ARTICLE{8936895,
author={Bah, Mamadou Dian and Hafiane, Adel and Canals, Raphael},
journal={IEEE Access}, title={CRowNet: Deep Network for Crop Row Detection in UAV Images},
year={2020},
volume={8},
number={},
pages={5189-5200},
abstract={Nowadays, the development of robots and smart tractors for the automation of sowing, harvesting, weeding etc. is transforming agriculture. Farmers are moving from an agriculture where everything is applied uniformly to a much more targeted farming. This new kind of farming is commonly referred to as precision agriculture. However for autonomous guidance of these agricultural machines and even sometimes for weed detection an accurate detection of crop rows is required. In this paper we propose a new method called CRowNet which uses a convolutional neural network (CNN) and the Hough transform to detect crop rows in images taken by an unmanned aerial vehicle (UAV). The method consists of a model formed with SegNet (S-SegNet) and a CNN based Hough transform (HoughCNet). The performance of the proposed method was quantitatively compared to traditional approaches and it showed the best and most robust result. A good crop row detection rate of 93.58% was obtained with an IoU score per crop row above 70%. Moreover the model trained on a given crop field is able to detect rows in images of different types of crops.},
keywords={Agriculture;Transforms;Strips;Unmanned aerial vehicles;Image segmentation;Robots;Soil;Crop row detection;deep learning;weed detection;Hough transform;image processing},
doi={10.1109/ACCESS.2019.2960873},
ISSN={2169-3536},
month={},}
@ARTICLE{8879593,
author={Mesquita, Daniel B. and Santos, Ronaldo F. dos and Macharet, Douglas G. and Campos, Mario F. M. and Nascimento, Erickson R.},
journal={IEEE Geoscience and Remote Sensing Letters}, title={Fully Convolutional Siamese Autoencoder for Change Detection in UAV Aerial Images},
year={2020},
volume={17},
number={8},
pages={1455-1459},
abstract={Different applications in remote sensing, such as crop monitoring and visual surveillance, demand the automatic detection of changes from sets of images acquired over time. Most traditional approaches use satellite imagery, which, besides the known issues such as cloud cover and image acquisition frequency for nongeostationary satellites, are very costly. In this context, with the recent technological advances, unmanned aerial vehicles (UAVs) have become ubiquitous in numerous applications. In this letter, we present a fully convolutional Siamese autoencoder method for change detection in aerial images, in particular for those obtained with UAVs. We show that, by using an autoencoder, we can further reduce the number of labeled samples required to achieve competitive results. We evaluated the performance of our approach on two different data sets, and the results showed that our methodology outperforms the state of the art, while demanding less training data.},
keywords={Unmanned aerial vehicles;Feature extraction;Remote sensing;Satellites;Task analysis;Streaming media;Convolution;Aerial images;change detection;fully convolutional neural networks (FCNNs);fully convolutional Siamese networks;unmanned aerial vehicles (UAVs)},
doi={10.1109/LGRS.2019.2945906},
ISSN={1558-0571},
month={Aug},}
@INPROCEEDINGS{7230963,
author={Pace, Pasquale and Aloi, Gianluca and Fortino, Giancarlo},
booktitle={2015 IEEE 19th International Conference on Computer Supported Cooperative Work in Design (CSCWD)}, title={An application-level framework for UAV/rover communication and coordination},
year={2015},
volume={},
number={},
pages={229-233},
abstract={The paper proposes AirGround, a flexible and expandable framework to support the collaboration and the coordination between aerial and terrestrial drones in order to accomplish a common mission in a more effective and fast way. In particular the designed application-level framework allows the dynamic tasks assignment to the different devices involved into the communication process and the distributed leader election according to specific executive parameters and system conditions (i.e., residual energy, computational power, abilities offered by specific on board sensors). The AirGround effectiveness has been evaluated throughout a real testbed to measure the overall system performance in terms of both neighbour discovery and leader election speed by increasing the number of drones in different channel and environmental conditions.},
keywords={Lead;Communication channels;Unicast;Scalability;Artificial neural networks},
doi={10.1109/CSCWD.2015.7230963},
ISSN={},
month={May},}
@INPROCEEDINGS{9145090,
author={Wang, Yining and Yang, Yang and Luo, Tao},
booktitle={2020 IEEE International Conference on Communications Workshops (ICC Workshops)}, title={Federated Convolutional Auto-Encoder for Optimal Deployment of UAVs with Visible Light Communications},
year={2020},
volume={},
number={},
pages={1-6},
abstract={In this paper, the problem of unmanned aerial vehicles (UAV) deployment is investigated for visible light communication (VLC)-enabled UAV networks. Here, UAVs can simul-taneously provide communications and illumination services to ground users. In this model, ambient illumination distribution of the service area must be considered since it can cause interference over the VLC link and affects the illumination requirements of users. This problem is formulated as an optimization problem, which jointly considers UAV deployment, user association, power efficiency, and predictions of the illumination distribution. To solve this problem, we first need to predict illumination distribution to proactively determine the UAV deployment and user association so as to minimize total transmission power of UAVs. To predict the illumination distribution of the entire service area, a federated learning framework based on the machine learning algorithm of convolutional auto-encoder (CAE) is proposed. Compared to the centralized machine learning algorithms that requires complete illumination data for centralized training, the proposed algorithm enables the UAVs to train their local CAE with partial illumination data and cooperatively build a global CAE model that can predict the entire illumination distribution. Using these predictions, the optimal UAV deployment and user association policy that minimizes the total transmission power of UAVs is determined. Simulation results demonstrate that the proposed approach reduces the transmission power of UAVs up to 14.8% and 25.1%, respectively, compared to the local CAE prediction models and the conventional optimal algorithm without illumination distribution predictions.},
keywords={Lighting;Unmanned aerial vehicles;Prediction algorithms;Predictive models;Interference;Data models;Machine learning algorithms},
doi={10.1109/ICCWorkshops49005.2020.9145090},
ISSN={2474-9133},
month={June},}
@INPROCEEDINGS{6852919,
author={Gai, Wendong and Zhang, Jing and Huang, Liangsong and Li, Yuxia},
booktitle={The 26th Chinese Control and Decision Conference (2014 CCDC)}, title={Transition flight control using adaptive neutral network dynamic inversion for Canard Rotor/Wing UAV},
year={2014},
volume={},
number={},
pages={4210-4214},
abstract={The problem of designing transition flight controller via improved adaptive neural network dynamic inversion for Canard Rotor/Wing (CRW) UAV is studied. The transition control strategy from rotary-wing mode to fixed-wing mode is derived according to the flight characteristic analysis. The controller is composed of trajectory outer-loop and attitude inner-loop. The dynamic inversion method is used to design these loops. In addition, the angular rate error equations with proportional-integral desired dynamics are used to design the adaptive update law for compensating the system model error. The main advantage of this approach is its ability of the fast adaptation that leads to good steady and transient performance as well as simple design process. The longitudinal nonlinear dynamic simulations show that this approach improves the stability and transient response of attitude angle and achieves the transition flight control of the CRW UAV successfully.},
keywords={Rotors;Adaptation models;Attitude control;Neural networks;Aircraft;Trajectory;Flight Control;Adaptive Neural Network;Canard Rotor/Wing UAV;Dynamic Inversion},
doi={10.1109/CCDC.2014.6852919},
ISSN={1948-9447},
month={May},}
@ARTICLE{9366781,
author={Venturini, Federico and Mason, Federico and Pase, Francesco and Chiariotti, Federico and Testolin, Alberto and Zanella, Andrea and Zorzi, Michele},
journal={IEEE Transactions on Cognitive Communications and Networking}, title={Distributed Reinforcement Learning for Flexible and Efficient UAV Swarm Control},
year={2021},
volume={7},
number={3},
pages={955-969},
abstract={Over the past few years, the use of swarms of Unmanned Aerial Vehicles (UAVs) in monitoring and remote area surveillance applications has become widespread thanks to the price reduction and the increased capabilities of drones. The drones in the swarm need to cooperatively explore an unknown area, in order to identify and monitor interesting targets, while minimizing their movements. In this work, we propose a distributed Reinforcement Learning (RL) approach that scales to larger swarms without modifications. The proposed framework relies on the possibility for the UAVs to exchange some information through a communication channel, in order to achieve context-awareness and implicitly coordinate the swarm’s actions. Our experiments show that the proposed method can yield effective strategies, which are robust to communication channel impairments, and that can easily deal with non-uniform distributions of targets and obstacles. Moreover, when agents are trained in a specific scenario, they can adapt to a new one with minimal additional training. We also show that our approach achieves better performance compared to a computationally intensive look-ahead heuristic.},
keywords={Drones;Training;Sensors;Surveillance;Reinforcement learning;Wireless communication;Transfer learning;Artificial intelligence;distributed decision making;mobile robots;neural network applications},
doi={10.1109/TCCN.2021.3063170},
ISSN={2332-7731},
month={Sep.},}
@INPROCEEDINGS{8304318,
author={Wang, Shengke and Liu, Lu and Duan, Lianghua and Yu, Changyin and Cai, Guiyan and Gao, Feng and Dong, Junyu},
booktitle={2017 International Conference on Security, Pattern Analysis, and Cybernetics (SPAC)}, title={Accurate segmentation of Ulva prolifera regions with superpixel and CNNs},
year={2017},
volume={},
number={},
pages={433-438},
abstract={To get regions of Ulva prolifera, we propose a novel end-to-end way to segment the Ulva prolifera regions via aggregation of local classify prediction results. We creatively adopt SEEDS (Superpixels Extracted via Energy-Driven Sampling) to generate local multi-scale patches. We use powerful convolution neural networks to learn and classify the patches. At last, mapping the classify prediction results of patches to the whole image according to the patches classify prediction results, we can get more detailed segmentation of Ulva prolifera. As for the dataset, we collected images by UAV (unmanned aerial vehicle) in coastal waters off Qingdao, China. We show experimentally this method achieves great segmentation performance of Ulva prolifera, despite its indistinct features. In contrast, we train the model in fully convolutional networks for semantic segmentation based on our dataset, while our result achieves superior accuracy.},
keywords={Image segmentation;Convolution;Neural networks;Security;Pattern analysis;Cybernetics;Green products;superpixel;convolution neural networks;segmentation;Ulva prolifera},
doi={10.1109/SPAC.2017.8304318},
ISSN={},
month={Dec},}
@INPROCEEDINGS{9075599,
author={Bini, D. and Pamela, D. and Prince, Shajin},
booktitle={2020 5th International Conference on Devices, Circuits and Systems (ICDCS)}, title={Machine Vision and Machine Learning for Intelligent Agrobots: A review},
year={2020},
volume={},
number={},
pages={12-16},
abstract={An intelligent precise autonomous farming by an agricultural robot achieves the farm duties possibly harvesting, weed detection, disease identification, pruning and fertilizing deals with path planning and mapping of the unstructured and uncertain environment. A machine vision-based Agrobots along with artificial intelligence provides unmanned ground vehicle and unmanned aerial vehicle to navigate the path and to implement the agricultural task for minimizing labour and increasing quality food production. The perception-related work uses a machine learning algorithm to detect the feature and analyze the agricultural tasks for the autonomous machine. The trained data sets create the ability for robots to learn and decide the farm practices. The dawn of autonomous system design gives us the outlook to develop a wide range of flexible agronomic equipment based on multi-robot, smart machines and human-robot systems which lessen waste, progresses economic feasibility also reduces conservational impact and intensifies food sustainability. The multi-tasking Agrobots overcomes the effort of farmers in agricultural husbandry, independent of the climatic conditions. In this paper, a study on Agrobots effective in a diverse environment, its control and action process conjoined with mapping and detection using machine vision and machine learning algorithms are distinguished.},
keywords={Task analysis;Machine vision;Agriculture;Robot sensing systems;Navigation;Agrobots;machine vision;machine learning;unmanned vehicles},
doi={10.1109/ICDCS48716.2020.243538},
ISSN={2644-1802},
month={March},}
@INPROCEEDINGS{7991445,
author={Manukyan, Anush and Olivares-Mendez, Miguel A. and Voos, Holger and Geist, Matthieu},
booktitle={2017 International Conference on Unmanned Aircraft Systems (ICUAS)}, title={Real time degradation identification of UAV using machine learning techniques},
year={2017},
volume={},
number={},
pages={1223-1230},
abstract={The usages and functionalities of Unmanned Aerial Vehicles (UAV) have grown rapidly during the last years. They are being engaged in many types of missions, ranging from military to agriculture passing by entertainment and rescue or even delivery. Nonetheless, for being able to perform such tasks, UAVs have to navigate safely in an often dynamic and partly unknown environment. This brings many challenges to overcome, some of which can lead to damages or degradations of different body parts. Thus, new tools and methods are required to allow the successful analysis and identification of the different threats that UAVs have to manage during their missions or flights. Various approaches, addressing this domain, have been proposed. However, most of them typically identify the changes in the UAVs behavior rather than the issue. This work presents an approach, which focuses not only on identifying degradations of UAVs during flights, but estimate the source of the failure as well.},
keywords={Degradation;Real-time systems;Data models;Solid modeling;Robot sensing systems},
doi={10.1109/ICUAS.2017.7991445},
ISSN={},
month={June},}
@INPROCEEDINGS{8568757,
author={Goudos, Sotirios K. and Tsoulos, George and Athanasiadou, Georgia},
booktitle={12th European Conference on Antennas and Propagation (EuCAP 2018)}, title={Artificial neural network optimal modelling of received signal strength in mobile communications using UAV measurements},
year={2018},
volume={},
number={},
pages={1-4},
abstract={In this paper, we apply an alternative procedure for the prediction of received signal strength in mobile communications based on Artificial Neural Networks (ANN). We use experimental data measurements taken from an unmanned aerial vehicle (UAV) for ANN training. We apply several evolutionary algorithms (EAs) in conjunction with the Levenberg-Marquardt (LM) backpropagation algorithm in order to train different ANNs. We design two new hybrid training methods by combing LM with self-adaptive Differential Evolution (DE) strategies. These new training methods achieve better convergence of neural network weight optimization than the original LM method. The received results are compared to the real values using representative ANN performance indices and exhibit satisfactory accuracy.},
keywords={UAV;mobile communications;propagation prediction;ANN;LM;DE},
doi={10.1049/cp.2018.1079},
ISSN={},
month={April},}
@INPROCEEDINGS{8666863,
author={Yun, Sun and Ying, Wang and Xiangfei, Meng and Fashun, Zhu and Wen, Guo},
booktitle={2018 International Conference on Information Systems and Computer Aided Education (ICISCAE)}, title={Methodology of estimating the embedding dimension in chaos time series based on the prediction performance of K-CV_GRNN},
year={2018},
volume={},
number={},
pages={202-205},
abstract={This paper is about the methodology of estimating the embedding dimension for phase space reconstruction of chaotic time series according to the Takens theorem. Based on the prediction of nonlinear performance, it proposed an approach to the estimation of the embedding dimension based on the Generalized Regression Neural Network of K-Fold Cross Validation to solve the problems of small data, existing noise, subjective evaluation indexes in the prediction of chaotic time series. That is, it determines the embedding dimension by considering the variation (prediction accuracy and normalized variance) of the performance of prediction model of chaotic time series with embedding dimension. Numerical simulations verify that the method is applicable for determining an appropriate embedding dimension.},
keywords={Time series analysis;Training;Predictive models;Estimation;Neural networks;Delays;Smoothing methods;chaos;phase space reconstruction;embedding dimension},
doi={10.1109/ICISCAE.2018.8666863},
ISSN={},
month={July},}
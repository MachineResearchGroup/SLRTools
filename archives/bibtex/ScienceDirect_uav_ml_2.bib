@article{PHAM2021103141,
title = {Swarm intelligence for next-generation networks: Recent advances and applications},
journal = {Journal of Network and Computer Applications},
volume = {191},
pages = {103141},
year = {2021},
issn = {1084-8045},
doi = {https://doi.org/10.1016/j.jnca.2021.103141},
url = {https://www.sciencedirect.com/science/article/pii/S1084804521001582},
author = {Quoc-Viet Pham and Dinh C. Nguyen and Seyedali Mirjalili and Dinh Thai Hoang and Diep N. Nguyen and Pubudu N. Pathirana and Won-Joo Hwang},
keywords = {5G and beyond, 6G, Artificial intelligence (AI), Computational intelligence, Swarm intelligence (SI), Next-generation wireless networks},
abstract = {In next-generation networks (NGN), a very large number of devices and applications are emerged, along with the heterogeneity of technologies, architectures, mobile data, etc., and optimizing such a network is of utmost importance. Besides convex optimization and game theory, swarm intelligence (SI) has recently appeared as a promising optimization tool for wireless networks. As a new subdivision of artificial intelligence, SI is inspired by the collective behaviors of societies of biological species. In SI, simple agents with limited capabilities can achieve intelligent strategies for high-dimensional and challenging problems, and thus SI has recently found many applications in NGN. However, SI techniques have still not fully investigated in the literature, especially in the contexts of wireless networks. In this work, our primary focus will be the integration of these two domains, i.e., NGN and SI. Firstly, we provide an overview of SI techniques from fundamental concepts to well-known optimizers. Secondly, we review the applications of SI to settle emerging issues in NGN, including spectrum management and resource allocation, wireless caching and edge computing, network security, and several other miscellaneous issues. Finally, we highlight challenges and issues in the literature, and introduce some interesting directions for future research.}
}
@article{LIU2017135,
title = {Control techniques of tilt rotor unmanned aerial vehicle systems: A review},
journal = {Chinese Journal of Aeronautics},
volume = {30},
number = {1},
pages = {135-148},
year = {2017},
issn = {1000-9361},
doi = {https://doi.org/10.1016/j.cja.2016.11.001},
url = {https://www.sciencedirect.com/science/article/pii/S1000936116302199},
author = {Zhong Liu and Yuqing He and Liying Yang and Jianda Han},
keywords = {Aircraft structures, Dynamics modeling, Flight control, Tilt rotors, Unmanned aerial vehicle (UAV)},
abstract = {The tilt rotor unmanned aerial vehicle (TRUAV) exhibits special application value due to its unique rotor structure. However, varying dynamics and aerodynamic interference caused by tiltable rotors are great technical challenges and key issues for TRUAV’s high-powered flight controls, which have attracted the attention of many researchers. This paper outlines the concept of TRUAV and some typical TRUAV platforms while focusing on control techniques. TRUAV structural features, dynamics modeling, and flight control methods are discussed, and major challenges and corresponding developmental tendencies associated with TRUAV flight control are summarized.}
}
@article{YANG2021386,
title = {Image recognition of wind turbine blade damage based on a deep learning model with transfer learning and an ensemble learning classifier},
journal = {Renewable Energy},
volume = {163},
pages = {386-397},
year = {2021},
issn = {0960-1481},
doi = {https://doi.org/10.1016/j.renene.2020.08.125},
url = {https://www.sciencedirect.com/science/article/pii/S0960148120313707},
author = {Xiyun Yang and Yanfeng Zhang and Wei Lv and Dong Wang},
keywords = {Wind turbine blades, Defect recognition, Deep learning, Transfer learning, Ensemble learning classifier},
abstract = {An image recognition model based on a deep learning network is proposed for the automatic extraction of image features and the accurate and efficient detection of wind turbine blade damage. The Otsu threshold segmentation method is used to segment the blade image to eliminate the influence of the image background on the detection task. In order to improve the recognition performance of the proposed deep learning model, transfer learning and an ensemble learning classifier are used in a convolutional neural network model. Transfer learning is used to enhance the ability of the proposed model to extract abstract features and accelerate the convergence efficiency, whereas the random forest-based ensemble learning classifier is used to improve the accuracy of detecting the blade defects. The performance of the proposed model is verified by using unmanned aerial vehicle (UAV) images of the wind turbine blades. The proposed model provided better performance than the support vector machine (SVM) method, the basic deep learning model and the deep learning model combined with the ensemble learning approach.}
}
@article{GONCALVES2017383,
title = {Unmanned aerial vehicle safety assessment modelling through petri Nets},
journal = {Reliability Engineering & System Safety},
volume = {167},
pages = {383-393},
year = {2017},
note = {Special Section: Applications of Probabilistic Graphical Models in Dependability, Diagnosis and Prognosis},
issn = {0951-8320},
doi = {https://doi.org/10.1016/j.ress.2017.06.021},
url = {https://www.sciencedirect.com/science/article/pii/S0951832016300953},
author = {P. Gonçalves and J. Sobral and L.A. Ferreira},
keywords = {Petri Nets, UAV, UAS, Safety assessment},
abstract = {Currently we are facing an increasing trend of use of Unmanned Aerial Vehicles (UAV) in various activities both civilian and military. Although there is no legal framework for the operation of these systems, regulatory authorities require the demonstration of a safety level equivalent to manned aircraft. It is known the high vulnerability of the UAV not only to unexpected failures of their systems but also to the environment. The purpose of this paper is to present a safety assessment process modelling of a UAV by Petri Nets, that can be accepted by certifying bodies, considering the recommendations of STANAG 4671 UAV Airworthiness Requirements Specification (USAR) for analysis of fault conditions that lead to the most feared events. It is intended to show through the use of Petri Nets the frequency that the UAV enters the identified states described as most feared events; the ability of the UAV to react after being in a fault situation to the inputs of the operating crew in order to enhance trust and to facilitate the operation authorization process in UAV operations. The results obtained allowed to identify and to define critical areas and corrective actions that will lead to an acceptable level of risk for the regulatory authority.}
}
@article{BOUTEMEDJET2019464,
title = {UAV aerodynamic design involving genetic algorithm and artificial neural network for wing preliminary computation},
journal = {Aerospace Science and Technology},
volume = {84},
pages = {464-483},
year = {2019},
issn = {1270-9638},
doi = {https://doi.org/10.1016/j.ast.2018.09.043},
url = {https://www.sciencedirect.com/science/article/pii/S1270963818302359},
author = {Abdelwahid Boutemedjet and Marija Samardžić and Lamine Rebhi and Zoran Rajić and Takieddine Mouada},
keywords = {Unmanned aerial vehicle, Preliminary aerodynamic design, Wing design, Genetic algorithm optimization, Computational Fluid Dynamic, Wind tunnel testing},
abstract = {In this paper, the aerodynamic design procedure of a mini unmanned aerial vehicle, intended to perform aerial reconnaissance at low altitude and low Reynolds number, was summarized. Design process was divided into two major parts: conceptual design phase and preliminary design phase. During the conceptual design, classical procedures and data from similar unmanned aerial vehicles already designed were employed to define the requirements related to unmanned aerial vehicle design. The preliminary design was performed using panel method where the emphasis was given on the design of the UAV wing, fuselage design and empennage. The wing planform parameters were determined through an aerodynamic optimization process using both genetic algorithms and artificial neural networks. Finally an aerodynamic analysis using panel method, Computational Fluid Dynamic simulations and wind tunnel testing was carried out. Unmanned aerial vehicle full configuration design process was consistent, where a comparison between the final obtained results was carried out and showed an agreement in terms of lift, drag and pitch moment coefficients.}
}
@article{SINGHAL2019100235,
title = {Chlorophyll estimation using multi-spectral unmanned aerial system based on machine learning techniques},
journal = {Remote Sensing Applications: Society and Environment},
volume = {15},
pages = {100235},
year = {2019},
issn = {2352-9385},
doi = {https://doi.org/10.1016/j.rsase.2019.100235},
url = {https://www.sciencedirect.com/science/article/pii/S2352938519300989},
author = {Gaurav Singhal and Babankumar Bansod and Lini Mathew and Jonali Goswami and B.U. Choudhury and P.L.N. Raju},
keywords = {Unmanned aerial vehicle, Leaf chlorophyll concentration, Machine learning},
abstract = {Remote sensing for precision agriculture is a proven tool for efficient management of crop inputs. High spatial and temporal resolutions are requisite for accurate and timely estimate of crop parameters. We made an attempt to estimatetheleaf chlorophyll concentration of standing maize plant from high resolution (5 cm) multi-spectral Unmanned Aerial Vehicle (UAV) images. The UAV images in Green, Red, Red-Edge and NIR bands of standing maize fields under various nutrient induced abiotic stresses were acquired by flying a hexacopter at an elevation of 60  m at ICAR Research Complex for NEH Region, Meghalaya. A handheld spectroradiometer was also used to record the spectra in 1024 bands, ranging from 350 nm to 2500 nm to support the UAV study. We evaluated advanced machine learning algorithms combined with spectral data and ground truth chlorophyll to model the chlorophyll estimates. Algorithms included Support vector regression, Relevance vector regression, Gaussian process regression, Kernel ridge regression and Random forest with K-fold cross validation. The multivariate analysis applied on spectroradiometer and UAV data showed the dominance of Red-band for chlorophyll prediction with R2 values greater than 0.80. Among the machine learning algorithms, we found the Kernel-Ridge regression was most robust method for developing chlorophyll estimation model with minimal RMSE (0.057 mg/gm) and regression coefficient of determination (R2 = 0.904). The relevance vector machine also predicted chlorophyll concentration satisfactorily (R2 = 0.87 with RMSE of 0.06 mg/gm), but took larger training time. The optimization and hybridisation of kernel based algorithms is further needed to enhance the reliability of models for prediction of leaf chlorophyll concentrations.}
}
@article{ZHOU2021106019,
title = {Assessment for crop water stress with infrared thermal imagery in precision agriculture: A review and future prospects for deep learning applications},
journal = {Computers and Electronics in Agriculture},
volume = {182},
pages = {106019},
year = {2021},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2021.106019},
url = {https://www.sciencedirect.com/science/article/pii/S0168169921000375},
author = {Zheng Zhou and Yaqoob Majeed and Geraldine {Diverres Naranjo} and Elena M.T. Gambacorta},
keywords = {Canopy temperature, CWSI, Canopy segmentation, Deep learning},
abstract = {With the increasing global water scarcity, efficient assessment methods for crop water stress have become a prerequisite to perform precision irrigation scheduling. The 1accessibility of infrared thermal sensor provides a powerful tool to detect and quantify crop water stress. This paper reviews the current practices of infrared thermal imagery utilized to assess crop water stress. Overall, three technological aspects of infrared thermal sensing applications for crop water stress assessment are reviewed along with the challenges and recommendations: (i) introduction of uncooled thermal camera and platforms, including ground-based platform and unmanned aerial vehicles (UAVs) platforms, for thermal imaging acquisition, (ii) strategies of canopy segmentation in thermal imaging used to obtain average canopy temperature for CWSI calculation, (iii) correlation between three forms of crop water stress index (CWSI) i.e. theoretical CWSI (CWSIt), empirical CWSI (CWSIe), and statistic CWSI (CWSIs) and physiological indicators. The emphasis is on imaging process techniques for canopy segmentation in thermal imaging. As a future perspective, the potential use of deep learning approaches to assess crop water stress has been elaborated highlighting the future trends.}
}
@article{HU20191,
title = {Pixel size of aerial imagery constrains the applications of unmanned aerial vehicle in crop breeding},
journal = {ISPRS Journal of Photogrammetry and Remote Sensing},
volume = {154},
pages = {1-9},
year = {2019},
issn = {0924-2716},
doi = {https://doi.org/10.1016/j.isprsjprs.2019.05.008},
url = {https://www.sciencedirect.com/science/article/pii/S0924271619301303},
author = {Pengcheng Hu and Wei Guo and Scott C. Chapman and Yan Guo and Bangyou Zheng},
keywords = {Plant phenotyping, Ground coverage, Remote sensing, Pixel size, UAV},
abstract = {Image analysis using proximal sensors can help accelerate the selection process in plant breeding and improve the breeding efficiency. However, the accuracies of extracted phenotypic traits, especially those that require image classification, are affected by the pixel size in images. Ground coverage (GC), the ratio of projected to ground vegetation area to total land area, is a simple and important trait to monitor crop growth and development and is often captured by visual-spectrum cameras on multiple platforms from ground-based vehicles to satellites. In this study, we used GC as an example trait and explored its dependency on pixel size. In developing new spring wheat varieties, breeders often aim for rapid GC estimation, which is challenging especially when coverage is low (<25%) in a species with thin leaves (ranging from 2 to 15 mm across). In a wheat trial comprising 28 treatments, high-resolution images were manually taken at ca. 1 m above canopies on seven occasions from emergence to flowering. Using a cubic interpolation algorithm, the original images with small pixel size were degraded into coarse images with large pixel size (from 0.1 to 5.0 cm per pixel, 26 extra levels in total) to mimic the image acquisition at different flight heights of an unmanned aerial vehicle (UAV) based platform. A machine learning based classification model was used to classify pixels of the original images and the corresponding degraded images into either vegetation and background classes, and then computed their GCs. GCs of original images were referred as reference values to their corresponding degraded images. As pixel size increased, GC of the degraded images tended to be underestimated when reference GC was less than about 50% and overestimated for GC > 50%. The greatest errors (about 30%) were observed when reference GCs were around 30% and 70%. Meanwhile, the largest pixel sizes to distinguish between two treatments depended on the difference between GCs of the two treatments and were rapidly increased when differences were greater than the specific values at given significance levels (i.e. about 10%, 8% and 6% for P < 0.01, 0.05 and 0.1, respectively). For wheat, small pixel size (e.g. <0.1 cm) is always required to accurately estimate ground coverage when the most practical flight height is about 20 to 30 m at present. This study provides a guideline to choose appropriate pixel sizes and flight plans to estimate GC and other traits in crop breeding using UAV based HTP platforms.}
}
@article{QIAN2020105519,
title = {UAV and a deep convolutional neural network for monitoring invasive alien plants in the wild},
journal = {Computers and Electronics in Agriculture},
volume = {174},
pages = {105519},
year = {2020},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2020.105519},
url = {https://www.sciencedirect.com/science/article/pii/S0168169920302921},
author = {Wanqiang Qian and Yiqi Huang and Qi Liu and Wei Fan and Zhongyu Sun and Hui Dong and Fanghao Wan and Xi Qiao},
keywords = {Invasive alien plant, Multi-object identification, Deep learning, Computer vision},
abstract = {Invasive alien plants (IAPs) are considered to be among the greatest global threats to biodiversity and ecosystems. Timely and effective monitoring is important for their prevention and control. However, monitoring remains mainly dependent on satellite remote sensing and manual inspection, which has a high cost and rather low accuracy and efficiency. We considered that this problem could be solved using unmanned aerial vehicle (UAV) intelligent monitoring. Accurate and rapid identification of IAPs in the wild is the core of intelligent monitoring. We intended to acquire colour images of the monitoring area in a field environment using an UAV and proposing a novel IAPsNet based on a deep convolutional neural network (CNN) to identify the IAPs appearing in the images. 6400 samples were one by one manually divided into seven IAP categories and one background category as training set. IAPsNet incorporated AlexNet local response normalization (LRN), GoogLeNet inception models, and continuous VGG convolution. Through training and testing, the IAPsNet performance for 893 testing samples was rather satisfactory, reaching an accuracy of 93.39% within a time of 1.8846 s and the average recall, average precision and average F1-score can reach 93.3%, 93.74% and 93.52% respectively. Moreover, in quantitative and qualitative comparative analysis, IAPsNet not only has high accuracy, high recall, high precision, high F1-score and efficiency but also has a high anti-interference capacity against blur, environment and multi-scales. Additionally, IAPsNet was applied to 4 different real wild conditions, proving that it is able to adapt to different scenes and simultaneously identify multiple species; it has potential to be used in the wild. High-quality distributional data of invasive plants are provided for subsequent ecological analysis. The data will help management authorities to implement the necessary steps in an identified area to develop a comprehensive strategy for IAP control.}
}
@article{ELHOUMMAIDI2021e08154,
title = {Using unmanned aerial systems and deep learning for agriculture mapping in Dubai},
journal = {Heliyon},
volume = {7},
number = {10},
pages = {e08154},
year = {2021},
issn = {2405-8440},
doi = {https://doi.org/10.1016/j.heliyon.2021.e08154},
url = {https://www.sciencedirect.com/science/article/pii/S240584402102257X},
author = {Lala {El Hoummaidi} and Abdelkader Larabi and Khan Alam},
keywords = {Agriculture mapping, Deep learning, GIS, Drone mapping, Precision agriculture, Multispectral images, UAV, UAS},
abstract = {As part of the sustainable future vision, sustainable agriculture has become an essential pillar of the food security strategies formulated by the Dubai Government. Therefore, the Dubai Emirate began relying on new technology to increase productivity and efficiency. Agriculture applications also depend on accurate land monitoring for timely food security control and support actions. However, traditional monitoring requires field surveys to be performed by experts, which is costly, slow, and rare. Agriculture monitoring systems must be furnished with sustainable land use monitoring solutions, starting with remote sensing using drone surveys for affordable, efficient, and time-sensitive agriculture mapping. Hence, the Dubai Municipality is currently using Unmanned Aerial Vehicles (UAVs) to map the farming areas all over the Emirate, support locating lands conducive to cultivation, and create an accurate agriculture database contributing to the decision-making process in determining areas suitable for crop growth. This study used a novel object detection method coupled with geospatial analysis as an integrated workflow to detect individual crops. The UAV flights were executed using a Trimble UX5 (HP) over twelve communities across the Dubai Emirate for six months. Detection methods were applied to high-resolution drone images, consisting of RGB and near-infrared (NIR) bands. Advanced geoprocessing tools were also used to analyze, evaluate, and enhance the results. The performance of detection of the selected deep learning models are discussed (vegetation cover accuracy = 85.4%, F1-scores for date palms and ghaf trees = 96.03% and 94.54% respectively, with respect to visual interpretation ground truth); moreover, sample images from the datasets are used for demonstrations. The main aim is to offer specialists a solution for measuring and assessing living green vegetation cover derived from the processed images that is integrated. The results provide insight into using UAS and deep learning algorithms as a solution for sustainable agricultural mapping on a large scale.}
}
@article{SHARMA2020102739,
title = {Communication and networking technologies for UAVs: A survey},
journal = {Journal of Network and Computer Applications},
volume = {168},
pages = {102739},
year = {2020},
issn = {1084-8045},
doi = {https://doi.org/10.1016/j.jnca.2020.102739},
url = {https://www.sciencedirect.com/science/article/pii/S1084804520302137},
author = {Abhishek Sharma and Pankhuri Vanjani and Nikhil Paliwal and Chathuranga M.Wijerathna Basnayaka and Dushantha Nalin K. Jayakody and Hwang-Cheng Wang and P. Muthuchidambaranathan},
keywords = {5G mobile communication, Mobile communication, Unmanned aerial vehicles, Wireless networks, Communication systems},
abstract = {With the advancement in drone technology, in just a few years, drones will be assisting humans in every domain. But there are many challenges to be tackled, communication being the chief one. This paper aims at providing insights into the latest UAV (Unmanned Aerial Vehicle) communication technologies through investigation of suitable task modules, antennas, resource handling platforms, and network architectures. Additionally, we explore techniques such as machine learning and path planning to enhance existing drone communication methods. Encryption and optimization techniques for ensuring long−lasting and secure communications, as well as for power management, are discussed. Moreover, applications of UAV networks for different contextual uses ranging from navigation to surveillance, URLLC (Ultra-reliable and low−latency communications), edge computing and work related to artificial intelligence are examined. In particular, the intricate interplay between UAV, advanced cellular communication, and internet of things constitutes one of the focal points of this paper. The survey encompasses lessons learned, insights, challenges, open issues, and future directions in UAV communications. Our literature review reveals the need for more research work on drone−to−drone and drone−to−device communications.}
}
@article{YANG2020107938,
title = {A near real-time deep learning approach for detecting rice phenology based on UAV images},
journal = {Agricultural and Forest Meteorology},
volume = {287},
pages = {107938},
year = {2020},
issn = {0168-1923},
doi = {https://doi.org/10.1016/j.agrformet.2020.107938},
url = {https://www.sciencedirect.com/science/article/pii/S016819232030040X},
author = {Qi Yang and Liangsheng Shi and Jingye Han and Jin Yu and Kai Huang},
keywords = {Rice phenology detection, UAV, Convolutional neural network, Shape model fitting, Deep learning},
abstract = {Near real-time crop phenology detection is essential for crop management, estimation of harvest time and yield estimation. Previous approaches to crop phenology detection have relied on time-series (multi-temporal) vegetation index (VI) data, and have included threshold-based, phenometrics-based and shape-model-fitting-based (SMF) methods. However, the performance of these methods depends on the duration and temporal resolution of the time-series data. In this study, we propose a new approach which identifies the principal growth stages of rice (Oryza sativa L.) directly from RGB images. Only a mono-temporal unmanned aerial vehicle (UAV) imagery was required for a large-area phenology detection via the well-trained network. An efficient convolutional neural network (CNN) architecture was designed to estimate rice phenology. The CNN incorporated spatial pyramid pooling (SPP), transfer learning and an auxiliary branch with external data. A total of 82 plots across a 160-hectare rice cultivation area of Southern China were selected to evaluate the proposed network. CNN predictions were ground truthed using rice phenology measurements taken from each plot throughout the growing season. Aerial data were collected using a fixed-wing UAV equipped with multispectral and RGB cameras. The performance of traditional SMF methods deteriorated when time-series VI data were of short duration. In contrast, the phenological stage estimated by the proposed network showed good agreement with ground observations, with a top-1 accuracy rate of 83.9% and mean absolute error (MAE) of 0.18. The spatial distribution of harvest dates for 627 plots in the study area were computed from the phenological stage estimates. The estimates matched well with the observed harvest dates. The results demonstrated the excellent performance of the proposed deep learning approach in near real-time phenology detection and harvest time estimation.}
}
@article{YANG20191716,
title = {Real-time object tracking via least squares transformation in spatial and Fourier domains for unmanned aerial vehicles},
journal = {Chinese Journal of Aeronautics},
volume = {32},
number = {7},
pages = {1716-1726},
year = {2019},
issn = {1000-9361},
doi = {https://doi.org/10.1016/j.cja.2019.01.020},
url = {https://www.sciencedirect.com/science/article/pii/S1000936119300858},
author = {Xiaoyuan YANG and Ridong ZHU and Jingkai WANG and Zhengze LI},
keywords = {Correlation filter, Discrete Fourier transform, Least squares, Object tracking, Unmanned aerial vehicle},
abstract = {This paper addresses the problem of real-time object tracking for unmanned aerial vehicles. We consider the task of object tracking as a classification problem. Training a good classifier always needs a huge number of samples, which is always time-consuming and not suitable for real-time applications. In this paper, we transform the large-scale least-squares problem in the spatial domain to a series of small-scale least-squares problems with constraints in the Fourier domain using the correlation filter technique. Then, this problem is efficiently solved by two stages. In the first stage, a fast method based on recursive least squares is used to solve the correlation filter problem without constraints in the Fourier domain. In the second stage, a weight matrix is constructed to prune the solution attained in the first stage to approach the constraints in the spatial domain. Then, the pruned classifier is used for tracking. To evaluate proposed tracker’s performance, comprehensive experiments are conducted on challenging aerial sequences in the UAV123 dataset. Experimental results demonstrate that proposed approach achieves a state-of-the-art tracking performance in aerial sequences and operates at a mean speed of beyond 40 frames/s. For further analysis of proposed tracker’s robustness, extensive experiments are also performed on recent benchmarks OTB50, OTB100, and VOT2016.}
}
@article{BUONOCORE20141234,
title = {Effects of Packet Losses on Formation Control of Unmanned Aerial Vehicles},
journal = {IFAC Proceedings Volumes},
volume = {47},
number = {3},
pages = {1234-1240},
year = {2014},
note = {19th IFAC World Congress},
issn = {1474-6670},
doi = {https://doi.org/10.3182/20140824-6-ZA-1003.02216},
url = {https://www.sciencedirect.com/science/article/pii/S1474667016417829},
author = {Luca Rosario Buonocore and Vincenzo Lippiello and Sabato Manfredi and Fabio Ruggiero and Bruno Siciliano},
abstract = {In this paper, the impact of the main packet loss models on the Unmanned Aerial Vehicle (UAV) formation control has been evaluated. A simulation environment has been built to introduce a centralized architecture, usually employed in mobile robotics to pursue global tasks, in the presence of loss models affecting the communication through robots hops. Simulation results show that the control performance in terms of tracking, collision avoidance and loss of connectivity are affected by the specific characteristics of packet loss. This suggests that the design of UAV formation control over wireless network has to be carried out strongly taking into account the effects of specific packet loss characteristics (due to wireless protocol, disturbance, traffic) on the performance quality.}
}
@article{ALVESRIBEIRO201711607,
title = {Multi-Objective Model Selection for Unmanned Aerial Vehicles Automatic Target Recognition Systems},
journal = {IFAC-PapersOnLine},
volume = {50},
number = {1},
pages = {11607-11612},
year = {2017},
note = {20th IFAC World Congress},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2017.08.1652},
url = {https://www.sciencedirect.com/science/article/pii/S2405896317322577},
author = {Victor Henrique {Alves Ribeiro} and Gilberto Reynoso-Meza and Leandro {dos Santos Coelho}},
keywords = {Classifiers, Artificial neural networks, Optimization, Multi-objective optimization, Genetic algorithms, Signal processing, Electromagnetic signals},
abstract = {Within unmanned aerial vehicles on-going research topics, automatic target recognition is acquiring relevance. This is due to the easiness with which it is possible to acquire such devices. In order to do this, signal processing and classification techniques could be adopted. Also, in order to improve the classification ratio, optimization techniques could be used. This subject is object of study for many researchers, but the authors worry about the lack of information while using single-objective optimization techniques. The proposed work comprises the application of multi-objective optimization design in order to create an automatic target recognition system to discriminate different types of unmanned aerial vehicles. In order to accomplish this, a K-band radar system is used to send and receive electromagnetic signals, which are then processed with feature extraction techniques, and finally, applied on an artificial neural network system. In order to improve the system’s classification ratio, the classifier is defined as a multi-objective problem, and evolutionary multi-objective optimization techniques are applied. Finally, in order to select the best possible trade-off, the level diagrams multi-criteria decision making methodology is used to compare different solutions.}
}
@article{SAEED201891,
title = {A survey of hybrid Unmanned Aerial Vehicles},
journal = {Progress in Aerospace Sciences},
volume = {98},
pages = {91-105},
year = {2018},
issn = {0376-0421},
doi = {https://doi.org/10.1016/j.paerosci.2018.03.007},
url = {https://www.sciencedirect.com/science/article/pii/S0376042117302233},
author = {Adnan S. Saeed and Ahmad Bani Younes and Chenxiao Cai and Guowei Cai},
keywords = {Hybrid UAVs, Platform design, Dynamic modeling, Flight control, Fixed wing VTOL, Tailsitter},
abstract = {This article presents a comprehensive overview on the recent advances of miniature hybrid Unmanned Aerial Vehicles (UAVs). For now, two conventional types, i.e., fixed-wing UAV and Vertical Takeoff and Landing (VTOL) UAV, dominate the miniature UAVs. Each type has its own inherent limitations on flexibility, payload, flight range, cruising speed, takeoff and landing requirements and endurance. Enhanced popularity and interest are recently gained by the newer type, named hybrid UAV, that integrates the beneficial features of both conventional ones. In this survey paper, a systematic categorization method for the hybrid UAV's platform designs is introduced, first presenting the technical features and representative examples. Next, the hybrid UAV's flight dynamics model and flight control strategies are explained addressing several representative modeling and control work. In addition, key observations, existing challenges and conclusive remarks based on the conducted review are discussed accordingly.}
}
@article{WANG2021107628,
title = {An Intelligent UAV based Data Aggregation Algorithm for 5G-enabled Internet of Things},
journal = {Computer Networks},
volume = {185},
pages = {107628},
year = {2021},
issn = {1389-1286},
doi = {https://doi.org/10.1016/j.comnet.2020.107628},
url = {https://www.sciencedirect.com/science/article/pii/S138912862031255X},
author = {Xiaoding Wang and Sahil Garg and Hui Lin and Georges Kaddoum and Jia Hu and Mohammed F. Alhamid},
keywords = {Unmanned Aerial Vehicle, 5G, Internet of Things, Data aggregation, Deep reinforcement learning},
abstract = {Unmanned Aerial Vehicle (UAV) has become a significant part of 5G or beyond 5G (B5G) paradigm, and is used in various scenarios, including cargo delivery, agricultural application, event surveillance, etc. Although plenty of studies have been proposed on UAV-based data aggregation, how to ensure security and energy-efficiency of the data aggregation process in 5G-enabled Internet of Things (IoT) is an open problem. In this paper, we propose an Intelligent UAV-based Data Aggregation Algorithm, named IDAA for 5G-Enabled IoT. Specifically, IDAA applies v-Support Vector Regression (v-svr) to predict the data collection rate. Then, a security level based task decomposition mechanism is designed that allows UAVs to accept the tasks of corresponding security levels. Finally, energy efficient routes for UAV are planned utilizing a deep reinforcement learning method to achieve the trade-off between the sinking ratio and the energy cost. The theoretical analysis and simulation results indicate that (i) IDAA improves the security of data aggregation; and (ii) IDAA enables UAVs to collect more data and consume less energy compared with baseline strategies.}
}
@article{FENG2020105711,
title = {Evaluation of cotton emergence using UAV-based imagery and deep learning},
journal = {Computers and Electronics in Agriculture},
volume = {177},
pages = {105711},
year = {2020},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2020.105711},
url = {https://www.sciencedirect.com/science/article/pii/S0168169920314216},
author = {Aijing Feng and Jianfeng Zhou and Earl Vories and Kenneth A. Sudduth},
keywords = {Emergence evaluation, Stand count, Row geo-reference, Real-time processing},
abstract = {Crop emergence is an important agronomic factor for making field management decisions, such as replanting, that are time-sensitive and need to be made at very early stages. Crop emergence, evaluated using plant population, stand count and uniformity, is conventionally quantified manually, not accurate, and labor and time intensive. Unmanned aerial vehicle (UAV)-based imaging systems are able to scout crop fields rapidly. However, data processing can be too slow to make timely decision making. The goal of this study was to develop a novel image processing method for processing UAV images in nearly real-time. In this study, a UAV imaging system was used to capture RGB image frames of cotton seedlings to evaluate stand count and canopy size. Images were pre-processed to correct distortions, calculate ground sample distance and geo-reference cotton rows in the images. A pre-trained deep learning model, resnet 18, was used to estimate stand count and canopy size of cotton seedlings in each image frame. Results showed that the developed method could estimate stand count accurately with R2 = 0.95 in the test dataset. Similar results were achieved for canopy size with an estimation accuracy of R2 = 0.93 in the test dataset. The processing time for each image frame of 20 M pixels with each crop row geo-referenced was 2.22 s (including 1.80 s for pre-processing), which was more efficient than traditional mosaic-based image processing methods. An open-source automated image-processing framework was developed for cotton emergence evaluation and is available to the community for efficient data processing and analytics.}
}
@article{HAO2021112,
title = {Automated tree-crown and height detection in a young forest plantation using mask region-based convolutional neural network (Mask R-CNN)},
journal = {ISPRS Journal of Photogrammetry and Remote Sensing},
volume = {178},
pages = {112-123},
year = {2021},
issn = {0924-2716},
doi = {https://doi.org/10.1016/j.isprsjprs.2021.06.003},
url = {https://www.sciencedirect.com/science/article/pii/S0924271621001611},
author = {Zhenbang Hao and Lili Lin and Christopher J. Post and Elena A. Mikhailova and Minghui Li and Yan Chen and Kunyong Yu and Jian Liu},
keywords = {Deep learning, Instance segmentation, Tree-crown delineation, Tree height, UAV imagery, Plantation forest},
abstract = {Tree-crown and height are primary tree measurements in forest inventory. Convolutional neural networks (CNNs) are a class of neural networks, which can be used in forest inventory; however, no prior studies have developed a CNN model to detect tree crown and height simultaneously. This study is the first-of-its-kind that explored training a mask region-based convolutional neural network (Mask R-CNN) for automatically and concurrently detecting discontinuous tree crown and height of Chinese fir (Cunninghamia lanceolata (Lamb) Hook) in a plantation. A DJI Phantom4-Multispectral Unmanned Aerial Vehicle (UAV) was used to obtain high-resolution images of the study site, Shunchang County, China. Tree crown and height of Chinese fir was manually delineated and derived from this UAV imagery. A portion of the ground-truthed tree height values were used as a test set, and the remaining measurements were used as the model training data. Six different band combinations and derivations of the UAV imagery were used to detect tree crown and height, respectively (Multi band-DSM, RGB-DSM, NDVI-DSM, Multi band-CHM, RGB-CHM, and NDVI-CHM combination). The Mask R-CNN model with the NDVI-CHM combination achieved superior performance. The accuracy of Chinese fir’s individual tree-crown detection was considerable (F1 score = 84.68%), the Intersection over Union (IoU) of tree crown delineation was 91.27%, and tree height estimates were highly correlated with the height from UAV imagery (R2 = 0.97, RMSE = 0.11 m, rRMSE = 4.35%) and field measurement (R2 = 0.87, RMSE = 0.24 m, rRMSE = 9.67%). Results demonstrate that the input image with an CHM achieves higher accuracy of tree crown delineation and tree height assessment compared to an image with a DSM. The accuracy and efficiency of Mask R-CNN has a great potential to assist the application of remote sensing in forests.}
}
@article{YU2021102363,
title = {A machine learning algorithm to detect pine wilt disease using UAV-based hyperspectral imagery and LiDAR data at the tree level},
journal = {International Journal of Applied Earth Observation and Geoinformation},
volume = {101},
pages = {102363},
year = {2021},
issn = {0303-2434},
doi = {https://doi.org/10.1016/j.jag.2021.102363},
url = {https://www.sciencedirect.com/science/article/pii/S0303243421000702},
author = {Run Yu and Youqing Luo and Quan Zhou and Xudong Zhang and Dewei Wu and Lili Ren},
keywords = {Pine wilt disease, Airborne hyperspectral imagery, Airborne LiDAR, Random forest},
abstract = {Pine wilt disease (PWD) is a global destructive threat to forests, having caused extreme damage in China. Therefore, the establishment of an effective method to accurately monitor and map the infection stage by PWD is imperative. Unmanned aerial vehicle (UAV)-based hyperspectral imaging (HI) and light detection and ranging (LiDAR) technique is an effective approach for forest health monitoring. However, few previous studies have used airborne HI and LiDAR to detect PWD and compared the capability for predicting PWD infection stage at the tree level. In this paper, PWD infection was divided into five stages (green, early, middle, heavy, and grey), and HI and LiDAR data were integrated to detect PWD. We estimated the power of the hyperspectral method (HI data only), LiDAR (LiDAR data only), and their combination (HI plus LiDAR data) to predict the infection stages of PWD using the random forest (RF) algorithm. We obtained the following results: (1) The classification accuracies of HI (OA: 66.86%, Kappa: 0.57) were higher than those of LiDAR (OA: 45.56%, Kappa: 0.27) for predicting PWD infection stages, and their combination had the best accuracies (OA: 73.96%, Kappa: 0.66); (2) LiDAR data had higher ability for dead tree identification than HI data; and (3) The combined use of HI and LiDAR data for estimation of PWD infection stages showed that LiDAR metrics (e.g., crown volume) were essential in the classification model, although the variables derived from HI data contributed more than those extracted from LiDAR. Therefore, we proposed a new approach combining the merits of HI and LiDAR data to precisely predict PWD infection stages at the tree level, allowing better PWD monitoring and control. The approach could also be employed for mapping and monitoring other forest disturbance issues.}
}
@article{LI2022107309,
title = {Low-Reynolds-number airfoil design optimization using deep-learning-based tailored airfoil modes},
journal = {Aerospace Science and Technology},
volume = {121},
pages = {107309},
year = {2022},
issn = {1270-9638},
doi = {https://doi.org/10.1016/j.ast.2021.107309},
url = {https://www.sciencedirect.com/science/article/pii/S1270963821008191},
author = {Jichao Li and Mengqi Zhang and Chien Ming Jonathan Tay and Ningyu Liu and Yongdong Cui and Siou Chye Chew and Boo Cheong Khoo},
keywords = {UAV, Low-Reynolds-number airfoil, Deep learning, Aerodynamic shape optimization, Modal parameterization, Geometric filtering},
abstract = {Low-Reynolds-number high-lift airfoil design is critical to the performance of unmanned aerial vehicles (UAV). However, since laminar-to-turbulent transition dominates the aerodynamic performance of low-Reynolds-number airfoils and the transition position may exhibit an abrupt change even with a small geometric deformation, aerodynamic coefficient functions become discontinuous in this regime, which brings significant difficulties to the application of conventional aerodynamic design optimization methods. To efficiently perform low-Reynolds-number airfoil design, we present a tailored airfoil modal parameterization method, which reasonably defines the desired design space using deep-learning techniques. Coupled with surrogate-based optimization, the proposed method has shown to be effective and efficient in low-Reynolds-number high-lift airfoil design. It is found that it is necessary to consider laminar-to-turbulent transition and to perform multi-point optimization in practical low-Reynolds-number airfoil design. The maximal lift coefficient is an active constraint influencing the selection of the optimal cruise lift coefficient. The results show the complexity of low-Reynolds-number high-lift airfoil design and highlight the significance of the proposed method in the improvement of optimization efficiency.}
}
@article{ZHONG2020112012,
title = {WHU-Hi: UAV-borne hyperspectral with high spatial resolution (H2) benchmark datasets and classifier for precise crop identification based on deep convolutional neural network with CRF},
journal = {Remote Sensing of Environment},
volume = {250},
pages = {112012},
year = {2020},
issn = {0034-4257},
doi = {https://doi.org/10.1016/j.rse.2020.112012},
url = {https://www.sciencedirect.com/science/article/pii/S0034425720303825},
author = {Yanfei Zhong and Xin Hu and Chang Luo and Xinyu Wang and Ji Zhao and Liangpei Zhang},
keywords = {Precise crop classification, UAV-borne hyperspectral imagery, Convolutional neural network, Conditional random fields, WHU-Hi dataset},
abstract = {Unmanned aerial vehicle (UAV)-borne hyperspectral systems can acquire hyperspectral imagery with a high spatial resolution (which we refer to here as H2 imagery). As a result of the low operating cost, high flexibility, and the ability to achieve real-time data acquisition, UAV-borne hyperspectral systems have become an important data source for remote sensing based agricultural monitoring. However, precise crop classification based on UAV-borne H2 imagery is a challenging task when faced with a number of different crop classes. The traditional hyperspectral classification methods, such as the spectral-based and object-oriented classification methods, have difficulty in classifying H2 imagery, faced with the problems of salt-and-pepper (SP) noise and scale selection. In this article, the deep convolutional neural network with a conditional random field classifier (CNNCRF) framework is proposed for precise crop classification with UAV-borne H2 imagery. In the proposed method, a deep convolutional neural network (CNN) is designed to extract and fuse in-depth spectral and local spatial features, and the conditional random field (CRF) model further incorporates the spatial-contextual information to improve the problem of holes and isolated regions in the classification map. Meanwhile, virtual sample augmentation based on the hyperspectral imaging mechanism is used to lessen the issue of the limited labeled samples. To validate the results, a new dataset—the Wuhan UAV-borne hyperspectral image (WHU-Hi) dataset—has been built for precise crop classification. The experimental results obtained using the WHU-Hi dataset confirm the accuracy and visualization performance of the proposed CNNCRF classification method, which outperforms the previous methods. In addition, the WHU-Hi dataset could serve as a benchmark dataset for hyperspectral image classification studies.}
}
@article{XU2019104938,
title = {Online spraying quality assessment system of plant protection unmanned aerial vehicle based on Android client},
journal = {Computers and Electronics in Agriculture},
volume = {166},
pages = {104938},
year = {2019},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2019.104938},
url = {https://www.sciencedirect.com/science/article/pii/S0168169919300845},
author = {Yang Xu and Xinyu Xue and Zhu Sun and Chun Chang and Wei Gu and Chen Chen and Yongkui Jin and Bin Peng},
keywords = {Plant protection UAV, Online assessment, Spraying quality, Android client, External Microphone, Endpoints extraction, Double-threshold, Gaussian Filtering},
abstract = {We develop an online spraying quality assessment system of plant protection unmanned aerial vehicle (UAV) based on Android Client. The built-in location and motion system of mobile phone are used to acquire the GPS data, speed and height of the UAV placed with Android mobile phone. A pump operation endpoints extraction model based on double-threshold method is developed to determine the pump operation status (on/off) during UAV flight. Adaptive Gaussian Filtering is employed to improve the positioning accuracy. Some assessment indexes including overlap spray and blank spray rates indicating plant protection UAV spraying quality are proposed in this paper. The test results show that: ① the max deviation of the beginning/end point extracted by double-threshold model is 2 s, and the max deviation of total operation time is 4 s; ② adaptive Gaussian Filtering can effectively improve the accuracy of static and dynamic positioning. We take filter parameter σ = 1, to decrease the measured dynamic positioning deviation and avoid clear reduction of measured total distance (when σ > 1) by smartphone; ③ when σ = 1, the difference values of effective spray rate, the overlap spray rate and the blank spray rate between smartphone measuring and UAV recording are only 1.08％, 0.68％and 1.07％, respectively.}
}
@article{OSCO202097,
title = {A convolutional neural network approach for counting and geolocating citrus-trees in UAV multispectral imagery},
journal = {ISPRS Journal of Photogrammetry and Remote Sensing},
volume = {160},
pages = {97-106},
year = {2020},
issn = {0924-2716},
doi = {https://doi.org/10.1016/j.isprsjprs.2019.12.010},
url = {https://www.sciencedirect.com/science/article/pii/S0924271619302989},
author = {Lucas Prado Osco and Mauro dos Santos de Arruda and José {Marcato Junior} and Neemias Buceli {da Silva} and Ana Paula Marques Ramos and Érika Akemi Saito Moryia and Nilton Nobuhiro Imai and Danillo Roberto Pereira and José Eduardo Creste and Edson Takashi Matsubara and Jonathan Li and Wesley Nunes Gonçalves},
keywords = {Deep learning, Multispectral image, UAV-borne sensor, Object detection, Citrus tree counting, Orchard},
abstract = {Visual inspection has been a common practice to determine the number of plants in orchards, which is a labor-intensive and time-consuming task. Deep learning algorithms have demonstrated great potential for counting plants on unmanned aerial vehicle (UAV)-borne sensor imagery. This paper presents a convolutional neural network (CNN) approach to address the challenge of estimating the number of citrus trees in highly dense orchards from UAV multispectral images. The method estimates a dense map with the confidence that a plant occurs in each pixel. A flight was conducted over an orchard of Valencia-orange trees planted in linear fashion, using a multispectral camera with four bands in green, red, red-edge and near-infrared. The approach was assessed considering the individual bands and their combinations. A total of 37,353 trees were adopted in point feature to evaluate the method. A variation of σ (0.5; 1.0 and 1.5) was used to generate different ground truth confidence maps. Different stages (T) were also used to refine the confidence map predicted. To evaluate the robustness of our method, we compared it with two state-of-the-art object detection CNN methods (Faster R-CNN and RetinaNet). The results show better performance with the combination of green, red and near-infrared bands, achieving a Mean Absolute Error (MAE), Mean Square Error (MSE), R2 and Normalized Root-Mean-Squared Error (NRMSE) of 2.28, 9.82, 0.96 and 0.05, respectively. This band combination, when adopting σ = 1 and a stage (T = 8), resulted in an R2, MAE, Precision, Recall and F1 of 0.97, 2.05, 0.95, 0.96 and 0.95, respectively. Our method outperforms significantly object detection methods for counting and geolocation. It was concluded that our CNN approach developed to estimate the number and geolocation of citrus trees in high-density orchards is satisfactory and is an effective strategy to replace the traditional visual inspection method to determine the number of plants in orchards trees.}
}
@article{MARAVALL2015101,
title = {Vision-based anticipatory controller for the autonomous navigation of an UAV using artificial neural networks},
journal = {Neurocomputing},
volume = {151},
pages = {101-107},
year = {2015},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2014.09.077},
url = {https://www.sciencedirect.com/science/article/pii/S0925231214013228},
author = {Darío Maravall and Javier {de Lope} and Juan {Pablo Fuentes}},
keywords = {Unmanned aerial vehicles, Vision-based dual anticipatory reactive controllers, Nearest neighbors methods, Topological maps, Neural networks},
abstract = {A vision-based anticipatory controller for the autonomous indoor navigation of an unmanned aerial vehicle (UAV) is the topic of this paper. A dual Feedforward/Feedback architecture has been used as the UAV׳s controller and the K-NN classifier using the gray level image histogram as discriminant variables has been applied for landmarks recognition. After a brief description of the UAV, we first identify the two main components of its autonomous navigation, namely, the landmark recognition and the dual controller based on cerebellar system of living beings, then we focus on the anticipatory module that has been implemented by an artificial neural network. Afterwards, the paper describes the experimental setup and discusses the experimental results centered mainly on the basic UAV׳s behavior of landmark approximation maneuver, which in topological navigation is known as the beaconing or homing problem.}
}
@article{ZHAO201968,
title = {Software-defined unmanned aerial vehicles networking for video dissemination services},
journal = {Ad Hoc Networks},
volume = {83},
pages = {68-77},
year = {2019},
issn = {1570-8705},
doi = {https://doi.org/10.1016/j.adhoc.2018.08.023},
url = {https://www.sciencedirect.com/science/article/pii/S1570870518306231},
author = {Zhongliang Zhao and Pedro Cumino and Arnaldo Souza and Denis Rosário and Torsten Braun and Eduardo Cerqueira and Mario Gerla},
keywords = {SDN, UAVNet, Video surveillance, Relay placement, Quality of experience},
abstract = {Unmanned Aerial Vehicles (UAVs) empower people to reach endangered areas under emergency situations. By collaborating with each other, multiple UAVs forming a UAV network (UAVNet) could work together to perform specific tasks in a more efficient and intelligent way than having a single UAV. UAVNets pose special characteristics of high dynamics, unstable aerial wireless links, and UAV collision probabilities. To address these challenges, we propose a Software-Defined UAV Networking (SD-UAVNet) architecture, which facilitates the management of UAV networks through a centralized SDN UAV controller. In addition, we introduce a use case scenario to evaluate the optimal UAV relay node placement for life video surveillance services with the proposed architecture. In the SD-UAVNet architecture, the controller considers the global UAV relevant context information to optimize the UAVs’ movements, selects proper routing paths, and prevents UAVs from collisions to determine the relay nodes deployment and guarantee satisfactory video quality. The experimental results show that the proposed SD-UAVNet architecture can effectively mitigate the challenges of UAVNet and it provides suitable Quality of Experience (QoE) to end-users.}
}
@article{LI2021106465,
title = {Fast detection and location of longan fruits using UAV images},
journal = {Computers and Electronics in Agriculture},
volume = {190},
pages = {106465},
year = {2021},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2021.106465},
url = {https://www.sciencedirect.com/science/article/pii/S0168169921004828},
author = {Denghui Li and Xiaoxuan Sun and Hamza Elkhouchlaa and Yuhang Jia and Zhongwei Yao and Peiyi Lin and Jun Li and Huazhong Lu},
keywords = {UAV, Image analysis, Convolutional neural network, RGB-D image, Detection and location of longan},
abstract = {In agriculture, fruit picking robots on the ground have difficulty adapting to the terrain conditions of mountain orchards and cannot pick longan fruit from tall longan trees. In this paper, aiming to allow picking of longan fruit by unmanned aerial vehicles (UAVs), a deep learning-based scheme to quickly and accurately detect and locate suitable picking points on fruit branches is proposed. The scheme includes a UAV fuzzy image preprocessing method, longan detection based on a convolutional neural network (CNN), red, green, blue and depth (RGB-D) information fusion and an accurate target location strategy. First, the UAV is equipped with an Intel Realsense D455 camera, which collects longan images from the front for training and testing the model. Second, the lightweight MobileNet backbone network is used to improve the performance of the You Only Look Once version 4 (YOLOv4) model in feature extraction. The results for the test set show that compared with the classical feature pyramid network (FPN), YOLOv3 and YOLOv4 models, this model reduces the computation, parameters and detection time of the model. Compared with MobileNet single-shot multibox detector (MobileNet-SSD) and YOLOv4-tiny, this model exhibits improved detection accuracy. Third, according to the target detection result map, a strategy is formulated to accurately determine the suitable picking point on the main branch of the result. Finally, the performance of the improved model and picking platform in the harvest scene is evaluated by performing picking experiments in a longan orchard. In summary, we fully exploit the advantages of the combination of UAVs, RGB-D cameras and CNNs to improve the speed and accuracy of target detection and location for longan picking by UAVs based on vision.}
}
@article{DAI2022107348,
title = {Aerodynamic optimization of high-lift devices using a 2D-to-3D optimization method based on deep reinforcement learning and transfer learning},
journal = {Aerospace Science and Technology},
pages = {107348},
year = {2022},
issn = {1270-9638},
doi = {https://doi.org/10.1016/j.ast.2022.107348},
url = {https://www.sciencedirect.com/science/article/pii/S1270963822000220},
author = {Jiahua Dai and Peiqing Liu and Qiulin Qu and Ling Li and Tongzhi Niu},
keywords = {High-lift device, Transfer learning, Deep reinforcement learning, Three-dimensional optimization},
abstract = {The computational fluid dynamics is the main method to evaluate the aerodynamic performance for the optimization of high-lift devices. Currently, the direct three-dimensional (3D) optimization requires significant computational resources. Additionally, the commonly used heuristic algorithms can not extract the experience of two-dimensional (2D) optimization to accelerate the 3D optimization process. In order to resolve these issues, a novel 2D-to-3D optimization method based on the coupling of Deep Reinforcement Learning (DRL) and Transfer Learning (TL) is proposed to conduct the aerodynamic optimization of the 3D high-lift devices and tested on the NASA Trap Wing model. The 2D optimization is first carried out, and then its neural networks in DRL and the optimal configuration are extracted by TL to turn into the 3D optimization. Compared with the direct 3D optimization, the proposed 2D-to-3D optimization method can result in improved aerodynamic performance for the same computational cost, or can save 51%-81% of the computational cost to obtain a similar performance.}
}
@article{GUPTA2021100057,
title = {Deep learning for object detection and scene perception in self-driving cars: Survey, challenges, and open issues},
journal = {Array},
volume = {10},
pages = {100057},
year = {2021},
issn = {2590-0056},
doi = {https://doi.org/10.1016/j.array.2021.100057},
url = {https://www.sciencedirect.com/science/article/pii/S2590005621000059},
author = {Abhishek Gupta and Alagan Anpalagan and Ling Guan and Ahmed Shaharyar Khwaja},
keywords = {Self-driving cars, Levels of automation, Machine learning, Deep learning, Convolutional neural networks, Scene perception, Object detection, Multimodal sensor fusion, LiDAR, Computer vision, Autonomous driving initiatives},
abstract = {This article presents a comprehensive survey of deep learning applications for object detection and scene perception in autonomous vehicles. Unlike existing review papers, we examine the theory underlying self-driving vehicles from deep learning perspective and current implementations, followed by their critical evaluations. Deep learning is one potential solution for object detection and scene perception problems, which can enable algorithm-driven and data-driven cars. In this article, we aim to bridge the gap between deep learning and self-driving cars through a comprehensive survey. We begin with an introduction to self-driving cars, deep learning, and computer vision followed by an overview of artificial general intelligence. Then, we classify existing powerful deep learning libraries and their role and significance in the growth of deep learning. Finally, we discuss several techniques that address the image perception issues in real-time driving, and critically evaluate recent implementations and tests conducted on self-driving cars. The findings and practices at various stages are summarized to correlate prevalent and futuristic techniques, and the applicability, scalability and feasibility of deep learning to self-driving cars for achieving safe driving without human intervention. Based on the current survey, several recommendations for further research are discussed at the end of this article.}
}
@article{DANG2020100250,
title = {UAV based wilt detection system via convolutional neural networks},
journal = {Sustainable Computing: Informatics and Systems},
volume = {28},
pages = {100250},
year = {2020},
issn = {2210-5379},
doi = {https://doi.org/10.1016/j.suscom.2018.05.010},
url = {https://www.sciencedirect.com/science/article/pii/S2210537917304018},
author = {L. Minh Dang and Syed {Ibrahim Hassan} and Im Suhyeon and Arun kumar Sangaiah and Irfan Mehmood and Seungmin Rho and Sanghyun Seo and Hyeonjoon Moon},
keywords = {Unmanned aerial vehicles, Feature extraction, Radish field clustering, Fusarium wilt of radish classification},
abstract = {The significant role of plants can be observed through the dependency of animals and humans on them. Oxygen, materials, food and the beauty of the world are contributed by plants. Climate change, the decrease in pollinators, and plant diseases are causing a significant decline in both quality and coverage ratio of the plants and crops on a global scale. In developed countries, above 80 percent of rural production is produced by sharecropping. However, due to widespread diseases in plants, yields are reported to have declined by more than a half. These diseases are identified and diagnosed by the agricultural and forestry department. Manual inspection on a large area of fields requires a huge amount of time and effort, thereby reduces the effectiveness significantly. To counter this problem, we propose an automatic disease detection and classification method in radish fields by using a camera attached to an unmanned aerial vehicle (UAV) to capture high quality images from the fields and analyze them by extracting both color and texture features, then we used K-means clustering to filter radish regions and feeds them into a fine-tuned GoogleNet to detect Fusarium wilt of radish efficiently at early stage and allow the authorities to take timely action which ensures the food safety for current and future generations.}
}
@article{LI2021457,
title = {Maneuvering target tracking of UAV based on MN-DDPG and transfer learning},
journal = {Defence Technology},
volume = {17},
number = {2},
pages = {457-466},
year = {2021},
issn = {2214-9147},
doi = {https://doi.org/10.1016/j.dt.2020.11.014},
url = {https://www.sciencedirect.com/science/article/pii/S2214914720304815},
author = {Bo Li and Zhi-peng Yang and Da-qing Chen and Shi-yang Liang and Hao Ma},
keywords = {UAVs, Maneuvering target tracking, Deep reinforcement learning, MN-DDPG, Mixed noises, Transfer learning},
abstract = {Tracking maneuvering target in real time autonomously and accurately in an uncertain environment is one of the challenging missions for unmanned aerial vehicles (UAVs). In this paper, aiming to address the control problem of maneuvering target tracking and obstacle avoidance, an online path planning approach for UAV is developed based on deep reinforcement learning. Through end-to-end learning powered by neural networks, the proposed approach can achieve the perception of the environment and continuous motion output control. This proposed approach includes: (1) A deep deterministic policy gradient (DDPG)-based control framework to provide learning and autonomous decision-making capability for UAVs; (2) An improved method named MN-DDPG for introducing a type of mixed noises to assist UAV with exploring stochastic strategies for online optimal planning; and (3) An algorithm of task-decomposition and pre-training for efficient transfer learning to improve the generalization capability of UAV’s control model built based on MN-DDPG. The experimental simulation results have verified that the proposed approach can achieve good self-adaptive adjustment of UAV’s flight attitude in the tasks of maneuvering target tracking with a significant improvement in generalization capability and training efficiency of UAV tracking controller in uncertain environments.}
}
@article{MARTIN2021116730,
title = {Enabling a large-scale assessment of litter along Saudi Arabian red sea shores by combining drones and machine learning},
journal = {Environmental Pollution},
volume = {277},
pages = {116730},
year = {2021},
issn = {0269-7491},
doi = {https://doi.org/10.1016/j.envpol.2021.116730},
url = {https://www.sciencedirect.com/science/article/pii/S0269749121003109},
author = {Cecilia Martin and Qiannan Zhang and Dongjun Zhai and Xiangliang Zhang and Carlos M. Duarte},
keywords = {Unmanned aerial vehicles, Deep neural network, Beach litter, Plastic, Marine debris},
abstract = {Beach litter assessments rely on time inefficient and high human cost protocols, mining the attainment of global beach litter estimates. Here we show the application of an emerging technique, the use of drones for acquisition of high-resolution beach images coupled with machine learning for their automatic processing, aimed at achieving the first national-scale beach litter survey completed by only one operator. The aerial survey had a time efficiency of 570 ± 40 m2 min−1 and the machine learning reached a mean (±SE) detection sensitivity of 59 ± 3% with high resolution images. The resulting mean (±SE) litter density on Saudi Arabian shores of the Red Sea is of 0.12 ± 0.02 litter items m−2, distributed independently of the population density in the area around the sampling station. Instead, accumulation of litter depended on the exposure of the beach to the prevailing wind and litter composition differed between islands and the main shore, where recreational activities are the major source of anthropogenic debris.}
}
@article{MOHAMED2020119293,
title = {Unmanned aerial vehicles applications in future smart cities},
journal = {Technological Forecasting and Social Change},
volume = {153},
pages = {119293},
year = {2020},
issn = {0040-1625},
doi = {https://doi.org/10.1016/j.techfore.2018.05.004},
url = {https://www.sciencedirect.com/science/article/pii/S0040162517314968},
author = {Nader Mohamed and Jameela Al-Jaroodi and Imad Jawhar and Ahmed Idries and Farhan Mohammed},
keywords = {UAVs, Smart cities, UAV applications, Smart cities services, Technological implications},
abstract = {Foreseeing changes in how smart cities manage their resources and provide services to the residents; research, development and production in various relevant technology fields is accelerating. Taking advantage of recent advances and innovations in Information and Communication Technologies (ICT), robotics and software; smart cities can optimize resources utilization and enhance operations in health, transportation, energy, and water services, as well as elevating the level of comfort of residents. Effectively and efficiently utilizing ICT and robotics in smart cities will result in reducing costs and resources consumption in addition to engaging more effectively and actively with the citizens. One of these technologies is the unmanned aerial vehicle (UAV), which can provide many applications for smart cities and create a positive impact on the society. For example, UAVs can be used for environmental monitoring, traffic management, pollution monitoring, civil security control, and merchandise delivery. UAV applications among several others can provide cost-effective services to help achieve the objectives of smart cities. However, the integration of UAVs in smart cities is very challenging due to several issues and concerns such as safety, privacy and ethical/legal use. This paper reviews the potential applications integrating UAVs in smart cities, their implications, and the technical and non-technical issues facing such integration. It also discusses regulations and enabling technologies currently available and being developed that can be utilized to support such integration.}
}
@article{JEONG2021107060,
title = {Hazardous flight region prediction for a small UAV operated in an urban area using a deep neural network},
journal = {Aerospace Science and Technology},
volume = {118},
pages = {107060},
year = {2021},
issn = {1270-9638},
doi = {https://doi.org/10.1016/j.ast.2021.107060},
url = {https://www.sciencedirect.com/science/article/pii/S1270963821005708},
author = {Shinkyu Jeong and Kangkuk You and Donghoon Seok},
keywords = {Hazardous flight region prediction system, WRF+LES, Deep neural network (DNN)},
abstract = {With an increase of UAVs in logistics and transportation, the safety of UAVs operated in the urban wind environment becomes an important issue. Small UAVs are more sensitive to the wind environment because of their small size, slow cruising speed, and limited endurance. In the unmanned aircraft system traffic management (UTM), a safety risk assessment under bad weather conditions is an important component. In this study, a hazardous flight region prediction system for small UAVs operated in urban areas is developed using a deep neural network (DNN) to support a risk assessment and safe trajectory planning. A large eddy simulation (LES) is applied to reflect the terrain-driven wind environment in the urban area. The result of a weather research and forecasting (WRF) model is used as an initial and boundary condition of the LES to generate a realistic complicated wind environment in an urban area. Furthermore, an iterative nesting algorithm is applied to the LES to obtain a sufficient resolution of the wind environment, which is suitable for the small UAV scale. The deviation distance from the original flight path due to the wind environment is considered as a flight hazard criterion in this study. The proposed system is able to predict deviation distance due to the wind environment over the entire flight space over time by using the DNN model. The training data for the DNN is obtained using the multicopter flight dynamics simulator, which can take into account the influence of a specific wind environment. With the indexes considering this deviation distance and the local topography (distribution of buildings) in the urban area, the hazardous flight region is predicted. The information supplied by the proposed hazardous flight region prediction model can be used for the flight risk assessment and safe flight trajectory planning to increase the flight safety of small UAVs.}
}
@article{ESCRIBANOMACIAS202056,
title = {Optimal hub selection for rapid medical deliveries using unmanned aerial vehicles},
journal = {Transportation Research Part C: Emerging Technologies},
volume = {110},
pages = {56-80},
year = {2020},
issn = {0968-090X},
doi = {https://doi.org/10.1016/j.trc.2019.11.002},
url = {https://www.sciencedirect.com/science/article/pii/S0968090X18310660},
author = {Jose {Escribano Macias} and Panagiotis Angeloudis and Washington Ochieng},
keywords = {UAV, Selection-routing problem, Trajectory optimisation, Humanitarian relief distribution, Heuristic},
abstract = {Unmanned Aerial Vehicles (UAVs) are being increasingly deployed in humanitarian response operations. Beyond regulations, vehicle range and integration with the humanitarian supply chain inhibit their deployment. To address these issues, we present a novel bi-stage operational planning approach that consists of a trajectory optimisation algorithm (that considers multiple flight stages), and a hub selection-routing algorithm that incorporates a new battery management heuristic. We apply the algorithm to a hypothetical response mission in Taiwan after the Chi-Chi earthquake of 1999 considering mission duration and distribution fairness. Our analysis indicates that UAV fleets can be used to provide rapid relief to populations of 20,000 individuals in under 24 h. Additionally, the proposed methodology achieves significant reductions in mission duration and battery stock requirements with respect to conservative energy estimations and other heuristics.}
}
@article{FERNANDES2016248,
title = {Developing a Novel Technique to Match Composite Sketches with Images Captured by Unmanned Aerial Vehicle},
journal = {Procedia Computer Science},
volume = {78},
pages = {248-254},
year = {2016},
note = {1st International Conference on Information Security & Privacy 2015},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2016.02.040},
url = {https://www.sciencedirect.com/science/article/pii/S1877050916000429},
author = {Steven Lawrence Fernandes and G. Josemin Bala},
keywords = {Unmanned aerial vehicle, Face detection, Image quality assessment},
abstract = {Police database cannot have images of first time offenders hence apprehending them becomes a difficult task. In this paper we propose a new method which matches composite sketches with images captured by Unmanned Aerial Vehicles (UAV). The UAV is sent in the area where the offender is likely to be present. The human face, obtained by passing the captured image to Face Detection module, is subjected to Image Quality Assessment (IQA) calculating module. Based on the IQA values obtained we decide if the given face image contains Pose variations, Illumination variations, Age variation etc. Based on the variations, suitable feature extraction and classification method is selected.}
}
@article{LU201773,
title = {Species classification using Unmanned Aerial Vehicle (UAV)-acquired high spatial resolution imagery in a heterogeneous grassland},
journal = {ISPRS Journal of Photogrammetry and Remote Sensing},
volume = {128},
pages = {73-85},
year = {2017},
issn = {0924-2716},
doi = {https://doi.org/10.1016/j.isprsjprs.2017.03.011},
url = {https://www.sciencedirect.com/science/article/pii/S0924271616305688},
author = {Bing Lu and Yuhong He},
keywords = {UAV, Grassland, Species composition, Object-based classification},
abstract = {Investigating spatio-temporal variations of species composition in grassland is an essential step in evaluating grassland health conditions, understanding the evolutionary processes of the local ecosystem, and developing grassland management strategies. Space-borne remote sensing images (e.g., MODIS, Landsat, and Quickbird) with spatial resolutions varying from less than 1m to 500m have been widely applied for vegetation species classification at spatial scales from community to regional levels. However, the spatial resolutions of these images are not fine enough to investigate grassland species composition, since grass species are generally small in size and highly mixed, and vegetation cover is greatly heterogeneous. Unmanned Aerial Vehicle (UAV) as an emerging remote sensing platform offers a unique ability to acquire imagery at very high spatial resolution (centimetres). Compared to satellites or airplanes, UAVs can be deployed quickly and repeatedly, and are less limited by weather conditions, facilitating advantageous temporal studies. In this study, we utilize an octocopter, on which we mounted a modified digital camera (with near-infrared (NIR), green, and blue bands), to investigate species composition in a tall grassland in Ontario, Canada. Seven flight missions were conducted during the growing season (April to December) in 2015 to detect seasonal variations, and four of them were selected in this study to investigate the spatio-temporal variations of species composition. To quantitatively compare images acquired at different times, we establish a processing flow of UAV-acquired imagery, focusing on imagery quality evaluation and radiometric correction. The corrected imagery is then applied to an object-based species classification. Maps of species distribution are subsequently used for a spatio-temporal change analysis. Results indicate that UAV-acquired imagery is an incomparable data source for studying fine-scale grassland species composition, owing to its high spatial resolution. The overall accuracy is around 85% for images acquired at different times. Species composition is spatially attributed by topographical features and soil moisture conditions. Spatio-temporal variation of species composition implies the growing process and succession of different species, which is critical for understanding the evolutionary features of grassland ecosystems. Strengths and challenges of applying UAV-acquired imagery for vegetation studies are summarized at the end.}
}
@article{BOCHIE2021103213,
title = {A survey on deep learning for challenged networks: Applications and trends},
journal = {Journal of Network and Computer Applications},
volume = {194},
pages = {103213},
year = {2021},
issn = {1084-8045},
doi = {https://doi.org/10.1016/j.jnca.2021.103213},
url = {https://www.sciencedirect.com/science/article/pii/S1084804521002149},
author = {Kaylani Bochie and Mateus S. Gilbert and Luana Gantert and Mariana S.M. Barbosa and Dianne S.V. Medeiros and Miguel Elias M. Campista},
keywords = {Challenged networks, Internet of Things, Sensor networks, Industrial networks, Wireless mobile networks, Vehicular networks, Deep learning, Machine learning},
abstract = {Computer networks are dealing with growing complexity, given the ever-increasing volume of data produced by all sorts of network nodes. Performance improvements are a non-stop ambition and require tuning fine-grained details of the system operation. Analyzing such data deluge, however, is not straightforward and sometimes not supported by the system. There are often problems regarding scalability and the predisposition of the involved nodes to understand and transfer the data. This issue is at least partially circumvented by knowledge acquisition from past experiences, which is a characteristic of the herein called “challenged networks”. The addition of intelligence in these scenarios is fundamental to extract linear and non-linear relationships from the data collected by multiple sources. This is undoubtedly an invitation to machine learning and, more particularly, to deep learning. This paper identifies five different challenged networks: IoT and sensor, mobile, industrial, and vehicular networks as typical scenarios that may have multiple and heterogeneous data sources and face obstacles concerning connectivity. As a consequence, deep learning solutions can contribute to system performance by adding intelligence and the ability to interpret data. We start the paper by providing an overview of deep learning, further explaining this approach’s benefits over the cited scenarios. We propose a workflow based on our observations of deep learning applications over challenged networks, and based on it, we strive to survey the literature on deep-learning-based solutions at an application-oriented level using the PRISMA methodology. Afterward, we also discuss new deep learning techniques that show enormous potential for further improvements as well as transversal issues, such as security. Finally, we provide lessons learned raising trends linking all surveyed papers to deep learning approaches. We are confident that the proposed paper contributes to the state of the art and can be a piece of inspiration for beginners and also for enthusiasts on advanced networking research.}
}
@article{BAI2022108166,
title = {Learning-based resilience guarantee for multi-UAV collaborative QoS management},
journal = {Pattern Recognition},
volume = {122},
pages = {108166},
year = {2022},
issn = {0031-3203},
doi = {https://doi.org/10.1016/j.patcog.2021.108166},
url = {https://www.sciencedirect.com/science/article/pii/S0031320321003538},
author = {Chengchao Bai and Peng Yan and Xiaoqiang Yu and Jifeng Guo},
keywords = {Unmanned business, Communication service, Multi-UAV, Deep reinforcement learning, QoS-aware, System resilience},
abstract = {Unmanned and intelligent technologies are the future development trend in the business field. It is of great significance for the connotation analysis and application characterization of massive interactive data. Particularly, during major epidemics or disasters, how to provide business services safely and securely is crucial. Specifically, providing users with resilient and guaranteed communication services is a challenging business task when the communication facilities are damaged. Unmanned aerial vehicles (UAVs), with flexible deployment and high maneuverability, can be used to serve as aerial base stations (BSs) to establish emergency networks. However, it is challenging to control multiple UAVs to provide efficient and fair communication quality of service (QoS) to users due to their limited communication service capabilities. In this paper, we propose a learning-based resilience guarantee framework for multi-UAV collaborative QoS management. We formulate this problem as a partial observable Markov decision process and solve it with proximal policy optimization (PPO), which is a policy-based deep reinforcement learning method. A centralized training and decentralized execution paradigm is used, where the experience collected by all UAVs is used to train the shared control policy. Each UAV takes actions based on the partial environment information it observes. In addition, the design of the reward function considers the average and variance of the communication QoS of all users. Extensive simulations are conducted for performance evaluation. The simulation results indicate that (1) the trained policies can adapt to different scenarios and provide resilient and guaranteed communication QoS to users, (2) increasing the number of UAVs can compensate for the lack of service capabilities of UAVs, (3) when UAVs have local communication service capabilities, the policies trained with PPO have better performance compared with the policies trained with other algorithms.}
}
@article{HUNG20121,
title = {On parallel hybrid-electric propulsion system for unmanned aerial vehicles},
journal = {Progress in Aerospace Sciences},
volume = {51},
pages = {1-17},
year = {2012},
issn = {0376-0421},
doi = {https://doi.org/10.1016/j.paerosci.2011.12.001},
url = {https://www.sciencedirect.com/science/article/pii/S0376042112000097},
author = {J.Y. Hung and L.F. Gonzalez},
keywords = {Unmanned aerial vehicle, Hybrid-electric propulsion system, Ideal operating line, Energy efficiency, Simulation},
abstract = {This paper presents a review of existing and current developments and the analysis of Hybrid-Electric Propulsion Systems (HEPS) for small fixed-wing Unmanned Aerial Vehicles (UAVs). Efficient energy utilisation on an UAV is essential to its functioning, often to achieve the operational goals of range, endurance and other specific mission requirements. Due to the limitations of the space available and the mass budget on the UAV, it is often a delicate balance between the onboard energy available (i.e. fuel) and achieving the operational goals. One technology with potential in this area is with the use of HEPS. In this paper, information on the state-of-art technology in this field of research is provided. A description and simulation of a parallel HEPS for a small fixed-wing UAV by incorporating an Ideal Operating Line (IOL) control strategy is described. Simulation models of the components in a HEPS were designed in the MATLAB Simulink environment. An IOL analysis of an UAV piston engine was used to determine the most efficient points of operation for this engine. The results show that an UAV equipped with this HEPS configuration is capable of achieving a fuel saving of 6.5%, compared to the engine-only configuration.}
}
@article{VANKLOMPENBURG2020105709,
title = {Crop yield prediction using machine learning: A systematic literature review},
journal = {Computers and Electronics in Agriculture},
volume = {177},
pages = {105709},
year = {2020},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2020.105709},
url = {https://www.sciencedirect.com/science/article/pii/S0168169920302301},
author = {Thomas {van Klompenburg} and Ayalew Kassahun and Cagatay Catal},
keywords = {Crop yield prediction, Decision support system, Systematic literature review, Machine learning, Deep learning},
abstract = {Machine learning is an important decision support tool for crop yield prediction, including supporting decisions on what crops to grow and what to do during the growing season of the crops. Several machine learning algorithms have been applied to support crop yield prediction research. In this study, we performed a Systematic Literature Review (SLR) to extract and synthesize the algorithms and features that have been used in crop yield prediction studies. Based on our search criteria, we retrieved 567 relevant studies from six electronic databases, of which we have selected 50 studies for further analysis using inclusion and exclusion criteria. We investigated these selected studies carefully, analyzed the methods and features used, and provided suggestions for further research. According to our analysis, the most used features are temperature, rainfall, and soil type, and the most applied algorithm is Artificial Neural Networks in these models. After this observation based on the analysis of machine learning-based 50 papers, we performed an additional search in electronic databases to identify deep learning-based studies, reached 30 deep learning-based papers, and extracted the applied deep learning algorithms. According to this additional analysis, Convolutional Neural Networks (CNN) is the most widely used deep learning algorithm in these studies, and the other widely used deep learning algorithms are Long-Short Term Memory (LSTM) and Deep Neural Networks (DNN).}
}
@article{SACCO2020769,
title = {An architecture for adaptive task planning in support of IoT-based machine learning applications for disaster scenarios},
journal = {Computer Communications},
volume = {160},
pages = {769-778},
year = {2020},
issn = {0140-3664},
doi = {https://doi.org/10.1016/j.comcom.2020.07.011},
url = {https://www.sciencedirect.com/science/article/pii/S0140366419316779},
author = {Alessio Sacco and Matteo Flocco and Flavio Esposito and Guido Marchetto},
keywords = {Network of queues, Machine Learning},
abstract = {The proliferation of the Internet of Things (IoT) in conjunction with edge computing has recently opened up several possibilities for several new applications. Typical examples are Unmanned Aerial Vehicles (UAV) that are deployed for rapid disaster response, photogrammetry, surveillance, and environmental monitoring. To support the flourishing development of Machine Learning assisted applications across all these networked applications, a common challenge is the provision of a persistent service, i.e., a service capable of consistently maintaining a high level of performance, facing possible failures. To address these service resilient challenges, we propose APRON, an edge solution for distributed and adaptive task planning management in a network of IoT devices, e.g., drones. Exploiting Jackson’s network model, our architecture applies a novel planning strategy to better support control and monitoring operations while the states of the network evolve. To demonstrate the functionalities of our architecture, we also implemented a deep-learning based audio-recognition application using the APRON NorthBound interface, to detect human voices in challenged networks. The application’s logic uses Transfer Learning to improve the audio classification accuracy and the runtime of the UAV-based rescue operations.}
}
@article{SILVA2022125,
title = {Automatic detection of Flavescense Dorée grapevine disease in hyperspectral images using machine learning},
journal = {Procedia Computer Science},
volume = {196},
pages = {125-132},
year = {2022},
note = {International Conference on ENTERprise Information Systems / ProjMAN - International Conference on Project MANagement / HCist - International Conference on Health and Social Care Information Systems and Technologies 2021},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2021.11.081},
url = {https://www.sciencedirect.com/science/article/pii/S1877050921022201},
author = {Diogo M. Silva and Théo Bernardin and Kévin Fanton and Roshan Nepaul and Luís Pádua and Joaquim J. Sousa and António Cunha},
keywords = {Hyperspectral images, grapevine diseases, automatic detection, autoencoder, machine learning},
abstract = {The technological revolution that we have been witnessing recently has allowed components miniaturization and made electronic components accessible. Hyperspectral sensors benefited from these advances and could be mounted on unmanned aerial vehicles, which was unthinkable until recently. This fact significantly increased the applications of hyperspectral data, namely in agriculture, especially in the detection of diseases at an early stage. The vineyard is one of the agricultural sectors that has the most to gain from the use of this type of data, both by the economic value and by the number of diseases the plants are exposed to. The Flavescense dorée is a disease that attacks vineyards and may conduct to a significant loss. Nowadays, the detection of this disease is based on the visual identification of symptoms performed by experts who cover the entire area. However, this work remains tedious and relies only on the human eye, which is a problem since sometimes healthy plants are torn out, while diseased ones are left. If the experts think they have found symptoms, they take samples to send to the laboratory for further analysis. If the test is positive, then the whole vine is uprooted, to limit the spread of the disease. In this context, the use of hyperspectral data will allow the development of new disease detection methods. However, it will be necessary to reduce the volume of data used to make them usable by conventional resources. Fortunately, the advent of machine learning techniques empowered the development of systems that allow better decisions to be made, and consequently save time and money. In this article, a machine learning approach, which is based on an Autoencoder to automatically detect wine disease, is proposed.}
}
@article{HANSEN201410555,
title = {A Framework for Diagnosis of Critical Faults in Unmanned Aerial Vehicles},
journal = {IFAC Proceedings Volumes},
volume = {47},
number = {3},
pages = {10555-10561},
year = {2014},
note = {19th IFAC World Congress},
issn = {1474-6670},
doi = {https://doi.org/10.3182/20140824-6-ZA-1003.02321},
url = {https://www.sciencedirect.com/science/article/pii/S1474667016432908},
author = {Søren Hansen and Mogens Blanke and Jens Adrian},
abstract = {Unmanned Aerial Vehicles (UAVs) need a large degree of tolerance towards faults. If not diagnosed and handled in time, many types of faults can have catastrophic consequences if they occur during flight. Prognosis of faults is also valuable and so is the ability to distinguish the severity of the different faults in terms of both consequences and the frequency with which they appear. In this paper flight data from a fleet of UAVs is analysed with respect to certain faults and their frequency of appearance. Data is taken from a group of UAV's of the same type but with small differences in weight and handling due to different types of payloads and engines used. Categories of critical faults, that could and have caused UAV crashes are analysed and requirements to diagnosis are formulated. Faults in air system sensors and in control surfaces are given special attention. In a stochastic framework, and based on a large number of data logged during flights, diagnostic methods are employed to diagnose faults and the performance of these fault detectors are evaluated against flight data. The paper demonstrates a significant potential for reducing the risk of unplanned loss of remotely piloted vehicles used by the Danish Navy for target practice.}
}
@article{YANG2019142,
title = {Deep convolutional neural networks for rice grain yield estimation at the ripening stage using UAV-based remotely sensed images},
journal = {Field Crops Research},
volume = {235},
pages = {142-153},
year = {2019},
issn = {0378-4290},
doi = {https://doi.org/10.1016/j.fcr.2019.02.022},
url = {https://www.sciencedirect.com/science/article/pii/S037842901831390X},
author = {Qi Yang and Liangsheng Shi and Jinye Han and Yuanyuan Zha and Penghui Zhu},
keywords = {Yield estimation, UAV, Rice crop, Deep learning, CNN},
abstract = {Forecasting rice grain yield prior to harvest is essential for crop management, food security evaluation, food trade, and policy-making. Many successful applications have been made in crop yield estimation using remotely sensed products, such as vegetation index (VI) from multispectral imagery. However, VI-based approaches are only suitable for estimating rice grain yield at the middle stage of growth but have limited capability at the ripening stage. In this study, an efficient convolutional neural network (CNN) architecture was proposed to learn the important features related to rice grain yield from low-altitude remotely sensed imagery. In one major region for rice cultivation of Southern China, a 160-hectare site with over 800 management units was chosen to investigate the ability of CNN in rice grain yield estimation. The datasets of RGB and multispectral images were obtained by a fixed-wing, unmanned aerial vehicle (UAV), which was mounted with a digital camera and multispectral sensors. The network was trained with different datasets and compared against the traditional vegetation index-based method. In addition, the temporal and spatial generality of the trained network was investigated. The results showed that the CNNs trained by RGB and multispectral datasets perform much better than VIs-based regression model for rice grain yield estimation at the ripening stage. The RGB imagery of very high spatial resolution contains important spatial features with respect to grain yield distribution, which can be learned by deep CNN. The results highlight the promising potential of deep convolutional neural networks for rice grain yield estimation with excellent spatial and temporal generality, and a wider time window of yield forecasting.}
}
@article{LIU2021108397,
title = {Task offloading optimization of cruising UAV with fixed trajectory},
journal = {Computer Networks},
volume = {199},
pages = {108397},
year = {2021},
issn = {1389-1286},
doi = {https://doi.org/10.1016/j.comnet.2021.108397},
url = {https://www.sciencedirect.com/science/article/pii/S1389128621003741},
author = {Peng Liu and Han He and Tingting Fu and Huijuan Lu and Abdulhameed Alelaiwi and Md Wasif Islam Wasi},
keywords = {Unmanned aerial vehicles, Task offloading, Edge computing, Q-learning},
abstract = {Unmanned aerial vehicle (UAV) have been deployed in many applications, such as Power Grid inspection, forest fire prevention, and pollution surveillance. They often cruise along a fixed route above the target area. Due to the cost of remote communication and local computationally intensive tasks, resource-constrained drones tend to offload tasks to edge servers. In most cases, drones do not know the prior knowledge of user nodes and edge servers, and must reduce the altitude to provide services. Therefore, it is necessary to carefully decide when and where to collect and offload tasks to avoid unnecessary energy consumption and time delays. In this paper, we propose the benefit maximization problem under constraints such as time sensitivity, and propose an optimized task offloading strategy based on the reinforcement learning algorithm. We strive to directly solve the deficiencies in the profit maximization problem with modified Q-Learning algorithm. We test the performance under practical application scenarios with different environmental parameters. The experimental results prove that the solution proposed in this paper has better convergence and performance, as well as better reusability in similar application scenarios.}
}
@article{MANSOURI20174727,
title = {Remaining Useful Battery Life Prediction for UAVs based on Machine Learning**This work has received partial funding from the European Union’s Horizon 2020 Research and Innovation Programme under the Grant Agreement No.644128, AEROWORKS},
journal = {IFAC-PapersOnLine},
volume = {50},
number = {1},
pages = {4727-4732},
year = {2017},
note = {20th IFAC World Congress},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2017.08.863},
url = {https://www.sciencedirect.com/science/article/pii/S2405896317313253},
author = {Sina Sharif Mansouri and Petros Karvelis and George Georgoulas and George Nikolakopoulos},
keywords = {Battery, Remaining Useful Life, Machine Learning, UAVs, Prediction},
abstract = {Unmanned Aerial Vehicles are becoming part of many industrial applications. The advancements in battery technologies played a crucial part for this trend. However, no matter what the advancements are, all batteries have a fixed capacity and after some time drain out. In order to extend the flying time window, the prediction of the time that the battery will no longer be able to support a flying condition is crucial. This in fact can be cast as a standard Remaining Useful Life prognostic problem, similarly encountered in many fields. In this article, the problem of Remaining Useful Life estimation of a battery, under different flight conditions, is tackled using four machine learning techniques: a linear sparse model, a variant of support vector regression, a multilayer perceptron and an advanced tree based algorithm. The efficiency of the overall proposed machine learning techniques, in the field of batteries prognostics, is evaluated based on multiple experimental data from different flight conditions.}
}
@article{NAKSHMI20201981,
title = {Optimizing Quality and Outputs by Improving Variable Rate Prescriptions in Agriculture using UAVs},
journal = {Procedia Computer Science},
volume = {167},
pages = {1981-1990},
year = {2020},
note = {International Conference on Computational Intelligence and Data Science},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2020.03.229},
url = {https://www.sciencedirect.com/science/article/pii/S1877050920306955},
author = {J V N Nakshmi and K S Hemanth and J Bharath},
keywords = {Agriculture, UAVs, Machine Learning, Deep Learning, Optimization},
abstract = {Agriculture was the most prominent occupation in India once upon a time. Nowadays due to various changes in technology, living style, trends, environment, and climate changes 80% of the population are not willing to be a farmer anymore. If this continues what could be the state of tomorrow’s world. In today’s world, the same technology can be implemented in the agriculture sectors for optimizing the output and fetching the quality crop. For retrieving best harvest some solutions based on images taken by satellites can be analyzed and appropriate prescriptions are given for the crops. This work proposes a system to identify the quality of the crop, fungus detection and infected areas by surveying based on image pattern recognition by collecting the pictures are taken by UAVs (Unmanned Aerial Vehicle); these images are very close to the crops for detecting weeds, differentiating the dried, healthy leaves and identifying the ripen fruits with different levels of intersections. This solution achieves a 50% growth in the harvest and quality of the crop. These technologies should again pave a way for agriculture to be a major occupation in India.}
}
@article{JAIMES2021274,
title = {An Incentive Mechanism for UAVs Crowdsensing Markets, a Negotiation Approach},
journal = {IFAC-PapersOnLine},
volume = {54},
number = {13},
pages = {274-279},
year = {2021},
note = {20th IFAC Conference on Technology, Culture, and International Stability TECIS 2021},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2021.10.458},
url = {https://www.sciencedirect.com/science/article/pii/S2405896321018954},
author = {Luis G Jaimes and Janar Kahr and Juan M. Calderon},
keywords = {Cost Oriented Automation, Intelligent Systems, Applications, Artificial intelligence, Deep Learning},
abstract = {In this paper, we present an incentive mechanism for Unmanned Aerial vehicles (UAVs) crowdsensing. In particular, we propose a solution to the problem of sensing coverage of lower regions of the atmosphere where a set of UAVs transverse it as part of their daily activities. We propose a UAV sensing market where data collection is an additional by-product that UAVs obtained while following their regular trajectories. In this model, participants use negotiation to compete and cooperate with each other while participating in data collection campaigns. Using the Virtual Robotics Environment (VRep) and extensive simulations, we show that our algorithm performs well in terms of sensing coverage, and participants retention while using a limited budget.}
}
@article{LIU2021,
title = {Ephemeral gully recognition and accuracy evaluation using deep learning in the hilly and gully region of the Loess Plateau in China},
journal = {International Soil and Water Conservation Research},
year = {2021},
issn = {2095-6339},
doi = {https://doi.org/10.1016/j.iswcr.2021.10.004},
url = {https://www.sciencedirect.com/science/article/pii/S2095633921000976},
author = {Boyang Liu and Biao Zhang and Hao Feng and Shufang Wu and Jiangtao Yang and Yufeng Zoua and Kadambot H.M. Siddique},
keywords = {, , , , , },
abstract = {Ephemeral gullies are widely distributed in the hilly and gully region of the Loess Plateau and play a unique role in the slope gully erosion system. Rapid and accurate identification of ephemeral gullies impacts the distribution law and development trend of soil erosion on the Loess Plateau. Deep learning algorithms can quickly and accurately process large data samples that recognize ephemeral gullies from remote sensing images. Here, we investigated ephemeral gullies in the Zhoutungou watershed in the hilly and gully region of the Loess Plateau in China using satellite and unmanned aerial vehicle images and combined a deep learning image semantic segmentation model to realize automatic recognition and feature extraction. Using Accuracy, Precision, Recall, F1value, and AUC, we compared the ephemeral gully recognition results and accuracy evaluation of U-Net, R2U-Net, and SegNet image semantic segmentation models. The SegNet model was ranked first, followed by the R2U-Net and U-Net models, for ephemeral gully recognition in the hilly and gully region of the Loess Plateau. The ephemeral gully length and width between predicted and measured values had RMSE values of 6.78 m and 0.50 m, respectively, indicating that the model has an excellent recognition effect. This study identified a fast and accurate method for ephemeral gully recognition in the hilly and gully region of the Loess Plateau based on remote sensing images to provide an academic reference and practical guidance for soil erosion monitoring and slope and gully management in the Loess Plateau region.}
}
@article{WANG2018708,
title = {Edge-based target detection for unmanned aerial vehicles using competitive Bird Swarm Algorithm},
journal = {Aerospace Science and Technology},
volume = {78},
pages = {708-720},
year = {2018},
issn = {1270-9638},
doi = {https://doi.org/10.1016/j.ast.2018.04.047},
url = {https://www.sciencedirect.com/science/article/pii/S1270963817309896},
author = {Xiaohua Wang and Yimin Deng and Haibin Duan},
keywords = {Unmanned aerial vehicle, Target detection, Edge potential function, Bird Swarm Algorithm},
abstract = {Target detection for unmanned aerial vehicles is an important issue in autonomous formation flight. In this paper, a novel target detection approach for unmanned aerial vehicle formation is proposed based on edge matching. The windowed edge potential function is utilized to describe the attraction field for similar edges. Afterwards, the edge-based target detection problem can be formulated as an optimization problem. An improved version of the bird swarm algorithm, which is called competitive bird swarm algorithm, is proposed to find the location, rotation angle and scale of a given template on a specific image. A strategy named “disturbing the local optimum” is designed to help the original bird swarm algorithm converge to the global optimal solution faster and more stably. Formation flight platforms, which consists of unmanned aerial vehicles moving in leader-follower pattern, are used in our experiments. Images obtained by vision sensors embedded in the leaders are used to verify the effectiveness of the proposed method. The proposed algorithm is tested on both indoor and outdoor images to demonstrate the robustness. Comparative experiments with other state-of-the-art algorithms, including genetic algorithm, particle swarm optimization, artificial bee colony algorithm, pigeon-inspired optimization, and the basic bird swarm algorithm, are also conducted. The results prove the superiority and robustness of the proposed target detection algorithm.}
}
@article{LIU2022101496,
title = {A greedy-model-based reinforcement learning algorithm for Beyond-5G cooperative data collection},
journal = {Physical Communication},
volume = {50},
pages = {101496},
year = {2022},
issn = {1874-4907},
doi = {https://doi.org/10.1016/j.phycom.2021.101496},
url = {https://www.sciencedirect.com/science/article/pii/S1874490721002305},
author = {Xinyu Liu and Qingfeng Zhou and Chi-Tsun Cheng and Chanzi Liu},
keywords = {Data collection, Cooperative, Mobile sink, UAVs, Beyond-5G, Intelligent communication, Reinforcement learning},
abstract = {Data collection is an essential part of Beyond-5G and Internet of Things applications. In urban area, heterogeneous access points such as Wi-Fi routers and base stations can meet the required communication coverage and bandwidth in data collection processes. However, in remote area, without communication infrastructures, it is hard to guarantee the communication quality of a large-scale data aggregation network. An existing approach is to use an unmanned aerial vehicle (UAV) to act as a mobile sink to perform data collection and increase the coverage of intelligent wireless sensing and communications. The efficiency and the reliability of such a UAV-assisted data collection system can be significantly enhanced with an intelligent cooperative strategy for the sensors deployed in the field to communicate with the UAV. Furthermore, an energy-efficient trajectory planning algorithm is crucial to address the physical limitations of the UAV in this application. In this paper, a data collection process is modeled as a Markov decision process (MDP). The paper begins with proposing two heuristic greedy algorithms, namely distance-greedy (DG) algorithm and rate-greedy (RG) algorithm, which are designed based on prior knowledge of the system and can guarantee the completion of the data collection process in a remote area without the help of fixed communication infrastructures. Based on the outcomes, a multi-agent greedy-model-based reinforcement learning (MG-RL) algorithm is proposed, which specifically designs the environmental state and the reward scheme, and introduces multiple UAVs with different parameters to explore environments in parallel to accelerate the training. In conclusion, the two proposed greedy algorithms have lower complexity of implementation while the proposed MG-RL algorithm yields practical UAVs’ flight trajectories and shortens the time for completing a data collection task.}
}
@article{GUO2020103124,
title = {Dense construction vehicle detection based on orientation-aware feature fusion convolutional neural network},
journal = {Automation in Construction},
volume = {112},
pages = {103124},
year = {2020},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2020.103124},
url = {https://www.sciencedirect.com/science/article/pii/S092658051930994X},
author = {Yapeng Guo and Yang Xu and Shunlong Li},
keywords = {Object detection, Dense multiple construction vehicles, Feature fusion, Orientation-aware bounding box, Unmanned aerial vehicle, Deep learning, Computer vision},
abstract = {During the construction process, many construction vehicles gather in a small area in a short period, thus the accurate identification of dense multiple vehicles is of great significance for ensuring the safety of construction sites. In this study, a novel end-to-end deep learning network, namely orientation-aware feature fusion single-stage detection (OAFF-SSD), is proposed for the precise detection of dense multiple construction vehicles using images from Unmanned Aerial Vehicle (UAV). The proposed OAFF-SSD consists of three main modules: (1) multi-level feature extraction, (2) novel feature fusion, and (3) new orientation-aware bounding box (OABB) proposal and regression. Meanwhile, specific strategies are designated for the fast convergence of training losses. The application of OAFF-SSD to real construction sites vehicle detection and comparison with the well-known SSD (a benchmark using traditional bounding box) and orientation-aware SSD (OA-SSD) demonstrate the efficiency and accuracy of the proposed method.}
}
@article{XU2019232,
title = {Morphing control of a new bionic morphing UAV with deep reinforcement learning},
journal = {Aerospace Science and Technology},
volume = {92},
pages = {232-243},
year = {2019},
issn = {1270-9638},
doi = {https://doi.org/10.1016/j.ast.2019.05.058},
url = {https://www.sciencedirect.com/science/article/pii/S127096381930344X},
author = {Dan Xu and Zhe Hui and Yongqi Liu and Gang Chen},
keywords = {Morphing aircraft, Deep neural networks, Reinforcement learning, Actor-critic, Model-free, Deep deterministic policy gradient},
abstract = {With rapid development of aviation technology, materials science and artificial intelligence, aircraft design is pursuing higher requirements both in civil and military fields. The new generation of aircraft should have the autonomous capable of performing a variety of tasks (such as take-off and landing, cruising, maneuvering, hover, attack, etc.) under a highly variable flight environment (height, Mach number, etc.) and meanwhile maintaining good performance. Morphing aircraft can use smart materials and actuators to autonomously deform the shape according to the changes in flight environment and mission, and always maintain an optimal aerodynamic shape, therefore get flourished developments. Based on the ability of birds to stretch wings when flying at low speed and to constrict wings at high speed, a new bionic morphing UAV has been designed and developed as the study model by our team. In order to make this new aircraft be able to complete rapid autonomous morphing and aerodynamic performance optimization under different missions and flight conditions, we developed deep neural networks and reinforcement learning techniques as a control strategy. Considering the continuity of the state and action spaces for model, the Deep Deterministic Policy Gradient (DDPG) algorithm based on the actor-critic, model-free algorithm was adopted and verified on the classic nonlinear Pendulum model and Cart Pole game. After the feasibility was verified, morphing aircraft model was controlled to complete prescribed deformation using DDPG algorithm. Furthermore, on the condition that the DDPG algorithm can control morphing well, through training and testing on model using simulation data from wind tunnel tests and actual flight, the autonomous morphing control for the shape optimization of the bionic morphing UAV model could be realized.}
}
@article{HUAMIN2011352,
title = {Neutral-Network -Based Output-Redefinition Control of an Unmanned Aerial Vehicle},
journal = {Procedia Engineering},
volume = {15},
pages = {352-357},
year = {2011},
note = {CEIS 2011},
issn = {1877-7058},
doi = {https://doi.org/10.1016/j.proeng.2011.08.068},
url = {https://www.sciencedirect.com/science/article/pii/S1877705811015694},
author = {Zhang Hua-min and Ding Xiao-liang and Tao Jin-niu},
keywords = {output redefinition, neutral network, nonminimun phase system},
abstract = {in this thesis, a flight control design of an unmanned aerial vehicle (UAV) using output redefinition based neutral network control technique is presented. The UAV model chosen is a nonlinear non-minimum phase system. The output redefinition technique is used in a way such that the resulting system is minimum phase and can be inverted.NARMA-L2 neural network is trained off-line to identify the forward dynamics of the UAV model with the redefined output, and then inverted to force the real output to approximately track the desired trajectory. The results show that a good tracking performance can be achieved using this control scheme.}
}
@article{COMERT2019105264,
title = {Mapping of shallow landslides with object-based image analysis from unmanned aerial vehicle data},
journal = {Engineering Geology},
volume = {260},
pages = {105264},
year = {2019},
issn = {0013-7952},
doi = {https://doi.org/10.1016/j.enggeo.2019.105264},
url = {https://www.sciencedirect.com/science/article/pii/S0013795219302261},
author = {Resul Comert and Ugur Avdan and Tolga Gorum and Hakan A. Nefeslioglu},
keywords = {Object-based image analysis, UAV, Landslide, Kurucasile (Bartin), Cayeli (Rize)},
abstract = {The Black Sea Region of Turkey is one of the most landslide prone areas due to its high slope topography, heavy rainfall, and highly weathered hillslope material conditions. Preparation of landslide inventory maps is the first step in producing landslide susceptibility maps. Ground-based methods for mapping landslide occurrences are time-consuming and expensive. Additionally, landslide mapping based on satellite imageries and aerial photographs has some limitations, including climatic conditions, cost, and limited repetitive measurement capacity. Visual interpretation-based landslide mapping, which is based on satellite imageries and aerial photographs, is a time-consuming procedure that requires an experience-based expert opinion. Therefore, the data acquisition based on unmanned aerial vehicle (UAV) and landslide event inventory maps using an object-based classification approach can be superior to other methods in terms of speed and cost. In this study, we developed a semiautomatic model using object-based image analyses for rapid mapping of shallow landslides from the data obtained from UAVs after major landslide events in the Black Sea Region of Turkey. For this purpose, two test sites—Kurucasile (Bartin) and Cayeli (Rize)—were selected. Landslide mapping models were developed in the investigation sites, and the performance of the models was evaluated. The landslides' data obtained with the developed models were compared to the landslides' data produced by the experts. The comparison process revealed that landslides mapped by using UAV data have an accuracy rate higher than 86% according to the number of landslides and 83% according to the landslide area.}
}
@article{DESHPANDE202190,
title = {Robust Deep Reinforcement Learning for Quadcopter Control},
journal = {IFAC-PapersOnLine},
volume = {54},
number = {20},
pages = {90-95},
year = {2021},
note = {Modeling, Estimation and Control Conference MECC 2021},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2021.11.158},
url = {https://www.sciencedirect.com/science/article/pii/S2405896321022023},
author = {Aditya M. Deshpande and Ali A. Minai and Manish Kumar},
keywords = {Reinforcement learning control, Robust adaptive control, Robotics, Flying robots},
abstract = {Deep reinforcement learning (RL) has made it possible to solve complex robotics problems using neural networks as function approximators. However, the policies trained on stationary environments suffer in terms of generalization when transferred from one environment to another. In this work, we use Robust Markov Decision Processes (RMDP) to train the drone control policy, which combines ideas from Robust Control and RL. It opts for pessimistic optimization to handle potential gaps between policy transfer from one environment to another. The trained control policy is tested on the task of quadcopter positional control. RL agents were trained in a MuJoCo simulator. During testing, different environment parameters (unseen during the training) were used to validate the robustness of the trained policy for transfer from one environment to another. The robust policy outperformed the standard agents in these environments, suggesting that the added robustness increases generality and can adapt to nonstationary environments.}
}
@article{ZHANG2020280,
title = {Identifying and mapping individual plants in a highly diverse high-elevation ecosystem using UAV imagery and deep learning},
journal = {ISPRS Journal of Photogrammetry and Remote Sensing},
volume = {169},
pages = {280-291},
year = {2020},
issn = {0924-2716},
doi = {https://doi.org/10.1016/j.isprsjprs.2020.09.025},
url = {https://www.sciencedirect.com/science/article/pii/S0924271620302720},
author = {Ce Zhang and Peter M. Atkinson and Charles George and Zhaofei Wen and Mauricio Diazgranados and France Gerard},
keywords = {Multi-scale deep learning, Residual U-Net, Scale sequence, Semantic segmentation, Páramos},
abstract = {The identification and counting of plant individuals is essential for environmental monitoring. UAV based imagery offer ultra-fine spatial resolution and flexibility in data acquisition, and so provide a great opportunity to enhance current plant and in-situ field surveying. However, accurate mapping of individual plants from UAV imagery remains challenging, given the great variation in the sizes and geometries of individual plants and in their distribution. This is true even for deep learning based semantic segmentation and classification methods. In this research, a novel Scale Sequence Residual U-Net (SS Res U-Net) deep learning method was proposed, which integrates a set of Residual U-Nets with a sequence of input scales that can be derived automatically. The SS Res U-Net classifies individual plants by continuously increasing the patch scale, with features learned at small scales passing gradually to larger scales, thus, achieving multi-scale information fusion while retaining fine spatial details of interest. The SS Res U-Net was tested to identify and map frailejones (all plant species of the subtribe Espeletiinae), the dominant plants in one of the world’s most biodiverse high-elevation ecosystems (i.e. the páramos) from UAV imagery. Results demonstrate that the SS Res U-Net has the ability to self-adapt to variation in objects, and consistently achieved the highest classification accuracy (91.67% on average) compared with four state-of-the-art benchmark approaches. In addition, SS Res U-Net produced the best performances in terms of both robustness to training sample size reduction and computational efficiency compared with the benchmarks. Thus, SS Res U-Net shows great promise for solving remotely sensed semantic segmentation and classification tasks, and more general machine intelligence. The prospective implementation of this method to identify and map frailejones in the páramos will benefit immensely the monitoring of their populations for conservation assessments and management, among many other applications.}
}
@article{GUIDO2016136,
title = {Evaluating the accuracy of vehicle tracking data obtained from Unmanned Aerial Vehicles},
journal = {International Journal of Transportation Science and Technology},
volume = {5},
number = {3},
pages = {136-151},
year = {2016},
note = {Unmanned Aerial Vehicles and Remote Sensing},
issn = {2046-0430},
doi = {https://doi.org/10.1016/j.ijtst.2016.12.001},
url = {https://www.sciencedirect.com/science/article/pii/S2046043016300272},
author = {Giuseppe Guido and Vincenzo Gallelli and Daniele Rogano and Alessandro Vitale},
keywords = {UAV, GPS, Vehicle tracking, Traffic data, Video processing},
abstract = {This paper presents a methodology for tracking moving vehicles that integrates Unmanned Aerial Vehicles with video processing techniques. The authors investigated the usefulness of Unmanned Aerial Vehicles to capture reliable individual vehicle data by using GPS technology as a benchmark. A video processing algorithm for vehicles trajectory acquisition is introduced. The algorithm is based on OpenCV libraries. In order to assess the accuracy of the proposed video processing algorithm an instrumented vehicle was equipped with a high precision GPS. The video capture experiments were performed in two case studies. From the field, about 24,000 positioning data were acquired for the analysis. The results of these experiments highlight the versatility of the Unmanned Aerial Vehicles technology combined with video processing technique in monitoring real traffic data.}
}
@article{MARIN2021106476,
title = {Detecting coffee leaf rust with UAV-based vegetation indices and decision tree machine learning models},
journal = {Computers and Electronics in Agriculture},
volume = {190},
pages = {106476},
year = {2021},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2021.106476},
url = {https://www.sciencedirect.com/science/article/pii/S0168169921004932},
author = {Diego Bedin Marin and Gabriel Araújo e Silva Ferraz and Lucas Santos Santana and Brenon Diennevan Souza Barbosa and Rafael Alexandre Pena Barata and Lucas Prado Osco and Ana Paula Marques Ramos and Paulo Henrique Sales Guimarães},
keywords = {Multispectral imagery, Precision agriculture, Plant disease, Logistic model tree},
abstract = {Coffee leaf rust (CLR) is one of the most devastating leaf diseases in coffee plantations. By knowing the symptoms, severity, and spatial distribution of CLR, farmers can improve disease management procedures and reduce losses associated with it. Recently, Unmanned Aerial Vehicles (UAVs)-based images, in conjunction with machine learning (ML) techniques, helped solve multiple agriculture-related problems. In this sense, vegetation indices processed with ML algorithms are a promising strategy. It is still a challenge to map severity levels of CLR using remote sensing data and an ML approach. Here we propose a framework to detect CLR severity with only vegetation indices extracted from UAV imagery. For that, we based our approach on decision tree models, as they demonstrated important results in related works. We evaluated a coffee field with different infestation classes of CLR: class 1 (from 2% to 5% rust); class 2 (from 5% to 10% rust); class 3 (from 10% to 20% rust), and; class 4 (from 20% to 40% rust). We acquired data with a Sequoia camera, producing images with a spatial resolution of 10.6 cm, in four spectral bands: green (530–570 nm), red (640–680 nm), red-edge (730–740 nm), and near-infrared (770–810 nm). A total of 63 vegetation indices was extracted from the images, and the following learners were evaluated in a cross-validation method with 10 folders: Logistic Model Tree (LMT); J48; ExtraTree; REPTree; Functional Trees (FT); Random Tree (RT), and; Random Forest (RF). The results indicated that the LMT method contributed the most to the accurate prediction of early and several infestation classes. For these classes, LMT returned F-measure values of 0.915 and 0.875, thus being a good indicator of early CLR (2 to 5% of rust) and later stages of CLR (20 to 40% of rust). We demonstrated a valid approach to model rust in coffee plants using only vegetation indices and ML algorithms, specifically for the disease's early and later stages. We concluded that the proposed framework allows inferring the predicted classes in remaining plants within the sampled area, thus helping the identification of potential CLR in non-sampled plants. We corroborate that the decision tree-based model may assist in precision agriculture practices, including mapping rust in coffee plantations, providing both an efficient non-invasive and spatially continuous monitoring of the disease.}
}
@article{FAICAL2014393,
title = {The use of unmanned aerial vehicles and wireless sensor networks for spraying pesticides},
journal = {Journal of Systems Architecture},
volume = {60},
number = {4},
pages = {393-404},
year = {2014},
issn = {1383-7621},
doi = {https://doi.org/10.1016/j.sysarc.2014.01.004},
url = {https://www.sciencedirect.com/science/article/pii/S1383762114000204},
author = {Bruno S. Faiçal and Fausto G. Costa and Gustavo Pessin and Jó Ueyama and Heitor Freitas and Alexandre Colombo and Pedro H. Fini and Leandro Villas and Fernando S. Osório and Patrícia A. Vargas and Torsten Braun},
keywords = {Architecture, Unmanned aerial vehicles, Control loop, Agricultural applications},
abstract = {The application of pesticides and fertilizers in agricultural areas is of crucial importance for crop yields. The use of aircrafts is becoming increasingly common in carrying out this task mainly because of their speed and effectiveness in the spraying operation. However, some factors may reduce the yield, or even cause damage (e.g., crop areas not covered in the spraying process, overlapping spraying of crop areas, applying pesticides on the outer edge of the crop). Weather conditions, such as the intensity and direction of the wind while spraying, add further complexity to the problem of maintaining control. In this paper, we describe an architecture to address the problem of self-adjustment of the UAV routes when spraying chemicals in a crop field. We propose and evaluate an algorithm to adjust the UAV route to changes in wind intensity and direction. The algorithm to adapt the path runs in the UAV and its input is the feedback obtained from the wireless sensor network (WSN) deployed in the crop field. Moreover, we evaluate the impact of the number of communication messages between the UAV and the WSN. The results show that the use of the feedback information from the sensors to make adjustments to the routes could significantly reduce the waste of pesticides and fertilizers.}
}
@article{CHEMALI2018242,
title = {State-of-charge estimation of Li-ion batteries using deep neural networks: A machine learning approach},
journal = {Journal of Power Sources},
volume = {400},
pages = {242-255},
year = {2018},
issn = {0378-7753},
doi = {https://doi.org/10.1016/j.jpowsour.2018.06.104},
url = {https://www.sciencedirect.com/science/article/pii/S0378775318307080},
author = {Ephrem Chemali and Phillip J. Kollmeyer and Matthias Preindl and Ali Emadi},
keywords = {Battery management systems, Deep neural networks, Energy storage system, Li-ion batteries, Machine learning, State of charge estimation},
abstract = {Accurate State of Charge (SOC) estimation is crucial to ensure the safe and reliable operation of Li-ion batteries, which are increasingly being used in Electric Vehicles (EV), grid-tied load-leveling applications as well as manned and unmanned aerial vehicles to name a few applications. In this paper, a novel approach using Deep Feedforward Neural Networks (DNN) is used for battery SOC estimation where battery measurements are directly mapped to SOC. Training data is generated in the lab by applying drive cycle loads at various ambient temperatures to a Li-ion battery so that the battery is exposed to variable dynamics. The DNN's ability to encode the dependencies in time into the network weights and in the process provide accurate estimates of SOC is presented. Moreover, data recorded at ambient temperatures lying between −20 °C and 25 °C are fed into the DNN during training. Once trained, this single DNN is able to estimate SOC at various ambient temperature conditions. The DNN is validated over many different datasets and achieves a Mean Absolute Error (MAE) of 1.10% over a 25 °C dataset as well as an MAE of 2.17% over a −20 °C dataset.}
}
@article{OMAR2017360,
title = {Remote sensing of concrete bridge decks using unmanned aerial vehicle infrared thermography},
journal = {Automation in Construction},
volume = {83},
pages = {360-371},
year = {2017},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2017.06.024},
url = {https://www.sciencedirect.com/science/article/pii/S0926580517301139},
author = {Tarek Omar and Moncef L. Nehdi},
keywords = {Remote sensing, Bridge deck, Delamination, Infrared thermography, Unmanned aerial vehicle, Mosaic thermogram, K-means clustering, Thresholds, Condition map},
abstract = {The present study explores the potential application of unmanned aerial vehicle (UAV) Infrared Thermography for detecting subsurface delaminations in concrete bridge decks, which requires neither traffic interruption nor physical contact with the deck being inspected. A UAV-borne thermal imaging system was utilized to survey two in-service concrete bridge decks. The inspection process involved the acquisition of thermal images via low altitude flights using a high resolution thermal camera. The images were then enhanced and stitched together using custom developed codes to create a mosaic thermal image for the entire bridge deck. Image analysis based on the k-means clustering technique was utilized to segment the mosaic and identify objective thresholds. Hence, a condition map delineating different categories of delamination severity was created. The results were validated using data generated by other non-destructive testing technologies on the same bridge decks, namely hammer sounding and half-cell potential testing. The findings reveal that UAV with high-resolution thermal infrared imagery offers an efficient tool for precisely detecting subsurface anomalies in bridge decks. The proposed methodology allows more frequent and less costly bridge deck inspection without traffic interruption. This should enable rapid bridge condition assessment at various service live stages, thus effectively allocating maintenance and repair funds.}
}
@article{HENTSCHKE2016320,
title = {Design and Implementation of a Control and Navigation System for a Small Unmanned Aerial Vehicle},
journal = {IFAC-PapersOnLine},
volume = {49},
number = {30},
pages = {320-324},
year = {2016},
note = {4th IFAC Symposium on Telematics Applications TA 2016},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2016.11.155},
url = {https://www.sciencedirect.com/science/article/pii/S2405896316326143},
author = {Matheus Hentschke and Edison P. {de Freitas}},
keywords = {UAV, Aircraft control, Aircraft Navigation, Fuzzy inference, Control system, Modeling technique},
abstract = {Abstract:
This paper describes the development of a control and navigation system for a small scale unmanned aerial vehicle (UAV) using as strategy a combination of classical control and Fuzzy Inference Systems (FIS). In this sense, the air-plane has been modelled through analytical techniques that use empirical estimations to compute the force and moment components acting on the aircraft. The control systems were designed using the aircraft's transfer functions to reach a desirable response for each command. Finally, the navigation control system is designed using a FIS to control the roll of the aircraft and the yaw control system to control the aircraft's heading. A route composed of waypoints is generated following a rummage of a selected area. The control systems are, then, tested in a simulated environment to ensure they accomplish the desired mission when they work together.}
}
@article{SONG2019362,
title = {Adaptive fault tolerant control for a small coaxial rotor unmanned aerial vehicles with partial loss of actuator effectiveness},
journal = {Aerospace Science and Technology},
volume = {88},
pages = {362-379},
year = {2019},
issn = {1270-9638},
doi = {https://doi.org/10.1016/j.ast.2019.03.016},
url = {https://www.sciencedirect.com/science/article/pii/S1270963818329882},
author = {Zhankui Song and Kaibiao Sun},
keywords = {Fault-tolerant control, Compensation control, Prescribed performance characteristic, Small coaxial-rotor unmanned aerial vehicles},
abstract = {This paper investigates the trajectory tracking problem for a small coaxial-rotor unmanned aerial vehicle (CRUAV) with partial loss of actuator effectiveness. The CRUAV model is decomposed into a dual loop structure based on back-stepping design idea. First, certain performance function specified a priori by the designer is introduced into the position loop such that the original position tracking error is transformed into an equivalent constrained variable providing for the performance judgment of the position loop. Then, a fault-tolerant control scheme is proposed based on adaptive strategies for compensating the effect caused by various adverse factors. Subsequently, an attitude control loop is derived by incorporating adaptive compensation method. It is proved that the proposed dual-loop structure is able to guarantee the satisfaction of the pre-specified constraint on the transformed errors. Finally, the effectiveness and benefits of the design dual-loop control system are validated via computer simulation.}
}
@article{YANG2021101314,
title = {Identification and micro-motion parameter estimation of non-cooperative UAV targets},
journal = {Physical Communication},
volume = {46},
pages = {101314},
year = {2021},
issn = {1874-4907},
doi = {https://doi.org/10.1016/j.phycom.2021.101314},
url = {https://www.sciencedirect.com/science/article/pii/S1874490721000513},
author = {Jiachen Yang and Zhuo Zhang and Wei Mao and Yue Yang},
keywords = {Radar cross section, UAV identification, Micro-motion, Deep learning},
abstract = {With the wide application of unmanned aerial vehicles (UAV) in industrial production, transportation, and entertainment, it is urgent to identify UAVs in time. Traditional UAV recognition mainly depends on wireless communication, which puts forward high requirements for a communication environment and has no way to deal with non-cooperative targets. Therefore, it is urgent to explore a UAV target recognition scheme based on perception. In this paper, aiming at the time series preprocessing method, a coding-based sequence preprocessing method is proposed. This method effectively improves the effect of the Deep Learning method in the identification task. In order to verify the ability of Deep Learning in radar time series data processing and the effectiveness of the proposed method, the Deep Learning method is used to analyze the radar signal time series of the target to realize the target recognition. Finally,considering the influence of micro-motion factors on UAV targets, the neural network is used to estimate UAV’s micro-motion parameters to enhance the ability of target recognition with the help of micro-motion information.}
}
@article{LI2018379,
title = {A half-Gaussian fitting method for estimating fractional vegetation cover of corn crops using unmanned aerial vehicle images},
journal = {Agricultural and Forest Meteorology},
volume = {262},
pages = {379-390},
year = {2018},
issn = {0168-1923},
doi = {https://doi.org/10.1016/j.agrformet.2018.07.028},
url = {https://www.sciencedirect.com/science/article/pii/S0168192318302491},
author = {Linyuan Li and Xihan Mu and Craig Macfarlane and Wanjuan Song and Jun Chen and Kai Yan and Guangjian Yan},
keywords = {Fractional vegetation cover (FVC), Unmanned aerial vehicle, (UAV), Low-altitude remote sensing (LARS), Digital photography, Half-Gaussian distribution, Histogram threshold},
abstract = {Accurate estimates of fractional vegetation cover (FVC) using remotely sensed images collected using unmanned aerial vehicles (UAVs) offer considerable potential for field measurement. However, most existing methods, which were originally designed to extract FVC from ground-based remotely sensed images (acquired at a few meters above the ground level), cannot be directly used to process aerial images because of the presence of large quantities of mixed pixels. To alleviate the negative effects of mixed pixels, we proposed a new method for decomposing the Gaussian mixture model and estimating FVC, namely, the half-Gaussian fitting method for FVC estimation (HAGFVC). In this method, the histograms of pure vegetation pixels and pure background pixels are firstly fit using two half-Gaussian distributions in the Commission Internationale d’Eclairage (CIE) L*a*b* color space. Then, a threshold is determined based on the parameters of Gaussian distribution to generate a more accurate FVC estimate. We acquired low-altitude remote-sensing (LARS) images in three vegetative growth stages at different flight altitudes over a cornfield. The HAGFVC method successfully fitted the half-Gaussian distributions and obtained stable thresholds for FVC estimation. The results indicate that the HAGFVC method can be used to effectively and accurately derive FVC images, with a small mean bias error (MBE) and with root mean square error (RMSE) of less than 0.04 in all cases. Comparatively, other methods we tested performed poorly (RMSE of up to 0.36) because of the abundance of mixed pixels in LARS images, especially at high altitudes above ground level (AGL) or in the case of moderate vegetation coverage. The results demonstrate the importance of developing image-processing methods that specially account for mixed pixels for LARS images. Simulations indicated that the theoretical accuracy (no errors in fitting the half-Gaussian distributions) of the HAGFVC method reflected an RMSE of less than 0.07. Additionally, this method provides a useful approach to efficiently estimating FVC by using LARS images over large areas.}
}
@article{WANG2020105523,
title = {UAV environmental perception and autonomous obstacle avoidance: A deep learning and depth camera combined solution},
journal = {Computers and Electronics in Agriculture},
volume = {175},
pages = {105523},
year = {2020},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2020.105523},
url = {https://www.sciencedirect.com/science/article/pii/S0168169920303379},
author = {Dashuai Wang and Wei Li and Xiaoguang Liu and Nan Li and Chunlong Zhang},
keywords = {UAVs, Deep learning, Depth camera, Object detection, Environmental perception, Obstacle avoidance},
abstract = {In agriculture, Unmanned Aerial Vehicles (UAVs) have shown great potential for plant protection. Uncertain obstacles randomly distributed in the unstructured farmland usually pose significant collision risks to flight safety. In order to improve the UAV’s intelligence and minimize the obstacle’s adverse impacts on operating safety and efficiency, we put forward a comprehensive solution which consists of deep-learning based object detection, image processing, RGB-D information fusion and Task Control System (TCS). Taking full advantages of both deep learning and depth camera, this solution allows the UAV to perceive not only the presence of obstacles, but also their attributes like category, profile and 3D spatial position. Based on the object detection results, collision avoidance strategy generation method and the corresponding calculation approach of optimal collision avoidance flight path are elaborated detailly. A series of experiments are conducted to verify the UAV’s environmental perception ability and autonomous obstacle avoidance performance. Results show that the average detection accuracy of CNN model is 75.4% and the mean time cost for processing single image is 53.33 ms. Additionally, we find that the prediction accuracy of obstacle’s profile and position depends heavily on the relative distance between the object and the depth camera. When the distance is between 4.5 m and 8.0 m, errors of object’s depth data, width and height are −0.53 m, −0.26 m and −0.24 m respectively. Outcomes of simulation flight experiments indicated that the UAV can autonomously determine optimal obstacle avoidance strategy and generate distance-minimized flight path based on the results of RGB-D information fusion. The proposed solution has extensive potential to enhance the UAV’s environmental perception and autonomous obstacle avoidance abilities.}
}
@article{YONGBO2017445,
title = {Three-dimensional unmanned aerial vehicle path planning using modified wolf pack search algorithm},
journal = {Neurocomputing},
volume = {266},
pages = {445-457},
year = {2017},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2017.05.059},
url = {https://www.sciencedirect.com/science/article/pii/S0925231217309220},
author = {Chen YongBo and Mei YueSong and Yu JianQiao and Su XiaoLong and Xu Nuo},
keywords = {Unmanned aerial vehicle (UAV) path planning, Modified wolf pack search (WPS) algorithm, Genetic algorithm (GA), Three dimensional (3D) space, Cubic B-spline curve},
abstract = {The unmanned aerial vehicle (UAV) has been a research focus in recent years. The path planner is a key element of the unmanned aerial vehicle autonomous control module. In this paper, the modified wolf pack search (WPS) algorithm is applied to compute the quasi-optimal trajectories for the rotor wing UAVs in the complex three-dimensional (3D) spaces including the real and fake 3D spaces. Moreover, it adopts the multi-objective cost function. In the path planning process, some concepts in the genetic algorithm (GA) are applied to realize the WPS algorithm. Then, the crossover and mutation operators in the GA method are introduced to improve the original WPS algorithm. Considering the dynamic properties of the vehicle, the path smoothing process based on the cubic B-spline curve is used to make the planning path suitable for the fixed wing UAVs. Simulation results show that this approach is efficient for the rotor wing UAVs and the fixed wing UAVs when taking into account of all kinds of constraints and the path generated is flyable. Moreover, the comparisons of the four algorithms show that the trajectories produced by the modified WPS algorithm are far superior to the original WPS algorithm, the GA and the random search way under the same conditions.}
}
@article{QIAO20201292,
title = {MmNet: Identifying Mikania micrantha Kunth in the wild via a deep Convolutional Neural Network},
journal = {Journal of Integrative Agriculture},
volume = {19},
number = {5},
pages = {1292-1300},
year = {2020},
issn = {2095-3119},
doi = {https://doi.org/10.1016/S2095-3119(19)62829-7},
url = {https://www.sciencedirect.com/science/article/pii/S2095311919628297},
author = {Xi QIAO and Yan-zhou LI and Guang-yuan SU and Hong-kun TIAN and Shuo ZHANG and Zhong-yu SUN and Long YANG and Fang-hao WAN and Wan-qiang QIAN},
keywords = { Kunth, invasive alien plant, image processing, deep learning},
abstract = {Mikania micrantha Kunth is an invasive alien weed and known as a plant killer around the world. Accurately and rapidly identifying M. micrantha in the wild is important for monitoring its growth status, as this helps management officials to take the necessary steps to devise a comprehensive strategy to control the invasive weed in the identified area. However, this approach still mainly depends on satellite remote sensing and manual inspection. The cost is high and the accuracy rate and efficiency are low. We acquired color images of the monitoring area in the wild environment using an Unmanned Aerial Vehicle (UAV) and proposed a novel network —MmNet— based on a deep Convolutional Neural Network (CNN) to identify M. micrantha in the images. The network consists of AlexNet Local Response Normalization (LRN), along with the GoogLeNet and continuous convolution of VGG inception models. After training and testing, the identification of 400 testing samples by MmNet is very good, with accuracy of 94.50% and time cost of 10.369 s. Moreover, in quantitative comparative analysis, the proposed MmNet not only has high accuracy and efficiency but also simple construction and outstanding repeatability. Compared with recently popular CNNs, MmNet is more suitable for the identification of M. micrantha in the wild. However, to meet the challenge of wild environments, more M. micrantha images need to be acquired for MmNet training. In addition, the classification labels need to be sorted in more detail. Altogether, this research provides some theoretical and scientific basis for the development of intelligent monitoring and early warning systems for M. micrantha and other invasive species.}
}
@article{HE2021103754,
title = {Infrared machine vision and infrared thermography with deep learning: A review},
journal = {Infrared Physics & Technology},
volume = {116},
pages = {103754},
year = {2021},
issn = {1350-4495},
doi = {https://doi.org/10.1016/j.infrared.2021.103754},
url = {https://www.sciencedirect.com/science/article/pii/S1350449521001262},
author = {Yunze He and Baoyuan Deng and Hongjin Wang and Liang Cheng and Ke Zhou and Siyuan Cai and Francesco Ciampa},
keywords = {Machine vision, Deep learning, Thermography non-destructive testing (TNDT), Unmanned aerial vehicle (UAV), Object detection, Semantic Segmentation},
abstract = {Infrared imaging-based machine vision (IRMV) is the technology used to automatically inspect, detect, and analyse infrared images (or videos) obtained by recording the intensity of infrared light emitted or reflected by observed objects. Depending on whether controllable excitation is used during the imaging of infrared rays, thermal IRMV can be categorised into passive thermography and active thermography. Passive thermography is an important supplement to conventional machine vision based on visible light and is a valid imaging tool for self-heating objects such as the human body and electrical power devices. Active thermography is a non-destructive testing method for the quality evaluation and safety assurance of non-self-heating objects. In active thermography, the trend is to inspect rapidly, reliably, and intelligently by introducing multiple-mode excitation sources and artificial intelligence. The rapid development of deep learning makes IRMV more and more intelligent and highly automated, thus considerably increasing its range of applications. This paper reviews the principle, cameras, and thermal data of IRMV and discusses the applications of deep learning applied to IRMV. Case studies of IRMV and deep learning on various platforms such as unmanned vehicles, mobile phones and embedded systems are also reported.}
}
@article{SARABAKHA2017361,
title = {Novel Levenberg–Marquardt based learning algorithm for unmanned aerial vehicles},
journal = {Information Sciences},
volume = {417},
pages = {361-380},
year = {2017},
issn = {0020-0255},
doi = {https://doi.org/10.1016/j.ins.2017.07.020},
url = {https://www.sciencedirect.com/science/article/pii/S0020025517308393},
author = {Andriy Sarabakha and Nursultan Imanberdiyev and Erdal Kayacan and Mojtaba Ahmadieh Khanesar and Hani Hagras},
keywords = {Fuzzy neural networks, Sliding mode control, Levenberg–Marquardt algorithm, Type-1 fuzzy logic control, Unmanned aerial vehicle},
abstract = {In this paper, Levenberg–Marquardt inspired sliding mode control theory based adaptation laws are proposed to train an intelligent fuzzy neural network controller for a quadrotor aircraft. The proposed controller is used to control and stabilize a quadrotor unmanned aerial vehicle in the presence of periodic wind gust. A proportional-derivative controller is firstly introduced based on which fuzzy neural network is able to learn the quadrotor’s control model on-line. The proposed design allows handling uncertainties and lack of modelling at a computationally inexpensive cost. The parameter update rules of the learning algorithms are derived based on a Levenberg–Marquardt inspired approach, and the proof of the stability of two proposed control laws are verified by using the Lyapunov stability theory. In order to evaluate the performance of the proposed controllers extensive simulations and real-time experiments are conducted. The 3D trajectory tracking problem for a quadrotor is considered in the presence of time-varying wind conditions.}
}
@article{AMORIM2019104932,
title = {Semi-supervised learning with convolutional neural networks for UAV images automatic recognition},
journal = {Computers and Electronics in Agriculture},
volume = {164},
pages = {104932},
year = {2019},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2019.104932},
url = {https://www.sciencedirect.com/science/article/pii/S0168169919305137},
author = {Willian Paraguassu Amorim and Everton Castelão Tetila and Hemerson Pistori and João Paulo Papa},
keywords = {Semi-supervised learning, Convolutional Neural Networks, Fine tuning, Transfer learning},
abstract = {The annotation of large datasets is an issue whose challenge increases as the number of labeled samples available to train the classifier reduces in comparison to the amount of unlabeled data. In this context, semi-supervised learning methods aim at discovering and propagating labels to unsupervised samples, such that their correct labeling can improve the classification performance. Our proposal makes use of semi-supervised methodologies to classify an unlabeled training set that is used to train a Convolution Neural Network using different training strategies. The proposed approach is experimentally validated for soybean leaf and herbivorous pest identification using images captured by Unmanned Aerial Vehicles and can support specialists and farmers in the pest control management in soybean fields, especially when they have a limited amount of labeled samples.}
}
@article{LIU2021106790,
title = {Anti-saturation adaptive finite-time neural network based fault-tolerant tracking control for a quadrotor UAV with external disturbances},
journal = {Aerospace Science and Technology},
volume = {115},
pages = {106790},
year = {2021},
issn = {1270-9638},
doi = {https://doi.org/10.1016/j.ast.2021.106790},
url = {https://www.sciencedirect.com/science/article/pii/S127096382100300X},
author = {Kang Liu and Rujing Wang and Xiaodong Wang and Xingxian Wang},
keywords = {Adaptive finite-time control, NN based fault-tolerant control, Input saturation, Quadrotor UAV},
abstract = {This brief is focused on the finite-time tracking control of the quadrotor unmanned aerial vehicle (UAV) subject to external disturbances, parametric uncertainties, actuator faults, and input saturation. According to the principle of the Euler-Lagrangian methodology, a comprehensive dynamics is first decomposed into the position and attitude subsystems to accommodate the controller design. Different from the most of previous studies with an ideal assumption that velocity information is available, a robust exact differentiator is employed to gain the precise information of unavailable velocity in finite time. Then, by utilizing the strong approximation of the radial basis function neural network (RBFNN), the NN-based fault-tolerant control scheme is proposed to compensate for parametric uncertainties, external disturbances and actuator faults. More importantly, a novel adaptive mechanism is responsible for automatically adjusting the NN's parameters, which not only can effectively avoid the selection of large adaptive gains, but can also greatly decrease the number of online-updated leaning parameters. To solve the input saturation problem, an auxiliary dynamics system is constructed. Based on the Lyapunov theoretical framework, it is proved that all the closed-loop signals are uniformly ultimately bounded and the tracking errors can converge into small neighborhoods around the origin in finite time. Finally, simulation results are verified to intuitively reveal the good tracking performance of the introduced composite controller in terms of the finite-time error convergence, strong robustness, fault tolerance, and saturation elimination.}
}
@article{WAN202290,
title = {UAV swarm based radar signal sorting via multi-source data fusion: A deep transfer learning framework},
journal = {Information Fusion},
volume = {78},
pages = {90-101},
year = {2022},
issn = {1566-2535},
doi = {https://doi.org/10.1016/j.inffus.2021.09.007},
url = {https://www.sciencedirect.com/science/article/pii/S1566253521001834},
author = {Liangtian Wan and Rong Liu and Lu Sun and Hansong Nie and Xianpeng Wang},
keywords = {Signal sorting, Deep transfer learning, Data fusion, UAV swarm},
abstract = {Traditional clustering algorithms can be applied for the pre-sorting step of radar signal sorting. It can effectively dilute the pulse stream and prevent the dense pulse stream from interfering pulse repetition interval (PRI) extraction. However, the pre-sorting deviation will cause interference and missing pulses during the main sorting process. To solve this problem, we deploy the unmanned aerial vehicle (UAV) swarm to monitor reconnaissance areas and put forward a novel deep transfer learning based signal sorting method. The UAV swarm can collect the pulses from different time and spatial domains, and interference and missing pulses in main sorting processing can be relieved dramatically. In our model, we pre-train our model with the data collected from multiple source areas, which corresponds to different areas detected by different parts of UAV swarms. Then we fine-tune our model with the data of the target area. The experimental results prove that the signal sorting accuracy of methods based on deep transfer learning, i.e., YOLO-MobileNet, F-RCNN and cascade RCNN, are higher than that of the baseline methods. In addition, the signal sorting accuracy of traditional methods based on deep learning can be greatly improved with the help of transfer learning.}
}
@article{GARCIAMARQUEZ2019152,
title = {Condition monitoring system for solar power plants with radiometric and thermographic sensors embedded in unmanned aerial vehicles},
journal = {Measurement},
volume = {139},
pages = {152-162},
year = {2019},
issn = {0263-2241},
doi = {https://doi.org/10.1016/j.measurement.2019.02.045},
url = {https://www.sciencedirect.com/science/article/pii/S0263224119301630},
author = {Fausto Pedro {García Márquez} and Isaac {Segovia Ramírez}},
keywords = {Radiometric sensor, Infrared thermography, Solar photovoltaic energy, Condition monitoring system, Remotely piloted aircraft, Non-destructive testing},
abstract = {The photovoltaic solar energy industry is expanding, and there is therefore a need to increase and improve its maintainability, operating costs, availability, reliability, safety, life cycle, etc. The aim of this article is to design, develop and check a new condition monitoring system to detect dust in solar photovoltaic panels. The condition monitoring system uses a radiometric sensor connected to an Arduino platform. This novel approach is based on emissivity analysis produced over a surface and characterized with a low emissivity value when dust appears. A thermographic camera is also employed to validate the results provided by the radiometric sensor. The system is designed to be embedded in an unmanned aerial vehicle. Radiometric data is sent and analysed, Internet of Things is employed, and thermograms are stored for further processing. Several scenarios with a real solar panel are used in the experiments, in which the angles and distances of the sensors and surface conditions are studied. An analysis of the radiometric sensor provides accuracy results, and the presence of dust is identified in all scenarios.}
}
@article{SALMAN2012109,
title = {Fuzzy Model Based Control of Unmanned Aerial Vehicle},
journal = {IFAC Proceedings Volumes},
volume = {45},
number = {1},
pages = {109-114},
year = {2012},
note = {1st IFAC Workshop on Embedded Guidance, Navigation and Control in Aerospace},
issn = {1474-6670},
doi = {https://doi.org/10.3182/20120213-3-IN-4034.00022},
url = {https://www.sciencedirect.com/science/article/pii/S1474667015350291},
author = {Shaaban A. Salman and Sreenatha G. Anavatti},
keywords = {Fuzzy Control, Unmanned Aerial Vehicle, Non-linear dynamics},
abstract = {The design of fuzzy model based controller with a new analytical inversion method is presented and applied for attitude control problem of Unmanned Aerial Vehicle (UAV). The purpose of adaptive controller is to follow a certain pitch angle command under level flight condition which requires the roll stabilization controller. The Aerosonde simulation model has been chosen to apply the proposed analytical fuzzy model based controller. The simulation results show that both the roll rate and the pitch angles are tracked by the adaptive controller without significant transients. Flight test results for angle of attack control of a fixed wing platform which has been developed at UNSW@ADFA show that the controller is robust to operate in a real time environment.}
}
@article{DAS2021108477,
title = {Evaluation of water status of wheat genotypes to aid prediction of yield on sodic soils using UAV-thermal imaging and machine learning},
journal = {Agricultural and Forest Meteorology},
volume = {307},
pages = {108477},
year = {2021},
issn = {0168-1923},
doi = {https://doi.org/10.1016/j.agrformet.2021.108477},
url = {https://www.sciencedirect.com/science/article/pii/S016819232100160X},
author = {Sumanta Das and Jack Christopher and Armando Apan and Malini Roy Choudhury and Scott Chapman and Neal W. Menzies and Yash P. Dang},
keywords = {Thermal remote sensing, Crop water stress, Classification and regression tree, Biomass yield, Grain yield, Sodic soils},
abstract = {Water stress limits wheat growth and the yield on rain-fed sodic soils. Appropriate selection of traits and novel methods are required to forecast yield and to identify water stress tolerant wheat genotypes on sodic soils. In this study, we proposed a thermal remote sensing and machine learning-based approach to help predict the biomass and grain yields of wheat genotypes grown with variable water stress in sodic soil environments. We employed unmanned aerial vehicle-based thermal imaging to quantify water stress of 18 contrasting wheat genotypes grown on moderately sodic (MS) and highly sodic (HS) soils in north-eastern grains growing regions of Australia and related these to ground-measured plant biomass and grain yields. We evaluated crop water stress indices; standardized canopy temperature index, crop water stress index, stomatal conductance index, vapour pressure deficit, and crop stress index, which were computed from thermal imagery and on-site agro-meteorological parameters close to flowering. We then employed a classification and regression tree (CRT) as a supervised machine learning algorithm to classify crop water stress and predict biomass and grain yields as a function of crop water stress indices. The CRT accurately predicted biomass yield (coefficient of determination (R2) = 0.86; root mean square error (RMSE) = 41.3 g/m2 and R2 = 0.75; RMSE = 47.7 g/m2 for the MS and HS site) and grain yield (R2 = 0.78; RMSE = 16.7 g/m2 and R2 = 0.69; RMSE = 23.2 g/m2 for the MS and HS site, respectively). High sodic soil constraints increased crop water stress more than moderately sodic constraints soil that limits wheat yield ~40%. Wheat genotypes; Bremer, Gregory, Lancer, Mace, and Mitch were more productive than Gladius, Flanker, Scout, Emu Rock, and Janz in sodic soil environments. The study improves our ability to develop decision-making tools to assist farmers and breeders in securing agricultural productivity on sodic soils.}
}
@article{MAIMAITIJIANG2020111599,
title = {Soybean yield prediction from UAV using multimodal data fusion and deep learning},
journal = {Remote Sensing of Environment},
volume = {237},
pages = {111599},
year = {2020},
issn = {0034-4257},
doi = {https://doi.org/10.1016/j.rse.2019.111599},
url = {https://www.sciencedirect.com/science/article/pii/S0034425719306194},
author = {Maitiniyazi Maimaitijiang and Vasit Sagan and Paheding Sidike and Sean Hartling and Flavio Esposito and Felix B. Fritschi},
keywords = {Remote sensing, Yield prediction, Multimodality, Data fusion, Deep learning, Phenotyping, Spatial autocorrelation},
abstract = {Preharvest crop yield prediction is critical for grain policy making and food security. Early estimation of yield at field or plot scale also contributes to high-throughput plant phenotyping and precision agriculture. New developments in Unmanned Aerial Vehicle (UAV) platforms and sensor technology facilitate cost-effective data collection through simultaneous multi-sensor/multimodal data collection at very high spatial and spectral resolutions. The objective of this study is to evaluate the power of UAV-based multimodal data fusion using RGB, multispectral and thermal sensors to estimate soybean (Glycine max) grain yield within the framework of Deep Neural Network (DNN). RGB, multispectral, and thermal images were collected using a low-cost multi-sensory UAV from a test site in Columbia, Missouri, USA. Multimodal information, such as canopy spectral, structure, thermal and texture features, was extracted and combined to predict crop grain yield using Partial Least Squares Regression (PLSR), Random Forest Regression (RFR), Support Vector Regression (SVR), input-level feature fusion based DNN (DNN-F1) and intermediate-level feature fusion based DNN (DNN-F2). The results can be summarized in three messages: (1) multimodal data fusion improves the yield prediction accuracy and is more adaptable to spatial variations; (2) DNN-based models improve yield prediction model accuracy: the highest accuracy was obtained by DNN-F2 with an R2 of 0.720 and a relative root mean square error (RMSE%) of 15.9%; (3) DNN-based models were less prone to saturation effects, and exhibited more adaptive performance in predicting grain yields across the Dwight, Pana and AG3432 soybean genotypes in our study. Furthermore, DNN-based models demonstrated consistent performance over space with less spatial dependency and variations. This study indicates that multimodal data fusion using low-cost UAV within a DNN framework can provide a relatively accurate and robust estimation of crop yield, and deliver valuable insight for high-throughput phenotyping and crop field management with high spatial precision.}
}
@article{PAJARES2015281,
title = {Overview and Current Status of Remote Sensing Applications Based on Unmanned Aerial Vehicles (UAVs)},
journal = {Photogrammetric Engineering & Remote Sensing},
volume = {81},
number = {4},
pages = {281-329},
year = {2015},
issn = {0099-1112},
doi = {https://doi.org/10.14358/PERS.81.4.281},
url = {https://www.sciencedirect.com/science/article/pii/S0099111215300793},
author = {Gonzalo Pajares},
abstract = {Abstract
Remotely Piloted Aircraft (RPA) is presently in continuous development at a rapid pace. Unmanned Aerial Vehicles (UAVs) or more extensively Unmanned Aerial Systems (UAS) are platforms considered under the RPAs paradigm. Simultaneously, the development of sensors and instruments to be installed onboard such platforms is growing exponentially. These two factors together have led to the increasing use of these platforms and sensors for remote sensing applications with new potential. Thus, the overall goal of this paper is to provide a panoramic overview about the current status of remote sensing applications based on unmanned aerial platforms equipped with a set of specific sensors and instruments. First, some examples of typical platforms used in remote sensing are provided. Second, a description of sensors and technologies is explored which are onboard instruments specifically intended to capture data for remote sensing applications. Third, multi-UAVs in collaboration, coordination, and cooperation in remote sensing are considered. Finally, a collection of applications in several areas are proposed, where the combination of unmanned platforms and sensors, together with methods, algorithms, and procedures provide the overview in very different remote sensing applications. This paper presents an overview of different areas, each independent from the others, so that the reader does not need to read the full paper when a specific application is of interest}
}
@article{WANNURAZWINSYAZWANI20221265,
title = {Automated image identification, detection and fruit counting of top-view pineapple crown using machine learning},
journal = {Alexandria Engineering Journal},
volume = {61},
number = {2},
pages = {1265-1276},
year = {2022},
issn = {1110-0168},
doi = {https://doi.org/10.1016/j.aej.2021.06.053},
url = {https://www.sciencedirect.com/science/article/pii/S111001682100418X},
author = {R. {Wan Nurazwin Syazwani} and H. {Muhammad Asraf} and M.A. {Megat Syahirul Amin} and K.A. {Nur Dalila}},
keywords = {Pineapple crown, Crop recognition, Image processing, Precision agriculture, Yield counting},
abstract = {Automated fruit identification or recognition using image processing is a key element in precision agriculture for performing object detection in large crop plots. Automation of fruit recognition for the captured top-view of RGB based images using an unmanned aerial vehicle (UAV) is a challenge. Image analysis demonstrated the difficulty of processing the captured image under variant illumination in natural environment and with textured objects of non-ideal geometric shapes. However, this is subjected to certain consideration settings and image-processing algorithms. The study presents an automatic method for identifying and recognising the pineapple’s crown images in the designated plot using image processing and further counts the detected images using machine learning classifiers namely artificial neural network (ANN), support vector machine (SVM), random forest (RF), naive Bayes (NB), decision trees (DT) and k-nearest neighbours (KNN). The high spatial-resolution aerial images were pre-processed and segmented, and its extracted features were analysed according to shape, colour and texture for recognising the pineapple crown before classifying it as fruit or non-fruit. Feature fusion using one-way analysis of variance (ANOVA) was incorporated in this study to optimise the performance of machine learning classifier. The algorithm was quantitatively analysed and validated for performance via accuracy, specificity, sensitivity and precision. The detection for the pineapple’s crown images with ANN-GDX classification has demonstrated best performance fruit counting with accuracy of 94.4% and has thus demonstrated clear potential application of an effective RGB images analysis for the pineapple industry.}
}
@article{NOGUERA20211,
title = {Nutritional status assessment of olive crops by means of the analysis and modelling of multispectral images taken with UAVs},
journal = {Biosystems Engineering},
volume = {211},
pages = {1-18},
year = {2021},
issn = {1537-5110},
doi = {https://doi.org/10.1016/j.biosystemseng.2021.08.035},
url = {https://www.sciencedirect.com/science/article/pii/S1537511021002191},
author = {Miguel Noguera and Arturo Aquino and Juan M. Ponce and António Cordeiro and José Silvestre and Rocío Arias-Calderón and Maria da Encarnação Marcelo and Pedro Jordão and José M. Andújar},
keywords = {Multispectral, Nitrogen, Phosphorus, Potassium, Artificial Neural Network (ANN), Unmanned Aerial Vehicle (UAV), Precision agriculture},
abstract = {This research was aimed at developing an efficient method for Nitrogen, Phosphorus, and Potassium (NPK) foliar content retrieval in olive trees by means of the analysis and modelling multispectral images taken by an unmanned aerial vehicle (UAV) under field conditions. To this end, an experiment was carried out in a super hight density olive orchard. The fertirrigation system of the experimental area was sectorized to obtain plots with different status of NPK. The orchard was overflown with a UAV equipped with a multispectral camera that photographed the entire experimental surface. A new image analysis approach was developed for integrating all the spectral images gathered during the flight in orthomosaics from which to automatically extract information from discrete points. Finally, several retrieval techniques (partial least squares regression, artificial neural network (ANN), support vector regression and Gaussian process regression) were evaluated for NPK leaf content retrieval by using the spectral data as input variables, and the results of chemical analyses as reference. Among all, the best results were obtained by ANN approach (N (R2 = 0.63), P (R2 = 0.89), K (R2 = 0.93)). These results showed the suitability of the proposed image processing approach and indicate ANN as the best recovery technique for the experimental conditions evaluated. However, the approach must be validated under other environmental conditions, olive varieties and plant vegetative stages before making fertilization recommendations.}
}
@article{LI20192466,
title = {A new modeling scheme for powered parafoil unmanned aerial vehicle platforms: Theory and experiments},
journal = {Chinese Journal of Aeronautics},
volume = {32},
number = {11},
pages = {2466-2479},
year = {2019},
issn = {1000-9361},
doi = {https://doi.org/10.1016/j.cja.2019.04.001},
url = {https://www.sciencedirect.com/science/article/pii/S1000936119301475},
author = {Bingbing LI and Yuqing HE and Jianda HAN and Jizhong XIAO},
keywords = {Active model, Data correlation analysis, Model complexity, Powered parafoil, State estimation, Unmanned aerial vehicle (UAV)},
abstract = {A novel framework is established for accurate modeling of Powered Parafoil Unmanned Aerial Vehicle (PPUAV). The model is developed in the following three steps: obtaining a linear dynamic model, simplifying the model structure, and estimating the model mismatch due to model variance and external disturbance factors. First, a six degree-of-freedom linear model, or the structured model, is obtained through dynamic establishment and linearization. Second, the data correlation analysis is adopted to determine the criterion for proper model complexity and to simplify the structured model. Next, an active model is established, combining the simplified model with the model mismatch estimator. An adapted Kalman filter is utilized for the real-time estimation of states and model mismatch. We finally derive a linear system model while taking into account of model variance and external disturbance. Actual flight tests verify the effectiveness of our active model in different flight scenarios.}
}
@article{TETILA2020105836,
title = {Detection and classification of soybean pests using deep learning with UAV images},
journal = {Computers and Electronics in Agriculture},
volume = {179},
pages = {105836},
year = {2020},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2020.105836},
url = {https://www.sciencedirect.com/science/article/pii/S016816991831055X},
author = {Everton Castelão Tetila and Bruno Brandoli Machado and Gilberto Astolfi and Nícolas Alessandro de Souza Belete and Willian Paraguassu Amorim and Antonia Railda Roel and Hemerson Pistori},
keywords = {UAV, Remote sensing, Soybean pests, Precision agriculture, Deep learning},
abstract = {This paper presents the results of the evaluation of five deep learning architectures for the classification of soybean pest images. The performance of Inception-v3, Resnet-50, VGG-16, VGG-19 and Xception was evaluated for different fine-tuning and transfer learning strategies over a dataset of 5,000 images captured in real field conditions. The experimental results showed that the deep learning architectures trained with a fine-tuning can lead to higher classification rates in comparison to other approaches, reaching accuracies of up to 93.82%. In addition, deep learning architectures outperformed traditional feature extraction methods, such as SIFT and SURF with Bag-of-Visual Words approach, the semi-supervised learning method OPFSEMImst, and supervised learning methods used to classify images, for example, SVM, k-NN and Random Forest. The results indicate that architectures evaluated can support specialists and farmers in the pest control management in soybean fields.}
}
@article{ESFAHLANI201942,
title = {Mixed reality and remote sensing application of unmanned aerial vehicle in fire and smoke detection},
journal = {Journal of Industrial Information Integration},
volume = {15},
pages = {42-49},
year = {2019},
issn = {2452-414X},
doi = {https://doi.org/10.1016/j.jii.2019.04.006},
url = {https://www.sciencedirect.com/science/article/pii/S2452414X18300773},
author = {Shabnam Sadeghi Esfahlani},
keywords = {Fire detection, Autonomous flight, Crazyflie 2.0, Monocular camera, Computer vision},
abstract = {This paper proposes the development of a system incorporating inertial measurement unit (IMU), a consumer-grade digital camera and a fire detection algorithm simultaneously with a nano Unmanned Aerial Vehicle (UAV) for inspection purposes. The video streams are collected through the monocular camera and navigation relied on the state-of-the-art indoor/outdoor Simultaneous Localisation and Mapping (SLAM) system. It implements the robotic operating system (ROS) and computer vision algorithm to provide a robust, accurate and unique inter-frame motion estimation. The collected onboard data are communicated to the ground station and used the SLAM system to generate a map of the environment. A robust and efficient re-localization was performed to recover from tracking failure, motion blur, and frame lost in the data received. The fire detection algorithm was deployed based on the color, movement attributes, temporal variation of fire intensity and its accumulation around a point. The cumulative time derivative matrix was utilized to analyze the frame-by-frame changes and to detect areas with high-frequency luminance flicker (random characteristic). Color, surface coarseness, boundary roughness, and skewness features were perceived as the quadrotor flew autonomously within the clutter and congested area. Mixed Reality system was adopted to visualize and test the proposed system in a physical environment, and the virtual simulation was conducted through the Unity game engine. The results showed that the UAV could successfully detect fire and flame, autonomously fly towards and hover around it, communicate with the ground station and simultaneously generate a map of the environment. There was a slight error between the real and virtual UAV calibration due to the ground truth data and the correlation complexity of tracking real and virtual camera coordinate frames.}
}
@article{FERDAUS2019313,
title = {Online identification of a rotary wing Unmanned Aerial Vehicle from data streams},
journal = {Applied Soft Computing},
volume = {76},
pages = {313-325},
year = {2019},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2018.12.013},
url = {https://www.sciencedirect.com/science/article/pii/S1568494618307026},
author = {Md Meftahul Ferdaus and Mahardhika Pratama and Sreenatha G. Anavatti and Matthew A. Garratt},
keywords = {Evolving, Fuzzy, Metacognitive, Online identification, Quadcopter, Scaffolding},
abstract = {Until now the majority of the neuro and fuzzy modeling and control approaches for rotary wing Unmanned Aerial Vehicles (UAVs), such as the quadrotor, have been based on batch learning techniques, therefore static in structure, and cannot adapt to rapidly changing environments. Implication of Evolving Intelligent System (EIS) based model-free data-driven techniques in fuzzy system are good alternatives, since they are able to evolve both their structure and parameters to cope with sudden changes in behavior, and performs perfectly in a single pass learning mode which is suitable for online real-time deployment. The Metacognitive Scaffolding Learning Machine (McSLM) is seen as a generalized version of EIS since the metacognitive concept enables the what-to-learn, how-to-learn, and when-to-learn scheme, and the scaffolding theory realizes a plug-and-play property which strengthens the online working principle of EISs. This paper proposes a novel online identification scheme, applied to a quadrotor using real-time experimental flight data streams based on McSLM, namely Metacognitive Scaffolding Interval Type 2 Recurrent Fuzzy Neural Network (McSIT2RFNN). Our proposed approach demonstrated significant improvements in both accuracy and complexity against some renowned existing variants of the McSLMs and EISs.}
}
@article{SUJATHA2021103615,
title = {Performance of deep learning vs machine learning in plant leaf disease detection},
journal = {Microprocessors and Microsystems},
volume = {80},
pages = {103615},
year = {2021},
issn = {0141-9331},
doi = {https://doi.org/10.1016/j.micpro.2020.103615},
url = {https://www.sciencedirect.com/science/article/pii/S0141933120307626},
author = {R. Sujatha and Jyotir Moy Chatterjee and NZ Jhanjhi and Sarfraz Nawaz Brohi},
keywords = {Plant disease, ML, DL, SVM, RF, SGD, Inception-v3, VGG-16, VGG-19, CA},
abstract = {Plants are recognized as essential as they are the primary source of humanity's energy production since they are having nutritious, medicinal, etc. values. At any time between crop farming, plant diseases can affect the leaf, resulting in enormous crop production damages and economic market value. Therefore, in the farming industry, identification of leaf disease plays a crucial role. It needs, however, enormous labor, greater preparation time, and comprehensive plant pathogen knowledge. For the identification of plant disease detection various machine learning (ML) as well as deep learning (DL) methods are developed & examined by various researchers, and many of the times they also got significant results in both cases. Motivated by those existing works, here in this article we are comparing the performance of ML (Support Vector Machine (SVM), Random Forest (RF), Stochastic Gradient Descent (SGD)) & DL (Inception-v3, VGG-16, VGG-19) in terms of citrus plant disease detection. The disease classification accuracy (CA) we received by experimentation is quite impressive as DL methods perform better than that of ML methods in case of disease detection as follows: RF-76.8% > SGD-86.5% > SVM-87% > VGG-19–87.4% > Inception-v3–89% > VGG-16–89.5%. From the result, we can tell that RF is giving the least CA whereas VGG-16 is giving the best in terms of CA.}
}
@article{CHOI2021107579,
title = {Study on robust aerial docking mechanism with deep learning based drogue detection and docking},
journal = {Mechanical Systems and Signal Processing},
volume = {154},
pages = {107579},
year = {2021},
issn = {0888-3270},
doi = {https://doi.org/10.1016/j.ymssp.2020.107579},
url = {https://www.sciencedirect.com/science/article/pii/S0888327020309651},
author = {Andrew Jaeyong Choi and Hyeon-Ho Yang and Jae-Hung Han},
keywords = {Aerial docking, Probe-and-drogue system, Bistable mechanism, Deep learning, Real-time detection, YOLOv3},
abstract = {This paper proposes a simple and a robust bistable docking system with a deep learning based real-time drogue detection and tracking system for Unmanned Aircraft Systems (UAS) for mid-air autonomous aerial docking. Secure aerial docking mechanisms between the leader and follower aerial vehicles with effective drogue detection and tracking strategies are fundamental challenges during the air-to-air docking phase of autonomous aerial docking. To confront those issues, this paper not only presents the design of a bistable-based aerial docking mechanism, but also proposes effective deep learning based real-time drogue detection using a convolutional neural network (CNN) and real-time tracking algorithm using a point cloud algorithm. To ensure novelty and robustness for the aerial docking mechanism, a foldable bistable gripper-type mechanism is designed to increase the grasping performance with simplicity and adaptability. The proposed gripper acts as a drogue by itself to grasp a probe which is attached to the follower aerial vehicle. To employ an effective drogue detection method, the deep learning based real-time object detection algorithm, YOLOv3, is used to implement the drogue detection system. The proposed new probe-and-drogue type bistable docking system has the advantages of being simple and robust. The deep learning based real-time drogue detection method increases the detection rate. Moreover, the real-time tracking algorithm with a depth camera system does not require a GPS/INS system and many other sensors to follow the drogue movement in the air.}
}
@article{PEREZORTIZ2015533,
title = {A semi-supervised system for weed mapping in sunflower crops using unmanned aerial vehicles and a crop row detection method},
journal = {Applied Soft Computing},
volume = {37},
pages = {533-544},
year = {2015},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2015.08.027},
url = {https://www.sciencedirect.com/science/article/pii/S1568494615005281},
author = {M. Pérez-Ortiz and J.M. Peña and P.A. Gutiérrez and J. Torres-Sánchez and C. Hervás-Martínez and F. López-Granados},
keywords = {Remote sensing, Unmanned aerial vehicles (UAV), Weed detection, Machine learning, Hough transform, Support vector machine},
abstract = {This paper presents a system for weed mapping, using imagery provided by unmanned aerial vehicles (UAVs). Weed control in precision agriculture is based on the design of site-specific control treatments according to weed coverage. A key component is precise and timely weed maps, and one of the crucial steps is weed monitoring, by ground sampling or remote detection. Traditional remote platforms, such as piloted planes and satellites, are not suitable for early weed mapping, given their low spatial and temporal resolutions. Nonetheless, the ultra-high spatial resolution provided by UAVs can be an efficient alternative. The proposed method for weed mapping partitions the image and complements the spectral information with other sources of information. Apart from the well-known vegetation indexes, which are commonly used in precision agriculture, a method for crop row detection is proposed. Given that crops are always organised in rows, this kind of information simplifies the separation between weeds and crops. Finally, the system incorporates classification techniques for the characterisation of pixels as crop, soil and weed. Different machine learning paradigms are compared to identify the best performing strategies, including unsupervised, semi-supervised and supervised techniques. The experiments study the effect of the flight altitude and the sensor used. Our results show that an excellent performance is obtained using very few labelled data complemented with unlabelled data (semi-supervised approach), which motivates the use of weed maps to design site-specific weed control strategies just when farmers implement the early post-emergence weed control.}
}
@article{AKTER2021108519,
title = {CNN-SSDI: Convolution neural network inspired surveillance system for UAVs detection and identification},
journal = {Computer Networks},
volume = {201},
pages = {108519},
year = {2021},
issn = {1389-1286},
doi = {https://doi.org/10.1016/j.comnet.2021.108519},
url = {https://www.sciencedirect.com/science/article/pii/S1389128621004503},
author = {Rubina Akter and Van-Sang Doan and Jae-Min Lee and Dong-Seong Kim},
keywords = {Convolution neural network, Drone detection and identification, Radio frequency signal},
abstract = {In recent years, the availability of commercial unmanned air vehicles (UAVs) has increased enormously because of device miniaturization and low cost. However, the abuse of UAVs needs to be investigated to prevent serious security threats for civilians. Therefore, this paper presents a convolutional neural network-based surveillance system for drone detection and its type identification, namely CNN-SSDI. The network architecture is cleverly designed based on deep convolution layers to successfully learn all intrinsic feature maps of radio-frequency signals that are collected from three different types of drones. Further, a detailed comparative analysis of various kernel impairments of the convolution layer structure was investigated under various performance metrics evaluation and higher accuracy in drone surveillance systems. According to the empirical results, CNN-SSDI can detect a UAV with 99.8% accuracy and recognize drone types with an accuracy of 94.5%, which outperforms other existing drone detection and identification techniques.}
}
@article{WIGMORE2019104,
title = {Sub-metre mapping of surface soil moisture in proglacial valleys of the tropical Andes using a multispectral unmanned aerial vehicle},
journal = {Remote Sensing of Environment},
volume = {222},
pages = {104-118},
year = {2019},
issn = {0034-4257},
doi = {https://doi.org/10.1016/j.rse.2018.12.024},
url = {https://www.sciencedirect.com/science/article/pii/S0034425718305777},
author = {Oliver Wigmore and Bryan Mark and Jeffrey McKenzie and Michel Baraer and Laura Lautz},
keywords = {Unmanned aerial vehicle, Soil moisture, Thermal, Multispectral, Cordillera Blanca},
abstract = {Surface soil moisture is a critical but often neglected component of the hydrologic budget. Within mountain environments, surface soil moisture is highly heterogeneous and challenging to measure. Point measurements are often poorly representative of larger areas, while satellite pixels are generally too coarse in these topographically varied landscapes. In the Cordillera Blanca, Peru, rapid glacier recession is impacting downstream water supply in timing, quantity and quality. Recent research has shown that these proglacial valleys provide vital ecosystem services and store considerable amounts of water within the groundwater systems. However, the spatial and temporal variability of soil water storage is poorly understood. In this tropical Andean setting, we use an unmanned aerial vehicle (UAV) with multispectral (visible, near infrared, thermal infrared) sensors to map sections of two proglacial valleys in the Cordillera Blanca, Peru at sub-metre resolution. We use the Temperature Vegetation Dryness Index (TVDI) (Sandholt et al., 2002), and apply it for the first time to UAV borne imagery to estimate absolute surface soil moisture through calibration with in-scene field measurements. Resulting surface soil moisture maps have 50 cm spatial resolution with an R2 value of 0.55 and 0.76 for the two study sites, Pachacoto and Llanganuco respectively. We analyse the multispectral orthomosaics and soil moisture maps to improve our understanding of the controls on spatial variability in surface soil moisture within the proglacial valleys of the Cordillera Blanca. The maps permit us to identify both important groundwater spring sources and areas where domestic grazing impacts observed soil moisture estimates. The high resolution observations provided by the UAV facilitate a greater understanding of fine scale heterogeneity within these environments.}
}
@article{HASSAAN201616,
title = {Precision Forestry: Trees Counting in Urban Areas Using Visible Imagery based on an Unmanned Aerial Vehicle},
journal = {IFAC-PapersOnLine},
volume = {49},
number = {16},
pages = {16-21},
year = {2016},
note = {5th IFAC Conference on Sensing, Control and Automation Technologies for Agriculture AGRICONTROL 2016},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2016.10.004},
url = {https://www.sciencedirect.com/science/article/pii/S2405896316315658},
author = {Omair Hassaan and Ahmad Kamal Nasir and Hubert Roth and M. Fakhir Khan},
keywords = {Precision Forestry, Robotics, Vision, UAV},
abstract = {Abstract:
This research work describes an approach to count trees in an urban environment. Furthermore it addresses the problems involved in detection of trees in aerial imagery. This work can be used to solve the problem of forest degradation and deforestation. Right now forest man labor isn’t efficient enough to detect or prevent this problem. A multi-rotor UAV equipped with high resolution RGB camera was used to acquire aerial images and to count number of trees in surveyed area. Various issues involved in the robust implementation of proposed algorithm are discussed. The result of successful implementation of the proposed algorithm on multiple scenarios are also presented and we show that our naive approach is able to achieve ≈ 0.72 accuracy within reasonable amount of time.}
}
@article{YADAV2021101247,
title = {Identification of disease using deep learning and evaluation of bacteriosis in peach leaf},
journal = {Ecological Informatics},
volume = {61},
pages = {101247},
year = {2021},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2021.101247},
url = {https://www.sciencedirect.com/science/article/pii/S1574954121000388},
author = {Saumya Yadav and Neha Sengar and Akriti Singh and Anushikha Singh and Malay Kishore Dutta},
keywords = {Bacterial spot, Deep learning, Image processing, Morphological processing, Peach crops},
abstract = {Bacteriosis is one of the most common and devastating diseases for peach crops all over the world. Timely identification of bacteriosis disease is necessary for reducing the usage of pesticides and minimize loss of crops. In this proposed work, convolutional neural network (CNN) models using deep learning and an imaging method is developed for bacteriosis detection from the peach leaf images. In the imaging method, disease affected area is quantified and an adaptive operation is applied to a selected suitable channel of the color image. Gray level slicing is done on pre-processed leaf images for segmentation and automatic identification of bacterial spot disease in peach crops. The datasets are augmented to make the algorithm more robust to different illumination conditions. The proposed work compares the result of imaging method and CNN method. Model architectures generated with different deep learning algorithms, had the best performance reaching an accuracy of 98.75%% identifying the corresponding peach leaf [bacterial and healthy] in 0.185 s per image. The test dataset is consist of images from real cultivation field and also from the laboratory conditions. The significantly high identification rate makes the model diagnostic or early warning tool, and an approach that could be further integrated with the unmanned aerial vehicle to operate in real farming conditions}
}
@article{BASRI20194374,
title = {Conceptual design and simulation validation based finite element optimisation for tubercle leading edge composite wing of an unmanned aerial vehicle},
journal = {Journal of Materials Research and Technology},
volume = {8},
number = {5},
pages = {4374-4386},
year = {2019},
issn = {2238-7854},
doi = {https://doi.org/10.1016/j.jmrt.2019.07.049},
url = {https://www.sciencedirect.com/science/article/pii/S2238785419301413},
author = {Ernnie Illyani Basri and Faizal Mustapha and Mohamed Thariq Hameed Sultan and Adi Azriff Basri and Mohd Firdaus Abas and Mohd Shukry Abdul Majid and Kamarul Arifin Ahmad},
keywords = {Laminates composite wing, Rib-reinforced, Monocoque-foam, Finite element analysis},
abstract = {A finite element model is developed to determine deformation and stresses on a composite wing of unmanned aerial vehicle (UAV) with a tubercle design at the leading edge of the wing. Tubercles, commonly known as protuberances found on the leading edge of a whale pectoral flipper, offering great performance from an aerodynamic perspective. This paper deals with a first order shear deformation theory (FSDT) approach to discover the UAV laminates composite wing model of tubercle leading edge (TLE) with rib-reinforced so that the equivalent stiffness and material properties are obtained from the simulation of finite element analysis using ANSYS. Another structural configuration of design replicating the idea of monocoque concept, whereby foam is used at the leading and trailing edges of the wing. Styrene acrylonitrile (SAN) core foam is used representing high strength-to-weight ratio with its superiority in the mechanical properties of polymeric sandwich composites. The updated static structural analysis from rib-reinforced can be applied to update the wing stiffness distribution of monocoque-foam. The optimum design is concluded from the tabulated deformation and stresses of both wings, where monocoque-foam showed better performance with a reduction in 50.72% of deformation and 35.88% of stress, compared to rib-reinforced design.}
}
@article{ZHEN201899,
title = {Automatic carrier landing control for unmanned aerial vehicles based on preview control and particle filtering},
journal = {Aerospace Science and Technology},
volume = {81},
pages = {99-107},
year = {2018},
issn = {1270-9638},
doi = {https://doi.org/10.1016/j.ast.2018.07.039},
url = {https://www.sciencedirect.com/science/article/pii/S1270963816308562},
author = {Ziyang Zhen and Shuoying Jiang and Kun Ma},
keywords = {Unmanned aerial vehicle, Automatic carrier landing, Preview control, Particle filtering, Flight control},
abstract = {For the carrier-based unmanned aerial vehicles (UAVs), one of the important problems is the design of an automatic carrier landing system (ACLS) that would enable autonomous landing of the UAVs on a moving aircraft carrier. However, the safe autolanding on a moving aircraft is a complex task, mainly because of the deck motion and airwake disturbances, and dimension limitation. In this paper, an innovative ACLS system for carrier-based UAVs is developed, which is composed of the flight deck motion prediction, reference glide slope generation and integrated guidance and control (IGC) modules. The particle filtering method is used to online predict the magnitudes and frequencies of the deck motion, which are used to correct the reference glide slope to achieve minimum dispersion around the ideal touchdown point. An optimal preview control (OPC) scheme is presented for the IGC subsystem design, which fuses the preview information of the reference glide slope, equality constraint of UAV dynamics and performance index function, and predicted information of the carrier deck motion. Simulation results of a nonlinear UAV model show the effectiveness of the ACLS system in carrier autolanding under the deck motion and airwake disturbances.}
}
@article{TANG2019105551,
title = {Spatial pattern of pika holes and their effects on vegetation coverage on the Tibetan Plateau: An analysis using unmanned aerial vehicle imagery},
journal = {Ecological Indicators},
volume = {107},
pages = {105551},
year = {2019},
issn = {1470-160X},
doi = {https://doi.org/10.1016/j.ecolind.2019.105551},
url = {https://www.sciencedirect.com/science/article/pii/S1470160X19305369},
author = {Ze Tang and Yangjian Zhang and Nan Cong and Michael Wimberly and Li Wang and Ke Huang and Junxiang Li and Jiaxing Zu and Yixuan Zhu and Ning Chen},
keywords = {Pika hole, Vegetation coverage, Northern Tibet, UAV images, Object-oriented classification},
abstract = {The pika (Ochotona curzoniae) hole is an important landscape feature in the Tibetan Plateau (TP) grasslands, and it indicates grassland degradation levels due to the destruction caused by pika burrowing activities on grasslands. However, no studies have ever explored landscape patterns of pika holes and their effects on adjacent vegetation coverage. Taking meadow grasslands in Northern Tibet as an example, this study gathered unmanned aerial vehicle (UAV) images and explored landscape patterns of pika holes and their effects on grass coverage in the surroundings. The performances of two classification methods, including the decision tree classification based on Fully Constrained Least Squares (FDC) and the object-oriented classification (OBC) were compared in recognizing sizes and shapes of pika holes. The results showed that: (1) The object-oriented classification exhibits higher classification accuracy in identifying pika holes. (2) The average size of pika holes in the study area is 0.01 m2 and they exhibit clustered distribution patterns. The average distance between any two nearest pika hole patches is 0.79 m. (3) It presents a significant quadratic relationship between the number of pika holes and grass coverage. (4) The average effective distance of pika holes on the surrounding grass coverage is 20 cm. The findings of this study can provide guidelines for pika control and improve grassland management on the TP.}
}
@article{ULLAH2020313,
title = {Applications of Artificial Intelligence and Machine learning in smart cities},
journal = {Computer Communications},
volume = {154},
pages = {313-323},
year = {2020},
issn = {0140-3664},
doi = {https://doi.org/10.1016/j.comcom.2020.02.069},
url = {https://www.sciencedirect.com/science/article/pii/S0140366419320821},
author = {Zaib Ullah and Fadi Al-Turjman and Leonardo Mostarda and Roberto Gagliardi},
keywords = {Smart city, 5G and B5G communication, UAVs, Intelligent Transportation System, Smart grids, Cyber-security, Internet of Things, mmWave communication},
abstract = {Smart cities are aimed to efficiently manage growing urbanization, energy consumption, maintain a green environment, improve the economic and living standards of their citizens, and raise the people’s capabilities to efficiently use and adopt the modern information and communication technology (ICT). In the smart cities concept, ICT is playing a vital role in policy design, decision, implementation, and ultimate productive services. The primary objective of this review is to explore the role of artificial intelligence (AI), machine learning (ML), and deep reinforcement learning (DRL) in the evolution of smart cities. The preceding techniques are efficiently used to design optimal policy regarding various smart city-oriented complex problems. In this survey, we present in-depth details of the applications of the prior techniques in intelligent transportation systems (ITSs), cyber-security, energy-efficient utilization of smart grids (SGs), effective use of unmanned aerial vehicles (UAVs) to assure the best services of 5G and beyond 5G (B5G) communications, and smart health care system in a smart city. Finally, we present various research challenges and future research directions where the aforementioned techniques can play an outstanding role to realize the concept of a smart city.}
}
@article{LONG2021107604,
title = {Deep learning-based planar crack damage evaluation using convolutional neural networks},
journal = {Engineering Fracture Mechanics},
volume = {246},
pages = {107604},
year = {2021},
issn = {0013-7944},
doi = {https://doi.org/10.1016/j.engfracmech.2021.107604},
url = {https://www.sciencedirect.com/science/article/pii/S0013794421000758},
author = {X.Y. Long and S.K. Zhao and C. Jiang and W.P. Li and C.H. Liu},
keywords = {Crack damage evaluation, Deep learning, Computational vision, Deep convolutional neural network, Stress intensity factor},
abstract = {This article presents a novel deep learning-based damage evaluation approach by using speckled images. A deep convolutional neural network (DCNN) for predicting the stress intensity factor (SIF) at the crack tip is designed. Based on the proposed DCNN, the SIF can be automatically predicted through computational vision. The data bank consisting of a reference speckled image and lots of deformed speckled images is prepared by a camera and an MTS testing machine. Experiments were performed to verify the method, and the achieved results are quite remarkable with larger than 96% of predicted SIF values falling within 5% of true SIF values when sufficient training images are available. The results also confirm that the appropriate subset size of images within the field of view is 400 × 400 pixel resolutions.}
}
@article{CORREAMARTINS2021101465,
title = {Machine learning and SLIC for Tree Canopies segmentation in urban areas},
journal = {Ecological Informatics},
volume = {66},
pages = {101465},
year = {2021},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2021.101465},
url = {https://www.sciencedirect.com/science/article/pii/S1574954121002569},
author = {José Augusto {Correa Martins} and Geazy Menezes and Wesley Gonçalves and Diego André Sant’Ana and Lucas Prado Osco and Veraldo Liesenberg and Jonathan Li and Lingfei Ma and Paulo Tarso Oliveira and Gilberto Astolfi and Hemerson Pistori and José Marcato Junior},
keywords = {Urban environment, Machine learning, Remote sensing, Photogrammetry, Computer vision},
abstract = {This paper presents a novel approach combining the Simple Linear Iterative Clustering (SLIC) superpixel algorithm with a Convolutional Neural Network (CNN) over high-resolution imagery to detect trees in a typical urban environment of the Brazilian Cerrado biome. Our analysis approach for better results uses the deep learning classifier ResNet-50, with a variation in the batch size and five traditional shallow learning methods. The results were processed and avaliated using mainly accuracy as a metric, but we show that the accuracy poorly represent the overlap between the manual annotation and the resulting map, so we bring the IoU metric results to better show the Network learning classification maps results. The combined SLIC algorithm and the best CNN resulted in an accuracy of 93.20%, IoU of 0.700 and a variation of 1% for difference in the area of tree canopies if compared to our labels, while the best shallow presented an accuracy of 91.70%, IoU of 0.200 and a variation in area of 12.52%. Demonstrating that the proposed CNN method is suitable for segmenting trees from high-resolution images acquired over urban environments. The segmentation with SLIC and CNN can provide very useful results for urban management using low cost RGB images. Such outcomes are of great interest for local managers since reliable maps showing the spatial distribution of trees in urban areas are often required for many applications.}
}
@article{DUCARD2021107035,
title = {Review of designs and flight control techniques of hybrid and convertible VTOL UAVs},
journal = {Aerospace Science and Technology},
volume = {118},
pages = {107035},
year = {2021},
issn = {1270-9638},
doi = {https://doi.org/10.1016/j.ast.2021.107035},
url = {https://www.sciencedirect.com/science/article/pii/S1270963821005459},
author = {Guillaume J.J. Ducard and Mike Allenspach},
keywords = {VTOL-flight transition control, Hybrid and convertible aircraft, Unmanned aerial vehicles (UAV), Control allocation},
abstract = {This paper provides a broad perspective and analysis of the work done in control of hybrid and convertible unmanned aerial vehicles (UAVs) for the main existing designs. These flying machines are capable of vertical take off and landing (VTOL) in helicopter mode and able to transition to high-speed forward flight in airplane mode and vice versa. This paper aims at helping engineers and researchers develop flight control systems for VTOL UAVs. To this end, a historical perspective first shows the technological advances in VTOL aircraft over the years. The main VTOL concepts and state-of-art flight control methods for VTOL UAVs are presented and discussed. This study shows both the common parts and the fundamental differences in the modeling, guidance, control, and control allocation for each hybrid-VTOL-UAV type. The open challenges and the current trends in the field are highlighted. These are namely: 1) augmenting or replacing classical controllers with data-driven methods such as neural networks and machine-learning-based controllers; 2) incorporating as much knowledge of the vehicle as possible into the flight controller, for example through model predictive control or model-based nonlinear controllers; 3) a trend towards finding a unified-control approach valid in all flight modes without the need to switch among flight controllers or to perform predefined-gain scheduling, and 4) the need to mitigate control complexity and available computing resources.}
}
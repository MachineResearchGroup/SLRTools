@ARTICLE{9615184,
author={Yakkati, Rajesh Reddy and Yakkati, Rakesh Reddy and Tripathy, Rajesh Kumar and Cenkeramaddi, Linga Reddy},
journal={IEEE Sensors Journal}, title={Radio Frequency Spectrum Sensing by Automatic Modulation Classification in Cognitive Radio System Using Multiscale Deep CNN},
year={2022},
volume={22},
number={1},
pages={926-938},
abstract={Automatic modulation categorization (AMC) is used in many applications such as cognitive radio, adaptive communication, electronic reconnaissance, and non-cooperative communications. Predicting the modulation class of an unknown radio signal without having any prior information of the signal parameters is challenging. This paper proposes a novel multiscale deep-learning-based approach for the automatic modulation classification using radio signals. The approach considered the fixed boundary range-based Empirical wavelet transform (FBREWT) based multiscale analysis technique to decompose the radio signal into sub-band signals or modes. The sub-band signals computed from the radio signal combined with the deep convolutional neural network (CNN) are used to classify modulation types. The approach is tested using the radio signals of different signal-to-noise ratio (SNR) values and four different channel types such as additive white Gaussian noise (AWGN) combination of Rayleigh fading and AWGN channels, the combination of Rician flat fading and AWGN channels, and combination of Nakagami-m fading and AWGN channels for AMC. The results show that the proposed FBREWT based deep-learning approach achieves an overall classification accuracy of 97% for AMC using the radio signals with 10dB SNR for the AWGN channel. Moreover, the proposed approach has obtained the accuracy’s as 94.56%, 95%, and 97.33% using radio signals with 10 dB SNR values for Rayleigh fading, Rician flat fading, and Nakagami-m fading channels combined through AWGN link. The comparison of the proposed multiscale deep learning-based approach with existing methods is shown for AMC.},
keywords={Modulation;Signal to noise ratio;Binary phase shift keying;AWGN channels;Rayleigh channels;Convolutional neural networks;Feature extraction;Modulation classification;fixed boundary range;empirical wavelet transform;deep CNN;SNR;accuracy},
doi={10.1109/JSEN.2021.3128395},
ISSN={1558-1748},
month={Jan},}
@INPROCEEDINGS{9327167,
author={Wang, Ning and Wang, Ying and Wang, Xiaolin and Zhou, Chuhan},
booktitle={2020 Chinese Automation Congress (CAC)}, title={A Low-Complexity Control Method with Guaranteed Performance for Nonlinear Large-Scale Non-Triangular Structure Systems},
year={2020},
volume={},
number={},
pages={5397-5401},
abstract={This work focuses on low-complexity prescribed performance control (PPC) for nonlinear large-scale non-triangular- structured dynamics whose system nonlinearities and control gain functions are relaxed to rely on the whole state vector. The peculiarity of this extended class is that the restrictive assumption that the unknown nonlinear functions must satisfy Lipschitz or setting bounding function conditions is removed and only the continuity of nonlinearities is required. A novel low-complexity prescribed performance control method is skillfully incorporated into backstepping technique so as to guarantee closed-loop stability while some transient and steady state performances can be also achieved. Different from the state of the art has focused on the PPC method, neither approximators (neural networks and fuzzy logic systems) nor adaptation technique are employed in the control design which alleviate the computation burden.},
keywords={MIMO communication;Nonlinear dynamical systems;Steady-state;Convergence;Complexity theory;Backstepping;Trajectory;Nontriangular structure;multiple-input and multiple-output (MIMO) nonlinear systems;prescribed performance control},
doi={10.1109/CAC51589.2020.9327167},
ISSN={2688-0938},
month={Nov},}
@INPROCEEDINGS{8923347,
author={Tsuyama, Masahiko and Aoki, Shuhei and Oki, Takuro and Miyamoto, Ryusuke},
booktitle={2018 International Symposium on Intelligent Signal Processing and Communication Systems (ISPACS)}, title={Hardware Implementation of a Classifier Trained with Informed-Filters Using Only Color Features},
year={2018},
volume={},
number={},
pages={319-324},
abstract={We are constructing a novel sensor networking system for real-time sensing human vital signs during exercise in real time using image-assisted routing. Image-assisted routing requires accurate localization of humans wearing sensor nodes using aerial images captured from cameras mounted on UAVs. To detect humans in aerial images in real time, we propose a hardware implementation of a classifier constructed with informed-filters using only color features that shows a higher accuracy than deep learning for sports scenes. Experimental results showed that the detection accuracy of the classifier did not become worse when we only applied fixed-point operations. The proposed hardware also requires a few computation resources in an FPGA though a large amount of memory was required. The processing time for an image whose size was 2560 ×1352 was about 36ms, demonstrating that our hardware can achieve very fast computation on an FPGA.},
keywords={Image color analysis;Hardware;Feature extraction;Real-time systems;Machine learning;Routing},
doi={10.1109/ISPACS.2018.8923347},
ISSN={2642-3529},
month={Nov},}
@ARTICLE{8916645,
author={Jiang, Zhi and Yang, Tingting and Zhou, Lin and Yuan, Yuqing and Feng, Hailong},
journal={Journal of Communications and Information Networks}, title={Maritime Search and Rescue Networking Based on Multi-Agent Cooperative Communication},
year={2019},
volume={4},
number={1},
pages={42-53},
abstract={Rapid and effective maritime search and rescue operations become the important guarantee for the safety of maritime navigation. The existing maritime search and rescue networking and model have slow response speed and low efficiency. The distribution, synergy, parallelism, robustness and intelligence of unmanned surface vehicle (USV) and unmanned aerial vehicle (UAV) provide a new idea for the novel maritime search and rescue networking, in which multi-agent could be used to build a layered control network. In this paper, a novel rapid search and rescue system is proposed by utilizing the improved ant colony optimization and the independent calculation decision of the agents. The system adopts the edge computing, relies on the information sharing and the cooperative decision between the search and rescue agent groups. It achieves the independent synchronous search and rescue. At the same time, we use particle swarm optimization to intelligently schedule data packets during the rescue process to optimize network forwarding performance. Based on the distributed cluster control of USV and UAV, this paper combines edge computing, cooperative communication and centralized task allocation together to make decision for rescue. The simulation results show that our proposed schemes realize a significant improvement for maritime search and rescue.},
keywords={Marine vehicles;Task analysis;Edge computing;Unmanned aerial vehicles;Accidents;Satellites;Base stations;edge computing;cooperative communication;swarm intelligence;search and rescue},
doi={10.23919/JCIN.2019.8916645},
ISSN={2509-3312},
month={March},}
@INPROCEEDINGS{9342179,
author={Ippalapally, Rohan and Mudumba, Sri Harsha and Adkay, Meghana and R., Nandi Vardhan H.},
booktitle={2020 IEEE 17th India Council International Conference (INDICON)}, title={Object Detection Using Thermal Imaging},
year={2020},
volume={},
number={},
pages={1-6},
abstract={Identification of objects in an image plays a crucial role in UAVs, self-autonomous vehicles, and other applications. It is vital to have the capability to navigate and identify objects at any time of the day, especially at night, when we encounter situations of low-light and dark conditions. This necessitates the ability to have a proper object detection model to predict the object in these conditions. We introduce a way to detect and classify objects in images taken with thermal cameras using different image processing techniques, pattern recognition, and machine learning algorithms. We have done a comparative study of two different models with appropriate hyper-parameter tuning that allows us to choose the right model for their application based on the constraints involved in the problem. We present an extensive study of the models based on the COCO evaluation metrics and other important loss metrics. Experimental results on the FLIR dataset confirm that we can use the pre-trained models in object detection to train, identify, and label objects in thermal images.},
keywords={Measurement;Analytical models;Object detection;Predictive models;Pattern recognition;Object recognition;Tuning;Object Detection;Machine Learning;Image Processing;Convolutional Neural Networks},
doi={10.1109/INDICON49873.2020.9342179},
ISSN={2325-9418},
month={Dec},}
@ARTICLE{8264734,
author={Loquercio, Antonio and Maqueda, Ana I. and del-Blanco, Carlos R. and Scaramuzza, Davide},
journal={IEEE Robotics and Automation Letters}, title={DroNet: Learning to Fly by Driving},
year={2018},
volume={3},
number={2},
pages={1088-1095},
abstract={Civilian drones are soon expected to be used in a wide variety of tasks, such as aerial surveillance, delivery, or monitoring of existing architectures. Nevertheless, their deployment in urban environments has so far been limited. Indeed, in unstructured and highly dynamic scenarios, drones face numerous challenges to navigate autonomously in a feasible and safe way. In contrast to traditional “map-localize-plan” methods, this letter explores a data-driven approach to cope with the above challenges. To accomplish this, we propose DroNet: a convolutional neural network that can safely drive a drone through the streets of a city. Designed as a fast eight-layers residual network, DroNet produces two outputs for each single input image: A steering angle to keep the drone navigating while avoiding obstacles, and a collision probability to let the UAV recognize dangerous situations and promptly react to them. The challenge is however to collect enough data in an unstructured outdoor environment such as a city. Clearly, having an expert pilot providing training trajectories is not an option given the large amount of data required and, above all, the risk that it involves for other vehicles or pedestrians moving in the streets. Therefore, we propose to train a UAV from data collected by cars and bicycles, which, already integrated into the urban environment, would not endanger other vehicles and pedestrians. Although trained on city streets from the viewpoint of urban vehicles, the navigation policy learned by DroNet is highly generalizable. Indeed, it allows a UAV to successfully fly at relative high altitudes and even in indoor environments, such as parking lots and corridors. To share our findings with the robotics community, we publicly release all our datasets, code, and trained networks.},
keywords={Drones;Navigation;Urban areas;Robots;Training;Automobiles;Learning from demonstration;deep learning in robotics and automation;aerial systems: perception and autonomy},
doi={10.1109/LRA.2018.2795643},
ISSN={2377-3766},
month={April},}
@INPROCEEDINGS{8453459,
author={Darrah, Marjorie and Rubenstein, Alex and Sorton, Eric and DeRoos, Brad},
booktitle={2018 International Conference on Unmanned Aircraft Systems (ICUAS)}, title={On-board Health-state Awareness to Detect Degradation in Multirotor Systems},
year={2018},
volume={},
number={},
pages={1134-1141},
abstract={This paper presents the development and demonstration of an on-board health-state awareness technology that can predict degradation over the dynamic operational life of the vehicle. We established the feasibility of replacing the standard electronic speed control on a small UAV with an Intelligent Electronic Speed Control (IESC) that uses the telemetry data from sensors to develop an intelligent rule set extracted from a trained artificial neural network to detect propulsion system degradation, predict specific types of failures by analyzing sensor data collected from the motor and ESC, and access life cycle characteristics for a UAV propulsion system. The IESC will improve performance and reliability, increase safety and decrease maintenance costs by detecting issues prior to flight. The long term goal of the project is to be able to predict failures across families of small UAV based upon historic performance data that can be shared among users.},
keywords={Sensors;Batteries;Biological neural networks;Microcontrollers;Telemetry;Temperature measurement;Unmanned aerial vehicles;Unmanned Aerial System;health monitoring;electronic speed control;neural network;multirotor},
doi={10.1109/ICUAS.2018.8453459},
ISSN={2575-7296},
month={June},}
@ARTICLE{9123345,
author={Rajagopal, Aghila and Ramachandran, A. and Shankar, K. and Khari, Manju and Jha, Sudan and Lee, Yongju and Joshi, Gyanendra Prasad},
journal={IEEE Access}, title={Fine-Tuned Residual Network-Based Features With Latent Variable Support Vector Machine-Based Optimal Scene Classification Model for Unmanned Aerial Vehicles},
year={2020},
volume={8},
number={},
pages={118396-118404},
abstract={In recent days, unmanned aerial vehicles (UAVs) becomes more familiar because of its versatility, automation abilities, and low cost. Dynamic scene classification gained significant interest among the UAV-based surveillance systems, e.g., high-voltage power line and forest fire monitoring, which facilitate the object detection, tracking process and drastically enhances the outcome of visual surveillance. This paper proposes a new optimal deep learning-based scene classification model captured by UAVs. The proposed model involves a residual network-based features extraction (RNBFE) which extracts features from the diverse convolution layers of a deep residual network. In addition, the several parameters in RNBFE lead to many configuration errors due to manual parameter tuning. So, self-adaptive global best harmony search (SGHS) algorithm is employed for tuning the parameters of the RNBFE. The resultant feature vectors undergo classification by the use of latent variable support vector machine (LVSVM) model. The presented optimal RNBFE (ORNBFE) model has been tested using two open access datasets namely UC Merced (UCM) Land Use Dataset and WHU-RS Dataset. The presented technique attains maximum scene classification accuracy over the other recently proposed methods.},
keywords={Feature extraction;Unmanned aerial vehicles;Training;Computational modeling;Support vector machines;Visualization;Image analysis;CNN;Harmony Search;LVSVM;residual network-based features extraction;RNBFE;scene classification;unmanned aerial vehicles},
doi={10.1109/ACCESS.2020.3004233},
ISSN={2169-3536},
month={},}
@INPROCEEDINGS{9096259,
author={Srigrarom, Sutthiphong and Lee, Shawndy Michael and Lee, Mengda and Shaohui, Foong and Ratsamee, Photchara},
booktitle={2020 5th International Conference on Control and Robotics Engineering (ICCRE)}, title={An Integrated Vision-based Detection-tracking-estimation System for Dynamic Localization of Small Aerial Vehicles},
year={2020},
volume={},
number={},
pages={152-158},
abstract={A unified detection-tracking-estimation vision navigation system and algorithms framework for position and pose estimation of small aerial vehicle (UAV) is proposed in conjunction with our recent 3D dynamic localization technique. The major contribution of this work is a novel combination of deep learning for detection of moving object as the small UAV, follow by the vision tracking and estimation of the spatial location in global frame. The system can be multiplied and that the extended systems would provide 3D coordinates of the UAV. The demonstrations in both indoor and outdoor were conducted and that the system was able to detect and locate the small aerial vehicle in 3D space.},
keywords={Cameras;Drones;Three-dimensional displays;Optical imaging;Two dimensional displays;Adaptive optics;Vehicle dynamics;dynamic detection;localization and tracking;small and fast moving object;multiple camera},
doi={10.1109/ICCRE49379.2020.9096259},
ISSN={},
month={April},}
@ARTICLE{9248998,
author={Li, Xianghui and Li, Xinde and Pan, Hong},
journal={IEEE Access}, title={Multi-Scale Vehicle Detection in High-Resolution Aerial Images With Context Information},
year={2020},
volume={8},
number={},
pages={208643-208657},
abstract={Recently, unmanned aerial vehicles (UAV) are widely used in many fields due to the low cost and high flexibility. One of the most popular applications of UAV is vehicle detection in aerial images which plays an important role in traffic surveillance and urban planning. Although, many deep learning based detectors have achieved state-of-the-art (SOTA) performance in natural images, the significant variation in object scales caused by the altitude change of the UAV platform brings great challenges to these detectors for precise localization of vehicles in aerial images. To improve the detection performance for vehicles with different scales, we propose a novel detection algorithm which consists of three stages. In the first stage, to reduce the distortion of vehicles during image resizing and keep more information of aerial images, we utilize an image cropping strategy to divide the image into two patches. In the second stage, we combine the original image and two patches into a batch and detect vehicles with a Convolutional Neural Network (CNN). For feature representation in our detector, we propose Scale-specific Prediction to strengthen the multi-scale features of vehicles with context information. In the final stage, to fuse detections and suppress false alarms, we propose an Outlier-Aware Non-Maximum Suppression. Extensive experiments are conducted to demonstrate the superiority of the proposed algorithm by comparison with other SOTA solutions.},
keywords={Fuses;Vehicle detection;Urban planning;Detectors;Traffic control;Feature extraction;Unmanned aerial vehicles;Vehicle detection;scale-specific prediction;single shot detector;high-resolution aerial images},
doi={10.1109/ACCESS.2020.3036075},
ISSN={2169-3536},
month={},}
@INPROCEEDINGS{8269562,
author={Padilla, Mark Lester F. and Lao, Selwyn Jenson C. and Baldovino, Renann G. and Bandala, Argel A. and Dadios, Elmer B.},
booktitle={2017IEEE 9th International Conference on Humanoid, Nanotechnology, Information Technology, Communication and Control, Environment and Management (HNICEM)}, title={Fuzzy-based fault-tolerant control of Micro Aerial Vehicles (MAV) — A preliminary study},
year={2017},
volume={},
number={},
pages={1-4},
abstract={Unmanned Aerial Vehicles (UAV) has gained popularity in the past decades. This has been widely used throughout the world in the fields of military, surveillance, agriculture, and construction. One of the main problems in Micro Aerial Vehicles (MAV), typically smaller version of UAV, is its ability to detect and tolerate faults inside the system. In this paper, a Fault-Tolerant Control (FTC) will be developed using fuzzy logic and uses battery percentage and degree of ability to hover as the crisp inputs. The fuzzy logic will use five and three membership functions for the Battery Percentage and Degree of Ability to Hover respectively. The output of the controller will be the degree of ability to continue a certain mission. Further studies can include other constraints such as mapping efficiency where neural networks and deep learning can be associated. Thus, making a hybrid system.},
keywords={Fault tolerant systems;Fault tolerance;Fuzzy logic;Unmanned aerial vehicles;Batteries;Rotors;Control systems;Fuzzy Logic Control;Fault-Tolerant Control;Micro Aerial Vehicles},
doi={10.1109/HNICEM.2017.8269562},
ISSN={},
month={Dec},}
@ARTICLE{8207610,
author={Zhang, Bo and Liu, Chi Harold and Tang, Jian and Xu, Zhiyuan and Ma, Jian and Wang, Wendong},
journal={IEEE Transactions on Industrial Informatics}, title={Learning-Based Energy-Efficient Data Collection by Unmanned Vehicles in Smart Cities},
year={2018},
volume={14},
number={4},
pages={1666-1676},
abstract={Mobile crowdsourcing (MCS) is now an important source of information for smart cities, especially with the help of unmanned aerial vehicles (UAVs) and driverless cars. They are equipped with different kinds of high-precision sensors, and can be scheduled/controlled completely during data collection, which will make MCS system more robust. However, they are limited to energy constraint, especially for long-term, long-distance sensing tasks, and cities are almost too crowded to set stationary charging station. Towards this end, in this paper we propose to leverage emerging deep reinforcement learning (DRL) techniques for enabling model-free unmanned vehicles control, and present a novel and highly effective control framework, called “DRL-RVC.” It utilizes the powerful convolutional neural network for feature extraction of the necessary information (including sample distribution, traffic flow, etc.), then makes decisions under the guidance of the deep Q network. That is, UAVs will cruise in the city without control and collect most required data in the sensing region, while mobile unmanned charging station will reach the charging point in the shortest possible time. Finally, we validate and evaluate the proposed framework via extensive simulations based on a real dataset in Rome. Extensive simulation results well justify the effectiveness and robustness of our approach.},
keywords={Sensors;Charging stations;Mobile communication;Data collection;Unmanned vehicles;Urban areas;Data crowdsourcing;energy-efficiency;smart city},
doi={10.1109/TII.2017.2783439},
ISSN={1941-0050},
month={April},}
@ARTICLE{9369386,
author={Sambolek, Sasa and Ivasic-Kos, Marina},
journal={IEEE Access}, title={Automatic Person Detection in Search and Rescue Operations Using Deep CNN Detectors},
year={2021},
volume={9},
number={},
pages={37905-37922},
abstract={Due to a growing number of people who carry out various adrenaline activities or adventure tourism and stay in the mountains and other inaccessible places, there is an increasing need to organize a search and rescue operation (SAR) to provide assistance and health care to the injured. The goal of SAR operation is to search the largest area of the territory in the shortest time possible and find a lost or injured person. Today, drones (UAVs or drones) are increasingly involved in search operations, as they can capture a large, controlled area in a short amount of time. However, a detailed examination of a large amount of recorded material remains a problem. Even for an expert, it is not easy to find searched people who are relatively small considering the area where they are, often sheltered by vegetation or merged with the ground and in unusual positions due to falls, injuries, or exhaustion. Therefore, the automatic detection of persons and objects in images/videos taken by drones in these operations is very significant. In this paper, the reliability of existing state-of-the-art detectors such as Faster R-CNN, YOLOv4, RetinaNet, and Cascade R-CNN on a VisDrone benchmark and custom-made dataset SARD build to simulate rescue scenes was investigated. After training the models on selected datasets, detection results were compared. Because of the high speed and accuracy and the small number of false detections, the YOLOv4 detector was chosen for further examination. YOLOv4 model results related to different network sizes, different detection accuracies, and transfer learning settings were analyzed. The model robustness to weather conditions and motion blur were also investigated. The paper proposes a model that can be used in SAR operations because of the excellent results in detecting people in search and rescue scenarios.},
keywords={Drones;Detectors;Search problems;Data models;Injuries;Feature extraction;Vegetation mapping;Convolutional neural networks;object detector;person detection;search and rescue operations;UAV;YOLO},
doi={10.1109/ACCESS.2021.3063681},
ISSN={2169-3536},
month={},}
@INPROCEEDINGS{9204228,
author={Dong, Liping and Meng, Zhaohui},
booktitle={2020 12th International Conference on Intelligent Human-Machine Systems and Cybernetics (IHMSC)}, title={Symmetric prior aerial object detection based on improved YOLOv3},
year={2020},
volume={1},
number={},
pages={35-39},
abstract={Recently, the research of aerial images, images and videos taken by UAV(unmanned aerial vehicles) have developed rapidly. People use these images to get useful information. For example, investigate the density of vehicles, analyze the development of urban suburbs. Symmetry as one of the important features of objects, has long been a research hot area in computer vision. Symmetry detection aims to extract symmetric information from given objects. Aerial images and unmanned images have their special view angle. The symmetrical characteristics of industrial design leads to the special nature of the image from the top view angle. It shows more symmetry of the object more. The objects always like airplanes, ships, automobiles or industrial products like oil drums and chimneys. An aerial object detection method based on improved YOLOv3 algorithm is proposed in this paper. First, a symmetry prior is introduced into the proposed network based on the properties of symmetry patterns. For new convolutional layer, symmetric constrains are added during the process of kernel weights update. The symmetric kernels help the proposed network to find the corresponding symmetry objects. In addition, this paper uses k-means to calculate the size of anchors in order to make the size more suitable for the size of the aerial image object. Compared with the original YOLOv3 algorithm, the improved YOLOv3 algorithm can effectively solve the missing detection of symmetry objects and improve the confidence of detection.},
keywords={Convolution;Feature extraction;Kernel;Object detection;Data mining;Machine learning;Training;component;object detection;aerial image;deep learning;YOLOv3;symmetry detection},
doi={10.1109/IHMSC49165.2020.00016},
ISSN={},
month={Aug},}
@INPROCEEDINGS{7402558,
author={Bai, He and Cook, Kevin and Yu, Huili and Ingersoll, Kyle and Beard, Randy and Seppi, Kevin and Avadhanam, Sharath},
booktitle={2015 54th IEEE Conference on Decision and Control (CDC)}, title={Improving cooperative tracking of an urban target with target motion model learning},
year={2015},
volume={},
number={},
pages={2347-2352},
abstract={Tracking a ground urban target with multiple unmanned aerial vehicles (UAVs) is a challenging problem due to cluttered urban environments and coordination of nonholonomic UAV motion. Our previous work has demonstrated in simulation that machine learning can be used in such an environment to learn a model of target motion and thereby improve tracking performance. We extend this previous work by creating a more realistic simulation using road network and building height data extracted from downtown San Diego. We demonstrate effectiveness of target motion model learning in the new simulation environment. Additionally, we demonstrate performance improvement by extending the algorithm used to coordinate the UAVs for tracking the urban target.},
keywords={Target tracking;Path planning;Predictive models;Cities and towns;Buildings;Optimization},
doi={10.1109/CDC.2015.7402558},
ISSN={},
month={Dec},}
@INPROCEEDINGS{5747529,
author={de Croon, G.C.H.E. and De Wagter, C. and Remes, B.D.W. and Ruijsink, R.},
booktitle={2011 Aerospace Conference}, title={Sky Segmentation Approach to obstacle avoidance},
year={2011},
volume={},
number={},
pages={1-16},
abstract={The capability to visually discern possible obstacles from the sky would be a valuable asset to a UAV for avoiding both other flying vehicles and static obstacles in its environment. The main contribution of this article is the presentation of a feasible approach to obstacle avoidance based on the segmentation of camera images into sky and non-sky regions. The approach is named the Sky Segmentation Approach (SSA). The central concept is that potentially threatening static obstacles protrude from the horizon line. The main challenge for SSA is automatically interpreting the images robustly enough for use in various environments and fast enough for real-time performance. In order to achieve robust image segmentation, machine learning is applied to a large database of images with many different types of skies. From these images, different types of visual features are extracted, among which most of the features investigated in the literature. In the interest of execution speed and comprehensibility, decision trees are learned to map the feature values at an image location to a classification as sky or non-sky. The learned decision trees are fast enough to allow real-time execution on a Digital Signal Processor: it is run onboard a small UAV at ~ 30 Hz. Experiments in simulation and preliminary experiments on a small UAV show the potential of SSA for achieving robust obstacle avoidance in urban areas.},
keywords={Image segmentation;Feature extraction;Pixel;Cameras;Databases;Decision trees;Training},
doi={10.1109/AERO.2011.5747529},
ISSN={1095-323X},
month={March},}
@ARTICLE{9646496,
author={Akram, Muhammad Wahid and Bashir, Ali Kashif and Shamshad, Salman and Saleem, Muhammad Asad and AlZubi, Ahmad Ali and Chaudhry, Shehzad Ashraf and Alzahrani, Bander A. and Zikria, Yousaf Bin},
journal={IEEE Transactions on Intelligent Transportation Systems}, title={A Secure and Lightweight Drones-Access Protocol for Smart City Surveillance},
year={2021},
volume={},
number={},
pages={1-10},
abstract={The rising popularity of ICT and the Internet has enabled Unmanned Aerial Vehicle (UAV) to offer advantageous assistance to Vehicular Ad-hoc Network (VANET), realizing a relay node's role among the disconnected segments in the road. In this scenario, the communication is done between Vehicles to UAVs (V2U), subsequently transforming into a UAV-assisted VANET. UAV-assisted VANET allows users to access real-time data, especially the monitoring data in smart cities using current mobile networks. Nevertheless, due to the open nature of communication infrastructure, the high mobility of vehicles along with the security and privacy constraints are the significant concerns of UAV-assisted VANET. In these scenarios, Deep Learning Algorithms (DLA) could play an effective role in the security, privacy, and routing issues of UAV-assisted VANET. Keeping this in mind, we have devised a DLA-based key-exchange protocol for UAV-assisted VANET. The proposed protocol extends the scalability and uses secure bitwise XOR operations, one-way hash functions, including user's biometric verification when users and drones are mutually authenticated. The proposed protocol can resist many well-known security attacks and provides formal and informal security under the Random Oracle Model (ROM). The security comparison shows that the proposed protocol outperforms the security performance in terms of running time cost and communication cost and has effective security features compared to other related protocols.},
keywords={Protocols;Security;Drones;Cryptography;Authentication;Vehicular ad hoc networks;Privacy;Authentication protocol;Internet of Drones;VANET;intelligent transportation systems;mutual authentication;information security.},
doi={10.1109/TITS.2021.3129913},
ISSN={1558-0016},
month={},}
@INPROCEEDINGS{8784844,
author={Al-Mahasneh, Ahmad Jobran and Anavatti, Sreenatha G and Ferdaus, Meftahul and Garratt, Matthew A},
booktitle={2019 IEEE International Conference on Industry 4.0, Artificial Intelligence, and Communications Technology (IAICT)}, title={Adaptive Neural Altitude Control and Attitude Stabilization of a Hexacopter with Uncertain Dynamics},
year={2019},
volume={},
number={},
pages={44-49},
abstract={Unmanned Aerial Vehicles (UAVs) are recently attracting significant research attention due to their potential applications in many fields. Hexacopter UAV offers higher payloads handling and faults tolerance than a quadcopter but its control is a demanding task. In this paper, an adaptive Neural Networks (NN) controller is proposed for altitude tracking and attitude stabilization of a hexacopter UAV with uncertain dynamics. The controller design, simulation and robustness against gust disturbances are discussed. Also, the controller performance is compared with a standard Filtered-Proportional-Derivative-Integrator (FPID) controller for different control scenarios.},
keywords={Uncertainty;Attitude control;Aerodynamics;Conferences;Industries;Artificial intelligence;Communications technology;Adaptive control;Hexacopter;altitude control;neural control;unmanned aerial vehicles},
doi={10.1109/ICIAICT.2019.8784844},
ISSN={},
month={July},}
@ARTICLE{9490639,
author={Hernández, Daniel and Cano, Juan-Carlos and Silla, Federico and Calafate, Carlos T. and Cecilia, José M.},
journal={IEEE Internet of Things Journal}, title={AI-enabled autonomous drones for fast climate change crisis assessment},
year={2021},
volume={},
number={},
pages={1-1},
abstract={Climate change is one of the greatest challenges for modern societies. Its consequences, often associated with extreme events, have dramatic results worldwide. New synergies between different disciplines including Artificial Intelligence (AI), Internet of Things (IoT), and edge computing can lead to radically new approaches for the real-time tracking of natural disasters that are also designed to reduce the environmental footprint. In this article, we propose an AI-based pipeline for processing natural disaster images taken from drones. The purpose of this pipeline is to reduce the number of images to be processed by the first responders of the natural disaster. It consists of three main stages, (1) a lightweight auto-encoder based on deep learning, (2) a dimensionality reduction using the t-SNE algorithm and (3) a fuzzy clustering procedure. This pipeline is evaluated on several edge computing platforms with low-power accelerators to assess the design of intelligent autonomous drones to provide this service in real time. Our experimental evaluation focuses on flooding, showing that the amount of information to be processed is substantially reduced whereas edge computing platforms with low-power GPUs are placed as a compelling alternative for processing these heavy computational workloads, obtaining a performance loss of only 2.3x compared to its cloud counterpart version, running both the training and inference steps.},
keywords={Internet of Things;Clustering algorithms;Cloud computing;Edge computing;Pipelines;Performance evaluation;Drones;Climate Change;UAVs;Deep Learning;Edge computing;Artificial Vision;Sustainable ICT.},
doi={10.1109/JIOT.2021.3098379},
ISSN={2327-4662},
month={},}
@ARTICLE{9488323,
author={Hassija, Vikas and Chamola, Vinay and Agrawal, Adhar and Goyal, Adit and Luong, Nguyen Cong and Niyato, Dusit and Yu, Fei Richard and Guizani, Mohsen},
journal={IEEE Communications Surveys Tutorials}, title={Fast, Reliable, and Secure Drone Communication: A Comprehensive Survey},
year={2021},
volume={23},
number={4},
pages={2802-2832},
abstract={Drone security is currently a major topic of discussion among researchers and industrialists. Although there are multiple applications of drones, if the security challenges are not anticipated and required architectural changes are not made, the upcoming drone applications will not be able to serve their actual purpose. Therefore, in this paper, we present a detailed review of the security-critical drone applications, and security-related challenges in drone communication such as DoS attacks, Man-in-the-middle attacks, De-Authentication attacks, and so on. Furthermore, as part of solution architectures, the use of Blockchain, Software Defined Networks (SDN), Machine Learning, and Fog/Edge computing are discussed as these are the most emerging technologies. Drones are highly resource-constrained devices and therefore it is not possible to deploy heavy security algorithms on board. Blockchain can be used to cryptographically store all the data that is sent to/from the drones, thereby saving it from tampering and eavesdropping. Various ML algorithms can be used to detect malicious drones in the network and to detect safe routes. Additionally, the SDN technology can be used to make the drone network reliable by allowing the controller to keep a close check on data traffic, and fog computing can be used to keep the computation capabilities closer to the drones without overloading them.},
keywords={Drones;Security;Privacy;Ad hoc networks;Tutorials;Encryption;Computer science;Blockchain;drone applications;drone security;fog computing;machine learning;software defined networks;UAV},
doi={10.1109/COMST.2021.3097916},
ISSN={1553-877X},
month={Fourthquarter},}
@INPROCEEDINGS{8926635,
author={Menshchikov, A. and Ermilov, D. and Dranitsky, I. and Kupchenko, L. and Panov, M. and Fedorov, M. and Somov, A.},
booktitle={IECON 2019 - 45th Annual Conference of the IEEE Industrial Electronics Society}, title={Data-Driven Body-Machine Interface for Drone Intuitive Control through Voice and Gestures},
year={2019},
volume={1},
number={},
pages={5602-5609},
abstract={Aerial drones can be used for a number of monitoring and control applications. Most of existing drone control platforms are quite primitive in terms of body-machine interface. They are usually a variation of a hand-held remote controller or ground control station. However, in a number of line-of-sight scenarios it would be more convenient to use the human gestures and voice for the drone control. In this work, we present an approach for instantaneous control of drones based on human voice and gestures. The proposed solution includes wearable sensors and embedded artificial intelligence. We use a microphone and an Inertial Measurement Unit (IMU) for capturing the human voice and the hand movements. Primary control is implemented by a voice recognition unit based on Recurrent Neural Network (RNN) while the secondary control is implemented by the gesture recognition system based on Convolutional Neural Network (CNN). For implementing the embedded intelligence, we use a low-power embedded system with a graphical processing unit able to run pre-trained neural networks on board of the drone. As a result, the system can perform different speech and gesture recognition tasks real-time.},
keywords={Drones;Artificial intelligence;Wireless communication;Graphics processing units;Microphones;Body-Machine Interface;Wearable Devices;Embedded Systems;Machine Learning;UAV;Teleoperation},
doi={10.1109/IECON.2019.8926635},
ISSN={2577-1647},
month={Oct},}
@ARTICLE{9530616,
author={Yang, Ning and Zhang, Bangning and Ding, Guoru and Wei, Yimin and Wei, Guofeng and Wang, Jian and Guo, Daoxing},
journal={IEEE Communications Letters}, title={Specific Emitter Identification with Limited Samples: A Model-Agnostic Meta-Learning Approach},
year={2021},
volume={},
number={},
pages={1-1},
abstract={It is necessary but difficult to obtain a large number of labeled samples to train the classification model in many real scenes. This letter proposes an approach for specific emitter identification(SEI) by introducing model-agnostic meta-learning, which can achieve high accuracy in the case of a limited number of labeled training samples. Specially, we improve the approach to make it suitable for the classification of electromagnetic signals of multiple types of equipments, without spending a lot of time and data to retrain the model structure. The data collected from ZigBee devices and UAVs are used to verify the proposed approach. The simulation results shows that the accuracy of proposed approach can reach more than 90% even though the training task and testing task are two types of devices.},
keywords={Zigbee;Training;Task analysis;Deep learning;Data models;Convolution;Adaptation models;Specific emitter identification;model-agnostic meta-learning;limited samples},
doi={10.1109/LCOMM.2021.3110775},
ISSN={1558-2558},
month={},}
@ARTICLE{9507513,
author={Munir, Arslan and Kwon, Jisu and Lee, Jong Hun and Kong, Joonho and Blasch, Erik and Aved, Alexander J. and Muhammad, Khan},
journal={IEEE Access}, title={FogSurv: A Fog-Assisted Architecture for Urban Surveillance Using Artificial Intelligence and Data Fusion},
year={2021},
volume={9},
number={},
pages={111938-111959},
abstract={Urban surveillance, of which airborne urban surveillance is a vital constituent, provides situational awareness (SA) and timely response to emergencies. The significance and scope of urban surveillance has increased manyfold in recent years due to the proliferation of unmanned aerial vehicles (UAVs), Internet of things (IoTs), and multitude of sensors. In this article, we propose FogSurv—a fog-assisted surveillance architecture and framework leveraging artificial intelligence (AI) and information/data fusion for enabling real-time SA and monitoring. We also propose an AI- and data-driven information fusion model for FogSurv to help provide (near) real-time SA, threat assessment, and automated decision-making. We further present a latency model for AI and information fusion processing in FogSurv. We then discuss several use cases of FogSurv that can have a huge impact on multifarious fronts of national significance ranging from safeguarding national security to monitoring of critical infrastructures. We conduct an extensive set of experiments to demonstrate that FogSurv using AI and data fusion help provide near real-time inferences and SA. Experimental results demonstrate that FogSurv provides a latency improvement of 37% on average over cloud architectures for the selected benchmarks. Results further indicate that combining AI with data fusion as in FogSurv can provide a speedup of up to $9.8\times $ over AI without data fusion while also maintaining or improving the inference accuracy. Additionally, results show that AI combined with fusion of different image modalities obtained through UAVs in FogSurv results in improved average precision of target detection for surveillance as compared to AI without data fusion for different target scales and environment complexity.},
keywords={Surveillance;Artificial intelligence;Computer architecture;Cloud computing;Data integration;Real-time systems;Peer-to-peer computing;Urban surveillance;situational awareness;fog computing;unmanned aerial vehicles;information fusion;artificial intelligence;deep neural networks},
doi={10.1109/ACCESS.2021.3102598},
ISSN={2169-3536},
month={},}
@INPROCEEDINGS{8485874,
author={Sandino, Juan and Gonzalez, Felipe},
booktitle={2018 23rd International Conference on Methods Models in Automation Robotics (MMAR)}, title={A Novel Approach for Invasive Weeds and Vegetation Surveys Using UAS and Artificial Intelligence},
year={2018},
volume={},
number={},
pages={515-520},
abstract={Surveillance tasks of weeds and vegetation in arid lands is a complex, difficult and time-consuming task. In this article we present a framework to detect and map invasive grasses, combining UAVs and high-resolution RGB technologies and machine learning for data processing. This approach is illustrated by segmenting Buffel Grass (Cenchrus ciliaris) and Spinifex (Triodia sp.), Segmentation results produced individual detection rates of 97% for buffel grass, 96% for spinifex and 97% for the overall classification task. The algorithm is robust against variations in illumination, occlusion, object rotation and density of vegetation.},
keywords={Vegetation mapping;Image color analysis;Soil;Sensors;Training;Mathematical model;Two dimensional displays;biosecurity;Cenchrus ciliaris;drones;remote sensing;Triodia sp;UAV;vegetation assessments;weeds},
doi={10.1109/MMAR.2018.8485874},
ISSN={},
month={Aug},}
@INPROCEEDINGS{8833919,
author={Chen, Jie and Chen, Zhuangzhuang and Fang, Min and Li, Jianqiang and Ming, Zhong and Wang, Shulan},
booktitle={2019 IEEE 4th International Conference on Advanced Robotics and Mechatronics (ICARM)}, title={A GAN-based Active Terrain Mapping for Collaborative Air-Ground Robotic System},
year={2019},
volume={},
number={},
pages={622-627},
abstract={Collaborative air-ground robotic system has recently emerged as an important research area and shown great potential in many practical applications of smart cities. This work aims to use such system to transform the aerial images from UAVs into terrain map exploited by UGVs to perform ground path planning or navigation tasks. We propose a novel GAN-based active terrain mapping (GAN-ATM) algorithm which integrates Active Learning (AL) strategy into Generative Adversarial Network (GAN) framework to build the terrain map efficiently with a very limited number of labeled data. The empirical results show that the proposed algorithm achieves the highest predictive accuracy of 90.35%. Due to a more accurate terrain map, the UAV using GAN-ATM can plan the shortest trajectory among all existing counterparts.},
keywords={Robots;Terrain mapping;Generative adversarial networks;Training;Collaboration;Path planning;Prediction algorithms;Collaborative Air-Ground Robotic System;Convolutional Neural Networks (CNN);Generative Adversarial Networks (GAN);Active Learning},
doi={10.1109/ICARM.2019.8833919},
ISSN={},
month={July},}
@INPROCEEDINGS{9587621,
author={Akshatha, K R and Biswas, Subhrajyoti and Karunakar, A K and Satish Shenoy, B},
booktitle={2021 2nd Global Conference for Advancement in Technology (GCAT)}, title={Anchored versus Anchorless Detector for Car Detection in Aerial Imagery},
year={2021},
volume={},
number={},
pages={1-6},
abstract={With the increase in the traffic on roadways, traffic monitoring is the major need we have at this moment. Using UAVs for traffic monitoring has numerous advantages such as broader field of view, higher mobility, no effect on detected traffic, etc., however, variation in camera orientation, UAV height, cluttered background imposes challenges to this aerial object detection. To provide a UAV-based traffic monitoring solution, we have proposed a car detection system for UAV images using deep learning approaches. We compared the performance of the anchorless Fully Convolutional One Stage (FCOS) object detection algorithm with the popular YOLOv3 algorithm. The performance analysis of these models based on mean Average Precision (mAP) indicates that FCOS yields better results over YOLOv3, whereas in terms of computation speed YOLOv3 performed better.},
keywords={Deep learning;Vehicle detection;Surveillance;Object detection;Detectors;Traffic control;Real-time systems;Object Detection;aerial images;FCOS;YOLOv3;car detection},
doi={10.1109/GCAT52182.2021.9587621},
ISSN={},
month={Oct},}
@INPROCEEDINGS{7991409,
author={Hasanzade, Mehmet and Herekoglu, Omer and Ure, N. Kemal and Koyuncu, Emre and Yeniceri, Ramazan and Inalhan, Gokhan},
booktitle={2017 International Conference on Unmanned Aircraft Systems (ICUAS)}, title={Localization and tracking of RF emitting targets with multiple unmanned aerial vehicles in large scale environments with uncertain transmitter power},
year={2017},
volume={},
number={},
pages={1058-1065},
abstract={In this paper we study the localization and tracking of a radio frequency (RF) emitting target using multiple unmanned aerial vehicles (UAVs) over a large scale environment. Although localization of RF emitting targets using multiple measurements is a well studied problem, the standard approaches become inefficient when the signal power is uncertain and there is significant noise in the received signal strength (RSS) when the search environment is large scale. We present a localization and tracking architecture, where a data driven neural network model is used for estimating the unknown signal strength and extended Kalman filters are utilized for eliminating the RSS noise and increase the precision of target tracking performance. We present simulation results in a 10 × 10 km2 search area, where 3 fixed wing UAVs localize and track a target with up to 28.3 m average error distance.},
keywords={Transmitters;Radio frequency;Target tracking;Neural networks;RF signals;Computational modeling;Kalman filters},
doi={10.1109/ICUAS.2017.7991409},
ISSN={},
month={June},}
@INPROCEEDINGS{8280969,
author={Ferdaus, Md Meftahul and Anavatti, Sreenatha G. and Garratt, Matthew A. and Pratama, Mahardhika},
booktitle={2017 IEEE Symposium Series on Computational Intelligence (SSCI)}, title={Fuzzy clustering based modelling and adaptive controlling of a flapping wing micro air vehicle},
year={2017},
volume={},
number={},
pages={1-6},
abstract={Development of Flapping Wing Micro Air Vehicle (FW MAV) is one of the latest research topics related to the field of autonomous Unmanned Aerial Vehicles (UAVs). A four wing Bio-inspired (BI) FW MAV is selected in this work due to advantages which include fast flight, vertical take-off and landing, hovering, and quick turn, and enhanced manoeuvrability when compared to similar sized fixed and rotary wing UAVs. The Fuzzy C-Means clustering algorithm is utilized to model the BIFW MAV, which has advantages over first principle based modelling since it does not need any information about the system dynamics and can incorporate various uncertainties like sensor error. The same fuzzy clustering technique is utilized to control the altitude of the BIFW MAV, which can adapt with various environmental perturbations by changing the centre and width of the Gaussian membership function.},
keywords={Adaptation models;Mathematical model;Autoregressive processes;Clustering algorithms;Actuators;Dynamics;Neural networks},
doi={10.1109/SSCI.2017.8280969},
ISSN={},
month={Nov},}
@INPROCEEDINGS{9212825,
author={Liu, Shaohua and Liu, Haibo and Shi, Wenhao and Wang, Suqin and Shi, Min and Wang, Lina and Mao, Tianlu},
booktitle={2019 International Conference on Virtual Reality and Visualization (ICVRV)}, title={Performance Analysis of Vehicle Detection Algorithm in Aerial Traffic Videos},
year={2019},
volume={},
number={},
pages={59-64},
abstract={This paper aims at the problem of vehicle detection in UAV aerial videos and tries to investigate the performance of different kinds of object detection algorithms under such a condition. We chose ViBe, HOG+SVM, Faster R-CNN and YOLOv3 as the typical detection algorithms. After applying them on UAV aerial videos with different height and traffic scenes and testing their precision and recall, we make a theoretical analysis of their performance. Our experiments showed that Faster R-CNN is the best method. Meanwhile, ViBe, with the advantages of less calculation and relatively low hardware requirements, is a good choice for a simple scene where the vehicles keep moving all the time.},
keywords={Videos;Vehicle detection;Object detection;Feature extraction;Adaptation models;Convolutional neural networks;Vehicle dynamics;Vehicle detection, Performance analysis, Aerial photographs, Traffic video},
doi={10.1109/ICVRV47840.2019.00018},
ISSN={2375-141X},
month={Nov},}
@INPROCEEDINGS{9147126,
author={Astrov, Igor and Udal, Andres},
booktitle={2020 IEEE 24th International Conference on Intelligent Engineering Systems (INES)}, title={Neural Predictive Tracking Control of Catamaran Model Sailboat for Situation Awareness Applications},
year={2020},
volume={},
number={},
pages={153-158},
abstract={Adding artificial intelligence into the control of autonomous vehicles has become a task of steeply rising importance in development of new transportation systems and cyber-physical systems for different applications like Industry 4.0 systems and attaining Situation Awareness (SA). In contrast to the significant growth in unmanned aerial vehicle research, the study autonomous waterborne craft has remained at a relatively modest level. Paper discusses methodology of model-based modeling and simulation in Simulink/MATLAB software environment of a catamaran sailboat moving under the wind influence. The functioning of catamaran sailboat together with predictive neural network controller has been simulated for movement at the different sailing angles and wind conditions. Results confirm the applicability and good quality of neural predictive control approach.},
keywords={Mathematical model;Artificial neural networks;Predictive models;Wind speed;Boats;catamaran sailboat;predictive neurocontroller;situation awareness},
doi={10.1109/INES49302.2020.9147126},
ISSN={1543-9259},
month={July},}
@INPROCEEDINGS{7354036,
author={Rebhuhn, Carrie and Skeele, Ryan and Jen Jen Chung and Hollinger, Geoffrey A. and Tumer, Kagan},
booktitle={2015 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)}, title={Learning to trick cost-based planners into cooperative behavior},
year={2015},
volume={},
number={},
pages={4627-4633},
abstract={In this paper we consider the problem of routing autonomously guided robots by manipulating the cost space to induce safe trajectories in the work space. Specifically, we examine the domain of UAV traffic management in urban airspaces. Each robot does not explicitly coordinate with other vehicles in the airspace. Instead, the robots execute their own individual internal cost-based planner to travel between locations. Given this structure, our goal is to develop a high-level UAV traffic management (UTM) system that can dynamically adapt the cost space to reduce the number of conflict incidents in the airspace without knowing the internal planners of each robot. We propose a decentralized and distributed system of high-level traffic controllers that each learn appropriate costing strategies via a neuro-evolutionary algorithm. The policies learned by our algorithm demonstrated a 16.4% reduction in the total number of conflict incidents experienced in the airspace while maintaining throughput performance.},
keywords={Routing;Artificial neural networks;Robot kinematics;Space exploration;Vehicles;Trajectory},
doi={10.1109/IROS.2015.7354036},
ISSN={},
month={Sep.},}
@INPROCEEDINGS{8875471,
author={Kim, Heekyung and Choi, Ken},
booktitle={2019 International Conference on Internet of Things (iThings) and IEEE Green Computing and Communications (GreenCom) and IEEE Cyber, Physical and Social Computing (CPSCom) and IEEE Smart Data (SmartData)}, title={The Implementation of a Power Efficient BCNN-Based Object Detection Acceleration on a Xilinx FPGA-SoC},
year={2019},
volume={},
number={},
pages={240-243},
abstract={This paper focuses on the power efficient design on the FPGA SoC for the object detection system based on Binary Convolutional Neural Network (BCNN). Especially, for the small IoT devices, such as an intelligent dash-cam, computer vision system installed on an unmanned aerial vehicle, the power consumption could be a significant factor of the performance and scalability. However, the optimized FPGA design has limitations to reduce the overall power consumption amount. We focus on the design of the FPGA Accelerator as well as the effective design of the peripherals including CPU. In our proposed FPGA-SoC design, it supports not only FPGA but also CPU and the peripheral component can be supported by additional virtual memory system for reducing the processing time. Overall customization including customized BCNN, virtual memories for CPU and FPGA part allows our testbed to achieve low power consumption without speed degradation. Our testbed is based on customized YOLOv2 which consists of applied binary and half precision convolution, and pipeline-based architecture with accelerated hardware design on the target device. The target device used in this paper is the Xilinx ZYNQ-SoC based PYNQ Z-1 board. Our proposed system achieves 15.15 frames per second (FPS) and 1.45 watts of power dissipation. Our result shows that our design technique is effective for real-time object detection and low power system.},
keywords={Field programmable gate arrays;Power demand;Object detection;Convolutional neural networks;Computational modeling;Acceleration;Computer architecture;Low Power;Power Efficient;High performance;Convolutional Neural Network;Accelerator;FPGA SoC Design;PYNQ Overlay;Real-time Object Detection},
doi={10.1109/iThings/GreenCom/CPSCom/SmartData.2019.00060},
ISSN={},
month={July},}
@INPROCEEDINGS{8127824,
author={Nogueira, Keiller and dos Santos, Jefersson A. and Cancian, Leonardo and Borges, Bruno D. and Silva, Thiago S. F. and Morellato, Leonor Patricia and Torres, Ricardo da S.},
booktitle={2017 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)}, title={Semantic segmentation of vegetation images acquired by unmanned aerial vehicles using an ensemble of ConvNets},
year={2017},
volume={},
number={},
pages={3787-3790},
abstract={Vegetation segmentation in high resolution images acquired by unmanned aerial vehicles (UAVs) is a challenging task that requires methods capable of learning high-level features while dealing with fine-grained data. In this paper, we propose a combination of different methods of semantic segmentation based on Convolutional Networks (ConvNets) to obtain highly accurate segmentation of individuals of different vegetation species. The objective is not only to learn specific and adaptable features depending on the data, but also to learn and combine appropriate classifiers. We conducted a systematic evaluation using a high-resolution UAV-based image dataset related to a campo rupestre vegetation in the Brazilian Cerrado biome. Experimental results show that the ensemble technique overcomes all segmentation strategies.},
keywords={Vegetation mapping;Image segmentation;Convolution;Semantics;Deconvolution;Unmanned aerial vehicles;Image resolution;Deep Learning;Semantic Image Segmentation;Unmanned Aerial Vehicles;Plant Species},
doi={10.1109/IGARSS.2017.8127824},
ISSN={2153-7003},
month={July},}
@ARTICLE{9494360,
author={Wang, Shaobo and Zhang, Cheng and Su, Di and Wang, Longlong and Jiang, Huan},
journal={IEEE Access}, title={High-Precision Binary Object Detector Based on a BSF-XNOR Convolutional Layer},
year={2021},
volume={9},
number={},
pages={106169-106180},
abstract={Recently, building an efficient and robust model for object detection has attracted the attention of the vision community. Although binary networks have a fast inference speed, they cannot be used directly on mobile devices such as unmanned aerial vehicles (UAVs) because of their low detection accuracy. Different from improving the detection accuracy of a binary network by adjusting the network structure or adjusting the update gradient, we propose an improved binary neural network based on the block scaling factor XNOR (BSF-XNOR) convolutional layer. In addition, we propose a two-level densely connected network structure, which further enhances the network layer's feature representation capabilities. Experiments using the TensorFlow framework prove the effectiveness of our algorithm in improving accuracy. Compared with the original standard XNOR network, the mean average precision (mAP) detected by our algorithm on the PASCAL VOC dataset was improved. The experimental results on the VisDrone2019 UAV dataset confirm that our method achieves a better balance between speed and accuracy than previous methods. Our algorithm aims to guide and deploy high-precision binary networks on the embedded device and solves the problem of low-precision binary networks.},
keywords={Object detection;Neural networks;Convolution;Standards;Classification algorithms;Training;Feature extraction;Binary network;object detector;embedded device},
doi={10.1109/ACCESS.2021.3099702},
ISSN={2169-3536},
month={},}
@INPROCEEDINGS{9212138,
author={Menshchikov, Alexander and Lopatkin, Daniil and Tsykunov, Evgeny and Tsetserukou, Dzmitry and Somov, Andrey},
booktitle={2020 25th IEEE International Conference on Emerging Technologies and Factory Automation (ETFA)}, title={Realizing Body-Machine Interface for Quadrotor Control Through Kalman Filters and Recurrent Neural Network},
year={2020},
volume={1},
number={},
pages={595-602},
abstract={Unmanned Aerial Vehicles (UAV) have been recently applied in several various civilian applications. Based on this, there is a growing need for intuitive UAV control interfaces. In this work, we report on the Body-Machine Interface (BMI), helping a human operator to control a quadrotor through the gesture commands. We perform the human motion capture through wearable sensors and Kalman filter to reduce the noise. For the gesture command recognition, we designed the Recurrent Neural Network recognizing gestures within 65 ms. For the quadrotor orientation estimation, we designed the Extended Kalman Filter (EKF). We assess the proposed BMI via the simulations and experiments: the standard deviation of the trajectories varies for up to 10 cm.},
keywords={Body-machine interface;Kalman filter;recurrent neural network;artificial intelligence;machine learning;wearable sensing},
doi={10.1109/ETFA46521.2020.9212138},
ISSN={1946-0759},
month={Sep.},}
@ARTICLE{9351600,
author={Deng, Wenjing and Shi, Qian and Li, Jun},
journal={IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing}, title={Attention-Gate-Based Encoder–Decoder Network for Automatical Building Extraction},
year={2021},
volume={14},
number={},
pages={2611-2620},
abstract={Rapidly developing remote sensing technology provides massive data for urban planning, mapping, and disaster management. As a carrier of human productive activities, buildings are essential to both urban dynamic monitoring and suburban construction inspection. Fully-convolutional-network-based methods have provided a paradigm for automatically extracting buildings from high-resolution imagery. However, high intraclass variance and complexity are two problems in building extraction. It is hard to identify different scales of buildings by using a single receptive field. For this purpose, in this article, we use the stable encoder- decoder architecture, combined with a grid-based attention gate and atrous spatial pyramid pooling module, to capture and restore features progressively and effectively. A modified ResNet50 encoder is also applied to extract features. The proposed method could learn gated features and distinguish buildings from complex surroundings such as trees. We evaluate our model on two building datasets, WHU aerial building dataset and our DB UAV rural building dataset. Experiments show that our model outperforms other five most recent models. The results also exhibit great potential for extracting buildings with different scales and validate the effectiveness of deep learning in practical scenarios.},
keywords={Buildings;Feature extraction;Convolution;Logic gates;Task analysis;Semantics;Decoding;Attention gate (AG);building extraction;deep learning;fully convolutional networks (FCNs);semantic segmentation},
doi={10.1109/JSTARS.2021.3058097},
ISSN={2151-1535},
month={},}
@INPROCEEDINGS{7966405,
author={Faigl, Jan and Váňa, Petr},
booktitle={2017 International Joint Conference on Neural Networks (IJCNN)}, title={Unsupervised learning for surveillance planning with team of aerial vehicles},
year={2017},
volume={},
number={},
pages={4340-4347},
abstract={In this paper, we extent an existing self-organizing map (SOM)-based approach for the Dubins traveling salesman problem (DTSP) to solve its multi-vehicle variant generalized for visiting target regions called k-DTSP with Neighborhoods (k-DTSPN). The Dubins TSP is a variant of the combinatorial TSP for curvature-constrained vehicles. The problem is to determine a cost efficient path to visit a given set of continuous regions while the path allows to satisfy kinematic constraints of non-holonomic vehicles. The k-DTSPN is a generalization to determine k such paths, one for each vehicle. Although the k-DTSPN has been addressed by evolutionary methods, the proposed approach is able to provide solutions very quickly in units of seconds on conventional computationally resources which makes the proposed SOM-based approach suitable for on-line planning. The studied problem is motivated by surveillance task in which it is required to quickly provide information about the given set of target locations. Therefore, real computational requirements are crucial properties of the desired k-DTSPN solver. The proposed method meets this requirement and feasibility of the found solutions are demonstrated not only in computer simulations but also with a practical deployment on real aerial vehicles.},
keywords={Planning;Trajectory;Surveillance;Robots;Memetics;Unsupervised learning;Self-organizing feature maps},
doi={10.1109/IJCNN.2017.7966405},
ISSN={2161-4407},
month={May},}
@INPROCEEDINGS{6564667,
author={Cook, Kevin and Bryan, Everett and Yu, Huili and Bai, He and Seppi, Kevin and Beard, Randal},
booktitle={2013 International Conference on Unmanned Aircraft Systems (ICUAS)}, title={Intelligent cooperative control for urban tracking with Unmanned Air Vehicles},
year={2013},
volume={},
number={},
pages={1-7},
abstract={We introduce an intelligent cooperative control system for ground target tracking in a cluttered urban environment with a team of Unmanned Air Vehicles (UAVs). We extend the work of Yu et. al. [1] to add a machine learning component that uses observations of target position to learn a model of target motion. Our learner is the Sequence Memoizer [2], a Bayesian model for discrete sequence data, which we use to predict future target location identifiers, given a context of previous location identifiers. Simulated cooperative control of a team of 3 UAVs in a 100-block city filled with various sizes of buildings verifies that learning a model of target motion can improve target tracking performance.},
keywords={Vehicles;Kinematics;Cities and towns;Target tracking;Artificial intelligence;Control systems;Buildings},
doi={10.1109/ICUAS.2013.6564667},
ISSN={},
month={May},}
@INPROCEEDINGS{7502586,
author={Carrio, Adrian and Sampedro, Carlos and Fu, Changhong and Collumeau, Jean-François and Campoy, Pascual},
booktitle={2016 International Conference on Unmanned Aircraft Systems (ICUAS)}, title={A real-time supervised learning approach for sky segmentation onboard unmanned aerial vehicles},
year={2016},
volume={},
number={},
pages={8-14},
abstract={Vision-based sky segmentation and horizon line detection can be extremely useful to perform important tasks onboard Unmanned Aerial Vehicles (UAVs), such as pose estimation and collision avoidance. Most of the existing vision-based solutions use traditional image processing methods to identify the horizon line. This results in good overall accuracy and fast computation times. However, difficult environmental conditions such as a foggy or cloudy skies hinder correct sky segmentation. This paper proposes a solution for sky segmentation in RGB images using a supervised Machine Learning approach by first splitting the image into fixed-size patches, extracting and classifying color descriptors for each patch and performing a final post-processing stage to improve segmentation quality. A method for automatic horizon line detection is also proposed. The performance of our approach was evaluated on flight images captured onboard UAVs, achieving performance accuracies above 93% at real-time frame rates.},
keywords={Image color analysis;Image segmentation;Aircraft;Image edge detection;Histograms;Real-time systems;Unmanned aerial vehicles},
doi={10.1109/ICUAS.2016.7502586},
ISSN={},
month={June},}
@INPROCEEDINGS{7502626,
author={Nakamura, Takuma and Johnson, Eric N.},
booktitle={2016 International Conference on Unmanned Aircraft Systems (ICUAS)}, title={Vision-based multiple model adaptive estimation of ground targets from airborne images},
year={2016},
volume={},
number={},
pages={598-607},
abstract={This paper describes a vision-based multiple model adaptive estimation using UAVs that enables the tracking of a mobile target that changes the system model depending on unknown factors. In our system the machine-learning-based target identification method uses Haar-like classifiers that detects the target position. The system uses multiple extended Kalman filters for each system model and estimates the states of the target through the observed positions. We estimate the probability that each system is true and use the max-probability method to determine the current model. The position controller of the UAVs uses the vision system not only to determine a desired waypoint but also to switch the control law for another model. Implementation of this system is validated through an image-in-the-loop simulation. We also explore an vision-based solution for Mission 7 of the international aerial robotics competition.},
keywords={Cameras;Target tracking;TV;Vehicles;Feature extraction;Wheels;Adaptation models},
doi={10.1109/ICUAS.2016.7502626},
ISSN={},
month={June},}
@INPROCEEDINGS{8204431,
author={Kwon, Seong-Ho and Ahn, Hyo-Sung},
booktitle={2017 17th International Conference on Control, Automation and Systems (ICCAS)}, title={Sensor failure detection, identification and accommodation using neural network and fuzzy voter},
year={2017},
volume={},
number={},
pages={139-144},
abstract={Sensor failure detection, identification and accommodation (SFDIA) is a challenging and important problem on unmanned aerial vehicles (UAVs) or other safety critical applications. This paper proposes new SFDIA scheme. The new scheme combines advantages of hardware redundancy and analytical redundancy. Fuzzy voter and neural network (NN)-based sensor estimators are developed in the proposed scheme. The fuzzy voter is based on the fuzzy voting scheme. The new SFDIA scheme has a more reliable redundancy based on the FCC NN. The performance of the SFDIA scheme is validated by experiments of quadrotor with two gyro sensor modules. It can detect the sensors failure, pinpoint what sensor fails, and replace the sensor with the other normal sensor.},
keywords={Artificial neural networks;Redundancy;FCC;Neurons;Computer architecture;Acceleration;Hardware;Sensor failure detection;identification and accommodation (SFDIA);neural networks;fuzzy voter;fault tolerance;quadrotor},
doi={10.23919/ICCAS.2017.8204431},
ISSN={},
month={Oct},}
@INPROCEEDINGS{6842300,
author={Lokman, Gurcan and Yilmaz, Guray},
booktitle={2014 International Conference on Unmanned Aircraft Systems (ICUAS)}, title={A new method for anomaly detection and target recognition},
year={2014},
volume={},
number={},
pages={577-583},
abstract={Use of unmanned Aerial Vehicles (UAVs) has gained significant importance in the recent years because they are capable of to be used in in civilian and military purposes for reconnaissance, surveillance, disaster relief, among other tasks. In this paper we present new automated anomaly detection and target recognition methodology that can be used on such a UAV. The standard paradigm for anomaly detection and target recognition in hyperspectral imagery (HSI) is to run a detection or recognition algorithm, typically statistical in nature, and visually inspect each high-scoring pixel to decide whether it is an anomaly or background data. A new method of anomaly detection and target recognition in HSI was studied based on a Neural Network (NN). Two multi-layered neural networks are used for anomaly detection and target recognition. The first phase of the model is used to detect anomalies in HSI. The second phase of the model is to use determine whether the anomaly is a predefined target or not. Both networks are trained in accordance with its intended purpose, so increase in performance is provided. This method can be a suitable solution for applications where the unmanned aerial vehicles used.},
keywords={Unmanned aerial vehicles},
doi={10.1109/ICUAS.2014.6842300},
ISSN={},
month={May},}
@INPROCEEDINGS{8658300,
author={Benjdira, Bilel and Khursheed, Taha and Koubaa, Anis and Ammar, Adel and Ouni, Kais},
booktitle={2019 1st International Conference on Unmanned Vehicle Systems-Oman (UVS)}, title={Car Detection using Unmanned Aerial Vehicles: Comparison between Faster R-CNN and YOLOv3},
year={2019},
volume={},
number={},
pages={1-6},
abstract={Unmanned Aerial Vehicles are increasingly being used in surveillance and traffic monitoring thanks to their high mobility and ability to cover areas at different altitudes and locations. One of the major challenges is to use aerial images to accurately detect cars and count-them in real-time for traffic monitoring purposes. Several deep learning techniques were recently proposed based on convolution neural network (CNN) for real-time classification and recognition in computer vision. However, their performance depends on the scenarios where they are used. In this paper, we investigate the performance of two state-of-the art CNN algorithms, namely Faster R-CNN and YOLOv3, in the context of car detection from aerial images. We trained and tested these two models on a large car dataset taken from UAVs. We demonstrated in this paper that YOLOv3 outperforms Faster R-CNN in sensitivity and processing time, although they are comparable in the precision metric.},
keywords={Automobiles;Feature extraction;Object detection;Computer architecture;Real-time systems;Surveillance;Proposals;Car detection;convolutional neural networks;You Only Look Once;Faster R-CNN;unmanned aerial vehicles;object detection and recognition},
doi={10.1109/UVS.2019.8658300},
ISSN={},
month={Feb},}
@ARTICLE{8723347,
author={Rohan, Ali and Rabah, Mohammed and Kim, Sung-Ho},
journal={IEEE Access}, title={Convolutional Neural Network-Based Real-Time Object Detection and Tracking for Parrot AR Drone 2},
year={2019},
volume={7},
number={},
pages={69575-69584},
abstract={Recent advancements in the field of Artificial Intelligence (AI) have provided an opportunity to create autonomous devices, robots, and machines characterized particularly with the ability to make decisions and perform tasks without human mediation. One of these devices, Unmanned Aerial Vehicles (UAVs) or drones are widely used to perform tasks like surveillance, search and rescue, object detection and target tracking, parcel delivery (recently started by Amazon), and many more. The sensitivity in performing said tasks demands that drones must be efficient and reliable. For this, in this paper, an approach to detect and track the target object, moving or still, for a drone is presented. The Parrot AR Drone 2 is used for this application. Convolutional Neural Network (CNN) is used for object detection and target tracking. The object detection results show that CNN detects and classifies object with a high level of accuracy (98%). For real-time tracking, the tracking algorithm responds faster than conventionally used approaches, efficiently tracking the detected object without losing it from sight. The calculations based on several iterations exhibit that the efficiency achieved for target tracking is 96.5%.},
keywords={Drones;Object detection;Target tracking;Cameras;Detectors;Training;Convolutional neural networks;Convolutional neural network;deep learning;object detection;target tracking;unmanned aerial vehicles},
doi={10.1109/ACCESS.2019.2919332},
ISSN={2169-3536},
month={},}
@INPROCEEDINGS{8996813,
author={Zhou, Kai and Wei, Ruixuan and Zhang, Qirui and Wu, Ziehen},
booktitle={2019 Chinese Automation Congress (CAC)}, title={Research on Decision-making Method for Territorial Defense Based on Fuzzy Reinforcement Learnin},
year={2019},
volume={},
number={},
pages={3759-3763},
abstract={Protecting important targets, which also called territorial defense, will be an important application of the unmanned aerial vehicles (UAVs) in the future. This paper designs a method to generate interception strategy by learning, which can deal with invaders launched from different directions and different velocity. Firstly, we analyze the influence of initial states on the game results, and explored the initial condition boundary inside which the invader could be intercepted. Secondly, territorial defense game is a complex multi-steps decision-making problem which has continuous action and state spaces. To address this problem, conventional decision methods such as dynamic programming, moving horizon optimization method and Q-learning will cause dimension explosion issue. In this paper, we introduce a fuzzy logic into the actor-critic algorithm and reduce the amount of computation effectively. We consider invaders with different directions and speeds, can offer a more realistic result. Experiments showed that the algorithm can balance the exploration and utilization behavior well and the defender can learn to intercept the invader without prior knowledge.},
keywords={Learning (artificial intelligence);Decision making;Unmanned aerial vehicles;Fuzzy rules;Reinforcement Learning;Territorial Defense;Decision-making},
doi={10.1109/CAC48633.2019.8996813},
ISSN={2688-0938},
month={Nov},}
@INPROCEEDINGS{8936110,
author={Dahmane, Mohamed and St-Charles, Pierre-Luc and Lalonde, Marc and Heffner, Kevin and Foucher, Samuel},
booktitle={2019 Ninth International Conference on Image Processing Theory, Tools and Applications (IPTA)}, title={Arousal and Valence Estimation for Visual Non-Intrusive Stress Monitoring},
year={2019},
volume={},
number={},
pages={1-6},
abstract={As the capabilities and usefulness of advanced Unmanned Aerial Vehicles (UAVs) increase, communication between the operator and these intelligent systems is becoming a very important factor for mission success. In this context, automatic stress detection is becoming a key research topic in emotion analysis. Stress can be estimated by means of an array of intrusive sensors or via the measurement of some biological markers (e.g. cortisol levels). However, these approaches are not appropriate in many cases of human-machine interactions. In this paper, we propose a deep learning-based psychological stress level estimation approach. The goal is to identify the region where the emotional state of the operator projects in the space defined by the latent dimensional emotions of arousal and valence. The stress region is well defined in this space according to prior works in psychology. The proposed predictive model first extracts and aligns the operator's face, then generates embeddings from a pre-trained face model. These embeddings are then used to train two different architectures, a hierarchical temporal CNN and a LSTM with an Attention Weighted Average layer. Since we deal with naturalistic behavior in a context of operator-machine interaction, the One-Minute Gradual-Emotion Behavior Challenge (OMG) dataset is used for the validation of continuously estimated arousal/valence levels.},
keywords={Stress;Face recognition;Visualization;Monitoring;Psychology;Predictive models;Faces;Continuous emotion analysis;operator stress monitoring;face analysis;deep learning;Unmanned Aerial Vehicles.},
doi={10.1109/IPTA.2019.8936110},
ISSN={2154-512X},
month={Nov},}
@INPROCEEDINGS{8451504,
author={Chou, Yi-Min and Chen, Chien-Hung and Liu, Keng-Hao and Chen, Chu-Song},
booktitle={2018 25th IEEE International Conference on Image Processing (ICIP)}, title={Changing Background to Foreground: An Augmentation Method Based on Conditional Generative Network for Stingray Detection},
year={2018},
volume={},
number={},
pages={2740-2744},
abstract={Image processing has been a popular tool for biological researches. Detecting specific animals in aerial images captured by an UAV is a crucial research topic. As the rapid progress of deep learning (DL), it has been a popular approach to many image classification and object detection tasks. However, DL usually requires a large set of training samples to learn the network weights, while the biological image materials are often insufficient to fulfill the demand. To improve the detection of stingrays in aerial images, this paper presents a new training sample augmentation method called Mixed Bg-Fg Synthesis. We extend a generative network, Generative Latent Optimization (GLO) to its conditional version, namely, Conditional GLO (C-GLO), which can increase stingray samples on the background and thus improve the training efficacy of a CNN detector. Unlike traditional data augmentation methods that generate new data only for image classification, our proposed method that mixes foreground and background together can generate new data for an object detection task. Experimental results show that the C-GLO augmented stingray samples is helpful to enhance the detection capability.},
keywords={Training;Gallium nitride;Object detection;Sea surface;Generators;Detectors;Task analysis;Object detection;aerial image;deep learning;generative model;generative latent optimization},
doi={10.1109/ICIP.2018.8451504},
ISSN={2381-8549},
month={Oct},}
@INPROCEEDINGS{9619842,
author={Velazquez, Alberto and Diaz, Jorge and Sardarmehni, Tohid and Xu, Lei},
booktitle={2021 IEEE International Symposium on Technologies for Homeland Security (HST)}, title={HUVS: Heterogeneous UV Swarm for Homeland Security Tasks},
year={2021},
volume={},
number={},
pages={1-6},
abstract={We have seen significant progress in the development of unmanned vehicles (UVs) recently, including both unmanned aerial vehicles (UAVs) and unmanned ground vehicles (UGVs). UVs have various applications for homeland security, especially border patrol and surveillance. UGVs and UAVs have different strengths and limitations in these tasks. Generally, a UGV can operate for a long period but can only cover a limited area while a UAV can cover a larger area but operate for a shorter period. While there are also sophisticated UAVs that have a long aloft time, the cost of such a UAV is too high for wide deployment. To address these challenges, we propose a heterogeneous architecture for a UV system that unleashes the potential of UGVs and UAVs. As the UV system may be deployed into hostile environments, we also discuss the details of security enhancements. Furthermore, we discuss methods to integrate artificial intelligence (AI) into the system considering the increased importance of AI technologies for homeland security tasks.},
keywords={Costs;Law enforcement;Surveillance;Machine learning;Autonomous aerial vehicles;Land vehicles;Security},
doi={10.1109/HST53381.2021.9619842},
ISSN={},
month={Nov},}
@ARTICLE{8943188,
author={Zhou, Longyu and Leng, Supeng and Liu, Qiang and Mao, Sun and Liao, Yinhua},
journal={IEEE Access}, title={Intelligent Resource Collaboration in Mobile Target Tracking Oriented Mission-Critical Sensor Networks},
year={2020},
volume={8},
number={},
pages={10971-10980},
abstract={Mobile target tracking-oriented sensor networks are a special kind of Mission-critical Sensor Networks (MCSN), in which the various missions with the diverse priorities exist. However, it is challenging to achieve real time tracking while keeping the MCSN a long life time with limited energy provision in a complicated environment. In this paper, we develop a collaborative perception and intelligent scheduling scheme, which jointly optimizes the system responding latency and tracking accuracy with the constraint of the available energy. A new hierarchical architecture is proposed to realize the coupled function of perception and computation. In particular, the multi-node collaborative perception scheme is applied to obtain the excellent sensing capacity, and the Unmanned Aerial Vehicles (UAVs) play as the edge nodes to provide the computing service for those resource-constrained sensor nodes. To reach the sustained target tracking, we propose an intelligent tracking policy by exploiting the deep deterministic policy gradient (DDPG) method. Simulation results demonstrate that the proposed intelligent collaboration scheme can improve the tracking accuracy by 45.5% compared with the random selection scheme. The system cost is also reduced approximately by 17.3% while guaranteeing the tracking accuracy.},
keywords={Target tracking;Collaboration;Intelligent sensors;Energy consumption;Wireless sensor networks;Monitoring;Multi-target tracking;energy consumption;collaborative perception;deep reinforcement learning},
doi={10.1109/ACCESS.2019.2962130},
ISSN={2169-3536},
month={},}
@INBOOK{8471082,
author={Pecht, Michael G. and Kang, Myeongsu},
booktitle={Prognostics and Health Management of Electronics: Fundamentals, Machine Learning, and the Internet of Things}, title={Uncertainty Representation, Quantification, and Management in Prognostics},
year={2019},
volume={},
number={},
pages={193-220},
abstract={This chapter analyzes the significance, interpretation, quantification, and management of uncertainty in prognostics, with an emphasis on predicting the remaining useful life (RUL) of engineering systems and components. Prognostics deals with predicting the future behavior of engineering systems and is affected by various sources of uncertainty. The chapter explains the paramount importance of uncertainty interpretation, quantification, and management in prognostics, focusing both on testing‐based life prediction and condition‐based prognostics. It discusses the suitability of classical and subjective approaches to uncertainty. The chapter also explains computational methods for uncertainty quantification and management. The most intuitive method for uncertainty propagation is to make use of Monte Carlo simulation (MCS). Having calculated the uncertainty in the prediction, it is necessary to facilitate uncertainty management from a decision‐making point of view in order to facilitate risk mitigation activities. The chapter presents a case study on the power system of an unmanned aerial vehicle.},
keywords={Uncertainty;Mathematical model;Prognostics and health management;Monitoring;Reliability;Predictive models},
doi={10.1002/9781119515326.ch8},
ISSN={},
publisher={IEEE},
isbn={9781119515302},
url={https://ieeexplore-ieee-org.ez294.periodicos.capes.gov.br/document/8471082},}
@INPROCEEDINGS{6237275,
author={Fang, Zhou and Hao, Chuanchuan and Li, Ping},
booktitle={2012 IEEE International Symposium on Industrial Electronics}, title={Model reference output feedback control using episodic natural actor-critic},
year={2012},
volume={},
number={},
pages={1286-1290},
abstract={In this paper, we develop a novel reinforcement learning algorithm which requires only system output and converges to an optimal output feedback control policy with expected dynamic performance. An informative reward function based on reference model is adopted to intuitively represent the desired closed-loop performance, which significantly reduces the difficulty of reward construction. A stochastic output feedback control policy based on PID law is used to release the complete observability requirement. The episodic Natural Actor-Critic (eNAC) algorithm is used for policy search. Simulations on a second-order unstable system and a nonlinear LPV model of UAV's longitudinal dynamics demonstrate the efficiency of the proposed algorithm.},
keywords={Heuristic algorithms;Output feedback;Learning;Stochastic processes;Educational institutions;Aerodynamics;Approximation algorithms},
doi={10.1109/ISIE.2012.6237275},
ISSN={2163-5145},
month={May},}
@INPROCEEDINGS{7989380,
author={Martinez-Cantin, Ruben},
booktitle={2017 IEEE International Conference on Robotics and Automation (ICRA)}, title={Bayesian optimization with adaptive kernels for robot control},
year={2017},
volume={},
number={},
pages={3350-3356},
abstract={Active policy search combines the trial-and-error methodology from policy search with Bayesian optimization to actively find the optimal policy. First, policy search is a type of reinforcement learning which has become very popular for robot control, for its ability to deal with complex continuous state and action spaces. Second, Bayesian optimization is a sample efficient global optimization method that uses a surrogate model, like a Gaussian process, and optimal decision making to carefully select each sample during the optimization process. Sample efficiency is of paramount importance when each trial involves the real robot, expensive Monte Carlo runs, or a complex simulator. Black-box Bayesian optimization generally assumes a cost function from a stationary process, because nonstationary modeling is usually based on prior knowledge. However, many control problems are inherently nonstationary due to their failure conditions, terminal states and other abrupt effects. In this paper, we present a kernel function specially designed for Bayesian optimization, that allows nonstationary modeling without prior knowledge, using an adaptive local region. The new kernel results in an improved local search (exploitation), without penalizing the global search (exploration), as shown experimentally in well-known optimization benchmarks and robot control scenarios. We finally show its potential for the design of the wing shape of a UAV.},
keywords={Kernel;Optimization;Bayes methods;Gaussian processes;Robots;Adaptation models;Learning (artificial intelligence)},
doi={10.1109/ICRA.2017.7989380},
ISSN={},
month={May},}
@INPROCEEDINGS{8784782,
author={Hartawan, Dean Rizki and Purboyo, Tito Waluyo and Setianingsih, Casi},
booktitle={2019 IEEE International Conference on Industry 4.0, Artificial Intelligence, and Communications Technology (IAICT)}, title={Disaster Victims Detection System Using Convolutional Neural Network (CNN) Method},
year={2019},
volume={},
number={},
pages={105-111},
abstract={Natural disasters are one of the things that cannot be predicted. Natural disasters can cause losses, both assets and objects can even take lives. To reduce the number of losses, rapid evacuation handling from the Search and Rescue (SAR) team is needed to help victims of natural disasters. But in fact, there are often obstacles in the evacuation process. Such obstacles are such as bad weather conditions, disconnection of telecommunications networks, difficulty access to the victims of natural disasters and the spread of SAR teams that are not evenly distributed throughout the disaster area. Convolutional Neural Network is one of the developments of Artificial Neural Networks for image classification, image segmentation, and object recognition with high accuracy and high performance. CNN can learn to detect various images according to images from the dataset studied. So, this paper designed a system for detecting victims of natural disasters using the CNN method and implemented it on a raspberry pi which can detect victims of natural disasters through streaming cameras placed on UAVs. In this paper, the Convolutional Neural Network (CNN) method with 100% accuracy with distance object 1-4 m uses the Mobile-net SSD model.},
keywords={Convolutional neural networks;Feature extraction;Convolution;Unmanned aerial vehicles;Artificial intelligence;Object detection;Cameras;Object Detection;Convolutional Neural Network (CNN);Disaster Victim Detection},
doi={10.1109/ICIAICT.2019.8784782},
ISSN={},
month={July},}
@ARTICLE{8241853,
author={Barmpounakis, Emmanouil N. and Vlahogianni, Eleni I. and Golias, John C.},
journal={IEEE Transactions on Intelligent Vehicles}, title={Identifying Predictable Patterns in the Unconventional Overtaking Decisions of PTW for Cooperative ITS},
year={2018},
volume={3},
number={1},
pages={102-111},
abstract={In the modern challenging urban environment, powered two wheelers (PTW) are selected for their everyday commuting. The way motorcycles and scooters travel through traffic is systematically emphasized in the recent relevant literature as being complex, especially in relation to overtaking. In this paper, meta-optimized Decision Trees, a special case of machine learning (ML) models, are developed in order to model the unconventional overtaking patterns of PTW drivers. Based on detailed naturalistic trajectory data collected using video footage from unmanned aerial vehicles (UAV) in a three-lane arterial in Athens, Greece, two different models of PTW driving behavior are developed. The first model addresses the decision of the PTW driver to overtake or not the preceding vehicle. The second model focuses on PTW driver's intention to overtake or undertake (pass from the right) it. The developed decision tree models are further analyzed in relation to the revealed significant factors during overtaking. Following, the applicability of the developed algorithms in the context of intelligent transportation systems and connected vehicles is discussed, which reveals the importance of acquiring quality data using advanced equipment combined with advanced ML approaches for advanced modeling methods.},
keywords={Decision trees;Data models;Predictive models;Unmanned aerial vehicles;Analytical models;Acceleration;Intelligent transportation systems (ITS);machine learning;overtaking;powered two wheelers (PTWs)},
doi={10.1109/TIV.2017.2788195},
ISSN={2379-8904},
month={March},}
@INPROCEEDINGS{9256712,
author={Milroy, Roger},
booktitle={2020 AIAA/IEEE 39th Digital Avionics Systems Conference (DASC)}, title={Where's WALL-E? A Comparison of the Extended Kalman Filter and Hybrid Inference for Pose Estimation in MAVs},
year={2020},
volume={},
number={},
pages={1-5},
abstract={Pose estimation is a core competence for cyber-physical systems and is all the more important where there is any element of autonomy. In the context of Micro Air Vehicles (MAVs) this task is more challenging due to weight and cost restrictions. These restrictions dictate that MAVs usually have noisy sensors and limited computational capacity. There are many different approaches to solving this problem but the standard approach is to use the Kalman Filter (KF) [1], or it's nonlinear variant the Extended Kalman Filter (EKF) [2], in order to fuse sensor data and provide optimal estimates of state. While the KF is an optimal estimator of linear systems given some assumptions, most systems are non-linear so the EKF is used. In either case the estimates rely on assumptions that may not always hold. This allows room for improvement. This paper implements the newly proposed technique of Hybrid Inference (HI) [3] on a model of an MAV simulated in Gazebo [4] and explores its performance as compared to the EKF which is used as the standard. HI is a framework for combining graphical models, like the KF, with inverse models which are learned with a Recurrent Message Passing Neural Network (MPNN) [5] [6]. This paper evaluates the technique in a more challenging domain than has previously been implemented. It explores the challenges of implementing the technique, analyses its computational performance and discusses its suitability for use at this time with a strong practical focus. The main findings are that it is too challenging to implement correctly to take full advantage of its proposed benefits. And that it is too computationally inefficient in its current form for it to be suitable for use in real time systems with current technology.},
keywords={Training;Kalman filters;Graphical models;Testing;Standards;Pose estimation;Optimization;Neural nets;Neural models;Graph Neural Networks;Filtering;MAV;UAV},
doi={10.1109/DASC50938.2020.9256712},
ISSN={2155-7209},
month={Oct},}
@ARTICLE{8869893,
author={Zhuang, Junfei and Dong, Yuan and Bai, Hongliang and Zuo, Peiliang and Cheng, Jianming},
journal={IEEE Access}, title={Auto-Selecting Receptive Field Network for Visual Tracking},
year={2019},
volume={7},
number={},
pages={157449-157458},
abstract={Recently, Convolutional Neural Networks (CNNs) have shown tremendous potential in the visual tracking community. It is well-known that the receptive field is a critical factor for CNN affecting performance. However, standard CNNs based tracking methods design the receptive fields of artificial neurons in each layer that have the same size. We identify the main bottleneck of affecting the tracking accuracy as regular receptive fields. To settle the problem, we propose an Auto-Selecting Receptive Field Network (ASRF) to select receptive field information and effective clues dynamically. In particular, a Selective Receptive Field Block (SRFB) is designed to adaptively adjust receptive field size for each neuron according to multiple scales of input information. Additionally, we develop a Multi-Scale Receptive Field module (MSRF) that marks a further step in selecting effective clues from different scale receptive fields. The proposed ASRF method performs favorably against state-of-the-art trackers on five benchmarks, including OTB-2013, OTB-2015, UAV-123, VOT-2015, and VOT-2017 while running beyond real-time tracking speed.},
keywords={Target tracking;Visualization;Convolution;Task analysis;Neurons;Benchmark testing;Computational modeling;Visual tracking;deep learning;Siamese network;receptive field},
doi={10.1109/ACCESS.2019.2947472},
ISSN={2169-3536},
month={},}
@INPROCEEDINGS{9594425,
author={Avila, Jovany and Brouwer, Tristan},
booktitle={2021 IEEE/AIAA 40th Digital Avionics Systems Conference (DASC)}, title={Indoor Autonomous Powerline Inspection Model},
year={2021},
volume={},
number={},
pages={1-5},
abstract={This paper presents the development of an autonomous system that leverages the Quanser Qdrone to perform above-ground indoor autonomous powerline inspections. The powerline infrastructure is exposed to various extreme weather conditions that create an operational concern for utility companies. Frequent inspections ensure the safe operation of a power transmission grid. There are mainly two methods of examination, ground and air [1]. The ground inspections are often slow and challenging due to the rough terrain, utility pole height, and inaccessible remote areas. The aerial inspections are accomplished by deploying helicopters that are expensive to operate, maintain, and repair. As an alternative, Unmanned Aerial Vehicles (UAVs) are being widely adopted for both surveillance and analysis throughout the energy and utility industries. UAVs are being used for inspections of utility towers as well as powerlines as they are energy efficient, user friendly, and convenient. Drone video capturing allows for safer, faster, and more cost-effective solutions to powerline and utility tower inspections as the user does not have to leave the ground aside from repairs. The objective of this project was to develop an autonomous UAV system to detect and track powerlines and utility poles to perform fault inspections of their electrical and material components. The proposed algorithm used a state flow machine paired with an image recognition neural network to make decisions for searching, identifying, and flying along utility poles and powerlines. The proposed system was implemented using MathWorks MATLAB and Simulink with Quarc, a third-party toolbox designed by Quanser, enabling real-time applications with the QDrone. The project yielded an algorithm that would autonomously fly the Quanser QDrone through a scan of the local area, leverage a neural network, PowerNet, to locate an initial tower within the work area, follow attached powerlines if there are any, and locate the secondary tower. Once the inspection was completed, the QDrone would return to the home point and land.},
keywords={Autonomous systems;Software packages;Surveillance;Poles and towers;Neural networks;Power transmission;Inspection;track;image recognition;Quanser;QDrone},
doi={10.1109/DASC52595.2021.9594425},
ISSN={2155-7209},
month={Oct},}
@INPROCEEDINGS{8790423,
author={Alqaisi, Walid Kh. and Brahmi, Brahim and Ghommam, Jawhar and Saad, Maarouf and Nerguizian, Vahé},
booktitle={2019 IEEE International Symposium on Robotic and Sensors Environments (ROSE)}, title={Adaptive Sliding mode Control Based on RBF Neural Network Approximation for Quadrotor},
year={2019},
volume={},
number={},
pages={1-7},
abstract={This paper addresses the design of a robust adaptive sliding mode tracking control approach utilizing a Radial Basis Function Neural Network RBF NN for quadrotor. The proposed system has great advantages in dealing with nonlinearities and it has the ability to approximate uncertainties. The output of the neural network is used as a compensator parameter in order to eliminate system uncertainties. Consequently, fast error convergence in the closed loop control system can be achieved. A preliminary study to apply the system in an agricultural application using visual sensing is introduced and tested. The proposed system stability is proved by Lyapunov analysis, simulation and experimental implementation.},
keywords={Adaptation models;Uncertainty;Vegetation;Artificial neural networks;Mathematical model;Control systems;Adaptive control;quadrotor;RBF neural network;sliding-mode;UAV},
doi={10.1109/ROSE.2019.8790423},
ISSN={},
month={June},}
@INPROCEEDINGS{8861770,
author={Domozi, Zsolt and Molnar, Andras},
booktitle={IEEE EUROCON 2019 -18th International Conference on Smart Technologies}, title={Surveying private pools in suburban areas with neural network based on drone photos},
year={2019},
volume={},
number={},
pages={1-6},
abstract={In many cases, there is a need for local authorities to carry out a territorial survey of municipalities. The purpose of surveys may be to refine the data or to verify the information that forms the basis of local taxes. Such data include the possession of private outdoor swimming pools belonging to family houses. The knowledge of the number of pools is important in many ways. Drainage load will increase significantly when pools are drained for which the channel operator needs to prepare. In the same way, filling also has a significant water demand for which the water supplier needs to be prepared. For all these reasons, it is understandable if the local government requests an extra contribution from the pool owners in the form of a tax. Up-to-date and accurate data are important for municipalities. Aerial photography can be used to recognize outdoor pools with ease. With drones, the process is fast and cost-effective. At the same time, the numerical quantification of pools from a large amount of data produced during the photo shoot (high-resolution orthophoto covering the area) is a time-consuming task. The method we have developed can automatically detect basins and to quantify them by using a neural network on orthophotos.},
keywords={Drones;Training;Satellites;Image resolution;Neural networks;Sports;Photography;UAV;orthophoto;swimming pool;neural network;detection},
doi={10.1109/EUROCON.2019.8861770},
ISSN={},
month={July},}
@INPROCEEDINGS{8125902,
author={Brahmbhatt, Khushal and Pai, Akshatha Rakesh and Singh, Sanjay},
booktitle={2017 International Conference on Advances in Computing, Communications and Informatics (ICACCI)}, title={Neural network approach for vision-based track navigation using low-powered computers on mavs},
year={2017},
volume={},
number={},
pages={578-583},
abstract={A quadrotor Micro Aerial Vehicle (MAV) is designed to navigate a track using neural network approach to identify the direction of the path from a stream of monocular images received from a downward-facing camera mounted on the vehicle. Current autonomous MAVs mainly employ computer vision techniques based on image processing and feature tracking for vision-based navigation tasks. It requires expensive onboard computation and can create latency in the real-time system when working with low-powered computers. By using a supervised image classifier, we shift the costly computational task of training a neural network to classify the direction of the track to an offboard computer. We make use of the learned weights obtained after training to perform simple mathematical operations to predict the class of the image on the onboard computer. We compare the computer vision based tracking approach with the proposed approach to navigate a track using a quadrotor and show that the processing rates of the latter is faster. This allows low-cost, low-powered computers such as the Raspberry Pi to be used efficiently as onboard companion computers for flying vision-based autonomous missions with MAVs.},
keywords={Computers;Navigation;Neural networks;Cameras;Computer vision;Mathematical model;MAVs;UAVs;autonomous navigation;vision-based navigation},
doi={10.1109/ICACCI.2017.8125902},
ISSN={},
month={Sep.},}
@INPROCEEDINGS{8265446,
author={Scharr, H. and Pridmore, T. and Tsaftaris, S. A.},
booktitle={2017 IEEE International Conference on Computer Vision Workshops (ICCVW)}, title={Computer Vision Problems in Plant Phenotyping, CVPPP 2017: Introduction to the CVPPP 2017 Workshop Papers},
year={2017},
volume={},
number={},
pages={2020-2021},
abstract={Plant phenotyping is the identification of effects on the phenotype (i.e., the plant appearance and behavior) as a result of genotype differences (i.e., differences in the genetic code) and the environment. Previously, the process of taking phenotypic measurements has been laborious, costly, and time consuming. In recent years, non-invasive, image-based methods have become more common. These images are recorded by a range of capture devices from small embedded camera systems to multi-million Euro smart-greenhouses, at scales ranging from microscopic images of cells, to entire fields captured by UAV imaging. These images needs to be analyzed in a high throughput, robust, and accurate manner.},
keywords={Conferences;Computer vision;Three-dimensional displays;Machine vision;Image analysis;Machine learning;Geology},
doi={10.1109/ICCVW.2017.236},
ISSN={2473-9944},
month={Oct},}
@ARTICLE{7469999,
author={Murphy, Robin R.},
journal={Computer}, title={Emergency Informatics: Using Computing to Improve Disaster Management},
year={2016},
volume={49},
number={5},
pages={19-27},
abstract={Three case studies of how two new emergency informatics tools--unmanned aerial vehicles and social media--were used to manage the 2015 Memorial Day weekend floods in Texas illustrate fundamental challenges and opportunities for computing research.},
keywords={Floods;Informatics;Stakeholders;Disaster management;Emergency services;Decision making;Mobile communication;emergency informatics;disaster management;decision support;autonomous vehicles;unmanned aerial vehicles;UAVs;emergency support functions;ESFs;social media;data mining;computer vision;machine learning;data analysis;project management;robotics},
doi={10.1109/MC.2016.135},
ISSN={1558-0814},
month={May},}
@INPROCEEDINGS{8936153,
author={Zahid, Javaid Iqbal and Hussain, Fatima and Ferworn, Alex},
booktitle={2019 IEEE 10th Annual Information Technology, Electronics and Mobile Communication Conference (IEMCON)}, title={A Model of Computing and Communication for Public Safety Integrating FirstNet, Edge Computing, and Internet of Things},
year={2019},
volume={},
number={},
pages={0619-0623},
abstract={A Public Safety Network (PSN) is an essential element of the Emergency Management System (EMS) for any country to deal with natural or man-made disasters. PSN is an information and communication infrastructure that assists managing first responders during incident operations. In this article we propose a model of computation and communication that could represent a future alternative public safety network. Our concept is based on the integration of emerging technologies like Fog/Edge Computing, Internet of Things (IoT), and FirstNet network partly in operation in the United States. Our model proposes a synergy between these technologies and forms a platform for highly qualified people (HQP) in training to develop and experiment with their research work. As the technology is similar to that in actual operation, any research results may be more easily adopted by PSNs in actual operations. Mobile edge devices like smart phones, dones, robots, and aerial platforms form part of deployed devices. These are interconnected via gateways to the Internet for providing useful information to incident command centers where managers can make timely decisions. Our model is implemented using off-the-shelf devices both for computing and communication tasks.},
keywords={Robot sensing systems;Computational modeling;Safety;Internet of Things;Cloud computing;Edge computing;Public Safety;Disaster Response (DR) Emergency Management;Fog/Edge Computing;FirstNet;Internet of Things (IoT);Robots;Unmanned Aerial Vehicles (UAV);Big data;Machine Learning;Distributed Database;Blockchain},
doi={10.1109/IEMCON.2019.8936153},
ISSN={2644-3163},
month={Oct},}
@ARTICLE{9540708,
author={Uyoata, Uyoata and Mwangama, Joyce and Adeogun, Ramoni},
journal={IEEE Access}, title={Relaying in the Internet of Things (IoT): A Survey},
year={2021},
volume={9},
number={},
pages={132675-132704},
abstract={The deployment of relays between Internet of Things (IoT) end devices and gateways can improve link quality. In cellular-based IoT, relays have the potential to reduce base station overload. The energy expended in single-hop long-range communication can be reduced if relays listen to transmissions of end devices and forward these observations to gateways. However, incorporating relays into IoT networks faces some challenges. IoT end devices are designed primarily for uplink communication of small-sized observations toward the network; hence, opportunistically using end devices as relays needs a redesign of both the medium access control (MAC) layer protocol of such end devices and possible addition of new communication interfaces. Additionally, the wake-up time of IoT end devices needs to be synchronized with that of the relays. For cellular-based IoT, the possibility of using infrastructure relays exists, and noncellular IoT networks can leverage the presence of mobile devices for relaying, for example, in remote healthcare. However, the latter presents problems of incentivizing relay participation and managing the mobility of relays. Furthermore, although relays can increase the lifetime of IoT networks, deploying relays implies the need for additional batteries to power them. This can erode the energy efficiency gain that relays offer. Therefore, designing relay-assisted IoT networks that provide acceptable trade-offs is key, and this goes beyond adding an extra transmit RF chain to a relay-enabled IoT end device. There has been increasing research interest in IoT relaying, as demonstrated in the available literature. Works that consider these issues are surveyed in this paper to provide insight into the state of the art, provide design insights for network designers and motivate future research directions.},
keywords={Relays;Internet of Things;Logic gates;Wireless communication;Device-to-device communication;5G mobile communication;Wireless sensor networks;Cooperative communication;energy harvesting;Internet of Things;federated learning;IoT relaying;relay networks;relay selection;secure relaying;SWIPT;UAV;machine learning;artificial intelligence},
doi={10.1109/ACCESS.2021.3112940},
ISSN={2169-3536},
month={},}
@INPROCEEDINGS{8343706,
author={Zhu, Mingzhu and Wang, Hongbo},
booktitle={2017 6th International Conference on Computer Science and Network Technology (ICCSNT)}, title={Fast detection of moving object based on improved frame-difference method},
year={2017},
volume={},
number={},
pages={299-303},
abstract={It is difficult to detect the moving object in the video which is captured with the moving camera, and it costs a lot of time to use current method of object detection, because there is a large false rate based on the basic method of moving object detection. In this paper, we propose an improved frame-difference method, which can shorten the running time and improve the accuracy of the object detection. The results of the experiment show that after adding the improved frame-difference method, the detection speed is increased by 21.06 times, the image detection accuracy is improved about 8%. The algorithm is robust and it can be adapted to different scenes including indoor and outdoor. It could be applied to the field of artificial intelligence, such as Intelligent Driving, UAV aerial detection technology and so on.},
keywords={Object detection;Cameras;Feature extraction;Streaming media;Image recognition;Machine learning algorithms;Artificial intelligence;Artificial Intelligence;moving object detection;frame-difference;robust},
doi={10.1109/ICCSNT.2017.8343706},
ISSN={},
month={Oct},}
@INPROCEEDINGS{9564996,
author={Wang, Zhuolin and Yu, Zhenhua and Liu, Yongxin and Song, Houbing},
booktitle={2021 IEEE International Conference on Signal Processing, Communications and Computing (ICSPCC)}, title={Abnormal Data Detection of Unmanned Aerial Vehicles Based on Double Shortcuts ZB-ResNet},
year={2021},
volume={},
number={},
pages={1-6},
abstract={Unmanned aerial vehicles (UAVs) are unmanned aircrafts operated by radio remote control and programmed control equipment. Due to their small size, low cost, and high flexibility, UAV s are widely used in military and civilian fields. Along with the broad applications of UAVs and the significant advancement of information technologies, they also face cyber threats. Among them, false spoofing is a typical cyber-attack. If this attack hits UAV s, it could result in damage to property and the release of private data or classified documents. In this paper, we propose the Double Shortcuts Zero-Bias Residual Network (Double Shortcuts ZB-ResNet) with small storage capacity and low time complexity for abnormal data detection of UAVs. It is designed by combining double shortcuts residual blocks and Zero-Bias (ZB) fully connected layer to anomaly detections. By comparing with the experimental results of the improved Convolutional Neural Networks with ZB layer, the detection accuracy of the Double Shortcuts ZB-ResNet model is improved by nearly two percentage points.},
keywords={Training;Signal processing algorithms;Signal processing;Fingerprint recognition;Military aircraft;Unmanned aerial vehicles;Time complexity;Security of unmanned aerial vehicles;deep learning;abnormal data detection},
doi={10.1109/ICSPCC52875.2021.9564996},
ISSN={},
month={Aug},}
@INPROCEEDINGS{9093284,
author={Bondi, Elizabeth and Jain, Raghav and Aggrawal, Palash and Anand, Saket and Hannaford, Robert and Kapoor, Ashish and Piavis, Jim and Shah, Shital and Joppa, Lucas and Dilkina, Bistra and Tambe, Milind},
booktitle={2020 IEEE Winter Conference on Applications of Computer Vision (WACV)}, title={BIRDSAI: A Dataset for Detection and Tracking in Aerial Thermal Infrared Videos},
year={2020},
volume={},
number={},
pages={1736-1745},
abstract={Monitoring of protected areas to curb illegal activities like poaching and animal trafficking is a monumental task. To augment existing manual patrolling efforts, unmanned aerial surveillance using visible and thermal infrared (TIR) cameras is increasingly being adopted. Automated data acquisition has become easier with advances in unmanned aerial vehicles (UAVs) and sensors like TIR cameras, which allow surveillance at night when poaching typically occurs. However, it is still a challenge to accurately and quickly process large amounts of the resulting TIR data. In this paper, we present the first large dataset collected using a TIR camera mounted on a fixed-wing UAV in multiple African protected areas. This dataset includes TIR videos of humans and animals with several challenging scenarios like scale variations, background clutter due to thermal reflections, large camera rotations, and motion blur. Additionally, we provide another dataset with videos synthetically generated with the publicly available Microsoft AirSim simulation platform using a 3D model of an African savanna and a TIR camera model. Through our benchmarking experiments on state-of-the-art detectors, we demonstrate that leveraging the synthetic data in a domain adaptive setting can significantly improve detection performance. We also evaluate various recent approaches for single and multi-object tracking. With the increasing popularity of aerial imagery for monitoring and surveillance purposes, we anticipate this unique dataset to be used to develop and evaluate techniques for object detection, tracking, and domain adaptation for aerial, TIR videos.},
keywords={Videos;Cameras;Surveillance;Animals;Task analysis;Benchmark testing},
doi={10.1109/WACV45572.2020.9093284},
ISSN={2642-9381},
month={March},}
@ARTICLE{8795113,
author={Rosales, C. and Tosetti, S. and Soria, C. and Rossomando, F.},
journal={IEEE Latin America Transactions}, title={Neural Adaptive PID Control of a Quadrotor using EFK},
year={2018},
volume={16},
number={11},
pages={2722-2730},
abstract={In this paper, we present a novel trajectory tracking algorithm for a four-rotor air vehicle (quadrotor). The PID controller is developed following an adaptive neuronal technique, and the discrete theory of Lyapunov verifies its stability. Also, the neuronal identification of the UAV dynamic model is presented. Besides, an extended Kalman filter is used in order to filter the signals from the aerial vehicle that are contaminated by measurement noises, and that can affect the quality of the identification. Then, the output errors are re-propagated to adjust the PID gains to reduce the control errors. Finally, the experimental results are presented using a four-rotor aerial vehicle (quadrotor), by comparing the presented proposal with a classical fixed-gain PID.},
keywords={Adaptation models;Kalman filters;Unmanned aerial vehicles;IEEE transactions;PI control;PD control;Stability analysis;Adaptive PID;Discrete Stability Analysis;Identification;Neural Networks;Quadrotor},
doi={10.1109/TLA.2018.8795113},
ISSN={1548-0992},
month={November},}
@INPROCEEDINGS{7845501,
author={Renwick, Jason D. and Klein, Levente J. and Hamann, Hendrik F.},
booktitle={2016 IEEE 3rd World Forum on Internet of Things (WF-IoT)}, title={Drone-based reconstruction for 3D geospatial data processing},
year={2016},
volume={},
number={},
pages={729-734},
abstract={Urban air quality affects health and well-being of more than half of the world's population. Measurement, modeling and real time action on pollution sources can alleviate their impact. A preliminary study for drone-based image acquisition and processing steps required for 3D reconstruction of potential pollution sources is presented. The 3D surface terrain models combined with sensor data are inputs into air pollution models for visualization, understanding and potential mitigation of methane plumes. Scaling these technologies across large areas requires the integration of big geospatial data with modeling, machine learning, and image processing.},
keywords={Drones;Cameras;Geospatial analysis;Three-dimensional displays;Transforms;Satellites;Data processing;Drones;Unmanned Air Vehicle;Internet of Things;Smart Cities;Open Source;IoT;UAV;Air Quality Monitoring},
doi={10.1109/WF-IoT.2016.7845501},
ISSN={},
month={Dec},}
@INPROCEEDINGS{8203456,
author={Michael, George and Efstathiou, Nectarios and Mantis, Kyriacos and Theocharides, Theocharis and Pau, Danilo},
booktitle={2017 IFIP/IEEE International Conference on Very Large Scale Integration (VLSI-SoC)}, title={Intelligent embedded and real-time ANN-based motor control for multi-rotor unmanned aircraft systems},
year={2017},
volume={},
number={},
pages={1-6},
abstract={Constant technological advancements in commercial multirotor unmanned aerial vehicles (drones) resulted in their deployment in more and more applications, ranging from entertainment to disaster management and many more domains. However, in contrast to their powerful and diverse entrance into our lifestyle and society, they do not yet provide sufficient intrinsic fail-safe mechanisms to prevent accidents that may occur due to technical problems or unforeseen flight incidents such as turbulent winds, inexperienced pilots, and so on. Therefore, in the current study, we propose the use of an integrated intelligent motor controller, which is trained to recognize incidents directly from the on-board sensors (barometer, gyroscope, compass and accelerometer) and react in real-time, adjusting the drone's motors. The goal is to provide a small, intelligent, low-power, real-time, built-in controller for multirotor UAVs that will be able to understand a dangerous scenario right before it happens, start taking counter measures to keep the drone safe, and provide the pilot with a bigger reaction-time window. We propose the use of an artificial neural network, implemented in a lightweight embedded processing board, that is able to recognize and react in real-time to various turbulent situations. Experimental results suggest that our controller is able to respond properly and timely to wind changes (turbulence) allowing the drone to maintain its expected state and path.},
keywords={Drones;Rotors;Real-time systems;Neural networks;Training;Intelligent sensors},
doi={10.1109/VLSI-SoC.2017.8203456},
ISSN={2324-8440},
month={Oct},}
@INPROCEEDINGS{8170439,
author={Choi, Yunho and Hwang, Inhwan and Oh, Songhwai},
booktitle={2017 IEEE International Conference on Multisensor Fusion and Integration for Intelligent Systems (MFI)}, title={Wearable gesture control of agile micro quadrotors},
year={2017},
volume={},
number={},
pages={266-271},
abstract={Quadrotor unmanned aerial vehicles (UAVs) have seen a surge of use in various applications due to its structural simplicity and high maneuverability. However, conventional control methods using joysticks prohibit novices from getting used to maneuvering quadrotors in short time. In this paper, we suggest the use of a wearable device, such as a smart watch, as a new remote-controller for a quadrotor. The user's command is recognized as gestures using the 9-DoF inertial measurement unit (IMU) of a wearable device through a recurrent neural network (RNN) with long short-term memory (LSTM) cells. Our implementation also makes it possible to align the heading of a quadrotor with the heading of the user. Our implementation allows nine different gestures and the trained RNN is used for real-time gesture recognition for controlling a micro quadrotor. The proposed system exploits available sensors in a wearable device and a quadrotor as much as possible to make the gesture-based control intuitive. We have experimentally validated the performance of the proposed system by using a Samsung Gear S smart watch and a Crazyflie Nano Quadcopter.},
keywords={Gesture recognition;Sensor systems;Performance evaluation;Cameras;Unmanned aerial vehicles;Recurrent neural networks},
doi={10.1109/MFI.2017.8170439},
ISSN={},
month={Nov},}
@INPROCEEDINGS{8324240,
author={Lerro, Angelo and Battipede, Manuela and Gili, Piero and Brandl, Alberto},
booktitle={2017 Intelligent Systems Conference (IntelliSys)}, title={Survey on a neural network for non linear estimation of aerodynamic angles},
year={2017},
volume={},
number={},
pages={929-935},
abstract={Unmanned Aerial Vehicles (UAV) design may involve issues on redundancy of the systems due to restricted available space and allowable weight. Virtual sensors offer great advantages from this point of view and several research projects carry out more or less complicated solutions in order to estimate a signal without applying a physical sensor. This approach brings to a reduction of the overall cost and to improve the Reliability, Availability, Maintainability and Safety (RAMS) performance. The patented technology named Smart-ADAHRS (Smart - Attitude and Heading Reference System) is a powerful technique presented during previous research for estimation of the aerodynamic angles. This algorithm is based on Artificial Neural Network (ANN) and receive inputs from on-board sensors only. Whereas previous studies considered also the signals coming from the Flight Control System (FCS), this work presents the important simplification of not considering them in the input vector. This paper resumes the previous results obtained in simulated environment with former neural network-based estimators. Then, a comparison of the results obtained by the new estimator, applying the reduced input vector in different environments, is carried out. Moreover, it re-discusses accuracy by means of a new test case that consider simulated realistic faults and noise. Eventually, a first analysis around performance in operative environment is conducted using data obtained from flight test campaigns. Results show how accuracy is preserved both in realistic situation and critical circumstances.},
keywords={Aerodynamics;Sensors;Estimation;Atmospheric modeling;Aircraft;Neural networks;Aerospace control;Aerodynamic angles;neural network;virtual sensor;operative environment;validation},
doi={10.1109/IntelliSys.2017.8324240},
ISSN={},
month={Sep.},}
@INPROCEEDINGS{9021981,
author={Chen, Changrui and Zhang, Yu and Lv, Qingxuan and Wei, Shuo and Wang, Xiaorui and Sun, Xin and Dong, Junyu},
booktitle={2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)}, title={RRNet: A Hybrid Detector for Object Detection in Drone-Captured Images},
year={2019},
volume={},
number={},
pages={100-108},
abstract={Objects captured by UAVs and drones in city scenes usually come in various sizes and are extremely dense. Therefore, we propose a hybrid detector, called RRNet, for object detection in such challenging tasks. We mix up the anchor-free detectors with a re-regression module to construct the detector. The discard of prior anchors released our model from the difficult task on bounding-box size regression so that we achieved a better performance in multi-scale object detection in the dense scene. The anchor-free based detector firstly generates the coarse boxes. A re-regression module is then applied on the coarse predictions to produce accurate bounding boxes. In addition, we introduce an adaptive resampling augmentation strategy to logically augment the data. Our experiments demonstrate that RRNet significantly outperforms all the state-of-the-art detectors on VisDrone2018 dataset. We are runner-up to the ICCV VisDrone2019 Object Detection in Images Challenge, and we achieve the best AP50, AR10, and AR100. Source code will be published on our official website in due course.},
keywords={Detectors;Object detection;Drones;Proposals;Roads;Feeds;Task analysis;Object Derection;Deep Learning},
doi={10.1109/ICCVW.2019.00018},
ISSN={2473-9944},
month={Oct},}
@INPROCEEDINGS{8832957,
author={Huang, Haoran and Liang, Lidong and Zhao, Gaopeng and Yang, Yi and Ou, Kai},
booktitle={2019 Chinese Control And Decision Conference (CCDC)}, title={Railway Clearance Intrusion Detection in Aerial Video Based on Convolutional Neural Network},
year={2019},
volume={},
number={},
pages={1644-1648},
abstract={Aiming at the problems of dynamic background and various types of objects in railway clearance intrusion detection in UAV aerial video, a railway clearance intrusion detection algorithm in aerial video based on convolutional neural network is proposed. Firstly, the rail track region is affirmed in aerial single frame image by the linear segmentation detection algorithm, line segments merging and line segments screening; Then, the improved convolution neural network model is used to detect and classify rail track region image in single frame image; Finally, the single frame detection result is optimized by the inter-frame correlation of the video to obtain the final result of the railway clearance intrusion detection in aerial video. Experiments on a self-built dataset show that the proposed method can effectively detect various types of objects in the aerial video.},
keywords={Rails;Rail transportation;Intrusion detection;Convolutional neural networks;Image segmentation;Training;Merging;machine vision;clearance intrusion detection;aerial video;convolutional neural network;line detection},
doi={10.1109/CCDC.2019.8832957},
ISSN={1948-9447},
month={June},}
@INPROCEEDINGS{9015131,
author={Abderrahmene, Senoussaoui and Mohammed, Chenafa and Abderrahmane, Kacimi and Rachida, Hocine},
booktitle={2019 International Conference on Advanced Electrical Engineering (ICAEE)}, title={Neural network NARMA-L2 control of a Twin Rotor MIMO System},
year={2019},
volume={},
number={},
pages={1-6},
abstract={This work presents the design of a nonlinear autoregressive-moving average controller (NARLA-L2) applied to a TWIN ROTOR MIMO SYSTEM (TRMS). This system simulates the dynamic of a helicopter, which is a kind of UAVs; they are the interest of nowadays researches, in particular the control of this system. Because of the difficulty presented in modeling of such non linear systems, a non model control technique is used -to avoid this hard and not exact task-based on neural network structure.So this method is applicable for the control of this type of complex nonlinear system, and its strength is that it is not based on physical modeling that is often far from the real system, thus the ease of synthesizing the corrector with good performances in trajectory tracking and disturbances rejection.},
keywords={Mathematical model;Rotors;Transmission line measurements;Autoregressive processes;Neural networks;MIMO communication;Control systems;neural network;intellegent control;non-model control;NARMA-L2;non linear system control;TWIN ROTOR MIMO SYSTEM(TRMS)},
doi={10.1109/ICAEE47123.2019.9015131},
ISSN={},
month={Nov},}
@INPROCEEDINGS{6693903,
author={Tang, Yimeng and Patton, Ron J.},
booktitle={2013 Conference on Control and Fault-Tolerant Systems (SysTol)}, title={Reconfigurable flight control using feedback linearization with online Neural Network adaption},
year={2013},
volume={},
number={},
pages={324-329},
abstract={This work suggests a design approach building on past results in the area of adaptive Neural Network (NN) based reconfigurable flight control which has been successfully utilized for a variety of aerospace applications, while incorporating recent advances in the areas of output feedback and NN adaptation algorithms. The paradigm is based on feedback linearization and synthesis of a fixed-gain dynamic compensator, whilst incorporating a neural network by using concurrent update information to compensate for model uncertainties, system faults and external disturbances. The concurrent learning networks update law is simplified and restructured for better and easy use during applications. The stability and reconfigurable ability of the improved control system based on the concurrent learning algorithm is validated with simulation performances of the nonlinear Machan UAV.},
keywords={Artificial neural networks;Radio frequency;Stability analysis;Xenon;Aircraft;Approximation methods},
doi={10.1109/SysTol.2013.6693903},
ISSN={2162-1209},
month={Oct},}
@INPROCEEDINGS{9558923,
author={Aktaş, Mustafa and Ateş, Hasan Fehmi},
booktitle={2021 6th International Conference on Computer Science and Engineering (UBMK)}, title={Small Object Detection and Tracking from Aerial Imagery},
year={2021},
volume={},
number={},
pages={688-693},
abstract={Object detection and tracking from airborne imagery draws attention to the parallel development of UAV systems and computer vision technologies. Aerial imagery has its own unique challenges that differ from the training set of modern-day object detectors, since it is made of images of larger areas compared to the regular datasets and the objects are very small on the contrary. These problems do not allow us to use common object detection models. The main purpose of this paper is to make modifications to the Faster-RCNN (FRCNN) model, then leverage it for small object detection and tracking from the aerial imagery. It is aimed to use both spatial and temporal information from the image sequence, as appearance information alone is insufficient. The anchors in the Region Proposal Network (RPN) stage will be adjusted for small objects. Also, intersection over union (IoU) is optimized for small objects. After improving detection performance, The DeepSORT algorithm is inserted right after the Region of Interest (ROI Head) to track the objects. The results show that the proposed model has good performance on the VisDrone-2019 dataset. Detection performance becomes considerably better than the original FRCNN and the algorithms that are evaluated in the VisDrone-2019 VID challenge. After completing the proposed modifications, the AP-AP50 values reached 14.07-29.41 from 8.08-18.70, which means approximately 75% improvement.},
keywords={Training;Computer science;Computer vision;Head;Object detection;Detectors;Approximation algorithms;Surveillance;Small Object Detection;Deep Learning},
doi={10.1109/UBMK52708.2021.9558923},
ISSN={2521-1641},
month={Sep.},}
@INPROCEEDINGS{8798141,
author={Zhang, Guoxiang and Alcala, Jose and Ng, Jeffrey and Chen, Mighty and Wu, Xiangyu and Mueller, Mark and Chen, YangQuan},
booktitle={2019 International Conference on Unmanned Aircraft Systems (ICUAS)}, title={Embedding Consequence Awareness in Unmanned Aerial Systems with Generative Adversarial Networks},
year={2019},
volume={},
number={},
pages={138-143},
abstract={Small unmanned aerial systems (sUAS) are becoming more prevalent, driven by consumer interest and their potential for revolutionizing aspects of commercial applications, such as delivery of urgent goods. The expected ubiquity of such systems raises concerns about their safety, and the ability of such autonomous systems to operate safely in densely populated areas (where their value will be greatest). In this paper, we outline a new framework aiming to add an additional layer of safety to aerial systems operated by a human pilot or autopilot by monitoring the UAVs environment for visual cues, and monitoring the human pilot for signs of distraction. The system will endow a UAS with the ability to reason about its safety, and the consequences of safety failures during its operation. The UAS will furthermore continuously reason about possible safety maneuvers in response to likely failures - in the event of an emergency, the vehicle can then execute its last safe maneuver, thus reducing the systems impending danger. Embedding consequence awareness in sUAS is an obvious appeal to safer and more insurable missions. For pilot skill level awareness, a method utilizing generative adversarial networks, which improves pilot skill level classification accuracy in our experiments, is proposed to compensate limited training data availability.},
keywords={Drones;Safety;Neural networks;Observers;Generative adversarial networks;Visualization;Training data},
doi={10.1109/ICUAS.2019.8798141},
ISSN={2575-7296},
month={June},}
@INPROCEEDINGS{8967919,
author={Koumis, Alexander S. and Preiss, James A. and Sukhatme, Gaurav S.},
booktitle={2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)}, title={Estimating Metric Scale Visual Odometry from Videos using 3D Convolutional Networks},
year={2019},
volume={},
number={},
pages={265-272},
abstract={We present an end-to-end deep learning approach for performing metric scale-sensitive regression tasks such visual odometry with a single camera and no additional sensors. We propose a novel 3D convolutional architecture, 3DC-VO, that can leverage temporal relationships over a short moving window of images to estimate linear and angular velocities. The network makes local predictions on stacks of images that can be integrated to form a full trajectory. We apply 3DC-VO to the KITTI visual odometry benchmark and the task of estimating a pilot’s control inputs from a first-person video of a quadrotor flight. Our method exhibits increased accuracy relative to comparable learning-based algorithms trained on monocular images. We also show promising results for quadrotor control input prediction when trained on a new dataset collected with a UAV simulator.},
keywords={Measurement;Training;Three-dimensional displays;Network architecture;Cameras;Prediction algorithms;Trajectory},
doi={10.1109/IROS40897.2019.8967919},
ISSN={2153-0866},
month={Nov},}
@INPROCEEDINGS{9081802,
author={Tian, Yifan and Njilla, Laurent and Raja, Ashok and Yuan, Jiawei and Yu, Shucheng and Steinbacher, Alexander and Tong, Thaniel and Tinsley, Jayson},
booktitle={2019 IEEE/AIAA 38th Digital Avionics Systems Conference (DASC)}, title={Cost-Effective NLOS Detection for Privacy Invasion Attacks by Consumer Drones},
year={2019},
volume={},
number={},
pages={1-7},
abstract={The pervasive operation of customer drones, or small-scale unmanned aerial vehicles (UAVs), has raised serious concerns about their privacy threats to the public. In recent years, privacy invasion events caused by customer drones have been frequently reported. Given such a fact, timely detection of invading drones has become an emerging task. Existing solutions using active radar, video or acoustic sensors are usually too costly (especially for individuals) or exhibit various constraints (e.g., requiring visual line of sight). Recent research on drone detection with passive RF signals provides an opportunity for low-cost deployment of drone detectors on commodity wireless devices. However, the state of the arts in this direction rely on line-of-sight (LOS) RF signals, which makes them only work under very constrained conditions. The support of more common scenarios, i.e., non-line-of-sight (NLOS), is still missing for low-cost solutions. In this paper, we propose a novel detection system for privacy invasion caused by customer drone. Our system is featured with accurate NLOS detection with low-cost hardware (under $50). By exploring and validating the relationship between drone motions and RF signal under the NLOS condition, we find that RF signatures of drones are somewhat “amplified” by multipaths in NLOS. Based on this observation, we design a two-step solution which first classifies received RSS measurements into LOS and NLOS categories; deep learning is then used to extract the signatures and ultimately detect the drones. Our experimental results show that LOS and NLOS signals can be identified at accuracy rates of 98.4% and 96% respectively. Our drone detection rate for NLOS condition is above 97% with a system implemented using Raspberry PI 3 B+.},
keywords={},
doi={10.1109/DASC43569.2019.9081802},
ISSN={2155-7209},
month={Sep.},}
@INPROCEEDINGS{9150631,
author={Koksal, Aybora and Ince, Kutalmis Gokalp and Aydin Alatan, A.},
booktitle={2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)}, title={Effect of Annotation Errors on Drone Detection with YOLOv3},
year={2020},
volume={},
number={},
pages={4439-4447},
abstract={Following the recent advances in deep networks, object detection and tracking algorithms with deep learning backbones have been improved significantly; however, this rapid development resulted in the necessity of large amounts of annotated labels. Even if the details of such semi-automatic annotation processes for most of these datasets are not known precisely, especially for the video annotations, some automated labeling processes are usually employed. Unfortunately, such approaches might result with erroneous annotations. In this work, different types of annotation errors for object detection problem are simulated and the performance of a popular state-of-the-art object detector, YOLOv3, with erroneous annotations during training and testing stages is examined. Moreover, some inevitable annotation errors in Anti-UAV Challenge dataset is also examined in this manner, while proposing a solution to correct such annotation errors of this valuable data set.},
keywords={Detectors;Training;Feature extraction;Labeling;Real-time systems;Measurement;Drones},
doi={10.1109/CVPRW50498.2020.00523},
ISSN={2160-7516},
month={June},}
@INPROCEEDINGS{9096949,
author={Andrew, William and Greatwood, Colin and Burghardt, Tilo},
booktitle={2020 IEEE Winter Applications of Computer Vision Workshops (WACVW)}, title={Fusing Animal Biometrics with Autonomous Robotics: Drone-based Search and Individual ID of Friesian Cattle (Extended Abstract)},
year={2020},
volume={},
number={},
pages={38-43},
abstract={This work covers the robotic drone integration of a re-identification system for Friesian Cattle. We have built a computationally-enhanced M100 UAV platform with an on-board deep learning inference system for integrated computer vision and navigation able to autonomously find and visually identify by coat pattern individual Holstein Friesian cattle in freely moving herds. For autonomous drone-based identification we describe an approach that utilises three deep convolutional neural network architectures running live onboard the aircraft; that is, a YoloV2-based species detector, a dual-stream Convolutional Neural Network (CNN) delivering exploratory agency and an InceptionV3-based biometric Long-term Recurrent Convoluational Network (LRCN) for individual animal identification. We evaluate the performance of components offline, and also online via real-world field tests of autonomous low-altitude flight in a farm environment. The presented proof-of-concept system is a successful step towards autonomous biometric identification of individual animals from the air in open pasture environments and inside farms for tag-less AI support in farming and ecology. The work is published in full in IROS 2019 [4].},
keywords={Cows;Navigation;Task analysis;Training;Biometrics (access control);Cameras},
doi={10.1109/WACVW50321.2020.9096949},
ISSN={},
month={March},}
@INPROCEEDINGS{9115112,
author={Zhao, Dequn and Li, Xinmeng},
booktitle={2020 Asia-Pacific Conference on Image Processing, Electronics and Computers (IPEC)}, title={Ocean ship detection and recognition algorithm based on aerial image},
year={2020},
volume={},
number={},
pages={218-222},
abstract={Because the image of UAV aerial photography is easy to be affected by light, sea area and other conditions, there are many kinds of ships. Under different conditions, the characteristics of ships are different, which makes the target recognition more difficult. In order to improve the efficiency of sea surface supervision and make the sea surface management more intelligent, an ocean ship detection algorithm based on aerial photography image is proposed. In this paper, the improved Yolo algorithm is mainly used for high-efficiency ship detection of aerial video, which can achieve real-time performance and detection speed of 23fps. In order to improve the accuracy, this paper proposes a standardized mechanism of fixed frame length detection results, which uses deep learning mask RCNN algorithm for fine detection of specific frame images, and the detection map is 85%, which improves the detection speed without affecting the detection speed The accuracy of the algorithm forms an efficient and accurate algorithm for the detection of ships on the sea, which brings convenience to the management of the sea.},
keywords={Yolo algorithm;Mask-RCNN;Ocean vessel;object detection},
doi={10.1109/IPEC49694.2020.9115112},
ISSN={},
month={April},}
@INPROCEEDINGS{8942376,
author={Duan, Tinglin and Punpongsanon, Parinya and Jia, Sheng and Iwai, Daisuke and Sato, Kosuke and Plataniotis, Konstantinos N.},
booktitle={2019 IEEE International Conference on Artificial Intelligence and Virtual Reality (AIVR)}, title={Remote Environment Exploration with Drone Agent and Haptic Force Feedback},
year={2019},
volume={},
number={},
pages={167-1673},
abstract={Camera drones allow exploring remote scenes that are inaccessible or inappropriate to visit in person. However, these exploration experiences are often limited due to insufficient scene information provided by front cameras, where only 2D images or videos are supplied. Combining a camera drone vision with haptic feedback would augment users' spatial understandings of the remote environment. But such designs are usually difficult for users to learn and apply, due to the complexity of the system and unfluent UAV control. In this paper, we present a new telepresence system for remote environment exploration, with a drone agent controlled by a VR mid-air panel. The drone is capable of generating real-time location and landmark details using integrated Simultaneous Location and Mapping (SLAM). The SLAMs' point cloud generations are produced using RGB input, and the results are passed to a Generative Adversarial Network (GAN) to reconstruct 3D remote scenes in real-time. The reconstructed objects are taken advantage of by haptic devices which could improve user experience through haptic rendering. Capable of providing both visual and haptic feedback, our system allows users to examine and exploit remote areas without having to be physically present. An experiment has been conducted to verify the usability of 3D reconstruction result in haptic feedback rendering.},
keywords={Three-dimensional displays;Drones;Haptic interfaces;Cameras;Simultaneous localization and mapping;Rendering (computer graphics);Real-time systems;telepresence, human drone interaction, machine learning, mid air haptic feedback},
doi={10.1109/AIVR46125.2019.00034},
ISSN={},
month={Dec},}
@INPROCEEDINGS{8015012,
author={Wu, Di and Zou, Wenbin and Li, Xia and Zhao, Yong},
booktitle={2017 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)}, title={Kernalised Multi-resolution Convnet for Visual Tracking},
year={2017},
volume={},
number={},
pages={2241-2248},
abstract={Visual tracking is intrinsically a temporal problem. Discriminative Correlation Filters (DCF) have demonstrated excellent performance for high-speed generic visual object tracking. Built upon their seminal work, there has been a plethora of recent improvements relying on convolutional neural network (CNN) pretrained on ImageNet as a feature extractor for visual tracking. However, most of their works relying on ad hoc analysis to design the weights for different layers either using boosting or hedging techniques as an ensemble tracker. In this paper, we go beyond the conventional DCF framework and propose a Kernalised Multi-resolution Convnet (KMC) formulation that utilises hierarchical response maps to directly output the target movement. When directly deployed the learnt network to predict the unseen challenging UAV tracking dataset without any weight adjustment, the proposed model consistently achieves excellent tracking performance. Moreover, the transfered multireslution CNN renders it possible to be integrated into the RNN temporal learning framework, therefore opening the door on the end-to-end temporal deep learning (TDL) for visual tracking.},
keywords={Feature extraction;Target tracking;Visualization;Correlation;Kernel;Training;Object tracking},
doi={10.1109/CVPRW.2017.278},
ISSN={2160-7516},
month={July},}
@INPROCEEDINGS{9627024,
author={Brandenburger, André and Hoffmann, Folker and Charlish, Alexander},
booktitle={2021 IEEE 24th International Conference on Information Fusion (FUSION)}, title={Co-Training an Observer and an Evading Target},
year={2021},
volume={},
number={},
pages={1-8},
abstract={Reinforcement learning (RL) is already widely applied to applications such as robotics, but it is only sparsely used in sensor management. In this paper, we apply the popular Proximal Policy Optimization (PPO) approach to a multi-agent UAV tracking scenario. While recorded data of real scenarios can accurately reflect the real world, the required amount of data is not always available. Simulation data, however, is typically cheap to generate, but the utilized target behavior is often naive and only vaguely represents the real world. In this paper, we utilize multi-agent RL to jointly generate protagonistic and antagonistic policies and overcome the data generation problem, as the policies are generated on-the-fly and adapt continuously. This way, we are able to clearly outperform baseline methods and robustly generate competitive policies. In addition, we investigate explainable artificial intelligence (XAI) by interpreting feature saliency and generating an easy-to-read decision tree as a simplified policy.},
keywords={Training;Adaptation models;Target tracking;Reinforcement learning;Observers;Robot sensing systems;Trajectory},
doi={},
ISSN={},
month={Nov},}
@INPROCEEDINGS{7502544,
author={Wang, Xian and Zhang, Youmin},
booktitle={2016 International Conference on Unmanned Aircraft Systems (ICUAS)}, title={Insulator identification from aerial images using Support Vector Machine with background suppression},
year={2016},
volume={},
number={},
pages={892-897},
abstract={Insulator identification in aerial videos is one of the key procedures to the condition analysis for aerial power line inspections. This paper proposes a novel insulator recognition method for images taken by Unmanned Aerial Vehicles (UAVs) with highly cluttered background, which is to adopt a machine learning algorithm Support Vector Machine (SVM) as a classifier to distinguish insulator from the cluttered background based on Gabor features. An innovative background suppression method is proposed to remove the redundant background information as much as possible. The test results show that not only the proposed method can successfully recognize insulator in the aerial images with complex and cluttered background, but also the background suppression procedure can greatly drop the computational load and reduce faulty classification.},
keywords={Insulators;Support vector machines;Feature extraction;Image recognition;Inspection;Training;Videos},
doi={10.1109/ICUAS.2016.7502544},
ISSN={},
month={June},}
@INPROCEEDINGS{8556769,
author={Das, Aditya and Kol, Patrik and Lundberg, Cody and Doelling, Kris and Sevil, Hakki Erhan and Lewis, Frank},
booktitle={NAECON 2018 - IEEE National Aerospace and Electronics Conference}, title={A Rapid Situational Awareness Development Framework for Heterogeneous Manned-Unmanned Teams},
year={2018},
volume={},
number={},
pages={417-424},
abstract={This paper presents a robust framework for configuring and deploying a heterogeneous team of smart unmanned systems and human agents in dynamic and un-modeled environments to rapidly build mission critical situational awareness with selective details of potential areas of interest, especially focusing on minimized cognitive loading of the human agents. Five key components, namely control, communication, artificial intelligence (AI), platform, and visualization, merge seamlessly into a holistic framework to deliver this rapid situational awareness development capability to the heterogeneous manned unmanned team (MUM-T). In this framework, the overall control is seen as a combination of agent level control and mission level control. A common software, Robot Operating System (ROS), is used to establish communication, and consequently consensus, among the heterogeneous swarm of unmanned systems. These unmanned platforms are customized with co-processing hardware that can execute advanced artificial intelligence machine learning (AI/ML) modules to not only deliver stable and cooperative performance of these unmanned platforms in the swarm but also support human-centric human robot interaction (HRI). Finally, to reduce the cognitive burden on the human agents, a triaged visualization scheme, enabled through mixed reality (MR) technology, is implemented. This paper presents a preliminary proof of concept study for the presented hybrid map (i.e. 2D mapping with 3D detailing) construction framework, tested with a heterogeneous swarm of unmanned aerial vehicles (UAVs) of varying capabilities, teamed with a human operator.},
keywords={Visualization;Three-dimensional displays;Operating systems;Mixed reality;Virtual reality;Unmanned aerial vehicles;Software;Supervised Autonomy;Triaged Visualization;Human Robot Interaction;Consensus Control;Mixed Reality},
doi={10.1109/NAECON.2018.8556769},
ISSN={2379-2027},
month={July},}
@ARTICLE{9220178,
author={Kim, Hyunbum and Ben-Othman, Jalel and Mokdad, Lynda and Son, Junggab and Li, Chunguo},
journal={IEEE Network}, title={Research Challenges and Security Threats to AI-Driven 5G Virtual Emotion Applications Using Autonomous Vehicles, Drones, and Smart Devices},
year={2020},
volume={34},
number={6},
pages={288-294},
abstract={Thanks to comprehensive potential with new access technology, massive bandwidths and ultrahigh reliability, it is highly expected that recent 5G network and beyond 5G network (B5G) will fundamentally influence various autonomous systems, applications and devices. Also, Artificial intelligence (Ai) is expanding its applicability to numerous existing and next generation systems and research branches. Conversely, Ai can be utilized to threaten 5G-enabled components as well as to attack Ai-based systems and machine learning algorithms. So, it is indispensable to investigate new Ai-based security threats and solutions in 5G-enabled smart cities. in this article, we introduce Ai-driven 5G integrated virtual emotion system, called 5G-i-VEmoSYS, which covers Ai-VEmoBAR, Ai-VEmoFLOW, and Ai-VEmoMAP as applications in 5G environments. First, we explain how to operate those Ai-driven promising applications in 5G-enabled components including autonomous vehicles, smart UAVs or drones. Also, we describe how to perform those applications in public areas and private areas with different perspectives. Then, we carefully deal with research challenges, security threats and issues according to the proposed 5G-i-VEmoSYS.},
keywords={5G mobile communication;Autonomous vehicles;Security;Smart devices;Drones;Smart cities},
doi={10.1109/MNET.011.2000245},
ISSN={1558-156X},
month={November},}
@INPROCEEDINGS{8797943,
author={Choi, Youngjun and Pate, David and Briceno, Simon and Mavris, Dimitri N.},
booktitle={2019 International Conference on Unmanned Aircraft Systems (ICUAS)}, title={Rapid and Automated Urban Modeling Techniques for UAS Applications},
year={2019},
volume={},
number={},
pages={838-847},
abstract={Urban models for testing UAV path-planning algorithms commonly apply simple representations using cuboid or cylinderical shapes which may not capture the characteristics of a urban environment. To address this limitation of existing urban models, this paper presents two urban modeling techniques for an unmanned aircraft flight simulation in an urban environment. The first proposed urban modeling technique is an airborne LiDAR source-based approach that incorporates machine learning algorithms to identify the number of buildings and characterize them from the LiDAR information. The second proposed urban modeling technique is an artificial urban modeling technique without any airborne LiDAR resources that applies an adaptive spacing method, an iterative algorithm to define an artificial urban environment. Unlike the LiDAR source-based approach that creates an approximated urban model, the adaptive spacing-based urban modeling algorithm generates an artificial urban environment that is visually different from a reference city, but has similar the characteristics to it. To demonstrate the two proposed urban modeling techniques, numerical simulations are conducted using open-source datasets to construct several realistic urban models.},
keywords={Urban planning;Laser radar;Buildings;Three-dimensional displays;Computational modeling;Collision avoidance},
doi={10.1109/ICUAS.2019.8797943},
ISSN={2575-7296},
month={June},}
@INPROCEEDINGS{7587103,
author={Zhong, Hang and Li, Shushuai and Wang, Yaonan and Liu, Hongjian},
booktitle={2016 12th IEEE/ASME International Conference on Mechatronic and Embedded Systems and Applications (MESA)}, title={Adaptive robust RBFNNs-based model estimator for a small quadrotor aircraft robot},
year={2016},
volume={},
number={},
pages={1-6},
abstract={This paper presents an on-line estimator that incorporates adaptive MIMO radical basis function neural networks (RBFNNs) for model identification of quadrotor unmanned aerial vehicles (UAVs). The inputs and outputs of quadrotor aircrafts can be obtained from dynamic models or real attitude and position sensors. The adaptive learning rate is employed in the gradient descent method for the update of the weights of RBFNNs, and Lyapunov approach guarantees the stability of the global convergence of the modeling errors. The Welsch functions are also employed as the error functions to get rid of the influence from the noise due to disturbances like wind gusts. Simulation results using Robotics Toolbox for Matlab verify the effectiveness and robustness of the proposed estimator compared with results of traditional RBFNNs. Experiment results from real aircraft platform show that RBFNNs combining adaptive learning rate and Welsch error functions can approximate the overall system with high accuracy and robustness to disturbances.},
keywords={Atmospheric modeling;Aircraft;Mathematical model;Adaptation models;Robustness;Robots;MIMO;Quadrotor;model estimator;RBFNNs;adaptive learning rate;Welsch functions},
doi={10.1109/MESA.2016.7587103},
ISSN={},
month={Aug},}
@ARTICLE{9233348,
author={Wang, Xiangtong and Li, Wei and Yang, Menglong and Cheng, Peng and Liang, Binbin},
journal={IEEE Access}, title={Unsupervised Monocular Training Method for Depth Estimation Using Statistical Masks},
year={2020},
volume={8},
number={},
pages={191530-191541},
abstract={Recently, unsupervised monocular training methods based on convolutional neural networks have already shown surprisingly progress in improving the accuracy of depth estimation. However, the performance of these methods suffers deeply from problematic pixels such as occluded pixels, low-texture pixels, and so on. In this paper, we introduce a method to a mask by the statistic of error maps for segmenting the problematic pixels. Different from the conventional methods which use additional segmentation networks to classify problematic pixels, we use a multi-task learning architecture to generate identical mask, mean mask, and variance mask for filtering the problematic pixels. Experimental results show that our proposed method has satisfactory performance compared with other relative methods on the KITTI dataset. Moreover, we also apply our method to the UAV dataset VisDrone, and the results also indicate the effectiveness of the method in detecting moving objects.},
keywords={Training;Estimation;Cameras;Adaptive optics;Optical imaging;Optical filters;Three-dimensional displays;Monocular depth estimation;error map;problematic pixels;statistical masks},
doi={10.1109/ACCESS.2020.3032582},
ISSN={2169-3536},
month={},}
@INPROCEEDINGS{9058045,
author={Sukanya and Dubey, Gaurav},
booktitle={2020 10th International Conference on Cloud Computing, Data Science Engineering (Confluence)}, title={Segmentation and Detection of Road Region in Aerial Images using Hybrid CNN-Random Field Algorithm},
year={2020},
volume={},
number={},
pages={502-506},
abstract={Road detection and segmentation is an important aspect in navigation system and is widely used to detect new roads and patterns in the region. These system has the main objective to help navigate the autonomous vehicle and robot on the ground. Road detection is very useful in finding valid road path where the vehicle can go for supportive vehicles preventing the collision with the obstacles, object detection on the road and other necessary information exchange. It has a variety of uses such as the disaster monitoring, traffic monitoring, crop monitoring, border surveillance, security and so on. There are several techniques used for detection and segmentation purpose of roads such as Artificial Neural Network, Support Vector Machine (SVM), Self-Organizing Map (SOM), Convolution Neural Network (CNN), and Deep learning techniques. In this paper, a new technique for road detection and segmentation is proposed which includes a combination algorithm of CNN and Random Field segmentation for road maps using aerial images. This road detection and segmentations give alternative solution for road classification and detection with a higher accuracy. In this system normally accuracy (ACC) have an average range of 97.7%.},
keywords={Roads;Image segmentation;Traffic control;Surveillance;Convolution;Classification algorithms;Road Detection;Image Processing;Convolution Neural Network;Segmentation;MATLAB},
doi={10.1109/Confluence47617.2020.9058045},
ISSN={},
month={Jan},}
@ARTICLE{9357330,
author={Pokhrel, Shiva Raj},
journal={IEEE Sensors Journal}, title={Blockchain Brings Trust to Collaborative Drones and LEO Satellites: An Intelligent Decentralized Learning in the Space},
year={2021},
volume={21},
number={22},
pages={25331-25339},
abstract={In this paper, we develop a foundation for a constellation of Low Earth Orbit (LEO) satellite IoT by constructing a Blockchain-based framework for continual knowledge sharing and learning collaboratively. This approach is directly applicable for a swarm of Unmanned Aerial Vehicles (UAVs). We ablate Federated Learning (FL) successful features as a basis to ensure high precision of learning inferences at timescales relevant to the underlying time-varying space network and channel dynamics. In such a dynamic setting, there is always a likelihood that miners may be compromised or fail to propagate information in time because of some intrinsic factors such as channel impairments, satellite handovers and attacks. Such transmission failures often lead to undesirable forking events in the Blockchain. Consequently, maintaining a low energy consumption and smallish delay in such an erratic network is highly nontrivial and challenging. To quantify the impacts of the forking and minimize the occurrence of such unwanted events and their adverse effects, we develop a procedure to estimate the expected energy consumption for a given set of miners, block transmissions, and LEOs’ or UAVs’ mobility. Besides, we shed light on deep learning-based resource allocation for mobile mining and demonstrate the synergic gain of FL with Blockchain.},
keywords={Blockchain;Drones;Delays;Satellites;Low earth orbit satellites;Sensors;Collaborative work;Blockchain;federated learning;forking;low earth orbit (LEO) satellites;mobile miners;satellite-IoT;UAVs},
doi={10.1109/JSEN.2021.3060185},
ISSN={1558-1748},
month={Nov},}
@INPROCEEDINGS{9596683,
author={Rezo, M. and Čagalj, K.-M. and Ušljebrka, I. and Kovačić, Z.},
booktitle={2021 44th International Convention on Information, Communication and Electronic Technology (MIPRO)}, title={Collecting Information for Biomass Estimation in Mariculture with a Heterogeneous Robotic System},
year={2021},
volume={},
number={},
pages={1125-1130},
abstract={In this paper, we address the problem of fish stock estimation in marine fisheries using a heterogeneous robotic system consisting of unmanned aerial vehicles (UAVs) and unmanned underwater vehicles (UUVs). UAVs take aerial photographs of the cage during fish feeding, while UUVs take photographs of fish from top to bottom in the cage. The photos and videos obtained provide the input data for estimating the number of fish and the amount of biomass of fish in the cage. The paper analyzes a number of factors that affect the accuracy of the estimate. Preliminary results obtained with an approximate method for estimating the number of fish, based on the processing of images obtained in a virtual simulator and resembling aerial photographs of fish taken during feeding, are described. The results obtained show that this problem is extremely complex and that it is worth trying to use machine learning and artificial intelligence methods to achieve the desired maximum estimation error of less than 20%.},
keywords={Graphical models;Estimation;Machine learning;Fish;Unmanned underwater vehicles;Unmanned aerial vehicles;Biomass;marine fish farming;heterogeneous robotics systems;fish counting;fish biomass estimation},
doi={10.23919/MIPRO52101.2021.9596683},
ISSN={2623-8764},
month={Sep.},}
@ARTICLE{9016205,
author={Qu, Xiaofei and Yang, Lin and Guo, Kai and Sun, Meng and Ma, Linru and Feng, Tao and Ren, Shuangyin and Li, Kechao and Ma, Xin},
journal={IEEE Access}, title={Direct Batch Growth Hierarchical Self-Organizing Mapping Based on Statistics for Efficient Network Intrusion Detection},
year={2020},
volume={8},
number={},
pages={42251-42260},
abstract={A new evaluation mechanism was proposed to enhance the representation of data topology in the directed batch growth hierarchical self-organizing mapping. In the proposed mechanism, the growth threshold and the correlation worked in a case-sensitive manner through the statistic calculation of the input data. Since the proposed model enabled a more thorough representation of data topology from both the horizontal and the vertical directions, it naturally held great potential in detecting various traffic attacks. Numerical experiments of network intrusion detection were carried out on the datasets of KDD99, Moore and CICIDS2017, where the good performance validated the superiority of the proposed method.},
keywords={Neurons;Correlation;Intrusion detection;Topology;Data models;Network topology;Neural networks;Network intrusion detection;growth hierarchical self-organizing mapping;statistical enhancement;growth threshold;correlation},
doi={10.1109/ACCESS.2020.2976810},
ISSN={2169-3536},
month={},}
@INPROCEEDINGS{9499600,
author={Huang, Bo and Li, Fang and Yang, Zixian},
booktitle={2021 IEEE MTT-S International Wireless Symposium (IWS)}, title={An improved Model and Estimation Method for Delay/Doppler Altimetry},
year={2021},
volume={},
number={},
pages={1-3},
abstract={Semi-analytical model for the echo of spaceborne delay/Doppler altimetry (DDA) has been proved efficient and meaningful. However, the complexity of motion errors could not be neglected in low-altitude and highly maneuver flight, such as unmanned aerial vehicles (UAV) remote sensing. At the beginning of this paper, an improved expression for the flat surface impulse response (FSIR) considering vertical motion errors is proposed. The formulation, being one term of the mean echo power, allows for an explicit understanding of how the various vertical position and slight movement affect the waveform. Then a convolution neural network (CNN) is utilized to classify the objects in quantities which are detected in the first step. Simulated results on a set of delay Doppler maps (DDMs) demonstrate that the proposed method is able to generate desirable description of the scene.},
keywords={Wireless communication;Analytical models;Wireless sensor networks;Surface waves;Neural networks;Estimation;Unmanned aerial vehicles;vertical motion errors;Delay/Doppler Altimeter (DDA);semi-analytical model;convolution neural network (CNN)},
doi={10.1109/IWS52775.2021.9499600},
ISSN={},
month={May},}
@INPROCEEDINGS{5650994,
author={Mussetta, M. and Pirinoli, P. and Cong, P.T. and Orefice, M. and Zich, R.E.},
booktitle={2010 International Conference on Electromagnetics in Advanced Applications}, title={Optimization of a dual-layer reflectarray antenna by means of soft-computing techniques},
year={2010},
volume={},
number={},
pages={716-719},
abstract={The nature of reflectarray (RA) optimization problems is intrinsically multi-target and therefore the use of a multi-objective optimization scheme is particularly convenient, although it can be computationally expensive. In this paper some considerations on the characterization and optimization of a RA are presented. The results of the use of efficient approaches for the modeling of the planar RA or of its elementary components are introduced: all of them tend to improve the numerical efficiency of the optimization procedure, without losing in accuracy. Numerical results are provided for the optimization of a dual layer reflectarray antenna with innovative radiating elements, for use in the base station of the WISPERS Project (Wireless Infomobility System for ultra-light Platforms for Emergency Radio Services), which is based on an innovative Unmanned Air Vehicle (UAV).},
keywords={Artificial neural networks;Optimization;Reflection;Computational modeling;Reflector antennas;Data models},
doi={10.1109/ICEAA.2010.5650994},
ISSN={},
month={Sep.},}
@ARTICLE{9638721,
author={Xie, Zhuojun and Hu, Jianwen and Kang, Xudong and Duan, Puhong and Li, Shutao},
journal={IEEE Transactions on Geoscience and Remote Sensing}, title={Multi-Layer Global Spectral-Spatial Attention Network for Wetland Hyperspectral Image Classification},
year={2021},
volume={},
number={},
pages={1-1},
abstract={Coastal wetland monitoring plays an important role for protection and restoration of ecosystems in this world. UAV-hyperspectral imaging, as an emerging technique for earth observation and space exploration, provides huge potential ability to identify different wetland species. In this work, a multi-layer global spectral-spatial attention network (MGSSAN) is proposed for mapping coastal wetlands, which mainly consists of two major steps: First, a two-branch convolutional neural network (CNN) framework with residual connection is developed to obtain an initial classification probability map, in which one branch is used to capture the spectral information, the other branch is used to extract spatial information, and a global spectral-spatial attention module is designed to guide networks focusing on those features which are more discriminative. Second, an extended random walker method is utilized to optimize the initial classification probabilities so as to yield the final map. Experiments performed on three wetland HSI datasets created by ourselves verify that the proposed method can obtain superior performance with respect to several state-of-the-art hyperspectral image classification methods.},
keywords={Feature extraction;Wetlands;Hyperspectral imaging;Sea measurements;Data mining;Autonomous aerial vehicles;Data visualization;Deep learning;global spectral-spatial attention;extended random walk;residual connection;hyperspectaral image classification},
doi={10.1109/TGRS.2021.3133454},
ISSN={1558-0644},
month={},}
@INPROCEEDINGS{9364137,
author={El Ferik, Sami and Mahmoud, Magdi S. and Maaruf, Muhammad},
booktitle={2020 17th International Multi-Conference on Systems, Signals Devices (SSD)}, title={Robust Adaptive Sliding Mode Control of Nonlinear Systems Using Neural Network},
year={2020},
volume={},
number={},
pages={591-596},
abstract={Many higher order complex nonlinear systems with unknown parameters cannot be expressed in the so called linear-in-the-unknown-parameters form. This brings a huge obstacle to the application of adaptive control to estimate the unknown parameters. Instead of estimating each of the unknown parameters of a function, a feed-forward neural network (NN) can approximate the whole function due to its universal approximation property. In this study, an adaptive neural network integral fast terminal sliding mode controller (NN-IFTSMC) has been proposed for a general n-th order nonlinear systems with parametric uncertainties and external disturbances. The closed loop system has been proven to be bounded near the origin using Lyapunov criterion. The designed control scheme was applied to a quadrotor (UAV) and an excellent trajectories' tracking were obtained.},
keywords={Uncertainty;Trajectory tracking;Artificial neural networks;Closed loop systems;Nonlinear systems;Adaptive control;Sliding mode control;Adaptive neural network;quadrotor;fast terminal sliding mode control;integral sliding mode control},
doi={10.1109/SSD49366.2020.9364137},
ISSN={2474-0446},
month={July},}
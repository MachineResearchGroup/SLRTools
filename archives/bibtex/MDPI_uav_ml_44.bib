
@Article{rs13142794,
AUTHOR = {Ran, Shuhao and Gao, Xianjun and Yang, Yuanwei and Li, Shaohua and Zhang, Guangbin and Wang, Ping},
TITLE = {Building Multi-Feature Fusion Refined Network for Building Extraction from High-Resolution Remote Sensing Images},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {14},
ARTICLE-NUMBER = {2794},
URL = {https://www.mdpi.com/2072-4292/13/14/2794},
ISSN = {2072-4292},
ABSTRACT = {Deep learning approaches have been widely used in building automatic extraction tasks and have made great progress in recent years. However, the missing detection and wrong detection causing by spectrum confusion is still a great challenge. The existing fully convolutional networks (FCNs) cannot effectively distinguish whether the feature differences are from one building or the building and its adjacent non-building objects. In order to overcome the limitations, a building multi-feature fusion refined network (BMFR-Net) was presented in this paper to extract buildings accurately and completely. BMFR-Net is based on an encoding and decoding structure, mainly consisting of two parts: the continuous atrous convolution pyramid (CACP) module and the multiscale output fusion constraint (MOFC) structure. The CACP module is positioned at the end of the contracting path and it effectively minimizes the loss of effective information in multiscale feature extraction and fusion by using parallel continuous small-scale atrous convolution. To improve the ability to aggregate semantic information from the context, the MOFC structure performs predictive output at each stage of the expanding path and integrates the results into the network. Furthermore, the multilevel joint weighted loss function effectively updates parameters well away from the output layer, enhancing the learning capacity of the network for low-level abstract features. The experimental results demonstrate that the proposed BMFR-Net outperforms the other five state-of-the-art approaches in both visual interpretation and quantitative evaluation.},
DOI = {10.3390/rs13142794}
}



@Article{rs13142796,
AUTHOR = {Vandendaele, Bastien and Fournier, Richard A. and Vepakomma, Udayalakshmi and Pelletier, Gaetan and Lejeune, Philippe and Martin-Ducup, Olivier},
TITLE = {Estimation of Northern Hardwood Forest Inventory Attributes Using UAV Laser Scanning (ULS): Transferability of Laser Scanning Methods and Comparison of Automated Approaches at the Tree- and Stand-Level},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {14},
ARTICLE-NUMBER = {2796},
URL = {https://www.mdpi.com/2072-4292/13/14/2796},
ISSN = {2072-4292},
ABSTRACT = {UAV laser scanning (ULS) has the potential to support forest operations since it provides high-density data with flexible operational conditions. This study examined the use of ULS systems to estimate several tree attributes from an uneven-aged northern hardwood stand. We investigated: (1) the transferability of raster-based and bottom-up point cloud-based individual tree detection (ITD) algorithms to ULS data; and (2) automated approaches to the retrieval of tree-level (i.e., height, crown diameter (CD), DBH) and stand-level (i.e., tree count, basal area (BA), DBH-distribution) forest inventory attributes. These objectives were studied under leaf-on and leaf-off canopy conditions. Results achieved from ULS data were cross-compared with ALS and TLS to better understand the potential and challenges faced by different laser scanning systems and methodological approaches in hardwood forest environments. The best results that characterized individual trees from ULS data were achieved under leaf-off conditions using a point cloud-based bottom-up ITD. The latter outperformed the raster-based ITD, improving the accuracy of tree detection (from 50% to 71%), crown delineation (from R2 = 0.29 to R2 = 0.61), and prediction of tree DBH (from R2 = 0.36 to R2 = 0.67), when compared with values that were estimated from reference TLS data. Major improvements were observed for the detection of trees in the lower canopy layer (from 9% with raster-based ITD to 51% with point cloud-based ITD) and in the intermediate canopy layer (from 24% with raster-based ITD to 59% with point cloud-based ITD). Under leaf-on conditions, LiDAR data from aerial systems include substantial signal occlusion incurred by the upper canopy. Under these conditions, the raster-based ITD was unable to detect low-level canopy trees (from 5% to 15% of trees detected from lower and intermediate canopy layers, respectively), resulting in a tree detection rate of about 40% for both ULS and ALS data. The cylinder-fitting method used to estimate tree DBH under leaf-off conditions did not meet inventory standards when compared to TLS DBH, resulting in RMSE = 7.4 cm, Bias = 3.1 cm, and R2 = 0.75. Yet, it yielded more accurate estimates of the BA (+3.5%) and DBH-distribution of the stand than did allometric models −12.9%), when compared with in situ field measurements. Results suggest that the use of bottom-up ITD on high-density ULS data from leaf-off hardwood forest leads to promising results when estimating trees and stand attributes, which opens up new possibilities for supporting forest inventories and operations.},
DOI = {10.3390/rs13142796}
}



@Article{ma14143994,
AUTHOR = {Jing, Chenchen and Zhu, Yanyan and Wang, Jie and Wang, Feifan and Lu, Jiping and Liu, Changmeng},
TITLE = {Investigation on Morphology and Mechanical Properties of Rod Units in Lattice Structures Fabricated by Selective Laser Melting},
JOURNAL = {Materials},
VOLUME = {14},
YEAR = {2021},
NUMBER = {14},
ARTICLE-NUMBER = {3994},
URL = {https://www.mdpi.com/1996-1944/14/14/3994},
PubMedID = {34300910},
ISSN = {1996-1944},
ABSTRACT = {Selective laser melting (SLM) fabrication of lattice structures has attracted considerable interest due to its many immanent advantages, such as high specific strength. A wide variety of lattice structures have been designed and fabricated. However, as a vital prerequisite for design optimization, a clear relation between the process constraint of SLM and the apparent properties of the fabricated lattice structure has received much less attention. Therefore, this work systematically investigates the characterization and preformation of rod units, which are the basic components of lattice structures, so as to evaluate the SLM manufacturability of lattice structures. A series of rod units with different inclination angles and diameters were fabricated by SLM. Their morphology and mechanical properties were measured by scanning electron microscope observation and a tensile test, respectively. The inclination angle was found to have significant effects on profile error and little effect on mechanical properties. The higher the inclination angle, the larger the profile error. The characteristic diameter had no significant correlation with profile errors and mechanical properties. Based on systematic studies, a formula is proposed to evaluate the cross-sectional area of the fabricated rod units and further estimate their load capacity. This has important implications for optimizing the design of lattice structures fabricated by SLM.},
DOI = {10.3390/ma14143994}
}



@Article{f12070943,
AUTHOR = {Vásquez, Felipe and Cravero, Ania and Castro, Manuel and Acevedo, Patricio},
TITLE = {Decision Support System Development of Wildland Fire: A Systematic Mapping},
JOURNAL = {Forests},
VOLUME = {12},
YEAR = {2021},
NUMBER = {7},
ARTICLE-NUMBER = {943},
URL = {https://www.mdpi.com/1999-4907/12/7/943},
ISSN = {1999-4907},
ABSTRACT = {Wildland fires have been a rising problem on the worldwide level, generating ecological and economic losses. Specifically, between wildland fire types, uncontrolled fires are critical due to the potential damage to the ecosystem and their effects on the soil, and, in the last decade, different technologies have been applied to fight them. Selecting a specific technology and Decision Support Systems (DSS) is fundamental, since the results and validity of this could drastically oscillate according to the different environmental and geographic factors of the terrain to be studied. Given the above, a systematic mapping was realized, with the purpose of recognizing the most-used DSS and context where they have been applied. One hundred and eighty-three studies were found that used different types of DSS to solve problems of detection, prediction, prevention, monitoring, simulation, administration, and access to routes. The concepts key to the type of solution are related to the use or development of systems or Information and Communication Technologies (ICT) in the computer science area. Although the use of BA and Big Data has increased in recent years, there are still many challenges to face, such as staff training, the friendly environment of DSS, and real-time decision-making.},
DOI = {10.3390/f12070943}
}



@Article{rs13142822,
AUTHOR = {Lin, Zhe and Guo, Wenxuan},
TITLE = {Cotton Stand Counting from Unmanned Aerial System Imagery Using MobileNet and CenterNet Deep Learning Models},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {14},
ARTICLE-NUMBER = {2822},
URL = {https://www.mdpi.com/2072-4292/13/14/2822},
ISSN = {2072-4292},
ABSTRACT = {An accurate stand count is a prerequisite to determining the emergence rate, assessing seedling vigor, and facilitating site-specific management for optimal crop production. Traditional manual counting methods in stand assessment are labor intensive and time consuming for large-scale breeding programs or production field operations. This study aimed to apply two deep learning models, the MobileNet and CenterNet, to detect and count cotton plants at the seedling stage with unmanned aerial system (UAS) images. These models were trained with two datasets containing 400 and 900 images with variations in plant size and soil background brightness. The performance of these models was assessed with two testing datasets of different dimensions, testing dataset 1 with 300 by 400 pixels and testing dataset 2 with 250 by 1200 pixels. The model validation results showed that the mean average precision (mAP) and average recall (AR) were 79% and 73% for the CenterNet model, and 86% and 72% for the MobileNet model with 900 training images. The accuracy of cotton plant detection and counting was higher with testing dataset 1 for both CenterNet and MobileNet models. The results showed that the CenterNet model had a better overall performance for cotton plant detection and counting with 900 training images. The results also indicated that more training images are required when applying object detection models on images with different dimensions from training datasets. The mean absolute percentage error (MAPE), coefficient of determination (R2), and the root mean squared error (RMSE) values of the cotton plant counting were 0.07%, 0.98 and 0.37, respectively, with testing dataset 1 for the CenterNet model with 900 training images. Both MobileNet and CenterNet models have the potential to accurately and timely detect and count cotton plants based on high-resolution UAS images at the seedling stage. This study provides valuable information for selecting the right deep learning tools and the appropriate number of training images for object detection projects in agricultural applications.},
DOI = {10.3390/rs13142822}
}



@Article{app11146603,
AUTHOR = {Tanwar, Monika and Park, Hyunseok and Raghavan, Nagarajan},
TITLE = {Multistate Diagnosis and Prognosis of Lubricating Oil Degradation Using Sticky Hierarchical Dirichlet Process–Hidden Markov Model Framework},
JOURNAL = {Applied Sciences},
VOLUME = {11},
YEAR = {2021},
NUMBER = {14},
ARTICLE-NUMBER = {6603},
URL = {https://www.mdpi.com/2076-3417/11/14/6603},
ISSN = {2076-3417},
ABSTRACT = {In this study, we present a state-based diagnostic and prognostic methodology for lubricating oil degradation based on a nonparametric Bayesian approach, i.e., sticky hierarchical Dirichlet process–hidden Markov model (HDP-HMM). An accurate health state-space assessment for diagnostics and prognostics has always been unobservable and hypothetical in the past. The lubrication condition monitoring (LCM) data is generally segregated as “healthy or unhealthy”, representing a binary state-based perspective to the problem. This two-state performance-based formulation poses limitations to the precision and accuracy of the diagnosis and prognosis for real data wherein there may be multiple states of discrete performance that are characteristic of the system functionality. In particular, the reversible and nonlinear time-series trends of degradation data increase the complexity of state-based modeling. We propose a multistate diagnostic and prognostic framework for LCM data in the wear-out phase (i.e., the unhealthy portion of degradation data), accounting for irregular oil replenishment and oil change effects (i.e., nonlinearity in the degradation signal). The LCM data is simulated for an elementary mechanical system with four components. The sticky HDP sets the prior for the HMM parameters. The unsupervised learning over infinite observations and emission reveals four discrete health states and helps estimate the associated state transition probabilities. The inferred state sequence provides information relating to the state dynamics, which provides further guidance to maintenance decision making. The decision making is further backed by prognostics based on the conditional reliability function and mean residual life estimation.},
DOI = {10.3390/app11146603}
}



@Article{rs13142827,
AUTHOR = {Hu, Pengcheng and Chapman, Scott C. and Jin, Huidong and Guo, Yan and Zheng, Bangyou},
TITLE = {Comparison of Modelling Strategies to Estimate Phenotypic Values from an Unmanned Aerial Vehicle with Spectral and Temporal Vegetation Indexes},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {14},
ARTICLE-NUMBER = {2827},
URL = {https://www.mdpi.com/2072-4292/13/14/2827},
ISSN = {2072-4292},
ABSTRACT = {Aboveground dry weight (AGDW) and leaf area index (LAI) are indicators of crop growth status and grain yield as affected by interactions of genotype, environment, and management. Unmanned aerial vehicle (UAV) based remote sensing provides cost-effective and non-destructive methods for the high-throughput phenotyping of crop traits (e.g., AGDW and LAI) through the integration of UAV-derived vegetation indexes (VIs) with statistical models. However, the effects of different modelling strategies that use different dataset compositions of explanatory variables (i.e., combinations of sources and temporal combinations of the VI datasets) on estimates of AGDW and LAI have rarely been evaluated. In this study, we evaluated the effects of three sources of VIs (visible, spectral, and combined) and three types of temporal combinations of the VI datasets (mono-, multi-, and full-temporal) on estimates of AGDW and LAI. The VIs were derived from visible (RGB) and multi-spectral imageries, which were acquired by a UAV-based platform over a wheat trial at five sampling dates before flowering. Partial least squares regression models were built with different modelling strategies to estimate AGDW and LAI at each prediction date. The results showed that models built with the three sources of mono-temporal VIs obtained similar performances for estimating AGDW (RRMSE = 11.86% to 15.80% for visible, 10.25% to 16.70% for spectral, and 10.25% to 16.70% for combined VIs) and LAI (RRMSE = 13.30% to 22.56% for visible, 12.04% to 22.85% for spectral, and 13.45% to 22.85% for combined VIs) across prediction dates. Mono-temporal models built with visible VIs outperformed the other two sources of VIs in general. Models built with mono-temporal VIs generally obtained better estimates than models with multi- and full-temporal VIs. The results suggested that the use of UAV-derived visible VIs can be an alternative to multi-spectral VIs for high-throughput and in-season estimates of AGDW and LAI. The combination of modelling strategies that used mono-temporal datasets and a self-calibration method demonstrated the potential for in-season estimates of AGDW and LAI (RRMSE normally less than 15%) in breeding or agronomy trials.},
DOI = {10.3390/rs13142827}
}



@Article{rs13142830,
AUTHOR = {Fernández-Novales, Juan and Saiz-Rubio, Verónica and Barrio, Ignacio and Rovira-Más, Francisco and Cuenca-Cuenca, Andrés and Santos Alves, Fernando and Valente, Joana and Tardaguila, Javier and Diago, María Paz},
TITLE = {Monitoring and Mapping Vineyard Water Status Using Non-Invasive Technologies by a Ground Robot},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {14},
ARTICLE-NUMBER = {2830},
URL = {https://www.mdpi.com/2072-4292/13/14/2830},
ISSN = {2072-4292},
ABSTRACT = {There is a growing need to provide support and applicable tools to farmers and the agro-industry in order to move from their traditional water status monitoring and high-water-demand cropping and irrigation practices to modern, more precise, reduced-demand systems and technologies. In precision viticulture, very few approaches with ground robots have served as moving platforms for carrying non-invasive sensors to deliver field maps that help growers in decision making. The goal of this work is to demonstrate the capability of the VineScout (developed in the context of a H2020 EU project), a ground robot designed to assess and map vineyard water status using thermal infrared radiometry in commercial vineyards. The trials were carried out in Douro Superior (Portugal) under different irrigation treatments during seasons 2019 and 2020. Grapevines of Vitis vinifera L. Touriga Nacional were monitored at different timings of the day using leaf water potential (Ψl) as reference indicators of plant water status. Grapevines’ canopy temperature (Tc) values, recorded with an infrared radiometer, as well as data acquired with an environmental sensor (Tair, RH, and AP) and NDVI measurements collected with a multispectral sensor were automatically saved in the computer of the autonomous robot to assess and map the spatial variability of a commercial vineyard water status. Calibration and prediction models were performed using Partial Least Squares (PLS) regression. The best prediction models for grapevine water status yielded a determination coefficient of cross-validation (r2cv) of 0.57 in the morning time and a r2cv of 0.42 in the midday. The root mean square error of cross-validation (RMSEcv) was 0.191 MPa and 0.139 MPa at morning and midday, respectively. Spatial–temporal variation maps were developed at two different times of the day to illustrate the capability to monitor the grapevine water status in order to reduce the consumption of water, implementing appropriate irrigation strategies and increase the efficiency in the real time vineyard management. The promising outcomes gathered with the VineScout using different sensors based on thermography, multispectral imaging and environmental data disclose the need for further studies considering new variables related with the plant water status, and more grapevine cultivars, seasons and locations to improve the accuracy, robustness and reliability of the predictive models, in the context of precision and sustainable viticulture.},
DOI = {10.3390/rs13142830}
}



@Article{agronomy11071435,
AUTHOR = {Che’Ya, Nik Norasma and Dunwoody, Ernest and Gupta, Madan},
TITLE = {Assessment of Weed Classification Using Hyperspectral Reflectance and Optimal Multispectral UAV Imagery},
JOURNAL = {Agronomy},
VOLUME = {11},
YEAR = {2021},
NUMBER = {7},
ARTICLE-NUMBER = {1435},
URL = {https://www.mdpi.com/2073-4395/11/7/1435},
ISSN = {2073-4395},
ABSTRACT = {Weeds compete with crops and are hard to differentiate and identify due to their similarities in color, shape, and size. In this study, the weed species present in sorghum (sorghum bicolor (L.) Moench) fields, such as amaranth (Amaranthus macrocarpus), pigweed (Portulaca oleracea), mallow weed (Malva sp.), nutgrass (Cyperus rotundus), liver seed grass (Urochoa panicoides), and Bellive (Ipomea plebeian), were discriminated using hyperspectral data and were detected and analyzed using multispectral images. Discriminant analysis (DA) was used to identify the most significant spectral bands in order to discriminate weeds from sorghum using hyperspectral data. The results demonstrated good separation accuracy for Amaranthus macrocarpus, Urochoa panicoides, Malva sp., Cyperus rotundus, and Sorghum bicolor (L.) Moench at 440, 560, 680, 710, 720, and 850 nm. Later, the multispectral images of these six bands were collected to detect weeds in the sorghum crop fields using object-based image analysis (OBIA). The results showed that the differences between sorghum and weed species were detectable using the six selected bands, with data collected using an unmanned aerial vehicle. Here, the highest spatial resolution had the highest accuracy for weed detection. It was concluded that each weed was successfully discriminated using hyperspectral data and was detectable using multispectral data with higher spatial resolution.},
DOI = {10.3390/agronomy11071435}
}



@Article{s21144929,
AUTHOR = {Hallee, Mitchell J. and Napolitano, Rebecca K. and Reinhart, Wesley F. and Glisic, Branko},
TITLE = {Crack Detection in Images of Masonry Using CNNs},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {14},
ARTICLE-NUMBER = {4929},
URL = {https://www.mdpi.com/1424-8220/21/14/4929},
PubMedID = {34300668},
ISSN = {1424-8220},
ABSTRACT = {While there is a significant body of research on crack detection by computer vision methods in concrete and asphalt, less attention has been given to masonry. We train a convolutional neural network (CNN) on images of brick walls built in a laboratory environment and test its ability to detect cracks in images of brick-and-mortar structures both in the laboratory and on real-world images taken from the internet. We also compare the performance of the CNN to a variety of simpler classifiers operating on handcrafted features. We find that the CNN performed better on the domain adaptation from laboratory to real-world images than these simple models. However, we also find that performance is significantly better in performing the reverse domain adaptation task, where the simple classifiers are trained on real-world images and tested on the laboratory images. This work demonstrates the ability to detect cracks in images of masonry using a variety of machine learning methods and provides guidance for improving the reliability of such models when performing domain adaptation for crack detection in masonry.},
DOI = {10.3390/s21144929}
}



@Article{electronics10151748,
AUTHOR = {Wei, Baoquan and Zuo, Yong and Liu, Yande and Luo, Wei and Wen, Kaiyun and Deng, Fangming},
TITLE = {Novel MOA Fault Detection Technology Based on Small Sample Infrared Image},
JOURNAL = {Electronics},
VOLUME = {10},
YEAR = {2021},
NUMBER = {15},
ARTICLE-NUMBER = {1748},
URL = {https://www.mdpi.com/2079-9292/10/15/1748},
ISSN = {2079-9292},
ABSTRACT = {This paper proposes a novel metal oxide arrester (MOA) fault detection technology based on a small sample infrared image. The research is carried out from the detection process and data enhancement. A lightweight MOA identification and location algorithm is designed at the edge, which can not only reduce the amount of data uploaded, but also reduce the search space of cloud algorithm. In order to improve the accuracy and generalization ability of the defect detection model under the condition of small samples, a multi-model fusion detection algorithm is proposed. Different features of the image are extracted by multiple convolutional neural networks, and then multiple classifiers are trained. Finally, the weighted voting strategy is used for fault diagnosis. In addition, the extended model of fault samples is constructed by transfer learning and deep convolutional generative adversarial networks (DCGAN) to solve the problem of unbalanced training data sets. The experimental results show that the proposed method can realize the accurate location of arrester under the condition of small samples, and after the data expansion, the recognition rate of arrester anomalies can be improved from 83% to 85%, showing high effectiveness and reliability.},
DOI = {10.3390/electronics10151748}
}



@Article{rs13152870,
AUTHOR = {Civico, Riccardo and Ricci, Tullio and Scarlato, Piergiorgio and Andronico, Daniele and Cantarero, Massimo and Carr, Brett B. and De Beni, Emanuela and Del Bello, Elisabetta and Johnson, Jeffrey B. and Kueppers, Ulrich and Pizzimenti, Luca and Schmid, Markus and Strehlow, Karen and Taddeucci, Jacopo},
TITLE = {Unoccupied Aircraft Systems (UASs) Reveal the Morphological Changes at Stromboli Volcano (Italy) before, between, and after the 3 July and 28 August 2019 Paroxysmal Eruptions},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {15},
ARTICLE-NUMBER = {2870},
URL = {https://www.mdpi.com/2072-4292/13/15/2870},
ISSN = {2072-4292},
ABSTRACT = {In July and August 2019, two paroxysmal eruptions dramatically changed the morphology of the crater terrace that hosts the active vents of Stromboli volcano (Italy). Here, we document these morphological changes, by using 2259 UAS-derived photographs from eight surveys and Structure-from-Motion (SfM) photogrammetric techniques, resulting in 3D point clouds, orthomosaics, and digital surface models (DSMs) with resolution ranging from 8.1 to 12.4 cm/pixel. We focus on the morphological evolution of volcanic features and volume changes in the crater terrace and the upper part of the underlying slope (Sciara del Fuoco). We identify both crater terrace and lava field variations, with vents shifting up to 47 m and the accumulation of tephra deposits. The maximum elevation changes related to the two paroxysmal eruptions (in between May and September 2019) range from +41.4 to −26.4 m at the lava field and N crater area, respectively. Throughout September 2018–June 2020, the total volume change in the surveyed area was +447,335 m3. Despite Stromboli being one of the best-studied volcanoes worldwide, the UAS-based photogrammetry products of this study provide unprecedented high spatiotemporal resolution observations of its entire summit area, in a period when volcanic activity made the classic field inspections and helicopter overflights too risky. Routinely applied UAS operations represent an effective and evolving tool for volcanic hazard assessment and to support decision-makers involved in volcanic surveillance and civil protection operations.},
DOI = {10.3390/rs13152870}
}



@Article{agronomy11081458,
AUTHOR = {Ammar, Adel and Koubaa, Anis and Benjdira, Bilel},
TITLE = {Deep-Learning-Based Automated Palm Tree Counting and Geolocation in Large Farms from Aerial Geotagged Images},
JOURNAL = {Agronomy},
VOLUME = {11},
YEAR = {2021},
NUMBER = {8},
ARTICLE-NUMBER = {1458},
URL = {https://www.mdpi.com/2073-4395/11/8/1458},
ISSN = {2073-4395},
ABSTRACT = {In this paper, we propose an original deep learning framework for the automated counting and geolocation of palm trees from aerial images using convolutional neural networks. For this purpose, we collected aerial images from two different regions in Saudi Arabia, using two DJI drones, and we built a dataset of around 11,000 instances of palm trees. Then, we applied several recent convolutional neural network models (Faster R-CNN, YOLOv3, YOLOv4, and EfficientDet) to detect palms and other trees, and we conducted a complete comparative evaluation in terms of average precision and inference speed. YOLOv4 and EfficientDet-D5 yielded the best trade-off between accuracy and speed (up to 99% mean average precision and 7.4 FPS). Furthermore, using the geotagged metadata of aerial images, we used photogrammetry concepts and distance corrections to automatically detect the geographical location of detected palm trees. This geolocation technique was tested on two different types of drones (DJI Mavic Pro and Phantom 4 pro) and was assessed to provide an average geolocation accuracy that attains 1.6 m. This GPS tagging allows us to uniquely identify palm trees and count their number from a series of drone images, while correctly dealing with the issue of image overlapping. Moreover, this innovative combination between deep learning object detection and geolocalization can be generalized to any other objects in UAV images.},
DOI = {10.3390/agronomy11081458}
}



@Article{min11080798,
AUTHOR = {Isheyskiy, Valentin and Martinyskin, Evgeny and Smirnov, Sergey and Vasilyev, Anton and Knyazev, Kirill and Fatyanov, Timur},
TITLE = {Specifics of MWD Data Collection and Verification during Formation of Training Datasets},
JOURNAL = {Minerals},
VOLUME = {11},
YEAR = {2021},
NUMBER = {8},
ARTICLE-NUMBER = {798},
URL = {https://www.mdpi.com/2075-163X/11/8/798},
ISSN = {2075-163X},
ABSTRACT = {This paper presents a structured analysis in the area of measurement while drilling (MWD) data processing and verification methods, as well as describes the main nuances and certain specifics of “clean” data selection in order to build a “parent” training database for subsequent use in machine learning algorithms. The main purpose of the authors is to create a trainable machine learning algorithm, which, based on the available “clean” input data associated with specific conditions, could correlate, process and select parameters obtained from the drilling rig and use them for further estimation of various rock characteristics, prediction of optimal drilling and blasting parameters, and blasting results. The paper is a continuation of a series of publications devoted to the prospects of using MWD technology for the quality management of drilling and blasting operations at mining enterprises.},
DOI = {10.3390/min11080798}
}



@Article{rs13152885,
AUTHOR = {Li, Mei and Li, Zengyuan and Liu, Qingwang and Chen, Erxue},
TITLE = {Comparison of Coniferous Plantation Heights Using Unmanned Aerial Vehicle (UAV) Laser Scanning and Stereo Photogrammetry},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {15},
ARTICLE-NUMBER = {2885},
URL = {https://www.mdpi.com/2072-4292/13/15/2885},
ISSN = {2072-4292},
ABSTRACT = {Plantation forests play a critical role in forest products and ecosystems. Unmanned aerial vehicle (UAV) remote sensing has become a promising technology in forest related applications. The stand heights will reflect the growth and competition of individual trees in plantation. UAV laser scanning (ULS) and UAV stereo photogrammetry (USP) can both be used to estimate stand heights using different algorithms. Thus, this study aimed to deeply explore the variations of four kinds of stand heights including mean height, Lorey’s height, dominated height, and median height of coniferous plantations using different models based on ULS and USP data. In addition, the impacts of thinned point density of 30 pts to 10 pts, 5 pts, 1 pts, and 0.8 pts/m2 were also analyzed. Forest stand heights were estimated from ULS and USP data metrics by linear regression and the prediction accuracy was assessed by 10-fold cross validation. The results showed that the prediction accuracy of the stand heights using metrics from USP was basically as good as that of ULS. Lorey’s height had the highest prediction accuracy, followed by dominated height, mean height, and median height. The correlation between height percentiles metrics from ULS and USP increased with the increased height. Different stand heights had their corresponding best height percentiles as variables based on stand height characteristics. Furthermore, canopy height model (CHM)-based metrics performed slightly better than normalized point cloud (NPC)-based metrics. The USP was not able to extract exact terrain information in a continuous coniferous plantation for forest canopy cover (CC) over 0.49. The combination of USP and terrain from ULS can be used to estimate forest stand heights with high accuracy. In addition, the estimation accuracy of each forest stand height was slightly affected by point density, which can also be ignored.},
DOI = {10.3390/rs13152885}
}



@Article{drones5030066,
AUTHOR = {Walambe, Rahee and Marathe, Aboli and Kotecha, Ketan},
TITLE = {Multiscale Object Detection from Drone Imagery Using Ensemble Transfer Learning},
JOURNAL = {Drones},
VOLUME = {5},
YEAR = {2021},
NUMBER = {3},
ARTICLE-NUMBER = {66},
URL = {https://www.mdpi.com/2504-446X/5/3/66},
ISSN = {2504-446X},
ABSTRACT = {Object detection in uncrewed aerial vehicle (UAV) images has been a longstanding challenge in the field of computer vision. Specifically, object detection in drone images is a complex task due to objects of various scales such as humans, buildings, water bodies, and hills. In this paper, we present an implementation of ensemble transfer learning to enhance the performance of the base models for multiscale object detection in drone imagery. Combined with a test-time augmentation pipeline, the algorithm combines different models and applies voting strategies to detect objects of various scales in UAV images. The data augmentation also presents a solution to the deficiency of drone image datasets. We experimented with two specific datasets in the open domain: the VisDrone dataset and the AU-AIR Dataset. Our approach is more practical and efficient due to the use of transfer learning and two-level voting strategy ensemble instead of training custom models on entire datasets. The experimentation shows significant improvement in the mAP for both VisDrone and AU-AIR datasets by employing the ensemble transfer learning method. Furthermore, the utilization of voting strategies further increases the 3reliability of the ensemble as the end-user can select and trace the effects of the mechanism for bounding box predictions.},
DOI = {10.3390/drones5030066}
}



@Article{rs13152899,
AUTHOR = {El Serafy, Ghada Y.H. and Schaeffer, Blake A. and Neely, Merrie-Beth and Spinosa, Anna and Odermatt, Daniel and Weathers, Kathleen C. and Baracchini, Theo and Bouffard, Damien and Carvalho, Laurence and Conmy, Robyn N. and Keukelaere, Liesbeth De and Hunter, Peter D. and Jamet, Cédric and Joehnk, Klaus D. and Johnston, John M. and Knudby, Anders and Minaudo, Camille and Pahlevan, Nima and Reusen, Ils and Rose, Kevin C. and Schalles, John and Tzortziou, Maria},
TITLE = {Integrating Inland and Coastal Water Quality Data for Actionable Knowledge},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {15},
ARTICLE-NUMBER = {2899},
URL = {https://www.mdpi.com/2072-4292/13/15/2899},
ISSN = {2072-4292},
ABSTRACT = {Water quality measures for inland and coastal waters are available as discrete samples from professional and volunteer water quality monitoring programs and higher-frequency, near-continuous data from automated in situ sensors. Water quality parameters also are estimated from model outputs and remote sensing. The integration of these data, via data assimilation, can result in a more holistic characterization of these highly dynamic ecosystems, and consequently improve water resource management. It is becoming common to see combinations of these data applied to answer relevant scientific questions. Yet, methods for scaling water quality data across regions and beyond, to provide actionable knowledge for stakeholders, have emerged only recently, particularly with the availability of satellite data now providing global coverage at high spatial resolution. In this paper, data sources and existing data integration frameworks are reviewed to give an overview of the present status and identify the gaps in existing frameworks. We propose an integration framework to provide information to user communities through the the Group on Earth Observations (GEO) AquaWatch Initiative. This aims to develop and build the global capacity and utility of water quality data, products, and information to support equitable and inclusive access for water resource management, policy and decision making.},
DOI = {10.3390/rs13152899}
}



@Article{rs13152912,
AUTHOR = {Wang, Jingrui and Wang, Shuqing and Zou, Dongxiao and Chen, Huimin and Zhong, Run and Li, Hanliang and Zhou, Wei and Yan, Kai},
TITLE = {Social Network and Bibliometric Analysis of Unmanned Aerial Vehicle Remote Sensing Applications from 2010 to 2021},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {15},
ARTICLE-NUMBER = {2912},
URL = {https://www.mdpi.com/2072-4292/13/15/2912},
ISSN = {2072-4292},
ABSTRACT = {Unmanned Aerial Vehicle (UAV) Remote sensing (RS) has unique advantages over traditional satellite RS, including convenience, high resolution, affordability and fast acquisition speed, making it widely used in many fields. To provide an overview of the development of UAV RS applications during the past decade, we screened related publications from the Web of Science core database from 2010 to 2021, built co-author networks, a discipline interaction network, a keywords timeline view, a co-citation cluster, and detected burst citations using bibliometrics and social network analysis. Our results show that: (1) The number of UAV RS publications had an increasing trend, with explosive growth in the past five years. The number of papers published by China and the United States (US) is far ahead in this field; (2) The US has currently the greatest influence in this field through the largest number of international cooperations. Cooperation is mainly concentrated in countries and institutions with a large number of publications but is not widely distributed. (3) The application of UAV RS involves multiple interdisciplinary subjects, among which “Environmental Science and Ecology” ranks first; (4) Future research trends of UAV RS are expected to be related to artificial intelligence (e.g., artificial neural networks-based research). This paper provides a scientific basis and guidance for future developments of UAV RS applications, which can help the research community to better grasp the developments of this field.},
DOI = {10.3390/rs13152912}
}



@Article{rs13152917,
AUTHOR = {Wei, Lifei and Wang, Kun and Lu, Qikai and Liang, Yajing and Li, Haibo and Wang, Zhengxiang and Wang, Run and Cao, Liqin},
TITLE = {Crops Fine Classification in Airborne Hyperspectral Imagery Based on Multi-Feature Fusion and Deep Learning},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {15},
ARTICLE-NUMBER = {2917},
URL = {https://www.mdpi.com/2072-4292/13/15/2917},
ISSN = {2072-4292},
ABSTRACT = {Hyperspectral imagery has been widely used in precision agriculture due to its rich spectral characteristics. With the rapid development of remote sensing technology, the airborne hyperspectral imagery shows detailed spatial information and temporal flexibility, which open a new way to accurate agricultural monitoring. To extract crop types from the airborne hyperspectral images, we propose a fine classification method based on multi-feature fusion and deep learning. In this research, the morphological profiles, GLCM texture and endmember abundance features are leveraged to exploit the spatial information of the hyperspectral imagery. Then, the multiple spatial information is fused with the original spectral information to generate classification result by using the deep neural network with conditional random field (DNN+CRF) model. Specifically, the deep neural network (DNN) is a deep recognition model which can extract depth features and mine the potential information of data. As a discriminant model, conditional random field (CRF) considers both spatial and contextual information to reduce the misclassification noises while keeping the object boundaries. Moreover, three multiple feature fusion approaches, namely feature stacking, decision fusion and probability fusion, are taken into account. In the experiments, two airborne hyperspectral remote sensing datasets (Honghu dataset and Xiong’an dataset) are used. The experimental results show that the classification performance of the proposed method is satisfactory, where the salt and pepper noise is decreased, and the boundary of the ground object is preserved.},
DOI = {10.3390/rs13152917}
}



@Article{rs13152918,
AUTHOR = {Banerjee, Bikram P. and Sharma, Vikas and Spangenberg, German and Kant, Surya},
TITLE = {Machine Learning Regression Analysis for Estimation of Crop Emergence Using Multispectral UAV Imagery},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {15},
ARTICLE-NUMBER = {2918},
URL = {https://www.mdpi.com/2072-4292/13/15/2918},
ISSN = {2072-4292},
ABSTRACT = {Optimal crop emergence is an important trait in crop breeding for genotypic screening and for achieving potential growth and yield. Emergence is conventionally quantified manually by counting the sub-sections of field plots or scoring; these are less reliable, laborious and inefficient. Remote sensing technology is being increasingly used for high-throughput estimation of agronomic traits in field crops. This study developed a method for estimating wheat seedlings using multispectral images captured from an unmanned aerial vehicle. A machine learning regression (MLR) analysis was used by combining spectral and morphological information extracted from the multispectral images. The approach was tested on diverse wheat genotypes varying in seedling emergence. In this study, three supervised MLR models including regression trees, support vector regression and Gaussian process regression (GPR) were evaluated for estimating wheat seedling emergence. The GPR model was the most effective compared to the other methods, with R2 = 0.86, RMSE = 4.07 and MAE = 3.21 when correlated to the manual seedling count. In addition, imagery data collected at multiple flight altitudes and different wheat growth stages suggested that 10 m altitude and 20 days after sowing were desirable for optimal spatial resolution and image analysis. The method is deployable on larger field trials and other crops for effective and reliable seedling emergence estimates.},
DOI = {10.3390/rs13152918}
}



@Article{rs13152920,
AUTHOR = {Huang, Tingting and Ding, Chenghui and Li, Weibiao and Chen, Yilun},
TITLE = {Morphology of Rain Clusters Influencing Rainfall Intensity over Hainan Island},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {15},
ARTICLE-NUMBER = {2920},
URL = {https://www.mdpi.com/2072-4292/13/15/2920},
ISSN = {2072-4292},
ABSTRACT = {Continuous observations from geostationary satellites can show the morphology of precipitation cloud systems in quasi-real-time, but there are still large deviations in the inversion of precipitation. We used binary-connected area recognition technology to identify meso-β-scale rain clusters over Hainan Island from 1 June 2000 to 31 December 2018, based on Global Precipitation Measurement (GPM) Integrated Multi-satellitE Retrievals for GPM data. We defined and statistically analyzed the parameters of rain clusters to reveal the typical morphological and precipitation characteristics of rain clusters, and to explore the relationship between the parameters and rainfall intensity of rain clusters. We found that the area and long axis of rain clusters over land were larger than those over the ocean, and that continental rain clusters were usually square in shape. Rain clusters with a larger area and longer axis were concentrated on the northern side of the mountains on Hainan Island and the intensity of rain was larger on the northern and eastern sides of the mountains. The variation of continental rain clusters over time was more dramatic than the variation of oceanic clusters. The area and long axis of rain clusters was larger between 14:00 and 21:00 from April to September and the long axis of the oceanic rain clusters increased in winter. There were clear positive correlations between the area, long axis and shape of the rain clusters and the maximum rain rate. The area and long axis of continental rain clusters had a higher correlation with the rain rate than those of oceanic clusters. The establishment of a relationship between the morphology of rain clusters and precipitation helps us to understand the laws of precipitation and improve the prediction of precipitation in this region.},
DOI = {10.3390/rs13152920}
}



@Article{rs13152937,
AUTHOR = {Zeng, Linglin and Peng, Guozhang and Meng, Ran and Man, Jianguo and Li, Weibo and Xu, Binyuan and Lv, Zhengang and Sun, Rui},
TITLE = {Wheat Yield Prediction Based on Unmanned Aerial Vehicles-Collected Red–Green–Blue Imagery},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {15},
ARTICLE-NUMBER = {2937},
URL = {https://www.mdpi.com/2072-4292/13/15/2937},
ISSN = {2072-4292},
ABSTRACT = {Unmanned aerial vehicles-collected (UAVs) digital red–green–blue (RGB) images provided a cost-effective method for precision agriculture applications regarding yield prediction. This study aims to fully explore the potential of UAV-collected RGB images in yield prediction of winter wheat by comparing it to multi-source observations, including thermal, structure, volumetric metrics, and ground-observed leaf area index (LAI) and chlorophyll content under the same level or across different levels of nitrogen fertilization. Color indices are vegetation indices calculated by the vegetation reflectance at visible bands (i.e., red, green, and blue) derived from RGB images. The results showed that some of the color indices collected at the jointing, flowering, and early maturity stages had high correlation (R2 = 0.76–0.93) with wheat grain yield. They gave the highest prediction power (R2 = 0.92–0.93) under four levels of nitrogen fertilization at the flowering stage. In contrast, the other measurements including canopy temperature, volumetric metrics, and ground-observed chlorophyll content showed lower correlation (R2 = 0.52–0.85) to grain yield. In addition, thermal information as well as volumetric metrics generally had little contribution to the improvement of grain yield prediction when combining them with color indices derived from digital images. Especially, LAI had inferior performance to color indices in grain yield prediction within the same level of nitrogen fertilization at the flowering stage (R2 = 0.00–0.40 and R2 = 0.55–0.68), and color indices provided slightly better prediction of yield than LAI at the flowering stage (R2 = 0.93, RMSE = 32.18 g/m2 and R2 = 0.89, RMSE = 39.82 g/m2) under all levels of nitrogen fertilization. This study highlights the capabilities of color indices in wheat yield prediction across genotypes, which also indicates the potential of precision agriculture application using many other flexible, affordable, and easy-to-handle devices such as mobile phones and near surface digital cameras in the future.},
DOI = {10.3390/rs13152937}
}



@Article{rs13152948,
AUTHOR = {Fernández, Claudio I. and Leblon, Brigitte and Wang, Jinfei and Haddadi, Ata and Wang, Keri},
TITLE = {Detecting Infected Cucumber Plants with Close-Range Multispectral Imagery},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {15},
ARTICLE-NUMBER = {2948},
URL = {https://www.mdpi.com/2072-4292/13/15/2948},
ISSN = {2072-4292},
ABSTRACT = {This study used close-range multispectral imagery over cucumber plants inside a commercial greenhouse to detect powdery mildew due to Podosphaera xanthii. It was collected using a MicaSense® RedEdge camera at 1.5 m over the top of the plant. Image registration was performed using Speeded-Up Robust Features (SURF) with an affine geometric transformation. The image background was removed using a binary mask created with the aligned NIR band of each image, and the illumination was corrected using Cheng et al.’s algorithm. Different features were computed, including RGB, image reflectance values, and several vegetation indices. For each feature, a fine Gaussian Support Vector Machines algorithm was trained and validated to classify healthy and infected pixels. The data set to train and validate the SVM was composed of 1000 healthy and 1000 infected pixels, split 70–30% into training and validation datasets, respectively. The overall validation accuracy was 89, 73, 82, 51, and 48%, respectively, for blue, green, red, red-edge, and NIR band image. With the RGB images, we obtained an overall validation accuracy of 89%, while the best vegetation index image was the PMVI-2 image which produced an overall accuracy of 81%. Using the five bands together, overall accuracy dropped from 99% in the training to 57% in the validation dataset. While the results of this work are promising, further research should be considered to increase the number of images to achieve better training and validation datasets.},
DOI = {10.3390/rs13152948}
}



@Article{rs13152956,
AUTHOR = {Wang, Li and Chen, Shuisen and Li, Dan and Wang, Chongyang and Jiang, Hao and Zheng, Qiong and Peng, Zhiping},
TITLE = {Estimation of Paddy Rice Nitrogen Content and Accumulation Both at Leaf and Plant Levels from UAV Hyperspectral Imagery},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {15},
ARTICLE-NUMBER = {2956},
URL = {https://www.mdpi.com/2072-4292/13/15/2956},
ISSN = {2072-4292},
ABSTRACT = {Remote sensing-based mapping of crop nitrogen (N) status is beneficial for precision N management over large geographic regions. Both leaf/canopy level nitrogen content and accumulation are valuable for crop nutrient diagnosis. However, previous studies mainly focused on leaf nitrogen content (LNC) estimation. The effects of growth stages on the modeling accuracy have not been widely discussed. This study aimed to estimate different paddy rice N traits—LNC, plant nitrogen content (PNC), leaf nitrogen accumulation (LNA) and plant nitrogen accumulation (PNA)—from unmanned aerial vehicle (UAV)-based hyperspectral images. Additionally, the effects of the growth stage were evaluated. Univariate regression models on vegetation indices (VIs), the traditional multivariate calibration method, partial least squares regression (PLSR) and modern machine learning (ML) methods, including artificial neural network (ANN), random forest (RF), and support vector machine (SVM), were evaluated both over the whole growing season and in each single growth stage (including the tillering, jointing, booting and heading growth stages). The results indicate that the correlation between the four nitrogen traits and the other three biochemical traits—leaf chlorophyll content, canopy chlorophyll content and aboveground biomass—are affected by the growth stage. Within a single growth stage, the performance of selected VIs is relatively constant. For the full-growth-stage models, the performance of the VI-based models is more diverse. For the full-growth-stage models, the transformed chlorophyll absorption in the reflectance index/optimized soil-adjusted vegetation index (TCARI/OSAVI) performs best for LNC, PNC and PNA estimation, while the three band vegetation index (TBVITian) performs best for LNA estimation. There are no obvious patterns regarding which method performs the best of the PLSR, ANN, RF and SVM in either the growth-stage-specific or full-growth-stage models. For the growth-stage-specific models, a lower mean relative error (MRE) and higher R2 can be acquired at the tillering and jointing growth stages. The PLSR and ML methods yield obviously better estimation accuracy for the full-growth-stage models than the VI-based models. For the growth-stage-specific models, the performance of VI-based models seems optimal and cannot be obviously surpassed. These results suggest that building linear regression models on VIs for paddy rice nitrogen traits estimation is still a reasonable choice when only a single growth stage is involved. However, when multiple growth stages are involved or missing the phenology information, using PLSR or ML methods is a better option.},
DOI = {10.3390/rs13152956}
}



@Article{rs13152965,
AUTHOR = {Ghaffarian, Saman and Valente, João and van der Voort, Mariska and Tekinerdogan, Bedir},
TITLE = {Effect of Attention Mechanism in Deep Learning-Based Remote Sensing Image Processing: A Systematic Literature Review},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {15},
ARTICLE-NUMBER = {2965},
URL = {https://www.mdpi.com/2072-4292/13/15/2965},
ISSN = {2072-4292},
ABSTRACT = {Machine learning, particularly deep learning (DL), has become a central and state-of-the-art method for several computer vision applications and remote sensing (RS) image processing. Researchers are continually trying to improve the performance of the DL methods by developing new architectural designs of the networks and/or developing new techniques, such as attention mechanisms. Since the attention mechanism has been proposed, regardless of its type, it has been increasingly used for diverse RS applications to improve the performances of the existing DL methods. However, these methods are scattered over different studies impeding the selection and application of the feasible approaches. This study provides an overview of the developed attention mechanisms and how to integrate them with different deep learning neural network architectures. In addition, it aims to investigate the effect of the attention mechanism on deep learning-based RS image processing. We identified and analyzed the advances in the corresponding attention mechanism-based deep learning (At-DL) methods. A systematic literature review was performed to identify the trends in publications, publishers, improved DL methods, data types used, attention types used, overall accuracies achieved using At-DL methods, and extracted the current research directions, weaknesses, and open problems to provide insights and recommendations for future studies. For this, five main research questions were formulated to extract the required data and information from the literature. Furthermore, we categorized the papers regarding the addressed RS image processing tasks (e.g., image classification, object detection, and change detection) and discussed the results within each group. In total, 270 papers were retrieved, of which 176 papers were selected according to the defined exclusion criteria for further analysis and detailed review. The results reveal that most of the papers reported an increase in overall accuracy when using the attention mechanism within the DL methods for image classification, image segmentation, change detection, and object detection using remote sensing images.},
DOI = {10.3390/rs13152965}
}



@Article{rs13152971,
AUTHOR = {Fraser, Benjamin T. and Congalton, Russell G.},
TITLE = {Estimating Primary Forest Attributes and Rare Community Characteristics Using Unmanned Aerial Systems (UAS): An Enrichment of Conventional Forest Inventories},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {15},
ARTICLE-NUMBER = {2971},
URL = {https://www.mdpi.com/2072-4292/13/15/2971},
ISSN = {2072-4292},
ABSTRACT = {The techniques for conducting forest inventories have been established over centuries of land management and conservation. In recent decades, however, compelling new tools and methodologies in remote sensing, computer vision, and data science have offered innovative pathways for enhancing the effectiveness and comprehension of these sampling designs. Now with the aid of Unmanned Aerial Systems (UAS) and advanced image processing techniques, we have never been closer to mapping forests at field-based inventory scales. Our research, conducted in New Hampshire on complex mixed-species forests, used natural color UAS imagery for estimating individual tree diameters (diameter at breast height (dbh)) as well as stand level estimates of Basal Area per Hectare (BA/ha), Quadratic Mean Diameter (QMD), Trees per Hectare (TPH), and a Stand Density Index (SDI) using digital photogrammetry. To strengthen our understanding of these forests, we also assessed the proficiency of the UAS to map the presence of large trees (i.e., &gt;40 cm in diameter). We assessed the proficiency of UAS digital photogrammetry for identifying large trees in two ways: (1) using the UAS estimated dbh and the 40 cm size threshold and (2) using a random forest supervised classification and a combination of spectral, textural, and geometric features. Our UAS-based estimates of tree diameter reported an average error of 19.7% to 33.7%. At the stand level, BA/ha and QMD were overestimated by 42.18% and 62.09%, respectively, while TPH and SDI were underestimated by 45.58% and 3.34%. When considering only stands larger than 9 ha however, the overestimation of BA/ha at the stand level dropped to 14.629%. The overall classification of large trees, using the random forest supervised classification achieved an overall accuracy of 85%. The efficiency and effectiveness of these methods offer local land managers the opportunity to better understand their forested ecosystems. Future research into individual tree crown detection and delineation, especially for co-dominant or suppressed trees, will further support these efforts.},
DOI = {10.3390/rs13152971}
}



@Article{rs13153001,
AUTHOR = {Yang, Kaili and Gong, Yan and Fang, Shenghui and Duan, Bo and Yuan, Ningge and Peng, Yi and Wu, Xianting and Zhu, Renshan},
TITLE = {Combining Spectral and Texture Features of UAV Images for the Remote Estimation of Rice LAI throughout the Entire Growing Season},
JOURNAL = {Remote Sensing},
VOLUME = {13},
YEAR = {2021},
NUMBER = {15},
ARTICLE-NUMBER = {3001},
URL = {https://www.mdpi.com/2072-4292/13/15/3001},
ISSN = {2072-4292},
ABSTRACT = {Leaf area index (LAI) estimation is very important, and not only for canopy structure analysis and yield prediction. The unmanned aerial vehicle (UAV) serves as a promising solution for LAI estimation due to its great applicability and flexibility. At present, vegetation index (VI) is still the most widely used method in LAI estimation because of its fast speed and simple calculation. However, VI only reflects the spectral information and ignores the texture information of images, so it is difficult to adapt to the unique and complex morphological changes of rice in different growth stages. In this study we put forward a novel method by combining the texture information derived from the local binary pattern and variance features (LBP and VAR) with the spectral information based on VI to improve the estimation accuracy of rice LAI throughout the entire growing season. The multitemporal images of two study areas located in Hainan and Hubei were acquired by a 12-band camera, and the main typical bands for constituting VIs such as green, red, red edge, and near-infrared were selected to analyze their changes in spectrum and texture during the entire growing season. After the mathematical combination of plot-level spectrum and texture values, new indices were constructed to estimate rice LAI. Comparing the corresponding VI, the new indices were all less sensitive to the appearance of panicles and slightly weakened the saturation issue. The coefficient of determination (R2) can be improved for all tested VIs throughout the entire growing season. The results showed that the combination of spectral and texture features exhibited a better predictive ability than VI for estimating rice LAI. This method only utilized the texture and spectral information of the UAV image itself, which is fast, easy to operate, does not need manual intervention, and can be a low-cost method for monitoring crop growth.},
DOI = {10.3390/rs13153001}
}



@Article{w13152080,
AUTHOR = {Wang, Yang and Tian, Yongzhong and Cao, Yan},
TITLE = {Dam Siting: A Review},
JOURNAL = {Water},
VOLUME = {13},
YEAR = {2021},
NUMBER = {15},
ARTICLE-NUMBER = {2080},
URL = {https://www.mdpi.com/2073-4441/13/15/2080},
ISSN = {2073-4441},
ABSTRACT = {Dams can effectively regulate the spatial and temporal distribution of water resources, where the rationality of dam siting determines whether the role of dams can be effectively performed. This paper reviews the research literature on dam siting in the past 20 years, discusses the methods used for dam siting, focuses on the factors influencing dam siting, and assesses the impact of different dam functions on siting factors. The results show the following: (1) Existing siting methods can be categorized into three types—namely, GIS/RS-based siting, MCDM- and MCDM-GIS-based siting, and machine learning-based siting. GIS/RS emphasizes the ability to capture and analyze data, MCDM has the advantage of weighing the importance of the relationship between multiple factors, and machine learning methods have a strong ability to learn and process complex data. (2) Site selection factors vary greatly, depending on the function of the dam. For dams with irrigation and water supply as the main purpose, the site selection is more focused on the evaluation of water quality. For dams with power generation as the main purpose, the hydrological factors characterizing the power generation potential are the most important. For dams with flood control as the main purpose, the topography and geological conditions are more important. (3) The integration of different siting methods and the siting of new functional dams in the existing research is not sufficient. Future research should focus on the integration of different methods and disciplines, in order to explore the siting of new types of dams.},
DOI = {10.3390/w13152080}
}



@Article{agronomy11081542,
AUTHOR = {Wang, Hao and Lyu, Suxing and Ren, Yaxin},
TITLE = {Paddy Rice Imagery Dataset for Panicle Segmentation},
JOURNAL = {Agronomy},
VOLUME = {11},
YEAR = {2021},
NUMBER = {8},
ARTICLE-NUMBER = {1542},
URL = {https://www.mdpi.com/2073-4395/11/8/1542},
ISSN = {2073-4395},
ABSTRACT = {Accurate panicle identification is a key step in rice-field phenotyping. Deep learning methods based on high-spatial-resolution images provide a high-throughput and accurate solution of panicle segmentation. Panicle segmentation tasks require costly annotations to train an accurate and robust deep learning model. However, few public datasets are available for rice-panicle phenotyping. We present a semi-supervised deep learning model training process, which greatly assists the annotation and refinement of training datasets. The model learns the panicle features with limited annotations and localizes more positive samples in the datasets, without further interaction. After the dataset refinement, the number of annotations increased by 40.6%. In addition, we trained and tested modern deep learning models to show how the dataset is beneficial to both detection and segmentation tasks. Results of our comparison experiments can inspire others in dataset preparation and model selection.},
DOI = {10.3390/agronomy11081542}
}



@Article{ijms22158266,
AUTHOR = {Kim, Minsu and Lee, Chaewon and Hong, Subin and Kim, Song Lim and Baek, Jeong-Ho and Kim, Kyung-Hwan},
TITLE = {High-Throughput Phenotyping Methods for Breeding Drought-Tolerant Crops},
JOURNAL = {International Journal of Molecular Sciences},
VOLUME = {22},
YEAR = {2021},
NUMBER = {15},
ARTICLE-NUMBER = {8266},
URL = {https://www.mdpi.com/1422-0067/22/15/8266},
PubMedID = {34361030},
ISSN = {1422-0067},
ABSTRACT = {Drought is a main factor limiting crop yields. Modern agricultural technologies such as irrigation systems, ground mulching, and rainwater storage can prevent drought, but these are only temporary solutions. Understanding the physiological, biochemical, and molecular reactions of plants to drought stress is therefore urgent. The recent rapid development of genomics tools has led to an increasing interest in phenomics, i.e., the study of phenotypic plant traits. Among phenomic strategies, high-throughput phenotyping (HTP) is attracting increasing attention as a way to address the bottlenecks of genomic and phenomic studies. HTP provides researchers a non-destructive and non-invasive method yet accurate in analyzing large-scale phenotypic data. This review describes plant responses to drought stress and introduces HTP methods that can detect changes in plant phenotypes in response to drought.},
DOI = {10.3390/ijms22158266}
}




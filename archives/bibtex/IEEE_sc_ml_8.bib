@ARTICLE{8233146,
author={Zhang, Yaodong and Jiang, Chunxiao and Wang, Jingjing and Han, Zhu and Yuan, Jian and Cao, Jiannong},
journal={IEEE Transactions on Industrial Informatics}, title={Green Wi-Fi Implementation and Management in Dense Autonomous Environments for Smart Cities},
year={2018},
volume={14},
number={4},
pages={1552-1563},
abstract={Advanced informatics technologies facilitate the construction of green smart cities, especially the Wi-Fi implementation and management, for rapidly increasing personal Wi-Fi devices in autonomous environments residing in nonoverlapped channels often result in low energy efficiency and severe cochannel interference. In this paper, a green Wi-Fi management framework is constructed in order to reduce the overall energy consumption through turning off a portion of access points (APs) and aggregating their users to the other active APs. A Tabu-search-assisted active AP selection algorithm is proposed to minimize the power consumption with a seamless wireless converge. For the active APs, based on our defined metric airtime cost that is integrated by the in-range interference and the hidden terminal interference, a reinforcement-learning-aided AP self-management algorithm is proposed to dynamically adjust APs' channels in the partially overlapped channel space. Extensive simulations and field experiments demonstrate that the power consumption can be reduced by about 65%, and the airtime cost of APs can be reduced by 50% compared with the typical least congestion channel search algorithm.},
keywords={Energy consumption;Wireless fidelity;Interference;Wireless communication;Green products;Power demand;Informatics;Energy efficiency;green Wi-Fi;partially overlapped channels (POCs);self-management},
doi={10.1109/TII.2017.2785820},
ISSN={1941-0050},
month={April},}
@ARTICLE{9377457,
author={Liu, Xiaoxue and Chen, Yiping and Wei, Mingqiang and Wang, Cheng and Gonçalves, Wesley Nunes and Marcato, José and Li, Jonathan},
journal={IEEE Geoscience and Remote Sensing Letters}, title={Building Instance Extraction Method Based on Improved Hybrid Task Cascade},
year={2022},
volume={19},
number={},
pages={1-5},
abstract={Automatic building extraction from remote sensing imagery is crucial to urban construction and management. To address the main challenges of diverse building scale and appearance, this letter proposes an automatic building instance extraction method based on an improved hybrid task cascade (HTC). Our method consists of three components by obtaining high-resolution representation, defining guided anchor, and forming focal loss to boost the adaptability of automatic building instance extraction. Comprehensive experimental results on WHU aerial building data set demonstrated that compared with the mainstream Mask R-CNN method, our method increased AP and AR in bounding box branch and mask branch by 9.8%–6.5% and 10.7%–8.0% respectively, especially AP $_{S}$ and AP $_{L}$ in the two branches by 10.1%–6.9% and 3.4%–2.4%, respectively. We evaluated the effectiveness and complexity of these components separately and discussed the universality and practicability of deep learning method in automatic building extraction.},
keywords={Buildings;Feature extraction;Convolution;Shape;Semantics;Task analysis;Deep learning;Aerial imagery;building extraction;deep learning;hybrid task cascade;instance segmentation},
doi={10.1109/LGRS.2021.3060960},
ISSN={1558-0571},
month={},}
@ARTICLE{8917577,
author={Yang, Rui and Zhang, Jilin and Wan, Jian and Zhou, Li and Shen, Jing and Zhang, Yunchen and Wei, Zhenguo and Zhang, Juncong and Wang, Jue},
journal={IEEE Access}, title={Parameter Communication Consistency Model for Large-Scale Security Monitoring Based on Mobile Computing},
year={2019},
volume={7},
number={},
pages={171884-171897},
abstract={With the application of mobile computing in the security field, security monitoring big data has also begun to emerge, providing favorable support for smart city construction and city-scale and investment expansion. Mobile computing takes full advantage of the computing power and communication capabilities of various sensing devices and uses these devices to form a computing cluster. When using such clusters for training of distributed machine learning models, the load imbalance and network transmission delay result in low efficiency of model training. Therefore, this paper proposes a distributed machine learning parameter communication consistency model based on the parameter server idea, which is called the limited synchronous parallel model. The model is based on the fault-tolerant characteristics of the machine learning algorithm, and it dynamically limits the size of the synchronization barrier of the parameter server, reduces the synchronization communication overhead, and ensures the accuracy of the model training; thus, the model realizes finite asynchronous calculation between the worker nodes and gives full play to the overall performance of the cluster. The implementation of cluster dynamic load balancing experiments shows that the model can fully utilize the cluster performance during the training of distributed machine learning models to ensure the accuracy of the model and improve the training speed.},
keywords={Machine learning;Computational modeling;Servers;Training;Load modeling;Synchronization;Security;Mobile computing;security monitoring;distributed machine learning;limited synchronous parallel model;parameter server},
doi={10.1109/ACCESS.2019.2956632},
ISSN={2169-3536},
month={},}
@INPROCEEDINGS{7383973,
author={Bi, Xiaodong and Jin, Weizu},
booktitle={2015 International Conference on Intelligent Transportation, Big Data and Smart City}, title={An Improved Collaborative Filtering Similarity Model Based on Neural Networks},
year={2015},
volume={},
number={},
pages={85-89},
abstract={At present, collaborative filtering has already become one of the most widely used means to provide personalized recommendation service. The crux of collaborative filtering is to utilize user-rating-data matrix for the sake of figuring out similar neighbor users or items with similar ratings, which can be realized mainly by virtue of similarity algorithms. Recommendation consequences which are gained though the traditional algorithms, like Pearson correlation coefficient, cosine and so forth, might not be satisfactory, especially in the context of comparatively sparse user-rating-data matrix. The thesis based on the improved similarity algorithms proposed by relevant researchers, analyses the shortcomings of the pre-existing algorithms, redefines the similarity algorithm formulas including the concept of weight, and furthermore makes use of the characteristics of neural network to practice in order to the optimal weight. This thesis designs an experiment on the foundation of two real data sets, comparing the recommendation effects between the newly-built similarity algorithm models and the pre-existing ones. The results indicate that the superiority of the new method in different parameter circumstances.},
keywords={Collaboration;Filtering;Algorithm design and analysis;Analytical models;Data models;Neural networks;Computational modeling;Collaborative filtering;Recommender systems;User similarity;Cold user;Neural networks},
doi={10.1109/ICITBS.2015.27},
ISSN={},
month={Dec},}
@INPROCEEDINGS{9179382,
author={Larsen, Gustavo Henrique and Yoshioka, Leopoldo Rideki and Marte, Claudio Luiz},
booktitle={2020 International Conference on Electrical, Communication, and Computer Engineering (ICECCE)}, title={Bus Travel Times Prediction based on Real-Time Traffic Data Forecast using Artificial Neural Networks},
year={2020},
volume={},
number={},
pages={1-6},
abstract={The concept of Smart Cities is a trend in large cities. Intelligent Transportation Systems) plays an essential role in providing accurate information on bus travel times. It improves the planning of passengers and the agency responsible for public transport. The purpose of this paper is to create a new methodology to predict the travel times of buses based on open data collected in real-time. We constructed a dataset from Sao Paulo City bus fleet location data, real-time traffic data, and traffic forecast from Google Maps. In the following, we trained an Artificial Neural Network (ANN). In the ANN training process, we alternated the dataset and its hyperparameters to find out the combination that provides the lower prediction error. The mean absolute percentage error found was 8.97%, using all data sets except weather data. We showed that our method could provide an accurate bus travel time prediction from web data collected in real-time.},
keywords={Real-time systems;Artificial neural networks;Predictive models;Public transportation;Kalman filters;Cloud computing;Support vector machines;ITS;AVL;API;Data Crossing;ANN},
doi={10.1109/ICECCE49384.2020.9179382},
ISSN={},
month={June},}
@ARTICLE{9210478,
author={Alhussein, Musaed and Aurangzeb, Khursheed and Haider, Syed Irtaza},
journal={IEEE Access}, title={Hybrid CNN-LSTM Model for Short-Term Individual Household Load Forecasting},
year={2020},
volume={8},
number={},
pages={180544-180557},
abstract={Power grids are transforming into flexible, smart, and cooperative systems with greater dissemination of distributed energy resources, advanced metering infrastructure, and advanced communication technologies. Short-term electric load forecasting for individual residential customers plays a progressively crucial role in the operation and planning of future grids. Compared to the aggregated electrical load at the community level, the prediction of individual household electric loads is legitimately challenging because of the high uncertainty and volatility involved. Results from previous studies show that prediction using machine learning and deep learning models is far from accurate, and there is still room for improvement. We herein propose a deep learning framework based on a combination of a convolutional neural network (CNN) and long short-term memory (LSTM). The proposed hybrid CNN-LSTM model uses CNN layers for feature extraction from the input data with LSTM layers for sequence learning. The performance of our developed framework is comprehensively compared to state-of-the-art systems currently in use for short-term individual household electric load forecasting. The proposed model achieved significantly better results compared to other competing techniques. We evaluated our proposed model with the recently explored LSTM-based deep learning model on a publicly available electrical load data of individual household customers from the Smart Grid Smart City (SGSC) project. We obtained an average mean absolute percentage error (MAPE) of 40.38% for individual household electric load forecasts in comparison with the LSTM-based model that obtained an average MAPE of 44.06%. Furthermore, we evaluated the effectiveness of the proposed model on different time horizons (up to 3 h ahead). Compared to the recently developed LSTM-based model tested on the same dataset, we obtained 4.01%, 4.76%, and 5.98% improvement for one, two, and six look-forward time steps, respectively (with 2 lookback time steps). Additionally, we have performed clustering analysis based on the power consumption behavior of the energy users, which indicate that prediction accuracy could be improved by grouping and training the representative model using large amount of data. The results indicated that the proposed model outperforms the LSTM-based model for both 1 h ahead and 3 h ahead in forecasting individual household electric loads.},
keywords={Load modeling;Predictive models;Load forecasting;Forecasting;Machine learning;Data models;Energy consumption;CNN;deep learning framework;energy consumption;energy consumption forecasting;individual household;LSTM},
doi={10.1109/ACCESS.2020.3028281},
ISSN={2169-3536},
month={},}
@INPROCEEDINGS{9322470,
author={Baccour, Emna and Erbad, Aiman and Mohamed, Amr and Hamdi, Mounir and Guizani, Mohsen},
booktitle={GLOBECOM 2020 - 2020 IEEE Global Communications Conference}, title={DistPrivacy: Privacy-Aware Distributed Deep Neural Networks in IoT surveillance systems},
year={2020},
volume={},
number={},
pages={1-6},
abstract={With the emergence of smart cities, Internet of Things (IoT) devices as well as deep learning technologies have witnessed an increasing adoption. To support the requirements of such paradigm in terms of memory and computation, joint and real-time deep co-inference framework with IoT synergy was introduced. However, the distribution of Deep Neural Networks (DNN) has drawn attention to the privacy protection of sensitive data. In this context, various threats have been presented, including black-box attacks, where a malicious participant can accurately recover an arbitrary input fed into his device. In this paper, we introduce a methodology aiming to secure the sensitive data through re-thinking the distribution strategy, without adding any computation overhead. First, we examine the characteristics of the model structure that make it susceptible to privacy threats. We found that the more we divide the model feature maps into a high number of devices, the better we hide proprieties of the original image. We formulate such a methodology, namely DistPrivacy, as an optimization problem, where we establish a trade-off between the latency of co-inference, the privacy level of the data, and the limited-resources of IoT participants. Due to the NP-hardness of the problem, we introduce an online heuristic that supports heterogeneous IoT devices as well as multiple DNNs and datasets, making the pervasive system a general-purpose platform for privacy-aware and low decision-latency applications.},
keywords={Privacy;Image segmentation;Task analysis;Computational modeling;Automobiles;Surveillance;Servers;IoT devices;distributed DNN;privacy;sensitive data;black-box;resource constraints},
doi={10.1109/GLOBECOM42002.2020.9322470},
ISSN={2576-6813},
month={Dec},}
@INPROCEEDINGS{8645596,
author={Ramanathan, Vallikannu and Meyyappan, T.},
booktitle={2019 4th MEC International Conference on Big Data and Smart City (ICBDSC)}, title={Twitter Text Mining for Sentiment Analysis on People’s Feedback about Oman Tourism},
year={2019},
volume={},
number={},
pages={1-5},
abstract={Sentiment analysis plays vital role in the internet era due to extensive range of business applications and social media. Inspiration behind sentiment analysis is that it provides people`s opinion about the product, which helps to improve the product quality. It also supports to take purchase/manufacturing decisions. In this paper we apply sentiment analysis to catch people feedback about Oman tourism using social media messages. For this we use tweeter data set to analyze tourist opinion about this country. In this paper, we recommend innovative sentiment analysis method based on common sense knowledge (Domain Specific Ontology). We created our own Oman tourism ontology based on ConceptNet. Entities are identified from the tweets using POS tagger and entities are compared with concepts in the domain specific ontology. Further the sentiment of the extracted entities are determined by the combined sentiment lexicon approach. Finally semantic orientations of domain specific features are combined with respect to the domain. We deliberate conceptual semantic as feature which can be combined with machine learning algorithm to enhance the performance of sentiment analysis of Oman tourism.},
keywords={Semantics;Sentiment analysis;Ontologies;Feature extraction;Machine learning;Social networking (online);Text mining;Domain specific ontology;Combine sentiment lexicon approach;Semantic features;Conceptual semantic sentiment analysis;machine learning method},
doi={10.1109/ICBDSC.2019.8645596},
ISSN={},
month={Jan},}
@INPROCEEDINGS{9480170,
author={Revati, G. and Hozefa, J. and Shadab, S. and Sheikh, A. and Wagh, S. R. and Singh, N. M.},
booktitle={2021 29th Mediterranean Conference on Control and Automation (MED)}, title={Smart Building Energy Management: Load Profile Prediction using Machine Learning},
year={2021},
volume={},
number={},
pages={380-385},
abstract={Smart buildings are gaining popularity with the surfacing trend of smart grid and smart city. Effective energy management is a major aspect of the smart building management system that demands accurate prediction of building electrical energy consumption profile. The paper focuses on a data-driven approach to load profile prediction with the highlighted benefit of a model-free environment. The electricity consumption profile of a commercial smart building is predicted using Gaussian Process Regression (GPR), and a comparative study is carried out to highlight the issues associated with Polynomial Regression, Artificial Neural Network (ANN), Dynamic Mode Decomposition (DMD), and Hankeled DMD (HDMD). For testing the effectiveness of the proposed methodology, various test scenarios were conducted and from the result, it is observed that the HDMD and GPR are preferred techniques to provide reliable prediction, which is beneficial for arranging a specific demand response schedule to earn benefits like financial rewards and carbon footprint curtailment.},
keywords={Schedules;Smart buildings;Smart cities;Process control;Artificial neural networks;Predictive models;Market research;Dynamic Mode Decomposition;Energy Management;Gaussian Process Regression;Smart Building},
doi={10.1109/MED51440.2021.9480170},
ISSN={2473-3504},
month={June},}
@ARTICLE{8653341,
author={Huang, Zhenhua and Tang, Jinyi and Shan, Guangxu and Ni, Juan and Chen, Yunwen and Wang, Cheng},
journal={IEEE Internet of Things Journal}, title={An Efficient Passenger-Hunting Recommendation Framework With Multitask Deep Learning},
year={2019},
volume={6},
number={5},
pages={7713-7721},
abstract={Using large-scale GPS trajectory data to improve taxi services has recently attracted much attention in Internet of Things and smart city communities. In this paper, we use a large-scale GPS trajectory dataset generated by over 12 000 taxis in a period of three months in Shanghai, China, and present an efficient passenger-hunting recommendation framework with the multitask deep learning paradigm. This framework contains two modules: 1) offline training of passenger-hunting recommendation model (OT-PHRM) and 2) online application of passenger-hunting recommendation model (OA-PHRM). The module OT-PHRM mainly includes two deep convolutional neural networks (DCNNs) and uses the multitask learning strategy. The first DCNN realizes the region prediction for picking up passengers, while the second DCNN uses the weight-sharing structure to predict the levels of road congestion and earnings of carrying passengers. In particular, for the input of two DCNNs, we not only consider contextual features of taxi driving, region features and valuable statistical features, but also combine individual features into meaningful ones. In the module OA-PHRM, we propose DL-PHRec, which calculates three prediction values using two trained DCNNs in OT-PHRM in real time, and then recommends a personal ranking-list of regions to each taxi driver according to their scores. The experimental results show the feasibility and effectiveness of our recommendation framework.},
keywords={Public transportation;Global Positioning System;Training;Vehicles;Task analysis;Trajectory;Roads;Deep learning;Internet of Things;passenger-hunting;representation learning;smart city},
doi={10.1109/JIOT.2019.2901759},
ISSN={2327-4662},
month={Oct},}
@INPROCEEDINGS{9342389,
author={Singh, Nidhi and Kumar, Manoj},
booktitle={2020 IEEE 17th India Council International Conference (INDICON)}, title={Conceptual Framework for Accident Prone Hotspot Identification and Removal using Historical Data Analytics},
year={2020},
volume={},
number={},
pages={1-7},
abstract={Traffic management in a smart city is a significant challenge due to various causes, and among the significant reasons is traffic congestion. Unexpected accidents occur due to multiple factors like bad weather, driving speed, road friction, peak hours, etc. and cause disabilities, health injuries and sometimes loss of life. Therefore, it becomes necessary to discover the relationship among attributes or identify the factor that may lead to the accident under specific situation. In this paper, various relevant papers are reviewed to investigate the accident analysis using traffic data and also a conceptual framework is proposed to predict the accident-prone hotspot using historical data analytics. Further, it is also proposed that alert must be generated for users about the possible precautions by analyzing various factors that could be responsible for the accident.},
keywords={Data analysis;Smart cities;Roads;Traffic congestion;Injuries;Accidents;Meteorology;Accident Analysis;Big Data analytics;Machine Learning;Deep Learning},
doi={10.1109/INDICON49873.2020.9342389},
ISSN={2325-9418},
month={Dec},}
@INPROCEEDINGS{9408027,
author={Wu, Fan and Liu, Huanghe and Zhu, Zongwei and Ji, Cheng and Xue, Chun Jason},
booktitle={2020 IEEE 22nd International Conference on High Performance Computing and Communications; IEEE 18th International Conference on Smart City; IEEE 6th International Conference on Data Science and Systems (HPCC/SmartCity/DSS)}, title={Overcoming Memory Constraint for Improved Target Classification Performance on Embedded Deep Learning Systems},
year={2020},
volume={},
number={},
pages={634-639},
abstract={Pattern recognition applications such as face recognition, detection of broken eggs, and classification of agricultural products are all using image classification in deep neural networks to improve the quality of services. However, traditional cloud inference models suffer from several problems such as network delay fluctuations and privacy leakage. In this regard, most real-time applications currently need to be deployed on edge computing devices. Constrained by the computing power and memory limitations of edge devices, the use of an efficient memory manager for model reasoning is the key to improving the quality of service. This study firstly explored the incremental loading strategy of model weights for the model reasoning. Next, the memory space at runtime is optimized through data layout reorganization from the spatial dimension. In particular, our proposed schemes are orthogonal and transparent to the model. Experimental results demonstrate that the proposed approach reduced the memory consumption by 43.74% on average without additional reasoning time overhead.},
keywords={Privacy;Tensors;Runtime;Computational modeling;Memory management;Layout;Quality of service;Memory management;Edge computing;Deep learning reasoning},
doi={10.1109/HPCC-SmartCity-DSS50907.2020.00081},
ISSN={},
month={Dec},}
@INPROCEEDINGS{8090827,
author={Liu, Shunqiang and Zhai, Sulan and Li, Chenglong and Tang, Jin},
booktitle={2017 International Smart Cities Conference (ISC2)}, title={An effective approach to crowd counting with CNN-based statistical features},
year={2017},
volume={},
number={},
pages={1-5},
abstract={Recent works on crowd counting have achieved promising performance by employing the Convolutional Neurol Network (CNN) based features. These works usually design a deep network to detect pedestrian heads, and then count them. In this paper, we propose a novel approach to count pedestrians effectively based on the statistical CNN features. In particular, our approach only uses the first layer features of the CNN pre-trained offline on ImageNet, and thus obtains an efficient solution for crowd counting. Then, by analyzing the statistical properties of the first layer features, we observate the number of people fluctuates according to the value of the statistical features. Therefore, we employ these statistical features to train SVM, and can thus directly obtain the number of pedestrians. Experimental results on standard benchmark, UCSD, verify the effectiveness of the proposed approach.},
keywords={Feature extraction;Support vector machines;Machine learning;Measurement;Neural networks;Image representation;Convolution;Support Vector Machine;Convolutional Neural Network;Crowd counting;statistical feature},
doi={10.1109/ISC2.2017.8090827},
ISSN={},
month={Sep.},}
@INPROCEEDINGS{9526056,
author={Zheng, Li and Min, Jie and Guo, Chenxi and Yan, Tianfeng},
booktitle={2021 International Conference on Intelligent Transportation, Big Data Smart City (ICITBS)}, title={Multi-scale Feature Fusion in Wireless Propagation Model Optimization Algorithms},
year={2021},
volume={},
number={},
pages={692-696},
abstract={In order to address the effects of various environmental variables on radio propagation and improve the quality of radio propagation. Inspired by the traditional empirical classification method and based on an artificial environment, this paper improves the experiments on the path well prediction results of the wireless propagation model according to the optimization algorithm with satellite remote sensing images as the input data of the network, and selects RESNet50 with the highest recognition efficiency by comparing the experimental data of eight deep learning networks such as VGG16 and RESNet50 under the self-built wireless transmission environment. By adding a feature pyramid to the network, the recognition accuracy of environmental variables reaches 96.4%, and the recognition time is 1.29 seconds per 1000 samples.},
keywords={Wireless communication;Wireless sensor networks;Smart cities;Satellite broadcasting;Radio propagation;Data models;Convolutional neural networks;Deep Learning;Radio Propagation Model;Characteristic Gold Tower},
doi={10.1109/ICITBS53129.2021.00174},
ISSN={},
month={March},}
@ARTICLE{9557305,
author={Chen, Dong and Zhuang, Yuan and Huai, Jianzhu and Sun, Xiao and Yang, Xiansheng and Awais Javed, Muhammad and Brown, Jason and Sheng, Zhengguo and Thompson, John},
journal={IEEE Sensors Journal}, title={Coexistence and Interference Mitigation for WPANs and WLANs From Traditional Approaches to Deep Learning: A Review},
year={2021},
volume={21},
number={22},
pages={25561-25589},
abstract={More and more devices, such as Bluetooth and IEEE 802.15.4 devices forming Wireless Personal Area Networks (WPANs) and IEEE 802.11 devices constituting Wireless Local Area Networks (WLANs), share the 2.4 GHz Industrial, Scientific and Medical (ISM) band in the realm of the Internet of Things (IoT) and Smart Cities. However, the coexistence of these devices could pose a real challenge—co-channel interference that would severely compromise network performances. Although the coexistence issues has been partially discussed elsewhere in some articles, there is no single review that fully summarises and compares recent research outcomes and challenges of IEEE 802.15.4 networks, Bluetooth and WLANs together. In this work, we revisit and provide a comprehensive review on the coexistence and interference mitigation for those three types of networks. We summarize the strengths and weaknesses of the current methodologies, analysis and simulation models in terms of numerous important metrics such as the packet reception ratio, latency, scalability and energy efficiency. We discover that although Bluetooth and IEEE 802.15.4 networks are both WPANs, they show quite different performances in the presence of WLANs. IEEE 802.15.4 networks are adversely impacted by WLANs, whereas WLANs are interfered by Bluetooth. When IEEE 802.15.4 networks and Bluetooth co-locate, they are unlikely to harm each other. Finally, we also discuss the future research trends and challenges especially Deep-Learning and Reinforcement-Learning-based approaches to detecting and mitigating the co-channel interference caused by WPANs and WLANs.},
keywords={IEEE 802.15 Standard;Wireless personal area networks;Bluetooth;Interference;Wireless LAN;Interchannel interference;Sensors;Internet of Things;WPANs;WLANs;Bluetooth;IEEE 802.15.4;interference mitigation;deep learning;reinforcement learning;heterogeneous networks},
doi={10.1109/JSEN.2021.3117399},
ISSN={1558-1748},
month={Nov},}
@ARTICLE{9176996,
author={Hossain, M. Anwar and Ferdousi, Rahatara and Hossain, Sk Alamgir and Alhamid, Mohammed F. and Saddik, Abdulmotaleb El},
journal={IEEE Access}, title={A Novel Framework for Recommending Data Mining Algorithm in Dynamic IoT Environment},
year={2020},
volume={8},
number={},
pages={157333-157345},
abstract={Internet of Things (IoT) has been the driving force for many smart city applications. The huge volume of IoT data generated from these applications require efficient processing to get the insight, which poses significant difficulty. Data mining and machine learning (DM) algorithms are used to minimize such difficulty. However, it is still very challenging to select a particular DM algorithm that can process a dynamic IoT dataset based on some application-specific goals to achieve better accuracy. This paper proposes a knowledge-driven framework that considers the knowledge of datasets, available DM algorithms, and application goals to select the suitable DM algorithm for performing a target data processing task. This work considers data from cultural domain, health domain, and transportation domain in the experiment. The results show that the proposed approach dynamically selects the best-suited DM algorithms for the available datasets and target goals that exhibits satisfactory performance in obtaining accurate results compared to the existing work. The proposed approach not only provides flexibility in conducting dynamic IoT data mining tasks, but also reduces the complexity that would otherwise be necessary while adopting the traditional data mining approaches.},
keywords={Heuristic algorithms;Data mining;Machine learning algorithms;Machine learning;Smart cities;Classification algorithms;Internet of Things;Internet of Things;data mining;machine learning;algorithm selection},
doi={10.1109/ACCESS.2020.3019480},
ISSN={2169-3536},
month={},}
@INPROCEEDINGS{9650427,
author={Goicoechea, María Pía and Mastieri, Julián and Tommasel, Antonela and Rodriguez, Juan Manuel},
booktitle={2021 40th International Conference of the Chilean Computer Science Society (SCCC)}, title={A Deep Learning model for estimating parking space availability},
year={2021},
volume={},
number={},
pages={1-8},
abstract={Finding a free space to park has become one of the main problems for drivers and urban mobility. Traffic congestion, usually caused by drivers looking for a free parking space, can increase energy consumption and air pollution. In this context, providing information regarding the availability of parking spots is crucial to help drivers find a free parking space faster, thus reducing parking search traffic. This paper proposes an approach based on GCNN and an LSTM model to forecast real-time future parking availability by capturing both the temporal occupancy patterns and the geospatial interactions in traffic flow. Different model configurations were evaluated by varying the information fed to the model (e.g., weather forecast, parking violations), the extent of historical data used, and the forecasting period. Experimental evaluation over historical parking data of the city of Tandil in Argentina showed that the proposed approach was able to outperform other state-of-the-art models significantly.},
keywords={Energy consumption;Computational modeling;Urban areas;Weather forecasting;Predictive models;Data models;Real-time systems;parking;smart mobility;deep learning;smart cities},
doi={10.1109/SCCC54552.2021.9650427},
ISSN={2691-0632},
month={Nov},}
@ARTICLE{9167233,
author={Sun, Ying and Su, Zhipeng and Zhao, Ying and Deng, Dan and Zhu, Fusheng and Xia, Junjuan},
journal={IEEE Access}, title={Mobile Cooperative Sensing Based Secure Communication Strategy of Edge Computational Networks for Smart Cities},
year={2020},
volume={8},
number={},
pages={150750-150758},
abstract={With the development of smart cities, lots of mobile cooperative sensing based nodes have emerged. However, due to the open nature of wireless transmission, attackers in the networks can use some intelligent radio devices to deteriorate the secure transmission, which imposes a severe issue of information leakage. In this paper, we consider the transmitter has some computational tasks to be computed, under the environments of intelligent attacker. Due to the limited computational capability, the sender needs to offload some tasks to the receiver. To address this problem, we propose a power allocation algorithm based on combining the technology of reinforcement learning and game theory, in order to achieve an optimal secure data rate and meanwhile reduce the whole task latency of the transmission and computation with Q learning and Nash equilibrium. Then, the Nash equilibrium and its existence conditions are derived and proven mathematically. Finally, we perform some simulations under Matlab platform, and the results show that the proposed algorithm can effectively improve the secrecy data rate and reduce the whole system latency.},
keywords={Task analysis;Sensors;Communication system security;Wireless communication;Wireless sensor networks;Jamming;Smart cities;Mobile cooperative sensing;secure communication;smart environments},
doi={10.1109/ACCESS.2020.3016764},
ISSN={2169-3536},
month={},}
@INPROCEEDINGS{9066655,
author={He, Junjie and Dong, Min and Bi, Sheng and Zhao, Weijie and Liao, Xutao},
booktitle={2019 IEEE 9th Annual International Conference on CYBER Technology in Automation, Control, and Intelligent Systems (CYBER)}, title={A Deep Neural Network for Anomaly Detection and Forecasting for Multivariate Time Series in Smart City},
year={2019},
volume={},
number={},
pages={615-620},
abstract={In the progress of constructing a smart city, large amounts of univariate and multivariate times series data is generated by complex real-world systems and internet of things(IoT) with sensors such as wearable devices. Abnormal status in univariate and multivariate time series are necessary to be identified by abnormal detection methods. Time series forecasting in univariate and multivariate which refers to detect the different patterns in the input time series is significant for managers. However, building a system for anomaly detection and forecasting is challenging. On the one hand, the temporal dependency is required to capture in time series data, on the other hand, inter-correlations in different pairs of time series data are so important for the system that the system needs to encode inter-correlations. In this work, we propose an Attention based Convolutional Recurrent Encoder-Decoder (ACRED), which is effective to address anomaly detection and forecasting problems in time series. The studies based on a Secure Water Treatment tested (SWaT) dataset suggest that ACRED can outperform popular deep recurrent neural network methods.},
keywords={Iron;IP networks;Conferences;Automation;Control systems;Intelligent systems;Neural networks},
doi={10.1109/CYBER46603.2019.9066655},
ISSN={2379-7711},
month={July},}
@ARTICLE{9107118,
author={Zhang, Fuquan and Wu, Tsu-Yang and Wang, Yiou and Xiong, Rui and Ding, Gangyi and Mei, Peng and Liu, Laiyang},
journal={IEEE Access}, title={Application of Quantum Genetic Optimization of LVQ Neural Network in Smart City Traffic Network Prediction},
year={2020},
volume={8},
number={},
pages={104555-104564},
abstract={Accurate prediction of traffic flow in urban networks is of great significance for smart city management. A short-term traffic flow prediction algorithm of Quantum Genetic Algorithm - Learning Vector Quantization (QGA-LVQ) neural network is proposed to forecast the changes of traffic flow. Different from BP neural network, Learning Vector Quantization (LVQ) neural network is of simple structure, easy implementation and better clustering effect. Utilizing the global optimization ability of Quantum Genetic Algorithm (QGA), it is combined with LVQ neural network to overcome some shortcomings of LVQ neural network, including sensitive to initial weights and prone to local minima. In order to test the convergence ability and the timeliness of QGA-LVQ neural network in short-term traffic flow, some contrast experiments are performed. Experimental simulation results show that, QGA-LVQ neural network obtains excellent prediction results in prediction accuracy and convergence speed. Besides, compared with GA-BP neural network and wavelet neural network, QGA-LVQ neural network performs better in short-term traffic flow prediction.},
keywords={Neural networks;Genetic algorithms;Biological cells;Optimization;Prediction algorithms;Hidden Markov models;Qubit;QGA;LVQ neural network;short-term traffic flow prediction;global optimization},
doi={10.1109/ACCESS.2020.2999608},
ISSN={2169-3536},
month={},}
@INPROCEEDINGS{9373129,
author={Huang, Huakun and Ogbodo, Mark and Wang, Zhishang and Qiu, Chen and Hisada, Masayuki and Abdallah, Abderazek Ben},
booktitle={2021 IEEE International Conference on Big Data and Smart Computing (BigComp)}, title={Smart Energy Management System based on Reconfigurable AI Chip and Electrical Vehicles},
year={2021},
volume={},
number={},
pages={233-238},
abstract={Almost every larger city in Europe has ambitious smart city projects. This is particularly true for Hamburg, a Hanseatic city in the north of Germany. Hamburg is the smartest city in Germany according to a Federal Association for Information Technology. Although there are no megacities in the European Union (the largest city in the European Union is Berlin with 3.7 million inhabitants), the increasing urbanization is apparent and produces problems to be solved. At the same time rural depopulation creates conjugated problems.One category of these problems is mobility. Mobility can be regarded as the need to move persons and freight. In densely populated cities an increasing amount of transport users have to share a decreasing amount of space with conflicting needs. At the same time in rural areas, a dwindling supply of local public transport makes the mobility of the remaining residents more difficult. The same applies to parcel delivery or the supply of goods. Autonomous systems have great potential to create a sustainable and livable environment. The author has initiated a publicly funded project to investigate technologies of autonomous mobile systems which interact with a smart city. The test area intelligent urban mobility (Testfeld intelligente Quartiersmobilitat) at the campus of Hamburgs University of Applied Sciences is created to do research on connected and autonomous mobile systems like multipurpose robots and other mobility users like pedestrians with a smartphone. A particular focus is on neighborhood mobility. This means that distances of less than 3 kilometers usually have to be covered. The special type of needs in neighborhood mobility has two important aspects that affect development of autonomous mobile systems: It is slow mobility and the transport users are especially vulnerable. The acceptance of the residents of autonomous systems is equally important, as is the protection of privacy when collecting environmental data. They are expected to make decisions on their own in complex environments. The real world usually differs from a simulation or an experimental setup in a laboratory - a problem commonly referred to as Sim-2-Real gap. Active and non-destructive exploration is expected from an autonomous system to solve unexpected problems. Machine learning methods come into play which in turn have their own pitfalls. The author has built a specialized laboratory to investigate machine learning technology applied to autonomous systems. In this laboratory miniature autonomous vehicles are developed. The general idea of this experimental setup allows research on new methodologies for autonomous systems in a very small scale},
keywords={Scalability;AI accelerators;Wind farms;User interfaces;Batteries;Energy management systems;Sustainable development;Smart Energy Management System;Virtual Power Plant;Hardware and Software Platform;Mobile Edge Intelligence;AI Chip;Electrical Vehicle},
doi={10.1109/BigComp51126.2021.00051},
ISSN={2375-9356},
month={Jan},}
@INPROCEEDINGS{9668589,
author={Lau, Chi-Yat and Yuen, Man-Ching and Yueng, Ka-Ho and Fan, Cheuk-Pan and Ko, On-Yi and Ngan, Lit-Wang and Tam, Wing-Chun and Yeung, Wai-Nam},
booktitle={2022 14th International Conference on COMmunication Systems NETworkS (COMSNETS)}, title={PC-based Intelligent Traffic Monitoring System with Real-time Analysis for Smart Cities},
year={2022},
volume={},
number={},
pages={324-328},
abstract={In recent years, Hong Kong has been experiencing severe traffic problems and especially traffic congestion. In this paper, we proposed a traffic monitoring system which is PC-based, no infrastructure requirement but suitable for the complex road networks in Hong Kong. Besides, our system is designed to recognize vehicle type and plate number for vehicles commonly used in Hong Kong. By analyzing the data collected on road usage, we present our findings for decision-making regarding traffic policies.},
keywords={Solid modeling;Analytical models;Smart cities;Roads;Urban planning;Decision making;Object detection;traffic monitoring;traffic analysis;smart cities;deep learning},
doi={10.1109/COMSNETS53615.2022.9668589},
ISSN={2155-2509},
month={Jan},}
@INPROCEEDINGS{9407972,
author={Hu, Chuanwen and Bai, Yuebin and Wang, Rui and Liu, Chang and Wang, Xiaolin},
booktitle={2020 IEEE 22nd International Conference on High Performance Computing and Communications; IEEE 18th International Conference on Smart City; IEEE 6th International Conference on Data Science and Systems (HPCC/SmartCity/DSS)}, title={CCIED: Cache-aided Collaborative Intelligence Between Edge Devices},
year={2020},
volume={},
number={},
pages={668-673},
abstract={Recently, deep learning technology has shined in the fields of computer vision, natural language processing and speech recognition, and related products have sprung up like mushrooms. Due to the storage and calculation of deep neural network (DNN) models are relatively large and mobile edge devices are often resource-constrained, how to efficiently deploy DNN models on resource-constrained edge devices has attracted great attention from academia and industry. There's strength in numbers, so we propose CCIED, a framework which lets edge devices cooperate with each other to complete DNN inference tasks. Due to task inputs in the mobile edge computing scenarios usually have great similarities, the outputs of the middle layer of the neural network and the corresponding labels are cached. When a similar input already exists in the cache, the device does not need to perform the remaining calculations, but directly returns the cached results. One of the challenges of collaborative inference is that the communication overhead associated with transferring intermediate data can be significant. We therefore perform weight pruning only on the layer that obtains the intermediate results, which can greatly reduce the redundant parameters of the intermediate results, thereby reducing the time for transferring data between devices, and basically does not reduce the complexity of the model. Experimental results show that CCIED can efficiently deploy the DNN model on edge devices with almost no loss of precision, and can significantly reduce the total latency during cache hits.},
keywords={Performance evaluation;Industries;Runtime;Computational modeling;High performance computing;Neural networks;Collaboration;Edge computing;Deep neural networks;Collaborative inference;Cache.},
doi={10.1109/HPCC-SmartCity-DSS50907.2020.00086},
ISSN={},
month={Dec},}
@INPROCEEDINGS{9533828,
author={Lit, Zhen and Cai, Sunzeng and Wang, Xiaoyi and Shao, Hanyang and Niu, Liang and Xue, Nian},
booktitle={2021 International Joint Conference on Neural Networks (IJCNN)}, title={Multiple Object Tracking with GRU Association and Kalman Prediction},
year={2021},
volume={},
number={},
pages={1-8},
abstract={Multiple Object Tracking (MOT) has been a useful yet challenging task in many real-world applications such as video surveillance, intelligent retail, and smart city. The challenge is how to model long-term temporal dependencies in an efficient manner. Some recent works employ Recurrent Neural Networks (RNN) to obtain good performance, which, however, requires a large amount of training data. In this paper, we proposed a novel tracking method that integrates the auto-tuning Kalman method for prediction and the Gated Recurrent Unit (GRU), and achieves a near-optimum with a small amount of training data. Experimental results show that our new algorithm can achieve competitive performance on the challenging MOT benchmark, with higher efficiency and more robustness compared to the state-of-the-art RNN-based online MOT algorithms.},
keywords={Recurrent neural networks;Smart cities;Training data;Benchmark testing;Prediction algorithms;Video surveillance;Robustness},
doi={10.1109/IJCNN52387.2021.9533828},
ISSN={2161-4407},
month={July},}
@INPROCEEDINGS{7944928,
author={Vuppalapati, Jaya Shankar and Kedari, Santosh and Ilapakurthy, Ananth and Ilapakurti, Anitha and Vuppalapati, Chandrasekar},
booktitle={2017 IEEE Third International Conference on Big Data Computing Service and Applications (BigDataService)}, title={Smart Dairies — Enablement of Smart City at Gross Root Level},
year={2017},
volume={},
number={},
pages={118-123},
abstract={Rural and urban areas are linked. A basic definition of rural-urban linkages is that they consist of flows (of goods, people, information, finance, waste, information, social relations) across space, linking rural and urban areas (Cecilia, 2015). Economically, rural and urban areas are linked by the reciprocal exchange of unprocessed and processed products, with both areas acting as mutually reinforcing markets [1]. Perhaps a less descriptive definition is of the functional links between sectors (agriculture, industry and services). The latter is central to structural change taking place in both rural and urban areas. Additionally, rural and urban economies exhibit symbiotic relationship. Cecilia [2] notes "in many regions of the world we are witnessing an increase in production, especially of perishable and high-value products such as fruit, vegetables and dairy, responding to urban demand". This is especially the case in rural areas that are well connected to urban markets by transport links, communications and electricity, and by networks of local traders (Cecilia, 2015). This is especially true with Dairy Industry. The dairy industry exhibits mini ecosystem of rural and urban linkage. The dairy industry plays an important role for both rural and urban dwellers: a) a major source of rural employment (12% to 14% of world population [6]), b) consistent non-seasonal source of income with immediate cash returns, c) major urban consumer staple and d) major contributor of agriculture GDP in developing countries. In many developing countries, dairy industry employees majority of workforce from rural and have direct influence on rural and urban commerce. As per the Food and Agriculture Organization of the United Nations [3], "more than 6 billion people worldwide consume milk and milk products; the majority of these people live in developing countries" [2]. It's clear from the above, urban and rural areas have symbiotic relationship and in order to make urban areas smart, aka Smart Cities, it is imperative that the linkage of urban, in this case rural areas, needs be Smart entities, aka. Smart Villages. For making Smart Village, according to Viswanadham [7] "the existing infrastructure and services (such as Power, Water, Buildings, Retail, Health care, etc.) need to be upgraded and in building the new ones. This requires standardization, use of IT and sensor networks". In this research paper, we propose innovative approach to develop dairy IoT sensor network that enables Smart dairy, making Smart Villages a reality. We offer development of Smart Dairy IoT Sensors that not only identify cattle related health issues but also enable data and information sharing with dairy farmers for better predicting milk production and improvement of productivity. In addition, the data collected from IoT sensor and analytics models play pivotal role in preventing spread of viral flus and cattle health issues. Finally, the data collected from our IoT Dairy sensors and analytics will enable digital transformation at village level thus enabling cities smarter. The paper presents prototyping solution design as well as its application and certain experimental results.},
keywords={Artificial intelligence;Conferences;Big Data;IoT;CEP;Internet Of Things;IoT reference architecture;Decision Tree;Machine Learning;Regression Analysis;Term Frequency and Inverse Document Frequency},
doi={10.1109/BigDataService.2017.35},
ISSN={},
month={April},}
@INPROCEEDINGS{8489031,
author={Oliveira, Thays A. and Barbosa, Alexandre C. and Ramalhinho, Helena and Oliver, Miquel},
booktitle={2018 International Joint Conference on Neural Networks (IJCNN)}, title={Citizens and Information and Communication Technologies},
year={2018},
volume={},
number={},
pages={1-7},
abstract={Smart cities have been receiving great focus during the recent years. One important topic that it covers is the use of technologies to help the connection between smart cities and citizens. These links can influence different cities services and governance such as transport, politics, education, public transparency, citizens' rights, among others. Those services work much better when they are connected, interconnected, participative and transparent. Any kind of environment requires these improvements, both in underdeveloped and developed countries. In this sense, for this cultural and evolution process, it is important to understand how the citizens are responding to these technological stimulus. This work describes and investigates how these themes are treated in the literature, using bibliometric method and data from SCOPUS, Web of Science (WoS), IEEEXplore. In this study, discussions will be focused on the technological area, however, with efforts in reaching distinct strategical areas that are nowadays working side by side on it.},
keywords={Smart cities;Information and communication technology;Databases;Tools;Government;Electronic mail},
doi={10.1109/IJCNN.2018.8489031},
ISSN={2161-4407},
month={July},}
@INPROCEEDINGS{9060109,
author={Jia, Hongda and Ding, Bo and Wang, Huaimin and Gong, Xudong and Zhou, Xing},
booktitle={2019 IEEE SmartWorld, Ubiquitous Intelligence Computing, Advanced Trusted Computing, Scalable Computing Communications, Cloud Big Data Computing, Internet of People and Smart City Innovation (SmartWorld/SCALCOM/UIC/ATC/CBDCom/IOP/SCI)}, title={Fast Adaptation via Meta Learning in Multi-agent Cooperative Tasks},
year={2019},
volume={},
number={},
pages={707-714},
abstract={Multi-agent deep reinforcement learning (MADRL) has been used for disaster rescue and other robotic applications. In most MADRL cases, agents are trained only to deal with specific tasks, so once there are unpredictable changes in target tasks, the earlier trained-models might no longer work, and agents have to get trained again from scratch in limited time, which means traditional MADRL is unsuited to unpredictable post-disaster environments. In order to promote the scalability and flexibility of the multi-agent system, meta-learning, which has achieved few shot learning successfully in supervised deep learning field, could reuse the earlier models as the prior knowledge to guide and speed up the new task learning process. In this work, we propose a framework to apply meta learning methods to multi-agent deep deterministic policy gradient (MADDPG), and achieve efficient adaption to new tasks with less time and fewer samples. Some common experiences in the previous tasks learning will be refined as the meta knowledge. Once the tasks get changed with new scenarios, agents will get retrained with good initial network parameters based on this meta knowledge. Although the new scenarios might be different from the previous scenarios, agents could quickly adjust their policy and get better performance within only few episodes. In two experiments, our method performs better learning efficiency than others, getting higher rewards in the first several episodes of new tasks learning.},
keywords={Task analysis;Training;Machine learning;Learning systems;Learning (artificial intelligence);Robots;Adaptation models;meta learning;multi-agent deep reinforcement learning;few-shot learning},
doi={10.1109/SmartWorld-UIC-ATC-SCALCOM-IOP-SCI.2019.00156},
ISSN={},
month={Aug},}
@ARTICLE{9086138,
author={He, Suining and Shin, Kang G.},
journal={IEEE Transactions on Knowledge and Data Engineering}, title={Spatio-Temporal Capsule-based Reinforcement Learning for Mobility-on-Demand Coordination},
year={2020},
volume={},
number={},
pages={1-1},
abstract={As an alternative means of convenient and smart transportation, mobility-on-demand (MOD), typified by online ride-sharing and connected taxicabs, has been rapidly growing and spreading worldwide. The large volume of complex traffic and the uncertainty of market supplies/demands have made it essential for many MOD service providers to proactively dispatch vehicles towards ride-seekers. To meet this need effectively, we propose STRide, an MOD coordination learning mechanism reinforced spatio-temporally with capsules. We formalize the adaptive coordination of vehicles into a reinforcement learning framework. STRide incorporates spatial and temporal distributions of supplies (vehicles) and demands (ride requests), customers' preferences and other external factors. A novel spatio-temporal capsule neural network is designed to predict the provider's rewards based on MOD network states, vehicles and their dispatch actions. This way, the MOD platform adapts itself to the supply-demand dynamics with the best potential rewards. We have conducted extensive data analytics and experimental evaluation with five large-scale datasets (~27 million rides from Uber, NYC/Chicago Taxis, Didi and Car2Go). STRide is shown to outperform state-of-the-arts, substantially reducing request-rejection rate and passenger waiting time, and also increasing the service provider's profits.},
keywords={Dispatching;Public transportation;Meteorology;Reinforcement learning;Vehicle dynamics;Urban areas;Standards;Mobility-on-demand;ride-sharing platform;human and vehicle mobility;coordination;smart transportation;reinforcement learning;spatio-temporal capsule network;smart city F},
doi={10.1109/TKDE.2020.2992565},
ISSN={1558-2191},
month={},}
@INPROCEEDINGS{9615488,
author={Maryum, Alina and Akram, Muhammad Usman and Salam, Anum Abdul},
booktitle={2021 IEEE 18th International Conference on Smart Communities: Improving Quality of Life Using ICT, IoT and AI (HONET)}, title={Cassava Leaf Disease Classification using Deep Neural Networks},
year={2021},
volume={},
number={},
pages={32-37},
abstract={In recent years, deep learning has gained much popularity over traditional machine learning techniques in terms of accuracy and precision when trained on substantial amount of data. In this work, a state-of-the-art deep learning technique has been employed for classification and prediction of cassava leaf diseases. Being the second largest producer of carbohydrates in the world, cassava plant has become an important source of calories for people in tropical regions, but it is highly susceptible to viral, bacterial, and fungal attacks resulting in stunted plant growth and hence the yield. So, the aim of the research is to help the farmers quickly identify diseased leaves before they cause any severe damage. The dataset that is used in this work is taken from Kaggle competition 2020 containing 21,397 images of cassava plant leaves belonging to 5 classes: Cassava Bacterial Blight, Cassava Brown Streak Disease, Cassava Green Mottle, Cassava Mosaic Disease and Healthy leaves. In this work, EfficientNet model B4 was trained using transfer learning approach. Further, to remove background noise, Segmentation was performed using U-Net to extract only the leaves from images. Our system provided reasonable performance when validation data was provided to trained model yielding 81.43% and 89.09% accuracy on original and segmented datasets, respectively.},
keywords={Deep learning;Image segmentation;Microorganisms;Image resolution;Smart cities;Transfer learning;Semantics;Cassava Plant;Deep Learning;Efficient-Net;Leaf Disease Classification;Segmentation;U-Net},
doi={10.1109/HONET53078.2021.9615488},
ISSN={1949-4106},
month={Oct},}
@INPROCEEDINGS{9046091,
author={Ribeiro, Vinícius and Greati, Vitor and Bezerra, Aguinaldo and Silvano, Gilles and Silva, Ivanovitch and Endo, Patrícia Takako and Lynn, Theo},
booktitle={2019 IX Brazilian Symposium on Computing Systems Engineering (SBESC)}, title={Brazilian Mercosur License Plate Detection: a Deep Learning Approach Relying on Synthetic Imagery},
year={2019},
volume={},
number={},
pages={1-8},
abstract={Automated license plate recognition (ALPR) technology is a powerful technology enabling more efficient and effective law enforcement, security, payment collection, and research. A common license plate standard was adopted by the member states of the Mercosur trading bloc (Argentina, Brazil, Paraguay and Uruguay) and consequently requires an upgrade to the ALPR software used by law enforcement and industry. Due to the scarcity of real license plate images, training state-of-the-art supervised detectors is unfeasible unless data augmentation techniques and synthetic training data are used. This paper presents an accurate and efficient automated Mercosur license plate detector using a Convolutional Neural Network (CNN) trained exclusively with synthetic imagery. In order to obtain the synthetic training data, Mercosur license plates were faithfully reproduced. Digital image processing techniques were employed to reduce the domain gap and a CNN with basic image manipulation was used to embed the artificial licensed plates in to realistic contexts. The trained model was then validated on real images captured from a parking lot and a publicly available traffic monitoring video stream. The results of experiments suggest detection accuracy of about 95% and an average running time of 40 milliseconds.},
keywords={Licenses;Standards;Training;Object detection;Detectors;Deep learning;Law enforcement;mercosur license plates;automated license plate recognition;license plate detection;smart cities;deep learning;synthetic data},
doi={10.1109/SBESC49506.2019.9046091},
ISSN={2324-7894},
month={Nov},}
@INPROCEEDINGS{8260681,
author={Haseltine, Carmen and Eman, Eman El-Sheikh},
booktitle={2017 16th IEEE International Conference on Machine Learning and Applications (ICMLA)}, title={Prediction of Power Grid Failure Using Neural Network Learning},
year={2017},
volume={},
number={},
pages={505-510},
abstract={Power Grid failures have the potential to drastically affect the population be it a localized outage or a large-scale blackout. Pre-event planning currently consists of preparation for all scenarios and some enthusiastic prognoses, leading to most resources spreading thin. Focus on a specific area of concern typically follows large scale power grid failures as post event analysis and does not include an overall analysis. In this study, a neural network is used to conduct “pre-event” analysis of a power grid to determine if it is susceptible to failure. This research study demonstrates that overall “pre-event” analysis can be beneficial with the use of a machine learning agent. The agent can also be used to determine areas that need the most attention. Future work with larger number of constraints and additional machine learning algorithms will be explored to further improve power grid analysis and performance.},
keywords={Power grids;Reliability;Hurricanes;Power system reliability;Neural networks;Monitoring;Control systems;power grid analysis;neural network;SAIDI forecast;binary classification;machine learning application;smart cities},
doi={10.1109/ICMLA.2017.0-111},
ISSN={},
month={Dec},}
@ARTICLE{9093004,
author={Fisher, Andrew and Mago, Vijay and Latimer, Eric},
journal={IEEE Access}, title={Simulating the Evolution of Homeless Populations in Canada Using Modified Deep Q-Learning (MDQL) and Modified Neural Fitted Q-Iteration (MNFQ) Algorithms},
year={2020},
volume={8},
number={},
pages={92954-92968},
abstract={It is estimated that over 235,000 Canadians experience homelessness at some point each year. With the emergence of smart cities, it would be beneficial to leverage the processing power of deep learning to assist in the planning and testing of different policies to address this issue. When examining a population of homeless individuals, one can view them as being distributed, at any one point in time, among several possible states: for example, the street or an emergency shelter. Our work aims to provide a means of simulating across these states, including no longer homeless, over time. The probability that an individual will transition from one state to another is called a transition probability. Thus, by creating a matrix of transition probabilities between all of the states, we have a transition probability matrix. If we simply approached this problem by using a mathematical model such as a Markov decision process, we run into the issue of how to accurately adjust the probabilities to produce realistic results. Ideally, we would have a model that can reasonably modify them based on real-life data. To do this, we introduce two modified deep learning algorithms; modified deep q-learning (MDQL) and modified neural fitted q-iteration (MNFQ). These algorithms dynamically produce a set of transition probability matrices for each week of the year. We discuss the modifications we made to these algorithms to adapt to the homelessness problem and create our simulation. After training our model on high resolution, weekly data, we will show that when running it on a low resolution data set that spans 3 years, our model is able to achieve a relative percent difference from the final population of 12.5%. The end result is a model that can be further improved over time with real world data to provide realistic results.},
keywords={Data models;Mathematical model;Urban areas;Sociology;Statistics;Machine learning;Heuristic algorithms;Simulation;machine learning;homelessness;policy making;planning},
doi={10.1109/ACCESS.2020.2994519},
ISSN={2169-3536},
month={},}
@ARTICLE{9437344,
author={Singh, Parminder and Kaur, Avinash and Batth, Ranbir Singh and Aujla, Gagangeet Singh and Masud, Mehedi},
journal={IEEE Internet of Things Journal}, title={Service vs Protection: A Bayesian Learning Approach for Trust Provisioning in Edge of Things Environment},
year={2021},
volume={},
number={},
pages={1-1},
abstract={Edge of Things (EoT) technology enables end-users participation with smart-sensors and mobile devices (such as smartphones, wearable devices) to the smart devices across the smart city. Trust management is the main challenge in EoT infrastructure to consider the trusted participants. The Quality of Service (QoS) is highly affected by malicious users with fake or altered data. In this paper, a Robust Trust Management (RTM) scheme is designed based on Bayesian learning and collaboration filtering. The proposed RTM model is regularly updated after a specific interval with the significant decay value to the current calculated scores to update the behavior changes quickly. The dynamic characteristics of edge nodes are analyzed with the new probability score mechanism from recent services’ behavior. The performance of the proposed trust management scheme is evaluated in a simulated environment. The percentage of collaboration devices are tuned as 10%, 50% and 100%. The maximum accuracy of 99.8% is achieved from the proposed RTM scheme. The experimental results demonstrate that the RTM scheme shows better performance than the existing techniques in filtering malicious behavior and accuracy.},
keywords={Trust management;Internet of Things;Smart cities;Computational modeling;Peer-to-peer computing;Data models;Analytical models;Edge of Things (EoT);Trust management;Machine Learning;Smart city;Smart Sensors;Malicious attack.},
doi={10.1109/JIOT.2021.3082272},
ISSN={2327-4662},
month={},}
@ARTICLE{9585309,
author={Chen, Xiaohong and Deng, Changxing and Zhou, Binggui and Zhang, Huan and Yang, Guanghua and Ma, Shaodan},
journal={IEEE Wireless Communications Letters}, title={High-Accuracy CSI Feedback With Super-Resolution Network for Massive MIMO Systems},
year={2022},
volume={11},
number={1},
pages={141-145},
abstract={Acquiring accurate channel state information (CSI) is critical for downlink precoding in frequency division duplexity (FDD) massive multiple-input multiple-output (MIMO) systems. In contrast to the traditional compressive sensing (CS) based methods, whose performance is hindered by excessive feedback overhead, this letter proposes a super-resolution network (SRNet) to compress and reconstruct the CSI. Specifically, the SRNet consists of encoder and decoder, where the encoder can transform channel matrices into codewords, and the decoder can restore different levels of spatial frequency features of CSI image based on a modified embedded block residual network (EBRN+). In addition, a principal component mark (PCM) method is proposed before encoding to lighten the encoder at UE. The experiment results show that our proposed model can achieve better performance than the state-of-the-art models with less training parameters and lower computational complexity at UE. Moreover, the superiority of our proposed model becomes much more significant especially under high compression ratio scenarios.},
keywords={Phase change materials;Image reconstruction;Image coding;Decoding;Massive MIMO;Downlink;Image restoration;CSI feedback;deep learning;massive MIMO;super-resolution network},
doi={10.1109/LWC.2021.3122462},
ISSN={2162-2345},
month={Jan},}
@INPROCEEDINGS{8397672,
author={Wang, Shuo and Ozcan, Koray and Sharma, Anuj},
booktitle={2017 IEEE SmartWorld, Ubiquitous Intelligence Computing, Advanced Trusted Computed, Scalable Computing Communications, Cloud Big Data Computing, Internet of People and Smart City Innovation (SmartWorld/SCALCOM/UIC/ATC/CBDCom/IOP/SCI)}, title={Region-based deformable fully convolutional networks for multi-class object detection at signalized traffic intersections: NVIDIA AICity challenge 2017 Track 1},
year={2017},
volume={},
number={},
pages={1-4},
abstract={Multi-class object detection is critical for intelligent traffic monitoring applications in smart cities as well as connected autonomous vehicles. Although, numerous research works evaluate the performance of image processing algorithms for on-vehicle cameras, the body of research evaluating performance of image processing of stationary cameras located near intersections is limited. In this research, we use region-based deformable fully convolutional networks to detect 14 different object classes within images from traffic surveillance cameras. The object classes include vehicles, pedestrians, bicyclists and traffic signals. The goal of the NVIDIA AICity challenge is to provide accurate localization and correct classification of objects for stationary cameras mounted near signalized traffic intersections. Our proposed method scores mean average precision of 0.41, 0.37, and 0.34 for aic480, aic1080, and aic540 challenge datasets.},
keywords={Object detection;Training;Cameras;Convolution;Proposals;Surveillance;Traffic control;multi-class object detection;surveillance camera;deformable convolutional networks;deep learning},
doi={10.1109/UIC-ATC.2017.8397672},
ISSN={},
month={Aug},}
@INPROCEEDINGS{9264859,
author={Amrani, A. and Pasini, K. and Khouadjia, M.},
booktitle={2020 Forum on Integrated and Sustainable Transportation Systems (FISTS)}, title={Enhance Journey Planner with Predictive Travel Information for Smart City Routing Services},
year={2020},
volume={},
number={},
pages={304-308},
abstract={Route planning in public transport receives an increasing interest in smart cities and particularly in metropolitan cities where crowded and jammed traffic is daily recorded in the transportation network. The availability of digital footprints, such as ticketing logs, or load on board the trains, provides a relevant opportunity to develop innovative decision-making tools for urban routing of passengers in order to assist them to better plan their journeys. In this paper, we propose to enrich existing journey planners with predictive travel information to enhance the passenger travel experience during his journey. For that purpose, we augment the planned trips with predictive passenger flow indicators such as the load on board trains, and passenger attendees at the station. These indicators are forecasted along the journey with the help of the developed machine learning models. The experiments are conducted on a real historical dataset covering the Paris Region with a focus on a railway transit network that serves mainly the suburb of Paris.},
keywords={Predictive models;Forecasting;Load modeling;Transportation;Real-time systems;Schedules;Computer architecture},
doi={10.1109/FISTS46898.2020.9264859},
ISSN={},
month={Nov},}
@INPROCEEDINGS{8683312,
author={Zeng, Weihong and Li, Fei and Huang, Hongyu and Huang, Yue and Ding, Xinghao},
booktitle={ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, title={Two-stream Multi-focus Image Fusion Based on the Latent Decision Map},
year={2019},
volume={},
number={},
pages={1762-1766},
abstract={The multi-focus image fusion with deep learning methods is mostly regarded as a two or three-category problem. Current systems utilize sliding windows to classify each pixel into focused or defocused, which is time consuming and requires post-processing such as denoising. In this paper, we propose a novel network architecture for multi-focus image fusion based on the latent decision map. For a regression task instead of a classification problem, we focus on learning the latent spatial decision map. This decision map indicates the degree of each focused pixel. To further improve the fusion result, we utilize the ResNet blocks to extract image features, and then combine low-level features with high-level semantic information. Our apporach makes the learning process easier and has better robustness and efficiency as well. Experimental results demonstrate that our framework has ability of achieving the state-of-the-art in terms of both qualitative and quantitative measures.},
keywords={Multi-Focus;Image Fusion;Two-Stream Feature Extraction;Latent Decision Map},
doi={10.1109/ICASSP.2019.8683312},
ISSN={2379-190X},
month={May},}
@INPROCEEDINGS{8669665,
author={Wang, Yu},
booktitle={2019 International Conference on Intelligent Transportation, Big Data Smart City (ICITBS)}, title={Development and Implementation of Intelligent Mathematics Teaching System Based on Individualized Learning Model},
year={2019},
volume={},
number={},
pages={417-420},
abstract={This paper inherits the advantages of the existing intelligent teaching system for mathematics and improves it by individualized learning model. A personalized intelligent teaching system of mathematics in primary schools based on EGL is studied and designed. First, the whole process of WEB2.0 program based on EGL language design is discussed based on in-depth learning, and its rationality and feasibility are analyzed. Then the specific business needs of personalized intelligent teaching are discussed and analyzed. Finally, by the implementation of the system, a relatively comprehensive system function and performance test is carried out, which proves that the scheme can effectively enhance the human-computer interaction experience of the system and improve the real-time performance of system.},
keywords={Education;Data models;Business;Analytical models;Mathematical model;Deep learning;mathematics teaching;deep learning;interest model;EGL},
doi={10.1109/ICITBS.2019.00109},
ISSN={},
month={Jan},}
@INPROCEEDINGS{9562915,
author={Sabour, Sepehr and Rao, Sanjeev and Ghaderi, Majid},
booktitle={2021 IEEE International Smart Cities Conference (ISC2)}, title={DeepFlow: Abnormal Traffic Flow Detection Using Siamese Networks},
year={2021},
volume={},
number={},
pages={1-7},
abstract={Nowadays, many cities are equipped with surveillance systems and traffic control centers to monitor vehicular traffic for road safety and efficiency. The monitoring process is mostly done manually which is inefficient and expensive. In recent years, several data-driven solutions have been proposed in the literature to automatically analyze traffic flow data using machine learning techniques. However, existing solutions require large and comprehensive datasets for training which are not readily available, thus limiting their application. In this paper, we develop a traffic anomaly detection system, referred to as DeepFlow, based on Siamese neural networks, which are suitable in scenarios where only small datasets are available for training. Our model can detect abnormal traffic flows by analyzing the trajectory data collected from the vehicles in a fleet. To evaluate DeepFlow, we use realistic vehicular traffic simulations in SUMO. Our results show that DeepFlow detects abnormal traffic patterns with an F1 score of 78%, while outperforming other existing approaches including: Dynamic Time Warping (DTW), Global Alignment Kernels (GAK), and iForest.},
keywords={Training;Smart cities;Shape;Surveillance;Neural networks;Machine learning;Traffic control},
doi={10.1109/ISC253183.2021.9562915},
ISSN={2687-8860},
month={Sep.},}
@INPROCEEDINGS{8669636,
author={Lin, Zhi-heng and Li, Yong-zhen},
booktitle={2019 International Conference on Intelligent Transportation, Big Data Smart City (ICITBS)}, title={Design and Implementation of Classroom Attendance System Based on Video Face Recognition},
year={2019},
volume={},
number={},
pages={385-388},
abstract={Classroom attendance, as an indispensable part of teaching activities, plays a very important role in classroom teaching. Classroom attendance can effectively supervise students to attend classes on time and ensure the quality of classroom teaching. However, the current classroom attendance is mainly achieved by the way of teacher's name-calling, which will cause a lot of waste of classroom time. This paper presents a classroom attendance system based on video face recognition technology. The system uses a camera installed in the classroom to obtain classroom video information. For the collected video information, it is first divided into a frame of static pictures, and from the pictures, several pictures with clear face and better light are selected for face recognition, and finally the recognition results are aggregated and merged. In order to solve the influence of the location of the camera on the recognition results, the system can be combined with the platform control system to control the rotation and focusing of the camera through the platform, and further improve the recognition accuracy.},
keywords={Face recognition;Cameras;Servers;Education;Face;Streaming media;Deep learning;attendance-in-class;face-recognition;image-segmentation;deep-learning},
doi={10.1109/ICITBS.2019.00101},
ISSN={},
month={Jan},}
@INPROCEEDINGS{9604507,
author={Zhang, Hailiang and Ma, Wenming and Shi, Zhenjie and Yin, Shuai and Zhao, Xiaofan},
booktitle={2021 IEEE SmartWorld, Ubiquitous Intelligence Computing, Advanced Trusted Computing, Scalable Computing Communications, Internet of People and Smart City Innovation (SmartWorld/SCALCOM/UIC/ATC/IOP/SCI)}, title={Indicator Diagram for Power Prediction of Pumping Unit Based on Machine Learning},
year={2021},
volume={},
number={},
pages={501-506},
abstract={This paper studies the problem of using machine learning to predict the indicator diagram of pumping unit according to the power of pumping unit in a period of time. In the past, it was troublesome to install a machine to collect indicator diagram data or indirectly collect the size of pumping units. This paper introduces several methods of indirectly predicting indicator diagram based on power. They are two nearest neighbor methods and three DNN methods. Finally, through experimental comparison, it is proved that the DNN network model with embedding layers used to distinguish different pumping unit specifications has better prediction index diagram ability, and its prediction index diagram is basically consistent with the original index diagram, which can replace the traditional method.},
keywords={Deep learning;Training;Pumps;Neurons;Predictive models;Data models;Indexes;Deep learning;Embedding;DNN;Indicator diagram;Pumping unit;KNN},
doi={10.1109/SWC50871.2021.00074},
ISSN={},
month={Oct},}
@INPROCEEDINGS{9323218,
author={Li, Wen and Zhang, Ziyue and Luo, Zhipeng and Xiao, Zhenlong and Wang, Cheng and Li, Jonathan},
booktitle={IGARSS 2020 - 2020 IEEE International Geoscience and Remote Sensing Symposium}, title={Extraction of Power Lines and Pylons from LiDAR Point Clouds Using a GCN-Based Method},
year={2020},
volume={},
number={},
pages={2767-2770},
abstract={The routine power line inspection is critical to maintain the reliability, availability, and sustainability of electricity supply. As a key part of inspection, power lines and pylons extraction is essential for resource management and power corridor safety, especially in the mountain regions. In this paper, we proposed a deep learning based method to extract power lines and pylons using ALS point clouds. First, a structure information preserved module is designed to mine the relationship of local neighborhood points. Then, a graph convolutional network (GCN) is used as basic module to extract point features. Finally, three categories, power lines, pylons and other objects are segmented from input point clouds. In addition, we provide an effective data enhancement strategy to generate enough samples to train the proposed model. We evaluated our method using a dataset acquired by our ALS scanning system. Experimental results demonstrate that our method is superior to the state-of-the-art methods on descriptiveness and efficiency. The overall accuracy and mean time are 99.1% and 9.3 seconds, respectively.},
keywords={Feature extraction;Poles and towers;Three-dimensional displays;Filtering;Data mining;Deep learning;Transforms;Power line;pylon extraction;ALS;point cloud;graph convolutional network},
doi={10.1109/IGARSS39084.2020.9323218},
ISSN={2153-7003},
month={Sep.},}
@ARTICLE{9325555,
author={Qi, Yimeng and Jin, Long and Luo, Xin and Zhou, MengChu},
journal={IEEE Transactions on Neural Networks and Learning Systems}, title={Recurrent Neural Dynamics Models for Perturbed Nonstationary Quadratic Programs: A Control-Theoretical Perspective},
year={2021},
volume={},
number={},
pages={1-12},
abstract={Recent decades have witnessed a trend that control-theoretical techniques are widely leveraged in various areas, e.g., design and analysis of computational models. Computational methods can be modeled as a controller and searching the equilibrium point of a dynamical system is identical to solving an algebraic equation. Thus, absorbing mature technologies in control theory and integrating it with neural dynamics models can lead to new achievements. This work makes progress along this direction by applying control-theoretical techniques to construct new recurrent neural dynamics for manipulating a perturbed nonstationary quadratic program (QP) with time-varying parameters considered. Specifically, to break the limitations of existing continuous-time models in handling nonstationary problems, a discrete recurrent neural dynamics model is proposed to robustly deal with noise. This work shows how iterative computational methods for solving nonstationary QP can be revisited, designed, and analyzed in a control framework. A modified Newton iteration model and an improved gradient-based neural dynamics are established by referring to the superior structural technology of the presented recurrent neural dynamics, where the chief breakthrough is their excellent convergence and robustness over the traditional models. Numerical experiments are conducted to show the eminence of the proposed models in solving perturbed nonstationary QP.},
keywords={Computational modeling;Mathematical model;Neural networks;Control theory;Analytical models;Real-time systems;Numerical models;Control-theoretical techniques;perturbed nonstationary quadratic program (QP);recurrent neural dynamics;robustness theoretical analysis.},
doi={10.1109/TNNLS.2020.3041364},
ISSN={2162-2388},
month={},}
@INPROCEEDINGS{8355147,
author={Park, Jiho and Jang, Kiyoung and Yang, Sung-Bong},
booktitle={2018 IEEE 4th World Forum on Internet of Things (WF-IoT)}, title={Deep neural networks for activity recognition with multi-sensor data in a smart home},
year={2018},
volume={},
number={},
pages={155-160},
abstract={Multi-sensor based human activity recognition is one of the challenges in the ambient intelligent environments such as smart home and smart city. Ordinary people in their daily lives usually share a similar and repetitive life pattern, also known as life cycle. Smart home environment and its multi sensors can provide assistance to human by collecting the data sequence of human activities to predict the desired actions. Our goal is to analyze the sequence of activities recorded by a specific resident using deep learning with multiple sensor data. In this paper, we train the multiple sensor data collected by a smart home using several deep neural networks. According to the characteristics of the Recurrent Neural Network (RNN) structure, multiple sensor data of smart home is suitable for RNN because it has a sequence data in time. To support our assumption, we proposed the Residual-RNN architecture to predict future activities of a resident. Furthermore, we also utilized attention module to filter out the meaningless data to have more effective results than the one without. To verify our proposed idea, we used real resident activity in smart home using Massachusetts Institute of Technology (MIT) dataset. After our experiments, our proposed model with attention mechanism outperform the Long Short-Term Memory (LSTM) and Gated Recurrent Unit (GRU) model in terms of predicting the desired activities of a smart home resident.},
keywords={Activity recognition;Intelligent sensors;Smart homes;Computer architecture;Microprocessors;Logic gates;Recurrent neural networks;Attention;Deep learning;Human activity recognition;Activity of daily life (ADL);Smart home},
doi={10.1109/WF-IoT.2018.8355147},
ISSN={},
month={Feb},}
@INPROCEEDINGS{8489344,
author={Santos, Edcarllos and Penna, Puca Huachi Vaz and Coelho, Igor Machado and Soares, Heder Dorneles and Ochi, Luiz Satoru and Simonetti, Luidi},
booktitle={2018 International Joint Conference on Neural Networks (IJCNN)}, title={Logistics SLA optimization service for transportation in smart cities},
year={2018},
volume={},
number={},
pages={1-8},
abstract={A Service-Level Agreement (SLA) usually refers to computational services (e.g., cloud/web services), indicating contract goals and expected Quality of Service (QoS), recently extended for transportation problems called Logistics SLA. Transportation problems are being systematically studied for Smart City (SC) applications due to its huge importance: public transportation services, drone delivery services, battery recharging for electric vehicles, and also transportation for private companies considering real-time traffic information. Many of these transportations problems involve not only one-way deliveries, but also pickups, forming a set of routes with desired QoS such as maximum route length/time, delivery/pickup sequences and time-windows. In order to achieve all desired QoS, while minimizing routing distances, this problem can be seen as an extension of the challenging Vehicle Routing Problem (VRP), which is known to be NP-Hard. Computational intelligence strategies such as metaheuristics are often employed to find near-optimal solutions in short computational times. In this paper, we deal with a practical industrial problem involving employees transportation to a workplace in a Brazilian metropolis, involving minimization of operational costs, achievement of QoS requirements and visualization of the routes.},
keywords={Transportation;Contracts;Quality of service;Employment;Logistics;Companies;Routing},
doi={10.1109/IJCNN.2018.8489344},
ISSN={2161-4407},
month={July},}
@INPROCEEDINGS{7825159,
author={Shuo, Li and Guodong, Li and Xiaoting, Wei and Lele, Wang},
booktitle={2016 International Conference on Smart City and Systems Engineering (ICSCSE)}, title={Robustness Design of Logic or CNN Template for Binary Image},
year={2016},
volume={},
number={},
pages={535-538},
abstract={The algorithm of logical or operation for binary image is less. A kind of Cellular Neural Networks (CNN) template that can realize logic or of binary image was studied and a new algorithm was proposed. By setting binary image logic or algorithms, and analyzes LOGOR CNN template robustness, proposed a theorem, finally gives a strict mathematical proof. As long as the actual use of the template parameters conform to theorem is given in the parameter range, CNN can realize logic or operation of binary image. Experimental results verify the effectiveness of LOGOR CNN and the feasibility of the design robustness theorem in practical application.},
keywords={Robustness;Mathematical model;Kinetic theory;Digital images;Algorithm design and analysis;Cellular neural networks;Standards;binary image;cellular neural networks;logic or operations;robust design},
doi={10.1109/ICSCSE.2016.0146},
ISSN={},
month={Nov},}
@INPROCEEDINGS{9647850,
author={Mosaiyebzadeh, Fatemeh and Araujo Rodriguez, Luis Gustavo and Macêdo Batista, Daniel and Hirata, R.},
booktitle={2021 IEEE Latin-American Conference on Communications (LATINCOM)}, title={A Network Intrusion Detection System using Deep Learning against MQTT Attacks in IoT},
year={2021},
volume={},
number={},
pages={1-6},
abstract={Cyber-attacks and threats are growing fast in the Internet of Things (IoT) infrastructure as applications in smart cities gain momentum. Usually, IoT devices communicate via machine-to-machine protocols such as Message Queuing Telemetry Transport (MQTT). Due to the heterogeneous structure in IoT and the absence of security by design methodologies, security mechanisms in environments with MQTT traffic are needed, and they can be deployed as Intrusion Detection Systems (IDS). This paper proposes a Deep Learning (DL) based Network IDS trained using a public dataset containing MQTT attacks. We assess the proposal using standard performance metrics such as accuracy, precision, recall, F1-score, and weighted average. When evaluating the performance of our DL-based Network IDS, it obtained, in average, 97.09% of accuracy and an F1-score equal to 98.33% in the detection of MQTT attacks. Another important contribution of our work is the sharing of the experiments on GitHub, which guarantees the reproducibility of the research.},
keywords={Deep learning;Protocols;Smart cities;Reproducibility of results;Security;Internet of Things;Telemetry;MQTT;IoT;Deep Learning;Cybersecurity.},
doi={10.1109/LATINCOM53176.2021.9647850},
ISSN={2330-989X},
month={Nov},}
@INPROCEEDINGS{7463805,
author={Assem, Haytham and O'Sullivan, Declan},
booktitle={2015 IEEE International Conference on Smart City/SocialCom/SustainCom (SmartCity)}, title={Towards Bridging the Gap between Machine Learning Researchers and Practitioners},
year={2015},
volume={},
number={},
pages={702-708},
abstract={As data keeps growing, Big Data starts to be everywhere, and there is almost an urgent need to make sense of this data. This is why Machine Learning has become crucial as it aids in improving business, decision making and it has the potential to provide solutions for a wide range of problems in computer science and other fields. Machine Learning (a.k.a. Data Mining or Predictive Analytics) algorithms can learn how to perform certain tasks by generalizing from the out of sample examples. This is a totally different paradigm than traditional programming language approaches based on writing programs that process data to produce an output. However, choosing a suitable machine learning algorithm for a particular application requires substantial amount of effort that is even hard to undertake even with text books. In order to reduce the effort, this paper introduces a recommender system that will aid machine learning researchers and practitioners to choose the optimum machine learning model to use. The system is based on an approach that is introduced in the paper called TCDC which stands for Train, Compare, Decide, and Change.},
keywords={Predictive models;Computational modeling;Adaptation models;Data models;Supervised learning;Measurement;Recommender systems;Machine Learning;Predictive Modelling;Supervised Learning;Regression Models;Classification Models},
doi={10.1109/SmartCity.2015.151},
ISSN={},
month={Dec},}
@INPROCEEDINGS{9408054,
author={Mohammadi, Samin and Chapon, Mathieu},
booktitle={2020 IEEE 22nd International Conference on High Performance Computing and Communications; IEEE 18th International Conference on Smart City; IEEE 6th International Conference on Data Science and Systems (HPCC/SmartCity/DSS)}, title={Investigating the Performance of Fine-tuned Text Classification Models Based-on Bert},
year={2020},
volume={},
number={},
pages={1252-1257},
abstract={Recently, deep learning has achieved impressive success in text mining and Natural Language Processing tasks. Bert is one of the remarkably rewarding deep learning models that is employed in a variety of NLP classification tasks such as intent and topic detection, question answering, sentiment analysis, hate speech detection, and so on. Plenty of studies have implemented different models of classification using pre-trained Bert models. Fine-tuning is done by adding either a simple fully connected layer, BiLSTM, convolutional layers, or a combination of them. Each of those models has fine-tuned Bert for a specific task. The results do not always approve neither the efficiency of using complex fine-tuned models of Bert nor the generalization of them. In this study, we extensively inspected various Bert-based fine-tuning models for different text classification tasks. Several types of fine-tuning Bert models varying in their classification layer are implemented and the performance of them is meticulously investigated. The implemented fine-tuning models are using alternatively deep learning networks such as convolutional networks and BiLSTM. The output layer of each model is studied to receive entirely varying inputs coming from the distinct layers of Bert. We conducted considerable experiments to find the most general outperforming model. We discover that adding a simple dense layer to the pre-trained Bert model, as a classifier, surpasses other types of deep neural network layers in the investigated tasks. We examine different values of hyperparameters to find the optimized combination providing the highest performance.},
keywords={Deep learning;Voice activity detection;Text mining;Analytical models;Sentiment analysis;Computational modeling;Text categorization;Text classification;Natural language processing;Deep learning;Fine-tuning model},
doi={10.1109/HPCC-SmartCity-DSS50907.2020.00162},
ISSN={},
month={Dec},}
@ARTICLE{8938741,
author={Tanwar, Sudeep and Bhatia, Qasim and Patel, Pruthvi and Kumari, Aparna and Singh, Pradeep Kumar and Hong, Wei-Chiang},
journal={IEEE Access}, title={Machine Learning Adoption in Blockchain-Based Smart Applications: The Challenges, and a Way Forward},
year={2020},
volume={8},
number={},
pages={474-488},
abstract={In recent years, the emergence of blockchain technology (BT) has become a unique, most disruptive, and trending technology. The decentralized database in BT emphasizes data security and privacy. Also, the consensus mechanism in it makes sure that data is secured and legitimate. Still, it raises new security issues such as majority attack and double-spending. To handle the aforementioned issues, data analytics is required on blockchain based secure data. Analytics on these data raises the importance of arisen technology Machine Learning (ML). ML involves the rational amount of data to make precise decisions. Data reliability and its sharing are very crucial in ML to improve the accuracy of results. The combination of these two technologies (ML and BT) can provide highly precise results. In this paper, we present a detailed study on ML adoption for making BT-based smart applications more resilient against attacks. There are various traditional ML techniques, for instance, Support Vector Machines (SVM), clustering, bagging, and Deep Learning (DL) algorithms such as Convolutional Neural Network (CNN) and Long short-term memory (LSTM) can be used to analyse the attacks on a blockchain-based network. Further, we include how both the technologies can be applied in several smart applications such as Unmanned Aerial Vehicle (UAV), Smart Grid (SG), healthcare, and smart cities. Then, future research issues and challenges are explored. At last, a case study is presented with a conclusion.},
keywords={Blockchain;Security;Machine learning;Taxonomy;Databases;Prediction algorithms;Malware;Blockchain;machine learning;smart grid;data security and privacy;data analytics;smart applications},
doi={10.1109/ACCESS.2019.2961372},
ISSN={2169-3536},
month={},}
@INPROCEEDINGS{9606402,
author={Yang, Helin and Zhao, Jun and Lam, Kwok-Yan and Garg, Sahil and Wu, Qingqing and Xiong, Zehui},
booktitle={2021 17th International Conference on Wireless and Mobile Computing, Networking and Communications (WiMob)}, title={Deep Reinforcement Learning Based Resource Allocation for Heterogeneous Networks},
year={2021},
volume={},
number={},
pages={253-258},
abstract={This paper investigates the problem of distributed resource management (i.e., joint device association, spectrum allocation, and power allocation) in two-tier heterogeneous networks without any central controller. Considering the fact that the network is highly complex with large state and action spaces, a multi-agent dueling deep-Q network-based algorithm combined with distributed coordinated learning is proposed to effectively learn the optimized intelligent resource management policy, where the algorithm adopts dueling deep network to learn the action-value distribution by estimating both the state-value and action advantage functions. Under the distributed coordinated learning manner and dueling architecture, the learning algorithm can rapidly converge to the optimized policy. Simulation results demonstrate that the proposed distributed coordinated learning algorithm outperforms other existing learning algorithms in terms of learning efficiency, network data rate, and QoS satisfaction probability.},
keywords={Heuristic algorithms;Wireless networks;Simulation;Reinforcement learning;Quality of service;Tools;Heterogeneous networks;Heterogeneous wireless networks;distributed resource management;dueling deep reinforcement learning},
doi={10.1109/WiMob52687.2021.9606402},
ISSN={2160-4894},
month={Oct},}
@ARTICLE{9658533,
author={Carrasco, Daniel Padilla and Rashwan, Hatem A. and García, Miguel Ángel and Puig, Domènec},
journal={IEEE Access}, title={T-YOLO: Tiny vehicle detection based on YOLO and multi-scale convolutional neural networks},
year={2021},
volume={},
number={},
pages={1-1},
abstract={To solve real-life problems for different smart city applications, using deep Neural Network, such as parking occupancy detection, requires fine-tuning of these networks. For large parking, it is desirable to use a cenital-plane camera located at a high distance that allows the monitoring of the entire parking space or a large parking area with only one camera. Today’s most popular object detection models, such as YOLO, achieve good precision scores at real-time speed. However, if we use our own data different from that of the general-purpose datasets, such as COCO and ImageNet, we have a large margin for improvisation. In this paper, we propose a modified, yet lightweight, deep object detection model based on the YOLO-v5 architecture. The proposed model can detect large, small, and tiny objects. Specifically, we propose the use of a multi-scale mechanism to learn deep discriminative feature representations at different scales and automatically determine the most suitable scales for detecting objects in a scene (i.e., in our case vehicles). The proposed multi-scale module reduces the number of trainable parameters compared to the original YOLO-v5 architecture. The experimental results also demonstrate that precision is improved by a large margin. In fact, as shown in the experiments, the results show a small reduction from 7.28 million parameters of the YOLO-v5-S profile to 7.26 million parameters in our model. In addition, we reduced the detection speed by inferring 30 fps compared to the YOLO-v5-L/X profiles. In addition, the tiny vehicle detection performance was significantly improved by 33% compared to the YOLO-v5-X profile.},
keywords={Object detection;Cameras;Feature extraction;Computational modeling;Automobiles;Convolutional neural networks;Detectors;Convolutional Neural Networks;Tiny Objects;Smart Parking},
doi={10.1109/ACCESS.2021.3137638},
ISSN={2169-3536},
month={},}
@INPROCEEDINGS{8855447,
author={Yan, Zhongxia and Ge, Jingguo and Wu, Yulei and Zheng, Hongbo and Li, Liangxiong and Li, Tong},
booktitle={2019 IEEE 21st International Conference on High Performance Computing and Communications; IEEE 17th International Conference on Smart City; IEEE 5th International Conference on Data Science and Systems (HPCC/SmartCity/DSS)}, title={Automatic Virtual Network Embedding Based on Deep Reinforcement Learning},
year={2019},
volume={},
number={},
pages={625-631},
abstract={The performance of virtual network embedding determines the effectiveness and efficiency of a virtualized network, making it a critical part of the network virtualization technology. However, most existing algorithms fail to provide automatic embedding solutions in an acceptable running time. In this paper, we combine reinforcement learning with a novel neural network structure and propose a new virtual network embedding algorithm. The proposed algorithm can learn to embed virtual networks automatically. Extensive simulation results show that our algorithm achieves the best performance on most metrics compared with the existing typical and stateof-the-art solutions.},
keywords={Substrates;Feature extraction;Bandwidth;Training;Network topology;Kernel;Conferences;Virtual Network Embedding;Network Virtualization;Reinforcement Learning;Graph Convolutional Network},
doi={10.1109/HPCC/SmartCity/DSS.2019.00095},
ISSN={},
month={Aug},}
@INPROCEEDINGS{8855498,
author={Guo, Li and Wang, Huan and Zhang, Jun},
booktitle={2019 IEEE 21st International Conference on High Performance Computing and Communications; IEEE 17th International Conference on Smart City; IEEE 5th International Conference on Data Science and Systems (HPCC/SmartCity/DSS)}, title={Data-Driven Grinding Control Using Reinforcement Learning},
year={2019},
volume={},
number={},
pages={2817-2824},
abstract={In the mineral industry, the grinding circuit (GC) is the most critical unit for mineral processing operations. The goal for GC control optimisation is to ensure the outputs of the controlled processes best follow the control actions and to ensure that the grinding product quality and efficiency are well controlled within the optimal ranges. However, it is hard to achieve these goals at the level of basic feedback control where global operational indices are not considered. Therefore, the higher-level advanced control mechanism is required for grinding operations. In this paper, we present our work using a big data driven and reinforcement learning-based approach for optimising GC processes. With our approach, it is not necessary to manually construct a system process model as it can be learnt from the historical GC log data automatically. To evaluate our method, a series of experiments have been conducted, and the experiment results show evident enhancement with regards to both product quality and grinding process efficiency.},
keywords={Process control;Ores;Optimization;Economics;Mathematical model;Throughput;Optimal Control;Reinforcement Learning;Actor-Critic;Proximal Policy Optimisation},
doi={10.1109/HPCC/SmartCity/DSS.2019.00395},
ISSN={},
month={Aug},}
@INPROCEEDINGS{8796664,
author={Sharma, Sachin and Ghanshala, Kamal Kumar and Mohan, Seshadri},
booktitle={2018 9th IEEE Annual Ubiquitous Computing, Electronics Mobile Communication Conference (UEMCON)}, title={A Security System Using Deep Learning Approach for Internet of Vehicles (IoV)},
year={2018},
volume={},
number={},
pages={1-5},
abstract={The Internet of Vehicles (IoV) will connect not only mobile devices with vehicles, but it will also connect vehicles with each other, and with smart offices, buildings, homes, theaters, shopping malls, and cities. The IoV facilitates optimal and reliable communication services to connected vehicles in smart cities. The backbone of connected vehicles communication is the critical V2X infrastructures deployment. The spectrum utilization depends on the demand by the end users and the development of infrastructure that includes efficient automation techniques together with the Internet of Things (IoT). The infrastructure enables us to build smart environments for spectrum utilization, which we refer to as Smart Spectrum Utilization (SSU). This paper presents an integrated system consisting of SSU with IoV. However, the tasks of securing IoV and protecting it from cyber attacks present considerable challenges. This paper introduces an IoV security system using deep learning approach to develop secure applications and reliable services. Deep learning composed of unsupervised learning and supervised learning, could optimize the IoV security system. The deep learning methodology is applied to monitor security threats. Results from simulations show that the monitoring accuracy of the proposed security system is superior to that of the traditional system.},
keywords={Connected vehicles;spectrum utilization;deep learning;IoV security system},
doi={10.1109/UEMCON.2018.8796664},
ISSN={},
month={Nov},}
@INPROCEEDINGS{9407943,
author={Long, Saiqin and Li, Zhetao and Xing, Yun and Tian, Shujuan and Li, Dongsheng and Yu, Rong},
booktitle={2020 IEEE 22nd International Conference on High Performance Computing and Communications; IEEE 18th International Conference on Smart City; IEEE 6th International Conference on Data Science and Systems (HPCC/SmartCity/DSS)}, title={A Reinforcement Learning-Based Virtual Machine Placement Strategy in Cloud Data Centers},
year={2020},
volume={},
number={},
pages={223-230},
abstract={With the widespread use of cloud computing, energy consumption of cloud data centers is increasing which mainly comes from IT equipment and cooling equipment. This paper argues that once the number of virtual machines on the physical machines reaches a certain level, resource competition occurs, resulting in a performance loss of the virtual machines. Unlike most papers, we do not impose placement constraints on virtual machines by giving a CPU cap to achieve the purpose of energy savings in cloud data centers. Instead, we use the measure of performance loss to weigh. We propose a reinforcement learning-based virtual machine placement strategy(RLVMP) for energy savings in cloud data centers. The strategy considers the weight of virtual machine performance loss and energy consumption, which is finally solved with the greedy strategy. Simulation experiments show that our strategy has a certain improvement in energy savings compared with the other algorithms.},
keywords={Weight measurement;Cloud computing;Data centers;Energy consumption;NP-hard problem;High performance computing;Virtual machining;Virtual Machine Placement;Cloud Data Centers;Reinforcement Learning;Energy Savings.},
doi={10.1109/HPCC-SmartCity-DSS50907.2020.00028},
ISSN={},
month={Dec},}
@ARTICLE{9357412,
author={Shang, Mingsheng and Yuan, Ye and Luo, Xin and Zhou, MengChu},
journal={IEEE Transactions on Cybernetics}, title={An α -β -Divergence-Generalized Recommender for Highly Accurate Predictions of Missing User Preferences},
year={2021},
volume={},
number={},
pages={1-13},
abstract={To quantify user-item preferences, a recommender system (RS) commonly adopts a high-dimensional and sparse (HiDS) matrix. Such a matrix can be represented by a non-negative latent factor analysis model relying on a single latent factor (LF)-dependent, non-negative, and multiplicative update algorithm. However, existing models' representative abilities are limited due to their specialized learning objective. To address this issue, this study proposes an α-β-divergence-generalized model that enjoys fast convergence. Its ideas are three-fold: 1) generalizing its learning objective with α -β -divergence to achieve highly accurate representation of HiDS data; 2) incorporating a generalized momentum method into parameter learning for fast convergence; and 3) implementing self-adaptation of controllable hyperparameters for excellent practicability. Empirical studies on six HiDS matrices from real RSs demonstrate that compared with state-of-the-art LF models, the proposed one achieves significant accuracy and efficiency gain to estimate huge missing data in an HiDS matrix.},
keywords={Computational modeling;Sparse matrices;Convergence;Data models;Predictive models;Linear programming;Euclidean distance;α -β -divergence;big data;convergence analysis;high-dimensional and sparse (HiDS) data;momentum;machine learning;missing data estimation;non-negative latent factor analysis (NLFA);recommender system (RS)},
doi={10.1109/TCYB.2020.3026425},
ISSN={2168-2275},
month={},}
@INPROCEEDINGS{6815206,
author={Idowu, Samuel and Åhlund, Christer and Schelén, Olov},
booktitle={2014 IEEE International Conference on Pervasive Computing and Communication Workshops (PERCOM WORKSHOPS)}, title={Machine learning in district heating system energy optimization},
year={2014},
volume={},
number={},
pages={224-227},
abstract={This paper introduces a work in progress, where we intend to investigate the application of Reinforcement Learning (RL) and online Supervised Learning (SL) to achieve energy optimization in District-Heating (DH) systems. We believe RL is an ideal approach since this task falls under the control-optimization problem where RL has yielded optimal results in previous work. The magnitude and scale of a DH system complexity incurs the curse of dimensionalities and model, hereby making RL a good choice since it provides a solution for the problem. To assist RL even further with the curse of dimensionalities, we intend to investigate the use of SL to reduce the state space. To achieve this, we shall use historical data to generate a heat load sub-model for each home. We believe using the output of these sub-models as feedback to the RL algorithm could significantly reduce the complexity of the learning task. Also, it could reduce convergence time for the RL algorithm. The desired goal is to achieve a realtime application, which takes operational actions when it receives new direct feedback. However, considering the dynamics of DH system such as large time delay and dissipation in DH network due to various factors, we hope to investigate things such as the appropriate data sampling rate and new parameters / sensors that could improve knowledge about the state of the system, especially on the consumer side of the DH network.},
keywords={DH-HEMTs;Space heating;Water heating;Cogeneration;Learning (artificial intelligence);Load modeling;Pervasive computing;reinforcement learning;online supervised learning;district heating system;smart city},
doi={10.1109/PerComW.2014.6815206},
ISSN={},
month={March},}
@INPROCEEDINGS{9340229,
author={Khatouni, Ali Safari and Bauer, Michael and Lutfiyya, Hanan},
booktitle={2020 7th International Conference on Internet of Things: Systems, Management and Security (IOTSMS)}, title={Indoor Temperature Characterization and its Implication on Power Consumption in a Campus Building},
year={2020},
volume={},
number={},
pages={1-8},
abstract={Building monitoring and management are some of the important components of smart cities. It provides valuable information to the city manager and power supplier to better optimize their resources. With a steady rise in electricity prices in recent years, the importance of efficient use of the Heating, Ventilating, and Air-Conditioning (HVAC) systems becomes vital since they contribute to more than 10% of building power consumption. Given the growth on the Internet of Things (IoT) more HVAC equipment is being deployed with sensors. These sensors can produce large amounts of data that can be transformed into knowledge about the operation of a building. In this paper, we examine a large amount of sensor data from a building with more than 200 rooms. We analyze the power consumption of the building and compare different algorithms to predict the power consumption of the building using indoor and outdoor temperatures. We compare 8 different Machine Learning (ML) algorithms in order to examine their effectiveness. We then cluster rooms based on the temperature settings. Our evaluation results illustrate reasonable prediction accuracy and pinpoint several clusters with an inefficient temperature setting. The results can help the university to better utilize its resources and reduce the power consumption costs.},
keywords={Temperature sensors;Power demand;HVAC;Buildings;Clustering algorithms;Prediction algorithms;Internet of Things;Smart city;Internet of Thing (IoT);power consumption;indoor temperature;HVAC systems;BACnet;Machine Learning;Clustering},
doi={10.1109/IOTSMS52051.2020.9340229},
ISSN={},
month={Dec},}
@INPROCEEDINGS{9294267,
author={Cribier-Delande, Perrine and Puget, Raphael and Noûs, Camille and Guigue, Vincent and Denoyer, Ludovic},
booktitle={2020 IEEE 23rd International Conference on Intelligent Transportation Systems (ITSC)}, title={Time series prediction amp; generation from disentangled latent factors: new opportunities for smart cities},
year={2020},
volume={},
number={},
pages={1-6},
abstract={The acceleration of urbanisation has brought many new challenges to cities around the world. Application range is wide, from air pollution to public transportation modelling. The availability of data pertaining to these issues has been growing fast in the last years, offering many opportunities to tackle those applications with machine learning algorithms. We propose an elegant and general architecture that is able to provide state of the art forecasting in several different domains. Our idea is the following: for many time-series, a number of factors, that often relate to the context they were created in, can influence the observed values, such as day or location. In this paper, we present a machine learning model that learns to represent and disentangle such factors. Our contribution is to provide an approach that works at different scales: on a short term basis (30 minutes to few hours) our deep neural network architecture delivers competitive forecasting in a classical setting; at the day/week/month level, we show that we can generate relevant time series associated with unknown contexts. To the best of our knowledge, this ambitious application has not been investigated until now.},
keywords={Time series analysis;Forecasting;Task analysis;Decoding;Computer architecture;Training;Encoding},
doi={10.1109/ITSC45102.2020.9294267},
ISSN={},
month={Sep.},}
@INPROCEEDINGS{8956878,
author={de Araujo, Arthur Cruz and Etemad, Ali},
booktitle={2019 IEEE SENSORS}, title={Deep Neural Networks for Predicting Vehicle Travel Times},
year={2019},
volume={},
number={},
pages={1-4},
abstract={This paper focuses on prediction if vehicle travel time. An established open dataset of taxi trips in New York City is used. We first perform statistical analysis on the data in order to determine the informative features that can be used for the problem at hand. Successive to detailed analysis of the data and features, we develop a deep neural network for travel time prediction. We show that our model performs with high accuracy, and outperforms a number of baseline techniques.},
keywords={smart city;vehicle travel time;deep learning},
doi={10.1109/SENSORS43011.2019.8956878},
ISSN={2168-9229},
month={Oct},}
@ARTICLE{9451542,
author={Chen, Junyang and Gong, Zhiguo and Mo, Jiqian and Wang, Wei and Wang, Wei and Wang, Cong and Dong, Xiao and Liu, Weiwen and Wu, Kaishun},
journal={IEEE Transactions on Neural Networks and Learning Systems}, title={Self-Training Enhanced: Network Embedding and Overlapping Community Detection With Adversarial Learning},
year={2021},
volume={},
number={},
pages={1-12},
abstract={Network embedding (NE) aims to encode the relations of vertices into a low-dimensional space. After NE, we can obtain the learned vectors of vertices that preserve the proximity of network structures for subsequent applications, e.g., vertex classification and link prediction. In existing NE models, they usually exploit the skip-gram with a negative sampling method to optimize their objective functions. Generally, this method learns the vertex representation only from the local connectivity of vertices (i.e., neighbors). However, there is a larger scope of vertex connectivity in real-world scenarios: a vertex may have multifaceted aspects and should belong to overlapping communities. Taking a social network as the overlapping example, a user may subscribe to the channels of politics, economy, and sports simultaneously, but the politics share more common attributes with the economy and less with the sports. In this article, we propose an adversarial learning approach (ACNE) for modeling overlapping communities of vertices. Specifically, we map the association between communities and vertices into an embedding space. Moreover, we take further research on enhancing our ACNE with the following two operations. First, in the initialization stage, we adopt a walking strategy with perception to obtain paths containing more possible boundary vertices to improve overlapping community detection. Then, after representation learning with ACNE, we use soft community assignments from a simple classifier as supervision to update the weights of ACNE. This self-training mechanism referred to as ACNE-ST can help ACNE to achieve better performance. Experimental results demonstrate that the proposed methods, including ACNE and ACNE-ST, can outperform the state-of-the-art models on the subsequent tasks of vertex classification and overlapping community detection.},
keywords={Legged locomotion;Sports;Learning systems;Biological system modeling;Task analysis;Social networking (online);Research and development;Adversarial learning;network embedding (NE);overlapping community detection;self-training.},
doi={10.1109/TNNLS.2021.3083318},
ISSN={2162-2388},
month={},}
@ARTICLE{9359362,
author={Li, Yuanman and Zhou, Jiantao and Tian, Jinyu and Zheng, Xianwei and Tang, Yuan Yan},
journal={IEEE Transactions on Neural Networks and Learning Systems}, title={Weighted Error Entropy-Based Information Theoretic Learning for Robust Subspace Representation},
year={2021},
volume={},
number={},
pages={1-15},
abstract={In most of the existing representation learning frameworks, the noise contaminating the data points is often assumed to be independent and identically distributed (i.i.d.), where the Gaussian distribution is often imposed. This assumption, though greatly simplifies the resulting representation problems, may not hold in many practical scenarios. For example, the noise in face representation is usually attributable to local variation, random occlusion, and unconstrained illumination, which is essentially structural, and hence, does not satisfy the i.i.d. property or the Gaussianity. In this article, we devise a generic noise model, referred to as independent and piecewise identically distributed (i.p.i.d.) model for robust presentation learning, where the statistical behavior of the underlying noise is characterized using a union of distributions. We demonstrate that our proposed i.p.i.d. model can better describe the complex noise encountered in practical scenarios and accommodate the traditional i.i.d. one as a special case. Assisted by the proposed noise model, we then develop a new information-theoretic learning framework for robust subspace representation through a novel minimum weighted error entropy criterion. Thanks to the superior modeling capability of the i.p.i.d. model, our proposed learning method achieves superior robustness against various types of noise. When applying our scheme to the subspace clustering and image recognition problems, we observe significant performance gains over the existing approaches.},
keywords={Entropy;Task analysis;Distributed databases;Optimization;Image recognition;Data models;Videos;Independent and piecewise identically distributed;information-theoretic learning (ITL);subspace representation (SR);weighted Parzen window (WPW).},
doi={10.1109/TNNLS.2021.3056188},
ISSN={2162-2388},
month={},}
@INPROCEEDINGS{8622965,
author={Howard, Alexander J. and Lee, Tim and Mahar, Sara and Intrevado, Paul and Myung-Kyung Woodbridge, Diane},
booktitle={2018 IEEE 20th International Conference on High Performance Computing and Communications; IEEE 16th International Conference on Smart City; IEEE 4th International Conference on Data Science and Systems (HPCC/SmartCity/DSS)}, title={Distributed Data Analytics Framework for Smart Transportation},
year={2018},
volume={},
number={},
pages={1374-1380},
abstract={As the amount data from IoT devices on transportation systems increases, developing a robust pipeline to stream, store and process data became critical. In this study, We explore prediction accuracy and computational performance of various supervised and unsupervised algorithms perform on distributed systems for developing a smart transportation data pipeline. Using a subset of New York City Taxi & Limousine Commission data, we evaluate Logistic Regression, Random Forrest Regressors and Classifiers, Principal Component Analysis, and Gradient Boosted Regression and Classification Tree machine learning techniques on a commodity computer as well as on a distributed system. Employing Amazon S3, EC2 and EMR, MongoDB, and Spark, we identify the conditions-data size and algorithm- under which the performance of distributed systems excel.},
keywords={Sparks;Public transportation;Machine learning algorithms;Vegetation;Task analysis;Urban areas;Machine learning;Distributed computing, Distributed information systems, Machine learning, Smart transportation},
doi={10.1109/HPCC/SmartCity/DSS.2018.00227},
ISSN={},
month={June},}
@INPROCEEDINGS{9148289,
author={Chai, Yuhan and Qiu, Jing and Su, Shen and Zhu, Chunsheng and Yin, Lihua and Tian, Zhihong},
booktitle={2020 International Wireless Communications and Mobile Computing (IWCMC)}, title={LGMal: A Joint Framework Based on Local and Global Features for Malware Detection},
year={2020},
volume={},
number={},
pages={463-468},
abstract={With the gradual advancement of smart city construction, various information systems have been widely used in smart cities. In order to obtain huge economic benefits, criminals frequently invade the information system, which leads to the increase of malware. Malware attacks not only seriously infringe on the legitimate rights and interests of users, but also cause huge economic losses. Signature-based malware detection algorithms can only detect known malware, and are susceptible to evasion techniques such as binary obfuscation. Behavior-based malware detection methods can solve this problem well. Although there are some malware behavior analysis works, they may ignore semantic information in the malware API call sequence. In this paper, we design a joint framework based on local and global features for malware detection to solve the problem of network security of smart cities, called LGMal, which combines the stacked convolutional neural network and graph convolutional networks. Specially, the stacked convolutional neural network is used to learn API call sequence information to capture local semantic features and the graph convolutional networks is used to learn API call semantic graph structure information to capture global semantic features. Experiments on Alibaba Cloud Security Malware Detection datasets show that the joint framework gets better results. The experimental results show that the precision is 87.76%, the recall is 88.08%, and the F1-measure is 87.79%. We hope this paper can provide a useful way for malware detection and protect the network security of smart city.},
keywords={Malware;Feature extraction;Semantics;Convolutional neural networks;Data mining;Smart cities;Static analysis;Malware Detection;Convolutional Neural Network;Graph Convolutional Networks;Smart City},
doi={10.1109/IWCMC48107.2020.9148289},
ISSN={2376-6506},
month={June},}
@INPROCEEDINGS{9604515,
author={Hina, Maryam and Ali, Mohsan and Javed, Abdul Rehman and Srivastava, Gautam and Gadekallu, Thippa Reddy and Jalil, Zunera},
booktitle={2021 IEEE SmartWorld, Ubiquitous Intelligence Computing, Advanced Trusted Computing, Scalable Computing Communications, Internet of People and Smart City Innovation (SmartWorld/SCALCOM/UIC/ATC/IOP/SCI)}, title={Email Classification and Forensics Analysis using Machine Learning},
year={2021},
volume={},
number={},
pages={630-635},
abstract={Emails are being used as a reliable, secure, and formal mode of communication for a long time. With fast and secure communication technologies, reliance on Email has increased as well. The massive increase in email data has led to a big challenge in managing emails. Emails so far can be classified and grouped based on sender, size, and date. However, there is a need to detect and classify emails based on the contents contained therein. Several approaches have been used in the past for content-based classification of emails as Spam or Non-Spam Email. In this paper, we propose a multi-label email classification approach to organize emails. An efficient classification method has been proposed for forensic investigations of massive email data (e.g., a disk image of an email server). This method would help the investigator in Email related crimes investigations. A comparative study of machine learning algorithms identified Logistic Regression as a method that achieves the highest accuracy compared to Naive Bayes, Stochastic Gradient Descent, Random Forest, and Support Vector Machine. Experiments conducted on benchmark data sets depicted that logistic Regression performs best, with an accuracy of 91.9% with bi-gram features.},
keywords={Support vector machines;Technological innovation;Machine learning algorithms;Forensics;Unsolicited e-mail;Benchmark testing;Electronic mail;Digital Forensics;Machine Learning;Email Forensics;Fraud Detection;Crime Investigation},
doi={10.1109/SWC50871.2021.00093},
ISSN={},
month={Oct},}
@INPROCEEDINGS{9074280,
author={Mirthubashini, J. and Santhi, V.},
booktitle={2020 6th International Conference on Advanced Computing and Communication Systems (ICACCS)}, title={Video Based Vehicle Counting Using Deep Learning Algorithms},
year={2020},
volume={},
number={},
pages={142-147},
abstract={Traffic density in roads has been increasing day by day which needs intelligent transportation system that can handle the traffic. Traffic management has become inevitable for smart cities. The enormous increase in vehicle numbers has generated more pressure to manage traffic congestion especially during peak hours. If the traffic congestion at a particular point of time can be found, then that information can be useful for managing the traffic in different lanes and change the traffic light cycle dynamically according to the vehicle count in different lanes. In recent years video surveillance and monitoring has been gaining importance. Video can be analyzed which can be used to find the traffic density. Many useful information can be obtained by video processing like real time traffic density. Vehicle counting can be done by detecting the object, tracking it and then finally counting the objects. Many different techniques are available for object detection and tracking. Deep learning techniques for object detection led to remarkable improvements compared to conventional image processing techniques by removing the weakness in the conventional techniques. This paper provides a survey on various techniques available for vehicle detection and tracking.},
keywords={Object detection;Feature extraction;Roads;Vehicle detection;Microsoft Windows;Flowcharts;Convolutional neural networks;Deep Learning;Convolutional Neural Network;Object Detection;Object Tracking;Vehicle counting},
doi={10.1109/ICACCS48705.2020.9074280},
ISSN={2575-7288},
month={March},}
@ARTICLE{9284628,
author={Muhammad, Khan and Ullah, Amin and Lloret, Jaime and Ser, Javier Del and de Albuquerque, Victor Hugo C.},
journal={IEEE Transactions on Intelligent Transportation Systems}, title={Deep Learning for Safe Autonomous Driving: Current Challenges and Future Directions},
year={2021},
volume={22},
number={7},
pages={4316-4336},
abstract={Advances in information and signal processing technologies have a significant impact on autonomous driving (AD), improving driving safety while minimizing the efforts of human drivers with the help of advanced artificial intelligence (AI) techniques. Recently, deep learning (DL) approaches have solved several real-world problems of complex nature. However, their strengths in terms of control processes for AD have not been deeply investigated and highlighted yet. This survey highlights the power of DL architectures in terms of reliability and efficient real-time performance and overviews state-of-the-art strategies for safe AD, with their major achievements and limitations. Furthermore, it covers major embodiments of DL along the AD pipeline including measurement, analysis, and execution, with a focus on road, lane, vehicle, pedestrian, drowsiness detection, collision avoidance, and traffic sign detection through sensing and vision-based DL methods. In addition, we discuss on the performance of several reviewed methods by using different evaluation metrics, with critics on their pros and cons. Finally, this survey highlights the current issues of safe DL-based AD with a prospect of recommendations for future research, rounding up a reference material for newcomers and researchers willing to join this vibrant area of Intelligent Transportation Systems.},
keywords={Roads;Task analysis;Safety;Automobiles;Accidents;Vehicles;Lane detection;Autonomous driving (AD);artificial intelligence;deep learning (DL);decision making;vehicular safety;vehicular technology;intelligent sensors},
doi={10.1109/TITS.2020.3032227},
ISSN={1558-0016},
month={July},}
@ARTICLE{7964673,
author={Ta-Shma, Paula and Akbar, Adnan and Gerson-Golan, Guy and Hadash, Guy and Carrez, Francois and Moessner, Klaus},
journal={IEEE Internet of Things Journal}, title={An Ingestion and Analytics Architecture for IoT Applied to Smart City Use Cases},
year={2018},
volume={5},
number={2},
pages={765-774},
abstract={As sensors are adopted in almost all fields of life, the Internet of Things (IoT) is triggering a massive influx of data. We need efficient and scalable methods to process this data to gain valuable insight and take timely action. Existing approaches which support both batch processing (suitable for analysis of large historical data sets) and event processing (suitable for realtime analysis) are complex. We propose the hut architecture, a simple but scalable architecture for ingesting and analyzing IoT data, which uses historical data analysis to provide context for real-time analysis. We implement our architecture using open source components optimized for Big Data applications and extend them, where needed. We demonstrate our solution on two real-world smart city use cases in transportation and energy management.},
keywords={Real-time systems;Computer architecture;Internet of Things;Transportation;Big Data;Batch production systems;Sparks;Big data;complex event processing (CEP);context-aware;energy management;ingestion;Internet of Things (IoT);machine learning;smart cities;spark;transportation},
doi={10.1109/JIOT.2017.2722378},
ISSN={2327-4662},
month={April},}
@INPROCEEDINGS{7845408,
author={Valipour, Sepehr and Siam, Mennatullah and Stroulia, Eleni and Jagersand, Martin},
booktitle={2016 IEEE 3rd World Forum on Internet of Things (WF-IoT)}, title={Parking-stall vacancy indicator system, based on deep convolutional neural networks},
year={2016},
volume={},
number={},
pages={655-660},
abstract={Parking-management systems, including services that recognize vacant stalls, can play a valuable role in reducing traffic and energy waste in large cities. Visual methods for detecting vacant parking spots are cost-effective options since they can take advantage of the cameras already available in many parking lots. However, visual-detection methods can be fragile and not easily generalizable. In this paper, we present a robust detection algorithm based on deep convolutional neural networks. We implemented and tested our algorithm on a large baseline dataset, and also tested on video feeds from web-accessible parking-lot cameras. Our detection method improved the state of the art AUC by 8.13%. It also showed robust performance in different testing scenarios including tests on public cameras. We have developed a fully functional system, from server-side image analysis to front-end user interface, to demonstrate the practicality of our method.},
keywords={Cameras;Visualization;Servers;Neural networks;Sensors;Urban areas;Robustness;Smart Cities;Smart Parking;Deep Learning;Internet of Things},
doi={10.1109/WF-IoT.2016.7845408},
ISSN={},
month={Dec},}
@ARTICLE{6891172,
author={Yu, Yongtao and Li, Jonathan and Guan, Haiyan and Jia, Fukai and Wang, Cheng},
journal={IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing}, title={Learning Hierarchical Features for Automated Extraction of Road Markings From 3-D Mobile LiDAR Point Clouds},
year={2015},
volume={8},
number={2},
pages={709-726},
abstract={This paper presents a novel method for automated extraction of road markings directly from three dimensional (3-D) point clouds acquired by a mobile light detection and ranging (LiDAR) system. First, road surface points are segmented from a raw point cloud using a curb-based approach. Then, road markings are directly extracted from road surface points through multisegment thresholding and spatial density filtering. Finally, seven specific types of road markings are further accurately delineated through a combination of Euclidean distance clustering, voxel-based normalized cut segmentation, large-size marking classification based on trajectory and curb-lines, and small-size marking classification based on deep learning, and principal component analysis (PCA). Quantitative evaluations indicate that the proposed method achieves an average completeness, correctness, and F-measure of 0.93, 0.92, and 0.93, respectively. Comparative studies also demonstrate that the proposed method achieves better performance and accuracy than those of the two existing methods.},
keywords={Roads;Three-dimensional displays;Feature extraction;Surface treatment;Trajectory;Mobile communication;Laser radar;Deep learning;mobile light detection and ranging (LiDAR);point cloud;road marking;three dimensional (3-D) extraction;Deep learning;mobile light detection and ranging (LiDAR);point cloud;road marking;three dimensional (3-D) extraction},
doi={10.1109/JSTARS.2014.2347276},
ISSN={2151-1535},
month={Feb},}
@INPROCEEDINGS{9666235,
author={Shrivastava, Prashant and Patel, Sachin},
booktitle={2021 IEEE 6th International Conference on Computing, Communication and Automation (ICCCA)}, title={Selection of Efficient and Accurate Prediction Algorithm for Employing Real Time 5G Data Load Prediction},
year={2021},
volume={},
number={},
pages={572-580},
abstract={In smart cities applications (i.e. intelligent transport systems, traffic management) cellular traffic load prediction is playing an essential role. The cellular data consumption can help to understand the road traffic patterns. In this context, the employment of predictive Machine Learning (ML)techniques can be useful for approximating the possible resource demands in cell towers. Therefore, cellular traffic data may very useful for finding trends and patterns of load of human activities in city traffic. In this paper, the main aim is to identify the suitable machine learning techniques, which can be used for traffic load prediction in a smart city application. The paper includes three main contributions, first providing an overview of 5G technology and their applications, second, a review on existing traffic load prediction techniques and finally, a comparative experimental study is performed among popular supervised and unsupervised learning approaches. In order to compare the performance of supervised learning algorithms, Support Vector Machine (SVM), Artificial Neural Network (ANN), Bays classifier, Linear Regression (LR), and Decision Tree (DT) are implemented. On the other hand, for comparing the performance of unsupervised learning algorithms the Self Organizing Map (SOM), Fuzzy C Means (FCM), and k-Means clustering algorithms have been involved. The experiments on publically available data on Kaggle for 4G (LTE Traffic Prediction) were used. According to the experimental analysis, SVM and ANN are accurate algorithms in the supervised learning algorithms. On the other side in unsupervised learning models, SOM shows superior accuracy. But after summarizing the results we found that the SVM and ANN algorithms are beneficial for the proposed application.},
keywords={Support vector machines;Self-organizing feature maps;Smart cities;Supervised learning;Clustering algorithms;Telecommunication traffic;Machine learning;traffic load prediction;cellular data;smart city traffic management;machine learning;supervised and unsupervised learning},
doi={10.1109/ICCCA52192.2021.9666235},
ISSN={2642-7354},
month={Dec},}
@ARTICLE{9495351,
author={Sanchez-Iborra, Ramon and Bernal-Escobedo, Luis and Santa, Jose},
journal={China Communications}, title={Machine learning-based radio access technology selection in the Internet of moving things},
year={2021},
volume={18},
number={7},
pages={13-24},
abstract={The Internet of Moving Things (IoMT) takes a step further with respect to traditional static IoT deployments. In this line, the integration of new eco-friendly mobility devices such as scooters or bicycles within the Cooperative-Intelligent Transportation Systems (C-ITS) and smart city ecosystems is crucial to provide novel services. To this end, a range of communication technologies is available, such as cellular, vehicular WiFi or Low-Power Wide-Area Network (LPWAN); however, none of them can fully cover energy consumption and Quality of Service (QoS) requirements. Thus, we propose a Decision Support System (DSS), based on supervised Machine Learning (ML) classification, for selecting the most adequate transmission interface to send a certain message in a multi-Radio Access Technology (RAT) set up. Different ML algorithms have been explored taking into account computing and energy constraints of IoMT enddevices and traffic type. Besides, a real implementation of a decision tree-based DSS for micro-controller units is presented and evaluated. The attained results demonstrate the validity of the proposal, saving energy in communication tasks as well as satisfying QoS requirements of certain urgent messages. The footprint of the real implementation on an Arduino Uno is 444 bytes and it can be executed in around 50 μs.},
keywords={Radio access technologies;Quality of service;Wireless fidelity;TCPIP;Rats;Decision support systems;Monitoring;internet of moving things;multi-RAT;CITS;classification;personal mobility},
doi={10.23919/JCC.2021.07.002},
ISSN={1673-5447},
month={July},}
@ARTICLE{9497869,
author={Li, Xinyu and Xu, Yang and Chen, Qi and Wang, Lei and Zhang, Xiaohu and Shi, Wenzhong},
journal={IEEE Transactions on Intelligent Transportation Systems}, title={Short-Term Forecast of Bicycle Usage in Bike Sharing Systems: A Spatial-Temporal Memory Network},
year={2021},
volume={},
number={},
pages={1-12},
abstract={Bike-sharing systems have made notable contributions to cities by providing green and sustainable mobility service to users. Over the years, many studies have been conducted to understand or anticipate the usage of these systems, with the hope to inform their future developments. One important task is to accurately predict usage patterns of the systems. Although many deep learning algorithms have been developed in recent years to support travel demand forecast, they have mainly been used to predict traffic volume or speed on roadways. Few studies have applied them to bike-sharing systems. Moreover, these studies usually focus on one single dataset or study area. The effectiveness and robustness of the prediction algorithms are not systematically evaluated. In this study, we propose a Spatial-Temporal Memory Network (STMN) to predict short-term usage of bicycles in bike-sharing systems. The framework employs Convolutional Long Short-Term Memory models and a feature engineering technique to capture the spatial-temporal dependencies in historical data for the prediction task. Four testing sites are used to evaluate the model. These four sites include two station-based systems (Chicago and New York) and two dockless bike-sharing systems (Singapore and New Taipei City). By assessing STMN with several baseline models, we find that STMN achieves the best overall performance in all the four cities. The model also achieves superior performance in urban areas with varying levels of bicycle usage and during peak periods when demand is high. The findings suggest the reliability of STMN in predicting bicycle usage for different types of bike-sharing systems.},
keywords={Bicycles;Deep learning;Predictive models;Urban areas;Feature extraction;Convolution;Task analysis;Bike sharing;deep learning;travel demand;prediction;shared mobility.},
doi={10.1109/TITS.2021.3097240},
ISSN={1558-0016},
month={},}
@INPROCEEDINGS{9337685,
author={Bian, Chunlei and xu, Yiming and Wang, Li and Gu, Haifeng and Zhou, Fangjie},
booktitle={2020 35th Youth Academic Annual Conference of Chinese Association of Automation (YAC)}, title={Abnormal behavior recognition based on edge feature and 3D convolutional neural network},
year={2020},
volume={},
number={},
pages={01-06},
abstract={With the rapid development of artificial intelligence and 5G technology, the development process of smart city has been greatly accelerated. An important part of the development of smart city is to improve the ability of video monitoring equipment to analyze the content of the video. This paper is to identify the specific abnormal behaviors in the video, including climbing, fighting and falling. The identification of these abnormal behaviors is helpful to find out the danger in time and intervene to ensure personal safety and social stability. Therefore, this paper proposes a deep learning method based on edge extraction. In the first step, the video is decomposed into several frames, and the canny edge detection algorithm is used to extract the edge of the images. In the second step, the extracted edge information is used as the input of the 3D convolutional neural network, and the 3D convolutional neural network model is trained iteratively to recognize the abnormal behaviors. Through a large number of experiments, the effectiveness of the proposed algorithm is verified.},
keywords={Solid modeling;Three-dimensional displays;Smart cities;Image edge detection;Stability analysis;Trajectory;Convolutional neural networks;behavior recognition;3D convolutional neural network;deep learning;edge extraction},
doi={10.1109/YAC51587.2020.9337685},
ISSN={},
month={Oct},}
@ARTICLE{9143576,
author={Bhatti, Mansoor Ahmed and Riaz, Rabia and Rizvi, Sanam Shahla and Shokat, Sana and Riaz, Farina and Kwon, Se Jin},
journal={Journal of Communications and Networks}, title={Outlier detection in indoor localization and Internet of Things (IoT) using machine learning},
year={2020},
volume={22},
number={3},
pages={236-243},
abstract={In Internet of things (IoT) millions of devices are intelligently connected for providing smart services. Especially in indoor localization environment, that is one of the most concerning topic of smart cities, internet of things and wireless sensor networks. Many technologies are being used for localization purpose in indoor environment and Wi-Fi using received signal strengths (RSSs) is one of them. Wi-Fi RSSs are sensitive to reflection, refraction, interference and channel noise that cause irregularity in signal strengths. The irregular and anomalous RSS values, used in a Wi-Fi indoor localization environment, cannot define the location of any unknown node correctly. Therefore, this research has developed an outlier detection technique named as iF_Ensemble for Wi-Fi indoor localization environment by analyzing RSSs using the combination of supervised, unsupervised and ensemble machine learning methods. In this research isolation forest (iForest) is used as an unsupervised learning method. Supervised learning method includes support vector machine (SVM), K-nearest neighbor (KNN) and random forest (RF) classifiers with stacking that is an ensemble learning method. For the evaluation purpose accuracy, precision, recall, F-score and ROC-AUC curve are used. The evaluation of used machine learning method provides high accuracy of 97.8 percent with proposed outlier detection methods and almost 2 percent improvement in the accuracy of localization process in indoor environment after eliminating outliers.},
keywords={Anomaly detection;Wireless fidelity;Indoor environments;Internet of Things;Machine learning;Wireless sensor networks;Forestry;Internet of things;localization;outliers;outliers detection},
doi={10.1109/JCN.2020.000018},
ISSN={1976-5541},
month={June},}
@INPROCEEDINGS{8862573,
author={Gogulaanand, R. and Balasubramaniyavijayan, T. and Arunsivaram, R. and Aishwarya, S. and Nag, P.V. Sunil and Kumar, C. Santhosh},
booktitle={2019 3rd International Conference on Trends in Electronics and Informatics (ICOEI)}, title={Intelligent monitoring of Synchronous Generators in Smart Grids using Deep Neural Network},
year={2019},
volume={},
number={},
pages={1376-1379},
abstract={Smart cities are on the rise and any component of such infrastructure would require reliable electrical power and hence reliable Synchronous generators. To reduce the down time of synchronous generators, it is necessary to implement an intelligent condition monitoring system. Stator inter turn fault is a critical fault as it is the beginning stage form many electrical faults in a Synchronous generator. Neural networks have proved their mettle in solving difficult classification problems. Here the stator interturn fault diagnosis problem has been cast as a multilabel, multiclass classification problem. It has been solved using neural networks using the Keras framework. The data for training the network was obtained from a Finite element model of a synchronous generator implemented in ANSYS Maxwell.},
keywords={Neural networks;Circuit faults;Synchronous generators;Finite element analysis;Stator windings;Fault diagnosis;Smart Cities;Synchronous generator;Neural networks;ANSYS Maxwell;Keras;inter-turn short},
doi={10.1109/ICOEI.2019.8862573},
ISSN={},
month={April},}
@INPROCEEDINGS{9210361,
author={Gupta, Lav},
booktitle={2020 Fourth World Conference on Smart Trends in Systems, Security and Sustainability (WorldS4)}, title={Hierarchical Deep Learning for Cybersecurity of Critical Service Systems},
year={2020},
volume={},
number={},
pages={346-351},
abstract={The costs of delivering critical services, such as healthcare, power, financial systems and transportation are spiraling up while the performance expectations of them have risen manifold. The mechanics of providing these services (e.g., activities like processing satellite imagery for defense and civil applications, analyzing patient data for diagnosing acute ailments, ensuring uneventful working of unmanned vehicles and big data analytics for sustaining smart cities) all require unprecedented data acquisition, storage, computation and communication. Driven by the need to achieve agility, intelligence and high performance at lower cost and improve outcomes, these systems are increasingly relying on advanced methods and technologies. Trends show the prevalence of IoT for data collection, multi-cloud computing for storage and analytics and virtualization of communication components. The increasing sophistication of technology also increases susceptibility of these systems to cyberattacks. The overarching objective of the work presented in this paper is to show the feasibility and usefulness of AI-based hierarchical sparse deep neural network models for providing security to data in motion. The novelty of the work lies in the use of variable complexity models across multiple clouds and their synergistic training to reduce training time and improve detection accuracy for unknown attacks.},
keywords={Cloud computing;Machine learning;Training;Logic gates;Data models;Security;Sensors;edge clouds;public clouds;network function virtualization;critical services;deep neural networks;multi-cloud systems;stacked sparse autoencoders},
doi={10.1109/WorldS450073.2020.9210361},
ISSN={},
month={July},}
@INPROCEEDINGS{9616794,
author={P.K, Binu and M, Kiran and M. V, Sreehari},
booktitle={2021 Fourth International Conference on Electrical, Computer and Communication Technologies (ICECCT)}, title={Attack and Anomaly Prediction in IoT Networks using Machine Learning Approaches},
year={2021},
volume={},
number={},
pages={1-6},
abstract={Cyber-attacks are becoming a very common problem we face in IoT networks nowadays. These attacks mainly target the comparatively less powerful IoT and gateway devices so that the attacker can compromise the device much faster. As the IoT infrastructure is getting exponential growth recently, the attacks are also getting the same pace. Based on various studies, almost 90% of attacks targeting IoT networks are Denial of Service (DoS) or Distributed Denial of Service (DDoS). So, like any other aspect, security is an inevitable part of IoT networks and devices because this is now deployed in highly critical areas like space technology, healthcare, smart cities, etc. Understanding these attacks, their behavior pattern, and their defense mechanisms will help to implement a highly safe and secure IoT infrastructure. The system proposed here is a prototype model for detecting the most common DoS attacks at the gateway device itself using the Machine Learning approach. ML approaches can recognize the behavior pattern of the attacks based on the previously trained data and can make efficient predictions with a high accuracy factor. This will help us to take proper countermeasures to protect our IoT network from such potential attacks. The need for a safe and secure IoT ecosystem is an important need for today and especially in the future.},
keywords={Electric potential;Smart cities;Space technology;Face recognition;Ecosystems;Prototypes;Machine learning;IoT;Cyber-attacks;NodeMCU;Arduino IDE;Matlab;Machine Learning;SVM;Bagged Trees},
doi={10.1109/ICECCT52121.2021.9616794},
ISSN={},
month={Sep.},}
@ARTICLE{9284464,
author={Zhang, Wei and Wen, Yonggang and Tseng, King Jet and Jin, Guangyu},
journal={IEEE Internet of Things Journal}, title={Demystifying Thermal Comfort in Smart Buildings: An Interpretable Machine Learning Approach},
year={2021},
volume={8},
number={10},
pages={8021-8031},
abstract={Thermal comfort is a key consideration in smart buildings and a number of comfort models are available nowadays to evaluate the comfort level of occupants. However, the models are often complex and hardly interpretable for the developers and operators. Indeed, the model interpretations are beneficial in multifold such as for system inspection and optimization. In this article, we propose an interpretable thermal comfort system to introduce interpretability to any black-box comfort models. First, we focus on the relationship between a model's input features and output comfort level. The feature impact on comfort is investigated and the impact patterns are shown to be diverse for different features. Second, we unveil the model mechanisms about the data processing inside the model by building the model surrogates based on the interpretable machine learning algorithms. The surrogates offer outstanding fidelity for simulating the actual model mechanisms and the interpretations based on the surrogates are intuitive and informative. Our interpretable comfort system can be integrated with the existing building management systems. Accordingly, we can ease building owner's concerns about adopting new black-box technologies and enable various smart building applications like smart energy management.},
keywords={Data models;Atmospheric modeling;Smart buildings;Internet of Things;Computational modeling;Systems architecture;Indexes;Deep learning;interpretable machine learning (ML);smart building;smart city;thermal comfort},
doi={10.1109/JIOT.2020.3042783},
ISSN={2327-4662},
month={May},}
@ARTICLE{9690148,
author={Muhammad, Ghulam and Hossain, M. Shamim},
journal={IEEE Wireless Communications}, title={Deep-Reinforcement-Learning-Based Sustainable Energy Distribution for Wireless Communication},
year={2021},
volume={28},
number={6},
pages={42-48},
abstract={Many countries and organizations have proposed smart city projects to address the exponential growth of the population by promoting and developing a new paradigm for maximizing electricity demand in cities. Since Internet of Things (IoT)-based systems are extensively used in smart cities where huge amounts of data are generated and distributed, it could be challenging to directly capture data from a composite environment and to offer precise control behavior in response. Proper scheduling of numerous energy devices to meet the need of users is a demand of the smart city. Deep reinforcement learning (DRL) is an emerging methodology that can yield successful control behavior for time-variant dynamic systems. This article proposes an efficient DRL-based energy scheduling approach that can effectively distribute the energy devices based on consumption and users' demand. First, a deep neural network classifies the energy devices currently available in a framework. The DRL then efficiently schedules the devices. Edge-cloud-coordinated DRL is shown to reduce the delay and cost of smart grid energy distribution.},
keywords={Deep learning;Wireless communication;Costs;Smart cities;Processor scheduling;Distributed databases;Scheduling},
doi={10.1109/MWC.015.2100177},
ISSN={1558-0687},
month={December},}
@ARTICLE{9238491,
author={Tang, Lulu and Chen, Ke and Wu, Chaozheng and Hong, Yu and Jia, Kui and Yang, Zhi-Xin},
journal={IEEE Transactions on Cybernetics}, title={Improving Semantic Analysis on Point Clouds via Auxiliary Supervision of Local Geometric Priors},
year={2020},
volume={},
number={},
pages={1-11},
abstract={Existing deep learning algorithms for point cloud analysis mainly concern discovering semantic patterns from the global configuration of local geometries in a supervised learning manner. However, very few explore geometric properties revealing local surface manifolds embedded in 3-D Euclidean space to discriminate semantic classes or object parts as additional supervision signals. This article is the first attempt to propose a unique multitask geometric learning network to improve semantic analysis by auxiliary geometric learning with local shape properties, which can be either generated via physical computation from point clouds themselves as self-supervision signals or provided as privileged information. Owing to explicitly encoding local shape manifolds in favor of semantic analysis, the proposed geometric self-supervised and privileged learning algorithms can achieve superior performance to their backbone baselines and other state-of-the-art methods, which are verified in the experiments on the popular benchmarks.},
keywords={Semantics;Three-dimensional displays;Shape;Task analysis;Encoding;Deep learning;Geometry;Geometric properties;point clouds;privileged learning;self-supervised learning;semantic analysis},
doi={10.1109/TCYB.2020.3025798},
ISSN={2168-2275},
month={},}
@INPROCEEDINGS{7828558,
author={Kang, Dongjun and Kim, Seunghwan and Lee, Tacklim and Hwang, Junyeon and Lee, Sanghoon and Jang, Seongman and Park, Sehyun},
booktitle={2016 IEEE 18th International Conference on High Performance Computing and Communications; IEEE 14th International Conference on Smart City; IEEE 2nd International Conference on Data Science and Systems (HPCC/SmartCity/DSS)}, title={Energy Information Analysis Using Data Algorithms Based on Big Data Platform},
year={2016},
volume={},
number={},
pages={1530-1531},
abstract={With the development of the IoT market, collectable data is increasing exponentially. Recently, various methods for big data analysis are being suggested. Existing general research on data analysis has some problem that if the size of data is getting bigger, the processing speed is rapidly slow. In this paper, we find out the optimal algorithm that efficiently manage the energy data based on Big data by comparing data which is analyzed using three algorithms.},
keywords={Algorithm design and analysis;Support vector machines;Data analysis;Prediction algorithms;Big data;Machine learning algorithms;Conferences;Big data;Data analysis;Algorithms;Energy;Machine learning},
doi={10.1109/HPCC-SmartCity-DSS.2016.0217},
ISSN={},
month={Dec},}
@ARTICLE{8478211,
author={You, Changbin and Wen, Chenglu and Wang, Cheng and Li, Jonathan and Habib, Ayman},
journal={IEEE Transactions on Intelligent Transportation Systems}, title={Joint 2-D–3-D Traffic Sign Landmark Data Set for Geo-Localization Using Mobile Laser Scanning Data},
year={2019},
volume={20},
number={7},
pages={2550-2565},
abstract={This paper presents a framework to build a joint 2-D-3-D traffic sign landmark data set for geo-localization using mobile laser scanning (MLS) data. The MLS data include 3-D point clouds and corresponding multi-view images. First, an integrated method, based on a deep learning network and the retro-reflective properties of traffic signs, is developed to accurately extract traffic signs from MLS point clouds. Next, the semantic and spatial properties of the traffic signs (type, location, position, and geometric characteristics) are obtained. Then, a joint 2-D-3-D traffic sign landmark data set is built, and a semantic-spatial organization graph is used to organize the traffic sign data set. Last, based on the traffic sign landmark data set, a geo-localization method for a driving car is proposed to estimate the driving trajectory. It can be used for auxiliary positioning of autonomous vehicles. Experimental results demonstrate the reliability of our proposed method for traffic sign detection and the potential of building 2-D-3-D traffic sign landmark data set for driving trajectory estimation from MLS data.},
keywords={Three-dimensional displays;Semantics;Trajectory;Machine learning;Shape;Autonomous vehicles;Estimation;Point cloud;multi-view images;mobile laser scanning (MLS);traffic sign;joint 2-D-3-D;geo-localization},
doi={10.1109/TITS.2018.2868168},
ISSN={1558-0016},
month={July},}
@INPROCEEDINGS{9604384,
author={Kumar, Shobhit and Das, Shirshendu and Jamadar, Manaal Mukhtar and Kaur, Jaspinder},
booktitle={2021 IEEE SmartWorld, Ubiquitous Intelligence Computing, Advanced Trusted Computing, Scalable Computing Communications, Internet of People and Smart City Innovation (SmartWorld/SCALCOM/UIC/ATC/IOP/SCI)}, title={Efficient On-chip Communication for Neuromorphic Systems},
year={2021},
volume={},
number={},
pages={234-239},
abstract={Neuromorphic computing is a trending area in computer architecture which deals with the simulation of the brain on hardware. Machine learning problems are very complex to solve by simple computers that work based on Von-Neumann architecture so we need to find architectures that are inspired by the brain and efficient for machine learning, artificial intelligence, and more complex applications. The design has been proposed to implement the traditional software-based Spiking Neural Net-works (SNN) on hardware. However, a major challenge that this SNN based hardware face is the efficient on-chip communications between the neurons. Since SNN has lots of multicast messages to be communicated among the layers, traditional on-chip routing techniques are not sufficient. In this paper, we have proposed a dynamic clustering based on-chip routing mechanism for SNN based hardware. The clustering is based on the dynamic behavior of routers. Compared with the existing clustering-based on-chip routing technique, the proposed technique gives 14% to 38% improvement over average packet latency.},
keywords={Technological innovation;Smart cities;Neuromorphic engineering;Neurons;Neural networks;Computer architecture;Machine learning;Neuromorphic System;On-Chip Interconnects;Spiking Neural Network},
doi={10.1109/SWC50871.2021.00040},
ISSN={},
month={Oct},}
@INPROCEEDINGS{8537362,
author={Khedkar, Sujata and Agnihotri, Shashank and Agarwal, Anshul and Pancholi, Mahak and Hande, Pooja},
booktitle={2018 International Conference on Smart City and Emerging Technology (ICSCET)}, title={Author Identification using Stylometry},
year={2018},
volume={},
number={},
pages={1-4},
abstract={“Every person is unique”, we have been hearing this since ages. Every person has a unique identity, a unique fingerprint, a unique retina and a lot more. These features playa vital role in identification of individuals for security purposes. Unfortunately, when it comes to security of written pieces or words from an individual, these primary unique identities are futile. One cannot identify a writer from a written piece of text on the basis of retina or fingerprint scans, sometimes even the signature can be forged, in such situations for security purposes and intellectual property rights it becomes very important to identify the true author. Stylometry plays an important role in this. Every author has a unique style of writing, measure of this style of writing is called Stylometry. This paper proposes to identify authors from text based on their style of writing. First a data set consisting of articles, short stories and emails will be used to train the system for multiple authors, then a random text would be given to the system to identify the author correctly, if the author predicted by the system is similar to the author claimed then the information is authentic otherwise the author claiming to be the writer is a fraud. For stylometry, over the ages, many features have been focused on, but this paper proposes new features to be used for this purpose. While writing, there are many unconscious styles that are incorporated by the author, these features have been unnoticed till date, but can playa vital role in accurate and fast identification of authors. These features include: `intellectual property right', `chapter length' and frequency of particular words per thousand words. The algorithms used to train the system can be Decision tree, Naive Bayesian or Multilayer Perceptron.},
keywords={Writing;Feature extraction;Decision trees;Principal component analysis;Multilayer perceptrons;Machine learning;Training;feature extraction;data set;Decision tree;artificial intelligence;machine learning;supervised learning},
doi={10.1109/ICSCET.2018.8537362},
ISSN={},
month={Jan},}
@INPROCEEDINGS{8560137,
author={Song, Shiwei and Lei, Yan and Yang, Kang and Xing, Tianzhang and Niu, Jinping and Chen, Feng and Fang, Dingyi},
booktitle={2018 IEEE SmartWorld, Ubiquitous Intelligence Computing, Advanced Trusted Computing, Scalable Computing Communications, Cloud Big Data Computing, Internet of People and Smart City Innovation (SmartWorld/SCALCOM/UIC/ATC/CBDCom/IOP/SCI)}, title={DeepAid: A Mobile Cognitive Aid System with Compacted Deep Learning},
year={2018},
volume={},
number={},
pages={873-880},
abstract={This paper presents DeepAid, a mobile system assisting cognitive decline patients. Existing designs of such systems suffer low accuracies for the recognition and long latencies for the interaction two major issues. DeepAid leverages deep learning to solve both issues at the same time. Deep learning naturally leads to high-accuracy object recognition. If it can further execute on the local device directly, the latency can be satisfied as well since frequent data transmission to the server in prior approaches can be avoided. The major contribution of this paper is to instrument the possibility that deep learning can be compact so as to achieve a good trade-off between accuracy and resource consumption, with the design of task decomposition and network scale minimization. To validate the effectiveness of DeepAid, we implement a series of experiments and compare with other related work. In the final, the DeepAid can achieve about 97% accuracy in object recognition with about 90ms time delay.},
keywords={Mobile Computing;Deep Learning;Convolutional Neural Network;Context Recognition},
doi={10.1109/SmartWorld.2018.00159},
ISSN={},
month={Oct},}
@ARTICLE{9040422,
author={Tao, Chongben and Gao, Zhen and Yan, Jinli and Li, Chunguang and Cui, Guozeng},
journal={IEEE Access}, title={Indoor 3D Semantic Robot VSLAM Based on Mask Regional Convolutional Neural Network},
year={2020},
volume={8},
number={},
pages={52906-52916},
abstract={During the construction of indoor environmental semantic maps by robot Vision SLAM (VSLAM), there exist some problems such as low label classification accuracy and low precision under the situation of sparse feature points. In this case, this paper proposes an indoor three-dimensional semantic VSLAM algorithm based on Mask Regional Convolutional Neural Network (RCNN). Firstly, an Oriented FAST and a Rotated BRIEF (ORB) algorithms are used to extract image feature points. Secondly, a Random Sample Consensus (RANSAC) algorithm is employed to eliminate mismatched points and estimate camera position-pose changes. Then, a Mask RCNN algorithm is applied to make partial adjustments to its hyper parameter. A self-made data set is used to transfer learning, fulfilling real-time target detection and instance segmentation of a scene. A three-dimensional semantic map is constructed in combination with VSLAM algorithm. The semantic information in the environment not only improves the accuracy of VSLAM construction and positioning, but also reduces the impact of object movement on the construction by marking movable objects. Meanwhile, the VSLAM algorithm is used to calculate the positional constraints between objects and improve the accuracy of semantic understanding. Finally, by comparing with other methods, it demonstrates that this method is more correct and effective. It was also verified that the proposed method can accurately interpret the semantic information in environment for the construction of three-dimensional semantic maps.},
keywords={Semantics;Feature extraction;Simultaneous localization and mapping;Three-dimensional displays;Object detection;Deep learning;VSLAM;deep learning;target detection;instance segmentation;semantic map},
doi={10.1109/ACCESS.2020.2981648},
ISSN={2169-3536},
month={},}
@INPROCEEDINGS{9221094,
author={Lücking, Markus and Rivera, Esteban and Kohout, Lukas and Zimmermann, Christoph and Polad, Duygu and Stork, Wilhelm},
booktitle={2020 IEEE 6th World Forum on Internet of Things (WF-IoT)}, title={A video-based vehicle counting system using an embedded device in realistic traffic conditions},
year={2020},
volume={},
number={},
pages={1-6},
abstract={One of the most important features of smart cities is efficient traffic monitoring. Currently, many monitoring approaches focus on video-processing techniques using traffic surveillance cameras. However, video analytics for traffic monitoring on edge devices like cameras is a difficult task, due to limited computational resources and variety of unknown traffic scenarios. To overcome these difficulties, we designed and evaluated a real-time vehicle counting system using deep neural networks in an embedded device. Experimental results were carried out to determine the best system configuration parameters and to analyze the impact of changing environmental conditions on our system performance. For urban vehicle counting, our approach could achieve a recall and precision values of 99% within a video processing time of 10 frames per second.},
keywords={Deep learning;Smart cities;Visual analytics;System performance;Surveillance;Traffic control;Cameras;Automatic vehicle counting system;edge computing;machine learning},
doi={10.1109/WF-IoT48130.2020.9221094},
ISSN={},
month={June},}
@ARTICLE{8769928,
author={Picano, Benedetta and Fantacci, Romano and Han, Zhu},
journal={IEEE Transactions on Vehicular Technology}, title={Nonlinear Dynamic Chaos Theory Framework for Passenger Demand Forecasting in Smart City},
year={2019},
volume={68},
number={9},
pages={8533-8545},
abstract={Recently chaos theory has emerged as a powerful tool to address forecasting problems of nonlinear time series, since it is able to meet the dynamical and geometrical structures of very complex systems, reaching higher accuracy on the prediction values than the classical approaches. This paper aims at applying the chaos theory principles to different problems, in order to pursue high levels of accuracy on the predicted results. After the verification of the chaotic behavior of the datasets taken into analysis through the largest Lyapunov exponent research, the detection of the suitable embedding dimension and time delay has been carried out, in order to reconstruct the phase space of the underlying dynamical systems. Three different predictive methods have been proposed for different datasets. Finally, the performance comparison with the moving average model, a deep neural network based strategy, and a chaos theory based algorithm recently proposed in literature has been provided.},
keywords={Forecasting;Time series analysis;Public transportation;Neural networks;Prediction algorithms;Complexity theory;Predictive models;Chaos theory;forecasting;nonlinear time series analysis},
doi={10.1109/TVT.2019.2930363},
ISSN={1939-9359},
month={Sep.},}
@INPROCEEDINGS{9207160,
author={Wu, Zipeng and Lian, Guan},
booktitle={2020 International Joint Conference on Neural Networks (IJCNN)}, title={A novel dynamically adjusted regressor chain for taxi demand prediction},
year={2020},
volume={},
number={},
pages={1-10},
abstract={Taxi is an essential part of urban traffic, accurately predicts the taxi demand, which not only facilitates people's travel but also promotes the further development of the entire smart city. The gap between demand and the actual amount for taxi causes trouble for travelers. Forecasts for taxi demand do not take into account the possible interactions of taxi demand between areas, which can lead to a decrease in the accuracy of the forecast. In further exploiting the interaction of taxi demand in each area, We propose An extended Maximum Correlation Regressor Chain method (MCRC) and a new MCRC-based Dynamically Adjusted Regressor Chain method. MCRC uses the various relationships existing among the targets, which are evaluated using Spearman's rank correlation coefficient, feature importance matrix, and maximal information coefficient, respectively, to form the maximum correlation chain with higher prediction accuracy. Based on MCRC, DARC dynamically adjusts the base-regressor of the regressor chain. A set of predictive approaches are implemented to compare the performances, and the results show that the maximal information coefficient DARC (DARC_MIC) achieves the best accurate rate by 91.80%. DARC_MIC is not only can provide managers a more rational taxi operation approach but also more proper for dealing with multi-target regression problems with Lots of targets. This idea of first measuring the degree of interaction between targets and then combining algorithms to further exploit this degree of interaction between targets can also be attempted to improve many other multi-target regression algorithms.},
keywords={Public transportation;Predictive models;Correlation;Computational modeling;Meteorology;Training;Smart cities;Traffic prediction;taxi demand;regressor chain;multi-target regression},
doi={10.1109/IJCNN48605.2020.9207160},
ISSN={2161-4407},
month={July},}
@INPROCEEDINGS{9239680,
author={Saponara, Sergio and Elhanashi, Abdussalam and Gagliardi, Alessio},
booktitle={2020 IEEE International Conference on Smart Computing (SMARTCOMP)}, title={Exploiting R-CNN for video smoke/fire sensing in antifire surveillance indoor and outdoor systems for smart cities},
year={2020},
volume={},
number={},
pages={392-397},
abstract={This work presents a video-camera-based fire/smoke sensing technique for early warning in antifire surveillance systems. By exploiting R-CNN (Region Convolutional Neural Network), a detection technique is developed for the measurement of the smoke and fire characteristics in restricted video surveillance environments, both indoor (e.g. a railway carriage, container, bus wagon, homes, offices), or outdoor (e.g. storage or parking areas). The considered application scenario, to reduce costs, is composed of a single, fixed camera per scene, working in the visible spectral range already installed in a closed-circuit television system for surveillance purposes. The training phase is done with indoor and outdoor image sets, with both smoke and non-smoke scenarios to assess the capability of true-positive/true-negative detection and false-positive/false-negative rejection. To generate the training set, a Ground Truth Labeler app is used and applied to the open-access Firesense dataset, including tens of indoor and outdoor fire/ smoke scenes developed as the output of an FP7 project, plus other videos not publicly available, provided by Trenitalia during specific fire/smoke tests on railway wagons performed at their testing facility in Osmannoro, Italy. The achieved results show that the proposed R-CNN technique is suitable for the creation of a smart video-surveillance system for fire/smoke detection.},
keywords={Training;TV;Video surveillance;Rail transportation;Sensors;Convolutional neural networks;Testing;Video smoke/fire sensing;Ground Truth Labeler;R-CNN (Region Convolutional Neural Network);Smart surveillance},
doi={10.1109/SMARTCOMP50058.2020.00083},
ISSN={},
month={Sep.},}
@INPROCEEDINGS{9415223,
author={Khan, Murad and Seo, Junho and Kim, Dongkyun},
booktitle={2021 International Conference on Artificial Intelligence in Information and Communication (ICAIIC)}, title={An Energy Efficient Sensor Duty Cycling for Smart Home Networks},
year={2021},
volume={},
number={},
pages={18-20},
abstract={Wireless Sensor Networks (WSN) applications are envisioned in various smart environments such as smart homes, smart cities, e-health, etc. Similarly, in future smart homes, an extensive sensor deployment would be required to control various home resident activities. However, deploying many sensors and operate them continuously requires a high amount of electrical energy. Therefore, in this paper, we presented a solution to prolong the sensors' battery life by assigning the pre-detected slots to the sensors using Bayesian Network (BN). Among the rest of the Idle Sensors (IS), a Watch Sensor (WS) is selected to detect the upcoming activities and activate the rest of the closely related sensors to the WS. The similarities between IS sensors are modeled using the Earth Mover's Distance (EMD) approach. Finally, an extensive set of simulations is performed in a smart home scenario to test the proposed scheme's performance. The simulation results show that the proposed approach significantly enhances the sensors' battery lifetime by scheduling the sensors' operational time to detect smart home resident activities.},
keywords={Wireless sensor networks;Energy consumption;Machine learning algorithms;Smart cities;Simulation;Smart homes;Switches;Sensor Duty Cycling;Bayesian Networks;Earth Mover’s Distance;Smart Homes},
doi={10.1109/ICAIIC51459.2021.9415223},
ISSN={},
month={April},}
@ARTICLE{9523537,
author={Xue, Qing and Sun, Yao and Wang, Jian and Feng, Gang and Yan, Li and Ma, Shaodan},
journal={IEEE Communications Letters}, title={User-Centric Association in Ultra-Dense mmWave Networks via Deep Reinforcement Learning},
year={2021},
volume={25},
number={11},
pages={3594-3598},
abstract={For ultra-dense networks, user-centric architecture is regarded as a promising candidate to offer mobile users better quality of service. One of the main challenges of user-centric architecture is exploring efficient scheme for user association in the ultra-dense network. In this letter, we study dynamic user-centric association (UCA) problem for ultra-dense millimeter wave (mmWave) networks to provide reliable connectivity and high achievable data rate. We consider time-varying network environments and propose a deep Q-network based UCA scheme to find the optimal association policy based on the historical experience. Simulation results are presented to verify the performance gain of our proposed scheme.},
keywords={Interference;Quality of service;Signal to noise ratio;Ultra-dense networks;Sun;Reinforcement learning;Radio frequency;Ultra-dense mmWave network;user-centric;multiple association;deep learning},
doi={10.1109/LCOMM.2021.3108013},
ISSN={1558-2558},
month={Nov},}
@INPROCEEDINGS{9060320,
author={Lian, Xu and Melancon, Sarah and Presta, Jon-Ross and Reevesman, Adam and Spiering, Brian and Woodbridge, Diane},
booktitle={2019 IEEE SmartWorld, Ubiquitous Intelligence Computing, Advanced Trusted Computing, Scalable Computing Communications, Cloud Big Data Computing, Internet of People and Smart City Innovation (SmartWorld/SCALCOM/UIC/ATC/CBDCom/IOP/SCI)}, title={Scalable Real-time Prediction and Analysis of San Francisco Fire Department Response Times},
year={2019},
volume={},
number={},
pages={694-699},
abstract={Predicting the San Francisco Fire Department (SFFD) emergency response time in real-time is critical for both callers and the SFFD. In this paper, we leverage machine learning and distributed computing to attempt a solution to this problem. While driving time can be estimated using the Google Maps API, there are many more factors that affect the response time. We obtained a publicly available SFFD call history dataset, using BigQuery, containing information about the location of the station, the location of the incident, and the time the call was received. We combined features from this dataset with driving time estimates from the Google Maps Distance Matrix API. Our dataset was over a gigabyte, calling for a distributed framework to efficient training of the machine learning models. We fit Linear Regression, Decision Tree Regression, and Random Forest Regression models in the Apache Spark machine learning library (MLlib) on an Amazon Web Services (AWS) Elastic MapReduce cluster. We benchmarked training time for each model on different cluster sizes.},
keywords={Time factors;Cloud computing;Machine learning;Medical services;Google;Linear regression;Fires;Distributed computing;Distributed information systems;Machine learning;Emergency services},
doi={10.1109/SmartWorld-UIC-ATC-SCALCOM-IOP-SCI.2019.00154},
ISSN={},
month={Aug},}
@INPROCEEDINGS{8855415,
author={Barreto Goes Perez, Tiago and Zhou, Xiaobo and Liu, Liu and Ding, Zhijun},
booktitle={2019 IEEE 21st International Conference on High Performance Computing and Communications; IEEE 17th International Conference on Smart City; IEEE 5th International Conference on Data Science and Systems (HPCC/SmartCity/DSS)}, title={Bottleneck-Aware Task Scheduling Based on Per-Stage and Multi-ML Profiling},
year={2019},
volume={},
number={},
pages={510-518},
abstract={In distributed computing clusters, assigning tasks and jobs to nodes that could lead to bottlenecks is detrimental to performance. Recent research has made extensive use of machine learning techniques to profile workloads, in order to predict their performance and schedule tasks to mitigate bottlenecks. However, those solutions take the entire workload as a single event, profiling at a coarse grained level and resulting in losses to model accuracy that limit the power of bottleneck detection to further improve on task allocation and cluster performance. Popular data analytics frameworks such as Spark utilize directed acyclic graphs to break down jobs into several smaller components such as stages, which allows for finer granularity for profiling. In this paper, we propose and develop Gargalo, a new bottleneck aware scheduler, that leverages a fine-grained, per-stage multi-machine learning profiling. As such we can find better model fitting for each stage of the job execution, and give the scheduler more accurate information to assign tasks to nodes. We leverage the use of multiple machine learning techniques for modeling performance and through a consensus we can combine the results for increased accuracy in each step. Our experiments with a Spark implementation, utilizing several popular benchmarking workloads, show that Gargalo improves speedup by up to 81% over the state-of-the-art bottleneck aware scheduler, 164% over the default speculation mechanism, and accuracy of up to 97% in predicting bottleneck detection. Gargalo is robust across different scenarios.},
keywords={Task analysis;Sparks;Peer-to-peer computing;Measurement;Machine learning;Data analysis;Conferences;Bottleneck detection;task scheduling;machine learning;performance prediction;per-stage profiling},
doi={10.1109/HPCC/SmartCity/DSS.2019.00081},
ISSN={},
month={Aug},}
@ARTICLE{9583294,
author={Weng, Xi and Yan, Yan and Chen, Si and Xue, Jing-Hao and Wang, Hanzi},
journal={IEEE Transactions on Circuits and Systems for Video Technology}, title={Stage-Aware Feature Alignment Network for Real-Time Semantic Segmentation of Street Scenes},
year={2021},
volume={},
number={},
pages={1-1},
abstract={Over the past few years, deep convolutional neural network-based methods have made great progress in semantic segmentation of street scenes. Some recent methods align feature maps to alleviate the semantic gap between them and achieve high segmentation accuracy. However, they usually adopt the feature alignment modules with the same network configuration in the decoder and thus ignore the different roles of stages of the decoder during feature aggregation, leading to a complex decoder structure. Such a manner greatly affects the inference speed. In this paper, we present a novel Stage-aware Feature Alignment Network (SFANet) based on the encoder-decoder structure for real-time semantic segmentation of street scenes. Specifically, a Stage-aware Feature Alignment module (SFA) is proposed to align and aggregate two adjacent levels of feature maps effectively. In the SFA, by taking into account the unique role of each stage in the decoder, a novel stage-aware Feature Enhancement Block (FEB) is designed to enhance spatial details and contextual information of feature maps from the encoder. In this way, we are able to address the misalignment problem with a very simple and efficient multi-branch decoder structure. Moreover, an auxiliary training strategy is developed to explicitly alleviate the multi-scale object problem without bringing additional computational costs during the inference phase. Experimental results show that the proposed SFANet exhibits a good balance between accuracy and speed for real-time semantic segmentation of street scenes. In particular, based on ResNet-18, SFANet respectively obtains 78.1% and 74.7% mean of class-wise Intersection-over-Union (mIoU) at inference speeds of 37 FPS and 96 FPS on the challenging Cityscapes and CamVid test datasets by using only a single GTX 1080Ti GPU.},
keywords={Semantics;Decoding;Real-time systems;Image segmentation;Training;Aggregates;Predictive models;Real-time semantic segmentation;street scene understanding;deep learning;lightweight convolutional neural network;feature alignment and aggregation},
doi={10.1109/TCSVT.2021.3121680},
ISSN={1558-2205},
month={},}
@INPROCEEDINGS{9615390,
author={Batool, Syeda and Ismail, Muhammad Ali and Ali, Shabbar},
booktitle={2021 IEEE 18th International Conference on Smart Communities: Improving Quality of Life Using ICT, IoT and AI (HONET)}, title={Analysis and Predictive Modeling of Traffic Incidents in Karachi using Machine Learning},
year={2021},
volume={},
number={},
pages={106-111},
abstract={Road traffic accidents have accounted to extremely dense road traffic and the relatively great freedom of movement given to drivers. Due to the increasing traffic accidents in Karachi, it is vital to investigate the major parameters that are causing these fatalities. For this purpose, machine learning techniques provide a greater advantage over other statistical methods. In this research, a novel approach that applies Random Forest and Support vector machine (SVM) algorithm out of many different machine learning algorithms for modeling traffic accidents prediction. Empirical results show that reasonable accuracy of the developed model. The results further showed the accuracy fluctuated according to the number of attributes in the output parameter. The results of SVM showed better predictions than that from Random Forest. The parameter with less attributes like Disposal has higher accuracy of prediction with Random Forest 83.12% whereas those with greater number of attribute have higher prediction accuracy with SVM e.g. Months with 64.98%.},
keywords={Support vector machines;Machine learning algorithms;Statistical analysis;Smart cities;Roads;Predictive models;Safety;Accuracy;attributes;fatalities;Machine Learning;parameters;Random Forest;Road Traffic Accidents;Support Vector Machine;traffic accidents prediction;Traffic safety},
doi={10.1109/HONET53078.2021.9615390},
ISSN={1949-4106},
month={Oct},}
@ARTICLE{8509149,
author={Duan, Lingyu and Lou, Yihang and Wang, Shiqi and Gao, Wen and Rui, Yong},
journal={IEEE MultiMedia}, title={AI-Oriented Large-Scale Video Management for Smart City: Technologies, Standards, and Beyond},
year={2019},
volume={26},
number={2},
pages={8-20},
abstract={Deep learning has achieved substantial success in intelligent video analysis. To practically facilitate deep neural network models in the large-scale video analysis, there are still unprecedented challenges. Deep feature coding, instead of video coding, provides a practical solution for handling the large-scale video surveillance data. To enable interoperability in the context of deep feature coding, standardization is urgent and important. This paper envisions the future deep feature coding standard for the AI-oriented large-scale video management and discusses existing techniques, standards, and possible solutions for these open problems.},
keywords={Feature extraction;Task analysis;Face recognition;Face;Standards;Encoding},
doi={10.1109/MMUL.2018.2873564},
ISSN={1941-0166},
month={April},}
@INPROCEEDINGS{9181961,
author={Albataineh, Hisham and Nijim, Mais and Bollampall, Divya},
booktitle={2020 IEEE 8th International Conference on Smart Energy Grid Engineering (SEGE)}, title={The Design of a Novel Smart Home Control System using Smart Grid Based on Edge and Cloud Computing},
year={2020},
volume={},
number={},
pages={88-91},
abstract={The Internet of Things (IoT) has transpired as a fascinating technology for smart cities, smart homes, and smart grids by using a vast amount of IoT data. A smart grid is one of the core components where transport, generation, delivery, and electricity consumption are enhanced in terms of protection and reliability. The existing power grid is suffering from many problems such as outages and unpredictable power disturbances, inflexible energy rates, unnoticeable customer fraud, and many other disadvantages. These problems lead to the ever-rising demand for fossil fuel and service costs. For example, the peak hour demand needs to be overestimated and more energy generated to minimize the risk of an outage. The main problem of the smart grid is the tremendous amount of data needs to be collected from the IoT devices, and processing the data is a challenge. Using and predicting a large amount of data in smart Grid and IoT is still in its infancy. To remedy this problem, we propose a hybrid solution by using the Cloud and Edge Computing to process the data. Processing and predicting at the edge that is close to the embedded devices and homes to save in latency and storage compared to putting all the processing in the Cloud. In this paper, we define a hybrid solution where we use the edge computing for the smart grid information processing where the microgrids are located on the edge of the IoT network, and on the Cloud to use for the power grid that distributes power to the microgrids. We proposed a machine learning engine that used the decision tree to establish the communication between the edge layer, failover between edges, and the Cloud layer.},
keywords={Cloud computing;Smart grids;Microgrids;Machine learning;Edge computing;Engines;Smart homes;component;smart grid;edge computing;cloud computing;machine learning;power utilization},
doi={10.1109/SEGE49949.2020.9181961},
ISSN={2575-2693},
month={Aug},}

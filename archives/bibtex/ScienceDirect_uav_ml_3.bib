@article{ZHAO201854,
title = {Survey on computational-intelligence-based UAV path planning},
journal = {Knowledge-Based Systems},
volume = {158},
pages = {54-64},
year = {2018},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2018.05.033},
url = {https://www.sciencedirect.com/science/article/pii/S0950705118302636},
author = {Yijing Zhao and Zheng Zheng and Yang Liu},
keywords = {Unmanned aerial vehicle, Path planning, Computational intelligence, Learning-based algorithms},
abstract = {The key objective of unmanned aerial vehicle (UAV) path planning is to produce a flight path that connects a start state and a goal state while meeting the required constraints. Computational intelligence (CI) is a set of nature-inspired computational methodologies and approaches for addressing complex real-world problems for which mathematical or traditional modelling does not perform well. It has been applied in the field of UAVs since it can yield effective, accurate and rapid solutions. This article provides an overview of studies on UAV path planning based on CI methods published in major journals and conference proceedings. We survey relevant studies with respect to different CI algorithms utilized in UAV path planning, the types of time domain in UAV path planning, namely, offline and online, and the types of environment models, namely, 2D and 3D. It is observed that CI methods outperform traditional methods on online and 3D problems. The analysis is useful for identifying key results from UAV path planning research and is leveraged in this article to highlight trends and open issues.}
}
@article{NYAMEKYE2021100053,
title = {Mapping changes in artisanal and small-scale mining (ASM) landscape using machine and deep learning algorithms. - a proxy evaluation of the 2017 ban on ASM in Ghana},
journal = {Environmental Challenges},
volume = {3},
pages = {100053},
year = {2021},
issn = {2667-0100},
doi = {https://doi.org/10.1016/j.envc.2021.100053},
url = {https://www.sciencedirect.com/science/article/pii/S2667010021000329},
author = {Clement Nyamekye and Benjamin Ghansah and Emmanuel Agyapong and Samuel Kwofie},
keywords = {Machine Learning, Sentinel-2, Artisanal and small-scale mining, Ghana, Land use land cover change},
abstract = {Artisanal and Small-Scale Mining (ASM) landscapes form integral part of the Land use land cover (LULC) in the developing worlds. However, the spatial, spectral, and temporal footprints of ASM present some challenges for using most of the freely available optical satellite sensors for change analysis. The challenge is even profound in tropical West African countries like Ghana where there is prolonged cloud cover. Whiles very few studies have used Sentinel-2 data to map change analysis in ASM landscape, none examined the contribution of individual S2 bands to the ASM classifications. Also, despite the capabilities of Machine Learning (ML) and Deep Learning (DL) models for LULC classifications, few studies have compared the performances of different classifiers in mapping ASM landscape. This study utilized Sentinel-2 data, four ML and DL models (Artificial Neural Network –ANN, Random Forest – RF, Support Vector Machines –SVM, a pixel-based Convolutional Neural Network-CNN) and image segmentation to examine the performance of S2 bands and ML and DL algorithms for change analysis in ASM landscape, with the Birim Basin in Ghana as a study area. The result of the change analysis was used to assess changes in LULC during the recent ban on the expansion of ASM in the country. It was found out that ANN is a better classifier of ASM achieving the highest overall accuracy (OA) of 99.80% on the segmented Sentinel-2 bands. The study also found out that the Band 5 Vegetation Red Edge (VRE) 1 contributed most to classifying ASM, with the segmented VRE 1 being superlative over the other predictors. In terms of expansion, ASM increased by 59.17 km2 within the period of the study (January 2017 to December 2018), suggesting that ASM still took place under the watch of the ban. The classification results showed that most of the peripheral of forest and farmland have been converted to ASM with little disturbance within the interior of the forest reserves. The study revealed that, the ban was yielding very little or no results due to a number of policy deficiencies including low staff strength, lack of logistics and low remuneration. Enforcement of legal instruments against ASM and farming activities within the forest reserves, improvement in the monitoring systems and intensification of public education on the value of forest and the need to protect it are some of the major recommendations that could control encroachment on the forest reserves.}
}
@article{NYAMEKYE2021100655,
title = {Examining the performances of true color RGB bands from Landsat-8, Sentinel-2 and UAV as stand-alone data for mapping artisanal and Small-Scale Mining (ASM)},
journal = {Remote Sensing Applications: Society and Environment},
volume = {24},
pages = {100655},
year = {2021},
issn = {2352-9385},
doi = {https://doi.org/10.1016/j.rsase.2021.100655},
url = {https://www.sciencedirect.com/science/article/pii/S2352938521001919},
author = {Clement Nyamekye and Benjamin Ghansah and Emmanuel Agyapong and Emmanuel Obuobie and Alfred Awuah and Samuel Kwofie},
keywords = {Sentinel-2, Landsat-8, Unmanned aerial vehicle, RGB},
abstract = {Conventional satellite sensors provide periodic data for monitoring Artisanal and Small-Scale Mining (ASM). Incorporating Unmanned Aerial Vehicle (UAV) sensors in monitoring ASM can increase data availability and also mitigate the challenge of cloud cover that causes data gaps in satellite data availability. However, most UAV sensors measure only in the Red-Green-Blue (RGB) bands and the utility of RGB for Land Use Land Cover (LULC) mapping is still in the preliminary stages. This study contributes to research by examining the accuracies of true color RGB images for mapping ASM, using the Birim Basin in Ghana as a case study. The study first compared Landsat 8 (L8) and Sentinel-2 (S2) full reflective bands for LULC mapping of the basin. The study then used true color RGB from UAV, L8 and S2 to map a subsection of the basin where there was active ASM. A test experiment was also performed in which other band combinations, single band, and indices were used to map ASM. From the results, the L8 and S2 full reflective bands attained Overall accuracy (OA) and User Accuracy (UA) over 97%, with less than 1% difference between their accuracies. All stand-alone RGB precisely mapped ASM with accuracies of 90% and above, indicating their fit for mapping ASM. However, the effect of image resolution caused differences in the surface area of the ASM estimated from the different sensors. Also, the different band combinations and indices could not accurately map ASM. Nonetheless, the results of the study showed increased scientific grounds for using UAV for mapping ASM. The overall results showed the capabilities of remote sensors in providing frequent and sustainable data for mapping ASM. Additionally, the results from the three images (L8, S2 and UAV) reavelaed much destruction of the forest cover due ASM. These results would be relevant in monitoring and managing the natural resources, which will help achieve environmental sustainability in meeting the SDG goals in 2030.}
}
@article{MOGHIMI2020105299,
title = {Aerial hyperspectral imagery and deep neural networks for high-throughput yield phenotyping in wheat},
journal = {Computers and Electronics in Agriculture},
volume = {172},
pages = {105299},
year = {2020},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2020.105299},
url = {https://www.sciencedirect.com/science/article/pii/S0168169919320721},
author = {Ali Moghimi and Ce Yang and James A. Anderson},
keywords = {Deep learning, Endmember, Hyperspectral imaging, Neural network, Phenotyping, UAV, Unmixing, Yield},
abstract = {Crop production needs to increase in a sustainable manner to meet the growing global demand for food. To identify crop varieties with high yield potential, plant scientists and breeders evaluate the performance of hundreds of lines in multiple locations over several years. To facilitate the process of selecting advanced varieties, an automated framework was developed in this study. A hyperspectral camera was mounted on an unmanned aerial vehicle to collect aerial imagery with high spatial and spectral resolution in a fast, cost-effective manner. Aerial images were captured in two consecutive growing seasons from three experimental yield fields composed of hundreds experimental wheat lines. The grain of more than thousand wheat plots was harvested by a combine, weighed, and recorded as the ground truth data. To investigate the yield variation at sub-plot scale and leverage the high spatial resolution, plots were divided into sub-plots using image processing techniques integrated by domain knowledge. Subsequent to extracting features from each sub-plot, deep neural networks were trained for yield estimation. The coefficient of determination for predicting the yield was 0.79 and 0.41 with normalized root mean square error of 0.24 and 0.14 g at sub-plot and plot scale, respectively. The results revealed that the proposed framework, as a valuable decision support tool, can facilitate the process of high-throughput yield phenotyping by offering the possibility of remote visual inspection of the plots as well as optimizing plot size to investigate more lines in a dedicated field each year.}
}
@article{MARQUESRAMOS2020105791,
title = {A random forest ranking approach to predict yield in maize with uav-based vegetation spectral indices},
journal = {Computers and Electronics in Agriculture},
volume = {178},
pages = {105791},
year = {2020},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2020.105791},
url = {https://www.sciencedirect.com/science/article/pii/S0168169920319591},
author = {Ana Paula {Marques Ramos} and Lucas {Prado Osco} and Danielle {Elis Garcia Furuya} and Wesley {Nunes Gonçalves} and Dthenifer {Cordeiro Santana} and Larissa {Pereira Ribeiro Teodoro} and Carlos {Antonio da Silva Junior} and Guilherme {Fernando Capristo-Silva} and Jonathan Li and Fábio {Henrique Rojo Baio} and José {Marcato Junior} and Paulo {Eduardo Teodoro} and Hemerson Pistori},
keywords = {Precision agriculture, Multispectral images, Shallow learner, Random Forest},
abstract = {Random Forest (RF) is a machine learning technique that has been proved to be highly accurate in several agricultural applications. However, to yield prediction, how much this technique may be improved with the adoption of a ranking-based strategy is still an unknown issue. Here we propose a ranking-based approach to potentialize the RF method for maize yield prediction. This approach is based on the correlation parameter of individual vegetation indices (VIs). The VIs were individually ranked based on a merit metric that measures the improvement on the Pearson’s correlation coefficient by using RF against a baseline method. As a result, only the most relevant VIs were considered as input features to the RF model. We used 33 VIs extracted from multispectral UAV-based (unmanned aerial vehicle) imagery. The multispectral data were generated with two different sensors: Sequoia and MicaSense; during the 2017/2018 and 2018/2019 crop seasons, respectively. Amongst all the evaluated indices, NDVI, NDRE, and GNDVI were the top three in the ranking-based analysis, and their combination with RF increased the maize yield prediction. Our approach also outperformed other known machine learning methods, like support vector machine and artificial neural network. Additive regression, using the RF as the base weak learner, provided a higher accuracy with a correlation coefficient and MAE (Mean Absolute Error) of 0.78 and 853.11 kg ha−1, respectively. We conclude that the ranking-based strategy of VIs is appropriate to predict maize yield using machine learning methods and data derived from multispectral images. We demonstrated that our approach reduces the number of VIs needed to determine a high accuracy and relative low MAE, and the approach may contribute to decision-making actions, resulting in accurate management of maize fields.}
}
@article{AHMED2019109253,
title = {Solving visual pollution with deep learning: A new nexus in environmental management},
journal = {Journal of Environmental Management},
volume = {248},
pages = {109253},
year = {2019},
issn = {0301-4797},
doi = {https://doi.org/10.1016/j.jenvman.2019.07.024},
url = {https://www.sciencedirect.com/science/article/pii/S0301479719309557},
author = {Nahian Ahmed and M. Nazmul Islam and Ahmad Saraf Tuba and M.R.C. Mahdy and Mohammad Sujauddin},
keywords = {Visual pollution, Deep learning, Convolutional neural network, Image recognition, Pollutant classification, Environmental management},
abstract = {Visual pollution is a relatively new concern amidst the existing plethora of mainstream environmental pollution, recommending the necessity for research to conceptualize, formalize, quantify and assess it from different dimensions. The purpose of this study is to create a new field of automated visual pollutant classification, harnessing the technological prowess of the 21st century for applications in environmental management. From the wide range of visual pollutants, four categories have been considered viz. (i) billboards and signage, (ii) telephone and communication wires, (iii) network and communication towers and (iv) street litter. The deep learning model used in this study simulates the human learning experience in the context of image recognition for visual pollutant classification by training and testing a convolutional neural network with several layers of artificial neurons. Data augmentation using image processing techniques and a train-test split ratio of 80:20 have been used. Training accuracy of 95% and validation accuracy of 85% have been achieved by the deep learning model. The results indicate that the upper limit of accuracy i.e. the asymptote, depends on the dataset size for this type of task. This study has several applications in environmental management. For example, the deployment of the trained model for processing of video/live footage from smartphone applications, closed-circuit television and drones/unmanned aerial vehicles can be applied for both the removal and management of visual pollutants in the natural and built environment. Furthermore, generating the ‘visual pollution score/index’ of urban regions such as towns and cities will create a new ‘metric/indicator’ in the field of urban environmental management.}
}
@article{ZHAO202267,
title = {A deep reinforcement learning based searching method for source localization},
journal = {Information Sciences},
volume = {588},
pages = {67-81},
year = {2022},
issn = {0020-0255},
doi = {https://doi.org/10.1016/j.ins.2021.12.041},
url = {https://www.sciencedirect.com/science/article/pii/S0020025521012615},
author = {Yong Zhao and Bin Chen and XiangHan Wang and Zhengqiu Zhu and Yiduo Wang and Guangquan Cheng and Rui Wang and Rongxiao Wang and Ming He and Yu Liu},
keywords = {Autonomous searching method, Deep reinforcement learning, DBSCAN algorithm, Entrotaxis algorithm},
abstract = {The localization of hazardous sources (e.g. poisonous gas sources) is an important task regarding the security of human society. To find the unknown source in time, various autonomous source searching methods have mushroomed and been employed over the past decade. This paper designs a fresh source searching approach, namely particle clustering-deep Q-network, PC-DQN, which applies the deep reinforcement learning (DRL) techniques as a source searching approach for the first time. Specifically, the search process is formulated as the partially observable Markov decision process, then converted into the Markov decision process based on the belief state (represented by the particle filter). PC-DQN leverages the density-based spatial clustering of applications with noise (DBSCAN) algorithm to extract the feature of belief state, and employ the deep Q-network (DQN) algorithm to find the optimal policy for the source searching task. Through the comparison with two baseline methods (i.e. RANDOM and Entrotaxis algorithm) under various experimental conditions, the viability of our proposed PC-DQN is testified. Results explicitly reveal that the success rate of the PC-DQN maintains at a high level (beyond 99.6%) in all scenarios in this paper, and the mean search step shows evident superiority over baseline methods in most scenarios. Significantly, we also introduce the transfer learning concept to reuse the well-trained Q-network into new scenarios. These findings show important implications of the DRL-based approach as an alternative and more effective source searching approach.}
}
@article{XU2020121,
title = {A cascade adaboost and CNN algorithm for drogue detection in UAV autonomous aerial refueling},
journal = {Neurocomputing},
volume = {408},
pages = {121-134},
year = {2020},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2019.10.115},
url = {https://www.sciencedirect.com/science/article/pii/S0925231220303404},
author = {Xiaobin Xu and Haibin Duan and Yanjie Guo and Yimin Deng},
keywords = {Autonomous aerial refueling, Cascade adaboost, Tiny convolutional neural networks, Improved focal loss},
abstract = {To promote the combat capability of unmanned aerial vehicles (UAVs) in the future battlefield, the autonomous aerial refueling (AAR) technology becomes a challenging research issue. An accurate position relationship between the tanker and the receiver is significant for AAR. A novel drogue detection method is presented in this paper. The Adaptive boosting (Adaboost) and the convolutional neural networks (CNN) classifier with the improved focal loss (IFL) function are utilized to detect the drogue in complex environments. The sample imbalance during the training stage of the CNN classifier is solved by the IFL function. The PyTorch deep learning framework is employed to implement the software system with the graphics processing units (GPUs). Real scenario images with a mimetic drogue on the tanker are captured for training and testing dataset by the airborne camera on the receiver. The experimental results indicate that the presented algorithm can accelerate the detection speed and improve the detection accuracy.}
}
@article{CORCOLES201331,
title = {Estimation of leaf area index in onion (Allium cepa L.) using an unmanned aerial vehicle},
journal = {Biosystems Engineering},
volume = {115},
number = {1},
pages = {31-42},
year = {2013},
issn = {1537-5110},
doi = {https://doi.org/10.1016/j.biosystemseng.2013.02.002},
url = {https://www.sciencedirect.com/science/article/pii/S1537511013000214},
author = {Juan I. Córcoles and Jose F. Ortega and David Hernández and Miguel A. Moreno},
abstract = {Leaf area index (LAI) is one of the most common indices in agronomy, being a parameter associated with physiological processes. Canopy cover and structure are related to LAI and they have effects on the interaction between crops and the environment. The aim was to evaluate a non-destructive method to measure canopy cover in an onion crop using an unmanned aerial vehicle (UAV). A field experiment was conducted in a commercial onion plot irrigated with a centre pivot system during the 2010 irrigation season. Several data sampling events were carried out in order to determine leaf area in eight experimental plots. In each one of these plots, aerial photographs were taken using a vertical take-off and landing (VTOL) quadrotor aircraft. Canopy cover (CC) was obtained by means of software developed for this study. The maximum value of LAI represents a CC of 56%, which is high for the characteristics of this crop. Three models were used to analyse the relationship between leaf area index and canopy cover. According to the results, a more linear relationship was found between both parameters during early growth stages than during more advanced stages. For the linear model, which best fitted all growth stages; the slope that relates CC with LAI was 2.877 with a coefficient of determination of 0.837.}
}
@article{SENGUPTA2020105596,
title = {A review of deep learning with special emphasis on architectures, applications and recent trends},
journal = {Knowledge-Based Systems},
volume = {194},
pages = {105596},
year = {2020},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2020.105596},
url = {https://www.sciencedirect.com/science/article/pii/S095070512030071X},
author = {Saptarshi Sengupta and Sanchita Basak and Pallabi Saikia and Sayak Paul and Vasilios Tsalavoutis and Frederick Atiah and Vadlamani Ravi and Alan Peters},
keywords = {Deep neural network architectures, Supervised learning, Unsupervised learning, Testing neural networks, Applications of deep learning, Evolutionary computation},
abstract = {Deep learning (DL) has solved a problem that a few years ago was thought to be intractable — the automatic recognition of patterns in spatial and temporal data with an accuracy superior to that of humans. It has solved problems beyond the realm of traditional, hand-crafted machine learning algorithms and captured the imagination of practitioners who are inundated with all types of data. As public awareness of the efficacy of DL increases so does the desire to make use of it. But even for highly trained professionals it can be daunting to approach the rapidly increasing body of knowledge in the field. Where does one start? How does one determine if a particular DL model is applicable to their problem? How does one train and deploy them? With these questions in mind, we present an overview of some of the key DL architectures. We also discuss some new automatic architecture optimization protocols that use multi-agent approaches. Further, since guaranteeing system uptime is critical to many applications, a section dwells on using DL for fault detection and mitigation. This is followed by an exploratory survey of several areas where DL emerged as a game-changer: fraud detection in financial applications, financial time-series forecasting, predictive and prescriptive analytics, medical image processing, power systems research and recommender systems. The thrust of this review is to outline emerging applications of DL and provide a reference to researchers seeking to use DL in their work for pattern recognition with unparalleled learning capacity and the ability to scale with data.}
}
@article{STOLFI2021107701,
title = {A competitive Predator–Prey approach to enhance surveillance by UAV swarms},
journal = {Applied Soft Computing},
volume = {111},
pages = {107701},
year = {2021},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2021.107701},
url = {https://www.sciencedirect.com/science/article/pii/S1568494621006220},
author = {Daniel H. Stolfi and Matthias R. Brust and Grégoire Danoy and Pascal Bouvry},
keywords = {Swarm robotics, Computer simulation, Mobility model, Unmanned aerial vehicle, Competitive coevolutionary genetic algorithm},
abstract = {In this paper we present the competitive optimisation of a swarm of Unmanned Aerial Vehicles (UAV) protecting a restricted area from a number of intruders following a Predator–Prey approach. We propose a Competitive Coevolutionary Genetic Algorithm (CompCGA) which optimises the parameters of the UAVs (i.e. predators) to maximise the detection of intruders, while the parameters of the intruders (i.e. preys) are optimised to maximise their intrusion success rate. Having chosen the CACOC (Chaotic Ant Colony Optimisation for Coverage) as the base mobility model for the UAVs, we propose an improved new version, where its behaviour is modified by identifying and optimising new parameters to improve the overall success rate when detecting intruders. Six case studies have been optimised using simulations by performing 30 independent runs (180 in total) of our CompCGA. Finally, we conducted a series of master tournaments (1,800,000 evaluations) using the best specimens obtained from each run and case study to test the robustness of our proposed approach against unexpected intruders. Our surveillance system improved the average percentage of intruders detected with respect to CACOC by a maximum of 126%. More than 90% of intruders were detected on average when using a swarm of 16 UAVs while CACOC’s detection rates are always under 80% in all cases.}
}
@article{SAGAN2021265,
title = {Field-scale crop yield prediction using multi-temporal WorldView-3 and PlanetScope satellite data and deep learning},
journal = {ISPRS Journal of Photogrammetry and Remote Sensing},
volume = {174},
pages = {265-281},
year = {2021},
issn = {0924-2716},
doi = {https://doi.org/10.1016/j.isprsjprs.2021.02.008},
url = {https://www.sciencedirect.com/science/article/pii/S0924271621000411},
author = {Vasit Sagan and Maitiniyazi Maimaitijiang and Sourav Bhadra and Matthew Maimaitiyiming and Davis R. Brown and Paheding Sidike and Felix B. Fritschi},
keywords = {PlanetScope, WorldView-3, Deep learning, Convolutionneural network, ResNet, Artificial intelligence, Food security},
abstract = {Agricultural management at field-scale is critical for improving yield to address global food security, as providing enough food for the world’s growing population has become a wicked problem for both scientists and policymakers. County- or regional-scale data do not provide meaningful information to farmers who are interested in field-scale yield forecasting for effective and timely field management. No studies directly utilized raw satellite imagery for field-scale yield prediction using deep learning. The objectives of this paper were twofold: (1) to develop a raw imagery-based deep learning approach for field-scale yield prediction, (2) investigate the contribution of in-season multitemporal imagery for grain yield prediction with hand-crafted features and WorldView-3 (WV) and PlanetScope (PS) imagery as the direct input, respectively. Four WV-3 and 25 PS imagery collected during the growing season of soybean were utilized. Both 2-dimensional (2D) and 3-dimensional (3D) convolution neural network (CNN) architectures were developed that integrated spectral, spatial, temporal information contained in the satellite data. For comparison, hundreds of carefully selected spectral, spatial, textural, and temporal features that are optimal for crop growth monitoring were extracted and fed into the same deep learning model. Our results demonstrated that (1) deep learning was able to predict yield directly using raw satellite imagery to the extent that was comparable to feature-fed deep learning approaches; (2) both 2D and 3D CNN models were able to explain nearly 90% variance in field-scale yield; (3) limited number of WV-3 outperformed multi-temporal PS data collected during entire growing season mainly attributed to RedEdge and SWIR bands available with WV-3; and (4) 3D CNN increased the prediction power of PS data compared to 2D CNN due to its ability to digest temporal features extracted from PS data.}
}
@article{ALHILO2021100391,
title = {A cooperative approach for content caching and delivery in UAV-assisted vehicular networks},
journal = {Vehicular Communications},
volume = {32},
pages = {100391},
year = {2021},
issn = {2214-2096},
doi = {https://doi.org/10.1016/j.vehcom.2021.100391},
url = {https://www.sciencedirect.com/science/article/pii/S2214209621000607},
author = {Ahmed Al-Hilo and Moataz Samir and Chadi Assi and Sanaa Sharafeddine and Dariush Ebrahimi},
keywords = {UAVs, Vehicular networks, Reinforcement learning, Optimization, Content caching},
abstract = {Given the advent of Intelligent Transportation Systems (ITSs), drivers and passengers could now spend more of their time enjoying entertainment applications, e.g., watching TV or streaming movies. However, such services can drastically increase the traffic load on the existing network infrastructure (i.e. Roadside Units (RSU) and Cellular Base Stations (CBS)). Recently, Unmanned Aerial Vehicles (UAVs) have been playing a remarkable role in offloading terrestrial networks and providing cellular services thanks to their agility and flexibility. Hence, this paper explores a cooperative approach for content caching and delivery in the context of internet of connected vehicles, where a RSU, having access to a library of contents but with limited communication coverage, collaborates with a UAV to deliver contents to vehicles on a road segment. In this context, the connected RSU is responsible for delivering contents to the UAV cache unit by leveraging passing by vehicles. The RSU loads the contents on these vehicles that in turn upload them to the UAV cache unit. We model this cooperation problem mathematically as a mixed integer non-linear programming (MINLP) problem with the objective to maximize the number of served vehicles. Owing to the complexity of solving this problem, it is alternatively cast as an MDP whose solution is obtained through a Dual-Task Reinforcement Learning method (DTDRL). Simulation results show the superiority of our proposed collaborative solution over non-collaborative methods.}
}
@article{TWEEDALE20141033,
title = {Enhancing the Dgree of Autonomy on a ‘Tier 1’ Unmanned Aerial Vehicle Using a Visual Landing Framework},
journal = {Procedia Computer Science},
volume = {35},
pages = {1033-1042},
year = {2014},
note = {Knowledge-Based and Intelligent Information & Engineering Systems 18th Annual Conference, KES-2014 Gdynia, Poland, September 2014 Proceedings},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2014.08.190},
url = {https://www.sciencedirect.com/science/article/pii/S1877050914011557},
author = {Jeffrey W. Tweedale and Dion Gonano},
keywords = {Agents, Artificial Intelligence, Automation, Autonomy, Autonomous Systems, Computational Intelligence, M2 M, Machine Intelligence, Machine Vision, Multi-Agent Systems, SIFT.},
abstract = {Humans continue to use tools to manually transform raw resources into valued outputs. The type of tool, amount of effort and form of energy required vary depending on the output; however they now enable industry to manufacture goods (with excellent quality and extremely high volume). Industry continues to invest heavily in machines so that people can operate productively. Similarly, researchers continue to pursue automation to increase the Degree of Autonomy (DOA) using Advanced Information Processing (AIP) techniques. Artificial Intelligence (AI), Computational Intelligence (CI) and Machine Intelligence (MI) now facilitate automation for numerous achievements. The proposed Visual Landing Framework (VLF) design uses a Multi-Agent System (MAS) to facilitate the development of components, that interoperate, via embedded business logic, to deliver the coordination and cooperation techniques required to automate a higher-level cognitive processing problem. As technology incorporates this ever increasing Level of Automation (LOA), humans remain in charge and are retained to make higher-order decisions. Unlike humans, heuristic and declarative logic systems suffers under these conditions and to need to adapt or make human-like decision to succeed. This paper discusses one possible avenue of enhancing the DOA on a ‘Tier 1’ Unmanned Aerial Vehicle (UAV) by reducing the need for the human to concentrate on a difficult cognitive task. The Machine to Machine (M2M) autonomy component uses an on-board camera, the Open Source Computer Vision Library (OpenCV) and Scale-Invariant Feature Transform (SIFT) algorithms to translate a fixed ground reference into positional commands. With this increased LOA the platform should be able to generate greater independence and enable more autonomous behaviour within unmanned control systems.}
}
@article{MANNO2021114315,
title = {Deep learning strategies for automatic fault diagnosis in photovoltaic systems by thermographic images},
journal = {Energy Conversion and Management},
volume = {241},
pages = {114315},
year = {2021},
issn = {0196-8904},
doi = {https://doi.org/10.1016/j.enconman.2021.114315},
url = {https://www.sciencedirect.com/science/article/pii/S019689042100491X},
author = {D. Manno and G. Cipriani and G. Ciulla and V. {Di Dio} and S. Guarino and V. {Lo Brano}},
keywords = {Automatic Fault recognition, Convolutional Neural Network, Photovoltaics, TensorFlow, Infrared Thermography},
abstract = {Losses of electricity production in photovoltaic systems are mainly caused by the presence of faults that affect the efficiency of the systems. The identification of any overheating in a photovoltaic module, through the thermographic non-destructive test, may be essential to maintain the correct functioning of the photovoltaic system quickly and cost-effectively, without interrupting its normal operation. This work proposes a system for the automatic classification of thermographic images using a convolutional neural network, developed via open-source libraries. To reduce image noise, various pre-processing strategies were evaluated, including normalization and homogenization of pixels, greyscaling, thresholding, discrete wavelet transform, and Sobel Feldman and box blur filtering. These techniques allow the classification of thermographic images of differen quality and acquired using different equipments, without specific protocols. Several tests with different parameters and overfitting reduction techniques were carried out to assess the performance of the neural networks: images acquired by unmanned aerial vehicles and ground-based operators were compared for the network performance and for the time required to execute the thermographic inspection. Our tool is based on a convolutional neural network that allows to immediately recognize a failure in a PV panel reaching a very high accuracy. Considering a dataset of 1000 images that refer to different acquisition protocols, it was reached an accuracy of 99% for a convolutional neural network with 30 min of computational time on Low Mid-Range CPU. While a dataset of 200 sectioned images, the same tool achieved 90% accuracy with a multi-layer perceptron architecture and 100% accuracy for a convolutional neural network. The proposed methodology offers an open alternative and a valid tool that improves the resolution of image classification for remote failure detection problems and that can be used in any scientific sector.}
}
@article{GONZALOMARTIN2021106179,
title = {Improving deep learning sorghum head detection through test time augmentation},
journal = {Computers and Electronics in Agriculture},
volume = {186},
pages = {106179},
year = {2021},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2021.106179},
url = {https://www.sciencedirect.com/science/article/pii/S0168169921001964},
author = {Consuelo Gonzalo-Martín and Angel García-Pedrero and Mario Lillo-Saavedra},
keywords = {Object detection, Deep learning, Test time augmentation, Unmanned aerial vehicle imagery},
abstract = {The continuous growth of the world’s population requires immediate action to ensure food security. Sorghum is among the five most-produced cereals and is a dietary staple in many developing countries. Therefore, it is of great importance to obtain precise information for improving cereal productivity. An indicator for estimating sorghum yields is the number of crop heads in different branching arrangements. Approaches based on image processing and artificial intelligence have proved useful for automatically and efficiently obtaining this type of information for different crops. However, their application to sorghum crops presents some additional challenges owing to differences in the shape and color of sorghum heads. In this study, a methodology to detect sorghum heads in unmanned aerial vehicle imagery was investigated, and its performance was evaluated using a standard quality index in object detection problems (mean average precision). Specifically, test-time-augmentation (TTA) techniques have been implemented using a set of geometrical and color transformations selected according to the sorghum plant imagery requiring analysis, as well as four different ensemble learning methods. Because these methods are weighted, two different approaches for calculating these weights to improve sorghum head detection have been proposed. The results show that in sorghum head detection, TTA strategies outperform detection based only on individual transformed testing sets. Moreover, these results were improved by the use of different weights during the ensemble of TTA results.}
}
@article{YU2021107128,
title = {Face recognition framework based on effective computing and adversarial neural network and its implementation in machine vision for social robots},
journal = {Computers & Electrical Engineering},
volume = {92},
pages = {107128},
year = {2021},
issn = {0045-7906},
doi = {https://doi.org/10.1016/j.compeleceng.2021.107128},
url = {https://www.sciencedirect.com/science/article/pii/S0045790621001324},
author = {Chenglin Yu and Hailong Pei},
keywords = {Computational model, Counter neural network, Deep learning, Face recognition, Machine vision},
abstract = {In recent years, with the continuous breakthrough of computer vision technology, the accuracy of object detection and target recognition has been improved by leaps and bounds. Face recognition is one of the important research directions in the field of computer vision, which is widely used in mobile payment, safe city, criminal investigation and other fields. Traditional face recognition methods need to extract face image features manually. The extracted features are greatly affected by subjective factors, and time-consuming and laborious. Deep learning is the most important technology in the field of computer vision at present. Compared with traditional face recognition methods, it can extract more essential features of face image without manual participation. In this paper, we build a face recognition system based on neural computing model and the principle of neural network. The experimental results show that the proposed method has high detection rate and short processing time.}
}
@article{YU201691,
title = {Development of methods to improve soybean yield estimation and predict plant maturity with an unmanned aerial vehicle based platform},
journal = {Remote Sensing of Environment},
volume = {187},
pages = {91-101},
year = {2016},
issn = {0034-4257},
doi = {https://doi.org/10.1016/j.rse.2016.10.005},
url = {https://www.sciencedirect.com/science/article/pii/S0034425716303777},
author = {Neil Yu and Liujun Li and Nathan Schmitz and Lei F. Tian and Jonathan A. Greenberg and Brian W. Diers},
keywords = {Soybean, Breeding efficiency, UAV, Multispectral image, Object classification},
abstract = {Advances in phenotyping technology are critical to ensure the genetic improvement of crops meet future global demands for food and fuel. Field-based phenotyping platforms are being evaluated for their ability to deliver the necessary throughput for large scale experiments and to provide an accurate depiction of trait performance in real-world environments. We developed a dual-camera high throughput phenotyping (HTP) platform on an unmanned aerial vehicle (UAV) and collected time course multispectral images for large scale soybean [Glycine max (L.) Merr.] breeding trials. We used a supervised machine learning model (Random Forest) to measure crop geometric features and obtained high correlations with final yield in breeding populations (r=0.82). The traditional yield estimation model was significantly improved by incorporating plot row length as covariate (p<0.01). We developed a binary prediction model from time-course multispectral HTP image data and achieved over 93% accuracy in classifying soybean maturity. This prediction model was validated in an independent breeding trial with a different plot type. These results show that multispectral data collected from the UAV-based HTP platform could improve yield estimation accuracy and maturity recording efficiency in a modern soybean breeding program.}
}
@article{SHIRMARD2022112750,
title = {A review of machine learning in processing remote sensing data for mineral exploration},
journal = {Remote Sensing of Environment},
volume = {268},
pages = {112750},
year = {2022},
issn = {0034-4257},
doi = {https://doi.org/10.1016/j.rse.2021.112750},
url = {https://www.sciencedirect.com/science/article/pii/S0034425721004703},
author = {Hojat Shirmard and Ehsan Farahbakhsh and R. Dietmar Müller and Rohitash Chandra},
keywords = {Machine learning, Remote sensing, Mineral exploration, Geological mapping, Alteration mapping},
abstract = {The decline of the number of newly discovered mineral deposits and increase in demand for different minerals in recent years has led exploration geologists to look for more efficient and innovative methods for processing different data types at each stage of mineral exploration. As a primary step, various features, such as lithological units, alteration types, structures, and indicator minerals, are mapped to aid decision-making in targeting ore deposits. Different types of remote sensing datasets, such as satellite and airborne data, make it possible to overcome common problems associated with mapping geological features. The rapid increase in the volume of remote sensing data obtained from different platforms has encouraged scientists to develop advanced, innovative, and robust data processing methodologies. Machine learning methods can help process a wide range of remote sensing datasets and determine the relationship between components such as the reflectance continuum and features of interest. These methods are robust in processing spectral and ground truth measurements against noise and uncertainties. In recent years, many studies have been carried out by supplementing geological surveys with remote sensing datasets, which is now prominent in geoscience research. This paper provides a comprehensive review of the implementation and adaptation of some popular and recently established machine learning methods for processing different types of remote sensing data and investigates their applications for detecting various ore deposit types. We demonstrate the high capability of combining remote sensing data and machine learning methods for mapping different geological features that are critical for providing potential maps. Moreover, we find there is scope for advanced methods such as deep learning to process the new generation of remote sensing data that provide high spatial and spectral resolution for creating improved mineral prospectivity maps.}
}
@article{SHAKARAMI2020107496,
title = {A survey on the computation offloading approaches in mobile edge computing: A machine learning-based perspective},
journal = {Computer Networks},
volume = {182},
pages = {107496},
year = {2020},
issn = {1389-1286},
doi = {https://doi.org/10.1016/j.comnet.2020.107496},
url = {https://www.sciencedirect.com/science/article/pii/S1389128620311634},
author = {Ali Shakarami and Mostafa Ghobaei-Arani and Ali Shahidinejad},
keywords = {Computation offloading, Mobile edge computing, Machine learning, Reinforcement learning, Supervised learning, Unsupervised learning},
abstract = {With the rapid developments in emerging mobile technologies, utilizing resource-hungry mobile applications such as media processing, online Gaming, Augmented Reality (AR), and Virtual Reality (VR) play an essential role in both businesses and entertainments. To soften the burden of such complexities incurred by fast developments of such serving technologies, distributed Mobile Edge Computing (MEC) has been developed, aimed at bringing the computation environments near the end-users, usually in one hop, to reach predefined requirements. In the literature, offloading approaches are developed to connect the computation environments to mobile devices by transferring resource-hungry tasks to the near servers. Because of some rising problems such as inherent software and hardware heterogeneity, restrictions, dynamism, and stochastic behavior of the ecosystem, the computation offloading issues consider as the essential challenging problems in the MEC environment. However, to the best of the author's knowledge, in spite of its significance, in machine learning-based (ML-based) computation offloading mechanisms, there is not any systematic, comprehensive, and detailed survey in the MEC environment. In this paper, we provide a review on the ML-based computation offloading mechanisms in the MEC environment in the form of a classical taxonomy to identify the contemporary mechanisms on this crucial topic and to offer open issues as well. The proposed taxonomy is classified into three main fields: Reinforcement learning-based mechanisms, supervised learning-based mechanisms, and unsupervised learning-based mechanisms. Next, these classes are compared with each other based on the essential features such as performance metrics, case studies, utilized techniques, and evaluation tools, and their advantages and weaknesses are discussed, as well. Finally, open issues and uncovered or inadequately covered future research challenges are argued, and the survey is concluded.}
}
@article{ZHOU202056,
title = {Survey on path and view planning for UAVs},
journal = {Virtual Reality & Intelligent Hardware},
volume = {2},
number = {1},
pages = {56-69},
year = {2020},
issn = {2096-5796},
doi = {https://doi.org/10.1016/j.vrih.2019.12.004},
url = {https://www.sciencedirect.com/science/article/pii/S2096579620300073},
author = {Xiaohui Zhou and Zimu Yi and Yilin Liu and Kai Huang and Hui Huang},
keywords = {Unmanned aerial vehicle, Path planning, View panning, Multi-view reconstruction, Autonomous exploration, Scene navigation, Obstacle avoidance, Drone cinematography, Camera control},
abstract = {Background
In recent decades, unmanned aerial vehicles (UAVs) have developed rapidly and been widely applied in many domains, including photography, reconstruction, monitoring, and search and rescue. In such applications, one key issue is path and view planning, which tells UAVs exactly where to fly and how to search.
Methods
With specific consideration for three popular UAV applications (scene reconstruction, environment exploration, and aerial cinematography), we present a survey that should assist researchers in positioning and evaluating their works in the context of existing solutions.
Results
/Conclusions It should also help newcomers and practitioners in related fields quickly gain an overview of the vast literature. In addition to the current research status, we analyze and elaborate on advantages, disadvantages, and potential explorative trends for each application domain.}
}
@article{SANTOS2019354,
title = {Scene wireframes sketching for Unmanned Aerial Vehicles},
journal = {Pattern Recognition},
volume = {86},
pages = {354-367},
year = {2019},
issn = {0031-3203},
doi = {https://doi.org/10.1016/j.patcog.2018.09.017},
url = {https://www.sciencedirect.com/science/article/pii/S0031320318303443},
author = {Roi Santos and Xose M. Pardo and Xose R. Fdez-Vidal},
keywords = {3D abstraction, Reconstruction, Line-based sketching, UAV},
abstract = {This paper introduces novel insights to improve the state-of-the-art line-based unsupervised observation and abstraction models of man-made environments. The increasing use of autonomous UAVs inside buildings and around human-made structures demands new accurate and comprehensive representation of their operation environments. Most of the 3D scene abstraction methods use invariant feature point matching, nevertheless some sparse 3D point clouds do not concisely represent the structure of the environment. The presented approach is based on observation and representation models using the straight line segments. The goal of the work is a complete method based on the matching of lines, that provides a complementary approach to state-of-the-art methods when facing 3D scene representation of poor texture environments for future autonomous UAV. Oppositely to other recently published methods obtaining 3D line abstractions, the proposed method features 3D segment abstraction in the absence of a previously generated point based reconstruction. Another advantage is the ability to group the resulting 3D lines according to different planes, for exploiting coplanar line intersections. These intersections are used like feature points in the reconstruction process. It has been proved that this method exclusively based on lines can obtain spatial information in the adverse situations when a SIFT-like SfM pipeline fails to generate a dense point cloud.}
}
@article{NIU202015784,
title = {A Low-cost Soil Moisture Monitoring Method by Using Walabot and Machine Learning Algorithms},
journal = {IFAC-PapersOnLine},
volume = {53},
number = {2},
pages = {15784-15789},
year = {2020},
note = {21st IFAC World Congress},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2020.12.206},
url = {https://www.sciencedirect.com/science/article/pii/S2405896320304717},
author = {Haoyu Niu and Yanan Wang and Tiebiao Zhao and YangQuan Chen},
keywords = {Soil moisture, proximate sensing, Walabot, machine learning},
abstract = {Soil moisture plays an important role in agricultural processes, which has a significant effect on crop evapotranspiration, the exchange of water, and energy fluxes. Recently, soil moisture can be measured by remote sensing or proximate sensing techniques, such as thermal, optical, and microwave measurements. However, there are limitations to the applications of these methods, such as low spatial resolution, limited surface penetration, and vegetation. In this study, it proposed a new low-cost soil moisture monitoring method by using a Walabot sensor and machine learning algorithms. Walabot is a pocket-sized device cutting-edge technology for Radio Frequency tridimensional sensing. Unlike the remote sensing tools such as unmanned aerial vehicles (UAVs) limited by cloud cover or payload capability, the Walabot can be used flexibly in the field and provide data information more promptly and accurately than UAVs or satellite. By putting different moisture levels of soil on the Walabot, the Walabot can collect radio frequency reflectance data from different levels of soil moisture. Then, machine learning algorithms, such as principal component analysis (PCA), linear discriminant analysis (LDA), have been applied for data processing. Results showed that Walabot has a state-of-art performance in estimating soil moisture.}
}
@article{CAO2021108275,
title = {Integrating Multi-Source Data for Rice Yield Prediction across China using Machine Learning and Deep Learning Approaches},
journal = {Agricultural and Forest Meteorology},
volume = {297},
pages = {108275},
year = {2021},
issn = {0168-1923},
doi = {https://doi.org/10.1016/j.agrformet.2020.108275},
url = {https://www.sciencedirect.com/science/article/pii/S0168192320303774},
author = {Juan Cao and Zhao Zhang and Fulu Tao and Liangliang Zhang and Yuchuan Luo and Jing Zhang and Jichong Han and Jun Xie},
keywords = {Rice, Google Earth Engine (GEE), Machine Learning (ML), Deep Learning (DL), Yield prediction, Early warning system},
abstract = {Timely and reliable yield prediction at a large scale is imperative and prerequisite to prevent climate risk and ensure food security, especially with climate change and increasing extreme climate events. In this study, integrating the publicly available data (i.e., satellite vegetation indexes, meteorological indexes, and soil properties) within the Google Earth Engine (GEE) platform, we developed one Least Absolute Shrinkage and Selection Operator (LASSO) regression, one machine learning (Random Forest, RF), and one deep learning (Long Short-Term Memory Networks, LSTM) model to predict rice yield at county-level across China. For satellite data, we compared the contiguous solar-induced chlorophyll fluorescence (SIF), a newly emerging satellite retrieval, with a traditional vegetation index (enhanced vegetation index, EVI). The results showed that LSTM (with R2 ranging from 0.77 to 0.87, RMSE from 298.11 to 724kg/ha) and RF (with R2 ranging from 0.76 to 0.82, RMSE from 366 to 723.3 kg/ha) models outperformed LASSO (with R2 ranging from 0.33 to 0.42, RMSE from 633.46 kg/ha to 1231.39 kg/ha) in yield prediction; and LSTM was better than RF. Besides, ESI (combining EVI and SIF together) could slightly improve the model performance compared with only using EVI or SIF as the single input, primarily due to the ability of satellite-based SIF in capturing extra information on drought and heat stress. Furthermore, we also explored the potential for timely rice yield prediction, and concluded that the optimal prediction could be achieved with approximately two/one-month leading-time before single/double rice maturity. Our findings demonstrated a scalable, simple and inexpensive methods for timely predicting rice yield over a large area with publicly available multi-source data, which can potentially be applied to areas with sparsely observed data and worldwide for estimating crop yields.}
}
@article{GOEL2018230,
title = {Three Dimensional Path Planning for UAVs in Dynamic Environment using Glow-worm Swarm Optimization},
journal = {Procedia Computer Science},
volume = {133},
pages = {230-239},
year = {2018},
note = {International Conference on Robotics and Smart Manufacturing (RoSMa2018)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2018.07.028},
url = {https://www.sciencedirect.com/science/article/pii/S1877050918309724},
author = {Utkarsh Goel and Shubham Varshney and Anshul Jain and Saumil Maheshwari and Anupam Shukla},
keywords = {Unmanned Aerial Vehicles (UAVs), 3D-Path Planning, Dynamic Environment, Nature Inspired Algorithms, Glow-worm Swarm Optimization (GSO)},
abstract = {We propose an efficient solution for finding a collision-free path in a Three-Dimensional environment with dynamic obstacles for Unmanned Aerial Vehicles (UAVs). Path Planning for Unmanned Aerial Vehicles (UAVs) in Three Dimensional Dynamic Environment is considered a challenging task in the field of robotics. During their mission, UAVs have to maneuver in an environment which can have obstacles of varying size and random motion. The aim of the proposed algorithm is to traverse an optimal flight route in real world environment with no collision with environmental elements. This paper proposes use of a Glow-worm Swarm Optimization (GSO) for Path-Planning of Unmanned Aerial Vehicles (UAVs). It provides improved convergence rate and accuracy than the other Meta Heuristic optimization algorithms. The simulation is modelled in a real world environment. A swarm of particles is made to co-ordinate with each other for optimal path planning. The simulation is run in Python and the viability of the algorithm according to path-cost, time and number of expanded nodes is measured.}
}
@article{DEMORAIS2020104630,
title = {Vision-based robust control framework based on deep reinforcement learning applied to autonomous ground vehicles},
journal = {Control Engineering Practice},
volume = {104},
pages = {104630},
year = {2020},
issn = {0967-0661},
doi = {https://doi.org/10.1016/j.conengprac.2020.104630},
url = {https://www.sciencedirect.com/science/article/pii/S0967066120302008},
author = {Gustavo A.P. {de Morais} and Lucas B. Marcos and José Nuno A.D. Bueno and Nilo F. {de Resende} and Marco Henrique Terra and Valdir {Grassi Jr}},
keywords = {Autonomous vehicles, Vision-based lateral control, Deep Reinforcement Learning, Robust Linear Quadratic Regulator, Evolutionary Algorithm},
abstract = {Given the recent advances in computer vision, image processing and control systems, self-driving vehicles has been one of the most promising and challenging research topics nowadays. The design of vision-based robust controllers to keep an autonomous car in the center of the lane, despite uncertainties and disturbances, is still an ongoing challenge. This paper presents a hybrid control architecture that combines Deep Reinforcement Learning (DRL) and Robust Linear Quadratic Regulator (RLQR) for vision-based lateral control of an autonomous vehicle. Evolutionary estimation is used to model the vehicle uncertainties. For performance comparison, a DRL method and three other hybrid controllers are also evaluated. The inputs for each controller are real-time semantically segmented RGB camera images which serve as the basis to calculate continuous steering actions to keep the vehicle on the center of the lane with a constant velocity. Simulation results show that the proposed hybrid RLQR with evolutionary estimation of uncertainties architecture outperforms the other algorithms implemented. It presents lower tracking errors, smoother steering inputs, total collision avoidance and better generalization in new urban environments. Furthermore, it significantly decreases the required training time.}
}
@article{DAMATO2015162,
title = {Nonlinear Dynamic Inversion and Neural Networks for a Tilt Tri-Rotor UAV},
journal = {IFAC-PapersOnLine},
volume = {48},
number = {9},
pages = {162-167},
year = {2015},
note = {1st IFAC Workshop on Advanced Control and Navigation for Autonomous Aerospace Vehicles ACNAAV’15},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2015.08.077},
url = {https://www.sciencedirect.com/science/article/pii/S2405896315009441},
author = {E. D'Amato and G. {Di Francesco} and I. Notaro and G. Tartaglione and M. Mattei},
keywords = {Unmanned Aerial Vehicle, Flight Control, Nonlinear Dynamic Inversion, Neural Networks, Adaptive Control},
abstract = {A small scale tri-rotor test bed with tilting propellers has been built to test flight control laws in view of the construction of a larger tilt rotor UAV. As a first step to achieve autonomous flight capabilities, a nonlinear dynamic inversion based flight controller is developed. This controller is designed on the basis of a time-scale principle with two levels. A lower level, fast control action, designed to achieve attitude control and stability goals, is driven by a higher level trajectory tracking control law. To achieve robust stability and performance in the presence of parametric variations and modelling uncertainties, an adaptive flight control law correction based on neural networks is investigated. A RBF neural network is implemented to mitigate the effects of imprecise inverse dynamics. The overall proposed flight controller performance are tested via numerical simulations on the mathematical model of the small scale tri-rotor. Preliminary results on the full tilt rotor are also shown.}
}
@article{SEO202015852,
title = {Soil Moisture Retrieval from Airborne Multispectral and Infrared Images using Convolutional Neural Network⁎⁎This work was supported by Science and Technology Facilities Council (STFC) under Newton fund with grant number ST/N006852/1.},
journal = {IFAC-PapersOnLine},
volume = {53},
number = {2},
pages = {15852-15857},
year = {2020},
note = {21st IFAC World Congress},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2020.12.240},
url = {https://www.sciencedirect.com/science/article/pii/S2405896320305152},
author = {Min-Guk Seo and Hyo-Sang Shin and Antonios Tsourdos},
keywords = {Remote Sensing, Sensor Fusion, Convolutional Neural Network, Soil Moisture Retrieval},
abstract = {This paper deals with the modeling of soil moisture retrieval from multispectral and infrared (IR) images using convolutional neural network (CNN). Since it is difficult to measure the soil moisture level of large fields, it is essential to retrieve soil moisture level from remotely sensed data. Quadrotor unmanned aerial vehicle (UAV) is considered as sensing platform in order to acquire data with high spatial resolution at anytime by non-experts. With considerations both on the availability of sensors for the platform and the information needed to overcome the effects of the canopies covering soil, IR and multispectral images are selected to be used for soil moisture retrieval. In order to prevent information loss by the calculation of parameters from measurements and enhance the applicabiliy for online operations, CNN is applied for the construction of soil moisture retrieval model to use the sensor measurement images directly as input data. Training and testing are conducted for the proposed CNN-based soil moisture retrieval model using the data from actual quadrotor flight over an agricultural field.}
}
@article{TANG2021101381,
title = {Battery-constrained federated edge learning in UAV-enabled IoT for B5G/6G networks},
journal = {Physical Communication},
volume = {47},
pages = {101381},
year = {2021},
issn = {1874-4907},
doi = {https://doi.org/10.1016/j.phycom.2021.101381},
url = {https://www.sciencedirect.com/science/article/pii/S187449072100118X},
author = {Shunpu Tang and Wenqi Zhou and Lunyuan Chen and Lijia Lai and Junjuan Xia and Liseng Fan},
keywords = {UAV, Federated learning, Latency, Energy consumption, Mobile edge computing},
abstract = {In this paper, we investigate how to optimize the federated edge learning (FEEL) in unmanned aerial vehicle (UAV)-enabled Internet of Things (IoT) for B5G/6G networks. Federated learning is an effective framework to train a shared model between decentralized edge devices and servers without exchanging raw data, which helps protecting data privacy. In UAV-enabled IoT networks, latency and energy consumption are two important metrics limiting the performance of FEEL. Although most of the existing works have studied how to reduce latency and improve energy efficiency, only few of them have investigated the impact of the devices’ limited batteries on FEEL. Motivated by this, we study the battery-constrained FEEL, where the UAVs can adjust their operating CPU-frequencies to prolong battery life and avoid dropping from federated learning training untimely. We optimize the system by jointly allocating the computational resources and wireless bandwidth in time-varying environments based on a deep deterministic policy gradient (DDPG) based strategy, where a linear combination of latency and energy consumption is used to evaluate the system cost. In this end, simulation results are demonstrated to show that the proposed strategy outperforms the conventional ones. In particular, it enables all the devices to complete all rounds of FEEL with limited batteries, and reduce the system cost effectively in the meantime.}
}
@article{ROMERO2018109,
title = {Vineyard water status estimation using multispectral imagery from an UAV platform and machine learning algorithms for irrigation scheduling management},
journal = {Computers and Electronics in Agriculture},
volume = {147},
pages = {109-117},
year = {2018},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2018.02.013},
url = {https://www.sciencedirect.com/science/article/pii/S0168169917315533},
author = {Maria Romero and Yuchen Luo and Baofeng Su and Sigfredo Fuentes},
keywords = {Remote sensing, Stem water potential, Artificial neural networks, Unmanned aerial vehicle, Water stress},
abstract = {Remote sensing can provide a fast and reliable alternative for traditional in situ water status measurement in vineyards. Several vegetation indices (VIs) derived from aerial multispectral imagery were tested to estimate midday stem water potential (Ψstem) of grapevines. The experimental trial was carried out in a vineyard in the Shangri-La region, located in Yunnan province in China. Statistical methods and machine learning algorithms were used to evaluate the correlations between Ψstem and VIs. Results by simple regression between VIs individually and Ψstem showed no significant relationships, with coefficient of determination (R2) for linear fitting smaller than 0.3 for almost all the indices studied, except for the Optimal Soil Adjusted Vegetation Index (OSAVI); R2 = 0.42 with statistical significance (p ≤ 0.001). However, results from a model obtained by fitting using Artificial Neural Network (ANN), using all VIs calculated as inputs and real Ψstem from plants within the study site (n = 90) as targets (Model 1), showed high correlation between the estimated water potential through ANN (Ψstem ANN) and the actual measured Ψstem. Training, validation and testing data sets presented individual correlations of R = 0.8, 0.72 and 0.62 respectively. The models obtained from the study site were then applied to a wider area from the vineyard studied and compared to further Ψstem measured obtained from different sites (n = 23) showing high correlation values between Ψstem ANN and real Ψstem (R2 = 0.83; slope = 1; p ≤ 0.001). Finally, a pattern recognition ANN model (Model 2) was developed for irrigation scheduling purposes using the same Ψstem measured in the study site as inputs and with the following thresholds as outputs: Ψstem below −1.2 MPa considered as severe water stress (SS), Ψstem between −0.8 to −1.2 MPa as moderate stress (MS) and Ψstem over −0.8 MPa with no water stress (NS). This model can be applied to analyze on a plant by plant basis to identify sectors of stress within the vineyard for optimal irrigation management and to identify spatial variability within the vineyards.}
}
@article{MIYANO2020100205,
title = {Multi-UAV Allocation Framework for Predictive Crime Deterrence and Data Acquisition},
journal = {Internet of Things},
volume = {11},
pages = {100205},
year = {2020},
issn = {2542-6605},
doi = {https://doi.org/10.1016/j.iot.2020.100205},
url = {https://www.sciencedirect.com/science/article/pii/S254266052030041X},
author = {Kosei Miyano and Ryoichi Shinkuma and Narushige Shiode and Shino Shiode and Takehiro Sato and Eiji Oki},
keywords = {unmanned aerial vehicle, surveillance, crime prediction, crime deterrence, sensor data acquisition, machine learning},
abstract = {The recent decline in the number of police and security force personnel has raised a serious security issue that could lead to reduced public safety and delayed response to crimes in urban areas. This may be alleviated in part by utilizing micro or small unmanned aerial vehicles (UAVs) and their high-mobility on-board sensors in conjunction with machine-learning techniques such as neural networks to offer better performance in predicting times and places that are high-risk and deterring crimes. The key to the success of such operation lies in the suitable placement of UAVs. This paper proposes a multi-UAV allocation framework for predictive crime deterrence and data acquisition that consists of the overarching methodology, a problem formulation, and an allocation method that work with a prediction model using a machine learning approach. In contrast to previous studies, our framework provides the most effective arrangement of UAVs for maximizing the chance to apprehend offenders whilst also acquiring data that will help improve the performance of subsequent crime prediction. This paper presents the system architecture assumed in this study, followed by a detailed description of the methodology, the formulation of the problem, and the UAV allocation method of the proposed framework. Our framework is tested using a real-world crime dataset to evaluate its performance with respect to the expected number of crimes deterred by the UAV patrol. Furthermore, to address the engineering practice of the proposed framework, we discuss the feasibility of the simulated deployment scenario in terms of energy consumption and the relationship between data analysis and crime prediction.}
}
@article{GUAN2021106987,
title = {UAV-lidar aids automatic intelligent powerline inspection},
journal = {International Journal of Electrical Power & Energy Systems},
volume = {130},
pages = {106987},
year = {2021},
issn = {0142-0615},
doi = {https://doi.org/10.1016/j.ijepes.2021.106987},
url = {https://www.sciencedirect.com/science/article/pii/S0142061521002271},
author = {Hongcan Guan and Xiliang Sun and Yanjun Su and Tianyu Hu and Haitao Wang and Heping Wang and Chigang Peng and Qinghua Guo},
keywords = {Powerline inspection, Intelligent, Unmanned aerial vehicle, Deep learning, Lidar},
abstract = {In recent decades, a substantial increase in electricity demand has put pressure on powerline systems to ensure an uninterrupted power supply. In order to prevent power failures, timely and thorough powerline inspections are needed to detect possible anomalies in advance. In the past few years, the emerging unmanned aerial vehicle (UAV)-mounted sensors (e.g. light detection and ranging/lidar, optical cameras, infrared cameras, and ultraviolet cameras) have provided rich data sources for comprehensive and accurate powerline inspections. A challenge that still hinders the use of UAVs in powerline inspection is that their operation is highly dependent on the pilot’s experience, which may pose risks to the safety of the powerline system and reduce inspection efficiency. An intelligent automatic inspection solution could overcome the limitations of current UAV-based inspection solutions. The main objective of this paper is to provide a contemporary look at the current state-of-the-art UAV-based inspections as well as to discuss a potential lidar-supported intelligent powerline inspection concept. Overall, standardized protocols for lidar-supported intelligent powerline inspections include four data analysis steps, i.e., point cloud classification, key point extraction, route generation, and fault detection. To demonstrate the feasibility of the proposed concept, we implemented a workflow using a dataset of 3536 powerline spans, showing that the inspection of a single powerline span could be completed in 10 min with only one or two technicians. This demonstrates that lidar-supported intelligent inspection can be used to inspect a powerline system with extremely high efficiency and low costs.}
}
@article{MADHUANAND20211,
title = {Self-supervised monocular depth estimation from oblique UAV videos},
journal = {ISPRS Journal of Photogrammetry and Remote Sensing},
volume = {176},
pages = {1-14},
year = {2021},
issn = {0924-2716},
doi = {https://doi.org/10.1016/j.isprsjprs.2021.03.024},
url = {https://www.sciencedirect.com/science/article/pii/S0924271621000952},
author = {Logambal Madhuanand and Francesco Nex and Michael Ying Yang},
keywords = {Depth estimation, Monocular, UAV video, Self-supervised learning, Scene Understanding},
abstract = {Unmanned Aerial Vehicles (UAVs) have become an essential photogrammetric measurement as they are affordable, easily accessible and versatile. Aerial images captured from UAVs have applications in small and large scale texture mapping, 3D modelling, object detection tasks, Digital Terrain Model (DTM) and Digital Surface Model (DSM) generation etc. Photogrammetric techniques are routinely used for 3D reconstruction from UAV images where multiple images of the same scene are acquired. Developments in computer vision and deep learning techniques have made Single Image Depth Estimation (SIDE) a field of intense research. Using SIDE techniques on UAV images can overcome the need for multiple images for 3D reconstruction. This paper aims to estimate depth from a single UAV aerial image using deep learning. We follow a self-supervised learning approach, Self-Supervised Monocular Depth Estimation (SMDE), which does not need ground truth depth or any extra information other than images for learning to estimate depth. Monocular video frames are used for training the deep learning model which learns depth and pose information jointly through two different networks, one each for depth and pose. The predicted depth and pose are used to reconstruct one image from the viewpoint of another image utilising the temporal information from videos. We propose a novel architecture with two 2D Convolutional Neural Network (CNN) encoders and a 3D CNN decoder for extracting information from consecutive temporal frames. A contrastive loss term is introduced for improving the quality of image generation. Our experiments are carried out on the public UAVid video dataset. The experimental results demonstrate that our model outperforms the state-of-the-art methods in estimating the depths.}
}
@article{RAMEZANIDOORAKI2021103671,
title = {An innovative bio-inspired flight controller for quad-rotor drones: Quad-rotor drone learning to fly using reinforcement learning},
journal = {Robotics and Autonomous Systems},
volume = {135},
pages = {103671},
year = {2021},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2020.103671},
url = {https://www.sciencedirect.com/science/article/pii/S092188902030511X},
author = {Amir {Ramezani Dooraki} and Deok-Jin Lee},
keywords = {Reinforcement learning, Autonomous system, Bio-inspired artificial intelligence, Policy optimization, Artificial neural network, Bio-inspired controller, Machine learning},
abstract = {Animals learn to master their capabilities by trial and error, and with out having any knowledge about their dynamics model and mathematical or physical rules. They use their maximum capabilities in an optimized way. This is the result of millions of years of evolution where the best of different possibilities are kept, and makes us rethink How does the nature perform things?, particularly when natural systems outperform our rigid systems. In this study, inspired by the nature, we developed an innovative algorithm by enhancing an existing reinforcement learning algorithm (proximal policy optimization (PPO)). Our algorithm is capable of learning to control a quad-rotor drone in order to fly. This new algorithm called Bio-inspired Flight Controller (BFC) does not use any conventional controller such as PID or MPC to control the quad-rotor drone. The goal of BFC is to completely replace the conventional controller with a controller that acts in a similar way to the animals where they learn to control their movements. It is capable of stabilizing a quad-copter in a desired point, and following way points. We implemented our algorithm in an AscTec Hummingbird quad-copter simulated in Gazebo, and tested it using different scenarios to fully measure its capabilities.}
}
@article{SUN2018336,
title = {Robust fuzzy tracking control of a quad-rotor unmanned aerial vehicle based on sector linearization and interval matrix approaches},
journal = {ISA Transactions},
volume = {80},
pages = {336-349},
year = {2018},
issn = {0019-0578},
doi = {https://doi.org/10.1016/j.isatra.2018.07.034},
url = {https://www.sciencedirect.com/science/article/pii/S0019057818302878},
author = {Miaoping Sun and Jingjing Liu and Haibo Wang and Xiaohong Nian and Hongyun Xiong},
keywords = {Quad-rotor UAV, T-S fuzzy error model, Sector linearization, Interval matrix, Exponential stability},
abstract = {In this paper, the robust H∞ fuzzy tracking control strategy for a quad-rotor unmanned aerial vehicle (UAV) with strong coupling and highly nonlinear is put forward based on the Takagi-Sugeno(T-S) fuzzy error model. Firstly, the quad-rotor UAV system is divided into altitude subsystem, position subsystem and attitude subsystem. Through selecting appropriate premise variables, three T-S fuzzy error models, which are equivalent to the error dynamic model, are established by the sector linearization approach. Next, the uncertainties in drag coefficients, moments of inertia are taken into account, and the interval matrix is introduced to describe them in altitude, position and attitude T-S fuzzy error models. Then the robust H∞ fuzzy feedback controllers are designed to stabilize T-S fuzzy subsystems. Besides, according to the Lyapunov stability theorem, it is obtained that the LMI sufficient conditions of exponential stability with the prescribed H∞ performance for T-S fuzzy closed-loop subsystems. Meanwhile, the method for solving the gain matrices of controller is presented. Finally, simulation results are given to demonstrate the effectiveness, robustness and advantages of the proposed method. Then the feasibility of the proposed method is further verified by experimental results.}
}
@article{XIA2022103992,
title = {Automated semantic segmentation of bridge point cloud based on local descriptor and machine learning},
journal = {Automation in Construction},
volume = {133},
pages = {103992},
year = {2022},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2021.103992},
url = {https://www.sciencedirect.com/science/article/pii/S092658052100443X},
author = {Tian Xia and Jian Yang and Long Chen},
keywords = {Bridge information model, Semantic segmentation, Local descriptor, Machine learning, Point cloud},
abstract = {In recent years, monitoring the health condition of existing bridges has become a common requirement. By providing an information management system, Bridge Information Model (BrIM) can highly improve the efficiency of health inspection and the reliability of condition evaluation. However, the current modeling processes still largely rely on manual work, where the cost outweighs the benefits. The main barrier lies in the challenging step of semantic segmentation of point clouds. Efforts have been made to identify and segment the structural components of bridges in existing research. But these methods are either dependent on manual data preprocessing or need big training dataset, which, however, has rendered them unpractical in real-world applications. This paper presents a combined local descriptor and machine learning based method to automatically detect structural components of bridges from point clouds. Based on the geometrical features of bridges, we design a multi-scale local descriptor, which is then used to train a deep classification neural network. In the end, a result refinement algorithm is adopted to optimize the segmentation results. Experiments on real-world reinforced concrete (RC) slab and beam-slab bridges show an average precision of 97.26%, recall of 98.00%, and intersection over union (IoU) of 95.38%, which significantly outperforms PointNet. This method has provided a potential solution to semantic segmentation of infrastructures by small sample learning and will contribute to the fulfillment of the automatic BrIM generation of typical highway bridges from the point cloud in the future.}
}
@article{SONG2017242,
title = {Adaptive compensation control for attitude adjustment of quad-rotor unmanned aerial vehicle},
journal = {ISA Transactions},
volume = {69},
pages = {242-255},
year = {2017},
issn = {0019-0578},
doi = {https://doi.org/10.1016/j.isatra.2017.04.003},
url = {https://www.sciencedirect.com/science/article/pii/S0019057817303749},
author = {Zhankui Song and Kaibiao Sun},
keywords = {Compensation control, Back-stepping, Prescribed performance characteristic, QR-UAV},
abstract = {A compensation control strategy based on adaptive back-stepping technique is presented to address the problem of attitude adjustment for a quad-rotor unmanned aerial vehicle (QR- UAV) with inertia parameter uncertainties, the limited airflow disturbance and the partial loss of rotation speed effectiveness. In the design process of control system, adaptive estimation technique is introduced into the closed loop system in order to compensate the lumped disturbance term. More specifically, the designed controller utilizes “prescribed performance bounds” method, and therefore guarantees the transient performance of tracking errors, even in the presence of the lumped disturbance. Adaptive compensation algorithms under the proposed closed loop system structure are derived in the sense of Lyapunov stability analysis such that the attitude tracking error converge to a small neighborhood of equilibrium point. Finally, the simulation results demonstrate the effectiveness of the proposed controller.}
}
@article{MA2020105159,
title = {Segmenting ears of winter wheat at flowering stage using digital images and deep learning},
journal = {Computers and Electronics in Agriculture},
volume = {168},
pages = {105159},
year = {2020},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2019.105159},
url = {https://www.sciencedirect.com/science/article/pii/S0168169919313845},
author = {Juncheng Ma and Yunxia Li and Keming Du and Feixiang Zheng and Lingxian Zhang and Zhihong Gong and Weihua Jiao},
keywords = {Ears of winter wheat, RGB images, Deep convolutional neural network, Fully convolutional network, Segmentation},
abstract = {Segmenting ears of winter wheat from canopy images was considered to be an important procedure prior to the extraction of related traits. Current segmentation method based on computer vision was susceptible to noise, which is limited in practical applications. In this study, a two-stage segmentation method for ears of winter wheat based on digital images of unit ground area and the state-of-the-art deep learning techniques was proposed. In the coarse segmentation stage, a deep convolutional neural network (DCNN) was constructed to classify the superpixels generated by entropy rate superpixel algorithm, achieving the coarse results. In the fine segmentation stage, a fully convolutional network (FCN) allowing pixel-wise semantic segmentation was constructed to eliminate the non-ear pixels in the coarse results. To compare the results of the proposed two-stage segmentation method, conventionally adopted methods for image segmentation were used. Results showed that the proposed two-stage segmentation method was able to accurately segmenting ears of winter wheat from canopy images captured at flowering stage (Qseg = 0.7197, F1 score = 83.70%, SSIM = 0.8605), outperforming the other compared methods. Generalization tests were conducted to evaluate the utility of the proposed two-stage segmentation method. Results showed that the two-stage segmentation method was still capable of accurately segmenting ears of winter wheat, even though the performance slightly decreased. Change of winter wheat cultivar and lack of descriptive information were two factors that could degrade the performance of the two-stage segmentation method. Tests of the methods on Unmanned Aerial Vehicle (UAV) based RGB images showed the Fully Convolutional Network stride 8 predictions (FCN-8s) had a good chance to achieve satisfactory performances on UAV based canopy images.}
}
@article{WANG20215562,
title = {A critical review of improved deep learning methods for the remaining useful life prediction of lithium-ion batteries},
journal = {Energy Reports},
volume = {7},
pages = {5562-5574},
year = {2021},
issn = {2352-4847},
doi = {https://doi.org/10.1016/j.egyr.2021.08.182},
url = {https://www.sciencedirect.com/science/article/pii/S235248472100785X},
author = {Shunli Wang and Siyu Jin and Dekui Bai and Yongcun Fan and Haotian Shi and Carlos Fernandez},
keywords = {Lithium-ion battery, Remaining useful life prediction, Deep learning, Deep convolutional neural network, Long short term memory, Recurrent neural network},
abstract = {As widely used for secondary energy storage, lithium-ion batteries have become the core component of the power supply system and accurate remaining useful life prediction is the key to ensure its reliability. Because of the complex working characteristics of lithium-ion batteries as well as the model parameter changing along with the aging process, the accuracy of the online remaining useful life prediction is difficult but urgent to be improved for the reliable power supply application. The deep learning algorithm improves the accuracy of the remaining useful life prediction, which also reduces the characteristic testing time requirement, providing the possibility to improve the power profitability of predictive energy management. This article analyzes, reviews, classifies, and compares different adaptive mathematical models on deep learning algorithms for the remaining useful life prediction. The features are identified for the modeling ability, according to which the adaptive prediction methods are classified. The specific criteria are defined to evaluate different modeling accuracy in the deep learning calculation procedure. The key features of effective life prediction are used to draw relevant conclusions and suggestions are provided, in which the high-accuracy deep convolutional neural network — extreme learning machine algorithm is chosen to be utilized for the stable remaining useful life prediction of lithium-ion batteries.}
}
@article{LI2022,
title = {Deep learning driven physical layer security for a simultaneously wireless information and power transfer network},
journal = {Alexandria Engineering Journal},
year = {2022},
issn = {1110-0168},
doi = {https://doi.org/10.1016/j.aej.2021.12.047},
url = {https://www.sciencedirect.com/science/article/pii/S1110016821008577},
author = {Junxia Li and Hui Zhao and Yiyun Huang and Miao Zhang and Sujesh P Lal},
keywords = {Deep neural network (DNN), Simultaneously wireless information and power transfer (SWIPT), Resource allocation, Physical layer security, Secrecy rate optimization},
abstract = {Artificial intelligent approaches have been considered as the promising techniques to enable smart communications in future wireless networks. In this paper, we investigate the deep learning based resource allocation approach for secure transmission in a simultaneously wireless information and power transfer (SWIPT) network. In particular, we design the resource allocations to maximize the minimum achievable secrecy rate of the legitimate user under the constraints of energy harvesting requirements of the energy receivers (ERs). Conventionally, the optimal or suboptimal solutions of resource allocation problems can be obtained by exploiting convex optimization approaches, which are often developed based on iterative algorithms, and always result in long computational time. To satisfy ultra low latency demands and achieve physical layer security for future SWIPT systems, we develop a DNN based approach that has the capability to optimize the power allocations for a SWIPT network, where the computational time and complexity have been significantly cut down. Numerical results are provided to illustrate that the effectiveness of our proposed DNN based approach, which is capable to achieve near optimal secrecy rate performances in comparing with convex optimization approach.}
}
@article{YU20202471,
title = {Optimal UAV Circumnavigation Control with Input Saturation Based on Information Geometry},
journal = {IFAC-PapersOnLine},
volume = {53},
number = {2},
pages = {2471-2476},
year = {2020},
note = {21st IFAC World Congress},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2020.12.196},
url = {https://www.sciencedirect.com/science/article/pii/S2405896320304614},
author = {Yangguang Yu and Xiangke Wang and Lincheng Shen},
keywords = {UAV, optimal control, Fisher information, circumnavigation, input saturation},
abstract = {In this paper, we investigate the problem of the optimal circumnavigation around a ground moving target for a fixed-wing unmanned aerial vehicle equipped with a radar. We propose an optimal circumnavigation control law which not only achieves the circumnavigation of a UAV around a moving target, but also maximizes the utilization of the sensor information. Firstly, an optimization criterion reflecting the extent of the sensor information utilization is established based on the Fisher information. Then, based on a neural network, an optimal circumnavigation control law with input saturation is designed. The result is a nearly optimal state feedback controller that has been tuned a priori off-line. Finally, a simulation is presented to demonstrate the validity and correctness of the proposed method.}
}
@article{SARWAR2021106219,
title = {Detecting sheep in UAV images},
journal = {Computers and Electronics in Agriculture},
volume = {187},
pages = {106219},
year = {2021},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2021.106219},
url = {https://www.sciencedirect.com/science/article/pii/S0168169921002362},
author = {Farah Sarwar and Anthony Griffin and Saeed Ur Rehman and Timotius Pasang},
keywords = {Deep learning, Object detection, Livestock, UAV},
abstract = {In the last decade, researchers have focused more on deep convolutional neural networks (CNNs) than other machine learning algorithms for object detection, localization, classification and segmentation. Such CNNs have achieved remarkable results in these fields and use the bounding boxes as the ground truth data. In this research article, we have used a fully connected network (FCN) for livestock detection in aerial images captured by an unmanned aerial vehicle (UAV), that used centroids as ground truth data. For performance evaluation and comparison, we have proposed a single-layered and a seven-layered CNN network in this article. These proposed networks are trained using state-of-the-art method, Region-based CNN. In addition, AlexNet, GoogLeNet, VGG16, VGG19 and ResNet50 were also fine-tuned for livestock detection. The results of the FCN and one of our proposed networks are then merged to improve the recall of the complete system from 90% to 98%.}
}
@article{WANG2016294,
title = {Detecting and tracking vehicles in traffic by unmanned aerial vehicles},
journal = {Automation in Construction},
volume = {72},
pages = {294-308},
year = {2016},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2016.05.008},
url = {https://www.sciencedirect.com/science/article/pii/S0926580516300887},
author = {Liang Wang and Fangliang Chen and Huiming Yin},
keywords = {Unmanned aerial vehicle (UAV), Vehicle detection, Vehicle tracking, Traffic data, Optical flow, Scale invariant feature transform (SIFT)},
abstract = {Using unmanned aerial vehicles (UAV) as devices for traffic data collection exhibits many advantages in collecting traffic information. This paper introduces a new vehicle detecting and tracking system based on image data collected by UAV. This system uses consecutive frames to generate vehicle's dynamic information, such as positions and velocities. Four major modules have been developed: image registration, image feature extraction, vehicle shape detecting, and vehicle tracking. Some unique features have been introduced into this system to customize the vehicle and traffic flow and to jointly use them in multiple consecutive images to increase the system accuracy of detecting and tracking vehicles. Field tests demonstrate that the present system exhibits high accuracy in traffic information acquisition at different UAV altitudes with different view scopes, which can be used in future traffic monitoring and control in metropolitan areas.}
}
@article{GARILLI2021103477,
title = {Automatic detection of stone pavement's pattern based on UAV photogrammetry},
journal = {Automation in Construction},
volume = {122},
pages = {103477},
year = {2021},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2020.103477},
url = {https://www.sciencedirect.com/science/article/pii/S0926580520310578},
author = {Erika Garilli and Nazarena Bruno and Federico Autelitano and Riccardo Roncella and Felice Giuliani},
keywords = {Pavement management system, Stone pavement, Segmental pavement, Automatic classification, Deep learning, Convolutional neural network},
abstract = {Pavement management system (PMS) is a set of tools that assist road agencies in finding optimal strategies for maintaining pavements in a serviceable condition over a period of time. Usually, municipalities base their PMS on the deterioration monitoring through a visual survey but the distresses identification is complex and the operations are based on visual and instrumental inspections. As regards natural stone pavements, which are very widespread in the road heritage of cities, in literature there are very few studies. The authors analyzed two supervised classification approaches (Semi-Automatic Classification Plugin for QGIS and a Convolutional Neural Network (CNN)), based on Unmanned Aerial Vehicle (UAV) photogrammetry, to detect stone pavement's pattern. This study showed that using a U-Net CNN on images obtained from UAV is an excellent alternative to the traditional manual inspection and can be implemented for other types of stone pavements, also with the aim of distress identification.}
}
@article{LIU20141273,
title = {Fuzzy adaptive tracking control within the full envelope for an unmanned aerial vehicle},
journal = {Chinese Journal of Aeronautics},
volume = {27},
number = {5},
pages = {1273-1287},
year = {2014},
issn = {1000-9361},
doi = {https://doi.org/10.1016/j.cja.2014.08.012},
url = {https://www.sciencedirect.com/science/article/pii/S1000936114001381},
author = {Zhi Liu and Yong Wang},
keywords = {Flight control systems, Full flight envelope, Fuzzy adaptive tracking control, Fuzzy multiple Lyapunov function, Fuzzy T–S model, Single hidden layer neural network},
abstract = {Motivated by the autopilot of an unmanned aerial vehicle (UAV) with a wide flight envelope span experiencing large parametric variations in the presence of uncertainties, a fuzzy adaptive tracking controller (FATC) is proposed. The controller consists of a fuzzy baseline controller and an adaptive increment, and the main highlight is that the fuzzy baseline controller and adaptation laws are both based on the fuzzy multiple Lyapunov function approach, which helps to reduce the conservatism for the large envelope and guarantees satisfactory tracking performances with strong robustness simultaneously within the whole envelope. The constraint condition of the fuzzy baseline controller is provided in the form of linear matrix inequality (LMI), and it specifies the satisfactory tracking performances in the absence of uncertainties. The adaptive increment ensures the uniformly ultimately bounded (UUB) predication errors to recover satisfactory responses in the presence of uncertainties. Simulation results show that the proposed controller helps to achieve high-accuracy tracking of airspeed and altitude desirable commands with strong robustness to uncertainties throughout the entire flight envelope.}
}
@article{WU2020105504,
title = {Extracting apple tree crown information from remote imagery using deep learning},
journal = {Computers and Electronics in Agriculture},
volume = {174},
pages = {105504},
year = {2020},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2020.105504},
url = {https://www.sciencedirect.com/science/article/pii/S0168169920301605},
author = {Jintao Wu and Guijun Yang and Hao Yang and Yaohui Zhu and Zhenhai Li and Lei Lei and Chunjiang Zhao},
keywords = {UAV, Apple tree, Deep learning, Computer vision, Detection, Segmentation},
abstract = {Manual measurement and visual inspection is a common practice for acquiring crop data in orchards and is a labor-intensive, time-consuming, and costly task. Accurate and rapid acquisition of crop data is vital for monitoring the dynamics of tree growth and optimizing farm management. In this work, we present a technique for orchard data acquisition and analysis that uses remote imagery acquired from unmanned aerial vehicles (UAVs) combined with deep learning convolutional neural networks to automatically detect and segment individual trees and measure the crown width, perimeter, and crown projection area of apple trees. By using an UAV platform, 50 high-resolution images of apple trees were collected from an orchard during dormancy (bare branches), and then each apple tree was detected by using a Faster R-CNN object detector. Based on these results, each tree was segmented by using a U-Net deep learning network. After convex tree boundaries were extracted from the semantic segmentation results by using an efficient pruning strategy, the crown parameters were automatically calculated, and the accuracy was compared with that obtained by manual delineation. The results show that the proposed remote sensing technique can be used to detect and count apple trees with precision and recall of 91.1% and 94.1%, respectively, segment their branches with an overall accuracy of 97.1%, and estimate crown parameter with an overall accuracy exceeding 92%. We conclude that this method not only saves labor by avoiding field measurements but also allows growers to dynamically monitor the growth of orchard trees.}
}
@article{SAMBASIVAM202127,
title = {A predictive machine learning application in agriculture: Cassava disease detection and classification with imbalanced dataset using convolutional neural networks},
journal = {Egyptian Informatics Journal},
volume = {22},
number = {1},
pages = {27-34},
year = {2021},
issn = {1110-8665},
doi = {https://doi.org/10.1016/j.eij.2020.02.007},
url = {https://www.sciencedirect.com/science/article/pii/S1110866520301110},
author = {G. Sambasivam and Geoffrey Duncan Opiyo},
keywords = {Agriculture, Cassava mosaic detection, Rectifier Linear Unit, Synthetic minority over-sampling technique, Stochastic gradient descent},
abstract = {This work is inspired by Kaggle competition which was part of the Fine-Grained Visual Categorization workshop at CVPR 2019 (Conference on Computer Vision and Pattern Recognition) we participated in. It aimed at detecting cassava diseases using 5 fine-grained cassava leaf disease categories with 10,000, labeled images collected during a regular survey in Uganda. Traditionally, this detection is done mostly through physical inspection and supervision of cassava plants in the garden by farmers or agricultural extension workers from NAADS (National Agricultural Advisory Services) and then reported to NARO (National Agricultural Advisory Services) for further analysis. However, this can be tiresome, capital intensive, and lacks the ability to detect cassava infection timely to help farmers apply preventive techniques to the non-infected cassava plants in order to improve on yields which subsequently increases African food basket leading to food security which fights famine. Using the dataset provided to train CNNs (Convolutional Neural Networks) to achieve high accuracy was very challenging due to two reasons: the dataset was small in size and has high-class imbalance being heavily biased towards CMD (Cassava Mosaic Disease) and CBB (Cassava Brown Streak Virus Disease) classes. Class imbalance is problematic in machine learning and exists in many domains. Note that, not all world data is balanced, in fact, most of the time you will not be extremely lucky to get a perfectly balanced real-world dataset, in recent years, a lot of research has been done for two-class problems such as fraudulent credit card and tumor detection among others. Interestingly, class imbalance in multi-class image datasets has received little attention. This paper, therefore, focused on techniques to achieve an accuracy score of over 93% with class weight, SMOTE (Synthetic Minority Over-sampling Technique) and focal loss with deep convolutional neural networks from scratch. The goal was to counter high-class imbalance so that the model can accurately predict underrepresented classes.}
}
@article{FRAVOLINI2010288,
title = {LMI-based design of a Neuro-Adaptive augmentation controller for an Unmanned Aerial Vehicle},
journal = {IFAC Proceedings Volumes},
volume = {43},
number = {16},
pages = {288-293},
year = {2010},
note = {7th IFAC Symposium on Intelligent Autonomous Vehicles},
issn = {1474-6670},
doi = {https://doi.org/10.3182/20100906-3-IT-2019.00051},
url = {https://www.sciencedirect.com/science/article/pii/S1474667016350716},
author = {M.L. Fravolini and S. Fiani and G. Campa},
keywords = {, , , , , },
abstract = {This paper presents a practical approach for verifying worst-case tracking performance of neuro-adaptive systems in presence of bounded uncertainties. Boundedness of the tracking error vector within an a-priori specified compact domain is obtained by applying robust invariant set analysis to the uncertain linear plant where the uncertainty and Neural Network (NN) reconstruction error are considered as norm bounded persistent uncertainties. In this framework it was possible to specify worst-case tracking error requirements via a set of LMIs and to systematically verify the specifications using a numerical LMI solver. The presented method was applied to the performance verification of an adaptive augmentation controller for the short term dynamics of an UAV model.}
}
@article{YUN20211,
title = {Distributed deep reinforcement learning for autonomous aerial eVTOL mobility in drone taxi applications},
journal = {ICT Express},
volume = {7},
number = {1},
pages = {1-4},
year = {2021},
issn = {2405-9595},
doi = {https://doi.org/10.1016/j.icte.2021.01.005},
url = {https://www.sciencedirect.com/science/article/pii/S2405959521000059},
author = {Won Joon Yun and Soyi Jung and Joongheon Kim and Jae-Hyun Kim},
keywords = {eVTOL, Drone taxi, Air taxi, Distributed deep reinforcement learning, Urban aerial mobility},
abstract = {The urban aerial mobility (UAM) system, such as drone taxi or air taxi, is one of future on-demand transportation networks. Among them, electric vertical takeoff and landing (eVTOL) is one of UAM systems that is for identifying the locations of passengers, flying to the positions where the passengers are located, loading the passengers, and delivering the passengers to their destinations. In this paper, we propose a distributed deep reinforcement learning where the agents are formulated as eVTOL vehicles that can compute the optimal passenger transportation routes under the consideration of passenger behaviors, collisions among eVTOL, and eVTOL battery status.}
}
@article{PASSALIS201937,
title = {Deep reinforcement learning for controlling frontal person close-up shooting},
journal = {Neurocomputing},
volume = {335},
pages = {37-47},
year = {2019},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2019.01.046},
url = {https://www.sciencedirect.com/science/article/pii/S0925231219300724},
author = {Nikolaos Passalis and Anastasios Tefas},
keywords = {Reinforcement learning, Deep learning, Drone-based cinematography},
abstract = {Drones, also known as Unmanned Aerial Vehicles, are capable of capturing spectacular aerial shots and can be used to aid several cinematography-oriented tasks. However, flying drones in a professional setting requires the cooperation of several people, increasing the production cost and possibly reducing the quality of the obtained shots. In this paper, a generic way for formulating cinematography-oriented control objectives, that can be used for training any RL agent to automate the drone and camera control processes, is proposed. To increase the convergence speed and learn more accurate deep RL agents, a hint-based reward function is also employed. Two simulation environments, one for drone control and one for camera control, were developed and used for training and evaluating the proposed methods. The proposed method can be combined both with methods capable of performing discrete control, as well as with continuous control methods. It was experimentally demonstrated that the proposed method improves the control accuracy over both handcrafted control techniques and deep RL models trained with other reward functions.}
}
@article{PADHY2018643,
title = {Deep Neural Network for Autonomous UAV Navigation in Indoor Corridor Environments},
journal = {Procedia Computer Science},
volume = {133},
pages = {643-650},
year = {2018},
note = {International Conference on Robotics and Smart Manufacturing (RoSMa2018)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2018.07.099},
url = {https://www.sciencedirect.com/science/article/pii/S1877050918310524},
author = {Ram Prasad Padhy and Sachin Verma and Shahzad Ahmad and Suman Kumar Choudhury and Pankaj Kumar Sa},
keywords = {UAV, Monocular, GPS, Convolution, Deep Neural Network, Classification Task},
abstract = {In recent years, the UAV technology is unceasingly emerging as a revolutionary reform among the research community. In this paper, we propose a method that facilitates UAVs with a monocular camera to navigate autonomously in previously unknown and GPS-denied indoor corridor arenas. The proposed system uses a state-of-the-art Convolutional Neural Network (CNN) model to achieve the task. We propose a novel approach, which uses the video feed extracted from the front camera of the UAV and passes it through a deep neural network model to decide on the next course of maneuver. The entire process is treated as a classification task where the deep neural network model is responsible for classifying the image as left, right or center of the corridor. The training is performed over a dataset of images, collected from various indoor corridor environments. Apart from utilizing the front facing camera, the model is not dependent on any other sensor. We demonstrate the efficacy of the proposed system in real-time indoor corridor scenarios.}
}
@article{WU2020106790,
title = {Real-time neural network scheduling of emergency medical mask production during COVID-19},
journal = {Applied Soft Computing},
volume = {97},
pages = {106790},
year = {2020},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2020.106790},
url = {https://www.sciencedirect.com/science/article/pii/S1568494620307286},
author = {Chen-Xin Wu and Min-Hui Liao and Mumtaz Karatas and Sheng-Yong Chen and Yu-Jun Zheng},
keywords = {Emergency production, Flow shop scheduling, Neural network, Reinforcement learning, Public health emergencies},
abstract = {During the outbreak of the novel coronavirus pneumonia (COVID-19), there is a huge demand for medical masks. A mask manufacturer often receives a large amount of orders that must be processed within a short response time. It is of critical importance for the manufacturer to schedule and reschedule mask production tasks as efficiently as possible. However, when the number of tasks is large, most existing scheduling algorithms require very long computational time and, therefore, cannot meet the needs of emergency response. In this paper, we propose an end-to-end neural network, which takes a sequence of production tasks as inputs and produces a schedule of tasks in a real-time manner. The network is trained by reinforcement learning using the negative total tardiness as the reward signal. We applied the proposed approach to schedule emergency production tasks for a medical mask manufacturer during the peak of COVID-19 in China. Computational results show that the neural network scheduler can solve problem instances with hundreds of tasks within seconds. The objective function value obtained by the neural network scheduler is significantly better than those of existing constructive heuristics, and is close to those of the state-of-the-art metaheuristics whose computational time is unaffordable in practice.}
}
@article{NETO201711,
title = {Performance evaluation of unmanned aerial vehicles in automatic power meter readings},
journal = {Ad Hoc Networks},
volume = {60},
pages = {11-25},
year = {2017},
issn = {1570-8705},
doi = {https://doi.org/10.1016/j.adhoc.2017.03.003},
url = {https://www.sciencedirect.com/science/article/pii/S1570870517300471},
author = {José R.T. Neto and Azzedine Boukerche and Roberto S. Yokoyama and Daniel L. Guidoni and Rodolfo I. Meneguette and Jo Ueyama and Leandro A. Villas},
keywords = {Automatic Meter Reading, Unmanned Aerial Vehicles, Wireless sensors networks, Message collision},
abstract = {Typically, the electric power companies employ a group of power meter readers to collect data on the customers energy consumption. This task is usually carried out manually, which can lead to high cost and errors, causing financial losses. Some approaches have tried to minimize these problems, using strategies such as discovering the minimal route or relying on vehicles to perform the readings. However, errors in the manual readings can occur and vehicles suffer from congestion and high fuel and maintenance costs. In this work, we go further and propose an architecture to the Automatic Meter Reading (AMR) system using Unmanned Aerial Vehicles (UAV). The main challenge of the solution is to design a robust and lightweight protocol that is capable of dealing with wireless communication collisions. Therefore, the main contribution of this work is the design of a new protocol to ensure wireless communication from UAV to the power meters. We validated and evaluated the architecture in an urban scenario, with results showing a decrease of time and distance when compared to other approaches. We also evaluated the system proposed with Linear Flight Plan, the Ant Colony Optimization and Guided Local Search metaheuristic. Our mechanism attains an improvement of 98% in reducing the message collisions and reducing the energy consumption of the power meters.}
}
@article{BHUVANESWARI20213263,
title = {Deep learning for material synthesis and manufacturing systems: A review},
journal = {Materials Today: Proceedings},
volume = {46},
pages = {3263-3269},
year = {2021},
note = {International Conference on Materials, Manufacturing and Mechanical Engineering for Sustainable Developments-2020 (ICMSD 2020)},
issn = {2214-7853},
doi = {https://doi.org/10.1016/j.matpr.2020.11.351},
url = {https://www.sciencedirect.com/science/article/pii/S2214785320389641},
author = {V. Bhuvaneswari and M. Priyadharshini and C. Deepa and D. Balaji and L. Rajeshkumar and M. Ramesh},
keywords = {Deep learning, Material synthesis, Neural network, Manufacturing system, Degradation, Crystal structure},
abstract = {Deep learning (DL) techniques are the evolutionary methods of machine learning (ML) advancements in which current industrial operations are focusing and this method is way far efficient in handling big data in a rapid pace and with autonomy. DL techniques are the analyzing tools for interpreting and operating according to the big data and process the data for variety of applications. This study discusses the evolution of DL methods from conventional ML techniques and the potentiality of DL over ML methods. This is followed by the enunciation of various computational DL methods which enhances the performance of technologies used in material synthesis, characterization and manufacturing methods. Studies focused on the determination crystal structure of a material by using deep neural network (DNN) tools which are trained from a huge crystallographic big data were also touched upon. Such crystallographic studies was reported to be possible by using atomic fingerprints of the multiple crystal structures which provides data regarding the topology of crystallographic regions and these data could be used for the training of DLL models that detects the crystal structure of an element in any crystallographic environment. Degradation of materials is another task that was successfully reported to be carried out using DL models. Though the material degradation is dependent on many factors and modelling of such degradation by using deterministic algorithms is difficult owing to the measuring constraints and interdependence of the governing variables, usage of appropriate DL tools and algorithms would make it easier. DL models for the synthesis of materials, analysis of spectroscopic results and deployment of manufacturing systems were individually discussed. This study is also extended towards the upcoming areas in which DL could be extensively applied and the challenges in it is also discussed.}
}
@article{WU2020105201,
title = {The autonomous navigation and obstacle avoidance for USVs with ANOA deep reinforcement learning method},
journal = {Knowledge-Based Systems},
volume = {196},
pages = {105201},
year = {2020},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2019.105201},
url = {https://www.sciencedirect.com/science/article/pii/S0950705119305350},
author = {Xing Wu and Haolei Chen and Changgu Chen and Mingyu Zhong and Shaorong Xie and Yike Guo and Hamido Fujita},
keywords = {Autonomous navigation, Obstacle avoidance, Reinforcement learning, Unmanned surface vehicle (USV)},
abstract = {The unmanned surface vehicle (USV) has been widely used to accomplish missions in the sea or dangerous marine areas for ships with sailors, which greatly expands protective capability and detection range. When USVs perform various missions in sophisticated marine environment, autonomous navigation and obstacle avoidance will be necessary and essential. However, there are few effective navigation methods with real-time path planning and obstacle avoidance in dynamic environment. With tailored design of state and action spaces and a dueling deep Q-network, a deep reinforcement learning method ANOA (Autonomous Navigation and Obstacle Avoidance) is proposed for the autonomous navigation and obstacle avoidance of USVs. Experimental results demonstrate that ANOA outperforms deep Q-network (DQN) and Deep Sarsa in the efficiency of exploration and the speed of convergence not only in static environment but also in dynamic environment. Furthermore, the ANOA is integrated with the real control model of a USV moving in surge, sway and yaw and it achieves a higher success rate than Recast navigation method in dynamic environment.}
}
@article{MASROOR2021102596,
title = {Resource management in UAV-assisted wireless networks: An optimization perspective},
journal = {Ad Hoc Networks},
volume = {121},
pages = {102596},
year = {2021},
issn = {1570-8705},
doi = {https://doi.org/10.1016/j.adhoc.2021.102596},
url = {https://www.sciencedirect.com/science/article/pii/S1570870521001311},
author = {Rooha Masroor and Muhammad Naeem and Waleed Ejaz},
keywords = {Optimization, Resource management, Unmanned aerial vehicles, Wireless networks},
abstract = {Wireless networks are expected to provide connectivity to an increasing number of users with heterogeneous requirements. Future wireless networks will integrate aerial and terrestrial networks to provide massive (a large number of users) connectivity. Unmanned aerial vehicles (UAV) can be deployed on-demand to provide connectivity in aerial networks. UAV-assisted wireless networks offer a broad range of applications in an overload situation, broadcasting and advertisement, public safety, disaster management, and many more. However, UAV-assisted wireless networks must use their resources efficiently to maintain key performance indicators. The challenges for the successful deployment of UAV-assisted wireless networks include spectrum efficiency, energy consumption, deployment time, backhaul, and cost of deployment. This paper provides a comprehensive survey of resource management in UAV-assisted wireless networks from an optimization viewpoint. We present the classification of UAVs, their benefits, and applications to highlight UAV-assisted wireless networks’ significance. We then provide a detailed discussion on resource management with metrics including placement of UAVs, UAV trajectory, backhaul, path planning, charging, spectrum, and data offloading. Moreover, different constraints, optimization types, and solutions tailored to support UAV-assisted wireless networks are discussed. Finally, we provide future research directions to address the challenges for the successful deployment of UAV-assisted wireless networks.}
}
@article{CARVAJALCASTRILLON2017729,
title = {Structural health monitoring on an unmanned aerial vehicle wing's beam based on fiber Bragg gratings and pattern recognition techniques},
journal = {Procedia Structural Integrity},
volume = {5},
pages = {729-736},
year = {2017},
note = {2nd International Conference on Structural Integrity, ICSI 2017, 4-7 September 2017, Funchal, Madeira, Portugal},
issn = {2452-3216},
doi = {https://doi.org/10.1016/j.prostr.2017.07.163},
url = {https://www.sciencedirect.com/science/article/pii/S2452321617302755},
author = {Alejandro Carvajal-Castrillón and Joham Alvarez-Montoya and Juliana Niño-Navia and Leonardo Betancur-Agudelo and Ferney Amaya-Fernández and Julián Sierra-Pérez},
keywords = {structural health monitoring, fiber Bragg gratings, unmanned aerial vehicles, pattern recognition techniques},
abstract = {Composite materials have been extensively used on new aircraft airframes because of their advantages over metallic materials. This represents a difficulty for damage detection, a vital task for safety on the aerospace industry, as most nondestructive testing techniques are not effective on these materials since those usually present internal failures like delaminations which are difficult to detect. A miniaturized strain acquisition and wireless transmission system is presented alongside with a novel technique for structural behavior assessment, based on the use of Fiber Bragg Gratings to measure strains and non-supervised classification techniques to recognize different operational conditions. Operational tests were performed on an Unmanned Aerial Vehicles wing's beam, made of composite materials with the sensors embedded during its manufacturing. Strain measurements were processed using an Optimal Baseline Selection methodology. The tests performed proved the system's capability to identify and separate different operational conditions for a healthy structure, based on the analysis of its strain fields. The implementation of this methodologies can lead to perform real-time damage detection on aerospace complex structures made of composite materials.}
}
@article{CHEN2020433,
title = {An intelligent task offloading algorithm (iTOA) for UAV edge computing network},
journal = {Digital Communications and Networks},
volume = {6},
number = {4},
pages = {433-443},
year = {2020},
issn = {2352-8648},
doi = {https://doi.org/10.1016/j.dcan.2020.04.008},
url = {https://www.sciencedirect.com/science/article/pii/S2352864819303037},
author = {Jienan Chen and Siyu Chen and Siyu Luo and Qi Wang and Bin Cao and Xiaoqian Li},
keywords = {Unmanned aerial vehicles (UAVs), Mobile edge computing (MEC), Intelligent task offloading algorithm (iTOA), Monte Carlo tree search (MCTS), Deep reinforcement learning, Splitting deep neural network (sDNN)},
abstract = {Unmanned Aerial Vehicle (UAV) has emerged as a promising technology for the support of human activities, such as target tracking, disaster rescue, and surveillance. However, these tasks require a large computation load of image or video processing, which imposes enormous pressure on the UAV computation platform. To solve this issue, in this work, we propose an intelligent Task Offloading Algorithm (iTOA) for UAV edge computing network. Compared with existing methods, iTOA is able to perceive the network’s environment intelligently to decide the offloading action based on deep Monte Calor Tree Search (MCTS), the core algorithm of Alpha Go. MCTS will simulate the offloading decision trajectories to acquire the best decision by maximizing the reward, such as lowest latency or power consumption. To accelerate the search convergence of MCTS, we also proposed a splitting Deep Neural Network (sDNN) to supply the prior probability for MCTS. The sDNN is trained by a self-supervised learning manager. Here, the training data set is obtained from iTOA itself as its own teacher. Compared with game theory and greedy search-based methods, the proposed iTOA improves service latency performance by 33% and 60%, respectively.}
}
@article{CALOU2020115,
title = {The use of UAVs in monitoring yellow sigatoka in banana},
journal = {Biosystems Engineering},
volume = {193},
pages = {115-125},
year = {2020},
issn = {1537-5110},
doi = {https://doi.org/10.1016/j.biosystemseng.2020.02.016},
url = {https://www.sciencedirect.com/science/article/pii/S1537511020300568},
author = {Vinícius Bitencourt Campos Calou and Adunias dos Santos Teixeira and Luis Clenio Jario Moreira and Cristiano Souza Lima and Joaquim Branco {de Oliveira} and Marcio Regys Rabelo {de Oliveira}},
keywords = {Remote sensing, Machine learning, Unmanned aerial vehicle,  spp, , PhotoScan},
abstract = {Monitoring pests and diseases is an extremely important activity for increasing productivity in agriculture. In this scenario, remote sensing, coupled with techniques of machine learning, offer new prospects for monitoring and identifying characteristic specific patterns, such as manifestations of diseases, pests, and water and nutritional stress. The aim was to use high spatial resolution aerial images to monitor the extent of an attack of yellow sigatoka in a banana crop, following the basic assumptions of identification, classification, quantification and prediction of phenotypic factors. Monthly flights were carried out on a commercial banana plantation using an unmanned aerial vehicle, equipped with a 16-megapixel RGB camera (GSD of 0.016781 m pixel−1). Five classification algorithms were used to identify and quantify the disease while field evaluations were also made following traditional methodology. The results showed that, for September 2017, the Support Vector Machine algorithm achieved the best performance (99.28% overall accuracy and 97.13 Kappa Index), followed by the Artificial Neural Network and Minimum Distance algorithms. In quantifying the disease, the SVM algorithm was more effective than other algorithms compared to the conventional methodology used to estimate the extent of yellow sigatoka, demonstrating that the tools used for monitoring leaf spots can be handled by remote sensing, machine learning and high spatial-resolution RGB images.}
}
@article{ZHANG2020658,
title = {Power cognition: Enabling intelligent energy harvesting and resource allocation for solar-powered UAVs},
journal = {Future Generation Computer Systems},
volume = {110},
pages = {658-664},
year = {2020},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2019.05.068},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X19308349},
author = {Jing Zhang and Minhao Lou and Lin Xiang and Long Hu},
keywords = {Solar-powered unmanned aerial vehicle, Power cognition, Resource allocation, Reinforcement learning},
abstract = {Solar-powered unmanned aerial vehicles (SUAVs) are a promising solution to increase the flight time of unmanned aerial vehicles (UAVs) in the sky, reducing human interventions for battery charging. Exploiting networked SUAVs for providing long-duration wireless communication cannot only improve the signal transmission reliability but realize energy autonomy. To reap these benefits, in this article, we propose an efficient energy and radio resource management framework based on intelligent power cognition at the SUAVs. Thereby, power-cognitive SUAVs can learn the environment including the spatial distributions of solar energy density, the channel state evolution, and the traffic patterns of wireless communication applications in adaption to the environment changes. These SUAVs intelligently adjust the energy harvesting, information transmission, and flight trajectory to improve the utilization of solar energy for two primary goals: staying aloft over a long time period and achieving high communication performance. We adopt reinforcement learning to compute the optimal decisions for maximization of the total system throughput within the lifetime of the SUAV. Simulation results show that the proposed power cognition scheme can simultaneously improve the communication throughput and the harvested energy for SUAVs.}
}
@article{MAHMUD2021106313,
title = {A systematic literature review on deep learning applications for precision cattle farming},
journal = {Computers and Electronics in Agriculture},
volume = {187},
pages = {106313},
year = {2021},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2021.106313},
url = {https://www.sciencedirect.com/science/article/pii/S0168169921003306},
author = {Md Sultan Mahmud and Azlan Zahid and Anup Kumar Das and Muhammad Muzammil and Muhammad Usman Khan},
keywords = {Artificial intelligence, Cattle behavior, Cattle detection, Cattle health, Cattle identification, Digital agriculture, Precision livestock farming},
abstract = {In animal agriculture, deep learning-based approaches have been widely implemented as a decision support tool for precision farming. Several deep learning models have been applied to solve diverse problems related to cattle health and identification. However, an overview of the state-of-the-art of deep learning in precision cattle farming is needed, for which we performed a systematic literature review (SLR). This study aims to provide an overview of the recent progress in deep learning applications for precision cattle farming, in particular health and identification. In the initial search, we retrieved 678 studies from different electronic databases. Only 56 studies qualify the selection criteria, which were then analyzed to extract the data to answer the research questions. The two major applications of deep learning for cattle farming were identified: identification and health monitoring. About 58% of the selected studies are dedicated to cattle identification and the rest for health monitoring. We identified 20 deep learning models that were used to solve different problems, and Convolutional Neural Networks (CNNs) is the most adopted model than others, including Long Short-Term Memory (LSTM), Mask-Region Based Convolutional Neural Networks (Mask-RCNN), and Faster-RCNN. We identified 19 training networks and of which ResNet is by far the most used. From our selection, 12 model evaluation parameters were determined, of which seven were used more than five times. The challenges most encountered with image quality, data processing speed, dataset size, redundant information, and motion of the cattle during data acquisition. In closing, we consider that this SLR study will pave the way for future research towards developing automatic systems for cattle farming.}
}
@article{ZHANG20202825,
title = {Cooperative task assignment of multi-UAV system},
journal = {Chinese Journal of Aeronautics},
volume = {33},
number = {11},
pages = {2825-2827},
year = {2020},
note = {SI: Emerging Technologies of Unmanned Aerial Vehicles},
issn = {1000-9361},
doi = {https://doi.org/10.1016/j.cja.2020.02.009},
url = {https://www.sciencedirect.com/science/article/pii/S1000936120300650},
author = {Jun ZHANG and Jiahao XING},
keywords = {Autonomous control, Cooperative task assignment, Intelligent operation, Multi-UAV collaboration, Unmanned aerial vehicles},
abstract = {With the rapid development of Unmanned Aerial Vehicle (UAV) technology, one of the emerging fields is to utilize multi-UAV as a team under autonomous control in a complex environment. Among the challenges in fully achieving autonomous control, Cooperative task assignment stands out as the key function. In this paper, we analyze the importance and difficulties of multi-UAV cooperative task assignment in characterizing scenarios and obtaining high-quality solutions. Furthermore, we present three promising directions for future research: Cooperative task assignment in a dynamic complex environment, in an unmanned-manned aircraft system and in a UAV swarm. Our goal is to provide a brief review of multi-UAV cooperative task assignment for readers to further explore.}
}
@article{ZHANG2022,
title = {Distributed adaptive specified-time synchronization tracking of multiple 6-DOF fixed-wing UAVs with guaranteed performances},
journal = {ISA Transactions},
year = {2022},
issn = {0019-0578},
doi = {https://doi.org/10.1016/j.isatra.2022.01.006},
url = {https://www.sciencedirect.com/science/article/pii/S001905782200012X},
author = {Boyang Zhang and Xiuxia Sun and Maolong Lv},
keywords = {Specified-time tracking, Specified-time performance function, Six-degree-of-freedom UAVs},
abstract = {Different from the finite/fixed-time control methodologies on longitudinal/attitude synchronization or 2-D motion of UAVs, this article attempts to propose a distributed adaptive specified-time control scheme for synchronization tracking of networked 6-degree-of-freedom (DOF) UAVs. To be specific, the novel specified-time performance functions (STPFs) are designed in such a way that the desired performance bounds can be imposed on velocity and attitude tracking errors. Based on the transformed errors, by utilizing the barrier Lyapunov functions (BLFs), a distributed specified-time control scheme is constructed with adaptive robustifying terms to enhance the fault-tolerant ability and compensate the modeling uncertainties. By means of Lyapunov stability theory, it is proved that the resulting control scheme can guarantee the boundedness of all closed-loop state variables, and preserve the guaranteed performance bounds for synchronization tracking errors of velocity and attitude at the same time. Theoretical results are confirmed by experiment and simulation validations. }
}
@article{THEISSLER2021107864,
title = {Predictive maintenance enabled by machine learning: Use cases and challenges in the automotive industry},
journal = {Reliability Engineering & System Safety},
volume = {215},
pages = {107864},
year = {2021},
issn = {0951-8320},
doi = {https://doi.org/10.1016/j.ress.2021.107864},
url = {https://www.sciencedirect.com/science/article/pii/S0951832021003835},
author = {Andreas Theissler and Judith Pérez-Velázquez and Marcel Kettelgerdes and Gordon Elger},
keywords = {Predictive maintenance, Artificial intelligence, Machine learning, Deep learning, Vehicle, Automotive, Reliability, Lifetime prediction, Condition monitoring},
abstract = {Recent developments in maintenance modelling fuelled by data-based approaches such as machine learning (ML), have enabled a broad range of applications. In the automotive industry, ensuring the functional safety over the product life cycle while limiting maintenance costs has become a major challenge. One crucial approach to achieve this, is predictive maintenance (PdM). Since modern vehicles come with an enormous amount of operating data, ML is an ideal candidate for PdM. While PdM and ML for automotive systems have both been covered in numerous review papers, there is no current survey on ML-based PdM for automotive systems. The number of publications in this field is increasing — underlining the need for such a survey. Consequently, we survey and categorize papers and analyse them from an application and ML perspective. Following that, we identify open challenges and discuss possible research directions. We conclude that (a) publicly available data would lead to a boost in research activities, (b) the majority of papers rely on supervised methods requiring labelled data, (c) combining multiple data sources can improve accuracies, (d) the use of deep learning methods will further increase but requires efficient and interpretable methods and the availability of large amounts of (labelled) data.}
}
@article{RAZMI201912,
title = {Neural network-based adaptive sliding mode control design for position and attitude control of a quadrotor UAV},
journal = {Aerospace Science and Technology},
volume = {91},
pages = {12-27},
year = {2019},
issn = {1270-9638},
doi = {https://doi.org/10.1016/j.ast.2019.04.055},
url = {https://www.sciencedirect.com/science/article/pii/S1270963818310447},
author = {Hadi Razmi and Sima Afshinfar},
keywords = {Sliding mode control, Neural network, Quadrotor},
abstract = {In this paper, a novel method is suggested for the position and attitude tracking control of a quadrotor UAV in the presence of parametric uncertainties and external disturbance. The proposed method combines neural network adaptive scheme with sliding mode control, which preserves the advantages of the two methods. Firstly, dynamic model of quadrotor is divided into two fully actuated and under actuated subsystems. Secondly, sliding mode controllers are corresponding designed for each subsystem, and their coefficients in sliding manifolds are adaptively tuned by the neural network method. In each section, using Lyapunov theory, stability of closed loop system is proven. Finally, the method is examined for a square path tracking and a maximum overshoot of 7.5133% and a settling time 5.6648 s are obtained. By comparing the results obtained through different methods, it is concluded that the proposed controller provides the following main advantages: (1) good transient and steady state behaviors, (2) insensitivity to parameter variations, (3) disturbance rejection capability, and (4) remarkable stability and performance robustness. Hence, for operational purposes in which the fast and accurate response are of crucial importance, using the neural network-based adaptive sliding mode control approach is recommended.}
}
@article{GAO201843,
title = {Fusion of pixel and object-based features for weed mapping using unmanned aerial vehicle imagery},
journal = {International Journal of Applied Earth Observation and Geoinformation},
volume = {67},
pages = {43-53},
year = {2018},
issn = {0303-2434},
doi = {https://doi.org/10.1016/j.jag.2017.12.012},
url = {https://www.sciencedirect.com/science/article/pii/S0303243417303252},
author = {Junfeng Gao and Wenzhi Liao and David Nuyttens and Peter Lootens and Jürgen Vangeyte and Aleksandra Pižurica and Yong He and Jan G. Pieters},
keywords = {UAVs, Inter- and intra-row weed detection, Feature fusion, OBIA, Random forests, Hyperparameter tuning, Feature evaluation},
abstract = {The developments in the use of unmanned aerial vehicles (UAVs) and advanced imaging sensors provide new opportunities for ultra-high resolution (e.g., less than a 10 cm ground sampling distance (GSD)) crop field monitoring and mapping in precision agriculture applications. In this study, we developed a strategy for inter- and intra-row weed detection in early season maize fields from aerial visual imagery. More specifically, the Hough transform algorithm (HT) was applied to the orthomosaicked images for inter-row weed detection. A semi-automatic Object-Based Image Analysis (OBIA) procedure was developed with Random Forests (RF) combined with feature selection techniques to classify soil, weeds and maize. Furthermore, the two binary weed masks generated from HT and OBIA were fused for accurate binary weed image. The developed RF classifier was evaluated by 5-fold cross validation, and it obtained an overall accuracy of 0.945, and Kappa value of 0.912. Finally, the relationship of detected weeds and their ground truth densities was quantified by a fitted linear model with a coefficient of determination of 0.895 and a root mean square error of 0.026. Besides, the importance of input features was evaluated, and it was found that the ratio of vegetation length and width was the most significant feature for the classification model. Overall, our approach can yield a satisfactory weed map, and we expect that the obtained accurate and timely weed map from UAV imagery will be applicable to realize site-specific weed management (SSWM) in early season crop fields for reducing spraying non-selective herbicides and costs.}
}
@article{ABBASPOUR2016193,
title = {Detection of Fault Data Injection Attack on UAV Using Adaptive Neural Network},
journal = {Procedia Computer Science},
volume = {95},
pages = {193-200},
year = {2016},
note = {Complex Adaptive Systems Los Angeles, CA November 2-4, 2016},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2016.09.312},
url = {https://www.sciencedirect.com/science/article/pii/S1877050916324851},
author = {Alireza Abbaspour and Kang K. Yen and Shirin Noei and Arman Sargolzaei},
keywords = {Cyber-attack, UAV, Sensors, Attacks and Faults Detection, Fault Data Injection, Adaptive Neural Network},
abstract = {A resilient and secure control system should be designed to be as safe and robust as possible in face of different types of attacks such as fault data injection (FDI) attacks; thus, nowadays, the control designers should also consider the probable attacks in their control design from the beginning. For this reason, detection of intentional faults and cyber-attacks attracts a great concern among researchers. This issue plays a great role in the safety of unmanned aerial vehicles (UAVs) due to the need of continuous supervision and control of these systems. In order to have a cyber-attack tolerant (CAT) controller, the attack and the type of attack should be detected in the first step. This paper introduces a new algorithm to detect fault data injection attack in UAV. An adaptive neural network is used to detect the injected faults in sensors of an UAV. An embedded Kalman filter (EKF) is used for online tuning of neural networks weights; these online tuning makes the attack detection faster and more accurate. The simulation results show that the proposed method can successfully detect FDI attacks applied to an UAV.}
}
@article{DENG20131238,
title = {Cooperative task assignment of multiple heterogeneous unmanned aerial vehicles using a modified genetic algorithm with multi-type genes},
journal = {Chinese Journal of Aeronautics},
volume = {26},
number = {5},
pages = {1238-1250},
year = {2013},
issn = {1000-9361},
doi = {https://doi.org/10.1016/j.cja.2013.07.009},
url = {https://www.sciencedirect.com/science/article/pii/S1000936113001453},
author = {Qibo Deng and Jianqiao Yu and Ningfei Wang},
keywords = {Cooperative control, Genetic algorithm, Heterogeneous unmanned aerial vehicles, Multi-type genes, Task assignment},
abstract = {The task assignment problem of multiple heterogeneous unmanned aerial vehicles (UAVs), concerned with cooperative decision making and control, is studied in this paper. The heterogeneous vehicles have different operational capabilities and kinematic constraints, and carry limited resources (e.g., weapons) onboard. They are designated to perform multiple consecutive tasks cooperatively on multiple ground targets. The problem becomes much more complicated because of these terms of heterogeneity. In order to tackle the challenge, we modify the former genetic algorithm with multi-type genes to stochastically search a best solution. Genes of chromosomes are different, and they are assorted into several types according to the tasks that must be performed on targets. Different types of genes are processed specifically in the improved genetic operators including initialization, crossover, and mutation. We also present a mirror representation of vehicles to deal with the limited resource constraint. Feasible chromosomes that vehicles could perform tasks using their limited resources under the assignment are created and evolved by genetic operators. The effect of the proposed algorithm is demonstrated in numerical simulations. The results show that it effectively provides good feasible solutions and finds an optimal one.}
}
@article{GARCIAGARIN2021116490,
title = {Automatic detection and quantification of floating marine macro-litter in aerial images: Introducing a novel deep learning approach connected to a web application in R},
journal = {Environmental Pollution},
volume = {273},
pages = {116490},
year = {2021},
issn = {0269-7491},
doi = {https://doi.org/10.1016/j.envpol.2021.116490},
url = {https://www.sciencedirect.com/science/article/pii/S0269749121000683},
author = {Odei Garcia-Garin and Toni Monleón-Getino and Pere López-Brosa and Asunción Borrell and Alex Aguilar and Ricardo Borja-Robalino and Luis Cardona and Morgana Vighi},
keywords = {Remote sensing, Machine learning, Unmanned aerial vehicles, Convolutional neural network, Marine litter},
abstract = {The threats posed by floating marine macro-litter (FMML) of anthropogenic origin to the marine fauna, and marine ecosystems in general, are universally recognized. Dedicated monitoring programmes and mitigation measures are in place to address this issue worldwide, with the increasing support of new technologies and the automation of analytical processes. In the current study, we developed algorithms capable of detecting and quantifying FMML in aerial images, and a web-oriented application that allows users to identify FMML within images of the sea surface. The proposed algorithm is based on a deep learning approach that uses convolutional neural networks (CNNs) capable of learning from unstructured or unlabelled data. The CNN-based deep learning model was trained and tested using 3723 aerial images (50% containing FMML, 50% without FMML) taken by drones and aircraft over the waters of the NW Mediterranean Sea. The accuracies of image classification (performed using all the images for training and testing the model) and cross-validation (performed using 90% of images for training and 10% for testing) were 0.85 and 0.81, respectively. The Shiny package of R was then used to develop a user-friendly application to identify and quantify FMML within the aerial images. The implementation of this, and similar algorithms, allows streamlining substantially the detection and quantification of FMML, providing support to the monitoring and assessment of this environmental threat. However, the automated monitoring of FMML in the open sea still represents a technological challenge, and further research is needed to improve the accuracy of current algorithms.}
}
@article{ANTONELLI20141108,
title = {CAVIS: a Control software Architecture for cooperative multi-unmanned aerial VehIcle-manipulator Systems},
journal = {IFAC Proceedings Volumes},
volume = {47},
number = {3},
pages = {1108-1113},
year = {2014},
note = {19th IFAC World Congress},
issn = {1474-6670},
doi = {https://doi.org/10.3182/20140824-6-ZA-1003.02366},
url = {https://www.sciencedirect.com/science/article/pii/S1474667016417623},
author = {G. Antonelli and K. Baizid and F. Caccavale and G. Giglio and F. Pierri},
keywords = {Control software architectures, Unmanned aerial vehicle-manipulator systems, Multi-robot systems, Cooperation, Coordination},
abstract = {In this paper a Control software Architecture for Cooperative multiple unmanned aerial VehIcle-manipulator Systems (CAVIS) is presented. The core of the architecture is a set of software components, communicating each other through a set of defined messages. To handle multiple control objectives simultaneously, a library of elementary behaviors is defined; then, multiple elementary behaviors are combined, in a given priority order, into tasks (compound behaviors); to this aim the Null-Space-based Behavioral (NSB) approach has been adopted. An application example, involving a cooperative transportation of a bar by two aerial vehicle-manipulator systems, is developed to assess the performance of the proposed architecture.}
}
@article{ROOSJEN201814,
title = {Improved estimation of leaf area index and leaf chlorophyll content of a potato crop using multi-angle spectral data – potential of unmanned aerial vehicle imagery},
journal = {International Journal of Applied Earth Observation and Geoinformation},
volume = {66},
pages = {14-26},
year = {2018},
issn = {0303-2434},
doi = {https://doi.org/10.1016/j.jag.2017.10.012},
url = {https://www.sciencedirect.com/science/article/pii/S0303243417302313},
author = {Peter P.J. Roosjen and Benjamin Brede and Juha M. Suomalainen and Harm M. Bartholomeus and Lammert Kooistra and Jan G.P.W. Clevers},
keywords = {Multi-angular reflectance, Unmanned aerial vehicle, Reflectance anisotropy, PROSAIL, Leaf area index, Leaf chlorophyll content, Model inversion},
abstract = {In addition to single-angle reflectance data, multi-angular observations can be used as an additional information source for the retrieval of properties of an observed target surface. In this paper, we studied the potential of multi-angular reflectance data for the improvement of leaf area index (LAI) and leaf chlorophyll content (LCC) estimation by numerical inversion of the PROSAIL model. The potential for improvement of LAI and LCC was evaluated for both measured data and simulated data. The measured data was collected on 19 July 2016 by a frame-camera mounted on an unmanned aerial vehicle (UAV) over a potato field, where eight experimental plots of 30×30m were designed with different fertilization levels. Dozens of viewing angles, covering the hemisphere up to around 30° from nadir, were obtained by a large forward and sideways overlap of collected images. Simultaneously to the UAV flight, in situ measurements of LAI and LCC were performed. Inversion of the PROSAIL model was done based on nadir data and based on multi-angular data collected by the UAV. Inversion based on the multi-angular data performed slightly better than inversion based on nadir data, indicated by the decrease in RMSE from 0.70 to 0.65m2/m2 for the estimation of LAI, and from 17.35 to 17.29μg/cm2 for the estimation of LCC, when nadir data were used and when multi-angular data were used, respectively. In addition to inversions based on measured data, we simulated several datasets at different multi-angular configurations and compared the accuracy of the inversions of these datasets with the inversion based on data simulated at nadir position. In general, the results based on simulated (synthetic) data indicated that when more viewing angles, more well distributed viewing angles, and viewing angles up to larger zenith angles were available for inversion, the most accurate estimations were obtained. Interestingly, when using spectra simulated at multi-angular sampling configurations as were captured by the UAV platform (view zenith angles up to 30°), already a huge improvement could be obtained when compared to solely using spectra simulated at nadir position. The results of this study show that the estimation of LAI and LCC by numerical inversion of the PROSAIL model can be improved when multi-angular observations are introduced. However, for the potato crop, PROSAIL inversion for measured data only showed moderate accuracy and slight improvements.}
}
@article{KHAN2021101337,
title = {UAVs path planning architecture for effective medical emergency response in future networks},
journal = {Physical Communication},
volume = {47},
pages = {101337},
year = {2021},
issn = {1874-4907},
doi = {https://doi.org/10.1016/j.phycom.2021.101337},
url = {https://www.sciencedirect.com/science/article/pii/S1874490721000744},
author = {Sara Imran Khan and Zakria Qadir and Hafiz Suliman Munawar and Soumya Ranjan Nayak and Anil Kumar Budati and K.D. Verma and Deo Prakash},
keywords = {Unmanned Aerial Vehicles, 6G, CVRP, PSO, ACO, Medical emergency},
abstract = {With the advancements of the Unmanned Aerial Vehicles (UAV) technology for use in different environments, it can be easily substituted for traditional transportation in event of emergencies. In the medical domain, UAV can play a vital role in the fast and efficient delivery of first aid and medical supplies. In the current study, safe and smooth UAV navigation from the initial position to the medical emergency location was achieved with optimal path planning through a proposed algorithm. On the notification of patient about his health condition using GSM band, doctor drone was sent from the nearest hospital facility. To avoid traffic congestion the doctor drone provides medical assistance with minimum computational time and transportation cost. The vehicle routing was carried out through proposed algorithms i.e., capacitated Vehicle Routing Problem (CVRP), Particle Swarm Optimization (PSO), Ant Colony Optimization (ACO) and Genetic Algorithm (GA). The comparison between the algorithms was carried out at different vehicle capacities and numbers. The CVRP was found to outperform other algorithms with a runtime of 0.06 sec and cost of 419 at vehicle capacity 10, which is 50% less having the same number of the vehicles but increasing the capacities to 20. The results indicate that the effective path planning method could be applied to provide medical aid in real-time with efficacy.}
}
@article{NASCIMENTO2021230526,
title = {Hybrid physics-informed neural networks for lithium-ion battery modeling and prognosis},
journal = {Journal of Power Sources},
volume = {513},
pages = {230526},
year = {2021},
issn = {0378-7753},
doi = {https://doi.org/10.1016/j.jpowsour.2021.230526},
url = {https://www.sciencedirect.com/science/article/pii/S0378775321010259},
author = {Renato G. Nascimento and Matteo Corbetta and Chetan S. Kulkarni and Felipe A.C. Viana},
keywords = {Physics-informed neural networks, Li-ion battery prognostics, Battery aging, Scientific machine learning, Uncertainty quantification, Hybrid models},
abstract = {Lithium-ion batteries are commonly used to power unmanned aircraft vehicles (UAVs). The ability to model and forecast remaining useful life of these batteries enables UAV reliability assurance. Building principled accurate models is challenging due to the complex electrochemistry that governs battery operation. Alternatively, reduced order models have the advantage of capturing the overall behavior of battery discharge, although they suffer from simplifications and residual discrepancy. This paper presents a hybrid modeling approach that directly implements physics within deep neural networks. While most of the input–output relationship is captured by reduced-order models, data-driven kernels reduce the gap between predictions and observations. A reduced-order model based on Nernst and Butler–Volmer equations represents the overall battery discharge, and a multilayer perceptron models the battery non-ideal voltage. Battery aging is characterized by time-dependent internal resistance and the amount of available Li-ions, which are modeled through an ensemble of variational Bayesian multilayer perceptrons. The approach is validated using data publicly available through the NASA Prognostics Center of Excellence website. Results showed that our hybrid battery prognosis model can be successfully calibrated, even with a limited number of observations. Moreover, the model can help optimizing battery operation by offering long-term forecast of battery capacity.}
}
@article{JAFARI2020100096,
title = {A biologically-inspired reinforcement learning based intelligent distributed flocking control for Multi-Agent Systems in presence of uncertain system and dynamic environment},
journal = {IFAC Journal of Systems and Control},
volume = {13},
pages = {100096},
year = {2020},
issn = {2468-6018},
doi = {https://doi.org/10.1016/j.ifacsc.2020.100096},
url = {https://www.sciencedirect.com/science/article/pii/S2468601820300146},
author = {Mohammad Jafari and Hao Xu and Luis Rodolfo Garcia Carrillo},
keywords = {Biologically-inspired reinforcement learning based intelligent control, BELBIC, Flocking control, Multi-Agent Systems},
abstract = {In this paper, we investigate the real-time flocking control of Multi-Agent Systems (MAS) in the presence of system uncertainties and dynamic environment. To handle the impacts from system uncertainties and dynamic environment, a novel reinforcement learning technique, which is appropriate for real-time implementation, has been integrated with multi-agent flocking control in this paper. The Brain Emotional Learning Based Intelligent Controller (BELBIC) is a biologically-inspired reinforcement learning-based controller relying on a computational model of emotional learning in the mammalian limbic system. The learning capabilities, multi-objective properties, and low computational complexity of BELBIC make it a very promising learning technique for implementation in real-time applications. Firstly, a novel brain emotional learning-based flocking control structure is proposed. Then, the real-time update laws are developed to tune the emotional signals based on real-time operational data. It is important to note that this data-driven reinforcement learning approach relaxes the requirement for system dynamics and effectively handle the uncertain impacts of the environment. Using the tuned emotional signals, the optimal flocking control can be obtained. The Lyapunov analysis has been used to prove the convergence of the proposed design. The effectiveness of the proposed design is also demonstrated through numerical and experimental results based on the coordination of multiple Unmanned Aerial Vehicles (UAVs).}
}
@article{XUE2021,
title = {3D reconstruction and automatic leakage defect quantification of metro tunnel based on SfM-Deep learning method},
journal = {Underground Space},
year = {2021},
issn = {2467-9674},
doi = {https://doi.org/10.1016/j.undsp.2021.08.004},
url = {https://www.sciencedirect.com/science/article/pii/S2467967421000751},
author = {Yadong Xue and Peizhe Shi and Fei Jia and Hongwei Huang},
keywords = {3D reconstruction, Leakage defect quantification, Visualization, Metro tunnel, Structure from motion, Deep learning},
abstract = {Various structural defects deteriorate tunnel operation status and threaten public safety. Current tunnel inspection methods face problems of low efficiency, high equipment expense, and difficult data management. Combining the deep learning model and the 3D reconstruction method based on structure from motion (SfM), this paper proposes a novel SfM-Deep learning method for tunnel inspection. The high-quality 3D tunnel model is constructed by using images taken every 1 m along the longitudinal direction. The instance segmentation of leakage in longitudinal images is realized using the mask region-based convolutional neural network deep learning model. The SfM-Deep learning method projects the texture of the images after defect recognition to the 3D model and realizes the visualization of leakage defects. By projecting the model to the design cylindrical surface and expanding it, the tunnel leakage area is quantified. Through its practical application in a Shanghai metro shield tunnel, the reliability of the proposed method was verified. The novel SfM-Deep learning method can help engineers efficiently carry out intelligent tunnel detection.}
}
@article{DAI2020346,
title = {Automatic obstacle avoidance of quadrotor UAV via CNN-based learning},
journal = {Neurocomputing},
volume = {402},
pages = {346-358},
year = {2020},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2020.04.020},
url = {https://www.sciencedirect.com/science/article/pii/S0925231220305853},
author = {Xi Dai and Yuxin Mao and Tianpeng Huang and Na Qin and Deqing Huang and Yanan Li},
keywords = {Obstacle avoidance, Unmanned aerial vehicle, Convolutional neural network, Collision probability},
abstract = {In this paper, a CNN-based learning scheme is proposed to enable a quadrotor unmanned aerial vehicle (UAV) to avoid obstacles automatically in unknown and unstructured environments. In order to reduce the decision delay and to improve the robustness for the UAV, a two-stage end-to-end obstacle avoidance architecture is designed, where a forward-facing monocular camera is used only. In the first stage, a convolutional neural network (CNN)-based model is adopted as the prediction mechanism. Utilizing three effective operations, namely depthwise convolution, group convolution and channel split, the model predicts the steering angle and the collision probability simultaneously. In the second stage, the control mechanism maps the steering angle to an instruction that changes the yaw angle of the UAV. Consequently, when the UAV encounters an obstacle, it can avoid collision by steering automatically. Meanwhile, the collision probability is mapped as a forward speed to maintain the flight or stop going forward. The presented automatic obstacle avoidance scheme of quadrotor UAV is verified by several indoor/outdoor tests, where the feasibility and efficacy have been demonstrated clearly. The novelties of the method lie in its low sensor requirement, light-weight network structure, strong learning ability and environmental adaptability.}
}
@article{YOO201713216,
title = {Learning communication delay patterns for remotely controlled UAV networks**This work has been supported in part by the Knut and Alice Wallenberg Foundation the Swedish Research Council (VR) and the Swedish Foundation for Strategic Research, including the SSF-NRF Sweden-Korea research program.},
journal = {IFAC-PapersOnLine},
volume = {50},
number = {1},
pages = {13216-13221},
year = {2017},
note = {20th IFAC World Congress},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2017.08.1954},
url = {https://www.sciencedirect.com/science/article/pii/S2405896317325843},
author = {Jaehyun Yoo and Karl H. Johansson},
keywords = {Networked robotics, unmanned aerial vehicles, time-delay systems, machine learning},
abstract = {This paper deals with collaborative unmanned aerial vehicles (UAVs) that are remotely controlled from a cloud server. The main contribution is to apply machine learning technique to find a pattern of network-induced effects on maneuvers of UAVs, in order to compensate for time delays and packet losses in remote communication. As machine learning technique, a Gaussian process (GP) based approach is employed due to its computational simplicity and flexibility in modelling complex expressions using a small number of parameters. We combine a deterministic compensation for an enhanced GP model to overcome a problem of the lack of training data at the beginning of training phase. This is done by defining training data input as a set of delayed observation and the deterministic compensation term, and by training the GP on residual between the true state and the input set. The proposed algorithm is evaluated to collaborative trajectory tracking of two UAVs. Simulations are performed for various delays and tracking scenarios. It is shown that the better tracking results are achieved compared to a conventional linear compensation algorithm.}
}
@article{DAI2019114,
title = {The multi-objective deployment optimization of UAV-mounted cache-enabled base stations},
journal = {Physical Communication},
volume = {34},
pages = {114-120},
year = {2019},
issn = {1874-4907},
doi = {https://doi.org/10.1016/j.phycom.2019.03.007},
url = {https://www.sciencedirect.com/science/article/pii/S1874490718303033},
author = {Haibo Dai and Haiyang Zhang and Baoyun Wang and Luxi Yang},
keywords = {Unmanned aerial vehicle, Deployment, Reinforcement learning, Caching, Multi-objective optimization},
abstract = {The deployment of unmanned aerial vehicle (UAV)-mounted base stations is emerging as an effective solution for providing wireless communication service to ground terminals (GTs) which have failed to be associated with ground base stations for some reason. Meanwhile, with the propose of reducing the transmission latency and easing the load of backhaul links between UAVs and the core network, UAVs are equipped with the ability of caching popular contents in the storage of base stations. In this paper, we investigate the efficient deployment problem of UAVs (such as transmitting power, number of UAVs, locations and caching) while guaranteeing the quality of service requirements. In this case, the UAV plays the role of a coordinator to provide high-quality communication service for GTs as well as maximize the benefit of caching. However, there exists an intractable issue that UAVs need to consider the optimization problem of multiple performance metrics with various types of optimization variables. To tackle the challenge, we propose a reinforcement learning-based approach to solve the multi-objective deployment problem while maintaining the optimal tradeoff between power consumption and backhaul saving. Numerical results evaluate the performance of the proposed algorithm.}
}
@article{NAVARRO201961,
title = {Sense and Avoid using Hybrid Convolutional and Recurrent Neural Networks},
journal = {IFAC-PapersOnLine},
volume = {52},
number = {12},
pages = {61-66},
year = {2019},
note = {21st IFAC Symposium on Automatic Control in Aerospace ACA 2019},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2019.11.070},
url = {https://www.sciencedirect.com/science/article/pii/S2405896319310055},
author = {Daniel Vidal Navarro and Chang-Hun Lee and Antonios Tsourdos},
keywords = {Sense, Avoid, neural networks, deep learning, computer vision, Kalman filter, range estimation, UAV},
abstract = {This work develops a Sense and Avoid strategy based on a deep learning approach to be used by UAVs using only one electro-optical camera to sense the environment. Hybrid Convolutional and Recurrent Neural Networks (CRNN) are used for object detection, classification and tracking whereas an Extended Kalman Filter (EKF) is considered for relative range estimation. Probabilistic conflict detection and geometric avoidance trajectory are considered for the last stage of this technique. The results show that the considered deep learning approach can work faster than other state-of-the-art computer vision methods. They also show that the collision can be successfully avoided considering design parameters that can be adjusted to adapt to different scenarios.}
}
@article{GUERBER2021102940,
title = {Machine Learning and Software Defined Network to secure communications in a swarm of drones},
journal = {Journal of Information Security and Applications},
volume = {61},
pages = {102940},
year = {2021},
issn = {2214-2126},
doi = {https://doi.org/10.1016/j.jisa.2021.102940},
url = {https://www.sciencedirect.com/science/article/pii/S2214212621001551},
author = {Christophe Guerber and Mickaël Royer and Nicolas Larrieu},
keywords = {FANET, SDN, AODV, Security architecture, Machine Learning, Random Forest Classifier},
abstract = {As drones become more and more frequent in industry and perhaps tomorrow in everyday life, the variety and sensitivity of their missions will increase. Securing the communication taking place with the drones and especially in the network of a swarm, is of primary importance to allow a safe integration of Unmanned Aerial Vehicles into air traffic. Drones are subject to a range of attacks, from GPS jamming to application bug exploits. Among these attacks, and irrespective to whether they have already been implemented or not, communication is one of the main contributors, both as a vector and as a target. In this article, we use previous work on security threats concerning drones to identify two main types of attack in a network of drones: intrusion from the outside and network usage from inside. We demonstrate the robustness of the Software Defined Network (SDN) architecture facing most common attacks from the outside. In addition, we propose a traffic injection detection technique and corresponding countermeasures based on SDN flow counters. Finally, we present an innovative machine learning solution based on Random Forest Classifier to address insider attacks, relying solely on flow creation events. We propose two specific features that characterizes the activity in the network. They allow detecting common network attacks such as denial of service, port scanning and brute force and are easily available to the controller. Detection performance of these abnormal behaviors are promising, both in terms of true positive and false negative, and in terms of detection delay. Detection of these common attacks will allow tightening of security in such wireless network by denying further access to the network by rogue nodes.}
}
@article{ELLENBERG2016155,
title = {Bridge deck delamination identification from unmanned aerial vehicle infrared imagery},
journal = {Automation in Construction},
volume = {72},
pages = {155-165},
year = {2016},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2016.08.024},
url = {https://www.sciencedirect.com/science/article/pii/S0926580516301789},
author = {A. Ellenberg and A. Kontsos and F. Moon and I. Bartoli},
abstract = {The rapid, cost-effective, and non-disruptive assessment of bridge deck condition has emerged as a critical challenge for bridge maintenance. Deck delaminations are a common form of deterioration which has been assessed, historically, through chain-drag techniques and more recently through nondestructive evaluation (NDE) including both acoustic and optical methods. Although NDE methods have proven to be capable to provide information related to the existence of delaminations in bridge decks, many of them are time-consuming, labor-intensive, expensive, while they further require significant disruptions to traffic. In this context, this article demonstrates the capability of unmanned aerial vehicles (UAVs) equipped with both color and infrared cameras to rapidly and effectively detect and estimate the size of regions where subsurface delaminations exist. To achieve this goal, a novel image post-processing algorithm was developed to use such multispectral imagery obtained by a UAV. To evaluate the capabilities of the presented approach, a bridge deck mockup with pre-manufactured defects was tested. The major advantages of the presented approach include its capability to rapidly identify locations where delaminations exist, as well as its potential to automate bridge-deck related damage detection procedures and further guide investigations using other higher accuracy and ground-based approaches.}
}
@article{ZHOU2020105369,
title = {Detection of ground straw coverage under conservation tillage based on deep learning},
journal = {Computers and Electronics in Agriculture},
volume = {172},
pages = {105369},
year = {2020},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2020.105369},
url = {https://www.sciencedirect.com/science/article/pii/S0168169919325517},
author = {Deyi Zhou and Mao Li and Yang Li and Jiangtao Qi and Kai Liu and Xu Cong and Xinliang Tian},
keywords = {Straw coverage, Conservation tillage, Semantic segmentation, Remote sensing, U-Net},
abstract = {Given the technical requirement for the fast acquisition of ground straw coverage from conservation tillage fields, we investigated the accurate detection of straw coverage by using unmanned aerial vehicle (UAV) low-altitude remote sensing images. Ground images of farmlands under conservation tillage were acquired using low-altitude UAV. A semantic segmentation algorithm of straw coverage was established with the improved U-Net on ResNet18. The algorithm was evaluated and compared with VGG11–U-Net (the algorithm with VGG11 as the U-Net extraction module), triangle algorithm (TRIANGLER) and ‘RGB, HSV and grey + support vector machine (SVM)’ (the algorithm based on multicolour space information fusion combined with SVM). The mean absolute deviation of field straw coverage determined by the new algorithm was 3.56%, which was lower than that by other algorithms. Thus, the new algorithm offers data for the rapid acquisition of ground straw coverage from farmlands under conservation tillage.}
}
@article{KERKECH2018237,
title = {Deep leaning approach with colorimetric spaces and vegetation indices for vine diseases detection in UAV images},
journal = {Computers and Electronics in Agriculture},
volume = {155},
pages = {237-243},
year = {2018},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2018.10.006},
url = {https://www.sciencedirect.com/science/article/pii/S0168169918310044},
author = {Mohamed Kerkech and Adel Hafiane and Raphael Canals},
keywords = {Deep learning, CNN, UAV, Image processing, Color spaces, Vegetation indices, Precision agriculture},
abstract = {Detection of symptoms in grape leaves is a very important factor in preventing a serious disease. An epidemic spread in vineyards has huge economic consequences and therefore it is considered a major challenge for viticulture. Automatic detection of vine diseases can play an important role in addressing the issue of diseases management. This study deals with the problem of identifying infected areas of grapevines using Unmanned Aerial Vehicles (UAV) images in the visible domain. In this paper we propose a method based on Convolutional neural network (CNN) and color information to detect symptoms in the vine yards. We studied and compared performances of CNNs using different color spaces, vegetation indices, as well as the combination of both information. The obtained results showed that CNNs with YUV color space combined with ExGR vegetation index, and CNNs with a combination of ExG, ExR, ExGR vegetation indices yield the best results with accuracy more than 95.8%.}
}
@article{HUERTAHERRAIZ2020334,
title = {Photovoltaic plant condition monitoring using thermal images analysis by convolutional neural network-based structure},
journal = {Renewable Energy},
volume = {153},
pages = {334-348},
year = {2020},
issn = {0960-1481},
doi = {https://doi.org/10.1016/j.renene.2020.01.148},
url = {https://www.sciencedirect.com/science/article/pii/S0960148120301701},
author = {Álvaro {Huerta Herraiz} and Alberto {Pliego Marugán} and Fausto Pedro {García Márquez}},
keywords = {Photovoltaic solar panels, Artificial neural networks, Unmanned aerial vehicle, Thermography, Convolutional neural network, Reliability},
abstract = {The size and the complexity of photovoltaic solar power plants are increasing, and it requires an advanced and robust condition monitoring systems for ensuring their reliability. This paper proposes a novel method for faults detection in photovoltaic panels employing a thermographic camera embedded in an unmanned aerial vehicle. The large amount of data generated by these systems must be processed and analyzed. This paper presents a novel approach to identify panels to detect hot spots, and to set their locations. Two novels region-based convolutional neural networks are unified to generate a robust detection structure. The main contribution is the combination of thermography and telemetry data to provide a response of the panel condition monitoring. The data are acquired and then automatically processed, allowing fault detection during the inspection. A detailed description of the methodology is presented, including the different stages to build the neural networks, i.e. the training process, the acquisition and processing of data and the outcomes generation. A thermographic inspection of a real photovoltaic solar plant is done to validate the proposed methodology. The accuracy, the efficiency and the performance of the approach under different real scenarios are evaluated statistically obtaining satisfactory results.}
}
@article{SOHEGE20208175,
title = {Deep Reinforcement Learning and Randomized Blending for Control under Novel Disturbances},
journal = {IFAC-PapersOnLine},
volume = {53},
number = {2},
pages = {8175-8180},
year = {2020},
note = {21st IFAC World Congress},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2020.12.2313},
url = {https://www.sciencedirect.com/science/article/pii/S2405896320329803},
author = {Yves Sohège and Gregory Provan and Marcos Quiñones-Grueiro and Gautam Biswas},
keywords = {Design of fault tolerant/reliable systems, Fault accommodation, Reconfiguration strategies, Methods based on neural networks and/or fuzzy logic for FDI},
abstract = {Enabling autonomous vehicles to maneuver in novel scenarios is a key unsolved problem. A well-known approach, Weighted Multiple Model Adaptive Control (WMMAC), uses a set of pre-tuned controllers and combines their control actions using a weight vector. Although WMMAC offers an improvement to traditional switched control in terms of smooth control oscillations, it depends on accurate fault isolation and cannot deal with unknown disturbances. A recent approach avoids state estimation by randomly assigning the controller weighting vector; however, this approach uses a uniform distribution for control-weight sampling, which is sub-optimal compared to state-estimation methods. In this article, we propose a framework that uses deep reinforcement learning (DRL) to learn weighted control distributions that optimize the performance of the randomized approach for both known and unknown disturbances. We show that RL-based randomized blending dominates pure randomized blending, a switched FDI-based architecture and pre-tuned controllers on a quadcopter trajectory optimisation task in which we penalise deviations in both position and attitude.}
}
@article{ELHAKI2021107128,
title = {A novel model-free robust saturated reinforcement learning-based controller for quadrotors guaranteeing prescribed transient and steady state performance},
journal = {Aerospace Science and Technology},
volume = {119},
pages = {107128},
year = {2021},
issn = {1270-9638},
doi = {https://doi.org/10.1016/j.ast.2021.107128},
url = {https://www.sciencedirect.com/science/article/pii/S1270963821006386},
author = {Omid Elhaki and Khoshnam Shojaei},
keywords = {Reinforcement learning, Saturation function, Prescribed performance, Actuator saturation, Quadrotor},
abstract = {For the purpose of improving the performance of trajectory tracking for quadrotors with the control input saturation, a novel model-free saturated prescribed performance reinforcement learning framework is proposed in the presence of the model uncertainties, nonlinearities and external disturbances. In this paper, saturation functions are employed to deal with input saturation, and the actuator's saturation nonlinearity is compensated by an intelligent method to decrease the saturation effects. Moreover, the prescribed performance control is utilized to ensure an adjustable transient and steady state response for the tracking errors. Besides, adaptive robust controllers are introduced to handle the effects of external disturbances online. A novel controller is proposed in collaboration with a reinforcement learning method based on actor-critic neural networks. The actor neural network is employed to estimate nonlinearities, actuator saturation nonlinearity, and model uncertainties, and the critic neural network is applied to estimate the reinforcement signals, which regulates the control action of the actor neural network online. The proposed actor-critic-based control structure benefits from a model-free calculation and only depends on the measurable signals of the closed-loop system. This freedom from system dynamics leads to a significant low computational load for the controller and, therefore, the proposed control method is computationally cost-effective. The adaptive robust controllers and the proposed actor-critic structures are trained online, and the convergence behavior of their learning laws is investigated in the course of stability examination. For the proof of stability, Lyapunov's direct method is used to show that all error variables of the closed-loop nonlinear control system are uniformly ultimately bounded. Finally, simulations along with some quantitative comparisons verify the efficiency and usefulness of the proposed control scheme.}
}
@article{KUMAR2021100549,
title = {Efficient Maize Tassel-Detection Method using UAV based remote sensing},
journal = {Remote Sensing Applications: Society and Environment},
volume = {23},
pages = {100549},
year = {2021},
issn = {2352-9385},
doi = {https://doi.org/10.1016/j.rsase.2021.100549},
url = {https://www.sciencedirect.com/science/article/pii/S2352938521000859},
author = {Ajay Kumar and Sai Vikas Desai and Vineeth N. Balasubramanian and P. Rajalakshmi and Wei Guo and B. {Balaji Naik} and M. Balram and Uday B. Desai},
keywords = {Automatic annotation, Labeled data, UAV based Remote sensing, Tassel detection, Maize crop},
abstract = {Regular monitoring is worthwhile to maintain a healthy crop. Historically, the manual observation was used to monitor crops, which is time-consuming and often costly. The recent boom in the development of Unmanned Aerial Vehicles (UAVs) has established a quick and easy way to monitor crops. UAVs can cover a wide area in a few minutes and obtain useful crop information with different sensors such as RGB, multispectral, hyperspectral cameras. Simultaneously, Convolutional Neural Networks (CNNs) have been effectively used for various vision-based agricultural monitoring activities, such as flower detection, fruit counting, and yield estimation. However, Convolutional Neural Network (CNN) requires a massive amount of labeled data for training, which is not always easy to obtain. Especially in agriculture, generating labeled datasets is time-consuming and exhaustive since interest objects are typically small in size and large in number. This paper proposes a novel method using k-means clustering with adaptive thresholding for detecting maize crop tassels to address these issues. The qualitative and quantitative analysis of the proposed method reveals that our method performs close to reference approaches and has an advantage over computational complexity. The proposed method detected and counted tassels with precision: 0.97438, recall: 0.88132, and F1 Score: 0.92412. In addition, using maize tassel detection from UAV images as the task in this paper, we propose a semi-automatic image annotation method to create labeled datasets of the maize crop easily. Based on the proposed method, the developed tool can be used in conjunction with a machine learning model to provide initial annotations for a given image, modified further by the user. Our tool's performance analysis reveals promising savings in annotation time, enabling the rapid production of maize crop labeled datasets.}
}
@article{DEROSA2021105880,
title = {Predicting pasture biomass using a statistical model and machine learning algorithm implemented with remotely sensed imagery},
journal = {Computers and Electronics in Agriculture},
volume = {180},
pages = {105880},
year = {2021},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2020.105880},
url = {https://www.sciencedirect.com/science/article/pii/S0168169920330854},
author = {Daniele {De Rosa} and Bruno Basso and Matteo Fasiolo and Johannes Friedl and Bill Fulkerson and Peter R. Grace and David W. Rowlings},
keywords = {Pasture, Generalised additive model, Random forest, Remote sensing, UAV, Multispectral imagery},
abstract = {Accurate daily estimates of pasture biomass can improve the profitability of pasture-based dairy system by optimising input of feed supplements and pasture utilisation. However, obtaining accurate pasture mass estimates is a laborious and time-consuming task. The aim of this study was to test the performance of an integrated method combining remote sensing imagery acquired with a multispectral camera mounted on an unmanned aerial vehicle (UAV), statistical models (generalised additive model, GAM) and machine learning algorithms (random forest, RF) implemented with publicly available data to predict future pasture biomass loads. This study showed that using observations of pasture growth along with environmental and pasture management variables enabled both models, GAM and RF to predict the pre-grazing pasture biomass production at field scale with an average error below 20%. If predictive variables (i.e. post-grazing pasture biomass) were excluded, model performance was reduced, generating errors up to 40%. The post-grazing biomass information at high spatial resolution (<1 m) acquired with the UAV-multispectral camera system was used as predictive variable for future pasture biomass. With the inclusion of the spatially explicit post-grazing biomass variable both models accurately predicted the pre-grazing pasture biomass with an error of 27.7% and 22.9% for RF and GAM, respectively. However, the GAM model performed better than RF in reproducing the spatial variability of pre-grazing pasture biomass. This study demonstrates the capability of statistical and machine learning models implemented with UAV or manually obtained pasture information along with publicly available data to accurately predict future pasture biomass at field and farm scale.}
}
@article{MATASSINI2016308,
title = {Adaptive Control with Neural Networks-based Disturbance Observer for a Spherical UAV},
journal = {IFAC-PapersOnLine},
volume = {49},
number = {17},
pages = {308-313},
year = {2016},
note = {20th IFAC Symposium on Automatic Control in AerospaceACA 2016},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2016.09.053},
url = {https://www.sciencedirect.com/science/article/pii/S2405896316315257},
author = {Tommaso Matassini and Hyo-Sang Shin and Antonios Tsourdos and Mario Innocenti},
keywords = {Spherical UAV, model uncertainties and external disturbances, disturbance observer, adaptive control, neural networks},
abstract = {This paper develops a control scheme for a Spherical Unmanned Aerial Vehicle (UAV) which can be used in complex scenarios where traditional navigation and communications systems would not succeed. The proposed scheme is based on the nonlinear control theory combined with Adaptive Neural-Networks Disturbance Observer (NN-DOB) and controls the attitude and altitude of the UAV in presence of model uncertainties and external disturbances. The NN-DOB can effectively estimate the uncertainties without the knowledge of their bounds and the control system stability is proven using Lyapunov’s stability theorems. Numerical simulation results demonstrate the validity of the proposed method on the UAV under model uncertainties and external disturbances.}
}
@article{GONCALVES2021,
title = {Automatic detection of Acacia longifolia invasive species based on UAV-acquired aerial imagery},
journal = {Information Processing in Agriculture},
year = {2021},
issn = {2214-3173},
doi = {https://doi.org/10.1016/j.inpa.2021.04.007},
url = {https://www.sciencedirect.com/science/article/pii/S2214317321000317},
author = {Carolina Gonçalves and Pedro Santana and Tomás Brandão and Magno Guedes},
keywords = {Pattern recognition, Convolutional neural networks, Invasive plants, },
abstract = {The Acacia longifolia species is known for its rapid growth and dissemination, causing loss of biodiversity in the affected areas. In order to avoid the uncontrolled spread of this species, it is important to effectively monitor its distribution on the agroforestry regions. For this purpose, this paper proposes the use of Convolutional Neural Networks (CNN) for the detection of Acacia longifolia, from images acquired by an unmanned aerial vehicle. Two models based on the same CNN architecture were elaborated. One classifies image patches into one of nine possible classes, which are later converted into a binary model; this model presented an accuracy of 98.6% and 98.5% in the validation and training sets, respectively. The second model was trained directly for binary classification and showed an accuracy of 98.8% and 98.7% for the validation and test sets, respectively. The results show that the use of multiple classes, useful to provide the aerial vehicle with richer semantic information regarding the environment, does not hamper the accuracy of Acacia longifolia detection in the classifier’s primary task. The presented system also includes a method for increasing classification’s accuracy by consulting an expert to review the model’s predictions on an automatically selected sub-set of the samples.}
}
@article{LU2021101393,
title = {Performance analysis of cache-aided UAV relaying networks},
journal = {Physical Communication},
volume = {47},
pages = {101393},
year = {2021},
issn = {1874-4907},
doi = {https://doi.org/10.1016/j.phycom.2021.101393},
url = {https://www.sciencedirect.com/science/article/pii/S1874490721001300},
author = {Bowen Lu and Zhulun Yang and Kai Kang and Zehua Yu and Xiangfei Feng and Xutao Li},
keywords = {Outage performance, Cache-aided relay, UAV relay},
abstract = {In this work, we analyze the effect of relaying network where unmanned aerial vehicles (UAVs) act as cache-aided relay nodes. Unmanned aerial vehicle (UAV) has high mobility, which can be flexibly scheduled when unable to communicate so that it can act as a wireless relay to assist communication. It can provide a more flexible deployment mode in different application scenarios to improve the performance of communication. What is more, how to transform the dynamic characteristics of UAVs into channel characteristics is also a challenge. To be more specific, UAVs act as decoded-and-forward (DF) relays to assist the wireless communication between the source and destination, and the speed and flying height remains unchanged. The UAVs are equipped with a wireless cache, which can provide reliable services and expand the channel capacity to reduce the outage probability of the network. Experimental and simulation results verify the effect of UAVs with cache on the outage performance in relaying networks.}
}
@article{NEVAVUORI2019104859,
title = {Crop yield prediction with deep convolutional neural networks},
journal = {Computers and Electronics in Agriculture},
volume = {163},
pages = {104859},
year = {2019},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2019.104859},
url = {https://www.sciencedirect.com/science/article/pii/S0168169919306842},
author = {Petteri Nevavuori and Nathaniel Narra and Tarmo Lipping},
keywords = {Crop yield prediction, Convolutional neural network, Wheat, Barley, UAV, Multispectral, NDVI, Growth phase},
abstract = {Using remote sensing and UAVs in smart farming is gaining momentum worldwide. The main objectives are crop and weed detection, biomass evaluation and yield prediction. Evaluating machine learning methods for remote sensing based yield prediction requires availability of yield mapping devices, which are still not very common among farmers. In this study Convolutional Neural Networks (CNNs) – a deep learning methodology showing outstanding performance in image classification tasks – are applied to build a model for crop yield prediction based on NDVI and RGB data acquired from UAVs. The effect of various aspects of the CNN such as selection of the training algorithm, depth of the network, regularization strategy, and tuning of the hyperparameters on the prediction efficiency are tested. Using the Adadelta training algorithm, L2 regularization with early stopping and a CNN with 6 convolutional layers, mean absolute error (MAE) in yield prediction of 484.3 kg/ha and mean absolute percentage error (MAPE) of 8.8% was achieved for data acquired during the early period of the growth season (i.e., in June of 2017, growth phase <25%) with RGB data. When using data acquired later in July and August of 2017 (growth phase >25%), MAE of 624.3 kg/ha (MAPE: 12.6%) was obtained. Significantly, the CNN architecture performed better with RGB data than the NDVI data.}
}
@article{WANG2022108690,
title = {Optimization for computational offloading in multi-access edge computing: A deep reinforcement learning scheme},
journal = {Computer Networks},
volume = {204},
pages = {108690},
year = {2022},
issn = {1389-1286},
doi = {https://doi.org/10.1016/j.comnet.2021.108690},
url = {https://www.sciencedirect.com/science/article/pii/S1389128621005569},
author = {Jian Wang and Hongchang Ke and Xuejie Liu and Hui Wang},
keywords = {Multi-access edge computing, Computation offloading, Markov decision process, Reinforcement learning},
abstract = {Owing to their limited computing power and battery level, wireless users (WUs) can hardly handle compute-intensive workflows by the local processor. Multi-access edge computing (MEC) servers attached to base stations have ample computing power and communication resources, which can be used to address the computation tasks or workloads of WUs. In this study, we design a framework with multiple static and vehicle-assisted MEC servers to handle the workloads offloaded by WUs. For obtaining the optimal computation offloading scheme to minimize the weighted sum cost, including transmission and execution cost, energy consumption cost, and communication bandwidth cost, we model the offloading decision optimization problem as a Markov decision process (MDP). Then, we propose a partial computation offloading scheme based on reinforcement learning (RL) to address the absence of priori knowledge. The proposed scheme can learn the optimal offloading decision based on stochastic workload arrival, the changing channel state, and the dynamic distance between WUs and the edge servers. Moreover, to avoid the curse of dimensionality caused by the complex state and action spaces, we present an improved computation offloading method based on deep RL (DRL) to learn the optimal offloading policy using deep neural networks. Extensive numerical results illustrate that the proposed algorithms based on RL and DRL can autonomously learn the optimal computation offloading policy with no priori knowledge, and their performance are better than that of four baselines algorithms.}
}
@article{GOMEZSELVARAJ2020110,
title = {Detection of banana plants and their major diseases through aerial images and machine learning methods: A case study in DR Congo and Republic of Benin},
journal = {ISPRS Journal of Photogrammetry and Remote Sensing},
volume = {169},
pages = {110-124},
year = {2020},
issn = {0924-2716},
doi = {https://doi.org/10.1016/j.isprsjprs.2020.08.025},
url = {https://www.sciencedirect.com/science/article/pii/S0924271620302410},
author = {Michael {Gomez Selvaraj} and Alejandro Vergara and Frank Montenegro and Henry {Alonso Ruiz} and Nancy Safari and Dries Raymaekers and Walter Ocimati and Jules Ntamwira and Laurent Tits and Aman Bonaventure Omondi and Guy Blomme},
keywords = {Artificial Intelligence, Banana detection, Deep learning, Disease detection, High-resolution satellite image, Surveillance, UAV images},
abstract = {Front-line remote sensing tools, coupled with machine learning (ML), have a significant role in crop monitoring and disease surveillance. Crop type classification and a disease early warning system are some of these remote sensing applications that provide precise, timely, and cost-effective information at different spatial, temporal, and spectral resolutions. To our knowledge, most disease surveillance systems focus on a single-sensor based solutions and lagging the integration of multiple information sources. Moreover, monitoring larger landscapes using unmanned aerial vehicles (UAV) are challenging, and, therefore combining high resolution satellite imagery data with advanced machine learning (ML) models through the use of mobile apps could help detect and classify banana plants and provide more information on its overall health status. In this study, we classified banana under mixed-complex African landscapes through pixel-based classifications and ML models derived from multi-level satellite images (Sentinel 2, PlanetScope and WorldView-2) and UAV (MicaSense RedEdge) platforms. Our pixel-based classification from random forest (RF) model using combined features of vegetation indices (VIs) and principal component analysis (PCA) showed up to 97% overall accuracy (OA) with less than 10% omission and commission errors (OE and CE) and Kappa coefficient of 0.96 in high resolution multispectral images. We used UAV-RGB aerial images from DR Congo and Republic of Benin fields to develop a mixed-model system combining object detection model (RetinaNet) and a custom classifier for simultaneous banana localization and disease classification. Their accuracies were tested using different performance metrics. Our UAV-RGB mixed-model revealed that the developed object detection and classification model successfully classified healthy and diseased plants with 99.4%, 92.8%, 93.3% and 90.8% accuracy for the four classes: banana bunchy top disease (BBTD), Xanthomonas Wilt of Banana (BXW), healthy banana cluster and individual banana plants, respectively. These approaches of aerial image-based ML models have high potential to provide a decision support system for major banana diseases in Africa.}
}
@article{MA201514,
title = {Training set size, scale, and features in Geographic Object-Based Image Analysis of very high resolution unmanned aerial vehicle imagery},
journal = {ISPRS Journal of Photogrammetry and Remote Sensing},
volume = {102},
pages = {14-27},
year = {2015},
issn = {0924-2716},
doi = {https://doi.org/10.1016/j.isprsjprs.2014.12.026},
url = {https://www.sciencedirect.com/science/article/pii/S0924271615000192},
author = {Lei Ma and Liang Cheng and Manchun Li and Yongxue Liu and Xiaoxue Ma},
keywords = {GEOBIA, OBIA, Scale, Training set size, UAV, Very High Resolution (VHR)},
abstract = {Unmanned Aerial Vehicle (UAV) has been used increasingly for natural resource applications in recent years due to their greater availability and the miniaturization of sensors. In addition, Geographic Object-Based Image Analysis (GEOBIA) has received more attention as a novel paradigm for remote sensing earth observation data. However, GEOBIA generates some new problems compared with pixel-based methods. In this study, we developed a strategy for the semi-automatic optimization of object-based classification, which involves an area-based accuracy assessment that analyzes the relationship between scale and the training set size. We found that the Overall Accuracy (OA) increased as the training set ratio (proportion of the segmented objects used for training) increased when the Segmentation Scale Parameter (SSP) was fixed. The OA increased more slowly as the training set ratio became larger and a similar rule was obtained according to the pixel-based image analysis. The OA decreased as the SSP increased when the training set ratio was fixed. Consequently, the SSP should not be too large during classification using a small training set ratio. By contrast, a large training set ratio is required if classification is performed using a high SSP. In addition, we suggest that the optimal SSP for each class has a high positive correlation with the mean area obtained by manual interpretation, which can be summarized by a linear correlation equation. We expect that these results will be applicable to UAV imagery classification to determine the optimal SSP for each class.}
}
@article{KAYNAK201063,
title = {FUZZY LOGIC BASED AUTONOMOUS LANDING SYSTEM FOR UNMANNED AERIAL VEHICLES},
journal = {IFAC Proceedings Volumes},
volume = {43},
number = {15},
pages = {63-70},
year = {2010},
note = {18th IFAC Symposium on Automatic Control in Aerospace},
issn = {1474-6670},
doi = {https://doi.org/10.3182/20100906-5-JP-2022.00012},
url = {https://www.sciencedirect.com/science/article/pii/S1474667015318176},
author = {Okyay Kaynak},
keywords = {Autonomous Landing System for UAVs, Fuzzy Logic Controller},
abstract = {Abstract
This paper is concerned with final approach and touch-down periods of UAVs and proposes a fuzzy logic based autonomous landing system controller. Three fuzzy logic modules are developed under the main landing system for the control of the horizontal and the vertical positions of the aircraft against the runway under a TACAN (Tactical Air Navigation) approach. The performance of the fuzzy logic based controllers is evaluated using MATLAB's standard configuration and the Aerosim Aeronautical Simulation Block Set which provides a complete set of tools for rapid development of 6 degree-of-freedom nonlinear generic manned/unmanned aerial vehicle models. Additionally, FlightGear Flight Simulator and GMS aircraft instruments are deployed in order to get visual outputs that aid the designer in evaluating the performance and the potential of the controllers. The simulated test flights on an Aerosonde indicate the capability of the approach in achieving the desired performance despite the simple design procedure.}
}
@article{WANG2021106320,
title = {An image segmentation method based on deep learning for damage assessment of the invasive weed Solanum rostratum Dunal},
journal = {Computers and Electronics in Agriculture},
volume = {188},
pages = {106320},
year = {2021},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2021.106320},
url = {https://www.sciencedirect.com/science/article/pii/S0168169921003379},
author = {Qifan Wang and Man Cheng and Xuepeng Xiao and Hongbo Yuan and Jiajun Zhu and Caihu Fan and Jinlin Zhang},
keywords = {Invasive weed, UAV, Convolutional neural network, Image segmentation, Damage assessment},
abstract = {Solanum rostratum Dunal is a common invasive weed that can cause significant harm to local natural environments and ecosystems. The prerequisite for preventing and managing the invasion of Solanum rostratum Dunal is timely detection and reasonable assessment of its damage level. Therefore, this paper proposes a deep learning-based image segmentation method for the detection of the invasion degree of Solanum rostratum Dunal. The Solanum rostratum Dunal images are acquired by UAV and then cropped into sub-images of the same size following a specific processing method. The sub-images are fed into a U-Net based convolutional neural network DeepSolanum-Net for processing. The pixels belonging to the Solanum rostratum Dunal plants are extracted and labeled after the sub-images pass through the DeepSolanum-Net. All the processed sub-images are stitched and reduced to the size of the original image, and all the target pixels belonging to the Solanum rostratum Dunal in the original image are segmented out from the background image. The coverage rate and the area covered by the Solanum rostratum Dunal on the ground are calculated based on the image segmentation results and the flight altitude of the UAV. A field test is executed and the test results demonstrate that the recognition precision of effective pixels of Solanum rostratum Dunal plants reach 89.95% and the recall rate reach 90.3% when the proposed method is used.}
}
@article{LI2021107406,
title = {Vehicle detection from road image sequences for intelligent traffic scheduling},
journal = {Computers & Electrical Engineering},
volume = {95},
pages = {107406},
year = {2021},
issn = {0045-7906},
doi = {https://doi.org/10.1016/j.compeleceng.2021.107406},
url = {https://www.sciencedirect.com/science/article/pii/S0045790621003712},
author = {Yaochen Li and Yuting Chen and Sheng Yuan and Jingle Liu and Xi Zhao and Yang Yang and Yuehu Liu},
keywords = {Intelligent transportation, Asymmetric convolution, Global context attention, Small object detection, Deep reinforcement learning},
abstract = {With the rapid development of unmanned aerial vehicle (UAV) technology, the UAV surveillance system has attracted extensive attention in the intelligent transportation community. In this paper, an object detection model with global context cross (YOLO-GCC) is proposed for identifying small sized traffic elements in UAV image sequences. The concept of the asymmetric convolution is introduced to increase the robustness of the object detection model. Moreover, a global context attention module is added to extract more efficient features to ensure the real-time performance while improving the detection accuracy of small objects. The evaluation and comparison results on multiple UAV datasets demonstrate the effectiveness of the proposed model. Furthermore, an intelligent traffic signal scheduling algorithm named Traffic Deep Q-Network(Traffic-DQN) using deep reinforcement learning is introduced, which utilizes the traffic flow data obtained from YOLO-GCC as the benchmark for traffic scheduling. The experimental results demonstrate that the proposed algorithm can effectively alleviate traffic congestion compared with other methods.}
}
@article{ZHANG2022e01999,
title = {A non-destructive method for rapid acquisition of grassland aboveground biomass for satellite ground verification using UAV RGB images},
journal = {Global Ecology and Conservation},
volume = {33},
pages = {e01999},
year = {2022},
issn = {2351-9894},
doi = {https://doi.org/10.1016/j.gecco.2022.e01999},
url = {https://www.sciencedirect.com/science/article/pii/S2351989422000014},
author = {Huifang Zhang and Zhonggang Tang and Binyao Wang and Baoping Meng and Yu Qin and Yi Sun and Yanyan Lv and Jianguo Zhang and Shuhua Yi},
keywords = {Grassland, Unmanned aerial vehicle, Aboveground biomass, Random forest, Vegetation, RGB image},
abstract = {Remote sensing has become an indispensable method for estimating the regional-scale collection of grassland aboveground biomass (AGB). However, the lack of ground verification samples often reduces the inversion accuracy. This paper aimed to find a non-destructive method to quickly obtain grassland AGB at quadrat-scale through unmanned aerial vehicles (UAVs) in a large area. Thus, we proposed and assessed the vertical and horizontal indices from UAV RGB images as predictors of grassland AGB using the random forest (RF) machine learning technique. By comparing the performance of different indices combinations, we found that the model combing the horizontal and vertical indices (RFVH) performed best (R2 = 0.78; RMSE = 24.80 g/m2), followed by the model using only horizontal indices (the RFH model; R2 =0.73; RMSE =26.54 g/m2), and the last was the model using only the vertical index. However, the RFVH model was unsuitable for collecting AGB samples in a large area because the UAVs with RGB cameras failed to obtain vegetation height information in areas with high vegetation coverage. In conclusion, the RFH model can be used to replace the traditional destructive method for collecting ground data over large regions for AGB satellite inversion.}
}
@article{MORAIS2021108081,
title = {The use of machine learning methods to estimate aboveground biomass of grasslands: A review},
journal = {Ecological Indicators},
volume = {130},
pages = {108081},
year = {2021},
issn = {1470-160X},
doi = {https://doi.org/10.1016/j.ecolind.2021.108081},
url = {https://www.sciencedirect.com/science/article/pii/S1470160X21007469},
author = {Tiago G. Morais and Ricardo F.M. Teixeira and Mario Figueiredo and Tiago Domingos},
keywords = {Remote sensing, Spectroscopy, Satellite, Unmanned Aerial Vehicles, Partial least squares regression, Random forests, Multiple linear regression},
abstract = {The study of grasslands using machine learning (ML) methods combined with proximal/remote sensing data (RS) has been steadily increasing in the last decades. Available algorithms range from a primarily academic use to more widespread practical applications intended at helping farm management. Here, we review the use of ML methods applied to aboveground biomass (AGB) estimation in grassland systems. Based on 26 recent papers, we perform a literature review of the topic to identify common practices, namely the relation between estimation performance and the ML method used, data sources, and scale (local/regional). In order to identify the relation between the characteristics of the studies and the estimation accuracy, we use descriptive and correlation analysis. In spite of a surge in the number of papers and application examples, there is no evidence that the estimation performance of the algorithms has been improving over time. In all approaches used by the authors of the papers herein considered, the number of field samples, RS data source, and species composition of the grassland systems are the most relevant variables to explain the estimation accuracy. This accuracy increases with the number of field samples until it plateaus, hinting at the existence of an optimum level for monitoring efforts. Accuracy also increases with the proximity of the sensor to the field, i.e., on average accuracy is higher using field spectroscopy than using satellite data. There is no evidence that any particular ML method is more suited to this problem. The literature also displays significant limitations in terms of its applications of the ML algorithms. For example, a limited number of papers validated the models, casting doubt on the potential of the models for generalized application. Despite those limitations, and considering the advancements verified, we expect that, in the near future, ML methods combined with RS/proximal data will continue to improve and be helpful for farm management.}
}